{
  "best_metric": 2.3844196796417236,
  "best_model_checkpoint": "/scratch/project_465000484/tetkoval/models_data2vec10/data2vec/checkpoint-622000",
  "epoch": 1000.0,
  "global_step": 622000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03,
      "learning_rate": 0.09999678456913183,
      "loss": 13.6491,
      "step": 20
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.09999356913826367,
      "loss": 11.5488,
      "step": 40
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.09999035370739551,
      "loss": 8.6985,
      "step": 60
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.09998713827652735,
      "loss": 7.7035,
      "step": 80
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.09998392284565917,
      "loss": 7.4547,
      "step": 100
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.099980707414791,
      "loss": 7.3448,
      "step": 120
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.09997749198392283,
      "loss": 7.279,
      "step": 140
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.09997427655305466,
      "loss": 7.2674,
      "step": 160
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.09997106112218651,
      "loss": 7.1779,
      "step": 180
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.09996784569131834,
      "loss": 7.0582,
      "step": 200
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.09996463026045016,
      "loss": 7.0021,
      "step": 220
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.099961414829582,
      "loss": 6.9483,
      "step": 240
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.09995819939871382,
      "loss": 6.8934,
      "step": 260
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.09995498396784566,
      "loss": 6.7857,
      "step": 280
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0999517685369775,
      "loss": 6.7509,
      "step": 300
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.09994855310610934,
      "loss": 6.7438,
      "step": 320
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.09994533767524116,
      "loss": 6.7407,
      "step": 340
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.09994212224437299,
      "loss": 6.7358,
      "step": 360
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.09993890681350483,
      "loss": 6.621,
      "step": 380
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.09993569138263667,
      "loss": 6.5296,
      "step": 400
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0999324759517685,
      "loss": 6.5,
      "step": 420
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.09992926052090033,
      "loss": 6.5056,
      "step": 440
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.09992604509003215,
      "loss": 6.5498,
      "step": 460
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.09992282965916399,
      "loss": 6.4884,
      "step": 480
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.09991961422829582,
      "loss": 6.4539,
      "step": 500
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.09991639879742767,
      "loss": 6.3789,
      "step": 520
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0999131833665595,
      "loss": 6.3778,
      "step": 540
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.09990996793569132,
      "loss": 6.3923,
      "step": 560
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.09990675250482316,
      "loss": 6.3165,
      "step": 580
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.09990353707395498,
      "loss": 6.2403,
      "step": 600
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.09990032164308682,
      "loss": 6.2233,
      "step": 620
    },
    {
      "epoch": 1.0,
      "eval_accuracy": {
        "accuracy": 0.06250485889761331
      },
      "eval_loss": 6.241814136505127,
      "eval_runtime": 5.7576,
      "eval_samples_per_second": 2234.084,
      "eval_steps_per_second": 34.91,
      "step": 622
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.09989710621221866,
      "loss": 6.1991,
      "step": 640
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.09989389078135048,
      "loss": 6.2287,
      "step": 660
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.09989067535048232,
      "loss": 6.1763,
      "step": 680
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.09988745991961415,
      "loss": 6.2196,
      "step": 700
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.09988424448874599,
      "loss": 6.2088,
      "step": 720
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.09988102905787782,
      "loss": 6.26,
      "step": 740
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.09987781362700965,
      "loss": 6.1953,
      "step": 760
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.09987459819614149,
      "loss": 6.0712,
      "step": 780
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.09987138276527331,
      "loss": 6.0088,
      "step": 800
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.09986816733440515,
      "loss": 5.9048,
      "step": 820
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.09986495190353697,
      "loss": 5.8444,
      "step": 840
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.09986173647266881,
      "loss": 5.8363,
      "step": 860
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.09985852104180065,
      "loss": 5.803,
      "step": 880
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.09985530561093248,
      "loss": 5.818,
      "step": 900
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.09985209018006432,
      "loss": 5.7842,
      "step": 920
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.09984887474919614,
      "loss": 5.8221,
      "step": 940
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.09984565931832799,
      "loss": 5.8195,
      "step": 960
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.09984244388745982,
      "loss": 5.8673,
      "step": 980
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.09983922845659164,
      "loss": 5.7847,
      "step": 1000
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.09983601302572348,
      "loss": 5.8184,
      "step": 1020
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0998327975948553,
      "loss": 5.736,
      "step": 1040
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.09982958216398714,
      "loss": 5.7348,
      "step": 1060
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.09982636673311898,
      "loss": 5.6701,
      "step": 1080
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.0998231513022508,
      "loss": 5.7228,
      "step": 1100
    },
    {
      "epoch": 1.8,
      "learning_rate": 0.09981993587138265,
      "loss": 5.6418,
      "step": 1120
    },
    {
      "epoch": 1.83,
      "learning_rate": 0.09981672044051447,
      "loss": 5.6877,
      "step": 1140
    },
    {
      "epoch": 1.86,
      "learning_rate": 0.09981350500964631,
      "loss": 5.6367,
      "step": 1160
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.09981028957877813,
      "loss": 5.6349,
      "step": 1180
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.09980707414790997,
      "loss": 5.652,
      "step": 1200
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.09980385871704181,
      "loss": 5.5569,
      "step": 1220
    },
    {
      "epoch": 1.99,
      "learning_rate": 0.09980064328617363,
      "loss": 5.6076,
      "step": 1240
    },
    {
      "epoch": 2.0,
      "eval_accuracy": {
        "accuracy": 0.10557412734198865
      },
      "eval_loss": 5.637336730957031,
      "eval_runtime": 2.549,
      "eval_samples_per_second": 5046.274,
      "eval_steps_per_second": 78.854,
      "step": 1244
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.09979742785530547,
      "loss": 5.5646,
      "step": 1260
    },
    {
      "epoch": 2.06,
      "learning_rate": 0.0997942124244373,
      "loss": 5.5768,
      "step": 1280
    },
    {
      "epoch": 2.09,
      "learning_rate": 0.09979099699356914,
      "loss": 5.4527,
      "step": 1300
    },
    {
      "epoch": 2.12,
      "learning_rate": 0.09978778156270098,
      "loss": 5.4487,
      "step": 1320
    },
    {
      "epoch": 2.15,
      "learning_rate": 0.0997845661318328,
      "loss": 5.4587,
      "step": 1340
    },
    {
      "epoch": 2.19,
      "learning_rate": 0.09978135070096464,
      "loss": 5.5016,
      "step": 1360
    },
    {
      "epoch": 2.22,
      "learning_rate": 0.09977813527009646,
      "loss": 5.4598,
      "step": 1380
    },
    {
      "epoch": 2.25,
      "learning_rate": 0.0997749198392283,
      "loss": 5.4216,
      "step": 1400
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.09977170440836014,
      "loss": 5.5378,
      "step": 1420
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.09976848897749196,
      "loss": 5.532,
      "step": 1440
    },
    {
      "epoch": 2.35,
      "learning_rate": 0.0997652735466238,
      "loss": 5.5273,
      "step": 1460
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.09976205811575563,
      "loss": 5.4754,
      "step": 1480
    },
    {
      "epoch": 2.41,
      "learning_rate": 0.09975884268488747,
      "loss": 5.3785,
      "step": 1500
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.09975562725401929,
      "loss": 5.4143,
      "step": 1520
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.09975241182315113,
      "loss": 5.4212,
      "step": 1540
    },
    {
      "epoch": 2.51,
      "learning_rate": 0.09974919639228297,
      "loss": 5.4466,
      "step": 1560
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.09974598096141479,
      "loss": 5.4186,
      "step": 1580
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.09974276553054663,
      "loss": 5.3533,
      "step": 1600
    },
    {
      "epoch": 2.6,
      "learning_rate": 0.09973955009967846,
      "loss": 5.4559,
      "step": 1620
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.0997363346688103,
      "loss": 5.5808,
      "step": 1640
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.09973311923794213,
      "loss": 5.5416,
      "step": 1660
    },
    {
      "epoch": 2.7,
      "learning_rate": 0.09972990380707396,
      "loss": 5.4486,
      "step": 1680
    },
    {
      "epoch": 2.73,
      "learning_rate": 0.0997266883762058,
      "loss": 5.385,
      "step": 1700
    },
    {
      "epoch": 2.77,
      "learning_rate": 0.09972347294533762,
      "loss": 5.3242,
      "step": 1720
    },
    {
      "epoch": 2.8,
      "learning_rate": 0.09972025751446946,
      "loss": 5.3039,
      "step": 1740
    },
    {
      "epoch": 2.83,
      "learning_rate": 0.0997170420836013,
      "loss": 5.2959,
      "step": 1760
    },
    {
      "epoch": 2.86,
      "learning_rate": 0.09971382665273312,
      "loss": 5.3713,
      "step": 1780
    },
    {
      "epoch": 2.89,
      "learning_rate": 0.09971061122186496,
      "loss": 5.3585,
      "step": 1800
    },
    {
      "epoch": 2.93,
      "learning_rate": 0.09970739579099679,
      "loss": 5.2857,
      "step": 1820
    },
    {
      "epoch": 2.96,
      "learning_rate": 0.09970418036012862,
      "loss": 5.2263,
      "step": 1840
    },
    {
      "epoch": 2.99,
      "learning_rate": 0.09970096492926045,
      "loss": 5.199,
      "step": 1860
    },
    {
      "epoch": 3.0,
      "eval_accuracy": {
        "accuracy": 0.14452305061027754
      },
      "eval_loss": 5.131618499755859,
      "eval_runtime": 2.8523,
      "eval_samples_per_second": 4509.657,
      "eval_steps_per_second": 70.469,
      "step": 1866
    },
    {
      "epoch": 3.02,
      "learning_rate": 0.09969774949839229,
      "loss": 5.2259,
      "step": 1880
    },
    {
      "epoch": 3.05,
      "learning_rate": 0.09969453406752413,
      "loss": 5.342,
      "step": 1900
    },
    {
      "epoch": 3.09,
      "learning_rate": 0.09969131863665595,
      "loss": 5.3206,
      "step": 1920
    },
    {
      "epoch": 3.12,
      "learning_rate": 0.09968810320578779,
      "loss": 5.196,
      "step": 1940
    },
    {
      "epoch": 3.15,
      "learning_rate": 0.09968488777491961,
      "loss": 5.3062,
      "step": 1960
    },
    {
      "epoch": 3.18,
      "learning_rate": 0.09968167234405145,
      "loss": 5.2352,
      "step": 1980
    },
    {
      "epoch": 3.22,
      "learning_rate": 0.09967845691318329,
      "loss": 5.158,
      "step": 2000
    },
    {
      "epoch": 3.25,
      "learning_rate": 0.09967524148231512,
      "loss": 5.1354,
      "step": 2020
    },
    {
      "epoch": 3.28,
      "learning_rate": 0.09967202605144695,
      "loss": 5.1,
      "step": 2040
    },
    {
      "epoch": 3.31,
      "learning_rate": 0.09966881062057878,
      "loss": 5.1011,
      "step": 2060
    },
    {
      "epoch": 3.34,
      "learning_rate": 0.09966559518971062,
      "loss": 5.0927,
      "step": 2080
    },
    {
      "epoch": 3.38,
      "learning_rate": 0.09966237975884246,
      "loss": 5.0612,
      "step": 2100
    },
    {
      "epoch": 3.41,
      "learning_rate": 0.09965916432797428,
      "loss": 5.0732,
      "step": 2120
    },
    {
      "epoch": 3.44,
      "learning_rate": 0.09965594889710612,
      "loss": 5.0571,
      "step": 2140
    },
    {
      "epoch": 3.47,
      "learning_rate": 0.09965273346623794,
      "loss": 5.0404,
      "step": 2160
    },
    {
      "epoch": 3.5,
      "learning_rate": 0.09964951803536978,
      "loss": 5.1057,
      "step": 2180
    },
    {
      "epoch": 3.54,
      "learning_rate": 0.09964630260450161,
      "loss": 5.1496,
      "step": 2200
    },
    {
      "epoch": 3.57,
      "learning_rate": 0.09964308717363345,
      "loss": 5.2482,
      "step": 2220
    },
    {
      "epoch": 3.6,
      "learning_rate": 0.09963987174276528,
      "loss": 5.2285,
      "step": 2240
    },
    {
      "epoch": 3.63,
      "learning_rate": 0.09963665631189711,
      "loss": 5.1911,
      "step": 2260
    },
    {
      "epoch": 3.67,
      "learning_rate": 0.09963344088102895,
      "loss": 5.2111,
      "step": 2280
    },
    {
      "epoch": 3.7,
      "learning_rate": 0.09963022545016077,
      "loss": 5.1245,
      "step": 2300
    },
    {
      "epoch": 3.73,
      "learning_rate": 0.09962701001929261,
      "loss": 5.083,
      "step": 2320
    },
    {
      "epoch": 3.76,
      "learning_rate": 0.09962379458842445,
      "loss": 5.001,
      "step": 2340
    },
    {
      "epoch": 3.79,
      "learning_rate": 0.09962057915755627,
      "loss": 5.096,
      "step": 2360
    },
    {
      "epoch": 3.83,
      "learning_rate": 0.09961736372668811,
      "loss": 5.1144,
      "step": 2380
    },
    {
      "epoch": 3.86,
      "learning_rate": 0.09961414829581994,
      "loss": 5.1127,
      "step": 2400
    },
    {
      "epoch": 3.89,
      "learning_rate": 0.09961093286495178,
      "loss": 5.1493,
      "step": 2420
    },
    {
      "epoch": 3.92,
      "learning_rate": 0.09960771743408361,
      "loss": 5.1041,
      "step": 2440
    },
    {
      "epoch": 3.95,
      "learning_rate": 0.09960450200321544,
      "loss": 5.0211,
      "step": 2460
    },
    {
      "epoch": 3.99,
      "learning_rate": 0.09960128657234728,
      "loss": 4.9438,
      "step": 2480
    },
    {
      "epoch": 4.0,
      "eval_accuracy": {
        "accuracy": 0.16255927855088237
      },
      "eval_loss": 4.9023308753967285,
      "eval_runtime": 3.0886,
      "eval_samples_per_second": 4164.669,
      "eval_steps_per_second": 65.078,
      "step": 2488
    },
    {
      "epoch": 4.02,
      "learning_rate": 0.0995980711414791,
      "loss": 4.9284,
      "step": 2500
    },
    {
      "epoch": 4.05,
      "learning_rate": 0.09959485571061094,
      "loss": 4.9855,
      "step": 2520
    },
    {
      "epoch": 4.08,
      "learning_rate": 0.09959164027974277,
      "loss": 5.1526,
      "step": 2540
    },
    {
      "epoch": 4.12,
      "learning_rate": 0.0995884248488746,
      "loss": 4.9484,
      "step": 2560
    },
    {
      "epoch": 4.15,
      "learning_rate": 0.09958520941800644,
      "loss": 4.9349,
      "step": 2580
    },
    {
      "epoch": 4.18,
      "learning_rate": 0.09958199398713827,
      "loss": 4.8552,
      "step": 2600
    },
    {
      "epoch": 4.21,
      "learning_rate": 0.0995787785562701,
      "loss": 4.8964,
      "step": 2620
    },
    {
      "epoch": 4.24,
      "learning_rate": 0.09957556312540193,
      "loss": 4.9017,
      "step": 2640
    },
    {
      "epoch": 4.28,
      "learning_rate": 0.09957234769453377,
      "loss": 4.9258,
      "step": 2660
    },
    {
      "epoch": 4.31,
      "learning_rate": 0.09956913226366561,
      "loss": 4.9605,
      "step": 2680
    },
    {
      "epoch": 4.34,
      "learning_rate": 0.09956591683279743,
      "loss": 4.9776,
      "step": 2700
    },
    {
      "epoch": 4.37,
      "learning_rate": 0.09956270140192927,
      "loss": 4.9127,
      "step": 2720
    },
    {
      "epoch": 4.41,
      "learning_rate": 0.0995594859710611,
      "loss": 4.9487,
      "step": 2740
    },
    {
      "epoch": 4.44,
      "learning_rate": 0.09955627054019292,
      "loss": 4.9749,
      "step": 2760
    },
    {
      "epoch": 4.47,
      "learning_rate": 0.09955305510932477,
      "loss": 4.8493,
      "step": 2780
    },
    {
      "epoch": 4.5,
      "learning_rate": 0.0995498396784566,
      "loss": 4.8358,
      "step": 2800
    },
    {
      "epoch": 4.53,
      "learning_rate": 0.09954662424758844,
      "loss": 4.9083,
      "step": 2820
    },
    {
      "epoch": 4.57,
      "learning_rate": 0.09954340881672026,
      "loss": 4.9056,
      "step": 2840
    },
    {
      "epoch": 4.6,
      "learning_rate": 0.09954019338585209,
      "loss": 4.833,
      "step": 2860
    },
    {
      "epoch": 4.63,
      "learning_rate": 0.09953697795498394,
      "loss": 4.8746,
      "step": 2880
    },
    {
      "epoch": 4.66,
      "learning_rate": 0.09953376252411576,
      "loss": 4.8603,
      "step": 2900
    },
    {
      "epoch": 4.69,
      "learning_rate": 0.0995305470932476,
      "loss": 4.8315,
      "step": 2920
    },
    {
      "epoch": 4.73,
      "learning_rate": 0.09952733166237943,
      "loss": 4.8589,
      "step": 2940
    },
    {
      "epoch": 4.76,
      "learning_rate": 0.09952411623151125,
      "loss": 4.8326,
      "step": 2960
    },
    {
      "epoch": 4.79,
      "learning_rate": 0.09952090080064309,
      "loss": 4.8367,
      "step": 2980
    },
    {
      "epoch": 4.82,
      "learning_rate": 0.09951768536977493,
      "loss": 4.8203,
      "step": 3000
    },
    {
      "epoch": 4.86,
      "learning_rate": 0.09951446993890677,
      "loss": 4.7814,
      "step": 3020
    },
    {
      "epoch": 4.89,
      "learning_rate": 0.09951125450803859,
      "loss": 4.7196,
      "step": 3040
    },
    {
      "epoch": 4.92,
      "learning_rate": 0.09950803907717043,
      "loss": 4.8119,
      "step": 3060
    },
    {
      "epoch": 4.95,
      "learning_rate": 0.09950482364630225,
      "loss": 4.9157,
      "step": 3080
    },
    {
      "epoch": 4.98,
      "learning_rate": 0.09950160821543408,
      "loss": 4.9344,
      "step": 3100
    },
    {
      "epoch": 5.0,
      "eval_accuracy": {
        "accuracy": 0.17647516131540075
      },
      "eval_loss": 4.981673240661621,
      "eval_runtime": 2.8398,
      "eval_samples_per_second": 4529.56,
      "eval_steps_per_second": 70.78,
      "step": 3110
    },
    {
      "epoch": 5.02,
      "learning_rate": 0.09949839278456593,
      "loss": 4.8989,
      "step": 3120
    },
    {
      "epoch": 5.05,
      "learning_rate": 0.09949517735369776,
      "loss": 4.8522,
      "step": 3140
    },
    {
      "epoch": 5.08,
      "learning_rate": 0.0994919619228296,
      "loss": 4.6839,
      "step": 3160
    },
    {
      "epoch": 5.11,
      "learning_rate": 0.09948874649196142,
      "loss": 4.7408,
      "step": 3180
    },
    {
      "epoch": 5.14,
      "learning_rate": 0.09948553106109324,
      "loss": 4.7349,
      "step": 3200
    },
    {
      "epoch": 5.18,
      "learning_rate": 0.0994823156302251,
      "loss": 4.7131,
      "step": 3220
    },
    {
      "epoch": 5.21,
      "learning_rate": 0.09947910019935692,
      "loss": 4.7435,
      "step": 3240
    },
    {
      "epoch": 5.24,
      "learning_rate": 0.09947588476848876,
      "loss": 4.8051,
      "step": 3260
    },
    {
      "epoch": 5.27,
      "learning_rate": 0.09947266933762058,
      "loss": 4.7384,
      "step": 3280
    },
    {
      "epoch": 5.31,
      "learning_rate": 0.09946945390675241,
      "loss": 4.7072,
      "step": 3300
    },
    {
      "epoch": 5.34,
      "learning_rate": 0.09946623847588425,
      "loss": 4.6709,
      "step": 3320
    },
    {
      "epoch": 5.37,
      "learning_rate": 0.09946302304501609,
      "loss": 4.7998,
      "step": 3340
    },
    {
      "epoch": 5.4,
      "learning_rate": 0.09945980761414792,
      "loss": 4.7759,
      "step": 3360
    },
    {
      "epoch": 5.43,
      "learning_rate": 0.09945659218327975,
      "loss": 4.7505,
      "step": 3380
    },
    {
      "epoch": 5.47,
      "learning_rate": 0.09945337675241157,
      "loss": 4.7578,
      "step": 3400
    },
    {
      "epoch": 5.5,
      "learning_rate": 0.09945016132154341,
      "loss": 4.7909,
      "step": 3420
    },
    {
      "epoch": 5.53,
      "learning_rate": 0.09944694589067524,
      "loss": 4.8086,
      "step": 3440
    },
    {
      "epoch": 5.56,
      "learning_rate": 0.09944373045980709,
      "loss": 4.8701,
      "step": 3460
    },
    {
      "epoch": 5.59,
      "learning_rate": 0.09944051502893891,
      "loss": 4.935,
      "step": 3480
    },
    {
      "epoch": 5.63,
      "learning_rate": 0.09943729959807074,
      "loss": 4.7969,
      "step": 3500
    },
    {
      "epoch": 5.66,
      "learning_rate": 0.09943408416720258,
      "loss": 4.7167,
      "step": 3520
    },
    {
      "epoch": 5.69,
      "learning_rate": 0.0994308687363344,
      "loss": 4.7008,
      "step": 3540
    },
    {
      "epoch": 5.72,
      "learning_rate": 0.09942765330546625,
      "loss": 4.6645,
      "step": 3560
    },
    {
      "epoch": 5.76,
      "learning_rate": 0.09942443787459808,
      "loss": 4.6642,
      "step": 3580
    },
    {
      "epoch": 5.79,
      "learning_rate": 0.0994212224437299,
      "loss": 4.7739,
      "step": 3600
    },
    {
      "epoch": 5.82,
      "learning_rate": 0.09941800701286174,
      "loss": 4.6545,
      "step": 3620
    },
    {
      "epoch": 5.85,
      "learning_rate": 0.09941479158199357,
      "loss": 4.7128,
      "step": 3640
    },
    {
      "epoch": 5.88,
      "learning_rate": 0.0994115761511254,
      "loss": 4.6564,
      "step": 3660
    },
    {
      "epoch": 5.92,
      "learning_rate": 0.09940836072025724,
      "loss": 4.6712,
      "step": 3680
    },
    {
      "epoch": 5.95,
      "learning_rate": 0.09940514528938908,
      "loss": 4.5818,
      "step": 3700
    },
    {
      "epoch": 5.98,
      "learning_rate": 0.09940192985852091,
      "loss": 4.6819,
      "step": 3720
    },
    {
      "epoch": 6.0,
      "eval_accuracy": {
        "accuracy": 0.1966104330249553
      },
      "eval_loss": 4.7507476806640625,
      "eval_runtime": 2.9217,
      "eval_samples_per_second": 4402.585,
      "eval_steps_per_second": 68.796,
      "step": 3732
    },
    {
      "epoch": 6.01,
      "learning_rate": 0.09939871442765273,
      "loss": 4.6879,
      "step": 3740
    },
    {
      "epoch": 6.05,
      "learning_rate": 0.09939549899678457,
      "loss": 4.6006,
      "step": 3760
    },
    {
      "epoch": 6.08,
      "learning_rate": 0.0993922835659164,
      "loss": 4.5833,
      "step": 3780
    },
    {
      "epoch": 6.11,
      "learning_rate": 0.09938906813504825,
      "loss": 4.5602,
      "step": 3800
    },
    {
      "epoch": 6.14,
      "learning_rate": 0.09938585270418007,
      "loss": 4.5739,
      "step": 3820
    },
    {
      "epoch": 6.17,
      "learning_rate": 0.0993826372733119,
      "loss": 4.5447,
      "step": 3840
    },
    {
      "epoch": 6.21,
      "learning_rate": 0.09937942184244374,
      "loss": 4.6195,
      "step": 3860
    },
    {
      "epoch": 6.24,
      "learning_rate": 0.09937620641157556,
      "loss": 4.5773,
      "step": 3880
    },
    {
      "epoch": 6.27,
      "learning_rate": 0.09937299098070741,
      "loss": 4.5934,
      "step": 3900
    },
    {
      "epoch": 6.3,
      "learning_rate": 0.09936977554983924,
      "loss": 4.6355,
      "step": 3920
    },
    {
      "epoch": 6.33,
      "learning_rate": 0.09936656011897106,
      "loss": 4.723,
      "step": 3940
    },
    {
      "epoch": 6.37,
      "learning_rate": 0.0993633446881029,
      "loss": 4.6553,
      "step": 3960
    },
    {
      "epoch": 6.4,
      "learning_rate": 0.09936012925723472,
      "loss": 4.6187,
      "step": 3980
    },
    {
      "epoch": 6.43,
      "learning_rate": 0.09935691382636656,
      "loss": 4.6223,
      "step": 4000
    },
    {
      "epoch": 6.46,
      "learning_rate": 0.0993536983954984,
      "loss": 4.703,
      "step": 4020
    },
    {
      "epoch": 6.5,
      "learning_rate": 0.09935048296463023,
      "loss": 4.6562,
      "step": 4040
    },
    {
      "epoch": 6.53,
      "learning_rate": 0.09934726753376207,
      "loss": 4.5413,
      "step": 4060
    },
    {
      "epoch": 6.56,
      "learning_rate": 0.09934405210289389,
      "loss": 4.579,
      "step": 4080
    },
    {
      "epoch": 6.59,
      "learning_rate": 0.09934083667202573,
      "loss": 4.6247,
      "step": 4100
    },
    {
      "epoch": 6.62,
      "learning_rate": 0.09933762124115755,
      "loss": 4.5485,
      "step": 4120
    },
    {
      "epoch": 6.66,
      "learning_rate": 0.09933440581028939,
      "loss": 4.5273,
      "step": 4140
    },
    {
      "epoch": 6.69,
      "learning_rate": 0.09933119037942123,
      "loss": 4.6088,
      "step": 4160
    },
    {
      "epoch": 6.72,
      "learning_rate": 0.09932797494855305,
      "loss": 4.6354,
      "step": 4180
    },
    {
      "epoch": 6.75,
      "learning_rate": 0.0993247595176849,
      "loss": 4.5968,
      "step": 4200
    },
    {
      "epoch": 6.78,
      "learning_rate": 0.09932154408681672,
      "loss": 4.6525,
      "step": 4220
    },
    {
      "epoch": 6.82,
      "learning_rate": 0.09931832865594856,
      "loss": 4.5833,
      "step": 4240
    },
    {
      "epoch": 6.85,
      "learning_rate": 0.0993151132250804,
      "loss": 4.5767,
      "step": 4260
    },
    {
      "epoch": 6.88,
      "learning_rate": 0.09931189779421222,
      "loss": 4.4416,
      "step": 4280
    },
    {
      "epoch": 6.91,
      "learning_rate": 0.09930868236334406,
      "loss": 4.4898,
      "step": 4300
    },
    {
      "epoch": 6.95,
      "learning_rate": 0.09930546693247588,
      "loss": 4.6515,
      "step": 4320
    },
    {
      "epoch": 6.98,
      "learning_rate": 0.09930225150160772,
      "loss": 4.5871,
      "step": 4340
    },
    {
      "epoch": 7.0,
      "eval_accuracy": {
        "accuracy": 0.2030630490554303
      },
      "eval_loss": 4.626713752746582,
      "eval_runtime": 2.5512,
      "eval_samples_per_second": 5041.964,
      "eval_steps_per_second": 78.787,
      "step": 4354
    },
    {
      "epoch": 7.01,
      "learning_rate": 0.09929903607073956,
      "loss": 4.6532,
      "step": 4360
    },
    {
      "epoch": 7.04,
      "learning_rate": 0.09929582063987138,
      "loss": 4.5333,
      "step": 4380
    },
    {
      "epoch": 7.07,
      "learning_rate": 0.09929260520900322,
      "loss": 4.608,
      "step": 4400
    },
    {
      "epoch": 7.11,
      "learning_rate": 0.09928938977813505,
      "loss": 4.5888,
      "step": 4420
    },
    {
      "epoch": 7.14,
      "learning_rate": 0.09928617434726689,
      "loss": 4.6135,
      "step": 4440
    },
    {
      "epoch": 7.17,
      "learning_rate": 0.09928295891639871,
      "loss": 4.531,
      "step": 4460
    },
    {
      "epoch": 7.2,
      "learning_rate": 0.09927974348553055,
      "loss": 4.5463,
      "step": 4480
    },
    {
      "epoch": 7.23,
      "learning_rate": 0.09927652805466239,
      "loss": 4.5514,
      "step": 4500
    },
    {
      "epoch": 7.27,
      "learning_rate": 0.09927331262379421,
      "loss": 4.4581,
      "step": 4520
    },
    {
      "epoch": 7.3,
      "learning_rate": 0.09927009719292605,
      "loss": 4.5238,
      "step": 4540
    },
    {
      "epoch": 7.33,
      "learning_rate": 0.09926688176205788,
      "loss": 4.5471,
      "step": 4560
    },
    {
      "epoch": 7.36,
      "learning_rate": 0.09926366633118971,
      "loss": 4.4944,
      "step": 4580
    },
    {
      "epoch": 7.4,
      "learning_rate": 0.09926045090032155,
      "loss": 4.6011,
      "step": 4600
    },
    {
      "epoch": 7.43,
      "learning_rate": 0.09925723546945338,
      "loss": 4.5785,
      "step": 4620
    },
    {
      "epoch": 7.46,
      "learning_rate": 0.09925402003858522,
      "loss": 4.6287,
      "step": 4640
    },
    {
      "epoch": 7.49,
      "learning_rate": 0.09925080460771704,
      "loss": 4.5918,
      "step": 4660
    },
    {
      "epoch": 7.52,
      "learning_rate": 0.09924758917684888,
      "loss": 4.4579,
      "step": 4680
    },
    {
      "epoch": 7.56,
      "learning_rate": 0.09924437374598072,
      "loss": 4.5283,
      "step": 4700
    },
    {
      "epoch": 7.59,
      "learning_rate": 0.09924115831511254,
      "loss": 4.5147,
      "step": 4720
    },
    {
      "epoch": 7.62,
      "learning_rate": 0.09923794288424438,
      "loss": 4.4288,
      "step": 4740
    },
    {
      "epoch": 7.65,
      "learning_rate": 0.0992347274533762,
      "loss": 4.4434,
      "step": 4760
    },
    {
      "epoch": 7.68,
      "learning_rate": 0.09923151202250804,
      "loss": 4.5032,
      "step": 4780
    },
    {
      "epoch": 7.72,
      "learning_rate": 0.09922829659163988,
      "loss": 4.4967,
      "step": 4800
    },
    {
      "epoch": 7.75,
      "learning_rate": 0.09922508116077171,
      "loss": 4.4626,
      "step": 4820
    },
    {
      "epoch": 7.78,
      "learning_rate": 0.09922186572990355,
      "loss": 4.5191,
      "step": 4840
    },
    {
      "epoch": 7.81,
      "learning_rate": 0.09921865029903537,
      "loss": 4.5132,
      "step": 4860
    },
    {
      "epoch": 7.85,
      "learning_rate": 0.09921543486816721,
      "loss": 4.4015,
      "step": 4880
    },
    {
      "epoch": 7.88,
      "learning_rate": 0.09921221943729903,
      "loss": 4.4403,
      "step": 4900
    },
    {
      "epoch": 7.91,
      "learning_rate": 0.09920900400643087,
      "loss": 4.3817,
      "step": 4920
    },
    {
      "epoch": 7.94,
      "learning_rate": 0.09920578857556271,
      "loss": 4.3798,
      "step": 4940
    },
    {
      "epoch": 7.97,
      "learning_rate": 0.09920257314469454,
      "loss": 4.4866,
      "step": 4960
    },
    {
      "epoch": 8.0,
      "eval_accuracy": {
        "accuracy": 0.20391821503537277
      },
      "eval_loss": 4.572452068328857,
      "eval_runtime": 2.8521,
      "eval_samples_per_second": 4509.965,
      "eval_steps_per_second": 70.474,
      "step": 4976
    },
    {
      "epoch": 8.01,
      "learning_rate": 0.09919935771382637,
      "loss": 4.4567,
      "step": 4980
    },
    {
      "epoch": 8.04,
      "learning_rate": 0.0991961422829582,
      "loss": 4.4331,
      "step": 5000
    },
    {
      "epoch": 8.07,
      "learning_rate": 0.09919292685209004,
      "loss": 4.347,
      "step": 5020
    },
    {
      "epoch": 8.1,
      "learning_rate": 0.09918971142122188,
      "loss": 4.3704,
      "step": 5040
    },
    {
      "epoch": 8.14,
      "learning_rate": 0.0991864959903537,
      "loss": 4.3435,
      "step": 5060
    },
    {
      "epoch": 8.17,
      "learning_rate": 0.09918328055948554,
      "loss": 4.4493,
      "step": 5080
    },
    {
      "epoch": 8.2,
      "learning_rate": 0.09918006512861736,
      "loss": 4.4145,
      "step": 5100
    },
    {
      "epoch": 8.23,
      "learning_rate": 0.0991768496977492,
      "loss": 4.4722,
      "step": 5120
    },
    {
      "epoch": 8.26,
      "learning_rate": 0.09917363426688104,
      "loss": 4.4127,
      "step": 5140
    },
    {
      "epoch": 8.3,
      "learning_rate": 0.09917041883601287,
      "loss": 4.4353,
      "step": 5160
    },
    {
      "epoch": 8.33,
      "learning_rate": 0.0991672034051447,
      "loss": 4.3924,
      "step": 5180
    },
    {
      "epoch": 8.36,
      "learning_rate": 0.09916398797427653,
      "loss": 4.3852,
      "step": 5200
    },
    {
      "epoch": 8.39,
      "learning_rate": 0.09916077254340837,
      "loss": 4.3637,
      "step": 5220
    },
    {
      "epoch": 8.42,
      "learning_rate": 0.09915755711254019,
      "loss": 4.3338,
      "step": 5240
    },
    {
      "epoch": 8.46,
      "learning_rate": 0.09915434168167203,
      "loss": 4.3424,
      "step": 5260
    },
    {
      "epoch": 8.49,
      "learning_rate": 0.09915112625080387,
      "loss": 4.3428,
      "step": 5280
    },
    {
      "epoch": 8.52,
      "learning_rate": 0.0991479108199357,
      "loss": 4.3618,
      "step": 5300
    },
    {
      "epoch": 8.55,
      "learning_rate": 0.09914469538906753,
      "loss": 4.3853,
      "step": 5320
    },
    {
      "epoch": 8.59,
      "learning_rate": 0.09914147995819936,
      "loss": 4.4279,
      "step": 5340
    },
    {
      "epoch": 8.62,
      "learning_rate": 0.0991382645273312,
      "loss": 4.4365,
      "step": 5360
    },
    {
      "epoch": 8.65,
      "learning_rate": 0.09913504909646303,
      "loss": 4.4364,
      "step": 5380
    },
    {
      "epoch": 8.68,
      "learning_rate": 0.09913183366559486,
      "loss": 4.4131,
      "step": 5400
    },
    {
      "epoch": 8.71,
      "learning_rate": 0.0991286182347267,
      "loss": 4.3192,
      "step": 5420
    },
    {
      "epoch": 8.75,
      "learning_rate": 0.09912540280385852,
      "loss": 4.3312,
      "step": 5440
    },
    {
      "epoch": 8.78,
      "learning_rate": 0.09912218737299036,
      "loss": 4.3304,
      "step": 5460
    },
    {
      "epoch": 8.81,
      "learning_rate": 0.0991189719421222,
      "loss": 4.3487,
      "step": 5480
    },
    {
      "epoch": 8.84,
      "learning_rate": 0.09911575651125402,
      "loss": 4.3471,
      "step": 5500
    },
    {
      "epoch": 8.87,
      "learning_rate": 0.09911254108038586,
      "loss": 4.3844,
      "step": 5520
    },
    {
      "epoch": 8.91,
      "learning_rate": 0.09910932564951769,
      "loss": 4.4464,
      "step": 5540
    },
    {
      "epoch": 8.94,
      "learning_rate": 0.09910611021864953,
      "loss": 4.3541,
      "step": 5560
    },
    {
      "epoch": 8.97,
      "learning_rate": 0.09910289478778135,
      "loss": 4.3591,
      "step": 5580
    },
    {
      "epoch": 9.0,
      "eval_accuracy": {
        "accuracy": 0.2292622249863951
      },
      "eval_loss": 4.353863716125488,
      "eval_runtime": 2.416,
      "eval_samples_per_second": 5324.018,
      "eval_steps_per_second": 83.194,
      "step": 5598
    },
    {
      "epoch": 9.0,
      "learning_rate": 0.09909967935691319,
      "loss": 4.3427,
      "step": 5600
    },
    {
      "epoch": 9.04,
      "learning_rate": 0.09909646392604503,
      "loss": 4.2871,
      "step": 5620
    },
    {
      "epoch": 9.07,
      "learning_rate": 0.09909324849517685,
      "loss": 4.2704,
      "step": 5640
    },
    {
      "epoch": 9.1,
      "learning_rate": 0.09909003306430869,
      "loss": 4.2941,
      "step": 5660
    },
    {
      "epoch": 9.13,
      "learning_rate": 0.09908681763344052,
      "loss": 4.284,
      "step": 5680
    },
    {
      "epoch": 9.16,
      "learning_rate": 0.09908360220257234,
      "loss": 4.4148,
      "step": 5700
    },
    {
      "epoch": 9.2,
      "learning_rate": 0.09908038677170419,
      "loss": 4.4416,
      "step": 5720
    },
    {
      "epoch": 9.23,
      "learning_rate": 0.09907717134083602,
      "loss": 4.3858,
      "step": 5740
    },
    {
      "epoch": 9.26,
      "learning_rate": 0.09907395590996786,
      "loss": 4.4215,
      "step": 5760
    },
    {
      "epoch": 9.29,
      "learning_rate": 0.09907074047909968,
      "loss": 4.3523,
      "step": 5780
    },
    {
      "epoch": 9.32,
      "learning_rate": 0.09906752504823152,
      "loss": 4.4161,
      "step": 5800
    },
    {
      "epoch": 9.36,
      "learning_rate": 0.09906430961736336,
      "loss": 4.3963,
      "step": 5820
    },
    {
      "epoch": 9.39,
      "learning_rate": 0.09906109418649518,
      "loss": 4.3166,
      "step": 5840
    },
    {
      "epoch": 9.42,
      "learning_rate": 0.09905787875562702,
      "loss": 4.3153,
      "step": 5860
    },
    {
      "epoch": 9.45,
      "learning_rate": 0.09905466332475885,
      "loss": 4.2412,
      "step": 5880
    },
    {
      "epoch": 9.49,
      "learning_rate": 0.09905144789389068,
      "loss": 4.2981,
      "step": 5900
    },
    {
      "epoch": 9.52,
      "learning_rate": 0.09904823246302251,
      "loss": 4.3913,
      "step": 5920
    },
    {
      "epoch": 9.55,
      "learning_rate": 0.09904501703215435,
      "loss": 4.3359,
      "step": 5940
    },
    {
      "epoch": 9.58,
      "learning_rate": 0.09904180160128619,
      "loss": 4.3451,
      "step": 5960
    },
    {
      "epoch": 9.61,
      "learning_rate": 0.09903858617041801,
      "loss": 4.3169,
      "step": 5980
    },
    {
      "epoch": 9.65,
      "learning_rate": 0.09903537073954985,
      "loss": 4.2993,
      "step": 6000
    },
    {
      "epoch": 9.68,
      "learning_rate": 0.09903215530868167,
      "loss": 4.3427,
      "step": 6020
    },
    {
      "epoch": 9.71,
      "learning_rate": 0.0990289398778135,
      "loss": 4.336,
      "step": 6040
    },
    {
      "epoch": 9.74,
      "learning_rate": 0.09902572444694535,
      "loss": 4.3617,
      "step": 6060
    },
    {
      "epoch": 9.77,
      "learning_rate": 0.09902250901607718,
      "loss": 4.3433,
      "step": 6080
    },
    {
      "epoch": 9.81,
      "learning_rate": 0.09901929358520901,
      "loss": 4.3218,
      "step": 6100
    },
    {
      "epoch": 9.84,
      "learning_rate": 0.09901607815434084,
      "loss": 4.2927,
      "step": 6120
    },
    {
      "epoch": 9.87,
      "learning_rate": 0.09901286272347266,
      "loss": 4.3321,
      "step": 6140
    },
    {
      "epoch": 9.9,
      "learning_rate": 0.09900964729260452,
      "loss": 4.3471,
      "step": 6160
    },
    {
      "epoch": 9.94,
      "learning_rate": 0.09900643186173634,
      "loss": 4.3107,
      "step": 6180
    },
    {
      "epoch": 9.97,
      "learning_rate": 0.09900321643086818,
      "loss": 4.3063,
      "step": 6200
    },
    {
      "epoch": 10.0,
      "learning_rate": 0.099000001,
      "loss": 4.2736,
      "step": 6220
    },
    {
      "epoch": 10.0,
      "eval_accuracy": {
        "accuracy": 0.2270076964938195
      },
      "eval_loss": 4.270135879516602,
      "eval_runtime": 2.5595,
      "eval_samples_per_second": 5025.59,
      "eval_steps_per_second": 78.531,
      "step": 6220
    },
    {
      "epoch": 10.03,
      "learning_rate": 0.09899678556913183,
      "loss": 4.2517,
      "step": 6240
    },
    {
      "epoch": 10.06,
      "learning_rate": 0.09899357013826367,
      "loss": 4.1628,
      "step": 6260
    },
    {
      "epoch": 10.1,
      "learning_rate": 0.0989903547073955,
      "loss": 4.2411,
      "step": 6280
    },
    {
      "epoch": 10.13,
      "learning_rate": 0.09898713927652734,
      "loss": 4.3042,
      "step": 6300
    },
    {
      "epoch": 10.16,
      "learning_rate": 0.09898392384565917,
      "loss": 4.2627,
      "step": 6320
    },
    {
      "epoch": 10.19,
      "learning_rate": 0.098980708414791,
      "loss": 4.2728,
      "step": 6340
    },
    {
      "epoch": 10.23,
      "learning_rate": 0.09897749298392283,
      "loss": 4.2905,
      "step": 6360
    },
    {
      "epoch": 10.26,
      "learning_rate": 0.09897427755305467,
      "loss": 4.2681,
      "step": 6380
    },
    {
      "epoch": 10.29,
      "learning_rate": 0.09897106212218651,
      "loss": 4.2836,
      "step": 6400
    },
    {
      "epoch": 10.32,
      "learning_rate": 0.09896784669131833,
      "loss": 4.2337,
      "step": 6420
    },
    {
      "epoch": 10.35,
      "learning_rate": 0.09896463126045017,
      "loss": 4.2637,
      "step": 6440
    },
    {
      "epoch": 10.39,
      "learning_rate": 0.098961415829582,
      "loss": 4.2598,
      "step": 6460
    },
    {
      "epoch": 10.42,
      "learning_rate": 0.09895820039871382,
      "loss": 4.2206,
      "step": 6480
    },
    {
      "epoch": 10.45,
      "learning_rate": 0.09895498496784567,
      "loss": 4.2587,
      "step": 6500
    },
    {
      "epoch": 10.48,
      "learning_rate": 0.0989517695369775,
      "loss": 4.3388,
      "step": 6520
    },
    {
      "epoch": 10.51,
      "learning_rate": 0.09894871487765275,
      "loss": 4.3055,
      "step": 6540
    },
    {
      "epoch": 10.55,
      "learning_rate": 0.09894549944678457,
      "loss": 4.3658,
      "step": 6560
    },
    {
      "epoch": 10.58,
      "learning_rate": 0.0989422840159164,
      "loss": 4.3203,
      "step": 6580
    },
    {
      "epoch": 10.61,
      "learning_rate": 0.09893906858504824,
      "loss": 4.2938,
      "step": 6600
    },
    {
      "epoch": 10.64,
      "learning_rate": 0.09893585315418006,
      "loss": 4.3068,
      "step": 6620
    },
    {
      "epoch": 10.68,
      "learning_rate": 0.09893263772331191,
      "loss": 4.3806,
      "step": 6640
    },
    {
      "epoch": 10.71,
      "learning_rate": 0.09892942229244374,
      "loss": 4.3402,
      "step": 6660
    },
    {
      "epoch": 10.74,
      "learning_rate": 0.09892620686157556,
      "loss": 4.2391,
      "step": 6680
    },
    {
      "epoch": 10.77,
      "learning_rate": 0.0989229914307074,
      "loss": 4.2393,
      "step": 6700
    },
    {
      "epoch": 10.8,
      "learning_rate": 0.09891977599983923,
      "loss": 4.2301,
      "step": 6720
    },
    {
      "epoch": 10.84,
      "learning_rate": 0.09891656056897107,
      "loss": 4.1812,
      "step": 6740
    },
    {
      "epoch": 10.87,
      "learning_rate": 0.0989133451381029,
      "loss": 4.1943,
      "step": 6760
    },
    {
      "epoch": 10.9,
      "learning_rate": 0.09891012970723473,
      "loss": 4.146,
      "step": 6780
    },
    {
      "epoch": 10.93,
      "learning_rate": 0.09890691427636657,
      "loss": 4.1812,
      "step": 6800
    },
    {
      "epoch": 10.96,
      "learning_rate": 0.09890369884549839,
      "loss": 4.1099,
      "step": 6820
    },
    {
      "epoch": 11.0,
      "learning_rate": 0.09890048341463023,
      "loss": 4.1732,
      "step": 6840
    },
    {
      "epoch": 11.0,
      "eval_accuracy": {
        "accuracy": 0.23742517297675503
      },
      "eval_loss": 4.2417216300964355,
      "eval_runtime": 2.5013,
      "eval_samples_per_second": 5142.458,
      "eval_steps_per_second": 80.357,
      "step": 6842
    },
    {
      "epoch": 11.03,
      "learning_rate": 0.09889726798376205,
      "loss": 4.1802,
      "step": 6860
    },
    {
      "epoch": 11.06,
      "learning_rate": 0.0988940525528939,
      "loss": 4.1664,
      "step": 6880
    },
    {
      "epoch": 11.09,
      "learning_rate": 0.09889083712202573,
      "loss": 4.2295,
      "step": 6900
    },
    {
      "epoch": 11.13,
      "learning_rate": 0.09888762169115756,
      "loss": 4.2186,
      "step": 6920
    },
    {
      "epoch": 11.16,
      "learning_rate": 0.0988844062602894,
      "loss": 4.2069,
      "step": 6940
    },
    {
      "epoch": 11.19,
      "learning_rate": 0.09888119082942122,
      "loss": 4.1836,
      "step": 6960
    },
    {
      "epoch": 11.22,
      "learning_rate": 0.09887797539855306,
      "loss": 4.1304,
      "step": 6980
    },
    {
      "epoch": 11.25,
      "learning_rate": 0.0988747599676849,
      "loss": 4.1793,
      "step": 7000
    },
    {
      "epoch": 11.29,
      "learning_rate": 0.09887154453681672,
      "loss": 4.1729,
      "step": 7020
    },
    {
      "epoch": 11.32,
      "learning_rate": 0.09886832910594856,
      "loss": 4.1612,
      "step": 7040
    },
    {
      "epoch": 11.35,
      "learning_rate": 0.09886511367508038,
      "loss": 4.19,
      "step": 7060
    },
    {
      "epoch": 11.38,
      "learning_rate": 0.09886189824421222,
      "loss": 4.183,
      "step": 7080
    },
    {
      "epoch": 11.41,
      "learning_rate": 0.09885868281334406,
      "loss": 4.1924,
      "step": 7100
    },
    {
      "epoch": 11.45,
      "learning_rate": 0.09885546738247589,
      "loss": 4.19,
      "step": 7120
    },
    {
      "epoch": 11.48,
      "learning_rate": 0.09885225195160773,
      "loss": 4.2374,
      "step": 7140
    },
    {
      "epoch": 11.51,
      "learning_rate": 0.09884903652073955,
      "loss": 4.1637,
      "step": 7160
    },
    {
      "epoch": 11.54,
      "learning_rate": 0.09884582108987139,
      "loss": 4.1757,
      "step": 7180
    },
    {
      "epoch": 11.58,
      "learning_rate": 0.09884260565900321,
      "loss": 4.1794,
      "step": 7200
    },
    {
      "epoch": 11.61,
      "learning_rate": 0.09883939022813505,
      "loss": 4.1341,
      "step": 7220
    },
    {
      "epoch": 11.64,
      "learning_rate": 0.09883617479726689,
      "loss": 4.1704,
      "step": 7240
    },
    {
      "epoch": 11.67,
      "learning_rate": 0.09883295936639871,
      "loss": 4.1688,
      "step": 7260
    },
    {
      "epoch": 11.7,
      "learning_rate": 0.09882974393553055,
      "loss": 4.1967,
      "step": 7280
    },
    {
      "epoch": 11.74,
      "learning_rate": 0.09882652850466238,
      "loss": 4.231,
      "step": 7300
    },
    {
      "epoch": 11.77,
      "learning_rate": 0.09882331307379422,
      "loss": 4.2391,
      "step": 7320
    },
    {
      "epoch": 11.8,
      "learning_rate": 0.09882009764292606,
      "loss": 4.1729,
      "step": 7340
    },
    {
      "epoch": 11.83,
      "learning_rate": 0.09881688221205788,
      "loss": 4.2201,
      "step": 7360
    },
    {
      "epoch": 11.86,
      "learning_rate": 0.09881366678118972,
      "loss": 4.1932,
      "step": 7380
    },
    {
      "epoch": 11.9,
      "learning_rate": 0.09881045135032154,
      "loss": 4.1987,
      "step": 7400
    },
    {
      "epoch": 11.93,
      "learning_rate": 0.09880723591945338,
      "loss": 4.202,
      "step": 7420
    },
    {
      "epoch": 11.96,
      "learning_rate": 0.09880402048858522,
      "loss": 4.1565,
      "step": 7440
    },
    {
      "epoch": 11.99,
      "learning_rate": 0.09880080505771704,
      "loss": 4.1828,
      "step": 7460
    },
    {
      "epoch": 12.0,
      "eval_accuracy": {
        "accuracy": 0.24247842649459692
      },
      "eval_loss": 4.328199863433838,
      "eval_runtime": 2.7838,
      "eval_samples_per_second": 4620.638,
      "eval_steps_per_second": 72.203,
      "step": 7464
    },
    {
      "epoch": 12.03,
      "learning_rate": 0.09879758962684888,
      "loss": 4.2027,
      "step": 7480
    },
    {
      "epoch": 12.06,
      "learning_rate": 0.09879437419598071,
      "loss": 4.1997,
      "step": 7500
    },
    {
      "epoch": 12.09,
      "learning_rate": 0.09879115876511255,
      "loss": 4.2458,
      "step": 7520
    },
    {
      "epoch": 12.12,
      "learning_rate": 0.09878794333424439,
      "loss": 4.2617,
      "step": 7540
    },
    {
      "epoch": 12.15,
      "learning_rate": 0.09878472790337621,
      "loss": 4.1814,
      "step": 7560
    },
    {
      "epoch": 12.19,
      "learning_rate": 0.09878151247250805,
      "loss": 4.2081,
      "step": 7580
    },
    {
      "epoch": 12.22,
      "learning_rate": 0.09877829704163987,
      "loss": 4.2392,
      "step": 7600
    },
    {
      "epoch": 12.25,
      "learning_rate": 0.09877508161077171,
      "loss": 4.2632,
      "step": 7620
    },
    {
      "epoch": 12.28,
      "learning_rate": 0.09877186617990354,
      "loss": 4.2041,
      "step": 7640
    },
    {
      "epoch": 12.32,
      "learning_rate": 0.09876865074903537,
      "loss": 4.2382,
      "step": 7660
    },
    {
      "epoch": 12.35,
      "learning_rate": 0.09876543531816721,
      "loss": 4.2295,
      "step": 7680
    },
    {
      "epoch": 12.38,
      "learning_rate": 0.09876221988729904,
      "loss": 4.1873,
      "step": 7700
    },
    {
      "epoch": 12.41,
      "learning_rate": 0.09875900445643088,
      "loss": 4.2804,
      "step": 7720
    },
    {
      "epoch": 12.44,
      "learning_rate": 0.0987557890255627,
      "loss": 4.2923,
      "step": 7740
    },
    {
      "epoch": 12.48,
      "learning_rate": 0.09875257359469454,
      "loss": 4.2462,
      "step": 7760
    },
    {
      "epoch": 12.51,
      "learning_rate": 0.09874935816382638,
      "loss": 4.2856,
      "step": 7780
    },
    {
      "epoch": 12.54,
      "learning_rate": 0.0987461427329582,
      "loss": 4.1776,
      "step": 7800
    },
    {
      "epoch": 12.57,
      "learning_rate": 0.09874292730209004,
      "loss": 4.0919,
      "step": 7820
    },
    {
      "epoch": 12.6,
      "learning_rate": 0.09873971187122187,
      "loss": 4.1222,
      "step": 7840
    },
    {
      "epoch": 12.64,
      "learning_rate": 0.0987364964403537,
      "loss": 4.0912,
      "step": 7860
    },
    {
      "epoch": 12.67,
      "learning_rate": 0.09873328100948554,
      "loss": 4.0779,
      "step": 7880
    },
    {
      "epoch": 12.7,
      "learning_rate": 0.09873006557861737,
      "loss": 4.1247,
      "step": 7900
    },
    {
      "epoch": 12.73,
      "learning_rate": 0.0987268501477492,
      "loss": 4.076,
      "step": 7920
    },
    {
      "epoch": 12.77,
      "learning_rate": 0.09872363471688103,
      "loss": 4.0915,
      "step": 7940
    },
    {
      "epoch": 12.8,
      "learning_rate": 0.09872041928601287,
      "loss": 4.1586,
      "step": 7960
    },
    {
      "epoch": 12.83,
      "learning_rate": 0.0987172038551447,
      "loss": 4.1892,
      "step": 7980
    },
    {
      "epoch": 12.86,
      "learning_rate": 0.09871398842427653,
      "loss": 4.2508,
      "step": 8000
    },
    {
      "epoch": 12.89,
      "learning_rate": 0.09871077299340837,
      "loss": 4.2889,
      "step": 8020
    },
    {
      "epoch": 12.93,
      "learning_rate": 0.0987075575625402,
      "loss": 4.2215,
      "step": 8040
    },
    {
      "epoch": 12.96,
      "learning_rate": 0.09870434213167203,
      "loss": 4.1782,
      "step": 8060
    },
    {
      "epoch": 12.99,
      "learning_rate": 0.09870112670080386,
      "loss": 4.1332,
      "step": 8080
    },
    {
      "epoch": 13.0,
      "eval_accuracy": {
        "accuracy": 0.2494752390577626
      },
      "eval_loss": 4.2170586585998535,
      "eval_runtime": 2.8065,
      "eval_samples_per_second": 4583.213,
      "eval_steps_per_second": 71.618,
      "step": 8086
    },
    {
      "epoch": 13.02,
      "learning_rate": 0.0986979112699357,
      "loss": 4.1225,
      "step": 8100
    },
    {
      "epoch": 13.05,
      "learning_rate": 0.09869469583906754,
      "loss": 4.1162,
      "step": 8120
    },
    {
      "epoch": 13.09,
      "learning_rate": 0.09869148040819936,
      "loss": 4.1321,
      "step": 8140
    },
    {
      "epoch": 13.12,
      "learning_rate": 0.0986882649773312,
      "loss": 4.1032,
      "step": 8160
    },
    {
      "epoch": 13.15,
      "learning_rate": 0.09868504954646302,
      "loss": 4.1782,
      "step": 8180
    },
    {
      "epoch": 13.18,
      "learning_rate": 0.09868183411559486,
      "loss": 4.1346,
      "step": 8200
    },
    {
      "epoch": 13.22,
      "learning_rate": 0.0986786186847267,
      "loss": 4.1016,
      "step": 8220
    },
    {
      "epoch": 13.25,
      "learning_rate": 0.09867540325385853,
      "loss": 4.1201,
      "step": 8240
    },
    {
      "epoch": 13.28,
      "learning_rate": 0.09867218782299036,
      "loss": 4.1514,
      "step": 8260
    },
    {
      "epoch": 13.31,
      "learning_rate": 0.09866897239212219,
      "loss": 4.1192,
      "step": 8280
    },
    {
      "epoch": 13.34,
      "learning_rate": 0.09866575696125403,
      "loss": 4.0937,
      "step": 8300
    },
    {
      "epoch": 13.38,
      "learning_rate": 0.09866254153038585,
      "loss": 4.1091,
      "step": 8320
    },
    {
      "epoch": 13.41,
      "learning_rate": 0.09865932609951769,
      "loss": 4.1416,
      "step": 8340
    },
    {
      "epoch": 13.44,
      "learning_rate": 0.09865611066864953,
      "loss": 4.0718,
      "step": 8360
    },
    {
      "epoch": 13.47,
      "learning_rate": 0.09865289523778135,
      "loss": 4.1001,
      "step": 8380
    },
    {
      "epoch": 13.5,
      "learning_rate": 0.09864967980691319,
      "loss": 4.0794,
      "step": 8400
    },
    {
      "epoch": 13.54,
      "learning_rate": 0.09864646437604502,
      "loss": 4.1087,
      "step": 8420
    },
    {
      "epoch": 13.57,
      "learning_rate": 0.09864324894517684,
      "loss": 4.1054,
      "step": 8440
    },
    {
      "epoch": 13.6,
      "learning_rate": 0.0986400335143087,
      "loss": 4.0387,
      "step": 8460
    },
    {
      "epoch": 13.63,
      "learning_rate": 0.09863681808344052,
      "loss": 4.0667,
      "step": 8480
    },
    {
      "epoch": 13.67,
      "learning_rate": 0.09863360265257236,
      "loss": 4.1006,
      "step": 8500
    },
    {
      "epoch": 13.7,
      "learning_rate": 0.09863038722170418,
      "loss": 4.1592,
      "step": 8520
    },
    {
      "epoch": 13.73,
      "learning_rate": 0.09862717179083601,
      "loss": 4.0878,
      "step": 8540
    },
    {
      "epoch": 13.76,
      "learning_rate": 0.09862395635996786,
      "loss": 4.0916,
      "step": 8560
    },
    {
      "epoch": 13.79,
      "learning_rate": 0.09862074092909968,
      "loss": 4.1042,
      "step": 8580
    },
    {
      "epoch": 13.83,
      "learning_rate": 0.09861752549823152,
      "loss": 4.0707,
      "step": 8600
    },
    {
      "epoch": 13.86,
      "learning_rate": 0.09861431006736335,
      "loss": 4.0734,
      "step": 8620
    },
    {
      "epoch": 13.89,
      "learning_rate": 0.09861109463649519,
      "loss": 4.0798,
      "step": 8640
    },
    {
      "epoch": 13.92,
      "learning_rate": 0.09860787920562701,
      "loss": 4.0854,
      "step": 8660
    },
    {
      "epoch": 13.95,
      "learning_rate": 0.09860466377475885,
      "loss": 4.1243,
      "step": 8680
    },
    {
      "epoch": 13.99,
      "learning_rate": 0.09860144834389069,
      "loss": 4.151,
      "step": 8700
    },
    {
      "epoch": 14.0,
      "eval_accuracy": {
        "accuracy": 0.24675425639430926
      },
      "eval_loss": 4.220243453979492,
      "eval_runtime": 2.7156,
      "eval_samples_per_second": 4736.764,
      "eval_steps_per_second": 74.018,
      "step": 8708
    },
    {
      "epoch": 14.02,
      "learning_rate": 0.09859823291302251,
      "loss": 4.1336,
      "step": 8720
    },
    {
      "epoch": 14.05,
      "learning_rate": 0.09859501748215435,
      "loss": 4.0863,
      "step": 8740
    },
    {
      "epoch": 14.08,
      "learning_rate": 0.09859180205128618,
      "loss": 4.0528,
      "step": 8760
    },
    {
      "epoch": 14.12,
      "learning_rate": 0.098588586620418,
      "loss": 4.0492,
      "step": 8780
    },
    {
      "epoch": 14.15,
      "learning_rate": 0.09858537118954985,
      "loss": 4.0244,
      "step": 8800
    },
    {
      "epoch": 14.18,
      "learning_rate": 0.09858215575868168,
      "loss": 4.0242,
      "step": 8820
    },
    {
      "epoch": 14.21,
      "learning_rate": 0.09857894032781352,
      "loss": 3.9902,
      "step": 8840
    },
    {
      "epoch": 14.24,
      "learning_rate": 0.09857572489694534,
      "loss": 4.0109,
      "step": 8860
    },
    {
      "epoch": 14.28,
      "learning_rate": 0.09857250946607717,
      "loss": 4.0318,
      "step": 8880
    },
    {
      "epoch": 14.31,
      "learning_rate": 0.09856929403520902,
      "loss": 4.0863,
      "step": 8900
    },
    {
      "epoch": 14.34,
      "learning_rate": 0.09856607860434084,
      "loss": 4.0952,
      "step": 8920
    },
    {
      "epoch": 14.37,
      "learning_rate": 0.09856286317347268,
      "loss": 4.1133,
      "step": 8940
    },
    {
      "epoch": 14.41,
      "learning_rate": 0.0985596477426045,
      "loss": 4.0646,
      "step": 8960
    },
    {
      "epoch": 14.44,
      "learning_rate": 0.09855643231173633,
      "loss": 4.0567,
      "step": 8980
    },
    {
      "epoch": 14.47,
      "learning_rate": 0.09855321688086817,
      "loss": 4.0215,
      "step": 9000
    },
    {
      "epoch": 14.5,
      "learning_rate": 0.09855000145000001,
      "loss": 4.0332,
      "step": 9020
    },
    {
      "epoch": 14.53,
      "learning_rate": 0.09854678601913185,
      "loss": 4.0829,
      "step": 9040
    },
    {
      "epoch": 14.57,
      "learning_rate": 0.09854357058826367,
      "loss": 4.1982,
      "step": 9060
    },
    {
      "epoch": 14.6,
      "learning_rate": 0.0985403551573955,
      "loss": 4.1085,
      "step": 9080
    },
    {
      "epoch": 14.63,
      "learning_rate": 0.09853713972652733,
      "loss": 3.9975,
      "step": 9100
    },
    {
      "epoch": 14.66,
      "learning_rate": 0.09853392429565917,
      "loss": 3.9737,
      "step": 9120
    },
    {
      "epoch": 14.69,
      "learning_rate": 0.09853070886479101,
      "loss": 3.9293,
      "step": 9140
    },
    {
      "epoch": 14.73,
      "learning_rate": 0.09852749343392284,
      "loss": 4.0207,
      "step": 9160
    },
    {
      "epoch": 14.76,
      "learning_rate": 0.09852427800305467,
      "loss": 4.0247,
      "step": 9180
    },
    {
      "epoch": 14.79,
      "learning_rate": 0.0985210625721865,
      "loss": 4.1278,
      "step": 9200
    },
    {
      "epoch": 14.82,
      "learning_rate": 0.09851784714131832,
      "loss": 4.1377,
      "step": 9220
    },
    {
      "epoch": 14.86,
      "learning_rate": 0.09851463171045018,
      "loss": 4.0638,
      "step": 9240
    },
    {
      "epoch": 14.89,
      "learning_rate": 0.098511416279582,
      "loss": 3.9865,
      "step": 9260
    },
    {
      "epoch": 14.92,
      "learning_rate": 0.09850820084871384,
      "loss": 3.9728,
      "step": 9280
    },
    {
      "epoch": 14.95,
      "learning_rate": 0.09850498541784566,
      "loss": 4.0261,
      "step": 9300
    },
    {
      "epoch": 14.98,
      "learning_rate": 0.09850176998697749,
      "loss": 4.0303,
      "step": 9320
    },
    {
      "epoch": 15.0,
      "eval_accuracy": {
        "accuracy": 0.2469874834797481
      },
      "eval_loss": 4.148540019989014,
      "eval_runtime": 2.8952,
      "eval_samples_per_second": 4442.899,
      "eval_steps_per_second": 69.426,
      "step": 9330
    },
    {
      "epoch": 15.02,
      "learning_rate": 0.09849855455610933,
      "loss": 4.0664,
      "step": 9340
    },
    {
      "epoch": 15.05,
      "learning_rate": 0.09849533912524117,
      "loss": 4.0388,
      "step": 9360
    },
    {
      "epoch": 15.08,
      "learning_rate": 0.098492123694373,
      "loss": 4.0263,
      "step": 9380
    },
    {
      "epoch": 15.11,
      "learning_rate": 0.09848890826350483,
      "loss": 4.0303,
      "step": 9400
    },
    {
      "epoch": 15.14,
      "learning_rate": 0.09848569283263665,
      "loss": 4.0422,
      "step": 9420
    },
    {
      "epoch": 15.18,
      "learning_rate": 0.09848247740176849,
      "loss": 4.042,
      "step": 9440
    },
    {
      "epoch": 15.21,
      "learning_rate": 0.09847926197090033,
      "loss": 4.0474,
      "step": 9460
    },
    {
      "epoch": 15.24,
      "learning_rate": 0.09847604654003217,
      "loss": 4.0483,
      "step": 9480
    },
    {
      "epoch": 15.27,
      "learning_rate": 0.098472831109164,
      "loss": 3.9658,
      "step": 9500
    },
    {
      "epoch": 15.31,
      "learning_rate": 0.09846961567829582,
      "loss": 3.9792,
      "step": 9520
    },
    {
      "epoch": 15.34,
      "learning_rate": 0.09846640024742766,
      "loss": 3.9514,
      "step": 9540
    },
    {
      "epoch": 15.37,
      "learning_rate": 0.09846318481655948,
      "loss": 3.974,
      "step": 9560
    },
    {
      "epoch": 15.4,
      "learning_rate": 0.09845996938569133,
      "loss": 4.0525,
      "step": 9580
    },
    {
      "epoch": 15.43,
      "learning_rate": 0.09845675395482316,
      "loss": 4.1062,
      "step": 9600
    },
    {
      "epoch": 15.47,
      "learning_rate": 0.09845353852395498,
      "loss": 4.0935,
      "step": 9620
    },
    {
      "epoch": 15.5,
      "learning_rate": 0.09845032309308682,
      "loss": 4.0379,
      "step": 9640
    },
    {
      "epoch": 15.53,
      "learning_rate": 0.09844710766221865,
      "loss": 4.0395,
      "step": 9660
    },
    {
      "epoch": 15.56,
      "learning_rate": 0.09844389223135049,
      "loss": 4.0131,
      "step": 9680
    },
    {
      "epoch": 15.59,
      "learning_rate": 0.09844067680048232,
      "loss": 4.0581,
      "step": 9700
    },
    {
      "epoch": 15.63,
      "learning_rate": 0.09843746136961415,
      "loss": 4.0316,
      "step": 9720
    },
    {
      "epoch": 15.66,
      "learning_rate": 0.09843424593874599,
      "loss": 4.0113,
      "step": 9740
    },
    {
      "epoch": 15.69,
      "learning_rate": 0.09843103050787781,
      "loss": 4.0501,
      "step": 9760
    },
    {
      "epoch": 15.72,
      "learning_rate": 0.09842781507700965,
      "loss": 4.0817,
      "step": 9780
    },
    {
      "epoch": 15.76,
      "learning_rate": 0.09842459964614149,
      "loss": 4.0104,
      "step": 9800
    },
    {
      "epoch": 15.79,
      "learning_rate": 0.09842138421527333,
      "loss": 4.0374,
      "step": 9820
    },
    {
      "epoch": 15.82,
      "learning_rate": 0.09841816878440515,
      "loss": 3.9997,
      "step": 9840
    },
    {
      "epoch": 15.85,
      "learning_rate": 0.09841495335353698,
      "loss": 4.0216,
      "step": 9860
    },
    {
      "epoch": 15.88,
      "learning_rate": 0.09841173792266882,
      "loss": 3.9803,
      "step": 9880
    },
    {
      "epoch": 15.92,
      "learning_rate": 0.09840852249180064,
      "loss": 3.9941,
      "step": 9900
    },
    {
      "epoch": 15.95,
      "learning_rate": 0.09840530706093249,
      "loss": 4.0516,
      "step": 9920
    },
    {
      "epoch": 15.98,
      "learning_rate": 0.09840209163006432,
      "loss": 4.0865,
      "step": 9940
    },
    {
      "epoch": 16.0,
      "eval_accuracy": {
        "accuracy": 0.25662753634455415
      },
      "eval_loss": 4.068516731262207,
      "eval_runtime": 2.6898,
      "eval_samples_per_second": 4782.143,
      "eval_steps_per_second": 74.727,
      "step": 9952
    },
    {
      "epoch": 16.01,
      "learning_rate": 0.09839887619919614,
      "loss": 4.0118,
      "step": 9960
    },
    {
      "epoch": 16.05,
      "learning_rate": 0.09839566076832798,
      "loss": 3.9824,
      "step": 9980
    },
    {
      "epoch": 16.08,
      "learning_rate": 0.0983924453374598,
      "loss": 3.9356,
      "step": 10000
    },
    {
      "epoch": 16.11,
      "learning_rate": 0.09838922990659164,
      "loss": 3.9497,
      "step": 10020
    },
    {
      "epoch": 16.14,
      "learning_rate": 0.09838601447572348,
      "loss": 3.9822,
      "step": 10040
    },
    {
      "epoch": 16.17,
      "learning_rate": 0.0983827990448553,
      "loss": 4.0232,
      "step": 10060
    },
    {
      "epoch": 16.21,
      "learning_rate": 0.09837958361398715,
      "loss": 4.0065,
      "step": 10080
    },
    {
      "epoch": 16.24,
      "learning_rate": 0.09837636818311897,
      "loss": 3.9672,
      "step": 10100
    },
    {
      "epoch": 16.27,
      "learning_rate": 0.09837315275225081,
      "loss": 3.9664,
      "step": 10120
    },
    {
      "epoch": 16.3,
      "learning_rate": 0.09836993732138265,
      "loss": 3.9664,
      "step": 10140
    },
    {
      "epoch": 16.33,
      "learning_rate": 0.09836672189051447,
      "loss": 4.0568,
      "step": 10160
    },
    {
      "epoch": 16.37,
      "learning_rate": 0.09836350645964631,
      "loss": 4.0068,
      "step": 10180
    },
    {
      "epoch": 16.4,
      "learning_rate": 0.09836029102877814,
      "loss": 4.0303,
      "step": 10200
    },
    {
      "epoch": 16.43,
      "learning_rate": 0.09835707559790997,
      "loss": 3.9608,
      "step": 10220
    },
    {
      "epoch": 16.46,
      "learning_rate": 0.0983538601670418,
      "loss": 4.0471,
      "step": 10240
    },
    {
      "epoch": 16.5,
      "learning_rate": 0.09835064473617364,
      "loss": 4.0791,
      "step": 10260
    },
    {
      "epoch": 16.53,
      "learning_rate": 0.09834742930530548,
      "loss": 4.0136,
      "step": 10280
    },
    {
      "epoch": 16.56,
      "learning_rate": 0.0983442138744373,
      "loss": 3.9822,
      "step": 10300
    },
    {
      "epoch": 16.59,
      "learning_rate": 0.09834099844356914,
      "loss": 3.9626,
      "step": 10320
    },
    {
      "epoch": 16.62,
      "learning_rate": 0.09833778301270096,
      "loss": 3.9796,
      "step": 10340
    },
    {
      "epoch": 16.66,
      "learning_rate": 0.0983345675818328,
      "loss": 4.0441,
      "step": 10360
    },
    {
      "epoch": 16.69,
      "learning_rate": 0.09833135215096464,
      "loss": 4.0,
      "step": 10380
    },
    {
      "epoch": 16.72,
      "learning_rate": 0.09832813672009647,
      "loss": 3.9771,
      "step": 10400
    },
    {
      "epoch": 16.75,
      "learning_rate": 0.0983249212892283,
      "loss": 3.9383,
      "step": 10420
    },
    {
      "epoch": 16.78,
      "learning_rate": 0.09832170585836013,
      "loss": 3.9385,
      "step": 10440
    },
    {
      "epoch": 16.82,
      "learning_rate": 0.09831849042749197,
      "loss": 3.8933,
      "step": 10460
    },
    {
      "epoch": 16.85,
      "learning_rate": 0.0983152749966238,
      "loss": 3.9146,
      "step": 10480
    },
    {
      "epoch": 16.88,
      "learning_rate": 0.09831205956575563,
      "loss": 3.9718,
      "step": 10500
    },
    {
      "epoch": 16.91,
      "learning_rate": 0.09830884413488747,
      "loss": 3.9732,
      "step": 10520
    },
    {
      "epoch": 16.95,
      "learning_rate": 0.0983056287040193,
      "loss": 3.9756,
      "step": 10540
    },
    {
      "epoch": 16.98,
      "learning_rate": 0.09830241327315113,
      "loss": 3.9189,
      "step": 10560
    },
    {
      "epoch": 17.0,
      "eval_accuracy": {
        "accuracy": 0.2671227551893027
      },
      "eval_loss": 3.9727320671081543,
      "eval_runtime": 3.3018,
      "eval_samples_per_second": 3895.706,
      "eval_steps_per_second": 60.875,
      "step": 10574
    },
    {
      "epoch": 17.01,
      "learning_rate": 0.09829919784228296,
      "loss": 3.9555,
      "step": 10580
    },
    {
      "epoch": 17.04,
      "learning_rate": 0.0982959824114148,
      "loss": 3.8783,
      "step": 10600
    },
    {
      "epoch": 17.07,
      "learning_rate": 0.09829292775209005,
      "loss": 3.9463,
      "step": 10620
    },
    {
      "epoch": 17.11,
      "learning_rate": 0.09828971232122187,
      "loss": 3.952,
      "step": 10640
    },
    {
      "epoch": 17.14,
      "learning_rate": 0.09828649689035371,
      "loss": 3.9055,
      "step": 10660
    },
    {
      "epoch": 17.17,
      "learning_rate": 0.09828328145948553,
      "loss": 3.9195,
      "step": 10680
    },
    {
      "epoch": 17.2,
      "learning_rate": 0.09828006602861737,
      "loss": 3.9499,
      "step": 10700
    },
    {
      "epoch": 17.23,
      "learning_rate": 0.0982768505977492,
      "loss": 4.0349,
      "step": 10720
    },
    {
      "epoch": 17.27,
      "learning_rate": 0.09827363516688103,
      "loss": 4.0256,
      "step": 10740
    },
    {
      "epoch": 17.3,
      "learning_rate": 0.09827041973601287,
      "loss": 4.0261,
      "step": 10760
    },
    {
      "epoch": 17.33,
      "learning_rate": 0.0982672043051447,
      "loss": 3.9833,
      "step": 10780
    },
    {
      "epoch": 17.36,
      "learning_rate": 0.09826398887427654,
      "loss": 3.9877,
      "step": 10800
    },
    {
      "epoch": 17.4,
      "learning_rate": 0.09826077344340836,
      "loss": 3.9569,
      "step": 10820
    },
    {
      "epoch": 17.43,
      "learning_rate": 0.0982575580125402,
      "loss": 3.9734,
      "step": 10840
    },
    {
      "epoch": 17.46,
      "learning_rate": 0.09825434258167204,
      "loss": 3.9459,
      "step": 10860
    },
    {
      "epoch": 17.49,
      "learning_rate": 0.09825112715080386,
      "loss": 3.9437,
      "step": 10880
    },
    {
      "epoch": 17.52,
      "learning_rate": 0.0982479117199357,
      "loss": 3.8385,
      "step": 10900
    },
    {
      "epoch": 17.56,
      "learning_rate": 0.09824469628906753,
      "loss": 3.9198,
      "step": 10920
    },
    {
      "epoch": 17.59,
      "learning_rate": 0.09824148085819936,
      "loss": 3.8941,
      "step": 10940
    },
    {
      "epoch": 17.62,
      "learning_rate": 0.0982382654273312,
      "loss": 3.8651,
      "step": 10960
    },
    {
      "epoch": 17.65,
      "learning_rate": 0.09823504999646303,
      "loss": 3.8933,
      "step": 10980
    },
    {
      "epoch": 17.68,
      "learning_rate": 0.09823183456559487,
      "loss": 3.8904,
      "step": 11000
    },
    {
      "epoch": 17.72,
      "learning_rate": 0.09822861913472669,
      "loss": 3.8963,
      "step": 11020
    },
    {
      "epoch": 17.75,
      "learning_rate": 0.09822540370385853,
      "loss": 3.9514,
      "step": 11040
    },
    {
      "epoch": 17.78,
      "learning_rate": 0.09822218827299035,
      "loss": 3.9508,
      "step": 11060
    },
    {
      "epoch": 17.81,
      "learning_rate": 0.09821897284212219,
      "loss": 3.986,
      "step": 11080
    },
    {
      "epoch": 17.85,
      "learning_rate": 0.09821575741125403,
      "loss": 3.9445,
      "step": 11100
    },
    {
      "epoch": 17.88,
      "learning_rate": 0.09821254198038586,
      "loss": 3.9678,
      "step": 11120
    },
    {
      "epoch": 17.91,
      "learning_rate": 0.0982093265495177,
      "loss": 3.9879,
      "step": 11140
    },
    {
      "epoch": 17.94,
      "learning_rate": 0.09820611111864952,
      "loss": 4.0052,
      "step": 11160
    },
    {
      "epoch": 17.97,
      "learning_rate": 0.09820289568778136,
      "loss": 3.9419,
      "step": 11180
    },
    {
      "epoch": 18.0,
      "eval_accuracy": {
        "accuracy": 0.2602814273497629
      },
      "eval_loss": 3.943838357925415,
      "eval_runtime": 2.7742,
      "eval_samples_per_second": 4636.637,
      "eval_steps_per_second": 72.453,
      "step": 11196
    },
    {
      "epoch": 18.01,
      "learning_rate": 0.0981996802569132,
      "loss": 3.9175,
      "step": 11200
    },
    {
      "epoch": 18.04,
      "learning_rate": 0.09819646482604502,
      "loss": 3.9672,
      "step": 11220
    },
    {
      "epoch": 18.07,
      "learning_rate": 0.09819324939517686,
      "loss": 3.92,
      "step": 11240
    },
    {
      "epoch": 18.1,
      "learning_rate": 0.09819003396430868,
      "loss": 3.8543,
      "step": 11260
    },
    {
      "epoch": 18.14,
      "learning_rate": 0.09818681853344051,
      "loss": 3.924,
      "step": 11280
    },
    {
      "epoch": 18.17,
      "learning_rate": 0.09818360310257236,
      "loss": 4.0271,
      "step": 11300
    },
    {
      "epoch": 18.2,
      "learning_rate": 0.09818038767170419,
      "loss": 4.0252,
      "step": 11320
    },
    {
      "epoch": 18.23,
      "learning_rate": 0.09817717224083602,
      "loss": 4.0449,
      "step": 11340
    },
    {
      "epoch": 18.26,
      "learning_rate": 0.09817395680996785,
      "loss": 4.0926,
      "step": 11360
    },
    {
      "epoch": 18.3,
      "learning_rate": 0.09817074137909969,
      "loss": 4.0261,
      "step": 11380
    },
    {
      "epoch": 18.33,
      "learning_rate": 0.09816752594823151,
      "loss": 3.9093,
      "step": 11400
    },
    {
      "epoch": 18.36,
      "learning_rate": 0.09816431051736335,
      "loss": 3.8487,
      "step": 11420
    },
    {
      "epoch": 18.39,
      "learning_rate": 0.09816109508649519,
      "loss": 3.9103,
      "step": 11440
    },
    {
      "epoch": 18.42,
      "learning_rate": 0.09815787965562701,
      "loss": 3.8779,
      "step": 11460
    },
    {
      "epoch": 18.46,
      "learning_rate": 0.09815466422475885,
      "loss": 3.9693,
      "step": 11480
    },
    {
      "epoch": 18.49,
      "learning_rate": 0.09815144879389068,
      "loss": 3.9477,
      "step": 11500
    },
    {
      "epoch": 18.52,
      "learning_rate": 0.09814823336302252,
      "loss": 3.9484,
      "step": 11520
    },
    {
      "epoch": 18.55,
      "learning_rate": 0.09814501793215435,
      "loss": 3.8794,
      "step": 11540
    },
    {
      "epoch": 18.59,
      "learning_rate": 0.09814180250128618,
      "loss": 3.8593,
      "step": 11560
    },
    {
      "epoch": 18.62,
      "learning_rate": 0.09813858707041802,
      "loss": 3.9211,
      "step": 11580
    },
    {
      "epoch": 18.65,
      "learning_rate": 0.09813537163954984,
      "loss": 3.972,
      "step": 11600
    },
    {
      "epoch": 18.68,
      "learning_rate": 0.09813215620868167,
      "loss": 3.8709,
      "step": 11620
    },
    {
      "epoch": 18.71,
      "learning_rate": 0.09812894077781352,
      "loss": 3.8738,
      "step": 11640
    },
    {
      "epoch": 18.75,
      "learning_rate": 0.09812572534694534,
      "loss": 3.8864,
      "step": 11660
    },
    {
      "epoch": 18.78,
      "learning_rate": 0.09812250991607718,
      "loss": 3.9441,
      "step": 11680
    },
    {
      "epoch": 18.81,
      "learning_rate": 0.09811929448520901,
      "loss": 3.8822,
      "step": 11700
    },
    {
      "epoch": 18.84,
      "learning_rate": 0.09811607905434083,
      "loss": 3.8343,
      "step": 11720
    },
    {
      "epoch": 18.87,
      "learning_rate": 0.09811286362347267,
      "loss": 3.9025,
      "step": 11740
    },
    {
      "epoch": 18.91,
      "learning_rate": 0.09810964819260451,
      "loss": 3.8488,
      "step": 11760
    },
    {
      "epoch": 18.94,
      "learning_rate": 0.09810643276173635,
      "loss": 3.8676,
      "step": 11780
    },
    {
      "epoch": 18.97,
      "learning_rate": 0.09810321733086817,
      "loss": 3.8949,
      "step": 11800
    },
    {
      "epoch": 19.0,
      "eval_accuracy": {
        "accuracy": 0.26463499961128817
      },
      "eval_loss": 4.0865559577941895,
      "eval_runtime": 2.8867,
      "eval_samples_per_second": 4455.992,
      "eval_steps_per_second": 69.63,
      "step": 11818
    },
    {
      "epoch": 19.0,
      "learning_rate": 0.0981000019,
      "loss": 4.0115,
      "step": 11820
    },
    {
      "epoch": 19.04,
      "learning_rate": 0.09809678646913184,
      "loss": 4.03,
      "step": 11840
    },
    {
      "epoch": 19.07,
      "learning_rate": 0.09809357103826367,
      "loss": 3.9539,
      "step": 11860
    },
    {
      "epoch": 19.1,
      "learning_rate": 0.09809035560739551,
      "loss": 3.8777,
      "step": 11880
    },
    {
      "epoch": 19.13,
      "learning_rate": 0.09808714017652734,
      "loss": 3.8673,
      "step": 11900
    },
    {
      "epoch": 19.16,
      "learning_rate": 0.09808392474565916,
      "loss": 3.9507,
      "step": 11920
    },
    {
      "epoch": 19.2,
      "learning_rate": 0.098080709314791,
      "loss": 3.8947,
      "step": 11940
    },
    {
      "epoch": 19.23,
      "learning_rate": 0.09807749388392283,
      "loss": 3.9017,
      "step": 11960
    },
    {
      "epoch": 19.26,
      "learning_rate": 0.09807427845305468,
      "loss": 3.9,
      "step": 11980
    },
    {
      "epoch": 19.29,
      "learning_rate": 0.0980710630221865,
      "loss": 3.8427,
      "step": 12000
    },
    {
      "epoch": 19.32,
      "learning_rate": 0.09806784759131834,
      "loss": 3.8784,
      "step": 12020
    },
    {
      "epoch": 19.36,
      "learning_rate": 0.09806463216045017,
      "loss": 4.0,
      "step": 12040
    },
    {
      "epoch": 19.39,
      "learning_rate": 0.09806141672958199,
      "loss": 3.9205,
      "step": 12060
    },
    {
      "epoch": 19.42,
      "learning_rate": 0.09805820129871383,
      "loss": 3.9231,
      "step": 12080
    },
    {
      "epoch": 19.45,
      "learning_rate": 0.09805498586784567,
      "loss": 3.8896,
      "step": 12100
    },
    {
      "epoch": 19.49,
      "learning_rate": 0.0980517704369775,
      "loss": 3.9596,
      "step": 12120
    },
    {
      "epoch": 19.52,
      "learning_rate": 0.09804855500610933,
      "loss": 3.9912,
      "step": 12140
    },
    {
      "epoch": 19.55,
      "learning_rate": 0.09804533957524116,
      "loss": 3.8964,
      "step": 12160
    },
    {
      "epoch": 19.58,
      "learning_rate": 0.098042124144373,
      "loss": 3.8814,
      "step": 12180
    },
    {
      "epoch": 19.61,
      "learning_rate": 0.09803890871350483,
      "loss": 3.8857,
      "step": 12200
    },
    {
      "epoch": 19.65,
      "learning_rate": 0.09803569328263667,
      "loss": 3.921,
      "step": 12220
    },
    {
      "epoch": 19.68,
      "learning_rate": 0.0980324778517685,
      "loss": 3.9124,
      "step": 12240
    },
    {
      "epoch": 19.71,
      "learning_rate": 0.09802926242090032,
      "loss": 3.9292,
      "step": 12260
    },
    {
      "epoch": 19.74,
      "learning_rate": 0.09802604699003216,
      "loss": 3.9129,
      "step": 12280
    },
    {
      "epoch": 19.77,
      "learning_rate": 0.09802283155916398,
      "loss": 3.9611,
      "step": 12300
    },
    {
      "epoch": 19.81,
      "learning_rate": 0.09801961612829584,
      "loss": 3.9792,
      "step": 12320
    },
    {
      "epoch": 19.84,
      "learning_rate": 0.09801640069742766,
      "loss": 3.9836,
      "step": 12340
    },
    {
      "epoch": 19.87,
      "learning_rate": 0.09801318526655949,
      "loss": 3.9447,
      "step": 12360
    },
    {
      "epoch": 19.9,
      "learning_rate": 0.09800996983569132,
      "loss": 4.0258,
      "step": 12380
    },
    {
      "epoch": 19.94,
      "learning_rate": 0.09800675440482315,
      "loss": 3.9966,
      "step": 12400
    },
    {
      "epoch": 19.97,
      "learning_rate": 0.09800353897395499,
      "loss": 3.9691,
      "step": 12420
    },
    {
      "epoch": 20.0,
      "learning_rate": 0.09800032354308683,
      "loss": 3.8608,
      "step": 12440
    },
    {
      "epoch": 20.0,
      "eval_accuracy": {
        "accuracy": 0.276218611521418
      },
      "eval_loss": 3.9229676723480225,
      "eval_runtime": 2.8874,
      "eval_samples_per_second": 4454.849,
      "eval_steps_per_second": 69.612,
      "step": 12440
    },
    {
      "epoch": 20.03,
      "learning_rate": 0.09799710811221865,
      "loss": 3.9029,
      "step": 12460
    },
    {
      "epoch": 20.06,
      "learning_rate": 0.09799389268135049,
      "loss": 3.9341,
      "step": 12480
    },
    {
      "epoch": 20.1,
      "learning_rate": 0.09799067725048231,
      "loss": 4.0059,
      "step": 12500
    },
    {
      "epoch": 20.13,
      "learning_rate": 0.09798746181961415,
      "loss": 3.8712,
      "step": 12520
    },
    {
      "epoch": 20.16,
      "learning_rate": 0.09798424638874599,
      "loss": 3.8826,
      "step": 12540
    },
    {
      "epoch": 20.19,
      "learning_rate": 0.09798103095787782,
      "loss": 3.8909,
      "step": 12560
    },
    {
      "epoch": 20.23,
      "learning_rate": 0.09797781552700965,
      "loss": 3.9122,
      "step": 12580
    },
    {
      "epoch": 20.26,
      "learning_rate": 0.09797460009614148,
      "loss": 3.8818,
      "step": 12600
    },
    {
      "epoch": 20.29,
      "learning_rate": 0.09797138466527332,
      "loss": 3.8092,
      "step": 12620
    },
    {
      "epoch": 20.32,
      "learning_rate": 0.09796816923440514,
      "loss": 3.7713,
      "step": 12640
    },
    {
      "epoch": 20.35,
      "learning_rate": 0.097964953803537,
      "loss": 3.8105,
      "step": 12660
    },
    {
      "epoch": 20.39,
      "learning_rate": 0.09796173837266882,
      "loss": 3.8808,
      "step": 12680
    },
    {
      "epoch": 20.42,
      "learning_rate": 0.09795852294180064,
      "loss": 3.8344,
      "step": 12700
    },
    {
      "epoch": 20.45,
      "learning_rate": 0.09795530751093248,
      "loss": 3.8382,
      "step": 12720
    },
    {
      "epoch": 20.48,
      "learning_rate": 0.0979520920800643,
      "loss": 3.863,
      "step": 12740
    },
    {
      "epoch": 20.51,
      "learning_rate": 0.09794903742073956,
      "loss": 3.8814,
      "step": 12760
    },
    {
      "epoch": 20.55,
      "learning_rate": 0.09794582198987138,
      "loss": 3.9514,
      "step": 12780
    },
    {
      "epoch": 20.58,
      "learning_rate": 0.09794260655900322,
      "loss": 3.8953,
      "step": 12800
    },
    {
      "epoch": 20.61,
      "learning_rate": 0.09793939112813506,
      "loss": 3.8553,
      "step": 12820
    },
    {
      "epoch": 20.64,
      "learning_rate": 0.09793617569726688,
      "loss": 3.8315,
      "step": 12840
    },
    {
      "epoch": 20.68,
      "learning_rate": 0.09793296026639872,
      "loss": 3.8403,
      "step": 12860
    },
    {
      "epoch": 20.71,
      "learning_rate": 0.09792974483553055,
      "loss": 3.8318,
      "step": 12880
    },
    {
      "epoch": 20.74,
      "learning_rate": 0.09792652940466239,
      "loss": 3.8345,
      "step": 12900
    },
    {
      "epoch": 20.77,
      "learning_rate": 0.09792331397379422,
      "loss": 3.9625,
      "step": 12920
    },
    {
      "epoch": 20.8,
      "learning_rate": 0.09792009854292605,
      "loss": 3.9771,
      "step": 12940
    },
    {
      "epoch": 20.84,
      "learning_rate": 0.09791688311205789,
      "loss": 3.878,
      "step": 12960
    },
    {
      "epoch": 20.87,
      "learning_rate": 0.09791366768118971,
      "loss": 3.9315,
      "step": 12980
    },
    {
      "epoch": 20.9,
      "learning_rate": 0.09791045225032155,
      "loss": 3.8659,
      "step": 13000
    },
    {
      "epoch": 20.93,
      "learning_rate": 0.09790723681945339,
      "loss": 3.8676,
      "step": 13020
    },
    {
      "epoch": 20.96,
      "learning_rate": 0.09790402138858521,
      "loss": 3.8323,
      "step": 13040
    },
    {
      "epoch": 21.0,
      "learning_rate": 0.09790080595771705,
      "loss": 3.8554,
      "step": 13060
    },
    {
      "epoch": 21.0,
      "eval_accuracy": {
        "accuracy": 0.2692995413200653
      },
      "eval_loss": 3.983095169067383,
      "eval_runtime": 2.6337,
      "eval_samples_per_second": 4884.083,
      "eval_steps_per_second": 76.32,
      "step": 13062
    },
    {
      "epoch": 21.03,
      "learning_rate": 0.09789759052684888,
      "loss": 3.8583,
      "step": 13080
    },
    {
      "epoch": 21.06,
      "learning_rate": 0.09789437509598072,
      "loss": 3.906,
      "step": 13100
    },
    {
      "epoch": 21.09,
      "learning_rate": 0.09789115966511254,
      "loss": 3.9434,
      "step": 13120
    },
    {
      "epoch": 21.13,
      "learning_rate": 0.09788794423424438,
      "loss": 3.8894,
      "step": 13140
    },
    {
      "epoch": 21.16,
      "learning_rate": 0.09788472880337622,
      "loss": 3.8501,
      "step": 13160
    },
    {
      "epoch": 21.19,
      "learning_rate": 0.09788151337250804,
      "loss": 3.8314,
      "step": 13180
    },
    {
      "epoch": 21.22,
      "learning_rate": 0.09787829794163988,
      "loss": 3.7513,
      "step": 13200
    },
    {
      "epoch": 21.25,
      "learning_rate": 0.0978750825107717,
      "loss": 3.8081,
      "step": 13220
    },
    {
      "epoch": 21.29,
      "learning_rate": 0.09787186707990354,
      "loss": 3.7454,
      "step": 13240
    },
    {
      "epoch": 21.32,
      "learning_rate": 0.09786865164903538,
      "loss": 3.7933,
      "step": 13260
    },
    {
      "epoch": 21.35,
      "learning_rate": 0.0978654362181672,
      "loss": 3.8004,
      "step": 13280
    },
    {
      "epoch": 21.38,
      "learning_rate": 0.09786222078729905,
      "loss": 3.7843,
      "step": 13300
    },
    {
      "epoch": 21.41,
      "learning_rate": 0.09785900535643087,
      "loss": 3.7761,
      "step": 13320
    },
    {
      "epoch": 21.45,
      "learning_rate": 0.09785578992556271,
      "loss": 3.8469,
      "step": 13340
    },
    {
      "epoch": 21.48,
      "learning_rate": 0.09785257449469455,
      "loss": 3.8175,
      "step": 13360
    },
    {
      "epoch": 21.51,
      "learning_rate": 0.09784935906382637,
      "loss": 3.8127,
      "step": 13380
    },
    {
      "epoch": 21.54,
      "learning_rate": 0.09784614363295821,
      "loss": 3.8844,
      "step": 13400
    },
    {
      "epoch": 21.58,
      "learning_rate": 0.09784292820209003,
      "loss": 3.829,
      "step": 13420
    },
    {
      "epoch": 21.61,
      "learning_rate": 0.09783971277122187,
      "loss": 3.8714,
      "step": 13440
    },
    {
      "epoch": 21.64,
      "learning_rate": 0.0978364973403537,
      "loss": 3.8351,
      "step": 13460
    },
    {
      "epoch": 21.67,
      "learning_rate": 0.09783328190948554,
      "loss": 3.7696,
      "step": 13480
    },
    {
      "epoch": 21.7,
      "learning_rate": 0.09783006647861738,
      "loss": 3.8186,
      "step": 13500
    },
    {
      "epoch": 21.74,
      "learning_rate": 0.0978268510477492,
      "loss": 3.7838,
      "step": 13520
    },
    {
      "epoch": 21.77,
      "learning_rate": 0.09782363561688104,
      "loss": 3.8201,
      "step": 13540
    },
    {
      "epoch": 21.8,
      "learning_rate": 0.09782042018601286,
      "loss": 3.8204,
      "step": 13560
    },
    {
      "epoch": 21.83,
      "learning_rate": 0.0978172047551447,
      "loss": 3.8313,
      "step": 13580
    },
    {
      "epoch": 21.86,
      "learning_rate": 0.09781398932427654,
      "loss": 3.828,
      "step": 13600
    },
    {
      "epoch": 21.9,
      "learning_rate": 0.09781077389340836,
      "loss": 3.7952,
      "step": 13620
    },
    {
      "epoch": 21.93,
      "learning_rate": 0.0978075584625402,
      "loss": 3.836,
      "step": 13640
    },
    {
      "epoch": 21.96,
      "learning_rate": 0.09780434303167203,
      "loss": 3.9033,
      "step": 13660
    },
    {
      "epoch": 21.99,
      "learning_rate": 0.09780112760080387,
      "loss": 3.8733,
      "step": 13680
    },
    {
      "epoch": 22.0,
      "eval_accuracy": {
        "accuracy": 0.26743372463655446
      },
      "eval_loss": 3.9715912342071533,
      "eval_runtime": 7.4938,
      "eval_samples_per_second": 1716.492,
      "eval_steps_per_second": 26.822,
      "step": 13684
    },
    {
      "epoch": 22.03,
      "learning_rate": 0.0977979121699357,
      "loss": 3.8859,
      "step": 13700
    },
    {
      "epoch": 22.06,
      "learning_rate": 0.09779469673906753,
      "loss": 3.8194,
      "step": 13720
    },
    {
      "epoch": 22.09,
      "learning_rate": 0.09779148130819937,
      "loss": 3.7941,
      "step": 13740
    },
    {
      "epoch": 22.12,
      "learning_rate": 0.09778826587733119,
      "loss": 3.8152,
      "step": 13760
    },
    {
      "epoch": 22.15,
      "learning_rate": 0.09778505044646303,
      "loss": 3.858,
      "step": 13780
    },
    {
      "epoch": 22.19,
      "learning_rate": 0.09778183501559486,
      "loss": 3.8421,
      "step": 13800
    },
    {
      "epoch": 22.22,
      "learning_rate": 0.0977786195847267,
      "loss": 3.878,
      "step": 13820
    },
    {
      "epoch": 22.25,
      "learning_rate": 0.09777540415385853,
      "loss": 3.8922,
      "step": 13840
    },
    {
      "epoch": 22.28,
      "learning_rate": 0.09777218872299036,
      "loss": 3.8559,
      "step": 13860
    },
    {
      "epoch": 22.32,
      "learning_rate": 0.0977689732921222,
      "loss": 3.8833,
      "step": 13880
    },
    {
      "epoch": 22.35,
      "learning_rate": 0.09776575786125402,
      "loss": 3.9026,
      "step": 13900
    },
    {
      "epoch": 22.38,
      "learning_rate": 0.09776254243038586,
      "loss": 3.8029,
      "step": 13920
    },
    {
      "epoch": 22.41,
      "learning_rate": 0.0977593269995177,
      "loss": 3.8198,
      "step": 13940
    },
    {
      "epoch": 22.44,
      "learning_rate": 0.09775611156864952,
      "loss": 3.7682,
      "step": 13960
    },
    {
      "epoch": 22.48,
      "learning_rate": 0.09775289613778136,
      "loss": 3.7349,
      "step": 13980
    },
    {
      "epoch": 22.51,
      "learning_rate": 0.09774968070691319,
      "loss": 3.7867,
      "step": 14000
    },
    {
      "epoch": 22.54,
      "learning_rate": 0.09774646527604501,
      "loss": 3.7887,
      "step": 14020
    },
    {
      "epoch": 22.57,
      "learning_rate": 0.09774324984517686,
      "loss": 3.7913,
      "step": 14040
    },
    {
      "epoch": 22.6,
      "learning_rate": 0.09774003441430869,
      "loss": 3.8092,
      "step": 14060
    },
    {
      "epoch": 22.64,
      "learning_rate": 0.09773681898344053,
      "loss": 3.8056,
      "step": 14080
    },
    {
      "epoch": 22.67,
      "learning_rate": 0.09773360355257235,
      "loss": 3.8163,
      "step": 14100
    },
    {
      "epoch": 22.7,
      "learning_rate": 0.09773038812170418,
      "loss": 3.9014,
      "step": 14120
    },
    {
      "epoch": 22.73,
      "learning_rate": 0.09772717269083601,
      "loss": 3.7852,
      "step": 14140
    },
    {
      "epoch": 22.77,
      "learning_rate": 0.09772395725996785,
      "loss": 3.8111,
      "step": 14160
    },
    {
      "epoch": 22.8,
      "learning_rate": 0.09772074182909969,
      "loss": 3.8574,
      "step": 14180
    },
    {
      "epoch": 22.83,
      "learning_rate": 0.09771752639823152,
      "loss": 3.831,
      "step": 14200
    },
    {
      "epoch": 22.86,
      "learning_rate": 0.09771431096736335,
      "loss": 3.7818,
      "step": 14220
    },
    {
      "epoch": 22.89,
      "learning_rate": 0.09771109553649518,
      "loss": 3.7885,
      "step": 14240
    },
    {
      "epoch": 22.93,
      "learning_rate": 0.09770788010562702,
      "loss": 3.8621,
      "step": 14260
    },
    {
      "epoch": 22.96,
      "learning_rate": 0.09770466467475886,
      "loss": 3.8718,
      "step": 14280
    },
    {
      "epoch": 22.99,
      "learning_rate": 0.09770144924389068,
      "loss": 3.8285,
      "step": 14300
    },
    {
      "epoch": 23.0,
      "eval_accuracy": {
        "accuracy": 0.2781621705667418
      },
      "eval_loss": 3.921801805496216,
      "eval_runtime": 2.6056,
      "eval_samples_per_second": 4936.764,
      "eval_steps_per_second": 77.143,
      "step": 14306
    },
    {
      "epoch": 23.02,
      "learning_rate": 0.09769823381302252,
      "loss": 3.864,
      "step": 14320
    },
    {
      "epoch": 23.05,
      "learning_rate": 0.09769501838215434,
      "loss": 3.7584,
      "step": 14340
    },
    {
      "epoch": 23.09,
      "learning_rate": 0.09769180295128617,
      "loss": 3.7236,
      "step": 14360
    },
    {
      "epoch": 23.12,
      "learning_rate": 0.09768858752041802,
      "loss": 3.7699,
      "step": 14380
    },
    {
      "epoch": 23.15,
      "learning_rate": 0.09768537208954985,
      "loss": 3.835,
      "step": 14400
    },
    {
      "epoch": 23.18,
      "learning_rate": 0.09768215665868168,
      "loss": 3.8339,
      "step": 14420
    },
    {
      "epoch": 23.22,
      "learning_rate": 0.09767894122781351,
      "loss": 3.7936,
      "step": 14440
    },
    {
      "epoch": 23.25,
      "learning_rate": 0.09767572579694533,
      "loss": 3.8241,
      "step": 14460
    },
    {
      "epoch": 23.28,
      "learning_rate": 0.09767251036607717,
      "loss": 3.7862,
      "step": 14480
    },
    {
      "epoch": 23.31,
      "learning_rate": 0.09766929493520901,
      "loss": 3.891,
      "step": 14500
    },
    {
      "epoch": 23.34,
      "learning_rate": 0.09766607950434085,
      "loss": 3.8966,
      "step": 14520
    },
    {
      "epoch": 23.38,
      "learning_rate": 0.09766286407347267,
      "loss": 3.8008,
      "step": 14540
    },
    {
      "epoch": 23.41,
      "learning_rate": 0.0976596486426045,
      "loss": 3.8342,
      "step": 14560
    },
    {
      "epoch": 23.44,
      "learning_rate": 0.09765643321173634,
      "loss": 3.8204,
      "step": 14580
    },
    {
      "epoch": 23.47,
      "learning_rate": 0.09765321778086818,
      "loss": 3.8543,
      "step": 14600
    },
    {
      "epoch": 23.5,
      "learning_rate": 0.09765000235000001,
      "loss": 3.8225,
      "step": 14620
    },
    {
      "epoch": 23.54,
      "learning_rate": 0.09764678691913184,
      "loss": 3.7972,
      "step": 14640
    },
    {
      "epoch": 23.57,
      "learning_rate": 0.09764357148826366,
      "loss": 3.8344,
      "step": 14660
    },
    {
      "epoch": 23.6,
      "learning_rate": 0.0976403560573955,
      "loss": 3.8627,
      "step": 14680
    },
    {
      "epoch": 23.63,
      "learning_rate": 0.09763714062652733,
      "loss": 3.8097,
      "step": 14700
    },
    {
      "epoch": 23.67,
      "learning_rate": 0.09763392519565918,
      "loss": 3.8133,
      "step": 14720
    },
    {
      "epoch": 23.7,
      "learning_rate": 0.097630709764791,
      "loss": 3.773,
      "step": 14740
    },
    {
      "epoch": 23.73,
      "learning_rate": 0.09762749433392283,
      "loss": 3.8085,
      "step": 14760
    },
    {
      "epoch": 23.76,
      "learning_rate": 0.09762427890305467,
      "loss": 3.7952,
      "step": 14780
    },
    {
      "epoch": 23.79,
      "learning_rate": 0.09762106347218649,
      "loss": 3.7412,
      "step": 14800
    },
    {
      "epoch": 23.83,
      "learning_rate": 0.09761784804131833,
      "loss": 3.7904,
      "step": 14820
    },
    {
      "epoch": 23.86,
      "learning_rate": 0.09761479338199357,
      "loss": 3.84,
      "step": 14840
    },
    {
      "epoch": 23.89,
      "learning_rate": 0.0976115779511254,
      "loss": 3.7846,
      "step": 14860
    },
    {
      "epoch": 23.92,
      "learning_rate": 0.09760836252025724,
      "loss": 3.7957,
      "step": 14880
    },
    {
      "epoch": 23.95,
      "learning_rate": 0.09760514708938907,
      "loss": 3.8496,
      "step": 14900
    },
    {
      "epoch": 23.99,
      "learning_rate": 0.09760193165852091,
      "loss": 3.7899,
      "step": 14920
    },
    {
      "epoch": 24.0,
      "eval_accuracy": {
        "accuracy": 0.285936406748037
      },
      "eval_loss": 3.8109989166259766,
      "eval_runtime": 2.4734,
      "eval_samples_per_second": 5200.496,
      "eval_steps_per_second": 81.264,
      "step": 14928
    },
    {
      "epoch": 24.02,
      "learning_rate": 0.09759871622765273,
      "loss": 3.7087,
      "step": 14940
    },
    {
      "epoch": 24.05,
      "learning_rate": 0.09759550079678457,
      "loss": 3.7083,
      "step": 14960
    },
    {
      "epoch": 24.08,
      "learning_rate": 0.09759228536591641,
      "loss": 3.7102,
      "step": 14980
    },
    {
      "epoch": 24.12,
      "learning_rate": 0.09758906993504823,
      "loss": 3.8435,
      "step": 15000
    },
    {
      "epoch": 24.15,
      "learning_rate": 0.09758585450418007,
      "loss": 3.7947,
      "step": 15020
    },
    {
      "epoch": 24.18,
      "learning_rate": 0.0975826390733119,
      "loss": 3.7856,
      "step": 15040
    },
    {
      "epoch": 24.21,
      "learning_rate": 0.09757942364244374,
      "loss": 3.8248,
      "step": 15060
    },
    {
      "epoch": 24.24,
      "learning_rate": 0.09757620821157556,
      "loss": 3.7141,
      "step": 15080
    },
    {
      "epoch": 24.28,
      "learning_rate": 0.0975729927807074,
      "loss": 3.737,
      "step": 15100
    },
    {
      "epoch": 24.31,
      "learning_rate": 0.09756977734983924,
      "loss": 3.7747,
      "step": 15120
    },
    {
      "epoch": 24.34,
      "learning_rate": 0.09756656191897106,
      "loss": 3.7807,
      "step": 15140
    },
    {
      "epoch": 24.37,
      "learning_rate": 0.0975633464881029,
      "loss": 3.8087,
      "step": 15160
    },
    {
      "epoch": 24.41,
      "learning_rate": 0.09756013105723473,
      "loss": 3.7613,
      "step": 15180
    },
    {
      "epoch": 24.44,
      "learning_rate": 0.09755691562636656,
      "loss": 3.7612,
      "step": 15200
    },
    {
      "epoch": 24.47,
      "learning_rate": 0.0975537001954984,
      "loss": 3.7561,
      "step": 15220
    },
    {
      "epoch": 24.5,
      "learning_rate": 0.09755048476463023,
      "loss": 3.8183,
      "step": 15240
    },
    {
      "epoch": 24.53,
      "learning_rate": 0.09754726933376207,
      "loss": 3.9148,
      "step": 15260
    },
    {
      "epoch": 24.57,
      "learning_rate": 0.09754405390289389,
      "loss": 3.8043,
      "step": 15280
    },
    {
      "epoch": 24.6,
      "learning_rate": 0.09754083847202573,
      "loss": 3.7702,
      "step": 15300
    },
    {
      "epoch": 24.63,
      "learning_rate": 0.09753762304115757,
      "loss": 3.8207,
      "step": 15320
    },
    {
      "epoch": 24.66,
      "learning_rate": 0.09753440761028939,
      "loss": 3.7711,
      "step": 15340
    },
    {
      "epoch": 24.69,
      "learning_rate": 0.09753119217942123,
      "loss": 3.7696,
      "step": 15360
    },
    {
      "epoch": 24.73,
      "learning_rate": 0.09752797674855306,
      "loss": 3.7525,
      "step": 15380
    },
    {
      "epoch": 24.76,
      "learning_rate": 0.0975247613176849,
      "loss": 3.7566,
      "step": 15400
    },
    {
      "epoch": 24.79,
      "learning_rate": 0.09752154588681672,
      "loss": 3.7931,
      "step": 15420
    },
    {
      "epoch": 24.82,
      "learning_rate": 0.09751833045594856,
      "loss": 3.7855,
      "step": 15440
    },
    {
      "epoch": 24.86,
      "learning_rate": 0.0975151150250804,
      "loss": 3.7879,
      "step": 15460
    },
    {
      "epoch": 24.89,
      "learning_rate": 0.09751189959421222,
      "loss": 3.8152,
      "step": 15480
    },
    {
      "epoch": 24.92,
      "learning_rate": 0.09750868416334406,
      "loss": 3.7547,
      "step": 15500
    },
    {
      "epoch": 24.95,
      "learning_rate": 0.09750546873247588,
      "loss": 3.7068,
      "step": 15520
    },
    {
      "epoch": 24.98,
      "learning_rate": 0.09750225330160772,
      "loss": 3.7323,
      "step": 15540
    },
    {
      "epoch": 25.0,
      "eval_accuracy": {
        "accuracy": 0.29021223664774937
      },
      "eval_loss": 3.8076586723327637,
      "eval_runtime": 2.5681,
      "eval_samples_per_second": 5008.857,
      "eval_steps_per_second": 78.269,
      "step": 15550
    },
    {
      "epoch": 25.02,
      "learning_rate": 0.09749903787073956,
      "loss": 3.739,
      "step": 15560
    },
    {
      "epoch": 25.05,
      "learning_rate": 0.09749582243987139,
      "loss": 3.7532,
      "step": 15580
    },
    {
      "epoch": 25.08,
      "learning_rate": 0.09749260700900322,
      "loss": 3.7872,
      "step": 15600
    },
    {
      "epoch": 25.11,
      "learning_rate": 0.09748939157813505,
      "loss": 3.7879,
      "step": 15620
    },
    {
      "epoch": 25.14,
      "learning_rate": 0.09748617614726689,
      "loss": 3.8307,
      "step": 15640
    },
    {
      "epoch": 25.18,
      "learning_rate": 0.09748296071639873,
      "loss": 3.7173,
      "step": 15660
    },
    {
      "epoch": 25.21,
      "learning_rate": 0.09747974528553055,
      "loss": 3.7677,
      "step": 15680
    },
    {
      "epoch": 25.24,
      "learning_rate": 0.09747652985466239,
      "loss": 3.7486,
      "step": 15700
    },
    {
      "epoch": 25.27,
      "learning_rate": 0.09747331442379421,
      "loss": 3.738,
      "step": 15720
    },
    {
      "epoch": 25.31,
      "learning_rate": 0.09747009899292605,
      "loss": 3.7777,
      "step": 15740
    },
    {
      "epoch": 25.34,
      "learning_rate": 0.09746688356205789,
      "loss": 3.735,
      "step": 15760
    },
    {
      "epoch": 25.37,
      "learning_rate": 0.09746366813118972,
      "loss": 3.7494,
      "step": 15780
    },
    {
      "epoch": 25.4,
      "learning_rate": 0.09746045270032155,
      "loss": 3.7562,
      "step": 15800
    },
    {
      "epoch": 25.43,
      "learning_rate": 0.09745723726945338,
      "loss": 3.7496,
      "step": 15820
    },
    {
      "epoch": 25.47,
      "learning_rate": 0.09745402183858522,
      "loss": 3.7754,
      "step": 15840
    },
    {
      "epoch": 25.5,
      "learning_rate": 0.09745080640771704,
      "loss": 3.7373,
      "step": 15860
    },
    {
      "epoch": 25.53,
      "learning_rate": 0.09744759097684888,
      "loss": 3.7642,
      "step": 15880
    },
    {
      "epoch": 25.56,
      "learning_rate": 0.09744437554598072,
      "loss": 3.7626,
      "step": 15900
    },
    {
      "epoch": 25.59,
      "learning_rate": 0.09744116011511254,
      "loss": 3.791,
      "step": 15920
    },
    {
      "epoch": 25.63,
      "learning_rate": 0.09743794468424438,
      "loss": 3.7522,
      "step": 15940
    },
    {
      "epoch": 25.66,
      "learning_rate": 0.0974347292533762,
      "loss": 3.7585,
      "step": 15960
    },
    {
      "epoch": 25.69,
      "learning_rate": 0.09743151382250805,
      "loss": 3.7596,
      "step": 15980
    },
    {
      "epoch": 25.72,
      "learning_rate": 0.09742829839163988,
      "loss": 3.8248,
      "step": 16000
    },
    {
      "epoch": 25.76,
      "learning_rate": 0.09742508296077171,
      "loss": 3.8088,
      "step": 16020
    },
    {
      "epoch": 25.79,
      "learning_rate": 0.09742186752990355,
      "loss": 3.7264,
      "step": 16040
    },
    {
      "epoch": 25.82,
      "learning_rate": 0.09741865209903537,
      "loss": 3.7356,
      "step": 16060
    },
    {
      "epoch": 25.85,
      "learning_rate": 0.09741543666816721,
      "loss": 3.7844,
      "step": 16080
    },
    {
      "epoch": 25.88,
      "learning_rate": 0.09741222123729905,
      "loss": 3.8034,
      "step": 16100
    },
    {
      "epoch": 25.92,
      "learning_rate": 0.09740900580643087,
      "loss": 3.7994,
      "step": 16120
    },
    {
      "epoch": 25.95,
      "learning_rate": 0.09740579037556271,
      "loss": 3.7678,
      "step": 16140
    },
    {
      "epoch": 25.98,
      "learning_rate": 0.09740257494469454,
      "loss": 3.7714,
      "step": 16160
    },
    {
      "epoch": 26.0,
      "eval_accuracy": {
        "accuracy": 0.28811319287879966
      },
      "eval_loss": 3.9062747955322266,
      "eval_runtime": 2.9837,
      "eval_samples_per_second": 4311.04,
      "eval_steps_per_second": 67.365,
      "step": 16172
    },
    {
      "epoch": 26.01,
      "learning_rate": 0.09739935951382638,
      "loss": 3.8316,
      "step": 16180
    },
    {
      "epoch": 26.05,
      "learning_rate": 0.0973961440829582,
      "loss": 3.7882,
      "step": 16200
    },
    {
      "epoch": 26.08,
      "learning_rate": 0.09739292865209004,
      "loss": 3.809,
      "step": 16220
    },
    {
      "epoch": 26.11,
      "learning_rate": 0.09738971322122188,
      "loss": 3.7982,
      "step": 16240
    },
    {
      "epoch": 26.14,
      "learning_rate": 0.0973864977903537,
      "loss": 3.8113,
      "step": 16260
    },
    {
      "epoch": 26.17,
      "learning_rate": 0.09738328235948554,
      "loss": 3.7898,
      "step": 16280
    },
    {
      "epoch": 26.21,
      "learning_rate": 0.09738006692861736,
      "loss": 3.7211,
      "step": 16300
    },
    {
      "epoch": 26.24,
      "learning_rate": 0.09737685149774919,
      "loss": 3.7093,
      "step": 16320
    },
    {
      "epoch": 26.27,
      "learning_rate": 0.09737363606688104,
      "loss": 3.7318,
      "step": 16340
    },
    {
      "epoch": 26.3,
      "learning_rate": 0.09737042063601287,
      "loss": 3.7405,
      "step": 16360
    },
    {
      "epoch": 26.33,
      "learning_rate": 0.0973672052051447,
      "loss": 3.6979,
      "step": 16380
    },
    {
      "epoch": 26.37,
      "learning_rate": 0.09736398977427653,
      "loss": 3.7507,
      "step": 16400
    },
    {
      "epoch": 26.4,
      "learning_rate": 0.09736077434340837,
      "loss": 3.7097,
      "step": 16420
    },
    {
      "epoch": 26.43,
      "learning_rate": 0.0973575589125402,
      "loss": 3.6912,
      "step": 16440
    },
    {
      "epoch": 26.46,
      "learning_rate": 0.09735434348167203,
      "loss": 3.7095,
      "step": 16460
    },
    {
      "epoch": 26.5,
      "learning_rate": 0.09735112805080387,
      "loss": 3.7329,
      "step": 16480
    },
    {
      "epoch": 26.53,
      "learning_rate": 0.0973479126199357,
      "loss": 3.7922,
      "step": 16500
    },
    {
      "epoch": 26.56,
      "learning_rate": 0.09734469718906753,
      "loss": 3.7561,
      "step": 16520
    },
    {
      "epoch": 26.59,
      "learning_rate": 0.09734148175819936,
      "loss": 3.7467,
      "step": 16540
    },
    {
      "epoch": 26.62,
      "learning_rate": 0.0973382663273312,
      "loss": 3.7507,
      "step": 16560
    },
    {
      "epoch": 26.66,
      "learning_rate": 0.09733505089646304,
      "loss": 3.7433,
      "step": 16580
    },
    {
      "epoch": 26.69,
      "learning_rate": 0.09733183546559486,
      "loss": 3.7334,
      "step": 16600
    },
    {
      "epoch": 26.72,
      "learning_rate": 0.0973286200347267,
      "loss": 3.6788,
      "step": 16620
    },
    {
      "epoch": 26.75,
      "learning_rate": 0.09732540460385852,
      "loss": 3.7425,
      "step": 16640
    },
    {
      "epoch": 26.78,
      "learning_rate": 0.09732218917299036,
      "loss": 3.8271,
      "step": 16660
    },
    {
      "epoch": 26.82,
      "learning_rate": 0.0973189737421222,
      "loss": 3.7704,
      "step": 16680
    },
    {
      "epoch": 26.85,
      "learning_rate": 0.09731575831125402,
      "loss": 3.6706,
      "step": 16700
    },
    {
      "epoch": 26.88,
      "learning_rate": 0.09731254288038586,
      "loss": 3.6363,
      "step": 16720
    },
    {
      "epoch": 26.91,
      "learning_rate": 0.09730932744951769,
      "loss": 3.6711,
      "step": 16740
    },
    {
      "epoch": 26.95,
      "learning_rate": 0.09730611201864951,
      "loss": 3.6927,
      "step": 16760
    },
    {
      "epoch": 26.98,
      "learning_rate": 0.09730289658778137,
      "loss": 3.7334,
      "step": 16780
    },
    {
      "epoch": 27.0,
      "eval_accuracy": {
        "accuracy": 0.2877244810697349
      },
      "eval_loss": 3.793606758117676,
      "eval_runtime": 2.6618,
      "eval_samples_per_second": 4832.363,
      "eval_steps_per_second": 75.512,
      "step": 16794
    },
    {
      "epoch": 27.01,
      "learning_rate": 0.09729968115691319,
      "loss": 3.7047,
      "step": 16800
    },
    {
      "epoch": 27.04,
      "learning_rate": 0.09729646572604503,
      "loss": 3.752,
      "step": 16820
    },
    {
      "epoch": 27.07,
      "learning_rate": 0.09729325029517685,
      "loss": 3.6917,
      "step": 16840
    },
    {
      "epoch": 27.11,
      "learning_rate": 0.09729003486430868,
      "loss": 3.6821,
      "step": 16860
    },
    {
      "epoch": 27.14,
      "learning_rate": 0.09728681943344052,
      "loss": 3.6443,
      "step": 16880
    },
    {
      "epoch": 27.17,
      "learning_rate": 0.09728360400257235,
      "loss": 3.6622,
      "step": 16900
    },
    {
      "epoch": 27.2,
      "learning_rate": 0.0972803885717042,
      "loss": 3.7221,
      "step": 16920
    },
    {
      "epoch": 27.23,
      "learning_rate": 0.09727733391237943,
      "loss": 3.7145,
      "step": 16940
    },
    {
      "epoch": 27.27,
      "learning_rate": 0.09727411848151125,
      "loss": 3.7397,
      "step": 16960
    },
    {
      "epoch": 27.3,
      "learning_rate": 0.09727090305064309,
      "loss": 3.7884,
      "step": 16980
    },
    {
      "epoch": 27.33,
      "learning_rate": 0.09726768761977492,
      "loss": 3.841,
      "step": 17000
    },
    {
      "epoch": 27.36,
      "learning_rate": 0.09726447218890676,
      "loss": 3.7091,
      "step": 17020
    },
    {
      "epoch": 27.4,
      "learning_rate": 0.0972612567580386,
      "loss": 3.6886,
      "step": 17040
    },
    {
      "epoch": 27.43,
      "learning_rate": 0.09725804132717042,
      "loss": 3.7004,
      "step": 17060
    },
    {
      "epoch": 27.46,
      "learning_rate": 0.09725482589630226,
      "loss": 3.7094,
      "step": 17080
    },
    {
      "epoch": 27.49,
      "learning_rate": 0.09725161046543408,
      "loss": 3.6841,
      "step": 17100
    },
    {
      "epoch": 27.52,
      "learning_rate": 0.09724839503456592,
      "loss": 3.6488,
      "step": 17120
    },
    {
      "epoch": 27.56,
      "learning_rate": 0.09724517960369775,
      "loss": 3.718,
      "step": 17140
    },
    {
      "epoch": 27.59,
      "learning_rate": 0.0972419641728296,
      "loss": 3.7445,
      "step": 17160
    },
    {
      "epoch": 27.62,
      "learning_rate": 0.09723874874196142,
      "loss": 3.7111,
      "step": 17180
    },
    {
      "epoch": 27.65,
      "learning_rate": 0.09723553331109325,
      "loss": 3.6803,
      "step": 17200
    },
    {
      "epoch": 27.68,
      "learning_rate": 0.09723231788022509,
      "loss": 3.6628,
      "step": 17220
    },
    {
      "epoch": 27.72,
      "learning_rate": 0.09722910244935691,
      "loss": 3.6363,
      "step": 17240
    },
    {
      "epoch": 27.75,
      "learning_rate": 0.09722588701848876,
      "loss": 3.6891,
      "step": 17260
    },
    {
      "epoch": 27.78,
      "learning_rate": 0.09722267158762059,
      "loss": 3.7588,
      "step": 17280
    },
    {
      "epoch": 27.81,
      "learning_rate": 0.09721945615675241,
      "loss": 3.7637,
      "step": 17300
    },
    {
      "epoch": 27.85,
      "learning_rate": 0.09721624072588425,
      "loss": 3.7524,
      "step": 17320
    },
    {
      "epoch": 27.88,
      "learning_rate": 0.09721302529501608,
      "loss": 3.6985,
      "step": 17340
    },
    {
      "epoch": 27.91,
      "learning_rate": 0.09720980986414791,
      "loss": 3.7333,
      "step": 17360
    },
    {
      "epoch": 27.94,
      "learning_rate": 0.09720659443327975,
      "loss": 3.7978,
      "step": 17380
    },
    {
      "epoch": 27.97,
      "learning_rate": 0.09720337900241158,
      "loss": 3.7489,
      "step": 17400
    },
    {
      "epoch": 28.0,
      "eval_accuracy": {
        "accuracy": 0.29495452071833944
      },
      "eval_loss": 3.6615982055664062,
      "eval_runtime": 2.9662,
      "eval_samples_per_second": 4336.524,
      "eval_steps_per_second": 67.763,
      "step": 17416
    },
    {
      "epoch": 28.01,
      "learning_rate": 0.09720016357154342,
      "loss": 3.6532,
      "step": 17420
    },
    {
      "epoch": 28.04,
      "learning_rate": 0.09719694814067524,
      "loss": 3.6786,
      "step": 17440
    },
    {
      "epoch": 28.07,
      "learning_rate": 0.09719373270980708,
      "loss": 3.7054,
      "step": 17460
    },
    {
      "epoch": 28.1,
      "learning_rate": 0.0971905172789389,
      "loss": 3.6818,
      "step": 17480
    },
    {
      "epoch": 28.14,
      "learning_rate": 0.09718730184807074,
      "loss": 3.6423,
      "step": 17500
    },
    {
      "epoch": 28.17,
      "learning_rate": 0.09718408641720258,
      "loss": 3.7612,
      "step": 17520
    },
    {
      "epoch": 28.2,
      "learning_rate": 0.0971808709863344,
      "loss": 3.7728,
      "step": 17540
    },
    {
      "epoch": 28.23,
      "learning_rate": 0.09717765555546624,
      "loss": 3.7323,
      "step": 17560
    },
    {
      "epoch": 28.26,
      "learning_rate": 0.09717444012459807,
      "loss": 3.7146,
      "step": 17580
    },
    {
      "epoch": 28.3,
      "learning_rate": 0.09717122469372991,
      "loss": 3.7856,
      "step": 17600
    },
    {
      "epoch": 28.33,
      "learning_rate": 0.09716800926286175,
      "loss": 3.7429,
      "step": 17620
    },
    {
      "epoch": 28.36,
      "learning_rate": 0.09716479383199357,
      "loss": 3.7052,
      "step": 17640
    },
    {
      "epoch": 28.39,
      "learning_rate": 0.09716157840112541,
      "loss": 3.6869,
      "step": 17660
    },
    {
      "epoch": 28.42,
      "learning_rate": 0.09715836297025723,
      "loss": 3.7941,
      "step": 17680
    },
    {
      "epoch": 28.46,
      "learning_rate": 0.09715514753938907,
      "loss": 3.8242,
      "step": 17700
    },
    {
      "epoch": 28.49,
      "learning_rate": 0.09715193210852091,
      "loss": 3.7674,
      "step": 17720
    },
    {
      "epoch": 28.52,
      "learning_rate": 0.09714871667765274,
      "loss": 3.7823,
      "step": 17740
    },
    {
      "epoch": 28.55,
      "learning_rate": 0.09714550124678457,
      "loss": 3.6652,
      "step": 17760
    },
    {
      "epoch": 28.59,
      "learning_rate": 0.0971422858159164,
      "loss": 3.6935,
      "step": 17780
    },
    {
      "epoch": 28.62,
      "learning_rate": 0.09713907038504824,
      "loss": 3.6681,
      "step": 17800
    },
    {
      "epoch": 28.65,
      "learning_rate": 0.09713585495418006,
      "loss": 3.685,
      "step": 17820
    },
    {
      "epoch": 28.68,
      "learning_rate": 0.0971326395233119,
      "loss": 3.718,
      "step": 17840
    },
    {
      "epoch": 28.71,
      "learning_rate": 0.09712942409244374,
      "loss": 3.6688,
      "step": 17860
    },
    {
      "epoch": 28.75,
      "learning_rate": 0.09712620866157556,
      "loss": 3.6401,
      "step": 17880
    },
    {
      "epoch": 28.78,
      "learning_rate": 0.0971229932307074,
      "loss": 3.6489,
      "step": 17900
    },
    {
      "epoch": 28.81,
      "learning_rate": 0.09711977779983923,
      "loss": 3.6481,
      "step": 17920
    },
    {
      "epoch": 28.84,
      "learning_rate": 0.09711656236897107,
      "loss": 3.6113,
      "step": 17940
    },
    {
      "epoch": 28.87,
      "learning_rate": 0.0971133469381029,
      "loss": 3.6958,
      "step": 17960
    },
    {
      "epoch": 28.91,
      "learning_rate": 0.09711013150723473,
      "loss": 3.7425,
      "step": 17980
    },
    {
      "epoch": 28.94,
      "learning_rate": 0.09710691607636657,
      "loss": 3.7222,
      "step": 18000
    },
    {
      "epoch": 28.97,
      "learning_rate": 0.09710370064549839,
      "loss": 3.7242,
      "step": 18020
    },
    {
      "epoch": 29.0,
      "eval_accuracy": {
        "accuracy": 0.2927777345875768
      },
      "eval_loss": 3.8092663288116455,
      "eval_runtime": 2.6178,
      "eval_samples_per_second": 4913.644,
      "eval_steps_per_second": 76.782,
      "step": 18038
    },
    {
      "epoch": 29.0,
      "learning_rate": 0.09710048521463023,
      "loss": 3.754,
      "step": 18040
    },
    {
      "epoch": 29.04,
      "learning_rate": 0.09709726978376207,
      "loss": 3.7414,
      "step": 18060
    },
    {
      "epoch": 29.07,
      "learning_rate": 0.0970940543528939,
      "loss": 3.7058,
      "step": 18080
    },
    {
      "epoch": 29.1,
      "learning_rate": 0.09709083892202573,
      "loss": 3.728,
      "step": 18100
    },
    {
      "epoch": 29.13,
      "learning_rate": 0.09708762349115756,
      "loss": 3.6645,
      "step": 18120
    },
    {
      "epoch": 29.16,
      "learning_rate": 0.0970844080602894,
      "loss": 3.6674,
      "step": 18140
    },
    {
      "epoch": 29.2,
      "learning_rate": 0.09708119262942123,
      "loss": 3.7062,
      "step": 18160
    },
    {
      "epoch": 29.23,
      "learning_rate": 0.09707797719855306,
      "loss": 3.6824,
      "step": 18180
    },
    {
      "epoch": 29.26,
      "learning_rate": 0.0970747617676849,
      "loss": 3.6938,
      "step": 18200
    },
    {
      "epoch": 29.29,
      "learning_rate": 0.09707154633681672,
      "loss": 3.6605,
      "step": 18220
    },
    {
      "epoch": 29.32,
      "learning_rate": 0.09706833090594856,
      "loss": 3.6708,
      "step": 18240
    },
    {
      "epoch": 29.36,
      "learning_rate": 0.09706511547508039,
      "loss": 3.6624,
      "step": 18260
    },
    {
      "epoch": 29.39,
      "learning_rate": 0.09706190004421222,
      "loss": 3.7969,
      "step": 18280
    },
    {
      "epoch": 29.42,
      "learning_rate": 0.09705868461334406,
      "loss": 3.7304,
      "step": 18300
    },
    {
      "epoch": 29.45,
      "learning_rate": 0.09705546918247589,
      "loss": 3.6603,
      "step": 18320
    },
    {
      "epoch": 29.49,
      "learning_rate": 0.09705225375160773,
      "loss": 3.702,
      "step": 18340
    },
    {
      "epoch": 29.52,
      "learning_rate": 0.09704903832073955,
      "loss": 3.6889,
      "step": 18360
    },
    {
      "epoch": 29.55,
      "learning_rate": 0.09704582288987139,
      "loss": 3.6457,
      "step": 18380
    },
    {
      "epoch": 29.58,
      "learning_rate": 0.09704260745900323,
      "loss": 3.6625,
      "step": 18400
    },
    {
      "epoch": 29.61,
      "learning_rate": 0.09703939202813505,
      "loss": 3.7181,
      "step": 18420
    },
    {
      "epoch": 29.65,
      "learning_rate": 0.09703617659726689,
      "loss": 3.7541,
      "step": 18440
    },
    {
      "epoch": 29.68,
      "learning_rate": 0.09703296116639872,
      "loss": 3.8016,
      "step": 18460
    },
    {
      "epoch": 29.71,
      "learning_rate": 0.09702974573553055,
      "loss": 3.6734,
      "step": 18480
    },
    {
      "epoch": 29.74,
      "learning_rate": 0.09702653030466239,
      "loss": 3.6706,
      "step": 18500
    },
    {
      "epoch": 29.77,
      "learning_rate": 0.09702331487379422,
      "loss": 3.7003,
      "step": 18520
    },
    {
      "epoch": 29.81,
      "learning_rate": 0.09702009944292606,
      "loss": 3.736,
      "step": 18540
    },
    {
      "epoch": 29.84,
      "learning_rate": 0.09701688401205788,
      "loss": 3.6907,
      "step": 18560
    },
    {
      "epoch": 29.87,
      "learning_rate": 0.09701366858118972,
      "loss": 3.6951,
      "step": 18580
    },
    {
      "epoch": 29.9,
      "learning_rate": 0.09701045315032154,
      "loss": 3.7941,
      "step": 18600
    },
    {
      "epoch": 29.94,
      "learning_rate": 0.09700723771945338,
      "loss": 3.7739,
      "step": 18620
    },
    {
      "epoch": 29.97,
      "learning_rate": 0.09700402228858522,
      "loss": 3.6352,
      "step": 18640
    },
    {
      "epoch": 30.0,
      "learning_rate": 0.09700080685771705,
      "loss": 3.6815,
      "step": 18660
    },
    {
      "epoch": 30.0,
      "eval_accuracy": {
        "accuracy": 0.29246676514032494
      },
      "eval_loss": 3.7250592708587646,
      "eval_runtime": 3.1484,
      "eval_samples_per_second": 4085.606,
      "eval_steps_per_second": 63.843,
      "step": 18660
    },
    {
      "epoch": 30.03,
      "learning_rate": 0.09699759142684888,
      "loss": 3.6684,
      "step": 18680
    },
    {
      "epoch": 30.06,
      "learning_rate": 0.09699437599598071,
      "loss": 3.6652,
      "step": 18700
    },
    {
      "epoch": 30.1,
      "learning_rate": 0.09699116056511255,
      "loss": 3.7376,
      "step": 18720
    },
    {
      "epoch": 30.13,
      "learning_rate": 0.09698794513424439,
      "loss": 3.7015,
      "step": 18740
    },
    {
      "epoch": 30.16,
      "learning_rate": 0.09698472970337621,
      "loss": 3.6892,
      "step": 18760
    },
    {
      "epoch": 30.19,
      "learning_rate": 0.09698151427250805,
      "loss": 3.6787,
      "step": 18780
    },
    {
      "epoch": 30.23,
      "learning_rate": 0.09697829884163987,
      "loss": 3.6379,
      "step": 18800
    },
    {
      "epoch": 30.26,
      "learning_rate": 0.09697508341077171,
      "loss": 3.6509,
      "step": 18820
    },
    {
      "epoch": 30.29,
      "learning_rate": 0.09697186797990355,
      "loss": 3.6551,
      "step": 18840
    },
    {
      "epoch": 30.32,
      "learning_rate": 0.09696865254903538,
      "loss": 3.646,
      "step": 18860
    },
    {
      "epoch": 30.35,
      "learning_rate": 0.09696543711816721,
      "loss": 3.642,
      "step": 18880
    },
    {
      "epoch": 30.39,
      "learning_rate": 0.09696222168729904,
      "loss": 3.6226,
      "step": 18900
    },
    {
      "epoch": 30.42,
      "learning_rate": 0.09695900625643088,
      "loss": 3.6428,
      "step": 18920
    },
    {
      "epoch": 30.45,
      "learning_rate": 0.0969557908255627,
      "loss": 3.6198,
      "step": 18940
    },
    {
      "epoch": 30.48,
      "learning_rate": 0.09695257539469454,
      "loss": 3.679,
      "step": 18960
    },
    {
      "epoch": 30.51,
      "learning_rate": 0.09694935996382638,
      "loss": 3.6508,
      "step": 18980
    },
    {
      "epoch": 30.55,
      "learning_rate": 0.0969461445329582,
      "loss": 3.6425,
      "step": 19000
    },
    {
      "epoch": 30.58,
      "learning_rate": 0.09694292910209004,
      "loss": 3.6744,
      "step": 19020
    },
    {
      "epoch": 30.61,
      "learning_rate": 0.09693987444276528,
      "loss": 3.6735,
      "step": 19040
    },
    {
      "epoch": 30.64,
      "learning_rate": 0.0969366590118971,
      "loss": 3.687,
      "step": 19060
    },
    {
      "epoch": 30.68,
      "learning_rate": 0.09693344358102894,
      "loss": 3.677,
      "step": 19080
    },
    {
      "epoch": 30.71,
      "learning_rate": 0.09693022815016078,
      "loss": 3.645,
      "step": 19100
    },
    {
      "epoch": 30.74,
      "learning_rate": 0.09692701271929262,
      "loss": 3.6245,
      "step": 19120
    },
    {
      "epoch": 30.77,
      "learning_rate": 0.09692379728842444,
      "loss": 3.646,
      "step": 19140
    },
    {
      "epoch": 30.8,
      "learning_rate": 0.09692058185755627,
      "loss": 3.6497,
      "step": 19160
    },
    {
      "epoch": 30.84,
      "learning_rate": 0.0969173664266881,
      "loss": 3.6828,
      "step": 19180
    },
    {
      "epoch": 30.87,
      "learning_rate": 0.09691415099581993,
      "loss": 3.7033,
      "step": 19200
    },
    {
      "epoch": 30.9,
      "learning_rate": 0.09691093556495178,
      "loss": 3.6455,
      "step": 19220
    },
    {
      "epoch": 30.93,
      "learning_rate": 0.09690772013408361,
      "loss": 3.6058,
      "step": 19240
    },
    {
      "epoch": 30.96,
      "learning_rate": 0.09690450470321543,
      "loss": 3.6215,
      "step": 19260
    },
    {
      "epoch": 31.0,
      "learning_rate": 0.09690128927234727,
      "loss": 3.6478,
      "step": 19280
    },
    {
      "epoch": 31.0,
      "eval_accuracy": {
        "accuracy": 0.2925445075021379
      },
      "eval_loss": 3.7446274757385254,
      "eval_runtime": 2.7729,
      "eval_samples_per_second": 4638.771,
      "eval_steps_per_second": 72.486,
      "step": 19282
    },
    {
      "epoch": 31.03,
      "learning_rate": 0.0968980738414791,
      "loss": 3.7071,
      "step": 19300
    },
    {
      "epoch": 31.06,
      "learning_rate": 0.09689485841061095,
      "loss": 3.7309,
      "step": 19320
    },
    {
      "epoch": 31.09,
      "learning_rate": 0.09689164297974277,
      "loss": 3.6866,
      "step": 19340
    },
    {
      "epoch": 31.13,
      "learning_rate": 0.09688842754887461,
      "loss": 3.6413,
      "step": 19360
    },
    {
      "epoch": 31.16,
      "learning_rate": 0.09688521211800644,
      "loss": 3.664,
      "step": 19380
    },
    {
      "epoch": 31.19,
      "learning_rate": 0.09688199668713826,
      "loss": 3.6988,
      "step": 19400
    },
    {
      "epoch": 31.22,
      "learning_rate": 0.0968787812562701,
      "loss": 3.7614,
      "step": 19420
    },
    {
      "epoch": 31.25,
      "learning_rate": 0.09687556582540194,
      "loss": 3.6948,
      "step": 19440
    },
    {
      "epoch": 31.29,
      "learning_rate": 0.09687235039453378,
      "loss": 3.699,
      "step": 19460
    },
    {
      "epoch": 31.32,
      "learning_rate": 0.0968691349636656,
      "loss": 3.7231,
      "step": 19480
    },
    {
      "epoch": 31.35,
      "learning_rate": 0.09686591953279743,
      "loss": 3.6573,
      "step": 19500
    },
    {
      "epoch": 31.38,
      "learning_rate": 0.09686270410192926,
      "loss": 3.7164,
      "step": 19520
    },
    {
      "epoch": 31.41,
      "learning_rate": 0.09685948867106109,
      "loss": 3.7121,
      "step": 19540
    },
    {
      "epoch": 31.45,
      "learning_rate": 0.09685627324019294,
      "loss": 3.6344,
      "step": 19560
    },
    {
      "epoch": 31.48,
      "learning_rate": 0.09685305780932477,
      "loss": 3.6844,
      "step": 19580
    },
    {
      "epoch": 31.51,
      "learning_rate": 0.09684984237845659,
      "loss": 3.6325,
      "step": 19600
    },
    {
      "epoch": 31.54,
      "learning_rate": 0.09684662694758843,
      "loss": 3.6345,
      "step": 19620
    },
    {
      "epoch": 31.58,
      "learning_rate": 0.09684341151672025,
      "loss": 3.6399,
      "step": 19640
    },
    {
      "epoch": 31.61,
      "learning_rate": 0.0968401960858521,
      "loss": 3.6567,
      "step": 19660
    },
    {
      "epoch": 31.64,
      "learning_rate": 0.09683698065498393,
      "loss": 3.663,
      "step": 19680
    },
    {
      "epoch": 31.67,
      "learning_rate": 0.09683376522411576,
      "loss": 3.6509,
      "step": 19700
    },
    {
      "epoch": 31.7,
      "learning_rate": 0.0968305497932476,
      "loss": 3.6849,
      "step": 19720
    },
    {
      "epoch": 31.74,
      "learning_rate": 0.09682733436237942,
      "loss": 3.6086,
      "step": 19740
    },
    {
      "epoch": 31.77,
      "learning_rate": 0.09682411893151126,
      "loss": 3.6598,
      "step": 19760
    },
    {
      "epoch": 31.8,
      "learning_rate": 0.0968209035006431,
      "loss": 3.6522,
      "step": 19780
    },
    {
      "epoch": 31.83,
      "learning_rate": 0.09681768806977492,
      "loss": 3.6631,
      "step": 19800
    },
    {
      "epoch": 31.86,
      "learning_rate": 0.09681447263890676,
      "loss": 3.6526,
      "step": 19820
    },
    {
      "epoch": 31.9,
      "learning_rate": 0.09681125720803858,
      "loss": 3.6998,
      "step": 19840
    },
    {
      "epoch": 31.93,
      "learning_rate": 0.09680804177717042,
      "loss": 3.7004,
      "step": 19860
    },
    {
      "epoch": 31.96,
      "learning_rate": 0.09680482634630225,
      "loss": 3.6495,
      "step": 19880
    },
    {
      "epoch": 31.99,
      "learning_rate": 0.09680161091543409,
      "loss": 3.6638,
      "step": 19900
    },
    {
      "epoch": 32.0,
      "eval_accuracy": {
        "accuracy": 0.2913006297131307
      },
      "eval_loss": 3.7059731483459473,
      "eval_runtime": 2.5544,
      "eval_samples_per_second": 5035.615,
      "eval_steps_per_second": 78.688,
      "step": 19904
    },
    {
      "epoch": 32.03,
      "learning_rate": 0.09679839548456592,
      "loss": 3.6773,
      "step": 19920
    },
    {
      "epoch": 32.06,
      "learning_rate": 0.09679518005369775,
      "loss": 3.6503,
      "step": 19940
    },
    {
      "epoch": 32.09,
      "learning_rate": 0.09679196462282959,
      "loss": 3.6521,
      "step": 19960
    },
    {
      "epoch": 32.12,
      "learning_rate": 0.09678874919196141,
      "loss": 3.6144,
      "step": 19980
    },
    {
      "epoch": 32.15,
      "learning_rate": 0.09678553376109326,
      "loss": 3.5589,
      "step": 20000
    },
    {
      "epoch": 32.19,
      "learning_rate": 0.09678231833022509,
      "loss": 3.6422,
      "step": 20020
    },
    {
      "epoch": 32.22,
      "learning_rate": 0.09677910289935691,
      "loss": 3.6637,
      "step": 20040
    },
    {
      "epoch": 32.25,
      "learning_rate": 0.09677588746848875,
      "loss": 3.6055,
      "step": 20060
    },
    {
      "epoch": 32.28,
      "learning_rate": 0.09677267203762058,
      "loss": 3.6427,
      "step": 20080
    },
    {
      "epoch": 32.32,
      "learning_rate": 0.09676945660675242,
      "loss": 3.6748,
      "step": 20100
    },
    {
      "epoch": 32.35,
      "learning_rate": 0.09676624117588425,
      "loss": 3.6411,
      "step": 20120
    },
    {
      "epoch": 32.38,
      "learning_rate": 0.09676302574501608,
      "loss": 3.599,
      "step": 20140
    },
    {
      "epoch": 32.41,
      "learning_rate": 0.09675981031414792,
      "loss": 3.5967,
      "step": 20160
    },
    {
      "epoch": 32.44,
      "learning_rate": 0.09675659488327974,
      "loss": 3.6235,
      "step": 20180
    },
    {
      "epoch": 32.48,
      "learning_rate": 0.09675337945241158,
      "loss": 3.6177,
      "step": 20200
    },
    {
      "epoch": 32.51,
      "learning_rate": 0.0967501640215434,
      "loss": 3.6333,
      "step": 20220
    },
    {
      "epoch": 32.54,
      "learning_rate": 0.09674694859067524,
      "loss": 3.6107,
      "step": 20240
    },
    {
      "epoch": 32.57,
      "learning_rate": 0.09674373315980708,
      "loss": 3.677,
      "step": 20260
    },
    {
      "epoch": 32.6,
      "learning_rate": 0.09674051772893891,
      "loss": 3.6806,
      "step": 20280
    },
    {
      "epoch": 32.64,
      "learning_rate": 0.09673730229807075,
      "loss": 3.6291,
      "step": 20300
    },
    {
      "epoch": 32.67,
      "learning_rate": 0.09673408686720257,
      "loss": 3.5854,
      "step": 20320
    },
    {
      "epoch": 32.7,
      "learning_rate": 0.09673087143633441,
      "loss": 3.6056,
      "step": 20340
    },
    {
      "epoch": 32.73,
      "learning_rate": 0.09672765600546625,
      "loss": 3.6066,
      "step": 20360
    },
    {
      "epoch": 32.77,
      "learning_rate": 0.09672444057459807,
      "loss": 3.6111,
      "step": 20380
    },
    {
      "epoch": 32.8,
      "learning_rate": 0.09672122514372991,
      "loss": 3.676,
      "step": 20400
    },
    {
      "epoch": 32.83,
      "learning_rate": 0.09671800971286174,
      "loss": 3.6956,
      "step": 20420
    },
    {
      "epoch": 32.86,
      "learning_rate": 0.09671479428199357,
      "loss": 3.6995,
      "step": 20440
    },
    {
      "epoch": 32.89,
      "learning_rate": 0.09671157885112541,
      "loss": 3.6631,
      "step": 20460
    },
    {
      "epoch": 32.93,
      "learning_rate": 0.09670836342025724,
      "loss": 3.6403,
      "step": 20480
    },
    {
      "epoch": 32.96,
      "learning_rate": 0.09670514798938908,
      "loss": 3.6876,
      "step": 20500
    },
    {
      "epoch": 32.99,
      "learning_rate": 0.0967019325585209,
      "loss": 3.7354,
      "step": 20520
    },
    {
      "epoch": 33.0,
      "eval_accuracy": {
        "accuracy": 0.2917670838840084
      },
      "eval_loss": 3.7380149364471436,
      "eval_runtime": 2.5245,
      "eval_samples_per_second": 5095.167,
      "eval_steps_per_second": 79.618,
      "step": 20526
    },
    {
      "epoch": 33.02,
      "learning_rate": 0.09669871712765274,
      "loss": 3.6544,
      "step": 20540
    },
    {
      "epoch": 33.05,
      "learning_rate": 0.09669550169678456,
      "loss": 3.5826,
      "step": 20560
    },
    {
      "epoch": 33.09,
      "learning_rate": 0.0966922862659164,
      "loss": 3.628,
      "step": 20580
    },
    {
      "epoch": 33.12,
      "learning_rate": 0.09668907083504824,
      "loss": 3.6552,
      "step": 20600
    },
    {
      "epoch": 33.15,
      "learning_rate": 0.09668585540418007,
      "loss": 3.6236,
      "step": 20620
    },
    {
      "epoch": 33.18,
      "learning_rate": 0.0966826399733119,
      "loss": 3.6118,
      "step": 20640
    },
    {
      "epoch": 33.22,
      "learning_rate": 0.09667942454244373,
      "loss": 3.5809,
      "step": 20660
    },
    {
      "epoch": 33.25,
      "learning_rate": 0.09667620911157557,
      "loss": 3.6169,
      "step": 20680
    },
    {
      "epoch": 33.28,
      "learning_rate": 0.0966729936807074,
      "loss": 3.6908,
      "step": 20700
    },
    {
      "epoch": 33.31,
      "learning_rate": 0.09666977824983923,
      "loss": 3.6009,
      "step": 20720
    },
    {
      "epoch": 33.34,
      "learning_rate": 0.09666656281897107,
      "loss": 3.6514,
      "step": 20740
    },
    {
      "epoch": 33.38,
      "learning_rate": 0.0966633473881029,
      "loss": 3.6576,
      "step": 20760
    },
    {
      "epoch": 33.41,
      "learning_rate": 0.09666013195723473,
      "loss": 3.6505,
      "step": 20780
    },
    {
      "epoch": 33.44,
      "learning_rate": 0.09665691652636657,
      "loss": 3.6827,
      "step": 20800
    },
    {
      "epoch": 33.47,
      "learning_rate": 0.0966537010954984,
      "loss": 3.7375,
      "step": 20820
    },
    {
      "epoch": 33.5,
      "learning_rate": 0.09665048566463023,
      "loss": 3.7361,
      "step": 20840
    },
    {
      "epoch": 33.54,
      "learning_rate": 0.09664727023376206,
      "loss": 3.6159,
      "step": 20860
    },
    {
      "epoch": 33.57,
      "learning_rate": 0.0966440548028939,
      "loss": 3.6023,
      "step": 20880
    },
    {
      "epoch": 33.6,
      "learning_rate": 0.09664083937202572,
      "loss": 3.5952,
      "step": 20900
    },
    {
      "epoch": 33.63,
      "learning_rate": 0.09663762394115756,
      "loss": 3.642,
      "step": 20920
    },
    {
      "epoch": 33.67,
      "learning_rate": 0.0966344085102894,
      "loss": 3.5889,
      "step": 20940
    },
    {
      "epoch": 33.7,
      "learning_rate": 0.09663119307942122,
      "loss": 3.5906,
      "step": 20960
    },
    {
      "epoch": 33.73,
      "learning_rate": 0.09662797764855306,
      "loss": 3.6724,
      "step": 20980
    },
    {
      "epoch": 33.76,
      "learning_rate": 0.09662476221768489,
      "loss": 3.6926,
      "step": 21000
    },
    {
      "epoch": 33.79,
      "learning_rate": 0.09662154678681673,
      "loss": 3.6513,
      "step": 21020
    },
    {
      "epoch": 33.83,
      "learning_rate": 0.09661833135594856,
      "loss": 3.6612,
      "step": 21040
    },
    {
      "epoch": 33.86,
      "learning_rate": 0.09661511592508039,
      "loss": 3.6098,
      "step": 21060
    },
    {
      "epoch": 33.89,
      "learning_rate": 0.09661190049421223,
      "loss": 3.591,
      "step": 21080
    },
    {
      "epoch": 33.92,
      "learning_rate": 0.09660868506334405,
      "loss": 3.6113,
      "step": 21100
    },
    {
      "epoch": 33.95,
      "learning_rate": 0.09660546963247589,
      "loss": 3.5605,
      "step": 21120
    },
    {
      "epoch": 33.99,
      "learning_rate": 0.09660225420160773,
      "loss": 3.5952,
      "step": 21140
    },
    {
      "epoch": 34.0,
      "eval_accuracy": {
        "accuracy": 0.30669361735209516
      },
      "eval_loss": 3.6524293422698975,
      "eval_runtime": 2.4399,
      "eval_samples_per_second": 5271.831,
      "eval_steps_per_second": 82.379,
      "step": 21148
    },
    {
      "epoch": 34.02,
      "learning_rate": 0.09659903877073955,
      "loss": 3.5503,
      "step": 21160
    },
    {
      "epoch": 34.05,
      "learning_rate": 0.09659582333987139,
      "loss": 3.5826,
      "step": 21180
    },
    {
      "epoch": 34.08,
      "learning_rate": 0.09659260790900322,
      "loss": 3.5511,
      "step": 21200
    },
    {
      "epoch": 34.12,
      "learning_rate": 0.09658939247813506,
      "loss": 3.6574,
      "step": 21220
    },
    {
      "epoch": 34.15,
      "learning_rate": 0.0965861770472669,
      "loss": 3.639,
      "step": 21240
    },
    {
      "epoch": 34.18,
      "learning_rate": 0.09658296161639872,
      "loss": 3.6446,
      "step": 21260
    },
    {
      "epoch": 34.21,
      "learning_rate": 0.09657974618553056,
      "loss": 3.6097,
      "step": 21280
    },
    {
      "epoch": 34.24,
      "learning_rate": 0.09657653075466238,
      "loss": 3.5825,
      "step": 21300
    },
    {
      "epoch": 34.28,
      "learning_rate": 0.09657331532379422,
      "loss": 3.544,
      "step": 21320
    },
    {
      "epoch": 34.31,
      "learning_rate": 0.09657009989292605,
      "loss": 3.5425,
      "step": 21340
    },
    {
      "epoch": 34.34,
      "learning_rate": 0.09656688446205788,
      "loss": 3.5559,
      "step": 21360
    },
    {
      "epoch": 34.37,
      "learning_rate": 0.09656366903118972,
      "loss": 3.6034,
      "step": 21380
    },
    {
      "epoch": 34.41,
      "learning_rate": 0.09656061437186496,
      "loss": 3.6849,
      "step": 21400
    },
    {
      "epoch": 34.44,
      "learning_rate": 0.0965573989409968,
      "loss": 3.5477,
      "step": 21420
    },
    {
      "epoch": 34.47,
      "learning_rate": 0.09655418351012862,
      "loss": 3.5611,
      "step": 21440
    },
    {
      "epoch": 34.5,
      "learning_rate": 0.09655096807926045,
      "loss": 3.6007,
      "step": 21460
    },
    {
      "epoch": 34.53,
      "learning_rate": 0.09654775264839228,
      "loss": 3.6683,
      "step": 21480
    },
    {
      "epoch": 34.57,
      "learning_rate": 0.09654453721752412,
      "loss": 3.6034,
      "step": 21500
    },
    {
      "epoch": 34.6,
      "learning_rate": 0.09654132178665596,
      "loss": 3.6404,
      "step": 21520
    },
    {
      "epoch": 34.63,
      "learning_rate": 0.09653810635578779,
      "loss": 3.6042,
      "step": 21540
    },
    {
      "epoch": 34.66,
      "learning_rate": 0.09653489092491963,
      "loss": 3.6616,
      "step": 21560
    },
    {
      "epoch": 34.69,
      "learning_rate": 0.09653167549405145,
      "loss": 3.5877,
      "step": 21580
    },
    {
      "epoch": 34.73,
      "learning_rate": 0.09652846006318327,
      "loss": 3.5967,
      "step": 21600
    },
    {
      "epoch": 34.76,
      "learning_rate": 0.09652524463231513,
      "loss": 3.6836,
      "step": 21620
    },
    {
      "epoch": 34.79,
      "learning_rate": 0.09652202920144695,
      "loss": 3.6524,
      "step": 21640
    },
    {
      "epoch": 34.82,
      "learning_rate": 0.09651881377057879,
      "loss": 3.6227,
      "step": 21660
    },
    {
      "epoch": 34.86,
      "learning_rate": 0.09651559833971061,
      "loss": 3.6079,
      "step": 21680
    },
    {
      "epoch": 34.89,
      "learning_rate": 0.09651238290884244,
      "loss": 3.6881,
      "step": 21700
    },
    {
      "epoch": 34.92,
      "learning_rate": 0.09650916747797429,
      "loss": 3.6385,
      "step": 21720
    },
    {
      "epoch": 34.95,
      "learning_rate": 0.09650595204710612,
      "loss": 3.5905,
      "step": 21740
    },
    {
      "epoch": 34.98,
      "learning_rate": 0.09650273661623796,
      "loss": 3.6801,
      "step": 21760
    },
    {
      "epoch": 35.0,
      "eval_accuracy": {
        "accuracy": 0.30443908885951954
      },
      "eval_loss": 3.6594974994659424,
      "eval_runtime": 2.4508,
      "eval_samples_per_second": 5248.556,
      "eval_steps_per_second": 82.015,
      "step": 21770
    },
    {
      "epoch": 35.02,
      "learning_rate": 0.09649952118536978,
      "loss": 3.6371,
      "step": 21780
    },
    {
      "epoch": 35.05,
      "learning_rate": 0.0964963057545016,
      "loss": 3.6538,
      "step": 21800
    },
    {
      "epoch": 35.08,
      "learning_rate": 0.09649309032363344,
      "loss": 3.7293,
      "step": 21820
    },
    {
      "epoch": 35.11,
      "learning_rate": 0.09648987489276528,
      "loss": 3.6348,
      "step": 21840
    },
    {
      "epoch": 35.14,
      "learning_rate": 0.09648665946189712,
      "loss": 3.5944,
      "step": 21860
    },
    {
      "epoch": 35.18,
      "learning_rate": 0.09648344403102894,
      "loss": 3.5891,
      "step": 21880
    },
    {
      "epoch": 35.21,
      "learning_rate": 0.09648022860016077,
      "loss": 3.5641,
      "step": 21900
    },
    {
      "epoch": 35.24,
      "learning_rate": 0.09647701316929261,
      "loss": 3.5686,
      "step": 21920
    },
    {
      "epoch": 35.27,
      "learning_rate": 0.09647379773842443,
      "loss": 3.6092,
      "step": 21940
    },
    {
      "epoch": 35.31,
      "learning_rate": 0.09647058230755629,
      "loss": 3.5929,
      "step": 21960
    },
    {
      "epoch": 35.34,
      "learning_rate": 0.09646736687668811,
      "loss": 3.5881,
      "step": 21980
    },
    {
      "epoch": 35.37,
      "learning_rate": 0.09646415144581993,
      "loss": 3.5933,
      "step": 22000
    },
    {
      "epoch": 35.4,
      "learning_rate": 0.09646093601495177,
      "loss": 3.5914,
      "step": 22020
    },
    {
      "epoch": 35.43,
      "learning_rate": 0.0964577205840836,
      "loss": 3.6041,
      "step": 22040
    },
    {
      "epoch": 35.47,
      "learning_rate": 0.09645450515321545,
      "loss": 3.6028,
      "step": 22060
    },
    {
      "epoch": 35.5,
      "learning_rate": 0.09645128972234727,
      "loss": 3.5908,
      "step": 22080
    },
    {
      "epoch": 35.53,
      "learning_rate": 0.0964480742914791,
      "loss": 3.5567,
      "step": 22100
    },
    {
      "epoch": 35.56,
      "learning_rate": 0.09644485886061094,
      "loss": 3.5415,
      "step": 22120
    },
    {
      "epoch": 35.59,
      "learning_rate": 0.09644164342974276,
      "loss": 3.5403,
      "step": 22140
    },
    {
      "epoch": 35.63,
      "learning_rate": 0.0964384279988746,
      "loss": 3.5869,
      "step": 22160
    },
    {
      "epoch": 35.66,
      "learning_rate": 0.09643521256800644,
      "loss": 3.5497,
      "step": 22180
    },
    {
      "epoch": 35.69,
      "learning_rate": 0.09643199713713828,
      "loss": 3.6014,
      "step": 22200
    },
    {
      "epoch": 35.72,
      "learning_rate": 0.0964287817062701,
      "loss": 3.6643,
      "step": 22220
    },
    {
      "epoch": 35.76,
      "learning_rate": 0.09642556627540193,
      "loss": 3.6452,
      "step": 22240
    },
    {
      "epoch": 35.79,
      "learning_rate": 0.09642235084453377,
      "loss": 3.6895,
      "step": 22260
    },
    {
      "epoch": 35.82,
      "learning_rate": 0.09641913541366559,
      "loss": 3.6617,
      "step": 22280
    },
    {
      "epoch": 35.85,
      "learning_rate": 0.09641591998279744,
      "loss": 3.7262,
      "step": 22300
    },
    {
      "epoch": 35.88,
      "learning_rate": 0.09641270455192927,
      "loss": 3.6795,
      "step": 22320
    },
    {
      "epoch": 35.92,
      "learning_rate": 0.09640948912106109,
      "loss": 3.6422,
      "step": 22340
    },
    {
      "epoch": 35.95,
      "learning_rate": 0.09640627369019293,
      "loss": 3.5646,
      "step": 22360
    },
    {
      "epoch": 35.98,
      "learning_rate": 0.09640305825932476,
      "loss": 3.5801,
      "step": 22380
    },
    {
      "epoch": 36.0,
      "eval_accuracy": {
        "accuracy": 0.3012516520251885
      },
      "eval_loss": 3.6158149242401123,
      "eval_runtime": 2.5623,
      "eval_samples_per_second": 5020.112,
      "eval_steps_per_second": 78.445,
      "step": 22392
    },
    {
      "epoch": 36.01,
      "learning_rate": 0.09639984282845661,
      "loss": 3.6123,
      "step": 22400
    },
    {
      "epoch": 36.05,
      "learning_rate": 0.09639662739758843,
      "loss": 3.67,
      "step": 22420
    },
    {
      "epoch": 36.08,
      "learning_rate": 0.09639341196672026,
      "loss": 3.5839,
      "step": 22440
    },
    {
      "epoch": 36.11,
      "learning_rate": 0.0963901965358521,
      "loss": 3.5886,
      "step": 22460
    },
    {
      "epoch": 36.14,
      "learning_rate": 0.09638698110498392,
      "loss": 3.5994,
      "step": 22480
    },
    {
      "epoch": 36.17,
      "learning_rate": 0.09638376567411576,
      "loss": 3.6354,
      "step": 22500
    },
    {
      "epoch": 36.21,
      "learning_rate": 0.0963805502432476,
      "loss": 3.5935,
      "step": 22520
    },
    {
      "epoch": 36.24,
      "learning_rate": 0.09637733481237942,
      "loss": 3.5929,
      "step": 22540
    },
    {
      "epoch": 36.27,
      "learning_rate": 0.09637411938151126,
      "loss": 3.5964,
      "step": 22560
    },
    {
      "epoch": 36.3,
      "learning_rate": 0.09637090395064309,
      "loss": 3.5983,
      "step": 22580
    },
    {
      "epoch": 36.33,
      "learning_rate": 0.09636768851977492,
      "loss": 3.5623,
      "step": 22600
    },
    {
      "epoch": 36.37,
      "learning_rate": 0.09636447308890675,
      "loss": 3.5801,
      "step": 22620
    },
    {
      "epoch": 36.4,
      "learning_rate": 0.09636125765803859,
      "loss": 3.6857,
      "step": 22640
    },
    {
      "epoch": 36.43,
      "learning_rate": 0.09635804222717043,
      "loss": 3.6091,
      "step": 22660
    },
    {
      "epoch": 36.46,
      "learning_rate": 0.09635482679630225,
      "loss": 3.5813,
      "step": 22680
    },
    {
      "epoch": 36.5,
      "learning_rate": 0.09635161136543409,
      "loss": 3.5247,
      "step": 22700
    },
    {
      "epoch": 36.53,
      "learning_rate": 0.09634839593456591,
      "loss": 3.5385,
      "step": 22720
    },
    {
      "epoch": 36.56,
      "learning_rate": 0.09634518050369775,
      "loss": 3.5605,
      "step": 22740
    },
    {
      "epoch": 36.59,
      "learning_rate": 0.09634196507282959,
      "loss": 3.5471,
      "step": 22760
    },
    {
      "epoch": 36.62,
      "learning_rate": 0.09633874964196142,
      "loss": 3.5338,
      "step": 22780
    },
    {
      "epoch": 36.66,
      "learning_rate": 0.09633553421109325,
      "loss": 3.5356,
      "step": 22800
    },
    {
      "epoch": 36.69,
      "learning_rate": 0.09633231878022508,
      "loss": 3.6171,
      "step": 22820
    },
    {
      "epoch": 36.72,
      "learning_rate": 0.09632910334935692,
      "loss": 3.6626,
      "step": 22840
    },
    {
      "epoch": 36.75,
      "learning_rate": 0.09632588791848876,
      "loss": 3.6527,
      "step": 22860
    },
    {
      "epoch": 36.78,
      "learning_rate": 0.09632267248762058,
      "loss": 3.5961,
      "step": 22880
    },
    {
      "epoch": 36.82,
      "learning_rate": 0.09631945705675242,
      "loss": 3.5566,
      "step": 22900
    },
    {
      "epoch": 36.85,
      "learning_rate": 0.09631624162588424,
      "loss": 3.5176,
      "step": 22920
    },
    {
      "epoch": 36.88,
      "learning_rate": 0.09631302619501608,
      "loss": 3.5446,
      "step": 22940
    },
    {
      "epoch": 36.91,
      "learning_rate": 0.09630981076414791,
      "loss": 3.533,
      "step": 22960
    },
    {
      "epoch": 36.95,
      "learning_rate": 0.09630659533327975,
      "loss": 3.5625,
      "step": 22980
    },
    {
      "epoch": 36.98,
      "learning_rate": 0.09630337990241158,
      "loss": 3.5422,
      "step": 23000
    },
    {
      "epoch": 37.0,
      "eval_accuracy": {
        "accuracy": 0.2959651714219078
      },
      "eval_loss": 3.642108201980591,
      "eval_runtime": 2.7368,
      "eval_samples_per_second": 4699.985,
      "eval_steps_per_second": 73.443,
      "step": 23014
    },
    {
      "epoch": 37.01,
      "learning_rate": 0.09630016447154341,
      "loss": 3.5671,
      "step": 23020
    },
    {
      "epoch": 37.04,
      "learning_rate": 0.09629694904067525,
      "loss": 3.5725,
      "step": 23040
    },
    {
      "epoch": 37.07,
      "learning_rate": 0.09629373360980707,
      "loss": 3.582,
      "step": 23060
    },
    {
      "epoch": 37.11,
      "learning_rate": 0.09629051817893891,
      "loss": 3.5754,
      "step": 23080
    },
    {
      "epoch": 37.14,
      "learning_rate": 0.09628730274807075,
      "loss": 3.6367,
      "step": 23100
    },
    {
      "epoch": 37.17,
      "learning_rate": 0.09628408731720257,
      "loss": 3.6253,
      "step": 23120
    },
    {
      "epoch": 37.2,
      "learning_rate": 0.09628087188633441,
      "loss": 3.5882,
      "step": 23140
    },
    {
      "epoch": 37.23,
      "learning_rate": 0.09627765645546624,
      "loss": 3.5308,
      "step": 23160
    },
    {
      "epoch": 37.27,
      "learning_rate": 0.09627444102459808,
      "loss": 3.5298,
      "step": 23180
    },
    {
      "epoch": 37.3,
      "learning_rate": 0.09627122559372991,
      "loss": 3.6615,
      "step": 23200
    },
    {
      "epoch": 37.33,
      "learning_rate": 0.09626801016286174,
      "loss": 3.6829,
      "step": 23220
    },
    {
      "epoch": 37.36,
      "learning_rate": 0.09626479473199358,
      "loss": 3.6487,
      "step": 23240
    },
    {
      "epoch": 37.4,
      "learning_rate": 0.0962615793011254,
      "loss": 3.645,
      "step": 23260
    },
    {
      "epoch": 37.43,
      "learning_rate": 0.09625836387025724,
      "loss": 3.6503,
      "step": 23280
    },
    {
      "epoch": 37.46,
      "learning_rate": 0.09625514843938907,
      "loss": 3.6664,
      "step": 23300
    },
    {
      "epoch": 37.49,
      "learning_rate": 0.0962519330085209,
      "loss": 3.5609,
      "step": 23320
    },
    {
      "epoch": 37.52,
      "learning_rate": 0.09624871757765274,
      "loss": 3.6131,
      "step": 23340
    },
    {
      "epoch": 37.56,
      "learning_rate": 0.09624550214678457,
      "loss": 3.6442,
      "step": 23360
    },
    {
      "epoch": 37.59,
      "learning_rate": 0.0962422867159164,
      "loss": 3.6369,
      "step": 23380
    },
    {
      "epoch": 37.62,
      "learning_rate": 0.09623907128504823,
      "loss": 3.6374,
      "step": 23400
    },
    {
      "epoch": 37.65,
      "learning_rate": 0.09623585585418007,
      "loss": 3.5946,
      "step": 23420
    },
    {
      "epoch": 37.68,
      "learning_rate": 0.09623264042331191,
      "loss": 3.5901,
      "step": 23440
    },
    {
      "epoch": 37.72,
      "learning_rate": 0.09622942499244373,
      "loss": 3.5908,
      "step": 23460
    },
    {
      "epoch": 37.75,
      "learning_rate": 0.09622620956157557,
      "loss": 3.5924,
      "step": 23480
    },
    {
      "epoch": 37.78,
      "learning_rate": 0.09622315490225081,
      "loss": 3.5934,
      "step": 23500
    },
    {
      "epoch": 37.81,
      "learning_rate": 0.09621993947138265,
      "loss": 3.631,
      "step": 23520
    },
    {
      "epoch": 37.85,
      "learning_rate": 0.09621672404051447,
      "loss": 3.6139,
      "step": 23540
    },
    {
      "epoch": 37.88,
      "learning_rate": 0.09621350860964631,
      "loss": 3.642,
      "step": 23560
    },
    {
      "epoch": 37.91,
      "learning_rate": 0.09621029317877815,
      "loss": 3.6612,
      "step": 23580
    },
    {
      "epoch": 37.94,
      "learning_rate": 0.09620707774790997,
      "loss": 3.6006,
      "step": 23600
    },
    {
      "epoch": 37.97,
      "learning_rate": 0.09620386231704181,
      "loss": 3.5531,
      "step": 23620
    },
    {
      "epoch": 38.0,
      "eval_accuracy": {
        "accuracy": 0.31003653891005206
      },
      "eval_loss": 3.5993340015411377,
      "eval_runtime": 2.4771,
      "eval_samples_per_second": 5192.844,
      "eval_steps_per_second": 81.145,
      "step": 23636
    },
    {
      "epoch": 38.01,
      "learning_rate": 0.09620064688617364,
      "loss": 3.5283,
      "step": 23640
    },
    {
      "epoch": 38.04,
      "learning_rate": 0.09619743145530546,
      "loss": 3.5359,
      "step": 23660
    },
    {
      "epoch": 38.07,
      "learning_rate": 0.09619421602443731,
      "loss": 3.5419,
      "step": 23680
    },
    {
      "epoch": 38.1,
      "learning_rate": 0.09619100059356914,
      "loss": 3.5712,
      "step": 23700
    },
    {
      "epoch": 38.14,
      "learning_rate": 0.09618778516270098,
      "loss": 3.5858,
      "step": 23720
    },
    {
      "epoch": 38.17,
      "learning_rate": 0.0961845697318328,
      "loss": 3.5589,
      "step": 23740
    },
    {
      "epoch": 38.2,
      "learning_rate": 0.09618135430096464,
      "loss": 3.5311,
      "step": 23760
    },
    {
      "epoch": 38.23,
      "learning_rate": 0.09617813887009648,
      "loss": 3.6213,
      "step": 23780
    },
    {
      "epoch": 38.26,
      "learning_rate": 0.0961749234392283,
      "loss": 3.5943,
      "step": 23800
    },
    {
      "epoch": 38.3,
      "learning_rate": 0.09617170800836014,
      "loss": 3.6259,
      "step": 23820
    },
    {
      "epoch": 38.33,
      "learning_rate": 0.09616849257749197,
      "loss": 3.6162,
      "step": 23840
    },
    {
      "epoch": 38.36,
      "learning_rate": 0.0961652771466238,
      "loss": 3.6703,
      "step": 23860
    },
    {
      "epoch": 38.39,
      "learning_rate": 0.09616206171575563,
      "loss": 3.5361,
      "step": 23880
    },
    {
      "epoch": 38.42,
      "learning_rate": 0.09615884628488747,
      "loss": 3.5408,
      "step": 23900
    },
    {
      "epoch": 38.46,
      "learning_rate": 0.0961556308540193,
      "loss": 3.5788,
      "step": 23920
    },
    {
      "epoch": 38.49,
      "learning_rate": 0.09615241542315113,
      "loss": 3.5955,
      "step": 23940
    },
    {
      "epoch": 38.52,
      "learning_rate": 0.09614919999228297,
      "loss": 3.5663,
      "step": 23960
    },
    {
      "epoch": 38.55,
      "learning_rate": 0.0961459845614148,
      "loss": 3.5372,
      "step": 23980
    },
    {
      "epoch": 38.59,
      "learning_rate": 0.09614276913054662,
      "loss": 3.6354,
      "step": 24000
    },
    {
      "epoch": 38.62,
      "learning_rate": 0.09613955369967847,
      "loss": 3.5065,
      "step": 24020
    },
    {
      "epoch": 38.65,
      "learning_rate": 0.0961363382688103,
      "loss": 3.5297,
      "step": 24040
    },
    {
      "epoch": 38.68,
      "learning_rate": 0.09613312283794213,
      "loss": 3.5761,
      "step": 24060
    },
    {
      "epoch": 38.71,
      "learning_rate": 0.09612990740707396,
      "loss": 3.5686,
      "step": 24080
    },
    {
      "epoch": 38.75,
      "learning_rate": 0.09612669197620578,
      "loss": 3.6013,
      "step": 24100
    },
    {
      "epoch": 38.78,
      "learning_rate": 0.09612347654533764,
      "loss": 3.5583,
      "step": 24120
    },
    {
      "epoch": 38.81,
      "learning_rate": 0.09612026111446946,
      "loss": 3.5551,
      "step": 24140
    },
    {
      "epoch": 38.84,
      "learning_rate": 0.0961170456836013,
      "loss": 3.5783,
      "step": 24160
    },
    {
      "epoch": 38.87,
      "learning_rate": 0.09611383025273312,
      "loss": 3.5707,
      "step": 24180
    },
    {
      "epoch": 38.91,
      "learning_rate": 0.09611061482186495,
      "loss": 3.5869,
      "step": 24200
    },
    {
      "epoch": 38.94,
      "learning_rate": 0.09610739939099679,
      "loss": 3.5921,
      "step": 24220
    },
    {
      "epoch": 38.97,
      "learning_rate": 0.09610418396012863,
      "loss": 3.6112,
      "step": 24240
    },
    {
      "epoch": 39.0,
      "eval_accuracy": {
        "accuracy": 0.3237191945891316
      },
      "eval_loss": 3.5115442276000977,
      "eval_runtime": 2.8858,
      "eval_samples_per_second": 4457.33,
      "eval_steps_per_second": 69.651,
      "step": 24258
    },
    {
      "epoch": 39.0,
      "learning_rate": 0.09610096852926046,
      "loss": 3.58,
      "step": 24260
    },
    {
      "epoch": 39.04,
      "learning_rate": 0.09609775309839229,
      "loss": 3.4761,
      "step": 24280
    },
    {
      "epoch": 39.07,
      "learning_rate": 0.09609453766752411,
      "loss": 3.5662,
      "step": 24300
    },
    {
      "epoch": 39.1,
      "learning_rate": 0.09609132223665595,
      "loss": 3.5694,
      "step": 24320
    },
    {
      "epoch": 39.13,
      "learning_rate": 0.09608810680578778,
      "loss": 3.5504,
      "step": 24340
    },
    {
      "epoch": 39.16,
      "learning_rate": 0.09608489137491963,
      "loss": 3.5369,
      "step": 24360
    },
    {
      "epoch": 39.2,
      "learning_rate": 0.09608167594405145,
      "loss": 3.498,
      "step": 24380
    },
    {
      "epoch": 39.23,
      "learning_rate": 0.09607846051318329,
      "loss": 3.5193,
      "step": 24400
    },
    {
      "epoch": 39.26,
      "learning_rate": 0.09607524508231512,
      "loss": 3.5192,
      "step": 24420
    },
    {
      "epoch": 39.29,
      "learning_rate": 0.09607202965144694,
      "loss": 3.501,
      "step": 24440
    },
    {
      "epoch": 39.32,
      "learning_rate": 0.0960688142205788,
      "loss": 3.5198,
      "step": 24460
    },
    {
      "epoch": 39.36,
      "learning_rate": 0.09606559878971062,
      "loss": 3.5732,
      "step": 24480
    },
    {
      "epoch": 39.39,
      "learning_rate": 0.09606238335884246,
      "loss": 3.5996,
      "step": 24500
    },
    {
      "epoch": 39.42,
      "learning_rate": 0.09605916792797428,
      "loss": 3.5876,
      "step": 24520
    },
    {
      "epoch": 39.45,
      "learning_rate": 0.0960559524971061,
      "loss": 3.5494,
      "step": 24540
    },
    {
      "epoch": 39.49,
      "learning_rate": 0.09605273706623794,
      "loss": 3.522,
      "step": 24560
    },
    {
      "epoch": 39.52,
      "learning_rate": 0.09604952163536978,
      "loss": 3.5946,
      "step": 24580
    },
    {
      "epoch": 39.55,
      "learning_rate": 0.09604630620450162,
      "loss": 3.6098,
      "step": 24600
    },
    {
      "epoch": 39.58,
      "learning_rate": 0.09604309077363345,
      "loss": 3.6218,
      "step": 24620
    },
    {
      "epoch": 39.61,
      "learning_rate": 0.09603987534276527,
      "loss": 3.5882,
      "step": 24640
    },
    {
      "epoch": 39.65,
      "learning_rate": 0.09603665991189711,
      "loss": 3.604,
      "step": 24660
    },
    {
      "epoch": 39.68,
      "learning_rate": 0.09603344448102893,
      "loss": 3.5494,
      "step": 24680
    },
    {
      "epoch": 39.71,
      "learning_rate": 0.09603022905016079,
      "loss": 3.5533,
      "step": 24700
    },
    {
      "epoch": 39.74,
      "learning_rate": 0.09602701361929261,
      "loss": 3.4857,
      "step": 24720
    },
    {
      "epoch": 39.77,
      "learning_rate": 0.09602379818842444,
      "loss": 3.5161,
      "step": 24740
    },
    {
      "epoch": 39.81,
      "learning_rate": 0.09602058275755627,
      "loss": 3.5437,
      "step": 24760
    },
    {
      "epoch": 39.84,
      "learning_rate": 0.0960173673266881,
      "loss": 3.5115,
      "step": 24780
    },
    {
      "epoch": 39.87,
      "learning_rate": 0.09601415189581995,
      "loss": 3.5287,
      "step": 24800
    },
    {
      "epoch": 39.9,
      "learning_rate": 0.09601093646495178,
      "loss": 3.5548,
      "step": 24820
    },
    {
      "epoch": 39.94,
      "learning_rate": 0.0960077210340836,
      "loss": 3.6192,
      "step": 24840
    },
    {
      "epoch": 39.97,
      "learning_rate": 0.09600450560321544,
      "loss": 3.6617,
      "step": 24860
    },
    {
      "epoch": 40.0,
      "learning_rate": 0.09600129017234726,
      "loss": 3.6564,
      "step": 24880
    },
    {
      "epoch": 40.0,
      "eval_accuracy": {
        "accuracy": 0.3080929798647283
      },
      "eval_loss": 3.6815037727355957,
      "eval_runtime": 2.8261,
      "eval_samples_per_second": 4551.536,
      "eval_steps_per_second": 71.123,
      "step": 24880
    },
    {
      "epoch": 40.03,
      "learning_rate": 0.0959980747414791,
      "loss": 3.6291,
      "step": 24900
    },
    {
      "epoch": 40.06,
      "learning_rate": 0.09599485931061094,
      "loss": 3.6,
      "step": 24920
    },
    {
      "epoch": 40.1,
      "learning_rate": 0.09599164387974277,
      "loss": 3.5852,
      "step": 24940
    },
    {
      "epoch": 40.13,
      "learning_rate": 0.0959884284488746,
      "loss": 3.6366,
      "step": 24960
    },
    {
      "epoch": 40.16,
      "learning_rate": 0.09598521301800643,
      "loss": 3.529,
      "step": 24980
    },
    {
      "epoch": 40.19,
      "learning_rate": 0.09598199758713827,
      "loss": 3.5133,
      "step": 25000
    },
    {
      "epoch": 40.23,
      "learning_rate": 0.09597878215627009,
      "loss": 3.4946,
      "step": 25020
    },
    {
      "epoch": 40.26,
      "learning_rate": 0.09597556672540195,
      "loss": 3.51,
      "step": 25040
    },
    {
      "epoch": 40.29,
      "learning_rate": 0.09597235129453377,
      "loss": 3.5225,
      "step": 25060
    },
    {
      "epoch": 40.32,
      "learning_rate": 0.0959691358636656,
      "loss": 3.5928,
      "step": 25080
    },
    {
      "epoch": 40.35,
      "learning_rate": 0.09596592043279743,
      "loss": 3.6,
      "step": 25100
    },
    {
      "epoch": 40.39,
      "learning_rate": 0.09596270500192926,
      "loss": 3.5678,
      "step": 25120
    },
    {
      "epoch": 40.42,
      "learning_rate": 0.09595948957106111,
      "loss": 3.5253,
      "step": 25140
    },
    {
      "epoch": 40.45,
      "learning_rate": 0.09595627414019293,
      "loss": 3.4742,
      "step": 25160
    },
    {
      "epoch": 40.48,
      "learning_rate": 0.09595305870932476,
      "loss": 3.5116,
      "step": 25180
    },
    {
      "epoch": 40.51,
      "learning_rate": 0.0959498432784566,
      "loss": 3.5196,
      "step": 25200
    },
    {
      "epoch": 40.55,
      "learning_rate": 0.09594662784758842,
      "loss": 3.518,
      "step": 25220
    },
    {
      "epoch": 40.58,
      "learning_rate": 0.09594341241672026,
      "loss": 3.5591,
      "step": 25240
    },
    {
      "epoch": 40.61,
      "learning_rate": 0.0959401969858521,
      "loss": 3.495,
      "step": 25260
    },
    {
      "epoch": 40.64,
      "learning_rate": 0.09593698155498392,
      "loss": 3.4923,
      "step": 25280
    },
    {
      "epoch": 40.68,
      "learning_rate": 0.09593376612411576,
      "loss": 3.5013,
      "step": 25300
    },
    {
      "epoch": 40.71,
      "learning_rate": 0.09593055069324759,
      "loss": 3.5554,
      "step": 25320
    },
    {
      "epoch": 40.74,
      "learning_rate": 0.09592733526237943,
      "loss": 3.6076,
      "step": 25340
    },
    {
      "epoch": 40.77,
      "learning_rate": 0.09592411983151125,
      "loss": 3.5569,
      "step": 25360
    },
    {
      "epoch": 40.8,
      "learning_rate": 0.09592090440064309,
      "loss": 3.5462,
      "step": 25380
    },
    {
      "epoch": 40.84,
      "learning_rate": 0.09591768896977493,
      "loss": 3.5157,
      "step": 25400
    },
    {
      "epoch": 40.87,
      "learning_rate": 0.09591447353890675,
      "loss": 3.5849,
      "step": 25420
    },
    {
      "epoch": 40.9,
      "learning_rate": 0.09591125810803859,
      "loss": 3.5264,
      "step": 25440
    },
    {
      "epoch": 40.93,
      "learning_rate": 0.09590804267717042,
      "loss": 3.5634,
      "step": 25460
    },
    {
      "epoch": 40.96,
      "learning_rate": 0.09590482724630225,
      "loss": 3.5127,
      "step": 25480
    },
    {
      "epoch": 41.0,
      "learning_rate": 0.09590161181543409,
      "loss": 3.5973,
      "step": 25500
    },
    {
      "epoch": 41.0,
      "eval_accuracy": {
        "accuracy": 0.30156262147244034
      },
      "eval_loss": 3.714233875274658,
      "eval_runtime": 3.4584,
      "eval_samples_per_second": 3719.379,
      "eval_steps_per_second": 58.12,
      "step": 25502
    },
    {
      "epoch": 41.03,
      "learning_rate": 0.09589839638456592,
      "loss": 3.6245,
      "step": 25520
    },
    {
      "epoch": 41.06,
      "learning_rate": 0.09589518095369776,
      "loss": 3.5216,
      "step": 25540
    },
    {
      "epoch": 41.09,
      "learning_rate": 0.09589196552282958,
      "loss": 3.555,
      "step": 25560
    },
    {
      "epoch": 41.13,
      "learning_rate": 0.09588875009196142,
      "loss": 3.5274,
      "step": 25580
    },
    {
      "epoch": 41.16,
      "learning_rate": 0.09588553466109326,
      "loss": 3.5194,
      "step": 25600
    },
    {
      "epoch": 41.19,
      "learning_rate": 0.09588231923022508,
      "loss": 3.4988,
      "step": 25620
    },
    {
      "epoch": 41.22,
      "learning_rate": 0.09587910379935692,
      "loss": 3.5152,
      "step": 25640
    },
    {
      "epoch": 41.25,
      "learning_rate": 0.09587604914003216,
      "loss": 3.4497,
      "step": 25660
    },
    {
      "epoch": 41.29,
      "learning_rate": 0.095872833709164,
      "loss": 3.5079,
      "step": 25680
    },
    {
      "epoch": 41.32,
      "learning_rate": 0.09586961827829582,
      "loss": 3.5111,
      "step": 25700
    },
    {
      "epoch": 41.35,
      "learning_rate": 0.09586640284742766,
      "loss": 3.5395,
      "step": 25720
    },
    {
      "epoch": 41.38,
      "learning_rate": 0.0958631874165595,
      "loss": 3.5311,
      "step": 25740
    },
    {
      "epoch": 41.41,
      "learning_rate": 0.09585997198569132,
      "loss": 3.5614,
      "step": 25760
    },
    {
      "epoch": 41.45,
      "learning_rate": 0.09585675655482316,
      "loss": 3.623,
      "step": 25780
    },
    {
      "epoch": 41.48,
      "learning_rate": 0.09585354112395499,
      "loss": 3.6346,
      "step": 25800
    },
    {
      "epoch": 41.51,
      "learning_rate": 0.09585032569308682,
      "loss": 3.5206,
      "step": 25820
    },
    {
      "epoch": 41.54,
      "learning_rate": 0.09584711026221866,
      "loss": 3.5128,
      "step": 25840
    },
    {
      "epoch": 41.58,
      "learning_rate": 0.09584389483135049,
      "loss": 3.5511,
      "step": 25860
    },
    {
      "epoch": 41.61,
      "learning_rate": 0.09584067940048233,
      "loss": 3.5292,
      "step": 25880
    },
    {
      "epoch": 41.64,
      "learning_rate": 0.09583746396961415,
      "loss": 3.5851,
      "step": 25900
    },
    {
      "epoch": 41.67,
      "learning_rate": 0.09583424853874599,
      "loss": 3.6488,
      "step": 25920
    },
    {
      "epoch": 41.7,
      "learning_rate": 0.09583103310787781,
      "loss": 3.5667,
      "step": 25940
    },
    {
      "epoch": 41.74,
      "learning_rate": 0.09582781767700965,
      "loss": 3.4935,
      "step": 25960
    },
    {
      "epoch": 41.77,
      "learning_rate": 0.09582460224614149,
      "loss": 3.5695,
      "step": 25980
    },
    {
      "epoch": 41.8,
      "learning_rate": 0.09582138681527332,
      "loss": 3.5745,
      "step": 26000
    },
    {
      "epoch": 41.83,
      "learning_rate": 0.09581817138440515,
      "loss": 3.5907,
      "step": 26020
    },
    {
      "epoch": 41.86,
      "learning_rate": 0.09581495595353698,
      "loss": 3.548,
      "step": 26040
    },
    {
      "epoch": 41.9,
      "learning_rate": 0.09581174052266882,
      "loss": 3.5276,
      "step": 26060
    },
    {
      "epoch": 41.93,
      "learning_rate": 0.09580852509180066,
      "loss": 3.5407,
      "step": 26080
    },
    {
      "epoch": 41.96,
      "learning_rate": 0.09580530966093248,
      "loss": 3.576,
      "step": 26100
    },
    {
      "epoch": 41.99,
      "learning_rate": 0.09580209423006432,
      "loss": 3.5676,
      "step": 26120
    },
    {
      "epoch": 42.0,
      "eval_accuracy": {
        "accuracy": 0.3106584778045557
      },
      "eval_loss": 3.7295665740966797,
      "eval_runtime": 2.7581,
      "eval_samples_per_second": 4663.776,
      "eval_steps_per_second": 72.877,
      "step": 26124
    },
    {
      "epoch": 42.03,
      "learning_rate": 0.09579887879919614,
      "loss": 3.585,
      "step": 26140
    },
    {
      "epoch": 42.06,
      "learning_rate": 0.09579566336832798,
      "loss": 3.5135,
      "step": 26160
    },
    {
      "epoch": 42.09,
      "learning_rate": 0.09579244793745982,
      "loss": 3.471,
      "step": 26180
    },
    {
      "epoch": 42.12,
      "learning_rate": 0.09578923250659165,
      "loss": 3.5142,
      "step": 26200
    },
    {
      "epoch": 42.15,
      "learning_rate": 0.09578601707572348,
      "loss": 3.4839,
      "step": 26220
    },
    {
      "epoch": 42.19,
      "learning_rate": 0.09578280164485531,
      "loss": 3.5351,
      "step": 26240
    },
    {
      "epoch": 42.22,
      "learning_rate": 0.09577958621398715,
      "loss": 3.4939,
      "step": 26260
    },
    {
      "epoch": 42.25,
      "learning_rate": 0.09577637078311897,
      "loss": 3.4919,
      "step": 26280
    },
    {
      "epoch": 42.28,
      "learning_rate": 0.09577315535225081,
      "loss": 3.5086,
      "step": 26300
    },
    {
      "epoch": 42.32,
      "learning_rate": 0.09576993992138265,
      "loss": 3.4395,
      "step": 26320
    },
    {
      "epoch": 42.35,
      "learning_rate": 0.09576672449051447,
      "loss": 3.508,
      "step": 26340
    },
    {
      "epoch": 42.38,
      "learning_rate": 0.09576350905964631,
      "loss": 3.4766,
      "step": 26360
    },
    {
      "epoch": 42.41,
      "learning_rate": 0.09576029362877814,
      "loss": 3.4639,
      "step": 26380
    },
    {
      "epoch": 42.44,
      "learning_rate": 0.09575707819790996,
      "loss": 3.519,
      "step": 26400
    },
    {
      "epoch": 42.48,
      "learning_rate": 0.09575386276704181,
      "loss": 3.4974,
      "step": 26420
    },
    {
      "epoch": 42.51,
      "learning_rate": 0.09575064733617364,
      "loss": 3.5558,
      "step": 26440
    },
    {
      "epoch": 42.54,
      "learning_rate": 0.09574743190530548,
      "loss": 3.5374,
      "step": 26460
    },
    {
      "epoch": 42.57,
      "learning_rate": 0.0957442164744373,
      "loss": 3.5149,
      "step": 26480
    },
    {
      "epoch": 42.6,
      "learning_rate": 0.09574100104356913,
      "loss": 3.4644,
      "step": 26500
    },
    {
      "epoch": 42.64,
      "learning_rate": 0.09573778561270098,
      "loss": 3.4828,
      "step": 26520
    },
    {
      "epoch": 42.67,
      "learning_rate": 0.0957345701818328,
      "loss": 3.5155,
      "step": 26540
    },
    {
      "epoch": 42.7,
      "learning_rate": 0.09573135475096464,
      "loss": 3.5258,
      "step": 26560
    },
    {
      "epoch": 42.73,
      "learning_rate": 0.09572813932009647,
      "loss": 3.5112,
      "step": 26580
    },
    {
      "epoch": 42.77,
      "learning_rate": 0.0957249238892283,
      "loss": 3.4796,
      "step": 26600
    },
    {
      "epoch": 42.8,
      "learning_rate": 0.09572170845836013,
      "loss": 3.4727,
      "step": 26620
    },
    {
      "epoch": 42.83,
      "learning_rate": 0.09571849302749197,
      "loss": 3.4887,
      "step": 26640
    },
    {
      "epoch": 42.86,
      "learning_rate": 0.09571527759662381,
      "loss": 3.4572,
      "step": 26660
    },
    {
      "epoch": 42.89,
      "learning_rate": 0.09571206216575563,
      "loss": 3.5377,
      "step": 26680
    },
    {
      "epoch": 42.93,
      "learning_rate": 0.09570884673488747,
      "loss": 3.5359,
      "step": 26700
    },
    {
      "epoch": 42.96,
      "learning_rate": 0.0957056313040193,
      "loss": 3.4968,
      "step": 26720
    },
    {
      "epoch": 42.99,
      "learning_rate": 0.09570241587315112,
      "loss": 3.4951,
      "step": 26740
    },
    {
      "epoch": 43.0,
      "eval_accuracy": {
        "accuracy": 0.31143590142268524
      },
      "eval_loss": 3.5618810653686523,
      "eval_runtime": 2.8818,
      "eval_samples_per_second": 4463.549,
      "eval_steps_per_second": 69.748,
      "step": 26746
    },
    {
      "epoch": 43.02,
      "learning_rate": 0.09569920044228297,
      "loss": 3.4948,
      "step": 26760
    },
    {
      "epoch": 43.05,
      "learning_rate": 0.0956959850114148,
      "loss": 3.4555,
      "step": 26780
    },
    {
      "epoch": 43.09,
      "learning_rate": 0.09569276958054664,
      "loss": 3.5051,
      "step": 26800
    },
    {
      "epoch": 43.12,
      "learning_rate": 0.09568955414967846,
      "loss": 3.4916,
      "step": 26820
    },
    {
      "epoch": 43.15,
      "learning_rate": 0.09568633871881028,
      "loss": 3.5837,
      "step": 26840
    },
    {
      "epoch": 43.18,
      "learning_rate": 0.09568312328794214,
      "loss": 3.5097,
      "step": 26860
    },
    {
      "epoch": 43.22,
      "learning_rate": 0.09567990785707396,
      "loss": 3.52,
      "step": 26880
    },
    {
      "epoch": 43.25,
      "learning_rate": 0.0956766924262058,
      "loss": 3.5345,
      "step": 26900
    },
    {
      "epoch": 43.28,
      "learning_rate": 0.09567347699533763,
      "loss": 3.5781,
      "step": 26920
    },
    {
      "epoch": 43.31,
      "learning_rate": 0.09567026156446945,
      "loss": 3.5851,
      "step": 26940
    },
    {
      "epoch": 43.34,
      "learning_rate": 0.09566704613360129,
      "loss": 3.6361,
      "step": 26960
    },
    {
      "epoch": 43.38,
      "learning_rate": 0.09566383070273313,
      "loss": 3.5252,
      "step": 26980
    },
    {
      "epoch": 43.41,
      "learning_rate": 0.09566061527186497,
      "loss": 3.5256,
      "step": 27000
    },
    {
      "epoch": 43.44,
      "learning_rate": 0.09565739984099679,
      "loss": 3.4913,
      "step": 27020
    },
    {
      "epoch": 43.47,
      "learning_rate": 0.09565418441012861,
      "loss": 3.5068,
      "step": 27040
    },
    {
      "epoch": 43.5,
      "learning_rate": 0.09565096897926045,
      "loss": 3.5106,
      "step": 27060
    },
    {
      "epoch": 43.54,
      "learning_rate": 0.09564775354839228,
      "loss": 3.4775,
      "step": 27080
    },
    {
      "epoch": 43.57,
      "learning_rate": 0.09564453811752413,
      "loss": 3.4987,
      "step": 27100
    },
    {
      "epoch": 43.6,
      "learning_rate": 0.09564132268665596,
      "loss": 3.4699,
      "step": 27120
    },
    {
      "epoch": 43.63,
      "learning_rate": 0.09563810725578778,
      "loss": 3.4815,
      "step": 27140
    },
    {
      "epoch": 43.67,
      "learning_rate": 0.09563489182491962,
      "loss": 3.4678,
      "step": 27160
    },
    {
      "epoch": 43.7,
      "learning_rate": 0.09563167639405144,
      "loss": 3.4606,
      "step": 27180
    },
    {
      "epoch": 43.73,
      "learning_rate": 0.0956284609631833,
      "loss": 3.541,
      "step": 27200
    },
    {
      "epoch": 43.76,
      "learning_rate": 0.09562524553231512,
      "loss": 3.5488,
      "step": 27220
    },
    {
      "epoch": 43.79,
      "learning_rate": 0.09562203010144696,
      "loss": 3.4985,
      "step": 27240
    },
    {
      "epoch": 43.83,
      "learning_rate": 0.09561881467057878,
      "loss": 3.5912,
      "step": 27260
    },
    {
      "epoch": 43.86,
      "learning_rate": 0.09561559923971061,
      "loss": 3.5549,
      "step": 27280
    },
    {
      "epoch": 43.89,
      "learning_rate": 0.09561238380884245,
      "loss": 3.6183,
      "step": 27300
    },
    {
      "epoch": 43.92,
      "learning_rate": 0.09560916837797429,
      "loss": 3.7277,
      "step": 27320
    },
    {
      "epoch": 43.95,
      "learning_rate": 0.09560595294710612,
      "loss": 3.6237,
      "step": 27340
    },
    {
      "epoch": 43.99,
      "learning_rate": 0.09560273751623795,
      "loss": 3.5776,
      "step": 27360
    },
    {
      "epoch": 44.0,
      "eval_accuracy": {
        "accuracy": 0.3147010806188292
      },
      "eval_loss": 3.711862325668335,
      "eval_runtime": 2.589,
      "eval_samples_per_second": 4968.373,
      "eval_steps_per_second": 77.637,
      "step": 27368
    },
    {
      "epoch": 44.02,
      "learning_rate": 0.09559952208536977,
      "loss": 3.586,
      "step": 27380
    },
    {
      "epoch": 44.05,
      "learning_rate": 0.09559630665450161,
      "loss": 3.5607,
      "step": 27400
    },
    {
      "epoch": 44.08,
      "learning_rate": 0.09559309122363344,
      "loss": 3.5083,
      "step": 27420
    },
    {
      "epoch": 44.12,
      "learning_rate": 0.09558987579276529,
      "loss": 3.4287,
      "step": 27440
    },
    {
      "epoch": 44.15,
      "learning_rate": 0.09558666036189711,
      "loss": 3.518,
      "step": 27460
    },
    {
      "epoch": 44.18,
      "learning_rate": 0.09558344493102894,
      "loss": 3.51,
      "step": 27480
    },
    {
      "epoch": 44.21,
      "learning_rate": 0.09558022950016078,
      "loss": 3.4841,
      "step": 27500
    },
    {
      "epoch": 44.24,
      "learning_rate": 0.0955770140692926,
      "loss": 3.4827,
      "step": 27520
    },
    {
      "epoch": 44.28,
      "learning_rate": 0.09557379863842445,
      "loss": 3.5338,
      "step": 27540
    },
    {
      "epoch": 44.31,
      "learning_rate": 0.09557058320755628,
      "loss": 3.5456,
      "step": 27560
    },
    {
      "epoch": 44.34,
      "learning_rate": 0.0955673677766881,
      "loss": 3.5194,
      "step": 27580
    },
    {
      "epoch": 44.37,
      "learning_rate": 0.09556415234581994,
      "loss": 3.4745,
      "step": 27600
    },
    {
      "epoch": 44.41,
      "learning_rate": 0.09556093691495177,
      "loss": 3.4343,
      "step": 27620
    },
    {
      "epoch": 44.44,
      "learning_rate": 0.0955577214840836,
      "loss": 3.4555,
      "step": 27640
    },
    {
      "epoch": 44.47,
      "learning_rate": 0.09555450605321544,
      "loss": 3.488,
      "step": 27660
    },
    {
      "epoch": 44.5,
      "learning_rate": 0.09555129062234727,
      "loss": 3.5004,
      "step": 27680
    },
    {
      "epoch": 44.53,
      "learning_rate": 0.0955480751914791,
      "loss": 3.5081,
      "step": 27700
    },
    {
      "epoch": 44.57,
      "learning_rate": 0.09554485976061093,
      "loss": 3.4735,
      "step": 27720
    },
    {
      "epoch": 44.6,
      "learning_rate": 0.09554164432974277,
      "loss": 3.4632,
      "step": 27740
    },
    {
      "epoch": 44.63,
      "learning_rate": 0.0955384288988746,
      "loss": 3.4502,
      "step": 27760
    },
    {
      "epoch": 44.66,
      "learning_rate": 0.09553521346800645,
      "loss": 3.4759,
      "step": 27780
    },
    {
      "epoch": 44.69,
      "learning_rate": 0.09553199803713827,
      "loss": 3.5066,
      "step": 27800
    },
    {
      "epoch": 44.73,
      "learning_rate": 0.09552894337781351,
      "loss": 3.5738,
      "step": 27820
    },
    {
      "epoch": 44.76,
      "learning_rate": 0.09552588871848876,
      "loss": 3.5692,
      "step": 27840
    },
    {
      "epoch": 44.79,
      "learning_rate": 0.09552267328762058,
      "loss": 3.5895,
      "step": 27860
    },
    {
      "epoch": 44.82,
      "learning_rate": 0.09551945785675242,
      "loss": 3.5102,
      "step": 27880
    },
    {
      "epoch": 44.86,
      "learning_rate": 0.09551624242588425,
      "loss": 3.5256,
      "step": 27900
    },
    {
      "epoch": 44.89,
      "learning_rate": 0.09551302699501608,
      "loss": 3.4836,
      "step": 27920
    },
    {
      "epoch": 44.92,
      "learning_rate": 0.09550981156414792,
      "loss": 3.4813,
      "step": 27940
    },
    {
      "epoch": 44.95,
      "learning_rate": 0.09550659613327975,
      "loss": 3.5044,
      "step": 27960
    },
    {
      "epoch": 44.98,
      "learning_rate": 0.09550338070241159,
      "loss": 3.5554,
      "step": 27980
    },
    {
      "epoch": 45.0,
      "eval_accuracy": {
        "accuracy": 0.3216978931819949
      },
      "eval_loss": 3.611436128616333,
      "eval_runtime": 2.719,
      "eval_samples_per_second": 4730.767,
      "eval_steps_per_second": 73.924,
      "step": 27990
    },
    {
      "epoch": 45.02,
      "learning_rate": 0.09550016527154341,
      "loss": 3.615,
      "step": 28000
    },
    {
      "epoch": 45.05,
      "learning_rate": 0.09549694984067525,
      "loss": 3.6157,
      "step": 28020
    },
    {
      "epoch": 45.08,
      "learning_rate": 0.09549373440980707,
      "loss": 3.5053,
      "step": 28040
    },
    {
      "epoch": 45.11,
      "learning_rate": 0.09549051897893891,
      "loss": 3.4563,
      "step": 28060
    },
    {
      "epoch": 45.14,
      "learning_rate": 0.09548730354807075,
      "loss": 3.5048,
      "step": 28080
    },
    {
      "epoch": 45.18,
      "learning_rate": 0.09548408811720258,
      "loss": 3.4513,
      "step": 28100
    },
    {
      "epoch": 45.21,
      "learning_rate": 0.09548087268633441,
      "loss": 3.4716,
      "step": 28120
    },
    {
      "epoch": 45.24,
      "learning_rate": 0.09547765725546624,
      "loss": 3.4681,
      "step": 28140
    },
    {
      "epoch": 45.27,
      "learning_rate": 0.09547444182459808,
      "loss": 3.4945,
      "step": 28160
    },
    {
      "epoch": 45.31,
      "learning_rate": 0.09547122639372992,
      "loss": 3.506,
      "step": 28180
    },
    {
      "epoch": 45.34,
      "learning_rate": 0.09546801096286174,
      "loss": 3.4715,
      "step": 28200
    },
    {
      "epoch": 45.37,
      "learning_rate": 0.09546479553199358,
      "loss": 3.4779,
      "step": 28220
    },
    {
      "epoch": 45.4,
      "learning_rate": 0.0954615801011254,
      "loss": 3.4918,
      "step": 28240
    },
    {
      "epoch": 45.43,
      "learning_rate": 0.09545836467025724,
      "loss": 3.4651,
      "step": 28260
    },
    {
      "epoch": 45.47,
      "learning_rate": 0.09545514923938908,
      "loss": 3.4652,
      "step": 28280
    },
    {
      "epoch": 45.5,
      "learning_rate": 0.0954519338085209,
      "loss": 3.5215,
      "step": 28300
    },
    {
      "epoch": 45.53,
      "learning_rate": 0.09544871837765274,
      "loss": 3.5511,
      "step": 28320
    },
    {
      "epoch": 45.56,
      "learning_rate": 0.09544550294678457,
      "loss": 3.5443,
      "step": 28340
    },
    {
      "epoch": 45.59,
      "learning_rate": 0.09544228751591641,
      "loss": 3.5099,
      "step": 28360
    },
    {
      "epoch": 45.63,
      "learning_rate": 0.09543907208504823,
      "loss": 3.5567,
      "step": 28380
    },
    {
      "epoch": 45.66,
      "learning_rate": 0.09543585665418007,
      "loss": 3.4741,
      "step": 28400
    },
    {
      "epoch": 45.69,
      "learning_rate": 0.09543264122331191,
      "loss": 3.5201,
      "step": 28420
    },
    {
      "epoch": 45.72,
      "learning_rate": 0.09542942579244373,
      "loss": 3.5331,
      "step": 28440
    },
    {
      "epoch": 45.76,
      "learning_rate": 0.09542621036157557,
      "loss": 3.5228,
      "step": 28460
    },
    {
      "epoch": 45.79,
      "learning_rate": 0.0954229949307074,
      "loss": 3.5167,
      "step": 28480
    },
    {
      "epoch": 45.82,
      "learning_rate": 0.09541977949983924,
      "loss": 3.4806,
      "step": 28500
    },
    {
      "epoch": 45.85,
      "learning_rate": 0.09541656406897107,
      "loss": 3.5262,
      "step": 28520
    },
    {
      "epoch": 45.88,
      "learning_rate": 0.0954133486381029,
      "loss": 3.5085,
      "step": 28540
    },
    {
      "epoch": 45.92,
      "learning_rate": 0.09541013320723474,
      "loss": 3.5898,
      "step": 28560
    },
    {
      "epoch": 45.95,
      "learning_rate": 0.09540691777636656,
      "loss": 3.5481,
      "step": 28580
    },
    {
      "epoch": 45.98,
      "learning_rate": 0.09540370234549839,
      "loss": 3.4846,
      "step": 28600
    },
    {
      "epoch": 46.0,
      "eval_accuracy": {
        "accuracy": 0.31524527715151984
      },
      "eval_loss": 3.5718469619750977,
      "eval_runtime": 2.7958,
      "eval_samples_per_second": 4600.854,
      "eval_steps_per_second": 71.894,
      "step": 28612
    },
    {
      "epoch": 46.01,
      "learning_rate": 0.09540048691463024,
      "loss": 3.4741,
      "step": 28620
    },
    {
      "epoch": 46.05,
      "learning_rate": 0.09539727148376206,
      "loss": 3.4634,
      "step": 28640
    },
    {
      "epoch": 46.08,
      "learning_rate": 0.0953940560528939,
      "loss": 3.5107,
      "step": 28660
    },
    {
      "epoch": 46.11,
      "learning_rate": 0.09539084062202573,
      "loss": 3.4869,
      "step": 28680
    },
    {
      "epoch": 46.14,
      "learning_rate": 0.09538762519115755,
      "loss": 3.5407,
      "step": 28700
    },
    {
      "epoch": 46.17,
      "learning_rate": 0.09538440976028939,
      "loss": 3.5474,
      "step": 28720
    },
    {
      "epoch": 46.21,
      "learning_rate": 0.09538119432942123,
      "loss": 3.5572,
      "step": 28740
    },
    {
      "epoch": 46.24,
      "learning_rate": 0.09537797889855307,
      "loss": 3.5242,
      "step": 28760
    },
    {
      "epoch": 46.27,
      "learning_rate": 0.09537476346768489,
      "loss": 3.4715,
      "step": 28780
    },
    {
      "epoch": 46.3,
      "learning_rate": 0.09537154803681672,
      "loss": 3.5145,
      "step": 28800
    },
    {
      "epoch": 46.33,
      "learning_rate": 0.09536833260594856,
      "loss": 3.4466,
      "step": 28820
    },
    {
      "epoch": 46.37,
      "learning_rate": 0.0953651171750804,
      "loss": 3.4428,
      "step": 28840
    },
    {
      "epoch": 46.4,
      "learning_rate": 0.09536190174421223,
      "loss": 3.4652,
      "step": 28860
    },
    {
      "epoch": 46.43,
      "learning_rate": 0.09535868631334406,
      "loss": 3.4945,
      "step": 28880
    },
    {
      "epoch": 46.46,
      "learning_rate": 0.0953554708824759,
      "loss": 3.4551,
      "step": 28900
    },
    {
      "epoch": 46.5,
      "learning_rate": 0.09535225545160772,
      "loss": 3.5001,
      "step": 28920
    },
    {
      "epoch": 46.53,
      "learning_rate": 0.09534904002073954,
      "loss": 3.4605,
      "step": 28940
    },
    {
      "epoch": 46.56,
      "learning_rate": 0.0953458245898714,
      "loss": 3.4593,
      "step": 28960
    },
    {
      "epoch": 46.59,
      "learning_rate": 0.09534260915900322,
      "loss": 3.4795,
      "step": 28980
    },
    {
      "epoch": 46.62,
      "learning_rate": 0.09533939372813506,
      "loss": 3.4567,
      "step": 29000
    },
    {
      "epoch": 46.66,
      "learning_rate": 0.09533617829726689,
      "loss": 3.4291,
      "step": 29020
    },
    {
      "epoch": 46.69,
      "learning_rate": 0.09533296286639871,
      "loss": 3.4512,
      "step": 29040
    },
    {
      "epoch": 46.72,
      "learning_rate": 0.09532974743553055,
      "loss": 3.5476,
      "step": 29060
    },
    {
      "epoch": 46.75,
      "learning_rate": 0.09532653200466239,
      "loss": 3.473,
      "step": 29080
    },
    {
      "epoch": 46.78,
      "learning_rate": 0.09532331657379423,
      "loss": 3.5571,
      "step": 29100
    },
    {
      "epoch": 46.82,
      "learning_rate": 0.09532010114292605,
      "loss": 3.5,
      "step": 29120
    },
    {
      "epoch": 46.85,
      "learning_rate": 0.09531688571205787,
      "loss": 3.4584,
      "step": 29140
    },
    {
      "epoch": 46.88,
      "learning_rate": 0.09531367028118971,
      "loss": 3.4646,
      "step": 29160
    },
    {
      "epoch": 46.91,
      "learning_rate": 0.09531045485032155,
      "loss": 3.4589,
      "step": 29180
    },
    {
      "epoch": 46.95,
      "learning_rate": 0.09530723941945339,
      "loss": 3.5196,
      "step": 29200
    },
    {
      "epoch": 46.98,
      "learning_rate": 0.09530402398858522,
      "loss": 3.4764,
      "step": 29220
    },
    {
      "epoch": 47.0,
      "eval_accuracy": {
        "accuracy": 0.32247531680012437
      },
      "eval_loss": 3.505511999130249,
      "eval_runtime": 2.6636,
      "eval_samples_per_second": 4829.097,
      "eval_steps_per_second": 75.461,
      "step": 29234
    },
    {
      "epoch": 47.01,
      "learning_rate": 0.09530080855771704,
      "loss": 3.4607,
      "step": 29240
    },
    {
      "epoch": 47.04,
      "learning_rate": 0.09529759312684888,
      "loss": 3.542,
      "step": 29260
    },
    {
      "epoch": 47.07,
      "learning_rate": 0.0952943776959807,
      "loss": 3.4625,
      "step": 29280
    },
    {
      "epoch": 47.11,
      "learning_rate": 0.09529116226511256,
      "loss": 3.4736,
      "step": 29300
    },
    {
      "epoch": 47.14,
      "learning_rate": 0.09528794683424438,
      "loss": 3.4803,
      "step": 29320
    },
    {
      "epoch": 47.17,
      "learning_rate": 0.0952847314033762,
      "loss": 3.5087,
      "step": 29340
    },
    {
      "epoch": 47.2,
      "learning_rate": 0.09528151597250804,
      "loss": 3.523,
      "step": 29360
    },
    {
      "epoch": 47.23,
      "learning_rate": 0.09527830054163987,
      "loss": 3.4119,
      "step": 29380
    },
    {
      "epoch": 47.27,
      "learning_rate": 0.0952750851107717,
      "loss": 3.4232,
      "step": 29400
    },
    {
      "epoch": 47.3,
      "learning_rate": 0.09527186967990355,
      "loss": 3.463,
      "step": 29420
    },
    {
      "epoch": 47.33,
      "learning_rate": 0.09526865424903537,
      "loss": 3.4707,
      "step": 29440
    },
    {
      "epoch": 47.36,
      "learning_rate": 0.09526543881816721,
      "loss": 3.4289,
      "step": 29460
    },
    {
      "epoch": 47.4,
      "learning_rate": 0.09526222338729903,
      "loss": 3.4677,
      "step": 29480
    },
    {
      "epoch": 47.43,
      "learning_rate": 0.09525900795643087,
      "loss": 3.4936,
      "step": 29500
    },
    {
      "epoch": 47.46,
      "learning_rate": 0.09525579252556271,
      "loss": 3.5173,
      "step": 29520
    },
    {
      "epoch": 47.49,
      "learning_rate": 0.09525257709469455,
      "loss": 3.4727,
      "step": 29540
    },
    {
      "epoch": 47.52,
      "learning_rate": 0.09524936166382637,
      "loss": 3.5399,
      "step": 29560
    },
    {
      "epoch": 47.56,
      "learning_rate": 0.0952461462329582,
      "loss": 3.4963,
      "step": 29580
    },
    {
      "epoch": 47.59,
      "learning_rate": 0.09524293080209004,
      "loss": 3.5237,
      "step": 29600
    },
    {
      "epoch": 47.62,
      "learning_rate": 0.09523971537122186,
      "loss": 3.4854,
      "step": 29620
    },
    {
      "epoch": 47.65,
      "learning_rate": 0.09523649994035371,
      "loss": 3.5385,
      "step": 29640
    },
    {
      "epoch": 47.68,
      "learning_rate": 0.09523328450948554,
      "loss": 3.4567,
      "step": 29660
    },
    {
      "epoch": 47.72,
      "learning_rate": 0.09523006907861736,
      "loss": 3.4346,
      "step": 29680
    },
    {
      "epoch": 47.75,
      "learning_rate": 0.0952268536477492,
      "loss": 3.5087,
      "step": 29700
    },
    {
      "epoch": 47.78,
      "learning_rate": 0.09522363821688103,
      "loss": 3.5301,
      "step": 29720
    },
    {
      "epoch": 47.81,
      "learning_rate": 0.09522042278601286,
      "loss": 3.5346,
      "step": 29740
    },
    {
      "epoch": 47.85,
      "learning_rate": 0.0952172073551447,
      "loss": 3.5556,
      "step": 29760
    },
    {
      "epoch": 47.88,
      "learning_rate": 0.09521399192427653,
      "loss": 3.5279,
      "step": 29780
    },
    {
      "epoch": 47.91,
      "learning_rate": 0.09521077649340837,
      "loss": 3.4483,
      "step": 29800
    },
    {
      "epoch": 47.94,
      "learning_rate": 0.09520756106254019,
      "loss": 3.4666,
      "step": 29820
    },
    {
      "epoch": 47.97,
      "learning_rate": 0.09520434563167203,
      "loss": 3.5058,
      "step": 29840
    },
    {
      "epoch": 48.0,
      "eval_accuracy": {
        "accuracy": 0.31120267433724635
      },
      "eval_loss": 3.621453285217285,
      "eval_runtime": 2.7032,
      "eval_samples_per_second": 4758.373,
      "eval_steps_per_second": 74.355,
      "step": 29856
    },
    {
      "epoch": 48.01,
      "learning_rate": 0.09520113020080387,
      "loss": 3.4996,
      "step": 29860
    },
    {
      "epoch": 48.04,
      "learning_rate": 0.0951979147699357,
      "loss": 3.5261,
      "step": 29880
    },
    {
      "epoch": 48.07,
      "learning_rate": 0.09519469933906753,
      "loss": 3.4884,
      "step": 29900
    },
    {
      "epoch": 48.1,
      "learning_rate": 0.09519148390819936,
      "loss": 3.5237,
      "step": 29920
    },
    {
      "epoch": 48.14,
      "learning_rate": 0.0951882684773312,
      "loss": 3.4292,
      "step": 29940
    },
    {
      "epoch": 48.17,
      "learning_rate": 0.09518505304646302,
      "loss": 3.4286,
      "step": 29960
    },
    {
      "epoch": 48.2,
      "learning_rate": 0.09518183761559486,
      "loss": 3.4501,
      "step": 29980
    },
    {
      "epoch": 48.23,
      "learning_rate": 0.0951786221847267,
      "loss": 3.4518,
      "step": 30000
    },
    {
      "epoch": 48.26,
      "learning_rate": 0.09517540675385852,
      "loss": 3.5282,
      "step": 30020
    },
    {
      "epoch": 48.3,
      "learning_rate": 0.09517219132299036,
      "loss": 3.5509,
      "step": 30040
    },
    {
      "epoch": 48.33,
      "learning_rate": 0.09516897589212218,
      "loss": 3.4794,
      "step": 30060
    },
    {
      "epoch": 48.36,
      "learning_rate": 0.09516576046125402,
      "loss": 3.4527,
      "step": 30080
    },
    {
      "epoch": 48.39,
      "learning_rate": 0.09516254503038586,
      "loss": 3.5007,
      "step": 30100
    },
    {
      "epoch": 48.42,
      "learning_rate": 0.09515932959951769,
      "loss": 3.478,
      "step": 30120
    },
    {
      "epoch": 48.46,
      "learning_rate": 0.09515611416864952,
      "loss": 3.4711,
      "step": 30140
    },
    {
      "epoch": 48.49,
      "learning_rate": 0.09515289873778135,
      "loss": 3.4948,
      "step": 30160
    },
    {
      "epoch": 48.52,
      "learning_rate": 0.09514968330691319,
      "loss": 3.507,
      "step": 30180
    },
    {
      "epoch": 48.55,
      "learning_rate": 0.09514646787604503,
      "loss": 3.4581,
      "step": 30200
    },
    {
      "epoch": 48.59,
      "learning_rate": 0.09514325244517685,
      "loss": 3.4706,
      "step": 30220
    },
    {
      "epoch": 48.62,
      "learning_rate": 0.09514003701430869,
      "loss": 3.4651,
      "step": 30240
    },
    {
      "epoch": 48.65,
      "learning_rate": 0.09513682158344051,
      "loss": 3.4483,
      "step": 30260
    },
    {
      "epoch": 48.68,
      "learning_rate": 0.09513360615257235,
      "loss": 3.4189,
      "step": 30280
    },
    {
      "epoch": 48.71,
      "learning_rate": 0.09513039072170418,
      "loss": 3.4569,
      "step": 30300
    },
    {
      "epoch": 48.75,
      "learning_rate": 0.09512717529083602,
      "loss": 3.491,
      "step": 30320
    },
    {
      "epoch": 48.78,
      "learning_rate": 0.09512395985996785,
      "loss": 3.4598,
      "step": 30340
    },
    {
      "epoch": 48.81,
      "learning_rate": 0.09512074442909968,
      "loss": 3.4841,
      "step": 30360
    },
    {
      "epoch": 48.84,
      "learning_rate": 0.09511752899823152,
      "loss": 3.4678,
      "step": 30380
    },
    {
      "epoch": 48.87,
      "learning_rate": 0.09511431356736334,
      "loss": 3.5133,
      "step": 30400
    },
    {
      "epoch": 48.91,
      "learning_rate": 0.09511109813649518,
      "loss": 3.4612,
      "step": 30420
    },
    {
      "epoch": 48.94,
      "learning_rate": 0.09510788270562702,
      "loss": 3.4581,
      "step": 30440
    },
    {
      "epoch": 48.97,
      "learning_rate": 0.09510466727475884,
      "loss": 3.4675,
      "step": 30460
    },
    {
      "epoch": 49.0,
      "eval_accuracy": {
        "accuracy": 0.31400139936251265
      },
      "eval_loss": 3.640293598175049,
      "eval_runtime": 2.5278,
      "eval_samples_per_second": 5088.594,
      "eval_steps_per_second": 79.515,
      "step": 30478
    },
    {
      "epoch": 49.0,
      "learning_rate": 0.09510145184389068,
      "loss": 3.474,
      "step": 30480
    },
    {
      "epoch": 49.04,
      "learning_rate": 0.09509823641302251,
      "loss": 3.4919,
      "step": 30500
    },
    {
      "epoch": 49.07,
      "learning_rate": 0.09509502098215435,
      "loss": 3.476,
      "step": 30520
    },
    {
      "epoch": 49.1,
      "learning_rate": 0.09509180555128618,
      "loss": 3.4898,
      "step": 30540
    },
    {
      "epoch": 49.13,
      "learning_rate": 0.09508859012041801,
      "loss": 3.4473,
      "step": 30560
    },
    {
      "epoch": 49.16,
      "learning_rate": 0.09508537468954985,
      "loss": 3.417,
      "step": 30580
    },
    {
      "epoch": 49.2,
      "learning_rate": 0.09508215925868167,
      "loss": 3.4404,
      "step": 30600
    },
    {
      "epoch": 49.23,
      "learning_rate": 0.09507894382781351,
      "loss": 3.4328,
      "step": 30620
    },
    {
      "epoch": 49.26,
      "learning_rate": 0.09507572839694535,
      "loss": 3.4627,
      "step": 30640
    },
    {
      "epoch": 49.29,
      "learning_rate": 0.09507251296607717,
      "loss": 3.4472,
      "step": 30660
    },
    {
      "epoch": 49.32,
      "learning_rate": 0.09506929753520901,
      "loss": 3.4834,
      "step": 30680
    },
    {
      "epoch": 49.36,
      "learning_rate": 0.09506608210434084,
      "loss": 3.5163,
      "step": 30700
    },
    {
      "epoch": 49.39,
      "learning_rate": 0.09506286667347268,
      "loss": 3.5453,
      "step": 30720
    },
    {
      "epoch": 49.42,
      "learning_rate": 0.0950596512426045,
      "loss": 3.5059,
      "step": 30740
    },
    {
      "epoch": 49.45,
      "learning_rate": 0.09505643581173634,
      "loss": 3.4958,
      "step": 30760
    },
    {
      "epoch": 49.49,
      "learning_rate": 0.09505322038086818,
      "loss": 3.4772,
      "step": 30780
    },
    {
      "epoch": 49.52,
      "learning_rate": 0.09505000495,
      "loss": 3.519,
      "step": 30800
    },
    {
      "epoch": 49.55,
      "learning_rate": 0.09504678951913184,
      "loss": 3.4631,
      "step": 30820
    },
    {
      "epoch": 49.58,
      "learning_rate": 0.09504357408826367,
      "loss": 3.4177,
      "step": 30840
    },
    {
      "epoch": 49.61,
      "learning_rate": 0.0950403586573955,
      "loss": 3.4494,
      "step": 30860
    },
    {
      "epoch": 49.65,
      "learning_rate": 0.09503714322652734,
      "loss": 3.3935,
      "step": 30880
    },
    {
      "epoch": 49.68,
      "learning_rate": 0.09503392779565917,
      "loss": 3.3575,
      "step": 30900
    },
    {
      "epoch": 49.71,
      "learning_rate": 0.095030712364791,
      "loss": 3.4317,
      "step": 30920
    },
    {
      "epoch": 49.74,
      "learning_rate": 0.09502749693392283,
      "loss": 3.4279,
      "step": 30940
    },
    {
      "epoch": 49.77,
      "learning_rate": 0.09502428150305467,
      "loss": 3.4892,
      "step": 30960
    },
    {
      "epoch": 49.81,
      "learning_rate": 0.09502106607218651,
      "loss": 3.4663,
      "step": 30980
    },
    {
      "epoch": 49.84,
      "learning_rate": 0.09501785064131833,
      "loss": 3.4539,
      "step": 31000
    },
    {
      "epoch": 49.87,
      "learning_rate": 0.09501463521045017,
      "loss": 3.4068,
      "step": 31020
    },
    {
      "epoch": 49.9,
      "learning_rate": 0.095011419779582,
      "loss": 3.3916,
      "step": 31040
    },
    {
      "epoch": 49.94,
      "learning_rate": 0.09500820434871383,
      "loss": 3.3827,
      "step": 31060
    },
    {
      "epoch": 49.97,
      "learning_rate": 0.09500498891784566,
      "loss": 3.4079,
      "step": 31080
    },
    {
      "epoch": 50.0,
      "learning_rate": 0.0950017734869775,
      "loss": 3.3856,
      "step": 31100
    },
    {
      "epoch": 50.0,
      "eval_accuracy": {
        "accuracy": 0.3240301640363834
      },
      "eval_loss": 3.503542184829712,
      "eval_runtime": 3.0981,
      "eval_samples_per_second": 4151.928,
      "eval_steps_per_second": 64.879,
      "step": 31100
    },
    {
      "epoch": 50.03,
      "learning_rate": 0.09499855805610934,
      "loss": 3.4989,
      "step": 31120
    },
    {
      "epoch": 50.06,
      "learning_rate": 0.09499534262524116,
      "loss": 3.424,
      "step": 31140
    },
    {
      "epoch": 50.1,
      "learning_rate": 0.094992127194373,
      "loss": 3.4732,
      "step": 31160
    },
    {
      "epoch": 50.13,
      "learning_rate": 0.09498891176350482,
      "loss": 3.4634,
      "step": 31180
    },
    {
      "epoch": 50.16,
      "learning_rate": 0.09498569633263666,
      "loss": 3.5021,
      "step": 31200
    },
    {
      "epoch": 50.19,
      "learning_rate": 0.0949824809017685,
      "loss": 3.4911,
      "step": 31220
    },
    {
      "epoch": 50.23,
      "learning_rate": 0.09497926547090033,
      "loss": 3.4916,
      "step": 31240
    },
    {
      "epoch": 50.26,
      "learning_rate": 0.09497605004003216,
      "loss": 3.4659,
      "step": 31260
    },
    {
      "epoch": 50.29,
      "learning_rate": 0.09497283460916399,
      "loss": 3.4276,
      "step": 31280
    },
    {
      "epoch": 50.32,
      "learning_rate": 0.09496961917829583,
      "loss": 3.4469,
      "step": 31300
    },
    {
      "epoch": 50.35,
      "learning_rate": 0.09496640374742767,
      "loss": 3.4566,
      "step": 31320
    },
    {
      "epoch": 50.39,
      "learning_rate": 0.09496318831655949,
      "loss": 3.4926,
      "step": 31340
    },
    {
      "epoch": 50.42,
      "learning_rate": 0.09495997288569133,
      "loss": 3.4408,
      "step": 31360
    },
    {
      "epoch": 50.45,
      "learning_rate": 0.09495675745482315,
      "loss": 3.4689,
      "step": 31380
    },
    {
      "epoch": 50.48,
      "learning_rate": 0.09495354202395499,
      "loss": 3.4774,
      "step": 31400
    },
    {
      "epoch": 50.51,
      "learning_rate": 0.09495032659308682,
      "loss": 3.5039,
      "step": 31420
    },
    {
      "epoch": 50.55,
      "learning_rate": 0.09494711116221866,
      "loss": 3.4514,
      "step": 31440
    },
    {
      "epoch": 50.58,
      "learning_rate": 0.0949438957313505,
      "loss": 3.4439,
      "step": 31460
    },
    {
      "epoch": 50.61,
      "learning_rate": 0.09494068030048232,
      "loss": 3.4629,
      "step": 31480
    },
    {
      "epoch": 50.64,
      "learning_rate": 0.09493746486961416,
      "loss": 3.4294,
      "step": 31500
    },
    {
      "epoch": 50.68,
      "learning_rate": 0.09493424943874598,
      "loss": 3.4357,
      "step": 31520
    },
    {
      "epoch": 50.71,
      "learning_rate": 0.09493103400787782,
      "loss": 3.4776,
      "step": 31540
    },
    {
      "epoch": 50.74,
      "learning_rate": 0.09492781857700966,
      "loss": 3.4377,
      "step": 31560
    },
    {
      "epoch": 50.77,
      "learning_rate": 0.09492460314614148,
      "loss": 3.4305,
      "step": 31580
    },
    {
      "epoch": 50.8,
      "learning_rate": 0.09492138771527332,
      "loss": 3.4186,
      "step": 31600
    },
    {
      "epoch": 50.84,
      "learning_rate": 0.09491817228440515,
      "loss": 3.4266,
      "step": 31620
    },
    {
      "epoch": 50.87,
      "learning_rate": 0.09491495685353699,
      "loss": 3.4292,
      "step": 31640
    },
    {
      "epoch": 50.9,
      "learning_rate": 0.09491174142266882,
      "loss": 3.4125,
      "step": 31660
    },
    {
      "epoch": 50.93,
      "learning_rate": 0.09490852599180065,
      "loss": 3.3987,
      "step": 31680
    },
    {
      "epoch": 50.96,
      "learning_rate": 0.09490531056093249,
      "loss": 3.4089,
      "step": 31700
    },
    {
      "epoch": 51.0,
      "learning_rate": 0.09490209513006431,
      "loss": 3.3698,
      "step": 31720
    },
    {
      "epoch": 51.0,
      "eval_accuracy": {
        "accuracy": 0.33141568840861385
      },
      "eval_loss": 3.409625768661499,
      "eval_runtime": 3.003,
      "eval_samples_per_second": 4283.327,
      "eval_steps_per_second": 66.932,
      "step": 31722
    },
    {
      "epoch": 51.03,
      "learning_rate": 0.09489887969919615,
      "loss": 3.3764,
      "step": 31740
    },
    {
      "epoch": 51.06,
      "learning_rate": 0.09489566426832798,
      "loss": 3.4468,
      "step": 31760
    },
    {
      "epoch": 51.09,
      "learning_rate": 0.09489244883745981,
      "loss": 3.452,
      "step": 31780
    },
    {
      "epoch": 51.13,
      "learning_rate": 0.09488923340659165,
      "loss": 3.4987,
      "step": 31800
    },
    {
      "epoch": 51.16,
      "learning_rate": 0.09488601797572348,
      "loss": 3.4529,
      "step": 31820
    },
    {
      "epoch": 51.19,
      "learning_rate": 0.09488280254485532,
      "loss": 3.4701,
      "step": 31840
    },
    {
      "epoch": 51.22,
      "learning_rate": 0.09487958711398714,
      "loss": 3.471,
      "step": 31860
    },
    {
      "epoch": 51.25,
      "learning_rate": 0.09487637168311897,
      "loss": 3.4461,
      "step": 31880
    },
    {
      "epoch": 51.29,
      "learning_rate": 0.09487315625225082,
      "loss": 3.4008,
      "step": 31900
    },
    {
      "epoch": 51.32,
      "learning_rate": 0.09486994082138264,
      "loss": 3.4285,
      "step": 31920
    },
    {
      "epoch": 51.35,
      "learning_rate": 0.09486672539051448,
      "loss": 3.4613,
      "step": 31940
    },
    {
      "epoch": 51.38,
      "learning_rate": 0.0948635099596463,
      "loss": 3.4617,
      "step": 31960
    },
    {
      "epoch": 51.41,
      "learning_rate": 0.09486029452877813,
      "loss": 3.528,
      "step": 31980
    },
    {
      "epoch": 51.45,
      "learning_rate": 0.09485707909790998,
      "loss": 3.4775,
      "step": 32000
    },
    {
      "epoch": 51.48,
      "learning_rate": 0.0948540244385852,
      "loss": 3.514,
      "step": 32020
    },
    {
      "epoch": 51.51,
      "learning_rate": 0.09485080900771706,
      "loss": 3.5792,
      "step": 32040
    },
    {
      "epoch": 51.54,
      "learning_rate": 0.09484759357684888,
      "loss": 3.5661,
      "step": 32060
    },
    {
      "epoch": 51.58,
      "learning_rate": 0.0948443781459807,
      "loss": 3.4744,
      "step": 32080
    },
    {
      "epoch": 51.61,
      "learning_rate": 0.09484116271511255,
      "loss": 3.4534,
      "step": 32100
    },
    {
      "epoch": 51.64,
      "learning_rate": 0.09483794728424437,
      "loss": 3.4602,
      "step": 32120
    },
    {
      "epoch": 51.67,
      "learning_rate": 0.09483473185337621,
      "loss": 3.4111,
      "step": 32140
    },
    {
      "epoch": 51.7,
      "learning_rate": 0.09483151642250805,
      "loss": 3.424,
      "step": 32160
    },
    {
      "epoch": 51.74,
      "learning_rate": 0.09482830099163987,
      "loss": 3.4334,
      "step": 32180
    },
    {
      "epoch": 51.77,
      "learning_rate": 0.09482508556077171,
      "loss": 3.466,
      "step": 32200
    },
    {
      "epoch": 51.8,
      "learning_rate": 0.09482187012990353,
      "loss": 3.4391,
      "step": 32220
    },
    {
      "epoch": 51.83,
      "learning_rate": 0.09481865469903537,
      "loss": 3.4483,
      "step": 32240
    },
    {
      "epoch": 51.86,
      "learning_rate": 0.09481543926816721,
      "loss": 3.491,
      "step": 32260
    },
    {
      "epoch": 51.9,
      "learning_rate": 0.09481222383729905,
      "loss": 3.4973,
      "step": 32280
    },
    {
      "epoch": 51.93,
      "learning_rate": 0.09480900840643088,
      "loss": 3.4865,
      "step": 32300
    },
    {
      "epoch": 51.96,
      "learning_rate": 0.0948057929755627,
      "loss": 3.488,
      "step": 32320
    },
    {
      "epoch": 51.99,
      "learning_rate": 0.09480257754469454,
      "loss": 3.4324,
      "step": 32340
    },
    {
      "epoch": 52.0,
      "eval_accuracy": {
        "accuracy": 0.31851045634766384
      },
      "eval_loss": 3.4857776165008545,
      "eval_runtime": 2.5722,
      "eval_samples_per_second": 5000.854,
      "eval_steps_per_second": 78.144,
      "step": 32344
    },
    {
      "epoch": 52.03,
      "learning_rate": 0.09479936211382636,
      "loss": 3.4704,
      "step": 32360
    },
    {
      "epoch": 52.06,
      "learning_rate": 0.09479614668295822,
      "loss": 3.4669,
      "step": 32380
    },
    {
      "epoch": 52.09,
      "learning_rate": 0.09479293125209004,
      "loss": 3.4474,
      "step": 32400
    },
    {
      "epoch": 52.12,
      "learning_rate": 0.09478971582122186,
      "loss": 3.4252,
      "step": 32420
    },
    {
      "epoch": 52.15,
      "learning_rate": 0.0947865003903537,
      "loss": 3.4552,
      "step": 32440
    },
    {
      "epoch": 52.19,
      "learning_rate": 0.09478328495948553,
      "loss": 3.4618,
      "step": 32460
    },
    {
      "epoch": 52.22,
      "learning_rate": 0.09478006952861737,
      "loss": 3.45,
      "step": 32480
    },
    {
      "epoch": 52.25,
      "learning_rate": 0.0947768540977492,
      "loss": 3.4738,
      "step": 32500
    },
    {
      "epoch": 52.28,
      "learning_rate": 0.09477363866688103,
      "loss": 3.4608,
      "step": 32520
    },
    {
      "epoch": 52.32,
      "learning_rate": 0.09477042323601287,
      "loss": 3.4482,
      "step": 32540
    },
    {
      "epoch": 52.35,
      "learning_rate": 0.0947672078051447,
      "loss": 3.474,
      "step": 32560
    },
    {
      "epoch": 52.38,
      "learning_rate": 0.09476399237427653,
      "loss": 3.4464,
      "step": 32580
    },
    {
      "epoch": 52.41,
      "learning_rate": 0.09476077694340837,
      "loss": 3.4329,
      "step": 32600
    },
    {
      "epoch": 52.44,
      "learning_rate": 0.0947575615125402,
      "loss": 3.4953,
      "step": 32620
    },
    {
      "epoch": 52.48,
      "learning_rate": 0.09475434608167203,
      "loss": 3.4943,
      "step": 32640
    },
    {
      "epoch": 52.51,
      "learning_rate": 0.09475113065080386,
      "loss": 3.4386,
      "step": 32660
    },
    {
      "epoch": 52.54,
      "learning_rate": 0.0947479152199357,
      "loss": 3.4456,
      "step": 32680
    },
    {
      "epoch": 52.57,
      "learning_rate": 0.09474469978906752,
      "loss": 3.4231,
      "step": 32700
    },
    {
      "epoch": 52.6,
      "learning_rate": 0.09474148435819936,
      "loss": 3.5089,
      "step": 32720
    },
    {
      "epoch": 52.64,
      "learning_rate": 0.0947382689273312,
      "loss": 3.4324,
      "step": 32740
    },
    {
      "epoch": 52.67,
      "learning_rate": 0.09473505349646302,
      "loss": 3.4093,
      "step": 32760
    },
    {
      "epoch": 52.7,
      "learning_rate": 0.09473183806559486,
      "loss": 3.4674,
      "step": 32780
    },
    {
      "epoch": 52.73,
      "learning_rate": 0.09472862263472669,
      "loss": 3.4665,
      "step": 32800
    },
    {
      "epoch": 52.77,
      "learning_rate": 0.09472540720385852,
      "loss": 3.4687,
      "step": 32820
    },
    {
      "epoch": 52.8,
      "learning_rate": 0.09472219177299036,
      "loss": 3.4426,
      "step": 32840
    },
    {
      "epoch": 52.83,
      "learning_rate": 0.09471897634212219,
      "loss": 3.4376,
      "step": 32860
    },
    {
      "epoch": 52.86,
      "learning_rate": 0.09471576091125403,
      "loss": 3.4044,
      "step": 32880
    },
    {
      "epoch": 52.89,
      "learning_rate": 0.09471254548038585,
      "loss": 3.3995,
      "step": 32900
    },
    {
      "epoch": 52.93,
      "learning_rate": 0.09470933004951769,
      "loss": 3.3933,
      "step": 32920
    },
    {
      "epoch": 52.96,
      "learning_rate": 0.09470611461864953,
      "loss": 3.3929,
      "step": 32940
    },
    {
      "epoch": 52.99,
      "learning_rate": 0.09470289918778135,
      "loss": 3.4387,
      "step": 32960
    },
    {
      "epoch": 53.0,
      "eval_accuracy": {
        "accuracy": 0.3211536966493042
      },
      "eval_loss": 3.5799667835235596,
      "eval_runtime": 2.8216,
      "eval_samples_per_second": 4558.711,
      "eval_steps_per_second": 71.235,
      "step": 32966
    },
    {
      "epoch": 53.02,
      "learning_rate": 0.09469968375691319,
      "loss": 3.4953,
      "step": 32980
    },
    {
      "epoch": 53.05,
      "learning_rate": 0.09469646832604502,
      "loss": 3.4829,
      "step": 33000
    },
    {
      "epoch": 53.09,
      "learning_rate": 0.09469325289517685,
      "loss": 3.4724,
      "step": 33020
    },
    {
      "epoch": 53.12,
      "learning_rate": 0.0946900374643087,
      "loss": 3.4067,
      "step": 33040
    },
    {
      "epoch": 53.15,
      "learning_rate": 0.09468682203344052,
      "loss": 3.4196,
      "step": 33060
    },
    {
      "epoch": 53.18,
      "learning_rate": 0.09468360660257236,
      "loss": 3.3829,
      "step": 33080
    },
    {
      "epoch": 53.22,
      "learning_rate": 0.09468039117170418,
      "loss": 3.3909,
      "step": 33100
    },
    {
      "epoch": 53.25,
      "learning_rate": 0.09467717574083602,
      "loss": 3.4334,
      "step": 33120
    },
    {
      "epoch": 53.28,
      "learning_rate": 0.09467396030996784,
      "loss": 3.4621,
      "step": 33140
    },
    {
      "epoch": 53.31,
      "learning_rate": 0.09467074487909968,
      "loss": 3.4917,
      "step": 33160
    },
    {
      "epoch": 53.34,
      "learning_rate": 0.09466752944823152,
      "loss": 3.4518,
      "step": 33180
    },
    {
      "epoch": 53.38,
      "learning_rate": 0.09466431401736335,
      "loss": 3.3639,
      "step": 33200
    },
    {
      "epoch": 53.41,
      "learning_rate": 0.09466109858649518,
      "loss": 3.3966,
      "step": 33220
    },
    {
      "epoch": 53.44,
      "learning_rate": 0.09465788315562701,
      "loss": 3.372,
      "step": 33240
    },
    {
      "epoch": 53.47,
      "learning_rate": 0.09465466772475885,
      "loss": 3.3722,
      "step": 33260
    },
    {
      "epoch": 53.5,
      "learning_rate": 0.09465145229389069,
      "loss": 3.4607,
      "step": 33280
    },
    {
      "epoch": 53.54,
      "learning_rate": 0.09464823686302251,
      "loss": 3.4649,
      "step": 33300
    },
    {
      "epoch": 53.57,
      "learning_rate": 0.09464502143215435,
      "loss": 3.4171,
      "step": 33320
    },
    {
      "epoch": 53.6,
      "learning_rate": 0.09464180600128617,
      "loss": 3.415,
      "step": 33340
    },
    {
      "epoch": 53.63,
      "learning_rate": 0.09463859057041801,
      "loss": 3.4171,
      "step": 33360
    },
    {
      "epoch": 53.67,
      "learning_rate": 0.09463537513954985,
      "loss": 3.4237,
      "step": 33380
    },
    {
      "epoch": 53.7,
      "learning_rate": 0.09463215970868168,
      "loss": 3.4282,
      "step": 33400
    },
    {
      "epoch": 53.73,
      "learning_rate": 0.09462894427781351,
      "loss": 3.4271,
      "step": 33420
    },
    {
      "epoch": 53.76,
      "learning_rate": 0.09462572884694534,
      "loss": 3.4078,
      "step": 33440
    },
    {
      "epoch": 53.79,
      "learning_rate": 0.09462251341607718,
      "loss": 3.4034,
      "step": 33460
    },
    {
      "epoch": 53.83,
      "learning_rate": 0.094619297985209,
      "loss": 3.4221,
      "step": 33480
    },
    {
      "epoch": 53.86,
      "learning_rate": 0.09461608255434084,
      "loss": 3.4244,
      "step": 33500
    },
    {
      "epoch": 53.89,
      "learning_rate": 0.09461286712347268,
      "loss": 3.4381,
      "step": 33520
    },
    {
      "epoch": 53.92,
      "learning_rate": 0.0946096516926045,
      "loss": 3.4071,
      "step": 33540
    },
    {
      "epoch": 53.95,
      "learning_rate": 0.09460643626173634,
      "loss": 3.4552,
      "step": 33560
    },
    {
      "epoch": 53.99,
      "learning_rate": 0.09460322083086817,
      "loss": 3.4456,
      "step": 33580
    },
    {
      "epoch": 54.0,
      "eval_accuracy": {
        "accuracy": 0.3232527404182539
      },
      "eval_loss": 3.5066795349121094,
      "eval_runtime": 3.1634,
      "eval_samples_per_second": 4066.221,
      "eval_steps_per_second": 63.54,
      "step": 33588
    },
    {
      "epoch": 54.02,
      "learning_rate": 0.0946000054,
      "loss": 3.4491,
      "step": 33600
    },
    {
      "epoch": 54.05,
      "learning_rate": 0.09459678996913184,
      "loss": 3.3885,
      "step": 33620
    },
    {
      "epoch": 54.08,
      "learning_rate": 0.09459357453826367,
      "loss": 3.4256,
      "step": 33640
    },
    {
      "epoch": 54.12,
      "learning_rate": 0.09459035910739551,
      "loss": 3.4203,
      "step": 33660
    },
    {
      "epoch": 54.15,
      "learning_rate": 0.09458714367652733,
      "loss": 3.4611,
      "step": 33680
    },
    {
      "epoch": 54.18,
      "learning_rate": 0.09458392824565917,
      "loss": 3.4119,
      "step": 33700
    },
    {
      "epoch": 54.21,
      "learning_rate": 0.09458071281479101,
      "loss": 3.4548,
      "step": 33720
    },
    {
      "epoch": 54.24,
      "learning_rate": 0.09457749738392283,
      "loss": 3.421,
      "step": 33740
    },
    {
      "epoch": 54.28,
      "learning_rate": 0.09457428195305467,
      "loss": 3.396,
      "step": 33760
    },
    {
      "epoch": 54.31,
      "learning_rate": 0.0945710665221865,
      "loss": 3.4298,
      "step": 33780
    },
    {
      "epoch": 54.34,
      "learning_rate": 0.09456785109131834,
      "loss": 3.4768,
      "step": 33800
    },
    {
      "epoch": 54.37,
      "learning_rate": 0.09456463566045016,
      "loss": 3.4738,
      "step": 33820
    },
    {
      "epoch": 54.41,
      "learning_rate": 0.094561420229582,
      "loss": 3.4652,
      "step": 33840
    },
    {
      "epoch": 54.44,
      "learning_rate": 0.09455820479871384,
      "loss": 3.4474,
      "step": 33860
    },
    {
      "epoch": 54.47,
      "learning_rate": 0.09455498936784566,
      "loss": 3.4199,
      "step": 33880
    },
    {
      "epoch": 54.5,
      "learning_rate": 0.0945517739369775,
      "loss": 3.4027,
      "step": 33900
    },
    {
      "epoch": 54.53,
      "learning_rate": 0.09454855850610933,
      "loss": 3.4107,
      "step": 33920
    },
    {
      "epoch": 54.57,
      "learning_rate": 0.09454534307524116,
      "loss": 3.4262,
      "step": 33940
    },
    {
      "epoch": 54.6,
      "learning_rate": 0.094542127644373,
      "loss": 3.4178,
      "step": 33960
    },
    {
      "epoch": 54.63,
      "learning_rate": 0.09453891221350483,
      "loss": 3.3961,
      "step": 33980
    },
    {
      "epoch": 54.66,
      "learning_rate": 0.09453569678263667,
      "loss": 3.4056,
      "step": 34000
    },
    {
      "epoch": 54.69,
      "learning_rate": 0.09453248135176849,
      "loss": 3.4021,
      "step": 34020
    },
    {
      "epoch": 54.73,
      "learning_rate": 0.09452926592090033,
      "loss": 3.4124,
      "step": 34040
    },
    {
      "epoch": 54.76,
      "learning_rate": 0.09452605049003217,
      "loss": 3.4174,
      "step": 34060
    },
    {
      "epoch": 54.79,
      "learning_rate": 0.09452283505916399,
      "loss": 3.3996,
      "step": 34080
    },
    {
      "epoch": 54.82,
      "learning_rate": 0.09451961962829583,
      "loss": 3.3852,
      "step": 34100
    },
    {
      "epoch": 54.86,
      "learning_rate": 0.09451640419742766,
      "loss": 3.3826,
      "step": 34120
    },
    {
      "epoch": 54.89,
      "learning_rate": 0.0945131887665595,
      "loss": 3.4286,
      "step": 34140
    },
    {
      "epoch": 54.92,
      "learning_rate": 0.09450997333569132,
      "loss": 3.3858,
      "step": 34160
    },
    {
      "epoch": 54.95,
      "learning_rate": 0.09450675790482316,
      "loss": 3.378,
      "step": 34180
    },
    {
      "epoch": 54.98,
      "learning_rate": 0.094503542473955,
      "loss": 3.3846,
      "step": 34200
    },
    {
      "epoch": 55.0,
      "eval_accuracy": {
        "accuracy": 0.3218533779056208
      },
      "eval_loss": 3.464839458465576,
      "eval_runtime": 2.5691,
      "eval_samples_per_second": 5006.767,
      "eval_steps_per_second": 78.237,
      "step": 34210
    },
    {
      "epoch": 55.02,
      "learning_rate": 0.09450032704308682,
      "loss": 3.4533,
      "step": 34220
    },
    {
      "epoch": 55.05,
      "learning_rate": 0.09449727238376207,
      "loss": 3.4744,
      "step": 34240
    },
    {
      "epoch": 55.08,
      "learning_rate": 0.0944940569528939,
      "loss": 3.4729,
      "step": 34260
    },
    {
      "epoch": 55.11,
      "learning_rate": 0.09449084152202572,
      "loss": 3.4071,
      "step": 34280
    },
    {
      "epoch": 55.14,
      "learning_rate": 0.09448762609115756,
      "loss": 3.3618,
      "step": 34300
    },
    {
      "epoch": 55.18,
      "learning_rate": 0.0944844106602894,
      "loss": 3.3924,
      "step": 34320
    },
    {
      "epoch": 55.21,
      "learning_rate": 0.09448119522942124,
      "loss": 3.392,
      "step": 34340
    },
    {
      "epoch": 55.24,
      "learning_rate": 0.09447797979855306,
      "loss": 3.3668,
      "step": 34360
    },
    {
      "epoch": 55.27,
      "learning_rate": 0.09447476436768489,
      "loss": 3.3903,
      "step": 34380
    },
    {
      "epoch": 55.31,
      "learning_rate": 0.09447154893681672,
      "loss": 3.3803,
      "step": 34400
    },
    {
      "epoch": 55.34,
      "learning_rate": 0.09446833350594855,
      "loss": 3.4141,
      "step": 34420
    },
    {
      "epoch": 55.37,
      "learning_rate": 0.0944651180750804,
      "loss": 3.4236,
      "step": 34440
    },
    {
      "epoch": 55.4,
      "learning_rate": 0.09446190264421223,
      "loss": 3.4112,
      "step": 34460
    },
    {
      "epoch": 55.43,
      "learning_rate": 0.09445868721334406,
      "loss": 3.3734,
      "step": 34480
    },
    {
      "epoch": 55.47,
      "learning_rate": 0.09445547178247589,
      "loss": 3.4511,
      "step": 34500
    },
    {
      "epoch": 55.5,
      "learning_rate": 0.09445225635160771,
      "loss": 3.4782,
      "step": 34520
    },
    {
      "epoch": 55.53,
      "learning_rate": 0.09444904092073955,
      "loss": 3.4207,
      "step": 34540
    },
    {
      "epoch": 55.56,
      "learning_rate": 0.09444582548987139,
      "loss": 3.431,
      "step": 34560
    },
    {
      "epoch": 55.59,
      "learning_rate": 0.09444261005900323,
      "loss": 3.5022,
      "step": 34580
    },
    {
      "epoch": 55.63,
      "learning_rate": 0.09443939462813505,
      "loss": 3.4485,
      "step": 34600
    },
    {
      "epoch": 55.66,
      "learning_rate": 0.09443617919726688,
      "loss": 3.4656,
      "step": 34620
    },
    {
      "epoch": 55.69,
      "learning_rate": 0.09443296376639872,
      "loss": 3.4634,
      "step": 34640
    },
    {
      "epoch": 55.72,
      "learning_rate": 0.09442974833553056,
      "loss": 3.4638,
      "step": 34660
    },
    {
      "epoch": 55.76,
      "learning_rate": 0.0944265329046624,
      "loss": 3.485,
      "step": 34680
    },
    {
      "epoch": 55.79,
      "learning_rate": 0.09442331747379422,
      "loss": 3.4473,
      "step": 34700
    },
    {
      "epoch": 55.82,
      "learning_rate": 0.09442010204292604,
      "loss": 3.3588,
      "step": 34720
    },
    {
      "epoch": 55.85,
      "learning_rate": 0.09441688661205788,
      "loss": 3.4367,
      "step": 34740
    },
    {
      "epoch": 55.88,
      "learning_rate": 0.0944136711811897,
      "loss": 3.4353,
      "step": 34760
    },
    {
      "epoch": 55.92,
      "learning_rate": 0.09441045575032156,
      "loss": 3.4473,
      "step": 34780
    },
    {
      "epoch": 55.95,
      "learning_rate": 0.09440724031945338,
      "loss": 3.3805,
      "step": 34800
    },
    {
      "epoch": 55.98,
      "learning_rate": 0.09440402488858521,
      "loss": 3.39,
      "step": 34820
    },
    {
      "epoch": 56.0,
      "eval_accuracy": {
        "accuracy": 0.3251962994635777
      },
      "eval_loss": 3.486009359359741,
      "eval_runtime": 2.8974,
      "eval_samples_per_second": 4439.505,
      "eval_steps_per_second": 69.373,
      "step": 34832
    },
    {
      "epoch": 56.01,
      "learning_rate": 0.09440080945771705,
      "loss": 3.4309,
      "step": 34840
    },
    {
      "epoch": 56.05,
      "learning_rate": 0.09439759402684887,
      "loss": 3.4422,
      "step": 34860
    },
    {
      "epoch": 56.08,
      "learning_rate": 0.09439437859598071,
      "loss": 3.43,
      "step": 34880
    },
    {
      "epoch": 56.11,
      "learning_rate": 0.09439116316511255,
      "loss": 3.4701,
      "step": 34900
    },
    {
      "epoch": 56.14,
      "learning_rate": 0.09438794773424437,
      "loss": 3.4214,
      "step": 34920
    },
    {
      "epoch": 56.17,
      "learning_rate": 0.09438473230337621,
      "loss": 3.3898,
      "step": 34940
    },
    {
      "epoch": 56.21,
      "learning_rate": 0.09438151687250804,
      "loss": 3.3638,
      "step": 34960
    },
    {
      "epoch": 56.24,
      "learning_rate": 0.09437830144163988,
      "loss": 3.3978,
      "step": 34980
    },
    {
      "epoch": 56.27,
      "learning_rate": 0.09437508601077171,
      "loss": 3.445,
      "step": 35000
    },
    {
      "epoch": 56.3,
      "learning_rate": 0.09437187057990354,
      "loss": 3.4249,
      "step": 35020
    },
    {
      "epoch": 56.33,
      "learning_rate": 0.09436865514903538,
      "loss": 3.3504,
      "step": 35040
    },
    {
      "epoch": 56.37,
      "learning_rate": 0.0943654397181672,
      "loss": 3.3967,
      "step": 35060
    },
    {
      "epoch": 56.4,
      "learning_rate": 0.09436222428729904,
      "loss": 3.4051,
      "step": 35080
    },
    {
      "epoch": 56.43,
      "learning_rate": 0.09435900885643086,
      "loss": 3.4137,
      "step": 35100
    },
    {
      "epoch": 56.46,
      "learning_rate": 0.09435579342556272,
      "loss": 3.41,
      "step": 35120
    },
    {
      "epoch": 56.5,
      "learning_rate": 0.09435257799469454,
      "loss": 3.3875,
      "step": 35140
    },
    {
      "epoch": 56.53,
      "learning_rate": 0.09434936256382637,
      "loss": 3.4233,
      "step": 35160
    },
    {
      "epoch": 56.56,
      "learning_rate": 0.0943461471329582,
      "loss": 3.3805,
      "step": 35180
    },
    {
      "epoch": 56.59,
      "learning_rate": 0.09434293170209003,
      "loss": 3.3868,
      "step": 35200
    },
    {
      "epoch": 56.62,
      "learning_rate": 0.09433971627122187,
      "loss": 3.384,
      "step": 35220
    },
    {
      "epoch": 56.66,
      "learning_rate": 0.09433650084035371,
      "loss": 3.3979,
      "step": 35240
    },
    {
      "epoch": 56.69,
      "learning_rate": 0.09433328540948553,
      "loss": 3.4494,
      "step": 35260
    },
    {
      "epoch": 56.72,
      "learning_rate": 0.09433006997861737,
      "loss": 3.4121,
      "step": 35280
    },
    {
      "epoch": 56.75,
      "learning_rate": 0.0943268545477492,
      "loss": 3.3824,
      "step": 35300
    },
    {
      "epoch": 56.78,
      "learning_rate": 0.09432363911688103,
      "loss": 3.3857,
      "step": 35320
    },
    {
      "epoch": 56.82,
      "learning_rate": 0.09432042368601287,
      "loss": 3.3808,
      "step": 35340
    },
    {
      "epoch": 56.85,
      "learning_rate": 0.0943172082551447,
      "loss": 3.4017,
      "step": 35360
    },
    {
      "epoch": 56.88,
      "learning_rate": 0.09431399282427654,
      "loss": 3.3712,
      "step": 35380
    },
    {
      "epoch": 56.91,
      "learning_rate": 0.09431077739340836,
      "loss": 3.3714,
      "step": 35400
    },
    {
      "epoch": 56.95,
      "learning_rate": 0.0943075619625402,
      "loss": 3.422,
      "step": 35420
    },
    {
      "epoch": 56.98,
      "learning_rate": 0.09430434653167202,
      "loss": 3.3991,
      "step": 35440
    },
    {
      "epoch": 57.0,
      "eval_accuracy": {
        "accuracy": 0.3254295265490166
      },
      "eval_loss": 3.5232276916503906,
      "eval_runtime": 2.5959,
      "eval_samples_per_second": 4955.208,
      "eval_steps_per_second": 77.431,
      "step": 35454
    },
    {
      "epoch": 57.01,
      "learning_rate": 0.09430113110080386,
      "loss": 3.4209,
      "step": 35460
    },
    {
      "epoch": 57.04,
      "learning_rate": 0.0942979156699357,
      "loss": 3.3841,
      "step": 35480
    },
    {
      "epoch": 57.07,
      "learning_rate": 0.09429470023906752,
      "loss": 3.3709,
      "step": 35500
    },
    {
      "epoch": 57.11,
      "learning_rate": 0.09429148480819936,
      "loss": 3.4418,
      "step": 35520
    },
    {
      "epoch": 57.14,
      "learning_rate": 0.09428826937733119,
      "loss": 3.4338,
      "step": 35540
    },
    {
      "epoch": 57.17,
      "learning_rate": 0.09428505394646303,
      "loss": 3.3679,
      "step": 35560
    },
    {
      "epoch": 57.2,
      "learning_rate": 0.09428183851559487,
      "loss": 3.3561,
      "step": 35580
    },
    {
      "epoch": 57.23,
      "learning_rate": 0.09427862308472669,
      "loss": 3.3959,
      "step": 35600
    },
    {
      "epoch": 57.27,
      "learning_rate": 0.09427540765385853,
      "loss": 3.3801,
      "step": 35620
    },
    {
      "epoch": 57.3,
      "learning_rate": 0.09427219222299035,
      "loss": 3.3878,
      "step": 35640
    },
    {
      "epoch": 57.33,
      "learning_rate": 0.09426897679212219,
      "loss": 3.3949,
      "step": 35660
    },
    {
      "epoch": 57.36,
      "learning_rate": 0.09426576136125403,
      "loss": 3.4085,
      "step": 35680
    },
    {
      "epoch": 57.4,
      "learning_rate": 0.09426254593038585,
      "loss": 3.4215,
      "step": 35700
    },
    {
      "epoch": 57.43,
      "learning_rate": 0.0942593304995177,
      "loss": 3.3882,
      "step": 35720
    },
    {
      "epoch": 57.46,
      "learning_rate": 0.09425611506864952,
      "loss": 3.3983,
      "step": 35740
    },
    {
      "epoch": 57.49,
      "learning_rate": 0.09425289963778136,
      "loss": 3.4151,
      "step": 35760
    },
    {
      "epoch": 57.52,
      "learning_rate": 0.0942496842069132,
      "loss": 3.4733,
      "step": 35780
    },
    {
      "epoch": 57.56,
      "learning_rate": 0.09424646877604502,
      "loss": 3.4133,
      "step": 35800
    },
    {
      "epoch": 57.59,
      "learning_rate": 0.09424325334517686,
      "loss": 3.4938,
      "step": 35820
    },
    {
      "epoch": 57.62,
      "learning_rate": 0.09424003791430868,
      "loss": 3.4002,
      "step": 35840
    },
    {
      "epoch": 57.65,
      "learning_rate": 0.09423682248344052,
      "loss": 3.3803,
      "step": 35860
    },
    {
      "epoch": 57.68,
      "learning_rate": 0.09423360705257235,
      "loss": 3.4151,
      "step": 35880
    },
    {
      "epoch": 57.72,
      "learning_rate": 0.09423039162170418,
      "loss": 3.4809,
      "step": 35900
    },
    {
      "epoch": 57.75,
      "learning_rate": 0.09422717619083602,
      "loss": 3.4109,
      "step": 35920
    },
    {
      "epoch": 57.78,
      "learning_rate": 0.09422396075996785,
      "loss": 3.4127,
      "step": 35940
    },
    {
      "epoch": 57.81,
      "learning_rate": 0.09422074532909969,
      "loss": 3.3225,
      "step": 35960
    },
    {
      "epoch": 57.85,
      "learning_rate": 0.09421752989823151,
      "loss": 3.374,
      "step": 35980
    },
    {
      "epoch": 57.88,
      "learning_rate": 0.09421431446736335,
      "loss": 3.4016,
      "step": 36000
    },
    {
      "epoch": 57.91,
      "learning_rate": 0.09421109903649519,
      "loss": 3.4305,
      "step": 36020
    },
    {
      "epoch": 57.94,
      "learning_rate": 0.09420788360562701,
      "loss": 3.4316,
      "step": 36040
    },
    {
      "epoch": 57.97,
      "learning_rate": 0.09420466817475885,
      "loss": 3.4146,
      "step": 36060
    },
    {
      "epoch": 58.0,
      "eval_accuracy": {
        "accuracy": 0.3301718106196066
      },
      "eval_loss": 3.5187299251556396,
      "eval_runtime": 2.5012,
      "eval_samples_per_second": 5142.698,
      "eval_steps_per_second": 80.361,
      "step": 36076
    },
    {
      "epoch": 58.01,
      "learning_rate": 0.09420145274389068,
      "loss": 3.4769,
      "step": 36080
    },
    {
      "epoch": 58.04,
      "learning_rate": 0.09419823731302251,
      "loss": 3.4231,
      "step": 36100
    },
    {
      "epoch": 58.07,
      "learning_rate": 0.09419502188215435,
      "loss": 3.3838,
      "step": 36120
    },
    {
      "epoch": 58.1,
      "learning_rate": 0.09419180645128618,
      "loss": 3.371,
      "step": 36140
    },
    {
      "epoch": 58.14,
      "learning_rate": 0.09418859102041802,
      "loss": 3.3195,
      "step": 36160
    },
    {
      "epoch": 58.17,
      "learning_rate": 0.09418537558954984,
      "loss": 3.401,
      "step": 36180
    },
    {
      "epoch": 58.2,
      "learning_rate": 0.09418216015868168,
      "loss": 3.3648,
      "step": 36200
    },
    {
      "epoch": 58.23,
      "learning_rate": 0.0941789447278135,
      "loss": 3.4292,
      "step": 36220
    },
    {
      "epoch": 58.26,
      "learning_rate": 0.09417572929694534,
      "loss": 3.4024,
      "step": 36240
    },
    {
      "epoch": 58.3,
      "learning_rate": 0.09417251386607718,
      "loss": 3.4068,
      "step": 36260
    },
    {
      "epoch": 58.33,
      "learning_rate": 0.094169298435209,
      "loss": 3.3963,
      "step": 36280
    },
    {
      "epoch": 58.36,
      "learning_rate": 0.09416608300434084,
      "loss": 3.3877,
      "step": 36300
    },
    {
      "epoch": 58.39,
      "learning_rate": 0.09416286757347267,
      "loss": 3.4111,
      "step": 36320
    },
    {
      "epoch": 58.42,
      "learning_rate": 0.09415981291414792,
      "loss": 3.4179,
      "step": 36340
    },
    {
      "epoch": 58.46,
      "learning_rate": 0.09415659748327974,
      "loss": 3.3952,
      "step": 36360
    },
    {
      "epoch": 58.49,
      "learning_rate": 0.09415338205241158,
      "loss": 3.4205,
      "step": 36380
    },
    {
      "epoch": 58.52,
      "learning_rate": 0.09415016662154342,
      "loss": 3.4018,
      "step": 36400
    },
    {
      "epoch": 58.55,
      "learning_rate": 0.09414695119067525,
      "loss": 3.4079,
      "step": 36420
    },
    {
      "epoch": 58.59,
      "learning_rate": 0.09414373575980708,
      "loss": 3.4298,
      "step": 36440
    },
    {
      "epoch": 58.62,
      "learning_rate": 0.09414052032893891,
      "loss": 3.4356,
      "step": 36460
    },
    {
      "epoch": 58.65,
      "learning_rate": 0.09413730489807073,
      "loss": 3.4275,
      "step": 36480
    },
    {
      "epoch": 58.68,
      "learning_rate": 0.09413408946720259,
      "loss": 3.4233,
      "step": 36500
    },
    {
      "epoch": 58.71,
      "learning_rate": 0.09413087403633441,
      "loss": 3.4179,
      "step": 36520
    },
    {
      "epoch": 58.75,
      "learning_rate": 0.09412765860546625,
      "loss": 3.3636,
      "step": 36540
    },
    {
      "epoch": 58.78,
      "learning_rate": 0.09412444317459807,
      "loss": 3.351,
      "step": 36560
    },
    {
      "epoch": 58.81,
      "learning_rate": 0.0941212277437299,
      "loss": 3.3557,
      "step": 36580
    },
    {
      "epoch": 58.84,
      "learning_rate": 0.09411801231286174,
      "loss": 3.3681,
      "step": 36600
    },
    {
      "epoch": 58.87,
      "learning_rate": 0.09411479688199358,
      "loss": 3.3803,
      "step": 36620
    },
    {
      "epoch": 58.91,
      "learning_rate": 0.09411158145112541,
      "loss": 3.3984,
      "step": 36640
    },
    {
      "epoch": 58.94,
      "learning_rate": 0.09410836602025724,
      "loss": 3.3928,
      "step": 36660
    },
    {
      "epoch": 58.97,
      "learning_rate": 0.09410515058938908,
      "loss": 3.3722,
      "step": 36680
    },
    {
      "epoch": 59.0,
      "eval_accuracy": {
        "accuracy": 0.3314934307704268
      },
      "eval_loss": 3.456510543823242,
      "eval_runtime": 2.6737,
      "eval_samples_per_second": 4811.003,
      "eval_steps_per_second": 75.178,
      "step": 36698
    },
    {
      "epoch": 59.0,
      "learning_rate": 0.0941019351585209,
      "loss": 3.3682,
      "step": 36700
    },
    {
      "epoch": 59.04,
      "learning_rate": 0.09409871972765274,
      "loss": 3.3186,
      "step": 36720
    },
    {
      "epoch": 59.07,
      "learning_rate": 0.09409550429678458,
      "loss": 3.3451,
      "step": 36740
    },
    {
      "epoch": 59.1,
      "learning_rate": 0.0940922888659164,
      "loss": 3.3616,
      "step": 36760
    },
    {
      "epoch": 59.13,
      "learning_rate": 0.09408907343504824,
      "loss": 3.3301,
      "step": 36780
    },
    {
      "epoch": 59.16,
      "learning_rate": 0.09408585800418007,
      "loss": 3.4112,
      "step": 36800
    },
    {
      "epoch": 59.2,
      "learning_rate": 0.09408264257331189,
      "loss": 3.3885,
      "step": 36820
    },
    {
      "epoch": 59.23,
      "learning_rate": 0.09407942714244374,
      "loss": 3.4419,
      "step": 36840
    },
    {
      "epoch": 59.26,
      "learning_rate": 0.09407621171157557,
      "loss": 3.5023,
      "step": 36860
    },
    {
      "epoch": 59.29,
      "learning_rate": 0.09407299628070741,
      "loss": 3.4692,
      "step": 36880
    },
    {
      "epoch": 59.32,
      "learning_rate": 0.09406978084983923,
      "loss": 3.4595,
      "step": 36900
    },
    {
      "epoch": 59.36,
      "learning_rate": 0.09406656541897106,
      "loss": 3.5483,
      "step": 36920
    },
    {
      "epoch": 59.39,
      "learning_rate": 0.0940633499881029,
      "loss": 3.4078,
      "step": 36940
    },
    {
      "epoch": 59.42,
      "learning_rate": 0.09406013455723473,
      "loss": 3.3483,
      "step": 36960
    },
    {
      "epoch": 59.45,
      "learning_rate": 0.09405691912636657,
      "loss": 3.3615,
      "step": 36980
    },
    {
      "epoch": 59.49,
      "learning_rate": 0.0940537036954984,
      "loss": 3.3499,
      "step": 37000
    },
    {
      "epoch": 59.52,
      "learning_rate": 0.09405048826463022,
      "loss": 3.4098,
      "step": 37020
    },
    {
      "epoch": 59.55,
      "learning_rate": 0.09404727283376206,
      "loss": 3.3612,
      "step": 37040
    },
    {
      "epoch": 59.58,
      "learning_rate": 0.0940440574028939,
      "loss": 3.3487,
      "step": 37060
    },
    {
      "epoch": 59.61,
      "learning_rate": 0.09404084197202574,
      "loss": 3.4179,
      "step": 37080
    },
    {
      "epoch": 59.65,
      "learning_rate": 0.09403762654115756,
      "loss": 3.4088,
      "step": 37100
    },
    {
      "epoch": 59.68,
      "learning_rate": 0.09403441111028939,
      "loss": 3.4279,
      "step": 37120
    },
    {
      "epoch": 59.71,
      "learning_rate": 0.09403119567942123,
      "loss": 3.4195,
      "step": 37140
    },
    {
      "epoch": 59.74,
      "learning_rate": 0.09402798024855305,
      "loss": 3.4331,
      "step": 37160
    },
    {
      "epoch": 59.77,
      "learning_rate": 0.0940247648176849,
      "loss": 3.4053,
      "step": 37180
    },
    {
      "epoch": 59.81,
      "learning_rate": 0.09402154938681673,
      "loss": 3.3248,
      "step": 37200
    },
    {
      "epoch": 59.84,
      "learning_rate": 0.09401833395594855,
      "loss": 3.3311,
      "step": 37220
    },
    {
      "epoch": 59.87,
      "learning_rate": 0.09401511852508039,
      "loss": 3.3879,
      "step": 37240
    },
    {
      "epoch": 59.9,
      "learning_rate": 0.09401190309421222,
      "loss": 3.3422,
      "step": 37260
    },
    {
      "epoch": 59.94,
      "learning_rate": 0.09400868766334405,
      "loss": 3.3788,
      "step": 37280
    },
    {
      "epoch": 59.97,
      "learning_rate": 0.09400547223247589,
      "loss": 3.3757,
      "step": 37300
    },
    {
      "epoch": 60.0,
      "learning_rate": 0.09400225680160773,
      "loss": 3.372,
      "step": 37320
    },
    {
      "epoch": 60.0,
      "eval_accuracy": {
        "accuracy": 0.3348363523283837
      },
      "eval_loss": 3.3908934593200684,
      "eval_runtime": 2.8262,
      "eval_samples_per_second": 4551.367,
      "eval_steps_per_second": 71.121,
      "step": 37320
    },
    {
      "epoch": 60.03,
      "learning_rate": 0.09399904137073956,
      "loss": 3.3359,
      "step": 37340
    },
    {
      "epoch": 60.06,
      "learning_rate": 0.09399582593987138,
      "loss": 3.3146,
      "step": 37360
    },
    {
      "epoch": 60.1,
      "learning_rate": 0.09399261050900322,
      "loss": 3.3441,
      "step": 37380
    },
    {
      "epoch": 60.13,
      "learning_rate": 0.09398939507813506,
      "loss": 3.3794,
      "step": 37400
    },
    {
      "epoch": 60.16,
      "learning_rate": 0.0939861796472669,
      "loss": 3.4212,
      "step": 37420
    },
    {
      "epoch": 60.19,
      "learning_rate": 0.09398296421639872,
      "loss": 3.3537,
      "step": 37440
    },
    {
      "epoch": 60.23,
      "learning_rate": 0.09397974878553055,
      "loss": 3.3547,
      "step": 37460
    },
    {
      "epoch": 60.26,
      "learning_rate": 0.09397653335466238,
      "loss": 3.4555,
      "step": 37480
    },
    {
      "epoch": 60.29,
      "learning_rate": 0.09397331792379421,
      "loss": 3.3866,
      "step": 37500
    },
    {
      "epoch": 60.32,
      "learning_rate": 0.09397010249292606,
      "loss": 3.4281,
      "step": 37520
    },
    {
      "epoch": 60.35,
      "learning_rate": 0.09396688706205789,
      "loss": 3.3703,
      "step": 37540
    },
    {
      "epoch": 60.39,
      "learning_rate": 0.09396367163118971,
      "loss": 3.3565,
      "step": 37560
    },
    {
      "epoch": 60.42,
      "learning_rate": 0.09396045620032155,
      "loss": 3.4406,
      "step": 37580
    },
    {
      "epoch": 60.45,
      "learning_rate": 0.09395724076945337,
      "loss": 3.478,
      "step": 37600
    },
    {
      "epoch": 60.48,
      "learning_rate": 0.09395402533858521,
      "loss": 3.4176,
      "step": 37620
    },
    {
      "epoch": 60.51,
      "learning_rate": 0.09395080990771705,
      "loss": 3.4014,
      "step": 37640
    },
    {
      "epoch": 60.55,
      "learning_rate": 0.09394759447684888,
      "loss": 3.378,
      "step": 37660
    },
    {
      "epoch": 60.58,
      "learning_rate": 0.09394437904598071,
      "loss": 3.3923,
      "step": 37680
    },
    {
      "epoch": 60.61,
      "learning_rate": 0.09394116361511254,
      "loss": 3.4149,
      "step": 37700
    },
    {
      "epoch": 60.64,
      "learning_rate": 0.09393794818424438,
      "loss": 3.3915,
      "step": 37720
    },
    {
      "epoch": 60.68,
      "learning_rate": 0.09393473275337622,
      "loss": 3.3659,
      "step": 37740
    },
    {
      "epoch": 60.71,
      "learning_rate": 0.09393151732250804,
      "loss": 3.3785,
      "step": 37760
    },
    {
      "epoch": 60.74,
      "learning_rate": 0.09392830189163988,
      "loss": 3.3821,
      "step": 37780
    },
    {
      "epoch": 60.77,
      "learning_rate": 0.0939250864607717,
      "loss": 3.3734,
      "step": 37800
    },
    {
      "epoch": 60.8,
      "learning_rate": 0.09392187102990354,
      "loss": 3.4244,
      "step": 37820
    },
    {
      "epoch": 60.84,
      "learning_rate": 0.09391865559903537,
      "loss": 3.3618,
      "step": 37840
    },
    {
      "epoch": 60.87,
      "learning_rate": 0.0939154401681672,
      "loss": 3.3885,
      "step": 37860
    },
    {
      "epoch": 60.9,
      "learning_rate": 0.09391222473729904,
      "loss": 3.3616,
      "step": 37880
    },
    {
      "epoch": 60.93,
      "learning_rate": 0.09390900930643087,
      "loss": 3.341,
      "step": 37900
    },
    {
      "epoch": 60.96,
      "learning_rate": 0.09390579387556271,
      "loss": 3.3242,
      "step": 37920
    },
    {
      "epoch": 61.0,
      "learning_rate": 0.09390257844469453,
      "loss": 3.3572,
      "step": 37940
    },
    {
      "epoch": 61.0,
      "eval_accuracy": {
        "accuracy": 0.3329705356448729
      },
      "eval_loss": 3.385343074798584,
      "eval_runtime": 2.7607,
      "eval_samples_per_second": 4659.254,
      "eval_steps_per_second": 72.807,
      "step": 37942
    },
    {
      "epoch": 61.03,
      "learning_rate": 0.09389936301382637,
      "loss": 3.3619,
      "step": 37960
    },
    {
      "epoch": 61.06,
      "learning_rate": 0.09389614758295821,
      "loss": 3.3581,
      "step": 37980
    },
    {
      "epoch": 61.09,
      "learning_rate": 0.09389293215209003,
      "loss": 3.3528,
      "step": 38000
    },
    {
      "epoch": 61.13,
      "learning_rate": 0.09388971672122187,
      "loss": 3.3906,
      "step": 38020
    },
    {
      "epoch": 61.16,
      "learning_rate": 0.0938865012903537,
      "loss": 3.3813,
      "step": 38040
    },
    {
      "epoch": 61.19,
      "learning_rate": 0.09388328585948554,
      "loss": 3.3793,
      "step": 38060
    },
    {
      "epoch": 61.22,
      "learning_rate": 0.09388007042861737,
      "loss": 3.363,
      "step": 38080
    },
    {
      "epoch": 61.25,
      "learning_rate": 0.0938768549977492,
      "loss": 3.3824,
      "step": 38100
    },
    {
      "epoch": 61.29,
      "learning_rate": 0.09387363956688104,
      "loss": 3.3748,
      "step": 38120
    },
    {
      "epoch": 61.32,
      "learning_rate": 0.09387042413601286,
      "loss": 3.3844,
      "step": 38140
    },
    {
      "epoch": 61.35,
      "learning_rate": 0.0938672087051447,
      "loss": 3.3914,
      "step": 38160
    },
    {
      "epoch": 61.38,
      "learning_rate": 0.09386399327427654,
      "loss": 3.3892,
      "step": 38180
    },
    {
      "epoch": 61.41,
      "learning_rate": 0.09386077784340836,
      "loss": 3.3652,
      "step": 38200
    },
    {
      "epoch": 61.45,
      "learning_rate": 0.0938575624125402,
      "loss": 3.3875,
      "step": 38220
    },
    {
      "epoch": 61.48,
      "learning_rate": 0.09385434698167203,
      "loss": 3.4178,
      "step": 38240
    },
    {
      "epoch": 61.51,
      "learning_rate": 0.09385113155080387,
      "loss": 3.4151,
      "step": 38260
    },
    {
      "epoch": 61.54,
      "learning_rate": 0.09384791611993569,
      "loss": 3.3868,
      "step": 38280
    },
    {
      "epoch": 61.58,
      "learning_rate": 0.09384470068906753,
      "loss": 3.4178,
      "step": 38300
    },
    {
      "epoch": 61.61,
      "learning_rate": 0.09384148525819937,
      "loss": 3.3718,
      "step": 38320
    },
    {
      "epoch": 61.64,
      "learning_rate": 0.09383826982733119,
      "loss": 3.3256,
      "step": 38340
    },
    {
      "epoch": 61.67,
      "learning_rate": 0.09383521516800644,
      "loss": 3.3282,
      "step": 38360
    },
    {
      "epoch": 61.7,
      "learning_rate": 0.09383199973713827,
      "loss": 3.3716,
      "step": 38380
    },
    {
      "epoch": 61.74,
      "learning_rate": 0.0938287843062701,
      "loss": 3.3748,
      "step": 38400
    },
    {
      "epoch": 61.77,
      "learning_rate": 0.09382556887540193,
      "loss": 3.4553,
      "step": 38420
    },
    {
      "epoch": 61.8,
      "learning_rate": 0.09382235344453377,
      "loss": 3.4041,
      "step": 38440
    },
    {
      "epoch": 61.83,
      "learning_rate": 0.0938191380136656,
      "loss": 3.3846,
      "step": 38460
    },
    {
      "epoch": 61.86,
      "learning_rate": 0.09381592258279743,
      "loss": 3.4346,
      "step": 38480
    },
    {
      "epoch": 61.9,
      "learning_rate": 0.09381270715192927,
      "loss": 3.4752,
      "step": 38500
    },
    {
      "epoch": 61.93,
      "learning_rate": 0.0938094917210611,
      "loss": 3.446,
      "step": 38520
    },
    {
      "epoch": 61.96,
      "learning_rate": 0.09380627629019293,
      "loss": 3.4655,
      "step": 38540
    },
    {
      "epoch": 61.99,
      "learning_rate": 0.09380306085932477,
      "loss": 3.4458,
      "step": 38560
    },
    {
      "epoch": 62.0,
      "eval_accuracy": {
        "accuracy": 0.329549871725103
      },
      "eval_loss": 3.547107219696045,
      "eval_runtime": 2.6326,
      "eval_samples_per_second": 4886.057,
      "eval_steps_per_second": 76.351,
      "step": 38564
    },
    {
      "epoch": 62.03,
      "learning_rate": 0.0937998454284566,
      "loss": 3.4399,
      "step": 38580
    },
    {
      "epoch": 62.06,
      "learning_rate": 0.09379662999758843,
      "loss": 3.3629,
      "step": 38600
    },
    {
      "epoch": 62.09,
      "learning_rate": 0.09379341456672026,
      "loss": 3.3865,
      "step": 38620
    },
    {
      "epoch": 62.12,
      "learning_rate": 0.0937901991358521,
      "loss": 3.3376,
      "step": 38640
    },
    {
      "epoch": 62.15,
      "learning_rate": 0.09378698370498392,
      "loss": 3.3571,
      "step": 38660
    },
    {
      "epoch": 62.19,
      "learning_rate": 0.09378376827411576,
      "loss": 3.3767,
      "step": 38680
    },
    {
      "epoch": 62.22,
      "learning_rate": 0.0937805528432476,
      "loss": 3.3593,
      "step": 38700
    },
    {
      "epoch": 62.25,
      "learning_rate": 0.09377733741237942,
      "loss": 3.3948,
      "step": 38720
    },
    {
      "epoch": 62.28,
      "learning_rate": 0.09377412198151126,
      "loss": 3.3753,
      "step": 38740
    },
    {
      "epoch": 62.32,
      "learning_rate": 0.09377090655064309,
      "loss": 3.3636,
      "step": 38760
    },
    {
      "epoch": 62.35,
      "learning_rate": 0.09376769111977493,
      "loss": 3.4511,
      "step": 38780
    },
    {
      "epoch": 62.38,
      "learning_rate": 0.09376447568890676,
      "loss": 3.422,
      "step": 38800
    },
    {
      "epoch": 62.41,
      "learning_rate": 0.09376126025803859,
      "loss": 3.3918,
      "step": 38820
    },
    {
      "epoch": 62.44,
      "learning_rate": 0.09375804482717043,
      "loss": 3.3402,
      "step": 38840
    },
    {
      "epoch": 62.48,
      "learning_rate": 0.09375482939630225,
      "loss": 3.3285,
      "step": 38860
    },
    {
      "epoch": 62.51,
      "learning_rate": 0.09375161396543409,
      "loss": 3.3696,
      "step": 38880
    },
    {
      "epoch": 62.54,
      "learning_rate": 0.09374839853456593,
      "loss": 3.4388,
      "step": 38900
    },
    {
      "epoch": 62.57,
      "learning_rate": 0.09374518310369775,
      "loss": 3.3768,
      "step": 38920
    },
    {
      "epoch": 62.6,
      "learning_rate": 0.0937419676728296,
      "loss": 3.3858,
      "step": 38940
    },
    {
      "epoch": 62.64,
      "learning_rate": 0.09373875224196142,
      "loss": 3.4074,
      "step": 38960
    },
    {
      "epoch": 62.67,
      "learning_rate": 0.09373553681109326,
      "loss": 3.3881,
      "step": 38980
    },
    {
      "epoch": 62.7,
      "learning_rate": 0.09373232138022508,
      "loss": 3.3738,
      "step": 39000
    },
    {
      "epoch": 62.73,
      "learning_rate": 0.09372910594935692,
      "loss": 3.387,
      "step": 39020
    },
    {
      "epoch": 62.77,
      "learning_rate": 0.09372589051848876,
      "loss": 3.3965,
      "step": 39040
    },
    {
      "epoch": 62.8,
      "learning_rate": 0.09372267508762058,
      "loss": 3.3866,
      "step": 39060
    },
    {
      "epoch": 62.83,
      "learning_rate": 0.09371945965675242,
      "loss": 3.3807,
      "step": 39080
    },
    {
      "epoch": 62.86,
      "learning_rate": 0.09371624422588425,
      "loss": 3.3597,
      "step": 39100
    },
    {
      "epoch": 62.89,
      "learning_rate": 0.09371302879501608,
      "loss": 3.3821,
      "step": 39120
    },
    {
      "epoch": 62.93,
      "learning_rate": 0.09370981336414792,
      "loss": 3.3527,
      "step": 39140
    },
    {
      "epoch": 62.96,
      "learning_rate": 0.09370659793327975,
      "loss": 3.4011,
      "step": 39160
    },
    {
      "epoch": 62.99,
      "learning_rate": 0.09370338250241159,
      "loss": 3.3705,
      "step": 39180
    },
    {
      "epoch": 63.0,
      "eval_accuracy": {
        "accuracy": 0.329549871725103
      },
      "eval_loss": 3.459580659866333,
      "eval_runtime": 2.4998,
      "eval_samples_per_second": 5145.652,
      "eval_steps_per_second": 80.407,
      "step": 39186
    },
    {
      "epoch": 63.02,
      "learning_rate": 0.09370016707154341,
      "loss": 3.394,
      "step": 39200
    },
    {
      "epoch": 63.05,
      "learning_rate": 0.09369695164067524,
      "loss": 3.3254,
      "step": 39220
    },
    {
      "epoch": 63.09,
      "learning_rate": 0.09369373620980709,
      "loss": 3.3163,
      "step": 39240
    },
    {
      "epoch": 63.12,
      "learning_rate": 0.09369052077893891,
      "loss": 3.35,
      "step": 39260
    },
    {
      "epoch": 63.15,
      "learning_rate": 0.09368730534807075,
      "loss": 3.2756,
      "step": 39280
    },
    {
      "epoch": 63.18,
      "learning_rate": 0.09368408991720258,
      "loss": 3.3447,
      "step": 39300
    },
    {
      "epoch": 63.22,
      "learning_rate": 0.0936808744863344,
      "loss": 3.3194,
      "step": 39320
    },
    {
      "epoch": 63.25,
      "learning_rate": 0.09367765905546624,
      "loss": 3.2964,
      "step": 39340
    },
    {
      "epoch": 63.28,
      "learning_rate": 0.09367444362459808,
      "loss": 3.3124,
      "step": 39360
    },
    {
      "epoch": 63.31,
      "learning_rate": 0.09367122819372992,
      "loss": 3.3554,
      "step": 39380
    },
    {
      "epoch": 63.34,
      "learning_rate": 0.09366801276286174,
      "loss": 3.3623,
      "step": 39400
    },
    {
      "epoch": 63.38,
      "learning_rate": 0.09366479733199357,
      "loss": 3.3945,
      "step": 39420
    },
    {
      "epoch": 63.41,
      "learning_rate": 0.0936615819011254,
      "loss": 3.3984,
      "step": 39440
    },
    {
      "epoch": 63.44,
      "learning_rate": 0.09365852724180064,
      "loss": 3.4308,
      "step": 39460
    },
    {
      "epoch": 63.47,
      "learning_rate": 0.09365531181093249,
      "loss": 3.4408,
      "step": 39480
    },
    {
      "epoch": 63.5,
      "learning_rate": 0.09365209638006432,
      "loss": 3.4501,
      "step": 39500
    },
    {
      "epoch": 63.54,
      "learning_rate": 0.09364888094919614,
      "loss": 3.3889,
      "step": 39520
    },
    {
      "epoch": 63.57,
      "learning_rate": 0.09364566551832798,
      "loss": 3.3423,
      "step": 39540
    },
    {
      "epoch": 63.6,
      "learning_rate": 0.0936424500874598,
      "loss": 3.3486,
      "step": 39560
    },
    {
      "epoch": 63.63,
      "learning_rate": 0.09363923465659164,
      "loss": 3.4004,
      "step": 39580
    },
    {
      "epoch": 63.67,
      "learning_rate": 0.09363601922572347,
      "loss": 3.3676,
      "step": 39600
    },
    {
      "epoch": 63.7,
      "learning_rate": 0.09363280379485532,
      "loss": 3.3759,
      "step": 39620
    },
    {
      "epoch": 63.73,
      "learning_rate": 0.09362958836398715,
      "loss": 3.3652,
      "step": 39640
    },
    {
      "epoch": 63.76,
      "learning_rate": 0.09362637293311897,
      "loss": 3.3941,
      "step": 39660
    },
    {
      "epoch": 63.79,
      "learning_rate": 0.09362315750225081,
      "loss": 3.3583,
      "step": 39680
    },
    {
      "epoch": 63.83,
      "learning_rate": 0.09361994207138263,
      "loss": 3.3049,
      "step": 39700
    },
    {
      "epoch": 63.86,
      "learning_rate": 0.09361672664051449,
      "loss": 3.3714,
      "step": 39720
    },
    {
      "epoch": 63.89,
      "learning_rate": 0.09361351120964631,
      "loss": 3.4366,
      "step": 39740
    },
    {
      "epoch": 63.92,
      "learning_rate": 0.09361029577877814,
      "loss": 3.333,
      "step": 39760
    },
    {
      "epoch": 63.95,
      "learning_rate": 0.09360708034790997,
      "loss": 3.3112,
      "step": 39780
    },
    {
      "epoch": 63.99,
      "learning_rate": 0.0936038649170418,
      "loss": 3.3947,
      "step": 39800
    },
    {
      "epoch": 64.0,
      "eval_accuracy": {
        "accuracy": 0.3356915183083262
      },
      "eval_loss": 3.4569790363311768,
      "eval_runtime": 2.5566,
      "eval_samples_per_second": 5031.344,
      "eval_steps_per_second": 78.621,
      "step": 39808
    },
    {
      "epoch": 64.02,
      "learning_rate": 0.09360064948617365,
      "loss": 3.3688,
      "step": 39820
    },
    {
      "epoch": 64.05,
      "learning_rate": 0.09359743405530548,
      "loss": 3.3098,
      "step": 39840
    },
    {
      "epoch": 64.08,
      "learning_rate": 0.0935942186244373,
      "loss": 3.3483,
      "step": 39860
    },
    {
      "epoch": 64.12,
      "learning_rate": 0.09359100319356914,
      "loss": 3.3633,
      "step": 39880
    },
    {
      "epoch": 64.15,
      "learning_rate": 0.09358778776270096,
      "loss": 3.3829,
      "step": 39900
    },
    {
      "epoch": 64.18,
      "learning_rate": 0.0935845723318328,
      "loss": 3.3229,
      "step": 39920
    },
    {
      "epoch": 64.21,
      "learning_rate": 0.09358135690096463,
      "loss": 3.3479,
      "step": 39940
    },
    {
      "epoch": 64.24,
      "learning_rate": 0.09357814147009647,
      "loss": 3.3518,
      "step": 39960
    },
    {
      "epoch": 64.28,
      "learning_rate": 0.0935749260392283,
      "loss": 3.3447,
      "step": 39980
    },
    {
      "epoch": 64.31,
      "learning_rate": 0.09357171060836013,
      "loss": 3.3427,
      "step": 40000
    },
    {
      "epoch": 64.34,
      "learning_rate": 0.09356849517749197,
      "loss": 3.3317,
      "step": 40020
    },
    {
      "epoch": 64.37,
      "learning_rate": 0.09356527974662379,
      "loss": 3.3873,
      "step": 40040
    },
    {
      "epoch": 64.41,
      "learning_rate": 0.09356206431575563,
      "loss": 3.3782,
      "step": 40060
    },
    {
      "epoch": 64.44,
      "learning_rate": 0.09355884888488747,
      "loss": 3.3454,
      "step": 40080
    },
    {
      "epoch": 64.47,
      "learning_rate": 0.0935556334540193,
      "loss": 3.345,
      "step": 40100
    },
    {
      "epoch": 64.5,
      "learning_rate": 0.09355241802315113,
      "loss": 3.3374,
      "step": 40120
    },
    {
      "epoch": 64.53,
      "learning_rate": 0.09354920259228296,
      "loss": 3.3738,
      "step": 40140
    },
    {
      "epoch": 64.57,
      "learning_rate": 0.0935459871614148,
      "loss": 3.3688,
      "step": 40160
    },
    {
      "epoch": 64.6,
      "learning_rate": 0.09354277173054663,
      "loss": 3.3477,
      "step": 40180
    },
    {
      "epoch": 64.63,
      "learning_rate": 0.09353955629967846,
      "loss": 3.4044,
      "step": 40200
    },
    {
      "epoch": 64.66,
      "learning_rate": 0.0935363408688103,
      "loss": 3.3881,
      "step": 40220
    },
    {
      "epoch": 64.69,
      "learning_rate": 0.09353312543794212,
      "loss": 3.3359,
      "step": 40240
    },
    {
      "epoch": 64.73,
      "learning_rate": 0.09352991000707396,
      "loss": 3.3306,
      "step": 40260
    },
    {
      "epoch": 64.76,
      "learning_rate": 0.09352669457620578,
      "loss": 3.344,
      "step": 40280
    },
    {
      "epoch": 64.79,
      "learning_rate": 0.09352347914533762,
      "loss": 3.3504,
      "step": 40300
    },
    {
      "epoch": 64.82,
      "learning_rate": 0.09352026371446946,
      "loss": 3.3453,
      "step": 40320
    },
    {
      "epoch": 64.86,
      "learning_rate": 0.09351704828360129,
      "loss": 3.4128,
      "step": 40340
    },
    {
      "epoch": 64.89,
      "learning_rate": 0.09351383285273313,
      "loss": 3.3924,
      "step": 40360
    },
    {
      "epoch": 64.92,
      "learning_rate": 0.09351061742186495,
      "loss": 3.333,
      "step": 40380
    },
    {
      "epoch": 64.95,
      "learning_rate": 0.09350740199099679,
      "loss": 3.3528,
      "step": 40400
    },
    {
      "epoch": 64.98,
      "learning_rate": 0.09350418656012863,
      "loss": 3.3962,
      "step": 40420
    },
    {
      "epoch": 65.0,
      "eval_accuracy": {
        "accuracy": 0.334369898157506
      },
      "eval_loss": 3.5220017433166504,
      "eval_runtime": 2.8726,
      "eval_samples_per_second": 4477.758,
      "eval_steps_per_second": 69.97,
      "step": 40430
    },
    {
      "epoch": 65.02,
      "learning_rate": 0.09350097112926045,
      "loss": 3.36,
      "step": 40440
    },
    {
      "epoch": 65.05,
      "learning_rate": 0.09349775569839229,
      "loss": 3.371,
      "step": 40460
    },
    {
      "epoch": 65.08,
      "learning_rate": 0.09349454026752411,
      "loss": 3.3348,
      "step": 40480
    },
    {
      "epoch": 65.11,
      "learning_rate": 0.09349132483665595,
      "loss": 3.3388,
      "step": 40500
    },
    {
      "epoch": 65.14,
      "learning_rate": 0.09348810940578779,
      "loss": 3.3056,
      "step": 40520
    },
    {
      "epoch": 65.18,
      "learning_rate": 0.09348489397491962,
      "loss": 3.3505,
      "step": 40540
    },
    {
      "epoch": 65.21,
      "learning_rate": 0.09348167854405146,
      "loss": 3.3665,
      "step": 40560
    },
    {
      "epoch": 65.24,
      "learning_rate": 0.09347846311318328,
      "loss": 3.3725,
      "step": 40580
    },
    {
      "epoch": 65.27,
      "learning_rate": 0.09347524768231512,
      "loss": 3.3923,
      "step": 40600
    },
    {
      "epoch": 65.31,
      "learning_rate": 0.09347203225144694,
      "loss": 3.3442,
      "step": 40620
    },
    {
      "epoch": 65.34,
      "learning_rate": 0.09346881682057878,
      "loss": 3.3281,
      "step": 40640
    },
    {
      "epoch": 65.37,
      "learning_rate": 0.09346560138971062,
      "loss": 3.3259,
      "step": 40660
    },
    {
      "epoch": 65.4,
      "learning_rate": 0.09346238595884244,
      "loss": 3.3858,
      "step": 40680
    },
    {
      "epoch": 65.43,
      "learning_rate": 0.09345917052797428,
      "loss": 3.3909,
      "step": 40700
    },
    {
      "epoch": 65.47,
      "learning_rate": 0.09345595509710611,
      "loss": 3.3501,
      "step": 40720
    },
    {
      "epoch": 65.5,
      "learning_rate": 0.09345273966623795,
      "loss": 3.3666,
      "step": 40740
    },
    {
      "epoch": 65.53,
      "learning_rate": 0.09344952423536979,
      "loss": 3.3904,
      "step": 40760
    },
    {
      "epoch": 65.56,
      "learning_rate": 0.09344630880450161,
      "loss": 3.2889,
      "step": 40780
    },
    {
      "epoch": 65.59,
      "learning_rate": 0.09344309337363345,
      "loss": 3.339,
      "step": 40800
    },
    {
      "epoch": 65.63,
      "learning_rate": 0.09343987794276527,
      "loss": 3.3585,
      "step": 40820
    },
    {
      "epoch": 65.66,
      "learning_rate": 0.09343666251189711,
      "loss": 3.3451,
      "step": 40840
    },
    {
      "epoch": 65.69,
      "learning_rate": 0.09343344708102895,
      "loss": 3.3564,
      "step": 40860
    },
    {
      "epoch": 65.72,
      "learning_rate": 0.09343023165016077,
      "loss": 3.3816,
      "step": 40880
    },
    {
      "epoch": 65.76,
      "learning_rate": 0.09342701621929261,
      "loss": 3.383,
      "step": 40900
    },
    {
      "epoch": 65.79,
      "learning_rate": 0.09342380078842444,
      "loss": 3.3443,
      "step": 40920
    },
    {
      "epoch": 65.82,
      "learning_rate": 0.09342058535755628,
      "loss": 3.3298,
      "step": 40940
    },
    {
      "epoch": 65.85,
      "learning_rate": 0.09341736992668812,
      "loss": 3.4136,
      "step": 40960
    },
    {
      "epoch": 65.88,
      "learning_rate": 0.09341415449581994,
      "loss": 3.4075,
      "step": 40980
    },
    {
      "epoch": 65.92,
      "learning_rate": 0.09341093906495178,
      "loss": 3.3877,
      "step": 41000
    },
    {
      "epoch": 65.95,
      "learning_rate": 0.0934077236340836,
      "loss": 3.3707,
      "step": 41020
    },
    {
      "epoch": 65.98,
      "learning_rate": 0.09340450820321544,
      "loss": 3.3792,
      "step": 41040
    },
    {
      "epoch": 66.0,
      "eval_accuracy": {
        "accuracy": 0.3412112259970458
      },
      "eval_loss": 3.4198849201202393,
      "eval_runtime": 2.7395,
      "eval_samples_per_second": 4695.46,
      "eval_steps_per_second": 73.372,
      "step": 41052
    },
    {
      "epoch": 66.01,
      "learning_rate": 0.09340129277234727,
      "loss": 3.374,
      "step": 41060
    },
    {
      "epoch": 66.05,
      "learning_rate": 0.0933980773414791,
      "loss": 3.3662,
      "step": 41080
    },
    {
      "epoch": 66.08,
      "learning_rate": 0.09339486191061094,
      "loss": 3.3129,
      "step": 41100
    },
    {
      "epoch": 66.11,
      "learning_rate": 0.09339164647974277,
      "loss": 3.3079,
      "step": 41120
    },
    {
      "epoch": 66.14,
      "learning_rate": 0.0933884310488746,
      "loss": 3.3171,
      "step": 41140
    },
    {
      "epoch": 66.17,
      "learning_rate": 0.09338521561800643,
      "loss": 3.3257,
      "step": 41160
    },
    {
      "epoch": 66.21,
      "learning_rate": 0.09338200018713827,
      "loss": 3.3838,
      "step": 41180
    },
    {
      "epoch": 66.24,
      "learning_rate": 0.09337878475627011,
      "loss": 3.3516,
      "step": 41200
    },
    {
      "epoch": 66.27,
      "learning_rate": 0.09337556932540193,
      "loss": 3.3855,
      "step": 41220
    },
    {
      "epoch": 66.3,
      "learning_rate": 0.09337235389453377,
      "loss": 3.345,
      "step": 41240
    },
    {
      "epoch": 66.33,
      "learning_rate": 0.0933691384636656,
      "loss": 3.3313,
      "step": 41260
    },
    {
      "epoch": 66.37,
      "learning_rate": 0.09336592303279743,
      "loss": 3.3236,
      "step": 41280
    },
    {
      "epoch": 66.4,
      "learning_rate": 0.09336270760192927,
      "loss": 3.2921,
      "step": 41300
    },
    {
      "epoch": 66.43,
      "learning_rate": 0.0933594921710611,
      "loss": 3.4086,
      "step": 41320
    },
    {
      "epoch": 66.46,
      "learning_rate": 0.09335627674019294,
      "loss": 3.3636,
      "step": 41340
    },
    {
      "epoch": 66.5,
      "learning_rate": 0.09335306130932476,
      "loss": 3.4314,
      "step": 41360
    },
    {
      "epoch": 66.53,
      "learning_rate": 0.0933498458784566,
      "loss": 3.4386,
      "step": 41380
    },
    {
      "epoch": 66.56,
      "learning_rate": 0.09334663044758842,
      "loss": 3.3629,
      "step": 41400
    },
    {
      "epoch": 66.59,
      "learning_rate": 0.09334341501672026,
      "loss": 3.3214,
      "step": 41420
    },
    {
      "epoch": 66.62,
      "learning_rate": 0.0933401995858521,
      "loss": 3.3797,
      "step": 41440
    },
    {
      "epoch": 66.66,
      "learning_rate": 0.09333698415498393,
      "loss": 3.3877,
      "step": 41460
    },
    {
      "epoch": 66.69,
      "learning_rate": 0.09333376872411576,
      "loss": 3.3859,
      "step": 41480
    },
    {
      "epoch": 66.72,
      "learning_rate": 0.09333055329324759,
      "loss": 3.3634,
      "step": 41500
    },
    {
      "epoch": 66.75,
      "learning_rate": 0.09332733786237943,
      "loss": 3.333,
      "step": 41520
    },
    {
      "epoch": 66.78,
      "learning_rate": 0.09332412243151127,
      "loss": 3.3699,
      "step": 41540
    },
    {
      "epoch": 66.82,
      "learning_rate": 0.09332090700064309,
      "loss": 3.351,
      "step": 41560
    },
    {
      "epoch": 66.85,
      "learning_rate": 0.09331769156977493,
      "loss": 3.3305,
      "step": 41580
    },
    {
      "epoch": 66.88,
      "learning_rate": 0.09331447613890675,
      "loss": 3.3286,
      "step": 41600
    },
    {
      "epoch": 66.91,
      "learning_rate": 0.09331126070803858,
      "loss": 3.3844,
      "step": 41620
    },
    {
      "epoch": 66.95,
      "learning_rate": 0.09330804527717043,
      "loss": 3.3994,
      "step": 41640
    },
    {
      "epoch": 66.98,
      "learning_rate": 0.09330482984630226,
      "loss": 3.3786,
      "step": 41660
    },
    {
      "epoch": 67.0,
      "eval_accuracy": {
        "accuracy": 0.33382570162481534
      },
      "eval_loss": 3.542678117752075,
      "eval_runtime": 2.9137,
      "eval_samples_per_second": 4414.68,
      "eval_steps_per_second": 68.985,
      "step": 41674
    },
    {
      "epoch": 67.01,
      "learning_rate": 0.0933016144154341,
      "loss": 3.3828,
      "step": 41680
    },
    {
      "epoch": 67.04,
      "learning_rate": 0.09329839898456592,
      "loss": 3.3907,
      "step": 41700
    },
    {
      "epoch": 67.07,
      "learning_rate": 0.09329518355369776,
      "loss": 3.3479,
      "step": 41720
    },
    {
      "epoch": 67.11,
      "learning_rate": 0.09329196812282958,
      "loss": 3.3506,
      "step": 41740
    },
    {
      "epoch": 67.14,
      "learning_rate": 0.09328875269196142,
      "loss": 3.3225,
      "step": 41760
    },
    {
      "epoch": 67.17,
      "learning_rate": 0.09328553726109326,
      "loss": 3.3185,
      "step": 41780
    },
    {
      "epoch": 67.2,
      "learning_rate": 0.09328232183022508,
      "loss": 3.329,
      "step": 41800
    },
    {
      "epoch": 67.23,
      "learning_rate": 0.09327910639935692,
      "loss": 3.3475,
      "step": 41820
    },
    {
      "epoch": 67.27,
      "learning_rate": 0.09327589096848875,
      "loss": 3.3405,
      "step": 41840
    },
    {
      "epoch": 67.3,
      "learning_rate": 0.09327267553762059,
      "loss": 3.3528,
      "step": 41860
    },
    {
      "epoch": 67.33,
      "learning_rate": 0.09326946010675242,
      "loss": 3.2998,
      "step": 41880
    },
    {
      "epoch": 67.36,
      "learning_rate": 0.09326624467588425,
      "loss": 3.3603,
      "step": 41900
    },
    {
      "epoch": 67.4,
      "learning_rate": 0.09326302924501609,
      "loss": 3.3113,
      "step": 41920
    },
    {
      "epoch": 67.43,
      "learning_rate": 0.09325981381414791,
      "loss": 3.3516,
      "step": 41940
    },
    {
      "epoch": 67.46,
      "learning_rate": 0.09325659838327974,
      "loss": 3.3664,
      "step": 41960
    },
    {
      "epoch": 67.49,
      "learning_rate": 0.09325338295241159,
      "loss": 3.29,
      "step": 41980
    },
    {
      "epoch": 67.52,
      "learning_rate": 0.09325016752154341,
      "loss": 3.3427,
      "step": 42000
    },
    {
      "epoch": 67.56,
      "learning_rate": 0.09324695209067525,
      "loss": 3.3652,
      "step": 42020
    },
    {
      "epoch": 67.59,
      "learning_rate": 0.09324373665980708,
      "loss": 3.2948,
      "step": 42040
    },
    {
      "epoch": 67.62,
      "learning_rate": 0.0932405212289389,
      "loss": 3.3111,
      "step": 42060
    },
    {
      "epoch": 67.65,
      "learning_rate": 0.09323730579807074,
      "loss": 3.3208,
      "step": 42080
    },
    {
      "epoch": 67.68,
      "learning_rate": 0.09323409036720258,
      "loss": 3.3244,
      "step": 42100
    },
    {
      "epoch": 67.72,
      "learning_rate": 0.09323087493633442,
      "loss": 3.3572,
      "step": 42120
    },
    {
      "epoch": 67.75,
      "learning_rate": 0.09322765950546624,
      "loss": 3.3727,
      "step": 42140
    },
    {
      "epoch": 67.78,
      "learning_rate": 0.09322444407459807,
      "loss": 3.3434,
      "step": 42160
    },
    {
      "epoch": 67.81,
      "learning_rate": 0.0932212286437299,
      "loss": 3.3354,
      "step": 42180
    },
    {
      "epoch": 67.85,
      "learning_rate": 0.09321801321286174,
      "loss": 3.3554,
      "step": 42200
    },
    {
      "epoch": 67.88,
      "learning_rate": 0.09321479778199358,
      "loss": 3.3217,
      "step": 42220
    },
    {
      "epoch": 67.91,
      "learning_rate": 0.09321158235112541,
      "loss": 3.3379,
      "step": 42240
    },
    {
      "epoch": 67.94,
      "learning_rate": 0.09320836692025723,
      "loss": 3.3648,
      "step": 42260
    },
    {
      "epoch": 67.97,
      "learning_rate": 0.09320515148938907,
      "loss": 3.3722,
      "step": 42280
    },
    {
      "epoch": 68.0,
      "eval_accuracy": {
        "accuracy": 0.33164891549405273
      },
      "eval_loss": 3.434062957763672,
      "eval_runtime": 2.8907,
      "eval_samples_per_second": 4449.783,
      "eval_steps_per_second": 69.533,
      "step": 42296
    },
    {
      "epoch": 68.01,
      "learning_rate": 0.09320193605852091,
      "loss": 3.3347,
      "step": 42300
    },
    {
      "epoch": 68.04,
      "learning_rate": 0.09319872062765275,
      "loss": 3.3249,
      "step": 42320
    },
    {
      "epoch": 68.07,
      "learning_rate": 0.09319550519678457,
      "loss": 3.3322,
      "step": 42340
    },
    {
      "epoch": 68.1,
      "learning_rate": 0.09319228976591641,
      "loss": 3.404,
      "step": 42360
    },
    {
      "epoch": 68.14,
      "learning_rate": 0.09318907433504824,
      "loss": 3.3155,
      "step": 42380
    },
    {
      "epoch": 68.17,
      "learning_rate": 0.09318585890418006,
      "loss": 3.3391,
      "step": 42400
    },
    {
      "epoch": 68.2,
      "learning_rate": 0.0931826434733119,
      "loss": 3.3404,
      "step": 42420
    },
    {
      "epoch": 68.23,
      "learning_rate": 0.09317942804244374,
      "loss": 3.3681,
      "step": 42440
    },
    {
      "epoch": 68.26,
      "learning_rate": 0.09317621261157558,
      "loss": 3.3084,
      "step": 42460
    },
    {
      "epoch": 68.3,
      "learning_rate": 0.0931729971807074,
      "loss": 3.3183,
      "step": 42480
    },
    {
      "epoch": 68.33,
      "learning_rate": 0.09316978174983923,
      "loss": 3.2973,
      "step": 42500
    },
    {
      "epoch": 68.36,
      "learning_rate": 0.09316656631897106,
      "loss": 3.3253,
      "step": 42520
    },
    {
      "epoch": 68.39,
      "learning_rate": 0.0931633508881029,
      "loss": 3.3428,
      "step": 42540
    },
    {
      "epoch": 68.42,
      "learning_rate": 0.09316013545723474,
      "loss": 3.3445,
      "step": 42560
    },
    {
      "epoch": 68.46,
      "learning_rate": 0.09315692002636657,
      "loss": 3.3693,
      "step": 42580
    },
    {
      "epoch": 68.49,
      "learning_rate": 0.09315370459549839,
      "loss": 3.3126,
      "step": 42600
    },
    {
      "epoch": 68.52,
      "learning_rate": 0.09315048916463023,
      "loss": 3.3122,
      "step": 42620
    },
    {
      "epoch": 68.55,
      "learning_rate": 0.09314727373376207,
      "loss": 3.3033,
      "step": 42640
    },
    {
      "epoch": 68.59,
      "learning_rate": 0.0931440583028939,
      "loss": 3.3655,
      "step": 42660
    },
    {
      "epoch": 68.62,
      "learning_rate": 0.09314084287202573,
      "loss": 3.3418,
      "step": 42680
    },
    {
      "epoch": 68.65,
      "learning_rate": 0.09313762744115756,
      "loss": 3.3728,
      "step": 42700
    },
    {
      "epoch": 68.68,
      "learning_rate": 0.0931344120102894,
      "loss": 3.3701,
      "step": 42720
    },
    {
      "epoch": 68.71,
      "learning_rate": 0.09313119657942122,
      "loss": 3.3791,
      "step": 42740
    },
    {
      "epoch": 68.75,
      "learning_rate": 0.09312798114855306,
      "loss": 3.3545,
      "step": 42760
    },
    {
      "epoch": 68.78,
      "learning_rate": 0.0931247657176849,
      "loss": 3.3103,
      "step": 42780
    },
    {
      "epoch": 68.81,
      "learning_rate": 0.09312155028681672,
      "loss": 3.3232,
      "step": 42800
    },
    {
      "epoch": 68.84,
      "learning_rate": 0.09311833485594856,
      "loss": 3.3878,
      "step": 42820
    },
    {
      "epoch": 68.87,
      "learning_rate": 0.09311511942508038,
      "loss": 3.34,
      "step": 42840
    },
    {
      "epoch": 68.91,
      "learning_rate": 0.09311190399421222,
      "loss": 3.3479,
      "step": 42860
    },
    {
      "epoch": 68.94,
      "learning_rate": 0.09310868856334406,
      "loss": 3.3367,
      "step": 42880
    },
    {
      "epoch": 68.97,
      "learning_rate": 0.09310547313247589,
      "loss": 3.368,
      "step": 42900
    },
    {
      "epoch": 69.0,
      "eval_accuracy": {
        "accuracy": 0.33351473217756356
      },
      "eval_loss": 3.417401075363159,
      "eval_runtime": 2.9805,
      "eval_samples_per_second": 4315.732,
      "eval_steps_per_second": 67.439,
      "step": 42918
    },
    {
      "epoch": 69.0,
      "learning_rate": 0.09310225770160772,
      "loss": 3.2973,
      "step": 42920
    },
    {
      "epoch": 69.04,
      "learning_rate": 0.09309904227073955,
      "loss": 3.3533,
      "step": 42940
    },
    {
      "epoch": 69.07,
      "learning_rate": 0.09309582683987139,
      "loss": 3.3731,
      "step": 42960
    },
    {
      "epoch": 69.1,
      "learning_rate": 0.09309261140900323,
      "loss": 3.2953,
      "step": 42980
    },
    {
      "epoch": 69.13,
      "learning_rate": 0.09308939597813506,
      "loss": 3.3041,
      "step": 43000
    },
    {
      "epoch": 69.16,
      "learning_rate": 0.09308618054726689,
      "loss": 3.2814,
      "step": 43020
    },
    {
      "epoch": 69.2,
      "learning_rate": 0.09308296511639871,
      "loss": 3.2926,
      "step": 43040
    },
    {
      "epoch": 69.23,
      "learning_rate": 0.09307974968553055,
      "loss": 3.2788,
      "step": 43060
    },
    {
      "epoch": 69.26,
      "learning_rate": 0.09307653425466238,
      "loss": 3.3318,
      "step": 43080
    },
    {
      "epoch": 69.29,
      "learning_rate": 0.09307331882379422,
      "loss": 3.3716,
      "step": 43100
    },
    {
      "epoch": 69.32,
      "learning_rate": 0.09307010339292605,
      "loss": 3.3592,
      "step": 43120
    },
    {
      "epoch": 69.36,
      "learning_rate": 0.09306688796205788,
      "loss": 3.3833,
      "step": 43140
    },
    {
      "epoch": 69.39,
      "learning_rate": 0.09306367253118972,
      "loss": 3.3534,
      "step": 43160
    },
    {
      "epoch": 69.42,
      "learning_rate": 0.09306045710032154,
      "loss": 3.3535,
      "step": 43180
    },
    {
      "epoch": 69.45,
      "learning_rate": 0.09305724166945338,
      "loss": 3.362,
      "step": 43200
    },
    {
      "epoch": 69.49,
      "learning_rate": 0.09305402623858522,
      "loss": 3.2778,
      "step": 43220
    },
    {
      "epoch": 69.52,
      "learning_rate": 0.09305081080771704,
      "loss": 3.2916,
      "step": 43240
    },
    {
      "epoch": 69.55,
      "learning_rate": 0.09304759537684888,
      "loss": 3.2998,
      "step": 43260
    },
    {
      "epoch": 69.58,
      "learning_rate": 0.0930443799459807,
      "loss": 3.2785,
      "step": 43280
    },
    {
      "epoch": 69.61,
      "learning_rate": 0.09304116451511255,
      "loss": 3.3092,
      "step": 43300
    },
    {
      "epoch": 69.65,
      "learning_rate": 0.09303794908424438,
      "loss": 3.3517,
      "step": 43320
    },
    {
      "epoch": 69.68,
      "learning_rate": 0.09303473365337621,
      "loss": 3.3398,
      "step": 43340
    },
    {
      "epoch": 69.71,
      "learning_rate": 0.09303151822250805,
      "loss": 3.321,
      "step": 43360
    },
    {
      "epoch": 69.74,
      "learning_rate": 0.09302830279163987,
      "loss": 3.3267,
      "step": 43380
    },
    {
      "epoch": 69.77,
      "learning_rate": 0.09302508736077171,
      "loss": 3.3377,
      "step": 43400
    },
    {
      "epoch": 69.81,
      "learning_rate": 0.09302187192990354,
      "loss": 3.3502,
      "step": 43420
    },
    {
      "epoch": 69.84,
      "learning_rate": 0.09301865649903537,
      "loss": 3.3297,
      "step": 43440
    },
    {
      "epoch": 69.87,
      "learning_rate": 0.09301544106816721,
      "loss": 3.3428,
      "step": 43460
    },
    {
      "epoch": 69.9,
      "learning_rate": 0.09301222563729904,
      "loss": 3.3641,
      "step": 43480
    },
    {
      "epoch": 69.94,
      "learning_rate": 0.09300901020643088,
      "loss": 3.3578,
      "step": 43500
    },
    {
      "epoch": 69.97,
      "learning_rate": 0.0930057947755627,
      "loss": 3.3732,
      "step": 43520
    },
    {
      "epoch": 70.0,
      "learning_rate": 0.09300257934469454,
      "loss": 3.3198,
      "step": 43540
    },
    {
      "epoch": 70.0,
      "eval_accuracy": {
        "accuracy": 0.33825701624815363
      },
      "eval_loss": 3.376837968826294,
      "eval_runtime": 2.7032,
      "eval_samples_per_second": 4758.485,
      "eval_steps_per_second": 74.357,
      "step": 43540
    },
    {
      "epoch": 70.03,
      "learning_rate": 0.09299952468536977,
      "loss": 3.3338,
      "step": 43560
    },
    {
      "epoch": 70.06,
      "learning_rate": 0.09299630925450161,
      "loss": 3.3511,
      "step": 43580
    },
    {
      "epoch": 70.1,
      "learning_rate": 0.09299309382363345,
      "loss": 3.3532,
      "step": 43600
    },
    {
      "epoch": 70.13,
      "learning_rate": 0.09298987839276528,
      "loss": 3.3425,
      "step": 43620
    },
    {
      "epoch": 70.16,
      "learning_rate": 0.09298666296189712,
      "loss": 3.3302,
      "step": 43640
    },
    {
      "epoch": 70.19,
      "learning_rate": 0.09298344753102894,
      "loss": 3.3205,
      "step": 43660
    },
    {
      "epoch": 70.23,
      "learning_rate": 0.09298023210016078,
      "loss": 3.297,
      "step": 43680
    },
    {
      "epoch": 70.26,
      "learning_rate": 0.09297701666929262,
      "loss": 3.3652,
      "step": 43700
    },
    {
      "epoch": 70.29,
      "learning_rate": 0.09297380123842444,
      "loss": 3.3705,
      "step": 43720
    },
    {
      "epoch": 70.32,
      "learning_rate": 0.09297058580755628,
      "loss": 3.3109,
      "step": 43740
    },
    {
      "epoch": 70.35,
      "learning_rate": 0.0929673703766881,
      "loss": 3.3499,
      "step": 43760
    },
    {
      "epoch": 70.39,
      "learning_rate": 0.09296415494581994,
      "loss": 3.3264,
      "step": 43780
    },
    {
      "epoch": 70.42,
      "learning_rate": 0.09296093951495177,
      "loss": 3.3707,
      "step": 43800
    },
    {
      "epoch": 70.45,
      "learning_rate": 0.0929577240840836,
      "loss": 3.3296,
      "step": 43820
    },
    {
      "epoch": 70.48,
      "learning_rate": 0.09295450865321545,
      "loss": 3.2582,
      "step": 43840
    },
    {
      "epoch": 70.51,
      "learning_rate": 0.09295129322234727,
      "loss": 3.314,
      "step": 43860
    },
    {
      "epoch": 70.55,
      "learning_rate": 0.09294807779147911,
      "loss": 3.3107,
      "step": 43880
    },
    {
      "epoch": 70.58,
      "learning_rate": 0.09294486236061093,
      "loss": 3.3141,
      "step": 43900
    },
    {
      "epoch": 70.61,
      "learning_rate": 0.09294164692974277,
      "loss": 3.3455,
      "step": 43920
    },
    {
      "epoch": 70.64,
      "learning_rate": 0.09293843149887461,
      "loss": 3.3198,
      "step": 43940
    },
    {
      "epoch": 70.68,
      "learning_rate": 0.09293521606800643,
      "loss": 3.269,
      "step": 43960
    },
    {
      "epoch": 70.71,
      "learning_rate": 0.09293200063713827,
      "loss": 3.3111,
      "step": 43980
    },
    {
      "epoch": 70.74,
      "learning_rate": 0.0929287852062701,
      "loss": 3.345,
      "step": 44000
    },
    {
      "epoch": 70.77,
      "learning_rate": 0.09292556977540194,
      "loss": 3.3439,
      "step": 44020
    },
    {
      "epoch": 70.8,
      "learning_rate": 0.09292235434453378,
      "loss": 3.3833,
      "step": 44040
    },
    {
      "epoch": 70.84,
      "learning_rate": 0.0929191389136656,
      "loss": 3.3523,
      "step": 44060
    },
    {
      "epoch": 70.87,
      "learning_rate": 0.09291592348279744,
      "loss": 3.2906,
      "step": 44080
    },
    {
      "epoch": 70.9,
      "learning_rate": 0.09291270805192926,
      "loss": 3.3137,
      "step": 44100
    },
    {
      "epoch": 70.93,
      "learning_rate": 0.0929094926210611,
      "loss": 3.3056,
      "step": 44120
    },
    {
      "epoch": 70.96,
      "learning_rate": 0.09290627719019293,
      "loss": 3.3063,
      "step": 44140
    },
    {
      "epoch": 71.0,
      "learning_rate": 0.09290306175932476,
      "loss": 3.3233,
      "step": 44160
    },
    {
      "epoch": 71.0,
      "eval_accuracy": {
        "accuracy": 0.34338801212780845
      },
      "eval_loss": 3.392223358154297,
      "eval_runtime": 2.6448,
      "eval_samples_per_second": 4863.431,
      "eval_steps_per_second": 75.997,
      "step": 44162
    },
    {
      "epoch": 71.03,
      "learning_rate": 0.0928998463284566,
      "loss": 3.3183,
      "step": 44180
    },
    {
      "epoch": 71.06,
      "learning_rate": 0.09289663089758843,
      "loss": 3.3413,
      "step": 44200
    },
    {
      "epoch": 71.09,
      "learning_rate": 0.09289341546672027,
      "loss": 3.3409,
      "step": 44220
    },
    {
      "epoch": 71.13,
      "learning_rate": 0.09289020003585209,
      "loss": 3.2996,
      "step": 44240
    },
    {
      "epoch": 71.16,
      "learning_rate": 0.09288698460498393,
      "loss": 3.3335,
      "step": 44260
    },
    {
      "epoch": 71.19,
      "learning_rate": 0.09288376917411577,
      "loss": 3.2779,
      "step": 44280
    },
    {
      "epoch": 71.22,
      "learning_rate": 0.09288055374324759,
      "loss": 3.3009,
      "step": 44300
    },
    {
      "epoch": 71.25,
      "learning_rate": 0.09287733831237943,
      "loss": 3.3225,
      "step": 44320
    },
    {
      "epoch": 71.29,
      "learning_rate": 0.09287412288151126,
      "loss": 3.3508,
      "step": 44340
    },
    {
      "epoch": 71.32,
      "learning_rate": 0.09287090745064308,
      "loss": 3.3343,
      "step": 44360
    },
    {
      "epoch": 71.35,
      "learning_rate": 0.09286769201977493,
      "loss": 3.3342,
      "step": 44380
    },
    {
      "epoch": 71.38,
      "learning_rate": 0.09286447658890676,
      "loss": 3.283,
      "step": 44400
    },
    {
      "epoch": 71.41,
      "learning_rate": 0.0928612611580386,
      "loss": 3.2918,
      "step": 44420
    },
    {
      "epoch": 71.45,
      "learning_rate": 0.09285804572717042,
      "loss": 3.3418,
      "step": 44440
    },
    {
      "epoch": 71.48,
      "learning_rate": 0.09285483029630225,
      "loss": 3.3997,
      "step": 44460
    },
    {
      "epoch": 71.51,
      "learning_rate": 0.09285161486543408,
      "loss": 3.3904,
      "step": 44480
    },
    {
      "epoch": 71.54,
      "learning_rate": 0.09284839943456592,
      "loss": 3.3494,
      "step": 44500
    },
    {
      "epoch": 71.58,
      "learning_rate": 0.09284518400369776,
      "loss": 3.3489,
      "step": 44520
    },
    {
      "epoch": 71.61,
      "learning_rate": 0.09284196857282959,
      "loss": 3.3354,
      "step": 44540
    },
    {
      "epoch": 71.64,
      "learning_rate": 0.09283875314196142,
      "loss": 3.3463,
      "step": 44560
    },
    {
      "epoch": 71.67,
      "learning_rate": 0.09283553771109325,
      "loss": 3.3424,
      "step": 44580
    },
    {
      "epoch": 71.7,
      "learning_rate": 0.09283232228022509,
      "loss": 3.3161,
      "step": 44600
    },
    {
      "epoch": 71.74,
      "learning_rate": 0.09282910684935693,
      "loss": 3.2567,
      "step": 44620
    },
    {
      "epoch": 71.77,
      "learning_rate": 0.09282589141848875,
      "loss": 3.3278,
      "step": 44640
    },
    {
      "epoch": 71.8,
      "learning_rate": 0.09282267598762059,
      "loss": 3.3278,
      "step": 44660
    },
    {
      "epoch": 71.83,
      "learning_rate": 0.09281946055675241,
      "loss": 3.339,
      "step": 44680
    },
    {
      "epoch": 71.86,
      "learning_rate": 0.09281624512588424,
      "loss": 3.3057,
      "step": 44700
    },
    {
      "epoch": 71.9,
      "learning_rate": 0.09281302969501609,
      "loss": 3.3184,
      "step": 44720
    },
    {
      "epoch": 71.93,
      "learning_rate": 0.09280981426414792,
      "loss": 3.3121,
      "step": 44740
    },
    {
      "epoch": 71.96,
      "learning_rate": 0.09280659883327975,
      "loss": 3.3273,
      "step": 44760
    },
    {
      "epoch": 71.99,
      "learning_rate": 0.09280338340241158,
      "loss": 3.266,
      "step": 44780
    },
    {
      "epoch": 72.0,
      "eval_accuracy": {
        "accuracy": 0.3407447718261681
      },
      "eval_loss": 3.3633387088775635,
      "eval_runtime": 2.8224,
      "eval_samples_per_second": 4557.533,
      "eval_steps_per_second": 71.217,
      "step": 44784
    },
    {
      "epoch": 72.03,
      "learning_rate": 0.0928001679715434,
      "loss": 3.2845,
      "step": 44800
    },
    {
      "epoch": 72.06,
      "learning_rate": 0.09279695254067524,
      "loss": 3.3154,
      "step": 44820
    },
    {
      "epoch": 72.09,
      "learning_rate": 0.09279373710980708,
      "loss": 3.2827,
      "step": 44840
    },
    {
      "epoch": 72.12,
      "learning_rate": 0.09279052167893892,
      "loss": 3.3275,
      "step": 44860
    },
    {
      "epoch": 72.15,
      "learning_rate": 0.09278730624807074,
      "loss": 3.3221,
      "step": 44880
    },
    {
      "epoch": 72.19,
      "learning_rate": 0.09278409081720257,
      "loss": 3.2943,
      "step": 44900
    },
    {
      "epoch": 72.22,
      "learning_rate": 0.09278087538633441,
      "loss": 3.2905,
      "step": 44920
    },
    {
      "epoch": 72.25,
      "learning_rate": 0.09277765995546625,
      "loss": 3.3569,
      "step": 44940
    },
    {
      "epoch": 72.28,
      "learning_rate": 0.09277444452459808,
      "loss": 3.3197,
      "step": 44960
    },
    {
      "epoch": 72.32,
      "learning_rate": 0.09277122909372991,
      "loss": 3.3654,
      "step": 44980
    },
    {
      "epoch": 72.35,
      "learning_rate": 0.09276801366286173,
      "loss": 3.3221,
      "step": 45000
    },
    {
      "epoch": 72.38,
      "learning_rate": 0.09276479823199357,
      "loss": 3.3128,
      "step": 45020
    },
    {
      "epoch": 72.41,
      "learning_rate": 0.09276158280112541,
      "loss": 3.3503,
      "step": 45040
    },
    {
      "epoch": 72.44,
      "learning_rate": 0.09275836737025725,
      "loss": 3.2958,
      "step": 45060
    },
    {
      "epoch": 72.48,
      "learning_rate": 0.09275515193938907,
      "loss": 3.3017,
      "step": 45080
    },
    {
      "epoch": 72.51,
      "learning_rate": 0.0927519365085209,
      "loss": 3.2712,
      "step": 45100
    },
    {
      "epoch": 72.54,
      "learning_rate": 0.09274872107765274,
      "loss": 3.3238,
      "step": 45120
    },
    {
      "epoch": 72.57,
      "learning_rate": 0.09274550564678456,
      "loss": 3.3436,
      "step": 45140
    },
    {
      "epoch": 72.6,
      "learning_rate": 0.0927422902159164,
      "loss": 3.3485,
      "step": 45160
    },
    {
      "epoch": 72.64,
      "learning_rate": 0.09273907478504824,
      "loss": 3.3361,
      "step": 45180
    },
    {
      "epoch": 72.67,
      "learning_rate": 0.09273585935418008,
      "loss": 3.3953,
      "step": 45200
    },
    {
      "epoch": 72.7,
      "learning_rate": 0.0927326439233119,
      "loss": 3.3298,
      "step": 45220
    },
    {
      "epoch": 72.73,
      "learning_rate": 0.09272942849244373,
      "loss": 3.2831,
      "step": 45240
    },
    {
      "epoch": 72.77,
      "learning_rate": 0.09272621306157557,
      "loss": 3.2485,
      "step": 45260
    },
    {
      "epoch": 72.8,
      "learning_rate": 0.0927229976307074,
      "loss": 3.2619,
      "step": 45280
    },
    {
      "epoch": 72.83,
      "learning_rate": 0.09271978219983924,
      "loss": 3.3357,
      "step": 45300
    },
    {
      "epoch": 72.86,
      "learning_rate": 0.09271656676897107,
      "loss": 3.3114,
      "step": 45320
    },
    {
      "epoch": 72.89,
      "learning_rate": 0.09271335133810289,
      "loss": 3.3023,
      "step": 45340
    },
    {
      "epoch": 72.93,
      "learning_rate": 0.09271013590723473,
      "loss": 3.2997,
      "step": 45360
    },
    {
      "epoch": 72.96,
      "learning_rate": 0.09270692047636657,
      "loss": 3.3166,
      "step": 45380
    },
    {
      "epoch": 72.99,
      "learning_rate": 0.09270370504549841,
      "loss": 3.285,
      "step": 45400
    },
    {
      "epoch": 73.0,
      "eval_accuracy": {
        "accuracy": 0.3298608411723548
      },
      "eval_loss": 3.405008554458618,
      "eval_runtime": 2.6897,
      "eval_samples_per_second": 4782.361,
      "eval_steps_per_second": 74.73,
      "step": 45406
    },
    {
      "epoch": 73.02,
      "learning_rate": 0.09270048961463023,
      "loss": 3.2861,
      "step": 45420
    },
    {
      "epoch": 73.05,
      "learning_rate": 0.09269727418376206,
      "loss": 3.2967,
      "step": 45440
    },
    {
      "epoch": 73.09,
      "learning_rate": 0.0926940587528939,
      "loss": 3.3082,
      "step": 45460
    },
    {
      "epoch": 73.12,
      "learning_rate": 0.09269084332202572,
      "loss": 3.3657,
      "step": 45480
    },
    {
      "epoch": 73.15,
      "learning_rate": 0.09268762789115756,
      "loss": 3.3826,
      "step": 45500
    },
    {
      "epoch": 73.18,
      "learning_rate": 0.0926844124602894,
      "loss": 3.3382,
      "step": 45520
    },
    {
      "epoch": 73.22,
      "learning_rate": 0.09268119702942122,
      "loss": 3.3684,
      "step": 45540
    },
    {
      "epoch": 73.25,
      "learning_rate": 0.09267798159855306,
      "loss": 3.3507,
      "step": 45560
    },
    {
      "epoch": 73.28,
      "learning_rate": 0.09267476616768489,
      "loss": 3.4071,
      "step": 45580
    },
    {
      "epoch": 73.31,
      "learning_rate": 0.09267155073681672,
      "loss": 3.34,
      "step": 45600
    },
    {
      "epoch": 73.34,
      "learning_rate": 0.09266833530594856,
      "loss": 3.3241,
      "step": 45620
    },
    {
      "epoch": 73.38,
      "learning_rate": 0.09266511987508039,
      "loss": 3.3196,
      "step": 45640
    },
    {
      "epoch": 73.41,
      "learning_rate": 0.09266190444421223,
      "loss": 3.3084,
      "step": 45660
    },
    {
      "epoch": 73.44,
      "learning_rate": 0.09265868901334405,
      "loss": 3.2683,
      "step": 45680
    },
    {
      "epoch": 73.47,
      "learning_rate": 0.09265547358247589,
      "loss": 3.3669,
      "step": 45700
    },
    {
      "epoch": 73.5,
      "learning_rate": 0.09265241892315113,
      "loss": 3.38,
      "step": 45720
    },
    {
      "epoch": 73.54,
      "learning_rate": 0.09264920349228296,
      "loss": 3.3233,
      "step": 45740
    },
    {
      "epoch": 73.57,
      "learning_rate": 0.09264598806141479,
      "loss": 3.3444,
      "step": 45760
    },
    {
      "epoch": 73.6,
      "learning_rate": 0.09264277263054663,
      "loss": 3.3069,
      "step": 45780
    },
    {
      "epoch": 73.63,
      "learning_rate": 0.09263955719967847,
      "loss": 3.3648,
      "step": 45800
    },
    {
      "epoch": 73.67,
      "learning_rate": 0.09263634176881029,
      "loss": 3.3226,
      "step": 45820
    },
    {
      "epoch": 73.7,
      "learning_rate": 0.09263312633794213,
      "loss": 3.276,
      "step": 45840
    },
    {
      "epoch": 73.73,
      "learning_rate": 0.09262991090707395,
      "loss": 3.2808,
      "step": 45860
    },
    {
      "epoch": 73.76,
      "learning_rate": 0.09262669547620579,
      "loss": 3.3077,
      "step": 45880
    },
    {
      "epoch": 73.79,
      "learning_rate": 0.09262348004533763,
      "loss": 3.2922,
      "step": 45900
    },
    {
      "epoch": 73.83,
      "learning_rate": 0.09262026461446946,
      "loss": 3.2727,
      "step": 45920
    },
    {
      "epoch": 73.86,
      "learning_rate": 0.0926170491836013,
      "loss": 3.2867,
      "step": 45940
    },
    {
      "epoch": 73.89,
      "learning_rate": 0.09261383375273312,
      "loss": 3.2941,
      "step": 45960
    },
    {
      "epoch": 73.92,
      "learning_rate": 0.09261061832186496,
      "loss": 3.3505,
      "step": 45980
    },
    {
      "epoch": 73.95,
      "learning_rate": 0.0926074028909968,
      "loss": 3.4356,
      "step": 46000
    },
    {
      "epoch": 73.99,
      "learning_rate": 0.09260418746012862,
      "loss": 3.4146,
      "step": 46020
    },
    {
      "epoch": 74.0,
      "eval_accuracy": {
        "accuracy": 0.3383347586099666
      },
      "eval_loss": 3.444035768508911,
      "eval_runtime": 2.8298,
      "eval_samples_per_second": 4545.603,
      "eval_steps_per_second": 71.031,
      "step": 46028
    },
    {
      "epoch": 74.02,
      "learning_rate": 0.09260097202926046,
      "loss": 3.361,
      "step": 46040
    },
    {
      "epoch": 74.05,
      "learning_rate": 0.09259775659839228,
      "loss": 3.3426,
      "step": 46060
    },
    {
      "epoch": 74.08,
      "learning_rate": 0.09259454116752412,
      "loss": 3.2786,
      "step": 46080
    },
    {
      "epoch": 74.12,
      "learning_rate": 0.09259132573665596,
      "loss": 3.2797,
      "step": 46100
    },
    {
      "epoch": 74.15,
      "learning_rate": 0.09258811030578779,
      "loss": 3.3088,
      "step": 46120
    },
    {
      "epoch": 74.18,
      "learning_rate": 0.09258489487491962,
      "loss": 3.2644,
      "step": 46140
    },
    {
      "epoch": 74.21,
      "learning_rate": 0.09258167944405145,
      "loss": 3.2473,
      "step": 46160
    },
    {
      "epoch": 74.24,
      "learning_rate": 0.09257846401318329,
      "loss": 3.2245,
      "step": 46180
    },
    {
      "epoch": 74.28,
      "learning_rate": 0.09257524858231511,
      "loss": 3.2715,
      "step": 46200
    },
    {
      "epoch": 74.31,
      "learning_rate": 0.09257203315144695,
      "loss": 3.2885,
      "step": 46220
    },
    {
      "epoch": 74.34,
      "learning_rate": 0.09256881772057879,
      "loss": 3.3353,
      "step": 46240
    },
    {
      "epoch": 74.37,
      "learning_rate": 0.09256560228971061,
      "loss": 3.2926,
      "step": 46260
    },
    {
      "epoch": 74.41,
      "learning_rate": 0.09256238685884245,
      "loss": 3.3203,
      "step": 46280
    },
    {
      "epoch": 74.44,
      "learning_rate": 0.09255917142797428,
      "loss": 3.2885,
      "step": 46300
    },
    {
      "epoch": 74.47,
      "learning_rate": 0.09255595599710612,
      "loss": 3.294,
      "step": 46320
    },
    {
      "epoch": 74.5,
      "learning_rate": 0.09255274056623795,
      "loss": 3.2941,
      "step": 46340
    },
    {
      "epoch": 74.53,
      "learning_rate": 0.09254952513536978,
      "loss": 3.3252,
      "step": 46360
    },
    {
      "epoch": 74.57,
      "learning_rate": 0.09254630970450162,
      "loss": 3.291,
      "step": 46380
    },
    {
      "epoch": 74.6,
      "learning_rate": 0.09254309427363344,
      "loss": 3.2922,
      "step": 46400
    },
    {
      "epoch": 74.63,
      "learning_rate": 0.09253987884276528,
      "loss": 3.3688,
      "step": 46420
    },
    {
      "epoch": 74.66,
      "learning_rate": 0.09253666341189712,
      "loss": 3.3627,
      "step": 46440
    },
    {
      "epoch": 74.69,
      "learning_rate": 0.09253344798102894,
      "loss": 3.3226,
      "step": 46460
    },
    {
      "epoch": 74.73,
      "learning_rate": 0.09253023255016078,
      "loss": 3.2678,
      "step": 46480
    },
    {
      "epoch": 74.76,
      "learning_rate": 0.0925270171192926,
      "loss": 3.3256,
      "step": 46500
    },
    {
      "epoch": 74.79,
      "learning_rate": 0.09252380168842445,
      "loss": 3.3753,
      "step": 46520
    },
    {
      "epoch": 74.82,
      "learning_rate": 0.09252058625755627,
      "loss": 3.3345,
      "step": 46540
    },
    {
      "epoch": 74.86,
      "learning_rate": 0.09251737082668811,
      "loss": 3.3388,
      "step": 46560
    },
    {
      "epoch": 74.89,
      "learning_rate": 0.09251415539581995,
      "loss": 3.3304,
      "step": 46580
    },
    {
      "epoch": 74.92,
      "learning_rate": 0.09251093996495177,
      "loss": 3.3311,
      "step": 46600
    },
    {
      "epoch": 74.95,
      "learning_rate": 0.09250772453408361,
      "loss": 3.309,
      "step": 46620
    },
    {
      "epoch": 74.98,
      "learning_rate": 0.09250450910321543,
      "loss": 3.3401,
      "step": 46640
    },
    {
      "epoch": 75.0,
      "eval_accuracy": {
        "accuracy": 0.3384125009717795
      },
      "eval_loss": 3.442779302597046,
      "eval_runtime": 2.5313,
      "eval_samples_per_second": 5081.531,
      "eval_steps_per_second": 79.405,
      "step": 46650
    },
    {
      "epoch": 75.02,
      "learning_rate": 0.09250129367234727,
      "loss": 3.3384,
      "step": 46660
    },
    {
      "epoch": 75.05,
      "learning_rate": 0.09249807824147911,
      "loss": 3.3307,
      "step": 46680
    },
    {
      "epoch": 75.08,
      "learning_rate": 0.09249486281061094,
      "loss": 3.3173,
      "step": 46700
    },
    {
      "epoch": 75.11,
      "learning_rate": 0.09249164737974278,
      "loss": 3.311,
      "step": 46720
    },
    {
      "epoch": 75.14,
      "learning_rate": 0.0924884319488746,
      "loss": 3.2902,
      "step": 46740
    },
    {
      "epoch": 75.18,
      "learning_rate": 0.09248521651800644,
      "loss": 3.3517,
      "step": 46760
    },
    {
      "epoch": 75.21,
      "learning_rate": 0.09248200108713828,
      "loss": 3.2756,
      "step": 46780
    },
    {
      "epoch": 75.24,
      "learning_rate": 0.0924787856562701,
      "loss": 3.2812,
      "step": 46800
    },
    {
      "epoch": 75.27,
      "learning_rate": 0.09247557022540194,
      "loss": 3.2661,
      "step": 46820
    },
    {
      "epoch": 75.31,
      "learning_rate": 0.09247235479453376,
      "loss": 3.3253,
      "step": 46840
    },
    {
      "epoch": 75.34,
      "learning_rate": 0.0924691393636656,
      "loss": 3.3154,
      "step": 46860
    },
    {
      "epoch": 75.37,
      "learning_rate": 0.09246592393279743,
      "loss": 3.3205,
      "step": 46880
    },
    {
      "epoch": 75.4,
      "learning_rate": 0.09246270850192927,
      "loss": 3.285,
      "step": 46900
    },
    {
      "epoch": 75.43,
      "learning_rate": 0.0924594930710611,
      "loss": 3.2328,
      "step": 46920
    },
    {
      "epoch": 75.47,
      "learning_rate": 0.09245627764019293,
      "loss": 3.2676,
      "step": 46940
    },
    {
      "epoch": 75.5,
      "learning_rate": 0.09245306220932477,
      "loss": 3.2712,
      "step": 46960
    },
    {
      "epoch": 75.53,
      "learning_rate": 0.09244984677845659,
      "loss": 3.2444,
      "step": 46980
    },
    {
      "epoch": 75.56,
      "learning_rate": 0.09244663134758843,
      "loss": 3.2822,
      "step": 47000
    },
    {
      "epoch": 75.59,
      "learning_rate": 0.09244341591672027,
      "loss": 3.2818,
      "step": 47020
    },
    {
      "epoch": 75.63,
      "learning_rate": 0.0924402004858521,
      "loss": 3.2976,
      "step": 47040
    },
    {
      "epoch": 75.66,
      "learning_rate": 0.09243698505498393,
      "loss": 3.3231,
      "step": 47060
    },
    {
      "epoch": 75.69,
      "learning_rate": 0.09243376962411576,
      "loss": 3.2687,
      "step": 47080
    },
    {
      "epoch": 75.72,
      "learning_rate": 0.09243055419324758,
      "loss": 3.2963,
      "step": 47100
    },
    {
      "epoch": 75.76,
      "learning_rate": 0.09242733876237944,
      "loss": 3.3179,
      "step": 47120
    },
    {
      "epoch": 75.79,
      "learning_rate": 0.09242412333151126,
      "loss": 3.3405,
      "step": 47140
    },
    {
      "epoch": 75.82,
      "learning_rate": 0.0924209079006431,
      "loss": 3.3575,
      "step": 47160
    },
    {
      "epoch": 75.85,
      "learning_rate": 0.09241769246977492,
      "loss": 3.3297,
      "step": 47180
    },
    {
      "epoch": 75.88,
      "learning_rate": 0.09241447703890675,
      "loss": 3.321,
      "step": 47200
    },
    {
      "epoch": 75.92,
      "learning_rate": 0.09241126160803859,
      "loss": 3.2904,
      "step": 47220
    },
    {
      "epoch": 75.95,
      "learning_rate": 0.09240804617717042,
      "loss": 3.2802,
      "step": 47240
    },
    {
      "epoch": 75.98,
      "learning_rate": 0.09240483074630226,
      "loss": 3.3201,
      "step": 47260
    },
    {
      "epoch": 76.0,
      "eval_accuracy": {
        "accuracy": 0.3402783176552904
      },
      "eval_loss": 3.4436075687408447,
      "eval_runtime": 2.8534,
      "eval_samples_per_second": 4507.938,
      "eval_steps_per_second": 70.442,
      "step": 47272
    },
    {
      "epoch": 76.01,
      "learning_rate": 0.09240161531543409,
      "loss": 3.3127,
      "step": 47280
    },
    {
      "epoch": 76.05,
      "learning_rate": 0.09239839988456591,
      "loss": 3.2756,
      "step": 47300
    },
    {
      "epoch": 76.08,
      "learning_rate": 0.09239518445369775,
      "loss": 3.2581,
      "step": 47320
    },
    {
      "epoch": 76.11,
      "learning_rate": 0.09239196902282959,
      "loss": 3.3272,
      "step": 47340
    },
    {
      "epoch": 76.14,
      "learning_rate": 0.09238875359196143,
      "loss": 3.3306,
      "step": 47360
    },
    {
      "epoch": 76.17,
      "learning_rate": 0.09238553816109325,
      "loss": 3.2695,
      "step": 47380
    },
    {
      "epoch": 76.21,
      "learning_rate": 0.09238232273022509,
      "loss": 3.2623,
      "step": 47400
    },
    {
      "epoch": 76.24,
      "learning_rate": 0.09237910729935692,
      "loss": 3.29,
      "step": 47420
    },
    {
      "epoch": 76.27,
      "learning_rate": 0.09237589186848874,
      "loss": 3.2778,
      "step": 47440
    },
    {
      "epoch": 76.3,
      "learning_rate": 0.0923726764376206,
      "loss": 3.2687,
      "step": 47460
    },
    {
      "epoch": 76.33,
      "learning_rate": 0.09236946100675242,
      "loss": 3.2854,
      "step": 47480
    },
    {
      "epoch": 76.37,
      "learning_rate": 0.09236624557588426,
      "loss": 3.3214,
      "step": 47500
    },
    {
      "epoch": 76.4,
      "learning_rate": 0.09236303014501608,
      "loss": 3.2793,
      "step": 47520
    },
    {
      "epoch": 76.43,
      "learning_rate": 0.0923598147141479,
      "loss": 3.2764,
      "step": 47540
    },
    {
      "epoch": 76.46,
      "learning_rate": 0.09235659928327974,
      "loss": 3.284,
      "step": 47560
    },
    {
      "epoch": 76.5,
      "learning_rate": 0.09235338385241158,
      "loss": 3.2641,
      "step": 47580
    },
    {
      "epoch": 76.53,
      "learning_rate": 0.09235016842154342,
      "loss": 3.253,
      "step": 47600
    },
    {
      "epoch": 76.56,
      "learning_rate": 0.09234695299067525,
      "loss": 3.2768,
      "step": 47620
    },
    {
      "epoch": 76.59,
      "learning_rate": 0.09234373755980707,
      "loss": 3.2854,
      "step": 47640
    },
    {
      "epoch": 76.62,
      "learning_rate": 0.09234052212893891,
      "loss": 3.2339,
      "step": 47660
    },
    {
      "epoch": 76.66,
      "learning_rate": 0.09233730669807075,
      "loss": 3.2972,
      "step": 47680
    },
    {
      "epoch": 76.69,
      "learning_rate": 0.09233409126720259,
      "loss": 3.3046,
      "step": 47700
    },
    {
      "epoch": 76.72,
      "learning_rate": 0.09233087583633441,
      "loss": 3.3403,
      "step": 47720
    },
    {
      "epoch": 76.75,
      "learning_rate": 0.09232766040546624,
      "loss": 3.3664,
      "step": 47740
    },
    {
      "epoch": 76.78,
      "learning_rate": 0.09232444497459807,
      "loss": 3.3166,
      "step": 47760
    },
    {
      "epoch": 76.82,
      "learning_rate": 0.09232122954372991,
      "loss": 3.3642,
      "step": 47780
    },
    {
      "epoch": 76.85,
      "learning_rate": 0.09231801411286175,
      "loss": 3.3224,
      "step": 47800
    },
    {
      "epoch": 76.88,
      "learning_rate": 0.09231479868199358,
      "loss": 3.2938,
      "step": 47820
    },
    {
      "epoch": 76.91,
      "learning_rate": 0.0923115832511254,
      "loss": 3.2909,
      "step": 47840
    },
    {
      "epoch": 76.95,
      "learning_rate": 0.09230836782025724,
      "loss": 3.2919,
      "step": 47860
    },
    {
      "epoch": 76.98,
      "learning_rate": 0.09230515238938906,
      "loss": 3.2564,
      "step": 47880
    },
    {
      "epoch": 77.0,
      "eval_accuracy": {
        "accuracy": 0.3307937495141102
      },
      "eval_loss": 3.4397053718566895,
      "eval_runtime": 2.4438,
      "eval_samples_per_second": 5263.501,
      "eval_steps_per_second": 82.249,
      "step": 47894
    },
    {
      "epoch": 77.01,
      "learning_rate": 0.0923019369585209,
      "loss": 3.3341,
      "step": 47900
    },
    {
      "epoch": 77.04,
      "learning_rate": 0.09229872152765274,
      "loss": 3.2756,
      "step": 47920
    },
    {
      "epoch": 77.07,
      "learning_rate": 0.09229550609678457,
      "loss": 3.2859,
      "step": 47940
    },
    {
      "epoch": 77.11,
      "learning_rate": 0.0922922906659164,
      "loss": 3.2496,
      "step": 47960
    },
    {
      "epoch": 77.14,
      "learning_rate": 0.09228907523504823,
      "loss": 3.2885,
      "step": 47980
    },
    {
      "epoch": 77.17,
      "learning_rate": 0.09228585980418007,
      "loss": 3.3112,
      "step": 48000
    },
    {
      "epoch": 77.2,
      "learning_rate": 0.0922826443733119,
      "loss": 3.2917,
      "step": 48020
    },
    {
      "epoch": 77.23,
      "learning_rate": 0.09227942894244374,
      "loss": 3.2943,
      "step": 48040
    },
    {
      "epoch": 77.27,
      "learning_rate": 0.09227621351157557,
      "loss": 3.3172,
      "step": 48060
    },
    {
      "epoch": 77.3,
      "learning_rate": 0.0922729980807074,
      "loss": 3.3367,
      "step": 48080
    },
    {
      "epoch": 77.33,
      "learning_rate": 0.09226978264983923,
      "loss": 3.2959,
      "step": 48100
    },
    {
      "epoch": 77.36,
      "learning_rate": 0.09226656721897107,
      "loss": 3.3412,
      "step": 48120
    },
    {
      "epoch": 77.4,
      "learning_rate": 0.09226335178810291,
      "loss": 3.2907,
      "step": 48140
    },
    {
      "epoch": 77.43,
      "learning_rate": 0.09226013635723473,
      "loss": 3.3374,
      "step": 48160
    },
    {
      "epoch": 77.46,
      "learning_rate": 0.09225692092636656,
      "loss": 3.2926,
      "step": 48180
    },
    {
      "epoch": 77.49,
      "learning_rate": 0.0922537054954984,
      "loss": 3.2529,
      "step": 48200
    },
    {
      "epoch": 77.52,
      "learning_rate": 0.09225065083617363,
      "loss": 3.3713,
      "step": 48220
    },
    {
      "epoch": 77.56,
      "learning_rate": 0.09224743540530547,
      "loss": 3.4272,
      "step": 48240
    },
    {
      "epoch": 77.59,
      "learning_rate": 0.0922442199744373,
      "loss": 3.3284,
      "step": 48260
    },
    {
      "epoch": 77.62,
      "learning_rate": 0.09224100454356914,
      "loss": 3.3021,
      "step": 48280
    },
    {
      "epoch": 77.65,
      "learning_rate": 0.09223778911270097,
      "loss": 3.3026,
      "step": 48300
    },
    {
      "epoch": 77.68,
      "learning_rate": 0.0922345736818328,
      "loss": 3.266,
      "step": 48320
    },
    {
      "epoch": 77.72,
      "learning_rate": 0.09223135825096464,
      "loss": 3.2817,
      "step": 48340
    },
    {
      "epoch": 77.75,
      "learning_rate": 0.09222814282009646,
      "loss": 3.3116,
      "step": 48360
    },
    {
      "epoch": 77.78,
      "learning_rate": 0.0922249273892283,
      "loss": 3.2741,
      "step": 48380
    },
    {
      "epoch": 77.81,
      "learning_rate": 0.09222171195836014,
      "loss": 3.2532,
      "step": 48400
    },
    {
      "epoch": 77.85,
      "learning_rate": 0.09221849652749196,
      "loss": 3.2334,
      "step": 48420
    },
    {
      "epoch": 77.88,
      "learning_rate": 0.0922152810966238,
      "loss": 3.2883,
      "step": 48440
    },
    {
      "epoch": 77.91,
      "learning_rate": 0.09221206566575563,
      "loss": 3.2876,
      "step": 48460
    },
    {
      "epoch": 77.94,
      "learning_rate": 0.09220885023488747,
      "loss": 3.3426,
      "step": 48480
    },
    {
      "epoch": 77.97,
      "learning_rate": 0.0922056348040193,
      "loss": 3.3434,
      "step": 48500
    },
    {
      "epoch": 78.0,
      "eval_accuracy": {
        "accuracy": 0.33981186348441267
      },
      "eval_loss": 3.3659539222717285,
      "eval_runtime": 2.6024,
      "eval_samples_per_second": 4942.702,
      "eval_steps_per_second": 77.236,
      "step": 48516
    },
    {
      "epoch": 78.01,
      "learning_rate": 0.09220241937315113,
      "loss": 3.307,
      "step": 48520
    },
    {
      "epoch": 78.04,
      "learning_rate": 0.09219920394228297,
      "loss": 3.2648,
      "step": 48540
    },
    {
      "epoch": 78.07,
      "learning_rate": 0.09219598851141479,
      "loss": 3.2509,
      "step": 48560
    },
    {
      "epoch": 78.1,
      "learning_rate": 0.09219277308054663,
      "loss": 3.2644,
      "step": 48580
    },
    {
      "epoch": 78.14,
      "learning_rate": 0.09218955764967846,
      "loss": 3.3281,
      "step": 48600
    },
    {
      "epoch": 78.17,
      "learning_rate": 0.0921863422188103,
      "loss": 3.2939,
      "step": 48620
    },
    {
      "epoch": 78.2,
      "learning_rate": 0.09218312678794213,
      "loss": 3.2589,
      "step": 48640
    },
    {
      "epoch": 78.23,
      "learning_rate": 0.09217991135707396,
      "loss": 3.2735,
      "step": 48660
    },
    {
      "epoch": 78.26,
      "learning_rate": 0.0921766959262058,
      "loss": 3.2669,
      "step": 48680
    },
    {
      "epoch": 78.3,
      "learning_rate": 0.09217348049533762,
      "loss": 3.3505,
      "step": 48700
    },
    {
      "epoch": 78.33,
      "learning_rate": 0.09217026506446946,
      "loss": 3.3059,
      "step": 48720
    },
    {
      "epoch": 78.36,
      "learning_rate": 0.0921670496336013,
      "loss": 3.2785,
      "step": 48740
    },
    {
      "epoch": 78.39,
      "learning_rate": 0.09216383420273312,
      "loss": 3.3007,
      "step": 48760
    },
    {
      "epoch": 78.42,
      "learning_rate": 0.09216061877186496,
      "loss": 3.3108,
      "step": 48780
    },
    {
      "epoch": 78.46,
      "learning_rate": 0.09215740334099679,
      "loss": 3.3154,
      "step": 48800
    },
    {
      "epoch": 78.49,
      "learning_rate": 0.09215418791012862,
      "loss": 3.3288,
      "step": 48820
    },
    {
      "epoch": 78.52,
      "learning_rate": 0.09215097247926046,
      "loss": 3.3329,
      "step": 48840
    },
    {
      "epoch": 78.55,
      "learning_rate": 0.09214775704839229,
      "loss": 3.32,
      "step": 48860
    },
    {
      "epoch": 78.59,
      "learning_rate": 0.09214454161752413,
      "loss": 3.2758,
      "step": 48880
    },
    {
      "epoch": 78.62,
      "learning_rate": 0.09214132618665595,
      "loss": 3.2889,
      "step": 48900
    },
    {
      "epoch": 78.65,
      "learning_rate": 0.09213811075578779,
      "loss": 3.2396,
      "step": 48920
    },
    {
      "epoch": 78.68,
      "learning_rate": 0.09213489532491961,
      "loss": 3.2425,
      "step": 48940
    },
    {
      "epoch": 78.71,
      "learning_rate": 0.09213167989405145,
      "loss": 3.3069,
      "step": 48960
    },
    {
      "epoch": 78.75,
      "learning_rate": 0.09212846446318329,
      "loss": 3.3242,
      "step": 48980
    },
    {
      "epoch": 78.78,
      "learning_rate": 0.09212524903231512,
      "loss": 3.289,
      "step": 49000
    },
    {
      "epoch": 78.81,
      "learning_rate": 0.09212203360144695,
      "loss": 3.2905,
      "step": 49020
    },
    {
      "epoch": 78.84,
      "learning_rate": 0.09211881817057878,
      "loss": 3.3435,
      "step": 49040
    },
    {
      "epoch": 78.87,
      "learning_rate": 0.09211560273971062,
      "loss": 3.3402,
      "step": 49060
    },
    {
      "epoch": 78.91,
      "learning_rate": 0.09211238730884246,
      "loss": 3.3313,
      "step": 49080
    },
    {
      "epoch": 78.94,
      "learning_rate": 0.09210917187797428,
      "loss": 3.2856,
      "step": 49100
    },
    {
      "epoch": 78.97,
      "learning_rate": 0.09210595644710612,
      "loss": 3.3142,
      "step": 49120
    },
    {
      "epoch": 79.0,
      "eval_accuracy": {
        "accuracy": 0.34641996423851357
      },
      "eval_loss": 3.317927122116089,
      "eval_runtime": 2.7514,
      "eval_samples_per_second": 4675.022,
      "eval_steps_per_second": 73.053,
      "step": 49138
    },
    {
      "epoch": 79.0,
      "learning_rate": 0.09210274101623794,
      "loss": 3.2785,
      "step": 49140
    },
    {
      "epoch": 79.04,
      "learning_rate": 0.09209952558536978,
      "loss": 3.2573,
      "step": 49160
    },
    {
      "epoch": 79.07,
      "learning_rate": 0.09209631015450162,
      "loss": 3.2074,
      "step": 49180
    },
    {
      "epoch": 79.1,
      "learning_rate": 0.09209309472363345,
      "loss": 3.2732,
      "step": 49200
    },
    {
      "epoch": 79.13,
      "learning_rate": 0.09208987929276528,
      "loss": 3.291,
      "step": 49220
    },
    {
      "epoch": 79.16,
      "learning_rate": 0.09208666386189711,
      "loss": 3.304,
      "step": 49240
    },
    {
      "epoch": 79.2,
      "learning_rate": 0.09208344843102895,
      "loss": 3.2529,
      "step": 49260
    },
    {
      "epoch": 79.23,
      "learning_rate": 0.09208023300016077,
      "loss": 3.3144,
      "step": 49280
    },
    {
      "epoch": 79.26,
      "learning_rate": 0.09207701756929261,
      "loss": 3.2725,
      "step": 49300
    },
    {
      "epoch": 79.29,
      "learning_rate": 0.09207380213842445,
      "loss": 3.2681,
      "step": 49320
    },
    {
      "epoch": 79.32,
      "learning_rate": 0.09207058670755627,
      "loss": 3.3155,
      "step": 49340
    },
    {
      "epoch": 79.36,
      "learning_rate": 0.09206737127668811,
      "loss": 3.2939,
      "step": 49360
    },
    {
      "epoch": 79.39,
      "learning_rate": 0.09206415584581994,
      "loss": 3.29,
      "step": 49380
    },
    {
      "epoch": 79.42,
      "learning_rate": 0.09206094041495178,
      "loss": 3.2693,
      "step": 49400
    },
    {
      "epoch": 79.45,
      "learning_rate": 0.09205772498408361,
      "loss": 3.2583,
      "step": 49420
    },
    {
      "epoch": 79.49,
      "learning_rate": 0.09205450955321544,
      "loss": 3.2612,
      "step": 49440
    },
    {
      "epoch": 79.52,
      "learning_rate": 0.09205129412234728,
      "loss": 3.2372,
      "step": 49460
    },
    {
      "epoch": 79.55,
      "learning_rate": 0.0920480786914791,
      "loss": 3.2816,
      "step": 49480
    },
    {
      "epoch": 79.58,
      "learning_rate": 0.09204486326061093,
      "loss": 3.2623,
      "step": 49500
    },
    {
      "epoch": 79.61,
      "learning_rate": 0.09204164782974278,
      "loss": 3.2665,
      "step": 49520
    },
    {
      "epoch": 79.65,
      "learning_rate": 0.0920384323988746,
      "loss": 3.2789,
      "step": 49540
    },
    {
      "epoch": 79.68,
      "learning_rate": 0.09203521696800644,
      "loss": 3.3054,
      "step": 49560
    },
    {
      "epoch": 79.71,
      "learning_rate": 0.09203200153713827,
      "loss": 3.2754,
      "step": 49580
    },
    {
      "epoch": 79.74,
      "learning_rate": 0.0920287861062701,
      "loss": 3.2588,
      "step": 49600
    },
    {
      "epoch": 79.77,
      "learning_rate": 0.09202557067540193,
      "loss": 3.3132,
      "step": 49620
    },
    {
      "epoch": 79.81,
      "learning_rate": 0.09202235524453377,
      "loss": 3.3351,
      "step": 49640
    },
    {
      "epoch": 79.84,
      "learning_rate": 0.0920191398136656,
      "loss": 3.3207,
      "step": 49660
    },
    {
      "epoch": 79.87,
      "learning_rate": 0.09201592438279743,
      "loss": 3.3189,
      "step": 49680
    },
    {
      "epoch": 79.9,
      "learning_rate": 0.09201270895192927,
      "loss": 3.3191,
      "step": 49700
    },
    {
      "epoch": 79.94,
      "learning_rate": 0.0920094935210611,
      "loss": 3.2948,
      "step": 49720
    },
    {
      "epoch": 79.97,
      "learning_rate": 0.09200627809019293,
      "loss": 3.3239,
      "step": 49740
    },
    {
      "epoch": 80.0,
      "learning_rate": 0.09200306265932477,
      "loss": 3.2784,
      "step": 49760
    },
    {
      "epoch": 80.0,
      "eval_accuracy": {
        "accuracy": 0.34385446629868616
      },
      "eval_loss": 3.323829174041748,
      "eval_runtime": 2.8915,
      "eval_samples_per_second": 4448.62,
      "eval_steps_per_second": 69.515,
      "step": 49760
    },
    {
      "epoch": 80.03,
      "learning_rate": 0.0919998472284566,
      "loss": 3.2356,
      "step": 49780
    },
    {
      "epoch": 80.06,
      "learning_rate": 0.09199663179758844,
      "loss": 3.2271,
      "step": 49800
    },
    {
      "epoch": 80.1,
      "learning_rate": 0.09199341636672026,
      "loss": 3.2347,
      "step": 49820
    },
    {
      "epoch": 80.13,
      "learning_rate": 0.09199020093585208,
      "loss": 3.2668,
      "step": 49840
    },
    {
      "epoch": 80.16,
      "learning_rate": 0.09198698550498394,
      "loss": 3.3159,
      "step": 49860
    },
    {
      "epoch": 80.19,
      "learning_rate": 0.09198377007411576,
      "loss": 3.3624,
      "step": 49880
    },
    {
      "epoch": 80.23,
      "learning_rate": 0.0919805546432476,
      "loss": 3.3171,
      "step": 49900
    },
    {
      "epoch": 80.26,
      "learning_rate": 0.09197733921237942,
      "loss": 3.3125,
      "step": 49920
    },
    {
      "epoch": 80.29,
      "learning_rate": 0.09197412378151125,
      "loss": 3.3028,
      "step": 49940
    },
    {
      "epoch": 80.32,
      "learning_rate": 0.09197090835064309,
      "loss": 3.3008,
      "step": 49960
    },
    {
      "epoch": 80.35,
      "learning_rate": 0.09196769291977493,
      "loss": 3.2997,
      "step": 49980
    },
    {
      "epoch": 80.39,
      "learning_rate": 0.09196447748890677,
      "loss": 3.2608,
      "step": 50000
    },
    {
      "epoch": 80.42,
      "learning_rate": 0.09196126205803859,
      "loss": 3.2616,
      "step": 50020
    },
    {
      "epoch": 80.45,
      "learning_rate": 0.09195804662717041,
      "loss": 3.285,
      "step": 50040
    },
    {
      "epoch": 80.48,
      "learning_rate": 0.09195483119630225,
      "loss": 3.302,
      "step": 50060
    },
    {
      "epoch": 80.51,
      "learning_rate": 0.09195161576543409,
      "loss": 3.2559,
      "step": 50080
    },
    {
      "epoch": 80.55,
      "learning_rate": 0.09194840033456593,
      "loss": 3.275,
      "step": 50100
    },
    {
      "epoch": 80.58,
      "learning_rate": 0.09194518490369775,
      "loss": 3.2583,
      "step": 50120
    },
    {
      "epoch": 80.61,
      "learning_rate": 0.09194196947282958,
      "loss": 3.249,
      "step": 50140
    },
    {
      "epoch": 80.64,
      "learning_rate": 0.09193875404196142,
      "loss": 3.2684,
      "step": 50160
    },
    {
      "epoch": 80.68,
      "learning_rate": 0.09193553861109326,
      "loss": 3.3099,
      "step": 50180
    },
    {
      "epoch": 80.71,
      "learning_rate": 0.0919323231802251,
      "loss": 3.3392,
      "step": 50200
    },
    {
      "epoch": 80.74,
      "learning_rate": 0.09192910774935692,
      "loss": 3.3272,
      "step": 50220
    },
    {
      "epoch": 80.77,
      "learning_rate": 0.09192589231848876,
      "loss": 3.2842,
      "step": 50240
    },
    {
      "epoch": 80.8,
      "learning_rate": 0.09192267688762058,
      "loss": 3.2604,
      "step": 50260
    },
    {
      "epoch": 80.84,
      "learning_rate": 0.09191946145675241,
      "loss": 3.216,
      "step": 50280
    },
    {
      "epoch": 80.87,
      "learning_rate": 0.09191624602588425,
      "loss": 3.2713,
      "step": 50300
    },
    {
      "epoch": 80.9,
      "learning_rate": 0.09191303059501608,
      "loss": 3.2785,
      "step": 50320
    },
    {
      "epoch": 80.93,
      "learning_rate": 0.09190997593569133,
      "loss": 3.36,
      "step": 50340
    },
    {
      "epoch": 80.96,
      "learning_rate": 0.09190676050482316,
      "loss": 3.332,
      "step": 50360
    },
    {
      "epoch": 81.0,
      "learning_rate": 0.09190354507395498,
      "loss": 3.2801,
      "step": 50380
    },
    {
      "epoch": 81.0,
      "eval_accuracy": {
        "accuracy": 0.3475083573038949
      },
      "eval_loss": 3.308520793914795,
      "eval_runtime": 2.5181,
      "eval_samples_per_second": 5108.3,
      "eval_steps_per_second": 79.823,
      "step": 50382
    },
    {
      "epoch": 81.03,
      "learning_rate": 0.09190032964308682,
      "loss": 3.2641,
      "step": 50400
    },
    {
      "epoch": 81.06,
      "learning_rate": 0.09189711421221865,
      "loss": 3.3332,
      "step": 50420
    },
    {
      "epoch": 81.09,
      "learning_rate": 0.0918938987813505,
      "loss": 3.2705,
      "step": 50440
    },
    {
      "epoch": 81.13,
      "learning_rate": 0.09189068335048232,
      "loss": 3.3443,
      "step": 50460
    },
    {
      "epoch": 81.16,
      "learning_rate": 0.09188746791961415,
      "loss": 3.3245,
      "step": 50480
    },
    {
      "epoch": 81.19,
      "learning_rate": 0.09188425248874599,
      "loss": 3.3102,
      "step": 50500
    },
    {
      "epoch": 81.22,
      "learning_rate": 0.09188103705787781,
      "loss": 3.2915,
      "step": 50520
    },
    {
      "epoch": 81.25,
      "learning_rate": 0.09187782162700965,
      "loss": 3.2505,
      "step": 50540
    },
    {
      "epoch": 81.29,
      "learning_rate": 0.09187460619614148,
      "loss": 3.2722,
      "step": 50560
    },
    {
      "epoch": 81.32,
      "learning_rate": 0.09187139076527331,
      "loss": 3.3103,
      "step": 50580
    },
    {
      "epoch": 81.35,
      "learning_rate": 0.09186817533440515,
      "loss": 3.3201,
      "step": 50600
    },
    {
      "epoch": 81.38,
      "learning_rate": 0.09186495990353698,
      "loss": 3.2944,
      "step": 50620
    },
    {
      "epoch": 81.41,
      "learning_rate": 0.09186174447266882,
      "loss": 3.3442,
      "step": 50640
    },
    {
      "epoch": 81.45,
      "learning_rate": 0.09185852904180064,
      "loss": 3.2778,
      "step": 50660
    },
    {
      "epoch": 81.48,
      "learning_rate": 0.09185531361093248,
      "loss": 3.2579,
      "step": 50680
    },
    {
      "epoch": 81.51,
      "learning_rate": 0.09185209818006432,
      "loss": 3.2442,
      "step": 50700
    },
    {
      "epoch": 81.54,
      "learning_rate": 0.09184888274919614,
      "loss": 3.2355,
      "step": 50720
    },
    {
      "epoch": 81.58,
      "learning_rate": 0.09184566731832798,
      "loss": 3.2762,
      "step": 50740
    },
    {
      "epoch": 81.61,
      "learning_rate": 0.0918424518874598,
      "loss": 3.2677,
      "step": 50760
    },
    {
      "epoch": 81.64,
      "learning_rate": 0.09183923645659164,
      "loss": 3.2575,
      "step": 50780
    },
    {
      "epoch": 81.67,
      "learning_rate": 0.09183602102572348,
      "loss": 3.2671,
      "step": 50800
    },
    {
      "epoch": 81.7,
      "learning_rate": 0.09183280559485531,
      "loss": 3.262,
      "step": 50820
    },
    {
      "epoch": 81.74,
      "learning_rate": 0.09182959016398715,
      "loss": 3.2369,
      "step": 50840
    },
    {
      "epoch": 81.77,
      "learning_rate": 0.09182637473311897,
      "loss": 3.2594,
      "step": 50860
    },
    {
      "epoch": 81.8,
      "learning_rate": 0.09182315930225081,
      "loss": 3.2568,
      "step": 50880
    },
    {
      "epoch": 81.83,
      "learning_rate": 0.09181994387138263,
      "loss": 3.2554,
      "step": 50900
    },
    {
      "epoch": 81.86,
      "learning_rate": 0.09181672844051447,
      "loss": 3.2486,
      "step": 50920
    },
    {
      "epoch": 81.9,
      "learning_rate": 0.09181351300964631,
      "loss": 3.2495,
      "step": 50940
    },
    {
      "epoch": 81.93,
      "learning_rate": 0.09181029757877814,
      "loss": 3.2691,
      "step": 50960
    },
    {
      "epoch": 81.96,
      "learning_rate": 0.09180708214790997,
      "loss": 3.2864,
      "step": 50980
    },
    {
      "epoch": 81.99,
      "learning_rate": 0.0918038667170418,
      "loss": 3.2636,
      "step": 51000
    },
    {
      "epoch": 82.0,
      "eval_accuracy": {
        "accuracy": 0.34323252740418253
      },
      "eval_loss": 3.3656158447265625,
      "eval_runtime": 2.6047,
      "eval_samples_per_second": 4938.328,
      "eval_steps_per_second": 77.167,
      "step": 51004
    },
    {
      "epoch": 82.03,
      "learning_rate": 0.09180065128617364,
      "loss": 3.2543,
      "step": 51020
    },
    {
      "epoch": 82.06,
      "learning_rate": 0.09179743585530548,
      "loss": 3.2721,
      "step": 51040
    },
    {
      "epoch": 82.09,
      "learning_rate": 0.0917942204244373,
      "loss": 3.2629,
      "step": 51060
    },
    {
      "epoch": 82.12,
      "learning_rate": 0.09179100499356914,
      "loss": 3.2574,
      "step": 51080
    },
    {
      "epoch": 82.15,
      "learning_rate": 0.09178778956270096,
      "loss": 3.2495,
      "step": 51100
    },
    {
      "epoch": 82.19,
      "learning_rate": 0.0917845741318328,
      "loss": 3.2815,
      "step": 51120
    },
    {
      "epoch": 82.22,
      "learning_rate": 0.09178135870096464,
      "loss": 3.2941,
      "step": 51140
    },
    {
      "epoch": 82.25,
      "learning_rate": 0.09177814327009647,
      "loss": 3.3432,
      "step": 51160
    },
    {
      "epoch": 82.28,
      "learning_rate": 0.0917749278392283,
      "loss": 3.2794,
      "step": 51180
    },
    {
      "epoch": 82.32,
      "learning_rate": 0.09177171240836013,
      "loss": 3.276,
      "step": 51200
    },
    {
      "epoch": 82.35,
      "learning_rate": 0.09176849697749197,
      "loss": 3.2887,
      "step": 51220
    },
    {
      "epoch": 82.38,
      "learning_rate": 0.0917652815466238,
      "loss": 3.3497,
      "step": 51240
    },
    {
      "epoch": 82.41,
      "learning_rate": 0.09176206611575563,
      "loss": 3.3393,
      "step": 51260
    },
    {
      "epoch": 82.44,
      "learning_rate": 0.09175885068488747,
      "loss": 3.3131,
      "step": 51280
    },
    {
      "epoch": 82.48,
      "learning_rate": 0.0917556352540193,
      "loss": 3.2771,
      "step": 51300
    },
    {
      "epoch": 82.51,
      "learning_rate": 0.09175241982315113,
      "loss": 3.2887,
      "step": 51320
    },
    {
      "epoch": 82.54,
      "learning_rate": 0.09174920439228296,
      "loss": 3.2524,
      "step": 51340
    },
    {
      "epoch": 82.57,
      "learning_rate": 0.0917459889614148,
      "loss": 3.2857,
      "step": 51360
    },
    {
      "epoch": 82.6,
      "learning_rate": 0.09174277353054663,
      "loss": 3.2823,
      "step": 51380
    },
    {
      "epoch": 82.64,
      "learning_rate": 0.09173955809967846,
      "loss": 3.2609,
      "step": 51400
    },
    {
      "epoch": 82.67,
      "learning_rate": 0.0917363426688103,
      "loss": 3.2708,
      "step": 51420
    },
    {
      "epoch": 82.7,
      "learning_rate": 0.09173312723794212,
      "loss": 3.3045,
      "step": 51440
    },
    {
      "epoch": 82.73,
      "learning_rate": 0.09172991180707396,
      "loss": 3.2967,
      "step": 51460
    },
    {
      "epoch": 82.77,
      "learning_rate": 0.0917266963762058,
      "loss": 3.2288,
      "step": 51480
    },
    {
      "epoch": 82.8,
      "learning_rate": 0.09172348094533762,
      "loss": 3.2259,
      "step": 51500
    },
    {
      "epoch": 82.83,
      "learning_rate": 0.09172026551446946,
      "loss": 3.2676,
      "step": 51520
    },
    {
      "epoch": 82.86,
      "learning_rate": 0.09171705008360129,
      "loss": 3.2494,
      "step": 51540
    },
    {
      "epoch": 82.89,
      "learning_rate": 0.09171383465273313,
      "loss": 3.2584,
      "step": 51560
    },
    {
      "epoch": 82.93,
      "learning_rate": 0.09171061922186496,
      "loss": 3.2654,
      "step": 51580
    },
    {
      "epoch": 82.96,
      "learning_rate": 0.09170740379099679,
      "loss": 3.2845,
      "step": 51600
    },
    {
      "epoch": 82.99,
      "learning_rate": 0.09170418836012863,
      "loss": 3.3675,
      "step": 51620
    },
    {
      "epoch": 83.0,
      "eval_accuracy": {
        "accuracy": 0.34408769338412504
      },
      "eval_loss": 3.441086769104004,
      "eval_runtime": 3.0215,
      "eval_samples_per_second": 4257.221,
      "eval_steps_per_second": 66.524,
      "step": 51626
    },
    {
      "epoch": 83.02,
      "learning_rate": 0.09170097292926045,
      "loss": 3.3209,
      "step": 51640
    },
    {
      "epoch": 83.05,
      "learning_rate": 0.09169775749839229,
      "loss": 3.3067,
      "step": 51660
    },
    {
      "epoch": 83.09,
      "learning_rate": 0.09169454206752412,
      "loss": 3.1814,
      "step": 51680
    },
    {
      "epoch": 83.12,
      "learning_rate": 0.09169132663665595,
      "loss": 3.2306,
      "step": 51700
    },
    {
      "epoch": 83.15,
      "learning_rate": 0.09168811120578779,
      "loss": 3.2871,
      "step": 51720
    },
    {
      "epoch": 83.18,
      "learning_rate": 0.09168489577491962,
      "loss": 3.3356,
      "step": 51740
    },
    {
      "epoch": 83.22,
      "learning_rate": 0.09168168034405146,
      "loss": 3.2938,
      "step": 51760
    },
    {
      "epoch": 83.25,
      "learning_rate": 0.09167846491318328,
      "loss": 3.2496,
      "step": 51780
    },
    {
      "epoch": 83.28,
      "learning_rate": 0.09167524948231512,
      "loss": 3.2621,
      "step": 51800
    },
    {
      "epoch": 83.31,
      "learning_rate": 0.09167203405144696,
      "loss": 3.2376,
      "step": 51820
    },
    {
      "epoch": 83.34,
      "learning_rate": 0.09166881862057878,
      "loss": 3.2261,
      "step": 51840
    },
    {
      "epoch": 83.38,
      "learning_rate": 0.09166560318971062,
      "loss": 3.2538,
      "step": 51860
    },
    {
      "epoch": 83.41,
      "learning_rate": 0.09166238775884245,
      "loss": 3.3496,
      "step": 51880
    },
    {
      "epoch": 83.44,
      "learning_rate": 0.09165917232797428,
      "loss": 3.2524,
      "step": 51900
    },
    {
      "epoch": 83.47,
      "learning_rate": 0.09165595689710612,
      "loss": 3.2659,
      "step": 51920
    },
    {
      "epoch": 83.5,
      "learning_rate": 0.09165274146623795,
      "loss": 3.1807,
      "step": 51940
    },
    {
      "epoch": 83.54,
      "learning_rate": 0.09164952603536979,
      "loss": 3.2403,
      "step": 51960
    },
    {
      "epoch": 83.57,
      "learning_rate": 0.09164631060450161,
      "loss": 3.2459,
      "step": 51980
    },
    {
      "epoch": 83.6,
      "learning_rate": 0.09164309517363345,
      "loss": 3.2433,
      "step": 52000
    },
    {
      "epoch": 83.63,
      "learning_rate": 0.09163987974276527,
      "loss": 3.2775,
      "step": 52020
    },
    {
      "epoch": 83.67,
      "learning_rate": 0.09163666431189711,
      "loss": 3.2681,
      "step": 52040
    },
    {
      "epoch": 83.7,
      "learning_rate": 0.09163344888102895,
      "loss": 3.2435,
      "step": 52060
    },
    {
      "epoch": 83.73,
      "learning_rate": 0.09163023345016078,
      "loss": 3.2284,
      "step": 52080
    },
    {
      "epoch": 83.76,
      "learning_rate": 0.09162701801929261,
      "loss": 3.2476,
      "step": 52100
    },
    {
      "epoch": 83.79,
      "learning_rate": 0.09162380258842444,
      "loss": 3.2908,
      "step": 52120
    },
    {
      "epoch": 83.83,
      "learning_rate": 0.09162058715755628,
      "loss": 3.3181,
      "step": 52140
    },
    {
      "epoch": 83.86,
      "learning_rate": 0.09161737172668812,
      "loss": 3.268,
      "step": 52160
    },
    {
      "epoch": 83.89,
      "learning_rate": 0.09161415629581994,
      "loss": 3.2621,
      "step": 52180
    },
    {
      "epoch": 83.92,
      "learning_rate": 0.09161094086495178,
      "loss": 3.2852,
      "step": 52200
    },
    {
      "epoch": 83.95,
      "learning_rate": 0.0916077254340836,
      "loss": 3.3081,
      "step": 52220
    },
    {
      "epoch": 83.99,
      "learning_rate": 0.09160451000321543,
      "loss": 3.2426,
      "step": 52240
    },
    {
      "epoch": 84.0,
      "eval_accuracy": {
        "accuracy": 0.3428438155951178
      },
      "eval_loss": 3.3532156944274902,
      "eval_runtime": 2.9115,
      "eval_samples_per_second": 4417.924,
      "eval_steps_per_second": 69.035,
      "step": 52248
    },
    {
      "epoch": 84.02,
      "learning_rate": 0.09160129457234728,
      "loss": 3.2494,
      "step": 52260
    },
    {
      "epoch": 84.05,
      "learning_rate": 0.0915980791414791,
      "loss": 3.2261,
      "step": 52280
    },
    {
      "epoch": 84.08,
      "learning_rate": 0.09159486371061094,
      "loss": 3.2184,
      "step": 52300
    },
    {
      "epoch": 84.12,
      "learning_rate": 0.09159164827974277,
      "loss": 3.2752,
      "step": 52320
    },
    {
      "epoch": 84.15,
      "learning_rate": 0.0915884328488746,
      "loss": 3.2978,
      "step": 52340
    },
    {
      "epoch": 84.18,
      "learning_rate": 0.09158521741800643,
      "loss": 3.2942,
      "step": 52360
    },
    {
      "epoch": 84.21,
      "learning_rate": 0.09158200198713827,
      "loss": 3.2707,
      "step": 52380
    },
    {
      "epoch": 84.24,
      "learning_rate": 0.09157878655627011,
      "loss": 3.2287,
      "step": 52400
    },
    {
      "epoch": 84.28,
      "learning_rate": 0.09157557112540193,
      "loss": 3.2669,
      "step": 52420
    },
    {
      "epoch": 84.31,
      "learning_rate": 0.09157235569453377,
      "loss": 3.2145,
      "step": 52440
    },
    {
      "epoch": 84.34,
      "learning_rate": 0.0915691402636656,
      "loss": 3.2497,
      "step": 52460
    },
    {
      "epoch": 84.37,
      "learning_rate": 0.09156592483279744,
      "loss": 3.2758,
      "step": 52480
    },
    {
      "epoch": 84.41,
      "learning_rate": 0.09156270940192927,
      "loss": 3.3122,
      "step": 52500
    },
    {
      "epoch": 84.44,
      "learning_rate": 0.0915594939710611,
      "loss": 3.2654,
      "step": 52520
    },
    {
      "epoch": 84.47,
      "learning_rate": 0.09155627854019294,
      "loss": 3.281,
      "step": 52540
    },
    {
      "epoch": 84.5,
      "learning_rate": 0.09155306310932476,
      "loss": 3.2602,
      "step": 52560
    },
    {
      "epoch": 84.53,
      "learning_rate": 0.09154984767845659,
      "loss": 3.2279,
      "step": 52580
    },
    {
      "epoch": 84.57,
      "learning_rate": 0.09154663224758844,
      "loss": 3.2313,
      "step": 52600
    },
    {
      "epoch": 84.6,
      "learning_rate": 0.09154341681672026,
      "loss": 3.2487,
      "step": 52620
    },
    {
      "epoch": 84.63,
      "learning_rate": 0.0915402013858521,
      "loss": 3.2467,
      "step": 52640
    },
    {
      "epoch": 84.66,
      "learning_rate": 0.09153698595498393,
      "loss": 3.2316,
      "step": 52660
    },
    {
      "epoch": 84.69,
      "learning_rate": 0.09153377052411575,
      "loss": 3.2646,
      "step": 52680
    },
    {
      "epoch": 84.73,
      "learning_rate": 0.09153055509324759,
      "loss": 3.229,
      "step": 52700
    },
    {
      "epoch": 84.76,
      "learning_rate": 0.09152733966237943,
      "loss": 3.1927,
      "step": 52720
    },
    {
      "epoch": 84.79,
      "learning_rate": 0.09152412423151127,
      "loss": 3.283,
      "step": 52740
    },
    {
      "epoch": 84.82,
      "learning_rate": 0.09152090880064309,
      "loss": 3.2976,
      "step": 52760
    },
    {
      "epoch": 84.86,
      "learning_rate": 0.09151769336977492,
      "loss": 3.262,
      "step": 52780
    },
    {
      "epoch": 84.89,
      "learning_rate": 0.09151447793890675,
      "loss": 3.2199,
      "step": 52800
    },
    {
      "epoch": 84.92,
      "learning_rate": 0.0915112625080386,
      "loss": 3.2428,
      "step": 52820
    },
    {
      "epoch": 84.95,
      "learning_rate": 0.09150804707717043,
      "loss": 3.2863,
      "step": 52840
    },
    {
      "epoch": 84.98,
      "learning_rate": 0.09150483164630226,
      "loss": 3.2815,
      "step": 52860
    },
    {
      "epoch": 85.0,
      "eval_accuracy": {
        "accuracy": 0.33234859675036926
      },
      "eval_loss": 3.384779453277588,
      "eval_runtime": 2.8018,
      "eval_samples_per_second": 4590.927,
      "eval_steps_per_second": 71.739,
      "step": 52870
    },
    {
      "epoch": 85.02,
      "learning_rate": 0.09150161621543408,
      "loss": 3.2956,
      "step": 52880
    },
    {
      "epoch": 85.05,
      "learning_rate": 0.09149840078456592,
      "loss": 3.2479,
      "step": 52900
    },
    {
      "epoch": 85.08,
      "learning_rate": 0.09149518535369776,
      "loss": 3.2961,
      "step": 52920
    },
    {
      "epoch": 85.11,
      "learning_rate": 0.0914919699228296,
      "loss": 3.2781,
      "step": 52940
    },
    {
      "epoch": 85.14,
      "learning_rate": 0.09148875449196142,
      "loss": 3.2584,
      "step": 52960
    },
    {
      "epoch": 85.18,
      "learning_rate": 0.09148553906109326,
      "loss": 3.2917,
      "step": 52980
    },
    {
      "epoch": 85.21,
      "learning_rate": 0.09148232363022508,
      "loss": 3.2584,
      "step": 53000
    },
    {
      "epoch": 85.24,
      "learning_rate": 0.09147910819935691,
      "loss": 3.2071,
      "step": 53020
    },
    {
      "epoch": 85.27,
      "learning_rate": 0.09147589276848875,
      "loss": 3.2586,
      "step": 53040
    },
    {
      "epoch": 85.31,
      "learning_rate": 0.09147267733762059,
      "loss": 3.2882,
      "step": 53060
    },
    {
      "epoch": 85.34,
      "learning_rate": 0.09146946190675243,
      "loss": 3.2878,
      "step": 53080
    },
    {
      "epoch": 85.37,
      "learning_rate": 0.09146640724742766,
      "loss": 3.2695,
      "step": 53100
    },
    {
      "epoch": 85.4,
      "learning_rate": 0.09146319181655949,
      "loss": 3.2725,
      "step": 53120
    },
    {
      "epoch": 85.43,
      "learning_rate": 0.09145997638569132,
      "loss": 3.2431,
      "step": 53140
    },
    {
      "epoch": 85.47,
      "learning_rate": 0.09145676095482315,
      "loss": 3.2533,
      "step": 53160
    },
    {
      "epoch": 85.5,
      "learning_rate": 0.091453545523955,
      "loss": 3.2439,
      "step": 53180
    },
    {
      "epoch": 85.53,
      "learning_rate": 0.09145033009308683,
      "loss": 3.2257,
      "step": 53200
    },
    {
      "epoch": 85.56,
      "learning_rate": 0.09144711466221865,
      "loss": 3.2326,
      "step": 53220
    },
    {
      "epoch": 85.59,
      "learning_rate": 0.09144389923135049,
      "loss": 3.2566,
      "step": 53240
    },
    {
      "epoch": 85.63,
      "learning_rate": 0.09144068380048231,
      "loss": 3.2407,
      "step": 53260
    },
    {
      "epoch": 85.66,
      "learning_rate": 0.09143746836961415,
      "loss": 3.2752,
      "step": 53280
    },
    {
      "epoch": 85.69,
      "learning_rate": 0.09143425293874598,
      "loss": 3.2891,
      "step": 53300
    },
    {
      "epoch": 85.72,
      "learning_rate": 0.09143103750787782,
      "loss": 3.2817,
      "step": 53320
    },
    {
      "epoch": 85.76,
      "learning_rate": 0.09142782207700965,
      "loss": 3.2542,
      "step": 53340
    },
    {
      "epoch": 85.79,
      "learning_rate": 0.09142460664614148,
      "loss": 3.2171,
      "step": 53360
    },
    {
      "epoch": 85.82,
      "learning_rate": 0.09142139121527332,
      "loss": 3.2088,
      "step": 53380
    },
    {
      "epoch": 85.85,
      "learning_rate": 0.09141817578440514,
      "loss": 3.2183,
      "step": 53400
    },
    {
      "epoch": 85.88,
      "learning_rate": 0.09141496035353698,
      "loss": 3.2545,
      "step": 53420
    },
    {
      "epoch": 85.92,
      "learning_rate": 0.09141174492266882,
      "loss": 3.284,
      "step": 53440
    },
    {
      "epoch": 85.95,
      "learning_rate": 0.09140852949180064,
      "loss": 3.2921,
      "step": 53460
    },
    {
      "epoch": 85.98,
      "learning_rate": 0.09140531406093248,
      "loss": 3.3681,
      "step": 53480
    },
    {
      "epoch": 86.0,
      "eval_accuracy": {
        "accuracy": 0.34641996423851357
      },
      "eval_loss": 3.363407611846924,
      "eval_runtime": 2.7575,
      "eval_samples_per_second": 4664.768,
      "eval_steps_per_second": 72.893,
      "step": 53492
    },
    {
      "epoch": 86.01,
      "learning_rate": 0.09140209863006431,
      "loss": 3.3423,
      "step": 53500
    },
    {
      "epoch": 86.05,
      "learning_rate": 0.09139888319919615,
      "loss": 3.2477,
      "step": 53520
    },
    {
      "epoch": 86.08,
      "learning_rate": 0.09139566776832798,
      "loss": 3.2796,
      "step": 53540
    },
    {
      "epoch": 86.11,
      "learning_rate": 0.09139245233745981,
      "loss": 3.2847,
      "step": 53560
    },
    {
      "epoch": 86.14,
      "learning_rate": 0.09138923690659165,
      "loss": 3.285,
      "step": 53580
    },
    {
      "epoch": 86.17,
      "learning_rate": 0.09138602147572347,
      "loss": 3.2352,
      "step": 53600
    },
    {
      "epoch": 86.21,
      "learning_rate": 0.09138280604485531,
      "loss": 3.2436,
      "step": 53620
    },
    {
      "epoch": 86.24,
      "learning_rate": 0.09137959061398715,
      "loss": 3.2674,
      "step": 53640
    },
    {
      "epoch": 86.27,
      "learning_rate": 0.09137637518311897,
      "loss": 3.2301,
      "step": 53660
    },
    {
      "epoch": 86.3,
      "learning_rate": 0.09137315975225081,
      "loss": 3.2689,
      "step": 53680
    },
    {
      "epoch": 86.33,
      "learning_rate": 0.09136994432138264,
      "loss": 3.2763,
      "step": 53700
    },
    {
      "epoch": 86.37,
      "learning_rate": 0.09136672889051448,
      "loss": 3.2752,
      "step": 53720
    },
    {
      "epoch": 86.4,
      "learning_rate": 0.0913635134596463,
      "loss": 3.3381,
      "step": 53740
    },
    {
      "epoch": 86.43,
      "learning_rate": 0.09136029802877814,
      "loss": 3.2589,
      "step": 53760
    },
    {
      "epoch": 86.46,
      "learning_rate": 0.09135708259790998,
      "loss": 3.2331,
      "step": 53780
    },
    {
      "epoch": 86.5,
      "learning_rate": 0.0913538671670418,
      "loss": 3.2743,
      "step": 53800
    },
    {
      "epoch": 86.53,
      "learning_rate": 0.09135065173617364,
      "loss": 3.2482,
      "step": 53820
    },
    {
      "epoch": 86.56,
      "learning_rate": 0.09134743630530547,
      "loss": 3.2554,
      "step": 53840
    },
    {
      "epoch": 86.59,
      "learning_rate": 0.0913442208744373,
      "loss": 3.3152,
      "step": 53860
    },
    {
      "epoch": 86.62,
      "learning_rate": 0.09134100544356914,
      "loss": 3.265,
      "step": 53880
    },
    {
      "epoch": 86.66,
      "learning_rate": 0.09133779001270097,
      "loss": 3.2703,
      "step": 53900
    },
    {
      "epoch": 86.69,
      "learning_rate": 0.0913345745818328,
      "loss": 3.2476,
      "step": 53920
    },
    {
      "epoch": 86.72,
      "learning_rate": 0.09133135915096463,
      "loss": 3.2318,
      "step": 53940
    },
    {
      "epoch": 86.75,
      "learning_rate": 0.09132814372009647,
      "loss": 3.2713,
      "step": 53960
    },
    {
      "epoch": 86.78,
      "learning_rate": 0.09132492828922831,
      "loss": 3.2362,
      "step": 53980
    },
    {
      "epoch": 86.82,
      "learning_rate": 0.09132171285836013,
      "loss": 3.241,
      "step": 54000
    },
    {
      "epoch": 86.85,
      "learning_rate": 0.09131849742749197,
      "loss": 3.2913,
      "step": 54020
    },
    {
      "epoch": 86.88,
      "learning_rate": 0.0913152819966238,
      "loss": 3.2666,
      "step": 54040
    },
    {
      "epoch": 86.91,
      "learning_rate": 0.09131206656575563,
      "loss": 3.2434,
      "step": 54060
    },
    {
      "epoch": 86.95,
      "learning_rate": 0.09130885113488746,
      "loss": 3.2655,
      "step": 54080
    },
    {
      "epoch": 86.98,
      "learning_rate": 0.0913056357040193,
      "loss": 3.2583,
      "step": 54100
    },
    {
      "epoch": 87.0,
      "eval_accuracy": {
        "accuracy": 0.34789706911295964
      },
      "eval_loss": 3.277911424636841,
      "eval_runtime": 2.9567,
      "eval_samples_per_second": 4350.459,
      "eval_steps_per_second": 67.981,
      "step": 54114
    },
    {
      "epoch": 87.01,
      "learning_rate": 0.09130242027315114,
      "loss": 3.2226,
      "step": 54120
    },
    {
      "epoch": 87.04,
      "learning_rate": 0.09129920484228296,
      "loss": 3.2475,
      "step": 54140
    },
    {
      "epoch": 87.07,
      "learning_rate": 0.0912959894114148,
      "loss": 3.2157,
      "step": 54160
    },
    {
      "epoch": 87.11,
      "learning_rate": 0.09129277398054662,
      "loss": 3.2514,
      "step": 54180
    },
    {
      "epoch": 87.14,
      "learning_rate": 0.09128955854967846,
      "loss": 3.234,
      "step": 54200
    },
    {
      "epoch": 87.17,
      "learning_rate": 0.0912863431188103,
      "loss": 3.2322,
      "step": 54220
    },
    {
      "epoch": 87.2,
      "learning_rate": 0.09128312768794213,
      "loss": 3.2492,
      "step": 54240
    },
    {
      "epoch": 87.23,
      "learning_rate": 0.09127991225707396,
      "loss": 3.1814,
      "step": 54260
    },
    {
      "epoch": 87.27,
      "learning_rate": 0.09127669682620579,
      "loss": 3.2013,
      "step": 54280
    },
    {
      "epoch": 87.3,
      "learning_rate": 0.09127348139533763,
      "loss": 3.2428,
      "step": 54300
    },
    {
      "epoch": 87.33,
      "learning_rate": 0.09127026596446947,
      "loss": 3.2618,
      "step": 54320
    },
    {
      "epoch": 87.36,
      "learning_rate": 0.09126705053360129,
      "loss": 3.2447,
      "step": 54340
    },
    {
      "epoch": 87.4,
      "learning_rate": 0.09126383510273313,
      "loss": 3.2671,
      "step": 54360
    },
    {
      "epoch": 87.43,
      "learning_rate": 0.09126061967186495,
      "loss": 3.282,
      "step": 54380
    },
    {
      "epoch": 87.46,
      "learning_rate": 0.09125740424099679,
      "loss": 3.2813,
      "step": 54400
    },
    {
      "epoch": 87.49,
      "learning_rate": 0.09125418881012862,
      "loss": 3.2709,
      "step": 54420
    },
    {
      "epoch": 87.52,
      "learning_rate": 0.09125097337926046,
      "loss": 3.2297,
      "step": 54440
    },
    {
      "epoch": 87.56,
      "learning_rate": 0.0912477579483923,
      "loss": 3.2549,
      "step": 54460
    },
    {
      "epoch": 87.59,
      "learning_rate": 0.09124454251752412,
      "loss": 3.2293,
      "step": 54480
    },
    {
      "epoch": 87.62,
      "learning_rate": 0.09124132708665596,
      "loss": 3.2598,
      "step": 54500
    },
    {
      "epoch": 87.65,
      "learning_rate": 0.09123811165578778,
      "loss": 3.2768,
      "step": 54520
    },
    {
      "epoch": 87.68,
      "learning_rate": 0.09123489622491962,
      "loss": 3.2377,
      "step": 54540
    },
    {
      "epoch": 87.72,
      "learning_rate": 0.09123168079405146,
      "loss": 3.2151,
      "step": 54560
    },
    {
      "epoch": 87.75,
      "learning_rate": 0.09122846536318328,
      "loss": 3.2987,
      "step": 54580
    },
    {
      "epoch": 87.78,
      "learning_rate": 0.09122524993231512,
      "loss": 3.2385,
      "step": 54600
    },
    {
      "epoch": 87.81,
      "learning_rate": 0.09122203450144695,
      "loss": 3.2283,
      "step": 54620
    },
    {
      "epoch": 87.85,
      "learning_rate": 0.09121881907057879,
      "loss": 3.2743,
      "step": 54640
    },
    {
      "epoch": 87.88,
      "learning_rate": 0.09121560363971062,
      "loss": 3.3004,
      "step": 54660
    },
    {
      "epoch": 87.91,
      "learning_rate": 0.09121238820884245,
      "loss": 3.2987,
      "step": 54680
    },
    {
      "epoch": 87.94,
      "learning_rate": 0.09120917277797429,
      "loss": 3.2736,
      "step": 54700
    },
    {
      "epoch": 87.97,
      "learning_rate": 0.09120595734710611,
      "loss": 3.2764,
      "step": 54720
    },
    {
      "epoch": 88.0,
      "eval_accuracy": {
        "accuracy": 0.35022933996734823
      },
      "eval_loss": 3.292405843734741,
      "eval_runtime": 2.9997,
      "eval_samples_per_second": 4288.048,
      "eval_steps_per_second": 67.006,
      "step": 54736
    },
    {
      "epoch": 88.01,
      "learning_rate": 0.09120274191623795,
      "loss": 3.2358,
      "step": 54740
    },
    {
      "epoch": 88.04,
      "learning_rate": 0.09119952648536978,
      "loss": 3.2205,
      "step": 54760
    },
    {
      "epoch": 88.07,
      "learning_rate": 0.09119631105450161,
      "loss": 3.196,
      "step": 54780
    },
    {
      "epoch": 88.1,
      "learning_rate": 0.09119309562363345,
      "loss": 3.2342,
      "step": 54800
    },
    {
      "epoch": 88.14,
      "learning_rate": 0.09118988019276528,
      "loss": 3.225,
      "step": 54820
    },
    {
      "epoch": 88.17,
      "learning_rate": 0.09118666476189712,
      "loss": 3.2084,
      "step": 54840
    },
    {
      "epoch": 88.2,
      "learning_rate": 0.09118344933102894,
      "loss": 3.2769,
      "step": 54860
    },
    {
      "epoch": 88.23,
      "learning_rate": 0.09118023390016078,
      "loss": 3.3058,
      "step": 54880
    },
    {
      "epoch": 88.26,
      "learning_rate": 0.09117701846929262,
      "loss": 3.2358,
      "step": 54900
    },
    {
      "epoch": 88.3,
      "learning_rate": 0.09117380303842444,
      "loss": 3.1769,
      "step": 54920
    },
    {
      "epoch": 88.33,
      "learning_rate": 0.09117058760755628,
      "loss": 3.2028,
      "step": 54940
    },
    {
      "epoch": 88.36,
      "learning_rate": 0.0911673721766881,
      "loss": 3.2592,
      "step": 54960
    },
    {
      "epoch": 88.39,
      "learning_rate": 0.09116415674581993,
      "loss": 3.2699,
      "step": 54980
    },
    {
      "epoch": 88.42,
      "learning_rate": 0.09116094131495178,
      "loss": 3.259,
      "step": 55000
    },
    {
      "epoch": 88.46,
      "learning_rate": 0.0911577258840836,
      "loss": 3.3245,
      "step": 55020
    },
    {
      "epoch": 88.49,
      "learning_rate": 0.09115451045321545,
      "loss": 3.2948,
      "step": 55040
    },
    {
      "epoch": 88.52,
      "learning_rate": 0.09115129502234727,
      "loss": 3.2431,
      "step": 55060
    },
    {
      "epoch": 88.55,
      "learning_rate": 0.0911480795914791,
      "loss": 3.2576,
      "step": 55080
    },
    {
      "epoch": 88.59,
      "learning_rate": 0.09114486416061093,
      "loss": 3.2727,
      "step": 55100
    },
    {
      "epoch": 88.62,
      "learning_rate": 0.09114164872974277,
      "loss": 3.2556,
      "step": 55120
    },
    {
      "epoch": 88.65,
      "learning_rate": 0.09113843329887461,
      "loss": 3.2318,
      "step": 55140
    },
    {
      "epoch": 88.68,
      "learning_rate": 0.09113521786800644,
      "loss": 3.2955,
      "step": 55160
    },
    {
      "epoch": 88.71,
      "learning_rate": 0.09113200243713827,
      "loss": 3.2312,
      "step": 55180
    },
    {
      "epoch": 88.75,
      "learning_rate": 0.0911287870062701,
      "loss": 3.2717,
      "step": 55200
    },
    {
      "epoch": 88.78,
      "learning_rate": 0.09112557157540194,
      "loss": 3.3064,
      "step": 55220
    },
    {
      "epoch": 88.81,
      "learning_rate": 0.09112235614453378,
      "loss": 3.3206,
      "step": 55240
    },
    {
      "epoch": 88.84,
      "learning_rate": 0.0911191407136656,
      "loss": 3.2838,
      "step": 55260
    },
    {
      "epoch": 88.87,
      "learning_rate": 0.09111592528279744,
      "loss": 3.2707,
      "step": 55280
    },
    {
      "epoch": 88.91,
      "learning_rate": 0.09111270985192926,
      "loss": 3.2519,
      "step": 55300
    },
    {
      "epoch": 88.94,
      "learning_rate": 0.0911094944210611,
      "loss": 3.2371,
      "step": 55320
    },
    {
      "epoch": 88.97,
      "learning_rate": 0.09110627899019294,
      "loss": 3.2437,
      "step": 55340
    },
    {
      "epoch": 89.0,
      "eval_accuracy": {
        "accuracy": 0.3434657544896214
      },
      "eval_loss": 3.354532480239868,
      "eval_runtime": 2.475,
      "eval_samples_per_second": 5197.208,
      "eval_steps_per_second": 81.213,
      "step": 55358
    },
    {
      "epoch": 89.0,
      "learning_rate": 0.09110306355932477,
      "loss": 3.2515,
      "step": 55360
    },
    {
      "epoch": 89.04,
      "learning_rate": 0.0910998481284566,
      "loss": 3.2291,
      "step": 55380
    },
    {
      "epoch": 89.07,
      "learning_rate": 0.09109663269758843,
      "loss": 3.2397,
      "step": 55400
    },
    {
      "epoch": 89.1,
      "learning_rate": 0.09109341726672025,
      "loss": 3.2304,
      "step": 55420
    },
    {
      "epoch": 89.13,
      "learning_rate": 0.09109020183585209,
      "loss": 3.1346,
      "step": 55440
    },
    {
      "epoch": 89.16,
      "learning_rate": 0.09108698640498393,
      "loss": 3.2304,
      "step": 55460
    },
    {
      "epoch": 89.2,
      "learning_rate": 0.09108377097411577,
      "loss": 3.223,
      "step": 55480
    },
    {
      "epoch": 89.23,
      "learning_rate": 0.0910805555432476,
      "loss": 3.2086,
      "step": 55500
    },
    {
      "epoch": 89.26,
      "learning_rate": 0.09107750088392283,
      "loss": 3.2233,
      "step": 55520
    },
    {
      "epoch": 89.29,
      "learning_rate": 0.09107428545305467,
      "loss": 3.2844,
      "step": 55540
    },
    {
      "epoch": 89.32,
      "learning_rate": 0.09107107002218649,
      "loss": 3.2344,
      "step": 55560
    },
    {
      "epoch": 89.36,
      "learning_rate": 0.09106785459131835,
      "loss": 3.206,
      "step": 55580
    },
    {
      "epoch": 89.39,
      "learning_rate": 0.09106463916045017,
      "loss": 3.256,
      "step": 55600
    },
    {
      "epoch": 89.42,
      "learning_rate": 0.091061423729582,
      "loss": 3.2698,
      "step": 55620
    },
    {
      "epoch": 89.45,
      "learning_rate": 0.09105820829871383,
      "loss": 3.2991,
      "step": 55640
    },
    {
      "epoch": 89.49,
      "learning_rate": 0.09105499286784566,
      "loss": 3.2564,
      "step": 55660
    },
    {
      "epoch": 89.52,
      "learning_rate": 0.0910517774369775,
      "loss": 3.25,
      "step": 55680
    },
    {
      "epoch": 89.55,
      "learning_rate": 0.09104856200610932,
      "loss": 3.1907,
      "step": 55700
    },
    {
      "epoch": 89.58,
      "learning_rate": 0.09104534657524116,
      "loss": 3.2202,
      "step": 55720
    },
    {
      "epoch": 89.61,
      "learning_rate": 0.091042131144373,
      "loss": 3.2384,
      "step": 55740
    },
    {
      "epoch": 89.65,
      "learning_rate": 0.09103891571350482,
      "loss": 3.256,
      "step": 55760
    },
    {
      "epoch": 89.68,
      "learning_rate": 0.09103570028263666,
      "loss": 3.2273,
      "step": 55780
    },
    {
      "epoch": 89.71,
      "learning_rate": 0.09103248485176849,
      "loss": 3.383,
      "step": 55800
    },
    {
      "epoch": 89.74,
      "learning_rate": 0.09102926942090032,
      "loss": 3.4052,
      "step": 55820
    },
    {
      "epoch": 89.77,
      "learning_rate": 0.09102605399003216,
      "loss": 3.278,
      "step": 55840
    },
    {
      "epoch": 89.81,
      "learning_rate": 0.09102283855916399,
      "loss": 3.2927,
      "step": 55860
    },
    {
      "epoch": 89.84,
      "learning_rate": 0.09101962312829583,
      "loss": 3.2438,
      "step": 55880
    },
    {
      "epoch": 89.87,
      "learning_rate": 0.09101640769742765,
      "loss": 3.278,
      "step": 55900
    },
    {
      "epoch": 89.9,
      "learning_rate": 0.0910131922665595,
      "loss": 3.2728,
      "step": 55920
    },
    {
      "epoch": 89.94,
      "learning_rate": 0.09100997683569133,
      "loss": 3.2383,
      "step": 55940
    },
    {
      "epoch": 89.97,
      "learning_rate": 0.09100676140482315,
      "loss": 3.2022,
      "step": 55960
    },
    {
      "epoch": 90.0,
      "learning_rate": 0.09100354597395499,
      "loss": 3.2378,
      "step": 55980
    },
    {
      "epoch": 90.0,
      "eval_accuracy": {
        "accuracy": 0.34626447951488765
      },
      "eval_loss": 3.3472824096679688,
      "eval_runtime": 2.4563,
      "eval_samples_per_second": 5236.795,
      "eval_steps_per_second": 81.831,
      "step": 55980
    },
    {
      "epoch": 90.03,
      "learning_rate": 0.09100033054308682,
      "loss": 3.2504,
      "step": 56000
    },
    {
      "epoch": 90.06,
      "learning_rate": 0.09099711511221865,
      "loss": 3.2079,
      "step": 56020
    },
    {
      "epoch": 90.1,
      "learning_rate": 0.09099389968135048,
      "loss": 3.2241,
      "step": 56040
    },
    {
      "epoch": 90.13,
      "learning_rate": 0.09099068425048232,
      "loss": 3.2578,
      "step": 56060
    },
    {
      "epoch": 90.16,
      "learning_rate": 0.09098746881961416,
      "loss": 3.2767,
      "step": 56080
    },
    {
      "epoch": 90.19,
      "learning_rate": 0.09098425338874598,
      "loss": 3.24,
      "step": 56100
    },
    {
      "epoch": 90.23,
      "learning_rate": 0.09098103795787782,
      "loss": 3.2039,
      "step": 56120
    },
    {
      "epoch": 90.26,
      "learning_rate": 0.09097782252700964,
      "loss": 3.2161,
      "step": 56140
    },
    {
      "epoch": 90.29,
      "learning_rate": 0.09097460709614148,
      "loss": 3.2398,
      "step": 56160
    },
    {
      "epoch": 90.32,
      "learning_rate": 0.09097139166527332,
      "loss": 3.2344,
      "step": 56180
    },
    {
      "epoch": 90.35,
      "learning_rate": 0.09096817623440515,
      "loss": 3.2662,
      "step": 56200
    },
    {
      "epoch": 90.39,
      "learning_rate": 0.09096496080353698,
      "loss": 3.2731,
      "step": 56220
    },
    {
      "epoch": 90.42,
      "learning_rate": 0.09096174537266881,
      "loss": 3.2534,
      "step": 56240
    },
    {
      "epoch": 90.45,
      "learning_rate": 0.09095852994180065,
      "loss": 3.2052,
      "step": 56260
    },
    {
      "epoch": 90.48,
      "learning_rate": 0.09095531451093249,
      "loss": 3.2323,
      "step": 56280
    },
    {
      "epoch": 90.51,
      "learning_rate": 0.09095209908006431,
      "loss": 3.2665,
      "step": 56300
    },
    {
      "epoch": 90.55,
      "learning_rate": 0.09094888364919615,
      "loss": 3.2492,
      "step": 56320
    },
    {
      "epoch": 90.58,
      "learning_rate": 0.09094566821832797,
      "loss": 3.2078,
      "step": 56340
    },
    {
      "epoch": 90.61,
      "learning_rate": 0.09094245278745981,
      "loss": 3.2243,
      "step": 56360
    },
    {
      "epoch": 90.64,
      "learning_rate": 0.09093923735659165,
      "loss": 3.2313,
      "step": 56380
    },
    {
      "epoch": 90.68,
      "learning_rate": 0.09093602192572348,
      "loss": 3.2564,
      "step": 56400
    },
    {
      "epoch": 90.71,
      "learning_rate": 0.09093280649485531,
      "loss": 3.2772,
      "step": 56420
    },
    {
      "epoch": 90.74,
      "learning_rate": 0.09092959106398714,
      "loss": 3.2216,
      "step": 56440
    },
    {
      "epoch": 90.77,
      "learning_rate": 0.09092637563311898,
      "loss": 3.2254,
      "step": 56460
    },
    {
      "epoch": 90.8,
      "learning_rate": 0.0909231602022508,
      "loss": 3.2511,
      "step": 56480
    },
    {
      "epoch": 90.84,
      "learning_rate": 0.09091994477138264,
      "loss": 3.2491,
      "step": 56500
    },
    {
      "epoch": 90.87,
      "learning_rate": 0.09091672934051448,
      "loss": 3.2829,
      "step": 56520
    },
    {
      "epoch": 90.9,
      "learning_rate": 0.0909135139096463,
      "loss": 3.2514,
      "step": 56540
    },
    {
      "epoch": 90.93,
      "learning_rate": 0.09091029847877814,
      "loss": 3.2374,
      "step": 56560
    },
    {
      "epoch": 90.96,
      "learning_rate": 0.09090708304790997,
      "loss": 3.2154,
      "step": 56580
    },
    {
      "epoch": 91.0,
      "learning_rate": 0.0909038676170418,
      "loss": 3.1897,
      "step": 56600
    },
    {
      "epoch": 91.0,
      "eval_accuracy": {
        "accuracy": 0.3526393531835497
      },
      "eval_loss": 3.2631750106811523,
      "eval_runtime": 2.5014,
      "eval_samples_per_second": 5142.316,
      "eval_steps_per_second": 80.355,
      "step": 56602
    },
    {
      "epoch": 91.03,
      "learning_rate": 0.09090065218617364,
      "loss": 3.179,
      "step": 56620
    },
    {
      "epoch": 91.06,
      "learning_rate": 0.09089743675530547,
      "loss": 3.1995,
      "step": 56640
    },
    {
      "epoch": 91.09,
      "learning_rate": 0.09089422132443731,
      "loss": 3.3048,
      "step": 56660
    },
    {
      "epoch": 91.13,
      "learning_rate": 0.09089100589356913,
      "loss": 3.3419,
      "step": 56680
    },
    {
      "epoch": 91.16,
      "learning_rate": 0.09088779046270097,
      "loss": 3.237,
      "step": 56700
    },
    {
      "epoch": 91.19,
      "learning_rate": 0.09088457503183281,
      "loss": 3.299,
      "step": 56720
    },
    {
      "epoch": 91.22,
      "learning_rate": 0.09088135960096463,
      "loss": 3.2173,
      "step": 56740
    },
    {
      "epoch": 91.25,
      "learning_rate": 0.09087814417009647,
      "loss": 3.196,
      "step": 56760
    },
    {
      "epoch": 91.29,
      "learning_rate": 0.0908749287392283,
      "loss": 3.208,
      "step": 56780
    },
    {
      "epoch": 91.32,
      "learning_rate": 0.09087171330836014,
      "loss": 3.2696,
      "step": 56800
    },
    {
      "epoch": 91.35,
      "learning_rate": 0.09086849787749196,
      "loss": 3.2696,
      "step": 56820
    },
    {
      "epoch": 91.38,
      "learning_rate": 0.0908652824466238,
      "loss": 3.2537,
      "step": 56840
    },
    {
      "epoch": 91.41,
      "learning_rate": 0.09086206701575564,
      "loss": 3.258,
      "step": 56860
    },
    {
      "epoch": 91.45,
      "learning_rate": 0.09085885158488746,
      "loss": 3.2394,
      "step": 56880
    },
    {
      "epoch": 91.48,
      "learning_rate": 0.0908556361540193,
      "loss": 3.2187,
      "step": 56900
    },
    {
      "epoch": 91.51,
      "learning_rate": 0.09085242072315113,
      "loss": 3.2316,
      "step": 56920
    },
    {
      "epoch": 91.54,
      "learning_rate": 0.09084920529228296,
      "loss": 3.2916,
      "step": 56940
    },
    {
      "epoch": 91.58,
      "learning_rate": 0.0908459898614148,
      "loss": 3.2827,
      "step": 56960
    },
    {
      "epoch": 91.61,
      "learning_rate": 0.09084277443054663,
      "loss": 3.2626,
      "step": 56980
    },
    {
      "epoch": 91.64,
      "learning_rate": 0.09083955899967847,
      "loss": 3.2653,
      "step": 57000
    },
    {
      "epoch": 91.67,
      "learning_rate": 0.09083634356881029,
      "loss": 3.2371,
      "step": 57020
    },
    {
      "epoch": 91.7,
      "learning_rate": 0.09083312813794213,
      "loss": 3.243,
      "step": 57040
    },
    {
      "epoch": 91.74,
      "learning_rate": 0.09082991270707397,
      "loss": 3.2585,
      "step": 57060
    },
    {
      "epoch": 91.77,
      "learning_rate": 0.09082669727620579,
      "loss": 3.2314,
      "step": 57080
    },
    {
      "epoch": 91.8,
      "learning_rate": 0.09082348184533763,
      "loss": 3.2021,
      "step": 57100
    },
    {
      "epoch": 91.83,
      "learning_rate": 0.09082026641446946,
      "loss": 3.222,
      "step": 57120
    },
    {
      "epoch": 91.86,
      "learning_rate": 0.0908170509836013,
      "loss": 3.2414,
      "step": 57140
    },
    {
      "epoch": 91.9,
      "learning_rate": 0.09081383555273312,
      "loss": 3.2756,
      "step": 57160
    },
    {
      "epoch": 91.93,
      "learning_rate": 0.09081062012186496,
      "loss": 3.208,
      "step": 57180
    },
    {
      "epoch": 91.96,
      "learning_rate": 0.0908074046909968,
      "loss": 3.2389,
      "step": 57200
    },
    {
      "epoch": 91.99,
      "learning_rate": 0.09080418926012862,
      "loss": 3.2031,
      "step": 57220
    },
    {
      "epoch": 92.0,
      "eval_accuracy": {
        "accuracy": 0.3464977066003265
      },
      "eval_loss": 3.335608959197998,
      "eval_runtime": 2.7308,
      "eval_samples_per_second": 4710.383,
      "eval_steps_per_second": 73.605,
      "step": 57224
    },
    {
      "epoch": 92.03,
      "learning_rate": 0.09080097382926046,
      "loss": 3.2062,
      "step": 57240
    },
    {
      "epoch": 92.06,
      "learning_rate": 0.09079775839839228,
      "loss": 3.2079,
      "step": 57260
    },
    {
      "epoch": 92.09,
      "learning_rate": 0.09079454296752412,
      "loss": 3.2157,
      "step": 57280
    },
    {
      "epoch": 92.12,
      "learning_rate": 0.09079132753665596,
      "loss": 3.2355,
      "step": 57300
    },
    {
      "epoch": 92.15,
      "learning_rate": 0.09078811210578779,
      "loss": 3.2047,
      "step": 57320
    },
    {
      "epoch": 92.19,
      "learning_rate": 0.09078489667491962,
      "loss": 3.1842,
      "step": 57340
    },
    {
      "epoch": 92.22,
      "learning_rate": 0.09078168124405145,
      "loss": 3.2262,
      "step": 57360
    },
    {
      "epoch": 92.25,
      "learning_rate": 0.09077846581318329,
      "loss": 3.2438,
      "step": 57380
    },
    {
      "epoch": 92.28,
      "learning_rate": 0.09077525038231513,
      "loss": 3.2934,
      "step": 57400
    },
    {
      "epoch": 92.32,
      "learning_rate": 0.09077203495144695,
      "loss": 3.2802,
      "step": 57420
    },
    {
      "epoch": 92.35,
      "learning_rate": 0.09076881952057879,
      "loss": 3.251,
      "step": 57440
    },
    {
      "epoch": 92.38,
      "learning_rate": 0.09076560408971061,
      "loss": 3.2485,
      "step": 57460
    },
    {
      "epoch": 92.41,
      "learning_rate": 0.09076238865884245,
      "loss": 3.2368,
      "step": 57480
    },
    {
      "epoch": 92.44,
      "learning_rate": 0.09075917322797428,
      "loss": 3.2047,
      "step": 57500
    },
    {
      "epoch": 92.48,
      "learning_rate": 0.09075595779710612,
      "loss": 3.2436,
      "step": 57520
    },
    {
      "epoch": 92.51,
      "learning_rate": 0.09075274236623795,
      "loss": 3.2706,
      "step": 57540
    },
    {
      "epoch": 92.54,
      "learning_rate": 0.09074952693536978,
      "loss": 3.2764,
      "step": 57560
    },
    {
      "epoch": 92.57,
      "learning_rate": 0.09074631150450162,
      "loss": 3.3125,
      "step": 57580
    },
    {
      "epoch": 92.6,
      "learning_rate": 0.09074309607363344,
      "loss": 3.249,
      "step": 57600
    },
    {
      "epoch": 92.64,
      "learning_rate": 0.09073988064276528,
      "loss": 3.2169,
      "step": 57620
    },
    {
      "epoch": 92.67,
      "learning_rate": 0.09073666521189712,
      "loss": 3.1938,
      "step": 57640
    },
    {
      "epoch": 92.7,
      "learning_rate": 0.09073344978102894,
      "loss": 3.1922,
      "step": 57660
    },
    {
      "epoch": 92.73,
      "learning_rate": 0.09073023435016078,
      "loss": 3.2234,
      "step": 57680
    },
    {
      "epoch": 92.77,
      "learning_rate": 0.0907270189192926,
      "loss": 3.2034,
      "step": 57700
    },
    {
      "epoch": 92.8,
      "learning_rate": 0.09072380348842443,
      "loss": 3.204,
      "step": 57720
    },
    {
      "epoch": 92.83,
      "learning_rate": 0.09072058805755628,
      "loss": 3.2137,
      "step": 57740
    },
    {
      "epoch": 92.86,
      "learning_rate": 0.09071737262668811,
      "loss": 3.2047,
      "step": 57760
    },
    {
      "epoch": 92.89,
      "learning_rate": 0.09071415719581995,
      "loss": 3.2224,
      "step": 57780
    },
    {
      "epoch": 92.93,
      "learning_rate": 0.09071094176495177,
      "loss": 3.2435,
      "step": 57800
    },
    {
      "epoch": 92.96,
      "learning_rate": 0.0907077263340836,
      "loss": 3.2014,
      "step": 57820
    },
    {
      "epoch": 92.99,
      "learning_rate": 0.09070451090321544,
      "loss": 3.2286,
      "step": 57840
    },
    {
      "epoch": 93.0,
      "eval_accuracy": {
        "accuracy": 0.34906320454015394
      },
      "eval_loss": 3.3432610034942627,
      "eval_runtime": 3.2021,
      "eval_samples_per_second": 4017.043,
      "eval_steps_per_second": 62.771,
      "step": 57846
    },
    {
      "epoch": 93.02,
      "learning_rate": 0.09070129547234727,
      "loss": 3.228,
      "step": 57860
    },
    {
      "epoch": 93.05,
      "learning_rate": 0.09069808004147911,
      "loss": 3.3146,
      "step": 57880
    },
    {
      "epoch": 93.09,
      "learning_rate": 0.09069502538215435,
      "loss": 3.2621,
      "step": 57900
    },
    {
      "epoch": 93.12,
      "learning_rate": 0.09069180995128617,
      "loss": 3.2753,
      "step": 57920
    },
    {
      "epoch": 93.15,
      "learning_rate": 0.09068859452041801,
      "loss": 3.2176,
      "step": 57940
    },
    {
      "epoch": 93.18,
      "learning_rate": 0.09068537908954984,
      "loss": 3.2734,
      "step": 57960
    },
    {
      "epoch": 93.22,
      "learning_rate": 0.09068216365868169,
      "loss": 3.1984,
      "step": 57980
    },
    {
      "epoch": 93.25,
      "learning_rate": 0.09067894822781351,
      "loss": 3.1967,
      "step": 58000
    },
    {
      "epoch": 93.28,
      "learning_rate": 0.09067573279694534,
      "loss": 3.209,
      "step": 58020
    },
    {
      "epoch": 93.31,
      "learning_rate": 0.09067251736607718,
      "loss": 3.2281,
      "step": 58040
    },
    {
      "epoch": 93.34,
      "learning_rate": 0.090669301935209,
      "loss": 3.1618,
      "step": 58060
    },
    {
      "epoch": 93.38,
      "learning_rate": 0.09066608650434084,
      "loss": 3.18,
      "step": 58080
    },
    {
      "epoch": 93.41,
      "learning_rate": 0.09066287107347266,
      "loss": 3.1971,
      "step": 58100
    },
    {
      "epoch": 93.44,
      "learning_rate": 0.09065965564260452,
      "loss": 3.212,
      "step": 58120
    },
    {
      "epoch": 93.47,
      "learning_rate": 0.09065644021173634,
      "loss": 3.2172,
      "step": 58140
    },
    {
      "epoch": 93.5,
      "learning_rate": 0.09065322478086817,
      "loss": 3.2414,
      "step": 58160
    },
    {
      "epoch": 93.54,
      "learning_rate": 0.09065000935,
      "loss": 3.2795,
      "step": 58180
    },
    {
      "epoch": 93.57,
      "learning_rate": 0.09064679391913183,
      "loss": 3.2151,
      "step": 58200
    },
    {
      "epoch": 93.6,
      "learning_rate": 0.09064357848826368,
      "loss": 3.2245,
      "step": 58220
    },
    {
      "epoch": 93.63,
      "learning_rate": 0.0906403630573955,
      "loss": 3.2356,
      "step": 58240
    },
    {
      "epoch": 93.67,
      "learning_rate": 0.09063714762652733,
      "loss": 3.1897,
      "step": 58260
    },
    {
      "epoch": 93.7,
      "learning_rate": 0.09063393219565917,
      "loss": 3.2117,
      "step": 58280
    },
    {
      "epoch": 93.73,
      "learning_rate": 0.090630716764791,
      "loss": 3.2046,
      "step": 58300
    },
    {
      "epoch": 93.76,
      "learning_rate": 0.09062750133392285,
      "loss": 3.2368,
      "step": 58320
    },
    {
      "epoch": 93.79,
      "learning_rate": 0.09062428590305467,
      "loss": 3.3157,
      "step": 58340
    },
    {
      "epoch": 93.83,
      "learning_rate": 0.0906210704721865,
      "loss": 3.2665,
      "step": 58360
    },
    {
      "epoch": 93.86,
      "learning_rate": 0.09061785504131833,
      "loss": 3.2527,
      "step": 58380
    },
    {
      "epoch": 93.89,
      "learning_rate": 0.09061463961045016,
      "loss": 3.276,
      "step": 58400
    },
    {
      "epoch": 93.92,
      "learning_rate": 0.090611424179582,
      "loss": 3.2985,
      "step": 58420
    },
    {
      "epoch": 93.95,
      "learning_rate": 0.09060820874871382,
      "loss": 3.2348,
      "step": 58440
    },
    {
      "epoch": 93.99,
      "learning_rate": 0.09060499331784566,
      "loss": 3.2002,
      "step": 58460
    },
    {
      "epoch": 94.0,
      "eval_accuracy": {
        "accuracy": 0.3482857809220244
      },
      "eval_loss": 3.293825149536133,
      "eval_runtime": 2.6241,
      "eval_samples_per_second": 4901.942,
      "eval_steps_per_second": 76.599,
      "step": 58468
    },
    {
      "epoch": 94.02,
      "learning_rate": 0.0906017778869775,
      "loss": 3.2249,
      "step": 58480
    },
    {
      "epoch": 94.05,
      "learning_rate": 0.09059856245610932,
      "loss": 3.2634,
      "step": 58500
    },
    {
      "epoch": 94.08,
      "learning_rate": 0.09059534702524116,
      "loss": 3.2332,
      "step": 58520
    },
    {
      "epoch": 94.12,
      "learning_rate": 0.09059213159437299,
      "loss": 3.2017,
      "step": 58540
    },
    {
      "epoch": 94.15,
      "learning_rate": 0.09058891616350483,
      "loss": 3.2117,
      "step": 58560
    },
    {
      "epoch": 94.18,
      "learning_rate": 0.09058570073263666,
      "loss": 3.2008,
      "step": 58580
    },
    {
      "epoch": 94.21,
      "learning_rate": 0.09058248530176849,
      "loss": 3.2589,
      "step": 58600
    },
    {
      "epoch": 94.24,
      "learning_rate": 0.09057926987090033,
      "loss": 3.3065,
      "step": 58620
    },
    {
      "epoch": 94.28,
      "learning_rate": 0.09057605444003215,
      "loss": 3.2574,
      "step": 58640
    },
    {
      "epoch": 94.31,
      "learning_rate": 0.09057283900916399,
      "loss": 3.1801,
      "step": 58660
    },
    {
      "epoch": 94.34,
      "learning_rate": 0.09056962357829583,
      "loss": 3.2097,
      "step": 58680
    },
    {
      "epoch": 94.37,
      "learning_rate": 0.09056640814742765,
      "loss": 3.2139,
      "step": 58700
    },
    {
      "epoch": 94.41,
      "learning_rate": 0.09056319271655949,
      "loss": 3.2546,
      "step": 58720
    },
    {
      "epoch": 94.44,
      "learning_rate": 0.09055997728569132,
      "loss": 3.2869,
      "step": 58740
    },
    {
      "epoch": 94.47,
      "learning_rate": 0.09055676185482316,
      "loss": 3.2474,
      "step": 58760
    },
    {
      "epoch": 94.5,
      "learning_rate": 0.09055354642395498,
      "loss": 3.2807,
      "step": 58780
    },
    {
      "epoch": 94.53,
      "learning_rate": 0.09055033099308682,
      "loss": 3.2336,
      "step": 58800
    },
    {
      "epoch": 94.57,
      "learning_rate": 0.09054711556221866,
      "loss": 3.2305,
      "step": 58820
    },
    {
      "epoch": 94.6,
      "learning_rate": 0.09054390013135048,
      "loss": 3.2448,
      "step": 58840
    },
    {
      "epoch": 94.63,
      "learning_rate": 0.09054068470048232,
      "loss": 3.202,
      "step": 58860
    },
    {
      "epoch": 94.66,
      "learning_rate": 0.09053746926961415,
      "loss": 3.145,
      "step": 58880
    },
    {
      "epoch": 94.69,
      "learning_rate": 0.09053425383874598,
      "loss": 3.2344,
      "step": 58900
    },
    {
      "epoch": 94.73,
      "learning_rate": 0.09053103840787782,
      "loss": 3.231,
      "step": 58920
    },
    {
      "epoch": 94.76,
      "learning_rate": 0.09052782297700965,
      "loss": 3.2291,
      "step": 58940
    },
    {
      "epoch": 94.79,
      "learning_rate": 0.09052460754614149,
      "loss": 3.2425,
      "step": 58960
    },
    {
      "epoch": 94.82,
      "learning_rate": 0.09052139211527331,
      "loss": 3.2479,
      "step": 58980
    },
    {
      "epoch": 94.86,
      "learning_rate": 0.09051817668440515,
      "loss": 3.2146,
      "step": 59000
    },
    {
      "epoch": 94.89,
      "learning_rate": 0.09051496125353699,
      "loss": 3.1927,
      "step": 59020
    },
    {
      "epoch": 94.92,
      "learning_rate": 0.09051174582266881,
      "loss": 3.1956,
      "step": 59040
    },
    {
      "epoch": 94.95,
      "learning_rate": 0.09050853039180065,
      "loss": 3.2112,
      "step": 59060
    },
    {
      "epoch": 94.98,
      "learning_rate": 0.09050531496093248,
      "loss": 3.2361,
      "step": 59080
    },
    {
      "epoch": 95.0,
      "eval_accuracy": {
        "accuracy": 0.34369898157506024
      },
      "eval_loss": 3.2886197566986084,
      "eval_runtime": 2.5988,
      "eval_samples_per_second": 4949.675,
      "eval_steps_per_second": 77.345,
      "step": 59090
    },
    {
      "epoch": 95.02,
      "learning_rate": 0.09050209953006431,
      "loss": 3.2189,
      "step": 59100
    },
    {
      "epoch": 95.05,
      "learning_rate": 0.09049888409919615,
      "loss": 3.1987,
      "step": 59120
    },
    {
      "epoch": 95.08,
      "learning_rate": 0.09049566866832798,
      "loss": 3.1781,
      "step": 59140
    },
    {
      "epoch": 95.11,
      "learning_rate": 0.09049245323745982,
      "loss": 3.1657,
      "step": 59160
    },
    {
      "epoch": 95.14,
      "learning_rate": 0.09048923780659164,
      "loss": 3.1591,
      "step": 59180
    },
    {
      "epoch": 95.18,
      "learning_rate": 0.09048602237572348,
      "loss": 3.1818,
      "step": 59200
    },
    {
      "epoch": 95.21,
      "learning_rate": 0.0904828069448553,
      "loss": 3.2082,
      "step": 59220
    },
    {
      "epoch": 95.24,
      "learning_rate": 0.09047959151398714,
      "loss": 3.2353,
      "step": 59240
    },
    {
      "epoch": 95.27,
      "learning_rate": 0.09047637608311898,
      "loss": 3.1815,
      "step": 59260
    },
    {
      "epoch": 95.31,
      "learning_rate": 0.0904731606522508,
      "loss": 3.2441,
      "step": 59280
    },
    {
      "epoch": 95.34,
      "learning_rate": 0.09046994522138264,
      "loss": 3.2197,
      "step": 59300
    },
    {
      "epoch": 95.37,
      "learning_rate": 0.09046672979051447,
      "loss": 3.2257,
      "step": 59320
    },
    {
      "epoch": 95.4,
      "learning_rate": 0.09046351435964631,
      "loss": 3.1793,
      "step": 59340
    },
    {
      "epoch": 95.43,
      "learning_rate": 0.09046029892877815,
      "loss": 3.2033,
      "step": 59360
    },
    {
      "epoch": 95.47,
      "learning_rate": 0.09045708349790997,
      "loss": 3.2255,
      "step": 59380
    },
    {
      "epoch": 95.5,
      "learning_rate": 0.09045386806704181,
      "loss": 3.1853,
      "step": 59400
    },
    {
      "epoch": 95.53,
      "learning_rate": 0.09045065263617363,
      "loss": 3.2478,
      "step": 59420
    },
    {
      "epoch": 95.56,
      "learning_rate": 0.09044743720530547,
      "loss": 3.2306,
      "step": 59440
    },
    {
      "epoch": 95.59,
      "learning_rate": 0.09044422177443731,
      "loss": 3.2353,
      "step": 59460
    },
    {
      "epoch": 95.63,
      "learning_rate": 0.09044100634356914,
      "loss": 3.2366,
      "step": 59480
    },
    {
      "epoch": 95.66,
      "learning_rate": 0.09043779091270097,
      "loss": 3.2797,
      "step": 59500
    },
    {
      "epoch": 95.69,
      "learning_rate": 0.0904345754818328,
      "loss": 3.3288,
      "step": 59520
    },
    {
      "epoch": 95.72,
      "learning_rate": 0.09043136005096464,
      "loss": 3.3338,
      "step": 59540
    },
    {
      "epoch": 95.76,
      "learning_rate": 0.09042814462009646,
      "loss": 3.2543,
      "step": 59560
    },
    {
      "epoch": 95.79,
      "learning_rate": 0.0904249291892283,
      "loss": 3.2264,
      "step": 59580
    },
    {
      "epoch": 95.82,
      "learning_rate": 0.09042171375836014,
      "loss": 3.219,
      "step": 59600
    },
    {
      "epoch": 95.85,
      "learning_rate": 0.09041849832749196,
      "loss": 3.2497,
      "step": 59620
    },
    {
      "epoch": 95.88,
      "learning_rate": 0.0904152828966238,
      "loss": 3.256,
      "step": 59640
    },
    {
      "epoch": 95.92,
      "learning_rate": 0.09041206746575563,
      "loss": 3.2457,
      "step": 59660
    },
    {
      "epoch": 95.95,
      "learning_rate": 0.09040885203488747,
      "loss": 3.2369,
      "step": 59680
    },
    {
      "epoch": 95.98,
      "learning_rate": 0.0904056366040193,
      "loss": 3.2292,
      "step": 59700
    },
    {
      "epoch": 96.0,
      "eval_accuracy": {
        "accuracy": 0.347275130218456
      },
      "eval_loss": 3.320859670639038,
      "eval_runtime": 3.092,
      "eval_samples_per_second": 4160.032,
      "eval_steps_per_second": 65.006,
      "step": 59712
    },
    {
      "epoch": 96.01,
      "learning_rate": 0.09040242117315113,
      "loss": 3.2216,
      "step": 59720
    },
    {
      "epoch": 96.05,
      "learning_rate": 0.09039920574228297,
      "loss": 3.2519,
      "step": 59740
    },
    {
      "epoch": 96.08,
      "learning_rate": 0.09039599031141479,
      "loss": 3.2165,
      "step": 59760
    },
    {
      "epoch": 96.11,
      "learning_rate": 0.09039277488054663,
      "loss": 3.2046,
      "step": 59780
    },
    {
      "epoch": 96.14,
      "learning_rate": 0.09038955944967847,
      "loss": 3.2019,
      "step": 59800
    },
    {
      "epoch": 96.17,
      "learning_rate": 0.0903863440188103,
      "loss": 3.179,
      "step": 59820
    },
    {
      "epoch": 96.21,
      "learning_rate": 0.09038312858794213,
      "loss": 3.186,
      "step": 59840
    },
    {
      "epoch": 96.24,
      "learning_rate": 0.09037991315707396,
      "loss": 3.2344,
      "step": 59860
    },
    {
      "epoch": 96.27,
      "learning_rate": 0.0903766977262058,
      "loss": 3.22,
      "step": 59880
    },
    {
      "epoch": 96.3,
      "learning_rate": 0.09037348229533762,
      "loss": 3.2583,
      "step": 59900
    },
    {
      "epoch": 96.33,
      "learning_rate": 0.09037042763601286,
      "loss": 3.2238,
      "step": 59920
    },
    {
      "epoch": 96.37,
      "learning_rate": 0.09036721220514471,
      "loss": 3.2202,
      "step": 59940
    },
    {
      "epoch": 96.4,
      "learning_rate": 0.09036399677427653,
      "loss": 3.2346,
      "step": 59960
    },
    {
      "epoch": 96.43,
      "learning_rate": 0.09036078134340837,
      "loss": 3.2309,
      "step": 59980
    },
    {
      "epoch": 96.46,
      "learning_rate": 0.0903575659125402,
      "loss": 3.2234,
      "step": 60000
    },
    {
      "epoch": 96.5,
      "learning_rate": 0.09035435048167202,
      "loss": 3.2176,
      "step": 60020
    },
    {
      "epoch": 96.53,
      "learning_rate": 0.09035113505080387,
      "loss": 3.2302,
      "step": 60040
    },
    {
      "epoch": 96.56,
      "learning_rate": 0.0903479196199357,
      "loss": 3.2027,
      "step": 60060
    },
    {
      "epoch": 96.59,
      "learning_rate": 0.09034470418906754,
      "loss": 3.2735,
      "step": 60080
    },
    {
      "epoch": 96.62,
      "learning_rate": 0.09034148875819936,
      "loss": 3.1584,
      "step": 60100
    },
    {
      "epoch": 96.66,
      "learning_rate": 0.09033827332733119,
      "loss": 3.1531,
      "step": 60120
    },
    {
      "epoch": 96.69,
      "learning_rate": 0.09033505789646303,
      "loss": 3.1674,
      "step": 60140
    },
    {
      "epoch": 96.72,
      "learning_rate": 0.09033184246559485,
      "loss": 3.1938,
      "step": 60160
    },
    {
      "epoch": 96.75,
      "learning_rate": 0.0903286270347267,
      "loss": 3.2175,
      "step": 60180
    },
    {
      "epoch": 96.78,
      "learning_rate": 0.09032541160385853,
      "loss": 3.2001,
      "step": 60200
    },
    {
      "epoch": 96.82,
      "learning_rate": 0.09032219617299035,
      "loss": 3.206,
      "step": 60220
    },
    {
      "epoch": 96.85,
      "learning_rate": 0.09031898074212219,
      "loss": 3.2318,
      "step": 60240
    },
    {
      "epoch": 96.88,
      "learning_rate": 0.09031576531125401,
      "loss": 3.2162,
      "step": 60260
    },
    {
      "epoch": 96.91,
      "learning_rate": 0.09031254988038587,
      "loss": 3.1872,
      "step": 60280
    },
    {
      "epoch": 96.95,
      "learning_rate": 0.09030933444951769,
      "loss": 3.2008,
      "step": 60300
    },
    {
      "epoch": 96.98,
      "learning_rate": 0.09030611901864953,
      "loss": 3.2005,
      "step": 60320
    },
    {
      "epoch": 97.0,
      "eval_accuracy": {
        "accuracy": 0.3402783176552904
      },
      "eval_loss": 3.4284472465515137,
      "eval_runtime": 2.5656,
      "eval_samples_per_second": 5013.698,
      "eval_steps_per_second": 78.345,
      "step": 60334
    },
    {
      "epoch": 97.01,
      "learning_rate": 0.09030290358778136,
      "loss": 3.269,
      "step": 60340
    },
    {
      "epoch": 97.04,
      "learning_rate": 0.09029968815691318,
      "loss": 3.2421,
      "step": 60360
    },
    {
      "epoch": 97.07,
      "learning_rate": 0.09029647272604503,
      "loss": 3.2228,
      "step": 60380
    },
    {
      "epoch": 97.11,
      "learning_rate": 0.09029325729517686,
      "loss": 3.2268,
      "step": 60400
    },
    {
      "epoch": 97.14,
      "learning_rate": 0.0902900418643087,
      "loss": 3.2254,
      "step": 60420
    },
    {
      "epoch": 97.17,
      "learning_rate": 0.09028682643344052,
      "loss": 3.1851,
      "step": 60440
    },
    {
      "epoch": 97.2,
      "learning_rate": 0.09028361100257234,
      "loss": 3.2056,
      "step": 60460
    },
    {
      "epoch": 97.23,
      "learning_rate": 0.09028039557170418,
      "loss": 3.1936,
      "step": 60480
    },
    {
      "epoch": 97.27,
      "learning_rate": 0.09027718014083601,
      "loss": 3.2289,
      "step": 60500
    },
    {
      "epoch": 97.3,
      "learning_rate": 0.09027396470996786,
      "loss": 3.1786,
      "step": 60520
    },
    {
      "epoch": 97.33,
      "learning_rate": 0.09027074927909969,
      "loss": 3.2009,
      "step": 60540
    },
    {
      "epoch": 97.36,
      "learning_rate": 0.09026753384823151,
      "loss": 3.18,
      "step": 60560
    },
    {
      "epoch": 97.4,
      "learning_rate": 0.09026431841736335,
      "loss": 3.2084,
      "step": 60580
    },
    {
      "epoch": 97.43,
      "learning_rate": 0.09026110298649517,
      "loss": 3.2093,
      "step": 60600
    },
    {
      "epoch": 97.46,
      "learning_rate": 0.09025788755562703,
      "loss": 3.1965,
      "step": 60620
    },
    {
      "epoch": 97.49,
      "learning_rate": 0.09025467212475885,
      "loss": 3.1726,
      "step": 60640
    },
    {
      "epoch": 97.52,
      "learning_rate": 0.09025145669389067,
      "loss": 3.1354,
      "step": 60660
    },
    {
      "epoch": 97.56,
      "learning_rate": 0.09024824126302251,
      "loss": 3.2153,
      "step": 60680
    },
    {
      "epoch": 97.59,
      "learning_rate": 0.09024502583215434,
      "loss": 3.2291,
      "step": 60700
    },
    {
      "epoch": 97.62,
      "learning_rate": 0.09024181040128619,
      "loss": 3.2223,
      "step": 60720
    },
    {
      "epoch": 97.65,
      "learning_rate": 0.09023859497041802,
      "loss": 3.2565,
      "step": 60740
    },
    {
      "epoch": 97.68,
      "learning_rate": 0.09023537953954984,
      "loss": 3.2093,
      "step": 60760
    },
    {
      "epoch": 97.72,
      "learning_rate": 0.09023216410868168,
      "loss": 3.2069,
      "step": 60780
    },
    {
      "epoch": 97.75,
      "learning_rate": 0.0902289486778135,
      "loss": 3.2189,
      "step": 60800
    },
    {
      "epoch": 97.78,
      "learning_rate": 0.09022573324694534,
      "loss": 3.2111,
      "step": 60820
    },
    {
      "epoch": 97.81,
      "learning_rate": 0.09022251781607717,
      "loss": 3.2124,
      "step": 60840
    },
    {
      "epoch": 97.85,
      "learning_rate": 0.090219302385209,
      "loss": 3.2202,
      "step": 60860
    },
    {
      "epoch": 97.88,
      "learning_rate": 0.09021608695434084,
      "loss": 3.2421,
      "step": 60880
    },
    {
      "epoch": 97.91,
      "learning_rate": 0.09021287152347267,
      "loss": 3.2056,
      "step": 60900
    },
    {
      "epoch": 97.94,
      "learning_rate": 0.0902096560926045,
      "loss": 3.2004,
      "step": 60920
    },
    {
      "epoch": 97.97,
      "learning_rate": 0.09020644066173633,
      "loss": 3.2023,
      "step": 60940
    },
    {
      "epoch": 98.0,
      "eval_accuracy": {
        "accuracy": 0.3447096322786286
      },
      "eval_loss": 3.327014684677124,
      "eval_runtime": 2.6822,
      "eval_samples_per_second": 4795.726,
      "eval_steps_per_second": 74.939,
      "step": 60956
    },
    {
      "epoch": 98.01,
      "learning_rate": 0.09020322523086818,
      "loss": 3.2338,
      "step": 60960
    },
    {
      "epoch": 98.04,
      "learning_rate": 0.09020000980000001,
      "loss": 3.2168,
      "step": 60980
    },
    {
      "epoch": 98.07,
      "learning_rate": 0.09019679436913183,
      "loss": 3.194,
      "step": 61000
    },
    {
      "epoch": 98.1,
      "learning_rate": 0.09019357893826367,
      "loss": 3.1786,
      "step": 61020
    },
    {
      "epoch": 98.14,
      "learning_rate": 0.0901903635073955,
      "loss": 3.1717,
      "step": 61040
    },
    {
      "epoch": 98.17,
      "learning_rate": 0.09018714807652735,
      "loss": 3.159,
      "step": 61060
    },
    {
      "epoch": 98.2,
      "learning_rate": 0.09018393264565917,
      "loss": 3.1929,
      "step": 61080
    },
    {
      "epoch": 98.23,
      "learning_rate": 0.090180717214791,
      "loss": 3.2251,
      "step": 61100
    },
    {
      "epoch": 98.26,
      "learning_rate": 0.09017750178392284,
      "loss": 3.2632,
      "step": 61120
    },
    {
      "epoch": 98.3,
      "learning_rate": 0.09017428635305466,
      "loss": 3.2734,
      "step": 61140
    },
    {
      "epoch": 98.33,
      "learning_rate": 0.0901710709221865,
      "loss": 3.2218,
      "step": 61160
    },
    {
      "epoch": 98.36,
      "learning_rate": 0.09016785549131832,
      "loss": 3.2592,
      "step": 61180
    },
    {
      "epoch": 98.39,
      "learning_rate": 0.09016464006045016,
      "loss": 3.2556,
      "step": 61200
    },
    {
      "epoch": 98.42,
      "learning_rate": 0.090161424629582,
      "loss": 3.2936,
      "step": 61220
    },
    {
      "epoch": 98.46,
      "learning_rate": 0.09015820919871383,
      "loss": 3.211,
      "step": 61240
    },
    {
      "epoch": 98.49,
      "learning_rate": 0.09015499376784566,
      "loss": 3.2057,
      "step": 61260
    },
    {
      "epoch": 98.52,
      "learning_rate": 0.09015177833697749,
      "loss": 3.2007,
      "step": 61280
    },
    {
      "epoch": 98.55,
      "learning_rate": 0.09014856290610933,
      "loss": 3.1981,
      "step": 61300
    },
    {
      "epoch": 98.59,
      "learning_rate": 0.09014534747524117,
      "loss": 3.231,
      "step": 61320
    },
    {
      "epoch": 98.62,
      "learning_rate": 0.09014213204437299,
      "loss": 3.2246,
      "step": 61340
    },
    {
      "epoch": 98.65,
      "learning_rate": 0.09013891661350483,
      "loss": 3.2246,
      "step": 61360
    },
    {
      "epoch": 98.68,
      "learning_rate": 0.09013570118263665,
      "loss": 3.2384,
      "step": 61380
    },
    {
      "epoch": 98.71,
      "learning_rate": 0.09013248575176849,
      "loss": 3.2287,
      "step": 61400
    },
    {
      "epoch": 98.75,
      "learning_rate": 0.09012927032090033,
      "loss": 3.2373,
      "step": 61420
    },
    {
      "epoch": 98.78,
      "learning_rate": 0.09012605489003216,
      "loss": 3.2257,
      "step": 61440
    },
    {
      "epoch": 98.81,
      "learning_rate": 0.090122839459164,
      "loss": 3.2438,
      "step": 61460
    },
    {
      "epoch": 98.84,
      "learning_rate": 0.09011962402829582,
      "loss": 3.1764,
      "step": 61480
    },
    {
      "epoch": 98.87,
      "learning_rate": 0.09011640859742766,
      "loss": 3.2223,
      "step": 61500
    },
    {
      "epoch": 98.91,
      "learning_rate": 0.0901131931665595,
      "loss": 3.2352,
      "step": 61520
    },
    {
      "epoch": 98.94,
      "learning_rate": 0.09010997773569132,
      "loss": 3.1872,
      "step": 61540
    },
    {
      "epoch": 98.97,
      "learning_rate": 0.09010676230482316,
      "loss": 3.2286,
      "step": 61560
    },
    {
      "epoch": 99.0,
      "eval_accuracy": {
        "accuracy": 0.35178418720360727
      },
      "eval_loss": 3.3326313495635986,
      "eval_runtime": 2.9378,
      "eval_samples_per_second": 4378.43,
      "eval_steps_per_second": 68.418,
      "step": 61578
    },
    {
      "epoch": 99.0,
      "learning_rate": 0.09010354687395498,
      "loss": 3.2257,
      "step": 61580
    },
    {
      "epoch": 99.04,
      "learning_rate": 0.09010033144308682,
      "loss": 3.2268,
      "step": 61600
    },
    {
      "epoch": 99.07,
      "learning_rate": 0.09009711601221865,
      "loss": 3.189,
      "step": 61620
    },
    {
      "epoch": 99.1,
      "learning_rate": 0.09009390058135049,
      "loss": 3.1965,
      "step": 61640
    },
    {
      "epoch": 99.13,
      "learning_rate": 0.09009068515048232,
      "loss": 3.1555,
      "step": 61660
    },
    {
      "epoch": 99.16,
      "learning_rate": 0.09008746971961415,
      "loss": 3.1984,
      "step": 61680
    },
    {
      "epoch": 99.2,
      "learning_rate": 0.09008425428874599,
      "loss": 3.22,
      "step": 61700
    },
    {
      "epoch": 99.23,
      "learning_rate": 0.09008103885787781,
      "loss": 3.215,
      "step": 61720
    },
    {
      "epoch": 99.26,
      "learning_rate": 0.09007782342700965,
      "loss": 3.1661,
      "step": 61740
    },
    {
      "epoch": 99.29,
      "learning_rate": 0.09007460799614149,
      "loss": 3.1595,
      "step": 61760
    },
    {
      "epoch": 99.32,
      "learning_rate": 0.09007139256527331,
      "loss": 3.2346,
      "step": 61780
    },
    {
      "epoch": 99.36,
      "learning_rate": 0.09006817713440515,
      "loss": 3.1963,
      "step": 61800
    },
    {
      "epoch": 99.39,
      "learning_rate": 0.09006496170353698,
      "loss": 3.186,
      "step": 61820
    },
    {
      "epoch": 99.42,
      "learning_rate": 0.09006174627266882,
      "loss": 3.2124,
      "step": 61840
    },
    {
      "epoch": 99.45,
      "learning_rate": 0.09005853084180065,
      "loss": 3.2168,
      "step": 61860
    },
    {
      "epoch": 99.49,
      "learning_rate": 0.09005531541093248,
      "loss": 3.1955,
      "step": 61880
    },
    {
      "epoch": 99.52,
      "learning_rate": 0.09005209998006432,
      "loss": 3.1806,
      "step": 61900
    },
    {
      "epoch": 99.55,
      "learning_rate": 0.09004888454919614,
      "loss": 3.1963,
      "step": 61920
    },
    {
      "epoch": 99.58,
      "learning_rate": 0.09004566911832798,
      "loss": 3.1791,
      "step": 61940
    },
    {
      "epoch": 99.61,
      "learning_rate": 0.0900424536874598,
      "loss": 3.2158,
      "step": 61960
    },
    {
      "epoch": 99.65,
      "learning_rate": 0.09003923825659164,
      "loss": 3.2056,
      "step": 61980
    },
    {
      "epoch": 99.68,
      "learning_rate": 0.09003602282572348,
      "loss": 3.2271,
      "step": 62000
    },
    {
      "epoch": 99.71,
      "learning_rate": 0.09003280739485531,
      "loss": 3.2625,
      "step": 62020
    },
    {
      "epoch": 99.74,
      "learning_rate": 0.09002959196398715,
      "loss": 3.2138,
      "step": 62040
    },
    {
      "epoch": 99.77,
      "learning_rate": 0.09002637653311897,
      "loss": 3.2068,
      "step": 62060
    },
    {
      "epoch": 99.81,
      "learning_rate": 0.09002316110225081,
      "loss": 3.248,
      "step": 62080
    },
    {
      "epoch": 99.84,
      "learning_rate": 0.09001994567138265,
      "loss": 3.2116,
      "step": 62100
    },
    {
      "epoch": 99.87,
      "learning_rate": 0.09001673024051447,
      "loss": 3.1826,
      "step": 62120
    },
    {
      "epoch": 99.9,
      "learning_rate": 0.09001351480964631,
      "loss": 3.1872,
      "step": 62140
    },
    {
      "epoch": 99.94,
      "learning_rate": 0.09001029937877814,
      "loss": 3.1988,
      "step": 62160
    },
    {
      "epoch": 99.97,
      "learning_rate": 0.09000708394790997,
      "loss": 3.2048,
      "step": 62180
    },
    {
      "epoch": 100.0,
      "learning_rate": 0.09000386851704181,
      "loss": 3.2085,
      "step": 62200
    },
    {
      "epoch": 100.0,
      "eval_accuracy": {
        "accuracy": 0.34641996423851357
      },
      "eval_loss": 3.298515558242798,
      "eval_runtime": 2.8164,
      "eval_samples_per_second": 4567.159,
      "eval_steps_per_second": 71.367,
      "step": 62200
    },
    {
      "epoch": 100.03,
      "learning_rate": 0.09000065308617364,
      "loss": 3.2493,
      "step": 62220
    },
    {
      "epoch": 100.06,
      "learning_rate": 0.08999743765530548,
      "loss": 3.2268,
      "step": 62240
    },
    {
      "epoch": 100.1,
      "learning_rate": 0.0899942222244373,
      "loss": 3.1807,
      "step": 62260
    },
    {
      "epoch": 100.13,
      "learning_rate": 0.08999100679356914,
      "loss": 3.2005,
      "step": 62280
    },
    {
      "epoch": 100.16,
      "learning_rate": 0.08998795213424438,
      "loss": 3.2211,
      "step": 62300
    },
    {
      "epoch": 100.19,
      "learning_rate": 0.0899847367033762,
      "loss": 3.2789,
      "step": 62320
    },
    {
      "epoch": 100.23,
      "learning_rate": 0.08998152127250805,
      "loss": 3.2824,
      "step": 62340
    },
    {
      "epoch": 100.26,
      "learning_rate": 0.08997830584163988,
      "loss": 3.2215,
      "step": 62360
    },
    {
      "epoch": 100.29,
      "learning_rate": 0.08997509041077172,
      "loss": 3.2047,
      "step": 62380
    },
    {
      "epoch": 100.32,
      "learning_rate": 0.08997187497990354,
      "loss": 3.1916,
      "step": 62400
    },
    {
      "epoch": 100.35,
      "learning_rate": 0.08996865954903537,
      "loss": 3.2238,
      "step": 62420
    },
    {
      "epoch": 100.39,
      "learning_rate": 0.08996544411816722,
      "loss": 3.2126,
      "step": 62440
    },
    {
      "epoch": 100.42,
      "learning_rate": 0.08996222868729904,
      "loss": 3.2191,
      "step": 62460
    },
    {
      "epoch": 100.45,
      "learning_rate": 0.08995901325643088,
      "loss": 3.2261,
      "step": 62480
    },
    {
      "epoch": 100.48,
      "learning_rate": 0.0899557978255627,
      "loss": 3.1705,
      "step": 62500
    },
    {
      "epoch": 100.51,
      "learning_rate": 0.08995258239469454,
      "loss": 3.201,
      "step": 62520
    },
    {
      "epoch": 100.55,
      "learning_rate": 0.08994936696382637,
      "loss": 3.1997,
      "step": 62540
    },
    {
      "epoch": 100.58,
      "learning_rate": 0.0899461515329582,
      "loss": 3.1552,
      "step": 62560
    },
    {
      "epoch": 100.61,
      "learning_rate": 0.08994293610209005,
      "loss": 3.1596,
      "step": 62580
    },
    {
      "epoch": 100.64,
      "learning_rate": 0.08993972067122187,
      "loss": 3.1737,
      "step": 62600
    },
    {
      "epoch": 100.68,
      "learning_rate": 0.08993650524035371,
      "loss": 3.1723,
      "step": 62620
    },
    {
      "epoch": 100.71,
      "learning_rate": 0.08993328980948553,
      "loss": 3.1874,
      "step": 62640
    },
    {
      "epoch": 100.74,
      "learning_rate": 0.08993007437861736,
      "loss": 3.2591,
      "step": 62660
    },
    {
      "epoch": 100.77,
      "learning_rate": 0.08992685894774921,
      "loss": 3.2849,
      "step": 62680
    },
    {
      "epoch": 100.8,
      "learning_rate": 0.08992364351688104,
      "loss": 3.2692,
      "step": 62700
    },
    {
      "epoch": 100.84,
      "learning_rate": 0.08992042808601287,
      "loss": 3.2358,
      "step": 62720
    },
    {
      "epoch": 100.87,
      "learning_rate": 0.0899172126551447,
      "loss": 3.2136,
      "step": 62740
    },
    {
      "epoch": 100.9,
      "learning_rate": 0.08991399722427652,
      "loss": 3.2144,
      "step": 62760
    },
    {
      "epoch": 100.93,
      "learning_rate": 0.08991078179340838,
      "loss": 3.2025,
      "step": 62780
    },
    {
      "epoch": 100.96,
      "learning_rate": 0.0899075663625402,
      "loss": 3.1914,
      "step": 62800
    },
    {
      "epoch": 101.0,
      "learning_rate": 0.08990435093167204,
      "loss": 3.2187,
      "step": 62820
    },
    {
      "epoch": 101.0,
      "eval_accuracy": {
        "accuracy": 0.3497628857964705
      },
      "eval_loss": 3.257117748260498,
      "eval_runtime": 2.6854,
      "eval_samples_per_second": 4789.949,
      "eval_steps_per_second": 74.849,
      "step": 62822
    },
    {
      "epoch": 101.03,
      "learning_rate": 0.08990113550080386,
      "loss": 3.1997,
      "step": 62840
    },
    {
      "epoch": 101.06,
      "learning_rate": 0.08989792006993569,
      "loss": 3.1683,
      "step": 62860
    },
    {
      "epoch": 101.09,
      "learning_rate": 0.08989470463906753,
      "loss": 3.2219,
      "step": 62880
    },
    {
      "epoch": 101.13,
      "learning_rate": 0.08989148920819935,
      "loss": 3.2123,
      "step": 62900
    },
    {
      "epoch": 101.16,
      "learning_rate": 0.0898882737773312,
      "loss": 3.2251,
      "step": 62920
    },
    {
      "epoch": 101.19,
      "learning_rate": 0.08988505834646303,
      "loss": 3.1988,
      "step": 62940
    },
    {
      "epoch": 101.22,
      "learning_rate": 0.08988184291559485,
      "loss": 3.1991,
      "step": 62960
    },
    {
      "epoch": 101.25,
      "learning_rate": 0.08987862748472669,
      "loss": 3.2062,
      "step": 62980
    },
    {
      "epoch": 101.29,
      "learning_rate": 0.08987541205385852,
      "loss": 3.2055,
      "step": 63000
    },
    {
      "epoch": 101.32,
      "learning_rate": 0.08987219662299037,
      "loss": 3.2411,
      "step": 63020
    },
    {
      "epoch": 101.35,
      "learning_rate": 0.0898689811921222,
      "loss": 3.2219,
      "step": 63040
    },
    {
      "epoch": 101.38,
      "learning_rate": 0.08986576576125402,
      "loss": 3.2148,
      "step": 63060
    },
    {
      "epoch": 101.41,
      "learning_rate": 0.08986255033038586,
      "loss": 3.1663,
      "step": 63080
    },
    {
      "epoch": 101.45,
      "learning_rate": 0.08985933489951768,
      "loss": 3.1974,
      "step": 63100
    },
    {
      "epoch": 101.48,
      "learning_rate": 0.08985611946864953,
      "loss": 3.1603,
      "step": 63120
    },
    {
      "epoch": 101.51,
      "learning_rate": 0.08985290403778136,
      "loss": 3.2409,
      "step": 63140
    },
    {
      "epoch": 101.54,
      "learning_rate": 0.0898496886069132,
      "loss": 3.2329,
      "step": 63160
    },
    {
      "epoch": 101.58,
      "learning_rate": 0.08984647317604502,
      "loss": 3.1931,
      "step": 63180
    },
    {
      "epoch": 101.61,
      "learning_rate": 0.08984325774517685,
      "loss": 3.1763,
      "step": 63200
    },
    {
      "epoch": 101.64,
      "learning_rate": 0.08984004231430869,
      "loss": 3.1821,
      "step": 63220
    },
    {
      "epoch": 101.67,
      "learning_rate": 0.08983682688344051,
      "loss": 3.1563,
      "step": 63240
    },
    {
      "epoch": 101.7,
      "learning_rate": 0.08983361145257236,
      "loss": 3.1855,
      "step": 63260
    },
    {
      "epoch": 101.74,
      "learning_rate": 0.08983039602170419,
      "loss": 3.2347,
      "step": 63280
    },
    {
      "epoch": 101.77,
      "learning_rate": 0.08982718059083601,
      "loss": 3.2462,
      "step": 63300
    },
    {
      "epoch": 101.8,
      "learning_rate": 0.08982396515996785,
      "loss": 3.2145,
      "step": 63320
    },
    {
      "epoch": 101.83,
      "learning_rate": 0.08982074972909967,
      "loss": 3.2313,
      "step": 63340
    },
    {
      "epoch": 101.86,
      "learning_rate": 0.08981753429823153,
      "loss": 3.2167,
      "step": 63360
    },
    {
      "epoch": 101.9,
      "learning_rate": 0.08981431886736335,
      "loss": 3.1852,
      "step": 63380
    },
    {
      "epoch": 101.93,
      "learning_rate": 0.08981110343649518,
      "loss": 3.1937,
      "step": 63400
    },
    {
      "epoch": 101.96,
      "learning_rate": 0.08980788800562702,
      "loss": 3.1988,
      "step": 63420
    },
    {
      "epoch": 101.99,
      "learning_rate": 0.08980467257475884,
      "loss": 3.1943,
      "step": 63440
    },
    {
      "epoch": 102.0,
      "eval_accuracy": {
        "accuracy": 0.34502060172588045
      },
      "eval_loss": 3.3128905296325684,
      "eval_runtime": 2.8371,
      "eval_samples_per_second": 4533.855,
      "eval_steps_per_second": 70.847,
      "step": 63444
    },
    {
      "epoch": 102.03,
      "learning_rate": 0.08980145714389069,
      "loss": 3.2105,
      "step": 63460
    },
    {
      "epoch": 102.06,
      "learning_rate": 0.08979824171302252,
      "loss": 3.268,
      "step": 63480
    },
    {
      "epoch": 102.09,
      "learning_rate": 0.08979502628215434,
      "loss": 3.2675,
      "step": 63500
    },
    {
      "epoch": 102.12,
      "learning_rate": 0.08979181085128618,
      "loss": 3.2903,
      "step": 63520
    },
    {
      "epoch": 102.15,
      "learning_rate": 0.089788595420418,
      "loss": 3.2666,
      "step": 63540
    },
    {
      "epoch": 102.19,
      "learning_rate": 0.08978537998954984,
      "loss": 3.2404,
      "step": 63560
    },
    {
      "epoch": 102.22,
      "learning_rate": 0.08978216455868167,
      "loss": 3.1894,
      "step": 63580
    },
    {
      "epoch": 102.25,
      "learning_rate": 0.0897789491278135,
      "loss": 3.235,
      "step": 63600
    },
    {
      "epoch": 102.28,
      "learning_rate": 0.08977573369694535,
      "loss": 3.1885,
      "step": 63620
    },
    {
      "epoch": 102.32,
      "learning_rate": 0.08977251826607717,
      "loss": 3.2448,
      "step": 63640
    },
    {
      "epoch": 102.35,
      "learning_rate": 0.08976930283520901,
      "loss": 3.1939,
      "step": 63660
    },
    {
      "epoch": 102.38,
      "learning_rate": 0.08976608740434083,
      "loss": 3.1636,
      "step": 63680
    },
    {
      "epoch": 102.41,
      "learning_rate": 0.08976287197347267,
      "loss": 3.1823,
      "step": 63700
    },
    {
      "epoch": 102.44,
      "learning_rate": 0.08975965654260451,
      "loss": 3.1939,
      "step": 63720
    },
    {
      "epoch": 102.48,
      "learning_rate": 0.08975644111173633,
      "loss": 3.2569,
      "step": 63740
    },
    {
      "epoch": 102.51,
      "learning_rate": 0.08975322568086817,
      "loss": 3.2003,
      "step": 63760
    },
    {
      "epoch": 102.54,
      "learning_rate": 0.08975001025,
      "loss": 3.2185,
      "step": 63780
    },
    {
      "epoch": 102.57,
      "learning_rate": 0.08974679481913185,
      "loss": 3.2135,
      "step": 63800
    },
    {
      "epoch": 102.6,
      "learning_rate": 0.08974357938826368,
      "loss": 3.1935,
      "step": 63820
    },
    {
      "epoch": 102.64,
      "learning_rate": 0.0897403639573955,
      "loss": 3.2197,
      "step": 63840
    },
    {
      "epoch": 102.67,
      "learning_rate": 0.08973714852652734,
      "loss": 3.2179,
      "step": 63860
    },
    {
      "epoch": 102.7,
      "learning_rate": 0.08973393309565916,
      "loss": 3.2804,
      "step": 63880
    },
    {
      "epoch": 102.73,
      "learning_rate": 0.089730717664791,
      "loss": 3.2533,
      "step": 63900
    },
    {
      "epoch": 102.77,
      "learning_rate": 0.08972750223392283,
      "loss": 3.1937,
      "step": 63920
    },
    {
      "epoch": 102.8,
      "learning_rate": 0.08972428680305466,
      "loss": 3.2032,
      "step": 63940
    },
    {
      "epoch": 102.83,
      "learning_rate": 0.0897210713721865,
      "loss": 3.1942,
      "step": 63960
    },
    {
      "epoch": 102.86,
      "learning_rate": 0.08971785594131833,
      "loss": 3.1867,
      "step": 63980
    },
    {
      "epoch": 102.89,
      "learning_rate": 0.08971464051045017,
      "loss": 3.1668,
      "step": 64000
    },
    {
      "epoch": 102.93,
      "learning_rate": 0.08971142507958199,
      "loss": 3.1812,
      "step": 64020
    },
    {
      "epoch": 102.96,
      "learning_rate": 0.08970820964871383,
      "loss": 3.1882,
      "step": 64040
    },
    {
      "epoch": 102.99,
      "learning_rate": 0.08970499421784567,
      "loss": 3.2097,
      "step": 64060
    },
    {
      "epoch": 103.0,
      "eval_accuracy": {
        "accuracy": 0.3450983440876934
      },
      "eval_loss": 3.3352627754211426,
      "eval_runtime": 2.9691,
      "eval_samples_per_second": 4332.347,
      "eval_steps_per_second": 67.698,
      "step": 64066
    },
    {
      "epoch": 103.02,
      "learning_rate": 0.08970177878697749,
      "loss": 3.234,
      "step": 64080
    },
    {
      "epoch": 103.05,
      "learning_rate": 0.08969856335610933,
      "loss": 3.1911,
      "step": 64100
    },
    {
      "epoch": 103.09,
      "learning_rate": 0.08969534792524116,
      "loss": 3.2342,
      "step": 64120
    },
    {
      "epoch": 103.12,
      "learning_rate": 0.089692132494373,
      "loss": 3.1889,
      "step": 64140
    },
    {
      "epoch": 103.15,
      "learning_rate": 0.08968891706350483,
      "loss": 3.2063,
      "step": 64160
    },
    {
      "epoch": 103.18,
      "learning_rate": 0.08968570163263666,
      "loss": 3.1549,
      "step": 64180
    },
    {
      "epoch": 103.22,
      "learning_rate": 0.0896824862017685,
      "loss": 3.1553,
      "step": 64200
    },
    {
      "epoch": 103.25,
      "learning_rate": 0.08967927077090032,
      "loss": 3.1718,
      "step": 64220
    },
    {
      "epoch": 103.28,
      "learning_rate": 0.08967605534003216,
      "loss": 3.1574,
      "step": 64240
    },
    {
      "epoch": 103.31,
      "learning_rate": 0.089672839909164,
      "loss": 3.1237,
      "step": 64260
    },
    {
      "epoch": 103.34,
      "learning_rate": 0.08966962447829582,
      "loss": 3.2323,
      "step": 64280
    },
    {
      "epoch": 103.38,
      "learning_rate": 0.08966640904742766,
      "loss": 3.2008,
      "step": 64300
    },
    {
      "epoch": 103.41,
      "learning_rate": 0.08966319361655949,
      "loss": 3.2341,
      "step": 64320
    },
    {
      "epoch": 103.44,
      "learning_rate": 0.08965997818569132,
      "loss": 3.2186,
      "step": 64340
    },
    {
      "epoch": 103.47,
      "learning_rate": 0.08965676275482315,
      "loss": 3.2246,
      "step": 64360
    },
    {
      "epoch": 103.5,
      "learning_rate": 0.08965354732395499,
      "loss": 3.2396,
      "step": 64380
    },
    {
      "epoch": 103.54,
      "learning_rate": 0.08965033189308683,
      "loss": 3.203,
      "step": 64400
    },
    {
      "epoch": 103.57,
      "learning_rate": 0.08964711646221865,
      "loss": 3.1807,
      "step": 64420
    },
    {
      "epoch": 103.6,
      "learning_rate": 0.0896440618028939,
      "loss": 3.2358,
      "step": 64440
    },
    {
      "epoch": 103.63,
      "learning_rate": 0.08964084637202573,
      "loss": 3.3135,
      "step": 64460
    },
    {
      "epoch": 103.67,
      "learning_rate": 0.08963763094115756,
      "loss": 3.2597,
      "step": 64480
    },
    {
      "epoch": 103.7,
      "learning_rate": 0.08963441551028939,
      "loss": 3.2121,
      "step": 64500
    },
    {
      "epoch": 103.73,
      "learning_rate": 0.08963120007942123,
      "loss": 3.17,
      "step": 64520
    },
    {
      "epoch": 103.76,
      "learning_rate": 0.08962798464855307,
      "loss": 3.228,
      "step": 64540
    },
    {
      "epoch": 103.79,
      "learning_rate": 0.08962476921768489,
      "loss": 3.1834,
      "step": 64560
    },
    {
      "epoch": 103.83,
      "learning_rate": 0.08962155378681673,
      "loss": 3.1587,
      "step": 64580
    },
    {
      "epoch": 103.86,
      "learning_rate": 0.08961833835594855,
      "loss": 3.1647,
      "step": 64600
    },
    {
      "epoch": 103.89,
      "learning_rate": 0.08961512292508038,
      "loss": 3.1378,
      "step": 64620
    },
    {
      "epoch": 103.92,
      "learning_rate": 0.08961190749421223,
      "loss": 3.1821,
      "step": 64640
    },
    {
      "epoch": 103.95,
      "learning_rate": 0.08960869206334406,
      "loss": 3.1933,
      "step": 64660
    },
    {
      "epoch": 103.99,
      "learning_rate": 0.0896054766324759,
      "loss": 3.1557,
      "step": 64680
    },
    {
      "epoch": 104.0,
      "eval_accuracy": {
        "accuracy": 0.35629324418875846
      },
      "eval_loss": 3.244462728500366,
      "eval_runtime": 2.6665,
      "eval_samples_per_second": 4823.939,
      "eval_steps_per_second": 75.38,
      "step": 64688
    },
    {
      "epoch": 104.02,
      "learning_rate": 0.08960226120160772,
      "loss": 3.2414,
      "step": 64700
    },
    {
      "epoch": 104.05,
      "learning_rate": 0.08959904577073956,
      "loss": 3.1781,
      "step": 64720
    },
    {
      "epoch": 104.08,
      "learning_rate": 0.0895958303398714,
      "loss": 3.2195,
      "step": 64740
    },
    {
      "epoch": 104.12,
      "learning_rate": 0.08959261490900322,
      "loss": 3.193,
      "step": 64760
    },
    {
      "epoch": 104.15,
      "learning_rate": 0.08958939947813506,
      "loss": 3.206,
      "step": 64780
    },
    {
      "epoch": 104.18,
      "learning_rate": 0.08958618404726688,
      "loss": 3.1294,
      "step": 64800
    },
    {
      "epoch": 104.21,
      "learning_rate": 0.08958296861639872,
      "loss": 3.1674,
      "step": 64820
    },
    {
      "epoch": 104.24,
      "learning_rate": 0.08957975318553056,
      "loss": 3.2225,
      "step": 64840
    },
    {
      "epoch": 104.28,
      "learning_rate": 0.08957653775466239,
      "loss": 3.2107,
      "step": 64860
    },
    {
      "epoch": 104.31,
      "learning_rate": 0.08957332232379422,
      "loss": 3.2365,
      "step": 64880
    },
    {
      "epoch": 104.34,
      "learning_rate": 0.08957010689292605,
      "loss": 3.2554,
      "step": 64900
    },
    {
      "epoch": 104.37,
      "learning_rate": 0.08956689146205789,
      "loss": 3.2208,
      "step": 64920
    },
    {
      "epoch": 104.41,
      "learning_rate": 0.08956367603118971,
      "loss": 3.1961,
      "step": 64940
    },
    {
      "epoch": 104.44,
      "learning_rate": 0.08956046060032154,
      "loss": 3.2154,
      "step": 64960
    },
    {
      "epoch": 104.47,
      "learning_rate": 0.08955724516945339,
      "loss": 3.1956,
      "step": 64980
    },
    {
      "epoch": 104.5,
      "learning_rate": 0.08955402973858521,
      "loss": 3.1987,
      "step": 65000
    },
    {
      "epoch": 104.53,
      "learning_rate": 0.08955081430771705,
      "loss": 3.2184,
      "step": 65020
    },
    {
      "epoch": 104.57,
      "learning_rate": 0.08954759887684888,
      "loss": 3.2109,
      "step": 65040
    },
    {
      "epoch": 104.6,
      "learning_rate": 0.0895443834459807,
      "loss": 3.2248,
      "step": 65060
    },
    {
      "epoch": 104.63,
      "learning_rate": 0.08954116801511255,
      "loss": 3.2067,
      "step": 65080
    },
    {
      "epoch": 104.66,
      "learning_rate": 0.08953795258424438,
      "loss": 3.2028,
      "step": 65100
    },
    {
      "epoch": 104.69,
      "learning_rate": 0.08953473715337622,
      "loss": 3.1989,
      "step": 65120
    },
    {
      "epoch": 104.73,
      "learning_rate": 0.08953152172250804,
      "loss": 3.2438,
      "step": 65140
    },
    {
      "epoch": 104.76,
      "learning_rate": 0.08952830629163987,
      "loss": 3.2199,
      "step": 65160
    },
    {
      "epoch": 104.79,
      "learning_rate": 0.08952509086077172,
      "loss": 3.259,
      "step": 65180
    },
    {
      "epoch": 104.82,
      "learning_rate": 0.08952187542990354,
      "loss": 3.2027,
      "step": 65200
    },
    {
      "epoch": 104.86,
      "learning_rate": 0.08951865999903538,
      "loss": 3.2058,
      "step": 65220
    },
    {
      "epoch": 104.89,
      "learning_rate": 0.08951544456816721,
      "loss": 3.1706,
      "step": 65240
    },
    {
      "epoch": 104.92,
      "learning_rate": 0.08951222913729903,
      "loss": 3.1277,
      "step": 65260
    },
    {
      "epoch": 104.95,
      "learning_rate": 0.08950901370643087,
      "loss": 3.156,
      "step": 65280
    },
    {
      "epoch": 104.98,
      "learning_rate": 0.0895057982755627,
      "loss": 3.1835,
      "step": 65300
    },
    {
      "epoch": 105.0,
      "eval_accuracy": {
        "accuracy": 0.35450516986706054
      },
      "eval_loss": 3.2956182956695557,
      "eval_runtime": 2.9123,
      "eval_samples_per_second": 4416.807,
      "eval_steps_per_second": 69.018,
      "step": 65310
    },
    {
      "epoch": 105.02,
      "learning_rate": 0.08950258284469455,
      "loss": 3.1633,
      "step": 65320
    },
    {
      "epoch": 105.05,
      "learning_rate": 0.08949936741382637,
      "loss": 3.2121,
      "step": 65340
    },
    {
      "epoch": 105.08,
      "learning_rate": 0.08949615198295821,
      "loss": 3.1563,
      "step": 65360
    },
    {
      "epoch": 105.11,
      "learning_rate": 0.08949293655209004,
      "loss": 3.1406,
      "step": 65380
    },
    {
      "epoch": 105.14,
      "learning_rate": 0.08948972112122186,
      "loss": 3.1443,
      "step": 65400
    },
    {
      "epoch": 105.18,
      "learning_rate": 0.08948650569035371,
      "loss": 3.1898,
      "step": 65420
    },
    {
      "epoch": 105.21,
      "learning_rate": 0.08948329025948554,
      "loss": 3.2041,
      "step": 65440
    },
    {
      "epoch": 105.24,
      "learning_rate": 0.08948007482861738,
      "loss": 3.19,
      "step": 65460
    },
    {
      "epoch": 105.27,
      "learning_rate": 0.0894768593977492,
      "loss": 3.2201,
      "step": 65480
    },
    {
      "epoch": 105.31,
      "learning_rate": 0.08947364396688103,
      "loss": 3.2337,
      "step": 65500
    },
    {
      "epoch": 105.34,
      "learning_rate": 0.08947042853601288,
      "loss": 3.1926,
      "step": 65520
    },
    {
      "epoch": 105.37,
      "learning_rate": 0.0894672131051447,
      "loss": 3.183,
      "step": 65540
    },
    {
      "epoch": 105.4,
      "learning_rate": 0.08946399767427654,
      "loss": 3.1529,
      "step": 65560
    },
    {
      "epoch": 105.43,
      "learning_rate": 0.08946078224340837,
      "loss": 3.1611,
      "step": 65580
    },
    {
      "epoch": 105.47,
      "learning_rate": 0.08945756681254019,
      "loss": 3.203,
      "step": 65600
    },
    {
      "epoch": 105.5,
      "learning_rate": 0.08945435138167203,
      "loss": 3.203,
      "step": 65620
    },
    {
      "epoch": 105.53,
      "learning_rate": 0.08945113595080385,
      "loss": 3.2537,
      "step": 65640
    },
    {
      "epoch": 105.56,
      "learning_rate": 0.0894479205199357,
      "loss": 3.2065,
      "step": 65660
    },
    {
      "epoch": 105.59,
      "learning_rate": 0.08944470508906753,
      "loss": 3.1654,
      "step": 65680
    },
    {
      "epoch": 105.63,
      "learning_rate": 0.08944148965819936,
      "loss": 3.2164,
      "step": 65700
    },
    {
      "epoch": 105.66,
      "learning_rate": 0.0894382742273312,
      "loss": 3.1904,
      "step": 65720
    },
    {
      "epoch": 105.69,
      "learning_rate": 0.08943505879646302,
      "loss": 3.2549,
      "step": 65740
    },
    {
      "epoch": 105.72,
      "learning_rate": 0.08943184336559487,
      "loss": 3.2168,
      "step": 65760
    },
    {
      "epoch": 105.76,
      "learning_rate": 0.0894286279347267,
      "loss": 3.1966,
      "step": 65780
    },
    {
      "epoch": 105.79,
      "learning_rate": 0.08942541250385852,
      "loss": 3.155,
      "step": 65800
    },
    {
      "epoch": 105.82,
      "learning_rate": 0.08942219707299036,
      "loss": 3.1666,
      "step": 65820
    },
    {
      "epoch": 105.85,
      "learning_rate": 0.08941898164212218,
      "loss": 3.1835,
      "step": 65840
    },
    {
      "epoch": 105.88,
      "learning_rate": 0.08941576621125404,
      "loss": 3.2457,
      "step": 65860
    },
    {
      "epoch": 105.92,
      "learning_rate": 0.08941255078038586,
      "loss": 3.1962,
      "step": 65880
    },
    {
      "epoch": 105.95,
      "learning_rate": 0.08940933534951769,
      "loss": 3.168,
      "step": 65900
    },
    {
      "epoch": 105.98,
      "learning_rate": 0.08940611991864952,
      "loss": 3.1858,
      "step": 65920
    },
    {
      "epoch": 106.0,
      "eval_accuracy": {
        "accuracy": 0.35730389489232683
      },
      "eval_loss": 3.30582332611084,
      "eval_runtime": 3.2874,
      "eval_samples_per_second": 3912.762,
      "eval_steps_per_second": 61.142,
      "step": 65932
    },
    {
      "epoch": 106.01,
      "learning_rate": 0.08940290448778135,
      "loss": 3.2072,
      "step": 65940
    },
    {
      "epoch": 106.05,
      "learning_rate": 0.08939968905691319,
      "loss": 3.2164,
      "step": 65960
    },
    {
      "epoch": 106.08,
      "learning_rate": 0.08939647362604501,
      "loss": 3.1713,
      "step": 65980
    },
    {
      "epoch": 106.11,
      "learning_rate": 0.08939325819517686,
      "loss": 3.1745,
      "step": 66000
    },
    {
      "epoch": 106.14,
      "learning_rate": 0.08939004276430869,
      "loss": 3.2177,
      "step": 66020
    },
    {
      "epoch": 106.17,
      "learning_rate": 0.08938682733344051,
      "loss": 3.2356,
      "step": 66040
    },
    {
      "epoch": 106.21,
      "learning_rate": 0.08938361190257235,
      "loss": 3.1754,
      "step": 66060
    },
    {
      "epoch": 106.24,
      "learning_rate": 0.08938039647170418,
      "loss": 3.2172,
      "step": 66080
    },
    {
      "epoch": 106.27,
      "learning_rate": 0.08937718104083603,
      "loss": 3.1798,
      "step": 66100
    },
    {
      "epoch": 106.3,
      "learning_rate": 0.08937396560996785,
      "loss": 3.1447,
      "step": 66120
    },
    {
      "epoch": 106.33,
      "learning_rate": 0.08937075017909968,
      "loss": 3.1213,
      "step": 66140
    },
    {
      "epoch": 106.37,
      "learning_rate": 0.08936753474823152,
      "loss": 3.113,
      "step": 66160
    },
    {
      "epoch": 106.4,
      "learning_rate": 0.08936431931736334,
      "loss": 3.1445,
      "step": 66180
    },
    {
      "epoch": 106.43,
      "learning_rate": 0.0893611038864952,
      "loss": 3.1892,
      "step": 66200
    },
    {
      "epoch": 106.46,
      "learning_rate": 0.08935788845562702,
      "loss": 3.208,
      "step": 66220
    },
    {
      "epoch": 106.5,
      "learning_rate": 0.08935467302475884,
      "loss": 3.215,
      "step": 66240
    },
    {
      "epoch": 106.53,
      "learning_rate": 0.08935145759389068,
      "loss": 3.1728,
      "step": 66260
    },
    {
      "epoch": 106.56,
      "learning_rate": 0.0893482421630225,
      "loss": 3.0989,
      "step": 66280
    },
    {
      "epoch": 106.59,
      "learning_rate": 0.08934502673215435,
      "loss": 3.1665,
      "step": 66300
    },
    {
      "epoch": 106.62,
      "learning_rate": 0.08934181130128617,
      "loss": 3.1637,
      "step": 66320
    },
    {
      "epoch": 106.66,
      "learning_rate": 0.08933859587041801,
      "loss": 3.1765,
      "step": 66340
    },
    {
      "epoch": 106.69,
      "learning_rate": 0.08933538043954985,
      "loss": 3.2253,
      "step": 66360
    },
    {
      "epoch": 106.72,
      "learning_rate": 0.08933216500868167,
      "loss": 3.205,
      "step": 66380
    },
    {
      "epoch": 106.75,
      "learning_rate": 0.08932894957781351,
      "loss": 3.1483,
      "step": 66400
    },
    {
      "epoch": 106.78,
      "learning_rate": 0.08932573414694533,
      "loss": 3.1591,
      "step": 66420
    },
    {
      "epoch": 106.82,
      "learning_rate": 0.08932251871607717,
      "loss": 3.174,
      "step": 66440
    },
    {
      "epoch": 106.85,
      "learning_rate": 0.08931930328520901,
      "loss": 3.1915,
      "step": 66460
    },
    {
      "epoch": 106.88,
      "learning_rate": 0.08931608785434084,
      "loss": 3.1691,
      "step": 66480
    },
    {
      "epoch": 106.91,
      "learning_rate": 0.08931287242347268,
      "loss": 3.149,
      "step": 66500
    },
    {
      "epoch": 106.95,
      "learning_rate": 0.0893096569926045,
      "loss": 3.2052,
      "step": 66520
    },
    {
      "epoch": 106.98,
      "learning_rate": 0.08930644156173634,
      "loss": 3.2444,
      "step": 66540
    },
    {
      "epoch": 107.0,
      "eval_accuracy": {
        "accuracy": 0.34665319132395245
      },
      "eval_loss": 3.3085739612579346,
      "eval_runtime": 2.8248,
      "eval_samples_per_second": 4553.63,
      "eval_steps_per_second": 71.156,
      "step": 66554
    },
    {
      "epoch": 107.01,
      "learning_rate": 0.08930322613086818,
      "loss": 3.2269,
      "step": 66560
    },
    {
      "epoch": 107.04,
      "learning_rate": 0.0893000107,
      "loss": 3.1991,
      "step": 66580
    },
    {
      "epoch": 107.07,
      "learning_rate": 0.08929679526913184,
      "loss": 3.1569,
      "step": 66600
    },
    {
      "epoch": 107.11,
      "learning_rate": 0.08929357983826366,
      "loss": 3.1846,
      "step": 66620
    },
    {
      "epoch": 107.14,
      "learning_rate": 0.0892903644073955,
      "loss": 3.2161,
      "step": 66640
    },
    {
      "epoch": 107.17,
      "learning_rate": 0.08928714897652734,
      "loss": 3.137,
      "step": 66660
    },
    {
      "epoch": 107.2,
      "learning_rate": 0.08928393354565917,
      "loss": 3.1501,
      "step": 66680
    },
    {
      "epoch": 107.23,
      "learning_rate": 0.089280718114791,
      "loss": 3.1935,
      "step": 66700
    },
    {
      "epoch": 107.27,
      "learning_rate": 0.08927750268392283,
      "loss": 3.2208,
      "step": 66720
    },
    {
      "epoch": 107.3,
      "learning_rate": 0.08927428725305467,
      "loss": 3.1942,
      "step": 66740
    },
    {
      "epoch": 107.33,
      "learning_rate": 0.08927107182218649,
      "loss": 3.1461,
      "step": 66760
    },
    {
      "epoch": 107.36,
      "learning_rate": 0.08926785639131833,
      "loss": 3.1972,
      "step": 66780
    },
    {
      "epoch": 107.4,
      "learning_rate": 0.08926464096045017,
      "loss": 3.176,
      "step": 66800
    },
    {
      "epoch": 107.43,
      "learning_rate": 0.089261425529582,
      "loss": 3.2137,
      "step": 66820
    },
    {
      "epoch": 107.46,
      "learning_rate": 0.08925821009871383,
      "loss": 3.1392,
      "step": 66840
    },
    {
      "epoch": 107.49,
      "learning_rate": 0.08925499466784566,
      "loss": 3.1229,
      "step": 66860
    },
    {
      "epoch": 107.52,
      "learning_rate": 0.0892517792369775,
      "loss": 3.1629,
      "step": 66880
    },
    {
      "epoch": 107.56,
      "learning_rate": 0.08924856380610934,
      "loss": 3.1906,
      "step": 66900
    },
    {
      "epoch": 107.59,
      "learning_rate": 0.08924534837524116,
      "loss": 3.1347,
      "step": 66920
    },
    {
      "epoch": 107.62,
      "learning_rate": 0.089242132944373,
      "loss": 3.1832,
      "step": 66940
    },
    {
      "epoch": 107.65,
      "learning_rate": 0.08923891751350482,
      "loss": 3.1952,
      "step": 66960
    },
    {
      "epoch": 107.68,
      "learning_rate": 0.08923570208263666,
      "loss": 3.1989,
      "step": 66980
    },
    {
      "epoch": 107.72,
      "learning_rate": 0.0892324866517685,
      "loss": 3.1517,
      "step": 67000
    },
    {
      "epoch": 107.75,
      "learning_rate": 0.08922927122090032,
      "loss": 3.1477,
      "step": 67020
    },
    {
      "epoch": 107.78,
      "learning_rate": 0.08922605579003216,
      "loss": 3.1774,
      "step": 67040
    },
    {
      "epoch": 107.81,
      "learning_rate": 0.08922284035916399,
      "loss": 3.1877,
      "step": 67060
    },
    {
      "epoch": 107.85,
      "learning_rate": 0.08921962492829583,
      "loss": 3.1823,
      "step": 67080
    },
    {
      "epoch": 107.88,
      "learning_rate": 0.08921640949742765,
      "loss": 3.1918,
      "step": 67100
    },
    {
      "epoch": 107.91,
      "learning_rate": 0.08921319406655949,
      "loss": 3.1709,
      "step": 67120
    },
    {
      "epoch": 107.94,
      "learning_rate": 0.08920997863569133,
      "loss": 3.1598,
      "step": 67140
    },
    {
      "epoch": 107.97,
      "learning_rate": 0.08920676320482315,
      "loss": 3.1535,
      "step": 67160
    },
    {
      "epoch": 108.0,
      "eval_accuracy": {
        "accuracy": 0.35745937961595275
      },
      "eval_loss": 3.2204415798187256,
      "eval_runtime": 2.5335,
      "eval_samples_per_second": 5077.094,
      "eval_steps_per_second": 79.336,
      "step": 67176
    },
    {
      "epoch": 108.01,
      "learning_rate": 0.08920354777395499,
      "loss": 3.1395,
      "step": 67180
    },
    {
      "epoch": 108.04,
      "learning_rate": 0.08920033234308682,
      "loss": 3.1354,
      "step": 67200
    },
    {
      "epoch": 108.07,
      "learning_rate": 0.08919711691221865,
      "loss": 3.1545,
      "step": 67220
    },
    {
      "epoch": 108.1,
      "learning_rate": 0.0891939014813505,
      "loss": 3.1852,
      "step": 67240
    },
    {
      "epoch": 108.14,
      "learning_rate": 0.08919068605048232,
      "loss": 3.1887,
      "step": 67260
    },
    {
      "epoch": 108.17,
      "learning_rate": 0.08918747061961416,
      "loss": 3.2228,
      "step": 67280
    },
    {
      "epoch": 108.2,
      "learning_rate": 0.08918425518874598,
      "loss": 3.2245,
      "step": 67300
    },
    {
      "epoch": 108.23,
      "learning_rate": 0.08918103975787782,
      "loss": 3.2108,
      "step": 67320
    },
    {
      "epoch": 108.26,
      "learning_rate": 0.08917782432700966,
      "loss": 3.1973,
      "step": 67340
    },
    {
      "epoch": 108.3,
      "learning_rate": 0.08917460889614148,
      "loss": 3.1566,
      "step": 67360
    },
    {
      "epoch": 108.33,
      "learning_rate": 0.08917139346527332,
      "loss": 3.1664,
      "step": 67380
    },
    {
      "epoch": 108.36,
      "learning_rate": 0.08916817803440515,
      "loss": 3.1832,
      "step": 67400
    },
    {
      "epoch": 108.39,
      "learning_rate": 0.08916496260353698,
      "loss": 3.1717,
      "step": 67420
    },
    {
      "epoch": 108.42,
      "learning_rate": 0.08916174717266881,
      "loss": 3.1577,
      "step": 67440
    },
    {
      "epoch": 108.46,
      "learning_rate": 0.08915853174180065,
      "loss": 3.1446,
      "step": 67460
    },
    {
      "epoch": 108.49,
      "learning_rate": 0.08915531631093249,
      "loss": 3.2025,
      "step": 67480
    },
    {
      "epoch": 108.52,
      "learning_rate": 0.08915210088006431,
      "loss": 3.1652,
      "step": 67500
    },
    {
      "epoch": 108.55,
      "learning_rate": 0.08914888544919615,
      "loss": 3.1823,
      "step": 67520
    },
    {
      "epoch": 108.59,
      "learning_rate": 0.08914567001832797,
      "loss": 3.1697,
      "step": 67540
    },
    {
      "epoch": 108.62,
      "learning_rate": 0.08914245458745981,
      "loss": 3.2196,
      "step": 67560
    },
    {
      "epoch": 108.65,
      "learning_rate": 0.08913923915659165,
      "loss": 3.2215,
      "step": 67580
    },
    {
      "epoch": 108.68,
      "learning_rate": 0.08913602372572348,
      "loss": 3.2015,
      "step": 67600
    },
    {
      "epoch": 108.71,
      "learning_rate": 0.08913280829485531,
      "loss": 3.2168,
      "step": 67620
    },
    {
      "epoch": 108.75,
      "learning_rate": 0.08912959286398714,
      "loss": 3.1699,
      "step": 67640
    },
    {
      "epoch": 108.78,
      "learning_rate": 0.08912637743311898,
      "loss": 3.2052,
      "step": 67660
    },
    {
      "epoch": 108.81,
      "learning_rate": 0.08912316200225082,
      "loss": 3.1958,
      "step": 67680
    },
    {
      "epoch": 108.84,
      "learning_rate": 0.08911994657138264,
      "loss": 3.1713,
      "step": 67700
    },
    {
      "epoch": 108.87,
      "learning_rate": 0.08911673114051448,
      "loss": 3.2018,
      "step": 67720
    },
    {
      "epoch": 108.91,
      "learning_rate": 0.0891135157096463,
      "loss": 3.2233,
      "step": 67740
    },
    {
      "epoch": 108.94,
      "learning_rate": 0.08911030027877814,
      "loss": 3.1997,
      "step": 67760
    },
    {
      "epoch": 108.97,
      "learning_rate": 0.08910708484790997,
      "loss": 3.2207,
      "step": 67780
    },
    {
      "epoch": 109.0,
      "eval_accuracy": {
        "accuracy": 0.3547383969524994
      },
      "eval_loss": 3.2496519088745117,
      "eval_runtime": 2.5331,
      "eval_samples_per_second": 5077.88,
      "eval_steps_per_second": 79.348,
      "step": 67798
    },
    {
      "epoch": 109.0,
      "learning_rate": 0.0891038694170418,
      "loss": 3.2023,
      "step": 67800
    },
    {
      "epoch": 109.04,
      "learning_rate": 0.08910065398617364,
      "loss": 3.168,
      "step": 67820
    },
    {
      "epoch": 109.07,
      "learning_rate": 0.08909743855530547,
      "loss": 3.1996,
      "step": 67840
    },
    {
      "epoch": 109.1,
      "learning_rate": 0.08909422312443731,
      "loss": 3.1716,
      "step": 67860
    },
    {
      "epoch": 109.13,
      "learning_rate": 0.08909100769356913,
      "loss": 3.2245,
      "step": 67880
    },
    {
      "epoch": 109.16,
      "learning_rate": 0.08908779226270097,
      "loss": 3.1637,
      "step": 67900
    },
    {
      "epoch": 109.2,
      "learning_rate": 0.08908457683183281,
      "loss": 3.1585,
      "step": 67920
    },
    {
      "epoch": 109.23,
      "learning_rate": 0.08908136140096463,
      "loss": 3.1169,
      "step": 67940
    },
    {
      "epoch": 109.26,
      "learning_rate": 0.08907814597009647,
      "loss": 3.1204,
      "step": 67960
    },
    {
      "epoch": 109.29,
      "learning_rate": 0.0890749305392283,
      "loss": 3.1214,
      "step": 67980
    },
    {
      "epoch": 109.32,
      "learning_rate": 0.08907171510836012,
      "loss": 3.1806,
      "step": 68000
    },
    {
      "epoch": 109.36,
      "learning_rate": 0.08906849967749197,
      "loss": 3.1892,
      "step": 68020
    },
    {
      "epoch": 109.39,
      "learning_rate": 0.0890652842466238,
      "loss": 3.168,
      "step": 68040
    },
    {
      "epoch": 109.42,
      "learning_rate": 0.08906206881575564,
      "loss": 3.1335,
      "step": 68060
    },
    {
      "epoch": 109.45,
      "learning_rate": 0.08905885338488746,
      "loss": 3.1775,
      "step": 68080
    },
    {
      "epoch": 109.49,
      "learning_rate": 0.0890556379540193,
      "loss": 3.1781,
      "step": 68100
    },
    {
      "epoch": 109.52,
      "learning_rate": 0.08905242252315113,
      "loss": 3.1932,
      "step": 68120
    },
    {
      "epoch": 109.55,
      "learning_rate": 0.08904920709228296,
      "loss": 3.1611,
      "step": 68140
    },
    {
      "epoch": 109.58,
      "learning_rate": 0.0890459916614148,
      "loss": 3.1904,
      "step": 68160
    },
    {
      "epoch": 109.61,
      "learning_rate": 0.08904277623054663,
      "loss": 3.1374,
      "step": 68180
    },
    {
      "epoch": 109.65,
      "learning_rate": 0.08903956079967847,
      "loss": 3.1594,
      "step": 68200
    },
    {
      "epoch": 109.68,
      "learning_rate": 0.08903634536881029,
      "loss": 3.2053,
      "step": 68220
    },
    {
      "epoch": 109.71,
      "learning_rate": 0.08903312993794213,
      "loss": 3.1559,
      "step": 68240
    },
    {
      "epoch": 109.74,
      "learning_rate": 0.08902991450707397,
      "loss": 3.1462,
      "step": 68260
    },
    {
      "epoch": 109.77,
      "learning_rate": 0.08902669907620579,
      "loss": 3.1313,
      "step": 68280
    },
    {
      "epoch": 109.81,
      "learning_rate": 0.08902348364533763,
      "loss": 3.1859,
      "step": 68300
    },
    {
      "epoch": 109.84,
      "learning_rate": 0.08902026821446946,
      "loss": 3.2184,
      "step": 68320
    },
    {
      "epoch": 109.87,
      "learning_rate": 0.0890170527836013,
      "loss": 3.1772,
      "step": 68340
    },
    {
      "epoch": 109.9,
      "learning_rate": 0.08901383735273313,
      "loss": 3.225,
      "step": 68360
    },
    {
      "epoch": 109.94,
      "learning_rate": 0.08901062192186496,
      "loss": 3.2109,
      "step": 68380
    },
    {
      "epoch": 109.97,
      "learning_rate": 0.0890074064909968,
      "loss": 3.2359,
      "step": 68400
    },
    {
      "epoch": 110.0,
      "learning_rate": 0.08900419106012862,
      "loss": 3.1781,
      "step": 68420
    },
    {
      "epoch": 110.0,
      "eval_accuracy": {
        "accuracy": 0.3461089947912618
      },
      "eval_loss": 3.294010639190674,
      "eval_runtime": 2.5638,
      "eval_samples_per_second": 5017.08,
      "eval_steps_per_second": 78.398,
      "step": 68420
    },
    {
      "epoch": 110.03,
      "learning_rate": 0.08900113640080386,
      "loss": 3.1417,
      "step": 68440
    },
    {
      "epoch": 110.06,
      "learning_rate": 0.0889979209699357,
      "loss": 3.1847,
      "step": 68460
    },
    {
      "epoch": 110.1,
      "learning_rate": 0.08899470553906752,
      "loss": 3.2122,
      "step": 68480
    },
    {
      "epoch": 110.13,
      "learning_rate": 0.08899149010819937,
      "loss": 3.1572,
      "step": 68500
    },
    {
      "epoch": 110.16,
      "learning_rate": 0.0889882746773312,
      "loss": 3.1985,
      "step": 68520
    },
    {
      "epoch": 110.19,
      "learning_rate": 0.08898505924646302,
      "loss": 3.1891,
      "step": 68540
    },
    {
      "epoch": 110.23,
      "learning_rate": 0.08898184381559486,
      "loss": 3.143,
      "step": 68560
    },
    {
      "epoch": 110.26,
      "learning_rate": 0.08897862838472669,
      "loss": 3.1594,
      "step": 68580
    },
    {
      "epoch": 110.29,
      "learning_rate": 0.08897541295385854,
      "loss": 3.1494,
      "step": 68600
    },
    {
      "epoch": 110.32,
      "learning_rate": 0.08897219752299036,
      "loss": 3.1491,
      "step": 68620
    },
    {
      "epoch": 110.35,
      "learning_rate": 0.08896898209212219,
      "loss": 3.1924,
      "step": 68640
    },
    {
      "epoch": 110.39,
      "learning_rate": 0.08896576666125403,
      "loss": 3.1505,
      "step": 68660
    },
    {
      "epoch": 110.42,
      "learning_rate": 0.08896255123038585,
      "loss": 3.2078,
      "step": 68680
    },
    {
      "epoch": 110.45,
      "learning_rate": 0.0889594965710611,
      "loss": 3.212,
      "step": 68700
    },
    {
      "epoch": 110.48,
      "learning_rate": 0.08895628114019292,
      "loss": 3.19,
      "step": 68720
    },
    {
      "epoch": 110.51,
      "learning_rate": 0.08895306570932476,
      "loss": 3.2289,
      "step": 68740
    },
    {
      "epoch": 110.55,
      "learning_rate": 0.0889498502784566,
      "loss": 3.1973,
      "step": 68760
    },
    {
      "epoch": 110.58,
      "learning_rate": 0.08894663484758843,
      "loss": 3.1681,
      "step": 68780
    },
    {
      "epoch": 110.61,
      "learning_rate": 0.08894341941672027,
      "loss": 3.164,
      "step": 68800
    },
    {
      "epoch": 110.64,
      "learning_rate": 0.08894020398585209,
      "loss": 3.1717,
      "step": 68820
    },
    {
      "epoch": 110.68,
      "learning_rate": 0.08893698855498393,
      "loss": 3.2075,
      "step": 68840
    },
    {
      "epoch": 110.71,
      "learning_rate": 0.08893377312411577,
      "loss": 3.2156,
      "step": 68860
    },
    {
      "epoch": 110.74,
      "learning_rate": 0.08893055769324759,
      "loss": 3.1719,
      "step": 68880
    },
    {
      "epoch": 110.77,
      "learning_rate": 0.08892734226237943,
      "loss": 3.1814,
      "step": 68900
    },
    {
      "epoch": 110.8,
      "learning_rate": 0.08892412683151125,
      "loss": 3.1448,
      "step": 68920
    },
    {
      "epoch": 110.84,
      "learning_rate": 0.0889209114006431,
      "loss": 3.1302,
      "step": 68940
    },
    {
      "epoch": 110.87,
      "learning_rate": 0.08891769596977492,
      "loss": 3.1393,
      "step": 68960
    },
    {
      "epoch": 110.9,
      "learning_rate": 0.08891448053890676,
      "loss": 3.1566,
      "step": 68980
    },
    {
      "epoch": 110.93,
      "learning_rate": 0.0889112651080386,
      "loss": 3.1919,
      "step": 69000
    },
    {
      "epoch": 110.96,
      "learning_rate": 0.08890804967717042,
      "loss": 3.1913,
      "step": 69020
    },
    {
      "epoch": 111.0,
      "learning_rate": 0.08890483424630226,
      "loss": 3.2217,
      "step": 69040
    },
    {
      "epoch": 111.0,
      "eval_accuracy": {
        "accuracy": 0.3533390344398663
      },
      "eval_loss": 3.313081741333008,
      "eval_runtime": 3.0489,
      "eval_samples_per_second": 4218.927,
      "eval_steps_per_second": 65.926,
      "step": 69042
    },
    {
      "epoch": 111.03,
      "learning_rate": 0.08890161881543408,
      "loss": 3.1961,
      "step": 69060
    },
    {
      "epoch": 111.06,
      "learning_rate": 0.08889840338456592,
      "loss": 3.222,
      "step": 69080
    },
    {
      "epoch": 111.09,
      "learning_rate": 0.08889518795369776,
      "loss": 3.2318,
      "step": 69100
    },
    {
      "epoch": 111.13,
      "learning_rate": 0.08889197252282958,
      "loss": 3.1447,
      "step": 69120
    },
    {
      "epoch": 111.16,
      "learning_rate": 0.08888875709196142,
      "loss": 3.1727,
      "step": 69140
    },
    {
      "epoch": 111.19,
      "learning_rate": 0.08888554166109325,
      "loss": 3.2312,
      "step": 69160
    },
    {
      "epoch": 111.22,
      "learning_rate": 0.08888232623022509,
      "loss": 3.1642,
      "step": 69180
    },
    {
      "epoch": 111.25,
      "learning_rate": 0.08887911079935693,
      "loss": 3.1789,
      "step": 69200
    },
    {
      "epoch": 111.29,
      "learning_rate": 0.08887589536848875,
      "loss": 3.1823,
      "step": 69220
    },
    {
      "epoch": 111.32,
      "learning_rate": 0.08887267993762059,
      "loss": 3.1575,
      "step": 69240
    },
    {
      "epoch": 111.35,
      "learning_rate": 0.08886946450675241,
      "loss": 3.1288,
      "step": 69260
    },
    {
      "epoch": 111.38,
      "learning_rate": 0.08886624907588425,
      "loss": 3.1655,
      "step": 69280
    },
    {
      "epoch": 111.41,
      "learning_rate": 0.08886303364501608,
      "loss": 3.2106,
      "step": 69300
    },
    {
      "epoch": 111.45,
      "learning_rate": 0.08885981821414791,
      "loss": 3.1493,
      "step": 69320
    },
    {
      "epoch": 111.48,
      "learning_rate": 0.08885660278327975,
      "loss": 3.1628,
      "step": 69340
    },
    {
      "epoch": 111.51,
      "learning_rate": 0.08885338735241158,
      "loss": 3.1432,
      "step": 69360
    },
    {
      "epoch": 111.54,
      "learning_rate": 0.08885017192154342,
      "loss": 3.1363,
      "step": 69380
    },
    {
      "epoch": 111.58,
      "learning_rate": 0.08884695649067524,
      "loss": 3.1472,
      "step": 69400
    },
    {
      "epoch": 111.61,
      "learning_rate": 0.08884374105980708,
      "loss": 3.1771,
      "step": 69420
    },
    {
      "epoch": 111.64,
      "learning_rate": 0.08884052562893892,
      "loss": 3.1668,
      "step": 69440
    },
    {
      "epoch": 111.67,
      "learning_rate": 0.08883731019807074,
      "loss": 3.195,
      "step": 69460
    },
    {
      "epoch": 111.7,
      "learning_rate": 0.08883409476720258,
      "loss": 3.1653,
      "step": 69480
    },
    {
      "epoch": 111.74,
      "learning_rate": 0.0888308793363344,
      "loss": 3.1503,
      "step": 69500
    },
    {
      "epoch": 111.77,
      "learning_rate": 0.08882766390546624,
      "loss": 3.1852,
      "step": 69520
    },
    {
      "epoch": 111.8,
      "learning_rate": 0.08882444847459808,
      "loss": 3.1441,
      "step": 69540
    },
    {
      "epoch": 111.83,
      "learning_rate": 0.08882123304372991,
      "loss": 3.1171,
      "step": 69560
    },
    {
      "epoch": 111.86,
      "learning_rate": 0.08881801761286175,
      "loss": 3.1549,
      "step": 69580
    },
    {
      "epoch": 111.9,
      "learning_rate": 0.08881480218199357,
      "loss": 3.1604,
      "step": 69600
    },
    {
      "epoch": 111.93,
      "learning_rate": 0.08881158675112541,
      "loss": 3.1656,
      "step": 69620
    },
    {
      "epoch": 111.96,
      "learning_rate": 0.08880837132025723,
      "loss": 3.1789,
      "step": 69640
    },
    {
      "epoch": 111.99,
      "learning_rate": 0.08880515588938907,
      "loss": 3.2054,
      "step": 69660
    },
    {
      "epoch": 112.0,
      "eval_accuracy": {
        "accuracy": 0.35116224830910364
      },
      "eval_loss": 3.286167860031128,
      "eval_runtime": 2.5991,
      "eval_samples_per_second": 4949.113,
      "eval_steps_per_second": 77.336,
      "step": 69664
    },
    {
      "epoch": 112.03,
      "learning_rate": 0.08880194045852091,
      "loss": 3.225,
      "step": 69680
    },
    {
      "epoch": 112.06,
      "learning_rate": 0.08879872502765274,
      "loss": 3.1696,
      "step": 69700
    },
    {
      "epoch": 112.09,
      "learning_rate": 0.08879550959678457,
      "loss": 3.1787,
      "step": 69720
    },
    {
      "epoch": 112.12,
      "learning_rate": 0.0887922941659164,
      "loss": 3.1774,
      "step": 69740
    },
    {
      "epoch": 112.15,
      "learning_rate": 0.08878907873504824,
      "loss": 3.1692,
      "step": 69760
    },
    {
      "epoch": 112.19,
      "learning_rate": 0.08878586330418008,
      "loss": 3.2047,
      "step": 69780
    },
    {
      "epoch": 112.22,
      "learning_rate": 0.0887826478733119,
      "loss": 3.1683,
      "step": 69800
    },
    {
      "epoch": 112.25,
      "learning_rate": 0.08877943244244374,
      "loss": 3.1469,
      "step": 69820
    },
    {
      "epoch": 112.28,
      "learning_rate": 0.08877621701157556,
      "loss": 3.1627,
      "step": 69840
    },
    {
      "epoch": 112.32,
      "learning_rate": 0.0887730015807074,
      "loss": 3.1495,
      "step": 69860
    },
    {
      "epoch": 112.35,
      "learning_rate": 0.08876978614983924,
      "loss": 3.1348,
      "step": 69880
    },
    {
      "epoch": 112.38,
      "learning_rate": 0.08876657071897107,
      "loss": 3.1704,
      "step": 69900
    },
    {
      "epoch": 112.41,
      "learning_rate": 0.0887633552881029,
      "loss": 3.1913,
      "step": 69920
    },
    {
      "epoch": 112.44,
      "learning_rate": 0.08876013985723473,
      "loss": 3.1461,
      "step": 69940
    },
    {
      "epoch": 112.48,
      "learning_rate": 0.08875692442636657,
      "loss": 3.161,
      "step": 69960
    },
    {
      "epoch": 112.51,
      "learning_rate": 0.0887537089954984,
      "loss": 3.1733,
      "step": 69980
    },
    {
      "epoch": 112.54,
      "learning_rate": 0.08875049356463023,
      "loss": 3.1625,
      "step": 70000
    },
    {
      "epoch": 112.57,
      "learning_rate": 0.08874727813376207,
      "loss": 3.1382,
      "step": 70020
    },
    {
      "epoch": 112.6,
      "learning_rate": 0.0887440627028939,
      "loss": 3.0807,
      "step": 70040
    },
    {
      "epoch": 112.64,
      "learning_rate": 0.08874084727202573,
      "loss": 3.1285,
      "step": 70060
    },
    {
      "epoch": 112.67,
      "learning_rate": 0.08873763184115756,
      "loss": 3.1492,
      "step": 70080
    },
    {
      "epoch": 112.7,
      "learning_rate": 0.08873441641028938,
      "loss": 3.1358,
      "step": 70100
    },
    {
      "epoch": 112.73,
      "learning_rate": 0.08873120097942123,
      "loss": 3.1685,
      "step": 70120
    },
    {
      "epoch": 112.77,
      "learning_rate": 0.08872798554855306,
      "loss": 3.1737,
      "step": 70140
    },
    {
      "epoch": 112.8,
      "learning_rate": 0.0887247701176849,
      "loss": 3.1727,
      "step": 70160
    },
    {
      "epoch": 112.83,
      "learning_rate": 0.08872155468681672,
      "loss": 3.1619,
      "step": 70180
    },
    {
      "epoch": 112.86,
      "learning_rate": 0.08871833925594855,
      "loss": 3.1315,
      "step": 70200
    },
    {
      "epoch": 112.89,
      "learning_rate": 0.0887151238250804,
      "loss": 3.1244,
      "step": 70220
    },
    {
      "epoch": 112.93,
      "learning_rate": 0.08871190839421222,
      "loss": 3.1852,
      "step": 70240
    },
    {
      "epoch": 112.96,
      "learning_rate": 0.08870869296334406,
      "loss": 3.1582,
      "step": 70260
    },
    {
      "epoch": 112.99,
      "learning_rate": 0.08870547753247589,
      "loss": 3.1467,
      "step": 70280
    },
    {
      "epoch": 113.0,
      "eval_accuracy": {
        "accuracy": 0.36826556790795306
      },
      "eval_loss": 3.2196342945098877,
      "eval_runtime": 2.5906,
      "eval_samples_per_second": 4965.182,
      "eval_steps_per_second": 77.587,
      "step": 70286
    },
    {
      "epoch": 113.02,
      "learning_rate": 0.08870226210160771,
      "loss": 3.1791,
      "step": 70300
    },
    {
      "epoch": 113.05,
      "learning_rate": 0.08869904667073956,
      "loss": 3.1662,
      "step": 70320
    },
    {
      "epoch": 113.09,
      "learning_rate": 0.08869583123987139,
      "loss": 3.1164,
      "step": 70340
    },
    {
      "epoch": 113.12,
      "learning_rate": 0.08869261580900323,
      "loss": 3.1259,
      "step": 70360
    },
    {
      "epoch": 113.15,
      "learning_rate": 0.08868940037813505,
      "loss": 3.1396,
      "step": 70380
    },
    {
      "epoch": 113.18,
      "learning_rate": 0.08868618494726689,
      "loss": 3.2227,
      "step": 70400
    },
    {
      "epoch": 113.22,
      "learning_rate": 0.08868296951639872,
      "loss": 3.2286,
      "step": 70420
    },
    {
      "epoch": 113.25,
      "learning_rate": 0.08867975408553054,
      "loss": 3.1969,
      "step": 70440
    },
    {
      "epoch": 113.28,
      "learning_rate": 0.08867653865466239,
      "loss": 3.179,
      "step": 70460
    },
    {
      "epoch": 113.31,
      "learning_rate": 0.08867332322379422,
      "loss": 3.1393,
      "step": 70480
    },
    {
      "epoch": 113.34,
      "learning_rate": 0.08867010779292606,
      "loss": 3.1336,
      "step": 70500
    },
    {
      "epoch": 113.38,
      "learning_rate": 0.08866689236205788,
      "loss": 3.1262,
      "step": 70520
    },
    {
      "epoch": 113.41,
      "learning_rate": 0.0886636769311897,
      "loss": 3.1805,
      "step": 70540
    },
    {
      "epoch": 113.44,
      "learning_rate": 0.08866046150032156,
      "loss": 3.1904,
      "step": 70560
    },
    {
      "epoch": 113.47,
      "learning_rate": 0.08865724606945338,
      "loss": 3.1943,
      "step": 70580
    },
    {
      "epoch": 113.5,
      "learning_rate": 0.08865403063858522,
      "loss": 3.2506,
      "step": 70600
    },
    {
      "epoch": 113.54,
      "learning_rate": 0.08865081520771705,
      "loss": 3.2247,
      "step": 70620
    },
    {
      "epoch": 113.57,
      "learning_rate": 0.08864759977684887,
      "loss": 3.1548,
      "step": 70640
    },
    {
      "epoch": 113.6,
      "learning_rate": 0.08864438434598072,
      "loss": 3.1619,
      "step": 70660
    },
    {
      "epoch": 113.63,
      "learning_rate": 0.08864116891511255,
      "loss": 3.1989,
      "step": 70680
    },
    {
      "epoch": 113.67,
      "learning_rate": 0.08863795348424439,
      "loss": 3.1718,
      "step": 70700
    },
    {
      "epoch": 113.7,
      "learning_rate": 0.08863473805337621,
      "loss": 3.1869,
      "step": 70720
    },
    {
      "epoch": 113.73,
      "learning_rate": 0.08863152262250804,
      "loss": 3.1622,
      "step": 70740
    },
    {
      "epoch": 113.76,
      "learning_rate": 0.08862830719163987,
      "loss": 3.198,
      "step": 70760
    },
    {
      "epoch": 113.79,
      "learning_rate": 0.0886250917607717,
      "loss": 3.2006,
      "step": 70780
    },
    {
      "epoch": 113.83,
      "learning_rate": 0.08862187632990355,
      "loss": 3.1764,
      "step": 70800
    },
    {
      "epoch": 113.86,
      "learning_rate": 0.08861866089903538,
      "loss": 3.1658,
      "step": 70820
    },
    {
      "epoch": 113.89,
      "learning_rate": 0.0886154454681672,
      "loss": 3.1863,
      "step": 70840
    },
    {
      "epoch": 113.92,
      "learning_rate": 0.08861223003729904,
      "loss": 3.1969,
      "step": 70860
    },
    {
      "epoch": 113.95,
      "learning_rate": 0.08860901460643086,
      "loss": 3.1944,
      "step": 70880
    },
    {
      "epoch": 113.99,
      "learning_rate": 0.08860579917556272,
      "loss": 3.2099,
      "step": 70900
    },
    {
      "epoch": 114.0,
      "eval_accuracy": {
        "accuracy": 0.3543496851434347
      },
      "eval_loss": 3.2783432006835938,
      "eval_runtime": 2.7231,
      "eval_samples_per_second": 4723.743,
      "eval_steps_per_second": 73.814,
      "step": 70908
    },
    {
      "epoch": 114.02,
      "learning_rate": 0.08860258374469454,
      "loss": 3.2081,
      "step": 70920
    },
    {
      "epoch": 114.05,
      "learning_rate": 0.08859936831382637,
      "loss": 3.1821,
      "step": 70940
    },
    {
      "epoch": 114.08,
      "learning_rate": 0.0885961528829582,
      "loss": 3.1659,
      "step": 70960
    },
    {
      "epoch": 114.12,
      "learning_rate": 0.08859293745209003,
      "loss": 3.1514,
      "step": 70980
    },
    {
      "epoch": 114.15,
      "learning_rate": 0.08858972202122188,
      "loss": 3.2082,
      "step": 71000
    },
    {
      "epoch": 114.18,
      "learning_rate": 0.0885865065903537,
      "loss": 3.2314,
      "step": 71020
    },
    {
      "epoch": 114.21,
      "learning_rate": 0.08858329115948554,
      "loss": 3.2003,
      "step": 71040
    },
    {
      "epoch": 114.24,
      "learning_rate": 0.08858007572861737,
      "loss": 3.1672,
      "step": 71060
    },
    {
      "epoch": 114.28,
      "learning_rate": 0.0885768602977492,
      "loss": 3.1395,
      "step": 71080
    },
    {
      "epoch": 114.31,
      "learning_rate": 0.08857364486688103,
      "loss": 3.1743,
      "step": 71100
    },
    {
      "epoch": 114.34,
      "learning_rate": 0.08857042943601286,
      "loss": 3.1944,
      "step": 71120
    },
    {
      "epoch": 114.37,
      "learning_rate": 0.08856721400514471,
      "loss": 3.1422,
      "step": 71140
    },
    {
      "epoch": 114.41,
      "learning_rate": 0.08856399857427653,
      "loss": 3.1429,
      "step": 71160
    },
    {
      "epoch": 114.44,
      "learning_rate": 0.08856078314340836,
      "loss": 3.1694,
      "step": 71180
    },
    {
      "epoch": 114.47,
      "learning_rate": 0.0885575677125402,
      "loss": 3.1184,
      "step": 71200
    },
    {
      "epoch": 114.5,
      "learning_rate": 0.08855435228167202,
      "loss": 3.1382,
      "step": 71220
    },
    {
      "epoch": 114.53,
      "learning_rate": 0.08855113685080387,
      "loss": 3.2021,
      "step": 71240
    },
    {
      "epoch": 114.57,
      "learning_rate": 0.0885479214199357,
      "loss": 3.1751,
      "step": 71260
    },
    {
      "epoch": 114.6,
      "learning_rate": 0.08854470598906752,
      "loss": 3.1186,
      "step": 71280
    },
    {
      "epoch": 114.63,
      "learning_rate": 0.08854149055819936,
      "loss": 3.1603,
      "step": 71300
    },
    {
      "epoch": 114.66,
      "learning_rate": 0.08853827512733119,
      "loss": 3.1877,
      "step": 71320
    },
    {
      "epoch": 114.69,
      "learning_rate": 0.08853505969646304,
      "loss": 3.2099,
      "step": 71340
    },
    {
      "epoch": 114.73,
      "learning_rate": 0.08853184426559486,
      "loss": 3.1983,
      "step": 71360
    },
    {
      "epoch": 114.76,
      "learning_rate": 0.08852862883472669,
      "loss": 3.1785,
      "step": 71380
    },
    {
      "epoch": 114.79,
      "learning_rate": 0.08852541340385853,
      "loss": 3.1402,
      "step": 71400
    },
    {
      "epoch": 114.82,
      "learning_rate": 0.08852219797299035,
      "loss": 3.1926,
      "step": 71420
    },
    {
      "epoch": 114.86,
      "learning_rate": 0.08851898254212219,
      "loss": 3.1904,
      "step": 71440
    },
    {
      "epoch": 114.89,
      "learning_rate": 0.08851576711125402,
      "loss": 3.2016,
      "step": 71460
    },
    {
      "epoch": 114.92,
      "learning_rate": 0.08851255168038585,
      "loss": 3.1297,
      "step": 71480
    },
    {
      "epoch": 114.95,
      "learning_rate": 0.08850933624951769,
      "loss": 3.1824,
      "step": 71500
    },
    {
      "epoch": 114.98,
      "learning_rate": 0.08850612081864952,
      "loss": 3.1315,
      "step": 71520
    },
    {
      "epoch": 115.0,
      "eval_accuracy": {
        "accuracy": 0.35450516986706054
      },
      "eval_loss": 3.2533063888549805,
      "eval_runtime": 2.8455,
      "eval_samples_per_second": 4520.426,
      "eval_steps_per_second": 70.637,
      "step": 71530
    },
    {
      "epoch": 115.02,
      "learning_rate": 0.08850290538778136,
      "loss": 3.1704,
      "step": 71540
    },
    {
      "epoch": 115.05,
      "learning_rate": 0.08849985072845659,
      "loss": 3.2291,
      "step": 71560
    },
    {
      "epoch": 115.08,
      "learning_rate": 0.08849663529758843,
      "loss": 3.2562,
      "step": 71580
    },
    {
      "epoch": 115.11,
      "learning_rate": 0.08849341986672027,
      "loss": 3.2314,
      "step": 71600
    },
    {
      "epoch": 115.14,
      "learning_rate": 0.0884902044358521,
      "loss": 3.1819,
      "step": 71620
    },
    {
      "epoch": 115.18,
      "learning_rate": 0.08848698900498393,
      "loss": 3.1437,
      "step": 71640
    },
    {
      "epoch": 115.21,
      "learning_rate": 0.08848377357411576,
      "loss": 3.133,
      "step": 71660
    },
    {
      "epoch": 115.24,
      "learning_rate": 0.0884805581432476,
      "loss": 3.1138,
      "step": 71680
    },
    {
      "epoch": 115.27,
      "learning_rate": 0.08847734271237942,
      "loss": 3.1329,
      "step": 71700
    },
    {
      "epoch": 115.31,
      "learning_rate": 0.08847412728151126,
      "loss": 3.1402,
      "step": 71720
    },
    {
      "epoch": 115.34,
      "learning_rate": 0.0884709118506431,
      "loss": 3.1896,
      "step": 71740
    },
    {
      "epoch": 115.37,
      "learning_rate": 0.08846769641977492,
      "loss": 3.1666,
      "step": 71760
    },
    {
      "epoch": 115.4,
      "learning_rate": 0.08846448098890676,
      "loss": 3.1811,
      "step": 71780
    },
    {
      "epoch": 115.43,
      "learning_rate": 0.08846126555803858,
      "loss": 3.1494,
      "step": 71800
    },
    {
      "epoch": 115.47,
      "learning_rate": 0.08845805012717042,
      "loss": 3.1523,
      "step": 71820
    },
    {
      "epoch": 115.5,
      "learning_rate": 0.08845483469630226,
      "loss": 3.1159,
      "step": 71840
    },
    {
      "epoch": 115.53,
      "learning_rate": 0.08845161926543409,
      "loss": 3.1846,
      "step": 71860
    },
    {
      "epoch": 115.56,
      "learning_rate": 0.08844840383456593,
      "loss": 3.1468,
      "step": 71880
    },
    {
      "epoch": 115.59,
      "learning_rate": 0.08844518840369775,
      "loss": 3.1386,
      "step": 71900
    },
    {
      "epoch": 115.63,
      "learning_rate": 0.08844197297282959,
      "loss": 3.1449,
      "step": 71920
    },
    {
      "epoch": 115.66,
      "learning_rate": 0.08843875754196143,
      "loss": 3.1813,
      "step": 71940
    },
    {
      "epoch": 115.69,
      "learning_rate": 0.08843554211109325,
      "loss": 3.1954,
      "step": 71960
    },
    {
      "epoch": 115.72,
      "learning_rate": 0.08843232668022509,
      "loss": 3.2322,
      "step": 71980
    },
    {
      "epoch": 115.76,
      "learning_rate": 0.08842911124935691,
      "loss": 3.1859,
      "step": 72000
    },
    {
      "epoch": 115.79,
      "learning_rate": 0.08842589581848875,
      "loss": 3.1251,
      "step": 72020
    },
    {
      "epoch": 115.82,
      "learning_rate": 0.08842268038762058,
      "loss": 3.1385,
      "step": 72040
    },
    {
      "epoch": 115.85,
      "learning_rate": 0.08841946495675242,
      "loss": 3.1388,
      "step": 72060
    },
    {
      "epoch": 115.88,
      "learning_rate": 0.08841624952588426,
      "loss": 3.1411,
      "step": 72080
    },
    {
      "epoch": 115.92,
      "learning_rate": 0.08841303409501608,
      "loss": 3.1724,
      "step": 72100
    },
    {
      "epoch": 115.95,
      "learning_rate": 0.08840981866414792,
      "loss": 3.1842,
      "step": 72120
    },
    {
      "epoch": 115.98,
      "learning_rate": 0.08840660323327974,
      "loss": 3.1877,
      "step": 72140
    },
    {
      "epoch": 116.0,
      "eval_accuracy": {
        "accuracy": 0.35893648449039883
      },
      "eval_loss": 3.199899911880493,
      "eval_runtime": 2.9402,
      "eval_samples_per_second": 4374.799,
      "eval_steps_per_second": 68.362,
      "step": 72152
    },
    {
      "epoch": 116.01,
      "learning_rate": 0.08840338780241158,
      "loss": 3.1502,
      "step": 72160
    },
    {
      "epoch": 116.05,
      "learning_rate": 0.08840017237154342,
      "loss": 3.1534,
      "step": 72180
    },
    {
      "epoch": 116.08,
      "learning_rate": 0.08839695694067524,
      "loss": 3.1223,
      "step": 72200
    },
    {
      "epoch": 116.11,
      "learning_rate": 0.08839374150980708,
      "loss": 3.1386,
      "step": 72220
    },
    {
      "epoch": 116.14,
      "learning_rate": 0.08839052607893891,
      "loss": 3.1168,
      "step": 72240
    },
    {
      "epoch": 116.17,
      "learning_rate": 0.08838731064807075,
      "loss": 3.1425,
      "step": 72260
    },
    {
      "epoch": 116.21,
      "learning_rate": 0.08838409521720259,
      "loss": 3.1244,
      "step": 72280
    },
    {
      "epoch": 116.24,
      "learning_rate": 0.08838087978633441,
      "loss": 3.1476,
      "step": 72300
    },
    {
      "epoch": 116.27,
      "learning_rate": 0.08837766435546625,
      "loss": 3.1439,
      "step": 72320
    },
    {
      "epoch": 116.3,
      "learning_rate": 0.08837444892459807,
      "loss": 3.1336,
      "step": 72340
    },
    {
      "epoch": 116.33,
      "learning_rate": 0.08837123349372991,
      "loss": 3.1348,
      "step": 72360
    },
    {
      "epoch": 116.37,
      "learning_rate": 0.08836801806286175,
      "loss": 3.1468,
      "step": 72380
    },
    {
      "epoch": 116.4,
      "learning_rate": 0.08836480263199357,
      "loss": 3.1331,
      "step": 72400
    },
    {
      "epoch": 116.43,
      "learning_rate": 0.08836158720112541,
      "loss": 3.177,
      "step": 72420
    },
    {
      "epoch": 116.46,
      "learning_rate": 0.08835837177025724,
      "loss": 3.1304,
      "step": 72440
    },
    {
      "epoch": 116.5,
      "learning_rate": 0.08835515633938908,
      "loss": 3.1611,
      "step": 72460
    },
    {
      "epoch": 116.53,
      "learning_rate": 0.0883519409085209,
      "loss": 3.1478,
      "step": 72480
    },
    {
      "epoch": 116.56,
      "learning_rate": 0.08834872547765273,
      "loss": 3.1063,
      "step": 72500
    },
    {
      "epoch": 116.59,
      "learning_rate": 0.08834551004678458,
      "loss": 3.1253,
      "step": 72520
    },
    {
      "epoch": 116.62,
      "learning_rate": 0.0883422946159164,
      "loss": 3.1457,
      "step": 72540
    },
    {
      "epoch": 116.66,
      "learning_rate": 0.08833907918504824,
      "loss": 3.1506,
      "step": 72560
    },
    {
      "epoch": 116.69,
      "learning_rate": 0.08833586375418007,
      "loss": 3.1515,
      "step": 72580
    },
    {
      "epoch": 116.72,
      "learning_rate": 0.0883326483233119,
      "loss": 3.1769,
      "step": 72600
    },
    {
      "epoch": 116.75,
      "learning_rate": 0.08832943289244374,
      "loss": 3.1728,
      "step": 72620
    },
    {
      "epoch": 116.78,
      "learning_rate": 0.08832621746157557,
      "loss": 3.1822,
      "step": 72640
    },
    {
      "epoch": 116.82,
      "learning_rate": 0.0883230020307074,
      "loss": 3.1333,
      "step": 72660
    },
    {
      "epoch": 116.85,
      "learning_rate": 0.08831978659983923,
      "loss": 3.1285,
      "step": 72680
    },
    {
      "epoch": 116.88,
      "learning_rate": 0.08831657116897107,
      "loss": 3.1099,
      "step": 72700
    },
    {
      "epoch": 116.91,
      "learning_rate": 0.08831335573810291,
      "loss": 3.1899,
      "step": 72720
    },
    {
      "epoch": 116.95,
      "learning_rate": 0.08831014030723473,
      "loss": 3.1927,
      "step": 72740
    },
    {
      "epoch": 116.98,
      "learning_rate": 0.08830692487636657,
      "loss": 3.2132,
      "step": 72760
    },
    {
      "epoch": 117.0,
      "eval_accuracy": {
        "accuracy": 0.35839228795770817
      },
      "eval_loss": 3.2398407459259033,
      "eval_runtime": 3.0492,
      "eval_samples_per_second": 4218.43,
      "eval_steps_per_second": 65.918,
      "step": 72774
    },
    {
      "epoch": 117.01,
      "learning_rate": 0.0883037094454984,
      "loss": 3.1935,
      "step": 72780
    },
    {
      "epoch": 117.04,
      "learning_rate": 0.08830049401463023,
      "loss": 3.1598,
      "step": 72800
    },
    {
      "epoch": 117.07,
      "learning_rate": 0.08829727858376206,
      "loss": 3.1924,
      "step": 72820
    },
    {
      "epoch": 117.11,
      "learning_rate": 0.08829406315289388,
      "loss": 3.1262,
      "step": 72840
    },
    {
      "epoch": 117.14,
      "learning_rate": 0.08829084772202574,
      "loss": 3.1562,
      "step": 72860
    },
    {
      "epoch": 117.17,
      "learning_rate": 0.08828763229115756,
      "loss": 3.1361,
      "step": 72880
    },
    {
      "epoch": 117.2,
      "learning_rate": 0.0882844168602894,
      "loss": 3.1484,
      "step": 72900
    },
    {
      "epoch": 117.23,
      "learning_rate": 0.08828120142942122,
      "loss": 3.148,
      "step": 72920
    },
    {
      "epoch": 117.27,
      "learning_rate": 0.08827798599855305,
      "loss": 3.1204,
      "step": 72940
    },
    {
      "epoch": 117.3,
      "learning_rate": 0.0882747705676849,
      "loss": 3.1497,
      "step": 72960
    },
    {
      "epoch": 117.33,
      "learning_rate": 0.08827155513681673,
      "loss": 3.151,
      "step": 72980
    },
    {
      "epoch": 117.36,
      "learning_rate": 0.08826833970594856,
      "loss": 3.1511,
      "step": 73000
    },
    {
      "epoch": 117.4,
      "learning_rate": 0.08826512427508039,
      "loss": 3.1793,
      "step": 73020
    },
    {
      "epoch": 117.43,
      "learning_rate": 0.08826190884421221,
      "loss": 3.2087,
      "step": 73040
    },
    {
      "epoch": 117.46,
      "learning_rate": 0.08825869341334407,
      "loss": 3.2404,
      "step": 73060
    },
    {
      "epoch": 117.49,
      "learning_rate": 0.08825547798247589,
      "loss": 3.171,
      "step": 73080
    },
    {
      "epoch": 117.52,
      "learning_rate": 0.08825226255160773,
      "loss": 3.1573,
      "step": 73100
    },
    {
      "epoch": 117.56,
      "learning_rate": 0.08824904712073955,
      "loss": 3.1406,
      "step": 73120
    },
    {
      "epoch": 117.59,
      "learning_rate": 0.08824583168987138,
      "loss": 3.1373,
      "step": 73140
    },
    {
      "epoch": 117.62,
      "learning_rate": 0.08824261625900322,
      "loss": 3.1488,
      "step": 73160
    },
    {
      "epoch": 117.65,
      "learning_rate": 0.08823940082813504,
      "loss": 3.1507,
      "step": 73180
    },
    {
      "epoch": 117.68,
      "learning_rate": 0.0882361853972669,
      "loss": 3.1495,
      "step": 73200
    },
    {
      "epoch": 117.72,
      "learning_rate": 0.08823296996639872,
      "loss": 3.1417,
      "step": 73220
    },
    {
      "epoch": 117.75,
      "learning_rate": 0.08822975453553056,
      "loss": 3.1512,
      "step": 73240
    },
    {
      "epoch": 117.78,
      "learning_rate": 0.08822653910466238,
      "loss": 3.2076,
      "step": 73260
    },
    {
      "epoch": 117.81,
      "learning_rate": 0.08822332367379421,
      "loss": 3.1942,
      "step": 73280
    },
    {
      "epoch": 117.85,
      "learning_rate": 0.08822010824292606,
      "loss": 3.1523,
      "step": 73300
    },
    {
      "epoch": 117.88,
      "learning_rate": 0.08821689281205788,
      "loss": 3.1374,
      "step": 73320
    },
    {
      "epoch": 117.91,
      "learning_rate": 0.08821367738118972,
      "loss": 3.1366,
      "step": 73340
    },
    {
      "epoch": 117.94,
      "learning_rate": 0.08821046195032155,
      "loss": 3.13,
      "step": 73360
    },
    {
      "epoch": 117.97,
      "learning_rate": 0.08820724651945337,
      "loss": 3.178,
      "step": 73380
    },
    {
      "epoch": 118.0,
      "eval_accuracy": {
        "accuracy": 0.35232838373629793
      },
      "eval_loss": 3.2942891120910645,
      "eval_runtime": 3.0292,
      "eval_samples_per_second": 4246.354,
      "eval_steps_per_second": 66.354,
      "step": 73396
    },
    {
      "epoch": 118.01,
      "learning_rate": 0.08820403108858522,
      "loss": 3.1413,
      "step": 73400
    },
    {
      "epoch": 118.04,
      "learning_rate": 0.08820081565771705,
      "loss": 3.173,
      "step": 73420
    },
    {
      "epoch": 118.07,
      "learning_rate": 0.08819760022684889,
      "loss": 3.2047,
      "step": 73440
    },
    {
      "epoch": 118.1,
      "learning_rate": 0.08819438479598071,
      "loss": 3.1525,
      "step": 73460
    },
    {
      "epoch": 118.14,
      "learning_rate": 0.08819116936511254,
      "loss": 3.1406,
      "step": 73480
    },
    {
      "epoch": 118.17,
      "learning_rate": 0.08818795393424438,
      "loss": 3.1277,
      "step": 73500
    },
    {
      "epoch": 118.2,
      "learning_rate": 0.0881847385033762,
      "loss": 3.1333,
      "step": 73520
    },
    {
      "epoch": 118.23,
      "learning_rate": 0.08818152307250805,
      "loss": 3.1812,
      "step": 73540
    },
    {
      "epoch": 118.26,
      "learning_rate": 0.08817830764163988,
      "loss": 3.1669,
      "step": 73560
    },
    {
      "epoch": 118.3,
      "learning_rate": 0.0881750922107717,
      "loss": 3.1374,
      "step": 73580
    },
    {
      "epoch": 118.33,
      "learning_rate": 0.08817187677990354,
      "loss": 3.1379,
      "step": 73600
    },
    {
      "epoch": 118.36,
      "learning_rate": 0.08816866134903537,
      "loss": 3.1786,
      "step": 73620
    },
    {
      "epoch": 118.39,
      "learning_rate": 0.08816544591816722,
      "loss": 3.1827,
      "step": 73640
    },
    {
      "epoch": 118.42,
      "learning_rate": 0.08816223048729904,
      "loss": 3.1734,
      "step": 73660
    },
    {
      "epoch": 118.46,
      "learning_rate": 0.08815901505643087,
      "loss": 3.1459,
      "step": 73680
    },
    {
      "epoch": 118.49,
      "learning_rate": 0.0881557996255627,
      "loss": 3.1342,
      "step": 73700
    },
    {
      "epoch": 118.52,
      "learning_rate": 0.08815258419469453,
      "loss": 3.1985,
      "step": 73720
    },
    {
      "epoch": 118.55,
      "learning_rate": 0.08814936876382638,
      "loss": 3.1385,
      "step": 73740
    },
    {
      "epoch": 118.59,
      "learning_rate": 0.08814615333295821,
      "loss": 3.1678,
      "step": 73760
    },
    {
      "epoch": 118.62,
      "learning_rate": 0.08814293790209005,
      "loss": 3.1675,
      "step": 73780
    },
    {
      "epoch": 118.65,
      "learning_rate": 0.08813972247122187,
      "loss": 3.1358,
      "step": 73800
    },
    {
      "epoch": 118.68,
      "learning_rate": 0.0881365070403537,
      "loss": 3.1722,
      "step": 73820
    },
    {
      "epoch": 118.71,
      "learning_rate": 0.08813329160948553,
      "loss": 3.1749,
      "step": 73840
    },
    {
      "epoch": 118.75,
      "learning_rate": 0.08813007617861736,
      "loss": 3.1719,
      "step": 73860
    },
    {
      "epoch": 118.78,
      "learning_rate": 0.08812686074774921,
      "loss": 3.1649,
      "step": 73880
    },
    {
      "epoch": 118.81,
      "learning_rate": 0.08812364531688104,
      "loss": 3.1202,
      "step": 73900
    },
    {
      "epoch": 118.84,
      "learning_rate": 0.08812042988601286,
      "loss": 3.1364,
      "step": 73920
    },
    {
      "epoch": 118.87,
      "learning_rate": 0.0881172144551447,
      "loss": 3.1804,
      "step": 73940
    },
    {
      "epoch": 118.91,
      "learning_rate": 0.08811399902427652,
      "loss": 3.1598,
      "step": 73960
    },
    {
      "epoch": 118.94,
      "learning_rate": 0.08811078359340838,
      "loss": 3.1565,
      "step": 73980
    },
    {
      "epoch": 118.97,
      "learning_rate": 0.0881075681625402,
      "loss": 3.1786,
      "step": 74000
    },
    {
      "epoch": 119.0,
      "eval_accuracy": {
        "accuracy": 0.3677213713752624
      },
      "eval_loss": 3.195711612701416,
      "eval_runtime": 2.8113,
      "eval_samples_per_second": 4575.509,
      "eval_steps_per_second": 71.498,
      "step": 74018
    },
    {
      "epoch": 119.0,
      "learning_rate": 0.08810435273167203,
      "loss": 3.1677,
      "step": 74020
    },
    {
      "epoch": 119.04,
      "learning_rate": 0.08810113730080386,
      "loss": 3.1763,
      "step": 74040
    },
    {
      "epoch": 119.07,
      "learning_rate": 0.08809792186993569,
      "loss": 3.1252,
      "step": 74060
    },
    {
      "epoch": 119.1,
      "learning_rate": 0.08809470643906754,
      "loss": 3.1653,
      "step": 74080
    },
    {
      "epoch": 119.13,
      "learning_rate": 0.08809149100819937,
      "loss": 3.1248,
      "step": 74100
    },
    {
      "epoch": 119.16,
      "learning_rate": 0.08808827557733119,
      "loss": 3.1506,
      "step": 74120
    },
    {
      "epoch": 119.2,
      "learning_rate": 0.08808506014646303,
      "loss": 3.1427,
      "step": 74140
    },
    {
      "epoch": 119.23,
      "learning_rate": 0.08808184471559485,
      "loss": 3.1622,
      "step": 74160
    },
    {
      "epoch": 119.26,
      "learning_rate": 0.08807862928472669,
      "loss": 3.151,
      "step": 74180
    },
    {
      "epoch": 119.29,
      "learning_rate": 0.08807541385385852,
      "loss": 3.0744,
      "step": 74200
    },
    {
      "epoch": 119.32,
      "learning_rate": 0.08807219842299036,
      "loss": 3.1078,
      "step": 74220
    },
    {
      "epoch": 119.36,
      "learning_rate": 0.0880689829921222,
      "loss": 3.0975,
      "step": 74240
    },
    {
      "epoch": 119.39,
      "learning_rate": 0.08806576756125402,
      "loss": 3.109,
      "step": 74260
    },
    {
      "epoch": 119.42,
      "learning_rate": 0.08806255213038586,
      "loss": 3.181,
      "step": 74280
    },
    {
      "epoch": 119.45,
      "learning_rate": 0.08805933669951768,
      "loss": 3.1165,
      "step": 74300
    },
    {
      "epoch": 119.49,
      "learning_rate": 0.08805612126864952,
      "loss": 3.141,
      "step": 74320
    },
    {
      "epoch": 119.52,
      "learning_rate": 0.08805290583778136,
      "loss": 3.1579,
      "step": 74340
    },
    {
      "epoch": 119.55,
      "learning_rate": 0.08804969040691318,
      "loss": 3.2116,
      "step": 74360
    },
    {
      "epoch": 119.58,
      "learning_rate": 0.08804647497604502,
      "loss": 3.203,
      "step": 74380
    },
    {
      "epoch": 119.61,
      "learning_rate": 0.08804325954517685,
      "loss": 3.1817,
      "step": 74400
    },
    {
      "epoch": 119.65,
      "learning_rate": 0.0880400441143087,
      "loss": 3.1624,
      "step": 74420
    },
    {
      "epoch": 119.68,
      "learning_rate": 0.08803682868344052,
      "loss": 3.1253,
      "step": 74440
    },
    {
      "epoch": 119.71,
      "learning_rate": 0.08803361325257235,
      "loss": 3.2003,
      "step": 74460
    },
    {
      "epoch": 119.74,
      "learning_rate": 0.08803039782170419,
      "loss": 3.1407,
      "step": 74480
    },
    {
      "epoch": 119.77,
      "learning_rate": 0.08802718239083601,
      "loss": 3.173,
      "step": 74500
    },
    {
      "epoch": 119.81,
      "learning_rate": 0.08802396695996785,
      "loss": 3.1893,
      "step": 74520
    },
    {
      "epoch": 119.84,
      "learning_rate": 0.08802075152909969,
      "loss": 3.1869,
      "step": 74540
    },
    {
      "epoch": 119.87,
      "learning_rate": 0.08801753609823151,
      "loss": 3.1588,
      "step": 74560
    },
    {
      "epoch": 119.9,
      "learning_rate": 0.08801432066736335,
      "loss": 3.1545,
      "step": 74580
    },
    {
      "epoch": 119.94,
      "learning_rate": 0.08801110523649518,
      "loss": 3.1528,
      "step": 74600
    },
    {
      "epoch": 119.97,
      "learning_rate": 0.08800788980562702,
      "loss": 3.1666,
      "step": 74620
    },
    {
      "epoch": 120.0,
      "learning_rate": 0.08800467437475884,
      "loss": 3.1248,
      "step": 74640
    },
    {
      "epoch": 120.0,
      "eval_accuracy": {
        "accuracy": 0.36266811785742054
      },
      "eval_loss": 3.2178001403808594,
      "eval_runtime": 3.3617,
      "eval_samples_per_second": 3826.36,
      "eval_steps_per_second": 59.792,
      "step": 74640
    },
    {
      "epoch": 120.03,
      "learning_rate": 0.08800145894389068,
      "loss": 3.156,
      "step": 74660
    },
    {
      "epoch": 120.06,
      "learning_rate": 0.08799824351302252,
      "loss": 3.1164,
      "step": 74680
    },
    {
      "epoch": 120.1,
      "learning_rate": 0.08799502808215434,
      "loss": 3.1338,
      "step": 74700
    },
    {
      "epoch": 120.13,
      "learning_rate": 0.08799181265128618,
      "loss": 3.1508,
      "step": 74720
    },
    {
      "epoch": 120.16,
      "learning_rate": 0.087988597220418,
      "loss": 3.1423,
      "step": 74740
    },
    {
      "epoch": 120.19,
      "learning_rate": 0.08798538178954984,
      "loss": 3.14,
      "step": 74760
    },
    {
      "epoch": 120.23,
      "learning_rate": 0.08798216635868168,
      "loss": 3.1224,
      "step": 74780
    },
    {
      "epoch": 120.26,
      "learning_rate": 0.0879789509278135,
      "loss": 3.1199,
      "step": 74800
    },
    {
      "epoch": 120.29,
      "learning_rate": 0.08797573549694535,
      "loss": 3.1559,
      "step": 74820
    },
    {
      "epoch": 120.32,
      "learning_rate": 0.08797252006607717,
      "loss": 3.1114,
      "step": 74840
    },
    {
      "epoch": 120.35,
      "learning_rate": 0.08796930463520901,
      "loss": 3.1681,
      "step": 74860
    },
    {
      "epoch": 120.39,
      "learning_rate": 0.08796608920434085,
      "loss": 3.1649,
      "step": 74880
    },
    {
      "epoch": 120.42,
      "learning_rate": 0.08796287377347267,
      "loss": 3.1239,
      "step": 74900
    },
    {
      "epoch": 120.45,
      "learning_rate": 0.08795965834260451,
      "loss": 3.1329,
      "step": 74920
    },
    {
      "epoch": 120.48,
      "learning_rate": 0.08795644291173633,
      "loss": 3.1622,
      "step": 74940
    },
    {
      "epoch": 120.51,
      "learning_rate": 0.08795338825241159,
      "loss": 3.1881,
      "step": 74960
    },
    {
      "epoch": 120.55,
      "learning_rate": 0.08795017282154341,
      "loss": 3.1852,
      "step": 74980
    },
    {
      "epoch": 120.58,
      "learning_rate": 0.08794695739067525,
      "loss": 3.1576,
      "step": 75000
    },
    {
      "epoch": 120.61,
      "learning_rate": 0.08794374195980709,
      "loss": 3.1994,
      "step": 75020
    },
    {
      "epoch": 120.64,
      "learning_rate": 0.08794052652893891,
      "loss": 3.1288,
      "step": 75040
    },
    {
      "epoch": 120.68,
      "learning_rate": 0.08793731109807075,
      "loss": 3.1301,
      "step": 75060
    },
    {
      "epoch": 120.71,
      "learning_rate": 0.08793409566720257,
      "loss": 3.1277,
      "step": 75080
    },
    {
      "epoch": 120.74,
      "learning_rate": 0.08793088023633441,
      "loss": 3.1634,
      "step": 75100
    },
    {
      "epoch": 120.77,
      "learning_rate": 0.08792766480546625,
      "loss": 3.1279,
      "step": 75120
    },
    {
      "epoch": 120.8,
      "learning_rate": 0.08792444937459808,
      "loss": 3.1387,
      "step": 75140
    },
    {
      "epoch": 120.84,
      "learning_rate": 0.08792123394372992,
      "loss": 3.109,
      "step": 75160
    },
    {
      "epoch": 120.87,
      "learning_rate": 0.08791801851286174,
      "loss": 3.1921,
      "step": 75180
    },
    {
      "epoch": 120.9,
      "learning_rate": 0.08791480308199358,
      "loss": 3.2422,
      "step": 75200
    },
    {
      "epoch": 120.93,
      "learning_rate": 0.0879115876511254,
      "loss": 3.2411,
      "step": 75220
    },
    {
      "epoch": 120.96,
      "learning_rate": 0.08790837222025723,
      "loss": 3.1712,
      "step": 75240
    },
    {
      "epoch": 121.0,
      "learning_rate": 0.08790515678938908,
      "loss": 3.1608,
      "step": 75260
    },
    {
      "epoch": 121.0,
      "eval_accuracy": {
        "accuracy": 0.36103552825934854
      },
      "eval_loss": 3.218960762023926,
      "eval_runtime": 3.0145,
      "eval_samples_per_second": 4267.038,
      "eval_steps_per_second": 66.678,
      "step": 75262
    },
    {
      "epoch": 121.03,
      "learning_rate": 0.0879019413585209,
      "loss": 3.1711,
      "step": 75280
    },
    {
      "epoch": 121.06,
      "learning_rate": 0.08789872592765274,
      "loss": 3.1956,
      "step": 75300
    },
    {
      "epoch": 121.09,
      "learning_rate": 0.08789551049678457,
      "loss": 3.156,
      "step": 75320
    },
    {
      "epoch": 121.13,
      "learning_rate": 0.0878922950659164,
      "loss": 3.1438,
      "step": 75340
    },
    {
      "epoch": 121.16,
      "learning_rate": 0.08788907963504825,
      "loss": 3.1433,
      "step": 75360
    },
    {
      "epoch": 121.19,
      "learning_rate": 0.08788586420418007,
      "loss": 3.1438,
      "step": 75380
    },
    {
      "epoch": 121.22,
      "learning_rate": 0.08788264877331191,
      "loss": 3.1685,
      "step": 75400
    },
    {
      "epoch": 121.25,
      "learning_rate": 0.08787943334244373,
      "loss": 3.1293,
      "step": 75420
    },
    {
      "epoch": 121.29,
      "learning_rate": 0.08787621791157557,
      "loss": 3.155,
      "step": 75440
    },
    {
      "epoch": 121.32,
      "learning_rate": 0.08787300248070741,
      "loss": 3.1222,
      "step": 75460
    },
    {
      "epoch": 121.35,
      "learning_rate": 0.08786978704983923,
      "loss": 3.132,
      "step": 75480
    },
    {
      "epoch": 121.38,
      "learning_rate": 0.08786657161897107,
      "loss": 3.1298,
      "step": 75500
    },
    {
      "epoch": 121.41,
      "learning_rate": 0.0878633561881029,
      "loss": 3.1296,
      "step": 75520
    },
    {
      "epoch": 121.45,
      "learning_rate": 0.08786014075723474,
      "loss": 3.1245,
      "step": 75540
    },
    {
      "epoch": 121.48,
      "learning_rate": 0.08785692532636656,
      "loss": 3.1452,
      "step": 75560
    },
    {
      "epoch": 121.51,
      "learning_rate": 0.08785370989549839,
      "loss": 3.1503,
      "step": 75580
    },
    {
      "epoch": 121.54,
      "learning_rate": 0.08785049446463024,
      "loss": 3.1228,
      "step": 75600
    },
    {
      "epoch": 121.58,
      "learning_rate": 0.08784727903376206,
      "loss": 3.1151,
      "step": 75620
    },
    {
      "epoch": 121.61,
      "learning_rate": 0.0878440636028939,
      "loss": 3.1874,
      "step": 75640
    },
    {
      "epoch": 121.64,
      "learning_rate": 0.08784084817202573,
      "loss": 3.1385,
      "step": 75660
    },
    {
      "epoch": 121.67,
      "learning_rate": 0.08783763274115755,
      "loss": 3.1749,
      "step": 75680
    },
    {
      "epoch": 121.7,
      "learning_rate": 0.0878344173102894,
      "loss": 3.2171,
      "step": 75700
    },
    {
      "epoch": 121.74,
      "learning_rate": 0.08783120187942123,
      "loss": 3.1507,
      "step": 75720
    },
    {
      "epoch": 121.77,
      "learning_rate": 0.08782798644855307,
      "loss": 3.2057,
      "step": 75740
    },
    {
      "epoch": 121.8,
      "learning_rate": 0.08782477101768489,
      "loss": 3.0996,
      "step": 75760
    },
    {
      "epoch": 121.83,
      "learning_rate": 0.08782155558681672,
      "loss": 3.0738,
      "step": 75780
    },
    {
      "epoch": 121.86,
      "learning_rate": 0.08781834015594857,
      "loss": 3.1338,
      "step": 75800
    },
    {
      "epoch": 121.9,
      "learning_rate": 0.08781512472508039,
      "loss": 3.1477,
      "step": 75820
    },
    {
      "epoch": 121.93,
      "learning_rate": 0.08781190929421223,
      "loss": 3.1287,
      "step": 75840
    },
    {
      "epoch": 121.96,
      "learning_rate": 0.08780869386334406,
      "loss": 3.1201,
      "step": 75860
    },
    {
      "epoch": 121.99,
      "learning_rate": 0.08780547843247588,
      "loss": 3.1197,
      "step": 75880
    },
    {
      "epoch": 122.0,
      "eval_accuracy": {
        "accuracy": 0.3565264712741973
      },
      "eval_loss": 3.2894744873046875,
      "eval_runtime": 2.7118,
      "eval_samples_per_second": 4743.36,
      "eval_steps_per_second": 74.121,
      "step": 75884
    },
    {
      "epoch": 122.03,
      "learning_rate": 0.08780226300160772,
      "loss": 3.1728,
      "step": 75900
    },
    {
      "epoch": 122.06,
      "learning_rate": 0.08779904757073954,
      "loss": 3.1231,
      "step": 75920
    },
    {
      "epoch": 122.09,
      "learning_rate": 0.0877958321398714,
      "loss": 3.1425,
      "step": 75940
    },
    {
      "epoch": 122.12,
      "learning_rate": 0.08779261670900322,
      "loss": 3.1475,
      "step": 75960
    },
    {
      "epoch": 122.15,
      "learning_rate": 0.08778940127813506,
      "loss": 3.1174,
      "step": 75980
    },
    {
      "epoch": 122.19,
      "learning_rate": 0.08778618584726688,
      "loss": 3.0831,
      "step": 76000
    },
    {
      "epoch": 122.22,
      "learning_rate": 0.08778297041639871,
      "loss": 3.1134,
      "step": 76020
    },
    {
      "epoch": 122.25,
      "learning_rate": 0.08777975498553056,
      "loss": 3.1593,
      "step": 76040
    },
    {
      "epoch": 122.28,
      "learning_rate": 0.08777653955466239,
      "loss": 3.1877,
      "step": 76060
    },
    {
      "epoch": 122.32,
      "learning_rate": 0.08777332412379422,
      "loss": 3.1506,
      "step": 76080
    },
    {
      "epoch": 122.35,
      "learning_rate": 0.08777010869292605,
      "loss": 3.1149,
      "step": 76100
    },
    {
      "epoch": 122.38,
      "learning_rate": 0.08776689326205787,
      "loss": 3.0931,
      "step": 76120
    },
    {
      "epoch": 122.41,
      "learning_rate": 0.08776367783118973,
      "loss": 3.0754,
      "step": 76140
    },
    {
      "epoch": 122.44,
      "learning_rate": 0.08776046240032155,
      "loss": 3.0941,
      "step": 76160
    },
    {
      "epoch": 122.48,
      "learning_rate": 0.08775724696945339,
      "loss": 3.0933,
      "step": 76180
    },
    {
      "epoch": 122.51,
      "learning_rate": 0.08775403153858521,
      "loss": 3.1856,
      "step": 76200
    },
    {
      "epoch": 122.54,
      "learning_rate": 0.08775081610771704,
      "loss": 3.1765,
      "step": 76220
    },
    {
      "epoch": 122.57,
      "learning_rate": 0.08774760067684888,
      "loss": 3.1561,
      "step": 76240
    },
    {
      "epoch": 122.6,
      "learning_rate": 0.0877443852459807,
      "loss": 3.1228,
      "step": 76260
    },
    {
      "epoch": 122.64,
      "learning_rate": 0.08774116981511255,
      "loss": 3.0973,
      "step": 76280
    },
    {
      "epoch": 122.67,
      "learning_rate": 0.08773795438424438,
      "loss": 3.1363,
      "step": 76300
    },
    {
      "epoch": 122.7,
      "learning_rate": 0.0877347389533762,
      "loss": 3.1131,
      "step": 76320
    },
    {
      "epoch": 122.73,
      "learning_rate": 0.08773152352250804,
      "loss": 3.1607,
      "step": 76340
    },
    {
      "epoch": 122.77,
      "learning_rate": 0.08772830809163987,
      "loss": 3.1189,
      "step": 76360
    },
    {
      "epoch": 122.8,
      "learning_rate": 0.08772509266077172,
      "loss": 3.1688,
      "step": 76380
    },
    {
      "epoch": 122.83,
      "learning_rate": 0.08772187722990354,
      "loss": 3.1782,
      "step": 76400
    },
    {
      "epoch": 122.86,
      "learning_rate": 0.08771866179903537,
      "loss": 3.1608,
      "step": 76420
    },
    {
      "epoch": 122.89,
      "learning_rate": 0.08771544636816721,
      "loss": 3.1596,
      "step": 76440
    },
    {
      "epoch": 122.93,
      "learning_rate": 0.08771223093729903,
      "loss": 3.1423,
      "step": 76460
    },
    {
      "epoch": 122.96,
      "learning_rate": 0.08770901550643088,
      "loss": 3.1609,
      "step": 76480
    },
    {
      "epoch": 122.99,
      "learning_rate": 0.08770580007556271,
      "loss": 3.1365,
      "step": 76500
    },
    {
      "epoch": 123.0,
      "eval_accuracy": {
        "accuracy": 0.35069579413822594
      },
      "eval_loss": 3.3266637325286865,
      "eval_runtime": 3.0826,
      "eval_samples_per_second": 4172.722,
      "eval_steps_per_second": 65.204,
      "step": 76506
    },
    {
      "epoch": 123.02,
      "learning_rate": 0.08770258464469453,
      "loss": 3.2208,
      "step": 76520
    },
    {
      "epoch": 123.05,
      "learning_rate": 0.08769936921382637,
      "loss": 3.1563,
      "step": 76540
    },
    {
      "epoch": 123.09,
      "learning_rate": 0.0876961537829582,
      "loss": 3.1504,
      "step": 76560
    },
    {
      "epoch": 123.12,
      "learning_rate": 0.08769293835209004,
      "loss": 3.139,
      "step": 76580
    },
    {
      "epoch": 123.15,
      "learning_rate": 0.08768972292122186,
      "loss": 3.1473,
      "step": 76600
    },
    {
      "epoch": 123.18,
      "learning_rate": 0.08768650749035371,
      "loss": 3.1224,
      "step": 76620
    },
    {
      "epoch": 123.22,
      "learning_rate": 0.08768329205948554,
      "loss": 3.1633,
      "step": 76640
    },
    {
      "epoch": 123.25,
      "learning_rate": 0.08768007662861736,
      "loss": 3.1463,
      "step": 76660
    },
    {
      "epoch": 123.28,
      "learning_rate": 0.0876768611977492,
      "loss": 3.1169,
      "step": 76680
    },
    {
      "epoch": 123.31,
      "learning_rate": 0.08767364576688103,
      "loss": 3.0859,
      "step": 76700
    },
    {
      "epoch": 123.34,
      "learning_rate": 0.08767043033601288,
      "loss": 3.136,
      "step": 76720
    },
    {
      "epoch": 123.38,
      "learning_rate": 0.0876672149051447,
      "loss": 3.1619,
      "step": 76740
    },
    {
      "epoch": 123.41,
      "learning_rate": 0.08766399947427653,
      "loss": 3.1616,
      "step": 76760
    },
    {
      "epoch": 123.44,
      "learning_rate": 0.08766078404340837,
      "loss": 3.1354,
      "step": 76780
    },
    {
      "epoch": 123.47,
      "learning_rate": 0.08765756861254019,
      "loss": 3.1114,
      "step": 76800
    },
    {
      "epoch": 123.5,
      "learning_rate": 0.08765435318167204,
      "loss": 3.1256,
      "step": 76820
    },
    {
      "epoch": 123.54,
      "learning_rate": 0.08765113775080387,
      "loss": 3.1062,
      "step": 76840
    },
    {
      "epoch": 123.57,
      "learning_rate": 0.08764792231993569,
      "loss": 3.1383,
      "step": 76860
    },
    {
      "epoch": 123.6,
      "learning_rate": 0.08764470688906753,
      "loss": 3.1355,
      "step": 76880
    },
    {
      "epoch": 123.63,
      "learning_rate": 0.08764149145819936,
      "loss": 3.1326,
      "step": 76900
    },
    {
      "epoch": 123.67,
      "learning_rate": 0.0876382760273312,
      "loss": 3.1449,
      "step": 76920
    },
    {
      "epoch": 123.7,
      "learning_rate": 0.08763506059646302,
      "loss": 3.1505,
      "step": 76940
    },
    {
      "epoch": 123.73,
      "learning_rate": 0.08763184516559486,
      "loss": 3.1441,
      "step": 76960
    },
    {
      "epoch": 123.76,
      "learning_rate": 0.0876286297347267,
      "loss": 3.1967,
      "step": 76980
    },
    {
      "epoch": 123.79,
      "learning_rate": 0.08762541430385852,
      "loss": 3.1801,
      "step": 77000
    },
    {
      "epoch": 123.83,
      "learning_rate": 0.08762219887299036,
      "loss": 3.1988,
      "step": 77020
    },
    {
      "epoch": 123.86,
      "learning_rate": 0.08761898344212218,
      "loss": 3.1745,
      "step": 77040
    },
    {
      "epoch": 123.89,
      "learning_rate": 0.08761576801125402,
      "loss": 3.1636,
      "step": 77060
    },
    {
      "epoch": 123.92,
      "learning_rate": 0.08761255258038586,
      "loss": 3.1473,
      "step": 77080
    },
    {
      "epoch": 123.95,
      "learning_rate": 0.08760933714951769,
      "loss": 3.1329,
      "step": 77100
    },
    {
      "epoch": 123.99,
      "learning_rate": 0.08760612171864952,
      "loss": 3.1083,
      "step": 77120
    },
    {
      "epoch": 124.0,
      "eval_accuracy": {
        "accuracy": 0.3524838684599238
      },
      "eval_loss": 3.2491908073425293,
      "eval_runtime": 3.6464,
      "eval_samples_per_second": 3527.618,
      "eval_steps_per_second": 55.123,
      "step": 77128
    },
    {
      "epoch": 124.02,
      "learning_rate": 0.08760290628778135,
      "loss": 3.1575,
      "step": 77140
    },
    {
      "epoch": 124.05,
      "learning_rate": 0.08759969085691319,
      "loss": 3.1495,
      "step": 77160
    },
    {
      "epoch": 124.08,
      "learning_rate": 0.08759647542604503,
      "loss": 3.0986,
      "step": 77180
    },
    {
      "epoch": 124.12,
      "learning_rate": 0.08759325999517685,
      "loss": 3.1177,
      "step": 77200
    },
    {
      "epoch": 124.15,
      "learning_rate": 0.08759004456430869,
      "loss": 3.1503,
      "step": 77220
    },
    {
      "epoch": 124.18,
      "learning_rate": 0.08758682913344051,
      "loss": 3.1088,
      "step": 77240
    },
    {
      "epoch": 124.21,
      "learning_rate": 0.08758361370257235,
      "loss": 3.1533,
      "step": 77260
    },
    {
      "epoch": 124.24,
      "learning_rate": 0.08758039827170419,
      "loss": 3.1066,
      "step": 77280
    },
    {
      "epoch": 124.28,
      "learning_rate": 0.08757718284083602,
      "loss": 3.1239,
      "step": 77300
    },
    {
      "epoch": 124.31,
      "learning_rate": 0.08757396740996785,
      "loss": 3.1271,
      "step": 77320
    },
    {
      "epoch": 124.34,
      "learning_rate": 0.08757075197909968,
      "loss": 3.127,
      "step": 77340
    },
    {
      "epoch": 124.37,
      "learning_rate": 0.08756753654823152,
      "loss": 3.1339,
      "step": 77360
    },
    {
      "epoch": 124.41,
      "learning_rate": 0.08756432111736334,
      "loss": 3.1042,
      "step": 77380
    },
    {
      "epoch": 124.44,
      "learning_rate": 0.08756110568649518,
      "loss": 3.1432,
      "step": 77400
    },
    {
      "epoch": 124.47,
      "learning_rate": 0.08755789025562702,
      "loss": 3.1174,
      "step": 77420
    },
    {
      "epoch": 124.5,
      "learning_rate": 0.08755467482475884,
      "loss": 3.1637,
      "step": 77440
    },
    {
      "epoch": 124.53,
      "learning_rate": 0.08755145939389068,
      "loss": 3.1568,
      "step": 77460
    },
    {
      "epoch": 124.57,
      "learning_rate": 0.0875482439630225,
      "loss": 3.1729,
      "step": 77480
    },
    {
      "epoch": 124.6,
      "learning_rate": 0.08754502853215435,
      "loss": 3.1696,
      "step": 77500
    },
    {
      "epoch": 124.63,
      "learning_rate": 0.08754181310128618,
      "loss": 3.1483,
      "step": 77520
    },
    {
      "epoch": 124.66,
      "learning_rate": 0.08753859767041801,
      "loss": 3.1671,
      "step": 77540
    },
    {
      "epoch": 124.69,
      "learning_rate": 0.08753538223954985,
      "loss": 3.1362,
      "step": 77560
    },
    {
      "epoch": 124.73,
      "learning_rate": 0.08753216680868167,
      "loss": 3.1267,
      "step": 77580
    },
    {
      "epoch": 124.76,
      "learning_rate": 0.08752895137781351,
      "loss": 3.1349,
      "step": 77600
    },
    {
      "epoch": 124.79,
      "learning_rate": 0.08752573594694535,
      "loss": 3.1053,
      "step": 77620
    },
    {
      "epoch": 124.82,
      "learning_rate": 0.08752252051607717,
      "loss": 3.1533,
      "step": 77640
    },
    {
      "epoch": 124.86,
      "learning_rate": 0.08751930508520901,
      "loss": 3.1257,
      "step": 77660
    },
    {
      "epoch": 124.89,
      "learning_rate": 0.08751608965434084,
      "loss": 3.0831,
      "step": 77680
    },
    {
      "epoch": 124.92,
      "learning_rate": 0.08751287422347268,
      "loss": 3.1484,
      "step": 77700
    },
    {
      "epoch": 124.95,
      "learning_rate": 0.0875096587926045,
      "loss": 3.1371,
      "step": 77720
    },
    {
      "epoch": 124.98,
      "learning_rate": 0.08750644336173634,
      "loss": 3.1252,
      "step": 77740
    },
    {
      "epoch": 125.0,
      "eval_accuracy": {
        "accuracy": 0.3571484101687009
      },
      "eval_loss": 3.2228612899780273,
      "eval_runtime": 3.1276,
      "eval_samples_per_second": 4112.682,
      "eval_steps_per_second": 64.266,
      "step": 77750
    },
    {
      "epoch": 125.02,
      "learning_rate": 0.08750322793086818,
      "loss": 3.1712,
      "step": 77760
    },
    {
      "epoch": 125.05,
      "learning_rate": 0.0875000125,
      "loss": 3.1686,
      "step": 77780
    },
    {
      "epoch": 125.08,
      "learning_rate": 0.08749679706913184,
      "loss": 3.1531,
      "step": 77800
    },
    {
      "epoch": 125.11,
      "learning_rate": 0.08749374240980708,
      "loss": 3.2221,
      "step": 77820
    },
    {
      "epoch": 125.14,
      "learning_rate": 0.08749052697893892,
      "loss": 3.2449,
      "step": 77840
    },
    {
      "epoch": 125.18,
      "learning_rate": 0.08748731154807075,
      "loss": 3.2437,
      "step": 77860
    },
    {
      "epoch": 125.21,
      "learning_rate": 0.08748409611720258,
      "loss": 3.1585,
      "step": 77880
    },
    {
      "epoch": 125.24,
      "learning_rate": 0.08748088068633442,
      "loss": 3.1343,
      "step": 77900
    },
    {
      "epoch": 125.27,
      "learning_rate": 0.08747766525546624,
      "loss": 3.1478,
      "step": 77920
    },
    {
      "epoch": 125.31,
      "learning_rate": 0.08747444982459808,
      "loss": 3.1615,
      "step": 77940
    },
    {
      "epoch": 125.34,
      "learning_rate": 0.0874712343937299,
      "loss": 3.151,
      "step": 77960
    },
    {
      "epoch": 125.37,
      "learning_rate": 0.08746801896286173,
      "loss": 3.113,
      "step": 77980
    },
    {
      "epoch": 125.4,
      "learning_rate": 0.08746480353199358,
      "loss": 3.1749,
      "step": 78000
    },
    {
      "epoch": 125.43,
      "learning_rate": 0.0874615881011254,
      "loss": 3.1364,
      "step": 78020
    },
    {
      "epoch": 125.47,
      "learning_rate": 0.08745837267025725,
      "loss": 3.1406,
      "step": 78040
    },
    {
      "epoch": 125.5,
      "learning_rate": 0.08745515723938907,
      "loss": 3.0927,
      "step": 78060
    },
    {
      "epoch": 125.53,
      "learning_rate": 0.0874519418085209,
      "loss": 3.1324,
      "step": 78080
    },
    {
      "epoch": 125.56,
      "learning_rate": 0.08744872637765275,
      "loss": 3.1375,
      "step": 78100
    },
    {
      "epoch": 125.59,
      "learning_rate": 0.08744551094678457,
      "loss": 3.1245,
      "step": 78120
    },
    {
      "epoch": 125.63,
      "learning_rate": 0.08744229551591641,
      "loss": 3.1284,
      "step": 78140
    },
    {
      "epoch": 125.66,
      "learning_rate": 0.08743908008504823,
      "loss": 3.1288,
      "step": 78160
    },
    {
      "epoch": 125.69,
      "learning_rate": 0.08743586465418007,
      "loss": 3.1011,
      "step": 78180
    },
    {
      "epoch": 125.72,
      "learning_rate": 0.08743264922331191,
      "loss": 3.1357,
      "step": 78200
    },
    {
      "epoch": 125.76,
      "learning_rate": 0.08742943379244374,
      "loss": 3.1558,
      "step": 78220
    },
    {
      "epoch": 125.79,
      "learning_rate": 0.08742621836157558,
      "loss": 3.1472,
      "step": 78240
    },
    {
      "epoch": 125.82,
      "learning_rate": 0.0874230029307074,
      "loss": 3.1011,
      "step": 78260
    },
    {
      "epoch": 125.85,
      "learning_rate": 0.08741978749983924,
      "loss": 3.1166,
      "step": 78280
    },
    {
      "epoch": 125.88,
      "learning_rate": 0.08741657206897106,
      "loss": 3.1434,
      "step": 78300
    },
    {
      "epoch": 125.92,
      "learning_rate": 0.08741335663810289,
      "loss": 3.1954,
      "step": 78320
    },
    {
      "epoch": 125.95,
      "learning_rate": 0.08741014120723474,
      "loss": 3.1698,
      "step": 78340
    },
    {
      "epoch": 125.98,
      "learning_rate": 0.08740692577636656,
      "loss": 3.1463,
      "step": 78360
    },
    {
      "epoch": 126.0,
      "eval_accuracy": {
        "accuracy": 0.36227940604835573
      },
      "eval_loss": 3.1993300914764404,
      "eval_runtime": 3.0647,
      "eval_samples_per_second": 4197.157,
      "eval_steps_per_second": 65.586,
      "step": 78372
    },
    {
      "epoch": 126.01,
      "learning_rate": 0.0874037103454984,
      "loss": 3.1232,
      "step": 78380
    },
    {
      "epoch": 126.05,
      "learning_rate": 0.08740049491463023,
      "loss": 3.1397,
      "step": 78400
    },
    {
      "epoch": 126.08,
      "learning_rate": 0.08739727948376205,
      "loss": 3.1107,
      "step": 78420
    },
    {
      "epoch": 126.11,
      "learning_rate": 0.0873940640528939,
      "loss": 3.0889,
      "step": 78440
    },
    {
      "epoch": 126.14,
      "learning_rate": 0.08739084862202573,
      "loss": 3.1263,
      "step": 78460
    },
    {
      "epoch": 126.17,
      "learning_rate": 0.08738763319115757,
      "loss": 3.1101,
      "step": 78480
    },
    {
      "epoch": 126.21,
      "learning_rate": 0.08738441776028939,
      "loss": 3.0892,
      "step": 78500
    },
    {
      "epoch": 126.24,
      "learning_rate": 0.08738120232942122,
      "loss": 3.1428,
      "step": 78520
    },
    {
      "epoch": 126.27,
      "learning_rate": 0.08737798689855307,
      "loss": 3.122,
      "step": 78540
    },
    {
      "epoch": 126.3,
      "learning_rate": 0.0873747714676849,
      "loss": 3.1434,
      "step": 78560
    },
    {
      "epoch": 126.33,
      "learning_rate": 0.08737155603681673,
      "loss": 3.1375,
      "step": 78580
    },
    {
      "epoch": 126.37,
      "learning_rate": 0.08736834060594856,
      "loss": 3.1647,
      "step": 78600
    },
    {
      "epoch": 126.4,
      "learning_rate": 0.08736512517508038,
      "loss": 3.1457,
      "step": 78620
    },
    {
      "epoch": 126.43,
      "learning_rate": 0.08736190974421222,
      "loss": 3.1257,
      "step": 78640
    },
    {
      "epoch": 126.46,
      "learning_rate": 0.08735869431334405,
      "loss": 3.1011,
      "step": 78660
    },
    {
      "epoch": 126.5,
      "learning_rate": 0.0873554788824759,
      "loss": 3.1623,
      "step": 78680
    },
    {
      "epoch": 126.53,
      "learning_rate": 0.08735226345160772,
      "loss": 3.1476,
      "step": 78700
    },
    {
      "epoch": 126.56,
      "learning_rate": 0.08734904802073955,
      "loss": 3.1355,
      "step": 78720
    },
    {
      "epoch": 126.59,
      "learning_rate": 0.08734583258987139,
      "loss": 3.1775,
      "step": 78740
    },
    {
      "epoch": 126.62,
      "learning_rate": 0.08734261715900321,
      "loss": 3.1605,
      "step": 78760
    },
    {
      "epoch": 126.66,
      "learning_rate": 0.08733940172813506,
      "loss": 3.1093,
      "step": 78780
    },
    {
      "epoch": 126.69,
      "learning_rate": 0.08733618629726689,
      "loss": 3.128,
      "step": 78800
    },
    {
      "epoch": 126.72,
      "learning_rate": 0.08733297086639873,
      "loss": 3.0881,
      "step": 78820
    },
    {
      "epoch": 126.75,
      "learning_rate": 0.08732975543553055,
      "loss": 3.1294,
      "step": 78840
    },
    {
      "epoch": 126.78,
      "learning_rate": 0.08732654000466238,
      "loss": 3.0941,
      "step": 78860
    },
    {
      "epoch": 126.82,
      "learning_rate": 0.08732332457379423,
      "loss": 3.098,
      "step": 78880
    },
    {
      "epoch": 126.85,
      "learning_rate": 0.08732010914292605,
      "loss": 3.1396,
      "step": 78900
    },
    {
      "epoch": 126.88,
      "learning_rate": 0.08731689371205789,
      "loss": 3.1644,
      "step": 78920
    },
    {
      "epoch": 126.91,
      "learning_rate": 0.08731367828118972,
      "loss": 3.1525,
      "step": 78940
    },
    {
      "epoch": 126.95,
      "learning_rate": 0.08731046285032154,
      "loss": 3.1206,
      "step": 78960
    },
    {
      "epoch": 126.98,
      "learning_rate": 0.08730724741945338,
      "loss": 3.1334,
      "step": 78980
    },
    {
      "epoch": 127.0,
      "eval_accuracy": {
        "accuracy": 0.3536500038871181
      },
      "eval_loss": 3.2472386360168457,
      "eval_runtime": 2.9948,
      "eval_samples_per_second": 4295.164,
      "eval_steps_per_second": 67.117,
      "step": 78994
    },
    {
      "epoch": 127.01,
      "learning_rate": 0.0873040319885852,
      "loss": 3.1258,
      "step": 79000
    },
    {
      "epoch": 127.04,
      "learning_rate": 0.08730081655771706,
      "loss": 3.1193,
      "step": 79020
    },
    {
      "epoch": 127.07,
      "learning_rate": 0.08729760112684888,
      "loss": 3.0973,
      "step": 79040
    },
    {
      "epoch": 127.11,
      "learning_rate": 0.0872943856959807,
      "loss": 3.1297,
      "step": 79060
    },
    {
      "epoch": 127.14,
      "learning_rate": 0.08729117026511254,
      "loss": 3.1553,
      "step": 79080
    },
    {
      "epoch": 127.17,
      "learning_rate": 0.08728795483424437,
      "loss": 3.1649,
      "step": 79100
    },
    {
      "epoch": 127.2,
      "learning_rate": 0.08728473940337622,
      "loss": 3.1223,
      "step": 79120
    },
    {
      "epoch": 127.23,
      "learning_rate": 0.08728152397250805,
      "loss": 3.1417,
      "step": 79140
    },
    {
      "epoch": 127.27,
      "learning_rate": 0.08727830854163987,
      "loss": 3.1363,
      "step": 79160
    },
    {
      "epoch": 127.3,
      "learning_rate": 0.08727509311077171,
      "loss": 3.1216,
      "step": 79180
    },
    {
      "epoch": 127.33,
      "learning_rate": 0.08727187767990353,
      "loss": 3.1038,
      "step": 79200
    },
    {
      "epoch": 127.36,
      "learning_rate": 0.08726866224903539,
      "loss": 3.1392,
      "step": 79220
    },
    {
      "epoch": 127.4,
      "learning_rate": 0.08726544681816721,
      "loss": 3.1274,
      "step": 79240
    },
    {
      "epoch": 127.43,
      "learning_rate": 0.08726223138729904,
      "loss": 3.1143,
      "step": 79260
    },
    {
      "epoch": 127.46,
      "learning_rate": 0.08725901595643087,
      "loss": 3.0982,
      "step": 79280
    },
    {
      "epoch": 127.49,
      "learning_rate": 0.0872558005255627,
      "loss": 3.1171,
      "step": 79300
    },
    {
      "epoch": 127.52,
      "learning_rate": 0.08725258509469455,
      "loss": 3.1395,
      "step": 79320
    },
    {
      "epoch": 127.56,
      "learning_rate": 0.08724936966382636,
      "loss": 3.1372,
      "step": 79340
    },
    {
      "epoch": 127.59,
      "learning_rate": 0.0872461542329582,
      "loss": 3.1453,
      "step": 79360
    },
    {
      "epoch": 127.62,
      "learning_rate": 0.08724293880209004,
      "loss": 3.1673,
      "step": 79380
    },
    {
      "epoch": 127.65,
      "learning_rate": 0.08723972337122186,
      "loss": 3.1138,
      "step": 79400
    },
    {
      "epoch": 127.68,
      "learning_rate": 0.0872365079403537,
      "loss": 3.1337,
      "step": 79420
    },
    {
      "epoch": 127.72,
      "learning_rate": 0.08723329250948553,
      "loss": 3.0807,
      "step": 79440
    },
    {
      "epoch": 127.75,
      "learning_rate": 0.08723007707861738,
      "loss": 3.134,
      "step": 79460
    },
    {
      "epoch": 127.78,
      "learning_rate": 0.0872268616477492,
      "loss": 3.1823,
      "step": 79480
    },
    {
      "epoch": 127.81,
      "learning_rate": 0.08722364621688103,
      "loss": 3.1372,
      "step": 79500
    },
    {
      "epoch": 127.85,
      "learning_rate": 0.08722043078601287,
      "loss": 3.1468,
      "step": 79520
    },
    {
      "epoch": 127.88,
      "learning_rate": 0.08721721535514469,
      "loss": 3.1404,
      "step": 79540
    },
    {
      "epoch": 127.91,
      "learning_rate": 0.08721399992427654,
      "loss": 3.1404,
      "step": 79560
    },
    {
      "epoch": 127.94,
      "learning_rate": 0.08721078449340837,
      "loss": 3.1397,
      "step": 79580
    },
    {
      "epoch": 127.97,
      "learning_rate": 0.0872075690625402,
      "loss": 3.1597,
      "step": 79600
    },
    {
      "epoch": 128.0,
      "eval_accuracy": {
        "accuracy": 0.3700536422296509
      },
      "eval_loss": 3.179532527923584,
      "eval_runtime": 3.0878,
      "eval_samples_per_second": 4165.694,
      "eval_steps_per_second": 65.094,
      "step": 79616
    },
    {
      "epoch": 128.01,
      "learning_rate": 0.08720435363167203,
      "loss": 3.1257,
      "step": 79620
    },
    {
      "epoch": 128.04,
      "learning_rate": 0.08720113820080386,
      "loss": 3.1129,
      "step": 79640
    },
    {
      "epoch": 128.07,
      "learning_rate": 0.08719792276993571,
      "loss": 3.069,
      "step": 79660
    },
    {
      "epoch": 128.1,
      "learning_rate": 0.08719470733906752,
      "loss": 3.1082,
      "step": 79680
    },
    {
      "epoch": 128.14,
      "learning_rate": 0.08719149190819936,
      "loss": 3.1323,
      "step": 79700
    },
    {
      "epoch": 128.17,
      "learning_rate": 0.0871882764773312,
      "loss": 3.1545,
      "step": 79720
    },
    {
      "epoch": 128.2,
      "learning_rate": 0.08718506104646302,
      "loss": 3.1335,
      "step": 79740
    },
    {
      "epoch": 128.23,
      "learning_rate": 0.08718184561559486,
      "loss": 3.1141,
      "step": 79760
    },
    {
      "epoch": 128.26,
      "learning_rate": 0.08717863018472669,
      "loss": 3.149,
      "step": 79780
    },
    {
      "epoch": 128.3,
      "learning_rate": 0.08717541475385852,
      "loss": 3.1692,
      "step": 79800
    },
    {
      "epoch": 128.33,
      "learning_rate": 0.08717219932299036,
      "loss": 3.1423,
      "step": 79820
    },
    {
      "epoch": 128.36,
      "learning_rate": 0.08716898389212219,
      "loss": 3.1116,
      "step": 79840
    },
    {
      "epoch": 128.39,
      "learning_rate": 0.08716576846125403,
      "loss": 3.1089,
      "step": 79860
    },
    {
      "epoch": 128.42,
      "learning_rate": 0.08716255303038585,
      "loss": 3.1197,
      "step": 79880
    },
    {
      "epoch": 128.46,
      "learning_rate": 0.08715933759951769,
      "loss": 3.1093,
      "step": 79900
    },
    {
      "epoch": 128.49,
      "learning_rate": 0.08715612216864953,
      "loss": 3.1354,
      "step": 79920
    },
    {
      "epoch": 128.52,
      "learning_rate": 0.08715290673778135,
      "loss": 3.1297,
      "step": 79940
    },
    {
      "epoch": 128.55,
      "learning_rate": 0.08714969130691319,
      "loss": 3.1568,
      "step": 79960
    },
    {
      "epoch": 128.59,
      "learning_rate": 0.08714647587604502,
      "loss": 3.185,
      "step": 79980
    },
    {
      "epoch": 128.62,
      "learning_rate": 0.08714326044517685,
      "loss": 3.1506,
      "step": 80000
    },
    {
      "epoch": 128.65,
      "learning_rate": 0.08714004501430868,
      "loss": 3.1508,
      "step": 80020
    },
    {
      "epoch": 128.68,
      "learning_rate": 0.08713682958344052,
      "loss": 3.099,
      "step": 80040
    },
    {
      "epoch": 128.71,
      "learning_rate": 0.08713361415257236,
      "loss": 3.0844,
      "step": 80060
    },
    {
      "epoch": 128.75,
      "learning_rate": 0.08713039872170418,
      "loss": 3.1188,
      "step": 80080
    },
    {
      "epoch": 128.78,
      "learning_rate": 0.08712718329083602,
      "loss": 3.1262,
      "step": 80100
    },
    {
      "epoch": 128.81,
      "learning_rate": 0.08712396785996784,
      "loss": 3.1503,
      "step": 80120
    },
    {
      "epoch": 128.84,
      "learning_rate": 0.08712075242909968,
      "loss": 3.0892,
      "step": 80140
    },
    {
      "epoch": 128.87,
      "learning_rate": 0.08711753699823152,
      "loss": 3.0997,
      "step": 80160
    },
    {
      "epoch": 128.91,
      "learning_rate": 0.08711432156736335,
      "loss": 3.098,
      "step": 80180
    },
    {
      "epoch": 128.94,
      "learning_rate": 0.08711110613649518,
      "loss": 3.1061,
      "step": 80200
    },
    {
      "epoch": 128.97,
      "learning_rate": 0.08710789070562701,
      "loss": 3.123,
      "step": 80220
    },
    {
      "epoch": 129.0,
      "eval_accuracy": {
        "accuracy": 0.358625515043147
      },
      "eval_loss": 3.243136405944824,
      "eval_runtime": 2.7384,
      "eval_samples_per_second": 4697.214,
      "eval_steps_per_second": 73.4,
      "step": 80238
    },
    {
      "epoch": 129.0,
      "learning_rate": 0.08710467527475885,
      "loss": 3.1521,
      "step": 80240
    },
    {
      "epoch": 129.04,
      "learning_rate": 0.08710145984389069,
      "loss": 3.1373,
      "step": 80260
    },
    {
      "epoch": 129.07,
      "learning_rate": 0.08709824441302251,
      "loss": 3.0663,
      "step": 80280
    },
    {
      "epoch": 129.1,
      "learning_rate": 0.08709502898215435,
      "loss": 3.0984,
      "step": 80300
    },
    {
      "epoch": 129.13,
      "learning_rate": 0.08709181355128617,
      "loss": 3.1064,
      "step": 80320
    },
    {
      "epoch": 129.16,
      "learning_rate": 0.08708859812041801,
      "loss": 3.1007,
      "step": 80340
    },
    {
      "epoch": 129.2,
      "learning_rate": 0.08708538268954984,
      "loss": 3.1011,
      "step": 80360
    },
    {
      "epoch": 129.23,
      "learning_rate": 0.08708216725868168,
      "loss": 3.1387,
      "step": 80380
    },
    {
      "epoch": 129.26,
      "learning_rate": 0.08707895182781351,
      "loss": 3.1218,
      "step": 80400
    },
    {
      "epoch": 129.29,
      "learning_rate": 0.08707589716848875,
      "loss": 3.1203,
      "step": 80420
    },
    {
      "epoch": 129.32,
      "learning_rate": 0.08707268173762059,
      "loss": 3.1578,
      "step": 80440
    },
    {
      "epoch": 129.36,
      "learning_rate": 0.08706946630675241,
      "loss": 3.1679,
      "step": 80460
    },
    {
      "epoch": 129.39,
      "learning_rate": 0.08706625087588425,
      "loss": 3.126,
      "step": 80480
    },
    {
      "epoch": 129.42,
      "learning_rate": 0.08706303544501609,
      "loss": 3.0914,
      "step": 80500
    },
    {
      "epoch": 129.45,
      "learning_rate": 0.08705982001414792,
      "loss": 3.076,
      "step": 80520
    },
    {
      "epoch": 129.49,
      "learning_rate": 0.08705660458327975,
      "loss": 3.0793,
      "step": 80540
    },
    {
      "epoch": 129.52,
      "learning_rate": 0.08705338915241158,
      "loss": 3.1025,
      "step": 80560
    },
    {
      "epoch": 129.55,
      "learning_rate": 0.08705017372154342,
      "loss": 3.1096,
      "step": 80580
    },
    {
      "epoch": 129.58,
      "learning_rate": 0.08704695829067526,
      "loss": 3.1016,
      "step": 80600
    },
    {
      "epoch": 129.61,
      "learning_rate": 0.08704374285980708,
      "loss": 3.1552,
      "step": 80620
    },
    {
      "epoch": 129.65,
      "learning_rate": 0.08704052742893892,
      "loss": 3.1684,
      "step": 80640
    },
    {
      "epoch": 129.68,
      "learning_rate": 0.08703731199807074,
      "loss": 3.1402,
      "step": 80660
    },
    {
      "epoch": 129.71,
      "learning_rate": 0.08703409656720258,
      "loss": 3.1384,
      "step": 80680
    },
    {
      "epoch": 129.74,
      "learning_rate": 0.0870308811363344,
      "loss": 3.1158,
      "step": 80700
    },
    {
      "epoch": 129.77,
      "learning_rate": 0.08702766570546623,
      "loss": 3.1489,
      "step": 80720
    },
    {
      "epoch": 129.81,
      "learning_rate": 0.08702445027459808,
      "loss": 3.0882,
      "step": 80740
    },
    {
      "epoch": 129.84,
      "learning_rate": 0.08702123484372991,
      "loss": 3.0807,
      "step": 80760
    },
    {
      "epoch": 129.87,
      "learning_rate": 0.08701801941286175,
      "loss": 3.1047,
      "step": 80780
    },
    {
      "epoch": 129.9,
      "learning_rate": 0.08701480398199357,
      "loss": 3.0944,
      "step": 80800
    },
    {
      "epoch": 129.94,
      "learning_rate": 0.0870115885511254,
      "loss": 3.0831,
      "step": 80820
    },
    {
      "epoch": 129.97,
      "learning_rate": 0.08700837312025725,
      "loss": 3.1314,
      "step": 80840
    },
    {
      "epoch": 130.0,
      "learning_rate": 0.08700515768938907,
      "loss": 3.1326,
      "step": 80860
    },
    {
      "epoch": 130.0,
      "eval_accuracy": {
        "accuracy": 0.35753712197776566
      },
      "eval_loss": 3.1995649337768555,
      "eval_runtime": 2.6575,
      "eval_samples_per_second": 4840.271,
      "eval_steps_per_second": 75.635,
      "step": 80860
    },
    {
      "epoch": 130.03,
      "learning_rate": 0.08700194225852091,
      "loss": 3.1302,
      "step": 80880
    },
    {
      "epoch": 130.06,
      "learning_rate": 0.08699872682765274,
      "loss": 3.0904,
      "step": 80900
    },
    {
      "epoch": 130.1,
      "learning_rate": 0.08699551139678456,
      "loss": 3.1421,
      "step": 80920
    },
    {
      "epoch": 130.13,
      "learning_rate": 0.08699229596591641,
      "loss": 3.1563,
      "step": 80940
    },
    {
      "epoch": 130.16,
      "learning_rate": 0.08698908053504824,
      "loss": 3.161,
      "step": 80960
    },
    {
      "epoch": 130.19,
      "learning_rate": 0.08698586510418008,
      "loss": 3.2028,
      "step": 80980
    },
    {
      "epoch": 130.23,
      "learning_rate": 0.0869826496733119,
      "loss": 3.1261,
      "step": 81000
    },
    {
      "epoch": 130.26,
      "learning_rate": 0.08697943424244374,
      "loss": 3.1325,
      "step": 81020
    },
    {
      "epoch": 130.29,
      "learning_rate": 0.08697621881157556,
      "loss": 3.1537,
      "step": 81040
    },
    {
      "epoch": 130.32,
      "learning_rate": 0.08697300338070739,
      "loss": 3.1235,
      "step": 81060
    },
    {
      "epoch": 130.35,
      "learning_rate": 0.08696978794983924,
      "loss": 3.1337,
      "step": 81080
    },
    {
      "epoch": 130.39,
      "learning_rate": 0.08696657251897107,
      "loss": 3.1263,
      "step": 81100
    },
    {
      "epoch": 130.42,
      "learning_rate": 0.0869633570881029,
      "loss": 3.1416,
      "step": 81120
    },
    {
      "epoch": 130.45,
      "learning_rate": 0.08696014165723473,
      "loss": 3.149,
      "step": 81140
    },
    {
      "epoch": 130.48,
      "learning_rate": 0.08695692622636655,
      "loss": 3.1227,
      "step": 81160
    },
    {
      "epoch": 130.51,
      "learning_rate": 0.0869537107954984,
      "loss": 3.0983,
      "step": 81180
    },
    {
      "epoch": 130.55,
      "learning_rate": 0.08695049536463023,
      "loss": 3.1469,
      "step": 81200
    },
    {
      "epoch": 130.58,
      "learning_rate": 0.08694727993376207,
      "loss": 3.1201,
      "step": 81220
    },
    {
      "epoch": 130.61,
      "learning_rate": 0.0869440645028939,
      "loss": 3.1352,
      "step": 81240
    },
    {
      "epoch": 130.64,
      "learning_rate": 0.08694084907202572,
      "loss": 3.123,
      "step": 81260
    },
    {
      "epoch": 130.68,
      "learning_rate": 0.08693763364115757,
      "loss": 3.1574,
      "step": 81280
    },
    {
      "epoch": 130.71,
      "learning_rate": 0.0869344182102894,
      "loss": 3.0924,
      "step": 81300
    },
    {
      "epoch": 130.74,
      "learning_rate": 0.08693120277942123,
      "loss": 3.1215,
      "step": 81320
    },
    {
      "epoch": 130.77,
      "learning_rate": 0.08692798734855306,
      "loss": 3.109,
      "step": 81340
    },
    {
      "epoch": 130.8,
      "learning_rate": 0.08692477191768488,
      "loss": 3.1061,
      "step": 81360
    },
    {
      "epoch": 130.84,
      "learning_rate": 0.08692155648681672,
      "loss": 3.1077,
      "step": 81380
    },
    {
      "epoch": 130.87,
      "learning_rate": 0.08691834105594855,
      "loss": 3.1315,
      "step": 81400
    },
    {
      "epoch": 130.9,
      "learning_rate": 0.0869151256250804,
      "loss": 3.154,
      "step": 81420
    },
    {
      "epoch": 130.93,
      "learning_rate": 0.08691191019421222,
      "loss": 3.1268,
      "step": 81440
    },
    {
      "epoch": 130.96,
      "learning_rate": 0.08690869476334405,
      "loss": 3.1501,
      "step": 81460
    },
    {
      "epoch": 131.0,
      "learning_rate": 0.08690547933247589,
      "loss": 3.1524,
      "step": 81480
    },
    {
      "epoch": 131.0,
      "eval_accuracy": {
        "accuracy": 0.3541164580579958
      },
      "eval_loss": 3.247688055038452,
      "eval_runtime": 2.9923,
      "eval_samples_per_second": 4298.639,
      "eval_steps_per_second": 67.171,
      "step": 81482
    },
    {
      "epoch": 131.03,
      "learning_rate": 0.08690226390160771,
      "loss": 3.1441,
      "step": 81500
    },
    {
      "epoch": 131.06,
      "learning_rate": 0.08689904847073956,
      "loss": 3.1399,
      "step": 81520
    },
    {
      "epoch": 131.09,
      "learning_rate": 0.08689583303987139,
      "loss": 3.1171,
      "step": 81540
    },
    {
      "epoch": 131.13,
      "learning_rate": 0.08689261760900321,
      "loss": 3.1123,
      "step": 81560
    },
    {
      "epoch": 131.16,
      "learning_rate": 0.08688940217813505,
      "loss": 3.0999,
      "step": 81580
    },
    {
      "epoch": 131.19,
      "learning_rate": 0.08688618674726688,
      "loss": 3.0698,
      "step": 81600
    },
    {
      "epoch": 131.22,
      "learning_rate": 0.08688297131639873,
      "loss": 3.1348,
      "step": 81620
    },
    {
      "epoch": 131.25,
      "learning_rate": 0.08687975588553055,
      "loss": 3.1076,
      "step": 81640
    },
    {
      "epoch": 131.29,
      "learning_rate": 0.0868765404546624,
      "loss": 3.1018,
      "step": 81660
    },
    {
      "epoch": 131.32,
      "learning_rate": 0.08687332502379422,
      "loss": 3.0906,
      "step": 81680
    },
    {
      "epoch": 131.35,
      "learning_rate": 0.08687010959292604,
      "loss": 3.1088,
      "step": 81700
    },
    {
      "epoch": 131.38,
      "learning_rate": 0.08686689416205788,
      "loss": 3.1085,
      "step": 81720
    },
    {
      "epoch": 131.41,
      "learning_rate": 0.0868636787311897,
      "loss": 3.1344,
      "step": 81740
    },
    {
      "epoch": 131.45,
      "learning_rate": 0.08686046330032156,
      "loss": 3.1498,
      "step": 81760
    },
    {
      "epoch": 131.48,
      "learning_rate": 0.08685724786945338,
      "loss": 3.138,
      "step": 81780
    },
    {
      "epoch": 131.51,
      "learning_rate": 0.08685403243858521,
      "loss": 3.105,
      "step": 81800
    },
    {
      "epoch": 131.54,
      "learning_rate": 0.08685081700771705,
      "loss": 3.1172,
      "step": 81820
    },
    {
      "epoch": 131.58,
      "learning_rate": 0.08684760157684887,
      "loss": 3.1418,
      "step": 81840
    },
    {
      "epoch": 131.61,
      "learning_rate": 0.08684438614598072,
      "loss": 3.1043,
      "step": 81860
    },
    {
      "epoch": 131.64,
      "learning_rate": 0.08684117071511255,
      "loss": 3.0703,
      "step": 81880
    },
    {
      "epoch": 131.67,
      "learning_rate": 0.08683795528424437,
      "loss": 3.1477,
      "step": 81900
    },
    {
      "epoch": 131.7,
      "learning_rate": 0.08683473985337621,
      "loss": 3.1173,
      "step": 81920
    },
    {
      "epoch": 131.74,
      "learning_rate": 0.08683152442250804,
      "loss": 3.1459,
      "step": 81940
    },
    {
      "epoch": 131.77,
      "learning_rate": 0.08682830899163989,
      "loss": 3.1151,
      "step": 81960
    },
    {
      "epoch": 131.8,
      "learning_rate": 0.08682509356077171,
      "loss": 3.1557,
      "step": 81980
    },
    {
      "epoch": 131.83,
      "learning_rate": 0.08682187812990354,
      "loss": 3.1161,
      "step": 82000
    },
    {
      "epoch": 131.86,
      "learning_rate": 0.08681866269903538,
      "loss": 3.1539,
      "step": 82020
    },
    {
      "epoch": 131.9,
      "learning_rate": 0.0868154472681672,
      "loss": 3.1703,
      "step": 82040
    },
    {
      "epoch": 131.93,
      "learning_rate": 0.08681223183729905,
      "loss": 3.1445,
      "step": 82060
    },
    {
      "epoch": 131.96,
      "learning_rate": 0.08680901640643086,
      "loss": 3.1535,
      "step": 82080
    },
    {
      "epoch": 131.99,
      "learning_rate": 0.0868058009755627,
      "loss": 3.1542,
      "step": 82100
    },
    {
      "epoch": 132.0,
      "eval_accuracy": {
        "accuracy": 0.3555158205706289
      },
      "eval_loss": 3.235710382461548,
      "eval_runtime": 2.5498,
      "eval_samples_per_second": 5044.647,
      "eval_steps_per_second": 78.829,
      "step": 82104
    },
    {
      "epoch": 132.03,
      "learning_rate": 0.08680258554469454,
      "loss": 3.081,
      "step": 82120
    },
    {
      "epoch": 132.06,
      "learning_rate": 0.08679937011382637,
      "loss": 3.1139,
      "step": 82140
    },
    {
      "epoch": 132.09,
      "learning_rate": 0.0867961546829582,
      "loss": 3.0679,
      "step": 82160
    },
    {
      "epoch": 132.12,
      "learning_rate": 0.08679293925209003,
      "loss": 3.0742,
      "step": 82180
    },
    {
      "epoch": 132.15,
      "learning_rate": 0.08678972382122187,
      "loss": 3.0928,
      "step": 82200
    },
    {
      "epoch": 132.19,
      "learning_rate": 0.0867865083903537,
      "loss": 3.1115,
      "step": 82220
    },
    {
      "epoch": 132.22,
      "learning_rate": 0.08678329295948553,
      "loss": 3.0923,
      "step": 82240
    },
    {
      "epoch": 132.25,
      "learning_rate": 0.08678007752861737,
      "loss": 3.1433,
      "step": 82260
    },
    {
      "epoch": 132.28,
      "learning_rate": 0.0867768620977492,
      "loss": 3.1379,
      "step": 82280
    },
    {
      "epoch": 132.32,
      "learning_rate": 0.08677364666688105,
      "loss": 3.1089,
      "step": 82300
    },
    {
      "epoch": 132.35,
      "learning_rate": 0.08677043123601287,
      "loss": 3.0773,
      "step": 82320
    },
    {
      "epoch": 132.38,
      "learning_rate": 0.0867672158051447,
      "loss": 3.116,
      "step": 82340
    },
    {
      "epoch": 132.41,
      "learning_rate": 0.08676400037427653,
      "loss": 3.0549,
      "step": 82360
    },
    {
      "epoch": 132.44,
      "learning_rate": 0.08676078494340836,
      "loss": 3.0663,
      "step": 82380
    },
    {
      "epoch": 132.48,
      "learning_rate": 0.08675756951254021,
      "loss": 3.0888,
      "step": 82400
    },
    {
      "epoch": 132.51,
      "learning_rate": 0.08675435408167202,
      "loss": 3.0576,
      "step": 82420
    },
    {
      "epoch": 132.54,
      "learning_rate": 0.08675113865080386,
      "loss": 3.0971,
      "step": 82440
    },
    {
      "epoch": 132.57,
      "learning_rate": 0.0867479232199357,
      "loss": 3.1069,
      "step": 82460
    },
    {
      "epoch": 132.6,
      "learning_rate": 0.08674470778906752,
      "loss": 3.0881,
      "step": 82480
    },
    {
      "epoch": 132.64,
      "learning_rate": 0.08674149235819936,
      "loss": 3.1537,
      "step": 82500
    },
    {
      "epoch": 132.67,
      "learning_rate": 0.08673827692733119,
      "loss": 3.1114,
      "step": 82520
    },
    {
      "epoch": 132.7,
      "learning_rate": 0.08673506149646303,
      "loss": 3.1537,
      "step": 82540
    },
    {
      "epoch": 132.73,
      "learning_rate": 0.08673184606559486,
      "loss": 3.1572,
      "step": 82560
    },
    {
      "epoch": 132.77,
      "learning_rate": 0.08672863063472669,
      "loss": 3.1008,
      "step": 82580
    },
    {
      "epoch": 132.8,
      "learning_rate": 0.08672541520385853,
      "loss": 3.1207,
      "step": 82600
    },
    {
      "epoch": 132.83,
      "learning_rate": 0.08672219977299035,
      "loss": 3.1136,
      "step": 82620
    },
    {
      "epoch": 132.86,
      "learning_rate": 0.08671898434212219,
      "loss": 3.1319,
      "step": 82640
    },
    {
      "epoch": 132.89,
      "learning_rate": 0.08671576891125403,
      "loss": 3.1245,
      "step": 82660
    },
    {
      "epoch": 132.93,
      "learning_rate": 0.08671255348038585,
      "loss": 3.1178,
      "step": 82680
    },
    {
      "epoch": 132.96,
      "learning_rate": 0.08670933804951769,
      "loss": 3.1622,
      "step": 82700
    },
    {
      "epoch": 132.99,
      "learning_rate": 0.08670612261864952,
      "loss": 3.1226,
      "step": 82720
    },
    {
      "epoch": 133.0,
      "eval_accuracy": {
        "accuracy": 0.37487366866205396
      },
      "eval_loss": 3.1347055435180664,
      "eval_runtime": 2.9278,
      "eval_samples_per_second": 4393.462,
      "eval_steps_per_second": 68.653,
      "step": 82726
    },
    {
      "epoch": 133.02,
      "learning_rate": 0.08670290718778136,
      "loss": 3.0967,
      "step": 82740
    },
    {
      "epoch": 133.05,
      "learning_rate": 0.08669969175691318,
      "loss": 3.0987,
      "step": 82760
    },
    {
      "epoch": 133.09,
      "learning_rate": 0.08669647632604502,
      "loss": 3.1143,
      "step": 82780
    },
    {
      "epoch": 133.12,
      "learning_rate": 0.08669326089517686,
      "loss": 3.1141,
      "step": 82800
    },
    {
      "epoch": 133.15,
      "learning_rate": 0.08669004546430868,
      "loss": 3.113,
      "step": 82820
    },
    {
      "epoch": 133.18,
      "learning_rate": 0.08668683003344052,
      "loss": 3.1362,
      "step": 82840
    },
    {
      "epoch": 133.22,
      "learning_rate": 0.08668361460257235,
      "loss": 3.1216,
      "step": 82860
    },
    {
      "epoch": 133.25,
      "learning_rate": 0.08668039917170418,
      "loss": 3.079,
      "step": 82880
    },
    {
      "epoch": 133.28,
      "learning_rate": 0.08667718374083602,
      "loss": 3.0884,
      "step": 82900
    },
    {
      "epoch": 133.31,
      "learning_rate": 0.08667396830996785,
      "loss": 3.0918,
      "step": 82920
    },
    {
      "epoch": 133.34,
      "learning_rate": 0.08667075287909969,
      "loss": 3.1158,
      "step": 82940
    },
    {
      "epoch": 133.38,
      "learning_rate": 0.08666753744823151,
      "loss": 3.1022,
      "step": 82960
    },
    {
      "epoch": 133.41,
      "learning_rate": 0.08666432201736335,
      "loss": 3.0897,
      "step": 82980
    },
    {
      "epoch": 133.44,
      "learning_rate": 0.08666110658649519,
      "loss": 3.0893,
      "step": 83000
    },
    {
      "epoch": 133.47,
      "learning_rate": 0.08665789115562701,
      "loss": 3.1415,
      "step": 83020
    },
    {
      "epoch": 133.5,
      "learning_rate": 0.08665467572475885,
      "loss": 3.134,
      "step": 83040
    },
    {
      "epoch": 133.54,
      "learning_rate": 0.08665146029389068,
      "loss": 3.1156,
      "step": 83060
    },
    {
      "epoch": 133.57,
      "learning_rate": 0.08664824486302251,
      "loss": 3.1164,
      "step": 83080
    },
    {
      "epoch": 133.6,
      "learning_rate": 0.08664502943215434,
      "loss": 3.1272,
      "step": 83100
    },
    {
      "epoch": 133.63,
      "learning_rate": 0.08664181400128618,
      "loss": 3.0969,
      "step": 83120
    },
    {
      "epoch": 133.67,
      "learning_rate": 0.08663859857041802,
      "loss": 3.1318,
      "step": 83140
    },
    {
      "epoch": 133.7,
      "learning_rate": 0.08663538313954984,
      "loss": 3.1136,
      "step": 83160
    },
    {
      "epoch": 133.73,
      "learning_rate": 0.08663216770868168,
      "loss": 3.1045,
      "step": 83180
    },
    {
      "epoch": 133.76,
      "learning_rate": 0.0866289522778135,
      "loss": 3.1236,
      "step": 83200
    },
    {
      "epoch": 133.79,
      "learning_rate": 0.08662573684694534,
      "loss": 3.133,
      "step": 83220
    },
    {
      "epoch": 133.83,
      "learning_rate": 0.08662252141607718,
      "loss": 3.0972,
      "step": 83240
    },
    {
      "epoch": 133.86,
      "learning_rate": 0.086619305985209,
      "loss": 3.1676,
      "step": 83260
    },
    {
      "epoch": 133.89,
      "learning_rate": 0.08661609055434084,
      "loss": 3.1484,
      "step": 83280
    },
    {
      "epoch": 133.92,
      "learning_rate": 0.08661287512347267,
      "loss": 3.1538,
      "step": 83300
    },
    {
      "epoch": 133.95,
      "learning_rate": 0.08660965969260451,
      "loss": 3.1677,
      "step": 83320
    },
    {
      "epoch": 133.99,
      "learning_rate": 0.08660644426173635,
      "loss": 3.1531,
      "step": 83340
    },
    {
      "epoch": 134.0,
      "eval_accuracy": {
        "accuracy": 0.3588587421285859
      },
      "eval_loss": 3.199110269546509,
      "eval_runtime": 2.87,
      "eval_samples_per_second": 4481.858,
      "eval_steps_per_second": 70.034,
      "step": 83348
    },
    {
      "epoch": 134.02,
      "learning_rate": 0.08660322883086817,
      "loss": 3.0902,
      "step": 83360
    },
    {
      "epoch": 134.05,
      "learning_rate": 0.08660001340000001,
      "loss": 3.0962,
      "step": 83380
    },
    {
      "epoch": 134.08,
      "learning_rate": 0.08659679796913183,
      "loss": 3.1015,
      "step": 83400
    },
    {
      "epoch": 134.12,
      "learning_rate": 0.08659358253826367,
      "loss": 3.144,
      "step": 83420
    },
    {
      "epoch": 134.15,
      "learning_rate": 0.0865903671073955,
      "loss": 3.1184,
      "step": 83440
    },
    {
      "epoch": 134.18,
      "learning_rate": 0.08658715167652734,
      "loss": 3.1197,
      "step": 83460
    },
    {
      "epoch": 134.21,
      "learning_rate": 0.08658409701720259,
      "loss": 3.1538,
      "step": 83480
    },
    {
      "epoch": 134.24,
      "learning_rate": 0.08658088158633441,
      "loss": 3.1294,
      "step": 83500
    },
    {
      "epoch": 134.28,
      "learning_rate": 0.08657766615546625,
      "loss": 3.1211,
      "step": 83520
    },
    {
      "epoch": 134.31,
      "learning_rate": 0.08657445072459807,
      "loss": 3.1439,
      "step": 83540
    },
    {
      "epoch": 134.34,
      "learning_rate": 0.0865712352937299,
      "loss": 3.1026,
      "step": 83560
    },
    {
      "epoch": 134.37,
      "learning_rate": 0.08656801986286175,
      "loss": 3.1386,
      "step": 83580
    },
    {
      "epoch": 134.41,
      "learning_rate": 0.08656480443199357,
      "loss": 3.1702,
      "step": 83600
    },
    {
      "epoch": 134.44,
      "learning_rate": 0.08656158900112541,
      "loss": 3.0782,
      "step": 83620
    },
    {
      "epoch": 134.47,
      "learning_rate": 0.08655837357025724,
      "loss": 3.0459,
      "step": 83640
    },
    {
      "epoch": 134.5,
      "learning_rate": 0.08655515813938906,
      "loss": 3.1037,
      "step": 83660
    },
    {
      "epoch": 134.53,
      "learning_rate": 0.08655194270852092,
      "loss": 3.1055,
      "step": 83680
    },
    {
      "epoch": 134.57,
      "learning_rate": 0.08654872727765274,
      "loss": 3.0551,
      "step": 83700
    },
    {
      "epoch": 134.6,
      "learning_rate": 0.08654551184678458,
      "loss": 3.1184,
      "step": 83720
    },
    {
      "epoch": 134.63,
      "learning_rate": 0.0865422964159164,
      "loss": 3.1446,
      "step": 83740
    },
    {
      "epoch": 134.66,
      "learning_rate": 0.08653908098504823,
      "loss": 3.0785,
      "step": 83760
    },
    {
      "epoch": 134.69,
      "learning_rate": 0.08653586555418007,
      "loss": 3.0869,
      "step": 83780
    },
    {
      "epoch": 134.73,
      "learning_rate": 0.08653265012331189,
      "loss": 3.136,
      "step": 83800
    },
    {
      "epoch": 134.76,
      "learning_rate": 0.08652943469244374,
      "loss": 3.1301,
      "step": 83820
    },
    {
      "epoch": 134.79,
      "learning_rate": 0.08652621926157557,
      "loss": 3.1166,
      "step": 83840
    },
    {
      "epoch": 134.82,
      "learning_rate": 0.0865230038307074,
      "loss": 3.1675,
      "step": 83860
    },
    {
      "epoch": 134.86,
      "learning_rate": 0.08651978839983923,
      "loss": 3.1047,
      "step": 83880
    },
    {
      "epoch": 134.89,
      "learning_rate": 0.08651657296897106,
      "loss": 3.0671,
      "step": 83900
    },
    {
      "epoch": 134.92,
      "learning_rate": 0.08651335753810291,
      "loss": 3.1202,
      "step": 83920
    },
    {
      "epoch": 134.95,
      "learning_rate": 0.08651014210723473,
      "loss": 3.0755,
      "step": 83940
    },
    {
      "epoch": 134.98,
      "learning_rate": 0.08650692667636657,
      "loss": 3.1553,
      "step": 83960
    },
    {
      "epoch": 135.0,
      "eval_accuracy": {
        "accuracy": 0.3660887817771904
      },
      "eval_loss": 3.187650680541992,
      "eval_runtime": 2.7527,
      "eval_samples_per_second": 4672.802,
      "eval_steps_per_second": 73.018,
      "step": 83970
    },
    {
      "epoch": 135.02,
      "learning_rate": 0.0865037112454984,
      "loss": 3.1175,
      "step": 83980
    },
    {
      "epoch": 135.05,
      "learning_rate": 0.08650049581463022,
      "loss": 3.1159,
      "step": 84000
    },
    {
      "epoch": 135.08,
      "learning_rate": 0.08649728038376207,
      "loss": 3.0743,
      "step": 84020
    },
    {
      "epoch": 135.11,
      "learning_rate": 0.0864940649528939,
      "loss": 3.1012,
      "step": 84040
    },
    {
      "epoch": 135.14,
      "learning_rate": 0.08649084952202574,
      "loss": 3.0931,
      "step": 84060
    },
    {
      "epoch": 135.18,
      "learning_rate": 0.08648763409115756,
      "loss": 3.1185,
      "step": 84080
    },
    {
      "epoch": 135.21,
      "learning_rate": 0.08648441866028939,
      "loss": 3.1258,
      "step": 84100
    },
    {
      "epoch": 135.24,
      "learning_rate": 0.08648120322942122,
      "loss": 3.0971,
      "step": 84120
    },
    {
      "epoch": 135.27,
      "learning_rate": 0.08647798779855305,
      "loss": 3.0757,
      "step": 84140
    },
    {
      "epoch": 135.31,
      "learning_rate": 0.0864747723676849,
      "loss": 3.0683,
      "step": 84160
    },
    {
      "epoch": 135.34,
      "learning_rate": 0.08647155693681673,
      "loss": 3.09,
      "step": 84180
    },
    {
      "epoch": 135.37,
      "learning_rate": 0.08646834150594855,
      "loss": 3.1221,
      "step": 84200
    },
    {
      "epoch": 135.4,
      "learning_rate": 0.08646512607508039,
      "loss": 3.0968,
      "step": 84220
    },
    {
      "epoch": 135.43,
      "learning_rate": 0.08646191064421221,
      "loss": 3.0555,
      "step": 84240
    },
    {
      "epoch": 135.47,
      "learning_rate": 0.08645869521334407,
      "loss": 3.0669,
      "step": 84260
    },
    {
      "epoch": 135.5,
      "learning_rate": 0.08645547978247589,
      "loss": 3.1053,
      "step": 84280
    },
    {
      "epoch": 135.53,
      "learning_rate": 0.08645226435160772,
      "loss": 3.1205,
      "step": 84300
    },
    {
      "epoch": 135.56,
      "learning_rate": 0.08644904892073955,
      "loss": 3.1076,
      "step": 84320
    },
    {
      "epoch": 135.59,
      "learning_rate": 0.08644583348987138,
      "loss": 3.1198,
      "step": 84340
    },
    {
      "epoch": 135.63,
      "learning_rate": 0.08644261805900323,
      "loss": 3.1005,
      "step": 84360
    },
    {
      "epoch": 135.66,
      "learning_rate": 0.08643940262813506,
      "loss": 3.0846,
      "step": 84380
    },
    {
      "epoch": 135.69,
      "learning_rate": 0.08643618719726688,
      "loss": 3.0872,
      "step": 84400
    },
    {
      "epoch": 135.72,
      "learning_rate": 0.08643297176639872,
      "loss": 3.1185,
      "step": 84420
    },
    {
      "epoch": 135.76,
      "learning_rate": 0.08642975633553054,
      "loss": 3.1108,
      "step": 84440
    },
    {
      "epoch": 135.79,
      "learning_rate": 0.0864265409046624,
      "loss": 3.148,
      "step": 84460
    },
    {
      "epoch": 135.82,
      "learning_rate": 0.08642332547379421,
      "loss": 3.0798,
      "step": 84480
    },
    {
      "epoch": 135.85,
      "learning_rate": 0.08642011004292606,
      "loss": 3.1156,
      "step": 84500
    },
    {
      "epoch": 135.88,
      "learning_rate": 0.08641689461205788,
      "loss": 3.1528,
      "step": 84520
    },
    {
      "epoch": 135.92,
      "learning_rate": 0.08641367918118971,
      "loss": 3.1335,
      "step": 84540
    },
    {
      "epoch": 135.95,
      "learning_rate": 0.08641046375032155,
      "loss": 3.1502,
      "step": 84560
    },
    {
      "epoch": 135.98,
      "learning_rate": 0.08640724831945337,
      "loss": 3.1103,
      "step": 84580
    },
    {
      "epoch": 136.0,
      "eval_accuracy": {
        "accuracy": 0.36227940604835573
      },
      "eval_loss": 3.2038683891296387,
      "eval_runtime": 3.0682,
      "eval_samples_per_second": 4192.336,
      "eval_steps_per_second": 65.51,
      "step": 84592
    },
    {
      "epoch": 136.01,
      "learning_rate": 0.08640403288858522,
      "loss": 3.1026,
      "step": 84600
    },
    {
      "epoch": 136.05,
      "learning_rate": 0.08640081745771705,
      "loss": 3.1147,
      "step": 84620
    },
    {
      "epoch": 136.08,
      "learning_rate": 0.08639760202684887,
      "loss": 3.1089,
      "step": 84640
    },
    {
      "epoch": 136.11,
      "learning_rate": 0.08639438659598071,
      "loss": 3.1402,
      "step": 84660
    },
    {
      "epoch": 136.14,
      "learning_rate": 0.08639117116511254,
      "loss": 3.153,
      "step": 84680
    },
    {
      "epoch": 136.17,
      "learning_rate": 0.08638795573424439,
      "loss": 3.0969,
      "step": 84700
    },
    {
      "epoch": 136.21,
      "learning_rate": 0.08638474030337621,
      "loss": 3.1085,
      "step": 84720
    },
    {
      "epoch": 136.24,
      "learning_rate": 0.08638152487250804,
      "loss": 3.0925,
      "step": 84740
    },
    {
      "epoch": 136.27,
      "learning_rate": 0.08637830944163988,
      "loss": 3.1086,
      "step": 84760
    },
    {
      "epoch": 136.3,
      "learning_rate": 0.0863750940107717,
      "loss": 3.1403,
      "step": 84780
    },
    {
      "epoch": 136.33,
      "learning_rate": 0.08637187857990355,
      "loss": 3.1542,
      "step": 84800
    },
    {
      "epoch": 136.37,
      "learning_rate": 0.08636866314903537,
      "loss": 3.1732,
      "step": 84820
    },
    {
      "epoch": 136.4,
      "learning_rate": 0.0863654477181672,
      "loss": 3.1105,
      "step": 84840
    },
    {
      "epoch": 136.43,
      "learning_rate": 0.08636223228729904,
      "loss": 3.0942,
      "step": 84860
    },
    {
      "epoch": 136.46,
      "learning_rate": 0.08635901685643087,
      "loss": 3.1304,
      "step": 84880
    },
    {
      "epoch": 136.5,
      "learning_rate": 0.0863558014255627,
      "loss": 3.1032,
      "step": 84900
    },
    {
      "epoch": 136.53,
      "learning_rate": 0.08635258599469453,
      "loss": 3.0533,
      "step": 84920
    },
    {
      "epoch": 136.56,
      "learning_rate": 0.08634937056382637,
      "loss": 3.081,
      "step": 84940
    },
    {
      "epoch": 136.59,
      "learning_rate": 0.08634615513295821,
      "loss": 3.1406,
      "step": 84960
    },
    {
      "epoch": 136.62,
      "learning_rate": 0.08634293970209003,
      "loss": 3.1066,
      "step": 84980
    },
    {
      "epoch": 136.66,
      "learning_rate": 0.08633972427122187,
      "loss": 3.1026,
      "step": 85000
    },
    {
      "epoch": 136.69,
      "learning_rate": 0.0863365088403537,
      "loss": 3.1336,
      "step": 85020
    },
    {
      "epoch": 136.72,
      "learning_rate": 0.08633329340948553,
      "loss": 3.1139,
      "step": 85040
    },
    {
      "epoch": 136.75,
      "learning_rate": 0.08633007797861737,
      "loss": 3.1144,
      "step": 85060
    },
    {
      "epoch": 136.78,
      "learning_rate": 0.0863268625477492,
      "loss": 3.0744,
      "step": 85080
    },
    {
      "epoch": 136.82,
      "learning_rate": 0.08632364711688104,
      "loss": 3.1077,
      "step": 85100
    },
    {
      "epoch": 136.85,
      "learning_rate": 0.08632043168601286,
      "loss": 3.0948,
      "step": 85120
    },
    {
      "epoch": 136.88,
      "learning_rate": 0.08631721625514471,
      "loss": 3.0952,
      "step": 85140
    },
    {
      "epoch": 136.91,
      "learning_rate": 0.08631400082427652,
      "loss": 3.0924,
      "step": 85160
    },
    {
      "epoch": 136.95,
      "learning_rate": 0.08631078539340836,
      "loss": 3.1173,
      "step": 85180
    },
    {
      "epoch": 136.98,
      "learning_rate": 0.0863075699625402,
      "loss": 3.1562,
      "step": 85200
    },
    {
      "epoch": 137.0,
      "eval_accuracy": {
        "accuracy": 0.3581590608722693
      },
      "eval_loss": 3.224069833755493,
      "eval_runtime": 2.6722,
      "eval_samples_per_second": 4813.672,
      "eval_steps_per_second": 75.219,
      "step": 85214
    },
    {
      "epoch": 137.01,
      "learning_rate": 0.08630435453167203,
      "loss": 3.1338,
      "step": 85220
    },
    {
      "epoch": 137.04,
      "learning_rate": 0.08630113910080386,
      "loss": 3.0944,
      "step": 85240
    },
    {
      "epoch": 137.07,
      "learning_rate": 0.08629792366993569,
      "loss": 3.1011,
      "step": 85260
    },
    {
      "epoch": 137.11,
      "learning_rate": 0.08629470823906753,
      "loss": 3.085,
      "step": 85280
    },
    {
      "epoch": 137.14,
      "learning_rate": 0.08629149280819937,
      "loss": 3.0626,
      "step": 85300
    },
    {
      "epoch": 137.17,
      "learning_rate": 0.08628827737733119,
      "loss": 3.0938,
      "step": 85320
    },
    {
      "epoch": 137.2,
      "learning_rate": 0.08628506194646303,
      "loss": 3.1455,
      "step": 85340
    },
    {
      "epoch": 137.23,
      "learning_rate": 0.08628184651559485,
      "loss": 3.1152,
      "step": 85360
    },
    {
      "epoch": 137.27,
      "learning_rate": 0.08627863108472669,
      "loss": 3.1049,
      "step": 85380
    },
    {
      "epoch": 137.3,
      "learning_rate": 0.08627541565385853,
      "loss": 3.111,
      "step": 85400
    },
    {
      "epoch": 137.33,
      "learning_rate": 0.08627220022299036,
      "loss": 3.0709,
      "step": 85420
    },
    {
      "epoch": 137.36,
      "learning_rate": 0.0862689847921222,
      "loss": 3.0804,
      "step": 85440
    },
    {
      "epoch": 137.4,
      "learning_rate": 0.08626576936125402,
      "loss": 3.1137,
      "step": 85460
    },
    {
      "epoch": 137.43,
      "learning_rate": 0.08626255393038586,
      "loss": 3.1136,
      "step": 85480
    },
    {
      "epoch": 137.46,
      "learning_rate": 0.08625933849951768,
      "loss": 3.1381,
      "step": 85500
    },
    {
      "epoch": 137.49,
      "learning_rate": 0.08625612306864952,
      "loss": 3.1074,
      "step": 85520
    },
    {
      "epoch": 137.52,
      "learning_rate": 0.08625290763778136,
      "loss": 3.1146,
      "step": 85540
    },
    {
      "epoch": 137.56,
      "learning_rate": 0.08624969220691318,
      "loss": 3.0764,
      "step": 85560
    },
    {
      "epoch": 137.59,
      "learning_rate": 0.08624647677604502,
      "loss": 3.115,
      "step": 85580
    },
    {
      "epoch": 137.62,
      "learning_rate": 0.08624326134517685,
      "loss": 3.0877,
      "step": 85600
    },
    {
      "epoch": 137.65,
      "learning_rate": 0.08624004591430869,
      "loss": 3.0916,
      "step": 85620
    },
    {
      "epoch": 137.68,
      "learning_rate": 0.08623683048344052,
      "loss": 3.0838,
      "step": 85640
    },
    {
      "epoch": 137.72,
      "learning_rate": 0.08623361505257235,
      "loss": 3.1086,
      "step": 85660
    },
    {
      "epoch": 137.75,
      "learning_rate": 0.08623039962170419,
      "loss": 3.123,
      "step": 85680
    },
    {
      "epoch": 137.78,
      "learning_rate": 0.08622718419083601,
      "loss": 3.1519,
      "step": 85700
    },
    {
      "epoch": 137.81,
      "learning_rate": 0.08622396875996785,
      "loss": 3.0868,
      "step": 85720
    },
    {
      "epoch": 137.85,
      "learning_rate": 0.08622075332909969,
      "loss": 3.1396,
      "step": 85740
    },
    {
      "epoch": 137.88,
      "learning_rate": 0.08621753789823151,
      "loss": 3.1411,
      "step": 85760
    },
    {
      "epoch": 137.91,
      "learning_rate": 0.08621432246736335,
      "loss": 3.0975,
      "step": 85780
    },
    {
      "epoch": 137.94,
      "learning_rate": 0.08621110703649518,
      "loss": 3.0867,
      "step": 85800
    },
    {
      "epoch": 137.97,
      "learning_rate": 0.08620789160562702,
      "loss": 3.0848,
      "step": 85820
    },
    {
      "epoch": 138.0,
      "eval_accuracy": {
        "accuracy": 0.3593251962994636
      },
      "eval_loss": 3.224280595779419,
      "eval_runtime": 3.01,
      "eval_samples_per_second": 4273.437,
      "eval_steps_per_second": 66.778,
      "step": 85836
    },
    {
      "epoch": 138.01,
      "learning_rate": 0.08620467617475884,
      "loss": 3.0956,
      "step": 85840
    },
    {
      "epoch": 138.04,
      "learning_rate": 0.08620146074389068,
      "loss": 3.0834,
      "step": 85860
    },
    {
      "epoch": 138.07,
      "learning_rate": 0.08619824531302252,
      "loss": 3.089,
      "step": 85880
    },
    {
      "epoch": 138.1,
      "learning_rate": 0.08619502988215434,
      "loss": 3.1124,
      "step": 85900
    },
    {
      "epoch": 138.14,
      "learning_rate": 0.08619181445128618,
      "loss": 3.0856,
      "step": 85920
    },
    {
      "epoch": 138.17,
      "learning_rate": 0.086188599020418,
      "loss": 3.1053,
      "step": 85940
    },
    {
      "epoch": 138.2,
      "learning_rate": 0.08618538358954984,
      "loss": 3.109,
      "step": 85960
    },
    {
      "epoch": 138.23,
      "learning_rate": 0.08618216815868168,
      "loss": 3.084,
      "step": 85980
    },
    {
      "epoch": 138.26,
      "learning_rate": 0.08617895272781351,
      "loss": 3.0891,
      "step": 86000
    },
    {
      "epoch": 138.3,
      "learning_rate": 0.08617573729694535,
      "loss": 3.1057,
      "step": 86020
    },
    {
      "epoch": 138.33,
      "learning_rate": 0.08617252186607717,
      "loss": 3.1216,
      "step": 86040
    },
    {
      "epoch": 138.36,
      "learning_rate": 0.08616930643520901,
      "loss": 3.1245,
      "step": 86060
    },
    {
      "epoch": 138.39,
      "learning_rate": 0.08616609100434085,
      "loss": 3.0827,
      "step": 86080
    },
    {
      "epoch": 138.42,
      "learning_rate": 0.08616287557347267,
      "loss": 3.1194,
      "step": 86100
    },
    {
      "epoch": 138.46,
      "learning_rate": 0.08615966014260451,
      "loss": 3.1378,
      "step": 86120
    },
    {
      "epoch": 138.49,
      "learning_rate": 0.08615644471173634,
      "loss": 3.1023,
      "step": 86140
    },
    {
      "epoch": 138.52,
      "learning_rate": 0.08615322928086817,
      "loss": 3.0815,
      "step": 86160
    },
    {
      "epoch": 138.55,
      "learning_rate": 0.08615001385,
      "loss": 3.0962,
      "step": 86180
    },
    {
      "epoch": 138.59,
      "learning_rate": 0.08614679841913184,
      "loss": 3.0896,
      "step": 86200
    },
    {
      "epoch": 138.62,
      "learning_rate": 0.08614358298826368,
      "loss": 3.1194,
      "step": 86220
    },
    {
      "epoch": 138.65,
      "learning_rate": 0.0861403675573955,
      "loss": 3.0657,
      "step": 86240
    },
    {
      "epoch": 138.68,
      "learning_rate": 0.08613715212652734,
      "loss": 3.0832,
      "step": 86260
    },
    {
      "epoch": 138.71,
      "learning_rate": 0.08613393669565916,
      "loss": 3.067,
      "step": 86280
    },
    {
      "epoch": 138.75,
      "learning_rate": 0.086130721264791,
      "loss": 3.0568,
      "step": 86300
    },
    {
      "epoch": 138.78,
      "learning_rate": 0.08612750583392284,
      "loss": 3.1363,
      "step": 86320
    },
    {
      "epoch": 138.81,
      "learning_rate": 0.08612429040305467,
      "loss": 3.1304,
      "step": 86340
    },
    {
      "epoch": 138.84,
      "learning_rate": 0.0861210749721865,
      "loss": 3.1255,
      "step": 86360
    },
    {
      "epoch": 138.87,
      "learning_rate": 0.08611785954131833,
      "loss": 3.0973,
      "step": 86380
    },
    {
      "epoch": 138.91,
      "learning_rate": 0.08611464411045017,
      "loss": 3.126,
      "step": 86400
    },
    {
      "epoch": 138.94,
      "learning_rate": 0.086111428679582,
      "loss": 3.1334,
      "step": 86420
    },
    {
      "epoch": 138.97,
      "learning_rate": 0.08610821324871383,
      "loss": 3.1516,
      "step": 86440
    },
    {
      "epoch": 139.0,
      "eval_accuracy": {
        "accuracy": 0.3615797247920392
      },
      "eval_loss": 3.2061421871185303,
      "eval_runtime": 2.8936,
      "eval_samples_per_second": 4445.274,
      "eval_steps_per_second": 69.463,
      "step": 86458
    },
    {
      "epoch": 139.0,
      "learning_rate": 0.08610499781784567,
      "loss": 3.1456,
      "step": 86460
    },
    {
      "epoch": 139.04,
      "learning_rate": 0.0861017823869775,
      "loss": 3.1882,
      "step": 86480
    },
    {
      "epoch": 139.07,
      "learning_rate": 0.08609856695610933,
      "loss": 3.1066,
      "step": 86500
    },
    {
      "epoch": 139.1,
      "learning_rate": 0.08609535152524116,
      "loss": 3.1059,
      "step": 86520
    },
    {
      "epoch": 139.13,
      "learning_rate": 0.086092136094373,
      "loss": 3.0641,
      "step": 86540
    },
    {
      "epoch": 139.16,
      "learning_rate": 0.08608892066350483,
      "loss": 3.05,
      "step": 86560
    },
    {
      "epoch": 139.2,
      "learning_rate": 0.08608570523263666,
      "loss": 3.1129,
      "step": 86580
    },
    {
      "epoch": 139.23,
      "learning_rate": 0.0860824898017685,
      "loss": 3.0752,
      "step": 86600
    },
    {
      "epoch": 139.26,
      "learning_rate": 0.08607927437090032,
      "loss": 3.1167,
      "step": 86620
    },
    {
      "epoch": 139.29,
      "learning_rate": 0.08607605894003216,
      "loss": 3.1016,
      "step": 86640
    },
    {
      "epoch": 139.32,
      "learning_rate": 0.086072843509164,
      "loss": 3.1339,
      "step": 86660
    },
    {
      "epoch": 139.36,
      "learning_rate": 0.08606962807829582,
      "loss": 3.1137,
      "step": 86680
    },
    {
      "epoch": 139.39,
      "learning_rate": 0.08606641264742766,
      "loss": 3.1269,
      "step": 86700
    },
    {
      "epoch": 139.42,
      "learning_rate": 0.08606319721655949,
      "loss": 3.0889,
      "step": 86720
    },
    {
      "epoch": 139.45,
      "learning_rate": 0.08605998178569133,
      "loss": 3.0762,
      "step": 86740
    },
    {
      "epoch": 139.49,
      "learning_rate": 0.08605676635482316,
      "loss": 3.0941,
      "step": 86760
    },
    {
      "epoch": 139.52,
      "learning_rate": 0.08605355092395499,
      "loss": 3.1184,
      "step": 86780
    },
    {
      "epoch": 139.55,
      "learning_rate": 0.08605033549308683,
      "loss": 3.1344,
      "step": 86800
    },
    {
      "epoch": 139.58,
      "learning_rate": 0.08604712006221865,
      "loss": 3.1443,
      "step": 86820
    },
    {
      "epoch": 139.61,
      "learning_rate": 0.08604390463135049,
      "loss": 3.1236,
      "step": 86840
    },
    {
      "epoch": 139.65,
      "learning_rate": 0.08604068920048233,
      "loss": 3.1397,
      "step": 86860
    },
    {
      "epoch": 139.68,
      "learning_rate": 0.08603747376961415,
      "loss": 3.068,
      "step": 86880
    },
    {
      "epoch": 139.71,
      "learning_rate": 0.08603425833874599,
      "loss": 3.1098,
      "step": 86900
    },
    {
      "epoch": 139.74,
      "learning_rate": 0.08603104290787782,
      "loss": 3.1576,
      "step": 86920
    },
    {
      "epoch": 139.77,
      "learning_rate": 0.08602782747700964,
      "loss": 3.1524,
      "step": 86940
    },
    {
      "epoch": 139.81,
      "learning_rate": 0.08602461204614148,
      "loss": 3.1565,
      "step": 86960
    },
    {
      "epoch": 139.84,
      "learning_rate": 0.08602139661527332,
      "loss": 3.1018,
      "step": 86980
    },
    {
      "epoch": 139.87,
      "learning_rate": 0.08601818118440516,
      "loss": 3.1212,
      "step": 87000
    },
    {
      "epoch": 139.9,
      "learning_rate": 0.08601496575353698,
      "loss": 3.1197,
      "step": 87020
    },
    {
      "epoch": 139.94,
      "learning_rate": 0.0860117503226688,
      "loss": 3.128,
      "step": 87040
    },
    {
      "epoch": 139.97,
      "learning_rate": 0.08600853489180064,
      "loss": 3.1139,
      "step": 87060
    },
    {
      "epoch": 140.0,
      "learning_rate": 0.08600531946093248,
      "loss": 3.1014,
      "step": 87080
    },
    {
      "epoch": 140.0,
      "eval_accuracy": {
        "accuracy": 0.36826556790795306
      },
      "eval_loss": 3.1571896076202393,
      "eval_runtime": 2.7213,
      "eval_samples_per_second": 4726.763,
      "eval_steps_per_second": 73.861,
      "step": 87080
    },
    {
      "epoch": 140.03,
      "learning_rate": 0.08600210403006432,
      "loss": 3.1044,
      "step": 87100
    },
    {
      "epoch": 140.06,
      "learning_rate": 0.08599888859919615,
      "loss": 3.1167,
      "step": 87120
    },
    {
      "epoch": 140.1,
      "learning_rate": 0.08599567316832799,
      "loss": 3.1332,
      "step": 87140
    },
    {
      "epoch": 140.13,
      "learning_rate": 0.08599245773745981,
      "loss": 3.1268,
      "step": 87160
    },
    {
      "epoch": 140.16,
      "learning_rate": 0.08598924230659165,
      "loss": 3.1617,
      "step": 87180
    },
    {
      "epoch": 140.19,
      "learning_rate": 0.08598602687572349,
      "loss": 3.1233,
      "step": 87200
    },
    {
      "epoch": 140.23,
      "learning_rate": 0.08598281144485531,
      "loss": 3.1221,
      "step": 87220
    },
    {
      "epoch": 140.26,
      "learning_rate": 0.08597959601398715,
      "loss": 3.1007,
      "step": 87240
    },
    {
      "epoch": 140.29,
      "learning_rate": 0.08597638058311897,
      "loss": 3.098,
      "step": 87260
    },
    {
      "epoch": 140.32,
      "learning_rate": 0.0859731651522508,
      "loss": 3.0957,
      "step": 87280
    },
    {
      "epoch": 140.35,
      "learning_rate": 0.08596994972138264,
      "loss": 3.1131,
      "step": 87300
    },
    {
      "epoch": 140.39,
      "learning_rate": 0.08596673429051448,
      "loss": 3.0982,
      "step": 87320
    },
    {
      "epoch": 140.42,
      "learning_rate": 0.08596351885964632,
      "loss": 3.0784,
      "step": 87340
    },
    {
      "epoch": 140.45,
      "learning_rate": 0.08596030342877814,
      "loss": 3.0828,
      "step": 87360
    },
    {
      "epoch": 140.48,
      "learning_rate": 0.08595708799790996,
      "loss": 3.1004,
      "step": 87380
    },
    {
      "epoch": 140.51,
      "learning_rate": 0.0859538725670418,
      "loss": 3.0696,
      "step": 87400
    },
    {
      "epoch": 140.55,
      "learning_rate": 0.08595065713617364,
      "loss": 3.1063,
      "step": 87420
    },
    {
      "epoch": 140.58,
      "learning_rate": 0.08594744170530548,
      "loss": 3.1266,
      "step": 87440
    },
    {
      "epoch": 140.61,
      "learning_rate": 0.0859442262744373,
      "loss": 3.0299,
      "step": 87460
    },
    {
      "epoch": 140.64,
      "learning_rate": 0.08594101084356913,
      "loss": 3.0866,
      "step": 87480
    },
    {
      "epoch": 140.68,
      "learning_rate": 0.08593779541270097,
      "loss": 3.1046,
      "step": 87500
    },
    {
      "epoch": 140.71,
      "learning_rate": 0.0859347407533762,
      "loss": 3.0847,
      "step": 87520
    },
    {
      "epoch": 140.74,
      "learning_rate": 0.08593152532250806,
      "loss": 3.1106,
      "step": 87540
    },
    {
      "epoch": 140.77,
      "learning_rate": 0.08592830989163987,
      "loss": 3.1354,
      "step": 87560
    },
    {
      "epoch": 140.8,
      "learning_rate": 0.08592525523231512,
      "loss": 3.1158,
      "step": 87580
    },
    {
      "epoch": 140.84,
      "learning_rate": 0.08592203980144696,
      "loss": 3.1618,
      "step": 87600
    },
    {
      "epoch": 140.87,
      "learning_rate": 0.08591882437057878,
      "loss": 3.0858,
      "step": 87620
    },
    {
      "epoch": 140.9,
      "learning_rate": 0.08591560893971062,
      "loss": 3.0941,
      "step": 87640
    },
    {
      "epoch": 140.93,
      "learning_rate": 0.08591239350884244,
      "loss": 3.1212,
      "step": 87660
    },
    {
      "epoch": 140.96,
      "learning_rate": 0.08590917807797428,
      "loss": 3.1112,
      "step": 87680
    },
    {
      "epoch": 141.0,
      "learning_rate": 0.08590596264710612,
      "loss": 3.1122,
      "step": 87700
    },
    {
      "epoch": 141.0,
      "eval_accuracy": {
        "accuracy": 0.36663297830988106
      },
      "eval_loss": 3.1675937175750732,
      "eval_runtime": 2.7193,
      "eval_samples_per_second": 4730.183,
      "eval_steps_per_second": 73.915,
      "step": 87702
    },
    {
      "epoch": 141.03,
      "learning_rate": 0.08590274721623795,
      "loss": 3.0937,
      "step": 87720
    },
    {
      "epoch": 141.06,
      "learning_rate": 0.08589953178536978,
      "loss": 3.0891,
      "step": 87740
    },
    {
      "epoch": 141.09,
      "learning_rate": 0.08589631635450161,
      "loss": 3.0792,
      "step": 87760
    },
    {
      "epoch": 141.13,
      "learning_rate": 0.08589310092363345,
      "loss": 3.1134,
      "step": 87780
    },
    {
      "epoch": 141.16,
      "learning_rate": 0.08588988549276529,
      "loss": 3.1005,
      "step": 87800
    },
    {
      "epoch": 141.19,
      "learning_rate": 0.08588667006189711,
      "loss": 3.1426,
      "step": 87820
    },
    {
      "epoch": 141.22,
      "learning_rate": 0.08588345463102895,
      "loss": 3.1984,
      "step": 87840
    },
    {
      "epoch": 141.25,
      "learning_rate": 0.08588023920016077,
      "loss": 3.1645,
      "step": 87860
    },
    {
      "epoch": 141.29,
      "learning_rate": 0.08587702376929261,
      "loss": 3.0903,
      "step": 87880
    },
    {
      "epoch": 141.32,
      "learning_rate": 0.08587380833842444,
      "loss": 3.0765,
      "step": 87900
    },
    {
      "epoch": 141.35,
      "learning_rate": 0.08587059290755628,
      "loss": 3.0543,
      "step": 87920
    },
    {
      "epoch": 141.38,
      "learning_rate": 0.08586737747668811,
      "loss": 3.0497,
      "step": 87940
    },
    {
      "epoch": 141.41,
      "learning_rate": 0.08586416204581994,
      "loss": 3.108,
      "step": 87960
    },
    {
      "epoch": 141.45,
      "learning_rate": 0.08586094661495178,
      "loss": 3.1061,
      "step": 87980
    },
    {
      "epoch": 141.48,
      "learning_rate": 0.0858577311840836,
      "loss": 3.0947,
      "step": 88000
    },
    {
      "epoch": 141.51,
      "learning_rate": 0.08585451575321544,
      "loss": 3.0664,
      "step": 88020
    },
    {
      "epoch": 141.54,
      "learning_rate": 0.08585130032234728,
      "loss": 3.0782,
      "step": 88040
    },
    {
      "epoch": 141.58,
      "learning_rate": 0.0858480848914791,
      "loss": 3.095,
      "step": 88060
    },
    {
      "epoch": 141.61,
      "learning_rate": 0.08584486946061094,
      "loss": 3.057,
      "step": 88080
    },
    {
      "epoch": 141.64,
      "learning_rate": 0.08584165402974277,
      "loss": 3.0904,
      "step": 88100
    },
    {
      "epoch": 141.67,
      "learning_rate": 0.0858384385988746,
      "loss": 3.1331,
      "step": 88120
    },
    {
      "epoch": 141.7,
      "learning_rate": 0.08583522316800644,
      "loss": 3.0983,
      "step": 88140
    },
    {
      "epoch": 141.74,
      "learning_rate": 0.08583200773713826,
      "loss": 3.0839,
      "step": 88160
    },
    {
      "epoch": 141.77,
      "learning_rate": 0.08582879230627011,
      "loss": 3.0848,
      "step": 88180
    },
    {
      "epoch": 141.8,
      "learning_rate": 0.08582557687540193,
      "loss": 3.0574,
      "step": 88200
    },
    {
      "epoch": 141.83,
      "learning_rate": 0.08582236144453377,
      "loss": 3.1021,
      "step": 88220
    },
    {
      "epoch": 141.86,
      "learning_rate": 0.0858191460136656,
      "loss": 3.0756,
      "step": 88240
    },
    {
      "epoch": 141.9,
      "learning_rate": 0.08581593058279743,
      "loss": 3.0673,
      "step": 88260
    },
    {
      "epoch": 141.93,
      "learning_rate": 0.08581271515192927,
      "loss": 3.0958,
      "step": 88280
    },
    {
      "epoch": 141.96,
      "learning_rate": 0.0858094997210611,
      "loss": 3.1219,
      "step": 88300
    },
    {
      "epoch": 141.99,
      "learning_rate": 0.08580628429019294,
      "loss": 3.1106,
      "step": 88320
    },
    {
      "epoch": 142.0,
      "eval_accuracy": {
        "accuracy": 0.3656223276063127
      },
      "eval_loss": 3.189054250717163,
      "eval_runtime": 2.9335,
      "eval_samples_per_second": 4384.794,
      "eval_steps_per_second": 68.518,
      "step": 88324
    },
    {
      "epoch": 142.03,
      "learning_rate": 0.08580306885932476,
      "loss": 3.0898,
      "step": 88340
    },
    {
      "epoch": 142.06,
      "learning_rate": 0.0857998534284566,
      "loss": 3.0752,
      "step": 88360
    },
    {
      "epoch": 142.09,
      "learning_rate": 0.08579663799758844,
      "loss": 3.1046,
      "step": 88380
    },
    {
      "epoch": 142.12,
      "learning_rate": 0.08579342256672026,
      "loss": 3.0929,
      "step": 88400
    },
    {
      "epoch": 142.15,
      "learning_rate": 0.0857902071358521,
      "loss": 3.06,
      "step": 88420
    },
    {
      "epoch": 142.19,
      "learning_rate": 0.08578699170498393,
      "loss": 3.0558,
      "step": 88440
    },
    {
      "epoch": 142.22,
      "learning_rate": 0.08578377627411576,
      "loss": 3.088,
      "step": 88460
    },
    {
      "epoch": 142.25,
      "learning_rate": 0.0857805608432476,
      "loss": 3.1169,
      "step": 88480
    },
    {
      "epoch": 142.28,
      "learning_rate": 0.08577734541237943,
      "loss": 3.1082,
      "step": 88500
    },
    {
      "epoch": 142.32,
      "learning_rate": 0.08577412998151127,
      "loss": 3.1327,
      "step": 88520
    },
    {
      "epoch": 142.35,
      "learning_rate": 0.08577091455064309,
      "loss": 3.1186,
      "step": 88540
    },
    {
      "epoch": 142.38,
      "learning_rate": 0.08576769911977493,
      "loss": 3.1411,
      "step": 88560
    },
    {
      "epoch": 142.41,
      "learning_rate": 0.08576448368890675,
      "loss": 3.1314,
      "step": 88580
    },
    {
      "epoch": 142.44,
      "learning_rate": 0.08576126825803858,
      "loss": 3.1043,
      "step": 88600
    },
    {
      "epoch": 142.48,
      "learning_rate": 0.08575805282717043,
      "loss": 3.0648,
      "step": 88620
    },
    {
      "epoch": 142.51,
      "learning_rate": 0.08575483739630226,
      "loss": 3.1129,
      "step": 88640
    },
    {
      "epoch": 142.54,
      "learning_rate": 0.0857516219654341,
      "loss": 3.121,
      "step": 88660
    },
    {
      "epoch": 142.57,
      "learning_rate": 0.08574840653456592,
      "loss": 3.0949,
      "step": 88680
    },
    {
      "epoch": 142.6,
      "learning_rate": 0.08574519110369774,
      "loss": 3.1023,
      "step": 88700
    },
    {
      "epoch": 142.64,
      "learning_rate": 0.0857419756728296,
      "loss": 3.1071,
      "step": 88720
    },
    {
      "epoch": 142.67,
      "learning_rate": 0.08573876024196142,
      "loss": 3.0887,
      "step": 88740
    },
    {
      "epoch": 142.7,
      "learning_rate": 0.08573554481109326,
      "loss": 3.0534,
      "step": 88760
    },
    {
      "epoch": 142.73,
      "learning_rate": 0.08573232938022508,
      "loss": 3.0891,
      "step": 88780
    },
    {
      "epoch": 142.77,
      "learning_rate": 0.08572911394935691,
      "loss": 3.076,
      "step": 88800
    },
    {
      "epoch": 142.8,
      "learning_rate": 0.08572589851848876,
      "loss": 3.1362,
      "step": 88820
    },
    {
      "epoch": 142.83,
      "learning_rate": 0.08572268308762059,
      "loss": 3.1075,
      "step": 88840
    },
    {
      "epoch": 142.86,
      "learning_rate": 0.08571946765675242,
      "loss": 3.098,
      "step": 88860
    },
    {
      "epoch": 142.89,
      "learning_rate": 0.08571625222588425,
      "loss": 3.1288,
      "step": 88880
    },
    {
      "epoch": 142.93,
      "learning_rate": 0.08571303679501609,
      "loss": 3.1374,
      "step": 88900
    },
    {
      "epoch": 142.96,
      "learning_rate": 0.08570982136414791,
      "loss": 3.1023,
      "step": 88920
    },
    {
      "epoch": 142.99,
      "learning_rate": 0.08570660593327974,
      "loss": 3.0742,
      "step": 88940
    },
    {
      "epoch": 143.0,
      "eval_accuracy": {
        "accuracy": 0.36577781232993856
      },
      "eval_loss": 3.214564085006714,
      "eval_runtime": 2.7912,
      "eval_samples_per_second": 4608.48,
      "eval_steps_per_second": 72.013,
      "step": 88946
    },
    {
      "epoch": 143.02,
      "learning_rate": 0.08570339050241159,
      "loss": 3.1157,
      "step": 88960
    },
    {
      "epoch": 143.05,
      "learning_rate": 0.08570017507154341,
      "loss": 3.1503,
      "step": 88980
    },
    {
      "epoch": 143.09,
      "learning_rate": 0.08569695964067525,
      "loss": 3.0936,
      "step": 89000
    },
    {
      "epoch": 143.12,
      "learning_rate": 0.08569374420980708,
      "loss": 3.1203,
      "step": 89020
    },
    {
      "epoch": 143.15,
      "learning_rate": 0.0856905287789389,
      "loss": 3.0669,
      "step": 89040
    },
    {
      "epoch": 143.18,
      "learning_rate": 0.08568731334807075,
      "loss": 3.0585,
      "step": 89060
    },
    {
      "epoch": 143.22,
      "learning_rate": 0.08568409791720258,
      "loss": 3.0931,
      "step": 89080
    },
    {
      "epoch": 143.25,
      "learning_rate": 0.08568088248633442,
      "loss": 3.0781,
      "step": 89100
    },
    {
      "epoch": 143.28,
      "learning_rate": 0.08567766705546624,
      "loss": 3.0756,
      "step": 89120
    },
    {
      "epoch": 143.31,
      "learning_rate": 0.08567445162459807,
      "loss": 3.0713,
      "step": 89140
    },
    {
      "epoch": 143.34,
      "learning_rate": 0.08567123619372992,
      "loss": 3.0553,
      "step": 89160
    },
    {
      "epoch": 143.38,
      "learning_rate": 0.08566802076286174,
      "loss": 3.0867,
      "step": 89180
    },
    {
      "epoch": 143.41,
      "learning_rate": 0.08566480533199358,
      "loss": 3.0988,
      "step": 89200
    },
    {
      "epoch": 143.44,
      "learning_rate": 0.0856615899011254,
      "loss": 3.0894,
      "step": 89220
    },
    {
      "epoch": 143.47,
      "learning_rate": 0.08565837447025723,
      "loss": 3.1139,
      "step": 89240
    },
    {
      "epoch": 143.5,
      "learning_rate": 0.08565515903938907,
      "loss": 3.0908,
      "step": 89260
    },
    {
      "epoch": 143.54,
      "learning_rate": 0.0856519436085209,
      "loss": 3.104,
      "step": 89280
    },
    {
      "epoch": 143.57,
      "learning_rate": 0.08564872817765275,
      "loss": 3.1375,
      "step": 89300
    },
    {
      "epoch": 143.6,
      "learning_rate": 0.08564551274678457,
      "loss": 3.1198,
      "step": 89320
    },
    {
      "epoch": 143.63,
      "learning_rate": 0.0856422973159164,
      "loss": 3.0834,
      "step": 89340
    },
    {
      "epoch": 143.67,
      "learning_rate": 0.08563908188504823,
      "loss": 3.0884,
      "step": 89360
    },
    {
      "epoch": 143.7,
      "learning_rate": 0.08563586645418006,
      "loss": 3.0494,
      "step": 89380
    },
    {
      "epoch": 143.73,
      "learning_rate": 0.08563265102331191,
      "loss": 3.1082,
      "step": 89400
    },
    {
      "epoch": 143.76,
      "learning_rate": 0.08562943559244374,
      "loss": 3.1169,
      "step": 89420
    },
    {
      "epoch": 143.79,
      "learning_rate": 0.08562622016157558,
      "loss": 3.0872,
      "step": 89440
    },
    {
      "epoch": 143.83,
      "learning_rate": 0.0856230047307074,
      "loss": 3.0895,
      "step": 89460
    },
    {
      "epoch": 143.86,
      "learning_rate": 0.08561978929983922,
      "loss": 3.1113,
      "step": 89480
    },
    {
      "epoch": 143.89,
      "learning_rate": 0.08561657386897108,
      "loss": 3.0675,
      "step": 89500
    },
    {
      "epoch": 143.92,
      "learning_rate": 0.0856133584381029,
      "loss": 3.0886,
      "step": 89520
    },
    {
      "epoch": 143.95,
      "learning_rate": 0.08561014300723474,
      "loss": 3.0649,
      "step": 89540
    },
    {
      "epoch": 143.99,
      "learning_rate": 0.08560692757636656,
      "loss": 3.0772,
      "step": 89560
    },
    {
      "epoch": 144.0,
      "eval_accuracy": {
        "accuracy": 0.36826556790795306
      },
      "eval_loss": 3.163391351699829,
      "eval_runtime": 3.1976,
      "eval_samples_per_second": 4022.712,
      "eval_steps_per_second": 62.86,
      "step": 89568
    },
    {
      "epoch": 144.02,
      "learning_rate": 0.08560371214549839,
      "loss": 3.0777,
      "step": 89580
    },
    {
      "epoch": 144.05,
      "learning_rate": 0.08560049671463024,
      "loss": 3.0402,
      "step": 89600
    },
    {
      "epoch": 144.08,
      "learning_rate": 0.08559728128376205,
      "loss": 3.0508,
      "step": 89620
    },
    {
      "epoch": 144.12,
      "learning_rate": 0.0855940658528939,
      "loss": 3.0382,
      "step": 89640
    },
    {
      "epoch": 144.15,
      "learning_rate": 0.08559085042202573,
      "loss": 3.0627,
      "step": 89660
    },
    {
      "epoch": 144.18,
      "learning_rate": 0.08558763499115755,
      "loss": 3.0757,
      "step": 89680
    },
    {
      "epoch": 144.21,
      "learning_rate": 0.0855844195602894,
      "loss": 3.0787,
      "step": 89700
    },
    {
      "epoch": 144.24,
      "learning_rate": 0.08558120412942122,
      "loss": 3.0885,
      "step": 89720
    },
    {
      "epoch": 144.28,
      "learning_rate": 0.08557798869855307,
      "loss": 3.1363,
      "step": 89740
    },
    {
      "epoch": 144.31,
      "learning_rate": 0.0855747732676849,
      "loss": 3.1419,
      "step": 89760
    },
    {
      "epoch": 144.34,
      "learning_rate": 0.08557155783681672,
      "loss": 3.134,
      "step": 89780
    },
    {
      "epoch": 144.37,
      "learning_rate": 0.08556834240594856,
      "loss": 3.0686,
      "step": 89800
    },
    {
      "epoch": 144.41,
      "learning_rate": 0.08556512697508038,
      "loss": 3.0802,
      "step": 89820
    },
    {
      "epoch": 144.44,
      "learning_rate": 0.08556191154421224,
      "loss": 3.1086,
      "step": 89840
    },
    {
      "epoch": 144.47,
      "learning_rate": 0.08555869611334406,
      "loss": 3.1086,
      "step": 89860
    },
    {
      "epoch": 144.5,
      "learning_rate": 0.08555548068247588,
      "loss": 3.0808,
      "step": 89880
    },
    {
      "epoch": 144.53,
      "learning_rate": 0.08555226525160772,
      "loss": 3.0557,
      "step": 89900
    },
    {
      "epoch": 144.57,
      "learning_rate": 0.08554904982073955,
      "loss": 3.1068,
      "step": 89920
    },
    {
      "epoch": 144.6,
      "learning_rate": 0.0855458343898714,
      "loss": 3.087,
      "step": 89940
    },
    {
      "epoch": 144.63,
      "learning_rate": 0.08554261895900321,
      "loss": 3.1124,
      "step": 89960
    },
    {
      "epoch": 144.66,
      "learning_rate": 0.08553940352813505,
      "loss": 3.0783,
      "step": 89980
    },
    {
      "epoch": 144.69,
      "learning_rate": 0.08553618809726689,
      "loss": 3.075,
      "step": 90000
    },
    {
      "epoch": 144.73,
      "learning_rate": 0.08553297266639871,
      "loss": 3.1054,
      "step": 90020
    },
    {
      "epoch": 144.76,
      "learning_rate": 0.08552975723553055,
      "loss": 3.0592,
      "step": 90040
    },
    {
      "epoch": 144.79,
      "learning_rate": 0.08552654180466238,
      "loss": 3.0776,
      "step": 90060
    },
    {
      "epoch": 144.82,
      "learning_rate": 0.08552332637379423,
      "loss": 3.0507,
      "step": 90080
    },
    {
      "epoch": 144.86,
      "learning_rate": 0.08552011094292605,
      "loss": 3.0698,
      "step": 90100
    },
    {
      "epoch": 144.89,
      "learning_rate": 0.08551689551205788,
      "loss": 3.098,
      "step": 90120
    },
    {
      "epoch": 144.92,
      "learning_rate": 0.08551368008118972,
      "loss": 3.1231,
      "step": 90140
    },
    {
      "epoch": 144.95,
      "learning_rate": 0.08551046465032154,
      "loss": 3.0717,
      "step": 90160
    },
    {
      "epoch": 144.98,
      "learning_rate": 0.0855072492194534,
      "loss": 3.06,
      "step": 90180
    },
    {
      "epoch": 145.0,
      "eval_accuracy": {
        "accuracy": 0.3599471351939672
      },
      "eval_loss": 3.1678390502929688,
      "eval_runtime": 2.8972,
      "eval_samples_per_second": 4439.761,
      "eval_steps_per_second": 69.377,
      "step": 90190
    },
    {
      "epoch": 145.02,
      "learning_rate": 0.08550403378858522,
      "loss": 3.0867,
      "step": 90200
    },
    {
      "epoch": 145.05,
      "learning_rate": 0.08550081835771704,
      "loss": 3.0784,
      "step": 90220
    },
    {
      "epoch": 145.08,
      "learning_rate": 0.08549760292684888,
      "loss": 3.116,
      "step": 90240
    },
    {
      "epoch": 145.11,
      "learning_rate": 0.0854943874959807,
      "loss": 3.1068,
      "step": 90260
    },
    {
      "epoch": 145.14,
      "learning_rate": 0.08549117206511256,
      "loss": 3.067,
      "step": 90280
    },
    {
      "epoch": 145.18,
      "learning_rate": 0.08548795663424437,
      "loss": 3.0727,
      "step": 90300
    },
    {
      "epoch": 145.21,
      "learning_rate": 0.08548474120337621,
      "loss": 3.0555,
      "step": 90320
    },
    {
      "epoch": 145.24,
      "learning_rate": 0.08548152577250805,
      "loss": 3.0455,
      "step": 90340
    },
    {
      "epoch": 145.27,
      "learning_rate": 0.08547831034163987,
      "loss": 3.0346,
      "step": 90360
    },
    {
      "epoch": 145.31,
      "learning_rate": 0.08547509491077171,
      "loss": 3.0805,
      "step": 90380
    },
    {
      "epoch": 145.34,
      "learning_rate": 0.08547187947990353,
      "loss": 3.1093,
      "step": 90400
    },
    {
      "epoch": 145.37,
      "learning_rate": 0.08546866404903537,
      "loss": 3.108,
      "step": 90420
    },
    {
      "epoch": 145.4,
      "learning_rate": 0.08546544861816721,
      "loss": 3.1381,
      "step": 90440
    },
    {
      "epoch": 145.43,
      "learning_rate": 0.08546223318729904,
      "loss": 3.0987,
      "step": 90460
    },
    {
      "epoch": 145.47,
      "learning_rate": 0.08545901775643087,
      "loss": 3.1019,
      "step": 90480
    },
    {
      "epoch": 145.5,
      "learning_rate": 0.0854558023255627,
      "loss": 3.0729,
      "step": 90500
    },
    {
      "epoch": 145.53,
      "learning_rate": 0.08545258689469454,
      "loss": 3.0566,
      "step": 90520
    },
    {
      "epoch": 145.56,
      "learning_rate": 0.08544937146382638,
      "loss": 3.0521,
      "step": 90540
    },
    {
      "epoch": 145.59,
      "learning_rate": 0.0854461560329582,
      "loss": 3.0958,
      "step": 90560
    },
    {
      "epoch": 145.63,
      "learning_rate": 0.08544294060209004,
      "loss": 3.1088,
      "step": 90580
    },
    {
      "epoch": 145.66,
      "learning_rate": 0.08543972517122186,
      "loss": 3.0908,
      "step": 90600
    },
    {
      "epoch": 145.69,
      "learning_rate": 0.08543667051189711,
      "loss": 3.1403,
      "step": 90620
    },
    {
      "epoch": 145.72,
      "learning_rate": 0.08543345508102894,
      "loss": 3.0981,
      "step": 90640
    },
    {
      "epoch": 145.76,
      "learning_rate": 0.08543023965016078,
      "loss": 3.0848,
      "step": 90660
    },
    {
      "epoch": 145.79,
      "learning_rate": 0.08542702421929262,
      "loss": 3.1178,
      "step": 90680
    },
    {
      "epoch": 145.82,
      "learning_rate": 0.08542380878842444,
      "loss": 3.0853,
      "step": 90700
    },
    {
      "epoch": 145.85,
      "learning_rate": 0.08542059335755628,
      "loss": 3.0915,
      "step": 90720
    },
    {
      "epoch": 145.88,
      "learning_rate": 0.0854173779266881,
      "loss": 3.0935,
      "step": 90740
    },
    {
      "epoch": 145.92,
      "learning_rate": 0.08541416249581994,
      "loss": 3.097,
      "step": 90760
    },
    {
      "epoch": 145.95,
      "learning_rate": 0.08541094706495178,
      "loss": 3.0884,
      "step": 90780
    },
    {
      "epoch": 145.98,
      "learning_rate": 0.0854077316340836,
      "loss": 3.0837,
      "step": 90800
    },
    {
      "epoch": 146.0,
      "eval_accuracy": {
        "accuracy": 0.36826556790795306
      },
      "eval_loss": 3.189481496810913,
      "eval_runtime": 2.5789,
      "eval_samples_per_second": 4987.794,
      "eval_steps_per_second": 77.94,
      "step": 90812
    },
    {
      "epoch": 146.01,
      "learning_rate": 0.08540451620321544,
      "loss": 3.0438,
      "step": 90820
    },
    {
      "epoch": 146.05,
      "learning_rate": 0.08540130077234727,
      "loss": 3.0611,
      "step": 90840
    },
    {
      "epoch": 146.08,
      "learning_rate": 0.08539808534147911,
      "loss": 3.0957,
      "step": 90860
    },
    {
      "epoch": 146.11,
      "learning_rate": 0.08539486991061095,
      "loss": 3.1075,
      "step": 90880
    },
    {
      "epoch": 146.14,
      "learning_rate": 0.08539165447974277,
      "loss": 3.0899,
      "step": 90900
    },
    {
      "epoch": 146.17,
      "learning_rate": 0.08538843904887461,
      "loss": 3.115,
      "step": 90920
    },
    {
      "epoch": 146.21,
      "learning_rate": 0.08538522361800643,
      "loss": 3.1112,
      "step": 90940
    },
    {
      "epoch": 146.24,
      "learning_rate": 0.08538200818713827,
      "loss": 3.098,
      "step": 90960
    },
    {
      "epoch": 146.27,
      "learning_rate": 0.0853787927562701,
      "loss": 3.0481,
      "step": 90980
    },
    {
      "epoch": 146.3,
      "learning_rate": 0.08537557732540192,
      "loss": 3.0773,
      "step": 91000
    },
    {
      "epoch": 146.33,
      "learning_rate": 0.08537236189453377,
      "loss": 3.1093,
      "step": 91020
    },
    {
      "epoch": 146.37,
      "learning_rate": 0.0853691464636656,
      "loss": 3.1114,
      "step": 91040
    },
    {
      "epoch": 146.4,
      "learning_rate": 0.08536593103279744,
      "loss": 3.082,
      "step": 91060
    },
    {
      "epoch": 146.43,
      "learning_rate": 0.08536271560192926,
      "loss": 3.0849,
      "step": 91080
    },
    {
      "epoch": 146.46,
      "learning_rate": 0.0853595001710611,
      "loss": 3.0636,
      "step": 91100
    },
    {
      "epoch": 146.5,
      "learning_rate": 0.08535628474019294,
      "loss": 3.0992,
      "step": 91120
    },
    {
      "epoch": 146.53,
      "learning_rate": 0.08535306930932476,
      "loss": 3.104,
      "step": 91140
    },
    {
      "epoch": 146.56,
      "learning_rate": 0.0853498538784566,
      "loss": 3.0954,
      "step": 91160
    },
    {
      "epoch": 146.59,
      "learning_rate": 0.08534663844758843,
      "loss": 3.1049,
      "step": 91180
    },
    {
      "epoch": 146.62,
      "learning_rate": 0.08534342301672027,
      "loss": 3.0709,
      "step": 91200
    },
    {
      "epoch": 146.66,
      "learning_rate": 0.0853402075858521,
      "loss": 3.1156,
      "step": 91220
    },
    {
      "epoch": 146.69,
      "learning_rate": 0.08533699215498393,
      "loss": 3.1625,
      "step": 91240
    },
    {
      "epoch": 146.72,
      "learning_rate": 0.08533377672411577,
      "loss": 3.1004,
      "step": 91260
    },
    {
      "epoch": 146.75,
      "learning_rate": 0.08533056129324759,
      "loss": 3.0826,
      "step": 91280
    },
    {
      "epoch": 146.78,
      "learning_rate": 0.08532734586237943,
      "loss": 3.106,
      "step": 91300
    },
    {
      "epoch": 146.82,
      "learning_rate": 0.08532413043151126,
      "loss": 3.0616,
      "step": 91320
    },
    {
      "epoch": 146.85,
      "learning_rate": 0.08532091500064308,
      "loss": 3.0847,
      "step": 91340
    },
    {
      "epoch": 146.88,
      "learning_rate": 0.08531769956977493,
      "loss": 3.117,
      "step": 91360
    },
    {
      "epoch": 146.91,
      "learning_rate": 0.08531448413890676,
      "loss": 3.1092,
      "step": 91380
    },
    {
      "epoch": 146.95,
      "learning_rate": 0.0853112687080386,
      "loss": 3.0501,
      "step": 91400
    },
    {
      "epoch": 146.98,
      "learning_rate": 0.08530805327717042,
      "loss": 3.0964,
      "step": 91420
    },
    {
      "epoch": 147.0,
      "eval_accuracy": {
        "accuracy": 0.361890694239291
      },
      "eval_loss": 3.197568893432617,
      "eval_runtime": 2.7246,
      "eval_samples_per_second": 4720.978,
      "eval_steps_per_second": 73.771,
      "step": 91434
    },
    {
      "epoch": 147.01,
      "learning_rate": 0.08530483784630224,
      "loss": 3.0772,
      "step": 91440
    },
    {
      "epoch": 147.04,
      "learning_rate": 0.0853016224154341,
      "loss": 3.0882,
      "step": 91460
    },
    {
      "epoch": 147.07,
      "learning_rate": 0.08529840698456592,
      "loss": 3.0515,
      "step": 91480
    },
    {
      "epoch": 147.11,
      "learning_rate": 0.08529519155369776,
      "loss": 3.0925,
      "step": 91500
    },
    {
      "epoch": 147.14,
      "learning_rate": 0.08529197612282959,
      "loss": 3.0917,
      "step": 91520
    },
    {
      "epoch": 147.17,
      "learning_rate": 0.08528876069196141,
      "loss": 3.1314,
      "step": 91540
    },
    {
      "epoch": 147.2,
      "learning_rate": 0.08528554526109326,
      "loss": 3.1162,
      "step": 91560
    },
    {
      "epoch": 147.23,
      "learning_rate": 0.08528232983022509,
      "loss": 3.0883,
      "step": 91580
    },
    {
      "epoch": 147.27,
      "learning_rate": 0.08527911439935693,
      "loss": 3.0706,
      "step": 91600
    },
    {
      "epoch": 147.3,
      "learning_rate": 0.08527589896848875,
      "loss": 3.1256,
      "step": 91620
    },
    {
      "epoch": 147.33,
      "learning_rate": 0.08527268353762059,
      "loss": 3.0932,
      "step": 91640
    },
    {
      "epoch": 147.36,
      "learning_rate": 0.08526946810675241,
      "loss": 3.0508,
      "step": 91660
    },
    {
      "epoch": 147.4,
      "learning_rate": 0.08526625267588424,
      "loss": 3.0979,
      "step": 91680
    },
    {
      "epoch": 147.43,
      "learning_rate": 0.08526303724501609,
      "loss": 3.0501,
      "step": 91700
    },
    {
      "epoch": 147.46,
      "learning_rate": 0.08525982181414792,
      "loss": 3.0583,
      "step": 91720
    },
    {
      "epoch": 147.49,
      "learning_rate": 0.08525660638327975,
      "loss": 3.1016,
      "step": 91740
    },
    {
      "epoch": 147.52,
      "learning_rate": 0.08525339095241158,
      "loss": 3.0341,
      "step": 91760
    },
    {
      "epoch": 147.56,
      "learning_rate": 0.0852501755215434,
      "loss": 3.0783,
      "step": 91780
    },
    {
      "epoch": 147.59,
      "learning_rate": 0.08524696009067526,
      "loss": 3.053,
      "step": 91800
    },
    {
      "epoch": 147.62,
      "learning_rate": 0.08524374465980708,
      "loss": 3.0722,
      "step": 91820
    },
    {
      "epoch": 147.65,
      "learning_rate": 0.08524052922893892,
      "loss": 3.0491,
      "step": 91840
    },
    {
      "epoch": 147.68,
      "learning_rate": 0.08523731379807074,
      "loss": 3.0634,
      "step": 91860
    },
    {
      "epoch": 147.72,
      "learning_rate": 0.08523409836720257,
      "loss": 3.0588,
      "step": 91880
    },
    {
      "epoch": 147.75,
      "learning_rate": 0.08523088293633442,
      "loss": 3.1245,
      "step": 91900
    },
    {
      "epoch": 147.78,
      "learning_rate": 0.08522766750546625,
      "loss": 3.095,
      "step": 91920
    },
    {
      "epoch": 147.81,
      "learning_rate": 0.08522445207459808,
      "loss": 3.0758,
      "step": 91940
    },
    {
      "epoch": 147.85,
      "learning_rate": 0.08522123664372991,
      "loss": 3.0824,
      "step": 91960
    },
    {
      "epoch": 147.88,
      "learning_rate": 0.08521802121286173,
      "loss": 3.0407,
      "step": 91980
    },
    {
      "epoch": 147.91,
      "learning_rate": 0.08521480578199357,
      "loss": 3.0338,
      "step": 92000
    },
    {
      "epoch": 147.94,
      "learning_rate": 0.0852115903511254,
      "loss": 3.0296,
      "step": 92020
    },
    {
      "epoch": 147.97,
      "learning_rate": 0.08520837492025725,
      "loss": 3.0618,
      "step": 92040
    },
    {
      "epoch": 148.0,
      "eval_accuracy": {
        "accuracy": 0.36103552825934854
      },
      "eval_loss": 3.212923526763916,
      "eval_runtime": 2.8804,
      "eval_samples_per_second": 4465.696,
      "eval_steps_per_second": 69.782,
      "step": 92056
    },
    {
      "epoch": 148.01,
      "learning_rate": 0.08520515948938907,
      "loss": 3.0848,
      "step": 92060
    },
    {
      "epoch": 148.04,
      "learning_rate": 0.0852019440585209,
      "loss": 3.1452,
      "step": 92080
    },
    {
      "epoch": 148.07,
      "learning_rate": 0.08519872862765274,
      "loss": 3.1186,
      "step": 92100
    },
    {
      "epoch": 148.1,
      "learning_rate": 0.08519551319678456,
      "loss": 3.0566,
      "step": 92120
    },
    {
      "epoch": 148.14,
      "learning_rate": 0.08519229776591641,
      "loss": 3.0368,
      "step": 92140
    },
    {
      "epoch": 148.17,
      "learning_rate": 0.08518908233504824,
      "loss": 3.0514,
      "step": 92160
    },
    {
      "epoch": 148.2,
      "learning_rate": 0.08518586690418006,
      "loss": 3.0269,
      "step": 92180
    },
    {
      "epoch": 148.23,
      "learning_rate": 0.0851826514733119,
      "loss": 3.06,
      "step": 92200
    },
    {
      "epoch": 148.26,
      "learning_rate": 0.08517943604244373,
      "loss": 3.0309,
      "step": 92220
    },
    {
      "epoch": 148.3,
      "learning_rate": 0.08517622061157558,
      "loss": 3.0837,
      "step": 92240
    },
    {
      "epoch": 148.33,
      "learning_rate": 0.0851730051807074,
      "loss": 3.1073,
      "step": 92260
    },
    {
      "epoch": 148.36,
      "learning_rate": 0.08516978974983924,
      "loss": 3.0912,
      "step": 92280
    },
    {
      "epoch": 148.39,
      "learning_rate": 0.08516657431897107,
      "loss": 3.0788,
      "step": 92300
    },
    {
      "epoch": 148.42,
      "learning_rate": 0.08516335888810289,
      "loss": 3.113,
      "step": 92320
    },
    {
      "epoch": 148.46,
      "learning_rate": 0.08516014345723474,
      "loss": 3.0757,
      "step": 92340
    },
    {
      "epoch": 148.49,
      "learning_rate": 0.08515692802636655,
      "loss": 3.0722,
      "step": 92360
    },
    {
      "epoch": 148.52,
      "learning_rate": 0.08515371259549841,
      "loss": 3.082,
      "step": 92380
    },
    {
      "epoch": 148.55,
      "learning_rate": 0.08515049716463023,
      "loss": 3.1295,
      "step": 92400
    },
    {
      "epoch": 148.59,
      "learning_rate": 0.08514728173376206,
      "loss": 3.1094,
      "step": 92420
    },
    {
      "epoch": 148.62,
      "learning_rate": 0.0851440663028939,
      "loss": 3.1006,
      "step": 92440
    },
    {
      "epoch": 148.65,
      "learning_rate": 0.08514085087202572,
      "loss": 3.0849,
      "step": 92460
    },
    {
      "epoch": 148.68,
      "learning_rate": 0.08513763544115757,
      "loss": 3.0833,
      "step": 92480
    },
    {
      "epoch": 148.71,
      "learning_rate": 0.0851344200102894,
      "loss": 3.0946,
      "step": 92500
    },
    {
      "epoch": 148.75,
      "learning_rate": 0.08513120457942122,
      "loss": 3.0972,
      "step": 92520
    },
    {
      "epoch": 148.78,
      "learning_rate": 0.08512798914855306,
      "loss": 3.0932,
      "step": 92540
    },
    {
      "epoch": 148.81,
      "learning_rate": 0.08512477371768488,
      "loss": 3.081,
      "step": 92560
    },
    {
      "epoch": 148.84,
      "learning_rate": 0.08512155828681674,
      "loss": 3.0442,
      "step": 92580
    },
    {
      "epoch": 148.87,
      "learning_rate": 0.08511834285594856,
      "loss": 3.0777,
      "step": 92600
    },
    {
      "epoch": 148.91,
      "learning_rate": 0.08511512742508039,
      "loss": 3.0755,
      "step": 92620
    },
    {
      "epoch": 148.94,
      "learning_rate": 0.08511191199421222,
      "loss": 3.0821,
      "step": 92640
    },
    {
      "epoch": 148.97,
      "learning_rate": 0.08510869656334405,
      "loss": 3.1092,
      "step": 92660
    },
    {
      "epoch": 149.0,
      "eval_accuracy": {
        "accuracy": 0.3736297908730467
      },
      "eval_loss": 3.103736162185669,
      "eval_runtime": 3.1225,
      "eval_samples_per_second": 4119.518,
      "eval_steps_per_second": 64.372,
      "step": 92678
    },
    {
      "epoch": 149.0,
      "learning_rate": 0.0851054811324759,
      "loss": 3.084,
      "step": 92680
    },
    {
      "epoch": 149.04,
      "learning_rate": 0.08510226570160771,
      "loss": 3.0361,
      "step": 92700
    },
    {
      "epoch": 149.07,
      "learning_rate": 0.08509905027073955,
      "loss": 3.0617,
      "step": 92720
    },
    {
      "epoch": 149.1,
      "learning_rate": 0.08509583483987139,
      "loss": 3.0993,
      "step": 92740
    },
    {
      "epoch": 149.13,
      "learning_rate": 0.08509261940900321,
      "loss": 3.0499,
      "step": 92760
    },
    {
      "epoch": 149.16,
      "learning_rate": 0.08508940397813505,
      "loss": 3.0913,
      "step": 92780
    },
    {
      "epoch": 149.2,
      "learning_rate": 0.08508618854726688,
      "loss": 3.0918,
      "step": 92800
    },
    {
      "epoch": 149.23,
      "learning_rate": 0.08508297311639872,
      "loss": 3.1004,
      "step": 92820
    },
    {
      "epoch": 149.26,
      "learning_rate": 0.08507975768553055,
      "loss": 3.0978,
      "step": 92840
    },
    {
      "epoch": 149.29,
      "learning_rate": 0.08507654225466238,
      "loss": 3.0885,
      "step": 92860
    },
    {
      "epoch": 149.32,
      "learning_rate": 0.08507332682379422,
      "loss": 3.1164,
      "step": 92880
    },
    {
      "epoch": 149.36,
      "learning_rate": 0.08507011139292604,
      "loss": 3.0999,
      "step": 92900
    },
    {
      "epoch": 149.39,
      "learning_rate": 0.0850668959620579,
      "loss": 3.0918,
      "step": 92920
    },
    {
      "epoch": 149.42,
      "learning_rate": 0.08506368053118972,
      "loss": 3.0898,
      "step": 92940
    },
    {
      "epoch": 149.45,
      "learning_rate": 0.08506046510032154,
      "loss": 3.0916,
      "step": 92960
    },
    {
      "epoch": 149.49,
      "learning_rate": 0.08505724966945338,
      "loss": 3.1314,
      "step": 92980
    },
    {
      "epoch": 149.52,
      "learning_rate": 0.08505403423858521,
      "loss": 3.1421,
      "step": 93000
    },
    {
      "epoch": 149.55,
      "learning_rate": 0.08505081880771706,
      "loss": 3.1083,
      "step": 93020
    },
    {
      "epoch": 149.58,
      "learning_rate": 0.08504760337684887,
      "loss": 3.104,
      "step": 93040
    },
    {
      "epoch": 149.61,
      "learning_rate": 0.08504438794598071,
      "loss": 3.1044,
      "step": 93060
    },
    {
      "epoch": 149.65,
      "learning_rate": 0.08504117251511255,
      "loss": 3.0768,
      "step": 93080
    },
    {
      "epoch": 149.68,
      "learning_rate": 0.08503795708424437,
      "loss": 3.1089,
      "step": 93100
    },
    {
      "epoch": 149.71,
      "learning_rate": 0.08503474165337621,
      "loss": 3.1215,
      "step": 93120
    },
    {
      "epoch": 149.74,
      "learning_rate": 0.08503152622250804,
      "loss": 3.0824,
      "step": 93140
    },
    {
      "epoch": 149.77,
      "learning_rate": 0.08502831079163987,
      "loss": 3.0882,
      "step": 93160
    },
    {
      "epoch": 149.81,
      "learning_rate": 0.08502509536077171,
      "loss": 3.0555,
      "step": 93180
    },
    {
      "epoch": 149.84,
      "learning_rate": 0.08502187992990354,
      "loss": 3.1057,
      "step": 93200
    },
    {
      "epoch": 149.87,
      "learning_rate": 0.08501866449903538,
      "loss": 3.1036,
      "step": 93220
    },
    {
      "epoch": 149.9,
      "learning_rate": 0.0850154490681672,
      "loss": 3.0666,
      "step": 93240
    },
    {
      "epoch": 149.94,
      "learning_rate": 0.08501223363729904,
      "loss": 3.039,
      "step": 93260
    },
    {
      "epoch": 149.97,
      "learning_rate": 0.08500901820643088,
      "loss": 3.0532,
      "step": 93280
    },
    {
      "epoch": 150.0,
      "learning_rate": 0.0850058027755627,
      "loss": 3.0797,
      "step": 93300
    },
    {
      "epoch": 150.0,
      "eval_accuracy": {
        "accuracy": 0.3702868693150898
      },
      "eval_loss": 3.2073378562927246,
      "eval_runtime": 2.7917,
      "eval_samples_per_second": 4607.517,
      "eval_steps_per_second": 71.998,
      "step": 93300
    },
    {
      "epoch": 150.03,
      "learning_rate": 0.08500258734469454,
      "loss": 3.1105,
      "step": 93320
    },
    {
      "epoch": 150.06,
      "learning_rate": 0.08499937191382637,
      "loss": 3.0895,
      "step": 93340
    },
    {
      "epoch": 150.1,
      "learning_rate": 0.0849961564829582,
      "loss": 3.0699,
      "step": 93360
    },
    {
      "epoch": 150.13,
      "learning_rate": 0.08499294105209003,
      "loss": 3.0807,
      "step": 93380
    },
    {
      "epoch": 150.16,
      "learning_rate": 0.08498972562122187,
      "loss": 3.0815,
      "step": 93400
    },
    {
      "epoch": 150.19,
      "learning_rate": 0.0849865101903537,
      "loss": 3.0663,
      "step": 93420
    },
    {
      "epoch": 150.23,
      "learning_rate": 0.08498329475948553,
      "loss": 3.0796,
      "step": 93440
    },
    {
      "epoch": 150.26,
      "learning_rate": 0.08498007932861737,
      "loss": 3.0491,
      "step": 93460
    },
    {
      "epoch": 150.29,
      "learning_rate": 0.0849768638977492,
      "loss": 3.0688,
      "step": 93480
    },
    {
      "epoch": 150.32,
      "learning_rate": 0.08497364846688103,
      "loss": 3.0331,
      "step": 93500
    },
    {
      "epoch": 150.35,
      "learning_rate": 0.08497043303601287,
      "loss": 3.0493,
      "step": 93520
    },
    {
      "epoch": 150.39,
      "learning_rate": 0.0849672176051447,
      "loss": 3.0616,
      "step": 93540
    },
    {
      "epoch": 150.42,
      "learning_rate": 0.08496400217427653,
      "loss": 3.0833,
      "step": 93560
    },
    {
      "epoch": 150.45,
      "learning_rate": 0.08496078674340836,
      "loss": 3.1026,
      "step": 93580
    },
    {
      "epoch": 150.48,
      "learning_rate": 0.0849575713125402,
      "loss": 3.1232,
      "step": 93600
    },
    {
      "epoch": 150.51,
      "learning_rate": 0.08495435588167204,
      "loss": 3.0861,
      "step": 93620
    },
    {
      "epoch": 150.55,
      "learning_rate": 0.08495114045080386,
      "loss": 3.0973,
      "step": 93640
    },
    {
      "epoch": 150.58,
      "learning_rate": 0.0849479250199357,
      "loss": 3.0951,
      "step": 93660
    },
    {
      "epoch": 150.61,
      "learning_rate": 0.08494470958906752,
      "loss": 3.1102,
      "step": 93680
    },
    {
      "epoch": 150.64,
      "learning_rate": 0.08494149415819936,
      "loss": 3.0418,
      "step": 93700
    },
    {
      "epoch": 150.68,
      "learning_rate": 0.08493827872733119,
      "loss": 3.0429,
      "step": 93720
    },
    {
      "epoch": 150.71,
      "learning_rate": 0.08493506329646303,
      "loss": 3.078,
      "step": 93740
    },
    {
      "epoch": 150.74,
      "learning_rate": 0.08493184786559486,
      "loss": 3.0818,
      "step": 93760
    },
    {
      "epoch": 150.77,
      "learning_rate": 0.08492863243472669,
      "loss": 3.1013,
      "step": 93780
    },
    {
      "epoch": 150.8,
      "learning_rate": 0.08492541700385853,
      "loss": 3.1132,
      "step": 93800
    },
    {
      "epoch": 150.84,
      "learning_rate": 0.08492220157299035,
      "loss": 3.1271,
      "step": 93820
    },
    {
      "epoch": 150.87,
      "learning_rate": 0.08491898614212219,
      "loss": 3.0896,
      "step": 93840
    },
    {
      "epoch": 150.9,
      "learning_rate": 0.08491577071125403,
      "loss": 3.0742,
      "step": 93860
    },
    {
      "epoch": 150.93,
      "learning_rate": 0.08491255528038585,
      "loss": 3.0537,
      "step": 93880
    },
    {
      "epoch": 150.96,
      "learning_rate": 0.08490933984951769,
      "loss": 3.0777,
      "step": 93900
    },
    {
      "epoch": 151.0,
      "learning_rate": 0.08490612441864952,
      "loss": 3.0937,
      "step": 93920
    },
    {
      "epoch": 151.0,
      "eval_accuracy": {
        "accuracy": 0.36391199564642773
      },
      "eval_loss": 3.2097270488739014,
      "eval_runtime": 2.6711,
      "eval_samples_per_second": 4815.68,
      "eval_steps_per_second": 75.251,
      "step": 93922
    },
    {
      "epoch": 151.03,
      "learning_rate": 0.08490290898778136,
      "loss": 3.1237,
      "step": 93940
    },
    {
      "epoch": 151.06,
      "learning_rate": 0.0848996935569132,
      "loss": 3.0626,
      "step": 93960
    },
    {
      "epoch": 151.09,
      "learning_rate": 0.08489647812604502,
      "loss": 3.0465,
      "step": 93980
    },
    {
      "epoch": 151.13,
      "learning_rate": 0.08489326269517686,
      "loss": 3.0937,
      "step": 94000
    },
    {
      "epoch": 151.16,
      "learning_rate": 0.08489004726430868,
      "loss": 3.0891,
      "step": 94020
    },
    {
      "epoch": 151.19,
      "learning_rate": 0.08488683183344052,
      "loss": 3.0626,
      "step": 94040
    },
    {
      "epoch": 151.22,
      "learning_rate": 0.08488361640257235,
      "loss": 3.0778,
      "step": 94060
    },
    {
      "epoch": 151.25,
      "learning_rate": 0.08488040097170418,
      "loss": 3.0931,
      "step": 94080
    },
    {
      "epoch": 151.29,
      "learning_rate": 0.08487718554083602,
      "loss": 3.0186,
      "step": 94100
    },
    {
      "epoch": 151.32,
      "learning_rate": 0.08487397010996785,
      "loss": 3.0256,
      "step": 94120
    },
    {
      "epoch": 151.35,
      "learning_rate": 0.08487075467909969,
      "loss": 3.0679,
      "step": 94140
    },
    {
      "epoch": 151.38,
      "learning_rate": 0.08486753924823151,
      "loss": 3.0532,
      "step": 94160
    },
    {
      "epoch": 151.41,
      "learning_rate": 0.08486432381736335,
      "loss": 3.064,
      "step": 94180
    },
    {
      "epoch": 151.45,
      "learning_rate": 0.08486110838649519,
      "loss": 3.0901,
      "step": 94200
    },
    {
      "epoch": 151.48,
      "learning_rate": 0.08485789295562701,
      "loss": 3.0922,
      "step": 94220
    },
    {
      "epoch": 151.51,
      "learning_rate": 0.08485467752475885,
      "loss": 3.0649,
      "step": 94240
    },
    {
      "epoch": 151.54,
      "learning_rate": 0.08485146209389068,
      "loss": 3.0503,
      "step": 94260
    },
    {
      "epoch": 151.58,
      "learning_rate": 0.08484824666302251,
      "loss": 3.0766,
      "step": 94280
    },
    {
      "epoch": 151.61,
      "learning_rate": 0.08484503123215435,
      "loss": 3.0753,
      "step": 94300
    },
    {
      "epoch": 151.64,
      "learning_rate": 0.08484181580128618,
      "loss": 3.0462,
      "step": 94320
    },
    {
      "epoch": 151.67,
      "learning_rate": 0.08483860037041802,
      "loss": 3.0334,
      "step": 94340
    },
    {
      "epoch": 151.7,
      "learning_rate": 0.08483538493954984,
      "loss": 3.0766,
      "step": 94360
    },
    {
      "epoch": 151.74,
      "learning_rate": 0.08483216950868168,
      "loss": 3.0261,
      "step": 94380
    },
    {
      "epoch": 151.77,
      "learning_rate": 0.0848289540778135,
      "loss": 3.0891,
      "step": 94400
    },
    {
      "epoch": 151.8,
      "learning_rate": 0.08482573864694534,
      "loss": 3.0994,
      "step": 94420
    },
    {
      "epoch": 151.83,
      "learning_rate": 0.08482252321607718,
      "loss": 3.0764,
      "step": 94440
    },
    {
      "epoch": 151.86,
      "learning_rate": 0.084819307785209,
      "loss": 3.0911,
      "step": 94460
    },
    {
      "epoch": 151.9,
      "learning_rate": 0.08481609235434084,
      "loss": 3.0721,
      "step": 94480
    },
    {
      "epoch": 151.93,
      "learning_rate": 0.08481287692347267,
      "loss": 3.066,
      "step": 94500
    },
    {
      "epoch": 151.96,
      "learning_rate": 0.08480966149260451,
      "loss": 3.0748,
      "step": 94520
    },
    {
      "epoch": 151.99,
      "learning_rate": 0.08480644606173635,
      "loss": 3.0932,
      "step": 94540
    },
    {
      "epoch": 152.0,
      "eval_accuracy": {
        "accuracy": 0.36779911373707536
      },
      "eval_loss": 3.165132761001587,
      "eval_runtime": 3.1531,
      "eval_samples_per_second": 4079.471,
      "eval_steps_per_second": 63.747,
      "step": 94544
    },
    {
      "epoch": 152.03,
      "learning_rate": 0.08480323063086817,
      "loss": 3.0762,
      "step": 94560
    },
    {
      "epoch": 152.06,
      "learning_rate": 0.08480001520000001,
      "loss": 3.0554,
      "step": 94580
    },
    {
      "epoch": 152.09,
      "learning_rate": 0.08479679976913183,
      "loss": 3.0902,
      "step": 94600
    },
    {
      "epoch": 152.12,
      "learning_rate": 0.08479358433826367,
      "loss": 3.096,
      "step": 94620
    },
    {
      "epoch": 152.15,
      "learning_rate": 0.08479052967893892,
      "loss": 3.0665,
      "step": 94640
    },
    {
      "epoch": 152.19,
      "learning_rate": 0.08478731424807075,
      "loss": 3.0741,
      "step": 94660
    },
    {
      "epoch": 152.22,
      "learning_rate": 0.08478409881720259,
      "loss": 3.0736,
      "step": 94680
    },
    {
      "epoch": 152.25,
      "learning_rate": 0.08478088338633441,
      "loss": 3.0504,
      "step": 94700
    },
    {
      "epoch": 152.28,
      "learning_rate": 0.08477782872700965,
      "loss": 3.1074,
      "step": 94720
    },
    {
      "epoch": 152.32,
      "learning_rate": 0.08477461329614148,
      "loss": 3.0613,
      "step": 94740
    },
    {
      "epoch": 152.35,
      "learning_rate": 0.08477139786527331,
      "loss": 3.0598,
      "step": 94760
    },
    {
      "epoch": 152.38,
      "learning_rate": 0.08476818243440515,
      "loss": 3.0807,
      "step": 94780
    },
    {
      "epoch": 152.41,
      "learning_rate": 0.08476496700353699,
      "loss": 3.0796,
      "step": 94800
    },
    {
      "epoch": 152.44,
      "learning_rate": 0.08476175157266881,
      "loss": 3.0486,
      "step": 94820
    },
    {
      "epoch": 152.48,
      "learning_rate": 0.08475853614180065,
      "loss": 3.0939,
      "step": 94840
    },
    {
      "epoch": 152.51,
      "learning_rate": 0.08475532071093247,
      "loss": 3.0755,
      "step": 94860
    },
    {
      "epoch": 152.54,
      "learning_rate": 0.08475210528006431,
      "loss": 3.0593,
      "step": 94880
    },
    {
      "epoch": 152.57,
      "learning_rate": 0.08474888984919615,
      "loss": 3.0598,
      "step": 94900
    },
    {
      "epoch": 152.6,
      "learning_rate": 0.08474567441832798,
      "loss": 3.0589,
      "step": 94920
    },
    {
      "epoch": 152.64,
      "learning_rate": 0.08474245898745981,
      "loss": 3.0694,
      "step": 94940
    },
    {
      "epoch": 152.67,
      "learning_rate": 0.08473924355659164,
      "loss": 3.0548,
      "step": 94960
    },
    {
      "epoch": 152.7,
      "learning_rate": 0.08473602812572348,
      "loss": 3.087,
      "step": 94980
    },
    {
      "epoch": 152.73,
      "learning_rate": 0.08473281269485532,
      "loss": 3.0275,
      "step": 95000
    },
    {
      "epoch": 152.77,
      "learning_rate": 0.08472959726398714,
      "loss": 3.046,
      "step": 95020
    },
    {
      "epoch": 152.8,
      "learning_rate": 0.08472638183311898,
      "loss": 3.0752,
      "step": 95040
    },
    {
      "epoch": 152.83,
      "learning_rate": 0.0847231664022508,
      "loss": 3.0982,
      "step": 95060
    },
    {
      "epoch": 152.86,
      "learning_rate": 0.08471995097138264,
      "loss": 3.0939,
      "step": 95080
    },
    {
      "epoch": 152.89,
      "learning_rate": 0.08471673554051447,
      "loss": 3.1059,
      "step": 95100
    },
    {
      "epoch": 152.93,
      "learning_rate": 0.0847135201096463,
      "loss": 3.0416,
      "step": 95120
    },
    {
      "epoch": 152.96,
      "learning_rate": 0.08471030467877814,
      "loss": 3.0481,
      "step": 95140
    },
    {
      "epoch": 152.99,
      "learning_rate": 0.08470708924790997,
      "loss": 3.063,
      "step": 95160
    },
    {
      "epoch": 153.0,
      "eval_accuracy": {
        "accuracy": 0.3726968825312913
      },
      "eval_loss": 3.1195852756500244,
      "eval_runtime": 2.8631,
      "eval_samples_per_second": 4492.627,
      "eval_steps_per_second": 70.203,
      "step": 95166
    },
    {
      "epoch": 153.02,
      "learning_rate": 0.08470387381704181,
      "loss": 3.0928,
      "step": 95180
    },
    {
      "epoch": 153.05,
      "learning_rate": 0.08470065838617363,
      "loss": 3.0785,
      "step": 95200
    },
    {
      "epoch": 153.09,
      "learning_rate": 0.08469744295530547,
      "loss": 3.0681,
      "step": 95220
    },
    {
      "epoch": 153.12,
      "learning_rate": 0.08469422752443731,
      "loss": 3.0859,
      "step": 95240
    },
    {
      "epoch": 153.15,
      "learning_rate": 0.08469101209356913,
      "loss": 3.1038,
      "step": 95260
    },
    {
      "epoch": 153.18,
      "learning_rate": 0.08468779666270097,
      "loss": 3.097,
      "step": 95280
    },
    {
      "epoch": 153.22,
      "learning_rate": 0.0846845812318328,
      "loss": 3.0867,
      "step": 95300
    },
    {
      "epoch": 153.25,
      "learning_rate": 0.08468136580096464,
      "loss": 3.0805,
      "step": 95320
    },
    {
      "epoch": 153.28,
      "learning_rate": 0.08467815037009647,
      "loss": 3.0659,
      "step": 95340
    },
    {
      "epoch": 153.31,
      "learning_rate": 0.0846749349392283,
      "loss": 3.0428,
      "step": 95360
    },
    {
      "epoch": 153.34,
      "learning_rate": 0.08467171950836014,
      "loss": 3.0226,
      "step": 95380
    },
    {
      "epoch": 153.38,
      "learning_rate": 0.08466850407749196,
      "loss": 3.0375,
      "step": 95400
    },
    {
      "epoch": 153.41,
      "learning_rate": 0.0846652886466238,
      "loss": 3.0324,
      "step": 95420
    },
    {
      "epoch": 153.44,
      "learning_rate": 0.08466207321575563,
      "loss": 3.061,
      "step": 95440
    },
    {
      "epoch": 153.47,
      "learning_rate": 0.08465885778488746,
      "loss": 3.0746,
      "step": 95460
    },
    {
      "epoch": 153.5,
      "learning_rate": 0.0846556423540193,
      "loss": 3.0582,
      "step": 95480
    },
    {
      "epoch": 153.54,
      "learning_rate": 0.08465242692315113,
      "loss": 3.1068,
      "step": 95500
    },
    {
      "epoch": 153.57,
      "learning_rate": 0.08464921149228297,
      "loss": 3.0651,
      "step": 95520
    },
    {
      "epoch": 153.6,
      "learning_rate": 0.08464599606141479,
      "loss": 3.0766,
      "step": 95540
    },
    {
      "epoch": 153.63,
      "learning_rate": 0.08464278063054663,
      "loss": 3.0729,
      "step": 95560
    },
    {
      "epoch": 153.67,
      "learning_rate": 0.08463956519967847,
      "loss": 3.0945,
      "step": 95580
    },
    {
      "epoch": 153.7,
      "learning_rate": 0.08463634976881029,
      "loss": 3.1079,
      "step": 95600
    },
    {
      "epoch": 153.73,
      "learning_rate": 0.08463313433794213,
      "loss": 3.0784,
      "step": 95620
    },
    {
      "epoch": 153.76,
      "learning_rate": 0.08462991890707396,
      "loss": 3.0839,
      "step": 95640
    },
    {
      "epoch": 153.79,
      "learning_rate": 0.0846267034762058,
      "loss": 3.0218,
      "step": 95660
    },
    {
      "epoch": 153.83,
      "learning_rate": 0.08462348804533763,
      "loss": 3.0659,
      "step": 95680
    },
    {
      "epoch": 153.86,
      "learning_rate": 0.08462027261446946,
      "loss": 3.042,
      "step": 95700
    },
    {
      "epoch": 153.89,
      "learning_rate": 0.0846170571836013,
      "loss": 3.0556,
      "step": 95720
    },
    {
      "epoch": 153.92,
      "learning_rate": 0.08461384175273312,
      "loss": 3.0892,
      "step": 95740
    },
    {
      "epoch": 153.95,
      "learning_rate": 0.08461062632186496,
      "loss": 3.0952,
      "step": 95760
    },
    {
      "epoch": 153.99,
      "learning_rate": 0.08460741089099678,
      "loss": 3.0912,
      "step": 95780
    },
    {
      "epoch": 154.0,
      "eval_accuracy": {
        "accuracy": 0.3576926067013916
      },
      "eval_loss": 3.231779098510742,
      "eval_runtime": 2.7096,
      "eval_samples_per_second": 4747.255,
      "eval_steps_per_second": 74.182,
      "step": 95788
    },
    {
      "epoch": 154.02,
      "learning_rate": 0.08460419546012862,
      "loss": 3.0886,
      "step": 95800
    },
    {
      "epoch": 154.05,
      "learning_rate": 0.08460098002926046,
      "loss": 3.1016,
      "step": 95820
    },
    {
      "epoch": 154.08,
      "learning_rate": 0.08459776459839229,
      "loss": 3.0361,
      "step": 95840
    },
    {
      "epoch": 154.12,
      "learning_rate": 0.08459454916752412,
      "loss": 3.0536,
      "step": 95860
    },
    {
      "epoch": 154.15,
      "learning_rate": 0.08459133373665595,
      "loss": 3.0389,
      "step": 95880
    },
    {
      "epoch": 154.18,
      "learning_rate": 0.08458811830578779,
      "loss": 3.0685,
      "step": 95900
    },
    {
      "epoch": 154.21,
      "learning_rate": 0.08458490287491963,
      "loss": 3.1159,
      "step": 95920
    },
    {
      "epoch": 154.24,
      "learning_rate": 0.08458168744405145,
      "loss": 3.0613,
      "step": 95940
    },
    {
      "epoch": 154.28,
      "learning_rate": 0.08457847201318329,
      "loss": 3.0547,
      "step": 95960
    },
    {
      "epoch": 154.31,
      "learning_rate": 0.08457525658231511,
      "loss": 3.0493,
      "step": 95980
    },
    {
      "epoch": 154.34,
      "learning_rate": 0.08457204115144695,
      "loss": 3.0705,
      "step": 96000
    },
    {
      "epoch": 154.37,
      "learning_rate": 0.08456882572057879,
      "loss": 3.0892,
      "step": 96020
    },
    {
      "epoch": 154.41,
      "learning_rate": 0.08456561028971062,
      "loss": 3.1031,
      "step": 96040
    },
    {
      "epoch": 154.44,
      "learning_rate": 0.08456239485884245,
      "loss": 3.085,
      "step": 96060
    },
    {
      "epoch": 154.47,
      "learning_rate": 0.08455917942797428,
      "loss": 3.0847,
      "step": 96080
    },
    {
      "epoch": 154.5,
      "learning_rate": 0.08455596399710612,
      "loss": 3.0949,
      "step": 96100
    },
    {
      "epoch": 154.53,
      "learning_rate": 0.08455274856623794,
      "loss": 3.0992,
      "step": 96120
    },
    {
      "epoch": 154.57,
      "learning_rate": 0.08454953313536978,
      "loss": 3.1054,
      "step": 96140
    },
    {
      "epoch": 154.6,
      "learning_rate": 0.08454631770450162,
      "loss": 3.0935,
      "step": 96160
    },
    {
      "epoch": 154.63,
      "learning_rate": 0.08454310227363344,
      "loss": 3.0809,
      "step": 96180
    },
    {
      "epoch": 154.66,
      "learning_rate": 0.08453988684276528,
      "loss": 3.0606,
      "step": 96200
    },
    {
      "epoch": 154.69,
      "learning_rate": 0.08453667141189711,
      "loss": 3.0942,
      "step": 96220
    },
    {
      "epoch": 154.73,
      "learning_rate": 0.08453345598102895,
      "loss": 3.1176,
      "step": 96240
    },
    {
      "epoch": 154.76,
      "learning_rate": 0.08453024055016078,
      "loss": 3.1045,
      "step": 96260
    },
    {
      "epoch": 154.79,
      "learning_rate": 0.08452702511929261,
      "loss": 3.0656,
      "step": 96280
    },
    {
      "epoch": 154.82,
      "learning_rate": 0.08452380968842445,
      "loss": 3.08,
      "step": 96300
    },
    {
      "epoch": 154.86,
      "learning_rate": 0.08452059425755627,
      "loss": 3.0988,
      "step": 96320
    },
    {
      "epoch": 154.89,
      "learning_rate": 0.08451737882668811,
      "loss": 3.1039,
      "step": 96340
    },
    {
      "epoch": 154.92,
      "learning_rate": 0.08451416339581995,
      "loss": 3.0878,
      "step": 96360
    },
    {
      "epoch": 154.95,
      "learning_rate": 0.08451094796495177,
      "loss": 3.0698,
      "step": 96380
    },
    {
      "epoch": 154.98,
      "learning_rate": 0.08450773253408361,
      "loss": 3.0731,
      "step": 96400
    },
    {
      "epoch": 155.0,
      "eval_accuracy": {
        "accuracy": 0.3529503226308015
      },
      "eval_loss": 3.3594236373901367,
      "eval_runtime": 2.964,
      "eval_samples_per_second": 4339.817,
      "eval_steps_per_second": 67.815,
      "step": 96410
    },
    {
      "epoch": 155.02,
      "learning_rate": 0.08450451710321544,
      "loss": 3.1904,
      "step": 96420
    },
    {
      "epoch": 155.05,
      "learning_rate": 0.08450130167234728,
      "loss": 3.0287,
      "step": 96440
    },
    {
      "epoch": 155.08,
      "learning_rate": 0.0844980862414791,
      "loss": 3.0489,
      "step": 96460
    },
    {
      "epoch": 155.11,
      "learning_rate": 0.08449487081061093,
      "loss": 3.0779,
      "step": 96480
    },
    {
      "epoch": 155.14,
      "learning_rate": 0.08449165537974278,
      "loss": 3.0895,
      "step": 96500
    },
    {
      "epoch": 155.18,
      "learning_rate": 0.0844884399488746,
      "loss": 3.0673,
      "step": 96520
    },
    {
      "epoch": 155.21,
      "learning_rate": 0.08448522451800644,
      "loss": 3.0584,
      "step": 96540
    },
    {
      "epoch": 155.24,
      "learning_rate": 0.08448200908713827,
      "loss": 3.0565,
      "step": 96560
    },
    {
      "epoch": 155.27,
      "learning_rate": 0.08447879365627009,
      "loss": 3.0721,
      "step": 96580
    },
    {
      "epoch": 155.31,
      "learning_rate": 0.08447557822540194,
      "loss": 3.054,
      "step": 96600
    },
    {
      "epoch": 155.34,
      "learning_rate": 0.08447236279453377,
      "loss": 3.0506,
      "step": 96620
    },
    {
      "epoch": 155.37,
      "learning_rate": 0.0844691473636656,
      "loss": 3.0832,
      "step": 96640
    },
    {
      "epoch": 155.4,
      "learning_rate": 0.08446593193279743,
      "loss": 3.1011,
      "step": 96660
    },
    {
      "epoch": 155.43,
      "learning_rate": 0.08446271650192927,
      "loss": 3.0737,
      "step": 96680
    },
    {
      "epoch": 155.47,
      "learning_rate": 0.08445950107106111,
      "loss": 3.1001,
      "step": 96700
    },
    {
      "epoch": 155.5,
      "learning_rate": 0.08445628564019293,
      "loss": 3.088,
      "step": 96720
    },
    {
      "epoch": 155.53,
      "learning_rate": 0.08445307020932477,
      "loss": 3.113,
      "step": 96740
    },
    {
      "epoch": 155.56,
      "learning_rate": 0.0844498547784566,
      "loss": 3.0816,
      "step": 96760
    },
    {
      "epoch": 155.59,
      "learning_rate": 0.08444663934758843,
      "loss": 3.039,
      "step": 96780
    },
    {
      "epoch": 155.63,
      "learning_rate": 0.08444342391672026,
      "loss": 3.046,
      "step": 96800
    },
    {
      "epoch": 155.66,
      "learning_rate": 0.08444020848585208,
      "loss": 3.006,
      "step": 96820
    },
    {
      "epoch": 155.69,
      "learning_rate": 0.08443699305498394,
      "loss": 3.0377,
      "step": 96840
    },
    {
      "epoch": 155.72,
      "learning_rate": 0.08443377762411576,
      "loss": 3.0477,
      "step": 96860
    },
    {
      "epoch": 155.76,
      "learning_rate": 0.0844305621932476,
      "loss": 3.1188,
      "step": 96880
    },
    {
      "epoch": 155.79,
      "learning_rate": 0.08442734676237942,
      "loss": 3.1694,
      "step": 96900
    },
    {
      "epoch": 155.82,
      "learning_rate": 0.08442413133151125,
      "loss": 3.1475,
      "step": 96920
    },
    {
      "epoch": 155.85,
      "learning_rate": 0.0844209159006431,
      "loss": 3.0592,
      "step": 96940
    },
    {
      "epoch": 155.88,
      "learning_rate": 0.08441770046977493,
      "loss": 3.0383,
      "step": 96960
    },
    {
      "epoch": 155.92,
      "learning_rate": 0.08441448503890676,
      "loss": 3.0341,
      "step": 96980
    },
    {
      "epoch": 155.95,
      "learning_rate": 0.08441126960803859,
      "loss": 3.0202,
      "step": 97000
    },
    {
      "epoch": 155.98,
      "learning_rate": 0.08440805417717041,
      "loss": 3.0628,
      "step": 97020
    },
    {
      "epoch": 156.0,
      "eval_accuracy": {
        "accuracy": 0.36974267278239914
      },
      "eval_loss": 3.145054578781128,
      "eval_runtime": 3.0334,
      "eval_samples_per_second": 4240.462,
      "eval_steps_per_second": 66.262,
      "step": 97032
    },
    {
      "epoch": 156.01,
      "learning_rate": 0.08440483874630227,
      "loss": 3.0512,
      "step": 97040
    },
    {
      "epoch": 156.05,
      "learning_rate": 0.08440162331543409,
      "loss": 3.0311,
      "step": 97060
    },
    {
      "epoch": 156.08,
      "learning_rate": 0.08439840788456593,
      "loss": 3.0489,
      "step": 97080
    },
    {
      "epoch": 156.11,
      "learning_rate": 0.08439519245369775,
      "loss": 3.0608,
      "step": 97100
    },
    {
      "epoch": 156.14,
      "learning_rate": 0.08439197702282958,
      "loss": 3.0441,
      "step": 97120
    },
    {
      "epoch": 156.17,
      "learning_rate": 0.08438876159196142,
      "loss": 3.0856,
      "step": 97140
    },
    {
      "epoch": 156.21,
      "learning_rate": 0.08438554616109324,
      "loss": 3.1026,
      "step": 97160
    },
    {
      "epoch": 156.24,
      "learning_rate": 0.0843823307302251,
      "loss": 3.035,
      "step": 97180
    },
    {
      "epoch": 156.27,
      "learning_rate": 0.08437911529935692,
      "loss": 3.0765,
      "step": 97200
    },
    {
      "epoch": 156.3,
      "learning_rate": 0.08437589986848874,
      "loss": 3.0612,
      "step": 97220
    },
    {
      "epoch": 156.33,
      "learning_rate": 0.08437268443762058,
      "loss": 3.076,
      "step": 97240
    },
    {
      "epoch": 156.37,
      "learning_rate": 0.0843694690067524,
      "loss": 3.0472,
      "step": 97260
    },
    {
      "epoch": 156.4,
      "learning_rate": 0.08436625357588426,
      "loss": 3.0324,
      "step": 97280
    },
    {
      "epoch": 156.43,
      "learning_rate": 0.08436303814501608,
      "loss": 3.0376,
      "step": 97300
    },
    {
      "epoch": 156.46,
      "learning_rate": 0.08435982271414792,
      "loss": 3.0602,
      "step": 97320
    },
    {
      "epoch": 156.5,
      "learning_rate": 0.08435660728327975,
      "loss": 3.0421,
      "step": 97340
    },
    {
      "epoch": 156.53,
      "learning_rate": 0.08435339185241157,
      "loss": 3.0412,
      "step": 97360
    },
    {
      "epoch": 156.56,
      "learning_rate": 0.08435017642154342,
      "loss": 3.0929,
      "step": 97380
    },
    {
      "epoch": 156.59,
      "learning_rate": 0.08434696099067525,
      "loss": 3.0965,
      "step": 97400
    },
    {
      "epoch": 156.62,
      "learning_rate": 0.08434374555980709,
      "loss": 3.0905,
      "step": 97420
    },
    {
      "epoch": 156.66,
      "learning_rate": 0.08434053012893891,
      "loss": 3.0899,
      "step": 97440
    },
    {
      "epoch": 156.69,
      "learning_rate": 0.08433731469807074,
      "loss": 3.0839,
      "step": 97460
    },
    {
      "epoch": 156.72,
      "learning_rate": 0.08433409926720259,
      "loss": 3.0717,
      "step": 97480
    },
    {
      "epoch": 156.75,
      "learning_rate": 0.0843308838363344,
      "loss": 3.0508,
      "step": 97500
    },
    {
      "epoch": 156.78,
      "learning_rate": 0.08432766840546625,
      "loss": 3.0689,
      "step": 97520
    },
    {
      "epoch": 156.82,
      "learning_rate": 0.08432445297459808,
      "loss": 3.0937,
      "step": 97540
    },
    {
      "epoch": 156.85,
      "learning_rate": 0.0843212375437299,
      "loss": 3.081,
      "step": 97560
    },
    {
      "epoch": 156.88,
      "learning_rate": 0.08431802211286174,
      "loss": 3.0937,
      "step": 97580
    },
    {
      "epoch": 156.91,
      "learning_rate": 0.08431480668199356,
      "loss": 3.0836,
      "step": 97600
    },
    {
      "epoch": 156.95,
      "learning_rate": 0.08431159125112542,
      "loss": 3.0772,
      "step": 97620
    },
    {
      "epoch": 156.98,
      "learning_rate": 0.08430837582025724,
      "loss": 3.1017,
      "step": 97640
    },
    {
      "epoch": 157.0,
      "eval_accuracy": {
        "accuracy": 0.3625126331337946
      },
      "eval_loss": 3.150768518447876,
      "eval_runtime": 2.8126,
      "eval_samples_per_second": 4573.347,
      "eval_steps_per_second": 71.464,
      "step": 97654
    },
    {
      "epoch": 157.01,
      "learning_rate": 0.08430516038938907,
      "loss": 3.0557,
      "step": 97660
    },
    {
      "epoch": 157.04,
      "learning_rate": 0.0843019449585209,
      "loss": 3.0869,
      "step": 97680
    },
    {
      "epoch": 157.07,
      "learning_rate": 0.08429872952765273,
      "loss": 3.0683,
      "step": 97700
    },
    {
      "epoch": 157.11,
      "learning_rate": 0.08429551409678458,
      "loss": 3.0609,
      "step": 97720
    },
    {
      "epoch": 157.14,
      "learning_rate": 0.08429229866591641,
      "loss": 3.095,
      "step": 97740
    },
    {
      "epoch": 157.17,
      "learning_rate": 0.08428908323504823,
      "loss": 3.0738,
      "step": 97760
    },
    {
      "epoch": 157.2,
      "learning_rate": 0.08428586780418007,
      "loss": 3.0269,
      "step": 97780
    },
    {
      "epoch": 157.23,
      "learning_rate": 0.0842826523733119,
      "loss": 3.0517,
      "step": 97800
    },
    {
      "epoch": 157.27,
      "learning_rate": 0.08427943694244375,
      "loss": 3.0497,
      "step": 97820
    },
    {
      "epoch": 157.3,
      "learning_rate": 0.08427622151157556,
      "loss": 3.0667,
      "step": 97840
    },
    {
      "epoch": 157.33,
      "learning_rate": 0.0842730060807074,
      "loss": 3.0364,
      "step": 97860
    },
    {
      "epoch": 157.36,
      "learning_rate": 0.08426979064983924,
      "loss": 3.0799,
      "step": 97880
    },
    {
      "epoch": 157.4,
      "learning_rate": 0.08426657521897106,
      "loss": 3.0861,
      "step": 97900
    },
    {
      "epoch": 157.43,
      "learning_rate": 0.0842633597881029,
      "loss": 3.0663,
      "step": 97920
    },
    {
      "epoch": 157.46,
      "learning_rate": 0.08426014435723472,
      "loss": 3.0532,
      "step": 97940
    },
    {
      "epoch": 157.49,
      "learning_rate": 0.08425692892636658,
      "loss": 3.0542,
      "step": 97960
    },
    {
      "epoch": 157.52,
      "learning_rate": 0.0842537134954984,
      "loss": 3.0775,
      "step": 97980
    },
    {
      "epoch": 157.56,
      "learning_rate": 0.08425049806463022,
      "loss": 3.0066,
      "step": 98000
    },
    {
      "epoch": 157.59,
      "learning_rate": 0.08424728263376206,
      "loss": 3.0325,
      "step": 98020
    },
    {
      "epoch": 157.62,
      "learning_rate": 0.08424406720289389,
      "loss": 3.0268,
      "step": 98040
    },
    {
      "epoch": 157.65,
      "learning_rate": 0.08424085177202574,
      "loss": 3.0294,
      "step": 98060
    },
    {
      "epoch": 157.68,
      "learning_rate": 0.08423763634115757,
      "loss": 3.0413,
      "step": 98080
    },
    {
      "epoch": 157.72,
      "learning_rate": 0.08423442091028939,
      "loss": 3.0628,
      "step": 98100
    },
    {
      "epoch": 157.75,
      "learning_rate": 0.08423120547942123,
      "loss": 3.0488,
      "step": 98120
    },
    {
      "epoch": 157.78,
      "learning_rate": 0.08422799004855305,
      "loss": 3.0657,
      "step": 98140
    },
    {
      "epoch": 157.81,
      "learning_rate": 0.0842247746176849,
      "loss": 3.1239,
      "step": 98160
    },
    {
      "epoch": 157.85,
      "learning_rate": 0.08422171995836013,
      "loss": 3.1583,
      "step": 98180
    },
    {
      "epoch": 157.88,
      "learning_rate": 0.08421850452749197,
      "loss": 3.0621,
      "step": 98200
    },
    {
      "epoch": 157.91,
      "learning_rate": 0.0842152890966238,
      "loss": 3.016,
      "step": 98220
    },
    {
      "epoch": 157.94,
      "learning_rate": 0.08421207366575563,
      "loss": 3.0311,
      "step": 98240
    },
    {
      "epoch": 157.97,
      "learning_rate": 0.08420885823488747,
      "loss": 3.0823,
      "step": 98260
    },
    {
      "epoch": 158.0,
      "eval_accuracy": {
        "accuracy": 0.3686542797170178
      },
      "eval_loss": 3.1230266094207764,
      "eval_runtime": 3.0511,
      "eval_samples_per_second": 4215.92,
      "eval_steps_per_second": 65.879,
      "step": 98276
    },
    {
      "epoch": 158.01,
      "learning_rate": 0.08420564280401929,
      "loss": 3.0244,
      "step": 98280
    },
    {
      "epoch": 158.04,
      "learning_rate": 0.08420242737315113,
      "loss": 3.084,
      "step": 98300
    },
    {
      "epoch": 158.07,
      "learning_rate": 0.08419921194228297,
      "loss": 3.0886,
      "step": 98320
    },
    {
      "epoch": 158.1,
      "learning_rate": 0.0841959965114148,
      "loss": 3.0456,
      "step": 98340
    },
    {
      "epoch": 158.14,
      "learning_rate": 0.08419278108054663,
      "loss": 3.0342,
      "step": 98360
    },
    {
      "epoch": 158.17,
      "learning_rate": 0.08418956564967846,
      "loss": 3.1113,
      "step": 98380
    },
    {
      "epoch": 158.2,
      "learning_rate": 0.0841863502188103,
      "loss": 3.0733,
      "step": 98400
    },
    {
      "epoch": 158.23,
      "learning_rate": 0.08418313478794213,
      "loss": 3.0909,
      "step": 98420
    },
    {
      "epoch": 158.26,
      "learning_rate": 0.08417991935707396,
      "loss": 3.0509,
      "step": 98440
    },
    {
      "epoch": 158.3,
      "learning_rate": 0.0841767039262058,
      "loss": 3.0707,
      "step": 98460
    },
    {
      "epoch": 158.33,
      "learning_rate": 0.08417348849533762,
      "loss": 3.0658,
      "step": 98480
    },
    {
      "epoch": 158.36,
      "learning_rate": 0.08417027306446946,
      "loss": 3.0623,
      "step": 98500
    },
    {
      "epoch": 158.39,
      "learning_rate": 0.08416705763360129,
      "loss": 3.0452,
      "step": 98520
    },
    {
      "epoch": 158.42,
      "learning_rate": 0.08416384220273312,
      "loss": 3.0611,
      "step": 98540
    },
    {
      "epoch": 158.46,
      "learning_rate": 0.08416062677186496,
      "loss": 3.0315,
      "step": 98560
    },
    {
      "epoch": 158.49,
      "learning_rate": 0.08415741134099679,
      "loss": 3.0994,
      "step": 98580
    },
    {
      "epoch": 158.52,
      "learning_rate": 0.08415419591012863,
      "loss": 3.0763,
      "step": 98600
    },
    {
      "epoch": 158.55,
      "learning_rate": 0.08415098047926045,
      "loss": 3.0883,
      "step": 98620
    },
    {
      "epoch": 158.59,
      "learning_rate": 0.08414776504839229,
      "loss": 3.0322,
      "step": 98640
    },
    {
      "epoch": 158.62,
      "learning_rate": 0.08414454961752413,
      "loss": 3.0365,
      "step": 98660
    },
    {
      "epoch": 158.65,
      "learning_rate": 0.08414133418665595,
      "loss": 3.0691,
      "step": 98680
    },
    {
      "epoch": 158.68,
      "learning_rate": 0.08413811875578779,
      "loss": 3.0878,
      "step": 98700
    },
    {
      "epoch": 158.71,
      "learning_rate": 0.08413490332491962,
      "loss": 3.0495,
      "step": 98720
    },
    {
      "epoch": 158.75,
      "learning_rate": 0.08413168789405145,
      "loss": 3.0641,
      "step": 98740
    },
    {
      "epoch": 158.78,
      "learning_rate": 0.0841284724631833,
      "loss": 3.0344,
      "step": 98760
    },
    {
      "epoch": 158.81,
      "learning_rate": 0.08412525703231512,
      "loss": 3.0532,
      "step": 98780
    },
    {
      "epoch": 158.84,
      "learning_rate": 0.08412204160144696,
      "loss": 3.0784,
      "step": 98800
    },
    {
      "epoch": 158.87,
      "learning_rate": 0.08411882617057878,
      "loss": 3.0648,
      "step": 98820
    },
    {
      "epoch": 158.91,
      "learning_rate": 0.08411561073971062,
      "loss": 3.0397,
      "step": 98840
    },
    {
      "epoch": 158.94,
      "learning_rate": 0.08411239530884244,
      "loss": 3.0644,
      "step": 98860
    },
    {
      "epoch": 158.97,
      "learning_rate": 0.08410917987797428,
      "loss": 3.0447,
      "step": 98880
    },
    {
      "epoch": 159.0,
      "eval_accuracy": {
        "accuracy": 0.3588587421285859
      },
      "eval_loss": 3.208383321762085,
      "eval_runtime": 2.8413,
      "eval_samples_per_second": 4527.123,
      "eval_steps_per_second": 70.742,
      "step": 98898
    },
    {
      "epoch": 159.0,
      "learning_rate": 0.08410596444710612,
      "loss": 3.0853,
      "step": 98900
    },
    {
      "epoch": 159.04,
      "learning_rate": 0.08410274901623795,
      "loss": 3.0963,
      "step": 98920
    },
    {
      "epoch": 159.07,
      "learning_rate": 0.08409953358536978,
      "loss": 3.119,
      "step": 98940
    },
    {
      "epoch": 159.1,
      "learning_rate": 0.08409631815450161,
      "loss": 3.0461,
      "step": 98960
    },
    {
      "epoch": 159.13,
      "learning_rate": 0.08409310272363345,
      "loss": 3.0014,
      "step": 98980
    },
    {
      "epoch": 159.16,
      "learning_rate": 0.08408988729276529,
      "loss": 3.0292,
      "step": 99000
    },
    {
      "epoch": 159.2,
      "learning_rate": 0.08408667186189711,
      "loss": 3.0119,
      "step": 99020
    },
    {
      "epoch": 159.23,
      "learning_rate": 0.08408345643102895,
      "loss": 3.0367,
      "step": 99040
    },
    {
      "epoch": 159.26,
      "learning_rate": 0.08408024100016077,
      "loss": 3.0589,
      "step": 99060
    },
    {
      "epoch": 159.29,
      "learning_rate": 0.08407702556929261,
      "loss": 3.0626,
      "step": 99080
    },
    {
      "epoch": 159.32,
      "learning_rate": 0.08407381013842445,
      "loss": 3.0663,
      "step": 99100
    },
    {
      "epoch": 159.36,
      "learning_rate": 0.08407059470755628,
      "loss": 3.0673,
      "step": 99120
    },
    {
      "epoch": 159.39,
      "learning_rate": 0.08406737927668811,
      "loss": 3.0575,
      "step": 99140
    },
    {
      "epoch": 159.42,
      "learning_rate": 0.08406416384581994,
      "loss": 3.0149,
      "step": 99160
    },
    {
      "epoch": 159.45,
      "learning_rate": 0.08406094841495178,
      "loss": 3.051,
      "step": 99180
    },
    {
      "epoch": 159.49,
      "learning_rate": 0.0840577329840836,
      "loss": 3.0823,
      "step": 99200
    },
    {
      "epoch": 159.52,
      "learning_rate": 0.08405451755321543,
      "loss": 3.0521,
      "step": 99220
    },
    {
      "epoch": 159.55,
      "learning_rate": 0.08405130212234728,
      "loss": 3.0695,
      "step": 99240
    },
    {
      "epoch": 159.58,
      "learning_rate": 0.0840480866914791,
      "loss": 3.0744,
      "step": 99260
    },
    {
      "epoch": 159.61,
      "learning_rate": 0.08404487126061094,
      "loss": 3.0402,
      "step": 99280
    },
    {
      "epoch": 159.65,
      "learning_rate": 0.08404165582974277,
      "loss": 3.1166,
      "step": 99300
    },
    {
      "epoch": 159.68,
      "learning_rate": 0.08403844039887459,
      "loss": 3.0583,
      "step": 99320
    },
    {
      "epoch": 159.71,
      "learning_rate": 0.08403522496800644,
      "loss": 3.0575,
      "step": 99340
    },
    {
      "epoch": 159.74,
      "learning_rate": 0.08403200953713827,
      "loss": 3.0587,
      "step": 99360
    },
    {
      "epoch": 159.77,
      "learning_rate": 0.08402879410627011,
      "loss": 3.0774,
      "step": 99380
    },
    {
      "epoch": 159.81,
      "learning_rate": 0.08402557867540193,
      "loss": 3.0804,
      "step": 99400
    },
    {
      "epoch": 159.84,
      "learning_rate": 0.08402236324453376,
      "loss": 3.0757,
      "step": 99420
    },
    {
      "epoch": 159.87,
      "learning_rate": 0.08401914781366561,
      "loss": 3.0686,
      "step": 99440
    },
    {
      "epoch": 159.9,
      "learning_rate": 0.08401593238279743,
      "loss": 3.0491,
      "step": 99460
    },
    {
      "epoch": 159.94,
      "learning_rate": 0.08401271695192927,
      "loss": 3.036,
      "step": 99480
    },
    {
      "epoch": 159.97,
      "learning_rate": 0.0840095015210611,
      "loss": 3.0409,
      "step": 99500
    },
    {
      "epoch": 160.0,
      "learning_rate": 0.08400628609019294,
      "loss": 3.0403,
      "step": 99520
    },
    {
      "epoch": 160.0,
      "eval_accuracy": {
        "accuracy": 0.3765840006219389
      },
      "eval_loss": 3.082106351852417,
      "eval_runtime": 3.3968,
      "eval_samples_per_second": 3786.839,
      "eval_steps_per_second": 59.174,
      "step": 99520
    },
    {
      "epoch": 160.03,
      "learning_rate": 0.08400307065932476,
      "loss": 3.0414,
      "step": 99540
    },
    {
      "epoch": 160.06,
      "learning_rate": 0.08399985522845659,
      "loss": 3.0491,
      "step": 99560
    },
    {
      "epoch": 160.1,
      "learning_rate": 0.08399663979758844,
      "loss": 3.0382,
      "step": 99580
    },
    {
      "epoch": 160.13,
      "learning_rate": 0.08399342436672026,
      "loss": 2.989,
      "step": 99600
    },
    {
      "epoch": 160.16,
      "learning_rate": 0.0839902089358521,
      "loss": 3.0465,
      "step": 99620
    },
    {
      "epoch": 160.19,
      "learning_rate": 0.08398699350498393,
      "loss": 3.0355,
      "step": 99640
    },
    {
      "epoch": 160.23,
      "learning_rate": 0.08398377807411575,
      "loss": 3.0413,
      "step": 99660
    },
    {
      "epoch": 160.26,
      "learning_rate": 0.0839805626432476,
      "loss": 3.0212,
      "step": 99680
    },
    {
      "epoch": 160.29,
      "learning_rate": 0.08397734721237943,
      "loss": 3.0395,
      "step": 99700
    },
    {
      "epoch": 160.32,
      "learning_rate": 0.08397413178151127,
      "loss": 3.0331,
      "step": 99720
    },
    {
      "epoch": 160.35,
      "learning_rate": 0.08397091635064309,
      "loss": 3.0099,
      "step": 99740
    },
    {
      "epoch": 160.39,
      "learning_rate": 0.08396770091977492,
      "loss": 3.0631,
      "step": 99760
    },
    {
      "epoch": 160.42,
      "learning_rate": 0.08396448548890677,
      "loss": 3.0796,
      "step": 99780
    },
    {
      "epoch": 160.45,
      "learning_rate": 0.08396127005803859,
      "loss": 3.0665,
      "step": 99800
    },
    {
      "epoch": 160.48,
      "learning_rate": 0.08395805462717043,
      "loss": 3.0757,
      "step": 99820
    },
    {
      "epoch": 160.51,
      "learning_rate": 0.08395483919630226,
      "loss": 3.0889,
      "step": 99840
    },
    {
      "epoch": 160.55,
      "learning_rate": 0.08395162376543408,
      "loss": 3.0524,
      "step": 99860
    },
    {
      "epoch": 160.58,
      "learning_rate": 0.08394840833456592,
      "loss": 3.0589,
      "step": 99880
    },
    {
      "epoch": 160.61,
      "learning_rate": 0.08394519290369774,
      "loss": 3.0282,
      "step": 99900
    },
    {
      "epoch": 160.64,
      "learning_rate": 0.0839419774728296,
      "loss": 3.0361,
      "step": 99920
    },
    {
      "epoch": 160.68,
      "learning_rate": 0.08393876204196142,
      "loss": 3.0459,
      "step": 99940
    },
    {
      "epoch": 160.71,
      "learning_rate": 0.08393554661109325,
      "loss": 3.0883,
      "step": 99960
    },
    {
      "epoch": 160.74,
      "learning_rate": 0.08393233118022508,
      "loss": 3.1129,
      "step": 99980
    },
    {
      "epoch": 160.77,
      "learning_rate": 0.08392911574935691,
      "loss": 3.0757,
      "step": 100000
    },
    {
      "epoch": 160.8,
      "learning_rate": 0.08392590031848876,
      "loss": 3.0195,
      "step": 100020
    },
    {
      "epoch": 160.84,
      "learning_rate": 0.08392268488762059,
      "loss": 3.0184,
      "step": 100040
    },
    {
      "epoch": 160.87,
      "learning_rate": 0.08391946945675241,
      "loss": 3.0771,
      "step": 100060
    },
    {
      "epoch": 160.9,
      "learning_rate": 0.08391625402588425,
      "loss": 3.0613,
      "step": 100080
    },
    {
      "epoch": 160.93,
      "learning_rate": 0.08391303859501607,
      "loss": 3.0937,
      "step": 100100
    },
    {
      "epoch": 160.96,
      "learning_rate": 0.08390982316414793,
      "loss": 3.085,
      "step": 100120
    },
    {
      "epoch": 161.0,
      "learning_rate": 0.08390660773327975,
      "loss": 3.071,
      "step": 100140
    },
    {
      "epoch": 161.0,
      "eval_accuracy": {
        "accuracy": 0.3712197776568452
      },
      "eval_loss": 3.1573164463043213,
      "eval_runtime": 2.7462,
      "eval_samples_per_second": 4683.854,
      "eval_steps_per_second": 73.191,
      "step": 100142
    },
    {
      "epoch": 161.03,
      "learning_rate": 0.08390339230241159,
      "loss": 3.0796,
      "step": 100160
    },
    {
      "epoch": 161.06,
      "learning_rate": 0.08390017687154341,
      "loss": 3.0477,
      "step": 100180
    },
    {
      "epoch": 161.09,
      "learning_rate": 0.08389696144067524,
      "loss": 3.0232,
      "step": 100200
    },
    {
      "epoch": 161.13,
      "learning_rate": 0.08389374600980709,
      "loss": 3.0448,
      "step": 100220
    },
    {
      "epoch": 161.16,
      "learning_rate": 0.0838905305789389,
      "loss": 3.1022,
      "step": 100240
    },
    {
      "epoch": 161.19,
      "learning_rate": 0.08388731514807075,
      "loss": 3.0839,
      "step": 100260
    },
    {
      "epoch": 161.22,
      "learning_rate": 0.08388409971720258,
      "loss": 3.0715,
      "step": 100280
    },
    {
      "epoch": 161.25,
      "learning_rate": 0.0838808842863344,
      "loss": 3.0669,
      "step": 100300
    },
    {
      "epoch": 161.29,
      "learning_rate": 0.08387766885546624,
      "loss": 3.0796,
      "step": 100320
    },
    {
      "epoch": 161.32,
      "learning_rate": 0.08387445342459807,
      "loss": 3.0321,
      "step": 100340
    },
    {
      "epoch": 161.35,
      "learning_rate": 0.08387123799372992,
      "loss": 3.0274,
      "step": 100360
    },
    {
      "epoch": 161.38,
      "learning_rate": 0.08386802256286174,
      "loss": 3.0441,
      "step": 100380
    },
    {
      "epoch": 161.41,
      "learning_rate": 0.08386480713199357,
      "loss": 3.0467,
      "step": 100400
    },
    {
      "epoch": 161.45,
      "learning_rate": 0.08386159170112541,
      "loss": 3.0192,
      "step": 100420
    },
    {
      "epoch": 161.48,
      "learning_rate": 0.08385837627025723,
      "loss": 3.0369,
      "step": 100440
    },
    {
      "epoch": 161.51,
      "learning_rate": 0.08385516083938908,
      "loss": 3.0466,
      "step": 100460
    },
    {
      "epoch": 161.54,
      "learning_rate": 0.08385194540852091,
      "loss": 3.0491,
      "step": 100480
    },
    {
      "epoch": 161.58,
      "learning_rate": 0.08384872997765273,
      "loss": 3.0583,
      "step": 100500
    },
    {
      "epoch": 161.61,
      "learning_rate": 0.08384551454678457,
      "loss": 3.0139,
      "step": 100520
    },
    {
      "epoch": 161.64,
      "learning_rate": 0.0838422991159164,
      "loss": 3.0315,
      "step": 100540
    },
    {
      "epoch": 161.67,
      "learning_rate": 0.08383908368504825,
      "loss": 3.0542,
      "step": 100560
    },
    {
      "epoch": 161.7,
      "learning_rate": 0.08383586825418006,
      "loss": 3.1186,
      "step": 100580
    },
    {
      "epoch": 161.74,
      "learning_rate": 0.0838326528233119,
      "loss": 3.1136,
      "step": 100600
    },
    {
      "epoch": 161.77,
      "learning_rate": 0.08382943739244374,
      "loss": 3.0684,
      "step": 100620
    },
    {
      "epoch": 161.8,
      "learning_rate": 0.08382622196157556,
      "loss": 3.08,
      "step": 100640
    },
    {
      "epoch": 161.83,
      "learning_rate": 0.0838230065307074,
      "loss": 2.9972,
      "step": 100660
    },
    {
      "epoch": 161.86,
      "learning_rate": 0.08381979109983922,
      "loss": 3.0658,
      "step": 100680
    },
    {
      "epoch": 161.9,
      "learning_rate": 0.08381657566897106,
      "loss": 3.0836,
      "step": 100700
    },
    {
      "epoch": 161.93,
      "learning_rate": 0.0838133602381029,
      "loss": 3.0999,
      "step": 100720
    },
    {
      "epoch": 161.96,
      "learning_rate": 0.08381014480723473,
      "loss": 3.0499,
      "step": 100740
    },
    {
      "epoch": 161.99,
      "learning_rate": 0.08380692937636657,
      "loss": 3.0312,
      "step": 100760
    },
    {
      "epoch": 162.0,
      "eval_accuracy": {
        "accuracy": 0.36616652413900336
      },
      "eval_loss": 3.160313844680786,
      "eval_runtime": 2.6867,
      "eval_samples_per_second": 4787.713,
      "eval_steps_per_second": 74.814,
      "step": 100764
    },
    {
      "epoch": 162.03,
      "learning_rate": 0.08380371394549839,
      "loss": 3.0728,
      "step": 100780
    },
    {
      "epoch": 162.06,
      "learning_rate": 0.08380049851463024,
      "loss": 3.1107,
      "step": 100800
    },
    {
      "epoch": 162.09,
      "learning_rate": 0.08379728308376207,
      "loss": 3.0631,
      "step": 100820
    },
    {
      "epoch": 162.12,
      "learning_rate": 0.08379406765289389,
      "loss": 3.0534,
      "step": 100840
    },
    {
      "epoch": 162.15,
      "learning_rate": 0.08379085222202573,
      "loss": 2.9933,
      "step": 100860
    },
    {
      "epoch": 162.19,
      "learning_rate": 0.08378763679115755,
      "loss": 2.9925,
      "step": 100880
    },
    {
      "epoch": 162.22,
      "learning_rate": 0.08378442136028941,
      "loss": 3.0357,
      "step": 100900
    },
    {
      "epoch": 162.25,
      "learning_rate": 0.08378120592942122,
      "loss": 3.0867,
      "step": 100920
    },
    {
      "epoch": 162.28,
      "learning_rate": 0.08377799049855306,
      "loss": 3.0612,
      "step": 100940
    },
    {
      "epoch": 162.32,
      "learning_rate": 0.0837747750676849,
      "loss": 3.0159,
      "step": 100960
    },
    {
      "epoch": 162.35,
      "learning_rate": 0.08377155963681672,
      "loss": 3.0047,
      "step": 100980
    },
    {
      "epoch": 162.38,
      "learning_rate": 0.08376834420594856,
      "loss": 3.0405,
      "step": 101000
    },
    {
      "epoch": 162.41,
      "learning_rate": 0.08376512877508038,
      "loss": 3.0273,
      "step": 101020
    },
    {
      "epoch": 162.44,
      "learning_rate": 0.08376191334421222,
      "loss": 3.0149,
      "step": 101040
    },
    {
      "epoch": 162.48,
      "learning_rate": 0.08375869791334406,
      "loss": 3.0667,
      "step": 101060
    },
    {
      "epoch": 162.51,
      "learning_rate": 0.08375548248247588,
      "loss": 3.098,
      "step": 101080
    },
    {
      "epoch": 162.54,
      "learning_rate": 0.08375226705160772,
      "loss": 3.0416,
      "step": 101100
    },
    {
      "epoch": 162.57,
      "learning_rate": 0.08374905162073955,
      "loss": 3.0301,
      "step": 101120
    },
    {
      "epoch": 162.6,
      "learning_rate": 0.08374583618987139,
      "loss": 3.0378,
      "step": 101140
    },
    {
      "epoch": 162.64,
      "learning_rate": 0.08374262075900323,
      "loss": 3.0381,
      "step": 101160
    },
    {
      "epoch": 162.67,
      "learning_rate": 0.08373940532813505,
      "loss": 3.041,
      "step": 101180
    },
    {
      "epoch": 162.7,
      "learning_rate": 0.08373618989726689,
      "loss": 3.031,
      "step": 101200
    },
    {
      "epoch": 162.73,
      "learning_rate": 0.08373297446639871,
      "loss": 3.0658,
      "step": 101220
    },
    {
      "epoch": 162.77,
      "learning_rate": 0.08372975903553055,
      "loss": 3.0541,
      "step": 101240
    },
    {
      "epoch": 162.8,
      "learning_rate": 0.08372654360466238,
      "loss": 3.0381,
      "step": 101260
    },
    {
      "epoch": 162.83,
      "learning_rate": 0.08372332817379421,
      "loss": 3.0643,
      "step": 101280
    },
    {
      "epoch": 162.86,
      "learning_rate": 0.08372011274292605,
      "loss": 3.0611,
      "step": 101300
    },
    {
      "epoch": 162.89,
      "learning_rate": 0.08371689731205788,
      "loss": 3.0895,
      "step": 101320
    },
    {
      "epoch": 162.93,
      "learning_rate": 0.08371368188118972,
      "loss": 3.0753,
      "step": 101340
    },
    {
      "epoch": 162.96,
      "learning_rate": 0.08371046645032154,
      "loss": 3.0854,
      "step": 101360
    },
    {
      "epoch": 162.99,
      "learning_rate": 0.08370725101945338,
      "loss": 3.0917,
      "step": 101380
    },
    {
      "epoch": 163.0,
      "eval_accuracy": {
        "accuracy": 0.37067558112415455
      },
      "eval_loss": 3.1354763507843018,
      "eval_runtime": 2.6351,
      "eval_samples_per_second": 4881.375,
      "eval_steps_per_second": 76.277,
      "step": 101386
    },
    {
      "epoch": 163.02,
      "learning_rate": 0.08370403558858522,
      "loss": 3.0837,
      "step": 101400
    },
    {
      "epoch": 163.05,
      "learning_rate": 0.08370082015771704,
      "loss": 3.0991,
      "step": 101420
    },
    {
      "epoch": 163.09,
      "learning_rate": 0.08369760472684888,
      "loss": 3.093,
      "step": 101440
    },
    {
      "epoch": 163.12,
      "learning_rate": 0.0836943892959807,
      "loss": 3.0503,
      "step": 101460
    },
    {
      "epoch": 163.15,
      "learning_rate": 0.08369117386511254,
      "loss": 3.0354,
      "step": 101480
    },
    {
      "epoch": 163.18,
      "learning_rate": 0.08368795843424438,
      "loss": 3.0955,
      "step": 101500
    },
    {
      "epoch": 163.22,
      "learning_rate": 0.08368474300337621,
      "loss": 3.0685,
      "step": 101520
    },
    {
      "epoch": 163.25,
      "learning_rate": 0.08368152757250805,
      "loss": 3.107,
      "step": 101540
    },
    {
      "epoch": 163.28,
      "learning_rate": 0.08367831214163987,
      "loss": 3.0987,
      "step": 101560
    },
    {
      "epoch": 163.31,
      "learning_rate": 0.08367509671077171,
      "loss": 3.0487,
      "step": 101580
    },
    {
      "epoch": 163.34,
      "learning_rate": 0.08367188127990353,
      "loss": 3.0382,
      "step": 101600
    },
    {
      "epoch": 163.38,
      "learning_rate": 0.08366866584903537,
      "loss": 3.0629,
      "step": 101620
    },
    {
      "epoch": 163.41,
      "learning_rate": 0.08366545041816721,
      "loss": 3.066,
      "step": 101640
    },
    {
      "epoch": 163.44,
      "learning_rate": 0.08366223498729904,
      "loss": 3.0711,
      "step": 101660
    },
    {
      "epoch": 163.47,
      "learning_rate": 0.08365901955643087,
      "loss": 3.0563,
      "step": 101680
    },
    {
      "epoch": 163.5,
      "learning_rate": 0.0836558041255627,
      "loss": 3.0216,
      "step": 101700
    },
    {
      "epoch": 163.54,
      "learning_rate": 0.08365258869469454,
      "loss": 3.0197,
      "step": 101720
    },
    {
      "epoch": 163.57,
      "learning_rate": 0.08364937326382638,
      "loss": 3.0154,
      "step": 101740
    },
    {
      "epoch": 163.6,
      "learning_rate": 0.0836461578329582,
      "loss": 3.0482,
      "step": 101760
    },
    {
      "epoch": 163.63,
      "learning_rate": 0.08364294240209004,
      "loss": 3.1309,
      "step": 101780
    },
    {
      "epoch": 163.67,
      "learning_rate": 0.08363972697122186,
      "loss": 3.0525,
      "step": 101800
    },
    {
      "epoch": 163.7,
      "learning_rate": 0.0836365115403537,
      "loss": 3.0472,
      "step": 101820
    },
    {
      "epoch": 163.73,
      "learning_rate": 0.08363329610948554,
      "loss": 3.0967,
      "step": 101840
    },
    {
      "epoch": 163.76,
      "learning_rate": 0.08363024145016078,
      "loss": 3.0455,
      "step": 101860
    },
    {
      "epoch": 163.79,
      "learning_rate": 0.08362702601929262,
      "loss": 3.0423,
      "step": 101880
    },
    {
      "epoch": 163.83,
      "learning_rate": 0.08362381058842444,
      "loss": 3.0182,
      "step": 101900
    },
    {
      "epoch": 163.86,
      "learning_rate": 0.08362059515755628,
      "loss": 3.043,
      "step": 101920
    },
    {
      "epoch": 163.89,
      "learning_rate": 0.0836173797266881,
      "loss": 3.0377,
      "step": 101940
    },
    {
      "epoch": 163.92,
      "learning_rate": 0.08361416429581993,
      "loss": 3.0656,
      "step": 101960
    },
    {
      "epoch": 163.95,
      "learning_rate": 0.08361094886495178,
      "loss": 3.0342,
      "step": 101980
    },
    {
      "epoch": 163.99,
      "learning_rate": 0.0836077334340836,
      "loss": 3.0658,
      "step": 102000
    },
    {
      "epoch": 164.0,
      "eval_accuracy": {
        "accuracy": 0.3740962450439244
      },
      "eval_loss": 3.1272153854370117,
      "eval_runtime": 2.6298,
      "eval_samples_per_second": 4891.305,
      "eval_steps_per_second": 76.433,
      "step": 102008
    },
    {
      "epoch": 164.02,
      "learning_rate": 0.08360451800321544,
      "loss": 3.0501,
      "step": 102020
    },
    {
      "epoch": 164.05,
      "learning_rate": 0.08360130257234727,
      "loss": 3.0868,
      "step": 102040
    },
    {
      "epoch": 164.08,
      "learning_rate": 0.0835980871414791,
      "loss": 3.0441,
      "step": 102060
    },
    {
      "epoch": 164.12,
      "learning_rate": 0.08359487171061095,
      "loss": 3.0391,
      "step": 102080
    },
    {
      "epoch": 164.15,
      "learning_rate": 0.08359165627974277,
      "loss": 3.0547,
      "step": 102100
    },
    {
      "epoch": 164.18,
      "learning_rate": 0.08358844084887461,
      "loss": 3.0488,
      "step": 102120
    },
    {
      "epoch": 164.21,
      "learning_rate": 0.08358522541800643,
      "loss": 3.093,
      "step": 102140
    },
    {
      "epoch": 164.24,
      "learning_rate": 0.08358200998713826,
      "loss": 3.0609,
      "step": 102160
    },
    {
      "epoch": 164.28,
      "learning_rate": 0.08357879455627011,
      "loss": 3.085,
      "step": 102180
    },
    {
      "epoch": 164.31,
      "learning_rate": 0.08357557912540194,
      "loss": 3.0517,
      "step": 102200
    },
    {
      "epoch": 164.34,
      "learning_rate": 0.08357236369453377,
      "loss": 3.0494,
      "step": 102220
    },
    {
      "epoch": 164.37,
      "learning_rate": 0.0835691482636656,
      "loss": 3.0309,
      "step": 102240
    },
    {
      "epoch": 164.41,
      "learning_rate": 0.08356593283279742,
      "loss": 3.0199,
      "step": 102260
    },
    {
      "epoch": 164.44,
      "learning_rate": 0.08356271740192926,
      "loss": 3.039,
      "step": 102280
    },
    {
      "epoch": 164.47,
      "learning_rate": 0.08355950197106109,
      "loss": 3.0479,
      "step": 102300
    },
    {
      "epoch": 164.5,
      "learning_rate": 0.08355628654019294,
      "loss": 3.0333,
      "step": 102320
    },
    {
      "epoch": 164.53,
      "learning_rate": 0.08355307110932476,
      "loss": 3.0491,
      "step": 102340
    },
    {
      "epoch": 164.57,
      "learning_rate": 0.0835498556784566,
      "loss": 3.0206,
      "step": 102360
    },
    {
      "epoch": 164.6,
      "learning_rate": 0.08354664024758843,
      "loss": 3.0641,
      "step": 102380
    },
    {
      "epoch": 164.63,
      "learning_rate": 0.08354342481672025,
      "loss": 3.03,
      "step": 102400
    },
    {
      "epoch": 164.66,
      "learning_rate": 0.0835402093858521,
      "loss": 3.0795,
      "step": 102420
    },
    {
      "epoch": 164.69,
      "learning_rate": 0.08353699395498393,
      "loss": 3.0262,
      "step": 102440
    },
    {
      "epoch": 164.73,
      "learning_rate": 0.08353377852411577,
      "loss": 3.028,
      "step": 102460
    },
    {
      "epoch": 164.76,
      "learning_rate": 0.08353056309324759,
      "loss": 3.0377,
      "step": 102480
    },
    {
      "epoch": 164.79,
      "learning_rate": 0.08352734766237942,
      "loss": 3.035,
      "step": 102500
    },
    {
      "epoch": 164.82,
      "learning_rate": 0.08352413223151127,
      "loss": 3.0433,
      "step": 102520
    },
    {
      "epoch": 164.86,
      "learning_rate": 0.0835209168006431,
      "loss": 3.1049,
      "step": 102540
    },
    {
      "epoch": 164.89,
      "learning_rate": 0.08351770136977493,
      "loss": 3.1121,
      "step": 102560
    },
    {
      "epoch": 164.92,
      "learning_rate": 0.08351448593890676,
      "loss": 3.0907,
      "step": 102580
    },
    {
      "epoch": 164.95,
      "learning_rate": 0.08351127050803858,
      "loss": 3.0649,
      "step": 102600
    },
    {
      "epoch": 164.98,
      "learning_rate": 0.08350805507717043,
      "loss": 3.084,
      "step": 102620
    },
    {
      "epoch": 165.0,
      "eval_accuracy": {
        "accuracy": 0.3722304283604136
      },
      "eval_loss": 3.1131651401519775,
      "eval_runtime": 2.8288,
      "eval_samples_per_second": 4547.098,
      "eval_steps_per_second": 71.054,
      "step": 102630
    },
    {
      "epoch": 165.02,
      "learning_rate": 0.08350483964630225,
      "loss": 3.0432,
      "step": 102640
    },
    {
      "epoch": 165.05,
      "learning_rate": 0.0835016242154341,
      "loss": 3.0676,
      "step": 102660
    },
    {
      "epoch": 165.08,
      "learning_rate": 0.08349840878456592,
      "loss": 3.0655,
      "step": 102680
    },
    {
      "epoch": 165.11,
      "learning_rate": 0.08349519335369775,
      "loss": 3.0426,
      "step": 102700
    },
    {
      "epoch": 165.14,
      "learning_rate": 0.08349197792282959,
      "loss": 3.0726,
      "step": 102720
    },
    {
      "epoch": 165.18,
      "learning_rate": 0.08348876249196141,
      "loss": 3.0792,
      "step": 102740
    },
    {
      "epoch": 165.21,
      "learning_rate": 0.08348554706109326,
      "loss": 3.0478,
      "step": 102760
    },
    {
      "epoch": 165.24,
      "learning_rate": 0.08348233163022509,
      "loss": 3.032,
      "step": 102780
    },
    {
      "epoch": 165.27,
      "learning_rate": 0.08347911619935691,
      "loss": 3.0452,
      "step": 102800
    },
    {
      "epoch": 165.31,
      "learning_rate": 0.08347590076848875,
      "loss": 3.0072,
      "step": 102820
    },
    {
      "epoch": 165.34,
      "learning_rate": 0.08347268533762058,
      "loss": 3.0409,
      "step": 102840
    },
    {
      "epoch": 165.37,
      "learning_rate": 0.08346946990675243,
      "loss": 3.057,
      "step": 102860
    },
    {
      "epoch": 165.4,
      "learning_rate": 0.08346625447588425,
      "loss": 3.0464,
      "step": 102880
    },
    {
      "epoch": 165.43,
      "learning_rate": 0.08346303904501608,
      "loss": 3.0458,
      "step": 102900
    },
    {
      "epoch": 165.47,
      "learning_rate": 0.08345982361414792,
      "loss": 3.0396,
      "step": 102920
    },
    {
      "epoch": 165.5,
      "learning_rate": 0.08345660818327974,
      "loss": 3.0499,
      "step": 102940
    },
    {
      "epoch": 165.53,
      "learning_rate": 0.08345339275241159,
      "loss": 3.0859,
      "step": 102960
    },
    {
      "epoch": 165.56,
      "learning_rate": 0.0834501773215434,
      "loss": 3.1005,
      "step": 102980
    },
    {
      "epoch": 165.59,
      "learning_rate": 0.08344696189067526,
      "loss": 3.1068,
      "step": 103000
    },
    {
      "epoch": 165.63,
      "learning_rate": 0.08344374645980708,
      "loss": 3.0768,
      "step": 103020
    },
    {
      "epoch": 165.66,
      "learning_rate": 0.0834405310289389,
      "loss": 3.0539,
      "step": 103040
    },
    {
      "epoch": 165.69,
      "learning_rate": 0.08343731559807074,
      "loss": 3.0412,
      "step": 103060
    },
    {
      "epoch": 165.72,
      "learning_rate": 0.08343410016720257,
      "loss": 3.0211,
      "step": 103080
    },
    {
      "epoch": 165.76,
      "learning_rate": 0.08343088473633442,
      "loss": 3.0714,
      "step": 103100
    },
    {
      "epoch": 165.79,
      "learning_rate": 0.08342766930546625,
      "loss": 3.0408,
      "step": 103120
    },
    {
      "epoch": 165.82,
      "learning_rate": 0.08342445387459807,
      "loss": 3.0016,
      "step": 103140
    },
    {
      "epoch": 165.85,
      "learning_rate": 0.08342123844372991,
      "loss": 3.0491,
      "step": 103160
    },
    {
      "epoch": 165.88,
      "learning_rate": 0.08341802301286173,
      "loss": 3.0524,
      "step": 103180
    },
    {
      "epoch": 165.92,
      "learning_rate": 0.08341480758199359,
      "loss": 3.076,
      "step": 103200
    },
    {
      "epoch": 165.95,
      "learning_rate": 0.08341159215112541,
      "loss": 3.0473,
      "step": 103220
    },
    {
      "epoch": 165.98,
      "learning_rate": 0.08340837672025724,
      "loss": 3.0564,
      "step": 103240
    },
    {
      "epoch": 166.0,
      "eval_accuracy": {
        "accuracy": 0.37487366866205396
      },
      "eval_loss": 3.1747934818267822,
      "eval_runtime": 2.6156,
      "eval_samples_per_second": 4917.892,
      "eval_steps_per_second": 76.848,
      "step": 103252
    },
    {
      "epoch": 166.01,
      "learning_rate": 0.08340516128938907,
      "loss": 3.0938,
      "step": 103260
    },
    {
      "epoch": 166.05,
      "learning_rate": 0.0834019458585209,
      "loss": 3.0313,
      "step": 103280
    },
    {
      "epoch": 166.08,
      "learning_rate": 0.08339873042765275,
      "loss": 3.0459,
      "step": 103300
    },
    {
      "epoch": 166.11,
      "learning_rate": 0.08339551499678456,
      "loss": 3.0482,
      "step": 103320
    },
    {
      "epoch": 166.14,
      "learning_rate": 0.0833922995659164,
      "loss": 3.05,
      "step": 103340
    },
    {
      "epoch": 166.17,
      "learning_rate": 0.08338908413504824,
      "loss": 3.0442,
      "step": 103360
    },
    {
      "epoch": 166.21,
      "learning_rate": 0.08338586870418006,
      "loss": 3.0273,
      "step": 103380
    },
    {
      "epoch": 166.24,
      "learning_rate": 0.0833826532733119,
      "loss": 3.0696,
      "step": 103400
    },
    {
      "epoch": 166.27,
      "learning_rate": 0.08337943784244373,
      "loss": 3.0685,
      "step": 103420
    },
    {
      "epoch": 166.3,
      "learning_rate": 0.08337622241157557,
      "loss": 3.0392,
      "step": 103440
    },
    {
      "epoch": 166.33,
      "learning_rate": 0.0833730069807074,
      "loss": 3.0464,
      "step": 103460
    },
    {
      "epoch": 166.37,
      "learning_rate": 0.08336979154983923,
      "loss": 3.049,
      "step": 103480
    },
    {
      "epoch": 166.4,
      "learning_rate": 0.08336657611897107,
      "loss": 3.0506,
      "step": 103500
    },
    {
      "epoch": 166.43,
      "learning_rate": 0.08336336068810289,
      "loss": 3.0633,
      "step": 103520
    },
    {
      "epoch": 166.46,
      "learning_rate": 0.08336014525723474,
      "loss": 3.0484,
      "step": 103540
    },
    {
      "epoch": 166.5,
      "learning_rate": 0.08335692982636657,
      "loss": 3.0297,
      "step": 103560
    },
    {
      "epoch": 166.53,
      "learning_rate": 0.0833537143954984,
      "loss": 3.0456,
      "step": 103580
    },
    {
      "epoch": 166.56,
      "learning_rate": 0.08335049896463023,
      "loss": 3.0297,
      "step": 103600
    },
    {
      "epoch": 166.59,
      "learning_rate": 0.08334728353376206,
      "loss": 3.0707,
      "step": 103620
    },
    {
      "epoch": 166.62,
      "learning_rate": 0.08334406810289391,
      "loss": 3.0474,
      "step": 103640
    },
    {
      "epoch": 166.66,
      "learning_rate": 0.08334085267202572,
      "loss": 3.0263,
      "step": 103660
    },
    {
      "epoch": 166.69,
      "learning_rate": 0.08333763724115756,
      "loss": 3.0578,
      "step": 103680
    },
    {
      "epoch": 166.72,
      "learning_rate": 0.0833344218102894,
      "loss": 3.0498,
      "step": 103700
    },
    {
      "epoch": 166.75,
      "learning_rate": 0.08333120637942122,
      "loss": 3.0586,
      "step": 103720
    },
    {
      "epoch": 166.78,
      "learning_rate": 0.08332799094855306,
      "loss": 3.053,
      "step": 103740
    },
    {
      "epoch": 166.82,
      "learning_rate": 0.08332477551768488,
      "loss": 3.0294,
      "step": 103760
    },
    {
      "epoch": 166.85,
      "learning_rate": 0.08332156008681672,
      "loss": 3.0244,
      "step": 103780
    },
    {
      "epoch": 166.88,
      "learning_rate": 0.08331834465594856,
      "loss": 3.0648,
      "step": 103800
    },
    {
      "epoch": 166.91,
      "learning_rate": 0.08331512922508039,
      "loss": 3.049,
      "step": 103820
    },
    {
      "epoch": 166.95,
      "learning_rate": 0.08331191379421223,
      "loss": 3.0398,
      "step": 103840
    },
    {
      "epoch": 166.98,
      "learning_rate": 0.08330869836334405,
      "loss": 3.016,
      "step": 103860
    },
    {
      "epoch": 167.0,
      "eval_accuracy": {
        "accuracy": 0.3686542797170178
      },
      "eval_loss": 3.178227424621582,
      "eval_runtime": 2.8649,
      "eval_samples_per_second": 4489.853,
      "eval_steps_per_second": 70.159,
      "step": 103874
    },
    {
      "epoch": 167.01,
      "learning_rate": 0.08330548293247589,
      "loss": 3.0221,
      "step": 103880
    },
    {
      "epoch": 167.04,
      "learning_rate": 0.08330226750160773,
      "loss": 3.0423,
      "step": 103900
    },
    {
      "epoch": 167.07,
      "learning_rate": 0.08329921284228296,
      "loss": 3.0729,
      "step": 103920
    },
    {
      "epoch": 167.11,
      "learning_rate": 0.0832959974114148,
      "loss": 3.1004,
      "step": 103940
    },
    {
      "epoch": 167.14,
      "learning_rate": 0.08329278198054663,
      "loss": 3.0597,
      "step": 103960
    },
    {
      "epoch": 167.17,
      "learning_rate": 0.08328956654967846,
      "loss": 3.0621,
      "step": 103980
    },
    {
      "epoch": 167.2,
      "learning_rate": 0.08328635111881029,
      "loss": 3.0154,
      "step": 104000
    },
    {
      "epoch": 167.23,
      "learning_rate": 0.08328313568794213,
      "loss": 3.036,
      "step": 104020
    },
    {
      "epoch": 167.27,
      "learning_rate": 0.08327992025707397,
      "loss": 3.0478,
      "step": 104040
    },
    {
      "epoch": 167.3,
      "learning_rate": 0.08327670482620579,
      "loss": 3.0737,
      "step": 104060
    },
    {
      "epoch": 167.33,
      "learning_rate": 0.08327348939533763,
      "loss": 3.0516,
      "step": 104080
    },
    {
      "epoch": 167.36,
      "learning_rate": 0.08327027396446945,
      "loss": 3.044,
      "step": 104100
    },
    {
      "epoch": 167.4,
      "learning_rate": 0.08326705853360129,
      "loss": 3.0655,
      "step": 104120
    },
    {
      "epoch": 167.43,
      "learning_rate": 0.08326384310273313,
      "loss": 3.0407,
      "step": 104140
    },
    {
      "epoch": 167.46,
      "learning_rate": 0.08326062767186496,
      "loss": 3.0164,
      "step": 104160
    },
    {
      "epoch": 167.49,
      "learning_rate": 0.0832574122409968,
      "loss": 3.0409,
      "step": 104180
    },
    {
      "epoch": 167.52,
      "learning_rate": 0.08325419681012862,
      "loss": 3.0505,
      "step": 104200
    },
    {
      "epoch": 167.56,
      "learning_rate": 0.08325098137926046,
      "loss": 3.0509,
      "step": 104220
    },
    {
      "epoch": 167.59,
      "learning_rate": 0.0832477659483923,
      "loss": 3.0422,
      "step": 104240
    },
    {
      "epoch": 167.62,
      "learning_rate": 0.08324455051752412,
      "loss": 3.0602,
      "step": 104260
    },
    {
      "epoch": 167.65,
      "learning_rate": 0.08324133508665596,
      "loss": 3.0931,
      "step": 104280
    },
    {
      "epoch": 167.68,
      "learning_rate": 0.08323811965578778,
      "loss": 3.0781,
      "step": 104300
    },
    {
      "epoch": 167.72,
      "learning_rate": 0.08323490422491962,
      "loss": 3.0009,
      "step": 104320
    },
    {
      "epoch": 167.75,
      "learning_rate": 0.08323168879405145,
      "loss": 3.0341,
      "step": 104340
    },
    {
      "epoch": 167.78,
      "learning_rate": 0.08322847336318327,
      "loss": 3.0803,
      "step": 104360
    },
    {
      "epoch": 167.81,
      "learning_rate": 0.08322525793231512,
      "loss": 3.0293,
      "step": 104380
    },
    {
      "epoch": 167.85,
      "learning_rate": 0.08322204250144695,
      "loss": 3.0686,
      "step": 104400
    },
    {
      "epoch": 167.88,
      "learning_rate": 0.08321882707057879,
      "loss": 3.0339,
      "step": 104420
    },
    {
      "epoch": 167.91,
      "learning_rate": 0.08321561163971061,
      "loss": 3.0315,
      "step": 104440
    },
    {
      "epoch": 167.94,
      "learning_rate": 0.08321239620884244,
      "loss": 3.0171,
      "step": 104460
    },
    {
      "epoch": 167.97,
      "learning_rate": 0.08320918077797429,
      "loss": 3.025,
      "step": 104480
    },
    {
      "epoch": 168.0,
      "eval_accuracy": {
        "accuracy": 0.37876078675270153
      },
      "eval_loss": 3.1110594272613525,
      "eval_runtime": 2.6632,
      "eval_samples_per_second": 4829.895,
      "eval_steps_per_second": 75.473,
      "step": 104496
    },
    {
      "epoch": 168.01,
      "learning_rate": 0.08320596534710611,
      "loss": 3.0666,
      "step": 104500
    },
    {
      "epoch": 168.04,
      "learning_rate": 0.08320274991623795,
      "loss": 3.0051,
      "step": 104520
    },
    {
      "epoch": 168.07,
      "learning_rate": 0.08319953448536978,
      "loss": 3.0147,
      "step": 104540
    },
    {
      "epoch": 168.1,
      "learning_rate": 0.08319631905450162,
      "loss": 3.0221,
      "step": 104560
    },
    {
      "epoch": 168.14,
      "learning_rate": 0.08319310362363345,
      "loss": 3.0906,
      "step": 104580
    },
    {
      "epoch": 168.17,
      "learning_rate": 0.08318988819276528,
      "loss": 3.0551,
      "step": 104600
    },
    {
      "epoch": 168.2,
      "learning_rate": 0.08318667276189712,
      "loss": 3.054,
      "step": 104620
    },
    {
      "epoch": 168.23,
      "learning_rate": 0.08318345733102894,
      "loss": 3.0361,
      "step": 104640
    },
    {
      "epoch": 168.26,
      "learning_rate": 0.08318024190016078,
      "loss": 3.0542,
      "step": 104660
    },
    {
      "epoch": 168.3,
      "learning_rate": 0.0831770264692926,
      "loss": 3.0252,
      "step": 104680
    },
    {
      "epoch": 168.33,
      "learning_rate": 0.08317381103842443,
      "loss": 3.0677,
      "step": 104700
    },
    {
      "epoch": 168.36,
      "learning_rate": 0.08317059560755628,
      "loss": 3.0437,
      "step": 104720
    },
    {
      "epoch": 168.39,
      "learning_rate": 0.08316738017668811,
      "loss": 3.0778,
      "step": 104740
    },
    {
      "epoch": 168.42,
      "learning_rate": 0.08316416474581995,
      "loss": 3.041,
      "step": 104760
    },
    {
      "epoch": 168.46,
      "learning_rate": 0.08316094931495177,
      "loss": 3.0497,
      "step": 104780
    },
    {
      "epoch": 168.49,
      "learning_rate": 0.0831577338840836,
      "loss": 3.0228,
      "step": 104800
    },
    {
      "epoch": 168.52,
      "learning_rate": 0.08315451845321545,
      "loss": 3.0424,
      "step": 104820
    },
    {
      "epoch": 168.55,
      "learning_rate": 0.08315130302234727,
      "loss": 3.0372,
      "step": 104840
    },
    {
      "epoch": 168.59,
      "learning_rate": 0.08314808759147911,
      "loss": 2.9968,
      "step": 104860
    },
    {
      "epoch": 168.62,
      "learning_rate": 0.08314487216061094,
      "loss": 3.0335,
      "step": 104880
    },
    {
      "epoch": 168.65,
      "learning_rate": 0.08314165672974276,
      "loss": 3.0521,
      "step": 104900
    },
    {
      "epoch": 168.68,
      "learning_rate": 0.08313844129887461,
      "loss": 3.0784,
      "step": 104920
    },
    {
      "epoch": 168.71,
      "learning_rate": 0.08313522586800644,
      "loss": 3.0537,
      "step": 104940
    },
    {
      "epoch": 168.75,
      "learning_rate": 0.08313201043713828,
      "loss": 3.0386,
      "step": 104960
    },
    {
      "epoch": 168.78,
      "learning_rate": 0.0831287950062701,
      "loss": 3.0856,
      "step": 104980
    },
    {
      "epoch": 168.81,
      "learning_rate": 0.08312557957540193,
      "loss": 3.0492,
      "step": 105000
    },
    {
      "epoch": 168.84,
      "learning_rate": 0.08312236414453376,
      "loss": 3.0592,
      "step": 105020
    },
    {
      "epoch": 168.87,
      "learning_rate": 0.08311914871366559,
      "loss": 3.0276,
      "step": 105040
    },
    {
      "epoch": 168.91,
      "learning_rate": 0.08311593328279744,
      "loss": 3.0328,
      "step": 105060
    },
    {
      "epoch": 168.94,
      "learning_rate": 0.08311271785192927,
      "loss": 3.0916,
      "step": 105080
    },
    {
      "epoch": 168.97,
      "learning_rate": 0.08310950242106109,
      "loss": 3.0754,
      "step": 105100
    },
    {
      "epoch": 169.0,
      "eval_accuracy": {
        "accuracy": 0.37230817072222655
      },
      "eval_loss": 3.1144354343414307,
      "eval_runtime": 3.2834,
      "eval_samples_per_second": 3917.56,
      "eval_steps_per_second": 61.217,
      "step": 105118
    },
    {
      "epoch": 169.0,
      "learning_rate": 0.08310628699019293,
      "loss": 3.0545,
      "step": 105120
    },
    {
      "epoch": 169.04,
      "learning_rate": 0.08310307155932475,
      "loss": 3.0363,
      "step": 105140
    },
    {
      "epoch": 169.07,
      "learning_rate": 0.0830998561284566,
      "loss": 3.035,
      "step": 105160
    },
    {
      "epoch": 169.1,
      "learning_rate": 0.08309664069758843,
      "loss": 2.9925,
      "step": 105180
    },
    {
      "epoch": 169.13,
      "learning_rate": 0.08309342526672027,
      "loss": 3.0342,
      "step": 105200
    },
    {
      "epoch": 169.16,
      "learning_rate": 0.0830902098358521,
      "loss": 3.087,
      "step": 105220
    },
    {
      "epoch": 169.2,
      "learning_rate": 0.08308699440498392,
      "loss": 3.1329,
      "step": 105240
    },
    {
      "epoch": 169.23,
      "learning_rate": 0.08308377897411577,
      "loss": 3.0216,
      "step": 105260
    },
    {
      "epoch": 169.26,
      "learning_rate": 0.0830805635432476,
      "loss": 3.0395,
      "step": 105280
    },
    {
      "epoch": 169.29,
      "learning_rate": 0.08307734811237943,
      "loss": 3.0213,
      "step": 105300
    },
    {
      "epoch": 169.32,
      "learning_rate": 0.08307413268151126,
      "loss": 3.0471,
      "step": 105320
    },
    {
      "epoch": 169.36,
      "learning_rate": 0.08307091725064308,
      "loss": 3.0748,
      "step": 105340
    },
    {
      "epoch": 169.39,
      "learning_rate": 0.08306770181977494,
      "loss": 3.0605,
      "step": 105360
    },
    {
      "epoch": 169.42,
      "learning_rate": 0.08306448638890675,
      "loss": 3.0399,
      "step": 105380
    },
    {
      "epoch": 169.45,
      "learning_rate": 0.0830612709580386,
      "loss": 3.0504,
      "step": 105400
    },
    {
      "epoch": 169.49,
      "learning_rate": 0.08305805552717042,
      "loss": 3.0419,
      "step": 105420
    },
    {
      "epoch": 169.52,
      "learning_rate": 0.08305484009630225,
      "loss": 3.0169,
      "step": 105440
    },
    {
      "epoch": 169.55,
      "learning_rate": 0.08305162466543409,
      "loss": 3.0236,
      "step": 105460
    },
    {
      "epoch": 169.58,
      "learning_rate": 0.08304840923456591,
      "loss": 3.0657,
      "step": 105480
    },
    {
      "epoch": 169.61,
      "learning_rate": 0.08304519380369776,
      "loss": 3.0352,
      "step": 105500
    },
    {
      "epoch": 169.65,
      "learning_rate": 0.08304197837282959,
      "loss": 3.0445,
      "step": 105520
    },
    {
      "epoch": 169.68,
      "learning_rate": 0.08303876294196141,
      "loss": 3.0246,
      "step": 105540
    },
    {
      "epoch": 169.71,
      "learning_rate": 0.08303554751109325,
      "loss": 3.0624,
      "step": 105560
    },
    {
      "epoch": 169.74,
      "learning_rate": 0.08303233208022508,
      "loss": 3.0437,
      "step": 105580
    },
    {
      "epoch": 169.77,
      "learning_rate": 0.08302911664935693,
      "loss": 3.0495,
      "step": 105600
    },
    {
      "epoch": 169.81,
      "learning_rate": 0.08302590121848875,
      "loss": 3.061,
      "step": 105620
    },
    {
      "epoch": 169.84,
      "learning_rate": 0.08302268578762058,
      "loss": 3.0246,
      "step": 105640
    },
    {
      "epoch": 169.87,
      "learning_rate": 0.08301947035675242,
      "loss": 3.0141,
      "step": 105660
    },
    {
      "epoch": 169.9,
      "learning_rate": 0.08301625492588424,
      "loss": 3.0414,
      "step": 105680
    },
    {
      "epoch": 169.94,
      "learning_rate": 0.0830130394950161,
      "loss": 3.0331,
      "step": 105700
    },
    {
      "epoch": 169.97,
      "learning_rate": 0.0830098240641479,
      "loss": 3.0333,
      "step": 105720
    },
    {
      "epoch": 170.0,
      "learning_rate": 0.08300660863327976,
      "loss": 3.0805,
      "step": 105740
    },
    {
      "epoch": 170.0,
      "eval_accuracy": {
        "accuracy": 0.36554458524449973
      },
      "eval_loss": 3.160930871963501,
      "eval_runtime": 3.1103,
      "eval_samples_per_second": 4135.641,
      "eval_steps_per_second": 64.624,
      "step": 105740
    },
    {
      "epoch": 170.03,
      "learning_rate": 0.08300339320241158,
      "loss": 3.0702,
      "step": 105760
    },
    {
      "epoch": 170.06,
      "learning_rate": 0.0830001777715434,
      "loss": 3.0359,
      "step": 105780
    },
    {
      "epoch": 170.1,
      "learning_rate": 0.08299696234067525,
      "loss": 3.099,
      "step": 105800
    },
    {
      "epoch": 170.13,
      "learning_rate": 0.08299374690980707,
      "loss": 3.0636,
      "step": 105820
    },
    {
      "epoch": 170.16,
      "learning_rate": 0.08299053147893892,
      "loss": 3.0459,
      "step": 105840
    },
    {
      "epoch": 170.19,
      "learning_rate": 0.08298731604807075,
      "loss": 3.0655,
      "step": 105860
    },
    {
      "epoch": 170.23,
      "learning_rate": 0.08298410061720257,
      "loss": 3.0394,
      "step": 105880
    },
    {
      "epoch": 170.26,
      "learning_rate": 0.08298088518633441,
      "loss": 3.015,
      "step": 105900
    },
    {
      "epoch": 170.29,
      "learning_rate": 0.08297766975546624,
      "loss": 2.9802,
      "step": 105920
    },
    {
      "epoch": 170.32,
      "learning_rate": 0.08297445432459809,
      "loss": 3.0476,
      "step": 105940
    },
    {
      "epoch": 170.35,
      "learning_rate": 0.08297123889372991,
      "loss": 3.0559,
      "step": 105960
    },
    {
      "epoch": 170.39,
      "learning_rate": 0.08296802346286174,
      "loss": 3.0691,
      "step": 105980
    },
    {
      "epoch": 170.42,
      "learning_rate": 0.08296480803199358,
      "loss": 3.0266,
      "step": 106000
    },
    {
      "epoch": 170.45,
      "learning_rate": 0.0829615926011254,
      "loss": 3.0222,
      "step": 106020
    },
    {
      "epoch": 170.48,
      "learning_rate": 0.08295837717025725,
      "loss": 3.0314,
      "step": 106040
    },
    {
      "epoch": 170.51,
      "learning_rate": 0.08295516173938906,
      "loss": 3.0372,
      "step": 106060
    },
    {
      "epoch": 170.55,
      "learning_rate": 0.0829519463085209,
      "loss": 3.0656,
      "step": 106080
    },
    {
      "epoch": 170.58,
      "learning_rate": 0.08294873087765274,
      "loss": 3.0416,
      "step": 106100
    },
    {
      "epoch": 170.61,
      "learning_rate": 0.08294551544678457,
      "loss": 3.0671,
      "step": 106120
    },
    {
      "epoch": 170.64,
      "learning_rate": 0.0829423000159164,
      "loss": 3.058,
      "step": 106140
    },
    {
      "epoch": 170.68,
      "learning_rate": 0.08293908458504823,
      "loss": 3.0642,
      "step": 106160
    },
    {
      "epoch": 170.71,
      "learning_rate": 0.08293586915418007,
      "loss": 2.9968,
      "step": 106180
    },
    {
      "epoch": 170.74,
      "learning_rate": 0.0829326537233119,
      "loss": 3.0606,
      "step": 106200
    },
    {
      "epoch": 170.77,
      "learning_rate": 0.08292943829244373,
      "loss": 3.025,
      "step": 106220
    },
    {
      "epoch": 170.8,
      "learning_rate": 0.08292622286157557,
      "loss": 3.0038,
      "step": 106240
    },
    {
      "epoch": 170.84,
      "learning_rate": 0.0829230074307074,
      "loss": 3.0336,
      "step": 106260
    },
    {
      "epoch": 170.87,
      "learning_rate": 0.08291979199983923,
      "loss": 3.0254,
      "step": 106280
    },
    {
      "epoch": 170.9,
      "learning_rate": 0.08291657656897107,
      "loss": 3.0136,
      "step": 106300
    },
    {
      "epoch": 170.93,
      "learning_rate": 0.0829133611381029,
      "loss": 3.0456,
      "step": 106320
    },
    {
      "epoch": 170.96,
      "learning_rate": 0.08291014570723473,
      "loss": 3.0666,
      "step": 106340
    },
    {
      "epoch": 171.0,
      "learning_rate": 0.08290693027636656,
      "loss": 3.0913,
      "step": 106360
    },
    {
      "epoch": 171.0,
      "eval_accuracy": {
        "accuracy": 0.3691984762497085
      },
      "eval_loss": 3.168287992477417,
      "eval_runtime": 3.2098,
      "eval_samples_per_second": 4007.398,
      "eval_steps_per_second": 62.62,
      "step": 106362
    },
    {
      "epoch": 171.03,
      "learning_rate": 0.08290371484549841,
      "loss": 3.0502,
      "step": 106380
    },
    {
      "epoch": 171.06,
      "learning_rate": 0.08290049941463022,
      "loss": 3.0214,
      "step": 106400
    },
    {
      "epoch": 171.09,
      "learning_rate": 0.08289728398376206,
      "loss": 3.0716,
      "step": 106420
    },
    {
      "epoch": 171.13,
      "learning_rate": 0.0828940685528939,
      "loss": 3.0252,
      "step": 106440
    },
    {
      "epoch": 171.16,
      "learning_rate": 0.08289085312202572,
      "loss": 3.101,
      "step": 106460
    },
    {
      "epoch": 171.19,
      "learning_rate": 0.08288763769115756,
      "loss": 3.0333,
      "step": 106480
    },
    {
      "epoch": 171.22,
      "learning_rate": 0.08288442226028939,
      "loss": 3.0079,
      "step": 106500
    },
    {
      "epoch": 171.25,
      "learning_rate": 0.08288120682942123,
      "loss": 3.0247,
      "step": 106520
    },
    {
      "epoch": 171.29,
      "learning_rate": 0.08287799139855306,
      "loss": 3.047,
      "step": 106540
    },
    {
      "epoch": 171.32,
      "learning_rate": 0.08287477596768489,
      "loss": 3.0384,
      "step": 106560
    },
    {
      "epoch": 171.35,
      "learning_rate": 0.08287156053681673,
      "loss": 3.025,
      "step": 106580
    },
    {
      "epoch": 171.38,
      "learning_rate": 0.08286834510594855,
      "loss": 3.0533,
      "step": 106600
    },
    {
      "epoch": 171.41,
      "learning_rate": 0.08286512967508039,
      "loss": 3.0251,
      "step": 106620
    },
    {
      "epoch": 171.45,
      "learning_rate": 0.08286191424421223,
      "loss": 3.0524,
      "step": 106640
    },
    {
      "epoch": 171.48,
      "learning_rate": 0.08285869881334405,
      "loss": 3.0331,
      "step": 106660
    },
    {
      "epoch": 171.51,
      "learning_rate": 0.08285548338247589,
      "loss": 3.0338,
      "step": 106680
    },
    {
      "epoch": 171.54,
      "learning_rate": 0.08285226795160772,
      "loss": 3.0535,
      "step": 106700
    },
    {
      "epoch": 171.58,
      "learning_rate": 0.08284905252073956,
      "loss": 3.0421,
      "step": 106720
    },
    {
      "epoch": 171.61,
      "learning_rate": 0.08284583708987138,
      "loss": 3.0529,
      "step": 106740
    },
    {
      "epoch": 171.64,
      "learning_rate": 0.08284262165900322,
      "loss": 3.0377,
      "step": 106760
    },
    {
      "epoch": 171.67,
      "learning_rate": 0.08283940622813506,
      "loss": 3.072,
      "step": 106780
    },
    {
      "epoch": 171.7,
      "learning_rate": 0.08283619079726688,
      "loss": 3.0258,
      "step": 106800
    },
    {
      "epoch": 171.74,
      "learning_rate": 0.08283297536639872,
      "loss": 3.0614,
      "step": 106820
    },
    {
      "epoch": 171.77,
      "learning_rate": 0.08282975993553054,
      "loss": 3.0376,
      "step": 106840
    },
    {
      "epoch": 171.8,
      "learning_rate": 0.08282654450466238,
      "loss": 3.0388,
      "step": 106860
    },
    {
      "epoch": 171.83,
      "learning_rate": 0.08282332907379422,
      "loss": 3.0558,
      "step": 106880
    },
    {
      "epoch": 171.86,
      "learning_rate": 0.08282011364292605,
      "loss": 3.0199,
      "step": 106900
    },
    {
      "epoch": 171.9,
      "learning_rate": 0.08281689821205789,
      "loss": 3.0311,
      "step": 106920
    },
    {
      "epoch": 171.93,
      "learning_rate": 0.08281368278118971,
      "loss": 3.0169,
      "step": 106940
    },
    {
      "epoch": 171.96,
      "learning_rate": 0.08281046735032155,
      "loss": 3.0309,
      "step": 106960
    },
    {
      "epoch": 171.99,
      "learning_rate": 0.08280725191945339,
      "loss": 3.0334,
      "step": 106980
    },
    {
      "epoch": 172.0,
      "eval_accuracy": {
        "accuracy": 0.3743294721293633
      },
      "eval_loss": 3.1404640674591064,
      "eval_runtime": 3.1886,
      "eval_samples_per_second": 4034.121,
      "eval_steps_per_second": 63.038,
      "step": 106984
    },
    {
      "epoch": 172.03,
      "learning_rate": 0.08280403648858521,
      "loss": 3.0025,
      "step": 107000
    },
    {
      "epoch": 172.06,
      "learning_rate": 0.08280082105771705,
      "loss": 3.0325,
      "step": 107020
    },
    {
      "epoch": 172.09,
      "learning_rate": 0.08279760562684887,
      "loss": 3.0677,
      "step": 107040
    },
    {
      "epoch": 172.12,
      "learning_rate": 0.08279439019598071,
      "loss": 3.0721,
      "step": 107060
    },
    {
      "epoch": 172.15,
      "learning_rate": 0.08279117476511254,
      "loss": 3.0696,
      "step": 107080
    },
    {
      "epoch": 172.19,
      "learning_rate": 0.08278795933424438,
      "loss": 2.9967,
      "step": 107100
    },
    {
      "epoch": 172.22,
      "learning_rate": 0.08278474390337622,
      "loss": 3.0137,
      "step": 107120
    },
    {
      "epoch": 172.25,
      "learning_rate": 0.08278152847250804,
      "loss": 3.0158,
      "step": 107140
    },
    {
      "epoch": 172.28,
      "learning_rate": 0.08277831304163988,
      "loss": 3.0358,
      "step": 107160
    },
    {
      "epoch": 172.32,
      "learning_rate": 0.0827750976107717,
      "loss": 3.0376,
      "step": 107180
    },
    {
      "epoch": 172.35,
      "learning_rate": 0.08277188217990354,
      "loss": 3.0416,
      "step": 107200
    },
    {
      "epoch": 172.38,
      "learning_rate": 0.08276866674903538,
      "loss": 3.0138,
      "step": 107220
    },
    {
      "epoch": 172.41,
      "learning_rate": 0.0827654513181672,
      "loss": 3.0308,
      "step": 107240
    },
    {
      "epoch": 172.44,
      "learning_rate": 0.08276223588729904,
      "loss": 3.04,
      "step": 107260
    },
    {
      "epoch": 172.48,
      "learning_rate": 0.08275902045643087,
      "loss": 2.9934,
      "step": 107280
    },
    {
      "epoch": 172.51,
      "learning_rate": 0.0827558050255627,
      "loss": 3.0294,
      "step": 107300
    },
    {
      "epoch": 172.54,
      "learning_rate": 0.08275258959469455,
      "loss": 3.0529,
      "step": 107320
    },
    {
      "epoch": 172.57,
      "learning_rate": 0.08274937416382637,
      "loss": 3.0197,
      "step": 107340
    },
    {
      "epoch": 172.6,
      "learning_rate": 0.08274615873295821,
      "loss": 2.9822,
      "step": 107360
    },
    {
      "epoch": 172.64,
      "learning_rate": 0.08274294330209003,
      "loss": 3.0116,
      "step": 107380
    },
    {
      "epoch": 172.67,
      "learning_rate": 0.08273972787122187,
      "loss": 3.0474,
      "step": 107400
    },
    {
      "epoch": 172.7,
      "learning_rate": 0.0827365124403537,
      "loss": 3.0686,
      "step": 107420
    },
    {
      "epoch": 172.73,
      "learning_rate": 0.08273329700948553,
      "loss": 3.0486,
      "step": 107440
    },
    {
      "epoch": 172.77,
      "learning_rate": 0.08273008157861737,
      "loss": 3.043,
      "step": 107460
    },
    {
      "epoch": 172.8,
      "learning_rate": 0.0827268661477492,
      "loss": 3.064,
      "step": 107480
    },
    {
      "epoch": 172.83,
      "learning_rate": 0.08272365071688104,
      "loss": 3.0908,
      "step": 107500
    },
    {
      "epoch": 172.86,
      "learning_rate": 0.08272043528601286,
      "loss": 3.0426,
      "step": 107520
    },
    {
      "epoch": 172.89,
      "learning_rate": 0.0827172198551447,
      "loss": 3.0188,
      "step": 107540
    },
    {
      "epoch": 172.93,
      "learning_rate": 0.08271400442427654,
      "loss": 3.0872,
      "step": 107560
    },
    {
      "epoch": 172.96,
      "learning_rate": 0.08271078899340836,
      "loss": 3.0316,
      "step": 107580
    },
    {
      "epoch": 172.99,
      "learning_rate": 0.0827075735625402,
      "loss": 3.0347,
      "step": 107600
    },
    {
      "epoch": 173.0,
      "eval_accuracy": {
        "accuracy": 0.3663220088626292
      },
      "eval_loss": 3.1397392749786377,
      "eval_runtime": 3.0386,
      "eval_samples_per_second": 4233.231,
      "eval_steps_per_second": 66.149,
      "step": 107606
    },
    {
      "epoch": 173.02,
      "learning_rate": 0.08270435813167203,
      "loss": 3.0491,
      "step": 107620
    },
    {
      "epoch": 173.05,
      "learning_rate": 0.08270114270080386,
      "loss": 3.032,
      "step": 107640
    },
    {
      "epoch": 173.09,
      "learning_rate": 0.0826979272699357,
      "loss": 3.0328,
      "step": 107660
    },
    {
      "epoch": 173.12,
      "learning_rate": 0.08269471183906753,
      "loss": 2.9995,
      "step": 107680
    },
    {
      "epoch": 173.15,
      "learning_rate": 0.08269149640819937,
      "loss": 3.0611,
      "step": 107700
    },
    {
      "epoch": 173.18,
      "learning_rate": 0.08268828097733119,
      "loss": 3.0131,
      "step": 107720
    },
    {
      "epoch": 173.22,
      "learning_rate": 0.08268506554646303,
      "loss": 3.0307,
      "step": 107740
    },
    {
      "epoch": 173.25,
      "learning_rate": 0.08268185011559487,
      "loss": 3.0446,
      "step": 107760
    },
    {
      "epoch": 173.28,
      "learning_rate": 0.08267863468472669,
      "loss": 3.0683,
      "step": 107780
    },
    {
      "epoch": 173.31,
      "learning_rate": 0.08267541925385853,
      "loss": 3.0872,
      "step": 107800
    },
    {
      "epoch": 173.34,
      "learning_rate": 0.08267220382299036,
      "loss": 3.0584,
      "step": 107820
    },
    {
      "epoch": 173.38,
      "learning_rate": 0.0826689883921222,
      "loss": 3.0493,
      "step": 107840
    },
    {
      "epoch": 173.41,
      "learning_rate": 0.08266577296125402,
      "loss": 3.0152,
      "step": 107860
    },
    {
      "epoch": 173.44,
      "learning_rate": 0.08266255753038586,
      "loss": 3.0053,
      "step": 107880
    },
    {
      "epoch": 173.47,
      "learning_rate": 0.0826593420995177,
      "loss": 3.0043,
      "step": 107900
    },
    {
      "epoch": 173.5,
      "learning_rate": 0.08265612666864952,
      "loss": 3.0199,
      "step": 107920
    },
    {
      "epoch": 173.54,
      "learning_rate": 0.08265291123778136,
      "loss": 3.0378,
      "step": 107940
    },
    {
      "epoch": 173.57,
      "learning_rate": 0.0826498565784566,
      "loss": 3.0705,
      "step": 107960
    },
    {
      "epoch": 173.6,
      "learning_rate": 0.08264664114758842,
      "loss": 3.0984,
      "step": 107980
    },
    {
      "epoch": 173.63,
      "learning_rate": 0.08264342571672027,
      "loss": 3.0607,
      "step": 108000
    },
    {
      "epoch": 173.67,
      "learning_rate": 0.0826402102858521,
      "loss": 3.0322,
      "step": 108020
    },
    {
      "epoch": 173.7,
      "learning_rate": 0.08263699485498394,
      "loss": 3.0202,
      "step": 108040
    },
    {
      "epoch": 173.73,
      "learning_rate": 0.08263377942411576,
      "loss": 3.0332,
      "step": 108060
    },
    {
      "epoch": 173.76,
      "learning_rate": 0.08263056399324759,
      "loss": 3.02,
      "step": 108080
    },
    {
      "epoch": 173.79,
      "learning_rate": 0.08262734856237944,
      "loss": 3.0494,
      "step": 108100
    },
    {
      "epoch": 173.83,
      "learning_rate": 0.08262413313151125,
      "loss": 3.0577,
      "step": 108120
    },
    {
      "epoch": 173.86,
      "learning_rate": 0.0826209177006431,
      "loss": 3.0237,
      "step": 108140
    },
    {
      "epoch": 173.89,
      "learning_rate": 0.08261770226977493,
      "loss": 2.9875,
      "step": 108160
    },
    {
      "epoch": 173.92,
      "learning_rate": 0.08261448683890675,
      "loss": 3.0151,
      "step": 108180
    },
    {
      "epoch": 173.95,
      "learning_rate": 0.08261127140803859,
      "loss": 3.0376,
      "step": 108200
    },
    {
      "epoch": 173.99,
      "learning_rate": 0.08260805597717041,
      "loss": 3.083,
      "step": 108220
    },
    {
      "epoch": 174.0,
      "eval_accuracy": {
        "accuracy": 0.37860530202907566
      },
      "eval_loss": 3.098053455352783,
      "eval_runtime": 2.6576,
      "eval_samples_per_second": 4839.998,
      "eval_steps_per_second": 75.631,
      "step": 108228
    },
    {
      "epoch": 174.02,
      "learning_rate": 0.08260484054630227,
      "loss": 3.0192,
      "step": 108240
    },
    {
      "epoch": 174.05,
      "learning_rate": 0.08260162511543409,
      "loss": 3.0302,
      "step": 108260
    },
    {
      "epoch": 174.08,
      "learning_rate": 0.08259840968456592,
      "loss": 3.0446,
      "step": 108280
    },
    {
      "epoch": 174.12,
      "learning_rate": 0.08259519425369775,
      "loss": 3.0579,
      "step": 108300
    },
    {
      "epoch": 174.15,
      "learning_rate": 0.08259197882282958,
      "loss": 2.9946,
      "step": 108320
    },
    {
      "epoch": 174.18,
      "learning_rate": 0.08258876339196143,
      "loss": 3.012,
      "step": 108340
    },
    {
      "epoch": 174.21,
      "learning_rate": 0.08258554796109326,
      "loss": 3.0412,
      "step": 108360
    },
    {
      "epoch": 174.24,
      "learning_rate": 0.08258233253022508,
      "loss": 3.0471,
      "step": 108380
    },
    {
      "epoch": 174.28,
      "learning_rate": 0.08257911709935692,
      "loss": 3.0407,
      "step": 108400
    },
    {
      "epoch": 174.31,
      "learning_rate": 0.08257590166848874,
      "loss": 3.0344,
      "step": 108420
    },
    {
      "epoch": 174.34,
      "learning_rate": 0.0825726862376206,
      "loss": 3.0392,
      "step": 108440
    },
    {
      "epoch": 174.37,
      "learning_rate": 0.0825694708067524,
      "loss": 3.0485,
      "step": 108460
    },
    {
      "epoch": 174.41,
      "learning_rate": 0.08256625537588425,
      "loss": 3.0421,
      "step": 108480
    },
    {
      "epoch": 174.44,
      "learning_rate": 0.08256303994501608,
      "loss": 3.0788,
      "step": 108500
    },
    {
      "epoch": 174.47,
      "learning_rate": 0.08255982451414791,
      "loss": 3.0408,
      "step": 108520
    },
    {
      "epoch": 174.5,
      "learning_rate": 0.08255660908327975,
      "loss": 3.0744,
      "step": 108540
    },
    {
      "epoch": 174.53,
      "learning_rate": 0.08255339365241157,
      "loss": 3.0229,
      "step": 108560
    },
    {
      "epoch": 174.57,
      "learning_rate": 0.08255017822154342,
      "loss": 3.0,
      "step": 108580
    },
    {
      "epoch": 174.6,
      "learning_rate": 0.08254696279067525,
      "loss": 3.0271,
      "step": 108600
    },
    {
      "epoch": 174.63,
      "learning_rate": 0.08254374735980707,
      "loss": 3.0874,
      "step": 108620
    },
    {
      "epoch": 174.66,
      "learning_rate": 0.08254053192893891,
      "loss": 3.0747,
      "step": 108640
    },
    {
      "epoch": 174.69,
      "learning_rate": 0.08253731649807074,
      "loss": 3.0553,
      "step": 108660
    },
    {
      "epoch": 174.73,
      "learning_rate": 0.08253410106720259,
      "loss": 3.0451,
      "step": 108680
    },
    {
      "epoch": 174.76,
      "learning_rate": 0.08253088563633441,
      "loss": 3.0365,
      "step": 108700
    },
    {
      "epoch": 174.79,
      "learning_rate": 0.08252767020546624,
      "loss": 3.0282,
      "step": 108720
    },
    {
      "epoch": 174.82,
      "learning_rate": 0.08252445477459808,
      "loss": 3.0327,
      "step": 108740
    },
    {
      "epoch": 174.86,
      "learning_rate": 0.0825212393437299,
      "loss": 3.0428,
      "step": 108760
    },
    {
      "epoch": 174.89,
      "learning_rate": 0.08251802391286175,
      "loss": 2.9957,
      "step": 108780
    },
    {
      "epoch": 174.92,
      "learning_rate": 0.08251480848199357,
      "loss": 3.0181,
      "step": 108800
    },
    {
      "epoch": 174.95,
      "learning_rate": 0.0825115930511254,
      "loss": 3.0597,
      "step": 108820
    },
    {
      "epoch": 174.98,
      "learning_rate": 0.08250837762025724,
      "loss": 3.0702,
      "step": 108840
    },
    {
      "epoch": 175.0,
      "eval_accuracy": {
        "accuracy": 0.3757288346419964
      },
      "eval_loss": 3.139432430267334,
      "eval_runtime": 2.6066,
      "eval_samples_per_second": 4934.81,
      "eval_steps_per_second": 77.112,
      "step": 108850
    },
    {
      "epoch": 175.02,
      "learning_rate": 0.08250516218938907,
      "loss": 3.0396,
      "step": 108860
    },
    {
      "epoch": 175.05,
      "learning_rate": 0.0825019467585209,
      "loss": 3.0616,
      "step": 108880
    },
    {
      "epoch": 175.08,
      "learning_rate": 0.08249873132765273,
      "loss": 3.0295,
      "step": 108900
    },
    {
      "epoch": 175.11,
      "learning_rate": 0.08249551589678457,
      "loss": 3.0305,
      "step": 108920
    },
    {
      "epoch": 175.14,
      "learning_rate": 0.08249230046591641,
      "loss": 3.0012,
      "step": 108940
    },
    {
      "epoch": 175.18,
      "learning_rate": 0.08248908503504823,
      "loss": 3.0167,
      "step": 108960
    },
    {
      "epoch": 175.21,
      "learning_rate": 0.08248586960418007,
      "loss": 3.0551,
      "step": 108980
    },
    {
      "epoch": 175.24,
      "learning_rate": 0.0824826541733119,
      "loss": 3.0661,
      "step": 109000
    },
    {
      "epoch": 175.27,
      "learning_rate": 0.08247943874244373,
      "loss": 3.0145,
      "step": 109020
    },
    {
      "epoch": 175.31,
      "learning_rate": 0.08247622331157557,
      "loss": 3.0546,
      "step": 109040
    },
    {
      "epoch": 175.34,
      "learning_rate": 0.0824730078807074,
      "loss": 3.0558,
      "step": 109060
    },
    {
      "epoch": 175.37,
      "learning_rate": 0.08246979244983924,
      "loss": 3.0174,
      "step": 109080
    },
    {
      "epoch": 175.4,
      "learning_rate": 0.08246657701897106,
      "loss": 3.01,
      "step": 109100
    },
    {
      "epoch": 175.43,
      "learning_rate": 0.0824633615881029,
      "loss": 3.0402,
      "step": 109120
    },
    {
      "epoch": 175.47,
      "learning_rate": 0.08246014615723472,
      "loss": 3.0095,
      "step": 109140
    },
    {
      "epoch": 175.5,
      "learning_rate": 0.08245693072636656,
      "loss": 3.0268,
      "step": 109160
    },
    {
      "epoch": 175.53,
      "learning_rate": 0.0824537152954984,
      "loss": 3.0446,
      "step": 109180
    },
    {
      "epoch": 175.56,
      "learning_rate": 0.08245049986463023,
      "loss": 3.0523,
      "step": 109200
    },
    {
      "epoch": 175.59,
      "learning_rate": 0.08244728443376206,
      "loss": 3.0683,
      "step": 109220
    },
    {
      "epoch": 175.63,
      "learning_rate": 0.08244406900289389,
      "loss": 3.0465,
      "step": 109240
    },
    {
      "epoch": 175.66,
      "learning_rate": 0.08244085357202573,
      "loss": 3.0689,
      "step": 109260
    },
    {
      "epoch": 175.69,
      "learning_rate": 0.08243763814115757,
      "loss": 3.0487,
      "step": 109280
    },
    {
      "epoch": 175.72,
      "learning_rate": 0.08243442271028939,
      "loss": 3.0453,
      "step": 109300
    },
    {
      "epoch": 175.76,
      "learning_rate": 0.08243120727942123,
      "loss": 3.0192,
      "step": 109320
    },
    {
      "epoch": 175.79,
      "learning_rate": 0.08242799184855305,
      "loss": 3.0385,
      "step": 109340
    },
    {
      "epoch": 175.82,
      "learning_rate": 0.08242477641768489,
      "loss": 3.0159,
      "step": 109360
    },
    {
      "epoch": 175.85,
      "learning_rate": 0.08242156098681673,
      "loss": 3.0709,
      "step": 109380
    },
    {
      "epoch": 175.88,
      "learning_rate": 0.08241834555594856,
      "loss": 3.0635,
      "step": 109400
    },
    {
      "epoch": 175.92,
      "learning_rate": 0.0824151301250804,
      "loss": 3.0244,
      "step": 109420
    },
    {
      "epoch": 175.95,
      "learning_rate": 0.08241191469421222,
      "loss": 2.9844,
      "step": 109440
    },
    {
      "epoch": 175.98,
      "learning_rate": 0.08240869926334406,
      "loss": 3.0514,
      "step": 109460
    },
    {
      "epoch": 176.0,
      "eval_accuracy": {
        "accuracy": 0.37378527559667263
      },
      "eval_loss": 3.12803316116333,
      "eval_runtime": 2.6167,
      "eval_samples_per_second": 4915.701,
      "eval_steps_per_second": 76.814,
      "step": 109472
    },
    {
      "epoch": 176.01,
      "learning_rate": 0.08240548383247588,
      "loss": 3.061,
      "step": 109480
    },
    {
      "epoch": 176.05,
      "learning_rate": 0.08240226840160772,
      "loss": 2.9772,
      "step": 109500
    },
    {
      "epoch": 176.08,
      "learning_rate": 0.08239905297073956,
      "loss": 3.0172,
      "step": 109520
    },
    {
      "epoch": 176.11,
      "learning_rate": 0.08239583753987138,
      "loss": 3.0273,
      "step": 109540
    },
    {
      "epoch": 176.14,
      "learning_rate": 0.08239262210900322,
      "loss": 3.0448,
      "step": 109560
    },
    {
      "epoch": 176.17,
      "learning_rate": 0.08238940667813505,
      "loss": 3.0204,
      "step": 109580
    },
    {
      "epoch": 176.21,
      "learning_rate": 0.08238619124726689,
      "loss": 3.0482,
      "step": 109600
    },
    {
      "epoch": 176.24,
      "learning_rate": 0.08238297581639872,
      "loss": 3.0793,
      "step": 109620
    },
    {
      "epoch": 176.27,
      "learning_rate": 0.08237976038553055,
      "loss": 3.0427,
      "step": 109640
    },
    {
      "epoch": 176.3,
      "learning_rate": 0.08237654495466239,
      "loss": 3.0005,
      "step": 109660
    },
    {
      "epoch": 176.33,
      "learning_rate": 0.08237332952379421,
      "loss": 3.0113,
      "step": 109680
    },
    {
      "epoch": 176.37,
      "learning_rate": 0.08237011409292605,
      "loss": 3.0294,
      "step": 109700
    },
    {
      "epoch": 176.4,
      "learning_rate": 0.08236689866205789,
      "loss": 3.0139,
      "step": 109720
    },
    {
      "epoch": 176.43,
      "learning_rate": 0.08236368323118971,
      "loss": 2.9951,
      "step": 109740
    },
    {
      "epoch": 176.46,
      "learning_rate": 0.08236046780032155,
      "loss": 3.0666,
      "step": 109760
    },
    {
      "epoch": 176.5,
      "learning_rate": 0.08235725236945338,
      "loss": 3.0785,
      "step": 109780
    },
    {
      "epoch": 176.53,
      "learning_rate": 0.08235403693858522,
      "loss": 3.0081,
      "step": 109800
    },
    {
      "epoch": 176.56,
      "learning_rate": 0.08235082150771704,
      "loss": 3.0512,
      "step": 109820
    },
    {
      "epoch": 176.59,
      "learning_rate": 0.08234760607684888,
      "loss": 3.0688,
      "step": 109840
    },
    {
      "epoch": 176.62,
      "learning_rate": 0.08234439064598072,
      "loss": 3.0561,
      "step": 109860
    },
    {
      "epoch": 176.66,
      "learning_rate": 0.08234117521511254,
      "loss": 3.0265,
      "step": 109880
    },
    {
      "epoch": 176.69,
      "learning_rate": 0.08233795978424438,
      "loss": 3.0257,
      "step": 109900
    },
    {
      "epoch": 176.72,
      "learning_rate": 0.0823347443533762,
      "loss": 3.0427,
      "step": 109920
    },
    {
      "epoch": 176.75,
      "learning_rate": 0.08233152892250804,
      "loss": 3.0226,
      "step": 109940
    },
    {
      "epoch": 176.78,
      "learning_rate": 0.08232831349163988,
      "loss": 2.9998,
      "step": 109960
    },
    {
      "epoch": 176.82,
      "learning_rate": 0.08232525883231512,
      "loss": 3.0402,
      "step": 109980
    },
    {
      "epoch": 176.85,
      "learning_rate": 0.08232204340144696,
      "loss": 3.0647,
      "step": 110000
    },
    {
      "epoch": 176.88,
      "learning_rate": 0.08231882797057878,
      "loss": 3.0606,
      "step": 110020
    },
    {
      "epoch": 176.91,
      "learning_rate": 0.0823156125397106,
      "loss": 3.0272,
      "step": 110040
    },
    {
      "epoch": 176.95,
      "learning_rate": 0.08231239710884246,
      "loss": 3.0073,
      "step": 110060
    },
    {
      "epoch": 176.98,
      "learning_rate": 0.08230918167797428,
      "loss": 2.9836,
      "step": 110080
    },
    {
      "epoch": 177.0,
      "eval_accuracy": {
        "accuracy": 0.37370753323485967
      },
      "eval_loss": 3.115567445755005,
      "eval_runtime": 3.0607,
      "eval_samples_per_second": 4202.615,
      "eval_steps_per_second": 65.671,
      "step": 110094
    },
    {
      "epoch": 177.01,
      "learning_rate": 0.08230596624710612,
      "loss": 3.0159,
      "step": 110100
    },
    {
      "epoch": 177.04,
      "learning_rate": 0.08230275081623795,
      "loss": 3.033,
      "step": 110120
    },
    {
      "epoch": 177.07,
      "learning_rate": 0.08229953538536978,
      "loss": 3.022,
      "step": 110140
    },
    {
      "epoch": 177.11,
      "learning_rate": 0.08229631995450161,
      "loss": 3.021,
      "step": 110160
    },
    {
      "epoch": 177.14,
      "learning_rate": 0.08229310452363343,
      "loss": 3.0275,
      "step": 110180
    },
    {
      "epoch": 177.17,
      "learning_rate": 0.08228988909276529,
      "loss": 3.0152,
      "step": 110200
    },
    {
      "epoch": 177.2,
      "learning_rate": 0.08228667366189711,
      "loss": 3.004,
      "step": 110220
    },
    {
      "epoch": 177.23,
      "learning_rate": 0.08228345823102895,
      "loss": 3.0692,
      "step": 110240
    },
    {
      "epoch": 177.27,
      "learning_rate": 0.08228024280016077,
      "loss": 3.0713,
      "step": 110260
    },
    {
      "epoch": 177.3,
      "learning_rate": 0.0822770273692926,
      "loss": 3.014,
      "step": 110280
    },
    {
      "epoch": 177.33,
      "learning_rate": 0.08227381193842445,
      "loss": 3.0356,
      "step": 110300
    },
    {
      "epoch": 177.36,
      "learning_rate": 0.08227059650755628,
      "loss": 3.0201,
      "step": 110320
    },
    {
      "epoch": 177.4,
      "learning_rate": 0.08226738107668811,
      "loss": 3.0316,
      "step": 110340
    },
    {
      "epoch": 177.43,
      "learning_rate": 0.08226416564581994,
      "loss": 3.0481,
      "step": 110360
    },
    {
      "epoch": 177.46,
      "learning_rate": 0.08226095021495176,
      "loss": 3.0103,
      "step": 110380
    },
    {
      "epoch": 177.49,
      "learning_rate": 0.08225773478408362,
      "loss": 3.0218,
      "step": 110400
    },
    {
      "epoch": 177.52,
      "learning_rate": 0.08225451935321544,
      "loss": 3.0128,
      "step": 110420
    },
    {
      "epoch": 177.56,
      "learning_rate": 0.08225130392234728,
      "loss": 3.028,
      "step": 110440
    },
    {
      "epoch": 177.59,
      "learning_rate": 0.0822480884914791,
      "loss": 3.0284,
      "step": 110460
    },
    {
      "epoch": 177.62,
      "learning_rate": 0.08224487306061093,
      "loss": 3.0565,
      "step": 110480
    },
    {
      "epoch": 177.65,
      "learning_rate": 0.08224165762974278,
      "loss": 3.0249,
      "step": 110500
    },
    {
      "epoch": 177.68,
      "learning_rate": 0.08223844219887459,
      "loss": 2.9857,
      "step": 110520
    },
    {
      "epoch": 177.72,
      "learning_rate": 0.08223522676800644,
      "loss": 3.0043,
      "step": 110540
    },
    {
      "epoch": 177.75,
      "learning_rate": 0.08223201133713827,
      "loss": 3.0021,
      "step": 110560
    },
    {
      "epoch": 177.78,
      "learning_rate": 0.0822287959062701,
      "loss": 2.9919,
      "step": 110580
    },
    {
      "epoch": 177.81,
      "learning_rate": 0.08222558047540193,
      "loss": 3.0144,
      "step": 110600
    },
    {
      "epoch": 177.85,
      "learning_rate": 0.08222236504453376,
      "loss": 3.0414,
      "step": 110620
    },
    {
      "epoch": 177.88,
      "learning_rate": 0.08221914961366561,
      "loss": 3.0331,
      "step": 110640
    },
    {
      "epoch": 177.91,
      "learning_rate": 0.08221593418279743,
      "loss": 3.0671,
      "step": 110660
    },
    {
      "epoch": 177.94,
      "learning_rate": 0.08221271875192926,
      "loss": 3.0101,
      "step": 110680
    },
    {
      "epoch": 177.97,
      "learning_rate": 0.0822095033210611,
      "loss": 3.0484,
      "step": 110700
    },
    {
      "epoch": 178.0,
      "eval_accuracy": {
        "accuracy": 0.37137526238047114
      },
      "eval_loss": 3.1143693923950195,
      "eval_runtime": 2.718,
      "eval_samples_per_second": 4732.528,
      "eval_steps_per_second": 73.951,
      "step": 110716
    },
    {
      "epoch": 178.01,
      "learning_rate": 0.08220628789019292,
      "loss": 3.0185,
      "step": 110720
    },
    {
      "epoch": 178.04,
      "learning_rate": 0.08220307245932477,
      "loss": 3.0299,
      "step": 110740
    },
    {
      "epoch": 178.07,
      "learning_rate": 0.0821998570284566,
      "loss": 3.0022,
      "step": 110760
    },
    {
      "epoch": 178.1,
      "learning_rate": 0.08219664159758844,
      "loss": 3.0087,
      "step": 110780
    },
    {
      "epoch": 178.14,
      "learning_rate": 0.08219342616672026,
      "loss": 3.0295,
      "step": 110800
    },
    {
      "epoch": 178.17,
      "learning_rate": 0.08219021073585209,
      "loss": 3.0369,
      "step": 110820
    },
    {
      "epoch": 178.2,
      "learning_rate": 0.08218699530498394,
      "loss": 3.0509,
      "step": 110840
    },
    {
      "epoch": 178.23,
      "learning_rate": 0.08218377987411575,
      "loss": 3.0169,
      "step": 110860
    },
    {
      "epoch": 178.26,
      "learning_rate": 0.0821805644432476,
      "loss": 3.0133,
      "step": 110880
    },
    {
      "epoch": 178.3,
      "learning_rate": 0.08217734901237943,
      "loss": 3.0251,
      "step": 110900
    },
    {
      "epoch": 178.33,
      "learning_rate": 0.08217413358151125,
      "loss": 3.0202,
      "step": 110920
    },
    {
      "epoch": 178.36,
      "learning_rate": 0.08217091815064309,
      "loss": 3.043,
      "step": 110940
    },
    {
      "epoch": 178.39,
      "learning_rate": 0.08216770271977492,
      "loss": 2.9946,
      "step": 110960
    },
    {
      "epoch": 178.42,
      "learning_rate": 0.08216448728890677,
      "loss": 3.0277,
      "step": 110980
    },
    {
      "epoch": 178.46,
      "learning_rate": 0.08216127185803859,
      "loss": 3.018,
      "step": 111000
    },
    {
      "epoch": 178.49,
      "learning_rate": 0.08215805642717042,
      "loss": 3.0229,
      "step": 111020
    },
    {
      "epoch": 178.52,
      "learning_rate": 0.08215484099630226,
      "loss": 3.0432,
      "step": 111040
    },
    {
      "epoch": 178.55,
      "learning_rate": 0.08215162556543408,
      "loss": 3.0444,
      "step": 111060
    },
    {
      "epoch": 178.59,
      "learning_rate": 0.08214841013456593,
      "loss": 3.0309,
      "step": 111080
    },
    {
      "epoch": 178.62,
      "learning_rate": 0.08214519470369776,
      "loss": 2.9942,
      "step": 111100
    },
    {
      "epoch": 178.65,
      "learning_rate": 0.08214197927282958,
      "loss": 3.0464,
      "step": 111120
    },
    {
      "epoch": 178.68,
      "learning_rate": 0.08213876384196142,
      "loss": 3.0242,
      "step": 111140
    },
    {
      "epoch": 178.71,
      "learning_rate": 0.08213554841109325,
      "loss": 2.9795,
      "step": 111160
    },
    {
      "epoch": 178.75,
      "learning_rate": 0.0821323329802251,
      "loss": 3.0403,
      "step": 111180
    },
    {
      "epoch": 178.78,
      "learning_rate": 0.08212911754935691,
      "loss": 3.0458,
      "step": 111200
    },
    {
      "epoch": 178.81,
      "learning_rate": 0.08212590211848875,
      "loss": 3.0194,
      "step": 111220
    },
    {
      "epoch": 178.84,
      "learning_rate": 0.08212268668762059,
      "loss": 3.0354,
      "step": 111240
    },
    {
      "epoch": 178.87,
      "learning_rate": 0.08211947125675241,
      "loss": 3.0164,
      "step": 111260
    },
    {
      "epoch": 178.91,
      "learning_rate": 0.08211625582588425,
      "loss": 3.0173,
      "step": 111280
    },
    {
      "epoch": 178.94,
      "learning_rate": 0.08211304039501607,
      "loss": 3.0189,
      "step": 111300
    },
    {
      "epoch": 178.97,
      "learning_rate": 0.08210982496414791,
      "loss": 3.0283,
      "step": 111320
    },
    {
      "epoch": 179.0,
      "eval_accuracy": {
        "accuracy": 0.37518463810930575
      },
      "eval_loss": 3.079042673110962,
      "eval_runtime": 2.706,
      "eval_samples_per_second": 4753.566,
      "eval_steps_per_second": 74.28,
      "step": 111338
    },
    {
      "epoch": 179.0,
      "learning_rate": 0.08210660953327975,
      "loss": 2.9915,
      "step": 111340
    },
    {
      "epoch": 179.04,
      "learning_rate": 0.08210339410241158,
      "loss": 2.9955,
      "step": 111360
    },
    {
      "epoch": 179.07,
      "learning_rate": 0.08210017867154341,
      "loss": 3.0372,
      "step": 111380
    },
    {
      "epoch": 179.1,
      "learning_rate": 0.08209696324067524,
      "loss": 3.0509,
      "step": 111400
    },
    {
      "epoch": 179.13,
      "learning_rate": 0.08209374780980709,
      "loss": 3.0118,
      "step": 111420
    },
    {
      "epoch": 179.16,
      "learning_rate": 0.08209053237893892,
      "loss": 2.9975,
      "step": 111440
    },
    {
      "epoch": 179.2,
      "learning_rate": 0.08208731694807074,
      "loss": 3.0005,
      "step": 111460
    },
    {
      "epoch": 179.23,
      "learning_rate": 0.08208410151720258,
      "loss": 3.0075,
      "step": 111480
    },
    {
      "epoch": 179.26,
      "learning_rate": 0.0820808860863344,
      "loss": 3.0092,
      "step": 111500
    },
    {
      "epoch": 179.29,
      "learning_rate": 0.08207767065546626,
      "loss": 3.0129,
      "step": 111520
    },
    {
      "epoch": 179.32,
      "learning_rate": 0.08207445522459807,
      "loss": 3.0407,
      "step": 111540
    },
    {
      "epoch": 179.36,
      "learning_rate": 0.0820712397937299,
      "loss": 3.0183,
      "step": 111560
    },
    {
      "epoch": 179.39,
      "learning_rate": 0.08206802436286174,
      "loss": 3.0003,
      "step": 111580
    },
    {
      "epoch": 179.42,
      "learning_rate": 0.08206480893199357,
      "loss": 3.0271,
      "step": 111600
    },
    {
      "epoch": 179.45,
      "learning_rate": 0.08206159350112541,
      "loss": 3.0019,
      "step": 111620
    },
    {
      "epoch": 179.49,
      "learning_rate": 0.08205837807025723,
      "loss": 3.0816,
      "step": 111640
    },
    {
      "epoch": 179.52,
      "learning_rate": 0.08205516263938907,
      "loss": 3.0602,
      "step": 111660
    },
    {
      "epoch": 179.55,
      "learning_rate": 0.08205194720852091,
      "loss": 3.034,
      "step": 111680
    },
    {
      "epoch": 179.58,
      "learning_rate": 0.08204873177765273,
      "loss": 3.0052,
      "step": 111700
    },
    {
      "epoch": 179.61,
      "learning_rate": 0.08204551634678457,
      "loss": 3.0393,
      "step": 111720
    },
    {
      "epoch": 179.65,
      "learning_rate": 0.0820423009159164,
      "loss": 2.9981,
      "step": 111740
    },
    {
      "epoch": 179.68,
      "learning_rate": 0.08203908548504824,
      "loss": 3.0342,
      "step": 111760
    },
    {
      "epoch": 179.71,
      "learning_rate": 0.08203587005418007,
      "loss": 3.0359,
      "step": 111780
    },
    {
      "epoch": 179.74,
      "learning_rate": 0.0820326546233119,
      "loss": 2.9819,
      "step": 111800
    },
    {
      "epoch": 179.77,
      "learning_rate": 0.08202943919244374,
      "loss": 2.9707,
      "step": 111820
    },
    {
      "epoch": 179.81,
      "learning_rate": 0.08202622376157556,
      "loss": 2.9882,
      "step": 111840
    },
    {
      "epoch": 179.84,
      "learning_rate": 0.0820230083307074,
      "loss": 3.0651,
      "step": 111860
    },
    {
      "epoch": 179.87,
      "learning_rate": 0.08201979289983923,
      "loss": 3.0744,
      "step": 111880
    },
    {
      "epoch": 179.9,
      "learning_rate": 0.08201657746897106,
      "loss": 3.0229,
      "step": 111900
    },
    {
      "epoch": 179.94,
      "learning_rate": 0.0820133620381029,
      "loss": 3.0309,
      "step": 111920
    },
    {
      "epoch": 179.97,
      "learning_rate": 0.08201014660723473,
      "loss": 3.0327,
      "step": 111940
    },
    {
      "epoch": 180.0,
      "learning_rate": 0.08200693117636657,
      "loss": 3.0265,
      "step": 111960
    },
    {
      "epoch": 180.0,
      "eval_accuracy": {
        "accuracy": 0.3750291533856799
      },
      "eval_loss": 3.1004862785339355,
      "eval_runtime": 2.9049,
      "eval_samples_per_second": 4428.071,
      "eval_steps_per_second": 69.194,
      "step": 111960
    },
    {
      "epoch": 180.03,
      "learning_rate": 0.08200371574549839,
      "loss": 2.9991,
      "step": 111980
    },
    {
      "epoch": 180.06,
      "learning_rate": 0.08200066108617364,
      "loss": 2.9863,
      "step": 112000
    },
    {
      "epoch": 180.1,
      "learning_rate": 0.08199744565530548,
      "loss": 2.9905,
      "step": 112020
    },
    {
      "epoch": 180.13,
      "learning_rate": 0.0819942302244373,
      "loss": 3.0706,
      "step": 112040
    },
    {
      "epoch": 180.16,
      "learning_rate": 0.08199101479356914,
      "loss": 3.0234,
      "step": 112060
    },
    {
      "epoch": 180.19,
      "learning_rate": 0.08198779936270097,
      "loss": 3.0221,
      "step": 112080
    },
    {
      "epoch": 180.23,
      "learning_rate": 0.0819845839318328,
      "loss": 3.0868,
      "step": 112100
    },
    {
      "epoch": 180.26,
      "learning_rate": 0.08198136850096464,
      "loss": 3.0722,
      "step": 112120
    },
    {
      "epoch": 180.29,
      "learning_rate": 0.08197815307009647,
      "loss": 3.0316,
      "step": 112140
    },
    {
      "epoch": 180.32,
      "learning_rate": 0.0819749376392283,
      "loss": 3.0106,
      "step": 112160
    },
    {
      "epoch": 180.35,
      "learning_rate": 0.08197172220836013,
      "loss": 2.9992,
      "step": 112180
    },
    {
      "epoch": 180.39,
      "learning_rate": 0.08196850677749197,
      "loss": 2.997,
      "step": 112200
    },
    {
      "epoch": 180.42,
      "learning_rate": 0.0819652913466238,
      "loss": 3.0223,
      "step": 112220
    },
    {
      "epoch": 180.45,
      "learning_rate": 0.08196207591575562,
      "loss": 3.0299,
      "step": 112240
    },
    {
      "epoch": 180.48,
      "learning_rate": 0.08195886048488747,
      "loss": 3.0071,
      "step": 112260
    },
    {
      "epoch": 180.51,
      "learning_rate": 0.0819556450540193,
      "loss": 3.0309,
      "step": 112280
    },
    {
      "epoch": 180.55,
      "learning_rate": 0.08195242962315114,
      "loss": 3.0122,
      "step": 112300
    },
    {
      "epoch": 180.58,
      "learning_rate": 0.08194921419228296,
      "loss": 3.0096,
      "step": 112320
    },
    {
      "epoch": 180.61,
      "learning_rate": 0.0819459987614148,
      "loss": 3.0325,
      "step": 112340
    },
    {
      "epoch": 180.64,
      "learning_rate": 0.08194278333054664,
      "loss": 3.0656,
      "step": 112360
    },
    {
      "epoch": 180.68,
      "learning_rate": 0.08193956789967846,
      "loss": 3.0116,
      "step": 112380
    },
    {
      "epoch": 180.71,
      "learning_rate": 0.0819363524688103,
      "loss": 3.0196,
      "step": 112400
    },
    {
      "epoch": 180.74,
      "learning_rate": 0.08193313703794212,
      "loss": 3.0289,
      "step": 112420
    },
    {
      "epoch": 180.77,
      "learning_rate": 0.08192992160707396,
      "loss": 3.0368,
      "step": 112440
    },
    {
      "epoch": 180.8,
      "learning_rate": 0.0819267061762058,
      "loss": 3.0351,
      "step": 112460
    },
    {
      "epoch": 180.84,
      "learning_rate": 0.08192349074533763,
      "loss": 3.0085,
      "step": 112480
    },
    {
      "epoch": 180.87,
      "learning_rate": 0.08192027531446947,
      "loss": 3.0056,
      "step": 112500
    },
    {
      "epoch": 180.9,
      "learning_rate": 0.08191705988360129,
      "loss": 3.0547,
      "step": 112520
    },
    {
      "epoch": 180.93,
      "learning_rate": 0.08191384445273313,
      "loss": 3.084,
      "step": 112540
    },
    {
      "epoch": 180.96,
      "learning_rate": 0.08191062902186495,
      "loss": 3.0346,
      "step": 112560
    },
    {
      "epoch": 181.0,
      "learning_rate": 0.08190741359099678,
      "loss": 2.9877,
      "step": 112580
    },
    {
      "epoch": 181.0,
      "eval_accuracy": {
        "accuracy": 0.3726968825312913
      },
      "eval_loss": 3.1464335918426514,
      "eval_runtime": 2.8786,
      "eval_samples_per_second": 4468.444,
      "eval_steps_per_second": 69.825,
      "step": 112582
    },
    {
      "epoch": 181.03,
      "learning_rate": 0.08190419816012863,
      "loss": 3.0085,
      "step": 112600
    },
    {
      "epoch": 181.06,
      "learning_rate": 0.08190098272926045,
      "loss": 3.0718,
      "step": 112620
    },
    {
      "epoch": 181.09,
      "learning_rate": 0.0818977672983923,
      "loss": 3.0406,
      "step": 112640
    },
    {
      "epoch": 181.13,
      "learning_rate": 0.08189455186752412,
      "loss": 3.0353,
      "step": 112660
    },
    {
      "epoch": 181.16,
      "learning_rate": 0.08189133643665594,
      "loss": 3.0237,
      "step": 112680
    },
    {
      "epoch": 181.19,
      "learning_rate": 0.0818881210057878,
      "loss": 3.0383,
      "step": 112700
    },
    {
      "epoch": 181.22,
      "learning_rate": 0.08188490557491962,
      "loss": 3.0315,
      "step": 112720
    },
    {
      "epoch": 181.25,
      "learning_rate": 0.08188169014405146,
      "loss": 3.0298,
      "step": 112740
    },
    {
      "epoch": 181.29,
      "learning_rate": 0.08187847471318328,
      "loss": 3.0195,
      "step": 112760
    },
    {
      "epoch": 181.32,
      "learning_rate": 0.08187525928231511,
      "loss": 2.9658,
      "step": 112780
    },
    {
      "epoch": 181.35,
      "learning_rate": 0.08187204385144696,
      "loss": 3.0391,
      "step": 112800
    },
    {
      "epoch": 181.38,
      "learning_rate": 0.08186882842057878,
      "loss": 3.0463,
      "step": 112820
    },
    {
      "epoch": 181.41,
      "learning_rate": 0.08186561298971062,
      "loss": 3.0382,
      "step": 112840
    },
    {
      "epoch": 181.45,
      "learning_rate": 0.08186239755884245,
      "loss": 3.0305,
      "step": 112860
    },
    {
      "epoch": 181.48,
      "learning_rate": 0.08185918212797427,
      "loss": 3.0511,
      "step": 112880
    },
    {
      "epoch": 181.51,
      "learning_rate": 0.08185596669710611,
      "loss": 3.0392,
      "step": 112900
    },
    {
      "epoch": 181.54,
      "learning_rate": 0.08185275126623794,
      "loss": 3.0109,
      "step": 112920
    },
    {
      "epoch": 181.58,
      "learning_rate": 0.08184953583536979,
      "loss": 3.0293,
      "step": 112940
    },
    {
      "epoch": 181.61,
      "learning_rate": 0.08184632040450161,
      "loss": 3.0301,
      "step": 112960
    },
    {
      "epoch": 181.64,
      "learning_rate": 0.08184310497363345,
      "loss": 3.0191,
      "step": 112980
    },
    {
      "epoch": 181.67,
      "learning_rate": 0.08183988954276528,
      "loss": 3.0113,
      "step": 113000
    },
    {
      "epoch": 181.7,
      "learning_rate": 0.0818366741118971,
      "loss": 3.0265,
      "step": 113020
    },
    {
      "epoch": 181.74,
      "learning_rate": 0.08183345868102895,
      "loss": 3.0469,
      "step": 113040
    },
    {
      "epoch": 181.77,
      "learning_rate": 0.08183024325016078,
      "loss": 3.0571,
      "step": 113060
    },
    {
      "epoch": 181.8,
      "learning_rate": 0.08182702781929262,
      "loss": 3.0145,
      "step": 113080
    },
    {
      "epoch": 181.83,
      "learning_rate": 0.08182381238842444,
      "loss": 3.0424,
      "step": 113100
    },
    {
      "epoch": 181.86,
      "learning_rate": 0.08182059695755627,
      "loss": 2.9884,
      "step": 113120
    },
    {
      "epoch": 181.9,
      "learning_rate": 0.08181738152668812,
      "loss": 3.0086,
      "step": 113140
    },
    {
      "epoch": 181.93,
      "learning_rate": 0.08181416609581994,
      "loss": 3.0444,
      "step": 113160
    },
    {
      "epoch": 181.96,
      "learning_rate": 0.08181095066495178,
      "loss": 3.0478,
      "step": 113180
    },
    {
      "epoch": 181.99,
      "learning_rate": 0.0818077352340836,
      "loss": 3.049,
      "step": 113200
    },
    {
      "epoch": 182.0,
      "eval_accuracy": {
        "accuracy": 0.36974267278239914
      },
      "eval_loss": 3.11802077293396,
      "eval_runtime": 2.9674,
      "eval_samples_per_second": 4334.734,
      "eval_steps_per_second": 67.735,
      "step": 113204
    },
    {
      "epoch": 182.03,
      "learning_rate": 0.08180451980321543,
      "loss": 2.9967,
      "step": 113220
    },
    {
      "epoch": 182.06,
      "learning_rate": 0.08180130437234728,
      "loss": 3.0303,
      "step": 113240
    },
    {
      "epoch": 182.09,
      "learning_rate": 0.0817980889414791,
      "loss": 3.0436,
      "step": 113260
    },
    {
      "epoch": 182.12,
      "learning_rate": 0.08179487351061095,
      "loss": 3.0421,
      "step": 113280
    },
    {
      "epoch": 182.15,
      "learning_rate": 0.08179165807974277,
      "loss": 3.0087,
      "step": 113300
    },
    {
      "epoch": 182.19,
      "learning_rate": 0.0817884426488746,
      "loss": 2.9937,
      "step": 113320
    },
    {
      "epoch": 182.22,
      "learning_rate": 0.08178522721800643,
      "loss": 2.9926,
      "step": 113340
    },
    {
      "epoch": 182.25,
      "learning_rate": 0.08178201178713826,
      "loss": 3.0253,
      "step": 113360
    },
    {
      "epoch": 182.28,
      "learning_rate": 0.08177879635627011,
      "loss": 3.0351,
      "step": 113380
    },
    {
      "epoch": 182.32,
      "learning_rate": 0.08177558092540194,
      "loss": 2.9863,
      "step": 113400
    },
    {
      "epoch": 182.35,
      "learning_rate": 0.08177236549453376,
      "loss": 2.9908,
      "step": 113420
    },
    {
      "epoch": 182.38,
      "learning_rate": 0.0817691500636656,
      "loss": 3.0197,
      "step": 113440
    },
    {
      "epoch": 182.41,
      "learning_rate": 0.08176593463279742,
      "loss": 3.0056,
      "step": 113460
    },
    {
      "epoch": 182.44,
      "learning_rate": 0.08176271920192928,
      "loss": 3.0417,
      "step": 113480
    },
    {
      "epoch": 182.48,
      "learning_rate": 0.0817595037710611,
      "loss": 3.0318,
      "step": 113500
    },
    {
      "epoch": 182.51,
      "learning_rate": 0.08175628834019293,
      "loss": 3.0055,
      "step": 113520
    },
    {
      "epoch": 182.54,
      "learning_rate": 0.08175307290932476,
      "loss": 2.9826,
      "step": 113540
    },
    {
      "epoch": 182.57,
      "learning_rate": 0.08174985747845659,
      "loss": 2.9798,
      "step": 113560
    },
    {
      "epoch": 182.6,
      "learning_rate": 0.08174664204758844,
      "loss": 3.0067,
      "step": 113580
    },
    {
      "epoch": 182.64,
      "learning_rate": 0.08174342661672025,
      "loss": 3.0421,
      "step": 113600
    },
    {
      "epoch": 182.67,
      "learning_rate": 0.0817402111858521,
      "loss": 3.0607,
      "step": 113620
    },
    {
      "epoch": 182.7,
      "learning_rate": 0.08173699575498393,
      "loss": 2.9953,
      "step": 113640
    },
    {
      "epoch": 182.73,
      "learning_rate": 0.08173378032411575,
      "loss": 3.0222,
      "step": 113660
    },
    {
      "epoch": 182.77,
      "learning_rate": 0.08173056489324759,
      "loss": 3.0369,
      "step": 113680
    },
    {
      "epoch": 182.8,
      "learning_rate": 0.08172734946237942,
      "loss": 3.0294,
      "step": 113700
    },
    {
      "epoch": 182.83,
      "learning_rate": 0.08172413403151127,
      "loss": 2.9963,
      "step": 113720
    },
    {
      "epoch": 182.86,
      "learning_rate": 0.0817209186006431,
      "loss": 3.0264,
      "step": 113740
    },
    {
      "epoch": 182.89,
      "learning_rate": 0.08171770316977492,
      "loss": 3.0485,
      "step": 113760
    },
    {
      "epoch": 182.93,
      "learning_rate": 0.08171448773890676,
      "loss": 3.031,
      "step": 113780
    },
    {
      "epoch": 182.96,
      "learning_rate": 0.08171127230803858,
      "loss": 3.0357,
      "step": 113800
    },
    {
      "epoch": 182.99,
      "learning_rate": 0.08170805687717043,
      "loss": 3.0419,
      "step": 113820
    },
    {
      "epoch": 183.0,
      "eval_accuracy": {
        "accuracy": 0.37090880820959343
      },
      "eval_loss": 3.1226494312286377,
      "eval_runtime": 2.5059,
      "eval_samples_per_second": 5132.991,
      "eval_steps_per_second": 80.209,
      "step": 113826
    },
    {
      "epoch": 183.02,
      "learning_rate": 0.08170484144630226,
      "loss": 3.0205,
      "step": 113840
    },
    {
      "epoch": 183.05,
      "learning_rate": 0.08170162601543408,
      "loss": 2.9952,
      "step": 113860
    },
    {
      "epoch": 183.09,
      "learning_rate": 0.08169841058456592,
      "loss": 2.9977,
      "step": 113880
    },
    {
      "epoch": 183.12,
      "learning_rate": 0.08169519515369775,
      "loss": 2.977,
      "step": 113900
    },
    {
      "epoch": 183.15,
      "learning_rate": 0.0816919797228296,
      "loss": 2.9951,
      "step": 113920
    },
    {
      "epoch": 183.18,
      "learning_rate": 0.08168876429196141,
      "loss": 3.0268,
      "step": 113940
    },
    {
      "epoch": 183.22,
      "learning_rate": 0.08168554886109325,
      "loss": 3.0422,
      "step": 113960
    },
    {
      "epoch": 183.25,
      "learning_rate": 0.08168233343022509,
      "loss": 3.0004,
      "step": 113980
    },
    {
      "epoch": 183.28,
      "learning_rate": 0.08167911799935691,
      "loss": 2.9937,
      "step": 114000
    },
    {
      "epoch": 183.31,
      "learning_rate": 0.08167606334003216,
      "loss": 3.0523,
      "step": 114020
    },
    {
      "epoch": 183.34,
      "learning_rate": 0.0816730086807074,
      "loss": 3.0059,
      "step": 114040
    },
    {
      "epoch": 183.38,
      "learning_rate": 0.08166979324983924,
      "loss": 3.0483,
      "step": 114060
    },
    {
      "epoch": 183.41,
      "learning_rate": 0.08166657781897106,
      "loss": 2.9756,
      "step": 114080
    },
    {
      "epoch": 183.44,
      "learning_rate": 0.0816633623881029,
      "loss": 2.9865,
      "step": 114100
    },
    {
      "epoch": 183.47,
      "learning_rate": 0.08166014695723474,
      "loss": 2.9856,
      "step": 114120
    },
    {
      "epoch": 183.5,
      "learning_rate": 0.08165693152636656,
      "loss": 3.0072,
      "step": 114140
    },
    {
      "epoch": 183.54,
      "learning_rate": 0.0816537160954984,
      "loss": 3.0197,
      "step": 114160
    },
    {
      "epoch": 183.57,
      "learning_rate": 0.08165050066463023,
      "loss": 3.0214,
      "step": 114180
    },
    {
      "epoch": 183.6,
      "learning_rate": 0.08164728523376207,
      "loss": 3.0039,
      "step": 114200
    },
    {
      "epoch": 183.63,
      "learning_rate": 0.08164406980289389,
      "loss": 2.9828,
      "step": 114220
    },
    {
      "epoch": 183.67,
      "learning_rate": 0.08164085437202573,
      "loss": 3.0128,
      "step": 114240
    },
    {
      "epoch": 183.7,
      "learning_rate": 0.08163763894115757,
      "loss": 3.0203,
      "step": 114260
    },
    {
      "epoch": 183.73,
      "learning_rate": 0.08163442351028939,
      "loss": 3.0178,
      "step": 114280
    },
    {
      "epoch": 183.76,
      "learning_rate": 0.08163120807942123,
      "loss": 3.0261,
      "step": 114300
    },
    {
      "epoch": 183.79,
      "learning_rate": 0.08162799264855305,
      "loss": 3.0289,
      "step": 114320
    },
    {
      "epoch": 183.83,
      "learning_rate": 0.0816247772176849,
      "loss": 2.9953,
      "step": 114340
    },
    {
      "epoch": 183.86,
      "learning_rate": 0.08162156178681673,
      "loss": 3.0158,
      "step": 114360
    },
    {
      "epoch": 183.89,
      "learning_rate": 0.08161834635594856,
      "loss": 3.0615,
      "step": 114380
    },
    {
      "epoch": 183.92,
      "learning_rate": 0.0816151309250804,
      "loss": 3.0213,
      "step": 114400
    },
    {
      "epoch": 183.95,
      "learning_rate": 0.08161191549421222,
      "loss": 3.039,
      "step": 114420
    },
    {
      "epoch": 183.99,
      "learning_rate": 0.08160870006334406,
      "loss": 3.0309,
      "step": 114440
    },
    {
      "epoch": 184.0,
      "eval_accuracy": {
        "accuracy": 0.3673326595661976
      },
      "eval_loss": 3.13362455368042,
      "eval_runtime": 2.8525,
      "eval_samples_per_second": 4509.307,
      "eval_steps_per_second": 70.463,
      "step": 114448
    },
    {
      "epoch": 184.02,
      "learning_rate": 0.0816054846324759,
      "loss": 3.0486,
      "step": 114460
    },
    {
      "epoch": 184.05,
      "learning_rate": 0.08160226920160772,
      "loss": 3.0431,
      "step": 114480
    },
    {
      "epoch": 184.08,
      "learning_rate": 0.08159905377073956,
      "loss": 3.0077,
      "step": 114500
    },
    {
      "epoch": 184.12,
      "learning_rate": 0.08159583833987138,
      "loss": 3.0033,
      "step": 114520
    },
    {
      "epoch": 184.15,
      "learning_rate": 0.08159262290900322,
      "loss": 3.0201,
      "step": 114540
    },
    {
      "epoch": 184.18,
      "learning_rate": 0.08158940747813505,
      "loss": 3.0003,
      "step": 114560
    },
    {
      "epoch": 184.21,
      "learning_rate": 0.08158619204726689,
      "loss": 2.9866,
      "step": 114580
    },
    {
      "epoch": 184.24,
      "learning_rate": 0.08158297661639873,
      "loss": 3.0126,
      "step": 114600
    },
    {
      "epoch": 184.28,
      "learning_rate": 0.08157976118553055,
      "loss": 3.0053,
      "step": 114620
    },
    {
      "epoch": 184.31,
      "learning_rate": 0.08157654575466239,
      "loss": 3.0032,
      "step": 114640
    },
    {
      "epoch": 184.34,
      "learning_rate": 0.08157333032379421,
      "loss": 3.0431,
      "step": 114660
    },
    {
      "epoch": 184.37,
      "learning_rate": 0.08157011489292605,
      "loss": 3.0147,
      "step": 114680
    },
    {
      "epoch": 184.41,
      "learning_rate": 0.08156689946205789,
      "loss": 3.0679,
      "step": 114700
    },
    {
      "epoch": 184.44,
      "learning_rate": 0.08156368403118971,
      "loss": 3.0631,
      "step": 114720
    },
    {
      "epoch": 184.47,
      "learning_rate": 0.08156046860032155,
      "loss": 3.0692,
      "step": 114740
    },
    {
      "epoch": 184.5,
      "learning_rate": 0.08155725316945338,
      "loss": 2.992,
      "step": 114760
    },
    {
      "epoch": 184.53,
      "learning_rate": 0.08155403773858522,
      "loss": 3.0033,
      "step": 114780
    },
    {
      "epoch": 184.57,
      "learning_rate": 0.08155082230771706,
      "loss": 3.0272,
      "step": 114800
    },
    {
      "epoch": 184.6,
      "learning_rate": 0.08154760687684888,
      "loss": 3.0256,
      "step": 114820
    },
    {
      "epoch": 184.63,
      "learning_rate": 0.08154439144598072,
      "loss": 3.0017,
      "step": 114840
    },
    {
      "epoch": 184.66,
      "learning_rate": 0.08154117601511254,
      "loss": 2.9947,
      "step": 114860
    },
    {
      "epoch": 184.69,
      "learning_rate": 0.08153796058424438,
      "loss": 3.0308,
      "step": 114880
    },
    {
      "epoch": 184.73,
      "learning_rate": 0.0815347451533762,
      "loss": 3.0115,
      "step": 114900
    },
    {
      "epoch": 184.76,
      "learning_rate": 0.08153152972250804,
      "loss": 3.0285,
      "step": 114920
    },
    {
      "epoch": 184.79,
      "learning_rate": 0.08152831429163988,
      "loss": 3.0162,
      "step": 114940
    },
    {
      "epoch": 184.82,
      "learning_rate": 0.08152509886077171,
      "loss": 2.96,
      "step": 114960
    },
    {
      "epoch": 184.86,
      "learning_rate": 0.08152188342990353,
      "loss": 3.0093,
      "step": 114980
    },
    {
      "epoch": 184.89,
      "learning_rate": 0.08151866799903537,
      "loss": 3.0126,
      "step": 115000
    },
    {
      "epoch": 184.92,
      "learning_rate": 0.08151545256816721,
      "loss": 3.0669,
      "step": 115020
    },
    {
      "epoch": 184.95,
      "learning_rate": 0.08151223713729905,
      "loss": 3.0165,
      "step": 115040
    },
    {
      "epoch": 184.98,
      "learning_rate": 0.08150902170643087,
      "loss": 3.0355,
      "step": 115060
    },
    {
      "epoch": 185.0,
      "eval_accuracy": {
        "accuracy": 0.36523361579724795
      },
      "eval_loss": 3.1550843715667725,
      "eval_runtime": 2.9962,
      "eval_samples_per_second": 4293.072,
      "eval_steps_per_second": 67.084,
      "step": 115070
    },
    {
      "epoch": 185.02,
      "learning_rate": 0.0815058062755627,
      "loss": 3.0016,
      "step": 115080
    },
    {
      "epoch": 185.05,
      "learning_rate": 0.08150259084469454,
      "loss": 3.0269,
      "step": 115100
    },
    {
      "epoch": 185.08,
      "learning_rate": 0.08149937541382637,
      "loss": 3.0553,
      "step": 115120
    },
    {
      "epoch": 185.11,
      "learning_rate": 0.08149615998295821,
      "loss": 2.9877,
      "step": 115140
    },
    {
      "epoch": 185.14,
      "learning_rate": 0.08149294455209004,
      "loss": 2.9735,
      "step": 115160
    },
    {
      "epoch": 185.18,
      "learning_rate": 0.08148972912122186,
      "loss": 2.995,
      "step": 115180
    },
    {
      "epoch": 185.21,
      "learning_rate": 0.0814865136903537,
      "loss": 2.9962,
      "step": 115200
    },
    {
      "epoch": 185.24,
      "learning_rate": 0.08148329825948554,
      "loss": 3.0062,
      "step": 115220
    },
    {
      "epoch": 185.27,
      "learning_rate": 0.08148008282861736,
      "loss": 3.0389,
      "step": 115240
    },
    {
      "epoch": 185.31,
      "learning_rate": 0.0814768673977492,
      "loss": 3.0174,
      "step": 115260
    },
    {
      "epoch": 185.34,
      "learning_rate": 0.08147365196688104,
      "loss": 2.9495,
      "step": 115280
    },
    {
      "epoch": 185.37,
      "learning_rate": 0.08147043653601287,
      "loss": 2.9841,
      "step": 115300
    },
    {
      "epoch": 185.4,
      "learning_rate": 0.08146722110514469,
      "loss": 2.9662,
      "step": 115320
    },
    {
      "epoch": 185.43,
      "learning_rate": 0.08146400567427653,
      "loss": 2.9934,
      "step": 115340
    },
    {
      "epoch": 185.47,
      "learning_rate": 0.08146079024340837,
      "loss": 2.9755,
      "step": 115360
    },
    {
      "epoch": 185.5,
      "learning_rate": 0.0814575748125402,
      "loss": 3.0226,
      "step": 115380
    },
    {
      "epoch": 185.53,
      "learning_rate": 0.08145435938167203,
      "loss": 3.0546,
      "step": 115400
    },
    {
      "epoch": 185.56,
      "learning_rate": 0.08145114395080386,
      "loss": 3.045,
      "step": 115420
    },
    {
      "epoch": 185.59,
      "learning_rate": 0.0814479285199357,
      "loss": 3.0858,
      "step": 115440
    },
    {
      "epoch": 185.63,
      "learning_rate": 0.08144471308906753,
      "loss": 3.0201,
      "step": 115460
    },
    {
      "epoch": 185.66,
      "learning_rate": 0.08144149765819937,
      "loss": 3.0175,
      "step": 115480
    },
    {
      "epoch": 185.69,
      "learning_rate": 0.0814382822273312,
      "loss": 3.0143,
      "step": 115500
    },
    {
      "epoch": 185.72,
      "learning_rate": 0.08143506679646302,
      "loss": 3.0657,
      "step": 115520
    },
    {
      "epoch": 185.76,
      "learning_rate": 0.08143185136559486,
      "loss": 3.0178,
      "step": 115540
    },
    {
      "epoch": 185.79,
      "learning_rate": 0.0814286359347267,
      "loss": 2.9972,
      "step": 115560
    },
    {
      "epoch": 185.82,
      "learning_rate": 0.08142542050385852,
      "loss": 3.0314,
      "step": 115580
    },
    {
      "epoch": 185.85,
      "learning_rate": 0.08142220507299036,
      "loss": 3.0017,
      "step": 115600
    },
    {
      "epoch": 185.88,
      "learning_rate": 0.08141898964212219,
      "loss": 2.9765,
      "step": 115620
    },
    {
      "epoch": 185.92,
      "learning_rate": 0.08141577421125402,
      "loss": 2.9952,
      "step": 115640
    },
    {
      "epoch": 185.95,
      "learning_rate": 0.08141255878038585,
      "loss": 3.0043,
      "step": 115660
    },
    {
      "epoch": 185.98,
      "learning_rate": 0.08140934334951769,
      "loss": 3.0333,
      "step": 115680
    },
    {
      "epoch": 186.0,
      "eval_accuracy": {
        "accuracy": 0.37324107906398196
      },
      "eval_loss": 3.111924648284912,
      "eval_runtime": 3.0625,
      "eval_samples_per_second": 4200.226,
      "eval_steps_per_second": 65.634,
      "step": 115692
    },
    {
      "epoch": 186.01,
      "learning_rate": 0.08140612791864953,
      "loss": 3.0029,
      "step": 115700
    },
    {
      "epoch": 186.05,
      "learning_rate": 0.08140291248778135,
      "loss": 3.05,
      "step": 115720
    },
    {
      "epoch": 186.08,
      "learning_rate": 0.08139969705691319,
      "loss": 3.0559,
      "step": 115740
    },
    {
      "epoch": 186.11,
      "learning_rate": 0.08139648162604501,
      "loss": 3.0461,
      "step": 115760
    },
    {
      "epoch": 186.14,
      "learning_rate": 0.08139326619517685,
      "loss": 3.0143,
      "step": 115780
    },
    {
      "epoch": 186.17,
      "learning_rate": 0.08139005076430869,
      "loss": 3.0449,
      "step": 115800
    },
    {
      "epoch": 186.21,
      "learning_rate": 0.08138683533344052,
      "loss": 2.978,
      "step": 115820
    },
    {
      "epoch": 186.24,
      "learning_rate": 0.08138361990257235,
      "loss": 3.0103,
      "step": 115840
    },
    {
      "epoch": 186.27,
      "learning_rate": 0.08138040447170418,
      "loss": 3.0063,
      "step": 115860
    },
    {
      "epoch": 186.3,
      "learning_rate": 0.08137718904083602,
      "loss": 3.0032,
      "step": 115880
    },
    {
      "epoch": 186.33,
      "learning_rate": 0.08137397360996786,
      "loss": 3.0198,
      "step": 115900
    },
    {
      "epoch": 186.37,
      "learning_rate": 0.08137075817909968,
      "loss": 2.9951,
      "step": 115920
    },
    {
      "epoch": 186.4,
      "learning_rate": 0.08136754274823152,
      "loss": 3.0296,
      "step": 115940
    },
    {
      "epoch": 186.43,
      "learning_rate": 0.08136432731736334,
      "loss": 3.0506,
      "step": 115960
    },
    {
      "epoch": 186.46,
      "learning_rate": 0.08136111188649518,
      "loss": 3.0161,
      "step": 115980
    },
    {
      "epoch": 186.5,
      "learning_rate": 0.08135789645562701,
      "loss": 3.0301,
      "step": 116000
    },
    {
      "epoch": 186.53,
      "learning_rate": 0.08135468102475885,
      "loss": 3.0197,
      "step": 116020
    },
    {
      "epoch": 186.56,
      "learning_rate": 0.08135146559389068,
      "loss": 3.0108,
      "step": 116040
    },
    {
      "epoch": 186.59,
      "learning_rate": 0.08134825016302251,
      "loss": 3.0262,
      "step": 116060
    },
    {
      "epoch": 186.62,
      "learning_rate": 0.08134503473215435,
      "loss": 3.0096,
      "step": 116080
    },
    {
      "epoch": 186.66,
      "learning_rate": 0.08134181930128617,
      "loss": 2.9817,
      "step": 116100
    },
    {
      "epoch": 186.69,
      "learning_rate": 0.08133860387041801,
      "loss": 3.0221,
      "step": 116120
    },
    {
      "epoch": 186.72,
      "learning_rate": 0.08133538843954985,
      "loss": 3.0043,
      "step": 116140
    },
    {
      "epoch": 186.75,
      "learning_rate": 0.08133217300868167,
      "loss": 3.0491,
      "step": 116160
    },
    {
      "epoch": 186.78,
      "learning_rate": 0.08132895757781351,
      "loss": 2.9962,
      "step": 116180
    },
    {
      "epoch": 186.82,
      "learning_rate": 0.08132574214694534,
      "loss": 3.021,
      "step": 116200
    },
    {
      "epoch": 186.85,
      "learning_rate": 0.08132252671607718,
      "loss": 3.0088,
      "step": 116220
    },
    {
      "epoch": 186.88,
      "learning_rate": 0.08131931128520901,
      "loss": 3.0008,
      "step": 116240
    },
    {
      "epoch": 186.91,
      "learning_rate": 0.08131609585434084,
      "loss": 3.0329,
      "step": 116260
    },
    {
      "epoch": 186.95,
      "learning_rate": 0.08131288042347268,
      "loss": 3.0118,
      "step": 116280
    },
    {
      "epoch": 186.98,
      "learning_rate": 0.0813096649926045,
      "loss": 2.977,
      "step": 116300
    },
    {
      "epoch": 187.0,
      "eval_accuracy": {
        "accuracy": 0.3686542797170178
      },
      "eval_loss": 3.13812518119812,
      "eval_runtime": 2.5667,
      "eval_samples_per_second": 5011.414,
      "eval_steps_per_second": 78.309,
      "step": 116314
    },
    {
      "epoch": 187.01,
      "learning_rate": 0.08130644956173634,
      "loss": 2.9864,
      "step": 116320
    },
    {
      "epoch": 187.04,
      "learning_rate": 0.08130323413086817,
      "loss": 2.9982,
      "step": 116340
    },
    {
      "epoch": 187.07,
      "learning_rate": 0.0813000187,
      "loss": 2.9872,
      "step": 116360
    },
    {
      "epoch": 187.11,
      "learning_rate": 0.08129680326913184,
      "loss": 3.0197,
      "step": 116380
    },
    {
      "epoch": 187.14,
      "learning_rate": 0.08129358783826367,
      "loss": 2.9909,
      "step": 116400
    },
    {
      "epoch": 187.17,
      "learning_rate": 0.0812903724073955,
      "loss": 3.0229,
      "step": 116420
    },
    {
      "epoch": 187.2,
      "learning_rate": 0.08128715697652733,
      "loss": 2.9805,
      "step": 116440
    },
    {
      "epoch": 187.23,
      "learning_rate": 0.08128394154565917,
      "loss": 3.0058,
      "step": 116460
    },
    {
      "epoch": 187.27,
      "learning_rate": 0.08128072611479101,
      "loss": 3.0233,
      "step": 116480
    },
    {
      "epoch": 187.3,
      "learning_rate": 0.08127751068392283,
      "loss": 3.0189,
      "step": 116500
    },
    {
      "epoch": 187.33,
      "learning_rate": 0.08127429525305467,
      "loss": 3.0043,
      "step": 116520
    },
    {
      "epoch": 187.36,
      "learning_rate": 0.0812710798221865,
      "loss": 2.9666,
      "step": 116540
    },
    {
      "epoch": 187.4,
      "learning_rate": 0.08126786439131833,
      "loss": 2.9843,
      "step": 116560
    },
    {
      "epoch": 187.43,
      "learning_rate": 0.08126464896045017,
      "loss": 3.0131,
      "step": 116580
    },
    {
      "epoch": 187.46,
      "learning_rate": 0.081261433529582,
      "loss": 3.0225,
      "step": 116600
    },
    {
      "epoch": 187.49,
      "learning_rate": 0.08125821809871384,
      "loss": 3.0152,
      "step": 116620
    },
    {
      "epoch": 187.52,
      "learning_rate": 0.08125500266784566,
      "loss": 3.0243,
      "step": 116640
    },
    {
      "epoch": 187.56,
      "learning_rate": 0.0812517872369775,
      "loss": 2.9914,
      "step": 116660
    },
    {
      "epoch": 187.59,
      "learning_rate": 0.08124857180610932,
      "loss": 2.98,
      "step": 116680
    },
    {
      "epoch": 187.62,
      "learning_rate": 0.08124535637524116,
      "loss": 3.0711,
      "step": 116700
    },
    {
      "epoch": 187.65,
      "learning_rate": 0.081242140944373,
      "loss": 3.0347,
      "step": 116720
    },
    {
      "epoch": 187.68,
      "learning_rate": 0.08123892551350483,
      "loss": 3.0106,
      "step": 116740
    },
    {
      "epoch": 187.72,
      "learning_rate": 0.08123571008263666,
      "loss": 2.9939,
      "step": 116760
    },
    {
      "epoch": 187.75,
      "learning_rate": 0.08123249465176849,
      "loss": 3.0424,
      "step": 116780
    },
    {
      "epoch": 187.78,
      "learning_rate": 0.08122927922090033,
      "loss": 3.0389,
      "step": 116800
    },
    {
      "epoch": 187.81,
      "learning_rate": 0.08122606379003217,
      "loss": 3.0171,
      "step": 116820
    },
    {
      "epoch": 187.85,
      "learning_rate": 0.08122284835916399,
      "loss": 3.0127,
      "step": 116840
    },
    {
      "epoch": 187.88,
      "learning_rate": 0.08121963292829583,
      "loss": 3.0302,
      "step": 116860
    },
    {
      "epoch": 187.91,
      "learning_rate": 0.08121641749742765,
      "loss": 3.0544,
      "step": 116880
    },
    {
      "epoch": 187.94,
      "learning_rate": 0.08121320206655949,
      "loss": 2.991,
      "step": 116900
    },
    {
      "epoch": 187.97,
      "learning_rate": 0.08120998663569133,
      "loss": 2.9932,
      "step": 116920
    },
    {
      "epoch": 188.0,
      "eval_accuracy": {
        "accuracy": 0.3745626992148021
      },
      "eval_loss": 3.0952701568603516,
      "eval_runtime": 2.5989,
      "eval_samples_per_second": 4949.356,
      "eval_steps_per_second": 77.34,
      "step": 116936
    },
    {
      "epoch": 188.01,
      "learning_rate": 0.08120677120482316,
      "loss": 2.9944,
      "step": 116940
    },
    {
      "epoch": 188.04,
      "learning_rate": 0.081203555773955,
      "loss": 3.0337,
      "step": 116960
    },
    {
      "epoch": 188.07,
      "learning_rate": 0.08120034034308682,
      "loss": 3.0449,
      "step": 116980
    },
    {
      "epoch": 188.1,
      "learning_rate": 0.08119712491221866,
      "loss": 3.0294,
      "step": 117000
    },
    {
      "epoch": 188.14,
      "learning_rate": 0.08119390948135048,
      "loss": 2.9946,
      "step": 117020
    },
    {
      "epoch": 188.17,
      "learning_rate": 0.08119069405048232,
      "loss": 2.9788,
      "step": 117040
    },
    {
      "epoch": 188.2,
      "learning_rate": 0.08118747861961416,
      "loss": 2.976,
      "step": 117060
    },
    {
      "epoch": 188.23,
      "learning_rate": 0.08118426318874598,
      "loss": 3.016,
      "step": 117080
    },
    {
      "epoch": 188.26,
      "learning_rate": 0.08118104775787782,
      "loss": 3.0183,
      "step": 117100
    },
    {
      "epoch": 188.3,
      "learning_rate": 0.08117783232700965,
      "loss": 3.015,
      "step": 117120
    },
    {
      "epoch": 188.33,
      "learning_rate": 0.08117461689614149,
      "loss": 3.0134,
      "step": 117140
    },
    {
      "epoch": 188.36,
      "learning_rate": 0.08117140146527332,
      "loss": 3.0273,
      "step": 117160
    },
    {
      "epoch": 188.39,
      "learning_rate": 0.08116818603440515,
      "loss": 3.0027,
      "step": 117180
    },
    {
      "epoch": 188.42,
      "learning_rate": 0.08116497060353699,
      "loss": 3.0423,
      "step": 117200
    },
    {
      "epoch": 188.46,
      "learning_rate": 0.08116175517266881,
      "loss": 3.0124,
      "step": 117220
    },
    {
      "epoch": 188.49,
      "learning_rate": 0.08115853974180065,
      "loss": 3.0218,
      "step": 117240
    },
    {
      "epoch": 188.52,
      "learning_rate": 0.08115532431093249,
      "loss": 3.0177,
      "step": 117260
    },
    {
      "epoch": 188.55,
      "learning_rate": 0.08115210888006431,
      "loss": 2.9873,
      "step": 117280
    },
    {
      "epoch": 188.59,
      "learning_rate": 0.08114889344919615,
      "loss": 3.0103,
      "step": 117300
    },
    {
      "epoch": 188.62,
      "learning_rate": 0.08114567801832798,
      "loss": 3.0089,
      "step": 117320
    },
    {
      "epoch": 188.65,
      "learning_rate": 0.08114246258745982,
      "loss": 3.0162,
      "step": 117340
    },
    {
      "epoch": 188.68,
      "learning_rate": 0.08113924715659164,
      "loss": 3.0604,
      "step": 117360
    },
    {
      "epoch": 188.71,
      "learning_rate": 0.08113603172572348,
      "loss": 3.0337,
      "step": 117380
    },
    {
      "epoch": 188.75,
      "learning_rate": 0.08113281629485532,
      "loss": 2.9934,
      "step": 117400
    },
    {
      "epoch": 188.78,
      "learning_rate": 0.08112960086398714,
      "loss": 2.9892,
      "step": 117420
    },
    {
      "epoch": 188.81,
      "learning_rate": 0.08112638543311898,
      "loss": 3.0032,
      "step": 117440
    },
    {
      "epoch": 188.84,
      "learning_rate": 0.0811231700022508,
      "loss": 3.0364,
      "step": 117460
    },
    {
      "epoch": 188.87,
      "learning_rate": 0.08111995457138264,
      "loss": 3.0472,
      "step": 117480
    },
    {
      "epoch": 188.91,
      "learning_rate": 0.08111673914051448,
      "loss": 3.0356,
      "step": 117500
    },
    {
      "epoch": 188.94,
      "learning_rate": 0.0811135237096463,
      "loss": 3.044,
      "step": 117520
    },
    {
      "epoch": 188.97,
      "learning_rate": 0.08111030827877815,
      "loss": 2.9812,
      "step": 117540
    },
    {
      "epoch": 189.0,
      "eval_accuracy": {
        "accuracy": 0.37821659022001086
      },
      "eval_loss": 3.096095085144043,
      "eval_runtime": 2.7253,
      "eval_samples_per_second": 4719.891,
      "eval_steps_per_second": 73.754,
      "step": 117558
    },
    {
      "epoch": 189.0,
      "learning_rate": 0.08110709284790997,
      "loss": 3.0435,
      "step": 117560
    },
    {
      "epoch": 189.04,
      "learning_rate": 0.08110387741704181,
      "loss": 2.9982,
      "step": 117580
    },
    {
      "epoch": 189.07,
      "learning_rate": 0.08110066198617365,
      "loss": 2.9997,
      "step": 117600
    },
    {
      "epoch": 189.1,
      "learning_rate": 0.08109744655530547,
      "loss": 3.0033,
      "step": 117620
    },
    {
      "epoch": 189.13,
      "learning_rate": 0.08109439189598071,
      "loss": 2.9916,
      "step": 117640
    },
    {
      "epoch": 189.16,
      "learning_rate": 0.08109117646511255,
      "loss": 3.083,
      "step": 117660
    },
    {
      "epoch": 189.2,
      "learning_rate": 0.08108796103424439,
      "loss": 3.0001,
      "step": 117680
    },
    {
      "epoch": 189.23,
      "learning_rate": 0.08108474560337621,
      "loss": 3.005,
      "step": 117700
    },
    {
      "epoch": 189.26,
      "learning_rate": 0.08108153017250803,
      "loss": 3.0107,
      "step": 117720
    },
    {
      "epoch": 189.29,
      "learning_rate": 0.08107831474163987,
      "loss": 2.9962,
      "step": 117740
    },
    {
      "epoch": 189.32,
      "learning_rate": 0.08107509931077171,
      "loss": 3.007,
      "step": 117760
    },
    {
      "epoch": 189.36,
      "learning_rate": 0.08107188387990355,
      "loss": 3.0034,
      "step": 117780
    },
    {
      "epoch": 189.39,
      "learning_rate": 0.08106866844903537,
      "loss": 3.0165,
      "step": 117800
    },
    {
      "epoch": 189.42,
      "learning_rate": 0.0810654530181672,
      "loss": 3.0218,
      "step": 117820
    },
    {
      "epoch": 189.45,
      "learning_rate": 0.08106223758729904,
      "loss": 3.0309,
      "step": 117840
    },
    {
      "epoch": 189.49,
      "learning_rate": 0.08105902215643088,
      "loss": 3.0411,
      "step": 117860
    },
    {
      "epoch": 189.52,
      "learning_rate": 0.08105580672556272,
      "loss": 3.0027,
      "step": 117880
    },
    {
      "epoch": 189.55,
      "learning_rate": 0.08105259129469454,
      "loss": 3.0156,
      "step": 117900
    },
    {
      "epoch": 189.58,
      "learning_rate": 0.08104937586382636,
      "loss": 2.9896,
      "step": 117920
    },
    {
      "epoch": 189.61,
      "learning_rate": 0.0810461604329582,
      "loss": 2.9867,
      "step": 117940
    },
    {
      "epoch": 189.65,
      "learning_rate": 0.08104294500209004,
      "loss": 2.9993,
      "step": 117960
    },
    {
      "epoch": 189.68,
      "learning_rate": 0.08103972957122187,
      "loss": 3.0541,
      "step": 117980
    },
    {
      "epoch": 189.71,
      "learning_rate": 0.0810365141403537,
      "loss": 3.0544,
      "step": 118000
    },
    {
      "epoch": 189.74,
      "learning_rate": 0.08103329870948553,
      "loss": 3.0002,
      "step": 118020
    },
    {
      "epoch": 189.77,
      "learning_rate": 0.08103008327861737,
      "loss": 2.9973,
      "step": 118040
    },
    {
      "epoch": 189.81,
      "learning_rate": 0.08102686784774919,
      "loss": 2.9791,
      "step": 118060
    },
    {
      "epoch": 189.84,
      "learning_rate": 0.08102365241688103,
      "loss": 2.9879,
      "step": 118080
    },
    {
      "epoch": 189.87,
      "learning_rate": 0.08102043698601287,
      "loss": 2.9932,
      "step": 118100
    },
    {
      "epoch": 189.9,
      "learning_rate": 0.08101722155514471,
      "loss": 3.0497,
      "step": 118120
    },
    {
      "epoch": 189.94,
      "learning_rate": 0.08101400612427653,
      "loss": 3.0077,
      "step": 118140
    },
    {
      "epoch": 189.97,
      "learning_rate": 0.08101079069340836,
      "loss": 2.9746,
      "step": 118160
    },
    {
      "epoch": 190.0,
      "learning_rate": 0.0810075752625402,
      "loss": 2.9813,
      "step": 118180
    },
    {
      "epoch": 190.0,
      "eval_accuracy": {
        "accuracy": 0.37922724092357923
      },
      "eval_loss": 3.078728675842285,
      "eval_runtime": 3.0697,
      "eval_samples_per_second": 4190.297,
      "eval_steps_per_second": 65.478,
      "step": 118180
    },
    {
      "epoch": 190.03,
      "learning_rate": 0.08100435983167203,
      "loss": 3.014,
      "step": 118200
    },
    {
      "epoch": 190.06,
      "learning_rate": 0.08100114440080387,
      "loss": 3.0053,
      "step": 118220
    },
    {
      "epoch": 190.1,
      "learning_rate": 0.0809979289699357,
      "loss": 3.0116,
      "step": 118240
    },
    {
      "epoch": 190.13,
      "learning_rate": 0.08099471353906752,
      "loss": 2.9975,
      "step": 118260
    },
    {
      "epoch": 190.16,
      "learning_rate": 0.08099149810819936,
      "loss": 2.9746,
      "step": 118280
    },
    {
      "epoch": 190.19,
      "learning_rate": 0.0809882826773312,
      "loss": 3.0056,
      "step": 118300
    },
    {
      "epoch": 190.23,
      "learning_rate": 0.08098506724646302,
      "loss": 2.9965,
      "step": 118320
    },
    {
      "epoch": 190.26,
      "learning_rate": 0.08098185181559486,
      "loss": 2.9645,
      "step": 118340
    },
    {
      "epoch": 190.29,
      "learning_rate": 0.08097863638472669,
      "loss": 2.9953,
      "step": 118360
    },
    {
      "epoch": 190.32,
      "learning_rate": 0.08097542095385853,
      "loss": 3.0167,
      "step": 118380
    },
    {
      "epoch": 190.35,
      "learning_rate": 0.08097220552299035,
      "loss": 2.9912,
      "step": 118400
    },
    {
      "epoch": 190.39,
      "learning_rate": 0.08096899009212219,
      "loss": 2.9731,
      "step": 118420
    },
    {
      "epoch": 190.42,
      "learning_rate": 0.08096577466125403,
      "loss": 2.9885,
      "step": 118440
    },
    {
      "epoch": 190.45,
      "learning_rate": 0.08096255923038585,
      "loss": 2.9926,
      "step": 118460
    },
    {
      "epoch": 190.48,
      "learning_rate": 0.08095934379951769,
      "loss": 3.0035,
      "step": 118480
    },
    {
      "epoch": 190.51,
      "learning_rate": 0.08095612836864952,
      "loss": 2.9887,
      "step": 118500
    },
    {
      "epoch": 190.55,
      "learning_rate": 0.08095291293778135,
      "loss": 3.0127,
      "step": 118520
    },
    {
      "epoch": 190.58,
      "learning_rate": 0.08094969750691319,
      "loss": 3.0118,
      "step": 118540
    },
    {
      "epoch": 190.61,
      "learning_rate": 0.08094648207604502,
      "loss": 2.9953,
      "step": 118560
    },
    {
      "epoch": 190.64,
      "learning_rate": 0.08094326664517686,
      "loss": 3.009,
      "step": 118580
    },
    {
      "epoch": 190.68,
      "learning_rate": 0.08094005121430868,
      "loss": 3.0258,
      "step": 118600
    },
    {
      "epoch": 190.71,
      "learning_rate": 0.08093683578344052,
      "loss": 3.0166,
      "step": 118620
    },
    {
      "epoch": 190.74,
      "learning_rate": 0.08093362035257236,
      "loss": 3.0215,
      "step": 118640
    },
    {
      "epoch": 190.77,
      "learning_rate": 0.08093040492170418,
      "loss": 3.0109,
      "step": 118660
    },
    {
      "epoch": 190.8,
      "learning_rate": 0.08092718949083602,
      "loss": 3.0347,
      "step": 118680
    },
    {
      "epoch": 190.84,
      "learning_rate": 0.08092397405996785,
      "loss": 3.0242,
      "step": 118700
    },
    {
      "epoch": 190.87,
      "learning_rate": 0.08092075862909968,
      "loss": 2.9728,
      "step": 118720
    },
    {
      "epoch": 190.9,
      "learning_rate": 0.08091754319823151,
      "loss": 3.0071,
      "step": 118740
    },
    {
      "epoch": 190.93,
      "learning_rate": 0.08091432776736335,
      "loss": 3.0046,
      "step": 118760
    },
    {
      "epoch": 190.96,
      "learning_rate": 0.08091111233649519,
      "loss": 3.0009,
      "step": 118780
    },
    {
      "epoch": 191.0,
      "learning_rate": 0.08090789690562701,
      "loss": 2.9754,
      "step": 118800
    },
    {
      "epoch": 191.0,
      "eval_accuracy": {
        "accuracy": 0.3782943325818238
      },
      "eval_loss": 3.0915281772613525,
      "eval_runtime": 2.6414,
      "eval_samples_per_second": 4869.693,
      "eval_steps_per_second": 76.095,
      "step": 118802
    },
    {
      "epoch": 191.03,
      "learning_rate": 0.08090468147475885,
      "loss": 2.9967,
      "step": 118820
    },
    {
      "epoch": 191.06,
      "learning_rate": 0.08090146604389067,
      "loss": 3.0259,
      "step": 118840
    },
    {
      "epoch": 191.09,
      "learning_rate": 0.08089825061302251,
      "loss": 3.0263,
      "step": 118860
    },
    {
      "epoch": 191.13,
      "learning_rate": 0.08089503518215435,
      "loss": 3.0056,
      "step": 118880
    },
    {
      "epoch": 191.16,
      "learning_rate": 0.08089181975128618,
      "loss": 2.9593,
      "step": 118900
    },
    {
      "epoch": 191.19,
      "learning_rate": 0.08088860432041801,
      "loss": 2.954,
      "step": 118920
    },
    {
      "epoch": 191.22,
      "learning_rate": 0.08088538888954984,
      "loss": 2.9804,
      "step": 118940
    },
    {
      "epoch": 191.25,
      "learning_rate": 0.08088217345868168,
      "loss": 2.984,
      "step": 118960
    },
    {
      "epoch": 191.29,
      "learning_rate": 0.08087895802781352,
      "loss": 3.059,
      "step": 118980
    },
    {
      "epoch": 191.32,
      "learning_rate": 0.08087574259694534,
      "loss": 2.9799,
      "step": 119000
    },
    {
      "epoch": 191.35,
      "learning_rate": 0.08087252716607718,
      "loss": 2.9982,
      "step": 119020
    },
    {
      "epoch": 191.38,
      "learning_rate": 0.080869311735209,
      "loss": 3.029,
      "step": 119040
    },
    {
      "epoch": 191.41,
      "learning_rate": 0.08086609630434084,
      "loss": 3.0005,
      "step": 119060
    },
    {
      "epoch": 191.45,
      "learning_rate": 0.08086288087347267,
      "loss": 3.0413,
      "step": 119080
    },
    {
      "epoch": 191.48,
      "learning_rate": 0.0808596654426045,
      "loss": 3.0202,
      "step": 119100
    },
    {
      "epoch": 191.51,
      "learning_rate": 0.08085645001173634,
      "loss": 3.0116,
      "step": 119120
    },
    {
      "epoch": 191.54,
      "learning_rate": 0.08085323458086817,
      "loss": 2.9994,
      "step": 119140
    },
    {
      "epoch": 191.58,
      "learning_rate": 0.08085001915000001,
      "loss": 3.0144,
      "step": 119160
    },
    {
      "epoch": 191.61,
      "learning_rate": 0.08084680371913183,
      "loss": 2.99,
      "step": 119180
    },
    {
      "epoch": 191.64,
      "learning_rate": 0.08084358828826367,
      "loss": 2.9883,
      "step": 119200
    },
    {
      "epoch": 191.67,
      "learning_rate": 0.08084037285739551,
      "loss": 3.0232,
      "step": 119220
    },
    {
      "epoch": 191.7,
      "learning_rate": 0.08083715742652733,
      "loss": 3.0053,
      "step": 119240
    },
    {
      "epoch": 191.74,
      "learning_rate": 0.08083394199565917,
      "loss": 3.0098,
      "step": 119260
    },
    {
      "epoch": 191.77,
      "learning_rate": 0.080830726564791,
      "loss": 3.0132,
      "step": 119280
    },
    {
      "epoch": 191.8,
      "learning_rate": 0.08082751113392284,
      "loss": 3.0075,
      "step": 119300
    },
    {
      "epoch": 191.83,
      "learning_rate": 0.08082429570305467,
      "loss": 3.0393,
      "step": 119320
    },
    {
      "epoch": 191.86,
      "learning_rate": 0.0808210802721865,
      "loss": 3.0764,
      "step": 119340
    },
    {
      "epoch": 191.9,
      "learning_rate": 0.08081786484131834,
      "loss": 3.0404,
      "step": 119360
    },
    {
      "epoch": 191.93,
      "learning_rate": 0.08081464941045016,
      "loss": 3.0128,
      "step": 119380
    },
    {
      "epoch": 191.96,
      "learning_rate": 0.080811433979582,
      "loss": 3.0048,
      "step": 119400
    },
    {
      "epoch": 191.99,
      "learning_rate": 0.08080821854871383,
      "loss": 2.9851,
      "step": 119420
    },
    {
      "epoch": 192.0,
      "eval_accuracy": {
        "accuracy": 0.3746404415766151
      },
      "eval_loss": 3.100102424621582,
      "eval_runtime": 2.6424,
      "eval_samples_per_second": 4867.949,
      "eval_steps_per_second": 76.068,
      "step": 119424
    },
    {
      "epoch": 192.03,
      "learning_rate": 0.08080500311784566,
      "loss": 2.9828,
      "step": 119440
    },
    {
      "epoch": 192.06,
      "learning_rate": 0.0808017876869775,
      "loss": 3.0268,
      "step": 119460
    },
    {
      "epoch": 192.09,
      "learning_rate": 0.08079857225610933,
      "loss": 3.005,
      "step": 119480
    },
    {
      "epoch": 192.12,
      "learning_rate": 0.08079535682524117,
      "loss": 2.9971,
      "step": 119500
    },
    {
      "epoch": 192.15,
      "learning_rate": 0.08079214139437299,
      "loss": 3.0088,
      "step": 119520
    },
    {
      "epoch": 192.19,
      "learning_rate": 0.08078892596350483,
      "loss": 2.9865,
      "step": 119540
    },
    {
      "epoch": 192.22,
      "learning_rate": 0.08078571053263667,
      "loss": 3.0589,
      "step": 119560
    },
    {
      "epoch": 192.25,
      "learning_rate": 0.08078249510176849,
      "loss": 2.9946,
      "step": 119580
    },
    {
      "epoch": 192.28,
      "learning_rate": 0.08077927967090033,
      "loss": 3.018,
      "step": 119600
    },
    {
      "epoch": 192.32,
      "learning_rate": 0.08077606424003216,
      "loss": 2.9984,
      "step": 119620
    },
    {
      "epoch": 192.35,
      "learning_rate": 0.080772848809164,
      "loss": 2.9974,
      "step": 119640
    },
    {
      "epoch": 192.38,
      "learning_rate": 0.08076963337829583,
      "loss": 2.9823,
      "step": 119660
    },
    {
      "epoch": 192.41,
      "learning_rate": 0.08076641794742766,
      "loss": 2.9888,
      "step": 119680
    },
    {
      "epoch": 192.44,
      "learning_rate": 0.0807632025165595,
      "loss": 2.9905,
      "step": 119700
    },
    {
      "epoch": 192.48,
      "learning_rate": 0.08075998708569132,
      "loss": 2.9899,
      "step": 119720
    },
    {
      "epoch": 192.51,
      "learning_rate": 0.08075677165482316,
      "loss": 2.9575,
      "step": 119740
    },
    {
      "epoch": 192.54,
      "learning_rate": 0.08075355622395498,
      "loss": 2.9888,
      "step": 119760
    },
    {
      "epoch": 192.57,
      "learning_rate": 0.08075034079308682,
      "loss": 3.002,
      "step": 119780
    },
    {
      "epoch": 192.6,
      "learning_rate": 0.08074712536221866,
      "loss": 3.008,
      "step": 119800
    },
    {
      "epoch": 192.64,
      "learning_rate": 0.08074390993135049,
      "loss": 2.9877,
      "step": 119820
    },
    {
      "epoch": 192.67,
      "learning_rate": 0.08074069450048232,
      "loss": 2.9764,
      "step": 119840
    },
    {
      "epoch": 192.7,
      "learning_rate": 0.08073747906961415,
      "loss": 2.9863,
      "step": 119860
    },
    {
      "epoch": 192.73,
      "learning_rate": 0.08073426363874599,
      "loss": 2.9867,
      "step": 119880
    },
    {
      "epoch": 192.77,
      "learning_rate": 0.08073104820787783,
      "loss": 2.9974,
      "step": 119900
    },
    {
      "epoch": 192.8,
      "learning_rate": 0.08072783277700965,
      "loss": 3.0061,
      "step": 119920
    },
    {
      "epoch": 192.83,
      "learning_rate": 0.08072461734614149,
      "loss": 2.9941,
      "step": 119940
    },
    {
      "epoch": 192.86,
      "learning_rate": 0.08072140191527331,
      "loss": 2.997,
      "step": 119960
    },
    {
      "epoch": 192.89,
      "learning_rate": 0.08071818648440515,
      "loss": 3.0005,
      "step": 119980
    },
    {
      "epoch": 192.93,
      "learning_rate": 0.08071497105353699,
      "loss": 3.0155,
      "step": 120000
    },
    {
      "epoch": 192.96,
      "learning_rate": 0.08071175562266882,
      "loss": 2.9964,
      "step": 120020
    },
    {
      "epoch": 192.99,
      "learning_rate": 0.08070854019180065,
      "loss": 3.0047,
      "step": 120040
    },
    {
      "epoch": 193.0,
      "eval_accuracy": {
        "accuracy": 0.3800046645417088
      },
      "eval_loss": 3.061109781265259,
      "eval_runtime": 2.9875,
      "eval_samples_per_second": 4305.564,
      "eval_steps_per_second": 67.28,
      "step": 120046
    },
    {
      "epoch": 193.02,
      "learning_rate": 0.08070532476093248,
      "loss": 3.0038,
      "step": 120060
    },
    {
      "epoch": 193.05,
      "learning_rate": 0.08070210933006432,
      "loss": 3.0023,
      "step": 120080
    },
    {
      "epoch": 193.09,
      "learning_rate": 0.08069889389919614,
      "loss": 3.0235,
      "step": 120100
    },
    {
      "epoch": 193.12,
      "learning_rate": 0.08069567846832797,
      "loss": 3.0057,
      "step": 120120
    },
    {
      "epoch": 193.15,
      "learning_rate": 0.08069246303745982,
      "loss": 3.0055,
      "step": 120140
    },
    {
      "epoch": 193.18,
      "learning_rate": 0.08068924760659164,
      "loss": 2.9561,
      "step": 120160
    },
    {
      "epoch": 193.22,
      "learning_rate": 0.08068603217572348,
      "loss": 2.9793,
      "step": 120180
    },
    {
      "epoch": 193.25,
      "learning_rate": 0.0806828167448553,
      "loss": 2.9739,
      "step": 120200
    },
    {
      "epoch": 193.28,
      "learning_rate": 0.08067960131398715,
      "loss": 2.9961,
      "step": 120220
    },
    {
      "epoch": 193.31,
      "learning_rate": 0.08067638588311898,
      "loss": 2.994,
      "step": 120240
    },
    {
      "epoch": 193.34,
      "learning_rate": 0.08067317045225081,
      "loss": 2.9864,
      "step": 120260
    },
    {
      "epoch": 193.38,
      "learning_rate": 0.08066995502138265,
      "loss": 3.0163,
      "step": 120280
    },
    {
      "epoch": 193.41,
      "learning_rate": 0.08066673959051447,
      "loss": 2.9801,
      "step": 120300
    },
    {
      "epoch": 193.44,
      "learning_rate": 0.08066352415964631,
      "loss": 3.0439,
      "step": 120320
    },
    {
      "epoch": 193.47,
      "learning_rate": 0.08066030872877815,
      "loss": 3.0646,
      "step": 120340
    },
    {
      "epoch": 193.5,
      "learning_rate": 0.08065709329790997,
      "loss": 3.0087,
      "step": 120360
    },
    {
      "epoch": 193.54,
      "learning_rate": 0.08065387786704181,
      "loss": 3.0178,
      "step": 120380
    },
    {
      "epoch": 193.57,
      "learning_rate": 0.08065066243617364,
      "loss": 3.004,
      "step": 120400
    },
    {
      "epoch": 193.6,
      "learning_rate": 0.08064744700530548,
      "loss": 3.0337,
      "step": 120420
    },
    {
      "epoch": 193.63,
      "learning_rate": 0.0806442315744373,
      "loss": 2.9985,
      "step": 120440
    },
    {
      "epoch": 193.67,
      "learning_rate": 0.08064101614356912,
      "loss": 2.9837,
      "step": 120460
    },
    {
      "epoch": 193.7,
      "learning_rate": 0.08063780071270098,
      "loss": 3.0337,
      "step": 120480
    },
    {
      "epoch": 193.73,
      "learning_rate": 0.0806345852818328,
      "loss": 3.0369,
      "step": 120500
    },
    {
      "epoch": 193.76,
      "learning_rate": 0.08063136985096464,
      "loss": 3.0339,
      "step": 120520
    },
    {
      "epoch": 193.79,
      "learning_rate": 0.08062815442009647,
      "loss": 3.0211,
      "step": 120540
    },
    {
      "epoch": 193.83,
      "learning_rate": 0.08062493898922829,
      "loss": 2.9958,
      "step": 120560
    },
    {
      "epoch": 193.86,
      "learning_rate": 0.08062172355836014,
      "loss": 2.9939,
      "step": 120580
    },
    {
      "epoch": 193.89,
      "learning_rate": 0.08061850812749197,
      "loss": 2.9851,
      "step": 120600
    },
    {
      "epoch": 193.92,
      "learning_rate": 0.0806152926966238,
      "loss": 3.02,
      "step": 120620
    },
    {
      "epoch": 193.95,
      "learning_rate": 0.08061207726575563,
      "loss": 2.9938,
      "step": 120640
    },
    {
      "epoch": 193.99,
      "learning_rate": 0.08060886183488745,
      "loss": 3.0169,
      "step": 120660
    },
    {
      "epoch": 194.0,
      "eval_accuracy": {
        "accuracy": 0.37230817072222655
      },
      "eval_loss": 3.1210803985595703,
      "eval_runtime": 2.8049,
      "eval_samples_per_second": 4585.913,
      "eval_steps_per_second": 71.66,
      "step": 120668
    },
    {
      "epoch": 194.02,
      "learning_rate": 0.08060564640401931,
      "loss": 2.9931,
      "step": 120680
    },
    {
      "epoch": 194.05,
      "learning_rate": 0.08060243097315113,
      "loss": 3.0197,
      "step": 120700
    },
    {
      "epoch": 194.08,
      "learning_rate": 0.08059921554228297,
      "loss": 3.0511,
      "step": 120720
    },
    {
      "epoch": 194.12,
      "learning_rate": 0.0805960001114148,
      "loss": 3.0314,
      "step": 120740
    },
    {
      "epoch": 194.15,
      "learning_rate": 0.08059278468054662,
      "loss": 3.003,
      "step": 120760
    },
    {
      "epoch": 194.18,
      "learning_rate": 0.08058956924967847,
      "loss": 2.992,
      "step": 120780
    },
    {
      "epoch": 194.21,
      "learning_rate": 0.08058635381881028,
      "loss": 3.0127,
      "step": 120800
    },
    {
      "epoch": 194.24,
      "learning_rate": 0.08058313838794214,
      "loss": 3.0237,
      "step": 120820
    },
    {
      "epoch": 194.28,
      "learning_rate": 0.08057992295707396,
      "loss": 2.9784,
      "step": 120840
    },
    {
      "epoch": 194.31,
      "learning_rate": 0.0805767075262058,
      "loss": 2.9813,
      "step": 120860
    },
    {
      "epoch": 194.34,
      "learning_rate": 0.08057349209533762,
      "loss": 3.019,
      "step": 120880
    },
    {
      "epoch": 194.37,
      "learning_rate": 0.08057027666446945,
      "loss": 3.0264,
      "step": 120900
    },
    {
      "epoch": 194.41,
      "learning_rate": 0.0805670612336013,
      "loss": 3.0092,
      "step": 120920
    },
    {
      "epoch": 194.44,
      "learning_rate": 0.08056384580273313,
      "loss": 2.9988,
      "step": 120940
    },
    {
      "epoch": 194.47,
      "learning_rate": 0.08056063037186496,
      "loss": 2.9871,
      "step": 120960
    },
    {
      "epoch": 194.5,
      "learning_rate": 0.08055741494099679,
      "loss": 3.0347,
      "step": 120980
    },
    {
      "epoch": 194.53,
      "learning_rate": 0.08055419951012861,
      "loss": 3.0219,
      "step": 121000
    },
    {
      "epoch": 194.57,
      "learning_rate": 0.08055098407926047,
      "loss": 2.9796,
      "step": 121020
    },
    {
      "epoch": 194.6,
      "learning_rate": 0.08054776864839229,
      "loss": 3.0286,
      "step": 121040
    },
    {
      "epoch": 194.63,
      "learning_rate": 0.08054455321752413,
      "loss": 3.005,
      "step": 121060
    },
    {
      "epoch": 194.66,
      "learning_rate": 0.08054133778665595,
      "loss": 2.9874,
      "step": 121080
    },
    {
      "epoch": 194.69,
      "learning_rate": 0.08053812235578778,
      "loss": 2.9903,
      "step": 121100
    },
    {
      "epoch": 194.73,
      "learning_rate": 0.08053490692491963,
      "loss": 3.0251,
      "step": 121120
    },
    {
      "epoch": 194.76,
      "learning_rate": 0.08053169149405144,
      "loss": 3.0066,
      "step": 121140
    },
    {
      "epoch": 194.79,
      "learning_rate": 0.0805284760631833,
      "loss": 3.0311,
      "step": 121160
    },
    {
      "epoch": 194.82,
      "learning_rate": 0.08052526063231512,
      "loss": 2.9831,
      "step": 121180
    },
    {
      "epoch": 194.86,
      "learning_rate": 0.08052204520144694,
      "loss": 2.9891,
      "step": 121200
    },
    {
      "epoch": 194.89,
      "learning_rate": 0.08051882977057878,
      "loss": 2.9994,
      "step": 121220
    },
    {
      "epoch": 194.92,
      "learning_rate": 0.0805156143397106,
      "loss": 2.9902,
      "step": 121240
    },
    {
      "epoch": 194.95,
      "learning_rate": 0.08051239890884246,
      "loss": 2.981,
      "step": 121260
    },
    {
      "epoch": 194.98,
      "learning_rate": 0.08050918347797428,
      "loss": 3.001,
      "step": 121280
    },
    {
      "epoch": 195.0,
      "eval_accuracy": {
        "accuracy": 0.37067558112415455
      },
      "eval_loss": 3.1522371768951416,
      "eval_runtime": 2.7156,
      "eval_samples_per_second": 4736.654,
      "eval_steps_per_second": 74.016,
      "step": 121290
    },
    {
      "epoch": 195.02,
      "learning_rate": 0.08050596804710611,
      "loss": 3.0254,
      "step": 121300
    },
    {
      "epoch": 195.05,
      "learning_rate": 0.08050275261623795,
      "loss": 3.0034,
      "step": 121320
    },
    {
      "epoch": 195.08,
      "learning_rate": 0.08049953718536977,
      "loss": 3.0112,
      "step": 121340
    },
    {
      "epoch": 195.11,
      "learning_rate": 0.08049632175450162,
      "loss": 3.0022,
      "step": 121360
    },
    {
      "epoch": 195.14,
      "learning_rate": 0.08049310632363345,
      "loss": 2.973,
      "step": 121380
    },
    {
      "epoch": 195.18,
      "learning_rate": 0.08048989089276529,
      "loss": 3.0142,
      "step": 121400
    },
    {
      "epoch": 195.21,
      "learning_rate": 0.08048667546189711,
      "loss": 2.9724,
      "step": 121420
    },
    {
      "epoch": 195.24,
      "learning_rate": 0.08048346003102894,
      "loss": 2.9809,
      "step": 121440
    },
    {
      "epoch": 195.27,
      "learning_rate": 0.08048024460016079,
      "loss": 2.9497,
      "step": 121460
    },
    {
      "epoch": 195.31,
      "learning_rate": 0.0804770291692926,
      "loss": 3.0003,
      "step": 121480
    },
    {
      "epoch": 195.34,
      "learning_rate": 0.08047381373842445,
      "loss": 2.9934,
      "step": 121500
    },
    {
      "epoch": 195.37,
      "learning_rate": 0.08047059830755628,
      "loss": 3.0253,
      "step": 121520
    },
    {
      "epoch": 195.4,
      "learning_rate": 0.0804673828766881,
      "loss": 3.0383,
      "step": 121540
    },
    {
      "epoch": 195.43,
      "learning_rate": 0.08046416744581994,
      "loss": 3.038,
      "step": 121560
    },
    {
      "epoch": 195.47,
      "learning_rate": 0.08046095201495176,
      "loss": 3.0023,
      "step": 121580
    },
    {
      "epoch": 195.5,
      "learning_rate": 0.08045773658408362,
      "loss": 2.9931,
      "step": 121600
    },
    {
      "epoch": 195.53,
      "learning_rate": 0.08045452115321544,
      "loss": 3.0185,
      "step": 121620
    },
    {
      "epoch": 195.56,
      "learning_rate": 0.08045130572234727,
      "loss": 2.9965,
      "step": 121640
    },
    {
      "epoch": 195.59,
      "learning_rate": 0.0804480902914791,
      "loss": 3.0059,
      "step": 121660
    },
    {
      "epoch": 195.63,
      "learning_rate": 0.08044487486061093,
      "loss": 3.0301,
      "step": 121680
    },
    {
      "epoch": 195.66,
      "learning_rate": 0.08044165942974278,
      "loss": 3.0174,
      "step": 121700
    },
    {
      "epoch": 195.69,
      "learning_rate": 0.08043860477041802,
      "loss": 3.0265,
      "step": 121720
    },
    {
      "epoch": 195.72,
      "learning_rate": 0.08043538933954984,
      "loss": 3.0161,
      "step": 121740
    },
    {
      "epoch": 195.76,
      "learning_rate": 0.08043217390868168,
      "loss": 3.0288,
      "step": 121760
    },
    {
      "epoch": 195.79,
      "learning_rate": 0.0804289584778135,
      "loss": 3.0608,
      "step": 121780
    },
    {
      "epoch": 195.82,
      "learning_rate": 0.08042574304694534,
      "loss": 3.0467,
      "step": 121800
    },
    {
      "epoch": 195.85,
      "learning_rate": 0.08042252761607717,
      "loss": 3.0431,
      "step": 121820
    },
    {
      "epoch": 195.88,
      "learning_rate": 0.08041931218520901,
      "loss": 3.0075,
      "step": 121840
    },
    {
      "epoch": 195.92,
      "learning_rate": 0.08041609675434085,
      "loss": 2.9798,
      "step": 121860
    },
    {
      "epoch": 195.95,
      "learning_rate": 0.08041288132347267,
      "loss": 2.9861,
      "step": 121880
    },
    {
      "epoch": 195.98,
      "learning_rate": 0.08040966589260451,
      "loss": 2.9814,
      "step": 121900
    },
    {
      "epoch": 196.0,
      "eval_accuracy": {
        "accuracy": 0.38194822358703256
      },
      "eval_loss": 3.0738589763641357,
      "eval_runtime": 2.9873,
      "eval_samples_per_second": 4305.849,
      "eval_steps_per_second": 67.284,
      "step": 121912
    },
    {
      "epoch": 196.01,
      "learning_rate": 0.08040645046173633,
      "loss": 3.0142,
      "step": 121920
    },
    {
      "epoch": 196.05,
      "learning_rate": 0.08040323503086817,
      "loss": 2.9866,
      "step": 121940
    },
    {
      "epoch": 196.08,
      "learning_rate": 0.08040001960000001,
      "loss": 3.0203,
      "step": 121960
    },
    {
      "epoch": 196.11,
      "learning_rate": 0.08039680416913184,
      "loss": 3.0147,
      "step": 121980
    },
    {
      "epoch": 196.14,
      "learning_rate": 0.08039358873826367,
      "loss": 2.9832,
      "step": 122000
    },
    {
      "epoch": 196.17,
      "learning_rate": 0.0803903733073955,
      "loss": 2.9681,
      "step": 122020
    },
    {
      "epoch": 196.21,
      "learning_rate": 0.08038715787652734,
      "loss": 2.9734,
      "step": 122040
    },
    {
      "epoch": 196.24,
      "learning_rate": 0.08038394244565918,
      "loss": 2.9841,
      "step": 122060
    },
    {
      "epoch": 196.27,
      "learning_rate": 0.080380727014791,
      "loss": 3.0187,
      "step": 122080
    },
    {
      "epoch": 196.3,
      "learning_rate": 0.08037751158392284,
      "loss": 3.012,
      "step": 122100
    },
    {
      "epoch": 196.33,
      "learning_rate": 0.08037429615305466,
      "loss": 3.0253,
      "step": 122120
    },
    {
      "epoch": 196.37,
      "learning_rate": 0.0803710807221865,
      "loss": 3.0084,
      "step": 122140
    },
    {
      "epoch": 196.4,
      "learning_rate": 0.08036786529131833,
      "loss": 2.9987,
      "step": 122160
    },
    {
      "epoch": 196.43,
      "learning_rate": 0.08036464986045017,
      "loss": 3.0177,
      "step": 122180
    },
    {
      "epoch": 196.46,
      "learning_rate": 0.080361434429582,
      "loss": 2.9741,
      "step": 122200
    },
    {
      "epoch": 196.5,
      "learning_rate": 0.08035821899871383,
      "loss": 2.9839,
      "step": 122220
    },
    {
      "epoch": 196.53,
      "learning_rate": 0.08035500356784567,
      "loss": 3.0198,
      "step": 122240
    },
    {
      "epoch": 196.56,
      "learning_rate": 0.08035178813697749,
      "loss": 3.0235,
      "step": 122260
    },
    {
      "epoch": 196.59,
      "learning_rate": 0.08034857270610933,
      "loss": 2.9698,
      "step": 122280
    },
    {
      "epoch": 196.62,
      "learning_rate": 0.08034535727524117,
      "loss": 3.004,
      "step": 122300
    },
    {
      "epoch": 196.66,
      "learning_rate": 0.080342141844373,
      "loss": 2.9716,
      "step": 122320
    },
    {
      "epoch": 196.69,
      "learning_rate": 0.08033892641350483,
      "loss": 3.0051,
      "step": 122340
    },
    {
      "epoch": 196.72,
      "learning_rate": 0.08033571098263666,
      "loss": 3.0108,
      "step": 122360
    },
    {
      "epoch": 196.75,
      "learning_rate": 0.0803324955517685,
      "loss": 2.9918,
      "step": 122380
    },
    {
      "epoch": 196.78,
      "learning_rate": 0.08032928012090033,
      "loss": 3.0124,
      "step": 122400
    },
    {
      "epoch": 196.82,
      "learning_rate": 0.08032606469003216,
      "loss": 3.0338,
      "step": 122420
    },
    {
      "epoch": 196.85,
      "learning_rate": 0.080322849259164,
      "loss": 3.0245,
      "step": 122440
    },
    {
      "epoch": 196.88,
      "learning_rate": 0.08031963382829582,
      "loss": 3.0149,
      "step": 122460
    },
    {
      "epoch": 196.91,
      "learning_rate": 0.08031641839742766,
      "loss": 3.0106,
      "step": 122480
    },
    {
      "epoch": 196.95,
      "learning_rate": 0.08031320296655949,
      "loss": 3.031,
      "step": 122500
    },
    {
      "epoch": 196.98,
      "learning_rate": 0.08030998753569132,
      "loss": 2.9884,
      "step": 122520
    },
    {
      "epoch": 197.0,
      "eval_accuracy": {
        "accuracy": 0.38622405348674493
      },
      "eval_loss": 3.038830518722534,
      "eval_runtime": 3.1304,
      "eval_samples_per_second": 4109.089,
      "eval_steps_per_second": 64.21,
      "step": 122534
    },
    {
      "epoch": 197.01,
      "learning_rate": 0.08030677210482316,
      "loss": 2.9552,
      "step": 122540
    },
    {
      "epoch": 197.04,
      "learning_rate": 0.08030355667395499,
      "loss": 2.9436,
      "step": 122560
    },
    {
      "epoch": 197.07,
      "learning_rate": 0.08030034124308683,
      "loss": 2.9886,
      "step": 122580
    },
    {
      "epoch": 197.11,
      "learning_rate": 0.08029712581221865,
      "loss": 2.9905,
      "step": 122600
    },
    {
      "epoch": 197.14,
      "learning_rate": 0.08029391038135049,
      "loss": 3.011,
      "step": 122620
    },
    {
      "epoch": 197.17,
      "learning_rate": 0.08029069495048233,
      "loss": 2.9566,
      "step": 122640
    },
    {
      "epoch": 197.2,
      "learning_rate": 0.08028747951961415,
      "loss": 2.9496,
      "step": 122660
    },
    {
      "epoch": 197.23,
      "learning_rate": 0.08028426408874599,
      "loss": 2.9929,
      "step": 122680
    },
    {
      "epoch": 197.27,
      "learning_rate": 0.08028104865787782,
      "loss": 2.9586,
      "step": 122700
    },
    {
      "epoch": 197.3,
      "learning_rate": 0.08027783322700965,
      "loss": 2.9535,
      "step": 122720
    },
    {
      "epoch": 197.33,
      "learning_rate": 0.08027461779614149,
      "loss": 2.9638,
      "step": 122740
    },
    {
      "epoch": 197.36,
      "learning_rate": 0.08027140236527332,
      "loss": 2.9658,
      "step": 122760
    },
    {
      "epoch": 197.4,
      "learning_rate": 0.08026818693440516,
      "loss": 3.0029,
      "step": 122780
    },
    {
      "epoch": 197.43,
      "learning_rate": 0.08026497150353698,
      "loss": 3.0195,
      "step": 122800
    },
    {
      "epoch": 197.46,
      "learning_rate": 0.08026175607266882,
      "loss": 3.0102,
      "step": 122820
    },
    {
      "epoch": 197.49,
      "learning_rate": 0.08025854064180064,
      "loss": 3.0016,
      "step": 122840
    },
    {
      "epoch": 197.52,
      "learning_rate": 0.08025532521093247,
      "loss": 2.9907,
      "step": 122860
    },
    {
      "epoch": 197.56,
      "learning_rate": 0.08025210978006432,
      "loss": 2.9668,
      "step": 122880
    },
    {
      "epoch": 197.59,
      "learning_rate": 0.08024889434919615,
      "loss": 3.0013,
      "step": 122900
    },
    {
      "epoch": 197.62,
      "learning_rate": 0.08024567891832798,
      "loss": 3.0037,
      "step": 122920
    },
    {
      "epoch": 197.65,
      "learning_rate": 0.08024246348745981,
      "loss": 3.0195,
      "step": 122940
    },
    {
      "epoch": 197.68,
      "learning_rate": 0.08023924805659163,
      "loss": 2.9666,
      "step": 122960
    },
    {
      "epoch": 197.72,
      "learning_rate": 0.08023603262572349,
      "loss": 2.9862,
      "step": 122980
    },
    {
      "epoch": 197.75,
      "learning_rate": 0.08023281719485531,
      "loss": 3.0029,
      "step": 123000
    },
    {
      "epoch": 197.78,
      "learning_rate": 0.08022960176398715,
      "loss": 3.0365,
      "step": 123020
    },
    {
      "epoch": 197.81,
      "learning_rate": 0.08022638633311897,
      "loss": 2.9834,
      "step": 123040
    },
    {
      "epoch": 197.85,
      "learning_rate": 0.08022317090225081,
      "loss": 2.9949,
      "step": 123060
    },
    {
      "epoch": 197.88,
      "learning_rate": 0.08021995547138265,
      "loss": 3.027,
      "step": 123080
    },
    {
      "epoch": 197.91,
      "learning_rate": 0.08021674004051448,
      "loss": 2.9879,
      "step": 123100
    },
    {
      "epoch": 197.94,
      "learning_rate": 0.08021352460964631,
      "loss": 2.9669,
      "step": 123120
    },
    {
      "epoch": 197.97,
      "learning_rate": 0.08021030917877814,
      "loss": 2.973,
      "step": 123140
    },
    {
      "epoch": 198.0,
      "eval_accuracy": {
        "accuracy": 0.3773614242400684
      },
      "eval_loss": 3.072064161300659,
      "eval_runtime": 2.6192,
      "eval_samples_per_second": 4911.018,
      "eval_steps_per_second": 76.741,
      "step": 123156
    },
    {
      "epoch": 198.01,
      "learning_rate": 0.08020709374790998,
      "loss": 2.977,
      "step": 123160
    },
    {
      "epoch": 198.04,
      "learning_rate": 0.0802038783170418,
      "loss": 2.9842,
      "step": 123180
    },
    {
      "epoch": 198.07,
      "learning_rate": 0.08020066288617363,
      "loss": 2.9763,
      "step": 123200
    },
    {
      "epoch": 198.1,
      "learning_rate": 0.08019744745530548,
      "loss": 3.0183,
      "step": 123220
    },
    {
      "epoch": 198.14,
      "learning_rate": 0.0801942320244373,
      "loss": 2.9817,
      "step": 123240
    },
    {
      "epoch": 198.17,
      "learning_rate": 0.08019101659356914,
      "loss": 2.9621,
      "step": 123260
    },
    {
      "epoch": 198.2,
      "learning_rate": 0.08018780116270097,
      "loss": 2.9903,
      "step": 123280
    },
    {
      "epoch": 198.23,
      "learning_rate": 0.08018458573183279,
      "loss": 3.0119,
      "step": 123300
    },
    {
      "epoch": 198.26,
      "learning_rate": 0.08018137030096464,
      "loss": 3.0283,
      "step": 123320
    },
    {
      "epoch": 198.3,
      "learning_rate": 0.08017815487009647,
      "loss": 3.0089,
      "step": 123340
    },
    {
      "epoch": 198.33,
      "learning_rate": 0.08017493943922831,
      "loss": 2.9787,
      "step": 123360
    },
    {
      "epoch": 198.36,
      "learning_rate": 0.08017172400836013,
      "loss": 2.9976,
      "step": 123380
    },
    {
      "epoch": 198.39,
      "learning_rate": 0.08016850857749196,
      "loss": 2.9976,
      "step": 123400
    },
    {
      "epoch": 198.42,
      "learning_rate": 0.08016529314662381,
      "loss": 3.0277,
      "step": 123420
    },
    {
      "epoch": 198.46,
      "learning_rate": 0.08016207771575563,
      "loss": 3.0602,
      "step": 123440
    },
    {
      "epoch": 198.49,
      "learning_rate": 0.08015886228488747,
      "loss": 3.0018,
      "step": 123460
    },
    {
      "epoch": 198.52,
      "learning_rate": 0.0801556468540193,
      "loss": 2.9877,
      "step": 123480
    },
    {
      "epoch": 198.55,
      "learning_rate": 0.08015243142315112,
      "loss": 3.0164,
      "step": 123500
    },
    {
      "epoch": 198.59,
      "learning_rate": 0.08014921599228297,
      "loss": 3.0135,
      "step": 123520
    },
    {
      "epoch": 198.62,
      "learning_rate": 0.08014600056141478,
      "loss": 2.9959,
      "step": 123540
    },
    {
      "epoch": 198.65,
      "learning_rate": 0.08014278513054664,
      "loss": 3.0497,
      "step": 123560
    },
    {
      "epoch": 198.68,
      "learning_rate": 0.08013956969967846,
      "loss": 2.9857,
      "step": 123580
    },
    {
      "epoch": 198.71,
      "learning_rate": 0.0801363542688103,
      "loss": 2.9806,
      "step": 123600
    },
    {
      "epoch": 198.75,
      "learning_rate": 0.08013313883794212,
      "loss": 3.0015,
      "step": 123620
    },
    {
      "epoch": 198.78,
      "learning_rate": 0.08012992340707395,
      "loss": 3.0081,
      "step": 123640
    },
    {
      "epoch": 198.81,
      "learning_rate": 0.0801267079762058,
      "loss": 3.035,
      "step": 123660
    },
    {
      "epoch": 198.84,
      "learning_rate": 0.08012349254533763,
      "loss": 3.0078,
      "step": 123680
    },
    {
      "epoch": 198.87,
      "learning_rate": 0.08012027711446947,
      "loss": 2.9926,
      "step": 123700
    },
    {
      "epoch": 198.91,
      "learning_rate": 0.08011706168360129,
      "loss": 2.9434,
      "step": 123720
    },
    {
      "epoch": 198.94,
      "learning_rate": 0.08011400702427653,
      "loss": 2.9746,
      "step": 123740
    },
    {
      "epoch": 198.97,
      "learning_rate": 0.08011079159340836,
      "loss": 3.021,
      "step": 123760
    },
    {
      "epoch": 199.0,
      "eval_accuracy": {
        "accuracy": 0.37145300474228404
      },
      "eval_loss": 3.0908565521240234,
      "eval_runtime": 3.4364,
      "eval_samples_per_second": 3743.165,
      "eval_steps_per_second": 58.491,
      "step": 123778
    },
    {
      "epoch": 199.0,
      "learning_rate": 0.0801075761625402,
      "loss": 3.0198,
      "step": 123780
    },
    {
      "epoch": 199.04,
      "learning_rate": 0.08010436073167203,
      "loss": 2.9905,
      "step": 123800
    },
    {
      "epoch": 199.07,
      "learning_rate": 0.08010114530080387,
      "loss": 3.0052,
      "step": 123820
    },
    {
      "epoch": 199.1,
      "learning_rate": 0.08009792986993569,
      "loss": 2.9693,
      "step": 123840
    },
    {
      "epoch": 199.13,
      "learning_rate": 0.08009471443906753,
      "loss": 3.0032,
      "step": 123860
    },
    {
      "epoch": 199.16,
      "learning_rate": 0.08009149900819935,
      "loss": 3.0144,
      "step": 123880
    },
    {
      "epoch": 199.2,
      "learning_rate": 0.08008828357733119,
      "loss": 2.9846,
      "step": 123900
    },
    {
      "epoch": 199.23,
      "learning_rate": 0.08008506814646303,
      "loss": 3.0176,
      "step": 123920
    },
    {
      "epoch": 199.26,
      "learning_rate": 0.08008185271559486,
      "loss": 3.0026,
      "step": 123940
    },
    {
      "epoch": 199.29,
      "learning_rate": 0.0800786372847267,
      "loss": 2.983,
      "step": 123960
    },
    {
      "epoch": 199.32,
      "learning_rate": 0.08007542185385852,
      "loss": 2.991,
      "step": 123980
    },
    {
      "epoch": 199.36,
      "learning_rate": 0.08007220642299036,
      "loss": 2.9418,
      "step": 124000
    },
    {
      "epoch": 199.39,
      "learning_rate": 0.0800689909921222,
      "loss": 2.9719,
      "step": 124020
    },
    {
      "epoch": 199.42,
      "learning_rate": 0.08006577556125402,
      "loss": 2.9909,
      "step": 124040
    },
    {
      "epoch": 199.45,
      "learning_rate": 0.08006256013038586,
      "loss": 2.9897,
      "step": 124060
    },
    {
      "epoch": 199.49,
      "learning_rate": 0.08005934469951768,
      "loss": 3.0399,
      "step": 124080
    },
    {
      "epoch": 199.52,
      "learning_rate": 0.08005612926864952,
      "loss": 2.9961,
      "step": 124100
    },
    {
      "epoch": 199.55,
      "learning_rate": 0.08005291383778136,
      "loss": 2.9667,
      "step": 124120
    },
    {
      "epoch": 199.58,
      "learning_rate": 0.08004969840691319,
      "loss": 2.9955,
      "step": 124140
    },
    {
      "epoch": 199.61,
      "learning_rate": 0.08004648297604502,
      "loss": 3.003,
      "step": 124160
    },
    {
      "epoch": 199.65,
      "learning_rate": 0.08004326754517685,
      "loss": 3.0031,
      "step": 124180
    },
    {
      "epoch": 199.68,
      "learning_rate": 0.08004005211430869,
      "loss": 2.9775,
      "step": 124200
    },
    {
      "epoch": 199.71,
      "learning_rate": 0.08003683668344051,
      "loss": 2.9605,
      "step": 124220
    },
    {
      "epoch": 199.74,
      "learning_rate": 0.08003362125257235,
      "loss": 2.9813,
      "step": 124240
    },
    {
      "epoch": 199.77,
      "learning_rate": 0.08003040582170419,
      "loss": 3.0141,
      "step": 124260
    },
    {
      "epoch": 199.81,
      "learning_rate": 0.08002719039083601,
      "loss": 3.0251,
      "step": 124280
    },
    {
      "epoch": 199.84,
      "learning_rate": 0.08002397495996785,
      "loss": 3.0163,
      "step": 124300
    },
    {
      "epoch": 199.87,
      "learning_rate": 0.08002075952909968,
      "loss": 3.0071,
      "step": 124320
    },
    {
      "epoch": 199.9,
      "learning_rate": 0.08001754409823152,
      "loss": 2.9855,
      "step": 124340
    },
    {
      "epoch": 199.94,
      "learning_rate": 0.08001432866736335,
      "loss": 2.9904,
      "step": 124360
    },
    {
      "epoch": 199.97,
      "learning_rate": 0.08001111323649518,
      "loss": 2.9958,
      "step": 124380
    },
    {
      "epoch": 200.0,
      "learning_rate": 0.08000789780562702,
      "loss": 3.0016,
      "step": 124400
    },
    {
      "epoch": 200.0,
      "eval_accuracy": {
        "accuracy": 0.3726968825312913
      },
      "eval_loss": 3.0949103832244873,
      "eval_runtime": 3.1046,
      "eval_samples_per_second": 4143.257,
      "eval_steps_per_second": 64.743,
      "step": 124400
    },
    {
      "epoch": 200.03,
      "learning_rate": 0.08000468237475884,
      "loss": 2.996,
      "step": 124420
    },
    {
      "epoch": 200.06,
      "learning_rate": 0.08000146694389068,
      "loss": 2.9411,
      "step": 124440
    },
    {
      "epoch": 200.1,
      "learning_rate": 0.07999825151302252,
      "loss": 2.9662,
      "step": 124460
    },
    {
      "epoch": 200.13,
      "learning_rate": 0.07999503608215434,
      "loss": 3.0149,
      "step": 124480
    },
    {
      "epoch": 200.16,
      "learning_rate": 0.07999182065128618,
      "loss": 3.0191,
      "step": 124500
    },
    {
      "epoch": 200.19,
      "learning_rate": 0.07998860522041801,
      "loss": 2.9979,
      "step": 124520
    },
    {
      "epoch": 200.23,
      "learning_rate": 0.07998538978954985,
      "loss": 3.0107,
      "step": 124540
    },
    {
      "epoch": 200.26,
      "learning_rate": 0.07998217435868167,
      "loss": 2.9848,
      "step": 124560
    },
    {
      "epoch": 200.29,
      "learning_rate": 0.07997895892781351,
      "loss": 2.9735,
      "step": 124580
    },
    {
      "epoch": 200.32,
      "learning_rate": 0.07997574349694535,
      "loss": 2.9987,
      "step": 124600
    },
    {
      "epoch": 200.35,
      "learning_rate": 0.07997252806607717,
      "loss": 3.0003,
      "step": 124620
    },
    {
      "epoch": 200.39,
      "learning_rate": 0.07996931263520901,
      "loss": 2.9767,
      "step": 124640
    },
    {
      "epoch": 200.42,
      "learning_rate": 0.07996609720434084,
      "loss": 2.9859,
      "step": 124660
    },
    {
      "epoch": 200.45,
      "learning_rate": 0.07996288177347267,
      "loss": 2.986,
      "step": 124680
    },
    {
      "epoch": 200.48,
      "learning_rate": 0.07995966634260451,
      "loss": 2.9973,
      "step": 124700
    },
    {
      "epoch": 200.51,
      "learning_rate": 0.07995645091173634,
      "loss": 2.9561,
      "step": 124720
    },
    {
      "epoch": 200.55,
      "learning_rate": 0.07995323548086818,
      "loss": 2.9913,
      "step": 124740
    },
    {
      "epoch": 200.58,
      "learning_rate": 0.07995002005,
      "loss": 2.9873,
      "step": 124760
    },
    {
      "epoch": 200.61,
      "learning_rate": 0.07994680461913184,
      "loss": 2.9636,
      "step": 124780
    },
    {
      "epoch": 200.64,
      "learning_rate": 0.07994358918826368,
      "loss": 2.9971,
      "step": 124800
    },
    {
      "epoch": 200.68,
      "learning_rate": 0.0799403737573955,
      "loss": 2.9969,
      "step": 124820
    },
    {
      "epoch": 200.71,
      "learning_rate": 0.07993715832652734,
      "loss": 2.9987,
      "step": 124840
    },
    {
      "epoch": 200.74,
      "learning_rate": 0.07993394289565917,
      "loss": 2.9959,
      "step": 124860
    },
    {
      "epoch": 200.77,
      "learning_rate": 0.079930727464791,
      "loss": 2.9999,
      "step": 124880
    },
    {
      "epoch": 200.8,
      "learning_rate": 0.07992751203392283,
      "loss": 2.9903,
      "step": 124900
    },
    {
      "epoch": 200.84,
      "learning_rate": 0.07992429660305467,
      "loss": 3.0244,
      "step": 124920
    },
    {
      "epoch": 200.87,
      "learning_rate": 0.0799210811721865,
      "loss": 3.0069,
      "step": 124940
    },
    {
      "epoch": 200.9,
      "learning_rate": 0.07991786574131833,
      "loss": 2.9786,
      "step": 124960
    },
    {
      "epoch": 200.93,
      "learning_rate": 0.07991465031045017,
      "loss": 3.013,
      "step": 124980
    },
    {
      "epoch": 200.96,
      "learning_rate": 0.079911434879582,
      "loss": 2.9844,
      "step": 125000
    },
    {
      "epoch": 201.0,
      "learning_rate": 0.07990821944871383,
      "loss": 2.9567,
      "step": 125020
    },
    {
      "epoch": 201.0,
      "eval_accuracy": {
        "accuracy": 0.38031563398896057
      },
      "eval_loss": 3.0705318450927734,
      "eval_runtime": 2.6275,
      "eval_samples_per_second": 4895.619,
      "eval_steps_per_second": 76.5,
      "step": 125022
    },
    {
      "epoch": 201.03,
      "learning_rate": 0.07990500401784567,
      "loss": 2.9694,
      "step": 125040
    },
    {
      "epoch": 201.06,
      "learning_rate": 0.0799017885869775,
      "loss": 2.9905,
      "step": 125060
    },
    {
      "epoch": 201.09,
      "learning_rate": 0.07989857315610933,
      "loss": 2.9641,
      "step": 125080
    },
    {
      "epoch": 201.13,
      "learning_rate": 0.07989535772524116,
      "loss": 2.9934,
      "step": 125100
    },
    {
      "epoch": 201.16,
      "learning_rate": 0.079892142294373,
      "loss": 2.976,
      "step": 125120
    },
    {
      "epoch": 201.19,
      "learning_rate": 0.07988892686350484,
      "loss": 3.0101,
      "step": 125140
    },
    {
      "epoch": 201.22,
      "learning_rate": 0.07988587220418007,
      "loss": 3.0106,
      "step": 125160
    },
    {
      "epoch": 201.25,
      "learning_rate": 0.0798826567733119,
      "loss": 2.9962,
      "step": 125180
    },
    {
      "epoch": 201.29,
      "learning_rate": 0.07987944134244374,
      "loss": 3.0031,
      "step": 125200
    },
    {
      "epoch": 201.32,
      "learning_rate": 0.07987622591157557,
      "loss": 3.0059,
      "step": 125220
    },
    {
      "epoch": 201.35,
      "learning_rate": 0.0798730104807074,
      "loss": 2.9717,
      "step": 125240
    },
    {
      "epoch": 201.38,
      "learning_rate": 0.07986979504983922,
      "loss": 2.9986,
      "step": 125260
    },
    {
      "epoch": 201.41,
      "learning_rate": 0.07986657961897106,
      "loss": 2.9898,
      "step": 125280
    },
    {
      "epoch": 201.45,
      "learning_rate": 0.0798633641881029,
      "loss": 2.9897,
      "step": 125300
    },
    {
      "epoch": 201.48,
      "learning_rate": 0.07986014875723474,
      "loss": 2.9726,
      "step": 125320
    },
    {
      "epoch": 201.51,
      "learning_rate": 0.07985693332636656,
      "loss": 2.9905,
      "step": 125340
    },
    {
      "epoch": 201.54,
      "learning_rate": 0.0798537178954984,
      "loss": 2.9738,
      "step": 125360
    },
    {
      "epoch": 201.58,
      "learning_rate": 0.07985050246463023,
      "loss": 2.9683,
      "step": 125380
    },
    {
      "epoch": 201.61,
      "learning_rate": 0.07984728703376207,
      "loss": 2.9761,
      "step": 125400
    },
    {
      "epoch": 201.64,
      "learning_rate": 0.0798440716028939,
      "loss": 2.9839,
      "step": 125420
    },
    {
      "epoch": 201.67,
      "learning_rate": 0.07984085617202573,
      "loss": 2.9733,
      "step": 125440
    },
    {
      "epoch": 201.7,
      "learning_rate": 0.07983764074115757,
      "loss": 3.0084,
      "step": 125460
    },
    {
      "epoch": 201.74,
      "learning_rate": 0.07983442531028939,
      "loss": 2.9985,
      "step": 125480
    },
    {
      "epoch": 201.77,
      "learning_rate": 0.07983120987942123,
      "loss": 2.9917,
      "step": 125500
    },
    {
      "epoch": 201.8,
      "learning_rate": 0.07982799444855306,
      "loss": 3.0006,
      "step": 125520
    },
    {
      "epoch": 201.83,
      "learning_rate": 0.0798247790176849,
      "loss": 3.0326,
      "step": 125540
    },
    {
      "epoch": 201.86,
      "learning_rate": 0.07982156358681673,
      "loss": 2.9785,
      "step": 125560
    },
    {
      "epoch": 201.9,
      "learning_rate": 0.07981834815594856,
      "loss": 2.9649,
      "step": 125580
    },
    {
      "epoch": 201.93,
      "learning_rate": 0.07981513272508038,
      "loss": 3.011,
      "step": 125600
    },
    {
      "epoch": 201.96,
      "learning_rate": 0.07981191729421222,
      "loss": 2.9941,
      "step": 125620
    },
    {
      "epoch": 201.99,
      "learning_rate": 0.07980870186334406,
      "loss": 3.0162,
      "step": 125640
    },
    {
      "epoch": 202.0,
      "eval_accuracy": {
        "accuracy": 0.37215268599860063
      },
      "eval_loss": 3.1050596237182617,
      "eval_runtime": 2.7614,
      "eval_samples_per_second": 4658.06,
      "eval_steps_per_second": 72.788,
      "step": 125644
    },
    {
      "epoch": 202.03,
      "learning_rate": 0.0798054864324759,
      "loss": 3.0343,
      "step": 125660
    },
    {
      "epoch": 202.06,
      "learning_rate": 0.07980227100160772,
      "loss": 2.988,
      "step": 125680
    },
    {
      "epoch": 202.09,
      "learning_rate": 0.07979905557073955,
      "loss": 2.941,
      "step": 125700
    },
    {
      "epoch": 202.12,
      "learning_rate": 0.07979584013987139,
      "loss": 2.9893,
      "step": 125720
    },
    {
      "epoch": 202.15,
      "learning_rate": 0.07979262470900322,
      "loss": 3.0249,
      "step": 125740
    },
    {
      "epoch": 202.19,
      "learning_rate": 0.07978940927813506,
      "loss": 3.0283,
      "step": 125760
    },
    {
      "epoch": 202.22,
      "learning_rate": 0.07978619384726689,
      "loss": 2.9397,
      "step": 125780
    },
    {
      "epoch": 202.25,
      "learning_rate": 0.07978297841639871,
      "loss": 2.9718,
      "step": 125800
    },
    {
      "epoch": 202.28,
      "learning_rate": 0.07977976298553055,
      "loss": 2.9999,
      "step": 125820
    },
    {
      "epoch": 202.32,
      "learning_rate": 0.07977654755466239,
      "loss": 3.0042,
      "step": 125840
    },
    {
      "epoch": 202.35,
      "learning_rate": 0.07977333212379421,
      "loss": 2.9947,
      "step": 125860
    },
    {
      "epoch": 202.38,
      "learning_rate": 0.07977011669292605,
      "loss": 2.9861,
      "step": 125880
    },
    {
      "epoch": 202.41,
      "learning_rate": 0.07976690126205788,
      "loss": 2.9425,
      "step": 125900
    },
    {
      "epoch": 202.44,
      "learning_rate": 0.07976368583118972,
      "loss": 2.9818,
      "step": 125920
    },
    {
      "epoch": 202.48,
      "learning_rate": 0.07976047040032154,
      "loss": 3.0141,
      "step": 125940
    },
    {
      "epoch": 202.51,
      "learning_rate": 0.07975725496945338,
      "loss": 3.0038,
      "step": 125960
    },
    {
      "epoch": 202.54,
      "learning_rate": 0.07975403953858522,
      "loss": 2.9808,
      "step": 125980
    },
    {
      "epoch": 202.57,
      "learning_rate": 0.07975082410771706,
      "loss": 2.9639,
      "step": 126000
    },
    {
      "epoch": 202.6,
      "learning_rate": 0.07974760867684888,
      "loss": 3.0142,
      "step": 126020
    },
    {
      "epoch": 202.64,
      "learning_rate": 0.0797443932459807,
      "loss": 2.9763,
      "step": 126040
    },
    {
      "epoch": 202.67,
      "learning_rate": 0.07974117781511254,
      "loss": 2.9859,
      "step": 126060
    },
    {
      "epoch": 202.7,
      "learning_rate": 0.07973796238424438,
      "loss": 2.9872,
      "step": 126080
    },
    {
      "epoch": 202.73,
      "learning_rate": 0.07973474695337622,
      "loss": 3.0068,
      "step": 126100
    },
    {
      "epoch": 202.77,
      "learning_rate": 0.07973153152250805,
      "loss": 2.9875,
      "step": 126120
    },
    {
      "epoch": 202.8,
      "learning_rate": 0.07972831609163987,
      "loss": 2.9789,
      "step": 126140
    },
    {
      "epoch": 202.83,
      "learning_rate": 0.07972510066077171,
      "loss": 2.986,
      "step": 126160
    },
    {
      "epoch": 202.86,
      "learning_rate": 0.07972188522990355,
      "loss": 3.0157,
      "step": 126180
    },
    {
      "epoch": 202.89,
      "learning_rate": 0.07971866979903537,
      "loss": 2.9897,
      "step": 126200
    },
    {
      "epoch": 202.93,
      "learning_rate": 0.07971545436816721,
      "loss": 2.9536,
      "step": 126220
    },
    {
      "epoch": 202.96,
      "learning_rate": 0.07971223893729903,
      "loss": 3.0283,
      "step": 126240
    },
    {
      "epoch": 202.99,
      "learning_rate": 0.07970902350643087,
      "loss": 3.0204,
      "step": 126260
    },
    {
      "epoch": 203.0,
      "eval_accuracy": {
        "accuracy": 0.3644561921791184
      },
      "eval_loss": 3.161801815032959,
      "eval_runtime": 2.9772,
      "eval_samples_per_second": 4320.552,
      "eval_steps_per_second": 67.514,
      "step": 126266
    },
    {
      "epoch": 203.02,
      "learning_rate": 0.0797058080755627,
      "loss": 3.0058,
      "step": 126280
    },
    {
      "epoch": 203.05,
      "learning_rate": 0.07970259264469454,
      "loss": 2.9863,
      "step": 126300
    },
    {
      "epoch": 203.09,
      "learning_rate": 0.07969937721382638,
      "loss": 3.0102,
      "step": 126320
    },
    {
      "epoch": 203.12,
      "learning_rate": 0.0796961617829582,
      "loss": 3.0091,
      "step": 126340
    },
    {
      "epoch": 203.15,
      "learning_rate": 0.07969294635209004,
      "loss": 2.9756,
      "step": 126360
    },
    {
      "epoch": 203.18,
      "learning_rate": 0.07968973092122186,
      "loss": 2.9786,
      "step": 126380
    },
    {
      "epoch": 203.22,
      "learning_rate": 0.0796865154903537,
      "loss": 2.9609,
      "step": 126400
    },
    {
      "epoch": 203.25,
      "learning_rate": 0.07968330005948554,
      "loss": 2.9286,
      "step": 126420
    },
    {
      "epoch": 203.28,
      "learning_rate": 0.07968008462861736,
      "loss": 2.94,
      "step": 126440
    },
    {
      "epoch": 203.31,
      "learning_rate": 0.0796768691977492,
      "loss": 2.9662,
      "step": 126460
    },
    {
      "epoch": 203.34,
      "learning_rate": 0.07967365376688103,
      "loss": 2.9891,
      "step": 126480
    },
    {
      "epoch": 203.38,
      "learning_rate": 0.07967043833601287,
      "loss": 2.9892,
      "step": 126500
    },
    {
      "epoch": 203.41,
      "learning_rate": 0.0796672229051447,
      "loss": 2.9733,
      "step": 126520
    },
    {
      "epoch": 203.44,
      "learning_rate": 0.07966400747427653,
      "loss": 2.9914,
      "step": 126540
    },
    {
      "epoch": 203.47,
      "learning_rate": 0.07966079204340837,
      "loss": 2.9683,
      "step": 126560
    },
    {
      "epoch": 203.5,
      "learning_rate": 0.07965757661254019,
      "loss": 2.9888,
      "step": 126580
    },
    {
      "epoch": 203.54,
      "learning_rate": 0.07965436118167203,
      "loss": 3.0127,
      "step": 126600
    },
    {
      "epoch": 203.57,
      "learning_rate": 0.07965114575080386,
      "loss": 2.971,
      "step": 126620
    },
    {
      "epoch": 203.6,
      "learning_rate": 0.0796479303199357,
      "loss": 2.9968,
      "step": 126640
    },
    {
      "epoch": 203.63,
      "learning_rate": 0.07964471488906753,
      "loss": 2.967,
      "step": 126660
    },
    {
      "epoch": 203.67,
      "learning_rate": 0.07964149945819936,
      "loss": 2.9994,
      "step": 126680
    },
    {
      "epoch": 203.7,
      "learning_rate": 0.0796382840273312,
      "loss": 3.0166,
      "step": 126700
    },
    {
      "epoch": 203.73,
      "learning_rate": 0.07963506859646302,
      "loss": 3.0127,
      "step": 126720
    },
    {
      "epoch": 203.76,
      "learning_rate": 0.07963185316559486,
      "loss": 2.965,
      "step": 126740
    },
    {
      "epoch": 203.79,
      "learning_rate": 0.0796286377347267,
      "loss": 2.9841,
      "step": 126760
    },
    {
      "epoch": 203.83,
      "learning_rate": 0.07962542230385852,
      "loss": 2.9718,
      "step": 126780
    },
    {
      "epoch": 203.86,
      "learning_rate": 0.07962220687299036,
      "loss": 3.0063,
      "step": 126800
    },
    {
      "epoch": 203.89,
      "learning_rate": 0.07961899144212219,
      "loss": 2.9617,
      "step": 126820
    },
    {
      "epoch": 203.92,
      "learning_rate": 0.07961577601125402,
      "loss": 2.9589,
      "step": 126840
    },
    {
      "epoch": 203.95,
      "learning_rate": 0.07961256058038586,
      "loss": 2.9623,
      "step": 126860
    },
    {
      "epoch": 203.99,
      "learning_rate": 0.07960934514951769,
      "loss": 3.0052,
      "step": 126880
    },
    {
      "epoch": 204.0,
      "eval_accuracy": {
        "accuracy": 0.3712197776568452
      },
      "eval_loss": 3.1123905181884766,
      "eval_runtime": 2.6576,
      "eval_samples_per_second": 4840.0,
      "eval_steps_per_second": 75.631,
      "step": 126888
    },
    {
      "epoch": 204.02,
      "learning_rate": 0.07960612971864953,
      "loss": 3.0247,
      "step": 126900
    },
    {
      "epoch": 204.05,
      "learning_rate": 0.07960291428778135,
      "loss": 2.9976,
      "step": 126920
    },
    {
      "epoch": 204.08,
      "learning_rate": 0.07959969885691319,
      "loss": 2.9764,
      "step": 126940
    },
    {
      "epoch": 204.12,
      "learning_rate": 0.07959648342604501,
      "loss": 2.975,
      "step": 126960
    },
    {
      "epoch": 204.15,
      "learning_rate": 0.07959326799517685,
      "loss": 3.0147,
      "step": 126980
    },
    {
      "epoch": 204.18,
      "learning_rate": 0.07959005256430869,
      "loss": 3.0048,
      "step": 127000
    },
    {
      "epoch": 204.21,
      "learning_rate": 0.07958683713344052,
      "loss": 3.0473,
      "step": 127020
    },
    {
      "epoch": 204.24,
      "learning_rate": 0.07958362170257235,
      "loss": 2.9733,
      "step": 127040
    },
    {
      "epoch": 204.28,
      "learning_rate": 0.07958040627170418,
      "loss": 2.946,
      "step": 127060
    },
    {
      "epoch": 204.31,
      "learning_rate": 0.07957719084083602,
      "loss": 2.9547,
      "step": 127080
    },
    {
      "epoch": 204.34,
      "learning_rate": 0.07957397540996786,
      "loss": 3.0236,
      "step": 127100
    },
    {
      "epoch": 204.37,
      "learning_rate": 0.07957075997909968,
      "loss": 3.0342,
      "step": 127120
    },
    {
      "epoch": 204.41,
      "learning_rate": 0.07956754454823152,
      "loss": 3.0071,
      "step": 127140
    },
    {
      "epoch": 204.44,
      "learning_rate": 0.07956432911736334,
      "loss": 3.0202,
      "step": 127160
    },
    {
      "epoch": 204.47,
      "learning_rate": 0.07956111368649518,
      "loss": 3.0012,
      "step": 127180
    },
    {
      "epoch": 204.5,
      "learning_rate": 0.07955789825562702,
      "loss": 2.9871,
      "step": 127200
    },
    {
      "epoch": 204.53,
      "learning_rate": 0.07955468282475885,
      "loss": 2.9628,
      "step": 127220
    },
    {
      "epoch": 204.57,
      "learning_rate": 0.07955146739389068,
      "loss": 2.9984,
      "step": 127240
    },
    {
      "epoch": 204.6,
      "learning_rate": 0.07954825196302251,
      "loss": 2.9971,
      "step": 127260
    },
    {
      "epoch": 204.63,
      "learning_rate": 0.07954503653215435,
      "loss": 2.9675,
      "step": 127280
    },
    {
      "epoch": 204.66,
      "learning_rate": 0.07954182110128617,
      "loss": 3.0135,
      "step": 127300
    },
    {
      "epoch": 204.69,
      "learning_rate": 0.07953860567041801,
      "loss": 2.9972,
      "step": 127320
    },
    {
      "epoch": 204.73,
      "learning_rate": 0.07953539023954985,
      "loss": 2.949,
      "step": 127340
    },
    {
      "epoch": 204.76,
      "learning_rate": 0.07953217480868167,
      "loss": 2.9951,
      "step": 127360
    },
    {
      "epoch": 204.79,
      "learning_rate": 0.07952895937781351,
      "loss": 3.0027,
      "step": 127380
    },
    {
      "epoch": 204.82,
      "learning_rate": 0.07952574394694534,
      "loss": 3.011,
      "step": 127400
    },
    {
      "epoch": 204.86,
      "learning_rate": 0.07952252851607718,
      "loss": 3.003,
      "step": 127420
    },
    {
      "epoch": 204.89,
      "learning_rate": 0.07951931308520901,
      "loss": 2.9431,
      "step": 127440
    },
    {
      "epoch": 204.92,
      "learning_rate": 0.07951609765434084,
      "loss": 3.0073,
      "step": 127460
    },
    {
      "epoch": 204.95,
      "learning_rate": 0.07951288222347268,
      "loss": 2.9971,
      "step": 127480
    },
    {
      "epoch": 204.98,
      "learning_rate": 0.0795096667926045,
      "loss": 2.9762,
      "step": 127500
    },
    {
      "epoch": 205.0,
      "eval_accuracy": {
        "accuracy": 0.38264790484334915
      },
      "eval_loss": 3.0053751468658447,
      "eval_runtime": 3.1047,
      "eval_samples_per_second": 4143.019,
      "eval_steps_per_second": 64.74,
      "step": 127510
    },
    {
      "epoch": 205.02,
      "learning_rate": 0.07950645136173634,
      "loss": 2.9361,
      "step": 127520
    },
    {
      "epoch": 205.05,
      "learning_rate": 0.07950323593086818,
      "loss": 2.989,
      "step": 127540
    },
    {
      "epoch": 205.08,
      "learning_rate": 0.0795000205,
      "loss": 2.9624,
      "step": 127560
    },
    {
      "epoch": 205.11,
      "learning_rate": 0.07949680506913184,
      "loss": 3.0138,
      "step": 127580
    },
    {
      "epoch": 205.14,
      "learning_rate": 0.07949358963826367,
      "loss": 2.9614,
      "step": 127600
    },
    {
      "epoch": 205.18,
      "learning_rate": 0.0794903742073955,
      "loss": 2.9186,
      "step": 127620
    },
    {
      "epoch": 205.21,
      "learning_rate": 0.07948715877652733,
      "loss": 2.9538,
      "step": 127640
    },
    {
      "epoch": 205.24,
      "learning_rate": 0.07948394334565917,
      "loss": 2.9879,
      "step": 127660
    },
    {
      "epoch": 205.27,
      "learning_rate": 0.07948072791479101,
      "loss": 3.0078,
      "step": 127680
    },
    {
      "epoch": 205.31,
      "learning_rate": 0.07947751248392283,
      "loss": 2.974,
      "step": 127700
    },
    {
      "epoch": 205.34,
      "learning_rate": 0.07947429705305467,
      "loss": 2.9987,
      "step": 127720
    },
    {
      "epoch": 205.37,
      "learning_rate": 0.0794710816221865,
      "loss": 2.9709,
      "step": 127740
    },
    {
      "epoch": 205.4,
      "learning_rate": 0.07946786619131833,
      "loss": 2.9434,
      "step": 127760
    },
    {
      "epoch": 205.43,
      "learning_rate": 0.07946465076045017,
      "loss": 2.9791,
      "step": 127780
    },
    {
      "epoch": 205.47,
      "learning_rate": 0.079461435329582,
      "loss": 2.9611,
      "step": 127800
    },
    {
      "epoch": 205.5,
      "learning_rate": 0.07945821989871384,
      "loss": 2.9729,
      "step": 127820
    },
    {
      "epoch": 205.53,
      "learning_rate": 0.07945500446784566,
      "loss": 2.9516,
      "step": 127840
    },
    {
      "epoch": 205.56,
      "learning_rate": 0.0794517890369775,
      "loss": 2.9766,
      "step": 127860
    },
    {
      "epoch": 205.59,
      "learning_rate": 0.07944857360610934,
      "loss": 2.9545,
      "step": 127880
    },
    {
      "epoch": 205.63,
      "learning_rate": 0.07944535817524116,
      "loss": 3.0024,
      "step": 127900
    },
    {
      "epoch": 205.66,
      "learning_rate": 0.079442142744373,
      "loss": 2.9815,
      "step": 127920
    },
    {
      "epoch": 205.69,
      "learning_rate": 0.07943892731350483,
      "loss": 3.0387,
      "step": 127940
    },
    {
      "epoch": 205.72,
      "learning_rate": 0.07943571188263666,
      "loss": 3.01,
      "step": 127960
    },
    {
      "epoch": 205.76,
      "learning_rate": 0.07943249645176849,
      "loss": 3.0028,
      "step": 127980
    },
    {
      "epoch": 205.79,
      "learning_rate": 0.07942928102090033,
      "loss": 2.9538,
      "step": 128000
    },
    {
      "epoch": 205.82,
      "learning_rate": 0.07942606559003217,
      "loss": 2.9914,
      "step": 128020
    },
    {
      "epoch": 205.85,
      "learning_rate": 0.07942285015916399,
      "loss": 2.966,
      "step": 128040
    },
    {
      "epoch": 205.88,
      "learning_rate": 0.07941963472829583,
      "loss": 2.9947,
      "step": 128060
    },
    {
      "epoch": 205.92,
      "learning_rate": 0.07941641929742765,
      "loss": 2.985,
      "step": 128080
    },
    {
      "epoch": 205.95,
      "learning_rate": 0.07941320386655949,
      "loss": 2.9889,
      "step": 128100
    },
    {
      "epoch": 205.98,
      "learning_rate": 0.07940998843569133,
      "loss": 2.9976,
      "step": 128120
    },
    {
      "epoch": 206.0,
      "eval_accuracy": {
        "accuracy": 0.3743294721293633
      },
      "eval_loss": 3.0584158897399902,
      "eval_runtime": 3.1229,
      "eval_samples_per_second": 4118.879,
      "eval_steps_per_second": 64.362,
      "step": 128132
    },
    {
      "epoch": 206.01,
      "learning_rate": 0.07940677300482316,
      "loss": 3.0154,
      "step": 128140
    },
    {
      "epoch": 206.05,
      "learning_rate": 0.079403557573955,
      "loss": 2.9965,
      "step": 128160
    },
    {
      "epoch": 206.08,
      "learning_rate": 0.07940034214308682,
      "loss": 3.0146,
      "step": 128180
    },
    {
      "epoch": 206.11,
      "learning_rate": 0.07939712671221866,
      "loss": 2.9647,
      "step": 128200
    },
    {
      "epoch": 206.14,
      "learning_rate": 0.0793939112813505,
      "loss": 2.9712,
      "step": 128220
    },
    {
      "epoch": 206.17,
      "learning_rate": 0.07939069585048232,
      "loss": 2.9713,
      "step": 128240
    },
    {
      "epoch": 206.21,
      "learning_rate": 0.07938748041961416,
      "loss": 2.9632,
      "step": 128260
    },
    {
      "epoch": 206.24,
      "learning_rate": 0.07938426498874598,
      "loss": 2.9701,
      "step": 128280
    },
    {
      "epoch": 206.27,
      "learning_rate": 0.07938104955787782,
      "loss": 2.9744,
      "step": 128300
    },
    {
      "epoch": 206.3,
      "learning_rate": 0.07937783412700965,
      "loss": 2.9752,
      "step": 128320
    },
    {
      "epoch": 206.33,
      "learning_rate": 0.07937461869614147,
      "loss": 2.9885,
      "step": 128340
    },
    {
      "epoch": 206.37,
      "learning_rate": 0.07937140326527332,
      "loss": 2.9848,
      "step": 128360
    },
    {
      "epoch": 206.4,
      "learning_rate": 0.07936818783440515,
      "loss": 3.0128,
      "step": 128380
    },
    {
      "epoch": 206.43,
      "learning_rate": 0.07936497240353699,
      "loss": 3.0065,
      "step": 128400
    },
    {
      "epoch": 206.46,
      "learning_rate": 0.07936175697266881,
      "loss": 2.9961,
      "step": 128420
    },
    {
      "epoch": 206.5,
      "learning_rate": 0.07935854154180064,
      "loss": 2.9911,
      "step": 128440
    },
    {
      "epoch": 206.53,
      "learning_rate": 0.07935532611093249,
      "loss": 2.9732,
      "step": 128460
    },
    {
      "epoch": 206.56,
      "learning_rate": 0.07935211068006431,
      "loss": 2.9998,
      "step": 128480
    },
    {
      "epoch": 206.59,
      "learning_rate": 0.07934889524919615,
      "loss": 2.9916,
      "step": 128500
    },
    {
      "epoch": 206.62,
      "learning_rate": 0.07934567981832798,
      "loss": 2.9855,
      "step": 128520
    },
    {
      "epoch": 206.66,
      "learning_rate": 0.0793424643874598,
      "loss": 2.9836,
      "step": 128540
    },
    {
      "epoch": 206.69,
      "learning_rate": 0.07933924895659165,
      "loss": 2.9847,
      "step": 128560
    },
    {
      "epoch": 206.72,
      "learning_rate": 0.07933603352572348,
      "loss": 2.9891,
      "step": 128580
    },
    {
      "epoch": 206.75,
      "learning_rate": 0.07933281809485532,
      "loss": 2.9977,
      "step": 128600
    },
    {
      "epoch": 206.78,
      "learning_rate": 0.07932992420707395,
      "loss": 3.0263,
      "step": 128620
    },
    {
      "epoch": 206.82,
      "learning_rate": 0.07932670877620579,
      "loss": 3.0582,
      "step": 128640
    },
    {
      "epoch": 206.85,
      "learning_rate": 0.07932349334533763,
      "loss": 3.0466,
      "step": 128660
    },
    {
      "epoch": 206.88,
      "learning_rate": 0.07932027791446945,
      "loss": 3.0202,
      "step": 128680
    },
    {
      "epoch": 206.91,
      "learning_rate": 0.07931706248360129,
      "loss": 2.961,
      "step": 128700
    },
    {
      "epoch": 206.95,
      "learning_rate": 0.07931384705273312,
      "loss": 2.995,
      "step": 128720
    },
    {
      "epoch": 206.98,
      "learning_rate": 0.07931063162186495,
      "loss": 3.0025,
      "step": 128740
    },
    {
      "epoch": 207.0,
      "eval_accuracy": {
        "accuracy": 0.37984917981808286
      },
      "eval_loss": 3.0332329273223877,
      "eval_runtime": 2.852,
      "eval_samples_per_second": 4510.109,
      "eval_steps_per_second": 70.476,
      "step": 128754
    },
    {
      "epoch": 207.01,
      "learning_rate": 0.0793074161909968,
      "loss": 2.9881,
      "step": 128760
    },
    {
      "epoch": 207.04,
      "learning_rate": 0.07930420076012862,
      "loss": 3.0069,
      "step": 128780
    },
    {
      "epoch": 207.07,
      "learning_rate": 0.07930098532926046,
      "loss": 2.974,
      "step": 128800
    },
    {
      "epoch": 207.11,
      "learning_rate": 0.07929776989839228,
      "loss": 2.9751,
      "step": 128820
    },
    {
      "epoch": 207.14,
      "learning_rate": 0.07929455446752412,
      "loss": 2.9816,
      "step": 128840
    },
    {
      "epoch": 207.17,
      "learning_rate": 0.07929133903665596,
      "loss": 2.9873,
      "step": 128860
    },
    {
      "epoch": 207.2,
      "learning_rate": 0.07928812360578778,
      "loss": 2.9631,
      "step": 128880
    },
    {
      "epoch": 207.23,
      "learning_rate": 0.07928490817491962,
      "loss": 2.9581,
      "step": 128900
    },
    {
      "epoch": 207.27,
      "learning_rate": 0.07928169274405145,
      "loss": 3.0107,
      "step": 128920
    },
    {
      "epoch": 207.3,
      "learning_rate": 0.07927847731318328,
      "loss": 2.9791,
      "step": 128940
    },
    {
      "epoch": 207.33,
      "learning_rate": 0.07927526188231511,
      "loss": 2.961,
      "step": 128960
    },
    {
      "epoch": 207.36,
      "learning_rate": 0.07927204645144695,
      "loss": 2.9574,
      "step": 128980
    },
    {
      "epoch": 207.4,
      "learning_rate": 0.07926883102057879,
      "loss": 2.9629,
      "step": 129000
    },
    {
      "epoch": 207.43,
      "learning_rate": 0.07926561558971061,
      "loss": 2.9955,
      "step": 129020
    },
    {
      "epoch": 207.46,
      "learning_rate": 0.07926240015884245,
      "loss": 2.9525,
      "step": 129040
    },
    {
      "epoch": 207.49,
      "learning_rate": 0.07925918472797427,
      "loss": 2.9653,
      "step": 129060
    },
    {
      "epoch": 207.52,
      "learning_rate": 0.07925596929710611,
      "loss": 2.9977,
      "step": 129080
    },
    {
      "epoch": 207.56,
      "learning_rate": 0.07925275386623795,
      "loss": 2.9687,
      "step": 129100
    },
    {
      "epoch": 207.59,
      "learning_rate": 0.07924953843536978,
      "loss": 2.988,
      "step": 129120
    },
    {
      "epoch": 207.62,
      "learning_rate": 0.07924632300450161,
      "loss": 2.9664,
      "step": 129140
    },
    {
      "epoch": 207.65,
      "learning_rate": 0.07924310757363344,
      "loss": 2.9579,
      "step": 129160
    },
    {
      "epoch": 207.68,
      "learning_rate": 0.07923989214276528,
      "loss": 2.9835,
      "step": 129180
    },
    {
      "epoch": 207.72,
      "learning_rate": 0.07923667671189712,
      "loss": 2.9665,
      "step": 129200
    },
    {
      "epoch": 207.75,
      "learning_rate": 0.07923346128102894,
      "loss": 2.971,
      "step": 129220
    },
    {
      "epoch": 207.78,
      "learning_rate": 0.07923024585016078,
      "loss": 2.9544,
      "step": 129240
    },
    {
      "epoch": 207.81,
      "learning_rate": 0.0792270304192926,
      "loss": 2.9506,
      "step": 129260
    },
    {
      "epoch": 207.85,
      "learning_rate": 0.07922381498842444,
      "loss": 2.987,
      "step": 129280
    },
    {
      "epoch": 207.88,
      "learning_rate": 0.07922059955755627,
      "loss": 2.9889,
      "step": 129300
    },
    {
      "epoch": 207.91,
      "learning_rate": 0.0792173841266881,
      "loss": 2.9744,
      "step": 129320
    },
    {
      "epoch": 207.94,
      "learning_rate": 0.07921416869581994,
      "loss": 2.9579,
      "step": 129340
    },
    {
      "epoch": 207.97,
      "learning_rate": 0.07921095326495177,
      "loss": 2.9769,
      "step": 129360
    },
    {
      "epoch": 208.0,
      "eval_accuracy": {
        "accuracy": 0.376428515898313
      },
      "eval_loss": 3.0522193908691406,
      "eval_runtime": 2.7171,
      "eval_samples_per_second": 4734.009,
      "eval_steps_per_second": 73.975,
      "step": 129376
    },
    {
      "epoch": 208.01,
      "learning_rate": 0.07920773783408361,
      "loss": 2.9967,
      "step": 129380
    },
    {
      "epoch": 208.04,
      "learning_rate": 0.07920452240321543,
      "loss": 2.9618,
      "step": 129400
    },
    {
      "epoch": 208.07,
      "learning_rate": 0.07920130697234727,
      "loss": 2.9981,
      "step": 129420
    },
    {
      "epoch": 208.1,
      "learning_rate": 0.07919809154147911,
      "loss": 2.9713,
      "step": 129440
    },
    {
      "epoch": 208.14,
      "learning_rate": 0.07919487611061093,
      "loss": 2.9977,
      "step": 129460
    },
    {
      "epoch": 208.17,
      "learning_rate": 0.07919166067974277,
      "loss": 2.9732,
      "step": 129480
    },
    {
      "epoch": 208.2,
      "learning_rate": 0.0791884452488746,
      "loss": 2.9991,
      "step": 129500
    },
    {
      "epoch": 208.23,
      "learning_rate": 0.07918522981800644,
      "loss": 2.9932,
      "step": 129520
    },
    {
      "epoch": 208.26,
      "learning_rate": 0.07918201438713827,
      "loss": 2.975,
      "step": 129540
    },
    {
      "epoch": 208.3,
      "learning_rate": 0.0791787989562701,
      "loss": 2.997,
      "step": 129560
    },
    {
      "epoch": 208.33,
      "learning_rate": 0.07917558352540194,
      "loss": 2.9975,
      "step": 129580
    },
    {
      "epoch": 208.36,
      "learning_rate": 0.07917236809453376,
      "loss": 2.9874,
      "step": 129600
    },
    {
      "epoch": 208.39,
      "learning_rate": 0.0791691526636656,
      "loss": 2.9887,
      "step": 129620
    },
    {
      "epoch": 208.42,
      "learning_rate": 0.07916593723279743,
      "loss": 2.9803,
      "step": 129640
    },
    {
      "epoch": 208.46,
      "learning_rate": 0.07916272180192926,
      "loss": 2.9847,
      "step": 129660
    },
    {
      "epoch": 208.49,
      "learning_rate": 0.0791595063710611,
      "loss": 3.0007,
      "step": 129680
    },
    {
      "epoch": 208.52,
      "learning_rate": 0.07915629094019293,
      "loss": 3.0194,
      "step": 129700
    },
    {
      "epoch": 208.55,
      "learning_rate": 0.07915307550932477,
      "loss": 2.9798,
      "step": 129720
    },
    {
      "epoch": 208.59,
      "learning_rate": 0.07914986007845659,
      "loss": 2.9613,
      "step": 129740
    },
    {
      "epoch": 208.62,
      "learning_rate": 0.07914664464758843,
      "loss": 2.9982,
      "step": 129760
    },
    {
      "epoch": 208.65,
      "learning_rate": 0.07914342921672027,
      "loss": 3.0186,
      "step": 129780
    },
    {
      "epoch": 208.68,
      "learning_rate": 0.07914021378585209,
      "loss": 2.9944,
      "step": 129800
    },
    {
      "epoch": 208.71,
      "learning_rate": 0.07913699835498393,
      "loss": 2.9962,
      "step": 129820
    },
    {
      "epoch": 208.75,
      "learning_rate": 0.07913378292411576,
      "loss": 2.9891,
      "step": 129840
    },
    {
      "epoch": 208.78,
      "learning_rate": 0.0791305674932476,
      "loss": 2.9859,
      "step": 129860
    },
    {
      "epoch": 208.81,
      "learning_rate": 0.07912735206237943,
      "loss": 2.9783,
      "step": 129880
    },
    {
      "epoch": 208.84,
      "learning_rate": 0.07912413663151126,
      "loss": 2.9816,
      "step": 129900
    },
    {
      "epoch": 208.87,
      "learning_rate": 0.0791209212006431,
      "loss": 2.9784,
      "step": 129920
    },
    {
      "epoch": 208.91,
      "learning_rate": 0.07911770576977492,
      "loss": 2.9743,
      "step": 129940
    },
    {
      "epoch": 208.94,
      "learning_rate": 0.07911449033890676,
      "loss": 2.9926,
      "step": 129960
    },
    {
      "epoch": 208.97,
      "learning_rate": 0.07911127490803858,
      "loss": 3.0024,
      "step": 129980
    },
    {
      "epoch": 209.0,
      "eval_accuracy": {
        "accuracy": 0.378061105496385
      },
      "eval_loss": 3.091259002685547,
      "eval_runtime": 2.8361,
      "eval_samples_per_second": 4535.415,
      "eval_steps_per_second": 70.871,
      "step": 129998
    },
    {
      "epoch": 209.0,
      "learning_rate": 0.07910805947717042,
      "loss": 3.0137,
      "step": 130000
    },
    {
      "epoch": 209.04,
      "learning_rate": 0.07910484404630226,
      "loss": 2.9862,
      "step": 130020
    },
    {
      "epoch": 209.07,
      "learning_rate": 0.07910162861543409,
      "loss": 2.9676,
      "step": 130040
    },
    {
      "epoch": 209.1,
      "learning_rate": 0.07909841318456592,
      "loss": 2.9317,
      "step": 130060
    },
    {
      "epoch": 209.13,
      "learning_rate": 0.07909519775369775,
      "loss": 2.9699,
      "step": 130080
    },
    {
      "epoch": 209.16,
      "learning_rate": 0.07909198232282959,
      "loss": 3.0038,
      "step": 130100
    },
    {
      "epoch": 209.2,
      "learning_rate": 0.07908876689196143,
      "loss": 2.9764,
      "step": 130120
    },
    {
      "epoch": 209.23,
      "learning_rate": 0.07908555146109325,
      "loss": 2.9787,
      "step": 130140
    },
    {
      "epoch": 209.26,
      "learning_rate": 0.07908233603022509,
      "loss": 2.9841,
      "step": 130160
    },
    {
      "epoch": 209.29,
      "learning_rate": 0.07907912059935691,
      "loss": 2.9833,
      "step": 130180
    },
    {
      "epoch": 209.32,
      "learning_rate": 0.07907590516848875,
      "loss": 2.9894,
      "step": 130200
    },
    {
      "epoch": 209.36,
      "learning_rate": 0.07907268973762059,
      "loss": 3.0002,
      "step": 130220
    },
    {
      "epoch": 209.39,
      "learning_rate": 0.07906947430675242,
      "loss": 2.9767,
      "step": 130240
    },
    {
      "epoch": 209.42,
      "learning_rate": 0.07906625887588425,
      "loss": 2.975,
      "step": 130260
    },
    {
      "epoch": 209.45,
      "learning_rate": 0.07906304344501608,
      "loss": 2.9747,
      "step": 130280
    },
    {
      "epoch": 209.49,
      "learning_rate": 0.07905982801414792,
      "loss": 2.9587,
      "step": 130300
    },
    {
      "epoch": 209.52,
      "learning_rate": 0.07905661258327974,
      "loss": 2.9467,
      "step": 130320
    },
    {
      "epoch": 209.55,
      "learning_rate": 0.07905339715241158,
      "loss": 2.9829,
      "step": 130340
    },
    {
      "epoch": 209.58,
      "learning_rate": 0.07905018172154342,
      "loss": 3.0079,
      "step": 130360
    },
    {
      "epoch": 209.61,
      "learning_rate": 0.07904696629067524,
      "loss": 2.9646,
      "step": 130380
    },
    {
      "epoch": 209.65,
      "learning_rate": 0.07904375085980708,
      "loss": 2.986,
      "step": 130400
    },
    {
      "epoch": 209.68,
      "learning_rate": 0.07904053542893891,
      "loss": 2.9546,
      "step": 130420
    },
    {
      "epoch": 209.71,
      "learning_rate": 0.07903731999807075,
      "loss": 2.9704,
      "step": 130440
    },
    {
      "epoch": 209.74,
      "learning_rate": 0.07903410456720258,
      "loss": 2.9729,
      "step": 130460
    },
    {
      "epoch": 209.77,
      "learning_rate": 0.07903088913633441,
      "loss": 2.9644,
      "step": 130480
    },
    {
      "epoch": 209.81,
      "learning_rate": 0.07902767370546625,
      "loss": 2.9668,
      "step": 130500
    },
    {
      "epoch": 209.84,
      "learning_rate": 0.07902445827459807,
      "loss": 2.9636,
      "step": 130520
    },
    {
      "epoch": 209.87,
      "learning_rate": 0.07902124284372991,
      "loss": 2.9725,
      "step": 130540
    },
    {
      "epoch": 209.9,
      "learning_rate": 0.07901802741286175,
      "loss": 2.9884,
      "step": 130560
    },
    {
      "epoch": 209.94,
      "learning_rate": 0.07901481198199357,
      "loss": 2.9512,
      "step": 130580
    },
    {
      "epoch": 209.97,
      "learning_rate": 0.07901159655112541,
      "loss": 2.9772,
      "step": 130600
    },
    {
      "epoch": 210.0,
      "learning_rate": 0.07900838112025724,
      "loss": 2.9347,
      "step": 130620
    },
    {
      "epoch": 210.0,
      "eval_accuracy": {
        "accuracy": 0.3743294721293633
      },
      "eval_loss": 3.070897340774536,
      "eval_runtime": 2.7962,
      "eval_samples_per_second": 4600.11,
      "eval_steps_per_second": 71.882,
      "step": 130620
    },
    {
      "epoch": 210.03,
      "learning_rate": 0.07900516568938908,
      "loss": 2.9852,
      "step": 130640
    },
    {
      "epoch": 210.06,
      "learning_rate": 0.0790019502585209,
      "loss": 2.9548,
      "step": 130660
    },
    {
      "epoch": 210.1,
      "learning_rate": 0.07899873482765274,
      "loss": 2.9473,
      "step": 130680
    },
    {
      "epoch": 210.13,
      "learning_rate": 0.07899551939678458,
      "loss": 2.9415,
      "step": 130700
    },
    {
      "epoch": 210.16,
      "learning_rate": 0.0789923039659164,
      "loss": 2.9802,
      "step": 130720
    },
    {
      "epoch": 210.19,
      "learning_rate": 0.07898908853504823,
      "loss": 2.9538,
      "step": 130740
    },
    {
      "epoch": 210.23,
      "learning_rate": 0.07898587310418007,
      "loss": 2.9847,
      "step": 130760
    },
    {
      "epoch": 210.26,
      "learning_rate": 0.0789826576733119,
      "loss": 2.9416,
      "step": 130780
    },
    {
      "epoch": 210.29,
      "learning_rate": 0.07897944224244374,
      "loss": 2.9396,
      "step": 130800
    },
    {
      "epoch": 210.32,
      "learning_rate": 0.07897622681157557,
      "loss": 2.997,
      "step": 130820
    },
    {
      "epoch": 210.35,
      "learning_rate": 0.07897301138070739,
      "loss": 2.9933,
      "step": 130840
    },
    {
      "epoch": 210.39,
      "learning_rate": 0.07896979594983923,
      "loss": 2.9974,
      "step": 130860
    },
    {
      "epoch": 210.42,
      "learning_rate": 0.07896658051897107,
      "loss": 2.9845,
      "step": 130880
    },
    {
      "epoch": 210.45,
      "learning_rate": 0.07896336508810291,
      "loss": 2.9842,
      "step": 130900
    },
    {
      "epoch": 210.48,
      "learning_rate": 0.07896014965723473,
      "loss": 2.9865,
      "step": 130920
    },
    {
      "epoch": 210.51,
      "learning_rate": 0.07895693422636657,
      "loss": 3.0232,
      "step": 130940
    },
    {
      "epoch": 210.55,
      "learning_rate": 0.0789537187954984,
      "loss": 2.9715,
      "step": 130960
    },
    {
      "epoch": 210.58,
      "learning_rate": 0.07895050336463023,
      "loss": 3.0103,
      "step": 130980
    },
    {
      "epoch": 210.61,
      "learning_rate": 0.07894728793376206,
      "loss": 3.0129,
      "step": 131000
    },
    {
      "epoch": 210.64,
      "learning_rate": 0.0789440725028939,
      "loss": 2.9743,
      "step": 131020
    },
    {
      "epoch": 210.68,
      "learning_rate": 0.07894085707202574,
      "loss": 2.9516,
      "step": 131040
    },
    {
      "epoch": 210.71,
      "learning_rate": 0.07893764164115756,
      "loss": 2.9635,
      "step": 131060
    },
    {
      "epoch": 210.74,
      "learning_rate": 0.07893442621028939,
      "loss": 2.9577,
      "step": 131080
    },
    {
      "epoch": 210.77,
      "learning_rate": 0.07893121077942122,
      "loss": 2.9616,
      "step": 131100
    },
    {
      "epoch": 210.8,
      "learning_rate": 0.07892799534855306,
      "loss": 2.9981,
      "step": 131120
    },
    {
      "epoch": 210.84,
      "learning_rate": 0.0789247799176849,
      "loss": 2.9656,
      "step": 131140
    },
    {
      "epoch": 210.87,
      "learning_rate": 0.07892156448681673,
      "loss": 2.9949,
      "step": 131160
    },
    {
      "epoch": 210.9,
      "learning_rate": 0.07891834905594855,
      "loss": 2.9657,
      "step": 131180
    },
    {
      "epoch": 210.93,
      "learning_rate": 0.07891513362508039,
      "loss": 2.9628,
      "step": 131200
    },
    {
      "epoch": 210.96,
      "learning_rate": 0.07891191819421223,
      "loss": 3.0043,
      "step": 131220
    },
    {
      "epoch": 211.0,
      "learning_rate": 0.07890870276334407,
      "loss": 3.004,
      "step": 131240
    },
    {
      "epoch": 211.0,
      "eval_accuracy": {
        "accuracy": 0.379693695094457
      },
      "eval_loss": 3.068340301513672,
      "eval_runtime": 5.8901,
      "eval_samples_per_second": 2183.838,
      "eval_steps_per_second": 34.125,
      "step": 131242
    },
    {
      "epoch": 211.03,
      "learning_rate": 0.07890548733247589,
      "loss": 2.9716,
      "step": 131260
    },
    {
      "epoch": 211.06,
      "learning_rate": 0.07890227190160772,
      "loss": 2.9834,
      "step": 131280
    },
    {
      "epoch": 211.09,
      "learning_rate": 0.07889905647073955,
      "loss": 2.956,
      "step": 131300
    },
    {
      "epoch": 211.13,
      "learning_rate": 0.07889584103987139,
      "loss": 2.9547,
      "step": 131320
    },
    {
      "epoch": 211.16,
      "learning_rate": 0.07889262560900322,
      "loss": 2.9963,
      "step": 131340
    },
    {
      "epoch": 211.19,
      "learning_rate": 0.07888941017813506,
      "loss": 2.9797,
      "step": 131360
    },
    {
      "epoch": 211.22,
      "learning_rate": 0.07888619474726688,
      "loss": 2.9659,
      "step": 131380
    },
    {
      "epoch": 211.25,
      "learning_rate": 0.07888297931639872,
      "loss": 2.9732,
      "step": 131400
    },
    {
      "epoch": 211.29,
      "learning_rate": 0.07887976388553054,
      "loss": 2.9663,
      "step": 131420
    },
    {
      "epoch": 211.32,
      "learning_rate": 0.07887654845466238,
      "loss": 2.9539,
      "step": 131440
    },
    {
      "epoch": 211.35,
      "learning_rate": 0.07887333302379422,
      "loss": 2.9722,
      "step": 131460
    },
    {
      "epoch": 211.38,
      "learning_rate": 0.07887011759292605,
      "loss": 2.9616,
      "step": 131480
    },
    {
      "epoch": 211.41,
      "learning_rate": 0.07886690216205788,
      "loss": 2.9671,
      "step": 131500
    },
    {
      "epoch": 211.45,
      "learning_rate": 0.07886368673118971,
      "loss": 2.9309,
      "step": 131520
    },
    {
      "epoch": 211.48,
      "learning_rate": 0.07886047130032155,
      "loss": 2.9836,
      "step": 131540
    },
    {
      "epoch": 211.51,
      "learning_rate": 0.07885725586945339,
      "loss": 2.984,
      "step": 131560
    },
    {
      "epoch": 211.54,
      "learning_rate": 0.07885404043858522,
      "loss": 2.9992,
      "step": 131580
    },
    {
      "epoch": 211.58,
      "learning_rate": 0.07885082500771705,
      "loss": 2.9713,
      "step": 131600
    },
    {
      "epoch": 211.61,
      "learning_rate": 0.07884760957684887,
      "loss": 3.0516,
      "step": 131620
    },
    {
      "epoch": 211.64,
      "learning_rate": 0.07884439414598071,
      "loss": 2.9679,
      "step": 131640
    },
    {
      "epoch": 211.67,
      "learning_rate": 0.07884117871511255,
      "loss": 3.0089,
      "step": 131660
    },
    {
      "epoch": 211.7,
      "learning_rate": 0.07883796328424438,
      "loss": 2.9546,
      "step": 131680
    },
    {
      "epoch": 211.74,
      "learning_rate": 0.07883474785337621,
      "loss": 2.9994,
      "step": 131700
    },
    {
      "epoch": 211.77,
      "learning_rate": 0.07883153242250804,
      "loss": 2.9917,
      "step": 131720
    },
    {
      "epoch": 211.8,
      "learning_rate": 0.07882831699163988,
      "loss": 2.9608,
      "step": 131740
    },
    {
      "epoch": 211.83,
      "learning_rate": 0.0788251015607717,
      "loss": 2.9637,
      "step": 131760
    },
    {
      "epoch": 211.86,
      "learning_rate": 0.07882188612990354,
      "loss": 2.9495,
      "step": 131780
    },
    {
      "epoch": 211.9,
      "learning_rate": 0.07881867069903538,
      "loss": 2.9743,
      "step": 131800
    },
    {
      "epoch": 211.93,
      "learning_rate": 0.0788154552681672,
      "loss": 2.9824,
      "step": 131820
    },
    {
      "epoch": 211.96,
      "learning_rate": 0.07881223983729904,
      "loss": 2.9712,
      "step": 131840
    },
    {
      "epoch": 211.99,
      "learning_rate": 0.07880902440643087,
      "loss": 2.9882,
      "step": 131860
    },
    {
      "epoch": 212.0,
      "eval_accuracy": {
        "accuracy": 0.374795926300241
      },
      "eval_loss": 3.063305377960205,
      "eval_runtime": 3.2176,
      "eval_samples_per_second": 3997.65,
      "eval_steps_per_second": 62.468,
      "step": 131864
    },
    {
      "epoch": 212.03,
      "learning_rate": 0.0788058089755627,
      "loss": 2.9969,
      "step": 131880
    },
    {
      "epoch": 212.06,
      "learning_rate": 0.07880259354469454,
      "loss": 2.9887,
      "step": 131900
    },
    {
      "epoch": 212.09,
      "learning_rate": 0.07879937811382637,
      "loss": 2.9494,
      "step": 131920
    },
    {
      "epoch": 212.12,
      "learning_rate": 0.0787961626829582,
      "loss": 2.9675,
      "step": 131940
    },
    {
      "epoch": 212.15,
      "learning_rate": 0.07879294725209003,
      "loss": 2.9554,
      "step": 131960
    },
    {
      "epoch": 212.19,
      "learning_rate": 0.07878973182122187,
      "loss": 2.9694,
      "step": 131980
    },
    {
      "epoch": 212.22,
      "learning_rate": 0.07878651639035371,
      "loss": 2.9572,
      "step": 132000
    },
    {
      "epoch": 212.25,
      "learning_rate": 0.07878330095948553,
      "loss": 2.9785,
      "step": 132020
    },
    {
      "epoch": 212.28,
      "learning_rate": 0.07878008552861737,
      "loss": 2.9698,
      "step": 132040
    },
    {
      "epoch": 212.32,
      "learning_rate": 0.0787768700977492,
      "loss": 3.0148,
      "step": 132060
    },
    {
      "epoch": 212.35,
      "learning_rate": 0.07877365466688104,
      "loss": 3.0056,
      "step": 132080
    },
    {
      "epoch": 212.38,
      "learning_rate": 0.07877043923601286,
      "loss": 2.9969,
      "step": 132100
    },
    {
      "epoch": 212.41,
      "learning_rate": 0.0787672238051447,
      "loss": 3.0098,
      "step": 132120
    },
    {
      "epoch": 212.44,
      "learning_rate": 0.07876400837427654,
      "loss": 2.9778,
      "step": 132140
    },
    {
      "epoch": 212.48,
      "learning_rate": 0.07876079294340836,
      "loss": 3.0461,
      "step": 132160
    },
    {
      "epoch": 212.51,
      "learning_rate": 0.0787575775125402,
      "loss": 2.971,
      "step": 132180
    },
    {
      "epoch": 212.54,
      "learning_rate": 0.07875436208167202,
      "loss": 2.9539,
      "step": 132200
    },
    {
      "epoch": 212.57,
      "learning_rate": 0.07875114665080386,
      "loss": 2.9443,
      "step": 132220
    },
    {
      "epoch": 212.6,
      "learning_rate": 0.0787479312199357,
      "loss": 2.9686,
      "step": 132240
    },
    {
      "epoch": 212.64,
      "learning_rate": 0.07874471578906753,
      "loss": 2.9611,
      "step": 132260
    },
    {
      "epoch": 212.67,
      "learning_rate": 0.07874150035819936,
      "loss": 2.95,
      "step": 132280
    },
    {
      "epoch": 212.7,
      "learning_rate": 0.07873828492733119,
      "loss": 2.9515,
      "step": 132300
    },
    {
      "epoch": 212.73,
      "learning_rate": 0.07873506949646303,
      "loss": 2.9881,
      "step": 132320
    },
    {
      "epoch": 212.77,
      "learning_rate": 0.07873185406559487,
      "loss": 3.0021,
      "step": 132340
    },
    {
      "epoch": 212.8,
      "learning_rate": 0.07872863863472669,
      "loss": 2.9969,
      "step": 132360
    },
    {
      "epoch": 212.83,
      "learning_rate": 0.07872542320385853,
      "loss": 2.9612,
      "step": 132380
    },
    {
      "epoch": 212.86,
      "learning_rate": 0.07872220777299035,
      "loss": 3.0099,
      "step": 132400
    },
    {
      "epoch": 212.89,
      "learning_rate": 0.0787189923421222,
      "loss": 2.9752,
      "step": 132420
    },
    {
      "epoch": 212.93,
      "learning_rate": 0.07871577691125402,
      "loss": 2.9577,
      "step": 132440
    },
    {
      "epoch": 212.96,
      "learning_rate": 0.07871256148038586,
      "loss": 2.9889,
      "step": 132460
    },
    {
      "epoch": 212.99,
      "learning_rate": 0.0787093460495177,
      "loss": 2.9681,
      "step": 132480
    },
    {
      "epoch": 213.0,
      "eval_accuracy": {
        "accuracy": 0.3832698437378528
      },
      "eval_loss": 3.0622379779815674,
      "eval_runtime": 3.1047,
      "eval_samples_per_second": 4143.012,
      "eval_steps_per_second": 64.74,
      "step": 132486
    },
    {
      "epoch": 213.02,
      "learning_rate": 0.07870613061864952,
      "loss": 2.972,
      "step": 132500
    },
    {
      "epoch": 213.05,
      "learning_rate": 0.07870291518778136,
      "loss": 2.9936,
      "step": 132520
    },
    {
      "epoch": 213.09,
      "learning_rate": 0.07869969975691318,
      "loss": 2.9941,
      "step": 132540
    },
    {
      "epoch": 213.12,
      "learning_rate": 0.07869648432604502,
      "loss": 2.9631,
      "step": 132560
    },
    {
      "epoch": 213.15,
      "learning_rate": 0.07869326889517686,
      "loss": 2.976,
      "step": 132580
    },
    {
      "epoch": 213.18,
      "learning_rate": 0.07869005346430868,
      "loss": 2.9771,
      "step": 132600
    },
    {
      "epoch": 213.22,
      "learning_rate": 0.07868683803344052,
      "loss": 2.9708,
      "step": 132620
    },
    {
      "epoch": 213.25,
      "learning_rate": 0.07868362260257235,
      "loss": 3.0089,
      "step": 132640
    },
    {
      "epoch": 213.28,
      "learning_rate": 0.0786805679432476,
      "loss": 2.9986,
      "step": 132660
    },
    {
      "epoch": 213.31,
      "learning_rate": 0.07867735251237942,
      "loss": 3.0502,
      "step": 132680
    },
    {
      "epoch": 213.34,
      "learning_rate": 0.07867413708151126,
      "loss": 2.9478,
      "step": 132700
    },
    {
      "epoch": 213.38,
      "learning_rate": 0.07867092165064309,
      "loss": 2.9796,
      "step": 132720
    },
    {
      "epoch": 213.41,
      "learning_rate": 0.07866770621977492,
      "loss": 2.9582,
      "step": 132740
    },
    {
      "epoch": 213.44,
      "learning_rate": 0.07866449078890676,
      "loss": 2.9871,
      "step": 132760
    },
    {
      "epoch": 213.47,
      "learning_rate": 0.07866127535803859,
      "loss": 3.0044,
      "step": 132780
    },
    {
      "epoch": 213.5,
      "learning_rate": 0.07865805992717043,
      "loss": 2.9721,
      "step": 132800
    },
    {
      "epoch": 213.54,
      "learning_rate": 0.07865484449630225,
      "loss": 2.9685,
      "step": 132820
    },
    {
      "epoch": 213.57,
      "learning_rate": 0.07865162906543409,
      "loss": 2.9662,
      "step": 132840
    },
    {
      "epoch": 213.6,
      "learning_rate": 0.07864841363456593,
      "loss": 2.9305,
      "step": 132860
    },
    {
      "epoch": 213.63,
      "learning_rate": 0.07864519820369775,
      "loss": 2.9494,
      "step": 132880
    },
    {
      "epoch": 213.67,
      "learning_rate": 0.07864198277282959,
      "loss": 2.9539,
      "step": 132900
    },
    {
      "epoch": 213.7,
      "learning_rate": 0.07863876734196142,
      "loss": 2.9594,
      "step": 132920
    },
    {
      "epoch": 213.73,
      "learning_rate": 0.07863555191109325,
      "loss": 2.9753,
      "step": 132940
    },
    {
      "epoch": 213.76,
      "learning_rate": 0.07863233648022509,
      "loss": 3.008,
      "step": 132960
    },
    {
      "epoch": 213.79,
      "learning_rate": 0.07862912104935692,
      "loss": 2.9517,
      "step": 132980
    },
    {
      "epoch": 213.83,
      "learning_rate": 0.07862590561848876,
      "loss": 2.9402,
      "step": 133000
    },
    {
      "epoch": 213.86,
      "learning_rate": 0.07862269018762058,
      "loss": 2.9774,
      "step": 133020
    },
    {
      "epoch": 213.89,
      "learning_rate": 0.07861947475675242,
      "loss": 2.9745,
      "step": 133040
    },
    {
      "epoch": 213.92,
      "learning_rate": 0.07861625932588424,
      "loss": 2.974,
      "step": 133060
    },
    {
      "epoch": 213.95,
      "learning_rate": 0.07861304389501608,
      "loss": 2.9926,
      "step": 133080
    },
    {
      "epoch": 213.99,
      "learning_rate": 0.07860982846414792,
      "loss": 2.9804,
      "step": 133100
    },
    {
      "epoch": 214.0,
      "eval_accuracy": {
        "accuracy": 0.3801601492653347
      },
      "eval_loss": 3.056410551071167,
      "eval_runtime": 2.7022,
      "eval_samples_per_second": 4760.276,
      "eval_steps_per_second": 74.385,
      "step": 133108
    },
    {
      "epoch": 214.02,
      "learning_rate": 0.07860661303327975,
      "loss": 2.9632,
      "step": 133120
    },
    {
      "epoch": 214.05,
      "learning_rate": 0.07860339760241158,
      "loss": 2.9878,
      "step": 133140
    },
    {
      "epoch": 214.08,
      "learning_rate": 0.07860018217154341,
      "loss": 3.0039,
      "step": 133160
    },
    {
      "epoch": 214.12,
      "learning_rate": 0.07859696674067525,
      "loss": 2.9804,
      "step": 133180
    },
    {
      "epoch": 214.15,
      "learning_rate": 0.07859375130980709,
      "loss": 2.9813,
      "step": 133200
    },
    {
      "epoch": 214.18,
      "learning_rate": 0.07859053587893891,
      "loss": 2.9708,
      "step": 133220
    },
    {
      "epoch": 214.21,
      "learning_rate": 0.07858732044807075,
      "loss": 2.9977,
      "step": 133240
    },
    {
      "epoch": 214.24,
      "learning_rate": 0.07858410501720257,
      "loss": 2.99,
      "step": 133260
    },
    {
      "epoch": 214.28,
      "learning_rate": 0.07858088958633441,
      "loss": 2.9544,
      "step": 133280
    },
    {
      "epoch": 214.31,
      "learning_rate": 0.07857767415546625,
      "loss": 2.9748,
      "step": 133300
    },
    {
      "epoch": 214.34,
      "learning_rate": 0.07857445872459808,
      "loss": 2.9396,
      "step": 133320
    },
    {
      "epoch": 214.37,
      "learning_rate": 0.07857124329372991,
      "loss": 2.9654,
      "step": 133340
    },
    {
      "epoch": 214.41,
      "learning_rate": 0.07856802786286174,
      "loss": 2.9611,
      "step": 133360
    },
    {
      "epoch": 214.44,
      "learning_rate": 0.07856481243199358,
      "loss": 2.9625,
      "step": 133380
    },
    {
      "epoch": 214.47,
      "learning_rate": 0.0785615970011254,
      "loss": 2.9883,
      "step": 133400
    },
    {
      "epoch": 214.5,
      "learning_rate": 0.07855838157025724,
      "loss": 2.9686,
      "step": 133420
    },
    {
      "epoch": 214.53,
      "learning_rate": 0.07855516613938908,
      "loss": 2.993,
      "step": 133440
    },
    {
      "epoch": 214.57,
      "learning_rate": 0.0785519507085209,
      "loss": 2.97,
      "step": 133460
    },
    {
      "epoch": 214.6,
      "learning_rate": 0.07854873527765273,
      "loss": 2.9771,
      "step": 133480
    },
    {
      "epoch": 214.63,
      "learning_rate": 0.07854551984678457,
      "loss": 2.9859,
      "step": 133500
    },
    {
      "epoch": 214.66,
      "learning_rate": 0.0785423044159164,
      "loss": 2.9796,
      "step": 133520
    },
    {
      "epoch": 214.69,
      "learning_rate": 0.07853908898504824,
      "loss": 2.9573,
      "step": 133540
    },
    {
      "epoch": 214.73,
      "learning_rate": 0.07853587355418007,
      "loss": 2.9685,
      "step": 133560
    },
    {
      "epoch": 214.76,
      "learning_rate": 0.0785326581233119,
      "loss": 2.9474,
      "step": 133580
    },
    {
      "epoch": 214.79,
      "learning_rate": 0.07852944269244373,
      "loss": 2.9641,
      "step": 133600
    },
    {
      "epoch": 214.82,
      "learning_rate": 0.07852622726157557,
      "loss": 2.9787,
      "step": 133620
    },
    {
      "epoch": 214.86,
      "learning_rate": 0.07852301183070741,
      "loss": 2.968,
      "step": 133640
    },
    {
      "epoch": 214.89,
      "learning_rate": 0.07851979639983923,
      "loss": 2.9835,
      "step": 133660
    },
    {
      "epoch": 214.92,
      "learning_rate": 0.07851658096897106,
      "loss": 2.9571,
      "step": 133680
    },
    {
      "epoch": 214.95,
      "learning_rate": 0.0785133655381029,
      "loss": 2.9706,
      "step": 133700
    },
    {
      "epoch": 214.98,
      "learning_rate": 0.07851015010723474,
      "loss": 2.9649,
      "step": 133720
    },
    {
      "epoch": 215.0,
      "eval_accuracy": {
        "accuracy": 0.3746404415766151
      },
      "eval_loss": 3.0847630500793457,
      "eval_runtime": 2.7136,
      "eval_samples_per_second": 4740.261,
      "eval_steps_per_second": 74.072,
      "step": 133730
    },
    {
      "epoch": 215.02,
      "learning_rate": 0.07850693467636656,
      "loss": 2.9661,
      "step": 133740
    },
    {
      "epoch": 215.05,
      "learning_rate": 0.0785037192454984,
      "loss": 2.9279,
      "step": 133760
    },
    {
      "epoch": 215.08,
      "learning_rate": 0.07850050381463024,
      "loss": 2.9504,
      "step": 133780
    },
    {
      "epoch": 215.11,
      "learning_rate": 0.07849728838376206,
      "loss": 2.9676,
      "step": 133800
    },
    {
      "epoch": 215.14,
      "learning_rate": 0.07849407295289389,
      "loss": 2.9566,
      "step": 133820
    },
    {
      "epoch": 215.18,
      "learning_rate": 0.07849085752202573,
      "loss": 2.9126,
      "step": 133840
    },
    {
      "epoch": 215.21,
      "learning_rate": 0.07848764209115756,
      "loss": 2.9838,
      "step": 133860
    },
    {
      "epoch": 215.24,
      "learning_rate": 0.0784844266602894,
      "loss": 2.9659,
      "step": 133880
    },
    {
      "epoch": 215.27,
      "learning_rate": 0.07848121122942123,
      "loss": 2.9448,
      "step": 133900
    },
    {
      "epoch": 215.31,
      "learning_rate": 0.07847799579855305,
      "loss": 2.9262,
      "step": 133920
    },
    {
      "epoch": 215.34,
      "learning_rate": 0.07847478036768489,
      "loss": 2.9535,
      "step": 133940
    },
    {
      "epoch": 215.37,
      "learning_rate": 0.07847156493681673,
      "loss": 2.9713,
      "step": 133960
    },
    {
      "epoch": 215.4,
      "learning_rate": 0.07846834950594857,
      "loss": 3.0135,
      "step": 133980
    },
    {
      "epoch": 215.43,
      "learning_rate": 0.07846513407508039,
      "loss": 2.9914,
      "step": 134000
    },
    {
      "epoch": 215.47,
      "learning_rate": 0.07846191864421222,
      "loss": 2.9816,
      "step": 134020
    },
    {
      "epoch": 215.5,
      "learning_rate": 0.07845870321334406,
      "loss": 2.9436,
      "step": 134040
    },
    {
      "epoch": 215.53,
      "learning_rate": 0.0784554877824759,
      "loss": 2.9713,
      "step": 134060
    },
    {
      "epoch": 215.56,
      "learning_rate": 0.07845227235160772,
      "loss": 2.9571,
      "step": 134080
    },
    {
      "epoch": 215.59,
      "learning_rate": 0.07844905692073956,
      "loss": 2.9683,
      "step": 134100
    },
    {
      "epoch": 215.63,
      "learning_rate": 0.07844584148987138,
      "loss": 2.9923,
      "step": 134120
    },
    {
      "epoch": 215.66,
      "learning_rate": 0.07844262605900322,
      "loss": 2.9345,
      "step": 134140
    },
    {
      "epoch": 215.69,
      "learning_rate": 0.07843941062813505,
      "loss": 2.9558,
      "step": 134160
    },
    {
      "epoch": 215.72,
      "learning_rate": 0.07843619519726688,
      "loss": 2.9831,
      "step": 134180
    },
    {
      "epoch": 215.76,
      "learning_rate": 0.07843297976639872,
      "loss": 3.0109,
      "step": 134200
    },
    {
      "epoch": 215.79,
      "learning_rate": 0.07842976433553055,
      "loss": 2.9782,
      "step": 134220
    },
    {
      "epoch": 215.82,
      "learning_rate": 0.07842654890466239,
      "loss": 2.9726,
      "step": 134240
    },
    {
      "epoch": 215.85,
      "learning_rate": 0.07842333347379421,
      "loss": 3.0198,
      "step": 134260
    },
    {
      "epoch": 215.88,
      "learning_rate": 0.07842011804292605,
      "loss": 2.9872,
      "step": 134280
    },
    {
      "epoch": 215.92,
      "learning_rate": 0.07841690261205789,
      "loss": 2.9837,
      "step": 134300
    },
    {
      "epoch": 215.95,
      "learning_rate": 0.07841368718118971,
      "loss": 2.9704,
      "step": 134320
    },
    {
      "epoch": 215.98,
      "learning_rate": 0.07841047175032155,
      "loss": 2.9647,
      "step": 134340
    },
    {
      "epoch": 216.0,
      "eval_accuracy": {
        "accuracy": 0.37518463810930575
      },
      "eval_loss": 3.0951082706451416,
      "eval_runtime": 2.6541,
      "eval_samples_per_second": 4846.413,
      "eval_steps_per_second": 75.731,
      "step": 134352
    },
    {
      "epoch": 216.01,
      "learning_rate": 0.07840725631945338,
      "loss": 2.9932,
      "step": 134360
    },
    {
      "epoch": 216.05,
      "learning_rate": 0.07840404088858521,
      "loss": 2.9826,
      "step": 134380
    },
    {
      "epoch": 216.08,
      "learning_rate": 0.07840082545771705,
      "loss": 2.9598,
      "step": 134400
    },
    {
      "epoch": 216.11,
      "learning_rate": 0.07839761002684888,
      "loss": 2.9351,
      "step": 134420
    },
    {
      "epoch": 216.14,
      "learning_rate": 0.07839439459598072,
      "loss": 2.9472,
      "step": 134440
    },
    {
      "epoch": 216.17,
      "learning_rate": 0.07839117916511254,
      "loss": 2.9667,
      "step": 134460
    },
    {
      "epoch": 216.21,
      "learning_rate": 0.07838796373424438,
      "loss": 2.9876,
      "step": 134480
    },
    {
      "epoch": 216.24,
      "learning_rate": 0.0783847483033762,
      "loss": 2.9528,
      "step": 134500
    },
    {
      "epoch": 216.27,
      "learning_rate": 0.07838153287250804,
      "loss": 2.9219,
      "step": 134520
    },
    {
      "epoch": 216.3,
      "learning_rate": 0.07837831744163988,
      "loss": 2.9983,
      "step": 134540
    },
    {
      "epoch": 216.33,
      "learning_rate": 0.0783751020107717,
      "loss": 2.9666,
      "step": 134560
    },
    {
      "epoch": 216.37,
      "learning_rate": 0.07837188657990354,
      "loss": 2.9404,
      "step": 134580
    },
    {
      "epoch": 216.4,
      "learning_rate": 0.07836867114903537,
      "loss": 2.9551,
      "step": 134600
    },
    {
      "epoch": 216.43,
      "learning_rate": 0.0783654557181672,
      "loss": 2.9431,
      "step": 134620
    },
    {
      "epoch": 216.46,
      "learning_rate": 0.07836224028729905,
      "loss": 2.9428,
      "step": 134640
    },
    {
      "epoch": 216.5,
      "learning_rate": 0.07835902485643087,
      "loss": 2.9703,
      "step": 134660
    },
    {
      "epoch": 216.53,
      "learning_rate": 0.07835580942556271,
      "loss": 2.9796,
      "step": 134680
    },
    {
      "epoch": 216.56,
      "learning_rate": 0.07835259399469453,
      "loss": 2.9773,
      "step": 134700
    },
    {
      "epoch": 216.59,
      "learning_rate": 0.07834937856382637,
      "loss": 2.9363,
      "step": 134720
    },
    {
      "epoch": 216.62,
      "learning_rate": 0.07834616313295821,
      "loss": 2.9932,
      "step": 134740
    },
    {
      "epoch": 216.66,
      "learning_rate": 0.07834294770209004,
      "loss": 2.9616,
      "step": 134760
    },
    {
      "epoch": 216.69,
      "learning_rate": 0.07833973227122187,
      "loss": 2.9362,
      "step": 134780
    },
    {
      "epoch": 216.72,
      "learning_rate": 0.0783365168403537,
      "loss": 2.9541,
      "step": 134800
    },
    {
      "epoch": 216.75,
      "learning_rate": 0.07833330140948554,
      "loss": 2.9894,
      "step": 134820
    },
    {
      "epoch": 216.78,
      "learning_rate": 0.07833008597861736,
      "loss": 2.9878,
      "step": 134840
    },
    {
      "epoch": 216.82,
      "learning_rate": 0.0783268705477492,
      "loss": 2.9437,
      "step": 134860
    },
    {
      "epoch": 216.85,
      "learning_rate": 0.07832365511688104,
      "loss": 2.9523,
      "step": 134880
    },
    {
      "epoch": 216.88,
      "learning_rate": 0.07832043968601286,
      "loss": 2.9532,
      "step": 134900
    },
    {
      "epoch": 216.91,
      "learning_rate": 0.0783172242551447,
      "loss": 2.9751,
      "step": 134920
    },
    {
      "epoch": 216.95,
      "learning_rate": 0.07831400882427653,
      "loss": 2.9765,
      "step": 134940
    },
    {
      "epoch": 216.98,
      "learning_rate": 0.07831079339340836,
      "loss": 2.9283,
      "step": 134960
    },
    {
      "epoch": 217.0,
      "eval_accuracy": {
        "accuracy": 0.3729301096167302
      },
      "eval_loss": 3.0752859115600586,
      "eval_runtime": 2.6628,
      "eval_samples_per_second": 4830.564,
      "eval_steps_per_second": 75.483,
      "step": 134974
    },
    {
      "epoch": 217.01,
      "learning_rate": 0.0783075779625402,
      "loss": 2.9935,
      "step": 134980
    },
    {
      "epoch": 217.04,
      "learning_rate": 0.07830436253167203,
      "loss": 2.9464,
      "step": 135000
    },
    {
      "epoch": 217.07,
      "learning_rate": 0.07830114710080387,
      "loss": 2.9582,
      "step": 135020
    },
    {
      "epoch": 217.11,
      "learning_rate": 0.07829793166993569,
      "loss": 2.9635,
      "step": 135040
    },
    {
      "epoch": 217.14,
      "learning_rate": 0.07829471623906753,
      "loss": 2.9798,
      "step": 135060
    },
    {
      "epoch": 217.17,
      "learning_rate": 0.07829150080819937,
      "loss": 2.9662,
      "step": 135080
    },
    {
      "epoch": 217.2,
      "learning_rate": 0.0782882853773312,
      "loss": 2.9624,
      "step": 135100
    },
    {
      "epoch": 217.23,
      "learning_rate": 0.07828506994646303,
      "loss": 2.995,
      "step": 135120
    },
    {
      "epoch": 217.27,
      "learning_rate": 0.07828185451559486,
      "loss": 2.9877,
      "step": 135140
    },
    {
      "epoch": 217.3,
      "learning_rate": 0.0782786390847267,
      "loss": 2.9785,
      "step": 135160
    },
    {
      "epoch": 217.33,
      "learning_rate": 0.07827542365385852,
      "loss": 2.9661,
      "step": 135180
    },
    {
      "epoch": 217.36,
      "learning_rate": 0.07827220822299036,
      "loss": 2.9415,
      "step": 135200
    },
    {
      "epoch": 217.4,
      "learning_rate": 0.0782689927921222,
      "loss": 2.9757,
      "step": 135220
    },
    {
      "epoch": 217.43,
      "learning_rate": 0.07826577736125402,
      "loss": 2.9977,
      "step": 135240
    },
    {
      "epoch": 217.46,
      "learning_rate": 0.07826256193038586,
      "loss": 2.9431,
      "step": 135260
    },
    {
      "epoch": 217.49,
      "learning_rate": 0.07825934649951768,
      "loss": 2.9535,
      "step": 135280
    },
    {
      "epoch": 217.52,
      "learning_rate": 0.07825613106864952,
      "loss": 2.9545,
      "step": 135300
    },
    {
      "epoch": 217.56,
      "learning_rate": 0.07825291563778136,
      "loss": 2.9625,
      "step": 135320
    },
    {
      "epoch": 217.59,
      "learning_rate": 0.07824970020691319,
      "loss": 2.9686,
      "step": 135340
    },
    {
      "epoch": 217.62,
      "learning_rate": 0.07824648477604502,
      "loss": 2.9901,
      "step": 135360
    },
    {
      "epoch": 217.65,
      "learning_rate": 0.07824326934517685,
      "loss": 2.9637,
      "step": 135380
    },
    {
      "epoch": 217.68,
      "learning_rate": 0.07824005391430869,
      "loss": 2.9706,
      "step": 135400
    },
    {
      "epoch": 217.72,
      "learning_rate": 0.07823683848344053,
      "loss": 2.9927,
      "step": 135420
    },
    {
      "epoch": 217.75,
      "learning_rate": 0.07823362305257235,
      "loss": 3.0166,
      "step": 135440
    },
    {
      "epoch": 217.78,
      "learning_rate": 0.07823040762170419,
      "loss": 2.9395,
      "step": 135460
    },
    {
      "epoch": 217.81,
      "learning_rate": 0.07822719219083601,
      "loss": 2.9384,
      "step": 135480
    },
    {
      "epoch": 217.85,
      "learning_rate": 0.07822397675996785,
      "loss": 2.9564,
      "step": 135500
    },
    {
      "epoch": 217.88,
      "learning_rate": 0.07822076132909968,
      "loss": 2.9449,
      "step": 135520
    },
    {
      "epoch": 217.91,
      "learning_rate": 0.07821754589823152,
      "loss": 2.988,
      "step": 135540
    },
    {
      "epoch": 217.94,
      "learning_rate": 0.07821433046736335,
      "loss": 3.0082,
      "step": 135560
    },
    {
      "epoch": 217.97,
      "learning_rate": 0.07821111503649518,
      "loss": 3.0013,
      "step": 135580
    },
    {
      "epoch": 218.0,
      "eval_accuracy": {
        "accuracy": 0.37961595273264404
      },
      "eval_loss": 3.0655739307403564,
      "eval_runtime": 2.7157,
      "eval_samples_per_second": 4736.535,
      "eval_steps_per_second": 74.014,
      "step": 135596
    },
    {
      "epoch": 218.01,
      "learning_rate": 0.07820789960562702,
      "loss": 2.9898,
      "step": 135600
    },
    {
      "epoch": 218.04,
      "learning_rate": 0.07820468417475884,
      "loss": 2.9542,
      "step": 135620
    },
    {
      "epoch": 218.07,
      "learning_rate": 0.07820146874389068,
      "loss": 2.9703,
      "step": 135640
    },
    {
      "epoch": 218.1,
      "learning_rate": 0.07819825331302252,
      "loss": 2.9671,
      "step": 135660
    },
    {
      "epoch": 218.14,
      "learning_rate": 0.07819503788215434,
      "loss": 2.9378,
      "step": 135680
    },
    {
      "epoch": 218.17,
      "learning_rate": 0.07819182245128618,
      "loss": 2.9325,
      "step": 135700
    },
    {
      "epoch": 218.2,
      "learning_rate": 0.07818860702041801,
      "loss": 2.9529,
      "step": 135720
    },
    {
      "epoch": 218.23,
      "learning_rate": 0.07818539158954985,
      "loss": 2.9732,
      "step": 135740
    },
    {
      "epoch": 218.26,
      "learning_rate": 0.07818217615868168,
      "loss": 2.9414,
      "step": 135760
    },
    {
      "epoch": 218.3,
      "learning_rate": 0.07817896072781351,
      "loss": 2.9222,
      "step": 135780
    },
    {
      "epoch": 218.33,
      "learning_rate": 0.07817574529694535,
      "loss": 2.9643,
      "step": 135800
    },
    {
      "epoch": 218.36,
      "learning_rate": 0.07817252986607717,
      "loss": 2.977,
      "step": 135820
    },
    {
      "epoch": 218.39,
      "learning_rate": 0.07816931443520901,
      "loss": 2.9769,
      "step": 135840
    },
    {
      "epoch": 218.42,
      "learning_rate": 0.07816609900434084,
      "loss": 2.9431,
      "step": 135860
    },
    {
      "epoch": 218.46,
      "learning_rate": 0.07816288357347267,
      "loss": 2.9494,
      "step": 135880
    },
    {
      "epoch": 218.49,
      "learning_rate": 0.07815966814260451,
      "loss": 2.9542,
      "step": 135900
    },
    {
      "epoch": 218.52,
      "learning_rate": 0.07815645271173634,
      "loss": 2.9603,
      "step": 135920
    },
    {
      "epoch": 218.55,
      "learning_rate": 0.07815323728086818,
      "loss": 2.9909,
      "step": 135940
    },
    {
      "epoch": 218.59,
      "learning_rate": 0.07815002185,
      "loss": 2.9736,
      "step": 135960
    },
    {
      "epoch": 218.62,
      "learning_rate": 0.07814680641913184,
      "loss": 2.9546,
      "step": 135980
    },
    {
      "epoch": 218.65,
      "learning_rate": 0.07814359098826368,
      "loss": 2.9955,
      "step": 136000
    },
    {
      "epoch": 218.68,
      "learning_rate": 0.0781403755573955,
      "loss": 2.9449,
      "step": 136020
    },
    {
      "epoch": 218.71,
      "learning_rate": 0.07813716012652734,
      "loss": 2.9846,
      "step": 136040
    },
    {
      "epoch": 218.75,
      "learning_rate": 0.07813394469565917,
      "loss": 3.0062,
      "step": 136060
    },
    {
      "epoch": 218.78,
      "learning_rate": 0.078130729264791,
      "loss": 2.9306,
      "step": 136080
    },
    {
      "epoch": 218.81,
      "learning_rate": 0.07812751383392284,
      "loss": 2.931,
      "step": 136100
    },
    {
      "epoch": 218.84,
      "learning_rate": 0.07812429840305467,
      "loss": 3.0008,
      "step": 136120
    },
    {
      "epoch": 218.87,
      "learning_rate": 0.0781210829721865,
      "loss": 2.9604,
      "step": 136140
    },
    {
      "epoch": 218.91,
      "learning_rate": 0.07811786754131833,
      "loss": 2.9738,
      "step": 136160
    },
    {
      "epoch": 218.94,
      "learning_rate": 0.07811465211045017,
      "loss": 2.9699,
      "step": 136180
    },
    {
      "epoch": 218.97,
      "learning_rate": 0.078111436679582,
      "loss": 2.9832,
      "step": 136200
    },
    {
      "epoch": 219.0,
      "eval_accuracy": {
        "accuracy": 0.3795382103708311
      },
      "eval_loss": 3.0509934425354004,
      "eval_runtime": 3.0724,
      "eval_samples_per_second": 4186.605,
      "eval_steps_per_second": 65.421,
      "step": 136218
    },
    {
      "epoch": 219.0,
      "learning_rate": 0.07810822124871382,
      "loss": 2.9452,
      "step": 136220
    },
    {
      "epoch": 219.04,
      "learning_rate": 0.07810500581784567,
      "loss": 2.9832,
      "step": 136240
    },
    {
      "epoch": 219.07,
      "learning_rate": 0.0781017903869775,
      "loss": 2.977,
      "step": 136260
    },
    {
      "epoch": 219.1,
      "learning_rate": 0.07809857495610933,
      "loss": 2.9577,
      "step": 136280
    },
    {
      "epoch": 219.13,
      "learning_rate": 0.07809535952524116,
      "loss": 2.9733,
      "step": 136300
    },
    {
      "epoch": 219.16,
      "learning_rate": 0.07809214409437298,
      "loss": 2.9686,
      "step": 136320
    },
    {
      "epoch": 219.2,
      "learning_rate": 0.07808892866350484,
      "loss": 2.9281,
      "step": 136340
    },
    {
      "epoch": 219.23,
      "learning_rate": 0.07808571323263666,
      "loss": 2.9039,
      "step": 136360
    },
    {
      "epoch": 219.26,
      "learning_rate": 0.0780824978017685,
      "loss": 2.94,
      "step": 136380
    },
    {
      "epoch": 219.29,
      "learning_rate": 0.07807928237090032,
      "loss": 2.9441,
      "step": 136400
    },
    {
      "epoch": 219.32,
      "learning_rate": 0.07807606694003215,
      "loss": 2.9644,
      "step": 136420
    },
    {
      "epoch": 219.36,
      "learning_rate": 0.078072851509164,
      "loss": 2.9504,
      "step": 136440
    },
    {
      "epoch": 219.39,
      "learning_rate": 0.07806963607829583,
      "loss": 2.9603,
      "step": 136460
    },
    {
      "epoch": 219.42,
      "learning_rate": 0.07806642064742766,
      "loss": 2.9785,
      "step": 136480
    },
    {
      "epoch": 219.45,
      "learning_rate": 0.07806320521655949,
      "loss": 2.971,
      "step": 136500
    },
    {
      "epoch": 219.49,
      "learning_rate": 0.07805998978569133,
      "loss": 2.9789,
      "step": 136520
    },
    {
      "epoch": 219.52,
      "learning_rate": 0.07805677435482317,
      "loss": 2.9637,
      "step": 136540
    },
    {
      "epoch": 219.55,
      "learning_rate": 0.07805355892395498,
      "loss": 2.974,
      "step": 136560
    },
    {
      "epoch": 219.58,
      "learning_rate": 0.07805034349308683,
      "loss": 2.9632,
      "step": 136580
    },
    {
      "epoch": 219.61,
      "learning_rate": 0.07804712806221865,
      "loss": 2.9884,
      "step": 136600
    },
    {
      "epoch": 219.65,
      "learning_rate": 0.07804391263135049,
      "loss": 2.966,
      "step": 136620
    },
    {
      "epoch": 219.68,
      "learning_rate": 0.07804069720048232,
      "loss": 2.9503,
      "step": 136640
    },
    {
      "epoch": 219.71,
      "learning_rate": 0.07803748176961414,
      "loss": 2.9203,
      "step": 136660
    },
    {
      "epoch": 219.74,
      "learning_rate": 0.078034266338746,
      "loss": 2.9583,
      "step": 136680
    },
    {
      "epoch": 219.77,
      "learning_rate": 0.07803105090787782,
      "loss": 2.9569,
      "step": 136700
    },
    {
      "epoch": 219.81,
      "learning_rate": 0.07802799624855307,
      "loss": 2.9896,
      "step": 136720
    },
    {
      "epoch": 219.84,
      "learning_rate": 0.0780247808176849,
      "loss": 2.9744,
      "step": 136740
    },
    {
      "epoch": 219.87,
      "learning_rate": 0.07802156538681672,
      "loss": 2.939,
      "step": 136760
    },
    {
      "epoch": 219.9,
      "learning_rate": 0.07801834995594856,
      "loss": 2.9584,
      "step": 136780
    },
    {
      "epoch": 219.94,
      "learning_rate": 0.0780151345250804,
      "loss": 2.9494,
      "step": 136800
    },
    {
      "epoch": 219.97,
      "learning_rate": 0.07801191909421222,
      "loss": 2.9681,
      "step": 136820
    },
    {
      "epoch": 220.0,
      "learning_rate": 0.07800870366334406,
      "loss": 2.9424,
      "step": 136840
    },
    {
      "epoch": 220.0,
      "eval_accuracy": {
        "accuracy": 0.38684599238124856
      },
      "eval_loss": 2.9876530170440674,
      "eval_runtime": 3.188,
      "eval_samples_per_second": 4034.858,
      "eval_steps_per_second": 63.05,
      "step": 136840
    },
    {
      "epoch": 220.03,
      "learning_rate": 0.07800548823247588,
      "loss": 2.9417,
      "step": 136860
    },
    {
      "epoch": 220.06,
      "learning_rate": 0.07800227280160772,
      "loss": 2.9402,
      "step": 136880
    },
    {
      "epoch": 220.1,
      "learning_rate": 0.07799905737073955,
      "loss": 2.9307,
      "step": 136900
    },
    {
      "epoch": 220.13,
      "learning_rate": 0.07799584193987139,
      "loss": 2.948,
      "step": 136920
    },
    {
      "epoch": 220.16,
      "learning_rate": 0.07799262650900322,
      "loss": 2.9846,
      "step": 136940
    },
    {
      "epoch": 220.19,
      "learning_rate": 0.07798941107813505,
      "loss": 3.017,
      "step": 136960
    },
    {
      "epoch": 220.23,
      "learning_rate": 0.07798619564726689,
      "loss": 3.0024,
      "step": 136980
    },
    {
      "epoch": 220.26,
      "learning_rate": 0.07798298021639871,
      "loss": 2.9673,
      "step": 137000
    },
    {
      "epoch": 220.29,
      "learning_rate": 0.07797976478553055,
      "loss": 2.9707,
      "step": 137020
    },
    {
      "epoch": 220.32,
      "learning_rate": 0.07797654935466239,
      "loss": 2.9832,
      "step": 137040
    },
    {
      "epoch": 220.35,
      "learning_rate": 0.07797333392379421,
      "loss": 2.9975,
      "step": 137060
    },
    {
      "epoch": 220.39,
      "learning_rate": 0.07797011849292605,
      "loss": 2.9966,
      "step": 137080
    },
    {
      "epoch": 220.42,
      "learning_rate": 0.07796690306205788,
      "loss": 2.9662,
      "step": 137100
    },
    {
      "epoch": 220.45,
      "learning_rate": 0.07796368763118972,
      "loss": 2.9877,
      "step": 137120
    },
    {
      "epoch": 220.48,
      "learning_rate": 0.07796047220032155,
      "loss": 2.9647,
      "step": 137140
    },
    {
      "epoch": 220.51,
      "learning_rate": 0.07795725676945338,
      "loss": 3.0003,
      "step": 137160
    },
    {
      "epoch": 220.55,
      "learning_rate": 0.07795404133858522,
      "loss": 2.9952,
      "step": 137180
    },
    {
      "epoch": 220.58,
      "learning_rate": 0.07795082590771704,
      "loss": 2.9902,
      "step": 137200
    },
    {
      "epoch": 220.61,
      "learning_rate": 0.07794761047684888,
      "loss": 2.9876,
      "step": 137220
    },
    {
      "epoch": 220.64,
      "learning_rate": 0.0779443950459807,
      "loss": 2.9682,
      "step": 137240
    },
    {
      "epoch": 220.68,
      "learning_rate": 0.07794117961511254,
      "loss": 2.9631,
      "step": 137260
    },
    {
      "epoch": 220.71,
      "learning_rate": 0.07793796418424438,
      "loss": 2.9756,
      "step": 137280
    },
    {
      "epoch": 220.74,
      "learning_rate": 0.0779347487533762,
      "loss": 2.9837,
      "step": 137300
    },
    {
      "epoch": 220.77,
      "learning_rate": 0.07793153332250805,
      "loss": 2.9831,
      "step": 137320
    },
    {
      "epoch": 220.8,
      "learning_rate": 0.07792831789163987,
      "loss": 2.9704,
      "step": 137340
    },
    {
      "epoch": 220.84,
      "learning_rate": 0.07792510246077171,
      "loss": 2.9741,
      "step": 137360
    },
    {
      "epoch": 220.87,
      "learning_rate": 0.07792188702990355,
      "loss": 2.9876,
      "step": 137380
    },
    {
      "epoch": 220.9,
      "learning_rate": 0.07791867159903537,
      "loss": 3.0043,
      "step": 137400
    },
    {
      "epoch": 220.93,
      "learning_rate": 0.07791545616816721,
      "loss": 2.9762,
      "step": 137420
    },
    {
      "epoch": 220.96,
      "learning_rate": 0.07791224073729903,
      "loss": 2.9348,
      "step": 137440
    },
    {
      "epoch": 221.0,
      "learning_rate": 0.07790902530643087,
      "loss": 2.9303,
      "step": 137460
    },
    {
      "epoch": 221.0,
      "eval_accuracy": {
        "accuracy": 0.3822591930342844
      },
      "eval_loss": 3.0187301635742188,
      "eval_runtime": 2.9835,
      "eval_samples_per_second": 4311.401,
      "eval_steps_per_second": 67.371,
      "step": 137462
    },
    {
      "epoch": 221.03,
      "learning_rate": 0.07790580987556271,
      "loss": 2.9626,
      "step": 137480
    },
    {
      "epoch": 221.06,
      "learning_rate": 0.07790259444469454,
      "loss": 2.9707,
      "step": 137500
    },
    {
      "epoch": 221.09,
      "learning_rate": 0.07789937901382638,
      "loss": 2.9895,
      "step": 137520
    },
    {
      "epoch": 221.13,
      "learning_rate": 0.0778961635829582,
      "loss": 2.9713,
      "step": 137540
    },
    {
      "epoch": 221.16,
      "learning_rate": 0.07789294815209004,
      "loss": 2.9759,
      "step": 137560
    },
    {
      "epoch": 221.19,
      "learning_rate": 0.07788973272122186,
      "loss": 2.9799,
      "step": 137580
    },
    {
      "epoch": 221.22,
      "learning_rate": 0.0778865172903537,
      "loss": 2.9791,
      "step": 137600
    },
    {
      "epoch": 221.25,
      "learning_rate": 0.07788330185948554,
      "loss": 2.9244,
      "step": 137620
    },
    {
      "epoch": 221.29,
      "learning_rate": 0.07788008642861736,
      "loss": 2.9355,
      "step": 137640
    },
    {
      "epoch": 221.32,
      "learning_rate": 0.0778768709977492,
      "loss": 2.9145,
      "step": 137660
    },
    {
      "epoch": 221.35,
      "learning_rate": 0.07787365556688103,
      "loss": 2.9314,
      "step": 137680
    },
    {
      "epoch": 221.38,
      "learning_rate": 0.07787044013601287,
      "loss": 2.9839,
      "step": 137700
    },
    {
      "epoch": 221.41,
      "learning_rate": 0.0778672247051447,
      "loss": 2.9551,
      "step": 137720
    },
    {
      "epoch": 221.45,
      "learning_rate": 0.07786400927427653,
      "loss": 2.9354,
      "step": 137740
    },
    {
      "epoch": 221.48,
      "learning_rate": 0.07786079384340837,
      "loss": 2.9748,
      "step": 137760
    },
    {
      "epoch": 221.51,
      "learning_rate": 0.0778575784125402,
      "loss": 2.962,
      "step": 137780
    },
    {
      "epoch": 221.54,
      "learning_rate": 0.07785436298167203,
      "loss": 2.9461,
      "step": 137800
    },
    {
      "epoch": 221.58,
      "learning_rate": 0.07785114755080387,
      "loss": 2.9835,
      "step": 137820
    },
    {
      "epoch": 221.61,
      "learning_rate": 0.0778479321199357,
      "loss": 2.9632,
      "step": 137840
    },
    {
      "epoch": 221.64,
      "learning_rate": 0.07784471668906753,
      "loss": 2.9675,
      "step": 137860
    },
    {
      "epoch": 221.67,
      "learning_rate": 0.07784150125819936,
      "loss": 2.9505,
      "step": 137880
    },
    {
      "epoch": 221.7,
      "learning_rate": 0.0778382858273312,
      "loss": 2.9572,
      "step": 137900
    },
    {
      "epoch": 221.74,
      "learning_rate": 0.07783507039646302,
      "loss": 3.0023,
      "step": 137920
    },
    {
      "epoch": 221.77,
      "learning_rate": 0.07783185496559486,
      "loss": 2.9596,
      "step": 137940
    },
    {
      "epoch": 221.8,
      "learning_rate": 0.0778286395347267,
      "loss": 2.969,
      "step": 137960
    },
    {
      "epoch": 221.83,
      "learning_rate": 0.07782542410385852,
      "loss": 2.9743,
      "step": 137980
    },
    {
      "epoch": 221.86,
      "learning_rate": 0.07782220867299036,
      "loss": 2.9834,
      "step": 138000
    },
    {
      "epoch": 221.9,
      "learning_rate": 0.07781899324212219,
      "loss": 2.937,
      "step": 138020
    },
    {
      "epoch": 221.93,
      "learning_rate": 0.07781577781125402,
      "loss": 2.9605,
      "step": 138040
    },
    {
      "epoch": 221.96,
      "learning_rate": 0.07781256238038586,
      "loss": 2.9836,
      "step": 138060
    },
    {
      "epoch": 221.99,
      "learning_rate": 0.07780934694951769,
      "loss": 2.9746,
      "step": 138080
    },
    {
      "epoch": 222.0,
      "eval_accuracy": {
        "accuracy": 0.379693695094457
      },
      "eval_loss": 3.080843210220337,
      "eval_runtime": 2.8568,
      "eval_samples_per_second": 4502.626,
      "eval_steps_per_second": 70.359,
      "step": 138084
    },
    {
      "epoch": 222.03,
      "learning_rate": 0.07780613151864953,
      "loss": 2.9797,
      "step": 138100
    },
    {
      "epoch": 222.06,
      "learning_rate": 0.07780291608778135,
      "loss": 2.9705,
      "step": 138120
    },
    {
      "epoch": 222.09,
      "learning_rate": 0.07779970065691319,
      "loss": 2.9443,
      "step": 138140
    },
    {
      "epoch": 222.12,
      "learning_rate": 0.07779648522604503,
      "loss": 2.9449,
      "step": 138160
    },
    {
      "epoch": 222.15,
      "learning_rate": 0.07779326979517685,
      "loss": 2.9465,
      "step": 138180
    },
    {
      "epoch": 222.19,
      "learning_rate": 0.07779005436430869,
      "loss": 2.9416,
      "step": 138200
    },
    {
      "epoch": 222.22,
      "learning_rate": 0.07778683893344052,
      "loss": 2.9816,
      "step": 138220
    },
    {
      "epoch": 222.25,
      "learning_rate": 0.07778362350257235,
      "loss": 2.9689,
      "step": 138240
    },
    {
      "epoch": 222.28,
      "learning_rate": 0.07778040807170418,
      "loss": 2.9576,
      "step": 138260
    },
    {
      "epoch": 222.32,
      "learning_rate": 0.07777719264083602,
      "loss": 2.9486,
      "step": 138280
    },
    {
      "epoch": 222.35,
      "learning_rate": 0.07777397720996786,
      "loss": 2.9443,
      "step": 138300
    },
    {
      "epoch": 222.38,
      "learning_rate": 0.07777076177909968,
      "loss": 2.9625,
      "step": 138320
    },
    {
      "epoch": 222.41,
      "learning_rate": 0.07776754634823152,
      "loss": 2.9344,
      "step": 138340
    },
    {
      "epoch": 222.44,
      "learning_rate": 0.07776433091736334,
      "loss": 2.9572,
      "step": 138360
    },
    {
      "epoch": 222.48,
      "learning_rate": 0.07776111548649518,
      "loss": 2.9563,
      "step": 138380
    },
    {
      "epoch": 222.51,
      "learning_rate": 0.07775790005562702,
      "loss": 2.9543,
      "step": 138400
    },
    {
      "epoch": 222.54,
      "learning_rate": 0.07775468462475885,
      "loss": 2.9299,
      "step": 138420
    },
    {
      "epoch": 222.57,
      "learning_rate": 0.07775146919389068,
      "loss": 2.9703,
      "step": 138440
    },
    {
      "epoch": 222.6,
      "learning_rate": 0.07774825376302251,
      "loss": 2.9596,
      "step": 138460
    },
    {
      "epoch": 222.64,
      "learning_rate": 0.07774503833215435,
      "loss": 2.9457,
      "step": 138480
    },
    {
      "epoch": 222.67,
      "learning_rate": 0.07774182290128619,
      "loss": 2.988,
      "step": 138500
    },
    {
      "epoch": 222.7,
      "learning_rate": 0.07773860747041801,
      "loss": 2.9841,
      "step": 138520
    },
    {
      "epoch": 222.73,
      "learning_rate": 0.07773539203954985,
      "loss": 2.9715,
      "step": 138540
    },
    {
      "epoch": 222.77,
      "learning_rate": 0.07773217660868167,
      "loss": 2.9574,
      "step": 138560
    },
    {
      "epoch": 222.8,
      "learning_rate": 0.07772896117781351,
      "loss": 2.9527,
      "step": 138580
    },
    {
      "epoch": 222.83,
      "learning_rate": 0.07772574574694534,
      "loss": 2.9628,
      "step": 138600
    },
    {
      "epoch": 222.86,
      "learning_rate": 0.07772253031607716,
      "loss": 2.9614,
      "step": 138620
    },
    {
      "epoch": 222.89,
      "learning_rate": 0.07771931488520901,
      "loss": 2.9765,
      "step": 138640
    },
    {
      "epoch": 222.93,
      "learning_rate": 0.07771609945434084,
      "loss": 2.9593,
      "step": 138660
    },
    {
      "epoch": 222.96,
      "learning_rate": 0.07771288402347268,
      "loss": 2.943,
      "step": 138680
    },
    {
      "epoch": 222.99,
      "learning_rate": 0.0777096685926045,
      "loss": 2.967,
      "step": 138700
    },
    {
      "epoch": 223.0,
      "eval_accuracy": {
        "accuracy": 0.38381404027054344
      },
      "eval_loss": 3.0750622749328613,
      "eval_runtime": 2.842,
      "eval_samples_per_second": 4525.963,
      "eval_steps_per_second": 70.724,
      "step": 138706
    },
    {
      "epoch": 223.02,
      "learning_rate": 0.07770645316173634,
      "loss": 2.9735,
      "step": 138720
    },
    {
      "epoch": 223.05,
      "learning_rate": 0.07770323773086818,
      "loss": 2.9818,
      "step": 138740
    },
    {
      "epoch": 223.09,
      "learning_rate": 0.0777000223,
      "loss": 3.0059,
      "step": 138760
    },
    {
      "epoch": 223.12,
      "learning_rate": 0.07769680686913184,
      "loss": 2.9645,
      "step": 138780
    },
    {
      "epoch": 223.15,
      "learning_rate": 0.07769375220980708,
      "loss": 2.9856,
      "step": 138800
    },
    {
      "epoch": 223.18,
      "learning_rate": 0.07769053677893892,
      "loss": 2.9875,
      "step": 138820
    },
    {
      "epoch": 223.22,
      "learning_rate": 0.07768732134807074,
      "loss": 2.9953,
      "step": 138840
    },
    {
      "epoch": 223.25,
      "learning_rate": 0.07768410591720258,
      "loss": 2.9257,
      "step": 138860
    },
    {
      "epoch": 223.28,
      "learning_rate": 0.0776808904863344,
      "loss": 2.9326,
      "step": 138880
    },
    {
      "epoch": 223.31,
      "learning_rate": 0.07767767505546624,
      "loss": 2.9821,
      "step": 138900
    },
    {
      "epoch": 223.34,
      "learning_rate": 0.07767445962459808,
      "loss": 2.9658,
      "step": 138920
    },
    {
      "epoch": 223.38,
      "learning_rate": 0.07767124419372991,
      "loss": 2.93,
      "step": 138940
    },
    {
      "epoch": 223.41,
      "learning_rate": 0.07766802876286173,
      "loss": 2.9843,
      "step": 138960
    },
    {
      "epoch": 223.44,
      "learning_rate": 0.07766481333199357,
      "loss": 2.9568,
      "step": 138980
    },
    {
      "epoch": 223.47,
      "learning_rate": 0.07766159790112541,
      "loss": 2.9582,
      "step": 139000
    },
    {
      "epoch": 223.5,
      "learning_rate": 0.07765838247025725,
      "loss": 2.9288,
      "step": 139020
    },
    {
      "epoch": 223.54,
      "learning_rate": 0.07765516703938907,
      "loss": 2.9323,
      "step": 139040
    },
    {
      "epoch": 223.57,
      "learning_rate": 0.0776519516085209,
      "loss": 2.9255,
      "step": 139060
    },
    {
      "epoch": 223.6,
      "learning_rate": 0.07764873617765274,
      "loss": 2.9354,
      "step": 139080
    },
    {
      "epoch": 223.63,
      "learning_rate": 0.07764552074678457,
      "loss": 2.953,
      "step": 139100
    },
    {
      "epoch": 223.67,
      "learning_rate": 0.07764230531591641,
      "loss": 2.9759,
      "step": 139120
    },
    {
      "epoch": 223.7,
      "learning_rate": 0.07763908988504824,
      "loss": 3.0124,
      "step": 139140
    },
    {
      "epoch": 223.73,
      "learning_rate": 0.07763587445418006,
      "loss": 2.9537,
      "step": 139160
    },
    {
      "epoch": 223.76,
      "learning_rate": 0.0776326590233119,
      "loss": 2.9323,
      "step": 139180
    },
    {
      "epoch": 223.79,
      "learning_rate": 0.07762944359244374,
      "loss": 2.9737,
      "step": 139200
    },
    {
      "epoch": 223.83,
      "learning_rate": 0.07762622816157556,
      "loss": 2.9497,
      "step": 139220
    },
    {
      "epoch": 223.86,
      "learning_rate": 0.0776230127307074,
      "loss": 2.9612,
      "step": 139240
    },
    {
      "epoch": 223.89,
      "learning_rate": 0.07761979729983923,
      "loss": 2.9615,
      "step": 139260
    },
    {
      "epoch": 223.92,
      "learning_rate": 0.07761658186897107,
      "loss": 2.9493,
      "step": 139280
    },
    {
      "epoch": 223.95,
      "learning_rate": 0.07761336643810289,
      "loss": 2.9293,
      "step": 139300
    },
    {
      "epoch": 223.99,
      "learning_rate": 0.07761015100723473,
      "loss": 2.9479,
      "step": 139320
    },
    {
      "epoch": 224.0,
      "eval_accuracy": {
        "accuracy": 0.38085983052165123
      },
      "eval_loss": 3.0447893142700195,
      "eval_runtime": 2.639,
      "eval_samples_per_second": 4874.207,
      "eval_steps_per_second": 76.165,
      "step": 139328
    },
    {
      "epoch": 224.02,
      "learning_rate": 0.07760693557636657,
      "loss": 2.9191,
      "step": 139340
    },
    {
      "epoch": 224.05,
      "learning_rate": 0.07760372014549839,
      "loss": 2.9126,
      "step": 139360
    },
    {
      "epoch": 224.08,
      "learning_rate": 0.07760050471463023,
      "loss": 2.9647,
      "step": 139380
    },
    {
      "epoch": 224.12,
      "learning_rate": 0.07759728928376206,
      "loss": 2.9184,
      "step": 139400
    },
    {
      "epoch": 224.15,
      "learning_rate": 0.0775940738528939,
      "loss": 2.9641,
      "step": 139420
    },
    {
      "epoch": 224.18,
      "learning_rate": 0.07759085842202573,
      "loss": 2.9502,
      "step": 139440
    },
    {
      "epoch": 224.21,
      "learning_rate": 0.07758764299115757,
      "loss": 2.9478,
      "step": 139460
    },
    {
      "epoch": 224.24,
      "learning_rate": 0.0775844275602894,
      "loss": 2.9689,
      "step": 139480
    },
    {
      "epoch": 224.28,
      "learning_rate": 0.07758121212942122,
      "loss": 2.9254,
      "step": 139500
    },
    {
      "epoch": 224.31,
      "learning_rate": 0.07757799669855306,
      "loss": 2.9436,
      "step": 139520
    },
    {
      "epoch": 224.34,
      "learning_rate": 0.0775747812676849,
      "loss": 3.0003,
      "step": 139540
    },
    {
      "epoch": 224.37,
      "learning_rate": 0.07757156583681672,
      "loss": 2.9903,
      "step": 139560
    },
    {
      "epoch": 224.41,
      "learning_rate": 0.07756835040594856,
      "loss": 2.9783,
      "step": 139580
    },
    {
      "epoch": 224.44,
      "learning_rate": 0.07756513497508039,
      "loss": 2.9459,
      "step": 139600
    },
    {
      "epoch": 224.47,
      "learning_rate": 0.07756191954421222,
      "loss": 2.9883,
      "step": 139620
    },
    {
      "epoch": 224.5,
      "learning_rate": 0.07755870411334405,
      "loss": 2.945,
      "step": 139640
    },
    {
      "epoch": 224.53,
      "learning_rate": 0.07755548868247589,
      "loss": 2.9521,
      "step": 139660
    },
    {
      "epoch": 224.57,
      "learning_rate": 0.07755227325160773,
      "loss": 2.9761,
      "step": 139680
    },
    {
      "epoch": 224.6,
      "learning_rate": 0.07754905782073955,
      "loss": 2.9752,
      "step": 139700
    },
    {
      "epoch": 224.63,
      "learning_rate": 0.07754584238987139,
      "loss": 2.9648,
      "step": 139720
    },
    {
      "epoch": 224.66,
      "learning_rate": 0.07754262695900321,
      "loss": 2.9388,
      "step": 139740
    },
    {
      "epoch": 224.69,
      "learning_rate": 0.07753941152813505,
      "loss": 2.9524,
      "step": 139760
    },
    {
      "epoch": 224.73,
      "learning_rate": 0.07753619609726689,
      "loss": 2.9441,
      "step": 139780
    },
    {
      "epoch": 224.76,
      "learning_rate": 0.07753298066639872,
      "loss": 2.9167,
      "step": 139800
    },
    {
      "epoch": 224.79,
      "learning_rate": 0.07752976523553055,
      "loss": 2.9425,
      "step": 139820
    },
    {
      "epoch": 224.82,
      "learning_rate": 0.07752654980466238,
      "loss": 2.9531,
      "step": 139840
    },
    {
      "epoch": 224.86,
      "learning_rate": 0.07752333437379422,
      "loss": 2.9517,
      "step": 139860
    },
    {
      "epoch": 224.89,
      "learning_rate": 0.07752011894292606,
      "loss": 2.9691,
      "step": 139880
    },
    {
      "epoch": 224.92,
      "learning_rate": 0.07751690351205788,
      "loss": 2.9756,
      "step": 139900
    },
    {
      "epoch": 224.95,
      "learning_rate": 0.07751368808118972,
      "loss": 2.9361,
      "step": 139920
    },
    {
      "epoch": 224.98,
      "learning_rate": 0.07751047265032154,
      "loss": 2.9421,
      "step": 139940
    },
    {
      "epoch": 225.0,
      "eval_accuracy": {
        "accuracy": 0.374795926300241
      },
      "eval_loss": 3.059412717819214,
      "eval_runtime": 3.1362,
      "eval_samples_per_second": 4101.523,
      "eval_steps_per_second": 64.091,
      "step": 139950
    },
    {
      "epoch": 225.02,
      "learning_rate": 0.07750725721945338,
      "loss": 2.9507,
      "step": 139960
    },
    {
      "epoch": 225.05,
      "learning_rate": 0.0775040417885852,
      "loss": 2.9759,
      "step": 139980
    },
    {
      "epoch": 225.08,
      "learning_rate": 0.07750082635771705,
      "loss": 2.9818,
      "step": 140000
    },
    {
      "epoch": 225.11,
      "learning_rate": 0.07749761092684888,
      "loss": 2.9211,
      "step": 140020
    },
    {
      "epoch": 225.14,
      "learning_rate": 0.07749439549598071,
      "loss": 2.9673,
      "step": 140040
    },
    {
      "epoch": 225.18,
      "learning_rate": 0.07749118006511255,
      "loss": 2.9478,
      "step": 140060
    },
    {
      "epoch": 225.21,
      "learning_rate": 0.07748796463424437,
      "loss": 2.9519,
      "step": 140080
    },
    {
      "epoch": 225.24,
      "learning_rate": 0.07748474920337621,
      "loss": 2.9491,
      "step": 140100
    },
    {
      "epoch": 225.27,
      "learning_rate": 0.07748153377250805,
      "loss": 2.9612,
      "step": 140120
    },
    {
      "epoch": 225.31,
      "learning_rate": 0.07747831834163987,
      "loss": 2.9527,
      "step": 140140
    },
    {
      "epoch": 225.34,
      "learning_rate": 0.07747510291077171,
      "loss": 2.9659,
      "step": 140160
    },
    {
      "epoch": 225.37,
      "learning_rate": 0.07747188747990354,
      "loss": 2.9554,
      "step": 140180
    },
    {
      "epoch": 225.4,
      "learning_rate": 0.07746867204903538,
      "loss": 2.9861,
      "step": 140200
    },
    {
      "epoch": 225.43,
      "learning_rate": 0.07746545661816721,
      "loss": 2.9629,
      "step": 140220
    },
    {
      "epoch": 225.47,
      "learning_rate": 0.07746224118729904,
      "loss": 2.9294,
      "step": 140240
    },
    {
      "epoch": 225.5,
      "learning_rate": 0.07745902575643088,
      "loss": 2.9511,
      "step": 140260
    },
    {
      "epoch": 225.53,
      "learning_rate": 0.0774558103255627,
      "loss": 2.9544,
      "step": 140280
    },
    {
      "epoch": 225.56,
      "learning_rate": 0.07745259489469454,
      "loss": 2.9653,
      "step": 140300
    },
    {
      "epoch": 225.59,
      "learning_rate": 0.07744937946382636,
      "loss": 2.9489,
      "step": 140320
    },
    {
      "epoch": 225.63,
      "learning_rate": 0.0774461640329582,
      "loss": 2.9799,
      "step": 140340
    },
    {
      "epoch": 225.66,
      "learning_rate": 0.07744294860209004,
      "loss": 2.9538,
      "step": 140360
    },
    {
      "epoch": 225.69,
      "learning_rate": 0.07743973317122187,
      "loss": 2.9706,
      "step": 140380
    },
    {
      "epoch": 225.72,
      "learning_rate": 0.0774365177403537,
      "loss": 2.9946,
      "step": 140400
    },
    {
      "epoch": 225.76,
      "learning_rate": 0.07743330230948553,
      "loss": 2.9584,
      "step": 140420
    },
    {
      "epoch": 225.79,
      "learning_rate": 0.07743008687861737,
      "loss": 2.9176,
      "step": 140440
    },
    {
      "epoch": 225.82,
      "learning_rate": 0.07742687144774921,
      "loss": 2.9456,
      "step": 140460
    },
    {
      "epoch": 225.85,
      "learning_rate": 0.07742365601688103,
      "loss": 2.9324,
      "step": 140480
    },
    {
      "epoch": 225.88,
      "learning_rate": 0.07742044058601287,
      "loss": 2.9065,
      "step": 140500
    },
    {
      "epoch": 225.92,
      "learning_rate": 0.0774172251551447,
      "loss": 2.9158,
      "step": 140520
    },
    {
      "epoch": 225.95,
      "learning_rate": 0.07741400972427653,
      "loss": 3.0009,
      "step": 140540
    },
    {
      "epoch": 225.98,
      "learning_rate": 0.07741079429340837,
      "loss": 2.9663,
      "step": 140560
    },
    {
      "epoch": 226.0,
      "eval_accuracy": {
        "accuracy": 0.37961595273264404
      },
      "eval_loss": 3.0519609451293945,
      "eval_runtime": 3.0787,
      "eval_samples_per_second": 4178.092,
      "eval_steps_per_second": 65.288,
      "step": 140572
    },
    {
      "epoch": 226.01,
      "learning_rate": 0.0774075788625402,
      "loss": 2.9649,
      "step": 140580
    },
    {
      "epoch": 226.05,
      "learning_rate": 0.07740436343167204,
      "loss": 2.8989,
      "step": 140600
    },
    {
      "epoch": 226.08,
      "learning_rate": 0.07740114800080386,
      "loss": 2.9278,
      "step": 140620
    },
    {
      "epoch": 226.11,
      "learning_rate": 0.0773979325699357,
      "loss": 2.9785,
      "step": 140640
    },
    {
      "epoch": 226.14,
      "learning_rate": 0.07739471713906752,
      "loss": 2.9612,
      "step": 140660
    },
    {
      "epoch": 226.17,
      "learning_rate": 0.07739150170819936,
      "loss": 2.9675,
      "step": 140680
    },
    {
      "epoch": 226.21,
      "learning_rate": 0.0773882862773312,
      "loss": 2.9193,
      "step": 140700
    },
    {
      "epoch": 226.24,
      "learning_rate": 0.07738507084646302,
      "loss": 2.9889,
      "step": 140720
    },
    {
      "epoch": 226.27,
      "learning_rate": 0.07738185541559486,
      "loss": 2.9874,
      "step": 140740
    },
    {
      "epoch": 226.3,
      "learning_rate": 0.07737863998472669,
      "loss": 2.9433,
      "step": 140760
    },
    {
      "epoch": 226.33,
      "learning_rate": 0.07737542455385853,
      "loss": 2.9569,
      "step": 140780
    },
    {
      "epoch": 226.37,
      "learning_rate": 0.07737220912299037,
      "loss": 2.9218,
      "step": 140800
    },
    {
      "epoch": 226.4,
      "learning_rate": 0.07736899369212219,
      "loss": 2.9152,
      "step": 140820
    },
    {
      "epoch": 226.43,
      "learning_rate": 0.07736577826125403,
      "loss": 2.9234,
      "step": 140840
    },
    {
      "epoch": 226.46,
      "learning_rate": 0.07736256283038585,
      "loss": 2.9757,
      "step": 140860
    },
    {
      "epoch": 226.5,
      "learning_rate": 0.07735934739951769,
      "loss": 2.976,
      "step": 140880
    },
    {
      "epoch": 226.53,
      "learning_rate": 0.07735613196864953,
      "loss": 2.9432,
      "step": 140900
    },
    {
      "epoch": 226.56,
      "learning_rate": 0.07735291653778135,
      "loss": 2.9502,
      "step": 140920
    },
    {
      "epoch": 226.59,
      "learning_rate": 0.07734986187845659,
      "loss": 2.946,
      "step": 140940
    },
    {
      "epoch": 226.62,
      "learning_rate": 0.07734664644758843,
      "loss": 2.9411,
      "step": 140960
    },
    {
      "epoch": 226.66,
      "learning_rate": 0.07734343101672027,
      "loss": 2.9511,
      "step": 140980
    },
    {
      "epoch": 226.69,
      "learning_rate": 0.07734021558585209,
      "loss": 2.9555,
      "step": 141000
    },
    {
      "epoch": 226.72,
      "learning_rate": 0.07733700015498393,
      "loss": 2.9533,
      "step": 141020
    },
    {
      "epoch": 226.75,
      "learning_rate": 0.07733378472411576,
      "loss": 2.9508,
      "step": 141040
    },
    {
      "epoch": 226.78,
      "learning_rate": 0.0773305692932476,
      "loss": 2.9488,
      "step": 141060
    },
    {
      "epoch": 226.82,
      "learning_rate": 0.07732735386237943,
      "loss": 3.0056,
      "step": 141080
    },
    {
      "epoch": 226.85,
      "learning_rate": 0.07732413843151126,
      "loss": 2.9716,
      "step": 141100
    },
    {
      "epoch": 226.88,
      "learning_rate": 0.0773209230006431,
      "loss": 2.9175,
      "step": 141120
    },
    {
      "epoch": 226.91,
      "learning_rate": 0.07731770756977492,
      "loss": 2.9822,
      "step": 141140
    },
    {
      "epoch": 226.95,
      "learning_rate": 0.07731449213890676,
      "loss": 2.9296,
      "step": 141160
    },
    {
      "epoch": 226.98,
      "learning_rate": 0.0773112767080386,
      "loss": 2.9355,
      "step": 141180
    },
    {
      "epoch": 227.0,
      "eval_accuracy": {
        "accuracy": 0.3793049832853922
      },
      "eval_loss": 3.0549092292785645,
      "eval_runtime": 2.8755,
      "eval_samples_per_second": 4473.369,
      "eval_steps_per_second": 69.902,
      "step": 141194
    },
    {
      "epoch": 227.01,
      "learning_rate": 0.07730806127717042,
      "loss": 2.9318,
      "step": 141200
    },
    {
      "epoch": 227.04,
      "learning_rate": 0.07730484584630226,
      "loss": 2.9404,
      "step": 141220
    },
    {
      "epoch": 227.07,
      "learning_rate": 0.07730163041543409,
      "loss": 2.9375,
      "step": 141240
    },
    {
      "epoch": 227.11,
      "learning_rate": 0.07729841498456592,
      "loss": 2.9558,
      "step": 141260
    },
    {
      "epoch": 227.14,
      "learning_rate": 0.07729519955369775,
      "loss": 2.9743,
      "step": 141280
    },
    {
      "epoch": 227.17,
      "learning_rate": 0.07729198412282959,
      "loss": 2.9678,
      "step": 141300
    },
    {
      "epoch": 227.2,
      "learning_rate": 0.07728876869196143,
      "loss": 2.9517,
      "step": 141320
    },
    {
      "epoch": 227.23,
      "learning_rate": 0.07728555326109325,
      "loss": 2.9561,
      "step": 141340
    },
    {
      "epoch": 227.27,
      "learning_rate": 0.07728233783022508,
      "loss": 2.9667,
      "step": 141360
    },
    {
      "epoch": 227.3,
      "learning_rate": 0.07727912239935691,
      "loss": 2.9373,
      "step": 141380
    },
    {
      "epoch": 227.33,
      "learning_rate": 0.07727590696848875,
      "loss": 2.9178,
      "step": 141400
    },
    {
      "epoch": 227.36,
      "learning_rate": 0.07727269153762059,
      "loss": 2.9538,
      "step": 141420
    },
    {
      "epoch": 227.4,
      "learning_rate": 0.07726947610675242,
      "loss": 2.9529,
      "step": 141440
    },
    {
      "epoch": 227.43,
      "learning_rate": 0.07726626067588424,
      "loss": 2.9395,
      "step": 141460
    },
    {
      "epoch": 227.46,
      "learning_rate": 0.07726304524501608,
      "loss": 2.9622,
      "step": 141480
    },
    {
      "epoch": 227.49,
      "learning_rate": 0.07725982981414792,
      "loss": 2.9578,
      "step": 141500
    },
    {
      "epoch": 227.52,
      "learning_rate": 0.07725661438327976,
      "loss": 2.95,
      "step": 141520
    },
    {
      "epoch": 227.56,
      "learning_rate": 0.07725339895241158,
      "loss": 2.935,
      "step": 141540
    },
    {
      "epoch": 227.59,
      "learning_rate": 0.0772501835215434,
      "loss": 2.9958,
      "step": 141560
    },
    {
      "epoch": 227.62,
      "learning_rate": 0.07724696809067524,
      "loss": 2.956,
      "step": 141580
    },
    {
      "epoch": 227.65,
      "learning_rate": 0.07724375265980708,
      "loss": 2.9362,
      "step": 141600
    },
    {
      "epoch": 227.68,
      "learning_rate": 0.07724053722893891,
      "loss": 2.9678,
      "step": 141620
    },
    {
      "epoch": 227.72,
      "learning_rate": 0.07723732179807075,
      "loss": 2.9461,
      "step": 141640
    },
    {
      "epoch": 227.75,
      "learning_rate": 0.07723410636720258,
      "loss": 2.9539,
      "step": 141660
    },
    {
      "epoch": 227.78,
      "learning_rate": 0.07723089093633441,
      "loss": 2.9392,
      "step": 141680
    },
    {
      "epoch": 227.81,
      "learning_rate": 0.07722767550546623,
      "loss": 2.9927,
      "step": 141700
    },
    {
      "epoch": 227.85,
      "learning_rate": 0.07722446007459807,
      "loss": 2.9851,
      "step": 141720
    },
    {
      "epoch": 227.88,
      "learning_rate": 0.07722124464372991,
      "loss": 2.9659,
      "step": 141740
    },
    {
      "epoch": 227.91,
      "learning_rate": 0.07721802921286175,
      "loss": 2.9682,
      "step": 141760
    },
    {
      "epoch": 227.94,
      "learning_rate": 0.07721481378199357,
      "loss": 2.9693,
      "step": 141780
    },
    {
      "epoch": 227.97,
      "learning_rate": 0.0772115983511254,
      "loss": 2.9753,
      "step": 141800
    },
    {
      "epoch": 228.0,
      "eval_accuracy": {
        "accuracy": 0.37114203529503226
      },
      "eval_loss": 3.104822874069214,
      "eval_runtime": 2.6202,
      "eval_samples_per_second": 4909.162,
      "eval_steps_per_second": 76.712,
      "step": 141816
    },
    {
      "epoch": 228.01,
      "learning_rate": 0.07720838292025724,
      "loss": 2.9743,
      "step": 141820
    },
    {
      "epoch": 228.04,
      "learning_rate": 0.07720516748938908,
      "loss": 3.0207,
      "step": 141840
    },
    {
      "epoch": 228.07,
      "learning_rate": 0.07720195205852091,
      "loss": 2.9902,
      "step": 141860
    },
    {
      "epoch": 228.1,
      "learning_rate": 0.07719873662765274,
      "loss": 2.9752,
      "step": 141880
    },
    {
      "epoch": 228.14,
      "learning_rate": 0.07719552119678456,
      "loss": 2.987,
      "step": 141900
    },
    {
      "epoch": 228.17,
      "learning_rate": 0.0771923057659164,
      "loss": 2.9486,
      "step": 141920
    },
    {
      "epoch": 228.2,
      "learning_rate": 0.07718909033504824,
      "loss": 2.9342,
      "step": 141940
    },
    {
      "epoch": 228.23,
      "learning_rate": 0.07718587490418007,
      "loss": 2.9526,
      "step": 141960
    },
    {
      "epoch": 228.26,
      "learning_rate": 0.0771826594733119,
      "loss": 2.9512,
      "step": 141980
    },
    {
      "epoch": 228.3,
      "learning_rate": 0.07717944404244373,
      "loss": 2.9448,
      "step": 142000
    },
    {
      "epoch": 228.33,
      "learning_rate": 0.07717622861157557,
      "loss": 2.9509,
      "step": 142020
    },
    {
      "epoch": 228.36,
      "learning_rate": 0.07717301318070739,
      "loss": 2.9666,
      "step": 142040
    },
    {
      "epoch": 228.39,
      "learning_rate": 0.07716979774983923,
      "loss": 2.9549,
      "step": 142060
    },
    {
      "epoch": 228.42,
      "learning_rate": 0.07716658231897107,
      "loss": 2.9476,
      "step": 142080
    },
    {
      "epoch": 228.46,
      "learning_rate": 0.0771633668881029,
      "loss": 2.9387,
      "step": 142100
    },
    {
      "epoch": 228.49,
      "learning_rate": 0.07716015145723473,
      "loss": 2.9417,
      "step": 142120
    },
    {
      "epoch": 228.52,
      "learning_rate": 0.07715693602636656,
      "loss": 2.9463,
      "step": 142140
    },
    {
      "epoch": 228.55,
      "learning_rate": 0.0771537205954984,
      "loss": 2.946,
      "step": 142160
    },
    {
      "epoch": 228.59,
      "learning_rate": 0.07715050516463023,
      "loss": 2.9378,
      "step": 142180
    },
    {
      "epoch": 228.62,
      "learning_rate": 0.07714728973376206,
      "loss": 2.9591,
      "step": 142200
    },
    {
      "epoch": 228.65,
      "learning_rate": 0.0771440743028939,
      "loss": 2.9507,
      "step": 142220
    },
    {
      "epoch": 228.68,
      "learning_rate": 0.07714085887202572,
      "loss": 2.9362,
      "step": 142240
    },
    {
      "epoch": 228.71,
      "learning_rate": 0.07713764344115756,
      "loss": 2.9615,
      "step": 142260
    },
    {
      "epoch": 228.75,
      "learning_rate": 0.0771344280102894,
      "loss": 2.9856,
      "step": 142280
    },
    {
      "epoch": 228.78,
      "learning_rate": 0.07713121257942122,
      "loss": 2.9778,
      "step": 142300
    },
    {
      "epoch": 228.81,
      "learning_rate": 0.07712799714855306,
      "loss": 2.9436,
      "step": 142320
    },
    {
      "epoch": 228.84,
      "learning_rate": 0.07712478171768489,
      "loss": 2.9516,
      "step": 142340
    },
    {
      "epoch": 228.87,
      "learning_rate": 0.07712156628681673,
      "loss": 2.9445,
      "step": 142360
    },
    {
      "epoch": 228.91,
      "learning_rate": 0.07711835085594855,
      "loss": 2.9706,
      "step": 142380
    },
    {
      "epoch": 228.94,
      "learning_rate": 0.07711513542508039,
      "loss": 2.9697,
      "step": 142400
    },
    {
      "epoch": 228.97,
      "learning_rate": 0.07711191999421223,
      "loss": 2.9401,
      "step": 142420
    },
    {
      "epoch": 229.0,
      "eval_accuracy": {
        "accuracy": 0.37681722770737774
      },
      "eval_loss": 3.0455873012542725,
      "eval_runtime": 2.5916,
      "eval_samples_per_second": 4963.324,
      "eval_steps_per_second": 77.558,
      "step": 142438
    },
    {
      "epoch": 229.0,
      "learning_rate": 0.07710870456334405,
      "loss": 2.9426,
      "step": 142440
    },
    {
      "epoch": 229.04,
      "learning_rate": 0.07710548913247589,
      "loss": 2.9509,
      "step": 142460
    },
    {
      "epoch": 229.07,
      "learning_rate": 0.07710227370160772,
      "loss": 2.9293,
      "step": 142480
    },
    {
      "epoch": 229.1,
      "learning_rate": 0.07709905827073955,
      "loss": 2.9849,
      "step": 142500
    },
    {
      "epoch": 229.13,
      "learning_rate": 0.07709584283987139,
      "loss": 2.9757,
      "step": 142520
    },
    {
      "epoch": 229.16,
      "learning_rate": 0.07709262740900322,
      "loss": 2.9623,
      "step": 142540
    },
    {
      "epoch": 229.2,
      "learning_rate": 0.07708941197813506,
      "loss": 2.9399,
      "step": 142560
    },
    {
      "epoch": 229.23,
      "learning_rate": 0.07708619654726688,
      "loss": 2.9271,
      "step": 142580
    },
    {
      "epoch": 229.26,
      "learning_rate": 0.07708298111639872,
      "loss": 2.901,
      "step": 142600
    },
    {
      "epoch": 229.29,
      "learning_rate": 0.07707976568553056,
      "loss": 2.9332,
      "step": 142620
    },
    {
      "epoch": 229.32,
      "learning_rate": 0.07707655025466238,
      "loss": 2.9339,
      "step": 142640
    },
    {
      "epoch": 229.36,
      "learning_rate": 0.07707333482379422,
      "loss": 2.9353,
      "step": 142660
    },
    {
      "epoch": 229.39,
      "learning_rate": 0.07707011939292605,
      "loss": 2.9206,
      "step": 142680
    },
    {
      "epoch": 229.42,
      "learning_rate": 0.07706690396205788,
      "loss": 2.9752,
      "step": 142700
    },
    {
      "epoch": 229.45,
      "learning_rate": 0.07706368853118971,
      "loss": 3.0049,
      "step": 142720
    },
    {
      "epoch": 229.49,
      "learning_rate": 0.07706047310032155,
      "loss": 2.9648,
      "step": 142740
    },
    {
      "epoch": 229.52,
      "learning_rate": 0.07705725766945339,
      "loss": 2.9884,
      "step": 142760
    },
    {
      "epoch": 229.55,
      "learning_rate": 0.07705404223858521,
      "loss": 2.9833,
      "step": 142780
    },
    {
      "epoch": 229.58,
      "learning_rate": 0.07705082680771705,
      "loss": 2.9728,
      "step": 142800
    },
    {
      "epoch": 229.61,
      "learning_rate": 0.07704761137684887,
      "loss": 2.9363,
      "step": 142820
    },
    {
      "epoch": 229.65,
      "learning_rate": 0.07704439594598071,
      "loss": 2.9503,
      "step": 142840
    },
    {
      "epoch": 229.68,
      "learning_rate": 0.07704118051511255,
      "loss": 2.9301,
      "step": 142860
    },
    {
      "epoch": 229.71,
      "learning_rate": 0.07703796508424438,
      "loss": 2.9911,
      "step": 142880
    },
    {
      "epoch": 229.74,
      "learning_rate": 0.07703474965337621,
      "loss": 2.935,
      "step": 142900
    },
    {
      "epoch": 229.77,
      "learning_rate": 0.07703153422250804,
      "loss": 2.9408,
      "step": 142920
    },
    {
      "epoch": 229.81,
      "learning_rate": 0.07702831879163988,
      "loss": 2.9254,
      "step": 142940
    },
    {
      "epoch": 229.84,
      "learning_rate": 0.07702526413231511,
      "loss": 2.9651,
      "step": 142960
    },
    {
      "epoch": 229.87,
      "learning_rate": 0.07702204870144695,
      "loss": 2.9402,
      "step": 142980
    },
    {
      "epoch": 229.9,
      "learning_rate": 0.07701883327057878,
      "loss": 2.9721,
      "step": 143000
    },
    {
      "epoch": 229.94,
      "learning_rate": 0.07701561783971062,
      "loss": 2.9638,
      "step": 143020
    },
    {
      "epoch": 229.97,
      "learning_rate": 0.07701240240884245,
      "loss": 2.9775,
      "step": 143040
    },
    {
      "epoch": 230.0,
      "learning_rate": 0.07700918697797428,
      "loss": 2.9702,
      "step": 143060
    },
    {
      "epoch": 230.0,
      "eval_accuracy": {
        "accuracy": 0.3814040270543419
      },
      "eval_loss": 3.021005630493164,
      "eval_runtime": 3.1616,
      "eval_samples_per_second": 4068.447,
      "eval_steps_per_second": 63.574,
      "step": 143060
    },
    {
      "epoch": 230.03,
      "learning_rate": 0.07700597154710612,
      "loss": 2.9747,
      "step": 143080
    },
    {
      "epoch": 230.06,
      "learning_rate": 0.07700275611623794,
      "loss": 2.9613,
      "step": 143100
    },
    {
      "epoch": 230.1,
      "learning_rate": 0.07699954068536978,
      "loss": 2.9396,
      "step": 143120
    },
    {
      "epoch": 230.13,
      "learning_rate": 0.07699632525450162,
      "loss": 2.9115,
      "step": 143140
    },
    {
      "epoch": 230.16,
      "learning_rate": 0.07699310982363344,
      "loss": 3.0005,
      "step": 143160
    },
    {
      "epoch": 230.19,
      "learning_rate": 0.07698989439276528,
      "loss": 2.9936,
      "step": 143180
    },
    {
      "epoch": 230.23,
      "learning_rate": 0.0769866789618971,
      "loss": 3.0142,
      "step": 143200
    },
    {
      "epoch": 230.26,
      "learning_rate": 0.07698346353102895,
      "loss": 2.9595,
      "step": 143220
    },
    {
      "epoch": 230.29,
      "learning_rate": 0.07698024810016078,
      "loss": 2.9331,
      "step": 143240
    },
    {
      "epoch": 230.32,
      "learning_rate": 0.07697703266929261,
      "loss": 2.9446,
      "step": 143260
    },
    {
      "epoch": 230.35,
      "learning_rate": 0.07697381723842445,
      "loss": 2.9244,
      "step": 143280
    },
    {
      "epoch": 230.39,
      "learning_rate": 0.07697060180755627,
      "loss": 2.936,
      "step": 143300
    },
    {
      "epoch": 230.42,
      "learning_rate": 0.07696738637668811,
      "loss": 2.9541,
      "step": 143320
    },
    {
      "epoch": 230.45,
      "learning_rate": 0.07696417094581993,
      "loss": 2.9425,
      "step": 143340
    },
    {
      "epoch": 230.48,
      "learning_rate": 0.07696095551495177,
      "loss": 2.9301,
      "step": 143360
    },
    {
      "epoch": 230.51,
      "learning_rate": 0.07695774008408361,
      "loss": 2.9336,
      "step": 143380
    },
    {
      "epoch": 230.55,
      "learning_rate": 0.07695452465321544,
      "loss": 2.9538,
      "step": 143400
    },
    {
      "epoch": 230.58,
      "learning_rate": 0.07695130922234727,
      "loss": 2.9579,
      "step": 143420
    },
    {
      "epoch": 230.61,
      "learning_rate": 0.0769480937914791,
      "loss": 2.9715,
      "step": 143440
    },
    {
      "epoch": 230.64,
      "learning_rate": 0.07694487836061094,
      "loss": 2.9576,
      "step": 143460
    },
    {
      "epoch": 230.68,
      "learning_rate": 0.07694166292974278,
      "loss": 2.9282,
      "step": 143480
    },
    {
      "epoch": 230.71,
      "learning_rate": 0.0769384474988746,
      "loss": 2.9274,
      "step": 143500
    },
    {
      "epoch": 230.74,
      "learning_rate": 0.07693523206800644,
      "loss": 2.9434,
      "step": 143520
    },
    {
      "epoch": 230.77,
      "learning_rate": 0.07693201663713826,
      "loss": 2.902,
      "step": 143540
    },
    {
      "epoch": 230.8,
      "learning_rate": 0.0769288012062701,
      "loss": 2.9458,
      "step": 143560
    },
    {
      "epoch": 230.84,
      "learning_rate": 0.07692558577540194,
      "loss": 2.9732,
      "step": 143580
    },
    {
      "epoch": 230.87,
      "learning_rate": 0.07692237034453377,
      "loss": 2.9204,
      "step": 143600
    },
    {
      "epoch": 230.9,
      "learning_rate": 0.0769191549136656,
      "loss": 2.9478,
      "step": 143620
    },
    {
      "epoch": 230.93,
      "learning_rate": 0.07691593948279743,
      "loss": 2.9591,
      "step": 143640
    },
    {
      "epoch": 230.96,
      "learning_rate": 0.07691272405192927,
      "loss": 2.9635,
      "step": 143660
    },
    {
      "epoch": 231.0,
      "learning_rate": 0.07690950862106109,
      "loss": 2.9607,
      "step": 143680
    },
    {
      "epoch": 231.0,
      "eval_accuracy": {
        "accuracy": 0.36880976444064373
      },
      "eval_loss": 3.069671154022217,
      "eval_runtime": 2.7135,
      "eval_samples_per_second": 4740.294,
      "eval_steps_per_second": 74.073,
      "step": 143682
    },
    {
      "epoch": 231.03,
      "learning_rate": 0.07690629319019293,
      "loss": 2.969,
      "step": 143700
    },
    {
      "epoch": 231.06,
      "learning_rate": 0.07690307775932477,
      "loss": 2.9147,
      "step": 143720
    },
    {
      "epoch": 231.09,
      "learning_rate": 0.0768998623284566,
      "loss": 2.886,
      "step": 143740
    },
    {
      "epoch": 231.13,
      "learning_rate": 0.07689664689758842,
      "loss": 2.9322,
      "step": 143760
    },
    {
      "epoch": 231.16,
      "learning_rate": 0.07689343146672026,
      "loss": 2.9567,
      "step": 143780
    },
    {
      "epoch": 231.19,
      "learning_rate": 0.0768902160358521,
      "loss": 2.9602,
      "step": 143800
    },
    {
      "epoch": 231.22,
      "learning_rate": 0.07688700060498393,
      "loss": 2.9496,
      "step": 143820
    },
    {
      "epoch": 231.25,
      "learning_rate": 0.07688378517411576,
      "loss": 2.9434,
      "step": 143840
    },
    {
      "epoch": 231.29,
      "learning_rate": 0.0768805697432476,
      "loss": 2.9713,
      "step": 143860
    },
    {
      "epoch": 231.32,
      "learning_rate": 0.07687735431237942,
      "loss": 2.9665,
      "step": 143880
    },
    {
      "epoch": 231.35,
      "learning_rate": 0.07687413888151126,
      "loss": 2.9533,
      "step": 143900
    },
    {
      "epoch": 231.38,
      "learning_rate": 0.0768709234506431,
      "loss": 2.9471,
      "step": 143920
    },
    {
      "epoch": 231.41,
      "learning_rate": 0.07686770801977492,
      "loss": 2.9851,
      "step": 143940
    },
    {
      "epoch": 231.45,
      "learning_rate": 0.07686449258890676,
      "loss": 2.9727,
      "step": 143960
    },
    {
      "epoch": 231.48,
      "learning_rate": 0.07686127715803859,
      "loss": 2.9857,
      "step": 143980
    },
    {
      "epoch": 231.51,
      "learning_rate": 0.07685806172717043,
      "loss": 2.9485,
      "step": 144000
    },
    {
      "epoch": 231.54,
      "learning_rate": 0.07685484629630225,
      "loss": 2.9427,
      "step": 144020
    },
    {
      "epoch": 231.58,
      "learning_rate": 0.07685163086543409,
      "loss": 2.9572,
      "step": 144040
    },
    {
      "epoch": 231.61,
      "learning_rate": 0.07684841543456593,
      "loss": 2.9561,
      "step": 144060
    },
    {
      "epoch": 231.64,
      "learning_rate": 0.07684520000369775,
      "loss": 2.9493,
      "step": 144080
    },
    {
      "epoch": 231.67,
      "learning_rate": 0.07684198457282958,
      "loss": 2.9595,
      "step": 144100
    },
    {
      "epoch": 231.7,
      "learning_rate": 0.07683876914196142,
      "loss": 2.9461,
      "step": 144120
    },
    {
      "epoch": 231.74,
      "learning_rate": 0.07683555371109325,
      "loss": 2.9396,
      "step": 144140
    },
    {
      "epoch": 231.77,
      "learning_rate": 0.0768323382802251,
      "loss": 2.9236,
      "step": 144160
    },
    {
      "epoch": 231.8,
      "learning_rate": 0.07682912284935692,
      "loss": 2.9717,
      "step": 144180
    },
    {
      "epoch": 231.83,
      "learning_rate": 0.07682590741848874,
      "loss": 2.9745,
      "step": 144200
    },
    {
      "epoch": 231.86,
      "learning_rate": 0.07682269198762058,
      "loss": 2.9695,
      "step": 144220
    },
    {
      "epoch": 231.9,
      "learning_rate": 0.07681947655675242,
      "loss": 2.9488,
      "step": 144240
    },
    {
      "epoch": 231.93,
      "learning_rate": 0.07681626112588426,
      "loss": 2.9528,
      "step": 144260
    },
    {
      "epoch": 231.96,
      "learning_rate": 0.07681304569501608,
      "loss": 2.9686,
      "step": 144280
    },
    {
      "epoch": 231.99,
      "learning_rate": 0.07680983026414791,
      "loss": 2.9711,
      "step": 144300
    },
    {
      "epoch": 232.0,
      "eval_accuracy": {
        "accuracy": 0.3823369353960973
      },
      "eval_loss": 3.0202410221099854,
      "eval_runtime": 2.7603,
      "eval_samples_per_second": 4659.961,
      "eval_steps_per_second": 72.818,
      "step": 144304
    },
    {
      "epoch": 232.03,
      "learning_rate": 0.07680661483327975,
      "loss": 2.958,
      "step": 144320
    },
    {
      "epoch": 232.06,
      "learning_rate": 0.07680339940241158,
      "loss": 2.9561,
      "step": 144340
    },
    {
      "epoch": 232.09,
      "learning_rate": 0.07680018397154341,
      "loss": 2.934,
      "step": 144360
    },
    {
      "epoch": 232.12,
      "learning_rate": 0.07679696854067525,
      "loss": 2.9313,
      "step": 144380
    },
    {
      "epoch": 232.15,
      "learning_rate": 0.07679375310980709,
      "loss": 2.9049,
      "step": 144400
    },
    {
      "epoch": 232.19,
      "learning_rate": 0.07679053767893891,
      "loss": 2.9698,
      "step": 144420
    },
    {
      "epoch": 232.22,
      "learning_rate": 0.07678732224807074,
      "loss": 2.9827,
      "step": 144440
    },
    {
      "epoch": 232.25,
      "learning_rate": 0.07678410681720257,
      "loss": 2.989,
      "step": 144460
    },
    {
      "epoch": 232.28,
      "learning_rate": 0.07678089138633441,
      "loss": 2.9731,
      "step": 144480
    },
    {
      "epoch": 232.32,
      "learning_rate": 0.07677767595546625,
      "loss": 2.9482,
      "step": 144500
    },
    {
      "epoch": 232.35,
      "learning_rate": 0.07677446052459808,
      "loss": 2.9614,
      "step": 144520
    },
    {
      "epoch": 232.38,
      "learning_rate": 0.0767712450937299,
      "loss": 2.9672,
      "step": 144540
    },
    {
      "epoch": 232.41,
      "learning_rate": 0.07676802966286174,
      "loss": 2.95,
      "step": 144560
    },
    {
      "epoch": 232.44,
      "learning_rate": 0.07676481423199358,
      "loss": 2.9289,
      "step": 144580
    },
    {
      "epoch": 232.48,
      "learning_rate": 0.07676159880112542,
      "loss": 2.9402,
      "step": 144600
    },
    {
      "epoch": 232.51,
      "learning_rate": 0.07675838337025724,
      "loss": 2.898,
      "step": 144620
    },
    {
      "epoch": 232.54,
      "learning_rate": 0.07675516793938907,
      "loss": 2.9576,
      "step": 144640
    },
    {
      "epoch": 232.57,
      "learning_rate": 0.0767519525085209,
      "loss": 2.9269,
      "step": 144660
    },
    {
      "epoch": 232.6,
      "learning_rate": 0.07674873707765274,
      "loss": 2.9572,
      "step": 144680
    },
    {
      "epoch": 232.64,
      "learning_rate": 0.07674552164678457,
      "loss": 2.9247,
      "step": 144700
    },
    {
      "epoch": 232.67,
      "learning_rate": 0.0767423062159164,
      "loss": 2.9539,
      "step": 144720
    },
    {
      "epoch": 232.7,
      "learning_rate": 0.07673909078504823,
      "loss": 2.9513,
      "step": 144740
    },
    {
      "epoch": 232.73,
      "learning_rate": 0.07673587535418007,
      "loss": 2.9827,
      "step": 144760
    },
    {
      "epoch": 232.77,
      "learning_rate": 0.0767326599233119,
      "loss": 2.9684,
      "step": 144780
    },
    {
      "epoch": 232.8,
      "learning_rate": 0.07672944449244373,
      "loss": 2.9596,
      "step": 144800
    },
    {
      "epoch": 232.83,
      "learning_rate": 0.07672622906157557,
      "loss": 2.9389,
      "step": 144820
    },
    {
      "epoch": 232.86,
      "learning_rate": 0.0767230136307074,
      "loss": 2.934,
      "step": 144840
    },
    {
      "epoch": 232.89,
      "learning_rate": 0.07671995897138265,
      "loss": 2.9317,
      "step": 144860
    },
    {
      "epoch": 232.93,
      "learning_rate": 0.07671674354051447,
      "loss": 2.9251,
      "step": 144880
    },
    {
      "epoch": 232.96,
      "learning_rate": 0.07671352810964631,
      "loss": 2.9683,
      "step": 144900
    },
    {
      "epoch": 232.99,
      "learning_rate": 0.07671031267877813,
      "loss": 2.9147,
      "step": 144920
    },
    {
      "epoch": 233.0,
      "eval_accuracy": {
        "accuracy": 0.3762730311746871
      },
      "eval_loss": 3.0797204971313477,
      "eval_runtime": 3.3971,
      "eval_samples_per_second": 3786.512,
      "eval_steps_per_second": 59.169,
      "step": 144926
    },
    {
      "epoch": 233.02,
      "learning_rate": 0.07670709724790997,
      "loss": 2.9721,
      "step": 144940
    },
    {
      "epoch": 233.05,
      "learning_rate": 0.07670388181704181,
      "loss": 2.9995,
      "step": 144960
    },
    {
      "epoch": 233.09,
      "learning_rate": 0.07670066638617364,
      "loss": 2.9665,
      "step": 144980
    },
    {
      "epoch": 233.12,
      "learning_rate": 0.07669745095530547,
      "loss": 2.9201,
      "step": 145000
    },
    {
      "epoch": 233.15,
      "learning_rate": 0.0766942355244373,
      "loss": 2.9364,
      "step": 145020
    },
    {
      "epoch": 233.18,
      "learning_rate": 0.07669102009356914,
      "loss": 2.9662,
      "step": 145040
    },
    {
      "epoch": 233.22,
      "learning_rate": 0.07668780466270096,
      "loss": 2.9687,
      "step": 145060
    },
    {
      "epoch": 233.25,
      "learning_rate": 0.0766845892318328,
      "loss": 2.9453,
      "step": 145080
    },
    {
      "epoch": 233.28,
      "learning_rate": 0.07668137380096464,
      "loss": 2.9594,
      "step": 145100
    },
    {
      "epoch": 233.31,
      "learning_rate": 0.07667815837009646,
      "loss": 2.9531,
      "step": 145120
    },
    {
      "epoch": 233.34,
      "learning_rate": 0.0766749429392283,
      "loss": 2.9286,
      "step": 145140
    },
    {
      "epoch": 233.38,
      "learning_rate": 0.07667172750836013,
      "loss": 2.9097,
      "step": 145160
    },
    {
      "epoch": 233.41,
      "learning_rate": 0.07666851207749197,
      "loss": 2.926,
      "step": 145180
    },
    {
      "epoch": 233.44,
      "learning_rate": 0.0766652966466238,
      "loss": 2.9419,
      "step": 145200
    },
    {
      "epoch": 233.47,
      "learning_rate": 0.07666208121575563,
      "loss": 2.9483,
      "step": 145220
    },
    {
      "epoch": 233.5,
      "learning_rate": 0.07665886578488747,
      "loss": 2.9448,
      "step": 145240
    },
    {
      "epoch": 233.54,
      "learning_rate": 0.07665565035401929,
      "loss": 2.9293,
      "step": 145260
    },
    {
      "epoch": 233.57,
      "learning_rate": 0.07665243492315113,
      "loss": 2.9268,
      "step": 145280
    },
    {
      "epoch": 233.6,
      "learning_rate": 0.07664921949228297,
      "loss": 2.9056,
      "step": 145300
    },
    {
      "epoch": 233.63,
      "learning_rate": 0.0766460040614148,
      "loss": 2.9302,
      "step": 145320
    },
    {
      "epoch": 233.67,
      "learning_rate": 0.07664278863054663,
      "loss": 2.9896,
      "step": 145340
    },
    {
      "epoch": 233.7,
      "learning_rate": 0.07663957319967846,
      "loss": 2.9613,
      "step": 145360
    },
    {
      "epoch": 233.73,
      "learning_rate": 0.0766363577688103,
      "loss": 2.9849,
      "step": 145380
    },
    {
      "epoch": 233.76,
      "learning_rate": 0.07663314233794212,
      "loss": 2.9544,
      "step": 145400
    },
    {
      "epoch": 233.79,
      "learning_rate": 0.07662992690707396,
      "loss": 2.9613,
      "step": 145420
    },
    {
      "epoch": 233.83,
      "learning_rate": 0.0766267114762058,
      "loss": 2.9604,
      "step": 145440
    },
    {
      "epoch": 233.86,
      "learning_rate": 0.07662349604533762,
      "loss": 2.9313,
      "step": 145460
    },
    {
      "epoch": 233.89,
      "learning_rate": 0.07662028061446946,
      "loss": 2.9485,
      "step": 145480
    },
    {
      "epoch": 233.92,
      "learning_rate": 0.07661706518360129,
      "loss": 2.9496,
      "step": 145500
    },
    {
      "epoch": 233.95,
      "learning_rate": 0.07661384975273312,
      "loss": 2.943,
      "step": 145520
    },
    {
      "epoch": 233.99,
      "learning_rate": 0.07661063432186496,
      "loss": 2.9451,
      "step": 145540
    },
    {
      "epoch": 234.0,
      "eval_accuracy": {
        "accuracy": 0.38008240690352174
      },
      "eval_loss": 3.0206520557403564,
      "eval_runtime": 2.8187,
      "eval_samples_per_second": 4563.449,
      "eval_steps_per_second": 71.309,
      "step": 145548
    },
    {
      "epoch": 234.02,
      "learning_rate": 0.07660741889099679,
      "loss": 2.9635,
      "step": 145560
    },
    {
      "epoch": 234.05,
      "learning_rate": 0.07660420346012863,
      "loss": 2.9731,
      "step": 145580
    },
    {
      "epoch": 234.08,
      "learning_rate": 0.07660098802926045,
      "loss": 2.9366,
      "step": 145600
    },
    {
      "epoch": 234.12,
      "learning_rate": 0.07659777259839229,
      "loss": 2.9304,
      "step": 145620
    },
    {
      "epoch": 234.15,
      "learning_rate": 0.07659455716752413,
      "loss": 2.9318,
      "step": 145640
    },
    {
      "epoch": 234.18,
      "learning_rate": 0.07659134173665595,
      "loss": 2.9321,
      "step": 145660
    },
    {
      "epoch": 234.21,
      "learning_rate": 0.07658812630578779,
      "loss": 2.9315,
      "step": 145680
    },
    {
      "epoch": 234.24,
      "learning_rate": 0.07658491087491962,
      "loss": 2.9024,
      "step": 145700
    },
    {
      "epoch": 234.28,
      "learning_rate": 0.07658169544405145,
      "loss": 2.9317,
      "step": 145720
    },
    {
      "epoch": 234.31,
      "learning_rate": 0.07657848001318328,
      "loss": 2.9384,
      "step": 145740
    },
    {
      "epoch": 234.34,
      "learning_rate": 0.07657526458231512,
      "loss": 2.9219,
      "step": 145760
    },
    {
      "epoch": 234.37,
      "learning_rate": 0.07657204915144696,
      "loss": 2.9529,
      "step": 145780
    },
    {
      "epoch": 234.41,
      "learning_rate": 0.07656883372057878,
      "loss": 2.9253,
      "step": 145800
    },
    {
      "epoch": 234.44,
      "learning_rate": 0.07656561828971062,
      "loss": 2.9384,
      "step": 145820
    },
    {
      "epoch": 234.47,
      "learning_rate": 0.07656240285884244,
      "loss": 2.9792,
      "step": 145840
    },
    {
      "epoch": 234.5,
      "learning_rate": 0.07655918742797428,
      "loss": 2.9652,
      "step": 145860
    },
    {
      "epoch": 234.53,
      "learning_rate": 0.07655597199710612,
      "loss": 2.95,
      "step": 145880
    },
    {
      "epoch": 234.57,
      "learning_rate": 0.07655275656623795,
      "loss": 2.9441,
      "step": 145900
    },
    {
      "epoch": 234.6,
      "learning_rate": 0.07654954113536978,
      "loss": 2.9923,
      "step": 145920
    },
    {
      "epoch": 234.63,
      "learning_rate": 0.07654632570450161,
      "loss": 2.9662,
      "step": 145940
    },
    {
      "epoch": 234.66,
      "learning_rate": 0.07654311027363345,
      "loss": 2.9227,
      "step": 145960
    },
    {
      "epoch": 234.69,
      "learning_rate": 0.07653989484276529,
      "loss": 2.9397,
      "step": 145980
    },
    {
      "epoch": 234.73,
      "learning_rate": 0.07653667941189711,
      "loss": 2.956,
      "step": 146000
    },
    {
      "epoch": 234.76,
      "learning_rate": 0.07653346398102895,
      "loss": 2.9443,
      "step": 146020
    },
    {
      "epoch": 234.79,
      "learning_rate": 0.07653024855016077,
      "loss": 2.951,
      "step": 146040
    },
    {
      "epoch": 234.82,
      "learning_rate": 0.07652703311929261,
      "loss": 2.9708,
      "step": 146060
    },
    {
      "epoch": 234.86,
      "learning_rate": 0.07652381768842444,
      "loss": 2.9627,
      "step": 146080
    },
    {
      "epoch": 234.89,
      "learning_rate": 0.07652060225755627,
      "loss": 2.9865,
      "step": 146100
    },
    {
      "epoch": 234.92,
      "learning_rate": 0.07651738682668811,
      "loss": 2.9584,
      "step": 146120
    },
    {
      "epoch": 234.95,
      "learning_rate": 0.07651417139581994,
      "loss": 2.9306,
      "step": 146140
    },
    {
      "epoch": 234.98,
      "learning_rate": 0.07651095596495178,
      "loss": 2.953,
      "step": 146160
    },
    {
      "epoch": 235.0,
      "eval_accuracy": {
        "accuracy": 0.3728523672549172
      },
      "eval_loss": 3.0889947414398193,
      "eval_runtime": 2.732,
      "eval_samples_per_second": 4708.196,
      "eval_steps_per_second": 73.571,
      "step": 146170
    },
    {
      "epoch": 235.02,
      "learning_rate": 0.0765077405340836,
      "loss": 2.9832,
      "step": 146180
    },
    {
      "epoch": 235.05,
      "learning_rate": 0.07650452510321544,
      "loss": 2.9201,
      "step": 146200
    },
    {
      "epoch": 235.08,
      "learning_rate": 0.07650130967234728,
      "loss": 2.9115,
      "step": 146220
    },
    {
      "epoch": 235.11,
      "learning_rate": 0.0764980942414791,
      "loss": 2.9494,
      "step": 146240
    },
    {
      "epoch": 235.14,
      "learning_rate": 0.07649487881061094,
      "loss": 2.9607,
      "step": 146260
    },
    {
      "epoch": 235.18,
      "learning_rate": 0.07649166337974277,
      "loss": 2.9503,
      "step": 146280
    },
    {
      "epoch": 235.21,
      "learning_rate": 0.0764884479488746,
      "loss": 2.9514,
      "step": 146300
    },
    {
      "epoch": 235.24,
      "learning_rate": 0.07648523251800644,
      "loss": 2.9447,
      "step": 146320
    },
    {
      "epoch": 235.27,
      "learning_rate": 0.07648201708713827,
      "loss": 2.967,
      "step": 146340
    },
    {
      "epoch": 235.31,
      "learning_rate": 0.0764788016562701,
      "loss": 2.9656,
      "step": 146360
    },
    {
      "epoch": 235.34,
      "learning_rate": 0.07647558622540193,
      "loss": 2.9368,
      "step": 146380
    },
    {
      "epoch": 235.37,
      "learning_rate": 0.07647237079453377,
      "loss": 2.9286,
      "step": 146400
    },
    {
      "epoch": 235.4,
      "learning_rate": 0.0764691553636656,
      "loss": 2.9476,
      "step": 146420
    },
    {
      "epoch": 235.43,
      "learning_rate": 0.07646593993279743,
      "loss": 2.9218,
      "step": 146440
    },
    {
      "epoch": 235.47,
      "learning_rate": 0.07646272450192927,
      "loss": 2.9338,
      "step": 146460
    },
    {
      "epoch": 235.5,
      "learning_rate": 0.0764595090710611,
      "loss": 2.9489,
      "step": 146480
    },
    {
      "epoch": 235.53,
      "learning_rate": 0.07645629364019292,
      "loss": 2.9424,
      "step": 146500
    },
    {
      "epoch": 235.56,
      "learning_rate": 0.07645307820932476,
      "loss": 2.9555,
      "step": 146520
    },
    {
      "epoch": 235.59,
      "learning_rate": 0.0764498627784566,
      "loss": 2.9807,
      "step": 146540
    },
    {
      "epoch": 235.63,
      "learning_rate": 0.07644664734758844,
      "loss": 2.9134,
      "step": 146560
    },
    {
      "epoch": 235.66,
      "learning_rate": 0.07644343191672026,
      "loss": 2.9272,
      "step": 146580
    },
    {
      "epoch": 235.69,
      "learning_rate": 0.0764402164858521,
      "loss": 3.0022,
      "step": 146600
    },
    {
      "epoch": 235.72,
      "learning_rate": 0.07643700105498392,
      "loss": 2.936,
      "step": 146620
    },
    {
      "epoch": 235.76,
      "learning_rate": 0.07643378562411576,
      "loss": 2.9433,
      "step": 146640
    },
    {
      "epoch": 235.79,
      "learning_rate": 0.0764305701932476,
      "loss": 2.9342,
      "step": 146660
    },
    {
      "epoch": 235.82,
      "learning_rate": 0.07642735476237943,
      "loss": 2.9037,
      "step": 146680
    },
    {
      "epoch": 235.85,
      "learning_rate": 0.07642413933151126,
      "loss": 2.9431,
      "step": 146700
    },
    {
      "epoch": 235.88,
      "learning_rate": 0.07642092390064309,
      "loss": 2.9675,
      "step": 146720
    },
    {
      "epoch": 235.92,
      "learning_rate": 0.07641770846977493,
      "loss": 2.977,
      "step": 146740
    },
    {
      "epoch": 235.95,
      "learning_rate": 0.07641449303890675,
      "loss": 2.9887,
      "step": 146760
    },
    {
      "epoch": 235.98,
      "learning_rate": 0.07641127760803859,
      "loss": 2.9911,
      "step": 146780
    },
    {
      "epoch": 236.0,
      "eval_accuracy": {
        "accuracy": 0.3902666563010184
      },
      "eval_loss": 3.013993740081787,
      "eval_runtime": 2.754,
      "eval_samples_per_second": 4670.597,
      "eval_steps_per_second": 72.984,
      "step": 146792
    },
    {
      "epoch": 236.01,
      "learning_rate": 0.07640806217717043,
      "loss": 2.9825,
      "step": 146800
    },
    {
      "epoch": 236.05,
      "learning_rate": 0.07640484674630225,
      "loss": 2.9269,
      "step": 146820
    },
    {
      "epoch": 236.08,
      "learning_rate": 0.07640163131543408,
      "loss": 2.9347,
      "step": 146840
    },
    {
      "epoch": 236.11,
      "learning_rate": 0.07639841588456592,
      "loss": 2.9234,
      "step": 146860
    },
    {
      "epoch": 236.14,
      "learning_rate": 0.07639520045369776,
      "loss": 2.976,
      "step": 146880
    },
    {
      "epoch": 236.17,
      "learning_rate": 0.0763919850228296,
      "loss": 2.9648,
      "step": 146900
    },
    {
      "epoch": 236.21,
      "learning_rate": 0.07638876959196142,
      "loss": 2.9695,
      "step": 146920
    },
    {
      "epoch": 236.24,
      "learning_rate": 0.07638555416109324,
      "loss": 2.9676,
      "step": 146940
    },
    {
      "epoch": 236.27,
      "learning_rate": 0.07638233873022508,
      "loss": 2.9432,
      "step": 146960
    },
    {
      "epoch": 236.3,
      "learning_rate": 0.07637912329935692,
      "loss": 2.9328,
      "step": 146980
    },
    {
      "epoch": 236.33,
      "learning_rate": 0.07637590786848876,
      "loss": 2.9298,
      "step": 147000
    },
    {
      "epoch": 236.37,
      "learning_rate": 0.07637269243762058,
      "loss": 2.9105,
      "step": 147020
    },
    {
      "epoch": 236.4,
      "learning_rate": 0.07636947700675241,
      "loss": 2.9048,
      "step": 147040
    },
    {
      "epoch": 236.43,
      "learning_rate": 0.07636626157588425,
      "loss": 2.9624,
      "step": 147060
    },
    {
      "epoch": 236.46,
      "learning_rate": 0.07636304614501609,
      "loss": 2.9549,
      "step": 147080
    },
    {
      "epoch": 236.5,
      "learning_rate": 0.07635983071414791,
      "loss": 2.9435,
      "step": 147100
    },
    {
      "epoch": 236.53,
      "learning_rate": 0.07635661528327975,
      "loss": 2.9196,
      "step": 147120
    },
    {
      "epoch": 236.56,
      "learning_rate": 0.07635339985241157,
      "loss": 2.9509,
      "step": 147140
    },
    {
      "epoch": 236.59,
      "learning_rate": 0.07635018442154341,
      "loss": 2.9701,
      "step": 147160
    },
    {
      "epoch": 236.62,
      "learning_rate": 0.07634696899067524,
      "loss": 2.9537,
      "step": 147180
    },
    {
      "epoch": 236.66,
      "learning_rate": 0.07634375355980708,
      "loss": 2.9226,
      "step": 147200
    },
    {
      "epoch": 236.69,
      "learning_rate": 0.07634053812893891,
      "loss": 2.9325,
      "step": 147220
    },
    {
      "epoch": 236.72,
      "learning_rate": 0.07633732269807075,
      "loss": 2.9445,
      "step": 147240
    },
    {
      "epoch": 236.75,
      "learning_rate": 0.07633410726720258,
      "loss": 2.9319,
      "step": 147260
    },
    {
      "epoch": 236.78,
      "learning_rate": 0.0763308918363344,
      "loss": 2.9271,
      "step": 147280
    },
    {
      "epoch": 236.82,
      "learning_rate": 0.07632767640546624,
      "loss": 2.925,
      "step": 147300
    },
    {
      "epoch": 236.85,
      "learning_rate": 0.07632446097459808,
      "loss": 2.9376,
      "step": 147320
    },
    {
      "epoch": 236.88,
      "learning_rate": 0.07632124554372992,
      "loss": 2.938,
      "step": 147340
    },
    {
      "epoch": 236.91,
      "learning_rate": 0.07631803011286174,
      "loss": 2.9911,
      "step": 147360
    },
    {
      "epoch": 236.95,
      "learning_rate": 0.07631481468199357,
      "loss": 2.9762,
      "step": 147380
    },
    {
      "epoch": 236.98,
      "learning_rate": 0.0763115992511254,
      "loss": 2.9444,
      "step": 147400
    },
    {
      "epoch": 237.0,
      "eval_accuracy": {
        "accuracy": 0.37487366866205396
      },
      "eval_loss": 3.0624780654907227,
      "eval_runtime": 2.996,
      "eval_samples_per_second": 4293.404,
      "eval_steps_per_second": 67.09,
      "step": 147414
    },
    {
      "epoch": 237.01,
      "learning_rate": 0.07630838382025724,
      "loss": 2.9581,
      "step": 147420
    },
    {
      "epoch": 237.04,
      "learning_rate": 0.07630516838938907,
      "loss": 2.9092,
      "step": 147440
    },
    {
      "epoch": 237.07,
      "learning_rate": 0.07630195295852091,
      "loss": 2.9244,
      "step": 147460
    },
    {
      "epoch": 237.11,
      "learning_rate": 0.07629873752765273,
      "loss": 2.9417,
      "step": 147480
    },
    {
      "epoch": 237.14,
      "learning_rate": 0.07629552209678457,
      "loss": 2.9403,
      "step": 147500
    },
    {
      "epoch": 237.17,
      "learning_rate": 0.0762923066659164,
      "loss": 2.9209,
      "step": 147520
    },
    {
      "epoch": 237.2,
      "learning_rate": 0.07628909123504823,
      "loss": 2.9645,
      "step": 147540
    },
    {
      "epoch": 237.23,
      "learning_rate": 0.07628587580418007,
      "loss": 2.9347,
      "step": 147560
    },
    {
      "epoch": 237.27,
      "learning_rate": 0.0762826603733119,
      "loss": 2.9239,
      "step": 147580
    },
    {
      "epoch": 237.3,
      "learning_rate": 0.07627944494244374,
      "loss": 2.921,
      "step": 147600
    },
    {
      "epoch": 237.33,
      "learning_rate": 0.07627622951157556,
      "loss": 2.928,
      "step": 147620
    },
    {
      "epoch": 237.36,
      "learning_rate": 0.0762730140807074,
      "loss": 2.9505,
      "step": 147640
    },
    {
      "epoch": 237.4,
      "learning_rate": 0.07626979864983924,
      "loss": 2.932,
      "step": 147660
    },
    {
      "epoch": 237.43,
      "learning_rate": 0.07626658321897106,
      "loss": 2.9554,
      "step": 147680
    },
    {
      "epoch": 237.46,
      "learning_rate": 0.0762633677881029,
      "loss": 2.9811,
      "step": 147700
    },
    {
      "epoch": 237.49,
      "learning_rate": 0.07626015235723473,
      "loss": 2.9543,
      "step": 147720
    },
    {
      "epoch": 237.52,
      "learning_rate": 0.07625693692636656,
      "loss": 2.9593,
      "step": 147740
    },
    {
      "epoch": 237.56,
      "learning_rate": 0.0762537214954984,
      "loss": 2.9354,
      "step": 147760
    },
    {
      "epoch": 237.59,
      "learning_rate": 0.07625050606463023,
      "loss": 2.9552,
      "step": 147780
    },
    {
      "epoch": 237.62,
      "learning_rate": 0.07624729063376207,
      "loss": 2.9294,
      "step": 147800
    },
    {
      "epoch": 237.65,
      "learning_rate": 0.07624407520289389,
      "loss": 2.9672,
      "step": 147820
    },
    {
      "epoch": 237.68,
      "learning_rate": 0.07624085977202573,
      "loss": 2.9491,
      "step": 147840
    },
    {
      "epoch": 237.72,
      "learning_rate": 0.07623764434115755,
      "loss": 2.9551,
      "step": 147860
    },
    {
      "epoch": 237.75,
      "learning_rate": 0.07623442891028939,
      "loss": 2.9526,
      "step": 147880
    },
    {
      "epoch": 237.78,
      "learning_rate": 0.07623121347942123,
      "loss": 2.9801,
      "step": 147900
    },
    {
      "epoch": 237.81,
      "learning_rate": 0.07622799804855306,
      "loss": 2.9626,
      "step": 147920
    },
    {
      "epoch": 237.85,
      "learning_rate": 0.0762247826176849,
      "loss": 2.9891,
      "step": 147940
    },
    {
      "epoch": 237.88,
      "learning_rate": 0.07622156718681672,
      "loss": 2.9512,
      "step": 147960
    },
    {
      "epoch": 237.91,
      "learning_rate": 0.07621835175594856,
      "loss": 2.9524,
      "step": 147980
    },
    {
      "epoch": 237.94,
      "learning_rate": 0.0762151363250804,
      "loss": 2.94,
      "step": 148000
    },
    {
      "epoch": 237.97,
      "learning_rate": 0.07621192089421222,
      "loss": 2.9615,
      "step": 148020
    },
    {
      "epoch": 238.0,
      "eval_accuracy": {
        "accuracy": 0.37137526238047114
      },
      "eval_loss": 3.0675811767578125,
      "eval_runtime": 3.0623,
      "eval_samples_per_second": 4200.441,
      "eval_steps_per_second": 65.637,
      "step": 148036
    },
    {
      "epoch": 238.01,
      "learning_rate": 0.07620870546334406,
      "loss": 2.9705,
      "step": 148040
    },
    {
      "epoch": 238.04,
      "learning_rate": 0.07620549003247588,
      "loss": 2.9314,
      "step": 148060
    },
    {
      "epoch": 238.07,
      "learning_rate": 0.07620227460160772,
      "loss": 2.923,
      "step": 148080
    },
    {
      "epoch": 238.1,
      "learning_rate": 0.07619905917073956,
      "loss": 2.917,
      "step": 148100
    },
    {
      "epoch": 238.14,
      "learning_rate": 0.07619584373987139,
      "loss": 2.9321,
      "step": 148120
    },
    {
      "epoch": 238.17,
      "learning_rate": 0.07619262830900322,
      "loss": 2.9098,
      "step": 148140
    },
    {
      "epoch": 238.2,
      "learning_rate": 0.07618941287813505,
      "loss": 2.9251,
      "step": 148160
    },
    {
      "epoch": 238.23,
      "learning_rate": 0.07618619744726689,
      "loss": 2.9163,
      "step": 148180
    },
    {
      "epoch": 238.26,
      "learning_rate": 0.07618298201639871,
      "loss": 2.9253,
      "step": 148200
    },
    {
      "epoch": 238.3,
      "learning_rate": 0.07617976658553055,
      "loss": 2.9621,
      "step": 148220
    },
    {
      "epoch": 238.33,
      "learning_rate": 0.07617655115466239,
      "loss": 2.9877,
      "step": 148240
    },
    {
      "epoch": 238.36,
      "learning_rate": 0.07617333572379421,
      "loss": 2.9423,
      "step": 148260
    },
    {
      "epoch": 238.39,
      "learning_rate": 0.07617012029292605,
      "loss": 2.9384,
      "step": 148280
    },
    {
      "epoch": 238.42,
      "learning_rate": 0.07616690486205788,
      "loss": 2.9666,
      "step": 148300
    },
    {
      "epoch": 238.46,
      "learning_rate": 0.07616368943118972,
      "loss": 2.92,
      "step": 148320
    },
    {
      "epoch": 238.49,
      "learning_rate": 0.07616047400032155,
      "loss": 2.9108,
      "step": 148340
    },
    {
      "epoch": 238.52,
      "learning_rate": 0.07615725856945338,
      "loss": 2.9528,
      "step": 148360
    },
    {
      "epoch": 238.55,
      "learning_rate": 0.07615404313858522,
      "loss": 2.9258,
      "step": 148380
    },
    {
      "epoch": 238.59,
      "learning_rate": 0.07615082770771704,
      "loss": 2.9226,
      "step": 148400
    },
    {
      "epoch": 238.62,
      "learning_rate": 0.07614761227684888,
      "loss": 2.892,
      "step": 148420
    },
    {
      "epoch": 238.65,
      "learning_rate": 0.07614439684598072,
      "loss": 2.9364,
      "step": 148440
    },
    {
      "epoch": 238.68,
      "learning_rate": 0.07614118141511254,
      "loss": 2.9599,
      "step": 148460
    },
    {
      "epoch": 238.71,
      "learning_rate": 0.07613796598424438,
      "loss": 2.9471,
      "step": 148480
    },
    {
      "epoch": 238.75,
      "learning_rate": 0.07613475055337621,
      "loss": 2.936,
      "step": 148500
    },
    {
      "epoch": 238.78,
      "learning_rate": 0.07613153512250805,
      "loss": 2.9493,
      "step": 148520
    },
    {
      "epoch": 238.81,
      "learning_rate": 0.07612831969163987,
      "loss": 2.945,
      "step": 148540
    },
    {
      "epoch": 238.84,
      "learning_rate": 0.07612510426077171,
      "loss": 2.927,
      "step": 148560
    },
    {
      "epoch": 238.87,
      "learning_rate": 0.07612188882990355,
      "loss": 2.9618,
      "step": 148580
    },
    {
      "epoch": 238.91,
      "learning_rate": 0.07611867339903537,
      "loss": 2.9573,
      "step": 148600
    },
    {
      "epoch": 238.94,
      "learning_rate": 0.07611545796816721,
      "loss": 2.9965,
      "step": 148620
    },
    {
      "epoch": 238.97,
      "learning_rate": 0.07611224253729904,
      "loss": 2.9056,
      "step": 148640
    },
    {
      "epoch": 239.0,
      "eval_accuracy": {
        "accuracy": 0.38070434579802537
      },
      "eval_loss": 3.0331690311431885,
      "eval_runtime": 3.3853,
      "eval_samples_per_second": 3799.641,
      "eval_steps_per_second": 59.374,
      "step": 148658
    },
    {
      "epoch": 239.0,
      "learning_rate": 0.07610902710643087,
      "loss": 2.9286,
      "step": 148660
    },
    {
      "epoch": 239.04,
      "learning_rate": 0.07610581167556271,
      "loss": 2.9361,
      "step": 148680
    },
    {
      "epoch": 239.07,
      "learning_rate": 0.07610259624469454,
      "loss": 2.9612,
      "step": 148700
    },
    {
      "epoch": 239.1,
      "learning_rate": 0.07609938081382638,
      "loss": 2.9154,
      "step": 148720
    },
    {
      "epoch": 239.13,
      "learning_rate": 0.0760961653829582,
      "loss": 2.9368,
      "step": 148740
    },
    {
      "epoch": 239.16,
      "learning_rate": 0.07609294995209004,
      "loss": 2.9266,
      "step": 148760
    },
    {
      "epoch": 239.2,
      "learning_rate": 0.07608973452122188,
      "loss": 2.9308,
      "step": 148780
    },
    {
      "epoch": 239.23,
      "learning_rate": 0.0760865190903537,
      "loss": 2.9364,
      "step": 148800
    },
    {
      "epoch": 239.26,
      "learning_rate": 0.07608330365948554,
      "loss": 2.9594,
      "step": 148820
    },
    {
      "epoch": 239.29,
      "learning_rate": 0.07608008822861737,
      "loss": 2.9761,
      "step": 148840
    },
    {
      "epoch": 239.32,
      "learning_rate": 0.0760768727977492,
      "loss": 2.9625,
      "step": 148860
    },
    {
      "epoch": 239.36,
      "learning_rate": 0.07607365736688103,
      "loss": 2.9439,
      "step": 148880
    },
    {
      "epoch": 239.39,
      "learning_rate": 0.07607044193601287,
      "loss": 2.9401,
      "step": 148900
    },
    {
      "epoch": 239.42,
      "learning_rate": 0.0760672265051447,
      "loss": 2.8909,
      "step": 148920
    },
    {
      "epoch": 239.45,
      "learning_rate": 0.07606401107427653,
      "loss": 2.9275,
      "step": 148940
    },
    {
      "epoch": 239.49,
      "learning_rate": 0.07606095641495178,
      "loss": 2.9584,
      "step": 148960
    },
    {
      "epoch": 239.52,
      "learning_rate": 0.0760577409840836,
      "loss": 2.923,
      "step": 148980
    },
    {
      "epoch": 239.55,
      "learning_rate": 0.07605452555321544,
      "loss": 2.9326,
      "step": 149000
    },
    {
      "epoch": 239.58,
      "learning_rate": 0.07605131012234727,
      "loss": 2.9261,
      "step": 149020
    },
    {
      "epoch": 239.61,
      "learning_rate": 0.0760480946914791,
      "loss": 2.9558,
      "step": 149040
    },
    {
      "epoch": 239.65,
      "learning_rate": 0.07604487926061095,
      "loss": 2.9318,
      "step": 149060
    },
    {
      "epoch": 239.68,
      "learning_rate": 0.07604166382974277,
      "loss": 2.9138,
      "step": 149080
    },
    {
      "epoch": 239.71,
      "learning_rate": 0.07603844839887461,
      "loss": 2.9358,
      "step": 149100
    },
    {
      "epoch": 239.74,
      "learning_rate": 0.07603523296800643,
      "loss": 2.9602,
      "step": 149120
    },
    {
      "epoch": 239.77,
      "learning_rate": 0.07603201753713827,
      "loss": 2.9596,
      "step": 149140
    },
    {
      "epoch": 239.81,
      "learning_rate": 0.0760288021062701,
      "loss": 2.9438,
      "step": 149160
    },
    {
      "epoch": 239.84,
      "learning_rate": 0.07602558667540193,
      "loss": 2.9834,
      "step": 149180
    },
    {
      "epoch": 239.87,
      "learning_rate": 0.07602237124453377,
      "loss": 2.9679,
      "step": 149200
    },
    {
      "epoch": 239.9,
      "learning_rate": 0.0760191558136656,
      "loss": 2.9402,
      "step": 149220
    },
    {
      "epoch": 239.94,
      "learning_rate": 0.07601594038279742,
      "loss": 2.9355,
      "step": 149240
    },
    {
      "epoch": 239.97,
      "learning_rate": 0.07601272495192926,
      "loss": 2.9477,
      "step": 149260
    },
    {
      "epoch": 240.0,
      "learning_rate": 0.0760095095210611,
      "loss": 2.9575,
      "step": 149280
    },
    {
      "epoch": 240.0,
      "eval_accuracy": {
        "accuracy": 0.37922724092357923
      },
      "eval_loss": 3.0608789920806885,
      "eval_runtime": 3.1515,
      "eval_samples_per_second": 4081.592,
      "eval_steps_per_second": 63.78,
      "step": 149280
    },
    {
      "epoch": 240.03,
      "learning_rate": 0.07600629409019294,
      "loss": 2.9462,
      "step": 149300
    },
    {
      "epoch": 240.06,
      "learning_rate": 0.07600307865932476,
      "loss": 2.9264,
      "step": 149320
    },
    {
      "epoch": 240.1,
      "learning_rate": 0.07599986322845659,
      "loss": 2.967,
      "step": 149340
    },
    {
      "epoch": 240.13,
      "learning_rate": 0.07599664779758843,
      "loss": 2.9179,
      "step": 149360
    },
    {
      "epoch": 240.16,
      "learning_rate": 0.07599343236672026,
      "loss": 2.9499,
      "step": 149380
    },
    {
      "epoch": 240.19,
      "learning_rate": 0.0759902169358521,
      "loss": 2.9429,
      "step": 149400
    },
    {
      "epoch": 240.23,
      "learning_rate": 0.07598700150498393,
      "loss": 2.9202,
      "step": 149420
    },
    {
      "epoch": 240.26,
      "learning_rate": 0.07598378607411577,
      "loss": 2.9311,
      "step": 149440
    },
    {
      "epoch": 240.29,
      "learning_rate": 0.07598057064324759,
      "loss": 2.9371,
      "step": 149460
    },
    {
      "epoch": 240.32,
      "learning_rate": 0.07597735521237943,
      "loss": 2.927,
      "step": 149480
    },
    {
      "epoch": 240.35,
      "learning_rate": 0.07597413978151125,
      "loss": 2.8871,
      "step": 149500
    },
    {
      "epoch": 240.39,
      "learning_rate": 0.0759709243506431,
      "loss": 2.9029,
      "step": 149520
    },
    {
      "epoch": 240.42,
      "learning_rate": 0.07596770891977493,
      "loss": 2.9459,
      "step": 149540
    },
    {
      "epoch": 240.45,
      "learning_rate": 0.07596449348890676,
      "loss": 2.9181,
      "step": 149560
    },
    {
      "epoch": 240.48,
      "learning_rate": 0.07596127805803858,
      "loss": 2.9562,
      "step": 149580
    },
    {
      "epoch": 240.51,
      "learning_rate": 0.07595806262717042,
      "loss": 2.9214,
      "step": 149600
    },
    {
      "epoch": 240.55,
      "learning_rate": 0.07595484719630226,
      "loss": 2.9431,
      "step": 149620
    },
    {
      "epoch": 240.58,
      "learning_rate": 0.0759516317654341,
      "loss": 2.8948,
      "step": 149640
    },
    {
      "epoch": 240.61,
      "learning_rate": 0.07594841633456592,
      "loss": 2.9408,
      "step": 149660
    },
    {
      "epoch": 240.64,
      "learning_rate": 0.07594520090369775,
      "loss": 2.9315,
      "step": 149680
    },
    {
      "epoch": 240.68,
      "learning_rate": 0.07594198547282958,
      "loss": 2.9714,
      "step": 149700
    },
    {
      "epoch": 240.71,
      "learning_rate": 0.07593877004196142,
      "loss": 2.953,
      "step": 149720
    },
    {
      "epoch": 240.74,
      "learning_rate": 0.07593555461109326,
      "loss": 2.9504,
      "step": 149740
    },
    {
      "epoch": 240.77,
      "learning_rate": 0.07593233918022509,
      "loss": 2.9433,
      "step": 149760
    },
    {
      "epoch": 240.8,
      "learning_rate": 0.07592912374935691,
      "loss": 2.9403,
      "step": 149780
    },
    {
      "epoch": 240.84,
      "learning_rate": 0.07592590831848875,
      "loss": 2.9426,
      "step": 149800
    },
    {
      "epoch": 240.87,
      "learning_rate": 0.07592269288762059,
      "loss": 2.9124,
      "step": 149820
    },
    {
      "epoch": 240.9,
      "learning_rate": 0.07591947745675241,
      "loss": 2.956,
      "step": 149840
    },
    {
      "epoch": 240.93,
      "learning_rate": 0.07591626202588425,
      "loss": 2.9365,
      "step": 149860
    },
    {
      "epoch": 240.96,
      "learning_rate": 0.07591304659501608,
      "loss": 2.9552,
      "step": 149880
    },
    {
      "epoch": 241.0,
      "learning_rate": 0.07590983116414791,
      "loss": 2.8983,
      "step": 149900
    },
    {
      "epoch": 241.0,
      "eval_accuracy": {
        "accuracy": 0.3849801756977377
      },
      "eval_loss": 2.981516122817993,
      "eval_runtime": 2.66,
      "eval_samples_per_second": 4835.715,
      "eval_steps_per_second": 75.564,
      "step": 149902
    },
    {
      "epoch": 241.03,
      "learning_rate": 0.07590661573327974,
      "loss": 2.9095,
      "step": 149920
    },
    {
      "epoch": 241.06,
      "learning_rate": 0.07590340030241158,
      "loss": 2.9706,
      "step": 149940
    },
    {
      "epoch": 241.09,
      "learning_rate": 0.07590018487154342,
      "loss": 2.9785,
      "step": 149960
    },
    {
      "epoch": 241.13,
      "learning_rate": 0.07589696944067524,
      "loss": 2.9051,
      "step": 149980
    },
    {
      "epoch": 241.16,
      "learning_rate": 0.07589375400980708,
      "loss": 2.9172,
      "step": 150000
    },
    {
      "epoch": 241.19,
      "learning_rate": 0.0758905385789389,
      "loss": 2.9328,
      "step": 150020
    },
    {
      "epoch": 241.22,
      "learning_rate": 0.07588732314807074,
      "loss": 2.9311,
      "step": 150040
    },
    {
      "epoch": 241.25,
      "learning_rate": 0.07588410771720258,
      "loss": 2.9325,
      "step": 150060
    },
    {
      "epoch": 241.29,
      "learning_rate": 0.07588089228633442,
      "loss": 2.9459,
      "step": 150080
    },
    {
      "epoch": 241.32,
      "learning_rate": 0.07587767685546624,
      "loss": 2.935,
      "step": 150100
    },
    {
      "epoch": 241.35,
      "learning_rate": 0.07587446142459807,
      "loss": 2.9345,
      "step": 150120
    },
    {
      "epoch": 241.38,
      "learning_rate": 0.07587124599372991,
      "loss": 2.9594,
      "step": 150140
    },
    {
      "epoch": 241.41,
      "learning_rate": 0.07586803056286175,
      "loss": 2.9546,
      "step": 150160
    },
    {
      "epoch": 241.45,
      "learning_rate": 0.07586481513199357,
      "loss": 2.9159,
      "step": 150180
    },
    {
      "epoch": 241.48,
      "learning_rate": 0.07586159970112541,
      "loss": 2.9023,
      "step": 150200
    },
    {
      "epoch": 241.51,
      "learning_rate": 0.07585838427025723,
      "loss": 2.9275,
      "step": 150220
    },
    {
      "epoch": 241.54,
      "learning_rate": 0.07585516883938907,
      "loss": 2.9137,
      "step": 150240
    },
    {
      "epoch": 241.58,
      "learning_rate": 0.0758519534085209,
      "loss": 2.9344,
      "step": 150260
    },
    {
      "epoch": 241.61,
      "learning_rate": 0.07584873797765274,
      "loss": 2.9414,
      "step": 150280
    },
    {
      "epoch": 241.64,
      "learning_rate": 0.07584552254678457,
      "loss": 2.9252,
      "step": 150300
    },
    {
      "epoch": 241.67,
      "learning_rate": 0.0758423071159164,
      "loss": 2.9387,
      "step": 150320
    },
    {
      "epoch": 241.7,
      "learning_rate": 0.07583909168504824,
      "loss": 2.9503,
      "step": 150340
    },
    {
      "epoch": 241.74,
      "learning_rate": 0.07583587625418006,
      "loss": 2.918,
      "step": 150360
    },
    {
      "epoch": 241.77,
      "learning_rate": 0.0758326608233119,
      "loss": 2.9638,
      "step": 150380
    },
    {
      "epoch": 241.8,
      "learning_rate": 0.07582944539244374,
      "loss": 2.9433,
      "step": 150400
    },
    {
      "epoch": 241.83,
      "learning_rate": 0.07582622996157556,
      "loss": 2.9516,
      "step": 150420
    },
    {
      "epoch": 241.86,
      "learning_rate": 0.0758230145307074,
      "loss": 2.9693,
      "step": 150440
    },
    {
      "epoch": 241.9,
      "learning_rate": 0.07581979909983923,
      "loss": 2.9197,
      "step": 150460
    },
    {
      "epoch": 241.93,
      "learning_rate": 0.07581658366897107,
      "loss": 2.9377,
      "step": 150480
    },
    {
      "epoch": 241.96,
      "learning_rate": 0.0758133682381029,
      "loss": 2.9378,
      "step": 150500
    },
    {
      "epoch": 241.99,
      "learning_rate": 0.07581015280723473,
      "loss": 2.9394,
      "step": 150520
    },
    {
      "epoch": 242.0,
      "eval_accuracy": {
        "accuracy": 0.37821659022001086
      },
      "eval_loss": 3.0540127754211426,
      "eval_runtime": 2.6705,
      "eval_samples_per_second": 4816.747,
      "eval_steps_per_second": 75.268,
      "step": 150524
    },
    {
      "epoch": 242.03,
      "learning_rate": 0.07580693737636657,
      "loss": 2.9237,
      "step": 150540
    },
    {
      "epoch": 242.06,
      "learning_rate": 0.07580372194549839,
      "loss": 2.9304,
      "step": 150560
    },
    {
      "epoch": 242.09,
      "learning_rate": 0.07580050651463023,
      "loss": 2.9439,
      "step": 150580
    },
    {
      "epoch": 242.12,
      "learning_rate": 0.07579729108376206,
      "loss": 2.9438,
      "step": 150600
    },
    {
      "epoch": 242.15,
      "learning_rate": 0.0757940756528939,
      "loss": 2.9636,
      "step": 150620
    },
    {
      "epoch": 242.19,
      "learning_rate": 0.07579086022202573,
      "loss": 2.9407,
      "step": 150640
    },
    {
      "epoch": 242.22,
      "learning_rate": 0.07578764479115756,
      "loss": 2.9343,
      "step": 150660
    },
    {
      "epoch": 242.25,
      "learning_rate": 0.0757844293602894,
      "loss": 2.9449,
      "step": 150680
    },
    {
      "epoch": 242.28,
      "learning_rate": 0.07578121392942122,
      "loss": 2.9364,
      "step": 150700
    },
    {
      "epoch": 242.32,
      "learning_rate": 0.07577799849855306,
      "loss": 2.9141,
      "step": 150720
    },
    {
      "epoch": 242.35,
      "learning_rate": 0.0757747830676849,
      "loss": 2.9393,
      "step": 150740
    },
    {
      "epoch": 242.38,
      "learning_rate": 0.07577156763681672,
      "loss": 2.9696,
      "step": 150760
    },
    {
      "epoch": 242.41,
      "learning_rate": 0.07576835220594856,
      "loss": 2.9389,
      "step": 150780
    },
    {
      "epoch": 242.44,
      "learning_rate": 0.07576513677508039,
      "loss": 2.94,
      "step": 150800
    },
    {
      "epoch": 242.48,
      "learning_rate": 0.07576192134421222,
      "loss": 2.8892,
      "step": 150820
    },
    {
      "epoch": 242.51,
      "learning_rate": 0.07575870591334406,
      "loss": 2.9344,
      "step": 150840
    },
    {
      "epoch": 242.54,
      "learning_rate": 0.07575549048247589,
      "loss": 2.9158,
      "step": 150860
    },
    {
      "epoch": 242.57,
      "learning_rate": 0.07575227505160773,
      "loss": 2.934,
      "step": 150880
    },
    {
      "epoch": 242.6,
      "learning_rate": 0.07574905962073955,
      "loss": 2.9533,
      "step": 150900
    },
    {
      "epoch": 242.64,
      "learning_rate": 0.07574584418987139,
      "loss": 2.9727,
      "step": 150920
    },
    {
      "epoch": 242.67,
      "learning_rate": 0.07574262875900321,
      "loss": 2.9305,
      "step": 150940
    },
    {
      "epoch": 242.7,
      "learning_rate": 0.07573941332813505,
      "loss": 2.8954,
      "step": 150960
    },
    {
      "epoch": 242.73,
      "learning_rate": 0.07573635866881029,
      "loss": 2.9508,
      "step": 150980
    },
    {
      "epoch": 242.77,
      "learning_rate": 0.07573314323794213,
      "loss": 2.9554,
      "step": 151000
    },
    {
      "epoch": 242.8,
      "learning_rate": 0.07572992780707397,
      "loss": 2.9049,
      "step": 151020
    },
    {
      "epoch": 242.83,
      "learning_rate": 0.07572671237620579,
      "loss": 2.9276,
      "step": 151040
    },
    {
      "epoch": 242.86,
      "learning_rate": 0.07572349694533763,
      "loss": 2.9123,
      "step": 151060
    },
    {
      "epoch": 242.89,
      "learning_rate": 0.07572028151446945,
      "loss": 2.9411,
      "step": 151080
    },
    {
      "epoch": 242.93,
      "learning_rate": 0.07571706608360129,
      "loss": 2.9499,
      "step": 151100
    },
    {
      "epoch": 242.96,
      "learning_rate": 0.07571385065273313,
      "loss": 2.9197,
      "step": 151120
    },
    {
      "epoch": 242.99,
      "learning_rate": 0.07571063522186496,
      "loss": 2.9479,
      "step": 151140
    },
    {
      "epoch": 243.0,
      "eval_accuracy": {
        "accuracy": 0.3809375728834642
      },
      "eval_loss": 3.07413911819458,
      "eval_runtime": 2.6592,
      "eval_samples_per_second": 4837.214,
      "eval_steps_per_second": 75.587,
      "step": 151146
    },
    {
      "epoch": 243.02,
      "learning_rate": 0.0757074197909968,
      "loss": 2.9619,
      "step": 151160
    },
    {
      "epoch": 243.05,
      "learning_rate": 0.07570420436012862,
      "loss": 2.9187,
      "step": 151180
    },
    {
      "epoch": 243.09,
      "learning_rate": 0.07570098892926046,
      "loss": 2.9432,
      "step": 151200
    },
    {
      "epoch": 243.12,
      "learning_rate": 0.07569777349839228,
      "loss": 2.8924,
      "step": 151220
    },
    {
      "epoch": 243.15,
      "learning_rate": 0.07569455806752412,
      "loss": 2.9146,
      "step": 151240
    },
    {
      "epoch": 243.18,
      "learning_rate": 0.07569134263665596,
      "loss": 2.9401,
      "step": 151260
    },
    {
      "epoch": 243.22,
      "learning_rate": 0.07568812720578778,
      "loss": 2.9706,
      "step": 151280
    },
    {
      "epoch": 243.25,
      "learning_rate": 0.07568491177491962,
      "loss": 2.9325,
      "step": 151300
    },
    {
      "epoch": 243.28,
      "learning_rate": 0.07568169634405145,
      "loss": 2.9365,
      "step": 151320
    },
    {
      "epoch": 243.31,
      "learning_rate": 0.07567848091318329,
      "loss": 2.9645,
      "step": 151340
    },
    {
      "epoch": 243.34,
      "learning_rate": 0.07567526548231512,
      "loss": 2.9561,
      "step": 151360
    },
    {
      "epoch": 243.38,
      "learning_rate": 0.07567205005144695,
      "loss": 2.9562,
      "step": 151380
    },
    {
      "epoch": 243.41,
      "learning_rate": 0.07566883462057879,
      "loss": 2.9372,
      "step": 151400
    },
    {
      "epoch": 243.44,
      "learning_rate": 0.07566561918971061,
      "loss": 2.9654,
      "step": 151420
    },
    {
      "epoch": 243.47,
      "learning_rate": 0.07566240375884245,
      "loss": 2.9483,
      "step": 151440
    },
    {
      "epoch": 243.5,
      "learning_rate": 0.07565918832797429,
      "loss": 2.9344,
      "step": 151460
    },
    {
      "epoch": 243.54,
      "learning_rate": 0.07565597289710611,
      "loss": 2.9049,
      "step": 151480
    },
    {
      "epoch": 243.57,
      "learning_rate": 0.07565275746623795,
      "loss": 2.9764,
      "step": 151500
    },
    {
      "epoch": 243.6,
      "learning_rate": 0.07564954203536978,
      "loss": 2.953,
      "step": 151520
    },
    {
      "epoch": 243.63,
      "learning_rate": 0.07564632660450162,
      "loss": 2.9315,
      "step": 151540
    },
    {
      "epoch": 243.67,
      "learning_rate": 0.07564311117363344,
      "loss": 2.9253,
      "step": 151560
    },
    {
      "epoch": 243.7,
      "learning_rate": 0.07563989574276528,
      "loss": 2.9202,
      "step": 151580
    },
    {
      "epoch": 243.73,
      "learning_rate": 0.07563668031189712,
      "loss": 2.9223,
      "step": 151600
    },
    {
      "epoch": 243.76,
      "learning_rate": 0.07563346488102894,
      "loss": 2.9628,
      "step": 151620
    },
    {
      "epoch": 243.79,
      "learning_rate": 0.07563024945016078,
      "loss": 2.9644,
      "step": 151640
    },
    {
      "epoch": 243.83,
      "learning_rate": 0.0756270340192926,
      "loss": 2.9296,
      "step": 151660
    },
    {
      "epoch": 243.86,
      "learning_rate": 0.07562381858842444,
      "loss": 2.9401,
      "step": 151680
    },
    {
      "epoch": 243.89,
      "learning_rate": 0.07562060315755628,
      "loss": 2.9476,
      "step": 151700
    },
    {
      "epoch": 243.92,
      "learning_rate": 0.0756173877266881,
      "loss": 2.9443,
      "step": 151720
    },
    {
      "epoch": 243.95,
      "learning_rate": 0.07561417229581995,
      "loss": 2.9791,
      "step": 151740
    },
    {
      "epoch": 243.99,
      "learning_rate": 0.07561095686495177,
      "loss": 2.9682,
      "step": 151760
    },
    {
      "epoch": 244.0,
      "eval_accuracy": {
        "accuracy": 0.3789940138381404
      },
      "eval_loss": 3.0519840717315674,
      "eval_runtime": 3.0325,
      "eval_samples_per_second": 4241.711,
      "eval_steps_per_second": 66.282,
      "step": 151768
    },
    {
      "epoch": 244.02,
      "learning_rate": 0.07560774143408361,
      "loss": 2.951,
      "step": 151780
    },
    {
      "epoch": 244.05,
      "learning_rate": 0.07560452600321545,
      "loss": 2.9599,
      "step": 151800
    },
    {
      "epoch": 244.08,
      "learning_rate": 0.07560131057234727,
      "loss": 2.9258,
      "step": 151820
    },
    {
      "epoch": 244.12,
      "learning_rate": 0.07559809514147911,
      "loss": 2.8927,
      "step": 151840
    },
    {
      "epoch": 244.15,
      "learning_rate": 0.07559487971061093,
      "loss": 2.9287,
      "step": 151860
    },
    {
      "epoch": 244.18,
      "learning_rate": 0.07559166427974277,
      "loss": 2.914,
      "step": 151880
    },
    {
      "epoch": 244.21,
      "learning_rate": 0.0755884488488746,
      "loss": 2.9151,
      "step": 151900
    },
    {
      "epoch": 244.24,
      "learning_rate": 0.07558523341800644,
      "loss": 2.9593,
      "step": 151920
    },
    {
      "epoch": 244.28,
      "learning_rate": 0.07558201798713828,
      "loss": 2.9614,
      "step": 151940
    },
    {
      "epoch": 244.31,
      "learning_rate": 0.0755788025562701,
      "loss": 2.9424,
      "step": 151960
    },
    {
      "epoch": 244.34,
      "learning_rate": 0.07557558712540192,
      "loss": 2.93,
      "step": 151980
    },
    {
      "epoch": 244.37,
      "learning_rate": 0.07557237169453376,
      "loss": 2.9198,
      "step": 152000
    },
    {
      "epoch": 244.41,
      "learning_rate": 0.0755691562636656,
      "loss": 2.9134,
      "step": 152020
    },
    {
      "epoch": 244.44,
      "learning_rate": 0.07556594083279744,
      "loss": 2.8783,
      "step": 152040
    },
    {
      "epoch": 244.47,
      "learning_rate": 0.07556272540192926,
      "loss": 2.933,
      "step": 152060
    },
    {
      "epoch": 244.5,
      "learning_rate": 0.07555950997106109,
      "loss": 2.919,
      "step": 152080
    },
    {
      "epoch": 244.53,
      "learning_rate": 0.07555629454019293,
      "loss": 2.9351,
      "step": 152100
    },
    {
      "epoch": 244.57,
      "learning_rate": 0.07555307910932477,
      "loss": 2.9418,
      "step": 152120
    },
    {
      "epoch": 244.6,
      "learning_rate": 0.0755498636784566,
      "loss": 2.9226,
      "step": 152140
    },
    {
      "epoch": 244.63,
      "learning_rate": 0.07554664824758843,
      "loss": 2.9454,
      "step": 152160
    },
    {
      "epoch": 244.66,
      "learning_rate": 0.07554343281672025,
      "loss": 2.9772,
      "step": 152180
    },
    {
      "epoch": 244.69,
      "learning_rate": 0.0755402173858521,
      "loss": 2.9192,
      "step": 152200
    },
    {
      "epoch": 244.73,
      "learning_rate": 0.07553700195498393,
      "loss": 2.9397,
      "step": 152220
    },
    {
      "epoch": 244.76,
      "learning_rate": 0.07553378652411576,
      "loss": 2.9654,
      "step": 152240
    },
    {
      "epoch": 244.79,
      "learning_rate": 0.0755305710932476,
      "loss": 2.965,
      "step": 152260
    },
    {
      "epoch": 244.82,
      "learning_rate": 0.07552735566237943,
      "loss": 2.9377,
      "step": 152280
    },
    {
      "epoch": 244.86,
      "learning_rate": 0.07552414023151126,
      "loss": 2.951,
      "step": 152300
    },
    {
      "epoch": 244.89,
      "learning_rate": 0.07552092480064308,
      "loss": 2.9423,
      "step": 152320
    },
    {
      "epoch": 244.92,
      "learning_rate": 0.07551770936977492,
      "loss": 2.9924,
      "step": 152340
    },
    {
      "epoch": 244.95,
      "learning_rate": 0.07551449393890676,
      "loss": 2.9626,
      "step": 152360
    },
    {
      "epoch": 244.98,
      "learning_rate": 0.0755112785080386,
      "loss": 2.9366,
      "step": 152380
    },
    {
      "epoch": 245.0,
      "eval_accuracy": {
        "accuracy": 0.38599082640130605
      },
      "eval_loss": 3.0530877113342285,
      "eval_runtime": 3.9784,
      "eval_samples_per_second": 3233.227,
      "eval_steps_per_second": 50.523,
      "step": 152390
    },
    {
      "epoch": 245.02,
      "learning_rate": 0.07550806307717042,
      "loss": 2.9472,
      "step": 152400
    },
    {
      "epoch": 245.05,
      "learning_rate": 0.07550484764630225,
      "loss": 2.9329,
      "step": 152420
    },
    {
      "epoch": 245.08,
      "learning_rate": 0.07550163221543409,
      "loss": 2.9151,
      "step": 152440
    },
    {
      "epoch": 245.11,
      "learning_rate": 0.07549841678456592,
      "loss": 2.9382,
      "step": 152460
    },
    {
      "epoch": 245.14,
      "learning_rate": 0.07549520135369776,
      "loss": 2.9284,
      "step": 152480
    },
    {
      "epoch": 245.18,
      "learning_rate": 0.07549198592282959,
      "loss": 2.9176,
      "step": 152500
    },
    {
      "epoch": 245.21,
      "learning_rate": 0.07548877049196141,
      "loss": 2.941,
      "step": 152520
    },
    {
      "epoch": 245.24,
      "learning_rate": 0.07548555506109325,
      "loss": 2.9351,
      "step": 152540
    },
    {
      "epoch": 245.27,
      "learning_rate": 0.07548233963022509,
      "loss": 2.9086,
      "step": 152560
    },
    {
      "epoch": 245.31,
      "learning_rate": 0.07547912419935691,
      "loss": 2.9278,
      "step": 152580
    },
    {
      "epoch": 245.34,
      "learning_rate": 0.07547590876848875,
      "loss": 2.8797,
      "step": 152600
    },
    {
      "epoch": 245.37,
      "learning_rate": 0.07547269333762058,
      "loss": 2.9234,
      "step": 152620
    },
    {
      "epoch": 245.4,
      "learning_rate": 0.07546947790675242,
      "loss": 2.9329,
      "step": 152640
    },
    {
      "epoch": 245.43,
      "learning_rate": 0.07546626247588424,
      "loss": 2.9227,
      "step": 152660
    },
    {
      "epoch": 245.47,
      "learning_rate": 0.07546304704501608,
      "loss": 2.9237,
      "step": 152680
    },
    {
      "epoch": 245.5,
      "learning_rate": 0.07545983161414792,
      "loss": 2.9812,
      "step": 152700
    },
    {
      "epoch": 245.53,
      "learning_rate": 0.07545661618327974,
      "loss": 2.9448,
      "step": 152720
    },
    {
      "epoch": 245.56,
      "learning_rate": 0.07545340075241158,
      "loss": 2.9486,
      "step": 152740
    },
    {
      "epoch": 245.59,
      "learning_rate": 0.0754501853215434,
      "loss": 2.913,
      "step": 152760
    },
    {
      "epoch": 245.63,
      "learning_rate": 0.07544696989067524,
      "loss": 2.9371,
      "step": 152780
    },
    {
      "epoch": 245.66,
      "learning_rate": 0.07544375445980708,
      "loss": 2.9631,
      "step": 152800
    },
    {
      "epoch": 245.69,
      "learning_rate": 0.07544053902893891,
      "loss": 2.9422,
      "step": 152820
    },
    {
      "epoch": 245.72,
      "learning_rate": 0.07543732359807075,
      "loss": 2.9173,
      "step": 152840
    },
    {
      "epoch": 245.76,
      "learning_rate": 0.07543410816720257,
      "loss": 2.9303,
      "step": 152860
    },
    {
      "epoch": 245.79,
      "learning_rate": 0.07543089273633441,
      "loss": 2.9359,
      "step": 152880
    },
    {
      "epoch": 245.82,
      "learning_rate": 0.07542767730546625,
      "loss": 2.9691,
      "step": 152900
    },
    {
      "epoch": 245.85,
      "learning_rate": 0.07542446187459807,
      "loss": 2.922,
      "step": 152920
    },
    {
      "epoch": 245.88,
      "learning_rate": 0.07542124644372991,
      "loss": 2.9123,
      "step": 152940
    },
    {
      "epoch": 245.92,
      "learning_rate": 0.07541803101286174,
      "loss": 2.9197,
      "step": 152960
    },
    {
      "epoch": 245.95,
      "learning_rate": 0.07541497635353699,
      "loss": 2.9229,
      "step": 152980
    },
    {
      "epoch": 245.98,
      "learning_rate": 0.07541176092266881,
      "loss": 2.8813,
      "step": 153000
    },
    {
      "epoch": 246.0,
      "eval_accuracy": {
        "accuracy": 0.3858353416776802
      },
      "eval_loss": 2.965923547744751,
      "eval_runtime": 2.7923,
      "eval_samples_per_second": 4606.542,
      "eval_steps_per_second": 71.983,
      "step": 153012
    },
    {
      "epoch": 246.01,
      "learning_rate": 0.07540854549180065,
      "loss": 2.9079,
      "step": 153020
    },
    {
      "epoch": 246.05,
      "learning_rate": 0.07540533006093247,
      "loss": 2.914,
      "step": 153040
    },
    {
      "epoch": 246.08,
      "learning_rate": 0.07540211463006431,
      "loss": 2.9295,
      "step": 153060
    },
    {
      "epoch": 246.11,
      "learning_rate": 0.07539889919919615,
      "loss": 2.9206,
      "step": 153080
    },
    {
      "epoch": 246.14,
      "learning_rate": 0.07539568376832798,
      "loss": 2.902,
      "step": 153100
    },
    {
      "epoch": 246.17,
      "learning_rate": 0.07539246833745981,
      "loss": 2.9194,
      "step": 153120
    },
    {
      "epoch": 246.21,
      "learning_rate": 0.07538925290659164,
      "loss": 2.8715,
      "step": 153140
    },
    {
      "epoch": 246.24,
      "learning_rate": 0.07538603747572348,
      "loss": 2.8911,
      "step": 153160
    },
    {
      "epoch": 246.27,
      "learning_rate": 0.07538282204485532,
      "loss": 2.8934,
      "step": 153180
    },
    {
      "epoch": 246.3,
      "learning_rate": 0.07537960661398714,
      "loss": 2.97,
      "step": 153200
    },
    {
      "epoch": 246.33,
      "learning_rate": 0.07537639118311898,
      "loss": 2.9555,
      "step": 153220
    },
    {
      "epoch": 246.37,
      "learning_rate": 0.0753731757522508,
      "loss": 2.9746,
      "step": 153240
    },
    {
      "epoch": 246.4,
      "learning_rate": 0.07536996032138264,
      "loss": 2.9677,
      "step": 153260
    },
    {
      "epoch": 246.43,
      "learning_rate": 0.07536674489051447,
      "loss": 2.9547,
      "step": 153280
    },
    {
      "epoch": 246.46,
      "learning_rate": 0.0753635294596463,
      "loss": 2.9415,
      "step": 153300
    },
    {
      "epoch": 246.5,
      "learning_rate": 0.07536031402877814,
      "loss": 2.9325,
      "step": 153320
    },
    {
      "epoch": 246.53,
      "learning_rate": 0.07535709859790997,
      "loss": 2.9575,
      "step": 153340
    },
    {
      "epoch": 246.56,
      "learning_rate": 0.07535388316704181,
      "loss": 2.8927,
      "step": 153360
    },
    {
      "epoch": 246.59,
      "learning_rate": 0.07535066773617363,
      "loss": 2.9271,
      "step": 153380
    },
    {
      "epoch": 246.62,
      "learning_rate": 0.07534745230530547,
      "loss": 2.9318,
      "step": 153400
    },
    {
      "epoch": 246.66,
      "learning_rate": 0.07534423687443731,
      "loss": 2.9474,
      "step": 153420
    },
    {
      "epoch": 246.69,
      "learning_rate": 0.07534102144356913,
      "loss": 2.9459,
      "step": 153440
    },
    {
      "epoch": 246.72,
      "learning_rate": 0.07533780601270097,
      "loss": 2.9478,
      "step": 153460
    },
    {
      "epoch": 246.75,
      "learning_rate": 0.0753345905818328,
      "loss": 2.9278,
      "step": 153480
    },
    {
      "epoch": 246.78,
      "learning_rate": 0.07533137515096464,
      "loss": 2.952,
      "step": 153500
    },
    {
      "epoch": 246.82,
      "learning_rate": 0.07532815972009647,
      "loss": 2.9525,
      "step": 153520
    },
    {
      "epoch": 246.85,
      "learning_rate": 0.0753249442892283,
      "loss": 2.9595,
      "step": 153540
    },
    {
      "epoch": 246.88,
      "learning_rate": 0.07532172885836014,
      "loss": 2.9298,
      "step": 153560
    },
    {
      "epoch": 246.91,
      "learning_rate": 0.07531851342749196,
      "loss": 2.9515,
      "step": 153580
    },
    {
      "epoch": 246.95,
      "learning_rate": 0.0753152979966238,
      "loss": 2.9349,
      "step": 153600
    },
    {
      "epoch": 246.98,
      "learning_rate": 0.07531208256575563,
      "loss": 2.9256,
      "step": 153620
    },
    {
      "epoch": 247.0,
      "eval_accuracy": {
        "accuracy": 0.38645728057218376
      },
      "eval_loss": 3.024289131164551,
      "eval_runtime": 2.7799,
      "eval_samples_per_second": 4627.171,
      "eval_steps_per_second": 72.305,
      "step": 153634
    },
    {
      "epoch": 247.01,
      "learning_rate": 0.07530886713488746,
      "loss": 2.9077,
      "step": 153640
    },
    {
      "epoch": 247.04,
      "learning_rate": 0.0753056517040193,
      "loss": 2.9383,
      "step": 153660
    },
    {
      "epoch": 247.07,
      "learning_rate": 0.07530243627315113,
      "loss": 2.913,
      "step": 153680
    },
    {
      "epoch": 247.11,
      "learning_rate": 0.07529922084228297,
      "loss": 2.9108,
      "step": 153700
    },
    {
      "epoch": 247.14,
      "learning_rate": 0.07529600541141479,
      "loss": 2.894,
      "step": 153720
    },
    {
      "epoch": 247.17,
      "learning_rate": 0.07529278998054663,
      "loss": 2.9114,
      "step": 153740
    },
    {
      "epoch": 247.2,
      "learning_rate": 0.07528957454967847,
      "loss": 2.9251,
      "step": 153760
    },
    {
      "epoch": 247.23,
      "learning_rate": 0.07528635911881029,
      "loss": 2.9228,
      "step": 153780
    },
    {
      "epoch": 247.27,
      "learning_rate": 0.07528314368794213,
      "loss": 2.9132,
      "step": 153800
    },
    {
      "epoch": 247.3,
      "learning_rate": 0.07527992825707396,
      "loss": 2.9302,
      "step": 153820
    },
    {
      "epoch": 247.33,
      "learning_rate": 0.0752767128262058,
      "loss": 2.9161,
      "step": 153840
    },
    {
      "epoch": 247.36,
      "learning_rate": 0.07527349739533763,
      "loss": 2.9122,
      "step": 153860
    },
    {
      "epoch": 247.4,
      "learning_rate": 0.07527028196446946,
      "loss": 2.9245,
      "step": 153880
    },
    {
      "epoch": 247.43,
      "learning_rate": 0.0752670665336013,
      "loss": 2.9117,
      "step": 153900
    },
    {
      "epoch": 247.46,
      "learning_rate": 0.07526385110273312,
      "loss": 2.9137,
      "step": 153920
    },
    {
      "epoch": 247.49,
      "learning_rate": 0.07526063567186496,
      "loss": 2.9199,
      "step": 153940
    },
    {
      "epoch": 247.52,
      "learning_rate": 0.07525742024099678,
      "loss": 2.915,
      "step": 153960
    },
    {
      "epoch": 247.56,
      "learning_rate": 0.07525420481012862,
      "loss": 2.8992,
      "step": 153980
    },
    {
      "epoch": 247.59,
      "learning_rate": 0.07525098937926046,
      "loss": 2.9266,
      "step": 154000
    },
    {
      "epoch": 247.62,
      "learning_rate": 0.07524777394839229,
      "loss": 2.9441,
      "step": 154020
    },
    {
      "epoch": 247.65,
      "learning_rate": 0.07524455851752412,
      "loss": 2.9333,
      "step": 154040
    },
    {
      "epoch": 247.68,
      "learning_rate": 0.07524134308665595,
      "loss": 2.9471,
      "step": 154060
    },
    {
      "epoch": 247.72,
      "learning_rate": 0.07523812765578779,
      "loss": 2.9168,
      "step": 154080
    },
    {
      "epoch": 247.75,
      "learning_rate": 0.07523491222491963,
      "loss": 2.966,
      "step": 154100
    },
    {
      "epoch": 247.78,
      "learning_rate": 0.07523169679405145,
      "loss": 2.9419,
      "step": 154120
    },
    {
      "epoch": 247.81,
      "learning_rate": 0.07522848136318329,
      "loss": 2.9837,
      "step": 154140
    },
    {
      "epoch": 247.85,
      "learning_rate": 0.07522526593231511,
      "loss": 2.977,
      "step": 154160
    },
    {
      "epoch": 247.88,
      "learning_rate": 0.07522205050144695,
      "loss": 2.9068,
      "step": 154180
    },
    {
      "epoch": 247.91,
      "learning_rate": 0.07521883507057879,
      "loss": 2.915,
      "step": 154200
    },
    {
      "epoch": 247.94,
      "learning_rate": 0.07521561963971062,
      "loss": 2.937,
      "step": 154220
    },
    {
      "epoch": 247.97,
      "learning_rate": 0.07521240420884245,
      "loss": 2.9393,
      "step": 154240
    },
    {
      "epoch": 248.0,
      "eval_accuracy": {
        "accuracy": 0.38054886107439945
      },
      "eval_loss": 3.0231211185455322,
      "eval_runtime": 2.7035,
      "eval_samples_per_second": 4757.973,
      "eval_steps_per_second": 74.349,
      "step": 154256
    },
    {
      "epoch": 248.01,
      "learning_rate": 0.07520918877797428,
      "loss": 2.9433,
      "step": 154260
    },
    {
      "epoch": 248.04,
      "learning_rate": 0.07520597334710612,
      "loss": 2.9363,
      "step": 154280
    },
    {
      "epoch": 248.07,
      "learning_rate": 0.07520275791623794,
      "loss": 2.894,
      "step": 154300
    },
    {
      "epoch": 248.1,
      "learning_rate": 0.07519954248536978,
      "loss": 2.9273,
      "step": 154320
    },
    {
      "epoch": 248.14,
      "learning_rate": 0.07519632705450162,
      "loss": 2.9314,
      "step": 154340
    },
    {
      "epoch": 248.17,
      "learning_rate": 0.07519311162363344,
      "loss": 2.9254,
      "step": 154360
    },
    {
      "epoch": 248.2,
      "learning_rate": 0.07518989619276527,
      "loss": 2.9436,
      "step": 154380
    },
    {
      "epoch": 248.23,
      "learning_rate": 0.0751866807618971,
      "loss": 2.8992,
      "step": 154400
    },
    {
      "epoch": 248.26,
      "learning_rate": 0.07518346533102895,
      "loss": 2.9156,
      "step": 154420
    },
    {
      "epoch": 248.3,
      "learning_rate": 0.07518024990016078,
      "loss": 2.9627,
      "step": 154440
    },
    {
      "epoch": 248.33,
      "learning_rate": 0.07517703446929261,
      "loss": 2.9198,
      "step": 154460
    },
    {
      "epoch": 248.36,
      "learning_rate": 0.07517381903842445,
      "loss": 2.9455,
      "step": 154480
    },
    {
      "epoch": 248.39,
      "learning_rate": 0.07517060360755627,
      "loss": 2.9696,
      "step": 154500
    },
    {
      "epoch": 248.42,
      "learning_rate": 0.07516738817668811,
      "loss": 2.9061,
      "step": 154520
    },
    {
      "epoch": 248.46,
      "learning_rate": 0.07516417274581995,
      "loss": 2.9062,
      "step": 154540
    },
    {
      "epoch": 248.49,
      "learning_rate": 0.07516095731495177,
      "loss": 2.9256,
      "step": 154560
    },
    {
      "epoch": 248.52,
      "learning_rate": 0.07515774188408361,
      "loss": 2.9322,
      "step": 154580
    },
    {
      "epoch": 248.55,
      "learning_rate": 0.07515452645321544,
      "loss": 2.9475,
      "step": 154600
    },
    {
      "epoch": 248.59,
      "learning_rate": 0.07515131102234728,
      "loss": 2.9031,
      "step": 154620
    },
    {
      "epoch": 248.62,
      "learning_rate": 0.0751480955914791,
      "loss": 2.9226,
      "step": 154640
    },
    {
      "epoch": 248.65,
      "learning_rate": 0.07514488016061094,
      "loss": 2.9164,
      "step": 154660
    },
    {
      "epoch": 248.68,
      "learning_rate": 0.07514166472974278,
      "loss": 2.8928,
      "step": 154680
    },
    {
      "epoch": 248.71,
      "learning_rate": 0.0751384492988746,
      "loss": 2.9443,
      "step": 154700
    },
    {
      "epoch": 248.75,
      "learning_rate": 0.07513523386800643,
      "loss": 2.9676,
      "step": 154720
    },
    {
      "epoch": 248.78,
      "learning_rate": 0.07513201843713826,
      "loss": 2.963,
      "step": 154740
    },
    {
      "epoch": 248.81,
      "learning_rate": 0.0751288030062701,
      "loss": 2.9357,
      "step": 154760
    },
    {
      "epoch": 248.84,
      "learning_rate": 0.07512558757540194,
      "loss": 2.9184,
      "step": 154780
    },
    {
      "epoch": 248.87,
      "learning_rate": 0.07512237214453377,
      "loss": 2.917,
      "step": 154800
    },
    {
      "epoch": 248.91,
      "learning_rate": 0.07511915671366559,
      "loss": 2.9415,
      "step": 154820
    },
    {
      "epoch": 248.94,
      "learning_rate": 0.07511594128279743,
      "loss": 2.912,
      "step": 154840
    },
    {
      "epoch": 248.97,
      "learning_rate": 0.07511272585192927,
      "loss": 2.9057,
      "step": 154860
    },
    {
      "epoch": 249.0,
      "eval_accuracy": {
        "accuracy": 0.38179273886340664
      },
      "eval_loss": 3.0264902114868164,
      "eval_runtime": 3.1357,
      "eval_samples_per_second": 4102.052,
      "eval_steps_per_second": 64.1,
      "step": 154878
    },
    {
      "epoch": 249.0,
      "learning_rate": 0.07510951042106111,
      "loss": 2.9202,
      "step": 154880
    },
    {
      "epoch": 249.04,
      "learning_rate": 0.07510629499019293,
      "loss": 2.9566,
      "step": 154900
    },
    {
      "epoch": 249.07,
      "learning_rate": 0.07510307955932476,
      "loss": 2.9371,
      "step": 154920
    },
    {
      "epoch": 249.1,
      "learning_rate": 0.0750998641284566,
      "loss": 2.9439,
      "step": 154940
    },
    {
      "epoch": 249.13,
      "learning_rate": 0.07509664869758843,
      "loss": 2.9215,
      "step": 154960
    },
    {
      "epoch": 249.16,
      "learning_rate": 0.07509343326672026,
      "loss": 2.961,
      "step": 154980
    },
    {
      "epoch": 249.2,
      "learning_rate": 0.0750902178358521,
      "loss": 2.9192,
      "step": 155000
    },
    {
      "epoch": 249.23,
      "learning_rate": 0.07508700240498392,
      "loss": 2.898,
      "step": 155020
    },
    {
      "epoch": 249.26,
      "learning_rate": 0.07508394774565917,
      "loss": 2.9168,
      "step": 155040
    },
    {
      "epoch": 249.29,
      "learning_rate": 0.075080732314791,
      "loss": 2.9122,
      "step": 155060
    },
    {
      "epoch": 249.32,
      "learning_rate": 0.07507751688392283,
      "loss": 2.9596,
      "step": 155080
    },
    {
      "epoch": 249.36,
      "learning_rate": 0.07507430145305466,
      "loss": 2.9455,
      "step": 155100
    },
    {
      "epoch": 249.39,
      "learning_rate": 0.0750710860221865,
      "loss": 2.9619,
      "step": 155120
    },
    {
      "epoch": 249.42,
      "learning_rate": 0.07506787059131834,
      "loss": 2.9455,
      "step": 155140
    },
    {
      "epoch": 249.45,
      "learning_rate": 0.07506465516045016,
      "loss": 2.9756,
      "step": 155160
    },
    {
      "epoch": 249.49,
      "learning_rate": 0.075061439729582,
      "loss": 2.8865,
      "step": 155180
    },
    {
      "epoch": 249.52,
      "learning_rate": 0.07505822429871382,
      "loss": 2.9037,
      "step": 155200
    },
    {
      "epoch": 249.55,
      "learning_rate": 0.07505500886784568,
      "loss": 2.884,
      "step": 155220
    },
    {
      "epoch": 249.58,
      "learning_rate": 0.0750517934369775,
      "loss": 2.9414,
      "step": 155240
    },
    {
      "epoch": 249.61,
      "learning_rate": 0.07504857800610933,
      "loss": 2.978,
      "step": 155260
    },
    {
      "epoch": 249.65,
      "learning_rate": 0.07504536257524116,
      "loss": 2.9518,
      "step": 155280
    },
    {
      "epoch": 249.68,
      "learning_rate": 0.07504214714437299,
      "loss": 2.8789,
      "step": 155300
    },
    {
      "epoch": 249.71,
      "learning_rate": 0.07503893171350483,
      "loss": 2.9226,
      "step": 155320
    },
    {
      "epoch": 249.74,
      "learning_rate": 0.07503571628263665,
      "loss": 2.9389,
      "step": 155340
    },
    {
      "epoch": 249.77,
      "learning_rate": 0.07503250085176849,
      "loss": 2.9499,
      "step": 155360
    },
    {
      "epoch": 249.81,
      "learning_rate": 0.07502928542090033,
      "loss": 2.9626,
      "step": 155380
    },
    {
      "epoch": 249.84,
      "learning_rate": 0.07502606999003215,
      "loss": 2.9035,
      "step": 155400
    },
    {
      "epoch": 249.87,
      "learning_rate": 0.07502285455916399,
      "loss": 2.9194,
      "step": 155420
    },
    {
      "epoch": 249.9,
      "learning_rate": 0.07501963912829582,
      "loss": 2.9461,
      "step": 155440
    },
    {
      "epoch": 249.94,
      "learning_rate": 0.07501642369742766,
      "loss": 2.9238,
      "step": 155460
    },
    {
      "epoch": 249.97,
      "learning_rate": 0.0750132082665595,
      "loss": 2.9334,
      "step": 155480
    },
    {
      "epoch": 250.0,
      "learning_rate": 0.07500999283569132,
      "loss": 2.9306,
      "step": 155500
    },
    {
      "epoch": 250.0,
      "eval_accuracy": {
        "accuracy": 0.3832698437378528
      },
      "eval_loss": 3.0333776473999023,
      "eval_runtime": 3.0447,
      "eval_samples_per_second": 4224.692,
      "eval_steps_per_second": 66.016,
      "step": 155500
    },
    {
      "epoch": 250.03,
      "learning_rate": 0.07500677740482316,
      "loss": 2.945,
      "step": 155520
    },
    {
      "epoch": 250.06,
      "learning_rate": 0.07500356197395498,
      "loss": 2.9298,
      "step": 155540
    },
    {
      "epoch": 250.1,
      "learning_rate": 0.07500034654308682,
      "loss": 2.9397,
      "step": 155560
    },
    {
      "epoch": 250.13,
      "learning_rate": 0.07499713111221865,
      "loss": 2.9772,
      "step": 155580
    },
    {
      "epoch": 250.16,
      "learning_rate": 0.07499391568135048,
      "loss": 2.9073,
      "step": 155600
    },
    {
      "epoch": 250.19,
      "learning_rate": 0.07499070025048232,
      "loss": 2.9191,
      "step": 155620
    },
    {
      "epoch": 250.23,
      "learning_rate": 0.07498748481961415,
      "loss": 2.9035,
      "step": 155640
    },
    {
      "epoch": 250.26,
      "learning_rate": 0.07498426938874599,
      "loss": 2.8979,
      "step": 155660
    },
    {
      "epoch": 250.29,
      "learning_rate": 0.07498105395787781,
      "loss": 2.8957,
      "step": 155680
    },
    {
      "epoch": 250.32,
      "learning_rate": 0.07497783852700965,
      "loss": 2.9446,
      "step": 155700
    },
    {
      "epoch": 250.35,
      "learning_rate": 0.07497462309614149,
      "loss": 2.9314,
      "step": 155720
    },
    {
      "epoch": 250.39,
      "learning_rate": 0.07497140766527331,
      "loss": 2.9285,
      "step": 155740
    },
    {
      "epoch": 250.42,
      "learning_rate": 0.07496819223440515,
      "loss": 2.9421,
      "step": 155760
    },
    {
      "epoch": 250.45,
      "learning_rate": 0.07496497680353698,
      "loss": 2.9377,
      "step": 155780
    },
    {
      "epoch": 250.48,
      "learning_rate": 0.07496176137266881,
      "loss": 2.9053,
      "step": 155800
    },
    {
      "epoch": 250.51,
      "learning_rate": 0.07495854594180065,
      "loss": 2.8892,
      "step": 155820
    },
    {
      "epoch": 250.55,
      "learning_rate": 0.07495533051093248,
      "loss": 2.946,
      "step": 155840
    },
    {
      "epoch": 250.58,
      "learning_rate": 0.07495211508006432,
      "loss": 2.9021,
      "step": 155860
    },
    {
      "epoch": 250.61,
      "learning_rate": 0.07494889964919614,
      "loss": 2.9056,
      "step": 155880
    },
    {
      "epoch": 250.64,
      "learning_rate": 0.07494568421832798,
      "loss": 2.9481,
      "step": 155900
    },
    {
      "epoch": 250.68,
      "learning_rate": 0.0749424687874598,
      "loss": 2.8944,
      "step": 155920
    },
    {
      "epoch": 250.71,
      "learning_rate": 0.07493925335659164,
      "loss": 2.9249,
      "step": 155940
    },
    {
      "epoch": 250.74,
      "learning_rate": 0.07493603792572348,
      "loss": 2.9624,
      "step": 155960
    },
    {
      "epoch": 250.77,
      "learning_rate": 0.0749328224948553,
      "loss": 2.9321,
      "step": 155980
    },
    {
      "epoch": 250.8,
      "learning_rate": 0.07492960706398714,
      "loss": 2.9672,
      "step": 156000
    },
    {
      "epoch": 250.84,
      "learning_rate": 0.07492639163311897,
      "loss": 2.9606,
      "step": 156020
    },
    {
      "epoch": 250.87,
      "learning_rate": 0.07492317620225081,
      "loss": 2.968,
      "step": 156040
    },
    {
      "epoch": 250.9,
      "learning_rate": 0.07491996077138265,
      "loss": 2.9527,
      "step": 156060
    },
    {
      "epoch": 250.93,
      "learning_rate": 0.07491674534051447,
      "loss": 2.9418,
      "step": 156080
    },
    {
      "epoch": 250.96,
      "learning_rate": 0.07491352990964631,
      "loss": 2.9244,
      "step": 156100
    },
    {
      "epoch": 251.0,
      "learning_rate": 0.07491031447877813,
      "loss": 2.9602,
      "step": 156120
    },
    {
      "epoch": 251.0,
      "eval_accuracy": {
        "accuracy": 0.3766617429837518
      },
      "eval_loss": 3.087667942047119,
      "eval_runtime": 2.7749,
      "eval_samples_per_second": 4635.505,
      "eval_steps_per_second": 72.435,
      "step": 156122
    },
    {
      "epoch": 251.03,
      "learning_rate": 0.07490709904790997,
      "loss": 2.953,
      "step": 156140
    },
    {
      "epoch": 251.06,
      "learning_rate": 0.07490388361704181,
      "loss": 2.8867,
      "step": 156160
    },
    {
      "epoch": 251.09,
      "learning_rate": 0.07490066818617364,
      "loss": 2.9213,
      "step": 156180
    },
    {
      "epoch": 251.13,
      "learning_rate": 0.07489745275530547,
      "loss": 2.9142,
      "step": 156200
    },
    {
      "epoch": 251.16,
      "learning_rate": 0.0748942373244373,
      "loss": 2.9406,
      "step": 156220
    },
    {
      "epoch": 251.19,
      "learning_rate": 0.07489102189356914,
      "loss": 2.9269,
      "step": 156240
    },
    {
      "epoch": 251.22,
      "learning_rate": 0.07488780646270096,
      "loss": 2.9178,
      "step": 156260
    },
    {
      "epoch": 251.25,
      "learning_rate": 0.0748845910318328,
      "loss": 2.9281,
      "step": 156280
    },
    {
      "epoch": 251.29,
      "learning_rate": 0.07488137560096464,
      "loss": 2.9509,
      "step": 156300
    },
    {
      "epoch": 251.32,
      "learning_rate": 0.07487816017009646,
      "loss": 2.9304,
      "step": 156320
    },
    {
      "epoch": 251.35,
      "learning_rate": 0.0748749447392283,
      "loss": 2.91,
      "step": 156340
    },
    {
      "epoch": 251.38,
      "learning_rate": 0.07487172930836013,
      "loss": 2.9081,
      "step": 156360
    },
    {
      "epoch": 251.41,
      "learning_rate": 0.07486851387749197,
      "loss": 2.9107,
      "step": 156380
    },
    {
      "epoch": 251.45,
      "learning_rate": 0.0748652984466238,
      "loss": 2.8861,
      "step": 156400
    },
    {
      "epoch": 251.48,
      "learning_rate": 0.07486208301575563,
      "loss": 2.8989,
      "step": 156420
    },
    {
      "epoch": 251.51,
      "learning_rate": 0.07485886758488747,
      "loss": 2.8985,
      "step": 156440
    },
    {
      "epoch": 251.54,
      "learning_rate": 0.07485565215401929,
      "loss": 2.9403,
      "step": 156460
    },
    {
      "epoch": 251.58,
      "learning_rate": 0.07485243672315113,
      "loss": 2.9254,
      "step": 156480
    },
    {
      "epoch": 251.61,
      "learning_rate": 0.07484922129228297,
      "loss": 2.9181,
      "step": 156500
    },
    {
      "epoch": 251.64,
      "learning_rate": 0.0748460058614148,
      "loss": 2.8964,
      "step": 156520
    },
    {
      "epoch": 251.67,
      "learning_rate": 0.07484279043054663,
      "loss": 2.8988,
      "step": 156540
    },
    {
      "epoch": 251.7,
      "learning_rate": 0.07483957499967846,
      "loss": 2.908,
      "step": 156560
    },
    {
      "epoch": 251.74,
      "learning_rate": 0.0748363595688103,
      "loss": 2.8983,
      "step": 156580
    },
    {
      "epoch": 251.77,
      "learning_rate": 0.07483314413794212,
      "loss": 2.9166,
      "step": 156600
    },
    {
      "epoch": 251.8,
      "learning_rate": 0.07482992870707396,
      "loss": 2.936,
      "step": 156620
    },
    {
      "epoch": 251.83,
      "learning_rate": 0.0748267132762058,
      "loss": 2.9224,
      "step": 156640
    },
    {
      "epoch": 251.86,
      "learning_rate": 0.07482349784533762,
      "loss": 2.9258,
      "step": 156660
    },
    {
      "epoch": 251.9,
      "learning_rate": 0.07482028241446946,
      "loss": 2.9436,
      "step": 156680
    },
    {
      "epoch": 251.93,
      "learning_rate": 0.07481706698360129,
      "loss": 2.9061,
      "step": 156700
    },
    {
      "epoch": 251.96,
      "learning_rate": 0.07481385155273312,
      "loss": 2.9398,
      "step": 156720
    },
    {
      "epoch": 251.99,
      "learning_rate": 0.07481063612186496,
      "loss": 2.9528,
      "step": 156740
    },
    {
      "epoch": 252.0,
      "eval_accuracy": {
        "accuracy": 0.37984917981808286
      },
      "eval_loss": 3.043759822845459,
      "eval_runtime": 3.1273,
      "eval_samples_per_second": 4113.099,
      "eval_steps_per_second": 64.272,
      "step": 156744
    },
    {
      "epoch": 252.03,
      "learning_rate": 0.07480742069099679,
      "loss": 2.9353,
      "step": 156760
    },
    {
      "epoch": 252.06,
      "learning_rate": 0.07480420526012863,
      "loss": 2.9308,
      "step": 156780
    },
    {
      "epoch": 252.09,
      "learning_rate": 0.07480098982926045,
      "loss": 2.9133,
      "step": 156800
    },
    {
      "epoch": 252.12,
      "learning_rate": 0.07479777439839229,
      "loss": 2.9374,
      "step": 156820
    },
    {
      "epoch": 252.15,
      "learning_rate": 0.07479455896752413,
      "loss": 2.9382,
      "step": 156840
    },
    {
      "epoch": 252.19,
      "learning_rate": 0.07479134353665595,
      "loss": 2.9425,
      "step": 156860
    },
    {
      "epoch": 252.22,
      "learning_rate": 0.07478812810578779,
      "loss": 2.9448,
      "step": 156880
    },
    {
      "epoch": 252.25,
      "learning_rate": 0.07478491267491962,
      "loss": 2.9202,
      "step": 156900
    },
    {
      "epoch": 252.28,
      "learning_rate": 0.07478169724405145,
      "loss": 2.916,
      "step": 156920
    },
    {
      "epoch": 252.32,
      "learning_rate": 0.07477848181318328,
      "loss": 2.8914,
      "step": 156940
    },
    {
      "epoch": 252.35,
      "learning_rate": 0.07477526638231512,
      "loss": 2.9025,
      "step": 156960
    },
    {
      "epoch": 252.38,
      "learning_rate": 0.07477205095144696,
      "loss": 2.9424,
      "step": 156980
    },
    {
      "epoch": 252.41,
      "learning_rate": 0.07476883552057878,
      "loss": 2.9555,
      "step": 157000
    },
    {
      "epoch": 252.44,
      "learning_rate": 0.07476562008971062,
      "loss": 2.9373,
      "step": 157020
    },
    {
      "epoch": 252.48,
      "learning_rate": 0.07476240465884244,
      "loss": 2.9139,
      "step": 157040
    },
    {
      "epoch": 252.51,
      "learning_rate": 0.07475918922797428,
      "loss": 2.9414,
      "step": 157060
    },
    {
      "epoch": 252.54,
      "learning_rate": 0.07475613456864953,
      "loss": 2.9129,
      "step": 157080
    },
    {
      "epoch": 252.57,
      "learning_rate": 0.07475291913778136,
      "loss": 2.9177,
      "step": 157100
    },
    {
      "epoch": 252.6,
      "learning_rate": 0.07474970370691318,
      "loss": 2.9584,
      "step": 157120
    },
    {
      "epoch": 252.64,
      "learning_rate": 0.07474648827604502,
      "loss": 2.9415,
      "step": 157140
    },
    {
      "epoch": 252.67,
      "learning_rate": 0.07474327284517684,
      "loss": 2.9411,
      "step": 157160
    },
    {
      "epoch": 252.7,
      "learning_rate": 0.0747400574143087,
      "loss": 2.9107,
      "step": 157180
    },
    {
      "epoch": 252.73,
      "learning_rate": 0.07473684198344051,
      "loss": 2.9317,
      "step": 157200
    },
    {
      "epoch": 252.77,
      "learning_rate": 0.07473362655257235,
      "loss": 2.9163,
      "step": 157220
    },
    {
      "epoch": 252.8,
      "learning_rate": 0.07473041112170418,
      "loss": 2.9122,
      "step": 157240
    },
    {
      "epoch": 252.83,
      "learning_rate": 0.07472719569083601,
      "loss": 2.893,
      "step": 157260
    },
    {
      "epoch": 252.86,
      "learning_rate": 0.07472398025996786,
      "loss": 2.9026,
      "step": 157280
    },
    {
      "epoch": 252.89,
      "learning_rate": 0.07472076482909967,
      "loss": 2.9215,
      "step": 157300
    },
    {
      "epoch": 252.93,
      "learning_rate": 0.07471754939823151,
      "loss": 2.9232,
      "step": 157320
    },
    {
      "epoch": 252.96,
      "learning_rate": 0.07471433396736335,
      "loss": 2.9804,
      "step": 157340
    },
    {
      "epoch": 252.99,
      "learning_rate": 0.07471111853649517,
      "loss": 2.9086,
      "step": 157360
    },
    {
      "epoch": 253.0,
      "eval_accuracy": {
        "accuracy": 0.3835030708232916
      },
      "eval_loss": 3.0095908641815186,
      "eval_runtime": 3.1629,
      "eval_samples_per_second": 4066.887,
      "eval_steps_per_second": 63.55,
      "step": 157366
    },
    {
      "epoch": 253.02,
      "learning_rate": 0.07470790310562703,
      "loss": 2.921,
      "step": 157380
    },
    {
      "epoch": 253.05,
      "learning_rate": 0.07470468767475884,
      "loss": 2.9259,
      "step": 157400
    },
    {
      "epoch": 253.09,
      "learning_rate": 0.07470147224389069,
      "loss": 2.906,
      "step": 157420
    },
    {
      "epoch": 253.12,
      "learning_rate": 0.07469825681302251,
      "loss": 2.9211,
      "step": 157440
    },
    {
      "epoch": 253.15,
      "learning_rate": 0.07469504138215434,
      "loss": 2.9011,
      "step": 157460
    },
    {
      "epoch": 253.18,
      "learning_rate": 0.07469182595128618,
      "loss": 2.8732,
      "step": 157480
    },
    {
      "epoch": 253.22,
      "learning_rate": 0.074688610520418,
      "loss": 2.9222,
      "step": 157500
    },
    {
      "epoch": 253.25,
      "learning_rate": 0.07468539508954986,
      "loss": 2.9136,
      "step": 157520
    },
    {
      "epoch": 253.28,
      "learning_rate": 0.07468217965868168,
      "loss": 2.9088,
      "step": 157540
    },
    {
      "epoch": 253.31,
      "learning_rate": 0.0746789642278135,
      "loss": 2.9139,
      "step": 157560
    },
    {
      "epoch": 253.34,
      "learning_rate": 0.07467574879694534,
      "loss": 2.9234,
      "step": 157580
    },
    {
      "epoch": 253.38,
      "learning_rate": 0.07467253336607717,
      "loss": 2.9105,
      "step": 157600
    },
    {
      "epoch": 253.41,
      "learning_rate": 0.07466931793520902,
      "loss": 2.916,
      "step": 157620
    },
    {
      "epoch": 253.44,
      "learning_rate": 0.07466610250434083,
      "loss": 2.9021,
      "step": 157640
    },
    {
      "epoch": 253.47,
      "learning_rate": 0.07466288707347267,
      "loss": 2.9297,
      "step": 157660
    },
    {
      "epoch": 253.5,
      "learning_rate": 0.07465967164260451,
      "loss": 2.9549,
      "step": 157680
    },
    {
      "epoch": 253.54,
      "learning_rate": 0.07465645621173633,
      "loss": 2.9256,
      "step": 157700
    },
    {
      "epoch": 253.57,
      "learning_rate": 0.07465324078086819,
      "loss": 2.8908,
      "step": 157720
    },
    {
      "epoch": 253.6,
      "learning_rate": 0.07465002535,
      "loss": 2.9275,
      "step": 157740
    },
    {
      "epoch": 253.63,
      "learning_rate": 0.07464680991913183,
      "loss": 2.9002,
      "step": 157760
    },
    {
      "epoch": 253.67,
      "learning_rate": 0.07464359448826367,
      "loss": 2.9154,
      "step": 157780
    },
    {
      "epoch": 253.7,
      "learning_rate": 0.0746403790573955,
      "loss": 2.9401,
      "step": 157800
    },
    {
      "epoch": 253.73,
      "learning_rate": 0.07463716362652734,
      "loss": 2.942,
      "step": 157820
    },
    {
      "epoch": 253.76,
      "learning_rate": 0.07463394819565916,
      "loss": 2.9091,
      "step": 157840
    },
    {
      "epoch": 253.79,
      "learning_rate": 0.074630732764791,
      "loss": 2.9213,
      "step": 157860
    },
    {
      "epoch": 253.83,
      "learning_rate": 0.07462751733392284,
      "loss": 2.9445,
      "step": 157880
    },
    {
      "epoch": 253.86,
      "learning_rate": 0.07462430190305466,
      "loss": 2.9055,
      "step": 157900
    },
    {
      "epoch": 253.89,
      "learning_rate": 0.0746210864721865,
      "loss": 2.9149,
      "step": 157920
    },
    {
      "epoch": 253.92,
      "learning_rate": 0.07461787104131833,
      "loss": 2.9055,
      "step": 157940
    },
    {
      "epoch": 253.95,
      "learning_rate": 0.07461465561045016,
      "loss": 2.93,
      "step": 157960
    },
    {
      "epoch": 253.99,
      "learning_rate": 0.07461144017958199,
      "loss": 2.9301,
      "step": 157980
    },
    {
      "epoch": 254.0,
      "eval_accuracy": {
        "accuracy": 0.3771281971546296
      },
      "eval_loss": 3.0629730224609375,
      "eval_runtime": 3.0536,
      "eval_samples_per_second": 4212.397,
      "eval_steps_per_second": 65.824,
      "step": 157988
    },
    {
      "epoch": 254.02,
      "learning_rate": 0.07460822474871383,
      "loss": 2.9261,
      "step": 158000
    },
    {
      "epoch": 254.05,
      "learning_rate": 0.07460500931784567,
      "loss": 2.917,
      "step": 158020
    },
    {
      "epoch": 254.08,
      "learning_rate": 0.07460179388697749,
      "loss": 2.8998,
      "step": 158040
    },
    {
      "epoch": 254.12,
      "learning_rate": 0.07459857845610934,
      "loss": 2.9209,
      "step": 158060
    },
    {
      "epoch": 254.15,
      "learning_rate": 0.07459536302524115,
      "loss": 2.9034,
      "step": 158080
    },
    {
      "epoch": 254.18,
      "learning_rate": 0.07459214759437299,
      "loss": 2.9352,
      "step": 158100
    },
    {
      "epoch": 254.21,
      "learning_rate": 0.07458893216350483,
      "loss": 2.9422,
      "step": 158120
    },
    {
      "epoch": 254.24,
      "learning_rate": 0.07458571673263666,
      "loss": 2.914,
      "step": 158140
    },
    {
      "epoch": 254.28,
      "learning_rate": 0.0745825013017685,
      "loss": 2.9162,
      "step": 158160
    },
    {
      "epoch": 254.31,
      "learning_rate": 0.07457928587090032,
      "loss": 2.934,
      "step": 158180
    },
    {
      "epoch": 254.34,
      "learning_rate": 0.07457607044003216,
      "loss": 2.9219,
      "step": 158200
    },
    {
      "epoch": 254.37,
      "learning_rate": 0.074572855009164,
      "loss": 2.8944,
      "step": 158220
    },
    {
      "epoch": 254.41,
      "learning_rate": 0.07456963957829582,
      "loss": 2.899,
      "step": 158240
    },
    {
      "epoch": 254.44,
      "learning_rate": 0.07456642414742766,
      "loss": 2.9314,
      "step": 158260
    },
    {
      "epoch": 254.47,
      "learning_rate": 0.07456320871655948,
      "loss": 2.9118,
      "step": 158280
    },
    {
      "epoch": 254.5,
      "learning_rate": 0.07455999328569132,
      "loss": 2.9065,
      "step": 158300
    },
    {
      "epoch": 254.53,
      "learning_rate": 0.07455677785482315,
      "loss": 2.9193,
      "step": 158320
    },
    {
      "epoch": 254.57,
      "learning_rate": 0.07455356242395499,
      "loss": 2.9474,
      "step": 158340
    },
    {
      "epoch": 254.6,
      "learning_rate": 0.07455034699308682,
      "loss": 2.9398,
      "step": 158360
    },
    {
      "epoch": 254.63,
      "learning_rate": 0.07454713156221865,
      "loss": 2.9271,
      "step": 158380
    },
    {
      "epoch": 254.66,
      "learning_rate": 0.07454391613135049,
      "loss": 2.9114,
      "step": 158400
    },
    {
      "epoch": 254.69,
      "learning_rate": 0.07454070070048231,
      "loss": 2.9628,
      "step": 158420
    },
    {
      "epoch": 254.73,
      "learning_rate": 0.07453748526961415,
      "loss": 2.9141,
      "step": 158440
    },
    {
      "epoch": 254.76,
      "learning_rate": 0.07453426983874599,
      "loss": 2.9166,
      "step": 158460
    },
    {
      "epoch": 254.79,
      "learning_rate": 0.07453105440787781,
      "loss": 2.8913,
      "step": 158480
    },
    {
      "epoch": 254.82,
      "learning_rate": 0.07452783897700965,
      "loss": 2.8945,
      "step": 158500
    },
    {
      "epoch": 254.86,
      "learning_rate": 0.07452462354614148,
      "loss": 2.9417,
      "step": 158520
    },
    {
      "epoch": 254.89,
      "learning_rate": 0.07452140811527332,
      "loss": 2.9336,
      "step": 158540
    },
    {
      "epoch": 254.92,
      "learning_rate": 0.07451819268440515,
      "loss": 2.888,
      "step": 158560
    },
    {
      "epoch": 254.95,
      "learning_rate": 0.07451497725353698,
      "loss": 2.8995,
      "step": 158580
    },
    {
      "epoch": 254.98,
      "learning_rate": 0.07451176182266882,
      "loss": 2.931,
      "step": 158600
    },
    {
      "epoch": 255.0,
      "eval_accuracy": {
        "accuracy": 0.38878955142657234
      },
      "eval_loss": 2.987771987915039,
      "eval_runtime": 2.6753,
      "eval_samples_per_second": 4808.045,
      "eval_steps_per_second": 75.132,
      "step": 158610
    },
    {
      "epoch": 255.02,
      "learning_rate": 0.07450854639180064,
      "loss": 2.9318,
      "step": 158620
    },
    {
      "epoch": 255.05,
      "learning_rate": 0.07450533096093248,
      "loss": 2.9267,
      "step": 158640
    },
    {
      "epoch": 255.08,
      "learning_rate": 0.0745021155300643,
      "loss": 2.9357,
      "step": 158660
    },
    {
      "epoch": 255.11,
      "learning_rate": 0.07449890009919614,
      "loss": 2.9177,
      "step": 158680
    },
    {
      "epoch": 255.14,
      "learning_rate": 0.07449568466832798,
      "loss": 2.9078,
      "step": 158700
    },
    {
      "epoch": 255.18,
      "learning_rate": 0.07449246923745981,
      "loss": 2.8936,
      "step": 158720
    },
    {
      "epoch": 255.21,
      "learning_rate": 0.07448925380659165,
      "loss": 2.9155,
      "step": 158740
    },
    {
      "epoch": 255.24,
      "learning_rate": 0.07448603837572347,
      "loss": 2.8854,
      "step": 158760
    },
    {
      "epoch": 255.27,
      "learning_rate": 0.07448282294485531,
      "loss": 2.9082,
      "step": 158780
    },
    {
      "epoch": 255.31,
      "learning_rate": 0.07447960751398715,
      "loss": 2.9483,
      "step": 158800
    },
    {
      "epoch": 255.34,
      "learning_rate": 0.07447639208311897,
      "loss": 2.9326,
      "step": 158820
    },
    {
      "epoch": 255.37,
      "learning_rate": 0.07447317665225081,
      "loss": 2.8964,
      "step": 158840
    },
    {
      "epoch": 255.4,
      "learning_rate": 0.07446996122138264,
      "loss": 2.8831,
      "step": 158860
    },
    {
      "epoch": 255.43,
      "learning_rate": 0.07446674579051447,
      "loss": 2.8759,
      "step": 158880
    },
    {
      "epoch": 255.47,
      "learning_rate": 0.07446353035964631,
      "loss": 2.8996,
      "step": 158900
    },
    {
      "epoch": 255.5,
      "learning_rate": 0.07446031492877814,
      "loss": 2.8839,
      "step": 158920
    },
    {
      "epoch": 255.53,
      "learning_rate": 0.07445709949790998,
      "loss": 2.8777,
      "step": 158940
    },
    {
      "epoch": 255.56,
      "learning_rate": 0.0744538840670418,
      "loss": 2.88,
      "step": 158960
    },
    {
      "epoch": 255.59,
      "learning_rate": 0.07445066863617364,
      "loss": 2.9175,
      "step": 158980
    },
    {
      "epoch": 255.63,
      "learning_rate": 0.07444745320530546,
      "loss": 2.9162,
      "step": 159000
    },
    {
      "epoch": 255.66,
      "learning_rate": 0.0744442377744373,
      "loss": 2.9391,
      "step": 159020
    },
    {
      "epoch": 255.69,
      "learning_rate": 0.07444102234356914,
      "loss": 2.9579,
      "step": 159040
    },
    {
      "epoch": 255.72,
      "learning_rate": 0.07443780691270097,
      "loss": 2.9503,
      "step": 159060
    },
    {
      "epoch": 255.76,
      "learning_rate": 0.0744345914818328,
      "loss": 2.9353,
      "step": 159080
    },
    {
      "epoch": 255.79,
      "learning_rate": 0.07443137605096463,
      "loss": 2.8917,
      "step": 159100
    },
    {
      "epoch": 255.82,
      "learning_rate": 0.07442816062009647,
      "loss": 2.9201,
      "step": 159120
    },
    {
      "epoch": 255.85,
      "learning_rate": 0.0744249451892283,
      "loss": 2.9752,
      "step": 159140
    },
    {
      "epoch": 255.88,
      "learning_rate": 0.07442189052990354,
      "loss": 2.9604,
      "step": 159160
    },
    {
      "epoch": 255.92,
      "learning_rate": 0.07441867509903538,
      "loss": 2.9546,
      "step": 159180
    },
    {
      "epoch": 255.95,
      "learning_rate": 0.0744154596681672,
      "loss": 2.9249,
      "step": 159200
    },
    {
      "epoch": 255.98,
      "learning_rate": 0.07441224423729903,
      "loss": 2.9233,
      "step": 159220
    },
    {
      "epoch": 256.0,
      "eval_accuracy": {
        "accuracy": 0.38622405348674493
      },
      "eval_loss": 3.0220963954925537,
      "eval_runtime": 3.0049,
      "eval_samples_per_second": 4280.738,
      "eval_steps_per_second": 66.892,
      "step": 159232
    },
    {
      "epoch": 256.01,
      "learning_rate": 0.07440902880643088,
      "loss": 2.9371,
      "step": 159240
    },
    {
      "epoch": 256.05,
      "learning_rate": 0.0744058133755627,
      "loss": 2.9795,
      "step": 159260
    },
    {
      "epoch": 256.08,
      "learning_rate": 0.07440259794469455,
      "loss": 2.9306,
      "step": 159280
    },
    {
      "epoch": 256.11,
      "learning_rate": 0.07439938251382637,
      "loss": 2.9292,
      "step": 159300
    },
    {
      "epoch": 256.14,
      "learning_rate": 0.0743961670829582,
      "loss": 2.9195,
      "step": 159320
    },
    {
      "epoch": 256.17,
      "learning_rate": 0.07439295165209005,
      "loss": 2.9038,
      "step": 159340
    },
    {
      "epoch": 256.21,
      "learning_rate": 0.07438973622122186,
      "loss": 2.9423,
      "step": 159360
    },
    {
      "epoch": 256.24,
      "learning_rate": 0.07438652079035371,
      "loss": 2.9186,
      "step": 159380
    },
    {
      "epoch": 256.27,
      "learning_rate": 0.07438330535948554,
      "loss": 2.9306,
      "step": 159400
    },
    {
      "epoch": 256.3,
      "learning_rate": 0.07438008992861736,
      "loss": 2.9023,
      "step": 159420
    },
    {
      "epoch": 256.33,
      "learning_rate": 0.07437687449774921,
      "loss": 2.9142,
      "step": 159440
    },
    {
      "epoch": 256.37,
      "learning_rate": 0.07437365906688102,
      "loss": 2.9216,
      "step": 159460
    },
    {
      "epoch": 256.4,
      "learning_rate": 0.07437044363601288,
      "loss": 2.9087,
      "step": 159480
    },
    {
      "epoch": 256.43,
      "learning_rate": 0.0743672282051447,
      "loss": 2.897,
      "step": 159500
    },
    {
      "epoch": 256.46,
      "learning_rate": 0.07436401277427653,
      "loss": 2.9141,
      "step": 159520
    },
    {
      "epoch": 256.5,
      "learning_rate": 0.07436079734340836,
      "loss": 2.9275,
      "step": 159540
    },
    {
      "epoch": 256.53,
      "learning_rate": 0.07435758191254019,
      "loss": 2.9692,
      "step": 159560
    },
    {
      "epoch": 256.56,
      "learning_rate": 0.07435436648167204,
      "loss": 2.8865,
      "step": 159580
    },
    {
      "epoch": 256.59,
      "learning_rate": 0.07435115105080385,
      "loss": 2.9156,
      "step": 159600
    },
    {
      "epoch": 256.62,
      "learning_rate": 0.0743479356199357,
      "loss": 2.9214,
      "step": 159620
    },
    {
      "epoch": 256.66,
      "learning_rate": 0.07434472018906753,
      "loss": 2.9108,
      "step": 159640
    },
    {
      "epoch": 256.69,
      "learning_rate": 0.07434150475819935,
      "loss": 2.9217,
      "step": 159660
    },
    {
      "epoch": 256.72,
      "learning_rate": 0.0743382893273312,
      "loss": 2.9024,
      "step": 159680
    },
    {
      "epoch": 256.75,
      "learning_rate": 0.07433507389646302,
      "loss": 2.9206,
      "step": 159700
    },
    {
      "epoch": 256.78,
      "learning_rate": 0.07433185846559487,
      "loss": 2.9253,
      "step": 159720
    },
    {
      "epoch": 256.82,
      "learning_rate": 0.0743286430347267,
      "loss": 2.9365,
      "step": 159740
    },
    {
      "epoch": 256.85,
      "learning_rate": 0.07432542760385852,
      "loss": 2.9168,
      "step": 159760
    },
    {
      "epoch": 256.88,
      "learning_rate": 0.07432221217299037,
      "loss": 2.9297,
      "step": 159780
    },
    {
      "epoch": 256.91,
      "learning_rate": 0.07431899674212218,
      "loss": 2.9468,
      "step": 159800
    },
    {
      "epoch": 256.95,
      "learning_rate": 0.07431578131125403,
      "loss": 2.9345,
      "step": 159820
    },
    {
      "epoch": 256.98,
      "learning_rate": 0.07431256588038586,
      "loss": 2.9535,
      "step": 159840
    },
    {
      "epoch": 257.0,
      "eval_accuracy": {
        "accuracy": 0.37534012283293167
      },
      "eval_loss": 3.0559065341949463,
      "eval_runtime": 2.9724,
      "eval_samples_per_second": 4327.524,
      "eval_steps_per_second": 67.623,
      "step": 159854
    },
    {
      "epoch": 257.01,
      "learning_rate": 0.07430935044951768,
      "loss": 2.9272,
      "step": 159860
    },
    {
      "epoch": 257.04,
      "learning_rate": 0.07430613501864952,
      "loss": 2.9113,
      "step": 159880
    },
    {
      "epoch": 257.07,
      "learning_rate": 0.07430291958778135,
      "loss": 2.9453,
      "step": 159900
    },
    {
      "epoch": 257.11,
      "learning_rate": 0.0742997041569132,
      "loss": 2.9206,
      "step": 159920
    },
    {
      "epoch": 257.14,
      "learning_rate": 0.07429648872604502,
      "loss": 2.9188,
      "step": 159940
    },
    {
      "epoch": 257.17,
      "learning_rate": 0.07429327329517685,
      "loss": 2.9156,
      "step": 159960
    },
    {
      "epoch": 257.2,
      "learning_rate": 0.07429005786430869,
      "loss": 2.9104,
      "step": 159980
    },
    {
      "epoch": 257.23,
      "learning_rate": 0.07428684243344051,
      "loss": 2.9462,
      "step": 160000
    },
    {
      "epoch": 257.27,
      "learning_rate": 0.07428362700257236,
      "loss": 2.9157,
      "step": 160020
    },
    {
      "epoch": 257.3,
      "learning_rate": 0.07428041157170417,
      "loss": 2.8842,
      "step": 160040
    },
    {
      "epoch": 257.33,
      "learning_rate": 0.07427719614083601,
      "loss": 2.9087,
      "step": 160060
    },
    {
      "epoch": 257.36,
      "learning_rate": 0.07427398070996785,
      "loss": 2.9605,
      "step": 160080
    },
    {
      "epoch": 257.4,
      "learning_rate": 0.07427076527909968,
      "loss": 2.919,
      "step": 160100
    },
    {
      "epoch": 257.43,
      "learning_rate": 0.07426754984823153,
      "loss": 2.887,
      "step": 160120
    },
    {
      "epoch": 257.46,
      "learning_rate": 0.07426433441736334,
      "loss": 2.8885,
      "step": 160140
    },
    {
      "epoch": 257.49,
      "learning_rate": 0.07426111898649518,
      "loss": 2.9349,
      "step": 160160
    },
    {
      "epoch": 257.52,
      "learning_rate": 0.07425790355562702,
      "loss": 2.9311,
      "step": 160180
    },
    {
      "epoch": 257.56,
      "learning_rate": 0.07425468812475884,
      "loss": 2.9168,
      "step": 160200
    },
    {
      "epoch": 257.59,
      "learning_rate": 0.07425147269389068,
      "loss": 2.9093,
      "step": 160220
    },
    {
      "epoch": 257.62,
      "learning_rate": 0.0742482572630225,
      "loss": 2.9301,
      "step": 160240
    },
    {
      "epoch": 257.65,
      "learning_rate": 0.07424504183215436,
      "loss": 2.9308,
      "step": 160260
    },
    {
      "epoch": 257.68,
      "learning_rate": 0.07424182640128618,
      "loss": 2.8796,
      "step": 160280
    },
    {
      "epoch": 257.72,
      "learning_rate": 0.074238610970418,
      "loss": 2.9086,
      "step": 160300
    },
    {
      "epoch": 257.75,
      "learning_rate": 0.07423539553954984,
      "loss": 2.9187,
      "step": 160320
    },
    {
      "epoch": 257.78,
      "learning_rate": 0.07423218010868167,
      "loss": 2.9006,
      "step": 160340
    },
    {
      "epoch": 257.81,
      "learning_rate": 0.07422896467781352,
      "loss": 2.9206,
      "step": 160360
    },
    {
      "epoch": 257.85,
      "learning_rate": 0.07422574924694533,
      "loss": 2.9322,
      "step": 160380
    },
    {
      "epoch": 257.88,
      "learning_rate": 0.07422253381607717,
      "loss": 2.9209,
      "step": 160400
    },
    {
      "epoch": 257.91,
      "learning_rate": 0.07421931838520901,
      "loss": 2.9252,
      "step": 160420
    },
    {
      "epoch": 257.94,
      "learning_rate": 0.07421610295434083,
      "loss": 2.9425,
      "step": 160440
    },
    {
      "epoch": 257.97,
      "learning_rate": 0.07421288752347269,
      "loss": 2.9168,
      "step": 160460
    },
    {
      "epoch": 258.0,
      "eval_accuracy": {
        "accuracy": 0.3816372541397808
      },
      "eval_loss": 3.0035903453826904,
      "eval_runtime": 2.729,
      "eval_samples_per_second": 4713.523,
      "eval_steps_per_second": 73.655,
      "step": 160476
    },
    {
      "epoch": 258.01,
      "learning_rate": 0.0742096720926045,
      "loss": 2.9339,
      "step": 160480
    },
    {
      "epoch": 258.04,
      "learning_rate": 0.07420645666173634,
      "loss": 2.9554,
      "step": 160500
    },
    {
      "epoch": 258.07,
      "learning_rate": 0.07420324123086817,
      "loss": 2.9416,
      "step": 160520
    },
    {
      "epoch": 258.1,
      "learning_rate": 0.0742000258,
      "loss": 2.9318,
      "step": 160540
    },
    {
      "epoch": 258.14,
      "learning_rate": 0.07419681036913184,
      "loss": 2.9204,
      "step": 160560
    },
    {
      "epoch": 258.17,
      "learning_rate": 0.07419359493826366,
      "loss": 2.8903,
      "step": 160580
    },
    {
      "epoch": 258.2,
      "learning_rate": 0.0741903795073955,
      "loss": 2.9465,
      "step": 160600
    },
    {
      "epoch": 258.23,
      "learning_rate": 0.07418716407652734,
      "loss": 2.9378,
      "step": 160620
    },
    {
      "epoch": 258.26,
      "learning_rate": 0.07418394864565916,
      "loss": 2.9085,
      "step": 160640
    },
    {
      "epoch": 258.3,
      "learning_rate": 0.074180733214791,
      "loss": 2.8931,
      "step": 160660
    },
    {
      "epoch": 258.33,
      "learning_rate": 0.07417751778392283,
      "loss": 2.8974,
      "step": 160680
    },
    {
      "epoch": 258.36,
      "learning_rate": 0.07417430235305467,
      "loss": 2.8867,
      "step": 160700
    },
    {
      "epoch": 258.39,
      "learning_rate": 0.07417108692218649,
      "loss": 2.9422,
      "step": 160720
    },
    {
      "epoch": 258.42,
      "learning_rate": 0.07416787149131833,
      "loss": 2.9471,
      "step": 160740
    },
    {
      "epoch": 258.46,
      "learning_rate": 0.07416465606045017,
      "loss": 2.9166,
      "step": 160760
    },
    {
      "epoch": 258.49,
      "learning_rate": 0.07416144062958199,
      "loss": 2.8859,
      "step": 160780
    },
    {
      "epoch": 258.52,
      "learning_rate": 0.07415822519871383,
      "loss": 2.9092,
      "step": 160800
    },
    {
      "epoch": 258.55,
      "learning_rate": 0.07415500976784566,
      "loss": 2.9023,
      "step": 160820
    },
    {
      "epoch": 258.59,
      "learning_rate": 0.0741517943369775,
      "loss": 2.9162,
      "step": 160840
    },
    {
      "epoch": 258.62,
      "learning_rate": 0.07414857890610933,
      "loss": 2.8925,
      "step": 160860
    },
    {
      "epoch": 258.65,
      "learning_rate": 0.07414536347524116,
      "loss": 2.9155,
      "step": 160880
    },
    {
      "epoch": 258.68,
      "learning_rate": 0.07414214804437301,
      "loss": 2.9187,
      "step": 160900
    },
    {
      "epoch": 258.71,
      "learning_rate": 0.07413893261350482,
      "loss": 2.8795,
      "step": 160920
    },
    {
      "epoch": 258.75,
      "learning_rate": 0.07413571718263666,
      "loss": 2.9082,
      "step": 160940
    },
    {
      "epoch": 258.78,
      "learning_rate": 0.0741325017517685,
      "loss": 2.9417,
      "step": 160960
    },
    {
      "epoch": 258.81,
      "learning_rate": 0.07412928632090032,
      "loss": 2.9509,
      "step": 160980
    },
    {
      "epoch": 258.84,
      "learning_rate": 0.07412607089003216,
      "loss": 2.9071,
      "step": 161000
    },
    {
      "epoch": 258.87,
      "learning_rate": 0.07412285545916399,
      "loss": 2.8992,
      "step": 161020
    },
    {
      "epoch": 258.91,
      "learning_rate": 0.07411964002829582,
      "loss": 2.9006,
      "step": 161040
    },
    {
      "epoch": 258.94,
      "learning_rate": 0.07411642459742765,
      "loss": 2.9389,
      "step": 161060
    },
    {
      "epoch": 258.97,
      "learning_rate": 0.07411320916655949,
      "loss": 2.8913,
      "step": 161080
    },
    {
      "epoch": 259.0,
      "eval_accuracy": {
        "accuracy": 0.38008240690352174
      },
      "eval_loss": 3.0153067111968994,
      "eval_runtime": 2.6722,
      "eval_samples_per_second": 4813.707,
      "eval_steps_per_second": 75.22,
      "step": 161098
    },
    {
      "epoch": 259.0,
      "learning_rate": 0.07410999373569133,
      "loss": 2.8995,
      "step": 161100
    },
    {
      "epoch": 259.04,
      "learning_rate": 0.07410677830482315,
      "loss": 2.9484,
      "step": 161120
    },
    {
      "epoch": 259.07,
      "learning_rate": 0.07410356287395499,
      "loss": 2.9069,
      "step": 161140
    },
    {
      "epoch": 259.1,
      "learning_rate": 0.07410034744308681,
      "loss": 2.9236,
      "step": 161160
    },
    {
      "epoch": 259.13,
      "learning_rate": 0.07409713201221865,
      "loss": 2.9055,
      "step": 161180
    },
    {
      "epoch": 259.16,
      "learning_rate": 0.07409391658135049,
      "loss": 2.9282,
      "step": 161200
    },
    {
      "epoch": 259.2,
      "learning_rate": 0.07409070115048232,
      "loss": 2.9042,
      "step": 161220
    },
    {
      "epoch": 259.23,
      "learning_rate": 0.07408748571961415,
      "loss": 2.9206,
      "step": 161240
    },
    {
      "epoch": 259.26,
      "learning_rate": 0.07408427028874598,
      "loss": 2.8929,
      "step": 161260
    },
    {
      "epoch": 259.29,
      "learning_rate": 0.07408105485787782,
      "loss": 2.9095,
      "step": 161280
    },
    {
      "epoch": 259.32,
      "learning_rate": 0.07407783942700966,
      "loss": 2.9333,
      "step": 161300
    },
    {
      "epoch": 259.36,
      "learning_rate": 0.07407462399614148,
      "loss": 2.8884,
      "step": 161320
    },
    {
      "epoch": 259.39,
      "learning_rate": 0.07407156933681673,
      "loss": 2.8963,
      "step": 161340
    },
    {
      "epoch": 259.42,
      "learning_rate": 0.07406835390594856,
      "loss": 2.9317,
      "step": 161360
    },
    {
      "epoch": 259.45,
      "learning_rate": 0.0740651384750804,
      "loss": 2.9385,
      "step": 161380
    },
    {
      "epoch": 259.49,
      "learning_rate": 0.07406192304421223,
      "loss": 2.9033,
      "step": 161400
    },
    {
      "epoch": 259.52,
      "learning_rate": 0.07405870761334404,
      "loss": 2.8908,
      "step": 161420
    },
    {
      "epoch": 259.55,
      "learning_rate": 0.0740554921824759,
      "loss": 2.8985,
      "step": 161440
    },
    {
      "epoch": 259.58,
      "learning_rate": 0.07405227675160772,
      "loss": 2.9261,
      "step": 161460
    },
    {
      "epoch": 259.61,
      "learning_rate": 0.07404906132073956,
      "loss": 2.8853,
      "step": 161480
    },
    {
      "epoch": 259.65,
      "learning_rate": 0.0740458458898714,
      "loss": 2.91,
      "step": 161500
    },
    {
      "epoch": 259.68,
      "learning_rate": 0.07404263045900321,
      "loss": 2.9555,
      "step": 161520
    },
    {
      "epoch": 259.71,
      "learning_rate": 0.07403941502813506,
      "loss": 2.9397,
      "step": 161540
    },
    {
      "epoch": 259.74,
      "learning_rate": 0.07403619959726689,
      "loss": 2.9202,
      "step": 161560
    },
    {
      "epoch": 259.77,
      "learning_rate": 0.07403298416639872,
      "loss": 2.9279,
      "step": 161580
    },
    {
      "epoch": 259.81,
      "learning_rate": 0.07402976873553055,
      "loss": 2.9484,
      "step": 161600
    },
    {
      "epoch": 259.84,
      "learning_rate": 0.07402655330466237,
      "loss": 2.9366,
      "step": 161620
    },
    {
      "epoch": 259.87,
      "learning_rate": 0.07402333787379423,
      "loss": 2.9389,
      "step": 161640
    },
    {
      "epoch": 259.9,
      "learning_rate": 0.07402012244292604,
      "loss": 2.9052,
      "step": 161660
    },
    {
      "epoch": 259.94,
      "learning_rate": 0.07401690701205789,
      "loss": 2.9125,
      "step": 161680
    },
    {
      "epoch": 259.97,
      "learning_rate": 0.07401369158118971,
      "loss": 2.9175,
      "step": 161700
    },
    {
      "epoch": 260.0,
      "learning_rate": 0.07401047615032154,
      "loss": 2.9118,
      "step": 161720
    },
    {
      "epoch": 260.0,
      "eval_accuracy": {
        "accuracy": 0.3716862318277229
      },
      "eval_loss": 3.1090598106384277,
      "eval_runtime": 2.9565,
      "eval_samples_per_second": 4350.685,
      "eval_steps_per_second": 67.985,
      "step": 161720
    },
    {
      "epoch": 260.03,
      "learning_rate": 0.07400726071945339,
      "loss": 2.9953,
      "step": 161740
    },
    {
      "epoch": 260.06,
      "learning_rate": 0.0740040452885852,
      "loss": 2.9606,
      "step": 161760
    },
    {
      "epoch": 260.1,
      "learning_rate": 0.07400082985771705,
      "loss": 2.8995,
      "step": 161780
    },
    {
      "epoch": 260.13,
      "learning_rate": 0.07399761442684888,
      "loss": 2.8997,
      "step": 161800
    },
    {
      "epoch": 260.16,
      "learning_rate": 0.07399439899598072,
      "loss": 2.9132,
      "step": 161820
    },
    {
      "epoch": 260.19,
      "learning_rate": 0.07399118356511256,
      "loss": 2.9069,
      "step": 161840
    },
    {
      "epoch": 260.23,
      "learning_rate": 0.07398796813424437,
      "loss": 2.9175,
      "step": 161860
    },
    {
      "epoch": 260.26,
      "learning_rate": 0.07398475270337622,
      "loss": 2.9047,
      "step": 161880
    },
    {
      "epoch": 260.29,
      "learning_rate": 0.07398153727250804,
      "loss": 2.9018,
      "step": 161900
    },
    {
      "epoch": 260.32,
      "learning_rate": 0.07397832184163988,
      "loss": 2.9053,
      "step": 161920
    },
    {
      "epoch": 260.35,
      "learning_rate": 0.07397510641077171,
      "loss": 2.9217,
      "step": 161940
    },
    {
      "epoch": 260.39,
      "learning_rate": 0.07397189097990353,
      "loss": 2.9202,
      "step": 161960
    },
    {
      "epoch": 260.42,
      "learning_rate": 0.07396867554903538,
      "loss": 2.9194,
      "step": 161980
    },
    {
      "epoch": 260.45,
      "learning_rate": 0.0739654601181672,
      "loss": 2.9386,
      "step": 162000
    },
    {
      "epoch": 260.48,
      "learning_rate": 0.07396224468729905,
      "loss": 2.9341,
      "step": 162020
    },
    {
      "epoch": 260.51,
      "learning_rate": 0.07395902925643087,
      "loss": 2.919,
      "step": 162040
    },
    {
      "epoch": 260.55,
      "learning_rate": 0.0739558138255627,
      "loss": 2.9505,
      "step": 162060
    },
    {
      "epoch": 260.58,
      "learning_rate": 0.07395259839469455,
      "loss": 2.9155,
      "step": 162080
    },
    {
      "epoch": 260.61,
      "learning_rate": 0.07394938296382636,
      "loss": 2.9053,
      "step": 162100
    },
    {
      "epoch": 260.64,
      "learning_rate": 0.07394616753295821,
      "loss": 2.8955,
      "step": 162120
    },
    {
      "epoch": 260.68,
      "learning_rate": 0.07394295210209004,
      "loss": 2.8792,
      "step": 162140
    },
    {
      "epoch": 260.71,
      "learning_rate": 0.07393973667122186,
      "loss": 2.9333,
      "step": 162160
    },
    {
      "epoch": 260.74,
      "learning_rate": 0.07393652124035371,
      "loss": 2.8941,
      "step": 162180
    },
    {
      "epoch": 260.77,
      "learning_rate": 0.07393330580948552,
      "loss": 2.9038,
      "step": 162200
    },
    {
      "epoch": 260.8,
      "learning_rate": 0.07393009037861738,
      "loss": 2.893,
      "step": 162220
    },
    {
      "epoch": 260.84,
      "learning_rate": 0.0739268749477492,
      "loss": 2.9341,
      "step": 162240
    },
    {
      "epoch": 260.87,
      "learning_rate": 0.07392365951688103,
      "loss": 2.9387,
      "step": 162260
    },
    {
      "epoch": 260.9,
      "learning_rate": 0.07392044408601287,
      "loss": 2.9155,
      "step": 162280
    },
    {
      "epoch": 260.93,
      "learning_rate": 0.07391722865514469,
      "loss": 2.918,
      "step": 162300
    },
    {
      "epoch": 260.96,
      "learning_rate": 0.07391401322427654,
      "loss": 2.9372,
      "step": 162320
    },
    {
      "epoch": 261.0,
      "learning_rate": 0.07391079779340835,
      "loss": 2.9221,
      "step": 162340
    },
    {
      "epoch": 261.0,
      "eval_accuracy": {
        "accuracy": 0.3924434424317811
      },
      "eval_loss": 2.9880452156066895,
      "eval_runtime": 2.6485,
      "eval_samples_per_second": 4856.628,
      "eval_steps_per_second": 75.891,
      "step": 162342
    },
    {
      "epoch": 261.03,
      "learning_rate": 0.07390758236254019,
      "loss": 2.8985,
      "step": 162360
    },
    {
      "epoch": 261.06,
      "learning_rate": 0.07390436693167203,
      "loss": 2.9465,
      "step": 162380
    },
    {
      "epoch": 261.09,
      "learning_rate": 0.07390115150080385,
      "loss": 2.9348,
      "step": 162400
    },
    {
      "epoch": 261.13,
      "learning_rate": 0.07389793606993571,
      "loss": 2.9099,
      "step": 162420
    },
    {
      "epoch": 261.16,
      "learning_rate": 0.07389472063906752,
      "loss": 2.9377,
      "step": 162440
    },
    {
      "epoch": 261.19,
      "learning_rate": 0.07389150520819937,
      "loss": 2.9249,
      "step": 162460
    },
    {
      "epoch": 261.22,
      "learning_rate": 0.0738882897773312,
      "loss": 2.9205,
      "step": 162480
    },
    {
      "epoch": 261.25,
      "learning_rate": 0.07388507434646302,
      "loss": 2.8831,
      "step": 162500
    },
    {
      "epoch": 261.29,
      "learning_rate": 0.07388185891559487,
      "loss": 2.9165,
      "step": 162520
    },
    {
      "epoch": 261.32,
      "learning_rate": 0.07387864348472668,
      "loss": 2.8671,
      "step": 162540
    },
    {
      "epoch": 261.35,
      "learning_rate": 0.07387542805385854,
      "loss": 2.9144,
      "step": 162560
    },
    {
      "epoch": 261.38,
      "learning_rate": 0.07387221262299036,
      "loss": 2.9299,
      "step": 162580
    },
    {
      "epoch": 261.41,
      "learning_rate": 0.07386899719212218,
      "loss": 2.9259,
      "step": 162600
    },
    {
      "epoch": 261.45,
      "learning_rate": 0.07386578176125402,
      "loss": 2.9411,
      "step": 162620
    },
    {
      "epoch": 261.48,
      "learning_rate": 0.07386256633038585,
      "loss": 2.8955,
      "step": 162640
    },
    {
      "epoch": 261.51,
      "learning_rate": 0.0738593508995177,
      "loss": 2.8899,
      "step": 162660
    },
    {
      "epoch": 261.54,
      "learning_rate": 0.07385613546864953,
      "loss": 2.8852,
      "step": 162680
    },
    {
      "epoch": 261.58,
      "learning_rate": 0.07385292003778135,
      "loss": 2.8754,
      "step": 162700
    },
    {
      "epoch": 261.61,
      "learning_rate": 0.07384970460691319,
      "loss": 2.9119,
      "step": 162720
    },
    {
      "epoch": 261.64,
      "learning_rate": 0.07384648917604501,
      "loss": 2.9086,
      "step": 162740
    },
    {
      "epoch": 261.67,
      "learning_rate": 0.07384327374517687,
      "loss": 2.9011,
      "step": 162760
    },
    {
      "epoch": 261.7,
      "learning_rate": 0.07384005831430868,
      "loss": 2.9233,
      "step": 162780
    },
    {
      "epoch": 261.74,
      "learning_rate": 0.07383684288344051,
      "loss": 2.9097,
      "step": 162800
    },
    {
      "epoch": 261.77,
      "learning_rate": 0.07383362745257235,
      "loss": 2.9051,
      "step": 162820
    },
    {
      "epoch": 261.8,
      "learning_rate": 0.07383041202170418,
      "loss": 2.9264,
      "step": 162840
    },
    {
      "epoch": 261.83,
      "learning_rate": 0.07382719659083603,
      "loss": 2.9358,
      "step": 162860
    },
    {
      "epoch": 261.86,
      "learning_rate": 0.07382398115996784,
      "loss": 2.9121,
      "step": 162880
    },
    {
      "epoch": 261.9,
      "learning_rate": 0.07382076572909968,
      "loss": 2.8917,
      "step": 162900
    },
    {
      "epoch": 261.93,
      "learning_rate": 0.07381755029823152,
      "loss": 2.9011,
      "step": 162920
    },
    {
      "epoch": 261.96,
      "learning_rate": 0.07381433486736334,
      "loss": 2.934,
      "step": 162940
    },
    {
      "epoch": 261.99,
      "learning_rate": 0.07381111943649518,
      "loss": 2.8999,
      "step": 162960
    },
    {
      "epoch": 262.0,
      "eval_accuracy": {
        "accuracy": 0.38435823680323405
      },
      "eval_loss": 3.008906126022339,
      "eval_runtime": 2.9032,
      "eval_samples_per_second": 4430.625,
      "eval_steps_per_second": 69.234,
      "step": 162964
    },
    {
      "epoch": 262.03,
      "learning_rate": 0.073807904005627,
      "loss": 2.8971,
      "step": 162980
    },
    {
      "epoch": 262.06,
      "learning_rate": 0.07380468857475884,
      "loss": 2.9375,
      "step": 163000
    },
    {
      "epoch": 262.09,
      "learning_rate": 0.07380147314389068,
      "loss": 2.9051,
      "step": 163020
    },
    {
      "epoch": 262.12,
      "learning_rate": 0.07379825771302251,
      "loss": 2.9185,
      "step": 163040
    },
    {
      "epoch": 262.15,
      "learning_rate": 0.07379504228215435,
      "loss": 2.9108,
      "step": 163060
    },
    {
      "epoch": 262.19,
      "learning_rate": 0.07379182685128617,
      "loss": 2.9248,
      "step": 163080
    },
    {
      "epoch": 262.22,
      "learning_rate": 0.07378861142041802,
      "loss": 2.9061,
      "step": 163100
    },
    {
      "epoch": 262.25,
      "learning_rate": 0.07378539598954983,
      "loss": 2.893,
      "step": 163120
    },
    {
      "epoch": 262.28,
      "learning_rate": 0.07378218055868167,
      "loss": 2.9028,
      "step": 163140
    },
    {
      "epoch": 262.32,
      "learning_rate": 0.07377896512781351,
      "loss": 2.8844,
      "step": 163160
    },
    {
      "epoch": 262.35,
      "learning_rate": 0.07377574969694534,
      "loss": 2.9271,
      "step": 163180
    },
    {
      "epoch": 262.38,
      "learning_rate": 0.07377253426607719,
      "loss": 2.9371,
      "step": 163200
    },
    {
      "epoch": 262.41,
      "learning_rate": 0.073769318835209,
      "loss": 2.9065,
      "step": 163220
    },
    {
      "epoch": 262.44,
      "learning_rate": 0.07376610340434084,
      "loss": 2.8776,
      "step": 163240
    },
    {
      "epoch": 262.48,
      "learning_rate": 0.07376288797347268,
      "loss": 2.8815,
      "step": 163260
    },
    {
      "epoch": 262.51,
      "learning_rate": 0.0737596725426045,
      "loss": 2.9019,
      "step": 163280
    },
    {
      "epoch": 262.54,
      "learning_rate": 0.07375645711173634,
      "loss": 2.9351,
      "step": 163300
    },
    {
      "epoch": 262.57,
      "learning_rate": 0.07375324168086816,
      "loss": 2.9242,
      "step": 163320
    },
    {
      "epoch": 262.6,
      "learning_rate": 0.07375002625,
      "loss": 2.8857,
      "step": 163340
    },
    {
      "epoch": 262.64,
      "learning_rate": 0.07374697159067525,
      "loss": 2.9046,
      "step": 163360
    },
    {
      "epoch": 262.67,
      "learning_rate": 0.07374375615980708,
      "loss": 2.8787,
      "step": 163380
    },
    {
      "epoch": 262.7,
      "learning_rate": 0.07374054072893892,
      "loss": 2.8971,
      "step": 163400
    },
    {
      "epoch": 262.73,
      "learning_rate": 0.07373732529807074,
      "loss": 2.9226,
      "step": 163420
    },
    {
      "epoch": 262.77,
      "learning_rate": 0.07373410986720258,
      "loss": 2.9039,
      "step": 163440
    },
    {
      "epoch": 262.8,
      "learning_rate": 0.07373089443633442,
      "loss": 2.9027,
      "step": 163460
    },
    {
      "epoch": 262.83,
      "learning_rate": 0.07372767900546624,
      "loss": 2.8844,
      "step": 163480
    },
    {
      "epoch": 262.86,
      "learning_rate": 0.07372446357459808,
      "loss": 2.9153,
      "step": 163500
    },
    {
      "epoch": 262.89,
      "learning_rate": 0.0737212481437299,
      "loss": 2.9015,
      "step": 163520
    },
    {
      "epoch": 262.93,
      "learning_rate": 0.07371803271286174,
      "loss": 2.8962,
      "step": 163540
    },
    {
      "epoch": 262.96,
      "learning_rate": 0.07371481728199358,
      "loss": 2.9115,
      "step": 163560
    },
    {
      "epoch": 262.99,
      "learning_rate": 0.07371160185112541,
      "loss": 2.9186,
      "step": 163580
    },
    {
      "epoch": 263.0,
      "eval_accuracy": {
        "accuracy": 0.3901111715773925
      },
      "eval_loss": 2.9901139736175537,
      "eval_runtime": 2.9445,
      "eval_samples_per_second": 4368.468,
      "eval_steps_per_second": 68.263,
      "step": 163586
    },
    {
      "epoch": 263.02,
      "learning_rate": 0.07370838642025725,
      "loss": 2.9148,
      "step": 163600
    },
    {
      "epoch": 263.05,
      "learning_rate": 0.07370517098938907,
      "loss": 2.9347,
      "step": 163620
    },
    {
      "epoch": 263.09,
      "learning_rate": 0.07370195555852091,
      "loss": 2.9262,
      "step": 163640
    },
    {
      "epoch": 263.12,
      "learning_rate": 0.07369874012765273,
      "loss": 2.8869,
      "step": 163660
    },
    {
      "epoch": 263.15,
      "learning_rate": 0.07369552469678457,
      "loss": 2.9292,
      "step": 163680
    },
    {
      "epoch": 263.18,
      "learning_rate": 0.07369230926591641,
      "loss": 2.9212,
      "step": 163700
    },
    {
      "epoch": 263.22,
      "learning_rate": 0.07368909383504822,
      "loss": 2.9823,
      "step": 163720
    },
    {
      "epoch": 263.25,
      "learning_rate": 0.07368587840418007,
      "loss": 2.9241,
      "step": 163740
    },
    {
      "epoch": 263.28,
      "learning_rate": 0.0736826629733119,
      "loss": 2.9294,
      "step": 163760
    },
    {
      "epoch": 263.31,
      "learning_rate": 0.07367944754244374,
      "loss": 2.9017,
      "step": 163780
    },
    {
      "epoch": 263.34,
      "learning_rate": 0.07367623211157558,
      "loss": 2.9094,
      "step": 163800
    },
    {
      "epoch": 263.38,
      "learning_rate": 0.07367301668070739,
      "loss": 2.8831,
      "step": 163820
    },
    {
      "epoch": 263.41,
      "learning_rate": 0.07366980124983924,
      "loss": 2.9317,
      "step": 163840
    },
    {
      "epoch": 263.44,
      "learning_rate": 0.07366658581897106,
      "loss": 2.9215,
      "step": 163860
    },
    {
      "epoch": 263.47,
      "learning_rate": 0.0736633703881029,
      "loss": 2.9089,
      "step": 163880
    },
    {
      "epoch": 263.5,
      "learning_rate": 0.07366015495723474,
      "loss": 2.8989,
      "step": 163900
    },
    {
      "epoch": 263.54,
      "learning_rate": 0.07365693952636655,
      "loss": 2.9016,
      "step": 163920
    },
    {
      "epoch": 263.57,
      "learning_rate": 0.0736537240954984,
      "loss": 2.9066,
      "step": 163940
    },
    {
      "epoch": 263.6,
      "learning_rate": 0.07365050866463023,
      "loss": 2.8961,
      "step": 163960
    },
    {
      "epoch": 263.63,
      "learning_rate": 0.07364729323376207,
      "loss": 2.9154,
      "step": 163980
    },
    {
      "epoch": 263.67,
      "learning_rate": 0.07364407780289389,
      "loss": 2.927,
      "step": 164000
    },
    {
      "epoch": 263.7,
      "learning_rate": 0.07364086237202573,
      "loss": 2.9295,
      "step": 164020
    },
    {
      "epoch": 263.73,
      "learning_rate": 0.07363764694115757,
      "loss": 2.9306,
      "step": 164040
    },
    {
      "epoch": 263.76,
      "learning_rate": 0.07363443151028938,
      "loss": 2.8909,
      "step": 164060
    },
    {
      "epoch": 263.79,
      "learning_rate": 0.07363121607942123,
      "loss": 2.8894,
      "step": 164080
    },
    {
      "epoch": 263.83,
      "learning_rate": 0.07362800064855306,
      "loss": 2.9066,
      "step": 164100
    },
    {
      "epoch": 263.86,
      "learning_rate": 0.0736247852176849,
      "loss": 2.9155,
      "step": 164120
    },
    {
      "epoch": 263.89,
      "learning_rate": 0.07362156978681673,
      "loss": 2.9388,
      "step": 164140
    },
    {
      "epoch": 263.92,
      "learning_rate": 0.07361835435594855,
      "loss": 2.8904,
      "step": 164160
    },
    {
      "epoch": 263.95,
      "learning_rate": 0.0736151389250804,
      "loss": 2.8996,
      "step": 164180
    },
    {
      "epoch": 263.99,
      "learning_rate": 0.07361192349421222,
      "loss": 2.8921,
      "step": 164200
    },
    {
      "epoch": 264.0,
      "eval_accuracy": {
        "accuracy": 0.3851356604213636
      },
      "eval_loss": 3.012877941131592,
      "eval_runtime": 2.7452,
      "eval_samples_per_second": 4685.637,
      "eval_steps_per_second": 73.219,
      "step": 164208
    },
    {
      "epoch": 264.02,
      "learning_rate": 0.07360870806334406,
      "loss": 2.9262,
      "step": 164220
    },
    {
      "epoch": 264.05,
      "learning_rate": 0.0736054926324759,
      "loss": 2.8938,
      "step": 164240
    },
    {
      "epoch": 264.08,
      "learning_rate": 0.07360227720160771,
      "loss": 2.8927,
      "step": 164260
    },
    {
      "epoch": 264.12,
      "learning_rate": 0.07359906177073956,
      "loss": 2.9034,
      "step": 164280
    },
    {
      "epoch": 264.15,
      "learning_rate": 0.07359584633987139,
      "loss": 2.8906,
      "step": 164300
    },
    {
      "epoch": 264.18,
      "learning_rate": 0.07359263090900323,
      "loss": 2.8907,
      "step": 164320
    },
    {
      "epoch": 264.21,
      "learning_rate": 0.07358941547813505,
      "loss": 2.8963,
      "step": 164340
    },
    {
      "epoch": 264.24,
      "learning_rate": 0.07358620004726688,
      "loss": 2.9279,
      "step": 164360
    },
    {
      "epoch": 264.28,
      "learning_rate": 0.07358298461639873,
      "loss": 2.8891,
      "step": 164380
    },
    {
      "epoch": 264.31,
      "learning_rate": 0.07357976918553054,
      "loss": 2.905,
      "step": 164400
    },
    {
      "epoch": 264.34,
      "learning_rate": 0.07357655375466239,
      "loss": 2.9023,
      "step": 164420
    },
    {
      "epoch": 264.37,
      "learning_rate": 0.07357333832379422,
      "loss": 2.9184,
      "step": 164440
    },
    {
      "epoch": 264.41,
      "learning_rate": 0.07357012289292604,
      "loss": 2.904,
      "step": 164460
    },
    {
      "epoch": 264.44,
      "learning_rate": 0.07356690746205789,
      "loss": 2.9517,
      "step": 164480
    },
    {
      "epoch": 264.47,
      "learning_rate": 0.0735636920311897,
      "loss": 2.9161,
      "step": 164500
    },
    {
      "epoch": 264.5,
      "learning_rate": 0.07356047660032156,
      "loss": 2.8705,
      "step": 164520
    },
    {
      "epoch": 264.53,
      "learning_rate": 0.07355726116945338,
      "loss": 2.9042,
      "step": 164540
    },
    {
      "epoch": 264.57,
      "learning_rate": 0.0735540457385852,
      "loss": 2.9102,
      "step": 164560
    },
    {
      "epoch": 264.6,
      "learning_rate": 0.07355083030771706,
      "loss": 2.9288,
      "step": 164580
    },
    {
      "epoch": 264.63,
      "learning_rate": 0.07354761487684887,
      "loss": 2.898,
      "step": 164600
    },
    {
      "epoch": 264.66,
      "learning_rate": 0.07354439944598072,
      "loss": 2.8977,
      "step": 164620
    },
    {
      "epoch": 264.69,
      "learning_rate": 0.07354118401511255,
      "loss": 2.9007,
      "step": 164640
    },
    {
      "epoch": 264.73,
      "learning_rate": 0.07353796858424438,
      "loss": 2.915,
      "step": 164660
    },
    {
      "epoch": 264.76,
      "learning_rate": 0.07353475315337621,
      "loss": 2.9317,
      "step": 164680
    },
    {
      "epoch": 264.79,
      "learning_rate": 0.07353153772250803,
      "loss": 2.9472,
      "step": 164700
    },
    {
      "epoch": 264.82,
      "learning_rate": 0.07352832229163989,
      "loss": 2.9132,
      "step": 164720
    },
    {
      "epoch": 264.86,
      "learning_rate": 0.0735251068607717,
      "loss": 2.8799,
      "step": 164740
    },
    {
      "epoch": 264.89,
      "learning_rate": 0.07352189142990355,
      "loss": 2.8925,
      "step": 164760
    },
    {
      "epoch": 264.92,
      "learning_rate": 0.07351867599903537,
      "loss": 2.8966,
      "step": 164780
    },
    {
      "epoch": 264.95,
      "learning_rate": 0.0735154605681672,
      "loss": 2.9367,
      "step": 164800
    },
    {
      "epoch": 264.98,
      "learning_rate": 0.07351224513729905,
      "loss": 2.9229,
      "step": 164820
    },
    {
      "epoch": 265.0,
      "eval_accuracy": {
        "accuracy": 0.3851356604213636
      },
      "eval_loss": 3.011186361312866,
      "eval_runtime": 2.9027,
      "eval_samples_per_second": 4431.406,
      "eval_steps_per_second": 69.246,
      "step": 164830
    },
    {
      "epoch": 265.02,
      "learning_rate": 0.07350902970643086,
      "loss": 2.9216,
      "step": 164840
    },
    {
      "epoch": 265.05,
      "learning_rate": 0.07350581427556271,
      "loss": 2.9357,
      "step": 164860
    },
    {
      "epoch": 265.08,
      "learning_rate": 0.07350259884469454,
      "loss": 2.9204,
      "step": 164880
    },
    {
      "epoch": 265.11,
      "learning_rate": 0.07349938341382636,
      "loss": 2.9054,
      "step": 164900
    },
    {
      "epoch": 265.14,
      "learning_rate": 0.07349616798295822,
      "loss": 2.894,
      "step": 164920
    },
    {
      "epoch": 265.18,
      "learning_rate": 0.07349295255209003,
      "loss": 2.8989,
      "step": 164940
    },
    {
      "epoch": 265.21,
      "learning_rate": 0.07348973712122188,
      "loss": 2.9329,
      "step": 164960
    },
    {
      "epoch": 265.24,
      "learning_rate": 0.0734865216903537,
      "loss": 2.8731,
      "step": 164980
    },
    {
      "epoch": 265.27,
      "learning_rate": 0.07348330625948553,
      "loss": 2.8955,
      "step": 165000
    },
    {
      "epoch": 265.31,
      "learning_rate": 0.07348009082861737,
      "loss": 2.9203,
      "step": 165020
    },
    {
      "epoch": 265.34,
      "learning_rate": 0.07347687539774919,
      "loss": 2.9274,
      "step": 165040
    },
    {
      "epoch": 265.37,
      "learning_rate": 0.07347365996688104,
      "loss": 2.926,
      "step": 165060
    },
    {
      "epoch": 265.4,
      "learning_rate": 0.07347044453601285,
      "loss": 2.92,
      "step": 165080
    },
    {
      "epoch": 265.43,
      "learning_rate": 0.0734672291051447,
      "loss": 2.9126,
      "step": 165100
    },
    {
      "epoch": 265.47,
      "learning_rate": 0.07346401367427653,
      "loss": 2.9033,
      "step": 165120
    },
    {
      "epoch": 265.5,
      "learning_rate": 0.07346079824340836,
      "loss": 2.9016,
      "step": 165140
    },
    {
      "epoch": 265.53,
      "learning_rate": 0.07345758281254021,
      "loss": 2.8823,
      "step": 165160
    },
    {
      "epoch": 265.56,
      "learning_rate": 0.07345436738167202,
      "loss": 2.912,
      "step": 165180
    },
    {
      "epoch": 265.59,
      "learning_rate": 0.07345115195080387,
      "loss": 2.9182,
      "step": 165200
    },
    {
      "epoch": 265.63,
      "learning_rate": 0.0734479365199357,
      "loss": 2.9215,
      "step": 165220
    },
    {
      "epoch": 265.66,
      "learning_rate": 0.07344472108906752,
      "loss": 2.9199,
      "step": 165240
    },
    {
      "epoch": 265.69,
      "learning_rate": 0.07344150565819937,
      "loss": 2.8934,
      "step": 165260
    },
    {
      "epoch": 265.72,
      "learning_rate": 0.07343829022733118,
      "loss": 2.8989,
      "step": 165280
    },
    {
      "epoch": 265.76,
      "learning_rate": 0.07343507479646304,
      "loss": 2.8995,
      "step": 165300
    },
    {
      "epoch": 265.79,
      "learning_rate": 0.07343185936559486,
      "loss": 2.8817,
      "step": 165320
    },
    {
      "epoch": 265.82,
      "learning_rate": 0.07342864393472669,
      "loss": 2.9248,
      "step": 165340
    },
    {
      "epoch": 265.85,
      "learning_rate": 0.07342542850385853,
      "loss": 2.9099,
      "step": 165360
    },
    {
      "epoch": 265.88,
      "learning_rate": 0.07342221307299035,
      "loss": 2.892,
      "step": 165380
    },
    {
      "epoch": 265.92,
      "learning_rate": 0.0734189976421222,
      "loss": 2.901,
      "step": 165400
    },
    {
      "epoch": 265.95,
      "learning_rate": 0.07341594298279744,
      "loss": 2.9039,
      "step": 165420
    },
    {
      "epoch": 265.98,
      "learning_rate": 0.07341272755192926,
      "loss": 2.9193,
      "step": 165440
    },
    {
      "epoch": 266.0,
      "eval_accuracy": {
        "accuracy": 0.3810930576070901
      },
      "eval_loss": 3.006359577178955,
      "eval_runtime": 3.0497,
      "eval_samples_per_second": 4217.771,
      "eval_steps_per_second": 65.908,
      "step": 165452
    },
    {
      "epoch": 266.01,
      "learning_rate": 0.0734095121210611,
      "loss": 2.8864,
      "step": 165460
    },
    {
      "epoch": 266.05,
      "learning_rate": 0.07340629669019293,
      "loss": 2.8963,
      "step": 165480
    },
    {
      "epoch": 266.08,
      "learning_rate": 0.07340308125932477,
      "loss": 2.9122,
      "step": 165500
    },
    {
      "epoch": 266.11,
      "learning_rate": 0.0733998658284566,
      "loss": 2.9135,
      "step": 165520
    },
    {
      "epoch": 266.14,
      "learning_rate": 0.07339665039758843,
      "loss": 2.9153,
      "step": 165540
    },
    {
      "epoch": 266.17,
      "learning_rate": 0.07339343496672027,
      "loss": 2.8817,
      "step": 165560
    },
    {
      "epoch": 266.21,
      "learning_rate": 0.07339021953585209,
      "loss": 2.9051,
      "step": 165580
    },
    {
      "epoch": 266.24,
      "learning_rate": 0.07338700410498393,
      "loss": 2.9333,
      "step": 165600
    },
    {
      "epoch": 266.27,
      "learning_rate": 0.07338378867411577,
      "loss": 2.9108,
      "step": 165620
    },
    {
      "epoch": 266.3,
      "learning_rate": 0.0733805732432476,
      "loss": 2.9415,
      "step": 165640
    },
    {
      "epoch": 266.33,
      "learning_rate": 0.07337735781237943,
      "loss": 2.9335,
      "step": 165660
    },
    {
      "epoch": 266.37,
      "learning_rate": 0.07337414238151126,
      "loss": 2.9021,
      "step": 165680
    },
    {
      "epoch": 266.4,
      "learning_rate": 0.0733709269506431,
      "loss": 2.8881,
      "step": 165700
    },
    {
      "epoch": 266.43,
      "learning_rate": 0.07336771151977492,
      "loss": 2.8828,
      "step": 165720
    },
    {
      "epoch": 266.46,
      "learning_rate": 0.07336449608890676,
      "loss": 2.9065,
      "step": 165740
    },
    {
      "epoch": 266.5,
      "learning_rate": 0.0733612806580386,
      "loss": 2.919,
      "step": 165760
    },
    {
      "epoch": 266.53,
      "learning_rate": 0.07335806522717042,
      "loss": 2.9167,
      "step": 165780
    },
    {
      "epoch": 266.56,
      "learning_rate": 0.07335484979630226,
      "loss": 2.9257,
      "step": 165800
    },
    {
      "epoch": 266.59,
      "learning_rate": 0.07335163436543408,
      "loss": 2.9252,
      "step": 165820
    },
    {
      "epoch": 266.62,
      "learning_rate": 0.07334841893456592,
      "loss": 2.9031,
      "step": 165840
    },
    {
      "epoch": 266.66,
      "learning_rate": 0.07334520350369776,
      "loss": 2.9366,
      "step": 165860
    },
    {
      "epoch": 266.69,
      "learning_rate": 0.07334198807282959,
      "loss": 2.907,
      "step": 165880
    },
    {
      "epoch": 266.72,
      "learning_rate": 0.07333877264196142,
      "loss": 2.9174,
      "step": 165900
    },
    {
      "epoch": 266.75,
      "learning_rate": 0.07333555721109325,
      "loss": 2.9267,
      "step": 165920
    },
    {
      "epoch": 266.78,
      "learning_rate": 0.07333234178022509,
      "loss": 2.9154,
      "step": 165940
    },
    {
      "epoch": 266.82,
      "learning_rate": 0.07332912634935693,
      "loss": 2.8951,
      "step": 165960
    },
    {
      "epoch": 266.85,
      "learning_rate": 0.07332591091848875,
      "loss": 2.9422,
      "step": 165980
    },
    {
      "epoch": 266.88,
      "learning_rate": 0.07332269548762059,
      "loss": 2.9231,
      "step": 166000
    },
    {
      "epoch": 266.91,
      "learning_rate": 0.07331948005675241,
      "loss": 2.9197,
      "step": 166020
    },
    {
      "epoch": 266.95,
      "learning_rate": 0.07331626462588425,
      "loss": 2.9248,
      "step": 166040
    },
    {
      "epoch": 266.98,
      "learning_rate": 0.07331304919501608,
      "loss": 2.8872,
      "step": 166060
    },
    {
      "epoch": 267.0,
      "eval_accuracy": {
        "accuracy": 0.38567985695405427
      },
      "eval_loss": 3.0153064727783203,
      "eval_runtime": 3.3862,
      "eval_samples_per_second": 3798.651,
      "eval_steps_per_second": 59.359,
      "step": 166074
    },
    {
      "epoch": 267.01,
      "learning_rate": 0.07330983376414792,
      "loss": 2.8919,
      "step": 166080
    },
    {
      "epoch": 267.04,
      "learning_rate": 0.07330661833327975,
      "loss": 2.9064,
      "step": 166100
    },
    {
      "epoch": 267.07,
      "learning_rate": 0.07330340290241157,
      "loss": 2.9416,
      "step": 166120
    },
    {
      "epoch": 267.11,
      "learning_rate": 0.07330018747154342,
      "loss": 2.8951,
      "step": 166140
    },
    {
      "epoch": 267.14,
      "learning_rate": 0.07329697204067524,
      "loss": 2.9031,
      "step": 166160
    },
    {
      "epoch": 267.17,
      "learning_rate": 0.07329375660980708,
      "loss": 2.8928,
      "step": 166180
    },
    {
      "epoch": 267.2,
      "learning_rate": 0.07329054117893892,
      "loss": 2.9121,
      "step": 166200
    },
    {
      "epoch": 267.23,
      "learning_rate": 0.07328732574807074,
      "loss": 2.9131,
      "step": 166220
    },
    {
      "epoch": 267.27,
      "learning_rate": 0.07328411031720258,
      "loss": 2.9083,
      "step": 166240
    },
    {
      "epoch": 267.3,
      "learning_rate": 0.07328089488633441,
      "loss": 2.9165,
      "step": 166260
    },
    {
      "epoch": 267.33,
      "learning_rate": 0.07327767945546625,
      "loss": 2.8877,
      "step": 166280
    },
    {
      "epoch": 267.36,
      "learning_rate": 0.07327446402459808,
      "loss": 2.9227,
      "step": 166300
    },
    {
      "epoch": 267.4,
      "learning_rate": 0.07327124859372991,
      "loss": 2.8785,
      "step": 166320
    },
    {
      "epoch": 267.43,
      "learning_rate": 0.07326803316286175,
      "loss": 2.8862,
      "step": 166340
    },
    {
      "epoch": 267.46,
      "learning_rate": 0.07326481773199357,
      "loss": 2.8406,
      "step": 166360
    },
    {
      "epoch": 267.49,
      "learning_rate": 0.07326160230112541,
      "loss": 2.8995,
      "step": 166380
    },
    {
      "epoch": 267.52,
      "learning_rate": 0.07325838687025724,
      "loss": 2.9017,
      "step": 166400
    },
    {
      "epoch": 267.56,
      "learning_rate": 0.07325517143938907,
      "loss": 2.9102,
      "step": 166420
    },
    {
      "epoch": 267.59,
      "learning_rate": 0.07325195600852091,
      "loss": 2.9145,
      "step": 166440
    },
    {
      "epoch": 267.62,
      "learning_rate": 0.07324874057765272,
      "loss": 2.8969,
      "step": 166460
    },
    {
      "epoch": 267.65,
      "learning_rate": 0.07324552514678458,
      "loss": 2.9036,
      "step": 166480
    },
    {
      "epoch": 267.68,
      "learning_rate": 0.0732423097159164,
      "loss": 2.9087,
      "step": 166500
    },
    {
      "epoch": 267.72,
      "learning_rate": 0.07323909428504824,
      "loss": 2.9021,
      "step": 166520
    },
    {
      "epoch": 267.75,
      "learning_rate": 0.07323587885418008,
      "loss": 2.9127,
      "step": 166540
    },
    {
      "epoch": 267.78,
      "learning_rate": 0.07323266342331189,
      "loss": 2.9733,
      "step": 166560
    },
    {
      "epoch": 267.81,
      "learning_rate": 0.07322944799244374,
      "loss": 2.9225,
      "step": 166580
    },
    {
      "epoch": 267.85,
      "learning_rate": 0.07322623256157557,
      "loss": 2.925,
      "step": 166600
    },
    {
      "epoch": 267.88,
      "learning_rate": 0.0732230171307074,
      "loss": 2.8903,
      "step": 166620
    },
    {
      "epoch": 267.91,
      "learning_rate": 0.07321980169983924,
      "loss": 2.9192,
      "step": 166640
    },
    {
      "epoch": 267.94,
      "learning_rate": 0.07321658626897105,
      "loss": 2.9246,
      "step": 166660
    },
    {
      "epoch": 267.97,
      "learning_rate": 0.0732133708381029,
      "loss": 2.9351,
      "step": 166680
    },
    {
      "epoch": 268.0,
      "eval_accuracy": {
        "accuracy": 0.3903443986628314
      },
      "eval_loss": 2.9705967903137207,
      "eval_runtime": 3.1267,
      "eval_samples_per_second": 4113.958,
      "eval_steps_per_second": 64.286,
      "step": 166696
    },
    {
      "epoch": 268.01,
      "learning_rate": 0.07321015540723473,
      "loss": 2.8998,
      "step": 166700
    },
    {
      "epoch": 268.04,
      "learning_rate": 0.07320693997636657,
      "loss": 2.9199,
      "step": 166720
    },
    {
      "epoch": 268.07,
      "learning_rate": 0.0732037245454984,
      "loss": 2.8842,
      "step": 166740
    },
    {
      "epoch": 268.1,
      "learning_rate": 0.07320050911463022,
      "loss": 2.9021,
      "step": 166760
    },
    {
      "epoch": 268.14,
      "learning_rate": 0.07319729368376207,
      "loss": 2.918,
      "step": 166780
    },
    {
      "epoch": 268.17,
      "learning_rate": 0.07319407825289388,
      "loss": 2.9349,
      "step": 166800
    },
    {
      "epoch": 268.2,
      "learning_rate": 0.07319086282202573,
      "loss": 2.9045,
      "step": 166820
    },
    {
      "epoch": 268.23,
      "learning_rate": 0.07318764739115756,
      "loss": 2.9105,
      "step": 166840
    },
    {
      "epoch": 268.26,
      "learning_rate": 0.0731844319602894,
      "loss": 2.9067,
      "step": 166860
    },
    {
      "epoch": 268.3,
      "learning_rate": 0.07318121652942124,
      "loss": 2.8994,
      "step": 166880
    },
    {
      "epoch": 268.33,
      "learning_rate": 0.07317800109855305,
      "loss": 2.9094,
      "step": 166900
    },
    {
      "epoch": 268.36,
      "learning_rate": 0.0731747856676849,
      "loss": 2.8963,
      "step": 166920
    },
    {
      "epoch": 268.39,
      "learning_rate": 0.07317157023681672,
      "loss": 2.9116,
      "step": 166940
    },
    {
      "epoch": 268.42,
      "learning_rate": 0.07316835480594856,
      "loss": 2.9015,
      "step": 166960
    },
    {
      "epoch": 268.46,
      "learning_rate": 0.0731651393750804,
      "loss": 2.8933,
      "step": 166980
    },
    {
      "epoch": 268.49,
      "learning_rate": 0.07316192394421221,
      "loss": 2.9157,
      "step": 167000
    },
    {
      "epoch": 268.52,
      "learning_rate": 0.07315870851334406,
      "loss": 2.901,
      "step": 167020
    },
    {
      "epoch": 268.55,
      "learning_rate": 0.07315549308247589,
      "loss": 2.8973,
      "step": 167040
    },
    {
      "epoch": 268.59,
      "learning_rate": 0.07315227765160773,
      "loss": 2.9,
      "step": 167060
    },
    {
      "epoch": 268.62,
      "learning_rate": 0.07314906222073955,
      "loss": 2.9057,
      "step": 167080
    },
    {
      "epoch": 268.65,
      "learning_rate": 0.07314584678987138,
      "loss": 2.9111,
      "step": 167100
    },
    {
      "epoch": 268.68,
      "learning_rate": 0.07314263135900323,
      "loss": 2.8799,
      "step": 167120
    },
    {
      "epoch": 268.71,
      "learning_rate": 0.07313941592813504,
      "loss": 2.9031,
      "step": 167140
    },
    {
      "epoch": 268.75,
      "learning_rate": 0.07313620049726689,
      "loss": 2.9139,
      "step": 167160
    },
    {
      "epoch": 268.78,
      "learning_rate": 0.07313298506639872,
      "loss": 2.912,
      "step": 167180
    },
    {
      "epoch": 268.81,
      "learning_rate": 0.07312976963553054,
      "loss": 2.9373,
      "step": 167200
    },
    {
      "epoch": 268.84,
      "learning_rate": 0.0731265542046624,
      "loss": 2.9362,
      "step": 167220
    },
    {
      "epoch": 268.87,
      "learning_rate": 0.0731233387737942,
      "loss": 2.9266,
      "step": 167240
    },
    {
      "epoch": 268.91,
      "learning_rate": 0.07312012334292606,
      "loss": 2.9233,
      "step": 167260
    },
    {
      "epoch": 268.94,
      "learning_rate": 0.07311690791205788,
      "loss": 2.9246,
      "step": 167280
    },
    {
      "epoch": 268.97,
      "learning_rate": 0.07311369248118971,
      "loss": 2.9159,
      "step": 167300
    },
    {
      "epoch": 269.0,
      "eval_accuracy": {
        "accuracy": 0.38148176941615486
      },
      "eval_loss": 3.026750087738037,
      "eval_runtime": 3.1031,
      "eval_samples_per_second": 4145.234,
      "eval_steps_per_second": 64.774,
      "step": 167318
    },
    {
      "epoch": 269.0,
      "learning_rate": 0.07311047705032156,
      "loss": 2.8987,
      "step": 167320
    },
    {
      "epoch": 269.04,
      "learning_rate": 0.07310726161945337,
      "loss": 2.9,
      "step": 167340
    },
    {
      "epoch": 269.07,
      "learning_rate": 0.07310404618858522,
      "loss": 2.8827,
      "step": 167360
    },
    {
      "epoch": 269.1,
      "learning_rate": 0.07310083075771705,
      "loss": 2.9177,
      "step": 167380
    },
    {
      "epoch": 269.13,
      "learning_rate": 0.07309761532684889,
      "loss": 2.8588,
      "step": 167400
    },
    {
      "epoch": 269.16,
      "learning_rate": 0.07309439989598071,
      "loss": 2.8602,
      "step": 167420
    },
    {
      "epoch": 269.2,
      "learning_rate": 0.07309134523665595,
      "loss": 2.8738,
      "step": 167440
    },
    {
      "epoch": 269.23,
      "learning_rate": 0.07308812980578779,
      "loss": 2.8658,
      "step": 167460
    },
    {
      "epoch": 269.26,
      "learning_rate": 0.07308491437491962,
      "loss": 2.9314,
      "step": 167480
    },
    {
      "epoch": 269.29,
      "learning_rate": 0.07308169894405145,
      "loss": 2.9293,
      "step": 167500
    },
    {
      "epoch": 269.32,
      "learning_rate": 0.07307848351318329,
      "loss": 2.9046,
      "step": 167520
    },
    {
      "epoch": 269.36,
      "learning_rate": 0.07307526808231511,
      "loss": 2.9169,
      "step": 167540
    },
    {
      "epoch": 269.39,
      "learning_rate": 0.07307205265144695,
      "loss": 2.907,
      "step": 167560
    },
    {
      "epoch": 269.42,
      "learning_rate": 0.07306883722057879,
      "loss": 2.9083,
      "step": 167580
    },
    {
      "epoch": 269.45,
      "learning_rate": 0.07306562178971061,
      "loss": 2.8976,
      "step": 167600
    },
    {
      "epoch": 269.49,
      "learning_rate": 0.07306240635884245,
      "loss": 2.8886,
      "step": 167620
    },
    {
      "epoch": 269.52,
      "learning_rate": 0.07305919092797428,
      "loss": 2.8849,
      "step": 167640
    },
    {
      "epoch": 269.55,
      "learning_rate": 0.07305597549710612,
      "loss": 2.8911,
      "step": 167660
    },
    {
      "epoch": 269.58,
      "learning_rate": 0.07305276006623795,
      "loss": 2.8977,
      "step": 167680
    },
    {
      "epoch": 269.61,
      "learning_rate": 0.07304954463536978,
      "loss": 2.8834,
      "step": 167700
    },
    {
      "epoch": 269.65,
      "learning_rate": 0.07304632920450162,
      "loss": 2.9111,
      "step": 167720
    },
    {
      "epoch": 269.68,
      "learning_rate": 0.07304311377363344,
      "loss": 2.9001,
      "step": 167740
    },
    {
      "epoch": 269.71,
      "learning_rate": 0.07303989834276528,
      "loss": 2.9377,
      "step": 167760
    },
    {
      "epoch": 269.74,
      "learning_rate": 0.0730366829118971,
      "loss": 2.8913,
      "step": 167780
    },
    {
      "epoch": 269.77,
      "learning_rate": 0.07303346748102894,
      "loss": 2.9115,
      "step": 167800
    },
    {
      "epoch": 269.81,
      "learning_rate": 0.07303025205016078,
      "loss": 2.9144,
      "step": 167820
    },
    {
      "epoch": 269.84,
      "learning_rate": 0.0730270366192926,
      "loss": 2.932,
      "step": 167840
    },
    {
      "epoch": 269.87,
      "learning_rate": 0.07302382118842445,
      "loss": 2.9098,
      "step": 167860
    },
    {
      "epoch": 269.9,
      "learning_rate": 0.07302060575755627,
      "loss": 2.8704,
      "step": 167880
    },
    {
      "epoch": 269.94,
      "learning_rate": 0.07301739032668811,
      "loss": 2.8916,
      "step": 167900
    },
    {
      "epoch": 269.97,
      "learning_rate": 0.07301417489581995,
      "loss": 2.8888,
      "step": 167920
    },
    {
      "epoch": 270.0,
      "learning_rate": 0.07301095946495177,
      "loss": 2.9245,
      "step": 167940
    },
    {
      "epoch": 270.0,
      "eval_accuracy": {
        "accuracy": 0.38785664308481693
      },
      "eval_loss": 2.989593505859375,
      "eval_runtime": 2.6272,
      "eval_samples_per_second": 4896.048,
      "eval_steps_per_second": 76.507,
      "step": 167940
    },
    {
      "epoch": 270.03,
      "learning_rate": 0.07300774403408361,
      "loss": 2.9462,
      "step": 167960
    },
    {
      "epoch": 270.06,
      "learning_rate": 0.07300452860321544,
      "loss": 2.8665,
      "step": 167980
    },
    {
      "epoch": 270.1,
      "learning_rate": 0.07300131317234727,
      "loss": 2.906,
      "step": 168000
    },
    {
      "epoch": 270.13,
      "learning_rate": 0.07299809774147911,
      "loss": 2.9132,
      "step": 168020
    },
    {
      "epoch": 270.16,
      "learning_rate": 0.07299488231061094,
      "loss": 2.9038,
      "step": 168040
    },
    {
      "epoch": 270.19,
      "learning_rate": 0.07299166687974278,
      "loss": 2.8974,
      "step": 168060
    },
    {
      "epoch": 270.23,
      "learning_rate": 0.0729884514488746,
      "loss": 2.9166,
      "step": 168080
    },
    {
      "epoch": 270.26,
      "learning_rate": 0.07298523601800644,
      "loss": 2.886,
      "step": 168100
    },
    {
      "epoch": 270.29,
      "learning_rate": 0.07298202058713826,
      "loss": 2.8888,
      "step": 168120
    },
    {
      "epoch": 270.32,
      "learning_rate": 0.0729788051562701,
      "loss": 2.8935,
      "step": 168140
    },
    {
      "epoch": 270.35,
      "learning_rate": 0.07297558972540194,
      "loss": 2.9051,
      "step": 168160
    },
    {
      "epoch": 270.39,
      "learning_rate": 0.07297237429453377,
      "loss": 2.8884,
      "step": 168180
    },
    {
      "epoch": 270.42,
      "learning_rate": 0.0729691588636656,
      "loss": 2.9277,
      "step": 168200
    },
    {
      "epoch": 270.45,
      "learning_rate": 0.07296594343279743,
      "loss": 2.9402,
      "step": 168220
    },
    {
      "epoch": 270.48,
      "learning_rate": 0.07296272800192927,
      "loss": 2.9497,
      "step": 168240
    },
    {
      "epoch": 270.51,
      "learning_rate": 0.0729595125710611,
      "loss": 2.9067,
      "step": 168260
    },
    {
      "epoch": 270.55,
      "learning_rate": 0.07295629714019293,
      "loss": 2.8847,
      "step": 168280
    },
    {
      "epoch": 270.58,
      "learning_rate": 0.07295308170932477,
      "loss": 2.8885,
      "step": 168300
    },
    {
      "epoch": 270.61,
      "learning_rate": 0.0729498662784566,
      "loss": 2.8997,
      "step": 168320
    },
    {
      "epoch": 270.64,
      "learning_rate": 0.07294665084758843,
      "loss": 2.9325,
      "step": 168340
    },
    {
      "epoch": 270.68,
      "learning_rate": 0.07294343541672027,
      "loss": 2.9065,
      "step": 168360
    },
    {
      "epoch": 270.71,
      "learning_rate": 0.0729402199858521,
      "loss": 2.8745,
      "step": 168380
    },
    {
      "epoch": 270.74,
      "learning_rate": 0.07293700455498393,
      "loss": 2.8931,
      "step": 168400
    },
    {
      "epoch": 270.77,
      "learning_rate": 0.07293378912411576,
      "loss": 2.8767,
      "step": 168420
    },
    {
      "epoch": 270.8,
      "learning_rate": 0.0729305736932476,
      "loss": 2.9027,
      "step": 168440
    },
    {
      "epoch": 270.84,
      "learning_rate": 0.07292735826237942,
      "loss": 2.9216,
      "step": 168460
    },
    {
      "epoch": 270.87,
      "learning_rate": 0.07292414283151126,
      "loss": 2.9353,
      "step": 168480
    },
    {
      "epoch": 270.9,
      "learning_rate": 0.0729209274006431,
      "loss": 2.8868,
      "step": 168500
    },
    {
      "epoch": 270.93,
      "learning_rate": 0.07291771196977492,
      "loss": 2.8699,
      "step": 168520
    },
    {
      "epoch": 270.96,
      "learning_rate": 0.07291449653890676,
      "loss": 2.8629,
      "step": 168540
    },
    {
      "epoch": 271.0,
      "learning_rate": 0.07291128110803859,
      "loss": 2.8856,
      "step": 168560
    },
    {
      "epoch": 271.0,
      "eval_accuracy": {
        "accuracy": 0.3882453548938817
      },
      "eval_loss": 2.9805397987365723,
      "eval_runtime": 2.9542,
      "eval_samples_per_second": 4354.075,
      "eval_steps_per_second": 68.038,
      "step": 168562
    },
    {
      "epoch": 271.03,
      "learning_rate": 0.07290806567717042,
      "loss": 2.8554,
      "step": 168580
    },
    {
      "epoch": 271.06,
      "learning_rate": 0.07290485024630226,
      "loss": 2.8707,
      "step": 168600
    },
    {
      "epoch": 271.09,
      "learning_rate": 0.07290163481543409,
      "loss": 2.8862,
      "step": 168620
    },
    {
      "epoch": 271.13,
      "learning_rate": 0.07289841938456593,
      "loss": 2.9129,
      "step": 168640
    },
    {
      "epoch": 271.16,
      "learning_rate": 0.07289520395369775,
      "loss": 2.922,
      "step": 168660
    },
    {
      "epoch": 271.19,
      "learning_rate": 0.07289198852282959,
      "loss": 2.8871,
      "step": 168680
    },
    {
      "epoch": 271.22,
      "learning_rate": 0.07288877309196143,
      "loss": 2.8722,
      "step": 168700
    },
    {
      "epoch": 271.25,
      "learning_rate": 0.07288555766109325,
      "loss": 2.885,
      "step": 168720
    },
    {
      "epoch": 271.29,
      "learning_rate": 0.07288234223022509,
      "loss": 2.8829,
      "step": 168740
    },
    {
      "epoch": 271.32,
      "learning_rate": 0.07287912679935692,
      "loss": 2.9281,
      "step": 168760
    },
    {
      "epoch": 271.35,
      "learning_rate": 0.07287591136848875,
      "loss": 2.8863,
      "step": 168780
    },
    {
      "epoch": 271.38,
      "learning_rate": 0.07287269593762058,
      "loss": 2.8651,
      "step": 168800
    },
    {
      "epoch": 271.41,
      "learning_rate": 0.07286948050675242,
      "loss": 2.9004,
      "step": 168820
    },
    {
      "epoch": 271.45,
      "learning_rate": 0.07286626507588426,
      "loss": 2.9134,
      "step": 168840
    },
    {
      "epoch": 271.48,
      "learning_rate": 0.07286304964501607,
      "loss": 2.9108,
      "step": 168860
    },
    {
      "epoch": 271.51,
      "learning_rate": 0.07285983421414792,
      "loss": 2.8923,
      "step": 168880
    },
    {
      "epoch": 271.54,
      "learning_rate": 0.07285661878327974,
      "loss": 2.8921,
      "step": 168900
    },
    {
      "epoch": 271.58,
      "learning_rate": 0.07285340335241158,
      "loss": 2.9144,
      "step": 168920
    },
    {
      "epoch": 271.61,
      "learning_rate": 0.07285018792154342,
      "loss": 2.9101,
      "step": 168940
    },
    {
      "epoch": 271.64,
      "learning_rate": 0.07284697249067523,
      "loss": 2.9162,
      "step": 168960
    },
    {
      "epoch": 271.67,
      "learning_rate": 0.07284375705980708,
      "loss": 2.911,
      "step": 168980
    },
    {
      "epoch": 271.7,
      "learning_rate": 0.07284054162893891,
      "loss": 2.9107,
      "step": 169000
    },
    {
      "epoch": 271.74,
      "learning_rate": 0.07283732619807075,
      "loss": 2.9279,
      "step": 169020
    },
    {
      "epoch": 271.77,
      "learning_rate": 0.07283411076720259,
      "loss": 2.8903,
      "step": 169040
    },
    {
      "epoch": 271.8,
      "learning_rate": 0.07283089533633441,
      "loss": 2.9127,
      "step": 169060
    },
    {
      "epoch": 271.83,
      "learning_rate": 0.07282767990546625,
      "loss": 2.9319,
      "step": 169080
    },
    {
      "epoch": 271.86,
      "learning_rate": 0.07282446447459807,
      "loss": 2.9037,
      "step": 169100
    },
    {
      "epoch": 271.9,
      "learning_rate": 0.07282124904372991,
      "loss": 2.9245,
      "step": 169120
    },
    {
      "epoch": 271.93,
      "learning_rate": 0.07281803361286174,
      "loss": 2.9174,
      "step": 169140
    },
    {
      "epoch": 271.96,
      "learning_rate": 0.07281481818199358,
      "loss": 2.9136,
      "step": 169160
    },
    {
      "epoch": 271.99,
      "learning_rate": 0.07281160275112541,
      "loss": 2.9183,
      "step": 169180
    },
    {
      "epoch": 272.0,
      "eval_accuracy": {
        "accuracy": 0.38622405348674493
      },
      "eval_loss": 3.011845588684082,
      "eval_runtime": 2.6973,
      "eval_samples_per_second": 4768.785,
      "eval_steps_per_second": 74.518,
      "step": 169184
    },
    {
      "epoch": 272.03,
      "learning_rate": 0.07280838732025723,
      "loss": 2.8906,
      "step": 169200
    },
    {
      "epoch": 272.06,
      "learning_rate": 0.07280517188938908,
      "loss": 2.921,
      "step": 169220
    },
    {
      "epoch": 272.09,
      "learning_rate": 0.0728019564585209,
      "loss": 2.8436,
      "step": 169240
    },
    {
      "epoch": 272.12,
      "learning_rate": 0.07279874102765274,
      "loss": 2.8835,
      "step": 169260
    },
    {
      "epoch": 272.15,
      "learning_rate": 0.07279552559678458,
      "loss": 2.9137,
      "step": 169280
    },
    {
      "epoch": 272.19,
      "learning_rate": 0.07279231016591639,
      "loss": 2.9395,
      "step": 169300
    },
    {
      "epoch": 272.22,
      "learning_rate": 0.07278909473504824,
      "loss": 2.879,
      "step": 169320
    },
    {
      "epoch": 272.25,
      "learning_rate": 0.07278587930418007,
      "loss": 2.9198,
      "step": 169340
    },
    {
      "epoch": 272.28,
      "learning_rate": 0.0727826638733119,
      "loss": 2.8943,
      "step": 169360
    },
    {
      "epoch": 272.32,
      "learning_rate": 0.07277944844244374,
      "loss": 2.8673,
      "step": 169380
    },
    {
      "epoch": 272.35,
      "learning_rate": 0.07277623301157556,
      "loss": 2.9194,
      "step": 169400
    },
    {
      "epoch": 272.38,
      "learning_rate": 0.07277301758070741,
      "loss": 2.8813,
      "step": 169420
    },
    {
      "epoch": 272.41,
      "learning_rate": 0.07276980214983923,
      "loss": 2.898,
      "step": 169440
    },
    {
      "epoch": 272.44,
      "learning_rate": 0.07276658671897107,
      "loss": 2.8741,
      "step": 169460
    },
    {
      "epoch": 272.48,
      "learning_rate": 0.0727633712881029,
      "loss": 2.8908,
      "step": 169480
    },
    {
      "epoch": 272.51,
      "learning_rate": 0.07276015585723472,
      "loss": 2.8675,
      "step": 169500
    },
    {
      "epoch": 272.54,
      "learning_rate": 0.07275710119790997,
      "loss": 2.8808,
      "step": 169520
    },
    {
      "epoch": 272.57,
      "learning_rate": 0.07275388576704181,
      "loss": 2.9533,
      "step": 169540
    },
    {
      "epoch": 272.6,
      "learning_rate": 0.07275067033617363,
      "loss": 2.859,
      "step": 169560
    },
    {
      "epoch": 272.64,
      "learning_rate": 0.07274745490530547,
      "loss": 2.9137,
      "step": 169580
    },
    {
      "epoch": 272.67,
      "learning_rate": 0.0727442394744373,
      "loss": 2.8993,
      "step": 169600
    },
    {
      "epoch": 272.7,
      "learning_rate": 0.07274102404356914,
      "loss": 2.9041,
      "step": 169620
    },
    {
      "epoch": 272.73,
      "learning_rate": 0.07273780861270097,
      "loss": 2.8788,
      "step": 169640
    },
    {
      "epoch": 272.77,
      "learning_rate": 0.0727345931818328,
      "loss": 2.9083,
      "step": 169660
    },
    {
      "epoch": 272.8,
      "learning_rate": 0.07273137775096464,
      "loss": 2.9225,
      "step": 169680
    },
    {
      "epoch": 272.83,
      "learning_rate": 0.07272816232009646,
      "loss": 2.9332,
      "step": 169700
    },
    {
      "epoch": 272.86,
      "learning_rate": 0.0727249468892283,
      "loss": 2.9471,
      "step": 169720
    },
    {
      "epoch": 272.89,
      "learning_rate": 0.07272173145836013,
      "loss": 2.9096,
      "step": 169740
    },
    {
      "epoch": 272.93,
      "learning_rate": 0.07271851602749196,
      "loss": 2.8949,
      "step": 169760
    },
    {
      "epoch": 272.96,
      "learning_rate": 0.0727153005966238,
      "loss": 2.9128,
      "step": 169780
    },
    {
      "epoch": 272.99,
      "learning_rate": 0.07271208516575564,
      "loss": 2.9062,
      "step": 169800
    },
    {
      "epoch": 273.0,
      "eval_accuracy": {
        "accuracy": 0.3866127652958097
      },
      "eval_loss": 3.023777723312378,
      "eval_runtime": 2.7131,
      "eval_samples_per_second": 4741.067,
      "eval_steps_per_second": 74.085,
      "step": 169806
    },
    {
      "epoch": 273.02,
      "learning_rate": 0.07270886973488747,
      "loss": 2.9252,
      "step": 169820
    },
    {
      "epoch": 273.05,
      "learning_rate": 0.07270565430401929,
      "loss": 2.9408,
      "step": 169840
    },
    {
      "epoch": 273.09,
      "learning_rate": 0.07270243887315113,
      "loss": 2.9074,
      "step": 169860
    },
    {
      "epoch": 273.12,
      "learning_rate": 0.07269922344228297,
      "loss": 2.9307,
      "step": 169880
    },
    {
      "epoch": 273.15,
      "learning_rate": 0.07269600801141479,
      "loss": 2.9458,
      "step": 169900
    },
    {
      "epoch": 273.18,
      "learning_rate": 0.07269279258054663,
      "loss": 2.9198,
      "step": 169920
    },
    {
      "epoch": 273.22,
      "learning_rate": 0.07268957714967846,
      "loss": 2.919,
      "step": 169940
    },
    {
      "epoch": 273.25,
      "learning_rate": 0.0726863617188103,
      "loss": 2.9198,
      "step": 169960
    },
    {
      "epoch": 273.28,
      "learning_rate": 0.07268314628794213,
      "loss": 2.8884,
      "step": 169980
    },
    {
      "epoch": 273.31,
      "learning_rate": 0.07267993085707396,
      "loss": 2.9146,
      "step": 170000
    },
    {
      "epoch": 273.34,
      "learning_rate": 0.0726767154262058,
      "loss": 2.8737,
      "step": 170020
    },
    {
      "epoch": 273.38,
      "learning_rate": 0.07267349999533762,
      "loss": 2.9072,
      "step": 170040
    },
    {
      "epoch": 273.41,
      "learning_rate": 0.07267028456446946,
      "loss": 2.8789,
      "step": 170060
    },
    {
      "epoch": 273.44,
      "learning_rate": 0.07266706913360128,
      "loss": 2.897,
      "step": 170080
    },
    {
      "epoch": 273.47,
      "learning_rate": 0.07266385370273312,
      "loss": 2.9027,
      "step": 170100
    },
    {
      "epoch": 273.5,
      "learning_rate": 0.07266063827186496,
      "loss": 2.8867,
      "step": 170120
    },
    {
      "epoch": 273.54,
      "learning_rate": 0.07265742284099679,
      "loss": 2.9096,
      "step": 170140
    },
    {
      "epoch": 273.57,
      "learning_rate": 0.07265420741012862,
      "loss": 2.8952,
      "step": 170160
    },
    {
      "epoch": 273.6,
      "learning_rate": 0.07265099197926045,
      "loss": 2.9123,
      "step": 170180
    },
    {
      "epoch": 273.63,
      "learning_rate": 0.07264777654839229,
      "loss": 2.8922,
      "step": 170200
    },
    {
      "epoch": 273.67,
      "learning_rate": 0.07264456111752413,
      "loss": 2.8778,
      "step": 170220
    },
    {
      "epoch": 273.7,
      "learning_rate": 0.07264134568665595,
      "loss": 2.8763,
      "step": 170240
    },
    {
      "epoch": 273.73,
      "learning_rate": 0.07263813025578779,
      "loss": 2.8966,
      "step": 170260
    },
    {
      "epoch": 273.76,
      "learning_rate": 0.07263491482491961,
      "loss": 2.9755,
      "step": 170280
    },
    {
      "epoch": 273.79,
      "learning_rate": 0.07263169939405145,
      "loss": 2.9072,
      "step": 170300
    },
    {
      "epoch": 273.83,
      "learning_rate": 0.07262848396318329,
      "loss": 2.8862,
      "step": 170320
    },
    {
      "epoch": 273.86,
      "learning_rate": 0.07262526853231512,
      "loss": 2.8825,
      "step": 170340
    },
    {
      "epoch": 273.89,
      "learning_rate": 0.07262205310144695,
      "loss": 2.8754,
      "step": 170360
    },
    {
      "epoch": 273.92,
      "learning_rate": 0.07261883767057878,
      "loss": 2.8749,
      "step": 170380
    },
    {
      "epoch": 273.95,
      "learning_rate": 0.07261562223971062,
      "loss": 2.8846,
      "step": 170400
    },
    {
      "epoch": 273.99,
      "learning_rate": 0.07261240680884246,
      "loss": 2.9142,
      "step": 170420
    },
    {
      "epoch": 274.0,
      "eval_accuracy": {
        "accuracy": 0.38381404027054344
      },
      "eval_loss": 3.026906967163086,
      "eval_runtime": 3.24,
      "eval_samples_per_second": 3970.122,
      "eval_steps_per_second": 62.038,
      "step": 170428
    },
    {
      "epoch": 274.02,
      "learning_rate": 0.07260919137797428,
      "loss": 2.9051,
      "step": 170440
    },
    {
      "epoch": 274.05,
      "learning_rate": 0.07260597594710612,
      "loss": 2.9145,
      "step": 170460
    },
    {
      "epoch": 274.08,
      "learning_rate": 0.07260276051623794,
      "loss": 2.8917,
      "step": 170480
    },
    {
      "epoch": 274.12,
      "learning_rate": 0.07259954508536978,
      "loss": 2.902,
      "step": 170500
    },
    {
      "epoch": 274.15,
      "learning_rate": 0.0725963296545016,
      "loss": 2.9177,
      "step": 170520
    },
    {
      "epoch": 274.18,
      "learning_rate": 0.07259311422363345,
      "loss": 2.9101,
      "step": 170540
    },
    {
      "epoch": 274.21,
      "learning_rate": 0.07258989879276528,
      "loss": 2.896,
      "step": 170560
    },
    {
      "epoch": 274.24,
      "learning_rate": 0.07258668336189711,
      "loss": 2.8984,
      "step": 170580
    },
    {
      "epoch": 274.28,
      "learning_rate": 0.07258346793102895,
      "loss": 2.8959,
      "step": 170600
    },
    {
      "epoch": 274.31,
      "learning_rate": 0.07258025250016077,
      "loss": 2.8885,
      "step": 170620
    },
    {
      "epoch": 274.34,
      "learning_rate": 0.07257703706929261,
      "loss": 2.8746,
      "step": 170640
    },
    {
      "epoch": 274.37,
      "learning_rate": 0.07257382163842445,
      "loss": 2.8514,
      "step": 170660
    },
    {
      "epoch": 274.41,
      "learning_rate": 0.07257060620755627,
      "loss": 2.8744,
      "step": 170680
    },
    {
      "epoch": 274.44,
      "learning_rate": 0.07256739077668811,
      "loss": 2.9043,
      "step": 170700
    },
    {
      "epoch": 274.47,
      "learning_rate": 0.07256417534581994,
      "loss": 2.9372,
      "step": 170720
    },
    {
      "epoch": 274.5,
      "learning_rate": 0.07256095991495178,
      "loss": 2.9222,
      "step": 170740
    },
    {
      "epoch": 274.53,
      "learning_rate": 0.07255774448408361,
      "loss": 2.9122,
      "step": 170760
    },
    {
      "epoch": 274.57,
      "learning_rate": 0.07255452905321544,
      "loss": 2.8917,
      "step": 170780
    },
    {
      "epoch": 274.6,
      "learning_rate": 0.07255131362234728,
      "loss": 2.8487,
      "step": 170800
    },
    {
      "epoch": 274.63,
      "learning_rate": 0.0725480981914791,
      "loss": 2.8553,
      "step": 170820
    },
    {
      "epoch": 274.66,
      "learning_rate": 0.07254488276061094,
      "loss": 2.9185,
      "step": 170840
    },
    {
      "epoch": 274.69,
      "learning_rate": 0.07254166732974276,
      "loss": 2.9047,
      "step": 170860
    },
    {
      "epoch": 274.73,
      "learning_rate": 0.0725384518988746,
      "loss": 2.9152,
      "step": 170880
    },
    {
      "epoch": 274.76,
      "learning_rate": 0.07253523646800644,
      "loss": 2.8847,
      "step": 170900
    },
    {
      "epoch": 274.79,
      "learning_rate": 0.07253202103713827,
      "loss": 2.8624,
      "step": 170920
    },
    {
      "epoch": 274.82,
      "learning_rate": 0.0725288056062701,
      "loss": 2.8869,
      "step": 170940
    },
    {
      "epoch": 274.86,
      "learning_rate": 0.07252559017540193,
      "loss": 2.9009,
      "step": 170960
    },
    {
      "epoch": 274.89,
      "learning_rate": 0.07252237474453377,
      "loss": 2.9199,
      "step": 170980
    },
    {
      "epoch": 274.92,
      "learning_rate": 0.07251915931366561,
      "loss": 2.8983,
      "step": 171000
    },
    {
      "epoch": 274.95,
      "learning_rate": 0.07251594388279743,
      "loss": 2.8996,
      "step": 171020
    },
    {
      "epoch": 274.98,
      "learning_rate": 0.07251272845192927,
      "loss": 2.8686,
      "step": 171040
    },
    {
      "epoch": 275.0,
      "eval_accuracy": {
        "accuracy": 0.38972245976832776
      },
      "eval_loss": 3.0035183429718018,
      "eval_runtime": 2.7129,
      "eval_samples_per_second": 4741.341,
      "eval_steps_per_second": 74.089,
      "step": 171050
    },
    {
      "epoch": 275.02,
      "learning_rate": 0.0725095130210611,
      "loss": 2.9061,
      "step": 171060
    },
    {
      "epoch": 275.05,
      "learning_rate": 0.07250629759019293,
      "loss": 2.869,
      "step": 171080
    },
    {
      "epoch": 275.08,
      "learning_rate": 0.07250308215932477,
      "loss": 2.8687,
      "step": 171100
    },
    {
      "epoch": 275.11,
      "learning_rate": 0.0724998667284566,
      "loss": 2.8706,
      "step": 171120
    },
    {
      "epoch": 275.14,
      "learning_rate": 0.07249665129758844,
      "loss": 2.8732,
      "step": 171140
    },
    {
      "epoch": 275.18,
      "learning_rate": 0.07249343586672026,
      "loss": 2.8747,
      "step": 171160
    },
    {
      "epoch": 275.21,
      "learning_rate": 0.0724902204358521,
      "loss": 2.9,
      "step": 171180
    },
    {
      "epoch": 275.24,
      "learning_rate": 0.07248700500498392,
      "loss": 2.9325,
      "step": 171200
    },
    {
      "epoch": 275.27,
      "learning_rate": 0.07248378957411576,
      "loss": 2.9033,
      "step": 171220
    },
    {
      "epoch": 275.31,
      "learning_rate": 0.0724805741432476,
      "loss": 2.9088,
      "step": 171240
    },
    {
      "epoch": 275.34,
      "learning_rate": 0.07247735871237942,
      "loss": 2.9063,
      "step": 171260
    },
    {
      "epoch": 275.37,
      "learning_rate": 0.07247414328151126,
      "loss": 2.8918,
      "step": 171280
    },
    {
      "epoch": 275.4,
      "learning_rate": 0.07247092785064309,
      "loss": 2.9029,
      "step": 171300
    },
    {
      "epoch": 275.43,
      "learning_rate": 0.07246771241977493,
      "loss": 2.8875,
      "step": 171320
    },
    {
      "epoch": 275.47,
      "learning_rate": 0.07246449698890677,
      "loss": 2.8758,
      "step": 171340
    },
    {
      "epoch": 275.5,
      "learning_rate": 0.07246128155803859,
      "loss": 2.8591,
      "step": 171360
    },
    {
      "epoch": 275.53,
      "learning_rate": 0.07245806612717043,
      "loss": 2.9002,
      "step": 171380
    },
    {
      "epoch": 275.56,
      "learning_rate": 0.07245485069630225,
      "loss": 2.8837,
      "step": 171400
    },
    {
      "epoch": 275.59,
      "learning_rate": 0.07245163526543409,
      "loss": 2.9439,
      "step": 171420
    },
    {
      "epoch": 275.63,
      "learning_rate": 0.07244841983456593,
      "loss": 2.9091,
      "step": 171440
    },
    {
      "epoch": 275.66,
      "learning_rate": 0.07244520440369775,
      "loss": 2.8903,
      "step": 171460
    },
    {
      "epoch": 275.69,
      "learning_rate": 0.0724419889728296,
      "loss": 2.895,
      "step": 171480
    },
    {
      "epoch": 275.72,
      "learning_rate": 0.07243877354196142,
      "loss": 2.8842,
      "step": 171500
    },
    {
      "epoch": 275.76,
      "learning_rate": 0.07243555811109326,
      "loss": 2.9027,
      "step": 171520
    },
    {
      "epoch": 275.79,
      "learning_rate": 0.07243234268022508,
      "loss": 2.89,
      "step": 171540
    },
    {
      "epoch": 275.82,
      "learning_rate": 0.07242912724935692,
      "loss": 2.9126,
      "step": 171560
    },
    {
      "epoch": 275.85,
      "learning_rate": 0.07242591181848876,
      "loss": 2.9079,
      "step": 171580
    },
    {
      "epoch": 275.88,
      "learning_rate": 0.07242269638762057,
      "loss": 2.9177,
      "step": 171600
    },
    {
      "epoch": 275.92,
      "learning_rate": 0.07241948095675242,
      "loss": 2.915,
      "step": 171620
    },
    {
      "epoch": 275.95,
      "learning_rate": 0.07241642629742766,
      "loss": 2.8957,
      "step": 171640
    },
    {
      "epoch": 275.98,
      "learning_rate": 0.0724132108665595,
      "loss": 2.9327,
      "step": 171660
    },
    {
      "epoch": 276.0,
      "eval_accuracy": {
        "accuracy": 0.38295887429060094
      },
      "eval_loss": 2.999295949935913,
      "eval_runtime": 3.2232,
      "eval_samples_per_second": 3990.773,
      "eval_steps_per_second": 62.361,
      "step": 171672
    },
    {
      "epoch": 276.01,
      "learning_rate": 0.07240999543569132,
      "loss": 2.8887,
      "step": 171680
    },
    {
      "epoch": 276.05,
      "learning_rate": 0.07240678000482316,
      "loss": 2.9024,
      "step": 171700
    },
    {
      "epoch": 276.08,
      "learning_rate": 0.07240356457395498,
      "loss": 2.9114,
      "step": 171720
    },
    {
      "epoch": 276.11,
      "learning_rate": 0.07240034914308682,
      "loss": 2.8902,
      "step": 171740
    },
    {
      "epoch": 276.14,
      "learning_rate": 0.07239713371221866,
      "loss": 2.9035,
      "step": 171760
    },
    {
      "epoch": 276.17,
      "learning_rate": 0.07239391828135049,
      "loss": 2.9117,
      "step": 171780
    },
    {
      "epoch": 276.21,
      "learning_rate": 0.07239070285048231,
      "loss": 2.8899,
      "step": 171800
    },
    {
      "epoch": 276.24,
      "learning_rate": 0.07238748741961415,
      "loss": 2.8787,
      "step": 171820
    },
    {
      "epoch": 276.27,
      "learning_rate": 0.07238427198874599,
      "loss": 2.8933,
      "step": 171840
    },
    {
      "epoch": 276.3,
      "learning_rate": 0.07238105655787783,
      "loss": 2.9015,
      "step": 171860
    },
    {
      "epoch": 276.33,
      "learning_rate": 0.07237784112700965,
      "loss": 2.8486,
      "step": 171880
    },
    {
      "epoch": 276.37,
      "learning_rate": 0.07237462569614148,
      "loss": 2.8676,
      "step": 171900
    },
    {
      "epoch": 276.4,
      "learning_rate": 0.07237141026527331,
      "loss": 2.8504,
      "step": 171920
    },
    {
      "epoch": 276.43,
      "learning_rate": 0.07236819483440515,
      "loss": 2.852,
      "step": 171940
    },
    {
      "epoch": 276.46,
      "learning_rate": 0.07236497940353698,
      "loss": 2.8713,
      "step": 171960
    },
    {
      "epoch": 276.5,
      "learning_rate": 0.07236176397266882,
      "loss": 2.89,
      "step": 171980
    },
    {
      "epoch": 276.53,
      "learning_rate": 0.07235854854180065,
      "loss": 2.8913,
      "step": 172000
    },
    {
      "epoch": 276.56,
      "learning_rate": 0.07235533311093248,
      "loss": 2.908,
      "step": 172020
    },
    {
      "epoch": 276.59,
      "learning_rate": 0.07235211768006432,
      "loss": 2.895,
      "step": 172040
    },
    {
      "epoch": 276.62,
      "learning_rate": 0.07234890224919614,
      "loss": 2.8821,
      "step": 172060
    },
    {
      "epoch": 276.66,
      "learning_rate": 0.07234568681832798,
      "loss": 2.9349,
      "step": 172080
    },
    {
      "epoch": 276.69,
      "learning_rate": 0.07234247138745982,
      "loss": 2.8962,
      "step": 172100
    },
    {
      "epoch": 276.72,
      "learning_rate": 0.07233925595659164,
      "loss": 2.9061,
      "step": 172120
    },
    {
      "epoch": 276.75,
      "learning_rate": 0.07233604052572347,
      "loss": 2.9257,
      "step": 172140
    },
    {
      "epoch": 276.78,
      "learning_rate": 0.07233282509485531,
      "loss": 2.917,
      "step": 172160
    },
    {
      "epoch": 276.82,
      "learning_rate": 0.07232960966398715,
      "loss": 2.9379,
      "step": 172180
    },
    {
      "epoch": 276.85,
      "learning_rate": 0.07232639423311898,
      "loss": 2.9267,
      "step": 172200
    },
    {
      "epoch": 276.88,
      "learning_rate": 0.07232317880225081,
      "loss": 2.8969,
      "step": 172220
    },
    {
      "epoch": 276.91,
      "learning_rate": 0.07231996337138263,
      "loss": 2.8744,
      "step": 172240
    },
    {
      "epoch": 276.95,
      "learning_rate": 0.07231674794051447,
      "loss": 2.9058,
      "step": 172260
    },
    {
      "epoch": 276.98,
      "learning_rate": 0.07231353250964631,
      "loss": 2.9049,
      "step": 172280
    },
    {
      "epoch": 277.0,
      "eval_accuracy": {
        "accuracy": 0.37860530202907566
      },
      "eval_loss": 3.0418217182159424,
      "eval_runtime": 2.8665,
      "eval_samples_per_second": 4487.286,
      "eval_steps_per_second": 70.119,
      "step": 172294
    },
    {
      "epoch": 277.01,
      "learning_rate": 0.07231031707877814,
      "loss": 2.8982,
      "step": 172300
    },
    {
      "epoch": 277.04,
      "learning_rate": 0.07230710164790997,
      "loss": 2.9098,
      "step": 172320
    },
    {
      "epoch": 277.07,
      "learning_rate": 0.0723038862170418,
      "loss": 2.8926,
      "step": 172340
    },
    {
      "epoch": 277.11,
      "learning_rate": 0.07230067078617364,
      "loss": 2.8791,
      "step": 172360
    },
    {
      "epoch": 277.14,
      "learning_rate": 0.07229745535530548,
      "loss": 2.898,
      "step": 172380
    },
    {
      "epoch": 277.17,
      "learning_rate": 0.0722942399244373,
      "loss": 2.9006,
      "step": 172400
    },
    {
      "epoch": 277.2,
      "learning_rate": 0.07229102449356914,
      "loss": 2.8972,
      "step": 172420
    },
    {
      "epoch": 277.23,
      "learning_rate": 0.07228780906270096,
      "loss": 2.8861,
      "step": 172440
    },
    {
      "epoch": 277.27,
      "learning_rate": 0.0722845936318328,
      "loss": 2.8605,
      "step": 172460
    },
    {
      "epoch": 277.3,
      "learning_rate": 0.07228137820096463,
      "loss": 2.892,
      "step": 172480
    },
    {
      "epoch": 277.33,
      "learning_rate": 0.07227816277009647,
      "loss": 2.9053,
      "step": 172500
    },
    {
      "epoch": 277.36,
      "learning_rate": 0.0722749473392283,
      "loss": 2.9195,
      "step": 172520
    },
    {
      "epoch": 277.4,
      "learning_rate": 0.07227173190836014,
      "loss": 2.935,
      "step": 172540
    },
    {
      "epoch": 277.43,
      "learning_rate": 0.07226851647749197,
      "loss": 2.9071,
      "step": 172560
    },
    {
      "epoch": 277.46,
      "learning_rate": 0.07226530104662379,
      "loss": 2.8944,
      "step": 172580
    },
    {
      "epoch": 277.49,
      "learning_rate": 0.07226208561575563,
      "loss": 2.8992,
      "step": 172600
    },
    {
      "epoch": 277.52,
      "learning_rate": 0.07225887018488747,
      "loss": 2.8878,
      "step": 172620
    },
    {
      "epoch": 277.56,
      "learning_rate": 0.0722556547540193,
      "loss": 2.9154,
      "step": 172640
    },
    {
      "epoch": 277.59,
      "learning_rate": 0.07225243932315113,
      "loss": 2.8797,
      "step": 172660
    },
    {
      "epoch": 277.62,
      "learning_rate": 0.07224922389228296,
      "loss": 2.888,
      "step": 172680
    },
    {
      "epoch": 277.65,
      "learning_rate": 0.0722460084614148,
      "loss": 2.9308,
      "step": 172700
    },
    {
      "epoch": 277.68,
      "learning_rate": 0.07224279303054663,
      "loss": 2.8964,
      "step": 172720
    },
    {
      "epoch": 277.72,
      "learning_rate": 0.07223957759967846,
      "loss": 2.8807,
      "step": 172740
    },
    {
      "epoch": 277.75,
      "learning_rate": 0.0722363621688103,
      "loss": 2.8844,
      "step": 172760
    },
    {
      "epoch": 277.78,
      "learning_rate": 0.07223314673794212,
      "loss": 2.8829,
      "step": 172780
    },
    {
      "epoch": 277.81,
      "learning_rate": 0.07222993130707396,
      "loss": 2.8942,
      "step": 172800
    },
    {
      "epoch": 277.85,
      "learning_rate": 0.0722267158762058,
      "loss": 2.9119,
      "step": 172820
    },
    {
      "epoch": 277.88,
      "learning_rate": 0.07222350044533762,
      "loss": 2.9087,
      "step": 172840
    },
    {
      "epoch": 277.91,
      "learning_rate": 0.07222028501446946,
      "loss": 2.906,
      "step": 172860
    },
    {
      "epoch": 277.94,
      "learning_rate": 0.07221706958360129,
      "loss": 2.8937,
      "step": 172880
    },
    {
      "epoch": 277.97,
      "learning_rate": 0.07221385415273313,
      "loss": 2.903,
      "step": 172900
    },
    {
      "epoch": 278.0,
      "eval_accuracy": {
        "accuracy": 0.38295887429060094
      },
      "eval_loss": 3.0172581672668457,
      "eval_runtime": 2.8942,
      "eval_samples_per_second": 4444.337,
      "eval_steps_per_second": 69.448,
      "step": 172916
    },
    {
      "epoch": 278.01,
      "learning_rate": 0.07221063872186495,
      "loss": 2.8782,
      "step": 172920
    },
    {
      "epoch": 278.04,
      "learning_rate": 0.07220742329099679,
      "loss": 2.8629,
      "step": 172940
    },
    {
      "epoch": 278.07,
      "learning_rate": 0.07220420786012863,
      "loss": 2.8561,
      "step": 172960
    },
    {
      "epoch": 278.1,
      "learning_rate": 0.07220099242926045,
      "loss": 2.8695,
      "step": 172980
    },
    {
      "epoch": 278.14,
      "learning_rate": 0.07219777699839229,
      "loss": 2.8553,
      "step": 173000
    },
    {
      "epoch": 278.17,
      "learning_rate": 0.07219456156752412,
      "loss": 2.8731,
      "step": 173020
    },
    {
      "epoch": 278.2,
      "learning_rate": 0.07219134613665595,
      "loss": 2.8853,
      "step": 173040
    },
    {
      "epoch": 278.23,
      "learning_rate": 0.07218813070578779,
      "loss": 2.9208,
      "step": 173060
    },
    {
      "epoch": 278.26,
      "learning_rate": 0.07218491527491962,
      "loss": 2.934,
      "step": 173080
    },
    {
      "epoch": 278.3,
      "learning_rate": 0.07218169984405146,
      "loss": 2.8979,
      "step": 173100
    },
    {
      "epoch": 278.33,
      "learning_rate": 0.07217848441318328,
      "loss": 2.9099,
      "step": 173120
    },
    {
      "epoch": 278.36,
      "learning_rate": 0.07217526898231512,
      "loss": 2.8922,
      "step": 173140
    },
    {
      "epoch": 278.39,
      "learning_rate": 0.07217205355144696,
      "loss": 2.8953,
      "step": 173160
    },
    {
      "epoch": 278.42,
      "learning_rate": 0.07216883812057878,
      "loss": 2.8928,
      "step": 173180
    },
    {
      "epoch": 278.46,
      "learning_rate": 0.07216562268971062,
      "loss": 2.8828,
      "step": 173200
    },
    {
      "epoch": 278.49,
      "learning_rate": 0.07216240725884245,
      "loss": 2.8934,
      "step": 173220
    },
    {
      "epoch": 278.52,
      "learning_rate": 0.07215919182797428,
      "loss": 2.8848,
      "step": 173240
    },
    {
      "epoch": 278.55,
      "learning_rate": 0.07215597639710611,
      "loss": 2.8699,
      "step": 173260
    },
    {
      "epoch": 278.59,
      "learning_rate": 0.07215276096623795,
      "loss": 2.8923,
      "step": 173280
    },
    {
      "epoch": 278.62,
      "learning_rate": 0.07214954553536979,
      "loss": 2.9076,
      "step": 173300
    },
    {
      "epoch": 278.65,
      "learning_rate": 0.07214633010450161,
      "loss": 2.8971,
      "step": 173320
    },
    {
      "epoch": 278.68,
      "learning_rate": 0.07214311467363345,
      "loss": 2.8609,
      "step": 173340
    },
    {
      "epoch": 278.71,
      "learning_rate": 0.07213989924276527,
      "loss": 2.8754,
      "step": 173360
    },
    {
      "epoch": 278.75,
      "learning_rate": 0.07213668381189711,
      "loss": 2.898,
      "step": 173380
    },
    {
      "epoch": 278.78,
      "learning_rate": 0.07213346838102895,
      "loss": 2.8963,
      "step": 173400
    },
    {
      "epoch": 278.81,
      "learning_rate": 0.07213025295016078,
      "loss": 2.9195,
      "step": 173420
    },
    {
      "epoch": 278.84,
      "learning_rate": 0.07212703751929261,
      "loss": 2.9011,
      "step": 173440
    },
    {
      "epoch": 278.87,
      "learning_rate": 0.07212382208842444,
      "loss": 2.8775,
      "step": 173460
    },
    {
      "epoch": 278.91,
      "learning_rate": 0.07212060665755628,
      "loss": 2.8811,
      "step": 173480
    },
    {
      "epoch": 278.94,
      "learning_rate": 0.07211739122668812,
      "loss": 2.9482,
      "step": 173500
    },
    {
      "epoch": 278.97,
      "learning_rate": 0.07211417579581994,
      "loss": 2.8904,
      "step": 173520
    },
    {
      "epoch": 279.0,
      "eval_accuracy": {
        "accuracy": 0.3867682500194356
      },
      "eval_loss": 2.98333477973938,
      "eval_runtime": 2.6839,
      "eval_samples_per_second": 4792.695,
      "eval_steps_per_second": 74.892,
      "step": 173538
    },
    {
      "epoch": 279.0,
      "learning_rate": 0.07211096036495178,
      "loss": 2.8739,
      "step": 173540
    },
    {
      "epoch": 279.04,
      "learning_rate": 0.0721077449340836,
      "loss": 2.8863,
      "step": 173560
    },
    {
      "epoch": 279.07,
      "learning_rate": 0.07210452950321544,
      "loss": 2.894,
      "step": 173580
    },
    {
      "epoch": 279.1,
      "learning_rate": 0.07210131407234727,
      "loss": 2.8976,
      "step": 173600
    },
    {
      "epoch": 279.13,
      "learning_rate": 0.0720980986414791,
      "loss": 2.873,
      "step": 173620
    },
    {
      "epoch": 279.16,
      "learning_rate": 0.07209488321061094,
      "loss": 2.8859,
      "step": 173640
    },
    {
      "epoch": 279.2,
      "learning_rate": 0.07209166777974277,
      "loss": 2.877,
      "step": 173660
    },
    {
      "epoch": 279.23,
      "learning_rate": 0.07208845234887461,
      "loss": 2.8777,
      "step": 173680
    },
    {
      "epoch": 279.26,
      "learning_rate": 0.07208539768954984,
      "loss": 2.8717,
      "step": 173700
    },
    {
      "epoch": 279.29,
      "learning_rate": 0.07208218225868168,
      "loss": 2.8911,
      "step": 173720
    },
    {
      "epoch": 279.32,
      "learning_rate": 0.0720789668278135,
      "loss": 2.897,
      "step": 173740
    },
    {
      "epoch": 279.36,
      "learning_rate": 0.07207575139694535,
      "loss": 2.8563,
      "step": 173760
    },
    {
      "epoch": 279.39,
      "learning_rate": 0.07207253596607717,
      "loss": 2.9043,
      "step": 173780
    },
    {
      "epoch": 279.42,
      "learning_rate": 0.07206932053520901,
      "loss": 2.8882,
      "step": 173800
    },
    {
      "epoch": 279.45,
      "learning_rate": 0.07206610510434085,
      "loss": 2.9113,
      "step": 173820
    },
    {
      "epoch": 279.49,
      "learning_rate": 0.07206288967347267,
      "loss": 2.8899,
      "step": 173840
    },
    {
      "epoch": 279.52,
      "learning_rate": 0.07205967424260451,
      "loss": 2.8809,
      "step": 173860
    },
    {
      "epoch": 279.55,
      "learning_rate": 0.07205645881173633,
      "loss": 2.87,
      "step": 173880
    },
    {
      "epoch": 279.58,
      "learning_rate": 0.07205324338086817,
      "loss": 2.9052,
      "step": 173900
    },
    {
      "epoch": 279.61,
      "learning_rate": 0.07205002795,
      "loss": 2.9468,
      "step": 173920
    },
    {
      "epoch": 279.65,
      "learning_rate": 0.07204681251913184,
      "loss": 2.9368,
      "step": 173940
    },
    {
      "epoch": 279.68,
      "learning_rate": 0.07204359708826368,
      "loss": 2.9275,
      "step": 173960
    },
    {
      "epoch": 279.71,
      "learning_rate": 0.0720403816573955,
      "loss": 2.8991,
      "step": 173980
    },
    {
      "epoch": 279.74,
      "learning_rate": 0.07203716622652734,
      "loss": 2.9024,
      "step": 174000
    },
    {
      "epoch": 279.77,
      "learning_rate": 0.07203395079565916,
      "loss": 2.885,
      "step": 174020
    },
    {
      "epoch": 279.81,
      "learning_rate": 0.072030735364791,
      "loss": 2.8856,
      "step": 174040
    },
    {
      "epoch": 279.84,
      "learning_rate": 0.07202751993392284,
      "loss": 2.8873,
      "step": 174060
    },
    {
      "epoch": 279.87,
      "learning_rate": 0.07202430450305466,
      "loss": 2.8759,
      "step": 174080
    },
    {
      "epoch": 279.9,
      "learning_rate": 0.0720210890721865,
      "loss": 2.9004,
      "step": 174100
    },
    {
      "epoch": 279.94,
      "learning_rate": 0.07201787364131833,
      "loss": 2.8955,
      "step": 174120
    },
    {
      "epoch": 279.97,
      "learning_rate": 0.07201465821045017,
      "loss": 2.8956,
      "step": 174140
    },
    {
      "epoch": 280.0,
      "learning_rate": 0.072011442779582,
      "loss": 2.891,
      "step": 174160
    },
    {
      "epoch": 280.0,
      "eval_accuracy": {
        "accuracy": 0.3849801756977377
      },
      "eval_loss": 3.017800807952881,
      "eval_runtime": 2.885,
      "eval_samples_per_second": 4458.646,
      "eval_steps_per_second": 69.672,
      "step": 174160
    },
    {
      "epoch": 280.03,
      "learning_rate": 0.07200822734871383,
      "loss": 2.8765,
      "step": 174180
    },
    {
      "epoch": 280.06,
      "learning_rate": 0.07200501191784567,
      "loss": 2.8843,
      "step": 174200
    },
    {
      "epoch": 280.1,
      "learning_rate": 0.07200179648697749,
      "loss": 2.8974,
      "step": 174220
    },
    {
      "epoch": 280.13,
      "learning_rate": 0.07199858105610933,
      "loss": 2.8571,
      "step": 174240
    },
    {
      "epoch": 280.16,
      "learning_rate": 0.07199536562524116,
      "loss": 2.8548,
      "step": 174260
    },
    {
      "epoch": 280.19,
      "learning_rate": 0.071992150194373,
      "loss": 2.8638,
      "step": 174280
    },
    {
      "epoch": 280.23,
      "learning_rate": 0.07198893476350483,
      "loss": 2.8768,
      "step": 174300
    },
    {
      "epoch": 280.26,
      "learning_rate": 0.07198571933263666,
      "loss": 2.9073,
      "step": 174320
    },
    {
      "epoch": 280.29,
      "learning_rate": 0.0719825039017685,
      "loss": 2.8895,
      "step": 174340
    },
    {
      "epoch": 280.32,
      "learning_rate": 0.07197928847090032,
      "loss": 2.9186,
      "step": 174360
    },
    {
      "epoch": 280.35,
      "learning_rate": 0.07197607304003216,
      "loss": 2.9204,
      "step": 174380
    },
    {
      "epoch": 280.39,
      "learning_rate": 0.071972857609164,
      "loss": 2.907,
      "step": 174400
    },
    {
      "epoch": 280.42,
      "learning_rate": 0.07196964217829582,
      "loss": 2.899,
      "step": 174420
    },
    {
      "epoch": 280.45,
      "learning_rate": 0.07196642674742766,
      "loss": 2.9034,
      "step": 174440
    },
    {
      "epoch": 280.48,
      "learning_rate": 0.07196321131655949,
      "loss": 2.8871,
      "step": 174460
    },
    {
      "epoch": 280.51,
      "learning_rate": 0.07195999588569132,
      "loss": 2.8964,
      "step": 174480
    },
    {
      "epoch": 280.55,
      "learning_rate": 0.07195678045482316,
      "loss": 2.9264,
      "step": 174500
    },
    {
      "epoch": 280.58,
      "learning_rate": 0.07195356502395499,
      "loss": 2.9043,
      "step": 174520
    },
    {
      "epoch": 280.61,
      "learning_rate": 0.07195034959308681,
      "loss": 2.8792,
      "step": 174540
    },
    {
      "epoch": 280.64,
      "learning_rate": 0.07194713416221865,
      "loss": 2.8843,
      "step": 174560
    },
    {
      "epoch": 280.68,
      "learning_rate": 0.07194391873135049,
      "loss": 2.9226,
      "step": 174580
    },
    {
      "epoch": 280.71,
      "learning_rate": 0.07194070330048233,
      "loss": 2.9098,
      "step": 174600
    },
    {
      "epoch": 280.74,
      "learning_rate": 0.07193748786961415,
      "loss": 2.8619,
      "step": 174620
    },
    {
      "epoch": 280.77,
      "learning_rate": 0.07193427243874598,
      "loss": 2.8803,
      "step": 174640
    },
    {
      "epoch": 280.8,
      "learning_rate": 0.07193105700787782,
      "loss": 2.8858,
      "step": 174660
    },
    {
      "epoch": 280.84,
      "learning_rate": 0.07192784157700965,
      "loss": 2.9154,
      "step": 174680
    },
    {
      "epoch": 280.87,
      "learning_rate": 0.07192462614614148,
      "loss": 2.9077,
      "step": 174700
    },
    {
      "epoch": 280.9,
      "learning_rate": 0.07192141071527332,
      "loss": 2.8901,
      "step": 174720
    },
    {
      "epoch": 280.93,
      "learning_rate": 0.07191819528440516,
      "loss": 2.8931,
      "step": 174740
    },
    {
      "epoch": 280.96,
      "learning_rate": 0.07191497985353698,
      "loss": 2.8756,
      "step": 174760
    },
    {
      "epoch": 281.0,
      "learning_rate": 0.07191176442266882,
      "loss": 2.8627,
      "step": 174780
    },
    {
      "epoch": 281.0,
      "eval_accuracy": {
        "accuracy": 0.38451372152686
      },
      "eval_loss": 2.9754831790924072,
      "eval_runtime": 2.7577,
      "eval_samples_per_second": 4664.367,
      "eval_steps_per_second": 72.886,
      "step": 174782
    },
    {
      "epoch": 281.03,
      "learning_rate": 0.07190854899180064,
      "loss": 2.8815,
      "step": 174800
    },
    {
      "epoch": 281.06,
      "learning_rate": 0.07190533356093248,
      "loss": 2.8588,
      "step": 174820
    },
    {
      "epoch": 281.09,
      "learning_rate": 0.07190211813006432,
      "loss": 2.8973,
      "step": 174840
    },
    {
      "epoch": 281.13,
      "learning_rate": 0.07189890269919615,
      "loss": 2.8669,
      "step": 174860
    },
    {
      "epoch": 281.16,
      "learning_rate": 0.07189568726832797,
      "loss": 2.8577,
      "step": 174880
    },
    {
      "epoch": 281.19,
      "learning_rate": 0.07189247183745981,
      "loss": 2.8682,
      "step": 174900
    },
    {
      "epoch": 281.22,
      "learning_rate": 0.07188925640659165,
      "loss": 2.8818,
      "step": 174920
    },
    {
      "epoch": 281.25,
      "learning_rate": 0.07188604097572349,
      "loss": 2.885,
      "step": 174940
    },
    {
      "epoch": 281.29,
      "learning_rate": 0.07188282554485531,
      "loss": 2.8778,
      "step": 174960
    },
    {
      "epoch": 281.32,
      "learning_rate": 0.07187961011398714,
      "loss": 2.8967,
      "step": 174980
    },
    {
      "epoch": 281.35,
      "learning_rate": 0.07187639468311897,
      "loss": 2.898,
      "step": 175000
    },
    {
      "epoch": 281.38,
      "learning_rate": 0.07187317925225081,
      "loss": 2.9013,
      "step": 175020
    },
    {
      "epoch": 281.41,
      "learning_rate": 0.07186996382138264,
      "loss": 2.861,
      "step": 175040
    },
    {
      "epoch": 281.45,
      "learning_rate": 0.07186674839051448,
      "loss": 2.8894,
      "step": 175060
    },
    {
      "epoch": 281.48,
      "learning_rate": 0.0718635329596463,
      "loss": 2.8831,
      "step": 175080
    },
    {
      "epoch": 281.51,
      "learning_rate": 0.07186031752877814,
      "loss": 2.8911,
      "step": 175100
    },
    {
      "epoch": 281.54,
      "learning_rate": 0.07185710209790998,
      "loss": 2.8827,
      "step": 175120
    },
    {
      "epoch": 281.58,
      "learning_rate": 0.0718538866670418,
      "loss": 2.8933,
      "step": 175140
    },
    {
      "epoch": 281.61,
      "learning_rate": 0.07185067123617364,
      "loss": 2.8649,
      "step": 175160
    },
    {
      "epoch": 281.64,
      "learning_rate": 0.07184745580530547,
      "loss": 2.9107,
      "step": 175180
    },
    {
      "epoch": 281.67,
      "learning_rate": 0.0718442403744373,
      "loss": 2.9337,
      "step": 175200
    },
    {
      "epoch": 281.7,
      "learning_rate": 0.07184102494356913,
      "loss": 2.9165,
      "step": 175220
    },
    {
      "epoch": 281.74,
      "learning_rate": 0.07183780951270097,
      "loss": 2.9067,
      "step": 175240
    },
    {
      "epoch": 281.77,
      "learning_rate": 0.0718345940818328,
      "loss": 2.8498,
      "step": 175260
    },
    {
      "epoch": 281.8,
      "learning_rate": 0.07183137865096463,
      "loss": 2.871,
      "step": 175280
    },
    {
      "epoch": 281.83,
      "learning_rate": 0.07182816322009647,
      "loss": 2.895,
      "step": 175300
    },
    {
      "epoch": 281.86,
      "learning_rate": 0.0718249477892283,
      "loss": 2.9248,
      "step": 175320
    },
    {
      "epoch": 281.9,
      "learning_rate": 0.07182173235836013,
      "loss": 2.8874,
      "step": 175340
    },
    {
      "epoch": 281.93,
      "learning_rate": 0.07181851692749197,
      "loss": 2.8878,
      "step": 175360
    },
    {
      "epoch": 281.96,
      "learning_rate": 0.0718153014966238,
      "loss": 2.8426,
      "step": 175380
    },
    {
      "epoch": 281.99,
      "learning_rate": 0.07181208606575563,
      "loss": 2.9139,
      "step": 175400
    },
    {
      "epoch": 282.0,
      "eval_accuracy": {
        "accuracy": 0.37938272564720515
      },
      "eval_loss": 3.022700786590576,
      "eval_runtime": 2.7814,
      "eval_samples_per_second": 4624.69,
      "eval_steps_per_second": 72.266,
      "step": 175404
    },
    {
      "epoch": 282.03,
      "learning_rate": 0.07180887063488746,
      "loss": 2.9041,
      "step": 175420
    },
    {
      "epoch": 282.06,
      "learning_rate": 0.0718056552040193,
      "loss": 2.905,
      "step": 175440
    },
    {
      "epoch": 282.09,
      "learning_rate": 0.07180243977315114,
      "loss": 2.8878,
      "step": 175460
    },
    {
      "epoch": 282.12,
      "learning_rate": 0.07179922434228296,
      "loss": 2.8946,
      "step": 175480
    },
    {
      "epoch": 282.15,
      "learning_rate": 0.0717960089114148,
      "loss": 2.8654,
      "step": 175500
    },
    {
      "epoch": 282.19,
      "learning_rate": 0.07179279348054662,
      "loss": 2.8721,
      "step": 175520
    },
    {
      "epoch": 282.22,
      "learning_rate": 0.07178957804967846,
      "loss": 2.8854,
      "step": 175540
    },
    {
      "epoch": 282.25,
      "learning_rate": 0.0717863626188103,
      "loss": 2.8678,
      "step": 175560
    },
    {
      "epoch": 282.28,
      "learning_rate": 0.07178314718794213,
      "loss": 2.9093,
      "step": 175580
    },
    {
      "epoch": 282.32,
      "learning_rate": 0.07177993175707396,
      "loss": 2.9151,
      "step": 175600
    },
    {
      "epoch": 282.35,
      "learning_rate": 0.07177671632620579,
      "loss": 2.9072,
      "step": 175620
    },
    {
      "epoch": 282.38,
      "learning_rate": 0.07177350089533763,
      "loss": 2.904,
      "step": 175640
    },
    {
      "epoch": 282.41,
      "learning_rate": 0.07177028546446945,
      "loss": 2.903,
      "step": 175660
    },
    {
      "epoch": 282.44,
      "learning_rate": 0.07176707003360129,
      "loss": 2.8853,
      "step": 175680
    },
    {
      "epoch": 282.48,
      "learning_rate": 0.07176385460273313,
      "loss": 2.8605,
      "step": 175700
    },
    {
      "epoch": 282.51,
      "learning_rate": 0.07176079994340837,
      "loss": 2.8879,
      "step": 175720
    },
    {
      "epoch": 282.54,
      "learning_rate": 0.07175758451254019,
      "loss": 2.9049,
      "step": 175740
    },
    {
      "epoch": 282.57,
      "learning_rate": 0.07175436908167203,
      "loss": 2.8799,
      "step": 175760
    },
    {
      "epoch": 282.6,
      "learning_rate": 0.07175115365080387,
      "loss": 2.8781,
      "step": 175780
    },
    {
      "epoch": 282.64,
      "learning_rate": 0.07174793821993569,
      "loss": 2.8395,
      "step": 175800
    },
    {
      "epoch": 282.67,
      "learning_rate": 0.07174472278906753,
      "loss": 2.8724,
      "step": 175820
    },
    {
      "epoch": 282.7,
      "learning_rate": 0.07174150735819936,
      "loss": 2.8877,
      "step": 175840
    },
    {
      "epoch": 282.73,
      "learning_rate": 0.0717382919273312,
      "loss": 2.8981,
      "step": 175860
    },
    {
      "epoch": 282.77,
      "learning_rate": 0.07173507649646303,
      "loss": 2.8739,
      "step": 175880
    },
    {
      "epoch": 282.8,
      "learning_rate": 0.07173186106559486,
      "loss": 2.8986,
      "step": 175900
    },
    {
      "epoch": 282.83,
      "learning_rate": 0.0717286456347267,
      "loss": 2.9011,
      "step": 175920
    },
    {
      "epoch": 282.86,
      "learning_rate": 0.07172543020385852,
      "loss": 2.9035,
      "step": 175940
    },
    {
      "epoch": 282.89,
      "learning_rate": 0.07172221477299036,
      "loss": 2.887,
      "step": 175960
    },
    {
      "epoch": 282.93,
      "learning_rate": 0.07171899934212218,
      "loss": 2.8911,
      "step": 175980
    },
    {
      "epoch": 282.96,
      "learning_rate": 0.07171578391125402,
      "loss": 2.8977,
      "step": 176000
    },
    {
      "epoch": 282.99,
      "learning_rate": 0.07171256848038586,
      "loss": 2.8977,
      "step": 176020
    },
    {
      "epoch": 283.0,
      "eval_accuracy": {
        "accuracy": 0.3836585555469175
      },
      "eval_loss": 3.017740488052368,
      "eval_runtime": 2.7738,
      "eval_samples_per_second": 4637.328,
      "eval_steps_per_second": 72.464,
      "step": 176026
    },
    {
      "epoch": 283.02,
      "learning_rate": 0.07170935304951769,
      "loss": 2.8925,
      "step": 176040
    },
    {
      "epoch": 283.05,
      "learning_rate": 0.07170613761864952,
      "loss": 2.9115,
      "step": 176060
    },
    {
      "epoch": 283.09,
      "learning_rate": 0.07170292218778135,
      "loss": 2.8941,
      "step": 176080
    },
    {
      "epoch": 283.12,
      "learning_rate": 0.07169970675691319,
      "loss": 2.8478,
      "step": 176100
    },
    {
      "epoch": 283.15,
      "learning_rate": 0.07169649132604503,
      "loss": 2.88,
      "step": 176120
    },
    {
      "epoch": 283.18,
      "learning_rate": 0.07169327589517685,
      "loss": 2.9043,
      "step": 176140
    },
    {
      "epoch": 283.22,
      "learning_rate": 0.07169006046430869,
      "loss": 2.8785,
      "step": 176160
    },
    {
      "epoch": 283.25,
      "learning_rate": 0.07168684503344051,
      "loss": 2.9298,
      "step": 176180
    },
    {
      "epoch": 283.28,
      "learning_rate": 0.07168362960257235,
      "loss": 2.8597,
      "step": 176200
    },
    {
      "epoch": 283.31,
      "learning_rate": 0.07168041417170419,
      "loss": 2.9106,
      "step": 176220
    },
    {
      "epoch": 283.34,
      "learning_rate": 0.07167719874083602,
      "loss": 2.9289,
      "step": 176240
    },
    {
      "epoch": 283.38,
      "learning_rate": 0.07167398330996785,
      "loss": 2.9308,
      "step": 176260
    },
    {
      "epoch": 283.41,
      "learning_rate": 0.07167076787909968,
      "loss": 2.9398,
      "step": 176280
    },
    {
      "epoch": 283.44,
      "learning_rate": 0.07166755244823152,
      "loss": 2.9294,
      "step": 176300
    },
    {
      "epoch": 283.47,
      "learning_rate": 0.07166433701736334,
      "loss": 2.9216,
      "step": 176320
    },
    {
      "epoch": 283.5,
      "learning_rate": 0.07166112158649518,
      "loss": 2.9226,
      "step": 176340
    },
    {
      "epoch": 283.54,
      "learning_rate": 0.07165790615562702,
      "loss": 2.9222,
      "step": 176360
    },
    {
      "epoch": 283.57,
      "learning_rate": 0.07165469072475884,
      "loss": 2.9339,
      "step": 176380
    },
    {
      "epoch": 283.6,
      "learning_rate": 0.07165147529389068,
      "loss": 2.8977,
      "step": 176400
    },
    {
      "epoch": 283.63,
      "learning_rate": 0.0716482598630225,
      "loss": 2.8916,
      "step": 176420
    },
    {
      "epoch": 283.67,
      "learning_rate": 0.07164504443215435,
      "loss": 2.8974,
      "step": 176440
    },
    {
      "epoch": 283.7,
      "learning_rate": 0.07164182900128618,
      "loss": 2.9114,
      "step": 176460
    },
    {
      "epoch": 283.73,
      "learning_rate": 0.07163861357041801,
      "loss": 2.8604,
      "step": 176480
    },
    {
      "epoch": 283.76,
      "learning_rate": 0.07163539813954985,
      "loss": 2.904,
      "step": 176500
    },
    {
      "epoch": 283.79,
      "learning_rate": 0.07163218270868167,
      "loss": 2.8696,
      "step": 176520
    },
    {
      "epoch": 283.83,
      "learning_rate": 0.07162896727781351,
      "loss": 2.8812,
      "step": 176540
    },
    {
      "epoch": 283.86,
      "learning_rate": 0.07162575184694535,
      "loss": 2.8644,
      "step": 176560
    },
    {
      "epoch": 283.89,
      "learning_rate": 0.07162253641607717,
      "loss": 2.9004,
      "step": 176580
    },
    {
      "epoch": 283.92,
      "learning_rate": 0.07161932098520901,
      "loss": 2.8673,
      "step": 176600
    },
    {
      "epoch": 283.95,
      "learning_rate": 0.07161610555434084,
      "loss": 2.8852,
      "step": 176620
    },
    {
      "epoch": 283.99,
      "learning_rate": 0.07161289012347268,
      "loss": 2.8906,
      "step": 176640
    },
    {
      "epoch": 284.0,
      "eval_accuracy": {
        "accuracy": 0.3905776257482702
      },
      "eval_loss": 2.958266258239746,
      "eval_runtime": 2.8876,
      "eval_samples_per_second": 4454.549,
      "eval_steps_per_second": 69.608,
      "step": 176648
    },
    {
      "epoch": 284.02,
      "learning_rate": 0.0716096746926045,
      "loss": 2.8629,
      "step": 176660
    },
    {
      "epoch": 284.05,
      "learning_rate": 0.07160645926173634,
      "loss": 2.8397,
      "step": 176680
    },
    {
      "epoch": 284.08,
      "learning_rate": 0.07160324383086818,
      "loss": 2.9037,
      "step": 176700
    },
    {
      "epoch": 284.12,
      "learning_rate": 0.0716000284,
      "loss": 2.8954,
      "step": 176720
    },
    {
      "epoch": 284.15,
      "learning_rate": 0.07159681296913184,
      "loss": 2.8857,
      "step": 176740
    },
    {
      "epoch": 284.18,
      "learning_rate": 0.07159359753826366,
      "loss": 2.9174,
      "step": 176760
    },
    {
      "epoch": 284.21,
      "learning_rate": 0.0715903821073955,
      "loss": 2.9121,
      "step": 176780
    },
    {
      "epoch": 284.24,
      "learning_rate": 0.07158716667652734,
      "loss": 2.8645,
      "step": 176800
    },
    {
      "epoch": 284.28,
      "learning_rate": 0.07158395124565917,
      "loss": 2.8594,
      "step": 176820
    },
    {
      "epoch": 284.31,
      "learning_rate": 0.071580735814791,
      "loss": 2.8779,
      "step": 176840
    },
    {
      "epoch": 284.34,
      "learning_rate": 0.07157752038392283,
      "loss": 2.8919,
      "step": 176860
    },
    {
      "epoch": 284.37,
      "learning_rate": 0.07157430495305467,
      "loss": 2.8713,
      "step": 176880
    },
    {
      "epoch": 284.41,
      "learning_rate": 0.0715710895221865,
      "loss": 2.8879,
      "step": 176900
    },
    {
      "epoch": 284.44,
      "learning_rate": 0.07156787409131833,
      "loss": 2.8745,
      "step": 176920
    },
    {
      "epoch": 284.47,
      "learning_rate": 0.07156465866045017,
      "loss": 2.8611,
      "step": 176940
    },
    {
      "epoch": 284.5,
      "learning_rate": 0.071561443229582,
      "loss": 2.8725,
      "step": 176960
    },
    {
      "epoch": 284.53,
      "learning_rate": 0.07155822779871383,
      "loss": 2.8871,
      "step": 176980
    },
    {
      "epoch": 284.57,
      "learning_rate": 0.07155501236784567,
      "loss": 2.8882,
      "step": 177000
    },
    {
      "epoch": 284.6,
      "learning_rate": 0.0715517969369775,
      "loss": 2.887,
      "step": 177020
    },
    {
      "epoch": 284.63,
      "learning_rate": 0.07154858150610933,
      "loss": 2.8787,
      "step": 177040
    },
    {
      "epoch": 284.66,
      "learning_rate": 0.07154536607524116,
      "loss": 2.8739,
      "step": 177060
    },
    {
      "epoch": 284.69,
      "learning_rate": 0.071542150644373,
      "loss": 2.8837,
      "step": 177080
    },
    {
      "epoch": 284.73,
      "learning_rate": 0.07153893521350482,
      "loss": 2.9079,
      "step": 177100
    },
    {
      "epoch": 284.76,
      "learning_rate": 0.07153571978263666,
      "loss": 2.8954,
      "step": 177120
    },
    {
      "epoch": 284.79,
      "learning_rate": 0.0715325043517685,
      "loss": 2.9468,
      "step": 177140
    },
    {
      "epoch": 284.82,
      "learning_rate": 0.07152928892090032,
      "loss": 2.9166,
      "step": 177160
    },
    {
      "epoch": 284.86,
      "learning_rate": 0.07152607349003216,
      "loss": 2.9004,
      "step": 177180
    },
    {
      "epoch": 284.89,
      "learning_rate": 0.07152285805916399,
      "loss": 2.8917,
      "step": 177200
    },
    {
      "epoch": 284.92,
      "learning_rate": 0.07151964262829583,
      "loss": 2.848,
      "step": 177220
    },
    {
      "epoch": 284.95,
      "learning_rate": 0.07151642719742766,
      "loss": 2.8792,
      "step": 177240
    },
    {
      "epoch": 284.98,
      "learning_rate": 0.07151321176655949,
      "loss": 2.9493,
      "step": 177260
    },
    {
      "epoch": 285.0,
      "eval_accuracy": {
        "accuracy": 0.39073311047189613
      },
      "eval_loss": 2.9823968410491943,
      "eval_runtime": 3.013,
      "eval_samples_per_second": 4269.165,
      "eval_steps_per_second": 66.711,
      "step": 177270
    },
    {
      "epoch": 285.02,
      "learning_rate": 0.07150999633569131,
      "loss": 2.8927,
      "step": 177280
    },
    {
      "epoch": 285.05,
      "learning_rate": 0.07150678090482315,
      "loss": 2.8983,
      "step": 177300
    },
    {
      "epoch": 285.08,
      "learning_rate": 0.07150356547395499,
      "loss": 2.8874,
      "step": 177320
    },
    {
      "epoch": 285.11,
      "learning_rate": 0.07150035004308683,
      "loss": 2.8782,
      "step": 177340
    },
    {
      "epoch": 285.14,
      "learning_rate": 0.07149713461221865,
      "loss": 2.9005,
      "step": 177360
    },
    {
      "epoch": 285.18,
      "learning_rate": 0.07149391918135048,
      "loss": 2.878,
      "step": 177380
    },
    {
      "epoch": 285.21,
      "learning_rate": 0.07149070375048232,
      "loss": 2.879,
      "step": 177400
    },
    {
      "epoch": 285.24,
      "learning_rate": 0.07148748831961416,
      "loss": 2.8857,
      "step": 177420
    },
    {
      "epoch": 285.27,
      "learning_rate": 0.07148427288874598,
      "loss": 2.882,
      "step": 177440
    },
    {
      "epoch": 285.31,
      "learning_rate": 0.07148105745787782,
      "loss": 2.8856,
      "step": 177460
    },
    {
      "epoch": 285.34,
      "learning_rate": 0.07147784202700964,
      "loss": 2.8744,
      "step": 177480
    },
    {
      "epoch": 285.37,
      "learning_rate": 0.07147462659614148,
      "loss": 2.8845,
      "step": 177500
    },
    {
      "epoch": 285.4,
      "learning_rate": 0.07147141116527332,
      "loss": 2.9064,
      "step": 177520
    },
    {
      "epoch": 285.43,
      "learning_rate": 0.07146819573440515,
      "loss": 2.9002,
      "step": 177540
    },
    {
      "epoch": 285.47,
      "learning_rate": 0.07146498030353698,
      "loss": 2.8993,
      "step": 177560
    },
    {
      "epoch": 285.5,
      "learning_rate": 0.07146176487266882,
      "loss": 2.8839,
      "step": 177580
    },
    {
      "epoch": 285.53,
      "learning_rate": 0.07145854944180065,
      "loss": 2.8825,
      "step": 177600
    },
    {
      "epoch": 285.56,
      "learning_rate": 0.07145533401093247,
      "loss": 2.8845,
      "step": 177620
    },
    {
      "epoch": 285.59,
      "learning_rate": 0.07145211858006431,
      "loss": 2.8835,
      "step": 177640
    },
    {
      "epoch": 285.63,
      "learning_rate": 0.07144890314919615,
      "loss": 2.8767,
      "step": 177660
    },
    {
      "epoch": 285.66,
      "learning_rate": 0.07144568771832799,
      "loss": 2.8915,
      "step": 177680
    },
    {
      "epoch": 285.69,
      "learning_rate": 0.07144247228745981,
      "loss": 2.8982,
      "step": 177700
    },
    {
      "epoch": 285.72,
      "learning_rate": 0.07143925685659164,
      "loss": 2.9141,
      "step": 177720
    },
    {
      "epoch": 285.76,
      "learning_rate": 0.07143604142572348,
      "loss": 2.9021,
      "step": 177740
    },
    {
      "epoch": 285.79,
      "learning_rate": 0.07143298676639871,
      "loss": 2.8965,
      "step": 177760
    },
    {
      "epoch": 285.82,
      "learning_rate": 0.07142977133553056,
      "loss": 2.8741,
      "step": 177780
    },
    {
      "epoch": 285.85,
      "learning_rate": 0.07142655590466238,
      "loss": 2.8935,
      "step": 177800
    },
    {
      "epoch": 285.88,
      "learning_rate": 0.07142334047379421,
      "loss": 2.907,
      "step": 177820
    },
    {
      "epoch": 285.92,
      "learning_rate": 0.07142012504292605,
      "loss": 2.9215,
      "step": 177840
    },
    {
      "epoch": 285.95,
      "learning_rate": 0.07141690961205788,
      "loss": 2.8841,
      "step": 177860
    },
    {
      "epoch": 285.98,
      "learning_rate": 0.07141369418118973,
      "loss": 2.8686,
      "step": 177880
    },
    {
      "epoch": 286.0,
      "eval_accuracy": {
        "accuracy": 0.38777890072300397
      },
      "eval_loss": 2.960618734359741,
      "eval_runtime": 2.9512,
      "eval_samples_per_second": 4358.6,
      "eval_steps_per_second": 68.108,
      "step": 177892
    },
    {
      "epoch": 286.01,
      "learning_rate": 0.07141047875032154,
      "loss": 2.869,
      "step": 177900
    },
    {
      "epoch": 286.05,
      "learning_rate": 0.07140726331945338,
      "loss": 2.8977,
      "step": 177920
    },
    {
      "epoch": 286.08,
      "learning_rate": 0.07140404788858522,
      "loss": 2.88,
      "step": 177940
    },
    {
      "epoch": 286.11,
      "learning_rate": 0.07140083245771704,
      "loss": 2.8547,
      "step": 177960
    },
    {
      "epoch": 286.14,
      "learning_rate": 0.07139761702684888,
      "loss": 2.8817,
      "step": 177980
    },
    {
      "epoch": 286.17,
      "learning_rate": 0.0713944015959807,
      "loss": 2.9098,
      "step": 178000
    },
    {
      "epoch": 286.21,
      "learning_rate": 0.07139118616511254,
      "loss": 2.8762,
      "step": 178020
    },
    {
      "epoch": 286.24,
      "learning_rate": 0.07138797073424437,
      "loss": 2.8936,
      "step": 178040
    },
    {
      "epoch": 286.27,
      "learning_rate": 0.07138475530337621,
      "loss": 2.907,
      "step": 178060
    },
    {
      "epoch": 286.3,
      "learning_rate": 0.07138153987250805,
      "loss": 2.8944,
      "step": 178080
    },
    {
      "epoch": 286.33,
      "learning_rate": 0.07137832444163987,
      "loss": 2.8852,
      "step": 178100
    },
    {
      "epoch": 286.37,
      "learning_rate": 0.07137510901077171,
      "loss": 2.8804,
      "step": 178120
    },
    {
      "epoch": 286.4,
      "learning_rate": 0.07137189357990353,
      "loss": 2.9003,
      "step": 178140
    },
    {
      "epoch": 286.43,
      "learning_rate": 0.07136867814903537,
      "loss": 2.9029,
      "step": 178160
    },
    {
      "epoch": 286.46,
      "learning_rate": 0.07136546271816721,
      "loss": 2.9116,
      "step": 178180
    },
    {
      "epoch": 286.5,
      "learning_rate": 0.07136224728729904,
      "loss": 2.8972,
      "step": 178200
    },
    {
      "epoch": 286.53,
      "learning_rate": 0.07135903185643087,
      "loss": 2.8827,
      "step": 178220
    },
    {
      "epoch": 286.56,
      "learning_rate": 0.0713558164255627,
      "loss": 2.8801,
      "step": 178240
    },
    {
      "epoch": 286.59,
      "learning_rate": 0.07135260099469454,
      "loss": 2.8869,
      "step": 178260
    },
    {
      "epoch": 286.62,
      "learning_rate": 0.07134938556382638,
      "loss": 2.8968,
      "step": 178280
    },
    {
      "epoch": 286.66,
      "learning_rate": 0.0713461701329582,
      "loss": 2.8797,
      "step": 178300
    },
    {
      "epoch": 286.69,
      "learning_rate": 0.07134295470209004,
      "loss": 2.8963,
      "step": 178320
    },
    {
      "epoch": 286.72,
      "learning_rate": 0.07133973927122186,
      "loss": 2.8675,
      "step": 178340
    },
    {
      "epoch": 286.75,
      "learning_rate": 0.0713365238403537,
      "loss": 2.8913,
      "step": 178360
    },
    {
      "epoch": 286.78,
      "learning_rate": 0.07133330840948553,
      "loss": 2.9054,
      "step": 178380
    },
    {
      "epoch": 286.82,
      "learning_rate": 0.07133009297861737,
      "loss": 2.8794,
      "step": 178400
    },
    {
      "epoch": 286.85,
      "learning_rate": 0.0713268775477492,
      "loss": 2.8655,
      "step": 178420
    },
    {
      "epoch": 286.88,
      "learning_rate": 0.07132366211688103,
      "loss": 2.9266,
      "step": 178440
    },
    {
      "epoch": 286.91,
      "learning_rate": 0.07132044668601287,
      "loss": 2.894,
      "step": 178460
    },
    {
      "epoch": 286.95,
      "learning_rate": 0.07131723125514469,
      "loss": 2.8611,
      "step": 178480
    },
    {
      "epoch": 286.98,
      "learning_rate": 0.07131401582427653,
      "loss": 2.8849,
      "step": 178500
    },
    {
      "epoch": 287.0,
      "eval_accuracy": {
        "accuracy": 0.38358081318510456
      },
      "eval_loss": 2.981717824935913,
      "eval_runtime": 2.9246,
      "eval_samples_per_second": 4398.191,
      "eval_steps_per_second": 68.727,
      "step": 178514
    },
    {
      "epoch": 287.01,
      "learning_rate": 0.07131080039340837,
      "loss": 2.8682,
      "step": 178520
    },
    {
      "epoch": 287.04,
      "learning_rate": 0.0713075849625402,
      "loss": 2.8622,
      "step": 178540
    },
    {
      "epoch": 287.07,
      "learning_rate": 0.07130436953167203,
      "loss": 2.8608,
      "step": 178560
    },
    {
      "epoch": 287.11,
      "learning_rate": 0.07130115410080386,
      "loss": 2.8855,
      "step": 178580
    },
    {
      "epoch": 287.14,
      "learning_rate": 0.0712979386699357,
      "loss": 2.8664,
      "step": 178600
    },
    {
      "epoch": 287.17,
      "learning_rate": 0.07129472323906753,
      "loss": 2.8867,
      "step": 178620
    },
    {
      "epoch": 287.2,
      "learning_rate": 0.07129150780819936,
      "loss": 2.8531,
      "step": 178640
    },
    {
      "epoch": 287.23,
      "learning_rate": 0.0712882923773312,
      "loss": 2.8919,
      "step": 178660
    },
    {
      "epoch": 287.27,
      "learning_rate": 0.07128507694646302,
      "loss": 2.8556,
      "step": 178680
    },
    {
      "epoch": 287.3,
      "learning_rate": 0.07128186151559486,
      "loss": 2.8877,
      "step": 178700
    },
    {
      "epoch": 287.33,
      "learning_rate": 0.07127864608472669,
      "loss": 2.8749,
      "step": 178720
    },
    {
      "epoch": 287.36,
      "learning_rate": 0.07127543065385852,
      "loss": 2.894,
      "step": 178740
    },
    {
      "epoch": 287.4,
      "learning_rate": 0.07127221522299036,
      "loss": 2.8925,
      "step": 178760
    },
    {
      "epoch": 287.43,
      "learning_rate": 0.07126899979212219,
      "loss": 2.9117,
      "step": 178780
    },
    {
      "epoch": 287.46,
      "learning_rate": 0.07126578436125403,
      "loss": 2.914,
      "step": 178800
    },
    {
      "epoch": 287.49,
      "learning_rate": 0.07126256893038585,
      "loss": 2.8941,
      "step": 178820
    },
    {
      "epoch": 287.52,
      "learning_rate": 0.07125935349951769,
      "loss": 2.8824,
      "step": 178840
    },
    {
      "epoch": 287.56,
      "learning_rate": 0.07125613806864953,
      "loss": 2.8796,
      "step": 178860
    },
    {
      "epoch": 287.59,
      "learning_rate": 0.07125292263778135,
      "loss": 2.8476,
      "step": 178880
    },
    {
      "epoch": 287.62,
      "learning_rate": 0.07124970720691319,
      "loss": 2.8952,
      "step": 178900
    },
    {
      "epoch": 287.65,
      "learning_rate": 0.07124649177604502,
      "loss": 2.9029,
      "step": 178920
    },
    {
      "epoch": 287.68,
      "learning_rate": 0.07124327634517685,
      "loss": 2.8816,
      "step": 178940
    },
    {
      "epoch": 287.72,
      "learning_rate": 0.07124006091430869,
      "loss": 2.9012,
      "step": 178960
    },
    {
      "epoch": 287.75,
      "learning_rate": 0.07123684548344052,
      "loss": 2.8845,
      "step": 178980
    },
    {
      "epoch": 287.78,
      "learning_rate": 0.07123379082411577,
      "loss": 2.8946,
      "step": 179000
    },
    {
      "epoch": 287.81,
      "learning_rate": 0.07123057539324759,
      "loss": 2.8943,
      "step": 179020
    },
    {
      "epoch": 287.85,
      "learning_rate": 0.07122735996237942,
      "loss": 2.903,
      "step": 179040
    },
    {
      "epoch": 287.88,
      "learning_rate": 0.07122414453151127,
      "loss": 2.8672,
      "step": 179060
    },
    {
      "epoch": 287.91,
      "learning_rate": 0.07122092910064308,
      "loss": 2.8688,
      "step": 179080
    },
    {
      "epoch": 287.94,
      "learning_rate": 0.07121771366977493,
      "loss": 2.8956,
      "step": 179100
    },
    {
      "epoch": 287.97,
      "learning_rate": 0.07121449823890676,
      "loss": 2.8828,
      "step": 179120
    },
    {
      "epoch": 288.0,
      "eval_accuracy": {
        "accuracy": 0.3807820881598383
      },
      "eval_loss": 3.02866268157959,
      "eval_runtime": 2.7249,
      "eval_samples_per_second": 4720.589,
      "eval_steps_per_second": 73.765,
      "step": 179136
    },
    {
      "epoch": 288.01,
      "learning_rate": 0.07121128280803858,
      "loss": 2.8936,
      "step": 179140
    },
    {
      "epoch": 288.04,
      "learning_rate": 0.07120806737717043,
      "loss": 2.9005,
      "step": 179160
    },
    {
      "epoch": 288.07,
      "learning_rate": 0.07120485194630224,
      "loss": 2.8715,
      "step": 179180
    },
    {
      "epoch": 288.1,
      "learning_rate": 0.0712016365154341,
      "loss": 2.8565,
      "step": 179200
    },
    {
      "epoch": 288.14,
      "learning_rate": 0.07119842108456592,
      "loss": 2.8846,
      "step": 179220
    },
    {
      "epoch": 288.17,
      "learning_rate": 0.07119520565369776,
      "loss": 2.8883,
      "step": 179240
    },
    {
      "epoch": 288.2,
      "learning_rate": 0.07119199022282958,
      "loss": 2.8653,
      "step": 179260
    },
    {
      "epoch": 288.23,
      "learning_rate": 0.07118877479196141,
      "loss": 2.8827,
      "step": 179280
    },
    {
      "epoch": 288.26,
      "learning_rate": 0.07118555936109326,
      "loss": 2.8671,
      "step": 179300
    },
    {
      "epoch": 288.3,
      "learning_rate": 0.07118234393022509,
      "loss": 2.8885,
      "step": 179320
    },
    {
      "epoch": 288.33,
      "learning_rate": 0.07117912849935693,
      "loss": 2.8631,
      "step": 179340
    },
    {
      "epoch": 288.36,
      "learning_rate": 0.07117591306848875,
      "loss": 2.8839,
      "step": 179360
    },
    {
      "epoch": 288.39,
      "learning_rate": 0.07117269763762057,
      "loss": 2.9254,
      "step": 179380
    },
    {
      "epoch": 288.42,
      "learning_rate": 0.07116948220675243,
      "loss": 2.874,
      "step": 179400
    },
    {
      "epoch": 288.46,
      "learning_rate": 0.07116626677588424,
      "loss": 2.8684,
      "step": 179420
    },
    {
      "epoch": 288.49,
      "learning_rate": 0.07116305134501609,
      "loss": 2.9029,
      "step": 179440
    },
    {
      "epoch": 288.52,
      "learning_rate": 0.07115983591414791,
      "loss": 2.8631,
      "step": 179460
    },
    {
      "epoch": 288.55,
      "learning_rate": 0.07115662048327974,
      "loss": 2.9129,
      "step": 179480
    },
    {
      "epoch": 288.59,
      "learning_rate": 0.07115340505241159,
      "loss": 2.9267,
      "step": 179500
    },
    {
      "epoch": 288.62,
      "learning_rate": 0.0711501896215434,
      "loss": 2.8741,
      "step": 179520
    },
    {
      "epoch": 288.65,
      "learning_rate": 0.07114697419067526,
      "loss": 2.8977,
      "step": 179540
    },
    {
      "epoch": 288.68,
      "learning_rate": 0.07114375875980708,
      "loss": 2.8315,
      "step": 179560
    },
    {
      "epoch": 288.71,
      "learning_rate": 0.0711405433289389,
      "loss": 2.8666,
      "step": 179580
    },
    {
      "epoch": 288.75,
      "learning_rate": 0.07113732789807076,
      "loss": 2.8985,
      "step": 179600
    },
    {
      "epoch": 288.78,
      "learning_rate": 0.07113411246720257,
      "loss": 2.8791,
      "step": 179620
    },
    {
      "epoch": 288.81,
      "learning_rate": 0.07113089703633442,
      "loss": 2.8752,
      "step": 179640
    },
    {
      "epoch": 288.84,
      "learning_rate": 0.07112768160546624,
      "loss": 2.8826,
      "step": 179660
    },
    {
      "epoch": 288.87,
      "learning_rate": 0.07112446617459807,
      "loss": 2.8567,
      "step": 179680
    },
    {
      "epoch": 288.91,
      "learning_rate": 0.07112125074372991,
      "loss": 2.9006,
      "step": 179700
    },
    {
      "epoch": 288.94,
      "learning_rate": 0.07111803531286173,
      "loss": 2.8925,
      "step": 179720
    },
    {
      "epoch": 288.97,
      "learning_rate": 0.07111481988199359,
      "loss": 2.8612,
      "step": 179740
    },
    {
      "epoch": 289.0,
      "eval_accuracy": {
        "accuracy": 0.38941149032107597
      },
      "eval_loss": 2.9812839031219482,
      "eval_runtime": 2.8632,
      "eval_samples_per_second": 4492.486,
      "eval_steps_per_second": 70.201,
      "step": 179758
    },
    {
      "epoch": 289.0,
      "learning_rate": 0.0711116044511254,
      "loss": 2.8891,
      "step": 179760
    },
    {
      "epoch": 289.04,
      "learning_rate": 0.07110838902025723,
      "loss": 2.8928,
      "step": 179780
    },
    {
      "epoch": 289.07,
      "learning_rate": 0.07110517358938907,
      "loss": 2.8745,
      "step": 179800
    },
    {
      "epoch": 289.1,
      "learning_rate": 0.0711019581585209,
      "loss": 2.8675,
      "step": 179820
    },
    {
      "epoch": 289.13,
      "learning_rate": 0.07109874272765275,
      "loss": 2.8911,
      "step": 179840
    },
    {
      "epoch": 289.16,
      "learning_rate": 0.07109552729678456,
      "loss": 2.902,
      "step": 179860
    },
    {
      "epoch": 289.2,
      "learning_rate": 0.07109231186591641,
      "loss": 2.8744,
      "step": 179880
    },
    {
      "epoch": 289.23,
      "learning_rate": 0.07108909643504824,
      "loss": 2.8826,
      "step": 179900
    },
    {
      "epoch": 289.26,
      "learning_rate": 0.07108588100418006,
      "loss": 2.8591,
      "step": 179920
    },
    {
      "epoch": 289.29,
      "learning_rate": 0.07108266557331192,
      "loss": 2.8746,
      "step": 179940
    },
    {
      "epoch": 289.32,
      "learning_rate": 0.07107945014244373,
      "loss": 2.8745,
      "step": 179960
    },
    {
      "epoch": 289.36,
      "learning_rate": 0.07107623471157558,
      "loss": 2.8818,
      "step": 179980
    },
    {
      "epoch": 289.39,
      "learning_rate": 0.0710730192807074,
      "loss": 2.9074,
      "step": 180000
    },
    {
      "epoch": 289.42,
      "learning_rate": 0.07106980384983923,
      "loss": 2.873,
      "step": 180020
    },
    {
      "epoch": 289.45,
      "learning_rate": 0.07106658841897107,
      "loss": 2.8688,
      "step": 180040
    },
    {
      "epoch": 289.49,
      "learning_rate": 0.07106337298810289,
      "loss": 2.8992,
      "step": 180060
    },
    {
      "epoch": 289.52,
      "learning_rate": 0.07106015755723474,
      "loss": 2.8721,
      "step": 180080
    },
    {
      "epoch": 289.55,
      "learning_rate": 0.07105694212636655,
      "loss": 2.8783,
      "step": 180100
    },
    {
      "epoch": 289.58,
      "learning_rate": 0.07105372669549839,
      "loss": 2.8649,
      "step": 180120
    },
    {
      "epoch": 289.61,
      "learning_rate": 0.07105051126463023,
      "loss": 2.9188,
      "step": 180140
    },
    {
      "epoch": 289.65,
      "learning_rate": 0.07104729583376206,
      "loss": 2.9158,
      "step": 180160
    },
    {
      "epoch": 289.68,
      "learning_rate": 0.07104408040289391,
      "loss": 2.8817,
      "step": 180180
    },
    {
      "epoch": 289.71,
      "learning_rate": 0.07104086497202572,
      "loss": 2.8599,
      "step": 180200
    },
    {
      "epoch": 289.74,
      "learning_rate": 0.07103764954115756,
      "loss": 2.833,
      "step": 180220
    },
    {
      "epoch": 289.77,
      "learning_rate": 0.0710344341102894,
      "loss": 2.8646,
      "step": 180240
    },
    {
      "epoch": 289.81,
      "learning_rate": 0.07103121867942122,
      "loss": 2.8997,
      "step": 180260
    },
    {
      "epoch": 289.84,
      "learning_rate": 0.07102800324855307,
      "loss": 2.8809,
      "step": 180280
    },
    {
      "epoch": 289.87,
      "learning_rate": 0.07102478781768488,
      "loss": 2.8697,
      "step": 180300
    },
    {
      "epoch": 289.9,
      "learning_rate": 0.07102157238681672,
      "loss": 2.902,
      "step": 180320
    },
    {
      "epoch": 289.94,
      "learning_rate": 0.07101835695594856,
      "loss": 2.8794,
      "step": 180340
    },
    {
      "epoch": 289.97,
      "learning_rate": 0.07101514152508039,
      "loss": 2.8709,
      "step": 180360
    },
    {
      "epoch": 290.0,
      "learning_rate": 0.07101192609421222,
      "loss": 2.9,
      "step": 180380
    },
    {
      "epoch": 290.0,
      "eval_accuracy": {
        "accuracy": 0.3814040270543419
      },
      "eval_loss": 3.021575927734375,
      "eval_runtime": 3.0443,
      "eval_samples_per_second": 4225.238,
      "eval_steps_per_second": 66.024,
      "step": 180380
    },
    {
      "epoch": 290.03,
      "learning_rate": 0.07100871066334405,
      "loss": 2.898,
      "step": 180400
    },
    {
      "epoch": 290.06,
      "learning_rate": 0.07100549523247589,
      "loss": 2.8519,
      "step": 180420
    },
    {
      "epoch": 290.1,
      "learning_rate": 0.07100227980160771,
      "loss": 2.9089,
      "step": 180440
    },
    {
      "epoch": 290.13,
      "learning_rate": 0.07099906437073955,
      "loss": 2.8692,
      "step": 180460
    },
    {
      "epoch": 290.16,
      "learning_rate": 0.07099584893987139,
      "loss": 2.8838,
      "step": 180480
    },
    {
      "epoch": 290.19,
      "learning_rate": 0.07099263350900321,
      "loss": 2.9268,
      "step": 180500
    },
    {
      "epoch": 290.23,
      "learning_rate": 0.07098941807813507,
      "loss": 2.8975,
      "step": 180520
    },
    {
      "epoch": 290.26,
      "learning_rate": 0.07098620264726688,
      "loss": 2.8775,
      "step": 180540
    },
    {
      "epoch": 290.29,
      "learning_rate": 0.07098298721639872,
      "loss": 2.8796,
      "step": 180560
    },
    {
      "epoch": 290.32,
      "learning_rate": 0.07097977178553055,
      "loss": 2.9126,
      "step": 180580
    },
    {
      "epoch": 290.35,
      "learning_rate": 0.07097655635466238,
      "loss": 2.9313,
      "step": 180600
    },
    {
      "epoch": 290.39,
      "learning_rate": 0.07097334092379423,
      "loss": 2.8822,
      "step": 180620
    },
    {
      "epoch": 290.42,
      "learning_rate": 0.07097012549292604,
      "loss": 2.8793,
      "step": 180640
    },
    {
      "epoch": 290.45,
      "learning_rate": 0.07096691006205788,
      "loss": 2.8532,
      "step": 180660
    },
    {
      "epoch": 290.48,
      "learning_rate": 0.07096369463118972,
      "loss": 2.8962,
      "step": 180680
    },
    {
      "epoch": 290.51,
      "learning_rate": 0.07096047920032154,
      "loss": 2.8585,
      "step": 180700
    },
    {
      "epoch": 290.55,
      "learning_rate": 0.07095726376945338,
      "loss": 2.9119,
      "step": 180720
    },
    {
      "epoch": 290.58,
      "learning_rate": 0.07095404833858521,
      "loss": 2.9121,
      "step": 180740
    },
    {
      "epoch": 290.61,
      "learning_rate": 0.07095083290771705,
      "loss": 2.8659,
      "step": 180760
    },
    {
      "epoch": 290.64,
      "learning_rate": 0.07094761747684887,
      "loss": 2.8904,
      "step": 180780
    },
    {
      "epoch": 290.68,
      "learning_rate": 0.07094440204598071,
      "loss": 2.8904,
      "step": 180800
    },
    {
      "epoch": 290.71,
      "learning_rate": 0.07094118661511255,
      "loss": 2.9101,
      "step": 180820
    },
    {
      "epoch": 290.74,
      "learning_rate": 0.07093797118424437,
      "loss": 2.9005,
      "step": 180840
    },
    {
      "epoch": 290.77,
      "learning_rate": 0.07093475575337621,
      "loss": 2.8951,
      "step": 180860
    },
    {
      "epoch": 290.8,
      "learning_rate": 0.07093154032250804,
      "loss": 2.9066,
      "step": 180880
    },
    {
      "epoch": 290.84,
      "learning_rate": 0.07092832489163987,
      "loss": 2.8778,
      "step": 180900
    },
    {
      "epoch": 290.87,
      "learning_rate": 0.07092510946077171,
      "loss": 2.9033,
      "step": 180920
    },
    {
      "epoch": 290.9,
      "learning_rate": 0.07092189402990354,
      "loss": 2.8466,
      "step": 180940
    },
    {
      "epoch": 290.93,
      "learning_rate": 0.07091867859903538,
      "loss": 2.8989,
      "step": 180960
    },
    {
      "epoch": 290.96,
      "learning_rate": 0.0709154631681672,
      "loss": 2.8809,
      "step": 180980
    },
    {
      "epoch": 291.0,
      "learning_rate": 0.07091224773729904,
      "loss": 2.8757,
      "step": 181000
    },
    {
      "epoch": 291.0,
      "eval_accuracy": {
        "accuracy": 0.386068568763119
      },
      "eval_loss": 2.9883575439453125,
      "eval_runtime": 3.2496,
      "eval_samples_per_second": 3958.288,
      "eval_steps_per_second": 61.853,
      "step": 181002
    },
    {
      "epoch": 291.03,
      "learning_rate": 0.07090903230643088,
      "loss": 2.8899,
      "step": 181020
    },
    {
      "epoch": 291.06,
      "learning_rate": 0.0709058168755627,
      "loss": 2.8567,
      "step": 181040
    },
    {
      "epoch": 291.09,
      "learning_rate": 0.07090260144469454,
      "loss": 2.8391,
      "step": 181060
    },
    {
      "epoch": 291.13,
      "learning_rate": 0.07089938601382637,
      "loss": 2.8736,
      "step": 181080
    },
    {
      "epoch": 291.16,
      "learning_rate": 0.0708961705829582,
      "loss": 2.8819,
      "step": 181100
    },
    {
      "epoch": 291.19,
      "learning_rate": 0.07089295515209003,
      "loss": 2.9039,
      "step": 181120
    },
    {
      "epoch": 291.22,
      "learning_rate": 0.07088973972122187,
      "loss": 2.9118,
      "step": 181140
    },
    {
      "epoch": 291.25,
      "learning_rate": 0.0708865242903537,
      "loss": 2.8971,
      "step": 181160
    },
    {
      "epoch": 291.29,
      "learning_rate": 0.07088330885948553,
      "loss": 2.8713,
      "step": 181180
    },
    {
      "epoch": 291.32,
      "learning_rate": 0.07088009342861737,
      "loss": 2.8883,
      "step": 181200
    },
    {
      "epoch": 291.35,
      "learning_rate": 0.0708768779977492,
      "loss": 2.8775,
      "step": 181220
    },
    {
      "epoch": 291.38,
      "learning_rate": 0.07087366256688103,
      "loss": 2.8689,
      "step": 181240
    },
    {
      "epoch": 291.41,
      "learning_rate": 0.07087044713601287,
      "loss": 2.8888,
      "step": 181260
    },
    {
      "epoch": 291.45,
      "learning_rate": 0.0708672317051447,
      "loss": 2.9018,
      "step": 181280
    },
    {
      "epoch": 291.48,
      "learning_rate": 0.07086401627427653,
      "loss": 2.8486,
      "step": 181300
    },
    {
      "epoch": 291.51,
      "learning_rate": 0.07086080084340836,
      "loss": 2.8711,
      "step": 181320
    },
    {
      "epoch": 291.54,
      "learning_rate": 0.0708575854125402,
      "loss": 2.8518,
      "step": 181340
    },
    {
      "epoch": 291.58,
      "learning_rate": 0.07085436998167204,
      "loss": 2.8699,
      "step": 181360
    },
    {
      "epoch": 291.61,
      "learning_rate": 0.07085115455080386,
      "loss": 2.8721,
      "step": 181380
    },
    {
      "epoch": 291.64,
      "learning_rate": 0.0708479391199357,
      "loss": 2.864,
      "step": 181400
    },
    {
      "epoch": 291.67,
      "learning_rate": 0.07084472368906752,
      "loss": 2.8653,
      "step": 181420
    },
    {
      "epoch": 291.7,
      "learning_rate": 0.07084150825819936,
      "loss": 2.8622,
      "step": 181440
    },
    {
      "epoch": 291.74,
      "learning_rate": 0.07083829282733119,
      "loss": 2.8375,
      "step": 181460
    },
    {
      "epoch": 291.77,
      "learning_rate": 0.07083507739646303,
      "loss": 2.8548,
      "step": 181480
    },
    {
      "epoch": 291.8,
      "learning_rate": 0.07083186196559486,
      "loss": 2.8826,
      "step": 181500
    },
    {
      "epoch": 291.83,
      "learning_rate": 0.07082864653472669,
      "loss": 2.9048,
      "step": 181520
    },
    {
      "epoch": 291.86,
      "learning_rate": 0.07082543110385853,
      "loss": 2.9056,
      "step": 181540
    },
    {
      "epoch": 291.9,
      "learning_rate": 0.07082221567299035,
      "loss": 2.876,
      "step": 181560
    },
    {
      "epoch": 291.93,
      "learning_rate": 0.07081900024212219,
      "loss": 2.8764,
      "step": 181580
    },
    {
      "epoch": 291.96,
      "learning_rate": 0.07081578481125403,
      "loss": 2.8834,
      "step": 181600
    },
    {
      "epoch": 291.99,
      "learning_rate": 0.07081256938038585,
      "loss": 2.8972,
      "step": 181620
    },
    {
      "epoch": 292.0,
      "eval_accuracy": {
        "accuracy": 0.382881131928788
      },
      "eval_loss": 2.9807794094085693,
      "eval_runtime": 2.6783,
      "eval_samples_per_second": 4802.711,
      "eval_steps_per_second": 75.048,
      "step": 181624
    },
    {
      "epoch": 292.03,
      "learning_rate": 0.07080935394951769,
      "loss": 2.8748,
      "step": 181640
    },
    {
      "epoch": 292.06,
      "learning_rate": 0.07080613851864952,
      "loss": 2.8585,
      "step": 181660
    },
    {
      "epoch": 292.09,
      "learning_rate": 0.07080292308778136,
      "loss": 2.8699,
      "step": 181680
    },
    {
      "epoch": 292.12,
      "learning_rate": 0.0707997076569132,
      "loss": 2.8747,
      "step": 181700
    },
    {
      "epoch": 292.15,
      "learning_rate": 0.07079649222604502,
      "loss": 2.9057,
      "step": 181720
    },
    {
      "epoch": 292.19,
      "learning_rate": 0.07079327679517686,
      "loss": 2.8909,
      "step": 181740
    },
    {
      "epoch": 292.22,
      "learning_rate": 0.07079006136430868,
      "loss": 2.8642,
      "step": 181760
    },
    {
      "epoch": 292.25,
      "learning_rate": 0.07078684593344052,
      "loss": 2.8595,
      "step": 181780
    },
    {
      "epoch": 292.28,
      "learning_rate": 0.07078363050257235,
      "loss": 2.8892,
      "step": 181800
    },
    {
      "epoch": 292.32,
      "learning_rate": 0.07078041507170418,
      "loss": 2.9029,
      "step": 181820
    },
    {
      "epoch": 292.35,
      "learning_rate": 0.07077719964083602,
      "loss": 2.8568,
      "step": 181840
    },
    {
      "epoch": 292.38,
      "learning_rate": 0.07077398420996785,
      "loss": 2.841,
      "step": 181860
    },
    {
      "epoch": 292.41,
      "learning_rate": 0.07077076877909969,
      "loss": 2.8728,
      "step": 181880
    },
    {
      "epoch": 292.44,
      "learning_rate": 0.07076755334823151,
      "loss": 2.8832,
      "step": 181900
    },
    {
      "epoch": 292.48,
      "learning_rate": 0.07076433791736335,
      "loss": 2.8812,
      "step": 181920
    },
    {
      "epoch": 292.51,
      "learning_rate": 0.07076112248649519,
      "loss": 2.8787,
      "step": 181940
    },
    {
      "epoch": 292.54,
      "learning_rate": 0.07075790705562701,
      "loss": 2.8976,
      "step": 181960
    },
    {
      "epoch": 292.57,
      "learning_rate": 0.07075469162475885,
      "loss": 2.897,
      "step": 181980
    },
    {
      "epoch": 292.6,
      "learning_rate": 0.07075147619389067,
      "loss": 2.8811,
      "step": 182000
    },
    {
      "epoch": 292.64,
      "learning_rate": 0.07074826076302251,
      "loss": 2.896,
      "step": 182020
    },
    {
      "epoch": 292.67,
      "learning_rate": 0.07074504533215435,
      "loss": 2.9286,
      "step": 182040
    },
    {
      "epoch": 292.7,
      "learning_rate": 0.07074182990128618,
      "loss": 2.9146,
      "step": 182060
    },
    {
      "epoch": 292.73,
      "learning_rate": 0.07073861447041802,
      "loss": 2.9028,
      "step": 182080
    },
    {
      "epoch": 292.77,
      "learning_rate": 0.07073539903954984,
      "loss": 2.8837,
      "step": 182100
    },
    {
      "epoch": 292.8,
      "learning_rate": 0.07073218360868168,
      "loss": 2.8855,
      "step": 182120
    },
    {
      "epoch": 292.83,
      "learning_rate": 0.07072896817781352,
      "loss": 2.8746,
      "step": 182140
    },
    {
      "epoch": 292.86,
      "learning_rate": 0.07072575274694534,
      "loss": 2.892,
      "step": 182160
    },
    {
      "epoch": 292.89,
      "learning_rate": 0.07072253731607718,
      "loss": 2.852,
      "step": 182180
    },
    {
      "epoch": 292.93,
      "learning_rate": 0.070719321885209,
      "loss": 2.8732,
      "step": 182200
    },
    {
      "epoch": 292.96,
      "learning_rate": 0.07071610645434084,
      "loss": 2.8499,
      "step": 182220
    },
    {
      "epoch": 292.99,
      "learning_rate": 0.07071289102347267,
      "loss": 2.8727,
      "step": 182240
    },
    {
      "epoch": 293.0,
      "eval_accuracy": {
        "accuracy": 0.3898779444919537
      },
      "eval_loss": 2.9765048027038574,
      "eval_runtime": 2.7285,
      "eval_samples_per_second": 4714.361,
      "eval_steps_per_second": 73.668,
      "step": 182246
    },
    {
      "epoch": 293.02,
      "learning_rate": 0.0707096755926045,
      "loss": 2.8805,
      "step": 182260
    },
    {
      "epoch": 293.05,
      "learning_rate": 0.07070646016173635,
      "loss": 2.8872,
      "step": 182280
    },
    {
      "epoch": 293.09,
      "learning_rate": 0.07070324473086817,
      "loss": 2.8602,
      "step": 182300
    },
    {
      "epoch": 293.12,
      "learning_rate": 0.07070002930000001,
      "loss": 2.9153,
      "step": 182320
    },
    {
      "epoch": 293.15,
      "learning_rate": 0.07069681386913183,
      "loss": 2.8908,
      "step": 182340
    },
    {
      "epoch": 293.18,
      "learning_rate": 0.07069359843826367,
      "loss": 2.8697,
      "step": 182360
    },
    {
      "epoch": 293.22,
      "learning_rate": 0.07069038300739551,
      "loss": 2.8765,
      "step": 182380
    },
    {
      "epoch": 293.25,
      "learning_rate": 0.07068716757652733,
      "loss": 2.8948,
      "step": 182400
    },
    {
      "epoch": 293.28,
      "learning_rate": 0.07068395214565916,
      "loss": 2.8775,
      "step": 182420
    },
    {
      "epoch": 293.31,
      "learning_rate": 0.070680736714791,
      "loss": 2.8597,
      "step": 182440
    },
    {
      "epoch": 293.34,
      "learning_rate": 0.07067752128392284,
      "loss": 2.8564,
      "step": 182460
    },
    {
      "epoch": 293.38,
      "learning_rate": 0.07067430585305468,
      "loss": 2.8782,
      "step": 182480
    },
    {
      "epoch": 293.41,
      "learning_rate": 0.0706710904221865,
      "loss": 2.8807,
      "step": 182500
    },
    {
      "epoch": 293.44,
      "learning_rate": 0.07066787499131832,
      "loss": 2.8849,
      "step": 182520
    },
    {
      "epoch": 293.47,
      "learning_rate": 0.07066465956045016,
      "loss": 2.8678,
      "step": 182540
    },
    {
      "epoch": 293.5,
      "learning_rate": 0.070661444129582,
      "loss": 2.8551,
      "step": 182560
    },
    {
      "epoch": 293.54,
      "learning_rate": 0.07065822869871383,
      "loss": 2.8748,
      "step": 182580
    },
    {
      "epoch": 293.57,
      "learning_rate": 0.07065501326784566,
      "loss": 2.905,
      "step": 182600
    },
    {
      "epoch": 293.6,
      "learning_rate": 0.0706517978369775,
      "loss": 2.8744,
      "step": 182620
    },
    {
      "epoch": 293.63,
      "learning_rate": 0.07064858240610933,
      "loss": 2.9108,
      "step": 182640
    },
    {
      "epoch": 293.67,
      "learning_rate": 0.07064536697524117,
      "loss": 2.8612,
      "step": 182660
    },
    {
      "epoch": 293.7,
      "learning_rate": 0.07064215154437299,
      "loss": 2.8544,
      "step": 182680
    },
    {
      "epoch": 293.73,
      "learning_rate": 0.07063893611350483,
      "loss": 2.8821,
      "step": 182700
    },
    {
      "epoch": 293.76,
      "learning_rate": 0.07063572068263667,
      "loss": 2.893,
      "step": 182720
    },
    {
      "epoch": 293.79,
      "learning_rate": 0.0706325052517685,
      "loss": 2.8967,
      "step": 182740
    },
    {
      "epoch": 293.83,
      "learning_rate": 0.07062928982090032,
      "loss": 2.8747,
      "step": 182760
    },
    {
      "epoch": 293.86,
      "learning_rate": 0.07062607439003216,
      "loss": 2.8792,
      "step": 182780
    },
    {
      "epoch": 293.89,
      "learning_rate": 0.070622858959164,
      "loss": 2.8949,
      "step": 182800
    },
    {
      "epoch": 293.92,
      "learning_rate": 0.07061964352829583,
      "loss": 2.8924,
      "step": 182820
    },
    {
      "epoch": 293.95,
      "learning_rate": 0.07061642809742766,
      "loss": 2.8902,
      "step": 182840
    },
    {
      "epoch": 293.99,
      "learning_rate": 0.07061321266655948,
      "loss": 2.8803,
      "step": 182860
    },
    {
      "epoch": 294.0,
      "eval_accuracy": {
        "accuracy": 0.3870014771048744
      },
      "eval_loss": 2.978937864303589,
      "eval_runtime": 2.7116,
      "eval_samples_per_second": 4743.641,
      "eval_steps_per_second": 74.125,
      "step": 182868
    },
    {
      "epoch": 294.02,
      "learning_rate": 0.07060999723569132,
      "loss": 2.8666,
      "step": 182880
    },
    {
      "epoch": 294.05,
      "learning_rate": 0.07060678180482316,
      "loss": 2.9115,
      "step": 182900
    },
    {
      "epoch": 294.08,
      "learning_rate": 0.07060356637395498,
      "loss": 2.8646,
      "step": 182920
    },
    {
      "epoch": 294.12,
      "learning_rate": 0.07060035094308682,
      "loss": 2.8627,
      "step": 182940
    },
    {
      "epoch": 294.15,
      "learning_rate": 0.07059713551221865,
      "loss": 2.8619,
      "step": 182960
    },
    {
      "epoch": 294.18,
      "learning_rate": 0.07059392008135049,
      "loss": 2.8866,
      "step": 182980
    },
    {
      "epoch": 294.21,
      "learning_rate": 0.07059070465048232,
      "loss": 2.8576,
      "step": 183000
    },
    {
      "epoch": 294.24,
      "learning_rate": 0.07058764999115757,
      "loss": 2.9088,
      "step": 183020
    },
    {
      "epoch": 294.28,
      "learning_rate": 0.07058443456028939,
      "loss": 2.8896,
      "step": 183040
    },
    {
      "epoch": 294.31,
      "learning_rate": 0.07058121912942122,
      "loss": 2.8789,
      "step": 183060
    },
    {
      "epoch": 294.34,
      "learning_rate": 0.07057800369855306,
      "loss": 2.8648,
      "step": 183080
    },
    {
      "epoch": 294.37,
      "learning_rate": 0.07057478826768489,
      "loss": 2.8955,
      "step": 183100
    },
    {
      "epoch": 294.41,
      "learning_rate": 0.07057157283681673,
      "loss": 2.9071,
      "step": 183120
    },
    {
      "epoch": 294.44,
      "learning_rate": 0.07056835740594855,
      "loss": 2.8919,
      "step": 183140
    },
    {
      "epoch": 294.47,
      "learning_rate": 0.07056514197508039,
      "loss": 2.8799,
      "step": 183160
    },
    {
      "epoch": 294.5,
      "learning_rate": 0.07056192654421221,
      "loss": 2.8738,
      "step": 183180
    },
    {
      "epoch": 294.53,
      "learning_rate": 0.07055871111334405,
      "loss": 2.9008,
      "step": 183200
    },
    {
      "epoch": 294.57,
      "learning_rate": 0.07055549568247589,
      "loss": 2.9043,
      "step": 183220
    },
    {
      "epoch": 294.6,
      "learning_rate": 0.07055228025160772,
      "loss": 2.8849,
      "step": 183240
    },
    {
      "epoch": 294.63,
      "learning_rate": 0.07054906482073955,
      "loss": 2.8512,
      "step": 183260
    },
    {
      "epoch": 294.66,
      "learning_rate": 0.07054584938987138,
      "loss": 2.8895,
      "step": 183280
    },
    {
      "epoch": 294.69,
      "learning_rate": 0.07054263395900322,
      "loss": 2.8874,
      "step": 183300
    },
    {
      "epoch": 294.73,
      "learning_rate": 0.07053941852813506,
      "loss": 2.8857,
      "step": 183320
    },
    {
      "epoch": 294.76,
      "learning_rate": 0.07053620309726688,
      "loss": 2.8694,
      "step": 183340
    },
    {
      "epoch": 294.79,
      "learning_rate": 0.07053298766639873,
      "loss": 2.8829,
      "step": 183360
    },
    {
      "epoch": 294.82,
      "learning_rate": 0.07052977223553054,
      "loss": 2.873,
      "step": 183380
    },
    {
      "epoch": 294.86,
      "learning_rate": 0.07052655680466238,
      "loss": 2.9098,
      "step": 183400
    },
    {
      "epoch": 294.89,
      "learning_rate": 0.07052334137379422,
      "loss": 2.8778,
      "step": 183420
    },
    {
      "epoch": 294.92,
      "learning_rate": 0.07052012594292605,
      "loss": 2.8979,
      "step": 183440
    },
    {
      "epoch": 294.95,
      "learning_rate": 0.07051691051205788,
      "loss": 2.8877,
      "step": 183460
    },
    {
      "epoch": 294.98,
      "learning_rate": 0.07051369508118971,
      "loss": 2.8759,
      "step": 183480
    },
    {
      "epoch": 295.0,
      "eval_accuracy": {
        "accuracy": 0.38762341599937805
      },
      "eval_loss": 2.9799387454986572,
      "eval_runtime": 3.0278,
      "eval_samples_per_second": 4248.303,
      "eval_steps_per_second": 66.385,
      "step": 183490
    },
    {
      "epoch": 295.02,
      "learning_rate": 0.07051047965032155,
      "loss": 2.8734,
      "step": 183500
    },
    {
      "epoch": 295.05,
      "learning_rate": 0.07050726421945337,
      "loss": 2.8559,
      "step": 183520
    },
    {
      "epoch": 295.08,
      "learning_rate": 0.07050404878858521,
      "loss": 2.8746,
      "step": 183540
    },
    {
      "epoch": 295.11,
      "learning_rate": 0.07050083335771705,
      "loss": 2.8758,
      "step": 183560
    },
    {
      "epoch": 295.14,
      "learning_rate": 0.07049761792684887,
      "loss": 2.8835,
      "step": 183580
    },
    {
      "epoch": 295.18,
      "learning_rate": 0.07049440249598071,
      "loss": 2.8987,
      "step": 183600
    },
    {
      "epoch": 295.21,
      "learning_rate": 0.07049118706511254,
      "loss": 2.8543,
      "step": 183620
    },
    {
      "epoch": 295.24,
      "learning_rate": 0.07048797163424438,
      "loss": 2.85,
      "step": 183640
    },
    {
      "epoch": 295.27,
      "learning_rate": 0.07048475620337621,
      "loss": 2.8698,
      "step": 183660
    },
    {
      "epoch": 295.31,
      "learning_rate": 0.07048154077250804,
      "loss": 2.8255,
      "step": 183680
    },
    {
      "epoch": 295.34,
      "learning_rate": 0.07047832534163988,
      "loss": 2.8816,
      "step": 183700
    },
    {
      "epoch": 295.37,
      "learning_rate": 0.0704751099107717,
      "loss": 2.8725,
      "step": 183720
    },
    {
      "epoch": 295.4,
      "learning_rate": 0.07047189447990354,
      "loss": 2.8575,
      "step": 183740
    },
    {
      "epoch": 295.43,
      "learning_rate": 0.07046867904903538,
      "loss": 2.8522,
      "step": 183760
    },
    {
      "epoch": 295.47,
      "learning_rate": 0.0704654636181672,
      "loss": 2.8568,
      "step": 183780
    },
    {
      "epoch": 295.5,
      "learning_rate": 0.07046224818729904,
      "loss": 2.8897,
      "step": 183800
    },
    {
      "epoch": 295.53,
      "learning_rate": 0.07045903275643087,
      "loss": 2.8818,
      "step": 183820
    },
    {
      "epoch": 295.56,
      "learning_rate": 0.0704558173255627,
      "loss": 2.8856,
      "step": 183840
    },
    {
      "epoch": 295.59,
      "learning_rate": 0.07045260189469453,
      "loss": 2.8801,
      "step": 183860
    },
    {
      "epoch": 295.63,
      "learning_rate": 0.07044938646382637,
      "loss": 2.8755,
      "step": 183880
    },
    {
      "epoch": 295.66,
      "learning_rate": 0.07044617103295821,
      "loss": 2.8533,
      "step": 183900
    },
    {
      "epoch": 295.69,
      "learning_rate": 0.07044295560209003,
      "loss": 2.8799,
      "step": 183920
    },
    {
      "epoch": 295.72,
      "learning_rate": 0.07043974017122187,
      "loss": 2.8997,
      "step": 183940
    },
    {
      "epoch": 295.76,
      "learning_rate": 0.0704365247403537,
      "loss": 2.9022,
      "step": 183960
    },
    {
      "epoch": 295.79,
      "learning_rate": 0.07043330930948553,
      "loss": 2.9026,
      "step": 183980
    },
    {
      "epoch": 295.82,
      "learning_rate": 0.07043009387861737,
      "loss": 2.9097,
      "step": 184000
    },
    {
      "epoch": 295.85,
      "learning_rate": 0.0704268784477492,
      "loss": 2.8852,
      "step": 184020
    },
    {
      "epoch": 295.88,
      "learning_rate": 0.07042366301688104,
      "loss": 2.9455,
      "step": 184040
    },
    {
      "epoch": 295.92,
      "learning_rate": 0.07042044758601286,
      "loss": 2.8403,
      "step": 184060
    },
    {
      "epoch": 295.95,
      "learning_rate": 0.0704172321551447,
      "loss": 2.8708,
      "step": 184080
    },
    {
      "epoch": 295.98,
      "learning_rate": 0.07041401672427654,
      "loss": 2.8538,
      "step": 184100
    },
    {
      "epoch": 296.0,
      "eval_accuracy": {
        "accuracy": 0.39213247298452925
      },
      "eval_loss": 2.9418587684631348,
      "eval_runtime": 2.73,
      "eval_samples_per_second": 4711.771,
      "eval_steps_per_second": 73.627,
      "step": 184112
    },
    {
      "epoch": 296.01,
      "learning_rate": 0.07041080129340836,
      "loss": 2.8421,
      "step": 184120
    },
    {
      "epoch": 296.05,
      "learning_rate": 0.0704075858625402,
      "loss": 2.881,
      "step": 184140
    },
    {
      "epoch": 296.08,
      "learning_rate": 0.07040437043167203,
      "loss": 2.8638,
      "step": 184160
    },
    {
      "epoch": 296.11,
      "learning_rate": 0.07040115500080386,
      "loss": 2.8607,
      "step": 184180
    },
    {
      "epoch": 296.14,
      "learning_rate": 0.07039793956993569,
      "loss": 2.8807,
      "step": 184200
    },
    {
      "epoch": 296.17,
      "learning_rate": 0.07039472413906753,
      "loss": 2.8661,
      "step": 184220
    },
    {
      "epoch": 296.21,
      "learning_rate": 0.07039150870819937,
      "loss": 2.8827,
      "step": 184240
    },
    {
      "epoch": 296.24,
      "learning_rate": 0.07038829327733119,
      "loss": 2.9,
      "step": 184260
    },
    {
      "epoch": 296.27,
      "learning_rate": 0.07038507784646303,
      "loss": 2.8422,
      "step": 184280
    },
    {
      "epoch": 296.3,
      "learning_rate": 0.07038186241559485,
      "loss": 2.8584,
      "step": 184300
    },
    {
      "epoch": 296.33,
      "learning_rate": 0.07037864698472669,
      "loss": 2.9049,
      "step": 184320
    },
    {
      "epoch": 296.37,
      "learning_rate": 0.07037543155385853,
      "loss": 2.8526,
      "step": 184340
    },
    {
      "epoch": 296.4,
      "learning_rate": 0.07037221612299036,
      "loss": 2.8575,
      "step": 184360
    },
    {
      "epoch": 296.43,
      "learning_rate": 0.0703690006921222,
      "loss": 2.8652,
      "step": 184380
    },
    {
      "epoch": 296.46,
      "learning_rate": 0.07036578526125402,
      "loss": 2.8709,
      "step": 184400
    },
    {
      "epoch": 296.5,
      "learning_rate": 0.07036256983038586,
      "loss": 2.8428,
      "step": 184420
    },
    {
      "epoch": 296.53,
      "learning_rate": 0.0703593543995177,
      "loss": 2.8644,
      "step": 184440
    },
    {
      "epoch": 296.56,
      "learning_rate": 0.07035613896864952,
      "loss": 2.8467,
      "step": 184460
    },
    {
      "epoch": 296.59,
      "learning_rate": 0.07035292353778136,
      "loss": 2.8578,
      "step": 184480
    },
    {
      "epoch": 296.62,
      "learning_rate": 0.07034970810691318,
      "loss": 2.8786,
      "step": 184500
    },
    {
      "epoch": 296.66,
      "learning_rate": 0.07034649267604502,
      "loss": 2.8787,
      "step": 184520
    },
    {
      "epoch": 296.69,
      "learning_rate": 0.07034327724517685,
      "loss": 2.91,
      "step": 184540
    },
    {
      "epoch": 296.72,
      "learning_rate": 0.07034006181430869,
      "loss": 2.9201,
      "step": 184560
    },
    {
      "epoch": 296.75,
      "learning_rate": 0.07033684638344052,
      "loss": 2.8707,
      "step": 184580
    },
    {
      "epoch": 296.78,
      "learning_rate": 0.07033363095257235,
      "loss": 2.8785,
      "step": 184600
    },
    {
      "epoch": 296.82,
      "learning_rate": 0.07033041552170419,
      "loss": 2.8544,
      "step": 184620
    },
    {
      "epoch": 296.85,
      "learning_rate": 0.07032720009083601,
      "loss": 2.8369,
      "step": 184640
    },
    {
      "epoch": 296.88,
      "learning_rate": 0.07032398465996785,
      "loss": 2.8936,
      "step": 184660
    },
    {
      "epoch": 296.91,
      "learning_rate": 0.07032076922909969,
      "loss": 2.8962,
      "step": 184680
    },
    {
      "epoch": 296.95,
      "learning_rate": 0.07031755379823151,
      "loss": 2.9243,
      "step": 184700
    },
    {
      "epoch": 296.98,
      "learning_rate": 0.07031433836736335,
      "loss": 2.8575,
      "step": 184720
    },
    {
      "epoch": 297.0,
      "eval_accuracy": {
        "accuracy": 0.3882453548938817
      },
      "eval_loss": 2.974041700363159,
      "eval_runtime": 2.772,
      "eval_samples_per_second": 4640.293,
      "eval_steps_per_second": 72.51,
      "step": 184734
    },
    {
      "epoch": 297.01,
      "learning_rate": 0.07031112293649518,
      "loss": 2.9112,
      "step": 184740
    },
    {
      "epoch": 297.04,
      "learning_rate": 0.07030790750562702,
      "loss": 2.9162,
      "step": 184760
    },
    {
      "epoch": 297.07,
      "learning_rate": 0.07030469207475885,
      "loss": 2.8578,
      "step": 184780
    },
    {
      "epoch": 297.11,
      "learning_rate": 0.07030147664389068,
      "loss": 2.8758,
      "step": 184800
    },
    {
      "epoch": 297.14,
      "learning_rate": 0.07029826121302252,
      "loss": 2.8233,
      "step": 184820
    },
    {
      "epoch": 297.17,
      "learning_rate": 0.07029504578215434,
      "loss": 2.8805,
      "step": 184840
    },
    {
      "epoch": 297.2,
      "learning_rate": 0.07029183035128618,
      "loss": 2.8774,
      "step": 184860
    },
    {
      "epoch": 297.23,
      "learning_rate": 0.07028861492041802,
      "loss": 2.8638,
      "step": 184880
    },
    {
      "epoch": 297.27,
      "learning_rate": 0.07028539948954984,
      "loss": 2.9006,
      "step": 184900
    },
    {
      "epoch": 297.3,
      "learning_rate": 0.07028218405868168,
      "loss": 2.8691,
      "step": 184920
    },
    {
      "epoch": 297.33,
      "learning_rate": 0.0702789686278135,
      "loss": 2.8583,
      "step": 184940
    },
    {
      "epoch": 297.36,
      "learning_rate": 0.07027575319694535,
      "loss": 2.8371,
      "step": 184960
    },
    {
      "epoch": 297.4,
      "learning_rate": 0.07027253776607717,
      "loss": 2.8579,
      "step": 184980
    },
    {
      "epoch": 297.43,
      "learning_rate": 0.07026932233520901,
      "loss": 2.8652,
      "step": 185000
    },
    {
      "epoch": 297.46,
      "learning_rate": 0.07026610690434085,
      "loss": 2.8864,
      "step": 185020
    },
    {
      "epoch": 297.49,
      "learning_rate": 0.07026289147347267,
      "loss": 2.8739,
      "step": 185040
    },
    {
      "epoch": 297.52,
      "learning_rate": 0.07025967604260451,
      "loss": 2.8823,
      "step": 185060
    },
    {
      "epoch": 297.56,
      "learning_rate": 0.07025646061173633,
      "loss": 2.8673,
      "step": 185080
    },
    {
      "epoch": 297.59,
      "learning_rate": 0.07025324518086817,
      "loss": 2.8599,
      "step": 185100
    },
    {
      "epoch": 297.62,
      "learning_rate": 0.07025002975000001,
      "loss": 2.8786,
      "step": 185120
    },
    {
      "epoch": 297.65,
      "learning_rate": 0.07024681431913184,
      "loss": 2.8757,
      "step": 185140
    },
    {
      "epoch": 297.68,
      "learning_rate": 0.07024359888826366,
      "loss": 2.8605,
      "step": 185160
    },
    {
      "epoch": 297.72,
      "learning_rate": 0.0702403834573955,
      "loss": 2.8749,
      "step": 185180
    },
    {
      "epoch": 297.75,
      "learning_rate": 0.07023716802652734,
      "loss": 2.8808,
      "step": 185200
    },
    {
      "epoch": 297.78,
      "learning_rate": 0.07023395259565918,
      "loss": 2.8779,
      "step": 185220
    },
    {
      "epoch": 297.81,
      "learning_rate": 0.0702308979363344,
      "loss": 2.8859,
      "step": 185240
    },
    {
      "epoch": 297.85,
      "learning_rate": 0.07022768250546624,
      "loss": 2.8788,
      "step": 185260
    },
    {
      "epoch": 297.88,
      "learning_rate": 0.07022446707459808,
      "loss": 2.8495,
      "step": 185280
    },
    {
      "epoch": 297.91,
      "learning_rate": 0.0702212516437299,
      "loss": 2.8808,
      "step": 185300
    },
    {
      "epoch": 297.94,
      "learning_rate": 0.07021803621286175,
      "loss": 2.8738,
      "step": 185320
    },
    {
      "epoch": 297.97,
      "learning_rate": 0.07021482078199356,
      "loss": 2.9165,
      "step": 185340
    },
    {
      "epoch": 298.0,
      "eval_accuracy": {
        "accuracy": 0.38925600559745005
      },
      "eval_loss": 2.9865469932556152,
      "eval_runtime": 2.8773,
      "eval_samples_per_second": 4470.496,
      "eval_steps_per_second": 69.857,
      "step": 185356
    },
    {
      "epoch": 298.01,
      "learning_rate": 0.0702116053511254,
      "loss": 2.8645,
      "step": 185360
    },
    {
      "epoch": 298.04,
      "learning_rate": 0.07020838992025724,
      "loss": 2.8673,
      "step": 185380
    },
    {
      "epoch": 298.07,
      "learning_rate": 0.07020517448938907,
      "loss": 2.8709,
      "step": 185400
    },
    {
      "epoch": 298.1,
      "learning_rate": 0.07020195905852092,
      "loss": 2.8559,
      "step": 185420
    },
    {
      "epoch": 298.14,
      "learning_rate": 0.07019874362765273,
      "loss": 2.8525,
      "step": 185440
    },
    {
      "epoch": 298.17,
      "learning_rate": 0.07019552819678457,
      "loss": 2.8646,
      "step": 185460
    },
    {
      "epoch": 298.2,
      "learning_rate": 0.0701923127659164,
      "loss": 2.8967,
      "step": 185480
    },
    {
      "epoch": 298.23,
      "learning_rate": 0.07018909733504823,
      "loss": 2.9159,
      "step": 185500
    },
    {
      "epoch": 298.26,
      "learning_rate": 0.07018588190418007,
      "loss": 2.8837,
      "step": 185520
    },
    {
      "epoch": 298.3,
      "learning_rate": 0.0701826664733119,
      "loss": 2.89,
      "step": 185540
    },
    {
      "epoch": 298.33,
      "learning_rate": 0.07017945104244375,
      "loss": 2.8752,
      "step": 185560
    },
    {
      "epoch": 298.36,
      "learning_rate": 0.07017623561157556,
      "loss": 2.8695,
      "step": 185580
    },
    {
      "epoch": 298.39,
      "learning_rate": 0.0701730201807074,
      "loss": 2.8772,
      "step": 185600
    },
    {
      "epoch": 298.42,
      "learning_rate": 0.07016980474983923,
      "loss": 2.8917,
      "step": 185620
    },
    {
      "epoch": 298.46,
      "learning_rate": 0.07016658931897106,
      "loss": 2.8931,
      "step": 185640
    },
    {
      "epoch": 298.49,
      "learning_rate": 0.07016337388810291,
      "loss": 2.883,
      "step": 185660
    },
    {
      "epoch": 298.52,
      "learning_rate": 0.07016015845723472,
      "loss": 2.8979,
      "step": 185680
    },
    {
      "epoch": 298.55,
      "learning_rate": 0.07015694302636656,
      "loss": 2.8793,
      "step": 185700
    },
    {
      "epoch": 298.59,
      "learning_rate": 0.0701537275954984,
      "loss": 2.838,
      "step": 185720
    },
    {
      "epoch": 298.62,
      "learning_rate": 0.07015051216463022,
      "loss": 2.8687,
      "step": 185740
    },
    {
      "epoch": 298.65,
      "learning_rate": 0.07014729673376208,
      "loss": 2.849,
      "step": 185760
    },
    {
      "epoch": 298.68,
      "learning_rate": 0.07014408130289389,
      "loss": 2.9051,
      "step": 185780
    },
    {
      "epoch": 298.71,
      "learning_rate": 0.07014086587202573,
      "loss": 2.8572,
      "step": 185800
    },
    {
      "epoch": 298.75,
      "learning_rate": 0.07013765044115756,
      "loss": 2.8782,
      "step": 185820
    },
    {
      "epoch": 298.78,
      "learning_rate": 0.07013443501028939,
      "loss": 2.8836,
      "step": 185840
    },
    {
      "epoch": 298.81,
      "learning_rate": 0.07013121957942123,
      "loss": 2.8448,
      "step": 185860
    },
    {
      "epoch": 298.84,
      "learning_rate": 0.07012800414855305,
      "loss": 2.885,
      "step": 185880
    },
    {
      "epoch": 298.87,
      "learning_rate": 0.07012478871768489,
      "loss": 2.8916,
      "step": 185900
    },
    {
      "epoch": 298.91,
      "learning_rate": 0.07012157328681672,
      "loss": 2.8714,
      "step": 185920
    },
    {
      "epoch": 298.94,
      "learning_rate": 0.07011835785594855,
      "loss": 2.8686,
      "step": 185940
    },
    {
      "epoch": 298.97,
      "learning_rate": 0.07011514242508039,
      "loss": 2.9033,
      "step": 185960
    },
    {
      "epoch": 299.0,
      "eval_accuracy": {
        "accuracy": 0.39182150353727746
      },
      "eval_loss": 2.9646077156066895,
      "eval_runtime": 2.816,
      "eval_samples_per_second": 4567.844,
      "eval_steps_per_second": 71.378,
      "step": 185978
    },
    {
      "epoch": 299.0,
      "learning_rate": 0.07011192699421222,
      "loss": 2.8842,
      "step": 185980
    },
    {
      "epoch": 299.04,
      "learning_rate": 0.07010871156334406,
      "loss": 2.8827,
      "step": 186000
    },
    {
      "epoch": 299.07,
      "learning_rate": 0.07010549613247588,
      "loss": 2.8694,
      "step": 186020
    },
    {
      "epoch": 299.1,
      "learning_rate": 0.07010228070160772,
      "loss": 2.8727,
      "step": 186040
    },
    {
      "epoch": 299.13,
      "learning_rate": 0.07009906527073956,
      "loss": 2.8822,
      "step": 186060
    },
    {
      "epoch": 299.16,
      "learning_rate": 0.07009584983987138,
      "loss": 2.8951,
      "step": 186080
    },
    {
      "epoch": 299.2,
      "learning_rate": 0.07009263440900322,
      "loss": 2.8639,
      "step": 186100
    },
    {
      "epoch": 299.23,
      "learning_rate": 0.07008941897813505,
      "loss": 2.8599,
      "step": 186120
    },
    {
      "epoch": 299.26,
      "learning_rate": 0.07008620354726688,
      "loss": 2.8885,
      "step": 186140
    },
    {
      "epoch": 299.29,
      "learning_rate": 0.07008298811639872,
      "loss": 2.8431,
      "step": 186160
    },
    {
      "epoch": 299.32,
      "learning_rate": 0.07007977268553055,
      "loss": 2.86,
      "step": 186180
    },
    {
      "epoch": 299.36,
      "learning_rate": 0.07007655725466239,
      "loss": 2.8936,
      "step": 186200
    },
    {
      "epoch": 299.39,
      "learning_rate": 0.07007334182379421,
      "loss": 2.87,
      "step": 186220
    },
    {
      "epoch": 299.42,
      "learning_rate": 0.07007012639292605,
      "loss": 2.8739,
      "step": 186240
    },
    {
      "epoch": 299.45,
      "learning_rate": 0.07006691096205787,
      "loss": 2.8943,
      "step": 186260
    },
    {
      "epoch": 299.49,
      "learning_rate": 0.07006369553118971,
      "loss": 2.8793,
      "step": 186280
    },
    {
      "epoch": 299.52,
      "learning_rate": 0.07006048010032155,
      "loss": 2.8862,
      "step": 186300
    },
    {
      "epoch": 299.55,
      "learning_rate": 0.07005726466945338,
      "loss": 2.8881,
      "step": 186320
    },
    {
      "epoch": 299.58,
      "learning_rate": 0.07005404923858521,
      "loss": 2.8577,
      "step": 186340
    },
    {
      "epoch": 299.61,
      "learning_rate": 0.07005083380771704,
      "loss": 2.8401,
      "step": 186360
    },
    {
      "epoch": 299.65,
      "learning_rate": 0.07004761837684888,
      "loss": 2.862,
      "step": 186380
    },
    {
      "epoch": 299.68,
      "learning_rate": 0.07004440294598072,
      "loss": 2.8726,
      "step": 186400
    },
    {
      "epoch": 299.71,
      "learning_rate": 0.07004118751511254,
      "loss": 2.8623,
      "step": 186420
    },
    {
      "epoch": 299.74,
      "learning_rate": 0.07003797208424438,
      "loss": 2.8797,
      "step": 186440
    },
    {
      "epoch": 299.77,
      "learning_rate": 0.0700347566533762,
      "loss": 2.8789,
      "step": 186460
    },
    {
      "epoch": 299.81,
      "learning_rate": 0.07003154122250804,
      "loss": 2.8586,
      "step": 186480
    },
    {
      "epoch": 299.84,
      "learning_rate": 0.07002832579163988,
      "loss": 2.8926,
      "step": 186500
    },
    {
      "epoch": 299.87,
      "learning_rate": 0.0700251103607717,
      "loss": 2.9141,
      "step": 186520
    },
    {
      "epoch": 299.9,
      "learning_rate": 0.07002189492990354,
      "loss": 2.8327,
      "step": 186540
    },
    {
      "epoch": 299.94,
      "learning_rate": 0.07001867949903537,
      "loss": 2.8484,
      "step": 186560
    },
    {
      "epoch": 299.97,
      "learning_rate": 0.07001546406816721,
      "loss": 2.8448,
      "step": 186580
    },
    {
      "epoch": 300.0,
      "learning_rate": 0.07001224863729903,
      "loss": 2.8787,
      "step": 186600
    },
    {
      "epoch": 300.0,
      "eval_accuracy": {
        "accuracy": 0.382881131928788
      },
      "eval_loss": 2.982436418533325,
      "eval_runtime": 2.7935,
      "eval_samples_per_second": 4604.627,
      "eval_steps_per_second": 71.953,
      "step": 186600
    },
    {
      "epoch": 300.03,
      "learning_rate": 0.07000903320643087,
      "loss": 2.8869,
      "step": 186620
    },
    {
      "epoch": 300.06,
      "learning_rate": 0.07000581777556271,
      "loss": 2.8389,
      "step": 186640
    },
    {
      "epoch": 300.1,
      "learning_rate": 0.07000260234469453,
      "loss": 2.8903,
      "step": 186660
    },
    {
      "epoch": 300.13,
      "learning_rate": 0.06999938691382637,
      "loss": 2.8821,
      "step": 186680
    },
    {
      "epoch": 300.16,
      "learning_rate": 0.0699961714829582,
      "loss": 2.8803,
      "step": 186700
    },
    {
      "epoch": 300.19,
      "learning_rate": 0.06999295605209004,
      "loss": 2.8987,
      "step": 186720
    },
    {
      "epoch": 300.23,
      "learning_rate": 0.06998974062122187,
      "loss": 2.8981,
      "step": 186740
    },
    {
      "epoch": 300.26,
      "learning_rate": 0.0699865251903537,
      "loss": 2.8944,
      "step": 186760
    },
    {
      "epoch": 300.29,
      "learning_rate": 0.06998330975948554,
      "loss": 2.8638,
      "step": 186780
    },
    {
      "epoch": 300.32,
      "learning_rate": 0.06998009432861736,
      "loss": 2.8696,
      "step": 186800
    },
    {
      "epoch": 300.35,
      "learning_rate": 0.0699768788977492,
      "loss": 2.8444,
      "step": 186820
    },
    {
      "epoch": 300.39,
      "learning_rate": 0.06997366346688104,
      "loss": 2.862,
      "step": 186840
    },
    {
      "epoch": 300.42,
      "learning_rate": 0.06997044803601286,
      "loss": 2.8545,
      "step": 186860
    },
    {
      "epoch": 300.45,
      "learning_rate": 0.0699672326051447,
      "loss": 2.8463,
      "step": 186880
    },
    {
      "epoch": 300.48,
      "learning_rate": 0.06996401717427653,
      "loss": 2.8517,
      "step": 186900
    },
    {
      "epoch": 300.51,
      "learning_rate": 0.06996080174340837,
      "loss": 2.8989,
      "step": 186920
    },
    {
      "epoch": 300.55,
      "learning_rate": 0.06995758631254019,
      "loss": 2.8505,
      "step": 186940
    },
    {
      "epoch": 300.58,
      "learning_rate": 0.06995437088167203,
      "loss": 2.853,
      "step": 186960
    },
    {
      "epoch": 300.61,
      "learning_rate": 0.06995115545080387,
      "loss": 2.8712,
      "step": 186980
    },
    {
      "epoch": 300.64,
      "learning_rate": 0.06994794001993569,
      "loss": 2.852,
      "step": 187000
    },
    {
      "epoch": 300.68,
      "learning_rate": 0.06994472458906753,
      "loss": 2.8931,
      "step": 187020
    },
    {
      "epoch": 300.71,
      "learning_rate": 0.06994150915819936,
      "loss": 2.8538,
      "step": 187040
    },
    {
      "epoch": 300.74,
      "learning_rate": 0.0699382937273312,
      "loss": 2.8545,
      "step": 187060
    },
    {
      "epoch": 300.77,
      "learning_rate": 0.06993507829646303,
      "loss": 2.8562,
      "step": 187080
    },
    {
      "epoch": 300.8,
      "learning_rate": 0.06993186286559486,
      "loss": 2.8688,
      "step": 187100
    },
    {
      "epoch": 300.84,
      "learning_rate": 0.0699286474347267,
      "loss": 2.8826,
      "step": 187120
    },
    {
      "epoch": 300.87,
      "learning_rate": 0.06992543200385852,
      "loss": 2.893,
      "step": 187140
    },
    {
      "epoch": 300.9,
      "learning_rate": 0.06992221657299036,
      "loss": 2.8665,
      "step": 187160
    },
    {
      "epoch": 300.93,
      "learning_rate": 0.0699190011421222,
      "loss": 2.8469,
      "step": 187180
    },
    {
      "epoch": 300.96,
      "learning_rate": 0.06991578571125402,
      "loss": 2.8787,
      "step": 187200
    },
    {
      "epoch": 301.0,
      "learning_rate": 0.06991257028038586,
      "loss": 2.8725,
      "step": 187220
    },
    {
      "epoch": 301.0,
      "eval_accuracy": {
        "accuracy": 0.3881676125320687
      },
      "eval_loss": 2.971109390258789,
      "eval_runtime": 3.9368,
      "eval_samples_per_second": 3267.384,
      "eval_steps_per_second": 51.057,
      "step": 187222
    },
    {
      "epoch": 301.03,
      "learning_rate": 0.0699095156210611,
      "loss": 2.8476,
      "step": 187240
    },
    {
      "epoch": 301.06,
      "learning_rate": 0.06990630019019292,
      "loss": 2.8811,
      "step": 187260
    },
    {
      "epoch": 301.09,
      "learning_rate": 0.06990308475932477,
      "loss": 2.8679,
      "step": 187280
    },
    {
      "epoch": 301.13,
      "learning_rate": 0.06989986932845658,
      "loss": 2.8522,
      "step": 187300
    },
    {
      "epoch": 301.16,
      "learning_rate": 0.06989665389758844,
      "loss": 2.9017,
      "step": 187320
    },
    {
      "epoch": 301.19,
      "learning_rate": 0.06989343846672026,
      "loss": 2.8768,
      "step": 187340
    },
    {
      "epoch": 301.22,
      "learning_rate": 0.06989022303585209,
      "loss": 2.8786,
      "step": 187360
    },
    {
      "epoch": 301.25,
      "learning_rate": 0.06988700760498394,
      "loss": 2.837,
      "step": 187380
    },
    {
      "epoch": 301.29,
      "learning_rate": 0.06988379217411575,
      "loss": 2.8606,
      "step": 187400
    },
    {
      "epoch": 301.32,
      "learning_rate": 0.0698805767432476,
      "loss": 2.8532,
      "step": 187420
    },
    {
      "epoch": 301.35,
      "learning_rate": 0.06987736131237943,
      "loss": 2.8618,
      "step": 187440
    },
    {
      "epoch": 301.38,
      "learning_rate": 0.06987414588151125,
      "loss": 2.9103,
      "step": 187460
    },
    {
      "epoch": 301.41,
      "learning_rate": 0.0698709304506431,
      "loss": 2.8805,
      "step": 187480
    },
    {
      "epoch": 301.45,
      "learning_rate": 0.06986771501977491,
      "loss": 2.8604,
      "step": 187500
    },
    {
      "epoch": 301.48,
      "learning_rate": 0.06986449958890677,
      "loss": 2.8806,
      "step": 187520
    },
    {
      "epoch": 301.51,
      "learning_rate": 0.06986128415803859,
      "loss": 2.8623,
      "step": 187540
    },
    {
      "epoch": 301.54,
      "learning_rate": 0.06985806872717042,
      "loss": 2.8829,
      "step": 187560
    },
    {
      "epoch": 301.58,
      "learning_rate": 0.06985485329630226,
      "loss": 2.8306,
      "step": 187580
    },
    {
      "epoch": 301.61,
      "learning_rate": 0.06985163786543408,
      "loss": 2.8888,
      "step": 187600
    },
    {
      "epoch": 301.64,
      "learning_rate": 0.06984842243456593,
      "loss": 2.9231,
      "step": 187620
    },
    {
      "epoch": 301.67,
      "learning_rate": 0.06984520700369774,
      "loss": 2.8627,
      "step": 187640
    },
    {
      "epoch": 301.7,
      "learning_rate": 0.06984199157282958,
      "loss": 2.8782,
      "step": 187660
    },
    {
      "epoch": 301.74,
      "learning_rate": 0.06983877614196142,
      "loss": 2.8575,
      "step": 187680
    },
    {
      "epoch": 301.77,
      "learning_rate": 0.06983556071109324,
      "loss": 2.8523,
      "step": 187700
    },
    {
      "epoch": 301.8,
      "learning_rate": 0.0698323452802251,
      "loss": 2.877,
      "step": 187720
    },
    {
      "epoch": 301.83,
      "learning_rate": 0.06982912984935691,
      "loss": 2.8803,
      "step": 187740
    },
    {
      "epoch": 301.86,
      "learning_rate": 0.06982591441848876,
      "loss": 2.8763,
      "step": 187760
    },
    {
      "epoch": 301.9,
      "learning_rate": 0.06982269898762059,
      "loss": 2.89,
      "step": 187780
    },
    {
      "epoch": 301.93,
      "learning_rate": 0.06981948355675241,
      "loss": 2.8769,
      "step": 187800
    },
    {
      "epoch": 301.96,
      "learning_rate": 0.06981626812588426,
      "loss": 2.8404,
      "step": 187820
    },
    {
      "epoch": 301.99,
      "learning_rate": 0.06981305269501607,
      "loss": 2.8891,
      "step": 187840
    },
    {
      "epoch": 302.0,
      "eval_accuracy": {
        "accuracy": 0.3931431236880976
      },
      "eval_loss": 2.95068097114563,
      "eval_runtime": 2.8765,
      "eval_samples_per_second": 4471.718,
      "eval_steps_per_second": 69.876,
      "step": 187844
    },
    {
      "epoch": 302.03,
      "learning_rate": 0.06980983726414793,
      "loss": 2.8565,
      "step": 187860
    },
    {
      "epoch": 302.06,
      "learning_rate": 0.06980662183327975,
      "loss": 2.8696,
      "step": 187880
    },
    {
      "epoch": 302.09,
      "learning_rate": 0.06980340640241157,
      "loss": 2.8622,
      "step": 187900
    },
    {
      "epoch": 302.12,
      "learning_rate": 0.06980019097154341,
      "loss": 2.86,
      "step": 187920
    },
    {
      "epoch": 302.15,
      "learning_rate": 0.06979697554067524,
      "loss": 2.8576,
      "step": 187940
    },
    {
      "epoch": 302.19,
      "learning_rate": 0.06979376010980709,
      "loss": 2.8236,
      "step": 187960
    },
    {
      "epoch": 302.22,
      "learning_rate": 0.0697905446789389,
      "loss": 2.8423,
      "step": 187980
    },
    {
      "epoch": 302.25,
      "learning_rate": 0.06978732924807074,
      "loss": 2.8348,
      "step": 188000
    },
    {
      "epoch": 302.28,
      "learning_rate": 0.06978411381720258,
      "loss": 2.8568,
      "step": 188020
    },
    {
      "epoch": 302.32,
      "learning_rate": 0.0697808983863344,
      "loss": 2.8885,
      "step": 188040
    },
    {
      "epoch": 302.35,
      "learning_rate": 0.06977768295546626,
      "loss": 2.8856,
      "step": 188060
    },
    {
      "epoch": 302.38,
      "learning_rate": 0.06977446752459807,
      "loss": 2.8446,
      "step": 188080
    },
    {
      "epoch": 302.41,
      "learning_rate": 0.0697712520937299,
      "loss": 2.8554,
      "step": 188100
    },
    {
      "epoch": 302.44,
      "learning_rate": 0.06976803666286174,
      "loss": 2.8402,
      "step": 188120
    },
    {
      "epoch": 302.48,
      "learning_rate": 0.06976482123199357,
      "loss": 2.8734,
      "step": 188140
    },
    {
      "epoch": 302.51,
      "learning_rate": 0.06976160580112542,
      "loss": 2.8475,
      "step": 188160
    },
    {
      "epoch": 302.54,
      "learning_rate": 0.06975839037025723,
      "loss": 2.8553,
      "step": 188180
    },
    {
      "epoch": 302.57,
      "learning_rate": 0.06975517493938907,
      "loss": 2.878,
      "step": 188200
    },
    {
      "epoch": 302.6,
      "learning_rate": 0.06975195950852091,
      "loss": 2.8949,
      "step": 188220
    },
    {
      "epoch": 302.64,
      "learning_rate": 0.06974874407765273,
      "loss": 2.914,
      "step": 188240
    },
    {
      "epoch": 302.67,
      "learning_rate": 0.06974552864678457,
      "loss": 2.867,
      "step": 188260
    },
    {
      "epoch": 302.7,
      "learning_rate": 0.0697423132159164,
      "loss": 2.8827,
      "step": 188280
    },
    {
      "epoch": 302.73,
      "learning_rate": 0.06973909778504823,
      "loss": 2.8708,
      "step": 188300
    },
    {
      "epoch": 302.77,
      "learning_rate": 0.06973588235418006,
      "loss": 2.8491,
      "step": 188320
    },
    {
      "epoch": 302.8,
      "learning_rate": 0.0697326669233119,
      "loss": 2.8621,
      "step": 188340
    },
    {
      "epoch": 302.83,
      "learning_rate": 0.06972945149244374,
      "loss": 2.8562,
      "step": 188360
    },
    {
      "epoch": 302.86,
      "learning_rate": 0.06972623606157556,
      "loss": 2.8767,
      "step": 188380
    },
    {
      "epoch": 302.89,
      "learning_rate": 0.06972302063070741,
      "loss": 2.8845,
      "step": 188400
    },
    {
      "epoch": 302.93,
      "learning_rate": 0.06971980519983922,
      "loss": 2.8793,
      "step": 188420
    },
    {
      "epoch": 302.96,
      "learning_rate": 0.06971658976897106,
      "loss": 2.8591,
      "step": 188440
    },
    {
      "epoch": 302.99,
      "learning_rate": 0.0697133743381029,
      "loss": 2.8648,
      "step": 188460
    },
    {
      "epoch": 303.0,
      "eval_accuracy": {
        "accuracy": 0.3879343854466299
      },
      "eval_loss": 2.967660903930664,
      "eval_runtime": 3.2432,
      "eval_samples_per_second": 3966.1,
      "eval_steps_per_second": 61.975,
      "step": 188466
    },
    {
      "epoch": 303.02,
      "learning_rate": 0.06971015890723473,
      "loss": 2.8622,
      "step": 188480
    },
    {
      "epoch": 303.05,
      "learning_rate": 0.06970694347636658,
      "loss": 2.8893,
      "step": 188500
    },
    {
      "epoch": 303.09,
      "learning_rate": 0.06970372804549839,
      "loss": 2.87,
      "step": 188520
    },
    {
      "epoch": 303.12,
      "learning_rate": 0.06970051261463023,
      "loss": 2.8495,
      "step": 188540
    },
    {
      "epoch": 303.15,
      "learning_rate": 0.06969729718376207,
      "loss": 2.8626,
      "step": 188560
    },
    {
      "epoch": 303.18,
      "learning_rate": 0.06969408175289389,
      "loss": 2.8812,
      "step": 188580
    },
    {
      "epoch": 303.22,
      "learning_rate": 0.06969086632202573,
      "loss": 2.8689,
      "step": 188600
    },
    {
      "epoch": 303.25,
      "learning_rate": 0.06968765089115755,
      "loss": 2.8492,
      "step": 188620
    },
    {
      "epoch": 303.28,
      "learning_rate": 0.06968443546028939,
      "loss": 2.8748,
      "step": 188640
    },
    {
      "epoch": 303.31,
      "learning_rate": 0.06968122002942122,
      "loss": 2.83,
      "step": 188660
    },
    {
      "epoch": 303.34,
      "learning_rate": 0.06967800459855306,
      "loss": 2.8465,
      "step": 188680
    },
    {
      "epoch": 303.38,
      "learning_rate": 0.0696747891676849,
      "loss": 2.8826,
      "step": 188700
    },
    {
      "epoch": 303.41,
      "learning_rate": 0.06967157373681672,
      "loss": 2.8911,
      "step": 188720
    },
    {
      "epoch": 303.44,
      "learning_rate": 0.06966835830594856,
      "loss": 2.8599,
      "step": 188740
    },
    {
      "epoch": 303.47,
      "learning_rate": 0.06966514287508038,
      "loss": 2.8579,
      "step": 188760
    },
    {
      "epoch": 303.5,
      "learning_rate": 0.06966192744421222,
      "loss": 2.865,
      "step": 188780
    },
    {
      "epoch": 303.54,
      "learning_rate": 0.06965871201334406,
      "loss": 2.8765,
      "step": 188800
    },
    {
      "epoch": 303.57,
      "learning_rate": 0.06965549658247588,
      "loss": 2.8668,
      "step": 188820
    },
    {
      "epoch": 303.6,
      "learning_rate": 0.06965228115160772,
      "loss": 2.8932,
      "step": 188840
    },
    {
      "epoch": 303.63,
      "learning_rate": 0.06964906572073955,
      "loss": 2.8398,
      "step": 188860
    },
    {
      "epoch": 303.67,
      "learning_rate": 0.06964585028987139,
      "loss": 2.8469,
      "step": 188880
    },
    {
      "epoch": 303.7,
      "learning_rate": 0.06964263485900322,
      "loss": 2.8945,
      "step": 188900
    },
    {
      "epoch": 303.73,
      "learning_rate": 0.06963941942813505,
      "loss": 2.893,
      "step": 188920
    },
    {
      "epoch": 303.76,
      "learning_rate": 0.06963620399726689,
      "loss": 2.8513,
      "step": 188940
    },
    {
      "epoch": 303.79,
      "learning_rate": 0.06963298856639871,
      "loss": 2.8779,
      "step": 188960
    },
    {
      "epoch": 303.83,
      "learning_rate": 0.06962977313553055,
      "loss": 2.8558,
      "step": 188980
    },
    {
      "epoch": 303.86,
      "learning_rate": 0.06962655770466238,
      "loss": 2.876,
      "step": 189000
    },
    {
      "epoch": 303.89,
      "learning_rate": 0.06962334227379421,
      "loss": 2.8554,
      "step": 189020
    },
    {
      "epoch": 303.92,
      "learning_rate": 0.06962012684292605,
      "loss": 2.8786,
      "step": 189040
    },
    {
      "epoch": 303.95,
      "learning_rate": 0.06961691141205788,
      "loss": 2.8794,
      "step": 189060
    },
    {
      "epoch": 303.99,
      "learning_rate": 0.06961369598118972,
      "loss": 2.8571,
      "step": 189080
    },
    {
      "epoch": 304.0,
      "eval_accuracy": {
        "accuracy": 0.3832698437378528
      },
      "eval_loss": 2.996811866760254,
      "eval_runtime": 3.8605,
      "eval_samples_per_second": 3331.979,
      "eval_steps_per_second": 52.066,
      "step": 189088
    },
    {
      "epoch": 304.02,
      "learning_rate": 0.06961048055032154,
      "loss": 2.854,
      "step": 189100
    },
    {
      "epoch": 304.05,
      "learning_rate": 0.06960726511945338,
      "loss": 2.8731,
      "step": 189120
    },
    {
      "epoch": 304.08,
      "learning_rate": 0.06960404968858522,
      "loss": 2.8729,
      "step": 189140
    },
    {
      "epoch": 304.12,
      "learning_rate": 0.06960083425771704,
      "loss": 2.8674,
      "step": 189160
    },
    {
      "epoch": 304.15,
      "learning_rate": 0.06959761882684888,
      "loss": 2.8579,
      "step": 189180
    },
    {
      "epoch": 304.18,
      "learning_rate": 0.0695944033959807,
      "loss": 2.8522,
      "step": 189200
    },
    {
      "epoch": 304.21,
      "learning_rate": 0.06959118796511254,
      "loss": 2.858,
      "step": 189220
    },
    {
      "epoch": 304.24,
      "learning_rate": 0.06958797253424438,
      "loss": 2.9104,
      "step": 189240
    },
    {
      "epoch": 304.28,
      "learning_rate": 0.06958475710337621,
      "loss": 2.9039,
      "step": 189260
    },
    {
      "epoch": 304.31,
      "learning_rate": 0.06958154167250805,
      "loss": 2.8501,
      "step": 189280
    },
    {
      "epoch": 304.34,
      "learning_rate": 0.06957832624163987,
      "loss": 2.8868,
      "step": 189300
    },
    {
      "epoch": 304.37,
      "learning_rate": 0.06957511081077171,
      "loss": 2.8657,
      "step": 189320
    },
    {
      "epoch": 304.41,
      "learning_rate": 0.06957205615144696,
      "loss": 2.8595,
      "step": 189340
    },
    {
      "epoch": 304.44,
      "learning_rate": 0.06956884072057877,
      "loss": 2.8893,
      "step": 189360
    },
    {
      "epoch": 304.47,
      "learning_rate": 0.06956562528971062,
      "loss": 2.8639,
      "step": 189380
    },
    {
      "epoch": 304.5,
      "learning_rate": 0.06956240985884245,
      "loss": 2.8595,
      "step": 189400
    },
    {
      "epoch": 304.53,
      "learning_rate": 0.06955919442797429,
      "loss": 2.8319,
      "step": 189420
    },
    {
      "epoch": 304.57,
      "learning_rate": 0.06955597899710612,
      "loss": 2.8703,
      "step": 189440
    },
    {
      "epoch": 304.6,
      "learning_rate": 0.06955276356623794,
      "loss": 2.8473,
      "step": 189460
    },
    {
      "epoch": 304.63,
      "learning_rate": 0.06954954813536979,
      "loss": 2.8477,
      "step": 189480
    },
    {
      "epoch": 304.66,
      "learning_rate": 0.06954633270450161,
      "loss": 2.8535,
      "step": 189500
    },
    {
      "epoch": 304.69,
      "learning_rate": 0.06954311727363345,
      "loss": 2.8497,
      "step": 189520
    },
    {
      "epoch": 304.73,
      "learning_rate": 0.06953990184276528,
      "loss": 2.8407,
      "step": 189540
    },
    {
      "epoch": 304.76,
      "learning_rate": 0.0695366864118971,
      "loss": 2.8468,
      "step": 189560
    },
    {
      "epoch": 304.79,
      "learning_rate": 0.06953347098102895,
      "loss": 2.8731,
      "step": 189580
    },
    {
      "epoch": 304.82,
      "learning_rate": 0.06953025555016078,
      "loss": 2.8349,
      "step": 189600
    },
    {
      "epoch": 304.86,
      "learning_rate": 0.06952704011929262,
      "loss": 2.8707,
      "step": 189620
    },
    {
      "epoch": 304.89,
      "learning_rate": 0.06952382468842444,
      "loss": 2.8586,
      "step": 189640
    },
    {
      "epoch": 304.92,
      "learning_rate": 0.06952060925755627,
      "loss": 2.8784,
      "step": 189660
    },
    {
      "epoch": 304.95,
      "learning_rate": 0.06951739382668812,
      "loss": 2.91,
      "step": 189680
    },
    {
      "epoch": 304.98,
      "learning_rate": 0.06951417839581993,
      "loss": 2.8973,
      "step": 189700
    },
    {
      "epoch": 305.0,
      "eval_accuracy": {
        "accuracy": 0.3902666563010184
      },
      "eval_loss": 2.9948675632476807,
      "eval_runtime": 3.4207,
      "eval_samples_per_second": 3760.357,
      "eval_steps_per_second": 58.76,
      "step": 189710
    },
    {
      "epoch": 305.02,
      "learning_rate": 0.06951096296495178,
      "loss": 2.8777,
      "step": 189720
    },
    {
      "epoch": 305.05,
      "learning_rate": 0.0695077475340836,
      "loss": 2.8554,
      "step": 189740
    },
    {
      "epoch": 305.08,
      "learning_rate": 0.06950453210321543,
      "loss": 2.8562,
      "step": 189760
    },
    {
      "epoch": 305.11,
      "learning_rate": 0.06950131667234728,
      "loss": 2.8607,
      "step": 189780
    },
    {
      "epoch": 305.14,
      "learning_rate": 0.0694981012414791,
      "loss": 2.8992,
      "step": 189800
    },
    {
      "epoch": 305.18,
      "learning_rate": 0.06949488581061095,
      "loss": 2.896,
      "step": 189820
    },
    {
      "epoch": 305.21,
      "learning_rate": 0.06949167037974277,
      "loss": 2.8418,
      "step": 189840
    },
    {
      "epoch": 305.24,
      "learning_rate": 0.0694884549488746,
      "loss": 2.879,
      "step": 189860
    },
    {
      "epoch": 305.27,
      "learning_rate": 0.06948523951800645,
      "loss": 2.8323,
      "step": 189880
    },
    {
      "epoch": 305.31,
      "learning_rate": 0.06948202408713826,
      "loss": 2.8369,
      "step": 189900
    },
    {
      "epoch": 305.34,
      "learning_rate": 0.06947880865627011,
      "loss": 2.8419,
      "step": 189920
    },
    {
      "epoch": 305.37,
      "learning_rate": 0.06947559322540194,
      "loss": 2.8828,
      "step": 189940
    },
    {
      "epoch": 305.4,
      "learning_rate": 0.06947237779453377,
      "loss": 2.8646,
      "step": 189960
    },
    {
      "epoch": 305.43,
      "learning_rate": 0.0694691623636656,
      "loss": 2.8805,
      "step": 189980
    },
    {
      "epoch": 305.47,
      "learning_rate": 0.06946594693279742,
      "loss": 2.881,
      "step": 190000
    },
    {
      "epoch": 305.5,
      "learning_rate": 0.06946273150192928,
      "loss": 2.8696,
      "step": 190020
    },
    {
      "epoch": 305.53,
      "learning_rate": 0.06945951607106109,
      "loss": 2.8862,
      "step": 190040
    },
    {
      "epoch": 305.56,
      "learning_rate": 0.06945630064019294,
      "loss": 2.8836,
      "step": 190060
    },
    {
      "epoch": 305.59,
      "learning_rate": 0.06945308520932476,
      "loss": 2.8806,
      "step": 190080
    },
    {
      "epoch": 305.63,
      "learning_rate": 0.06944986977845659,
      "loss": 2.8904,
      "step": 190100
    },
    {
      "epoch": 305.66,
      "learning_rate": 0.06944665434758844,
      "loss": 2.8824,
      "step": 190120
    },
    {
      "epoch": 305.69,
      "learning_rate": 0.06944343891672025,
      "loss": 2.8837,
      "step": 190140
    },
    {
      "epoch": 305.72,
      "learning_rate": 0.0694402234858521,
      "loss": 2.8644,
      "step": 190160
    },
    {
      "epoch": 305.76,
      "learning_rate": 0.06943700805498393,
      "loss": 2.8871,
      "step": 190180
    },
    {
      "epoch": 305.79,
      "learning_rate": 0.06943379262411575,
      "loss": 2.8709,
      "step": 190200
    },
    {
      "epoch": 305.82,
      "learning_rate": 0.0694305771932476,
      "loss": 2.8943,
      "step": 190220
    },
    {
      "epoch": 305.85,
      "learning_rate": 0.06942736176237942,
      "loss": 2.8879,
      "step": 190240
    },
    {
      "epoch": 305.88,
      "learning_rate": 0.06942414633151127,
      "loss": 2.8658,
      "step": 190260
    },
    {
      "epoch": 305.92,
      "learning_rate": 0.0694209309006431,
      "loss": 2.8313,
      "step": 190280
    },
    {
      "epoch": 305.95,
      "learning_rate": 0.06941771546977492,
      "loss": 2.8827,
      "step": 190300
    },
    {
      "epoch": 305.98,
      "learning_rate": 0.06941450003890676,
      "loss": 2.8911,
      "step": 190320
    },
    {
      "epoch": 306.0,
      "eval_accuracy": {
        "accuracy": 0.3918992458990904
      },
      "eval_loss": 2.948953628540039,
      "eval_runtime": 2.8592,
      "eval_samples_per_second": 4498.825,
      "eval_steps_per_second": 70.3,
      "step": 190332
    },
    {
      "epoch": 306.01,
      "learning_rate": 0.06941128460803858,
      "loss": 2.8517,
      "step": 190340
    },
    {
      "epoch": 306.05,
      "learning_rate": 0.06940806917717043,
      "loss": 2.8503,
      "step": 190360
    },
    {
      "epoch": 306.08,
      "learning_rate": 0.06940485374630224,
      "loss": 2.8458,
      "step": 190380
    },
    {
      "epoch": 306.11,
      "learning_rate": 0.06940163831543408,
      "loss": 2.8613,
      "step": 190400
    },
    {
      "epoch": 306.14,
      "learning_rate": 0.06939842288456592,
      "loss": 2.8694,
      "step": 190420
    },
    {
      "epoch": 306.17,
      "learning_rate": 0.06939520745369775,
      "loss": 2.859,
      "step": 190440
    },
    {
      "epoch": 306.21,
      "learning_rate": 0.0693919920228296,
      "loss": 2.8966,
      "step": 190460
    },
    {
      "epoch": 306.24,
      "learning_rate": 0.06938877659196141,
      "loss": 2.8601,
      "step": 190480
    },
    {
      "epoch": 306.27,
      "learning_rate": 0.06938556116109325,
      "loss": 2.8819,
      "step": 190500
    },
    {
      "epoch": 306.3,
      "learning_rate": 0.06938234573022509,
      "loss": 2.7972,
      "step": 190520
    },
    {
      "epoch": 306.33,
      "learning_rate": 0.06937913029935691,
      "loss": 2.8231,
      "step": 190540
    },
    {
      "epoch": 306.37,
      "learning_rate": 0.06937591486848876,
      "loss": 2.8398,
      "step": 190560
    },
    {
      "epoch": 306.4,
      "learning_rate": 0.06937269943762057,
      "loss": 2.8676,
      "step": 190580
    },
    {
      "epoch": 306.43,
      "learning_rate": 0.06936948400675243,
      "loss": 2.8578,
      "step": 190600
    },
    {
      "epoch": 306.46,
      "learning_rate": 0.06936626857588425,
      "loss": 2.8745,
      "step": 190620
    },
    {
      "epoch": 306.5,
      "learning_rate": 0.06936305314501608,
      "loss": 2.8535,
      "step": 190640
    },
    {
      "epoch": 306.53,
      "learning_rate": 0.06935983771414791,
      "loss": 2.9263,
      "step": 190660
    },
    {
      "epoch": 306.56,
      "learning_rate": 0.06935662228327974,
      "loss": 2.9242,
      "step": 190680
    },
    {
      "epoch": 306.59,
      "learning_rate": 0.06935340685241159,
      "loss": 2.9128,
      "step": 190700
    },
    {
      "epoch": 306.62,
      "learning_rate": 0.0693501914215434,
      "loss": 2.8941,
      "step": 190720
    },
    {
      "epoch": 306.66,
      "learning_rate": 0.06934697599067524,
      "loss": 2.886,
      "step": 190740
    },
    {
      "epoch": 306.69,
      "learning_rate": 0.06934376055980708,
      "loss": 2.8865,
      "step": 190760
    },
    {
      "epoch": 306.72,
      "learning_rate": 0.0693405451289389,
      "loss": 2.9339,
      "step": 190780
    },
    {
      "epoch": 306.75,
      "learning_rate": 0.06933732969807076,
      "loss": 2.8957,
      "step": 190800
    },
    {
      "epoch": 306.78,
      "learning_rate": 0.06933411426720257,
      "loss": 2.881,
      "step": 190820
    },
    {
      "epoch": 306.82,
      "learning_rate": 0.0693308988363344,
      "loss": 2.8838,
      "step": 190840
    },
    {
      "epoch": 306.85,
      "learning_rate": 0.06932768340546624,
      "loss": 2.8331,
      "step": 190860
    },
    {
      "epoch": 306.88,
      "learning_rate": 0.06932446797459807,
      "loss": 2.8603,
      "step": 190880
    },
    {
      "epoch": 306.91,
      "learning_rate": 0.06932125254372992,
      "loss": 2.8516,
      "step": 190900
    },
    {
      "epoch": 306.95,
      "learning_rate": 0.06931803711286173,
      "loss": 2.8601,
      "step": 190920
    },
    {
      "epoch": 306.98,
      "learning_rate": 0.06931482168199357,
      "loss": 2.8659,
      "step": 190940
    },
    {
      "epoch": 307.0,
      "eval_accuracy": {
        "accuracy": 0.382881131928788
      },
      "eval_loss": 2.9753189086914062,
      "eval_runtime": 2.7244,
      "eval_samples_per_second": 4721.343,
      "eval_steps_per_second": 73.777,
      "step": 190954
    },
    {
      "epoch": 307.01,
      "learning_rate": 0.06931160625112541,
      "loss": 2.8893,
      "step": 190960
    },
    {
      "epoch": 307.04,
      "learning_rate": 0.06930839082025723,
      "loss": 2.8897,
      "step": 190980
    },
    {
      "epoch": 307.07,
      "learning_rate": 0.06930517538938907,
      "loss": 2.8771,
      "step": 191000
    },
    {
      "epoch": 307.11,
      "learning_rate": 0.0693019599585209,
      "loss": 2.8391,
      "step": 191020
    },
    {
      "epoch": 307.14,
      "learning_rate": 0.06929874452765274,
      "loss": 2.8611,
      "step": 191040
    },
    {
      "epoch": 307.17,
      "learning_rate": 0.06929552909678456,
      "loss": 2.8443,
      "step": 191060
    },
    {
      "epoch": 307.2,
      "learning_rate": 0.0692923136659164,
      "loss": 2.8271,
      "step": 191080
    },
    {
      "epoch": 307.23,
      "learning_rate": 0.06928909823504824,
      "loss": 2.8489,
      "step": 191100
    },
    {
      "epoch": 307.27,
      "learning_rate": 0.06928588280418006,
      "loss": 2.8411,
      "step": 191120
    },
    {
      "epoch": 307.3,
      "learning_rate": 0.06928266737331192,
      "loss": 2.8081,
      "step": 191140
    },
    {
      "epoch": 307.33,
      "learning_rate": 0.06927945194244373,
      "loss": 2.864,
      "step": 191160
    },
    {
      "epoch": 307.36,
      "learning_rate": 0.06927623651157556,
      "loss": 2.8778,
      "step": 191180
    },
    {
      "epoch": 307.4,
      "learning_rate": 0.0692730210807074,
      "loss": 2.8548,
      "step": 191200
    },
    {
      "epoch": 307.43,
      "learning_rate": 0.06926980564983923,
      "loss": 2.8752,
      "step": 191220
    },
    {
      "epoch": 307.46,
      "learning_rate": 0.06926659021897108,
      "loss": 2.8751,
      "step": 191240
    },
    {
      "epoch": 307.49,
      "learning_rate": 0.06926337478810289,
      "loss": 2.8667,
      "step": 191260
    },
    {
      "epoch": 307.52,
      "learning_rate": 0.06926015935723473,
      "loss": 2.8489,
      "step": 191280
    },
    {
      "epoch": 307.56,
      "learning_rate": 0.06925694392636657,
      "loss": 2.8646,
      "step": 191300
    },
    {
      "epoch": 307.59,
      "learning_rate": 0.06925372849549839,
      "loss": 2.8194,
      "step": 191320
    },
    {
      "epoch": 307.62,
      "learning_rate": 0.06925051306463023,
      "loss": 2.8452,
      "step": 191340
    },
    {
      "epoch": 307.65,
      "learning_rate": 0.06924729763376206,
      "loss": 2.8389,
      "step": 191360
    },
    {
      "epoch": 307.68,
      "learning_rate": 0.0692440822028939,
      "loss": 2.8573,
      "step": 191380
    },
    {
      "epoch": 307.72,
      "learning_rate": 0.06924086677202572,
      "loss": 2.8635,
      "step": 191400
    },
    {
      "epoch": 307.75,
      "learning_rate": 0.06923765134115756,
      "loss": 2.862,
      "step": 191420
    },
    {
      "epoch": 307.78,
      "learning_rate": 0.0692344359102894,
      "loss": 2.8645,
      "step": 191440
    },
    {
      "epoch": 307.81,
      "learning_rate": 0.06923122047942122,
      "loss": 2.893,
      "step": 191460
    },
    {
      "epoch": 307.85,
      "learning_rate": 0.06922816582009647,
      "loss": 2.8476,
      "step": 191480
    },
    {
      "epoch": 307.88,
      "learning_rate": 0.06922495038922831,
      "loss": 2.8963,
      "step": 191500
    },
    {
      "epoch": 307.91,
      "learning_rate": 0.06922173495836013,
      "loss": 2.8715,
      "step": 191520
    },
    {
      "epoch": 307.94,
      "learning_rate": 0.06921851952749197,
      "loss": 2.8694,
      "step": 191540
    },
    {
      "epoch": 307.97,
      "learning_rate": 0.0692153040966238,
      "loss": 2.8735,
      "step": 191560
    },
    {
      "epoch": 308.0,
      "eval_accuracy": {
        "accuracy": 0.38808987017025576
      },
      "eval_loss": 2.9804084300994873,
      "eval_runtime": 3.081,
      "eval_samples_per_second": 4174.992,
      "eval_steps_per_second": 65.239,
      "step": 191576
    },
    {
      "epoch": 308.01,
      "learning_rate": 0.06921208866575564,
      "loss": 2.8559,
      "step": 191580
    },
    {
      "epoch": 308.04,
      "learning_rate": 0.06920887323488746,
      "loss": 2.8488,
      "step": 191600
    },
    {
      "epoch": 308.07,
      "learning_rate": 0.0692056578040193,
      "loss": 2.8695,
      "step": 191620
    },
    {
      "epoch": 308.1,
      "learning_rate": 0.06920244237315114,
      "loss": 2.8604,
      "step": 191640
    },
    {
      "epoch": 308.14,
      "learning_rate": 0.06919922694228296,
      "loss": 2.891,
      "step": 191660
    },
    {
      "epoch": 308.17,
      "learning_rate": 0.0691960115114148,
      "loss": 2.8617,
      "step": 191680
    },
    {
      "epoch": 308.2,
      "learning_rate": 0.06919279608054663,
      "loss": 2.8774,
      "step": 191700
    },
    {
      "epoch": 308.23,
      "learning_rate": 0.06918958064967846,
      "loss": 2.8621,
      "step": 191720
    },
    {
      "epoch": 308.26,
      "learning_rate": 0.0691863652188103,
      "loss": 2.8455,
      "step": 191740
    },
    {
      "epoch": 308.3,
      "learning_rate": 0.06918314978794211,
      "loss": 2.9055,
      "step": 191760
    },
    {
      "epoch": 308.33,
      "learning_rate": 0.06917993435707397,
      "loss": 2.8483,
      "step": 191780
    },
    {
      "epoch": 308.36,
      "learning_rate": 0.06917671892620579,
      "loss": 2.8431,
      "step": 191800
    },
    {
      "epoch": 308.39,
      "learning_rate": 0.06917350349533763,
      "loss": 2.8707,
      "step": 191820
    },
    {
      "epoch": 308.42,
      "learning_rate": 0.06917028806446947,
      "loss": 2.8732,
      "step": 191840
    },
    {
      "epoch": 308.46,
      "learning_rate": 0.06916707263360128,
      "loss": 2.8422,
      "step": 191860
    },
    {
      "epoch": 308.49,
      "learning_rate": 0.06916385720273313,
      "loss": 2.8376,
      "step": 191880
    },
    {
      "epoch": 308.52,
      "learning_rate": 0.06916064177186496,
      "loss": 2.8498,
      "step": 191900
    },
    {
      "epoch": 308.55,
      "learning_rate": 0.0691574263409968,
      "loss": 2.8354,
      "step": 191920
    },
    {
      "epoch": 308.59,
      "learning_rate": 0.06915421091012862,
      "loss": 2.8721,
      "step": 191940
    },
    {
      "epoch": 308.62,
      "learning_rate": 0.06915099547926044,
      "loss": 2.8676,
      "step": 191960
    },
    {
      "epoch": 308.65,
      "learning_rate": 0.0691477800483923,
      "loss": 2.871,
      "step": 191980
    },
    {
      "epoch": 308.68,
      "learning_rate": 0.06914456461752412,
      "loss": 2.867,
      "step": 192000
    },
    {
      "epoch": 308.71,
      "learning_rate": 0.06914134918665596,
      "loss": 2.853,
      "step": 192020
    },
    {
      "epoch": 308.75,
      "learning_rate": 0.06913813375578778,
      "loss": 2.8586,
      "step": 192040
    },
    {
      "epoch": 308.78,
      "learning_rate": 0.06913491832491961,
      "loss": 2.8883,
      "step": 192060
    },
    {
      "epoch": 308.81,
      "learning_rate": 0.06913170289405146,
      "loss": 2.8755,
      "step": 192080
    },
    {
      "epoch": 308.84,
      "learning_rate": 0.06912848746318327,
      "loss": 2.8758,
      "step": 192100
    },
    {
      "epoch": 308.87,
      "learning_rate": 0.06912527203231512,
      "loss": 2.8624,
      "step": 192120
    },
    {
      "epoch": 308.91,
      "learning_rate": 0.06912205660144695,
      "loss": 2.8555,
      "step": 192140
    },
    {
      "epoch": 308.94,
      "learning_rate": 0.06911884117057879,
      "loss": 2.8516,
      "step": 192160
    },
    {
      "epoch": 308.97,
      "learning_rate": 0.06911562573971063,
      "loss": 2.88,
      "step": 192180
    },
    {
      "epoch": 309.0,
      "eval_accuracy": {
        "accuracy": 0.3948534556479826
      },
      "eval_loss": 2.9284119606018066,
      "eval_runtime": 3.1959,
      "eval_samples_per_second": 4024.883,
      "eval_steps_per_second": 62.894,
      "step": 192198
    },
    {
      "epoch": 309.0,
      "learning_rate": 0.06911241030884244,
      "loss": 2.8581,
      "step": 192200
    },
    {
      "epoch": 309.04,
      "learning_rate": 0.06910919487797429,
      "loss": 2.8585,
      "step": 192220
    },
    {
      "epoch": 309.07,
      "learning_rate": 0.06910597944710611,
      "loss": 2.8775,
      "step": 192240
    },
    {
      "epoch": 309.1,
      "learning_rate": 0.06910276401623795,
      "loss": 2.8562,
      "step": 192260
    },
    {
      "epoch": 309.13,
      "learning_rate": 0.06909954858536978,
      "loss": 2.8816,
      "step": 192280
    },
    {
      "epoch": 309.16,
      "learning_rate": 0.0690963331545016,
      "loss": 2.8761,
      "step": 192300
    },
    {
      "epoch": 309.2,
      "learning_rate": 0.06909311772363345,
      "loss": 2.8808,
      "step": 192320
    },
    {
      "epoch": 309.23,
      "learning_rate": 0.06908990229276528,
      "loss": 2.8786,
      "step": 192340
    },
    {
      "epoch": 309.26,
      "learning_rate": 0.06908668686189712,
      "loss": 2.8613,
      "step": 192360
    },
    {
      "epoch": 309.29,
      "learning_rate": 0.06908347143102894,
      "loss": 2.8704,
      "step": 192380
    },
    {
      "epoch": 309.32,
      "learning_rate": 0.06908025600016077,
      "loss": 2.8539,
      "step": 192400
    },
    {
      "epoch": 309.36,
      "learning_rate": 0.06907704056929262,
      "loss": 2.8739,
      "step": 192420
    },
    {
      "epoch": 309.39,
      "learning_rate": 0.06907382513842443,
      "loss": 2.8212,
      "step": 192440
    },
    {
      "epoch": 309.42,
      "learning_rate": 0.06907060970755628,
      "loss": 2.8471,
      "step": 192460
    },
    {
      "epoch": 309.45,
      "learning_rate": 0.06906739427668811,
      "loss": 2.8278,
      "step": 192480
    },
    {
      "epoch": 309.49,
      "learning_rate": 0.06906417884581993,
      "loss": 2.8643,
      "step": 192500
    },
    {
      "epoch": 309.52,
      "learning_rate": 0.06906096341495178,
      "loss": 2.8532,
      "step": 192520
    },
    {
      "epoch": 309.55,
      "learning_rate": 0.0690577479840836,
      "loss": 2.8652,
      "step": 192540
    },
    {
      "epoch": 309.58,
      "learning_rate": 0.06905453255321545,
      "loss": 2.8788,
      "step": 192560
    },
    {
      "epoch": 309.61,
      "learning_rate": 0.06905131712234727,
      "loss": 2.8742,
      "step": 192580
    },
    {
      "epoch": 309.65,
      "learning_rate": 0.0690481016914791,
      "loss": 2.8677,
      "step": 192600
    },
    {
      "epoch": 309.68,
      "learning_rate": 0.06904488626061095,
      "loss": 2.8318,
      "step": 192620
    },
    {
      "epoch": 309.71,
      "learning_rate": 0.06904167082974276,
      "loss": 2.8582,
      "step": 192640
    },
    {
      "epoch": 309.74,
      "learning_rate": 0.06903845539887461,
      "loss": 2.8488,
      "step": 192660
    },
    {
      "epoch": 309.77,
      "learning_rate": 0.06903523996800644,
      "loss": 2.8762,
      "step": 192680
    },
    {
      "epoch": 309.81,
      "learning_rate": 0.06903202453713826,
      "loss": 2.8462,
      "step": 192700
    },
    {
      "epoch": 309.84,
      "learning_rate": 0.0690288091062701,
      "loss": 2.837,
      "step": 192720
    },
    {
      "epoch": 309.87,
      "learning_rate": 0.06902559367540193,
      "loss": 2.8438,
      "step": 192740
    },
    {
      "epoch": 309.9,
      "learning_rate": 0.06902237824453378,
      "loss": 2.8744,
      "step": 192760
    },
    {
      "epoch": 309.94,
      "learning_rate": 0.06901916281366559,
      "loss": 2.9035,
      "step": 192780
    },
    {
      "epoch": 309.97,
      "learning_rate": 0.06901594738279744,
      "loss": 2.9079,
      "step": 192800
    },
    {
      "epoch": 310.0,
      "learning_rate": 0.06901273195192927,
      "loss": 2.8748,
      "step": 192820
    },
    {
      "epoch": 310.0,
      "eval_accuracy": {
        "accuracy": 0.3875456736375651
      },
      "eval_loss": 2.9813907146453857,
      "eval_runtime": 2.6759,
      "eval_samples_per_second": 4806.921,
      "eval_steps_per_second": 75.114,
      "step": 192820
    },
    {
      "epoch": 310.03,
      "learning_rate": 0.06900951652106109,
      "loss": 2.834,
      "step": 192840
    },
    {
      "epoch": 310.06,
      "learning_rate": 0.06900630109019294,
      "loss": 2.8621,
      "step": 192860
    },
    {
      "epoch": 310.1,
      "learning_rate": 0.06900308565932475,
      "loss": 2.8633,
      "step": 192880
    },
    {
      "epoch": 310.13,
      "learning_rate": 0.0689998702284566,
      "loss": 2.8413,
      "step": 192900
    },
    {
      "epoch": 310.16,
      "learning_rate": 0.06899665479758843,
      "loss": 2.8803,
      "step": 192920
    },
    {
      "epoch": 310.19,
      "learning_rate": 0.06899343936672026,
      "loss": 2.8898,
      "step": 192940
    },
    {
      "epoch": 310.23,
      "learning_rate": 0.06899022393585211,
      "loss": 2.8767,
      "step": 192960
    },
    {
      "epoch": 310.26,
      "learning_rate": 0.06898700850498392,
      "loss": 2.8242,
      "step": 192980
    },
    {
      "epoch": 310.29,
      "learning_rate": 0.06898379307411577,
      "loss": 2.8561,
      "step": 193000
    },
    {
      "epoch": 310.32,
      "learning_rate": 0.0689805776432476,
      "loss": 2.8479,
      "step": 193020
    },
    {
      "epoch": 310.35,
      "learning_rate": 0.06897736221237942,
      "loss": 2.8713,
      "step": 193040
    },
    {
      "epoch": 310.39,
      "learning_rate": 0.06897414678151126,
      "loss": 2.8692,
      "step": 193060
    },
    {
      "epoch": 310.42,
      "learning_rate": 0.06897093135064308,
      "loss": 2.8262,
      "step": 193080
    },
    {
      "epoch": 310.45,
      "learning_rate": 0.06896771591977494,
      "loss": 2.8589,
      "step": 193100
    },
    {
      "epoch": 310.48,
      "learning_rate": 0.06896450048890675,
      "loss": 2.8346,
      "step": 193120
    },
    {
      "epoch": 310.51,
      "learning_rate": 0.06896128505803858,
      "loss": 2.8756,
      "step": 193140
    },
    {
      "epoch": 310.55,
      "learning_rate": 0.06895806962717042,
      "loss": 2.87,
      "step": 193160
    },
    {
      "epoch": 310.58,
      "learning_rate": 0.06895485419630225,
      "loss": 2.8569,
      "step": 193180
    },
    {
      "epoch": 310.61,
      "learning_rate": 0.0689516387654341,
      "loss": 2.8675,
      "step": 193200
    },
    {
      "epoch": 310.64,
      "learning_rate": 0.06894842333456591,
      "loss": 2.8697,
      "step": 193220
    },
    {
      "epoch": 310.68,
      "learning_rate": 0.06894520790369775,
      "loss": 2.8733,
      "step": 193240
    },
    {
      "epoch": 310.71,
      "learning_rate": 0.06894199247282959,
      "loss": 2.8785,
      "step": 193260
    },
    {
      "epoch": 310.74,
      "learning_rate": 0.06893877704196141,
      "loss": 2.8371,
      "step": 193280
    },
    {
      "epoch": 310.77,
      "learning_rate": 0.06893556161109327,
      "loss": 2.8399,
      "step": 193300
    },
    {
      "epoch": 310.8,
      "learning_rate": 0.06893234618022508,
      "loss": 2.8311,
      "step": 193320
    },
    {
      "epoch": 310.84,
      "learning_rate": 0.06892913074935693,
      "loss": 2.8353,
      "step": 193340
    },
    {
      "epoch": 310.87,
      "learning_rate": 0.06892591531848875,
      "loss": 2.794,
      "step": 193360
    },
    {
      "epoch": 310.9,
      "learning_rate": 0.06892269988762058,
      "loss": 2.8743,
      "step": 193380
    },
    {
      "epoch": 310.93,
      "learning_rate": 0.06891948445675242,
      "loss": 2.8942,
      "step": 193400
    },
    {
      "epoch": 310.96,
      "learning_rate": 0.06891626902588424,
      "loss": 2.8826,
      "step": 193420
    },
    {
      "epoch": 311.0,
      "learning_rate": 0.0689130535950161,
      "loss": 2.8837,
      "step": 193440
    },
    {
      "epoch": 311.0,
      "eval_accuracy": {
        "accuracy": 0.39609733343698983
      },
      "eval_loss": 2.962502956390381,
      "eval_runtime": 2.78,
      "eval_samples_per_second": 4627.049,
      "eval_steps_per_second": 72.303,
      "step": 193442
    },
    {
      "epoch": 311.03,
      "learning_rate": 0.0689098381641479,
      "loss": 2.8276,
      "step": 193460
    },
    {
      "epoch": 311.06,
      "learning_rate": 0.06890662273327974,
      "loss": 2.8473,
      "step": 193480
    },
    {
      "epoch": 311.09,
      "learning_rate": 0.068903568073955,
      "loss": 2.811,
      "step": 193500
    },
    {
      "epoch": 311.13,
      "learning_rate": 0.06890035264308682,
      "loss": 2.8458,
      "step": 193520
    },
    {
      "epoch": 311.16,
      "learning_rate": 0.06889713721221866,
      "loss": 2.858,
      "step": 193540
    },
    {
      "epoch": 311.19,
      "learning_rate": 0.0688939217813505,
      "loss": 2.8369,
      "step": 193560
    },
    {
      "epoch": 311.22,
      "learning_rate": 0.06889070635048232,
      "loss": 2.8546,
      "step": 193580
    },
    {
      "epoch": 311.25,
      "learning_rate": 0.06888749091961416,
      "loss": 2.852,
      "step": 193600
    },
    {
      "epoch": 311.29,
      "learning_rate": 0.06888427548874598,
      "loss": 2.8551,
      "step": 193620
    },
    {
      "epoch": 311.32,
      "learning_rate": 0.06888106005787782,
      "loss": 2.855,
      "step": 193640
    },
    {
      "epoch": 311.35,
      "learning_rate": 0.06887784462700965,
      "loss": 2.8551,
      "step": 193660
    },
    {
      "epoch": 311.38,
      "learning_rate": 0.06887462919614148,
      "loss": 2.8457,
      "step": 193680
    },
    {
      "epoch": 311.41,
      "learning_rate": 0.06887141376527332,
      "loss": 2.8699,
      "step": 193700
    },
    {
      "epoch": 311.45,
      "learning_rate": 0.06886819833440515,
      "loss": 2.8637,
      "step": 193720
    },
    {
      "epoch": 311.48,
      "learning_rate": 0.06886498290353699,
      "loss": 2.8716,
      "step": 193740
    },
    {
      "epoch": 311.51,
      "learning_rate": 0.06886176747266881,
      "loss": 2.8789,
      "step": 193760
    },
    {
      "epoch": 311.54,
      "learning_rate": 0.06885855204180065,
      "loss": 2.8644,
      "step": 193780
    },
    {
      "epoch": 311.58,
      "learning_rate": 0.06885533661093249,
      "loss": 2.8662,
      "step": 193800
    },
    {
      "epoch": 311.61,
      "learning_rate": 0.06885212118006431,
      "loss": 2.9031,
      "step": 193820
    },
    {
      "epoch": 311.64,
      "learning_rate": 0.06884890574919615,
      "loss": 2.8565,
      "step": 193840
    },
    {
      "epoch": 311.67,
      "learning_rate": 0.06884569031832798,
      "loss": 2.863,
      "step": 193860
    },
    {
      "epoch": 311.7,
      "learning_rate": 0.06884247488745981,
      "loss": 2.8562,
      "step": 193880
    },
    {
      "epoch": 311.74,
      "learning_rate": 0.06883925945659165,
      "loss": 2.8788,
      "step": 193900
    },
    {
      "epoch": 311.77,
      "learning_rate": 0.06883604402572348,
      "loss": 2.8981,
      "step": 193920
    },
    {
      "epoch": 311.8,
      "learning_rate": 0.06883282859485532,
      "loss": 2.8779,
      "step": 193940
    },
    {
      "epoch": 311.83,
      "learning_rate": 0.06882961316398714,
      "loss": 2.8691,
      "step": 193960
    },
    {
      "epoch": 311.86,
      "learning_rate": 0.06882639773311898,
      "loss": 2.8416,
      "step": 193980
    },
    {
      "epoch": 311.9,
      "learning_rate": 0.0688231823022508,
      "loss": 2.9111,
      "step": 194000
    },
    {
      "epoch": 311.93,
      "learning_rate": 0.06881996687138264,
      "loss": 2.8951,
      "step": 194020
    },
    {
      "epoch": 311.96,
      "learning_rate": 0.06881675144051448,
      "loss": 2.8285,
      "step": 194040
    },
    {
      "epoch": 311.99,
      "learning_rate": 0.0688135360096463,
      "loss": 2.8713,
      "step": 194060
    },
    {
      "epoch": 312.0,
      "eval_accuracy": {
        "accuracy": 0.38521340278317656
      },
      "eval_loss": 2.9764223098754883,
      "eval_runtime": 2.8328,
      "eval_samples_per_second": 4540.698,
      "eval_steps_per_second": 70.954,
      "step": 194064
    },
    {
      "epoch": 312.03,
      "learning_rate": 0.06881032057877814,
      "loss": 2.891,
      "step": 194080
    },
    {
      "epoch": 312.06,
      "learning_rate": 0.06880710514790997,
      "loss": 2.8505,
      "step": 194100
    },
    {
      "epoch": 312.09,
      "learning_rate": 0.06880388971704181,
      "loss": 2.8359,
      "step": 194120
    },
    {
      "epoch": 312.12,
      "learning_rate": 0.06880067428617365,
      "loss": 2.825,
      "step": 194140
    },
    {
      "epoch": 312.15,
      "learning_rate": 0.06879745885530546,
      "loss": 2.8343,
      "step": 194160
    },
    {
      "epoch": 312.19,
      "learning_rate": 0.06879424342443731,
      "loss": 2.8891,
      "step": 194180
    },
    {
      "epoch": 312.22,
      "learning_rate": 0.06879102799356913,
      "loss": 2.8343,
      "step": 194200
    },
    {
      "epoch": 312.25,
      "learning_rate": 0.06878781256270097,
      "loss": 2.8671,
      "step": 194220
    },
    {
      "epoch": 312.28,
      "learning_rate": 0.06878459713183281,
      "loss": 2.849,
      "step": 194240
    },
    {
      "epoch": 312.32,
      "learning_rate": 0.06878138170096462,
      "loss": 2.866,
      "step": 194260
    },
    {
      "epoch": 312.35,
      "learning_rate": 0.06877816627009647,
      "loss": 2.8801,
      "step": 194280
    },
    {
      "epoch": 312.38,
      "learning_rate": 0.0687749508392283,
      "loss": 2.8526,
      "step": 194300
    },
    {
      "epoch": 312.41,
      "learning_rate": 0.06877173540836014,
      "loss": 2.8298,
      "step": 194320
    },
    {
      "epoch": 312.44,
      "learning_rate": 0.06876851997749196,
      "loss": 2.8142,
      "step": 194340
    },
    {
      "epoch": 312.48,
      "learning_rate": 0.0687653045466238,
      "loss": 2.8474,
      "step": 194360
    },
    {
      "epoch": 312.51,
      "learning_rate": 0.06876208911575564,
      "loss": 2.8745,
      "step": 194380
    },
    {
      "epoch": 312.54,
      "learning_rate": 0.06875887368488746,
      "loss": 2.8715,
      "step": 194400
    },
    {
      "epoch": 312.57,
      "learning_rate": 0.0687556582540193,
      "loss": 2.8829,
      "step": 194420
    },
    {
      "epoch": 312.6,
      "learning_rate": 0.06875244282315113,
      "loss": 2.8409,
      "step": 194440
    },
    {
      "epoch": 312.64,
      "learning_rate": 0.06874922739228297,
      "loss": 2.8669,
      "step": 194460
    },
    {
      "epoch": 312.67,
      "learning_rate": 0.0687460119614148,
      "loss": 2.9015,
      "step": 194480
    },
    {
      "epoch": 312.7,
      "learning_rate": 0.06874279653054662,
      "loss": 2.8857,
      "step": 194500
    },
    {
      "epoch": 312.73,
      "learning_rate": 0.06873958109967847,
      "loss": 2.8929,
      "step": 194520
    },
    {
      "epoch": 312.77,
      "learning_rate": 0.06873636566881029,
      "loss": 2.8607,
      "step": 194540
    },
    {
      "epoch": 312.8,
      "learning_rate": 0.06873315023794213,
      "loss": 2.8727,
      "step": 194560
    },
    {
      "epoch": 312.83,
      "learning_rate": 0.06872993480707397,
      "loss": 2.881,
      "step": 194580
    },
    {
      "epoch": 312.86,
      "learning_rate": 0.06872671937620578,
      "loss": 2.8563,
      "step": 194600
    },
    {
      "epoch": 312.89,
      "learning_rate": 0.06872350394533763,
      "loss": 2.8912,
      "step": 194620
    },
    {
      "epoch": 312.93,
      "learning_rate": 0.06872028851446946,
      "loss": 2.8774,
      "step": 194640
    },
    {
      "epoch": 312.96,
      "learning_rate": 0.0687170730836013,
      "loss": 2.8598,
      "step": 194660
    },
    {
      "epoch": 312.99,
      "learning_rate": 0.06871385765273312,
      "loss": 2.8531,
      "step": 194680
    },
    {
      "epoch": 313.0,
      "eval_accuracy": {
        "accuracy": 0.3803933763507735
      },
      "eval_loss": 3.0065364837646484,
      "eval_runtime": 3.1199,
      "eval_samples_per_second": 4122.9,
      "eval_steps_per_second": 64.425,
      "step": 194686
    },
    {
      "epoch": 313.02,
      "learning_rate": 0.06871064222186495,
      "loss": 2.859,
      "step": 194700
    },
    {
      "epoch": 313.05,
      "learning_rate": 0.0687074267909968,
      "loss": 2.8677,
      "step": 194720
    },
    {
      "epoch": 313.09,
      "learning_rate": 0.06870421136012862,
      "loss": 2.8386,
      "step": 194740
    },
    {
      "epoch": 313.12,
      "learning_rate": 0.06870099592926046,
      "loss": 2.8671,
      "step": 194760
    },
    {
      "epoch": 313.15,
      "learning_rate": 0.06869778049839229,
      "loss": 2.8421,
      "step": 194780
    },
    {
      "epoch": 313.18,
      "learning_rate": 0.06869456506752411,
      "loss": 2.8538,
      "step": 194800
    },
    {
      "epoch": 313.22,
      "learning_rate": 0.06869134963665596,
      "loss": 2.8666,
      "step": 194820
    },
    {
      "epoch": 313.25,
      "learning_rate": 0.06868813420578777,
      "loss": 2.8898,
      "step": 194840
    },
    {
      "epoch": 313.28,
      "learning_rate": 0.06868491877491963,
      "loss": 2.8543,
      "step": 194860
    },
    {
      "epoch": 313.31,
      "learning_rate": 0.06868170334405145,
      "loss": 2.8585,
      "step": 194880
    },
    {
      "epoch": 313.34,
      "learning_rate": 0.06867848791318329,
      "loss": 2.8699,
      "step": 194900
    },
    {
      "epoch": 313.38,
      "learning_rate": 0.06867527248231513,
      "loss": 2.8628,
      "step": 194920
    },
    {
      "epoch": 313.41,
      "learning_rate": 0.06867205705144694,
      "loss": 2.8733,
      "step": 194940
    },
    {
      "epoch": 313.44,
      "learning_rate": 0.06866884162057879,
      "loss": 2.8588,
      "step": 194960
    },
    {
      "epoch": 313.47,
      "learning_rate": 0.06866562618971062,
      "loss": 2.8665,
      "step": 194980
    },
    {
      "epoch": 313.5,
      "learning_rate": 0.06866241075884245,
      "loss": 2.8579,
      "step": 195000
    },
    {
      "epoch": 313.54,
      "learning_rate": 0.06865919532797429,
      "loss": 2.8517,
      "step": 195020
    },
    {
      "epoch": 313.57,
      "learning_rate": 0.0686559798971061,
      "loss": 2.842,
      "step": 195040
    },
    {
      "epoch": 313.6,
      "learning_rate": 0.06865276446623796,
      "loss": 2.8664,
      "step": 195060
    },
    {
      "epoch": 313.63,
      "learning_rate": 0.06864954903536978,
      "loss": 2.8487,
      "step": 195080
    },
    {
      "epoch": 313.67,
      "learning_rate": 0.06864633360450162,
      "loss": 2.8774,
      "step": 195100
    },
    {
      "epoch": 313.7,
      "learning_rate": 0.06864311817363344,
      "loss": 2.8502,
      "step": 195120
    },
    {
      "epoch": 313.73,
      "learning_rate": 0.06863990274276527,
      "loss": 2.8317,
      "step": 195140
    },
    {
      "epoch": 313.76,
      "learning_rate": 0.06863668731189712,
      "loss": 2.8085,
      "step": 195160
    },
    {
      "epoch": 313.79,
      "learning_rate": 0.06863347188102893,
      "loss": 2.842,
      "step": 195180
    },
    {
      "epoch": 313.83,
      "learning_rate": 0.06863025645016078,
      "loss": 2.8397,
      "step": 195200
    },
    {
      "epoch": 313.86,
      "learning_rate": 0.06862704101929261,
      "loss": 2.8667,
      "step": 195220
    },
    {
      "epoch": 313.89,
      "learning_rate": 0.06862382558842443,
      "loss": 2.8515,
      "step": 195240
    },
    {
      "epoch": 313.92,
      "learning_rate": 0.06862061015755629,
      "loss": 2.8542,
      "step": 195260
    },
    {
      "epoch": 313.95,
      "learning_rate": 0.0686173947266881,
      "loss": 2.8569,
      "step": 195280
    },
    {
      "epoch": 313.99,
      "learning_rate": 0.06861417929581995,
      "loss": 2.8209,
      "step": 195300
    },
    {
      "epoch": 314.0,
      "eval_accuracy": {
        "accuracy": 0.39990670916582444
      },
      "eval_loss": 2.879652500152588,
      "eval_runtime": 2.9591,
      "eval_samples_per_second": 4346.893,
      "eval_steps_per_second": 67.925,
      "step": 195308
    },
    {
      "epoch": 314.02,
      "learning_rate": 0.06861096386495177,
      "loss": 2.8453,
      "step": 195320
    },
    {
      "epoch": 314.05,
      "learning_rate": 0.0686077484340836,
      "loss": 2.8273,
      "step": 195340
    },
    {
      "epoch": 314.08,
      "learning_rate": 0.06860453300321545,
      "loss": 2.8321,
      "step": 195360
    },
    {
      "epoch": 314.12,
      "learning_rate": 0.06860131757234726,
      "loss": 2.8715,
      "step": 195380
    },
    {
      "epoch": 314.15,
      "learning_rate": 0.06859810214147911,
      "loss": 2.8741,
      "step": 195400
    },
    {
      "epoch": 314.18,
      "learning_rate": 0.06859488671061094,
      "loss": 2.8926,
      "step": 195420
    },
    {
      "epoch": 314.21,
      "learning_rate": 0.06859167127974276,
      "loss": 2.8529,
      "step": 195440
    },
    {
      "epoch": 314.24,
      "learning_rate": 0.0685884558488746,
      "loss": 2.8834,
      "step": 195460
    },
    {
      "epoch": 314.28,
      "learning_rate": 0.06858524041800643,
      "loss": 2.8616,
      "step": 195480
    },
    {
      "epoch": 314.31,
      "learning_rate": 0.06858202498713828,
      "loss": 2.8586,
      "step": 195500
    },
    {
      "epoch": 314.34,
      "learning_rate": 0.06857880955627009,
      "loss": 2.8195,
      "step": 195520
    },
    {
      "epoch": 314.37,
      "learning_rate": 0.06857559412540194,
      "loss": 2.832,
      "step": 195540
    },
    {
      "epoch": 314.41,
      "learning_rate": 0.06857237869453377,
      "loss": 2.894,
      "step": 195560
    },
    {
      "epoch": 314.44,
      "learning_rate": 0.068569324035209,
      "loss": 2.8723,
      "step": 195580
    },
    {
      "epoch": 314.47,
      "learning_rate": 0.06856610860434084,
      "loss": 2.827,
      "step": 195600
    },
    {
      "epoch": 314.5,
      "learning_rate": 0.06856289317347268,
      "loss": 2.8522,
      "step": 195620
    },
    {
      "epoch": 314.53,
      "learning_rate": 0.0685596777426045,
      "loss": 2.8845,
      "step": 195640
    },
    {
      "epoch": 314.57,
      "learning_rate": 0.06855646231173634,
      "loss": 2.8909,
      "step": 195660
    },
    {
      "epoch": 314.6,
      "learning_rate": 0.06855324688086817,
      "loss": 2.8427,
      "step": 195680
    },
    {
      "epoch": 314.63,
      "learning_rate": 0.06855003145,
      "loss": 2.8457,
      "step": 195700
    },
    {
      "epoch": 314.66,
      "learning_rate": 0.06854681601913183,
      "loss": 2.8548,
      "step": 195720
    },
    {
      "epoch": 314.69,
      "learning_rate": 0.06854360058826367,
      "loss": 2.8797,
      "step": 195740
    },
    {
      "epoch": 314.73,
      "learning_rate": 0.06854038515739551,
      "loss": 2.8375,
      "step": 195760
    },
    {
      "epoch": 314.76,
      "learning_rate": 0.06853716972652733,
      "loss": 2.8288,
      "step": 195780
    },
    {
      "epoch": 314.79,
      "learning_rate": 0.06853395429565917,
      "loss": 2.8566,
      "step": 195800
    },
    {
      "epoch": 314.82,
      "learning_rate": 0.068530738864791,
      "loss": 2.8547,
      "step": 195820
    },
    {
      "epoch": 314.86,
      "learning_rate": 0.06852752343392284,
      "loss": 2.8479,
      "step": 195840
    },
    {
      "epoch": 314.89,
      "learning_rate": 0.06852430800305467,
      "loss": 2.8788,
      "step": 195860
    },
    {
      "epoch": 314.92,
      "learning_rate": 0.0685210925721865,
      "loss": 2.8581,
      "step": 195880
    },
    {
      "epoch": 314.95,
      "learning_rate": 0.06851787714131834,
      "loss": 2.8519,
      "step": 195900
    },
    {
      "epoch": 314.98,
      "learning_rate": 0.06851466171045016,
      "loss": 2.8427,
      "step": 195920
    },
    {
      "epoch": 315.0,
      "eval_accuracy": {
        "accuracy": 0.3873901889139392
      },
      "eval_loss": 2.985778331756592,
      "eval_runtime": 2.8386,
      "eval_samples_per_second": 4531.468,
      "eval_steps_per_second": 70.81,
      "step": 195930
    },
    {
      "epoch": 315.02,
      "learning_rate": 0.068511446279582,
      "loss": 2.8398,
      "step": 195940
    },
    {
      "epoch": 315.05,
      "learning_rate": 0.06850823084871384,
      "loss": 2.8551,
      "step": 195960
    },
    {
      "epoch": 315.08,
      "learning_rate": 0.06850501541784566,
      "loss": 2.8366,
      "step": 195980
    },
    {
      "epoch": 315.11,
      "learning_rate": 0.0685017999869775,
      "loss": 2.8446,
      "step": 196000
    },
    {
      "epoch": 315.14,
      "learning_rate": 0.06849858455610933,
      "loss": 2.8343,
      "step": 196020
    },
    {
      "epoch": 315.18,
      "learning_rate": 0.06849536912524117,
      "loss": 2.8692,
      "step": 196040
    },
    {
      "epoch": 315.21,
      "learning_rate": 0.06849215369437299,
      "loss": 2.8686,
      "step": 196060
    },
    {
      "epoch": 315.24,
      "learning_rate": 0.06848893826350483,
      "loss": 2.8392,
      "step": 196080
    },
    {
      "epoch": 315.27,
      "learning_rate": 0.06848572283263667,
      "loss": 2.867,
      "step": 196100
    },
    {
      "epoch": 315.31,
      "learning_rate": 0.06848250740176849,
      "loss": 2.8386,
      "step": 196120
    },
    {
      "epoch": 315.34,
      "learning_rate": 0.06847929197090033,
      "loss": 2.8477,
      "step": 196140
    },
    {
      "epoch": 315.37,
      "learning_rate": 0.06847607654003215,
      "loss": 2.85,
      "step": 196160
    },
    {
      "epoch": 315.4,
      "learning_rate": 0.068472861109164,
      "loss": 2.8617,
      "step": 196180
    },
    {
      "epoch": 315.43,
      "learning_rate": 0.06846964567829583,
      "loss": 2.8388,
      "step": 196200
    },
    {
      "epoch": 315.47,
      "learning_rate": 0.06846643024742766,
      "loss": 2.8276,
      "step": 196220
    },
    {
      "epoch": 315.5,
      "learning_rate": 0.0684632148165595,
      "loss": 2.8474,
      "step": 196240
    },
    {
      "epoch": 315.53,
      "learning_rate": 0.06845999938569132,
      "loss": 2.8579,
      "step": 196260
    },
    {
      "epoch": 315.56,
      "learning_rate": 0.06845678395482316,
      "loss": 2.8657,
      "step": 196280
    },
    {
      "epoch": 315.59,
      "learning_rate": 0.068453568523955,
      "loss": 2.8618,
      "step": 196300
    },
    {
      "epoch": 315.63,
      "learning_rate": 0.06845035309308682,
      "loss": 2.8689,
      "step": 196320
    },
    {
      "epoch": 315.66,
      "learning_rate": 0.06844713766221866,
      "loss": 2.8358,
      "step": 196340
    },
    {
      "epoch": 315.69,
      "learning_rate": 0.06844392223135048,
      "loss": 2.8491,
      "step": 196360
    },
    {
      "epoch": 315.72,
      "learning_rate": 0.06844070680048232,
      "loss": 2.872,
      "step": 196380
    },
    {
      "epoch": 315.76,
      "learning_rate": 0.06843749136961415,
      "loss": 2.866,
      "step": 196400
    },
    {
      "epoch": 315.79,
      "learning_rate": 0.06843427593874599,
      "loss": 2.8583,
      "step": 196420
    },
    {
      "epoch": 315.82,
      "learning_rate": 0.06843106050787783,
      "loss": 2.8414,
      "step": 196440
    },
    {
      "epoch": 315.85,
      "learning_rate": 0.06842784507700964,
      "loss": 2.8572,
      "step": 196460
    },
    {
      "epoch": 315.88,
      "learning_rate": 0.06842462964614149,
      "loss": 2.8522,
      "step": 196480
    },
    {
      "epoch": 315.92,
      "learning_rate": 0.06842141421527331,
      "loss": 2.8663,
      "step": 196500
    },
    {
      "epoch": 315.95,
      "learning_rate": 0.06841819878440515,
      "loss": 2.8497,
      "step": 196520
    },
    {
      "epoch": 315.98,
      "learning_rate": 0.06841498335353699,
      "loss": 2.8419,
      "step": 196540
    },
    {
      "epoch": 316.0,
      "eval_accuracy": {
        "accuracy": 0.39252118479359405
      },
      "eval_loss": 2.9652419090270996,
      "eval_runtime": 2.8362,
      "eval_samples_per_second": 4535.309,
      "eval_steps_per_second": 70.87,
      "step": 196552
    },
    {
      "epoch": 316.01,
      "learning_rate": 0.06841176792266881,
      "loss": 2.8537,
      "step": 196560
    },
    {
      "epoch": 316.05,
      "learning_rate": 0.06840855249180065,
      "loss": 2.8779,
      "step": 196580
    },
    {
      "epoch": 316.08,
      "learning_rate": 0.06840533706093248,
      "loss": 2.8338,
      "step": 196600
    },
    {
      "epoch": 316.11,
      "learning_rate": 0.06840212163006432,
      "loss": 2.8316,
      "step": 196620
    },
    {
      "epoch": 316.14,
      "learning_rate": 0.06839890619919615,
      "loss": 2.8273,
      "step": 196640
    },
    {
      "epoch": 316.17,
      "learning_rate": 0.06839569076832798,
      "loss": 2.8714,
      "step": 196660
    },
    {
      "epoch": 316.21,
      "learning_rate": 0.06839247533745982,
      "loss": 2.8423,
      "step": 196680
    },
    {
      "epoch": 316.24,
      "learning_rate": 0.06838925990659164,
      "loss": 2.8637,
      "step": 196700
    },
    {
      "epoch": 316.27,
      "learning_rate": 0.06838604447572348,
      "loss": 2.85,
      "step": 196720
    },
    {
      "epoch": 316.3,
      "learning_rate": 0.0683828290448553,
      "loss": 2.8261,
      "step": 196740
    },
    {
      "epoch": 316.33,
      "learning_rate": 0.06837961361398714,
      "loss": 2.8587,
      "step": 196760
    },
    {
      "epoch": 316.37,
      "learning_rate": 0.06837639818311898,
      "loss": 2.8804,
      "step": 196780
    },
    {
      "epoch": 316.4,
      "learning_rate": 0.06837318275225081,
      "loss": 2.8292,
      "step": 196800
    },
    {
      "epoch": 316.43,
      "learning_rate": 0.06836996732138265,
      "loss": 2.8446,
      "step": 196820
    },
    {
      "epoch": 316.46,
      "learning_rate": 0.06836675189051447,
      "loss": 2.8489,
      "step": 196840
    },
    {
      "epoch": 316.5,
      "learning_rate": 0.06836353645964631,
      "loss": 2.8598,
      "step": 196860
    },
    {
      "epoch": 316.53,
      "learning_rate": 0.06836032102877815,
      "loss": 2.8106,
      "step": 196880
    },
    {
      "epoch": 316.56,
      "learning_rate": 0.06835710559790996,
      "loss": 2.8464,
      "step": 196900
    },
    {
      "epoch": 316.59,
      "learning_rate": 0.06835389016704181,
      "loss": 2.8538,
      "step": 196920
    },
    {
      "epoch": 316.62,
      "learning_rate": 0.06835067473617364,
      "loss": 2.836,
      "step": 196940
    },
    {
      "epoch": 316.66,
      "learning_rate": 0.06834745930530547,
      "loss": 2.8377,
      "step": 196960
    },
    {
      "epoch": 316.69,
      "learning_rate": 0.06834424387443731,
      "loss": 2.8441,
      "step": 196980
    },
    {
      "epoch": 316.72,
      "learning_rate": 0.06834102844356912,
      "loss": 2.8302,
      "step": 197000
    },
    {
      "epoch": 316.75,
      "learning_rate": 0.06833781301270098,
      "loss": 2.8713,
      "step": 197020
    },
    {
      "epoch": 316.78,
      "learning_rate": 0.0683345975818328,
      "loss": 2.8729,
      "step": 197040
    },
    {
      "epoch": 316.82,
      "learning_rate": 0.06833138215096464,
      "loss": 2.8508,
      "step": 197060
    },
    {
      "epoch": 316.85,
      "learning_rate": 0.06832816672009646,
      "loss": 2.8766,
      "step": 197080
    },
    {
      "epoch": 316.88,
      "learning_rate": 0.0683249512892283,
      "loss": 2.8744,
      "step": 197100
    },
    {
      "epoch": 316.91,
      "learning_rate": 0.06832173585836014,
      "loss": 2.896,
      "step": 197120
    },
    {
      "epoch": 316.95,
      "learning_rate": 0.06831852042749197,
      "loss": 2.8521,
      "step": 197140
    },
    {
      "epoch": 316.98,
      "learning_rate": 0.0683153049966238,
      "loss": 2.8806,
      "step": 197160
    },
    {
      "epoch": 317.0,
      "eval_accuracy": {
        "accuracy": 0.3917437611754645
      },
      "eval_loss": 2.933706521987915,
      "eval_runtime": 3.0357,
      "eval_samples_per_second": 4237.236,
      "eval_steps_per_second": 66.212,
      "step": 197174
    },
    {
      "epoch": 317.01,
      "learning_rate": 0.06831208956575563,
      "loss": 2.8478,
      "step": 197180
    },
    {
      "epoch": 317.04,
      "learning_rate": 0.06830887413488747,
      "loss": 2.8396,
      "step": 197200
    },
    {
      "epoch": 317.07,
      "learning_rate": 0.0683056587040193,
      "loss": 2.8924,
      "step": 197220
    },
    {
      "epoch": 317.11,
      "learning_rate": 0.06830244327315112,
      "loss": 2.8734,
      "step": 197240
    },
    {
      "epoch": 317.14,
      "learning_rate": 0.06829922784228297,
      "loss": 2.8695,
      "step": 197260
    },
    {
      "epoch": 317.17,
      "learning_rate": 0.0682960124114148,
      "loss": 2.8805,
      "step": 197280
    },
    {
      "epoch": 317.2,
      "learning_rate": 0.06829279698054663,
      "loss": 2.8336,
      "step": 197300
    },
    {
      "epoch": 317.23,
      "learning_rate": 0.06828958154967847,
      "loss": 2.8518,
      "step": 197320
    },
    {
      "epoch": 317.27,
      "learning_rate": 0.06828636611881028,
      "loss": 2.849,
      "step": 197340
    },
    {
      "epoch": 317.3,
      "learning_rate": 0.06828315068794213,
      "loss": 2.8414,
      "step": 197360
    },
    {
      "epoch": 317.33,
      "learning_rate": 0.06827993525707396,
      "loss": 2.8592,
      "step": 197380
    },
    {
      "epoch": 317.36,
      "learning_rate": 0.0682767198262058,
      "loss": 2.8691,
      "step": 197400
    },
    {
      "epoch": 317.4,
      "learning_rate": 0.06827350439533762,
      "loss": 2.8538,
      "step": 197420
    },
    {
      "epoch": 317.43,
      "learning_rate": 0.06827028896446945,
      "loss": 2.8309,
      "step": 197440
    },
    {
      "epoch": 317.46,
      "learning_rate": 0.0682670735336013,
      "loss": 2.8333,
      "step": 197460
    },
    {
      "epoch": 317.49,
      "learning_rate": 0.06826385810273312,
      "loss": 2.8196,
      "step": 197480
    },
    {
      "epoch": 317.52,
      "learning_rate": 0.06826064267186496,
      "loss": 2.8558,
      "step": 197500
    },
    {
      "epoch": 317.56,
      "learning_rate": 0.06825742724099679,
      "loss": 2.8809,
      "step": 197520
    },
    {
      "epoch": 317.59,
      "learning_rate": 0.06825421181012861,
      "loss": 2.8682,
      "step": 197540
    },
    {
      "epoch": 317.62,
      "learning_rate": 0.06825099637926046,
      "loss": 2.8472,
      "step": 197560
    },
    {
      "epoch": 317.65,
      "learning_rate": 0.06824778094839228,
      "loss": 2.8522,
      "step": 197580
    },
    {
      "epoch": 317.68,
      "learning_rate": 0.06824456551752413,
      "loss": 2.848,
      "step": 197600
    },
    {
      "epoch": 317.72,
      "learning_rate": 0.06824135008665595,
      "loss": 2.838,
      "step": 197620
    },
    {
      "epoch": 317.75,
      "learning_rate": 0.06823813465578778,
      "loss": 2.8574,
      "step": 197640
    },
    {
      "epoch": 317.78,
      "learning_rate": 0.06823491922491963,
      "loss": 2.8757,
      "step": 197660
    },
    {
      "epoch": 317.81,
      "learning_rate": 0.06823170379405144,
      "loss": 2.8816,
      "step": 197680
    },
    {
      "epoch": 317.85,
      "learning_rate": 0.06822848836318329,
      "loss": 2.8498,
      "step": 197700
    },
    {
      "epoch": 317.88,
      "learning_rate": 0.06822527293231512,
      "loss": 2.8693,
      "step": 197720
    },
    {
      "epoch": 317.91,
      "learning_rate": 0.06822205750144696,
      "loss": 2.8353,
      "step": 197740
    },
    {
      "epoch": 317.94,
      "learning_rate": 0.0682188420705788,
      "loss": 2.8894,
      "step": 197760
    },
    {
      "epoch": 317.97,
      "learning_rate": 0.0682156266397106,
      "loss": 2.8439,
      "step": 197780
    },
    {
      "epoch": 318.0,
      "eval_accuracy": {
        "accuracy": 0.386146311124932
      },
      "eval_loss": 2.998514175415039,
      "eval_runtime": 3.3481,
      "eval_samples_per_second": 3841.863,
      "eval_steps_per_second": 60.034,
      "step": 197796
    },
    {
      "epoch": 318.01,
      "learning_rate": 0.06821257198038586,
      "loss": 2.8392,
      "step": 197800
    },
    {
      "epoch": 318.04,
      "learning_rate": 0.0682093565495177,
      "loss": 2.8451,
      "step": 197820
    },
    {
      "epoch": 318.07,
      "learning_rate": 0.06820614111864952,
      "loss": 2.8391,
      "step": 197840
    },
    {
      "epoch": 318.1,
      "learning_rate": 0.06820292568778136,
      "loss": 2.8259,
      "step": 197860
    },
    {
      "epoch": 318.14,
      "learning_rate": 0.06819971025691318,
      "loss": 2.8821,
      "step": 197880
    },
    {
      "epoch": 318.17,
      "learning_rate": 0.06819649482604502,
      "loss": 2.8821,
      "step": 197900
    },
    {
      "epoch": 318.2,
      "learning_rate": 0.06819327939517686,
      "loss": 2.8368,
      "step": 197920
    },
    {
      "epoch": 318.23,
      "learning_rate": 0.06819006396430868,
      "loss": 2.8499,
      "step": 197940
    },
    {
      "epoch": 318.26,
      "learning_rate": 0.06818684853344052,
      "loss": 2.8656,
      "step": 197960
    },
    {
      "epoch": 318.3,
      "learning_rate": 0.06818363310257235,
      "loss": 2.8406,
      "step": 197980
    },
    {
      "epoch": 318.33,
      "learning_rate": 0.06818041767170419,
      "loss": 2.8089,
      "step": 198000
    },
    {
      "epoch": 318.36,
      "learning_rate": 0.06817720224083602,
      "loss": 2.8675,
      "step": 198020
    },
    {
      "epoch": 318.39,
      "learning_rate": 0.06817398680996785,
      "loss": 2.8827,
      "step": 198040
    },
    {
      "epoch": 318.42,
      "learning_rate": 0.06817077137909969,
      "loss": 2.8522,
      "step": 198060
    },
    {
      "epoch": 318.46,
      "learning_rate": 0.06816755594823151,
      "loss": 2.8814,
      "step": 198080
    },
    {
      "epoch": 318.49,
      "learning_rate": 0.06816434051736335,
      "loss": 2.8243,
      "step": 198100
    },
    {
      "epoch": 318.52,
      "learning_rate": 0.06816112508649518,
      "loss": 2.8388,
      "step": 198120
    },
    {
      "epoch": 318.55,
      "learning_rate": 0.06815790965562701,
      "loss": 2.8666,
      "step": 198140
    },
    {
      "epoch": 318.59,
      "learning_rate": 0.06815469422475885,
      "loss": 2.8679,
      "step": 198160
    },
    {
      "epoch": 318.62,
      "learning_rate": 0.06815147879389068,
      "loss": 2.8444,
      "step": 198180
    },
    {
      "epoch": 318.65,
      "learning_rate": 0.06814826336302252,
      "loss": 2.8453,
      "step": 198200
    },
    {
      "epoch": 318.68,
      "learning_rate": 0.06814504793215434,
      "loss": 2.8617,
      "step": 198220
    },
    {
      "epoch": 318.71,
      "learning_rate": 0.06814183250128618,
      "loss": 2.8909,
      "step": 198240
    },
    {
      "epoch": 318.75,
      "learning_rate": 0.06813861707041802,
      "loss": 2.8628,
      "step": 198260
    },
    {
      "epoch": 318.78,
      "learning_rate": 0.06813540163954984,
      "loss": 2.8485,
      "step": 198280
    },
    {
      "epoch": 318.81,
      "learning_rate": 0.06813218620868168,
      "loss": 2.8607,
      "step": 198300
    },
    {
      "epoch": 318.84,
      "learning_rate": 0.0681289707778135,
      "loss": 2.805,
      "step": 198320
    },
    {
      "epoch": 318.87,
      "learning_rate": 0.06812575534694534,
      "loss": 2.8488,
      "step": 198340
    },
    {
      "epoch": 318.91,
      "learning_rate": 0.06812253991607718,
      "loss": 2.8378,
      "step": 198360
    },
    {
      "epoch": 318.94,
      "learning_rate": 0.068119324485209,
      "loss": 2.8411,
      "step": 198380
    },
    {
      "epoch": 318.97,
      "learning_rate": 0.06811610905434085,
      "loss": 2.8662,
      "step": 198400
    },
    {
      "epoch": 319.0,
      "eval_accuracy": {
        "accuracy": 0.38311435901422686
      },
      "eval_loss": 2.9769718647003174,
      "eval_runtime": 2.9322,
      "eval_samples_per_second": 4386.745,
      "eval_steps_per_second": 68.548,
      "step": 198418
    },
    {
      "epoch": 319.0,
      "learning_rate": 0.06811289362347267,
      "loss": 2.8707,
      "step": 198420
    },
    {
      "epoch": 319.04,
      "learning_rate": 0.06810967819260451,
      "loss": 2.8462,
      "step": 198440
    },
    {
      "epoch": 319.07,
      "learning_rate": 0.06810646276173633,
      "loss": 2.8731,
      "step": 198460
    },
    {
      "epoch": 319.1,
      "learning_rate": 0.06810324733086817,
      "loss": 2.821,
      "step": 198480
    },
    {
      "epoch": 319.13,
      "learning_rate": 0.06810003190000001,
      "loss": 2.8546,
      "step": 198500
    },
    {
      "epoch": 319.16,
      "learning_rate": 0.06809681646913184,
      "loss": 2.8166,
      "step": 198520
    },
    {
      "epoch": 319.2,
      "learning_rate": 0.06809360103826367,
      "loss": 2.8738,
      "step": 198540
    },
    {
      "epoch": 319.23,
      "learning_rate": 0.0680903856073955,
      "loss": 2.8491,
      "step": 198560
    },
    {
      "epoch": 319.26,
      "learning_rate": 0.06808717017652734,
      "loss": 2.8529,
      "step": 198580
    },
    {
      "epoch": 319.29,
      "learning_rate": 0.06808395474565918,
      "loss": 2.8643,
      "step": 198600
    },
    {
      "epoch": 319.32,
      "learning_rate": 0.068080739314791,
      "loss": 2.8405,
      "step": 198620
    },
    {
      "epoch": 319.36,
      "learning_rate": 0.06807752388392284,
      "loss": 2.8682,
      "step": 198640
    },
    {
      "epoch": 319.39,
      "learning_rate": 0.06807430845305466,
      "loss": 2.8437,
      "step": 198660
    },
    {
      "epoch": 319.42,
      "learning_rate": 0.0680710930221865,
      "loss": 2.9016,
      "step": 198680
    },
    {
      "epoch": 319.45,
      "learning_rate": 0.06806787759131834,
      "loss": 2.8507,
      "step": 198700
    },
    {
      "epoch": 319.49,
      "learning_rate": 0.06806466216045017,
      "loss": 2.8671,
      "step": 198720
    },
    {
      "epoch": 319.52,
      "learning_rate": 0.068061446729582,
      "loss": 2.8202,
      "step": 198740
    },
    {
      "epoch": 319.55,
      "learning_rate": 0.06805823129871383,
      "loss": 2.8792,
      "step": 198760
    },
    {
      "epoch": 319.58,
      "learning_rate": 0.06805501586784567,
      "loss": 2.9057,
      "step": 198780
    },
    {
      "epoch": 319.61,
      "learning_rate": 0.06805180043697749,
      "loss": 2.8631,
      "step": 198800
    },
    {
      "epoch": 319.65,
      "learning_rate": 0.06804858500610933,
      "loss": 2.8338,
      "step": 198820
    },
    {
      "epoch": 319.68,
      "learning_rate": 0.06804536957524117,
      "loss": 2.8228,
      "step": 198840
    },
    {
      "epoch": 319.71,
      "learning_rate": 0.068042154144373,
      "loss": 2.8431,
      "step": 198860
    },
    {
      "epoch": 319.74,
      "learning_rate": 0.06803893871350483,
      "loss": 2.8775,
      "step": 198880
    },
    {
      "epoch": 319.77,
      "learning_rate": 0.06803572328263666,
      "loss": 2.8753,
      "step": 198900
    },
    {
      "epoch": 319.81,
      "learning_rate": 0.0680325078517685,
      "loss": 2.8675,
      "step": 198920
    },
    {
      "epoch": 319.84,
      "learning_rate": 0.06802929242090033,
      "loss": 2.8809,
      "step": 198940
    },
    {
      "epoch": 319.87,
      "learning_rate": 0.06802607699003216,
      "loss": 2.8638,
      "step": 198960
    },
    {
      "epoch": 319.9,
      "learning_rate": 0.068022861559164,
      "loss": 2.8531,
      "step": 198980
    },
    {
      "epoch": 319.94,
      "learning_rate": 0.06801964612829582,
      "loss": 2.8706,
      "step": 199000
    },
    {
      "epoch": 319.97,
      "learning_rate": 0.06801643069742766,
      "loss": 2.8664,
      "step": 199020
    },
    {
      "epoch": 320.0,
      "learning_rate": 0.0680132152665595,
      "loss": 2.8798,
      "step": 199040
    },
    {
      "epoch": 320.0,
      "eval_accuracy": {
        "accuracy": 0.38599082640130605
      },
      "eval_loss": 3.005460739135742,
      "eval_runtime": 3.6925,
      "eval_samples_per_second": 3483.526,
      "eval_steps_per_second": 54.434,
      "step": 199040
    },
    {
      "epoch": 320.03,
      "learning_rate": 0.06800999983569132,
      "loss": 2.8729,
      "step": 199060
    },
    {
      "epoch": 320.06,
      "learning_rate": 0.06800678440482316,
      "loss": 2.8516,
      "step": 199080
    },
    {
      "epoch": 320.1,
      "learning_rate": 0.06800356897395499,
      "loss": 2.8658,
      "step": 199100
    },
    {
      "epoch": 320.13,
      "learning_rate": 0.06800035354308683,
      "loss": 2.8593,
      "step": 199120
    },
    {
      "epoch": 320.16,
      "learning_rate": 0.06799713811221865,
      "loss": 2.8391,
      "step": 199140
    },
    {
      "epoch": 320.19,
      "learning_rate": 0.06799392268135049,
      "loss": 2.8945,
      "step": 199160
    },
    {
      "epoch": 320.23,
      "learning_rate": 0.06799070725048233,
      "loss": 2.8522,
      "step": 199180
    },
    {
      "epoch": 320.26,
      "learning_rate": 0.06798749181961415,
      "loss": 2.8813,
      "step": 199200
    },
    {
      "epoch": 320.29,
      "learning_rate": 0.06798427638874599,
      "loss": 2.8659,
      "step": 199220
    },
    {
      "epoch": 320.32,
      "learning_rate": 0.06798106095787781,
      "loss": 2.8252,
      "step": 199240
    },
    {
      "epoch": 320.35,
      "learning_rate": 0.06797784552700965,
      "loss": 2.8715,
      "step": 199260
    },
    {
      "epoch": 320.39,
      "learning_rate": 0.06797463009614149,
      "loss": 2.8439,
      "step": 199280
    },
    {
      "epoch": 320.42,
      "learning_rate": 0.06797141466527332,
      "loss": 2.8161,
      "step": 199300
    },
    {
      "epoch": 320.45,
      "learning_rate": 0.06796819923440515,
      "loss": 2.8322,
      "step": 199320
    },
    {
      "epoch": 320.48,
      "learning_rate": 0.06796498380353698,
      "loss": 2.8493,
      "step": 199340
    },
    {
      "epoch": 320.51,
      "learning_rate": 0.06796176837266882,
      "loss": 2.8759,
      "step": 199360
    },
    {
      "epoch": 320.55,
      "learning_rate": 0.06795855294180066,
      "loss": 2.8684,
      "step": 199380
    },
    {
      "epoch": 320.58,
      "learning_rate": 0.06795533751093248,
      "loss": 2.8544,
      "step": 199400
    },
    {
      "epoch": 320.61,
      "learning_rate": 0.06795212208006432,
      "loss": 2.878,
      "step": 199420
    },
    {
      "epoch": 320.64,
      "learning_rate": 0.06794890664919614,
      "loss": 2.865,
      "step": 199440
    },
    {
      "epoch": 320.68,
      "learning_rate": 0.06794569121832798,
      "loss": 2.8754,
      "step": 199460
    },
    {
      "epoch": 320.71,
      "learning_rate": 0.06794247578745981,
      "loss": 2.8523,
      "step": 199480
    },
    {
      "epoch": 320.74,
      "learning_rate": 0.06793926035659165,
      "loss": 2.8646,
      "step": 199500
    },
    {
      "epoch": 320.77,
      "learning_rate": 0.06793604492572348,
      "loss": 2.8613,
      "step": 199520
    },
    {
      "epoch": 320.8,
      "learning_rate": 0.06793282949485531,
      "loss": 2.8572,
      "step": 199540
    },
    {
      "epoch": 320.84,
      "learning_rate": 0.06792961406398715,
      "loss": 2.7849,
      "step": 199560
    },
    {
      "epoch": 320.87,
      "learning_rate": 0.06792639863311897,
      "loss": 2.8488,
      "step": 199580
    },
    {
      "epoch": 320.9,
      "learning_rate": 0.06792318320225081,
      "loss": 2.8344,
      "step": 199600
    },
    {
      "epoch": 320.93,
      "learning_rate": 0.06791996777138265,
      "loss": 2.8223,
      "step": 199620
    },
    {
      "epoch": 320.96,
      "learning_rate": 0.06791675234051446,
      "loss": 2.895,
      "step": 199640
    },
    {
      "epoch": 321.0,
      "learning_rate": 0.06791353690964631,
      "loss": 2.8446,
      "step": 199660
    },
    {
      "epoch": 321.0,
      "eval_accuracy": {
        "accuracy": 0.39119956464277383
      },
      "eval_loss": 2.956662893295288,
      "eval_runtime": 3.1939,
      "eval_samples_per_second": 4027.416,
      "eval_steps_per_second": 62.933,
      "step": 199662
    },
    {
      "epoch": 321.03,
      "learning_rate": 0.06791032147877814,
      "loss": 2.8515,
      "step": 199680
    },
    {
      "epoch": 321.06,
      "learning_rate": 0.06790710604790998,
      "loss": 2.8678,
      "step": 199700
    },
    {
      "epoch": 321.09,
      "learning_rate": 0.06790389061704181,
      "loss": 2.8381,
      "step": 199720
    },
    {
      "epoch": 321.13,
      "learning_rate": 0.06790067518617363,
      "loss": 2.861,
      "step": 199740
    },
    {
      "epoch": 321.16,
      "learning_rate": 0.06789745975530548,
      "loss": 2.8354,
      "step": 199760
    },
    {
      "epoch": 321.19,
      "learning_rate": 0.0678942443244373,
      "loss": 2.82,
      "step": 199780
    },
    {
      "epoch": 321.22,
      "learning_rate": 0.06789102889356914,
      "loss": 2.8251,
      "step": 199800
    },
    {
      "epoch": 321.25,
      "learning_rate": 0.06788781346270097,
      "loss": 2.8519,
      "step": 199820
    },
    {
      "epoch": 321.29,
      "learning_rate": 0.06788459803183279,
      "loss": 2.8466,
      "step": 199840
    },
    {
      "epoch": 321.32,
      "learning_rate": 0.06788138260096464,
      "loss": 2.847,
      "step": 199860
    },
    {
      "epoch": 321.35,
      "learning_rate": 0.06787816717009647,
      "loss": 2.8846,
      "step": 199880
    },
    {
      "epoch": 321.38,
      "learning_rate": 0.0678749517392283,
      "loss": 2.8897,
      "step": 199900
    },
    {
      "epoch": 321.41,
      "learning_rate": 0.06787189707990354,
      "loss": 2.858,
      "step": 199920
    },
    {
      "epoch": 321.45,
      "learning_rate": 0.06786868164903537,
      "loss": 2.8775,
      "step": 199940
    },
    {
      "epoch": 321.48,
      "learning_rate": 0.0678654662181672,
      "loss": 2.849,
      "step": 199960
    },
    {
      "epoch": 321.51,
      "learning_rate": 0.06786225078729904,
      "loss": 2.8495,
      "step": 199980
    },
    {
      "epoch": 321.54,
      "learning_rate": 0.06785903535643087,
      "loss": 2.8656,
      "step": 200000
    },
    {
      "epoch": 321.58,
      "learning_rate": 0.06785581992556271,
      "loss": 2.8496,
      "step": 200020
    },
    {
      "epoch": 321.61,
      "learning_rate": 0.06785260449469455,
      "loss": 2.8667,
      "step": 200040
    },
    {
      "epoch": 321.64,
      "learning_rate": 0.06784938906382637,
      "loss": 2.8647,
      "step": 200060
    },
    {
      "epoch": 321.67,
      "learning_rate": 0.06784617363295821,
      "loss": 2.8551,
      "step": 200080
    },
    {
      "epoch": 321.7,
      "learning_rate": 0.06784295820209003,
      "loss": 2.853,
      "step": 200100
    },
    {
      "epoch": 321.74,
      "learning_rate": 0.06783974277122187,
      "loss": 2.8256,
      "step": 200120
    },
    {
      "epoch": 321.77,
      "learning_rate": 0.06783652734035371,
      "loss": 2.8293,
      "step": 200140
    },
    {
      "epoch": 321.8,
      "learning_rate": 0.06783331190948554,
      "loss": 2.8915,
      "step": 200160
    },
    {
      "epoch": 321.83,
      "learning_rate": 0.06783009647861736,
      "loss": 2.8573,
      "step": 200180
    },
    {
      "epoch": 321.86,
      "learning_rate": 0.0678268810477492,
      "loss": 2.8401,
      "step": 200200
    },
    {
      "epoch": 321.9,
      "learning_rate": 0.06782366561688104,
      "loss": 2.8633,
      "step": 200220
    },
    {
      "epoch": 321.93,
      "learning_rate": 0.06782045018601286,
      "loss": 2.8358,
      "step": 200240
    },
    {
      "epoch": 321.96,
      "learning_rate": 0.0678172347551447,
      "loss": 2.852,
      "step": 200260
    },
    {
      "epoch": 321.99,
      "learning_rate": 0.06781401932427653,
      "loss": 2.8476,
      "step": 200280
    },
    {
      "epoch": 322.0,
      "eval_accuracy": {
        "accuracy": 0.39780766539687473
      },
      "eval_loss": 2.920720100402832,
      "eval_runtime": 2.7255,
      "eval_samples_per_second": 4719.568,
      "eval_steps_per_second": 73.749,
      "step": 200284
    },
    {
      "epoch": 322.03,
      "learning_rate": 0.06781080389340836,
      "loss": 2.8354,
      "step": 200300
    },
    {
      "epoch": 322.06,
      "learning_rate": 0.0678075884625402,
      "loss": 2.827,
      "step": 200320
    },
    {
      "epoch": 322.09,
      "learning_rate": 0.06780437303167203,
      "loss": 2.8379,
      "step": 200340
    },
    {
      "epoch": 322.12,
      "learning_rate": 0.06780115760080387,
      "loss": 2.8302,
      "step": 200360
    },
    {
      "epoch": 322.15,
      "learning_rate": 0.06779794216993569,
      "loss": 2.8061,
      "step": 200380
    },
    {
      "epoch": 322.19,
      "learning_rate": 0.06779472673906753,
      "loss": 2.825,
      "step": 200400
    },
    {
      "epoch": 322.22,
      "learning_rate": 0.06779151130819937,
      "loss": 2.8613,
      "step": 200420
    },
    {
      "epoch": 322.25,
      "learning_rate": 0.06778829587733119,
      "loss": 2.813,
      "step": 200440
    },
    {
      "epoch": 322.28,
      "learning_rate": 0.06778508044646303,
      "loss": 2.8324,
      "step": 200460
    },
    {
      "epoch": 322.32,
      "learning_rate": 0.06778186501559486,
      "loss": 2.8279,
      "step": 200480
    },
    {
      "epoch": 322.35,
      "learning_rate": 0.0677786495847267,
      "loss": 2.8187,
      "step": 200500
    },
    {
      "epoch": 322.38,
      "learning_rate": 0.06777543415385852,
      "loss": 2.8213,
      "step": 200520
    },
    {
      "epoch": 322.41,
      "learning_rate": 0.06777221872299036,
      "loss": 2.8533,
      "step": 200540
    },
    {
      "epoch": 322.44,
      "learning_rate": 0.0677690032921222,
      "loss": 2.8211,
      "step": 200560
    },
    {
      "epoch": 322.48,
      "learning_rate": 0.06776578786125402,
      "loss": 2.8085,
      "step": 200580
    },
    {
      "epoch": 322.51,
      "learning_rate": 0.06776257243038586,
      "loss": 2.8592,
      "step": 200600
    },
    {
      "epoch": 322.54,
      "learning_rate": 0.06775935699951768,
      "loss": 2.8776,
      "step": 200620
    },
    {
      "epoch": 322.57,
      "learning_rate": 0.06775614156864952,
      "loss": 2.8879,
      "step": 200640
    },
    {
      "epoch": 322.6,
      "learning_rate": 0.06775292613778136,
      "loss": 2.8667,
      "step": 200660
    },
    {
      "epoch": 322.64,
      "learning_rate": 0.06774971070691319,
      "loss": 2.8687,
      "step": 200680
    },
    {
      "epoch": 322.67,
      "learning_rate": 0.06774649527604502,
      "loss": 2.8431,
      "step": 200700
    },
    {
      "epoch": 322.7,
      "learning_rate": 0.06774327984517685,
      "loss": 2.8512,
      "step": 200720
    },
    {
      "epoch": 322.73,
      "learning_rate": 0.06774006441430869,
      "loss": 2.8547,
      "step": 200740
    },
    {
      "epoch": 322.77,
      "learning_rate": 0.06773684898344053,
      "loss": 2.8553,
      "step": 200760
    },
    {
      "epoch": 322.8,
      "learning_rate": 0.06773363355257235,
      "loss": 2.8513,
      "step": 200780
    },
    {
      "epoch": 322.83,
      "learning_rate": 0.06773041812170419,
      "loss": 2.8529,
      "step": 200800
    },
    {
      "epoch": 322.86,
      "learning_rate": 0.06772720269083601,
      "loss": 2.83,
      "step": 200820
    },
    {
      "epoch": 322.89,
      "learning_rate": 0.06772398725996785,
      "loss": 2.8475,
      "step": 200840
    },
    {
      "epoch": 322.93,
      "learning_rate": 0.06772077182909968,
      "loss": 2.818,
      "step": 200860
    },
    {
      "epoch": 322.96,
      "learning_rate": 0.06771755639823152,
      "loss": 2.8854,
      "step": 200880
    },
    {
      "epoch": 322.99,
      "learning_rate": 0.06771434096736335,
      "loss": 2.7985,
      "step": 200900
    },
    {
      "epoch": 323.0,
      "eval_accuracy": {
        "accuracy": 0.390966337557335
      },
      "eval_loss": 2.979367971420288,
      "eval_runtime": 2.799,
      "eval_samples_per_second": 4595.627,
      "eval_steps_per_second": 71.812,
      "step": 200906
    },
    {
      "epoch": 323.02,
      "learning_rate": 0.06771112553649518,
      "loss": 2.8449,
      "step": 200920
    },
    {
      "epoch": 323.05,
      "learning_rate": 0.06770791010562702,
      "loss": 2.85,
      "step": 200940
    },
    {
      "epoch": 323.09,
      "learning_rate": 0.06770469467475884,
      "loss": 2.842,
      "step": 200960
    },
    {
      "epoch": 323.12,
      "learning_rate": 0.06770147924389068,
      "loss": 2.8692,
      "step": 200980
    },
    {
      "epoch": 323.15,
      "learning_rate": 0.06769826381302252,
      "loss": 2.8751,
      "step": 201000
    },
    {
      "epoch": 323.18,
      "learning_rate": 0.06769504838215434,
      "loss": 2.7991,
      "step": 201020
    },
    {
      "epoch": 323.22,
      "learning_rate": 0.06769183295128618,
      "loss": 2.841,
      "step": 201040
    },
    {
      "epoch": 323.25,
      "learning_rate": 0.067688617520418,
      "loss": 2.8529,
      "step": 201060
    },
    {
      "epoch": 323.28,
      "learning_rate": 0.06768540208954985,
      "loss": 2.8437,
      "step": 201080
    },
    {
      "epoch": 323.31,
      "learning_rate": 0.06768218665868168,
      "loss": 2.8468,
      "step": 201100
    },
    {
      "epoch": 323.34,
      "learning_rate": 0.06767897122781351,
      "loss": 2.8862,
      "step": 201120
    },
    {
      "epoch": 323.38,
      "learning_rate": 0.06767575579694535,
      "loss": 2.8821,
      "step": 201140
    },
    {
      "epoch": 323.41,
      "learning_rate": 0.06767254036607717,
      "loss": 2.8702,
      "step": 201160
    },
    {
      "epoch": 323.44,
      "learning_rate": 0.06766932493520901,
      "loss": 2.8563,
      "step": 201180
    },
    {
      "epoch": 323.47,
      "learning_rate": 0.06766610950434084,
      "loss": 2.8665,
      "step": 201200
    },
    {
      "epoch": 323.5,
      "learning_rate": 0.06766289407347267,
      "loss": 2.8478,
      "step": 201220
    },
    {
      "epoch": 323.54,
      "learning_rate": 0.06765967864260451,
      "loss": 2.868,
      "step": 201240
    },
    {
      "epoch": 323.57,
      "learning_rate": 0.06765646321173634,
      "loss": 2.8401,
      "step": 201260
    },
    {
      "epoch": 323.6,
      "learning_rate": 0.06765324778086818,
      "loss": 2.8557,
      "step": 201280
    },
    {
      "epoch": 323.63,
      "learning_rate": 0.06765003235,
      "loss": 2.8551,
      "step": 201300
    },
    {
      "epoch": 323.67,
      "learning_rate": 0.06764681691913184,
      "loss": 2.8621,
      "step": 201320
    },
    {
      "epoch": 323.7,
      "learning_rate": 0.06764360148826368,
      "loss": 2.849,
      "step": 201340
    },
    {
      "epoch": 323.73,
      "learning_rate": 0.0676403860573955,
      "loss": 2.875,
      "step": 201360
    },
    {
      "epoch": 323.76,
      "learning_rate": 0.06763717062652734,
      "loss": 2.8287,
      "step": 201380
    },
    {
      "epoch": 323.79,
      "learning_rate": 0.06763395519565917,
      "loss": 2.8051,
      "step": 201400
    },
    {
      "epoch": 323.83,
      "learning_rate": 0.067630739764791,
      "loss": 2.8755,
      "step": 201420
    },
    {
      "epoch": 323.86,
      "learning_rate": 0.06762752433392284,
      "loss": 2.8626,
      "step": 201440
    },
    {
      "epoch": 323.89,
      "learning_rate": 0.06762430890305467,
      "loss": 2.8562,
      "step": 201460
    },
    {
      "epoch": 323.92,
      "learning_rate": 0.0676210934721865,
      "loss": 2.8651,
      "step": 201480
    },
    {
      "epoch": 323.95,
      "learning_rate": 0.06761787804131833,
      "loss": 2.8525,
      "step": 201500
    },
    {
      "epoch": 323.99,
      "learning_rate": 0.06761466261045017,
      "loss": 2.8498,
      "step": 201520
    },
    {
      "epoch": 324.0,
      "eval_accuracy": {
        "accuracy": 0.38902277851201117
      },
      "eval_loss": 2.9393584728240967,
      "eval_runtime": 2.7302,
      "eval_samples_per_second": 4711.363,
      "eval_steps_per_second": 73.621,
      "step": 201528
    },
    {
      "epoch": 324.02,
      "learning_rate": 0.067611447179582,
      "loss": 2.8545,
      "step": 201540
    },
    {
      "epoch": 324.05,
      "learning_rate": 0.06760823174871383,
      "loss": 2.8466,
      "step": 201560
    },
    {
      "epoch": 324.08,
      "learning_rate": 0.06760501631784567,
      "loss": 2.8348,
      "step": 201580
    },
    {
      "epoch": 324.12,
      "learning_rate": 0.0676018008869775,
      "loss": 2.857,
      "step": 201600
    },
    {
      "epoch": 324.15,
      "learning_rate": 0.06759858545610933,
      "loss": 2.8223,
      "step": 201620
    },
    {
      "epoch": 324.18,
      "learning_rate": 0.06759537002524116,
      "loss": 2.8381,
      "step": 201640
    },
    {
      "epoch": 324.21,
      "learning_rate": 0.067592154594373,
      "loss": 2.8731,
      "step": 201660
    },
    {
      "epoch": 324.24,
      "learning_rate": 0.06758893916350484,
      "loss": 2.8565,
      "step": 201680
    },
    {
      "epoch": 324.28,
      "learning_rate": 0.06758572373263666,
      "loss": 2.8329,
      "step": 201700
    },
    {
      "epoch": 324.31,
      "learning_rate": 0.0675825083017685,
      "loss": 2.8231,
      "step": 201720
    },
    {
      "epoch": 324.34,
      "learning_rate": 0.06757929287090032,
      "loss": 2.8542,
      "step": 201740
    },
    {
      "epoch": 324.37,
      "learning_rate": 0.06757607744003216,
      "loss": 2.841,
      "step": 201760
    },
    {
      "epoch": 324.41,
      "learning_rate": 0.067572862009164,
      "loss": 2.8204,
      "step": 201780
    },
    {
      "epoch": 324.44,
      "learning_rate": 0.06756964657829582,
      "loss": 2.8316,
      "step": 201800
    },
    {
      "epoch": 324.47,
      "learning_rate": 0.06756643114742766,
      "loss": 2.8583,
      "step": 201820
    },
    {
      "epoch": 324.5,
      "learning_rate": 0.06756321571655949,
      "loss": 2.8397,
      "step": 201840
    },
    {
      "epoch": 324.53,
      "learning_rate": 0.06756000028569133,
      "loss": 2.8674,
      "step": 201860
    },
    {
      "epoch": 324.57,
      "learning_rate": 0.06755678485482315,
      "loss": 2.8838,
      "step": 201880
    },
    {
      "epoch": 324.6,
      "learning_rate": 0.06755356942395499,
      "loss": 2.8628,
      "step": 201900
    },
    {
      "epoch": 324.63,
      "learning_rate": 0.06755035399308683,
      "loss": 2.8567,
      "step": 201920
    },
    {
      "epoch": 324.66,
      "learning_rate": 0.06754713856221865,
      "loss": 2.8526,
      "step": 201940
    },
    {
      "epoch": 324.69,
      "learning_rate": 0.06754392313135049,
      "loss": 2.8268,
      "step": 201960
    },
    {
      "epoch": 324.73,
      "learning_rate": 0.06754070770048232,
      "loss": 2.8476,
      "step": 201980
    },
    {
      "epoch": 324.76,
      "learning_rate": 0.06753749226961415,
      "loss": 2.8602,
      "step": 202000
    },
    {
      "epoch": 324.79,
      "learning_rate": 0.067534276838746,
      "loss": 2.8428,
      "step": 202020
    },
    {
      "epoch": 324.82,
      "learning_rate": 0.0675310614078778,
      "loss": 2.8405,
      "step": 202040
    },
    {
      "epoch": 324.86,
      "learning_rate": 0.06752784597700966,
      "loss": 2.8149,
      "step": 202060
    },
    {
      "epoch": 324.89,
      "learning_rate": 0.06752463054614148,
      "loss": 2.8594,
      "step": 202080
    },
    {
      "epoch": 324.92,
      "learning_rate": 0.06752141511527332,
      "loss": 2.818,
      "step": 202100
    },
    {
      "epoch": 324.95,
      "learning_rate": 0.06751819968440516,
      "loss": 2.8205,
      "step": 202120
    },
    {
      "epoch": 324.98,
      "learning_rate": 0.06751498425353698,
      "loss": 2.851,
      "step": 202140
    },
    {
      "epoch": 325.0,
      "eval_accuracy": {
        "accuracy": 0.3887118090647594
      },
      "eval_loss": 2.9727373123168945,
      "eval_runtime": 3.1851,
      "eval_samples_per_second": 4038.525,
      "eval_steps_per_second": 63.107,
      "step": 202150
    },
    {
      "epoch": 325.02,
      "learning_rate": 0.06751176882266882,
      "loss": 2.8691,
      "step": 202160
    },
    {
      "epoch": 325.05,
      "learning_rate": 0.06750855339180065,
      "loss": 2.8301,
      "step": 202180
    },
    {
      "epoch": 325.08,
      "learning_rate": 0.06750533796093248,
      "loss": 2.8466,
      "step": 202200
    },
    {
      "epoch": 325.11,
      "learning_rate": 0.06750212253006431,
      "loss": 2.8248,
      "step": 202220
    },
    {
      "epoch": 325.14,
      "learning_rate": 0.06749906787073956,
      "loss": 2.8216,
      "step": 202240
    },
    {
      "epoch": 325.18,
      "learning_rate": 0.06749585243987138,
      "loss": 2.896,
      "step": 202260
    },
    {
      "epoch": 325.21,
      "learning_rate": 0.06749263700900322,
      "loss": 2.8514,
      "step": 202280
    },
    {
      "epoch": 325.24,
      "learning_rate": 0.06748942157813505,
      "loss": 2.854,
      "step": 202300
    },
    {
      "epoch": 325.27,
      "learning_rate": 0.06748620614726689,
      "loss": 2.8553,
      "step": 202320
    },
    {
      "epoch": 325.31,
      "learning_rate": 0.06748299071639872,
      "loss": 2.8402,
      "step": 202340
    },
    {
      "epoch": 325.34,
      "learning_rate": 0.06747977528553055,
      "loss": 2.8362,
      "step": 202360
    },
    {
      "epoch": 325.37,
      "learning_rate": 0.06747655985466239,
      "loss": 2.8374,
      "step": 202380
    },
    {
      "epoch": 325.4,
      "learning_rate": 0.06747334442379421,
      "loss": 2.8578,
      "step": 202400
    },
    {
      "epoch": 325.43,
      "learning_rate": 0.06747012899292605,
      "loss": 2.82,
      "step": 202420
    },
    {
      "epoch": 325.47,
      "learning_rate": 0.06746691356205789,
      "loss": 2.8343,
      "step": 202440
    },
    {
      "epoch": 325.5,
      "learning_rate": 0.06746369813118971,
      "loss": 2.8808,
      "step": 202460
    },
    {
      "epoch": 325.53,
      "learning_rate": 0.06746048270032155,
      "loss": 2.8623,
      "step": 202480
    },
    {
      "epoch": 325.56,
      "learning_rate": 0.06745726726945338,
      "loss": 2.8366,
      "step": 202500
    },
    {
      "epoch": 325.59,
      "learning_rate": 0.06745405183858522,
      "loss": 2.8312,
      "step": 202520
    },
    {
      "epoch": 325.63,
      "learning_rate": 0.06745083640771705,
      "loss": 2.846,
      "step": 202540
    },
    {
      "epoch": 325.66,
      "learning_rate": 0.06744762097684888,
      "loss": 2.8186,
      "step": 202560
    },
    {
      "epoch": 325.69,
      "learning_rate": 0.0674444055459807,
      "loss": 2.8365,
      "step": 202580
    },
    {
      "epoch": 325.72,
      "learning_rate": 0.06744119011511254,
      "loss": 2.8348,
      "step": 202600
    },
    {
      "epoch": 325.76,
      "learning_rate": 0.06743797468424438,
      "loss": 2.8327,
      "step": 202620
    },
    {
      "epoch": 325.79,
      "learning_rate": 0.0674347592533762,
      "loss": 2.8309,
      "step": 202640
    },
    {
      "epoch": 325.82,
      "learning_rate": 0.06743154382250804,
      "loss": 2.8506,
      "step": 202660
    },
    {
      "epoch": 325.85,
      "learning_rate": 0.06742832839163987,
      "loss": 2.8289,
      "step": 202680
    },
    {
      "epoch": 325.88,
      "learning_rate": 0.06742511296077171,
      "loss": 2.8153,
      "step": 202700
    },
    {
      "epoch": 325.92,
      "learning_rate": 0.06742189752990355,
      "loss": 2.8684,
      "step": 202720
    },
    {
      "epoch": 325.95,
      "learning_rate": 0.06741868209903537,
      "loss": 2.8287,
      "step": 202740
    },
    {
      "epoch": 325.98,
      "learning_rate": 0.06741546666816721,
      "loss": 2.8401,
      "step": 202760
    },
    {
      "epoch": 326.0,
      "eval_accuracy": {
        "accuracy": 0.39065536811008317
      },
      "eval_loss": 2.943229913711548,
      "eval_runtime": 3.1247,
      "eval_samples_per_second": 4116.494,
      "eval_steps_per_second": 64.325,
      "step": 202772
    },
    {
      "epoch": 326.01,
      "learning_rate": 0.06741225123729903,
      "loss": 2.8373,
      "step": 202780
    },
    {
      "epoch": 326.05,
      "learning_rate": 0.06740903580643087,
      "loss": 2.8384,
      "step": 202800
    },
    {
      "epoch": 326.08,
      "learning_rate": 0.06740582037556271,
      "loss": 2.8732,
      "step": 202820
    },
    {
      "epoch": 326.11,
      "learning_rate": 0.06740260494469454,
      "loss": 2.822,
      "step": 202840
    },
    {
      "epoch": 326.14,
      "learning_rate": 0.06739938951382637,
      "loss": 2.8152,
      "step": 202860
    },
    {
      "epoch": 326.17,
      "learning_rate": 0.06739617408295821,
      "loss": 2.8502,
      "step": 202880
    },
    {
      "epoch": 326.21,
      "learning_rate": 0.06739295865209004,
      "loss": 2.8162,
      "step": 202900
    },
    {
      "epoch": 326.24,
      "learning_rate": 0.06738974322122186,
      "loss": 2.843,
      "step": 202920
    },
    {
      "epoch": 326.27,
      "learning_rate": 0.0673865277903537,
      "loss": 2.8727,
      "step": 202940
    },
    {
      "epoch": 326.3,
      "learning_rate": 0.06738331235948554,
      "loss": 2.863,
      "step": 202960
    },
    {
      "epoch": 326.33,
      "learning_rate": 0.06738009692861736,
      "loss": 2.8609,
      "step": 202980
    },
    {
      "epoch": 326.37,
      "learning_rate": 0.0673768814977492,
      "loss": 2.8546,
      "step": 203000
    },
    {
      "epoch": 326.4,
      "learning_rate": 0.06737366606688103,
      "loss": 2.8663,
      "step": 203020
    },
    {
      "epoch": 326.43,
      "learning_rate": 0.06737045063601287,
      "loss": 2.8222,
      "step": 203040
    },
    {
      "epoch": 326.46,
      "learning_rate": 0.0673672352051447,
      "loss": 2.8515,
      "step": 203060
    },
    {
      "epoch": 326.5,
      "learning_rate": 0.06736401977427653,
      "loss": 2.8338,
      "step": 203080
    },
    {
      "epoch": 326.53,
      "learning_rate": 0.06736080434340837,
      "loss": 2.8387,
      "step": 203100
    },
    {
      "epoch": 326.56,
      "learning_rate": 0.06735758891254019,
      "loss": 2.8574,
      "step": 203120
    },
    {
      "epoch": 326.59,
      "learning_rate": 0.06735437348167203,
      "loss": 2.8802,
      "step": 203140
    },
    {
      "epoch": 326.62,
      "learning_rate": 0.06735115805080387,
      "loss": 2.8669,
      "step": 203160
    },
    {
      "epoch": 326.66,
      "learning_rate": 0.0673479426199357,
      "loss": 2.7971,
      "step": 203180
    },
    {
      "epoch": 326.69,
      "learning_rate": 0.06734472718906753,
      "loss": 2.8572,
      "step": 203200
    },
    {
      "epoch": 326.72,
      "learning_rate": 0.06734151175819936,
      "loss": 2.8461,
      "step": 203220
    },
    {
      "epoch": 326.75,
      "learning_rate": 0.0673382963273312,
      "loss": 2.8266,
      "step": 203240
    },
    {
      "epoch": 326.78,
      "learning_rate": 0.06733508089646302,
      "loss": 2.8526,
      "step": 203260
    },
    {
      "epoch": 326.82,
      "learning_rate": 0.06733186546559486,
      "loss": 2.8436,
      "step": 203280
    },
    {
      "epoch": 326.85,
      "learning_rate": 0.0673286500347267,
      "loss": 2.8493,
      "step": 203300
    },
    {
      "epoch": 326.88,
      "learning_rate": 0.06732543460385852,
      "loss": 2.8576,
      "step": 203320
    },
    {
      "epoch": 326.91,
      "learning_rate": 0.06732221917299036,
      "loss": 2.8265,
      "step": 203340
    },
    {
      "epoch": 326.95,
      "learning_rate": 0.06731900374212219,
      "loss": 2.8132,
      "step": 203360
    },
    {
      "epoch": 326.98,
      "learning_rate": 0.06731578831125402,
      "loss": 2.8517,
      "step": 203380
    },
    {
      "epoch": 327.0,
      "eval_accuracy": {
        "accuracy": 0.4037160848946591
      },
      "eval_loss": 2.916285991668701,
      "eval_runtime": 3.1151,
      "eval_samples_per_second": 4129.243,
      "eval_steps_per_second": 64.524,
      "step": 203394
    },
    {
      "epoch": 327.01,
      "learning_rate": 0.06731257288038586,
      "loss": 2.8235,
      "step": 203400
    },
    {
      "epoch": 327.04,
      "learning_rate": 0.06730935744951769,
      "loss": 2.8434,
      "step": 203420
    },
    {
      "epoch": 327.07,
      "learning_rate": 0.06730614201864953,
      "loss": 2.826,
      "step": 203440
    },
    {
      "epoch": 327.11,
      "learning_rate": 0.06730292658778135,
      "loss": 2.8429,
      "step": 203460
    },
    {
      "epoch": 327.14,
      "learning_rate": 0.06729971115691319,
      "loss": 2.8304,
      "step": 203480
    },
    {
      "epoch": 327.17,
      "learning_rate": 0.06729649572604503,
      "loss": 2.8346,
      "step": 203500
    },
    {
      "epoch": 327.2,
      "learning_rate": 0.06729328029517685,
      "loss": 2.8527,
      "step": 203520
    },
    {
      "epoch": 327.23,
      "learning_rate": 0.06729006486430869,
      "loss": 2.8072,
      "step": 203540
    },
    {
      "epoch": 327.27,
      "learning_rate": 0.06728684943344052,
      "loss": 2.853,
      "step": 203560
    },
    {
      "epoch": 327.3,
      "learning_rate": 0.06728363400257235,
      "loss": 2.8306,
      "step": 203580
    },
    {
      "epoch": 327.33,
      "learning_rate": 0.06728041857170418,
      "loss": 2.8577,
      "step": 203600
    },
    {
      "epoch": 327.36,
      "learning_rate": 0.06727720314083602,
      "loss": 2.8236,
      "step": 203620
    },
    {
      "epoch": 327.4,
      "learning_rate": 0.06727398770996786,
      "loss": 2.8759,
      "step": 203640
    },
    {
      "epoch": 327.43,
      "learning_rate": 0.06727077227909968,
      "loss": 2.8599,
      "step": 203660
    },
    {
      "epoch": 327.46,
      "learning_rate": 0.06726755684823152,
      "loss": 2.8565,
      "step": 203680
    },
    {
      "epoch": 327.49,
      "learning_rate": 0.06726434141736334,
      "loss": 2.8722,
      "step": 203700
    },
    {
      "epoch": 327.52,
      "learning_rate": 0.06726112598649518,
      "loss": 2.8743,
      "step": 203720
    },
    {
      "epoch": 327.56,
      "learning_rate": 0.06725791055562702,
      "loss": 2.8188,
      "step": 203740
    },
    {
      "epoch": 327.59,
      "learning_rate": 0.06725469512475885,
      "loss": 2.7956,
      "step": 203760
    },
    {
      "epoch": 327.62,
      "learning_rate": 0.06725147969389068,
      "loss": 2.8218,
      "step": 203780
    },
    {
      "epoch": 327.65,
      "learning_rate": 0.06724826426302251,
      "loss": 2.841,
      "step": 203800
    },
    {
      "epoch": 327.68,
      "learning_rate": 0.06724504883215435,
      "loss": 2.8552,
      "step": 203820
    },
    {
      "epoch": 327.72,
      "learning_rate": 0.06724183340128619,
      "loss": 2.8554,
      "step": 203840
    },
    {
      "epoch": 327.75,
      "learning_rate": 0.06723861797041801,
      "loss": 2.8419,
      "step": 203860
    },
    {
      "epoch": 327.78,
      "learning_rate": 0.06723540253954985,
      "loss": 2.8581,
      "step": 203880
    },
    {
      "epoch": 327.81,
      "learning_rate": 0.06723218710868167,
      "loss": 2.8591,
      "step": 203900
    },
    {
      "epoch": 327.85,
      "learning_rate": 0.06722897167781351,
      "loss": 2.8402,
      "step": 203920
    },
    {
      "epoch": 327.88,
      "learning_rate": 0.06722575624694534,
      "loss": 2.8602,
      "step": 203940
    },
    {
      "epoch": 327.91,
      "learning_rate": 0.06722254081607718,
      "loss": 2.8665,
      "step": 203960
    },
    {
      "epoch": 327.94,
      "learning_rate": 0.06721932538520901,
      "loss": 2.8593,
      "step": 203980
    },
    {
      "epoch": 327.97,
      "learning_rate": 0.06721610995434084,
      "loss": 2.8688,
      "step": 204000
    },
    {
      "epoch": 328.0,
      "eval_accuracy": {
        "accuracy": 0.3938428049444142
      },
      "eval_loss": 2.943124532699585,
      "eval_runtime": 2.7382,
      "eval_samples_per_second": 4697.534,
      "eval_steps_per_second": 73.405,
      "step": 204016
    },
    {
      "epoch": 328.01,
      "learning_rate": 0.06721289452347268,
      "loss": 2.87,
      "step": 204020
    },
    {
      "epoch": 328.04,
      "learning_rate": 0.0672096790926045,
      "loss": 2.8308,
      "step": 204040
    },
    {
      "epoch": 328.07,
      "learning_rate": 0.06720646366173634,
      "loss": 2.8139,
      "step": 204060
    },
    {
      "epoch": 328.1,
      "learning_rate": 0.06720324823086818,
      "loss": 2.8467,
      "step": 204080
    },
    {
      "epoch": 328.14,
      "learning_rate": 0.0672000328,
      "loss": 2.9083,
      "step": 204100
    },
    {
      "epoch": 328.17,
      "learning_rate": 0.06719681736913184,
      "loss": 2.8417,
      "step": 204120
    },
    {
      "epoch": 328.2,
      "learning_rate": 0.06719360193826367,
      "loss": 2.8658,
      "step": 204140
    },
    {
      "epoch": 328.23,
      "learning_rate": 0.0671903865073955,
      "loss": 2.8577,
      "step": 204160
    },
    {
      "epoch": 328.26,
      "learning_rate": 0.06718717107652734,
      "loss": 2.8454,
      "step": 204180
    },
    {
      "epoch": 328.3,
      "learning_rate": 0.06718395564565917,
      "loss": 2.8537,
      "step": 204200
    },
    {
      "epoch": 328.33,
      "learning_rate": 0.06718074021479101,
      "loss": 2.87,
      "step": 204220
    },
    {
      "epoch": 328.36,
      "learning_rate": 0.06717752478392283,
      "loss": 2.8341,
      "step": 204240
    },
    {
      "epoch": 328.39,
      "learning_rate": 0.06717430935305467,
      "loss": 2.8257,
      "step": 204260
    },
    {
      "epoch": 328.42,
      "learning_rate": 0.0671710939221865,
      "loss": 2.8498,
      "step": 204280
    },
    {
      "epoch": 328.46,
      "learning_rate": 0.06716787849131833,
      "loss": 2.8186,
      "step": 204300
    },
    {
      "epoch": 328.49,
      "learning_rate": 0.06716466306045017,
      "loss": 2.8147,
      "step": 204320
    },
    {
      "epoch": 328.52,
      "learning_rate": 0.06716160840112541,
      "loss": 2.8709,
      "step": 204340
    },
    {
      "epoch": 328.55,
      "learning_rate": 0.06715839297025723,
      "loss": 2.8413,
      "step": 204360
    },
    {
      "epoch": 328.59,
      "learning_rate": 0.06715517753938907,
      "loss": 2.8297,
      "step": 204380
    },
    {
      "epoch": 328.62,
      "learning_rate": 0.06715196210852091,
      "loss": 2.8182,
      "step": 204400
    },
    {
      "epoch": 328.65,
      "learning_rate": 0.06714874667765273,
      "loss": 2.8136,
      "step": 204420
    },
    {
      "epoch": 328.68,
      "learning_rate": 0.06714553124678457,
      "loss": 2.855,
      "step": 204440
    },
    {
      "epoch": 328.71,
      "learning_rate": 0.0671423158159164,
      "loss": 2.8534,
      "step": 204460
    },
    {
      "epoch": 328.75,
      "learning_rate": 0.06713910038504824,
      "loss": 2.8437,
      "step": 204480
    },
    {
      "epoch": 328.78,
      "learning_rate": 0.06713588495418008,
      "loss": 2.8723,
      "step": 204500
    },
    {
      "epoch": 328.81,
      "learning_rate": 0.0671326695233119,
      "loss": 2.8686,
      "step": 204520
    },
    {
      "epoch": 328.84,
      "learning_rate": 0.06712945409244374,
      "loss": 2.8631,
      "step": 204540
    },
    {
      "epoch": 328.87,
      "learning_rate": 0.06712623866157556,
      "loss": 2.8563,
      "step": 204560
    },
    {
      "epoch": 328.91,
      "learning_rate": 0.0671230232307074,
      "loss": 2.8286,
      "step": 204580
    },
    {
      "epoch": 328.94,
      "learning_rate": 0.06711980779983924,
      "loss": 2.8639,
      "step": 204600
    },
    {
      "epoch": 328.97,
      "learning_rate": 0.06711659236897106,
      "loss": 2.8602,
      "step": 204620
    },
    {
      "epoch": 329.0,
      "eval_accuracy": {
        "accuracy": 0.3926766695172199
      },
      "eval_loss": 2.939340591430664,
      "eval_runtime": 2.8176,
      "eval_samples_per_second": 4565.194,
      "eval_steps_per_second": 71.337,
      "step": 204638
    },
    {
      "epoch": 329.0,
      "learning_rate": 0.0671133769381029,
      "loss": 2.8474,
      "step": 204640
    },
    {
      "epoch": 329.04,
      "learning_rate": 0.06711016150723473,
      "loss": 2.8046,
      "step": 204660
    },
    {
      "epoch": 329.07,
      "learning_rate": 0.06710694607636657,
      "loss": 2.8376,
      "step": 204680
    },
    {
      "epoch": 329.1,
      "learning_rate": 0.06710373064549839,
      "loss": 2.8353,
      "step": 204700
    },
    {
      "epoch": 329.13,
      "learning_rate": 0.06710051521463023,
      "loss": 2.8448,
      "step": 204720
    },
    {
      "epoch": 329.16,
      "learning_rate": 0.06709729978376207,
      "loss": 2.8216,
      "step": 204740
    },
    {
      "epoch": 329.2,
      "learning_rate": 0.06709408435289389,
      "loss": 2.8251,
      "step": 204760
    },
    {
      "epoch": 329.23,
      "learning_rate": 0.06709086892202573,
      "loss": 2.8444,
      "step": 204780
    },
    {
      "epoch": 329.26,
      "learning_rate": 0.06708765349115756,
      "loss": 2.8703,
      "step": 204800
    },
    {
      "epoch": 329.29,
      "learning_rate": 0.0670844380602894,
      "loss": 2.8692,
      "step": 204820
    },
    {
      "epoch": 329.32,
      "learning_rate": 0.06708122262942123,
      "loss": 2.8504,
      "step": 204840
    },
    {
      "epoch": 329.36,
      "learning_rate": 0.06707800719855306,
      "loss": 2.8522,
      "step": 204860
    },
    {
      "epoch": 329.39,
      "learning_rate": 0.0670747917676849,
      "loss": 2.8418,
      "step": 204880
    },
    {
      "epoch": 329.42,
      "learning_rate": 0.06707157633681672,
      "loss": 2.8262,
      "step": 204900
    },
    {
      "epoch": 329.45,
      "learning_rate": 0.06706836090594856,
      "loss": 2.8556,
      "step": 204920
    },
    {
      "epoch": 329.49,
      "learning_rate": 0.0670651454750804,
      "loss": 2.8503,
      "step": 204940
    },
    {
      "epoch": 329.52,
      "learning_rate": 0.06706193004421222,
      "loss": 2.8129,
      "step": 204960
    },
    {
      "epoch": 329.55,
      "learning_rate": 0.06705871461334405,
      "loss": 2.8287,
      "step": 204980
    },
    {
      "epoch": 329.58,
      "learning_rate": 0.06705549918247589,
      "loss": 2.8612,
      "step": 205000
    },
    {
      "epoch": 329.61,
      "learning_rate": 0.06705228375160772,
      "loss": 2.843,
      "step": 205020
    },
    {
      "epoch": 329.65,
      "learning_rate": 0.06704906832073955,
      "loss": 2.8592,
      "step": 205040
    },
    {
      "epoch": 329.68,
      "learning_rate": 0.06704585288987139,
      "loss": 2.855,
      "step": 205060
    },
    {
      "epoch": 329.71,
      "learning_rate": 0.06704263745900323,
      "loss": 2.815,
      "step": 205080
    },
    {
      "epoch": 329.74,
      "learning_rate": 0.06703942202813505,
      "loss": 2.8752,
      "step": 205100
    },
    {
      "epoch": 329.77,
      "learning_rate": 0.06703620659726689,
      "loss": 2.8402,
      "step": 205120
    },
    {
      "epoch": 329.81,
      "learning_rate": 0.06703299116639871,
      "loss": 2.8329,
      "step": 205140
    },
    {
      "epoch": 329.84,
      "learning_rate": 0.06702977573553055,
      "loss": 2.8649,
      "step": 205160
    },
    {
      "epoch": 329.87,
      "learning_rate": 0.06702656030466239,
      "loss": 2.8408,
      "step": 205180
    },
    {
      "epoch": 329.9,
      "learning_rate": 0.06702334487379422,
      "loss": 2.845,
      "step": 205200
    },
    {
      "epoch": 329.94,
      "learning_rate": 0.06702012944292605,
      "loss": 2.8509,
      "step": 205220
    },
    {
      "epoch": 329.97,
      "learning_rate": 0.06701691401205788,
      "loss": 2.8386,
      "step": 205240
    },
    {
      "epoch": 330.0,
      "learning_rate": 0.06701369858118972,
      "loss": 2.8648,
      "step": 205260
    },
    {
      "epoch": 330.0,
      "eval_accuracy": {
        "accuracy": 0.3902666563010184
      },
      "eval_loss": 2.967103958129883,
      "eval_runtime": 2.8541,
      "eval_samples_per_second": 4506.875,
      "eval_steps_per_second": 70.425,
      "step": 205260
    },
    {
      "epoch": 330.03,
      "learning_rate": 0.06701048315032156,
      "loss": 2.8415,
      "step": 205280
    },
    {
      "epoch": 330.06,
      "learning_rate": 0.06700726771945338,
      "loss": 2.8183,
      "step": 205300
    },
    {
      "epoch": 330.1,
      "learning_rate": 0.0670040522885852,
      "loss": 2.8306,
      "step": 205320
    },
    {
      "epoch": 330.13,
      "learning_rate": 0.06700083685771704,
      "loss": 2.8307,
      "step": 205340
    },
    {
      "epoch": 330.16,
      "learning_rate": 0.06699762142684888,
      "loss": 2.8153,
      "step": 205360
    },
    {
      "epoch": 330.19,
      "learning_rate": 0.06699440599598071,
      "loss": 2.8544,
      "step": 205380
    },
    {
      "epoch": 330.23,
      "learning_rate": 0.06699119056511255,
      "loss": 2.8222,
      "step": 205400
    },
    {
      "epoch": 330.26,
      "learning_rate": 0.06698797513424437,
      "loss": 2.8272,
      "step": 205420
    },
    {
      "epoch": 330.29,
      "learning_rate": 0.06698475970337621,
      "loss": 2.8161,
      "step": 205440
    },
    {
      "epoch": 330.32,
      "learning_rate": 0.06698154427250805,
      "loss": 2.8362,
      "step": 205460
    },
    {
      "epoch": 330.35,
      "learning_rate": 0.06697832884163987,
      "loss": 2.8361,
      "step": 205480
    },
    {
      "epoch": 330.39,
      "learning_rate": 0.06697511341077171,
      "loss": 2.8523,
      "step": 205500
    },
    {
      "epoch": 330.42,
      "learning_rate": 0.06697189797990354,
      "loss": 2.8763,
      "step": 205520
    },
    {
      "epoch": 330.45,
      "learning_rate": 0.06696868254903537,
      "loss": 2.8791,
      "step": 205540
    },
    {
      "epoch": 330.48,
      "learning_rate": 0.06696546711816721,
      "loss": 2.844,
      "step": 205560
    },
    {
      "epoch": 330.51,
      "learning_rate": 0.06696225168729904,
      "loss": 2.8544,
      "step": 205580
    },
    {
      "epoch": 330.55,
      "learning_rate": 0.06695903625643088,
      "loss": 2.8547,
      "step": 205600
    },
    {
      "epoch": 330.58,
      "learning_rate": 0.0669558208255627,
      "loss": 2.8773,
      "step": 205620
    },
    {
      "epoch": 330.61,
      "learning_rate": 0.06695260539469454,
      "loss": 2.8589,
      "step": 205640
    },
    {
      "epoch": 330.64,
      "learning_rate": 0.06694938996382636,
      "loss": 2.8318,
      "step": 205660
    },
    {
      "epoch": 330.68,
      "learning_rate": 0.0669461745329582,
      "loss": 2.8404,
      "step": 205680
    },
    {
      "epoch": 330.71,
      "learning_rate": 0.06694295910209004,
      "loss": 2.8202,
      "step": 205700
    },
    {
      "epoch": 330.74,
      "learning_rate": 0.06693974367122187,
      "loss": 2.8015,
      "step": 205720
    },
    {
      "epoch": 330.77,
      "learning_rate": 0.0669365282403537,
      "loss": 2.8313,
      "step": 205740
    },
    {
      "epoch": 330.8,
      "learning_rate": 0.06693331280948553,
      "loss": 2.8643,
      "step": 205760
    },
    {
      "epoch": 330.84,
      "learning_rate": 0.06693009737861737,
      "loss": 2.8282,
      "step": 205780
    },
    {
      "epoch": 330.87,
      "learning_rate": 0.0669268819477492,
      "loss": 2.8643,
      "step": 205800
    },
    {
      "epoch": 330.9,
      "learning_rate": 0.06692366651688103,
      "loss": 2.8231,
      "step": 205820
    },
    {
      "epoch": 330.93,
      "learning_rate": 0.06692045108601287,
      "loss": 2.8423,
      "step": 205840
    },
    {
      "epoch": 330.96,
      "learning_rate": 0.0669172356551447,
      "loss": 2.8779,
      "step": 205860
    },
    {
      "epoch": 331.0,
      "learning_rate": 0.06691402022427653,
      "loss": 2.893,
      "step": 205880
    },
    {
      "epoch": 331.0,
      "eval_accuracy": {
        "accuracy": 0.39065536811008317
      },
      "eval_loss": 2.947262763977051,
      "eval_runtime": 3.9332,
      "eval_samples_per_second": 3270.386,
      "eval_steps_per_second": 51.104,
      "step": 205882
    },
    {
      "epoch": 331.03,
      "learning_rate": 0.06691080479340837,
      "loss": 2.8516,
      "step": 205900
    },
    {
      "epoch": 331.06,
      "learning_rate": 0.0669075893625402,
      "loss": 2.797,
      "step": 205920
    },
    {
      "epoch": 331.09,
      "learning_rate": 0.06690437393167203,
      "loss": 2.8304,
      "step": 205940
    },
    {
      "epoch": 331.13,
      "learning_rate": 0.06690115850080386,
      "loss": 2.8336,
      "step": 205960
    },
    {
      "epoch": 331.16,
      "learning_rate": 0.0668979430699357,
      "loss": 2.8374,
      "step": 205980
    },
    {
      "epoch": 331.19,
      "learning_rate": 0.06689472763906752,
      "loss": 2.8525,
      "step": 206000
    },
    {
      "epoch": 331.22,
      "learning_rate": 0.06689151220819936,
      "loss": 2.8701,
      "step": 206020
    },
    {
      "epoch": 331.25,
      "learning_rate": 0.0668882967773312,
      "loss": 2.8543,
      "step": 206040
    },
    {
      "epoch": 331.29,
      "learning_rate": 0.06688508134646302,
      "loss": 2.8747,
      "step": 206060
    },
    {
      "epoch": 331.32,
      "learning_rate": 0.06688186591559486,
      "loss": 2.8462,
      "step": 206080
    },
    {
      "epoch": 331.35,
      "learning_rate": 0.06687865048472669,
      "loss": 2.851,
      "step": 206100
    },
    {
      "epoch": 331.38,
      "learning_rate": 0.06687543505385853,
      "loss": 2.8162,
      "step": 206120
    },
    {
      "epoch": 331.41,
      "learning_rate": 0.06687221962299036,
      "loss": 2.8482,
      "step": 206140
    },
    {
      "epoch": 331.45,
      "learning_rate": 0.06686900419212219,
      "loss": 2.8427,
      "step": 206160
    },
    {
      "epoch": 331.48,
      "learning_rate": 0.06686578876125403,
      "loss": 2.8493,
      "step": 206180
    },
    {
      "epoch": 331.51,
      "learning_rate": 0.06686257333038585,
      "loss": 2.848,
      "step": 206200
    },
    {
      "epoch": 331.54,
      "learning_rate": 0.06685935789951769,
      "loss": 2.8231,
      "step": 206220
    },
    {
      "epoch": 331.58,
      "learning_rate": 0.06685614246864953,
      "loss": 2.8193,
      "step": 206240
    },
    {
      "epoch": 331.61,
      "learning_rate": 0.06685292703778135,
      "loss": 2.8417,
      "step": 206260
    },
    {
      "epoch": 331.64,
      "learning_rate": 0.06684971160691319,
      "loss": 2.8694,
      "step": 206280
    },
    {
      "epoch": 331.67,
      "learning_rate": 0.06684649617604502,
      "loss": 2.8663,
      "step": 206300
    },
    {
      "epoch": 331.7,
      "learning_rate": 0.06684328074517686,
      "loss": 2.8229,
      "step": 206320
    },
    {
      "epoch": 331.74,
      "learning_rate": 0.06684006531430868,
      "loss": 2.8413,
      "step": 206340
    },
    {
      "epoch": 331.77,
      "learning_rate": 0.06683684988344052,
      "loss": 2.833,
      "step": 206360
    },
    {
      "epoch": 331.8,
      "learning_rate": 0.06683363445257236,
      "loss": 2.8248,
      "step": 206380
    },
    {
      "epoch": 331.83,
      "learning_rate": 0.06683041902170418,
      "loss": 2.8411,
      "step": 206400
    },
    {
      "epoch": 331.86,
      "learning_rate": 0.06682720359083602,
      "loss": 2.814,
      "step": 206420
    },
    {
      "epoch": 331.9,
      "learning_rate": 0.06682398815996785,
      "loss": 2.8442,
      "step": 206440
    },
    {
      "epoch": 331.93,
      "learning_rate": 0.06682077272909968,
      "loss": 2.8597,
      "step": 206460
    },
    {
      "epoch": 331.96,
      "learning_rate": 0.06681771806977492,
      "loss": 2.8588,
      "step": 206480
    },
    {
      "epoch": 331.99,
      "learning_rate": 0.06681450263890676,
      "loss": 2.8584,
      "step": 206500
    },
    {
      "epoch": 332.0,
      "eval_accuracy": {
        "accuracy": 0.39376506258260124
      },
      "eval_loss": 2.956172227859497,
      "eval_runtime": 3.459,
      "eval_samples_per_second": 3718.668,
      "eval_steps_per_second": 58.109,
      "step": 206504
    },
    {
      "epoch": 332.03,
      "learning_rate": 0.06681128720803858,
      "loss": 2.8767,
      "step": 206520
    },
    {
      "epoch": 332.06,
      "learning_rate": 0.06680807177717042,
      "loss": 2.8324,
      "step": 206540
    },
    {
      "epoch": 332.09,
      "learning_rate": 0.06680485634630226,
      "loss": 2.811,
      "step": 206560
    },
    {
      "epoch": 332.12,
      "learning_rate": 0.06680164091543409,
      "loss": 2.8042,
      "step": 206580
    },
    {
      "epoch": 332.15,
      "learning_rate": 0.06679842548456592,
      "loss": 2.8287,
      "step": 206600
    },
    {
      "epoch": 332.19,
      "learning_rate": 0.06679521005369775,
      "loss": 2.8321,
      "step": 206620
    },
    {
      "epoch": 332.22,
      "learning_rate": 0.06679199462282959,
      "loss": 2.8149,
      "step": 206640
    },
    {
      "epoch": 332.25,
      "learning_rate": 0.06678877919196143,
      "loss": 2.8137,
      "step": 206660
    },
    {
      "epoch": 332.28,
      "learning_rate": 0.06678556376109325,
      "loss": 2.8736,
      "step": 206680
    },
    {
      "epoch": 332.32,
      "learning_rate": 0.06678234833022509,
      "loss": 2.8627,
      "step": 206700
    },
    {
      "epoch": 332.35,
      "learning_rate": 0.06677913289935691,
      "loss": 2.8299,
      "step": 206720
    },
    {
      "epoch": 332.38,
      "learning_rate": 0.06677591746848875,
      "loss": 2.8708,
      "step": 206740
    },
    {
      "epoch": 332.41,
      "learning_rate": 0.06677270203762058,
      "loss": 2.8535,
      "step": 206760
    },
    {
      "epoch": 332.44,
      "learning_rate": 0.06676948660675242,
      "loss": 2.8272,
      "step": 206780
    },
    {
      "epoch": 332.48,
      "learning_rate": 0.06676627117588425,
      "loss": 2.8514,
      "step": 206800
    },
    {
      "epoch": 332.51,
      "learning_rate": 0.06676305574501608,
      "loss": 2.8517,
      "step": 206820
    },
    {
      "epoch": 332.54,
      "learning_rate": 0.06675984031414792,
      "loss": 2.8615,
      "step": 206840
    },
    {
      "epoch": 332.57,
      "learning_rate": 0.06675662488327974,
      "loss": 2.8568,
      "step": 206860
    },
    {
      "epoch": 332.6,
      "learning_rate": 0.06675340945241158,
      "loss": 2.8759,
      "step": 206880
    },
    {
      "epoch": 332.64,
      "learning_rate": 0.06675019402154342,
      "loss": 2.8343,
      "step": 206900
    },
    {
      "epoch": 332.67,
      "learning_rate": 0.06674697859067524,
      "loss": 2.8355,
      "step": 206920
    },
    {
      "epoch": 332.7,
      "learning_rate": 0.06674376315980708,
      "loss": 2.8443,
      "step": 206940
    },
    {
      "epoch": 332.73,
      "learning_rate": 0.0667405477289389,
      "loss": 2.861,
      "step": 206960
    },
    {
      "epoch": 332.77,
      "learning_rate": 0.06673733229807075,
      "loss": 2.8559,
      "step": 206980
    },
    {
      "epoch": 332.8,
      "learning_rate": 0.06673411686720258,
      "loss": 2.8495,
      "step": 207000
    },
    {
      "epoch": 332.83,
      "learning_rate": 0.06673090143633441,
      "loss": 2.85,
      "step": 207020
    },
    {
      "epoch": 332.86,
      "learning_rate": 0.06672768600546625,
      "loss": 2.8593,
      "step": 207040
    },
    {
      "epoch": 332.89,
      "learning_rate": 0.06672447057459807,
      "loss": 2.836,
      "step": 207060
    },
    {
      "epoch": 332.93,
      "learning_rate": 0.06672125514372991,
      "loss": 2.8517,
      "step": 207080
    },
    {
      "epoch": 332.96,
      "learning_rate": 0.06671803971286173,
      "loss": 2.8446,
      "step": 207100
    },
    {
      "epoch": 332.99,
      "learning_rate": 0.06671482428199357,
      "loss": 2.8497,
      "step": 207120
    },
    {
      "epoch": 333.0,
      "eval_accuracy": {
        "accuracy": 0.3870792194666874
      },
      "eval_loss": 2.9605605602264404,
      "eval_runtime": 3.0116,
      "eval_samples_per_second": 4271.177,
      "eval_steps_per_second": 66.742,
      "step": 207126
    },
    {
      "epoch": 333.02,
      "learning_rate": 0.06671160885112541,
      "loss": 2.843,
      "step": 207140
    },
    {
      "epoch": 333.05,
      "learning_rate": 0.06670839342025724,
      "loss": 2.838,
      "step": 207160
    },
    {
      "epoch": 333.09,
      "learning_rate": 0.06670517798938908,
      "loss": 2.8327,
      "step": 207180
    },
    {
      "epoch": 333.12,
      "learning_rate": 0.0667019625585209,
      "loss": 2.8193,
      "step": 207200
    },
    {
      "epoch": 333.15,
      "learning_rate": 0.06669874712765274,
      "loss": 2.8447,
      "step": 207220
    },
    {
      "epoch": 333.18,
      "learning_rate": 0.06669553169678458,
      "loss": 2.8476,
      "step": 207240
    },
    {
      "epoch": 333.22,
      "learning_rate": 0.0666923162659164,
      "loss": 2.8824,
      "step": 207260
    },
    {
      "epoch": 333.25,
      "learning_rate": 0.06668910083504824,
      "loss": 2.8245,
      "step": 207280
    },
    {
      "epoch": 333.28,
      "learning_rate": 0.06668588540418006,
      "loss": 2.8288,
      "step": 207300
    },
    {
      "epoch": 333.31,
      "learning_rate": 0.0666826699733119,
      "loss": 2.8214,
      "step": 207320
    },
    {
      "epoch": 333.34,
      "learning_rate": 0.06667945454244374,
      "loss": 2.8591,
      "step": 207340
    },
    {
      "epoch": 333.38,
      "learning_rate": 0.06667623911157557,
      "loss": 2.8447,
      "step": 207360
    },
    {
      "epoch": 333.41,
      "learning_rate": 0.0666730236807074,
      "loss": 2.8655,
      "step": 207380
    },
    {
      "epoch": 333.44,
      "learning_rate": 0.06666980824983923,
      "loss": 2.8245,
      "step": 207400
    },
    {
      "epoch": 333.47,
      "learning_rate": 0.06666659281897107,
      "loss": 2.8054,
      "step": 207420
    },
    {
      "epoch": 333.5,
      "learning_rate": 0.06666337738810289,
      "loss": 2.7992,
      "step": 207440
    },
    {
      "epoch": 333.54,
      "learning_rate": 0.06666016195723473,
      "loss": 2.8219,
      "step": 207460
    },
    {
      "epoch": 333.57,
      "learning_rate": 0.06665694652636657,
      "loss": 2.8264,
      "step": 207480
    },
    {
      "epoch": 333.6,
      "learning_rate": 0.0666537310954984,
      "loss": 2.8406,
      "step": 207500
    },
    {
      "epoch": 333.63,
      "learning_rate": 0.06665051566463023,
      "loss": 2.8758,
      "step": 207520
    },
    {
      "epoch": 333.67,
      "learning_rate": 0.06664730023376206,
      "loss": 2.8806,
      "step": 207540
    },
    {
      "epoch": 333.7,
      "learning_rate": 0.0666440848028939,
      "loss": 2.8402,
      "step": 207560
    },
    {
      "epoch": 333.73,
      "learning_rate": 0.06664086937202574,
      "loss": 2.8249,
      "step": 207580
    },
    {
      "epoch": 333.76,
      "learning_rate": 0.06663765394115756,
      "loss": 2.8269,
      "step": 207600
    },
    {
      "epoch": 333.79,
      "learning_rate": 0.0666344385102894,
      "loss": 2.8088,
      "step": 207620
    },
    {
      "epoch": 333.83,
      "learning_rate": 0.06663122307942122,
      "loss": 2.8251,
      "step": 207640
    },
    {
      "epoch": 333.86,
      "learning_rate": 0.06662800764855306,
      "loss": 2.8137,
      "step": 207660
    },
    {
      "epoch": 333.89,
      "learning_rate": 0.0666247922176849,
      "loss": 2.8181,
      "step": 207680
    },
    {
      "epoch": 333.92,
      "learning_rate": 0.06662157678681672,
      "loss": 2.8399,
      "step": 207700
    },
    {
      "epoch": 333.95,
      "learning_rate": 0.06661836135594855,
      "loss": 2.8522,
      "step": 207720
    },
    {
      "epoch": 333.99,
      "learning_rate": 0.06661514592508039,
      "loss": 2.8217,
      "step": 207740
    },
    {
      "epoch": 334.0,
      "eval_accuracy": {
        "accuracy": 0.38995568685376664
      },
      "eval_loss": 2.9697115421295166,
      "eval_runtime": 3.1455,
      "eval_samples_per_second": 4089.292,
      "eval_steps_per_second": 63.9,
      "step": 207748
    },
    {
      "epoch": 334.02,
      "learning_rate": 0.06661193049421223,
      "loss": 2.8184,
      "step": 207760
    },
    {
      "epoch": 334.05,
      "learning_rate": 0.06660871506334405,
      "loss": 2.8687,
      "step": 207780
    },
    {
      "epoch": 334.08,
      "learning_rate": 0.06660549963247589,
      "loss": 2.8496,
      "step": 207800
    },
    {
      "epoch": 334.12,
      "learning_rate": 0.06660228420160771,
      "loss": 2.8351,
      "step": 207820
    },
    {
      "epoch": 334.15,
      "learning_rate": 0.06659906877073955,
      "loss": 2.8312,
      "step": 207840
    },
    {
      "epoch": 334.18,
      "learning_rate": 0.06659585333987139,
      "loss": 2.8332,
      "step": 207860
    },
    {
      "epoch": 334.21,
      "learning_rate": 0.06659263790900322,
      "loss": 2.8217,
      "step": 207880
    },
    {
      "epoch": 334.24,
      "learning_rate": 0.06658942247813505,
      "loss": 2.8364,
      "step": 207900
    },
    {
      "epoch": 334.28,
      "learning_rate": 0.0665862070472669,
      "loss": 2.8631,
      "step": 207920
    },
    {
      "epoch": 334.31,
      "learning_rate": 0.06658299161639872,
      "loss": 2.8126,
      "step": 207940
    },
    {
      "epoch": 334.34,
      "learning_rate": 0.06657977618553056,
      "loss": 2.8526,
      "step": 207960
    },
    {
      "epoch": 334.37,
      "learning_rate": 0.06657656075466238,
      "loss": 2.8483,
      "step": 207980
    },
    {
      "epoch": 334.41,
      "learning_rate": 0.06657334532379422,
      "loss": 2.8408,
      "step": 208000
    },
    {
      "epoch": 334.44,
      "learning_rate": 0.06657012989292606,
      "loss": 2.832,
      "step": 208020
    },
    {
      "epoch": 334.47,
      "learning_rate": 0.06656691446205788,
      "loss": 2.8317,
      "step": 208040
    },
    {
      "epoch": 334.5,
      "learning_rate": 0.06656369903118971,
      "loss": 2.8263,
      "step": 208060
    },
    {
      "epoch": 334.53,
      "learning_rate": 0.06656048360032155,
      "loss": 2.8445,
      "step": 208080
    },
    {
      "epoch": 334.57,
      "learning_rate": 0.06655726816945338,
      "loss": 2.857,
      "step": 208100
    },
    {
      "epoch": 334.6,
      "learning_rate": 0.06655405273858521,
      "loss": 2.849,
      "step": 208120
    },
    {
      "epoch": 334.63,
      "learning_rate": 0.06655083730771705,
      "loss": 2.844,
      "step": 208140
    },
    {
      "epoch": 334.66,
      "learning_rate": 0.06654762187684887,
      "loss": 2.8637,
      "step": 208160
    },
    {
      "epoch": 334.69,
      "learning_rate": 0.06654440644598071,
      "loss": 2.8514,
      "step": 208180
    },
    {
      "epoch": 334.73,
      "learning_rate": 0.06654119101511255,
      "loss": 2.8543,
      "step": 208200
    },
    {
      "epoch": 334.76,
      "learning_rate": 0.06653797558424437,
      "loss": 2.8335,
      "step": 208220
    },
    {
      "epoch": 334.79,
      "learning_rate": 0.06653476015337621,
      "loss": 2.8237,
      "step": 208240
    },
    {
      "epoch": 334.82,
      "learning_rate": 0.06653154472250804,
      "loss": 2.8542,
      "step": 208260
    },
    {
      "epoch": 334.86,
      "learning_rate": 0.06652832929163988,
      "loss": 2.8677,
      "step": 208280
    },
    {
      "epoch": 334.89,
      "learning_rate": 0.06652511386077171,
      "loss": 2.8648,
      "step": 208300
    },
    {
      "epoch": 334.92,
      "learning_rate": 0.06652189842990354,
      "loss": 2.8619,
      "step": 208320
    },
    {
      "epoch": 334.95,
      "learning_rate": 0.06651868299903538,
      "loss": 2.855,
      "step": 208340
    },
    {
      "epoch": 334.98,
      "learning_rate": 0.0665154675681672,
      "loss": 2.8349,
      "step": 208360
    },
    {
      "epoch": 335.0,
      "eval_accuracy": {
        "accuracy": 0.38762341599937805
      },
      "eval_loss": 2.987340211868286,
      "eval_runtime": 2.7313,
      "eval_samples_per_second": 4709.526,
      "eval_steps_per_second": 73.592,
      "step": 208370
    },
    {
      "epoch": 335.02,
      "learning_rate": 0.06651225213729904,
      "loss": 2.8323,
      "step": 208380
    },
    {
      "epoch": 335.05,
      "learning_rate": 0.06650903670643087,
      "loss": 2.8219,
      "step": 208400
    },
    {
      "epoch": 335.08,
      "learning_rate": 0.0665058212755627,
      "loss": 2.8502,
      "step": 208420
    },
    {
      "epoch": 335.11,
      "learning_rate": 0.06650260584469454,
      "loss": 2.8249,
      "step": 208440
    },
    {
      "epoch": 335.14,
      "learning_rate": 0.06649939041382637,
      "loss": 2.8246,
      "step": 208460
    },
    {
      "epoch": 335.18,
      "learning_rate": 0.0664961749829582,
      "loss": 2.8146,
      "step": 208480
    },
    {
      "epoch": 335.21,
      "learning_rate": 0.06649295955209003,
      "loss": 2.8297,
      "step": 208500
    },
    {
      "epoch": 335.24,
      "learning_rate": 0.06648974412122187,
      "loss": 2.8166,
      "step": 208520
    },
    {
      "epoch": 335.27,
      "learning_rate": 0.0664866894618971,
      "loss": 2.8218,
      "step": 208540
    },
    {
      "epoch": 335.31,
      "learning_rate": 0.06648347403102894,
      "loss": 2.8644,
      "step": 208560
    },
    {
      "epoch": 335.34,
      "learning_rate": 0.06648025860016077,
      "loss": 2.8827,
      "step": 208580
    },
    {
      "epoch": 335.37,
      "learning_rate": 0.06647704316929261,
      "loss": 2.8226,
      "step": 208600
    },
    {
      "epoch": 335.4,
      "learning_rate": 0.06647382773842445,
      "loss": 2.8316,
      "step": 208620
    },
    {
      "epoch": 335.43,
      "learning_rate": 0.06647061230755627,
      "loss": 2.8317,
      "step": 208640
    },
    {
      "epoch": 335.47,
      "learning_rate": 0.06646739687668811,
      "loss": 2.8372,
      "step": 208660
    },
    {
      "epoch": 335.5,
      "learning_rate": 0.06646418144581993,
      "loss": 2.8259,
      "step": 208680
    },
    {
      "epoch": 335.53,
      "learning_rate": 0.06646096601495177,
      "loss": 2.8374,
      "step": 208700
    },
    {
      "epoch": 335.56,
      "learning_rate": 0.06645775058408361,
      "loss": 2.8727,
      "step": 208720
    },
    {
      "epoch": 335.59,
      "learning_rate": 0.06645453515321544,
      "loss": 2.8518,
      "step": 208740
    },
    {
      "epoch": 335.63,
      "learning_rate": 0.06645131972234727,
      "loss": 2.8337,
      "step": 208760
    },
    {
      "epoch": 335.66,
      "learning_rate": 0.0664481042914791,
      "loss": 2.8372,
      "step": 208780
    },
    {
      "epoch": 335.69,
      "learning_rate": 0.06644488886061094,
      "loss": 2.8571,
      "step": 208800
    },
    {
      "epoch": 335.72,
      "learning_rate": 0.06644167342974276,
      "loss": 2.8435,
      "step": 208820
    },
    {
      "epoch": 335.76,
      "learning_rate": 0.0664384579988746,
      "loss": 2.8544,
      "step": 208840
    },
    {
      "epoch": 335.79,
      "learning_rate": 0.06643524256800644,
      "loss": 2.822,
      "step": 208860
    },
    {
      "epoch": 335.82,
      "learning_rate": 0.06643202713713826,
      "loss": 2.8147,
      "step": 208880
    },
    {
      "epoch": 335.85,
      "learning_rate": 0.0664288117062701,
      "loss": 2.8382,
      "step": 208900
    },
    {
      "epoch": 335.88,
      "learning_rate": 0.06642559627540193,
      "loss": 2.8159,
      "step": 208920
    },
    {
      "epoch": 335.92,
      "learning_rate": 0.06642238084453377,
      "loss": 2.8484,
      "step": 208940
    },
    {
      "epoch": 335.95,
      "learning_rate": 0.0664191654136656,
      "loss": 2.8567,
      "step": 208960
    },
    {
      "epoch": 335.98,
      "learning_rate": 0.06641594998279743,
      "loss": 2.8432,
      "step": 208980
    },
    {
      "epoch": 336.0,
      "eval_accuracy": {
        "accuracy": 0.39446474383891783
      },
      "eval_loss": 2.9474782943725586,
      "eval_runtime": 2.763,
      "eval_samples_per_second": 4655.46,
      "eval_steps_per_second": 72.747,
      "step": 208992
    },
    {
      "epoch": 336.01,
      "learning_rate": 0.06641273455192927,
      "loss": 2.815,
      "step": 209000
    },
    {
      "epoch": 336.05,
      "learning_rate": 0.06640951912106109,
      "loss": 2.8152,
      "step": 209020
    },
    {
      "epoch": 336.08,
      "learning_rate": 0.06640630369019293,
      "loss": 2.8222,
      "step": 209040
    },
    {
      "epoch": 336.11,
      "learning_rate": 0.06640308825932477,
      "loss": 2.82,
      "step": 209060
    },
    {
      "epoch": 336.14,
      "learning_rate": 0.0663998728284566,
      "loss": 2.8097,
      "step": 209080
    },
    {
      "epoch": 336.17,
      "learning_rate": 0.06639665739758843,
      "loss": 2.8286,
      "step": 209100
    },
    {
      "epoch": 336.21,
      "learning_rate": 0.06639344196672026,
      "loss": 2.8272,
      "step": 209120
    },
    {
      "epoch": 336.24,
      "learning_rate": 0.0663902265358521,
      "loss": 2.8448,
      "step": 209140
    },
    {
      "epoch": 336.27,
      "learning_rate": 0.06638701110498392,
      "loss": 2.849,
      "step": 209160
    },
    {
      "epoch": 336.3,
      "learning_rate": 0.06638379567411576,
      "loss": 2.8152,
      "step": 209180
    },
    {
      "epoch": 336.33,
      "learning_rate": 0.0663805802432476,
      "loss": 2.8152,
      "step": 209200
    },
    {
      "epoch": 336.37,
      "learning_rate": 0.06637736481237942,
      "loss": 2.8449,
      "step": 209220
    },
    {
      "epoch": 336.4,
      "learning_rate": 0.06637414938151126,
      "loss": 2.8481,
      "step": 209240
    },
    {
      "epoch": 336.43,
      "learning_rate": 0.06637093395064309,
      "loss": 2.8222,
      "step": 209260
    },
    {
      "epoch": 336.46,
      "learning_rate": 0.06636771851977492,
      "loss": 2.8376,
      "step": 209280
    },
    {
      "epoch": 336.5,
      "learning_rate": 0.06636450308890676,
      "loss": 2.8525,
      "step": 209300
    },
    {
      "epoch": 336.53,
      "learning_rate": 0.06636128765803859,
      "loss": 2.8553,
      "step": 209320
    },
    {
      "epoch": 336.56,
      "learning_rate": 0.06635807222717043,
      "loss": 2.821,
      "step": 209340
    },
    {
      "epoch": 336.59,
      "learning_rate": 0.06635485679630225,
      "loss": 2.8149,
      "step": 209360
    },
    {
      "epoch": 336.62,
      "learning_rate": 0.06635164136543409,
      "loss": 2.8391,
      "step": 209380
    },
    {
      "epoch": 336.66,
      "learning_rate": 0.06634842593456593,
      "loss": 2.8049,
      "step": 209400
    },
    {
      "epoch": 336.69,
      "learning_rate": 0.06634521050369775,
      "loss": 2.818,
      "step": 209420
    },
    {
      "epoch": 336.72,
      "learning_rate": 0.06634199507282959,
      "loss": 2.8483,
      "step": 209440
    },
    {
      "epoch": 336.75,
      "learning_rate": 0.06633877964196142,
      "loss": 2.8529,
      "step": 209460
    },
    {
      "epoch": 336.78,
      "learning_rate": 0.06633556421109325,
      "loss": 2.8159,
      "step": 209480
    },
    {
      "epoch": 336.82,
      "learning_rate": 0.06633234878022508,
      "loss": 2.8684,
      "step": 209500
    },
    {
      "epoch": 336.85,
      "learning_rate": 0.06632913334935692,
      "loss": 2.8266,
      "step": 209520
    },
    {
      "epoch": 336.88,
      "learning_rate": 0.06632591791848876,
      "loss": 2.8362,
      "step": 209540
    },
    {
      "epoch": 336.91,
      "learning_rate": 0.06632270248762058,
      "loss": 2.855,
      "step": 209560
    },
    {
      "epoch": 336.95,
      "learning_rate": 0.06631948705675242,
      "loss": 2.8345,
      "step": 209580
    },
    {
      "epoch": 336.98,
      "learning_rate": 0.06631627162588424,
      "loss": 2.8365,
      "step": 209600
    },
    {
      "epoch": 337.0,
      "eval_accuracy": {
        "accuracy": 0.3905776257482702
      },
      "eval_loss": 2.953866481781006,
      "eval_runtime": 2.7934,
      "eval_samples_per_second": 4604.745,
      "eval_steps_per_second": 71.955,
      "step": 209614
    },
    {
      "epoch": 337.01,
      "learning_rate": 0.06631305619501608,
      "loss": 2.8275,
      "step": 209620
    },
    {
      "epoch": 337.04,
      "learning_rate": 0.06630984076414792,
      "loss": 2.8525,
      "step": 209640
    },
    {
      "epoch": 337.07,
      "learning_rate": 0.06630662533327975,
      "loss": 2.8503,
      "step": 209660
    },
    {
      "epoch": 337.11,
      "learning_rate": 0.06630340990241158,
      "loss": 2.8358,
      "step": 209680
    },
    {
      "epoch": 337.14,
      "learning_rate": 0.06630019447154341,
      "loss": 2.8581,
      "step": 209700
    },
    {
      "epoch": 337.17,
      "learning_rate": 0.06629697904067525,
      "loss": 2.8452,
      "step": 209720
    },
    {
      "epoch": 337.2,
      "learning_rate": 0.06629376360980709,
      "loss": 2.8202,
      "step": 209740
    },
    {
      "epoch": 337.23,
      "learning_rate": 0.06629054817893891,
      "loss": 2.8596,
      "step": 209760
    },
    {
      "epoch": 337.27,
      "learning_rate": 0.06628733274807075,
      "loss": 2.8494,
      "step": 209780
    },
    {
      "epoch": 337.3,
      "learning_rate": 0.06628411731720257,
      "loss": 2.8475,
      "step": 209800
    },
    {
      "epoch": 337.33,
      "learning_rate": 0.06628090188633441,
      "loss": 2.8692,
      "step": 209820
    },
    {
      "epoch": 337.36,
      "learning_rate": 0.06627768645546624,
      "loss": 2.8702,
      "step": 209840
    },
    {
      "epoch": 337.4,
      "learning_rate": 0.06627447102459808,
      "loss": 2.8185,
      "step": 209860
    },
    {
      "epoch": 337.43,
      "learning_rate": 0.06627125559372991,
      "loss": 2.8087,
      "step": 209880
    },
    {
      "epoch": 337.46,
      "learning_rate": 0.06626804016286174,
      "loss": 2.8692,
      "step": 209900
    },
    {
      "epoch": 337.49,
      "learning_rate": 0.06626482473199358,
      "loss": 2.8565,
      "step": 209920
    },
    {
      "epoch": 337.52,
      "learning_rate": 0.0662616093011254,
      "loss": 2.8334,
      "step": 209940
    },
    {
      "epoch": 337.56,
      "learning_rate": 0.06625839387025724,
      "loss": 2.8285,
      "step": 209960
    },
    {
      "epoch": 337.59,
      "learning_rate": 0.06625517843938908,
      "loss": 2.8307,
      "step": 209980
    },
    {
      "epoch": 337.62,
      "learning_rate": 0.0662519630085209,
      "loss": 2.832,
      "step": 210000
    },
    {
      "epoch": 337.65,
      "learning_rate": 0.06624874757765274,
      "loss": 2.8144,
      "step": 210020
    },
    {
      "epoch": 337.68,
      "learning_rate": 0.06624553214678457,
      "loss": 2.8244,
      "step": 210040
    },
    {
      "epoch": 337.72,
      "learning_rate": 0.0662423167159164,
      "loss": 2.808,
      "step": 210060
    },
    {
      "epoch": 337.75,
      "learning_rate": 0.06623910128504824,
      "loss": 2.8392,
      "step": 210080
    },
    {
      "epoch": 337.78,
      "learning_rate": 0.06623588585418007,
      "loss": 2.8333,
      "step": 210100
    },
    {
      "epoch": 337.81,
      "learning_rate": 0.0662326704233119,
      "loss": 2.8211,
      "step": 210120
    },
    {
      "epoch": 337.85,
      "learning_rate": 0.06622945499244373,
      "loss": 2.8142,
      "step": 210140
    },
    {
      "epoch": 337.88,
      "learning_rate": 0.06622623956157557,
      "loss": 2.8136,
      "step": 210160
    },
    {
      "epoch": 337.91,
      "learning_rate": 0.0662230241307074,
      "loss": 2.7945,
      "step": 210180
    },
    {
      "epoch": 337.94,
      "learning_rate": 0.06621980869983923,
      "loss": 2.8685,
      "step": 210200
    },
    {
      "epoch": 337.97,
      "learning_rate": 0.06621659326897107,
      "loss": 2.8407,
      "step": 210220
    },
    {
      "epoch": 338.0,
      "eval_accuracy": {
        "accuracy": 0.38575759931586723
      },
      "eval_loss": 2.9847164154052734,
      "eval_runtime": 2.761,
      "eval_samples_per_second": 4658.835,
      "eval_steps_per_second": 72.8,
      "step": 210236
    },
    {
      "epoch": 338.01,
      "learning_rate": 0.0662133778381029,
      "loss": 2.8506,
      "step": 210240
    },
    {
      "epoch": 338.04,
      "learning_rate": 0.06621016240723474,
      "loss": 2.8442,
      "step": 210260
    },
    {
      "epoch": 338.07,
      "learning_rate": 0.06620694697636656,
      "loss": 2.8286,
      "step": 210280
    },
    {
      "epoch": 338.1,
      "learning_rate": 0.0662037315454984,
      "loss": 2.8353,
      "step": 210300
    },
    {
      "epoch": 338.14,
      "learning_rate": 0.06620051611463024,
      "loss": 2.8465,
      "step": 210320
    },
    {
      "epoch": 338.17,
      "learning_rate": 0.06619730068376206,
      "loss": 2.8272,
      "step": 210340
    },
    {
      "epoch": 338.2,
      "learning_rate": 0.0661940852528939,
      "loss": 2.8297,
      "step": 210360
    },
    {
      "epoch": 338.23,
      "learning_rate": 0.06619086982202572,
      "loss": 2.8166,
      "step": 210380
    },
    {
      "epoch": 338.26,
      "learning_rate": 0.06618765439115756,
      "loss": 2.8547,
      "step": 210400
    },
    {
      "epoch": 338.3,
      "learning_rate": 0.0661844389602894,
      "loss": 2.8374,
      "step": 210420
    },
    {
      "epoch": 338.33,
      "learning_rate": 0.06618122352942123,
      "loss": 2.8366,
      "step": 210440
    },
    {
      "epoch": 338.36,
      "learning_rate": 0.06617800809855305,
      "loss": 2.8595,
      "step": 210460
    },
    {
      "epoch": 338.39,
      "learning_rate": 0.06617479266768489,
      "loss": 2.8224,
      "step": 210480
    },
    {
      "epoch": 338.42,
      "learning_rate": 0.06617157723681673,
      "loss": 2.7916,
      "step": 210500
    },
    {
      "epoch": 338.46,
      "learning_rate": 0.06616836180594855,
      "loss": 2.8471,
      "step": 210520
    },
    {
      "epoch": 338.49,
      "learning_rate": 0.06616514637508039,
      "loss": 2.8686,
      "step": 210540
    },
    {
      "epoch": 338.52,
      "learning_rate": 0.06616209171575563,
      "loss": 2.8375,
      "step": 210560
    },
    {
      "epoch": 338.55,
      "learning_rate": 0.06615887628488747,
      "loss": 2.8278,
      "step": 210580
    },
    {
      "epoch": 338.59,
      "learning_rate": 0.06615566085401929,
      "loss": 2.8553,
      "step": 210600
    },
    {
      "epoch": 338.62,
      "learning_rate": 0.06615244542315114,
      "loss": 2.8447,
      "step": 210620
    },
    {
      "epoch": 338.65,
      "learning_rate": 0.06614922999228295,
      "loss": 2.8298,
      "step": 210640
    },
    {
      "epoch": 338.68,
      "learning_rate": 0.06614601456141479,
      "loss": 2.8438,
      "step": 210660
    },
    {
      "epoch": 338.71,
      "learning_rate": 0.06614279913054663,
      "loss": 2.8481,
      "step": 210680
    },
    {
      "epoch": 338.75,
      "learning_rate": 0.06613958369967846,
      "loss": 2.8242,
      "step": 210700
    },
    {
      "epoch": 338.78,
      "learning_rate": 0.0661363682688103,
      "loss": 2.8098,
      "step": 210720
    },
    {
      "epoch": 338.81,
      "learning_rate": 0.06613315283794212,
      "loss": 2.8006,
      "step": 210740
    },
    {
      "epoch": 338.84,
      "learning_rate": 0.06612993740707396,
      "loss": 2.8405,
      "step": 210760
    },
    {
      "epoch": 338.87,
      "learning_rate": 0.06612672197620578,
      "loss": 2.8381,
      "step": 210780
    },
    {
      "epoch": 338.91,
      "learning_rate": 0.06612350654533762,
      "loss": 2.8517,
      "step": 210800
    },
    {
      "epoch": 338.94,
      "learning_rate": 0.06612029111446946,
      "loss": 2.8481,
      "step": 210820
    },
    {
      "epoch": 338.97,
      "learning_rate": 0.06611707568360128,
      "loss": 2.82,
      "step": 210840
    },
    {
      "epoch": 339.0,
      "eval_accuracy": {
        "accuracy": 0.3964083028842416
      },
      "eval_loss": 2.9382519721984863,
      "eval_runtime": 2.8823,
      "eval_samples_per_second": 4462.749,
      "eval_steps_per_second": 69.736,
      "step": 210858
    },
    {
      "epoch": 339.0,
      "learning_rate": 0.06611386025273314,
      "loss": 2.8444,
      "step": 210860
    },
    {
      "epoch": 339.04,
      "learning_rate": 0.06611064482186495,
      "loss": 2.813,
      "step": 210880
    },
    {
      "epoch": 339.07,
      "learning_rate": 0.06610742939099679,
      "loss": 2.8246,
      "step": 210900
    },
    {
      "epoch": 339.1,
      "learning_rate": 0.06610421396012862,
      "loss": 2.8342,
      "step": 210920
    },
    {
      "epoch": 339.13,
      "learning_rate": 0.06610099852926045,
      "loss": 2.8313,
      "step": 210940
    },
    {
      "epoch": 339.16,
      "learning_rate": 0.0660977830983923,
      "loss": 2.8758,
      "step": 210960
    },
    {
      "epoch": 339.2,
      "learning_rate": 0.06609456766752411,
      "loss": 2.8209,
      "step": 210980
    },
    {
      "epoch": 339.23,
      "learning_rate": 0.06609135223665595,
      "loss": 2.8573,
      "step": 211000
    },
    {
      "epoch": 339.26,
      "learning_rate": 0.06608813680578779,
      "loss": 2.8315,
      "step": 211020
    },
    {
      "epoch": 339.29,
      "learning_rate": 0.06608492137491961,
      "loss": 2.8536,
      "step": 211040
    },
    {
      "epoch": 339.32,
      "learning_rate": 0.06608170594405145,
      "loss": 2.8304,
      "step": 211060
    },
    {
      "epoch": 339.36,
      "learning_rate": 0.06607849051318328,
      "loss": 2.8266,
      "step": 211080
    },
    {
      "epoch": 339.39,
      "learning_rate": 0.06607527508231512,
      "loss": 2.8106,
      "step": 211100
    },
    {
      "epoch": 339.42,
      "learning_rate": 0.06607205965144695,
      "loss": 2.8171,
      "step": 211120
    },
    {
      "epoch": 339.45,
      "learning_rate": 0.06606884422057878,
      "loss": 2.8228,
      "step": 211140
    },
    {
      "epoch": 339.49,
      "learning_rate": 0.06606562878971062,
      "loss": 2.8086,
      "step": 211160
    },
    {
      "epoch": 339.52,
      "learning_rate": 0.06606241335884244,
      "loss": 2.8228,
      "step": 211180
    },
    {
      "epoch": 339.55,
      "learning_rate": 0.06605919792797428,
      "loss": 2.843,
      "step": 211200
    },
    {
      "epoch": 339.58,
      "learning_rate": 0.0660559824971061,
      "loss": 2.8583,
      "step": 211220
    },
    {
      "epoch": 339.61,
      "learning_rate": 0.06605276706623794,
      "loss": 2.8345,
      "step": 211240
    },
    {
      "epoch": 339.65,
      "learning_rate": 0.06604955163536978,
      "loss": 2.8084,
      "step": 211260
    },
    {
      "epoch": 339.68,
      "learning_rate": 0.06604633620450161,
      "loss": 2.8265,
      "step": 211280
    },
    {
      "epoch": 339.71,
      "learning_rate": 0.06604312077363345,
      "loss": 2.8372,
      "step": 211300
    },
    {
      "epoch": 339.74,
      "learning_rate": 0.06603990534276527,
      "loss": 2.8693,
      "step": 211320
    },
    {
      "epoch": 339.77,
      "learning_rate": 0.06603668991189711,
      "loss": 2.8411,
      "step": 211340
    },
    {
      "epoch": 339.81,
      "learning_rate": 0.06603347448102895,
      "loss": 2.8216,
      "step": 211360
    },
    {
      "epoch": 339.84,
      "learning_rate": 0.06603025905016077,
      "loss": 2.8328,
      "step": 211380
    },
    {
      "epoch": 339.87,
      "learning_rate": 0.06602704361929261,
      "loss": 2.8298,
      "step": 211400
    },
    {
      "epoch": 339.9,
      "learning_rate": 0.06602382818842444,
      "loss": 2.8315,
      "step": 211420
    },
    {
      "epoch": 339.94,
      "learning_rate": 0.06602061275755627,
      "loss": 2.8253,
      "step": 211440
    },
    {
      "epoch": 339.97,
      "learning_rate": 0.06601739732668811,
      "loss": 2.8422,
      "step": 211460
    },
    {
      "epoch": 340.0,
      "learning_rate": 0.06601418189581994,
      "loss": 2.8016,
      "step": 211480
    },
    {
      "epoch": 340.0,
      "eval_accuracy": {
        "accuracy": 0.3842027520796082
      },
      "eval_loss": 2.9704086780548096,
      "eval_runtime": 2.761,
      "eval_samples_per_second": 4658.768,
      "eval_steps_per_second": 72.799,
      "step": 211480
    },
    {
      "epoch": 340.03,
      "learning_rate": 0.06601096646495178,
      "loss": 2.8388,
      "step": 211500
    },
    {
      "epoch": 340.06,
      "learning_rate": 0.0660077510340836,
      "loss": 2.8356,
      "step": 211520
    },
    {
      "epoch": 340.1,
      "learning_rate": 0.06600453560321544,
      "loss": 2.8586,
      "step": 211540
    },
    {
      "epoch": 340.13,
      "learning_rate": 0.06600132017234726,
      "loss": 2.8198,
      "step": 211560
    },
    {
      "epoch": 340.16,
      "learning_rate": 0.0659981047414791,
      "loss": 2.8284,
      "step": 211580
    },
    {
      "epoch": 340.19,
      "learning_rate": 0.06599488931061094,
      "loss": 2.8221,
      "step": 211600
    },
    {
      "epoch": 340.23,
      "learning_rate": 0.06599167387974277,
      "loss": 2.8141,
      "step": 211620
    },
    {
      "epoch": 340.26,
      "learning_rate": 0.0659884584488746,
      "loss": 2.8226,
      "step": 211640
    },
    {
      "epoch": 340.29,
      "learning_rate": 0.06598524301800643,
      "loss": 2.8632,
      "step": 211660
    },
    {
      "epoch": 340.32,
      "learning_rate": 0.06598202758713827,
      "loss": 2.8208,
      "step": 211680
    },
    {
      "epoch": 340.35,
      "learning_rate": 0.0659788121562701,
      "loss": 2.7906,
      "step": 211700
    },
    {
      "epoch": 340.39,
      "learning_rate": 0.06597559672540193,
      "loss": 2.8308,
      "step": 211720
    },
    {
      "epoch": 340.42,
      "learning_rate": 0.06597238129453377,
      "loss": 2.8414,
      "step": 211740
    },
    {
      "epoch": 340.45,
      "learning_rate": 0.0659691658636656,
      "loss": 2.8446,
      "step": 211760
    },
    {
      "epoch": 340.48,
      "learning_rate": 0.06596595043279743,
      "loss": 2.8474,
      "step": 211780
    },
    {
      "epoch": 340.51,
      "learning_rate": 0.06596273500192927,
      "loss": 2.8509,
      "step": 211800
    },
    {
      "epoch": 340.55,
      "learning_rate": 0.0659595195710611,
      "loss": 2.8442,
      "step": 211820
    },
    {
      "epoch": 340.58,
      "learning_rate": 0.06595630414019293,
      "loss": 2.8162,
      "step": 211840
    },
    {
      "epoch": 340.61,
      "learning_rate": 0.06595308870932476,
      "loss": 2.8443,
      "step": 211860
    },
    {
      "epoch": 340.64,
      "learning_rate": 0.0659498732784566,
      "loss": 2.8539,
      "step": 211880
    },
    {
      "epoch": 340.68,
      "learning_rate": 0.06594665784758842,
      "loss": 2.8491,
      "step": 211900
    },
    {
      "epoch": 340.71,
      "learning_rate": 0.06594344241672026,
      "loss": 2.8393,
      "step": 211920
    },
    {
      "epoch": 340.74,
      "learning_rate": 0.0659402269858521,
      "loss": 2.8621,
      "step": 211940
    },
    {
      "epoch": 340.77,
      "learning_rate": 0.06593701155498392,
      "loss": 2.8384,
      "step": 211960
    },
    {
      "epoch": 340.8,
      "learning_rate": 0.06593379612411576,
      "loss": 2.8175,
      "step": 211980
    },
    {
      "epoch": 340.84,
      "learning_rate": 0.06593058069324759,
      "loss": 2.8016,
      "step": 212000
    },
    {
      "epoch": 340.87,
      "learning_rate": 0.06592736526237943,
      "loss": 2.8214,
      "step": 212020
    },
    {
      "epoch": 340.9,
      "learning_rate": 0.06592414983151126,
      "loss": 2.806,
      "step": 212040
    },
    {
      "epoch": 340.93,
      "learning_rate": 0.06592093440064309,
      "loss": 2.8418,
      "step": 212060
    },
    {
      "epoch": 340.96,
      "learning_rate": 0.06591771896977493,
      "loss": 2.83,
      "step": 212080
    },
    {
      "epoch": 341.0,
      "learning_rate": 0.06591450353890675,
      "loss": 2.8413,
      "step": 212100
    },
    {
      "epoch": 341.0,
      "eval_accuracy": {
        "accuracy": 0.3898002021301407
      },
      "eval_loss": 2.994009494781494,
      "eval_runtime": 3.045,
      "eval_samples_per_second": 4224.348,
      "eval_steps_per_second": 66.011,
      "step": 212102
    },
    {
      "epoch": 341.03,
      "learning_rate": 0.06591128810803859,
      "loss": 2.8767,
      "step": 212120
    },
    {
      "epoch": 341.06,
      "learning_rate": 0.06590807267717043,
      "loss": 2.8755,
      "step": 212140
    },
    {
      "epoch": 341.09,
      "learning_rate": 0.06590485724630225,
      "loss": 2.8376,
      "step": 212160
    },
    {
      "epoch": 341.13,
      "learning_rate": 0.06590164181543409,
      "loss": 2.8238,
      "step": 212180
    },
    {
      "epoch": 341.16,
      "learning_rate": 0.06589842638456592,
      "loss": 2.8521,
      "step": 212200
    },
    {
      "epoch": 341.19,
      "learning_rate": 0.06589521095369776,
      "loss": 2.8285,
      "step": 212220
    },
    {
      "epoch": 341.22,
      "learning_rate": 0.06589199552282958,
      "loss": 2.8219,
      "step": 212240
    },
    {
      "epoch": 341.25,
      "learning_rate": 0.06588878009196142,
      "loss": 2.8184,
      "step": 212260
    },
    {
      "epoch": 341.29,
      "learning_rate": 0.06588556466109326,
      "loss": 2.7948,
      "step": 212280
    },
    {
      "epoch": 341.32,
      "learning_rate": 0.06588234923022508,
      "loss": 2.8208,
      "step": 212300
    },
    {
      "epoch": 341.35,
      "learning_rate": 0.06587913379935692,
      "loss": 2.8356,
      "step": 212320
    },
    {
      "epoch": 341.38,
      "learning_rate": 0.06587591836848875,
      "loss": 2.8323,
      "step": 212340
    },
    {
      "epoch": 341.41,
      "learning_rate": 0.06587270293762058,
      "loss": 2.82,
      "step": 212360
    },
    {
      "epoch": 341.45,
      "learning_rate": 0.06586948750675242,
      "loss": 2.8375,
      "step": 212380
    },
    {
      "epoch": 341.48,
      "learning_rate": 0.06586627207588425,
      "loss": 2.8334,
      "step": 212400
    },
    {
      "epoch": 341.51,
      "learning_rate": 0.06586305664501609,
      "loss": 2.817,
      "step": 212420
    },
    {
      "epoch": 341.54,
      "learning_rate": 0.06585984121414791,
      "loss": 2.8308,
      "step": 212440
    },
    {
      "epoch": 341.58,
      "learning_rate": 0.06585662578327975,
      "loss": 2.834,
      "step": 212460
    },
    {
      "epoch": 341.61,
      "learning_rate": 0.06585341035241159,
      "loss": 2.8293,
      "step": 212480
    },
    {
      "epoch": 341.64,
      "learning_rate": 0.06585019492154341,
      "loss": 2.8221,
      "step": 212500
    },
    {
      "epoch": 341.67,
      "learning_rate": 0.06584697949067525,
      "loss": 2.8226,
      "step": 212520
    },
    {
      "epoch": 341.7,
      "learning_rate": 0.06584376405980708,
      "loss": 2.8413,
      "step": 212540
    },
    {
      "epoch": 341.74,
      "learning_rate": 0.06584054862893891,
      "loss": 2.7998,
      "step": 212560
    },
    {
      "epoch": 341.77,
      "learning_rate": 0.06583733319807074,
      "loss": 2.8469,
      "step": 212580
    },
    {
      "epoch": 341.8,
      "learning_rate": 0.06583411776720258,
      "loss": 2.8344,
      "step": 212600
    },
    {
      "epoch": 341.83,
      "learning_rate": 0.06583090233633442,
      "loss": 2.8384,
      "step": 212620
    },
    {
      "epoch": 341.86,
      "learning_rate": 0.06582768690546624,
      "loss": 2.8213,
      "step": 212640
    },
    {
      "epoch": 341.9,
      "learning_rate": 0.06582463224614148,
      "loss": 2.829,
      "step": 212660
    },
    {
      "epoch": 341.93,
      "learning_rate": 0.06582141681527333,
      "loss": 2.8211,
      "step": 212680
    },
    {
      "epoch": 341.96,
      "learning_rate": 0.06581820138440514,
      "loss": 2.8462,
      "step": 212700
    },
    {
      "epoch": 341.99,
      "learning_rate": 0.06581498595353699,
      "loss": 2.8499,
      "step": 212720
    },
    {
      "epoch": 342.0,
      "eval_accuracy": {
        "accuracy": 0.39345409313534946
      },
      "eval_loss": 2.9855897426605225,
      "eval_runtime": 2.7091,
      "eval_samples_per_second": 4747.988,
      "eval_steps_per_second": 74.193,
      "step": 212724
    },
    {
      "epoch": 342.03,
      "learning_rate": 0.06581177052266882,
      "loss": 2.8534,
      "step": 212740
    },
    {
      "epoch": 342.06,
      "learning_rate": 0.06580855509180064,
      "loss": 2.8566,
      "step": 212760
    },
    {
      "epoch": 342.09,
      "learning_rate": 0.06580533966093248,
      "loss": 2.815,
      "step": 212780
    },
    {
      "epoch": 342.12,
      "learning_rate": 0.0658021242300643,
      "loss": 2.8279,
      "step": 212800
    },
    {
      "epoch": 342.15,
      "learning_rate": 0.06579890879919616,
      "loss": 2.842,
      "step": 212820
    },
    {
      "epoch": 342.19,
      "learning_rate": 0.06579569336832797,
      "loss": 2.8225,
      "step": 212840
    },
    {
      "epoch": 342.22,
      "learning_rate": 0.0657924779374598,
      "loss": 2.8129,
      "step": 212860
    },
    {
      "epoch": 342.25,
      "learning_rate": 0.06578926250659164,
      "loss": 2.8631,
      "step": 212880
    },
    {
      "epoch": 342.28,
      "learning_rate": 0.06578604707572347,
      "loss": 2.8125,
      "step": 212900
    },
    {
      "epoch": 342.32,
      "learning_rate": 0.06578283164485532,
      "loss": 2.8222,
      "step": 212920
    },
    {
      "epoch": 342.35,
      "learning_rate": 0.06577961621398713,
      "loss": 2.8254,
      "step": 212940
    },
    {
      "epoch": 342.38,
      "learning_rate": 0.06577640078311897,
      "loss": 2.8166,
      "step": 212960
    },
    {
      "epoch": 342.41,
      "learning_rate": 0.06577318535225081,
      "loss": 2.8286,
      "step": 212980
    },
    {
      "epoch": 342.44,
      "learning_rate": 0.06576996992138263,
      "loss": 2.8379,
      "step": 213000
    },
    {
      "epoch": 342.48,
      "learning_rate": 0.06576675449051449,
      "loss": 2.8394,
      "step": 213020
    },
    {
      "epoch": 342.51,
      "learning_rate": 0.0657635390596463,
      "loss": 2.839,
      "step": 213040
    },
    {
      "epoch": 342.54,
      "learning_rate": 0.06576032362877815,
      "loss": 2.814,
      "step": 213060
    },
    {
      "epoch": 342.57,
      "learning_rate": 0.06575710819790997,
      "loss": 2.8501,
      "step": 213080
    },
    {
      "epoch": 342.6,
      "learning_rate": 0.0657538927670418,
      "loss": 2.8559,
      "step": 213100
    },
    {
      "epoch": 342.64,
      "learning_rate": 0.06575067733617364,
      "loss": 2.8053,
      "step": 213120
    },
    {
      "epoch": 342.67,
      "learning_rate": 0.06574746190530546,
      "loss": 2.8269,
      "step": 213140
    },
    {
      "epoch": 342.7,
      "learning_rate": 0.06574424647443732,
      "loss": 2.8193,
      "step": 213160
    },
    {
      "epoch": 342.73,
      "learning_rate": 0.06574103104356913,
      "loss": 2.7998,
      "step": 213180
    },
    {
      "epoch": 342.77,
      "learning_rate": 0.06573781561270096,
      "loss": 2.8215,
      "step": 213200
    },
    {
      "epoch": 342.8,
      "learning_rate": 0.0657346001818328,
      "loss": 2.8379,
      "step": 213220
    },
    {
      "epoch": 342.83,
      "learning_rate": 0.06573138475096463,
      "loss": 2.8523,
      "step": 213240
    },
    {
      "epoch": 342.86,
      "learning_rate": 0.06572816932009648,
      "loss": 2.8199,
      "step": 213260
    },
    {
      "epoch": 342.89,
      "learning_rate": 0.06572495388922829,
      "loss": 2.8172,
      "step": 213280
    },
    {
      "epoch": 342.93,
      "learning_rate": 0.06572173845836013,
      "loss": 2.8494,
      "step": 213300
    },
    {
      "epoch": 342.96,
      "learning_rate": 0.06571852302749197,
      "loss": 2.8494,
      "step": 213320
    },
    {
      "epoch": 342.99,
      "learning_rate": 0.06571530759662379,
      "loss": 2.8586,
      "step": 213340
    },
    {
      "epoch": 343.0,
      "eval_accuracy": {
        "accuracy": 0.3966415299696805
      },
      "eval_loss": 2.9162867069244385,
      "eval_runtime": 3.2407,
      "eval_samples_per_second": 3969.183,
      "eval_steps_per_second": 62.023,
      "step": 213346
    },
    {
      "epoch": 343.02,
      "learning_rate": 0.06571209216575565,
      "loss": 2.8221,
      "step": 213360
    },
    {
      "epoch": 343.05,
      "learning_rate": 0.06570887673488746,
      "loss": 2.8394,
      "step": 213380
    },
    {
      "epoch": 343.09,
      "learning_rate": 0.0657056613040193,
      "loss": 2.8597,
      "step": 213400
    },
    {
      "epoch": 343.12,
      "learning_rate": 0.06570244587315113,
      "loss": 2.8066,
      "step": 213420
    },
    {
      "epoch": 343.15,
      "learning_rate": 0.06569923044228296,
      "loss": 2.8557,
      "step": 213440
    },
    {
      "epoch": 343.18,
      "learning_rate": 0.0656960150114148,
      "loss": 2.826,
      "step": 213460
    },
    {
      "epoch": 343.22,
      "learning_rate": 0.06569279958054662,
      "loss": 2.8251,
      "step": 213480
    },
    {
      "epoch": 343.25,
      "learning_rate": 0.06568958414967846,
      "loss": 2.8288,
      "step": 213500
    },
    {
      "epoch": 343.28,
      "learning_rate": 0.06568636871881028,
      "loss": 2.8281,
      "step": 213520
    },
    {
      "epoch": 343.31,
      "learning_rate": 0.06568315328794212,
      "loss": 2.7797,
      "step": 213540
    },
    {
      "epoch": 343.34,
      "learning_rate": 0.06567993785707396,
      "loss": 2.8071,
      "step": 213560
    },
    {
      "epoch": 343.38,
      "learning_rate": 0.06567672242620579,
      "loss": 2.814,
      "step": 213580
    },
    {
      "epoch": 343.41,
      "learning_rate": 0.06567350699533762,
      "loss": 2.8323,
      "step": 213600
    },
    {
      "epoch": 343.44,
      "learning_rate": 0.06567029156446945,
      "loss": 2.8402,
      "step": 213620
    },
    {
      "epoch": 343.47,
      "learning_rate": 0.06566707613360129,
      "loss": 2.8268,
      "step": 213640
    },
    {
      "epoch": 343.5,
      "learning_rate": 0.06566386070273313,
      "loss": 2.8197,
      "step": 213660
    },
    {
      "epoch": 343.54,
      "learning_rate": 0.06566064527186495,
      "loss": 2.8235,
      "step": 213680
    },
    {
      "epoch": 343.57,
      "learning_rate": 0.0656574298409968,
      "loss": 2.8015,
      "step": 213700
    },
    {
      "epoch": 343.6,
      "learning_rate": 0.06565421441012861,
      "loss": 2.8101,
      "step": 213720
    },
    {
      "epoch": 343.63,
      "learning_rate": 0.06565099897926045,
      "loss": 2.8502,
      "step": 213740
    },
    {
      "epoch": 343.67,
      "learning_rate": 0.06564778354839229,
      "loss": 2.8239,
      "step": 213760
    },
    {
      "epoch": 343.7,
      "learning_rate": 0.06564456811752412,
      "loss": 2.829,
      "step": 213780
    },
    {
      "epoch": 343.73,
      "learning_rate": 0.06564135268665595,
      "loss": 2.8375,
      "step": 213800
    },
    {
      "epoch": 343.76,
      "learning_rate": 0.06563813725578778,
      "loss": 2.8375,
      "step": 213820
    },
    {
      "epoch": 343.79,
      "learning_rate": 0.06563492182491962,
      "loss": 2.8218,
      "step": 213840
    },
    {
      "epoch": 343.83,
      "learning_rate": 0.06563170639405146,
      "loss": 2.7946,
      "step": 213860
    },
    {
      "epoch": 343.86,
      "learning_rate": 0.06562849096318328,
      "loss": 2.8215,
      "step": 213880
    },
    {
      "epoch": 343.89,
      "learning_rate": 0.06562527553231512,
      "loss": 2.8335,
      "step": 213900
    },
    {
      "epoch": 343.92,
      "learning_rate": 0.06562206010144694,
      "loss": 2.8262,
      "step": 213920
    },
    {
      "epoch": 343.95,
      "learning_rate": 0.06561884467057878,
      "loss": 2.8291,
      "step": 213940
    },
    {
      "epoch": 343.99,
      "learning_rate": 0.06561562923971061,
      "loss": 2.8184,
      "step": 213960
    },
    {
      "epoch": 344.0,
      "eval_accuracy": {
        "accuracy": 0.39493119800979554
      },
      "eval_loss": 2.9233341217041016,
      "eval_runtime": 3.2356,
      "eval_samples_per_second": 3975.447,
      "eval_steps_per_second": 62.121,
      "step": 213968
    },
    {
      "epoch": 344.02,
      "learning_rate": 0.06561241380884245,
      "loss": 2.8156,
      "step": 213980
    },
    {
      "epoch": 344.05,
      "learning_rate": 0.06560919837797428,
      "loss": 2.7996,
      "step": 214000
    },
    {
      "epoch": 344.08,
      "learning_rate": 0.06560598294710611,
      "loss": 2.7915,
      "step": 214020
    },
    {
      "epoch": 344.12,
      "learning_rate": 0.06560276751623795,
      "loss": 2.8201,
      "step": 214040
    },
    {
      "epoch": 344.15,
      "learning_rate": 0.06559955208536977,
      "loss": 2.8318,
      "step": 214060
    },
    {
      "epoch": 344.18,
      "learning_rate": 0.06559633665450161,
      "loss": 2.8382,
      "step": 214080
    },
    {
      "epoch": 344.21,
      "learning_rate": 0.06559312122363345,
      "loss": 2.8027,
      "step": 214100
    },
    {
      "epoch": 344.24,
      "learning_rate": 0.06558990579276527,
      "loss": 2.8298,
      "step": 214120
    },
    {
      "epoch": 344.28,
      "learning_rate": 0.06558669036189711,
      "loss": 2.7961,
      "step": 214140
    },
    {
      "epoch": 344.31,
      "learning_rate": 0.06558347493102894,
      "loss": 2.8322,
      "step": 214160
    },
    {
      "epoch": 344.34,
      "learning_rate": 0.06558025950016078,
      "loss": 2.8535,
      "step": 214180
    },
    {
      "epoch": 344.37,
      "learning_rate": 0.06557704406929261,
      "loss": 2.8347,
      "step": 214200
    },
    {
      "epoch": 344.41,
      "learning_rate": 0.06557382863842444,
      "loss": 2.8423,
      "step": 214220
    },
    {
      "epoch": 344.44,
      "learning_rate": 0.06557061320755628,
      "loss": 2.8213,
      "step": 214240
    },
    {
      "epoch": 344.47,
      "learning_rate": 0.0655673977766881,
      "loss": 2.807,
      "step": 214260
    },
    {
      "epoch": 344.5,
      "learning_rate": 0.06556434311736335,
      "loss": 2.8279,
      "step": 214280
    },
    {
      "epoch": 344.53,
      "learning_rate": 0.06556112768649519,
      "loss": 2.8394,
      "step": 214300
    },
    {
      "epoch": 344.57,
      "learning_rate": 0.065557912255627,
      "loss": 2.8159,
      "step": 214320
    },
    {
      "epoch": 344.6,
      "learning_rate": 0.06555469682475885,
      "loss": 2.8395,
      "step": 214340
    },
    {
      "epoch": 344.63,
      "learning_rate": 0.06555148139389068,
      "loss": 2.8407,
      "step": 214360
    },
    {
      "epoch": 344.66,
      "learning_rate": 0.06554826596302252,
      "loss": 2.8119,
      "step": 214380
    },
    {
      "epoch": 344.69,
      "learning_rate": 0.06554505053215436,
      "loss": 2.845,
      "step": 214400
    },
    {
      "epoch": 344.73,
      "learning_rate": 0.06554183510128617,
      "loss": 2.8724,
      "step": 214420
    },
    {
      "epoch": 344.76,
      "learning_rate": 0.06553861967041802,
      "loss": 2.8529,
      "step": 214440
    },
    {
      "epoch": 344.79,
      "learning_rate": 0.06553540423954984,
      "loss": 2.82,
      "step": 214460
    },
    {
      "epoch": 344.82,
      "learning_rate": 0.06553218880868168,
      "loss": 2.7865,
      "step": 214480
    },
    {
      "epoch": 344.86,
      "learning_rate": 0.06552897337781351,
      "loss": 2.8254,
      "step": 214500
    },
    {
      "epoch": 344.89,
      "learning_rate": 0.06552575794694533,
      "loss": 2.8185,
      "step": 214520
    },
    {
      "epoch": 344.92,
      "learning_rate": 0.06552254251607718,
      "loss": 2.8444,
      "step": 214540
    },
    {
      "epoch": 344.95,
      "learning_rate": 0.065519327085209,
      "loss": 2.8354,
      "step": 214560
    },
    {
      "epoch": 344.98,
      "learning_rate": 0.06551611165434085,
      "loss": 2.8232,
      "step": 214580
    },
    {
      "epoch": 345.0,
      "eval_accuracy": {
        "accuracy": 0.39633056052242865
      },
      "eval_loss": 2.899501085281372,
      "eval_runtime": 3.028,
      "eval_samples_per_second": 4248.072,
      "eval_steps_per_second": 66.381,
      "step": 214590
    },
    {
      "epoch": 345.02,
      "learning_rate": 0.06551289622347267,
      "loss": 2.8408,
      "step": 214600
    },
    {
      "epoch": 345.05,
      "learning_rate": 0.06550968079260451,
      "loss": 2.7928,
      "step": 214620
    },
    {
      "epoch": 345.08,
      "learning_rate": 0.06550646536173635,
      "loss": 2.8479,
      "step": 214640
    },
    {
      "epoch": 345.11,
      "learning_rate": 0.06550324993086816,
      "loss": 2.8533,
      "step": 214660
    },
    {
      "epoch": 345.14,
      "learning_rate": 0.06550003450000001,
      "loss": 2.8586,
      "step": 214680
    },
    {
      "epoch": 345.18,
      "learning_rate": 0.06549681906913184,
      "loss": 2.8225,
      "step": 214700
    },
    {
      "epoch": 345.21,
      "learning_rate": 0.06549360363826368,
      "loss": 2.8162,
      "step": 214720
    },
    {
      "epoch": 345.24,
      "learning_rate": 0.06549038820739551,
      "loss": 2.8297,
      "step": 214740
    },
    {
      "epoch": 345.27,
      "learning_rate": 0.06548717277652732,
      "loss": 2.8579,
      "step": 214760
    },
    {
      "epoch": 345.31,
      "learning_rate": 0.06548395734565918,
      "loss": 2.8372,
      "step": 214780
    },
    {
      "epoch": 345.34,
      "learning_rate": 0.065480741914791,
      "loss": 2.8207,
      "step": 214800
    },
    {
      "epoch": 345.37,
      "learning_rate": 0.06547752648392284,
      "loss": 2.8317,
      "step": 214820
    },
    {
      "epoch": 345.4,
      "learning_rate": 0.06547431105305467,
      "loss": 2.815,
      "step": 214840
    },
    {
      "epoch": 345.43,
      "learning_rate": 0.06547109562218649,
      "loss": 2.8347,
      "step": 214860
    },
    {
      "epoch": 345.47,
      "learning_rate": 0.06546788019131834,
      "loss": 2.7998,
      "step": 214880
    },
    {
      "epoch": 345.5,
      "learning_rate": 0.06546466476045015,
      "loss": 2.8344,
      "step": 214900
    },
    {
      "epoch": 345.53,
      "learning_rate": 0.065461449329582,
      "loss": 2.7972,
      "step": 214920
    },
    {
      "epoch": 345.56,
      "learning_rate": 0.06545823389871383,
      "loss": 2.825,
      "step": 214940
    },
    {
      "epoch": 345.59,
      "learning_rate": 0.06545501846784565,
      "loss": 2.8266,
      "step": 214960
    },
    {
      "epoch": 345.63,
      "learning_rate": 0.06545180303697751,
      "loss": 2.8241,
      "step": 214980
    },
    {
      "epoch": 345.66,
      "learning_rate": 0.06544858760610932,
      "loss": 2.8293,
      "step": 215000
    },
    {
      "epoch": 345.69,
      "learning_rate": 0.06544537217524117,
      "loss": 2.8364,
      "step": 215020
    },
    {
      "epoch": 345.72,
      "learning_rate": 0.065442156744373,
      "loss": 2.8375,
      "step": 215040
    },
    {
      "epoch": 345.76,
      "learning_rate": 0.06543894131350482,
      "loss": 2.8686,
      "step": 215060
    },
    {
      "epoch": 345.79,
      "learning_rate": 0.06543572588263667,
      "loss": 2.8593,
      "step": 215080
    },
    {
      "epoch": 345.82,
      "learning_rate": 0.06543251045176848,
      "loss": 2.8168,
      "step": 215100
    },
    {
      "epoch": 345.85,
      "learning_rate": 0.06542929502090034,
      "loss": 2.8192,
      "step": 215120
    },
    {
      "epoch": 345.88,
      "learning_rate": 0.06542607959003216,
      "loss": 2.8131,
      "step": 215140
    },
    {
      "epoch": 345.92,
      "learning_rate": 0.06542286415916398,
      "loss": 2.8433,
      "step": 215160
    },
    {
      "epoch": 345.95,
      "learning_rate": 0.06541964872829582,
      "loss": 2.8505,
      "step": 215180
    },
    {
      "epoch": 345.98,
      "learning_rate": 0.06541643329742765,
      "loss": 2.8187,
      "step": 215200
    },
    {
      "epoch": 346.0,
      "eval_accuracy": {
        "accuracy": 0.39298763896447175
      },
      "eval_loss": 2.9348299503326416,
      "eval_runtime": 3.0984,
      "eval_samples_per_second": 4151.504,
      "eval_steps_per_second": 64.872,
      "step": 215212
    },
    {
      "epoch": 346.01,
      "learning_rate": 0.0654132178665595,
      "loss": 2.8415,
      "step": 215220
    },
    {
      "epoch": 346.05,
      "learning_rate": 0.06541000243569131,
      "loss": 2.8356,
      "step": 215240
    },
    {
      "epoch": 346.08,
      "learning_rate": 0.06540678700482316,
      "loss": 2.7931,
      "step": 215260
    },
    {
      "epoch": 346.11,
      "learning_rate": 0.06540357157395499,
      "loss": 2.7993,
      "step": 215280
    },
    {
      "epoch": 346.14,
      "learning_rate": 0.06540035614308681,
      "loss": 2.8012,
      "step": 215300
    },
    {
      "epoch": 346.17,
      "learning_rate": 0.06539714071221867,
      "loss": 2.807,
      "step": 215320
    },
    {
      "epoch": 346.21,
      "learning_rate": 0.06539392528135048,
      "loss": 2.7962,
      "step": 215340
    },
    {
      "epoch": 346.24,
      "learning_rate": 0.06539070985048233,
      "loss": 2.8133,
      "step": 215360
    },
    {
      "epoch": 346.27,
      "learning_rate": 0.06538749441961415,
      "loss": 2.8205,
      "step": 215380
    },
    {
      "epoch": 346.3,
      "learning_rate": 0.06538427898874598,
      "loss": 2.8128,
      "step": 215400
    },
    {
      "epoch": 346.33,
      "learning_rate": 0.06538106355787783,
      "loss": 2.8615,
      "step": 215420
    },
    {
      "epoch": 346.37,
      "learning_rate": 0.06537784812700964,
      "loss": 2.8504,
      "step": 215440
    },
    {
      "epoch": 346.4,
      "learning_rate": 0.0653746326961415,
      "loss": 2.8331,
      "step": 215460
    },
    {
      "epoch": 346.43,
      "learning_rate": 0.06537141726527332,
      "loss": 2.8528,
      "step": 215480
    },
    {
      "epoch": 346.46,
      "learning_rate": 0.06536820183440514,
      "loss": 2.8373,
      "step": 215500
    },
    {
      "epoch": 346.5,
      "learning_rate": 0.06536498640353698,
      "loss": 2.8306,
      "step": 215520
    },
    {
      "epoch": 346.53,
      "learning_rate": 0.0653617709726688,
      "loss": 2.8135,
      "step": 215540
    },
    {
      "epoch": 346.56,
      "learning_rate": 0.06535855554180066,
      "loss": 2.7952,
      "step": 215560
    },
    {
      "epoch": 346.59,
      "learning_rate": 0.06535534011093247,
      "loss": 2.8264,
      "step": 215580
    },
    {
      "epoch": 346.62,
      "learning_rate": 0.06535212468006431,
      "loss": 2.8162,
      "step": 215600
    },
    {
      "epoch": 346.66,
      "learning_rate": 0.06534890924919615,
      "loss": 2.8492,
      "step": 215620
    },
    {
      "epoch": 346.69,
      "learning_rate": 0.06534569381832797,
      "loss": 2.834,
      "step": 215640
    },
    {
      "epoch": 346.72,
      "learning_rate": 0.06534247838745982,
      "loss": 2.8135,
      "step": 215660
    },
    {
      "epoch": 346.75,
      "learning_rate": 0.06533926295659163,
      "loss": 2.8315,
      "step": 215680
    },
    {
      "epoch": 346.78,
      "learning_rate": 0.06533604752572347,
      "loss": 2.8185,
      "step": 215700
    },
    {
      "epoch": 346.82,
      "learning_rate": 0.06533283209485531,
      "loss": 2.8408,
      "step": 215720
    },
    {
      "epoch": 346.85,
      "learning_rate": 0.06532961666398714,
      "loss": 2.8494,
      "step": 215740
    },
    {
      "epoch": 346.88,
      "learning_rate": 0.06532640123311899,
      "loss": 2.8752,
      "step": 215760
    },
    {
      "epoch": 346.91,
      "learning_rate": 0.0653231858022508,
      "loss": 2.8671,
      "step": 215780
    },
    {
      "epoch": 346.95,
      "learning_rate": 0.06531997037138264,
      "loss": 2.844,
      "step": 215800
    },
    {
      "epoch": 346.98,
      "learning_rate": 0.06531675494051448,
      "loss": 2.8126,
      "step": 215820
    },
    {
      "epoch": 347.0,
      "eval_accuracy": {
        "accuracy": 0.39508668273342146
      },
      "eval_loss": 2.9228692054748535,
      "eval_runtime": 2.7669,
      "eval_samples_per_second": 4648.887,
      "eval_steps_per_second": 72.645,
      "step": 215834
    },
    {
      "epoch": 347.01,
      "learning_rate": 0.0653135395096463,
      "loss": 2.8265,
      "step": 215840
    },
    {
      "epoch": 347.04,
      "learning_rate": 0.06531032407877814,
      "loss": 2.8232,
      "step": 215860
    },
    {
      "epoch": 347.07,
      "learning_rate": 0.06530710864790996,
      "loss": 2.8033,
      "step": 215880
    },
    {
      "epoch": 347.11,
      "learning_rate": 0.06530389321704182,
      "loss": 2.8132,
      "step": 215900
    },
    {
      "epoch": 347.14,
      "learning_rate": 0.06530067778617363,
      "loss": 2.81,
      "step": 215920
    },
    {
      "epoch": 347.17,
      "learning_rate": 0.06529746235530547,
      "loss": 2.8362,
      "step": 215940
    },
    {
      "epoch": 347.2,
      "learning_rate": 0.0652942469244373,
      "loss": 2.8396,
      "step": 215960
    },
    {
      "epoch": 347.23,
      "learning_rate": 0.06529103149356913,
      "loss": 2.8407,
      "step": 215980
    },
    {
      "epoch": 347.27,
      "learning_rate": 0.06528781606270098,
      "loss": 2.8293,
      "step": 216000
    },
    {
      "epoch": 347.3,
      "learning_rate": 0.06528460063183279,
      "loss": 2.818,
      "step": 216020
    },
    {
      "epoch": 347.33,
      "learning_rate": 0.06528138520096463,
      "loss": 2.8374,
      "step": 216040
    },
    {
      "epoch": 347.36,
      "learning_rate": 0.06527816977009647,
      "loss": 2.8328,
      "step": 216060
    },
    {
      "epoch": 347.4,
      "learning_rate": 0.0652749543392283,
      "loss": 2.813,
      "step": 216080
    },
    {
      "epoch": 347.43,
      "learning_rate": 0.06527173890836015,
      "loss": 2.7955,
      "step": 216100
    },
    {
      "epoch": 347.46,
      "learning_rate": 0.06526852347749196,
      "loss": 2.8282,
      "step": 216120
    },
    {
      "epoch": 347.49,
      "learning_rate": 0.0652653080466238,
      "loss": 2.847,
      "step": 216140
    },
    {
      "epoch": 347.52,
      "learning_rate": 0.06526209261575563,
      "loss": 2.8328,
      "step": 216160
    },
    {
      "epoch": 347.56,
      "learning_rate": 0.06525887718488746,
      "loss": 2.8552,
      "step": 216180
    },
    {
      "epoch": 347.59,
      "learning_rate": 0.0652556617540193,
      "loss": 2.8008,
      "step": 216200
    },
    {
      "epoch": 347.62,
      "learning_rate": 0.06525244632315112,
      "loss": 2.8158,
      "step": 216220
    },
    {
      "epoch": 347.65,
      "learning_rate": 0.06524923089228296,
      "loss": 2.8242,
      "step": 216240
    },
    {
      "epoch": 347.68,
      "learning_rate": 0.0652460154614148,
      "loss": 2.7905,
      "step": 216260
    },
    {
      "epoch": 347.72,
      "learning_rate": 0.06524280003054662,
      "loss": 2.816,
      "step": 216280
    },
    {
      "epoch": 347.75,
      "learning_rate": 0.06523958459967846,
      "loss": 2.8302,
      "step": 216300
    },
    {
      "epoch": 347.78,
      "learning_rate": 0.06523636916881029,
      "loss": 2.8182,
      "step": 216320
    },
    {
      "epoch": 347.81,
      "learning_rate": 0.06523315373794213,
      "loss": 2.8415,
      "step": 216340
    },
    {
      "epoch": 347.85,
      "learning_rate": 0.06522993830707395,
      "loss": 2.8417,
      "step": 216360
    },
    {
      "epoch": 347.88,
      "learning_rate": 0.06522672287620579,
      "loss": 2.7794,
      "step": 216380
    },
    {
      "epoch": 347.91,
      "learning_rate": 0.06522350744533763,
      "loss": 2.8102,
      "step": 216400
    },
    {
      "epoch": 347.94,
      "learning_rate": 0.06522029201446945,
      "loss": 2.8166,
      "step": 216420
    },
    {
      "epoch": 347.97,
      "learning_rate": 0.0652170765836013,
      "loss": 2.8003,
      "step": 216440
    },
    {
      "epoch": 348.0,
      "eval_accuracy": {
        "accuracy": 0.402316722382026
      },
      "eval_loss": 2.8899636268615723,
      "eval_runtime": 3.2335,
      "eval_samples_per_second": 3978.089,
      "eval_steps_per_second": 62.162,
      "step": 216456
    },
    {
      "epoch": 348.01,
      "learning_rate": 0.06521386115273312,
      "loss": 2.7871,
      "step": 216460
    },
    {
      "epoch": 348.04,
      "learning_rate": 0.06521064572186495,
      "loss": 2.8458,
      "step": 216480
    },
    {
      "epoch": 348.07,
      "learning_rate": 0.06520743029099679,
      "loss": 2.8134,
      "step": 216500
    },
    {
      "epoch": 348.1,
      "learning_rate": 0.06520421486012862,
      "loss": 2.8204,
      "step": 216520
    },
    {
      "epoch": 348.14,
      "learning_rate": 0.06520099942926046,
      "loss": 2.8057,
      "step": 216540
    },
    {
      "epoch": 348.17,
      "learning_rate": 0.06519778399839228,
      "loss": 2.8185,
      "step": 216560
    },
    {
      "epoch": 348.2,
      "learning_rate": 0.06519456856752412,
      "loss": 2.8391,
      "step": 216580
    },
    {
      "epoch": 348.23,
      "learning_rate": 0.06519135313665596,
      "loss": 2.8011,
      "step": 216600
    },
    {
      "epoch": 348.26,
      "learning_rate": 0.06518813770578778,
      "loss": 2.802,
      "step": 216620
    },
    {
      "epoch": 348.3,
      "learning_rate": 0.06518492227491962,
      "loss": 2.8175,
      "step": 216640
    },
    {
      "epoch": 348.33,
      "learning_rate": 0.06518170684405145,
      "loss": 2.8687,
      "step": 216660
    },
    {
      "epoch": 348.36,
      "learning_rate": 0.06517849141318328,
      "loss": 2.8536,
      "step": 216680
    },
    {
      "epoch": 348.39,
      "learning_rate": 0.06517527598231511,
      "loss": 2.8439,
      "step": 216700
    },
    {
      "epoch": 348.42,
      "learning_rate": 0.06517206055144695,
      "loss": 2.8087,
      "step": 216720
    },
    {
      "epoch": 348.46,
      "learning_rate": 0.06516884512057879,
      "loss": 2.8373,
      "step": 216740
    },
    {
      "epoch": 348.49,
      "learning_rate": 0.06516562968971061,
      "loss": 2.8194,
      "step": 216760
    },
    {
      "epoch": 348.52,
      "learning_rate": 0.06516241425884245,
      "loss": 2.844,
      "step": 216780
    },
    {
      "epoch": 348.55,
      "learning_rate": 0.06515919882797427,
      "loss": 2.8249,
      "step": 216800
    },
    {
      "epoch": 348.59,
      "learning_rate": 0.06515598339710611,
      "loss": 2.826,
      "step": 216820
    },
    {
      "epoch": 348.62,
      "learning_rate": 0.06515276796623795,
      "loss": 2.8243,
      "step": 216840
    },
    {
      "epoch": 348.65,
      "learning_rate": 0.06514955253536978,
      "loss": 2.8359,
      "step": 216860
    },
    {
      "epoch": 348.68,
      "learning_rate": 0.06514633710450161,
      "loss": 2.8168,
      "step": 216880
    },
    {
      "epoch": 348.71,
      "learning_rate": 0.06514312167363344,
      "loss": 2.8067,
      "step": 216900
    },
    {
      "epoch": 348.75,
      "learning_rate": 0.06513990624276528,
      "loss": 2.8219,
      "step": 216920
    },
    {
      "epoch": 348.78,
      "learning_rate": 0.06513669081189712,
      "loss": 2.8295,
      "step": 216940
    },
    {
      "epoch": 348.81,
      "learning_rate": 0.06513347538102894,
      "loss": 2.8297,
      "step": 216960
    },
    {
      "epoch": 348.84,
      "learning_rate": 0.06513025995016078,
      "loss": 2.7835,
      "step": 216980
    },
    {
      "epoch": 348.87,
      "learning_rate": 0.0651270445192926,
      "loss": 2.827,
      "step": 217000
    },
    {
      "epoch": 348.91,
      "learning_rate": 0.06512382908842444,
      "loss": 2.8132,
      "step": 217020
    },
    {
      "epoch": 348.94,
      "learning_rate": 0.06512061365755627,
      "loss": 2.8263,
      "step": 217040
    },
    {
      "epoch": 348.97,
      "learning_rate": 0.0651173982266881,
      "loss": 2.8261,
      "step": 217060
    },
    {
      "epoch": 349.0,
      "eval_accuracy": {
        "accuracy": 0.3929098966026588
      },
      "eval_loss": 2.928997039794922,
      "eval_runtime": 2.8029,
      "eval_samples_per_second": 4589.17,
      "eval_steps_per_second": 71.711,
      "step": 217078
    },
    {
      "epoch": 349.0,
      "learning_rate": 0.06511418279581994,
      "loss": 2.8385,
      "step": 217080
    },
    {
      "epoch": 349.04,
      "learning_rate": 0.06511096736495177,
      "loss": 2.7927,
      "step": 217100
    },
    {
      "epoch": 349.07,
      "learning_rate": 0.06510775193408361,
      "loss": 2.8312,
      "step": 217120
    },
    {
      "epoch": 349.1,
      "learning_rate": 0.06510453650321543,
      "loss": 2.8214,
      "step": 217140
    },
    {
      "epoch": 349.13,
      "learning_rate": 0.06510132107234727,
      "loss": 2.8264,
      "step": 217160
    },
    {
      "epoch": 349.16,
      "learning_rate": 0.06509810564147911,
      "loss": 2.8242,
      "step": 217180
    },
    {
      "epoch": 349.2,
      "learning_rate": 0.06509489021061093,
      "loss": 2.8106,
      "step": 217200
    },
    {
      "epoch": 349.23,
      "learning_rate": 0.06509167477974277,
      "loss": 2.8201,
      "step": 217220
    },
    {
      "epoch": 349.26,
      "learning_rate": 0.0650884593488746,
      "loss": 2.8171,
      "step": 217240
    },
    {
      "epoch": 349.29,
      "learning_rate": 0.06508524391800644,
      "loss": 2.824,
      "step": 217260
    },
    {
      "epoch": 349.32,
      "learning_rate": 0.06508202848713827,
      "loss": 2.8297,
      "step": 217280
    },
    {
      "epoch": 349.36,
      "learning_rate": 0.0650788130562701,
      "loss": 2.8295,
      "step": 217300
    },
    {
      "epoch": 349.39,
      "learning_rate": 0.06507559762540194,
      "loss": 2.8147,
      "step": 217320
    },
    {
      "epoch": 349.42,
      "learning_rate": 0.06507238219453376,
      "loss": 2.8204,
      "step": 217340
    },
    {
      "epoch": 349.45,
      "learning_rate": 0.0650691667636656,
      "loss": 2.8301,
      "step": 217360
    },
    {
      "epoch": 349.49,
      "learning_rate": 0.06506595133279743,
      "loss": 2.8254,
      "step": 217380
    },
    {
      "epoch": 349.52,
      "learning_rate": 0.06506273590192926,
      "loss": 2.8239,
      "step": 217400
    },
    {
      "epoch": 349.55,
      "learning_rate": 0.0650595204710611,
      "loss": 2.8262,
      "step": 217420
    },
    {
      "epoch": 349.58,
      "learning_rate": 0.06505630504019293,
      "loss": 2.8497,
      "step": 217440
    },
    {
      "epoch": 349.61,
      "learning_rate": 0.06505308960932477,
      "loss": 2.8208,
      "step": 217460
    },
    {
      "epoch": 349.65,
      "learning_rate": 0.06504987417845659,
      "loss": 2.8324,
      "step": 217480
    },
    {
      "epoch": 349.68,
      "learning_rate": 0.06504665874758843,
      "loss": 2.8436,
      "step": 217500
    },
    {
      "epoch": 349.71,
      "learning_rate": 0.06504344331672027,
      "loss": 2.8239,
      "step": 217520
    },
    {
      "epoch": 349.74,
      "learning_rate": 0.06504022788585209,
      "loss": 2.8263,
      "step": 217540
    },
    {
      "epoch": 349.77,
      "learning_rate": 0.06503701245498393,
      "loss": 2.8513,
      "step": 217560
    },
    {
      "epoch": 349.81,
      "learning_rate": 0.06503379702411576,
      "loss": 2.8438,
      "step": 217580
    },
    {
      "epoch": 349.84,
      "learning_rate": 0.0650305815932476,
      "loss": 2.8609,
      "step": 217600
    },
    {
      "epoch": 349.87,
      "learning_rate": 0.06502736616237943,
      "loss": 2.8411,
      "step": 217620
    },
    {
      "epoch": 349.9,
      "learning_rate": 0.06502415073151126,
      "loss": 2.8413,
      "step": 217640
    },
    {
      "epoch": 349.94,
      "learning_rate": 0.0650209353006431,
      "loss": 2.8119,
      "step": 217660
    },
    {
      "epoch": 349.97,
      "learning_rate": 0.06501771986977492,
      "loss": 2.807,
      "step": 217680
    },
    {
      "epoch": 350.0,
      "learning_rate": 0.06501450443890676,
      "loss": 2.7857,
      "step": 217700
    },
    {
      "epoch": 350.0,
      "eval_accuracy": {
        "accuracy": 0.3930653813262847
      },
      "eval_loss": 2.908447027206421,
      "eval_runtime": 3.1983,
      "eval_samples_per_second": 4021.823,
      "eval_steps_per_second": 62.846,
      "step": 217700
    },
    {
      "epoch": 350.03,
      "learning_rate": 0.06501128900803858,
      "loss": 2.811,
      "step": 217720
    },
    {
      "epoch": 350.06,
      "learning_rate": 0.06500807357717042,
      "loss": 2.8039,
      "step": 217740
    },
    {
      "epoch": 350.1,
      "learning_rate": 0.06500485814630226,
      "loss": 2.813,
      "step": 217760
    },
    {
      "epoch": 350.13,
      "learning_rate": 0.06500164271543409,
      "loss": 2.8201,
      "step": 217780
    },
    {
      "epoch": 350.16,
      "learning_rate": 0.06499842728456592,
      "loss": 2.8261,
      "step": 217800
    },
    {
      "epoch": 350.19,
      "learning_rate": 0.06499521185369775,
      "loss": 2.834,
      "step": 217820
    },
    {
      "epoch": 350.23,
      "learning_rate": 0.06499199642282959,
      "loss": 2.813,
      "step": 217840
    },
    {
      "epoch": 350.26,
      "learning_rate": 0.06498878099196143,
      "loss": 2.7897,
      "step": 217860
    },
    {
      "epoch": 350.29,
      "learning_rate": 0.06498556556109325,
      "loss": 2.8172,
      "step": 217880
    },
    {
      "epoch": 350.32,
      "learning_rate": 0.06498235013022509,
      "loss": 2.7999,
      "step": 217900
    },
    {
      "epoch": 350.35,
      "learning_rate": 0.06497913469935691,
      "loss": 2.7952,
      "step": 217920
    },
    {
      "epoch": 350.39,
      "learning_rate": 0.06497591926848875,
      "loss": 2.7925,
      "step": 217940
    },
    {
      "epoch": 350.42,
      "learning_rate": 0.06497270383762059,
      "loss": 2.8113,
      "step": 217960
    },
    {
      "epoch": 350.45,
      "learning_rate": 0.06496948840675242,
      "loss": 2.8657,
      "step": 217980
    },
    {
      "epoch": 350.48,
      "learning_rate": 0.06496627297588425,
      "loss": 2.8434,
      "step": 218000
    },
    {
      "epoch": 350.51,
      "learning_rate": 0.06496305754501608,
      "loss": 2.7987,
      "step": 218020
    },
    {
      "epoch": 350.55,
      "learning_rate": 0.06495984211414792,
      "loss": 2.828,
      "step": 218040
    },
    {
      "epoch": 350.58,
      "learning_rate": 0.06495662668327974,
      "loss": 2.8491,
      "step": 218060
    },
    {
      "epoch": 350.61,
      "learning_rate": 0.06495341125241158,
      "loss": 2.8328,
      "step": 218080
    },
    {
      "epoch": 350.64,
      "learning_rate": 0.06495019582154342,
      "loss": 2.8365,
      "step": 218100
    },
    {
      "epoch": 350.68,
      "learning_rate": 0.06494698039067524,
      "loss": 2.8334,
      "step": 218120
    },
    {
      "epoch": 350.71,
      "learning_rate": 0.06494376495980708,
      "loss": 2.8585,
      "step": 218140
    },
    {
      "epoch": 350.74,
      "learning_rate": 0.0649405495289389,
      "loss": 2.8166,
      "step": 218160
    },
    {
      "epoch": 350.77,
      "learning_rate": 0.06493733409807075,
      "loss": 2.8163,
      "step": 218180
    },
    {
      "epoch": 350.8,
      "learning_rate": 0.06493411866720258,
      "loss": 2.8124,
      "step": 218200
    },
    {
      "epoch": 350.84,
      "learning_rate": 0.06493090323633441,
      "loss": 2.8133,
      "step": 218220
    },
    {
      "epoch": 350.87,
      "learning_rate": 0.06492768780546625,
      "loss": 2.8084,
      "step": 218240
    },
    {
      "epoch": 350.9,
      "learning_rate": 0.06492447237459807,
      "loss": 2.8098,
      "step": 218260
    },
    {
      "epoch": 350.93,
      "learning_rate": 0.06492125694372991,
      "loss": 2.8049,
      "step": 218280
    },
    {
      "epoch": 350.96,
      "learning_rate": 0.06491820228440516,
      "loss": 2.8131,
      "step": 218300
    },
    {
      "epoch": 351.0,
      "learning_rate": 0.06491498685353697,
      "loss": 2.8231,
      "step": 218320
    },
    {
      "epoch": 351.0,
      "eval_accuracy": {
        "accuracy": 0.3922102153463422
      },
      "eval_loss": 2.929962635040283,
      "eval_runtime": 4.0751,
      "eval_samples_per_second": 3156.467,
      "eval_steps_per_second": 49.324,
      "step": 218322
    },
    {
      "epoch": 351.03,
      "learning_rate": 0.06491177142266881,
      "loss": 2.8455,
      "step": 218340
    },
    {
      "epoch": 351.06,
      "learning_rate": 0.06490855599180065,
      "loss": 2.821,
      "step": 218360
    },
    {
      "epoch": 351.09,
      "learning_rate": 0.06490534056093247,
      "loss": 2.8348,
      "step": 218380
    },
    {
      "epoch": 351.13,
      "learning_rate": 0.06490212513006433,
      "loss": 2.8097,
      "step": 218400
    },
    {
      "epoch": 351.16,
      "learning_rate": 0.06489890969919614,
      "loss": 2.8533,
      "step": 218420
    },
    {
      "epoch": 351.19,
      "learning_rate": 0.06489569426832797,
      "loss": 2.8225,
      "step": 218440
    },
    {
      "epoch": 351.22,
      "learning_rate": 0.06489247883745981,
      "loss": 2.8291,
      "step": 218460
    },
    {
      "epoch": 351.25,
      "learning_rate": 0.06488926340659164,
      "loss": 2.8137,
      "step": 218480
    },
    {
      "epoch": 351.29,
      "learning_rate": 0.06488604797572349,
      "loss": 2.8055,
      "step": 218500
    },
    {
      "epoch": 351.32,
      "learning_rate": 0.0648828325448553,
      "loss": 2.8385,
      "step": 218520
    },
    {
      "epoch": 351.35,
      "learning_rate": 0.06487961711398714,
      "loss": 2.8314,
      "step": 218540
    },
    {
      "epoch": 351.38,
      "learning_rate": 0.06487640168311898,
      "loss": 2.8161,
      "step": 218560
    },
    {
      "epoch": 351.41,
      "learning_rate": 0.0648731862522508,
      "loss": 2.8087,
      "step": 218580
    },
    {
      "epoch": 351.45,
      "learning_rate": 0.06486997082138264,
      "loss": 2.814,
      "step": 218600
    },
    {
      "epoch": 351.48,
      "learning_rate": 0.06486675539051447,
      "loss": 2.8696,
      "step": 218620
    },
    {
      "epoch": 351.51,
      "learning_rate": 0.06486353995964632,
      "loss": 2.8282,
      "step": 218640
    },
    {
      "epoch": 351.54,
      "learning_rate": 0.06486032452877813,
      "loss": 2.787,
      "step": 218660
    },
    {
      "epoch": 351.58,
      "learning_rate": 0.06485710909790997,
      "loss": 2.8104,
      "step": 218680
    },
    {
      "epoch": 351.61,
      "learning_rate": 0.0648538936670418,
      "loss": 2.8254,
      "step": 218700
    },
    {
      "epoch": 351.64,
      "learning_rate": 0.06485067823617363,
      "loss": 2.8066,
      "step": 218720
    },
    {
      "epoch": 351.67,
      "learning_rate": 0.06484746280530548,
      "loss": 2.7862,
      "step": 218740
    },
    {
      "epoch": 351.7,
      "learning_rate": 0.0648442473744373,
      "loss": 2.8108,
      "step": 218760
    },
    {
      "epoch": 351.74,
      "learning_rate": 0.06484103194356913,
      "loss": 2.8484,
      "step": 218780
    },
    {
      "epoch": 351.77,
      "learning_rate": 0.06483781651270097,
      "loss": 2.8304,
      "step": 218800
    },
    {
      "epoch": 351.8,
      "learning_rate": 0.0648346010818328,
      "loss": 2.83,
      "step": 218820
    },
    {
      "epoch": 351.83,
      "learning_rate": 0.06483138565096465,
      "loss": 2.8171,
      "step": 218840
    },
    {
      "epoch": 351.86,
      "learning_rate": 0.06482817022009646,
      "loss": 2.8145,
      "step": 218860
    },
    {
      "epoch": 351.9,
      "learning_rate": 0.0648249547892283,
      "loss": 2.8324,
      "step": 218880
    },
    {
      "epoch": 351.93,
      "learning_rate": 0.06482173935836014,
      "loss": 2.8495,
      "step": 218900
    },
    {
      "epoch": 351.96,
      "learning_rate": 0.06481852392749196,
      "loss": 2.8208,
      "step": 218920
    },
    {
      "epoch": 351.99,
      "learning_rate": 0.0648153084966238,
      "loss": 2.8436,
      "step": 218940
    },
    {
      "epoch": 352.0,
      "eval_accuracy": {
        "accuracy": 0.39462022856254375
      },
      "eval_loss": 2.9269707202911377,
      "eval_runtime": 2.8754,
      "eval_samples_per_second": 4473.482,
      "eval_steps_per_second": 69.904,
      "step": 218944
    },
    {
      "epoch": 352.03,
      "learning_rate": 0.06481209306575562,
      "loss": 2.8173,
      "step": 218960
    },
    {
      "epoch": 352.06,
      "learning_rate": 0.06480887763488746,
      "loss": 2.8001,
      "step": 218980
    },
    {
      "epoch": 352.09,
      "learning_rate": 0.0648056622040193,
      "loss": 2.8214,
      "step": 219000
    },
    {
      "epoch": 352.12,
      "learning_rate": 0.06480244677315113,
      "loss": 2.8351,
      "step": 219020
    },
    {
      "epoch": 352.15,
      "learning_rate": 0.06479923134228296,
      "loss": 2.8377,
      "step": 219040
    },
    {
      "epoch": 352.19,
      "learning_rate": 0.06479601591141479,
      "loss": 2.8153,
      "step": 219060
    },
    {
      "epoch": 352.22,
      "learning_rate": 0.06479280048054663,
      "loss": 2.8063,
      "step": 219080
    },
    {
      "epoch": 352.25,
      "learning_rate": 0.06478958504967845,
      "loss": 2.808,
      "step": 219100
    },
    {
      "epoch": 352.28,
      "learning_rate": 0.06478636961881029,
      "loss": 2.8045,
      "step": 219120
    },
    {
      "epoch": 352.32,
      "learning_rate": 0.06478315418794213,
      "loss": 2.8155,
      "step": 219140
    },
    {
      "epoch": 352.35,
      "learning_rate": 0.06477993875707395,
      "loss": 2.8391,
      "step": 219160
    },
    {
      "epoch": 352.38,
      "learning_rate": 0.06477672332620579,
      "loss": 2.8279,
      "step": 219180
    },
    {
      "epoch": 352.41,
      "learning_rate": 0.06477350789533762,
      "loss": 2.8128,
      "step": 219200
    },
    {
      "epoch": 352.44,
      "learning_rate": 0.06477029246446946,
      "loss": 2.8244,
      "step": 219220
    },
    {
      "epoch": 352.48,
      "learning_rate": 0.0647670770336013,
      "loss": 2.8263,
      "step": 219240
    },
    {
      "epoch": 352.51,
      "learning_rate": 0.06476386160273312,
      "loss": 2.8516,
      "step": 219260
    },
    {
      "epoch": 352.54,
      "learning_rate": 0.06476064617186496,
      "loss": 2.7994,
      "step": 219280
    },
    {
      "epoch": 352.57,
      "learning_rate": 0.06475743074099678,
      "loss": 2.8211,
      "step": 219300
    },
    {
      "epoch": 352.6,
      "learning_rate": 0.06475421531012862,
      "loss": 2.8389,
      "step": 219320
    },
    {
      "epoch": 352.64,
      "learning_rate": 0.06475099987926046,
      "loss": 2.8156,
      "step": 219340
    },
    {
      "epoch": 352.67,
      "learning_rate": 0.06474778444839228,
      "loss": 2.8247,
      "step": 219360
    },
    {
      "epoch": 352.7,
      "learning_rate": 0.06474456901752412,
      "loss": 2.8391,
      "step": 219380
    },
    {
      "epoch": 352.73,
      "learning_rate": 0.06474135358665595,
      "loss": 2.8377,
      "step": 219400
    },
    {
      "epoch": 352.77,
      "learning_rate": 0.06473813815578779,
      "loss": 2.8355,
      "step": 219420
    },
    {
      "epoch": 352.8,
      "learning_rate": 0.06473492272491961,
      "loss": 2.8512,
      "step": 219440
    },
    {
      "epoch": 352.83,
      "learning_rate": 0.06473170729405145,
      "loss": 2.8101,
      "step": 219460
    },
    {
      "epoch": 352.86,
      "learning_rate": 0.06472849186318329,
      "loss": 2.7828,
      "step": 219480
    },
    {
      "epoch": 352.89,
      "learning_rate": 0.06472527643231511,
      "loss": 2.8505,
      "step": 219500
    },
    {
      "epoch": 352.93,
      "learning_rate": 0.06472206100144695,
      "loss": 2.8592,
      "step": 219520
    },
    {
      "epoch": 352.96,
      "learning_rate": 0.06471884557057878,
      "loss": 2.8286,
      "step": 219540
    },
    {
      "epoch": 352.99,
      "learning_rate": 0.06471563013971061,
      "loss": 2.8347,
      "step": 219560
    },
    {
      "epoch": 353.0,
      "eval_accuracy": {
        "accuracy": 0.38832309725569464
      },
      "eval_loss": 2.975555181503296,
      "eval_runtime": 3.2075,
      "eval_samples_per_second": 4010.251,
      "eval_steps_per_second": 62.665,
      "step": 219566
    },
    {
      "epoch": 353.02,
      "learning_rate": 0.06471241470884245,
      "loss": 2.8062,
      "step": 219580
    },
    {
      "epoch": 353.05,
      "learning_rate": 0.06470919927797428,
      "loss": 2.8311,
      "step": 219600
    },
    {
      "epoch": 353.09,
      "learning_rate": 0.06470598384710612,
      "loss": 2.84,
      "step": 219620
    },
    {
      "epoch": 353.12,
      "learning_rate": 0.06470276841623794,
      "loss": 2.8571,
      "step": 219640
    },
    {
      "epoch": 353.15,
      "learning_rate": 0.06469955298536978,
      "loss": 2.8246,
      "step": 219660
    },
    {
      "epoch": 353.18,
      "learning_rate": 0.06469633755450162,
      "loss": 2.8081,
      "step": 219680
    },
    {
      "epoch": 353.22,
      "learning_rate": 0.06469312212363344,
      "loss": 2.8351,
      "step": 219700
    },
    {
      "epoch": 353.25,
      "learning_rate": 0.06468990669276528,
      "loss": 2.8298,
      "step": 219720
    },
    {
      "epoch": 353.28,
      "learning_rate": 0.0646866912618971,
      "loss": 2.8504,
      "step": 219740
    },
    {
      "epoch": 353.31,
      "learning_rate": 0.06468347583102894,
      "loss": 2.8435,
      "step": 219760
    },
    {
      "epoch": 353.34,
      "learning_rate": 0.06468026040016077,
      "loss": 2.8531,
      "step": 219780
    },
    {
      "epoch": 353.38,
      "learning_rate": 0.06467704496929261,
      "loss": 2.8346,
      "step": 219800
    },
    {
      "epoch": 353.41,
      "learning_rate": 0.06467382953842445,
      "loss": 2.8177,
      "step": 219820
    },
    {
      "epoch": 353.44,
      "learning_rate": 0.06467061410755627,
      "loss": 2.8237,
      "step": 219840
    },
    {
      "epoch": 353.47,
      "learning_rate": 0.06466739867668811,
      "loss": 2.8388,
      "step": 219860
    },
    {
      "epoch": 353.5,
      "learning_rate": 0.06466418324581993,
      "loss": 2.8137,
      "step": 219880
    },
    {
      "epoch": 353.54,
      "learning_rate": 0.06466096781495177,
      "loss": 2.7988,
      "step": 219900
    },
    {
      "epoch": 353.57,
      "learning_rate": 0.06465775238408361,
      "loss": 2.7904,
      "step": 219920
    },
    {
      "epoch": 353.6,
      "learning_rate": 0.06465453695321544,
      "loss": 2.8332,
      "step": 219940
    },
    {
      "epoch": 353.63,
      "learning_rate": 0.06465132152234727,
      "loss": 2.8048,
      "step": 219960
    },
    {
      "epoch": 353.67,
      "learning_rate": 0.0646481060914791,
      "loss": 2.7999,
      "step": 219980
    },
    {
      "epoch": 353.7,
      "learning_rate": 0.06464489066061094,
      "loss": 2.8309,
      "step": 220000
    },
    {
      "epoch": 353.73,
      "learning_rate": 0.06464167522974278,
      "loss": 2.8203,
      "step": 220020
    },
    {
      "epoch": 353.76,
      "learning_rate": 0.0646384597988746,
      "loss": 2.8404,
      "step": 220040
    },
    {
      "epoch": 353.79,
      "learning_rate": 0.06463524436800644,
      "loss": 2.8528,
      "step": 220060
    },
    {
      "epoch": 353.83,
      "learning_rate": 0.06463202893713826,
      "loss": 2.7863,
      "step": 220080
    },
    {
      "epoch": 353.86,
      "learning_rate": 0.0646288135062701,
      "loss": 2.8082,
      "step": 220100
    },
    {
      "epoch": 353.89,
      "learning_rate": 0.06462559807540193,
      "loss": 2.7995,
      "step": 220120
    },
    {
      "epoch": 353.92,
      "learning_rate": 0.06462238264453377,
      "loss": 2.813,
      "step": 220140
    },
    {
      "epoch": 353.95,
      "learning_rate": 0.0646191672136656,
      "loss": 2.8198,
      "step": 220160
    },
    {
      "epoch": 353.99,
      "learning_rate": 0.06461595178279743,
      "loss": 2.7954,
      "step": 220180
    },
    {
      "epoch": 354.0,
      "eval_accuracy": {
        "accuracy": 0.39469797092435666
      },
      "eval_loss": 2.9317333698272705,
      "eval_runtime": 3.185,
      "eval_samples_per_second": 4038.637,
      "eval_steps_per_second": 63.109,
      "step": 220188
    },
    {
      "epoch": 354.02,
      "learning_rate": 0.06461273635192927,
      "loss": 2.7973,
      "step": 220200
    },
    {
      "epoch": 354.05,
      "learning_rate": 0.06460952092106109,
      "loss": 2.805,
      "step": 220220
    },
    {
      "epoch": 354.08,
      "learning_rate": 0.06460630549019293,
      "loss": 2.7816,
      "step": 220240
    },
    {
      "epoch": 354.12,
      "learning_rate": 0.06460309005932477,
      "loss": 2.8372,
      "step": 220260
    },
    {
      "epoch": 354.15,
      "learning_rate": 0.0645998746284566,
      "loss": 2.8254,
      "step": 220280
    },
    {
      "epoch": 354.18,
      "learning_rate": 0.06459665919758843,
      "loss": 2.8037,
      "step": 220300
    },
    {
      "epoch": 354.21,
      "learning_rate": 0.06459344376672026,
      "loss": 2.8086,
      "step": 220320
    },
    {
      "epoch": 354.24,
      "learning_rate": 0.0645903891073955,
      "loss": 2.8148,
      "step": 220340
    },
    {
      "epoch": 354.28,
      "learning_rate": 0.06458717367652735,
      "loss": 2.8042,
      "step": 220360
    },
    {
      "epoch": 354.31,
      "learning_rate": 0.06458395824565916,
      "loss": 2.8124,
      "step": 220380
    },
    {
      "epoch": 354.34,
      "learning_rate": 0.06458074281479101,
      "loss": 2.8011,
      "step": 220400
    },
    {
      "epoch": 354.37,
      "learning_rate": 0.06457752738392283,
      "loss": 2.8024,
      "step": 220420
    },
    {
      "epoch": 354.41,
      "learning_rate": 0.06457431195305466,
      "loss": 2.8201,
      "step": 220440
    },
    {
      "epoch": 354.44,
      "learning_rate": 0.06457109652218651,
      "loss": 2.8322,
      "step": 220460
    },
    {
      "epoch": 354.47,
      "learning_rate": 0.06456788109131832,
      "loss": 2.8208,
      "step": 220480
    },
    {
      "epoch": 354.5,
      "learning_rate": 0.06456466566045017,
      "loss": 2.8302,
      "step": 220500
    },
    {
      "epoch": 354.53,
      "learning_rate": 0.064561450229582,
      "loss": 2.7888,
      "step": 220520
    },
    {
      "epoch": 354.57,
      "learning_rate": 0.06455823479871382,
      "loss": 2.7983,
      "step": 220540
    },
    {
      "epoch": 354.6,
      "learning_rate": 0.06455501936784568,
      "loss": 2.8204,
      "step": 220560
    },
    {
      "epoch": 354.63,
      "learning_rate": 0.06455180393697749,
      "loss": 2.8135,
      "step": 220580
    },
    {
      "epoch": 354.66,
      "learning_rate": 0.06454858850610934,
      "loss": 2.8417,
      "step": 220600
    },
    {
      "epoch": 354.69,
      "learning_rate": 0.06454537307524116,
      "loss": 2.8304,
      "step": 220620
    },
    {
      "epoch": 354.73,
      "learning_rate": 0.06454215764437299,
      "loss": 2.8529,
      "step": 220640
    },
    {
      "epoch": 354.76,
      "learning_rate": 0.06453894221350483,
      "loss": 2.8244,
      "step": 220660
    },
    {
      "epoch": 354.79,
      "learning_rate": 0.06453572678263665,
      "loss": 2.816,
      "step": 220680
    },
    {
      "epoch": 354.82,
      "learning_rate": 0.0645325113517685,
      "loss": 2.8139,
      "step": 220700
    },
    {
      "epoch": 354.86,
      "learning_rate": 0.06452929592090031,
      "loss": 2.8077,
      "step": 220720
    },
    {
      "epoch": 354.89,
      "learning_rate": 0.06452608049003215,
      "loss": 2.8309,
      "step": 220740
    },
    {
      "epoch": 354.92,
      "learning_rate": 0.06452286505916399,
      "loss": 2.8384,
      "step": 220760
    },
    {
      "epoch": 354.95,
      "learning_rate": 0.06451964962829582,
      "loss": 2.8169,
      "step": 220780
    },
    {
      "epoch": 354.98,
      "learning_rate": 0.06451643419742767,
      "loss": 2.8465,
      "step": 220800
    },
    {
      "epoch": 355.0,
      "eval_accuracy": {
        "accuracy": 0.39718572650237116
      },
      "eval_loss": 2.9036569595336914,
      "eval_runtime": 3.1214,
      "eval_samples_per_second": 4120.869,
      "eval_steps_per_second": 64.394,
      "step": 220810
    },
    {
      "epoch": 355.02,
      "learning_rate": 0.06451321876655948,
      "loss": 2.8151,
      "step": 220820
    },
    {
      "epoch": 355.05,
      "learning_rate": 0.06451000333569133,
      "loss": 2.8274,
      "step": 220840
    },
    {
      "epoch": 355.08,
      "learning_rate": 0.06450678790482316,
      "loss": 2.8366,
      "step": 220860
    },
    {
      "epoch": 355.11,
      "learning_rate": 0.06450357247395498,
      "loss": 2.8047,
      "step": 220880
    },
    {
      "epoch": 355.14,
      "learning_rate": 0.06450035704308683,
      "loss": 2.8123,
      "step": 220900
    },
    {
      "epoch": 355.18,
      "learning_rate": 0.06449714161221864,
      "loss": 2.7815,
      "step": 220920
    },
    {
      "epoch": 355.21,
      "learning_rate": 0.0644939261813505,
      "loss": 2.7988,
      "step": 220940
    },
    {
      "epoch": 355.24,
      "learning_rate": 0.06449071075048232,
      "loss": 2.7756,
      "step": 220960
    },
    {
      "epoch": 355.27,
      "learning_rate": 0.06448749531961415,
      "loss": 2.7992,
      "step": 220980
    },
    {
      "epoch": 355.31,
      "learning_rate": 0.06448427988874599,
      "loss": 2.8263,
      "step": 221000
    },
    {
      "epoch": 355.34,
      "learning_rate": 0.06448106445787781,
      "loss": 2.8367,
      "step": 221020
    },
    {
      "epoch": 355.37,
      "learning_rate": 0.06447784902700966,
      "loss": 2.8298,
      "step": 221040
    },
    {
      "epoch": 355.4,
      "learning_rate": 0.06447463359614147,
      "loss": 2.831,
      "step": 221060
    },
    {
      "epoch": 355.43,
      "learning_rate": 0.06447141816527331,
      "loss": 2.8079,
      "step": 221080
    },
    {
      "epoch": 355.47,
      "learning_rate": 0.06446820273440515,
      "loss": 2.818,
      "step": 221100
    },
    {
      "epoch": 355.5,
      "learning_rate": 0.06446498730353697,
      "loss": 2.8138,
      "step": 221120
    },
    {
      "epoch": 355.53,
      "learning_rate": 0.06446177187266883,
      "loss": 2.8098,
      "step": 221140
    },
    {
      "epoch": 355.56,
      "learning_rate": 0.06445855644180064,
      "loss": 2.8195,
      "step": 221160
    },
    {
      "epoch": 355.59,
      "learning_rate": 0.06445534101093248,
      "loss": 2.8076,
      "step": 221180
    },
    {
      "epoch": 355.63,
      "learning_rate": 0.06445212558006432,
      "loss": 2.8172,
      "step": 221200
    },
    {
      "epoch": 355.66,
      "learning_rate": 0.06444891014919614,
      "loss": 2.8664,
      "step": 221220
    },
    {
      "epoch": 355.69,
      "learning_rate": 0.06444569471832799,
      "loss": 2.8216,
      "step": 221240
    },
    {
      "epoch": 355.72,
      "learning_rate": 0.0644424792874598,
      "loss": 2.8268,
      "step": 221260
    },
    {
      "epoch": 355.76,
      "learning_rate": 0.06443926385659164,
      "loss": 2.8575,
      "step": 221280
    },
    {
      "epoch": 355.79,
      "learning_rate": 0.06443604842572348,
      "loss": 2.8252,
      "step": 221300
    },
    {
      "epoch": 355.82,
      "learning_rate": 0.0644328329948553,
      "loss": 2.7926,
      "step": 221320
    },
    {
      "epoch": 355.85,
      "learning_rate": 0.06442961756398714,
      "loss": 2.7823,
      "step": 221340
    },
    {
      "epoch": 355.88,
      "learning_rate": 0.06442640213311897,
      "loss": 2.7879,
      "step": 221360
    },
    {
      "epoch": 355.92,
      "learning_rate": 0.0644231867022508,
      "loss": 2.8282,
      "step": 221380
    },
    {
      "epoch": 355.95,
      "learning_rate": 0.06441997127138263,
      "loss": 2.8244,
      "step": 221400
    },
    {
      "epoch": 355.98,
      "learning_rate": 0.06441675584051447,
      "loss": 2.811,
      "step": 221420
    },
    {
      "epoch": 356.0,
      "eval_accuracy": {
        "accuracy": 0.39166601881365154
      },
      "eval_loss": 2.948978900909424,
      "eval_runtime": 4.0858,
      "eval_samples_per_second": 3148.19,
      "eval_steps_per_second": 49.194,
      "step": 221432
    },
    {
      "epoch": 356.01,
      "learning_rate": 0.06441354040964631,
      "loss": 2.7991,
      "step": 221440
    },
    {
      "epoch": 356.05,
      "learning_rate": 0.06441032497877813,
      "loss": 2.7799,
      "step": 221460
    },
    {
      "epoch": 356.08,
      "learning_rate": 0.06440710954790999,
      "loss": 2.792,
      "step": 221480
    },
    {
      "epoch": 356.11,
      "learning_rate": 0.0644038941170418,
      "loss": 2.841,
      "step": 221500
    },
    {
      "epoch": 356.14,
      "learning_rate": 0.06440067868617363,
      "loss": 2.7843,
      "step": 221520
    },
    {
      "epoch": 356.17,
      "learning_rate": 0.06439746325530547,
      "loss": 2.8284,
      "step": 221540
    },
    {
      "epoch": 356.21,
      "learning_rate": 0.0643942478244373,
      "loss": 2.8112,
      "step": 221560
    },
    {
      "epoch": 356.24,
      "learning_rate": 0.06439103239356915,
      "loss": 2.801,
      "step": 221580
    },
    {
      "epoch": 356.27,
      "learning_rate": 0.06438781696270096,
      "loss": 2.7663,
      "step": 221600
    },
    {
      "epoch": 356.3,
      "learning_rate": 0.0643846015318328,
      "loss": 2.8088,
      "step": 221620
    },
    {
      "epoch": 356.33,
      "learning_rate": 0.06438138610096464,
      "loss": 2.8036,
      "step": 221640
    },
    {
      "epoch": 356.37,
      "learning_rate": 0.06437817067009646,
      "loss": 2.8153,
      "step": 221660
    },
    {
      "epoch": 356.4,
      "learning_rate": 0.0643749552392283,
      "loss": 2.8294,
      "step": 221680
    },
    {
      "epoch": 356.43,
      "learning_rate": 0.06437173980836013,
      "loss": 2.8522,
      "step": 221700
    },
    {
      "epoch": 356.46,
      "learning_rate": 0.06436852437749196,
      "loss": 2.8402,
      "step": 221720
    },
    {
      "epoch": 356.5,
      "learning_rate": 0.0643653089466238,
      "loss": 2.8382,
      "step": 221740
    },
    {
      "epoch": 356.53,
      "learning_rate": 0.06436209351575563,
      "loss": 2.8118,
      "step": 221760
    },
    {
      "epoch": 356.56,
      "learning_rate": 0.06435887808488747,
      "loss": 2.8181,
      "step": 221780
    },
    {
      "epoch": 356.59,
      "learning_rate": 0.06435566265401929,
      "loss": 2.8204,
      "step": 221800
    },
    {
      "epoch": 356.62,
      "learning_rate": 0.06435244722315113,
      "loss": 2.7994,
      "step": 221820
    },
    {
      "epoch": 356.66,
      "learning_rate": 0.06434923179228295,
      "loss": 2.8186,
      "step": 221840
    },
    {
      "epoch": 356.69,
      "learning_rate": 0.06434601636141479,
      "loss": 2.8087,
      "step": 221860
    },
    {
      "epoch": 356.72,
      "learning_rate": 0.06434280093054663,
      "loss": 2.8049,
      "step": 221880
    },
    {
      "epoch": 356.75,
      "learning_rate": 0.06433958549967846,
      "loss": 2.8232,
      "step": 221900
    },
    {
      "epoch": 356.78,
      "learning_rate": 0.0643363700688103,
      "loss": 2.8244,
      "step": 221920
    },
    {
      "epoch": 356.82,
      "learning_rate": 0.06433315463794212,
      "loss": 2.8296,
      "step": 221940
    },
    {
      "epoch": 356.85,
      "learning_rate": 0.06432993920707396,
      "loss": 2.8245,
      "step": 221960
    },
    {
      "epoch": 356.88,
      "learning_rate": 0.0643267237762058,
      "loss": 2.8311,
      "step": 221980
    },
    {
      "epoch": 356.91,
      "learning_rate": 0.06432350834533762,
      "loss": 2.8434,
      "step": 222000
    },
    {
      "epoch": 356.95,
      "learning_rate": 0.06432029291446946,
      "loss": 2.8269,
      "step": 222020
    },
    {
      "epoch": 356.98,
      "learning_rate": 0.06431707748360128,
      "loss": 2.7896,
      "step": 222040
    },
    {
      "epoch": 357.0,
      "eval_accuracy": {
        "accuracy": 0.3873901889139392
      },
      "eval_loss": 2.9562036991119385,
      "eval_runtime": 3.1681,
      "eval_samples_per_second": 4060.206,
      "eval_steps_per_second": 63.446,
      "step": 222054
    },
    {
      "epoch": 357.01,
      "learning_rate": 0.06431386205273312,
      "loss": 2.8178,
      "step": 222060
    },
    {
      "epoch": 357.04,
      "learning_rate": 0.06431064662186496,
      "loss": 2.822,
      "step": 222080
    },
    {
      "epoch": 357.07,
      "learning_rate": 0.06430743119099679,
      "loss": 2.8072,
      "step": 222100
    },
    {
      "epoch": 357.11,
      "learning_rate": 0.06430421576012862,
      "loss": 2.809,
      "step": 222120
    },
    {
      "epoch": 357.14,
      "learning_rate": 0.06430100032926045,
      "loss": 2.8175,
      "step": 222140
    },
    {
      "epoch": 357.17,
      "learning_rate": 0.06429778489839229,
      "loss": 2.8167,
      "step": 222160
    },
    {
      "epoch": 357.2,
      "learning_rate": 0.06429456946752411,
      "loss": 2.8116,
      "step": 222180
    },
    {
      "epoch": 357.23,
      "learning_rate": 0.06429135403665595,
      "loss": 2.7846,
      "step": 222200
    },
    {
      "epoch": 357.27,
      "learning_rate": 0.06428813860578779,
      "loss": 2.816,
      "step": 222220
    },
    {
      "epoch": 357.3,
      "learning_rate": 0.06428492317491961,
      "loss": 2.8202,
      "step": 222240
    },
    {
      "epoch": 357.33,
      "learning_rate": 0.06428170774405145,
      "loss": 2.8228,
      "step": 222260
    },
    {
      "epoch": 357.36,
      "learning_rate": 0.06427849231318328,
      "loss": 2.777,
      "step": 222280
    },
    {
      "epoch": 357.4,
      "learning_rate": 0.06427527688231512,
      "loss": 2.799,
      "step": 222300
    },
    {
      "epoch": 357.43,
      "learning_rate": 0.06427206145144695,
      "loss": 2.7934,
      "step": 222320
    },
    {
      "epoch": 357.46,
      "learning_rate": 0.06426884602057878,
      "loss": 2.8383,
      "step": 222340
    },
    {
      "epoch": 357.49,
      "learning_rate": 0.06426563058971062,
      "loss": 2.817,
      "step": 222360
    },
    {
      "epoch": 357.52,
      "learning_rate": 0.06426241515884244,
      "loss": 2.7816,
      "step": 222380
    },
    {
      "epoch": 357.56,
      "learning_rate": 0.06425919972797428,
      "loss": 2.8088,
      "step": 222400
    },
    {
      "epoch": 357.59,
      "learning_rate": 0.06425598429710612,
      "loss": 2.8407,
      "step": 222420
    },
    {
      "epoch": 357.62,
      "learning_rate": 0.06425276886623794,
      "loss": 2.8325,
      "step": 222440
    },
    {
      "epoch": 357.65,
      "learning_rate": 0.0642497142069132,
      "loss": 2.802,
      "step": 222460
    },
    {
      "epoch": 357.68,
      "learning_rate": 0.06424649877604502,
      "loss": 2.8196,
      "step": 222480
    },
    {
      "epoch": 357.72,
      "learning_rate": 0.06424328334517686,
      "loss": 2.8023,
      "step": 222500
    },
    {
      "epoch": 357.75,
      "learning_rate": 0.0642400679143087,
      "loss": 2.8225,
      "step": 222520
    },
    {
      "epoch": 357.78,
      "learning_rate": 0.0642368524834405,
      "loss": 2.8232,
      "step": 222540
    },
    {
      "epoch": 357.81,
      "learning_rate": 0.06423363705257236,
      "loss": 2.7967,
      "step": 222560
    },
    {
      "epoch": 357.85,
      "learning_rate": 0.06423042162170418,
      "loss": 2.8281,
      "step": 222580
    },
    {
      "epoch": 357.88,
      "learning_rate": 0.06422720619083602,
      "loss": 2.853,
      "step": 222600
    },
    {
      "epoch": 357.91,
      "learning_rate": 0.06422399075996786,
      "loss": 2.8087,
      "step": 222620
    },
    {
      "epoch": 357.94,
      "learning_rate": 0.06422077532909967,
      "loss": 2.8208,
      "step": 222640
    },
    {
      "epoch": 357.97,
      "learning_rate": 0.06421755989823152,
      "loss": 2.816,
      "step": 222660
    },
    {
      "epoch": 358.0,
      "eval_accuracy": {
        "accuracy": 0.39073311047189613
      },
      "eval_loss": 2.946671962738037,
      "eval_runtime": 2.8355,
      "eval_samples_per_second": 4536.377,
      "eval_steps_per_second": 70.886,
      "step": 222676
    },
    {
      "epoch": 358.01,
      "learning_rate": 0.06421434446736335,
      "loss": 2.8209,
      "step": 222680
    },
    {
      "epoch": 358.04,
      "learning_rate": 0.06421112903649519,
      "loss": 2.8051,
      "step": 222700
    },
    {
      "epoch": 358.07,
      "learning_rate": 0.06420791360562701,
      "loss": 2.821,
      "step": 222720
    },
    {
      "epoch": 358.1,
      "learning_rate": 0.06420469817475884,
      "loss": 2.7798,
      "step": 222740
    },
    {
      "epoch": 358.14,
      "learning_rate": 0.06420148274389069,
      "loss": 2.8345,
      "step": 222760
    },
    {
      "epoch": 358.17,
      "learning_rate": 0.0641982673130225,
      "loss": 2.8015,
      "step": 222780
    },
    {
      "epoch": 358.2,
      "learning_rate": 0.06419505188215435,
      "loss": 2.8062,
      "step": 222800
    },
    {
      "epoch": 358.23,
      "learning_rate": 0.06419183645128618,
      "loss": 2.7743,
      "step": 222820
    },
    {
      "epoch": 358.26,
      "learning_rate": 0.064188621020418,
      "loss": 2.7805,
      "step": 222840
    },
    {
      "epoch": 358.3,
      "learning_rate": 0.06418540558954985,
      "loss": 2.8064,
      "step": 222860
    },
    {
      "epoch": 358.33,
      "learning_rate": 0.06418219015868167,
      "loss": 2.819,
      "step": 222880
    },
    {
      "epoch": 358.36,
      "learning_rate": 0.06417897472781352,
      "loss": 2.8432,
      "step": 222900
    },
    {
      "epoch": 358.39,
      "learning_rate": 0.06417575929694534,
      "loss": 2.8095,
      "step": 222920
    },
    {
      "epoch": 358.42,
      "learning_rate": 0.06417254386607717,
      "loss": 2.8191,
      "step": 222940
    },
    {
      "epoch": 358.46,
      "learning_rate": 0.06416932843520902,
      "loss": 2.8049,
      "step": 222960
    },
    {
      "epoch": 358.49,
      "learning_rate": 0.06416611300434083,
      "loss": 2.8177,
      "step": 222980
    },
    {
      "epoch": 358.52,
      "learning_rate": 0.06416289757347268,
      "loss": 2.8222,
      "step": 223000
    },
    {
      "epoch": 358.55,
      "learning_rate": 0.06415968214260451,
      "loss": 2.8149,
      "step": 223020
    },
    {
      "epoch": 358.59,
      "learning_rate": 0.06415646671173635,
      "loss": 2.8174,
      "step": 223040
    },
    {
      "epoch": 358.62,
      "learning_rate": 0.06415325128086817,
      "loss": 2.8275,
      "step": 223060
    },
    {
      "epoch": 358.65,
      "learning_rate": 0.06415003585,
      "loss": 2.8111,
      "step": 223080
    },
    {
      "epoch": 358.68,
      "learning_rate": 0.06414682041913185,
      "loss": 2.8295,
      "step": 223100
    },
    {
      "epoch": 358.71,
      "learning_rate": 0.06414360498826366,
      "loss": 2.8328,
      "step": 223120
    },
    {
      "epoch": 358.75,
      "learning_rate": 0.06414038955739551,
      "loss": 2.8,
      "step": 223140
    },
    {
      "epoch": 358.78,
      "learning_rate": 0.06413717412652734,
      "loss": 2.8227,
      "step": 223160
    },
    {
      "epoch": 358.81,
      "learning_rate": 0.06413395869565916,
      "loss": 2.8175,
      "step": 223180
    },
    {
      "epoch": 358.84,
      "learning_rate": 0.06413074326479101,
      "loss": 2.8098,
      "step": 223200
    },
    {
      "epoch": 358.87,
      "learning_rate": 0.06412752783392282,
      "loss": 2.8227,
      "step": 223220
    },
    {
      "epoch": 358.91,
      "learning_rate": 0.06412431240305468,
      "loss": 2.8011,
      "step": 223240
    },
    {
      "epoch": 358.94,
      "learning_rate": 0.0641210969721865,
      "loss": 2.8168,
      "step": 223260
    },
    {
      "epoch": 358.97,
      "learning_rate": 0.06411788154131833,
      "loss": 2.8053,
      "step": 223280
    },
    {
      "epoch": 359.0,
      "eval_accuracy": {
        "accuracy": 0.39213247298452925
      },
      "eval_loss": 2.955152988433838,
      "eval_runtime": 2.7636,
      "eval_samples_per_second": 4654.418,
      "eval_steps_per_second": 72.731,
      "step": 223298
    },
    {
      "epoch": 359.0,
      "learning_rate": 0.06411466611045018,
      "loss": 2.824,
      "step": 223300
    },
    {
      "epoch": 359.04,
      "learning_rate": 0.06411145067958199,
      "loss": 2.8245,
      "step": 223320
    },
    {
      "epoch": 359.07,
      "learning_rate": 0.06410823524871384,
      "loss": 2.8172,
      "step": 223340
    },
    {
      "epoch": 359.1,
      "learning_rate": 0.06410501981784567,
      "loss": 2.8253,
      "step": 223360
    },
    {
      "epoch": 359.13,
      "learning_rate": 0.06410180438697749,
      "loss": 2.7972,
      "step": 223380
    },
    {
      "epoch": 359.16,
      "learning_rate": 0.06409858895610933,
      "loss": 2.8017,
      "step": 223400
    },
    {
      "epoch": 359.2,
      "learning_rate": 0.06409537352524115,
      "loss": 2.7981,
      "step": 223420
    },
    {
      "epoch": 359.23,
      "learning_rate": 0.064092158094373,
      "loss": 2.8364,
      "step": 223440
    },
    {
      "epoch": 359.26,
      "learning_rate": 0.06408894266350482,
      "loss": 2.853,
      "step": 223460
    },
    {
      "epoch": 359.29,
      "learning_rate": 0.06408572723263666,
      "loss": 2.8309,
      "step": 223480
    },
    {
      "epoch": 359.32,
      "learning_rate": 0.0640825118017685,
      "loss": 2.8496,
      "step": 223500
    },
    {
      "epoch": 359.36,
      "learning_rate": 0.06407929637090032,
      "loss": 2.7863,
      "step": 223520
    },
    {
      "epoch": 359.39,
      "learning_rate": 0.06407608094003217,
      "loss": 2.7893,
      "step": 223540
    },
    {
      "epoch": 359.42,
      "learning_rate": 0.06407286550916398,
      "loss": 2.8445,
      "step": 223560
    },
    {
      "epoch": 359.45,
      "learning_rate": 0.06406965007829582,
      "loss": 2.8316,
      "step": 223580
    },
    {
      "epoch": 359.49,
      "learning_rate": 0.06406643464742766,
      "loss": 2.8511,
      "step": 223600
    },
    {
      "epoch": 359.52,
      "learning_rate": 0.06406321921655948,
      "loss": 2.8148,
      "step": 223620
    },
    {
      "epoch": 359.55,
      "learning_rate": 0.06406000378569134,
      "loss": 2.7913,
      "step": 223640
    },
    {
      "epoch": 359.58,
      "learning_rate": 0.06405678835482315,
      "loss": 2.8135,
      "step": 223660
    },
    {
      "epoch": 359.61,
      "learning_rate": 0.064053572923955,
      "loss": 2.7928,
      "step": 223680
    },
    {
      "epoch": 359.65,
      "learning_rate": 0.06405035749308682,
      "loss": 2.7987,
      "step": 223700
    },
    {
      "epoch": 359.68,
      "learning_rate": 0.06404714206221865,
      "loss": 2.8,
      "step": 223720
    },
    {
      "epoch": 359.71,
      "learning_rate": 0.06404392663135049,
      "loss": 2.8382,
      "step": 223740
    },
    {
      "epoch": 359.74,
      "learning_rate": 0.06404071120048231,
      "loss": 2.8372,
      "step": 223760
    },
    {
      "epoch": 359.77,
      "learning_rate": 0.06403749576961416,
      "loss": 2.7998,
      "step": 223780
    },
    {
      "epoch": 359.81,
      "learning_rate": 0.06403428033874597,
      "loss": 2.8326,
      "step": 223800
    },
    {
      "epoch": 359.84,
      "learning_rate": 0.06403106490787781,
      "loss": 2.8129,
      "step": 223820
    },
    {
      "epoch": 359.87,
      "learning_rate": 0.06402784947700965,
      "loss": 2.8287,
      "step": 223840
    },
    {
      "epoch": 359.9,
      "learning_rate": 0.06402463404614148,
      "loss": 2.8348,
      "step": 223860
    },
    {
      "epoch": 359.94,
      "learning_rate": 0.06402141861527333,
      "loss": 2.8359,
      "step": 223880
    },
    {
      "epoch": 359.97,
      "learning_rate": 0.06401820318440514,
      "loss": 2.8133,
      "step": 223900
    },
    {
      "epoch": 360.0,
      "learning_rate": 0.06401498775353698,
      "loss": 2.7873,
      "step": 223920
    },
    {
      "epoch": 360.0,
      "eval_accuracy": {
        "accuracy": 0.39073311047189613
      },
      "eval_loss": 2.9079606533050537,
      "eval_runtime": 3.0348,
      "eval_samples_per_second": 4238.539,
      "eval_steps_per_second": 66.232,
      "step": 223920
    },
    {
      "epoch": 360.03,
      "learning_rate": 0.06401177232266882,
      "loss": 2.8053,
      "step": 223940
    },
    {
      "epoch": 360.06,
      "learning_rate": 0.06400855689180064,
      "loss": 2.8357,
      "step": 223960
    },
    {
      "epoch": 360.1,
      "learning_rate": 0.0640053414609325,
      "loss": 2.7695,
      "step": 223980
    },
    {
      "epoch": 360.13,
      "learning_rate": 0.0640021260300643,
      "loss": 2.7878,
      "step": 224000
    },
    {
      "epoch": 360.16,
      "learning_rate": 0.06399891059919614,
      "loss": 2.7942,
      "step": 224020
    },
    {
      "epoch": 360.19,
      "learning_rate": 0.06399569516832798,
      "loss": 2.7913,
      "step": 224040
    },
    {
      "epoch": 360.23,
      "learning_rate": 0.0639924797374598,
      "loss": 2.8056,
      "step": 224060
    },
    {
      "epoch": 360.26,
      "learning_rate": 0.06398926430659164,
      "loss": 2.8104,
      "step": 224080
    },
    {
      "epoch": 360.29,
      "learning_rate": 0.06398604887572347,
      "loss": 2.822,
      "step": 224100
    },
    {
      "epoch": 360.32,
      "learning_rate": 0.06398283344485531,
      "loss": 2.8106,
      "step": 224120
    },
    {
      "epoch": 360.35,
      "learning_rate": 0.06397961801398715,
      "loss": 2.8148,
      "step": 224140
    },
    {
      "epoch": 360.39,
      "learning_rate": 0.06397640258311897,
      "loss": 2.8217,
      "step": 224160
    },
    {
      "epoch": 360.42,
      "learning_rate": 0.06397318715225081,
      "loss": 2.8024,
      "step": 224180
    },
    {
      "epoch": 360.45,
      "learning_rate": 0.06396997172138263,
      "loss": 2.817,
      "step": 224200
    },
    {
      "epoch": 360.48,
      "learning_rate": 0.06396675629051447,
      "loss": 2.83,
      "step": 224220
    },
    {
      "epoch": 360.51,
      "learning_rate": 0.0639635408596463,
      "loss": 2.822,
      "step": 224240
    },
    {
      "epoch": 360.55,
      "learning_rate": 0.06396032542877814,
      "loss": 2.8337,
      "step": 224260
    },
    {
      "epoch": 360.58,
      "learning_rate": 0.06395710999790997,
      "loss": 2.8011,
      "step": 224280
    },
    {
      "epoch": 360.61,
      "learning_rate": 0.0639538945670418,
      "loss": 2.7817,
      "step": 224300
    },
    {
      "epoch": 360.64,
      "learning_rate": 0.06395067913617365,
      "loss": 2.8112,
      "step": 224320
    },
    {
      "epoch": 360.68,
      "learning_rate": 0.06394746370530546,
      "loss": 2.8126,
      "step": 224340
    },
    {
      "epoch": 360.71,
      "learning_rate": 0.0639442482744373,
      "loss": 2.8318,
      "step": 224360
    },
    {
      "epoch": 360.74,
      "learning_rate": 0.06394103284356914,
      "loss": 2.8162,
      "step": 224380
    },
    {
      "epoch": 360.77,
      "learning_rate": 0.06393781741270096,
      "loss": 2.7876,
      "step": 224400
    },
    {
      "epoch": 360.8,
      "learning_rate": 0.0639346019818328,
      "loss": 2.815,
      "step": 224420
    },
    {
      "epoch": 360.84,
      "learning_rate": 0.06393138655096463,
      "loss": 2.7901,
      "step": 224440
    },
    {
      "epoch": 360.87,
      "learning_rate": 0.06392817112009647,
      "loss": 2.8036,
      "step": 224460
    },
    {
      "epoch": 360.9,
      "learning_rate": 0.0639249556892283,
      "loss": 2.7841,
      "step": 224480
    },
    {
      "epoch": 360.93,
      "learning_rate": 0.06392174025836013,
      "loss": 2.8241,
      "step": 224500
    },
    {
      "epoch": 360.96,
      "learning_rate": 0.06391852482749197,
      "loss": 2.8309,
      "step": 224520
    },
    {
      "epoch": 361.0,
      "learning_rate": 0.06391530939662379,
      "loss": 2.8517,
      "step": 224540
    },
    {
      "epoch": 361.0,
      "eval_accuracy": {
        "accuracy": 0.3905776257482702
      },
      "eval_loss": 2.9387669563293457,
      "eval_runtime": 3.2128,
      "eval_samples_per_second": 4003.663,
      "eval_steps_per_second": 62.562,
      "step": 224542
    },
    {
      "epoch": 361.03,
      "learning_rate": 0.06391225473729904,
      "loss": 2.8468,
      "step": 224560
    },
    {
      "epoch": 361.06,
      "learning_rate": 0.06390903930643088,
      "loss": 2.8118,
      "step": 224580
    },
    {
      "epoch": 361.09,
      "learning_rate": 0.0639058238755627,
      "loss": 2.7927,
      "step": 224600
    },
    {
      "epoch": 361.13,
      "learning_rate": 0.06390260844469454,
      "loss": 2.8164,
      "step": 224620
    },
    {
      "epoch": 361.16,
      "learning_rate": 0.06389939301382637,
      "loss": 2.8442,
      "step": 224640
    },
    {
      "epoch": 361.19,
      "learning_rate": 0.06389617758295821,
      "loss": 2.8304,
      "step": 224660
    },
    {
      "epoch": 361.22,
      "learning_rate": 0.06389296215209005,
      "loss": 2.8244,
      "step": 224680
    },
    {
      "epoch": 361.25,
      "learning_rate": 0.06388974672122187,
      "loss": 2.8195,
      "step": 224700
    },
    {
      "epoch": 361.29,
      "learning_rate": 0.06388653129035371,
      "loss": 2.7987,
      "step": 224720
    },
    {
      "epoch": 361.32,
      "learning_rate": 0.06388331585948553,
      "loss": 2.809,
      "step": 224740
    },
    {
      "epoch": 361.35,
      "learning_rate": 0.06388010042861737,
      "loss": 2.7925,
      "step": 224760
    },
    {
      "epoch": 361.38,
      "learning_rate": 0.0638768849977492,
      "loss": 2.7859,
      "step": 224780
    },
    {
      "epoch": 361.41,
      "learning_rate": 0.06387366956688104,
      "loss": 2.8313,
      "step": 224800
    },
    {
      "epoch": 361.45,
      "learning_rate": 0.06387045413601287,
      "loss": 2.7917,
      "step": 224820
    },
    {
      "epoch": 361.48,
      "learning_rate": 0.06386723870514469,
      "loss": 2.8086,
      "step": 224840
    },
    {
      "epoch": 361.51,
      "learning_rate": 0.06386402327427654,
      "loss": 2.8014,
      "step": 224860
    },
    {
      "epoch": 361.54,
      "learning_rate": 0.06386080784340836,
      "loss": 2.7893,
      "step": 224880
    },
    {
      "epoch": 361.58,
      "learning_rate": 0.0638575924125402,
      "loss": 2.8071,
      "step": 224900
    },
    {
      "epoch": 361.61,
      "learning_rate": 0.06385437698167204,
      "loss": 2.8145,
      "step": 224920
    },
    {
      "epoch": 361.64,
      "learning_rate": 0.06385116155080385,
      "loss": 2.8127,
      "step": 224940
    },
    {
      "epoch": 361.67,
      "learning_rate": 0.0638479461199357,
      "loss": 2.8376,
      "step": 224960
    },
    {
      "epoch": 361.7,
      "learning_rate": 0.06384473068906753,
      "loss": 2.8042,
      "step": 224980
    },
    {
      "epoch": 361.74,
      "learning_rate": 0.06384151525819937,
      "loss": 2.8505,
      "step": 225000
    },
    {
      "epoch": 361.77,
      "learning_rate": 0.0638382998273312,
      "loss": 2.8062,
      "step": 225020
    },
    {
      "epoch": 361.8,
      "learning_rate": 0.06383508439646302,
      "loss": 2.8043,
      "step": 225040
    },
    {
      "epoch": 361.83,
      "learning_rate": 0.06383186896559487,
      "loss": 2.8214,
      "step": 225060
    },
    {
      "epoch": 361.86,
      "learning_rate": 0.06382865353472669,
      "loss": 2.8145,
      "step": 225080
    },
    {
      "epoch": 361.9,
      "learning_rate": 0.06382543810385853,
      "loss": 2.819,
      "step": 225100
    },
    {
      "epoch": 361.93,
      "learning_rate": 0.06382222267299036,
      "loss": 2.8074,
      "step": 225120
    },
    {
      "epoch": 361.96,
      "learning_rate": 0.06381900724212218,
      "loss": 2.7966,
      "step": 225140
    },
    {
      "epoch": 361.99,
      "learning_rate": 0.06381579181125403,
      "loss": 2.8012,
      "step": 225160
    },
    {
      "epoch": 362.0,
      "eval_accuracy": {
        "accuracy": 0.3981186348441266
      },
      "eval_loss": 2.901662826538086,
      "eval_runtime": 3.3864,
      "eval_samples_per_second": 3798.479,
      "eval_steps_per_second": 59.356,
      "step": 225164
    },
    {
      "epoch": 362.03,
      "learning_rate": 0.06381257638038584,
      "loss": 2.8124,
      "step": 225180
    },
    {
      "epoch": 362.06,
      "learning_rate": 0.0638093609495177,
      "loss": 2.814,
      "step": 225200
    },
    {
      "epoch": 362.09,
      "learning_rate": 0.06380614551864952,
      "loss": 2.8108,
      "step": 225220
    },
    {
      "epoch": 362.12,
      "learning_rate": 0.06380293008778136,
      "loss": 2.832,
      "step": 225240
    },
    {
      "epoch": 362.15,
      "learning_rate": 0.0637997146569132,
      "loss": 2.8003,
      "step": 225260
    },
    {
      "epoch": 362.19,
      "learning_rate": 0.06379649922604501,
      "loss": 2.7777,
      "step": 225280
    },
    {
      "epoch": 362.22,
      "learning_rate": 0.06379328379517686,
      "loss": 2.8213,
      "step": 225300
    },
    {
      "epoch": 362.25,
      "learning_rate": 0.06379006836430869,
      "loss": 2.7984,
      "step": 225320
    },
    {
      "epoch": 362.28,
      "learning_rate": 0.06378685293344052,
      "loss": 2.8178,
      "step": 225340
    },
    {
      "epoch": 362.32,
      "learning_rate": 0.06378363750257236,
      "loss": 2.7997,
      "step": 225360
    },
    {
      "epoch": 362.35,
      "learning_rate": 0.06378042207170417,
      "loss": 2.8125,
      "step": 225380
    },
    {
      "epoch": 362.38,
      "learning_rate": 0.06377720664083603,
      "loss": 2.8076,
      "step": 225400
    },
    {
      "epoch": 362.41,
      "learning_rate": 0.06377399120996785,
      "loss": 2.7877,
      "step": 225420
    },
    {
      "epoch": 362.44,
      "learning_rate": 0.06377077577909969,
      "loss": 2.8363,
      "step": 225440
    },
    {
      "epoch": 362.48,
      "learning_rate": 0.06376756034823151,
      "loss": 2.7878,
      "step": 225460
    },
    {
      "epoch": 362.51,
      "learning_rate": 0.06376434491736334,
      "loss": 2.7974,
      "step": 225480
    },
    {
      "epoch": 362.54,
      "learning_rate": 0.06376112948649519,
      "loss": 2.7969,
      "step": 225500
    },
    {
      "epoch": 362.57,
      "learning_rate": 0.063757914055627,
      "loss": 2.8122,
      "step": 225520
    },
    {
      "epoch": 362.6,
      "learning_rate": 0.06375469862475885,
      "loss": 2.8197,
      "step": 225540
    },
    {
      "epoch": 362.64,
      "learning_rate": 0.06375148319389068,
      "loss": 2.828,
      "step": 225560
    },
    {
      "epoch": 362.67,
      "learning_rate": 0.0637482677630225,
      "loss": 2.807,
      "step": 225580
    },
    {
      "epoch": 362.7,
      "learning_rate": 0.06374505233215436,
      "loss": 2.8031,
      "step": 225600
    },
    {
      "epoch": 362.73,
      "learning_rate": 0.06374183690128617,
      "loss": 2.8056,
      "step": 225620
    },
    {
      "epoch": 362.77,
      "learning_rate": 0.06373862147041802,
      "loss": 2.8262,
      "step": 225640
    },
    {
      "epoch": 362.8,
      "learning_rate": 0.06373540603954984,
      "loss": 2.7984,
      "step": 225660
    },
    {
      "epoch": 362.83,
      "learning_rate": 0.06373219060868167,
      "loss": 2.801,
      "step": 225680
    },
    {
      "epoch": 362.86,
      "learning_rate": 0.06372897517781352,
      "loss": 2.7954,
      "step": 225700
    },
    {
      "epoch": 362.89,
      "learning_rate": 0.06372575974694533,
      "loss": 2.8161,
      "step": 225720
    },
    {
      "epoch": 362.93,
      "learning_rate": 0.06372254431607718,
      "loss": 2.8488,
      "step": 225740
    },
    {
      "epoch": 362.96,
      "learning_rate": 0.06371932888520901,
      "loss": 2.7982,
      "step": 225760
    },
    {
      "epoch": 362.99,
      "learning_rate": 0.06371611345434083,
      "loss": 2.8043,
      "step": 225780
    },
    {
      "epoch": 363.0,
      "eval_accuracy": {
        "accuracy": 0.39975122444219857
      },
      "eval_loss": 2.9187872409820557,
      "eval_runtime": 3.1171,
      "eval_samples_per_second": 4126.583,
      "eval_steps_per_second": 64.483,
      "step": 225786
    },
    {
      "epoch": 363.02,
      "learning_rate": 0.06371289802347267,
      "loss": 2.784,
      "step": 225800
    },
    {
      "epoch": 363.05,
      "learning_rate": 0.0637096825926045,
      "loss": 2.8165,
      "step": 225820
    },
    {
      "epoch": 363.09,
      "learning_rate": 0.06370646716173635,
      "loss": 2.7976,
      "step": 225840
    },
    {
      "epoch": 363.12,
      "learning_rate": 0.06370325173086816,
      "loss": 2.8182,
      "step": 225860
    },
    {
      "epoch": 363.15,
      "learning_rate": 0.06370003630000001,
      "loss": 2.788,
      "step": 225880
    },
    {
      "epoch": 363.18,
      "learning_rate": 0.06369682086913184,
      "loss": 2.7946,
      "step": 225900
    },
    {
      "epoch": 363.22,
      "learning_rate": 0.06369360543826366,
      "loss": 2.7896,
      "step": 225920
    },
    {
      "epoch": 363.25,
      "learning_rate": 0.06369039000739551,
      "loss": 2.8386,
      "step": 225940
    },
    {
      "epoch": 363.28,
      "learning_rate": 0.06368717457652733,
      "loss": 2.7976,
      "step": 225960
    },
    {
      "epoch": 363.31,
      "learning_rate": 0.06368395914565918,
      "loss": 2.8018,
      "step": 225980
    },
    {
      "epoch": 363.34,
      "learning_rate": 0.063680743714791,
      "loss": 2.8125,
      "step": 226000
    },
    {
      "epoch": 363.38,
      "learning_rate": 0.06367752828392283,
      "loss": 2.8194,
      "step": 226020
    },
    {
      "epoch": 363.41,
      "learning_rate": 0.06367431285305468,
      "loss": 2.8363,
      "step": 226040
    },
    {
      "epoch": 363.44,
      "learning_rate": 0.06367109742218649,
      "loss": 2.8356,
      "step": 226060
    },
    {
      "epoch": 363.47,
      "learning_rate": 0.06366788199131834,
      "loss": 2.7706,
      "step": 226080
    },
    {
      "epoch": 363.5,
      "learning_rate": 0.06366466656045017,
      "loss": 2.8196,
      "step": 226100
    },
    {
      "epoch": 363.54,
      "learning_rate": 0.06366145112958199,
      "loss": 2.8128,
      "step": 226120
    },
    {
      "epoch": 363.57,
      "learning_rate": 0.06365823569871383,
      "loss": 2.8163,
      "step": 226140
    },
    {
      "epoch": 363.6,
      "learning_rate": 0.06365502026784566,
      "loss": 2.8022,
      "step": 226160
    },
    {
      "epoch": 363.63,
      "learning_rate": 0.06365180483697751,
      "loss": 2.8104,
      "step": 226180
    },
    {
      "epoch": 363.67,
      "learning_rate": 0.06364858940610932,
      "loss": 2.8228,
      "step": 226200
    },
    {
      "epoch": 363.7,
      "learning_rate": 0.06364537397524116,
      "loss": 2.8524,
      "step": 226220
    },
    {
      "epoch": 363.73,
      "learning_rate": 0.063642158544373,
      "loss": 2.8289,
      "step": 226240
    },
    {
      "epoch": 363.76,
      "learning_rate": 0.06363894311350482,
      "loss": 2.8095,
      "step": 226260
    },
    {
      "epoch": 363.79,
      "learning_rate": 0.06363572768263667,
      "loss": 2.8399,
      "step": 226280
    },
    {
      "epoch": 363.83,
      "learning_rate": 0.06363251225176848,
      "loss": 2.8312,
      "step": 226300
    },
    {
      "epoch": 363.86,
      "learning_rate": 0.06362929682090032,
      "loss": 2.8281,
      "step": 226320
    },
    {
      "epoch": 363.89,
      "learning_rate": 0.06362608139003216,
      "loss": 2.8062,
      "step": 226340
    },
    {
      "epoch": 363.92,
      "learning_rate": 0.06362286595916399,
      "loss": 2.8459,
      "step": 226360
    },
    {
      "epoch": 363.95,
      "learning_rate": 0.06361965052829584,
      "loss": 2.7823,
      "step": 226380
    },
    {
      "epoch": 363.99,
      "learning_rate": 0.06361643509742765,
      "loss": 2.8064,
      "step": 226400
    },
    {
      "epoch": 364.0,
      "eval_accuracy": {
        "accuracy": 0.3939982896680401
      },
      "eval_loss": 2.9447033405303955,
      "eval_runtime": 3.1334,
      "eval_samples_per_second": 4105.177,
      "eval_steps_per_second": 64.148,
      "step": 226408
    },
    {
      "epoch": 364.02,
      "learning_rate": 0.06361321966655949,
      "loss": 2.8041,
      "step": 226420
    },
    {
      "epoch": 364.05,
      "learning_rate": 0.06361000423569133,
      "loss": 2.8213,
      "step": 226440
    },
    {
      "epoch": 364.08,
      "learning_rate": 0.06360678880482315,
      "loss": 2.8403,
      "step": 226460
    },
    {
      "epoch": 364.12,
      "learning_rate": 0.06360357337395499,
      "loss": 2.804,
      "step": 226480
    },
    {
      "epoch": 364.15,
      "learning_rate": 0.06360035794308681,
      "loss": 2.8271,
      "step": 226500
    },
    {
      "epoch": 364.18,
      "learning_rate": 0.06359714251221867,
      "loss": 2.8009,
      "step": 226520
    },
    {
      "epoch": 364.21,
      "learning_rate": 0.06359392708135048,
      "loss": 2.8536,
      "step": 226540
    },
    {
      "epoch": 364.24,
      "learning_rate": 0.06359071165048231,
      "loss": 2.8309,
      "step": 226560
    },
    {
      "epoch": 364.28,
      "learning_rate": 0.06358749621961415,
      "loss": 2.7827,
      "step": 226580
    },
    {
      "epoch": 364.31,
      "learning_rate": 0.06358428078874598,
      "loss": 2.7795,
      "step": 226600
    },
    {
      "epoch": 364.34,
      "learning_rate": 0.06358106535787783,
      "loss": 2.7752,
      "step": 226620
    },
    {
      "epoch": 364.37,
      "learning_rate": 0.06357784992700964,
      "loss": 2.7953,
      "step": 226640
    },
    {
      "epoch": 364.41,
      "learning_rate": 0.06357463449614148,
      "loss": 2.7718,
      "step": 226660
    },
    {
      "epoch": 364.44,
      "learning_rate": 0.06357141906527332,
      "loss": 2.7656,
      "step": 226680
    },
    {
      "epoch": 364.47,
      "learning_rate": 0.06356820363440514,
      "loss": 2.8265,
      "step": 226700
    },
    {
      "epoch": 364.5,
      "learning_rate": 0.063564988203537,
      "loss": 2.8389,
      "step": 226720
    },
    {
      "epoch": 364.53,
      "learning_rate": 0.0635617727726688,
      "loss": 2.8038,
      "step": 226740
    },
    {
      "epoch": 364.57,
      "learning_rate": 0.06355855734180064,
      "loss": 2.813,
      "step": 226760
    },
    {
      "epoch": 364.6,
      "learning_rate": 0.06355534191093248,
      "loss": 2.792,
      "step": 226780
    },
    {
      "epoch": 364.63,
      "learning_rate": 0.06355212648006431,
      "loss": 2.8181,
      "step": 226800
    },
    {
      "epoch": 364.66,
      "learning_rate": 0.06354891104919615,
      "loss": 2.8091,
      "step": 226820
    },
    {
      "epoch": 364.69,
      "learning_rate": 0.06354569561832797,
      "loss": 2.8084,
      "step": 226840
    },
    {
      "epoch": 364.73,
      "learning_rate": 0.06354248018745981,
      "loss": 2.79,
      "step": 226860
    },
    {
      "epoch": 364.76,
      "learning_rate": 0.06353926475659165,
      "loss": 2.7974,
      "step": 226880
    },
    {
      "epoch": 364.79,
      "learning_rate": 0.06353604932572347,
      "loss": 2.8507,
      "step": 226900
    },
    {
      "epoch": 364.82,
      "learning_rate": 0.06353283389485531,
      "loss": 2.8356,
      "step": 226920
    },
    {
      "epoch": 364.86,
      "learning_rate": 0.06352961846398714,
      "loss": 2.8484,
      "step": 226940
    },
    {
      "epoch": 364.89,
      "learning_rate": 0.06352640303311897,
      "loss": 2.8139,
      "step": 226960
    },
    {
      "epoch": 364.92,
      "learning_rate": 0.06352334837379423,
      "loss": 2.8073,
      "step": 226980
    },
    {
      "epoch": 364.95,
      "learning_rate": 0.06352013294292605,
      "loss": 2.8187,
      "step": 227000
    },
    {
      "epoch": 364.98,
      "learning_rate": 0.06351691751205789,
      "loss": 2.8064,
      "step": 227020
    },
    {
      "epoch": 365.0,
      "eval_accuracy": {
        "accuracy": 0.39065536811008317
      },
      "eval_loss": 2.9239754676818848,
      "eval_runtime": 2.7706,
      "eval_samples_per_second": 4642.635,
      "eval_steps_per_second": 72.547,
      "step": 227030
    },
    {
      "epoch": 365.02,
      "learning_rate": 0.06351370208118971,
      "loss": 2.8008,
      "step": 227040
    },
    {
      "epoch": 365.05,
      "learning_rate": 0.06351048665032155,
      "loss": 2.7991,
      "step": 227060
    },
    {
      "epoch": 365.08,
      "learning_rate": 0.06350727121945339,
      "loss": 2.8114,
      "step": 227080
    },
    {
      "epoch": 365.11,
      "learning_rate": 0.06350405578858521,
      "loss": 2.8236,
      "step": 227100
    },
    {
      "epoch": 365.14,
      "learning_rate": 0.06350084035771705,
      "loss": 2.7836,
      "step": 227120
    },
    {
      "epoch": 365.18,
      "learning_rate": 0.06349762492684888,
      "loss": 2.8067,
      "step": 227140
    },
    {
      "epoch": 365.21,
      "learning_rate": 0.06349440949598072,
      "loss": 2.8217,
      "step": 227160
    },
    {
      "epoch": 365.24,
      "learning_rate": 0.06349119406511254,
      "loss": 2.8315,
      "step": 227180
    },
    {
      "epoch": 365.27,
      "learning_rate": 0.06348797863424438,
      "loss": 2.8,
      "step": 227200
    },
    {
      "epoch": 365.31,
      "learning_rate": 0.06348476320337622,
      "loss": 2.8379,
      "step": 227220
    },
    {
      "epoch": 365.34,
      "learning_rate": 0.06348154777250803,
      "loss": 2.8346,
      "step": 227240
    },
    {
      "epoch": 365.37,
      "learning_rate": 0.06347833234163988,
      "loss": 2.8313,
      "step": 227260
    },
    {
      "epoch": 365.4,
      "learning_rate": 0.0634751169107717,
      "loss": 2.7997,
      "step": 227280
    },
    {
      "epoch": 365.43,
      "learning_rate": 0.06347190147990354,
      "loss": 2.7986,
      "step": 227300
    },
    {
      "epoch": 365.47,
      "learning_rate": 0.06346868604903538,
      "loss": 2.7946,
      "step": 227320
    },
    {
      "epoch": 365.5,
      "learning_rate": 0.0634654706181672,
      "loss": 2.8007,
      "step": 227340
    },
    {
      "epoch": 365.53,
      "learning_rate": 0.06346225518729905,
      "loss": 2.7711,
      "step": 227360
    },
    {
      "epoch": 365.56,
      "learning_rate": 0.06345903975643087,
      "loss": 2.8183,
      "step": 227380
    },
    {
      "epoch": 365.59,
      "learning_rate": 0.06345582432556271,
      "loss": 2.7837,
      "step": 227400
    },
    {
      "epoch": 365.63,
      "learning_rate": 0.06345260889469455,
      "loss": 2.7863,
      "step": 227420
    },
    {
      "epoch": 365.66,
      "learning_rate": 0.06344939346382637,
      "loss": 2.8141,
      "step": 227440
    },
    {
      "epoch": 365.69,
      "learning_rate": 0.06344617803295821,
      "loss": 2.8108,
      "step": 227460
    },
    {
      "epoch": 365.72,
      "learning_rate": 0.06344296260209004,
      "loss": 2.8054,
      "step": 227480
    },
    {
      "epoch": 365.76,
      "learning_rate": 0.06343974717122187,
      "loss": 2.8119,
      "step": 227500
    },
    {
      "epoch": 365.79,
      "learning_rate": 0.0634365317403537,
      "loss": 2.7868,
      "step": 227520
    },
    {
      "epoch": 365.82,
      "learning_rate": 0.06343331630948554,
      "loss": 2.7573,
      "step": 227540
    },
    {
      "epoch": 365.85,
      "learning_rate": 0.06343010087861738,
      "loss": 2.8166,
      "step": 227560
    },
    {
      "epoch": 365.88,
      "learning_rate": 0.06342688544774919,
      "loss": 2.8342,
      "step": 227580
    },
    {
      "epoch": 365.92,
      "learning_rate": 0.06342367001688104,
      "loss": 2.8201,
      "step": 227600
    },
    {
      "epoch": 365.95,
      "learning_rate": 0.06342045458601286,
      "loss": 2.8212,
      "step": 227620
    },
    {
      "epoch": 365.98,
      "learning_rate": 0.0634172391551447,
      "loss": 2.8498,
      "step": 227640
    },
    {
      "epoch": 366.0,
      "eval_accuracy": {
        "accuracy": 0.39889605846225606
      },
      "eval_loss": 2.9432337284088135,
      "eval_runtime": 2.9983,
      "eval_samples_per_second": 4290.093,
      "eval_steps_per_second": 67.038,
      "step": 227652
    },
    {
      "epoch": 366.01,
      "learning_rate": 0.06341402372427654,
      "loss": 2.8409,
      "step": 227660
    },
    {
      "epoch": 366.05,
      "learning_rate": 0.06341080829340835,
      "loss": 2.8361,
      "step": 227680
    },
    {
      "epoch": 366.08,
      "learning_rate": 0.0634075928625402,
      "loss": 2.8062,
      "step": 227700
    },
    {
      "epoch": 366.11,
      "learning_rate": 0.06340437743167203,
      "loss": 2.8238,
      "step": 227720
    },
    {
      "epoch": 366.14,
      "learning_rate": 0.06340116200080387,
      "loss": 2.7882,
      "step": 227740
    },
    {
      "epoch": 366.17,
      "learning_rate": 0.0633979465699357,
      "loss": 2.8116,
      "step": 227760
    },
    {
      "epoch": 366.21,
      "learning_rate": 0.06339473113906752,
      "loss": 2.8071,
      "step": 227780
    },
    {
      "epoch": 366.24,
      "learning_rate": 0.06339151570819937,
      "loss": 2.7641,
      "step": 227800
    },
    {
      "epoch": 366.27,
      "learning_rate": 0.0633883002773312,
      "loss": 2.8127,
      "step": 227820
    },
    {
      "epoch": 366.3,
      "learning_rate": 0.06338508484646303,
      "loss": 2.817,
      "step": 227840
    },
    {
      "epoch": 366.33,
      "learning_rate": 0.06338186941559486,
      "loss": 2.8211,
      "step": 227860
    },
    {
      "epoch": 366.37,
      "learning_rate": 0.06337865398472668,
      "loss": 2.7947,
      "step": 227880
    },
    {
      "epoch": 366.4,
      "learning_rate": 0.06337543855385853,
      "loss": 2.7983,
      "step": 227900
    },
    {
      "epoch": 366.43,
      "learning_rate": 0.06337222312299035,
      "loss": 2.8091,
      "step": 227920
    },
    {
      "epoch": 366.46,
      "learning_rate": 0.0633690076921222,
      "loss": 2.7965,
      "step": 227940
    },
    {
      "epoch": 366.5,
      "learning_rate": 0.06336579226125402,
      "loss": 2.8132,
      "step": 227960
    },
    {
      "epoch": 366.53,
      "learning_rate": 0.06336257683038585,
      "loss": 2.7916,
      "step": 227980
    },
    {
      "epoch": 366.56,
      "learning_rate": 0.0633593613995177,
      "loss": 2.7926,
      "step": 228000
    },
    {
      "epoch": 366.59,
      "learning_rate": 0.06335614596864951,
      "loss": 2.7985,
      "step": 228020
    },
    {
      "epoch": 366.62,
      "learning_rate": 0.06335293053778136,
      "loss": 2.8104,
      "step": 228040
    },
    {
      "epoch": 366.66,
      "learning_rate": 0.06334971510691319,
      "loss": 2.8047,
      "step": 228060
    },
    {
      "epoch": 366.69,
      "learning_rate": 0.06334649967604503,
      "loss": 2.799,
      "step": 228080
    },
    {
      "epoch": 366.72,
      "learning_rate": 0.06334328424517686,
      "loss": 2.8182,
      "step": 228100
    },
    {
      "epoch": 366.75,
      "learning_rate": 0.06334006881430868,
      "loss": 2.7987,
      "step": 228120
    },
    {
      "epoch": 366.78,
      "learning_rate": 0.06333685338344053,
      "loss": 2.8221,
      "step": 228140
    },
    {
      "epoch": 366.82,
      "learning_rate": 0.06333363795257235,
      "loss": 2.8063,
      "step": 228160
    },
    {
      "epoch": 366.85,
      "learning_rate": 0.06333042252170419,
      "loss": 2.8188,
      "step": 228180
    },
    {
      "epoch": 366.88,
      "learning_rate": 0.06332720709083602,
      "loss": 2.7893,
      "step": 228200
    },
    {
      "epoch": 366.91,
      "learning_rate": 0.06332399165996784,
      "loss": 2.8124,
      "step": 228220
    },
    {
      "epoch": 366.95,
      "learning_rate": 0.06332077622909969,
      "loss": 2.8551,
      "step": 228240
    },
    {
      "epoch": 366.98,
      "learning_rate": 0.0633175607982315,
      "loss": 2.8378,
      "step": 228260
    },
    {
      "epoch": 367.0,
      "eval_accuracy": {
        "accuracy": 0.39228795770815517
      },
      "eval_loss": 2.941326379776001,
      "eval_runtime": 2.86,
      "eval_samples_per_second": 4497.615,
      "eval_steps_per_second": 70.281,
      "step": 228274
    },
    {
      "epoch": 367.01,
      "learning_rate": 0.06331434536736336,
      "loss": 2.8184,
      "step": 228280
    },
    {
      "epoch": 367.04,
      "learning_rate": 0.06331112993649518,
      "loss": 2.818,
      "step": 228300
    },
    {
      "epoch": 367.07,
      "learning_rate": 0.063307914505627,
      "loss": 2.8013,
      "step": 228320
    },
    {
      "epoch": 367.11,
      "learning_rate": 0.06330469907475886,
      "loss": 2.7976,
      "step": 228340
    },
    {
      "epoch": 367.14,
      "learning_rate": 0.06330148364389067,
      "loss": 2.8108,
      "step": 228360
    },
    {
      "epoch": 367.17,
      "learning_rate": 0.06329826821302252,
      "loss": 2.8016,
      "step": 228380
    },
    {
      "epoch": 367.2,
      "learning_rate": 0.06329505278215435,
      "loss": 2.809,
      "step": 228400
    },
    {
      "epoch": 367.23,
      "learning_rate": 0.06329183735128617,
      "loss": 2.7569,
      "step": 228420
    },
    {
      "epoch": 367.27,
      "learning_rate": 0.06328862192041802,
      "loss": 2.7888,
      "step": 228440
    },
    {
      "epoch": 367.3,
      "learning_rate": 0.06328540648954983,
      "loss": 2.8311,
      "step": 228460
    },
    {
      "epoch": 367.33,
      "learning_rate": 0.06328219105868169,
      "loss": 2.8167,
      "step": 228480
    },
    {
      "epoch": 367.36,
      "learning_rate": 0.06327897562781351,
      "loss": 2.8144,
      "step": 228500
    },
    {
      "epoch": 367.4,
      "learning_rate": 0.06327576019694534,
      "loss": 2.8163,
      "step": 228520
    },
    {
      "epoch": 367.43,
      "learning_rate": 0.06327254476607717,
      "loss": 2.8109,
      "step": 228540
    },
    {
      "epoch": 367.46,
      "learning_rate": 0.063269329335209,
      "loss": 2.8011,
      "step": 228560
    },
    {
      "epoch": 367.49,
      "learning_rate": 0.06326611390434085,
      "loss": 2.7784,
      "step": 228580
    },
    {
      "epoch": 367.52,
      "learning_rate": 0.06326289847347266,
      "loss": 2.8043,
      "step": 228600
    },
    {
      "epoch": 367.56,
      "learning_rate": 0.0632596830426045,
      "loss": 2.8407,
      "step": 228620
    },
    {
      "epoch": 367.59,
      "learning_rate": 0.06325646761173634,
      "loss": 2.8364,
      "step": 228640
    },
    {
      "epoch": 367.62,
      "learning_rate": 0.06325325218086816,
      "loss": 2.797,
      "step": 228660
    },
    {
      "epoch": 367.65,
      "learning_rate": 0.06325003675000002,
      "loss": 2.8592,
      "step": 228680
    },
    {
      "epoch": 367.68,
      "learning_rate": 0.06324682131913183,
      "loss": 2.8149,
      "step": 228700
    },
    {
      "epoch": 367.72,
      "learning_rate": 0.06324360588826368,
      "loss": 2.8059,
      "step": 228720
    },
    {
      "epoch": 367.75,
      "learning_rate": 0.0632403904573955,
      "loss": 2.7974,
      "step": 228740
    },
    {
      "epoch": 367.78,
      "learning_rate": 0.06323717502652733,
      "loss": 2.819,
      "step": 228760
    },
    {
      "epoch": 367.81,
      "learning_rate": 0.06323395959565918,
      "loss": 2.7922,
      "step": 228780
    },
    {
      "epoch": 367.85,
      "learning_rate": 0.06323074416479099,
      "loss": 2.8129,
      "step": 228800
    },
    {
      "epoch": 367.88,
      "learning_rate": 0.06322752873392284,
      "loss": 2.7937,
      "step": 228820
    },
    {
      "epoch": 367.91,
      "learning_rate": 0.06322431330305467,
      "loss": 2.7771,
      "step": 228840
    },
    {
      "epoch": 367.94,
      "learning_rate": 0.0632210978721865,
      "loss": 2.7839,
      "step": 228860
    },
    {
      "epoch": 367.97,
      "learning_rate": 0.06321788244131833,
      "loss": 2.8101,
      "step": 228880
    },
    {
      "epoch": 368.0,
      "eval_accuracy": {
        "accuracy": 0.39446474383891783
      },
      "eval_loss": 2.9381353855133057,
      "eval_runtime": 3.1809,
      "eval_samples_per_second": 4043.806,
      "eval_steps_per_second": 63.189,
      "step": 228896
    },
    {
      "epoch": 368.01,
      "learning_rate": 0.06321466701045016,
      "loss": 2.7939,
      "step": 228900
    },
    {
      "epoch": 368.04,
      "learning_rate": 0.06321145157958201,
      "loss": 2.8158,
      "step": 228920
    },
    {
      "epoch": 368.07,
      "learning_rate": 0.06320823614871382,
      "loss": 2.7962,
      "step": 228940
    },
    {
      "epoch": 368.1,
      "learning_rate": 0.06320502071784566,
      "loss": 2.78,
      "step": 228960
    },
    {
      "epoch": 368.14,
      "learning_rate": 0.0632018052869775,
      "loss": 2.7806,
      "step": 228980
    },
    {
      "epoch": 368.17,
      "learning_rate": 0.06319858985610932,
      "loss": 2.7876,
      "step": 229000
    },
    {
      "epoch": 368.2,
      "learning_rate": 0.06319537442524117,
      "loss": 2.8063,
      "step": 229020
    },
    {
      "epoch": 368.23,
      "learning_rate": 0.06319231976591641,
      "loss": 2.8372,
      "step": 229040
    },
    {
      "epoch": 368.26,
      "learning_rate": 0.06318910433504824,
      "loss": 2.7914,
      "step": 229060
    },
    {
      "epoch": 368.3,
      "learning_rate": 0.06318588890418007,
      "loss": 2.8339,
      "step": 229080
    },
    {
      "epoch": 368.33,
      "learning_rate": 0.0631826734733119,
      "loss": 2.8009,
      "step": 229100
    },
    {
      "epoch": 368.36,
      "learning_rate": 0.06317945804244374,
      "loss": 2.8231,
      "step": 229120
    },
    {
      "epoch": 368.39,
      "learning_rate": 0.06317624261157558,
      "loss": 2.8108,
      "step": 229140
    },
    {
      "epoch": 368.42,
      "learning_rate": 0.0631730271807074,
      "loss": 2.8195,
      "step": 229160
    },
    {
      "epoch": 368.46,
      "learning_rate": 0.06316981174983924,
      "loss": 2.7934,
      "step": 229180
    },
    {
      "epoch": 368.49,
      "learning_rate": 0.06316659631897106,
      "loss": 2.8183,
      "step": 229200
    },
    {
      "epoch": 368.52,
      "learning_rate": 0.0631633808881029,
      "loss": 2.7882,
      "step": 229220
    },
    {
      "epoch": 368.55,
      "learning_rate": 0.06316016545723473,
      "loss": 2.7973,
      "step": 229240
    },
    {
      "epoch": 368.59,
      "learning_rate": 0.06315695002636657,
      "loss": 2.8163,
      "step": 229260
    },
    {
      "epoch": 368.62,
      "learning_rate": 0.0631537345954984,
      "loss": 2.7998,
      "step": 229280
    },
    {
      "epoch": 368.65,
      "learning_rate": 0.06315051916463023,
      "loss": 2.7954,
      "step": 229300
    },
    {
      "epoch": 368.68,
      "learning_rate": 0.06314730373376207,
      "loss": 2.7851,
      "step": 229320
    },
    {
      "epoch": 368.71,
      "learning_rate": 0.06314408830289389,
      "loss": 2.8172,
      "step": 229340
    },
    {
      "epoch": 368.75,
      "learning_rate": 0.06314087287202573,
      "loss": 2.7973,
      "step": 229360
    },
    {
      "epoch": 368.78,
      "learning_rate": 0.06313765744115757,
      "loss": 2.7964,
      "step": 229380
    },
    {
      "epoch": 368.81,
      "learning_rate": 0.0631344420102894,
      "loss": 2.8028,
      "step": 229400
    },
    {
      "epoch": 368.84,
      "learning_rate": 0.06313122657942123,
      "loss": 2.8083,
      "step": 229420
    },
    {
      "epoch": 368.87,
      "learning_rate": 0.06312801114855306,
      "loss": 2.8007,
      "step": 229440
    },
    {
      "epoch": 368.91,
      "learning_rate": 0.0631247957176849,
      "loss": 2.8135,
      "step": 229460
    },
    {
      "epoch": 368.94,
      "learning_rate": 0.06312158028681673,
      "loss": 2.8205,
      "step": 229480
    },
    {
      "epoch": 368.97,
      "learning_rate": 0.06311836485594856,
      "loss": 2.8386,
      "step": 229500
    },
    {
      "epoch": 369.0,
      "eval_accuracy": {
        "accuracy": 0.39392054730622716
      },
      "eval_loss": 2.940751314163208,
      "eval_runtime": 3.1269,
      "eval_samples_per_second": 4113.604,
      "eval_steps_per_second": 64.28,
      "step": 229518
    },
    {
      "epoch": 369.0,
      "learning_rate": 0.0631151494250804,
      "loss": 2.8334,
      "step": 229520
    },
    {
      "epoch": 369.04,
      "learning_rate": 0.06311193399421222,
      "loss": 2.8082,
      "step": 229540
    },
    {
      "epoch": 369.07,
      "learning_rate": 0.06310871856334406,
      "loss": 2.8256,
      "step": 229560
    },
    {
      "epoch": 369.1,
      "learning_rate": 0.06310550313247588,
      "loss": 2.8259,
      "step": 229580
    },
    {
      "epoch": 369.13,
      "learning_rate": 0.06310228770160772,
      "loss": 2.8199,
      "step": 229600
    },
    {
      "epoch": 369.16,
      "learning_rate": 0.06309907227073956,
      "loss": 2.7823,
      "step": 229620
    },
    {
      "epoch": 369.2,
      "learning_rate": 0.06309585683987139,
      "loss": 2.8141,
      "step": 229640
    },
    {
      "epoch": 369.23,
      "learning_rate": 0.06309264140900323,
      "loss": 2.7876,
      "step": 229660
    },
    {
      "epoch": 369.26,
      "learning_rate": 0.06308942597813505,
      "loss": 2.777,
      "step": 229680
    },
    {
      "epoch": 369.29,
      "learning_rate": 0.06308621054726689,
      "loss": 2.8059,
      "step": 229700
    },
    {
      "epoch": 369.32,
      "learning_rate": 0.06308299511639873,
      "loss": 2.7807,
      "step": 229720
    },
    {
      "epoch": 369.36,
      "learning_rate": 0.06307977968553055,
      "loss": 2.7827,
      "step": 229740
    },
    {
      "epoch": 369.39,
      "learning_rate": 0.06307656425466239,
      "loss": 2.7899,
      "step": 229760
    },
    {
      "epoch": 369.42,
      "learning_rate": 0.06307334882379421,
      "loss": 2.8002,
      "step": 229780
    },
    {
      "epoch": 369.45,
      "learning_rate": 0.06307013339292605,
      "loss": 2.8198,
      "step": 229800
    },
    {
      "epoch": 369.49,
      "learning_rate": 0.06306691796205789,
      "loss": 2.8037,
      "step": 229820
    },
    {
      "epoch": 369.52,
      "learning_rate": 0.06306370253118972,
      "loss": 2.8227,
      "step": 229840
    },
    {
      "epoch": 369.55,
      "learning_rate": 0.06306048710032156,
      "loss": 2.7802,
      "step": 229860
    },
    {
      "epoch": 369.58,
      "learning_rate": 0.06305727166945338,
      "loss": 2.7962,
      "step": 229880
    },
    {
      "epoch": 369.61,
      "learning_rate": 0.06305405623858522,
      "loss": 2.781,
      "step": 229900
    },
    {
      "epoch": 369.65,
      "learning_rate": 0.06305084080771704,
      "loss": 2.8207,
      "step": 229920
    },
    {
      "epoch": 369.68,
      "learning_rate": 0.06304762537684888,
      "loss": 2.7873,
      "step": 229940
    },
    {
      "epoch": 369.71,
      "learning_rate": 0.06304440994598072,
      "loss": 2.7969,
      "step": 229960
    },
    {
      "epoch": 369.74,
      "learning_rate": 0.06304119451511253,
      "loss": 2.8216,
      "step": 229980
    },
    {
      "epoch": 369.77,
      "learning_rate": 0.06303797908424438,
      "loss": 2.8148,
      "step": 230000
    },
    {
      "epoch": 369.81,
      "learning_rate": 0.06303476365337621,
      "loss": 2.7908,
      "step": 230020
    },
    {
      "epoch": 369.84,
      "learning_rate": 0.06303154822250805,
      "loss": 2.842,
      "step": 230040
    },
    {
      "epoch": 369.87,
      "learning_rate": 0.06302833279163989,
      "loss": 2.8286,
      "step": 230060
    },
    {
      "epoch": 369.9,
      "learning_rate": 0.0630251173607717,
      "loss": 2.8298,
      "step": 230080
    },
    {
      "epoch": 369.94,
      "learning_rate": 0.06302190192990355,
      "loss": 2.8342,
      "step": 230100
    },
    {
      "epoch": 369.97,
      "learning_rate": 0.06301868649903537,
      "loss": 2.8008,
      "step": 230120
    },
    {
      "epoch": 370.0,
      "learning_rate": 0.06301547106816721,
      "loss": 2.8072,
      "step": 230140
    },
    {
      "epoch": 370.0,
      "eval_accuracy": {
        "accuracy": 0.39741895358781
      },
      "eval_loss": 2.899322748184204,
      "eval_runtime": 2.7338,
      "eval_samples_per_second": 4705.227,
      "eval_steps_per_second": 73.525,
      "step": 230140
    },
    {
      "epoch": 370.03,
      "learning_rate": 0.06301225563729905,
      "loss": 2.7652,
      "step": 230160
    },
    {
      "epoch": 370.06,
      "learning_rate": 0.06300904020643086,
      "loss": 2.8187,
      "step": 230180
    },
    {
      "epoch": 370.1,
      "learning_rate": 0.06300582477556271,
      "loss": 2.8374,
      "step": 230200
    },
    {
      "epoch": 370.13,
      "learning_rate": 0.06300260934469454,
      "loss": 2.8197,
      "step": 230220
    },
    {
      "epoch": 370.16,
      "learning_rate": 0.06299939391382638,
      "loss": 2.7947,
      "step": 230240
    },
    {
      "epoch": 370.19,
      "learning_rate": 0.0629961784829582,
      "loss": 2.803,
      "step": 230260
    },
    {
      "epoch": 370.23,
      "learning_rate": 0.06299296305209004,
      "loss": 2.7847,
      "step": 230280
    },
    {
      "epoch": 370.26,
      "learning_rate": 0.06298974762122188,
      "loss": 2.8135,
      "step": 230300
    },
    {
      "epoch": 370.29,
      "learning_rate": 0.06298653219035369,
      "loss": 2.8303,
      "step": 230320
    },
    {
      "epoch": 370.32,
      "learning_rate": 0.06298331675948554,
      "loss": 2.7839,
      "step": 230340
    },
    {
      "epoch": 370.35,
      "learning_rate": 0.06298010132861737,
      "loss": 2.7989,
      "step": 230360
    },
    {
      "epoch": 370.39,
      "learning_rate": 0.0629768858977492,
      "loss": 2.8006,
      "step": 230380
    },
    {
      "epoch": 370.42,
      "learning_rate": 0.06297367046688104,
      "loss": 2.794,
      "step": 230400
    },
    {
      "epoch": 370.45,
      "learning_rate": 0.06297045503601285,
      "loss": 2.8039,
      "step": 230420
    },
    {
      "epoch": 370.48,
      "learning_rate": 0.0629672396051447,
      "loss": 2.7951,
      "step": 230440
    },
    {
      "epoch": 370.51,
      "learning_rate": 0.06296402417427653,
      "loss": 2.7953,
      "step": 230460
    },
    {
      "epoch": 370.55,
      "learning_rate": 0.06296080874340837,
      "loss": 2.8056,
      "step": 230480
    },
    {
      "epoch": 370.58,
      "learning_rate": 0.06295759331254021,
      "loss": 2.8069,
      "step": 230500
    },
    {
      "epoch": 370.61,
      "learning_rate": 0.06295437788167202,
      "loss": 2.829,
      "step": 230520
    },
    {
      "epoch": 370.64,
      "learning_rate": 0.06295116245080387,
      "loss": 2.7981,
      "step": 230540
    },
    {
      "epoch": 370.68,
      "learning_rate": 0.0629479470199357,
      "loss": 2.7954,
      "step": 230560
    },
    {
      "epoch": 370.71,
      "learning_rate": 0.06294473158906753,
      "loss": 2.814,
      "step": 230580
    },
    {
      "epoch": 370.74,
      "learning_rate": 0.06294151615819936,
      "loss": 2.8084,
      "step": 230600
    },
    {
      "epoch": 370.77,
      "learning_rate": 0.06293830072733118,
      "loss": 2.7843,
      "step": 230620
    },
    {
      "epoch": 370.8,
      "learning_rate": 0.06293508529646304,
      "loss": 2.7869,
      "step": 230640
    },
    {
      "epoch": 370.84,
      "learning_rate": 0.06293186986559485,
      "loss": 2.7898,
      "step": 230660
    },
    {
      "epoch": 370.87,
      "learning_rate": 0.0629286544347267,
      "loss": 2.8062,
      "step": 230680
    },
    {
      "epoch": 370.9,
      "learning_rate": 0.06292543900385852,
      "loss": 2.825,
      "step": 230700
    },
    {
      "epoch": 370.93,
      "learning_rate": 0.06292222357299035,
      "loss": 2.8121,
      "step": 230720
    },
    {
      "epoch": 370.96,
      "learning_rate": 0.0629190081421222,
      "loss": 2.8001,
      "step": 230740
    },
    {
      "epoch": 371.0,
      "learning_rate": 0.06291579271125401,
      "loss": 2.7953,
      "step": 230760
    },
    {
      "epoch": 371.0,
      "eval_accuracy": {
        "accuracy": 0.39975122444219857
      },
      "eval_loss": 2.892253875732422,
      "eval_runtime": 3.079,
      "eval_samples_per_second": 4177.67,
      "eval_steps_per_second": 65.281,
      "step": 230762
    },
    {
      "epoch": 371.03,
      "learning_rate": 0.06291257728038586,
      "loss": 2.8186,
      "step": 230780
    },
    {
      "epoch": 371.06,
      "learning_rate": 0.06290936184951769,
      "loss": 2.7748,
      "step": 230800
    },
    {
      "epoch": 371.09,
      "learning_rate": 0.06290614641864951,
      "loss": 2.7946,
      "step": 230820
    },
    {
      "epoch": 371.13,
      "learning_rate": 0.06290293098778137,
      "loss": 2.8094,
      "step": 230840
    },
    {
      "epoch": 371.16,
      "learning_rate": 0.06289971555691318,
      "loss": 2.7815,
      "step": 230860
    },
    {
      "epoch": 371.19,
      "learning_rate": 0.06289650012604503,
      "loss": 2.7779,
      "step": 230880
    },
    {
      "epoch": 371.22,
      "learning_rate": 0.06289328469517685,
      "loss": 2.8061,
      "step": 230900
    },
    {
      "epoch": 371.25,
      "learning_rate": 0.06289006926430869,
      "loss": 2.824,
      "step": 230920
    },
    {
      "epoch": 371.29,
      "learning_rate": 0.06288685383344052,
      "loss": 2.8198,
      "step": 230940
    },
    {
      "epoch": 371.32,
      "learning_rate": 0.06288363840257234,
      "loss": 2.8005,
      "step": 230960
    },
    {
      "epoch": 371.35,
      "learning_rate": 0.0628804229717042,
      "loss": 2.7719,
      "step": 230980
    },
    {
      "epoch": 371.38,
      "learning_rate": 0.062877207540836,
      "loss": 2.771,
      "step": 231000
    },
    {
      "epoch": 371.41,
      "learning_rate": 0.06287399210996786,
      "loss": 2.7975,
      "step": 231020
    },
    {
      "epoch": 371.45,
      "learning_rate": 0.06287077667909968,
      "loss": 2.8433,
      "step": 231040
    },
    {
      "epoch": 371.48,
      "learning_rate": 0.06286756124823151,
      "loss": 2.8302,
      "step": 231060
    },
    {
      "epoch": 371.51,
      "learning_rate": 0.06286434581736336,
      "loss": 2.8231,
      "step": 231080
    },
    {
      "epoch": 371.54,
      "learning_rate": 0.06286113038649517,
      "loss": 2.8195,
      "step": 231100
    },
    {
      "epoch": 371.58,
      "learning_rate": 0.06285791495562702,
      "loss": 2.786,
      "step": 231120
    },
    {
      "epoch": 371.61,
      "learning_rate": 0.06285469952475885,
      "loss": 2.7837,
      "step": 231140
    },
    {
      "epoch": 371.64,
      "learning_rate": 0.06285148409389067,
      "loss": 2.8023,
      "step": 231160
    },
    {
      "epoch": 371.67,
      "learning_rate": 0.06284826866302252,
      "loss": 2.7963,
      "step": 231180
    },
    {
      "epoch": 371.7,
      "learning_rate": 0.06284505323215434,
      "loss": 2.8219,
      "step": 231200
    },
    {
      "epoch": 371.74,
      "learning_rate": 0.06284183780128619,
      "loss": 2.7982,
      "step": 231220
    },
    {
      "epoch": 371.77,
      "learning_rate": 0.06283862237041801,
      "loss": 2.7993,
      "step": 231240
    },
    {
      "epoch": 371.8,
      "learning_rate": 0.06283540693954984,
      "loss": 2.8213,
      "step": 231260
    },
    {
      "epoch": 371.83,
      "learning_rate": 0.06283219150868168,
      "loss": 2.7989,
      "step": 231280
    },
    {
      "epoch": 371.86,
      "learning_rate": 0.0628289760778135,
      "loss": 2.7733,
      "step": 231300
    },
    {
      "epoch": 371.9,
      "learning_rate": 0.06282576064694535,
      "loss": 2.7662,
      "step": 231320
    },
    {
      "epoch": 371.93,
      "learning_rate": 0.06282270598762059,
      "loss": 2.7988,
      "step": 231340
    },
    {
      "epoch": 371.96,
      "learning_rate": 0.06281949055675241,
      "loss": 2.7798,
      "step": 231360
    },
    {
      "epoch": 371.99,
      "learning_rate": 0.06281627512588425,
      "loss": 2.7941,
      "step": 231380
    },
    {
      "epoch": 372.0,
      "eval_accuracy": {
        "accuracy": 0.39415377439166605
      },
      "eval_loss": 2.905078411102295,
      "eval_runtime": 2.9237,
      "eval_samples_per_second": 4399.565,
      "eval_steps_per_second": 68.749,
      "step": 231384
    },
    {
      "epoch": 372.03,
      "learning_rate": 0.06281305969501608,
      "loss": 2.8077,
      "step": 231400
    },
    {
      "epoch": 372.06,
      "learning_rate": 0.06280984426414792,
      "loss": 2.8023,
      "step": 231420
    },
    {
      "epoch": 372.09,
      "learning_rate": 0.06280662883327975,
      "loss": 2.7969,
      "step": 231440
    },
    {
      "epoch": 372.12,
      "learning_rate": 0.06280341340241158,
      "loss": 2.7926,
      "step": 231460
    },
    {
      "epoch": 372.15,
      "learning_rate": 0.06280019797154342,
      "loss": 2.8003,
      "step": 231480
    },
    {
      "epoch": 372.19,
      "learning_rate": 0.06279698254067524,
      "loss": 2.789,
      "step": 231500
    },
    {
      "epoch": 372.22,
      "learning_rate": 0.06279376710980708,
      "loss": 2.7889,
      "step": 231520
    },
    {
      "epoch": 372.25,
      "learning_rate": 0.0627905516789389,
      "loss": 2.7841,
      "step": 231540
    },
    {
      "epoch": 372.28,
      "learning_rate": 0.06278733624807074,
      "loss": 2.8225,
      "step": 231560
    },
    {
      "epoch": 372.32,
      "learning_rate": 0.06278412081720258,
      "loss": 2.8267,
      "step": 231580
    },
    {
      "epoch": 372.35,
      "learning_rate": 0.0627809053863344,
      "loss": 2.767,
      "step": 231600
    },
    {
      "epoch": 372.38,
      "learning_rate": 0.06277768995546625,
      "loss": 2.8059,
      "step": 231620
    },
    {
      "epoch": 372.41,
      "learning_rate": 0.06277447452459807,
      "loss": 2.7964,
      "step": 231640
    },
    {
      "epoch": 372.44,
      "learning_rate": 0.06277125909372991,
      "loss": 2.7852,
      "step": 231660
    },
    {
      "epoch": 372.48,
      "learning_rate": 0.06276804366286175,
      "loss": 2.7754,
      "step": 231680
    },
    {
      "epoch": 372.51,
      "learning_rate": 0.06276482823199357,
      "loss": 2.7683,
      "step": 231700
    },
    {
      "epoch": 372.54,
      "learning_rate": 0.06276161280112541,
      "loss": 2.7851,
      "step": 231720
    },
    {
      "epoch": 372.57,
      "learning_rate": 0.06275839737025724,
      "loss": 2.7978,
      "step": 231740
    },
    {
      "epoch": 372.6,
      "learning_rate": 0.06275518193938907,
      "loss": 2.8135,
      "step": 231760
    },
    {
      "epoch": 372.64,
      "learning_rate": 0.06275196650852091,
      "loss": 2.8294,
      "step": 231780
    },
    {
      "epoch": 372.67,
      "learning_rate": 0.06274875107765274,
      "loss": 2.7953,
      "step": 231800
    },
    {
      "epoch": 372.7,
      "learning_rate": 0.06274553564678458,
      "loss": 2.8026,
      "step": 231820
    },
    {
      "epoch": 372.73,
      "learning_rate": 0.0627423202159164,
      "loss": 2.8058,
      "step": 231840
    },
    {
      "epoch": 372.77,
      "learning_rate": 0.06273910478504824,
      "loss": 2.8228,
      "step": 231860
    },
    {
      "epoch": 372.8,
      "learning_rate": 0.06273588935418008,
      "loss": 2.7927,
      "step": 231880
    },
    {
      "epoch": 372.83,
      "learning_rate": 0.0627326739233119,
      "loss": 2.8044,
      "step": 231900
    },
    {
      "epoch": 372.86,
      "learning_rate": 0.06272945849244374,
      "loss": 2.8171,
      "step": 231920
    },
    {
      "epoch": 372.89,
      "learning_rate": 0.06272624306157557,
      "loss": 2.7987,
      "step": 231940
    },
    {
      "epoch": 372.93,
      "learning_rate": 0.0627230276307074,
      "loss": 2.7767,
      "step": 231960
    },
    {
      "epoch": 372.96,
      "learning_rate": 0.06271981219983923,
      "loss": 2.7991,
      "step": 231980
    },
    {
      "epoch": 372.99,
      "learning_rate": 0.06271659676897107,
      "loss": 2.8239,
      "step": 232000
    },
    {
      "epoch": 373.0,
      "eval_accuracy": {
        "accuracy": 0.39555313690429916
      },
      "eval_loss": 2.933899164199829,
      "eval_runtime": 2.8467,
      "eval_samples_per_second": 4518.63,
      "eval_steps_per_second": 70.609,
      "step": 232006
    },
    {
      "epoch": 373.02,
      "learning_rate": 0.0627133813381029,
      "loss": 2.8195,
      "step": 232020
    },
    {
      "epoch": 373.05,
      "learning_rate": 0.06271016590723473,
      "loss": 2.8262,
      "step": 232040
    },
    {
      "epoch": 373.09,
      "learning_rate": 0.06270695047636657,
      "loss": 2.7842,
      "step": 232060
    },
    {
      "epoch": 373.12,
      "learning_rate": 0.0627037350454984,
      "loss": 2.8008,
      "step": 232080
    },
    {
      "epoch": 373.15,
      "learning_rate": 0.06270051961463023,
      "loss": 2.8161,
      "step": 232100
    },
    {
      "epoch": 373.18,
      "learning_rate": 0.06269730418376207,
      "loss": 2.8061,
      "step": 232120
    },
    {
      "epoch": 373.22,
      "learning_rate": 0.0626940887528939,
      "loss": 2.8156,
      "step": 232140
    },
    {
      "epoch": 373.25,
      "learning_rate": 0.06269087332202573,
      "loss": 2.8142,
      "step": 232160
    },
    {
      "epoch": 373.28,
      "learning_rate": 0.06268765789115756,
      "loss": 2.8101,
      "step": 232180
    },
    {
      "epoch": 373.31,
      "learning_rate": 0.0626844424602894,
      "loss": 2.776,
      "step": 232200
    },
    {
      "epoch": 373.34,
      "learning_rate": 0.06268122702942124,
      "loss": 2.802,
      "step": 232220
    },
    {
      "epoch": 373.38,
      "learning_rate": 0.06267801159855306,
      "loss": 2.7697,
      "step": 232240
    },
    {
      "epoch": 373.41,
      "learning_rate": 0.0626747961676849,
      "loss": 2.8149,
      "step": 232260
    },
    {
      "epoch": 373.44,
      "learning_rate": 0.06267158073681672,
      "loss": 2.7995,
      "step": 232280
    },
    {
      "epoch": 373.47,
      "learning_rate": 0.06266836530594856,
      "loss": 2.7866,
      "step": 232300
    },
    {
      "epoch": 373.5,
      "learning_rate": 0.06266514987508039,
      "loss": 2.8311,
      "step": 232320
    },
    {
      "epoch": 373.54,
      "learning_rate": 0.06266193444421223,
      "loss": 2.8088,
      "step": 232340
    },
    {
      "epoch": 373.57,
      "learning_rate": 0.06265871901334406,
      "loss": 2.8018,
      "step": 232360
    },
    {
      "epoch": 373.6,
      "learning_rate": 0.06265550358247587,
      "loss": 2.7893,
      "step": 232380
    },
    {
      "epoch": 373.63,
      "learning_rate": 0.06265228815160773,
      "loss": 2.7986,
      "step": 232400
    },
    {
      "epoch": 373.67,
      "learning_rate": 0.06264907272073955,
      "loss": 2.8067,
      "step": 232420
    },
    {
      "epoch": 373.7,
      "learning_rate": 0.06264585728987139,
      "loss": 2.8214,
      "step": 232440
    },
    {
      "epoch": 373.73,
      "learning_rate": 0.06264264185900323,
      "loss": 2.8252,
      "step": 232460
    },
    {
      "epoch": 373.76,
      "learning_rate": 0.06263942642813505,
      "loss": 2.8066,
      "step": 232480
    },
    {
      "epoch": 373.79,
      "learning_rate": 0.06263621099726689,
      "loss": 2.8331,
      "step": 232500
    },
    {
      "epoch": 373.83,
      "learning_rate": 0.06263299556639872,
      "loss": 2.7982,
      "step": 232520
    },
    {
      "epoch": 373.86,
      "learning_rate": 0.06262978013553056,
      "loss": 2.8291,
      "step": 232540
    },
    {
      "epoch": 373.89,
      "learning_rate": 0.0626265647046624,
      "loss": 2.8073,
      "step": 232560
    },
    {
      "epoch": 373.92,
      "learning_rate": 0.06262334927379422,
      "loss": 2.8078,
      "step": 232580
    },
    {
      "epoch": 373.95,
      "learning_rate": 0.06262013384292606,
      "loss": 2.7979,
      "step": 232600
    },
    {
      "epoch": 373.99,
      "learning_rate": 0.06261691841205788,
      "loss": 2.7814,
      "step": 232620
    },
    {
      "epoch": 374.0,
      "eval_accuracy": {
        "accuracy": 0.39275441187903287
      },
      "eval_loss": 2.9252822399139404,
      "eval_runtime": 2.8545,
      "eval_samples_per_second": 4506.23,
      "eval_steps_per_second": 70.415,
      "step": 232628
    },
    {
      "epoch": 374.02,
      "learning_rate": 0.06261370298118972,
      "loss": 2.813,
      "step": 232640
    },
    {
      "epoch": 374.05,
      "learning_rate": 0.06261048755032154,
      "loss": 2.7947,
      "step": 232660
    },
    {
      "epoch": 374.08,
      "learning_rate": 0.06260727211945338,
      "loss": 2.7631,
      "step": 232680
    },
    {
      "epoch": 374.12,
      "learning_rate": 0.06260405668858522,
      "loss": 2.8114,
      "step": 232700
    },
    {
      "epoch": 374.15,
      "learning_rate": 0.06260084125771703,
      "loss": 2.768,
      "step": 232720
    },
    {
      "epoch": 374.18,
      "learning_rate": 0.06259762582684888,
      "loss": 2.8039,
      "step": 232740
    },
    {
      "epoch": 374.21,
      "learning_rate": 0.06259441039598071,
      "loss": 2.769,
      "step": 232760
    },
    {
      "epoch": 374.24,
      "learning_rate": 0.06259119496511255,
      "loss": 2.8025,
      "step": 232780
    },
    {
      "epoch": 374.28,
      "learning_rate": 0.06258797953424439,
      "loss": 2.8249,
      "step": 232800
    },
    {
      "epoch": 374.31,
      "learning_rate": 0.0625847641033762,
      "loss": 2.8172,
      "step": 232820
    },
    {
      "epoch": 374.34,
      "learning_rate": 0.06258154867250805,
      "loss": 2.7904,
      "step": 232840
    },
    {
      "epoch": 374.37,
      "learning_rate": 0.06257833324163987,
      "loss": 2.796,
      "step": 232860
    },
    {
      "epoch": 374.41,
      "learning_rate": 0.06257511781077171,
      "loss": 2.8104,
      "step": 232880
    },
    {
      "epoch": 374.44,
      "learning_rate": 0.06257190237990355,
      "loss": 2.7963,
      "step": 232900
    },
    {
      "epoch": 374.47,
      "learning_rate": 0.06256868694903536,
      "loss": 2.8012,
      "step": 232920
    },
    {
      "epoch": 374.5,
      "learning_rate": 0.06256547151816721,
      "loss": 2.7776,
      "step": 232940
    },
    {
      "epoch": 374.53,
      "learning_rate": 0.06256225608729904,
      "loss": 2.8196,
      "step": 232960
    },
    {
      "epoch": 374.57,
      "learning_rate": 0.06255904065643088,
      "loss": 2.7896,
      "step": 232980
    },
    {
      "epoch": 374.6,
      "learning_rate": 0.0625558252255627,
      "loss": 2.8183,
      "step": 233000
    },
    {
      "epoch": 374.63,
      "learning_rate": 0.06255260979469453,
      "loss": 2.8076,
      "step": 233020
    },
    {
      "epoch": 374.66,
      "learning_rate": 0.06254939436382638,
      "loss": 2.8076,
      "step": 233040
    },
    {
      "epoch": 374.69,
      "learning_rate": 0.06254617893295819,
      "loss": 2.8161,
      "step": 233060
    },
    {
      "epoch": 374.73,
      "learning_rate": 0.06254296350209004,
      "loss": 2.8231,
      "step": 233080
    },
    {
      "epoch": 374.76,
      "learning_rate": 0.06253974807122187,
      "loss": 2.8133,
      "step": 233100
    },
    {
      "epoch": 374.79,
      "learning_rate": 0.0625365326403537,
      "loss": 2.7872,
      "step": 233120
    },
    {
      "epoch": 374.82,
      "learning_rate": 0.06253331720948554,
      "loss": 2.8177,
      "step": 233140
    },
    {
      "epoch": 374.86,
      "learning_rate": 0.06253010177861736,
      "loss": 2.7882,
      "step": 233160
    },
    {
      "epoch": 374.89,
      "learning_rate": 0.06252688634774921,
      "loss": 2.7939,
      "step": 233180
    },
    {
      "epoch": 374.92,
      "learning_rate": 0.06252367091688103,
      "loss": 2.7819,
      "step": 233200
    },
    {
      "epoch": 374.95,
      "learning_rate": 0.06252045548601287,
      "loss": 2.7887,
      "step": 233220
    },
    {
      "epoch": 374.98,
      "learning_rate": 0.06251724005514471,
      "loss": 2.8091,
      "step": 233240
    },
    {
      "epoch": 375.0,
      "eval_accuracy": {
        "accuracy": 0.39205473062271634
      },
      "eval_loss": 2.899148941040039,
      "eval_runtime": 3.3825,
      "eval_samples_per_second": 3802.759,
      "eval_steps_per_second": 59.423,
      "step": 233250
    },
    {
      "epoch": 375.02,
      "learning_rate": 0.06251402462427652,
      "loss": 2.8032,
      "step": 233260
    },
    {
      "epoch": 375.05,
      "learning_rate": 0.06251080919340837,
      "loss": 2.792,
      "step": 233280
    },
    {
      "epoch": 375.08,
      "learning_rate": 0.0625075937625402,
      "loss": 2.7625,
      "step": 233300
    },
    {
      "epoch": 375.11,
      "learning_rate": 0.06250437833167204,
      "loss": 2.782,
      "step": 233320
    },
    {
      "epoch": 375.14,
      "learning_rate": 0.06250116290080386,
      "loss": 2.7848,
      "step": 233340
    },
    {
      "epoch": 375.18,
      "learning_rate": 0.06249794746993569,
      "loss": 2.758,
      "step": 233360
    },
    {
      "epoch": 375.21,
      "learning_rate": 0.062494732039067524,
      "loss": 2.8187,
      "step": 233380
    },
    {
      "epoch": 375.24,
      "learning_rate": 0.06249151660819935,
      "loss": 2.8124,
      "step": 233400
    },
    {
      "epoch": 375.27,
      "learning_rate": 0.0624883011773312,
      "loss": 2.8074,
      "step": 233420
    },
    {
      "epoch": 375.31,
      "learning_rate": 0.062485085746463026,
      "loss": 2.827,
      "step": 233440
    },
    {
      "epoch": 375.34,
      "learning_rate": 0.06248187031559486,
      "loss": 2.8137,
      "step": 233460
    },
    {
      "epoch": 375.37,
      "learning_rate": 0.062478815656270094,
      "loss": 2.8398,
      "step": 233480
    },
    {
      "epoch": 375.4,
      "learning_rate": 0.06247560022540194,
      "loss": 2.8065,
      "step": 233500
    },
    {
      "epoch": 375.43,
      "learning_rate": 0.062472384794533764,
      "loss": 2.8093,
      "step": 233520
    },
    {
      "epoch": 375.47,
      "learning_rate": 0.0624691693636656,
      "loss": 2.8136,
      "step": 233540
    },
    {
      "epoch": 375.5,
      "learning_rate": 0.06246595393279744,
      "loss": 2.7704,
      "step": 233560
    },
    {
      "epoch": 375.53,
      "learning_rate": 0.062462738501929266,
      "loss": 2.7973,
      "step": 233580
    },
    {
      "epoch": 375.56,
      "learning_rate": 0.0624595230710611,
      "loss": 2.7816,
      "step": 233600
    },
    {
      "epoch": 375.59,
      "learning_rate": 0.06245630764019292,
      "loss": 2.7982,
      "step": 233620
    },
    {
      "epoch": 375.63,
      "learning_rate": 0.06245309220932477,
      "loss": 2.7965,
      "step": 233640
    },
    {
      "epoch": 375.66,
      "learning_rate": 0.06244987677845659,
      "loss": 2.8219,
      "step": 233660
    },
    {
      "epoch": 375.69,
      "learning_rate": 0.06244666134758843,
      "loss": 2.8091,
      "step": 233680
    },
    {
      "epoch": 375.72,
      "learning_rate": 0.06244344591672027,
      "loss": 2.783,
      "step": 233700
    },
    {
      "epoch": 375.76,
      "learning_rate": 0.062440230485852094,
      "loss": 2.7838,
      "step": 233720
    },
    {
      "epoch": 375.79,
      "learning_rate": 0.062437015054983926,
      "loss": 2.8069,
      "step": 233740
    },
    {
      "epoch": 375.82,
      "learning_rate": 0.06243379962411575,
      "loss": 2.8237,
      "step": 233760
    },
    {
      "epoch": 375.85,
      "learning_rate": 0.062430584193247596,
      "loss": 2.8436,
      "step": 233780
    },
    {
      "epoch": 375.88,
      "learning_rate": 0.06242736876237942,
      "loss": 2.8267,
      "step": 233800
    },
    {
      "epoch": 375.92,
      "learning_rate": 0.06242415333151126,
      "loss": 2.8207,
      "step": 233820
    },
    {
      "epoch": 375.95,
      "learning_rate": 0.0624209379006431,
      "loss": 2.796,
      "step": 233840
    },
    {
      "epoch": 375.98,
      "learning_rate": 0.06241772246977492,
      "loss": 2.8144,
      "step": 233860
    },
    {
      "epoch": 376.0,
      "eval_accuracy": {
        "accuracy": 0.39889605846225606
      },
      "eval_loss": 2.8892791271209717,
      "eval_runtime": 3.323,
      "eval_samples_per_second": 3870.934,
      "eval_steps_per_second": 60.488,
      "step": 233872
    },
    {
      "epoch": 376.01,
      "learning_rate": 0.062414507038906754,
      "loss": 2.8191,
      "step": 233880
    },
    {
      "epoch": 376.05,
      "learning_rate": 0.06241129160803859,
      "loss": 2.8005,
      "step": 233900
    },
    {
      "epoch": 376.08,
      "learning_rate": 0.062408076177170424,
      "loss": 2.8198,
      "step": 233920
    },
    {
      "epoch": 376.11,
      "learning_rate": 0.06240486074630225,
      "loss": 2.8234,
      "step": 233940
    },
    {
      "epoch": 376.14,
      "learning_rate": 0.06240164531543407,
      "loss": 2.8171,
      "step": 233960
    },
    {
      "epoch": 376.17,
      "learning_rate": 0.062398429884565926,
      "loss": 2.7994,
      "step": 233980
    },
    {
      "epoch": 376.21,
      "learning_rate": 0.06239521445369776,
      "loss": 2.7527,
      "step": 234000
    },
    {
      "epoch": 376.24,
      "learning_rate": 0.06239199902282958,
      "loss": 2.8029,
      "step": 234020
    },
    {
      "epoch": 376.27,
      "learning_rate": 0.06238878359196142,
      "loss": 2.7738,
      "step": 234040
    },
    {
      "epoch": 376.3,
      "learning_rate": 0.06238556816109325,
      "loss": 2.7743,
      "step": 234060
    },
    {
      "epoch": 376.33,
      "learning_rate": 0.06238235273022509,
      "loss": 2.804,
      "step": 234080
    },
    {
      "epoch": 376.37,
      "learning_rate": 0.0623791372993569,
      "loss": 2.8228,
      "step": 234100
    },
    {
      "epoch": 376.4,
      "learning_rate": 0.062375921868488754,
      "loss": 2.7952,
      "step": 234120
    },
    {
      "epoch": 376.43,
      "learning_rate": 0.062372706437620586,
      "loss": 2.7864,
      "step": 234140
    },
    {
      "epoch": 376.46,
      "learning_rate": 0.06236949100675241,
      "loss": 2.7776,
      "step": 234160
    },
    {
      "epoch": 376.5,
      "learning_rate": 0.062366275575884256,
      "loss": 2.8192,
      "step": 234180
    },
    {
      "epoch": 376.53,
      "learning_rate": 0.062363060145016073,
      "loss": 2.7901,
      "step": 234200
    },
    {
      "epoch": 376.56,
      "learning_rate": 0.06235984471414792,
      "loss": 2.7916,
      "step": 234220
    },
    {
      "epoch": 376.59,
      "learning_rate": 0.06235662928327976,
      "loss": 2.8056,
      "step": 234240
    },
    {
      "epoch": 376.62,
      "learning_rate": 0.06235341385241158,
      "loss": 2.7906,
      "step": 234260
    },
    {
      "epoch": 376.66,
      "learning_rate": 0.062350198421543414,
      "loss": 2.8109,
      "step": 234280
    },
    {
      "epoch": 376.69,
      "learning_rate": 0.06234698299067524,
      "loss": 2.7747,
      "step": 234300
    },
    {
      "epoch": 376.72,
      "learning_rate": 0.062343767559807084,
      "loss": 2.771,
      "step": 234320
    },
    {
      "epoch": 376.75,
      "learning_rate": 0.06234055212893891,
      "loss": 2.7833,
      "step": 234340
    },
    {
      "epoch": 376.78,
      "learning_rate": 0.06233733669807075,
      "loss": 2.7966,
      "step": 234360
    },
    {
      "epoch": 376.82,
      "learning_rate": 0.062334121267202586,
      "loss": 2.7962,
      "step": 234380
    },
    {
      "epoch": 376.85,
      "learning_rate": 0.06233090583633441,
      "loss": 2.7797,
      "step": 234400
    },
    {
      "epoch": 376.88,
      "learning_rate": 0.06232769040546624,
      "loss": 2.7852,
      "step": 234420
    },
    {
      "epoch": 376.91,
      "learning_rate": 0.06232447497459807,
      "loss": 2.7895,
      "step": 234440
    },
    {
      "epoch": 376.95,
      "learning_rate": 0.06232125954372991,
      "loss": 2.8199,
      "step": 234460
    },
    {
      "epoch": 376.98,
      "learning_rate": 0.06231804411286174,
      "loss": 2.8376,
      "step": 234480
    },
    {
      "epoch": 377.0,
      "eval_accuracy": {
        "accuracy": 0.3982741195677525
      },
      "eval_loss": 2.917895555496216,
      "eval_runtime": 2.7837,
      "eval_samples_per_second": 4620.87,
      "eval_steps_per_second": 72.207,
      "step": 234494
    },
    {
      "epoch": 377.01,
      "learning_rate": 0.06231482868199356,
      "loss": 2.8186,
      "step": 234500
    },
    {
      "epoch": 377.04,
      "learning_rate": 0.062311613251125414,
      "loss": 2.7958,
      "step": 234520
    },
    {
      "epoch": 377.07,
      "learning_rate": 0.06230839782025724,
      "loss": 2.7851,
      "step": 234540
    },
    {
      "epoch": 377.11,
      "learning_rate": 0.06230518238938907,
      "loss": 2.7956,
      "step": 234560
    },
    {
      "epoch": 377.14,
      "learning_rate": 0.06230196695852091,
      "loss": 2.7826,
      "step": 234580
    },
    {
      "epoch": 377.17,
      "learning_rate": 0.06229875152765273,
      "loss": 2.7981,
      "step": 234600
    },
    {
      "epoch": 377.2,
      "learning_rate": 0.06229553609678458,
      "loss": 2.8061,
      "step": 234620
    },
    {
      "epoch": 377.23,
      "learning_rate": 0.06229232066591639,
      "loss": 2.785,
      "step": 234640
    },
    {
      "epoch": 377.27,
      "learning_rate": 0.06228910523504824,
      "loss": 2.7753,
      "step": 234660
    },
    {
      "epoch": 377.3,
      "learning_rate": 0.062285889804180074,
      "loss": 2.7949,
      "step": 234680
    },
    {
      "epoch": 377.33,
      "learning_rate": 0.0622826743733119,
      "loss": 2.7803,
      "step": 234700
    },
    {
      "epoch": 377.36,
      "learning_rate": 0.06227945894244372,
      "loss": 2.7969,
      "step": 234720
    },
    {
      "epoch": 377.4,
      "learning_rate": 0.06227624351157556,
      "loss": 2.8082,
      "step": 234740
    },
    {
      "epoch": 377.43,
      "learning_rate": 0.06227302808070741,
      "loss": 2.7924,
      "step": 234760
    },
    {
      "epoch": 377.46,
      "learning_rate": 0.06226981264983922,
      "loss": 2.7887,
      "step": 234780
    },
    {
      "epoch": 377.49,
      "learning_rate": 0.06226659721897107,
      "loss": 2.7994,
      "step": 234800
    },
    {
      "epoch": 377.52,
      "learning_rate": 0.062263381788102895,
      "loss": 2.8117,
      "step": 234820
    },
    {
      "epoch": 377.56,
      "learning_rate": 0.06226016635723473,
      "loss": 2.8166,
      "step": 234840
    },
    {
      "epoch": 377.59,
      "learning_rate": 0.06225695092636657,
      "loss": 2.7857,
      "step": 234860
    },
    {
      "epoch": 377.62,
      "learning_rate": 0.06225373549549839,
      "loss": 2.7765,
      "step": 234880
    },
    {
      "epoch": 377.65,
      "learning_rate": 0.062250520064630235,
      "loss": 2.8085,
      "step": 234900
    },
    {
      "epoch": 377.68,
      "learning_rate": 0.06224730463376206,
      "loss": 2.8186,
      "step": 234920
    },
    {
      "epoch": 377.72,
      "learning_rate": 0.0622440892028939,
      "loss": 2.7952,
      "step": 234940
    },
    {
      "epoch": 377.75,
      "learning_rate": 0.06224087377202573,
      "loss": 2.7971,
      "step": 234960
    },
    {
      "epoch": 377.78,
      "learning_rate": 0.062237658341157555,
      "loss": 2.8005,
      "step": 234980
    },
    {
      "epoch": 377.81,
      "learning_rate": 0.0622344429102894,
      "loss": 2.7835,
      "step": 235000
    },
    {
      "epoch": 377.85,
      "learning_rate": 0.062231227479421225,
      "loss": 2.7581,
      "step": 235020
    },
    {
      "epoch": 377.88,
      "learning_rate": 0.06222801204855305,
      "loss": 2.7894,
      "step": 235040
    },
    {
      "epoch": 377.91,
      "learning_rate": 0.06222479661768489,
      "loss": 2.8259,
      "step": 235060
    },
    {
      "epoch": 377.94,
      "learning_rate": 0.06222158118681673,
      "loss": 2.8052,
      "step": 235080
    },
    {
      "epoch": 377.97,
      "learning_rate": 0.06221836575594856,
      "loss": 2.824,
      "step": 235100
    },
    {
      "epoch": 378.0,
      "eval_accuracy": {
        "accuracy": 0.39104407991914797
      },
      "eval_loss": 2.9245474338531494,
      "eval_runtime": 3.1402,
      "eval_samples_per_second": 4096.253,
      "eval_steps_per_second": 64.009,
      "step": 235116
    },
    {
      "epoch": 378.01,
      "learning_rate": 0.06221515032508038,
      "loss": 2.7971,
      "step": 235120
    },
    {
      "epoch": 378.04,
      "learning_rate": 0.06221193489421222,
      "loss": 2.7788,
      "step": 235140
    },
    {
      "epoch": 378.07,
      "learning_rate": 0.06220871946334405,
      "loss": 2.8046,
      "step": 235160
    },
    {
      "epoch": 378.1,
      "learning_rate": 0.06220550403247588,
      "loss": 2.7878,
      "step": 235180
    },
    {
      "epoch": 378.14,
      "learning_rate": 0.06220228860160773,
      "loss": 2.8106,
      "step": 235200
    },
    {
      "epoch": 378.17,
      "learning_rate": 0.062199073170739555,
      "loss": 2.8193,
      "step": 235220
    },
    {
      "epoch": 378.2,
      "learning_rate": 0.06219585773987139,
      "loss": 2.8097,
      "step": 235240
    },
    {
      "epoch": 378.23,
      "learning_rate": 0.06219264230900321,
      "loss": 2.8039,
      "step": 235260
    },
    {
      "epoch": 378.26,
      "learning_rate": 0.06218942687813505,
      "loss": 2.7942,
      "step": 235280
    },
    {
      "epoch": 378.3,
      "learning_rate": 0.062186211447266895,
      "loss": 2.8325,
      "step": 235300
    },
    {
      "epoch": 378.33,
      "learning_rate": 0.062182996016398706,
      "loss": 2.801,
      "step": 235320
    },
    {
      "epoch": 378.36,
      "learning_rate": 0.06217978058553056,
      "loss": 2.777,
      "step": 235340
    },
    {
      "epoch": 378.39,
      "learning_rate": 0.06217656515466238,
      "loss": 2.771,
      "step": 235360
    },
    {
      "epoch": 378.42,
      "learning_rate": 0.062173349723794215,
      "loss": 2.8232,
      "step": 235380
    },
    {
      "epoch": 378.46,
      "learning_rate": 0.06217013429292604,
      "loss": 2.7784,
      "step": 235400
    },
    {
      "epoch": 378.49,
      "learning_rate": 0.06216691886205788,
      "loss": 2.7693,
      "step": 235420
    },
    {
      "epoch": 378.52,
      "learning_rate": 0.062163703431189724,
      "loss": 2.8077,
      "step": 235440
    },
    {
      "epoch": 378.55,
      "learning_rate": 0.062160488000321534,
      "loss": 2.7989,
      "step": 235460
    },
    {
      "epoch": 378.59,
      "learning_rate": 0.06215727256945339,
      "loss": 2.8031,
      "step": 235480
    },
    {
      "epoch": 378.62,
      "learning_rate": 0.06215421791012862,
      "loss": 2.7846,
      "step": 235500
    },
    {
      "epoch": 378.65,
      "learning_rate": 0.062151002479260455,
      "loss": 2.7954,
      "step": 235520
    },
    {
      "epoch": 378.68,
      "learning_rate": 0.06214778704839228,
      "loss": 2.7938,
      "step": 235540
    },
    {
      "epoch": 378.71,
      "learning_rate": 0.062144571617524125,
      "loss": 2.7964,
      "step": 235560
    },
    {
      "epoch": 378.75,
      "learning_rate": 0.06214135618665595,
      "loss": 2.8033,
      "step": 235580
    },
    {
      "epoch": 378.78,
      "learning_rate": 0.06213814075578779,
      "loss": 2.8114,
      "step": 235600
    },
    {
      "epoch": 378.81,
      "learning_rate": 0.062134925324919626,
      "loss": 2.8182,
      "step": 235620
    },
    {
      "epoch": 378.84,
      "learning_rate": 0.06213170989405145,
      "loss": 2.7924,
      "step": 235640
    },
    {
      "epoch": 378.87,
      "learning_rate": 0.06212849446318328,
      "loss": 2.8094,
      "step": 235660
    },
    {
      "epoch": 378.91,
      "learning_rate": 0.06212527903231511,
      "loss": 2.8041,
      "step": 235680
    },
    {
      "epoch": 378.94,
      "learning_rate": 0.06212206360144695,
      "loss": 2.8014,
      "step": 235700
    },
    {
      "epoch": 378.97,
      "learning_rate": 0.06211884817057878,
      "loss": 2.7916,
      "step": 235720
    },
    {
      "epoch": 379.0,
      "eval_accuracy": {
        "accuracy": 0.3975744383114359
      },
      "eval_loss": 2.901974678039551,
      "eval_runtime": 3.1588,
      "eval_samples_per_second": 4072.163,
      "eval_steps_per_second": 63.632,
      "step": 235738
    },
    {
      "epoch": 379.0,
      "learning_rate": 0.062115632739710616,
      "loss": 2.7986,
      "step": 235740
    },
    {
      "epoch": 379.04,
      "learning_rate": 0.062112417308842455,
      "loss": 2.7808,
      "step": 235760
    },
    {
      "epoch": 379.07,
      "learning_rate": 0.06210920187797428,
      "loss": 2.7886,
      "step": 235780
    },
    {
      "epoch": 379.1,
      "learning_rate": 0.06210598644710611,
      "loss": 2.809,
      "step": 235800
    },
    {
      "epoch": 379.13,
      "learning_rate": 0.062102771016237936,
      "loss": 2.7752,
      "step": 235820
    },
    {
      "epoch": 379.16,
      "learning_rate": 0.06209955558536978,
      "loss": 2.7953,
      "step": 235840
    },
    {
      "epoch": 379.2,
      "learning_rate": 0.062096340154501606,
      "loss": 2.793,
      "step": 235860
    },
    {
      "epoch": 379.23,
      "learning_rate": 0.062093124723633444,
      "loss": 2.8142,
      "step": 235880
    },
    {
      "epoch": 379.26,
      "learning_rate": 0.06208990929276528,
      "loss": 2.7681,
      "step": 235900
    },
    {
      "epoch": 379.29,
      "learning_rate": 0.06208669386189711,
      "loss": 2.8089,
      "step": 235920
    },
    {
      "epoch": 379.32,
      "learning_rate": 0.06208347843102894,
      "loss": 2.7827,
      "step": 235940
    },
    {
      "epoch": 379.36,
      "learning_rate": 0.06208026300016078,
      "loss": 2.7948,
      "step": 235960
    },
    {
      "epoch": 379.39,
      "learning_rate": 0.06207704756929261,
      "loss": 2.7805,
      "step": 235980
    },
    {
      "epoch": 379.42,
      "learning_rate": 0.062073832138424434,
      "loss": 2.7942,
      "step": 236000
    },
    {
      "epoch": 379.45,
      "learning_rate": 0.06207061670755627,
      "loss": 2.8048,
      "step": 236020
    },
    {
      "epoch": 379.49,
      "learning_rate": 0.06206740127668811,
      "loss": 2.8119,
      "step": 236040
    },
    {
      "epoch": 379.52,
      "learning_rate": 0.06206418584581994,
      "loss": 2.8261,
      "step": 236060
    },
    {
      "epoch": 379.55,
      "learning_rate": 0.06206097041495177,
      "loss": 2.8116,
      "step": 236080
    },
    {
      "epoch": 379.58,
      "learning_rate": 0.062057754984083606,
      "loss": 2.7703,
      "step": 236100
    },
    {
      "epoch": 379.61,
      "learning_rate": 0.06205453955321544,
      "loss": 2.7751,
      "step": 236120
    },
    {
      "epoch": 379.65,
      "learning_rate": 0.062051324122347276,
      "loss": 2.7873,
      "step": 236140
    },
    {
      "epoch": 379.68,
      "learning_rate": 0.06204810869147909,
      "loss": 2.7773,
      "step": 236160
    },
    {
      "epoch": 379.71,
      "learning_rate": 0.06204489326061094,
      "loss": 2.7828,
      "step": 236180
    },
    {
      "epoch": 379.74,
      "learning_rate": 0.06204167782974277,
      "loss": 2.7793,
      "step": 236200
    },
    {
      "epoch": 379.77,
      "learning_rate": 0.062038462398874596,
      "loss": 2.7579,
      "step": 236220
    },
    {
      "epoch": 379.81,
      "learning_rate": 0.06203524696800644,
      "loss": 2.8027,
      "step": 236240
    },
    {
      "epoch": 379.84,
      "learning_rate": 0.062032031537138266,
      "loss": 2.8133,
      "step": 236260
    },
    {
      "epoch": 379.87,
      "learning_rate": 0.062028816106270104,
      "loss": 2.784,
      "step": 236280
    },
    {
      "epoch": 379.9,
      "learning_rate": 0.06202560067540194,
      "loss": 2.7971,
      "step": 236300
    },
    {
      "epoch": 379.94,
      "learning_rate": 0.06202238524453377,
      "loss": 2.7763,
      "step": 236320
    },
    {
      "epoch": 379.97,
      "learning_rate": 0.0620191698136656,
      "loss": 2.7794,
      "step": 236340
    },
    {
      "epoch": 380.0,
      "learning_rate": 0.062015954382797424,
      "loss": 2.8047,
      "step": 236360
    },
    {
      "epoch": 380.0,
      "eval_accuracy": {
        "accuracy": 0.40216123765840006
      },
      "eval_loss": 2.875971794128418,
      "eval_runtime": 3.1061,
      "eval_samples_per_second": 4141.232,
      "eval_steps_per_second": 64.712,
      "step": 236360
    },
    {
      "epoch": 380.03,
      "learning_rate": 0.06201273895192927,
      "loss": 2.7939,
      "step": 236380
    },
    {
      "epoch": 380.06,
      "learning_rate": 0.062009523521061094,
      "loss": 2.7805,
      "step": 236400
    },
    {
      "epoch": 380.1,
      "learning_rate": 0.06200630809019293,
      "loss": 2.7878,
      "step": 236420
    },
    {
      "epoch": 380.13,
      "learning_rate": 0.06200309265932477,
      "loss": 2.8157,
      "step": 236440
    },
    {
      "epoch": 380.16,
      "learning_rate": 0.061999877228456596,
      "loss": 2.7876,
      "step": 236460
    },
    {
      "epoch": 380.19,
      "learning_rate": 0.06199666179758843,
      "loss": 2.8112,
      "step": 236480
    },
    {
      "epoch": 380.23,
      "learning_rate": 0.06199344636672025,
      "loss": 2.7947,
      "step": 236500
    },
    {
      "epoch": 380.26,
      "learning_rate": 0.0619902309358521,
      "loss": 2.7834,
      "step": 236520
    },
    {
      "epoch": 380.29,
      "learning_rate": 0.06198701550498392,
      "loss": 2.7923,
      "step": 236540
    },
    {
      "epoch": 380.32,
      "learning_rate": 0.06198380007411576,
      "loss": 2.8125,
      "step": 236560
    },
    {
      "epoch": 380.35,
      "learning_rate": 0.0619805846432476,
      "loss": 2.8018,
      "step": 236580
    },
    {
      "epoch": 380.39,
      "learning_rate": 0.061977369212379424,
      "loss": 2.8129,
      "step": 236600
    },
    {
      "epoch": 380.42,
      "learning_rate": 0.061974153781511256,
      "loss": 2.8112,
      "step": 236620
    },
    {
      "epoch": 380.45,
      "learning_rate": 0.061970938350643094,
      "loss": 2.8097,
      "step": 236640
    },
    {
      "epoch": 380.48,
      "learning_rate": 0.061967722919774926,
      "loss": 2.8433,
      "step": 236660
    },
    {
      "epoch": 380.51,
      "learning_rate": 0.06196450748890675,
      "loss": 2.795,
      "step": 236680
    },
    {
      "epoch": 380.55,
      "learning_rate": 0.061961292058038575,
      "loss": 2.7951,
      "step": 236700
    },
    {
      "epoch": 380.58,
      "learning_rate": 0.06195807662717043,
      "loss": 2.8221,
      "step": 236720
    },
    {
      "epoch": 380.61,
      "learning_rate": 0.06195486119630226,
      "loss": 2.8026,
      "step": 236740
    },
    {
      "epoch": 380.64,
      "learning_rate": 0.061951645765434084,
      "loss": 2.813,
      "step": 236760
    },
    {
      "epoch": 380.68,
      "learning_rate": 0.06194843033456592,
      "loss": 2.7885,
      "step": 236780
    },
    {
      "epoch": 380.71,
      "learning_rate": 0.06194521490369775,
      "loss": 2.8141,
      "step": 236800
    },
    {
      "epoch": 380.74,
      "learning_rate": 0.06194199947282959,
      "loss": 2.8073,
      "step": 236820
    },
    {
      "epoch": 380.77,
      "learning_rate": 0.0619387840419614,
      "loss": 2.7845,
      "step": 236840
    },
    {
      "epoch": 380.8,
      "learning_rate": 0.061935568611093256,
      "loss": 2.8247,
      "step": 236860
    },
    {
      "epoch": 380.84,
      "learning_rate": 0.06193235318022509,
      "loss": 2.7993,
      "step": 236880
    },
    {
      "epoch": 380.87,
      "learning_rate": 0.06192913774935691,
      "loss": 2.8014,
      "step": 236900
    },
    {
      "epoch": 380.9,
      "learning_rate": 0.06192592231848876,
      "loss": 2.8017,
      "step": 236920
    },
    {
      "epoch": 380.93,
      "learning_rate": 0.061922706887620575,
      "loss": 2.8089,
      "step": 236940
    },
    {
      "epoch": 380.96,
      "learning_rate": 0.06191949145675242,
      "loss": 2.8088,
      "step": 236960
    },
    {
      "epoch": 381.0,
      "learning_rate": 0.06191627602588426,
      "loss": 2.7842,
      "step": 236980
    },
    {
      "epoch": 381.0,
      "eval_accuracy": {
        "accuracy": 0.3987405737386302
      },
      "eval_loss": 2.88283371925354,
      "eval_runtime": 2.8628,
      "eval_samples_per_second": 4493.128,
      "eval_steps_per_second": 70.211,
      "step": 236982
    },
    {
      "epoch": 381.03,
      "learning_rate": 0.061913060595016084,
      "loss": 2.7862,
      "step": 237000
    },
    {
      "epoch": 381.06,
      "learning_rate": 0.061909845164147916,
      "loss": 2.784,
      "step": 237020
    },
    {
      "epoch": 381.09,
      "learning_rate": 0.06190662973327974,
      "loss": 2.7638,
      "step": 237040
    },
    {
      "epoch": 381.13,
      "learning_rate": 0.061903414302411586,
      "loss": 2.7404,
      "step": 237060
    },
    {
      "epoch": 381.16,
      "learning_rate": 0.06190019887154341,
      "loss": 2.7646,
      "step": 237080
    },
    {
      "epoch": 381.19,
      "learning_rate": 0.06189698344067525,
      "loss": 2.7672,
      "step": 237100
    },
    {
      "epoch": 381.22,
      "learning_rate": 0.061893768009807074,
      "loss": 2.7971,
      "step": 237120
    },
    {
      "epoch": 381.25,
      "learning_rate": 0.06189055257893891,
      "loss": 2.7732,
      "step": 237140
    },
    {
      "epoch": 381.29,
      "learning_rate": 0.061887337148070744,
      "loss": 2.8028,
      "step": 237160
    },
    {
      "epoch": 381.32,
      "learning_rate": 0.06188412171720257,
      "loss": 2.807,
      "step": 237180
    },
    {
      "epoch": 381.35,
      "learning_rate": 0.061880906286334414,
      "loss": 2.7938,
      "step": 237200
    },
    {
      "epoch": 381.38,
      "learning_rate": 0.06187769085546624,
      "loss": 2.8013,
      "step": 237220
    },
    {
      "epoch": 381.41,
      "learning_rate": 0.06187447542459806,
      "loss": 2.7766,
      "step": 237240
    },
    {
      "epoch": 381.45,
      "learning_rate": 0.061871259993729916,
      "loss": 2.7804,
      "step": 237260
    },
    {
      "epoch": 381.48,
      "learning_rate": 0.06186804456286174,
      "loss": 2.789,
      "step": 237280
    },
    {
      "epoch": 381.51,
      "learning_rate": 0.06186482913199357,
      "loss": 2.8181,
      "step": 237300
    },
    {
      "epoch": 381.54,
      "learning_rate": 0.06186161370112541,
      "loss": 2.787,
      "step": 237320
    },
    {
      "epoch": 381.58,
      "learning_rate": 0.061858398270257235,
      "loss": 2.7543,
      "step": 237340
    },
    {
      "epoch": 381.61,
      "learning_rate": 0.06185518283938908,
      "loss": 2.7842,
      "step": 237360
    },
    {
      "epoch": 381.64,
      "learning_rate": 0.06185196740852089,
      "loss": 2.8197,
      "step": 237380
    },
    {
      "epoch": 381.67,
      "learning_rate": 0.061848751977652744,
      "loss": 2.7846,
      "step": 237400
    },
    {
      "epoch": 381.7,
      "learning_rate": 0.061845536546784576,
      "loss": 2.7792,
      "step": 237420
    },
    {
      "epoch": 381.74,
      "learning_rate": 0.0618423211159164,
      "loss": 2.8041,
      "step": 237440
    },
    {
      "epoch": 381.77,
      "learning_rate": 0.061839105685048225,
      "loss": 2.7957,
      "step": 237460
    },
    {
      "epoch": 381.8,
      "learning_rate": 0.06183589025418006,
      "loss": 2.7846,
      "step": 237480
    },
    {
      "epoch": 381.83,
      "learning_rate": 0.06183267482331191,
      "loss": 2.7953,
      "step": 237500
    },
    {
      "epoch": 381.86,
      "learning_rate": 0.06182945939244372,
      "loss": 2.8002,
      "step": 237520
    },
    {
      "epoch": 381.9,
      "learning_rate": 0.06182624396157557,
      "loss": 2.825,
      "step": 237540
    },
    {
      "epoch": 381.93,
      "learning_rate": 0.0618230285307074,
      "loss": 2.815,
      "step": 237560
    },
    {
      "epoch": 381.96,
      "learning_rate": 0.06181981309983923,
      "loss": 2.7908,
      "step": 237580
    },
    {
      "epoch": 381.99,
      "learning_rate": 0.061816597668971074,
      "loss": 2.7916,
      "step": 237600
    },
    {
      "epoch": 382.0,
      "eval_accuracy": {
        "accuracy": 0.39679701469330636
      },
      "eval_loss": 2.8965559005737305,
      "eval_runtime": 3.1217,
      "eval_samples_per_second": 4120.568,
      "eval_steps_per_second": 64.389,
      "step": 237604
    },
    {
      "epoch": 382.03,
      "learning_rate": 0.06181338223810289,
      "loss": 2.7926,
      "step": 237620
    },
    {
      "epoch": 382.06,
      "learning_rate": 0.06181016680723474,
      "loss": 2.7937,
      "step": 237640
    },
    {
      "epoch": 382.09,
      "learning_rate": 0.06180695137636656,
      "loss": 2.7863,
      "step": 237660
    },
    {
      "epoch": 382.12,
      "learning_rate": 0.0618037359454984,
      "loss": 2.7621,
      "step": 237680
    },
    {
      "epoch": 382.15,
      "learning_rate": 0.06180052051463023,
      "loss": 2.8106,
      "step": 237700
    },
    {
      "epoch": 382.19,
      "learning_rate": 0.06179730508376206,
      "loss": 2.8134,
      "step": 237720
    },
    {
      "epoch": 382.22,
      "learning_rate": 0.0617940896528939,
      "loss": 2.7783,
      "step": 237740
    },
    {
      "epoch": 382.25,
      "learning_rate": 0.06179087422202573,
      "loss": 2.7976,
      "step": 237760
    },
    {
      "epoch": 382.28,
      "learning_rate": 0.06178765879115755,
      "loss": 2.7885,
      "step": 237780
    },
    {
      "epoch": 382.32,
      "learning_rate": 0.06178444336028939,
      "loss": 2.7952,
      "step": 237800
    },
    {
      "epoch": 382.35,
      "learning_rate": 0.06178122792942123,
      "loss": 2.795,
      "step": 237820
    },
    {
      "epoch": 382.38,
      "learning_rate": 0.06177801249855306,
      "loss": 2.8037,
      "step": 237840
    },
    {
      "epoch": 382.41,
      "learning_rate": 0.061774797067684885,
      "loss": 2.7677,
      "step": 237860
    },
    {
      "epoch": 382.44,
      "learning_rate": 0.06177158163681672,
      "loss": 2.7973,
      "step": 237880
    },
    {
      "epoch": 382.48,
      "learning_rate": 0.061768366205948555,
      "loss": 2.7933,
      "step": 237900
    },
    {
      "epoch": 382.51,
      "learning_rate": 0.06176515077508038,
      "loss": 2.7782,
      "step": 237920
    },
    {
      "epoch": 382.54,
      "learning_rate": 0.06176193534421223,
      "loss": 2.8073,
      "step": 237940
    },
    {
      "epoch": 382.57,
      "learning_rate": 0.06175871991334406,
      "loss": 2.8154,
      "step": 237960
    },
    {
      "epoch": 382.6,
      "learning_rate": 0.06175566525401929,
      "loss": 2.8155,
      "step": 237980
    },
    {
      "epoch": 382.64,
      "learning_rate": 0.061752449823151125,
      "loss": 2.8032,
      "step": 238000
    },
    {
      "epoch": 382.67,
      "learning_rate": 0.06174923439228296,
      "loss": 2.7827,
      "step": 238020
    },
    {
      "epoch": 382.7,
      "learning_rate": 0.061746018961414795,
      "loss": 2.8081,
      "step": 238040
    },
    {
      "epoch": 382.73,
      "learning_rate": 0.06174280353054662,
      "loss": 2.801,
      "step": 238060
    },
    {
      "epoch": 382.77,
      "learning_rate": 0.06173958809967846,
      "loss": 2.8206,
      "step": 238080
    },
    {
      "epoch": 382.8,
      "learning_rate": 0.061736372668810297,
      "loss": 2.7714,
      "step": 238100
    },
    {
      "epoch": 382.83,
      "learning_rate": 0.06173315723794212,
      "loss": 2.7791,
      "step": 238120
    },
    {
      "epoch": 382.86,
      "learning_rate": 0.06172994180707395,
      "loss": 2.7813,
      "step": 238140
    },
    {
      "epoch": 382.89,
      "learning_rate": 0.06172672637620579,
      "loss": 2.7766,
      "step": 238160
    },
    {
      "epoch": 382.93,
      "learning_rate": 0.06172351094533762,
      "loss": 2.7673,
      "step": 238180
    },
    {
      "epoch": 382.96,
      "learning_rate": 0.06172029551446946,
      "loss": 2.7924,
      "step": 238200
    },
    {
      "epoch": 382.99,
      "learning_rate": 0.061717080083601286,
      "loss": 2.807,
      "step": 238220
    },
    {
      "epoch": 383.0,
      "eval_accuracy": {
        "accuracy": 0.40247220710565185
      },
      "eval_loss": 2.8975868225097656,
      "eval_runtime": 2.8669,
      "eval_samples_per_second": 4486.75,
      "eval_steps_per_second": 70.111,
      "step": 238226
    },
    {
      "epoch": 383.02,
      "learning_rate": 0.061713864652733125,
      "loss": 2.802,
      "step": 238240
    },
    {
      "epoch": 383.05,
      "learning_rate": 0.061710649221864956,
      "loss": 2.8127,
      "step": 238260
    },
    {
      "epoch": 383.09,
      "learning_rate": 0.06170743379099678,
      "loss": 2.793,
      "step": 238280
    },
    {
      "epoch": 383.12,
      "learning_rate": 0.061704218360128626,
      "loss": 2.7979,
      "step": 238300
    },
    {
      "epoch": 383.15,
      "learning_rate": 0.06170100292926045,
      "loss": 2.7991,
      "step": 238320
    },
    {
      "epoch": 383.18,
      "learning_rate": 0.06169778749839229,
      "loss": 2.8161,
      "step": 238340
    },
    {
      "epoch": 383.22,
      "learning_rate": 0.06169457206752413,
      "loss": 2.7831,
      "step": 238360
    },
    {
      "epoch": 383.25,
      "learning_rate": 0.06169135663665595,
      "loss": 2.7906,
      "step": 238380
    },
    {
      "epoch": 383.28,
      "learning_rate": 0.061688141205787785,
      "loss": 2.8169,
      "step": 238400
    },
    {
      "epoch": 383.31,
      "learning_rate": 0.06168492577491961,
      "loss": 2.7872,
      "step": 238420
    },
    {
      "epoch": 383.34,
      "learning_rate": 0.061681710344051455,
      "loss": 2.782,
      "step": 238440
    },
    {
      "epoch": 383.38,
      "learning_rate": 0.06167849491318328,
      "loss": 2.7902,
      "step": 238460
    },
    {
      "epoch": 383.41,
      "learning_rate": 0.06167527948231512,
      "loss": 2.8132,
      "step": 238480
    },
    {
      "epoch": 383.44,
      "learning_rate": 0.061672064051446956,
      "loss": 2.8135,
      "step": 238500
    },
    {
      "epoch": 383.47,
      "learning_rate": 0.06166884862057878,
      "loss": 2.8196,
      "step": 238520
    },
    {
      "epoch": 383.5,
      "learning_rate": 0.06166563318971061,
      "loss": 2.8193,
      "step": 238540
    },
    {
      "epoch": 383.54,
      "learning_rate": 0.06166241775884244,
      "loss": 2.7944,
      "step": 238560
    },
    {
      "epoch": 383.57,
      "learning_rate": 0.06165920232797428,
      "loss": 2.7838,
      "step": 238580
    },
    {
      "epoch": 383.6,
      "learning_rate": 0.06165598689710611,
      "loss": 2.8241,
      "step": 238600
    },
    {
      "epoch": 383.63,
      "learning_rate": 0.061652771466237946,
      "loss": 2.7658,
      "step": 238620
    },
    {
      "epoch": 383.67,
      "learning_rate": 0.061649556035369785,
      "loss": 2.7771,
      "step": 238640
    },
    {
      "epoch": 383.7,
      "learning_rate": 0.06164634060450161,
      "loss": 2.7807,
      "step": 238660
    },
    {
      "epoch": 383.73,
      "learning_rate": 0.06164312517363344,
      "loss": 2.7629,
      "step": 238680
    },
    {
      "epoch": 383.76,
      "learning_rate": 0.06163990974276528,
      "loss": 2.7882,
      "step": 238700
    },
    {
      "epoch": 383.79,
      "learning_rate": 0.06163669431189711,
      "loss": 2.7864,
      "step": 238720
    },
    {
      "epoch": 383.83,
      "learning_rate": 0.061633478881028936,
      "loss": 2.7875,
      "step": 238740
    },
    {
      "epoch": 383.86,
      "learning_rate": 0.061630263450160774,
      "loss": 2.8093,
      "step": 238760
    },
    {
      "epoch": 383.89,
      "learning_rate": 0.06162704801929261,
      "loss": 2.8099,
      "step": 238780
    },
    {
      "epoch": 383.92,
      "learning_rate": 0.061623832588424445,
      "loss": 2.7811,
      "step": 238800
    },
    {
      "epoch": 383.95,
      "learning_rate": 0.06162061715755627,
      "loss": 2.7677,
      "step": 238820
    },
    {
      "epoch": 383.99,
      "learning_rate": 0.06161740172668811,
      "loss": 2.803,
      "step": 238840
    },
    {
      "epoch": 384.0,
      "eval_accuracy": {
        "accuracy": 0.4035606001710332
      },
      "eval_loss": 2.8767576217651367,
      "eval_runtime": 3.1909,
      "eval_samples_per_second": 4031.17,
      "eval_steps_per_second": 62.992,
      "step": 238848
    },
    {
      "epoch": 384.02,
      "learning_rate": 0.06161418629581994,
      "loss": 2.8216,
      "step": 238860
    },
    {
      "epoch": 384.05,
      "learning_rate": 0.06161097086495178,
      "loss": 2.8036,
      "step": 238880
    },
    {
      "epoch": 384.08,
      "learning_rate": 0.06160775543408359,
      "loss": 2.7794,
      "step": 238900
    },
    {
      "epoch": 384.12,
      "learning_rate": 0.06160454000321544,
      "loss": 2.7836,
      "step": 238920
    },
    {
      "epoch": 384.15,
      "learning_rate": 0.06160132457234727,
      "loss": 2.7807,
      "step": 238940
    },
    {
      "epoch": 384.18,
      "learning_rate": 0.0615981091414791,
      "loss": 2.7841,
      "step": 238960
    },
    {
      "epoch": 384.21,
      "learning_rate": 0.06159489371061094,
      "loss": 2.7934,
      "step": 238980
    },
    {
      "epoch": 384.24,
      "learning_rate": 0.06159167827974276,
      "loss": 2.8104,
      "step": 239000
    },
    {
      "epoch": 384.28,
      "learning_rate": 0.061588462848874606,
      "loss": 2.7736,
      "step": 239020
    },
    {
      "epoch": 384.31,
      "learning_rate": 0.061585247418006445,
      "loss": 2.7753,
      "step": 239040
    },
    {
      "epoch": 384.34,
      "learning_rate": 0.06158203198713827,
      "loss": 2.759,
      "step": 239060
    },
    {
      "epoch": 384.37,
      "learning_rate": 0.0615788165562701,
      "loss": 2.7614,
      "step": 239080
    },
    {
      "epoch": 384.41,
      "learning_rate": 0.061575601125401926,
      "loss": 2.7722,
      "step": 239100
    },
    {
      "epoch": 384.44,
      "learning_rate": 0.06157238569453377,
      "loss": 2.8222,
      "step": 239120
    },
    {
      "epoch": 384.47,
      "learning_rate": 0.061569170263665596,
      "loss": 2.806,
      "step": 239140
    },
    {
      "epoch": 384.5,
      "learning_rate": 0.061565954832797434,
      "loss": 2.783,
      "step": 239160
    },
    {
      "epoch": 384.53,
      "learning_rate": 0.06156273940192927,
      "loss": 2.799,
      "step": 239180
    },
    {
      "epoch": 384.57,
      "learning_rate": 0.0615595239710611,
      "loss": 2.7761,
      "step": 239200
    },
    {
      "epoch": 384.6,
      "learning_rate": 0.06155630854019293,
      "loss": 2.7746,
      "step": 239220
    },
    {
      "epoch": 384.63,
      "learning_rate": 0.061553093109324754,
      "loss": 2.7925,
      "step": 239240
    },
    {
      "epoch": 384.66,
      "learning_rate": 0.0615498776784566,
      "loss": 2.7822,
      "step": 239260
    },
    {
      "epoch": 384.69,
      "learning_rate": 0.061546662247588424,
      "loss": 2.7784,
      "step": 239280
    },
    {
      "epoch": 384.73,
      "learning_rate": 0.06154344681672026,
      "loss": 2.761,
      "step": 239300
    },
    {
      "epoch": 384.76,
      "learning_rate": 0.0615402313858521,
      "loss": 2.8106,
      "step": 239320
    },
    {
      "epoch": 384.79,
      "learning_rate": 0.061537015954983926,
      "loss": 2.7971,
      "step": 239340
    },
    {
      "epoch": 384.82,
      "learning_rate": 0.06153380052411576,
      "loss": 2.7758,
      "step": 239360
    },
    {
      "epoch": 384.86,
      "learning_rate": 0.061530585093247596,
      "loss": 2.763,
      "step": 239380
    },
    {
      "epoch": 384.89,
      "learning_rate": 0.06152736966237943,
      "loss": 2.7807,
      "step": 239400
    },
    {
      "epoch": 384.92,
      "learning_rate": 0.061524154231511266,
      "loss": 2.8049,
      "step": 239420
    },
    {
      "epoch": 384.95,
      "learning_rate": 0.06152093880064308,
      "loss": 2.7948,
      "step": 239440
    },
    {
      "epoch": 384.98,
      "learning_rate": 0.06151772336977493,
      "loss": 2.8206,
      "step": 239460
    },
    {
      "epoch": 385.0,
      "eval_accuracy": {
        "accuracy": 0.3914327917282127
      },
      "eval_loss": 2.9256789684295654,
      "eval_runtime": 2.8678,
      "eval_samples_per_second": 4485.357,
      "eval_steps_per_second": 70.089,
      "step": 239470
    },
    {
      "epoch": 385.02,
      "learning_rate": 0.06151450793890676,
      "loss": 2.8314,
      "step": 239480
    },
    {
      "epoch": 385.05,
      "learning_rate": 0.061511292508038586,
      "loss": 2.7999,
      "step": 239500
    },
    {
      "epoch": 385.08,
      "learning_rate": 0.061508077077170424,
      "loss": 2.8108,
      "step": 239520
    },
    {
      "epoch": 385.11,
      "learning_rate": 0.06150486164630225,
      "loss": 2.8288,
      "step": 239540
    },
    {
      "epoch": 385.14,
      "learning_rate": 0.061501646215434094,
      "loss": 2.7979,
      "step": 239560
    },
    {
      "epoch": 385.18,
      "learning_rate": 0.061498430784565905,
      "loss": 2.7997,
      "step": 239580
    },
    {
      "epoch": 385.21,
      "learning_rate": 0.06149521535369776,
      "loss": 2.7768,
      "step": 239600
    },
    {
      "epoch": 385.24,
      "learning_rate": 0.06149199992282959,
      "loss": 2.7588,
      "step": 239620
    },
    {
      "epoch": 385.27,
      "learning_rate": 0.061488784491961414,
      "loss": 2.7728,
      "step": 239640
    },
    {
      "epoch": 385.31,
      "learning_rate": 0.06148556906109326,
      "loss": 2.7953,
      "step": 239660
    },
    {
      "epoch": 385.34,
      "learning_rate": 0.06148235363022508,
      "loss": 2.7852,
      "step": 239680
    },
    {
      "epoch": 385.37,
      "learning_rate": 0.06147913819935692,
      "loss": 2.7431,
      "step": 239700
    },
    {
      "epoch": 385.4,
      "learning_rate": 0.06147592276848876,
      "loss": 2.8066,
      "step": 239720
    },
    {
      "epoch": 385.43,
      "learning_rate": 0.061472707337620586,
      "loss": 2.8014,
      "step": 239740
    },
    {
      "epoch": 385.47,
      "learning_rate": 0.06146949190675242,
      "loss": 2.8021,
      "step": 239760
    },
    {
      "epoch": 385.5,
      "learning_rate": 0.06146627647588424,
      "loss": 2.7924,
      "step": 239780
    },
    {
      "epoch": 385.53,
      "learning_rate": 0.06146306104501609,
      "loss": 2.8031,
      "step": 239800
    },
    {
      "epoch": 385.56,
      "learning_rate": 0.06145984561414791,
      "loss": 2.7977,
      "step": 239820
    },
    {
      "epoch": 385.59,
      "learning_rate": 0.06145663018327975,
      "loss": 2.7969,
      "step": 239840
    },
    {
      "epoch": 385.63,
      "learning_rate": 0.061453414752411575,
      "loss": 2.7808,
      "step": 239860
    },
    {
      "epoch": 385.66,
      "learning_rate": 0.061450199321543414,
      "loss": 2.7842,
      "step": 239880
    },
    {
      "epoch": 385.69,
      "learning_rate": 0.061446983890675246,
      "loss": 2.7936,
      "step": 239900
    },
    {
      "epoch": 385.72,
      "learning_rate": 0.06144376845980707,
      "loss": 2.7693,
      "step": 239920
    },
    {
      "epoch": 385.76,
      "learning_rate": 0.061440553028938916,
      "loss": 2.7777,
      "step": 239940
    },
    {
      "epoch": 385.79,
      "learning_rate": 0.06143733759807074,
      "loss": 2.7841,
      "step": 239960
    },
    {
      "epoch": 385.82,
      "learning_rate": 0.061434122167202565,
      "loss": 2.778,
      "step": 239980
    },
    {
      "epoch": 385.85,
      "learning_rate": 0.06143090673633442,
      "loss": 2.8019,
      "step": 240000
    },
    {
      "epoch": 385.88,
      "learning_rate": 0.06142769130546624,
      "loss": 2.8042,
      "step": 240020
    },
    {
      "epoch": 385.92,
      "learning_rate": 0.061424475874598074,
      "loss": 2.7955,
      "step": 240040
    },
    {
      "epoch": 385.95,
      "learning_rate": 0.06142126044372991,
      "loss": 2.7876,
      "step": 240060
    },
    {
      "epoch": 385.98,
      "learning_rate": 0.06141804501286174,
      "loss": 2.7924,
      "step": 240080
    },
    {
      "epoch": 386.0,
      "eval_accuracy": {
        "accuracy": 0.3950089403716085
      },
      "eval_loss": 2.8725125789642334,
      "eval_runtime": 3.0561,
      "eval_samples_per_second": 4208.992,
      "eval_steps_per_second": 65.771,
      "step": 240092
    },
    {
      "epoch": 386.01,
      "learning_rate": 0.06141482958199358,
      "loss": 2.7821,
      "step": 240100
    },
    {
      "epoch": 386.05,
      "learning_rate": 0.06141161415112539,
      "loss": 2.7866,
      "step": 240120
    },
    {
      "epoch": 386.08,
      "learning_rate": 0.061408398720257246,
      "loss": 2.7656,
      "step": 240140
    },
    {
      "epoch": 386.11,
      "learning_rate": 0.06140534406093249,
      "loss": 2.7799,
      "step": 240160
    },
    {
      "epoch": 386.14,
      "learning_rate": 0.06140212863006431,
      "loss": 2.7867,
      "step": 240180
    },
    {
      "epoch": 386.17,
      "learning_rate": 0.06139891319919614,
      "loss": 2.7854,
      "step": 240200
    },
    {
      "epoch": 386.21,
      "learning_rate": 0.06139569776832798,
      "loss": 2.7541,
      "step": 240220
    },
    {
      "epoch": 386.24,
      "learning_rate": 0.06139248233745981,
      "loss": 2.8148,
      "step": 240240
    },
    {
      "epoch": 386.27,
      "learning_rate": 0.06138926690659166,
      "loss": 2.8089,
      "step": 240260
    },
    {
      "epoch": 386.3,
      "learning_rate": 0.06138605147572347,
      "loss": 2.7892,
      "step": 240280
    },
    {
      "epoch": 386.33,
      "learning_rate": 0.06138283604485531,
      "loss": 2.8252,
      "step": 240300
    },
    {
      "epoch": 386.37,
      "learning_rate": 0.06137962061398714,
      "loss": 2.7721,
      "step": 240320
    },
    {
      "epoch": 386.4,
      "learning_rate": 0.061376405183118966,
      "loss": 2.7823,
      "step": 240340
    },
    {
      "epoch": 386.43,
      "learning_rate": 0.06137318975225081,
      "loss": 2.7889,
      "step": 240360
    },
    {
      "epoch": 386.46,
      "learning_rate": 0.061369974321382637,
      "loss": 2.8046,
      "step": 240380
    },
    {
      "epoch": 386.5,
      "learning_rate": 0.061366758890514475,
      "loss": 2.7951,
      "step": 240400
    },
    {
      "epoch": 386.53,
      "learning_rate": 0.061363543459646314,
      "loss": 2.804,
      "step": 240420
    },
    {
      "epoch": 386.56,
      "learning_rate": 0.06136032802877814,
      "loss": 2.8041,
      "step": 240440
    },
    {
      "epoch": 386.59,
      "learning_rate": 0.06135711259790997,
      "loss": 2.7447,
      "step": 240460
    },
    {
      "epoch": 386.62,
      "learning_rate": 0.061353897167041795,
      "loss": 2.7711,
      "step": 240480
    },
    {
      "epoch": 386.66,
      "learning_rate": 0.06135068173617364,
      "loss": 2.7784,
      "step": 240500
    },
    {
      "epoch": 386.69,
      "learning_rate": 0.061347466305305465,
      "loss": 2.7886,
      "step": 240520
    },
    {
      "epoch": 386.72,
      "learning_rate": 0.0613442508744373,
      "loss": 2.7976,
      "step": 240540
    },
    {
      "epoch": 386.75,
      "learning_rate": 0.06134103544356914,
      "loss": 2.7807,
      "step": 240560
    },
    {
      "epoch": 386.78,
      "learning_rate": 0.061337820012700967,
      "loss": 2.805,
      "step": 240580
    },
    {
      "epoch": 386.82,
      "learning_rate": 0.0613346045818328,
      "loss": 2.8147,
      "step": 240600
    },
    {
      "epoch": 386.85,
      "learning_rate": 0.06133138915096462,
      "loss": 2.8136,
      "step": 240620
    },
    {
      "epoch": 386.88,
      "learning_rate": 0.06132817372009647,
      "loss": 2.8042,
      "step": 240640
    },
    {
      "epoch": 386.91,
      "learning_rate": 0.06132495828922829,
      "loss": 2.7867,
      "step": 240660
    },
    {
      "epoch": 386.95,
      "learning_rate": 0.06132174285836013,
      "loss": 2.8004,
      "step": 240680
    },
    {
      "epoch": 386.98,
      "learning_rate": 0.06131852742749197,
      "loss": 2.7851,
      "step": 240700
    },
    {
      "epoch": 387.0,
      "eval_accuracy": {
        "accuracy": 0.39780766539687473
      },
      "eval_loss": 2.886347770690918,
      "eval_runtime": 2.6938,
      "eval_samples_per_second": 4775.056,
      "eval_steps_per_second": 74.616,
      "step": 240714
    },
    {
      "epoch": 387.01,
      "learning_rate": 0.061315311996623795,
      "loss": 2.7772,
      "step": 240720
    },
    {
      "epoch": 387.04,
      "learning_rate": 0.061312096565755626,
      "loss": 2.7614,
      "step": 240740
    },
    {
      "epoch": 387.07,
      "learning_rate": 0.061308881134887465,
      "loss": 2.7848,
      "step": 240760
    },
    {
      "epoch": 387.11,
      "learning_rate": 0.061305665704019296,
      "loss": 2.7932,
      "step": 240780
    },
    {
      "epoch": 387.14,
      "learning_rate": 0.06130245027315112,
      "loss": 2.7966,
      "step": 240800
    },
    {
      "epoch": 387.17,
      "learning_rate": 0.06129923484228296,
      "loss": 2.7797,
      "step": 240820
    },
    {
      "epoch": 387.2,
      "learning_rate": 0.0612960194114148,
      "loss": 2.7818,
      "step": 240840
    },
    {
      "epoch": 387.23,
      "learning_rate": 0.06129280398054662,
      "loss": 2.7732,
      "step": 240860
    },
    {
      "epoch": 387.27,
      "learning_rate": 0.061289588549678455,
      "loss": 2.7708,
      "step": 240880
    },
    {
      "epoch": 387.3,
      "learning_rate": 0.06128637311881029,
      "loss": 2.7983,
      "step": 240900
    },
    {
      "epoch": 387.33,
      "learning_rate": 0.061283157687942125,
      "loss": 2.7818,
      "step": 240920
    },
    {
      "epoch": 387.36,
      "learning_rate": 0.06127994225707396,
      "loss": 2.7839,
      "step": 240940
    },
    {
      "epoch": 387.4,
      "learning_rate": 0.06127672682620579,
      "loss": 2.8337,
      "step": 240960
    },
    {
      "epoch": 387.43,
      "learning_rate": 0.061273511395337626,
      "loss": 2.7958,
      "step": 240980
    },
    {
      "epoch": 387.46,
      "learning_rate": 0.06127029596446946,
      "loss": 2.7819,
      "step": 241000
    },
    {
      "epoch": 387.49,
      "learning_rate": 0.06126708053360128,
      "loss": 2.8075,
      "step": 241020
    },
    {
      "epoch": 387.52,
      "learning_rate": 0.06126386510273313,
      "loss": 2.7936,
      "step": 241040
    },
    {
      "epoch": 387.56,
      "learning_rate": 0.06126064967186495,
      "loss": 2.7683,
      "step": 241060
    },
    {
      "epoch": 387.59,
      "learning_rate": 0.06125743424099679,
      "loss": 2.7932,
      "step": 241080
    },
    {
      "epoch": 387.62,
      "learning_rate": 0.06125421881012863,
      "loss": 2.7625,
      "step": 241100
    },
    {
      "epoch": 387.65,
      "learning_rate": 0.061251003379260455,
      "loss": 2.7927,
      "step": 241120
    },
    {
      "epoch": 387.68,
      "learning_rate": 0.061247787948392286,
      "loss": 2.7579,
      "step": 241140
    },
    {
      "epoch": 387.72,
      "learning_rate": 0.06124457251752411,
      "loss": 2.7876,
      "step": 241160
    },
    {
      "epoch": 387.75,
      "learning_rate": 0.061241357086655956,
      "loss": 2.775,
      "step": 241180
    },
    {
      "epoch": 387.78,
      "learning_rate": 0.06123814165578778,
      "loss": 2.799,
      "step": 241200
    },
    {
      "epoch": 387.81,
      "learning_rate": 0.06123492622491962,
      "loss": 2.7888,
      "step": 241220
    },
    {
      "epoch": 387.85,
      "learning_rate": 0.06123171079405146,
      "loss": 2.8115,
      "step": 241240
    },
    {
      "epoch": 387.88,
      "learning_rate": 0.06122849536318328,
      "loss": 2.7893,
      "step": 241260
    },
    {
      "epoch": 387.91,
      "learning_rate": 0.061225279932315115,
      "loss": 2.7609,
      "step": 241280
    },
    {
      "epoch": 387.94,
      "learning_rate": 0.06122206450144694,
      "loss": 2.8026,
      "step": 241300
    },
    {
      "epoch": 387.97,
      "learning_rate": 0.061218849070578785,
      "loss": 2.798,
      "step": 241320
    },
    {
      "epoch": 388.0,
      "eval_accuracy": {
        "accuracy": 0.3988183161004431
      },
      "eval_loss": 2.8996737003326416,
      "eval_runtime": 3.0981,
      "eval_samples_per_second": 4151.959,
      "eval_steps_per_second": 64.879,
      "step": 241336
    },
    {
      "epoch": 388.01,
      "learning_rate": 0.06121563363971061,
      "loss": 2.7841,
      "step": 241340
    },
    {
      "epoch": 388.04,
      "learning_rate": 0.06121241820884245,
      "loss": 2.8074,
      "step": 241360
    },
    {
      "epoch": 388.07,
      "learning_rate": 0.061209202777974286,
      "loss": 2.7956,
      "step": 241380
    },
    {
      "epoch": 388.1,
      "learning_rate": 0.06120598734710611,
      "loss": 2.7605,
      "step": 241400
    },
    {
      "epoch": 388.14,
      "learning_rate": 0.06120277191623794,
      "loss": 2.7838,
      "step": 241420
    },
    {
      "epoch": 388.17,
      "learning_rate": 0.06119955648536978,
      "loss": 2.8207,
      "step": 241440
    },
    {
      "epoch": 388.2,
      "learning_rate": 0.06119634105450161,
      "loss": 2.7887,
      "step": 241460
    },
    {
      "epoch": 388.23,
      "learning_rate": 0.06119312562363344,
      "loss": 2.7761,
      "step": 241480
    },
    {
      "epoch": 388.26,
      "learning_rate": 0.061189910192765276,
      "loss": 2.7912,
      "step": 241500
    },
    {
      "epoch": 388.3,
      "learning_rate": 0.061186694761897115,
      "loss": 2.7833,
      "step": 241520
    },
    {
      "epoch": 388.33,
      "learning_rate": 0.061183479331028946,
      "loss": 2.7798,
      "step": 241540
    },
    {
      "epoch": 388.36,
      "learning_rate": 0.06118026390016077,
      "loss": 2.7614,
      "step": 241560
    },
    {
      "epoch": 388.39,
      "learning_rate": 0.06117704846929261,
      "loss": 2.7812,
      "step": 241580
    },
    {
      "epoch": 388.42,
      "learning_rate": 0.06117383303842444,
      "loss": 2.783,
      "step": 241600
    },
    {
      "epoch": 388.46,
      "learning_rate": 0.06117061760755628,
      "loss": 2.7958,
      "step": 241620
    },
    {
      "epoch": 388.49,
      "learning_rate": 0.06116740217668809,
      "loss": 2.7811,
      "step": 241640
    },
    {
      "epoch": 388.52,
      "learning_rate": 0.06116418674581994,
      "loss": 2.7667,
      "step": 241660
    },
    {
      "epoch": 388.55,
      "learning_rate": 0.061160971314951774,
      "loss": 2.7603,
      "step": 241680
    },
    {
      "epoch": 388.59,
      "learning_rate": 0.0611577558840836,
      "loss": 2.7786,
      "step": 241700
    },
    {
      "epoch": 388.62,
      "learning_rate": 0.061154540453215445,
      "loss": 2.8027,
      "step": 241720
    },
    {
      "epoch": 388.65,
      "learning_rate": 0.06115132502234726,
      "loss": 2.8005,
      "step": 241740
    },
    {
      "epoch": 388.68,
      "learning_rate": 0.06114810959147911,
      "loss": 2.7786,
      "step": 241760
    },
    {
      "epoch": 388.71,
      "learning_rate": 0.061144894160610946,
      "loss": 2.7639,
      "step": 241780
    },
    {
      "epoch": 388.75,
      "learning_rate": 0.06114167872974277,
      "loss": 2.7675,
      "step": 241800
    },
    {
      "epoch": 388.78,
      "learning_rate": 0.0611384632988746,
      "loss": 2.7897,
      "step": 241820
    },
    {
      "epoch": 388.81,
      "learning_rate": 0.06113524786800643,
      "loss": 2.8111,
      "step": 241840
    },
    {
      "epoch": 388.84,
      "learning_rate": 0.06113203243713827,
      "loss": 2.8035,
      "step": 241860
    },
    {
      "epoch": 388.87,
      "learning_rate": 0.0611288170062701,
      "loss": 2.799,
      "step": 241880
    },
    {
      "epoch": 388.91,
      "learning_rate": 0.061125601575401936,
      "loss": 2.7891,
      "step": 241900
    },
    {
      "epoch": 388.94,
      "learning_rate": 0.061122386144533775,
      "loss": 2.805,
      "step": 241920
    },
    {
      "epoch": 388.97,
      "learning_rate": 0.0611191707136656,
      "loss": 2.8025,
      "step": 241940
    },
    {
      "epoch": 389.0,
      "eval_accuracy": {
        "accuracy": 0.40122832931664465
      },
      "eval_loss": 2.8681657314300537,
      "eval_runtime": 3.1575,
      "eval_samples_per_second": 4073.772,
      "eval_steps_per_second": 63.658,
      "step": 241958
    },
    {
      "epoch": 389.0,
      "learning_rate": 0.06111595528279743,
      "loss": 2.7866,
      "step": 241960
    },
    {
      "epoch": 389.04,
      "learning_rate": 0.061112739851929256,
      "loss": 2.7986,
      "step": 241980
    },
    {
      "epoch": 389.07,
      "learning_rate": 0.0611095244210611,
      "loss": 2.7899,
      "step": 242000
    },
    {
      "epoch": 389.1,
      "learning_rate": 0.061106308990192926,
      "loss": 2.7871,
      "step": 242020
    },
    {
      "epoch": 389.13,
      "learning_rate": 0.061103093559324764,
      "loss": 2.7772,
      "step": 242040
    },
    {
      "epoch": 389.16,
      "learning_rate": 0.0610998781284566,
      "loss": 2.7752,
      "step": 242060
    },
    {
      "epoch": 389.2,
      "learning_rate": 0.06109666269758843,
      "loss": 2.7792,
      "step": 242080
    },
    {
      "epoch": 389.23,
      "learning_rate": 0.06109344726672026,
      "loss": 2.7496,
      "step": 242100
    },
    {
      "epoch": 389.26,
      "learning_rate": 0.0610902318358521,
      "loss": 2.7388,
      "step": 242120
    },
    {
      "epoch": 389.29,
      "learning_rate": 0.06108701640498393,
      "loss": 2.7769,
      "step": 242140
    },
    {
      "epoch": 389.32,
      "learning_rate": 0.06108380097411577,
      "loss": 2.8156,
      "step": 242160
    },
    {
      "epoch": 389.36,
      "learning_rate": 0.06108058554324758,
      "loss": 2.7787,
      "step": 242180
    },
    {
      "epoch": 389.39,
      "learning_rate": 0.06107737011237943,
      "loss": 2.7968,
      "step": 242200
    },
    {
      "epoch": 389.42,
      "learning_rate": 0.06107415468151126,
      "loss": 2.7848,
      "step": 242220
    },
    {
      "epoch": 389.45,
      "learning_rate": 0.06107093925064309,
      "loss": 2.7934,
      "step": 242240
    },
    {
      "epoch": 389.49,
      "learning_rate": 0.061067723819774926,
      "loss": 2.7784,
      "step": 242260
    },
    {
      "epoch": 389.52,
      "learning_rate": 0.06106450838890675,
      "loss": 2.7625,
      "step": 242280
    },
    {
      "epoch": 389.55,
      "learning_rate": 0.061061292958038596,
      "loss": 2.7904,
      "step": 242300
    },
    {
      "epoch": 389.58,
      "learning_rate": 0.06105807752717041,
      "loss": 2.7796,
      "step": 242320
    },
    {
      "epoch": 389.61,
      "learning_rate": 0.06105486209630226,
      "loss": 2.7719,
      "step": 242340
    },
    {
      "epoch": 389.65,
      "learning_rate": 0.06105164666543409,
      "loss": 2.8078,
      "step": 242360
    },
    {
      "epoch": 389.68,
      "learning_rate": 0.061048431234565916,
      "loss": 2.7903,
      "step": 242380
    },
    {
      "epoch": 389.71,
      "learning_rate": 0.06104521580369776,
      "loss": 2.7813,
      "step": 242400
    },
    {
      "epoch": 389.74,
      "learning_rate": 0.06104200037282958,
      "loss": 2.7918,
      "step": 242420
    },
    {
      "epoch": 389.77,
      "learning_rate": 0.061038784941961424,
      "loss": 2.828,
      "step": 242440
    },
    {
      "epoch": 389.81,
      "learning_rate": 0.06103556951109326,
      "loss": 2.8015,
      "step": 242460
    },
    {
      "epoch": 389.84,
      "learning_rate": 0.06103235408022509,
      "loss": 2.7812,
      "step": 242480
    },
    {
      "epoch": 389.87,
      "learning_rate": 0.06102913864935692,
      "loss": 2.7872,
      "step": 242500
    },
    {
      "epoch": 389.9,
      "learning_rate": 0.061025923218488744,
      "loss": 2.8225,
      "step": 242520
    },
    {
      "epoch": 389.94,
      "learning_rate": 0.06102270778762059,
      "loss": 2.781,
      "step": 242540
    },
    {
      "epoch": 389.97,
      "learning_rate": 0.061019492356752414,
      "loss": 2.7833,
      "step": 242560
    },
    {
      "epoch": 390.0,
      "learning_rate": 0.06101627692588425,
      "loss": 2.8013,
      "step": 242580
    },
    {
      "epoch": 390.0,
      "eval_accuracy": {
        "accuracy": 0.4001399362512633
      },
      "eval_loss": 2.8969407081604004,
      "eval_runtime": 3.203,
      "eval_samples_per_second": 4015.885,
      "eval_steps_per_second": 62.753,
      "step": 242580
    },
    {
      "epoch": 390.03,
      "learning_rate": 0.06101306149501608,
      "loss": 2.7811,
      "step": 242600
    },
    {
      "epoch": 390.06,
      "learning_rate": 0.061009846064147916,
      "loss": 2.7511,
      "step": 242620
    },
    {
      "epoch": 390.1,
      "learning_rate": 0.06100663063327975,
      "loss": 2.7681,
      "step": 242640
    },
    {
      "epoch": 390.13,
      "learning_rate": 0.06100341520241157,
      "loss": 2.7733,
      "step": 242660
    },
    {
      "epoch": 390.16,
      "learning_rate": 0.06100019977154342,
      "loss": 2.7634,
      "step": 242680
    },
    {
      "epoch": 390.19,
      "learning_rate": 0.06099698434067524,
      "loss": 2.7841,
      "step": 242700
    },
    {
      "epoch": 390.23,
      "learning_rate": 0.06099376890980707,
      "loss": 2.8205,
      "step": 242720
    },
    {
      "epoch": 390.26,
      "learning_rate": 0.06099055347893892,
      "loss": 2.7807,
      "step": 242740
    },
    {
      "epoch": 390.29,
      "learning_rate": 0.060987338048070744,
      "loss": 2.7542,
      "step": 242760
    },
    {
      "epoch": 390.32,
      "learning_rate": 0.060984122617202575,
      "loss": 2.7875,
      "step": 242780
    },
    {
      "epoch": 390.35,
      "learning_rate": 0.06098106795787781,
      "loss": 2.7791,
      "step": 242800
    },
    {
      "epoch": 390.39,
      "learning_rate": 0.06097785252700965,
      "loss": 2.7782,
      "step": 242820
    },
    {
      "epoch": 390.42,
      "learning_rate": 0.06097463709614148,
      "loss": 2.8177,
      "step": 242840
    },
    {
      "epoch": 390.45,
      "learning_rate": 0.06097142166527331,
      "loss": 2.7833,
      "step": 242860
    },
    {
      "epoch": 390.48,
      "learning_rate": 0.060968206234405145,
      "loss": 2.8019,
      "step": 242880
    },
    {
      "epoch": 390.51,
      "learning_rate": 0.060964990803536984,
      "loss": 2.7753,
      "step": 242900
    },
    {
      "epoch": 390.55,
      "learning_rate": 0.06096177537266881,
      "loss": 2.7722,
      "step": 242920
    },
    {
      "epoch": 390.58,
      "learning_rate": 0.06095855994180064,
      "loss": 2.7451,
      "step": 242940
    },
    {
      "epoch": 390.61,
      "learning_rate": 0.06095534451093248,
      "loss": 2.7939,
      "step": 242960
    },
    {
      "epoch": 390.64,
      "learning_rate": 0.06095212908006431,
      "loss": 2.7661,
      "step": 242980
    },
    {
      "epoch": 390.68,
      "learning_rate": 0.06094891364919616,
      "loss": 2.7661,
      "step": 243000
    },
    {
      "epoch": 390.71,
      "learning_rate": 0.06094569821832797,
      "loss": 2.8015,
      "step": 243020
    },
    {
      "epoch": 390.74,
      "learning_rate": 0.06094248278745981,
      "loss": 2.7883,
      "step": 243040
    },
    {
      "epoch": 390.77,
      "learning_rate": 0.06093926735659164,
      "loss": 2.7983,
      "step": 243060
    },
    {
      "epoch": 390.8,
      "learning_rate": 0.06093605192572347,
      "loss": 2.78,
      "step": 243080
    },
    {
      "epoch": 390.84,
      "learning_rate": 0.060932836494855314,
      "loss": 2.802,
      "step": 243100
    },
    {
      "epoch": 390.87,
      "learning_rate": 0.06092962106398714,
      "loss": 2.7746,
      "step": 243120
    },
    {
      "epoch": 390.9,
      "learning_rate": 0.06092640563311898,
      "loss": 2.7683,
      "step": 243140
    },
    {
      "epoch": 390.93,
      "learning_rate": 0.060923190202250815,
      "loss": 2.7383,
      "step": 243160
    },
    {
      "epoch": 390.96,
      "learning_rate": 0.06091997477138264,
      "loss": 2.7551,
      "step": 243180
    },
    {
      "epoch": 391.0,
      "learning_rate": 0.06091675934051447,
      "loss": 2.8204,
      "step": 243200
    },
    {
      "epoch": 391.0,
      "eval_accuracy": {
        "accuracy": 0.4008396175075799
      },
      "eval_loss": 2.8760628700256348,
      "eval_runtime": 2.9074,
      "eval_samples_per_second": 4424.212,
      "eval_steps_per_second": 69.134,
      "step": 243202
    },
    {
      "epoch": 391.03,
      "learning_rate": 0.060913543909646296,
      "loss": 2.7766,
      "step": 243220
    },
    {
      "epoch": 391.06,
      "learning_rate": 0.06091032847877814,
      "loss": 2.7505,
      "step": 243240
    },
    {
      "epoch": 391.09,
      "learning_rate": 0.060907113047909966,
      "loss": 2.7961,
      "step": 243260
    },
    {
      "epoch": 391.13,
      "learning_rate": 0.060903897617041805,
      "loss": 2.7977,
      "step": 243280
    },
    {
      "epoch": 391.16,
      "learning_rate": 0.060900682186173644,
      "loss": 2.795,
      "step": 243300
    },
    {
      "epoch": 391.19,
      "learning_rate": 0.06089746675530547,
      "loss": 2.8075,
      "step": 243320
    },
    {
      "epoch": 391.22,
      "learning_rate": 0.0608942513244373,
      "loss": 2.7785,
      "step": 243340
    },
    {
      "epoch": 391.25,
      "learning_rate": 0.060891035893569125,
      "loss": 2.7692,
      "step": 243360
    },
    {
      "epoch": 391.29,
      "learning_rate": 0.06088782046270097,
      "loss": 2.7627,
      "step": 243380
    },
    {
      "epoch": 391.32,
      "learning_rate": 0.060884605031832795,
      "loss": 2.7902,
      "step": 243400
    },
    {
      "epoch": 391.35,
      "learning_rate": 0.06088138960096463,
      "loss": 2.7874,
      "step": 243420
    },
    {
      "epoch": 391.38,
      "learning_rate": 0.06087817417009647,
      "loss": 2.7987,
      "step": 243440
    },
    {
      "epoch": 391.41,
      "learning_rate": 0.060874958739228296,
      "loss": 2.7962,
      "step": 243460
    },
    {
      "epoch": 391.45,
      "learning_rate": 0.06087174330836013,
      "loss": 2.7925,
      "step": 243480
    },
    {
      "epoch": 391.48,
      "learning_rate": 0.06086852787749197,
      "loss": 2.7444,
      "step": 243500
    },
    {
      "epoch": 391.51,
      "learning_rate": 0.0608653124466238,
      "loss": 2.7811,
      "step": 243520
    },
    {
      "epoch": 391.54,
      "learning_rate": 0.06086209701575562,
      "loss": 2.8105,
      "step": 243540
    },
    {
      "epoch": 391.58,
      "learning_rate": 0.06085888158488746,
      "loss": 2.8114,
      "step": 243560
    },
    {
      "epoch": 391.61,
      "learning_rate": 0.0608556661540193,
      "loss": 2.8041,
      "step": 243580
    },
    {
      "epoch": 391.64,
      "learning_rate": 0.060852450723151125,
      "loss": 2.803,
      "step": 243600
    },
    {
      "epoch": 391.67,
      "learning_rate": 0.060849235292282956,
      "loss": 2.7951,
      "step": 243620
    },
    {
      "epoch": 391.7,
      "learning_rate": 0.060846019861414795,
      "loss": 2.7701,
      "step": 243640
    },
    {
      "epoch": 391.74,
      "learning_rate": 0.060842804430546626,
      "loss": 2.7647,
      "step": 243660
    },
    {
      "epoch": 391.77,
      "learning_rate": 0.060839588999678465,
      "loss": 2.7825,
      "step": 243680
    },
    {
      "epoch": 391.8,
      "learning_rate": 0.06083637356881029,
      "loss": 2.779,
      "step": 243700
    },
    {
      "epoch": 391.83,
      "learning_rate": 0.06083315813794213,
      "loss": 2.8051,
      "step": 243720
    },
    {
      "epoch": 391.86,
      "learning_rate": 0.06082994270707396,
      "loss": 2.7734,
      "step": 243740
    },
    {
      "epoch": 391.9,
      "learning_rate": 0.060826727276205785,
      "loss": 2.7624,
      "step": 243760
    },
    {
      "epoch": 391.93,
      "learning_rate": 0.06082351184533763,
      "loss": 2.7799,
      "step": 243780
    },
    {
      "epoch": 391.96,
      "learning_rate": 0.060820296414469455,
      "loss": 2.7885,
      "step": 243800
    },
    {
      "epoch": 391.99,
      "learning_rate": 0.06081708098360129,
      "loss": 2.787,
      "step": 243820
    },
    {
      "epoch": 392.0,
      "eval_accuracy": {
        "accuracy": 0.40247220710565185
      },
      "eval_loss": 2.8822197914123535,
      "eval_runtime": 2.7767,
      "eval_samples_per_second": 4632.518,
      "eval_steps_per_second": 72.389,
      "step": 243824
    },
    {
      "epoch": 392.03,
      "learning_rate": 0.06081386555273313,
      "loss": 2.7729,
      "step": 243840
    },
    {
      "epoch": 392.06,
      "learning_rate": 0.060810650121864956,
      "loss": 2.7423,
      "step": 243860
    },
    {
      "epoch": 392.09,
      "learning_rate": 0.06080743469099679,
      "loss": 2.7684,
      "step": 243880
    },
    {
      "epoch": 392.12,
      "learning_rate": 0.06080421926012861,
      "loss": 2.7625,
      "step": 243900
    },
    {
      "epoch": 392.15,
      "learning_rate": 0.06080100382926046,
      "loss": 2.7517,
      "step": 243920
    },
    {
      "epoch": 392.19,
      "learning_rate": 0.06079778839839228,
      "loss": 2.778,
      "step": 243940
    },
    {
      "epoch": 392.22,
      "learning_rate": 0.06079457296752412,
      "loss": 2.7849,
      "step": 243960
    },
    {
      "epoch": 392.25,
      "learning_rate": 0.06079135753665596,
      "loss": 2.7876,
      "step": 243980
    },
    {
      "epoch": 392.28,
      "learning_rate": 0.060788142105787785,
      "loss": 2.7931,
      "step": 244000
    },
    {
      "epoch": 392.32,
      "learning_rate": 0.060784926674919616,
      "loss": 2.7759,
      "step": 244020
    },
    {
      "epoch": 392.35,
      "learning_rate": 0.06078171124405144,
      "loss": 2.8039,
      "step": 244040
    },
    {
      "epoch": 392.38,
      "learning_rate": 0.060778495813183286,
      "loss": 2.8071,
      "step": 244060
    },
    {
      "epoch": 392.41,
      "learning_rate": 0.06077528038231511,
      "loss": 2.7671,
      "step": 244080
    },
    {
      "epoch": 392.44,
      "learning_rate": 0.06077206495144695,
      "loss": 2.7871,
      "step": 244100
    },
    {
      "epoch": 392.48,
      "learning_rate": 0.06076884952057879,
      "loss": 2.7724,
      "step": 244120
    },
    {
      "epoch": 392.51,
      "learning_rate": 0.06076563408971061,
      "loss": 2.7661,
      "step": 244140
    },
    {
      "epoch": 392.54,
      "learning_rate": 0.060762418658842444,
      "loss": 2.7618,
      "step": 244160
    },
    {
      "epoch": 392.57,
      "learning_rate": 0.06075920322797428,
      "loss": 2.7842,
      "step": 244180
    },
    {
      "epoch": 392.6,
      "learning_rate": 0.060755987797106115,
      "loss": 2.7727,
      "step": 244200
    },
    {
      "epoch": 392.64,
      "learning_rate": 0.06075277236623794,
      "loss": 2.7823,
      "step": 244220
    },
    {
      "epoch": 392.67,
      "learning_rate": 0.06074955693536978,
      "loss": 2.7808,
      "step": 244240
    },
    {
      "epoch": 392.7,
      "learning_rate": 0.060746341504501616,
      "loss": 2.7785,
      "step": 244260
    },
    {
      "epoch": 392.73,
      "learning_rate": 0.06074312607363345,
      "loss": 2.7593,
      "step": 244280
    },
    {
      "epoch": 392.77,
      "learning_rate": 0.06073991064276527,
      "loss": 2.7651,
      "step": 244300
    },
    {
      "epoch": 392.8,
      "learning_rate": 0.06073669521189711,
      "loss": 2.7685,
      "step": 244320
    },
    {
      "epoch": 392.83,
      "learning_rate": 0.06073347978102894,
      "loss": 2.8147,
      "step": 244340
    },
    {
      "epoch": 392.86,
      "learning_rate": 0.06073026435016078,
      "loss": 2.7817,
      "step": 244360
    },
    {
      "epoch": 392.89,
      "learning_rate": 0.06072704891929259,
      "loss": 2.8031,
      "step": 244380
    },
    {
      "epoch": 392.93,
      "learning_rate": 0.060723833488424445,
      "loss": 2.8081,
      "step": 244400
    },
    {
      "epoch": 392.96,
      "learning_rate": 0.060720618057556276,
      "loss": 2.7914,
      "step": 244420
    },
    {
      "epoch": 392.99,
      "learning_rate": 0.0607174026266881,
      "loss": 2.7648,
      "step": 244440
    },
    {
      "epoch": 393.0,
      "eval_accuracy": {
        "accuracy": 0.39415377439166605
      },
      "eval_loss": 2.931589126586914,
      "eval_runtime": 2.8085,
      "eval_samples_per_second": 4580.07,
      "eval_steps_per_second": 71.569,
      "step": 244446
    },
    {
      "epoch": 393.02,
      "learning_rate": 0.060714187195819946,
      "loss": 2.784,
      "step": 244460
    },
    {
      "epoch": 393.05,
      "learning_rate": 0.060710971764951764,
      "loss": 2.8305,
      "step": 244480
    },
    {
      "epoch": 393.09,
      "learning_rate": 0.06070775633408361,
      "loss": 2.7727,
      "step": 244500
    },
    {
      "epoch": 393.12,
      "learning_rate": 0.06070454090321545,
      "loss": 2.7832,
      "step": 244520
    },
    {
      "epoch": 393.15,
      "learning_rate": 0.06070132547234727,
      "loss": 2.8108,
      "step": 244540
    },
    {
      "epoch": 393.18,
      "learning_rate": 0.060698110041479104,
      "loss": 2.7942,
      "step": 244560
    },
    {
      "epoch": 393.22,
      "learning_rate": 0.06069489461061093,
      "loss": 2.8032,
      "step": 244580
    },
    {
      "epoch": 393.25,
      "learning_rate": 0.060691679179742775,
      "loss": 2.8158,
      "step": 244600
    },
    {
      "epoch": 393.28,
      "learning_rate": 0.0606884637488746,
      "loss": 2.7947,
      "step": 244620
    },
    {
      "epoch": 393.31,
      "learning_rate": 0.06068524831800644,
      "loss": 2.7552,
      "step": 244640
    },
    {
      "epoch": 393.34,
      "learning_rate": 0.060682032887138276,
      "loss": 2.7668,
      "step": 244660
    },
    {
      "epoch": 393.38,
      "learning_rate": 0.0606788174562701,
      "loss": 2.7986,
      "step": 244680
    },
    {
      "epoch": 393.41,
      "learning_rate": 0.06067560202540193,
      "loss": 2.7707,
      "step": 244700
    },
    {
      "epoch": 393.44,
      "learning_rate": 0.06067238659453376,
      "loss": 2.7941,
      "step": 244720
    },
    {
      "epoch": 393.47,
      "learning_rate": 0.0606691711636656,
      "loss": 2.7676,
      "step": 244740
    },
    {
      "epoch": 393.5,
      "learning_rate": 0.06066595573279743,
      "loss": 2.7764,
      "step": 244760
    },
    {
      "epoch": 393.54,
      "learning_rate": 0.060662740301929266,
      "loss": 2.775,
      "step": 244780
    },
    {
      "epoch": 393.57,
      "learning_rate": 0.060659524871061105,
      "loss": 2.7549,
      "step": 244800
    },
    {
      "epoch": 393.6,
      "learning_rate": 0.06065630944019293,
      "loss": 2.8067,
      "step": 244820
    },
    {
      "epoch": 393.63,
      "learning_rate": 0.06065309400932476,
      "loss": 2.8022,
      "step": 244840
    },
    {
      "epoch": 393.67,
      "learning_rate": 0.0606498785784566,
      "loss": 2.7693,
      "step": 244860
    },
    {
      "epoch": 393.7,
      "learning_rate": 0.06064666314758843,
      "loss": 2.7611,
      "step": 244880
    },
    {
      "epoch": 393.73,
      "learning_rate": 0.06064344771672027,
      "loss": 2.7894,
      "step": 244900
    },
    {
      "epoch": 393.76,
      "learning_rate": 0.06064039305739549,
      "loss": 2.8181,
      "step": 244920
    },
    {
      "epoch": 393.79,
      "learning_rate": 0.06063717762652733,
      "loss": 2.7932,
      "step": 244940
    },
    {
      "epoch": 393.83,
      "learning_rate": 0.060633962195659176,
      "loss": 2.7875,
      "step": 244960
    },
    {
      "epoch": 393.86,
      "learning_rate": 0.060630746764790994,
      "loss": 2.7941,
      "step": 244980
    },
    {
      "epoch": 393.89,
      "learning_rate": 0.060627531333922825,
      "loss": 2.753,
      "step": 245000
    },
    {
      "epoch": 393.92,
      "learning_rate": 0.060624315903054664,
      "loss": 2.7842,
      "step": 245020
    },
    {
      "epoch": 393.95,
      "learning_rate": 0.060621100472186495,
      "loss": 2.7696,
      "step": 245040
    },
    {
      "epoch": 393.99,
      "learning_rate": 0.06061788504131835,
      "loss": 2.7578,
      "step": 245060
    },
    {
      "epoch": 394.0,
      "eval_accuracy": {
        "accuracy": 0.4046489932364145
      },
      "eval_loss": 2.8847174644470215,
      "eval_runtime": 2.7879,
      "eval_samples_per_second": 4613.851,
      "eval_steps_per_second": 72.097,
      "step": 245068
    },
    {
      "epoch": 394.02,
      "learning_rate": 0.06061466961045016,
      "loss": 2.8018,
      "step": 245080
    },
    {
      "epoch": 394.05,
      "learning_rate": 0.060611454179582,
      "loss": 2.7889,
      "step": 245100
    },
    {
      "epoch": 394.08,
      "learning_rate": 0.06060823874871383,
      "loss": 2.7922,
      "step": 245120
    },
    {
      "epoch": 394.12,
      "learning_rate": 0.060605023317845653,
      "loss": 2.7702,
      "step": 245140
    },
    {
      "epoch": 394.15,
      "learning_rate": 0.0606018078869775,
      "loss": 2.7633,
      "step": 245160
    },
    {
      "epoch": 394.18,
      "learning_rate": 0.060598592456109324,
      "loss": 2.7709,
      "step": 245180
    },
    {
      "epoch": 394.21,
      "learning_rate": 0.060595377025241176,
      "loss": 2.7669,
      "step": 245200
    },
    {
      "epoch": 394.24,
      "learning_rate": 0.060592161594373,
      "loss": 2.7499,
      "step": 245220
    },
    {
      "epoch": 394.28,
      "learning_rate": 0.060588946163504825,
      "loss": 2.7741,
      "step": 245240
    },
    {
      "epoch": 394.31,
      "learning_rate": 0.06058573073263666,
      "loss": 2.777,
      "step": 245260
    },
    {
      "epoch": 394.34,
      "learning_rate": 0.06058251530176848,
      "loss": 2.8018,
      "step": 245280
    },
    {
      "epoch": 394.37,
      "learning_rate": 0.06057929987090033,
      "loss": 2.7755,
      "step": 245300
    },
    {
      "epoch": 394.41,
      "learning_rate": 0.06057608444003215,
      "loss": 2.7895,
      "step": 245320
    },
    {
      "epoch": 394.44,
      "learning_rate": 0.06057286900916399,
      "loss": 2.7522,
      "step": 245340
    },
    {
      "epoch": 394.47,
      "learning_rate": 0.06056965357829583,
      "loss": 2.7807,
      "step": 245360
    },
    {
      "epoch": 394.5,
      "learning_rate": 0.060566438147427654,
      "loss": 2.8306,
      "step": 245380
    },
    {
      "epoch": 394.53,
      "learning_rate": 0.0605632227165595,
      "loss": 2.8102,
      "step": 245400
    },
    {
      "epoch": 394.57,
      "learning_rate": 0.06056000728569131,
      "loss": 2.7861,
      "step": 245420
    },
    {
      "epoch": 394.6,
      "learning_rate": 0.060556791854823155,
      "loss": 2.7547,
      "step": 245440
    },
    {
      "epoch": 394.63,
      "learning_rate": 0.06055357642395498,
      "loss": 2.7815,
      "step": 245460
    },
    {
      "epoch": 394.66,
      "learning_rate": 0.06055036099308682,
      "loss": 2.8179,
      "step": 245480
    },
    {
      "epoch": 394.69,
      "learning_rate": 0.060547145562218664,
      "loss": 2.7785,
      "step": 245500
    },
    {
      "epoch": 394.73,
      "learning_rate": 0.06054393013135048,
      "loss": 2.7915,
      "step": 245520
    },
    {
      "epoch": 394.76,
      "learning_rate": 0.06054071470048231,
      "loss": 2.7683,
      "step": 245540
    },
    {
      "epoch": 394.79,
      "learning_rate": 0.06053749926961415,
      "loss": 2.7963,
      "step": 245560
    },
    {
      "epoch": 394.82,
      "learning_rate": 0.060534283838745984,
      "loss": 2.8308,
      "step": 245580
    },
    {
      "epoch": 394.86,
      "learning_rate": 0.06053106840787781,
      "loss": 2.7783,
      "step": 245600
    },
    {
      "epoch": 394.89,
      "learning_rate": 0.06052785297700965,
      "loss": 2.7543,
      "step": 245620
    },
    {
      "epoch": 394.92,
      "learning_rate": 0.060524637546141485,
      "loss": 2.8035,
      "step": 245640
    },
    {
      "epoch": 394.95,
      "learning_rate": 0.06052142211527331,
      "loss": 2.7956,
      "step": 245660
    },
    {
      "epoch": 394.98,
      "learning_rate": 0.06051820668440514,
      "loss": 2.814,
      "step": 245680
    },
    {
      "epoch": 395.0,
      "eval_accuracy": {
        "accuracy": 0.39586410635155095
      },
      "eval_loss": 2.9179110527038574,
      "eval_runtime": 2.7505,
      "eval_samples_per_second": 4676.525,
      "eval_steps_per_second": 73.076,
      "step": 245690
    },
    {
      "epoch": 395.02,
      "learning_rate": 0.06051499125353698,
      "loss": 2.8229,
      "step": 245700
    },
    {
      "epoch": 395.05,
      "learning_rate": 0.06051177582266881,
      "loss": 2.7626,
      "step": 245720
    },
    {
      "epoch": 395.08,
      "learning_rate": 0.06050856039180065,
      "loss": 2.7636,
      "step": 245740
    },
    {
      "epoch": 395.11,
      "learning_rate": 0.060505344960932475,
      "loss": 2.779,
      "step": 245760
    },
    {
      "epoch": 395.14,
      "learning_rate": 0.060502129530064314,
      "loss": 2.788,
      "step": 245780
    },
    {
      "epoch": 395.18,
      "learning_rate": 0.060498914099196145,
      "loss": 2.8,
      "step": 245800
    },
    {
      "epoch": 395.21,
      "learning_rate": 0.06049569866832797,
      "loss": 2.7843,
      "step": 245820
    },
    {
      "epoch": 395.24,
      "learning_rate": 0.060492483237459815,
      "loss": 2.7558,
      "step": 245840
    },
    {
      "epoch": 395.27,
      "learning_rate": 0.06048926780659164,
      "loss": 2.7679,
      "step": 245860
    },
    {
      "epoch": 395.31,
      "learning_rate": 0.06048605237572348,
      "loss": 2.8051,
      "step": 245880
    },
    {
      "epoch": 395.34,
      "learning_rate": 0.06048283694485532,
      "loss": 2.8138,
      "step": 245900
    },
    {
      "epoch": 395.37,
      "learning_rate": 0.06047962151398714,
      "loss": 2.7671,
      "step": 245920
    },
    {
      "epoch": 395.4,
      "learning_rate": 0.06047640608311897,
      "loss": 2.7813,
      "step": 245940
    },
    {
      "epoch": 395.43,
      "learning_rate": 0.0604731906522508,
      "loss": 2.7862,
      "step": 245960
    },
    {
      "epoch": 395.47,
      "learning_rate": 0.060469975221382644,
      "loss": 2.7705,
      "step": 245980
    },
    {
      "epoch": 395.5,
      "learning_rate": 0.06046675979051447,
      "loss": 2.7495,
      "step": 246000
    },
    {
      "epoch": 395.53,
      "learning_rate": 0.06046354435964631,
      "loss": 2.794,
      "step": 246020
    },
    {
      "epoch": 395.56,
      "learning_rate": 0.060460328928778145,
      "loss": 2.7829,
      "step": 246040
    },
    {
      "epoch": 395.59,
      "learning_rate": 0.06045711349790997,
      "loss": 2.7552,
      "step": 246060
    },
    {
      "epoch": 395.63,
      "learning_rate": 0.0604538980670418,
      "loss": 2.7918,
      "step": 246080
    },
    {
      "epoch": 395.66,
      "learning_rate": 0.060450682636173626,
      "loss": 2.7729,
      "step": 246100
    },
    {
      "epoch": 395.69,
      "learning_rate": 0.06044746720530547,
      "loss": 2.7902,
      "step": 246120
    },
    {
      "epoch": 395.72,
      "learning_rate": 0.060444251774437296,
      "loss": 2.8222,
      "step": 246140
    },
    {
      "epoch": 395.76,
      "learning_rate": 0.060441036343569135,
      "loss": 2.8097,
      "step": 246160
    },
    {
      "epoch": 395.79,
      "learning_rate": 0.060437820912700974,
      "loss": 2.8125,
      "step": 246180
    },
    {
      "epoch": 395.82,
      "learning_rate": 0.0604346054818328,
      "loss": 2.8106,
      "step": 246200
    },
    {
      "epoch": 395.85,
      "learning_rate": 0.06043139005096463,
      "loss": 2.7756,
      "step": 246220
    },
    {
      "epoch": 395.88,
      "learning_rate": 0.06042817462009647,
      "loss": 2.7628,
      "step": 246240
    },
    {
      "epoch": 395.92,
      "learning_rate": 0.0604249591892283,
      "loss": 2.7583,
      "step": 246260
    },
    {
      "epoch": 395.95,
      "learning_rate": 0.060421743758360125,
      "loss": 2.773,
      "step": 246280
    },
    {
      "epoch": 395.98,
      "learning_rate": 0.06041852832749196,
      "loss": 2.7638,
      "step": 246300
    },
    {
      "epoch": 396.0,
      "eval_accuracy": {
        "accuracy": 0.4017725258493353
      },
      "eval_loss": 2.8794586658477783,
      "eval_runtime": 2.7457,
      "eval_samples_per_second": 4684.699,
      "eval_steps_per_second": 73.204,
      "step": 246312
    },
    {
      "epoch": 396.01,
      "learning_rate": 0.0604153128966238,
      "loss": 2.7846,
      "step": 246320
    },
    {
      "epoch": 396.05,
      "learning_rate": 0.06041209746575563,
      "loss": 2.8057,
      "step": 246340
    },
    {
      "epoch": 396.08,
      "learning_rate": 0.06040888203488746,
      "loss": 2.7774,
      "step": 246360
    },
    {
      "epoch": 396.11,
      "learning_rate": 0.0604056666040193,
      "loss": 2.7583,
      "step": 246380
    },
    {
      "epoch": 396.14,
      "learning_rate": 0.06040245117315113,
      "loss": 2.7836,
      "step": 246400
    },
    {
      "epoch": 396.17,
      "learning_rate": 0.06039923574228297,
      "loss": 2.7872,
      "step": 246420
    },
    {
      "epoch": 396.21,
      "learning_rate": 0.06039602031141479,
      "loss": 2.8023,
      "step": 246440
    },
    {
      "epoch": 396.24,
      "learning_rate": 0.06039280488054663,
      "loss": 2.7897,
      "step": 246460
    },
    {
      "epoch": 396.27,
      "learning_rate": 0.06038958944967846,
      "loss": 2.7543,
      "step": 246480
    },
    {
      "epoch": 396.3,
      "learning_rate": 0.060386374018810286,
      "loss": 2.7694,
      "step": 246500
    },
    {
      "epoch": 396.33,
      "learning_rate": 0.06038315858794213,
      "loss": 2.7696,
      "step": 246520
    },
    {
      "epoch": 396.37,
      "learning_rate": 0.060379943157073956,
      "loss": 2.7719,
      "step": 246540
    },
    {
      "epoch": 396.4,
      "learning_rate": 0.060376727726205795,
      "loss": 2.7942,
      "step": 246560
    },
    {
      "epoch": 396.43,
      "learning_rate": 0.060373512295337634,
      "loss": 2.7637,
      "step": 246580
    },
    {
      "epoch": 396.46,
      "learning_rate": 0.06037029686446946,
      "loss": 2.7767,
      "step": 246600
    },
    {
      "epoch": 396.5,
      "learning_rate": 0.06036708143360129,
      "loss": 2.8016,
      "step": 246620
    },
    {
      "epoch": 396.53,
      "learning_rate": 0.060363866002733114,
      "loss": 2.785,
      "step": 246640
    },
    {
      "epoch": 396.56,
      "learning_rate": 0.06036065057186496,
      "loss": 2.7507,
      "step": 246660
    },
    {
      "epoch": 396.59,
      "learning_rate": 0.060357435140996785,
      "loss": 2.7541,
      "step": 246680
    },
    {
      "epoch": 396.62,
      "learning_rate": 0.06035421971012862,
      "loss": 2.8085,
      "step": 246700
    },
    {
      "epoch": 396.66,
      "learning_rate": 0.06035100427926046,
      "loss": 2.8049,
      "step": 246720
    },
    {
      "epoch": 396.69,
      "learning_rate": 0.060347788848392286,
      "loss": 2.7579,
      "step": 246740
    },
    {
      "epoch": 396.72,
      "learning_rate": 0.06034457341752412,
      "loss": 2.7754,
      "step": 246760
    },
    {
      "epoch": 396.75,
      "learning_rate": 0.06034135798665594,
      "loss": 2.7799,
      "step": 246780
    },
    {
      "epoch": 396.78,
      "learning_rate": 0.06033814255578779,
      "loss": 2.802,
      "step": 246800
    },
    {
      "epoch": 396.82,
      "learning_rate": 0.06033492712491961,
      "loss": 2.7937,
      "step": 246820
    },
    {
      "epoch": 396.85,
      "learning_rate": 0.06033171169405145,
      "loss": 2.7715,
      "step": 246840
    },
    {
      "epoch": 396.88,
      "learning_rate": 0.06032849626318329,
      "loss": 2.7522,
      "step": 246860
    },
    {
      "epoch": 396.91,
      "learning_rate": 0.060325280832315115,
      "loss": 2.7746,
      "step": 246880
    },
    {
      "epoch": 396.95,
      "learning_rate": 0.060322065401446946,
      "loss": 2.7997,
      "step": 246900
    },
    {
      "epoch": 396.98,
      "learning_rate": 0.060318849970578785,
      "loss": 2.7947,
      "step": 246920
    },
    {
      "epoch": 397.0,
      "eval_accuracy": {
        "accuracy": 0.39298763896447175
      },
      "eval_loss": 2.8953640460968018,
      "eval_runtime": 2.7432,
      "eval_samples_per_second": 4689.116,
      "eval_steps_per_second": 73.273,
      "step": 246934
    },
    {
      "epoch": 397.01,
      "learning_rate": 0.060315634539710616,
      "loss": 2.7756,
      "step": 246940
    },
    {
      "epoch": 397.04,
      "learning_rate": 0.06031241910884244,
      "loss": 2.7875,
      "step": 246960
    },
    {
      "epoch": 397.07,
      "learning_rate": 0.06030920367797428,
      "loss": 2.7946,
      "step": 246980
    },
    {
      "epoch": 397.11,
      "learning_rate": 0.06030598824710612,
      "loss": 2.7471,
      "step": 247000
    },
    {
      "epoch": 397.14,
      "learning_rate": 0.06030277281623795,
      "loss": 2.7532,
      "step": 247020
    },
    {
      "epoch": 397.17,
      "learning_rate": 0.060299557385369774,
      "loss": 2.7978,
      "step": 247040
    },
    {
      "epoch": 397.2,
      "learning_rate": 0.06029634195450161,
      "loss": 2.7763,
      "step": 247060
    },
    {
      "epoch": 397.23,
      "learning_rate": 0.060293126523633445,
      "loss": 2.7423,
      "step": 247080
    },
    {
      "epoch": 397.27,
      "learning_rate": 0.06028991109276528,
      "loss": 2.7488,
      "step": 247100
    },
    {
      "epoch": 397.3,
      "learning_rate": 0.060286695661897094,
      "loss": 2.7734,
      "step": 247120
    },
    {
      "epoch": 397.33,
      "learning_rate": 0.060283480231028946,
      "loss": 2.7525,
      "step": 247140
    },
    {
      "epoch": 397.36,
      "learning_rate": 0.06028026480016078,
      "loss": 2.7552,
      "step": 247160
    },
    {
      "epoch": 397.4,
      "learning_rate": 0.0602770493692926,
      "loss": 2.7482,
      "step": 247180
    },
    {
      "epoch": 397.43,
      "learning_rate": 0.06027383393842445,
      "loss": 2.7559,
      "step": 247200
    },
    {
      "epoch": 397.46,
      "learning_rate": 0.060270618507556266,
      "loss": 2.8039,
      "step": 247220
    },
    {
      "epoch": 397.49,
      "learning_rate": 0.06026740307668811,
      "loss": 2.7518,
      "step": 247240
    },
    {
      "epoch": 397.52,
      "learning_rate": 0.06026418764581995,
      "loss": 2.7696,
      "step": 247260
    },
    {
      "epoch": 397.56,
      "learning_rate": 0.060260972214951775,
      "loss": 2.7388,
      "step": 247280
    },
    {
      "epoch": 397.59,
      "learning_rate": 0.06025791755562701,
      "loss": 2.8292,
      "step": 247300
    },
    {
      "epoch": 397.62,
      "learning_rate": 0.06025470212475884,
      "loss": 2.8196,
      "step": 247320
    },
    {
      "epoch": 397.65,
      "learning_rate": 0.06025148669389067,
      "loss": 2.7966,
      "step": 247340
    },
    {
      "epoch": 397.68,
      "learning_rate": 0.06024827126302251,
      "loss": 2.7801,
      "step": 247360
    },
    {
      "epoch": 397.72,
      "learning_rate": 0.06024505583215434,
      "loss": 2.7683,
      "step": 247380
    },
    {
      "epoch": 397.75,
      "learning_rate": 0.06024184040128619,
      "loss": 2.7878,
      "step": 247400
    },
    {
      "epoch": 397.78,
      "learning_rate": 0.060238624970418014,
      "loss": 2.7763,
      "step": 247420
    },
    {
      "epoch": 397.81,
      "learning_rate": 0.06023540953954984,
      "loss": 2.7916,
      "step": 247440
    },
    {
      "epoch": 397.85,
      "learning_rate": 0.060232194108681684,
      "loss": 2.8176,
      "step": 247460
    },
    {
      "epoch": 397.88,
      "learning_rate": 0.060228978677813495,
      "loss": 2.7762,
      "step": 247480
    },
    {
      "epoch": 397.91,
      "learning_rate": 0.06022576324694534,
      "loss": 2.7603,
      "step": 247500
    },
    {
      "epoch": 397.94,
      "learning_rate": 0.060222547816077165,
      "loss": 2.7765,
      "step": 247520
    },
    {
      "epoch": 397.97,
      "learning_rate": 0.060219332385209004,
      "loss": 2.7871,
      "step": 247540
    },
    {
      "epoch": 398.0,
      "eval_accuracy": {
        "accuracy": 0.40200575293477414
      },
      "eval_loss": 2.878474712371826,
      "eval_runtime": 2.9422,
      "eval_samples_per_second": 4371.969,
      "eval_steps_per_second": 68.317,
      "step": 247556
    },
    {
      "epoch": 398.01,
      "learning_rate": 0.06021611695434085,
      "loss": 2.773,
      "step": 247560
    },
    {
      "epoch": 398.04,
      "learning_rate": 0.06021290152347267,
      "loss": 2.7694,
      "step": 247580
    },
    {
      "epoch": 398.07,
      "learning_rate": 0.06020968609260451,
      "loss": 2.7571,
      "step": 247600
    },
    {
      "epoch": 398.1,
      "learning_rate": 0.06020647066173634,
      "loss": 2.805,
      "step": 247620
    },
    {
      "epoch": 398.14,
      "learning_rate": 0.06020325523086817,
      "loss": 2.7753,
      "step": 247640
    },
    {
      "epoch": 398.17,
      "learning_rate": 0.060200039799999994,
      "loss": 2.7963,
      "step": 247660
    },
    {
      "epoch": 398.2,
      "learning_rate": 0.06019682436913183,
      "loss": 2.7831,
      "step": 247680
    },
    {
      "epoch": 398.23,
      "learning_rate": 0.06019360893826368,
      "loss": 2.7979,
      "step": 247700
    },
    {
      "epoch": 398.26,
      "learning_rate": 0.060190393507395495,
      "loss": 2.7703,
      "step": 247720
    },
    {
      "epoch": 398.3,
      "learning_rate": 0.06018717807652733,
      "loss": 2.7627,
      "step": 247740
    },
    {
      "epoch": 398.33,
      "learning_rate": 0.060183962645659166,
      "loss": 2.7852,
      "step": 247760
    },
    {
      "epoch": 398.36,
      "learning_rate": 0.060180747214791,
      "loss": 2.7761,
      "step": 247780
    },
    {
      "epoch": 398.39,
      "learning_rate": 0.06017753178392285,
      "loss": 2.7658,
      "step": 247800
    },
    {
      "epoch": 398.42,
      "learning_rate": 0.06017431635305466,
      "loss": 2.7599,
      "step": 247820
    },
    {
      "epoch": 398.46,
      "learning_rate": 0.0601711009221865,
      "loss": 2.7651,
      "step": 247840
    },
    {
      "epoch": 398.49,
      "learning_rate": 0.06016788549131833,
      "loss": 2.7883,
      "step": 247860
    },
    {
      "epoch": 398.52,
      "learning_rate": 0.060164670060450155,
      "loss": 2.7632,
      "step": 247880
    },
    {
      "epoch": 398.55,
      "learning_rate": 0.060161454629582,
      "loss": 2.794,
      "step": 247900
    },
    {
      "epoch": 398.59,
      "learning_rate": 0.060158239198713825,
      "loss": 2.7988,
      "step": 247920
    },
    {
      "epoch": 398.62,
      "learning_rate": 0.060155023767845664,
      "loss": 2.8105,
      "step": 247940
    },
    {
      "epoch": 398.65,
      "learning_rate": 0.0601518083369775,
      "loss": 2.8168,
      "step": 247960
    },
    {
      "epoch": 398.68,
      "learning_rate": 0.06014859290610933,
      "loss": 2.7866,
      "step": 247980
    },
    {
      "epoch": 398.71,
      "learning_rate": 0.06014537747524116,
      "loss": 2.7763,
      "step": 248000
    },
    {
      "epoch": 398.75,
      "learning_rate": 0.06014216204437298,
      "loss": 2.7751,
      "step": 248020
    },
    {
      "epoch": 398.78,
      "learning_rate": 0.06013894661350483,
      "loss": 2.7631,
      "step": 248040
    },
    {
      "epoch": 398.81,
      "learning_rate": 0.060135731182636654,
      "loss": 2.7925,
      "step": 248060
    },
    {
      "epoch": 398.84,
      "learning_rate": 0.06013251575176849,
      "loss": 2.7722,
      "step": 248080
    },
    {
      "epoch": 398.87,
      "learning_rate": 0.06012930032090033,
      "loss": 2.7965,
      "step": 248100
    },
    {
      "epoch": 398.91,
      "learning_rate": 0.060126084890032155,
      "loss": 2.776,
      "step": 248120
    },
    {
      "epoch": 398.94,
      "learning_rate": 0.060122869459164,
      "loss": 2.7756,
      "step": 248140
    },
    {
      "epoch": 398.97,
      "learning_rate": 0.06011965402829581,
      "loss": 2.7602,
      "step": 248160
    },
    {
      "epoch": 399.0,
      "eval_accuracy": {
        "accuracy": 0.40052864806032806
      },
      "eval_loss": 2.872504711151123,
      "eval_runtime": 2.896,
      "eval_samples_per_second": 4441.599,
      "eval_steps_per_second": 69.405,
      "step": 248178
    },
    {
      "epoch": 399.0,
      "learning_rate": 0.06011643859742766,
      "loss": 2.7623,
      "step": 248180
    },
    {
      "epoch": 399.04,
      "learning_rate": 0.06011322316655948,
      "loss": 2.7586,
      "step": 248200
    },
    {
      "epoch": 399.07,
      "learning_rate": 0.06011000773569132,
      "loss": 2.7641,
      "step": 248220
    },
    {
      "epoch": 399.1,
      "learning_rate": 0.060106792304823166,
      "loss": 2.753,
      "step": 248240
    },
    {
      "epoch": 399.13,
      "learning_rate": 0.060103576873954984,
      "loss": 2.7839,
      "step": 248260
    },
    {
      "epoch": 399.16,
      "learning_rate": 0.060100361443086815,
      "loss": 2.7698,
      "step": 248280
    },
    {
      "epoch": 399.2,
      "learning_rate": 0.060097146012218654,
      "loss": 2.79,
      "step": 248300
    },
    {
      "epoch": 399.23,
      "learning_rate": 0.060093930581350485,
      "loss": 2.8026,
      "step": 248320
    },
    {
      "epoch": 399.26,
      "learning_rate": 0.06009071515048231,
      "loss": 2.7854,
      "step": 248340
    },
    {
      "epoch": 399.29,
      "learning_rate": 0.06008749971961415,
      "loss": 2.7979,
      "step": 248360
    },
    {
      "epoch": 399.32,
      "learning_rate": 0.06008428428874599,
      "loss": 2.7864,
      "step": 248380
    },
    {
      "epoch": 399.36,
      "learning_rate": 0.06008106885787781,
      "loss": 2.7599,
      "step": 248400
    },
    {
      "epoch": 399.39,
      "learning_rate": 0.06007785342700964,
      "loss": 2.7671,
      "step": 248420
    },
    {
      "epoch": 399.42,
      "learning_rate": 0.06007463799614148,
      "loss": 2.7766,
      "step": 248440
    },
    {
      "epoch": 399.45,
      "learning_rate": 0.060071422565273314,
      "loss": 2.7701,
      "step": 248460
    },
    {
      "epoch": 399.49,
      "learning_rate": 0.06006820713440515,
      "loss": 2.7775,
      "step": 248480
    },
    {
      "epoch": 399.52,
      "learning_rate": 0.06006499170353698,
      "loss": 2.7778,
      "step": 248500
    },
    {
      "epoch": 399.55,
      "learning_rate": 0.060061776272668815,
      "loss": 2.7463,
      "step": 248520
    },
    {
      "epoch": 399.58,
      "learning_rate": 0.06005856084180065,
      "loss": 2.7544,
      "step": 248540
    },
    {
      "epoch": 399.61,
      "learning_rate": 0.06005534541093247,
      "loss": 2.7745,
      "step": 248560
    },
    {
      "epoch": 399.65,
      "learning_rate": 0.06005212998006432,
      "loss": 2.7805,
      "step": 248580
    },
    {
      "epoch": 399.68,
      "learning_rate": 0.06004891454919614,
      "loss": 2.7809,
      "step": 248600
    },
    {
      "epoch": 399.71,
      "learning_rate": 0.06004569911832798,
      "loss": 2.7464,
      "step": 248620
    },
    {
      "epoch": 399.74,
      "learning_rate": 0.06004248368745982,
      "loss": 2.7607,
      "step": 248640
    },
    {
      "epoch": 399.77,
      "learning_rate": 0.060039268256591644,
      "loss": 2.7651,
      "step": 248660
    },
    {
      "epoch": 399.81,
      "learning_rate": 0.060036052825723475,
      "loss": 2.8033,
      "step": 248680
    },
    {
      "epoch": 399.84,
      "learning_rate": 0.0600328373948553,
      "loss": 2.7674,
      "step": 248700
    },
    {
      "epoch": 399.87,
      "learning_rate": 0.060029621963987145,
      "loss": 2.7952,
      "step": 248720
    },
    {
      "epoch": 399.9,
      "learning_rate": 0.06002640653311897,
      "loss": 2.7904,
      "step": 248740
    },
    {
      "epoch": 399.94,
      "learning_rate": 0.06002319110225081,
      "loss": 2.7672,
      "step": 248760
    },
    {
      "epoch": 399.97,
      "learning_rate": 0.06001997567138265,
      "loss": 2.7498,
      "step": 248780
    },
    {
      "epoch": 400.0,
      "learning_rate": 0.06001676024051447,
      "loss": 2.766,
      "step": 248800
    },
    {
      "epoch": 400.0,
      "eval_accuracy": {
        "accuracy": 0.39749669594962295
      },
      "eval_loss": 2.903395652770996,
      "eval_runtime": 2.8164,
      "eval_samples_per_second": 4567.201,
      "eval_steps_per_second": 71.368,
      "step": 248800
    },
    {
      "epoch": 400.03,
      "learning_rate": 0.0600135448096463,
      "loss": 2.8014,
      "step": 248820
    },
    {
      "epoch": 400.06,
      "learning_rate": 0.06001032937877813,
      "loss": 2.766,
      "step": 248840
    },
    {
      "epoch": 400.1,
      "learning_rate": 0.060007113947909974,
      "loss": 2.7567,
      "step": 248860
    },
    {
      "epoch": 400.13,
      "learning_rate": 0.0600038985170418,
      "loss": 2.7509,
      "step": 248880
    },
    {
      "epoch": 400.16,
      "learning_rate": 0.06000068308617364,
      "loss": 2.7761,
      "step": 248900
    },
    {
      "epoch": 400.19,
      "learning_rate": 0.059997467655305475,
      "loss": 2.7735,
      "step": 248920
    },
    {
      "epoch": 400.23,
      "learning_rate": 0.0599942522244373,
      "loss": 2.7653,
      "step": 248940
    },
    {
      "epoch": 400.26,
      "learning_rate": 0.05999103679356913,
      "loss": 2.7994,
      "step": 248960
    },
    {
      "epoch": 400.29,
      "learning_rate": 0.05998782136270097,
      "loss": 2.7795,
      "step": 248980
    },
    {
      "epoch": 400.32,
      "learning_rate": 0.0599846059318328,
      "loss": 2.765,
      "step": 249000
    },
    {
      "epoch": 400.35,
      "learning_rate": 0.059981390500964626,
      "loss": 2.7871,
      "step": 249020
    },
    {
      "epoch": 400.39,
      "learning_rate": 0.059978175070096465,
      "loss": 2.7572,
      "step": 249040
    },
    {
      "epoch": 400.42,
      "learning_rate": 0.059974959639228304,
      "loss": 2.7801,
      "step": 249060
    },
    {
      "epoch": 400.45,
      "learning_rate": 0.059971744208360135,
      "loss": 2.7704,
      "step": 249080
    },
    {
      "epoch": 400.48,
      "learning_rate": 0.05996852877749196,
      "loss": 2.7809,
      "step": 249100
    },
    {
      "epoch": 400.51,
      "learning_rate": 0.0599653133466238,
      "loss": 2.79,
      "step": 249120
    },
    {
      "epoch": 400.55,
      "learning_rate": 0.05996209791575563,
      "loss": 2.7694,
      "step": 249140
    },
    {
      "epoch": 400.58,
      "learning_rate": 0.05995888248488747,
      "loss": 2.7583,
      "step": 249160
    },
    {
      "epoch": 400.61,
      "learning_rate": 0.05995566705401929,
      "loss": 2.806,
      "step": 249180
    },
    {
      "epoch": 400.64,
      "learning_rate": 0.05995245162315113,
      "loss": 2.7533,
      "step": 249200
    },
    {
      "epoch": 400.68,
      "learning_rate": 0.05994923619228296,
      "loss": 2.7785,
      "step": 249220
    },
    {
      "epoch": 400.71,
      "learning_rate": 0.05994602076141479,
      "loss": 2.8005,
      "step": 249240
    },
    {
      "epoch": 400.74,
      "learning_rate": 0.059942805330546634,
      "loss": 2.7897,
      "step": 249260
    },
    {
      "epoch": 400.77,
      "learning_rate": 0.05993958989967846,
      "loss": 2.7707,
      "step": 249280
    },
    {
      "epoch": 400.8,
      "learning_rate": 0.0599363744688103,
      "loss": 2.7843,
      "step": 249300
    },
    {
      "epoch": 400.84,
      "learning_rate": 0.059933159037942135,
      "loss": 2.802,
      "step": 249320
    },
    {
      "epoch": 400.87,
      "learning_rate": 0.05992994360707396,
      "loss": 2.7753,
      "step": 249340
    },
    {
      "epoch": 400.9,
      "learning_rate": 0.05992672817620579,
      "loss": 2.7843,
      "step": 249360
    },
    {
      "epoch": 400.93,
      "learning_rate": 0.05992367351688103,
      "loss": 2.7986,
      "step": 249380
    },
    {
      "epoch": 400.96,
      "learning_rate": 0.05992045808601285,
      "loss": 2.7945,
      "step": 249400
    },
    {
      "epoch": 401.0,
      "learning_rate": 0.0599172426551447,
      "loss": 2.7771,
      "step": 249420
    },
    {
      "epoch": 401.0,
      "eval_accuracy": {
        "accuracy": 0.39703024177874524
      },
      "eval_loss": 2.893031597137451,
      "eval_runtime": 3.5587,
      "eval_samples_per_second": 3614.491,
      "eval_steps_per_second": 56.481,
      "step": 249422
    },
    {
      "epoch": 401.03,
      "learning_rate": 0.05991402722427652,
      "loss": 2.7861,
      "step": 249440
    },
    {
      "epoch": 401.06,
      "learning_rate": 0.059910811793408375,
      "loss": 2.7756,
      "step": 249460
    },
    {
      "epoch": 401.09,
      "learning_rate": 0.0599075963625402,
      "loss": 2.778,
      "step": 249480
    },
    {
      "epoch": 401.13,
      "learning_rate": 0.059904380931672024,
      "loss": 2.764,
      "step": 249500
    },
    {
      "epoch": 401.16,
      "learning_rate": 0.05990116550080387,
      "loss": 2.7582,
      "step": 249520
    },
    {
      "epoch": 401.19,
      "learning_rate": 0.05989795006993568,
      "loss": 2.7766,
      "step": 249540
    },
    {
      "epoch": 401.22,
      "learning_rate": 0.059894734639067526,
      "loss": 2.7702,
      "step": 249560
    },
    {
      "epoch": 401.25,
      "learning_rate": 0.059891519208199365,
      "loss": 2.7464,
      "step": 249580
    },
    {
      "epoch": 401.29,
      "learning_rate": 0.0598883037773312,
      "loss": 2.7978,
      "step": 249600
    },
    {
      "epoch": 401.32,
      "learning_rate": 0.059885088346463035,
      "loss": 2.8079,
      "step": 249620
    },
    {
      "epoch": 401.35,
      "learning_rate": 0.05988187291559485,
      "loss": 2.8157,
      "step": 249640
    },
    {
      "epoch": 401.38,
      "learning_rate": 0.0598786574847267,
      "loss": 2.7449,
      "step": 249660
    },
    {
      "epoch": 401.41,
      "learning_rate": 0.05987544205385853,
      "loss": 2.7561,
      "step": 249680
    },
    {
      "epoch": 401.45,
      "learning_rate": 0.059872226622990354,
      "loss": 2.7841,
      "step": 249700
    },
    {
      "epoch": 401.48,
      "learning_rate": 0.05986901119212218,
      "loss": 2.7584,
      "step": 249720
    },
    {
      "epoch": 401.51,
      "learning_rate": 0.05986579576125402,
      "loss": 2.7906,
      "step": 249740
    },
    {
      "epoch": 401.54,
      "learning_rate": 0.05986258033038586,
      "loss": 2.7949,
      "step": 249760
    },
    {
      "epoch": 401.58,
      "learning_rate": 0.05985936489951768,
      "loss": 2.7899,
      "step": 249780
    },
    {
      "epoch": 401.61,
      "learning_rate": 0.059856149468649526,
      "loss": 2.7594,
      "step": 249800
    },
    {
      "epoch": 401.64,
      "learning_rate": 0.05985293403778135,
      "loss": 2.7598,
      "step": 249820
    },
    {
      "epoch": 401.67,
      "learning_rate": 0.05984971860691318,
      "loss": 2.7427,
      "step": 249840
    },
    {
      "epoch": 401.7,
      "learning_rate": 0.059846503176045035,
      "loss": 2.7526,
      "step": 249860
    },
    {
      "epoch": 401.74,
      "learning_rate": 0.059843287745176846,
      "loss": 2.7663,
      "step": 249880
    },
    {
      "epoch": 401.77,
      "learning_rate": 0.05984007231430869,
      "loss": 2.7894,
      "step": 249900
    },
    {
      "epoch": 401.8,
      "learning_rate": 0.059836856883440516,
      "loss": 2.7836,
      "step": 249920
    },
    {
      "epoch": 401.83,
      "learning_rate": 0.05983364145257234,
      "loss": 2.767,
      "step": 249940
    },
    {
      "epoch": 401.86,
      "learning_rate": 0.059830426021704186,
      "loss": 2.765,
      "step": 249960
    },
    {
      "epoch": 401.9,
      "learning_rate": 0.05982721059083601,
      "loss": 2.7901,
      "step": 249980
    },
    {
      "epoch": 401.93,
      "learning_rate": 0.05982399515996786,
      "loss": 2.8065,
      "step": 250000
    },
    {
      "epoch": 401.96,
      "learning_rate": 0.05982077972909969,
      "loss": 2.7716,
      "step": 250020
    },
    {
      "epoch": 401.99,
      "learning_rate": 0.05981756429823151,
      "loss": 2.7976,
      "step": 250040
    },
    {
      "epoch": 402.0,
      "eval_accuracy": {
        "accuracy": 0.39679701469330636
      },
      "eval_loss": 2.8956458568573,
      "eval_runtime": 2.7658,
      "eval_samples_per_second": 4650.734,
      "eval_steps_per_second": 72.673,
      "step": 250044
    },
    {
      "epoch": 402.03,
      "learning_rate": 0.059814348867363344,
      "loss": 2.7812,
      "step": 250060
    },
    {
      "epoch": 402.06,
      "learning_rate": 0.05981113343649517,
      "loss": 2.7809,
      "step": 250080
    },
    {
      "epoch": 402.09,
      "learning_rate": 0.059807918005627014,
      "loss": 2.7803,
      "step": 250100
    },
    {
      "epoch": 402.12,
      "learning_rate": 0.05980470257475884,
      "loss": 2.7521,
      "step": 250120
    },
    {
      "epoch": 402.15,
      "learning_rate": 0.05980148714389068,
      "loss": 2.7551,
      "step": 250140
    },
    {
      "epoch": 402.19,
      "learning_rate": 0.059798271713022516,
      "loss": 2.7638,
      "step": 250160
    },
    {
      "epoch": 402.22,
      "learning_rate": 0.05979505628215434,
      "loss": 2.7771,
      "step": 250180
    },
    {
      "epoch": 402.25,
      "learning_rate": 0.059791840851286186,
      "loss": 2.7776,
      "step": 250200
    },
    {
      "epoch": 402.28,
      "learning_rate": 0.059788625420418,
      "loss": 2.7764,
      "step": 250220
    },
    {
      "epoch": 402.32,
      "learning_rate": 0.05978540998954984,
      "loss": 2.7869,
      "step": 250240
    },
    {
      "epoch": 402.35,
      "learning_rate": 0.05978219455868167,
      "loss": 2.7672,
      "step": 250260
    },
    {
      "epoch": 402.38,
      "learning_rate": 0.059778979127813506,
      "loss": 2.7487,
      "step": 250280
    },
    {
      "epoch": 402.41,
      "learning_rate": 0.05977576369694535,
      "loss": 2.787,
      "step": 250300
    },
    {
      "epoch": 402.44,
      "learning_rate": 0.05977254826607717,
      "loss": 2.7984,
      "step": 250320
    },
    {
      "epoch": 402.48,
      "learning_rate": 0.059769332835209014,
      "loss": 2.7808,
      "step": 250340
    },
    {
      "epoch": 402.51,
      "learning_rate": 0.05976611740434084,
      "loss": 2.783,
      "step": 250360
    },
    {
      "epoch": 402.54,
      "learning_rate": 0.05976290197347267,
      "loss": 2.7829,
      "step": 250380
    },
    {
      "epoch": 402.57,
      "learning_rate": 0.059759686542604495,
      "loss": 2.7627,
      "step": 250400
    },
    {
      "epoch": 402.6,
      "learning_rate": 0.059756471111736334,
      "loss": 2.7346,
      "step": 250420
    },
    {
      "epoch": 402.64,
      "learning_rate": 0.05975325568086818,
      "loss": 2.7434,
      "step": 250440
    },
    {
      "epoch": 402.67,
      "learning_rate": 0.05975004025,
      "loss": 2.7456,
      "step": 250460
    },
    {
      "epoch": 402.7,
      "learning_rate": 0.05974682481913183,
      "loss": 2.7933,
      "step": 250480
    },
    {
      "epoch": 402.73,
      "learning_rate": 0.05974360938826367,
      "loss": 2.7856,
      "step": 250500
    },
    {
      "epoch": 402.77,
      "learning_rate": 0.0597403939573955,
      "loss": 2.7747,
      "step": 250520
    },
    {
      "epoch": 402.8,
      "learning_rate": 0.05973717852652735,
      "loss": 2.7552,
      "step": 250540
    },
    {
      "epoch": 402.83,
      "learning_rate": 0.05973396309565916,
      "loss": 2.7495,
      "step": 250560
    },
    {
      "epoch": 402.86,
      "learning_rate": 0.059730747664791,
      "loss": 2.7579,
      "step": 250580
    },
    {
      "epoch": 402.89,
      "learning_rate": 0.05972753223392283,
      "loss": 2.7847,
      "step": 250600
    },
    {
      "epoch": 402.93,
      "learning_rate": 0.05972431680305466,
      "loss": 2.7951,
      "step": 250620
    },
    {
      "epoch": 402.96,
      "learning_rate": 0.0597211013721865,
      "loss": 2.7737,
      "step": 250640
    },
    {
      "epoch": 402.99,
      "learning_rate": 0.05971788594131833,
      "loss": 2.7601,
      "step": 250660
    },
    {
      "epoch": 403.0,
      "eval_accuracy": {
        "accuracy": 0.3959418487133639
      },
      "eval_loss": 2.8973402976989746,
      "eval_runtime": 2.9424,
      "eval_samples_per_second": 4371.566,
      "eval_steps_per_second": 68.311,
      "step": 250666
    },
    {
      "epoch": 403.02,
      "learning_rate": 0.059714670510450166,
      "loss": 2.7839,
      "step": 250680
    },
    {
      "epoch": 403.05,
      "learning_rate": 0.059711455079582004,
      "loss": 2.7943,
      "step": 250700
    },
    {
      "epoch": 403.09,
      "learning_rate": 0.05970823964871383,
      "loss": 2.7905,
      "step": 250720
    },
    {
      "epoch": 403.12,
      "learning_rate": 0.05970502421784566,
      "loss": 2.7883,
      "step": 250740
    },
    {
      "epoch": 403.15,
      "learning_rate": 0.059701808786977485,
      "loss": 2.772,
      "step": 250760
    },
    {
      "epoch": 403.18,
      "learning_rate": 0.05969859335610933,
      "loss": 2.7523,
      "step": 250780
    },
    {
      "epoch": 403.22,
      "learning_rate": 0.059695377925241155,
      "loss": 2.8036,
      "step": 250800
    },
    {
      "epoch": 403.25,
      "learning_rate": 0.059692162494372994,
      "loss": 2.7774,
      "step": 250820
    },
    {
      "epoch": 403.28,
      "learning_rate": 0.05968894706350483,
      "loss": 2.8018,
      "step": 250840
    },
    {
      "epoch": 403.31,
      "learning_rate": 0.05968573163263666,
      "loss": 2.8057,
      "step": 250860
    },
    {
      "epoch": 403.34,
      "learning_rate": 0.0596825162017685,
      "loss": 2.7815,
      "step": 250880
    },
    {
      "epoch": 403.38,
      "learning_rate": 0.05967930077090031,
      "loss": 2.7523,
      "step": 250900
    },
    {
      "epoch": 403.41,
      "learning_rate": 0.05967608534003216,
      "loss": 2.7724,
      "step": 250920
    },
    {
      "epoch": 403.44,
      "learning_rate": 0.059672869909163984,
      "loss": 2.7593,
      "step": 250940
    },
    {
      "epoch": 403.47,
      "learning_rate": 0.05966965447829582,
      "loss": 2.7473,
      "step": 250960
    },
    {
      "epoch": 403.5,
      "learning_rate": 0.05966643904742767,
      "loss": 2.7704,
      "step": 250980
    },
    {
      "epoch": 403.54,
      "learning_rate": 0.059663223616559485,
      "loss": 2.7738,
      "step": 251000
    },
    {
      "epoch": 403.57,
      "learning_rate": 0.05966000818569132,
      "loss": 2.7672,
      "step": 251020
    },
    {
      "epoch": 403.6,
      "learning_rate": 0.059656792754823156,
      "loss": 2.7373,
      "step": 251040
    },
    {
      "epoch": 403.63,
      "learning_rate": 0.05965357732395499,
      "loss": 2.7389,
      "step": 251060
    },
    {
      "epoch": 403.67,
      "learning_rate": 0.05965036189308681,
      "loss": 2.7683,
      "step": 251080
    },
    {
      "epoch": 403.7,
      "learning_rate": 0.05964714646221865,
      "loss": 2.7857,
      "step": 251100
    },
    {
      "epoch": 403.73,
      "learning_rate": 0.05964393103135049,
      "loss": 2.7673,
      "step": 251120
    },
    {
      "epoch": 403.76,
      "learning_rate": 0.059640715600482314,
      "loss": 2.761,
      "step": 251140
    },
    {
      "epoch": 403.79,
      "learning_rate": 0.059637500169614145,
      "loss": 2.7457,
      "step": 251160
    },
    {
      "epoch": 403.83,
      "learning_rate": 0.059634284738745984,
      "loss": 2.7503,
      "step": 251180
    },
    {
      "epoch": 403.86,
      "learning_rate": 0.059631069307877815,
      "loss": 2.7829,
      "step": 251200
    },
    {
      "epoch": 403.89,
      "learning_rate": 0.059627853877009654,
      "loss": 2.778,
      "step": 251220
    },
    {
      "epoch": 403.92,
      "learning_rate": 0.05962463844614148,
      "loss": 2.7603,
      "step": 251240
    },
    {
      "epoch": 403.95,
      "learning_rate": 0.05962142301527332,
      "loss": 2.7415,
      "step": 251260
    },
    {
      "epoch": 403.99,
      "learning_rate": 0.05961820758440515,
      "loss": 2.769,
      "step": 251280
    },
    {
      "epoch": 404.0,
      "eval_accuracy": {
        "accuracy": 0.3945424862007308
      },
      "eval_loss": 2.905893087387085,
      "eval_runtime": 2.7181,
      "eval_samples_per_second": 4732.377,
      "eval_steps_per_second": 73.949,
      "step": 251288
    },
    {
      "epoch": 404.02,
      "learning_rate": 0.05961499215353697,
      "loss": 2.7814,
      "step": 251300
    },
    {
      "epoch": 404.05,
      "learning_rate": 0.05961177672266882,
      "loss": 2.7762,
      "step": 251320
    },
    {
      "epoch": 404.08,
      "learning_rate": 0.059608561291800644,
      "loss": 2.76,
      "step": 251340
    },
    {
      "epoch": 404.12,
      "learning_rate": 0.05960534586093248,
      "loss": 2.7715,
      "step": 251360
    },
    {
      "epoch": 404.15,
      "learning_rate": 0.05960213043006432,
      "loss": 2.7517,
      "step": 251380
    },
    {
      "epoch": 404.18,
      "learning_rate": 0.059598914999196145,
      "loss": 2.7704,
      "step": 251400
    },
    {
      "epoch": 404.21,
      "learning_rate": 0.05959569956832798,
      "loss": 2.792,
      "step": 251420
    },
    {
      "epoch": 404.24,
      "learning_rate": 0.0595924841374598,
      "loss": 2.7798,
      "step": 251440
    },
    {
      "epoch": 404.28,
      "learning_rate": 0.05958926870659165,
      "loss": 2.7446,
      "step": 251460
    },
    {
      "epoch": 404.31,
      "learning_rate": 0.05958605327572347,
      "loss": 2.7534,
      "step": 251480
    },
    {
      "epoch": 404.34,
      "learning_rate": 0.05958283784485531,
      "loss": 2.7737,
      "step": 251500
    },
    {
      "epoch": 404.37,
      "learning_rate": 0.05957962241398715,
      "loss": 2.798,
      "step": 251520
    },
    {
      "epoch": 404.41,
      "learning_rate": 0.059576406983118974,
      "loss": 2.7855,
      "step": 251540
    },
    {
      "epoch": 404.44,
      "learning_rate": 0.059573191552250805,
      "loss": 2.8061,
      "step": 251560
    },
    {
      "epoch": 404.47,
      "learning_rate": 0.059570136892926055,
      "loss": 2.7693,
      "step": 251580
    },
    {
      "epoch": 404.5,
      "learning_rate": 0.059566921462057866,
      "loss": 2.7448,
      "step": 251600
    },
    {
      "epoch": 404.53,
      "learning_rate": 0.05956370603118971,
      "loss": 2.7666,
      "step": 251620
    },
    {
      "epoch": 404.57,
      "learning_rate": 0.05956049060032155,
      "loss": 2.7656,
      "step": 251640
    },
    {
      "epoch": 404.6,
      "learning_rate": 0.05955727516945339,
      "loss": 2.7575,
      "step": 251660
    },
    {
      "epoch": 404.63,
      "learning_rate": 0.05955405973858522,
      "loss": 2.7709,
      "step": 251680
    },
    {
      "epoch": 404.66,
      "learning_rate": 0.05955084430771704,
      "loss": 2.769,
      "step": 251700
    },
    {
      "epoch": 404.69,
      "learning_rate": 0.05954762887684888,
      "loss": 2.7662,
      "step": 251720
    },
    {
      "epoch": 404.73,
      "learning_rate": 0.059544413445980715,
      "loss": 2.7901,
      "step": 251740
    },
    {
      "epoch": 404.76,
      "learning_rate": 0.05954119801511254,
      "loss": 2.7536,
      "step": 251760
    },
    {
      "epoch": 404.79,
      "learning_rate": 0.05953798258424438,
      "loss": 2.7711,
      "step": 251780
    },
    {
      "epoch": 404.82,
      "learning_rate": 0.05953476715337622,
      "loss": 2.7754,
      "step": 251800
    },
    {
      "epoch": 404.86,
      "learning_rate": 0.05953155172250805,
      "loss": 2.7452,
      "step": 251820
    },
    {
      "epoch": 404.89,
      "learning_rate": 0.059528336291639866,
      "loss": 2.7704,
      "step": 251840
    },
    {
      "epoch": 404.92,
      "learning_rate": 0.05952512086077171,
      "loss": 2.7755,
      "step": 251860
    },
    {
      "epoch": 404.95,
      "learning_rate": 0.05952190542990354,
      "loss": 2.7918,
      "step": 251880
    },
    {
      "epoch": 404.98,
      "learning_rate": 0.05951868999903537,
      "loss": 2.7635,
      "step": 251900
    },
    {
      "epoch": 405.0,
      "eval_accuracy": {
        "accuracy": 0.3950089403716085
      },
      "eval_loss": 2.926222562789917,
      "eval_runtime": 2.9327,
      "eval_samples_per_second": 4386.106,
      "eval_steps_per_second": 68.538,
      "step": 251910
    },
    {
      "epoch": 405.02,
      "learning_rate": 0.05951547456816722,
      "loss": 2.8096,
      "step": 251920
    },
    {
      "epoch": 405.05,
      "learning_rate": 0.05951225913729903,
      "loss": 2.8168,
      "step": 251940
    },
    {
      "epoch": 405.08,
      "learning_rate": 0.05950904370643088,
      "loss": 2.7781,
      "step": 251960
    },
    {
      "epoch": 405.11,
      "learning_rate": 0.0595058282755627,
      "loss": 2.7805,
      "step": 251980
    },
    {
      "epoch": 405.14,
      "learning_rate": 0.05950261284469454,
      "loss": 2.7638,
      "step": 252000
    },
    {
      "epoch": 405.18,
      "learning_rate": 0.05949939741382637,
      "loss": 2.77,
      "step": 252020
    },
    {
      "epoch": 405.21,
      "learning_rate": 0.059496181982958196,
      "loss": 2.7591,
      "step": 252040
    },
    {
      "epoch": 405.24,
      "learning_rate": 0.05949296655209005,
      "loss": 2.7544,
      "step": 252060
    },
    {
      "epoch": 405.27,
      "learning_rate": 0.05948975112122187,
      "loss": 2.7532,
      "step": 252080
    },
    {
      "epoch": 405.31,
      "learning_rate": 0.059486535690353705,
      "loss": 2.7816,
      "step": 252100
    },
    {
      "epoch": 405.34,
      "learning_rate": 0.05948332025948553,
      "loss": 2.7898,
      "step": 252120
    },
    {
      "epoch": 405.37,
      "learning_rate": 0.059480104828617354,
      "loss": 2.7837,
      "step": 252140
    },
    {
      "epoch": 405.4,
      "learning_rate": 0.0594768893977492,
      "loss": 2.7884,
      "step": 252160
    },
    {
      "epoch": 405.43,
      "learning_rate": 0.059473673966881024,
      "loss": 2.7753,
      "step": 252180
    },
    {
      "epoch": 405.47,
      "learning_rate": 0.05947045853601288,
      "loss": 2.7565,
      "step": 252200
    },
    {
      "epoch": 405.5,
      "learning_rate": 0.0594672431051447,
      "loss": 2.7821,
      "step": 252220
    },
    {
      "epoch": 405.53,
      "learning_rate": 0.059464027674276526,
      "loss": 2.7308,
      "step": 252240
    },
    {
      "epoch": 405.56,
      "learning_rate": 0.05946081224340837,
      "loss": 2.7519,
      "step": 252260
    },
    {
      "epoch": 405.59,
      "learning_rate": 0.05945759681254018,
      "loss": 2.7695,
      "step": 252280
    },
    {
      "epoch": 405.63,
      "learning_rate": 0.05945438138167203,
      "loss": 2.7709,
      "step": 252300
    },
    {
      "epoch": 405.66,
      "learning_rate": 0.059451165950803866,
      "loss": 2.7609,
      "step": 252320
    },
    {
      "epoch": 405.69,
      "learning_rate": 0.05944795051993569,
      "loss": 2.7343,
      "step": 252340
    },
    {
      "epoch": 405.72,
      "learning_rate": 0.05944473508906754,
      "loss": 2.7672,
      "step": 252360
    },
    {
      "epoch": 405.76,
      "learning_rate": 0.059441519658199354,
      "loss": 2.7842,
      "step": 252380
    },
    {
      "epoch": 405.79,
      "learning_rate": 0.0594383042273312,
      "loss": 2.8104,
      "step": 252400
    },
    {
      "epoch": 405.82,
      "learning_rate": 0.05943508879646303,
      "loss": 2.8089,
      "step": 252420
    },
    {
      "epoch": 405.85,
      "learning_rate": 0.059431873365594856,
      "loss": 2.7882,
      "step": 252440
    },
    {
      "epoch": 405.88,
      "learning_rate": 0.05942865793472668,
      "loss": 2.7981,
      "step": 252460
    },
    {
      "epoch": 405.92,
      "learning_rate": 0.05942544250385852,
      "loss": 2.7661,
      "step": 252480
    },
    {
      "epoch": 405.95,
      "learning_rate": 0.059422227072990365,
      "loss": 2.744,
      "step": 252500
    },
    {
      "epoch": 405.98,
      "learning_rate": 0.05941901164212218,
      "loss": 2.7629,
      "step": 252520
    },
    {
      "epoch": 406.0,
      "eval_accuracy": {
        "accuracy": 0.3995179973567597
      },
      "eval_loss": 2.8891191482543945,
      "eval_runtime": 2.8281,
      "eval_samples_per_second": 4548.23,
      "eval_steps_per_second": 71.072,
      "step": 252532
    },
    {
      "epoch": 406.01,
      "learning_rate": 0.05941579621125403,
      "loss": 2.8025,
      "step": 252540
    },
    {
      "epoch": 406.05,
      "learning_rate": 0.05941258078038585,
      "loss": 2.7735,
      "step": 252560
    },
    {
      "epoch": 406.08,
      "learning_rate": 0.059409365349517684,
      "loss": 2.7362,
      "step": 252580
    },
    {
      "epoch": 406.11,
      "learning_rate": 0.05940614991864954,
      "loss": 2.7608,
      "step": 252600
    },
    {
      "epoch": 406.14,
      "learning_rate": 0.05940293448778135,
      "loss": 2.7721,
      "step": 252620
    },
    {
      "epoch": 406.17,
      "learning_rate": 0.05939971905691319,
      "loss": 2.7685,
      "step": 252640
    },
    {
      "epoch": 406.21,
      "learning_rate": 0.05939650362604502,
      "loss": 2.7626,
      "step": 252660
    },
    {
      "epoch": 406.24,
      "learning_rate": 0.05939328819517684,
      "loss": 2.7606,
      "step": 252680
    },
    {
      "epoch": 406.27,
      "learning_rate": 0.05939007276430869,
      "loss": 2.7724,
      "step": 252700
    },
    {
      "epoch": 406.3,
      "learning_rate": 0.05938685733344051,
      "loss": 2.7706,
      "step": 252720
    },
    {
      "epoch": 406.33,
      "learning_rate": 0.059383641902572365,
      "loss": 2.7578,
      "step": 252740
    },
    {
      "epoch": 406.37,
      "learning_rate": 0.05938042647170419,
      "loss": 2.7574,
      "step": 252760
    },
    {
      "epoch": 406.4,
      "learning_rate": 0.059377211040836014,
      "loss": 2.7438,
      "step": 252780
    },
    {
      "epoch": 406.43,
      "learning_rate": 0.059373995609967846,
      "loss": 2.7748,
      "step": 252800
    },
    {
      "epoch": 406.46,
      "learning_rate": 0.05937078017909967,
      "loss": 2.7675,
      "step": 252820
    },
    {
      "epoch": 406.5,
      "learning_rate": 0.059367564748231516,
      "loss": 2.76,
      "step": 252840
    },
    {
      "epoch": 406.53,
      "learning_rate": 0.05936434931736334,
      "loss": 2.7662,
      "step": 252860
    },
    {
      "epoch": 406.56,
      "learning_rate": 0.05936113388649518,
      "loss": 2.7635,
      "step": 252880
    },
    {
      "epoch": 406.59,
      "learning_rate": 0.05935791845562702,
      "loss": 2.7746,
      "step": 252900
    },
    {
      "epoch": 406.62,
      "learning_rate": 0.05935470302475884,
      "loss": 2.7893,
      "step": 252920
    },
    {
      "epoch": 406.66,
      "learning_rate": 0.05935148759389069,
      "loss": 2.7678,
      "step": 252940
    },
    {
      "epoch": 406.69,
      "learning_rate": 0.0593482721630225,
      "loss": 2.7738,
      "step": 252960
    },
    {
      "epoch": 406.72,
      "learning_rate": 0.059345056732154344,
      "loss": 2.7852,
      "step": 252980
    },
    {
      "epoch": 406.75,
      "learning_rate": 0.05934184130128617,
      "loss": 2.7938,
      "step": 253000
    },
    {
      "epoch": 406.78,
      "learning_rate": 0.05933862587041801,
      "loss": 2.7792,
      "step": 253020
    },
    {
      "epoch": 406.82,
      "learning_rate": 0.05933541043954985,
      "loss": 2.7737,
      "step": 253040
    },
    {
      "epoch": 406.85,
      "learning_rate": 0.05933219500868167,
      "loss": 2.7603,
      "step": 253060
    },
    {
      "epoch": 406.88,
      "learning_rate": 0.059328979577813516,
      "loss": 2.7602,
      "step": 253080
    },
    {
      "epoch": 406.91,
      "learning_rate": 0.05932576414694534,
      "loss": 2.785,
      "step": 253100
    },
    {
      "epoch": 406.95,
      "learning_rate": 0.05932254871607717,
      "loss": 2.7676,
      "step": 253120
    },
    {
      "epoch": 406.98,
      "learning_rate": 0.059319333285209,
      "loss": 2.7398,
      "step": 253140
    },
    {
      "epoch": 407.0,
      "eval_accuracy": {
        "accuracy": 0.3966415299696805
      },
      "eval_loss": 2.9142045974731445,
      "eval_runtime": 3.1644,
      "eval_samples_per_second": 4064.967,
      "eval_steps_per_second": 63.52,
      "step": 253154
    },
    {
      "epoch": 407.01,
      "learning_rate": 0.059316117854340836,
      "loss": 2.7677,
      "step": 253160
    },
    {
      "epoch": 407.04,
      "learning_rate": 0.05931290242347268,
      "loss": 2.7764,
      "step": 253180
    },
    {
      "epoch": 407.07,
      "learning_rate": 0.0593096869926045,
      "loss": 2.7678,
      "step": 253200
    },
    {
      "epoch": 407.11,
      "learning_rate": 0.05930647156173633,
      "loss": 2.7686,
      "step": 253220
    },
    {
      "epoch": 407.14,
      "learning_rate": 0.05930325613086817,
      "loss": 2.7663,
      "step": 253240
    },
    {
      "epoch": 407.17,
      "learning_rate": 0.0593000407,
      "loss": 2.759,
      "step": 253260
    },
    {
      "epoch": 407.2,
      "learning_rate": 0.05929682526913185,
      "loss": 2.7772,
      "step": 253280
    },
    {
      "epoch": 407.23,
      "learning_rate": 0.059293609838263664,
      "loss": 2.7648,
      "step": 253300
    },
    {
      "epoch": 407.27,
      "learning_rate": 0.0592903944073955,
      "loss": 2.7673,
      "step": 253320
    },
    {
      "epoch": 407.3,
      "learning_rate": 0.059287178976527334,
      "loss": 2.8029,
      "step": 253340
    },
    {
      "epoch": 407.33,
      "learning_rate": 0.05928396354565916,
      "loss": 2.7882,
      "step": 253360
    },
    {
      "epoch": 407.36,
      "learning_rate": 0.059280748114791004,
      "loss": 2.7552,
      "step": 253380
    },
    {
      "epoch": 407.4,
      "learning_rate": 0.05927753268392283,
      "loss": 2.7705,
      "step": 253400
    },
    {
      "epoch": 407.43,
      "learning_rate": 0.05927431725305467,
      "loss": 2.7552,
      "step": 253420
    },
    {
      "epoch": 407.46,
      "learning_rate": 0.059271101822186506,
      "loss": 2.7354,
      "step": 253440
    },
    {
      "epoch": 407.49,
      "learning_rate": 0.05926788639131833,
      "loss": 2.7524,
      "step": 253460
    },
    {
      "epoch": 407.52,
      "learning_rate": 0.05926467096045016,
      "loss": 2.7734,
      "step": 253480
    },
    {
      "epoch": 407.56,
      "learning_rate": 0.05926145552958199,
      "loss": 2.7901,
      "step": 253500
    },
    {
      "epoch": 407.59,
      "learning_rate": 0.05925824009871383,
      "loss": 2.8113,
      "step": 253520
    },
    {
      "epoch": 407.62,
      "learning_rate": 0.05925502466784566,
      "loss": 2.7926,
      "step": 253540
    },
    {
      "epoch": 407.65,
      "learning_rate": 0.059251809236977496,
      "loss": 2.7623,
      "step": 253560
    },
    {
      "epoch": 407.68,
      "learning_rate": 0.059248593806109334,
      "loss": 2.7691,
      "step": 253580
    },
    {
      "epoch": 407.72,
      "learning_rate": 0.05924537837524116,
      "loss": 2.7628,
      "step": 253600
    },
    {
      "epoch": 407.75,
      "learning_rate": 0.059242162944373004,
      "loss": 2.7709,
      "step": 253620
    },
    {
      "epoch": 407.78,
      "learning_rate": 0.059238947513504815,
      "loss": 2.7683,
      "step": 253640
    },
    {
      "epoch": 407.81,
      "learning_rate": 0.05923573208263666,
      "loss": 2.7836,
      "step": 253660
    },
    {
      "epoch": 407.85,
      "learning_rate": 0.0592326774233119,
      "loss": 2.7658,
      "step": 253680
    },
    {
      "epoch": 407.88,
      "learning_rate": 0.059229461992443735,
      "loss": 2.7529,
      "step": 253700
    },
    {
      "epoch": 407.91,
      "learning_rate": 0.059226246561575574,
      "loss": 2.7802,
      "step": 253720
    },
    {
      "epoch": 407.94,
      "learning_rate": 0.0592230311307074,
      "loss": 2.7796,
      "step": 253740
    },
    {
      "epoch": 407.97,
      "learning_rate": 0.05921981569983923,
      "loss": 2.774,
      "step": 253760
    },
    {
      "epoch": 408.0,
      "eval_accuracy": {
        "accuracy": 0.4030164036383425
      },
      "eval_loss": 2.8736438751220703,
      "eval_runtime": 2.8015,
      "eval_samples_per_second": 4591.39,
      "eval_steps_per_second": 71.746,
      "step": 253776
    },
    {
      "epoch": 408.01,
      "learning_rate": 0.05921660026897107,
      "loss": 2.7846,
      "step": 253780
    },
    {
      "epoch": 408.04,
      "learning_rate": 0.0592133848381029,
      "loss": 2.7531,
      "step": 253800
    },
    {
      "epoch": 408.07,
      "learning_rate": 0.059210169407234725,
      "loss": 2.7509,
      "step": 253820
    },
    {
      "epoch": 408.1,
      "learning_rate": 0.059206953976366564,
      "loss": 2.7709,
      "step": 253840
    },
    {
      "epoch": 408.14,
      "learning_rate": 0.0592037385454984,
      "loss": 2.7435,
      "step": 253860
    },
    {
      "epoch": 408.17,
      "learning_rate": 0.059200523114630234,
      "loss": 2.7715,
      "step": 253880
    },
    {
      "epoch": 408.2,
      "learning_rate": 0.05919730768376205,
      "loss": 2.763,
      "step": 253900
    },
    {
      "epoch": 408.23,
      "learning_rate": 0.0591940922528939,
      "loss": 2.7656,
      "step": 253920
    },
    {
      "epoch": 408.26,
      "learning_rate": 0.05919087682202573,
      "loss": 2.7473,
      "step": 253940
    },
    {
      "epoch": 408.3,
      "learning_rate": 0.05918766139115755,
      "loss": 2.7693,
      "step": 253960
    },
    {
      "epoch": 408.33,
      "learning_rate": 0.059184445960289406,
      "loss": 2.7715,
      "step": 253980
    },
    {
      "epoch": 408.36,
      "learning_rate": 0.05918123052942123,
      "loss": 2.7988,
      "step": 254000
    },
    {
      "epoch": 408.39,
      "learning_rate": 0.05917801509855306,
      "loss": 2.7837,
      "step": 254020
    },
    {
      "epoch": 408.42,
      "learning_rate": 0.05917479966768489,
      "loss": 2.7652,
      "step": 254040
    },
    {
      "epoch": 408.46,
      "learning_rate": 0.059171584236816725,
      "loss": 2.7749,
      "step": 254060
    },
    {
      "epoch": 408.49,
      "learning_rate": 0.05916836880594856,
      "loss": 2.7506,
      "step": 254080
    },
    {
      "epoch": 408.52,
      "learning_rate": 0.05916515337508038,
      "loss": 2.7687,
      "step": 254100
    },
    {
      "epoch": 408.55,
      "learning_rate": 0.059161937944212234,
      "loss": 2.7863,
      "step": 254120
    },
    {
      "epoch": 408.59,
      "learning_rate": 0.05915872251334406,
      "loss": 2.7601,
      "step": 254140
    },
    {
      "epoch": 408.62,
      "learning_rate": 0.05915550708247589,
      "loss": 2.756,
      "step": 254160
    },
    {
      "epoch": 408.65,
      "learning_rate": 0.059152291651607715,
      "loss": 2.7796,
      "step": 254180
    },
    {
      "epoch": 408.68,
      "learning_rate": 0.05914907622073955,
      "loss": 2.778,
      "step": 254200
    },
    {
      "epoch": 408.71,
      "learning_rate": 0.059145860789871385,
      "loss": 2.7934,
      "step": 254220
    },
    {
      "epoch": 408.75,
      "learning_rate": 0.05914264535900321,
      "loss": 2.7815,
      "step": 254240
    },
    {
      "epoch": 408.78,
      "learning_rate": 0.05913942992813506,
      "loss": 2.7628,
      "step": 254260
    },
    {
      "epoch": 408.81,
      "learning_rate": 0.05913621449726689,
      "loss": 2.7706,
      "step": 254280
    },
    {
      "epoch": 408.84,
      "learning_rate": 0.05913299906639872,
      "loss": 2.7651,
      "step": 254300
    },
    {
      "epoch": 408.87,
      "learning_rate": 0.05912978363553056,
      "loss": 2.7888,
      "step": 254320
    },
    {
      "epoch": 408.91,
      "learning_rate": 0.05912656820466237,
      "loss": 2.7549,
      "step": 254340
    },
    {
      "epoch": 408.94,
      "learning_rate": 0.05912335277379421,
      "loss": 2.7677,
      "step": 254360
    },
    {
      "epoch": 408.97,
      "learning_rate": 0.05912013734292605,
      "loss": 2.7724,
      "step": 254380
    },
    {
      "epoch": 409.0,
      "eval_accuracy": {
        "accuracy": 0.4025499494674648
      },
      "eval_loss": 2.8456716537475586,
      "eval_runtime": 2.8051,
      "eval_samples_per_second": 4585.594,
      "eval_steps_per_second": 71.655,
      "step": 254398
    },
    {
      "epoch": 409.0,
      "learning_rate": 0.05911692191205789,
      "loss": 2.7581,
      "step": 254400
    },
    {
      "epoch": 409.04,
      "learning_rate": 0.05911370648118972,
      "loss": 2.7643,
      "step": 254420
    },
    {
      "epoch": 409.07,
      "learning_rate": 0.05911049105032154,
      "loss": 2.7696,
      "step": 254440
    },
    {
      "epoch": 409.1,
      "learning_rate": 0.059107275619453385,
      "loss": 2.7786,
      "step": 254460
    },
    {
      "epoch": 409.13,
      "learning_rate": 0.05910406018858522,
      "loss": 2.7472,
      "step": 254480
    },
    {
      "epoch": 409.16,
      "learning_rate": 0.05910084475771704,
      "loss": 2.7622,
      "step": 254500
    },
    {
      "epoch": 409.2,
      "learning_rate": 0.05909762932684888,
      "loss": 2.7692,
      "step": 254520
    },
    {
      "epoch": 409.23,
      "learning_rate": 0.059094413895980705,
      "loss": 2.7702,
      "step": 254540
    },
    {
      "epoch": 409.26,
      "learning_rate": 0.05909119846511255,
      "loss": 2.7747,
      "step": 254560
    },
    {
      "epoch": 409.29,
      "learning_rate": 0.05908798303424437,
      "loss": 2.7581,
      "step": 254580
    },
    {
      "epoch": 409.32,
      "learning_rate": 0.05908476760337621,
      "loss": 2.7452,
      "step": 254600
    },
    {
      "epoch": 409.36,
      "learning_rate": 0.059081552172508045,
      "loss": 2.7772,
      "step": 254620
    },
    {
      "epoch": 409.39,
      "learning_rate": 0.05907833674163987,
      "loss": 2.7659,
      "step": 254640
    },
    {
      "epoch": 409.42,
      "learning_rate": 0.05907512131077172,
      "loss": 2.7768,
      "step": 254660
    },
    {
      "epoch": 409.45,
      "learning_rate": 0.05907190587990353,
      "loss": 2.7802,
      "step": 254680
    },
    {
      "epoch": 409.49,
      "learning_rate": 0.05906869044903538,
      "loss": 2.7579,
      "step": 254700
    },
    {
      "epoch": 409.52,
      "learning_rate": 0.0590654750181672,
      "loss": 2.7677,
      "step": 254720
    },
    {
      "epoch": 409.55,
      "learning_rate": 0.05906225958729904,
      "loss": 2.7344,
      "step": 254740
    },
    {
      "epoch": 409.58,
      "learning_rate": 0.05905904415643087,
      "loss": 2.8001,
      "step": 254760
    },
    {
      "epoch": 409.61,
      "learning_rate": 0.0590558287255627,
      "loss": 2.7709,
      "step": 254780
    },
    {
      "epoch": 409.65,
      "learning_rate": 0.05905261329469455,
      "loss": 2.7849,
      "step": 254800
    },
    {
      "epoch": 409.68,
      "learning_rate": 0.059049397863826375,
      "loss": 2.7708,
      "step": 254820
    },
    {
      "epoch": 409.71,
      "learning_rate": 0.05904618243295821,
      "loss": 2.7942,
      "step": 254840
    },
    {
      "epoch": 409.74,
      "learning_rate": 0.05904296700209003,
      "loss": 2.7733,
      "step": 254860
    },
    {
      "epoch": 409.77,
      "learning_rate": 0.059039751571221856,
      "loss": 2.7706,
      "step": 254880
    },
    {
      "epoch": 409.81,
      "learning_rate": 0.0590365361403537,
      "loss": 2.8036,
      "step": 254900
    },
    {
      "epoch": 409.84,
      "learning_rate": 0.059033320709485526,
      "loss": 2.7842,
      "step": 254920
    },
    {
      "epoch": 409.87,
      "learning_rate": 0.05903010527861738,
      "loss": 2.7712,
      "step": 254940
    },
    {
      "epoch": 409.9,
      "learning_rate": 0.0590268898477492,
      "loss": 2.7961,
      "step": 254960
    },
    {
      "epoch": 409.94,
      "learning_rate": 0.05902367441688103,
      "loss": 2.7953,
      "step": 254980
    },
    {
      "epoch": 409.97,
      "learning_rate": 0.05902045898601287,
      "loss": 2.7941,
      "step": 255000
    },
    {
      "epoch": 410.0,
      "learning_rate": 0.059017243555144684,
      "loss": 2.7723,
      "step": 255020
    },
    {
      "epoch": 410.0,
      "eval_accuracy": {
        "accuracy": 0.4044935085127886
      },
      "eval_loss": 2.8496408462524414,
      "eval_runtime": 2.8568,
      "eval_samples_per_second": 4502.538,
      "eval_steps_per_second": 70.358,
      "step": 255020
    },
    {
      "epoch": 410.03,
      "learning_rate": 0.05901402812427653,
      "loss": 2.7525,
      "step": 255040
    },
    {
      "epoch": 410.06,
      "learning_rate": 0.05901081269340837,
      "loss": 2.7709,
      "step": 255060
    },
    {
      "epoch": 410.1,
      "learning_rate": 0.05900759726254019,
      "loss": 2.7664,
      "step": 255080
    },
    {
      "epoch": 410.13,
      "learning_rate": 0.05900438183167204,
      "loss": 2.7549,
      "step": 255100
    },
    {
      "epoch": 410.16,
      "learning_rate": 0.059001166400803856,
      "loss": 2.7604,
      "step": 255120
    },
    {
      "epoch": 410.19,
      "learning_rate": 0.0589979509699357,
      "loss": 2.7452,
      "step": 255140
    },
    {
      "epoch": 410.23,
      "learning_rate": 0.05899473553906753,
      "loss": 2.7457,
      "step": 255160
    },
    {
      "epoch": 410.26,
      "learning_rate": 0.05899152010819936,
      "loss": 2.791,
      "step": 255180
    },
    {
      "epoch": 410.29,
      "learning_rate": 0.05898830467733118,
      "loss": 2.7598,
      "step": 255200
    },
    {
      "epoch": 410.32,
      "learning_rate": 0.05898508924646302,
      "loss": 2.7422,
      "step": 255220
    },
    {
      "epoch": 410.35,
      "learning_rate": 0.05898187381559487,
      "loss": 2.7581,
      "step": 255240
    },
    {
      "epoch": 410.39,
      "learning_rate": 0.058978658384726684,
      "loss": 2.7765,
      "step": 255260
    },
    {
      "epoch": 410.42,
      "learning_rate": 0.05897544295385853,
      "loss": 2.7645,
      "step": 255280
    },
    {
      "epoch": 410.45,
      "learning_rate": 0.058972227522990354,
      "loss": 2.7806,
      "step": 255300
    },
    {
      "epoch": 410.48,
      "learning_rate": 0.058969012092122186,
      "loss": 2.7592,
      "step": 255320
    },
    {
      "epoch": 410.51,
      "learning_rate": 0.05896579666125404,
      "loss": 2.7539,
      "step": 255340
    },
    {
      "epoch": 410.55,
      "learning_rate": 0.05896258123038585,
      "loss": 2.7744,
      "step": 255360
    },
    {
      "epoch": 410.58,
      "learning_rate": 0.058959365799517695,
      "loss": 2.7787,
      "step": 255380
    },
    {
      "epoch": 410.61,
      "learning_rate": 0.05895615036864952,
      "loss": 2.7509,
      "step": 255400
    },
    {
      "epoch": 410.64,
      "learning_rate": 0.058952934937781344,
      "loss": 2.7514,
      "step": 255420
    },
    {
      "epoch": 410.68,
      "learning_rate": 0.05894971950691319,
      "loss": 2.7558,
      "step": 255440
    },
    {
      "epoch": 410.71,
      "learning_rate": 0.058946504076045014,
      "loss": 2.7567,
      "step": 255460
    },
    {
      "epoch": 410.74,
      "learning_rate": 0.05894328864517687,
      "loss": 2.7424,
      "step": 255480
    },
    {
      "epoch": 410.77,
      "learning_rate": 0.05894007321430869,
      "loss": 2.7558,
      "step": 255500
    },
    {
      "epoch": 410.8,
      "learning_rate": 0.058936857783440516,
      "loss": 2.763,
      "step": 255520
    },
    {
      "epoch": 410.84,
      "learning_rate": 0.05893364235257235,
      "loss": 2.7564,
      "step": 255540
    },
    {
      "epoch": 410.87,
      "learning_rate": 0.05893042692170417,
      "loss": 2.7871,
      "step": 255560
    },
    {
      "epoch": 410.9,
      "learning_rate": 0.05892721149083602,
      "loss": 2.7837,
      "step": 255580
    },
    {
      "epoch": 410.93,
      "learning_rate": 0.05892399605996784,
      "loss": 2.7805,
      "step": 255600
    },
    {
      "epoch": 410.96,
      "learning_rate": 0.05892078062909968,
      "loss": 2.7568,
      "step": 255620
    },
    {
      "epoch": 411.0,
      "learning_rate": 0.05891756519823152,
      "loss": 2.7771,
      "step": 255640
    },
    {
      "epoch": 411.0,
      "eval_accuracy": {
        "accuracy": 0.4089248231361269
      },
      "eval_loss": 2.8400111198425293,
      "eval_runtime": 2.9247,
      "eval_samples_per_second": 4398.02,
      "eval_steps_per_second": 68.724,
      "step": 255642
    },
    {
      "epoch": 411.03,
      "learning_rate": 0.058914349767363344,
      "loss": 2.7598,
      "step": 255660
    },
    {
      "epoch": 411.06,
      "learning_rate": 0.05891113433649519,
      "loss": 2.774,
      "step": 255680
    },
    {
      "epoch": 411.09,
      "learning_rate": 0.058907918905627,
      "loss": 2.7767,
      "step": 255700
    },
    {
      "epoch": 411.13,
      "learning_rate": 0.058904703474758846,
      "loss": 2.799,
      "step": 255720
    },
    {
      "epoch": 411.16,
      "learning_rate": 0.05890148804389067,
      "loss": 2.7587,
      "step": 255740
    },
    {
      "epoch": 411.19,
      "learning_rate": 0.05889827261302251,
      "loss": 2.7712,
      "step": 255760
    },
    {
      "epoch": 411.22,
      "learning_rate": 0.058895057182154355,
      "loss": 2.7451,
      "step": 255780
    },
    {
      "epoch": 411.25,
      "learning_rate": 0.05889184175128617,
      "loss": 2.742,
      "step": 255800
    },
    {
      "epoch": 411.29,
      "learning_rate": 0.05888862632041802,
      "loss": 2.7834,
      "step": 255820
    },
    {
      "epoch": 411.32,
      "learning_rate": 0.05888541088954984,
      "loss": 2.777,
      "step": 255840
    },
    {
      "epoch": 411.35,
      "learning_rate": 0.058882195458681674,
      "loss": 2.7807,
      "step": 255860
    },
    {
      "epoch": 411.38,
      "learning_rate": 0.0588789800278135,
      "loss": 2.7668,
      "step": 255880
    },
    {
      "epoch": 411.41,
      "learning_rate": 0.05887576459694534,
      "loss": 2.7896,
      "step": 255900
    },
    {
      "epoch": 411.45,
      "learning_rate": 0.05887254916607718,
      "loss": 2.7445,
      "step": 255920
    },
    {
      "epoch": 411.48,
      "learning_rate": 0.058869333735209,
      "loss": 2.7578,
      "step": 255940
    },
    {
      "epoch": 411.51,
      "learning_rate": 0.058866279075884244,
      "loss": 2.7559,
      "step": 255960
    },
    {
      "epoch": 411.54,
      "learning_rate": 0.05886306364501608,
      "loss": 2.7573,
      "step": 255980
    },
    {
      "epoch": 411.58,
      "learning_rate": 0.058859848214147914,
      "loss": 2.7813,
      "step": 256000
    },
    {
      "epoch": 411.61,
      "learning_rate": 0.05885663278327974,
      "loss": 2.7724,
      "step": 256020
    },
    {
      "epoch": 411.64,
      "learning_rate": 0.05885341735241159,
      "loss": 2.7874,
      "step": 256040
    },
    {
      "epoch": 411.67,
      "learning_rate": 0.058850201921543416,
      "loss": 2.763,
      "step": 256060
    },
    {
      "epoch": 411.7,
      "learning_rate": 0.05884698649067525,
      "loss": 2.7681,
      "step": 256080
    },
    {
      "epoch": 411.74,
      "learning_rate": 0.05884377105980707,
      "loss": 2.7576,
      "step": 256100
    },
    {
      "epoch": 411.77,
      "learning_rate": 0.05884055562893891,
      "loss": 2.7579,
      "step": 256120
    },
    {
      "epoch": 411.8,
      "learning_rate": 0.05883734019807074,
      "loss": 2.7644,
      "step": 256140
    },
    {
      "epoch": 411.83,
      "learning_rate": 0.05883412476720257,
      "loss": 2.755,
      "step": 256160
    },
    {
      "epoch": 411.86,
      "learning_rate": 0.05883090933633442,
      "loss": 2.8018,
      "step": 256180
    },
    {
      "epoch": 411.9,
      "learning_rate": 0.058827693905466244,
      "loss": 2.767,
      "step": 256200
    },
    {
      "epoch": 411.93,
      "learning_rate": 0.058824478474598076,
      "loss": 2.7585,
      "step": 256220
    },
    {
      "epoch": 411.96,
      "learning_rate": 0.0588212630437299,
      "loss": 2.7726,
      "step": 256240
    },
    {
      "epoch": 411.99,
      "learning_rate": 0.05881804761286174,
      "loss": 2.7344,
      "step": 256260
    },
    {
      "epoch": 412.0,
      "eval_accuracy": {
        "accuracy": 0.402238980020213
      },
      "eval_loss": 2.8763515949249268,
      "eval_runtime": 3.2104,
      "eval_samples_per_second": 4006.642,
      "eval_steps_per_second": 62.609,
      "step": 256264
    },
    {
      "epoch": 412.03,
      "learning_rate": 0.05881483218199357,
      "loss": 2.7716,
      "step": 256280
    },
    {
      "epoch": 412.06,
      "learning_rate": 0.058811616751125395,
      "loss": 2.7753,
      "step": 256300
    },
    {
      "epoch": 412.09,
      "learning_rate": 0.05880840132025725,
      "loss": 2.7666,
      "step": 256320
    },
    {
      "epoch": 412.12,
      "learning_rate": 0.05880518588938907,
      "loss": 2.7485,
      "step": 256340
    },
    {
      "epoch": 412.15,
      "learning_rate": 0.058801970458520904,
      "loss": 2.7924,
      "step": 256360
    },
    {
      "epoch": 412.19,
      "learning_rate": 0.05879875502765274,
      "loss": 2.7599,
      "step": 256380
    },
    {
      "epoch": 412.22,
      "learning_rate": 0.05879553959678457,
      "loss": 2.7752,
      "step": 256400
    },
    {
      "epoch": 412.25,
      "learning_rate": 0.0587923241659164,
      "loss": 2.7955,
      "step": 256420
    },
    {
      "epoch": 412.28,
      "learning_rate": 0.05878910873504824,
      "loss": 2.7442,
      "step": 256440
    },
    {
      "epoch": 412.32,
      "learning_rate": 0.058785893304180076,
      "loss": 2.7676,
      "step": 256460
    },
    {
      "epoch": 412.35,
      "learning_rate": 0.05878267787331191,
      "loss": 2.7864,
      "step": 256480
    },
    {
      "epoch": 412.38,
      "learning_rate": 0.05877946244244373,
      "loss": 2.7564,
      "step": 256500
    },
    {
      "epoch": 412.41,
      "learning_rate": 0.05877624701157557,
      "loss": 2.7499,
      "step": 256520
    },
    {
      "epoch": 412.44,
      "learning_rate": 0.0587730315807074,
      "loss": 2.7699,
      "step": 256540
    },
    {
      "epoch": 412.48,
      "learning_rate": 0.05876981614983923,
      "loss": 2.7507,
      "step": 256560
    },
    {
      "epoch": 412.51,
      "learning_rate": 0.058766600718971065,
      "loss": 2.7462,
      "step": 256580
    },
    {
      "epoch": 412.54,
      "learning_rate": 0.058763385288102904,
      "loss": 2.7587,
      "step": 256600
    },
    {
      "epoch": 412.57,
      "learning_rate": 0.058760169857234736,
      "loss": 2.7538,
      "step": 256620
    },
    {
      "epoch": 412.6,
      "learning_rate": 0.05875695442636655,
      "loss": 2.7583,
      "step": 256640
    },
    {
      "epoch": 412.64,
      "learning_rate": 0.0587537389954984,
      "loss": 2.759,
      "step": 256660
    },
    {
      "epoch": 412.67,
      "learning_rate": 0.05875052356463023,
      "loss": 2.7871,
      "step": 256680
    },
    {
      "epoch": 412.7,
      "learning_rate": 0.058747308133762055,
      "loss": 2.7783,
      "step": 256700
    },
    {
      "epoch": 412.73,
      "learning_rate": 0.05874409270289391,
      "loss": 2.799,
      "step": 256720
    },
    {
      "epoch": 412.77,
      "learning_rate": 0.05874087727202572,
      "loss": 2.7621,
      "step": 256740
    },
    {
      "epoch": 412.8,
      "learning_rate": 0.058737661841157564,
      "loss": 2.7719,
      "step": 256760
    },
    {
      "epoch": 412.83,
      "learning_rate": 0.05873444641028939,
      "loss": 2.7417,
      "step": 256780
    },
    {
      "epoch": 412.86,
      "learning_rate": 0.05873123097942123,
      "loss": 2.7773,
      "step": 256800
    },
    {
      "epoch": 412.89,
      "learning_rate": 0.05872801554855306,
      "loss": 2.7622,
      "step": 256820
    },
    {
      "epoch": 412.93,
      "learning_rate": 0.05872480011768488,
      "loss": 2.7911,
      "step": 256840
    },
    {
      "epoch": 412.96,
      "learning_rate": 0.058721584686816736,
      "loss": 2.7869,
      "step": 256860
    },
    {
      "epoch": 412.99,
      "learning_rate": 0.05871836925594856,
      "loss": 2.7602,
      "step": 256880
    },
    {
      "epoch": 413.0,
      "eval_accuracy": {
        "accuracy": 0.402238980020213
      },
      "eval_loss": 2.8676342964172363,
      "eval_runtime": 2.7961,
      "eval_samples_per_second": 4600.326,
      "eval_steps_per_second": 71.886,
      "step": 256886
    },
    {
      "epoch": 413.02,
      "learning_rate": 0.05871515382508039,
      "loss": 2.7637,
      "step": 256900
    },
    {
      "epoch": 413.05,
      "learning_rate": 0.05871193839421222,
      "loss": 2.7614,
      "step": 256920
    },
    {
      "epoch": 413.09,
      "learning_rate": 0.058708722963344055,
      "loss": 2.7747,
      "step": 256940
    },
    {
      "epoch": 413.12,
      "learning_rate": 0.05870550753247589,
      "loss": 2.7456,
      "step": 256960
    },
    {
      "epoch": 413.15,
      "learning_rate": 0.05870229210160771,
      "loss": 2.7521,
      "step": 256980
    },
    {
      "epoch": 413.18,
      "learning_rate": 0.058699076670739564,
      "loss": 2.7546,
      "step": 257000
    },
    {
      "epoch": 413.22,
      "learning_rate": 0.05869586123987139,
      "loss": 2.7267,
      "step": 257020
    },
    {
      "epoch": 413.25,
      "learning_rate": 0.05869264580900322,
      "loss": 2.7563,
      "step": 257040
    },
    {
      "epoch": 413.28,
      "learning_rate": 0.05868943037813506,
      "loss": 2.7676,
      "step": 257060
    },
    {
      "epoch": 413.31,
      "learning_rate": 0.05868621494726687,
      "loss": 2.7809,
      "step": 257080
    },
    {
      "epoch": 413.34,
      "learning_rate": 0.058682999516398715,
      "loss": 2.7824,
      "step": 257100
    },
    {
      "epoch": 413.38,
      "learning_rate": 0.058679784085530554,
      "loss": 2.7677,
      "step": 257120
    },
    {
      "epoch": 413.41,
      "learning_rate": 0.05867656865466239,
      "loss": 2.7431,
      "step": 257140
    },
    {
      "epoch": 413.44,
      "learning_rate": 0.058673353223794224,
      "loss": 2.7524,
      "step": 257160
    },
    {
      "epoch": 413.47,
      "learning_rate": 0.05867013779292604,
      "loss": 2.7723,
      "step": 257180
    },
    {
      "epoch": 413.5,
      "learning_rate": 0.05866692236205789,
      "loss": 2.7643,
      "step": 257200
    },
    {
      "epoch": 413.54,
      "learning_rate": 0.05866370693118972,
      "loss": 2.7702,
      "step": 257220
    },
    {
      "epoch": 413.57,
      "learning_rate": 0.05866049150032154,
      "loss": 2.7614,
      "step": 257240
    },
    {
      "epoch": 413.6,
      "learning_rate": 0.05865727606945338,
      "loss": 2.7806,
      "step": 257260
    },
    {
      "epoch": 413.63,
      "learning_rate": 0.058654060638585206,
      "loss": 2.773,
      "step": 257280
    },
    {
      "epoch": 413.67,
      "learning_rate": 0.05865084520771705,
      "loss": 2.774,
      "step": 257300
    },
    {
      "epoch": 413.7,
      "learning_rate": 0.05864762977684887,
      "loss": 2.7479,
      "step": 257320
    },
    {
      "epoch": 413.73,
      "learning_rate": 0.058644414345980715,
      "loss": 2.7629,
      "step": 257340
    },
    {
      "epoch": 413.76,
      "learning_rate": 0.05864119891511255,
      "loss": 2.7707,
      "step": 257360
    },
    {
      "epoch": 413.79,
      "learning_rate": 0.05863798348424437,
      "loss": 2.7664,
      "step": 257380
    },
    {
      "epoch": 413.83,
      "learning_rate": 0.058634768053376224,
      "loss": 2.7521,
      "step": 257400
    },
    {
      "epoch": 413.86,
      "learning_rate": 0.058631552622508035,
      "loss": 2.7691,
      "step": 257420
    },
    {
      "epoch": 413.89,
      "learning_rate": 0.05862833719163988,
      "loss": 2.7296,
      "step": 257440
    },
    {
      "epoch": 413.92,
      "learning_rate": 0.058625121760771705,
      "loss": 2.7342,
      "step": 257460
    },
    {
      "epoch": 413.95,
      "learning_rate": 0.05862190632990354,
      "loss": 2.711,
      "step": 257480
    },
    {
      "epoch": 413.99,
      "learning_rate": 0.058618690899035375,
      "loss": 2.7355,
      "step": 257500
    },
    {
      "epoch": 414.0,
      "eval_accuracy": {
        "accuracy": 0.39283215424084583
      },
      "eval_loss": 2.8738183975219727,
      "eval_runtime": 2.6902,
      "eval_samples_per_second": 4781.517,
      "eval_steps_per_second": 74.717,
      "step": 257508
    },
    {
      "epoch": 414.02,
      "learning_rate": 0.0586154754681672,
      "loss": 2.7757,
      "step": 257520
    },
    {
      "epoch": 414.05,
      "learning_rate": 0.05861226003729905,
      "loss": 2.7581,
      "step": 257540
    },
    {
      "epoch": 414.08,
      "learning_rate": 0.05860904460643088,
      "loss": 2.7635,
      "step": 257560
    },
    {
      "epoch": 414.12,
      "learning_rate": 0.05860582917556271,
      "loss": 2.759,
      "step": 257580
    },
    {
      "epoch": 414.15,
      "learning_rate": 0.05860261374469453,
      "loss": 2.7675,
      "step": 257600
    },
    {
      "epoch": 414.18,
      "learning_rate": 0.05859939831382636,
      "loss": 2.7617,
      "step": 257620
    },
    {
      "epoch": 414.21,
      "learning_rate": 0.0585961828829582,
      "loss": 2.7571,
      "step": 257640
    },
    {
      "epoch": 414.24,
      "learning_rate": 0.05859296745209003,
      "loss": 2.7502,
      "step": 257660
    },
    {
      "epoch": 414.28,
      "learning_rate": 0.05858975202122188,
      "loss": 2.7544,
      "step": 257680
    },
    {
      "epoch": 414.31,
      "learning_rate": 0.058586536590353705,
      "loss": 2.7584,
      "step": 257700
    },
    {
      "epoch": 414.34,
      "learning_rate": 0.05858332115948553,
      "loss": 2.7985,
      "step": 257720
    },
    {
      "epoch": 414.37,
      "learning_rate": 0.058580105728617375,
      "loss": 2.786,
      "step": 257740
    },
    {
      "epoch": 414.41,
      "learning_rate": 0.058576890297749186,
      "loss": 2.7808,
      "step": 257760
    },
    {
      "epoch": 414.44,
      "learning_rate": 0.05857367486688103,
      "loss": 2.7724,
      "step": 257780
    },
    {
      "epoch": 414.47,
      "learning_rate": 0.05857045943601287,
      "loss": 2.7351,
      "step": 257800
    },
    {
      "epoch": 414.5,
      "learning_rate": 0.058567244005144695,
      "loss": 2.7669,
      "step": 257820
    },
    {
      "epoch": 414.53,
      "learning_rate": 0.05856402857427654,
      "loss": 2.7649,
      "step": 257840
    },
    {
      "epoch": 414.57,
      "learning_rate": 0.05856081314340836,
      "loss": 2.7743,
      "step": 257860
    },
    {
      "epoch": 414.6,
      "learning_rate": 0.0585575977125402,
      "loss": 2.7706,
      "step": 257880
    },
    {
      "epoch": 414.63,
      "learning_rate": 0.058554382281672035,
      "loss": 2.7917,
      "step": 257900
    },
    {
      "epoch": 414.66,
      "learning_rate": 0.05855116685080386,
      "loss": 2.7875,
      "step": 257920
    },
    {
      "epoch": 414.69,
      "learning_rate": 0.058547951419935684,
      "loss": 2.74,
      "step": 257940
    },
    {
      "epoch": 414.73,
      "learning_rate": 0.05854473598906752,
      "loss": 2.764,
      "step": 257960
    },
    {
      "epoch": 414.76,
      "learning_rate": 0.05854152055819937,
      "loss": 2.746,
      "step": 257980
    },
    {
      "epoch": 414.79,
      "learning_rate": 0.058538465898874605,
      "loss": 2.7663,
      "step": 258000
    },
    {
      "epoch": 414.82,
      "learning_rate": 0.05853525046800643,
      "loss": 2.7245,
      "step": 258020
    },
    {
      "epoch": 414.86,
      "learning_rate": 0.05853203503713827,
      "loss": 2.7254,
      "step": 258040
    },
    {
      "epoch": 414.89,
      "learning_rate": 0.0585288196062701,
      "loss": 2.7706,
      "step": 258060
    },
    {
      "epoch": 414.92,
      "learning_rate": 0.058525604175401924,
      "loss": 2.7414,
      "step": 258080
    },
    {
      "epoch": 414.95,
      "learning_rate": 0.058522388744533776,
      "loss": 2.7515,
      "step": 258100
    },
    {
      "epoch": 414.98,
      "learning_rate": 0.0585191733136656,
      "loss": 2.749,
      "step": 258120
    },
    {
      "epoch": 415.0,
      "eval_accuracy": {
        "accuracy": 0.39508668273342146
      },
      "eval_loss": 2.8978071212768555,
      "eval_runtime": 3.0326,
      "eval_samples_per_second": 4241.512,
      "eval_steps_per_second": 66.279,
      "step": 258130
    },
    {
      "epoch": 415.02,
      "learning_rate": 0.05851595788279743,
      "loss": 2.7764,
      "step": 258140
    },
    {
      "epoch": 415.05,
      "learning_rate": 0.05851274245192926,
      "loss": 2.7611,
      "step": 258160
    },
    {
      "epoch": 415.08,
      "learning_rate": 0.058509527021061096,
      "loss": 2.7401,
      "step": 258180
    },
    {
      "epoch": 415.11,
      "learning_rate": 0.05850631159019293,
      "loss": 2.7706,
      "step": 258200
    },
    {
      "epoch": 415.14,
      "learning_rate": 0.05850309615932475,
      "loss": 2.7572,
      "step": 258220
    },
    {
      "epoch": 415.18,
      "learning_rate": 0.058499880728456605,
      "loss": 2.7599,
      "step": 258240
    },
    {
      "epoch": 415.21,
      "learning_rate": 0.05849666529758843,
      "loss": 2.7735,
      "step": 258260
    },
    {
      "epoch": 415.24,
      "learning_rate": 0.05849344986672026,
      "loss": 2.7732,
      "step": 258280
    },
    {
      "epoch": 415.27,
      "learning_rate": 0.058490234435852086,
      "loss": 2.7542,
      "step": 258300
    },
    {
      "epoch": 415.31,
      "learning_rate": 0.058487019004983924,
      "loss": 2.7524,
      "step": 258320
    },
    {
      "epoch": 415.34,
      "learning_rate": 0.058483803574115756,
      "loss": 2.8001,
      "step": 258340
    },
    {
      "epoch": 415.37,
      "learning_rate": 0.05848058814324758,
      "loss": 2.755,
      "step": 258360
    },
    {
      "epoch": 415.4,
      "learning_rate": 0.05847737271237943,
      "loss": 2.7788,
      "step": 258380
    },
    {
      "epoch": 415.43,
      "learning_rate": 0.05847415728151126,
      "loss": 2.7834,
      "step": 258400
    },
    {
      "epoch": 415.47,
      "learning_rate": 0.05847094185064309,
      "loss": 2.7609,
      "step": 258420
    },
    {
      "epoch": 415.5,
      "learning_rate": 0.058467726419774935,
      "loss": 2.7711,
      "step": 258440
    },
    {
      "epoch": 415.53,
      "learning_rate": 0.05846451098890675,
      "loss": 2.7983,
      "step": 258460
    },
    {
      "epoch": 415.56,
      "learning_rate": 0.058461295558038584,
      "loss": 2.7714,
      "step": 258480
    },
    {
      "epoch": 415.59,
      "learning_rate": 0.05845808012717042,
      "loss": 2.7707,
      "step": 258500
    },
    {
      "epoch": 415.63,
      "learning_rate": 0.05845486469630226,
      "loss": 2.7589,
      "step": 258520
    },
    {
      "epoch": 415.66,
      "learning_rate": 0.058451649265434086,
      "loss": 2.7694,
      "step": 258540
    },
    {
      "epoch": 415.69,
      "learning_rate": 0.05844843383456592,
      "loss": 2.7561,
      "step": 258560
    },
    {
      "epoch": 415.72,
      "learning_rate": 0.058445218403697756,
      "loss": 2.7803,
      "step": 258580
    },
    {
      "epoch": 415.76,
      "learning_rate": 0.05844200297282959,
      "loss": 2.7357,
      "step": 258600
    },
    {
      "epoch": 415.79,
      "learning_rate": 0.05843878754196141,
      "loss": 2.7646,
      "step": 258620
    },
    {
      "epoch": 415.82,
      "learning_rate": 0.05843557211109325,
      "loss": 2.7679,
      "step": 258640
    },
    {
      "epoch": 415.85,
      "learning_rate": 0.05843235668022509,
      "loss": 2.7711,
      "step": 258660
    },
    {
      "epoch": 415.88,
      "learning_rate": 0.05842914124935692,
      "loss": 2.7337,
      "step": 258680
    },
    {
      "epoch": 415.92,
      "learning_rate": 0.058425925818488746,
      "loss": 2.7658,
      "step": 258700
    },
    {
      "epoch": 415.95,
      "learning_rate": 0.058422710387620584,
      "loss": 2.7603,
      "step": 258720
    },
    {
      "epoch": 415.98,
      "learning_rate": 0.058419494956752416,
      "loss": 2.7685,
      "step": 258740
    },
    {
      "epoch": 416.0,
      "eval_accuracy": {
        "accuracy": 0.3966415299696805
      },
      "eval_loss": 2.869671583175659,
      "eval_runtime": 2.7495,
      "eval_samples_per_second": 4678.346,
      "eval_steps_per_second": 73.105,
      "step": 258752
    },
    {
      "epoch": 416.01,
      "learning_rate": 0.05841627952588424,
      "loss": 2.7611,
      "step": 258760
    },
    {
      "epoch": 416.05,
      "learning_rate": 0.05841306409501609,
      "loss": 2.7436,
      "step": 258780
    },
    {
      "epoch": 416.08,
      "learning_rate": 0.05840984866414792,
      "loss": 2.7764,
      "step": 258800
    },
    {
      "epoch": 416.11,
      "learning_rate": 0.05840663323327975,
      "loss": 2.7653,
      "step": 258820
    },
    {
      "epoch": 416.14,
      "learning_rate": 0.058403417802411574,
      "loss": 2.7687,
      "step": 258840
    },
    {
      "epoch": 416.17,
      "learning_rate": 0.05840020237154341,
      "loss": 2.7384,
      "step": 258860
    },
    {
      "epoch": 416.21,
      "learning_rate": 0.058396986940675244,
      "loss": 2.7677,
      "step": 258880
    },
    {
      "epoch": 416.24,
      "learning_rate": 0.05839377150980707,
      "loss": 2.7727,
      "step": 258900
    },
    {
      "epoch": 416.27,
      "learning_rate": 0.05839055607893892,
      "loss": 2.7726,
      "step": 258920
    },
    {
      "epoch": 416.3,
      "learning_rate": 0.058387340648070746,
      "loss": 2.7479,
      "step": 258940
    },
    {
      "epoch": 416.33,
      "learning_rate": 0.05838412521720258,
      "loss": 2.7463,
      "step": 258960
    },
    {
      "epoch": 416.37,
      "learning_rate": 0.0583809097863344,
      "loss": 2.7529,
      "step": 258980
    },
    {
      "epoch": 416.4,
      "learning_rate": 0.05837769435546624,
      "loss": 2.7383,
      "step": 259000
    },
    {
      "epoch": 416.43,
      "learning_rate": 0.05837447892459807,
      "loss": 2.7965,
      "step": 259020
    },
    {
      "epoch": 416.46,
      "learning_rate": 0.0583712634937299,
      "loss": 2.7485,
      "step": 259040
    },
    {
      "epoch": 416.5,
      "learning_rate": 0.05836804806286175,
      "loss": 2.7717,
      "step": 259060
    },
    {
      "epoch": 416.53,
      "learning_rate": 0.058364832631993574,
      "loss": 2.764,
      "step": 259080
    },
    {
      "epoch": 416.56,
      "learning_rate": 0.058361617201125406,
      "loss": 2.759,
      "step": 259100
    },
    {
      "epoch": 416.59,
      "learning_rate": 0.058358401770257244,
      "loss": 2.8047,
      "step": 259120
    },
    {
      "epoch": 416.62,
      "learning_rate": 0.05835518633938907,
      "loss": 2.7482,
      "step": 259140
    },
    {
      "epoch": 416.66,
      "learning_rate": 0.0583519709085209,
      "loss": 2.7481,
      "step": 259160
    },
    {
      "epoch": 416.69,
      "learning_rate": 0.05834875547765274,
      "loss": 2.7382,
      "step": 259180
    },
    {
      "epoch": 416.72,
      "learning_rate": 0.05834554004678458,
      "loss": 2.7405,
      "step": 259200
    },
    {
      "epoch": 416.75,
      "learning_rate": 0.05834232461591641,
      "loss": 2.7465,
      "step": 259220
    },
    {
      "epoch": 416.78,
      "learning_rate": 0.058339109185048234,
      "loss": 2.7667,
      "step": 259240
    },
    {
      "epoch": 416.82,
      "learning_rate": 0.05833589375418007,
      "loss": 2.7751,
      "step": 259260
    },
    {
      "epoch": 416.85,
      "learning_rate": 0.058332678323311904,
      "loss": 2.7645,
      "step": 259280
    },
    {
      "epoch": 416.88,
      "learning_rate": 0.05832946289244373,
      "loss": 2.7585,
      "step": 259300
    },
    {
      "epoch": 416.91,
      "learning_rate": 0.05832624746157557,
      "loss": 2.7548,
      "step": 259320
    },
    {
      "epoch": 416.95,
      "learning_rate": 0.058323032030707406,
      "loss": 2.7682,
      "step": 259340
    },
    {
      "epoch": 416.98,
      "learning_rate": 0.05831981659983924,
      "loss": 2.7684,
      "step": 259360
    },
    {
      "epoch": 417.0,
      "eval_accuracy": {
        "accuracy": 0.39671927233149346
      },
      "eval_loss": 2.8989293575286865,
      "eval_runtime": 3.1566,
      "eval_samples_per_second": 4074.969,
      "eval_steps_per_second": 63.676,
      "step": 259374
    },
    {
      "epoch": 417.01,
      "learning_rate": 0.058316601168971055,
      "loss": 2.7942,
      "step": 259380
    },
    {
      "epoch": 417.04,
      "learning_rate": 0.0583133857381029,
      "loss": 2.7754,
      "step": 259400
    },
    {
      "epoch": 417.07,
      "learning_rate": 0.05831017030723473,
      "loss": 2.7437,
      "step": 259420
    },
    {
      "epoch": 417.11,
      "learning_rate": 0.05830695487636656,
      "loss": 2.7589,
      "step": 259440
    },
    {
      "epoch": 417.14,
      "learning_rate": 0.05830373944549841,
      "loss": 2.7679,
      "step": 259460
    },
    {
      "epoch": 417.17,
      "learning_rate": 0.05830052401463022,
      "loss": 2.7715,
      "step": 259480
    },
    {
      "epoch": 417.2,
      "learning_rate": 0.058297308583762066,
      "loss": 2.7496,
      "step": 259500
    },
    {
      "epoch": 417.23,
      "learning_rate": 0.05829409315289389,
      "loss": 2.7527,
      "step": 259520
    },
    {
      "epoch": 417.27,
      "learning_rate": 0.05829087772202573,
      "loss": 2.7436,
      "step": 259540
    },
    {
      "epoch": 417.3,
      "learning_rate": 0.05828766229115756,
      "loss": 2.7286,
      "step": 259560
    },
    {
      "epoch": 417.33,
      "learning_rate": 0.058284446860289385,
      "loss": 2.7586,
      "step": 259580
    },
    {
      "epoch": 417.36,
      "learning_rate": 0.05828123142942124,
      "loss": 2.7759,
      "step": 259600
    },
    {
      "epoch": 417.4,
      "learning_rate": 0.05827801599855306,
      "loss": 2.7495,
      "step": 259620
    },
    {
      "epoch": 417.43,
      "learning_rate": 0.058274800567684894,
      "loss": 2.7726,
      "step": 259640
    },
    {
      "epoch": 417.46,
      "learning_rate": 0.05827158513681672,
      "loss": 2.7615,
      "step": 259660
    },
    {
      "epoch": 417.49,
      "learning_rate": 0.05826836970594856,
      "loss": 2.7755,
      "step": 259680
    },
    {
      "epoch": 417.52,
      "learning_rate": 0.05826515427508039,
      "loss": 2.7884,
      "step": 259700
    },
    {
      "epoch": 417.56,
      "learning_rate": 0.05826193884421221,
      "loss": 2.7838,
      "step": 259720
    },
    {
      "epoch": 417.59,
      "learning_rate": 0.058258723413344066,
      "loss": 2.765,
      "step": 259740
    },
    {
      "epoch": 417.62,
      "learning_rate": 0.05825550798247589,
      "loss": 2.7789,
      "step": 259760
    },
    {
      "epoch": 417.65,
      "learning_rate": 0.05825229255160772,
      "loss": 2.7445,
      "step": 259780
    },
    {
      "epoch": 417.68,
      "learning_rate": 0.05824907712073956,
      "loss": 2.762,
      "step": 259800
    },
    {
      "epoch": 417.72,
      "learning_rate": 0.05824586168987137,
      "loss": 2.7663,
      "step": 259820
    },
    {
      "epoch": 417.75,
      "learning_rate": 0.05824264625900322,
      "loss": 2.7906,
      "step": 259840
    },
    {
      "epoch": 417.78,
      "learning_rate": 0.058239430828135055,
      "loss": 2.7701,
      "step": 259860
    },
    {
      "epoch": 417.81,
      "learning_rate": 0.058236215397266894,
      "loss": 2.767,
      "step": 259880
    },
    {
      "epoch": 417.85,
      "learning_rate": 0.058232999966398725,
      "loss": 2.7634,
      "step": 259900
    },
    {
      "epoch": 417.88,
      "learning_rate": 0.05822978453553054,
      "loss": 2.7473,
      "step": 259920
    },
    {
      "epoch": 417.91,
      "learning_rate": 0.05822656910466239,
      "loss": 2.7577,
      "step": 259940
    },
    {
      "epoch": 417.94,
      "learning_rate": 0.05822335367379422,
      "loss": 2.8021,
      "step": 259960
    },
    {
      "epoch": 417.97,
      "learning_rate": 0.058220138242926045,
      "loss": 2.783,
      "step": 259980
    },
    {
      "epoch": 418.0,
      "eval_accuracy": {
        "accuracy": 0.3977299230350618
      },
      "eval_loss": 2.8736164569854736,
      "eval_runtime": 2.9003,
      "eval_samples_per_second": 4434.995,
      "eval_steps_per_second": 69.302,
      "step": 259996
    },
    {
      "epoch": 418.01,
      "learning_rate": 0.058216922812057884,
      "loss": 2.7578,
      "step": 260000
    },
    {
      "epoch": 418.04,
      "learning_rate": 0.05821370738118971,
      "loss": 2.7194,
      "step": 260020
    },
    {
      "epoch": 418.07,
      "learning_rate": 0.058210491950321554,
      "loss": 2.743,
      "step": 260040
    },
    {
      "epoch": 418.1,
      "learning_rate": 0.05820727651945337,
      "loss": 2.7361,
      "step": 260060
    },
    {
      "epoch": 418.14,
      "learning_rate": 0.05820406108858522,
      "loss": 2.7514,
      "step": 260080
    },
    {
      "epoch": 418.17,
      "learning_rate": 0.05820084565771705,
      "loss": 2.784,
      "step": 260100
    },
    {
      "epoch": 418.2,
      "learning_rate": 0.05819763022684887,
      "loss": 2.7511,
      "step": 260120
    },
    {
      "epoch": 418.23,
      "learning_rate": 0.058194414795980726,
      "loss": 2.7511,
      "step": 260140
    },
    {
      "epoch": 418.26,
      "learning_rate": 0.058191199365112536,
      "loss": 2.7538,
      "step": 260160
    },
    {
      "epoch": 418.3,
      "learning_rate": 0.05818798393424438,
      "loss": 2.7221,
      "step": 260180
    },
    {
      "epoch": 418.33,
      "learning_rate": 0.05818492927491962,
      "loss": 2.7423,
      "step": 260200
    },
    {
      "epoch": 418.36,
      "learning_rate": 0.05818171384405144,
      "loss": 2.7921,
      "step": 260220
    },
    {
      "epoch": 418.39,
      "learning_rate": 0.05817849841318328,
      "loss": 2.7778,
      "step": 260240
    },
    {
      "epoch": 418.42,
      "learning_rate": 0.05817528298231511,
      "loss": 2.7713,
      "step": 260260
    },
    {
      "epoch": 418.46,
      "learning_rate": 0.05817206755144694,
      "loss": 2.7834,
      "step": 260280
    },
    {
      "epoch": 418.49,
      "learning_rate": 0.05816885212057879,
      "loss": 2.7724,
      "step": 260300
    },
    {
      "epoch": 418.52,
      "learning_rate": 0.058165636689710615,
      "loss": 2.7517,
      "step": 260320
    },
    {
      "epoch": 418.55,
      "learning_rate": 0.058162421258842446,
      "loss": 2.7564,
      "step": 260340
    },
    {
      "epoch": 418.59,
      "learning_rate": 0.05815920582797427,
      "loss": 2.7638,
      "step": 260360
    },
    {
      "epoch": 418.62,
      "learning_rate": 0.05815599039710611,
      "loss": 2.7519,
      "step": 260380
    },
    {
      "epoch": 418.65,
      "learning_rate": 0.058152774966237955,
      "loss": 2.7534,
      "step": 260400
    },
    {
      "epoch": 418.68,
      "learning_rate": 0.058149559535369766,
      "loss": 2.7811,
      "step": 260420
    },
    {
      "epoch": 418.71,
      "learning_rate": 0.05814634410450162,
      "loss": 2.7408,
      "step": 260440
    },
    {
      "epoch": 418.75,
      "learning_rate": 0.05814312867363344,
      "loss": 2.7548,
      "step": 260460
    },
    {
      "epoch": 418.78,
      "learning_rate": 0.058139913242765275,
      "loss": 2.7614,
      "step": 260480
    },
    {
      "epoch": 418.81,
      "learning_rate": 0.05813669781189712,
      "loss": 2.7816,
      "step": 260500
    },
    {
      "epoch": 418.84,
      "learning_rate": 0.05813348238102894,
      "loss": 2.7329,
      "step": 260520
    },
    {
      "epoch": 418.87,
      "learning_rate": 0.05813026695016077,
      "loss": 2.7356,
      "step": 260540
    },
    {
      "epoch": 418.91,
      "learning_rate": 0.05812705151929261,
      "loss": 2.7449,
      "step": 260560
    },
    {
      "epoch": 418.94,
      "learning_rate": 0.058123836088424446,
      "loss": 2.7385,
      "step": 260580
    },
    {
      "epoch": 418.97,
      "learning_rate": 0.05812062065755627,
      "loss": 2.7758,
      "step": 260600
    },
    {
      "epoch": 419.0,
      "eval_accuracy": {
        "accuracy": 0.40006219388945036
      },
      "eval_loss": 2.8849971294403076,
      "eval_runtime": 3.1764,
      "eval_samples_per_second": 4049.544,
      "eval_steps_per_second": 63.279,
      "step": 260618
    },
    {
      "epoch": 419.0,
      "learning_rate": 0.0581174052266881,
      "loss": 2.7483,
      "step": 260620
    },
    {
      "epoch": 419.04,
      "learning_rate": 0.05811418979581995,
      "loss": 2.7572,
      "step": 260640
    },
    {
      "epoch": 419.07,
      "learning_rate": 0.058110974364951766,
      "loss": 2.7505,
      "step": 260660
    },
    {
      "epoch": 419.1,
      "learning_rate": 0.0581077589340836,
      "loss": 2.7542,
      "step": 260680
    },
    {
      "epoch": 419.13,
      "learning_rate": 0.058104543503215436,
      "loss": 2.747,
      "step": 260700
    },
    {
      "epoch": 419.16,
      "learning_rate": 0.058101328072347275,
      "loss": 2.7468,
      "step": 260720
    },
    {
      "epoch": 419.2,
      "learning_rate": 0.058098112641479106,
      "loss": 2.7447,
      "step": 260740
    },
    {
      "epoch": 419.23,
      "learning_rate": 0.05809489721061093,
      "loss": 2.7186,
      "step": 260760
    },
    {
      "epoch": 419.26,
      "learning_rate": 0.05809168177974277,
      "loss": 2.7696,
      "step": 260780
    },
    {
      "epoch": 419.29,
      "learning_rate": 0.0580884663488746,
      "loss": 2.778,
      "step": 260800
    },
    {
      "epoch": 419.32,
      "learning_rate": 0.058085250918006426,
      "loss": 2.7514,
      "step": 260820
    },
    {
      "epoch": 419.36,
      "learning_rate": 0.05808203548713828,
      "loss": 2.7508,
      "step": 260840
    },
    {
      "epoch": 419.39,
      "learning_rate": 0.0580788200562701,
      "loss": 2.7388,
      "step": 260860
    },
    {
      "epoch": 419.42,
      "learning_rate": 0.058075604625401935,
      "loss": 2.7547,
      "step": 260880
    },
    {
      "epoch": 419.45,
      "learning_rate": 0.05807238919453376,
      "loss": 2.8046,
      "step": 260900
    },
    {
      "epoch": 419.49,
      "learning_rate": 0.0580691737636656,
      "loss": 2.7545,
      "step": 260920
    },
    {
      "epoch": 419.52,
      "learning_rate": 0.05806595833279743,
      "loss": 2.7601,
      "step": 260940
    },
    {
      "epoch": 419.55,
      "learning_rate": 0.058062742901929254,
      "loss": 2.7572,
      "step": 260960
    },
    {
      "epoch": 419.58,
      "learning_rate": 0.058059527471061106,
      "loss": 2.7588,
      "step": 260980
    },
    {
      "epoch": 419.61,
      "learning_rate": 0.05805631204019293,
      "loss": 2.7609,
      "step": 261000
    },
    {
      "epoch": 419.65,
      "learning_rate": 0.05805309660932476,
      "loss": 2.759,
      "step": 261020
    },
    {
      "epoch": 419.68,
      "learning_rate": 0.05804988117845659,
      "loss": 2.7746,
      "step": 261040
    },
    {
      "epoch": 419.71,
      "learning_rate": 0.058046665747588426,
      "loss": 2.7565,
      "step": 261060
    },
    {
      "epoch": 419.74,
      "learning_rate": 0.05804345031672026,
      "loss": 2.7673,
      "step": 261080
    },
    {
      "epoch": 419.77,
      "learning_rate": 0.05804023488585208,
      "loss": 2.7279,
      "step": 261100
    },
    {
      "epoch": 419.81,
      "learning_rate": 0.058037019454983935,
      "loss": 2.7599,
      "step": 261120
    },
    {
      "epoch": 419.84,
      "learning_rate": 0.05803380402411576,
      "loss": 2.7715,
      "step": 261140
    },
    {
      "epoch": 419.87,
      "learning_rate": 0.05803058859324759,
      "loss": 2.7649,
      "step": 261160
    },
    {
      "epoch": 419.9,
      "learning_rate": 0.05802737316237943,
      "loss": 2.7495,
      "step": 261180
    },
    {
      "epoch": 419.94,
      "learning_rate": 0.058024157731511254,
      "loss": 2.7525,
      "step": 261200
    },
    {
      "epoch": 419.97,
      "learning_rate": 0.058020942300643086,
      "loss": 2.7503,
      "step": 261220
    },
    {
      "epoch": 420.0,
      "learning_rate": 0.058017726869774924,
      "loss": 2.766,
      "step": 261240
    },
    {
      "epoch": 420.0,
      "eval_accuracy": {
        "accuracy": 0.40410479670372385
      },
      "eval_loss": 2.880328416824341,
      "eval_runtime": 3.2031,
      "eval_samples_per_second": 4015.841,
      "eval_steps_per_second": 62.752,
      "step": 261240
    },
    {
      "epoch": 420.03,
      "learning_rate": 0.05801451143890676,
      "loss": 2.761,
      "step": 261260
    },
    {
      "epoch": 420.06,
      "learning_rate": 0.05801129600803859,
      "loss": 2.7627,
      "step": 261280
    },
    {
      "epoch": 420.1,
      "learning_rate": 0.05800808057717042,
      "loss": 2.7541,
      "step": 261300
    },
    {
      "epoch": 420.13,
      "learning_rate": 0.05800486514630226,
      "loss": 2.7444,
      "step": 261320
    },
    {
      "epoch": 420.16,
      "learning_rate": 0.05800164971543409,
      "loss": 2.7565,
      "step": 261340
    },
    {
      "epoch": 420.19,
      "learning_rate": 0.057998434284565914,
      "loss": 2.7528,
      "step": 261360
    },
    {
      "epoch": 420.23,
      "learning_rate": 0.05799521885369775,
      "loss": 2.7373,
      "step": 261380
    },
    {
      "epoch": 420.26,
      "learning_rate": 0.05799200342282959,
      "loss": 2.7605,
      "step": 261400
    },
    {
      "epoch": 420.29,
      "learning_rate": 0.05798878799196142,
      "loss": 2.7474,
      "step": 261420
    },
    {
      "epoch": 420.32,
      "learning_rate": 0.05798557256109325,
      "loss": 2.758,
      "step": 261440
    },
    {
      "epoch": 420.35,
      "learning_rate": 0.057982357130225086,
      "loss": 2.7545,
      "step": 261460
    },
    {
      "epoch": 420.39,
      "learning_rate": 0.05797914169935692,
      "loss": 2.7434,
      "step": 261480
    },
    {
      "epoch": 420.42,
      "learning_rate": 0.05797592626848874,
      "loss": 2.7343,
      "step": 261500
    },
    {
      "epoch": 420.45,
      "learning_rate": 0.057972710837620595,
      "loss": 2.7817,
      "step": 261520
    },
    {
      "epoch": 420.48,
      "learning_rate": 0.05796949540675242,
      "loss": 2.7556,
      "step": 261540
    },
    {
      "epoch": 420.51,
      "learning_rate": 0.05796627997588425,
      "loss": 2.7508,
      "step": 261560
    },
    {
      "epoch": 420.55,
      "learning_rate": 0.057963064545016076,
      "loss": 2.731,
      "step": 261580
    },
    {
      "epoch": 420.58,
      "learning_rate": 0.057959849114147914,
      "loss": 2.7326,
      "step": 261600
    },
    {
      "epoch": 420.61,
      "learning_rate": 0.057956633683279746,
      "loss": 2.7464,
      "step": 261620
    },
    {
      "epoch": 420.64,
      "learning_rate": 0.05795341825241157,
      "loss": 2.7873,
      "step": 261640
    },
    {
      "epoch": 420.68,
      "learning_rate": 0.05795020282154342,
      "loss": 2.7631,
      "step": 261660
    },
    {
      "epoch": 420.71,
      "learning_rate": 0.05794698739067525,
      "loss": 2.7754,
      "step": 261680
    },
    {
      "epoch": 420.74,
      "learning_rate": 0.05794377195980708,
      "loss": 2.709,
      "step": 261700
    },
    {
      "epoch": 420.77,
      "learning_rate": 0.057940556528938904,
      "loss": 2.7355,
      "step": 261720
    },
    {
      "epoch": 420.8,
      "learning_rate": 0.05793734109807074,
      "loss": 2.76,
      "step": 261740
    },
    {
      "epoch": 420.84,
      "learning_rate": 0.057934125667202574,
      "loss": 2.7524,
      "step": 261760
    },
    {
      "epoch": 420.87,
      "learning_rate": 0.0579309102363344,
      "loss": 2.7687,
      "step": 261780
    },
    {
      "epoch": 420.9,
      "learning_rate": 0.05792769480546625,
      "loss": 2.7698,
      "step": 261800
    },
    {
      "epoch": 420.93,
      "learning_rate": 0.057924479374598076,
      "loss": 2.7805,
      "step": 261820
    },
    {
      "epoch": 420.96,
      "learning_rate": 0.05792126394372991,
      "loss": 2.7544,
      "step": 261840
    },
    {
      "epoch": 421.0,
      "learning_rate": 0.057918048512861746,
      "loss": 2.7618,
      "step": 261860
    },
    {
      "epoch": 421.0,
      "eval_accuracy": {
        "accuracy": 0.4004509056985151
      },
      "eval_loss": 2.867936611175537,
      "eval_runtime": 2.8363,
      "eval_samples_per_second": 4535.205,
      "eval_steps_per_second": 70.868,
      "step": 261862
    },
    {
      "epoch": 421.03,
      "learning_rate": 0.05791483308199357,
      "loss": 2.7629,
      "step": 261880
    },
    {
      "epoch": 421.06,
      "learning_rate": 0.0579116176511254,
      "loss": 2.7665,
      "step": 261900
    },
    {
      "epoch": 421.09,
      "learning_rate": 0.05790840222025724,
      "loss": 2.7566,
      "step": 261920
    },
    {
      "epoch": 421.13,
      "learning_rate": 0.05790518678938908,
      "loss": 2.7637,
      "step": 261940
    },
    {
      "epoch": 421.16,
      "learning_rate": 0.05790197135852091,
      "loss": 2.7395,
      "step": 261960
    },
    {
      "epoch": 421.19,
      "learning_rate": 0.057898755927652736,
      "loss": 2.7445,
      "step": 261980
    },
    {
      "epoch": 421.22,
      "learning_rate": 0.057895540496784574,
      "loss": 2.7342,
      "step": 262000
    },
    {
      "epoch": 421.25,
      "learning_rate": 0.057892325065916406,
      "loss": 2.7765,
      "step": 262020
    },
    {
      "epoch": 421.29,
      "learning_rate": 0.05788910963504823,
      "loss": 2.779,
      "step": 262040
    },
    {
      "epoch": 421.32,
      "learning_rate": 0.05788589420418007,
      "loss": 2.7404,
      "step": 262060
    },
    {
      "epoch": 421.35,
      "learning_rate": 0.05788267877331191,
      "loss": 2.7558,
      "step": 262080
    },
    {
      "epoch": 421.38,
      "learning_rate": 0.05787946334244374,
      "loss": 2.7219,
      "step": 262100
    },
    {
      "epoch": 421.41,
      "learning_rate": 0.05787624791157556,
      "loss": 2.7719,
      "step": 262120
    },
    {
      "epoch": 421.45,
      "learning_rate": 0.0578730324807074,
      "loss": 2.7438,
      "step": 262140
    },
    {
      "epoch": 421.48,
      "learning_rate": 0.057869817049839234,
      "loss": 2.7424,
      "step": 262160
    },
    {
      "epoch": 421.51,
      "learning_rate": 0.05786660161897106,
      "loss": 2.7394,
      "step": 262180
    },
    {
      "epoch": 421.54,
      "learning_rate": 0.05786338618810291,
      "loss": 2.753,
      "step": 262200
    },
    {
      "epoch": 421.58,
      "learning_rate": 0.05786017075723472,
      "loss": 2.7778,
      "step": 262220
    },
    {
      "epoch": 421.61,
      "learning_rate": 0.05785695532636657,
      "loss": 2.7646,
      "step": 262240
    },
    {
      "epoch": 421.64,
      "learning_rate": 0.05785373989549839,
      "loss": 2.7569,
      "step": 262260
    },
    {
      "epoch": 421.67,
      "learning_rate": 0.05785052446463023,
      "loss": 2.7896,
      "step": 262280
    },
    {
      "epoch": 421.7,
      "learning_rate": 0.05784730903376206,
      "loss": 2.7631,
      "step": 262300
    },
    {
      "epoch": 421.74,
      "learning_rate": 0.0578442543744373,
      "loss": 2.7531,
      "step": 262320
    },
    {
      "epoch": 421.77,
      "learning_rate": 0.05784103894356912,
      "loss": 2.7367,
      "step": 262340
    },
    {
      "epoch": 421.8,
      "learning_rate": 0.057837823512700975,
      "loss": 2.7732,
      "step": 262360
    },
    {
      "epoch": 421.83,
      "learning_rate": 0.0578346080818328,
      "loss": 2.754,
      "step": 262380
    },
    {
      "epoch": 421.86,
      "learning_rate": 0.05783139265096463,
      "loss": 2.7804,
      "step": 262400
    },
    {
      "epoch": 421.9,
      "learning_rate": 0.057828177220096456,
      "loss": 2.7728,
      "step": 262420
    },
    {
      "epoch": 421.93,
      "learning_rate": 0.057824961789228295,
      "loss": 2.7442,
      "step": 262440
    },
    {
      "epoch": 421.96,
      "learning_rate": 0.05782174635836014,
      "loss": 2.7503,
      "step": 262460
    },
    {
      "epoch": 421.99,
      "learning_rate": 0.05781853092749195,
      "loss": 2.7468,
      "step": 262480
    },
    {
      "epoch": 422.0,
      "eval_accuracy": {
        "accuracy": 0.39990670916582444
      },
      "eval_loss": 2.88454532623291,
      "eval_runtime": 3.2497,
      "eval_samples_per_second": 3958.177,
      "eval_steps_per_second": 61.851,
      "step": 262484
    },
    {
      "epoch": 422.03,
      "learning_rate": 0.057815315496623804,
      "loss": 2.7677,
      "step": 262500
    },
    {
      "epoch": 422.06,
      "learning_rate": 0.057812100065755635,
      "loss": 2.7651,
      "step": 262520
    },
    {
      "epoch": 422.09,
      "learning_rate": 0.05780888463488746,
      "loss": 2.7555,
      "step": 262540
    },
    {
      "epoch": 422.12,
      "learning_rate": 0.057805669204019305,
      "loss": 2.7552,
      "step": 262560
    },
    {
      "epoch": 422.15,
      "learning_rate": 0.05780245377315112,
      "loss": 2.7363,
      "step": 262580
    },
    {
      "epoch": 422.19,
      "learning_rate": 0.05779923834228297,
      "loss": 2.7307,
      "step": 262600
    },
    {
      "epoch": 422.22,
      "learning_rate": 0.05779602291141481,
      "loss": 2.7629,
      "step": 262620
    },
    {
      "epoch": 422.25,
      "learning_rate": 0.05779280748054663,
      "loss": 2.7614,
      "step": 262640
    },
    {
      "epoch": 422.28,
      "learning_rate": 0.05778959204967846,
      "loss": 2.7412,
      "step": 262660
    },
    {
      "epoch": 422.32,
      "learning_rate": 0.05778637661881029,
      "loss": 2.7284,
      "step": 262680
    },
    {
      "epoch": 422.35,
      "learning_rate": 0.057783161187942134,
      "loss": 2.7425,
      "step": 262700
    },
    {
      "epoch": 422.38,
      "learning_rate": 0.05777994575707395,
      "loss": 2.7166,
      "step": 262720
    },
    {
      "epoch": 422.41,
      "learning_rate": 0.05777673032620578,
      "loss": 2.7567,
      "step": 262740
    },
    {
      "epoch": 422.44,
      "learning_rate": 0.05777351489533762,
      "loss": 2.7468,
      "step": 262760
    },
    {
      "epoch": 422.48,
      "learning_rate": 0.05777029946446946,
      "loss": 2.7731,
      "step": 262780
    },
    {
      "epoch": 422.51,
      "learning_rate": 0.05776708403360129,
      "loss": 2.7717,
      "step": 262800
    },
    {
      "epoch": 422.54,
      "learning_rate": 0.057763868602733116,
      "loss": 2.7636,
      "step": 262820
    },
    {
      "epoch": 422.57,
      "learning_rate": 0.05776065317186496,
      "loss": 2.7451,
      "step": 262840
    },
    {
      "epoch": 422.6,
      "learning_rate": 0.057757437740996787,
      "loss": 2.7697,
      "step": 262860
    },
    {
      "epoch": 422.64,
      "learning_rate": 0.05775422231012861,
      "loss": 2.7644,
      "step": 262880
    },
    {
      "epoch": 422.67,
      "learning_rate": 0.057751006879260464,
      "loss": 2.7664,
      "step": 262900
    },
    {
      "epoch": 422.7,
      "learning_rate": 0.05774779144839229,
      "loss": 2.759,
      "step": 262920
    },
    {
      "epoch": 422.73,
      "learning_rate": 0.05774457601752412,
      "loss": 2.7513,
      "step": 262940
    },
    {
      "epoch": 422.77,
      "learning_rate": 0.057741360586655945,
      "loss": 2.7645,
      "step": 262960
    },
    {
      "epoch": 422.8,
      "learning_rate": 0.05773814515578778,
      "loss": 2.7593,
      "step": 262980
    },
    {
      "epoch": 422.83,
      "learning_rate": 0.057734929724919615,
      "loss": 2.7658,
      "step": 263000
    },
    {
      "epoch": 422.86,
      "learning_rate": 0.05773171429405144,
      "loss": 2.7772,
      "step": 263020
    },
    {
      "epoch": 422.89,
      "learning_rate": 0.05772849886318329,
      "loss": 2.7832,
      "step": 263040
    },
    {
      "epoch": 422.93,
      "learning_rate": 0.057725283432315116,
      "loss": 2.7446,
      "step": 263060
    },
    {
      "epoch": 422.96,
      "learning_rate": 0.05772206800144695,
      "loss": 2.7725,
      "step": 263080
    },
    {
      "epoch": 422.99,
      "learning_rate": 0.05771885257057877,
      "loss": 2.7443,
      "step": 263100
    },
    {
      "epoch": 423.0,
      "eval_accuracy": {
        "accuracy": 0.41133483635232837
      },
      "eval_loss": 2.829509735107422,
      "eval_runtime": 2.8365,
      "eval_samples_per_second": 4534.763,
      "eval_steps_per_second": 70.861,
      "step": 263106
    },
    {
      "epoch": 423.02,
      "learning_rate": 0.05771563713971061,
      "loss": 2.743,
      "step": 263120
    },
    {
      "epoch": 423.05,
      "learning_rate": 0.05771242170884246,
      "loss": 2.7322,
      "step": 263140
    },
    {
      "epoch": 423.09,
      "learning_rate": 0.05770920627797427,
      "loss": 2.7878,
      "step": 263160
    },
    {
      "epoch": 423.12,
      "learning_rate": 0.05770599084710612,
      "loss": 2.7454,
      "step": 263180
    },
    {
      "epoch": 423.15,
      "learning_rate": 0.057702775416237945,
      "loss": 2.7555,
      "step": 263200
    },
    {
      "epoch": 423.18,
      "learning_rate": 0.057699559985369776,
      "loss": 2.7522,
      "step": 263220
    },
    {
      "epoch": 423.22,
      "learning_rate": 0.05769634455450162,
      "loss": 2.7943,
      "step": 263240
    },
    {
      "epoch": 423.25,
      "learning_rate": 0.05769312912363344,
      "loss": 2.7317,
      "step": 263260
    },
    {
      "epoch": 423.28,
      "learning_rate": 0.05768991369276527,
      "loss": 2.7577,
      "step": 263280
    },
    {
      "epoch": 423.31,
      "learning_rate": 0.05768669826189711,
      "loss": 2.7551,
      "step": 263300
    },
    {
      "epoch": 423.34,
      "learning_rate": 0.05768348283102895,
      "loss": 2.7556,
      "step": 263320
    },
    {
      "epoch": 423.38,
      "learning_rate": 0.05768026740016077,
      "loss": 2.748,
      "step": 263340
    },
    {
      "epoch": 423.41,
      "learning_rate": 0.057677051969292605,
      "loss": 2.7396,
      "step": 263360
    },
    {
      "epoch": 423.44,
      "learning_rate": 0.05767383653842444,
      "loss": 2.7582,
      "step": 263380
    },
    {
      "epoch": 423.47,
      "learning_rate": 0.057670621107556275,
      "loss": 2.7363,
      "step": 263400
    },
    {
      "epoch": 423.5,
      "learning_rate": 0.0576674056766881,
      "loss": 2.7279,
      "step": 263420
    },
    {
      "epoch": 423.54,
      "learning_rate": 0.05766419024581994,
      "loss": 2.7402,
      "step": 263440
    },
    {
      "epoch": 423.57,
      "learning_rate": 0.057660974814951776,
      "loss": 2.7588,
      "step": 263460
    },
    {
      "epoch": 423.6,
      "learning_rate": 0.05765775938408361,
      "loss": 2.7527,
      "step": 263480
    },
    {
      "epoch": 423.63,
      "learning_rate": 0.05765454395321543,
      "loss": 2.7328,
      "step": 263500
    },
    {
      "epoch": 423.67,
      "learning_rate": 0.05765132852234727,
      "loss": 2.7718,
      "step": 263520
    },
    {
      "epoch": 423.7,
      "learning_rate": 0.0576481130914791,
      "loss": 2.787,
      "step": 263540
    },
    {
      "epoch": 423.73,
      "learning_rate": 0.05764489766061093,
      "loss": 2.7592,
      "step": 263560
    },
    {
      "epoch": 423.76,
      "learning_rate": 0.05764168222974278,
      "loss": 2.7516,
      "step": 263580
    },
    {
      "epoch": 423.79,
      "learning_rate": 0.057638466798874605,
      "loss": 2.7614,
      "step": 263600
    },
    {
      "epoch": 423.83,
      "learning_rate": 0.057635251368006436,
      "loss": 2.7647,
      "step": 263620
    },
    {
      "epoch": 423.86,
      "learning_rate": 0.05763203593713826,
      "loss": 2.7318,
      "step": 263640
    },
    {
      "epoch": 423.89,
      "learning_rate": 0.0576288205062701,
      "loss": 2.7475,
      "step": 263660
    },
    {
      "epoch": 423.92,
      "learning_rate": 0.05762560507540193,
      "loss": 2.775,
      "step": 263680
    },
    {
      "epoch": 423.95,
      "learning_rate": 0.057622389644533756,
      "loss": 2.7633,
      "step": 263700
    },
    {
      "epoch": 423.99,
      "learning_rate": 0.05761917421366561,
      "loss": 2.762,
      "step": 263720
    },
    {
      "epoch": 424.0,
      "eval_accuracy": {
        "accuracy": 0.40799191479437147
      },
      "eval_loss": 2.836045980453491,
      "eval_runtime": 3.1497,
      "eval_samples_per_second": 4083.818,
      "eval_steps_per_second": 63.815,
      "step": 263728
    },
    {
      "epoch": 424.02,
      "learning_rate": 0.05761595878279743,
      "loss": 2.7638,
      "step": 263740
    },
    {
      "epoch": 424.05,
      "learning_rate": 0.057612743351929264,
      "loss": 2.7412,
      "step": 263760
    },
    {
      "epoch": 424.08,
      "learning_rate": 0.05760952792106109,
      "loss": 2.7376,
      "step": 263780
    },
    {
      "epoch": 424.12,
      "learning_rate": 0.05760631249019293,
      "loss": 2.7929,
      "step": 263800
    },
    {
      "epoch": 424.15,
      "learning_rate": 0.05760309705932476,
      "loss": 2.7295,
      "step": 263820
    },
    {
      "epoch": 424.18,
      "learning_rate": 0.057599881628456584,
      "loss": 2.75,
      "step": 263840
    },
    {
      "epoch": 424.21,
      "learning_rate": 0.057596666197588436,
      "loss": 2.7351,
      "step": 263860
    },
    {
      "epoch": 424.24,
      "learning_rate": 0.05759345076672026,
      "loss": 2.7144,
      "step": 263880
    },
    {
      "epoch": 424.28,
      "learning_rate": 0.05759023533585209,
      "loss": 2.7589,
      "step": 263900
    },
    {
      "epoch": 424.31,
      "learning_rate": 0.05758701990498393,
      "loss": 2.7647,
      "step": 263920
    },
    {
      "epoch": 424.34,
      "learning_rate": 0.057583804474115756,
      "loss": 2.7645,
      "step": 263940
    },
    {
      "epoch": 424.37,
      "learning_rate": 0.05758058904324759,
      "loss": 2.7454,
      "step": 263960
    },
    {
      "epoch": 424.41,
      "learning_rate": 0.057577373612379426,
      "loss": 2.7378,
      "step": 263980
    },
    {
      "epoch": 424.44,
      "learning_rate": 0.057574158181511265,
      "loss": 2.7666,
      "step": 264000
    },
    {
      "epoch": 424.47,
      "learning_rate": 0.05757094275064309,
      "loss": 2.7964,
      "step": 264020
    },
    {
      "epoch": 424.5,
      "learning_rate": 0.05756772731977492,
      "loss": 2.7597,
      "step": 264040
    },
    {
      "epoch": 424.53,
      "learning_rate": 0.05756451188890676,
      "loss": 2.7376,
      "step": 264060
    },
    {
      "epoch": 424.57,
      "learning_rate": 0.05756129645803859,
      "loss": 2.7473,
      "step": 264080
    },
    {
      "epoch": 424.6,
      "learning_rate": 0.057558081027170416,
      "loss": 2.7727,
      "step": 264100
    },
    {
      "epoch": 424.63,
      "learning_rate": 0.057554865596302254,
      "loss": 2.7646,
      "step": 264120
    },
    {
      "epoch": 424.66,
      "learning_rate": 0.05755165016543409,
      "loss": 2.7438,
      "step": 264140
    },
    {
      "epoch": 424.69,
      "learning_rate": 0.057548434734565924,
      "loss": 2.7413,
      "step": 264160
    },
    {
      "epoch": 424.73,
      "learning_rate": 0.05754521930369775,
      "loss": 2.7598,
      "step": 264180
    },
    {
      "epoch": 424.76,
      "learning_rate": 0.05754200387282959,
      "loss": 2.7405,
      "step": 264200
    },
    {
      "epoch": 424.79,
      "learning_rate": 0.05753878844196142,
      "loss": 2.7829,
      "step": 264220
    },
    {
      "epoch": 424.82,
      "learning_rate": 0.057535573011093244,
      "loss": 2.7443,
      "step": 264240
    },
    {
      "epoch": 424.86,
      "learning_rate": 0.057532357580225096,
      "loss": 2.736,
      "step": 264260
    },
    {
      "epoch": 424.89,
      "learning_rate": 0.05752914214935692,
      "loss": 2.7623,
      "step": 264280
    },
    {
      "epoch": 424.92,
      "learning_rate": 0.05752592671848875,
      "loss": 2.7541,
      "step": 264300
    },
    {
      "epoch": 424.95,
      "learning_rate": 0.05752271128762058,
      "loss": 2.7522,
      "step": 264320
    },
    {
      "epoch": 424.98,
      "learning_rate": 0.057519495856752416,
      "loss": 2.7975,
      "step": 264340
    },
    {
      "epoch": 425.0,
      "eval_accuracy": {
        "accuracy": 0.39889605846225606
      },
      "eval_loss": 2.8760986328125,
      "eval_runtime": 2.8934,
      "eval_samples_per_second": 4445.702,
      "eval_steps_per_second": 69.469,
      "step": 264350
    },
    {
      "epoch": 425.02,
      "learning_rate": 0.05751644119742766,
      "loss": 2.7899,
      "step": 264360
    },
    {
      "epoch": 425.05,
      "learning_rate": 0.057513225766559484,
      "loss": 2.7677,
      "step": 264380
    },
    {
      "epoch": 425.08,
      "learning_rate": 0.05751001033569132,
      "loss": 2.7607,
      "step": 264400
    },
    {
      "epoch": 425.11,
      "learning_rate": 0.05750679490482316,
      "loss": 2.7705,
      "step": 264420
    },
    {
      "epoch": 425.14,
      "learning_rate": 0.057503579473954985,
      "loss": 2.731,
      "step": 264440
    },
    {
      "epoch": 425.18,
      "learning_rate": 0.05750036404308682,
      "loss": 2.7505,
      "step": 264460
    },
    {
      "epoch": 425.21,
      "learning_rate": 0.057497148612218656,
      "loss": 2.7625,
      "step": 264480
    },
    {
      "epoch": 425.24,
      "learning_rate": 0.05749393318135049,
      "loss": 2.7817,
      "step": 264500
    },
    {
      "epoch": 425.27,
      "learning_rate": 0.057490717750482326,
      "loss": 2.7505,
      "step": 264520
    },
    {
      "epoch": 425.31,
      "learning_rate": 0.05748750231961414,
      "loss": 2.7325,
      "step": 264540
    },
    {
      "epoch": 425.34,
      "learning_rate": 0.05748428688874599,
      "loss": 2.7529,
      "step": 264560
    },
    {
      "epoch": 425.37,
      "learning_rate": 0.05748107145787782,
      "loss": 2.7512,
      "step": 264580
    },
    {
      "epoch": 425.4,
      "learning_rate": 0.057477856027009645,
      "loss": 2.75,
      "step": 264600
    },
    {
      "epoch": 425.43,
      "learning_rate": 0.05747464059614149,
      "loss": 2.7582,
      "step": 264620
    },
    {
      "epoch": 425.47,
      "learning_rate": 0.05747142516527331,
      "loss": 2.7802,
      "step": 264640
    },
    {
      "epoch": 425.5,
      "learning_rate": 0.057468209734405154,
      "loss": 2.7838,
      "step": 264660
    },
    {
      "epoch": 425.53,
      "learning_rate": 0.05746499430353699,
      "loss": 2.7732,
      "step": 264680
    },
    {
      "epoch": 425.56,
      "learning_rate": 0.05746177887266882,
      "loss": 2.7811,
      "step": 264700
    },
    {
      "epoch": 425.59,
      "learning_rate": 0.05745856344180065,
      "loss": 2.7641,
      "step": 264720
    },
    {
      "epoch": 425.63,
      "learning_rate": 0.057455348010932474,
      "loss": 2.7863,
      "step": 264740
    },
    {
      "epoch": 425.66,
      "learning_rate": 0.05745213258006432,
      "loss": 2.7394,
      "step": 264760
    },
    {
      "epoch": 425.69,
      "learning_rate": 0.05744891714919614,
      "loss": 2.7458,
      "step": 264780
    },
    {
      "epoch": 425.72,
      "learning_rate": 0.05744570171832798,
      "loss": 2.7502,
      "step": 264800
    },
    {
      "epoch": 425.76,
      "learning_rate": 0.05744248628745982,
      "loss": 2.7585,
      "step": 264820
    },
    {
      "epoch": 425.79,
      "learning_rate": 0.057439270856591645,
      "loss": 2.7666,
      "step": 264840
    },
    {
      "epoch": 425.82,
      "learning_rate": 0.05743605542572348,
      "loss": 2.7499,
      "step": 264860
    },
    {
      "epoch": 425.85,
      "learning_rate": 0.0574328399948553,
      "loss": 2.7505,
      "step": 264880
    },
    {
      "epoch": 425.88,
      "learning_rate": 0.05742962456398715,
      "loss": 2.7403,
      "step": 264900
    },
    {
      "epoch": 425.92,
      "learning_rate": 0.05742640913311897,
      "loss": 2.7705,
      "step": 264920
    },
    {
      "epoch": 425.95,
      "learning_rate": 0.0574231937022508,
      "loss": 2.7656,
      "step": 264940
    },
    {
      "epoch": 425.98,
      "learning_rate": 0.05741997827138265,
      "loss": 2.745,
      "step": 264960
    },
    {
      "epoch": 426.0,
      "eval_accuracy": {
        "accuracy": 0.41071289745782474
      },
      "eval_loss": 2.857447624206543,
      "eval_runtime": 3.4134,
      "eval_samples_per_second": 3768.382,
      "eval_steps_per_second": 58.886,
      "step": 264972
    },
    {
      "epoch": 426.01,
      "learning_rate": 0.057416762840514474,
      "loss": 2.767,
      "step": 264980
    },
    {
      "epoch": 426.05,
      "learning_rate": 0.057413547409646305,
      "loss": 2.7331,
      "step": 265000
    },
    {
      "epoch": 426.08,
      "learning_rate": 0.057410331978778144,
      "loss": 2.7461,
      "step": 265020
    },
    {
      "epoch": 426.11,
      "learning_rate": 0.057407116547909975,
      "loss": 2.7283,
      "step": 265040
    },
    {
      "epoch": 426.14,
      "learning_rate": 0.0574039011170418,
      "loss": 2.7501,
      "step": 265060
    },
    {
      "epoch": 426.17,
      "learning_rate": 0.057400685686173625,
      "loss": 2.762,
      "step": 265080
    },
    {
      "epoch": 426.21,
      "learning_rate": 0.05739747025530548,
      "loss": 2.7897,
      "step": 265100
    },
    {
      "epoch": 426.24,
      "learning_rate": 0.0573942548244373,
      "loss": 2.7258,
      "step": 265120
    },
    {
      "epoch": 426.27,
      "learning_rate": 0.057391039393569133,
      "loss": 2.7773,
      "step": 265140
    },
    {
      "epoch": 426.3,
      "learning_rate": 0.05738782396270096,
      "loss": 2.7584,
      "step": 265160
    },
    {
      "epoch": 426.33,
      "learning_rate": 0.0573846085318328,
      "loss": 2.7492,
      "step": 265180
    },
    {
      "epoch": 426.37,
      "learning_rate": 0.05738139310096464,
      "loss": 2.7518,
      "step": 265200
    },
    {
      "epoch": 426.4,
      "learning_rate": 0.05737817767009645,
      "loss": 2.7556,
      "step": 265220
    },
    {
      "epoch": 426.43,
      "learning_rate": 0.057374962239228305,
      "loss": 2.7533,
      "step": 265240
    },
    {
      "epoch": 426.46,
      "learning_rate": 0.05737174680836013,
      "loss": 2.7669,
      "step": 265260
    },
    {
      "epoch": 426.5,
      "learning_rate": 0.05736853137749196,
      "loss": 2.7409,
      "step": 265280
    },
    {
      "epoch": 426.53,
      "learning_rate": 0.05736531594662381,
      "loss": 2.7383,
      "step": 265300
    },
    {
      "epoch": 426.56,
      "learning_rate": 0.057362100515755625,
      "loss": 2.7519,
      "step": 265320
    },
    {
      "epoch": 426.59,
      "learning_rate": 0.05735888508488747,
      "loss": 2.767,
      "step": 265340
    },
    {
      "epoch": 426.62,
      "learning_rate": 0.05735566965401931,
      "loss": 2.7448,
      "step": 265360
    },
    {
      "epoch": 426.66,
      "learning_rate": 0.057352454223151134,
      "loss": 2.7578,
      "step": 265380
    },
    {
      "epoch": 426.69,
      "learning_rate": 0.05734923879228296,
      "loss": 2.7623,
      "step": 265400
    },
    {
      "epoch": 426.72,
      "learning_rate": 0.05734602336141479,
      "loss": 2.7373,
      "step": 265420
    },
    {
      "epoch": 426.75,
      "learning_rate": 0.057342807930546635,
      "loss": 2.7439,
      "step": 265440
    },
    {
      "epoch": 426.78,
      "learning_rate": 0.05733959249967845,
      "loss": 2.7284,
      "step": 265460
    },
    {
      "epoch": 426.82,
      "learning_rate": 0.057336377068810285,
      "loss": 2.7176,
      "step": 265480
    },
    {
      "epoch": 426.85,
      "learning_rate": 0.05733316163794212,
      "loss": 2.7646,
      "step": 265500
    },
    {
      "epoch": 426.88,
      "learning_rate": 0.05732994620707396,
      "loss": 2.7421,
      "step": 265520
    },
    {
      "epoch": 426.91,
      "learning_rate": 0.05732673077620579,
      "loss": 2.777,
      "step": 265540
    },
    {
      "epoch": 426.95,
      "learning_rate": 0.05732351534533762,
      "loss": 2.7755,
      "step": 265560
    },
    {
      "epoch": 426.98,
      "learning_rate": 0.05732029991446946,
      "loss": 2.7482,
      "step": 265580
    },
    {
      "epoch": 427.0,
      "eval_accuracy": {
        "accuracy": 0.4018502682111483
      },
      "eval_loss": 2.842024803161621,
      "eval_runtime": 2.8865,
      "eval_samples_per_second": 4456.253,
      "eval_steps_per_second": 69.634,
      "step": 265594
    },
    {
      "epoch": 427.01,
      "learning_rate": 0.05731708448360129,
      "loss": 2.7534,
      "step": 265600
    },
    {
      "epoch": 427.04,
      "learning_rate": 0.05731386905273311,
      "loss": 2.7622,
      "step": 265620
    },
    {
      "epoch": 427.07,
      "learning_rate": 0.057310653621864965,
      "loss": 2.7644,
      "step": 265640
    },
    {
      "epoch": 427.11,
      "learning_rate": 0.05730743819099679,
      "loss": 2.7797,
      "step": 265660
    },
    {
      "epoch": 427.14,
      "learning_rate": 0.05730422276012862,
      "loss": 2.7665,
      "step": 265680
    },
    {
      "epoch": 427.17,
      "learning_rate": 0.057301007329260446,
      "loss": 2.7858,
      "step": 265700
    },
    {
      "epoch": 427.2,
      "learning_rate": 0.057297791898392285,
      "loss": 2.7803,
      "step": 265720
    },
    {
      "epoch": 427.23,
      "learning_rate": 0.057294576467524116,
      "loss": 2.7864,
      "step": 265740
    },
    {
      "epoch": 427.27,
      "learning_rate": 0.05729136103665594,
      "loss": 2.7312,
      "step": 265760
    },
    {
      "epoch": 427.3,
      "learning_rate": 0.057288145605787794,
      "loss": 2.7578,
      "step": 265780
    },
    {
      "epoch": 427.33,
      "learning_rate": 0.05728493017491962,
      "loss": 2.7267,
      "step": 265800
    },
    {
      "epoch": 427.36,
      "learning_rate": 0.05728171474405145,
      "loss": 2.7953,
      "step": 265820
    },
    {
      "epoch": 427.4,
      "learning_rate": 0.057278499313183275,
      "loss": 2.7431,
      "step": 265840
    },
    {
      "epoch": 427.43,
      "learning_rate": 0.05727528388231511,
      "loss": 2.7423,
      "step": 265860
    },
    {
      "epoch": 427.46,
      "learning_rate": 0.05727206845144696,
      "loss": 2.7762,
      "step": 265880
    },
    {
      "epoch": 427.49,
      "learning_rate": 0.05726885302057877,
      "loss": 2.7763,
      "step": 265900
    },
    {
      "epoch": 427.52,
      "learning_rate": 0.05726563758971062,
      "loss": 2.7405,
      "step": 265920
    },
    {
      "epoch": 427.56,
      "learning_rate": 0.057262422158842446,
      "loss": 2.7154,
      "step": 265940
    },
    {
      "epoch": 427.59,
      "learning_rate": 0.05725920672797428,
      "loss": 2.7251,
      "step": 265960
    },
    {
      "epoch": 427.62,
      "learning_rate": 0.057255991297106124,
      "loss": 2.7564,
      "step": 265980
    },
    {
      "epoch": 427.65,
      "learning_rate": 0.05725277586623794,
      "loss": 2.7514,
      "step": 266000
    },
    {
      "epoch": 427.68,
      "learning_rate": 0.05724956043536977,
      "loss": 2.7343,
      "step": 266020
    },
    {
      "epoch": 427.72,
      "learning_rate": 0.05724634500450161,
      "loss": 2.7545,
      "step": 266040
    },
    {
      "epoch": 427.75,
      "learning_rate": 0.05724312957363345,
      "loss": 2.7343,
      "step": 266060
    },
    {
      "epoch": 427.78,
      "learning_rate": 0.057239914142765275,
      "loss": 2.7498,
      "step": 266080
    },
    {
      "epoch": 427.81,
      "learning_rate": 0.057236698711897106,
      "loss": 2.7474,
      "step": 266100
    },
    {
      "epoch": 427.85,
      "learning_rate": 0.057233483281028945,
      "loss": 2.7362,
      "step": 266120
    },
    {
      "epoch": 427.88,
      "learning_rate": 0.057230267850160776,
      "loss": 2.7543,
      "step": 266140
    },
    {
      "epoch": 427.91,
      "learning_rate": 0.0572270524192926,
      "loss": 2.7568,
      "step": 266160
    },
    {
      "epoch": 427.94,
      "learning_rate": 0.05722383698842444,
      "loss": 2.7573,
      "step": 266180
    },
    {
      "epoch": 427.97,
      "learning_rate": 0.05722062155755628,
      "loss": 2.7595,
      "step": 266200
    },
    {
      "epoch": 428.0,
      "eval_accuracy": {
        "accuracy": 0.4017725258493353
      },
      "eval_loss": 2.8678154945373535,
      "eval_runtime": 3.0409,
      "eval_samples_per_second": 4229.949,
      "eval_steps_per_second": 66.098,
      "step": 266216
    },
    {
      "epoch": 428.01,
      "learning_rate": 0.05721740612668811,
      "loss": 2.7479,
      "step": 266220
    },
    {
      "epoch": 428.04,
      "learning_rate": 0.057214190695819934,
      "loss": 2.7449,
      "step": 266240
    },
    {
      "epoch": 428.07,
      "learning_rate": 0.05721097526495177,
      "loss": 2.7123,
      "step": 266260
    },
    {
      "epoch": 428.1,
      "learning_rate": 0.057207759834083605,
      "loss": 2.7199,
      "step": 266280
    },
    {
      "epoch": 428.14,
      "learning_rate": 0.05720454440321543,
      "loss": 2.7587,
      "step": 266300
    },
    {
      "epoch": 428.17,
      "learning_rate": 0.05720132897234728,
      "loss": 2.7569,
      "step": 266320
    },
    {
      "epoch": 428.2,
      "learning_rate": 0.057198113541479106,
      "loss": 2.7486,
      "step": 266340
    },
    {
      "epoch": 428.23,
      "learning_rate": 0.05719489811061094,
      "loss": 2.7163,
      "step": 266360
    },
    {
      "epoch": 428.26,
      "learning_rate": 0.05719168267974276,
      "loss": 2.7405,
      "step": 266380
    },
    {
      "epoch": 428.3,
      "learning_rate": 0.0571884672488746,
      "loss": 2.7302,
      "step": 266400
    },
    {
      "epoch": 428.33,
      "learning_rate": 0.05718525181800643,
      "loss": 2.7513,
      "step": 266420
    },
    {
      "epoch": 428.36,
      "learning_rate": 0.05718203638713826,
      "loss": 2.7622,
      "step": 266440
    },
    {
      "epoch": 428.39,
      "learning_rate": 0.05717882095627011,
      "loss": 2.7625,
      "step": 266460
    },
    {
      "epoch": 428.42,
      "learning_rate": 0.057175605525401935,
      "loss": 2.7741,
      "step": 266480
    },
    {
      "epoch": 428.46,
      "learning_rate": 0.057172390094533766,
      "loss": 2.7535,
      "step": 266500
    },
    {
      "epoch": 428.49,
      "learning_rate": 0.05716917466366559,
      "loss": 2.7552,
      "step": 266520
    },
    {
      "epoch": 428.52,
      "learning_rate": 0.05716595923279743,
      "loss": 2.7785,
      "step": 266540
    },
    {
      "epoch": 428.55,
      "learning_rate": 0.05716274380192926,
      "loss": 2.762,
      "step": 266560
    },
    {
      "epoch": 428.59,
      "learning_rate": 0.057159528371061086,
      "loss": 2.7814,
      "step": 266580
    },
    {
      "epoch": 428.62,
      "learning_rate": 0.05715631294019294,
      "loss": 2.7752,
      "step": 266600
    },
    {
      "epoch": 428.65,
      "learning_rate": 0.05715309750932476,
      "loss": 2.7419,
      "step": 266620
    },
    {
      "epoch": 428.68,
      "learning_rate": 0.057149882078456594,
      "loss": 2.7278,
      "step": 266640
    },
    {
      "epoch": 428.71,
      "learning_rate": 0.05714666664758843,
      "loss": 2.7754,
      "step": 266660
    },
    {
      "epoch": 428.75,
      "learning_rate": 0.05714345121672026,
      "loss": 2.7706,
      "step": 266680
    },
    {
      "epoch": 428.78,
      "learning_rate": 0.05714023578585209,
      "loss": 2.7429,
      "step": 266700
    },
    {
      "epoch": 428.81,
      "learning_rate": 0.05713702035498393,
      "loss": 2.7428,
      "step": 266720
    },
    {
      "epoch": 428.84,
      "learning_rate": 0.057133804924115766,
      "loss": 2.7592,
      "step": 266740
    },
    {
      "epoch": 428.87,
      "learning_rate": 0.057130750264791,
      "loss": 2.7481,
      "step": 266760
    },
    {
      "epoch": 428.91,
      "learning_rate": 0.057127534833922834,
      "loss": 2.7592,
      "step": 266780
    },
    {
      "epoch": 428.94,
      "learning_rate": 0.05712431940305466,
      "loss": 2.7637,
      "step": 266800
    },
    {
      "epoch": 428.97,
      "learning_rate": 0.057121103972186504,
      "loss": 2.7321,
      "step": 266820
    },
    {
      "epoch": 429.0,
      "eval_accuracy": {
        "accuracy": 0.40752546062349376
      },
      "eval_loss": 2.8335413932800293,
      "eval_runtime": 2.8936,
      "eval_samples_per_second": 4445.325,
      "eval_steps_per_second": 69.464,
      "step": 266838
    },
    {
      "epoch": 429.0,
      "learning_rate": 0.05711788854131832,
      "loss": 2.763,
      "step": 266840
    },
    {
      "epoch": 429.04,
      "learning_rate": 0.05711467311045017,
      "loss": 2.7225,
      "step": 266860
    },
    {
      "epoch": 429.07,
      "learning_rate": 0.057111457679582006,
      "loss": 2.7718,
      "step": 266880
    },
    {
      "epoch": 429.1,
      "learning_rate": 0.05710824224871383,
      "loss": 2.758,
      "step": 266900
    },
    {
      "epoch": 429.13,
      "learning_rate": 0.05710502681784566,
      "loss": 2.7431,
      "step": 266920
    },
    {
      "epoch": 429.16,
      "learning_rate": 0.05710181138697749,
      "loss": 2.7463,
      "step": 266940
    },
    {
      "epoch": 429.2,
      "learning_rate": 0.05709859595610933,
      "loss": 2.7494,
      "step": 266960
    },
    {
      "epoch": 429.23,
      "learning_rate": 0.05709538052524116,
      "loss": 2.7303,
      "step": 266980
    },
    {
      "epoch": 429.26,
      "learning_rate": 0.057092165094372996,
      "loss": 2.7459,
      "step": 267000
    },
    {
      "epoch": 429.29,
      "learning_rate": 0.057088949663504834,
      "loss": 2.7357,
      "step": 267020
    },
    {
      "epoch": 429.32,
      "learning_rate": 0.05708573423263666,
      "loss": 2.7395,
      "step": 267040
    },
    {
      "epoch": 429.36,
      "learning_rate": 0.05708251880176849,
      "loss": 2.726,
      "step": 267060
    },
    {
      "epoch": 429.39,
      "learning_rate": 0.05707930337090033,
      "loss": 2.725,
      "step": 267080
    },
    {
      "epoch": 429.42,
      "learning_rate": 0.05707608794003216,
      "loss": 2.7543,
      "step": 267100
    },
    {
      "epoch": 429.45,
      "learning_rate": 0.057072872509163985,
      "loss": 2.7649,
      "step": 267120
    },
    {
      "epoch": 429.49,
      "learning_rate": 0.05706965707829581,
      "loss": 2.7464,
      "step": 267140
    },
    {
      "epoch": 429.52,
      "learning_rate": 0.05706644164742766,
      "loss": 2.7339,
      "step": 267160
    },
    {
      "epoch": 429.55,
      "learning_rate": 0.05706322621655949,
      "loss": 2.6984,
      "step": 267180
    },
    {
      "epoch": 429.58,
      "learning_rate": 0.05706001078569132,
      "loss": 2.7428,
      "step": 267200
    },
    {
      "epoch": 429.61,
      "learning_rate": 0.05705679535482316,
      "loss": 2.7555,
      "step": 267220
    },
    {
      "epoch": 429.65,
      "learning_rate": 0.05705357992395499,
      "loss": 2.7529,
      "step": 267240
    },
    {
      "epoch": 429.68,
      "learning_rate": 0.05705036449308683,
      "loss": 2.7661,
      "step": 267260
    },
    {
      "epoch": 429.71,
      "learning_rate": 0.05704714906221864,
      "loss": 2.7573,
      "step": 267280
    },
    {
      "epoch": 429.74,
      "learning_rate": 0.05704393363135049,
      "loss": 2.7332,
      "step": 267300
    },
    {
      "epoch": 429.77,
      "learning_rate": 0.05704071820048232,
      "loss": 2.7219,
      "step": 267320
    },
    {
      "epoch": 429.81,
      "learning_rate": 0.05703750276961415,
      "loss": 2.7597,
      "step": 267340
    },
    {
      "epoch": 429.84,
      "learning_rate": 0.05703428733874599,
      "loss": 2.7639,
      "step": 267360
    },
    {
      "epoch": 429.87,
      "learning_rate": 0.05703107190787781,
      "loss": 2.7552,
      "step": 267380
    },
    {
      "epoch": 429.9,
      "learning_rate": 0.057027856477009656,
      "loss": 2.7589,
      "step": 267400
    },
    {
      "epoch": 429.94,
      "learning_rate": 0.057024641046141494,
      "loss": 2.7438,
      "step": 267420
    },
    {
      "epoch": 429.97,
      "learning_rate": 0.05702142561527332,
      "loss": 2.7692,
      "step": 267440
    },
    {
      "epoch": 430.0,
      "learning_rate": 0.057018210184405144,
      "loss": 2.7306,
      "step": 267460
    },
    {
      "epoch": 430.0,
      "eval_accuracy": {
        "accuracy": 0.395786363989738
      },
      "eval_loss": 2.883720874786377,
      "eval_runtime": 3.0901,
      "eval_samples_per_second": 4162.668,
      "eval_steps_per_second": 65.047,
      "step": 267460
    },
    {
      "epoch": 430.03,
      "learning_rate": 0.057014994753536975,
      "loss": 2.7858,
      "step": 267480
    },
    {
      "epoch": 430.06,
      "learning_rate": 0.05701177932266882,
      "loss": 2.7707,
      "step": 267500
    },
    {
      "epoch": 430.1,
      "learning_rate": 0.05700856389180064,
      "loss": 2.733,
      "step": 267520
    },
    {
      "epoch": 430.13,
      "learning_rate": 0.057005348460932484,
      "loss": 2.7372,
      "step": 267540
    },
    {
      "epoch": 430.16,
      "learning_rate": 0.05700213303006432,
      "loss": 2.7441,
      "step": 267560
    },
    {
      "epoch": 430.19,
      "learning_rate": 0.05699891759919615,
      "loss": 2.7481,
      "step": 267580
    },
    {
      "epoch": 430.23,
      "learning_rate": 0.05699570216832798,
      "loss": 2.7629,
      "step": 267600
    },
    {
      "epoch": 430.26,
      "learning_rate": 0.056992486737459803,
      "loss": 2.7479,
      "step": 267620
    },
    {
      "epoch": 430.29,
      "learning_rate": 0.05698927130659165,
      "loss": 2.7318,
      "step": 267640
    },
    {
      "epoch": 430.32,
      "learning_rate": 0.056986055875723474,
      "loss": 2.7212,
      "step": 267660
    },
    {
      "epoch": 430.35,
      "learning_rate": 0.0569828404448553,
      "loss": 2.7588,
      "step": 267680
    },
    {
      "epoch": 430.39,
      "learning_rate": 0.05697962501398715,
      "loss": 2.7519,
      "step": 267700
    },
    {
      "epoch": 430.42,
      "learning_rate": 0.056976409583118975,
      "loss": 2.7392,
      "step": 267720
    },
    {
      "epoch": 430.45,
      "learning_rate": 0.05697319415225081,
      "loss": 2.7415,
      "step": 267740
    },
    {
      "epoch": 430.48,
      "learning_rate": 0.056969978721382646,
      "loss": 2.727,
      "step": 267760
    },
    {
      "epoch": 430.51,
      "learning_rate": 0.05696676329051447,
      "loss": 2.7426,
      "step": 267780
    },
    {
      "epoch": 430.55,
      "learning_rate": 0.0569635478596463,
      "loss": 2.7397,
      "step": 267800
    },
    {
      "epoch": 430.58,
      "learning_rate": 0.056960332428778127,
      "loss": 2.7244,
      "step": 267820
    },
    {
      "epoch": 430.61,
      "learning_rate": 0.05695711699790998,
      "loss": 2.7536,
      "step": 267840
    },
    {
      "epoch": 430.64,
      "learning_rate": 0.056953901567041804,
      "loss": 2.7654,
      "step": 267860
    },
    {
      "epoch": 430.68,
      "learning_rate": 0.056950686136173635,
      "loss": 2.7614,
      "step": 267880
    },
    {
      "epoch": 430.71,
      "learning_rate": 0.05694747070530546,
      "loss": 2.7846,
      "step": 267900
    },
    {
      "epoch": 430.74,
      "learning_rate": 0.0569442552744373,
      "loss": 2.7728,
      "step": 267920
    },
    {
      "epoch": 430.77,
      "learning_rate": 0.056941039843569144,
      "loss": 2.7442,
      "step": 267940
    },
    {
      "epoch": 430.8,
      "learning_rate": 0.056937824412700955,
      "loss": 2.7198,
      "step": 267960
    },
    {
      "epoch": 430.84,
      "learning_rate": 0.05693460898183281,
      "loss": 2.7439,
      "step": 267980
    },
    {
      "epoch": 430.87,
      "learning_rate": 0.05693139355096463,
      "loss": 2.7543,
      "step": 268000
    },
    {
      "epoch": 430.9,
      "learning_rate": 0.05692817812009646,
      "loss": 2.7425,
      "step": 268020
    },
    {
      "epoch": 430.93,
      "learning_rate": 0.05692496268922831,
      "loss": 2.769,
      "step": 268040
    },
    {
      "epoch": 430.96,
      "learning_rate": 0.05692174725836013,
      "loss": 2.749,
      "step": 268060
    },
    {
      "epoch": 431.0,
      "learning_rate": 0.05691853182749197,
      "loss": 2.7614,
      "step": 268080
    },
    {
      "epoch": 431.0,
      "eval_accuracy": {
        "accuracy": 0.40379382725647206
      },
      "eval_loss": 2.8579204082489014,
      "eval_runtime": 3.031,
      "eval_samples_per_second": 4243.832,
      "eval_steps_per_second": 66.315,
      "step": 268082
    },
    {
      "epoch": 431.03,
      "learning_rate": 0.0569153163966238,
      "loss": 2.7401,
      "step": 268100
    },
    {
      "epoch": 431.06,
      "learning_rate": 0.056912100965755635,
      "loss": 2.7484,
      "step": 268120
    },
    {
      "epoch": 431.09,
      "learning_rate": 0.05690888553488746,
      "loss": 2.7491,
      "step": 268140
    },
    {
      "epoch": 431.13,
      "learning_rate": 0.05690567010401929,
      "loss": 2.7549,
      "step": 268160
    },
    {
      "epoch": 431.16,
      "learning_rate": 0.05690245467315114,
      "loss": 2.7574,
      "step": 268180
    },
    {
      "epoch": 431.19,
      "learning_rate": 0.056899239242282955,
      "loss": 2.7572,
      "step": 268200
    },
    {
      "epoch": 431.22,
      "learning_rate": 0.056896023811414786,
      "loss": 2.7367,
      "step": 268220
    },
    {
      "epoch": 431.25,
      "learning_rate": 0.056892808380546625,
      "loss": 2.7741,
      "step": 268240
    },
    {
      "epoch": 431.29,
      "learning_rate": 0.056889592949678464,
      "loss": 2.7602,
      "step": 268260
    },
    {
      "epoch": 431.32,
      "learning_rate": 0.056886377518810295,
      "loss": 2.7519,
      "step": 268280
    },
    {
      "epoch": 431.35,
      "learning_rate": 0.05688316208794212,
      "loss": 2.7523,
      "step": 268300
    },
    {
      "epoch": 431.38,
      "learning_rate": 0.05687994665707396,
      "loss": 2.7514,
      "step": 268320
    },
    {
      "epoch": 431.41,
      "learning_rate": 0.05687673122620579,
      "loss": 2.7434,
      "step": 268340
    },
    {
      "epoch": 431.45,
      "learning_rate": 0.056873515795337615,
      "loss": 2.7516,
      "step": 268360
    },
    {
      "epoch": 431.48,
      "learning_rate": 0.05687030036446947,
      "loss": 2.7597,
      "step": 268380
    },
    {
      "epoch": 431.51,
      "learning_rate": 0.05686708493360129,
      "loss": 2.7817,
      "step": 268400
    },
    {
      "epoch": 431.54,
      "learning_rate": 0.05686386950273312,
      "loss": 2.7664,
      "step": 268420
    },
    {
      "epoch": 431.58,
      "learning_rate": 0.05686065407186495,
      "loss": 2.7406,
      "step": 268440
    },
    {
      "epoch": 431.61,
      "learning_rate": 0.05685743864099679,
      "loss": 2.7282,
      "step": 268460
    },
    {
      "epoch": 431.64,
      "learning_rate": 0.05685422321012862,
      "loss": 2.7387,
      "step": 268480
    },
    {
      "epoch": 431.67,
      "learning_rate": 0.05685100777926044,
      "loss": 2.747,
      "step": 268500
    },
    {
      "epoch": 431.7,
      "learning_rate": 0.056847792348392295,
      "loss": 2.7713,
      "step": 268520
    },
    {
      "epoch": 431.74,
      "learning_rate": 0.05684457691752412,
      "loss": 2.7603,
      "step": 268540
    },
    {
      "epoch": 431.77,
      "learning_rate": 0.05684136148665595,
      "loss": 2.7286,
      "step": 268560
    },
    {
      "epoch": 431.8,
      "learning_rate": 0.056838146055787776,
      "loss": 2.7354,
      "step": 268580
    },
    {
      "epoch": 431.83,
      "learning_rate": 0.056834930624919615,
      "loss": 2.7265,
      "step": 268600
    },
    {
      "epoch": 431.86,
      "learning_rate": 0.05683171519405146,
      "loss": 2.7812,
      "step": 268620
    },
    {
      "epoch": 431.9,
      "learning_rate": 0.05682849976318327,
      "loss": 2.7316,
      "step": 268640
    },
    {
      "epoch": 431.93,
      "learning_rate": 0.056825284332315124,
      "loss": 2.7059,
      "step": 268660
    },
    {
      "epoch": 431.96,
      "learning_rate": 0.05682206890144695,
      "loss": 2.754,
      "step": 268680
    },
    {
      "epoch": 431.99,
      "learning_rate": 0.05681885347057878,
      "loss": 2.748,
      "step": 268700
    },
    {
      "epoch": 432.0,
      "eval_accuracy": {
        "accuracy": 0.4093135349451916
      },
      "eval_loss": 2.870243787765503,
      "eval_runtime": 3.0602,
      "eval_samples_per_second": 4203.256,
      "eval_steps_per_second": 65.681,
      "step": 268704
    },
    {
      "epoch": 432.03,
      "learning_rate": 0.056815638039710625,
      "loss": 2.7288,
      "step": 268720
    },
    {
      "epoch": 432.06,
      "learning_rate": 0.05681242260884244,
      "loss": 2.7252,
      "step": 268740
    },
    {
      "epoch": 432.09,
      "learning_rate": 0.056809207177974275,
      "loss": 2.7509,
      "step": 268760
    },
    {
      "epoch": 432.12,
      "learning_rate": 0.05680599174710611,
      "loss": 2.7576,
      "step": 268780
    },
    {
      "epoch": 432.15,
      "learning_rate": 0.05680277631623795,
      "loss": 2.7525,
      "step": 268800
    },
    {
      "epoch": 432.19,
      "learning_rate": 0.056799560885369776,
      "loss": 2.7618,
      "step": 268820
    },
    {
      "epoch": 432.22,
      "learning_rate": 0.05679650622604502,
      "loss": 2.7881,
      "step": 268840
    },
    {
      "epoch": 432.25,
      "learning_rate": 0.056793290795176844,
      "loss": 2.7444,
      "step": 268860
    },
    {
      "epoch": 432.28,
      "learning_rate": 0.05679007536430869,
      "loss": 2.7354,
      "step": 268880
    },
    {
      "epoch": 432.32,
      "learning_rate": 0.056786859933440514,
      "loss": 2.7265,
      "step": 268900
    },
    {
      "epoch": 432.35,
      "learning_rate": 0.05678364450257235,
      "loss": 2.7412,
      "step": 268920
    },
    {
      "epoch": 432.38,
      "learning_rate": 0.05678042907170419,
      "loss": 2.7633,
      "step": 268940
    },
    {
      "epoch": 432.41,
      "learning_rate": 0.056777213640836016,
      "loss": 2.7556,
      "step": 268960
    },
    {
      "epoch": 432.44,
      "learning_rate": 0.05677399820996785,
      "loss": 2.7648,
      "step": 268980
    },
    {
      "epoch": 432.48,
      "learning_rate": 0.05677078277909967,
      "loss": 2.7413,
      "step": 269000
    },
    {
      "epoch": 432.51,
      "learning_rate": 0.05676756734823152,
      "loss": 2.7307,
      "step": 269020
    },
    {
      "epoch": 432.54,
      "learning_rate": 0.05676435191736334,
      "loss": 2.7603,
      "step": 269040
    },
    {
      "epoch": 432.57,
      "learning_rate": 0.05676113648649518,
      "loss": 2.7541,
      "step": 269060
    },
    {
      "epoch": 432.6,
      "learning_rate": 0.05675792105562702,
      "loss": 2.7674,
      "step": 269080
    },
    {
      "epoch": 432.64,
      "learning_rate": 0.056754705624758844,
      "loss": 2.763,
      "step": 269100
    },
    {
      "epoch": 432.67,
      "learning_rate": 0.056751490193890676,
      "loss": 2.7685,
      "step": 269120
    },
    {
      "epoch": 432.7,
      "learning_rate": 0.056748274763022515,
      "loss": 2.7777,
      "step": 269140
    },
    {
      "epoch": 432.73,
      "learning_rate": 0.056745059332154346,
      "loss": 2.7556,
      "step": 269160
    },
    {
      "epoch": 432.77,
      "learning_rate": 0.05674184390128617,
      "loss": 2.7318,
      "step": 269180
    },
    {
      "epoch": 432.8,
      "learning_rate": 0.05673862847041801,
      "loss": 2.7469,
      "step": 269200
    },
    {
      "epoch": 432.83,
      "learning_rate": 0.05673541303954985,
      "loss": 2.7465,
      "step": 269220
    },
    {
      "epoch": 432.86,
      "learning_rate": 0.05673219760868167,
      "loss": 2.7358,
      "step": 269240
    },
    {
      "epoch": 432.89,
      "learning_rate": 0.056728982177813504,
      "loss": 2.7461,
      "step": 269260
    },
    {
      "epoch": 432.93,
      "learning_rate": 0.05672576674694534,
      "loss": 2.7466,
      "step": 269280
    },
    {
      "epoch": 432.96,
      "learning_rate": 0.056722551316077174,
      "loss": 2.7518,
      "step": 269300
    },
    {
      "epoch": 432.99,
      "learning_rate": 0.05671933588520901,
      "loss": 2.7379,
      "step": 269320
    },
    {
      "epoch": 433.0,
      "eval_accuracy": {
        "accuracy": 0.4002176786130763
      },
      "eval_loss": 2.8515539169311523,
      "eval_runtime": 2.8567,
      "eval_samples_per_second": 4502.747,
      "eval_steps_per_second": 70.361,
      "step": 269326
    },
    {
      "epoch": 433.02,
      "learning_rate": 0.056716120454340824,
      "loss": 2.7504,
      "step": 269340
    },
    {
      "epoch": 433.05,
      "learning_rate": 0.056712905023472676,
      "loss": 2.7358,
      "step": 269360
    },
    {
      "epoch": 433.09,
      "learning_rate": 0.05670968959260451,
      "loss": 2.7571,
      "step": 269380
    },
    {
      "epoch": 433.12,
      "learning_rate": 0.05670647416173633,
      "loss": 2.7384,
      "step": 269400
    },
    {
      "epoch": 433.15,
      "learning_rate": 0.05670325873086818,
      "loss": 2.7551,
      "step": 269420
    },
    {
      "epoch": 433.18,
      "learning_rate": 0.0567000433,
      "loss": 2.732,
      "step": 269440
    },
    {
      "epoch": 433.22,
      "learning_rate": 0.05669682786913184,
      "loss": 2.7257,
      "step": 269460
    },
    {
      "epoch": 433.25,
      "learning_rate": 0.05669361243826368,
      "loss": 2.7585,
      "step": 269480
    },
    {
      "epoch": 433.28,
      "learning_rate": 0.056690397007395504,
      "loss": 2.7399,
      "step": 269500
    },
    {
      "epoch": 433.31,
      "learning_rate": 0.056687181576527336,
      "loss": 2.7435,
      "step": 269520
    },
    {
      "epoch": 433.34,
      "learning_rate": 0.05668396614565916,
      "loss": 2.7363,
      "step": 269540
    },
    {
      "epoch": 433.38,
      "learning_rate": 0.056680750714791006,
      "loss": 2.7186,
      "step": 269560
    },
    {
      "epoch": 433.41,
      "learning_rate": 0.056677535283922824,
      "loss": 2.7407,
      "step": 269580
    },
    {
      "epoch": 433.44,
      "learning_rate": 0.05667431985305467,
      "loss": 2.7377,
      "step": 269600
    },
    {
      "epoch": 433.47,
      "learning_rate": 0.05667110442218651,
      "loss": 2.7171,
      "step": 269620
    },
    {
      "epoch": 433.5,
      "learning_rate": 0.05666788899131833,
      "loss": 2.7391,
      "step": 269640
    },
    {
      "epoch": 433.54,
      "learning_rate": 0.056664673560450164,
      "loss": 2.775,
      "step": 269660
    },
    {
      "epoch": 433.57,
      "learning_rate": 0.05666145812958199,
      "loss": 2.781,
      "step": 269680
    },
    {
      "epoch": 433.6,
      "learning_rate": 0.056658242698713834,
      "loss": 2.7268,
      "step": 269700
    },
    {
      "epoch": 433.63,
      "learning_rate": 0.05665502726784566,
      "loss": 2.7071,
      "step": 269720
    },
    {
      "epoch": 433.67,
      "learning_rate": 0.0566518118369775,
      "loss": 2.7455,
      "step": 269740
    },
    {
      "epoch": 433.7,
      "learning_rate": 0.056648596406109336,
      "loss": 2.7454,
      "step": 269760
    },
    {
      "epoch": 433.73,
      "learning_rate": 0.05664538097524116,
      "loss": 2.7552,
      "step": 269780
    },
    {
      "epoch": 433.76,
      "learning_rate": 0.05664216554437299,
      "loss": 2.7635,
      "step": 269800
    },
    {
      "epoch": 433.79,
      "learning_rate": 0.05663895011350483,
      "loss": 2.7569,
      "step": 269820
    },
    {
      "epoch": 433.83,
      "learning_rate": 0.05663573468263666,
      "loss": 2.7466,
      "step": 269840
    },
    {
      "epoch": 433.86,
      "learning_rate": 0.05663251925176849,
      "loss": 2.7444,
      "step": 269860
    },
    {
      "epoch": 433.89,
      "learning_rate": 0.05662930382090031,
      "loss": 2.7508,
      "step": 269880
    },
    {
      "epoch": 433.92,
      "learning_rate": 0.056626088390032164,
      "loss": 2.7666,
      "step": 269900
    },
    {
      "epoch": 433.95,
      "learning_rate": 0.05662287295916399,
      "loss": 2.734,
      "step": 269920
    },
    {
      "epoch": 433.99,
      "learning_rate": 0.05661965752829582,
      "loss": 2.7697,
      "step": 269940
    },
    {
      "epoch": 434.0,
      "eval_accuracy": {
        "accuracy": 0.40138381404027057
      },
      "eval_loss": 2.8746771812438965,
      "eval_runtime": 3.1652,
      "eval_samples_per_second": 4063.876,
      "eval_steps_per_second": 63.503,
      "step": 269948
    },
    {
      "epoch": 434.02,
      "learning_rate": 0.05661644209742766,
      "loss": 2.7415,
      "step": 269960
    },
    {
      "epoch": 434.05,
      "learning_rate": 0.056613226666559484,
      "loss": 2.7464,
      "step": 269980
    },
    {
      "epoch": 434.08,
      "learning_rate": 0.05661001123569133,
      "loss": 2.769,
      "step": 270000
    },
    {
      "epoch": 434.12,
      "learning_rate": 0.05660679580482314,
      "loss": 2.7353,
      "step": 270020
    },
    {
      "epoch": 434.15,
      "learning_rate": 0.05660358037395499,
      "loss": 2.7433,
      "step": 270040
    },
    {
      "epoch": 434.18,
      "learning_rate": 0.056600364943086824,
      "loss": 2.7468,
      "step": 270060
    },
    {
      "epoch": 434.21,
      "learning_rate": 0.05659714951221865,
      "loss": 2.7376,
      "step": 270080
    },
    {
      "epoch": 434.24,
      "learning_rate": 0.056593934081350494,
      "loss": 2.7423,
      "step": 270100
    },
    {
      "epoch": 434.28,
      "learning_rate": 0.05659071865048231,
      "loss": 2.7797,
      "step": 270120
    },
    {
      "epoch": 434.31,
      "learning_rate": 0.05658750321961416,
      "loss": 2.7468,
      "step": 270140
    },
    {
      "epoch": 434.34,
      "learning_rate": 0.056584287788745996,
      "loss": 2.7352,
      "step": 270160
    },
    {
      "epoch": 434.37,
      "learning_rate": 0.05658107235787782,
      "loss": 2.7384,
      "step": 270180
    },
    {
      "epoch": 434.41,
      "learning_rate": 0.056577856927009645,
      "loss": 2.7295,
      "step": 270200
    },
    {
      "epoch": 434.44,
      "learning_rate": 0.05657464149614148,
      "loss": 2.7632,
      "step": 270220
    },
    {
      "epoch": 434.47,
      "learning_rate": 0.05657142606527332,
      "loss": 2.7281,
      "step": 270240
    },
    {
      "epoch": 434.5,
      "learning_rate": 0.05656821063440514,
      "loss": 2.7297,
      "step": 270260
    },
    {
      "epoch": 434.53,
      "learning_rate": 0.056564995203536986,
      "loss": 2.7257,
      "step": 270280
    },
    {
      "epoch": 434.57,
      "learning_rate": 0.05656177977266881,
      "loss": 2.7513,
      "step": 270300
    },
    {
      "epoch": 434.6,
      "learning_rate": 0.05655856434180065,
      "loss": 2.7481,
      "step": 270320
    },
    {
      "epoch": 434.63,
      "learning_rate": 0.05655534891093248,
      "loss": 2.7226,
      "step": 270340
    },
    {
      "epoch": 434.66,
      "learning_rate": 0.056552133480064305,
      "loss": 2.7852,
      "step": 270360
    },
    {
      "epoch": 434.69,
      "learning_rate": 0.05654891804919615,
      "loss": 2.7643,
      "step": 270380
    },
    {
      "epoch": 434.73,
      "learning_rate": 0.056545702618327975,
      "loss": 2.7488,
      "step": 270400
    },
    {
      "epoch": 434.76,
      "learning_rate": 0.0565424871874598,
      "loss": 2.7709,
      "step": 270420
    },
    {
      "epoch": 434.79,
      "learning_rate": 0.05653927175659165,
      "loss": 2.7817,
      "step": 270440
    },
    {
      "epoch": 434.82,
      "learning_rate": 0.05653605632572348,
      "loss": 2.7431,
      "step": 270460
    },
    {
      "epoch": 434.86,
      "learning_rate": 0.05653284089485531,
      "loss": 2.7392,
      "step": 270480
    },
    {
      "epoch": 434.89,
      "learning_rate": 0.05652962546398715,
      "loss": 2.7435,
      "step": 270500
    },
    {
      "epoch": 434.92,
      "learning_rate": 0.05652641003311897,
      "loss": 2.7483,
      "step": 270520
    },
    {
      "epoch": 434.95,
      "learning_rate": 0.056523194602250804,
      "loss": 2.7429,
      "step": 270540
    },
    {
      "epoch": 434.98,
      "learning_rate": 0.05651997917138263,
      "loss": 2.7479,
      "step": 270560
    },
    {
      "epoch": 435.0,
      "eval_accuracy": {
        "accuracy": 0.41413356137759466
      },
      "eval_loss": 2.7997231483459473,
      "eval_runtime": 2.8954,
      "eval_samples_per_second": 4442.587,
      "eval_steps_per_second": 69.421,
      "step": 270570
    },
    {
      "epoch": 435.02,
      "learning_rate": 0.05651676374051448,
      "loss": 2.7444,
      "step": 270580
    },
    {
      "epoch": 435.05,
      "learning_rate": 0.056513548309646305,
      "loss": 2.7444,
      "step": 270600
    },
    {
      "epoch": 435.08,
      "learning_rate": 0.05651033287877814,
      "loss": 2.7156,
      "step": 270620
    },
    {
      "epoch": 435.11,
      "learning_rate": 0.05650711744790996,
      "loss": 2.7055,
      "step": 270640
    },
    {
      "epoch": 435.14,
      "learning_rate": 0.0565039020170418,
      "loss": 2.7435,
      "step": 270660
    },
    {
      "epoch": 435.18,
      "learning_rate": 0.056500686586173646,
      "loss": 2.7435,
      "step": 270680
    },
    {
      "epoch": 435.21,
      "learning_rate": 0.056497471155305456,
      "loss": 2.7514,
      "step": 270700
    },
    {
      "epoch": 435.24,
      "learning_rate": 0.05649425572443731,
      "loss": 2.729,
      "step": 270720
    },
    {
      "epoch": 435.27,
      "learning_rate": 0.056491040293569134,
      "loss": 2.7493,
      "step": 270740
    },
    {
      "epoch": 435.31,
      "learning_rate": 0.056487824862700965,
      "loss": 2.7597,
      "step": 270760
    },
    {
      "epoch": 435.34,
      "learning_rate": 0.05648460943183281,
      "loss": 2.7509,
      "step": 270780
    },
    {
      "epoch": 435.37,
      "learning_rate": 0.05648139400096463,
      "loss": 2.7199,
      "step": 270800
    },
    {
      "epoch": 435.4,
      "learning_rate": 0.056478178570096474,
      "loss": 2.7264,
      "step": 270820
    },
    {
      "epoch": 435.43,
      "learning_rate": 0.0564749631392283,
      "loss": 2.7424,
      "step": 270840
    },
    {
      "epoch": 435.47,
      "learning_rate": 0.05647174770836014,
      "loss": 2.7208,
      "step": 270860
    },
    {
      "epoch": 435.5,
      "learning_rate": 0.05646853227749196,
      "loss": 2.7336,
      "step": 270880
    },
    {
      "epoch": 435.53,
      "learning_rate": 0.05646531684662379,
      "loss": 2.7373,
      "step": 270900
    },
    {
      "epoch": 435.56,
      "learning_rate": 0.05646210141575564,
      "loss": 2.7476,
      "step": 270920
    },
    {
      "epoch": 435.59,
      "learning_rate": 0.056459046756430875,
      "loss": 2.7367,
      "step": 270940
    },
    {
      "epoch": 435.63,
      "learning_rate": 0.0564558313255627,
      "loss": 2.7585,
      "step": 270960
    },
    {
      "epoch": 435.66,
      "learning_rate": 0.05645261589469454,
      "loss": 2.7654,
      "step": 270980
    },
    {
      "epoch": 435.69,
      "learning_rate": 0.05644940046382638,
      "loss": 2.754,
      "step": 271000
    },
    {
      "epoch": 435.72,
      "learning_rate": 0.0564461850329582,
      "loss": 2.7597,
      "step": 271020
    },
    {
      "epoch": 435.76,
      "learning_rate": 0.05644296960209003,
      "loss": 2.7483,
      "step": 271040
    },
    {
      "epoch": 435.79,
      "learning_rate": 0.05643975417122186,
      "loss": 2.7362,
      "step": 271060
    },
    {
      "epoch": 435.82,
      "learning_rate": 0.0564365387403537,
      "loss": 2.7093,
      "step": 271080
    },
    {
      "epoch": 435.85,
      "learning_rate": 0.05643332330948553,
      "loss": 2.7431,
      "step": 271100
    },
    {
      "epoch": 435.88,
      "learning_rate": 0.05643010787861737,
      "loss": 2.7446,
      "step": 271120
    },
    {
      "epoch": 435.92,
      "learning_rate": 0.05642689244774921,
      "loss": 2.7122,
      "step": 271140
    },
    {
      "epoch": 435.95,
      "learning_rate": 0.05642367701688103,
      "loss": 2.751,
      "step": 271160
    },
    {
      "epoch": 435.98,
      "learning_rate": 0.05642046158601286,
      "loss": 2.7565,
      "step": 271180
    },
    {
      "epoch": 436.0,
      "eval_accuracy": {
        "accuracy": 0.40076187514576694
      },
      "eval_loss": 2.8370778560638428,
      "eval_runtime": 3.1923,
      "eval_samples_per_second": 4029.377,
      "eval_steps_per_second": 62.964,
      "step": 271192
    },
    {
      "epoch": 436.01,
      "learning_rate": 0.0564172461551447,
      "loss": 2.7328,
      "step": 271200
    },
    {
      "epoch": 436.05,
      "learning_rate": 0.05641403072427653,
      "loss": 2.7332,
      "step": 271220
    },
    {
      "epoch": 436.08,
      "learning_rate": 0.056410815293408356,
      "loss": 2.7415,
      "step": 271240
    },
    {
      "epoch": 436.11,
      "learning_rate": 0.056407599862540195,
      "loss": 2.7645,
      "step": 271260
    },
    {
      "epoch": 436.14,
      "learning_rate": 0.05640438443167203,
      "loss": 2.724,
      "step": 271280
    },
    {
      "epoch": 436.17,
      "learning_rate": 0.05640116900080386,
      "loss": 2.723,
      "step": 271300
    },
    {
      "epoch": 436.21,
      "learning_rate": 0.05639795356993569,
      "loss": 2.7319,
      "step": 271320
    },
    {
      "epoch": 436.24,
      "learning_rate": 0.05639473813906753,
      "loss": 2.7833,
      "step": 271340
    },
    {
      "epoch": 436.27,
      "learning_rate": 0.05639152270819936,
      "loss": 2.7585,
      "step": 271360
    },
    {
      "epoch": 436.3,
      "learning_rate": 0.0563883072773312,
      "loss": 2.7439,
      "step": 271380
    },
    {
      "epoch": 436.33,
      "learning_rate": 0.05638509184646302,
      "loss": 2.7281,
      "step": 271400
    },
    {
      "epoch": 436.37,
      "learning_rate": 0.05638187641559486,
      "loss": 2.7538,
      "step": 271420
    },
    {
      "epoch": 436.4,
      "learning_rate": 0.05637866098472669,
      "loss": 2.7328,
      "step": 271440
    },
    {
      "epoch": 436.43,
      "learning_rate": 0.05637544555385852,
      "loss": 2.7198,
      "step": 271460
    },
    {
      "epoch": 436.46,
      "learning_rate": 0.05637223012299036,
      "loss": 2.7347,
      "step": 271480
    },
    {
      "epoch": 436.5,
      "learning_rate": 0.05636901469212219,
      "loss": 2.7358,
      "step": 271500
    },
    {
      "epoch": 436.53,
      "learning_rate": 0.056365799261254027,
      "loss": 2.7408,
      "step": 271520
    },
    {
      "epoch": 436.56,
      "learning_rate": 0.056362583830385865,
      "loss": 2.7254,
      "step": 271540
    },
    {
      "epoch": 436.59,
      "learning_rate": 0.05635936839951769,
      "loss": 2.7584,
      "step": 271560
    },
    {
      "epoch": 436.62,
      "learning_rate": 0.05635615296864952,
      "loss": 2.7537,
      "step": 271580
    },
    {
      "epoch": 436.66,
      "learning_rate": 0.056352937537781346,
      "loss": 2.7682,
      "step": 271600
    },
    {
      "epoch": 436.69,
      "learning_rate": 0.05634972210691319,
      "loss": 2.7473,
      "step": 271620
    },
    {
      "epoch": 436.72,
      "learning_rate": 0.056346506676045016,
      "loss": 2.7212,
      "step": 271640
    },
    {
      "epoch": 436.75,
      "learning_rate": 0.056343291245176855,
      "loss": 2.7292,
      "step": 271660
    },
    {
      "epoch": 436.78,
      "learning_rate": 0.05634007581430869,
      "loss": 2.7364,
      "step": 271680
    },
    {
      "epoch": 436.82,
      "learning_rate": 0.05633686038344052,
      "loss": 2.7453,
      "step": 271700
    },
    {
      "epoch": 436.85,
      "learning_rate": 0.05633364495257235,
      "loss": 2.7396,
      "step": 271720
    },
    {
      "epoch": 436.88,
      "learning_rate": 0.056330429521704174,
      "loss": 2.7395,
      "step": 271740
    },
    {
      "epoch": 436.91,
      "learning_rate": 0.05632721409083602,
      "loss": 2.7643,
      "step": 271760
    },
    {
      "epoch": 436.95,
      "learning_rate": 0.056323998659967844,
      "loss": 2.7383,
      "step": 271780
    },
    {
      "epoch": 436.98,
      "learning_rate": 0.05632078322909968,
      "loss": 2.7093,
      "step": 271800
    },
    {
      "epoch": 437.0,
      "eval_accuracy": {
        "accuracy": 0.3972634688641841
      },
      "eval_loss": 2.902559757232666,
      "eval_runtime": 3.1215,
      "eval_samples_per_second": 4120.822,
      "eval_steps_per_second": 64.393,
      "step": 271814
    },
    {
      "epoch": 437.01,
      "learning_rate": 0.05631756779823152,
      "loss": 2.7553,
      "step": 271820
    },
    {
      "epoch": 437.04,
      "learning_rate": 0.056314352367363346,
      "loss": 2.7378,
      "step": 271840
    },
    {
      "epoch": 437.07,
      "learning_rate": 0.05631113693649518,
      "loss": 2.7265,
      "step": 271860
    },
    {
      "epoch": 437.11,
      "learning_rate": 0.056307921505627016,
      "loss": 2.7132,
      "step": 271880
    },
    {
      "epoch": 437.14,
      "learning_rate": 0.05630470607475885,
      "loss": 2.7221,
      "step": 271900
    },
    {
      "epoch": 437.17,
      "learning_rate": 0.05630149064389067,
      "loss": 2.7599,
      "step": 271920
    },
    {
      "epoch": 437.2,
      "learning_rate": 0.05629827521302251,
      "loss": 2.743,
      "step": 271940
    },
    {
      "epoch": 437.23,
      "learning_rate": 0.05629505978215435,
      "loss": 2.737,
      "step": 271960
    },
    {
      "epoch": 437.27,
      "learning_rate": 0.056291844351286174,
      "loss": 2.7469,
      "step": 271980
    },
    {
      "epoch": 437.3,
      "learning_rate": 0.056288628920418006,
      "loss": 2.7209,
      "step": 272000
    },
    {
      "epoch": 437.33,
      "learning_rate": 0.056285413489549845,
      "loss": 2.7443,
      "step": 272020
    },
    {
      "epoch": 437.36,
      "learning_rate": 0.056282198058681676,
      "loss": 2.7323,
      "step": 272040
    },
    {
      "epoch": 437.4,
      "learning_rate": 0.056278982627813515,
      "loss": 2.7376,
      "step": 272060
    },
    {
      "epoch": 437.43,
      "learning_rate": 0.056275767196945325,
      "loss": 2.7773,
      "step": 272080
    },
    {
      "epoch": 437.46,
      "learning_rate": 0.05627255176607718,
      "loss": 2.7561,
      "step": 272100
    },
    {
      "epoch": 437.49,
      "learning_rate": 0.05626933633520901,
      "loss": 2.7639,
      "step": 272120
    },
    {
      "epoch": 437.52,
      "learning_rate": 0.056266120904340834,
      "loss": 2.7423,
      "step": 272140
    },
    {
      "epoch": 437.56,
      "learning_rate": 0.05626290547347268,
      "loss": 2.7383,
      "step": 272160
    },
    {
      "epoch": 437.59,
      "learning_rate": 0.0562596900426045,
      "loss": 2.7632,
      "step": 272180
    },
    {
      "epoch": 437.62,
      "learning_rate": 0.05625647461173634,
      "loss": 2.769,
      "step": 272200
    },
    {
      "epoch": 437.65,
      "learning_rate": 0.05625325918086818,
      "loss": 2.7452,
      "step": 272220
    },
    {
      "epoch": 437.68,
      "learning_rate": 0.056250043750000006,
      "loss": 2.7288,
      "step": 272240
    },
    {
      "epoch": 437.72,
      "learning_rate": 0.05624682831913184,
      "loss": 2.7502,
      "step": 272260
    },
    {
      "epoch": 437.75,
      "learning_rate": 0.05624361288826366,
      "loss": 2.7341,
      "step": 272280
    },
    {
      "epoch": 437.78,
      "learning_rate": 0.05624039745739551,
      "loss": 2.7334,
      "step": 272300
    },
    {
      "epoch": 437.81,
      "learning_rate": 0.056237182026527326,
      "loss": 2.7584,
      "step": 272320
    },
    {
      "epoch": 437.85,
      "learning_rate": 0.05623396659565917,
      "loss": 2.7495,
      "step": 272340
    },
    {
      "epoch": 437.88,
      "learning_rate": 0.05623075116479101,
      "loss": 2.7747,
      "step": 272360
    },
    {
      "epoch": 437.91,
      "learning_rate": 0.056227535733922834,
      "loss": 2.7304,
      "step": 272380
    },
    {
      "epoch": 437.94,
      "learning_rate": 0.056224320303054666,
      "loss": 2.7306,
      "step": 272400
    },
    {
      "epoch": 437.97,
      "learning_rate": 0.05622110487218649,
      "loss": 2.7366,
      "step": 272420
    },
    {
      "epoch": 438.0,
      "eval_accuracy": {
        "accuracy": 0.3982741195677525
      },
      "eval_loss": 2.8933205604553223,
      "eval_runtime": 2.8621,
      "eval_samples_per_second": 4494.239,
      "eval_steps_per_second": 70.228,
      "step": 272436
    },
    {
      "epoch": 438.01,
      "learning_rate": 0.056217889441318336,
      "loss": 2.7344,
      "step": 272440
    },
    {
      "epoch": 438.04,
      "learning_rate": 0.05621467401045016,
      "loss": 2.7515,
      "step": 272460
    },
    {
      "epoch": 438.07,
      "learning_rate": 0.056211458579582,
      "loss": 2.7526,
      "step": 272480
    },
    {
      "epoch": 438.1,
      "learning_rate": 0.05620824314871384,
      "loss": 2.7387,
      "step": 272500
    },
    {
      "epoch": 438.14,
      "learning_rate": 0.05620502771784566,
      "loss": 2.7374,
      "step": 272520
    },
    {
      "epoch": 438.17,
      "learning_rate": 0.056201812286977494,
      "loss": 2.7378,
      "step": 272540
    },
    {
      "epoch": 438.2,
      "learning_rate": 0.05619859685610933,
      "loss": 2.7223,
      "step": 272560
    },
    {
      "epoch": 438.23,
      "learning_rate": 0.056195381425241164,
      "loss": 2.733,
      "step": 272580
    },
    {
      "epoch": 438.26,
      "learning_rate": 0.05619216599437299,
      "loss": 2.7386,
      "step": 272600
    },
    {
      "epoch": 438.3,
      "learning_rate": 0.056188950563504814,
      "loss": 2.7449,
      "step": 272620
    },
    {
      "epoch": 438.33,
      "learning_rate": 0.056185735132636666,
      "loss": 2.7597,
      "step": 272640
    },
    {
      "epoch": 438.36,
      "learning_rate": 0.05618251970176849,
      "loss": 2.7694,
      "step": 272660
    },
    {
      "epoch": 438.39,
      "learning_rate": 0.05617930427090032,
      "loss": 2.7541,
      "step": 272680
    },
    {
      "epoch": 438.42,
      "learning_rate": 0.05617608884003216,
      "loss": 2.7396,
      "step": 272700
    },
    {
      "epoch": 438.46,
      "learning_rate": 0.056172873409163986,
      "loss": 2.7606,
      "step": 272720
    },
    {
      "epoch": 438.49,
      "learning_rate": 0.05616965797829583,
      "loss": 2.7652,
      "step": 272740
    },
    {
      "epoch": 438.52,
      "learning_rate": 0.05616644254742764,
      "loss": 2.7442,
      "step": 272760
    },
    {
      "epoch": 438.55,
      "learning_rate": 0.056163227116559494,
      "loss": 2.7348,
      "step": 272780
    },
    {
      "epoch": 438.59,
      "learning_rate": 0.056160011685691326,
      "loss": 2.7359,
      "step": 272800
    },
    {
      "epoch": 438.62,
      "learning_rate": 0.05615679625482315,
      "loss": 2.7596,
      "step": 272820
    },
    {
      "epoch": 438.65,
      "learning_rate": 0.056153580823954996,
      "loss": 2.7486,
      "step": 272840
    },
    {
      "epoch": 438.68,
      "learning_rate": 0.056150365393086814,
      "loss": 2.7627,
      "step": 272860
    },
    {
      "epoch": 438.71,
      "learning_rate": 0.05614714996221866,
      "loss": 2.7341,
      "step": 272880
    },
    {
      "epoch": 438.75,
      "learning_rate": 0.0561439345313505,
      "loss": 2.7586,
      "step": 272900
    },
    {
      "epoch": 438.78,
      "learning_rate": 0.05614071910048232,
      "loss": 2.767,
      "step": 272920
    },
    {
      "epoch": 438.81,
      "learning_rate": 0.05613750366961415,
      "loss": 2.7311,
      "step": 272940
    },
    {
      "epoch": 438.84,
      "learning_rate": 0.05613428823874598,
      "loss": 2.7261,
      "step": 272960
    },
    {
      "epoch": 438.87,
      "learning_rate": 0.056131072807877824,
      "loss": 2.7257,
      "step": 272980
    },
    {
      "epoch": 438.91,
      "learning_rate": 0.05612785737700964,
      "loss": 2.7393,
      "step": 273000
    },
    {
      "epoch": 438.94,
      "learning_rate": 0.05612464194614149,
      "loss": 2.7781,
      "step": 273020
    },
    {
      "epoch": 438.97,
      "learning_rate": 0.05612142651527331,
      "loss": 2.7377,
      "step": 273040
    },
    {
      "epoch": 439.0,
      "eval_accuracy": {
        "accuracy": 0.4065148099199254
      },
      "eval_loss": 2.8273696899414062,
      "eval_runtime": 3.0783,
      "eval_samples_per_second": 4178.563,
      "eval_steps_per_second": 65.295,
      "step": 273058
    },
    {
      "epoch": 439.0,
      "learning_rate": 0.05611821108440515,
      "loss": 2.7291,
      "step": 273060
    },
    {
      "epoch": 439.04,
      "learning_rate": 0.05611499565353698,
      "loss": 2.7168,
      "step": 273080
    },
    {
      "epoch": 439.07,
      "learning_rate": 0.05611178022266881,
      "loss": 2.7216,
      "step": 273100
    },
    {
      "epoch": 439.1,
      "learning_rate": 0.05610856479180065,
      "loss": 2.7346,
      "step": 273120
    },
    {
      "epoch": 439.13,
      "learning_rate": 0.05610534936093248,
      "loss": 2.7406,
      "step": 273140
    },
    {
      "epoch": 439.16,
      "learning_rate": 0.0561021339300643,
      "loss": 2.7512,
      "step": 273160
    },
    {
      "epoch": 439.2,
      "learning_rate": 0.056098918499196154,
      "loss": 2.7849,
      "step": 273180
    },
    {
      "epoch": 439.23,
      "learning_rate": 0.05609570306832798,
      "loss": 2.7898,
      "step": 273200
    },
    {
      "epoch": 439.26,
      "learning_rate": 0.05609248763745981,
      "loss": 2.7658,
      "step": 273220
    },
    {
      "epoch": 439.29,
      "learning_rate": 0.05608927220659165,
      "loss": 2.7409,
      "step": 273240
    },
    {
      "epoch": 439.32,
      "learning_rate": 0.056086056775723474,
      "loss": 2.7063,
      "step": 273260
    },
    {
      "epoch": 439.36,
      "learning_rate": 0.056082841344855305,
      "loss": 2.7133,
      "step": 273280
    },
    {
      "epoch": 439.39,
      "learning_rate": 0.05607962591398713,
      "loss": 2.7403,
      "step": 273300
    },
    {
      "epoch": 439.42,
      "learning_rate": 0.05607641048311898,
      "loss": 2.7406,
      "step": 273320
    },
    {
      "epoch": 439.45,
      "learning_rate": 0.05607319505225081,
      "loss": 2.733,
      "step": 273340
    },
    {
      "epoch": 439.49,
      "learning_rate": 0.05606997962138264,
      "loss": 2.7375,
      "step": 273360
    },
    {
      "epoch": 439.52,
      "learning_rate": 0.05606676419051446,
      "loss": 2.7485,
      "step": 273380
    },
    {
      "epoch": 439.55,
      "learning_rate": 0.0560635487596463,
      "loss": 2.7488,
      "step": 273400
    },
    {
      "epoch": 439.58,
      "learning_rate": 0.05606033332877815,
      "loss": 2.751,
      "step": 273420
    },
    {
      "epoch": 439.61,
      "learning_rate": 0.05605711789790996,
      "loss": 2.7157,
      "step": 273440
    },
    {
      "epoch": 439.65,
      "learning_rate": 0.05605390246704181,
      "loss": 2.7401,
      "step": 273460
    },
    {
      "epoch": 439.68,
      "learning_rate": 0.056050687036173635,
      "loss": 2.7426,
      "step": 273480
    },
    {
      "epoch": 439.71,
      "learning_rate": 0.05604747160530547,
      "loss": 2.7525,
      "step": 273500
    },
    {
      "epoch": 439.74,
      "learning_rate": 0.05604425617443731,
      "loss": 2.717,
      "step": 273520
    },
    {
      "epoch": 439.77,
      "learning_rate": 0.05604104074356913,
      "loss": 2.7223,
      "step": 273540
    },
    {
      "epoch": 439.81,
      "learning_rate": 0.05603798608424437,
      "loss": 2.7385,
      "step": 273560
    },
    {
      "epoch": 439.84,
      "learning_rate": 0.05603477065337621,
      "loss": 2.7238,
      "step": 273580
    },
    {
      "epoch": 439.87,
      "learning_rate": 0.05603155522250805,
      "loss": 2.7206,
      "step": 273600
    },
    {
      "epoch": 439.9,
      "learning_rate": 0.056028339791639875,
      "loss": 2.7495,
      "step": 273620
    },
    {
      "epoch": 439.94,
      "learning_rate": 0.05602512436077171,
      "loss": 2.7626,
      "step": 273640
    },
    {
      "epoch": 439.97,
      "learning_rate": 0.05602190892990353,
      "loss": 2.78,
      "step": 273660
    },
    {
      "epoch": 440.0,
      "learning_rate": 0.05601869349903538,
      "loss": 2.7593,
      "step": 273680
    },
    {
      "epoch": 440.0,
      "eval_accuracy": {
        "accuracy": 0.4027054341910907
      },
      "eval_loss": 2.8562986850738525,
      "eval_runtime": 3.2681,
      "eval_samples_per_second": 3935.872,
      "eval_steps_per_second": 61.503,
      "step": 273680
    },
    {
      "epoch": 440.03,
      "learning_rate": 0.0560154780681672,
      "loss": 2.7593,
      "step": 273700
    },
    {
      "epoch": 440.06,
      "learning_rate": 0.05601226263729904,
      "loss": 2.7211,
      "step": 273720
    },
    {
      "epoch": 440.1,
      "learning_rate": 0.05600904720643088,
      "loss": 2.7398,
      "step": 273740
    },
    {
      "epoch": 440.13,
      "learning_rate": 0.0560058317755627,
      "loss": 2.709,
      "step": 273760
    },
    {
      "epoch": 440.16,
      "learning_rate": 0.056002616344694535,
      "loss": 2.7403,
      "step": 273780
    },
    {
      "epoch": 440.19,
      "learning_rate": 0.05599940091382636,
      "loss": 2.7193,
      "step": 273800
    },
    {
      "epoch": 440.23,
      "learning_rate": 0.055996185482958205,
      "loss": 2.7368,
      "step": 273820
    },
    {
      "epoch": 440.26,
      "learning_rate": 0.05599297005209003,
      "loss": 2.7523,
      "step": 273840
    },
    {
      "epoch": 440.29,
      "learning_rate": 0.05598975462122187,
      "loss": 2.7577,
      "step": 273860
    },
    {
      "epoch": 440.32,
      "learning_rate": 0.05598653919035371,
      "loss": 2.7389,
      "step": 273880
    },
    {
      "epoch": 440.35,
      "learning_rate": 0.05598332375948553,
      "loss": 2.7455,
      "step": 273900
    },
    {
      "epoch": 440.39,
      "learning_rate": 0.05598010832861736,
      "loss": 2.7319,
      "step": 273920
    },
    {
      "epoch": 440.42,
      "learning_rate": 0.0559768928977492,
      "loss": 2.7125,
      "step": 273940
    },
    {
      "epoch": 440.45,
      "learning_rate": 0.05597367746688103,
      "loss": 2.7253,
      "step": 273960
    },
    {
      "epoch": 440.48,
      "learning_rate": 0.05597046203601286,
      "loss": 2.734,
      "step": 273980
    },
    {
      "epoch": 440.51,
      "learning_rate": 0.055967246605144697,
      "loss": 2.7319,
      "step": 274000
    },
    {
      "epoch": 440.55,
      "learning_rate": 0.055964031174276535,
      "loss": 2.7203,
      "step": 274020
    },
    {
      "epoch": 440.58,
      "learning_rate": 0.05596081574340836,
      "loss": 2.7365,
      "step": 274040
    },
    {
      "epoch": 440.61,
      "learning_rate": 0.05595760031254019,
      "loss": 2.7317,
      "step": 274060
    },
    {
      "epoch": 440.64,
      "learning_rate": 0.05595438488167203,
      "loss": 2.7531,
      "step": 274080
    },
    {
      "epoch": 440.68,
      "learning_rate": 0.05595116945080386,
      "loss": 2.7623,
      "step": 274100
    },
    {
      "epoch": 440.71,
      "learning_rate": 0.0559479540199357,
      "loss": 2.7142,
      "step": 274120
    },
    {
      "epoch": 440.74,
      "learning_rate": 0.055944738589067525,
      "loss": 2.7664,
      "step": 274140
    },
    {
      "epoch": 440.77,
      "learning_rate": 0.05594152315819936,
      "loss": 2.7589,
      "step": 274160
    },
    {
      "epoch": 440.8,
      "learning_rate": 0.055938307727331195,
      "loss": 2.7722,
      "step": 274180
    },
    {
      "epoch": 440.84,
      "learning_rate": 0.05593509229646302,
      "loss": 2.7544,
      "step": 274200
    },
    {
      "epoch": 440.87,
      "learning_rate": 0.055931876865594865,
      "loss": 2.7492,
      "step": 274220
    },
    {
      "epoch": 440.9,
      "learning_rate": 0.05592866143472669,
      "loss": 2.7482,
      "step": 274240
    },
    {
      "epoch": 440.93,
      "learning_rate": 0.05592544600385853,
      "loss": 2.7196,
      "step": 274260
    },
    {
      "epoch": 440.96,
      "learning_rate": 0.05592223057299037,
      "loss": 2.7459,
      "step": 274280
    },
    {
      "epoch": 441.0,
      "learning_rate": 0.05591901514212219,
      "loss": 2.7341,
      "step": 274300
    },
    {
      "epoch": 441.0,
      "eval_accuracy": {
        "accuracy": 0.4095467620306305
      },
      "eval_loss": 2.8464393615722656,
      "eval_runtime": 3.2597,
      "eval_samples_per_second": 3946.12,
      "eval_steps_per_second": 61.663,
      "step": 274302
    },
    {
      "epoch": 441.03,
      "learning_rate": 0.05591579971125402,
      "loss": 2.728,
      "step": 274320
    },
    {
      "epoch": 441.06,
      "learning_rate": 0.05591258428038585,
      "loss": 2.7517,
      "step": 274340
    },
    {
      "epoch": 441.09,
      "learning_rate": 0.05590936884951769,
      "loss": 2.7288,
      "step": 274360
    },
    {
      "epoch": 441.13,
      "learning_rate": 0.05590615341864951,
      "loss": 2.7377,
      "step": 274380
    },
    {
      "epoch": 441.16,
      "learning_rate": 0.055902937987781356,
      "loss": 2.7182,
      "step": 274400
    },
    {
      "epoch": 441.19,
      "learning_rate": 0.055899722556913195,
      "loss": 2.7276,
      "step": 274420
    },
    {
      "epoch": 441.22,
      "learning_rate": 0.05589650712604502,
      "loss": 2.7424,
      "step": 274440
    },
    {
      "epoch": 441.25,
      "learning_rate": 0.05589329169517685,
      "loss": 2.734,
      "step": 274460
    },
    {
      "epoch": 441.29,
      "learning_rate": 0.055890076264308676,
      "loss": 2.746,
      "step": 274480
    },
    {
      "epoch": 441.32,
      "learning_rate": 0.05588686083344052,
      "loss": 2.7279,
      "step": 274500
    },
    {
      "epoch": 441.35,
      "learning_rate": 0.055883645402572346,
      "loss": 2.7121,
      "step": 274520
    },
    {
      "epoch": 441.38,
      "learning_rate": 0.055880429971704185,
      "loss": 2.7289,
      "step": 274540
    },
    {
      "epoch": 441.41,
      "learning_rate": 0.05587721454083602,
      "loss": 2.7368,
      "step": 274560
    },
    {
      "epoch": 441.45,
      "learning_rate": 0.05587399910996785,
      "loss": 2.7418,
      "step": 274580
    },
    {
      "epoch": 441.48,
      "learning_rate": 0.05587078367909968,
      "loss": 2.7258,
      "step": 274600
    },
    {
      "epoch": 441.51,
      "learning_rate": 0.05586756824823152,
      "loss": 2.7261,
      "step": 274620
    },
    {
      "epoch": 441.54,
      "learning_rate": 0.05586435281736335,
      "loss": 2.7267,
      "step": 274640
    },
    {
      "epoch": 441.58,
      "learning_rate": 0.055861137386495174,
      "loss": 2.694,
      "step": 274660
    },
    {
      "epoch": 441.61,
      "learning_rate": 0.05585792195562701,
      "loss": 2.7659,
      "step": 274680
    },
    {
      "epoch": 441.64,
      "learning_rate": 0.05585470652475885,
      "loss": 2.7633,
      "step": 274700
    },
    {
      "epoch": 441.67,
      "learning_rate": 0.055851491093890676,
      "loss": 2.7417,
      "step": 274720
    },
    {
      "epoch": 441.7,
      "learning_rate": 0.05584827566302251,
      "loss": 2.7457,
      "step": 274740
    },
    {
      "epoch": 441.74,
      "learning_rate": 0.055845060232154346,
      "loss": 2.7295,
      "step": 274760
    },
    {
      "epoch": 441.77,
      "learning_rate": 0.05584184480128618,
      "loss": 2.7699,
      "step": 274780
    },
    {
      "epoch": 441.8,
      "learning_rate": 0.055838629370418016,
      "loss": 2.7451,
      "step": 274800
    },
    {
      "epoch": 441.83,
      "learning_rate": 0.05583541393954983,
      "loss": 2.7608,
      "step": 274820
    },
    {
      "epoch": 441.86,
      "learning_rate": 0.05583219850868168,
      "loss": 2.7786,
      "step": 274840
    },
    {
      "epoch": 441.9,
      "learning_rate": 0.05582898307781351,
      "loss": 2.7645,
      "step": 274860
    },
    {
      "epoch": 441.93,
      "learning_rate": 0.055825767646945336,
      "loss": 2.7481,
      "step": 274880
    },
    {
      "epoch": 441.96,
      "learning_rate": 0.05582255221607718,
      "loss": 2.7448,
      "step": 274900
    },
    {
      "epoch": 441.99,
      "learning_rate": 0.055819336785209,
      "loss": 2.7531,
      "step": 274920
    },
    {
      "epoch": 442.0,
      "eval_accuracy": {
        "accuracy": 0.40604835574904763
      },
      "eval_loss": 2.814817190170288,
      "eval_runtime": 2.7454,
      "eval_samples_per_second": 4685.228,
      "eval_steps_per_second": 73.212,
      "step": 274924
    },
    {
      "epoch": 442.03,
      "learning_rate": 0.055816121354340845,
      "loss": 2.7337,
      "step": 274940
    },
    {
      "epoch": 442.06,
      "learning_rate": 0.05581290592347268,
      "loss": 2.7457,
      "step": 274960
    },
    {
      "epoch": 442.09,
      "learning_rate": 0.05580969049260451,
      "loss": 2.7129,
      "step": 274980
    },
    {
      "epoch": 442.12,
      "learning_rate": 0.05580647506173634,
      "loss": 2.7403,
      "step": 275000
    },
    {
      "epoch": 442.15,
      "learning_rate": 0.055803259630868164,
      "loss": 2.7492,
      "step": 275020
    },
    {
      "epoch": 442.19,
      "learning_rate": 0.05580004420000001,
      "loss": 2.7359,
      "step": 275040
    },
    {
      "epoch": 442.22,
      "learning_rate": 0.05579682876913183,
      "loss": 2.7212,
      "step": 275060
    },
    {
      "epoch": 442.25,
      "learning_rate": 0.05579361333826367,
      "loss": 2.7275,
      "step": 275080
    },
    {
      "epoch": 442.28,
      "learning_rate": 0.05579039790739551,
      "loss": 2.7048,
      "step": 275100
    },
    {
      "epoch": 442.32,
      "learning_rate": 0.055787182476527336,
      "loss": 2.7376,
      "step": 275120
    },
    {
      "epoch": 442.35,
      "learning_rate": 0.05578396704565917,
      "loss": 2.7437,
      "step": 275140
    },
    {
      "epoch": 442.38,
      "learning_rate": 0.05578075161479099,
      "loss": 2.718,
      "step": 275160
    },
    {
      "epoch": 442.41,
      "learning_rate": 0.05577753618392284,
      "loss": 2.7346,
      "step": 275180
    },
    {
      "epoch": 442.44,
      "learning_rate": 0.05577432075305466,
      "loss": 2.7216,
      "step": 275200
    },
    {
      "epoch": 442.48,
      "learning_rate": 0.0557711053221865,
      "loss": 2.7436,
      "step": 275220
    },
    {
      "epoch": 442.51,
      "learning_rate": 0.05576788989131834,
      "loss": 2.7266,
      "step": 275240
    },
    {
      "epoch": 442.54,
      "learning_rate": 0.055764674460450164,
      "loss": 2.761,
      "step": 275260
    },
    {
      "epoch": 442.57,
      "learning_rate": 0.055761459029581996,
      "loss": 2.7423,
      "step": 275280
    },
    {
      "epoch": 442.6,
      "learning_rate": 0.055758243598713834,
      "loss": 2.7212,
      "step": 275300
    },
    {
      "epoch": 442.64,
      "learning_rate": 0.055755028167845666,
      "loss": 2.7286,
      "step": 275320
    },
    {
      "epoch": 442.67,
      "learning_rate": 0.05575181273697749,
      "loss": 2.7677,
      "step": 275340
    },
    {
      "epoch": 442.7,
      "learning_rate": 0.055748597306109315,
      "loss": 2.7345,
      "step": 275360
    },
    {
      "epoch": 442.73,
      "learning_rate": 0.05574538187524117,
      "loss": 2.7534,
      "step": 275380
    },
    {
      "epoch": 442.77,
      "learning_rate": 0.05574216644437299,
      "loss": 2.7317,
      "step": 275400
    },
    {
      "epoch": 442.8,
      "learning_rate": 0.055738951013504824,
      "loss": 2.7392,
      "step": 275420
    },
    {
      "epoch": 442.83,
      "learning_rate": 0.05573573558263666,
      "loss": 2.7236,
      "step": 275440
    },
    {
      "epoch": 442.86,
      "learning_rate": 0.05573252015176849,
      "loss": 2.7402,
      "step": 275460
    },
    {
      "epoch": 442.89,
      "learning_rate": 0.05572930472090033,
      "loss": 2.7428,
      "step": 275480
    },
    {
      "epoch": 442.93,
      "learning_rate": 0.055726089290032144,
      "loss": 2.7272,
      "step": 275500
    },
    {
      "epoch": 442.96,
      "learning_rate": 0.055722873859163996,
      "loss": 2.7185,
      "step": 275520
    },
    {
      "epoch": 442.99,
      "learning_rate": 0.05571965842829583,
      "loss": 2.7345,
      "step": 275540
    },
    {
      "epoch": 443.0,
      "eval_accuracy": {
        "accuracy": 0.39928477027132087
      },
      "eval_loss": 2.859665870666504,
      "eval_runtime": 2.8303,
      "eval_samples_per_second": 4544.695,
      "eval_steps_per_second": 71.016,
      "step": 275546
    },
    {
      "epoch": 443.02,
      "learning_rate": 0.05571644299742765,
      "loss": 2.748,
      "step": 275560
    },
    {
      "epoch": 443.05,
      "learning_rate": 0.0557132275665595,
      "loss": 2.7211,
      "step": 275580
    },
    {
      "epoch": 443.09,
      "learning_rate": 0.055710012135691316,
      "loss": 2.7541,
      "step": 275600
    },
    {
      "epoch": 443.12,
      "learning_rate": 0.05570679670482316,
      "loss": 2.7111,
      "step": 275620
    },
    {
      "epoch": 443.15,
      "learning_rate": 0.055703581273955,
      "loss": 2.7376,
      "step": 275640
    },
    {
      "epoch": 443.18,
      "learning_rate": 0.055700365843086824,
      "loss": 2.7429,
      "step": 275660
    },
    {
      "epoch": 443.22,
      "learning_rate": 0.05569715041221865,
      "loss": 2.7195,
      "step": 275680
    },
    {
      "epoch": 443.25,
      "learning_rate": 0.05569393498135048,
      "loss": 2.736,
      "step": 275700
    },
    {
      "epoch": 443.28,
      "learning_rate": 0.055690719550482326,
      "loss": 2.7354,
      "step": 275720
    },
    {
      "epoch": 443.31,
      "learning_rate": 0.055687504119614144,
      "loss": 2.7513,
      "step": 275740
    },
    {
      "epoch": 443.34,
      "learning_rate": 0.05568428868874599,
      "loss": 2.7404,
      "step": 275760
    },
    {
      "epoch": 443.38,
      "learning_rate": 0.055681073257877814,
      "loss": 2.7073,
      "step": 275780
    },
    {
      "epoch": 443.41,
      "learning_rate": 0.05567785782700965,
      "loss": 2.7585,
      "step": 275800
    },
    {
      "epoch": 443.44,
      "learning_rate": 0.05567480316768489,
      "loss": 2.7671,
      "step": 275820
    },
    {
      "epoch": 443.47,
      "learning_rate": 0.055671587736816734,
      "loss": 2.7539,
      "step": 275840
    },
    {
      "epoch": 443.5,
      "learning_rate": 0.055668372305948545,
      "loss": 2.7501,
      "step": 275860
    },
    {
      "epoch": 443.54,
      "learning_rate": 0.05566515687508039,
      "loss": 2.7781,
      "step": 275880
    },
    {
      "epoch": 443.57,
      "learning_rate": 0.055661941444212215,
      "loss": 2.7592,
      "step": 275900
    },
    {
      "epoch": 443.6,
      "learning_rate": 0.055658726013344054,
      "loss": 2.7378,
      "step": 275920
    },
    {
      "epoch": 443.63,
      "learning_rate": 0.05565551058247589,
      "loss": 2.7579,
      "step": 275940
    },
    {
      "epoch": 443.67,
      "learning_rate": 0.05565229515160772,
      "loss": 2.7156,
      "step": 275960
    },
    {
      "epoch": 443.7,
      "learning_rate": 0.05564907972073955,
      "loss": 2.7721,
      "step": 275980
    },
    {
      "epoch": 443.73,
      "learning_rate": 0.05564586428987139,
      "loss": 2.7511,
      "step": 276000
    },
    {
      "epoch": 443.76,
      "learning_rate": 0.05564264885900322,
      "loss": 2.7483,
      "step": 276020
    },
    {
      "epoch": 443.79,
      "learning_rate": 0.05563943342813504,
      "loss": 2.7351,
      "step": 276040
    },
    {
      "epoch": 443.83,
      "learning_rate": 0.05563621799726688,
      "loss": 2.7425,
      "step": 276060
    },
    {
      "epoch": 443.86,
      "learning_rate": 0.05563300256639872,
      "loss": 2.7575,
      "step": 276080
    },
    {
      "epoch": 443.89,
      "learning_rate": 0.055629787135530545,
      "loss": 2.736,
      "step": 276100
    },
    {
      "epoch": 443.92,
      "learning_rate": 0.05562657170466238,
      "loss": 2.7177,
      "step": 276120
    },
    {
      "epoch": 443.95,
      "learning_rate": 0.055623356273794215,
      "loss": 2.7541,
      "step": 276140
    },
    {
      "epoch": 443.99,
      "learning_rate": 0.05562014084292605,
      "loss": 2.7291,
      "step": 276160
    },
    {
      "epoch": 444.0,
      "eval_accuracy": {
        "accuracy": 0.3999844515276374
      },
      "eval_loss": 2.858611583709717,
      "eval_runtime": 2.7253,
      "eval_samples_per_second": 4719.823,
      "eval_steps_per_second": 73.753,
      "step": 276168
    },
    {
      "epoch": 444.02,
      "learning_rate": 0.0556169254120579,
      "loss": 2.7513,
      "step": 276180
    },
    {
      "epoch": 444.05,
      "learning_rate": 0.05561370998118971,
      "loss": 2.7371,
      "step": 276200
    },
    {
      "epoch": 444.08,
      "learning_rate": 0.05561049455032155,
      "loss": 2.7317,
      "step": 276220
    },
    {
      "epoch": 444.12,
      "learning_rate": 0.05560727911945338,
      "loss": 2.7387,
      "step": 276240
    },
    {
      "epoch": 444.15,
      "learning_rate": 0.055604063688585205,
      "loss": 2.706,
      "step": 276260
    },
    {
      "epoch": 444.18,
      "learning_rate": 0.05560084825771705,
      "loss": 2.7318,
      "step": 276280
    },
    {
      "epoch": 444.21,
      "learning_rate": 0.055597632826848875,
      "loss": 2.7201,
      "step": 276300
    },
    {
      "epoch": 444.24,
      "learning_rate": 0.055594417395980714,
      "loss": 2.7213,
      "step": 276320
    },
    {
      "epoch": 444.28,
      "learning_rate": 0.05559120196511255,
      "loss": 2.7517,
      "step": 276340
    },
    {
      "epoch": 444.31,
      "learning_rate": 0.05558798653424438,
      "loss": 2.7548,
      "step": 276360
    },
    {
      "epoch": 444.34,
      "learning_rate": 0.05558477110337621,
      "loss": 2.7393,
      "step": 276380
    },
    {
      "epoch": 444.37,
      "learning_rate": 0.05558155567250803,
      "loss": 2.7393,
      "step": 276400
    },
    {
      "epoch": 444.41,
      "learning_rate": 0.05557834024163988,
      "loss": 2.7387,
      "step": 276420
    },
    {
      "epoch": 444.44,
      "learning_rate": 0.0555751248107717,
      "loss": 2.747,
      "step": 276440
    },
    {
      "epoch": 444.47,
      "learning_rate": 0.05557190937990354,
      "loss": 2.7522,
      "step": 276460
    },
    {
      "epoch": 444.5,
      "learning_rate": 0.05556869394903538,
      "loss": 2.745,
      "step": 276480
    },
    {
      "epoch": 444.53,
      "learning_rate": 0.055565478518167205,
      "loss": 2.7545,
      "step": 276500
    },
    {
      "epoch": 444.57,
      "learning_rate": 0.05556226308729904,
      "loss": 2.75,
      "step": 276520
    },
    {
      "epoch": 444.6,
      "learning_rate": 0.05555904765643086,
      "loss": 2.7555,
      "step": 276540
    },
    {
      "epoch": 444.63,
      "learning_rate": 0.05555583222556271,
      "loss": 2.7047,
      "step": 276560
    },
    {
      "epoch": 444.66,
      "learning_rate": 0.05555261679469453,
      "loss": 2.7262,
      "step": 276580
    },
    {
      "epoch": 444.69,
      "learning_rate": 0.05554940136382637,
      "loss": 2.7461,
      "step": 276600
    },
    {
      "epoch": 444.73,
      "learning_rate": 0.05554618593295821,
      "loss": 2.7095,
      "step": 276620
    },
    {
      "epoch": 444.76,
      "learning_rate": 0.05554297050209003,
      "loss": 2.7304,
      "step": 276640
    },
    {
      "epoch": 444.79,
      "learning_rate": 0.055539755071221865,
      "loss": 2.7594,
      "step": 276660
    },
    {
      "epoch": 444.82,
      "learning_rate": 0.0555365396403537,
      "loss": 2.7805,
      "step": 276680
    },
    {
      "epoch": 444.86,
      "learning_rate": 0.055533324209485535,
      "loss": 2.7581,
      "step": 276700
    },
    {
      "epoch": 444.89,
      "learning_rate": 0.05553010877861736,
      "loss": 2.7519,
      "step": 276720
    },
    {
      "epoch": 444.92,
      "learning_rate": 0.0555268933477492,
      "loss": 2.7418,
      "step": 276740
    },
    {
      "epoch": 444.95,
      "learning_rate": 0.05552367791688104,
      "loss": 2.7215,
      "step": 276760
    },
    {
      "epoch": 444.98,
      "learning_rate": 0.05552046248601286,
      "loss": 2.7566,
      "step": 276780
    },
    {
      "epoch": 445.0,
      "eval_accuracy": {
        "accuracy": 0.39936251263313377
      },
      "eval_loss": 2.8880844116210938,
      "eval_runtime": 2.8971,
      "eval_samples_per_second": 4439.955,
      "eval_steps_per_second": 69.38,
      "step": 276790
    },
    {
      "epoch": 445.02,
      "learning_rate": 0.05551724705514469,
      "loss": 2.7414,
      "step": 276800
    },
    {
      "epoch": 445.05,
      "learning_rate": 0.05551403162427653,
      "loss": 2.7242,
      "step": 276820
    },
    {
      "epoch": 445.08,
      "learning_rate": 0.05551081619340836,
      "loss": 2.6988,
      "step": 276840
    },
    {
      "epoch": 445.11,
      "learning_rate": 0.0555076007625402,
      "loss": 2.7441,
      "step": 276860
    },
    {
      "epoch": 445.14,
      "learning_rate": 0.055504385331672026,
      "loss": 2.7383,
      "step": 276880
    },
    {
      "epoch": 445.18,
      "learning_rate": 0.055501169900803865,
      "loss": 2.7453,
      "step": 276900
    },
    {
      "epoch": 445.21,
      "learning_rate": 0.0554979544699357,
      "loss": 2.7242,
      "step": 276920
    },
    {
      "epoch": 445.24,
      "learning_rate": 0.05549473903906752,
      "loss": 2.714,
      "step": 276940
    },
    {
      "epoch": 445.27,
      "learning_rate": 0.05549152360819937,
      "loss": 2.7146,
      "step": 276960
    },
    {
      "epoch": 445.31,
      "learning_rate": 0.05548830817733119,
      "loss": 2.7155,
      "step": 276980
    },
    {
      "epoch": 445.34,
      "learning_rate": 0.05548509274646303,
      "loss": 2.7305,
      "step": 277000
    },
    {
      "epoch": 445.37,
      "learning_rate": 0.05548187731559487,
      "loss": 2.7102,
      "step": 277020
    },
    {
      "epoch": 445.4,
      "learning_rate": 0.05547866188472669,
      "loss": 2.7129,
      "step": 277040
    },
    {
      "epoch": 445.43,
      "learning_rate": 0.055475446453858525,
      "loss": 2.7463,
      "step": 277060
    },
    {
      "epoch": 445.47,
      "learning_rate": 0.05547223102299035,
      "loss": 2.7227,
      "step": 277080
    },
    {
      "epoch": 445.5,
      "learning_rate": 0.055469015592122195,
      "loss": 2.7509,
      "step": 277100
    },
    {
      "epoch": 445.53,
      "learning_rate": 0.05546580016125401,
      "loss": 2.7428,
      "step": 277120
    },
    {
      "epoch": 445.56,
      "learning_rate": 0.05546258473038586,
      "loss": 2.7861,
      "step": 277140
    },
    {
      "epoch": 445.59,
      "learning_rate": 0.0554593692995177,
      "loss": 2.7329,
      "step": 277160
    },
    {
      "epoch": 445.63,
      "learning_rate": 0.05545615386864952,
      "loss": 2.7646,
      "step": 277180
    },
    {
      "epoch": 445.66,
      "learning_rate": 0.05545293843778135,
      "loss": 2.7225,
      "step": 277200
    },
    {
      "epoch": 445.69,
      "learning_rate": 0.05544972300691318,
      "loss": 2.7104,
      "step": 277220
    },
    {
      "epoch": 445.72,
      "learning_rate": 0.05544650757604502,
      "loss": 2.7378,
      "step": 277240
    },
    {
      "epoch": 445.76,
      "learning_rate": 0.05544329214517685,
      "loss": 2.7304,
      "step": 277260
    },
    {
      "epoch": 445.79,
      "learning_rate": 0.055440076714308686,
      "loss": 2.7547,
      "step": 277280
    },
    {
      "epoch": 445.82,
      "learning_rate": 0.055436861283440525,
      "loss": 2.7552,
      "step": 277300
    },
    {
      "epoch": 445.85,
      "learning_rate": 0.05543364585257235,
      "loss": 2.7647,
      "step": 277320
    },
    {
      "epoch": 445.88,
      "learning_rate": 0.05543043042170418,
      "loss": 2.755,
      "step": 277340
    },
    {
      "epoch": 445.92,
      "learning_rate": 0.05542721499083602,
      "loss": 2.7417,
      "step": 277360
    },
    {
      "epoch": 445.95,
      "learning_rate": 0.05542399955996785,
      "loss": 2.7192,
      "step": 277380
    },
    {
      "epoch": 445.98,
      "learning_rate": 0.055420784129099676,
      "loss": 2.7387,
      "step": 277400
    },
    {
      "epoch": 446.0,
      "eval_accuracy": {
        "accuracy": 0.4068257793671772
      },
      "eval_loss": 2.821599006652832,
      "eval_runtime": 2.8633,
      "eval_samples_per_second": 4492.445,
      "eval_steps_per_second": 70.2,
      "step": 277412
    },
    {
      "epoch": 446.01,
      "learning_rate": 0.055417568698231515,
      "loss": 2.7228,
      "step": 277420
    },
    {
      "epoch": 446.05,
      "learning_rate": 0.05541435326736335,
      "loss": 2.7341,
      "step": 277440
    },
    {
      "epoch": 446.08,
      "learning_rate": 0.05541113783649518,
      "loss": 2.7067,
      "step": 277460
    },
    {
      "epoch": 446.11,
      "learning_rate": 0.05540792240562701,
      "loss": 2.6975,
      "step": 277480
    },
    {
      "epoch": 446.14,
      "learning_rate": 0.05540470697475885,
      "loss": 2.7463,
      "step": 277500
    },
    {
      "epoch": 446.17,
      "learning_rate": 0.05540149154389068,
      "loss": 2.7512,
      "step": 277520
    },
    {
      "epoch": 446.21,
      "learning_rate": 0.05539827611302252,
      "loss": 2.7387,
      "step": 277540
    },
    {
      "epoch": 446.24,
      "learning_rate": 0.05539506068215433,
      "loss": 2.7032,
      "step": 277560
    },
    {
      "epoch": 446.27,
      "learning_rate": 0.05539184525128618,
      "loss": 2.7153,
      "step": 277580
    },
    {
      "epoch": 446.3,
      "learning_rate": 0.05538862982041801,
      "loss": 2.7054,
      "step": 277600
    },
    {
      "epoch": 446.33,
      "learning_rate": 0.05538541438954984,
      "loss": 2.7398,
      "step": 277620
    },
    {
      "epoch": 446.37,
      "learning_rate": 0.05538219895868168,
      "loss": 2.7562,
      "step": 277640
    },
    {
      "epoch": 446.4,
      "learning_rate": 0.0553789835278135,
      "loss": 2.755,
      "step": 277660
    },
    {
      "epoch": 446.43,
      "learning_rate": 0.055375768096945346,
      "loss": 2.7568,
      "step": 277680
    },
    {
      "epoch": 446.46,
      "learning_rate": 0.055372552666077185,
      "loss": 2.7457,
      "step": 277700
    },
    {
      "epoch": 446.5,
      "learning_rate": 0.05536933723520901,
      "loss": 2.7423,
      "step": 277720
    },
    {
      "epoch": 446.53,
      "learning_rate": 0.05536612180434084,
      "loss": 2.7562,
      "step": 277740
    },
    {
      "epoch": 446.56,
      "learning_rate": 0.055362906373472666,
      "loss": 2.742,
      "step": 277760
    },
    {
      "epoch": 446.59,
      "learning_rate": 0.05535969094260451,
      "loss": 2.7421,
      "step": 277780
    },
    {
      "epoch": 446.62,
      "learning_rate": 0.05535647551173633,
      "loss": 2.7208,
      "step": 277800
    },
    {
      "epoch": 446.66,
      "learning_rate": 0.055353260080868175,
      "loss": 2.7459,
      "step": 277820
    },
    {
      "epoch": 446.69,
      "learning_rate": 0.05535004465000001,
      "loss": 2.7345,
      "step": 277840
    },
    {
      "epoch": 446.72,
      "learning_rate": 0.05534682921913184,
      "loss": 2.7387,
      "step": 277860
    },
    {
      "epoch": 446.75,
      "learning_rate": 0.05534361378826367,
      "loss": 2.7409,
      "step": 277880
    },
    {
      "epoch": 446.78,
      "learning_rate": 0.055340398357395494,
      "loss": 2.7163,
      "step": 277900
    },
    {
      "epoch": 446.82,
      "learning_rate": 0.05533734369807073,
      "loss": 2.705,
      "step": 277920
    },
    {
      "epoch": 446.85,
      "learning_rate": 0.055334128267202576,
      "loss": 2.7357,
      "step": 277940
    },
    {
      "epoch": 446.88,
      "learning_rate": 0.0553309128363344,
      "loss": 2.7313,
      "step": 277960
    },
    {
      "epoch": 446.91,
      "learning_rate": 0.05532769740546624,
      "loss": 2.7581,
      "step": 277980
    },
    {
      "epoch": 446.95,
      "learning_rate": 0.05532448197459808,
      "loss": 2.7222,
      "step": 278000
    },
    {
      "epoch": 446.98,
      "learning_rate": 0.0553212665437299,
      "loss": 2.7386,
      "step": 278020
    },
    {
      "epoch": 447.0,
      "eval_accuracy": {
        "accuracy": 0.4034051154474073
      },
      "eval_loss": 2.828684091567993,
      "eval_runtime": 2.8036,
      "eval_samples_per_second": 4588.019,
      "eval_steps_per_second": 71.693,
      "step": 278034
    },
    {
      "epoch": 447.01,
      "learning_rate": 0.05531805111286175,
      "loss": 2.7473,
      "step": 278040
    },
    {
      "epoch": 447.04,
      "learning_rate": 0.05531483568199358,
      "loss": 2.7368,
      "step": 278060
    },
    {
      "epoch": 447.07,
      "learning_rate": 0.055311620251125404,
      "loss": 2.7464,
      "step": 278080
    },
    {
      "epoch": 447.11,
      "learning_rate": 0.05530840482025723,
      "loss": 2.7333,
      "step": 278100
    },
    {
      "epoch": 447.14,
      "learning_rate": 0.05530518938938907,
      "loss": 2.7443,
      "step": 278120
    },
    {
      "epoch": 447.17,
      "learning_rate": 0.05530197395852091,
      "loss": 2.7306,
      "step": 278140
    },
    {
      "epoch": 447.2,
      "learning_rate": 0.05529875852765273,
      "loss": 2.7335,
      "step": 278160
    },
    {
      "epoch": 447.23,
      "learning_rate": 0.05529554309678456,
      "loss": 2.7164,
      "step": 278180
    },
    {
      "epoch": 447.27,
      "learning_rate": 0.0552923276659164,
      "loss": 2.7178,
      "step": 278200
    },
    {
      "epoch": 447.3,
      "learning_rate": 0.05528911223504823,
      "loss": 2.7167,
      "step": 278220
    },
    {
      "epoch": 447.33,
      "learning_rate": 0.055285896804180085,
      "loss": 2.7128,
      "step": 278240
    },
    {
      "epoch": 447.36,
      "learning_rate": 0.055282681373311895,
      "loss": 2.7564,
      "step": 278260
    },
    {
      "epoch": 447.4,
      "learning_rate": 0.055279465942443734,
      "loss": 2.7331,
      "step": 278280
    },
    {
      "epoch": 447.43,
      "learning_rate": 0.055276250511575566,
      "loss": 2.6838,
      "step": 278300
    },
    {
      "epoch": 447.46,
      "learning_rate": 0.05527303508070739,
      "loss": 2.7152,
      "step": 278320
    },
    {
      "epoch": 447.49,
      "learning_rate": 0.05526981964983923,
      "loss": 2.7435,
      "step": 278340
    },
    {
      "epoch": 447.52,
      "learning_rate": 0.05526660421897106,
      "loss": 2.7168,
      "step": 278360
    },
    {
      "epoch": 447.56,
      "learning_rate": 0.05526338878810291,
      "loss": 2.749,
      "step": 278380
    },
    {
      "epoch": 447.59,
      "learning_rate": 0.05526017335723474,
      "loss": 2.7502,
      "step": 278400
    },
    {
      "epoch": 447.62,
      "learning_rate": 0.05525695792636656,
      "loss": 2.7459,
      "step": 278420
    },
    {
      "epoch": 447.65,
      "learning_rate": 0.055253742495498394,
      "loss": 2.7348,
      "step": 278440
    },
    {
      "epoch": 447.68,
      "learning_rate": 0.05525052706463022,
      "loss": 2.7469,
      "step": 278460
    },
    {
      "epoch": 447.72,
      "learning_rate": 0.055247311633762064,
      "loss": 2.7561,
      "step": 278480
    },
    {
      "epoch": 447.75,
      "learning_rate": 0.05524409620289389,
      "loss": 2.737,
      "step": 278500
    },
    {
      "epoch": 447.78,
      "learning_rate": 0.05524088077202573,
      "loss": 2.7531,
      "step": 278520
    },
    {
      "epoch": 447.81,
      "learning_rate": 0.055237665341157566,
      "loss": 2.7322,
      "step": 278540
    },
    {
      "epoch": 447.85,
      "learning_rate": 0.05523444991028939,
      "loss": 2.7444,
      "step": 278560
    },
    {
      "epoch": 447.88,
      "learning_rate": 0.055231234479421236,
      "loss": 2.761,
      "step": 278580
    },
    {
      "epoch": 447.91,
      "learning_rate": 0.05522801904855305,
      "loss": 2.7476,
      "step": 278600
    },
    {
      "epoch": 447.94,
      "learning_rate": 0.05522480361768489,
      "loss": 2.7211,
      "step": 278620
    },
    {
      "epoch": 447.97,
      "learning_rate": 0.05522158818681672,
      "loss": 2.7205,
      "step": 278640
    },
    {
      "epoch": 448.0,
      "eval_accuracy": {
        "accuracy": 0.4118012905232061
      },
      "eval_loss": 2.8111517429351807,
      "eval_runtime": 3.4195,
      "eval_samples_per_second": 3761.674,
      "eval_steps_per_second": 58.781,
      "step": 278656
    },
    {
      "epoch": 448.01,
      "learning_rate": 0.055218372755948555,
      "loss": 2.725,
      "step": 278660
    },
    {
      "epoch": 448.04,
      "learning_rate": 0.0552151573250804,
      "loss": 2.7327,
      "step": 278680
    },
    {
      "epoch": 448.07,
      "learning_rate": 0.05521194189421222,
      "loss": 2.7217,
      "step": 278700
    },
    {
      "epoch": 448.1,
      "learning_rate": 0.05520872646334405,
      "loss": 2.715,
      "step": 278720
    },
    {
      "epoch": 448.14,
      "learning_rate": 0.05520551103247589,
      "loss": 2.7259,
      "step": 278740
    },
    {
      "epoch": 448.17,
      "learning_rate": 0.05520229560160772,
      "loss": 2.7098,
      "step": 278760
    },
    {
      "epoch": 448.2,
      "learning_rate": 0.055199080170739545,
      "loss": 2.7297,
      "step": 278780
    },
    {
      "epoch": 448.23,
      "learning_rate": 0.055195864739871384,
      "loss": 2.7272,
      "step": 278800
    },
    {
      "epoch": 448.26,
      "learning_rate": 0.05519264930900322,
      "loss": 2.7243,
      "step": 278820
    },
    {
      "epoch": 448.3,
      "learning_rate": 0.05518943387813505,
      "loss": 2.6965,
      "step": 278840
    },
    {
      "epoch": 448.33,
      "learning_rate": 0.05518621844726688,
      "loss": 2.7298,
      "step": 278860
    },
    {
      "epoch": 448.36,
      "learning_rate": 0.05518300301639872,
      "loss": 2.7423,
      "step": 278880
    },
    {
      "epoch": 448.39,
      "learning_rate": 0.05517978758553055,
      "loss": 2.7421,
      "step": 278900
    },
    {
      "epoch": 448.42,
      "learning_rate": 0.0551765721546624,
      "loss": 2.7058,
      "step": 278920
    },
    {
      "epoch": 448.46,
      "learning_rate": 0.05517335672379421,
      "loss": 2.7328,
      "step": 278940
    },
    {
      "epoch": 448.49,
      "learning_rate": 0.05517014129292605,
      "loss": 2.7157,
      "step": 278960
    },
    {
      "epoch": 448.52,
      "learning_rate": 0.05516692586205788,
      "loss": 2.7701,
      "step": 278980
    },
    {
      "epoch": 448.55,
      "learning_rate": 0.05516371043118971,
      "loss": 2.7424,
      "step": 279000
    },
    {
      "epoch": 448.59,
      "learning_rate": 0.05516049500032155,
      "loss": 2.739,
      "step": 279020
    },
    {
      "epoch": 448.62,
      "learning_rate": 0.05515727956945338,
      "loss": 2.7331,
      "step": 279040
    },
    {
      "epoch": 448.65,
      "learning_rate": 0.055154064138585215,
      "loss": 2.7215,
      "step": 279060
    },
    {
      "epoch": 448.68,
      "learning_rate": 0.055150848707717054,
      "loss": 2.745,
      "step": 279080
    },
    {
      "epoch": 448.71,
      "learning_rate": 0.05514763327684888,
      "loss": 2.6969,
      "step": 279100
    },
    {
      "epoch": 448.75,
      "learning_rate": 0.05514441784598071,
      "loss": 2.7421,
      "step": 279120
    },
    {
      "epoch": 448.78,
      "learning_rate": 0.055141202415112535,
      "loss": 2.7318,
      "step": 279140
    },
    {
      "epoch": 448.81,
      "learning_rate": 0.05513798698424438,
      "loss": 2.7291,
      "step": 279160
    },
    {
      "epoch": 448.84,
      "learning_rate": 0.055134771553376205,
      "loss": 2.7408,
      "step": 279180
    },
    {
      "epoch": 448.87,
      "learning_rate": 0.055131556122508044,
      "loss": 2.7477,
      "step": 279200
    },
    {
      "epoch": 448.91,
      "learning_rate": 0.05512834069163988,
      "loss": 2.7646,
      "step": 279220
    },
    {
      "epoch": 448.94,
      "learning_rate": 0.05512512526077171,
      "loss": 2.7092,
      "step": 279240
    },
    {
      "epoch": 448.97,
      "learning_rate": 0.05512190982990354,
      "loss": 2.7366,
      "step": 279260
    },
    {
      "epoch": 449.0,
      "eval_accuracy": {
        "accuracy": 0.4068257793671772
      },
      "eval_loss": 2.8504655361175537,
      "eval_runtime": 3.2937,
      "eval_samples_per_second": 3905.362,
      "eval_steps_per_second": 61.026,
      "step": 279278
    },
    {
      "epoch": 449.0,
      "learning_rate": 0.05511869439903536,
      "loss": 2.736,
      "step": 279280
    },
    {
      "epoch": 449.04,
      "learning_rate": 0.05511547896816721,
      "loss": 2.7246,
      "step": 279300
    },
    {
      "epoch": 449.07,
      "learning_rate": 0.05511226353729903,
      "loss": 2.7367,
      "step": 279320
    },
    {
      "epoch": 449.1,
      "learning_rate": 0.05510904810643087,
      "loss": 2.7166,
      "step": 279340
    },
    {
      "epoch": 449.13,
      "learning_rate": 0.05510583267556271,
      "loss": 2.736,
      "step": 279360
    },
    {
      "epoch": 449.16,
      "learning_rate": 0.055102617244694535,
      "loss": 2.7024,
      "step": 279380
    },
    {
      "epoch": 449.2,
      "learning_rate": 0.05509940181382637,
      "loss": 2.6965,
      "step": 279400
    },
    {
      "epoch": 449.23,
      "learning_rate": 0.055096186382958205,
      "loss": 2.7075,
      "step": 279420
    },
    {
      "epoch": 449.26,
      "learning_rate": 0.05509297095209004,
      "loss": 2.7028,
      "step": 279440
    },
    {
      "epoch": 449.29,
      "learning_rate": 0.05508975552122186,
      "loss": 2.7379,
      "step": 279460
    },
    {
      "epoch": 449.32,
      "learning_rate": 0.0550865400903537,
      "loss": 2.7614,
      "step": 279480
    },
    {
      "epoch": 449.36,
      "learning_rate": 0.05508332465948554,
      "loss": 2.7381,
      "step": 279500
    },
    {
      "epoch": 449.39,
      "learning_rate": 0.05508010922861736,
      "loss": 2.7201,
      "step": 279520
    },
    {
      "epoch": 449.42,
      "learning_rate": 0.055076893797749195,
      "loss": 2.7146,
      "step": 279540
    },
    {
      "epoch": 449.45,
      "learning_rate": 0.05507367836688103,
      "loss": 2.7226,
      "step": 279560
    },
    {
      "epoch": 449.49,
      "learning_rate": 0.055070462936012865,
      "loss": 2.7353,
      "step": 279580
    },
    {
      "epoch": 449.52,
      "learning_rate": 0.055067247505144704,
      "loss": 2.7404,
      "step": 279600
    },
    {
      "epoch": 449.55,
      "learning_rate": 0.05506403207427653,
      "loss": 2.7413,
      "step": 279620
    },
    {
      "epoch": 449.58,
      "learning_rate": 0.05506081664340837,
      "loss": 2.7438,
      "step": 279640
    },
    {
      "epoch": 449.61,
      "learning_rate": 0.0550576012125402,
      "loss": 2.7288,
      "step": 279660
    },
    {
      "epoch": 449.65,
      "learning_rate": 0.05505438578167202,
      "loss": 2.7424,
      "step": 279680
    },
    {
      "epoch": 449.68,
      "learning_rate": 0.05505117035080387,
      "loss": 2.7559,
      "step": 279700
    },
    {
      "epoch": 449.71,
      "learning_rate": 0.05504795491993569,
      "loss": 2.7416,
      "step": 279720
    },
    {
      "epoch": 449.74,
      "learning_rate": 0.05504473948906753,
      "loss": 2.7449,
      "step": 279740
    },
    {
      "epoch": 449.77,
      "learning_rate": 0.05504152405819937,
      "loss": 2.7439,
      "step": 279760
    },
    {
      "epoch": 449.81,
      "learning_rate": 0.055038308627331195,
      "loss": 2.7228,
      "step": 279780
    },
    {
      "epoch": 449.84,
      "learning_rate": 0.05503509319646303,
      "loss": 2.7341,
      "step": 279800
    },
    {
      "epoch": 449.87,
      "learning_rate": 0.05503187776559485,
      "loss": 2.7437,
      "step": 279820
    },
    {
      "epoch": 449.9,
      "learning_rate": 0.0550286623347267,
      "loss": 2.7359,
      "step": 279840
    },
    {
      "epoch": 449.94,
      "learning_rate": 0.055025446903858515,
      "loss": 2.7268,
      "step": 279860
    },
    {
      "epoch": 449.97,
      "learning_rate": 0.05502223147299036,
      "loss": 2.6984,
      "step": 279880
    },
    {
      "epoch": 450.0,
      "learning_rate": 0.0550190160421222,
      "loss": 2.7287,
      "step": 279900
    },
    {
      "epoch": 450.0,
      "eval_accuracy": {
        "accuracy": 0.4105574127341989
      },
      "eval_loss": 2.8086493015289307,
      "eval_runtime": 2.7925,
      "eval_samples_per_second": 4606.292,
      "eval_steps_per_second": 71.979,
      "step": 279900
    },
    {
      "epoch": 450.03,
      "learning_rate": 0.05501580061125402,
      "loss": 2.7237,
      "step": 279920
    },
    {
      "epoch": 450.06,
      "learning_rate": 0.055012585180385855,
      "loss": 2.721,
      "step": 279940
    },
    {
      "epoch": 450.1,
      "learning_rate": 0.05500936974951768,
      "loss": 2.6892,
      "step": 279960
    },
    {
      "epoch": 450.13,
      "learning_rate": 0.055006154318649525,
      "loss": 2.7353,
      "step": 279980
    },
    {
      "epoch": 450.16,
      "learning_rate": 0.05500293888778135,
      "loss": 2.7426,
      "step": 280000
    },
    {
      "epoch": 450.19,
      "learning_rate": 0.0549998842284566,
      "loss": 2.7356,
      "step": 280020
    },
    {
      "epoch": 450.23,
      "learning_rate": 0.05499666879758844,
      "loss": 2.7363,
      "step": 280040
    },
    {
      "epoch": 450.26,
      "learning_rate": 0.05499345336672026,
      "loss": 2.7117,
      "step": 280060
    },
    {
      "epoch": 450.29,
      "learning_rate": 0.05499023793585209,
      "loss": 2.7229,
      "step": 280080
    },
    {
      "epoch": 450.32,
      "learning_rate": 0.05498702250498393,
      "loss": 2.7228,
      "step": 280100
    },
    {
      "epoch": 450.35,
      "learning_rate": 0.054983807074115744,
      "loss": 2.7358,
      "step": 280120
    },
    {
      "epoch": 450.39,
      "learning_rate": 0.05498059164324759,
      "loss": 2.7504,
      "step": 280140
    },
    {
      "epoch": 450.42,
      "learning_rate": 0.054977376212379414,
      "loss": 2.7528,
      "step": 280160
    },
    {
      "epoch": 450.45,
      "learning_rate": 0.05497416078151125,
      "loss": 2.7269,
      "step": 280180
    },
    {
      "epoch": 450.48,
      "learning_rate": 0.0549709453506431,
      "loss": 2.7335,
      "step": 280200
    },
    {
      "epoch": 450.51,
      "learning_rate": 0.054967729919774916,
      "loss": 2.745,
      "step": 280220
    },
    {
      "epoch": 450.55,
      "learning_rate": 0.05496451448890676,
      "loss": 2.7488,
      "step": 280240
    },
    {
      "epoch": 450.58,
      "learning_rate": 0.05496129905803859,
      "loss": 2.7449,
      "step": 280260
    },
    {
      "epoch": 450.61,
      "learning_rate": 0.05495808362717042,
      "loss": 2.7365,
      "step": 280280
    },
    {
      "epoch": 450.64,
      "learning_rate": 0.05495486819630227,
      "loss": 2.7217,
      "step": 280300
    },
    {
      "epoch": 450.68,
      "learning_rate": 0.05495165276543408,
      "loss": 2.7298,
      "step": 280320
    },
    {
      "epoch": 450.71,
      "learning_rate": 0.054948437334565926,
      "loss": 2.7426,
      "step": 280340
    },
    {
      "epoch": 450.74,
      "learning_rate": 0.05494522190369775,
      "loss": 2.7154,
      "step": 280360
    },
    {
      "epoch": 450.77,
      "learning_rate": 0.054942006472829576,
      "loss": 2.719,
      "step": 280380
    },
    {
      "epoch": 450.8,
      "learning_rate": 0.054938791041961414,
      "loss": 2.7238,
      "step": 280400
    },
    {
      "epoch": 450.84,
      "learning_rate": 0.054935575611093246,
      "loss": 2.738,
      "step": 280420
    },
    {
      "epoch": 450.87,
      "learning_rate": 0.0549323601802251,
      "loss": 2.7287,
      "step": 280440
    },
    {
      "epoch": 450.9,
      "learning_rate": 0.05492914474935692,
      "loss": 2.7285,
      "step": 280460
    },
    {
      "epoch": 450.93,
      "learning_rate": 0.054925929318488755,
      "loss": 2.7414,
      "step": 280480
    },
    {
      "epoch": 450.96,
      "learning_rate": 0.05492271388762058,
      "loss": 2.7195,
      "step": 280500
    },
    {
      "epoch": 451.0,
      "learning_rate": 0.054919498456752404,
      "loss": 2.7388,
      "step": 280520
    },
    {
      "epoch": 451.0,
      "eval_accuracy": {
        "accuracy": 0.400684132783954
      },
      "eval_loss": 2.9082953929901123,
      "eval_runtime": 2.9932,
      "eval_samples_per_second": 4297.453,
      "eval_steps_per_second": 67.153,
      "step": 280522
    },
    {
      "epoch": 451.03,
      "learning_rate": 0.05491628302588425,
      "loss": 2.7621,
      "step": 280540
    },
    {
      "epoch": 451.06,
      "learning_rate": 0.054913067595016074,
      "loss": 2.724,
      "step": 280560
    },
    {
      "epoch": 451.09,
      "learning_rate": 0.054909852164147926,
      "loss": 2.7356,
      "step": 280580
    },
    {
      "epoch": 451.13,
      "learning_rate": 0.05490663673327975,
      "loss": 2.736,
      "step": 280600
    },
    {
      "epoch": 451.16,
      "learning_rate": 0.054903421302411576,
      "loss": 2.7477,
      "step": 280620
    },
    {
      "epoch": 451.19,
      "learning_rate": 0.05490020587154342,
      "loss": 2.7409,
      "step": 280640
    },
    {
      "epoch": 451.22,
      "learning_rate": 0.05489699044067523,
      "loss": 2.7428,
      "step": 280660
    },
    {
      "epoch": 451.25,
      "learning_rate": 0.05489377500980708,
      "loss": 2.7092,
      "step": 280680
    },
    {
      "epoch": 451.29,
      "learning_rate": 0.0548905595789389,
      "loss": 2.7281,
      "step": 280700
    },
    {
      "epoch": 451.32,
      "learning_rate": 0.05488734414807074,
      "loss": 2.6991,
      "step": 280720
    },
    {
      "epoch": 451.35,
      "learning_rate": 0.05488412871720258,
      "loss": 2.7363,
      "step": 280740
    },
    {
      "epoch": 451.38,
      "learning_rate": 0.054880913286334404,
      "loss": 2.7309,
      "step": 280760
    },
    {
      "epoch": 451.41,
      "learning_rate": 0.05487769785546625,
      "loss": 2.6849,
      "step": 280780
    },
    {
      "epoch": 451.45,
      "learning_rate": 0.05487448242459808,
      "loss": 2.7216,
      "step": 280800
    },
    {
      "epoch": 451.48,
      "learning_rate": 0.054871266993729906,
      "loss": 2.7487,
      "step": 280820
    },
    {
      "epoch": 451.51,
      "learning_rate": 0.05486805156286173,
      "loss": 2.7271,
      "step": 280840
    },
    {
      "epoch": 451.54,
      "learning_rate": 0.05486483613199357,
      "loss": 2.7283,
      "step": 280860
    },
    {
      "epoch": 451.58,
      "learning_rate": 0.054861620701125415,
      "loss": 2.7354,
      "step": 280880
    },
    {
      "epoch": 451.61,
      "learning_rate": 0.05485840527025723,
      "loss": 2.7436,
      "step": 280900
    },
    {
      "epoch": 451.64,
      "learning_rate": 0.054855189839389064,
      "loss": 2.733,
      "step": 280920
    },
    {
      "epoch": 451.67,
      "learning_rate": 0.0548519744085209,
      "loss": 2.7415,
      "step": 280940
    },
    {
      "epoch": 451.7,
      "learning_rate": 0.054848758977652734,
      "loss": 2.7347,
      "step": 280960
    },
    {
      "epoch": 451.74,
      "learning_rate": 0.054845543546784586,
      "loss": 2.7201,
      "step": 280980
    },
    {
      "epoch": 451.77,
      "learning_rate": 0.0548423281159164,
      "loss": 2.714,
      "step": 281000
    },
    {
      "epoch": 451.8,
      "learning_rate": 0.054839112685048236,
      "loss": 2.7217,
      "step": 281020
    },
    {
      "epoch": 451.83,
      "learning_rate": 0.05483589725418007,
      "loss": 2.7293,
      "step": 281040
    },
    {
      "epoch": 451.86,
      "learning_rate": 0.05483268182331189,
      "loss": 2.7551,
      "step": 281060
    },
    {
      "epoch": 451.9,
      "learning_rate": 0.05482946639244373,
      "loss": 2.7704,
      "step": 281080
    },
    {
      "epoch": 451.93,
      "learning_rate": 0.05482625096157556,
      "loss": 2.7033,
      "step": 281100
    },
    {
      "epoch": 451.96,
      "learning_rate": 0.054823035530707415,
      "loss": 2.7403,
      "step": 281120
    },
    {
      "epoch": 451.99,
      "learning_rate": 0.05481982009983924,
      "loss": 2.7299,
      "step": 281140
    },
    {
      "epoch": 452.0,
      "eval_accuracy": {
        "accuracy": 0.40410479670372385
      },
      "eval_loss": 2.8535263538360596,
      "eval_runtime": 2.9144,
      "eval_samples_per_second": 4413.6,
      "eval_steps_per_second": 68.968,
      "step": 281144
    },
    {
      "epoch": 452.03,
      "learning_rate": 0.054816604668971064,
      "loss": 2.7403,
      "step": 281160
    },
    {
      "epoch": 452.06,
      "learning_rate": 0.054813389238102896,
      "loss": 2.7407,
      "step": 281180
    },
    {
      "epoch": 452.09,
      "learning_rate": 0.05481017380723472,
      "loss": 2.7454,
      "step": 281200
    },
    {
      "epoch": 452.12,
      "learning_rate": 0.054806958376366566,
      "loss": 2.7326,
      "step": 281220
    },
    {
      "epoch": 452.15,
      "learning_rate": 0.05480374294549839,
      "loss": 2.7435,
      "step": 281240
    },
    {
      "epoch": 452.19,
      "learning_rate": 0.05480052751463023,
      "loss": 2.7353,
      "step": 281260
    },
    {
      "epoch": 452.22,
      "learning_rate": 0.05479731208376207,
      "loss": 2.7209,
      "step": 281280
    },
    {
      "epoch": 452.25,
      "learning_rate": 0.05479409665289389,
      "loss": 2.7206,
      "step": 281300
    },
    {
      "epoch": 452.28,
      "learning_rate": 0.05479088122202574,
      "loss": 2.7334,
      "step": 281320
    },
    {
      "epoch": 452.32,
      "learning_rate": 0.05478766579115755,
      "loss": 2.7473,
      "step": 281340
    },
    {
      "epoch": 452.35,
      "learning_rate": 0.054784450360289394,
      "loss": 2.7184,
      "step": 281360
    },
    {
      "epoch": 452.38,
      "learning_rate": 0.05478123492942122,
      "loss": 2.7326,
      "step": 281380
    },
    {
      "epoch": 452.41,
      "learning_rate": 0.05477801949855306,
      "loss": 2.7425,
      "step": 281400
    },
    {
      "epoch": 452.44,
      "learning_rate": 0.0547748040676849,
      "loss": 2.7267,
      "step": 281420
    },
    {
      "epoch": 452.48,
      "learning_rate": 0.05477158863681672,
      "loss": 2.7407,
      "step": 281440
    },
    {
      "epoch": 452.51,
      "learning_rate": 0.05476837320594855,
      "loss": 2.7233,
      "step": 281460
    },
    {
      "epoch": 452.54,
      "learning_rate": 0.05476515777508039,
      "loss": 2.7169,
      "step": 281480
    },
    {
      "epoch": 452.57,
      "learning_rate": 0.05476194234421222,
      "loss": 2.7425,
      "step": 281500
    },
    {
      "epoch": 452.6,
      "learning_rate": 0.05475872691334405,
      "loss": 2.6928,
      "step": 281520
    },
    {
      "epoch": 452.64,
      "learning_rate": 0.054755511482475885,
      "loss": 2.7533,
      "step": 281540
    },
    {
      "epoch": 452.67,
      "learning_rate": 0.054752296051607724,
      "loss": 2.7276,
      "step": 281560
    },
    {
      "epoch": 452.7,
      "learning_rate": 0.05474908062073955,
      "loss": 2.7294,
      "step": 281580
    },
    {
      "epoch": 452.73,
      "learning_rate": 0.05474586518987138,
      "loss": 2.7351,
      "step": 281600
    },
    {
      "epoch": 452.77,
      "learning_rate": 0.05474264975900322,
      "loss": 2.7357,
      "step": 281620
    },
    {
      "epoch": 452.8,
      "learning_rate": 0.05473943432813505,
      "loss": 2.7304,
      "step": 281640
    },
    {
      "epoch": 452.83,
      "learning_rate": 0.05473621889726689,
      "loss": 2.7493,
      "step": 281660
    },
    {
      "epoch": 452.86,
      "learning_rate": 0.054733003466398714,
      "loss": 2.7059,
      "step": 281680
    },
    {
      "epoch": 452.89,
      "learning_rate": 0.05472978803553055,
      "loss": 2.7424,
      "step": 281700
    },
    {
      "epoch": 452.93,
      "learning_rate": 0.054726572604662384,
      "loss": 2.7029,
      "step": 281720
    },
    {
      "epoch": 452.96,
      "learning_rate": 0.05472335717379421,
      "loss": 2.7198,
      "step": 281740
    },
    {
      "epoch": 452.99,
      "learning_rate": 0.054720141742926054,
      "loss": 2.7527,
      "step": 281760
    },
    {
      "epoch": 453.0,
      "eval_accuracy": {
        "accuracy": 0.40029542097488924
      },
      "eval_loss": 2.857050895690918,
      "eval_runtime": 2.7732,
      "eval_samples_per_second": 4638.381,
      "eval_steps_per_second": 72.48,
      "step": 281766
    },
    {
      "epoch": 453.02,
      "learning_rate": 0.05471692631205788,
      "loss": 2.7453,
      "step": 281780
    },
    {
      "epoch": 453.05,
      "learning_rate": 0.05471371088118972,
      "loss": 2.7557,
      "step": 281800
    },
    {
      "epoch": 453.09,
      "learning_rate": 0.054710495450321556,
      "loss": 2.7272,
      "step": 281820
    },
    {
      "epoch": 453.12,
      "learning_rate": 0.05470728001945338,
      "loss": 2.6981,
      "step": 281840
    },
    {
      "epoch": 453.15,
      "learning_rate": 0.05470406458858521,
      "loss": 2.7329,
      "step": 281860
    },
    {
      "epoch": 453.18,
      "learning_rate": 0.05470084915771704,
      "loss": 2.716,
      "step": 281880
    },
    {
      "epoch": 453.22,
      "learning_rate": 0.05469763372684888,
      "loss": 2.7284,
      "step": 281900
    },
    {
      "epoch": 453.25,
      "learning_rate": 0.05469441829598071,
      "loss": 2.7031,
      "step": 281920
    },
    {
      "epoch": 453.28,
      "learning_rate": 0.054691202865112545,
      "loss": 2.7117,
      "step": 281940
    },
    {
      "epoch": 453.31,
      "learning_rate": 0.054687987434244384,
      "loss": 2.7358,
      "step": 281960
    },
    {
      "epoch": 453.34,
      "learning_rate": 0.05468477200337621,
      "loss": 2.718,
      "step": 281980
    },
    {
      "epoch": 453.38,
      "learning_rate": 0.05468155657250804,
      "loss": 2.72,
      "step": 282000
    },
    {
      "epoch": 453.41,
      "learning_rate": 0.05467850191318329,
      "loss": 2.7392,
      "step": 282020
    },
    {
      "epoch": 453.44,
      "learning_rate": 0.0546752864823151,
      "loss": 2.7223,
      "step": 282040
    },
    {
      "epoch": 453.47,
      "learning_rate": 0.05467207105144695,
      "loss": 2.708,
      "step": 282060
    },
    {
      "epoch": 453.5,
      "learning_rate": 0.054668855620578785,
      "loss": 2.7372,
      "step": 282080
    },
    {
      "epoch": 453.54,
      "learning_rate": 0.054665640189710624,
      "loss": 2.7441,
      "step": 282100
    },
    {
      "epoch": 453.57,
      "learning_rate": 0.05466242475884245,
      "loss": 2.7579,
      "step": 282120
    },
    {
      "epoch": 453.6,
      "learning_rate": 0.05465920932797428,
      "loss": 2.7659,
      "step": 282140
    },
    {
      "epoch": 453.63,
      "learning_rate": 0.05465599389710612,
      "loss": 2.7184,
      "step": 282160
    },
    {
      "epoch": 453.67,
      "learning_rate": 0.05465277846623793,
      "loss": 2.743,
      "step": 282180
    },
    {
      "epoch": 453.7,
      "learning_rate": 0.054649563035369775,
      "loss": 2.7196,
      "step": 282200
    },
    {
      "epoch": 453.73,
      "learning_rate": 0.05464634760450161,
      "loss": 2.7277,
      "step": 282220
    },
    {
      "epoch": 453.76,
      "learning_rate": 0.05464313217363345,
      "loss": 2.7333,
      "step": 282240
    },
    {
      "epoch": 453.79,
      "learning_rate": 0.054639916742765283,
      "loss": 2.7131,
      "step": 282260
    },
    {
      "epoch": 453.83,
      "learning_rate": 0.0546367013118971,
      "loss": 2.7577,
      "step": 282280
    },
    {
      "epoch": 453.86,
      "learning_rate": 0.05463348588102895,
      "loss": 2.7627,
      "step": 282300
    },
    {
      "epoch": 453.89,
      "learning_rate": 0.05463027045016078,
      "loss": 2.7413,
      "step": 282320
    },
    {
      "epoch": 453.92,
      "learning_rate": 0.0546270550192926,
      "loss": 2.7428,
      "step": 282340
    },
    {
      "epoch": 453.95,
      "learning_rate": 0.054623839588424455,
      "loss": 2.7412,
      "step": 282360
    },
    {
      "epoch": 453.99,
      "learning_rate": 0.054620624157556266,
      "loss": 2.7277,
      "step": 282380
    },
    {
      "epoch": 454.0,
      "eval_accuracy": {
        "accuracy": 0.4079141724325585
      },
      "eval_loss": 2.809532403945923,
      "eval_runtime": 2.8659,
      "eval_samples_per_second": 4488.23,
      "eval_steps_per_second": 70.134,
      "step": 282388
    },
    {
      "epoch": 454.02,
      "learning_rate": 0.05461740872668811,
      "loss": 2.7046,
      "step": 282400
    },
    {
      "epoch": 454.05,
      "learning_rate": 0.054614193295819936,
      "loss": 2.723,
      "step": 282420
    },
    {
      "epoch": 454.08,
      "learning_rate": 0.054610977864951775,
      "loss": 2.7206,
      "step": 282440
    },
    {
      "epoch": 454.12,
      "learning_rate": 0.054607762434083607,
      "loss": 2.7338,
      "step": 282460
    },
    {
      "epoch": 454.15,
      "learning_rate": 0.05460454700321543,
      "loss": 2.71,
      "step": 282480
    },
    {
      "epoch": 454.18,
      "learning_rate": 0.054601331572347284,
      "loss": 2.6985,
      "step": 282500
    },
    {
      "epoch": 454.21,
      "learning_rate": 0.054598116141479094,
      "loss": 2.7285,
      "step": 282520
    },
    {
      "epoch": 454.24,
      "learning_rate": 0.05459490071061094,
      "loss": 2.7286,
      "step": 282540
    },
    {
      "epoch": 454.28,
      "learning_rate": 0.054591685279742765,
      "loss": 2.7022,
      "step": 282560
    },
    {
      "epoch": 454.31,
      "learning_rate": 0.05458846984887459,
      "loss": 2.7253,
      "step": 282580
    },
    {
      "epoch": 454.34,
      "learning_rate": 0.054585254418006435,
      "loss": 2.7586,
      "step": 282600
    },
    {
      "epoch": 454.37,
      "learning_rate": 0.05458203898713826,
      "loss": 2.7273,
      "step": 282620
    },
    {
      "epoch": 454.41,
      "learning_rate": 0.05457882355627011,
      "loss": 2.7259,
      "step": 282640
    },
    {
      "epoch": 454.44,
      "learning_rate": 0.054575608125401937,
      "loss": 2.725,
      "step": 282660
    },
    {
      "epoch": 454.47,
      "learning_rate": 0.05457239269453377,
      "loss": 2.7413,
      "step": 282680
    },
    {
      "epoch": 454.5,
      "learning_rate": 0.05456917726366561,
      "loss": 2.74,
      "step": 282700
    },
    {
      "epoch": 454.53,
      "learning_rate": 0.05456596183279742,
      "loss": 2.713,
      "step": 282720
    },
    {
      "epoch": 454.57,
      "learning_rate": 0.05456274640192926,
      "loss": 2.7387,
      "step": 282740
    },
    {
      "epoch": 454.6,
      "learning_rate": 0.0545595309710611,
      "loss": 2.7295,
      "step": 282760
    },
    {
      "epoch": 454.63,
      "learning_rate": 0.05455631554019294,
      "loss": 2.7063,
      "step": 282780
    },
    {
      "epoch": 454.66,
      "learning_rate": 0.054553100109324765,
      "loss": 2.7395,
      "step": 282800
    },
    {
      "epoch": 454.69,
      "learning_rate": 0.05454988467845659,
      "loss": 2.7537,
      "step": 282820
    },
    {
      "epoch": 454.73,
      "learning_rate": 0.054546669247588435,
      "loss": 2.7522,
      "step": 282840
    },
    {
      "epoch": 454.76,
      "learning_rate": 0.054543453816720246,
      "loss": 2.6914,
      "step": 282860
    },
    {
      "epoch": 454.79,
      "learning_rate": 0.05454023838585209,
      "loss": 2.7256,
      "step": 282880
    },
    {
      "epoch": 454.82,
      "learning_rate": 0.054537022954983916,
      "loss": 2.7429,
      "step": 282900
    },
    {
      "epoch": 454.86,
      "learning_rate": 0.054533807524115754,
      "loss": 2.7397,
      "step": 282920
    },
    {
      "epoch": 454.89,
      "learning_rate": 0.0545305920932476,
      "loss": 2.7451,
      "step": 282940
    },
    {
      "epoch": 454.92,
      "learning_rate": 0.05452737666237942,
      "loss": 2.7293,
      "step": 282960
    },
    {
      "epoch": 454.95,
      "learning_rate": 0.05452416123151126,
      "loss": 2.7308,
      "step": 282980
    },
    {
      "epoch": 454.98,
      "learning_rate": 0.054520945800643095,
      "loss": 2.7582,
      "step": 283000
    },
    {
      "epoch": 455.0,
      "eval_accuracy": {
        "accuracy": 0.4019280105729612
      },
      "eval_loss": 2.851280689239502,
      "eval_runtime": 2.8608,
      "eval_samples_per_second": 4496.256,
      "eval_steps_per_second": 70.259,
      "step": 283010
    },
    {
      "epoch": 455.02,
      "learning_rate": 0.05451773036977492,
      "loss": 2.736,
      "step": 283020
    },
    {
      "epoch": 455.05,
      "learning_rate": 0.05451451493890677,
      "loss": 2.7469,
      "step": 283040
    },
    {
      "epoch": 455.08,
      "learning_rate": 0.05451129950803858,
      "loss": 2.7453,
      "step": 283060
    },
    {
      "epoch": 455.11,
      "learning_rate": 0.05450808407717043,
      "loss": 2.7318,
      "step": 283080
    },
    {
      "epoch": 455.14,
      "learning_rate": 0.05450486864630225,
      "loss": 2.7351,
      "step": 283100
    },
    {
      "epoch": 455.18,
      "learning_rate": 0.05450165321543408,
      "loss": 2.7311,
      "step": 283120
    },
    {
      "epoch": 455.21,
      "learning_rate": 0.054498437784565916,
      "loss": 2.7126,
      "step": 283140
    },
    {
      "epoch": 455.24,
      "learning_rate": 0.05449522235369775,
      "loss": 2.7316,
      "step": 283160
    },
    {
      "epoch": 455.27,
      "learning_rate": 0.0544920069228296,
      "loss": 2.7402,
      "step": 283180
    },
    {
      "epoch": 455.31,
      "learning_rate": 0.054488791491961425,
      "loss": 2.7138,
      "step": 283200
    },
    {
      "epoch": 455.34,
      "learning_rate": 0.05448557606109325,
      "loss": 2.7261,
      "step": 283220
    },
    {
      "epoch": 455.37,
      "learning_rate": 0.05448236063022508,
      "loss": 2.7159,
      "step": 283240
    },
    {
      "epoch": 455.4,
      "learning_rate": 0.054479145199356906,
      "loss": 2.723,
      "step": 283260
    },
    {
      "epoch": 455.43,
      "learning_rate": 0.05447592976848875,
      "loss": 2.7129,
      "step": 283280
    },
    {
      "epoch": 455.47,
      "learning_rate": 0.054472714337620576,
      "loss": 2.7229,
      "step": 283300
    },
    {
      "epoch": 455.5,
      "learning_rate": 0.05446949890675243,
      "loss": 2.7401,
      "step": 283320
    },
    {
      "epoch": 455.53,
      "learning_rate": 0.05446628347588425,
      "loss": 2.7702,
      "step": 283340
    },
    {
      "epoch": 455.56,
      "learning_rate": 0.05446306804501608,
      "loss": 2.7461,
      "step": 283360
    },
    {
      "epoch": 455.59,
      "learning_rate": 0.05445985261414792,
      "loss": 2.737,
      "step": 283380
    },
    {
      "epoch": 455.63,
      "learning_rate": 0.054456637183279734,
      "loss": 2.754,
      "step": 283400
    },
    {
      "epoch": 455.66,
      "learning_rate": 0.05445342175241158,
      "loss": 2.7471,
      "step": 283420
    },
    {
      "epoch": 455.69,
      "learning_rate": 0.054450206321543404,
      "loss": 2.7185,
      "step": 283440
    },
    {
      "epoch": 455.72,
      "learning_rate": 0.05444699089067524,
      "loss": 2.7534,
      "step": 283460
    },
    {
      "epoch": 455.76,
      "learning_rate": 0.05444377545980708,
      "loss": 2.7175,
      "step": 283480
    },
    {
      "epoch": 455.79,
      "learning_rate": 0.054440560028938906,
      "loss": 2.7261,
      "step": 283500
    },
    {
      "epoch": 455.82,
      "learning_rate": 0.05443734459807075,
      "loss": 2.7209,
      "step": 283520
    },
    {
      "epoch": 455.85,
      "learning_rate": 0.054434129167202576,
      "loss": 2.7295,
      "step": 283540
    },
    {
      "epoch": 455.88,
      "learning_rate": 0.05443091373633441,
      "loss": 2.728,
      "step": 283560
    },
    {
      "epoch": 455.92,
      "learning_rate": 0.05442769830546623,
      "loss": 2.7275,
      "step": 283580
    },
    {
      "epoch": 455.95,
      "learning_rate": 0.05442448287459807,
      "loss": 2.7217,
      "step": 283600
    },
    {
      "epoch": 455.98,
      "learning_rate": 0.054421267443729916,
      "loss": 2.7221,
      "step": 283620
    },
    {
      "epoch": 456.0,
      "eval_accuracy": {
        "accuracy": 0.40052864806032806
      },
      "eval_loss": 2.8681650161743164,
      "eval_runtime": 3.1873,
      "eval_samples_per_second": 4035.652,
      "eval_steps_per_second": 63.062,
      "step": 283632
    },
    {
      "epoch": 456.01,
      "learning_rate": 0.054418052012861734,
      "loss": 2.7182,
      "step": 283640
    },
    {
      "epoch": 456.05,
      "learning_rate": 0.054414836581993566,
      "loss": 2.7138,
      "step": 283660
    },
    {
      "epoch": 456.08,
      "learning_rate": 0.054411621151125404,
      "loss": 2.7136,
      "step": 283680
    },
    {
      "epoch": 456.11,
      "learning_rate": 0.054408405720257236,
      "loss": 2.7148,
      "step": 283700
    },
    {
      "epoch": 456.14,
      "learning_rate": 0.05440519028938909,
      "loss": 2.7176,
      "step": 283720
    },
    {
      "epoch": 456.17,
      "learning_rate": 0.0544019748585209,
      "loss": 2.7283,
      "step": 283740
    },
    {
      "epoch": 456.21,
      "learning_rate": 0.05439875942765274,
      "loss": 2.7398,
      "step": 283760
    },
    {
      "epoch": 456.24,
      "learning_rate": 0.05439554399678457,
      "loss": 2.7184,
      "step": 283780
    },
    {
      "epoch": 456.27,
      "learning_rate": 0.054392328565916394,
      "loss": 2.7285,
      "step": 283800
    },
    {
      "epoch": 456.3,
      "learning_rate": 0.05438911313504824,
      "loss": 2.7214,
      "step": 283820
    },
    {
      "epoch": 456.33,
      "learning_rate": 0.054385897704180064,
      "loss": 2.7093,
      "step": 283840
    },
    {
      "epoch": 456.37,
      "learning_rate": 0.0543826822733119,
      "loss": 2.747,
      "step": 283860
    },
    {
      "epoch": 456.4,
      "learning_rate": 0.05437946684244374,
      "loss": 2.732,
      "step": 283880
    },
    {
      "epoch": 456.43,
      "learning_rate": 0.054376251411575566,
      "loss": 2.7264,
      "step": 283900
    },
    {
      "epoch": 456.46,
      "learning_rate": 0.0543730359807074,
      "loss": 2.7379,
      "step": 283920
    },
    {
      "epoch": 456.5,
      "learning_rate": 0.05436982054983922,
      "loss": 2.7239,
      "step": 283940
    },
    {
      "epoch": 456.53,
      "learning_rate": 0.05436660511897107,
      "loss": 2.7443,
      "step": 283960
    },
    {
      "epoch": 456.56,
      "learning_rate": 0.05436338968810289,
      "loss": 2.7128,
      "step": 283980
    },
    {
      "epoch": 456.59,
      "learning_rate": 0.05436017425723473,
      "loss": 2.7144,
      "step": 284000
    },
    {
      "epoch": 456.62,
      "learning_rate": 0.05435695882636657,
      "loss": 2.7315,
      "step": 284020
    },
    {
      "epoch": 456.66,
      "learning_rate": 0.054353743395498394,
      "loss": 2.7137,
      "step": 284040
    },
    {
      "epoch": 456.69,
      "learning_rate": 0.05435052796463024,
      "loss": 2.717,
      "step": 284060
    },
    {
      "epoch": 456.72,
      "learning_rate": 0.05434731253376205,
      "loss": 2.738,
      "step": 284080
    },
    {
      "epoch": 456.75,
      "learning_rate": 0.054344097102893896,
      "loss": 2.7204,
      "step": 284100
    },
    {
      "epoch": 456.78,
      "learning_rate": 0.05434088167202572,
      "loss": 2.7359,
      "step": 284120
    },
    {
      "epoch": 456.82,
      "learning_rate": 0.05433766624115756,
      "loss": 2.7133,
      "step": 284140
    },
    {
      "epoch": 456.85,
      "learning_rate": 0.054334450810289404,
      "loss": 2.7467,
      "step": 284160
    },
    {
      "epoch": 456.88,
      "learning_rate": 0.05433123537942122,
      "loss": 2.7494,
      "step": 284180
    },
    {
      "epoch": 456.91,
      "learning_rate": 0.054328019948553054,
      "loss": 2.754,
      "step": 284200
    },
    {
      "epoch": 456.95,
      "learning_rate": 0.05432480451768489,
      "loss": 2.7458,
      "step": 284220
    },
    {
      "epoch": 456.98,
      "learning_rate": 0.054321589086816724,
      "loss": 2.73,
      "step": 284240
    },
    {
      "epoch": 457.0,
      "eval_accuracy": {
        "accuracy": 0.4044935085127886
      },
      "eval_loss": 2.8636739253997803,
      "eval_runtime": 3.4668,
      "eval_samples_per_second": 3710.357,
      "eval_steps_per_second": 57.979,
      "step": 284254
    },
    {
      "epoch": 457.01,
      "learning_rate": 0.05431837365594855,
      "loss": 2.7373,
      "step": 284260
    },
    {
      "epoch": 457.04,
      "learning_rate": 0.05431515822508039,
      "loss": 2.7271,
      "step": 284280
    },
    {
      "epoch": 457.07,
      "learning_rate": 0.054311942794212226,
      "loss": 2.7157,
      "step": 284300
    },
    {
      "epoch": 457.11,
      "learning_rate": 0.05430872736334405,
      "loss": 2.7345,
      "step": 284320
    },
    {
      "epoch": 457.14,
      "learning_rate": 0.05430551193247588,
      "loss": 2.7255,
      "step": 284340
    },
    {
      "epoch": 457.17,
      "learning_rate": 0.05430229650160772,
      "loss": 2.6993,
      "step": 284360
    },
    {
      "epoch": 457.2,
      "learning_rate": 0.05429908107073955,
      "loss": 2.6727,
      "step": 284380
    },
    {
      "epoch": 457.23,
      "learning_rate": 0.05429586563987139,
      "loss": 2.7003,
      "step": 284400
    },
    {
      "epoch": 457.27,
      "learning_rate": 0.054292650209003215,
      "loss": 2.7271,
      "step": 284420
    },
    {
      "epoch": 457.3,
      "learning_rate": 0.054289434778135054,
      "loss": 2.7007,
      "step": 284440
    },
    {
      "epoch": 457.33,
      "learning_rate": 0.054286219347266886,
      "loss": 2.6981,
      "step": 284460
    },
    {
      "epoch": 457.36,
      "learning_rate": 0.05428300391639871,
      "loss": 2.7012,
      "step": 284480
    },
    {
      "epoch": 457.4,
      "learning_rate": 0.054279788485530556,
      "loss": 2.7441,
      "step": 284500
    },
    {
      "epoch": 457.43,
      "learning_rate": 0.05427657305466238,
      "loss": 2.7282,
      "step": 284520
    },
    {
      "epoch": 457.46,
      "learning_rate": 0.05427335762379422,
      "loss": 2.7126,
      "step": 284540
    },
    {
      "epoch": 457.49,
      "learning_rate": 0.05427014219292606,
      "loss": 2.734,
      "step": 284560
    },
    {
      "epoch": 457.52,
      "learning_rate": 0.05426692676205788,
      "loss": 2.7354,
      "step": 284580
    },
    {
      "epoch": 457.56,
      "learning_rate": 0.054263711331189714,
      "loss": 2.6986,
      "step": 284600
    },
    {
      "epoch": 457.59,
      "learning_rate": 0.05426049590032154,
      "loss": 2.7361,
      "step": 284620
    },
    {
      "epoch": 457.62,
      "learning_rate": 0.054257280469453384,
      "loss": 2.7083,
      "step": 284640
    },
    {
      "epoch": 457.65,
      "learning_rate": 0.05425406503858521,
      "loss": 2.7194,
      "step": 284660
    },
    {
      "epoch": 457.68,
      "learning_rate": 0.05425084960771705,
      "loss": 2.7545,
      "step": 284680
    },
    {
      "epoch": 457.72,
      "learning_rate": 0.0542477949483923,
      "loss": 2.7369,
      "step": 284700
    },
    {
      "epoch": 457.75,
      "learning_rate": 0.05424457951752412,
      "loss": 2.7339,
      "step": 284720
    },
    {
      "epoch": 457.78,
      "learning_rate": 0.054241364086655953,
      "loss": 2.721,
      "step": 284740
    },
    {
      "epoch": 457.81,
      "learning_rate": 0.05423814865578779,
      "loss": 2.7435,
      "step": 284760
    },
    {
      "epoch": 457.85,
      "learning_rate": 0.0542349332249196,
      "loss": 2.7331,
      "step": 284780
    },
    {
      "epoch": 457.88,
      "learning_rate": 0.05423171779405145,
      "loss": 2.7345,
      "step": 284800
    },
    {
      "epoch": 457.91,
      "learning_rate": 0.05422850236318329,
      "loss": 2.748,
      "step": 284820
    },
    {
      "epoch": 457.94,
      "learning_rate": 0.054225286932315125,
      "loss": 2.7174,
      "step": 284840
    },
    {
      "epoch": 457.97,
      "learning_rate": 0.05422207150144695,
      "loss": 2.7675,
      "step": 284860
    },
    {
      "epoch": 458.0,
      "eval_accuracy": {
        "accuracy": 0.4118012905232061
      },
      "eval_loss": 2.8134572505950928,
      "eval_runtime": 2.7792,
      "eval_samples_per_second": 4628.228,
      "eval_steps_per_second": 72.322,
      "step": 284876
    },
    {
      "epoch": 458.01,
      "learning_rate": 0.05421885607057878,
      "loss": 2.7032,
      "step": 284880
    },
    {
      "epoch": 458.04,
      "learning_rate": 0.05421564063971062,
      "loss": 2.7475,
      "step": 284900
    },
    {
      "epoch": 458.07,
      "learning_rate": 0.05421242520884243,
      "loss": 2.7191,
      "step": 284920
    },
    {
      "epoch": 458.1,
      "learning_rate": 0.05420920977797428,
      "loss": 2.7046,
      "step": 284940
    },
    {
      "epoch": 458.14,
      "learning_rate": 0.054205994347106115,
      "loss": 2.7263,
      "step": 284960
    },
    {
      "epoch": 458.17,
      "learning_rate": 0.054202778916237954,
      "loss": 2.7421,
      "step": 284980
    },
    {
      "epoch": 458.2,
      "learning_rate": 0.054199563485369785,
      "loss": 2.7491,
      "step": 285000
    },
    {
      "epoch": 458.23,
      "learning_rate": 0.0541963480545016,
      "loss": 2.7486,
      "step": 285020
    },
    {
      "epoch": 458.26,
      "learning_rate": 0.05419313262363345,
      "loss": 2.718,
      "step": 285040
    },
    {
      "epoch": 458.3,
      "learning_rate": 0.05418991719276528,
      "loss": 2.707,
      "step": 285060
    },
    {
      "epoch": 458.33,
      "learning_rate": 0.054186701761897105,
      "loss": 2.7279,
      "step": 285080
    },
    {
      "epoch": 458.36,
      "learning_rate": 0.05418348633102896,
      "loss": 2.721,
      "step": 285100
    },
    {
      "epoch": 458.39,
      "learning_rate": 0.05418027090016077,
      "loss": 2.7497,
      "step": 285120
    },
    {
      "epoch": 458.42,
      "learning_rate": 0.05417705546929261,
      "loss": 2.7235,
      "step": 285140
    },
    {
      "epoch": 458.46,
      "learning_rate": 0.05417384003842444,
      "loss": 2.7305,
      "step": 285160
    },
    {
      "epoch": 458.49,
      "learning_rate": 0.05417062460755628,
      "loss": 2.7069,
      "step": 285180
    },
    {
      "epoch": 458.52,
      "learning_rate": 0.05416740917668811,
      "loss": 2.7177,
      "step": 285200
    },
    {
      "epoch": 458.55,
      "learning_rate": 0.05416419374581993,
      "loss": 2.7071,
      "step": 285220
    },
    {
      "epoch": 458.59,
      "learning_rate": 0.054160978314951785,
      "loss": 2.7209,
      "step": 285240
    },
    {
      "epoch": 458.62,
      "learning_rate": 0.054157762884083596,
      "loss": 2.7122,
      "step": 285260
    },
    {
      "epoch": 458.65,
      "learning_rate": 0.05415454745321544,
      "loss": 2.7096,
      "step": 285280
    },
    {
      "epoch": 458.68,
      "learning_rate": 0.054151332022347266,
      "loss": 2.7435,
      "step": 285300
    },
    {
      "epoch": 458.71,
      "learning_rate": 0.05414811659147909,
      "loss": 2.7414,
      "step": 285320
    },
    {
      "epoch": 458.75,
      "learning_rate": 0.054144901160610936,
      "loss": 2.7504,
      "step": 285340
    },
    {
      "epoch": 458.78,
      "learning_rate": 0.05414168572974276,
      "loss": 2.7352,
      "step": 285360
    },
    {
      "epoch": 458.81,
      "learning_rate": 0.054138470298874614,
      "loss": 2.7475,
      "step": 285380
    },
    {
      "epoch": 458.84,
      "learning_rate": 0.05413525486800644,
      "loss": 2.698,
      "step": 285400
    },
    {
      "epoch": 458.87,
      "learning_rate": 0.05413203943713826,
      "loss": 2.7149,
      "step": 285420
    },
    {
      "epoch": 458.91,
      "learning_rate": 0.05412882400627011,
      "loss": 2.7477,
      "step": 285440
    },
    {
      "epoch": 458.94,
      "learning_rate": 0.05412560857540192,
      "loss": 2.7302,
      "step": 285460
    },
    {
      "epoch": 458.97,
      "learning_rate": 0.054122393144533765,
      "loss": 2.7069,
      "step": 285480
    },
    {
      "epoch": 459.0,
      "eval_accuracy": {
        "accuracy": 0.4051931897691052
      },
      "eval_loss": 2.8324265480041504,
      "eval_runtime": 3.1403,
      "eval_samples_per_second": 4096.17,
      "eval_steps_per_second": 64.008,
      "step": 285498
    },
    {
      "epoch": 459.0,
      "learning_rate": 0.0541191777136656,
      "loss": 2.7137,
      "step": 285500
    },
    {
      "epoch": 459.04,
      "learning_rate": 0.05411596228279744,
      "loss": 2.7096,
      "step": 285520
    },
    {
      "epoch": 459.07,
      "learning_rate": 0.054112746851929266,
      "loss": 2.7308,
      "step": 285540
    },
    {
      "epoch": 459.1,
      "learning_rate": 0.05410953142106109,
      "loss": 2.7258,
      "step": 285560
    },
    {
      "epoch": 459.13,
      "learning_rate": 0.05410631599019294,
      "loss": 2.7189,
      "step": 285580
    },
    {
      "epoch": 459.16,
      "learning_rate": 0.05410310055932477,
      "loss": 2.7187,
      "step": 285600
    },
    {
      "epoch": 459.2,
      "learning_rate": 0.05409988512845659,
      "loss": 2.7402,
      "step": 285620
    },
    {
      "epoch": 459.23,
      "learning_rate": 0.05409666969758842,
      "loss": 2.7319,
      "step": 285640
    },
    {
      "epoch": 459.26,
      "learning_rate": 0.054093454266720256,
      "loss": 2.7022,
      "step": 285660
    },
    {
      "epoch": 459.29,
      "learning_rate": 0.0540902388358521,
      "loss": 2.7189,
      "step": 285680
    },
    {
      "epoch": 459.32,
      "learning_rate": 0.05408702340498392,
      "loss": 2.721,
      "step": 285700
    },
    {
      "epoch": 459.36,
      "learning_rate": 0.054083807974115765,
      "loss": 2.7285,
      "step": 285720
    },
    {
      "epoch": 459.39,
      "learning_rate": 0.05408059254324759,
      "loss": 2.7204,
      "step": 285740
    },
    {
      "epoch": 459.42,
      "learning_rate": 0.05407737711237942,
      "loss": 2.7046,
      "step": 285760
    },
    {
      "epoch": 459.45,
      "learning_rate": 0.054074161681511274,
      "loss": 2.73,
      "step": 285780
    },
    {
      "epoch": 459.49,
      "learning_rate": 0.054070946250643084,
      "loss": 2.752,
      "step": 285800
    },
    {
      "epoch": 459.52,
      "learning_rate": 0.05406773081977493,
      "loss": 2.7537,
      "step": 285820
    },
    {
      "epoch": 459.55,
      "learning_rate": 0.054064515388906755,
      "loss": 2.7017,
      "step": 285840
    },
    {
      "epoch": 459.58,
      "learning_rate": 0.05406129995803858,
      "loss": 2.7142,
      "step": 285860
    },
    {
      "epoch": 459.61,
      "learning_rate": 0.05405808452717042,
      "loss": 2.7401,
      "step": 285880
    },
    {
      "epoch": 459.65,
      "learning_rate": 0.05405486909630225,
      "loss": 2.7301,
      "step": 285900
    },
    {
      "epoch": 459.68,
      "learning_rate": 0.0540516536654341,
      "loss": 2.7718,
      "step": 285920
    },
    {
      "epoch": 459.71,
      "learning_rate": 0.054048438234565926,
      "loss": 2.7226,
      "step": 285940
    },
    {
      "epoch": 459.74,
      "learning_rate": 0.05404522280369775,
      "loss": 2.715,
      "step": 285960
    },
    {
      "epoch": 459.77,
      "learning_rate": 0.05404200737282958,
      "loss": 2.7063,
      "step": 285980
    },
    {
      "epoch": 459.81,
      "learning_rate": 0.05403879194196141,
      "loss": 2.7294,
      "step": 286000
    },
    {
      "epoch": 459.84,
      "learning_rate": 0.05403557651109325,
      "loss": 2.6966,
      "step": 286020
    },
    {
      "epoch": 459.87,
      "learning_rate": 0.05403236108022508,
      "loss": 2.7456,
      "step": 286040
    },
    {
      "epoch": 459.9,
      "learning_rate": 0.054029145649356916,
      "loss": 2.7082,
      "step": 286060
    },
    {
      "epoch": 459.94,
      "learning_rate": 0.054025930218488755,
      "loss": 2.7143,
      "step": 286080
    },
    {
      "epoch": 459.97,
      "learning_rate": 0.05402271478762058,
      "loss": 2.7007,
      "step": 286100
    },
    {
      "epoch": 460.0,
      "learning_rate": 0.054019499356752425,
      "loss": 2.7096,
      "step": 286120
    },
    {
      "epoch": 460.0,
      "eval_accuracy": {
        "accuracy": 0.41491098499572415
      },
      "eval_loss": 2.7949490547180176,
      "eval_runtime": 2.7535,
      "eval_samples_per_second": 4671.495,
      "eval_steps_per_second": 72.998,
      "step": 286120
    },
    {
      "epoch": 460.03,
      "learning_rate": 0.054016283925884236,
      "loss": 2.6904,
      "step": 286140
    },
    {
      "epoch": 460.06,
      "learning_rate": 0.05401306849501608,
      "loss": 2.7179,
      "step": 286160
    },
    {
      "epoch": 460.1,
      "learning_rate": 0.054009853064147906,
      "loss": 2.7402,
      "step": 286180
    },
    {
      "epoch": 460.13,
      "learning_rate": 0.054006637633279744,
      "loss": 2.7189,
      "step": 286200
    },
    {
      "epoch": 460.16,
      "learning_rate": 0.05400342220241158,
      "loss": 2.7584,
      "step": 286220
    },
    {
      "epoch": 460.19,
      "learning_rate": 0.05400020677154341,
      "loss": 2.695,
      "step": 286240
    },
    {
      "epoch": 460.23,
      "learning_rate": 0.05399699134067525,
      "loss": 2.7064,
      "step": 286260
    },
    {
      "epoch": 460.26,
      "learning_rate": 0.05399377590980708,
      "loss": 2.7191,
      "step": 286280
    },
    {
      "epoch": 460.29,
      "learning_rate": 0.05399056047893891,
      "loss": 2.7162,
      "step": 286300
    },
    {
      "epoch": 460.32,
      "learning_rate": 0.053987345048070734,
      "loss": 2.744,
      "step": 286320
    },
    {
      "epoch": 460.35,
      "learning_rate": 0.05398412961720257,
      "loss": 2.7264,
      "step": 286340
    },
    {
      "epoch": 460.39,
      "learning_rate": 0.05398091418633442,
      "loss": 2.7294,
      "step": 286360
    },
    {
      "epoch": 460.42,
      "learning_rate": 0.053977698755466236,
      "loss": 2.7235,
      "step": 286380
    },
    {
      "epoch": 460.45,
      "learning_rate": 0.05397448332459807,
      "loss": 2.7273,
      "step": 286400
    },
    {
      "epoch": 460.48,
      "learning_rate": 0.053971267893729906,
      "loss": 2.724,
      "step": 286420
    },
    {
      "epoch": 460.51,
      "learning_rate": 0.05396805246286174,
      "loss": 2.7265,
      "step": 286440
    },
    {
      "epoch": 460.55,
      "learning_rate": 0.05396483703199359,
      "loss": 2.7383,
      "step": 286460
    },
    {
      "epoch": 460.58,
      "learning_rate": 0.0539616216011254,
      "loss": 2.7056,
      "step": 286480
    },
    {
      "epoch": 460.61,
      "learning_rate": 0.05395840617025724,
      "loss": 2.7088,
      "step": 286500
    },
    {
      "epoch": 460.64,
      "learning_rate": 0.05395519073938907,
      "loss": 2.7363,
      "step": 286520
    },
    {
      "epoch": 460.68,
      "learning_rate": 0.053951975308520896,
      "loss": 2.7362,
      "step": 286540
    },
    {
      "epoch": 460.71,
      "learning_rate": 0.05394875987765274,
      "loss": 2.7083,
      "step": 286560
    },
    {
      "epoch": 460.74,
      "learning_rate": 0.053945544446784566,
      "loss": 2.7069,
      "step": 286580
    },
    {
      "epoch": 460.77,
      "learning_rate": 0.053942329015916404,
      "loss": 2.7273,
      "step": 286600
    },
    {
      "epoch": 460.8,
      "learning_rate": 0.05393911358504824,
      "loss": 2.7476,
      "step": 286620
    },
    {
      "epoch": 460.84,
      "learning_rate": 0.05393589815418007,
      "loss": 2.7196,
      "step": 286640
    },
    {
      "epoch": 460.87,
      "learning_rate": 0.0539326827233119,
      "loss": 2.7347,
      "step": 286660
    },
    {
      "epoch": 460.9,
      "learning_rate": 0.053929467292443724,
      "loss": 2.7307,
      "step": 286680
    },
    {
      "epoch": 460.93,
      "learning_rate": 0.05392625186157557,
      "loss": 2.7388,
      "step": 286700
    },
    {
      "epoch": 460.96,
      "learning_rate": 0.053923036430707394,
      "loss": 2.7193,
      "step": 286720
    },
    {
      "epoch": 461.0,
      "learning_rate": 0.05391982099983923,
      "loss": 2.7205,
      "step": 286740
    },
    {
      "epoch": 461.0,
      "eval_accuracy": {
        "accuracy": 0.40690352172899014
      },
      "eval_loss": 2.8419790267944336,
      "eval_runtime": 2.7557,
      "eval_samples_per_second": 4667.698,
      "eval_steps_per_second": 72.938,
      "step": 286742
    },
    {
      "epoch": 461.03,
      "learning_rate": 0.05391660556897107,
      "loss": 2.7468,
      "step": 286760
    },
    {
      "epoch": 461.06,
      "learning_rate": 0.053913390138102896,
      "loss": 2.7043,
      "step": 286780
    },
    {
      "epoch": 461.09,
      "learning_rate": 0.05391017470723474,
      "loss": 2.7174,
      "step": 286800
    },
    {
      "epoch": 461.13,
      "learning_rate": 0.05390695927636655,
      "loss": 2.7174,
      "step": 286820
    },
    {
      "epoch": 461.16,
      "learning_rate": 0.0539037438454984,
      "loss": 2.719,
      "step": 286840
    },
    {
      "epoch": 461.19,
      "learning_rate": 0.05390052841463022,
      "loss": 2.757,
      "step": 286860
    },
    {
      "epoch": 461.22,
      "learning_rate": 0.05389731298376206,
      "loss": 2.7422,
      "step": 286880
    },
    {
      "epoch": 461.25,
      "learning_rate": 0.053894097552893906,
      "loss": 2.7478,
      "step": 286900
    },
    {
      "epoch": 461.29,
      "learning_rate": 0.053890882122025724,
      "loss": 2.7436,
      "step": 286920
    },
    {
      "epoch": 461.32,
      "learning_rate": 0.053887666691157556,
      "loss": 2.7241,
      "step": 286940
    },
    {
      "epoch": 461.35,
      "learning_rate": 0.053884451260289394,
      "loss": 2.7436,
      "step": 286960
    },
    {
      "epoch": 461.38,
      "learning_rate": 0.053881235829421226,
      "loss": 2.6874,
      "step": 286980
    },
    {
      "epoch": 461.41,
      "learning_rate": 0.05387802039855305,
      "loss": 2.7158,
      "step": 287000
    },
    {
      "epoch": 461.45,
      "learning_rate": 0.05387480496768489,
      "loss": 2.7207,
      "step": 287020
    },
    {
      "epoch": 461.48,
      "learning_rate": 0.05387158953681673,
      "loss": 2.7267,
      "step": 287040
    },
    {
      "epoch": 461.51,
      "learning_rate": 0.05386837410594855,
      "loss": 2.749,
      "step": 287060
    },
    {
      "epoch": 461.54,
      "learning_rate": 0.053865158675080384,
      "loss": 2.744,
      "step": 287080
    },
    {
      "epoch": 461.58,
      "learning_rate": 0.05386194324421222,
      "loss": 2.7104,
      "step": 287100
    },
    {
      "epoch": 461.61,
      "learning_rate": 0.053858727813344054,
      "loss": 2.7352,
      "step": 287120
    },
    {
      "epoch": 461.64,
      "learning_rate": 0.05385551238247589,
      "loss": 2.7035,
      "step": 287140
    },
    {
      "epoch": 461.67,
      "learning_rate": 0.05385229695160772,
      "loss": 2.7154,
      "step": 287160
    },
    {
      "epoch": 461.7,
      "learning_rate": 0.053849081520739556,
      "loss": 2.6954,
      "step": 287180
    },
    {
      "epoch": 461.74,
      "learning_rate": 0.05384586608987139,
      "loss": 2.7296,
      "step": 287200
    },
    {
      "epoch": 461.77,
      "learning_rate": 0.05384265065900321,
      "loss": 2.7215,
      "step": 287220
    },
    {
      "epoch": 461.8,
      "learning_rate": 0.05383943522813506,
      "loss": 2.7341,
      "step": 287240
    },
    {
      "epoch": 461.83,
      "learning_rate": 0.05383621979726688,
      "loss": 2.7316,
      "step": 287260
    },
    {
      "epoch": 461.86,
      "learning_rate": 0.05383300436639872,
      "loss": 2.7452,
      "step": 287280
    },
    {
      "epoch": 461.9,
      "learning_rate": 0.05382978893553056,
      "loss": 2.7358,
      "step": 287300
    },
    {
      "epoch": 461.93,
      "learning_rate": 0.053826573504662384,
      "loss": 2.7355,
      "step": 287320
    },
    {
      "epoch": 461.96,
      "learning_rate": 0.053823358073794215,
      "loss": 2.7433,
      "step": 287340
    },
    {
      "epoch": 461.99,
      "learning_rate": 0.05382014264292604,
      "loss": 2.7436,
      "step": 287360
    },
    {
      "epoch": 462.0,
      "eval_accuracy": {
        "accuracy": 0.4072144911762419
      },
      "eval_loss": 2.8398826122283936,
      "eval_runtime": 3.2133,
      "eval_samples_per_second": 4003.05,
      "eval_steps_per_second": 62.553,
      "step": 287364
    },
    {
      "epoch": 462.03,
      "learning_rate": 0.053816927212057886,
      "loss": 2.7222,
      "step": 287380
    },
    {
      "epoch": 462.06,
      "learning_rate": 0.05381371178118971,
      "loss": 2.7366,
      "step": 287400
    },
    {
      "epoch": 462.09,
      "learning_rate": 0.05381049635032155,
      "loss": 2.7076,
      "step": 287420
    },
    {
      "epoch": 462.12,
      "learning_rate": 0.05380728091945339,
      "loss": 2.7417,
      "step": 287440
    },
    {
      "epoch": 462.15,
      "learning_rate": 0.05380406548858521,
      "loss": 2.6909,
      "step": 287460
    },
    {
      "epoch": 462.19,
      "learning_rate": 0.053800850057717044,
      "loss": 2.7238,
      "step": 287480
    },
    {
      "epoch": 462.22,
      "learning_rate": 0.053797795398392294,
      "loss": 2.7314,
      "step": 287500
    },
    {
      "epoch": 462.25,
      "learning_rate": 0.053794579967524105,
      "loss": 2.7307,
      "step": 287520
    },
    {
      "epoch": 462.28,
      "learning_rate": 0.05379136453665595,
      "loss": 2.6925,
      "step": 287540
    },
    {
      "epoch": 462.32,
      "learning_rate": 0.05378814910578779,
      "loss": 2.7781,
      "step": 287560
    },
    {
      "epoch": 462.35,
      "learning_rate": 0.05378493367491963,
      "loss": 2.6987,
      "step": 287580
    },
    {
      "epoch": 462.38,
      "learning_rate": 0.05378171824405145,
      "loss": 2.7087,
      "step": 287600
    },
    {
      "epoch": 462.41,
      "learning_rate": 0.053778502813183277,
      "loss": 2.7086,
      "step": 287620
    },
    {
      "epoch": 462.44,
      "learning_rate": 0.05377528738231512,
      "loss": 2.7242,
      "step": 287640
    },
    {
      "epoch": 462.48,
      "learning_rate": 0.05377207195144693,
      "loss": 2.7335,
      "step": 287660
    },
    {
      "epoch": 462.51,
      "learning_rate": 0.05376885652057878,
      "loss": 2.7294,
      "step": 287680
    },
    {
      "epoch": 462.54,
      "learning_rate": 0.05376564108971062,
      "loss": 2.6979,
      "step": 287700
    },
    {
      "epoch": 462.57,
      "learning_rate": 0.053762425658842455,
      "loss": 2.699,
      "step": 287720
    },
    {
      "epoch": 462.6,
      "learning_rate": 0.05375921022797429,
      "loss": 2.7046,
      "step": 287740
    },
    {
      "epoch": 462.64,
      "learning_rate": 0.053755994797106105,
      "loss": 2.7311,
      "step": 287760
    },
    {
      "epoch": 462.67,
      "learning_rate": 0.05375277936623795,
      "loss": 2.7087,
      "step": 287780
    },
    {
      "epoch": 462.7,
      "learning_rate": 0.05374956393536978,
      "loss": 2.7032,
      "step": 287800
    },
    {
      "epoch": 462.73,
      "learning_rate": 0.053746348504501607,
      "loss": 2.7211,
      "step": 287820
    },
    {
      "epoch": 462.77,
      "learning_rate": 0.05374313307363346,
      "loss": 2.7192,
      "step": 287840
    },
    {
      "epoch": 462.8,
      "learning_rate": 0.05373991764276527,
      "loss": 2.7507,
      "step": 287860
    },
    {
      "epoch": 462.83,
      "learning_rate": 0.053736702211897115,
      "loss": 2.7294,
      "step": 287880
    },
    {
      "epoch": 462.86,
      "learning_rate": 0.05373348678102894,
      "loss": 2.7079,
      "step": 287900
    },
    {
      "epoch": 462.89,
      "learning_rate": 0.05373027135016078,
      "loss": 2.7234,
      "step": 287920
    },
    {
      "epoch": 462.93,
      "learning_rate": 0.0537270559192926,
      "loss": 2.7208,
      "step": 287940
    },
    {
      "epoch": 462.96,
      "learning_rate": 0.053723840488424435,
      "loss": 2.7169,
      "step": 287960
    },
    {
      "epoch": 462.99,
      "learning_rate": 0.05372062505755629,
      "loss": 2.7303,
      "step": 287980
    },
    {
      "epoch": 463.0,
      "eval_accuracy": {
        "accuracy": 0.4118012905232061
      },
      "eval_loss": 2.7915701866149902,
      "eval_runtime": 2.9439,
      "eval_samples_per_second": 4369.36,
      "eval_steps_per_second": 68.277,
      "step": 287986
    },
    {
      "epoch": 463.02,
      "learning_rate": 0.0537174096266881,
      "loss": 2.7356,
      "step": 288000
    },
    {
      "epoch": 463.05,
      "learning_rate": 0.05371419419581994,
      "loss": 2.7224,
      "step": 288020
    },
    {
      "epoch": 463.09,
      "learning_rate": 0.05371097876495177,
      "loss": 2.7087,
      "step": 288040
    },
    {
      "epoch": 463.12,
      "learning_rate": 0.05370776333408359,
      "loss": 2.6861,
      "step": 288060
    },
    {
      "epoch": 463.15,
      "learning_rate": 0.05370454790321544,
      "loss": 2.7071,
      "step": 288080
    },
    {
      "epoch": 463.18,
      "learning_rate": 0.05370133247234726,
      "loss": 2.7184,
      "step": 288100
    },
    {
      "epoch": 463.22,
      "learning_rate": 0.053698117041479115,
      "loss": 2.7215,
      "step": 288120
    },
    {
      "epoch": 463.25,
      "learning_rate": 0.05369490161061094,
      "loss": 2.7102,
      "step": 288140
    },
    {
      "epoch": 463.28,
      "learning_rate": 0.053691686179742765,
      "loss": 2.6927,
      "step": 288160
    },
    {
      "epoch": 463.31,
      "learning_rate": 0.05368847074887461,
      "loss": 2.7217,
      "step": 288180
    },
    {
      "epoch": 463.34,
      "learning_rate": 0.05368525531800642,
      "loss": 2.7389,
      "step": 288200
    },
    {
      "epoch": 463.38,
      "learning_rate": 0.053682039887138266,
      "loss": 2.6981,
      "step": 288220
    },
    {
      "epoch": 463.41,
      "learning_rate": 0.053678824456270105,
      "loss": 2.7285,
      "step": 288240
    },
    {
      "epoch": 463.44,
      "learning_rate": 0.05367560902540193,
      "loss": 2.7238,
      "step": 288260
    },
    {
      "epoch": 463.47,
      "learning_rate": 0.05367239359453377,
      "loss": 2.7392,
      "step": 288280
    },
    {
      "epoch": 463.5,
      "learning_rate": 0.05366917816366559,
      "loss": 2.7199,
      "step": 288300
    },
    {
      "epoch": 463.54,
      "learning_rate": 0.05366596273279744,
      "loss": 2.7196,
      "step": 288320
    },
    {
      "epoch": 463.57,
      "learning_rate": 0.05366274730192927,
      "loss": 2.7256,
      "step": 288340
    },
    {
      "epoch": 463.6,
      "learning_rate": 0.053659531871061095,
      "loss": 2.7055,
      "step": 288360
    },
    {
      "epoch": 463.63,
      "learning_rate": 0.05365631644019292,
      "loss": 2.7095,
      "step": 288380
    },
    {
      "epoch": 463.67,
      "learning_rate": 0.05365310100932476,
      "loss": 2.751,
      "step": 288400
    },
    {
      "epoch": 463.7,
      "learning_rate": 0.0536498855784566,
      "loss": 2.7144,
      "step": 288420
    },
    {
      "epoch": 463.73,
      "learning_rate": 0.05364667014758842,
      "loss": 2.7019,
      "step": 288440
    },
    {
      "epoch": 463.76,
      "learning_rate": 0.05364345471672027,
      "loss": 2.7066,
      "step": 288460
    },
    {
      "epoch": 463.79,
      "learning_rate": 0.05364023928585209,
      "loss": 2.7201,
      "step": 288480
    },
    {
      "epoch": 463.83,
      "learning_rate": 0.05363702385498392,
      "loss": 2.7104,
      "step": 288500
    },
    {
      "epoch": 463.86,
      "learning_rate": 0.053633808424115775,
      "loss": 2.7145,
      "step": 288520
    },
    {
      "epoch": 463.89,
      "learning_rate": 0.053630592993247586,
      "loss": 2.7062,
      "step": 288540
    },
    {
      "epoch": 463.92,
      "learning_rate": 0.05362737756237943,
      "loss": 2.7257,
      "step": 288560
    },
    {
      "epoch": 463.95,
      "learning_rate": 0.053624162131511256,
      "loss": 2.7215,
      "step": 288580
    },
    {
      "epoch": 463.99,
      "learning_rate": 0.05362094670064308,
      "loss": 2.7345,
      "step": 288600
    },
    {
      "epoch": 464.0,
      "eval_accuracy": {
        "accuracy": 0.41086838218145066
      },
      "eval_loss": 2.809478759765625,
      "eval_runtime": 2.8623,
      "eval_samples_per_second": 4493.927,
      "eval_steps_per_second": 70.223,
      "step": 288608
    },
    {
      "epoch": 464.02,
      "learning_rate": 0.05361773126977492,
      "loss": 2.7297,
      "step": 288620
    },
    {
      "epoch": 464.05,
      "learning_rate": 0.05361451583890675,
      "loss": 2.7338,
      "step": 288640
    },
    {
      "epoch": 464.08,
      "learning_rate": 0.053611300408038604,
      "loss": 2.7466,
      "step": 288660
    },
    {
      "epoch": 464.12,
      "learning_rate": 0.05360808497717043,
      "loss": 2.7338,
      "step": 288680
    },
    {
      "epoch": 464.15,
      "learning_rate": 0.05360486954630225,
      "loss": 2.7121,
      "step": 288700
    },
    {
      "epoch": 464.18,
      "learning_rate": 0.053601654115434084,
      "loss": 2.7171,
      "step": 288720
    },
    {
      "epoch": 464.21,
      "learning_rate": 0.05359843868456591,
      "loss": 2.7052,
      "step": 288740
    },
    {
      "epoch": 464.24,
      "learning_rate": 0.053595223253697755,
      "loss": 2.6917,
      "step": 288760
    },
    {
      "epoch": 464.28,
      "learning_rate": 0.05359200782282958,
      "loss": 2.7209,
      "step": 288780
    },
    {
      "epoch": 464.31,
      "learning_rate": 0.05358879239196142,
      "loss": 2.7032,
      "step": 288800
    },
    {
      "epoch": 464.34,
      "learning_rate": 0.053585576961093256,
      "loss": 2.7054,
      "step": 288820
    },
    {
      "epoch": 464.37,
      "learning_rate": 0.05358236153022508,
      "loss": 2.7368,
      "step": 288840
    },
    {
      "epoch": 464.41,
      "learning_rate": 0.05357914609935693,
      "loss": 2.7202,
      "step": 288860
    },
    {
      "epoch": 464.44,
      "learning_rate": 0.05357593066848874,
      "loss": 2.6954,
      "step": 288880
    },
    {
      "epoch": 464.47,
      "learning_rate": 0.05357271523762058,
      "loss": 2.7051,
      "step": 288900
    },
    {
      "epoch": 464.5,
      "learning_rate": 0.05356949980675241,
      "loss": 2.711,
      "step": 288920
    },
    {
      "epoch": 464.53,
      "learning_rate": 0.053566284375884246,
      "loss": 2.7089,
      "step": 288940
    },
    {
      "epoch": 464.57,
      "learning_rate": 0.053563068945016085,
      "loss": 2.713,
      "step": 288960
    },
    {
      "epoch": 464.6,
      "learning_rate": 0.05355985351414791,
      "loss": 2.7245,
      "step": 288980
    },
    {
      "epoch": 464.63,
      "learning_rate": 0.053556638083279755,
      "loss": 2.7007,
      "step": 289000
    },
    {
      "epoch": 464.66,
      "learning_rate": 0.05355342265241158,
      "loss": 2.7028,
      "step": 289020
    },
    {
      "epoch": 464.69,
      "learning_rate": 0.05355020722154341,
      "loss": 2.7003,
      "step": 289040
    },
    {
      "epoch": 464.73,
      "learning_rate": 0.053546991790675236,
      "loss": 2.6838,
      "step": 289060
    },
    {
      "epoch": 464.76,
      "learning_rate": 0.053543776359807074,
      "loss": 2.7264,
      "step": 289080
    },
    {
      "epoch": 464.79,
      "learning_rate": 0.05354056092893892,
      "loss": 2.7228,
      "step": 289100
    },
    {
      "epoch": 464.82,
      "learning_rate": 0.05353734549807074,
      "loss": 2.7123,
      "step": 289120
    },
    {
      "epoch": 464.86,
      "learning_rate": 0.05353413006720257,
      "loss": 2.7263,
      "step": 289140
    },
    {
      "epoch": 464.89,
      "learning_rate": 0.05353091463633441,
      "loss": 2.7113,
      "step": 289160
    },
    {
      "epoch": 464.92,
      "learning_rate": 0.05352769920546624,
      "loss": 2.7245,
      "step": 289180
    },
    {
      "epoch": 464.95,
      "learning_rate": 0.05352448377459809,
      "loss": 2.7266,
      "step": 289200
    },
    {
      "epoch": 464.98,
      "learning_rate": 0.0535212683437299,
      "loss": 2.7297,
      "step": 289220
    },
    {
      "epoch": 465.0,
      "eval_accuracy": {
        "accuracy": 0.41063515509601184
      },
      "eval_loss": 2.821460723876953,
      "eval_runtime": 3.3042,
      "eval_samples_per_second": 3892.939,
      "eval_steps_per_second": 60.832,
      "step": 289230
    },
    {
      "epoch": 465.02,
      "learning_rate": 0.05351805291286174,
      "loss": 2.7033,
      "step": 289240
    },
    {
      "epoch": 465.05,
      "learning_rate": 0.05351483748199357,
      "loss": 2.7424,
      "step": 289260
    },
    {
      "epoch": 465.08,
      "learning_rate": 0.0535116220511254,
      "loss": 2.7471,
      "step": 289280
    },
    {
      "epoch": 465.11,
      "learning_rate": 0.05350840662025724,
      "loss": 2.7194,
      "step": 289300
    },
    {
      "epoch": 465.14,
      "learning_rate": 0.05350519118938907,
      "loss": 2.7239,
      "step": 289320
    },
    {
      "epoch": 465.18,
      "learning_rate": 0.053501975758520906,
      "loss": 2.7023,
      "step": 289340
    },
    {
      "epoch": 465.21,
      "learning_rate": 0.053498760327652745,
      "loss": 2.7391,
      "step": 289360
    },
    {
      "epoch": 465.24,
      "learning_rate": 0.05349554489678457,
      "loss": 2.7157,
      "step": 289380
    },
    {
      "epoch": 465.27,
      "learning_rate": 0.0534923294659164,
      "loss": 2.7025,
      "step": 289400
    },
    {
      "epoch": 465.31,
      "learning_rate": 0.053489114035048226,
      "loss": 2.7048,
      "step": 289420
    },
    {
      "epoch": 465.34,
      "learning_rate": 0.05348589860418007,
      "loss": 2.7048,
      "step": 289440
    },
    {
      "epoch": 465.37,
      "learning_rate": 0.053482683173311896,
      "loss": 2.7063,
      "step": 289460
    },
    {
      "epoch": 465.4,
      "learning_rate": 0.053479467742443734,
      "loss": 2.6883,
      "step": 289480
    },
    {
      "epoch": 465.43,
      "learning_rate": 0.05347625231157557,
      "loss": 2.7286,
      "step": 289500
    },
    {
      "epoch": 465.47,
      "learning_rate": 0.0534730368807074,
      "loss": 2.718,
      "step": 289520
    },
    {
      "epoch": 465.5,
      "learning_rate": 0.05346982144983923,
      "loss": 2.7004,
      "step": 289540
    },
    {
      "epoch": 465.53,
      "learning_rate": 0.053466606018971054,
      "loss": 2.7264,
      "step": 289560
    },
    {
      "epoch": 465.56,
      "learning_rate": 0.0534633905881029,
      "loss": 2.7194,
      "step": 289580
    },
    {
      "epoch": 465.59,
      "learning_rate": 0.053460175157234724,
      "loss": 2.7248,
      "step": 289600
    },
    {
      "epoch": 465.63,
      "learning_rate": 0.05345695972636656,
      "loss": 2.7313,
      "step": 289620
    },
    {
      "epoch": 465.66,
      "learning_rate": 0.05345374429549841,
      "loss": 2.7172,
      "step": 289640
    },
    {
      "epoch": 465.69,
      "learning_rate": 0.053450528864630226,
      "loss": 2.7268,
      "step": 289660
    },
    {
      "epoch": 465.72,
      "learning_rate": 0.05344731343376206,
      "loss": 2.7216,
      "step": 289680
    },
    {
      "epoch": 465.76,
      "learning_rate": 0.053444098002893896,
      "loss": 2.7254,
      "step": 289700
    },
    {
      "epoch": 465.79,
      "learning_rate": 0.05344088257202573,
      "loss": 2.7297,
      "step": 289720
    },
    {
      "epoch": 465.82,
      "learning_rate": 0.05343766714115755,
      "loss": 2.7355,
      "step": 289740
    },
    {
      "epoch": 465.85,
      "learning_rate": 0.05343445171028939,
      "loss": 2.7299,
      "step": 289760
    },
    {
      "epoch": 465.88,
      "learning_rate": 0.05343123627942123,
      "loss": 2.7103,
      "step": 289780
    },
    {
      "epoch": 465.92,
      "learning_rate": 0.053428020848553054,
      "loss": 2.7168,
      "step": 289800
    },
    {
      "epoch": 465.95,
      "learning_rate": 0.053424805417684886,
      "loss": 2.7153,
      "step": 289820
    },
    {
      "epoch": 465.98,
      "learning_rate": 0.053421589986816724,
      "loss": 2.7064,
      "step": 289840
    },
    {
      "epoch": 466.0,
      "eval_accuracy": {
        "accuracy": 0.39741895358781
      },
      "eval_loss": 2.874199390411377,
      "eval_runtime": 3.2884,
      "eval_samples_per_second": 3911.576,
      "eval_steps_per_second": 61.123,
      "step": 289852
    },
    {
      "epoch": 466.01,
      "learning_rate": 0.053418374555948556,
      "loss": 2.756,
      "step": 289860
    },
    {
      "epoch": 466.05,
      "learning_rate": 0.053415159125080394,
      "loss": 2.7344,
      "step": 289880
    },
    {
      "epoch": 466.08,
      "learning_rate": 0.05341194369421222,
      "loss": 2.7282,
      "step": 289900
    },
    {
      "epoch": 466.11,
      "learning_rate": 0.05340872826334406,
      "loss": 2.757,
      "step": 289920
    },
    {
      "epoch": 466.14,
      "learning_rate": 0.05340551283247589,
      "loss": 2.7185,
      "step": 289940
    },
    {
      "epoch": 466.17,
      "learning_rate": 0.053402297401607714,
      "loss": 2.7079,
      "step": 289960
    },
    {
      "epoch": 466.21,
      "learning_rate": 0.05339908197073956,
      "loss": 2.7212,
      "step": 289980
    },
    {
      "epoch": 466.24,
      "learning_rate": 0.053395866539871384,
      "loss": 2.7176,
      "step": 290000
    },
    {
      "epoch": 466.27,
      "learning_rate": 0.05339265110900322,
      "loss": 2.724,
      "step": 290020
    },
    {
      "epoch": 466.3,
      "learning_rate": 0.05338943567813506,
      "loss": 2.7077,
      "step": 290040
    },
    {
      "epoch": 466.33,
      "learning_rate": 0.053386220247266886,
      "loss": 2.7043,
      "step": 290060
    },
    {
      "epoch": 466.37,
      "learning_rate": 0.05338300481639872,
      "loss": 2.7002,
      "step": 290080
    },
    {
      "epoch": 466.4,
      "learning_rate": 0.05337978938553054,
      "loss": 2.6974,
      "step": 290100
    },
    {
      "epoch": 466.43,
      "learning_rate": 0.05337657395466239,
      "loss": 2.7255,
      "step": 290120
    },
    {
      "epoch": 466.46,
      "learning_rate": 0.05337335852379421,
      "loss": 2.7375,
      "step": 290140
    },
    {
      "epoch": 466.5,
      "learning_rate": 0.05337014309292605,
      "loss": 2.7425,
      "step": 290160
    },
    {
      "epoch": 466.53,
      "learning_rate": 0.05336692766205789,
      "loss": 2.7152,
      "step": 290180
    },
    {
      "epoch": 466.56,
      "learning_rate": 0.053363712231189714,
      "loss": 2.7067,
      "step": 290200
    },
    {
      "epoch": 466.59,
      "learning_rate": 0.053360496800321545,
      "loss": 2.7244,
      "step": 290220
    },
    {
      "epoch": 466.62,
      "learning_rate": 0.05335728136945337,
      "loss": 2.6965,
      "step": 290240
    },
    {
      "epoch": 466.66,
      "learning_rate": 0.053354065938585216,
      "loss": 2.7105,
      "step": 290260
    },
    {
      "epoch": 466.69,
      "learning_rate": 0.05335085050771704,
      "loss": 2.7193,
      "step": 290280
    },
    {
      "epoch": 466.72,
      "learning_rate": 0.05334763507684888,
      "loss": 2.6999,
      "step": 290300
    },
    {
      "epoch": 466.75,
      "learning_rate": 0.05334441964598072,
      "loss": 2.7092,
      "step": 290320
    },
    {
      "epoch": 466.78,
      "learning_rate": 0.053341364986655954,
      "loss": 2.7067,
      "step": 290340
    },
    {
      "epoch": 466.82,
      "learning_rate": 0.05333814955578778,
      "loss": 2.7065,
      "step": 290360
    },
    {
      "epoch": 466.85,
      "learning_rate": 0.053334934124919624,
      "loss": 2.7305,
      "step": 290380
    },
    {
      "epoch": 466.88,
      "learning_rate": 0.053331718694051435,
      "loss": 2.7004,
      "step": 290400
    },
    {
      "epoch": 466.91,
      "learning_rate": 0.05332850326318328,
      "loss": 2.7262,
      "step": 290420
    },
    {
      "epoch": 466.95,
      "learning_rate": 0.05332528783231512,
      "loss": 2.731,
      "step": 290440
    },
    {
      "epoch": 466.98,
      "learning_rate": 0.05332207240144694,
      "loss": 2.7406,
      "step": 290460
    },
    {
      "epoch": 467.0,
      "eval_accuracy": {
        "accuracy": 0.4065925522817383
      },
      "eval_loss": 2.833937168121338,
      "eval_runtime": 3.1558,
      "eval_samples_per_second": 4075.936,
      "eval_steps_per_second": 63.691,
      "step": 290474
    },
    {
      "epoch": 467.01,
      "learning_rate": 0.05331885697057879,
      "loss": 2.7277,
      "step": 290480
    },
    {
      "epoch": 467.04,
      "learning_rate": 0.053315641539710606,
      "loss": 2.7177,
      "step": 290500
    },
    {
      "epoch": 467.07,
      "learning_rate": 0.05331242610884245,
      "loss": 2.7054,
      "step": 290520
    },
    {
      "epoch": 467.11,
      "learning_rate": 0.053309210677974284,
      "loss": 2.7195,
      "step": 290540
    },
    {
      "epoch": 467.14,
      "learning_rate": 0.05330599524710611,
      "loss": 2.715,
      "step": 290560
    },
    {
      "epoch": 467.17,
      "learning_rate": 0.05330277981623796,
      "loss": 2.7558,
      "step": 290580
    },
    {
      "epoch": 467.2,
      "learning_rate": 0.05329956438536977,
      "loss": 2.7339,
      "step": 290600
    },
    {
      "epoch": 467.23,
      "learning_rate": 0.05329634895450162,
      "loss": 2.7134,
      "step": 290620
    },
    {
      "epoch": 467.27,
      "learning_rate": 0.05329313352363344,
      "loss": 2.725,
      "step": 290640
    },
    {
      "epoch": 467.3,
      "learning_rate": 0.05328991809276528,
      "loss": 2.7159,
      "step": 290660
    },
    {
      "epoch": 467.33,
      "learning_rate": 0.053286702661897105,
      "loss": 2.7383,
      "step": 290680
    },
    {
      "epoch": 467.36,
      "learning_rate": 0.053283487231028936,
      "loss": 2.749,
      "step": 290700
    },
    {
      "epoch": 467.4,
      "learning_rate": 0.05328027180016079,
      "loss": 2.7004,
      "step": 290720
    },
    {
      "epoch": 467.43,
      "learning_rate": 0.053277056369292614,
      "loss": 2.7145,
      "step": 290740
    },
    {
      "epoch": 467.46,
      "learning_rate": 0.053273840938424445,
      "loss": 2.7278,
      "step": 290760
    },
    {
      "epoch": 467.49,
      "learning_rate": 0.05327062550755627,
      "loss": 2.7335,
      "step": 290780
    },
    {
      "epoch": 467.52,
      "learning_rate": 0.053267410076688095,
      "loss": 2.7432,
      "step": 290800
    },
    {
      "epoch": 467.56,
      "learning_rate": 0.05326419464581994,
      "loss": 2.7459,
      "step": 290820
    },
    {
      "epoch": 467.59,
      "learning_rate": 0.053260979214951765,
      "loss": 2.7225,
      "step": 290840
    },
    {
      "epoch": 467.62,
      "learning_rate": 0.05325776378408362,
      "loss": 2.7212,
      "step": 290860
    },
    {
      "epoch": 467.65,
      "learning_rate": 0.05325454835321544,
      "loss": 2.7072,
      "step": 290880
    },
    {
      "epoch": 467.68,
      "learning_rate": 0.053251332922347266,
      "loss": 2.6981,
      "step": 290900
    },
    {
      "epoch": 467.72,
      "learning_rate": 0.05324811749147911,
      "loss": 2.7094,
      "step": 290920
    },
    {
      "epoch": 467.75,
      "learning_rate": 0.05324490206061092,
      "loss": 2.7,
      "step": 290940
    },
    {
      "epoch": 467.78,
      "learning_rate": 0.05324168662974277,
      "loss": 2.7142,
      "step": 290960
    },
    {
      "epoch": 467.81,
      "learning_rate": 0.05323847119887461,
      "loss": 2.7037,
      "step": 290980
    },
    {
      "epoch": 467.85,
      "learning_rate": 0.05323525576800643,
      "loss": 2.7166,
      "step": 291000
    },
    {
      "epoch": 467.88,
      "learning_rate": 0.05323204033713827,
      "loss": 2.7242,
      "step": 291020
    },
    {
      "epoch": 467.91,
      "learning_rate": 0.053228824906270095,
      "loss": 2.712,
      "step": 291040
    },
    {
      "epoch": 467.94,
      "learning_rate": 0.05322560947540194,
      "loss": 2.7232,
      "step": 291060
    },
    {
      "epoch": 467.97,
      "learning_rate": 0.05322239404453377,
      "loss": 2.7709,
      "step": 291080
    },
    {
      "epoch": 468.0,
      "eval_accuracy": {
        "accuracy": 0.4035606001710332
      },
      "eval_loss": 2.8490965366363525,
      "eval_runtime": 2.9674,
      "eval_samples_per_second": 4334.841,
      "eval_steps_per_second": 67.737,
      "step": 291096
    },
    {
      "epoch": 468.01,
      "learning_rate": 0.053219178613665596,
      "loss": 2.7724,
      "step": 291100
    },
    {
      "epoch": 468.04,
      "learning_rate": 0.05321596318279742,
      "loss": 2.7091,
      "step": 291120
    },
    {
      "epoch": 468.07,
      "learning_rate": 0.05321274775192926,
      "loss": 2.6985,
      "step": 291140
    },
    {
      "epoch": 468.1,
      "learning_rate": 0.053209532321061105,
      "loss": 2.7006,
      "step": 291160
    },
    {
      "epoch": 468.14,
      "learning_rate": 0.05320631689019292,
      "loss": 2.7267,
      "step": 291180
    },
    {
      "epoch": 468.17,
      "learning_rate": 0.05320310145932477,
      "loss": 2.691,
      "step": 291200
    },
    {
      "epoch": 468.2,
      "learning_rate": 0.05319988602845659,
      "loss": 2.7233,
      "step": 291220
    },
    {
      "epoch": 468.23,
      "learning_rate": 0.053196670597588425,
      "loss": 2.7048,
      "step": 291240
    },
    {
      "epoch": 468.26,
      "learning_rate": 0.05319345516672028,
      "loss": 2.6874,
      "step": 291260
    },
    {
      "epoch": 468.3,
      "learning_rate": 0.05319023973585209,
      "loss": 2.7046,
      "step": 291280
    },
    {
      "epoch": 468.33,
      "learning_rate": 0.05318702430498393,
      "loss": 2.7212,
      "step": 291300
    },
    {
      "epoch": 468.36,
      "learning_rate": 0.05318380887411576,
      "loss": 2.698,
      "step": 291320
    },
    {
      "epoch": 468.39,
      "learning_rate": 0.05318059344324758,
      "loss": 2.7063,
      "step": 291340
    },
    {
      "epoch": 468.42,
      "learning_rate": 0.05317737801237942,
      "loss": 2.6835,
      "step": 291360
    },
    {
      "epoch": 468.46,
      "learning_rate": 0.05317416258151125,
      "loss": 2.71,
      "step": 291380
    },
    {
      "epoch": 468.49,
      "learning_rate": 0.053170947150643105,
      "loss": 2.7011,
      "step": 291400
    },
    {
      "epoch": 468.52,
      "learning_rate": 0.05316773171977493,
      "loss": 2.7459,
      "step": 291420
    },
    {
      "epoch": 468.55,
      "learning_rate": 0.053164516288906755,
      "loss": 2.7153,
      "step": 291440
    },
    {
      "epoch": 468.59,
      "learning_rate": 0.053161300858038586,
      "loss": 2.702,
      "step": 291460
    },
    {
      "epoch": 468.62,
      "learning_rate": 0.05315808542717041,
      "loss": 2.7089,
      "step": 291480
    },
    {
      "epoch": 468.65,
      "learning_rate": 0.053154869996302256,
      "loss": 2.7091,
      "step": 291500
    },
    {
      "epoch": 468.68,
      "learning_rate": 0.05315165456543408,
      "loss": 2.6917,
      "step": 291520
    },
    {
      "epoch": 468.71,
      "learning_rate": 0.05314843913456592,
      "loss": 2.6958,
      "step": 291540
    },
    {
      "epoch": 468.75,
      "learning_rate": 0.05314522370369776,
      "loss": 2.7062,
      "step": 291560
    },
    {
      "epoch": 468.78,
      "learning_rate": 0.05314200827282958,
      "loss": 2.7238,
      "step": 291580
    },
    {
      "epoch": 468.81,
      "learning_rate": 0.05313879284196143,
      "loss": 2.6944,
      "step": 291600
    },
    {
      "epoch": 468.84,
      "learning_rate": 0.05313557741109324,
      "loss": 2.7325,
      "step": 291620
    },
    {
      "epoch": 468.87,
      "learning_rate": 0.053132361980225085,
      "loss": 2.7229,
      "step": 291640
    },
    {
      "epoch": 468.91,
      "learning_rate": 0.05312914654935691,
      "loss": 2.7229,
      "step": 291660
    },
    {
      "epoch": 468.94,
      "learning_rate": 0.05312593111848875,
      "loss": 2.735,
      "step": 291680
    },
    {
      "epoch": 468.97,
      "learning_rate": 0.05312271568762059,
      "loss": 2.7407,
      "step": 291700
    },
    {
      "epoch": 469.0,
      "eval_accuracy": {
        "accuracy": 0.4008396175075799
      },
      "eval_loss": 2.841757297515869,
      "eval_runtime": 3.1629,
      "eval_samples_per_second": 4066.886,
      "eval_steps_per_second": 63.55,
      "step": 291718
    },
    {
      "epoch": 469.0,
      "learning_rate": 0.05311950025675241,
      "loss": 2.719,
      "step": 291720
    },
    {
      "epoch": 469.04,
      "learning_rate": 0.05311628482588424,
      "loss": 2.6997,
      "step": 291740
    },
    {
      "epoch": 469.07,
      "learning_rate": 0.05311306939501608,
      "loss": 2.737,
      "step": 291760
    },
    {
      "epoch": 469.1,
      "learning_rate": 0.05310985396414791,
      "loss": 2.722,
      "step": 291780
    },
    {
      "epoch": 469.13,
      "learning_rate": 0.05310663853327974,
      "loss": 2.7059,
      "step": 291800
    },
    {
      "epoch": 469.16,
      "learning_rate": 0.053103423102411576,
      "loss": 2.6816,
      "step": 291820
    },
    {
      "epoch": 469.2,
      "learning_rate": 0.05310020767154342,
      "loss": 2.6905,
      "step": 291840
    },
    {
      "epoch": 469.23,
      "learning_rate": 0.05309699224067524,
      "loss": 2.7047,
      "step": 291860
    },
    {
      "epoch": 469.26,
      "learning_rate": 0.05309377680980707,
      "loss": 2.7343,
      "step": 291880
    },
    {
      "epoch": 469.29,
      "learning_rate": 0.05309056137893891,
      "loss": 2.6946,
      "step": 291900
    },
    {
      "epoch": 469.32,
      "learning_rate": 0.05308734594807074,
      "loss": 2.7044,
      "step": 291920
    },
    {
      "epoch": 469.36,
      "learning_rate": 0.05308413051720259,
      "loss": 2.7019,
      "step": 291940
    },
    {
      "epoch": 469.39,
      "learning_rate": 0.053080915086334404,
      "loss": 2.7299,
      "step": 291960
    },
    {
      "epoch": 469.42,
      "learning_rate": 0.05307769965546624,
      "loss": 2.718,
      "step": 291980
    },
    {
      "epoch": 469.45,
      "learning_rate": 0.053074484224598074,
      "loss": 2.7266,
      "step": 292000
    },
    {
      "epoch": 469.49,
      "learning_rate": 0.0530712687937299,
      "loss": 2.7192,
      "step": 292020
    },
    {
      "epoch": 469.52,
      "learning_rate": 0.053068053362861745,
      "loss": 2.6815,
      "step": 292040
    },
    {
      "epoch": 469.55,
      "learning_rate": 0.05306483793199357,
      "loss": 2.7107,
      "step": 292060
    },
    {
      "epoch": 469.58,
      "learning_rate": 0.05306162250112541,
      "loss": 2.7216,
      "step": 292080
    },
    {
      "epoch": 469.61,
      "learning_rate": 0.053058407070257246,
      "loss": 2.7269,
      "step": 292100
    },
    {
      "epoch": 469.65,
      "learning_rate": 0.05305519163938907,
      "loss": 2.7305,
      "step": 292120
    },
    {
      "epoch": 469.68,
      "learning_rate": 0.0530519762085209,
      "loss": 2.7309,
      "step": 292140
    },
    {
      "epoch": 469.71,
      "learning_rate": 0.05304876077765273,
      "loss": 2.735,
      "step": 292160
    },
    {
      "epoch": 469.74,
      "learning_rate": 0.05304554534678457,
      "loss": 2.7063,
      "step": 292180
    },
    {
      "epoch": 469.77,
      "learning_rate": 0.0530423299159164,
      "loss": 2.7191,
      "step": 292200
    },
    {
      "epoch": 469.81,
      "learning_rate": 0.053039114485048236,
      "loss": 2.6978,
      "step": 292220
    },
    {
      "epoch": 469.84,
      "learning_rate": 0.053035899054180075,
      "loss": 2.7051,
      "step": 292240
    },
    {
      "epoch": 469.87,
      "learning_rate": 0.0530326836233119,
      "loss": 2.7262,
      "step": 292260
    },
    {
      "epoch": 469.9,
      "learning_rate": 0.05302946819244373,
      "loss": 2.7141,
      "step": 292280
    },
    {
      "epoch": 469.94,
      "learning_rate": 0.053026252761575556,
      "loss": 2.7072,
      "step": 292300
    },
    {
      "epoch": 469.97,
      "learning_rate": 0.0530230373307074,
      "loss": 2.7118,
      "step": 292320
    },
    {
      "epoch": 470.0,
      "learning_rate": 0.053019821899839226,
      "loss": 2.7279,
      "step": 292340
    },
    {
      "epoch": 470.0,
      "eval_accuracy": {
        "accuracy": 0.41491098499572415
      },
      "eval_loss": 2.794661283493042,
      "eval_runtime": 3.1862,
      "eval_samples_per_second": 4037.084,
      "eval_steps_per_second": 63.084,
      "step": 292340
    },
    {
      "epoch": 470.03,
      "learning_rate": 0.053016606468971064,
      "loss": 2.7056,
      "step": 292360
    },
    {
      "epoch": 470.06,
      "learning_rate": 0.05301339103810291,
      "loss": 2.728,
      "step": 292380
    },
    {
      "epoch": 470.1,
      "learning_rate": 0.05301017560723473,
      "loss": 2.7237,
      "step": 292400
    },
    {
      "epoch": 470.13,
      "learning_rate": 0.05300696017636656,
      "loss": 2.7179,
      "step": 292420
    },
    {
      "epoch": 470.16,
      "learning_rate": 0.0530037447454984,
      "loss": 2.7214,
      "step": 292440
    },
    {
      "epoch": 470.19,
      "learning_rate": 0.05300052931463023,
      "loss": 2.7231,
      "step": 292460
    },
    {
      "epoch": 470.23,
      "learning_rate": 0.052997313883762054,
      "loss": 2.7109,
      "step": 292480
    },
    {
      "epoch": 470.26,
      "learning_rate": 0.05299409845289389,
      "loss": 2.7294,
      "step": 292500
    },
    {
      "epoch": 470.29,
      "learning_rate": 0.05299088302202573,
      "loss": 2.7141,
      "step": 292520
    },
    {
      "epoch": 470.32,
      "learning_rate": 0.052987667591157556,
      "loss": 2.7031,
      "step": 292540
    },
    {
      "epoch": 470.35,
      "learning_rate": 0.05298445216028939,
      "loss": 2.692,
      "step": 292560
    },
    {
      "epoch": 470.39,
      "learning_rate": 0.052981236729421226,
      "loss": 2.7054,
      "step": 292580
    },
    {
      "epoch": 470.42,
      "learning_rate": 0.05297802129855306,
      "loss": 2.7067,
      "step": 292600
    },
    {
      "epoch": 470.45,
      "learning_rate": 0.052974805867684896,
      "loss": 2.6804,
      "step": 292620
    },
    {
      "epoch": 470.48,
      "learning_rate": 0.05297159043681672,
      "loss": 2.7038,
      "step": 292640
    },
    {
      "epoch": 470.51,
      "learning_rate": 0.05296837500594856,
      "loss": 2.7075,
      "step": 292660
    },
    {
      "epoch": 470.55,
      "learning_rate": 0.05296515957508039,
      "loss": 2.6894,
      "step": 292680
    },
    {
      "epoch": 470.58,
      "learning_rate": 0.052961944144212215,
      "loss": 2.7132,
      "step": 292700
    },
    {
      "epoch": 470.61,
      "learning_rate": 0.05295872871334406,
      "loss": 2.7301,
      "step": 292720
    },
    {
      "epoch": 470.64,
      "learning_rate": 0.052955513282475886,
      "loss": 2.7415,
      "step": 292740
    },
    {
      "epoch": 470.68,
      "learning_rate": 0.052952297851607724,
      "loss": 2.7353,
      "step": 292760
    },
    {
      "epoch": 470.71,
      "learning_rate": 0.05294908242073956,
      "loss": 2.7285,
      "step": 292780
    },
    {
      "epoch": 470.74,
      "learning_rate": 0.05294586698987139,
      "loss": 2.7245,
      "step": 292800
    },
    {
      "epoch": 470.77,
      "learning_rate": 0.05294265155900322,
      "loss": 2.7294,
      "step": 292820
    },
    {
      "epoch": 470.8,
      "learning_rate": 0.052939436128135044,
      "loss": 2.7175,
      "step": 292840
    },
    {
      "epoch": 470.84,
      "learning_rate": 0.05293622069726689,
      "loss": 2.7166,
      "step": 292860
    },
    {
      "epoch": 470.87,
      "learning_rate": 0.05293300526639871,
      "loss": 2.6921,
      "step": 292880
    },
    {
      "epoch": 470.9,
      "learning_rate": 0.05292978983553055,
      "loss": 2.7221,
      "step": 292900
    },
    {
      "epoch": 470.93,
      "learning_rate": 0.05292657440466239,
      "loss": 2.6752,
      "step": 292920
    },
    {
      "epoch": 470.96,
      "learning_rate": 0.052923358973794216,
      "loss": 2.6884,
      "step": 292940
    },
    {
      "epoch": 471.0,
      "learning_rate": 0.05292014354292605,
      "loss": 2.704,
      "step": 292960
    },
    {
      "epoch": 471.0,
      "eval_accuracy": {
        "accuracy": 0.40410479670372385
      },
      "eval_loss": 2.8283793926239014,
      "eval_runtime": 2.9683,
      "eval_samples_per_second": 4333.505,
      "eval_steps_per_second": 67.716,
      "step": 292962
    },
    {
      "epoch": 471.03,
      "learning_rate": 0.05291692811205787,
      "loss": 2.7302,
      "step": 292980
    },
    {
      "epoch": 471.06,
      "learning_rate": 0.05291371268118972,
      "loss": 2.7288,
      "step": 293000
    },
    {
      "epoch": 471.09,
      "learning_rate": 0.05291049725032154,
      "loss": 2.7102,
      "step": 293020
    },
    {
      "epoch": 471.13,
      "learning_rate": 0.05290728181945338,
      "loss": 2.7092,
      "step": 293040
    },
    {
      "epoch": 471.16,
      "learning_rate": 0.05290406638858522,
      "loss": 2.7172,
      "step": 293060
    },
    {
      "epoch": 471.19,
      "learning_rate": 0.052900850957717044,
      "loss": 2.738,
      "step": 293080
    },
    {
      "epoch": 471.22,
      "learning_rate": 0.052897635526848875,
      "loss": 2.6996,
      "step": 293100
    },
    {
      "epoch": 471.25,
      "learning_rate": 0.052894420095980714,
      "loss": 2.7078,
      "step": 293120
    },
    {
      "epoch": 471.29,
      "learning_rate": 0.052891204665112546,
      "loss": 2.7136,
      "step": 293140
    },
    {
      "epoch": 471.32,
      "learning_rate": 0.05288798923424437,
      "loss": 2.7179,
      "step": 293160
    },
    {
      "epoch": 471.35,
      "learning_rate": 0.05288477380337621,
      "loss": 2.7052,
      "step": 293180
    },
    {
      "epoch": 471.38,
      "learning_rate": 0.05288155837250805,
      "loss": 2.7053,
      "step": 293200
    },
    {
      "epoch": 471.41,
      "learning_rate": 0.05287834294163987,
      "loss": 2.7041,
      "step": 293220
    },
    {
      "epoch": 471.45,
      "learning_rate": 0.052875127510771704,
      "loss": 2.7022,
      "step": 293240
    },
    {
      "epoch": 471.48,
      "learning_rate": 0.05287191207990354,
      "loss": 2.7044,
      "step": 293260
    },
    {
      "epoch": 471.51,
      "learning_rate": 0.052868696649035374,
      "loss": 2.7335,
      "step": 293280
    },
    {
      "epoch": 471.54,
      "learning_rate": 0.05286548121816721,
      "loss": 2.7188,
      "step": 293300
    },
    {
      "epoch": 471.58,
      "learning_rate": 0.05286226578729902,
      "loss": 2.6868,
      "step": 293320
    },
    {
      "epoch": 471.61,
      "learning_rate": 0.052859050356430876,
      "loss": 2.729,
      "step": 293340
    },
    {
      "epoch": 471.64,
      "learning_rate": 0.05285583492556271,
      "loss": 2.7516,
      "step": 293360
    },
    {
      "epoch": 471.67,
      "learning_rate": 0.05285261949469453,
      "loss": 2.7013,
      "step": 293380
    },
    {
      "epoch": 471.7,
      "learning_rate": 0.05284940406382638,
      "loss": 2.6942,
      "step": 293400
    },
    {
      "epoch": 471.74,
      "learning_rate": 0.052846188632958195,
      "loss": 2.7105,
      "step": 293420
    },
    {
      "epoch": 471.77,
      "learning_rate": 0.05284297320209004,
      "loss": 2.6852,
      "step": 293440
    },
    {
      "epoch": 471.8,
      "learning_rate": 0.05283975777122188,
      "loss": 2.7109,
      "step": 293460
    },
    {
      "epoch": 471.83,
      "learning_rate": 0.052836542340353704,
      "loss": 2.7204,
      "step": 293480
    },
    {
      "epoch": 471.86,
      "learning_rate": 0.052833326909485535,
      "loss": 2.7125,
      "step": 293500
    },
    {
      "epoch": 471.9,
      "learning_rate": 0.05283011147861736,
      "loss": 2.7197,
      "step": 293520
    },
    {
      "epoch": 471.93,
      "learning_rate": 0.052826896047749206,
      "loss": 2.7657,
      "step": 293540
    },
    {
      "epoch": 471.96,
      "learning_rate": 0.05282368061688102,
      "loss": 2.7019,
      "step": 293560
    },
    {
      "epoch": 471.99,
      "learning_rate": 0.05282046518601287,
      "loss": 2.7014,
      "step": 293580
    },
    {
      "epoch": 472.0,
      "eval_accuracy": {
        "accuracy": 0.40410479670372385
      },
      "eval_loss": 2.859070062637329,
      "eval_runtime": 3.0264,
      "eval_samples_per_second": 4250.236,
      "eval_steps_per_second": 66.415,
      "step": 293584
    },
    {
      "epoch": 472.03,
      "learning_rate": 0.05281724975514471,
      "loss": 2.7164,
      "step": 293600
    },
    {
      "epoch": 472.06,
      "learning_rate": 0.05281403432427653,
      "loss": 2.6982,
      "step": 293620
    },
    {
      "epoch": 472.09,
      "learning_rate": 0.052810818893408364,
      "loss": 2.6974,
      "step": 293640
    },
    {
      "epoch": 472.12,
      "learning_rate": 0.052807764234083614,
      "loss": 2.7029,
      "step": 293660
    },
    {
      "epoch": 472.15,
      "learning_rate": 0.052804548803215424,
      "loss": 2.7352,
      "step": 293680
    },
    {
      "epoch": 472.19,
      "learning_rate": 0.05280133337234727,
      "loss": 2.6834,
      "step": 293700
    },
    {
      "epoch": 472.22,
      "learning_rate": 0.05279811794147911,
      "loss": 2.6906,
      "step": 293720
    },
    {
      "epoch": 472.25,
      "learning_rate": 0.05279490251061093,
      "loss": 2.6886,
      "step": 293740
    },
    {
      "epoch": 472.28,
      "learning_rate": 0.05279168707974277,
      "loss": 2.709,
      "step": 293760
    },
    {
      "epoch": 472.32,
      "learning_rate": 0.052788471648874596,
      "loss": 2.7194,
      "step": 293780
    },
    {
      "epoch": 472.35,
      "learning_rate": 0.05278525621800644,
      "loss": 2.7277,
      "step": 293800
    },
    {
      "epoch": 472.38,
      "learning_rate": 0.052782040787138274,
      "loss": 2.7009,
      "step": 293820
    },
    {
      "epoch": 472.41,
      "learning_rate": 0.0527788253562701,
      "loss": 2.681,
      "step": 293840
    },
    {
      "epoch": 472.44,
      "learning_rate": 0.05277560992540192,
      "loss": 2.6887,
      "step": 293860
    },
    {
      "epoch": 472.48,
      "learning_rate": 0.05277239449453376,
      "loss": 2.7044,
      "step": 293880
    },
    {
      "epoch": 472.51,
      "learning_rate": 0.05276917906366561,
      "loss": 2.6977,
      "step": 293900
    },
    {
      "epoch": 472.54,
      "learning_rate": 0.052765963632797425,
      "loss": 2.7001,
      "step": 293920
    },
    {
      "epoch": 472.57,
      "learning_rate": 0.052762748201929256,
      "loss": 2.6912,
      "step": 293940
    },
    {
      "epoch": 472.6,
      "learning_rate": 0.052759532771061095,
      "loss": 2.7079,
      "step": 293960
    },
    {
      "epoch": 472.64,
      "learning_rate": 0.052756317340192926,
      "loss": 2.7028,
      "step": 293980
    },
    {
      "epoch": 472.67,
      "learning_rate": 0.05275310190932478,
      "loss": 2.735,
      "step": 294000
    },
    {
      "epoch": 472.7,
      "learning_rate": 0.05274988647845659,
      "loss": 2.7183,
      "step": 294020
    },
    {
      "epoch": 472.73,
      "learning_rate": 0.052746671047588435,
      "loss": 2.711,
      "step": 294040
    },
    {
      "epoch": 472.77,
      "learning_rate": 0.05274345561672026,
      "loss": 2.732,
      "step": 294060
    },
    {
      "epoch": 472.8,
      "learning_rate": 0.052740240185852084,
      "loss": 2.7167,
      "step": 294080
    },
    {
      "epoch": 472.83,
      "learning_rate": 0.05273702475498392,
      "loss": 2.7106,
      "step": 294100
    },
    {
      "epoch": 472.86,
      "learning_rate": 0.052733809324115755,
      "loss": 2.7143,
      "step": 294120
    },
    {
      "epoch": 472.89,
      "learning_rate": 0.05273059389324761,
      "loss": 2.755,
      "step": 294140
    },
    {
      "epoch": 472.93,
      "learning_rate": 0.05272737846237943,
      "loss": 2.7273,
      "step": 294160
    },
    {
      "epoch": 472.96,
      "learning_rate": 0.052724163031511256,
      "loss": 2.7142,
      "step": 294180
    },
    {
      "epoch": 472.99,
      "learning_rate": 0.05272094760064309,
      "loss": 2.7356,
      "step": 294200
    },
    {
      "epoch": 473.0,
      "eval_accuracy": {
        "accuracy": 0.41016870092513413
      },
      "eval_loss": 2.8094658851623535,
      "eval_runtime": 2.8353,
      "eval_samples_per_second": 4536.734,
      "eval_steps_per_second": 70.892,
      "step": 294206
    },
    {
      "epoch": 473.02,
      "learning_rate": 0.05271773216977491,
      "loss": 2.7009,
      "step": 294220
    },
    {
      "epoch": 473.05,
      "learning_rate": 0.05271451673890676,
      "loss": 2.7147,
      "step": 294240
    },
    {
      "epoch": 473.09,
      "learning_rate": 0.05271130130803858,
      "loss": 2.7217,
      "step": 294260
    },
    {
      "epoch": 473.12,
      "learning_rate": 0.05270808587717042,
      "loss": 2.7105,
      "step": 294280
    },
    {
      "epoch": 473.15,
      "learning_rate": 0.05270487044630226,
      "loss": 2.7066,
      "step": 294300
    },
    {
      "epoch": 473.18,
      "learning_rate": 0.052701655015434085,
      "loss": 2.6999,
      "step": 294320
    },
    {
      "epoch": 473.22,
      "learning_rate": 0.05269843958456593,
      "loss": 2.7105,
      "step": 294340
    },
    {
      "epoch": 473.25,
      "learning_rate": 0.05269522415369774,
      "loss": 2.7117,
      "step": 294360
    },
    {
      "epoch": 473.28,
      "learning_rate": 0.052692008722829586,
      "loss": 2.6946,
      "step": 294380
    },
    {
      "epoch": 473.31,
      "learning_rate": 0.05268879329196141,
      "loss": 2.7178,
      "step": 294400
    },
    {
      "epoch": 473.34,
      "learning_rate": 0.05268557786109325,
      "loss": 2.7182,
      "step": 294420
    },
    {
      "epoch": 473.38,
      "learning_rate": 0.052682362430225095,
      "loss": 2.7097,
      "step": 294440
    },
    {
      "epoch": 473.41,
      "learning_rate": 0.05267914699935691,
      "loss": 2.6995,
      "step": 294460
    },
    {
      "epoch": 473.44,
      "learning_rate": 0.052675931568488744,
      "loss": 2.7354,
      "step": 294480
    },
    {
      "epoch": 473.47,
      "learning_rate": 0.05267271613762058,
      "loss": 2.7197,
      "step": 294500
    },
    {
      "epoch": 473.5,
      "learning_rate": 0.052669500706752415,
      "loss": 2.7138,
      "step": 294520
    },
    {
      "epoch": 473.54,
      "learning_rate": 0.05266628527588424,
      "loss": 2.7213,
      "step": 294540
    },
    {
      "epoch": 473.57,
      "learning_rate": 0.05266306984501608,
      "loss": 2.7134,
      "step": 294560
    },
    {
      "epoch": 473.6,
      "learning_rate": 0.05265985441414792,
      "loss": 2.6825,
      "step": 294580
    },
    {
      "epoch": 473.63,
      "learning_rate": 0.05265663898327974,
      "loss": 2.6987,
      "step": 294600
    },
    {
      "epoch": 473.67,
      "learning_rate": 0.05265342355241157,
      "loss": 2.6963,
      "step": 294620
    },
    {
      "epoch": 473.7,
      "learning_rate": 0.05265020812154341,
      "loss": 2.7325,
      "step": 294640
    },
    {
      "epoch": 473.73,
      "learning_rate": 0.05264699269067524,
      "loss": 2.7401,
      "step": 294660
    },
    {
      "epoch": 473.76,
      "learning_rate": 0.052643777259807095,
      "loss": 2.7147,
      "step": 294680
    },
    {
      "epoch": 473.79,
      "learning_rate": 0.052640561828938906,
      "loss": 2.6832,
      "step": 294700
    },
    {
      "epoch": 473.83,
      "learning_rate": 0.052637346398070745,
      "loss": 2.7312,
      "step": 294720
    },
    {
      "epoch": 473.86,
      "learning_rate": 0.052634130967202576,
      "loss": 2.7039,
      "step": 294740
    },
    {
      "epoch": 473.89,
      "learning_rate": 0.0526309155363344,
      "loss": 2.716,
      "step": 294760
    },
    {
      "epoch": 473.92,
      "learning_rate": 0.052627700105466246,
      "loss": 2.6954,
      "step": 294780
    },
    {
      "epoch": 473.95,
      "learning_rate": 0.05262448467459807,
      "loss": 2.7062,
      "step": 294800
    },
    {
      "epoch": 473.99,
      "learning_rate": 0.05262126924372991,
      "loss": 2.735,
      "step": 294820
    },
    {
      "epoch": 474.0,
      "eval_accuracy": {
        "accuracy": 0.41304516831221333
      },
      "eval_loss": 2.794506311416626,
      "eval_runtime": 2.8503,
      "eval_samples_per_second": 4512.852,
      "eval_steps_per_second": 70.519,
      "step": 294828
    },
    {
      "epoch": 474.02,
      "learning_rate": 0.05261805381286175,
      "loss": 2.6834,
      "step": 294840
    },
    {
      "epoch": 474.05,
      "learning_rate": 0.05261483838199357,
      "loss": 2.7303,
      "step": 294860
    },
    {
      "epoch": 474.08,
      "learning_rate": 0.052611622951125404,
      "loss": 2.7257,
      "step": 294880
    },
    {
      "epoch": 474.12,
      "learning_rate": 0.05260840752025723,
      "loss": 2.7202,
      "step": 294900
    },
    {
      "epoch": 474.15,
      "learning_rate": 0.052605192089389075,
      "loss": 2.7046,
      "step": 294920
    },
    {
      "epoch": 474.18,
      "learning_rate": 0.0526019766585209,
      "loss": 2.6958,
      "step": 294940
    },
    {
      "epoch": 474.21,
      "learning_rate": 0.05259876122765274,
      "loss": 2.7016,
      "step": 294960
    },
    {
      "epoch": 474.24,
      "learning_rate": 0.052595545796784576,
      "loss": 2.689,
      "step": 294980
    },
    {
      "epoch": 474.28,
      "learning_rate": 0.0525923303659164,
      "loss": 2.7107,
      "step": 295000
    },
    {
      "epoch": 474.31,
      "learning_rate": 0.05258911493504823,
      "loss": 2.7091,
      "step": 295020
    },
    {
      "epoch": 474.34,
      "learning_rate": 0.05258589950418006,
      "loss": 2.6996,
      "step": 295040
    },
    {
      "epoch": 474.37,
      "learning_rate": 0.0525826840733119,
      "loss": 2.6845,
      "step": 295060
    },
    {
      "epoch": 474.41,
      "learning_rate": 0.05257946864244373,
      "loss": 2.7194,
      "step": 295080
    },
    {
      "epoch": 474.44,
      "learning_rate": 0.052576253211575566,
      "loss": 2.7083,
      "step": 295100
    },
    {
      "epoch": 474.47,
      "learning_rate": 0.052573037780707405,
      "loss": 2.7166,
      "step": 295120
    },
    {
      "epoch": 474.5,
      "learning_rate": 0.05256982234983923,
      "loss": 2.6996,
      "step": 295140
    },
    {
      "epoch": 474.53,
      "learning_rate": 0.05256660691897106,
      "loss": 2.6884,
      "step": 295160
    },
    {
      "epoch": 474.57,
      "learning_rate": 0.0525633914881029,
      "loss": 2.6896,
      "step": 295180
    },
    {
      "epoch": 474.6,
      "learning_rate": 0.05256017605723473,
      "loss": 2.7328,
      "step": 295200
    },
    {
      "epoch": 474.63,
      "learning_rate": 0.052556960626366556,
      "loss": 2.7206,
      "step": 295220
    },
    {
      "epoch": 474.66,
      "learning_rate": 0.052553745195498394,
      "loss": 2.7005,
      "step": 295240
    },
    {
      "epoch": 474.69,
      "learning_rate": 0.05255052976463023,
      "loss": 2.7045,
      "step": 295260
    },
    {
      "epoch": 474.73,
      "learning_rate": 0.05254731433376206,
      "loss": 2.7385,
      "step": 295280
    },
    {
      "epoch": 474.76,
      "learning_rate": 0.05254409890289389,
      "loss": 2.7158,
      "step": 295300
    },
    {
      "epoch": 474.79,
      "learning_rate": 0.05254088347202573,
      "loss": 2.7326,
      "step": 295320
    },
    {
      "epoch": 474.82,
      "learning_rate": 0.05253766804115756,
      "loss": 2.7196,
      "step": 295340
    },
    {
      "epoch": 474.86,
      "learning_rate": 0.0525344526102894,
      "loss": 2.7135,
      "step": 295360
    },
    {
      "epoch": 474.89,
      "learning_rate": 0.05253123717942122,
      "loss": 2.7267,
      "step": 295380
    },
    {
      "epoch": 474.92,
      "learning_rate": 0.05252802174855306,
      "loss": 2.6993,
      "step": 295400
    },
    {
      "epoch": 474.95,
      "learning_rate": 0.05252480631768489,
      "loss": 2.6981,
      "step": 295420
    },
    {
      "epoch": 474.98,
      "learning_rate": 0.05252159088681672,
      "loss": 2.7131,
      "step": 295440
    },
    {
      "epoch": 475.0,
      "eval_accuracy": {
        "accuracy": 0.3956308792661121
      },
      "eval_loss": 2.877352237701416,
      "eval_runtime": 2.8058,
      "eval_samples_per_second": 4584.417,
      "eval_steps_per_second": 71.637,
      "step": 295450
    },
    {
      "epoch": 475.02,
      "learning_rate": 0.05251837545594856,
      "loss": 2.6963,
      "step": 295460
    },
    {
      "epoch": 475.05,
      "learning_rate": 0.05251516002508039,
      "loss": 2.6926,
      "step": 295480
    },
    {
      "epoch": 475.08,
      "learning_rate": 0.052511944594212226,
      "loss": 2.6951,
      "step": 295500
    },
    {
      "epoch": 475.11,
      "learning_rate": 0.052508729163344064,
      "loss": 2.7141,
      "step": 295520
    },
    {
      "epoch": 475.14,
      "learning_rate": 0.05250551373247589,
      "loss": 2.6902,
      "step": 295540
    },
    {
      "epoch": 475.18,
      "learning_rate": 0.05250229830160772,
      "loss": 2.7058,
      "step": 295560
    },
    {
      "epoch": 475.21,
      "learning_rate": 0.052499082870739545,
      "loss": 2.7126,
      "step": 295580
    },
    {
      "epoch": 475.24,
      "learning_rate": 0.05249586743987139,
      "loss": 2.7067,
      "step": 295600
    },
    {
      "epoch": 475.27,
      "learning_rate": 0.05249265200900321,
      "loss": 2.7064,
      "step": 295620
    },
    {
      "epoch": 475.31,
      "learning_rate": 0.052489436578135054,
      "loss": 2.7153,
      "step": 295640
    },
    {
      "epoch": 475.34,
      "learning_rate": 0.05248622114726689,
      "loss": 2.7188,
      "step": 295660
    },
    {
      "epoch": 475.37,
      "learning_rate": 0.05248300571639872,
      "loss": 2.73,
      "step": 295680
    },
    {
      "epoch": 475.4,
      "learning_rate": 0.05247995105707396,
      "loss": 2.6964,
      "step": 295700
    },
    {
      "epoch": 475.43,
      "learning_rate": 0.0524767356262058,
      "loss": 2.7271,
      "step": 295720
    },
    {
      "epoch": 475.47,
      "learning_rate": 0.05247352019533761,
      "loss": 2.7053,
      "step": 295740
    },
    {
      "epoch": 475.5,
      "learning_rate": 0.052470304764469455,
      "loss": 2.7121,
      "step": 295760
    },
    {
      "epoch": 475.53,
      "learning_rate": 0.052467089333601294,
      "loss": 2.6823,
      "step": 295780
    },
    {
      "epoch": 475.56,
      "learning_rate": 0.05246387390273313,
      "loss": 2.7059,
      "step": 295800
    },
    {
      "epoch": 475.59,
      "learning_rate": 0.05246065847186496,
      "loss": 2.708,
      "step": 295820
    },
    {
      "epoch": 475.63,
      "learning_rate": 0.05245744304099678,
      "loss": 2.7422,
      "step": 295840
    },
    {
      "epoch": 475.66,
      "learning_rate": 0.05245422761012863,
      "loss": 2.7081,
      "step": 295860
    },
    {
      "epoch": 475.69,
      "learning_rate": 0.05245101217926046,
      "loss": 2.7055,
      "step": 295880
    },
    {
      "epoch": 475.72,
      "learning_rate": 0.052447796748392284,
      "loss": 2.7072,
      "step": 295900
    },
    {
      "epoch": 475.76,
      "learning_rate": 0.05244458131752412,
      "loss": 2.7158,
      "step": 295920
    },
    {
      "epoch": 475.79,
      "learning_rate": 0.05244136588665595,
      "loss": 2.696,
      "step": 295940
    },
    {
      "epoch": 475.82,
      "learning_rate": 0.05243815045578779,
      "loss": 2.6863,
      "step": 295960
    },
    {
      "epoch": 475.85,
      "learning_rate": 0.05243493502491961,
      "loss": 2.7363,
      "step": 295980
    },
    {
      "epoch": 475.88,
      "learning_rate": 0.052431719594051455,
      "loss": 2.7187,
      "step": 296000
    },
    {
      "epoch": 475.92,
      "learning_rate": 0.05242850416318329,
      "loss": 2.7122,
      "step": 296020
    },
    {
      "epoch": 475.95,
      "learning_rate": 0.05242528873231511,
      "loss": 2.7288,
      "step": 296040
    },
    {
      "epoch": 475.98,
      "learning_rate": 0.052422073301446964,
      "loss": 2.7077,
      "step": 296060
    },
    {
      "epoch": 476.0,
      "eval_accuracy": {
        "accuracy": 0.41397807665396874
      },
      "eval_loss": 2.792325496673584,
      "eval_runtime": 2.7672,
      "eval_samples_per_second": 4648.302,
      "eval_steps_per_second": 72.635,
      "step": 296072
    },
    {
      "epoch": 476.01,
      "learning_rate": 0.052418857870578775,
      "loss": 2.6963,
      "step": 296080
    },
    {
      "epoch": 476.05,
      "learning_rate": 0.05241564243971062,
      "loss": 2.6986,
      "step": 296100
    },
    {
      "epoch": 476.08,
      "learning_rate": 0.052412427008842445,
      "loss": 2.7238,
      "step": 296120
    },
    {
      "epoch": 476.11,
      "learning_rate": 0.05240921157797427,
      "loss": 2.7003,
      "step": 296140
    },
    {
      "epoch": 476.14,
      "learning_rate": 0.05240599614710611,
      "loss": 2.7062,
      "step": 296160
    },
    {
      "epoch": 476.17,
      "learning_rate": 0.05240278071623794,
      "loss": 2.7127,
      "step": 296180
    },
    {
      "epoch": 476.21,
      "learning_rate": 0.05239956528536979,
      "loss": 2.7184,
      "step": 296200
    },
    {
      "epoch": 476.24,
      "learning_rate": 0.05239634985450162,
      "loss": 2.7055,
      "step": 296220
    },
    {
      "epoch": 476.27,
      "learning_rate": 0.05239313442363345,
      "loss": 2.733,
      "step": 296240
    },
    {
      "epoch": 476.3,
      "learning_rate": 0.05238991899276527,
      "loss": 2.7109,
      "step": 296260
    },
    {
      "epoch": 476.33,
      "learning_rate": 0.0523867035618971,
      "loss": 2.7209,
      "step": 296280
    },
    {
      "epoch": 476.37,
      "learning_rate": 0.052383488131028944,
      "loss": 2.716,
      "step": 296300
    },
    {
      "epoch": 476.4,
      "learning_rate": 0.05238027270016077,
      "loss": 2.7415,
      "step": 296320
    },
    {
      "epoch": 476.43,
      "learning_rate": 0.05237705726929262,
      "loss": 2.7151,
      "step": 296340
    },
    {
      "epoch": 476.46,
      "learning_rate": 0.052373841838424445,
      "loss": 2.7072,
      "step": 296360
    },
    {
      "epoch": 476.5,
      "learning_rate": 0.05237062640755627,
      "loss": 2.6772,
      "step": 296380
    },
    {
      "epoch": 476.53,
      "learning_rate": 0.052367410976688115,
      "loss": 2.6922,
      "step": 296400
    },
    {
      "epoch": 476.56,
      "learning_rate": 0.052364195545819926,
      "loss": 2.6782,
      "step": 296420
    },
    {
      "epoch": 476.59,
      "learning_rate": 0.05236098011495177,
      "loss": 2.7199,
      "step": 296440
    },
    {
      "epoch": 476.62,
      "learning_rate": 0.05235776468408361,
      "loss": 2.715,
      "step": 296460
    },
    {
      "epoch": 476.66,
      "learning_rate": 0.052354549253215435,
      "loss": 2.7272,
      "step": 296480
    },
    {
      "epoch": 476.69,
      "learning_rate": 0.052351333822347274,
      "loss": 2.7032,
      "step": 296500
    },
    {
      "epoch": 476.72,
      "learning_rate": 0.0523481183914791,
      "loss": 2.7138,
      "step": 296520
    },
    {
      "epoch": 476.75,
      "learning_rate": 0.052344902960610944,
      "loss": 2.7054,
      "step": 296540
    },
    {
      "epoch": 476.78,
      "learning_rate": 0.052341687529742775,
      "loss": 2.6872,
      "step": 296560
    },
    {
      "epoch": 476.82,
      "learning_rate": 0.0523384720988746,
      "loss": 2.7354,
      "step": 296580
    },
    {
      "epoch": 476.85,
      "learning_rate": 0.052335256668006425,
      "loss": 2.7221,
      "step": 296600
    },
    {
      "epoch": 476.88,
      "learning_rate": 0.05233204123713826,
      "loss": 2.7386,
      "step": 296620
    },
    {
      "epoch": 476.91,
      "learning_rate": 0.05232882580627011,
      "loss": 2.711,
      "step": 296640
    },
    {
      "epoch": 476.95,
      "learning_rate": 0.052325610375401926,
      "loss": 2.7254,
      "step": 296660
    },
    {
      "epoch": 476.98,
      "learning_rate": 0.05232239494453376,
      "loss": 2.7253,
      "step": 296680
    },
    {
      "epoch": 477.0,
      "eval_accuracy": {
        "accuracy": 0.4098577314778823
      },
      "eval_loss": 2.796060562133789,
      "eval_runtime": 2.9276,
      "eval_samples_per_second": 4393.628,
      "eval_steps_per_second": 68.656,
      "step": 296694
    },
    {
      "epoch": 477.01,
      "learning_rate": 0.0523191795136656,
      "loss": 2.694,
      "step": 296700
    },
    {
      "epoch": 477.04,
      "learning_rate": 0.05231596408279743,
      "loss": 2.6872,
      "step": 296720
    },
    {
      "epoch": 477.07,
      "learning_rate": 0.05231274865192928,
      "loss": 2.7287,
      "step": 296740
    },
    {
      "epoch": 477.11,
      "learning_rate": 0.05230953322106109,
      "loss": 2.7147,
      "step": 296760
    },
    {
      "epoch": 477.14,
      "learning_rate": 0.05230631779019294,
      "loss": 2.691,
      "step": 296780
    },
    {
      "epoch": 477.17,
      "learning_rate": 0.05230310235932476,
      "loss": 2.7036,
      "step": 296800
    },
    {
      "epoch": 477.2,
      "learning_rate": 0.052299886928456586,
      "loss": 2.7024,
      "step": 296820
    },
    {
      "epoch": 477.23,
      "learning_rate": 0.05229667149758843,
      "loss": 2.7098,
      "step": 296840
    },
    {
      "epoch": 477.27,
      "learning_rate": 0.052293456066720256,
      "loss": 2.6778,
      "step": 296860
    },
    {
      "epoch": 477.3,
      "learning_rate": 0.05229024063585211,
      "loss": 2.715,
      "step": 296880
    },
    {
      "epoch": 477.33,
      "learning_rate": 0.05228702520498393,
      "loss": 2.7026,
      "step": 296900
    },
    {
      "epoch": 477.36,
      "learning_rate": 0.05228380977411576,
      "loss": 2.6934,
      "step": 296920
    },
    {
      "epoch": 477.4,
      "learning_rate": 0.05228059434324759,
      "loss": 2.6831,
      "step": 296940
    },
    {
      "epoch": 477.43,
      "learning_rate": 0.052277378912379414,
      "loss": 2.7092,
      "step": 296960
    },
    {
      "epoch": 477.46,
      "learning_rate": 0.05227416348151126,
      "loss": 2.7036,
      "step": 296980
    },
    {
      "epoch": 477.49,
      "learning_rate": 0.052270948050643085,
      "loss": 2.7092,
      "step": 297000
    },
    {
      "epoch": 477.52,
      "learning_rate": 0.05226773261977492,
      "loss": 2.7073,
      "step": 297020
    },
    {
      "epoch": 477.56,
      "learning_rate": 0.05226451718890676,
      "loss": 2.7164,
      "step": 297040
    },
    {
      "epoch": 477.59,
      "learning_rate": 0.052261301758038586,
      "loss": 2.7055,
      "step": 297060
    },
    {
      "epoch": 477.62,
      "learning_rate": 0.05225808632717043,
      "loss": 2.7121,
      "step": 297080
    },
    {
      "epoch": 477.65,
      "learning_rate": 0.05225487089630224,
      "loss": 2.6965,
      "step": 297100
    },
    {
      "epoch": 477.68,
      "learning_rate": 0.05225165546543409,
      "loss": 2.6957,
      "step": 297120
    },
    {
      "epoch": 477.72,
      "learning_rate": 0.05224844003456591,
      "loss": 2.7136,
      "step": 297140
    },
    {
      "epoch": 477.75,
      "learning_rate": 0.05224522460369775,
      "loss": 2.7363,
      "step": 297160
    },
    {
      "epoch": 477.78,
      "learning_rate": 0.0522420091728296,
      "loss": 2.7222,
      "step": 297180
    },
    {
      "epoch": 477.81,
      "learning_rate": 0.052238793741961415,
      "loss": 2.7206,
      "step": 297200
    },
    {
      "epoch": 477.85,
      "learning_rate": 0.052235578311093246,
      "loss": 2.7174,
      "step": 297220
    },
    {
      "epoch": 477.88,
      "learning_rate": 0.052232362880225085,
      "loss": 2.6784,
      "step": 297240
    },
    {
      "epoch": 477.91,
      "learning_rate": 0.052229147449356916,
      "loss": 2.6995,
      "step": 297260
    },
    {
      "epoch": 477.94,
      "learning_rate": 0.05222593201848874,
      "loss": 2.716,
      "step": 297280
    },
    {
      "epoch": 477.97,
      "learning_rate": 0.05222271658762058,
      "loss": 2.7221,
      "step": 297300
    },
    {
      "epoch": 478.0,
      "eval_accuracy": {
        "accuracy": 0.4034051154474073
      },
      "eval_loss": 2.8689496517181396,
      "eval_runtime": 2.8775,
      "eval_samples_per_second": 4470.181,
      "eval_steps_per_second": 69.852,
      "step": 297316
    },
    {
      "epoch": 478.01,
      "learning_rate": 0.05221950115675242,
      "loss": 2.7294,
      "step": 297320
    },
    {
      "epoch": 478.04,
      "learning_rate": 0.05221628572588424,
      "loss": 2.7125,
      "step": 297340
    },
    {
      "epoch": 478.07,
      "learning_rate": 0.052213070295016074,
      "loss": 2.7172,
      "step": 297360
    },
    {
      "epoch": 478.1,
      "learning_rate": 0.05220985486414791,
      "loss": 2.7042,
      "step": 297380
    },
    {
      "epoch": 478.14,
      "learning_rate": 0.052206639433279745,
      "loss": 2.719,
      "step": 297400
    },
    {
      "epoch": 478.17,
      "learning_rate": 0.0522034240024116,
      "loss": 2.6844,
      "step": 297420
    },
    {
      "epoch": 478.2,
      "learning_rate": 0.05220020857154341,
      "loss": 2.6773,
      "step": 297440
    },
    {
      "epoch": 478.23,
      "learning_rate": 0.052196993140675246,
      "loss": 2.6938,
      "step": 297460
    },
    {
      "epoch": 478.26,
      "learning_rate": 0.05219377770980708,
      "loss": 2.6938,
      "step": 297480
    },
    {
      "epoch": 478.3,
      "learning_rate": 0.0521905622789389,
      "loss": 2.7096,
      "step": 297500
    },
    {
      "epoch": 478.33,
      "learning_rate": 0.05218734684807075,
      "loss": 2.7076,
      "step": 297520
    },
    {
      "epoch": 478.36,
      "learning_rate": 0.05218413141720257,
      "loss": 2.714,
      "step": 297540
    },
    {
      "epoch": 478.39,
      "learning_rate": 0.05218091598633441,
      "loss": 2.6961,
      "step": 297560
    },
    {
      "epoch": 478.42,
      "learning_rate": 0.05217770055546625,
      "loss": 2.7063,
      "step": 297580
    },
    {
      "epoch": 478.46,
      "learning_rate": 0.052174485124598075,
      "loss": 2.7266,
      "step": 297600
    },
    {
      "epoch": 478.49,
      "learning_rate": 0.052171269693729906,
      "loss": 2.7087,
      "step": 297620
    },
    {
      "epoch": 478.52,
      "learning_rate": 0.05216805426286173,
      "loss": 2.7061,
      "step": 297640
    },
    {
      "epoch": 478.55,
      "learning_rate": 0.052164838831993576,
      "loss": 2.7119,
      "step": 297660
    },
    {
      "epoch": 478.59,
      "learning_rate": 0.0521616234011254,
      "loss": 2.6979,
      "step": 297680
    },
    {
      "epoch": 478.62,
      "learning_rate": 0.05215840797025724,
      "loss": 2.7032,
      "step": 297700
    },
    {
      "epoch": 478.65,
      "learning_rate": 0.05215519253938908,
      "loss": 2.7136,
      "step": 297720
    },
    {
      "epoch": 478.68,
      "learning_rate": 0.0521519771085209,
      "loss": 2.7028,
      "step": 297740
    },
    {
      "epoch": 478.71,
      "learning_rate": 0.052148761677652734,
      "loss": 2.6799,
      "step": 297760
    },
    {
      "epoch": 478.75,
      "learning_rate": 0.052145707018327984,
      "loss": 2.7421,
      "step": 297780
    },
    {
      "epoch": 478.78,
      "learning_rate": 0.05214249158745981,
      "loss": 2.7183,
      "step": 297800
    },
    {
      "epoch": 478.81,
      "learning_rate": 0.05213927615659164,
      "loss": 2.7021,
      "step": 297820
    },
    {
      "epoch": 478.84,
      "learning_rate": 0.05213606072572348,
      "loss": 2.7102,
      "step": 297840
    },
    {
      "epoch": 478.87,
      "learning_rate": 0.05213284529485532,
      "loss": 2.7129,
      "step": 297860
    },
    {
      "epoch": 478.91,
      "learning_rate": 0.05212962986398714,
      "loss": 2.7357,
      "step": 297880
    },
    {
      "epoch": 478.94,
      "learning_rate": 0.052126414433118974,
      "loss": 2.702,
      "step": 297900
    },
    {
      "epoch": 478.97,
      "learning_rate": 0.05212319900225081,
      "loss": 2.7054,
      "step": 297920
    },
    {
      "epoch": 479.0,
      "eval_accuracy": {
        "accuracy": 0.40853611132706213
      },
      "eval_loss": 2.8118696212768555,
      "eval_runtime": 2.9855,
      "eval_samples_per_second": 4308.55,
      "eval_steps_per_second": 67.326,
      "step": 297938
    },
    {
      "epoch": 479.0,
      "learning_rate": 0.05211998357138262,
      "loss": 2.7268,
      "step": 297940
    },
    {
      "epoch": 479.04,
      "learning_rate": 0.05211676814051447,
      "loss": 2.717,
      "step": 297960
    },
    {
      "epoch": 479.07,
      "learning_rate": 0.05211355270964631,
      "loss": 2.727,
      "step": 297980
    },
    {
      "epoch": 479.1,
      "learning_rate": 0.052110337278778146,
      "loss": 2.7201,
      "step": 298000
    },
    {
      "epoch": 479.13,
      "learning_rate": 0.05210712184790998,
      "loss": 2.7077,
      "step": 298020
    },
    {
      "epoch": 479.16,
      "learning_rate": 0.052103906417041795,
      "loss": 2.6875,
      "step": 298040
    },
    {
      "epoch": 479.2,
      "learning_rate": 0.05210069098617364,
      "loss": 2.7286,
      "step": 298060
    },
    {
      "epoch": 479.23,
      "learning_rate": 0.05209747555530547,
      "loss": 2.72,
      "step": 298080
    },
    {
      "epoch": 479.26,
      "learning_rate": 0.0520942601244373,
      "loss": 2.6947,
      "step": 298100
    },
    {
      "epoch": 479.29,
      "learning_rate": 0.05209104469356915,
      "loss": 2.7373,
      "step": 298120
    },
    {
      "epoch": 479.32,
      "learning_rate": 0.05208782926270096,
      "loss": 2.7148,
      "step": 298140
    },
    {
      "epoch": 479.36,
      "learning_rate": 0.052084613831832806,
      "loss": 2.7205,
      "step": 298160
    },
    {
      "epoch": 479.39,
      "learning_rate": 0.05208139840096463,
      "loss": 2.7144,
      "step": 298180
    },
    {
      "epoch": 479.42,
      "learning_rate": 0.05207818297009647,
      "loss": 2.7036,
      "step": 298200
    },
    {
      "epoch": 479.45,
      "learning_rate": 0.0520749675392283,
      "loss": 2.7033,
      "step": 298220
    },
    {
      "epoch": 479.49,
      "learning_rate": 0.052071752108360125,
      "loss": 2.6742,
      "step": 298240
    },
    {
      "epoch": 479.52,
      "learning_rate": 0.05206853667749198,
      "loss": 2.7027,
      "step": 298260
    },
    {
      "epoch": 479.55,
      "learning_rate": 0.05206532124662379,
      "loss": 2.7152,
      "step": 298280
    },
    {
      "epoch": 479.58,
      "learning_rate": 0.052062105815755634,
      "loss": 2.7041,
      "step": 298300
    },
    {
      "epoch": 479.61,
      "learning_rate": 0.05205889038488746,
      "loss": 2.6928,
      "step": 298320
    },
    {
      "epoch": 479.65,
      "learning_rate": 0.05205567495401928,
      "loss": 2.7129,
      "step": 298340
    },
    {
      "epoch": 479.68,
      "learning_rate": 0.05205245952315113,
      "loss": 2.6875,
      "step": 298360
    },
    {
      "epoch": 479.71,
      "learning_rate": 0.052049244092282954,
      "loss": 2.7122,
      "step": 298380
    },
    {
      "epoch": 479.74,
      "learning_rate": 0.052046028661414806,
      "loss": 2.7066,
      "step": 298400
    },
    {
      "epoch": 479.77,
      "learning_rate": 0.05204281323054663,
      "loss": 2.6865,
      "step": 298420
    },
    {
      "epoch": 479.81,
      "learning_rate": 0.05203959779967846,
      "loss": 2.7105,
      "step": 298440
    },
    {
      "epoch": 479.84,
      "learning_rate": 0.0520363823688103,
      "loss": 2.6941,
      "step": 298460
    },
    {
      "epoch": 479.87,
      "learning_rate": 0.05203316693794211,
      "loss": 2.7098,
      "step": 298480
    },
    {
      "epoch": 479.9,
      "learning_rate": 0.05202995150707396,
      "loss": 2.6957,
      "step": 298500
    },
    {
      "epoch": 479.94,
      "learning_rate": 0.052026736076205796,
      "loss": 2.7074,
      "step": 298520
    },
    {
      "epoch": 479.97,
      "learning_rate": 0.052023520645337634,
      "loss": 2.6925,
      "step": 298540
    },
    {
      "epoch": 480.0,
      "learning_rate": 0.05202030521446946,
      "loss": 2.6974,
      "step": 298560
    },
    {
      "epoch": 480.0,
      "eval_accuracy": {
        "accuracy": 0.4072922335380549
      },
      "eval_loss": 2.8435146808624268,
      "eval_runtime": 2.9279,
      "eval_samples_per_second": 4393.183,
      "eval_steps_per_second": 68.649,
      "step": 298560
    },
    {
      "epoch": 480.03,
      "learning_rate": 0.052017089783601284,
      "loss": 2.6797,
      "step": 298580
    },
    {
      "epoch": 480.06,
      "learning_rate": 0.05201387435273313,
      "loss": 2.6902,
      "step": 298600
    },
    {
      "epoch": 480.1,
      "learning_rate": 0.05201065892186496,
      "loss": 2.6897,
      "step": 298620
    },
    {
      "epoch": 480.13,
      "learning_rate": 0.052007443490996785,
      "loss": 2.6634,
      "step": 298640
    },
    {
      "epoch": 480.16,
      "learning_rate": 0.052004228060128624,
      "loss": 2.6964,
      "step": 298660
    },
    {
      "epoch": 480.19,
      "learning_rate": 0.05200101262926045,
      "loss": 2.7196,
      "step": 298680
    },
    {
      "epoch": 480.23,
      "learning_rate": 0.051997797198392294,
      "loss": 2.7038,
      "step": 298700
    },
    {
      "epoch": 480.26,
      "learning_rate": 0.05199458176752411,
      "loss": 2.684,
      "step": 298720
    },
    {
      "epoch": 480.29,
      "learning_rate": 0.05199136633665596,
      "loss": 2.6915,
      "step": 298740
    },
    {
      "epoch": 480.32,
      "learning_rate": 0.05198815090578779,
      "loss": 2.7074,
      "step": 298760
    },
    {
      "epoch": 480.35,
      "learning_rate": 0.051984935474919614,
      "loss": 2.6784,
      "step": 298780
    },
    {
      "epoch": 480.39,
      "learning_rate": 0.051981720044051466,
      "loss": 2.7291,
      "step": 298800
    },
    {
      "epoch": 480.42,
      "learning_rate": 0.05197850461318328,
      "loss": 2.6974,
      "step": 298820
    },
    {
      "epoch": 480.45,
      "learning_rate": 0.05197528918231512,
      "loss": 2.7021,
      "step": 298840
    },
    {
      "epoch": 480.48,
      "learning_rate": 0.05197207375144695,
      "loss": 2.7262,
      "step": 298860
    },
    {
      "epoch": 480.51,
      "learning_rate": 0.05196885832057877,
      "loss": 2.7096,
      "step": 298880
    },
    {
      "epoch": 480.55,
      "learning_rate": 0.05196564288971061,
      "loss": 2.7107,
      "step": 298900
    },
    {
      "epoch": 480.58,
      "learning_rate": 0.05196242745884244,
      "loss": 2.7261,
      "step": 298920
    },
    {
      "epoch": 480.61,
      "learning_rate": 0.051959212027974294,
      "loss": 2.7135,
      "step": 298940
    },
    {
      "epoch": 480.64,
      "learning_rate": 0.05195599659710612,
      "loss": 2.6895,
      "step": 298960
    },
    {
      "epoch": 480.68,
      "learning_rate": 0.05195278116623795,
      "loss": 2.6954,
      "step": 298980
    },
    {
      "epoch": 480.71,
      "learning_rate": 0.051949565735369775,
      "loss": 2.712,
      "step": 299000
    },
    {
      "epoch": 480.74,
      "learning_rate": 0.0519463503045016,
      "loss": 2.7216,
      "step": 299020
    },
    {
      "epoch": 480.77,
      "learning_rate": 0.051943134873633445,
      "loss": 2.7244,
      "step": 299040
    },
    {
      "epoch": 480.8,
      "learning_rate": 0.05193991944276527,
      "loss": 2.7227,
      "step": 299060
    },
    {
      "epoch": 480.84,
      "learning_rate": 0.05193670401189712,
      "loss": 2.7212,
      "step": 299080
    },
    {
      "epoch": 480.87,
      "learning_rate": 0.05193348858102895,
      "loss": 2.7215,
      "step": 299100
    },
    {
      "epoch": 480.9,
      "learning_rate": 0.05193027315016077,
      "loss": 2.7176,
      "step": 299120
    },
    {
      "epoch": 480.93,
      "learning_rate": 0.05192705771929262,
      "loss": 2.7296,
      "step": 299140
    },
    {
      "epoch": 480.96,
      "learning_rate": 0.05192384228842443,
      "loss": 2.7311,
      "step": 299160
    },
    {
      "epoch": 481.0,
      "learning_rate": 0.051920626857556273,
      "loss": 2.6934,
      "step": 299180
    },
    {
      "epoch": 481.0,
      "eval_accuracy": {
        "accuracy": 0.4065148099199254
      },
      "eval_loss": 2.823549509048462,
      "eval_runtime": 2.7408,
      "eval_samples_per_second": 4693.189,
      "eval_steps_per_second": 73.337,
      "step": 299182
    },
    {
      "epoch": 481.03,
      "learning_rate": 0.0519174114266881,
      "loss": 2.7208,
      "step": 299200
    },
    {
      "epoch": 481.06,
      "learning_rate": 0.05191419599581994,
      "loss": 2.7005,
      "step": 299220
    },
    {
      "epoch": 481.09,
      "learning_rate": 0.051910980564951775,
      "loss": 2.717,
      "step": 299240
    },
    {
      "epoch": 481.13,
      "learning_rate": 0.0519077651340836,
      "loss": 2.691,
      "step": 299260
    },
    {
      "epoch": 481.16,
      "learning_rate": 0.051904549703215445,
      "loss": 2.7237,
      "step": 299280
    },
    {
      "epoch": 481.19,
      "learning_rate": 0.05190133427234728,
      "loss": 2.7004,
      "step": 299300
    },
    {
      "epoch": 481.22,
      "learning_rate": 0.0518981188414791,
      "loss": 2.7114,
      "step": 299320
    },
    {
      "epoch": 481.25,
      "learning_rate": 0.051894903410610926,
      "loss": 2.7272,
      "step": 299340
    },
    {
      "epoch": 481.29,
      "learning_rate": 0.051891687979742765,
      "loss": 2.7155,
      "step": 299360
    },
    {
      "epoch": 481.32,
      "learning_rate": 0.05188847254887461,
      "loss": 2.7105,
      "step": 299380
    },
    {
      "epoch": 481.35,
      "learning_rate": 0.05188525711800643,
      "loss": 2.7035,
      "step": 299400
    },
    {
      "epoch": 481.38,
      "learning_rate": 0.05188204168713826,
      "loss": 2.7085,
      "step": 299420
    },
    {
      "epoch": 481.41,
      "learning_rate": 0.0518788262562701,
      "loss": 2.7082,
      "step": 299440
    },
    {
      "epoch": 481.45,
      "learning_rate": 0.05187561082540193,
      "loss": 2.7046,
      "step": 299460
    },
    {
      "epoch": 481.48,
      "learning_rate": 0.05187239539453378,
      "loss": 2.6911,
      "step": 299480
    },
    {
      "epoch": 481.51,
      "learning_rate": 0.05186917996366559,
      "loss": 2.7002,
      "step": 299500
    },
    {
      "epoch": 481.54,
      "learning_rate": 0.05186596453279743,
      "loss": 2.6746,
      "step": 299520
    },
    {
      "epoch": 481.58,
      "learning_rate": 0.05186274910192926,
      "loss": 2.6979,
      "step": 299540
    },
    {
      "epoch": 481.61,
      "learning_rate": 0.05185953367106109,
      "loss": 2.7218,
      "step": 299560
    },
    {
      "epoch": 481.64,
      "learning_rate": 0.05185631824019293,
      "loss": 2.6963,
      "step": 299580
    },
    {
      "epoch": 481.67,
      "learning_rate": 0.05185310280932476,
      "loss": 2.7022,
      "step": 299600
    },
    {
      "epoch": 481.7,
      "learning_rate": 0.05184988737845661,
      "loss": 2.6916,
      "step": 299620
    },
    {
      "epoch": 481.74,
      "learning_rate": 0.051846671947588435,
      "loss": 2.7092,
      "step": 299640
    },
    {
      "epoch": 481.77,
      "learning_rate": 0.05184345651672026,
      "loss": 2.6816,
      "step": 299660
    },
    {
      "epoch": 481.8,
      "learning_rate": 0.05184024108585209,
      "loss": 2.6761,
      "step": 299680
    },
    {
      "epoch": 481.83,
      "learning_rate": 0.051837025654983916,
      "loss": 2.7329,
      "step": 299700
    },
    {
      "epoch": 481.86,
      "learning_rate": 0.05183381022411576,
      "loss": 2.6983,
      "step": 299720
    },
    {
      "epoch": 481.9,
      "learning_rate": 0.051830594793247586,
      "loss": 2.7115,
      "step": 299740
    },
    {
      "epoch": 481.93,
      "learning_rate": 0.051827379362379425,
      "loss": 2.6828,
      "step": 299760
    },
    {
      "epoch": 481.96,
      "learning_rate": 0.05182416393151126,
      "loss": 2.6997,
      "step": 299780
    },
    {
      "epoch": 481.99,
      "learning_rate": 0.05182094850064309,
      "loss": 2.6833,
      "step": 299800
    },
    {
      "epoch": 482.0,
      "eval_accuracy": {
        "accuracy": 0.415221954442976
      },
      "eval_loss": 2.7937417030334473,
      "eval_runtime": 3.4583,
      "eval_samples_per_second": 3719.502,
      "eval_steps_per_second": 58.122,
      "step": 299804
    },
    {
      "epoch": 482.03,
      "learning_rate": 0.051817733069774934,
      "loss": 2.7123,
      "step": 299820
    },
    {
      "epoch": 482.06,
      "learning_rate": 0.05181467841045017,
      "loss": 2.6982,
      "step": 299840
    },
    {
      "epoch": 482.09,
      "learning_rate": 0.051811462979581994,
      "loss": 2.7164,
      "step": 299860
    },
    {
      "epoch": 482.12,
      "learning_rate": 0.051808247548713826,
      "loss": 2.7009,
      "step": 299880
    },
    {
      "epoch": 482.15,
      "learning_rate": 0.051805032117845665,
      "loss": 2.7228,
      "step": 299900
    },
    {
      "epoch": 482.19,
      "learning_rate": 0.0518018166869775,
      "loss": 2.7147,
      "step": 299920
    },
    {
      "epoch": 482.22,
      "learning_rate": 0.05179860125610933,
      "loss": 2.6889,
      "step": 299940
    },
    {
      "epoch": 482.25,
      "learning_rate": 0.05179538582524116,
      "loss": 2.6962,
      "step": 299960
    },
    {
      "epoch": 482.28,
      "learning_rate": 0.051792170394373,
      "loss": 2.7216,
      "step": 299980
    },
    {
      "epoch": 482.32,
      "learning_rate": 0.05178895496350482,
      "loss": 2.6985,
      "step": 300000
    },
    {
      "epoch": 482.35,
      "learning_rate": 0.051785739532636654,
      "loss": 2.698,
      "step": 300020
    },
    {
      "epoch": 482.38,
      "learning_rate": 0.05178252410176849,
      "loss": 2.7333,
      "step": 300040
    },
    {
      "epoch": 482.41,
      "learning_rate": 0.05177930867090033,
      "loss": 2.7231,
      "step": 300060
    },
    {
      "epoch": 482.44,
      "learning_rate": 0.05177609324003216,
      "loss": 2.7076,
      "step": 300080
    },
    {
      "epoch": 482.48,
      "learning_rate": 0.05177287780916399,
      "loss": 2.7202,
      "step": 300100
    },
    {
      "epoch": 482.51,
      "learning_rate": 0.051769662378295826,
      "loss": 2.6741,
      "step": 300120
    },
    {
      "epoch": 482.54,
      "learning_rate": 0.05176644694742766,
      "loss": 2.679,
      "step": 300140
    },
    {
      "epoch": 482.57,
      "learning_rate": 0.05176323151655948,
      "loss": 2.6742,
      "step": 300160
    },
    {
      "epoch": 482.6,
      "learning_rate": 0.051760016085691335,
      "loss": 2.6762,
      "step": 300180
    },
    {
      "epoch": 482.64,
      "learning_rate": 0.05175680065482316,
      "loss": 2.71,
      "step": 300200
    },
    {
      "epoch": 482.67,
      "learning_rate": 0.05175358522395499,
      "loss": 2.7046,
      "step": 300220
    },
    {
      "epoch": 482.7,
      "learning_rate": 0.051750369793086816,
      "loss": 2.724,
      "step": 300240
    },
    {
      "epoch": 482.73,
      "learning_rate": 0.051747154362218654,
      "loss": 2.7009,
      "step": 300260
    },
    {
      "epoch": 482.77,
      "learning_rate": 0.051743938931350486,
      "loss": 2.7237,
      "step": 300280
    },
    {
      "epoch": 482.8,
      "learning_rate": 0.05174072350048231,
      "loss": 2.7188,
      "step": 300300
    },
    {
      "epoch": 482.83,
      "learning_rate": 0.05173750806961416,
      "loss": 2.6983,
      "step": 300320
    },
    {
      "epoch": 482.86,
      "learning_rate": 0.051734292638745974,
      "loss": 2.7214,
      "step": 300340
    },
    {
      "epoch": 482.89,
      "learning_rate": 0.05173107720787782,
      "loss": 2.7096,
      "step": 300360
    },
    {
      "epoch": 482.93,
      "learning_rate": 0.051727861777009644,
      "loss": 2.7038,
      "step": 300380
    },
    {
      "epoch": 482.96,
      "learning_rate": 0.05172464634614148,
      "loss": 2.6877,
      "step": 300400
    },
    {
      "epoch": 482.99,
      "learning_rate": 0.051721430915273314,
      "loss": 2.6968,
      "step": 300420
    },
    {
      "epoch": 483.0,
      "eval_accuracy": {
        "accuracy": 0.4056596439399829
      },
      "eval_loss": 2.8127281665802,
      "eval_runtime": 3.6718,
      "eval_samples_per_second": 3503.19,
      "eval_steps_per_second": 54.742,
      "step": 300426
    },
    {
      "epoch": 483.02,
      "learning_rate": 0.05171821548440514,
      "loss": 2.7132,
      "step": 300440
    },
    {
      "epoch": 483.05,
      "learning_rate": 0.05171500005353699,
      "loss": 2.7,
      "step": 300460
    },
    {
      "epoch": 483.09,
      "learning_rate": 0.051711784622668816,
      "loss": 2.678,
      "step": 300480
    },
    {
      "epoch": 483.12,
      "learning_rate": 0.05170856919180065,
      "loss": 2.7207,
      "step": 300500
    },
    {
      "epoch": 483.15,
      "learning_rate": 0.051705353760932486,
      "loss": 2.7033,
      "step": 300520
    },
    {
      "epoch": 483.18,
      "learning_rate": 0.05170213833006431,
      "loss": 2.6973,
      "step": 300540
    },
    {
      "epoch": 483.22,
      "learning_rate": 0.05169892289919614,
      "loss": 2.6913,
      "step": 300560
    },
    {
      "epoch": 483.25,
      "learning_rate": 0.05169570746832798,
      "loss": 2.6876,
      "step": 300580
    },
    {
      "epoch": 483.28,
      "learning_rate": 0.05169249203745982,
      "loss": 2.6797,
      "step": 300600
    },
    {
      "epoch": 483.31,
      "learning_rate": 0.051689276606591644,
      "loss": 2.7041,
      "step": 300620
    },
    {
      "epoch": 483.34,
      "learning_rate": 0.051686061175723476,
      "loss": 2.7121,
      "step": 300640
    },
    {
      "epoch": 483.38,
      "learning_rate": 0.051682845744855314,
      "loss": 2.7088,
      "step": 300660
    },
    {
      "epoch": 483.41,
      "learning_rate": 0.051679630313987125,
      "loss": 2.7073,
      "step": 300680
    },
    {
      "epoch": 483.44,
      "learning_rate": 0.05167641488311897,
      "loss": 2.7324,
      "step": 300700
    },
    {
      "epoch": 483.47,
      "learning_rate": 0.05167319945225081,
      "loss": 2.7082,
      "step": 300720
    },
    {
      "epoch": 483.5,
      "learning_rate": 0.05166998402138265,
      "loss": 2.7336,
      "step": 300740
    },
    {
      "epoch": 483.54,
      "learning_rate": 0.05166676859051448,
      "loss": 2.7198,
      "step": 300760
    },
    {
      "epoch": 483.57,
      "learning_rate": 0.0516635531596463,
      "loss": 2.6795,
      "step": 300780
    },
    {
      "epoch": 483.6,
      "learning_rate": 0.05166033772877814,
      "loss": 2.6914,
      "step": 300800
    },
    {
      "epoch": 483.63,
      "learning_rate": 0.051657122297909974,
      "loss": 2.6931,
      "step": 300820
    },
    {
      "epoch": 483.67,
      "learning_rate": 0.0516539068670418,
      "loss": 2.7256,
      "step": 300840
    },
    {
      "epoch": 483.7,
      "learning_rate": 0.05165069143617365,
      "loss": 2.6768,
      "step": 300860
    },
    {
      "epoch": 483.73,
      "learning_rate": 0.05164747600530546,
      "loss": 2.7094,
      "step": 300880
    },
    {
      "epoch": 483.76,
      "learning_rate": 0.05164426057443731,
      "loss": 2.7156,
      "step": 300900
    },
    {
      "epoch": 483.79,
      "learning_rate": 0.05164104514356913,
      "loss": 2.6969,
      "step": 300920
    },
    {
      "epoch": 483.83,
      "learning_rate": 0.05163782971270097,
      "loss": 2.676,
      "step": 300940
    },
    {
      "epoch": 483.86,
      "learning_rate": 0.0516346142818328,
      "loss": 2.7295,
      "step": 300960
    },
    {
      "epoch": 483.89,
      "learning_rate": 0.05163139885096463,
      "loss": 2.7154,
      "step": 300980
    },
    {
      "epoch": 483.92,
      "learning_rate": 0.05162818342009648,
      "loss": 2.707,
      "step": 301000
    },
    {
      "epoch": 483.95,
      "learning_rate": 0.05162496798922829,
      "loss": 2.6837,
      "step": 301020
    },
    {
      "epoch": 483.99,
      "learning_rate": 0.051621752558360136,
      "loss": 2.7146,
      "step": 301040
    },
    {
      "epoch": 484.0,
      "eval_accuracy": {
        "accuracy": 0.40830288424162325
      },
      "eval_loss": 2.8291714191436768,
      "eval_runtime": 3.0329,
      "eval_samples_per_second": 4241.169,
      "eval_steps_per_second": 66.273,
      "step": 301048
    },
    {
      "epoch": 484.02,
      "learning_rate": 0.05161853712749196,
      "loss": 2.6885,
      "step": 301060
    },
    {
      "epoch": 484.05,
      "learning_rate": 0.051615321696623785,
      "loss": 2.7004,
      "step": 301080
    },
    {
      "epoch": 484.08,
      "learning_rate": 0.05161210626575563,
      "loss": 2.6844,
      "step": 301100
    },
    {
      "epoch": 484.12,
      "learning_rate": 0.051608890834887455,
      "loss": 2.7102,
      "step": 301120
    },
    {
      "epoch": 484.15,
      "learning_rate": 0.05160567540401931,
      "loss": 2.6933,
      "step": 301140
    },
    {
      "epoch": 484.18,
      "learning_rate": 0.05160245997315113,
      "loss": 2.6915,
      "step": 301160
    },
    {
      "epoch": 484.21,
      "learning_rate": 0.051599244542282964,
      "loss": 2.6778,
      "step": 301180
    },
    {
      "epoch": 484.24,
      "learning_rate": 0.0515960291114148,
      "loss": 2.6958,
      "step": 301200
    },
    {
      "epoch": 484.28,
      "learning_rate": 0.05159281368054661,
      "loss": 2.717,
      "step": 301220
    },
    {
      "epoch": 484.31,
      "learning_rate": 0.05158959824967846,
      "loss": 2.7228,
      "step": 301240
    },
    {
      "epoch": 484.34,
      "learning_rate": 0.0515863828188103,
      "loss": 2.7147,
      "step": 301260
    },
    {
      "epoch": 484.37,
      "learning_rate": 0.051583167387942136,
      "loss": 2.7149,
      "step": 301280
    },
    {
      "epoch": 484.41,
      "learning_rate": 0.05157995195707396,
      "loss": 2.7126,
      "step": 301300
    },
    {
      "epoch": 484.44,
      "learning_rate": 0.051576736526205785,
      "loss": 2.6805,
      "step": 301320
    },
    {
      "epoch": 484.47,
      "learning_rate": 0.05157352109533763,
      "loss": 2.6815,
      "step": 301340
    },
    {
      "epoch": 484.5,
      "learning_rate": 0.05157030566446946,
      "loss": 2.7215,
      "step": 301360
    },
    {
      "epoch": 484.53,
      "learning_rate": 0.05156709023360129,
      "loss": 2.7031,
      "step": 301380
    },
    {
      "epoch": 484.57,
      "learning_rate": 0.05156387480273311,
      "loss": 2.6919,
      "step": 301400
    },
    {
      "epoch": 484.6,
      "learning_rate": 0.05156065937186495,
      "loss": 2.6946,
      "step": 301420
    },
    {
      "epoch": 484.63,
      "learning_rate": 0.051557443940996796,
      "loss": 2.7014,
      "step": 301440
    },
    {
      "epoch": 484.66,
      "learning_rate": 0.051554228510128614,
      "loss": 2.6991,
      "step": 301460
    },
    {
      "epoch": 484.69,
      "learning_rate": 0.05155101307926046,
      "loss": 2.6935,
      "step": 301480
    },
    {
      "epoch": 484.73,
      "learning_rate": 0.05154779764839229,
      "loss": 2.7141,
      "step": 301500
    },
    {
      "epoch": 484.76,
      "learning_rate": 0.051544582217524115,
      "loss": 2.7094,
      "step": 301520
    },
    {
      "epoch": 484.79,
      "learning_rate": 0.05154136678665597,
      "loss": 2.6798,
      "step": 301540
    },
    {
      "epoch": 484.82,
      "learning_rate": 0.05153815135578778,
      "loss": 2.7204,
      "step": 301560
    },
    {
      "epoch": 484.86,
      "learning_rate": 0.051534935924919624,
      "loss": 2.7053,
      "step": 301580
    },
    {
      "epoch": 484.89,
      "learning_rate": 0.05153172049405145,
      "loss": 2.7026,
      "step": 301600
    },
    {
      "epoch": 484.92,
      "learning_rate": 0.05152850506318327,
      "loss": 2.7056,
      "step": 301620
    },
    {
      "epoch": 484.95,
      "learning_rate": 0.05152528963231511,
      "loss": 2.7108,
      "step": 301640
    },
    {
      "epoch": 484.98,
      "learning_rate": 0.051522074201446943,
      "loss": 2.7242,
      "step": 301660
    },
    {
      "epoch": 485.0,
      "eval_accuracy": {
        "accuracy": 0.4043380237891627
      },
      "eval_loss": 2.834822416305542,
      "eval_runtime": 2.8524,
      "eval_samples_per_second": 4509.584,
      "eval_steps_per_second": 70.468,
      "step": 301670
    },
    {
      "epoch": 485.02,
      "learning_rate": 0.051518858770578796,
      "loss": 2.7141,
      "step": 301680
    },
    {
      "epoch": 485.05,
      "learning_rate": 0.05151564333971062,
      "loss": 2.692,
      "step": 301700
    },
    {
      "epoch": 485.08,
      "learning_rate": 0.051512427908842445,
      "loss": 2.7232,
      "step": 301720
    },
    {
      "epoch": 485.11,
      "learning_rate": 0.05150921247797428,
      "loss": 2.7044,
      "step": 301740
    },
    {
      "epoch": 485.14,
      "learning_rate": 0.0515059970471061,
      "loss": 2.6831,
      "step": 301760
    },
    {
      "epoch": 485.18,
      "learning_rate": 0.05150278161623795,
      "loss": 2.689,
      "step": 301780
    },
    {
      "epoch": 485.21,
      "learning_rate": 0.05149956618536977,
      "loss": 2.7091,
      "step": 301800
    },
    {
      "epoch": 485.24,
      "learning_rate": 0.051496350754501624,
      "loss": 2.6942,
      "step": 301820
    },
    {
      "epoch": 485.27,
      "learning_rate": 0.05149313532363345,
      "loss": 2.7057,
      "step": 301840
    },
    {
      "epoch": 485.31,
      "learning_rate": 0.051490080664308685,
      "loss": 2.72,
      "step": 301860
    },
    {
      "epoch": 485.34,
      "learning_rate": 0.05148686523344052,
      "loss": 2.7008,
      "step": 301880
    },
    {
      "epoch": 485.37,
      "learning_rate": 0.05148364980257236,
      "loss": 2.6819,
      "step": 301900
    },
    {
      "epoch": 485.4,
      "learning_rate": 0.05148043437170418,
      "loss": 2.7119,
      "step": 301920
    },
    {
      "epoch": 485.43,
      "learning_rate": 0.05147721894083601,
      "loss": 2.6925,
      "step": 301940
    },
    {
      "epoch": 485.47,
      "learning_rate": 0.05147400350996785,
      "loss": 2.6974,
      "step": 301960
    },
    {
      "epoch": 485.5,
      "learning_rate": 0.05147078807909969,
      "loss": 2.705,
      "step": 301980
    },
    {
      "epoch": 485.53,
      "learning_rate": 0.05146757264823151,
      "loss": 2.6897,
      "step": 302000
    },
    {
      "epoch": 485.56,
      "learning_rate": 0.051464357217363345,
      "loss": 2.7017,
      "step": 302020
    },
    {
      "epoch": 485.59,
      "learning_rate": 0.05146114178649518,
      "loss": 2.6877,
      "step": 302040
    },
    {
      "epoch": 485.63,
      "learning_rate": 0.05145792635562701,
      "loss": 2.7285,
      "step": 302060
    },
    {
      "epoch": 485.66,
      "learning_rate": 0.05145471092475884,
      "loss": 2.7128,
      "step": 302080
    },
    {
      "epoch": 485.69,
      "learning_rate": 0.05145149549389068,
      "loss": 2.7201,
      "step": 302100
    },
    {
      "epoch": 485.72,
      "learning_rate": 0.05144828006302252,
      "loss": 2.7125,
      "step": 302120
    },
    {
      "epoch": 485.76,
      "learning_rate": 0.05144506463215435,
      "loss": 2.7118,
      "step": 302140
    },
    {
      "epoch": 485.79,
      "learning_rate": 0.05144184920128617,
      "loss": 2.7037,
      "step": 302160
    },
    {
      "epoch": 485.82,
      "learning_rate": 0.05143863377041801,
      "loss": 2.7032,
      "step": 302180
    },
    {
      "epoch": 485.85,
      "learning_rate": 0.05143541833954984,
      "loss": 2.6662,
      "step": 302200
    },
    {
      "epoch": 485.88,
      "learning_rate": 0.05143220290868167,
      "loss": 2.7101,
      "step": 302220
    },
    {
      "epoch": 485.92,
      "learning_rate": 0.05142898747781352,
      "loss": 2.7032,
      "step": 302240
    },
    {
      "epoch": 485.95,
      "learning_rate": 0.051425772046945345,
      "loss": 2.7099,
      "step": 302260
    },
    {
      "epoch": 485.98,
      "learning_rate": 0.05142255661607718,
      "loss": 2.7161,
      "step": 302280
    },
    {
      "epoch": 486.0,
      "eval_accuracy": {
        "accuracy": 0.41273419886496154
      },
      "eval_loss": 2.807960271835327,
      "eval_runtime": 3.3814,
      "eval_samples_per_second": 3803.994,
      "eval_steps_per_second": 59.442,
      "step": 302292
    },
    {
      "epoch": 486.01,
      "learning_rate": 0.051419341185209,
      "loss": 2.678,
      "step": 302300
    },
    {
      "epoch": 486.05,
      "learning_rate": 0.05141612575434084,
      "loss": 2.7083,
      "step": 302320
    },
    {
      "epoch": 486.08,
      "learning_rate": 0.05141291032347267,
      "loss": 2.7034,
      "step": 302340
    },
    {
      "epoch": 486.11,
      "learning_rate": 0.051409694892604496,
      "loss": 2.6819,
      "step": 302360
    },
    {
      "epoch": 486.14,
      "learning_rate": 0.05140647946173635,
      "loss": 2.7059,
      "step": 302380
    },
    {
      "epoch": 486.17,
      "learning_rate": 0.05140326403086817,
      "loss": 2.6794,
      "step": 302400
    },
    {
      "epoch": 486.21,
      "learning_rate": 0.051400048600000005,
      "loss": 2.6936,
      "step": 302420
    },
    {
      "epoch": 486.24,
      "learning_rate": 0.05139683316913183,
      "loss": 2.7166,
      "step": 302440
    },
    {
      "epoch": 486.27,
      "learning_rate": 0.05139361773826367,
      "loss": 2.713,
      "step": 302460
    },
    {
      "epoch": 486.3,
      "learning_rate": 0.0513904023073955,
      "loss": 2.6948,
      "step": 302480
    },
    {
      "epoch": 486.33,
      "learning_rate": 0.051387186876527324,
      "loss": 2.6964,
      "step": 302500
    },
    {
      "epoch": 486.37,
      "learning_rate": 0.05138397144565918,
      "loss": 2.7225,
      "step": 302520
    },
    {
      "epoch": 486.4,
      "learning_rate": 0.051380756014791,
      "loss": 2.6914,
      "step": 302540
    },
    {
      "epoch": 486.43,
      "learning_rate": 0.05137754058392283,
      "loss": 2.6888,
      "step": 302560
    },
    {
      "epoch": 486.46,
      "learning_rate": 0.05137432515305467,
      "loss": 2.7042,
      "step": 302580
    },
    {
      "epoch": 486.5,
      "learning_rate": 0.051371109722186496,
      "loss": 2.6807,
      "step": 302600
    },
    {
      "epoch": 486.53,
      "learning_rate": 0.05136789429131833,
      "loss": 2.6942,
      "step": 302620
    },
    {
      "epoch": 486.56,
      "learning_rate": 0.051364678860450166,
      "loss": 2.708,
      "step": 302640
    },
    {
      "epoch": 486.59,
      "learning_rate": 0.051361463429582005,
      "loss": 2.7031,
      "step": 302660
    },
    {
      "epoch": 486.62,
      "learning_rate": 0.05135824799871383,
      "loss": 2.7142,
      "step": 302680
    },
    {
      "epoch": 486.66,
      "learning_rate": 0.05135503256784566,
      "loss": 2.7191,
      "step": 302700
    },
    {
      "epoch": 486.69,
      "learning_rate": 0.0513518171369775,
      "loss": 2.7075,
      "step": 302720
    },
    {
      "epoch": 486.72,
      "learning_rate": 0.051348601706109324,
      "loss": 2.7176,
      "step": 302740
    },
    {
      "epoch": 486.75,
      "learning_rate": 0.051345386275241156,
      "loss": 2.6849,
      "step": 302760
    },
    {
      "epoch": 486.78,
      "learning_rate": 0.051342170844372995,
      "loss": 2.7359,
      "step": 302780
    },
    {
      "epoch": 486.82,
      "learning_rate": 0.05133895541350483,
      "loss": 2.7395,
      "step": 302800
    },
    {
      "epoch": 486.85,
      "learning_rate": 0.051335739982636665,
      "loss": 2.7141,
      "step": 302820
    },
    {
      "epoch": 486.88,
      "learning_rate": 0.05133252455176849,
      "loss": 2.7155,
      "step": 302840
    },
    {
      "epoch": 486.91,
      "learning_rate": 0.05132930912090033,
      "loss": 2.6998,
      "step": 302860
    },
    {
      "epoch": 486.95,
      "learning_rate": 0.05132609369003216,
      "loss": 2.6887,
      "step": 302880
    },
    {
      "epoch": 486.98,
      "learning_rate": 0.051322878259163984,
      "loss": 2.692,
      "step": 302900
    },
    {
      "epoch": 487.0,
      "eval_accuracy": {
        "accuracy": 0.40153929876389644
      },
      "eval_loss": 2.8685576915740967,
      "eval_runtime": 2.9898,
      "eval_samples_per_second": 4302.223,
      "eval_steps_per_second": 67.227,
      "step": 302914
    },
    {
      "epoch": 487.01,
      "learning_rate": 0.05131966282829584,
      "loss": 2.7096,
      "step": 302920
    },
    {
      "epoch": 487.04,
      "learning_rate": 0.05131644739742766,
      "loss": 2.7217,
      "step": 302940
    },
    {
      "epoch": 487.07,
      "learning_rate": 0.05131323196655949,
      "loss": 2.6925,
      "step": 302960
    },
    {
      "epoch": 487.11,
      "learning_rate": 0.05131001653569132,
      "loss": 2.6754,
      "step": 302980
    },
    {
      "epoch": 487.14,
      "learning_rate": 0.051306801104823156,
      "loss": 2.7093,
      "step": 303000
    },
    {
      "epoch": 487.17,
      "learning_rate": 0.05130358567395499,
      "loss": 2.6879,
      "step": 303020
    },
    {
      "epoch": 487.2,
      "learning_rate": 0.05130037024308681,
      "loss": 2.6848,
      "step": 303040
    },
    {
      "epoch": 487.23,
      "learning_rate": 0.051297154812218665,
      "loss": 2.7164,
      "step": 303060
    },
    {
      "epoch": 487.27,
      "learning_rate": 0.051293939381350476,
      "loss": 2.7097,
      "step": 303080
    },
    {
      "epoch": 487.3,
      "learning_rate": 0.05129072395048232,
      "loss": 2.6976,
      "step": 303100
    },
    {
      "epoch": 487.33,
      "learning_rate": 0.051287508519614146,
      "loss": 2.7049,
      "step": 303120
    },
    {
      "epoch": 487.36,
      "learning_rate": 0.051284293088745984,
      "loss": 2.6946,
      "step": 303140
    },
    {
      "epoch": 487.4,
      "learning_rate": 0.051281077657877816,
      "loss": 2.6863,
      "step": 303160
    },
    {
      "epoch": 487.43,
      "learning_rate": 0.05127786222700964,
      "loss": 2.7013,
      "step": 303180
    },
    {
      "epoch": 487.46,
      "learning_rate": 0.05127464679614149,
      "loss": 2.6913,
      "step": 303200
    },
    {
      "epoch": 487.49,
      "learning_rate": 0.05127143136527332,
      "loss": 2.6894,
      "step": 303220
    },
    {
      "epoch": 487.52,
      "learning_rate": 0.05126821593440515,
      "loss": 2.6997,
      "step": 303240
    },
    {
      "epoch": 487.56,
      "learning_rate": 0.05126500050353699,
      "loss": 2.6901,
      "step": 303260
    },
    {
      "epoch": 487.59,
      "learning_rate": 0.0512617850726688,
      "loss": 2.7008,
      "step": 303280
    },
    {
      "epoch": 487.62,
      "learning_rate": 0.051258569641800644,
      "loss": 2.7207,
      "step": 303300
    },
    {
      "epoch": 487.65,
      "learning_rate": 0.05125535421093248,
      "loss": 2.7269,
      "step": 303320
    },
    {
      "epoch": 487.68,
      "learning_rate": 0.05125213878006432,
      "loss": 2.7073,
      "step": 303340
    },
    {
      "epoch": 487.72,
      "learning_rate": 0.051248923349196146,
      "loss": 2.6814,
      "step": 303360
    },
    {
      "epoch": 487.75,
      "learning_rate": 0.05124570791832798,
      "loss": 2.6882,
      "step": 303380
    },
    {
      "epoch": 487.78,
      "learning_rate": 0.051242492487459816,
      "loss": 2.678,
      "step": 303400
    },
    {
      "epoch": 487.81,
      "learning_rate": 0.05123927705659163,
      "loss": 2.6882,
      "step": 303420
    },
    {
      "epoch": 487.85,
      "learning_rate": 0.05123606162572347,
      "loss": 2.6839,
      "step": 303440
    },
    {
      "epoch": 487.88,
      "learning_rate": 0.05123284619485531,
      "loss": 2.7021,
      "step": 303460
    },
    {
      "epoch": 487.91,
      "learning_rate": 0.05122963076398715,
      "loss": 2.6963,
      "step": 303480
    },
    {
      "epoch": 487.94,
      "learning_rate": 0.05122641533311898,
      "loss": 2.6862,
      "step": 303500
    },
    {
      "epoch": 487.97,
      "learning_rate": 0.0512231999022508,
      "loss": 2.7373,
      "step": 303520
    },
    {
      "epoch": 488.0,
      "eval_accuracy": {
        "accuracy": 0.4044157661509757
      },
      "eval_loss": 2.8491225242614746,
      "eval_runtime": 3.2161,
      "eval_samples_per_second": 3999.544,
      "eval_steps_per_second": 62.498,
      "step": 303536
    },
    {
      "epoch": 488.01,
      "learning_rate": 0.051219984471382644,
      "loss": 2.6972,
      "step": 303540
    },
    {
      "epoch": 488.04,
      "learning_rate": 0.051216769040514476,
      "loss": 2.7023,
      "step": 303560
    },
    {
      "epoch": 488.07,
      "learning_rate": 0.0512135536096463,
      "loss": 2.7198,
      "step": 303580
    },
    {
      "epoch": 488.1,
      "learning_rate": 0.05121033817877815,
      "loss": 2.7047,
      "step": 303600
    },
    {
      "epoch": 488.14,
      "learning_rate": 0.051207122747909964,
      "loss": 2.7085,
      "step": 303620
    },
    {
      "epoch": 488.17,
      "learning_rate": 0.05120390731704181,
      "loss": 2.6807,
      "step": 303640
    },
    {
      "epoch": 488.2,
      "learning_rate": 0.051200691886173634,
      "loss": 2.6838,
      "step": 303660
    },
    {
      "epoch": 488.23,
      "learning_rate": 0.05119747645530547,
      "loss": 2.6809,
      "step": 303680
    },
    {
      "epoch": 488.26,
      "learning_rate": 0.051194261024437304,
      "loss": 2.684,
      "step": 303700
    },
    {
      "epoch": 488.3,
      "learning_rate": 0.05119104559356913,
      "loss": 2.6937,
      "step": 303720
    },
    {
      "epoch": 488.33,
      "learning_rate": 0.05118783016270098,
      "loss": 2.688,
      "step": 303740
    },
    {
      "epoch": 488.36,
      "learning_rate": 0.051184614731832806,
      "loss": 2.7046,
      "step": 303760
    },
    {
      "epoch": 488.39,
      "learning_rate": 0.05118139930096464,
      "loss": 2.728,
      "step": 303780
    },
    {
      "epoch": 488.42,
      "learning_rate": 0.05117818387009646,
      "loss": 2.6993,
      "step": 303800
    },
    {
      "epoch": 488.46,
      "learning_rate": 0.05117496843922829,
      "loss": 2.6902,
      "step": 303820
    },
    {
      "epoch": 488.49,
      "learning_rate": 0.05117175300836013,
      "loss": 2.6887,
      "step": 303840
    },
    {
      "epoch": 488.52,
      "learning_rate": 0.05116853757749196,
      "loss": 2.7139,
      "step": 303860
    },
    {
      "epoch": 488.55,
      "learning_rate": 0.05116532214662381,
      "loss": 2.7081,
      "step": 303880
    },
    {
      "epoch": 488.59,
      "learning_rate": 0.051162106715755634,
      "loss": 2.6866,
      "step": 303900
    },
    {
      "epoch": 488.62,
      "learning_rate": 0.05115889128488746,
      "loss": 2.7293,
      "step": 303920
    },
    {
      "epoch": 488.65,
      "learning_rate": 0.051155675854019304,
      "loss": 2.7145,
      "step": 303940
    },
    {
      "epoch": 488.68,
      "learning_rate": 0.051152460423151115,
      "loss": 2.6925,
      "step": 303960
    },
    {
      "epoch": 488.71,
      "learning_rate": 0.05114924499228296,
      "loss": 2.6932,
      "step": 303980
    },
    {
      "epoch": 488.75,
      "learning_rate": 0.0511460295614148,
      "loss": 2.7061,
      "step": 304000
    },
    {
      "epoch": 488.78,
      "learning_rate": 0.05114281413054664,
      "loss": 2.7016,
      "step": 304020
    },
    {
      "epoch": 488.81,
      "learning_rate": 0.05113959869967846,
      "loss": 2.7069,
      "step": 304040
    },
    {
      "epoch": 488.84,
      "learning_rate": 0.05113638326881029,
      "loss": 2.6931,
      "step": 304060
    },
    {
      "epoch": 488.87,
      "learning_rate": 0.05113316783794213,
      "loss": 2.7209,
      "step": 304080
    },
    {
      "epoch": 488.91,
      "learning_rate": 0.051129952407073964,
      "loss": 2.7084,
      "step": 304100
    },
    {
      "epoch": 488.94,
      "learning_rate": 0.05112673697620579,
      "loss": 2.7185,
      "step": 304120
    },
    {
      "epoch": 488.97,
      "learning_rate": 0.051123521545337614,
      "loss": 2.68,
      "step": 304140
    },
    {
      "epoch": 489.0,
      "eval_accuracy": {
        "accuracy": 0.4213636010261992
      },
      "eval_loss": 2.7982115745544434,
      "eval_runtime": 2.9297,
      "eval_samples_per_second": 4390.537,
      "eval_steps_per_second": 68.607,
      "step": 304158
    },
    {
      "epoch": 489.0,
      "learning_rate": 0.05112030611446945,
      "loss": 2.686,
      "step": 304160
    },
    {
      "epoch": 489.04,
      "learning_rate": 0.0511170906836013,
      "loss": 2.704,
      "step": 304180
    },
    {
      "epoch": 489.07,
      "learning_rate": 0.051113875252733115,
      "loss": 2.6953,
      "step": 304200
    },
    {
      "epoch": 489.1,
      "learning_rate": 0.05111065982186496,
      "loss": 2.6935,
      "step": 304220
    },
    {
      "epoch": 489.13,
      "learning_rate": 0.051107444390996785,
      "loss": 2.7066,
      "step": 304240
    },
    {
      "epoch": 489.16,
      "learning_rate": 0.05110422896012862,
      "loss": 2.6929,
      "step": 304260
    },
    {
      "epoch": 489.2,
      "learning_rate": 0.05110101352926047,
      "loss": 2.7215,
      "step": 304280
    },
    {
      "epoch": 489.23,
      "learning_rate": 0.05109779809839228,
      "loss": 2.7102,
      "step": 304300
    },
    {
      "epoch": 489.26,
      "learning_rate": 0.051094582667524126,
      "loss": 2.7062,
      "step": 304320
    },
    {
      "epoch": 489.29,
      "learning_rate": 0.05109136723665595,
      "loss": 2.6916,
      "step": 304340
    },
    {
      "epoch": 489.32,
      "learning_rate": 0.051088151805787775,
      "loss": 2.6839,
      "step": 304360
    },
    {
      "epoch": 489.36,
      "learning_rate": 0.051084936374919614,
      "loss": 2.6866,
      "step": 304380
    },
    {
      "epoch": 489.39,
      "learning_rate": 0.051081720944051445,
      "loss": 2.7017,
      "step": 304400
    },
    {
      "epoch": 489.42,
      "learning_rate": 0.0510785055131833,
      "loss": 2.7082,
      "step": 304420
    },
    {
      "epoch": 489.45,
      "learning_rate": 0.05107529008231512,
      "loss": 2.7147,
      "step": 304440
    },
    {
      "epoch": 489.49,
      "learning_rate": 0.05107207465144695,
      "loss": 2.7148,
      "step": 304460
    },
    {
      "epoch": 489.52,
      "learning_rate": 0.05106885922057878,
      "loss": 2.7251,
      "step": 304480
    },
    {
      "epoch": 489.55,
      "learning_rate": 0.0510656437897106,
      "loss": 2.6966,
      "step": 304500
    },
    {
      "epoch": 489.58,
      "learning_rate": 0.05106242835884245,
      "loss": 2.7233,
      "step": 304520
    },
    {
      "epoch": 489.61,
      "learning_rate": 0.05105921292797427,
      "loss": 2.6867,
      "step": 304540
    },
    {
      "epoch": 489.65,
      "learning_rate": 0.05105599749710611,
      "loss": 2.6935,
      "step": 304560
    },
    {
      "epoch": 489.68,
      "learning_rate": 0.05105278206623795,
      "loss": 2.6705,
      "step": 304580
    },
    {
      "epoch": 489.71,
      "learning_rate": 0.051049566635369775,
      "loss": 2.6948,
      "step": 304600
    },
    {
      "epoch": 489.74,
      "learning_rate": 0.05104635120450162,
      "loss": 2.6948,
      "step": 304620
    },
    {
      "epoch": 489.77,
      "learning_rate": 0.05104313577363343,
      "loss": 2.7287,
      "step": 304640
    },
    {
      "epoch": 489.81,
      "learning_rate": 0.05103992034276528,
      "loss": 2.6992,
      "step": 304660
    },
    {
      "epoch": 489.84,
      "learning_rate": 0.0510367049118971,
      "loss": 2.7025,
      "step": 304680
    },
    {
      "epoch": 489.87,
      "learning_rate": 0.05103348948102894,
      "loss": 2.6901,
      "step": 304700
    },
    {
      "epoch": 489.9,
      "learning_rate": 0.051030274050160786,
      "loss": 2.7043,
      "step": 304720
    },
    {
      "epoch": 489.94,
      "learning_rate": 0.051027219390836015,
      "loss": 2.6789,
      "step": 304740
    },
    {
      "epoch": 489.97,
      "learning_rate": 0.05102400395996785,
      "loss": 2.715,
      "step": 304760
    },
    {
      "epoch": 490.0,
      "learning_rate": 0.051020788529099685,
      "loss": 2.6746,
      "step": 304780
    },
    {
      "epoch": 490.0,
      "eval_accuracy": {
        "accuracy": 0.4122677446940838
      },
      "eval_loss": 2.801063060760498,
      "eval_runtime": 3.0282,
      "eval_samples_per_second": 4247.711,
      "eval_steps_per_second": 66.376,
      "step": 304780
    },
    {
      "epoch": 490.03,
      "learning_rate": 0.05101757309823151,
      "loss": 2.6602,
      "step": 304800
    },
    {
      "epoch": 490.06,
      "learning_rate": 0.05101435766736334,
      "loss": 2.6845,
      "step": 304820
    },
    {
      "epoch": 490.1,
      "learning_rate": 0.05101114223649518,
      "loss": 2.6735,
      "step": 304840
    },
    {
      "epoch": 490.13,
      "learning_rate": 0.05100792680562702,
      "loss": 2.6565,
      "step": 304860
    },
    {
      "epoch": 490.16,
      "learning_rate": 0.05100471137475885,
      "loss": 2.6844,
      "step": 304880
    },
    {
      "epoch": 490.19,
      "learning_rate": 0.051001495943890675,
      "loss": 2.687,
      "step": 304900
    },
    {
      "epoch": 490.23,
      "learning_rate": 0.05099828051302251,
      "loss": 2.6995,
      "step": 304920
    },
    {
      "epoch": 490.26,
      "learning_rate": 0.050995065082154345,
      "loss": 2.6979,
      "step": 304940
    },
    {
      "epoch": 490.29,
      "learning_rate": 0.05099184965128617,
      "loss": 2.7123,
      "step": 304960
    },
    {
      "epoch": 490.32,
      "learning_rate": 0.05098863422041802,
      "loss": 2.7107,
      "step": 304980
    },
    {
      "epoch": 490.35,
      "learning_rate": 0.05098541878954985,
      "loss": 2.7031,
      "step": 305000
    },
    {
      "epoch": 490.39,
      "learning_rate": 0.05098220335868168,
      "loss": 2.6882,
      "step": 305020
    },
    {
      "epoch": 490.42,
      "learning_rate": 0.0509789879278135,
      "loss": 2.6891,
      "step": 305040
    },
    {
      "epoch": 490.45,
      "learning_rate": 0.05097577249694534,
      "loss": 2.6899,
      "step": 305060
    },
    {
      "epoch": 490.48,
      "learning_rate": 0.05097255706607717,
      "loss": 2.6887,
      "step": 305080
    },
    {
      "epoch": 490.51,
      "learning_rate": 0.050969341635209,
      "loss": 2.6882,
      "step": 305100
    },
    {
      "epoch": 490.55,
      "learning_rate": 0.05096612620434085,
      "loss": 2.6653,
      "step": 305120
    },
    {
      "epoch": 490.58,
      "learning_rate": 0.050962910773472675,
      "loss": 2.6808,
      "step": 305140
    },
    {
      "epoch": 490.61,
      "learning_rate": 0.05095969534260451,
      "loss": 2.7385,
      "step": 305160
    },
    {
      "epoch": 490.64,
      "learning_rate": 0.05095647991173633,
      "loss": 2.7129,
      "step": 305180
    },
    {
      "epoch": 490.68,
      "learning_rate": 0.05095326448086817,
      "loss": 2.74,
      "step": 305200
    },
    {
      "epoch": 490.71,
      "learning_rate": 0.05095004905,
      "loss": 2.7299,
      "step": 305220
    },
    {
      "epoch": 490.74,
      "learning_rate": 0.050946833619131826,
      "loss": 2.7117,
      "step": 305240
    },
    {
      "epoch": 490.77,
      "learning_rate": 0.05094361818826368,
      "loss": 2.715,
      "step": 305260
    },
    {
      "epoch": 490.8,
      "learning_rate": 0.0509404027573955,
      "loss": 2.6903,
      "step": 305280
    },
    {
      "epoch": 490.84,
      "learning_rate": 0.050937187326527335,
      "loss": 2.6962,
      "step": 305300
    },
    {
      "epoch": 490.87,
      "learning_rate": 0.05093397189565917,
      "loss": 2.6805,
      "step": 305320
    },
    {
      "epoch": 490.9,
      "learning_rate": 0.050930756464791,
      "loss": 2.7017,
      "step": 305340
    },
    {
      "epoch": 490.93,
      "learning_rate": 0.05092754103392283,
      "loss": 2.7132,
      "step": 305360
    },
    {
      "epoch": 490.96,
      "learning_rate": 0.05092432560305467,
      "loss": 2.7144,
      "step": 305380
    },
    {
      "epoch": 491.0,
      "learning_rate": 0.05092111017218651,
      "loss": 2.7236,
      "step": 305400
    },
    {
      "epoch": 491.0,
      "eval_accuracy": {
        "accuracy": 0.4142113037394076
      },
      "eval_loss": 2.7997658252716064,
      "eval_runtime": 2.7913,
      "eval_samples_per_second": 4608.291,
      "eval_steps_per_second": 72.01,
      "step": 305402
    },
    {
      "epoch": 491.03,
      "learning_rate": 0.05091789474131833,
      "loss": 2.7123,
      "step": 305420
    },
    {
      "epoch": 491.06,
      "learning_rate": 0.05091467931045016,
      "loss": 2.6978,
      "step": 305440
    },
    {
      "epoch": 491.09,
      "learning_rate": 0.050911463879582,
      "loss": 2.6927,
      "step": 305460
    },
    {
      "epoch": 491.13,
      "learning_rate": 0.05090824844871381,
      "loss": 2.6804,
      "step": 305480
    },
    {
      "epoch": 491.16,
      "learning_rate": 0.05090503301784566,
      "loss": 2.6806,
      "step": 305500
    },
    {
      "epoch": 491.19,
      "learning_rate": 0.050901817586977496,
      "loss": 2.6873,
      "step": 305520
    },
    {
      "epoch": 491.22,
      "learning_rate": 0.050898602156109335,
      "loss": 2.7042,
      "step": 305540
    },
    {
      "epoch": 491.25,
      "learning_rate": 0.050895386725241167,
      "loss": 2.7122,
      "step": 305560
    },
    {
      "epoch": 491.29,
      "learning_rate": 0.05089217129437299,
      "loss": 2.6999,
      "step": 305580
    },
    {
      "epoch": 491.32,
      "learning_rate": 0.05088895586350483,
      "loss": 2.6962,
      "step": 305600
    },
    {
      "epoch": 491.35,
      "learning_rate": 0.05088574043263666,
      "loss": 2.6921,
      "step": 305620
    },
    {
      "epoch": 491.38,
      "learning_rate": 0.050882525001768486,
      "loss": 2.6997,
      "step": 305640
    },
    {
      "epoch": 491.41,
      "learning_rate": 0.05087930957090034,
      "loss": 2.6878,
      "step": 305660
    },
    {
      "epoch": 491.45,
      "learning_rate": 0.05087609414003216,
      "loss": 2.6736,
      "step": 305680
    },
    {
      "epoch": 491.48,
      "learning_rate": 0.050872878709163995,
      "loss": 2.6799,
      "step": 305700
    },
    {
      "epoch": 491.51,
      "learning_rate": 0.05086966327829582,
      "loss": 2.6789,
      "step": 305720
    },
    {
      "epoch": 491.54,
      "learning_rate": 0.05086644784742766,
      "loss": 2.7159,
      "step": 305740
    },
    {
      "epoch": 491.58,
      "learning_rate": 0.05086323241655949,
      "loss": 2.7258,
      "step": 305760
    },
    {
      "epoch": 491.61,
      "learning_rate": 0.050860016985691314,
      "loss": 2.7151,
      "step": 305780
    },
    {
      "epoch": 491.64,
      "learning_rate": 0.05085680155482317,
      "loss": 2.6984,
      "step": 305800
    },
    {
      "epoch": 491.67,
      "learning_rate": 0.05085358612395498,
      "loss": 2.6814,
      "step": 305820
    },
    {
      "epoch": 491.7,
      "learning_rate": 0.05085037069308682,
      "loss": 2.7028,
      "step": 305840
    },
    {
      "epoch": 491.74,
      "learning_rate": 0.05084715526221865,
      "loss": 2.6993,
      "step": 305860
    },
    {
      "epoch": 491.77,
      "learning_rate": 0.050843939831350486,
      "loss": 2.6848,
      "step": 305880
    },
    {
      "epoch": 491.8,
      "learning_rate": 0.05084072440048232,
      "loss": 2.7279,
      "step": 305900
    },
    {
      "epoch": 491.83,
      "learning_rate": 0.05083750896961414,
      "loss": 2.6947,
      "step": 305920
    },
    {
      "epoch": 491.86,
      "learning_rate": 0.050834293538745995,
      "loss": 2.6795,
      "step": 305940
    },
    {
      "epoch": 491.9,
      "learning_rate": 0.05083107810787782,
      "loss": 2.6961,
      "step": 305960
    },
    {
      "epoch": 491.93,
      "learning_rate": 0.05082786267700965,
      "loss": 2.7018,
      "step": 305980
    },
    {
      "epoch": 491.96,
      "learning_rate": 0.05082464724614149,
      "loss": 2.7092,
      "step": 306000
    },
    {
      "epoch": 491.99,
      "learning_rate": 0.0508214318152733,
      "loss": 2.7181,
      "step": 306020
    },
    {
      "epoch": 492.0,
      "eval_accuracy": {
        "accuracy": 0.4004509056985151
      },
      "eval_loss": 2.8513691425323486,
      "eval_runtime": 2.8647,
      "eval_samples_per_second": 4490.218,
      "eval_steps_per_second": 70.165,
      "step": 306024
    },
    {
      "epoch": 492.03,
      "learning_rate": 0.050818216384405146,
      "loss": 2.7028,
      "step": 306040
    },
    {
      "epoch": 492.06,
      "learning_rate": 0.050815000953536985,
      "loss": 2.6856,
      "step": 306060
    },
    {
      "epoch": 492.09,
      "learning_rate": 0.05081178552266882,
      "loss": 2.6627,
      "step": 306080
    },
    {
      "epoch": 492.12,
      "learning_rate": 0.05080857009180065,
      "loss": 2.6758,
      "step": 306100
    },
    {
      "epoch": 492.15,
      "learning_rate": 0.05080535466093247,
      "loss": 2.6606,
      "step": 306120
    },
    {
      "epoch": 492.19,
      "learning_rate": 0.05080213923006432,
      "loss": 2.7045,
      "step": 306140
    },
    {
      "epoch": 492.22,
      "learning_rate": 0.05079892379919613,
      "loss": 2.6868,
      "step": 306160
    },
    {
      "epoch": 492.25,
      "learning_rate": 0.050795708368327974,
      "loss": 2.6975,
      "step": 306180
    },
    {
      "epoch": 492.28,
      "learning_rate": 0.05079249293745981,
      "loss": 2.7069,
      "step": 306200
    },
    {
      "epoch": 492.32,
      "learning_rate": 0.05078927750659165,
      "loss": 2.6709,
      "step": 306220
    },
    {
      "epoch": 492.35,
      "learning_rate": 0.05078606207572348,
      "loss": 2.7027,
      "step": 306240
    },
    {
      "epoch": 492.38,
      "learning_rate": 0.0507828466448553,
      "loss": 2.6871,
      "step": 306260
    },
    {
      "epoch": 492.41,
      "learning_rate": 0.050779631213987146,
      "loss": 2.6749,
      "step": 306280
    },
    {
      "epoch": 492.44,
      "learning_rate": 0.05077641578311898,
      "loss": 2.7174,
      "step": 306300
    },
    {
      "epoch": 492.48,
      "learning_rate": 0.0507732003522508,
      "loss": 2.6852,
      "step": 306320
    },
    {
      "epoch": 492.51,
      "learning_rate": 0.050769984921382655,
      "loss": 2.6925,
      "step": 306340
    },
    {
      "epoch": 492.54,
      "learning_rate": 0.050766769490514466,
      "loss": 2.6813,
      "step": 306360
    },
    {
      "epoch": 492.57,
      "learning_rate": 0.05076355405964631,
      "loss": 2.7177,
      "step": 306380
    },
    {
      "epoch": 492.6,
      "learning_rate": 0.050760338628778136,
      "loss": 2.6986,
      "step": 306400
    },
    {
      "epoch": 492.64,
      "learning_rate": 0.050757123197909974,
      "loss": 2.6848,
      "step": 306420
    },
    {
      "epoch": 492.67,
      "learning_rate": 0.0507539077670418,
      "loss": 2.7352,
      "step": 306440
    },
    {
      "epoch": 492.7,
      "learning_rate": 0.05075069233617363,
      "loss": 2.6986,
      "step": 306460
    },
    {
      "epoch": 492.73,
      "learning_rate": 0.05074747690530548,
      "loss": 2.7193,
      "step": 306480
    },
    {
      "epoch": 492.77,
      "learning_rate": 0.05074426147443731,
      "loss": 2.6968,
      "step": 306500
    },
    {
      "epoch": 492.8,
      "learning_rate": 0.05074104604356914,
      "loss": 2.7099,
      "step": 306520
    },
    {
      "epoch": 492.83,
      "learning_rate": 0.050737830612700964,
      "loss": 2.713,
      "step": 306540
    },
    {
      "epoch": 492.86,
      "learning_rate": 0.05073461518183279,
      "loss": 2.7317,
      "step": 306560
    },
    {
      "epoch": 492.89,
      "learning_rate": 0.050731399750964634,
      "loss": 2.6718,
      "step": 306580
    },
    {
      "epoch": 492.93,
      "learning_rate": 0.05072818432009646,
      "loss": 2.7024,
      "step": 306600
    },
    {
      "epoch": 492.96,
      "learning_rate": 0.05072496888922831,
      "loss": 2.6641,
      "step": 306620
    },
    {
      "epoch": 492.99,
      "learning_rate": 0.050721753458360136,
      "loss": 2.6923,
      "step": 306640
    },
    {
      "epoch": 493.0,
      "eval_accuracy": {
        "accuracy": 0.40667029464355126
      },
      "eval_loss": 2.806464910507202,
      "eval_runtime": 3.7004,
      "eval_samples_per_second": 3476.11,
      "eval_steps_per_second": 54.318,
      "step": 306646
    },
    {
      "epoch": 493.02,
      "learning_rate": 0.05071853802749196,
      "loss": 2.6974,
      "step": 306660
    },
    {
      "epoch": 493.05,
      "learning_rate": 0.050715322596623806,
      "loss": 2.7093,
      "step": 306680
    },
    {
      "epoch": 493.09,
      "learning_rate": 0.05071210716575562,
      "loss": 2.6935,
      "step": 306700
    },
    {
      "epoch": 493.12,
      "learning_rate": 0.05070889173488746,
      "loss": 2.7053,
      "step": 306720
    },
    {
      "epoch": 493.15,
      "learning_rate": 0.0507056763040193,
      "loss": 2.6864,
      "step": 306740
    },
    {
      "epoch": 493.18,
      "learning_rate": 0.050702460873151126,
      "loss": 2.6887,
      "step": 306760
    },
    {
      "epoch": 493.22,
      "learning_rate": 0.050699245442282964,
      "loss": 2.6814,
      "step": 306780
    },
    {
      "epoch": 493.25,
      "learning_rate": 0.05069603001141479,
      "loss": 2.6798,
      "step": 306800
    },
    {
      "epoch": 493.28,
      "learning_rate": 0.050692814580546634,
      "loss": 2.7065,
      "step": 306820
    },
    {
      "epoch": 493.31,
      "learning_rate": 0.050689599149678466,
      "loss": 2.7018,
      "step": 306840
    },
    {
      "epoch": 493.34,
      "learning_rate": 0.05068638371881029,
      "loss": 2.7013,
      "step": 306860
    },
    {
      "epoch": 493.38,
      "learning_rate": 0.050683168287942115,
      "loss": 2.694,
      "step": 306880
    },
    {
      "epoch": 493.41,
      "learning_rate": 0.050679952857073954,
      "loss": 2.7139,
      "step": 306900
    },
    {
      "epoch": 493.44,
      "learning_rate": 0.050676898197749204,
      "loss": 2.6957,
      "step": 306920
    },
    {
      "epoch": 493.47,
      "learning_rate": 0.050673682766881036,
      "loss": 2.6858,
      "step": 306940
    },
    {
      "epoch": 493.5,
      "learning_rate": 0.05067046733601286,
      "loss": 2.6988,
      "step": 306960
    },
    {
      "epoch": 493.54,
      "learning_rate": 0.0506672519051447,
      "loss": 2.7016,
      "step": 306980
    },
    {
      "epoch": 493.57,
      "learning_rate": 0.05066403647427653,
      "loss": 2.6983,
      "step": 307000
    },
    {
      "epoch": 493.6,
      "learning_rate": 0.050660821043408355,
      "loss": 2.6924,
      "step": 307020
    },
    {
      "epoch": 493.63,
      "learning_rate": 0.05065760561254021,
      "loss": 2.6779,
      "step": 307040
    },
    {
      "epoch": 493.67,
      "learning_rate": 0.05065439018167203,
      "loss": 2.7124,
      "step": 307060
    },
    {
      "epoch": 493.7,
      "learning_rate": 0.050651174750803864,
      "loss": 2.6953,
      "step": 307080
    },
    {
      "epoch": 493.73,
      "learning_rate": 0.05064795931993569,
      "loss": 2.6882,
      "step": 307100
    },
    {
      "epoch": 493.76,
      "learning_rate": 0.05064474388906753,
      "loss": 2.6731,
      "step": 307120
    },
    {
      "epoch": 493.79,
      "learning_rate": 0.05064152845819936,
      "loss": 2.6873,
      "step": 307140
    },
    {
      "epoch": 493.83,
      "learning_rate": 0.05063831302733118,
      "loss": 2.7057,
      "step": 307160
    },
    {
      "epoch": 493.86,
      "learning_rate": 0.050635097596463036,
      "loss": 2.7019,
      "step": 307180
    },
    {
      "epoch": 493.89,
      "learning_rate": 0.05063188216559486,
      "loss": 2.7206,
      "step": 307200
    },
    {
      "epoch": 493.92,
      "learning_rate": 0.05062866673472669,
      "loss": 2.7102,
      "step": 307220
    },
    {
      "epoch": 493.95,
      "learning_rate": 0.05062545130385852,
      "loss": 2.668,
      "step": 307240
    },
    {
      "epoch": 493.99,
      "learning_rate": 0.050622235872990355,
      "loss": 2.6904,
      "step": 307260
    },
    {
      "epoch": 494.0,
      "eval_accuracy": {
        "accuracy": 0.4110238669050766
      },
      "eval_loss": 2.7953672409057617,
      "eval_runtime": 2.8236,
      "eval_samples_per_second": 4555.542,
      "eval_steps_per_second": 71.186,
      "step": 307268
    },
    {
      "epoch": 494.02,
      "learning_rate": 0.0506190204421222,
      "loss": 2.6967,
      "step": 307280
    },
    {
      "epoch": 494.05,
      "learning_rate": 0.05061580501125401,
      "loss": 2.6807,
      "step": 307300
    },
    {
      "epoch": 494.08,
      "learning_rate": 0.050612589580385864,
      "loss": 2.6633,
      "step": 307320
    },
    {
      "epoch": 494.12,
      "learning_rate": 0.05060937414951769,
      "loss": 2.6975,
      "step": 307340
    },
    {
      "epoch": 494.15,
      "learning_rate": 0.05060615871864952,
      "loss": 2.6797,
      "step": 307360
    },
    {
      "epoch": 494.18,
      "learning_rate": 0.050602943287781366,
      "loss": 2.6916,
      "step": 307380
    },
    {
      "epoch": 494.21,
      "learning_rate": 0.05059972785691318,
      "loss": 2.7039,
      "step": 307400
    },
    {
      "epoch": 494.24,
      "learning_rate": 0.050596512426045015,
      "loss": 2.6937,
      "step": 307420
    },
    {
      "epoch": 494.28,
      "learning_rate": 0.050593296995176854,
      "loss": 2.6952,
      "step": 307440
    },
    {
      "epoch": 494.31,
      "learning_rate": 0.05059008156430869,
      "loss": 2.7054,
      "step": 307460
    },
    {
      "epoch": 494.34,
      "learning_rate": 0.05058686613344052,
      "loss": 2.7065,
      "step": 307480
    },
    {
      "epoch": 494.37,
      "learning_rate": 0.05058365070257235,
      "loss": 2.6889,
      "step": 307500
    },
    {
      "epoch": 494.41,
      "learning_rate": 0.05058043527170419,
      "loss": 2.6919,
      "step": 307520
    },
    {
      "epoch": 494.44,
      "learning_rate": 0.05057721984083601,
      "loss": 2.6981,
      "step": 307540
    },
    {
      "epoch": 494.47,
      "learning_rate": 0.05057400440996784,
      "loss": 2.7007,
      "step": 307560
    },
    {
      "epoch": 494.5,
      "learning_rate": 0.05057078897909968,
      "loss": 2.7031,
      "step": 307580
    },
    {
      "epoch": 494.53,
      "learning_rate": 0.05056757354823152,
      "loss": 2.6671,
      "step": 307600
    },
    {
      "epoch": 494.57,
      "learning_rate": 0.05056435811736335,
      "loss": 2.6845,
      "step": 307620
    },
    {
      "epoch": 494.6,
      "learning_rate": 0.05056114268649518,
      "loss": 2.6645,
      "step": 307640
    },
    {
      "epoch": 494.63,
      "learning_rate": 0.050557927255627015,
      "loss": 2.674,
      "step": 307660
    },
    {
      "epoch": 494.66,
      "learning_rate": 0.05055471182475885,
      "loss": 2.6802,
      "step": 307680
    },
    {
      "epoch": 494.69,
      "learning_rate": 0.05055149639389067,
      "loss": 2.6957,
      "step": 307700
    },
    {
      "epoch": 494.73,
      "learning_rate": 0.050548280963022524,
      "loss": 2.7076,
      "step": 307720
    },
    {
      "epoch": 494.76,
      "learning_rate": 0.05054506553215435,
      "loss": 2.7007,
      "step": 307740
    },
    {
      "epoch": 494.79,
      "learning_rate": 0.05054185010128618,
      "loss": 2.7179,
      "step": 307760
    },
    {
      "epoch": 494.82,
      "learning_rate": 0.050538634670418005,
      "loss": 2.7248,
      "step": 307780
    },
    {
      "epoch": 494.86,
      "learning_rate": 0.05053541923954984,
      "loss": 2.7077,
      "step": 307800
    },
    {
      "epoch": 494.89,
      "learning_rate": 0.050532203808681675,
      "loss": 2.682,
      "step": 307820
    },
    {
      "epoch": 494.92,
      "learning_rate": 0.0505289883778135,
      "loss": 2.6803,
      "step": 307840
    },
    {
      "epoch": 494.95,
      "learning_rate": 0.05052577294694535,
      "loss": 2.7083,
      "step": 307860
    },
    {
      "epoch": 494.98,
      "learning_rate": 0.05052255751607718,
      "loss": 2.6944,
      "step": 307880
    },
    {
      "epoch": 495.0,
      "eval_accuracy": {
        "accuracy": 0.4111793516287025
      },
      "eval_loss": 2.8020195960998535,
      "eval_runtime": 3.0685,
      "eval_samples_per_second": 4192.017,
      "eval_steps_per_second": 65.505,
      "step": 307890
    },
    {
      "epoch": 495.02,
      "learning_rate": 0.05051934208520901,
      "loss": 2.6702,
      "step": 307900
    },
    {
      "epoch": 495.05,
      "learning_rate": 0.05051612665434083,
      "loss": 2.701,
      "step": 307920
    },
    {
      "epoch": 495.08,
      "learning_rate": 0.05051291122347267,
      "loss": 2.6613,
      "step": 307940
    },
    {
      "epoch": 495.11,
      "learning_rate": 0.0505096957926045,
      "loss": 2.6935,
      "step": 307960
    },
    {
      "epoch": 495.14,
      "learning_rate": 0.05050648036173633,
      "loss": 2.6835,
      "step": 307980
    },
    {
      "epoch": 495.18,
      "learning_rate": 0.05050326493086818,
      "loss": 2.6946,
      "step": 308000
    },
    {
      "epoch": 495.21,
      "learning_rate": 0.050500049500000005,
      "loss": 2.7075,
      "step": 308020
    },
    {
      "epoch": 495.24,
      "learning_rate": 0.05049683406913184,
      "loss": 2.6965,
      "step": 308040
    },
    {
      "epoch": 495.27,
      "learning_rate": 0.050493618638263675,
      "loss": 2.6544,
      "step": 308060
    },
    {
      "epoch": 495.31,
      "learning_rate": 0.0504904032073955,
      "loss": 2.7128,
      "step": 308080
    },
    {
      "epoch": 495.34,
      "learning_rate": 0.05048718777652733,
      "loss": 2.6989,
      "step": 308100
    },
    {
      "epoch": 495.37,
      "learning_rate": 0.05048397234565917,
      "loss": 2.6922,
      "step": 308120
    },
    {
      "epoch": 495.4,
      "learning_rate": 0.05048075691479101,
      "loss": 2.6823,
      "step": 308140
    },
    {
      "epoch": 495.43,
      "learning_rate": 0.05047754148392283,
      "loss": 2.673,
      "step": 308160
    },
    {
      "epoch": 495.47,
      "learning_rate": 0.050474326053054665,
      "loss": 2.673,
      "step": 308180
    },
    {
      "epoch": 495.5,
      "learning_rate": 0.0504711106221865,
      "loss": 2.6983,
      "step": 308200
    },
    {
      "epoch": 495.53,
      "learning_rate": 0.050467895191318314,
      "loss": 2.6676,
      "step": 308220
    },
    {
      "epoch": 495.56,
      "learning_rate": 0.05046467976045016,
      "loss": 2.6799,
      "step": 308240
    },
    {
      "epoch": 495.59,
      "learning_rate": 0.050461464329582,
      "loss": 2.7089,
      "step": 308260
    },
    {
      "epoch": 495.63,
      "learning_rate": 0.05045824889871384,
      "loss": 2.6921,
      "step": 308280
    },
    {
      "epoch": 495.66,
      "learning_rate": 0.05045503346784567,
      "loss": 2.6928,
      "step": 308300
    },
    {
      "epoch": 495.69,
      "learning_rate": 0.050451818036977486,
      "loss": 2.6922,
      "step": 308320
    },
    {
      "epoch": 495.72,
      "learning_rate": 0.05044860260610933,
      "loss": 2.7173,
      "step": 308340
    },
    {
      "epoch": 495.76,
      "learning_rate": 0.05044538717524116,
      "loss": 2.6975,
      "step": 308360
    },
    {
      "epoch": 495.79,
      "learning_rate": 0.05044217174437299,
      "loss": 2.6843,
      "step": 308380
    },
    {
      "epoch": 495.82,
      "learning_rate": 0.05043895631350484,
      "loss": 2.7206,
      "step": 308400
    },
    {
      "epoch": 495.85,
      "learning_rate": 0.050435740882636665,
      "loss": 2.7024,
      "step": 308420
    },
    {
      "epoch": 495.88,
      "learning_rate": 0.050432525451768496,
      "loss": 2.6994,
      "step": 308440
    },
    {
      "epoch": 495.92,
      "learning_rate": 0.05042931002090032,
      "loss": 2.6969,
      "step": 308460
    },
    {
      "epoch": 495.95,
      "learning_rate": 0.05042609459003216,
      "loss": 2.6936,
      "step": 308480
    },
    {
      "epoch": 495.98,
      "learning_rate": 0.05042287915916399,
      "loss": 2.6703,
      "step": 308500
    },
    {
      "epoch": 496.0,
      "eval_accuracy": {
        "accuracy": 0.4061260981108606
      },
      "eval_loss": 2.818998098373413,
      "eval_runtime": 2.8544,
      "eval_samples_per_second": 4506.385,
      "eval_steps_per_second": 70.418,
      "step": 308512
    },
    {
      "epoch": 496.01,
      "learning_rate": 0.050419663728295816,
      "loss": 2.6924,
      "step": 308520
    },
    {
      "epoch": 496.05,
      "learning_rate": 0.05041644829742767,
      "loss": 2.6769,
      "step": 308540
    },
    {
      "epoch": 496.08,
      "learning_rate": 0.05041323286655948,
      "loss": 2.6855,
      "step": 308560
    },
    {
      "epoch": 496.11,
      "learning_rate": 0.050410017435691325,
      "loss": 2.705,
      "step": 308580
    },
    {
      "epoch": 496.14,
      "learning_rate": 0.05040680200482315,
      "loss": 2.6979,
      "step": 308600
    },
    {
      "epoch": 496.17,
      "learning_rate": 0.05040358657395499,
      "loss": 2.6824,
      "step": 308620
    },
    {
      "epoch": 496.21,
      "learning_rate": 0.05040037114308682,
      "loss": 2.6922,
      "step": 308640
    },
    {
      "epoch": 496.24,
      "learning_rate": 0.050397155712218644,
      "loss": 2.7011,
      "step": 308660
    },
    {
      "epoch": 496.27,
      "learning_rate": 0.0503939402813505,
      "loss": 2.6899,
      "step": 308680
    },
    {
      "epoch": 496.3,
      "learning_rate": 0.05039072485048232,
      "loss": 2.6578,
      "step": 308700
    },
    {
      "epoch": 496.33,
      "learning_rate": 0.05038750941961415,
      "loss": 2.6947,
      "step": 308720
    },
    {
      "epoch": 496.37,
      "learning_rate": 0.05038429398874599,
      "loss": 2.7052,
      "step": 308740
    },
    {
      "epoch": 496.4,
      "learning_rate": 0.0503810785578778,
      "loss": 2.7053,
      "step": 308760
    },
    {
      "epoch": 496.43,
      "learning_rate": 0.05037786312700965,
      "loss": 2.6793,
      "step": 308780
    },
    {
      "epoch": 496.46,
      "learning_rate": 0.050374647696141486,
      "loss": 2.6883,
      "step": 308800
    },
    {
      "epoch": 496.5,
      "learning_rate": 0.050371432265273325,
      "loss": 2.6838,
      "step": 308820
    },
    {
      "epoch": 496.53,
      "learning_rate": 0.05036821683440515,
      "loss": 2.6932,
      "step": 308840
    },
    {
      "epoch": 496.56,
      "learning_rate": 0.050365001403536974,
      "loss": 2.6774,
      "step": 308860
    },
    {
      "epoch": 496.59,
      "learning_rate": 0.05036178597266882,
      "loss": 2.67,
      "step": 308880
    },
    {
      "epoch": 496.62,
      "learning_rate": 0.05035857054180065,
      "loss": 2.714,
      "step": 308900
    },
    {
      "epoch": 496.66,
      "learning_rate": 0.050355355110932476,
      "loss": 2.6913,
      "step": 308920
    },
    {
      "epoch": 496.69,
      "learning_rate": 0.050352139680064315,
      "loss": 2.6863,
      "step": 308940
    },
    {
      "epoch": 496.72,
      "learning_rate": 0.05034892424919614,
      "loss": 2.67,
      "step": 308960
    },
    {
      "epoch": 496.75,
      "learning_rate": 0.050345708818327985,
      "loss": 2.6734,
      "step": 308980
    },
    {
      "epoch": 496.78,
      "learning_rate": 0.0503424933874598,
      "loss": 2.6925,
      "step": 309000
    },
    {
      "epoch": 496.82,
      "learning_rate": 0.05033927795659165,
      "loss": 2.6864,
      "step": 309020
    },
    {
      "epoch": 496.85,
      "learning_rate": 0.05033606252572348,
      "loss": 2.6914,
      "step": 309040
    },
    {
      "epoch": 496.88,
      "learning_rate": 0.050332847094855304,
      "loss": 2.6931,
      "step": 309060
    },
    {
      "epoch": 496.91,
      "learning_rate": 0.05032963166398716,
      "loss": 2.6998,
      "step": 309080
    },
    {
      "epoch": 496.95,
      "learning_rate": 0.05032641623311897,
      "loss": 2.7137,
      "step": 309100
    },
    {
      "epoch": 496.98,
      "learning_rate": 0.05032320080225081,
      "loss": 2.6963,
      "step": 309120
    },
    {
      "epoch": 497.0,
      "eval_accuracy": {
        "accuracy": 0.40962450439244347
      },
      "eval_loss": 2.8035244941711426,
      "eval_runtime": 3.2877,
      "eval_samples_per_second": 3912.466,
      "eval_steps_per_second": 61.137,
      "step": 309134
    },
    {
      "epoch": 497.01,
      "learning_rate": 0.05031998537138264,
      "loss": 2.6929,
      "step": 309140
    },
    {
      "epoch": 497.04,
      "learning_rate": 0.050316769940514476,
      "loss": 2.7153,
      "step": 309160
    },
    {
      "epoch": 497.07,
      "learning_rate": 0.0503135545096463,
      "loss": 2.6901,
      "step": 309180
    },
    {
      "epoch": 497.11,
      "learning_rate": 0.05031033907877813,
      "loss": 2.7198,
      "step": 309200
    },
    {
      "epoch": 497.14,
      "learning_rate": 0.050307123647909985,
      "loss": 2.6943,
      "step": 309220
    },
    {
      "epoch": 497.17,
      "learning_rate": 0.05030390821704181,
      "loss": 2.7079,
      "step": 309240
    },
    {
      "epoch": 497.2,
      "learning_rate": 0.05030069278617364,
      "loss": 2.6662,
      "step": 309260
    },
    {
      "epoch": 497.23,
      "learning_rate": 0.050297477355305466,
      "loss": 2.6848,
      "step": 309280
    },
    {
      "epoch": 497.27,
      "learning_rate": 0.05029426192443729,
      "loss": 2.6894,
      "step": 309300
    },
    {
      "epoch": 497.3,
      "learning_rate": 0.050291046493569136,
      "loss": 2.6784,
      "step": 309320
    },
    {
      "epoch": 497.33,
      "learning_rate": 0.05028783106270096,
      "loss": 2.6848,
      "step": 309340
    },
    {
      "epoch": 497.36,
      "learning_rate": 0.05028461563183281,
      "loss": 2.6884,
      "step": 309360
    },
    {
      "epoch": 497.4,
      "learning_rate": 0.05028140020096464,
      "loss": 2.7045,
      "step": 309380
    },
    {
      "epoch": 497.43,
      "learning_rate": 0.05027818477009646,
      "loss": 2.7021,
      "step": 309400
    },
    {
      "epoch": 497.46,
      "learning_rate": 0.05027496933922831,
      "loss": 2.6792,
      "step": 309420
    },
    {
      "epoch": 497.49,
      "learning_rate": 0.05027175390836012,
      "loss": 2.7324,
      "step": 309440
    },
    {
      "epoch": 497.52,
      "learning_rate": 0.050268538477491964,
      "loss": 2.7067,
      "step": 309460
    },
    {
      "epoch": 497.56,
      "learning_rate": 0.0502653230466238,
      "loss": 2.7,
      "step": 309480
    },
    {
      "epoch": 497.59,
      "learning_rate": 0.05026210761575563,
      "loss": 2.6824,
      "step": 309500
    },
    {
      "epoch": 497.62,
      "learning_rate": 0.050258892184887466,
      "loss": 2.6719,
      "step": 309520
    },
    {
      "epoch": 497.65,
      "learning_rate": 0.05025567675401929,
      "loss": 2.6999,
      "step": 309540
    },
    {
      "epoch": 497.68,
      "learning_rate": 0.050252461323151136,
      "loss": 2.7148,
      "step": 309560
    },
    {
      "epoch": 497.72,
      "learning_rate": 0.05024924589228297,
      "loss": 2.7071,
      "step": 309580
    },
    {
      "epoch": 497.75,
      "learning_rate": 0.05024603046141479,
      "loss": 2.683,
      "step": 309600
    },
    {
      "epoch": 497.78,
      "learning_rate": 0.05024281503054662,
      "loss": 2.6905,
      "step": 309620
    },
    {
      "epoch": 497.81,
      "learning_rate": 0.05023976037122187,
      "loss": 2.7279,
      "step": 309640
    },
    {
      "epoch": 497.85,
      "learning_rate": 0.050236544940353706,
      "loss": 2.6924,
      "step": 309660
    },
    {
      "epoch": 497.88,
      "learning_rate": 0.05023332950948554,
      "loss": 2.6991,
      "step": 309680
    },
    {
      "epoch": 497.91,
      "learning_rate": 0.05023011407861736,
      "loss": 2.6759,
      "step": 309700
    },
    {
      "epoch": 497.94,
      "learning_rate": 0.0502268986477492,
      "loss": 2.6811,
      "step": 309720
    },
    {
      "epoch": 497.97,
      "learning_rate": 0.05022368321688103,
      "loss": 2.684,
      "step": 309740
    },
    {
      "epoch": 498.0,
      "eval_accuracy": {
        "accuracy": 0.40962450439244347
      },
      "eval_loss": 2.8244597911834717,
      "eval_runtime": 2.8531,
      "eval_samples_per_second": 4508.351,
      "eval_steps_per_second": 70.448,
      "step": 309756
    },
    {
      "epoch": 498.01,
      "learning_rate": 0.05022046778601286,
      "loss": 2.692,
      "step": 309760
    },
    {
      "epoch": 498.04,
      "learning_rate": 0.05021725235514471,
      "loss": 2.7007,
      "step": 309780
    },
    {
      "epoch": 498.07,
      "learning_rate": 0.050214036924276534,
      "loss": 2.6902,
      "step": 309800
    },
    {
      "epoch": 498.1,
      "learning_rate": 0.050210821493408365,
      "loss": 2.6845,
      "step": 309820
    },
    {
      "epoch": 498.14,
      "learning_rate": 0.05020760606254019,
      "loss": 2.6815,
      "step": 309840
    },
    {
      "epoch": 498.17,
      "learning_rate": 0.05020439063167203,
      "loss": 2.669,
      "step": 309860
    },
    {
      "epoch": 498.2,
      "learning_rate": 0.05020117520080386,
      "loss": 2.6961,
      "step": 309880
    },
    {
      "epoch": 498.23,
      "learning_rate": 0.050197959769935685,
      "loss": 2.6648,
      "step": 309900
    },
    {
      "epoch": 498.26,
      "learning_rate": 0.05019474433906754,
      "loss": 2.6891,
      "step": 309920
    },
    {
      "epoch": 498.3,
      "learning_rate": 0.05019152890819936,
      "loss": 2.699,
      "step": 309940
    },
    {
      "epoch": 498.33,
      "learning_rate": 0.050188313477331194,
      "loss": 2.6834,
      "step": 309960
    },
    {
      "epoch": 498.36,
      "learning_rate": 0.05018509804646302,
      "loss": 2.69,
      "step": 309980
    },
    {
      "epoch": 498.39,
      "learning_rate": 0.05018188261559486,
      "loss": 2.7048,
      "step": 310000
    },
    {
      "epoch": 498.42,
      "learning_rate": 0.05017866718472669,
      "loss": 2.6803,
      "step": 310020
    },
    {
      "epoch": 498.46,
      "learning_rate": 0.05017545175385851,
      "loss": 2.6939,
      "step": 310040
    },
    {
      "epoch": 498.49,
      "learning_rate": 0.050172236322990366,
      "loss": 2.6977,
      "step": 310060
    },
    {
      "epoch": 498.52,
      "learning_rate": 0.05016902089212219,
      "loss": 2.6717,
      "step": 310080
    },
    {
      "epoch": 498.55,
      "learning_rate": 0.05016580546125402,
      "loss": 2.6764,
      "step": 310100
    },
    {
      "epoch": 498.59,
      "learning_rate": 0.05016259003038587,
      "loss": 2.6788,
      "step": 310120
    },
    {
      "epoch": 498.62,
      "learning_rate": 0.050159374599517685,
      "loss": 2.6876,
      "step": 310140
    },
    {
      "epoch": 498.65,
      "learning_rate": 0.05015615916864952,
      "loss": 2.7134,
      "step": 310160
    },
    {
      "epoch": 498.68,
      "learning_rate": 0.050152943737781355,
      "loss": 2.6935,
      "step": 310180
    },
    {
      "epoch": 498.71,
      "learning_rate": 0.050149728306913194,
      "loss": 2.6792,
      "step": 310200
    },
    {
      "epoch": 498.75,
      "learning_rate": 0.05014651287604502,
      "loss": 2.7175,
      "step": 310220
    },
    {
      "epoch": 498.78,
      "learning_rate": 0.05014329744517685,
      "loss": 2.6996,
      "step": 310240
    },
    {
      "epoch": 498.81,
      "learning_rate": 0.05014008201430869,
      "loss": 2.697,
      "step": 310260
    },
    {
      "epoch": 498.84,
      "learning_rate": 0.05013686658344051,
      "loss": 2.7178,
      "step": 310280
    },
    {
      "epoch": 498.87,
      "learning_rate": 0.050133651152572345,
      "loss": 2.7153,
      "step": 310300
    },
    {
      "epoch": 498.91,
      "learning_rate": 0.050130435721704183,
      "loss": 2.7097,
      "step": 310320
    },
    {
      "epoch": 498.94,
      "learning_rate": 0.05012722029083602,
      "loss": 2.702,
      "step": 310340
    },
    {
      "epoch": 498.97,
      "learning_rate": 0.050124004859967854,
      "loss": 2.6949,
      "step": 310360
    },
    {
      "epoch": 499.0,
      "eval_accuracy": {
        "accuracy": 0.41327839539765215
      },
      "eval_loss": 2.7894227504730225,
      "eval_runtime": 2.8539,
      "eval_samples_per_second": 4507.226,
      "eval_steps_per_second": 70.431,
      "step": 310378
    },
    {
      "epoch": 499.0,
      "learning_rate": 0.05012078942909968,
      "loss": 2.689,
      "step": 310380
    },
    {
      "epoch": 499.04,
      "learning_rate": 0.05011757399823152,
      "loss": 2.6864,
      "step": 310400
    },
    {
      "epoch": 499.07,
      "learning_rate": 0.05011435856736335,
      "loss": 2.676,
      "step": 310420
    },
    {
      "epoch": 499.1,
      "learning_rate": 0.05011114313649517,
      "loss": 2.6927,
      "step": 310440
    },
    {
      "epoch": 499.13,
      "learning_rate": 0.050107927705627026,
      "loss": 2.6797,
      "step": 310460
    },
    {
      "epoch": 499.16,
      "learning_rate": 0.05010471227475885,
      "loss": 2.6698,
      "step": 310480
    },
    {
      "epoch": 499.2,
      "learning_rate": 0.05010149684389068,
      "loss": 2.7085,
      "step": 310500
    },
    {
      "epoch": 499.23,
      "learning_rate": 0.05009828141302251,
      "loss": 2.6729,
      "step": 310520
    },
    {
      "epoch": 499.26,
      "learning_rate": 0.050095065982154345,
      "loss": 2.6821,
      "step": 310540
    },
    {
      "epoch": 499.29,
      "learning_rate": 0.05009185055128618,
      "loss": 2.694,
      "step": 310560
    },
    {
      "epoch": 499.32,
      "learning_rate": 0.050088635120418,
      "loss": 2.6603,
      "step": 310580
    },
    {
      "epoch": 499.36,
      "learning_rate": 0.050085419689549854,
      "loss": 2.6775,
      "step": 310600
    },
    {
      "epoch": 499.39,
      "learning_rate": 0.05008220425868168,
      "loss": 2.6814,
      "step": 310620
    },
    {
      "epoch": 499.42,
      "learning_rate": 0.05007898882781351,
      "loss": 2.6618,
      "step": 310640
    },
    {
      "epoch": 499.45,
      "learning_rate": 0.050075773396945335,
      "loss": 2.6864,
      "step": 310660
    },
    {
      "epoch": 499.49,
      "learning_rate": 0.05007255796607717,
      "loss": 2.7091,
      "step": 310680
    },
    {
      "epoch": 499.52,
      "learning_rate": 0.050069342535209005,
      "loss": 2.6843,
      "step": 310700
    },
    {
      "epoch": 499.55,
      "learning_rate": 0.05006612710434083,
      "loss": 2.6702,
      "step": 310720
    },
    {
      "epoch": 499.58,
      "learning_rate": 0.05006291167347268,
      "loss": 2.6917,
      "step": 310740
    },
    {
      "epoch": 499.61,
      "learning_rate": 0.05005969624260451,
      "loss": 2.6921,
      "step": 310760
    },
    {
      "epoch": 499.65,
      "learning_rate": 0.05005648081173634,
      "loss": 2.7205,
      "step": 310780
    },
    {
      "epoch": 499.68,
      "learning_rate": 0.05005326538086818,
      "loss": 2.7046,
      "step": 310800
    },
    {
      "epoch": 499.71,
      "learning_rate": 0.05005004995,
      "loss": 2.6967,
      "step": 310820
    },
    {
      "epoch": 499.74,
      "learning_rate": 0.05004683451913183,
      "loss": 2.6949,
      "step": 310840
    },
    {
      "epoch": 499.77,
      "learning_rate": 0.05004361908826367,
      "loss": 2.6619,
      "step": 310860
    },
    {
      "epoch": 499.81,
      "learning_rate": 0.05004040365739551,
      "loss": 2.6738,
      "step": 310880
    },
    {
      "epoch": 499.84,
      "learning_rate": 0.050037188226527335,
      "loss": 2.6765,
      "step": 310900
    },
    {
      "epoch": 499.87,
      "learning_rate": 0.050033972795659166,
      "loss": 2.6952,
      "step": 310920
    },
    {
      "epoch": 499.9,
      "learning_rate": 0.050030757364791005,
      "loss": 2.6929,
      "step": 310940
    },
    {
      "epoch": 499.94,
      "learning_rate": 0.050027541933922816,
      "loss": 2.6788,
      "step": 310960
    },
    {
      "epoch": 499.97,
      "learning_rate": 0.05002432650305466,
      "loss": 2.689,
      "step": 310980
    },
    {
      "epoch": 500.0,
      "learning_rate": 0.0500211110721865,
      "loss": 2.6927,
      "step": 311000
    },
    {
      "epoch": 500.0,
      "eval_accuracy": {
        "accuracy": 0.41576615097566666
      },
      "eval_loss": 2.788828134536743,
      "eval_runtime": 2.8316,
      "eval_samples_per_second": 4542.619,
      "eval_steps_per_second": 70.984,
      "step": 311000
    },
    {
      "epoch": 500.03,
      "learning_rate": 0.05001789564131834,
      "loss": 2.6635,
      "step": 311020
    },
    {
      "epoch": 500.06,
      "learning_rate": 0.05001468021045017,
      "loss": 2.674,
      "step": 311040
    },
    {
      "epoch": 500.1,
      "learning_rate": 0.05001146477958199,
      "loss": 2.6857,
      "step": 311060
    },
    {
      "epoch": 500.13,
      "learning_rate": 0.05000824934871383,
      "loss": 2.6981,
      "step": 311080
    },
    {
      "epoch": 500.16,
      "learning_rate": 0.050005033917845665,
      "loss": 2.6738,
      "step": 311100
    },
    {
      "epoch": 500.19,
      "learning_rate": 0.05000181848697749,
      "loss": 2.6793,
      "step": 311120
    },
    {
      "epoch": 500.23,
      "learning_rate": 0.04999860305610933,
      "loss": 2.6728,
      "step": 311140
    },
    {
      "epoch": 500.26,
      "learning_rate": 0.04999538762524117,
      "loss": 2.7011,
      "step": 311160
    },
    {
      "epoch": 500.29,
      "learning_rate": 0.049992172194373,
      "loss": 2.6597,
      "step": 311180
    },
    {
      "epoch": 500.32,
      "learning_rate": 0.04998895676350483,
      "loss": 2.674,
      "step": 311200
    },
    {
      "epoch": 500.35,
      "learning_rate": 0.04998574133263666,
      "loss": 2.6778,
      "step": 311220
    },
    {
      "epoch": 500.39,
      "learning_rate": 0.04998252590176849,
      "loss": 2.7006,
      "step": 311240
    },
    {
      "epoch": 500.42,
      "learning_rate": 0.049979310470900325,
      "loss": 2.6847,
      "step": 311260
    },
    {
      "epoch": 500.45,
      "learning_rate": 0.04997609504003216,
      "loss": 2.7081,
      "step": 311280
    },
    {
      "epoch": 500.48,
      "learning_rate": 0.049972879609163995,
      "loss": 2.7133,
      "step": 311300
    },
    {
      "epoch": 500.51,
      "learning_rate": 0.049969664178295826,
      "loss": 2.6805,
      "step": 311320
    },
    {
      "epoch": 500.55,
      "learning_rate": 0.04996644874742766,
      "loss": 2.6871,
      "step": 311340
    },
    {
      "epoch": 500.58,
      "learning_rate": 0.04996323331655949,
      "loss": 2.6858,
      "step": 311360
    },
    {
      "epoch": 500.61,
      "learning_rate": 0.049960017885691314,
      "loss": 2.6867,
      "step": 311380
    },
    {
      "epoch": 500.64,
      "learning_rate": 0.04995680245482316,
      "loss": 2.6935,
      "step": 311400
    },
    {
      "epoch": 500.68,
      "learning_rate": 0.04995358702395499,
      "loss": 2.6754,
      "step": 311420
    },
    {
      "epoch": 500.71,
      "learning_rate": 0.04995037159308682,
      "loss": 2.7206,
      "step": 311440
    },
    {
      "epoch": 500.74,
      "learning_rate": 0.049947156162218655,
      "loss": 2.7249,
      "step": 311460
    },
    {
      "epoch": 500.77,
      "learning_rate": 0.04994394073135048,
      "loss": 2.7,
      "step": 311480
    },
    {
      "epoch": 500.8,
      "learning_rate": 0.049940725300482325,
      "loss": 2.7153,
      "step": 311500
    },
    {
      "epoch": 500.84,
      "learning_rate": 0.049937509869614156,
      "loss": 2.7101,
      "step": 311520
    },
    {
      "epoch": 500.87,
      "learning_rate": 0.04993429443874599,
      "loss": 2.6928,
      "step": 311540
    },
    {
      "epoch": 500.9,
      "learning_rate": 0.04993107900787782,
      "loss": 2.7036,
      "step": 311560
    },
    {
      "epoch": 500.93,
      "learning_rate": 0.04992786357700965,
      "loss": 2.6939,
      "step": 311580
    },
    {
      "epoch": 500.96,
      "learning_rate": 0.049924648146141476,
      "loss": 2.6815,
      "step": 311600
    },
    {
      "epoch": 501.0,
      "learning_rate": 0.04992143271527332,
      "loss": 2.6646,
      "step": 311620
    },
    {
      "epoch": 501.0,
      "eval_accuracy": {
        "accuracy": 0.4110238669050766
      },
      "eval_loss": 2.7967066764831543,
      "eval_runtime": 2.8228,
      "eval_samples_per_second": 4556.839,
      "eval_steps_per_second": 71.206,
      "step": 311622
    },
    {
      "epoch": 501.03,
      "learning_rate": 0.04991821728440515,
      "loss": 2.6997,
      "step": 311640
    },
    {
      "epoch": 501.06,
      "learning_rate": 0.049915001853536985,
      "loss": 2.7107,
      "step": 311660
    },
    {
      "epoch": 501.09,
      "learning_rate": 0.049911786422668816,
      "loss": 2.6969,
      "step": 311680
    },
    {
      "epoch": 501.13,
      "learning_rate": 0.04990857099180064,
      "loss": 2.6846,
      "step": 311700
    },
    {
      "epoch": 501.16,
      "learning_rate": 0.04990535556093247,
      "loss": 2.6732,
      "step": 311720
    },
    {
      "epoch": 501.19,
      "learning_rate": 0.04990214013006432,
      "loss": 2.6898,
      "step": 311740
    },
    {
      "epoch": 501.22,
      "learning_rate": 0.04989892469919615,
      "loss": 2.6936,
      "step": 311760
    },
    {
      "epoch": 501.25,
      "learning_rate": 0.04989570926832798,
      "loss": 2.6725,
      "step": 311780
    },
    {
      "epoch": 501.29,
      "learning_rate": 0.049892493837459806,
      "loss": 2.6897,
      "step": 311800
    },
    {
      "epoch": 501.32,
      "learning_rate": 0.04988927840659164,
      "loss": 2.6891,
      "step": 311820
    },
    {
      "epoch": 501.35,
      "learning_rate": 0.04988606297572348,
      "loss": 2.6979,
      "step": 311840
    },
    {
      "epoch": 501.38,
      "learning_rate": 0.049882847544855315,
      "loss": 2.6675,
      "step": 311860
    },
    {
      "epoch": 501.41,
      "learning_rate": 0.049879632113987146,
      "loss": 2.6554,
      "step": 311880
    },
    {
      "epoch": 501.45,
      "learning_rate": 0.04987641668311898,
      "loss": 2.6696,
      "step": 311900
    },
    {
      "epoch": 501.48,
      "learning_rate": 0.0498732012522508,
      "loss": 2.6736,
      "step": 311920
    },
    {
      "epoch": 501.51,
      "learning_rate": 0.049869985821382634,
      "loss": 2.7069,
      "step": 311940
    },
    {
      "epoch": 501.54,
      "learning_rate": 0.04986677039051448,
      "loss": 2.6997,
      "step": 311960
    },
    {
      "epoch": 501.58,
      "learning_rate": 0.04986355495964631,
      "loss": 2.6861,
      "step": 311980
    },
    {
      "epoch": 501.61,
      "learning_rate": 0.04986033952877814,
      "loss": 2.6772,
      "step": 312000
    },
    {
      "epoch": 501.64,
      "learning_rate": 0.04985712409790997,
      "loss": 2.6729,
      "step": 312020
    },
    {
      "epoch": 501.67,
      "learning_rate": 0.0498539086670418,
      "loss": 2.7017,
      "step": 312040
    },
    {
      "epoch": 501.7,
      "learning_rate": 0.04985069323617363,
      "loss": 2.6884,
      "step": 312060
    },
    {
      "epoch": 501.74,
      "learning_rate": 0.049847477805305476,
      "loss": 2.6604,
      "step": 312080
    },
    {
      "epoch": 501.77,
      "learning_rate": 0.04984426237443731,
      "loss": 2.6819,
      "step": 312100
    },
    {
      "epoch": 501.8,
      "learning_rate": 0.04984104694356913,
      "loss": 2.7,
      "step": 312120
    },
    {
      "epoch": 501.83,
      "learning_rate": 0.049837831512700964,
      "loss": 2.6734,
      "step": 312140
    },
    {
      "epoch": 501.86,
      "learning_rate": 0.049834616081832796,
      "loss": 2.7005,
      "step": 312160
    },
    {
      "epoch": 501.9,
      "learning_rate": 0.04983140065096464,
      "loss": 2.7303,
      "step": 312180
    },
    {
      "epoch": 501.93,
      "learning_rate": 0.04982818522009647,
      "loss": 2.7149,
      "step": 312200
    },
    {
      "epoch": 501.96,
      "learning_rate": 0.049824969789228304,
      "loss": 2.6966,
      "step": 312220
    },
    {
      "epoch": 501.99,
      "learning_rate": 0.04982175435836013,
      "loss": 2.6955,
      "step": 312240
    },
    {
      "epoch": 502.0,
      "eval_accuracy": {
        "accuracy": 0.40962450439244347
      },
      "eval_loss": 2.816126585006714,
      "eval_runtime": 3.0887,
      "eval_samples_per_second": 4164.587,
      "eval_steps_per_second": 65.077,
      "step": 312244
    },
    {
      "epoch": 502.03,
      "learning_rate": 0.04981869969903537,
      "loss": 2.6782,
      "step": 312260
    },
    {
      "epoch": 502.06,
      "learning_rate": 0.049815484268167204,
      "loss": 2.6983,
      "step": 312280
    },
    {
      "epoch": 502.09,
      "learning_rate": 0.049812268837299035,
      "loss": 2.6946,
      "step": 312300
    },
    {
      "epoch": 502.12,
      "learning_rate": 0.04980905340643088,
      "loss": 2.6944,
      "step": 312320
    },
    {
      "epoch": 502.15,
      "learning_rate": 0.049805837975562706,
      "loss": 2.6924,
      "step": 312340
    },
    {
      "epoch": 502.19,
      "learning_rate": 0.04980262254469454,
      "loss": 2.6793,
      "step": 312360
    },
    {
      "epoch": 502.22,
      "learning_rate": 0.04979940711382637,
      "loss": 2.6873,
      "step": 312380
    },
    {
      "epoch": 502.25,
      "learning_rate": 0.0497961916829582,
      "loss": 2.6672,
      "step": 312400
    },
    {
      "epoch": 502.28,
      "learning_rate": 0.04979297625209003,
      "loss": 2.6586,
      "step": 312420
    },
    {
      "epoch": 502.32,
      "learning_rate": 0.04978976082122187,
      "loss": 2.6767,
      "step": 312440
    },
    {
      "epoch": 502.35,
      "learning_rate": 0.0497865453903537,
      "loss": 2.6966,
      "step": 312460
    },
    {
      "epoch": 502.38,
      "learning_rate": 0.049783329959485534,
      "loss": 2.6879,
      "step": 312480
    },
    {
      "epoch": 502.41,
      "learning_rate": 0.049780114528617365,
      "loss": 2.6733,
      "step": 312500
    },
    {
      "epoch": 502.44,
      "learning_rate": 0.0497768990977492,
      "loss": 2.7084,
      "step": 312520
    },
    {
      "epoch": 502.48,
      "learning_rate": 0.04977368366688103,
      "loss": 2.6939,
      "step": 312540
    },
    {
      "epoch": 502.51,
      "learning_rate": 0.04977046823601287,
      "loss": 2.6722,
      "step": 312560
    },
    {
      "epoch": 502.54,
      "learning_rate": 0.0497672528051447,
      "loss": 2.6784,
      "step": 312580
    },
    {
      "epoch": 502.57,
      "learning_rate": 0.04976403737427653,
      "loss": 2.6714,
      "step": 312600
    },
    {
      "epoch": 502.6,
      "learning_rate": 0.04976082194340836,
      "loss": 2.6946,
      "step": 312620
    },
    {
      "epoch": 502.64,
      "learning_rate": 0.049757606512540194,
      "loss": 2.6827,
      "step": 312640
    },
    {
      "epoch": 502.67,
      "learning_rate": 0.04975439108167203,
      "loss": 2.6863,
      "step": 312660
    },
    {
      "epoch": 502.7,
      "learning_rate": 0.049751175650803864,
      "loss": 2.6807,
      "step": 312680
    },
    {
      "epoch": 502.73,
      "learning_rate": 0.049747960219935695,
      "loss": 2.681,
      "step": 312700
    },
    {
      "epoch": 502.77,
      "learning_rate": 0.04974474478906753,
      "loss": 2.6865,
      "step": 312720
    },
    {
      "epoch": 502.8,
      "learning_rate": 0.04974152935819936,
      "loss": 2.6866,
      "step": 312740
    },
    {
      "epoch": 502.83,
      "learning_rate": 0.04973831392733119,
      "loss": 2.7026,
      "step": 312760
    },
    {
      "epoch": 502.86,
      "learning_rate": 0.04973509849646303,
      "loss": 2.7005,
      "step": 312780
    },
    {
      "epoch": 502.89,
      "learning_rate": 0.04973188306559486,
      "loss": 2.6812,
      "step": 312800
    },
    {
      "epoch": 502.93,
      "learning_rate": 0.04972866763472669,
      "loss": 2.7026,
      "step": 312820
    },
    {
      "epoch": 502.96,
      "learning_rate": 0.049725452203858524,
      "loss": 2.72,
      "step": 312840
    },
    {
      "epoch": 502.99,
      "learning_rate": 0.049722236772990355,
      "loss": 2.7201,
      "step": 312860
    },
    {
      "epoch": 503.0,
      "eval_accuracy": {
        "accuracy": 0.4158438933374796
      },
      "eval_loss": 2.7904951572418213,
      "eval_runtime": 2.8732,
      "eval_samples_per_second": 4476.955,
      "eval_steps_per_second": 69.958,
      "step": 312866
    },
    {
      "epoch": 503.02,
      "learning_rate": 0.04971902134212219,
      "loss": 2.7248,
      "step": 312880
    },
    {
      "epoch": 503.05,
      "learning_rate": 0.049715805911254025,
      "loss": 2.6881,
      "step": 312900
    },
    {
      "epoch": 503.09,
      "learning_rate": 0.04971259048038586,
      "loss": 2.6596,
      "step": 312920
    },
    {
      "epoch": 503.12,
      "learning_rate": 0.04970937504951769,
      "loss": 2.6766,
      "step": 312940
    },
    {
      "epoch": 503.15,
      "learning_rate": 0.04970615961864952,
      "loss": 2.6803,
      "step": 312960
    },
    {
      "epoch": 503.18,
      "learning_rate": 0.04970294418778135,
      "loss": 2.6967,
      "step": 312980
    },
    {
      "epoch": 503.22,
      "learning_rate": 0.04969972875691319,
      "loss": 2.6803,
      "step": 313000
    },
    {
      "epoch": 503.25,
      "learning_rate": 0.04969651332604502,
      "loss": 2.6762,
      "step": 313020
    },
    {
      "epoch": 503.28,
      "learning_rate": 0.049693297895176854,
      "loss": 2.6634,
      "step": 313040
    },
    {
      "epoch": 503.31,
      "learning_rate": 0.049690082464308685,
      "loss": 2.6699,
      "step": 313060
    },
    {
      "epoch": 503.34,
      "learning_rate": 0.04968686703344052,
      "loss": 2.6966,
      "step": 313080
    },
    {
      "epoch": 503.38,
      "learning_rate": 0.04968365160257235,
      "loss": 2.6997,
      "step": 313100
    },
    {
      "epoch": 503.41,
      "learning_rate": 0.04968043617170419,
      "loss": 2.6842,
      "step": 313120
    },
    {
      "epoch": 503.44,
      "learning_rate": 0.04967722074083602,
      "loss": 2.6891,
      "step": 313140
    },
    {
      "epoch": 503.47,
      "learning_rate": 0.04967400530996785,
      "loss": 2.666,
      "step": 313160
    },
    {
      "epoch": 503.5,
      "learning_rate": 0.04967078987909968,
      "loss": 2.6767,
      "step": 313180
    },
    {
      "epoch": 503.54,
      "learning_rate": 0.04966757444823151,
      "loss": 2.7011,
      "step": 313200
    },
    {
      "epoch": 503.57,
      "learning_rate": 0.049664359017363345,
      "loss": 2.6868,
      "step": 313220
    },
    {
      "epoch": 503.6,
      "learning_rate": 0.049661143586495184,
      "loss": 2.6854,
      "step": 313240
    },
    {
      "epoch": 503.63,
      "learning_rate": 0.049657928155627015,
      "loss": 2.6566,
      "step": 313260
    },
    {
      "epoch": 503.67,
      "learning_rate": 0.04965471272475885,
      "loss": 2.6771,
      "step": 313280
    },
    {
      "epoch": 503.7,
      "learning_rate": 0.04965149729389068,
      "loss": 2.6983,
      "step": 313300
    },
    {
      "epoch": 503.73,
      "learning_rate": 0.04964828186302251,
      "loss": 2.6795,
      "step": 313320
    },
    {
      "epoch": 503.76,
      "learning_rate": 0.04964506643215435,
      "loss": 2.6647,
      "step": 313340
    },
    {
      "epoch": 503.79,
      "learning_rate": 0.04964185100128618,
      "loss": 2.6877,
      "step": 313360
    },
    {
      "epoch": 503.83,
      "learning_rate": 0.04963863557041801,
      "loss": 2.6839,
      "step": 313380
    },
    {
      "epoch": 503.86,
      "learning_rate": 0.04963542013954984,
      "loss": 2.6911,
      "step": 313400
    },
    {
      "epoch": 503.89,
      "learning_rate": 0.049632204708681675,
      "loss": 2.6958,
      "step": 313420
    },
    {
      "epoch": 503.92,
      "learning_rate": 0.04962898927781351,
      "loss": 2.6942,
      "step": 313440
    },
    {
      "epoch": 503.95,
      "learning_rate": 0.049625773846945345,
      "loss": 2.682,
      "step": 313460
    },
    {
      "epoch": 503.99,
      "learning_rate": 0.04962255841607718,
      "loss": 2.6782,
      "step": 313480
    },
    {
      "epoch": 504.0,
      "eval_accuracy": {
        "accuracy": 0.40799191479437147
      },
      "eval_loss": 2.7943928241729736,
      "eval_runtime": 2.8023,
      "eval_samples_per_second": 4590.228,
      "eval_steps_per_second": 71.728,
      "step": 313488
    },
    {
      "epoch": 504.02,
      "learning_rate": 0.04961934298520901,
      "loss": 2.6819,
      "step": 313500
    },
    {
      "epoch": 504.05,
      "learning_rate": 0.04961612755434084,
      "loss": 2.6845,
      "step": 313520
    },
    {
      "epoch": 504.08,
      "learning_rate": 0.04961291212347267,
      "loss": 2.6746,
      "step": 313540
    },
    {
      "epoch": 504.12,
      "learning_rate": 0.04960969669260451,
      "loss": 2.6861,
      "step": 313560
    },
    {
      "epoch": 504.15,
      "learning_rate": 0.04960648126173634,
      "loss": 2.666,
      "step": 313580
    },
    {
      "epoch": 504.18,
      "learning_rate": 0.04960326583086817,
      "loss": 2.7067,
      "step": 313600
    },
    {
      "epoch": 504.21,
      "learning_rate": 0.049600050400000005,
      "loss": 2.6816,
      "step": 313620
    },
    {
      "epoch": 504.24,
      "learning_rate": 0.04959683496913184,
      "loss": 2.7161,
      "step": 313640
    },
    {
      "epoch": 504.28,
      "learning_rate": 0.04959361953826367,
      "loss": 2.6976,
      "step": 313660
    },
    {
      "epoch": 504.31,
      "learning_rate": 0.04959040410739551,
      "loss": 2.7019,
      "step": 313680
    },
    {
      "epoch": 504.34,
      "learning_rate": 0.04958718867652734,
      "loss": 2.6661,
      "step": 313700
    },
    {
      "epoch": 504.37,
      "learning_rate": 0.04958397324565917,
      "loss": 2.6893,
      "step": 313720
    },
    {
      "epoch": 504.41,
      "learning_rate": 0.049580757814791,
      "loss": 2.6895,
      "step": 313740
    },
    {
      "epoch": 504.44,
      "learning_rate": 0.04957754238392283,
      "loss": 2.6872,
      "step": 313760
    },
    {
      "epoch": 504.47,
      "learning_rate": 0.049574326953054665,
      "loss": 2.6926,
      "step": 313780
    },
    {
      "epoch": 504.5,
      "learning_rate": 0.0495711115221865,
      "loss": 2.6924,
      "step": 313800
    },
    {
      "epoch": 504.53,
      "learning_rate": 0.049567896091318335,
      "loss": 2.6779,
      "step": 313820
    },
    {
      "epoch": 504.57,
      "learning_rate": 0.04956468066045017,
      "loss": 2.7123,
      "step": 313840
    },
    {
      "epoch": 504.6,
      "learning_rate": 0.049561465229582,
      "loss": 2.6998,
      "step": 313860
    },
    {
      "epoch": 504.63,
      "learning_rate": 0.04955824979871383,
      "loss": 2.6812,
      "step": 313880
    },
    {
      "epoch": 504.66,
      "learning_rate": 0.04955503436784567,
      "loss": 2.6736,
      "step": 313900
    },
    {
      "epoch": 504.69,
      "learning_rate": 0.0495518189369775,
      "loss": 2.6819,
      "step": 313920
    },
    {
      "epoch": 504.73,
      "learning_rate": 0.04954860350610933,
      "loss": 2.6833,
      "step": 313940
    },
    {
      "epoch": 504.76,
      "learning_rate": 0.04954538807524116,
      "loss": 2.7035,
      "step": 313960
    },
    {
      "epoch": 504.79,
      "learning_rate": 0.049542172644372995,
      "loss": 2.675,
      "step": 313980
    },
    {
      "epoch": 504.82,
      "learning_rate": 0.04953895721350482,
      "loss": 2.6907,
      "step": 314000
    },
    {
      "epoch": 504.86,
      "learning_rate": 0.049535741782636665,
      "loss": 2.6821,
      "step": 314020
    },
    {
      "epoch": 504.89,
      "learning_rate": 0.0495325263517685,
      "loss": 2.6687,
      "step": 314040
    },
    {
      "epoch": 504.92,
      "learning_rate": 0.04952931092090033,
      "loss": 2.6703,
      "step": 314060
    },
    {
      "epoch": 504.95,
      "learning_rate": 0.04952609549003216,
      "loss": 2.7023,
      "step": 314080
    },
    {
      "epoch": 504.98,
      "learning_rate": 0.04952288005916399,
      "loss": 2.6729,
      "step": 314100
    },
    {
      "epoch": 505.0,
      "eval_accuracy": {
        "accuracy": 0.40604835574904763
      },
      "eval_loss": 2.817575454711914,
      "eval_runtime": 2.805,
      "eval_samples_per_second": 4585.76,
      "eval_steps_per_second": 71.658,
      "step": 314110
    },
    {
      "epoch": 505.02,
      "learning_rate": 0.049519664628295816,
      "loss": 2.6948,
      "step": 314120
    },
    {
      "epoch": 505.05,
      "learning_rate": 0.04951644919742766,
      "loss": 2.6854,
      "step": 314140
    },
    {
      "epoch": 505.08,
      "learning_rate": 0.04951323376655949,
      "loss": 2.6892,
      "step": 314160
    },
    {
      "epoch": 505.11,
      "learning_rate": 0.049510018335691325,
      "loss": 2.6893,
      "step": 314180
    },
    {
      "epoch": 505.14,
      "learning_rate": 0.049506802904823156,
      "loss": 2.691,
      "step": 314200
    },
    {
      "epoch": 505.18,
      "learning_rate": 0.04950358747395498,
      "loss": 2.6903,
      "step": 314220
    },
    {
      "epoch": 505.21,
      "learning_rate": 0.04950037204308683,
      "loss": 2.6774,
      "step": 314240
    },
    {
      "epoch": 505.24,
      "learning_rate": 0.04949715661221866,
      "loss": 2.7107,
      "step": 314260
    },
    {
      "epoch": 505.27,
      "learning_rate": 0.04949394118135049,
      "loss": 2.6853,
      "step": 314280
    },
    {
      "epoch": 505.31,
      "learning_rate": 0.04949072575048232,
      "loss": 2.6803,
      "step": 314300
    },
    {
      "epoch": 505.34,
      "learning_rate": 0.049487510319614146,
      "loss": 2.6859,
      "step": 314320
    },
    {
      "epoch": 505.37,
      "learning_rate": 0.04948429488874598,
      "loss": 2.6684,
      "step": 314340
    },
    {
      "epoch": 505.4,
      "learning_rate": 0.04948107945787782,
      "loss": 2.6945,
      "step": 314360
    },
    {
      "epoch": 505.43,
      "learning_rate": 0.049477864027009655,
      "loss": 2.712,
      "step": 314380
    },
    {
      "epoch": 505.47,
      "learning_rate": 0.049474648596141486,
      "loss": 2.6703,
      "step": 314400
    },
    {
      "epoch": 505.5,
      "learning_rate": 0.04947143316527332,
      "loss": 2.6984,
      "step": 314420
    },
    {
      "epoch": 505.53,
      "learning_rate": 0.04946821773440514,
      "loss": 2.6904,
      "step": 314440
    },
    {
      "epoch": 505.56,
      "learning_rate": 0.049465002303536974,
      "loss": 2.6563,
      "step": 314460
    },
    {
      "epoch": 505.59,
      "learning_rate": 0.04946178687266882,
      "loss": 2.693,
      "step": 314480
    },
    {
      "epoch": 505.63,
      "learning_rate": 0.04945857144180065,
      "loss": 2.7077,
      "step": 314500
    },
    {
      "epoch": 505.66,
      "learning_rate": 0.04945535601093248,
      "loss": 2.6974,
      "step": 314520
    },
    {
      "epoch": 505.69,
      "learning_rate": 0.04945214058006431,
      "loss": 2.6895,
      "step": 314540
    },
    {
      "epoch": 505.72,
      "learning_rate": 0.04944892514919614,
      "loss": 2.6947,
      "step": 314560
    },
    {
      "epoch": 505.76,
      "learning_rate": 0.049445709718327985,
      "loss": 2.6795,
      "step": 314580
    },
    {
      "epoch": 505.79,
      "learning_rate": 0.049442494287459816,
      "loss": 2.7061,
      "step": 314600
    },
    {
      "epoch": 505.82,
      "learning_rate": 0.04943927885659165,
      "loss": 2.6956,
      "step": 314620
    },
    {
      "epoch": 505.85,
      "learning_rate": 0.04943606342572348,
      "loss": 2.682,
      "step": 314640
    },
    {
      "epoch": 505.88,
      "learning_rate": 0.049432847994855304,
      "loss": 2.6921,
      "step": 314660
    },
    {
      "epoch": 505.92,
      "learning_rate": 0.049429632563987136,
      "loss": 2.6859,
      "step": 314680
    },
    {
      "epoch": 505.95,
      "learning_rate": 0.04942641713311898,
      "loss": 2.6807,
      "step": 314700
    },
    {
      "epoch": 505.98,
      "learning_rate": 0.04942320170225081,
      "loss": 2.6835,
      "step": 314720
    },
    {
      "epoch": 506.0,
      "eval_accuracy": {
        "accuracy": 0.41281194122677445
      },
      "eval_loss": 2.7967171669006348,
      "eval_runtime": 3.0092,
      "eval_samples_per_second": 4274.542,
      "eval_steps_per_second": 66.795,
      "step": 314732
    },
    {
      "epoch": 506.01,
      "learning_rate": 0.049419986271382645,
      "loss": 2.658,
      "step": 314740
    },
    {
      "epoch": 506.05,
      "learning_rate": 0.04941677084051447,
      "loss": 2.6894,
      "step": 314760
    },
    {
      "epoch": 506.08,
      "learning_rate": 0.0494135554096463,
      "loss": 2.7001,
      "step": 314780
    },
    {
      "epoch": 506.11,
      "learning_rate": 0.04941033997877813,
      "loss": 2.6914,
      "step": 314800
    },
    {
      "epoch": 506.14,
      "learning_rate": 0.04940712454790998,
      "loss": 2.693,
      "step": 314820
    },
    {
      "epoch": 506.17,
      "learning_rate": 0.04940390911704181,
      "loss": 2.6785,
      "step": 314840
    },
    {
      "epoch": 506.21,
      "learning_rate": 0.049400693686173634,
      "loss": 2.6709,
      "step": 314860
    },
    {
      "epoch": 506.24,
      "learning_rate": 0.049397478255305466,
      "loss": 2.6711,
      "step": 314880
    },
    {
      "epoch": 506.27,
      "learning_rate": 0.0493942628244373,
      "loss": 2.6663,
      "step": 314900
    },
    {
      "epoch": 506.3,
      "learning_rate": 0.04939104739356914,
      "loss": 2.6991,
      "step": 314920
    },
    {
      "epoch": 506.33,
      "learning_rate": 0.049387831962700975,
      "loss": 2.7121,
      "step": 314940
    },
    {
      "epoch": 506.37,
      "learning_rate": 0.049384616531832806,
      "loss": 2.6492,
      "step": 314960
    },
    {
      "epoch": 506.4,
      "learning_rate": 0.04938140110096463,
      "loss": 2.6868,
      "step": 314980
    },
    {
      "epoch": 506.43,
      "learning_rate": 0.04937818567009646,
      "loss": 2.68,
      "step": 315000
    },
    {
      "epoch": 506.46,
      "learning_rate": 0.049374970239228294,
      "loss": 2.6656,
      "step": 315020
    },
    {
      "epoch": 506.5,
      "learning_rate": 0.04937175480836014,
      "loss": 2.6612,
      "step": 315040
    },
    {
      "epoch": 506.53,
      "learning_rate": 0.04936853937749197,
      "loss": 2.6943,
      "step": 315060
    },
    {
      "epoch": 506.56,
      "learning_rate": 0.049365323946623796,
      "loss": 2.6773,
      "step": 315080
    },
    {
      "epoch": 506.59,
      "learning_rate": 0.04936210851575563,
      "loss": 2.658,
      "step": 315100
    },
    {
      "epoch": 506.62,
      "learning_rate": 0.04935889308488746,
      "loss": 2.6866,
      "step": 315120
    },
    {
      "epoch": 506.66,
      "learning_rate": 0.04935567765401929,
      "loss": 2.7002,
      "step": 315140
    },
    {
      "epoch": 506.69,
      "learning_rate": 0.049352462223151136,
      "loss": 2.6908,
      "step": 315160
    },
    {
      "epoch": 506.72,
      "learning_rate": 0.04934924679228296,
      "loss": 2.6737,
      "step": 315180
    },
    {
      "epoch": 506.75,
      "learning_rate": 0.04934603136141479,
      "loss": 2.6868,
      "step": 315200
    },
    {
      "epoch": 506.78,
      "learning_rate": 0.049342815930546624,
      "loss": 2.7227,
      "step": 315220
    },
    {
      "epoch": 506.82,
      "learning_rate": 0.049339600499678456,
      "loss": 2.7025,
      "step": 315240
    },
    {
      "epoch": 506.85,
      "learning_rate": 0.0493363850688103,
      "loss": 2.7071,
      "step": 315260
    },
    {
      "epoch": 506.88,
      "learning_rate": 0.04933316963794213,
      "loss": 2.6924,
      "step": 315280
    },
    {
      "epoch": 506.91,
      "learning_rate": 0.04933011497861737,
      "loss": 2.6831,
      "step": 315300
    },
    {
      "epoch": 506.95,
      "learning_rate": 0.0493268995477492,
      "loss": 2.6921,
      "step": 315320
    },
    {
      "epoch": 506.98,
      "learning_rate": 0.04932368411688103,
      "loss": 2.6809,
      "step": 315340
    },
    {
      "epoch": 507.0,
      "eval_accuracy": {
        "accuracy": 0.4100132162015082
      },
      "eval_loss": 2.7986204624176025,
      "eval_runtime": 2.8865,
      "eval_samples_per_second": 4456.308,
      "eval_steps_per_second": 69.635,
      "step": 315354
    },
    {
      "epoch": 507.01,
      "learning_rate": 0.049320468686012864,
      "loss": 2.6934,
      "step": 315360
    },
    {
      "epoch": 507.04,
      "learning_rate": 0.049317253255144695,
      "loss": 2.6927,
      "step": 315380
    },
    {
      "epoch": 507.07,
      "learning_rate": 0.049314037824276534,
      "loss": 2.6945,
      "step": 315400
    },
    {
      "epoch": 507.11,
      "learning_rate": 0.049310822393408366,
      "loss": 2.6829,
      "step": 315420
    },
    {
      "epoch": 507.14,
      "learning_rate": 0.0493076069625402,
      "loss": 2.6632,
      "step": 315440
    },
    {
      "epoch": 507.17,
      "learning_rate": 0.04930439153167203,
      "loss": 2.6638,
      "step": 315460
    },
    {
      "epoch": 507.2,
      "learning_rate": 0.04930117610080386,
      "loss": 2.6889,
      "step": 315480
    },
    {
      "epoch": 507.23,
      "learning_rate": 0.04929796066993569,
      "loss": 2.6971,
      "step": 315500
    },
    {
      "epoch": 507.27,
      "learning_rate": 0.04929474523906753,
      "loss": 2.6847,
      "step": 315520
    },
    {
      "epoch": 507.3,
      "learning_rate": 0.04929152980819936,
      "loss": 2.7031,
      "step": 315540
    },
    {
      "epoch": 507.33,
      "learning_rate": 0.049288314377331194,
      "loss": 2.6887,
      "step": 315560
    },
    {
      "epoch": 507.36,
      "learning_rate": 0.049285098946463025,
      "loss": 2.693,
      "step": 315580
    },
    {
      "epoch": 507.4,
      "learning_rate": 0.04928188351559486,
      "loss": 2.7271,
      "step": 315600
    },
    {
      "epoch": 507.43,
      "learning_rate": 0.04927866808472669,
      "loss": 2.6942,
      "step": 315620
    },
    {
      "epoch": 507.46,
      "learning_rate": 0.04927545265385853,
      "loss": 2.6667,
      "step": 315640
    },
    {
      "epoch": 507.49,
      "learning_rate": 0.04927223722299036,
      "loss": 2.6695,
      "step": 315660
    },
    {
      "epoch": 507.52,
      "learning_rate": 0.04926902179212219,
      "loss": 2.6705,
      "step": 315680
    },
    {
      "epoch": 507.56,
      "learning_rate": 0.04926580636125402,
      "loss": 2.7099,
      "step": 315700
    },
    {
      "epoch": 507.59,
      "learning_rate": 0.049262590930385854,
      "loss": 2.6593,
      "step": 315720
    },
    {
      "epoch": 507.62,
      "learning_rate": 0.04925937549951769,
      "loss": 2.6981,
      "step": 315740
    },
    {
      "epoch": 507.65,
      "learning_rate": 0.049256160068649524,
      "loss": 2.6693,
      "step": 315760
    },
    {
      "epoch": 507.68,
      "learning_rate": 0.049252944637781355,
      "loss": 2.6616,
      "step": 315780
    },
    {
      "epoch": 507.72,
      "learning_rate": 0.04924972920691319,
      "loss": 2.6772,
      "step": 315800
    },
    {
      "epoch": 507.75,
      "learning_rate": 0.04924651377604502,
      "loss": 2.6898,
      "step": 315820
    },
    {
      "epoch": 507.78,
      "learning_rate": 0.04924329834517685,
      "loss": 2.68,
      "step": 315840
    },
    {
      "epoch": 507.81,
      "learning_rate": 0.04924008291430869,
      "loss": 2.7028,
      "step": 315860
    },
    {
      "epoch": 507.85,
      "learning_rate": 0.04923686748344052,
      "loss": 2.6915,
      "step": 315880
    },
    {
      "epoch": 507.88,
      "learning_rate": 0.04923365205257235,
      "loss": 2.7049,
      "step": 315900
    },
    {
      "epoch": 507.91,
      "learning_rate": 0.049230436621704184,
      "loss": 2.7154,
      "step": 315920
    },
    {
      "epoch": 507.94,
      "learning_rate": 0.049227221190836015,
      "loss": 2.707,
      "step": 315940
    },
    {
      "epoch": 507.97,
      "learning_rate": 0.04922400575996785,
      "loss": 2.6859,
      "step": 315960
    },
    {
      "epoch": 508.0,
      "eval_accuracy": {
        "accuracy": 0.41203451760864496
      },
      "eval_loss": 2.7944700717926025,
      "eval_runtime": 2.922,
      "eval_samples_per_second": 4402.077,
      "eval_steps_per_second": 68.788,
      "step": 315976
    },
    {
      "epoch": 508.01,
      "learning_rate": 0.049220790329099685,
      "loss": 2.6661,
      "step": 315980
    },
    {
      "epoch": 508.04,
      "learning_rate": 0.04921757489823152,
      "loss": 2.6837,
      "step": 316000
    },
    {
      "epoch": 508.07,
      "learning_rate": 0.04921435946736335,
      "loss": 2.6795,
      "step": 316020
    },
    {
      "epoch": 508.1,
      "learning_rate": 0.04921114403649518,
      "loss": 2.6698,
      "step": 316040
    },
    {
      "epoch": 508.14,
      "learning_rate": 0.04920792860562701,
      "loss": 2.6725,
      "step": 316060
    },
    {
      "epoch": 508.17,
      "learning_rate": 0.04920471317475885,
      "loss": 2.6851,
      "step": 316080
    },
    {
      "epoch": 508.2,
      "learning_rate": 0.04920149774389068,
      "loss": 2.6721,
      "step": 316100
    },
    {
      "epoch": 508.23,
      "learning_rate": 0.049198282313022514,
      "loss": 2.677,
      "step": 316120
    },
    {
      "epoch": 508.26,
      "learning_rate": 0.049195066882154345,
      "loss": 2.6877,
      "step": 316140
    },
    {
      "epoch": 508.3,
      "learning_rate": 0.04919185145128618,
      "loss": 2.6886,
      "step": 316160
    },
    {
      "epoch": 508.33,
      "learning_rate": 0.04918863602041801,
      "loss": 2.6743,
      "step": 316180
    },
    {
      "epoch": 508.36,
      "learning_rate": 0.04918542058954985,
      "loss": 2.6732,
      "step": 316200
    },
    {
      "epoch": 508.39,
      "learning_rate": 0.04918220515868168,
      "loss": 2.667,
      "step": 316220
    },
    {
      "epoch": 508.42,
      "learning_rate": 0.04917898972781351,
      "loss": 2.669,
      "step": 316240
    },
    {
      "epoch": 508.46,
      "learning_rate": 0.04917577429694534,
      "loss": 2.6599,
      "step": 316260
    },
    {
      "epoch": 508.49,
      "learning_rate": 0.04917255886607717,
      "loss": 2.7044,
      "step": 316280
    },
    {
      "epoch": 508.52,
      "learning_rate": 0.04916934343520901,
      "loss": 2.6897,
      "step": 316300
    },
    {
      "epoch": 508.55,
      "learning_rate": 0.049166128004340844,
      "loss": 2.6631,
      "step": 316320
    },
    {
      "epoch": 508.59,
      "learning_rate": 0.049162912573472675,
      "loss": 2.6691,
      "step": 316340
    },
    {
      "epoch": 508.62,
      "learning_rate": 0.04915969714260451,
      "loss": 2.702,
      "step": 316360
    },
    {
      "epoch": 508.65,
      "learning_rate": 0.04915648171173634,
      "loss": 2.7044,
      "step": 316380
    },
    {
      "epoch": 508.68,
      "learning_rate": 0.04915326628086817,
      "loss": 2.7147,
      "step": 316400
    },
    {
      "epoch": 508.71,
      "learning_rate": 0.04915005085000001,
      "loss": 2.6893,
      "step": 316420
    },
    {
      "epoch": 508.75,
      "learning_rate": 0.04914683541913184,
      "loss": 2.684,
      "step": 316440
    },
    {
      "epoch": 508.78,
      "learning_rate": 0.04914361998826367,
      "loss": 2.68,
      "step": 316460
    },
    {
      "epoch": 508.81,
      "learning_rate": 0.0491404045573955,
      "loss": 2.6807,
      "step": 316480
    },
    {
      "epoch": 508.84,
      "learning_rate": 0.049137189126527335,
      "loss": 2.6897,
      "step": 316500
    },
    {
      "epoch": 508.87,
      "learning_rate": 0.04913397369565916,
      "loss": 2.6596,
      "step": 316520
    },
    {
      "epoch": 508.91,
      "learning_rate": 0.049130758264791005,
      "loss": 2.6849,
      "step": 316540
    },
    {
      "epoch": 508.94,
      "learning_rate": 0.04912754283392284,
      "loss": 2.6877,
      "step": 316560
    },
    {
      "epoch": 508.97,
      "learning_rate": 0.04912432740305467,
      "loss": 2.6796,
      "step": 316580
    },
    {
      "epoch": 509.0,
      "eval_accuracy": {
        "accuracy": 0.4117235481613931
      },
      "eval_loss": 2.779146194458008,
      "eval_runtime": 3.0137,
      "eval_samples_per_second": 4268.233,
      "eval_steps_per_second": 66.696,
      "step": 316598
    },
    {
      "epoch": 509.0,
      "learning_rate": 0.0491211119721865,
      "loss": 2.6682,
      "step": 316600
    },
    {
      "epoch": 509.04,
      "learning_rate": 0.04911789654131833,
      "loss": 2.6579,
      "step": 316620
    },
    {
      "epoch": 509.07,
      "learning_rate": 0.04911468111045017,
      "loss": 2.6662,
      "step": 316640
    },
    {
      "epoch": 509.1,
      "learning_rate": 0.049111465679582,
      "loss": 2.6772,
      "step": 316660
    },
    {
      "epoch": 509.13,
      "learning_rate": 0.04910825024871383,
      "loss": 2.667,
      "step": 316680
    },
    {
      "epoch": 509.16,
      "learning_rate": 0.049105034817845665,
      "loss": 2.6973,
      "step": 316700
    },
    {
      "epoch": 509.2,
      "learning_rate": 0.0491018193869775,
      "loss": 2.7108,
      "step": 316720
    },
    {
      "epoch": 509.23,
      "learning_rate": 0.04909860395610932,
      "loss": 2.6782,
      "step": 316740
    },
    {
      "epoch": 509.26,
      "learning_rate": 0.04909538852524117,
      "loss": 2.6901,
      "step": 316760
    },
    {
      "epoch": 509.29,
      "learning_rate": 0.049092173094373,
      "loss": 2.6914,
      "step": 316780
    },
    {
      "epoch": 509.32,
      "learning_rate": 0.04908895766350483,
      "loss": 2.6791,
      "step": 316800
    },
    {
      "epoch": 509.36,
      "learning_rate": 0.04908574223263666,
      "loss": 2.6753,
      "step": 316820
    },
    {
      "epoch": 509.39,
      "learning_rate": 0.04908252680176849,
      "loss": 2.6984,
      "step": 316840
    },
    {
      "epoch": 509.42,
      "learning_rate": 0.04907931137090032,
      "loss": 2.6799,
      "step": 316860
    },
    {
      "epoch": 509.45,
      "learning_rate": 0.04907609594003216,
      "loss": 2.6781,
      "step": 316880
    },
    {
      "epoch": 509.49,
      "learning_rate": 0.049072880509163995,
      "loss": 2.6823,
      "step": 316900
    },
    {
      "epoch": 509.52,
      "learning_rate": 0.04906966507829583,
      "loss": 2.6673,
      "step": 316920
    },
    {
      "epoch": 509.55,
      "learning_rate": 0.04906644964742766,
      "loss": 2.6899,
      "step": 316940
    },
    {
      "epoch": 509.58,
      "learning_rate": 0.04906323421655948,
      "loss": 2.6799,
      "step": 316960
    },
    {
      "epoch": 509.61,
      "learning_rate": 0.04906001878569133,
      "loss": 2.674,
      "step": 316980
    },
    {
      "epoch": 509.65,
      "learning_rate": 0.04905680335482316,
      "loss": 2.6935,
      "step": 317000
    },
    {
      "epoch": 509.68,
      "learning_rate": 0.04905358792395499,
      "loss": 2.6821,
      "step": 317020
    },
    {
      "epoch": 509.71,
      "learning_rate": 0.04905037249308682,
      "loss": 2.6781,
      "step": 317040
    },
    {
      "epoch": 509.74,
      "learning_rate": 0.04904715706221865,
      "loss": 2.6673,
      "step": 317060
    },
    {
      "epoch": 509.77,
      "learning_rate": 0.04904394163135048,
      "loss": 2.6984,
      "step": 317080
    },
    {
      "epoch": 509.81,
      "learning_rate": 0.049040726200482325,
      "loss": 2.6833,
      "step": 317100
    },
    {
      "epoch": 509.84,
      "learning_rate": 0.04903751076961416,
      "loss": 2.6736,
      "step": 317120
    },
    {
      "epoch": 509.87,
      "learning_rate": 0.04903429533874599,
      "loss": 2.6935,
      "step": 317140
    },
    {
      "epoch": 509.9,
      "learning_rate": 0.04903107990787782,
      "loss": 2.6916,
      "step": 317160
    },
    {
      "epoch": 509.94,
      "learning_rate": 0.049027864477009644,
      "loss": 2.6858,
      "step": 317180
    },
    {
      "epoch": 509.97,
      "learning_rate": 0.049024649046141476,
      "loss": 2.689,
      "step": 317200
    },
    {
      "epoch": 510.0,
      "learning_rate": 0.04902143361527332,
      "loss": 2.7044,
      "step": 317220
    },
    {
      "epoch": 510.0,
      "eval_accuracy": {
        "accuracy": 0.4137448495685299
      },
      "eval_loss": 2.775688409805298,
      "eval_runtime": 3.0463,
      "eval_samples_per_second": 4222.523,
      "eval_steps_per_second": 65.982,
      "step": 317220
    },
    {
      "epoch": 510.03,
      "learning_rate": 0.04901821818440515,
      "loss": 2.6864,
      "step": 317240
    },
    {
      "epoch": 510.06,
      "learning_rate": 0.049015002753536985,
      "loss": 2.6603,
      "step": 317260
    },
    {
      "epoch": 510.1,
      "learning_rate": 0.04901178732266881,
      "loss": 2.6698,
      "step": 317280
    },
    {
      "epoch": 510.13,
      "learning_rate": 0.04900857189180064,
      "loss": 2.6799,
      "step": 317300
    },
    {
      "epoch": 510.16,
      "learning_rate": 0.04900535646093249,
      "loss": 2.6587,
      "step": 317320
    },
    {
      "epoch": 510.19,
      "learning_rate": 0.04900214103006432,
      "loss": 2.7074,
      "step": 317340
    },
    {
      "epoch": 510.23,
      "learning_rate": 0.04899892559919615,
      "loss": 2.6991,
      "step": 317360
    },
    {
      "epoch": 510.26,
      "learning_rate": 0.048995710168327974,
      "loss": 2.6601,
      "step": 317380
    },
    {
      "epoch": 510.29,
      "learning_rate": 0.048992494737459806,
      "loss": 2.6502,
      "step": 317400
    },
    {
      "epoch": 510.32,
      "learning_rate": 0.04898927930659164,
      "loss": 2.6708,
      "step": 317420
    },
    {
      "epoch": 510.35,
      "learning_rate": 0.04898606387572348,
      "loss": 2.6773,
      "step": 317440
    },
    {
      "epoch": 510.39,
      "learning_rate": 0.048982848444855315,
      "loss": 2.6688,
      "step": 317460
    },
    {
      "epoch": 510.42,
      "learning_rate": 0.048979633013987146,
      "loss": 2.6775,
      "step": 317480
    },
    {
      "epoch": 510.45,
      "learning_rate": 0.04897641758311897,
      "loss": 2.6956,
      "step": 317500
    },
    {
      "epoch": 510.48,
      "learning_rate": 0.0489732021522508,
      "loss": 2.685,
      "step": 317520
    },
    {
      "epoch": 510.51,
      "learning_rate": 0.048969986721382634,
      "loss": 2.6744,
      "step": 317540
    },
    {
      "epoch": 510.55,
      "learning_rate": 0.04896677129051448,
      "loss": 2.668,
      "step": 317560
    },
    {
      "epoch": 510.58,
      "learning_rate": 0.04896355585964631,
      "loss": 2.6728,
      "step": 317580
    },
    {
      "epoch": 510.61,
      "learning_rate": 0.048960340428778136,
      "loss": 2.6732,
      "step": 317600
    },
    {
      "epoch": 510.64,
      "learning_rate": 0.04895728576945338,
      "loss": 2.6696,
      "step": 317620
    },
    {
      "epoch": 510.68,
      "learning_rate": 0.04895407033858521,
      "loss": 2.6749,
      "step": 317640
    },
    {
      "epoch": 510.71,
      "learning_rate": 0.04895085490771704,
      "loss": 2.7109,
      "step": 317660
    },
    {
      "epoch": 510.74,
      "learning_rate": 0.048947639476848874,
      "loss": 2.7178,
      "step": 317680
    },
    {
      "epoch": 510.77,
      "learning_rate": 0.04894442404598071,
      "loss": 2.7003,
      "step": 317700
    },
    {
      "epoch": 510.8,
      "learning_rate": 0.048941208615112544,
      "loss": 2.6855,
      "step": 317720
    },
    {
      "epoch": 510.84,
      "learning_rate": 0.048937993184244376,
      "loss": 2.6904,
      "step": 317740
    },
    {
      "epoch": 510.87,
      "learning_rate": 0.04893477775337621,
      "loss": 2.6766,
      "step": 317760
    },
    {
      "epoch": 510.9,
      "learning_rate": 0.04893156232250804,
      "loss": 2.6663,
      "step": 317780
    },
    {
      "epoch": 510.93,
      "learning_rate": 0.04892834689163988,
      "loss": 2.6704,
      "step": 317800
    },
    {
      "epoch": 510.96,
      "learning_rate": 0.04892513146077171,
      "loss": 2.6891,
      "step": 317820
    },
    {
      "epoch": 511.0,
      "learning_rate": 0.04892191602990354,
      "loss": 2.6697,
      "step": 317840
    },
    {
      "epoch": 511.0,
      "eval_accuracy": {
        "accuracy": 0.4155329238902278
      },
      "eval_loss": 2.786026954650879,
      "eval_runtime": 2.9641,
      "eval_samples_per_second": 4339.606,
      "eval_steps_per_second": 67.812,
      "step": 317842
    },
    {
      "epoch": 511.03,
      "learning_rate": 0.04891870059903537,
      "loss": 2.6782,
      "step": 317860
    },
    {
      "epoch": 511.06,
      "learning_rate": 0.048915485168167204,
      "loss": 2.6768,
      "step": 317880
    },
    {
      "epoch": 511.09,
      "learning_rate": 0.048912269737299036,
      "loss": 2.6844,
      "step": 317900
    },
    {
      "epoch": 511.13,
      "learning_rate": 0.048909054306430874,
      "loss": 2.6905,
      "step": 317920
    },
    {
      "epoch": 511.16,
      "learning_rate": 0.048905838875562706,
      "loss": 2.6815,
      "step": 317940
    },
    {
      "epoch": 511.19,
      "learning_rate": 0.04890262344469454,
      "loss": 2.6803,
      "step": 317960
    },
    {
      "epoch": 511.22,
      "learning_rate": 0.04889940801382637,
      "loss": 2.6714,
      "step": 317980
    },
    {
      "epoch": 511.25,
      "learning_rate": 0.0488961925829582,
      "loss": 2.6355,
      "step": 318000
    },
    {
      "epoch": 511.29,
      "learning_rate": 0.04889297715209003,
      "loss": 2.6762,
      "step": 318020
    },
    {
      "epoch": 511.32,
      "learning_rate": 0.04888976172122187,
      "loss": 2.6982,
      "step": 318040
    },
    {
      "epoch": 511.35,
      "learning_rate": 0.0488865462903537,
      "loss": 2.6878,
      "step": 318060
    },
    {
      "epoch": 511.38,
      "learning_rate": 0.048883330859485534,
      "loss": 2.6982,
      "step": 318080
    },
    {
      "epoch": 511.41,
      "learning_rate": 0.048880115428617366,
      "loss": 2.6881,
      "step": 318100
    },
    {
      "epoch": 511.45,
      "learning_rate": 0.0488768999977492,
      "loss": 2.6687,
      "step": 318120
    },
    {
      "epoch": 511.48,
      "learning_rate": 0.048873684566881036,
      "loss": 2.6654,
      "step": 318140
    },
    {
      "epoch": 511.51,
      "learning_rate": 0.04887046913601287,
      "loss": 2.6781,
      "step": 318160
    },
    {
      "epoch": 511.54,
      "learning_rate": 0.0488672537051447,
      "loss": 2.6926,
      "step": 318180
    },
    {
      "epoch": 511.58,
      "learning_rate": 0.04886403827427653,
      "loss": 2.6948,
      "step": 318200
    },
    {
      "epoch": 511.61,
      "learning_rate": 0.04886082284340836,
      "loss": 2.6818,
      "step": 318220
    },
    {
      "epoch": 511.64,
      "learning_rate": 0.048857607412540194,
      "loss": 2.7196,
      "step": 318240
    },
    {
      "epoch": 511.67,
      "learning_rate": 0.04885439198167203,
      "loss": 2.6937,
      "step": 318260
    },
    {
      "epoch": 511.7,
      "learning_rate": 0.048851176550803864,
      "loss": 2.6717,
      "step": 318280
    },
    {
      "epoch": 511.74,
      "learning_rate": 0.048847961119935696,
      "loss": 2.6796,
      "step": 318300
    },
    {
      "epoch": 511.77,
      "learning_rate": 0.04884474568906753,
      "loss": 2.6615,
      "step": 318320
    },
    {
      "epoch": 511.8,
      "learning_rate": 0.04884153025819936,
      "loss": 2.6879,
      "step": 318340
    },
    {
      "epoch": 511.83,
      "learning_rate": 0.04883831482733119,
      "loss": 2.7014,
      "step": 318360
    },
    {
      "epoch": 511.86,
      "learning_rate": 0.04883509939646303,
      "loss": 2.7153,
      "step": 318380
    },
    {
      "epoch": 511.9,
      "learning_rate": 0.04883188396559486,
      "loss": 2.6671,
      "step": 318400
    },
    {
      "epoch": 511.93,
      "learning_rate": 0.04882866853472669,
      "loss": 2.6816,
      "step": 318420
    },
    {
      "epoch": 511.96,
      "learning_rate": 0.048825453103858524,
      "loss": 2.6719,
      "step": 318440
    },
    {
      "epoch": 511.99,
      "learning_rate": 0.048822237672990355,
      "loss": 2.6822,
      "step": 318460
    },
    {
      "epoch": 512.0,
      "eval_accuracy": {
        "accuracy": 0.4105574127341989
      },
      "eval_loss": 2.8057823181152344,
      "eval_runtime": 2.8578,
      "eval_samples_per_second": 4500.973,
      "eval_steps_per_second": 70.333,
      "step": 318464
    },
    {
      "epoch": 512.03,
      "learning_rate": 0.048819022242122194,
      "loss": 2.6687,
      "step": 318480
    },
    {
      "epoch": 512.06,
      "learning_rate": 0.048815806811254026,
      "loss": 2.6857,
      "step": 318500
    },
    {
      "epoch": 512.09,
      "learning_rate": 0.04881259138038586,
      "loss": 2.675,
      "step": 318520
    },
    {
      "epoch": 512.12,
      "learning_rate": 0.04880937594951769,
      "loss": 2.681,
      "step": 318540
    },
    {
      "epoch": 512.15,
      "learning_rate": 0.04880616051864952,
      "loss": 2.6748,
      "step": 318560
    },
    {
      "epoch": 512.19,
      "learning_rate": 0.04880294508778135,
      "loss": 2.6802,
      "step": 318580
    },
    {
      "epoch": 512.22,
      "learning_rate": 0.04879972965691319,
      "loss": 2.6771,
      "step": 318600
    },
    {
      "epoch": 512.25,
      "learning_rate": 0.04879651422604502,
      "loss": 2.6791,
      "step": 318620
    },
    {
      "epoch": 512.28,
      "learning_rate": 0.048793298795176854,
      "loss": 2.6587,
      "step": 318640
    },
    {
      "epoch": 512.32,
      "learning_rate": 0.048790083364308685,
      "loss": 2.6846,
      "step": 318660
    },
    {
      "epoch": 512.35,
      "learning_rate": 0.04878686793344052,
      "loss": 2.6658,
      "step": 318680
    },
    {
      "epoch": 512.38,
      "learning_rate": 0.04878365250257235,
      "loss": 2.6633,
      "step": 318700
    },
    {
      "epoch": 512.41,
      "learning_rate": 0.04878043707170419,
      "loss": 2.6854,
      "step": 318720
    },
    {
      "epoch": 512.44,
      "learning_rate": 0.04877722164083602,
      "loss": 2.696,
      "step": 318740
    },
    {
      "epoch": 512.48,
      "learning_rate": 0.04877400620996785,
      "loss": 2.6459,
      "step": 318760
    },
    {
      "epoch": 512.51,
      "learning_rate": 0.04877079077909968,
      "loss": 2.7109,
      "step": 318780
    },
    {
      "epoch": 512.54,
      "learning_rate": 0.048767575348231514,
      "loss": 2.6696,
      "step": 318800
    },
    {
      "epoch": 512.57,
      "learning_rate": 0.04876435991736335,
      "loss": 2.654,
      "step": 318820
    },
    {
      "epoch": 512.6,
      "learning_rate": 0.048761144486495184,
      "loss": 2.6683,
      "step": 318840
    },
    {
      "epoch": 512.64,
      "learning_rate": 0.048757929055627015,
      "loss": 2.6749,
      "step": 318860
    },
    {
      "epoch": 512.67,
      "learning_rate": 0.04875471362475885,
      "loss": 2.6893,
      "step": 318880
    },
    {
      "epoch": 512.7,
      "learning_rate": 0.04875149819389068,
      "loss": 2.6684,
      "step": 318900
    },
    {
      "epoch": 512.73,
      "learning_rate": 0.04874828276302251,
      "loss": 2.67,
      "step": 318920
    },
    {
      "epoch": 512.77,
      "learning_rate": 0.04874506733215435,
      "loss": 2.6732,
      "step": 318940
    },
    {
      "epoch": 512.8,
      "learning_rate": 0.04874185190128618,
      "loss": 2.6894,
      "step": 318960
    },
    {
      "epoch": 512.83,
      "learning_rate": 0.04873863647041801,
      "loss": 2.6621,
      "step": 318980
    },
    {
      "epoch": 512.86,
      "learning_rate": 0.048735421039549844,
      "loss": 2.6989,
      "step": 319000
    },
    {
      "epoch": 512.89,
      "learning_rate": 0.048732205608681675,
      "loss": 2.6834,
      "step": 319020
    },
    {
      "epoch": 512.93,
      "learning_rate": 0.048728990177813514,
      "loss": 2.6927,
      "step": 319040
    },
    {
      "epoch": 512.96,
      "learning_rate": 0.048725774746945345,
      "loss": 2.6622,
      "step": 319060
    },
    {
      "epoch": 512.99,
      "learning_rate": 0.04872255931607718,
      "loss": 2.6614,
      "step": 319080
    },
    {
      "epoch": 513.0,
      "eval_accuracy": {
        "accuracy": 0.40480447796004043
      },
      "eval_loss": 2.8304898738861084,
      "eval_runtime": 2.8812,
      "eval_samples_per_second": 4464.442,
      "eval_steps_per_second": 69.762,
      "step": 319086
    },
    {
      "epoch": 513.02,
      "learning_rate": 0.04871934388520901,
      "loss": 2.6907,
      "step": 319100
    },
    {
      "epoch": 513.05,
      "learning_rate": 0.04871612845434084,
      "loss": 2.6423,
      "step": 319120
    },
    {
      "epoch": 513.09,
      "learning_rate": 0.04871291302347267,
      "loss": 2.7131,
      "step": 319140
    },
    {
      "epoch": 513.12,
      "learning_rate": 0.04870969759260451,
      "loss": 2.6886,
      "step": 319160
    },
    {
      "epoch": 513.15,
      "learning_rate": 0.04870648216173634,
      "loss": 2.6585,
      "step": 319180
    },
    {
      "epoch": 513.18,
      "learning_rate": 0.048703266730868174,
      "loss": 2.6792,
      "step": 319200
    },
    {
      "epoch": 513.22,
      "learning_rate": 0.048700051300000005,
      "loss": 2.6907,
      "step": 319220
    },
    {
      "epoch": 513.25,
      "learning_rate": 0.04869683586913184,
      "loss": 2.6824,
      "step": 319240
    },
    {
      "epoch": 513.28,
      "learning_rate": 0.04869362043826366,
      "loss": 2.6853,
      "step": 319260
    },
    {
      "epoch": 513.31,
      "learning_rate": 0.04869040500739551,
      "loss": 2.6734,
      "step": 319280
    },
    {
      "epoch": 513.34,
      "learning_rate": 0.04868718957652734,
      "loss": 2.6717,
      "step": 319300
    },
    {
      "epoch": 513.38,
      "learning_rate": 0.04868397414565917,
      "loss": 2.6785,
      "step": 319320
    },
    {
      "epoch": 513.41,
      "learning_rate": 0.048680758714791,
      "loss": 2.7176,
      "step": 319340
    },
    {
      "epoch": 513.44,
      "learning_rate": 0.04867754328392283,
      "loss": 2.7134,
      "step": 319360
    },
    {
      "epoch": 513.47,
      "learning_rate": 0.04867432785305467,
      "loss": 2.6853,
      "step": 319380
    },
    {
      "epoch": 513.5,
      "learning_rate": 0.048671112422186504,
      "loss": 2.6544,
      "step": 319400
    },
    {
      "epoch": 513.54,
      "learning_rate": 0.048667896991318335,
      "loss": 2.6804,
      "step": 319420
    },
    {
      "epoch": 513.57,
      "learning_rate": 0.04866468156045017,
      "loss": 2.6824,
      "step": 319440
    },
    {
      "epoch": 513.6,
      "learning_rate": 0.048661466129582,
      "loss": 2.6769,
      "step": 319460
    },
    {
      "epoch": 513.63,
      "learning_rate": 0.04865825069871382,
      "loss": 2.6813,
      "step": 319480
    },
    {
      "epoch": 513.67,
      "learning_rate": 0.04865503526784567,
      "loss": 2.6866,
      "step": 319500
    },
    {
      "epoch": 513.7,
      "learning_rate": 0.0486518198369775,
      "loss": 2.6708,
      "step": 319520
    },
    {
      "epoch": 513.73,
      "learning_rate": 0.04864860440610933,
      "loss": 2.6797,
      "step": 319540
    },
    {
      "epoch": 513.76,
      "learning_rate": 0.04864538897524116,
      "loss": 2.6917,
      "step": 319560
    },
    {
      "epoch": 513.79,
      "learning_rate": 0.04864217354437299,
      "loss": 2.6955,
      "step": 319580
    },
    {
      "epoch": 513.83,
      "learning_rate": 0.04863895811350482,
      "loss": 2.6701,
      "step": 319600
    },
    {
      "epoch": 513.86,
      "learning_rate": 0.048635742682636665,
      "loss": 2.6843,
      "step": 319620
    },
    {
      "epoch": 513.89,
      "learning_rate": 0.0486325272517685,
      "loss": 2.677,
      "step": 319640
    },
    {
      "epoch": 513.92,
      "learning_rate": 0.04862931182090033,
      "loss": 2.6615,
      "step": 319660
    },
    {
      "epoch": 513.95,
      "learning_rate": 0.04862609639003216,
      "loss": 2.671,
      "step": 319680
    },
    {
      "epoch": 513.99,
      "learning_rate": 0.048622880959163985,
      "loss": 2.6733,
      "step": 319700
    },
    {
      "epoch": 514.0,
      "eval_accuracy": {
        "accuracy": 0.40736997589986784
      },
      "eval_loss": 2.809908390045166,
      "eval_runtime": 2.9039,
      "eval_samples_per_second": 4429.554,
      "eval_steps_per_second": 69.217,
      "step": 319708
    },
    {
      "epoch": 514.02,
      "learning_rate": 0.04861966552829583,
      "loss": 2.6776,
      "step": 319720
    },
    {
      "epoch": 514.05,
      "learning_rate": 0.04861645009742766,
      "loss": 2.6685,
      "step": 319740
    },
    {
      "epoch": 514.08,
      "learning_rate": 0.04861323466655949,
      "loss": 2.6774,
      "step": 319760
    },
    {
      "epoch": 514.12,
      "learning_rate": 0.048610019235691325,
      "loss": 2.6834,
      "step": 319780
    },
    {
      "epoch": 514.15,
      "learning_rate": 0.04860680380482315,
      "loss": 2.6485,
      "step": 319800
    },
    {
      "epoch": 514.18,
      "learning_rate": 0.04860358837395498,
      "loss": 2.6676,
      "step": 319820
    },
    {
      "epoch": 514.21,
      "learning_rate": 0.04860037294308683,
      "loss": 2.6764,
      "step": 319840
    },
    {
      "epoch": 514.24,
      "learning_rate": 0.04859715751221866,
      "loss": 2.7023,
      "step": 319860
    },
    {
      "epoch": 514.28,
      "learning_rate": 0.04859394208135049,
      "loss": 2.6971,
      "step": 319880
    },
    {
      "epoch": 514.31,
      "learning_rate": 0.048590726650482315,
      "loss": 2.6936,
      "step": 319900
    },
    {
      "epoch": 514.34,
      "learning_rate": 0.048587511219614146,
      "loss": 2.6743,
      "step": 319920
    },
    {
      "epoch": 514.37,
      "learning_rate": 0.04858429578874598,
      "loss": 2.6862,
      "step": 319940
    },
    {
      "epoch": 514.41,
      "learning_rate": 0.04858108035787782,
      "loss": 2.6721,
      "step": 319960
    },
    {
      "epoch": 514.44,
      "learning_rate": 0.048577864927009655,
      "loss": 2.6777,
      "step": 319980
    },
    {
      "epoch": 514.47,
      "learning_rate": 0.048574649496141487,
      "loss": 2.6765,
      "step": 320000
    },
    {
      "epoch": 514.5,
      "learning_rate": 0.04857143406527331,
      "loss": 2.6543,
      "step": 320020
    },
    {
      "epoch": 514.53,
      "learning_rate": 0.04856821863440514,
      "loss": 2.6746,
      "step": 320040
    },
    {
      "epoch": 514.57,
      "learning_rate": 0.04856500320353699,
      "loss": 2.6713,
      "step": 320060
    },
    {
      "epoch": 514.6,
      "learning_rate": 0.04856178777266882,
      "loss": 2.6568,
      "step": 320080
    },
    {
      "epoch": 514.63,
      "learning_rate": 0.04855857234180065,
      "loss": 2.6489,
      "step": 320100
    },
    {
      "epoch": 514.66,
      "learning_rate": 0.048555356910932476,
      "loss": 2.6661,
      "step": 320120
    },
    {
      "epoch": 514.69,
      "learning_rate": 0.04855214148006431,
      "loss": 2.6759,
      "step": 320140
    },
    {
      "epoch": 514.73,
      "learning_rate": 0.04854892604919614,
      "loss": 2.6929,
      "step": 320160
    },
    {
      "epoch": 514.76,
      "learning_rate": 0.048545710618327985,
      "loss": 2.6723,
      "step": 320180
    },
    {
      "epoch": 514.79,
      "learning_rate": 0.048542495187459817,
      "loss": 2.6794,
      "step": 320200
    },
    {
      "epoch": 514.82,
      "learning_rate": 0.04853927975659164,
      "loss": 2.6729,
      "step": 320220
    },
    {
      "epoch": 514.86,
      "learning_rate": 0.04853606432572347,
      "loss": 2.677,
      "step": 320240
    },
    {
      "epoch": 514.89,
      "learning_rate": 0.048532848894855304,
      "loss": 2.7045,
      "step": 320260
    },
    {
      "epoch": 514.92,
      "learning_rate": 0.048529633463987136,
      "loss": 2.6765,
      "step": 320280
    },
    {
      "epoch": 514.95,
      "learning_rate": 0.04852641803311898,
      "loss": 2.6702,
      "step": 320300
    },
    {
      "epoch": 514.98,
      "learning_rate": 0.04852320260225081,
      "loss": 2.6707,
      "step": 320320
    },
    {
      "epoch": 515.0,
      "eval_accuracy": {
        "accuracy": 0.41032418564876
      },
      "eval_loss": 2.7880308628082275,
      "eval_runtime": 3.1651,
      "eval_samples_per_second": 4064.03,
      "eval_steps_per_second": 63.505,
      "step": 320330
    },
    {
      "epoch": 515.02,
      "learning_rate": 0.04852014794292605,
      "loss": 2.6783,
      "step": 320340
    },
    {
      "epoch": 515.05,
      "learning_rate": 0.04851693251205788,
      "loss": 2.7146,
      "step": 320360
    },
    {
      "epoch": 515.08,
      "learning_rate": 0.04851371708118971,
      "loss": 2.6879,
      "step": 320380
    },
    {
      "epoch": 515.11,
      "learning_rate": 0.048510501650321544,
      "loss": 2.6788,
      "step": 320400
    },
    {
      "epoch": 515.14,
      "learning_rate": 0.048507286219453376,
      "loss": 2.689,
      "step": 320420
    },
    {
      "epoch": 515.18,
      "learning_rate": 0.048504070788585214,
      "loss": 2.691,
      "step": 320440
    },
    {
      "epoch": 515.21,
      "learning_rate": 0.048500855357717046,
      "loss": 2.6919,
      "step": 320460
    },
    {
      "epoch": 515.24,
      "learning_rate": 0.04849763992684888,
      "loss": 2.6559,
      "step": 320480
    },
    {
      "epoch": 515.27,
      "learning_rate": 0.04849442449598071,
      "loss": 2.6984,
      "step": 320500
    },
    {
      "epoch": 515.31,
      "learning_rate": 0.04849120906511254,
      "loss": 2.6776,
      "step": 320520
    },
    {
      "epoch": 515.34,
      "learning_rate": 0.04848799363424438,
      "loss": 2.6811,
      "step": 320540
    },
    {
      "epoch": 515.37,
      "learning_rate": 0.04848477820337621,
      "loss": 2.6587,
      "step": 320560
    },
    {
      "epoch": 515.4,
      "learning_rate": 0.04848156277250804,
      "loss": 2.6711,
      "step": 320580
    },
    {
      "epoch": 515.43,
      "learning_rate": 0.048478347341639874,
      "loss": 2.6476,
      "step": 320600
    },
    {
      "epoch": 515.47,
      "learning_rate": 0.048475131910771706,
      "loss": 2.6866,
      "step": 320620
    },
    {
      "epoch": 515.5,
      "learning_rate": 0.04847191647990354,
      "loss": 2.6792,
      "step": 320640
    },
    {
      "epoch": 515.53,
      "learning_rate": 0.048468701049035376,
      "loss": 2.6633,
      "step": 320660
    },
    {
      "epoch": 515.56,
      "learning_rate": 0.04846548561816721,
      "loss": 2.6406,
      "step": 320680
    },
    {
      "epoch": 515.59,
      "learning_rate": 0.04846227018729904,
      "loss": 2.6639,
      "step": 320700
    },
    {
      "epoch": 515.63,
      "learning_rate": 0.04845905475643087,
      "loss": 2.6802,
      "step": 320720
    },
    {
      "epoch": 515.66,
      "learning_rate": 0.0484558393255627,
      "loss": 2.6832,
      "step": 320740
    },
    {
      "epoch": 515.69,
      "learning_rate": 0.048452623894694534,
      "loss": 2.6721,
      "step": 320760
    },
    {
      "epoch": 515.72,
      "learning_rate": 0.04844940846382637,
      "loss": 2.651,
      "step": 320780
    },
    {
      "epoch": 515.76,
      "learning_rate": 0.048446193032958204,
      "loss": 2.6684,
      "step": 320800
    },
    {
      "epoch": 515.79,
      "learning_rate": 0.048442977602090036,
      "loss": 2.664,
      "step": 320820
    },
    {
      "epoch": 515.82,
      "learning_rate": 0.04843976217122187,
      "loss": 2.6706,
      "step": 320840
    },
    {
      "epoch": 515.85,
      "learning_rate": 0.0484365467403537,
      "loss": 2.6491,
      "step": 320860
    },
    {
      "epoch": 515.88,
      "learning_rate": 0.04843333130948554,
      "loss": 2.6842,
      "step": 320880
    },
    {
      "epoch": 515.92,
      "learning_rate": 0.04843011587861737,
      "loss": 2.6825,
      "step": 320900
    },
    {
      "epoch": 515.95,
      "learning_rate": 0.0484269004477492,
      "loss": 2.711,
      "step": 320920
    },
    {
      "epoch": 515.98,
      "learning_rate": 0.04842368501688103,
      "loss": 2.6744,
      "step": 320940
    },
    {
      "epoch": 516.0,
      "eval_accuracy": {
        "accuracy": 0.41320065303583925
      },
      "eval_loss": 2.796858549118042,
      "eval_runtime": 2.9411,
      "eval_samples_per_second": 4373.463,
      "eval_steps_per_second": 68.341,
      "step": 320952
    },
    {
      "epoch": 516.01,
      "learning_rate": 0.048420469586012864,
      "loss": 2.6656,
      "step": 320960
    },
    {
      "epoch": 516.05,
      "learning_rate": 0.048417254155144696,
      "loss": 2.6729,
      "step": 320980
    },
    {
      "epoch": 516.08,
      "learning_rate": 0.048414038724276534,
      "loss": 2.6923,
      "step": 321000
    },
    {
      "epoch": 516.11,
      "learning_rate": 0.048410823293408366,
      "loss": 2.6674,
      "step": 321020
    },
    {
      "epoch": 516.14,
      "learning_rate": 0.0484076078625402,
      "loss": 2.6735,
      "step": 321040
    },
    {
      "epoch": 516.17,
      "learning_rate": 0.04840439243167203,
      "loss": 2.666,
      "step": 321060
    },
    {
      "epoch": 516.21,
      "learning_rate": 0.04840117700080386,
      "loss": 2.6919,
      "step": 321080
    },
    {
      "epoch": 516.24,
      "learning_rate": 0.04839796156993569,
      "loss": 2.6766,
      "step": 321100
    },
    {
      "epoch": 516.27,
      "learning_rate": 0.04839474613906753,
      "loss": 2.6638,
      "step": 321120
    },
    {
      "epoch": 516.3,
      "learning_rate": 0.04839153070819936,
      "loss": 2.6797,
      "step": 321140
    },
    {
      "epoch": 516.33,
      "learning_rate": 0.048388315277331194,
      "loss": 2.6589,
      "step": 321160
    },
    {
      "epoch": 516.37,
      "learning_rate": 0.048385099846463026,
      "loss": 2.6527,
      "step": 321180
    },
    {
      "epoch": 516.4,
      "learning_rate": 0.04838188441559486,
      "loss": 2.6573,
      "step": 321200
    },
    {
      "epoch": 516.43,
      "learning_rate": 0.048378668984726696,
      "loss": 2.6902,
      "step": 321220
    },
    {
      "epoch": 516.46,
      "learning_rate": 0.04837545355385853,
      "loss": 2.6726,
      "step": 321240
    },
    {
      "epoch": 516.5,
      "learning_rate": 0.04837223812299036,
      "loss": 2.6611,
      "step": 321260
    },
    {
      "epoch": 516.53,
      "learning_rate": 0.04836902269212219,
      "loss": 2.6766,
      "step": 321280
    },
    {
      "epoch": 516.56,
      "learning_rate": 0.04836580726125402,
      "loss": 2.6697,
      "step": 321300
    },
    {
      "epoch": 516.59,
      "learning_rate": 0.048362591830385854,
      "loss": 2.7052,
      "step": 321320
    },
    {
      "epoch": 516.62,
      "learning_rate": 0.04835937639951769,
      "loss": 2.6952,
      "step": 321340
    },
    {
      "epoch": 516.66,
      "learning_rate": 0.048356160968649524,
      "loss": 2.6883,
      "step": 321360
    },
    {
      "epoch": 516.69,
      "learning_rate": 0.048352945537781356,
      "loss": 2.6995,
      "step": 321380
    },
    {
      "epoch": 516.72,
      "learning_rate": 0.04834973010691319,
      "loss": 2.6682,
      "step": 321400
    },
    {
      "epoch": 516.75,
      "learning_rate": 0.04834651467604502,
      "loss": 2.6731,
      "step": 321420
    },
    {
      "epoch": 516.78,
      "learning_rate": 0.04834329924517686,
      "loss": 2.6611,
      "step": 321440
    },
    {
      "epoch": 516.82,
      "learning_rate": 0.04834008381430869,
      "loss": 2.6826,
      "step": 321460
    },
    {
      "epoch": 516.85,
      "learning_rate": 0.04833686838344052,
      "loss": 2.6707,
      "step": 321480
    },
    {
      "epoch": 516.88,
      "learning_rate": 0.04833365295257235,
      "loss": 2.6742,
      "step": 321500
    },
    {
      "epoch": 516.91,
      "learning_rate": 0.048330437521704184,
      "loss": 2.6484,
      "step": 321520
    },
    {
      "epoch": 516.95,
      "learning_rate": 0.048327222090836015,
      "loss": 2.6679,
      "step": 321540
    },
    {
      "epoch": 516.98,
      "learning_rate": 0.048324006659967854,
      "loss": 2.6812,
      "step": 321560
    },
    {
      "epoch": 517.0,
      "eval_accuracy": {
        "accuracy": 0.4090803078597528
      },
      "eval_loss": 2.7996928691864014,
      "eval_runtime": 3.001,
      "eval_samples_per_second": 4286.241,
      "eval_steps_per_second": 66.978,
      "step": 321574
    },
    {
      "epoch": 517.01,
      "learning_rate": 0.048320791229099685,
      "loss": 2.7053,
      "step": 321580
    },
    {
      "epoch": 517.04,
      "learning_rate": 0.04831757579823152,
      "loss": 2.6779,
      "step": 321600
    },
    {
      "epoch": 517.07,
      "learning_rate": 0.04831436036736335,
      "loss": 2.6786,
      "step": 321620
    },
    {
      "epoch": 517.11,
      "learning_rate": 0.04831114493649518,
      "loss": 2.6566,
      "step": 321640
    },
    {
      "epoch": 517.14,
      "learning_rate": 0.04830792950562701,
      "loss": 2.6375,
      "step": 321660
    },
    {
      "epoch": 517.17,
      "learning_rate": 0.04830471407475885,
      "loss": 2.6542,
      "step": 321680
    },
    {
      "epoch": 517.2,
      "learning_rate": 0.04830149864389068,
      "loss": 2.6747,
      "step": 321700
    },
    {
      "epoch": 517.23,
      "learning_rate": 0.048298283213022514,
      "loss": 2.6901,
      "step": 321720
    },
    {
      "epoch": 517.27,
      "learning_rate": 0.048295067782154345,
      "loss": 2.6403,
      "step": 321740
    },
    {
      "epoch": 517.3,
      "learning_rate": 0.04829185235128618,
      "loss": 2.6655,
      "step": 321760
    },
    {
      "epoch": 517.33,
      "learning_rate": 0.048288636920418015,
      "loss": 2.6786,
      "step": 321780
    },
    {
      "epoch": 517.36,
      "learning_rate": 0.04828542148954985,
      "loss": 2.6832,
      "step": 321800
    },
    {
      "epoch": 517.4,
      "learning_rate": 0.04828220605868168,
      "loss": 2.6951,
      "step": 321820
    },
    {
      "epoch": 517.43,
      "learning_rate": 0.04827899062781351,
      "loss": 2.6657,
      "step": 321840
    },
    {
      "epoch": 517.46,
      "learning_rate": 0.04827577519694534,
      "loss": 2.685,
      "step": 321860
    },
    {
      "epoch": 517.49,
      "learning_rate": 0.048272559766077174,
      "loss": 2.6927,
      "step": 321880
    },
    {
      "epoch": 517.52,
      "learning_rate": 0.04826934433520901,
      "loss": 2.6571,
      "step": 321900
    },
    {
      "epoch": 517.56,
      "learning_rate": 0.048266128904340844,
      "loss": 2.6535,
      "step": 321920
    },
    {
      "epoch": 517.59,
      "learning_rate": 0.048262913473472675,
      "loss": 2.6992,
      "step": 321940
    },
    {
      "epoch": 517.62,
      "learning_rate": 0.04825969804260451,
      "loss": 2.6692,
      "step": 321960
    },
    {
      "epoch": 517.65,
      "learning_rate": 0.04825648261173634,
      "loss": 2.6659,
      "step": 321980
    },
    {
      "epoch": 517.68,
      "learning_rate": 0.04825326718086816,
      "loss": 2.6823,
      "step": 322000
    },
    {
      "epoch": 517.72,
      "learning_rate": 0.04825005175000001,
      "loss": 2.6277,
      "step": 322020
    },
    {
      "epoch": 517.75,
      "learning_rate": 0.04824683631913184,
      "loss": 2.6611,
      "step": 322040
    },
    {
      "epoch": 517.78,
      "learning_rate": 0.04824362088826367,
      "loss": 2.6642,
      "step": 322060
    },
    {
      "epoch": 517.81,
      "learning_rate": 0.048240405457395504,
      "loss": 2.6853,
      "step": 322080
    },
    {
      "epoch": 517.85,
      "learning_rate": 0.04823719002652733,
      "loss": 2.6942,
      "step": 322100
    },
    {
      "epoch": 517.88,
      "learning_rate": 0.048233974595659174,
      "loss": 2.6706,
      "step": 322120
    },
    {
      "epoch": 517.91,
      "learning_rate": 0.048230759164791005,
      "loss": 2.6794,
      "step": 322140
    },
    {
      "epoch": 517.94,
      "learning_rate": 0.04822754373392284,
      "loss": 2.6781,
      "step": 322160
    },
    {
      "epoch": 517.97,
      "learning_rate": 0.04822432830305467,
      "loss": 2.6559,
      "step": 322180
    },
    {
      "epoch": 518.0,
      "eval_accuracy": {
        "accuracy": 0.41351162248309103
      },
      "eval_loss": 2.7645153999328613,
      "eval_runtime": 2.8141,
      "eval_samples_per_second": 4570.97,
      "eval_steps_per_second": 71.427,
      "step": 322196
    },
    {
      "epoch": 518.01,
      "learning_rate": 0.0482211128721865,
      "loss": 2.6561,
      "step": 322200
    },
    {
      "epoch": 518.04,
      "learning_rate": 0.048217897441318325,
      "loss": 2.6447,
      "step": 322220
    },
    {
      "epoch": 518.07,
      "learning_rate": 0.04821468201045017,
      "loss": 2.6295,
      "step": 322240
    },
    {
      "epoch": 518.1,
      "learning_rate": 0.048211466579582,
      "loss": 2.6834,
      "step": 322260
    },
    {
      "epoch": 518.14,
      "learning_rate": 0.048208251148713833,
      "loss": 2.6591,
      "step": 322280
    },
    {
      "epoch": 518.17,
      "learning_rate": 0.048205035717845665,
      "loss": 2.6977,
      "step": 322300
    },
    {
      "epoch": 518.2,
      "learning_rate": 0.04820182028697749,
      "loss": 2.6785,
      "step": 322320
    },
    {
      "epoch": 518.23,
      "learning_rate": 0.04819860485610932,
      "loss": 2.6767,
      "step": 322340
    },
    {
      "epoch": 518.26,
      "learning_rate": 0.04819538942524117,
      "loss": 2.6599,
      "step": 322360
    },
    {
      "epoch": 518.3,
      "learning_rate": 0.048192173994373,
      "loss": 2.6645,
      "step": 322380
    },
    {
      "epoch": 518.33,
      "learning_rate": 0.04818895856350483,
      "loss": 2.6837,
      "step": 322400
    },
    {
      "epoch": 518.36,
      "learning_rate": 0.048185743132636655,
      "loss": 2.6887,
      "step": 322420
    },
    {
      "epoch": 518.39,
      "learning_rate": 0.048182527701768486,
      "loss": 2.6349,
      "step": 322440
    },
    {
      "epoch": 518.42,
      "learning_rate": 0.04817931227090033,
      "loss": 2.6646,
      "step": 322460
    },
    {
      "epoch": 518.46,
      "learning_rate": 0.048176096840032163,
      "loss": 2.6748,
      "step": 322480
    },
    {
      "epoch": 518.49,
      "learning_rate": 0.048172881409163995,
      "loss": 2.6817,
      "step": 322500
    },
    {
      "epoch": 518.52,
      "learning_rate": 0.04816966597829583,
      "loss": 2.684,
      "step": 322520
    },
    {
      "epoch": 518.55,
      "learning_rate": 0.04816645054742765,
      "loss": 2.6592,
      "step": 322540
    },
    {
      "epoch": 518.59,
      "learning_rate": 0.04816323511655948,
      "loss": 2.6676,
      "step": 322560
    },
    {
      "epoch": 518.62,
      "learning_rate": 0.04816001968569133,
      "loss": 2.661,
      "step": 322580
    },
    {
      "epoch": 518.65,
      "learning_rate": 0.04815680425482316,
      "loss": 2.698,
      "step": 322600
    },
    {
      "epoch": 518.68,
      "learning_rate": 0.04815358882395499,
      "loss": 2.7017,
      "step": 322620
    },
    {
      "epoch": 518.71,
      "learning_rate": 0.048150373393086816,
      "loss": 2.678,
      "step": 322640
    },
    {
      "epoch": 518.75,
      "learning_rate": 0.04814715796221865,
      "loss": 2.6847,
      "step": 322660
    },
    {
      "epoch": 518.78,
      "learning_rate": 0.04814410330289389,
      "loss": 2.6935,
      "step": 322680
    },
    {
      "epoch": 518.81,
      "learning_rate": 0.04814088787202572,
      "loss": 2.652,
      "step": 322700
    },
    {
      "epoch": 518.84,
      "learning_rate": 0.04813767244115757,
      "loss": 2.6735,
      "step": 322720
    },
    {
      "epoch": 518.87,
      "learning_rate": 0.04813445701028939,
      "loss": 2.6737,
      "step": 322740
    },
    {
      "epoch": 518.91,
      "learning_rate": 0.048131241579421224,
      "loss": 2.6984,
      "step": 322760
    },
    {
      "epoch": 518.94,
      "learning_rate": 0.048128026148553056,
      "loss": 2.6692,
      "step": 322780
    },
    {
      "epoch": 518.97,
      "learning_rate": 0.04812481071768489,
      "loss": 2.6656,
      "step": 322800
    },
    {
      "epoch": 519.0,
      "eval_accuracy": {
        "accuracy": 0.42190779755888985
      },
      "eval_loss": 2.7441232204437256,
      "eval_runtime": 3.2119,
      "eval_samples_per_second": 4004.814,
      "eval_steps_per_second": 62.58,
      "step": 322818
    },
    {
      "epoch": 519.0,
      "learning_rate": 0.04812159528681672,
      "loss": 2.6575,
      "step": 322820
    },
    {
      "epoch": 519.04,
      "learning_rate": 0.04811837985594856,
      "loss": 2.6733,
      "step": 322840
    },
    {
      "epoch": 519.07,
      "learning_rate": 0.04811516442508039,
      "loss": 2.6769,
      "step": 322860
    },
    {
      "epoch": 519.1,
      "learning_rate": 0.04811194899421222,
      "loss": 2.6777,
      "step": 322880
    },
    {
      "epoch": 519.13,
      "learning_rate": 0.04810873356334405,
      "loss": 2.6776,
      "step": 322900
    },
    {
      "epoch": 519.16,
      "learning_rate": 0.048105518132475884,
      "loss": 2.6881,
      "step": 322920
    },
    {
      "epoch": 519.2,
      "learning_rate": 0.04810230270160773,
      "loss": 2.6574,
      "step": 322940
    },
    {
      "epoch": 519.23,
      "learning_rate": 0.048099087270739554,
      "loss": 2.691,
      "step": 322960
    },
    {
      "epoch": 519.26,
      "learning_rate": 0.048095871839871386,
      "loss": 2.6657,
      "step": 322980
    },
    {
      "epoch": 519.29,
      "learning_rate": 0.04809265640900322,
      "loss": 2.6882,
      "step": 323000
    },
    {
      "epoch": 519.32,
      "learning_rate": 0.04808944097813505,
      "loss": 2.6856,
      "step": 323020
    },
    {
      "epoch": 519.36,
      "learning_rate": 0.04808622554726688,
      "loss": 2.6569,
      "step": 323040
    },
    {
      "epoch": 519.39,
      "learning_rate": 0.04808301011639872,
      "loss": 2.6656,
      "step": 323060
    },
    {
      "epoch": 519.42,
      "learning_rate": 0.04807979468553055,
      "loss": 2.6846,
      "step": 323080
    },
    {
      "epoch": 519.45,
      "learning_rate": 0.04807657925466238,
      "loss": 2.6833,
      "step": 323100
    },
    {
      "epoch": 519.49,
      "learning_rate": 0.048073363823794214,
      "loss": 2.6588,
      "step": 323120
    },
    {
      "epoch": 519.52,
      "learning_rate": 0.048070148392926046,
      "loss": 2.6641,
      "step": 323140
    },
    {
      "epoch": 519.55,
      "learning_rate": 0.04806693296205788,
      "loss": 2.6637,
      "step": 323160
    },
    {
      "epoch": 519.58,
      "learning_rate": 0.048063717531189716,
      "loss": 2.6811,
      "step": 323180
    },
    {
      "epoch": 519.61,
      "learning_rate": 0.04806050210032155,
      "loss": 2.6784,
      "step": 323200
    },
    {
      "epoch": 519.65,
      "learning_rate": 0.04805728666945338,
      "loss": 2.6915,
      "step": 323220
    },
    {
      "epoch": 519.68,
      "learning_rate": 0.04805407123858521,
      "loss": 2.6843,
      "step": 323240
    },
    {
      "epoch": 519.71,
      "learning_rate": 0.04805085580771704,
      "loss": 2.6469,
      "step": 323260
    },
    {
      "epoch": 519.74,
      "learning_rate": 0.04804764037684888,
      "loss": 2.6929,
      "step": 323280
    },
    {
      "epoch": 519.77,
      "learning_rate": 0.04804442494598071,
      "loss": 2.6977,
      "step": 323300
    },
    {
      "epoch": 519.81,
      "learning_rate": 0.048041209515112544,
      "loss": 2.6872,
      "step": 323320
    },
    {
      "epoch": 519.84,
      "learning_rate": 0.048037994084244376,
      "loss": 2.6756,
      "step": 323340
    },
    {
      "epoch": 519.87,
      "learning_rate": 0.04803477865337621,
      "loss": 2.6835,
      "step": 323360
    },
    {
      "epoch": 519.9,
      "learning_rate": 0.04803156322250804,
      "loss": 2.673,
      "step": 323380
    },
    {
      "epoch": 519.94,
      "learning_rate": 0.04802834779163988,
      "loss": 2.6736,
      "step": 323400
    },
    {
      "epoch": 519.97,
      "learning_rate": 0.04802513236077171,
      "loss": 2.6772,
      "step": 323420
    },
    {
      "epoch": 520.0,
      "learning_rate": 0.04802191692990354,
      "loss": 2.6825,
      "step": 323440
    },
    {
      "epoch": 520.0,
      "eval_accuracy": {
        "accuracy": 0.41677680167923503
      },
      "eval_loss": 2.7631354331970215,
      "eval_runtime": 2.844,
      "eval_samples_per_second": 4522.845,
      "eval_steps_per_second": 70.675,
      "step": 323440
    },
    {
      "epoch": 520.03,
      "learning_rate": 0.04801870149903537,
      "loss": 2.6883,
      "step": 323460
    },
    {
      "epoch": 520.06,
      "learning_rate": 0.048015486068167204,
      "loss": 2.6761,
      "step": 323480
    },
    {
      "epoch": 520.1,
      "learning_rate": 0.048012270637299036,
      "loss": 2.6622,
      "step": 323500
    },
    {
      "epoch": 520.13,
      "learning_rate": 0.048009055206430874,
      "loss": 2.6617,
      "step": 323520
    },
    {
      "epoch": 520.16,
      "learning_rate": 0.048005839775562706,
      "loss": 2.6642,
      "step": 323540
    },
    {
      "epoch": 520.19,
      "learning_rate": 0.04800262434469454,
      "loss": 2.6869,
      "step": 323560
    },
    {
      "epoch": 520.23,
      "learning_rate": 0.04799940891382637,
      "loss": 2.642,
      "step": 323580
    },
    {
      "epoch": 520.26,
      "learning_rate": 0.0479961934829582,
      "loss": 2.6665,
      "step": 323600
    },
    {
      "epoch": 520.29,
      "learning_rate": 0.04799297805209004,
      "loss": 2.6822,
      "step": 323620
    },
    {
      "epoch": 520.32,
      "learning_rate": 0.04798976262122187,
      "loss": 2.6777,
      "step": 323640
    },
    {
      "epoch": 520.35,
      "learning_rate": 0.0479865471903537,
      "loss": 2.653,
      "step": 323660
    },
    {
      "epoch": 520.39,
      "learning_rate": 0.047983331759485534,
      "loss": 2.6422,
      "step": 323680
    },
    {
      "epoch": 520.42,
      "learning_rate": 0.047980116328617366,
      "loss": 2.6504,
      "step": 323700
    },
    {
      "epoch": 520.45,
      "learning_rate": 0.0479769008977492,
      "loss": 2.682,
      "step": 323720
    },
    {
      "epoch": 520.48,
      "learning_rate": 0.047973685466881036,
      "loss": 2.6763,
      "step": 323740
    },
    {
      "epoch": 520.51,
      "learning_rate": 0.04797047003601287,
      "loss": 2.6754,
      "step": 323760
    },
    {
      "epoch": 520.55,
      "learning_rate": 0.0479672546051447,
      "loss": 2.6426,
      "step": 323780
    },
    {
      "epoch": 520.58,
      "learning_rate": 0.04796403917427653,
      "loss": 2.6575,
      "step": 323800
    },
    {
      "epoch": 520.61,
      "learning_rate": 0.04796082374340836,
      "loss": 2.6716,
      "step": 323820
    },
    {
      "epoch": 520.64,
      "learning_rate": 0.047957608312540194,
      "loss": 2.6525,
      "step": 323840
    },
    {
      "epoch": 520.68,
      "learning_rate": 0.04795439288167203,
      "loss": 2.6804,
      "step": 323860
    },
    {
      "epoch": 520.71,
      "learning_rate": 0.047951177450803864,
      "loss": 2.6868,
      "step": 323880
    },
    {
      "epoch": 520.74,
      "learning_rate": 0.047947962019935696,
      "loss": 2.6882,
      "step": 323900
    },
    {
      "epoch": 520.77,
      "learning_rate": 0.04794474658906753,
      "loss": 2.6744,
      "step": 323920
    },
    {
      "epoch": 520.8,
      "learning_rate": 0.04794153115819936,
      "loss": 2.6858,
      "step": 323940
    },
    {
      "epoch": 520.84,
      "learning_rate": 0.0479383157273312,
      "loss": 2.6895,
      "step": 323960
    },
    {
      "epoch": 520.87,
      "learning_rate": 0.04793510029646303,
      "loss": 2.6464,
      "step": 323980
    },
    {
      "epoch": 520.9,
      "learning_rate": 0.04793188486559486,
      "loss": 2.6678,
      "step": 324000
    },
    {
      "epoch": 520.93,
      "learning_rate": 0.04792866943472669,
      "loss": 2.7092,
      "step": 324020
    },
    {
      "epoch": 520.96,
      "learning_rate": 0.047925454003858524,
      "loss": 2.6925,
      "step": 324040
    },
    {
      "epoch": 521.0,
      "learning_rate": 0.047922238572990355,
      "loss": 2.6624,
      "step": 324060
    },
    {
      "epoch": 521.0,
      "eval_accuracy": {
        "accuracy": 0.41794293710642927
      },
      "eval_loss": 2.7711052894592285,
      "eval_runtime": 2.9774,
      "eval_samples_per_second": 4320.197,
      "eval_steps_per_second": 67.508,
      "step": 324062
    },
    {
      "epoch": 521.03,
      "learning_rate": 0.047919023142122194,
      "loss": 2.664,
      "step": 324080
    },
    {
      "epoch": 521.06,
      "learning_rate": 0.047915807711254026,
      "loss": 2.6666,
      "step": 324100
    },
    {
      "epoch": 521.09,
      "learning_rate": 0.04791259228038586,
      "loss": 2.6471,
      "step": 324120
    },
    {
      "epoch": 521.13,
      "learning_rate": 0.04790937684951769,
      "loss": 2.6755,
      "step": 324140
    },
    {
      "epoch": 521.16,
      "learning_rate": 0.04790616141864952,
      "loss": 2.6686,
      "step": 324160
    },
    {
      "epoch": 521.19,
      "learning_rate": 0.04790294598778136,
      "loss": 2.6534,
      "step": 324180
    },
    {
      "epoch": 521.22,
      "learning_rate": 0.04789973055691319,
      "loss": 2.661,
      "step": 324200
    },
    {
      "epoch": 521.25,
      "learning_rate": 0.04789651512604502,
      "loss": 2.6839,
      "step": 324220
    },
    {
      "epoch": 521.29,
      "learning_rate": 0.047893299695176854,
      "loss": 2.6556,
      "step": 324240
    },
    {
      "epoch": 521.32,
      "learning_rate": 0.047890084264308685,
      "loss": 2.6875,
      "step": 324260
    },
    {
      "epoch": 521.35,
      "learning_rate": 0.04788686883344052,
      "loss": 2.6758,
      "step": 324280
    },
    {
      "epoch": 521.38,
      "learning_rate": 0.047883653402572356,
      "loss": 2.6772,
      "step": 324300
    },
    {
      "epoch": 521.41,
      "learning_rate": 0.04788043797170419,
      "loss": 2.6533,
      "step": 324320
    },
    {
      "epoch": 521.45,
      "learning_rate": 0.04787722254083602,
      "loss": 2.6818,
      "step": 324340
    },
    {
      "epoch": 521.48,
      "learning_rate": 0.04787400710996785,
      "loss": 2.6909,
      "step": 324360
    },
    {
      "epoch": 521.51,
      "learning_rate": 0.04787079167909968,
      "loss": 2.6554,
      "step": 324380
    },
    {
      "epoch": 521.54,
      "learning_rate": 0.047867576248231514,
      "loss": 2.6861,
      "step": 324400
    },
    {
      "epoch": 521.58,
      "learning_rate": 0.04786436081736335,
      "loss": 2.6779,
      "step": 324420
    },
    {
      "epoch": 521.61,
      "learning_rate": 0.047861145386495184,
      "loss": 2.6556,
      "step": 324440
    },
    {
      "epoch": 521.64,
      "learning_rate": 0.047857929955627015,
      "loss": 2.6381,
      "step": 324460
    },
    {
      "epoch": 521.67,
      "learning_rate": 0.04785471452475885,
      "loss": 2.6674,
      "step": 324480
    },
    {
      "epoch": 521.7,
      "learning_rate": 0.04785149909389068,
      "loss": 2.6717,
      "step": 324500
    },
    {
      "epoch": 521.74,
      "learning_rate": 0.04784828366302252,
      "loss": 2.6364,
      "step": 324520
    },
    {
      "epoch": 521.77,
      "learning_rate": 0.04784506823215435,
      "loss": 2.6999,
      "step": 324540
    },
    {
      "epoch": 521.8,
      "learning_rate": 0.04784185280128618,
      "loss": 2.7076,
      "step": 324560
    },
    {
      "epoch": 521.83,
      "learning_rate": 0.04783863737041801,
      "loss": 2.6938,
      "step": 324580
    },
    {
      "epoch": 521.86,
      "learning_rate": 0.047835421939549844,
      "loss": 2.6776,
      "step": 324600
    },
    {
      "epoch": 521.9,
      "learning_rate": 0.04783220650868167,
      "loss": 2.7,
      "step": 324620
    },
    {
      "epoch": 521.93,
      "learning_rate": 0.047828991077813514,
      "loss": 2.6672,
      "step": 324640
    },
    {
      "epoch": 521.96,
      "learning_rate": 0.047825775646945345,
      "loss": 2.6944,
      "step": 324660
    },
    {
      "epoch": 521.99,
      "learning_rate": 0.04782256021607718,
      "loss": 2.6898,
      "step": 324680
    },
    {
      "epoch": 522.0,
      "eval_accuracy": {
        "accuracy": 0.40806965715618443
      },
      "eval_loss": 2.8038997650146484,
      "eval_runtime": 2.9977,
      "eval_samples_per_second": 4290.936,
      "eval_steps_per_second": 67.051,
      "step": 324684
    },
    {
      "epoch": 522.03,
      "learning_rate": 0.04781934478520901,
      "loss": 2.6809,
      "step": 324700
    },
    {
      "epoch": 522.06,
      "learning_rate": 0.04781612935434084,
      "loss": 2.6879,
      "step": 324720
    },
    {
      "epoch": 522.09,
      "learning_rate": 0.047812913923472665,
      "loss": 2.679,
      "step": 324740
    },
    {
      "epoch": 522.12,
      "learning_rate": 0.04780969849260451,
      "loss": 2.6679,
      "step": 324760
    },
    {
      "epoch": 522.15,
      "learning_rate": 0.04780648306173634,
      "loss": 2.6772,
      "step": 324780
    },
    {
      "epoch": 522.19,
      "learning_rate": 0.047803267630868174,
      "loss": 2.677,
      "step": 324800
    },
    {
      "epoch": 522.22,
      "learning_rate": 0.047800052200000005,
      "loss": 2.6537,
      "step": 324820
    },
    {
      "epoch": 522.25,
      "learning_rate": 0.04779683676913183,
      "loss": 2.6322,
      "step": 324840
    },
    {
      "epoch": 522.28,
      "learning_rate": 0.047793621338263675,
      "loss": 2.6628,
      "step": 324860
    },
    {
      "epoch": 522.32,
      "learning_rate": 0.04779040590739551,
      "loss": 2.6614,
      "step": 324880
    },
    {
      "epoch": 522.35,
      "learning_rate": 0.04778719047652734,
      "loss": 2.7082,
      "step": 324900
    },
    {
      "epoch": 522.38,
      "learning_rate": 0.04778397504565917,
      "loss": 2.6832,
      "step": 324920
    },
    {
      "epoch": 522.41,
      "learning_rate": 0.047780759614790995,
      "loss": 2.6644,
      "step": 324940
    },
    {
      "epoch": 522.44,
      "learning_rate": 0.04777754418392283,
      "loss": 2.656,
      "step": 324960
    },
    {
      "epoch": 522.48,
      "learning_rate": 0.04777432875305467,
      "loss": 2.6704,
      "step": 324980
    },
    {
      "epoch": 522.51,
      "learning_rate": 0.047771113322186504,
      "loss": 2.6603,
      "step": 325000
    },
    {
      "epoch": 522.54,
      "learning_rate": 0.047767897891318335,
      "loss": 2.6849,
      "step": 325020
    },
    {
      "epoch": 522.57,
      "learning_rate": 0.04776468246045017,
      "loss": 2.6821,
      "step": 325040
    },
    {
      "epoch": 522.6,
      "learning_rate": 0.04776146702958199,
      "loss": 2.6515,
      "step": 325060
    },
    {
      "epoch": 522.64,
      "learning_rate": 0.04775825159871382,
      "loss": 2.6685,
      "step": 325080
    },
    {
      "epoch": 522.67,
      "learning_rate": 0.04775503616784567,
      "loss": 2.6467,
      "step": 325100
    },
    {
      "epoch": 522.7,
      "learning_rate": 0.0477518207369775,
      "loss": 2.6651,
      "step": 325120
    },
    {
      "epoch": 522.73,
      "learning_rate": 0.04774860530610933,
      "loss": 2.6784,
      "step": 325140
    },
    {
      "epoch": 522.77,
      "learning_rate": 0.047745389875241157,
      "loss": 2.672,
      "step": 325160
    },
    {
      "epoch": 522.8,
      "learning_rate": 0.04774217444437299,
      "loss": 2.6574,
      "step": 325180
    },
    {
      "epoch": 522.83,
      "learning_rate": 0.047738959013504834,
      "loss": 2.6779,
      "step": 325200
    },
    {
      "epoch": 522.86,
      "learning_rate": 0.047735743582636665,
      "loss": 2.6818,
      "step": 325220
    },
    {
      "epoch": 522.89,
      "learning_rate": 0.0477325281517685,
      "loss": 2.6673,
      "step": 325240
    },
    {
      "epoch": 522.93,
      "learning_rate": 0.04772931272090032,
      "loss": 2.6338,
      "step": 325260
    },
    {
      "epoch": 522.96,
      "learning_rate": 0.04772609729003215,
      "loss": 2.6526,
      "step": 325280
    },
    {
      "epoch": 522.99,
      "learning_rate": 0.047722881859163985,
      "loss": 2.665,
      "step": 325300
    },
    {
      "epoch": 523.0,
      "eval_accuracy": {
        "accuracy": 0.4133561377594651
      },
      "eval_loss": 2.785789966583252,
      "eval_runtime": 2.8077,
      "eval_samples_per_second": 4581.359,
      "eval_steps_per_second": 71.589,
      "step": 325306
    },
    {
      "epoch": 523.02,
      "learning_rate": 0.04771966642829583,
      "loss": 2.6781,
      "step": 325320
    },
    {
      "epoch": 523.05,
      "learning_rate": 0.04771645099742766,
      "loss": 2.6603,
      "step": 325340
    },
    {
      "epoch": 523.09,
      "learning_rate": 0.04771323556655949,
      "loss": 2.6684,
      "step": 325360
    },
    {
      "epoch": 523.12,
      "learning_rate": 0.04771002013569132,
      "loss": 2.6655,
      "step": 325380
    },
    {
      "epoch": 523.15,
      "learning_rate": 0.04770680470482315,
      "loss": 2.6569,
      "step": 325400
    },
    {
      "epoch": 523.18,
      "learning_rate": 0.04770358927395498,
      "loss": 2.66,
      "step": 325420
    },
    {
      "epoch": 523.22,
      "learning_rate": 0.04770037384308683,
      "loss": 2.6853,
      "step": 325440
    },
    {
      "epoch": 523.25,
      "learning_rate": 0.04769715841221866,
      "loss": 2.6672,
      "step": 325460
    },
    {
      "epoch": 523.28,
      "learning_rate": 0.04769394298135048,
      "loss": 2.6541,
      "step": 325480
    },
    {
      "epoch": 523.31,
      "learning_rate": 0.047690727550482315,
      "loss": 2.6743,
      "step": 325500
    },
    {
      "epoch": 523.34,
      "learning_rate": 0.047687512119614146,
      "loss": 2.6566,
      "step": 325520
    },
    {
      "epoch": 523.38,
      "learning_rate": 0.04768429668874599,
      "loss": 2.6484,
      "step": 325540
    },
    {
      "epoch": 523.41,
      "learning_rate": 0.04768108125787782,
      "loss": 2.6946,
      "step": 325560
    },
    {
      "epoch": 523.44,
      "learning_rate": 0.04767786582700965,
      "loss": 2.6744,
      "step": 325580
    },
    {
      "epoch": 523.47,
      "learning_rate": 0.04767465039614148,
      "loss": 2.6698,
      "step": 325600
    },
    {
      "epoch": 523.5,
      "learning_rate": 0.04767143496527331,
      "loss": 2.6856,
      "step": 325620
    },
    {
      "epoch": 523.54,
      "learning_rate": 0.04766821953440514,
      "loss": 2.6902,
      "step": 325640
    },
    {
      "epoch": 523.57,
      "learning_rate": 0.04766500410353699,
      "loss": 2.6869,
      "step": 325660
    },
    {
      "epoch": 523.6,
      "learning_rate": 0.04766178867266882,
      "loss": 2.6738,
      "step": 325680
    },
    {
      "epoch": 523.63,
      "learning_rate": 0.047658573241800645,
      "loss": 2.6714,
      "step": 325700
    },
    {
      "epoch": 523.67,
      "learning_rate": 0.047655357810932476,
      "loss": 2.692,
      "step": 325720
    },
    {
      "epoch": 523.7,
      "learning_rate": 0.04765214238006431,
      "loss": 2.6698,
      "step": 325740
    },
    {
      "epoch": 523.73,
      "learning_rate": 0.04764892694919614,
      "loss": 2.6593,
      "step": 325760
    },
    {
      "epoch": 523.76,
      "learning_rate": 0.047645711518327985,
      "loss": 2.6862,
      "step": 325780
    },
    {
      "epoch": 523.79,
      "learning_rate": 0.04764249608745981,
      "loss": 2.6613,
      "step": 325800
    },
    {
      "epoch": 523.83,
      "learning_rate": 0.04763928065659164,
      "loss": 2.7013,
      "step": 325820
    },
    {
      "epoch": 523.86,
      "learning_rate": 0.04763606522572347,
      "loss": 2.6737,
      "step": 325840
    },
    {
      "epoch": 523.89,
      "learning_rate": 0.047632849794855305,
      "loss": 2.6436,
      "step": 325860
    },
    {
      "epoch": 523.92,
      "learning_rate": 0.04762963436398715,
      "loss": 2.6689,
      "step": 325880
    },
    {
      "epoch": 523.95,
      "learning_rate": 0.047626418933118975,
      "loss": 2.7029,
      "step": 325900
    },
    {
      "epoch": 523.99,
      "learning_rate": 0.047623203502250806,
      "loss": 2.6528,
      "step": 325920
    },
    {
      "epoch": 524.0,
      "eval_accuracy": {
        "accuracy": 0.41444453082484645
      },
      "eval_loss": 2.7855265140533447,
      "eval_runtime": 3.131,
      "eval_samples_per_second": 4108.312,
      "eval_steps_per_second": 64.197,
      "step": 325928
    },
    {
      "epoch": 524.02,
      "learning_rate": 0.04761998807138264,
      "loss": 2.6681,
      "step": 325940
    },
    {
      "epoch": 524.05,
      "learning_rate": 0.04761677264051447,
      "loss": 2.6576,
      "step": 325960
    },
    {
      "epoch": 524.08,
      "learning_rate": 0.0476135572096463,
      "loss": 2.6739,
      "step": 325980
    },
    {
      "epoch": 524.12,
      "learning_rate": 0.04761034177877815,
      "loss": 2.6535,
      "step": 326000
    },
    {
      "epoch": 524.15,
      "learning_rate": 0.04760712634790997,
      "loss": 2.6555,
      "step": 326020
    },
    {
      "epoch": 524.18,
      "learning_rate": 0.0476039109170418,
      "loss": 2.6322,
      "step": 326040
    },
    {
      "epoch": 524.21,
      "learning_rate": 0.047600695486173634,
      "loss": 2.6771,
      "step": 326060
    },
    {
      "epoch": 524.24,
      "learning_rate": 0.047597480055305466,
      "loss": 2.6634,
      "step": 326080
    },
    {
      "epoch": 524.28,
      "learning_rate": 0.04759426462443731,
      "loss": 2.6614,
      "step": 326100
    },
    {
      "epoch": 524.31,
      "learning_rate": 0.04759120996511254,
      "loss": 2.6878,
      "step": 326120
    },
    {
      "epoch": 524.34,
      "learning_rate": 0.04758799453424438,
      "loss": 2.664,
      "step": 326140
    },
    {
      "epoch": 524.37,
      "learning_rate": 0.04758477910337621,
      "loss": 2.6664,
      "step": 326160
    },
    {
      "epoch": 524.41,
      "learning_rate": 0.04758156367250804,
      "loss": 2.6695,
      "step": 326180
    },
    {
      "epoch": 524.44,
      "learning_rate": 0.047578348241639874,
      "loss": 2.6789,
      "step": 326200
    },
    {
      "epoch": 524.47,
      "learning_rate": 0.047575132810771706,
      "loss": 2.6583,
      "step": 326220
    },
    {
      "epoch": 524.5,
      "learning_rate": 0.04757191737990354,
      "loss": 2.6669,
      "step": 326240
    },
    {
      "epoch": 524.53,
      "learning_rate": 0.047568701949035376,
      "loss": 2.6741,
      "step": 326260
    },
    {
      "epoch": 524.57,
      "learning_rate": 0.04756548651816721,
      "loss": 2.655,
      "step": 326280
    },
    {
      "epoch": 524.6,
      "learning_rate": 0.04756227108729904,
      "loss": 2.6614,
      "step": 326300
    },
    {
      "epoch": 524.63,
      "learning_rate": 0.04755905565643087,
      "loss": 2.686,
      "step": 326320
    },
    {
      "epoch": 524.66,
      "learning_rate": 0.0475558402255627,
      "loss": 2.6715,
      "step": 326340
    },
    {
      "epoch": 524.69,
      "learning_rate": 0.04755262479469454,
      "loss": 2.6738,
      "step": 326360
    },
    {
      "epoch": 524.73,
      "learning_rate": 0.04754940936382637,
      "loss": 2.6974,
      "step": 326380
    },
    {
      "epoch": 524.76,
      "learning_rate": 0.047546193932958204,
      "loss": 2.6895,
      "step": 326400
    },
    {
      "epoch": 524.79,
      "learning_rate": 0.047542978502090036,
      "loss": 2.675,
      "step": 326420
    },
    {
      "epoch": 524.82,
      "learning_rate": 0.04753976307122187,
      "loss": 2.6703,
      "step": 326440
    },
    {
      "epoch": 524.86,
      "learning_rate": 0.0475365476403537,
      "loss": 2.6445,
      "step": 326460
    },
    {
      "epoch": 524.89,
      "learning_rate": 0.04753333220948554,
      "loss": 2.6721,
      "step": 326480
    },
    {
      "epoch": 524.92,
      "learning_rate": 0.04753011677861737,
      "loss": 2.6743,
      "step": 326500
    },
    {
      "epoch": 524.95,
      "learning_rate": 0.0475269013477492,
      "loss": 2.6699,
      "step": 326520
    },
    {
      "epoch": 524.98,
      "learning_rate": 0.04752368591688103,
      "loss": 2.6754,
      "step": 326540
    },
    {
      "epoch": 525.0,
      "eval_accuracy": {
        "accuracy": 0.4140558190157817
      },
      "eval_loss": 2.783614158630371,
      "eval_runtime": 3.2578,
      "eval_samples_per_second": 3948.366,
      "eval_steps_per_second": 61.698,
      "step": 326550
    },
    {
      "epoch": 525.02,
      "learning_rate": 0.047520470486012864,
      "loss": 2.6849,
      "step": 326560
    },
    {
      "epoch": 525.05,
      "learning_rate": 0.0475172550551447,
      "loss": 2.6426,
      "step": 326580
    },
    {
      "epoch": 525.08,
      "learning_rate": 0.047514039624276534,
      "loss": 2.6518,
      "step": 326600
    },
    {
      "epoch": 525.11,
      "learning_rate": 0.047510824193408366,
      "loss": 2.651,
      "step": 326620
    },
    {
      "epoch": 525.14,
      "learning_rate": 0.0475076087625402,
      "loss": 2.6869,
      "step": 326640
    },
    {
      "epoch": 525.18,
      "learning_rate": 0.04750439333167203,
      "loss": 2.6615,
      "step": 326660
    },
    {
      "epoch": 525.21,
      "learning_rate": 0.04750117790080386,
      "loss": 2.6692,
      "step": 326680
    },
    {
      "epoch": 525.24,
      "learning_rate": 0.0474979624699357,
      "loss": 2.6782,
      "step": 326700
    },
    {
      "epoch": 525.27,
      "learning_rate": 0.04749474703906753,
      "loss": 2.6643,
      "step": 326720
    },
    {
      "epoch": 525.31,
      "learning_rate": 0.04749153160819936,
      "loss": 2.6646,
      "step": 326740
    },
    {
      "epoch": 525.34,
      "learning_rate": 0.047488316177331194,
      "loss": 2.6278,
      "step": 326760
    },
    {
      "epoch": 525.37,
      "learning_rate": 0.047485100746463026,
      "loss": 2.6738,
      "step": 326780
    },
    {
      "epoch": 525.4,
      "learning_rate": 0.04748188531559486,
      "loss": 2.6516,
      "step": 326800
    },
    {
      "epoch": 525.43,
      "learning_rate": 0.047478669884726696,
      "loss": 2.6665,
      "step": 326820
    },
    {
      "epoch": 525.47,
      "learning_rate": 0.04747545445385853,
      "loss": 2.6579,
      "step": 326840
    },
    {
      "epoch": 525.5,
      "learning_rate": 0.04747223902299036,
      "loss": 2.6611,
      "step": 326860
    },
    {
      "epoch": 525.53,
      "learning_rate": 0.04746902359212219,
      "loss": 2.689,
      "step": 326880
    },
    {
      "epoch": 525.56,
      "learning_rate": 0.04746580816125402,
      "loss": 2.6871,
      "step": 326900
    },
    {
      "epoch": 525.59,
      "learning_rate": 0.04746259273038586,
      "loss": 2.7022,
      "step": 326920
    },
    {
      "epoch": 525.63,
      "learning_rate": 0.04745937729951769,
      "loss": 2.6891,
      "step": 326940
    },
    {
      "epoch": 525.66,
      "learning_rate": 0.047456161868649524,
      "loss": 2.686,
      "step": 326960
    },
    {
      "epoch": 525.69,
      "learning_rate": 0.047452946437781356,
      "loss": 2.6906,
      "step": 326980
    },
    {
      "epoch": 525.72,
      "learning_rate": 0.04744973100691319,
      "loss": 2.6874,
      "step": 327000
    },
    {
      "epoch": 525.76,
      "learning_rate": 0.04744651557604502,
      "loss": 2.6841,
      "step": 327020
    },
    {
      "epoch": 525.79,
      "learning_rate": 0.04744330014517686,
      "loss": 2.669,
      "step": 327040
    },
    {
      "epoch": 525.82,
      "learning_rate": 0.04744008471430869,
      "loss": 2.6519,
      "step": 327060
    },
    {
      "epoch": 525.85,
      "learning_rate": 0.04743686928344052,
      "loss": 2.6671,
      "step": 327080
    },
    {
      "epoch": 525.88,
      "learning_rate": 0.04743365385257235,
      "loss": 2.6912,
      "step": 327100
    },
    {
      "epoch": 525.92,
      "learning_rate": 0.047430438421704184,
      "loss": 2.6622,
      "step": 327120
    },
    {
      "epoch": 525.95,
      "learning_rate": 0.04742722299083601,
      "loss": 2.6915,
      "step": 327140
    },
    {
      "epoch": 525.98,
      "learning_rate": 0.047424007559967854,
      "loss": 2.6825,
      "step": 327160
    },
    {
      "epoch": 526.0,
      "eval_accuracy": {
        "accuracy": 0.41071289745782474
      },
      "eval_loss": 2.7949957847595215,
      "eval_runtime": 3.2036,
      "eval_samples_per_second": 4015.21,
      "eval_steps_per_second": 62.743,
      "step": 327172
    },
    {
      "epoch": 526.01,
      "learning_rate": 0.047420792129099686,
      "loss": 2.6726,
      "step": 327180
    },
    {
      "epoch": 526.05,
      "learning_rate": 0.04741757669823152,
      "loss": 2.6502,
      "step": 327200
    },
    {
      "epoch": 526.08,
      "learning_rate": 0.04741436126736335,
      "loss": 2.667,
      "step": 327220
    },
    {
      "epoch": 526.11,
      "learning_rate": 0.04741114583649518,
      "loss": 2.6804,
      "step": 327240
    },
    {
      "epoch": 526.14,
      "learning_rate": 0.04740793040562702,
      "loss": 2.6822,
      "step": 327260
    },
    {
      "epoch": 526.17,
      "learning_rate": 0.04740471497475885,
      "loss": 2.6701,
      "step": 327280
    },
    {
      "epoch": 526.21,
      "learning_rate": 0.04740149954389068,
      "loss": 2.6811,
      "step": 327300
    },
    {
      "epoch": 526.24,
      "learning_rate": 0.047398284113022514,
      "loss": 2.6824,
      "step": 327320
    },
    {
      "epoch": 526.27,
      "learning_rate": 0.047395068682154345,
      "loss": 2.6597,
      "step": 327340
    },
    {
      "epoch": 526.3,
      "learning_rate": 0.04739185325128617,
      "loss": 2.6969,
      "step": 327360
    },
    {
      "epoch": 526.33,
      "learning_rate": 0.047388637820418016,
      "loss": 2.6646,
      "step": 327380
    },
    {
      "epoch": 526.37,
      "learning_rate": 0.04738542238954985,
      "loss": 2.6898,
      "step": 327400
    },
    {
      "epoch": 526.4,
      "learning_rate": 0.04738220695868168,
      "loss": 2.6485,
      "step": 327420
    },
    {
      "epoch": 526.43,
      "learning_rate": 0.04737899152781351,
      "loss": 2.6686,
      "step": 327440
    },
    {
      "epoch": 526.46,
      "learning_rate": 0.047375776096945335,
      "loss": 2.6701,
      "step": 327460
    },
    {
      "epoch": 526.5,
      "learning_rate": 0.04737256066607717,
      "loss": 2.6652,
      "step": 327480
    },
    {
      "epoch": 526.53,
      "learning_rate": 0.04736934523520901,
      "loss": 2.6354,
      "step": 327500
    },
    {
      "epoch": 526.56,
      "learning_rate": 0.047366129804340844,
      "loss": 2.6464,
      "step": 327520
    },
    {
      "epoch": 526.59,
      "learning_rate": 0.047362914373472675,
      "loss": 2.6762,
      "step": 327540
    },
    {
      "epoch": 526.62,
      "learning_rate": 0.04735969894260451,
      "loss": 2.6631,
      "step": 327560
    },
    {
      "epoch": 526.66,
      "learning_rate": 0.04735648351173633,
      "loss": 2.652,
      "step": 327580
    },
    {
      "epoch": 526.69,
      "learning_rate": 0.04735326808086818,
      "loss": 2.6858,
      "step": 327600
    },
    {
      "epoch": 526.72,
      "learning_rate": 0.04735005265000001,
      "loss": 2.6581,
      "step": 327620
    },
    {
      "epoch": 526.75,
      "learning_rate": 0.04734683721913184,
      "loss": 2.6544,
      "step": 327640
    },
    {
      "epoch": 526.78,
      "learning_rate": 0.04734362178826367,
      "loss": 2.668,
      "step": 327660
    },
    {
      "epoch": 526.82,
      "learning_rate": 0.0473404063573955,
      "loss": 2.6636,
      "step": 327680
    },
    {
      "epoch": 526.85,
      "learning_rate": 0.04733719092652733,
      "loss": 2.6873,
      "step": 327700
    },
    {
      "epoch": 526.88,
      "learning_rate": 0.047333975495659174,
      "loss": 2.6604,
      "step": 327720
    },
    {
      "epoch": 526.91,
      "learning_rate": 0.047330760064791005,
      "loss": 2.6736,
      "step": 327740
    },
    {
      "epoch": 526.95,
      "learning_rate": 0.04732754463392284,
      "loss": 2.667,
      "step": 327760
    },
    {
      "epoch": 526.98,
      "learning_rate": 0.04732432920305466,
      "loss": 2.6728,
      "step": 327780
    },
    {
      "epoch": 527.0,
      "eval_accuracy": {
        "accuracy": 0.4139003342921558
      },
      "eval_loss": 2.7738959789276123,
      "eval_runtime": 2.8998,
      "eval_samples_per_second": 4435.856,
      "eval_steps_per_second": 69.316,
      "step": 327794
    },
    {
      "epoch": 527.01,
      "learning_rate": 0.04732111377218649,
      "loss": 2.6845,
      "step": 327800
    },
    {
      "epoch": 527.04,
      "learning_rate": 0.047317898341318325,
      "loss": 2.672,
      "step": 327820
    },
    {
      "epoch": 527.07,
      "learning_rate": 0.04731468291045017,
      "loss": 2.6642,
      "step": 327840
    },
    {
      "epoch": 527.11,
      "learning_rate": 0.047311467479582,
      "loss": 2.6898,
      "step": 327860
    },
    {
      "epoch": 527.14,
      "learning_rate": 0.047308252048713834,
      "loss": 2.672,
      "step": 327880
    },
    {
      "epoch": 527.17,
      "learning_rate": 0.04730503661784566,
      "loss": 2.6753,
      "step": 327900
    },
    {
      "epoch": 527.2,
      "learning_rate": 0.04730182118697749,
      "loss": 2.6782,
      "step": 327920
    },
    {
      "epoch": 527.23,
      "learning_rate": 0.047298605756109335,
      "loss": 2.6862,
      "step": 327940
    },
    {
      "epoch": 527.27,
      "learning_rate": 0.04729539032524117,
      "loss": 2.671,
      "step": 327960
    },
    {
      "epoch": 527.3,
      "learning_rate": 0.047292174894373,
      "loss": 2.6619,
      "step": 327980
    },
    {
      "epoch": 527.33,
      "learning_rate": 0.04728895946350482,
      "loss": 2.6743,
      "step": 328000
    },
    {
      "epoch": 527.36,
      "learning_rate": 0.047285744032636655,
      "loss": 2.6705,
      "step": 328020
    },
    {
      "epoch": 527.4,
      "learning_rate": 0.047282528601768486,
      "loss": 2.6736,
      "step": 328040
    },
    {
      "epoch": 527.43,
      "learning_rate": 0.04727931317090033,
      "loss": 2.6685,
      "step": 328060
    },
    {
      "epoch": 527.46,
      "learning_rate": 0.047276097740032164,
      "loss": 2.6722,
      "step": 328080
    },
    {
      "epoch": 527.49,
      "learning_rate": 0.04727288230916399,
      "loss": 2.6514,
      "step": 328100
    },
    {
      "epoch": 527.52,
      "learning_rate": 0.04726966687829582,
      "loss": 2.6866,
      "step": 328120
    },
    {
      "epoch": 527.56,
      "learning_rate": 0.04726645144742765,
      "loss": 2.6755,
      "step": 328140
    },
    {
      "epoch": 527.59,
      "learning_rate": 0.04726323601655948,
      "loss": 2.6859,
      "step": 328160
    },
    {
      "epoch": 527.62,
      "learning_rate": 0.04726002058569133,
      "loss": 2.6603,
      "step": 328180
    },
    {
      "epoch": 527.65,
      "learning_rate": 0.04725680515482316,
      "loss": 2.6681,
      "step": 328200
    },
    {
      "epoch": 527.68,
      "learning_rate": 0.047253589723954985,
      "loss": 2.6713,
      "step": 328220
    },
    {
      "epoch": 527.72,
      "learning_rate": 0.047250374293086816,
      "loss": 2.6555,
      "step": 328240
    },
    {
      "epoch": 527.75,
      "learning_rate": 0.04724715886221865,
      "loss": 2.6684,
      "step": 328260
    },
    {
      "epoch": 527.78,
      "learning_rate": 0.047243943431350494,
      "loss": 2.6866,
      "step": 328280
    },
    {
      "epoch": 527.81,
      "learning_rate": 0.047240728000482325,
      "loss": 2.6511,
      "step": 328300
    },
    {
      "epoch": 527.85,
      "learning_rate": 0.04723751256961415,
      "loss": 2.6486,
      "step": 328320
    },
    {
      "epoch": 527.88,
      "learning_rate": 0.04723429713874598,
      "loss": 2.6577,
      "step": 328340
    },
    {
      "epoch": 527.91,
      "learning_rate": 0.04723108170787781,
      "loss": 2.6664,
      "step": 328360
    },
    {
      "epoch": 527.94,
      "learning_rate": 0.047227866277009645,
      "loss": 2.659,
      "step": 328380
    },
    {
      "epoch": 527.97,
      "learning_rate": 0.04722465084614149,
      "loss": 2.6523,
      "step": 328400
    },
    {
      "epoch": 528.0,
      "eval_accuracy": {
        "accuracy": 0.41840939127730703
      },
      "eval_loss": 2.7657651901245117,
      "eval_runtime": 3.2564,
      "eval_samples_per_second": 3950.127,
      "eval_steps_per_second": 61.726,
      "step": 328416
    },
    {
      "epoch": 528.01,
      "learning_rate": 0.047221435415273315,
      "loss": 2.6681,
      "step": 328420
    },
    {
      "epoch": 528.04,
      "learning_rate": 0.047218219984405146,
      "loss": 2.6425,
      "step": 328440
    },
    {
      "epoch": 528.07,
      "learning_rate": 0.04721500455353698,
      "loss": 2.6759,
      "step": 328460
    },
    {
      "epoch": 528.1,
      "learning_rate": 0.04721178912266881,
      "loss": 2.6686,
      "step": 328480
    },
    {
      "epoch": 528.14,
      "learning_rate": 0.047208573691800655,
      "loss": 2.6514,
      "step": 328500
    },
    {
      "epoch": 528.17,
      "learning_rate": 0.04720535826093249,
      "loss": 2.67,
      "step": 328520
    },
    {
      "epoch": 528.2,
      "learning_rate": 0.04720214283006431,
      "loss": 2.6532,
      "step": 328540
    },
    {
      "epoch": 528.23,
      "learning_rate": 0.04719892739919614,
      "loss": 2.6784,
      "step": 328560
    },
    {
      "epoch": 528.26,
      "learning_rate": 0.047195711968327975,
      "loss": 2.6562,
      "step": 328580
    },
    {
      "epoch": 528.3,
      "learning_rate": 0.047192496537459806,
      "loss": 2.6724,
      "step": 328600
    },
    {
      "epoch": 528.33,
      "learning_rate": 0.04718928110659165,
      "loss": 2.6734,
      "step": 328620
    },
    {
      "epoch": 528.36,
      "learning_rate": 0.047186065675723476,
      "loss": 2.6796,
      "step": 328640
    },
    {
      "epoch": 528.39,
      "learning_rate": 0.04718285024485531,
      "loss": 2.677,
      "step": 328660
    },
    {
      "epoch": 528.42,
      "learning_rate": 0.04717963481398714,
      "loss": 2.6799,
      "step": 328680
    },
    {
      "epoch": 528.46,
      "learning_rate": 0.04717641938311897,
      "loss": 2.6627,
      "step": 328700
    },
    {
      "epoch": 528.49,
      "learning_rate": 0.0471732039522508,
      "loss": 2.669,
      "step": 328720
    },
    {
      "epoch": 528.52,
      "learning_rate": 0.04716998852138265,
      "loss": 2.6524,
      "step": 328740
    },
    {
      "epoch": 528.55,
      "learning_rate": 0.04716677309051447,
      "loss": 2.6567,
      "step": 328760
    },
    {
      "epoch": 528.59,
      "learning_rate": 0.047163557659646305,
      "loss": 2.6597,
      "step": 328780
    },
    {
      "epoch": 528.62,
      "learning_rate": 0.047160342228778136,
      "loss": 2.6542,
      "step": 328800
    },
    {
      "epoch": 528.65,
      "learning_rate": 0.04715712679790997,
      "loss": 2.6532,
      "step": 328820
    },
    {
      "epoch": 528.68,
      "learning_rate": 0.04715391136704181,
      "loss": 2.6624,
      "step": 328840
    },
    {
      "epoch": 528.71,
      "learning_rate": 0.04715069593617364,
      "loss": 2.649,
      "step": 328860
    },
    {
      "epoch": 528.75,
      "learning_rate": 0.04714748050530547,
      "loss": 2.6644,
      "step": 328880
    },
    {
      "epoch": 528.78,
      "learning_rate": 0.0471442650744373,
      "loss": 2.6762,
      "step": 328900
    },
    {
      "epoch": 528.81,
      "learning_rate": 0.04714104964356913,
      "loss": 2.6851,
      "step": 328920
    },
    {
      "epoch": 528.84,
      "learning_rate": 0.047137834212700964,
      "loss": 2.672,
      "step": 328940
    },
    {
      "epoch": 528.87,
      "learning_rate": 0.0471346187818328,
      "loss": 2.6487,
      "step": 328960
    },
    {
      "epoch": 528.91,
      "learning_rate": 0.047131403350964635,
      "loss": 2.6733,
      "step": 328980
    },
    {
      "epoch": 528.94,
      "learning_rate": 0.047128187920096466,
      "loss": 2.6721,
      "step": 329000
    },
    {
      "epoch": 528.97,
      "learning_rate": 0.0471249724892283,
      "loss": 2.6743,
      "step": 329020
    },
    {
      "epoch": 529.0,
      "eval_accuracy": {
        "accuracy": 0.4142113037394076
      },
      "eval_loss": 2.7966818809509277,
      "eval_runtime": 3.1406,
      "eval_samples_per_second": 4095.744,
      "eval_steps_per_second": 64.001,
      "step": 329038
    },
    {
      "epoch": 529.0,
      "learning_rate": 0.04712175705836013,
      "loss": 2.6759,
      "step": 329040
    },
    {
      "epoch": 529.04,
      "learning_rate": 0.04711854162749196,
      "loss": 2.667,
      "step": 329060
    },
    {
      "epoch": 529.07,
      "learning_rate": 0.0471153261966238,
      "loss": 2.643,
      "step": 329080
    },
    {
      "epoch": 529.1,
      "learning_rate": 0.04711211076575563,
      "loss": 2.6537,
      "step": 329100
    },
    {
      "epoch": 529.13,
      "learning_rate": 0.04710889533488746,
      "loss": 2.684,
      "step": 329120
    },
    {
      "epoch": 529.16,
      "learning_rate": 0.047105679904019294,
      "loss": 2.6442,
      "step": 329140
    },
    {
      "epoch": 529.2,
      "learning_rate": 0.047102464473151126,
      "loss": 2.6778,
      "step": 329160
    },
    {
      "epoch": 529.23,
      "learning_rate": 0.047099249042282965,
      "loss": 2.6661,
      "step": 329180
    },
    {
      "epoch": 529.26,
      "learning_rate": 0.047096033611414796,
      "loss": 2.6733,
      "step": 329200
    },
    {
      "epoch": 529.29,
      "learning_rate": 0.04709281818054663,
      "loss": 2.6827,
      "step": 329220
    },
    {
      "epoch": 529.32,
      "learning_rate": 0.04708960274967846,
      "loss": 2.68,
      "step": 329240
    },
    {
      "epoch": 529.36,
      "learning_rate": 0.04708638731881029,
      "loss": 2.6614,
      "step": 329260
    },
    {
      "epoch": 529.39,
      "learning_rate": 0.04708317188794212,
      "loss": 2.6642,
      "step": 329280
    },
    {
      "epoch": 529.42,
      "learning_rate": 0.04707995645707396,
      "loss": 2.6575,
      "step": 329300
    },
    {
      "epoch": 529.45,
      "learning_rate": 0.04707674102620579,
      "loss": 2.6512,
      "step": 329320
    },
    {
      "epoch": 529.49,
      "learning_rate": 0.047073525595337624,
      "loss": 2.6745,
      "step": 329340
    },
    {
      "epoch": 529.52,
      "learning_rate": 0.047070310164469456,
      "loss": 2.6429,
      "step": 329360
    },
    {
      "epoch": 529.55,
      "learning_rate": 0.04706709473360129,
      "loss": 2.6816,
      "step": 329380
    },
    {
      "epoch": 529.58,
      "learning_rate": 0.04706387930273312,
      "loss": 2.6687,
      "step": 329400
    },
    {
      "epoch": 529.61,
      "learning_rate": 0.04706066387186496,
      "loss": 2.6677,
      "step": 329420
    },
    {
      "epoch": 529.65,
      "learning_rate": 0.04705744844099679,
      "loss": 2.6674,
      "step": 329440
    },
    {
      "epoch": 529.68,
      "learning_rate": 0.04705423301012862,
      "loss": 2.6574,
      "step": 329460
    },
    {
      "epoch": 529.71,
      "learning_rate": 0.04705101757926045,
      "loss": 2.6725,
      "step": 329480
    },
    {
      "epoch": 529.74,
      "learning_rate": 0.047047802148392284,
      "loss": 2.6736,
      "step": 329500
    },
    {
      "epoch": 529.77,
      "learning_rate": 0.04704458671752412,
      "loss": 2.6609,
      "step": 329520
    },
    {
      "epoch": 529.81,
      "learning_rate": 0.047041371286655954,
      "loss": 2.6519,
      "step": 329540
    },
    {
      "epoch": 529.84,
      "learning_rate": 0.047038155855787786,
      "loss": 2.6612,
      "step": 329560
    },
    {
      "epoch": 529.87,
      "learning_rate": 0.04703494042491962,
      "loss": 2.6505,
      "step": 329580
    },
    {
      "epoch": 529.9,
      "learning_rate": 0.04703172499405145,
      "loss": 2.6532,
      "step": 329600
    },
    {
      "epoch": 529.94,
      "learning_rate": 0.04702850956318328,
      "loss": 2.6947,
      "step": 329620
    },
    {
      "epoch": 529.97,
      "learning_rate": 0.04702529413231512,
      "loss": 2.6607,
      "step": 329640
    },
    {
      "epoch": 530.0,
      "learning_rate": 0.04702207870144695,
      "loss": 2.6751,
      "step": 329660
    },
    {
      "epoch": 530.0,
      "eval_accuracy": {
        "accuracy": 0.41063515509601184
      },
      "eval_loss": 2.777639865875244,
      "eval_runtime": 3.0344,
      "eval_samples_per_second": 4239.058,
      "eval_steps_per_second": 66.24,
      "step": 329660
    },
    {
      "epoch": 530.03,
      "learning_rate": 0.04701886327057878,
      "loss": 2.6348,
      "step": 329680
    },
    {
      "epoch": 530.06,
      "learning_rate": 0.047015647839710614,
      "loss": 2.6504,
      "step": 329700
    },
    {
      "epoch": 530.1,
      "learning_rate": 0.047012432408842446,
      "loss": 2.6378,
      "step": 329720
    },
    {
      "epoch": 530.13,
      "learning_rate": 0.04700921697797428,
      "loss": 2.6274,
      "step": 329740
    },
    {
      "epoch": 530.16,
      "learning_rate": 0.047006001547106116,
      "loss": 2.6624,
      "step": 329760
    },
    {
      "epoch": 530.19,
      "learning_rate": 0.04700278611623795,
      "loss": 2.6527,
      "step": 329780
    },
    {
      "epoch": 530.23,
      "learning_rate": 0.04699957068536978,
      "loss": 2.6507,
      "step": 329800
    },
    {
      "epoch": 530.26,
      "learning_rate": 0.04699635525450161,
      "loss": 2.6581,
      "step": 329820
    },
    {
      "epoch": 530.29,
      "learning_rate": 0.04699313982363344,
      "loss": 2.6696,
      "step": 329840
    },
    {
      "epoch": 530.32,
      "learning_rate": 0.04698992439276528,
      "loss": 2.6654,
      "step": 329860
    },
    {
      "epoch": 530.35,
      "learning_rate": 0.04698670896189711,
      "loss": 2.6732,
      "step": 329880
    },
    {
      "epoch": 530.39,
      "learning_rate": 0.046983493531028944,
      "loss": 2.6705,
      "step": 329900
    },
    {
      "epoch": 530.42,
      "learning_rate": 0.046980278100160776,
      "loss": 2.6659,
      "step": 329920
    },
    {
      "epoch": 530.45,
      "learning_rate": 0.04697706266929261,
      "loss": 2.679,
      "step": 329940
    },
    {
      "epoch": 530.48,
      "learning_rate": 0.04697384723842444,
      "loss": 2.6848,
      "step": 329960
    },
    {
      "epoch": 530.51,
      "learning_rate": 0.04697063180755628,
      "loss": 2.6586,
      "step": 329980
    },
    {
      "epoch": 530.55,
      "learning_rate": 0.04696741637668811,
      "loss": 2.6633,
      "step": 330000
    },
    {
      "epoch": 530.58,
      "learning_rate": 0.04696420094581994,
      "loss": 2.6778,
      "step": 330020
    },
    {
      "epoch": 530.61,
      "learning_rate": 0.04696098551495177,
      "loss": 2.6606,
      "step": 330040
    },
    {
      "epoch": 530.64,
      "learning_rate": 0.046957770084083604,
      "loss": 2.6835,
      "step": 330060
    },
    {
      "epoch": 530.68,
      "learning_rate": 0.046954554653215436,
      "loss": 2.6631,
      "step": 330080
    },
    {
      "epoch": 530.71,
      "learning_rate": 0.04695149999389067,
      "loss": 2.6658,
      "step": 330100
    },
    {
      "epoch": 530.74,
      "learning_rate": 0.04694828456302252,
      "loss": 2.6811,
      "step": 330120
    },
    {
      "epoch": 530.77,
      "learning_rate": 0.04694506913215435,
      "loss": 2.6627,
      "step": 330140
    },
    {
      "epoch": 530.8,
      "learning_rate": 0.04694185370128618,
      "loss": 2.6635,
      "step": 330160
    },
    {
      "epoch": 530.84,
      "learning_rate": 0.04693863827041801,
      "loss": 2.6781,
      "step": 330180
    },
    {
      "epoch": 530.87,
      "learning_rate": 0.04693542283954984,
      "loss": 2.6761,
      "step": 330200
    },
    {
      "epoch": 530.9,
      "learning_rate": 0.04693220740868167,
      "loss": 2.6658,
      "step": 330220
    },
    {
      "epoch": 530.93,
      "learning_rate": 0.046928991977813514,
      "loss": 2.652,
      "step": 330240
    },
    {
      "epoch": 530.96,
      "learning_rate": 0.046925776546945346,
      "loss": 2.6867,
      "step": 330260
    },
    {
      "epoch": 531.0,
      "learning_rate": 0.04692256111607718,
      "loss": 2.651,
      "step": 330280
    },
    {
      "epoch": 531.0,
      "eval_accuracy": {
        "accuracy": 0.41980875378994015
      },
      "eval_loss": 2.7394773960113525,
      "eval_runtime": 3.0005,
      "eval_samples_per_second": 4286.922,
      "eval_steps_per_second": 66.988,
      "step": 330282
    },
    {
      "epoch": 531.03,
      "learning_rate": 0.046919345685209,
      "loss": 2.6706,
      "step": 330300
    },
    {
      "epoch": 531.06,
      "learning_rate": 0.04691613025434083,
      "loss": 2.6711,
      "step": 330320
    },
    {
      "epoch": 531.09,
      "learning_rate": 0.04691291482347268,
      "loss": 2.6761,
      "step": 330340
    },
    {
      "epoch": 531.13,
      "learning_rate": 0.04690969939260451,
      "loss": 2.6732,
      "step": 330360
    },
    {
      "epoch": 531.16,
      "learning_rate": 0.04690648396173634,
      "loss": 2.6651,
      "step": 330380
    },
    {
      "epoch": 531.19,
      "learning_rate": 0.046903268530868174,
      "loss": 2.6414,
      "step": 330400
    },
    {
      "epoch": 531.22,
      "learning_rate": 0.0469000531,
      "loss": 2.6933,
      "step": 330420
    },
    {
      "epoch": 531.25,
      "learning_rate": 0.04689683766913183,
      "loss": 2.6633,
      "step": 330440
    },
    {
      "epoch": 531.29,
      "learning_rate": 0.046893622238263676,
      "loss": 2.6297,
      "step": 330460
    },
    {
      "epoch": 531.32,
      "learning_rate": 0.04689040680739551,
      "loss": 2.6392,
      "step": 330480
    },
    {
      "epoch": 531.35,
      "learning_rate": 0.04688719137652734,
      "loss": 2.6547,
      "step": 330500
    },
    {
      "epoch": 531.38,
      "learning_rate": 0.04688397594565916,
      "loss": 2.649,
      "step": 330520
    },
    {
      "epoch": 531.41,
      "learning_rate": 0.046880760514790995,
      "loss": 2.6657,
      "step": 330540
    },
    {
      "epoch": 531.45,
      "learning_rate": 0.04687754508392283,
      "loss": 2.6661,
      "step": 330560
    },
    {
      "epoch": 531.48,
      "learning_rate": 0.04687432965305467,
      "loss": 2.6295,
      "step": 330580
    },
    {
      "epoch": 531.51,
      "learning_rate": 0.046871114222186504,
      "loss": 2.6228,
      "step": 330600
    },
    {
      "epoch": 531.54,
      "learning_rate": 0.046867898791318335,
      "loss": 2.6595,
      "step": 330620
    },
    {
      "epoch": 531.58,
      "learning_rate": 0.04686468336045016,
      "loss": 2.648,
      "step": 330640
    },
    {
      "epoch": 531.61,
      "learning_rate": 0.04686146792958199,
      "loss": 2.6346,
      "step": 330660
    },
    {
      "epoch": 531.64,
      "learning_rate": 0.04685825249871384,
      "loss": 2.6659,
      "step": 330680
    },
    {
      "epoch": 531.67,
      "learning_rate": 0.04685503706784567,
      "loss": 2.6608,
      "step": 330700
    },
    {
      "epoch": 531.7,
      "learning_rate": 0.0468518216369775,
      "loss": 2.6477,
      "step": 330720
    },
    {
      "epoch": 531.74,
      "learning_rate": 0.046848606206109325,
      "loss": 2.6468,
      "step": 330740
    },
    {
      "epoch": 531.77,
      "learning_rate": 0.04684539077524116,
      "loss": 2.658,
      "step": 330760
    },
    {
      "epoch": 531.8,
      "learning_rate": 0.04684217534437299,
      "loss": 2.6374,
      "step": 330780
    },
    {
      "epoch": 531.83,
      "learning_rate": 0.046838959913504834,
      "loss": 2.6762,
      "step": 330800
    },
    {
      "epoch": 531.86,
      "learning_rate": 0.046835744482636665,
      "loss": 2.6443,
      "step": 330820
    },
    {
      "epoch": 531.9,
      "learning_rate": 0.04683252905176849,
      "loss": 2.6553,
      "step": 330840
    },
    {
      "epoch": 531.93,
      "learning_rate": 0.04682931362090032,
      "loss": 2.6554,
      "step": 330860
    },
    {
      "epoch": 531.96,
      "learning_rate": 0.04682609819003215,
      "loss": 2.6563,
      "step": 330880
    },
    {
      "epoch": 531.99,
      "learning_rate": 0.046822882759163985,
      "loss": 2.629,
      "step": 330900
    },
    {
      "epoch": 532.0,
      "eval_accuracy": {
        "accuracy": 0.41864261836274586
      },
      "eval_loss": 2.7572953701019287,
      "eval_runtime": 3.3038,
      "eval_samples_per_second": 3893.395,
      "eval_steps_per_second": 60.839,
      "step": 330904
    },
    {
      "epoch": 532.03,
      "learning_rate": 0.04681966732829583,
      "loss": 2.6672,
      "step": 330920
    },
    {
      "epoch": 532.06,
      "learning_rate": 0.04681645189742766,
      "loss": 2.6605,
      "step": 330940
    },
    {
      "epoch": 532.09,
      "learning_rate": 0.04681323646655949,
      "loss": 2.6526,
      "step": 330960
    },
    {
      "epoch": 532.12,
      "learning_rate": 0.04681002103569132,
      "loss": 2.6583,
      "step": 330980
    },
    {
      "epoch": 532.15,
      "learning_rate": 0.04680680560482315,
      "loss": 2.652,
      "step": 331000
    },
    {
      "epoch": 532.19,
      "learning_rate": 0.046803590173954995,
      "loss": 2.6523,
      "step": 331020
    },
    {
      "epoch": 532.22,
      "learning_rate": 0.04680037474308683,
      "loss": 2.6572,
      "step": 331040
    },
    {
      "epoch": 532.25,
      "learning_rate": 0.04679715931221865,
      "loss": 2.6561,
      "step": 331060
    },
    {
      "epoch": 532.28,
      "learning_rate": 0.04679394388135048,
      "loss": 2.6496,
      "step": 331080
    },
    {
      "epoch": 532.32,
      "learning_rate": 0.046790728450482315,
      "loss": 2.6863,
      "step": 331100
    },
    {
      "epoch": 532.35,
      "learning_rate": 0.046787513019614146,
      "loss": 2.662,
      "step": 331120
    },
    {
      "epoch": 532.38,
      "learning_rate": 0.04678429758874599,
      "loss": 2.6677,
      "step": 331140
    },
    {
      "epoch": 532.41,
      "learning_rate": 0.04678108215787782,
      "loss": 2.6452,
      "step": 331160
    },
    {
      "epoch": 532.44,
      "learning_rate": 0.04677786672700965,
      "loss": 2.6742,
      "step": 331180
    },
    {
      "epoch": 532.48,
      "learning_rate": 0.04677465129614148,
      "loss": 2.6489,
      "step": 331200
    },
    {
      "epoch": 532.51,
      "learning_rate": 0.04677143586527331,
      "loss": 2.6771,
      "step": 331220
    },
    {
      "epoch": 532.54,
      "learning_rate": 0.04676822043440516,
      "loss": 2.6701,
      "step": 331240
    },
    {
      "epoch": 532.57,
      "learning_rate": 0.04676500500353699,
      "loss": 2.6644,
      "step": 331260
    },
    {
      "epoch": 532.6,
      "learning_rate": 0.04676178957266881,
      "loss": 2.6664,
      "step": 331280
    },
    {
      "epoch": 532.64,
      "learning_rate": 0.046758574141800645,
      "loss": 2.6633,
      "step": 331300
    },
    {
      "epoch": 532.67,
      "learning_rate": 0.046755358710932476,
      "loss": 2.6517,
      "step": 331320
    },
    {
      "epoch": 532.7,
      "learning_rate": 0.04675214328006431,
      "loss": 2.672,
      "step": 331340
    },
    {
      "epoch": 532.73,
      "learning_rate": 0.046748927849196154,
      "loss": 2.6205,
      "step": 331360
    },
    {
      "epoch": 532.77,
      "learning_rate": 0.04674571241832798,
      "loss": 2.6835,
      "step": 331380
    },
    {
      "epoch": 532.8,
      "learning_rate": 0.04674249698745981,
      "loss": 2.6988,
      "step": 331400
    },
    {
      "epoch": 532.83,
      "learning_rate": 0.04673928155659164,
      "loss": 2.6833,
      "step": 331420
    },
    {
      "epoch": 532.86,
      "learning_rate": 0.04673606612572347,
      "loss": 2.6746,
      "step": 331440
    },
    {
      "epoch": 532.89,
      "learning_rate": 0.046732850694855305,
      "loss": 2.678,
      "step": 331460
    },
    {
      "epoch": 532.93,
      "learning_rate": 0.04672963526398714,
      "loss": 2.6684,
      "step": 331480
    },
    {
      "epoch": 532.96,
      "learning_rate": 0.046726419833118975,
      "loss": 2.6641,
      "step": 331500
    },
    {
      "epoch": 532.99,
      "learning_rate": 0.046723204402250806,
      "loss": 2.6623,
      "step": 331520
    },
    {
      "epoch": 533.0,
      "eval_accuracy": {
        "accuracy": 0.41397807665396874
      },
      "eval_loss": 2.7714357376098633,
      "eval_runtime": 3.1389,
      "eval_samples_per_second": 4097.941,
      "eval_steps_per_second": 64.035,
      "step": 331526
    },
    {
      "epoch": 533.02,
      "learning_rate": 0.04671998897138264,
      "loss": 2.6631,
      "step": 331540
    },
    {
      "epoch": 533.05,
      "learning_rate": 0.04671677354051447,
      "loss": 2.674,
      "step": 331560
    },
    {
      "epoch": 533.09,
      "learning_rate": 0.046713558109646315,
      "loss": 2.6596,
      "step": 331580
    },
    {
      "epoch": 533.12,
      "learning_rate": 0.04671034267877814,
      "loss": 2.6487,
      "step": 331600
    },
    {
      "epoch": 533.15,
      "learning_rate": 0.04670712724790997,
      "loss": 2.6352,
      "step": 331620
    },
    {
      "epoch": 533.18,
      "learning_rate": 0.0467039118170418,
      "loss": 2.6693,
      "step": 331640
    },
    {
      "epoch": 533.22,
      "learning_rate": 0.046700696386173635,
      "loss": 2.6676,
      "step": 331660
    },
    {
      "epoch": 533.25,
      "learning_rate": 0.046697480955305466,
      "loss": 2.6763,
      "step": 331680
    },
    {
      "epoch": 533.28,
      "learning_rate": 0.046694265524437305,
      "loss": 2.6382,
      "step": 331700
    },
    {
      "epoch": 533.31,
      "learning_rate": 0.046691050093569136,
      "loss": 2.6893,
      "step": 331720
    },
    {
      "epoch": 533.34,
      "learning_rate": 0.04668783466270097,
      "loss": 2.663,
      "step": 331740
    },
    {
      "epoch": 533.38,
      "learning_rate": 0.0466846192318328,
      "loss": 2.6707,
      "step": 331760
    },
    {
      "epoch": 533.41,
      "learning_rate": 0.04668140380096463,
      "loss": 2.6584,
      "step": 331780
    },
    {
      "epoch": 533.44,
      "learning_rate": 0.04667818837009646,
      "loss": 2.6472,
      "step": 331800
    },
    {
      "epoch": 533.47,
      "learning_rate": 0.0466749729392283,
      "loss": 2.6396,
      "step": 331820
    },
    {
      "epoch": 533.5,
      "learning_rate": 0.04667175750836013,
      "loss": 2.658,
      "step": 331840
    },
    {
      "epoch": 533.54,
      "learning_rate": 0.046668542077491965,
      "loss": 2.6498,
      "step": 331860
    },
    {
      "epoch": 533.57,
      "learning_rate": 0.046665326646623796,
      "loss": 2.6592,
      "step": 331880
    },
    {
      "epoch": 533.6,
      "learning_rate": 0.04666211121575563,
      "loss": 2.6728,
      "step": 331900
    },
    {
      "epoch": 533.63,
      "learning_rate": 0.046658895784887466,
      "loss": 2.6783,
      "step": 331920
    },
    {
      "epoch": 533.67,
      "learning_rate": 0.0466556803540193,
      "loss": 2.6457,
      "step": 331940
    },
    {
      "epoch": 533.7,
      "learning_rate": 0.04665246492315113,
      "loss": 2.6603,
      "step": 331960
    },
    {
      "epoch": 533.73,
      "learning_rate": 0.04664924949228296,
      "loss": 2.6687,
      "step": 331980
    },
    {
      "epoch": 533.76,
      "learning_rate": 0.04664603406141479,
      "loss": 2.6869,
      "step": 332000
    },
    {
      "epoch": 533.79,
      "learning_rate": 0.046642818630546624,
      "loss": 2.6875,
      "step": 332020
    },
    {
      "epoch": 533.83,
      "learning_rate": 0.04663960319967846,
      "loss": 2.658,
      "step": 332040
    },
    {
      "epoch": 533.86,
      "learning_rate": 0.046636387768810295,
      "loss": 2.6745,
      "step": 332060
    },
    {
      "epoch": 533.89,
      "learning_rate": 0.046633172337942126,
      "loss": 2.6753,
      "step": 332080
    },
    {
      "epoch": 533.92,
      "learning_rate": 0.04662995690707396,
      "loss": 2.6625,
      "step": 332100
    },
    {
      "epoch": 533.95,
      "learning_rate": 0.04662674147620579,
      "loss": 2.6638,
      "step": 332120
    },
    {
      "epoch": 533.99,
      "learning_rate": 0.04662352604533762,
      "loss": 2.668,
      "step": 332140
    },
    {
      "epoch": 534.0,
      "eval_accuracy": {
        "accuracy": 0.4218300551970769
      },
      "eval_loss": 2.7602596282958984,
      "eval_runtime": 3.1187,
      "eval_samples_per_second": 4124.514,
      "eval_steps_per_second": 64.451,
      "step": 332148
    },
    {
      "epoch": 534.02,
      "learning_rate": 0.04662031061446946,
      "loss": 2.6636,
      "step": 332160
    },
    {
      "epoch": 534.05,
      "learning_rate": 0.04661709518360129,
      "loss": 2.6419,
      "step": 332180
    },
    {
      "epoch": 534.08,
      "learning_rate": 0.04661387975273312,
      "loss": 2.6231,
      "step": 332200
    },
    {
      "epoch": 534.12,
      "learning_rate": 0.046610664321864954,
      "loss": 2.6422,
      "step": 332220
    },
    {
      "epoch": 534.15,
      "learning_rate": 0.046607448890996786,
      "loss": 2.6766,
      "step": 332240
    },
    {
      "epoch": 534.18,
      "learning_rate": 0.046604233460128625,
      "loss": 2.6505,
      "step": 332260
    },
    {
      "epoch": 534.21,
      "learning_rate": 0.046601018029260456,
      "loss": 2.6607,
      "step": 332280
    },
    {
      "epoch": 534.24,
      "learning_rate": 0.04659780259839229,
      "loss": 2.6535,
      "step": 332300
    },
    {
      "epoch": 534.28,
      "learning_rate": 0.04659458716752412,
      "loss": 2.6842,
      "step": 332320
    },
    {
      "epoch": 534.31,
      "learning_rate": 0.04659137173665595,
      "loss": 2.6743,
      "step": 332340
    },
    {
      "epoch": 534.34,
      "learning_rate": 0.04658815630578778,
      "loss": 2.6702,
      "step": 332360
    },
    {
      "epoch": 534.37,
      "learning_rate": 0.04658494087491962,
      "loss": 2.6712,
      "step": 332380
    },
    {
      "epoch": 534.41,
      "learning_rate": 0.04658172544405145,
      "loss": 2.6732,
      "step": 332400
    },
    {
      "epoch": 534.44,
      "learning_rate": 0.046578510013183284,
      "loss": 2.6631,
      "step": 332420
    },
    {
      "epoch": 534.47,
      "learning_rate": 0.046575294582315116,
      "loss": 2.6558,
      "step": 332440
    },
    {
      "epoch": 534.5,
      "learning_rate": 0.04657207915144695,
      "loss": 2.6596,
      "step": 332460
    },
    {
      "epoch": 534.53,
      "learning_rate": 0.04656886372057878,
      "loss": 2.6577,
      "step": 332480
    },
    {
      "epoch": 534.57,
      "learning_rate": 0.04656564828971062,
      "loss": 2.6796,
      "step": 332500
    },
    {
      "epoch": 534.6,
      "learning_rate": 0.04656243285884245,
      "loss": 2.6635,
      "step": 332520
    },
    {
      "epoch": 534.63,
      "learning_rate": 0.04655921742797428,
      "loss": 2.6488,
      "step": 332540
    },
    {
      "epoch": 534.66,
      "learning_rate": 0.04655600199710611,
      "loss": 2.6706,
      "step": 332560
    },
    {
      "epoch": 534.69,
      "learning_rate": 0.046552786566237944,
      "loss": 2.6685,
      "step": 332580
    },
    {
      "epoch": 534.73,
      "learning_rate": 0.04654957113536978,
      "loss": 2.6925,
      "step": 332600
    },
    {
      "epoch": 534.76,
      "learning_rate": 0.046546355704501614,
      "loss": 2.6566,
      "step": 332620
    },
    {
      "epoch": 534.79,
      "learning_rate": 0.046543140273633446,
      "loss": 2.6556,
      "step": 332640
    },
    {
      "epoch": 534.82,
      "learning_rate": 0.04653992484276528,
      "loss": 2.6726,
      "step": 332660
    },
    {
      "epoch": 534.86,
      "learning_rate": 0.04653670941189711,
      "loss": 2.6631,
      "step": 332680
    },
    {
      "epoch": 534.89,
      "learning_rate": 0.04653349398102894,
      "loss": 2.6419,
      "step": 332700
    },
    {
      "epoch": 534.92,
      "learning_rate": 0.04653027855016078,
      "loss": 2.6454,
      "step": 332720
    },
    {
      "epoch": 534.95,
      "learning_rate": 0.04652706311929261,
      "loss": 2.664,
      "step": 332740
    },
    {
      "epoch": 534.98,
      "learning_rate": 0.04652384768842444,
      "loss": 2.629,
      "step": 332760
    },
    {
      "epoch": 535.0,
      "eval_accuracy": {
        "accuracy": 0.41607712042291845
      },
      "eval_loss": 2.7602357864379883,
      "eval_runtime": 3.0128,
      "eval_samples_per_second": 4269.423,
      "eval_steps_per_second": 66.715,
      "step": 332770
    },
    {
      "epoch": 535.02,
      "learning_rate": 0.046520632257556274,
      "loss": 2.6702,
      "step": 332780
    },
    {
      "epoch": 535.05,
      "learning_rate": 0.046517416826688106,
      "loss": 2.6698,
      "step": 332800
    },
    {
      "epoch": 535.08,
      "learning_rate": 0.046514201395819944,
      "loss": 2.6632,
      "step": 332820
    },
    {
      "epoch": 535.11,
      "learning_rate": 0.046510985964951776,
      "loss": 2.6689,
      "step": 332840
    },
    {
      "epoch": 535.14,
      "learning_rate": 0.04650777053408361,
      "loss": 2.6523,
      "step": 332860
    },
    {
      "epoch": 535.18,
      "learning_rate": 0.04650455510321544,
      "loss": 2.6652,
      "step": 332880
    },
    {
      "epoch": 535.21,
      "learning_rate": 0.04650133967234727,
      "loss": 2.6749,
      "step": 332900
    },
    {
      "epoch": 535.24,
      "learning_rate": 0.0464981242414791,
      "loss": 2.6674,
      "step": 332920
    },
    {
      "epoch": 535.27,
      "learning_rate": 0.04649490881061094,
      "loss": 2.6504,
      "step": 332940
    },
    {
      "epoch": 535.31,
      "learning_rate": 0.04649169337974277,
      "loss": 2.6628,
      "step": 332960
    },
    {
      "epoch": 535.34,
      "learning_rate": 0.046488477948874604,
      "loss": 2.6634,
      "step": 332980
    },
    {
      "epoch": 535.37,
      "learning_rate": 0.046485262518006436,
      "loss": 2.6504,
      "step": 333000
    },
    {
      "epoch": 535.4,
      "learning_rate": 0.04648204708713827,
      "loss": 2.649,
      "step": 333020
    },
    {
      "epoch": 535.43,
      "learning_rate": 0.0464788316562701,
      "loss": 2.6729,
      "step": 333040
    },
    {
      "epoch": 535.47,
      "learning_rate": 0.04647561622540194,
      "loss": 2.6391,
      "step": 333060
    },
    {
      "epoch": 535.5,
      "learning_rate": 0.04647256156607718,
      "loss": 2.6794,
      "step": 333080
    },
    {
      "epoch": 535.53,
      "learning_rate": 0.04646934613520901,
      "loss": 2.6439,
      "step": 333100
    },
    {
      "epoch": 535.56,
      "learning_rate": 0.046466130704340844,
      "loss": 2.6559,
      "step": 333120
    },
    {
      "epoch": 535.59,
      "learning_rate": 0.046462915273472676,
      "loss": 2.6589,
      "step": 333140
    },
    {
      "epoch": 535.63,
      "learning_rate": 0.0464596998426045,
      "loss": 2.671,
      "step": 333160
    },
    {
      "epoch": 535.66,
      "learning_rate": 0.04645648441173633,
      "loss": 2.644,
      "step": 333180
    },
    {
      "epoch": 535.69,
      "learning_rate": 0.04645326898086818,
      "loss": 2.6703,
      "step": 333200
    },
    {
      "epoch": 535.72,
      "learning_rate": 0.04645005355000001,
      "loss": 2.6609,
      "step": 333220
    },
    {
      "epoch": 535.76,
      "learning_rate": 0.04644683811913184,
      "loss": 2.6438,
      "step": 333240
    },
    {
      "epoch": 535.79,
      "learning_rate": 0.046443622688263665,
      "loss": 2.6534,
      "step": 333260
    },
    {
      "epoch": 535.82,
      "learning_rate": 0.0464404072573955,
      "loss": 2.6516,
      "step": 333280
    },
    {
      "epoch": 535.85,
      "learning_rate": 0.04643719182652733,
      "loss": 2.6758,
      "step": 333300
    },
    {
      "epoch": 535.88,
      "learning_rate": 0.046433976395659174,
      "loss": 2.6711,
      "step": 333320
    },
    {
      "epoch": 535.92,
      "learning_rate": 0.046430760964791006,
      "loss": 2.6687,
      "step": 333340
    },
    {
      "epoch": 535.95,
      "learning_rate": 0.04642754553392283,
      "loss": 2.6408,
      "step": 333360
    },
    {
      "epoch": 535.98,
      "learning_rate": 0.04642433010305466,
      "loss": 2.6841,
      "step": 333380
    },
    {
      "epoch": 536.0,
      "eval_accuracy": {
        "accuracy": 0.41794293710642927
      },
      "eval_loss": 2.7720861434936523,
      "eval_runtime": 2.9873,
      "eval_samples_per_second": 4305.872,
      "eval_steps_per_second": 67.284,
      "step": 333392
    },
    {
      "epoch": 536.01,
      "learning_rate": 0.04642111467218649,
      "loss": 2.6588,
      "step": 333400
    },
    {
      "epoch": 536.05,
      "learning_rate": 0.04641789924131834,
      "loss": 2.6543,
      "step": 333420
    },
    {
      "epoch": 536.08,
      "learning_rate": 0.04641468381045017,
      "loss": 2.6692,
      "step": 333440
    },
    {
      "epoch": 536.11,
      "learning_rate": 0.046411468379582,
      "loss": 2.663,
      "step": 333460
    },
    {
      "epoch": 536.14,
      "learning_rate": 0.04640825294871383,
      "loss": 2.6509,
      "step": 333480
    },
    {
      "epoch": 536.17,
      "learning_rate": 0.04640503751784566,
      "loss": 2.6303,
      "step": 333500
    },
    {
      "epoch": 536.21,
      "learning_rate": 0.04640182208697749,
      "loss": 2.6715,
      "step": 333520
    },
    {
      "epoch": 536.24,
      "learning_rate": 0.046398606656109335,
      "loss": 2.6515,
      "step": 333540
    },
    {
      "epoch": 536.27,
      "learning_rate": 0.04639539122524117,
      "loss": 2.6488,
      "step": 333560
    },
    {
      "epoch": 536.3,
      "learning_rate": 0.04639217579437299,
      "loss": 2.657,
      "step": 333580
    },
    {
      "epoch": 536.33,
      "learning_rate": 0.04638896036350482,
      "loss": 2.6657,
      "step": 333600
    },
    {
      "epoch": 536.37,
      "learning_rate": 0.046385744932636655,
      "loss": 2.6806,
      "step": 333620
    },
    {
      "epoch": 536.4,
      "learning_rate": 0.0463825295017685,
      "loss": 2.6553,
      "step": 333640
    },
    {
      "epoch": 536.43,
      "learning_rate": 0.04637931407090033,
      "loss": 2.6671,
      "step": 333660
    },
    {
      "epoch": 536.46,
      "learning_rate": 0.04637609864003216,
      "loss": 2.6679,
      "step": 333680
    },
    {
      "epoch": 536.5,
      "learning_rate": 0.04637288320916399,
      "loss": 2.68,
      "step": 333700
    },
    {
      "epoch": 536.53,
      "learning_rate": 0.04636966777829582,
      "loss": 2.6582,
      "step": 333720
    },
    {
      "epoch": 536.56,
      "learning_rate": 0.04636645234742765,
      "loss": 2.6455,
      "step": 333740
    },
    {
      "epoch": 536.59,
      "learning_rate": 0.0463632369165595,
      "loss": 2.6631,
      "step": 333760
    },
    {
      "epoch": 536.62,
      "learning_rate": 0.04636002148569133,
      "loss": 2.6532,
      "step": 333780
    },
    {
      "epoch": 536.66,
      "learning_rate": 0.04635680605482315,
      "loss": 2.6595,
      "step": 333800
    },
    {
      "epoch": 536.69,
      "learning_rate": 0.046353590623954985,
      "loss": 2.6634,
      "step": 333820
    },
    {
      "epoch": 536.72,
      "learning_rate": 0.04635037519308682,
      "loss": 2.6436,
      "step": 333840
    },
    {
      "epoch": 536.75,
      "learning_rate": 0.04634715976221865,
      "loss": 2.6436,
      "step": 333860
    },
    {
      "epoch": 536.78,
      "learning_rate": 0.046343944331350494,
      "loss": 2.667,
      "step": 333880
    },
    {
      "epoch": 536.82,
      "learning_rate": 0.04634072890048232,
      "loss": 2.6709,
      "step": 333900
    },
    {
      "epoch": 536.85,
      "learning_rate": 0.04633751346961415,
      "loss": 2.6602,
      "step": 333920
    },
    {
      "epoch": 536.88,
      "learning_rate": 0.04633429803874598,
      "loss": 2.6657,
      "step": 333940
    },
    {
      "epoch": 536.91,
      "learning_rate": 0.04633108260787781,
      "loss": 2.6688,
      "step": 333960
    },
    {
      "epoch": 536.95,
      "learning_rate": 0.04632786717700966,
      "loss": 2.6559,
      "step": 333980
    },
    {
      "epoch": 536.98,
      "learning_rate": 0.04632465174614148,
      "loss": 2.6531,
      "step": 334000
    },
    {
      "epoch": 537.0,
      "eval_accuracy": {
        "accuracy": 0.4142890461012206
      },
      "eval_loss": 2.755030870437622,
      "eval_runtime": 3.2297,
      "eval_samples_per_second": 3982.778,
      "eval_steps_per_second": 62.236,
      "step": 334014
    },
    {
      "epoch": 537.01,
      "learning_rate": 0.046321436315273315,
      "loss": 2.6399,
      "step": 334020
    },
    {
      "epoch": 537.04,
      "learning_rate": 0.04631822088440515,
      "loss": 2.6559,
      "step": 334040
    },
    {
      "epoch": 537.07,
      "learning_rate": 0.04631500545353698,
      "loss": 2.6456,
      "step": 334060
    },
    {
      "epoch": 537.11,
      "learning_rate": 0.04631179002266881,
      "loss": 2.6451,
      "step": 334080
    },
    {
      "epoch": 537.14,
      "learning_rate": 0.046308574591800655,
      "loss": 2.6768,
      "step": 334100
    },
    {
      "epoch": 537.17,
      "learning_rate": 0.04630535916093248,
      "loss": 2.641,
      "step": 334120
    },
    {
      "epoch": 537.2,
      "learning_rate": 0.04630214373006431,
      "loss": 2.6585,
      "step": 334140
    },
    {
      "epoch": 537.23,
      "learning_rate": 0.04629892829919614,
      "loss": 2.648,
      "step": 334160
    },
    {
      "epoch": 537.27,
      "learning_rate": 0.046295712868327975,
      "loss": 2.6306,
      "step": 334180
    },
    {
      "epoch": 537.3,
      "learning_rate": 0.046292497437459806,
      "loss": 2.6386,
      "step": 334200
    },
    {
      "epoch": 537.33,
      "learning_rate": 0.046289282006591645,
      "loss": 2.6501,
      "step": 334220
    },
    {
      "epoch": 537.36,
      "learning_rate": 0.04628606657572348,
      "loss": 2.6506,
      "step": 334240
    },
    {
      "epoch": 537.4,
      "learning_rate": 0.04628285114485531,
      "loss": 2.6628,
      "step": 334260
    },
    {
      "epoch": 537.43,
      "learning_rate": 0.04627963571398714,
      "loss": 2.6801,
      "step": 334280
    },
    {
      "epoch": 537.46,
      "learning_rate": 0.04627642028311897,
      "loss": 2.6494,
      "step": 334300
    },
    {
      "epoch": 537.49,
      "learning_rate": 0.04627320485225081,
      "loss": 2.647,
      "step": 334320
    },
    {
      "epoch": 537.52,
      "learning_rate": 0.04626998942138264,
      "loss": 2.6691,
      "step": 334340
    },
    {
      "epoch": 537.56,
      "learning_rate": 0.04626677399051447,
      "loss": 2.6439,
      "step": 334360
    },
    {
      "epoch": 537.59,
      "learning_rate": 0.046263558559646305,
      "loss": 2.6475,
      "step": 334380
    },
    {
      "epoch": 537.62,
      "learning_rate": 0.046260343128778136,
      "loss": 2.6695,
      "step": 334400
    },
    {
      "epoch": 537.65,
      "learning_rate": 0.04625712769790997,
      "loss": 2.6684,
      "step": 334420
    },
    {
      "epoch": 537.68,
      "learning_rate": 0.046253912267041807,
      "loss": 2.6383,
      "step": 334440
    },
    {
      "epoch": 537.72,
      "learning_rate": 0.04625069683617364,
      "loss": 2.6547,
      "step": 334460
    },
    {
      "epoch": 537.75,
      "learning_rate": 0.04624748140530547,
      "loss": 2.6487,
      "step": 334480
    },
    {
      "epoch": 537.78,
      "learning_rate": 0.0462442659744373,
      "loss": 2.6655,
      "step": 334500
    },
    {
      "epoch": 537.81,
      "learning_rate": 0.04624105054356913,
      "loss": 2.6424,
      "step": 334520
    },
    {
      "epoch": 537.85,
      "learning_rate": 0.046237835112700965,
      "loss": 2.6575,
      "step": 334540
    },
    {
      "epoch": 537.88,
      "learning_rate": 0.0462346196818328,
      "loss": 2.668,
      "step": 334560
    },
    {
      "epoch": 537.91,
      "learning_rate": 0.046231404250964635,
      "loss": 2.6541,
      "step": 334580
    },
    {
      "epoch": 537.94,
      "learning_rate": 0.046228188820096466,
      "loss": 2.6549,
      "step": 334600
    },
    {
      "epoch": 537.97,
      "learning_rate": 0.0462249733892283,
      "loss": 2.6629,
      "step": 334620
    },
    {
      "epoch": 538.0,
      "eval_accuracy": {
        "accuracy": 0.41320065303583925
      },
      "eval_loss": 2.779930830001831,
      "eval_runtime": 3.1794,
      "eval_samples_per_second": 4045.67,
      "eval_steps_per_second": 63.219,
      "step": 334636
    },
    {
      "epoch": 538.01,
      "learning_rate": 0.04622175795836013,
      "loss": 2.6465,
      "step": 334640
    },
    {
      "epoch": 538.04,
      "learning_rate": 0.04621854252749197,
      "loss": 2.656,
      "step": 334660
    },
    {
      "epoch": 538.07,
      "learning_rate": 0.0462153270966238,
      "loss": 2.6481,
      "step": 334680
    },
    {
      "epoch": 538.1,
      "learning_rate": 0.04621211166575563,
      "loss": 2.6578,
      "step": 334700
    },
    {
      "epoch": 538.14,
      "learning_rate": 0.04620889623488746,
      "loss": 2.6313,
      "step": 334720
    },
    {
      "epoch": 538.17,
      "learning_rate": 0.046205680804019295,
      "loss": 2.6533,
      "step": 334740
    },
    {
      "epoch": 538.2,
      "learning_rate": 0.046202465373151126,
      "loss": 2.6295,
      "step": 334760
    },
    {
      "epoch": 538.23,
      "learning_rate": 0.046199249942282965,
      "loss": 2.6606,
      "step": 334780
    },
    {
      "epoch": 538.26,
      "learning_rate": 0.046196034511414796,
      "loss": 2.6586,
      "step": 334800
    },
    {
      "epoch": 538.3,
      "learning_rate": 0.04619281908054663,
      "loss": 2.6673,
      "step": 334820
    },
    {
      "epoch": 538.33,
      "learning_rate": 0.04618960364967846,
      "loss": 2.6619,
      "step": 334840
    },
    {
      "epoch": 538.36,
      "learning_rate": 0.04618638821881029,
      "loss": 2.6403,
      "step": 334860
    },
    {
      "epoch": 538.39,
      "learning_rate": 0.04618317278794212,
      "loss": 2.6348,
      "step": 334880
    },
    {
      "epoch": 538.42,
      "learning_rate": 0.04617995735707396,
      "loss": 2.657,
      "step": 334900
    },
    {
      "epoch": 538.46,
      "learning_rate": 0.04617674192620579,
      "loss": 2.659,
      "step": 334920
    },
    {
      "epoch": 538.49,
      "learning_rate": 0.046173526495337625,
      "loss": 2.6665,
      "step": 334940
    },
    {
      "epoch": 538.52,
      "learning_rate": 0.046170311064469456,
      "loss": 2.6642,
      "step": 334960
    },
    {
      "epoch": 538.55,
      "learning_rate": 0.04616709563360129,
      "loss": 2.6705,
      "step": 334980
    },
    {
      "epoch": 538.59,
      "learning_rate": 0.046163880202733126,
      "loss": 2.6693,
      "step": 335000
    },
    {
      "epoch": 538.62,
      "learning_rate": 0.04616066477186496,
      "loss": 2.6506,
      "step": 335020
    },
    {
      "epoch": 538.65,
      "learning_rate": 0.04615744934099679,
      "loss": 2.673,
      "step": 335040
    },
    {
      "epoch": 538.68,
      "learning_rate": 0.04615423391012862,
      "loss": 2.6809,
      "step": 335060
    },
    {
      "epoch": 538.71,
      "learning_rate": 0.04615101847926045,
      "loss": 2.6748,
      "step": 335080
    },
    {
      "epoch": 538.75,
      "learning_rate": 0.046147803048392284,
      "loss": 2.6543,
      "step": 335100
    },
    {
      "epoch": 538.78,
      "learning_rate": 0.04614458761752412,
      "loss": 2.6369,
      "step": 335120
    },
    {
      "epoch": 538.81,
      "learning_rate": 0.046141372186655955,
      "loss": 2.6348,
      "step": 335140
    },
    {
      "epoch": 538.84,
      "learning_rate": 0.046138156755787786,
      "loss": 2.6895,
      "step": 335160
    },
    {
      "epoch": 538.87,
      "learning_rate": 0.04613494132491962,
      "loss": 2.6596,
      "step": 335180
    },
    {
      "epoch": 538.91,
      "learning_rate": 0.04613172589405145,
      "loss": 2.6713,
      "step": 335200
    },
    {
      "epoch": 538.94,
      "learning_rate": 0.04612851046318328,
      "loss": 2.6802,
      "step": 335220
    },
    {
      "epoch": 538.97,
      "learning_rate": 0.04612529503231512,
      "loss": 2.6926,
      "step": 335240
    },
    {
      "epoch": 539.0,
      "eval_accuracy": {
        "accuracy": 0.4185648760009329
      },
      "eval_loss": 2.7561495304107666,
      "eval_runtime": 2.9354,
      "eval_samples_per_second": 4382.044,
      "eval_steps_per_second": 68.475,
      "step": 335258
    },
    {
      "epoch": 539.0,
      "learning_rate": 0.04612207960144695,
      "loss": 2.6433,
      "step": 335260
    },
    {
      "epoch": 539.04,
      "learning_rate": 0.04611886417057878,
      "loss": 2.6709,
      "step": 335280
    },
    {
      "epoch": 539.07,
      "learning_rate": 0.046115648739710614,
      "loss": 2.6842,
      "step": 335300
    },
    {
      "epoch": 539.1,
      "learning_rate": 0.046112433308842446,
      "loss": 2.6671,
      "step": 335320
    },
    {
      "epoch": 539.13,
      "learning_rate": 0.046109217877974285,
      "loss": 2.6745,
      "step": 335340
    },
    {
      "epoch": 539.16,
      "learning_rate": 0.046106002447106116,
      "loss": 2.6432,
      "step": 335360
    },
    {
      "epoch": 539.2,
      "learning_rate": 0.04610278701623795,
      "loss": 2.6477,
      "step": 335380
    },
    {
      "epoch": 539.23,
      "learning_rate": 0.04609957158536978,
      "loss": 2.6565,
      "step": 335400
    },
    {
      "epoch": 539.26,
      "learning_rate": 0.04609635615450161,
      "loss": 2.6521,
      "step": 335420
    },
    {
      "epoch": 539.29,
      "learning_rate": 0.04609314072363344,
      "loss": 2.6525,
      "step": 335440
    },
    {
      "epoch": 539.32,
      "learning_rate": 0.04608992529276528,
      "loss": 2.6603,
      "step": 335460
    },
    {
      "epoch": 539.36,
      "learning_rate": 0.04608670986189711,
      "loss": 2.6668,
      "step": 335480
    },
    {
      "epoch": 539.39,
      "learning_rate": 0.046083494431028944,
      "loss": 2.6566,
      "step": 335500
    },
    {
      "epoch": 539.42,
      "learning_rate": 0.046080279000160776,
      "loss": 2.6499,
      "step": 335520
    },
    {
      "epoch": 539.45,
      "learning_rate": 0.04607706356929261,
      "loss": 2.6307,
      "step": 335540
    },
    {
      "epoch": 539.49,
      "learning_rate": 0.046073848138424446,
      "loss": 2.6582,
      "step": 335560
    },
    {
      "epoch": 539.52,
      "learning_rate": 0.04607063270755628,
      "loss": 2.6474,
      "step": 335580
    },
    {
      "epoch": 539.55,
      "learning_rate": 0.04606741727668811,
      "loss": 2.6436,
      "step": 335600
    },
    {
      "epoch": 539.58,
      "learning_rate": 0.04606420184581994,
      "loss": 2.6565,
      "step": 335620
    },
    {
      "epoch": 539.61,
      "learning_rate": 0.04606098641495177,
      "loss": 2.6453,
      "step": 335640
    },
    {
      "epoch": 539.65,
      "learning_rate": 0.046057770984083604,
      "loss": 2.6562,
      "step": 335660
    },
    {
      "epoch": 539.68,
      "learning_rate": 0.04605455555321544,
      "loss": 2.6518,
      "step": 335680
    },
    {
      "epoch": 539.71,
      "learning_rate": 0.046051340122347274,
      "loss": 2.6486,
      "step": 335700
    },
    {
      "epoch": 539.74,
      "learning_rate": 0.046048124691479106,
      "loss": 2.6619,
      "step": 335720
    },
    {
      "epoch": 539.77,
      "learning_rate": 0.04604490926061094,
      "loss": 2.631,
      "step": 335740
    },
    {
      "epoch": 539.81,
      "learning_rate": 0.04604169382974277,
      "loss": 2.659,
      "step": 335760
    },
    {
      "epoch": 539.84,
      "learning_rate": 0.046038478398874594,
      "loss": 2.6669,
      "step": 335780
    },
    {
      "epoch": 539.87,
      "learning_rate": 0.04603526296800644,
      "loss": 2.6535,
      "step": 335800
    },
    {
      "epoch": 539.9,
      "learning_rate": 0.04603204753713827,
      "loss": 2.6704,
      "step": 335820
    },
    {
      "epoch": 539.94,
      "learning_rate": 0.0460288321062701,
      "loss": 2.6695,
      "step": 335840
    },
    {
      "epoch": 539.97,
      "learning_rate": 0.046025616675401934,
      "loss": 2.6597,
      "step": 335860
    },
    {
      "epoch": 540.0,
      "learning_rate": 0.046022401244533766,
      "loss": 2.6565,
      "step": 335880
    },
    {
      "epoch": 540.0,
      "eval_accuracy": {
        "accuracy": 0.4166213169556091
      },
      "eval_loss": 2.754840612411499,
      "eval_runtime": 2.9493,
      "eval_samples_per_second": 4361.436,
      "eval_steps_per_second": 68.153,
      "step": 335880
    },
    {
      "epoch": 540.03,
      "learning_rate": 0.046019185813665604,
      "loss": 2.6606,
      "step": 335900
    },
    {
      "epoch": 540.06,
      "learning_rate": 0.046015970382797436,
      "loss": 2.6492,
      "step": 335920
    },
    {
      "epoch": 540.1,
      "learning_rate": 0.04601275495192927,
      "loss": 2.6905,
      "step": 335940
    },
    {
      "epoch": 540.13,
      "learning_rate": 0.0460095395210611,
      "loss": 2.6485,
      "step": 335960
    },
    {
      "epoch": 540.16,
      "learning_rate": 0.04600632409019293,
      "loss": 2.6588,
      "step": 335980
    },
    {
      "epoch": 540.19,
      "learning_rate": 0.046003108659324755,
      "loss": 2.6691,
      "step": 336000
    },
    {
      "epoch": 540.23,
      "learning_rate": 0.0459998932284566,
      "loss": 2.6503,
      "step": 336020
    },
    {
      "epoch": 540.26,
      "learning_rate": 0.04599667779758843,
      "loss": 2.6344,
      "step": 336040
    },
    {
      "epoch": 540.29,
      "learning_rate": 0.045993462366720264,
      "loss": 2.662,
      "step": 336060
    },
    {
      "epoch": 540.32,
      "learning_rate": 0.045990246935852096,
      "loss": 2.6641,
      "step": 336080
    },
    {
      "epoch": 540.35,
      "learning_rate": 0.04598703150498392,
      "loss": 2.6536,
      "step": 336100
    },
    {
      "epoch": 540.39,
      "learning_rate": 0.04598381607411575,
      "loss": 2.6494,
      "step": 336120
    },
    {
      "epoch": 540.42,
      "learning_rate": 0.0459806006432476,
      "loss": 2.6668,
      "step": 336140
    },
    {
      "epoch": 540.45,
      "learning_rate": 0.04597738521237943,
      "loss": 2.658,
      "step": 336160
    },
    {
      "epoch": 540.48,
      "learning_rate": 0.04597416978151126,
      "loss": 2.6507,
      "step": 336180
    },
    {
      "epoch": 540.51,
      "learning_rate": 0.04597095435064309,
      "loss": 2.679,
      "step": 336200
    },
    {
      "epoch": 540.55,
      "learning_rate": 0.04596773891977492,
      "loss": 2.6394,
      "step": 336220
    },
    {
      "epoch": 540.58,
      "learning_rate": 0.04596452348890676,
      "loss": 2.6387,
      "step": 336240
    },
    {
      "epoch": 540.61,
      "learning_rate": 0.045961308058038594,
      "loss": 2.674,
      "step": 336260
    },
    {
      "epoch": 540.64,
      "learning_rate": 0.045958092627170426,
      "loss": 2.6656,
      "step": 336280
    },
    {
      "epoch": 540.68,
      "learning_rate": 0.04595487719630226,
      "loss": 2.6645,
      "step": 336300
    },
    {
      "epoch": 540.71,
      "learning_rate": 0.04595166176543408,
      "loss": 2.6475,
      "step": 336320
    },
    {
      "epoch": 540.74,
      "learning_rate": 0.045948446334565914,
      "loss": 2.6557,
      "step": 336340
    },
    {
      "epoch": 540.77,
      "learning_rate": 0.04594523090369776,
      "loss": 2.6646,
      "step": 336360
    },
    {
      "epoch": 540.8,
      "learning_rate": 0.04594201547282959,
      "loss": 2.6578,
      "step": 336380
    },
    {
      "epoch": 540.84,
      "learning_rate": 0.04593880004196142,
      "loss": 2.6546,
      "step": 336400
    },
    {
      "epoch": 540.87,
      "learning_rate": 0.04593558461109325,
      "loss": 2.6574,
      "step": 336420
    },
    {
      "epoch": 540.9,
      "learning_rate": 0.04593236918022508,
      "loss": 2.6786,
      "step": 336440
    },
    {
      "epoch": 540.93,
      "learning_rate": 0.04592915374935691,
      "loss": 2.6577,
      "step": 336460
    },
    {
      "epoch": 540.96,
      "learning_rate": 0.045925938318488756,
      "loss": 2.6437,
      "step": 336480
    },
    {
      "epoch": 541.0,
      "learning_rate": 0.04592272288762059,
      "loss": 2.6568,
      "step": 336500
    },
    {
      "epoch": 541.0,
      "eval_accuracy": {
        "accuracy": 0.41086838218145066
      },
      "eval_loss": 2.7528164386749268,
      "eval_runtime": 3.0809,
      "eval_samples_per_second": 4175.113,
      "eval_steps_per_second": 65.241,
      "step": 336502
    },
    {
      "epoch": 541.03,
      "learning_rate": 0.04591950745675242,
      "loss": 2.6424,
      "step": 336520
    },
    {
      "epoch": 541.06,
      "learning_rate": 0.045916292025884244,
      "loss": 2.6596,
      "step": 336540
    },
    {
      "epoch": 541.09,
      "learning_rate": 0.045913076595016075,
      "loss": 2.6909,
      "step": 336560
    },
    {
      "epoch": 541.13,
      "learning_rate": 0.04590986116414792,
      "loss": 2.6597,
      "step": 336580
    },
    {
      "epoch": 541.16,
      "learning_rate": 0.04590664573327975,
      "loss": 2.6292,
      "step": 336600
    },
    {
      "epoch": 541.19,
      "learning_rate": 0.045903430302411584,
      "loss": 2.6361,
      "step": 336620
    },
    {
      "epoch": 541.22,
      "learning_rate": 0.04590021487154341,
      "loss": 2.6635,
      "step": 336640
    },
    {
      "epoch": 541.25,
      "learning_rate": 0.04589699944067524,
      "loss": 2.6569,
      "step": 336660
    },
    {
      "epoch": 541.29,
      "learning_rate": 0.04589378400980707,
      "loss": 2.6721,
      "step": 336680
    },
    {
      "epoch": 541.32,
      "learning_rate": 0.04589056857893892,
      "loss": 2.6605,
      "step": 336700
    },
    {
      "epoch": 541.35,
      "learning_rate": 0.04588735314807075,
      "loss": 2.6749,
      "step": 336720
    },
    {
      "epoch": 541.38,
      "learning_rate": 0.045884137717202574,
      "loss": 2.659,
      "step": 336740
    },
    {
      "epoch": 541.41,
      "learning_rate": 0.045880922286334405,
      "loss": 2.6222,
      "step": 336760
    },
    {
      "epoch": 541.45,
      "learning_rate": 0.04587770685546624,
      "loss": 2.6391,
      "step": 336780
    },
    {
      "epoch": 541.48,
      "learning_rate": 0.04587449142459807,
      "loss": 2.6617,
      "step": 336800
    },
    {
      "epoch": 541.51,
      "learning_rate": 0.045871275993729914,
      "loss": 2.6521,
      "step": 336820
    },
    {
      "epoch": 541.54,
      "learning_rate": 0.045868060562861745,
      "loss": 2.6619,
      "step": 336840
    },
    {
      "epoch": 541.58,
      "learning_rate": 0.04586484513199357,
      "loss": 2.6779,
      "step": 336860
    },
    {
      "epoch": 541.61,
      "learning_rate": 0.0458616297011254,
      "loss": 2.6442,
      "step": 336880
    },
    {
      "epoch": 541.64,
      "learning_rate": 0.04585841427025723,
      "loss": 2.6814,
      "step": 336900
    },
    {
      "epoch": 541.67,
      "learning_rate": 0.04585519883938908,
      "loss": 2.6461,
      "step": 336920
    },
    {
      "epoch": 541.7,
      "learning_rate": 0.04585198340852091,
      "loss": 2.64,
      "step": 336940
    },
    {
      "epoch": 541.74,
      "learning_rate": 0.045848767977652735,
      "loss": 2.6374,
      "step": 336960
    },
    {
      "epoch": 541.77,
      "learning_rate": 0.04584555254678457,
      "loss": 2.653,
      "step": 336980
    },
    {
      "epoch": 541.8,
      "learning_rate": 0.0458423371159164,
      "loss": 2.6425,
      "step": 337000
    },
    {
      "epoch": 541.83,
      "learning_rate": 0.04583912168504823,
      "loss": 2.6489,
      "step": 337020
    },
    {
      "epoch": 541.86,
      "learning_rate": 0.045835906254180075,
      "loss": 2.6741,
      "step": 337040
    },
    {
      "epoch": 541.9,
      "learning_rate": 0.0458326908233119,
      "loss": 2.6816,
      "step": 337060
    },
    {
      "epoch": 541.93,
      "learning_rate": 0.04582963616398714,
      "loss": 2.6865,
      "step": 337080
    },
    {
      "epoch": 541.96,
      "learning_rate": 0.045826420733118975,
      "loss": 2.6684,
      "step": 337100
    },
    {
      "epoch": 541.99,
      "learning_rate": 0.045823205302250807,
      "loss": 2.6633,
      "step": 337120
    },
    {
      "epoch": 542.0,
      "eval_accuracy": {
        "accuracy": 0.4100132162015082
      },
      "eval_loss": 2.787581205368042,
      "eval_runtime": 2.9696,
      "eval_samples_per_second": 4331.508,
      "eval_steps_per_second": 67.685,
      "step": 337124
    },
    {
      "epoch": 542.03,
      "learning_rate": 0.04581998987138264,
      "loss": 2.6728,
      "step": 337140
    },
    {
      "epoch": 542.06,
      "learning_rate": 0.04581677444051447,
      "loss": 2.6416,
      "step": 337160
    },
    {
      "epoch": 542.09,
      "learning_rate": 0.04581355900964631,
      "loss": 2.6723,
      "step": 337180
    },
    {
      "epoch": 542.12,
      "learning_rate": 0.04581034357877814,
      "loss": 2.6469,
      "step": 337200
    },
    {
      "epoch": 542.15,
      "learning_rate": 0.04580712814790997,
      "loss": 2.6478,
      "step": 337220
    },
    {
      "epoch": 542.19,
      "learning_rate": 0.0458039127170418,
      "loss": 2.6481,
      "step": 337240
    },
    {
      "epoch": 542.22,
      "learning_rate": 0.045800697286173635,
      "loss": 2.6183,
      "step": 337260
    },
    {
      "epoch": 542.25,
      "learning_rate": 0.045797481855305466,
      "loss": 2.663,
      "step": 337280
    },
    {
      "epoch": 542.28,
      "learning_rate": 0.045794266424437305,
      "loss": 2.6473,
      "step": 337300
    },
    {
      "epoch": 542.32,
      "learning_rate": 0.045791050993569136,
      "loss": 2.6407,
      "step": 337320
    },
    {
      "epoch": 542.35,
      "learning_rate": 0.04578783556270097,
      "loss": 2.6369,
      "step": 337340
    },
    {
      "epoch": 542.38,
      "learning_rate": 0.0457846201318328,
      "loss": 2.6378,
      "step": 337360
    },
    {
      "epoch": 542.41,
      "learning_rate": 0.04578140470096463,
      "loss": 2.6696,
      "step": 337380
    },
    {
      "epoch": 542.44,
      "learning_rate": 0.04577818927009647,
      "loss": 2.6623,
      "step": 337400
    },
    {
      "epoch": 542.48,
      "learning_rate": 0.0457749738392283,
      "loss": 2.6535,
      "step": 337420
    },
    {
      "epoch": 542.51,
      "learning_rate": 0.04577175840836013,
      "loss": 2.6655,
      "step": 337440
    },
    {
      "epoch": 542.54,
      "learning_rate": 0.045768542977491965,
      "loss": 2.6409,
      "step": 337460
    },
    {
      "epoch": 542.57,
      "learning_rate": 0.045765327546623796,
      "loss": 2.6451,
      "step": 337480
    },
    {
      "epoch": 542.6,
      "learning_rate": 0.04576211211575563,
      "loss": 2.6597,
      "step": 337500
    },
    {
      "epoch": 542.64,
      "learning_rate": 0.045758896684887466,
      "loss": 2.6433,
      "step": 337520
    },
    {
      "epoch": 542.67,
      "learning_rate": 0.0457556812540193,
      "loss": 2.636,
      "step": 337540
    },
    {
      "epoch": 542.7,
      "learning_rate": 0.04575246582315113,
      "loss": 2.666,
      "step": 337560
    },
    {
      "epoch": 542.73,
      "learning_rate": 0.04574925039228296,
      "loss": 2.6793,
      "step": 337580
    },
    {
      "epoch": 542.77,
      "learning_rate": 0.04574603496141479,
      "loss": 2.6723,
      "step": 337600
    },
    {
      "epoch": 542.8,
      "learning_rate": 0.045742819530546625,
      "loss": 2.6595,
      "step": 337620
    },
    {
      "epoch": 542.83,
      "learning_rate": 0.04573960409967846,
      "loss": 2.6445,
      "step": 337640
    },
    {
      "epoch": 542.86,
      "learning_rate": 0.045736388668810295,
      "loss": 2.654,
      "step": 337660
    },
    {
      "epoch": 542.89,
      "learning_rate": 0.045733173237942126,
      "loss": 2.6422,
      "step": 337680
    },
    {
      "epoch": 542.93,
      "learning_rate": 0.04572995780707396,
      "loss": 2.6665,
      "step": 337700
    },
    {
      "epoch": 542.96,
      "learning_rate": 0.04572674237620579,
      "loss": 2.658,
      "step": 337720
    },
    {
      "epoch": 542.99,
      "learning_rate": 0.04572368771688103,
      "loss": 2.6878,
      "step": 337740
    },
    {
      "epoch": 543.0,
      "eval_accuracy": {
        "accuracy": 0.4055819015781699
      },
      "eval_loss": 2.7992868423461914,
      "eval_runtime": 2.9328,
      "eval_samples_per_second": 4385.914,
      "eval_steps_per_second": 68.535,
      "step": 337746
    },
    {
      "epoch": 543.02,
      "learning_rate": 0.04572047228601286,
      "loss": 2.6345,
      "step": 337760
    },
    {
      "epoch": 543.05,
      "learning_rate": 0.0457172568551447,
      "loss": 2.6435,
      "step": 337780
    },
    {
      "epoch": 543.09,
      "learning_rate": 0.045714041424276534,
      "loss": 2.659,
      "step": 337800
    },
    {
      "epoch": 543.12,
      "learning_rate": 0.045710825993408366,
      "loss": 2.6593,
      "step": 337820
    },
    {
      "epoch": 543.15,
      "learning_rate": 0.0457076105625402,
      "loss": 2.635,
      "step": 337840
    },
    {
      "epoch": 543.18,
      "learning_rate": 0.04570439513167203,
      "loss": 2.6657,
      "step": 337860
    },
    {
      "epoch": 543.22,
      "learning_rate": 0.04570117970080387,
      "loss": 2.6365,
      "step": 337880
    },
    {
      "epoch": 543.25,
      "learning_rate": 0.0456979642699357,
      "loss": 2.6542,
      "step": 337900
    },
    {
      "epoch": 543.28,
      "learning_rate": 0.04569474883906753,
      "loss": 2.6326,
      "step": 337920
    },
    {
      "epoch": 543.31,
      "learning_rate": 0.04569153340819936,
      "loss": 2.6552,
      "step": 337940
    },
    {
      "epoch": 543.34,
      "learning_rate": 0.045688317977331194,
      "loss": 2.6445,
      "step": 337960
    },
    {
      "epoch": 543.38,
      "learning_rate": 0.04568510254646302,
      "loss": 2.6659,
      "step": 337980
    },
    {
      "epoch": 543.41,
      "learning_rate": 0.045681887115594864,
      "loss": 2.6681,
      "step": 338000
    },
    {
      "epoch": 543.44,
      "learning_rate": 0.045678671684726696,
      "loss": 2.6402,
      "step": 338020
    },
    {
      "epoch": 543.47,
      "learning_rate": 0.04567545625385853,
      "loss": 2.6682,
      "step": 338040
    },
    {
      "epoch": 543.5,
      "learning_rate": 0.04567224082299036,
      "loss": 2.6337,
      "step": 338060
    },
    {
      "epoch": 543.54,
      "learning_rate": 0.045669025392122184,
      "loss": 2.6722,
      "step": 338080
    },
    {
      "epoch": 543.57,
      "learning_rate": 0.045665809961254016,
      "loss": 2.64,
      "step": 338100
    },
    {
      "epoch": 543.6,
      "learning_rate": 0.04566259453038586,
      "loss": 2.6619,
      "step": 338120
    },
    {
      "epoch": 543.63,
      "learning_rate": 0.04565937909951769,
      "loss": 2.649,
      "step": 338140
    },
    {
      "epoch": 543.67,
      "learning_rate": 0.045656163668649524,
      "loss": 2.6819,
      "step": 338160
    },
    {
      "epoch": 543.7,
      "learning_rate": 0.045652948237781356,
      "loss": 2.6558,
      "step": 338180
    },
    {
      "epoch": 543.73,
      "learning_rate": 0.04564973280691318,
      "loss": 2.6536,
      "step": 338200
    },
    {
      "epoch": 543.76,
      "learning_rate": 0.045646517376045026,
      "loss": 2.6582,
      "step": 338220
    },
    {
      "epoch": 543.79,
      "learning_rate": 0.04564330194517686,
      "loss": 2.6183,
      "step": 338240
    },
    {
      "epoch": 543.83,
      "learning_rate": 0.04564008651430869,
      "loss": 2.6413,
      "step": 338260
    },
    {
      "epoch": 543.86,
      "learning_rate": 0.04563687108344052,
      "loss": 2.6511,
      "step": 338280
    },
    {
      "epoch": 543.89,
      "learning_rate": 0.045633655652572346,
      "loss": 2.6597,
      "step": 338300
    },
    {
      "epoch": 543.92,
      "learning_rate": 0.04563044022170418,
      "loss": 2.6338,
      "step": 338320
    },
    {
      "epoch": 543.95,
      "learning_rate": 0.04562722479083602,
      "loss": 2.648,
      "step": 338340
    },
    {
      "epoch": 543.99,
      "learning_rate": 0.045624009359967854,
      "loss": 2.6693,
      "step": 338360
    },
    {
      "epoch": 544.0,
      "eval_accuracy": {
        "accuracy": 0.4166213169556091
      },
      "eval_loss": 2.7641782760620117,
      "eval_runtime": 3.2327,
      "eval_samples_per_second": 3979.033,
      "eval_steps_per_second": 62.177,
      "step": 338368
    },
    {
      "epoch": 544.02,
      "learning_rate": 0.045620793929099686,
      "loss": 2.6409,
      "step": 338380
    },
    {
      "epoch": 544.05,
      "learning_rate": 0.04561757849823151,
      "loss": 2.6507,
      "step": 338400
    },
    {
      "epoch": 544.08,
      "learning_rate": 0.04561436306736334,
      "loss": 2.6624,
      "step": 338420
    },
    {
      "epoch": 544.12,
      "learning_rate": 0.045611147636495174,
      "loss": 2.6584,
      "step": 338440
    },
    {
      "epoch": 544.15,
      "learning_rate": 0.04560793220562702,
      "loss": 2.67,
      "step": 338460
    },
    {
      "epoch": 544.18,
      "learning_rate": 0.04560471677475885,
      "loss": 2.6583,
      "step": 338480
    },
    {
      "epoch": 544.21,
      "learning_rate": 0.04560150134389068,
      "loss": 2.6375,
      "step": 338500
    },
    {
      "epoch": 544.24,
      "learning_rate": 0.04559828591302251,
      "loss": 2.6353,
      "step": 338520
    },
    {
      "epoch": 544.28,
      "learning_rate": 0.04559507048215434,
      "loss": 2.6531,
      "step": 338540
    },
    {
      "epoch": 544.31,
      "learning_rate": 0.045591855051286184,
      "loss": 2.653,
      "step": 338560
    },
    {
      "epoch": 544.34,
      "learning_rate": 0.045588639620418016,
      "loss": 2.6571,
      "step": 338580
    },
    {
      "epoch": 544.37,
      "learning_rate": 0.04558542418954985,
      "loss": 2.647,
      "step": 338600
    },
    {
      "epoch": 544.41,
      "learning_rate": 0.04558220875868167,
      "loss": 2.6576,
      "step": 338620
    },
    {
      "epoch": 544.44,
      "learning_rate": 0.045578993327813504,
      "loss": 2.6245,
      "step": 338640
    },
    {
      "epoch": 544.47,
      "learning_rate": 0.045575777896945335,
      "loss": 2.667,
      "step": 338660
    },
    {
      "epoch": 544.5,
      "learning_rate": 0.04557256246607718,
      "loss": 2.6264,
      "step": 338680
    },
    {
      "epoch": 544.53,
      "learning_rate": 0.04556934703520901,
      "loss": 2.6376,
      "step": 338700
    },
    {
      "epoch": 544.57,
      "learning_rate": 0.04556613160434084,
      "loss": 2.6556,
      "step": 338720
    },
    {
      "epoch": 544.6,
      "learning_rate": 0.04556291617347267,
      "loss": 2.6804,
      "step": 338740
    },
    {
      "epoch": 544.63,
      "learning_rate": 0.0455597007426045,
      "loss": 2.6488,
      "step": 338760
    },
    {
      "epoch": 544.66,
      "learning_rate": 0.045556485311736346,
      "loss": 2.6785,
      "step": 338780
    },
    {
      "epoch": 544.69,
      "learning_rate": 0.04555326988086818,
      "loss": 2.6626,
      "step": 338800
    },
    {
      "epoch": 544.73,
      "learning_rate": 0.04555005445000001,
      "loss": 2.6481,
      "step": 338820
    },
    {
      "epoch": 544.76,
      "learning_rate": 0.045546839019131834,
      "loss": 2.6484,
      "step": 338840
    },
    {
      "epoch": 544.79,
      "learning_rate": 0.045543623588263665,
      "loss": 2.6463,
      "step": 338860
    },
    {
      "epoch": 544.82,
      "learning_rate": 0.0455404081573955,
      "loss": 2.6422,
      "step": 338880
    },
    {
      "epoch": 544.86,
      "learning_rate": 0.04553719272652734,
      "loss": 2.6335,
      "step": 338900
    },
    {
      "epoch": 544.89,
      "learning_rate": 0.045533977295659174,
      "loss": 2.6416,
      "step": 338920
    },
    {
      "epoch": 544.92,
      "learning_rate": 0.045530761864791,
      "loss": 2.6477,
      "step": 338940
    },
    {
      "epoch": 544.95,
      "learning_rate": 0.04552754643392283,
      "loss": 2.6316,
      "step": 338960
    },
    {
      "epoch": 544.98,
      "learning_rate": 0.04552433100305466,
      "loss": 2.6486,
      "step": 338980
    },
    {
      "epoch": 545.0,
      "eval_accuracy": {
        "accuracy": 0.41638808987017023
      },
      "eval_loss": 2.770855188369751,
      "eval_runtime": 2.8446,
      "eval_samples_per_second": 4521.833,
      "eval_steps_per_second": 70.659,
      "step": 338990
    },
    {
      "epoch": 545.02,
      "learning_rate": 0.045521115572186494,
      "loss": 2.6495,
      "step": 339000
    },
    {
      "epoch": 545.05,
      "learning_rate": 0.04551790014131834,
      "loss": 2.6351,
      "step": 339020
    },
    {
      "epoch": 545.08,
      "learning_rate": 0.045514684710450164,
      "loss": 2.6396,
      "step": 339040
    },
    {
      "epoch": 545.11,
      "learning_rate": 0.045511469279581995,
      "loss": 2.6382,
      "step": 339060
    },
    {
      "epoch": 545.14,
      "learning_rate": 0.04550825384871383,
      "loss": 2.6437,
      "step": 339080
    },
    {
      "epoch": 545.18,
      "learning_rate": 0.04550503841784566,
      "loss": 2.6583,
      "step": 339100
    },
    {
      "epoch": 545.21,
      "learning_rate": 0.045501822986977504,
      "loss": 2.6636,
      "step": 339120
    },
    {
      "epoch": 545.24,
      "learning_rate": 0.045498607556109336,
      "loss": 2.6377,
      "step": 339140
    },
    {
      "epoch": 545.27,
      "learning_rate": 0.04549539212524116,
      "loss": 2.6446,
      "step": 339160
    },
    {
      "epoch": 545.31,
      "learning_rate": 0.04549217669437299,
      "loss": 2.6208,
      "step": 339180
    },
    {
      "epoch": 545.34,
      "learning_rate": 0.045488961263504823,
      "loss": 2.6632,
      "step": 339200
    },
    {
      "epoch": 545.37,
      "learning_rate": 0.045485745832636655,
      "loss": 2.6404,
      "step": 339220
    },
    {
      "epoch": 545.4,
      "learning_rate": 0.0454825304017685,
      "loss": 2.6305,
      "step": 339240
    },
    {
      "epoch": 545.43,
      "learning_rate": 0.045479314970900325,
      "loss": 2.6521,
      "step": 339260
    },
    {
      "epoch": 545.47,
      "learning_rate": 0.04547609954003216,
      "loss": 2.6443,
      "step": 339280
    },
    {
      "epoch": 545.5,
      "learning_rate": 0.04547288410916399,
      "loss": 2.6346,
      "step": 339300
    },
    {
      "epoch": 545.53,
      "learning_rate": 0.04546966867829582,
      "loss": 2.6508,
      "step": 339320
    },
    {
      "epoch": 545.56,
      "learning_rate": 0.04546645324742765,
      "loss": 2.6613,
      "step": 339340
    },
    {
      "epoch": 545.59,
      "learning_rate": 0.04546323781655949,
      "loss": 2.6567,
      "step": 339360
    },
    {
      "epoch": 545.63,
      "learning_rate": 0.04546002238569132,
      "loss": 2.6626,
      "step": 339380
    },
    {
      "epoch": 545.66,
      "learning_rate": 0.045456806954823153,
      "loss": 2.6548,
      "step": 339400
    },
    {
      "epoch": 545.69,
      "learning_rate": 0.045453591523954985,
      "loss": 2.6463,
      "step": 339420
    },
    {
      "epoch": 545.72,
      "learning_rate": 0.04545037609308682,
      "loss": 2.6741,
      "step": 339440
    },
    {
      "epoch": 545.76,
      "learning_rate": 0.04544716066221866,
      "loss": 2.6515,
      "step": 339460
    },
    {
      "epoch": 545.79,
      "learning_rate": 0.04544394523135049,
      "loss": 2.6596,
      "step": 339480
    },
    {
      "epoch": 545.82,
      "learning_rate": 0.04544072980048232,
      "loss": 2.6377,
      "step": 339500
    },
    {
      "epoch": 545.85,
      "learning_rate": 0.04543751436961415,
      "loss": 2.6602,
      "step": 339520
    },
    {
      "epoch": 545.88,
      "learning_rate": 0.04543429893874598,
      "loss": 2.6579,
      "step": 339540
    },
    {
      "epoch": 545.92,
      "learning_rate": 0.04543108350787781,
      "loss": 2.6534,
      "step": 339560
    },
    {
      "epoch": 545.95,
      "learning_rate": 0.04542786807700965,
      "loss": 2.6477,
      "step": 339580
    },
    {
      "epoch": 545.98,
      "learning_rate": 0.04542465264614148,
      "loss": 2.6682,
      "step": 339600
    },
    {
      "epoch": 546.0,
      "eval_accuracy": {
        "accuracy": 0.41957552670450127
      },
      "eval_loss": 2.7520103454589844,
      "eval_runtime": 2.9358,
      "eval_samples_per_second": 4381.467,
      "eval_steps_per_second": 68.466,
      "step": 339612
    },
    {
      "epoch": 546.01,
      "learning_rate": 0.045421437215273315,
      "loss": 2.6408,
      "step": 339620
    },
    {
      "epoch": 546.05,
      "learning_rate": 0.04541822178440515,
      "loss": 2.6354,
      "step": 339640
    },
    {
      "epoch": 546.08,
      "learning_rate": 0.04541500635353698,
      "loss": 2.6566,
      "step": 339660
    },
    {
      "epoch": 546.11,
      "learning_rate": 0.04541179092266881,
      "loss": 2.6386,
      "step": 339680
    },
    {
      "epoch": 546.14,
      "learning_rate": 0.04540857549180065,
      "loss": 2.6454,
      "step": 339700
    },
    {
      "epoch": 546.17,
      "learning_rate": 0.04540536006093248,
      "loss": 2.6407,
      "step": 339720
    },
    {
      "epoch": 546.21,
      "learning_rate": 0.04540214463006431,
      "loss": 2.6596,
      "step": 339740
    },
    {
      "epoch": 546.24,
      "learning_rate": 0.04539892919919614,
      "loss": 2.6517,
      "step": 339760
    },
    {
      "epoch": 546.27,
      "learning_rate": 0.045395713768327975,
      "loss": 2.6366,
      "step": 339780
    },
    {
      "epoch": 546.3,
      "learning_rate": 0.04539249833745981,
      "loss": 2.6531,
      "step": 339800
    },
    {
      "epoch": 546.33,
      "learning_rate": 0.045389282906591645,
      "loss": 2.6517,
      "step": 339820
    },
    {
      "epoch": 546.37,
      "learning_rate": 0.04538606747572348,
      "loss": 2.6612,
      "step": 339840
    },
    {
      "epoch": 546.4,
      "learning_rate": 0.04538285204485531,
      "loss": 2.6504,
      "step": 339860
    },
    {
      "epoch": 546.43,
      "learning_rate": 0.04537963661398714,
      "loss": 2.6496,
      "step": 339880
    },
    {
      "epoch": 546.46,
      "learning_rate": 0.04537642118311897,
      "loss": 2.6457,
      "step": 339900
    },
    {
      "epoch": 546.5,
      "learning_rate": 0.04537320575225081,
      "loss": 2.6304,
      "step": 339920
    },
    {
      "epoch": 546.53,
      "learning_rate": 0.04536999032138264,
      "loss": 2.6265,
      "step": 339940
    },
    {
      "epoch": 546.56,
      "learning_rate": 0.045366935662057885,
      "loss": 2.6581,
      "step": 339960
    },
    {
      "epoch": 546.59,
      "learning_rate": 0.045363720231189716,
      "loss": 2.6672,
      "step": 339980
    },
    {
      "epoch": 546.62,
      "learning_rate": 0.04536050480032155,
      "loss": 2.6573,
      "step": 340000
    },
    {
      "epoch": 546.66,
      "learning_rate": 0.04535728936945338,
      "loss": 2.6647,
      "step": 340020
    },
    {
      "epoch": 546.69,
      "learning_rate": 0.04535407393858521,
      "loss": 2.673,
      "step": 340040
    },
    {
      "epoch": 546.72,
      "learning_rate": 0.04535085850771705,
      "loss": 2.6605,
      "step": 340060
    },
    {
      "epoch": 546.75,
      "learning_rate": 0.04534764307684888,
      "loss": 2.6499,
      "step": 340080
    },
    {
      "epoch": 546.78,
      "learning_rate": 0.04534442764598071,
      "loss": 2.6478,
      "step": 340100
    },
    {
      "epoch": 546.82,
      "learning_rate": 0.045341212215112545,
      "loss": 2.6595,
      "step": 340120
    },
    {
      "epoch": 546.85,
      "learning_rate": 0.045337996784244376,
      "loss": 2.6574,
      "step": 340140
    },
    {
      "epoch": 546.88,
      "learning_rate": 0.04533478135337621,
      "loss": 2.6564,
      "step": 340160
    },
    {
      "epoch": 546.91,
      "learning_rate": 0.045331565922508046,
      "loss": 2.6452,
      "step": 340180
    },
    {
      "epoch": 546.95,
      "learning_rate": 0.04532835049163988,
      "loss": 2.6606,
      "step": 340200
    },
    {
      "epoch": 546.98,
      "learning_rate": 0.04532513506077171,
      "loss": 2.6388,
      "step": 340220
    },
    {
      "epoch": 547.0,
      "eval_accuracy": {
        "accuracy": 0.4164658322319832
      },
      "eval_loss": 2.7611396312713623,
      "eval_runtime": 2.8415,
      "eval_samples_per_second": 4526.823,
      "eval_steps_per_second": 70.737,
      "step": 340234
    },
    {
      "epoch": 547.01,
      "learning_rate": 0.04532191962990354,
      "loss": 2.6596,
      "step": 340240
    },
    {
      "epoch": 547.04,
      "learning_rate": 0.04531870419903537,
      "loss": 2.658,
      "step": 340260
    },
    {
      "epoch": 547.07,
      "learning_rate": 0.04531548876816721,
      "loss": 2.6379,
      "step": 340280
    },
    {
      "epoch": 547.11,
      "learning_rate": 0.04531227333729904,
      "loss": 2.6286,
      "step": 340300
    },
    {
      "epoch": 547.14,
      "learning_rate": 0.045309057906430875,
      "loss": 2.6499,
      "step": 340320
    },
    {
      "epoch": 547.17,
      "learning_rate": 0.045305842475562706,
      "loss": 2.6692,
      "step": 340340
    },
    {
      "epoch": 547.2,
      "learning_rate": 0.04530262704469454,
      "loss": 2.6465,
      "step": 340360
    },
    {
      "epoch": 547.23,
      "learning_rate": 0.04529941161382637,
      "loss": 2.6523,
      "step": 340380
    },
    {
      "epoch": 547.27,
      "learning_rate": 0.04529619618295821,
      "loss": 2.66,
      "step": 340400
    },
    {
      "epoch": 547.3,
      "learning_rate": 0.04529298075209004,
      "loss": 2.6279,
      "step": 340420
    },
    {
      "epoch": 547.33,
      "learning_rate": 0.04528976532122187,
      "loss": 2.6501,
      "step": 340440
    },
    {
      "epoch": 547.36,
      "learning_rate": 0.0452865498903537,
      "loss": 2.6353,
      "step": 340460
    },
    {
      "epoch": 547.4,
      "learning_rate": 0.045283334459485534,
      "loss": 2.6484,
      "step": 340480
    },
    {
      "epoch": 547.43,
      "learning_rate": 0.04528011902861736,
      "loss": 2.654,
      "step": 340500
    },
    {
      "epoch": 547.46,
      "learning_rate": 0.045276903597749205,
      "loss": 2.646,
      "step": 340520
    },
    {
      "epoch": 547.49,
      "learning_rate": 0.045273688166881036,
      "loss": 2.6593,
      "step": 340540
    },
    {
      "epoch": 547.52,
      "learning_rate": 0.04527047273601287,
      "loss": 2.6664,
      "step": 340560
    },
    {
      "epoch": 547.56,
      "learning_rate": 0.0452672573051447,
      "loss": 2.6576,
      "step": 340580
    },
    {
      "epoch": 547.59,
      "learning_rate": 0.045264041874276524,
      "loss": 2.65,
      "step": 340600
    },
    {
      "epoch": 547.62,
      "learning_rate": 0.04526082644340837,
      "loss": 2.6497,
      "step": 340620
    },
    {
      "epoch": 547.65,
      "learning_rate": 0.0452576110125402,
      "loss": 2.6712,
      "step": 340640
    },
    {
      "epoch": 547.68,
      "learning_rate": 0.04525439558167203,
      "loss": 2.6439,
      "step": 340660
    },
    {
      "epoch": 547.72,
      "learning_rate": 0.045251180150803864,
      "loss": 2.629,
      "step": 340680
    },
    {
      "epoch": 547.75,
      "learning_rate": 0.045247964719935696,
      "loss": 2.6414,
      "step": 340700
    },
    {
      "epoch": 547.78,
      "learning_rate": 0.04524474928906752,
      "loss": 2.6491,
      "step": 340720
    },
    {
      "epoch": 547.81,
      "learning_rate": 0.045241533858199366,
      "loss": 2.645,
      "step": 340740
    },
    {
      "epoch": 547.85,
      "learning_rate": 0.0452383184273312,
      "loss": 2.6679,
      "step": 340760
    },
    {
      "epoch": 547.88,
      "learning_rate": 0.04523510299646303,
      "loss": 2.6546,
      "step": 340780
    },
    {
      "epoch": 547.91,
      "learning_rate": 0.04523188756559486,
      "loss": 2.6424,
      "step": 340800
    },
    {
      "epoch": 547.94,
      "learning_rate": 0.045228672134726686,
      "loss": 2.6669,
      "step": 340820
    },
    {
      "epoch": 547.97,
      "learning_rate": 0.04522545670385852,
      "loss": 2.6351,
      "step": 340840
    },
    {
      "epoch": 548.0,
      "eval_accuracy": {
        "accuracy": 0.4191868148954365
      },
      "eval_loss": 2.7652575969696045,
      "eval_runtime": 3.2539,
      "eval_samples_per_second": 3953.071,
      "eval_steps_per_second": 61.772,
      "step": 340856
    },
    {
      "epoch": 548.01,
      "learning_rate": 0.04522224127299036,
      "loss": 2.659,
      "step": 340860
    },
    {
      "epoch": 548.04,
      "learning_rate": 0.045219025842122194,
      "loss": 2.6613,
      "step": 340880
    },
    {
      "epoch": 548.07,
      "learning_rate": 0.045215810411254026,
      "loss": 2.663,
      "step": 340900
    },
    {
      "epoch": 548.1,
      "learning_rate": 0.04521259498038585,
      "loss": 2.6391,
      "step": 340920
    },
    {
      "epoch": 548.14,
      "learning_rate": 0.04520937954951768,
      "loss": 2.663,
      "step": 340940
    },
    {
      "epoch": 548.17,
      "learning_rate": 0.04520616411864953,
      "loss": 2.6568,
      "step": 340960
    },
    {
      "epoch": 548.2,
      "learning_rate": 0.04520294868778136,
      "loss": 2.6513,
      "step": 340980
    },
    {
      "epoch": 548.23,
      "learning_rate": 0.04519973325691319,
      "loss": 2.6478,
      "step": 341000
    },
    {
      "epoch": 548.26,
      "learning_rate": 0.04519651782604502,
      "loss": 2.6595,
      "step": 341020
    },
    {
      "epoch": 548.3,
      "learning_rate": 0.04519330239517685,
      "loss": 2.6583,
      "step": 341040
    },
    {
      "epoch": 548.33,
      "learning_rate": 0.04519008696430868,
      "loss": 2.6658,
      "step": 341060
    },
    {
      "epoch": 548.36,
      "learning_rate": 0.045186871533440524,
      "loss": 2.6596,
      "step": 341080
    },
    {
      "epoch": 548.39,
      "learning_rate": 0.045183656102572356,
      "loss": 2.613,
      "step": 341100
    },
    {
      "epoch": 548.42,
      "learning_rate": 0.04518044067170419,
      "loss": 2.6485,
      "step": 341120
    },
    {
      "epoch": 548.46,
      "learning_rate": 0.04517722524083601,
      "loss": 2.6469,
      "step": 341140
    },
    {
      "epoch": 548.49,
      "learning_rate": 0.045174009809967844,
      "loss": 2.6724,
      "step": 341160
    },
    {
      "epoch": 548.52,
      "learning_rate": 0.045170794379099675,
      "loss": 2.64,
      "step": 341180
    },
    {
      "epoch": 548.55,
      "learning_rate": 0.04516757894823152,
      "loss": 2.6243,
      "step": 341200
    },
    {
      "epoch": 548.59,
      "learning_rate": 0.04516436351736335,
      "loss": 2.6243,
      "step": 341220
    },
    {
      "epoch": 548.62,
      "learning_rate": 0.04516114808649518,
      "loss": 2.6153,
      "step": 341240
    },
    {
      "epoch": 548.65,
      "learning_rate": 0.04515793265562701,
      "loss": 2.6573,
      "step": 341260
    },
    {
      "epoch": 548.68,
      "learning_rate": 0.04515471722475884,
      "loss": 2.6652,
      "step": 341280
    },
    {
      "epoch": 548.71,
      "learning_rate": 0.045151501793890686,
      "loss": 2.6436,
      "step": 341300
    },
    {
      "epoch": 548.75,
      "learning_rate": 0.04514828636302252,
      "loss": 2.646,
      "step": 341320
    },
    {
      "epoch": 548.78,
      "learning_rate": 0.04514507093215435,
      "loss": 2.6669,
      "step": 341340
    },
    {
      "epoch": 548.81,
      "learning_rate": 0.045141855501286174,
      "loss": 2.6481,
      "step": 341360
    },
    {
      "epoch": 548.84,
      "learning_rate": 0.045138640070418005,
      "loss": 2.6491,
      "step": 341380
    },
    {
      "epoch": 548.87,
      "learning_rate": 0.04513542463954984,
      "loss": 2.6391,
      "step": 341400
    },
    {
      "epoch": 548.91,
      "learning_rate": 0.04513220920868168,
      "loss": 2.6227,
      "step": 341420
    },
    {
      "epoch": 548.94,
      "learning_rate": 0.045128993777813514,
      "loss": 2.6386,
      "step": 341440
    },
    {
      "epoch": 548.97,
      "learning_rate": 0.04512577834694534,
      "loss": 2.6506,
      "step": 341460
    },
    {
      "epoch": 549.0,
      "eval_accuracy": {
        "accuracy": 0.42027520796081785
      },
      "eval_loss": 2.7548515796661377,
      "eval_runtime": 3.2925,
      "eval_samples_per_second": 3906.801,
      "eval_steps_per_second": 61.049,
      "step": 341478
    },
    {
      "epoch": 549.0,
      "learning_rate": 0.04512256291607717,
      "loss": 2.6469,
      "step": 341480
    },
    {
      "epoch": 549.04,
      "learning_rate": 0.045119347485209,
      "loss": 2.6365,
      "step": 341500
    },
    {
      "epoch": 549.07,
      "learning_rate": 0.04511613205434085,
      "loss": 2.6459,
      "step": 341520
    },
    {
      "epoch": 549.1,
      "learning_rate": 0.04511291662347268,
      "loss": 2.6591,
      "step": 341540
    },
    {
      "epoch": 549.13,
      "learning_rate": 0.045109701192604504,
      "loss": 2.6601,
      "step": 341560
    },
    {
      "epoch": 549.16,
      "learning_rate": 0.045106485761736335,
      "loss": 2.6652,
      "step": 341580
    },
    {
      "epoch": 549.2,
      "learning_rate": 0.04510327033086817,
      "loss": 2.6267,
      "step": 341600
    },
    {
      "epoch": 549.23,
      "learning_rate": 0.0451000549,
      "loss": 2.6471,
      "step": 341620
    },
    {
      "epoch": 549.26,
      "learning_rate": 0.045096839469131844,
      "loss": 2.6465,
      "step": 341640
    },
    {
      "epoch": 549.29,
      "learning_rate": 0.045093624038263676,
      "loss": 2.6778,
      "step": 341660
    },
    {
      "epoch": 549.32,
      "learning_rate": 0.0450904086073955,
      "loss": 2.645,
      "step": 341680
    },
    {
      "epoch": 549.36,
      "learning_rate": 0.04508719317652733,
      "loss": 2.653,
      "step": 341700
    },
    {
      "epoch": 549.39,
      "learning_rate": 0.045083977745659164,
      "loss": 2.6486,
      "step": 341720
    },
    {
      "epoch": 549.42,
      "learning_rate": 0.045080762314790995,
      "loss": 2.6397,
      "step": 341740
    },
    {
      "epoch": 549.45,
      "learning_rate": 0.04507754688392284,
      "loss": 2.6217,
      "step": 341760
    },
    {
      "epoch": 549.49,
      "learning_rate": 0.045074331453054665,
      "loss": 2.65,
      "step": 341780
    },
    {
      "epoch": 549.52,
      "learning_rate": 0.0450711160221865,
      "loss": 2.6271,
      "step": 341800
    },
    {
      "epoch": 549.55,
      "learning_rate": 0.04506790059131833,
      "loss": 2.6875,
      "step": 341820
    },
    {
      "epoch": 549.58,
      "learning_rate": 0.04506468516045016,
      "loss": 2.6768,
      "step": 341840
    },
    {
      "epoch": 549.61,
      "learning_rate": 0.045061469729582006,
      "loss": 2.6331,
      "step": 341860
    },
    {
      "epoch": 549.65,
      "learning_rate": 0.04505825429871383,
      "loss": 2.6288,
      "step": 341880
    },
    {
      "epoch": 549.68,
      "learning_rate": 0.04505503886784566,
      "loss": 2.6474,
      "step": 341900
    },
    {
      "epoch": 549.71,
      "learning_rate": 0.045051823436977494,
      "loss": 2.6464,
      "step": 341920
    },
    {
      "epoch": 549.74,
      "learning_rate": 0.045048608006109325,
      "loss": 2.658,
      "step": 341940
    },
    {
      "epoch": 549.77,
      "learning_rate": 0.04504539257524116,
      "loss": 2.62,
      "step": 341960
    },
    {
      "epoch": 549.81,
      "learning_rate": 0.045042177144373,
      "loss": 2.6469,
      "step": 341980
    },
    {
      "epoch": 549.84,
      "learning_rate": 0.04503896171350483,
      "loss": 2.6264,
      "step": 342000
    },
    {
      "epoch": 549.87,
      "learning_rate": 0.04503574628263666,
      "loss": 2.647,
      "step": 342020
    },
    {
      "epoch": 549.9,
      "learning_rate": 0.04503253085176849,
      "loss": 2.6131,
      "step": 342040
    },
    {
      "epoch": 549.94,
      "learning_rate": 0.04502931542090032,
      "loss": 2.6576,
      "step": 342060
    },
    {
      "epoch": 549.97,
      "learning_rate": 0.04502609999003215,
      "loss": 2.6688,
      "step": 342080
    },
    {
      "epoch": 550.0,
      "learning_rate": 0.04502288455916399,
      "loss": 2.6407,
      "step": 342100
    },
    {
      "epoch": 550.0,
      "eval_accuracy": {
        "accuracy": 0.4118012905232061
      },
      "eval_loss": 2.773951292037964,
      "eval_runtime": 3.0911,
      "eval_samples_per_second": 4161.26,
      "eval_steps_per_second": 65.025,
      "step": 342100
    },
    {
      "epoch": 550.03,
      "learning_rate": 0.045019669128295824,
      "loss": 2.6651,
      "step": 342120
    },
    {
      "epoch": 550.06,
      "learning_rate": 0.045016453697427655,
      "loss": 2.6386,
      "step": 342140
    },
    {
      "epoch": 550.1,
      "learning_rate": 0.04501323826655949,
      "loss": 2.6493,
      "step": 342160
    },
    {
      "epoch": 550.13,
      "learning_rate": 0.04501002283569132,
      "loss": 2.6457,
      "step": 342180
    },
    {
      "epoch": 550.16,
      "learning_rate": 0.04500680740482316,
      "loss": 2.6778,
      "step": 342200
    },
    {
      "epoch": 550.19,
      "learning_rate": 0.04500359197395499,
      "loss": 2.6683,
      "step": 342220
    },
    {
      "epoch": 550.23,
      "learning_rate": 0.04500053731463023,
      "loss": 2.6628,
      "step": 342240
    },
    {
      "epoch": 550.26,
      "learning_rate": 0.04499732188376206,
      "loss": 2.6579,
      "step": 342260
    },
    {
      "epoch": 550.29,
      "learning_rate": 0.044994106452893895,
      "loss": 2.6509,
      "step": 342280
    },
    {
      "epoch": 550.32,
      "learning_rate": 0.04499089102202573,
      "loss": 2.6476,
      "step": 342300
    },
    {
      "epoch": 550.35,
      "learning_rate": 0.04498767559115756,
      "loss": 2.6414,
      "step": 342320
    },
    {
      "epoch": 550.39,
      "learning_rate": 0.0449844601602894,
      "loss": 2.6296,
      "step": 342340
    },
    {
      "epoch": 550.42,
      "learning_rate": 0.04498124472942123,
      "loss": 2.6564,
      "step": 342360
    },
    {
      "epoch": 550.45,
      "learning_rate": 0.04497802929855306,
      "loss": 2.6503,
      "step": 342380
    },
    {
      "epoch": 550.48,
      "learning_rate": 0.04497481386768489,
      "loss": 2.6732,
      "step": 342400
    },
    {
      "epoch": 550.51,
      "learning_rate": 0.04497159843681672,
      "loss": 2.6168,
      "step": 342420
    },
    {
      "epoch": 550.55,
      "learning_rate": 0.044968383005948555,
      "loss": 2.6537,
      "step": 342440
    },
    {
      "epoch": 550.58,
      "learning_rate": 0.04496516757508039,
      "loss": 2.6502,
      "step": 342460
    },
    {
      "epoch": 550.61,
      "learning_rate": 0.044961952144212225,
      "loss": 2.6625,
      "step": 342480
    },
    {
      "epoch": 550.64,
      "learning_rate": 0.04495873671334406,
      "loss": 2.6352,
      "step": 342500
    },
    {
      "epoch": 550.68,
      "learning_rate": 0.04495552128247589,
      "loss": 2.6445,
      "step": 342520
    },
    {
      "epoch": 550.71,
      "learning_rate": 0.04495230585160772,
      "loss": 2.6447,
      "step": 342540
    },
    {
      "epoch": 550.74,
      "learning_rate": 0.04494909042073955,
      "loss": 2.6336,
      "step": 342560
    },
    {
      "epoch": 550.77,
      "learning_rate": 0.04494587498987139,
      "loss": 2.6747,
      "step": 342580
    },
    {
      "epoch": 550.8,
      "learning_rate": 0.04494265955900322,
      "loss": 2.652,
      "step": 342600
    },
    {
      "epoch": 550.84,
      "learning_rate": 0.04493944412813505,
      "loss": 2.6677,
      "step": 342620
    },
    {
      "epoch": 550.87,
      "learning_rate": 0.044936228697266885,
      "loss": 2.6422,
      "step": 342640
    },
    {
      "epoch": 550.9,
      "learning_rate": 0.044933013266398716,
      "loss": 2.6202,
      "step": 342660
    },
    {
      "epoch": 550.93,
      "learning_rate": 0.044929797835530555,
      "loss": 2.6113,
      "step": 342680
    },
    {
      "epoch": 550.96,
      "learning_rate": 0.04492658240466239,
      "loss": 2.6509,
      "step": 342700
    },
    {
      "epoch": 551.0,
      "learning_rate": 0.04492336697379422,
      "loss": 2.6651,
      "step": 342720
    },
    {
      "epoch": 551.0,
      "eval_accuracy": {
        "accuracy": 0.41537743916660186
      },
      "eval_loss": 2.7473249435424805,
      "eval_runtime": 2.958,
      "eval_samples_per_second": 4348.557,
      "eval_steps_per_second": 67.951,
      "step": 342722
    },
    {
      "epoch": 551.03,
      "learning_rate": 0.04492015154292605,
      "loss": 2.6412,
      "step": 342740
    },
    {
      "epoch": 551.06,
      "learning_rate": 0.04491693611205788,
      "loss": 2.6622,
      "step": 342760
    },
    {
      "epoch": 551.09,
      "learning_rate": 0.04491372068118971,
      "loss": 2.6376,
      "step": 342780
    },
    {
      "epoch": 551.13,
      "learning_rate": 0.04491050525032155,
      "loss": 2.6253,
      "step": 342800
    },
    {
      "epoch": 551.16,
      "learning_rate": 0.04490728981945338,
      "loss": 2.6407,
      "step": 342820
    },
    {
      "epoch": 551.19,
      "learning_rate": 0.044904074388585215,
      "loss": 2.6549,
      "step": 342840
    },
    {
      "epoch": 551.22,
      "learning_rate": 0.044900858957717046,
      "loss": 2.6575,
      "step": 342860
    },
    {
      "epoch": 551.25,
      "learning_rate": 0.04489764352684888,
      "loss": 2.6347,
      "step": 342880
    },
    {
      "epoch": 551.29,
      "learning_rate": 0.04489442809598071,
      "loss": 2.6501,
      "step": 342900
    },
    {
      "epoch": 551.32,
      "learning_rate": 0.04489121266511255,
      "loss": 2.6423,
      "step": 342920
    },
    {
      "epoch": 551.35,
      "learning_rate": 0.04488799723424438,
      "loss": 2.6333,
      "step": 342940
    },
    {
      "epoch": 551.38,
      "learning_rate": 0.04488478180337621,
      "loss": 2.667,
      "step": 342960
    },
    {
      "epoch": 551.41,
      "learning_rate": 0.04488156637250804,
      "loss": 2.6399,
      "step": 342980
    },
    {
      "epoch": 551.45,
      "learning_rate": 0.044878350941639875,
      "loss": 2.6567,
      "step": 343000
    },
    {
      "epoch": 551.48,
      "learning_rate": 0.04487513551077171,
      "loss": 2.651,
      "step": 343020
    },
    {
      "epoch": 551.51,
      "learning_rate": 0.044871920079903545,
      "loss": 2.6551,
      "step": 343040
    },
    {
      "epoch": 551.54,
      "learning_rate": 0.044868704649035376,
      "loss": 2.6565,
      "step": 343060
    },
    {
      "epoch": 551.58,
      "learning_rate": 0.04486548921816721,
      "loss": 2.6497,
      "step": 343080
    },
    {
      "epoch": 551.61,
      "learning_rate": 0.04486227378729904,
      "loss": 2.6474,
      "step": 343100
    },
    {
      "epoch": 551.64,
      "learning_rate": 0.044859058356430864,
      "loss": 2.6496,
      "step": 343120
    },
    {
      "epoch": 551.67,
      "learning_rate": 0.04485584292556271,
      "loss": 2.6161,
      "step": 343140
    },
    {
      "epoch": 551.7,
      "learning_rate": 0.04485262749469454,
      "loss": 2.6228,
      "step": 343160
    },
    {
      "epoch": 551.74,
      "learning_rate": 0.04484941206382637,
      "loss": 2.646,
      "step": 343180
    },
    {
      "epoch": 551.77,
      "learning_rate": 0.044846196632958205,
      "loss": 2.6442,
      "step": 343200
    },
    {
      "epoch": 551.8,
      "learning_rate": 0.044842981202090036,
      "loss": 2.6531,
      "step": 343220
    },
    {
      "epoch": 551.83,
      "learning_rate": 0.04483976577122186,
      "loss": 2.6951,
      "step": 343240
    },
    {
      "epoch": 551.86,
      "learning_rate": 0.044836550340353706,
      "loss": 2.675,
      "step": 343260
    },
    {
      "epoch": 551.9,
      "learning_rate": 0.04483333490948554,
      "loss": 2.6389,
      "step": 343280
    },
    {
      "epoch": 551.93,
      "learning_rate": 0.04483011947861737,
      "loss": 2.6552,
      "step": 343300
    },
    {
      "epoch": 551.96,
      "learning_rate": 0.0448269040477492,
      "loss": 2.6455,
      "step": 343320
    },
    {
      "epoch": 551.99,
      "learning_rate": 0.044823688616881026,
      "loss": 2.6524,
      "step": 343340
    },
    {
      "epoch": 552.0,
      "eval_accuracy": {
        "accuracy": 0.41460001554847237
      },
      "eval_loss": 2.765960931777954,
      "eval_runtime": 3.099,
      "eval_samples_per_second": 4150.704,
      "eval_steps_per_second": 64.86,
      "step": 343344
    },
    {
      "epoch": 552.03,
      "learning_rate": 0.04482047318601287,
      "loss": 2.6494,
      "step": 343360
    },
    {
      "epoch": 552.06,
      "learning_rate": 0.0448172577551447,
      "loss": 2.6275,
      "step": 343380
    },
    {
      "epoch": 552.09,
      "learning_rate": 0.044814042324276535,
      "loss": 2.6409,
      "step": 343400
    },
    {
      "epoch": 552.12,
      "learning_rate": 0.044810826893408366,
      "loss": 2.648,
      "step": 343420
    },
    {
      "epoch": 552.15,
      "learning_rate": 0.04480761146254019,
      "loss": 2.6692,
      "step": 343440
    },
    {
      "epoch": 552.19,
      "learning_rate": 0.04480439603167202,
      "loss": 2.6458,
      "step": 343460
    },
    {
      "epoch": 552.22,
      "learning_rate": 0.04480118060080387,
      "loss": 2.6153,
      "step": 343480
    },
    {
      "epoch": 552.25,
      "learning_rate": 0.0447979651699357,
      "loss": 2.6466,
      "step": 343500
    },
    {
      "epoch": 552.28,
      "learning_rate": 0.04479474973906753,
      "loss": 2.6389,
      "step": 343520
    },
    {
      "epoch": 552.32,
      "learning_rate": 0.04479153430819936,
      "loss": 2.6276,
      "step": 343540
    },
    {
      "epoch": 552.35,
      "learning_rate": 0.04478831887733119,
      "loss": 2.6623,
      "step": 343560
    },
    {
      "epoch": 552.38,
      "learning_rate": 0.04478510344646302,
      "loss": 2.6629,
      "step": 343580
    },
    {
      "epoch": 552.41,
      "learning_rate": 0.044781888015594865,
      "loss": 2.652,
      "step": 343600
    },
    {
      "epoch": 552.44,
      "learning_rate": 0.044778672584726696,
      "loss": 2.6604,
      "step": 343620
    },
    {
      "epoch": 552.48,
      "learning_rate": 0.04477545715385853,
      "loss": 2.642,
      "step": 343640
    },
    {
      "epoch": 552.51,
      "learning_rate": 0.04477224172299035,
      "loss": 2.6501,
      "step": 343660
    },
    {
      "epoch": 552.54,
      "learning_rate": 0.044769026292122184,
      "loss": 2.6309,
      "step": 343680
    },
    {
      "epoch": 552.57,
      "learning_rate": 0.04476581086125403,
      "loss": 2.6451,
      "step": 343700
    },
    {
      "epoch": 552.6,
      "learning_rate": 0.04476259543038586,
      "loss": 2.6107,
      "step": 343720
    },
    {
      "epoch": 552.64,
      "learning_rate": 0.04475937999951769,
      "loss": 2.6466,
      "step": 343740
    },
    {
      "epoch": 552.67,
      "learning_rate": 0.04475616456864952,
      "loss": 2.6679,
      "step": 343760
    },
    {
      "epoch": 552.7,
      "learning_rate": 0.04475294913778135,
      "loss": 2.654,
      "step": 343780
    },
    {
      "epoch": 552.73,
      "learning_rate": 0.04474973370691318,
      "loss": 2.627,
      "step": 343800
    },
    {
      "epoch": 552.77,
      "learning_rate": 0.044746518276045026,
      "loss": 2.665,
      "step": 343820
    },
    {
      "epoch": 552.8,
      "learning_rate": 0.04474330284517686,
      "loss": 2.6471,
      "step": 343840
    },
    {
      "epoch": 552.83,
      "learning_rate": 0.04474008741430869,
      "loss": 2.6165,
      "step": 343860
    },
    {
      "epoch": 552.86,
      "learning_rate": 0.044736871983440514,
      "loss": 2.6434,
      "step": 343880
    },
    {
      "epoch": 552.89,
      "learning_rate": 0.044733656552572346,
      "loss": 2.6184,
      "step": 343900
    },
    {
      "epoch": 552.93,
      "learning_rate": 0.04473044112170419,
      "loss": 2.6305,
      "step": 343920
    },
    {
      "epoch": 552.96,
      "learning_rate": 0.04472722569083602,
      "loss": 2.6391,
      "step": 343940
    },
    {
      "epoch": 552.99,
      "learning_rate": 0.044724010259967854,
      "loss": 2.6681,
      "step": 343960
    },
    {
      "epoch": 553.0,
      "eval_accuracy": {
        "accuracy": 0.4128896835885874
      },
      "eval_loss": 2.8066158294677734,
      "eval_runtime": 2.8414,
      "eval_samples_per_second": 4526.984,
      "eval_steps_per_second": 70.74,
      "step": 343966
    },
    {
      "epoch": 553.02,
      "learning_rate": 0.04472079482909968,
      "loss": 2.6734,
      "step": 343980
    },
    {
      "epoch": 553.05,
      "learning_rate": 0.04471757939823151,
      "loss": 2.6473,
      "step": 344000
    },
    {
      "epoch": 553.09,
      "learning_rate": 0.04471436396736334,
      "loss": 2.6081,
      "step": 344020
    },
    {
      "epoch": 553.12,
      "learning_rate": 0.04471114853649519,
      "loss": 2.6325,
      "step": 344040
    },
    {
      "epoch": 553.15,
      "learning_rate": 0.04470793310562702,
      "loss": 2.6341,
      "step": 344060
    },
    {
      "epoch": 553.18,
      "learning_rate": 0.044704717674758844,
      "loss": 2.6374,
      "step": 344080
    },
    {
      "epoch": 553.22,
      "learning_rate": 0.044701502243890676,
      "loss": 2.6327,
      "step": 344100
    },
    {
      "epoch": 553.25,
      "learning_rate": 0.04469828681302251,
      "loss": 2.6443,
      "step": 344120
    },
    {
      "epoch": 553.28,
      "learning_rate": 0.04469507138215434,
      "loss": 2.6543,
      "step": 344140
    },
    {
      "epoch": 553.31,
      "learning_rate": 0.044691855951286184,
      "loss": 2.6315,
      "step": 344160
    },
    {
      "epoch": 553.34,
      "learning_rate": 0.044688640520418016,
      "loss": 2.6439,
      "step": 344180
    },
    {
      "epoch": 553.38,
      "learning_rate": 0.04468542508954984,
      "loss": 2.6642,
      "step": 344200
    },
    {
      "epoch": 553.41,
      "learning_rate": 0.04468220965868167,
      "loss": 2.637,
      "step": 344220
    },
    {
      "epoch": 553.44,
      "learning_rate": 0.044678994227813504,
      "loss": 2.6376,
      "step": 344240
    },
    {
      "epoch": 553.47,
      "learning_rate": 0.04467577879694535,
      "loss": 2.6528,
      "step": 344260
    },
    {
      "epoch": 553.5,
      "learning_rate": 0.04467256336607718,
      "loss": 2.6737,
      "step": 344280
    },
    {
      "epoch": 553.54,
      "learning_rate": 0.044669347935209006,
      "loss": 2.6311,
      "step": 344300
    },
    {
      "epoch": 553.57,
      "learning_rate": 0.04466613250434084,
      "loss": 2.6511,
      "step": 344320
    },
    {
      "epoch": 553.6,
      "learning_rate": 0.04466307784501608,
      "loss": 2.6597,
      "step": 344340
    },
    {
      "epoch": 553.63,
      "learning_rate": 0.04465986241414791,
      "loss": 2.656,
      "step": 344360
    },
    {
      "epoch": 553.67,
      "learning_rate": 0.044656646983279744,
      "loss": 2.6521,
      "step": 344380
    },
    {
      "epoch": 553.7,
      "learning_rate": 0.044653431552411575,
      "loss": 2.6394,
      "step": 344400
    },
    {
      "epoch": 553.73,
      "learning_rate": 0.044650216121543414,
      "loss": 2.6661,
      "step": 344420
    },
    {
      "epoch": 553.76,
      "learning_rate": 0.044647000690675245,
      "loss": 2.656,
      "step": 344440
    },
    {
      "epoch": 553.79,
      "learning_rate": 0.04464378525980708,
      "loss": 2.6788,
      "step": 344460
    },
    {
      "epoch": 553.83,
      "learning_rate": 0.04464056982893891,
      "loss": 2.6511,
      "step": 344480
    },
    {
      "epoch": 553.86,
      "learning_rate": 0.04463735439807074,
      "loss": 2.6597,
      "step": 344500
    },
    {
      "epoch": 553.89,
      "learning_rate": 0.04463413896720258,
      "loss": 2.6599,
      "step": 344520
    },
    {
      "epoch": 553.92,
      "learning_rate": 0.04463092353633441,
      "loss": 2.6423,
      "step": 344540
    },
    {
      "epoch": 553.95,
      "learning_rate": 0.04462770810546624,
      "loss": 2.6382,
      "step": 344560
    },
    {
      "epoch": 553.99,
      "learning_rate": 0.044624492674598074,
      "loss": 2.6582,
      "step": 344580
    },
    {
      "epoch": 554.0,
      "eval_accuracy": {
        "accuracy": 0.4190313301718106
      },
      "eval_loss": 2.7421655654907227,
      "eval_runtime": 3.0538,
      "eval_samples_per_second": 4212.064,
      "eval_steps_per_second": 65.819,
      "step": 344588
    },
    {
      "epoch": 554.02,
      "learning_rate": 0.044621277243729905,
      "loss": 2.6385,
      "step": 344600
    },
    {
      "epoch": 554.05,
      "learning_rate": 0.04461806181286174,
      "loss": 2.615,
      "step": 344620
    },
    {
      "epoch": 554.08,
      "learning_rate": 0.044614846381993575,
      "loss": 2.65,
      "step": 344640
    },
    {
      "epoch": 554.12,
      "learning_rate": 0.04461163095112541,
      "loss": 2.665,
      "step": 344660
    },
    {
      "epoch": 554.15,
      "learning_rate": 0.04460841552025724,
      "loss": 2.6735,
      "step": 344680
    },
    {
      "epoch": 554.18,
      "learning_rate": 0.04460520008938907,
      "loss": 2.6339,
      "step": 344700
    },
    {
      "epoch": 554.21,
      "learning_rate": 0.0446019846585209,
      "loss": 2.6194,
      "step": 344720
    },
    {
      "epoch": 554.24,
      "learning_rate": 0.04459876922765274,
      "loss": 2.6144,
      "step": 344740
    },
    {
      "epoch": 554.28,
      "learning_rate": 0.04459555379678457,
      "loss": 2.6423,
      "step": 344760
    },
    {
      "epoch": 554.31,
      "learning_rate": 0.044592338365916404,
      "loss": 2.6126,
      "step": 344780
    },
    {
      "epoch": 554.34,
      "learning_rate": 0.044589122935048235,
      "loss": 2.6435,
      "step": 344800
    },
    {
      "epoch": 554.37,
      "learning_rate": 0.04458590750418007,
      "loss": 2.6385,
      "step": 344820
    },
    {
      "epoch": 554.41,
      "learning_rate": 0.0445826920733119,
      "loss": 2.6305,
      "step": 344840
    },
    {
      "epoch": 554.44,
      "learning_rate": 0.04457947664244374,
      "loss": 2.6491,
      "step": 344860
    },
    {
      "epoch": 554.47,
      "learning_rate": 0.04457626121157557,
      "loss": 2.6467,
      "step": 344880
    },
    {
      "epoch": 554.5,
      "learning_rate": 0.0445730457807074,
      "loss": 2.6268,
      "step": 344900
    },
    {
      "epoch": 554.53,
      "learning_rate": 0.04456983034983923,
      "loss": 2.641,
      "step": 344920
    },
    {
      "epoch": 554.57,
      "learning_rate": 0.04456661491897106,
      "loss": 2.6427,
      "step": 344940
    },
    {
      "epoch": 554.6,
      "learning_rate": 0.044563399488102895,
      "loss": 2.6531,
      "step": 344960
    },
    {
      "epoch": 554.63,
      "learning_rate": 0.044560184057234734,
      "loss": 2.6254,
      "step": 344980
    },
    {
      "epoch": 554.66,
      "learning_rate": 0.044556968626366565,
      "loss": 2.6383,
      "step": 345000
    },
    {
      "epoch": 554.69,
      "learning_rate": 0.0445537531954984,
      "loss": 2.6449,
      "step": 345020
    },
    {
      "epoch": 554.73,
      "learning_rate": 0.04455053776463023,
      "loss": 2.643,
      "step": 345040
    },
    {
      "epoch": 554.76,
      "learning_rate": 0.04454732233376206,
      "loss": 2.6543,
      "step": 345060
    },
    {
      "epoch": 554.79,
      "learning_rate": 0.0445441069028939,
      "loss": 2.6457,
      "step": 345080
    },
    {
      "epoch": 554.82,
      "learning_rate": 0.04454089147202573,
      "loss": 2.6421,
      "step": 345100
    },
    {
      "epoch": 554.86,
      "learning_rate": 0.04453767604115756,
      "loss": 2.6471,
      "step": 345120
    },
    {
      "epoch": 554.89,
      "learning_rate": 0.04453446061028939,
      "loss": 2.6471,
      "step": 345140
    },
    {
      "epoch": 554.92,
      "learning_rate": 0.044531245179421225,
      "loss": 2.6586,
      "step": 345160
    },
    {
      "epoch": 554.95,
      "learning_rate": 0.04452802974855306,
      "loss": 2.651,
      "step": 345180
    },
    {
      "epoch": 554.98,
      "learning_rate": 0.044524814317684895,
      "loss": 2.6714,
      "step": 345200
    },
    {
      "epoch": 555.0,
      "eval_accuracy": {
        "accuracy": 0.4196532690663142
      },
      "eval_loss": 2.7423229217529297,
      "eval_runtime": 2.8244,
      "eval_samples_per_second": 4554.268,
      "eval_steps_per_second": 71.166,
      "step": 345210
    },
    {
      "epoch": 555.02,
      "learning_rate": 0.04452159888681673,
      "loss": 2.6396,
      "step": 345220
    },
    {
      "epoch": 555.05,
      "learning_rate": 0.04451838345594856,
      "loss": 2.6258,
      "step": 345240
    },
    {
      "epoch": 555.08,
      "learning_rate": 0.04451516802508039,
      "loss": 2.668,
      "step": 345260
    },
    {
      "epoch": 555.11,
      "learning_rate": 0.04451195259421222,
      "loss": 2.6357,
      "step": 345280
    },
    {
      "epoch": 555.14,
      "learning_rate": 0.04450873716334405,
      "loss": 2.5926,
      "step": 345300
    },
    {
      "epoch": 555.18,
      "learning_rate": 0.04450552173247589,
      "loss": 2.6484,
      "step": 345320
    },
    {
      "epoch": 555.21,
      "learning_rate": 0.04450230630160772,
      "loss": 2.6816,
      "step": 345340
    },
    {
      "epoch": 555.24,
      "learning_rate": 0.044499090870739555,
      "loss": 2.6496,
      "step": 345360
    },
    {
      "epoch": 555.27,
      "learning_rate": 0.04449587543987139,
      "loss": 2.6484,
      "step": 345380
    },
    {
      "epoch": 555.31,
      "learning_rate": 0.04449266000900322,
      "loss": 2.6595,
      "step": 345400
    },
    {
      "epoch": 555.34,
      "learning_rate": 0.04448944457813506,
      "loss": 2.665,
      "step": 345420
    },
    {
      "epoch": 555.37,
      "learning_rate": 0.04448622914726689,
      "loss": 2.6517,
      "step": 345440
    },
    {
      "epoch": 555.4,
      "learning_rate": 0.04448301371639872,
      "loss": 2.6664,
      "step": 345460
    },
    {
      "epoch": 555.43,
      "learning_rate": 0.04447979828553055,
      "loss": 2.6714,
      "step": 345480
    },
    {
      "epoch": 555.47,
      "learning_rate": 0.04447658285466238,
      "loss": 2.6508,
      "step": 345500
    },
    {
      "epoch": 555.5,
      "learning_rate": 0.044473367423794215,
      "loss": 2.6264,
      "step": 345520
    },
    {
      "epoch": 555.53,
      "learning_rate": 0.04447015199292605,
      "loss": 2.639,
      "step": 345540
    },
    {
      "epoch": 555.56,
      "learning_rate": 0.044466936562057885,
      "loss": 2.6459,
      "step": 345560
    },
    {
      "epoch": 555.59,
      "learning_rate": 0.044463721131189717,
      "loss": 2.6469,
      "step": 345580
    },
    {
      "epoch": 555.63,
      "learning_rate": 0.04446050570032155,
      "loss": 2.6644,
      "step": 345600
    },
    {
      "epoch": 555.66,
      "learning_rate": 0.04445729026945338,
      "loss": 2.6366,
      "step": 345620
    },
    {
      "epoch": 555.69,
      "learning_rate": 0.044454074838585204,
      "loss": 2.641,
      "step": 345640
    },
    {
      "epoch": 555.72,
      "learning_rate": 0.04445085940771705,
      "loss": 2.6427,
      "step": 345660
    },
    {
      "epoch": 555.76,
      "learning_rate": 0.04444764397684888,
      "loss": 2.6692,
      "step": 345680
    },
    {
      "epoch": 555.79,
      "learning_rate": 0.04444442854598071,
      "loss": 2.6301,
      "step": 345700
    },
    {
      "epoch": 555.82,
      "learning_rate": 0.044441213115112545,
      "loss": 2.6417,
      "step": 345720
    },
    {
      "epoch": 555.85,
      "learning_rate": 0.044437997684244376,
      "loss": 2.6456,
      "step": 345740
    },
    {
      "epoch": 555.88,
      "learning_rate": 0.044434782253376215,
      "loss": 2.6347,
      "step": 345760
    },
    {
      "epoch": 555.92,
      "learning_rate": 0.044431566822508047,
      "loss": 2.6584,
      "step": 345780
    },
    {
      "epoch": 555.95,
      "learning_rate": 0.04442835139163988,
      "loss": 2.6553,
      "step": 345800
    },
    {
      "epoch": 555.98,
      "learning_rate": 0.04442513596077171,
      "loss": 2.6389,
      "step": 345820
    },
    {
      "epoch": 556.0,
      "eval_accuracy": {
        "accuracy": 0.4224519940915805
      },
      "eval_loss": 2.750429391860962,
      "eval_runtime": 2.847,
      "eval_samples_per_second": 4518.11,
      "eval_steps_per_second": 70.601,
      "step": 345832
    },
    {
      "epoch": 556.01,
      "learning_rate": 0.04442192052990354,
      "loss": 2.6253,
      "step": 345840
    },
    {
      "epoch": 556.05,
      "learning_rate": 0.044418705099035366,
      "loss": 2.655,
      "step": 345860
    },
    {
      "epoch": 556.08,
      "learning_rate": 0.04441548966816721,
      "loss": 2.6291,
      "step": 345880
    },
    {
      "epoch": 556.11,
      "learning_rate": 0.04441227423729904,
      "loss": 2.6462,
      "step": 345900
    },
    {
      "epoch": 556.14,
      "learning_rate": 0.044409058806430875,
      "loss": 2.6602,
      "step": 345920
    },
    {
      "epoch": 556.17,
      "learning_rate": 0.044405843375562706,
      "loss": 2.6479,
      "step": 345940
    },
    {
      "epoch": 556.21,
      "learning_rate": 0.04440262794469453,
      "loss": 2.63,
      "step": 345960
    },
    {
      "epoch": 556.24,
      "learning_rate": 0.04439941251382636,
      "loss": 2.641,
      "step": 345980
    },
    {
      "epoch": 556.27,
      "learning_rate": 0.04439619708295821,
      "loss": 2.6479,
      "step": 346000
    },
    {
      "epoch": 556.3,
      "learning_rate": 0.04439298165209004,
      "loss": 2.6439,
      "step": 346020
    },
    {
      "epoch": 556.33,
      "learning_rate": 0.04438976622122187,
      "loss": 2.6424,
      "step": 346040
    },
    {
      "epoch": 556.37,
      "learning_rate": 0.0443865507903537,
      "loss": 2.6501,
      "step": 346060
    },
    {
      "epoch": 556.4,
      "learning_rate": 0.04438333535948553,
      "loss": 2.6341,
      "step": 346080
    },
    {
      "epoch": 556.43,
      "learning_rate": 0.04438011992861737,
      "loss": 2.642,
      "step": 346100
    },
    {
      "epoch": 556.46,
      "learning_rate": 0.044376904497749205,
      "loss": 2.6407,
      "step": 346120
    },
    {
      "epoch": 556.5,
      "learning_rate": 0.044373689066881036,
      "loss": 2.6226,
      "step": 346140
    },
    {
      "epoch": 556.53,
      "learning_rate": 0.04437047363601287,
      "loss": 2.6541,
      "step": 346160
    },
    {
      "epoch": 556.56,
      "learning_rate": 0.04436725820514469,
      "loss": 2.6662,
      "step": 346180
    },
    {
      "epoch": 556.59,
      "learning_rate": 0.044364042774276524,
      "loss": 2.6503,
      "step": 346200
    },
    {
      "epoch": 556.62,
      "learning_rate": 0.04436082734340837,
      "loss": 2.6417,
      "step": 346220
    },
    {
      "epoch": 556.66,
      "learning_rate": 0.0443576119125402,
      "loss": 2.6084,
      "step": 346240
    },
    {
      "epoch": 556.69,
      "learning_rate": 0.04435439648167203,
      "loss": 2.6337,
      "step": 346260
    },
    {
      "epoch": 556.72,
      "learning_rate": 0.04435118105080386,
      "loss": 2.6215,
      "step": 346280
    },
    {
      "epoch": 556.75,
      "learning_rate": 0.04434796561993569,
      "loss": 2.6604,
      "step": 346300
    },
    {
      "epoch": 556.78,
      "learning_rate": 0.04434475018906752,
      "loss": 2.6233,
      "step": 346320
    },
    {
      "epoch": 556.82,
      "learning_rate": 0.044341534758199366,
      "loss": 2.652,
      "step": 346340
    },
    {
      "epoch": 556.85,
      "learning_rate": 0.0443383193273312,
      "loss": 2.6276,
      "step": 346360
    },
    {
      "epoch": 556.88,
      "learning_rate": 0.04433510389646303,
      "loss": 2.6572,
      "step": 346380
    },
    {
      "epoch": 556.91,
      "learning_rate": 0.044331888465594854,
      "loss": 2.6555,
      "step": 346400
    },
    {
      "epoch": 556.95,
      "learning_rate": 0.044328673034726686,
      "loss": 2.6695,
      "step": 346420
    },
    {
      "epoch": 556.98,
      "learning_rate": 0.04432545760385853,
      "loss": 2.6515,
      "step": 346440
    },
    {
      "epoch": 557.0,
      "eval_accuracy": {
        "accuracy": 0.4176319676591775
      },
      "eval_loss": 2.7730016708374023,
      "eval_runtime": 2.9449,
      "eval_samples_per_second": 4367.859,
      "eval_steps_per_second": 68.253,
      "step": 346454
    },
    {
      "epoch": 557.01,
      "learning_rate": 0.04432224217299036,
      "loss": 2.6548,
      "step": 346460
    },
    {
      "epoch": 557.04,
      "learning_rate": 0.044319026742122195,
      "loss": 2.6348,
      "step": 346480
    },
    {
      "epoch": 557.07,
      "learning_rate": 0.04431581131125402,
      "loss": 2.6677,
      "step": 346500
    },
    {
      "epoch": 557.11,
      "learning_rate": 0.04431259588038585,
      "loss": 2.6447,
      "step": 346520
    },
    {
      "epoch": 557.14,
      "learning_rate": 0.04430938044951768,
      "loss": 2.6442,
      "step": 346540
    },
    {
      "epoch": 557.17,
      "learning_rate": 0.04430616501864953,
      "loss": 2.6227,
      "step": 346560
    },
    {
      "epoch": 557.2,
      "learning_rate": 0.04430294958778136,
      "loss": 2.6294,
      "step": 346580
    },
    {
      "epoch": 557.23,
      "learning_rate": 0.044299734156913184,
      "loss": 2.6298,
      "step": 346600
    },
    {
      "epoch": 557.27,
      "learning_rate": 0.044296518726045016,
      "loss": 2.6191,
      "step": 346620
    },
    {
      "epoch": 557.3,
      "learning_rate": 0.04429330329517685,
      "loss": 2.6592,
      "step": 346640
    },
    {
      "epoch": 557.33,
      "learning_rate": 0.04429008786430869,
      "loss": 2.6343,
      "step": 346660
    },
    {
      "epoch": 557.36,
      "learning_rate": 0.044286872433440524,
      "loss": 2.6428,
      "step": 346680
    },
    {
      "epoch": 557.4,
      "learning_rate": 0.044283657002572356,
      "loss": 2.6406,
      "step": 346700
    },
    {
      "epoch": 557.43,
      "learning_rate": 0.04428044157170418,
      "loss": 2.652,
      "step": 346720
    },
    {
      "epoch": 557.46,
      "learning_rate": 0.04427722614083601,
      "loss": 2.6309,
      "step": 346740
    },
    {
      "epoch": 557.49,
      "learning_rate": 0.044274010709967844,
      "loss": 2.6525,
      "step": 346760
    },
    {
      "epoch": 557.52,
      "learning_rate": 0.04427079527909969,
      "loss": 2.6747,
      "step": 346780
    },
    {
      "epoch": 557.56,
      "learning_rate": 0.04426757984823152,
      "loss": 2.667,
      "step": 346800
    },
    {
      "epoch": 557.59,
      "learning_rate": 0.044264364417363346,
      "loss": 2.6485,
      "step": 346820
    },
    {
      "epoch": 557.62,
      "learning_rate": 0.04426114898649518,
      "loss": 2.6497,
      "step": 346840
    },
    {
      "epoch": 557.65,
      "learning_rate": 0.04425809432717042,
      "loss": 2.6232,
      "step": 346860
    },
    {
      "epoch": 557.68,
      "learning_rate": 0.04425487889630225,
      "loss": 2.6444,
      "step": 346880
    },
    {
      "epoch": 557.72,
      "learning_rate": 0.044251663465434084,
      "loss": 2.6431,
      "step": 346900
    },
    {
      "epoch": 557.75,
      "learning_rate": 0.04424844803456592,
      "loss": 2.6147,
      "step": 346920
    },
    {
      "epoch": 557.78,
      "learning_rate": 0.044245232603697754,
      "loss": 2.6602,
      "step": 346940
    },
    {
      "epoch": 557.81,
      "learning_rate": 0.044242017172829586,
      "loss": 2.6401,
      "step": 346960
    },
    {
      "epoch": 557.85,
      "learning_rate": 0.04423880174196142,
      "loss": 2.6614,
      "step": 346980
    },
    {
      "epoch": 557.88,
      "learning_rate": 0.04423558631109325,
      "loss": 2.641,
      "step": 347000
    },
    {
      "epoch": 557.91,
      "learning_rate": 0.04423237088022508,
      "loss": 2.6781,
      "step": 347020
    },
    {
      "epoch": 557.94,
      "learning_rate": 0.04422915544935692,
      "loss": 2.6588,
      "step": 347040
    },
    {
      "epoch": 557.97,
      "learning_rate": 0.04422594001848875,
      "loss": 2.637,
      "step": 347060
    },
    {
      "epoch": 558.0,
      "eval_accuracy": {
        "accuracy": 0.4213636010261992
      },
      "eval_loss": 2.758657455444336,
      "eval_runtime": 3.0614,
      "eval_samples_per_second": 4201.656,
      "eval_steps_per_second": 65.656,
      "step": 347076
    },
    {
      "epoch": 558.01,
      "learning_rate": 0.04422272458762058,
      "loss": 2.6377,
      "step": 347080
    },
    {
      "epoch": 558.04,
      "learning_rate": 0.044219509156752414,
      "loss": 2.6241,
      "step": 347100
    },
    {
      "epoch": 558.07,
      "learning_rate": 0.044216293725884245,
      "loss": 2.64,
      "step": 347120
    },
    {
      "epoch": 558.1,
      "learning_rate": 0.04421307829501608,
      "loss": 2.6119,
      "step": 347140
    },
    {
      "epoch": 558.14,
      "learning_rate": 0.044209862864147915,
      "loss": 2.6338,
      "step": 347160
    },
    {
      "epoch": 558.17,
      "learning_rate": 0.04420664743327975,
      "loss": 2.6307,
      "step": 347180
    },
    {
      "epoch": 558.2,
      "learning_rate": 0.04420343200241158,
      "loss": 2.6186,
      "step": 347200
    },
    {
      "epoch": 558.23,
      "learning_rate": 0.04420021657154341,
      "loss": 2.6543,
      "step": 347220
    },
    {
      "epoch": 558.26,
      "learning_rate": 0.04419700114067524,
      "loss": 2.6417,
      "step": 347240
    },
    {
      "epoch": 558.3,
      "learning_rate": 0.04419378570980708,
      "loss": 2.6541,
      "step": 347260
    },
    {
      "epoch": 558.33,
      "learning_rate": 0.04419057027893891,
      "loss": 2.6508,
      "step": 347280
    },
    {
      "epoch": 558.36,
      "learning_rate": 0.044187354848070744,
      "loss": 2.6366,
      "step": 347300
    },
    {
      "epoch": 558.39,
      "learning_rate": 0.044184139417202575,
      "loss": 2.6542,
      "step": 347320
    },
    {
      "epoch": 558.42,
      "learning_rate": 0.04418092398633441,
      "loss": 2.633,
      "step": 347340
    },
    {
      "epoch": 558.46,
      "learning_rate": 0.04417770855546624,
      "loss": 2.6502,
      "step": 347360
    },
    {
      "epoch": 558.49,
      "learning_rate": 0.04417449312459808,
      "loss": 2.6321,
      "step": 347380
    },
    {
      "epoch": 558.52,
      "learning_rate": 0.04417127769372991,
      "loss": 2.6276,
      "step": 347400
    },
    {
      "epoch": 558.55,
      "learning_rate": 0.04416806226286174,
      "loss": 2.651,
      "step": 347420
    },
    {
      "epoch": 558.59,
      "learning_rate": 0.04416484683199357,
      "loss": 2.6577,
      "step": 347440
    },
    {
      "epoch": 558.62,
      "learning_rate": 0.044161631401125404,
      "loss": 2.6292,
      "step": 347460
    },
    {
      "epoch": 558.65,
      "learning_rate": 0.04415841597025724,
      "loss": 2.6219,
      "step": 347480
    },
    {
      "epoch": 558.68,
      "learning_rate": 0.044155200539389074,
      "loss": 2.6356,
      "step": 347500
    },
    {
      "epoch": 558.71,
      "learning_rate": 0.044151985108520905,
      "loss": 2.6427,
      "step": 347520
    },
    {
      "epoch": 558.75,
      "learning_rate": 0.04414876967765274,
      "loss": 2.622,
      "step": 347540
    },
    {
      "epoch": 558.78,
      "learning_rate": 0.04414555424678457,
      "loss": 2.6602,
      "step": 347560
    },
    {
      "epoch": 558.81,
      "learning_rate": 0.0441423388159164,
      "loss": 2.6366,
      "step": 347580
    },
    {
      "epoch": 558.84,
      "learning_rate": 0.04413912338504824,
      "loss": 2.6517,
      "step": 347600
    },
    {
      "epoch": 558.87,
      "learning_rate": 0.04413590795418007,
      "loss": 2.6429,
      "step": 347620
    },
    {
      "epoch": 558.91,
      "learning_rate": 0.0441326925233119,
      "loss": 2.6289,
      "step": 347640
    },
    {
      "epoch": 558.94,
      "learning_rate": 0.044129477092443734,
      "loss": 2.6244,
      "step": 347660
    },
    {
      "epoch": 558.97,
      "learning_rate": 0.044126261661575565,
      "loss": 2.6102,
      "step": 347680
    },
    {
      "epoch": 559.0,
      "eval_accuracy": {
        "accuracy": 0.4201974655990049
      },
      "eval_loss": 2.7483150959014893,
      "eval_runtime": 2.9083,
      "eval_samples_per_second": 4422.839,
      "eval_steps_per_second": 69.112,
      "step": 347698
    },
    {
      "epoch": 559.0,
      "learning_rate": 0.0441230462307074,
      "loss": 2.6541,
      "step": 347700
    },
    {
      "epoch": 559.04,
      "learning_rate": 0.044119830799839235,
      "loss": 2.6368,
      "step": 347720
    },
    {
      "epoch": 559.07,
      "learning_rate": 0.04411661536897107,
      "loss": 2.628,
      "step": 347740
    },
    {
      "epoch": 559.1,
      "learning_rate": 0.0441133999381029,
      "loss": 2.635,
      "step": 347760
    },
    {
      "epoch": 559.13,
      "learning_rate": 0.04411018450723473,
      "loss": 2.6224,
      "step": 347780
    },
    {
      "epoch": 559.16,
      "learning_rate": 0.04410696907636656,
      "loss": 2.6279,
      "step": 347800
    },
    {
      "epoch": 559.2,
      "learning_rate": 0.0441037536454984,
      "loss": 2.6557,
      "step": 347820
    },
    {
      "epoch": 559.23,
      "learning_rate": 0.04410053821463023,
      "loss": 2.635,
      "step": 347840
    },
    {
      "epoch": 559.26,
      "learning_rate": 0.044097322783762063,
      "loss": 2.6353,
      "step": 347860
    },
    {
      "epoch": 559.29,
      "learning_rate": 0.044094107352893895,
      "loss": 2.6501,
      "step": 347880
    },
    {
      "epoch": 559.32,
      "learning_rate": 0.04409089192202573,
      "loss": 2.631,
      "step": 347900
    },
    {
      "epoch": 559.36,
      "learning_rate": 0.04408767649115756,
      "loss": 2.626,
      "step": 347920
    },
    {
      "epoch": 559.39,
      "learning_rate": 0.0440844610602894,
      "loss": 2.6502,
      "step": 347940
    },
    {
      "epoch": 559.42,
      "learning_rate": 0.04408124562942123,
      "loss": 2.6415,
      "step": 347960
    },
    {
      "epoch": 559.45,
      "learning_rate": 0.04407803019855306,
      "loss": 2.6226,
      "step": 347980
    },
    {
      "epoch": 559.49,
      "learning_rate": 0.04407481476768489,
      "loss": 2.6267,
      "step": 348000
    },
    {
      "epoch": 559.52,
      "learning_rate": 0.04407159933681672,
      "loss": 2.6463,
      "step": 348020
    },
    {
      "epoch": 559.55,
      "learning_rate": 0.044068383905948555,
      "loss": 2.63,
      "step": 348040
    },
    {
      "epoch": 559.58,
      "learning_rate": 0.044065168475080393,
      "loss": 2.6368,
      "step": 348060
    },
    {
      "epoch": 559.61,
      "learning_rate": 0.044061953044212225,
      "loss": 2.6424,
      "step": 348080
    },
    {
      "epoch": 559.65,
      "learning_rate": 0.04405873761334406,
      "loss": 2.6588,
      "step": 348100
    },
    {
      "epoch": 559.68,
      "learning_rate": 0.04405552218247589,
      "loss": 2.6563,
      "step": 348120
    },
    {
      "epoch": 559.71,
      "learning_rate": 0.04405230675160772,
      "loss": 2.6793,
      "step": 348140
    },
    {
      "epoch": 559.74,
      "learning_rate": 0.04404909132073956,
      "loss": 2.6558,
      "step": 348160
    },
    {
      "epoch": 559.77,
      "learning_rate": 0.04404587588987139,
      "loss": 2.6235,
      "step": 348180
    },
    {
      "epoch": 559.81,
      "learning_rate": 0.04404266045900322,
      "loss": 2.6332,
      "step": 348200
    },
    {
      "epoch": 559.84,
      "learning_rate": 0.04403944502813505,
      "loss": 2.6572,
      "step": 348220
    },
    {
      "epoch": 559.87,
      "learning_rate": 0.044036229597266885,
      "loss": 2.6265,
      "step": 348240
    },
    {
      "epoch": 559.9,
      "learning_rate": 0.044033014166398717,
      "loss": 2.6169,
      "step": 348260
    },
    {
      "epoch": 559.94,
      "learning_rate": 0.044029798735530555,
      "loss": 2.6003,
      "step": 348280
    },
    {
      "epoch": 559.97,
      "learning_rate": 0.04402658330466239,
      "loss": 2.6249,
      "step": 348300
    },
    {
      "epoch": 560.0,
      "learning_rate": 0.04402336787379422,
      "loss": 2.6496,
      "step": 348320
    },
    {
      "epoch": 560.0,
      "eval_accuracy": {
        "accuracy": 0.4194200419808754
      },
      "eval_loss": 2.7541613578796387,
      "eval_runtime": 2.8546,
      "eval_samples_per_second": 4506.095,
      "eval_steps_per_second": 70.413,
      "step": 348320
    },
    {
      "epoch": 560.03,
      "learning_rate": 0.04402015244292605,
      "loss": 2.644,
      "step": 348340
    },
    {
      "epoch": 560.06,
      "learning_rate": 0.04401693701205788,
      "loss": 2.6485,
      "step": 348360
    },
    {
      "epoch": 560.1,
      "learning_rate": 0.044013721581189706,
      "loss": 2.6625,
      "step": 348380
    },
    {
      "epoch": 560.13,
      "learning_rate": 0.04401050615032155,
      "loss": 2.6459,
      "step": 348400
    },
    {
      "epoch": 560.16,
      "learning_rate": 0.04400729071945338,
      "loss": 2.6342,
      "step": 348420
    },
    {
      "epoch": 560.19,
      "learning_rate": 0.044004075288585215,
      "loss": 2.6296,
      "step": 348440
    },
    {
      "epoch": 560.23,
      "learning_rate": 0.044000859857717046,
      "loss": 2.6433,
      "step": 348460
    },
    {
      "epoch": 560.26,
      "learning_rate": 0.04399764442684887,
      "loss": 2.6325,
      "step": 348480
    },
    {
      "epoch": 560.29,
      "learning_rate": 0.04399442899598072,
      "loss": 2.6195,
      "step": 348500
    },
    {
      "epoch": 560.32,
      "learning_rate": 0.04399121356511255,
      "loss": 2.6466,
      "step": 348520
    },
    {
      "epoch": 560.35,
      "learning_rate": 0.04398799813424438,
      "loss": 2.656,
      "step": 348540
    },
    {
      "epoch": 560.39,
      "learning_rate": 0.04398478270337621,
      "loss": 2.6465,
      "step": 348560
    },
    {
      "epoch": 560.42,
      "learning_rate": 0.04398156727250804,
      "loss": 2.6358,
      "step": 348580
    },
    {
      "epoch": 560.45,
      "learning_rate": 0.04397835184163987,
      "loss": 2.6394,
      "step": 348600
    },
    {
      "epoch": 560.48,
      "learning_rate": 0.04397513641077171,
      "loss": 2.6348,
      "step": 348620
    },
    {
      "epoch": 560.51,
      "learning_rate": 0.043971920979903545,
      "loss": 2.6284,
      "step": 348640
    },
    {
      "epoch": 560.55,
      "learning_rate": 0.043968705549035376,
      "loss": 2.6403,
      "step": 348660
    },
    {
      "epoch": 560.58,
      "learning_rate": 0.04396549011816721,
      "loss": 2.617,
      "step": 348680
    },
    {
      "epoch": 560.61,
      "learning_rate": 0.04396227468729903,
      "loss": 2.6337,
      "step": 348700
    },
    {
      "epoch": 560.64,
      "learning_rate": 0.043959059256430864,
      "loss": 2.6555,
      "step": 348720
    },
    {
      "epoch": 560.68,
      "learning_rate": 0.04395584382556271,
      "loss": 2.6373,
      "step": 348740
    },
    {
      "epoch": 560.71,
      "learning_rate": 0.04395262839469454,
      "loss": 2.6329,
      "step": 348760
    },
    {
      "epoch": 560.74,
      "learning_rate": 0.04394941296382637,
      "loss": 2.6364,
      "step": 348780
    },
    {
      "epoch": 560.77,
      "learning_rate": 0.043946197532958205,
      "loss": 2.6337,
      "step": 348800
    },
    {
      "epoch": 560.8,
      "learning_rate": 0.04394298210209003,
      "loss": 2.6153,
      "step": 348820
    },
    {
      "epoch": 560.84,
      "learning_rate": 0.043939766671221875,
      "loss": 2.6303,
      "step": 348840
    },
    {
      "epoch": 560.87,
      "learning_rate": 0.043936551240353706,
      "loss": 2.6134,
      "step": 348860
    },
    {
      "epoch": 560.9,
      "learning_rate": 0.04393333580948554,
      "loss": 2.6411,
      "step": 348880
    },
    {
      "epoch": 560.93,
      "learning_rate": 0.04393012037861737,
      "loss": 2.6424,
      "step": 348900
    },
    {
      "epoch": 560.96,
      "learning_rate": 0.043926904947749194,
      "loss": 2.6311,
      "step": 348920
    },
    {
      "epoch": 561.0,
      "learning_rate": 0.043923689516881026,
      "loss": 2.6445,
      "step": 348940
    },
    {
      "epoch": 561.0,
      "eval_accuracy": {
        "accuracy": 0.41802067946824223
      },
      "eval_loss": 2.7569336891174316,
      "eval_runtime": 3.2056,
      "eval_samples_per_second": 4012.655,
      "eval_steps_per_second": 62.703,
      "step": 348942
    },
    {
      "epoch": 561.03,
      "learning_rate": 0.04392047408601287,
      "loss": 2.6179,
      "step": 348960
    },
    {
      "epoch": 561.06,
      "learning_rate": 0.0439172586551447,
      "loss": 2.649,
      "step": 348980
    },
    {
      "epoch": 561.09,
      "learning_rate": 0.043914043224276535,
      "loss": 2.6639,
      "step": 349000
    },
    {
      "epoch": 561.13,
      "learning_rate": 0.04391082779340836,
      "loss": 2.6224,
      "step": 349020
    },
    {
      "epoch": 561.16,
      "learning_rate": 0.04390761236254019,
      "loss": 2.6219,
      "step": 349040
    },
    {
      "epoch": 561.19,
      "learning_rate": 0.04390439693167202,
      "loss": 2.6317,
      "step": 349060
    },
    {
      "epoch": 561.22,
      "learning_rate": 0.04390118150080387,
      "loss": 2.6403,
      "step": 349080
    },
    {
      "epoch": 561.25,
      "learning_rate": 0.0438979660699357,
      "loss": 2.6495,
      "step": 349100
    },
    {
      "epoch": 561.29,
      "learning_rate": 0.04389475063906753,
      "loss": 2.645,
      "step": 349120
    },
    {
      "epoch": 561.32,
      "learning_rate": 0.043891535208199356,
      "loss": 2.6273,
      "step": 349140
    },
    {
      "epoch": 561.35,
      "learning_rate": 0.04388831977733119,
      "loss": 2.6339,
      "step": 349160
    },
    {
      "epoch": 561.38,
      "learning_rate": 0.04388510434646303,
      "loss": 2.6596,
      "step": 349180
    },
    {
      "epoch": 561.41,
      "learning_rate": 0.043881888915594865,
      "loss": 2.627,
      "step": 349200
    },
    {
      "epoch": 561.45,
      "learning_rate": 0.043878673484726696,
      "loss": 2.606,
      "step": 349220
    },
    {
      "epoch": 561.48,
      "learning_rate": 0.04387545805385852,
      "loss": 2.6447,
      "step": 349240
    },
    {
      "epoch": 561.51,
      "learning_rate": 0.04387224262299035,
      "loss": 2.6499,
      "step": 349260
    },
    {
      "epoch": 561.54,
      "learning_rate": 0.043869027192122184,
      "loss": 2.6334,
      "step": 349280
    },
    {
      "epoch": 561.58,
      "learning_rate": 0.04386581176125403,
      "loss": 2.6201,
      "step": 349300
    },
    {
      "epoch": 561.61,
      "learning_rate": 0.04386259633038586,
      "loss": 2.6458,
      "step": 349320
    },
    {
      "epoch": 561.64,
      "learning_rate": 0.043859380899517686,
      "loss": 2.6226,
      "step": 349340
    },
    {
      "epoch": 561.67,
      "learning_rate": 0.04385616546864952,
      "loss": 2.6082,
      "step": 349360
    },
    {
      "epoch": 561.7,
      "learning_rate": 0.04385295003778135,
      "loss": 2.6185,
      "step": 349380
    },
    {
      "epoch": 561.74,
      "learning_rate": 0.043849734606913195,
      "loss": 2.6396,
      "step": 349400
    },
    {
      "epoch": 561.77,
      "learning_rate": 0.043846519176045026,
      "loss": 2.638,
      "step": 349420
    },
    {
      "epoch": 561.8,
      "learning_rate": 0.04384330374517686,
      "loss": 2.634,
      "step": 349440
    },
    {
      "epoch": 561.83,
      "learning_rate": 0.04384008831430868,
      "loss": 2.6588,
      "step": 349460
    },
    {
      "epoch": 561.86,
      "learning_rate": 0.043836872883440514,
      "loss": 2.6132,
      "step": 349480
    },
    {
      "epoch": 561.9,
      "learning_rate": 0.043833657452572346,
      "loss": 2.6286,
      "step": 349500
    },
    {
      "epoch": 561.93,
      "learning_rate": 0.04383044202170419,
      "loss": 2.6576,
      "step": 349520
    },
    {
      "epoch": 561.96,
      "learning_rate": 0.04382722659083602,
      "loss": 2.6555,
      "step": 349540
    },
    {
      "epoch": 561.99,
      "learning_rate": 0.04382401115996785,
      "loss": 2.659,
      "step": 349560
    },
    {
      "epoch": 562.0,
      "eval_accuracy": {
        "accuracy": 0.41561066625204074
      },
      "eval_loss": 2.7673099040985107,
      "eval_runtime": 2.7846,
      "eval_samples_per_second": 4619.323,
      "eval_steps_per_second": 72.183,
      "step": 349564
    },
    {
      "epoch": 562.03,
      "learning_rate": 0.04382079572909968,
      "loss": 2.6623,
      "step": 349580
    },
    {
      "epoch": 562.06,
      "learning_rate": 0.04381758029823151,
      "loss": 2.6405,
      "step": 349600
    },
    {
      "epoch": 562.09,
      "learning_rate": 0.04381436486736334,
      "loss": 2.618,
      "step": 349620
    },
    {
      "epoch": 562.12,
      "learning_rate": 0.04381114943649519,
      "loss": 2.6401,
      "step": 349640
    },
    {
      "epoch": 562.15,
      "learning_rate": 0.04380793400562701,
      "loss": 2.6221,
      "step": 349660
    },
    {
      "epoch": 562.19,
      "learning_rate": 0.043804718574758844,
      "loss": 2.6299,
      "step": 349680
    },
    {
      "epoch": 562.22,
      "learning_rate": 0.043801503143890676,
      "loss": 2.6319,
      "step": 349700
    },
    {
      "epoch": 562.25,
      "learning_rate": 0.04379828771302251,
      "loss": 2.6402,
      "step": 349720
    },
    {
      "epoch": 562.28,
      "learning_rate": 0.04379507228215435,
      "loss": 2.6436,
      "step": 349740
    },
    {
      "epoch": 562.32,
      "learning_rate": 0.043791856851286184,
      "loss": 2.6412,
      "step": 349760
    },
    {
      "epoch": 562.35,
      "learning_rate": 0.04378864142041801,
      "loss": 2.6169,
      "step": 349780
    },
    {
      "epoch": 562.38,
      "learning_rate": 0.04378542598954984,
      "loss": 2.6383,
      "step": 349800
    },
    {
      "epoch": 562.41,
      "learning_rate": 0.04378221055868167,
      "loss": 2.6498,
      "step": 349820
    },
    {
      "epoch": 562.44,
      "learning_rate": 0.043778995127813504,
      "loss": 2.6405,
      "step": 349840
    },
    {
      "epoch": 562.48,
      "learning_rate": 0.04377577969694535,
      "loss": 2.6596,
      "step": 349860
    },
    {
      "epoch": 562.51,
      "learning_rate": 0.043772564266077174,
      "loss": 2.6215,
      "step": 349880
    },
    {
      "epoch": 562.54,
      "learning_rate": 0.043769348835209006,
      "loss": 2.6445,
      "step": 349900
    },
    {
      "epoch": 562.57,
      "learning_rate": 0.04376613340434084,
      "loss": 2.6305,
      "step": 349920
    },
    {
      "epoch": 562.6,
      "learning_rate": 0.04376291797347267,
      "loss": 2.6517,
      "step": 349940
    },
    {
      "epoch": 562.64,
      "learning_rate": 0.0437597025426045,
      "loss": 2.6177,
      "step": 349960
    },
    {
      "epoch": 562.67,
      "learning_rate": 0.04375648711173634,
      "loss": 2.6275,
      "step": 349980
    },
    {
      "epoch": 562.7,
      "learning_rate": 0.04375327168086817,
      "loss": 2.6275,
      "step": 350000
    },
    {
      "epoch": 562.73,
      "learning_rate": 0.04375005625,
      "loss": 2.64,
      "step": 350020
    },
    {
      "epoch": 562.77,
      "learning_rate": 0.043746840819131834,
      "loss": 2.638,
      "step": 350040
    },
    {
      "epoch": 562.8,
      "learning_rate": 0.043743625388263666,
      "loss": 2.6631,
      "step": 350060
    },
    {
      "epoch": 562.83,
      "learning_rate": 0.04374040995739551,
      "loss": 2.6595,
      "step": 350080
    },
    {
      "epoch": 562.86,
      "learning_rate": 0.043737194526527336,
      "loss": 2.6392,
      "step": 350100
    },
    {
      "epoch": 562.89,
      "learning_rate": 0.04373397909565917,
      "loss": 2.6379,
      "step": 350120
    },
    {
      "epoch": 562.93,
      "learning_rate": 0.043730763664791,
      "loss": 2.6643,
      "step": 350140
    },
    {
      "epoch": 562.96,
      "learning_rate": 0.04372754823392283,
      "loss": 2.69,
      "step": 350160
    },
    {
      "epoch": 562.99,
      "learning_rate": 0.04372433280305466,
      "loss": 2.6487,
      "step": 350180
    },
    {
      "epoch": 563.0,
      "eval_accuracy": {
        "accuracy": 0.42338490243333593
      },
      "eval_loss": 2.749401092529297,
      "eval_runtime": 2.8782,
      "eval_samples_per_second": 4469.125,
      "eval_steps_per_second": 69.836,
      "step": 350186
    },
    {
      "epoch": 563.02,
      "learning_rate": 0.0437211173721865,
      "loss": 2.6322,
      "step": 350200
    },
    {
      "epoch": 563.05,
      "learning_rate": 0.04371790194131833,
      "loss": 2.616,
      "step": 350220
    },
    {
      "epoch": 563.09,
      "learning_rate": 0.043714686510450164,
      "loss": 2.6349,
      "step": 350240
    },
    {
      "epoch": 563.12,
      "learning_rate": 0.043711471079581996,
      "loss": 2.6304,
      "step": 350260
    },
    {
      "epoch": 563.15,
      "learning_rate": 0.04370825564871383,
      "loss": 2.6516,
      "step": 350280
    },
    {
      "epoch": 563.18,
      "learning_rate": 0.04370504021784566,
      "loss": 2.6224,
      "step": 350300
    },
    {
      "epoch": 563.22,
      "learning_rate": 0.0437018247869775,
      "loss": 2.6218,
      "step": 350320
    },
    {
      "epoch": 563.25,
      "learning_rate": 0.04369860935610933,
      "loss": 2.6671,
      "step": 350340
    },
    {
      "epoch": 563.28,
      "learning_rate": 0.04369539392524116,
      "loss": 2.6494,
      "step": 350360
    },
    {
      "epoch": 563.31,
      "learning_rate": 0.04369217849437299,
      "loss": 2.6507,
      "step": 350380
    },
    {
      "epoch": 563.34,
      "learning_rate": 0.043688963063504824,
      "loss": 2.6418,
      "step": 350400
    },
    {
      "epoch": 563.38,
      "learning_rate": 0.04368574763263666,
      "loss": 2.607,
      "step": 350420
    },
    {
      "epoch": 563.41,
      "learning_rate": 0.0436826929733119,
      "loss": 2.6249,
      "step": 350440
    },
    {
      "epoch": 563.44,
      "learning_rate": 0.04367947754244374,
      "loss": 2.6485,
      "step": 350460
    },
    {
      "epoch": 563.47,
      "learning_rate": 0.04367626211157557,
      "loss": 2.6243,
      "step": 350480
    },
    {
      "epoch": 563.5,
      "learning_rate": 0.0436730466807074,
      "loss": 2.6266,
      "step": 350500
    },
    {
      "epoch": 563.54,
      "learning_rate": 0.04366983124983923,
      "loss": 2.6527,
      "step": 350520
    },
    {
      "epoch": 563.57,
      "learning_rate": 0.043666615818971063,
      "loss": 2.6334,
      "step": 350540
    },
    {
      "epoch": 563.6,
      "learning_rate": 0.0436634003881029,
      "loss": 2.6505,
      "step": 350560
    },
    {
      "epoch": 563.63,
      "learning_rate": 0.043660184957234734,
      "loss": 2.6299,
      "step": 350580
    },
    {
      "epoch": 563.67,
      "learning_rate": 0.043656969526366565,
      "loss": 2.6137,
      "step": 350600
    },
    {
      "epoch": 563.7,
      "learning_rate": 0.0436537540954984,
      "loss": 2.6286,
      "step": 350620
    },
    {
      "epoch": 563.73,
      "learning_rate": 0.04365053866463023,
      "loss": 2.6293,
      "step": 350640
    },
    {
      "epoch": 563.76,
      "learning_rate": 0.04364732323376206,
      "loss": 2.6498,
      "step": 350660
    },
    {
      "epoch": 563.79,
      "learning_rate": 0.0436441078028939,
      "loss": 2.6539,
      "step": 350680
    },
    {
      "epoch": 563.83,
      "learning_rate": 0.04364089237202573,
      "loss": 2.6462,
      "step": 350700
    },
    {
      "epoch": 563.86,
      "learning_rate": 0.04363767694115756,
      "loss": 2.6651,
      "step": 350720
    },
    {
      "epoch": 563.89,
      "learning_rate": 0.04363446151028939,
      "loss": 2.6488,
      "step": 350740
    },
    {
      "epoch": 563.92,
      "learning_rate": 0.043631246079421225,
      "loss": 2.6466,
      "step": 350760
    },
    {
      "epoch": 563.95,
      "learning_rate": 0.04362803064855306,
      "loss": 2.6225,
      "step": 350780
    },
    {
      "epoch": 563.99,
      "learning_rate": 0.043624815217684895,
      "loss": 2.6469,
      "step": 350800
    },
    {
      "epoch": 564.0,
      "eval_accuracy": {
        "accuracy": 0.4205084350462567
      },
      "eval_loss": 2.7179720401763916,
      "eval_runtime": 2.9968,
      "eval_samples_per_second": 4292.246,
      "eval_steps_per_second": 67.072,
      "step": 350808
    },
    {
      "epoch": 564.02,
      "learning_rate": 0.04362159978681673,
      "loss": 2.6308,
      "step": 350820
    },
    {
      "epoch": 564.05,
      "learning_rate": 0.04361838435594856,
      "loss": 2.6205,
      "step": 350840
    },
    {
      "epoch": 564.08,
      "learning_rate": 0.04361516892508039,
      "loss": 2.6703,
      "step": 350860
    },
    {
      "epoch": 564.12,
      "learning_rate": 0.04361195349421222,
      "loss": 2.647,
      "step": 350880
    },
    {
      "epoch": 564.15,
      "learning_rate": 0.04360873806334406,
      "loss": 2.6415,
      "step": 350900
    },
    {
      "epoch": 564.18,
      "learning_rate": 0.04360552263247589,
      "loss": 2.6549,
      "step": 350920
    },
    {
      "epoch": 564.21,
      "learning_rate": 0.04360230720160772,
      "loss": 2.6139,
      "step": 350940
    },
    {
      "epoch": 564.24,
      "learning_rate": 0.043599091770739555,
      "loss": 2.6501,
      "step": 350960
    },
    {
      "epoch": 564.28,
      "learning_rate": 0.04359587633987139,
      "loss": 2.6152,
      "step": 350980
    },
    {
      "epoch": 564.31,
      "learning_rate": 0.04359266090900322,
      "loss": 2.632,
      "step": 351000
    },
    {
      "epoch": 564.34,
      "learning_rate": 0.04358944547813506,
      "loss": 2.6244,
      "step": 351020
    },
    {
      "epoch": 564.37,
      "learning_rate": 0.04358623004726689,
      "loss": 2.6405,
      "step": 351040
    },
    {
      "epoch": 564.41,
      "learning_rate": 0.04358301461639872,
      "loss": 2.6294,
      "step": 351060
    },
    {
      "epoch": 564.44,
      "learning_rate": 0.04357979918553055,
      "loss": 2.6403,
      "step": 351080
    },
    {
      "epoch": 564.47,
      "learning_rate": 0.04357658375466238,
      "loss": 2.626,
      "step": 351100
    },
    {
      "epoch": 564.5,
      "learning_rate": 0.04357336832379421,
      "loss": 2.6544,
      "step": 351120
    },
    {
      "epoch": 564.53,
      "learning_rate": 0.04357015289292605,
      "loss": 2.6295,
      "step": 351140
    },
    {
      "epoch": 564.57,
      "learning_rate": 0.043566937462057885,
      "loss": 2.6115,
      "step": 351160
    },
    {
      "epoch": 564.6,
      "learning_rate": 0.04356372203118972,
      "loss": 2.6221,
      "step": 351180
    },
    {
      "epoch": 564.63,
      "learning_rate": 0.04356050660032155,
      "loss": 2.618,
      "step": 351200
    },
    {
      "epoch": 564.66,
      "learning_rate": 0.04355729116945337,
      "loss": 2.6217,
      "step": 351220
    },
    {
      "epoch": 564.69,
      "learning_rate": 0.04355407573858522,
      "loss": 2.6256,
      "step": 351240
    },
    {
      "epoch": 564.73,
      "learning_rate": 0.04355086030771705,
      "loss": 2.6392,
      "step": 351260
    },
    {
      "epoch": 564.76,
      "learning_rate": 0.04354764487684888,
      "loss": 2.6105,
      "step": 351280
    },
    {
      "epoch": 564.79,
      "learning_rate": 0.04354442944598071,
      "loss": 2.641,
      "step": 351300
    },
    {
      "epoch": 564.82,
      "learning_rate": 0.043541214015112545,
      "loss": 2.6384,
      "step": 351320
    },
    {
      "epoch": 564.86,
      "learning_rate": 0.04353799858424437,
      "loss": 2.6381,
      "step": 351340
    },
    {
      "epoch": 564.89,
      "learning_rate": 0.043534783153376215,
      "loss": 2.6555,
      "step": 351360
    },
    {
      "epoch": 564.92,
      "learning_rate": 0.04353156772250805,
      "loss": 2.6541,
      "step": 351380
    },
    {
      "epoch": 564.95,
      "learning_rate": 0.04352835229163988,
      "loss": 2.6454,
      "step": 351400
    },
    {
      "epoch": 564.98,
      "learning_rate": 0.04352513686077171,
      "loss": 2.6472,
      "step": 351420
    },
    {
      "epoch": 565.0,
      "eval_accuracy": {
        "accuracy": 0.4258726580113504
      },
      "eval_loss": 2.713181972503662,
      "eval_runtime": 2.9245,
      "eval_samples_per_second": 4398.318,
      "eval_steps_per_second": 68.729,
      "step": 351430
    },
    {
      "epoch": 565.02,
      "learning_rate": 0.043521921429903535,
      "loss": 2.6386,
      "step": 351440
    },
    {
      "epoch": 565.05,
      "learning_rate": 0.043518705999035366,
      "loss": 2.6155,
      "step": 351460
    },
    {
      "epoch": 565.08,
      "learning_rate": 0.04351549056816721,
      "loss": 2.6073,
      "step": 351480
    },
    {
      "epoch": 565.11,
      "learning_rate": 0.04351227513729904,
      "loss": 2.6199,
      "step": 351500
    },
    {
      "epoch": 565.14,
      "learning_rate": 0.043509059706430875,
      "loss": 2.6437,
      "step": 351520
    },
    {
      "epoch": 565.18,
      "learning_rate": 0.0435058442755627,
      "loss": 2.6288,
      "step": 351540
    },
    {
      "epoch": 565.21,
      "learning_rate": 0.04350262884469453,
      "loss": 2.6418,
      "step": 351560
    },
    {
      "epoch": 565.24,
      "learning_rate": 0.04349941341382638,
      "loss": 2.6192,
      "step": 351580
    },
    {
      "epoch": 565.27,
      "learning_rate": 0.04349619798295821,
      "loss": 2.6221,
      "step": 351600
    },
    {
      "epoch": 565.31,
      "learning_rate": 0.04349298255209004,
      "loss": 2.621,
      "step": 351620
    },
    {
      "epoch": 565.34,
      "learning_rate": 0.04348976712122187,
      "loss": 2.6268,
      "step": 351640
    },
    {
      "epoch": 565.37,
      "learning_rate": 0.043486551690353696,
      "loss": 2.6376,
      "step": 351660
    },
    {
      "epoch": 565.4,
      "learning_rate": 0.04348333625948553,
      "loss": 2.6085,
      "step": 351680
    },
    {
      "epoch": 565.43,
      "learning_rate": 0.04348012082861737,
      "loss": 2.6312,
      "step": 351700
    },
    {
      "epoch": 565.47,
      "learning_rate": 0.043476905397749205,
      "loss": 2.6458,
      "step": 351720
    },
    {
      "epoch": 565.5,
      "learning_rate": 0.043473689966881036,
      "loss": 2.6237,
      "step": 351740
    },
    {
      "epoch": 565.53,
      "learning_rate": 0.04347047453601286,
      "loss": 2.6211,
      "step": 351760
    },
    {
      "epoch": 565.56,
      "learning_rate": 0.04346725910514469,
      "loss": 2.6241,
      "step": 351780
    },
    {
      "epoch": 565.59,
      "learning_rate": 0.04346404367427654,
      "loss": 2.6474,
      "step": 351800
    },
    {
      "epoch": 565.63,
      "learning_rate": 0.04346082824340837,
      "loss": 2.6606,
      "step": 351820
    },
    {
      "epoch": 565.66,
      "learning_rate": 0.0434576128125402,
      "loss": 2.5976,
      "step": 351840
    },
    {
      "epoch": 565.69,
      "learning_rate": 0.043454397381672026,
      "loss": 2.6201,
      "step": 351860
    },
    {
      "epoch": 565.72,
      "learning_rate": 0.04345118195080386,
      "loss": 2.6347,
      "step": 351880
    },
    {
      "epoch": 565.76,
      "learning_rate": 0.04344796651993569,
      "loss": 2.6429,
      "step": 351900
    },
    {
      "epoch": 565.79,
      "learning_rate": 0.043444751089067535,
      "loss": 2.6305,
      "step": 351920
    },
    {
      "epoch": 565.82,
      "learning_rate": 0.043441535658199366,
      "loss": 2.6156,
      "step": 351940
    },
    {
      "epoch": 565.85,
      "learning_rate": 0.0434383202273312,
      "loss": 2.6519,
      "step": 351960
    },
    {
      "epoch": 565.88,
      "learning_rate": 0.04343510479646302,
      "loss": 2.6318,
      "step": 351980
    },
    {
      "epoch": 565.92,
      "learning_rate": 0.043431889365594854,
      "loss": 2.617,
      "step": 352000
    },
    {
      "epoch": 565.95,
      "learning_rate": 0.043428673934726686,
      "loss": 2.6349,
      "step": 352020
    },
    {
      "epoch": 565.98,
      "learning_rate": 0.04342545850385853,
      "loss": 2.6321,
      "step": 352040
    },
    {
      "epoch": 566.0,
      "eval_accuracy": {
        "accuracy": 0.4213636010261992
      },
      "eval_loss": 2.7289023399353027,
      "eval_runtime": 3.0848,
      "eval_samples_per_second": 4169.767,
      "eval_steps_per_second": 65.158,
      "step": 352052
    },
    {
      "epoch": 566.01,
      "learning_rate": 0.04342224307299036,
      "loss": 2.6547,
      "step": 352060
    },
    {
      "epoch": 566.05,
      "learning_rate": 0.04341902764212219,
      "loss": 2.6476,
      "step": 352080
    },
    {
      "epoch": 566.08,
      "learning_rate": 0.04341581221125402,
      "loss": 2.626,
      "step": 352100
    },
    {
      "epoch": 566.11,
      "learning_rate": 0.04341259678038585,
      "loss": 2.6206,
      "step": 352120
    },
    {
      "epoch": 566.14,
      "learning_rate": 0.043409381349517696,
      "loss": 2.6295,
      "step": 352140
    },
    {
      "epoch": 566.17,
      "learning_rate": 0.04340616591864953,
      "loss": 2.6132,
      "step": 352160
    },
    {
      "epoch": 566.21,
      "learning_rate": 0.04340295048778135,
      "loss": 2.6305,
      "step": 352180
    },
    {
      "epoch": 566.24,
      "learning_rate": 0.043399735056913184,
      "loss": 2.6347,
      "step": 352200
    },
    {
      "epoch": 566.27,
      "learning_rate": 0.043396519626045016,
      "loss": 2.6203,
      "step": 352220
    },
    {
      "epoch": 566.3,
      "learning_rate": 0.04339330419517685,
      "loss": 2.646,
      "step": 352240
    },
    {
      "epoch": 566.33,
      "learning_rate": 0.04339008876430869,
      "loss": 2.6425,
      "step": 352260
    },
    {
      "epoch": 566.37,
      "learning_rate": 0.043386873333440525,
      "loss": 2.64,
      "step": 352280
    },
    {
      "epoch": 566.4,
      "learning_rate": 0.04338365790257235,
      "loss": 2.6276,
      "step": 352300
    },
    {
      "epoch": 566.43,
      "learning_rate": 0.04338044247170418,
      "loss": 2.6128,
      "step": 352320
    },
    {
      "epoch": 566.46,
      "learning_rate": 0.04337722704083601,
      "loss": 2.6197,
      "step": 352340
    },
    {
      "epoch": 566.5,
      "learning_rate": 0.043374011609967844,
      "loss": 2.6413,
      "step": 352360
    },
    {
      "epoch": 566.53,
      "learning_rate": 0.04337079617909969,
      "loss": 2.621,
      "step": 352380
    },
    {
      "epoch": 566.56,
      "learning_rate": 0.043367580748231514,
      "loss": 2.6383,
      "step": 352400
    },
    {
      "epoch": 566.59,
      "learning_rate": 0.043364365317363346,
      "loss": 2.6239,
      "step": 352420
    },
    {
      "epoch": 566.62,
      "learning_rate": 0.04336114988649518,
      "loss": 2.6492,
      "step": 352440
    },
    {
      "epoch": 566.66,
      "learning_rate": 0.04335793445562701,
      "loss": 2.6321,
      "step": 352460
    },
    {
      "epoch": 566.69,
      "learning_rate": 0.043354719024758855,
      "loss": 2.6462,
      "step": 352480
    },
    {
      "epoch": 566.72,
      "learning_rate": 0.04335150359389068,
      "loss": 2.6111,
      "step": 352500
    },
    {
      "epoch": 566.75,
      "learning_rate": 0.04334828816302251,
      "loss": 2.6369,
      "step": 352520
    },
    {
      "epoch": 566.78,
      "learning_rate": 0.04334507273215434,
      "loss": 2.6322,
      "step": 352540
    },
    {
      "epoch": 566.82,
      "learning_rate": 0.043341857301286174,
      "loss": 2.6349,
      "step": 352560
    },
    {
      "epoch": 566.85,
      "learning_rate": 0.043338641870418006,
      "loss": 2.6512,
      "step": 352580
    },
    {
      "epoch": 566.88,
      "learning_rate": 0.04333542643954985,
      "loss": 2.6231,
      "step": 352600
    },
    {
      "epoch": 566.91,
      "learning_rate": 0.043332211008681676,
      "loss": 2.6372,
      "step": 352620
    },
    {
      "epoch": 566.95,
      "learning_rate": 0.04332899557781351,
      "loss": 2.6275,
      "step": 352640
    },
    {
      "epoch": 566.98,
      "learning_rate": 0.04332578014694534,
      "loss": 2.6138,
      "step": 352660
    },
    {
      "epoch": 567.0,
      "eval_accuracy": {
        "accuracy": 0.41351162248309103
      },
      "eval_loss": 2.7601163387298584,
      "eval_runtime": 2.7388,
      "eval_samples_per_second": 4696.541,
      "eval_steps_per_second": 73.389,
      "step": 352674
    },
    {
      "epoch": 567.01,
      "learning_rate": 0.04332256471607717,
      "loss": 2.6391,
      "step": 352680
    },
    {
      "epoch": 567.04,
      "learning_rate": 0.043319349285209,
      "loss": 2.6479,
      "step": 352700
    },
    {
      "epoch": 567.07,
      "learning_rate": 0.04331613385434084,
      "loss": 2.6317,
      "step": 352720
    },
    {
      "epoch": 567.11,
      "learning_rate": 0.04331291842347267,
      "loss": 2.612,
      "step": 352740
    },
    {
      "epoch": 567.14,
      "learning_rate": 0.043309702992604504,
      "loss": 2.6324,
      "step": 352760
    },
    {
      "epoch": 567.17,
      "learning_rate": 0.043306487561736336,
      "loss": 2.6154,
      "step": 352780
    },
    {
      "epoch": 567.2,
      "learning_rate": 0.04330343290241158,
      "loss": 2.6211,
      "step": 352800
    },
    {
      "epoch": 567.23,
      "learning_rate": 0.04330021747154341,
      "loss": 2.6218,
      "step": 352820
    },
    {
      "epoch": 567.27,
      "learning_rate": 0.04329700204067524,
      "loss": 2.6177,
      "step": 352840
    },
    {
      "epoch": 567.3,
      "learning_rate": 0.04329378660980708,
      "loss": 2.6416,
      "step": 352860
    },
    {
      "epoch": 567.33,
      "learning_rate": 0.04329057117893891,
      "loss": 2.626,
      "step": 352880
    },
    {
      "epoch": 567.36,
      "learning_rate": 0.043287355748070744,
      "loss": 2.6488,
      "step": 352900
    },
    {
      "epoch": 567.4,
      "learning_rate": 0.043284140317202575,
      "loss": 2.6432,
      "step": 352920
    },
    {
      "epoch": 567.43,
      "learning_rate": 0.04328092488633441,
      "loss": 2.6504,
      "step": 352940
    },
    {
      "epoch": 567.46,
      "learning_rate": 0.043277709455466246,
      "loss": 2.6401,
      "step": 352960
    },
    {
      "epoch": 567.49,
      "learning_rate": 0.04327449402459808,
      "loss": 2.6447,
      "step": 352980
    },
    {
      "epoch": 567.52,
      "learning_rate": 0.04327127859372991,
      "loss": 2.6484,
      "step": 353000
    },
    {
      "epoch": 567.56,
      "learning_rate": 0.04326806316286174,
      "loss": 2.6273,
      "step": 353020
    },
    {
      "epoch": 567.59,
      "learning_rate": 0.04326484773199357,
      "loss": 2.6399,
      "step": 353040
    },
    {
      "epoch": 567.62,
      "learning_rate": 0.043261632301125404,
      "loss": 2.6403,
      "step": 353060
    },
    {
      "epoch": 567.65,
      "learning_rate": 0.04325841687025724,
      "loss": 2.6278,
      "step": 353080
    },
    {
      "epoch": 567.68,
      "learning_rate": 0.043255201439389074,
      "loss": 2.5975,
      "step": 353100
    },
    {
      "epoch": 567.72,
      "learning_rate": 0.043251986008520905,
      "loss": 2.6374,
      "step": 353120
    },
    {
      "epoch": 567.75,
      "learning_rate": 0.04324877057765274,
      "loss": 2.6204,
      "step": 353140
    },
    {
      "epoch": 567.78,
      "learning_rate": 0.04324555514678457,
      "loss": 2.6224,
      "step": 353160
    },
    {
      "epoch": 567.81,
      "learning_rate": 0.0432423397159164,
      "loss": 2.6303,
      "step": 353180
    },
    {
      "epoch": 567.85,
      "learning_rate": 0.04323912428504824,
      "loss": 2.617,
      "step": 353200
    },
    {
      "epoch": 567.88,
      "learning_rate": 0.04323590885418007,
      "loss": 2.6269,
      "step": 353220
    },
    {
      "epoch": 567.91,
      "learning_rate": 0.0432326934233119,
      "loss": 2.6466,
      "step": 353240
    },
    {
      "epoch": 567.94,
      "learning_rate": 0.043229477992443734,
      "loss": 2.6547,
      "step": 353260
    },
    {
      "epoch": 567.97,
      "learning_rate": 0.043226262561575565,
      "loss": 2.6513,
      "step": 353280
    },
    {
      "epoch": 568.0,
      "eval_accuracy": {
        "accuracy": 0.42447329549871726
      },
      "eval_loss": 2.7305727005004883,
      "eval_runtime": 2.8134,
      "eval_samples_per_second": 4572.109,
      "eval_steps_per_second": 71.445,
      "step": 353296
    },
    {
      "epoch": 568.01,
      "learning_rate": 0.043223047130707404,
      "loss": 2.6417,
      "step": 353300
    },
    {
      "epoch": 568.04,
      "learning_rate": 0.043219831699839235,
      "loss": 2.6356,
      "step": 353320
    },
    {
      "epoch": 568.07,
      "learning_rate": 0.04321661626897107,
      "loss": 2.6354,
      "step": 353340
    },
    {
      "epoch": 568.1,
      "learning_rate": 0.0432134008381029,
      "loss": 2.6325,
      "step": 353360
    },
    {
      "epoch": 568.14,
      "learning_rate": 0.04321018540723473,
      "loss": 2.6383,
      "step": 353380
    },
    {
      "epoch": 568.17,
      "learning_rate": 0.04320696997636656,
      "loss": 2.6282,
      "step": 353400
    },
    {
      "epoch": 568.2,
      "learning_rate": 0.0432037545454984,
      "loss": 2.6431,
      "step": 353420
    },
    {
      "epoch": 568.23,
      "learning_rate": 0.04320053911463023,
      "loss": 2.6243,
      "step": 353440
    },
    {
      "epoch": 568.26,
      "learning_rate": 0.043197323683762064,
      "loss": 2.6098,
      "step": 353460
    },
    {
      "epoch": 568.3,
      "learning_rate": 0.043194108252893895,
      "loss": 2.6473,
      "step": 353480
    },
    {
      "epoch": 568.33,
      "learning_rate": 0.04319089282202573,
      "loss": 2.6552,
      "step": 353500
    },
    {
      "epoch": 568.36,
      "learning_rate": 0.04318767739115756,
      "loss": 2.6376,
      "step": 353520
    },
    {
      "epoch": 568.39,
      "learning_rate": 0.0431844619602894,
      "loss": 2.6171,
      "step": 353540
    },
    {
      "epoch": 568.42,
      "learning_rate": 0.04318124652942123,
      "loss": 2.6238,
      "step": 353560
    },
    {
      "epoch": 568.46,
      "learning_rate": 0.04317803109855306,
      "loss": 2.6448,
      "step": 353580
    },
    {
      "epoch": 568.49,
      "learning_rate": 0.04317481566768489,
      "loss": 2.6423,
      "step": 353600
    },
    {
      "epoch": 568.52,
      "learning_rate": 0.04317160023681672,
      "loss": 2.6349,
      "step": 353620
    },
    {
      "epoch": 568.55,
      "learning_rate": 0.04316838480594856,
      "loss": 2.6405,
      "step": 353640
    },
    {
      "epoch": 568.59,
      "learning_rate": 0.043165169375080394,
      "loss": 2.6088,
      "step": 353660
    },
    {
      "epoch": 568.62,
      "learning_rate": 0.043161953944212225,
      "loss": 2.6356,
      "step": 353680
    },
    {
      "epoch": 568.65,
      "learning_rate": 0.04315873851334406,
      "loss": 2.6494,
      "step": 353700
    },
    {
      "epoch": 568.68,
      "learning_rate": 0.04315552308247589,
      "loss": 2.6058,
      "step": 353720
    },
    {
      "epoch": 568.71,
      "learning_rate": 0.04315230765160771,
      "loss": 2.6334,
      "step": 353740
    },
    {
      "epoch": 568.75,
      "learning_rate": 0.04314909222073956,
      "loss": 2.6172,
      "step": 353760
    },
    {
      "epoch": 568.78,
      "learning_rate": 0.04314587678987139,
      "loss": 2.6343,
      "step": 353780
    },
    {
      "epoch": 568.81,
      "learning_rate": 0.04314266135900322,
      "loss": 2.6551,
      "step": 353800
    },
    {
      "epoch": 568.84,
      "learning_rate": 0.04313944592813505,
      "loss": 2.6491,
      "step": 353820
    },
    {
      "epoch": 568.87,
      "learning_rate": 0.043136230497266885,
      "loss": 2.6098,
      "step": 353840
    },
    {
      "epoch": 568.91,
      "learning_rate": 0.04313301506639871,
      "loss": 2.6277,
      "step": 353860
    },
    {
      "epoch": 568.94,
      "learning_rate": 0.043129799635530555,
      "loss": 2.6355,
      "step": 353880
    },
    {
      "epoch": 568.97,
      "learning_rate": 0.04312658420466239,
      "loss": 2.6503,
      "step": 353900
    },
    {
      "epoch": 569.0,
      "eval_accuracy": {
        "accuracy": 0.4124232294177097
      },
      "eval_loss": 2.7851662635803223,
      "eval_runtime": 2.9522,
      "eval_samples_per_second": 4357.04,
      "eval_steps_per_second": 68.084,
      "step": 353918
    },
    {
      "epoch": 569.0,
      "learning_rate": 0.04312336877379422,
      "loss": 2.6584,
      "step": 353920
    },
    {
      "epoch": 569.04,
      "learning_rate": 0.04312015334292605,
      "loss": 2.6544,
      "step": 353940
    },
    {
      "epoch": 569.07,
      "learning_rate": 0.043116937912057875,
      "loss": 2.6427,
      "step": 353960
    },
    {
      "epoch": 569.1,
      "learning_rate": 0.04311372248118972,
      "loss": 2.6449,
      "step": 353980
    },
    {
      "epoch": 569.13,
      "learning_rate": 0.04311050705032155,
      "loss": 2.6052,
      "step": 354000
    },
    {
      "epoch": 569.16,
      "learning_rate": 0.04310729161945338,
      "loss": 2.6078,
      "step": 354020
    },
    {
      "epoch": 569.2,
      "learning_rate": 0.043104076188585215,
      "loss": 2.6265,
      "step": 354040
    },
    {
      "epoch": 569.23,
      "learning_rate": 0.04310086075771704,
      "loss": 2.6303,
      "step": 354060
    },
    {
      "epoch": 569.26,
      "learning_rate": 0.04309764532684887,
      "loss": 2.6373,
      "step": 354080
    },
    {
      "epoch": 569.29,
      "learning_rate": 0.04309442989598072,
      "loss": 2.6233,
      "step": 354100
    },
    {
      "epoch": 569.32,
      "learning_rate": 0.04309121446511255,
      "loss": 2.6304,
      "step": 354120
    },
    {
      "epoch": 569.36,
      "learning_rate": 0.04308799903424438,
      "loss": 2.6255,
      "step": 354140
    },
    {
      "epoch": 569.39,
      "learning_rate": 0.04308478360337621,
      "loss": 2.6357,
      "step": 354160
    },
    {
      "epoch": 569.42,
      "learning_rate": 0.043081568172508036,
      "loss": 2.647,
      "step": 354180
    },
    {
      "epoch": 569.45,
      "learning_rate": 0.04307835274163987,
      "loss": 2.6513,
      "step": 354200
    },
    {
      "epoch": 569.49,
      "learning_rate": 0.04307513731077171,
      "loss": 2.6168,
      "step": 354220
    },
    {
      "epoch": 569.52,
      "learning_rate": 0.043071921879903545,
      "loss": 2.6232,
      "step": 354240
    },
    {
      "epoch": 569.55,
      "learning_rate": 0.04306870644903538,
      "loss": 2.6456,
      "step": 354260
    },
    {
      "epoch": 569.58,
      "learning_rate": 0.0430654910181672,
      "loss": 2.6441,
      "step": 354280
    },
    {
      "epoch": 569.61,
      "learning_rate": 0.04306227558729903,
      "loss": 2.6234,
      "step": 354300
    },
    {
      "epoch": 569.65,
      "learning_rate": 0.04305906015643088,
      "loss": 2.6262,
      "step": 354320
    },
    {
      "epoch": 569.68,
      "learning_rate": 0.04305584472556271,
      "loss": 2.6354,
      "step": 354340
    },
    {
      "epoch": 569.71,
      "learning_rate": 0.04305262929469454,
      "loss": 2.6296,
      "step": 354360
    },
    {
      "epoch": 569.74,
      "learning_rate": 0.043049413863826366,
      "loss": 2.6258,
      "step": 354380
    },
    {
      "epoch": 569.77,
      "learning_rate": 0.0430461984329582,
      "loss": 2.6401,
      "step": 354400
    },
    {
      "epoch": 569.81,
      "learning_rate": 0.04304298300209003,
      "loss": 2.618,
      "step": 354420
    },
    {
      "epoch": 569.84,
      "learning_rate": 0.043039767571221875,
      "loss": 2.6354,
      "step": 354440
    },
    {
      "epoch": 569.87,
      "learning_rate": 0.04303655214035371,
      "loss": 2.6465,
      "step": 354460
    },
    {
      "epoch": 569.9,
      "learning_rate": 0.04303333670948554,
      "loss": 2.6301,
      "step": 354480
    },
    {
      "epoch": 569.94,
      "learning_rate": 0.04303012127861736,
      "loss": 2.6319,
      "step": 354500
    },
    {
      "epoch": 569.97,
      "learning_rate": 0.043026905847749194,
      "loss": 2.6343,
      "step": 354520
    },
    {
      "epoch": 570.0,
      "learning_rate": 0.04302369041688104,
      "loss": 2.6436,
      "step": 354540
    },
    {
      "epoch": 570.0,
      "eval_accuracy": {
        "accuracy": 0.42284070590064526
      },
      "eval_loss": 2.736220121383667,
      "eval_runtime": 3.1697,
      "eval_samples_per_second": 4058.098,
      "eval_steps_per_second": 63.413,
      "step": 354540
    },
    {
      "epoch": 570.03,
      "learning_rate": 0.04302047498601287,
      "loss": 2.6366,
      "step": 354560
    },
    {
      "epoch": 570.06,
      "learning_rate": 0.0430172595551447,
      "loss": 2.6186,
      "step": 354580
    },
    {
      "epoch": 570.1,
      "learning_rate": 0.04301404412427653,
      "loss": 2.6116,
      "step": 354600
    },
    {
      "epoch": 570.13,
      "learning_rate": 0.04301082869340836,
      "loss": 2.6193,
      "step": 354620
    },
    {
      "epoch": 570.16,
      "learning_rate": 0.04300761326254019,
      "loss": 2.6249,
      "step": 354640
    },
    {
      "epoch": 570.19,
      "learning_rate": 0.04300439783167204,
      "loss": 2.6418,
      "step": 354660
    },
    {
      "epoch": 570.23,
      "learning_rate": 0.04300118240080387,
      "loss": 2.6393,
      "step": 354680
    },
    {
      "epoch": 570.26,
      "learning_rate": 0.04299796696993569,
      "loss": 2.5981,
      "step": 354700
    },
    {
      "epoch": 570.29,
      "learning_rate": 0.042994751539067524,
      "loss": 2.6411,
      "step": 354720
    },
    {
      "epoch": 570.32,
      "learning_rate": 0.042991536108199356,
      "loss": 2.6438,
      "step": 354740
    },
    {
      "epoch": 570.35,
      "learning_rate": 0.04298832067733119,
      "loss": 2.659,
      "step": 354760
    },
    {
      "epoch": 570.39,
      "learning_rate": 0.04298510524646303,
      "loss": 2.6198,
      "step": 354780
    },
    {
      "epoch": 570.42,
      "learning_rate": 0.042981889815594865,
      "loss": 2.6046,
      "step": 354800
    },
    {
      "epoch": 570.45,
      "learning_rate": 0.04297867438472669,
      "loss": 2.6336,
      "step": 354820
    },
    {
      "epoch": 570.48,
      "learning_rate": 0.04297545895385852,
      "loss": 2.6298,
      "step": 354840
    },
    {
      "epoch": 570.51,
      "learning_rate": 0.04297224352299035,
      "loss": 2.6189,
      "step": 354860
    },
    {
      "epoch": 570.55,
      "learning_rate": 0.0429690280921222,
      "loss": 2.6351,
      "step": 354880
    },
    {
      "epoch": 570.58,
      "learning_rate": 0.04296581266125403,
      "loss": 2.6408,
      "step": 354900
    },
    {
      "epoch": 570.61,
      "learning_rate": 0.042962597230385854,
      "loss": 2.6419,
      "step": 354920
    },
    {
      "epoch": 570.64,
      "learning_rate": 0.042959381799517686,
      "loss": 2.6345,
      "step": 354940
    },
    {
      "epoch": 570.68,
      "learning_rate": 0.04295616636864952,
      "loss": 2.6144,
      "step": 354960
    },
    {
      "epoch": 570.71,
      "learning_rate": 0.04295295093778135,
      "loss": 2.642,
      "step": 354980
    },
    {
      "epoch": 570.74,
      "learning_rate": 0.042949735506913195,
      "loss": 2.6245,
      "step": 355000
    },
    {
      "epoch": 570.77,
      "learning_rate": 0.04294652007604502,
      "loss": 2.6141,
      "step": 355020
    },
    {
      "epoch": 570.8,
      "learning_rate": 0.04294330464517685,
      "loss": 2.6565,
      "step": 355040
    },
    {
      "epoch": 570.84,
      "learning_rate": 0.04294008921430868,
      "loss": 2.6378,
      "step": 355060
    },
    {
      "epoch": 570.87,
      "learning_rate": 0.042936873783440514,
      "loss": 2.6493,
      "step": 355080
    },
    {
      "epoch": 570.9,
      "learning_rate": 0.042933658352572346,
      "loss": 2.6221,
      "step": 355100
    },
    {
      "epoch": 570.93,
      "learning_rate": 0.04293044292170419,
      "loss": 2.6306,
      "step": 355120
    },
    {
      "epoch": 570.96,
      "learning_rate": 0.042927227490836016,
      "loss": 2.6339,
      "step": 355140
    },
    {
      "epoch": 571.0,
      "learning_rate": 0.04292401205996785,
      "loss": 2.6293,
      "step": 355160
    },
    {
      "epoch": 571.0,
      "eval_accuracy": {
        "accuracy": 0.4211303739407603
      },
      "eval_loss": 2.735926866531372,
      "eval_runtime": 3.0108,
      "eval_samples_per_second": 4272.259,
      "eval_steps_per_second": 66.759,
      "step": 355162
    },
    {
      "epoch": 571.03,
      "learning_rate": 0.04292079662909968,
      "loss": 2.6234,
      "step": 355180
    },
    {
      "epoch": 571.06,
      "learning_rate": 0.04291758119823151,
      "loss": 2.6312,
      "step": 355200
    },
    {
      "epoch": 571.09,
      "learning_rate": 0.042914365767363356,
      "loss": 2.6425,
      "step": 355220
    },
    {
      "epoch": 571.13,
      "learning_rate": 0.04291115033649518,
      "loss": 2.6291,
      "step": 355240
    },
    {
      "epoch": 571.16,
      "learning_rate": 0.04290793490562701,
      "loss": 2.6285,
      "step": 355260
    },
    {
      "epoch": 571.19,
      "learning_rate": 0.042904719474758844,
      "loss": 2.6276,
      "step": 355280
    },
    {
      "epoch": 571.22,
      "learning_rate": 0.042901504043890676,
      "loss": 2.6255,
      "step": 355300
    },
    {
      "epoch": 571.25,
      "learning_rate": 0.04289828861302251,
      "loss": 2.6329,
      "step": 355320
    },
    {
      "epoch": 571.29,
      "learning_rate": 0.042895073182154346,
      "loss": 2.6346,
      "step": 355340
    },
    {
      "epoch": 571.32,
      "learning_rate": 0.04289185775128618,
      "loss": 2.6472,
      "step": 355360
    },
    {
      "epoch": 571.35,
      "learning_rate": 0.04288864232041801,
      "loss": 2.621,
      "step": 355380
    },
    {
      "epoch": 571.38,
      "learning_rate": 0.04288542688954984,
      "loss": 2.6213,
      "step": 355400
    },
    {
      "epoch": 571.41,
      "learning_rate": 0.04288221145868167,
      "loss": 2.6214,
      "step": 355420
    },
    {
      "epoch": 571.45,
      "learning_rate": 0.042878996027813504,
      "loss": 2.6432,
      "step": 355440
    },
    {
      "epoch": 571.48,
      "learning_rate": 0.04287578059694534,
      "loss": 2.6173,
      "step": 355460
    },
    {
      "epoch": 571.51,
      "learning_rate": 0.042872565166077174,
      "loss": 2.649,
      "step": 355480
    },
    {
      "epoch": 571.54,
      "learning_rate": 0.042869349735209006,
      "loss": 2.6313,
      "step": 355500
    },
    {
      "epoch": 571.58,
      "learning_rate": 0.04286613430434084,
      "loss": 2.618,
      "step": 355520
    },
    {
      "epoch": 571.61,
      "learning_rate": 0.04286291887347267,
      "loss": 2.6163,
      "step": 355540
    },
    {
      "epoch": 571.64,
      "learning_rate": 0.04285970344260451,
      "loss": 2.6215,
      "step": 355560
    },
    {
      "epoch": 571.67,
      "learning_rate": 0.04285648801173634,
      "loss": 2.6257,
      "step": 355580
    },
    {
      "epoch": 571.7,
      "learning_rate": 0.04285327258086817,
      "loss": 2.6165,
      "step": 355600
    },
    {
      "epoch": 571.74,
      "learning_rate": 0.04285005715,
      "loss": 2.639,
      "step": 355620
    },
    {
      "epoch": 571.77,
      "learning_rate": 0.042846841719131834,
      "loss": 2.6479,
      "step": 355640
    },
    {
      "epoch": 571.8,
      "learning_rate": 0.042843626288263666,
      "loss": 2.637,
      "step": 355660
    },
    {
      "epoch": 571.83,
      "learning_rate": 0.042840410857395504,
      "loss": 2.6597,
      "step": 355680
    },
    {
      "epoch": 571.86,
      "learning_rate": 0.042837195426527336,
      "loss": 2.6449,
      "step": 355700
    },
    {
      "epoch": 571.9,
      "learning_rate": 0.04283397999565917,
      "loss": 2.6138,
      "step": 355720
    },
    {
      "epoch": 571.93,
      "learning_rate": 0.04283092533633441,
      "loss": 2.6207,
      "step": 355740
    },
    {
      "epoch": 571.96,
      "learning_rate": 0.04282770990546624,
      "loss": 2.6102,
      "step": 355760
    },
    {
      "epoch": 571.99,
      "learning_rate": 0.042824494474598074,
      "loss": 2.6412,
      "step": 355780
    },
    {
      "epoch": 572.0,
      "eval_accuracy": {
        "accuracy": 0.41833164891549407
      },
      "eval_loss": 2.748807191848755,
      "eval_runtime": 4.2568,
      "eval_samples_per_second": 3021.745,
      "eval_steps_per_second": 47.218,
      "step": 355784
    },
    {
      "epoch": 572.03,
      "learning_rate": 0.042821279043729905,
      "loss": 2.6253,
      "step": 355800
    },
    {
      "epoch": 572.06,
      "learning_rate": 0.042818063612861744,
      "loss": 2.6241,
      "step": 355820
    },
    {
      "epoch": 572.09,
      "learning_rate": 0.042814848181993576,
      "loss": 2.6145,
      "step": 355840
    },
    {
      "epoch": 572.12,
      "learning_rate": 0.04281163275112541,
      "loss": 2.6289,
      "step": 355860
    },
    {
      "epoch": 572.15,
      "learning_rate": 0.04280841732025724,
      "loss": 2.6224,
      "step": 355880
    },
    {
      "epoch": 572.19,
      "learning_rate": 0.04280520188938907,
      "loss": 2.6341,
      "step": 355900
    },
    {
      "epoch": 572.22,
      "learning_rate": 0.0428019864585209,
      "loss": 2.6093,
      "step": 355920
    },
    {
      "epoch": 572.25,
      "learning_rate": 0.04279877102765274,
      "loss": 2.6422,
      "step": 355940
    },
    {
      "epoch": 572.28,
      "learning_rate": 0.04279555559678457,
      "loss": 2.6293,
      "step": 355960
    },
    {
      "epoch": 572.32,
      "learning_rate": 0.042792340165916404,
      "loss": 2.6285,
      "step": 355980
    },
    {
      "epoch": 572.35,
      "learning_rate": 0.042789124735048235,
      "loss": 2.6316,
      "step": 356000
    },
    {
      "epoch": 572.38,
      "learning_rate": 0.04278590930418007,
      "loss": 2.6182,
      "step": 356020
    },
    {
      "epoch": 572.41,
      "learning_rate": 0.042782693873311906,
      "loss": 2.6414,
      "step": 356040
    },
    {
      "epoch": 572.44,
      "learning_rate": 0.04277947844244374,
      "loss": 2.6275,
      "step": 356060
    },
    {
      "epoch": 572.48,
      "learning_rate": 0.04277626301157557,
      "loss": 2.6516,
      "step": 356080
    },
    {
      "epoch": 572.51,
      "learning_rate": 0.0427730475807074,
      "loss": 2.5989,
      "step": 356100
    },
    {
      "epoch": 572.54,
      "learning_rate": 0.04276983214983923,
      "loss": 2.6397,
      "step": 356120
    },
    {
      "epoch": 572.57,
      "learning_rate": 0.042766616718971064,
      "loss": 2.6466,
      "step": 356140
    },
    {
      "epoch": 572.6,
      "learning_rate": 0.0427634012881029,
      "loss": 2.6411,
      "step": 356160
    },
    {
      "epoch": 572.64,
      "learning_rate": 0.042760185857234734,
      "loss": 2.6394,
      "step": 356180
    },
    {
      "epoch": 572.67,
      "learning_rate": 0.042756970426366565,
      "loss": 2.6259,
      "step": 356200
    },
    {
      "epoch": 572.7,
      "learning_rate": 0.0427537549954984,
      "loss": 2.6059,
      "step": 356220
    },
    {
      "epoch": 572.73,
      "learning_rate": 0.04275053956463023,
      "loss": 2.6279,
      "step": 356240
    },
    {
      "epoch": 572.77,
      "learning_rate": 0.04274732413376205,
      "loss": 2.658,
      "step": 356260
    },
    {
      "epoch": 572.8,
      "learning_rate": 0.0427441087028939,
      "loss": 2.6237,
      "step": 356280
    },
    {
      "epoch": 572.83,
      "learning_rate": 0.04274089327202573,
      "loss": 2.6297,
      "step": 356300
    },
    {
      "epoch": 572.86,
      "learning_rate": 0.04273767784115756,
      "loss": 2.6296,
      "step": 356320
    },
    {
      "epoch": 572.89,
      "learning_rate": 0.042734462410289394,
      "loss": 2.6105,
      "step": 356340
    },
    {
      "epoch": 572.93,
      "learning_rate": 0.042731246979421225,
      "loss": 2.5954,
      "step": 356360
    },
    {
      "epoch": 572.96,
      "learning_rate": 0.042728031548553064,
      "loss": 2.6167,
      "step": 356380
    },
    {
      "epoch": 572.99,
      "learning_rate": 0.042724816117684895,
      "loss": 2.6106,
      "step": 356400
    },
    {
      "epoch": 573.0,
      "eval_accuracy": {
        "accuracy": 0.4226074788152064
      },
      "eval_loss": 2.730208158493042,
      "eval_runtime": 2.9315,
      "eval_samples_per_second": 4387.853,
      "eval_steps_per_second": 68.566,
      "step": 356406
    },
    {
      "epoch": 573.02,
      "learning_rate": 0.04272160068681673,
      "loss": 2.6365,
      "step": 356420
    },
    {
      "epoch": 573.05,
      "learning_rate": 0.04271838525594856,
      "loss": 2.6375,
      "step": 356440
    },
    {
      "epoch": 573.09,
      "learning_rate": 0.04271516982508039,
      "loss": 2.6299,
      "step": 356460
    },
    {
      "epoch": 573.12,
      "learning_rate": 0.042711954394212215,
      "loss": 2.6263,
      "step": 356480
    },
    {
      "epoch": 573.15,
      "learning_rate": 0.04270873896334406,
      "loss": 2.618,
      "step": 356500
    },
    {
      "epoch": 573.18,
      "learning_rate": 0.04270552353247589,
      "loss": 2.6435,
      "step": 356520
    },
    {
      "epoch": 573.22,
      "learning_rate": 0.042702308101607724,
      "loss": 2.6332,
      "step": 356540
    },
    {
      "epoch": 573.25,
      "learning_rate": 0.042699092670739555,
      "loss": 2.6154,
      "step": 356560
    },
    {
      "epoch": 573.28,
      "learning_rate": 0.04269587723987138,
      "loss": 2.651,
      "step": 356580
    },
    {
      "epoch": 573.31,
      "learning_rate": 0.04269266180900321,
      "loss": 2.6076,
      "step": 356600
    },
    {
      "epoch": 573.34,
      "learning_rate": 0.04268944637813506,
      "loss": 2.6449,
      "step": 356620
    },
    {
      "epoch": 573.38,
      "learning_rate": 0.04268623094726689,
      "loss": 2.6344,
      "step": 356640
    },
    {
      "epoch": 573.41,
      "learning_rate": 0.04268301551639872,
      "loss": 2.6226,
      "step": 356660
    },
    {
      "epoch": 573.44,
      "learning_rate": 0.04267980008553055,
      "loss": 2.6124,
      "step": 356680
    },
    {
      "epoch": 573.47,
      "learning_rate": 0.042676584654662376,
      "loss": 2.6336,
      "step": 356700
    },
    {
      "epoch": 573.5,
      "learning_rate": 0.04267336922379422,
      "loss": 2.6413,
      "step": 356720
    },
    {
      "epoch": 573.54,
      "learning_rate": 0.042670153792926054,
      "loss": 2.6582,
      "step": 356740
    },
    {
      "epoch": 573.57,
      "learning_rate": 0.042666938362057885,
      "loss": 2.6212,
      "step": 356760
    },
    {
      "epoch": 573.6,
      "learning_rate": 0.04266372293118972,
      "loss": 2.6193,
      "step": 356780
    },
    {
      "epoch": 573.63,
      "learning_rate": 0.04266050750032154,
      "loss": 2.621,
      "step": 356800
    },
    {
      "epoch": 573.67,
      "learning_rate": 0.04265729206945337,
      "loss": 2.6356,
      "step": 356820
    },
    {
      "epoch": 573.7,
      "learning_rate": 0.04265407663858522,
      "loss": 2.631,
      "step": 356840
    },
    {
      "epoch": 573.73,
      "learning_rate": 0.04265086120771705,
      "loss": 2.6273,
      "step": 356860
    },
    {
      "epoch": 573.76,
      "learning_rate": 0.04264764577684888,
      "loss": 2.6264,
      "step": 356880
    },
    {
      "epoch": 573.79,
      "learning_rate": 0.042644430345980706,
      "loss": 2.6561,
      "step": 356900
    },
    {
      "epoch": 573.83,
      "learning_rate": 0.04264121491511254,
      "loss": 2.6223,
      "step": 356920
    },
    {
      "epoch": 573.86,
      "learning_rate": 0.042637999484244384,
      "loss": 2.6351,
      "step": 356940
    },
    {
      "epoch": 573.89,
      "learning_rate": 0.042634784053376215,
      "loss": 2.6239,
      "step": 356960
    },
    {
      "epoch": 573.92,
      "learning_rate": 0.04263156862250805,
      "loss": 2.6216,
      "step": 356980
    },
    {
      "epoch": 573.95,
      "learning_rate": 0.04262835319163988,
      "loss": 2.6338,
      "step": 357000
    },
    {
      "epoch": 573.99,
      "learning_rate": 0.0426251377607717,
      "loss": 2.6305,
      "step": 357020
    },
    {
      "epoch": 574.0,
      "eval_accuracy": {
        "accuracy": 0.4212858586643862
      },
      "eval_loss": 2.7342965602874756,
      "eval_runtime": 2.9932,
      "eval_samples_per_second": 4297.446,
      "eval_steps_per_second": 67.153,
      "step": 357028
    },
    {
      "epoch": 574.02,
      "learning_rate": 0.042621922329903535,
      "loss": 2.6302,
      "step": 357040
    },
    {
      "epoch": 574.05,
      "learning_rate": 0.04261870689903538,
      "loss": 2.6362,
      "step": 357060
    },
    {
      "epoch": 574.08,
      "learning_rate": 0.04261549146816721,
      "loss": 2.6191,
      "step": 357080
    },
    {
      "epoch": 574.12,
      "learning_rate": 0.04261227603729904,
      "loss": 2.6402,
      "step": 357100
    },
    {
      "epoch": 574.15,
      "learning_rate": 0.04260906060643087,
      "loss": 2.6354,
      "step": 357120
    },
    {
      "epoch": 574.18,
      "learning_rate": 0.0426058451755627,
      "loss": 2.639,
      "step": 357140
    },
    {
      "epoch": 574.21,
      "learning_rate": 0.04260262974469453,
      "loss": 2.6269,
      "step": 357160
    },
    {
      "epoch": 574.24,
      "learning_rate": 0.04259941431382638,
      "loss": 2.6382,
      "step": 357180
    },
    {
      "epoch": 574.28,
      "learning_rate": 0.04259619888295821,
      "loss": 2.5988,
      "step": 357200
    },
    {
      "epoch": 574.31,
      "learning_rate": 0.04259298345209003,
      "loss": 2.6164,
      "step": 357220
    },
    {
      "epoch": 574.34,
      "learning_rate": 0.042589768021221865,
      "loss": 2.6021,
      "step": 357240
    },
    {
      "epoch": 574.37,
      "learning_rate": 0.042586552590353696,
      "loss": 2.6149,
      "step": 357260
    },
    {
      "epoch": 574.41,
      "learning_rate": 0.04258333715948554,
      "loss": 2.6057,
      "step": 357280
    },
    {
      "epoch": 574.44,
      "learning_rate": 0.04258012172861737,
      "loss": 2.6572,
      "step": 357300
    },
    {
      "epoch": 574.47,
      "learning_rate": 0.042576906297749205,
      "loss": 2.6573,
      "step": 357320
    },
    {
      "epoch": 574.5,
      "learning_rate": 0.04257369086688103,
      "loss": 2.6298,
      "step": 357340
    },
    {
      "epoch": 574.53,
      "learning_rate": 0.04257047543601286,
      "loss": 2.629,
      "step": 357360
    },
    {
      "epoch": 574.57,
      "learning_rate": 0.04256726000514469,
      "loss": 2.6158,
      "step": 357380
    },
    {
      "epoch": 574.6,
      "learning_rate": 0.04256404457427654,
      "loss": 2.633,
      "step": 357400
    },
    {
      "epoch": 574.63,
      "learning_rate": 0.04256082914340837,
      "loss": 2.6306,
      "step": 357420
    },
    {
      "epoch": 574.66,
      "learning_rate": 0.042557613712540195,
      "loss": 2.6453,
      "step": 357440
    },
    {
      "epoch": 574.69,
      "learning_rate": 0.042554398281672026,
      "loss": 2.6456,
      "step": 357460
    },
    {
      "epoch": 574.73,
      "learning_rate": 0.04255118285080386,
      "loss": 2.632,
      "step": 357480
    },
    {
      "epoch": 574.76,
      "learning_rate": 0.04254796741993569,
      "loss": 2.6128,
      "step": 357500
    },
    {
      "epoch": 574.79,
      "learning_rate": 0.042544751989067535,
      "loss": 2.6289,
      "step": 357520
    },
    {
      "epoch": 574.82,
      "learning_rate": 0.04254153655819936,
      "loss": 2.6108,
      "step": 357540
    },
    {
      "epoch": 574.86,
      "learning_rate": 0.04253832112733119,
      "loss": 2.606,
      "step": 357560
    },
    {
      "epoch": 574.89,
      "learning_rate": 0.04253510569646302,
      "loss": 2.6028,
      "step": 357580
    },
    {
      "epoch": 574.92,
      "learning_rate": 0.042531890265594854,
      "loss": 2.6431,
      "step": 357600
    },
    {
      "epoch": 574.95,
      "learning_rate": 0.0425286748347267,
      "loss": 2.637,
      "step": 357620
    },
    {
      "epoch": 574.98,
      "learning_rate": 0.04252545940385853,
      "loss": 2.636,
      "step": 357640
    },
    {
      "epoch": 575.0,
      "eval_accuracy": {
        "accuracy": 0.4251729767550338
      },
      "eval_loss": 2.7120981216430664,
      "eval_runtime": 2.9156,
      "eval_samples_per_second": 4411.709,
      "eval_steps_per_second": 68.938,
      "step": 357650
    },
    {
      "epoch": 575.02,
      "learning_rate": 0.042522243972990356,
      "loss": 2.6404,
      "step": 357660
    },
    {
      "epoch": 575.05,
      "learning_rate": 0.04251902854212219,
      "loss": 2.5983,
      "step": 357680
    },
    {
      "epoch": 575.08,
      "learning_rate": 0.04251581311125402,
      "loss": 2.6244,
      "step": 357700
    },
    {
      "epoch": 575.11,
      "learning_rate": 0.04251259768038585,
      "loss": 2.6232,
      "step": 357720
    },
    {
      "epoch": 575.14,
      "learning_rate": 0.042509382249517697,
      "loss": 2.6001,
      "step": 357740
    },
    {
      "epoch": 575.18,
      "learning_rate": 0.04250616681864952,
      "loss": 2.6406,
      "step": 357760
    },
    {
      "epoch": 575.21,
      "learning_rate": 0.04250295138778135,
      "loss": 2.6374,
      "step": 357780
    },
    {
      "epoch": 575.24,
      "learning_rate": 0.042499735956913184,
      "loss": 2.6399,
      "step": 357800
    },
    {
      "epoch": 575.27,
      "learning_rate": 0.042496520526045016,
      "loss": 2.6254,
      "step": 357820
    },
    {
      "epoch": 575.31,
      "learning_rate": 0.04249330509517685,
      "loss": 2.6332,
      "step": 357840
    },
    {
      "epoch": 575.34,
      "learning_rate": 0.042490089664308686,
      "loss": 2.6156,
      "step": 357860
    },
    {
      "epoch": 575.37,
      "learning_rate": 0.04248687423344052,
      "loss": 2.6264,
      "step": 357880
    },
    {
      "epoch": 575.4,
      "learning_rate": 0.04248365880257235,
      "loss": 2.6046,
      "step": 357900
    },
    {
      "epoch": 575.43,
      "learning_rate": 0.04248044337170418,
      "loss": 2.6198,
      "step": 357920
    },
    {
      "epoch": 575.47,
      "learning_rate": 0.04247722794083601,
      "loss": 2.6302,
      "step": 357940
    },
    {
      "epoch": 575.5,
      "learning_rate": 0.04247401250996786,
      "loss": 2.6254,
      "step": 357960
    },
    {
      "epoch": 575.53,
      "learning_rate": 0.04247095785064309,
      "loss": 2.6247,
      "step": 357980
    },
    {
      "epoch": 575.56,
      "learning_rate": 0.042467742419774926,
      "loss": 2.6235,
      "step": 358000
    },
    {
      "epoch": 575.59,
      "learning_rate": 0.04246452698890676,
      "loss": 2.6235,
      "step": 358020
    },
    {
      "epoch": 575.63,
      "learning_rate": 0.04246131155803859,
      "loss": 2.6455,
      "step": 358040
    },
    {
      "epoch": 575.66,
      "learning_rate": 0.04245809612717042,
      "loss": 2.6253,
      "step": 358060
    },
    {
      "epoch": 575.69,
      "learning_rate": 0.04245488069630225,
      "loss": 2.6194,
      "step": 358080
    },
    {
      "epoch": 575.72,
      "learning_rate": 0.04245166526543409,
      "loss": 2.6249,
      "step": 358100
    },
    {
      "epoch": 575.76,
      "learning_rate": 0.04244844983456592,
      "loss": 2.637,
      "step": 358120
    },
    {
      "epoch": 575.79,
      "learning_rate": 0.042445234403697754,
      "loss": 2.6466,
      "step": 358140
    },
    {
      "epoch": 575.82,
      "learning_rate": 0.042442018972829586,
      "loss": 2.651,
      "step": 358160
    },
    {
      "epoch": 575.85,
      "learning_rate": 0.04243880354196142,
      "loss": 2.609,
      "step": 358180
    },
    {
      "epoch": 575.88,
      "learning_rate": 0.04243558811109325,
      "loss": 2.6453,
      "step": 358200
    },
    {
      "epoch": 575.92,
      "learning_rate": 0.04243237268022509,
      "loss": 2.6329,
      "step": 358220
    },
    {
      "epoch": 575.95,
      "learning_rate": 0.04242915724935692,
      "loss": 2.594,
      "step": 358240
    },
    {
      "epoch": 575.98,
      "learning_rate": 0.04242594181848875,
      "loss": 2.6257,
      "step": 358260
    },
    {
      "epoch": 576.0,
      "eval_accuracy": {
        "accuracy": 0.4191868148954365
      },
      "eval_loss": 2.739531993865967,
      "eval_runtime": 2.8419,
      "eval_samples_per_second": 4526.231,
      "eval_steps_per_second": 70.728,
      "step": 358272
    },
    {
      "epoch": 576.01,
      "learning_rate": 0.04242272638762058,
      "loss": 2.6296,
      "step": 358280
    },
    {
      "epoch": 576.05,
      "learning_rate": 0.042419510956752414,
      "loss": 2.6348,
      "step": 358300
    },
    {
      "epoch": 576.08,
      "learning_rate": 0.042416295525884246,
      "loss": 2.6374,
      "step": 358320
    },
    {
      "epoch": 576.11,
      "learning_rate": 0.042413080095016084,
      "loss": 2.6358,
      "step": 358340
    },
    {
      "epoch": 576.14,
      "learning_rate": 0.042409864664147916,
      "loss": 2.6013,
      "step": 358360
    },
    {
      "epoch": 576.17,
      "learning_rate": 0.04240664923327975,
      "loss": 2.6352,
      "step": 358380
    },
    {
      "epoch": 576.21,
      "learning_rate": 0.04240343380241158,
      "loss": 2.6245,
      "step": 358400
    },
    {
      "epoch": 576.24,
      "learning_rate": 0.04240021837154341,
      "loss": 2.5934,
      "step": 358420
    },
    {
      "epoch": 576.27,
      "learning_rate": 0.04239700294067525,
      "loss": 2.6335,
      "step": 358440
    },
    {
      "epoch": 576.3,
      "learning_rate": 0.04239378750980708,
      "loss": 2.6179,
      "step": 358460
    },
    {
      "epoch": 576.33,
      "learning_rate": 0.04239057207893891,
      "loss": 2.6484,
      "step": 358480
    },
    {
      "epoch": 576.37,
      "learning_rate": 0.042387356648070744,
      "loss": 2.6363,
      "step": 358500
    },
    {
      "epoch": 576.4,
      "learning_rate": 0.042384141217202576,
      "loss": 2.6642,
      "step": 358520
    },
    {
      "epoch": 576.43,
      "learning_rate": 0.04238092578633441,
      "loss": 2.622,
      "step": 358540
    },
    {
      "epoch": 576.46,
      "learning_rate": 0.042377710355466246,
      "loss": 2.6101,
      "step": 358560
    },
    {
      "epoch": 576.5,
      "learning_rate": 0.04237449492459808,
      "loss": 2.6319,
      "step": 358580
    },
    {
      "epoch": 576.53,
      "learning_rate": 0.04237127949372991,
      "loss": 2.6254,
      "step": 358600
    },
    {
      "epoch": 576.56,
      "learning_rate": 0.04236806406286174,
      "loss": 2.6319,
      "step": 358620
    },
    {
      "epoch": 576.59,
      "learning_rate": 0.04236484863199357,
      "loss": 2.6399,
      "step": 358640
    },
    {
      "epoch": 576.62,
      "learning_rate": 0.042361633201125404,
      "loss": 2.6272,
      "step": 358660
    },
    {
      "epoch": 576.66,
      "learning_rate": 0.04235841777025724,
      "loss": 2.6323,
      "step": 358680
    },
    {
      "epoch": 576.69,
      "learning_rate": 0.042355202339389074,
      "loss": 2.6118,
      "step": 358700
    },
    {
      "epoch": 576.72,
      "learning_rate": 0.042351986908520906,
      "loss": 2.6523,
      "step": 358720
    },
    {
      "epoch": 576.75,
      "learning_rate": 0.04234877147765274,
      "loss": 2.6217,
      "step": 358740
    },
    {
      "epoch": 576.78,
      "learning_rate": 0.04234555604678457,
      "loss": 2.6144,
      "step": 358760
    },
    {
      "epoch": 576.82,
      "learning_rate": 0.04234234061591641,
      "loss": 2.6132,
      "step": 358780
    },
    {
      "epoch": 576.85,
      "learning_rate": 0.04233912518504824,
      "loss": 2.6348,
      "step": 358800
    },
    {
      "epoch": 576.88,
      "learning_rate": 0.04233590975418007,
      "loss": 2.629,
      "step": 358820
    },
    {
      "epoch": 576.91,
      "learning_rate": 0.0423326943233119,
      "loss": 2.6257,
      "step": 358840
    },
    {
      "epoch": 576.95,
      "learning_rate": 0.042329478892443734,
      "loss": 2.619,
      "step": 358860
    },
    {
      "epoch": 576.98,
      "learning_rate": 0.042326263461575565,
      "loss": 2.6356,
      "step": 358880
    },
    {
      "epoch": 577.0,
      "eval_accuracy": {
        "accuracy": 0.4220632822825157
      },
      "eval_loss": 2.738715410232544,
      "eval_runtime": 3.0121,
      "eval_samples_per_second": 4270.507,
      "eval_steps_per_second": 66.732,
      "step": 358894
    },
    {
      "epoch": 577.01,
      "learning_rate": 0.042323048030707404,
      "loss": 2.6161,
      "step": 358900
    },
    {
      "epoch": 577.04,
      "learning_rate": 0.042319832599839236,
      "loss": 2.6165,
      "step": 358920
    },
    {
      "epoch": 577.07,
      "learning_rate": 0.04231661716897107,
      "loss": 2.6272,
      "step": 358940
    },
    {
      "epoch": 577.11,
      "learning_rate": 0.0423134017381029,
      "loss": 2.6118,
      "step": 358960
    },
    {
      "epoch": 577.14,
      "learning_rate": 0.04231018630723473,
      "loss": 2.624,
      "step": 358980
    },
    {
      "epoch": 577.17,
      "learning_rate": 0.042306970876366555,
      "loss": 2.6232,
      "step": 359000
    },
    {
      "epoch": 577.2,
      "learning_rate": 0.0423037554454984,
      "loss": 2.5989,
      "step": 359020
    },
    {
      "epoch": 577.23,
      "learning_rate": 0.04230054001463023,
      "loss": 2.6281,
      "step": 359040
    },
    {
      "epoch": 577.27,
      "learning_rate": 0.042297324583762064,
      "loss": 2.6298,
      "step": 359060
    },
    {
      "epoch": 577.3,
      "learning_rate": 0.042294109152893895,
      "loss": 2.6502,
      "step": 359080
    },
    {
      "epoch": 577.33,
      "learning_rate": 0.04229089372202572,
      "loss": 2.6285,
      "step": 359100
    },
    {
      "epoch": 577.36,
      "learning_rate": 0.042287678291157565,
      "loss": 2.6156,
      "step": 359120
    },
    {
      "epoch": 577.4,
      "learning_rate": 0.0422844628602894,
      "loss": 2.6202,
      "step": 359140
    },
    {
      "epoch": 577.43,
      "learning_rate": 0.04228124742942123,
      "loss": 2.6214,
      "step": 359160
    },
    {
      "epoch": 577.46,
      "learning_rate": 0.04227803199855306,
      "loss": 2.6363,
      "step": 359180
    },
    {
      "epoch": 577.49,
      "learning_rate": 0.04227481656768489,
      "loss": 2.649,
      "step": 359200
    },
    {
      "epoch": 577.52,
      "learning_rate": 0.04227160113681672,
      "loss": 2.6353,
      "step": 359220
    },
    {
      "epoch": 577.56,
      "learning_rate": 0.04226838570594856,
      "loss": 2.626,
      "step": 359240
    },
    {
      "epoch": 577.59,
      "learning_rate": 0.042265170275080394,
      "loss": 2.6359,
      "step": 359260
    },
    {
      "epoch": 577.62,
      "learning_rate": 0.042261954844212225,
      "loss": 2.634,
      "step": 359280
    },
    {
      "epoch": 577.65,
      "learning_rate": 0.04225873941334406,
      "loss": 2.6308,
      "step": 359300
    },
    {
      "epoch": 577.68,
      "learning_rate": 0.04225552398247588,
      "loss": 2.6279,
      "step": 359320
    },
    {
      "epoch": 577.72,
      "learning_rate": 0.04225230855160771,
      "loss": 2.6154,
      "step": 359340
    },
    {
      "epoch": 577.75,
      "learning_rate": 0.04224909312073956,
      "loss": 2.6274,
      "step": 359360
    },
    {
      "epoch": 577.78,
      "learning_rate": 0.04224587768987139,
      "loss": 2.608,
      "step": 359380
    },
    {
      "epoch": 577.81,
      "learning_rate": 0.04224266225900322,
      "loss": 2.6223,
      "step": 359400
    },
    {
      "epoch": 577.85,
      "learning_rate": 0.04223944682813505,
      "loss": 2.6125,
      "step": 359420
    },
    {
      "epoch": 577.88,
      "learning_rate": 0.04223623139726688,
      "loss": 2.6087,
      "step": 359440
    },
    {
      "epoch": 577.91,
      "learning_rate": 0.042233015966398724,
      "loss": 2.6482,
      "step": 359460
    },
    {
      "epoch": 577.94,
      "learning_rate": 0.042229800535530555,
      "loss": 2.6174,
      "step": 359480
    },
    {
      "epoch": 577.97,
      "learning_rate": 0.04222658510466239,
      "loss": 2.6095,
      "step": 359500
    },
    {
      "epoch": 578.0,
      "eval_accuracy": {
        "accuracy": 0.42330716007152297
      },
      "eval_loss": 2.7438697814941406,
      "eval_runtime": 2.9852,
      "eval_samples_per_second": 4308.89,
      "eval_steps_per_second": 67.332,
      "step": 359516
    },
    {
      "epoch": 578.01,
      "learning_rate": 0.04222336967379422,
      "loss": 2.6429,
      "step": 359520
    },
    {
      "epoch": 578.04,
      "learning_rate": 0.04222015424292604,
      "loss": 2.6365,
      "step": 359540
    },
    {
      "epoch": 578.07,
      "learning_rate": 0.042216938812057875,
      "loss": 2.601,
      "step": 359560
    },
    {
      "epoch": 578.1,
      "learning_rate": 0.04221372338118972,
      "loss": 2.6251,
      "step": 359580
    },
    {
      "epoch": 578.14,
      "learning_rate": 0.04221050795032155,
      "loss": 2.6131,
      "step": 359600
    },
    {
      "epoch": 578.17,
      "learning_rate": 0.042207292519453384,
      "loss": 2.6228,
      "step": 359620
    },
    {
      "epoch": 578.2,
      "learning_rate": 0.04220407708858521,
      "loss": 2.6253,
      "step": 359640
    },
    {
      "epoch": 578.23,
      "learning_rate": 0.04220086165771704,
      "loss": 2.6023,
      "step": 359660
    },
    {
      "epoch": 578.26,
      "learning_rate": 0.042197646226848885,
      "loss": 2.6037,
      "step": 359680
    },
    {
      "epoch": 578.3,
      "learning_rate": 0.04219443079598072,
      "loss": 2.6173,
      "step": 359700
    },
    {
      "epoch": 578.33,
      "learning_rate": 0.04219121536511255,
      "loss": 2.6333,
      "step": 359720
    },
    {
      "epoch": 578.36,
      "learning_rate": 0.04218799993424437,
      "loss": 2.6301,
      "step": 359740
    },
    {
      "epoch": 578.39,
      "learning_rate": 0.042184784503376205,
      "loss": 2.6418,
      "step": 359760
    },
    {
      "epoch": 578.42,
      "learning_rate": 0.042181569072508036,
      "loss": 2.6182,
      "step": 359780
    },
    {
      "epoch": 578.46,
      "learning_rate": 0.04217835364163988,
      "loss": 2.6057,
      "step": 359800
    },
    {
      "epoch": 578.49,
      "learning_rate": 0.042175138210771713,
      "loss": 2.6316,
      "step": 359820
    },
    {
      "epoch": 578.52,
      "learning_rate": 0.042171922779903545,
      "loss": 2.6181,
      "step": 359840
    },
    {
      "epoch": 578.55,
      "learning_rate": 0.04216870734903537,
      "loss": 2.6299,
      "step": 359860
    },
    {
      "epoch": 578.59,
      "learning_rate": 0.0421654919181672,
      "loss": 2.6342,
      "step": 359880
    },
    {
      "epoch": 578.62,
      "learning_rate": 0.04216227648729903,
      "loss": 2.6432,
      "step": 359900
    },
    {
      "epoch": 578.65,
      "learning_rate": 0.04215906105643088,
      "loss": 2.6257,
      "step": 359920
    },
    {
      "epoch": 578.68,
      "learning_rate": 0.04215584562556271,
      "loss": 2.6236,
      "step": 359940
    },
    {
      "epoch": 578.71,
      "learning_rate": 0.042152630194694535,
      "loss": 2.6347,
      "step": 359960
    },
    {
      "epoch": 578.75,
      "learning_rate": 0.042149414763826366,
      "loss": 2.6106,
      "step": 359980
    },
    {
      "epoch": 578.78,
      "learning_rate": 0.0421461993329582,
      "loss": 2.6438,
      "step": 360000
    },
    {
      "epoch": 578.81,
      "learning_rate": 0.04214298390209004,
      "loss": 2.6129,
      "step": 360020
    },
    {
      "epoch": 578.84,
      "learning_rate": 0.042139768471221875,
      "loss": 2.6175,
      "step": 360040
    },
    {
      "epoch": 578.87,
      "learning_rate": 0.0421365530403537,
      "loss": 2.6095,
      "step": 360060
    },
    {
      "epoch": 578.91,
      "learning_rate": 0.04213349838102894,
      "loss": 2.6179,
      "step": 360080
    },
    {
      "epoch": 578.94,
      "learning_rate": 0.042130282950160775,
      "loss": 2.6299,
      "step": 360100
    },
    {
      "epoch": 578.97,
      "learning_rate": 0.042127067519292606,
      "loss": 2.6238,
      "step": 360120
    },
    {
      "epoch": 579.0,
      "eval_accuracy": {
        "accuracy": 0.41514421208116303
      },
      "eval_loss": 2.7429630756378174,
      "eval_runtime": 3.01,
      "eval_samples_per_second": 4273.467,
      "eval_steps_per_second": 66.778,
      "step": 360138
    },
    {
      "epoch": 579.0,
      "learning_rate": 0.04212385208842444,
      "loss": 2.6283,
      "step": 360140
    },
    {
      "epoch": 579.04,
      "learning_rate": 0.04212063665755627,
      "loss": 2.6453,
      "step": 360160
    },
    {
      "epoch": 579.07,
      "learning_rate": 0.04211742122668811,
      "loss": 2.6252,
      "step": 360180
    },
    {
      "epoch": 579.1,
      "learning_rate": 0.04211420579581994,
      "loss": 2.6425,
      "step": 360200
    },
    {
      "epoch": 579.13,
      "learning_rate": 0.04211099036495177,
      "loss": 2.6027,
      "step": 360220
    },
    {
      "epoch": 579.16,
      "learning_rate": 0.0421077749340836,
      "loss": 2.6197,
      "step": 360240
    },
    {
      "epoch": 579.2,
      "learning_rate": 0.042104559503215434,
      "loss": 2.6268,
      "step": 360260
    },
    {
      "epoch": 579.23,
      "learning_rate": 0.04210134407234727,
      "loss": 2.6387,
      "step": 360280
    },
    {
      "epoch": 579.26,
      "learning_rate": 0.042098128641479104,
      "loss": 2.6305,
      "step": 360300
    },
    {
      "epoch": 579.29,
      "learning_rate": 0.042094913210610936,
      "loss": 2.627,
      "step": 360320
    },
    {
      "epoch": 579.32,
      "learning_rate": 0.04209169777974277,
      "loss": 2.6128,
      "step": 360340
    },
    {
      "epoch": 579.36,
      "learning_rate": 0.0420884823488746,
      "loss": 2.6411,
      "step": 360360
    },
    {
      "epoch": 579.39,
      "learning_rate": 0.04208526691800643,
      "loss": 2.621,
      "step": 360380
    },
    {
      "epoch": 579.42,
      "learning_rate": 0.04208205148713827,
      "loss": 2.5996,
      "step": 360400
    },
    {
      "epoch": 579.45,
      "learning_rate": 0.0420788360562701,
      "loss": 2.6154,
      "step": 360420
    },
    {
      "epoch": 579.49,
      "learning_rate": 0.04207562062540193,
      "loss": 2.6346,
      "step": 360440
    },
    {
      "epoch": 579.52,
      "learning_rate": 0.042072405194533764,
      "loss": 2.6337,
      "step": 360460
    },
    {
      "epoch": 579.55,
      "learning_rate": 0.042069189763665596,
      "loss": 2.6274,
      "step": 360480
    },
    {
      "epoch": 579.58,
      "learning_rate": 0.042065974332797434,
      "loss": 2.6332,
      "step": 360500
    },
    {
      "epoch": 579.61,
      "learning_rate": 0.042062758901929266,
      "loss": 2.6448,
      "step": 360520
    },
    {
      "epoch": 579.65,
      "learning_rate": 0.0420595434710611,
      "loss": 2.6283,
      "step": 360540
    },
    {
      "epoch": 579.68,
      "learning_rate": 0.04205632804019293,
      "loss": 2.6188,
      "step": 360560
    },
    {
      "epoch": 579.71,
      "learning_rate": 0.04205311260932476,
      "loss": 2.6108,
      "step": 360580
    },
    {
      "epoch": 579.74,
      "learning_rate": 0.04204989717845659,
      "loss": 2.6308,
      "step": 360600
    },
    {
      "epoch": 579.77,
      "learning_rate": 0.04204668174758843,
      "loss": 2.6366,
      "step": 360620
    },
    {
      "epoch": 579.81,
      "learning_rate": 0.04204346631672026,
      "loss": 2.6293,
      "step": 360640
    },
    {
      "epoch": 579.84,
      "learning_rate": 0.042040250885852094,
      "loss": 2.6445,
      "step": 360660
    },
    {
      "epoch": 579.87,
      "learning_rate": 0.042037035454983926,
      "loss": 2.6359,
      "step": 360680
    },
    {
      "epoch": 579.9,
      "learning_rate": 0.04203382002411576,
      "loss": 2.6336,
      "step": 360700
    },
    {
      "epoch": 579.94,
      "learning_rate": 0.04203060459324759,
      "loss": 2.6199,
      "step": 360720
    },
    {
      "epoch": 579.97,
      "learning_rate": 0.04202738916237943,
      "loss": 2.6159,
      "step": 360740
    },
    {
      "epoch": 580.0,
      "learning_rate": 0.04202417373151126,
      "loss": 2.6055,
      "step": 360760
    },
    {
      "epoch": 580.0,
      "eval_accuracy": {
        "accuracy": 0.42167457047345097
      },
      "eval_loss": 2.7327072620391846,
      "eval_runtime": 2.9841,
      "eval_samples_per_second": 4310.451,
      "eval_steps_per_second": 67.356,
      "step": 360760
    },
    {
      "epoch": 580.03,
      "learning_rate": 0.04202095830064309,
      "loss": 2.6175,
      "step": 360780
    },
    {
      "epoch": 580.06,
      "learning_rate": 0.04201774286977492,
      "loss": 2.6259,
      "step": 360800
    },
    {
      "epoch": 580.1,
      "learning_rate": 0.042014527438906754,
      "loss": 2.6218,
      "step": 360820
    },
    {
      "epoch": 580.13,
      "learning_rate": 0.04201131200803859,
      "loss": 2.6412,
      "step": 360840
    },
    {
      "epoch": 580.16,
      "learning_rate": 0.042008096577170424,
      "loss": 2.5968,
      "step": 360860
    },
    {
      "epoch": 580.19,
      "learning_rate": 0.042004881146302256,
      "loss": 2.6119,
      "step": 360880
    },
    {
      "epoch": 580.23,
      "learning_rate": 0.04200166571543409,
      "loss": 2.6319,
      "step": 360900
    },
    {
      "epoch": 580.26,
      "learning_rate": 0.04199845028456592,
      "loss": 2.6135,
      "step": 360920
    },
    {
      "epoch": 580.29,
      "learning_rate": 0.04199523485369775,
      "loss": 2.6094,
      "step": 360940
    },
    {
      "epoch": 580.32,
      "learning_rate": 0.04199201942282959,
      "loss": 2.6224,
      "step": 360960
    },
    {
      "epoch": 580.35,
      "learning_rate": 0.04198880399196142,
      "loss": 2.6185,
      "step": 360980
    },
    {
      "epoch": 580.39,
      "learning_rate": 0.04198558856109325,
      "loss": 2.6286,
      "step": 361000
    },
    {
      "epoch": 580.42,
      "learning_rate": 0.041982373130225084,
      "loss": 2.6094,
      "step": 361020
    },
    {
      "epoch": 580.45,
      "learning_rate": 0.041979157699356916,
      "loss": 2.6145,
      "step": 361040
    },
    {
      "epoch": 580.48,
      "learning_rate": 0.04197594226848875,
      "loss": 2.6243,
      "step": 361060
    },
    {
      "epoch": 580.51,
      "learning_rate": 0.041972726837620586,
      "loss": 2.6303,
      "step": 361080
    },
    {
      "epoch": 580.55,
      "learning_rate": 0.04196951140675242,
      "loss": 2.6132,
      "step": 361100
    },
    {
      "epoch": 580.58,
      "learning_rate": 0.04196629597588425,
      "loss": 2.6208,
      "step": 361120
    },
    {
      "epoch": 580.61,
      "learning_rate": 0.04196308054501608,
      "loss": 2.6277,
      "step": 361140
    },
    {
      "epoch": 580.64,
      "learning_rate": 0.04195986511414791,
      "loss": 2.6008,
      "step": 361160
    },
    {
      "epoch": 580.68,
      "learning_rate": 0.04195664968327975,
      "loss": 2.6115,
      "step": 361180
    },
    {
      "epoch": 580.71,
      "learning_rate": 0.04195343425241158,
      "loss": 2.6319,
      "step": 361200
    },
    {
      "epoch": 580.74,
      "learning_rate": 0.041950218821543414,
      "loss": 2.6317,
      "step": 361220
    },
    {
      "epoch": 580.77,
      "learning_rate": 0.041947003390675246,
      "loss": 2.6133,
      "step": 361240
    },
    {
      "epoch": 580.8,
      "learning_rate": 0.04194378795980708,
      "loss": 2.6359,
      "step": 361260
    },
    {
      "epoch": 580.84,
      "learning_rate": 0.04194057252893891,
      "loss": 2.6076,
      "step": 361280
    },
    {
      "epoch": 580.87,
      "learning_rate": 0.04193735709807075,
      "loss": 2.6183,
      "step": 361300
    },
    {
      "epoch": 580.9,
      "learning_rate": 0.04193414166720258,
      "loss": 2.6432,
      "step": 361320
    },
    {
      "epoch": 580.93,
      "learning_rate": 0.04193092623633441,
      "loss": 2.6317,
      "step": 361340
    },
    {
      "epoch": 580.96,
      "learning_rate": 0.04192771080546624,
      "loss": 2.6244,
      "step": 361360
    },
    {
      "epoch": 581.0,
      "learning_rate": 0.041924495374598074,
      "loss": 2.6332,
      "step": 361380
    },
    {
      "epoch": 581.0,
      "eval_accuracy": {
        "accuracy": 0.42361812951877476
      },
      "eval_loss": 2.7391276359558105,
      "eval_runtime": 3.2058,
      "eval_samples_per_second": 4012.437,
      "eval_steps_per_second": 62.699,
      "step": 361382
    },
    {
      "epoch": 581.03,
      "learning_rate": 0.041921279943729906,
      "loss": 2.6238,
      "step": 361400
    },
    {
      "epoch": 581.06,
      "learning_rate": 0.041918064512861744,
      "loss": 2.6282,
      "step": 361420
    },
    {
      "epoch": 581.09,
      "learning_rate": 0.041914849081993576,
      "loss": 2.6272,
      "step": 361440
    },
    {
      "epoch": 581.13,
      "learning_rate": 0.04191163365112541,
      "loss": 2.6238,
      "step": 361460
    },
    {
      "epoch": 581.16,
      "learning_rate": 0.04190841822025724,
      "loss": 2.6008,
      "step": 361480
    },
    {
      "epoch": 581.19,
      "learning_rate": 0.04190520278938907,
      "loss": 2.6184,
      "step": 361500
    },
    {
      "epoch": 581.22,
      "learning_rate": 0.04190198735852091,
      "loss": 2.6055,
      "step": 361520
    },
    {
      "epoch": 581.25,
      "learning_rate": 0.04189877192765274,
      "loss": 2.6429,
      "step": 361540
    },
    {
      "epoch": 581.29,
      "learning_rate": 0.04189555649678457,
      "loss": 2.6024,
      "step": 361560
    },
    {
      "epoch": 581.32,
      "learning_rate": 0.041892341065916404,
      "loss": 2.6033,
      "step": 361580
    },
    {
      "epoch": 581.35,
      "learning_rate": 0.041889125635048235,
      "loss": 2.6181,
      "step": 361600
    },
    {
      "epoch": 581.38,
      "learning_rate": 0.04188591020418006,
      "loss": 2.6107,
      "step": 361620
    },
    {
      "epoch": 581.41,
      "learning_rate": 0.041882694773311906,
      "loss": 2.636,
      "step": 361640
    },
    {
      "epoch": 581.45,
      "learning_rate": 0.04187947934244374,
      "loss": 2.618,
      "step": 361660
    },
    {
      "epoch": 581.48,
      "learning_rate": 0.04187626391157557,
      "loss": 2.6251,
      "step": 361680
    },
    {
      "epoch": 581.51,
      "learning_rate": 0.0418730484807074,
      "loss": 2.5974,
      "step": 361700
    },
    {
      "epoch": 581.54,
      "learning_rate": 0.04186983304983923,
      "loss": 2.6009,
      "step": 361720
    },
    {
      "epoch": 581.58,
      "learning_rate": 0.04186661761897106,
      "loss": 2.6316,
      "step": 361740
    },
    {
      "epoch": 581.61,
      "learning_rate": 0.0418634021881029,
      "loss": 2.6119,
      "step": 361760
    },
    {
      "epoch": 581.64,
      "learning_rate": 0.041860186757234734,
      "loss": 2.618,
      "step": 361780
    },
    {
      "epoch": 581.67,
      "learning_rate": 0.041856971326366565,
      "loss": 2.6167,
      "step": 361800
    },
    {
      "epoch": 581.7,
      "learning_rate": 0.0418537558954984,
      "loss": 2.6217,
      "step": 361820
    },
    {
      "epoch": 581.74,
      "learning_rate": 0.04185054046463022,
      "loss": 2.6266,
      "step": 361840
    },
    {
      "epoch": 581.77,
      "learning_rate": 0.04184732503376207,
      "loss": 2.6416,
      "step": 361860
    },
    {
      "epoch": 581.8,
      "learning_rate": 0.0418441096028939,
      "loss": 2.6361,
      "step": 361880
    },
    {
      "epoch": 581.83,
      "learning_rate": 0.04184089417202573,
      "loss": 2.6249,
      "step": 361900
    },
    {
      "epoch": 581.86,
      "learning_rate": 0.04183767874115756,
      "loss": 2.6087,
      "step": 361920
    },
    {
      "epoch": 581.9,
      "learning_rate": 0.04183446331028939,
      "loss": 2.6314,
      "step": 361940
    },
    {
      "epoch": 581.93,
      "learning_rate": 0.04183124787942122,
      "loss": 2.6307,
      "step": 361960
    },
    {
      "epoch": 581.96,
      "learning_rate": 0.041828032448553064,
      "loss": 2.6123,
      "step": 361980
    },
    {
      "epoch": 581.99,
      "learning_rate": 0.041824817017684895,
      "loss": 2.6107,
      "step": 362000
    },
    {
      "epoch": 582.0,
      "eval_accuracy": {
        "accuracy": 0.42447329549871726
      },
      "eval_loss": 2.7227602005004883,
      "eval_runtime": 3.1733,
      "eval_samples_per_second": 4053.523,
      "eval_steps_per_second": 63.341,
      "step": 362004
    },
    {
      "epoch": 582.03,
      "learning_rate": 0.04182160158681673,
      "loss": 2.6146,
      "step": 362020
    },
    {
      "epoch": 582.06,
      "learning_rate": 0.04181838615594856,
      "loss": 2.6173,
      "step": 362040
    },
    {
      "epoch": 582.09,
      "learning_rate": 0.04181517072508038,
      "loss": 2.616,
      "step": 362060
    },
    {
      "epoch": 582.12,
      "learning_rate": 0.04181195529421223,
      "loss": 2.6122,
      "step": 362080
    },
    {
      "epoch": 582.15,
      "learning_rate": 0.04180890063488746,
      "loss": 2.618,
      "step": 362100
    },
    {
      "epoch": 582.19,
      "learning_rate": 0.041805685204019304,
      "loss": 2.5941,
      "step": 362120
    },
    {
      "epoch": 582.22,
      "learning_rate": 0.041802469773151135,
      "loss": 2.5996,
      "step": 362140
    },
    {
      "epoch": 582.25,
      "learning_rate": 0.04179925434228296,
      "loss": 2.6529,
      "step": 362160
    },
    {
      "epoch": 582.28,
      "learning_rate": 0.04179603891141479,
      "loss": 2.6247,
      "step": 362180
    },
    {
      "epoch": 582.32,
      "learning_rate": 0.04179282348054662,
      "loss": 2.6078,
      "step": 362200
    },
    {
      "epoch": 582.35,
      "learning_rate": 0.041789608049678455,
      "loss": 2.6386,
      "step": 362220
    },
    {
      "epoch": 582.38,
      "learning_rate": 0.0417863926188103,
      "loss": 2.6246,
      "step": 362240
    },
    {
      "epoch": 582.41,
      "learning_rate": 0.041783177187942125,
      "loss": 2.6406,
      "step": 362260
    },
    {
      "epoch": 582.44,
      "learning_rate": 0.041779961757073956,
      "loss": 2.6124,
      "step": 362280
    },
    {
      "epoch": 582.48,
      "learning_rate": 0.04177674632620579,
      "loss": 2.5989,
      "step": 362300
    },
    {
      "epoch": 582.51,
      "learning_rate": 0.04177353089533762,
      "loss": 2.6133,
      "step": 362320
    },
    {
      "epoch": 582.54,
      "learning_rate": 0.041770315464469465,
      "loss": 2.6326,
      "step": 362340
    },
    {
      "epoch": 582.57,
      "learning_rate": 0.04176710003360129,
      "loss": 2.6119,
      "step": 362360
    },
    {
      "epoch": 582.6,
      "learning_rate": 0.04176388460273312,
      "loss": 2.645,
      "step": 362380
    },
    {
      "epoch": 582.64,
      "learning_rate": 0.04176066917186495,
      "loss": 2.6411,
      "step": 362400
    },
    {
      "epoch": 582.67,
      "learning_rate": 0.041757453740996785,
      "loss": 2.6113,
      "step": 362420
    },
    {
      "epoch": 582.7,
      "learning_rate": 0.041754238310128616,
      "loss": 2.6092,
      "step": 362440
    },
    {
      "epoch": 582.73,
      "learning_rate": 0.04175102287926046,
      "loss": 2.6132,
      "step": 362460
    },
    {
      "epoch": 582.77,
      "learning_rate": 0.041747807448392286,
      "loss": 2.6399,
      "step": 362480
    },
    {
      "epoch": 582.8,
      "learning_rate": 0.04174459201752412,
      "loss": 2.6164,
      "step": 362500
    },
    {
      "epoch": 582.83,
      "learning_rate": 0.04174137658665595,
      "loss": 2.6218,
      "step": 362520
    },
    {
      "epoch": 582.86,
      "learning_rate": 0.04173816115578778,
      "loss": 2.6153,
      "step": 362540
    },
    {
      "epoch": 582.89,
      "learning_rate": 0.04173494572491961,
      "loss": 2.6302,
      "step": 362560
    },
    {
      "epoch": 582.93,
      "learning_rate": 0.04173173029405145,
      "loss": 2.6312,
      "step": 362580
    },
    {
      "epoch": 582.96,
      "learning_rate": 0.04172851486318328,
      "loss": 2.6232,
      "step": 362600
    },
    {
      "epoch": 582.99,
      "learning_rate": 0.041725299432315115,
      "loss": 2.6327,
      "step": 362620
    },
    {
      "epoch": 583.0,
      "eval_accuracy": {
        "accuracy": 0.4240845836896525
      },
      "eval_loss": 2.7308404445648193,
      "eval_runtime": 2.9073,
      "eval_samples_per_second": 4424.353,
      "eval_steps_per_second": 69.136,
      "step": 362626
    },
    {
      "epoch": 583.02,
      "learning_rate": 0.041722084001446946,
      "loss": 2.6103,
      "step": 362640
    },
    {
      "epoch": 583.05,
      "learning_rate": 0.04171886857057878,
      "loss": 2.6122,
      "step": 362660
    },
    {
      "epoch": 583.09,
      "learning_rate": 0.041715653139710616,
      "loss": 2.6304,
      "step": 362680
    },
    {
      "epoch": 583.12,
      "learning_rate": 0.04171243770884245,
      "loss": 2.6104,
      "step": 362700
    },
    {
      "epoch": 583.15,
      "learning_rate": 0.04170922227797428,
      "loss": 2.6238,
      "step": 362720
    },
    {
      "epoch": 583.18,
      "learning_rate": 0.04170600684710611,
      "loss": 2.6141,
      "step": 362740
    },
    {
      "epoch": 583.22,
      "learning_rate": 0.04170279141623794,
      "loss": 2.5947,
      "step": 362760
    },
    {
      "epoch": 583.25,
      "learning_rate": 0.041699575985369775,
      "loss": 2.615,
      "step": 362780
    },
    {
      "epoch": 583.28,
      "learning_rate": 0.04169636055450161,
      "loss": 2.6377,
      "step": 362800
    },
    {
      "epoch": 583.31,
      "learning_rate": 0.041693145123633445,
      "loss": 2.6357,
      "step": 362820
    },
    {
      "epoch": 583.34,
      "learning_rate": 0.041689929692765276,
      "loss": 2.6501,
      "step": 362840
    },
    {
      "epoch": 583.38,
      "learning_rate": 0.04168671426189711,
      "loss": 2.6214,
      "step": 362860
    },
    {
      "epoch": 583.41,
      "learning_rate": 0.04168349883102894,
      "loss": 2.6308,
      "step": 362880
    },
    {
      "epoch": 583.44,
      "learning_rate": 0.04168028340016078,
      "loss": 2.5937,
      "step": 362900
    },
    {
      "epoch": 583.47,
      "learning_rate": 0.04167706796929261,
      "loss": 2.6296,
      "step": 362920
    },
    {
      "epoch": 583.5,
      "learning_rate": 0.04167385253842444,
      "loss": 2.6125,
      "step": 362940
    },
    {
      "epoch": 583.54,
      "learning_rate": 0.04167063710755627,
      "loss": 2.6254,
      "step": 362960
    },
    {
      "epoch": 583.57,
      "learning_rate": 0.041667421676688104,
      "loss": 2.6147,
      "step": 362980
    },
    {
      "epoch": 583.6,
      "learning_rate": 0.041664206245819936,
      "loss": 2.6021,
      "step": 363000
    },
    {
      "epoch": 583.63,
      "learning_rate": 0.041660990814951775,
      "loss": 2.6378,
      "step": 363020
    },
    {
      "epoch": 583.67,
      "learning_rate": 0.041657775384083606,
      "loss": 2.6181,
      "step": 363040
    },
    {
      "epoch": 583.7,
      "learning_rate": 0.04165455995321544,
      "loss": 2.6198,
      "step": 363060
    },
    {
      "epoch": 583.73,
      "learning_rate": 0.04165134452234727,
      "loss": 2.6187,
      "step": 363080
    },
    {
      "epoch": 583.76,
      "learning_rate": 0.0416481290914791,
      "loss": 2.6309,
      "step": 363100
    },
    {
      "epoch": 583.79,
      "learning_rate": 0.04164491366061093,
      "loss": 2.6435,
      "step": 363120
    },
    {
      "epoch": 583.83,
      "learning_rate": 0.04164169822974277,
      "loss": 2.6023,
      "step": 363140
    },
    {
      "epoch": 583.86,
      "learning_rate": 0.0416384827988746,
      "loss": 2.6066,
      "step": 363160
    },
    {
      "epoch": 583.89,
      "learning_rate": 0.041635267368006434,
      "loss": 2.5883,
      "step": 363180
    },
    {
      "epoch": 583.92,
      "learning_rate": 0.041632051937138266,
      "loss": 2.608,
      "step": 363200
    },
    {
      "epoch": 583.95,
      "learning_rate": 0.0416288365062701,
      "loss": 2.6258,
      "step": 363220
    },
    {
      "epoch": 583.99,
      "learning_rate": 0.041625621075401936,
      "loss": 2.653,
      "step": 363240
    },
    {
      "epoch": 584.0,
      "eval_accuracy": {
        "accuracy": 0.41848713363911993
      },
      "eval_loss": 2.753159523010254,
      "eval_runtime": 2.9567,
      "eval_samples_per_second": 4350.45,
      "eval_steps_per_second": 67.981,
      "step": 363248
    },
    {
      "epoch": 584.02,
      "learning_rate": 0.04162240564453377,
      "loss": 2.6264,
      "step": 363260
    },
    {
      "epoch": 584.05,
      "learning_rate": 0.0416191902136656,
      "loss": 2.6215,
      "step": 363280
    },
    {
      "epoch": 584.08,
      "learning_rate": 0.04161597478279743,
      "loss": 2.613,
      "step": 363300
    },
    {
      "epoch": 584.12,
      "learning_rate": 0.04161275935192926,
      "loss": 2.6254,
      "step": 363320
    },
    {
      "epoch": 584.15,
      "learning_rate": 0.041609543921061094,
      "loss": 2.6167,
      "step": 363340
    },
    {
      "epoch": 584.18,
      "learning_rate": 0.04160632849019293,
      "loss": 2.6088,
      "step": 363360
    },
    {
      "epoch": 584.21,
      "learning_rate": 0.041603113059324764,
      "loss": 2.608,
      "step": 363380
    },
    {
      "epoch": 584.24,
      "learning_rate": 0.041599897628456596,
      "loss": 2.6098,
      "step": 363400
    },
    {
      "epoch": 584.28,
      "learning_rate": 0.04159668219758843,
      "loss": 2.6406,
      "step": 363420
    },
    {
      "epoch": 584.31,
      "learning_rate": 0.04159346676672026,
      "loss": 2.6224,
      "step": 363440
    },
    {
      "epoch": 584.34,
      "learning_rate": 0.04159025133585209,
      "loss": 2.6216,
      "step": 363460
    },
    {
      "epoch": 584.37,
      "learning_rate": 0.04158703590498393,
      "loss": 2.6211,
      "step": 363480
    },
    {
      "epoch": 584.41,
      "learning_rate": 0.04158382047411576,
      "loss": 2.6232,
      "step": 363500
    },
    {
      "epoch": 584.44,
      "learning_rate": 0.04158060504324759,
      "loss": 2.6258,
      "step": 363520
    },
    {
      "epoch": 584.47,
      "learning_rate": 0.041577389612379424,
      "loss": 2.6337,
      "step": 363540
    },
    {
      "epoch": 584.5,
      "learning_rate": 0.041574174181511256,
      "loss": 2.6229,
      "step": 363560
    },
    {
      "epoch": 584.53,
      "learning_rate": 0.041570958750643094,
      "loss": 2.6216,
      "step": 363580
    },
    {
      "epoch": 584.57,
      "learning_rate": 0.041567743319774926,
      "loss": 2.6214,
      "step": 363600
    },
    {
      "epoch": 584.6,
      "learning_rate": 0.04156452788890676,
      "loss": 2.6182,
      "step": 363620
    },
    {
      "epoch": 584.63,
      "learning_rate": 0.04156131245803859,
      "loss": 2.625,
      "step": 363640
    },
    {
      "epoch": 584.66,
      "learning_rate": 0.04155809702717042,
      "loss": 2.5965,
      "step": 363660
    },
    {
      "epoch": 584.69,
      "learning_rate": 0.04155488159630225,
      "loss": 2.6064,
      "step": 363680
    },
    {
      "epoch": 584.73,
      "learning_rate": 0.04155166616543409,
      "loss": 2.6052,
      "step": 363700
    },
    {
      "epoch": 584.76,
      "learning_rate": 0.04154845073456592,
      "loss": 2.6137,
      "step": 363720
    },
    {
      "epoch": 584.79,
      "learning_rate": 0.041545235303697754,
      "loss": 2.6099,
      "step": 363740
    },
    {
      "epoch": 584.82,
      "learning_rate": 0.041542019872829586,
      "loss": 2.6262,
      "step": 363760
    },
    {
      "epoch": 584.86,
      "learning_rate": 0.04153880444196142,
      "loss": 2.6458,
      "step": 363780
    },
    {
      "epoch": 584.89,
      "learning_rate": 0.04153558901109325,
      "loss": 2.5943,
      "step": 363800
    },
    {
      "epoch": 584.92,
      "learning_rate": 0.04153237358022509,
      "loss": 2.6163,
      "step": 363820
    },
    {
      "epoch": 584.95,
      "learning_rate": 0.04152915814935692,
      "loss": 2.6205,
      "step": 363840
    },
    {
      "epoch": 584.98,
      "learning_rate": 0.04152594271848875,
      "loss": 2.6235,
      "step": 363860
    },
    {
      "epoch": 585.0,
      "eval_accuracy": {
        "accuracy": 0.41537743916660186
      },
      "eval_loss": 2.7550442218780518,
      "eval_runtime": 3.2847,
      "eval_samples_per_second": 3916.02,
      "eval_steps_per_second": 61.193,
      "step": 363870
    },
    {
      "epoch": 585.02,
      "learning_rate": 0.04152272728762058,
      "loss": 2.6315,
      "step": 363880
    },
    {
      "epoch": 585.05,
      "learning_rate": 0.041519511856752414,
      "loss": 2.6159,
      "step": 363900
    },
    {
      "epoch": 585.08,
      "learning_rate": 0.04151629642588425,
      "loss": 2.6173,
      "step": 363920
    },
    {
      "epoch": 585.11,
      "learning_rate": 0.041513080995016084,
      "loss": 2.601,
      "step": 363940
    },
    {
      "epoch": 585.14,
      "learning_rate": 0.041509865564147916,
      "loss": 2.6228,
      "step": 363960
    },
    {
      "epoch": 585.18,
      "learning_rate": 0.04150665013327975,
      "loss": 2.6061,
      "step": 363980
    },
    {
      "epoch": 585.21,
      "learning_rate": 0.04150343470241158,
      "loss": 2.6106,
      "step": 364000
    },
    {
      "epoch": 585.24,
      "learning_rate": 0.04150021927154341,
      "loss": 2.6202,
      "step": 364020
    },
    {
      "epoch": 585.27,
      "learning_rate": 0.04149700384067525,
      "loss": 2.6124,
      "step": 364040
    },
    {
      "epoch": 585.31,
      "learning_rate": 0.04149378840980708,
      "loss": 2.6104,
      "step": 364060
    },
    {
      "epoch": 585.34,
      "learning_rate": 0.04149057297893891,
      "loss": 2.6184,
      "step": 364080
    },
    {
      "epoch": 585.37,
      "learning_rate": 0.041487357548070744,
      "loss": 2.6078,
      "step": 364100
    },
    {
      "epoch": 585.4,
      "learning_rate": 0.041484142117202576,
      "loss": 2.5992,
      "step": 364120
    },
    {
      "epoch": 585.43,
      "learning_rate": 0.0414809266863344,
      "loss": 2.6201,
      "step": 364140
    },
    {
      "epoch": 585.47,
      "learning_rate": 0.041477711255466246,
      "loss": 2.6209,
      "step": 364160
    },
    {
      "epoch": 585.5,
      "learning_rate": 0.04147449582459808,
      "loss": 2.6197,
      "step": 364180
    },
    {
      "epoch": 585.53,
      "learning_rate": 0.04147128039372991,
      "loss": 2.6499,
      "step": 364200
    },
    {
      "epoch": 585.56,
      "learning_rate": 0.04146806496286174,
      "loss": 2.6201,
      "step": 364220
    },
    {
      "epoch": 585.59,
      "learning_rate": 0.04146484953199357,
      "loss": 2.6222,
      "step": 364240
    },
    {
      "epoch": 585.63,
      "learning_rate": 0.04146179487266881,
      "loss": 2.634,
      "step": 364260
    },
    {
      "epoch": 585.66,
      "learning_rate": 0.04145857944180064,
      "loss": 2.6188,
      "step": 364280
    },
    {
      "epoch": 585.69,
      "learning_rate": 0.041455364010932486,
      "loss": 2.6136,
      "step": 364300
    },
    {
      "epoch": 585.72,
      "learning_rate": 0.04145214858006432,
      "loss": 2.6256,
      "step": 364320
    },
    {
      "epoch": 585.76,
      "learning_rate": 0.04144893314919615,
      "loss": 2.644,
      "step": 364340
    },
    {
      "epoch": 585.79,
      "learning_rate": 0.04144571771832797,
      "loss": 2.6292,
      "step": 364360
    },
    {
      "epoch": 585.82,
      "learning_rate": 0.041442502287459805,
      "loss": 2.6455,
      "step": 364380
    },
    {
      "epoch": 585.85,
      "learning_rate": 0.04143928685659165,
      "loss": 2.6168,
      "step": 364400
    },
    {
      "epoch": 585.88,
      "learning_rate": 0.04143607142572348,
      "loss": 2.6138,
      "step": 364420
    },
    {
      "epoch": 585.92,
      "learning_rate": 0.041432855994855314,
      "loss": 2.636,
      "step": 364440
    },
    {
      "epoch": 585.95,
      "learning_rate": 0.04142964056398714,
      "loss": 2.6128,
      "step": 364460
    },
    {
      "epoch": 585.98,
      "learning_rate": 0.04142642513311897,
      "loss": 2.6218,
      "step": 364480
    },
    {
      "epoch": 586.0,
      "eval_accuracy": {
        "accuracy": 0.42268522117701934
      },
      "eval_loss": 2.7274091243743896,
      "eval_runtime": 2.9019,
      "eval_samples_per_second": 4432.57,
      "eval_steps_per_second": 69.264,
      "step": 364492
    },
    {
      "epoch": 586.01,
      "learning_rate": 0.0414232097022508,
      "loss": 2.6197,
      "step": 364500
    },
    {
      "epoch": 586.05,
      "learning_rate": 0.04141999427138265,
      "loss": 2.6051,
      "step": 364520
    },
    {
      "epoch": 586.08,
      "learning_rate": 0.04141677884051448,
      "loss": 2.6358,
      "step": 364540
    },
    {
      "epoch": 586.11,
      "learning_rate": 0.0414135634096463,
      "loss": 2.6075,
      "step": 364560
    },
    {
      "epoch": 586.14,
      "learning_rate": 0.041410347978778135,
      "loss": 2.6128,
      "step": 364580
    },
    {
      "epoch": 586.17,
      "learning_rate": 0.04140713254790997,
      "loss": 2.6183,
      "step": 364600
    },
    {
      "epoch": 586.21,
      "learning_rate": 0.0414039171170418,
      "loss": 2.6181,
      "step": 364620
    },
    {
      "epoch": 586.24,
      "learning_rate": 0.041400701686173644,
      "loss": 2.6308,
      "step": 364640
    },
    {
      "epoch": 586.27,
      "learning_rate": 0.041397486255305475,
      "loss": 2.6453,
      "step": 364660
    },
    {
      "epoch": 586.3,
      "learning_rate": 0.0413942708244373,
      "loss": 2.6,
      "step": 364680
    },
    {
      "epoch": 586.33,
      "learning_rate": 0.04139105539356913,
      "loss": 2.621,
      "step": 364700
    },
    {
      "epoch": 586.37,
      "learning_rate": 0.04138783996270096,
      "loss": 2.5943,
      "step": 364720
    },
    {
      "epoch": 586.4,
      "learning_rate": 0.04138462453183281,
      "loss": 2.6105,
      "step": 364740
    },
    {
      "epoch": 586.43,
      "learning_rate": 0.04138140910096464,
      "loss": 2.6162,
      "step": 364760
    },
    {
      "epoch": 586.46,
      "learning_rate": 0.041378193670096465,
      "loss": 2.6177,
      "step": 364780
    },
    {
      "epoch": 586.5,
      "learning_rate": 0.0413749782392283,
      "loss": 2.6239,
      "step": 364800
    },
    {
      "epoch": 586.53,
      "learning_rate": 0.04137176280836013,
      "loss": 2.6285,
      "step": 364820
    },
    {
      "epoch": 586.56,
      "learning_rate": 0.04136854737749196,
      "loss": 2.6115,
      "step": 364840
    },
    {
      "epoch": 586.59,
      "learning_rate": 0.041365331946623805,
      "loss": 2.6004,
      "step": 364860
    },
    {
      "epoch": 586.62,
      "learning_rate": 0.04136211651575563,
      "loss": 2.5935,
      "step": 364880
    },
    {
      "epoch": 586.66,
      "learning_rate": 0.04135890108488746,
      "loss": 2.618,
      "step": 364900
    },
    {
      "epoch": 586.69,
      "learning_rate": 0.04135568565401929,
      "loss": 2.6098,
      "step": 364920
    },
    {
      "epoch": 586.72,
      "learning_rate": 0.041352470223151125,
      "loss": 2.6058,
      "step": 364940
    },
    {
      "epoch": 586.75,
      "learning_rate": 0.041349254792282956,
      "loss": 2.6267,
      "step": 364960
    },
    {
      "epoch": 586.78,
      "learning_rate": 0.0413460393614148,
      "loss": 2.6365,
      "step": 364980
    },
    {
      "epoch": 586.82,
      "learning_rate": 0.04134282393054663,
      "loss": 2.6276,
      "step": 365000
    },
    {
      "epoch": 586.85,
      "learning_rate": 0.04133960849967846,
      "loss": 2.6259,
      "step": 365020
    },
    {
      "epoch": 586.88,
      "learning_rate": 0.04133639306881029,
      "loss": 2.6042,
      "step": 365040
    },
    {
      "epoch": 586.91,
      "learning_rate": 0.04133317763794212,
      "loss": 2.6234,
      "step": 365060
    },
    {
      "epoch": 586.95,
      "learning_rate": 0.04132996220707397,
      "loss": 2.6265,
      "step": 365080
    },
    {
      "epoch": 586.98,
      "learning_rate": 0.04132674677620579,
      "loss": 2.611,
      "step": 365100
    },
    {
      "epoch": 587.0,
      "eval_accuracy": {
        "accuracy": 0.41491098499572415
      },
      "eval_loss": 2.7464542388916016,
      "eval_runtime": 3.2523,
      "eval_samples_per_second": 3955.05,
      "eval_steps_per_second": 61.802,
      "step": 365114
    },
    {
      "epoch": 587.01,
      "learning_rate": 0.04132353134533762,
      "loss": 2.6065,
      "step": 365120
    },
    {
      "epoch": 587.04,
      "learning_rate": 0.041320315914469455,
      "loss": 2.6259,
      "step": 365140
    },
    {
      "epoch": 587.07,
      "learning_rate": 0.041317100483601286,
      "loss": 2.6128,
      "step": 365160
    },
    {
      "epoch": 587.11,
      "learning_rate": 0.04131388505273312,
      "loss": 2.607,
      "step": 365180
    },
    {
      "epoch": 587.14,
      "learning_rate": 0.04131066962186496,
      "loss": 2.6245,
      "step": 365200
    },
    {
      "epoch": 587.17,
      "learning_rate": 0.04130745419099679,
      "loss": 2.6239,
      "step": 365220
    },
    {
      "epoch": 587.2,
      "learning_rate": 0.04130423876012862,
      "loss": 2.5921,
      "step": 365240
    },
    {
      "epoch": 587.23,
      "learning_rate": 0.04130102332926045,
      "loss": 2.6048,
      "step": 365260
    },
    {
      "epoch": 587.27,
      "learning_rate": 0.04129780789839228,
      "loss": 2.6057,
      "step": 365280
    },
    {
      "epoch": 587.3,
      "learning_rate": 0.041294592467524115,
      "loss": 2.6166,
      "step": 365300
    },
    {
      "epoch": 587.33,
      "learning_rate": 0.04129137703665595,
      "loss": 2.6329,
      "step": 365320
    },
    {
      "epoch": 587.36,
      "learning_rate": 0.041288161605787785,
      "loss": 2.6251,
      "step": 365340
    },
    {
      "epoch": 587.4,
      "learning_rate": 0.041284946174919616,
      "loss": 2.6343,
      "step": 365360
    },
    {
      "epoch": 587.43,
      "learning_rate": 0.04128173074405145,
      "loss": 2.6182,
      "step": 365380
    },
    {
      "epoch": 587.46,
      "learning_rate": 0.04127851531318328,
      "loss": 2.6291,
      "step": 365400
    },
    {
      "epoch": 587.49,
      "learning_rate": 0.04127529988231512,
      "loss": 2.6116,
      "step": 365420
    },
    {
      "epoch": 587.52,
      "learning_rate": 0.04127208445144695,
      "loss": 2.6161,
      "step": 365440
    },
    {
      "epoch": 587.56,
      "learning_rate": 0.04126886902057878,
      "loss": 2.623,
      "step": 365460
    },
    {
      "epoch": 587.59,
      "learning_rate": 0.04126565358971061,
      "loss": 2.634,
      "step": 365480
    },
    {
      "epoch": 587.62,
      "learning_rate": 0.041262438158842445,
      "loss": 2.6366,
      "step": 365500
    },
    {
      "epoch": 587.65,
      "learning_rate": 0.041259222727974276,
      "loss": 2.6152,
      "step": 365520
    },
    {
      "epoch": 587.68,
      "learning_rate": 0.041256007297106115,
      "loss": 2.6244,
      "step": 365540
    },
    {
      "epoch": 587.72,
      "learning_rate": 0.041252791866237946,
      "loss": 2.6102,
      "step": 365560
    },
    {
      "epoch": 587.75,
      "learning_rate": 0.04124957643536978,
      "loss": 2.6062,
      "step": 365580
    },
    {
      "epoch": 587.78,
      "learning_rate": 0.04124636100450161,
      "loss": 2.6121,
      "step": 365600
    },
    {
      "epoch": 587.81,
      "learning_rate": 0.04124314557363344,
      "loss": 2.5819,
      "step": 365620
    },
    {
      "epoch": 587.85,
      "learning_rate": 0.04123993014276528,
      "loss": 2.6222,
      "step": 365640
    },
    {
      "epoch": 587.88,
      "learning_rate": 0.04123671471189711,
      "loss": 2.6353,
      "step": 365660
    },
    {
      "epoch": 587.91,
      "learning_rate": 0.04123349928102894,
      "loss": 2.6019,
      "step": 365680
    },
    {
      "epoch": 587.94,
      "learning_rate": 0.041230283850160775,
      "loss": 2.6208,
      "step": 365700
    },
    {
      "epoch": 587.97,
      "learning_rate": 0.041227068419292606,
      "loss": 2.5992,
      "step": 365720
    },
    {
      "epoch": 588.0,
      "eval_accuracy": {
        "accuracy": 0.4247065225841561
      },
      "eval_loss": 2.7374062538146973,
      "eval_runtime": 2.9009,
      "eval_samples_per_second": 4434.1,
      "eval_steps_per_second": 69.288,
      "step": 365736
    },
    {
      "epoch": 588.01,
      "learning_rate": 0.04122385298842444,
      "loss": 2.6194,
      "step": 365740
    },
    {
      "epoch": 588.04,
      "learning_rate": 0.041220637557556276,
      "loss": 2.6146,
      "step": 365760
    },
    {
      "epoch": 588.07,
      "learning_rate": 0.04121742212668811,
      "loss": 2.6027,
      "step": 365780
    },
    {
      "epoch": 588.1,
      "learning_rate": 0.04121420669581994,
      "loss": 2.6081,
      "step": 365800
    },
    {
      "epoch": 588.14,
      "learning_rate": 0.04121099126495177,
      "loss": 2.6043,
      "step": 365820
    },
    {
      "epoch": 588.17,
      "learning_rate": 0.0412077758340836,
      "loss": 2.6015,
      "step": 365840
    },
    {
      "epoch": 588.2,
      "learning_rate": 0.041204560403215434,
      "loss": 2.6211,
      "step": 365860
    },
    {
      "epoch": 588.23,
      "learning_rate": 0.04120134497234727,
      "loss": 2.618,
      "step": 365880
    },
    {
      "epoch": 588.26,
      "learning_rate": 0.041198129541479105,
      "loss": 2.606,
      "step": 365900
    },
    {
      "epoch": 588.3,
      "learning_rate": 0.041194914110610936,
      "loss": 2.6446,
      "step": 365920
    },
    {
      "epoch": 588.33,
      "learning_rate": 0.04119169867974277,
      "loss": 2.6217,
      "step": 365940
    },
    {
      "epoch": 588.36,
      "learning_rate": 0.0411884832488746,
      "loss": 2.6223,
      "step": 365960
    },
    {
      "epoch": 588.39,
      "learning_rate": 0.04118526781800644,
      "loss": 2.6384,
      "step": 365980
    },
    {
      "epoch": 588.42,
      "learning_rate": 0.04118205238713827,
      "loss": 2.5887,
      "step": 366000
    },
    {
      "epoch": 588.46,
      "learning_rate": 0.0411788369562701,
      "loss": 2.6102,
      "step": 366020
    },
    {
      "epoch": 588.49,
      "learning_rate": 0.04117562152540193,
      "loss": 2.6337,
      "step": 366040
    },
    {
      "epoch": 588.52,
      "learning_rate": 0.041172406094533764,
      "loss": 2.6219,
      "step": 366060
    },
    {
      "epoch": 588.55,
      "learning_rate": 0.041169190663665596,
      "loss": 2.6177,
      "step": 366080
    },
    {
      "epoch": 588.59,
      "learning_rate": 0.041165975232797435,
      "loss": 2.6259,
      "step": 366100
    },
    {
      "epoch": 588.62,
      "learning_rate": 0.041162759801929266,
      "loss": 2.6261,
      "step": 366120
    },
    {
      "epoch": 588.65,
      "learning_rate": 0.0411595443710611,
      "loss": 2.626,
      "step": 366140
    },
    {
      "epoch": 588.68,
      "learning_rate": 0.04115632894019293,
      "loss": 2.6295,
      "step": 366160
    },
    {
      "epoch": 588.71,
      "learning_rate": 0.04115311350932476,
      "loss": 2.6182,
      "step": 366180
    },
    {
      "epoch": 588.75,
      "learning_rate": 0.04114989807845659,
      "loss": 2.6178,
      "step": 366200
    },
    {
      "epoch": 588.78,
      "learning_rate": 0.04114668264758843,
      "loss": 2.6544,
      "step": 366220
    },
    {
      "epoch": 588.81,
      "learning_rate": 0.04114346721672026,
      "loss": 2.6224,
      "step": 366240
    },
    {
      "epoch": 588.84,
      "learning_rate": 0.041140251785852094,
      "loss": 2.619,
      "step": 366260
    },
    {
      "epoch": 588.87,
      "learning_rate": 0.041137036354983926,
      "loss": 2.6165,
      "step": 366280
    },
    {
      "epoch": 588.91,
      "learning_rate": 0.04113382092411576,
      "loss": 2.6405,
      "step": 366300
    },
    {
      "epoch": 588.94,
      "learning_rate": 0.041130605493247596,
      "loss": 2.6088,
      "step": 366320
    },
    {
      "epoch": 588.97,
      "learning_rate": 0.04112739006237943,
      "loss": 2.6581,
      "step": 366340
    },
    {
      "epoch": 589.0,
      "eval_accuracy": {
        "accuracy": 0.424862007307782
      },
      "eval_loss": 2.7260453701019287,
      "eval_runtime": 3.0083,
      "eval_samples_per_second": 4275.888,
      "eval_steps_per_second": 66.816,
      "step": 366358
    },
    {
      "epoch": 589.0,
      "learning_rate": 0.04112433540305467,
      "loss": 2.625,
      "step": 366360
    },
    {
      "epoch": 589.04,
      "learning_rate": 0.0411211199721865,
      "loss": 2.608,
      "step": 366380
    },
    {
      "epoch": 589.07,
      "learning_rate": 0.041117904541318334,
      "loss": 2.6183,
      "step": 366400
    },
    {
      "epoch": 589.1,
      "learning_rate": 0.041114689110450166,
      "loss": 2.6106,
      "step": 366420
    },
    {
      "epoch": 589.13,
      "learning_rate": 0.04111147367958199,
      "loss": 2.5979,
      "step": 366440
    },
    {
      "epoch": 589.16,
      "learning_rate": 0.041108258248713836,
      "loss": 2.5916,
      "step": 366460
    },
    {
      "epoch": 589.2,
      "learning_rate": 0.04110504281784567,
      "loss": 2.6091,
      "step": 366480
    },
    {
      "epoch": 589.23,
      "learning_rate": 0.0411018273869775,
      "loss": 2.596,
      "step": 366500
    },
    {
      "epoch": 589.26,
      "learning_rate": 0.04109861195610933,
      "loss": 2.6025,
      "step": 366520
    },
    {
      "epoch": 589.29,
      "learning_rate": 0.04109539652524116,
      "loss": 2.6339,
      "step": 366540
    },
    {
      "epoch": 589.32,
      "learning_rate": 0.04109218109437299,
      "loss": 2.6224,
      "step": 366560
    },
    {
      "epoch": 589.36,
      "learning_rate": 0.04108896566350483,
      "loss": 2.6171,
      "step": 366580
    },
    {
      "epoch": 589.39,
      "learning_rate": 0.041085750232636664,
      "loss": 2.5953,
      "step": 366600
    },
    {
      "epoch": 589.42,
      "learning_rate": 0.041082534801768496,
      "loss": 2.6139,
      "step": 366620
    },
    {
      "epoch": 589.45,
      "learning_rate": 0.04107931937090033,
      "loss": 2.6236,
      "step": 366640
    },
    {
      "epoch": 589.49,
      "learning_rate": 0.04107610394003215,
      "loss": 2.6246,
      "step": 366660
    },
    {
      "epoch": 589.52,
      "learning_rate": 0.041072888509163984,
      "loss": 2.6184,
      "step": 366680
    },
    {
      "epoch": 589.55,
      "learning_rate": 0.04106967307829583,
      "loss": 2.598,
      "step": 366700
    },
    {
      "epoch": 589.58,
      "learning_rate": 0.04106645764742766,
      "loss": 2.6291,
      "step": 366720
    },
    {
      "epoch": 589.61,
      "learning_rate": 0.04106324221655949,
      "loss": 2.631,
      "step": 366740
    },
    {
      "epoch": 589.65,
      "learning_rate": 0.04106002678569132,
      "loss": 2.6125,
      "step": 366760
    },
    {
      "epoch": 589.68,
      "learning_rate": 0.04105681135482315,
      "loss": 2.6004,
      "step": 366780
    },
    {
      "epoch": 589.71,
      "learning_rate": 0.041053595923954994,
      "loss": 2.6139,
      "step": 366800
    },
    {
      "epoch": 589.74,
      "learning_rate": 0.041050380493086826,
      "loss": 2.6362,
      "step": 366820
    },
    {
      "epoch": 589.77,
      "learning_rate": 0.04104716506221866,
      "loss": 2.6408,
      "step": 366840
    },
    {
      "epoch": 589.81,
      "learning_rate": 0.04104394963135049,
      "loss": 2.6279,
      "step": 366860
    },
    {
      "epoch": 589.84,
      "learning_rate": 0.041040734200482314,
      "loss": 2.6322,
      "step": 366880
    },
    {
      "epoch": 589.87,
      "learning_rate": 0.041037518769614145,
      "loss": 2.6317,
      "step": 366900
    },
    {
      "epoch": 589.9,
      "learning_rate": 0.04103430333874599,
      "loss": 2.6147,
      "step": 366920
    },
    {
      "epoch": 589.94,
      "learning_rate": 0.04103108790787782,
      "loss": 2.6024,
      "step": 366940
    },
    {
      "epoch": 589.97,
      "learning_rate": 0.041027872477009654,
      "loss": 2.6011,
      "step": 366960
    },
    {
      "epoch": 590.0,
      "learning_rate": 0.04102465704614148,
      "loss": 2.6173,
      "step": 366980
    },
    {
      "epoch": 590.0,
      "eval_accuracy": {
        "accuracy": 0.4203529503226308
      },
      "eval_loss": 2.722212314605713,
      "eval_runtime": 2.9921,
      "eval_samples_per_second": 4299.024,
      "eval_steps_per_second": 67.177,
      "step": 366980
    },
    {
      "epoch": 590.03,
      "learning_rate": 0.04102144161527331,
      "loss": 2.5919,
      "step": 367000
    },
    {
      "epoch": 590.06,
      "learning_rate": 0.04101822618440514,
      "loss": 2.601,
      "step": 367020
    },
    {
      "epoch": 590.1,
      "learning_rate": 0.04101501075353699,
      "loss": 2.6042,
      "step": 367040
    },
    {
      "epoch": 590.13,
      "learning_rate": 0.04101179532266882,
      "loss": 2.6158,
      "step": 367060
    },
    {
      "epoch": 590.16,
      "learning_rate": 0.041008579891800644,
      "loss": 2.6212,
      "step": 367080
    },
    {
      "epoch": 590.19,
      "learning_rate": 0.041005364460932475,
      "loss": 2.6073,
      "step": 367100
    },
    {
      "epoch": 590.23,
      "learning_rate": 0.04100214903006431,
      "loss": 2.6009,
      "step": 367120
    },
    {
      "epoch": 590.26,
      "learning_rate": 0.04099893359919615,
      "loss": 2.6205,
      "step": 367140
    },
    {
      "epoch": 590.29,
      "learning_rate": 0.040995718168327984,
      "loss": 2.6322,
      "step": 367160
    },
    {
      "epoch": 590.32,
      "learning_rate": 0.040992502737459816,
      "loss": 2.6106,
      "step": 367180
    },
    {
      "epoch": 590.35,
      "learning_rate": 0.04098928730659164,
      "loss": 2.6203,
      "step": 367200
    },
    {
      "epoch": 590.39,
      "learning_rate": 0.04098607187572347,
      "loss": 2.602,
      "step": 367220
    },
    {
      "epoch": 590.42,
      "learning_rate": 0.0409828564448553,
      "loss": 2.6241,
      "step": 367240
    },
    {
      "epoch": 590.45,
      "learning_rate": 0.04097964101398715,
      "loss": 2.6331,
      "step": 367260
    },
    {
      "epoch": 590.48,
      "learning_rate": 0.04097642558311898,
      "loss": 2.6161,
      "step": 367280
    },
    {
      "epoch": 590.51,
      "learning_rate": 0.040973210152250805,
      "loss": 2.6378,
      "step": 367300
    },
    {
      "epoch": 590.55,
      "learning_rate": 0.04096999472138264,
      "loss": 2.6207,
      "step": 367320
    },
    {
      "epoch": 590.58,
      "learning_rate": 0.04096677929051447,
      "loss": 2.5979,
      "step": 367340
    },
    {
      "epoch": 590.61,
      "learning_rate": 0.0409635638596463,
      "loss": 2.619,
      "step": 367360
    },
    {
      "epoch": 590.64,
      "learning_rate": 0.040960348428778146,
      "loss": 2.6144,
      "step": 367380
    },
    {
      "epoch": 590.68,
      "learning_rate": 0.04095713299790997,
      "loss": 2.6186,
      "step": 367400
    },
    {
      "epoch": 590.71,
      "learning_rate": 0.0409539175670418,
      "loss": 2.6145,
      "step": 367420
    },
    {
      "epoch": 590.74,
      "learning_rate": 0.04095070213617363,
      "loss": 2.6078,
      "step": 367440
    },
    {
      "epoch": 590.77,
      "learning_rate": 0.040947486705305465,
      "loss": 2.6293,
      "step": 367460
    },
    {
      "epoch": 590.8,
      "learning_rate": 0.04094427127443731,
      "loss": 2.6243,
      "step": 367480
    },
    {
      "epoch": 590.84,
      "learning_rate": 0.04094105584356914,
      "loss": 2.5972,
      "step": 367500
    },
    {
      "epoch": 590.87,
      "learning_rate": 0.04093784041270097,
      "loss": 2.5996,
      "step": 367520
    },
    {
      "epoch": 590.9,
      "learning_rate": 0.0409346249818328,
      "loss": 2.6017,
      "step": 367540
    },
    {
      "epoch": 590.93,
      "learning_rate": 0.04093140955096463,
      "loss": 2.6111,
      "step": 367560
    },
    {
      "epoch": 590.96,
      "learning_rate": 0.04092819412009646,
      "loss": 2.6089,
      "step": 367580
    },
    {
      "epoch": 591.0,
      "learning_rate": 0.04092497868922831,
      "loss": 2.5926,
      "step": 367600
    },
    {
      "epoch": 591.0,
      "eval_accuracy": {
        "accuracy": 0.42447329549871726
      },
      "eval_loss": 2.7202188968658447,
      "eval_runtime": 3.4385,
      "eval_samples_per_second": 3740.923,
      "eval_steps_per_second": 58.456,
      "step": 367602
    },
    {
      "epoch": 591.03,
      "learning_rate": 0.04092176325836013,
      "loss": 2.617,
      "step": 367620
    },
    {
      "epoch": 591.06,
      "learning_rate": 0.04091854782749196,
      "loss": 2.6119,
      "step": 367640
    },
    {
      "epoch": 591.09,
      "learning_rate": 0.040915332396623795,
      "loss": 2.6044,
      "step": 367660
    },
    {
      "epoch": 591.13,
      "learning_rate": 0.04091211696575563,
      "loss": 2.6144,
      "step": 367680
    },
    {
      "epoch": 591.16,
      "learning_rate": 0.04090890153488746,
      "loss": 2.6172,
      "step": 367700
    },
    {
      "epoch": 591.19,
      "learning_rate": 0.040905686104019304,
      "loss": 2.5958,
      "step": 367720
    },
    {
      "epoch": 591.22,
      "learning_rate": 0.04090247067315113,
      "loss": 2.6053,
      "step": 367740
    },
    {
      "epoch": 591.25,
      "learning_rate": 0.04089925524228296,
      "loss": 2.5957,
      "step": 367760
    },
    {
      "epoch": 591.29,
      "learning_rate": 0.04089603981141479,
      "loss": 2.6059,
      "step": 367780
    },
    {
      "epoch": 591.32,
      "learning_rate": 0.04089282438054662,
      "loss": 2.6133,
      "step": 367800
    },
    {
      "epoch": 591.35,
      "learning_rate": 0.04088960894967847,
      "loss": 2.5985,
      "step": 367820
    },
    {
      "epoch": 591.38,
      "learning_rate": 0.04088639351881029,
      "loss": 2.5885,
      "step": 367840
    },
    {
      "epoch": 591.41,
      "learning_rate": 0.040883178087942125,
      "loss": 2.6143,
      "step": 367860
    },
    {
      "epoch": 591.45,
      "learning_rate": 0.04087996265707396,
      "loss": 2.6173,
      "step": 367880
    },
    {
      "epoch": 591.48,
      "learning_rate": 0.04087674722620579,
      "loss": 2.6199,
      "step": 367900
    },
    {
      "epoch": 591.51,
      "learning_rate": 0.04087353179533762,
      "loss": 2.6064,
      "step": 367920
    },
    {
      "epoch": 591.54,
      "learning_rate": 0.04087031636446946,
      "loss": 2.5965,
      "step": 367940
    },
    {
      "epoch": 591.58,
      "learning_rate": 0.04086710093360129,
      "loss": 2.6065,
      "step": 367960
    },
    {
      "epoch": 591.61,
      "learning_rate": 0.04086388550273312,
      "loss": 2.6112,
      "step": 367980
    },
    {
      "epoch": 591.64,
      "learning_rate": 0.04086067007186495,
      "loss": 2.6318,
      "step": 368000
    },
    {
      "epoch": 591.67,
      "learning_rate": 0.040857454640996785,
      "loss": 2.6199,
      "step": 368020
    },
    {
      "epoch": 591.7,
      "learning_rate": 0.04085423921012863,
      "loss": 2.6327,
      "step": 368040
    },
    {
      "epoch": 591.74,
      "learning_rate": 0.040851023779260455,
      "loss": 2.6246,
      "step": 368060
    },
    {
      "epoch": 591.77,
      "learning_rate": 0.04084780834839229,
      "loss": 2.6292,
      "step": 368080
    },
    {
      "epoch": 591.8,
      "learning_rate": 0.04084459291752412,
      "loss": 2.6319,
      "step": 368100
    },
    {
      "epoch": 591.83,
      "learning_rate": 0.04084137748665595,
      "loss": 2.601,
      "step": 368120
    },
    {
      "epoch": 591.86,
      "learning_rate": 0.04083816205578778,
      "loss": 2.6298,
      "step": 368140
    },
    {
      "epoch": 591.9,
      "learning_rate": 0.04083494662491962,
      "loss": 2.6454,
      "step": 368160
    },
    {
      "epoch": 591.93,
      "learning_rate": 0.04083173119405145,
      "loss": 2.6124,
      "step": 368180
    },
    {
      "epoch": 591.96,
      "learning_rate": 0.04082851576318328,
      "loss": 2.5913,
      "step": 368200
    },
    {
      "epoch": 591.99,
      "learning_rate": 0.040825300332315115,
      "loss": 2.6137,
      "step": 368220
    },
    {
      "epoch": 592.0,
      "eval_accuracy": {
        "accuracy": 0.41848713363911993
      },
      "eval_loss": 2.7514312267303467,
      "eval_runtime": 3.1882,
      "eval_samples_per_second": 4034.58,
      "eval_steps_per_second": 63.045,
      "step": 368224
    },
    {
      "epoch": 592.03,
      "learning_rate": 0.040822084901446946,
      "loss": 2.623,
      "step": 368240
    },
    {
      "epoch": 592.06,
      "learning_rate": 0.04081886947057878,
      "loss": 2.6078,
      "step": 368260
    },
    {
      "epoch": 592.09,
      "learning_rate": 0.04081565403971062,
      "loss": 2.6354,
      "step": 368280
    },
    {
      "epoch": 592.12,
      "learning_rate": 0.04081243860884245,
      "loss": 2.6204,
      "step": 368300
    },
    {
      "epoch": 592.15,
      "learning_rate": 0.04080922317797428,
      "loss": 2.6226,
      "step": 368320
    },
    {
      "epoch": 592.19,
      "learning_rate": 0.04080600774710611,
      "loss": 2.6021,
      "step": 368340
    },
    {
      "epoch": 592.22,
      "learning_rate": 0.04080279231623794,
      "loss": 2.5951,
      "step": 368360
    },
    {
      "epoch": 592.25,
      "learning_rate": 0.04079957688536978,
      "loss": 2.6532,
      "step": 368380
    },
    {
      "epoch": 592.28,
      "learning_rate": 0.04079636145450161,
      "loss": 2.6193,
      "step": 368400
    },
    {
      "epoch": 592.32,
      "learning_rate": 0.040793146023633445,
      "loss": 2.6071,
      "step": 368420
    },
    {
      "epoch": 592.35,
      "learning_rate": 0.040789930592765276,
      "loss": 2.594,
      "step": 368440
    },
    {
      "epoch": 592.38,
      "learning_rate": 0.04078671516189711,
      "loss": 2.6052,
      "step": 368460
    },
    {
      "epoch": 592.41,
      "learning_rate": 0.04078349973102894,
      "loss": 2.6075,
      "step": 368480
    },
    {
      "epoch": 592.44,
      "learning_rate": 0.04078028430016078,
      "loss": 2.5958,
      "step": 368500
    },
    {
      "epoch": 592.48,
      "learning_rate": 0.04077706886929261,
      "loss": 2.6136,
      "step": 368520
    },
    {
      "epoch": 592.51,
      "learning_rate": 0.04077385343842444,
      "loss": 2.6253,
      "step": 368540
    },
    {
      "epoch": 592.54,
      "learning_rate": 0.04077063800755627,
      "loss": 2.5987,
      "step": 368560
    },
    {
      "epoch": 592.57,
      "learning_rate": 0.040767422576688105,
      "loss": 2.6024,
      "step": 368580
    },
    {
      "epoch": 592.6,
      "learning_rate": 0.040764207145819936,
      "loss": 2.6068,
      "step": 368600
    },
    {
      "epoch": 592.64,
      "learning_rate": 0.040760991714951775,
      "loss": 2.6136,
      "step": 368620
    },
    {
      "epoch": 592.67,
      "learning_rate": 0.040757776284083606,
      "loss": 2.6196,
      "step": 368640
    },
    {
      "epoch": 592.7,
      "learning_rate": 0.04075456085321544,
      "loss": 2.5993,
      "step": 368660
    },
    {
      "epoch": 592.73,
      "learning_rate": 0.04075134542234727,
      "loss": 2.6318,
      "step": 368680
    },
    {
      "epoch": 592.77,
      "learning_rate": 0.0407481299914791,
      "loss": 2.6238,
      "step": 368700
    },
    {
      "epoch": 592.8,
      "learning_rate": 0.04074491456061094,
      "loss": 2.6052,
      "step": 368720
    },
    {
      "epoch": 592.83,
      "learning_rate": 0.04074169912974277,
      "loss": 2.6216,
      "step": 368740
    },
    {
      "epoch": 592.86,
      "learning_rate": 0.0407384836988746,
      "loss": 2.6089,
      "step": 368760
    },
    {
      "epoch": 592.89,
      "learning_rate": 0.040735268268006435,
      "loss": 2.6195,
      "step": 368780
    },
    {
      "epoch": 592.93,
      "learning_rate": 0.040732052837138266,
      "loss": 2.6153,
      "step": 368800
    },
    {
      "epoch": 592.96,
      "learning_rate": 0.0407288374062701,
      "loss": 2.6308,
      "step": 368820
    },
    {
      "epoch": 592.99,
      "learning_rate": 0.040725621975401936,
      "loss": 2.616,
      "step": 368840
    },
    {
      "epoch": 593.0,
      "eval_accuracy": {
        "accuracy": 0.4212858586643862
      },
      "eval_loss": 2.7341179847717285,
      "eval_runtime": 2.9478,
      "eval_samples_per_second": 4363.596,
      "eval_steps_per_second": 68.186,
      "step": 368846
    },
    {
      "epoch": 593.02,
      "learning_rate": 0.04072240654453377,
      "loss": 2.6221,
      "step": 368860
    },
    {
      "epoch": 593.05,
      "learning_rate": 0.0407191911136656,
      "loss": 2.6155,
      "step": 368880
    },
    {
      "epoch": 593.09,
      "learning_rate": 0.04071597568279743,
      "loss": 2.6176,
      "step": 368900
    },
    {
      "epoch": 593.12,
      "learning_rate": 0.04071276025192926,
      "loss": 2.5832,
      "step": 368920
    },
    {
      "epoch": 593.15,
      "learning_rate": 0.040709544821061094,
      "loss": 2.6417,
      "step": 368940
    },
    {
      "epoch": 593.18,
      "learning_rate": 0.04070632939019293,
      "loss": 2.6076,
      "step": 368960
    },
    {
      "epoch": 593.22,
      "learning_rate": 0.040703113959324765,
      "loss": 2.6242,
      "step": 368980
    },
    {
      "epoch": 593.25,
      "learning_rate": 0.040699898528456596,
      "loss": 2.6179,
      "step": 369000
    },
    {
      "epoch": 593.28,
      "learning_rate": 0.04069668309758843,
      "loss": 2.6337,
      "step": 369020
    },
    {
      "epoch": 593.31,
      "learning_rate": 0.04069346766672026,
      "loss": 2.6181,
      "step": 369040
    },
    {
      "epoch": 593.34,
      "learning_rate": 0.0406902522358521,
      "loss": 2.5981,
      "step": 369060
    },
    {
      "epoch": 593.38,
      "learning_rate": 0.04068703680498393,
      "loss": 2.5842,
      "step": 369080
    },
    {
      "epoch": 593.41,
      "learning_rate": 0.04068382137411576,
      "loss": 2.6136,
      "step": 369100
    },
    {
      "epoch": 593.44,
      "learning_rate": 0.04068060594324759,
      "loss": 2.6052,
      "step": 369120
    },
    {
      "epoch": 593.47,
      "learning_rate": 0.040677390512379424,
      "loss": 2.6066,
      "step": 369140
    },
    {
      "epoch": 593.5,
      "learning_rate": 0.040674175081511256,
      "loss": 2.6345,
      "step": 369160
    },
    {
      "epoch": 593.54,
      "learning_rate": 0.040670959650643095,
      "loss": 2.6253,
      "step": 369180
    },
    {
      "epoch": 593.57,
      "learning_rate": 0.040667744219774926,
      "loss": 2.6302,
      "step": 369200
    },
    {
      "epoch": 593.6,
      "learning_rate": 0.04066452878890676,
      "loss": 2.6122,
      "step": 369220
    },
    {
      "epoch": 593.63,
      "learning_rate": 0.04066131335803859,
      "loss": 2.5958,
      "step": 369240
    },
    {
      "epoch": 593.67,
      "learning_rate": 0.04065809792717042,
      "loss": 2.6075,
      "step": 369260
    },
    {
      "epoch": 593.7,
      "learning_rate": 0.04065488249630225,
      "loss": 2.6133,
      "step": 369280
    },
    {
      "epoch": 593.73,
      "learning_rate": 0.04065166706543409,
      "loss": 2.6016,
      "step": 369300
    },
    {
      "epoch": 593.76,
      "learning_rate": 0.04064845163456592,
      "loss": 2.5892,
      "step": 369320
    },
    {
      "epoch": 593.79,
      "learning_rate": 0.040645236203697754,
      "loss": 2.6218,
      "step": 369340
    },
    {
      "epoch": 593.83,
      "learning_rate": 0.040642020772829586,
      "loss": 2.5826,
      "step": 369360
    },
    {
      "epoch": 593.86,
      "learning_rate": 0.04063880534196142,
      "loss": 2.5898,
      "step": 369380
    },
    {
      "epoch": 593.89,
      "learning_rate": 0.040635589911093256,
      "loss": 2.6164,
      "step": 369400
    },
    {
      "epoch": 593.92,
      "learning_rate": 0.04063237448022509,
      "loss": 2.6196,
      "step": 369420
    },
    {
      "epoch": 593.95,
      "learning_rate": 0.04062915904935692,
      "loss": 2.6189,
      "step": 369440
    },
    {
      "epoch": 593.99,
      "learning_rate": 0.04062594361848875,
      "loss": 2.5979,
      "step": 369460
    },
    {
      "epoch": 594.0,
      "eval_accuracy": {
        "accuracy": 0.41895358780999764
      },
      "eval_loss": 2.72097110748291,
      "eval_runtime": 3.0919,
      "eval_samples_per_second": 4160.193,
      "eval_steps_per_second": 65.008,
      "step": 369468
    },
    {
      "epoch": 594.02,
      "learning_rate": 0.04062272818762058,
      "loss": 2.6088,
      "step": 369480
    },
    {
      "epoch": 594.05,
      "learning_rate": 0.040619512756752414,
      "loss": 2.6019,
      "step": 369500
    },
    {
      "epoch": 594.08,
      "learning_rate": 0.04061629732588425,
      "loss": 2.6405,
      "step": 369520
    },
    {
      "epoch": 594.12,
      "learning_rate": 0.040613081895016084,
      "loss": 2.6295,
      "step": 369540
    },
    {
      "epoch": 594.15,
      "learning_rate": 0.040609866464147916,
      "loss": 2.62,
      "step": 369560
    },
    {
      "epoch": 594.18,
      "learning_rate": 0.04060665103327975,
      "loss": 2.5958,
      "step": 369580
    },
    {
      "epoch": 594.21,
      "learning_rate": 0.04060343560241158,
      "loss": 2.573,
      "step": 369600
    },
    {
      "epoch": 594.24,
      "learning_rate": 0.040600220171543404,
      "loss": 2.6057,
      "step": 369620
    },
    {
      "epoch": 594.28,
      "learning_rate": 0.04059716551221865,
      "loss": 2.6139,
      "step": 369640
    },
    {
      "epoch": 594.31,
      "learning_rate": 0.04059395008135049,
      "loss": 2.6028,
      "step": 369660
    },
    {
      "epoch": 594.34,
      "learning_rate": 0.040590734650482324,
      "loss": 2.6298,
      "step": 369680
    },
    {
      "epoch": 594.37,
      "learning_rate": 0.040587519219614156,
      "loss": 2.6105,
      "step": 369700
    },
    {
      "epoch": 594.41,
      "learning_rate": 0.04058430378874598,
      "loss": 2.5869,
      "step": 369720
    },
    {
      "epoch": 594.44,
      "learning_rate": 0.04058108835787781,
      "loss": 2.6228,
      "step": 369740
    },
    {
      "epoch": 594.47,
      "learning_rate": 0.040577872927009644,
      "loss": 2.6091,
      "step": 369760
    },
    {
      "epoch": 594.5,
      "learning_rate": 0.04057465749614149,
      "loss": 2.6169,
      "step": 369780
    },
    {
      "epoch": 594.53,
      "learning_rate": 0.04057144206527332,
      "loss": 2.5964,
      "step": 369800
    },
    {
      "epoch": 594.57,
      "learning_rate": 0.040568226634405145,
      "loss": 2.6102,
      "step": 369820
    },
    {
      "epoch": 594.6,
      "learning_rate": 0.04056501120353698,
      "loss": 2.6216,
      "step": 369840
    },
    {
      "epoch": 594.63,
      "learning_rate": 0.04056179577266881,
      "loss": 2.6136,
      "step": 369860
    },
    {
      "epoch": 594.66,
      "learning_rate": 0.040558580341800654,
      "loss": 2.5826,
      "step": 369880
    },
    {
      "epoch": 594.69,
      "learning_rate": 0.040555364910932486,
      "loss": 2.6048,
      "step": 369900
    },
    {
      "epoch": 594.73,
      "learning_rate": 0.04055214948006432,
      "loss": 2.6215,
      "step": 369920
    },
    {
      "epoch": 594.76,
      "learning_rate": 0.04054893404919614,
      "loss": 2.5979,
      "step": 369940
    },
    {
      "epoch": 594.79,
      "learning_rate": 0.040545718618327974,
      "loss": 2.5921,
      "step": 369960
    },
    {
      "epoch": 594.82,
      "learning_rate": 0.040542503187459805,
      "loss": 2.622,
      "step": 369980
    },
    {
      "epoch": 594.86,
      "learning_rate": 0.04053928775659165,
      "loss": 2.5987,
      "step": 370000
    },
    {
      "epoch": 594.89,
      "learning_rate": 0.04053607232572348,
      "loss": 2.6206,
      "step": 370020
    },
    {
      "epoch": 594.92,
      "learning_rate": 0.04053285689485531,
      "loss": 2.6181,
      "step": 370040
    },
    {
      "epoch": 594.95,
      "learning_rate": 0.04052964146398714,
      "loss": 2.6463,
      "step": 370060
    },
    {
      "epoch": 594.98,
      "learning_rate": 0.04052642603311897,
      "loss": 2.623,
      "step": 370080
    },
    {
      "epoch": 595.0,
      "eval_accuracy": {
        "accuracy": 0.4194200419808754
      },
      "eval_loss": 2.728148937225342,
      "eval_runtime": 3.2816,
      "eval_samples_per_second": 3919.787,
      "eval_steps_per_second": 61.251,
      "step": 370090
    },
    {
      "epoch": 595.02,
      "learning_rate": 0.0405232106022508,
      "loss": 2.5938,
      "step": 370100
    },
    {
      "epoch": 595.05,
      "learning_rate": 0.04051999517138265,
      "loss": 2.6151,
      "step": 370120
    },
    {
      "epoch": 595.08,
      "learning_rate": 0.04051677974051447,
      "loss": 2.6088,
      "step": 370140
    },
    {
      "epoch": 595.11,
      "learning_rate": 0.040513564309646304,
      "loss": 2.6064,
      "step": 370160
    },
    {
      "epoch": 595.14,
      "learning_rate": 0.040510348878778135,
      "loss": 2.5811,
      "step": 370180
    },
    {
      "epoch": 595.18,
      "learning_rate": 0.04050713344790997,
      "loss": 2.6136,
      "step": 370200
    },
    {
      "epoch": 595.21,
      "learning_rate": 0.04050391801704181,
      "loss": 2.6022,
      "step": 370220
    },
    {
      "epoch": 595.24,
      "learning_rate": 0.040500702586173644,
      "loss": 2.6012,
      "step": 370240
    },
    {
      "epoch": 595.27,
      "learning_rate": 0.04049748715530547,
      "loss": 2.5989,
      "step": 370260
    },
    {
      "epoch": 595.31,
      "learning_rate": 0.0404942717244373,
      "loss": 2.6122,
      "step": 370280
    },
    {
      "epoch": 595.34,
      "learning_rate": 0.04049105629356913,
      "loss": 2.5921,
      "step": 370300
    },
    {
      "epoch": 595.37,
      "learning_rate": 0.04048784086270096,
      "loss": 2.6014,
      "step": 370320
    },
    {
      "epoch": 595.4,
      "learning_rate": 0.04048462543183281,
      "loss": 2.598,
      "step": 370340
    },
    {
      "epoch": 595.43,
      "learning_rate": 0.040481410000964634,
      "loss": 2.6073,
      "step": 370360
    },
    {
      "epoch": 595.47,
      "learning_rate": 0.040478194570096465,
      "loss": 2.6175,
      "step": 370380
    },
    {
      "epoch": 595.5,
      "learning_rate": 0.0404749791392283,
      "loss": 2.5917,
      "step": 370400
    },
    {
      "epoch": 595.53,
      "learning_rate": 0.04047176370836013,
      "loss": 2.6302,
      "step": 370420
    },
    {
      "epoch": 595.56,
      "learning_rate": 0.04046854827749196,
      "loss": 2.5957,
      "step": 370440
    },
    {
      "epoch": 595.59,
      "learning_rate": 0.0404653328466238,
      "loss": 2.6023,
      "step": 370460
    },
    {
      "epoch": 595.63,
      "learning_rate": 0.04046211741575563,
      "loss": 2.6285,
      "step": 370480
    },
    {
      "epoch": 595.66,
      "learning_rate": 0.04045890198488746,
      "loss": 2.5964,
      "step": 370500
    },
    {
      "epoch": 595.69,
      "learning_rate": 0.04045568655401929,
      "loss": 2.6173,
      "step": 370520
    },
    {
      "epoch": 595.72,
      "learning_rate": 0.040452471123151125,
      "loss": 2.607,
      "step": 370540
    },
    {
      "epoch": 595.76,
      "learning_rate": 0.04044925569228297,
      "loss": 2.6008,
      "step": 370560
    },
    {
      "epoch": 595.79,
      "learning_rate": 0.040446040261414795,
      "loss": 2.6156,
      "step": 370580
    },
    {
      "epoch": 595.82,
      "learning_rate": 0.04044282483054663,
      "loss": 2.6097,
      "step": 370600
    },
    {
      "epoch": 595.85,
      "learning_rate": 0.04043960939967846,
      "loss": 2.6048,
      "step": 370620
    },
    {
      "epoch": 595.88,
      "learning_rate": 0.04043639396881029,
      "loss": 2.5712,
      "step": 370640
    },
    {
      "epoch": 595.92,
      "learning_rate": 0.04043317853794212,
      "loss": 2.612,
      "step": 370660
    },
    {
      "epoch": 595.95,
      "learning_rate": 0.04042996310707396,
      "loss": 2.6244,
      "step": 370680
    },
    {
      "epoch": 595.98,
      "learning_rate": 0.04042674767620579,
      "loss": 2.6159,
      "step": 370700
    },
    {
      "epoch": 596.0,
      "eval_accuracy": {
        "accuracy": 0.4196532690663142
      },
      "eval_loss": 2.726325511932373,
      "eval_runtime": 2.9691,
      "eval_samples_per_second": 4332.219,
      "eval_steps_per_second": 67.696,
      "step": 370712
    },
    {
      "epoch": 596.01,
      "learning_rate": 0.04042353224533762,
      "loss": 2.6299,
      "step": 370720
    },
    {
      "epoch": 596.05,
      "learning_rate": 0.040420316814469455,
      "loss": 2.6197,
      "step": 370740
    },
    {
      "epoch": 596.08,
      "learning_rate": 0.04041710138360129,
      "loss": 2.6002,
      "step": 370760
    },
    {
      "epoch": 596.11,
      "learning_rate": 0.040413885952733125,
      "loss": 2.6203,
      "step": 370780
    },
    {
      "epoch": 596.14,
      "learning_rate": 0.04041067052186496,
      "loss": 2.6087,
      "step": 370800
    },
    {
      "epoch": 596.17,
      "learning_rate": 0.04040745509099679,
      "loss": 2.6282,
      "step": 370820
    },
    {
      "epoch": 596.21,
      "learning_rate": 0.04040423966012862,
      "loss": 2.6234,
      "step": 370840
    },
    {
      "epoch": 596.24,
      "learning_rate": 0.04040102422926045,
      "loss": 2.5921,
      "step": 370860
    },
    {
      "epoch": 596.27,
      "learning_rate": 0.04039780879839228,
      "loss": 2.5987,
      "step": 370880
    },
    {
      "epoch": 596.3,
      "learning_rate": 0.04039459336752412,
      "loss": 2.5974,
      "step": 370900
    },
    {
      "epoch": 596.33,
      "learning_rate": 0.04039137793665595,
      "loss": 2.6039,
      "step": 370920
    },
    {
      "epoch": 596.37,
      "learning_rate": 0.040388162505787785,
      "loss": 2.6232,
      "step": 370940
    },
    {
      "epoch": 596.4,
      "learning_rate": 0.04038494707491962,
      "loss": 2.5763,
      "step": 370960
    },
    {
      "epoch": 596.43,
      "learning_rate": 0.04038173164405145,
      "loss": 2.5978,
      "step": 370980
    },
    {
      "epoch": 596.46,
      "learning_rate": 0.04037851621318328,
      "loss": 2.6113,
      "step": 371000
    },
    {
      "epoch": 596.5,
      "learning_rate": 0.04037530078231512,
      "loss": 2.6201,
      "step": 371020
    },
    {
      "epoch": 596.53,
      "learning_rate": 0.04037208535144695,
      "loss": 2.6188,
      "step": 371040
    },
    {
      "epoch": 596.56,
      "learning_rate": 0.04036886992057878,
      "loss": 2.6099,
      "step": 371060
    },
    {
      "epoch": 596.59,
      "learning_rate": 0.04036565448971061,
      "loss": 2.6191,
      "step": 371080
    },
    {
      "epoch": 596.62,
      "learning_rate": 0.040362439058842445,
      "loss": 2.6281,
      "step": 371100
    },
    {
      "epoch": 596.66,
      "learning_rate": 0.04035922362797428,
      "loss": 2.6247,
      "step": 371120
    },
    {
      "epoch": 596.69,
      "learning_rate": 0.040356008197106115,
      "loss": 2.6222,
      "step": 371140
    },
    {
      "epoch": 596.72,
      "learning_rate": 0.04035279276623795,
      "loss": 2.6181,
      "step": 371160
    },
    {
      "epoch": 596.75,
      "learning_rate": 0.04034957733536978,
      "loss": 2.6152,
      "step": 371180
    },
    {
      "epoch": 596.78,
      "learning_rate": 0.04034636190450161,
      "loss": 2.609,
      "step": 371200
    },
    {
      "epoch": 596.82,
      "learning_rate": 0.04034314647363344,
      "loss": 2.627,
      "step": 371220
    },
    {
      "epoch": 596.85,
      "learning_rate": 0.04033993104276528,
      "loss": 2.6075,
      "step": 371240
    },
    {
      "epoch": 596.88,
      "learning_rate": 0.04033671561189711,
      "loss": 2.6002,
      "step": 371260
    },
    {
      "epoch": 596.91,
      "learning_rate": 0.04033350018102894,
      "loss": 2.5934,
      "step": 371280
    },
    {
      "epoch": 596.95,
      "learning_rate": 0.040330284750160775,
      "loss": 2.6208,
      "step": 371300
    },
    {
      "epoch": 596.98,
      "learning_rate": 0.040327069319292606,
      "loss": 2.6002,
      "step": 371320
    },
    {
      "epoch": 597.0,
      "eval_accuracy": {
        "accuracy": 0.42493974966959497
      },
      "eval_loss": 2.7074995040893555,
      "eval_runtime": 2.9225,
      "eval_samples_per_second": 4401.341,
      "eval_steps_per_second": 68.776,
      "step": 371334
    },
    {
      "epoch": 597.01,
      "learning_rate": 0.04032385388842444,
      "loss": 2.603,
      "step": 371340
    },
    {
      "epoch": 597.04,
      "learning_rate": 0.040320638457556277,
      "loss": 2.607,
      "step": 371360
    },
    {
      "epoch": 597.07,
      "learning_rate": 0.04031742302668811,
      "loss": 2.6169,
      "step": 371380
    },
    {
      "epoch": 597.11,
      "learning_rate": 0.04031420759581994,
      "loss": 2.597,
      "step": 371400
    },
    {
      "epoch": 597.14,
      "learning_rate": 0.04031099216495177,
      "loss": 2.5891,
      "step": 371420
    },
    {
      "epoch": 597.17,
      "learning_rate": 0.0403077767340836,
      "loss": 2.6395,
      "step": 371440
    },
    {
      "epoch": 597.2,
      "learning_rate": 0.04030456130321544,
      "loss": 2.5955,
      "step": 371460
    },
    {
      "epoch": 597.23,
      "learning_rate": 0.04030134587234727,
      "loss": 2.6293,
      "step": 371480
    },
    {
      "epoch": 597.27,
      "learning_rate": 0.040298130441479105,
      "loss": 2.6393,
      "step": 371500
    },
    {
      "epoch": 597.3,
      "learning_rate": 0.040294915010610936,
      "loss": 2.6041,
      "step": 371520
    },
    {
      "epoch": 597.33,
      "learning_rate": 0.04029169957974277,
      "loss": 2.6014,
      "step": 371540
    },
    {
      "epoch": 597.36,
      "learning_rate": 0.0402884841488746,
      "loss": 2.5925,
      "step": 371560
    },
    {
      "epoch": 597.4,
      "learning_rate": 0.04028526871800644,
      "loss": 2.5862,
      "step": 371580
    },
    {
      "epoch": 597.43,
      "learning_rate": 0.04028205328713827,
      "loss": 2.6034,
      "step": 371600
    },
    {
      "epoch": 597.46,
      "learning_rate": 0.0402788378562701,
      "loss": 2.6044,
      "step": 371620
    },
    {
      "epoch": 597.49,
      "learning_rate": 0.04027562242540193,
      "loss": 2.5983,
      "step": 371640
    },
    {
      "epoch": 597.52,
      "learning_rate": 0.040272406994533765,
      "loss": 2.6017,
      "step": 371660
    },
    {
      "epoch": 597.56,
      "learning_rate": 0.040269191563665596,
      "loss": 2.6001,
      "step": 371680
    },
    {
      "epoch": 597.59,
      "learning_rate": 0.040265976132797435,
      "loss": 2.5832,
      "step": 371700
    },
    {
      "epoch": 597.62,
      "learning_rate": 0.040262760701929266,
      "loss": 2.627,
      "step": 371720
    },
    {
      "epoch": 597.65,
      "learning_rate": 0.0402595452710611,
      "loss": 2.6013,
      "step": 371740
    },
    {
      "epoch": 597.68,
      "learning_rate": 0.04025632984019293,
      "loss": 2.6204,
      "step": 371760
    },
    {
      "epoch": 597.72,
      "learning_rate": 0.04025311440932476,
      "loss": 2.5991,
      "step": 371780
    },
    {
      "epoch": 597.75,
      "learning_rate": 0.0402498989784566,
      "loss": 2.6238,
      "step": 371800
    },
    {
      "epoch": 597.78,
      "learning_rate": 0.04024668354758843,
      "loss": 2.5995,
      "step": 371820
    },
    {
      "epoch": 597.81,
      "learning_rate": 0.04024346811672026,
      "loss": 2.621,
      "step": 371840
    },
    {
      "epoch": 597.85,
      "learning_rate": 0.040240252685852095,
      "loss": 2.6272,
      "step": 371860
    },
    {
      "epoch": 597.88,
      "learning_rate": 0.040237037254983926,
      "loss": 2.6322,
      "step": 371880
    },
    {
      "epoch": 597.91,
      "learning_rate": 0.04023382182411576,
      "loss": 2.6256,
      "step": 371900
    },
    {
      "epoch": 597.94,
      "learning_rate": 0.040230606393247596,
      "loss": 2.6537,
      "step": 371920
    },
    {
      "epoch": 597.97,
      "learning_rate": 0.04022739096237943,
      "loss": 2.6372,
      "step": 371940
    },
    {
      "epoch": 598.0,
      "eval_accuracy": {
        "accuracy": 0.42595040037316334
      },
      "eval_loss": 2.7163281440734863,
      "eval_runtime": 3.2725,
      "eval_samples_per_second": 3930.652,
      "eval_steps_per_second": 61.421,
      "step": 371956
    },
    {
      "epoch": 598.01,
      "learning_rate": 0.04022417553151126,
      "loss": 2.6191,
      "step": 371960
    },
    {
      "epoch": 598.04,
      "learning_rate": 0.04022096010064309,
      "loss": 2.6129,
      "step": 371980
    },
    {
      "epoch": 598.07,
      "learning_rate": 0.04021774466977492,
      "loss": 2.6198,
      "step": 372000
    },
    {
      "epoch": 598.1,
      "learning_rate": 0.040214529238906754,
      "loss": 2.5949,
      "step": 372020
    },
    {
      "epoch": 598.14,
      "learning_rate": 0.04021131380803859,
      "loss": 2.5967,
      "step": 372040
    },
    {
      "epoch": 598.17,
      "learning_rate": 0.040208098377170425,
      "loss": 2.6138,
      "step": 372060
    },
    {
      "epoch": 598.2,
      "learning_rate": 0.040204882946302256,
      "loss": 2.6212,
      "step": 372080
    },
    {
      "epoch": 598.23,
      "learning_rate": 0.04020166751543409,
      "loss": 2.6029,
      "step": 372100
    },
    {
      "epoch": 598.26,
      "learning_rate": 0.04019845208456592,
      "loss": 2.5991,
      "step": 372120
    },
    {
      "epoch": 598.3,
      "learning_rate": 0.04019523665369776,
      "loss": 2.607,
      "step": 372140
    },
    {
      "epoch": 598.33,
      "learning_rate": 0.04019202122282959,
      "loss": 2.6022,
      "step": 372160
    },
    {
      "epoch": 598.36,
      "learning_rate": 0.04018880579196142,
      "loss": 2.6016,
      "step": 372180
    },
    {
      "epoch": 598.39,
      "learning_rate": 0.04018559036109325,
      "loss": 2.598,
      "step": 372200
    },
    {
      "epoch": 598.42,
      "learning_rate": 0.040182374930225084,
      "loss": 2.5927,
      "step": 372220
    },
    {
      "epoch": 598.46,
      "learning_rate": 0.04017915949935691,
      "loss": 2.6112,
      "step": 372240
    },
    {
      "epoch": 598.49,
      "learning_rate": 0.040175944068488754,
      "loss": 2.6077,
      "step": 372260
    },
    {
      "epoch": 598.52,
      "learning_rate": 0.040172728637620586,
      "loss": 2.6225,
      "step": 372280
    },
    {
      "epoch": 598.55,
      "learning_rate": 0.04016951320675242,
      "loss": 2.6033,
      "step": 372300
    },
    {
      "epoch": 598.59,
      "learning_rate": 0.04016629777588425,
      "loss": 2.5885,
      "step": 372320
    },
    {
      "epoch": 598.62,
      "learning_rate": 0.04016308234501608,
      "loss": 2.6252,
      "step": 372340
    },
    {
      "epoch": 598.65,
      "learning_rate": 0.040159866914147906,
      "loss": 2.6081,
      "step": 372360
    },
    {
      "epoch": 598.68,
      "learning_rate": 0.04015665148327975,
      "loss": 2.6029,
      "step": 372380
    },
    {
      "epoch": 598.71,
      "learning_rate": 0.04015343605241158,
      "loss": 2.5774,
      "step": 372400
    },
    {
      "epoch": 598.75,
      "learning_rate": 0.040150220621543414,
      "loss": 2.5914,
      "step": 372420
    },
    {
      "epoch": 598.78,
      "learning_rate": 0.040147005190675246,
      "loss": 2.5774,
      "step": 372440
    },
    {
      "epoch": 598.81,
      "learning_rate": 0.04014378975980707,
      "loss": 2.6089,
      "step": 372460
    },
    {
      "epoch": 598.84,
      "learning_rate": 0.040140574328938916,
      "loss": 2.6045,
      "step": 372480
    },
    {
      "epoch": 598.87,
      "learning_rate": 0.04013735889807075,
      "loss": 2.6112,
      "step": 372500
    },
    {
      "epoch": 598.91,
      "learning_rate": 0.04013414346720258,
      "loss": 2.6327,
      "step": 372520
    },
    {
      "epoch": 598.94,
      "learning_rate": 0.04013092803633441,
      "loss": 2.6341,
      "step": 372540
    },
    {
      "epoch": 598.97,
      "learning_rate": 0.040127712605466236,
      "loss": 2.5959,
      "step": 372560
    },
    {
      "epoch": 599.0,
      "eval_accuracy": {
        "accuracy": 0.4247065225841561
      },
      "eval_loss": 2.7284581661224365,
      "eval_runtime": 2.902,
      "eval_samples_per_second": 4432.529,
      "eval_steps_per_second": 69.264,
      "step": 372578
    },
    {
      "epoch": 599.0,
      "learning_rate": 0.04012449717459807,
      "loss": 2.6199,
      "step": 372580
    },
    {
      "epoch": 599.04,
      "learning_rate": 0.04012128174372991,
      "loss": 2.6151,
      "step": 372600
    },
    {
      "epoch": 599.07,
      "learning_rate": 0.040118066312861744,
      "loss": 2.6291,
      "step": 372620
    },
    {
      "epoch": 599.1,
      "learning_rate": 0.040114850881993576,
      "loss": 2.6161,
      "step": 372640
    },
    {
      "epoch": 599.13,
      "learning_rate": 0.04011163545112541,
      "loss": 2.6398,
      "step": 372660
    },
    {
      "epoch": 599.16,
      "learning_rate": 0.04010842002025723,
      "loss": 2.5855,
      "step": 372680
    },
    {
      "epoch": 599.2,
      "learning_rate": 0.04010520458938908,
      "loss": 2.6082,
      "step": 372700
    },
    {
      "epoch": 599.23,
      "learning_rate": 0.04010198915852091,
      "loss": 2.626,
      "step": 372720
    },
    {
      "epoch": 599.26,
      "learning_rate": 0.04009877372765274,
      "loss": 2.6131,
      "step": 372740
    },
    {
      "epoch": 599.29,
      "learning_rate": 0.04009555829678457,
      "loss": 2.6233,
      "step": 372760
    },
    {
      "epoch": 599.32,
      "learning_rate": 0.0400923428659164,
      "loss": 2.5918,
      "step": 372780
    },
    {
      "epoch": 599.36,
      "learning_rate": 0.04008912743504823,
      "loss": 2.599,
      "step": 372800
    },
    {
      "epoch": 599.39,
      "learning_rate": 0.040085912004180074,
      "loss": 2.6111,
      "step": 372820
    },
    {
      "epoch": 599.42,
      "learning_rate": 0.040082696573311906,
      "loss": 2.6136,
      "step": 372840
    },
    {
      "epoch": 599.45,
      "learning_rate": 0.04007948114244374,
      "loss": 2.5711,
      "step": 372860
    },
    {
      "epoch": 599.49,
      "learning_rate": 0.04007626571157556,
      "loss": 2.5879,
      "step": 372880
    },
    {
      "epoch": 599.52,
      "learning_rate": 0.040073050280707394,
      "loss": 2.6078,
      "step": 372900
    },
    {
      "epoch": 599.55,
      "learning_rate": 0.040069834849839225,
      "loss": 2.6031,
      "step": 372920
    },
    {
      "epoch": 599.58,
      "learning_rate": 0.04006661941897107,
      "loss": 2.594,
      "step": 372940
    },
    {
      "epoch": 599.61,
      "learning_rate": 0.0400634039881029,
      "loss": 2.5913,
      "step": 372960
    },
    {
      "epoch": 599.65,
      "learning_rate": 0.040060188557234734,
      "loss": 2.5846,
      "step": 372980
    },
    {
      "epoch": 599.68,
      "learning_rate": 0.04005697312636656,
      "loss": 2.5957,
      "step": 373000
    },
    {
      "epoch": 599.71,
      "learning_rate": 0.04005375769549839,
      "loss": 2.6089,
      "step": 373020
    },
    {
      "epoch": 599.74,
      "learning_rate": 0.040050542264630236,
      "loss": 2.5985,
      "step": 373040
    },
    {
      "epoch": 599.77,
      "learning_rate": 0.04004732683376207,
      "loss": 2.6122,
      "step": 373060
    },
    {
      "epoch": 599.81,
      "learning_rate": 0.0400441114028939,
      "loss": 2.6318,
      "step": 373080
    },
    {
      "epoch": 599.84,
      "learning_rate": 0.040040895972025724,
      "loss": 2.613,
      "step": 373100
    },
    {
      "epoch": 599.87,
      "learning_rate": 0.040037680541157555,
      "loss": 2.6241,
      "step": 373120
    },
    {
      "epoch": 599.9,
      "learning_rate": 0.04003446511028939,
      "loss": 2.6046,
      "step": 373140
    },
    {
      "epoch": 599.94,
      "learning_rate": 0.04003124967942123,
      "loss": 2.6023,
      "step": 373160
    },
    {
      "epoch": 599.97,
      "learning_rate": 0.040028034248553064,
      "loss": 2.6255,
      "step": 373180
    },
    {
      "epoch": 600.0,
      "learning_rate": 0.04002481881768489,
      "loss": 2.614,
      "step": 373200
    },
    {
      "epoch": 600.0,
      "eval_accuracy": {
        "accuracy": 0.42944880665474616
      },
      "eval_loss": 2.6824467182159424,
      "eval_runtime": 3.2262,
      "eval_samples_per_second": 3987.052,
      "eval_steps_per_second": 62.303,
      "step": 373200
    },
    {
      "epoch": 600.03,
      "learning_rate": 0.04002160338681672,
      "loss": 2.6014,
      "step": 373220
    },
    {
      "epoch": 600.06,
      "learning_rate": 0.04001838795594855,
      "loss": 2.5963,
      "step": 373240
    },
    {
      "epoch": 600.1,
      "learning_rate": 0.040015172525080384,
      "loss": 2.6178,
      "step": 373260
    },
    {
      "epoch": 600.13,
      "learning_rate": 0.04001195709421223,
      "loss": 2.6,
      "step": 373280
    },
    {
      "epoch": 600.16,
      "learning_rate": 0.04000874166334406,
      "loss": 2.6018,
      "step": 373300
    },
    {
      "epoch": 600.19,
      "learning_rate": 0.040005526232475885,
      "loss": 2.6081,
      "step": 373320
    },
    {
      "epoch": 600.23,
      "learning_rate": 0.04000231080160772,
      "loss": 2.6046,
      "step": 373340
    },
    {
      "epoch": 600.26,
      "learning_rate": 0.03999909537073955,
      "loss": 2.5972,
      "step": 373360
    },
    {
      "epoch": 600.29,
      "learning_rate": 0.039995879939871394,
      "loss": 2.5991,
      "step": 373380
    },
    {
      "epoch": 600.32,
      "learning_rate": 0.03999282528054662,
      "loss": 2.624,
      "step": 373400
    },
    {
      "epoch": 600.35,
      "learning_rate": 0.03998960984967846,
      "loss": 2.6356,
      "step": 373420
    },
    {
      "epoch": 600.39,
      "learning_rate": 0.039986394418810293,
      "loss": 2.6135,
      "step": 373440
    },
    {
      "epoch": 600.42,
      "learning_rate": 0.039983178987942125,
      "loss": 2.6101,
      "step": 373460
    },
    {
      "epoch": 600.45,
      "learning_rate": 0.03997996355707396,
      "loss": 2.6103,
      "step": 373480
    },
    {
      "epoch": 600.48,
      "learning_rate": 0.03997674812620579,
      "loss": 2.6046,
      "step": 373500
    },
    {
      "epoch": 600.51,
      "learning_rate": 0.03997353269533763,
      "loss": 2.6049,
      "step": 373520
    },
    {
      "epoch": 600.55,
      "learning_rate": 0.03997031726446946,
      "loss": 2.595,
      "step": 373540
    },
    {
      "epoch": 600.58,
      "learning_rate": 0.03996710183360129,
      "loss": 2.6125,
      "step": 373560
    },
    {
      "epoch": 600.61,
      "learning_rate": 0.03996388640273312,
      "loss": 2.6008,
      "step": 373580
    },
    {
      "epoch": 600.64,
      "learning_rate": 0.03996067097186495,
      "loss": 2.6232,
      "step": 373600
    },
    {
      "epoch": 600.68,
      "learning_rate": 0.039957455540996785,
      "loss": 2.5849,
      "step": 373620
    },
    {
      "epoch": 600.71,
      "learning_rate": 0.039954240110128623,
      "loss": 2.6045,
      "step": 373640
    },
    {
      "epoch": 600.74,
      "learning_rate": 0.039951024679260455,
      "loss": 2.5909,
      "step": 373660
    },
    {
      "epoch": 600.77,
      "learning_rate": 0.03994780924839229,
      "loss": 2.6148,
      "step": 373680
    },
    {
      "epoch": 600.8,
      "learning_rate": 0.03994459381752412,
      "loss": 2.5963,
      "step": 373700
    },
    {
      "epoch": 600.84,
      "learning_rate": 0.03994137838665595,
      "loss": 2.5965,
      "step": 373720
    },
    {
      "epoch": 600.87,
      "learning_rate": 0.03993816295578778,
      "loss": 2.6083,
      "step": 373740
    },
    {
      "epoch": 600.9,
      "learning_rate": 0.03993494752491962,
      "loss": 2.6147,
      "step": 373760
    },
    {
      "epoch": 600.93,
      "learning_rate": 0.03993173209405145,
      "loss": 2.5998,
      "step": 373780
    },
    {
      "epoch": 600.96,
      "learning_rate": 0.03992851666318328,
      "loss": 2.5872,
      "step": 373800
    },
    {
      "epoch": 601.0,
      "learning_rate": 0.039925301232315115,
      "loss": 2.6277,
      "step": 373820
    },
    {
      "epoch": 601.0,
      "eval_accuracy": {
        "accuracy": 0.42711653580035763
      },
      "eval_loss": 2.718076467514038,
      "eval_runtime": 3.6206,
      "eval_samples_per_second": 3552.712,
      "eval_steps_per_second": 55.515,
      "step": 373822
    },
    {
      "epoch": 601.03,
      "learning_rate": 0.039922085801446947,
      "loss": 2.6208,
      "step": 373840
    },
    {
      "epoch": 601.06,
      "learning_rate": 0.039918870370578785,
      "loss": 2.6137,
      "step": 373860
    },
    {
      "epoch": 601.09,
      "learning_rate": 0.03991565493971062,
      "loss": 2.5705,
      "step": 373880
    },
    {
      "epoch": 601.13,
      "learning_rate": 0.03991243950884245,
      "loss": 2.6136,
      "step": 373900
    },
    {
      "epoch": 601.16,
      "learning_rate": 0.03990922407797428,
      "loss": 2.5976,
      "step": 373920
    },
    {
      "epoch": 601.19,
      "learning_rate": 0.03990600864710611,
      "loss": 2.5965,
      "step": 373940
    },
    {
      "epoch": 601.22,
      "learning_rate": 0.03990279321623794,
      "loss": 2.591,
      "step": 373960
    },
    {
      "epoch": 601.25,
      "learning_rate": 0.03989957778536978,
      "loss": 2.6119,
      "step": 373980
    },
    {
      "epoch": 601.29,
      "learning_rate": 0.03989636235450161,
      "loss": 2.6097,
      "step": 374000
    },
    {
      "epoch": 601.32,
      "learning_rate": 0.039893146923633445,
      "loss": 2.6378,
      "step": 374020
    },
    {
      "epoch": 601.35,
      "learning_rate": 0.039889931492765276,
      "loss": 2.6188,
      "step": 374040
    },
    {
      "epoch": 601.38,
      "learning_rate": 0.03988671606189711,
      "loss": 2.5773,
      "step": 374060
    },
    {
      "epoch": 601.41,
      "learning_rate": 0.03988350063102894,
      "loss": 2.5896,
      "step": 374080
    },
    {
      "epoch": 601.45,
      "learning_rate": 0.03988028520016078,
      "loss": 2.6156,
      "step": 374100
    },
    {
      "epoch": 601.48,
      "learning_rate": 0.03987706976929261,
      "loss": 2.6116,
      "step": 374120
    },
    {
      "epoch": 601.51,
      "learning_rate": 0.03987385433842444,
      "loss": 2.6106,
      "step": 374140
    },
    {
      "epoch": 601.54,
      "learning_rate": 0.03987063890755627,
      "loss": 2.5934,
      "step": 374160
    },
    {
      "epoch": 601.58,
      "learning_rate": 0.039867423476688105,
      "loss": 2.6193,
      "step": 374180
    },
    {
      "epoch": 601.61,
      "learning_rate": 0.03986420804581994,
      "loss": 2.62,
      "step": 374200
    },
    {
      "epoch": 601.64,
      "learning_rate": 0.039860992614951775,
      "loss": 2.6312,
      "step": 374220
    },
    {
      "epoch": 601.67,
      "learning_rate": 0.039857777184083606,
      "loss": 2.6099,
      "step": 374240
    },
    {
      "epoch": 601.7,
      "learning_rate": 0.03985456175321544,
      "loss": 2.6025,
      "step": 374260
    },
    {
      "epoch": 601.74,
      "learning_rate": 0.03985134632234727,
      "loss": 2.6077,
      "step": 374280
    },
    {
      "epoch": 601.77,
      "learning_rate": 0.0398481308914791,
      "loss": 2.5999,
      "step": 374300
    },
    {
      "epoch": 601.8,
      "learning_rate": 0.03984491546061094,
      "loss": 2.6149,
      "step": 374320
    },
    {
      "epoch": 601.83,
      "learning_rate": 0.03984170002974277,
      "loss": 2.5902,
      "step": 374340
    },
    {
      "epoch": 601.86,
      "learning_rate": 0.0398384845988746,
      "loss": 2.6085,
      "step": 374360
    },
    {
      "epoch": 601.9,
      "learning_rate": 0.039835269168006435,
      "loss": 2.622,
      "step": 374380
    },
    {
      "epoch": 601.93,
      "learning_rate": 0.039832053737138266,
      "loss": 2.6171,
      "step": 374400
    },
    {
      "epoch": 601.96,
      "learning_rate": 0.0398288383062701,
      "loss": 2.5984,
      "step": 374420
    },
    {
      "epoch": 601.99,
      "learning_rate": 0.039825622875401936,
      "loss": 2.6141,
      "step": 374440
    },
    {
      "epoch": 602.0,
      "eval_accuracy": {
        "accuracy": 0.42501749203140793
      },
      "eval_loss": 2.712686777114868,
      "eval_runtime": 2.8593,
      "eval_samples_per_second": 4498.705,
      "eval_steps_per_second": 70.298,
      "step": 374444
    },
    {
      "epoch": 602.03,
      "learning_rate": 0.03982240744453377,
      "loss": 2.6021,
      "step": 374460
    },
    {
      "epoch": 602.06,
      "learning_rate": 0.0398191920136656,
      "loss": 2.588,
      "step": 374480
    },
    {
      "epoch": 602.09,
      "learning_rate": 0.03981597658279743,
      "loss": 2.5881,
      "step": 374500
    },
    {
      "epoch": 602.12,
      "learning_rate": 0.03981276115192926,
      "loss": 2.5777,
      "step": 374520
    },
    {
      "epoch": 602.15,
      "learning_rate": 0.0398095457210611,
      "loss": 2.6028,
      "step": 374540
    },
    {
      "epoch": 602.19,
      "learning_rate": 0.03980633029019293,
      "loss": 2.6041,
      "step": 374560
    },
    {
      "epoch": 602.22,
      "learning_rate": 0.039803114859324765,
      "loss": 2.5898,
      "step": 374580
    },
    {
      "epoch": 602.25,
      "learning_rate": 0.039799899428456596,
      "loss": 2.5928,
      "step": 374600
    },
    {
      "epoch": 602.28,
      "learning_rate": 0.03979668399758843,
      "loss": 2.5921,
      "step": 374620
    },
    {
      "epoch": 602.32,
      "learning_rate": 0.03979346856672026,
      "loss": 2.6001,
      "step": 374640
    },
    {
      "epoch": 602.35,
      "learning_rate": 0.0397902531358521,
      "loss": 2.6245,
      "step": 374660
    },
    {
      "epoch": 602.38,
      "learning_rate": 0.03978703770498393,
      "loss": 2.6115,
      "step": 374680
    },
    {
      "epoch": 602.41,
      "learning_rate": 0.03978382227411576,
      "loss": 2.5854,
      "step": 374700
    },
    {
      "epoch": 602.44,
      "learning_rate": 0.03978060684324759,
      "loss": 2.5882,
      "step": 374720
    },
    {
      "epoch": 602.48,
      "learning_rate": 0.039777391412379424,
      "loss": 2.5952,
      "step": 374740
    },
    {
      "epoch": 602.51,
      "learning_rate": 0.03977417598151125,
      "loss": 2.6075,
      "step": 374760
    },
    {
      "epoch": 602.54,
      "learning_rate": 0.039770960550643095,
      "loss": 2.6008,
      "step": 374780
    },
    {
      "epoch": 602.57,
      "learning_rate": 0.039767745119774926,
      "loss": 2.5998,
      "step": 374800
    },
    {
      "epoch": 602.6,
      "learning_rate": 0.03976452968890676,
      "loss": 2.6191,
      "step": 374820
    },
    {
      "epoch": 602.64,
      "learning_rate": 0.03976131425803859,
      "loss": 2.6154,
      "step": 374840
    },
    {
      "epoch": 602.67,
      "learning_rate": 0.03975809882717042,
      "loss": 2.6113,
      "step": 374860
    },
    {
      "epoch": 602.7,
      "learning_rate": 0.03975488339630226,
      "loss": 2.6099,
      "step": 374880
    },
    {
      "epoch": 602.73,
      "learning_rate": 0.03975166796543409,
      "loss": 2.5924,
      "step": 374900
    },
    {
      "epoch": 602.77,
      "learning_rate": 0.03974845253456592,
      "loss": 2.5946,
      "step": 374920
    },
    {
      "epoch": 602.8,
      "learning_rate": 0.039745237103697754,
      "loss": 2.6267,
      "step": 374940
    },
    {
      "epoch": 602.83,
      "learning_rate": 0.039742021672829586,
      "loss": 2.6168,
      "step": 374960
    },
    {
      "epoch": 602.86,
      "learning_rate": 0.03973880624196141,
      "loss": 2.6188,
      "step": 374980
    },
    {
      "epoch": 602.89,
      "learning_rate": 0.039735590811093256,
      "loss": 2.6025,
      "step": 375000
    },
    {
      "epoch": 602.93,
      "learning_rate": 0.03973237538022509,
      "loss": 2.6142,
      "step": 375020
    },
    {
      "epoch": 602.96,
      "learning_rate": 0.03972915994935692,
      "loss": 2.6094,
      "step": 375040
    },
    {
      "epoch": 602.99,
      "learning_rate": 0.03972594451848875,
      "loss": 2.6133,
      "step": 375060
    },
    {
      "epoch": 603.0,
      "eval_accuracy": {
        "accuracy": 0.4258726580113504
      },
      "eval_loss": 2.6951982975006104,
      "eval_runtime": 2.97,
      "eval_samples_per_second": 4330.928,
      "eval_steps_per_second": 67.676,
      "step": 375066
    },
    {
      "epoch": 603.02,
      "learning_rate": 0.039722729087620576,
      "loss": 2.5982,
      "step": 375080
    },
    {
      "epoch": 603.05,
      "learning_rate": 0.03971951365675242,
      "loss": 2.5997,
      "step": 375100
    },
    {
      "epoch": 603.09,
      "learning_rate": 0.03971629822588425,
      "loss": 2.6044,
      "step": 375120
    },
    {
      "epoch": 603.12,
      "learning_rate": 0.039713082795016084,
      "loss": 2.5961,
      "step": 375140
    },
    {
      "epoch": 603.15,
      "learning_rate": 0.039709867364147916,
      "loss": 2.6106,
      "step": 375160
    },
    {
      "epoch": 603.18,
      "learning_rate": 0.03970665193327975,
      "loss": 2.6324,
      "step": 375180
    },
    {
      "epoch": 603.22,
      "learning_rate": 0.03970343650241157,
      "loss": 2.5995,
      "step": 375200
    },
    {
      "epoch": 603.25,
      "learning_rate": 0.03970022107154342,
      "loss": 2.5998,
      "step": 375220
    },
    {
      "epoch": 603.28,
      "learning_rate": 0.03969700564067525,
      "loss": 2.602,
      "step": 375240
    },
    {
      "epoch": 603.31,
      "learning_rate": 0.03969379020980708,
      "loss": 2.6344,
      "step": 375260
    },
    {
      "epoch": 603.34,
      "learning_rate": 0.03969057477893891,
      "loss": 2.6091,
      "step": 375280
    },
    {
      "epoch": 603.38,
      "learning_rate": 0.03968735934807074,
      "loss": 2.6106,
      "step": 375300
    },
    {
      "epoch": 603.41,
      "learning_rate": 0.03968414391720257,
      "loss": 2.6173,
      "step": 375320
    },
    {
      "epoch": 603.44,
      "learning_rate": 0.039680928486334414,
      "loss": 2.6194,
      "step": 375340
    },
    {
      "epoch": 603.47,
      "learning_rate": 0.039677713055466246,
      "loss": 2.5994,
      "step": 375360
    },
    {
      "epoch": 603.5,
      "learning_rate": 0.03967449762459808,
      "loss": 2.5982,
      "step": 375380
    },
    {
      "epoch": 603.54,
      "learning_rate": 0.0396712821937299,
      "loss": 2.6212,
      "step": 375400
    },
    {
      "epoch": 603.57,
      "learning_rate": 0.039668066762861734,
      "loss": 2.6125,
      "step": 375420
    },
    {
      "epoch": 603.6,
      "learning_rate": 0.03966485133199358,
      "loss": 2.5984,
      "step": 375440
    },
    {
      "epoch": 603.63,
      "learning_rate": 0.03966163590112541,
      "loss": 2.5988,
      "step": 375460
    },
    {
      "epoch": 603.67,
      "learning_rate": 0.03965842047025724,
      "loss": 2.6172,
      "step": 375480
    },
    {
      "epoch": 603.7,
      "learning_rate": 0.039655205039389074,
      "loss": 2.5939,
      "step": 375500
    },
    {
      "epoch": 603.73,
      "learning_rate": 0.0396519896085209,
      "loss": 2.5807,
      "step": 375520
    },
    {
      "epoch": 603.76,
      "learning_rate": 0.03964893494919614,
      "loss": 2.5929,
      "step": 375540
    },
    {
      "epoch": 603.79,
      "learning_rate": 0.039645719518327974,
      "loss": 2.6053,
      "step": 375560
    },
    {
      "epoch": 603.83,
      "learning_rate": 0.039642504087459805,
      "loss": 2.6011,
      "step": 375580
    },
    {
      "epoch": 603.86,
      "learning_rate": 0.03963928865659165,
      "loss": 2.6113,
      "step": 375600
    },
    {
      "epoch": 603.89,
      "learning_rate": 0.039636073225723475,
      "loss": 2.5926,
      "step": 375620
    },
    {
      "epoch": 603.92,
      "learning_rate": 0.03963285779485531,
      "loss": 2.5832,
      "step": 375640
    },
    {
      "epoch": 603.95,
      "learning_rate": 0.03962964236398714,
      "loss": 2.6029,
      "step": 375660
    },
    {
      "epoch": 603.99,
      "learning_rate": 0.03962642693311897,
      "loss": 2.585,
      "step": 375680
    },
    {
      "epoch": 604.0,
      "eval_accuracy": {
        "accuracy": 0.4243955531369043
      },
      "eval_loss": 2.7191102504730225,
      "eval_runtime": 3.0227,
      "eval_samples_per_second": 4255.426,
      "eval_steps_per_second": 66.496,
      "step": 375688
    },
    {
      "epoch": 604.02,
      "learning_rate": 0.039623211502250816,
      "loss": 2.6106,
      "step": 375700
    },
    {
      "epoch": 604.05,
      "learning_rate": 0.03961999607138264,
      "loss": 2.6059,
      "step": 375720
    },
    {
      "epoch": 604.08,
      "learning_rate": 0.03961678064051447,
      "loss": 2.6049,
      "step": 375740
    },
    {
      "epoch": 604.12,
      "learning_rate": 0.039613565209646304,
      "loss": 2.6203,
      "step": 375760
    },
    {
      "epoch": 604.15,
      "learning_rate": 0.039610349778778135,
      "loss": 2.6031,
      "step": 375780
    },
    {
      "epoch": 604.18,
      "learning_rate": 0.03960713434790997,
      "loss": 2.5879,
      "step": 375800
    },
    {
      "epoch": 604.21,
      "learning_rate": 0.039603918917041805,
      "loss": 2.6125,
      "step": 375820
    },
    {
      "epoch": 604.24,
      "learning_rate": 0.03960070348617364,
      "loss": 2.6002,
      "step": 375840
    },
    {
      "epoch": 604.28,
      "learning_rate": 0.03959748805530547,
      "loss": 2.5942,
      "step": 375860
    },
    {
      "epoch": 604.31,
      "learning_rate": 0.0395942726244373,
      "loss": 2.5786,
      "step": 375880
    },
    {
      "epoch": 604.34,
      "learning_rate": 0.03959105719356913,
      "loss": 2.6137,
      "step": 375900
    },
    {
      "epoch": 604.37,
      "learning_rate": 0.03958784176270098,
      "loss": 2.5994,
      "step": 375920
    },
    {
      "epoch": 604.41,
      "learning_rate": 0.0395846263318328,
      "loss": 2.5891,
      "step": 375940
    },
    {
      "epoch": 604.44,
      "learning_rate": 0.039581410900964634,
      "loss": 2.5887,
      "step": 375960
    },
    {
      "epoch": 604.47,
      "learning_rate": 0.039578195470096465,
      "loss": 2.6091,
      "step": 375980
    },
    {
      "epoch": 604.5,
      "learning_rate": 0.0395749800392283,
      "loss": 2.5924,
      "step": 376000
    },
    {
      "epoch": 604.53,
      "learning_rate": 0.03957176460836013,
      "loss": 2.6122,
      "step": 376020
    },
    {
      "epoch": 604.57,
      "learning_rate": 0.03956854917749197,
      "loss": 2.6042,
      "step": 376040
    },
    {
      "epoch": 604.6,
      "learning_rate": 0.0395653337466238,
      "loss": 2.6214,
      "step": 376060
    },
    {
      "epoch": 604.63,
      "learning_rate": 0.03956211831575563,
      "loss": 2.6013,
      "step": 376080
    },
    {
      "epoch": 604.66,
      "learning_rate": 0.03955890288488746,
      "loss": 2.6075,
      "step": 376100
    },
    {
      "epoch": 604.69,
      "learning_rate": 0.039555687454019293,
      "loss": 2.6125,
      "step": 376120
    },
    {
      "epoch": 604.73,
      "learning_rate": 0.039552472023151125,
      "loss": 2.604,
      "step": 376140
    },
    {
      "epoch": 604.76,
      "learning_rate": 0.039549256592282964,
      "loss": 2.6238,
      "step": 376160
    },
    {
      "epoch": 604.79,
      "learning_rate": 0.039546041161414795,
      "loss": 2.6024,
      "step": 376180
    },
    {
      "epoch": 604.82,
      "learning_rate": 0.03954282573054663,
      "loss": 2.61,
      "step": 376200
    },
    {
      "epoch": 604.86,
      "learning_rate": 0.03953961029967846,
      "loss": 2.6026,
      "step": 376220
    },
    {
      "epoch": 604.89,
      "learning_rate": 0.03953639486881029,
      "loss": 2.6029,
      "step": 376240
    },
    {
      "epoch": 604.92,
      "learning_rate": 0.03953317943794213,
      "loss": 2.5794,
      "step": 376260
    },
    {
      "epoch": 604.95,
      "learning_rate": 0.03952996400707396,
      "loss": 2.5941,
      "step": 376280
    },
    {
      "epoch": 604.98,
      "learning_rate": 0.03952674857620579,
      "loss": 2.6091,
      "step": 376300
    },
    {
      "epoch": 605.0,
      "eval_accuracy": {
        "accuracy": 0.4234626447951489
      },
      "eval_loss": 2.720273971557617,
      "eval_runtime": 3.1519,
      "eval_samples_per_second": 4081.075,
      "eval_steps_per_second": 63.772,
      "step": 376310
    },
    {
      "epoch": 605.02,
      "learning_rate": 0.03952353314533762,
      "loss": 2.6044,
      "step": 376320
    },
    {
      "epoch": 605.05,
      "learning_rate": 0.039520317714469455,
      "loss": 2.6004,
      "step": 376340
    },
    {
      "epoch": 605.08,
      "learning_rate": 0.03951710228360129,
      "loss": 2.6082,
      "step": 376360
    },
    {
      "epoch": 605.11,
      "learning_rate": 0.039513886852733125,
      "loss": 2.5997,
      "step": 376380
    },
    {
      "epoch": 605.14,
      "learning_rate": 0.03951067142186496,
      "loss": 2.6001,
      "step": 376400
    },
    {
      "epoch": 605.18,
      "learning_rate": 0.03950745599099679,
      "loss": 2.5925,
      "step": 376420
    },
    {
      "epoch": 605.21,
      "learning_rate": 0.03950424056012862,
      "loss": 2.6247,
      "step": 376440
    },
    {
      "epoch": 605.24,
      "learning_rate": 0.03950102512926045,
      "loss": 2.6279,
      "step": 376460
    },
    {
      "epoch": 605.27,
      "learning_rate": 0.03949780969839228,
      "loss": 2.6131,
      "step": 376480
    },
    {
      "epoch": 605.31,
      "learning_rate": 0.03949459426752412,
      "loss": 2.6111,
      "step": 376500
    },
    {
      "epoch": 605.34,
      "learning_rate": 0.03949137883665595,
      "loss": 2.596,
      "step": 376520
    },
    {
      "epoch": 605.37,
      "learning_rate": 0.039488163405787785,
      "loss": 2.5906,
      "step": 376540
    },
    {
      "epoch": 605.4,
      "learning_rate": 0.03948494797491962,
      "loss": 2.5943,
      "step": 376560
    },
    {
      "epoch": 605.43,
      "learning_rate": 0.03948173254405145,
      "loss": 2.602,
      "step": 376580
    },
    {
      "epoch": 605.47,
      "learning_rate": 0.03947851711318329,
      "loss": 2.5959,
      "step": 376600
    },
    {
      "epoch": 605.5,
      "learning_rate": 0.03947530168231512,
      "loss": 2.6046,
      "step": 376620
    },
    {
      "epoch": 605.53,
      "learning_rate": 0.03947208625144695,
      "loss": 2.622,
      "step": 376640
    },
    {
      "epoch": 605.56,
      "learning_rate": 0.03946887082057878,
      "loss": 2.6044,
      "step": 376660
    },
    {
      "epoch": 605.59,
      "learning_rate": 0.03946565538971061,
      "loss": 2.5974,
      "step": 376680
    },
    {
      "epoch": 605.63,
      "learning_rate": 0.039462439958842445,
      "loss": 2.6176,
      "step": 376700
    },
    {
      "epoch": 605.66,
      "learning_rate": 0.03945922452797428,
      "loss": 2.595,
      "step": 376720
    },
    {
      "epoch": 605.69,
      "learning_rate": 0.039456009097106115,
      "loss": 2.6012,
      "step": 376740
    },
    {
      "epoch": 605.72,
      "learning_rate": 0.03945279366623795,
      "loss": 2.5756,
      "step": 376760
    },
    {
      "epoch": 605.76,
      "learning_rate": 0.03944957823536978,
      "loss": 2.5967,
      "step": 376780
    },
    {
      "epoch": 605.79,
      "learning_rate": 0.03944636280450161,
      "loss": 2.5942,
      "step": 376800
    },
    {
      "epoch": 605.82,
      "learning_rate": 0.03944314737363344,
      "loss": 2.6081,
      "step": 376820
    },
    {
      "epoch": 605.85,
      "learning_rate": 0.03943993194276528,
      "loss": 2.6341,
      "step": 376840
    },
    {
      "epoch": 605.88,
      "learning_rate": 0.03943671651189711,
      "loss": 2.5995,
      "step": 376860
    },
    {
      "epoch": 605.92,
      "learning_rate": 0.03943350108102894,
      "loss": 2.5658,
      "step": 376880
    },
    {
      "epoch": 605.95,
      "learning_rate": 0.039430285650160775,
      "loss": 2.604,
      "step": 376900
    },
    {
      "epoch": 605.98,
      "learning_rate": 0.039427070219292606,
      "loss": 2.6268,
      "step": 376920
    },
    {
      "epoch": 606.0,
      "eval_accuracy": {
        "accuracy": 0.41910907253362356
      },
      "eval_loss": 2.7256298065185547,
      "eval_runtime": 2.9734,
      "eval_samples_per_second": 4326.069,
      "eval_steps_per_second": 67.6,
      "step": 376932
    },
    {
      "epoch": 606.01,
      "learning_rate": 0.039423854788424445,
      "loss": 2.5907,
      "step": 376940
    },
    {
      "epoch": 606.05,
      "learning_rate": 0.03942063935755628,
      "loss": 2.5884,
      "step": 376960
    },
    {
      "epoch": 606.08,
      "learning_rate": 0.03941742392668811,
      "loss": 2.6313,
      "step": 376980
    },
    {
      "epoch": 606.11,
      "learning_rate": 0.03941420849581994,
      "loss": 2.6089,
      "step": 377000
    },
    {
      "epoch": 606.14,
      "learning_rate": 0.03941099306495177,
      "loss": 2.6026,
      "step": 377020
    },
    {
      "epoch": 606.17,
      "learning_rate": 0.0394077776340836,
      "loss": 2.602,
      "step": 377040
    },
    {
      "epoch": 606.21,
      "learning_rate": 0.03940456220321544,
      "loss": 2.6212,
      "step": 377060
    },
    {
      "epoch": 606.24,
      "learning_rate": 0.03940134677234727,
      "loss": 2.6489,
      "step": 377080
    },
    {
      "epoch": 606.27,
      "learning_rate": 0.039398131341479105,
      "loss": 2.6127,
      "step": 377100
    },
    {
      "epoch": 606.3,
      "learning_rate": 0.039394915910610936,
      "loss": 2.588,
      "step": 377120
    },
    {
      "epoch": 606.33,
      "learning_rate": 0.03939170047974277,
      "loss": 2.6196,
      "step": 377140
    },
    {
      "epoch": 606.37,
      "learning_rate": 0.0393884850488746,
      "loss": 2.5982,
      "step": 377160
    },
    {
      "epoch": 606.4,
      "learning_rate": 0.03938526961800644,
      "loss": 2.6061,
      "step": 377180
    },
    {
      "epoch": 606.43,
      "learning_rate": 0.03938205418713827,
      "loss": 2.6195,
      "step": 377200
    },
    {
      "epoch": 606.46,
      "learning_rate": 0.0393788387562701,
      "loss": 2.6066,
      "step": 377220
    },
    {
      "epoch": 606.5,
      "learning_rate": 0.03937562332540193,
      "loss": 2.5733,
      "step": 377240
    },
    {
      "epoch": 606.53,
      "learning_rate": 0.039372407894533765,
      "loss": 2.5898,
      "step": 377260
    },
    {
      "epoch": 606.56,
      "learning_rate": 0.0393691924636656,
      "loss": 2.6039,
      "step": 377280
    },
    {
      "epoch": 606.59,
      "learning_rate": 0.039365977032797435,
      "loss": 2.6178,
      "step": 377300
    },
    {
      "epoch": 606.62,
      "learning_rate": 0.039362761601929266,
      "loss": 2.5827,
      "step": 377320
    },
    {
      "epoch": 606.66,
      "learning_rate": 0.0393595461710611,
      "loss": 2.6119,
      "step": 377340
    },
    {
      "epoch": 606.69,
      "learning_rate": 0.03935633074019293,
      "loss": 2.5832,
      "step": 377360
    },
    {
      "epoch": 606.72,
      "learning_rate": 0.03935311530932476,
      "loss": 2.5946,
      "step": 377380
    },
    {
      "epoch": 606.75,
      "learning_rate": 0.0393498998784566,
      "loss": 2.5921,
      "step": 377400
    },
    {
      "epoch": 606.78,
      "learning_rate": 0.03934668444758843,
      "loss": 2.5874,
      "step": 377420
    },
    {
      "epoch": 606.82,
      "learning_rate": 0.03934346901672026,
      "loss": 2.6132,
      "step": 377440
    },
    {
      "epoch": 606.85,
      "learning_rate": 0.039340253585852095,
      "loss": 2.6042,
      "step": 377460
    },
    {
      "epoch": 606.88,
      "learning_rate": 0.039337038154983926,
      "loss": 2.595,
      "step": 377480
    },
    {
      "epoch": 606.91,
      "learning_rate": 0.03933382272411575,
      "loss": 2.5855,
      "step": 377500
    },
    {
      "epoch": 606.95,
      "learning_rate": 0.039330607293247596,
      "loss": 2.5781,
      "step": 377520
    },
    {
      "epoch": 606.98,
      "learning_rate": 0.03932739186237943,
      "loss": 2.5953,
      "step": 377540
    },
    {
      "epoch": 607.0,
      "eval_accuracy": {
        "accuracy": 0.4212858586643862
      },
      "eval_loss": 2.7254772186279297,
      "eval_runtime": 3.0409,
      "eval_samples_per_second": 4229.947,
      "eval_steps_per_second": 66.098,
      "step": 377554
    },
    {
      "epoch": 607.01,
      "learning_rate": 0.03932417643151126,
      "loss": 2.5991,
      "step": 377560
    },
    {
      "epoch": 607.04,
      "learning_rate": 0.03932096100064309,
      "loss": 2.6005,
      "step": 377580
    },
    {
      "epoch": 607.07,
      "learning_rate": 0.039317745569774916,
      "loss": 2.6219,
      "step": 377600
    },
    {
      "epoch": 607.11,
      "learning_rate": 0.03931453013890676,
      "loss": 2.5665,
      "step": 377620
    },
    {
      "epoch": 607.14,
      "learning_rate": 0.03931131470803859,
      "loss": 2.5951,
      "step": 377640
    },
    {
      "epoch": 607.17,
      "learning_rate": 0.039308099277170425,
      "loss": 2.5763,
      "step": 377660
    },
    {
      "epoch": 607.2,
      "learning_rate": 0.039304883846302256,
      "loss": 2.5944,
      "step": 377680
    },
    {
      "epoch": 607.23,
      "learning_rate": 0.03930166841543409,
      "loss": 2.5901,
      "step": 377700
    },
    {
      "epoch": 607.27,
      "learning_rate": 0.03929845298456591,
      "loss": 2.6004,
      "step": 377720
    },
    {
      "epoch": 607.3,
      "learning_rate": 0.03929523755369776,
      "loss": 2.6094,
      "step": 377740
    },
    {
      "epoch": 607.33,
      "learning_rate": 0.03929202212282959,
      "loss": 2.6033,
      "step": 377760
    },
    {
      "epoch": 607.36,
      "learning_rate": 0.03928880669196142,
      "loss": 2.5906,
      "step": 377780
    },
    {
      "epoch": 607.4,
      "learning_rate": 0.03928559126109325,
      "loss": 2.6148,
      "step": 377800
    },
    {
      "epoch": 607.43,
      "learning_rate": 0.03928237583022508,
      "loss": 2.5915,
      "step": 377820
    },
    {
      "epoch": 607.46,
      "learning_rate": 0.03927916039935692,
      "loss": 2.6272,
      "step": 377840
    },
    {
      "epoch": 607.49,
      "learning_rate": 0.039275944968488755,
      "loss": 2.6121,
      "step": 377860
    },
    {
      "epoch": 607.52,
      "learning_rate": 0.039272729537620586,
      "loss": 2.6157,
      "step": 377880
    },
    {
      "epoch": 607.56,
      "learning_rate": 0.03926951410675242,
      "loss": 2.6077,
      "step": 377900
    },
    {
      "epoch": 607.59,
      "learning_rate": 0.03926629867588424,
      "loss": 2.5821,
      "step": 377920
    },
    {
      "epoch": 607.62,
      "learning_rate": 0.039263244016559486,
      "loss": 2.6058,
      "step": 377940
    },
    {
      "epoch": 607.65,
      "learning_rate": 0.03926002858569132,
      "loss": 2.5926,
      "step": 377960
    },
    {
      "epoch": 607.68,
      "learning_rate": 0.03925681315482315,
      "loss": 2.604,
      "step": 377980
    },
    {
      "epoch": 607.72,
      "learning_rate": 0.039253597723954994,
      "loss": 2.6041,
      "step": 378000
    },
    {
      "epoch": 607.75,
      "learning_rate": 0.03925038229308682,
      "loss": 2.606,
      "step": 378020
    },
    {
      "epoch": 607.78,
      "learning_rate": 0.03924716686221865,
      "loss": 2.5997,
      "step": 378040
    },
    {
      "epoch": 607.81,
      "learning_rate": 0.03924395143135048,
      "loss": 2.6242,
      "step": 378060
    },
    {
      "epoch": 607.85,
      "learning_rate": 0.039240736000482314,
      "loss": 2.5902,
      "step": 378080
    },
    {
      "epoch": 607.88,
      "learning_rate": 0.03923752056961416,
      "loss": 2.6114,
      "step": 378100
    },
    {
      "epoch": 607.91,
      "learning_rate": 0.03923430513874599,
      "loss": 2.6048,
      "step": 378120
    },
    {
      "epoch": 607.94,
      "learning_rate": 0.039231089707877816,
      "loss": 2.6076,
      "step": 378140
    },
    {
      "epoch": 607.97,
      "learning_rate": 0.03922787427700965,
      "loss": 2.6052,
      "step": 378160
    },
    {
      "epoch": 608.0,
      "eval_accuracy": {
        "accuracy": 0.42493974966959497
      },
      "eval_loss": 2.7181851863861084,
      "eval_runtime": 2.9219,
      "eval_samples_per_second": 4402.318,
      "eval_steps_per_second": 68.792,
      "step": 378176
    },
    {
      "epoch": 608.01,
      "learning_rate": 0.03922465884614148,
      "loss": 2.6254,
      "step": 378180
    },
    {
      "epoch": 608.04,
      "learning_rate": 0.03922144341527331,
      "loss": 2.6166,
      "step": 378200
    },
    {
      "epoch": 608.07,
      "learning_rate": 0.039218227984405156,
      "loss": 2.5873,
      "step": 378220
    },
    {
      "epoch": 608.1,
      "learning_rate": 0.03921501255353698,
      "loss": 2.5833,
      "step": 378240
    },
    {
      "epoch": 608.14,
      "learning_rate": 0.03921179712266881,
      "loss": 2.5897,
      "step": 378260
    },
    {
      "epoch": 608.17,
      "learning_rate": 0.039208581691800644,
      "loss": 2.5994,
      "step": 378280
    },
    {
      "epoch": 608.2,
      "learning_rate": 0.039205366260932475,
      "loss": 2.5844,
      "step": 378300
    },
    {
      "epoch": 608.23,
      "learning_rate": 0.03920215083006431,
      "loss": 2.5965,
      "step": 378320
    },
    {
      "epoch": 608.26,
      "learning_rate": 0.039198935399196146,
      "loss": 2.6011,
      "step": 378340
    },
    {
      "epoch": 608.3,
      "learning_rate": 0.03919571996832798,
      "loss": 2.6175,
      "step": 378360
    },
    {
      "epoch": 608.33,
      "learning_rate": 0.03919250453745981,
      "loss": 2.6198,
      "step": 378380
    },
    {
      "epoch": 608.36,
      "learning_rate": 0.03918928910659164,
      "loss": 2.5905,
      "step": 378400
    },
    {
      "epoch": 608.39,
      "learning_rate": 0.03918607367572347,
      "loss": 2.6078,
      "step": 378420
    },
    {
      "epoch": 608.42,
      "learning_rate": 0.03918285824485532,
      "loss": 2.6097,
      "step": 378440
    },
    {
      "epoch": 608.46,
      "learning_rate": 0.03917964281398714,
      "loss": 2.6101,
      "step": 378460
    },
    {
      "epoch": 608.49,
      "learning_rate": 0.039176427383118974,
      "loss": 2.5775,
      "step": 378480
    },
    {
      "epoch": 608.52,
      "learning_rate": 0.039173211952250805,
      "loss": 2.6124,
      "step": 378500
    },
    {
      "epoch": 608.55,
      "learning_rate": 0.03916999652138264,
      "loss": 2.613,
      "step": 378520
    },
    {
      "epoch": 608.59,
      "learning_rate": 0.03916678109051447,
      "loss": 2.6059,
      "step": 378540
    },
    {
      "epoch": 608.62,
      "learning_rate": 0.03916356565964631,
      "loss": 2.5998,
      "step": 378560
    },
    {
      "epoch": 608.65,
      "learning_rate": 0.03916035022877814,
      "loss": 2.6237,
      "step": 378580
    },
    {
      "epoch": 608.68,
      "learning_rate": 0.03915713479790997,
      "loss": 2.6015,
      "step": 378600
    },
    {
      "epoch": 608.71,
      "learning_rate": 0.0391539193670418,
      "loss": 2.5903,
      "step": 378620
    },
    {
      "epoch": 608.75,
      "learning_rate": 0.039150703936173634,
      "loss": 2.6115,
      "step": 378640
    },
    {
      "epoch": 608.78,
      "learning_rate": 0.03914748850530547,
      "loss": 2.5958,
      "step": 378660
    },
    {
      "epoch": 608.81,
      "learning_rate": 0.039144273074437304,
      "loss": 2.5829,
      "step": 378680
    },
    {
      "epoch": 608.84,
      "learning_rate": 0.039141057643569135,
      "loss": 2.5824,
      "step": 378700
    },
    {
      "epoch": 608.87,
      "learning_rate": 0.03913784221270097,
      "loss": 2.6082,
      "step": 378720
    },
    {
      "epoch": 608.91,
      "learning_rate": 0.0391346267818328,
      "loss": 2.6234,
      "step": 378740
    },
    {
      "epoch": 608.94,
      "learning_rate": 0.03913141135096463,
      "loss": 2.6085,
      "step": 378760
    },
    {
      "epoch": 608.97,
      "learning_rate": 0.03912819592009647,
      "loss": 2.6099,
      "step": 378780
    },
    {
      "epoch": 609.0,
      "eval_accuracy": {
        "accuracy": 0.42711653580035763
      },
      "eval_loss": 2.7168021202087402,
      "eval_runtime": 2.9663,
      "eval_samples_per_second": 4336.378,
      "eval_steps_per_second": 67.761,
      "step": 378798
    },
    {
      "epoch": 609.0,
      "learning_rate": 0.0391249804892283,
      "loss": 2.5899,
      "step": 378800
    },
    {
      "epoch": 609.04,
      "learning_rate": 0.03912176505836013,
      "loss": 2.5897,
      "step": 378820
    },
    {
      "epoch": 609.07,
      "learning_rate": 0.039118549627491964,
      "loss": 2.5763,
      "step": 378840
    },
    {
      "epoch": 609.1,
      "learning_rate": 0.039115334196623795,
      "loss": 2.6063,
      "step": 378860
    },
    {
      "epoch": 609.13,
      "learning_rate": 0.03911211876575563,
      "loss": 2.576,
      "step": 378880
    },
    {
      "epoch": 609.16,
      "learning_rate": 0.039108903334887465,
      "loss": 2.6001,
      "step": 378900
    },
    {
      "epoch": 609.2,
      "learning_rate": 0.0391056879040193,
      "loss": 2.6179,
      "step": 378920
    },
    {
      "epoch": 609.23,
      "learning_rate": 0.03910247247315113,
      "loss": 2.6064,
      "step": 378940
    },
    {
      "epoch": 609.26,
      "learning_rate": 0.03909925704228296,
      "loss": 2.5937,
      "step": 378960
    },
    {
      "epoch": 609.29,
      "learning_rate": 0.03909604161141479,
      "loss": 2.6194,
      "step": 378980
    },
    {
      "epoch": 609.32,
      "learning_rate": 0.03909282618054663,
      "loss": 2.595,
      "step": 379000
    },
    {
      "epoch": 609.36,
      "learning_rate": 0.03908961074967846,
      "loss": 2.6027,
      "step": 379020
    },
    {
      "epoch": 609.39,
      "learning_rate": 0.039086395318810294,
      "loss": 2.5998,
      "step": 379040
    },
    {
      "epoch": 609.42,
      "learning_rate": 0.039083179887942125,
      "loss": 2.6008,
      "step": 379060
    },
    {
      "epoch": 609.45,
      "learning_rate": 0.03907996445707396,
      "loss": 2.6074,
      "step": 379080
    },
    {
      "epoch": 609.49,
      "learning_rate": 0.03907674902620579,
      "loss": 2.5839,
      "step": 379100
    },
    {
      "epoch": 609.52,
      "learning_rate": 0.03907353359533763,
      "loss": 2.6233,
      "step": 379120
    },
    {
      "epoch": 609.55,
      "learning_rate": 0.03907031816446946,
      "loss": 2.6148,
      "step": 379140
    },
    {
      "epoch": 609.58,
      "learning_rate": 0.03906710273360129,
      "loss": 2.5821,
      "step": 379160
    },
    {
      "epoch": 609.61,
      "learning_rate": 0.03906388730273312,
      "loss": 2.5976,
      "step": 379180
    },
    {
      "epoch": 609.65,
      "learning_rate": 0.03906067187186495,
      "loss": 2.5961,
      "step": 379200
    },
    {
      "epoch": 609.68,
      "learning_rate": 0.039057456440996785,
      "loss": 2.6058,
      "step": 379220
    },
    {
      "epoch": 609.71,
      "learning_rate": 0.039054241010128624,
      "loss": 2.5699,
      "step": 379240
    },
    {
      "epoch": 609.74,
      "learning_rate": 0.039051025579260455,
      "loss": 2.6007,
      "step": 379260
    },
    {
      "epoch": 609.77,
      "learning_rate": 0.03904781014839229,
      "loss": 2.6001,
      "step": 379280
    },
    {
      "epoch": 609.81,
      "learning_rate": 0.03904459471752412,
      "loss": 2.5926,
      "step": 379300
    },
    {
      "epoch": 609.84,
      "learning_rate": 0.03904137928665595,
      "loss": 2.5952,
      "step": 379320
    },
    {
      "epoch": 609.87,
      "learning_rate": 0.03903816385578779,
      "loss": 2.5751,
      "step": 379340
    },
    {
      "epoch": 609.9,
      "learning_rate": 0.03903494842491962,
      "loss": 2.6087,
      "step": 379360
    },
    {
      "epoch": 609.94,
      "learning_rate": 0.03903173299405145,
      "loss": 2.5641,
      "step": 379380
    },
    {
      "epoch": 609.97,
      "learning_rate": 0.03902851756318328,
      "loss": 2.6014,
      "step": 379400
    },
    {
      "epoch": 610.0,
      "learning_rate": 0.039025302132315115,
      "loss": 2.6109,
      "step": 379420
    },
    {
      "epoch": 610.0,
      "eval_accuracy": {
        "accuracy": 0.42867138303661667
      },
      "eval_loss": 2.7154951095581055,
      "eval_runtime": 3.156,
      "eval_samples_per_second": 4075.695,
      "eval_steps_per_second": 63.688,
      "step": 379420
    },
    {
      "epoch": 610.03,
      "learning_rate": 0.03902208670144695,
      "loss": 2.5964,
      "step": 379440
    },
    {
      "epoch": 610.06,
      "learning_rate": 0.039018871270578785,
      "loss": 2.5918,
      "step": 379460
    },
    {
      "epoch": 610.1,
      "learning_rate": 0.03901565583971062,
      "loss": 2.6144,
      "step": 379480
    },
    {
      "epoch": 610.13,
      "learning_rate": 0.03901244040884245,
      "loss": 2.5938,
      "step": 379500
    },
    {
      "epoch": 610.16,
      "learning_rate": 0.03900922497797428,
      "loss": 2.574,
      "step": 379520
    },
    {
      "epoch": 610.19,
      "learning_rate": 0.03900600954710611,
      "loss": 2.5803,
      "step": 379540
    },
    {
      "epoch": 610.23,
      "learning_rate": 0.03900279411623794,
      "loss": 2.6044,
      "step": 379560
    },
    {
      "epoch": 610.26,
      "learning_rate": 0.03899957868536978,
      "loss": 2.5968,
      "step": 379580
    },
    {
      "epoch": 610.29,
      "learning_rate": 0.03899636325450161,
      "loss": 2.6133,
      "step": 379600
    },
    {
      "epoch": 610.32,
      "learning_rate": 0.038993147823633445,
      "loss": 2.595,
      "step": 379620
    },
    {
      "epoch": 610.35,
      "learning_rate": 0.03898993239276528,
      "loss": 2.572,
      "step": 379640
    },
    {
      "epoch": 610.39,
      "learning_rate": 0.03898671696189711,
      "loss": 2.6036,
      "step": 379660
    },
    {
      "epoch": 610.42,
      "learning_rate": 0.03898350153102895,
      "loss": 2.6033,
      "step": 379680
    },
    {
      "epoch": 610.45,
      "learning_rate": 0.03898028610016078,
      "loss": 2.594,
      "step": 379700
    },
    {
      "epoch": 610.48,
      "learning_rate": 0.03897707066929261,
      "loss": 2.5899,
      "step": 379720
    },
    {
      "epoch": 610.51,
      "learning_rate": 0.03897385523842444,
      "loss": 2.5967,
      "step": 379740
    },
    {
      "epoch": 610.55,
      "learning_rate": 0.03897063980755627,
      "loss": 2.6085,
      "step": 379760
    },
    {
      "epoch": 610.58,
      "learning_rate": 0.038967424376688105,
      "loss": 2.5808,
      "step": 379780
    },
    {
      "epoch": 610.61,
      "learning_rate": 0.03896420894581994,
      "loss": 2.5917,
      "step": 379800
    },
    {
      "epoch": 610.64,
      "learning_rate": 0.038960993514951775,
      "loss": 2.624,
      "step": 379820
    },
    {
      "epoch": 610.68,
      "learning_rate": 0.03895777808408361,
      "loss": 2.5798,
      "step": 379840
    },
    {
      "epoch": 610.71,
      "learning_rate": 0.03895456265321544,
      "loss": 2.5972,
      "step": 379860
    },
    {
      "epoch": 610.74,
      "learning_rate": 0.03895134722234727,
      "loss": 2.5841,
      "step": 379880
    },
    {
      "epoch": 610.77,
      "learning_rate": 0.0389481317914791,
      "loss": 2.58,
      "step": 379900
    },
    {
      "epoch": 610.8,
      "learning_rate": 0.03894491636061094,
      "loss": 2.6187,
      "step": 379920
    },
    {
      "epoch": 610.84,
      "learning_rate": 0.03894170092974277,
      "loss": 2.6099,
      "step": 379940
    },
    {
      "epoch": 610.87,
      "learning_rate": 0.0389384854988746,
      "loss": 2.6095,
      "step": 379960
    },
    {
      "epoch": 610.9,
      "learning_rate": 0.038935270068006435,
      "loss": 2.587,
      "step": 379980
    },
    {
      "epoch": 610.93,
      "learning_rate": 0.038932054637138266,
      "loss": 2.593,
      "step": 380000
    },
    {
      "epoch": 610.96,
      "learning_rate": 0.038928839206270105,
      "loss": 2.5658,
      "step": 380020
    },
    {
      "epoch": 611.0,
      "learning_rate": 0.03892562377540194,
      "loss": 2.5831,
      "step": 380040
    },
    {
      "epoch": 611.0,
      "eval_accuracy": {
        "accuracy": 0.4302262302728757
      },
      "eval_loss": 2.6745896339416504,
      "eval_runtime": 3.1926,
      "eval_samples_per_second": 4029.02,
      "eval_steps_per_second": 62.958,
      "step": 380042
    },
    {
      "epoch": 611.03,
      "learning_rate": 0.03892240834453377,
      "loss": 2.6038,
      "step": 380060
    },
    {
      "epoch": 611.06,
      "learning_rate": 0.0389191929136656,
      "loss": 2.6051,
      "step": 380080
    },
    {
      "epoch": 611.09,
      "learning_rate": 0.03891597748279743,
      "loss": 2.5858,
      "step": 380100
    },
    {
      "epoch": 611.13,
      "learning_rate": 0.038912762051929256,
      "loss": 2.592,
      "step": 380120
    },
    {
      "epoch": 611.16,
      "learning_rate": 0.0389095466210611,
      "loss": 2.6102,
      "step": 380140
    },
    {
      "epoch": 611.19,
      "learning_rate": 0.03890633119019293,
      "loss": 2.5853,
      "step": 380160
    },
    {
      "epoch": 611.22,
      "learning_rate": 0.038903115759324765,
      "loss": 2.5891,
      "step": 380180
    },
    {
      "epoch": 611.25,
      "learning_rate": 0.038899900328456596,
      "loss": 2.5765,
      "step": 380200
    },
    {
      "epoch": 611.29,
      "learning_rate": 0.03889668489758843,
      "loss": 2.5997,
      "step": 380220
    },
    {
      "epoch": 611.32,
      "learning_rate": 0.03889346946672027,
      "loss": 2.621,
      "step": 380240
    },
    {
      "epoch": 611.35,
      "learning_rate": 0.0388902540358521,
      "loss": 2.595,
      "step": 380260
    },
    {
      "epoch": 611.38,
      "learning_rate": 0.03888703860498393,
      "loss": 2.6065,
      "step": 380280
    },
    {
      "epoch": 611.41,
      "learning_rate": 0.03888382317411576,
      "loss": 2.5815,
      "step": 380300
    },
    {
      "epoch": 611.45,
      "learning_rate": 0.03888060774324759,
      "loss": 2.568,
      "step": 380320
    },
    {
      "epoch": 611.48,
      "learning_rate": 0.03887739231237942,
      "loss": 2.6102,
      "step": 380340
    },
    {
      "epoch": 611.51,
      "learning_rate": 0.03887417688151126,
      "loss": 2.5986,
      "step": 380360
    },
    {
      "epoch": 611.54,
      "learning_rate": 0.038870961450643095,
      "loss": 2.5973,
      "step": 380380
    },
    {
      "epoch": 611.58,
      "learning_rate": 0.038867746019774926,
      "loss": 2.6114,
      "step": 380400
    },
    {
      "epoch": 611.61,
      "learning_rate": 0.03886453058890676,
      "loss": 2.5874,
      "step": 380420
    },
    {
      "epoch": 611.64,
      "learning_rate": 0.03886131515803858,
      "loss": 2.6066,
      "step": 380440
    },
    {
      "epoch": 611.67,
      "learning_rate": 0.038858099727170414,
      "loss": 2.6034,
      "step": 380460
    },
    {
      "epoch": 611.7,
      "learning_rate": 0.03885488429630226,
      "loss": 2.5857,
      "step": 380480
    },
    {
      "epoch": 611.74,
      "learning_rate": 0.03885166886543409,
      "loss": 2.5789,
      "step": 380500
    },
    {
      "epoch": 611.77,
      "learning_rate": 0.03884845343456592,
      "loss": 2.6077,
      "step": 380520
    },
    {
      "epoch": 611.8,
      "learning_rate": 0.038845238003697755,
      "loss": 2.6058,
      "step": 380540
    },
    {
      "epoch": 611.83,
      "learning_rate": 0.03884202257282958,
      "loss": 2.6081,
      "step": 380560
    },
    {
      "epoch": 611.86,
      "learning_rate": 0.038838807141961425,
      "loss": 2.6336,
      "step": 380580
    },
    {
      "epoch": 611.9,
      "learning_rate": 0.038835591711093256,
      "loss": 2.6125,
      "step": 380600
    },
    {
      "epoch": 611.93,
      "learning_rate": 0.03883237628022509,
      "loss": 2.5763,
      "step": 380620
    },
    {
      "epoch": 611.96,
      "learning_rate": 0.03882916084935692,
      "loss": 2.5936,
      "step": 380640
    },
    {
      "epoch": 611.99,
      "learning_rate": 0.038825945418488744,
      "loss": 2.5972,
      "step": 380660
    },
    {
      "epoch": 612.0,
      "eval_accuracy": {
        "accuracy": 0.42493974966959497
      },
      "eval_loss": 2.703871726989746,
      "eval_runtime": 3.7029,
      "eval_samples_per_second": 3473.722,
      "eval_steps_per_second": 54.281,
      "step": 380664
    },
    {
      "epoch": 612.03,
      "learning_rate": 0.038822729987620576,
      "loss": 2.5594,
      "step": 380680
    },
    {
      "epoch": 612.06,
      "learning_rate": 0.03881951455675242,
      "loss": 2.5878,
      "step": 380700
    },
    {
      "epoch": 612.09,
      "learning_rate": 0.03881629912588425,
      "loss": 2.6038,
      "step": 380720
    },
    {
      "epoch": 612.12,
      "learning_rate": 0.038813083695016085,
      "loss": 2.5773,
      "step": 380740
    },
    {
      "epoch": 612.15,
      "learning_rate": 0.03880986826414791,
      "loss": 2.587,
      "step": 380760
    },
    {
      "epoch": 612.19,
      "learning_rate": 0.03880665283327974,
      "loss": 2.6063,
      "step": 380780
    },
    {
      "epoch": 612.22,
      "learning_rate": 0.03880343740241157,
      "loss": 2.6033,
      "step": 380800
    },
    {
      "epoch": 612.25,
      "learning_rate": 0.03880022197154342,
      "loss": 2.5855,
      "step": 380820
    },
    {
      "epoch": 612.28,
      "learning_rate": 0.03879700654067525,
      "loss": 2.6178,
      "step": 380840
    },
    {
      "epoch": 612.32,
      "learning_rate": 0.03879379110980708,
      "loss": 2.5889,
      "step": 380860
    },
    {
      "epoch": 612.35,
      "learning_rate": 0.038790575678938906,
      "loss": 2.5995,
      "step": 380880
    },
    {
      "epoch": 612.38,
      "learning_rate": 0.03878736024807074,
      "loss": 2.6036,
      "step": 380900
    },
    {
      "epoch": 612.41,
      "learning_rate": 0.03878414481720258,
      "loss": 2.5963,
      "step": 380920
    },
    {
      "epoch": 612.44,
      "learning_rate": 0.038780929386334415,
      "loss": 2.5955,
      "step": 380940
    },
    {
      "epoch": 612.48,
      "learning_rate": 0.038777713955466246,
      "loss": 2.5813,
      "step": 380960
    },
    {
      "epoch": 612.51,
      "learning_rate": 0.03877449852459807,
      "loss": 2.6006,
      "step": 380980
    },
    {
      "epoch": 612.54,
      "learning_rate": 0.0387712830937299,
      "loss": 2.6004,
      "step": 381000
    },
    {
      "epoch": 612.57,
      "learning_rate": 0.038768067662861734,
      "loss": 2.5964,
      "step": 381020
    },
    {
      "epoch": 612.6,
      "learning_rate": 0.03876485223199358,
      "loss": 2.5952,
      "step": 381040
    },
    {
      "epoch": 612.64,
      "learning_rate": 0.03876163680112541,
      "loss": 2.6149,
      "step": 381060
    },
    {
      "epoch": 612.67,
      "learning_rate": 0.03875842137025724,
      "loss": 2.5876,
      "step": 381080
    },
    {
      "epoch": 612.7,
      "learning_rate": 0.03875520593938907,
      "loss": 2.601,
      "step": 381100
    },
    {
      "epoch": 612.73,
      "learning_rate": 0.0387519905085209,
      "loss": 2.5773,
      "step": 381120
    },
    {
      "epoch": 612.77,
      "learning_rate": 0.03874877507765273,
      "loss": 2.5878,
      "step": 381140
    },
    {
      "epoch": 612.8,
      "learning_rate": 0.038745559646784576,
      "loss": 2.5907,
      "step": 381160
    },
    {
      "epoch": 612.83,
      "learning_rate": 0.03874234421591641,
      "loss": 2.5612,
      "step": 381180
    },
    {
      "epoch": 612.86,
      "learning_rate": 0.03873912878504823,
      "loss": 2.5967,
      "step": 381200
    },
    {
      "epoch": 612.89,
      "learning_rate": 0.038735913354180064,
      "loss": 2.5935,
      "step": 381220
    },
    {
      "epoch": 612.93,
      "learning_rate": 0.038732697923311896,
      "loss": 2.6124,
      "step": 381240
    },
    {
      "epoch": 612.96,
      "learning_rate": 0.03872948249244374,
      "loss": 2.6067,
      "step": 381260
    },
    {
      "epoch": 612.99,
      "learning_rate": 0.03872626706157557,
      "loss": 2.6127,
      "step": 381280
    },
    {
      "epoch": 613.0,
      "eval_accuracy": {
        "accuracy": 0.41895358780999764
      },
      "eval_loss": 2.739431858062744,
      "eval_runtime": 3.3958,
      "eval_samples_per_second": 3787.928,
      "eval_steps_per_second": 59.191,
      "step": 381286
    },
    {
      "epoch": 613.02,
      "learning_rate": 0.0387230516307074,
      "loss": 2.6082,
      "step": 381300
    },
    {
      "epoch": 613.05,
      "learning_rate": 0.03871983619983923,
      "loss": 2.591,
      "step": 381320
    },
    {
      "epoch": 613.09,
      "learning_rate": 0.03871662076897106,
      "loss": 2.5823,
      "step": 381340
    },
    {
      "epoch": 613.12,
      "learning_rate": 0.03871340533810289,
      "loss": 2.6085,
      "step": 381360
    },
    {
      "epoch": 613.15,
      "learning_rate": 0.03871018990723474,
      "loss": 2.6213,
      "step": 381380
    },
    {
      "epoch": 613.18,
      "learning_rate": 0.03870697447636657,
      "loss": 2.6077,
      "step": 381400
    },
    {
      "epoch": 613.22,
      "learning_rate": 0.038703759045498394,
      "loss": 2.5971,
      "step": 381420
    },
    {
      "epoch": 613.25,
      "learning_rate": 0.038700543614630226,
      "loss": 2.5833,
      "step": 381440
    },
    {
      "epoch": 613.28,
      "learning_rate": 0.03869732818376206,
      "loss": 2.5849,
      "step": 381460
    },
    {
      "epoch": 613.31,
      "learning_rate": 0.03869411275289389,
      "loss": 2.5831,
      "step": 381480
    },
    {
      "epoch": 613.34,
      "learning_rate": 0.038690897322025734,
      "loss": 2.5775,
      "step": 381500
    },
    {
      "epoch": 613.38,
      "learning_rate": 0.03868768189115756,
      "loss": 2.5955,
      "step": 381520
    },
    {
      "epoch": 613.41,
      "learning_rate": 0.03868446646028939,
      "loss": 2.5726,
      "step": 381540
    },
    {
      "epoch": 613.44,
      "learning_rate": 0.03868125102942122,
      "loss": 2.6144,
      "step": 381560
    },
    {
      "epoch": 613.47,
      "learning_rate": 0.038678035598553054,
      "loss": 2.6012,
      "step": 381580
    },
    {
      "epoch": 613.5,
      "learning_rate": 0.0386748201676849,
      "loss": 2.6257,
      "step": 381600
    },
    {
      "epoch": 613.54,
      "learning_rate": 0.038671604736816724,
      "loss": 2.5769,
      "step": 381620
    },
    {
      "epoch": 613.57,
      "learning_rate": 0.038668389305948556,
      "loss": 2.5861,
      "step": 381640
    },
    {
      "epoch": 613.6,
      "learning_rate": 0.03866517387508039,
      "loss": 2.6035,
      "step": 381660
    },
    {
      "epoch": 613.63,
      "learning_rate": 0.03866195844421222,
      "loss": 2.6185,
      "step": 381680
    },
    {
      "epoch": 613.67,
      "learning_rate": 0.03865874301334405,
      "loss": 2.6076,
      "step": 381700
    },
    {
      "epoch": 613.7,
      "learning_rate": 0.038655527582475896,
      "loss": 2.5996,
      "step": 381720
    },
    {
      "epoch": 613.73,
      "learning_rate": 0.03865231215160772,
      "loss": 2.5776,
      "step": 381740
    },
    {
      "epoch": 613.76,
      "learning_rate": 0.03864909672073955,
      "loss": 2.5973,
      "step": 381760
    },
    {
      "epoch": 613.79,
      "learning_rate": 0.038645881289871384,
      "loss": 2.6022,
      "step": 381780
    },
    {
      "epoch": 613.83,
      "learning_rate": 0.038642665859003215,
      "loss": 2.6034,
      "step": 381800
    },
    {
      "epoch": 613.86,
      "learning_rate": 0.03863945042813505,
      "loss": 2.586,
      "step": 381820
    },
    {
      "epoch": 613.89,
      "learning_rate": 0.03863639576881029,
      "loss": 2.6018,
      "step": 381840
    },
    {
      "epoch": 613.92,
      "learning_rate": 0.03863318033794213,
      "loss": 2.5838,
      "step": 381860
    },
    {
      "epoch": 613.95,
      "learning_rate": 0.03862996490707396,
      "loss": 2.5821,
      "step": 381880
    },
    {
      "epoch": 613.99,
      "learning_rate": 0.03862674947620579,
      "loss": 2.5887,
      "step": 381900
    },
    {
      "epoch": 614.0,
      "eval_accuracy": {
        "accuracy": 0.4277384746948612
      },
      "eval_loss": 2.6863229274749756,
      "eval_runtime": 3.0353,
      "eval_samples_per_second": 4237.809,
      "eval_steps_per_second": 66.221,
      "step": 381908
    },
    {
      "epoch": 614.02,
      "learning_rate": 0.038623534045337624,
      "loss": 2.5872,
      "step": 381920
    },
    {
      "epoch": 614.05,
      "learning_rate": 0.038620318614469455,
      "loss": 2.6226,
      "step": 381940
    },
    {
      "epoch": 614.08,
      "learning_rate": 0.03861710318360129,
      "loss": 2.5729,
      "step": 381960
    },
    {
      "epoch": 614.12,
      "learning_rate": 0.038613887752733125,
      "loss": 2.5935,
      "step": 381980
    },
    {
      "epoch": 614.15,
      "learning_rate": 0.03861067232186496,
      "loss": 2.5662,
      "step": 382000
    },
    {
      "epoch": 614.18,
      "learning_rate": 0.03860745689099679,
      "loss": 2.6041,
      "step": 382020
    },
    {
      "epoch": 614.21,
      "learning_rate": 0.03860424146012862,
      "loss": 2.5988,
      "step": 382040
    },
    {
      "epoch": 614.24,
      "learning_rate": 0.03860102602926045,
      "loss": 2.6168,
      "step": 382060
    },
    {
      "epoch": 614.28,
      "learning_rate": 0.03859781059839229,
      "loss": 2.589,
      "step": 382080
    },
    {
      "epoch": 614.31,
      "learning_rate": 0.03859459516752412,
      "loss": 2.585,
      "step": 382100
    },
    {
      "epoch": 614.34,
      "learning_rate": 0.038591379736655954,
      "loss": 2.5893,
      "step": 382120
    },
    {
      "epoch": 614.37,
      "learning_rate": 0.038588164305787785,
      "loss": 2.6057,
      "step": 382140
    },
    {
      "epoch": 614.41,
      "learning_rate": 0.03858494887491962,
      "loss": 2.6145,
      "step": 382160
    },
    {
      "epoch": 614.44,
      "learning_rate": 0.03858173344405145,
      "loss": 2.5874,
      "step": 382180
    },
    {
      "epoch": 614.47,
      "learning_rate": 0.03857851801318329,
      "loss": 2.6142,
      "step": 382200
    },
    {
      "epoch": 614.5,
      "learning_rate": 0.03857530258231512,
      "loss": 2.6127,
      "step": 382220
    },
    {
      "epoch": 614.53,
      "learning_rate": 0.03857208715144695,
      "loss": 2.6228,
      "step": 382240
    },
    {
      "epoch": 614.57,
      "learning_rate": 0.03856887172057878,
      "loss": 2.5659,
      "step": 382260
    },
    {
      "epoch": 614.6,
      "learning_rate": 0.03856565628971061,
      "loss": 2.576,
      "step": 382280
    },
    {
      "epoch": 614.63,
      "learning_rate": 0.038562440858842445,
      "loss": 2.5906,
      "step": 382300
    },
    {
      "epoch": 614.66,
      "learning_rate": 0.038559225427974284,
      "loss": 2.5912,
      "step": 382320
    },
    {
      "epoch": 614.69,
      "learning_rate": 0.038556009997106115,
      "loss": 2.5888,
      "step": 382340
    },
    {
      "epoch": 614.73,
      "learning_rate": 0.03855279456623795,
      "loss": 2.5905,
      "step": 382360
    },
    {
      "epoch": 614.76,
      "learning_rate": 0.03854957913536978,
      "loss": 2.5987,
      "step": 382380
    },
    {
      "epoch": 614.79,
      "learning_rate": 0.03854636370450161,
      "loss": 2.6016,
      "step": 382400
    },
    {
      "epoch": 614.82,
      "learning_rate": 0.03854314827363345,
      "loss": 2.5877,
      "step": 382420
    },
    {
      "epoch": 614.86,
      "learning_rate": 0.03853993284276528,
      "loss": 2.6051,
      "step": 382440
    },
    {
      "epoch": 614.89,
      "learning_rate": 0.03853671741189711,
      "loss": 2.588,
      "step": 382460
    },
    {
      "epoch": 614.92,
      "learning_rate": 0.03853350198102894,
      "loss": 2.5822,
      "step": 382480
    },
    {
      "epoch": 614.95,
      "learning_rate": 0.038530286550160775,
      "loss": 2.585,
      "step": 382500
    },
    {
      "epoch": 614.98,
      "learning_rate": 0.03852707111929261,
      "loss": 2.6158,
      "step": 382520
    },
    {
      "epoch": 615.0,
      "eval_accuracy": {
        "accuracy": 0.4290600948456814
      },
      "eval_loss": 2.7056326866149902,
      "eval_runtime": 3.0515,
      "eval_samples_per_second": 4215.353,
      "eval_steps_per_second": 65.87,
      "step": 382530
    },
    {
      "epoch": 615.02,
      "learning_rate": 0.038523855688424445,
      "loss": 2.5736,
      "step": 382540
    },
    {
      "epoch": 615.05,
      "learning_rate": 0.03852064025755628,
      "loss": 2.6129,
      "step": 382560
    },
    {
      "epoch": 615.08,
      "learning_rate": 0.03851742482668811,
      "loss": 2.5993,
      "step": 382580
    },
    {
      "epoch": 615.11,
      "learning_rate": 0.03851420939581994,
      "loss": 2.5978,
      "step": 382600
    },
    {
      "epoch": 615.14,
      "learning_rate": 0.03851099396495177,
      "loss": 2.6117,
      "step": 382620
    },
    {
      "epoch": 615.18,
      "learning_rate": 0.038507778534083596,
      "loss": 2.5753,
      "step": 382640
    },
    {
      "epoch": 615.21,
      "learning_rate": 0.03850456310321544,
      "loss": 2.6118,
      "step": 382660
    },
    {
      "epoch": 615.24,
      "learning_rate": 0.03850134767234727,
      "loss": 2.5794,
      "step": 382680
    },
    {
      "epoch": 615.27,
      "learning_rate": 0.038498132241479105,
      "loss": 2.6029,
      "step": 382700
    },
    {
      "epoch": 615.31,
      "learning_rate": 0.03849491681061094,
      "loss": 2.586,
      "step": 382720
    },
    {
      "epoch": 615.34,
      "learning_rate": 0.03849170137974277,
      "loss": 2.5894,
      "step": 382740
    },
    {
      "epoch": 615.37,
      "learning_rate": 0.03848848594887461,
      "loss": 2.6046,
      "step": 382760
    },
    {
      "epoch": 615.4,
      "learning_rate": 0.03848527051800644,
      "loss": 2.6061,
      "step": 382780
    },
    {
      "epoch": 615.43,
      "learning_rate": 0.03848205508713827,
      "loss": 2.5873,
      "step": 382800
    },
    {
      "epoch": 615.47,
      "learning_rate": 0.0384788396562701,
      "loss": 2.5803,
      "step": 382820
    },
    {
      "epoch": 615.5,
      "learning_rate": 0.03847562422540193,
      "loss": 2.5783,
      "step": 382840
    },
    {
      "epoch": 615.53,
      "learning_rate": 0.03847240879453376,
      "loss": 2.5749,
      "step": 382860
    },
    {
      "epoch": 615.56,
      "learning_rate": 0.0384691933636656,
      "loss": 2.5837,
      "step": 382880
    },
    {
      "epoch": 615.59,
      "learning_rate": 0.038465977932797435,
      "loss": 2.5951,
      "step": 382900
    },
    {
      "epoch": 615.63,
      "learning_rate": 0.03846276250192927,
      "loss": 2.6125,
      "step": 382920
    },
    {
      "epoch": 615.66,
      "learning_rate": 0.0384595470710611,
      "loss": 2.5839,
      "step": 382940
    },
    {
      "epoch": 615.69,
      "learning_rate": 0.03845633164019293,
      "loss": 2.5969,
      "step": 382960
    },
    {
      "epoch": 615.72,
      "learning_rate": 0.03845311620932477,
      "loss": 2.6039,
      "step": 382980
    },
    {
      "epoch": 615.76,
      "learning_rate": 0.0384499007784566,
      "loss": 2.5928,
      "step": 383000
    },
    {
      "epoch": 615.79,
      "learning_rate": 0.03844668534758843,
      "loss": 2.594,
      "step": 383020
    },
    {
      "epoch": 615.82,
      "learning_rate": 0.03844346991672026,
      "loss": 2.615,
      "step": 383040
    },
    {
      "epoch": 615.85,
      "learning_rate": 0.038440254485852095,
      "loss": 2.614,
      "step": 383060
    },
    {
      "epoch": 615.88,
      "learning_rate": 0.03843703905498392,
      "loss": 2.5673,
      "step": 383080
    },
    {
      "epoch": 615.92,
      "learning_rate": 0.038433823624115765,
      "loss": 2.5878,
      "step": 383100
    },
    {
      "epoch": 615.95,
      "learning_rate": 0.038430608193247597,
      "loss": 2.5768,
      "step": 383120
    },
    {
      "epoch": 615.98,
      "learning_rate": 0.03842739276237943,
      "loss": 2.6138,
      "step": 383140
    },
    {
      "epoch": 616.0,
      "eval_accuracy": {
        "accuracy": 0.42385135660421364
      },
      "eval_loss": 2.7016448974609375,
      "eval_runtime": 3.0249,
      "eval_samples_per_second": 4252.34,
      "eval_steps_per_second": 66.448,
      "step": 383152
    },
    {
      "epoch": 616.01,
      "learning_rate": 0.03842417733151126,
      "loss": 2.5924,
      "step": 383160
    },
    {
      "epoch": 616.05,
      "learning_rate": 0.038420961900643084,
      "loss": 2.5964,
      "step": 383180
    },
    {
      "epoch": 616.08,
      "learning_rate": 0.038417746469774916,
      "loss": 2.5974,
      "step": 383200
    },
    {
      "epoch": 616.11,
      "learning_rate": 0.03841453103890676,
      "loss": 2.572,
      "step": 383220
    },
    {
      "epoch": 616.14,
      "learning_rate": 0.03841131560803859,
      "loss": 2.5952,
      "step": 383240
    },
    {
      "epoch": 616.17,
      "learning_rate": 0.038408100177170425,
      "loss": 2.5795,
      "step": 383260
    },
    {
      "epoch": 616.21,
      "learning_rate": 0.038404884746302256,
      "loss": 2.6024,
      "step": 383280
    },
    {
      "epoch": 616.24,
      "learning_rate": 0.03840166931543408,
      "loss": 2.6168,
      "step": 383300
    },
    {
      "epoch": 616.27,
      "learning_rate": 0.038398453884565927,
      "loss": 2.5853,
      "step": 383320
    },
    {
      "epoch": 616.3,
      "learning_rate": 0.03839523845369776,
      "loss": 2.5803,
      "step": 383340
    },
    {
      "epoch": 616.33,
      "learning_rate": 0.03839202302282959,
      "loss": 2.6096,
      "step": 383360
    },
    {
      "epoch": 616.37,
      "learning_rate": 0.03838880759196142,
      "loss": 2.612,
      "step": 383380
    },
    {
      "epoch": 616.4,
      "learning_rate": 0.038385592161093246,
      "loss": 2.6154,
      "step": 383400
    },
    {
      "epoch": 616.43,
      "learning_rate": 0.03838237673022508,
      "loss": 2.5922,
      "step": 383420
    },
    {
      "epoch": 616.46,
      "learning_rate": 0.03837916129935692,
      "loss": 2.5998,
      "step": 383440
    },
    {
      "epoch": 616.5,
      "learning_rate": 0.038375945868488755,
      "loss": 2.5876,
      "step": 383460
    },
    {
      "epoch": 616.53,
      "learning_rate": 0.038372730437620586,
      "loss": 2.6007,
      "step": 383480
    },
    {
      "epoch": 616.56,
      "learning_rate": 0.03836951500675241,
      "loss": 2.5905,
      "step": 383500
    },
    {
      "epoch": 616.59,
      "learning_rate": 0.03836629957588424,
      "loss": 2.5953,
      "step": 383520
    },
    {
      "epoch": 616.62,
      "learning_rate": 0.038363084145016074,
      "loss": 2.6195,
      "step": 383540
    },
    {
      "epoch": 616.66,
      "learning_rate": 0.03835986871414792,
      "loss": 2.5977,
      "step": 383560
    },
    {
      "epoch": 616.69,
      "learning_rate": 0.03835665328327975,
      "loss": 2.5796,
      "step": 383580
    },
    {
      "epoch": 616.72,
      "learning_rate": 0.03835343785241158,
      "loss": 2.5749,
      "step": 383600
    },
    {
      "epoch": 616.75,
      "learning_rate": 0.03835022242154341,
      "loss": 2.6045,
      "step": 383620
    },
    {
      "epoch": 616.78,
      "learning_rate": 0.03834700699067524,
      "loss": 2.593,
      "step": 383640
    },
    {
      "epoch": 616.82,
      "learning_rate": 0.038343791559807085,
      "loss": 2.5759,
      "step": 383660
    },
    {
      "epoch": 616.85,
      "learning_rate": 0.038340576128938916,
      "loss": 2.5753,
      "step": 383680
    },
    {
      "epoch": 616.88,
      "learning_rate": 0.03833736069807075,
      "loss": 2.6105,
      "step": 383700
    },
    {
      "epoch": 616.91,
      "learning_rate": 0.03833414526720257,
      "loss": 2.5967,
      "step": 383720
    },
    {
      "epoch": 616.95,
      "learning_rate": 0.038330929836334404,
      "loss": 2.6016,
      "step": 383740
    },
    {
      "epoch": 616.98,
      "learning_rate": 0.038327714405466236,
      "loss": 2.6018,
      "step": 383760
    },
    {
      "epoch": 617.0,
      "eval_accuracy": {
        "accuracy": 0.42641685454404105
      },
      "eval_loss": 2.6944150924682617,
      "eval_runtime": 3.1258,
      "eval_samples_per_second": 4115.046,
      "eval_steps_per_second": 64.303,
      "step": 383774
    },
    {
      "epoch": 617.01,
      "learning_rate": 0.03832449897459808,
      "loss": 2.576,
      "step": 383780
    },
    {
      "epoch": 617.04,
      "learning_rate": 0.03832128354372991,
      "loss": 2.5884,
      "step": 383800
    },
    {
      "epoch": 617.07,
      "learning_rate": 0.03831806811286174,
      "loss": 2.5624,
      "step": 383820
    },
    {
      "epoch": 617.11,
      "learning_rate": 0.03831485268199357,
      "loss": 2.5841,
      "step": 383840
    },
    {
      "epoch": 617.14,
      "learning_rate": 0.0383116372511254,
      "loss": 2.5706,
      "step": 383860
    },
    {
      "epoch": 617.17,
      "learning_rate": 0.03830842182025723,
      "loss": 2.5831,
      "step": 383880
    },
    {
      "epoch": 617.2,
      "learning_rate": 0.03830520638938908,
      "loss": 2.5899,
      "step": 383900
    },
    {
      "epoch": 617.23,
      "learning_rate": 0.03830199095852091,
      "loss": 2.6058,
      "step": 383920
    },
    {
      "epoch": 617.27,
      "learning_rate": 0.038298775527652734,
      "loss": 2.5989,
      "step": 383940
    },
    {
      "epoch": 617.3,
      "learning_rate": 0.038295560096784566,
      "loss": 2.6035,
      "step": 383960
    },
    {
      "epoch": 617.33,
      "learning_rate": 0.0382923446659164,
      "loss": 2.6046,
      "step": 383980
    },
    {
      "epoch": 617.36,
      "learning_rate": 0.03828912923504824,
      "loss": 2.6003,
      "step": 384000
    },
    {
      "epoch": 617.4,
      "learning_rate": 0.038285913804180075,
      "loss": 2.5987,
      "step": 384020
    },
    {
      "epoch": 617.43,
      "learning_rate": 0.03828285914485531,
      "loss": 2.5897,
      "step": 384040
    },
    {
      "epoch": 617.46,
      "learning_rate": 0.03827964371398714,
      "loss": 2.5968,
      "step": 384060
    },
    {
      "epoch": 617.49,
      "learning_rate": 0.038276428283118974,
      "loss": 2.6125,
      "step": 384080
    },
    {
      "epoch": 617.52,
      "learning_rate": 0.038273212852250806,
      "loss": 2.5931,
      "step": 384100
    },
    {
      "epoch": 617.56,
      "learning_rate": 0.03826999742138264,
      "loss": 2.5619,
      "step": 384120
    },
    {
      "epoch": 617.59,
      "learning_rate": 0.038266781990514476,
      "loss": 2.5779,
      "step": 384140
    },
    {
      "epoch": 617.62,
      "learning_rate": 0.03826356655964631,
      "loss": 2.5993,
      "step": 384160
    },
    {
      "epoch": 617.65,
      "learning_rate": 0.03826035112877814,
      "loss": 2.5753,
      "step": 384180
    },
    {
      "epoch": 617.68,
      "learning_rate": 0.03825713569790997,
      "loss": 2.6046,
      "step": 384200
    },
    {
      "epoch": 617.72,
      "learning_rate": 0.0382539202670418,
      "loss": 2.5948,
      "step": 384220
    },
    {
      "epoch": 617.75,
      "learning_rate": 0.038250704836173634,
      "loss": 2.6066,
      "step": 384240
    },
    {
      "epoch": 617.78,
      "learning_rate": 0.03824748940530547,
      "loss": 2.5863,
      "step": 384260
    },
    {
      "epoch": 617.81,
      "learning_rate": 0.038244273974437304,
      "loss": 2.6027,
      "step": 384280
    },
    {
      "epoch": 617.85,
      "learning_rate": 0.038241058543569136,
      "loss": 2.5942,
      "step": 384300
    },
    {
      "epoch": 617.88,
      "learning_rate": 0.03823784311270097,
      "loss": 2.5959,
      "step": 384320
    },
    {
      "epoch": 617.91,
      "learning_rate": 0.0382346276818328,
      "loss": 2.5822,
      "step": 384340
    },
    {
      "epoch": 617.94,
      "learning_rate": 0.03823141225096463,
      "loss": 2.5705,
      "step": 384360
    },
    {
      "epoch": 617.97,
      "learning_rate": 0.03822819682009647,
      "loss": 2.6131,
      "step": 384380
    },
    {
      "epoch": 618.0,
      "eval_accuracy": {
        "accuracy": 0.42734976288579646
      },
      "eval_loss": 2.7053325176239014,
      "eval_runtime": 2.9224,
      "eval_samples_per_second": 4401.446,
      "eval_steps_per_second": 68.778,
      "step": 384396
    },
    {
      "epoch": 618.01,
      "learning_rate": 0.0382249813892283,
      "loss": 2.5892,
      "step": 384400
    },
    {
      "epoch": 618.04,
      "learning_rate": 0.03822176595836013,
      "loss": 2.6121,
      "step": 384420
    },
    {
      "epoch": 618.07,
      "learning_rate": 0.038218550527491964,
      "loss": 2.6031,
      "step": 384440
    },
    {
      "epoch": 618.1,
      "learning_rate": 0.038215335096623795,
      "loss": 2.5818,
      "step": 384460
    },
    {
      "epoch": 618.14,
      "learning_rate": 0.038212119665755634,
      "loss": 2.5855,
      "step": 384480
    },
    {
      "epoch": 618.17,
      "learning_rate": 0.038208904234887466,
      "loss": 2.5621,
      "step": 384500
    },
    {
      "epoch": 618.2,
      "learning_rate": 0.0382056888040193,
      "loss": 2.5672,
      "step": 384520
    },
    {
      "epoch": 618.23,
      "learning_rate": 0.03820247337315113,
      "loss": 2.5848,
      "step": 384540
    },
    {
      "epoch": 618.26,
      "learning_rate": 0.03819925794228296,
      "loss": 2.5912,
      "step": 384560
    },
    {
      "epoch": 618.3,
      "learning_rate": 0.03819604251141479,
      "loss": 2.5907,
      "step": 384580
    },
    {
      "epoch": 618.33,
      "learning_rate": 0.03819282708054663,
      "loss": 2.5948,
      "step": 384600
    },
    {
      "epoch": 618.36,
      "learning_rate": 0.03818961164967846,
      "loss": 2.5708,
      "step": 384620
    },
    {
      "epoch": 618.39,
      "learning_rate": 0.038186396218810294,
      "loss": 2.5735,
      "step": 384640
    },
    {
      "epoch": 618.42,
      "learning_rate": 0.038183180787942125,
      "loss": 2.565,
      "step": 384660
    },
    {
      "epoch": 618.46,
      "learning_rate": 0.03817996535707396,
      "loss": 2.581,
      "step": 384680
    },
    {
      "epoch": 618.49,
      "learning_rate": 0.03817674992620579,
      "loss": 2.5933,
      "step": 384700
    },
    {
      "epoch": 618.52,
      "learning_rate": 0.03817353449533763,
      "loss": 2.5974,
      "step": 384720
    },
    {
      "epoch": 618.55,
      "learning_rate": 0.03817031906446946,
      "loss": 2.587,
      "step": 384740
    },
    {
      "epoch": 618.59,
      "learning_rate": 0.03816710363360129,
      "loss": 2.6277,
      "step": 384760
    },
    {
      "epoch": 618.62,
      "learning_rate": 0.03816388820273312,
      "loss": 2.6128,
      "step": 384780
    },
    {
      "epoch": 618.65,
      "learning_rate": 0.038160672771864954,
      "loss": 2.5981,
      "step": 384800
    },
    {
      "epoch": 618.68,
      "learning_rate": 0.03815745734099679,
      "loss": 2.5684,
      "step": 384820
    },
    {
      "epoch": 618.71,
      "learning_rate": 0.038154241910128624,
      "loss": 2.6011,
      "step": 384840
    },
    {
      "epoch": 618.75,
      "learning_rate": 0.038151026479260455,
      "loss": 2.5932,
      "step": 384860
    },
    {
      "epoch": 618.78,
      "learning_rate": 0.03814781104839229,
      "loss": 2.5711,
      "step": 384880
    },
    {
      "epoch": 618.81,
      "learning_rate": 0.03814459561752412,
      "loss": 2.5862,
      "step": 384900
    },
    {
      "epoch": 618.84,
      "learning_rate": 0.03814138018665595,
      "loss": 2.5825,
      "step": 384920
    },
    {
      "epoch": 618.87,
      "learning_rate": 0.03813816475578779,
      "loss": 2.6121,
      "step": 384940
    },
    {
      "epoch": 618.91,
      "learning_rate": 0.03813494932491962,
      "loss": 2.6197,
      "step": 384960
    },
    {
      "epoch": 618.94,
      "learning_rate": 0.03813173389405145,
      "loss": 2.6156,
      "step": 384980
    },
    {
      "epoch": 618.97,
      "learning_rate": 0.038128518463183284,
      "loss": 2.6188,
      "step": 385000
    },
    {
      "epoch": 619.0,
      "eval_accuracy": {
        "accuracy": 0.42175231283526393
      },
      "eval_loss": 2.720580577850342,
      "eval_runtime": 3.0666,
      "eval_samples_per_second": 4194.564,
      "eval_steps_per_second": 65.545,
      "step": 385018
    },
    {
      "epoch": 619.0,
      "learning_rate": 0.038125303032315115,
      "loss": 2.6091,
      "step": 385020
    },
    {
      "epoch": 619.04,
      "learning_rate": 0.03812208760144695,
      "loss": 2.6058,
      "step": 385040
    },
    {
      "epoch": 619.07,
      "learning_rate": 0.038118872170578785,
      "loss": 2.5702,
      "step": 385060
    },
    {
      "epoch": 619.1,
      "learning_rate": 0.03811565673971062,
      "loss": 2.5538,
      "step": 385080
    },
    {
      "epoch": 619.13,
      "learning_rate": 0.03811244130884245,
      "loss": 2.606,
      "step": 385100
    },
    {
      "epoch": 619.16,
      "learning_rate": 0.03810922587797428,
      "loss": 2.5658,
      "step": 385120
    },
    {
      "epoch": 619.2,
      "learning_rate": 0.03810601044710611,
      "loss": 2.5892,
      "step": 385140
    },
    {
      "epoch": 619.23,
      "learning_rate": 0.03810279501623795,
      "loss": 2.5857,
      "step": 385160
    },
    {
      "epoch": 619.26,
      "learning_rate": 0.03809957958536978,
      "loss": 2.5789,
      "step": 385180
    },
    {
      "epoch": 619.29,
      "learning_rate": 0.038096364154501614,
      "loss": 2.6003,
      "step": 385200
    },
    {
      "epoch": 619.32,
      "learning_rate": 0.038093148723633445,
      "loss": 2.6003,
      "step": 385220
    },
    {
      "epoch": 619.36,
      "learning_rate": 0.03808993329276528,
      "loss": 2.6035,
      "step": 385240
    },
    {
      "epoch": 619.39,
      "learning_rate": 0.03808671786189711,
      "loss": 2.5972,
      "step": 385260
    },
    {
      "epoch": 619.42,
      "learning_rate": 0.03808350243102895,
      "loss": 2.5952,
      "step": 385280
    },
    {
      "epoch": 619.45,
      "learning_rate": 0.03808028700016078,
      "loss": 2.589,
      "step": 385300
    },
    {
      "epoch": 619.49,
      "learning_rate": 0.03807707156929261,
      "loss": 2.6075,
      "step": 385320
    },
    {
      "epoch": 619.52,
      "learning_rate": 0.03807385613842444,
      "loss": 2.5837,
      "step": 385340
    },
    {
      "epoch": 619.55,
      "learning_rate": 0.03807064070755627,
      "loss": 2.5777,
      "step": 385360
    },
    {
      "epoch": 619.58,
      "learning_rate": 0.0380674252766881,
      "loss": 2.568,
      "step": 385380
    },
    {
      "epoch": 619.61,
      "learning_rate": 0.038064209845819943,
      "loss": 2.5887,
      "step": 385400
    },
    {
      "epoch": 619.65,
      "learning_rate": 0.038060994414951775,
      "loss": 2.5755,
      "step": 385420
    },
    {
      "epoch": 619.68,
      "learning_rate": 0.03805777898408361,
      "loss": 2.6057,
      "step": 385440
    },
    {
      "epoch": 619.71,
      "learning_rate": 0.03805456355321544,
      "loss": 2.5948,
      "step": 385460
    },
    {
      "epoch": 619.74,
      "learning_rate": 0.03805134812234727,
      "loss": 2.5863,
      "step": 385480
    },
    {
      "epoch": 619.77,
      "learning_rate": 0.03804813269147911,
      "loss": 2.5906,
      "step": 385500
    },
    {
      "epoch": 619.81,
      "learning_rate": 0.03804491726061094,
      "loss": 2.6059,
      "step": 385520
    },
    {
      "epoch": 619.84,
      "learning_rate": 0.03804170182974277,
      "loss": 2.572,
      "step": 385540
    },
    {
      "epoch": 619.87,
      "learning_rate": 0.0380384863988746,
      "loss": 2.5778,
      "step": 385560
    },
    {
      "epoch": 619.9,
      "learning_rate": 0.038035270968006435,
      "loss": 2.5714,
      "step": 385580
    },
    {
      "epoch": 619.94,
      "learning_rate": 0.03803205553713826,
      "loss": 2.5689,
      "step": 385600
    },
    {
      "epoch": 619.97,
      "learning_rate": 0.038028840106270105,
      "loss": 2.6098,
      "step": 385620
    },
    {
      "epoch": 620.0,
      "learning_rate": 0.03802562467540194,
      "loss": 2.5883,
      "step": 385640
    },
    {
      "epoch": 620.0,
      "eval_accuracy": {
        "accuracy": 0.4237736142424007
      },
      "eval_loss": 2.712420701980591,
      "eval_runtime": 3.2388,
      "eval_samples_per_second": 3971.521,
      "eval_steps_per_second": 62.06,
      "step": 385640
    },
    {
      "epoch": 620.03,
      "learning_rate": 0.03802240924453377,
      "loss": 2.608,
      "step": 385660
    },
    {
      "epoch": 620.06,
      "learning_rate": 0.0380191938136656,
      "loss": 2.613,
      "step": 385680
    },
    {
      "epoch": 620.1,
      "learning_rate": 0.038015978382797425,
      "loss": 2.5867,
      "step": 385700
    },
    {
      "epoch": 620.13,
      "learning_rate": 0.03801276295192927,
      "loss": 2.6015,
      "step": 385720
    },
    {
      "epoch": 620.16,
      "learning_rate": 0.0380095475210611,
      "loss": 2.5849,
      "step": 385740
    },
    {
      "epoch": 620.19,
      "learning_rate": 0.03800633209019293,
      "loss": 2.5814,
      "step": 385760
    },
    {
      "epoch": 620.23,
      "learning_rate": 0.038003116659324765,
      "loss": 2.5743,
      "step": 385780
    },
    {
      "epoch": 620.26,
      "learning_rate": 0.037999901228456597,
      "loss": 2.5934,
      "step": 385800
    },
    {
      "epoch": 620.29,
      "learning_rate": 0.03799668579758842,
      "loss": 2.5997,
      "step": 385820
    },
    {
      "epoch": 620.32,
      "learning_rate": 0.03799347036672027,
      "loss": 2.6028,
      "step": 385840
    },
    {
      "epoch": 620.35,
      "learning_rate": 0.0379902549358521,
      "loss": 2.5953,
      "step": 385860
    },
    {
      "epoch": 620.39,
      "learning_rate": 0.03798703950498393,
      "loss": 2.5745,
      "step": 385880
    },
    {
      "epoch": 620.42,
      "learning_rate": 0.03798382407411576,
      "loss": 2.5866,
      "step": 385900
    },
    {
      "epoch": 620.45,
      "learning_rate": 0.037980608643247586,
      "loss": 2.6,
      "step": 385920
    },
    {
      "epoch": 620.48,
      "learning_rate": 0.03797739321237942,
      "loss": 2.6012,
      "step": 385940
    },
    {
      "epoch": 620.51,
      "learning_rate": 0.03797417778151126,
      "loss": 2.6153,
      "step": 385960
    },
    {
      "epoch": 620.55,
      "learning_rate": 0.037970962350643095,
      "loss": 2.595,
      "step": 385980
    },
    {
      "epoch": 620.58,
      "learning_rate": 0.037967746919774926,
      "loss": 2.6031,
      "step": 386000
    },
    {
      "epoch": 620.61,
      "learning_rate": 0.03796453148890675,
      "loss": 2.5737,
      "step": 386020
    },
    {
      "epoch": 620.64,
      "learning_rate": 0.03796131605803858,
      "loss": 2.5942,
      "step": 386040
    },
    {
      "epoch": 620.68,
      "learning_rate": 0.03795810062717043,
      "loss": 2.5901,
      "step": 386060
    },
    {
      "epoch": 620.71,
      "learning_rate": 0.03795488519630226,
      "loss": 2.5802,
      "step": 386080
    },
    {
      "epoch": 620.74,
      "learning_rate": 0.03795166976543409,
      "loss": 2.6044,
      "step": 386100
    },
    {
      "epoch": 620.77,
      "learning_rate": 0.03794845433456592,
      "loss": 2.5769,
      "step": 386120
    },
    {
      "epoch": 620.8,
      "learning_rate": 0.03794523890369775,
      "loss": 2.5975,
      "step": 386140
    },
    {
      "epoch": 620.84,
      "learning_rate": 0.03794202347282958,
      "loss": 2.5951,
      "step": 386160
    },
    {
      "epoch": 620.87,
      "learning_rate": 0.037938808041961425,
      "loss": 2.5796,
      "step": 386180
    },
    {
      "epoch": 620.9,
      "learning_rate": 0.037935592611093256,
      "loss": 2.5602,
      "step": 386200
    },
    {
      "epoch": 620.93,
      "learning_rate": 0.03793237718022509,
      "loss": 2.5893,
      "step": 386220
    },
    {
      "epoch": 620.96,
      "learning_rate": 0.03792916174935691,
      "loss": 2.5596,
      "step": 386240
    },
    {
      "epoch": 621.0,
      "learning_rate": 0.037925946318488744,
      "loss": 2.5924,
      "step": 386260
    },
    {
      "epoch": 621.0,
      "eval_accuracy": {
        "accuracy": 0.4198864961517531
      },
      "eval_loss": 2.7258260250091553,
      "eval_runtime": 3.2699,
      "eval_samples_per_second": 3933.756,
      "eval_steps_per_second": 61.47,
      "step": 386262
    },
    {
      "epoch": 621.03,
      "learning_rate": 0.037922730887620576,
      "loss": 2.6055,
      "step": 386280
    },
    {
      "epoch": 621.06,
      "learning_rate": 0.03791951545675242,
      "loss": 2.6041,
      "step": 386300
    },
    {
      "epoch": 621.09,
      "learning_rate": 0.03791630002588425,
      "loss": 2.6227,
      "step": 386320
    },
    {
      "epoch": 621.13,
      "learning_rate": 0.03791308459501608,
      "loss": 2.5719,
      "step": 386340
    },
    {
      "epoch": 621.16,
      "learning_rate": 0.03790986916414791,
      "loss": 2.5897,
      "step": 386360
    },
    {
      "epoch": 621.19,
      "learning_rate": 0.03790665373327974,
      "loss": 2.5771,
      "step": 386380
    },
    {
      "epoch": 621.22,
      "learning_rate": 0.037903438302411586,
      "loss": 2.5996,
      "step": 386400
    },
    {
      "epoch": 621.25,
      "learning_rate": 0.03790022287154342,
      "loss": 2.5837,
      "step": 386420
    },
    {
      "epoch": 621.29,
      "learning_rate": 0.03789700744067525,
      "loss": 2.5771,
      "step": 386440
    },
    {
      "epoch": 621.32,
      "learning_rate": 0.037893792009807074,
      "loss": 2.5979,
      "step": 386460
    },
    {
      "epoch": 621.35,
      "learning_rate": 0.037890576578938906,
      "loss": 2.5789,
      "step": 386480
    },
    {
      "epoch": 621.38,
      "learning_rate": 0.03788736114807074,
      "loss": 2.5926,
      "step": 386500
    },
    {
      "epoch": 621.41,
      "learning_rate": 0.03788414571720258,
      "loss": 2.5915,
      "step": 386520
    },
    {
      "epoch": 621.45,
      "learning_rate": 0.037880930286334415,
      "loss": 2.5918,
      "step": 386540
    },
    {
      "epoch": 621.48,
      "learning_rate": 0.03787771485546624,
      "loss": 2.5813,
      "step": 386560
    },
    {
      "epoch": 621.51,
      "learning_rate": 0.03787449942459807,
      "loss": 2.6034,
      "step": 386580
    },
    {
      "epoch": 621.54,
      "learning_rate": 0.0378712839937299,
      "loss": 2.5791,
      "step": 386600
    },
    {
      "epoch": 621.58,
      "learning_rate": 0.037868068562861734,
      "loss": 2.5852,
      "step": 386620
    },
    {
      "epoch": 621.61,
      "learning_rate": 0.03786485313199358,
      "loss": 2.6173,
      "step": 386640
    },
    {
      "epoch": 621.64,
      "learning_rate": 0.037861637701125404,
      "loss": 2.6012,
      "step": 386660
    },
    {
      "epoch": 621.67,
      "learning_rate": 0.037858422270257236,
      "loss": 2.5964,
      "step": 386680
    },
    {
      "epoch": 621.7,
      "learning_rate": 0.03785520683938907,
      "loss": 2.5902,
      "step": 386700
    },
    {
      "epoch": 621.74,
      "learning_rate": 0.0378519914085209,
      "loss": 2.5947,
      "step": 386720
    },
    {
      "epoch": 621.77,
      "learning_rate": 0.037848775977652745,
      "loss": 2.6028,
      "step": 386740
    },
    {
      "epoch": 621.8,
      "learning_rate": 0.037845560546784576,
      "loss": 2.5989,
      "step": 386760
    },
    {
      "epoch": 621.83,
      "learning_rate": 0.0378423451159164,
      "loss": 2.5905,
      "step": 386780
    },
    {
      "epoch": 621.86,
      "learning_rate": 0.03783912968504823,
      "loss": 2.5725,
      "step": 386800
    },
    {
      "epoch": 621.9,
      "learning_rate": 0.037835914254180064,
      "loss": 2.5887,
      "step": 386820
    },
    {
      "epoch": 621.93,
      "learning_rate": 0.037832698823311896,
      "loss": 2.5872,
      "step": 386840
    },
    {
      "epoch": 621.96,
      "learning_rate": 0.03782948339244374,
      "loss": 2.5886,
      "step": 386860
    },
    {
      "epoch": 621.99,
      "learning_rate": 0.037826267961575566,
      "loss": 2.5844,
      "step": 386880
    },
    {
      "epoch": 622.0,
      "eval_accuracy": {
        "accuracy": 0.4227629635388323
      },
      "eval_loss": 2.7088587284088135,
      "eval_runtime": 3.2666,
      "eval_samples_per_second": 3937.705,
      "eval_steps_per_second": 61.531,
      "step": 386884
    },
    {
      "epoch": 622.03,
      "learning_rate": 0.0378230525307074,
      "loss": 2.5948,
      "step": 386900
    },
    {
      "epoch": 622.06,
      "learning_rate": 0.03781983709983923,
      "loss": 2.5927,
      "step": 386920
    },
    {
      "epoch": 622.09,
      "learning_rate": 0.03781662166897106,
      "loss": 2.5954,
      "step": 386940
    },
    {
      "epoch": 622.12,
      "learning_rate": 0.03781340623810289,
      "loss": 2.5871,
      "step": 386960
    },
    {
      "epoch": 622.15,
      "learning_rate": 0.03781019080723473,
      "loss": 2.5918,
      "step": 386980
    },
    {
      "epoch": 622.19,
      "learning_rate": 0.03780697537636656,
      "loss": 2.5869,
      "step": 387000
    },
    {
      "epoch": 622.22,
      "learning_rate": 0.037803759945498394,
      "loss": 2.5905,
      "step": 387020
    },
    {
      "epoch": 622.25,
      "learning_rate": 0.037800544514630226,
      "loss": 2.5877,
      "step": 387040
    },
    {
      "epoch": 622.28,
      "learning_rate": 0.03779732908376206,
      "loss": 2.5817,
      "step": 387060
    },
    {
      "epoch": 622.32,
      "learning_rate": 0.0377941136528939,
      "loss": 2.5943,
      "step": 387080
    },
    {
      "epoch": 622.35,
      "learning_rate": 0.03779089822202573,
      "loss": 2.6095,
      "step": 387100
    },
    {
      "epoch": 622.38,
      "learning_rate": 0.03778768279115756,
      "loss": 2.5857,
      "step": 387120
    },
    {
      "epoch": 622.41,
      "learning_rate": 0.03778446736028939,
      "loss": 2.5603,
      "step": 387140
    },
    {
      "epoch": 622.44,
      "learning_rate": 0.03778125192942122,
      "loss": 2.5918,
      "step": 387160
    },
    {
      "epoch": 622.48,
      "learning_rate": 0.037778036498553054,
      "loss": 2.5553,
      "step": 387180
    },
    {
      "epoch": 622.51,
      "learning_rate": 0.03777482106768489,
      "loss": 2.5686,
      "step": 387200
    },
    {
      "epoch": 622.54,
      "learning_rate": 0.037771605636816724,
      "loss": 2.5891,
      "step": 387220
    },
    {
      "epoch": 622.57,
      "learning_rate": 0.037768390205948556,
      "loss": 2.5826,
      "step": 387240
    },
    {
      "epoch": 622.6,
      "learning_rate": 0.03776517477508039,
      "loss": 2.6019,
      "step": 387260
    },
    {
      "epoch": 622.64,
      "learning_rate": 0.03776195934421222,
      "loss": 2.592,
      "step": 387280
    },
    {
      "epoch": 622.67,
      "learning_rate": 0.03775874391334406,
      "loss": 2.6008,
      "step": 387300
    },
    {
      "epoch": 622.7,
      "learning_rate": 0.03775552848247589,
      "loss": 2.5651,
      "step": 387320
    },
    {
      "epoch": 622.73,
      "learning_rate": 0.03775231305160772,
      "loss": 2.5867,
      "step": 387340
    },
    {
      "epoch": 622.77,
      "learning_rate": 0.03774909762073955,
      "loss": 2.6058,
      "step": 387360
    },
    {
      "epoch": 622.8,
      "learning_rate": 0.037745882189871384,
      "loss": 2.5969,
      "step": 387380
    },
    {
      "epoch": 622.83,
      "learning_rate": 0.037742666759003216,
      "loss": 2.5681,
      "step": 387400
    },
    {
      "epoch": 622.86,
      "learning_rate": 0.037739451328135054,
      "loss": 2.5775,
      "step": 387420
    },
    {
      "epoch": 622.89,
      "learning_rate": 0.037736235897266886,
      "loss": 2.5968,
      "step": 387440
    },
    {
      "epoch": 622.93,
      "learning_rate": 0.03773302046639872,
      "loss": 2.6012,
      "step": 387460
    },
    {
      "epoch": 622.96,
      "learning_rate": 0.03772980503553055,
      "loss": 2.6055,
      "step": 387480
    },
    {
      "epoch": 622.99,
      "learning_rate": 0.03772658960466238,
      "loss": 2.5977,
      "step": 387500
    },
    {
      "epoch": 623.0,
      "eval_accuracy": {
        "accuracy": 0.4213636010261992
      },
      "eval_loss": 2.714182138442993,
      "eval_runtime": 3.0907,
      "eval_samples_per_second": 4161.795,
      "eval_steps_per_second": 65.033,
      "step": 387506
    },
    {
      "epoch": 623.02,
      "learning_rate": 0.03772337417379421,
      "loss": 2.5731,
      "step": 387520
    },
    {
      "epoch": 623.05,
      "learning_rate": 0.03772015874292605,
      "loss": 2.5752,
      "step": 387540
    },
    {
      "epoch": 623.09,
      "learning_rate": 0.03771694331205788,
      "loss": 2.5661,
      "step": 387560
    },
    {
      "epoch": 623.12,
      "learning_rate": 0.037713727881189714,
      "loss": 2.5959,
      "step": 387580
    },
    {
      "epoch": 623.15,
      "learning_rate": 0.037710512450321546,
      "loss": 2.5968,
      "step": 387600
    },
    {
      "epoch": 623.18,
      "learning_rate": 0.03770729701945338,
      "loss": 2.593,
      "step": 387620
    },
    {
      "epoch": 623.22,
      "learning_rate": 0.037704081588585216,
      "loss": 2.5715,
      "step": 387640
    },
    {
      "epoch": 623.25,
      "learning_rate": 0.03770086615771705,
      "loss": 2.5922,
      "step": 387660
    },
    {
      "epoch": 623.28,
      "learning_rate": 0.03769765072684888,
      "loss": 2.5909,
      "step": 387680
    },
    {
      "epoch": 623.31,
      "learning_rate": 0.03769443529598071,
      "loss": 2.5674,
      "step": 387700
    },
    {
      "epoch": 623.34,
      "learning_rate": 0.03769121986511254,
      "loss": 2.5579,
      "step": 387720
    },
    {
      "epoch": 623.38,
      "learning_rate": 0.037688004434244374,
      "loss": 2.5657,
      "step": 387740
    },
    {
      "epoch": 623.41,
      "learning_rate": 0.03768478900337621,
      "loss": 2.6001,
      "step": 387760
    },
    {
      "epoch": 623.44,
      "learning_rate": 0.037681573572508044,
      "loss": 2.5893,
      "step": 387780
    },
    {
      "epoch": 623.47,
      "learning_rate": 0.037678358141639876,
      "loss": 2.5843,
      "step": 387800
    },
    {
      "epoch": 623.5,
      "learning_rate": 0.03767514271077171,
      "loss": 2.5902,
      "step": 387820
    },
    {
      "epoch": 623.54,
      "learning_rate": 0.03767192727990354,
      "loss": 2.6037,
      "step": 387840
    },
    {
      "epoch": 623.57,
      "learning_rate": 0.03766871184903537,
      "loss": 2.5907,
      "step": 387860
    },
    {
      "epoch": 623.6,
      "learning_rate": 0.03766549641816721,
      "loss": 2.6,
      "step": 387880
    },
    {
      "epoch": 623.63,
      "learning_rate": 0.03766228098729904,
      "loss": 2.5949,
      "step": 387900
    },
    {
      "epoch": 623.67,
      "learning_rate": 0.03765906555643087,
      "loss": 2.6056,
      "step": 387920
    },
    {
      "epoch": 623.7,
      "learning_rate": 0.037655850125562704,
      "loss": 2.5954,
      "step": 387940
    },
    {
      "epoch": 623.73,
      "learning_rate": 0.037652634694694535,
      "loss": 2.5738,
      "step": 387960
    },
    {
      "epoch": 623.76,
      "learning_rate": 0.037649419263826374,
      "loss": 2.5819,
      "step": 387980
    },
    {
      "epoch": 623.79,
      "learning_rate": 0.037646203832958205,
      "loss": 2.5681,
      "step": 388000
    },
    {
      "epoch": 623.83,
      "learning_rate": 0.03764298840209004,
      "loss": 2.5792,
      "step": 388020
    },
    {
      "epoch": 623.86,
      "learning_rate": 0.03763993374276528,
      "loss": 2.586,
      "step": 388040
    },
    {
      "epoch": 623.89,
      "learning_rate": 0.03763671831189711,
      "loss": 2.6016,
      "step": 388060
    },
    {
      "epoch": 623.92,
      "learning_rate": 0.037633502881028943,
      "loss": 2.607,
      "step": 388080
    },
    {
      "epoch": 623.95,
      "learning_rate": 0.037630287450160775,
      "loss": 2.5773,
      "step": 388100
    },
    {
      "epoch": 623.99,
      "learning_rate": 0.037627072019292614,
      "loss": 2.5986,
      "step": 388120
    },
    {
      "epoch": 624.0,
      "eval_accuracy": {
        "accuracy": 0.42898235248386846
      },
      "eval_loss": 2.6905510425567627,
      "eval_runtime": 3.1199,
      "eval_samples_per_second": 4122.931,
      "eval_steps_per_second": 64.426,
      "step": 388128
    },
    {
      "epoch": 624.02,
      "learning_rate": 0.037623856588424445,
      "loss": 2.5863,
      "step": 388140
    },
    {
      "epoch": 624.05,
      "learning_rate": 0.03762064115755628,
      "loss": 2.5879,
      "step": 388160
    },
    {
      "epoch": 624.08,
      "learning_rate": 0.03761742572668811,
      "loss": 2.5665,
      "step": 388180
    },
    {
      "epoch": 624.12,
      "learning_rate": 0.03761421029581994,
      "loss": 2.5609,
      "step": 388200
    },
    {
      "epoch": 624.15,
      "learning_rate": 0.037610994864951765,
      "loss": 2.5942,
      "step": 388220
    },
    {
      "epoch": 624.18,
      "learning_rate": 0.03760777943408361,
      "loss": 2.5988,
      "step": 388240
    },
    {
      "epoch": 624.21,
      "learning_rate": 0.03760456400321544,
      "loss": 2.5917,
      "step": 388260
    },
    {
      "epoch": 624.24,
      "learning_rate": 0.03760134857234727,
      "loss": 2.6072,
      "step": 388280
    },
    {
      "epoch": 624.28,
      "learning_rate": 0.037598133141479105,
      "loss": 2.5822,
      "step": 388300
    },
    {
      "epoch": 624.31,
      "learning_rate": 0.03759491771061094,
      "loss": 2.5941,
      "step": 388320
    },
    {
      "epoch": 624.34,
      "learning_rate": 0.03759170227974276,
      "loss": 2.5856,
      "step": 388340
    },
    {
      "epoch": 624.37,
      "learning_rate": 0.03758848684887461,
      "loss": 2.5877,
      "step": 388360
    },
    {
      "epoch": 624.41,
      "learning_rate": 0.03758527141800644,
      "loss": 2.5783,
      "step": 388380
    },
    {
      "epoch": 624.44,
      "learning_rate": 0.03758205598713827,
      "loss": 2.5809,
      "step": 388400
    },
    {
      "epoch": 624.47,
      "learning_rate": 0.0375788405562701,
      "loss": 2.5904,
      "step": 388420
    },
    {
      "epoch": 624.5,
      "learning_rate": 0.037575625125401926,
      "loss": 2.6115,
      "step": 388440
    },
    {
      "epoch": 624.53,
      "learning_rate": 0.03757240969453377,
      "loss": 2.5659,
      "step": 388460
    },
    {
      "epoch": 624.57,
      "learning_rate": 0.0375691942636656,
      "loss": 2.6131,
      "step": 388480
    },
    {
      "epoch": 624.6,
      "learning_rate": 0.037565978832797435,
      "loss": 2.5894,
      "step": 388500
    },
    {
      "epoch": 624.63,
      "learning_rate": 0.03756276340192927,
      "loss": 2.6009,
      "step": 388520
    },
    {
      "epoch": 624.66,
      "learning_rate": 0.03755954797106109,
      "loss": 2.5786,
      "step": 388540
    },
    {
      "epoch": 624.69,
      "learning_rate": 0.03755633254019292,
      "loss": 2.5974,
      "step": 388560
    },
    {
      "epoch": 624.73,
      "learning_rate": 0.03755311710932477,
      "loss": 2.6083,
      "step": 388580
    },
    {
      "epoch": 624.76,
      "learning_rate": 0.0375499016784566,
      "loss": 2.5619,
      "step": 388600
    },
    {
      "epoch": 624.79,
      "learning_rate": 0.03754668624758843,
      "loss": 2.5512,
      "step": 388620
    },
    {
      "epoch": 624.82,
      "learning_rate": 0.03754347081672026,
      "loss": 2.6084,
      "step": 388640
    },
    {
      "epoch": 624.86,
      "learning_rate": 0.03754025538585209,
      "loss": 2.6092,
      "step": 388660
    },
    {
      "epoch": 624.89,
      "learning_rate": 0.03753703995498392,
      "loss": 2.5856,
      "step": 388680
    },
    {
      "epoch": 624.92,
      "learning_rate": 0.037533824524115765,
      "loss": 2.5756,
      "step": 388700
    },
    {
      "epoch": 624.95,
      "learning_rate": 0.0375306090932476,
      "loss": 2.5726,
      "step": 388720
    },
    {
      "epoch": 624.98,
      "learning_rate": 0.03752739366237943,
      "loss": 2.5978,
      "step": 388740
    },
    {
      "epoch": 625.0,
      "eval_accuracy": {
        "accuracy": 0.42672782399129283
      },
      "eval_loss": 2.7024991512298584,
      "eval_runtime": 3.1521,
      "eval_samples_per_second": 4080.72,
      "eval_steps_per_second": 63.766,
      "step": 388750
    },
    {
      "epoch": 625.02,
      "learning_rate": 0.03752417823151125,
      "loss": 2.5813,
      "step": 388760
    },
    {
      "epoch": 625.05,
      "learning_rate": 0.037520962800643085,
      "loss": 2.571,
      "step": 388780
    },
    {
      "epoch": 625.08,
      "learning_rate": 0.03751774736977493,
      "loss": 2.578,
      "step": 388800
    },
    {
      "epoch": 625.11,
      "learning_rate": 0.03751453193890676,
      "loss": 2.5798,
      "step": 388820
    },
    {
      "epoch": 625.14,
      "learning_rate": 0.03751131650803859,
      "loss": 2.5696,
      "step": 388840
    },
    {
      "epoch": 625.18,
      "learning_rate": 0.03750810107717042,
      "loss": 2.5955,
      "step": 388860
    },
    {
      "epoch": 625.21,
      "learning_rate": 0.03750488564630225,
      "loss": 2.5624,
      "step": 388880
    },
    {
      "epoch": 625.24,
      "learning_rate": 0.03750167021543408,
      "loss": 2.5748,
      "step": 388900
    },
    {
      "epoch": 625.27,
      "learning_rate": 0.03749845478456593,
      "loss": 2.6013,
      "step": 388920
    },
    {
      "epoch": 625.31,
      "learning_rate": 0.03749523935369776,
      "loss": 2.5643,
      "step": 388940
    },
    {
      "epoch": 625.34,
      "learning_rate": 0.037492184694372994,
      "loss": 2.5873,
      "step": 388960
    },
    {
      "epoch": 625.37,
      "learning_rate": 0.037488969263504826,
      "loss": 2.58,
      "step": 388980
    },
    {
      "epoch": 625.4,
      "learning_rate": 0.03748575383263666,
      "loss": 2.5775,
      "step": 389000
    },
    {
      "epoch": 625.43,
      "learning_rate": 0.03748253840176849,
      "loss": 2.5925,
      "step": 389020
    },
    {
      "epoch": 625.47,
      "learning_rate": 0.03747932297090032,
      "loss": 2.5521,
      "step": 389040
    },
    {
      "epoch": 625.5,
      "learning_rate": 0.037476107540032166,
      "loss": 2.5775,
      "step": 389060
    },
    {
      "epoch": 625.53,
      "learning_rate": 0.03747289210916399,
      "loss": 2.6074,
      "step": 389080
    },
    {
      "epoch": 625.56,
      "learning_rate": 0.03746967667829582,
      "loss": 2.6117,
      "step": 389100
    },
    {
      "epoch": 625.59,
      "learning_rate": 0.037466461247427654,
      "loss": 2.5983,
      "step": 389120
    },
    {
      "epoch": 625.63,
      "learning_rate": 0.037463245816559486,
      "loss": 2.5776,
      "step": 389140
    },
    {
      "epoch": 625.66,
      "learning_rate": 0.03746003038569132,
      "loss": 2.5847,
      "step": 389160
    },
    {
      "epoch": 625.69,
      "learning_rate": 0.037456814954823156,
      "loss": 2.6014,
      "step": 389180
    },
    {
      "epoch": 625.72,
      "learning_rate": 0.03745359952395499,
      "loss": 2.5803,
      "step": 389200
    },
    {
      "epoch": 625.76,
      "learning_rate": 0.03745038409308682,
      "loss": 2.5947,
      "step": 389220
    },
    {
      "epoch": 625.79,
      "learning_rate": 0.03744716866221865,
      "loss": 2.583,
      "step": 389240
    },
    {
      "epoch": 625.82,
      "learning_rate": 0.03744395323135048,
      "loss": 2.5812,
      "step": 389260
    },
    {
      "epoch": 625.85,
      "learning_rate": 0.03744073780048232,
      "loss": 2.608,
      "step": 389280
    },
    {
      "epoch": 625.88,
      "learning_rate": 0.03743752236961415,
      "loss": 2.6086,
      "step": 389300
    },
    {
      "epoch": 625.92,
      "learning_rate": 0.037434306938745984,
      "loss": 2.5839,
      "step": 389320
    },
    {
      "epoch": 625.95,
      "learning_rate": 0.037431091507877816,
      "loss": 2.5616,
      "step": 389340
    },
    {
      "epoch": 625.98,
      "learning_rate": 0.03742787607700965,
      "loss": 2.5956,
      "step": 389360
    },
    {
      "epoch": 626.0,
      "eval_accuracy": {
        "accuracy": 0.4198864961517531
      },
      "eval_loss": 2.723748207092285,
      "eval_runtime": 2.7724,
      "eval_samples_per_second": 4639.645,
      "eval_steps_per_second": 72.5,
      "step": 389372
    },
    {
      "epoch": 626.01,
      "learning_rate": 0.03742466064614148,
      "loss": 2.5869,
      "step": 389380
    },
    {
      "epoch": 626.05,
      "learning_rate": 0.03742144521527332,
      "loss": 2.5905,
      "step": 389400
    },
    {
      "epoch": 626.08,
      "learning_rate": 0.03741822978440515,
      "loss": 2.5744,
      "step": 389420
    },
    {
      "epoch": 626.11,
      "learning_rate": 0.03741501435353698,
      "loss": 2.579,
      "step": 389440
    },
    {
      "epoch": 626.14,
      "learning_rate": 0.03741179892266881,
      "loss": 2.5756,
      "step": 389460
    },
    {
      "epoch": 626.17,
      "learning_rate": 0.037408583491800644,
      "loss": 2.5912,
      "step": 389480
    },
    {
      "epoch": 626.21,
      "learning_rate": 0.037405368060932476,
      "loss": 2.5577,
      "step": 389500
    },
    {
      "epoch": 626.24,
      "learning_rate": 0.037402152630064314,
      "loss": 2.5747,
      "step": 389520
    },
    {
      "epoch": 626.27,
      "learning_rate": 0.037398937199196146,
      "loss": 2.604,
      "step": 389540
    },
    {
      "epoch": 626.3,
      "learning_rate": 0.03739572176832798,
      "loss": 2.5787,
      "step": 389560
    },
    {
      "epoch": 626.33,
      "learning_rate": 0.03739250633745981,
      "loss": 2.6144,
      "step": 389580
    },
    {
      "epoch": 626.37,
      "learning_rate": 0.03738929090659164,
      "loss": 2.5764,
      "step": 389600
    },
    {
      "epoch": 626.4,
      "learning_rate": 0.03738607547572348,
      "loss": 2.5635,
      "step": 389620
    },
    {
      "epoch": 626.43,
      "learning_rate": 0.03738286004485531,
      "loss": 2.573,
      "step": 389640
    },
    {
      "epoch": 626.46,
      "learning_rate": 0.03737964461398714,
      "loss": 2.5836,
      "step": 389660
    },
    {
      "epoch": 626.5,
      "learning_rate": 0.037376429183118974,
      "loss": 2.5879,
      "step": 389680
    },
    {
      "epoch": 626.53,
      "learning_rate": 0.037373213752250806,
      "loss": 2.5841,
      "step": 389700
    },
    {
      "epoch": 626.56,
      "learning_rate": 0.03736999832138264,
      "loss": 2.5781,
      "step": 389720
    },
    {
      "epoch": 626.59,
      "learning_rate": 0.037366782890514476,
      "loss": 2.5794,
      "step": 389740
    },
    {
      "epoch": 626.62,
      "learning_rate": 0.03736356745964631,
      "loss": 2.5775,
      "step": 389760
    },
    {
      "epoch": 626.66,
      "learning_rate": 0.03736035202877814,
      "loss": 2.5953,
      "step": 389780
    },
    {
      "epoch": 626.69,
      "learning_rate": 0.03735713659790997,
      "loss": 2.5895,
      "step": 389800
    },
    {
      "epoch": 626.72,
      "learning_rate": 0.0373539211670418,
      "loss": 2.5973,
      "step": 389820
    },
    {
      "epoch": 626.75,
      "learning_rate": 0.037350705736173634,
      "loss": 2.5847,
      "step": 389840
    },
    {
      "epoch": 626.78,
      "learning_rate": 0.03734749030530547,
      "loss": 2.6027,
      "step": 389860
    },
    {
      "epoch": 626.82,
      "learning_rate": 0.037344274874437304,
      "loss": 2.5937,
      "step": 389880
    },
    {
      "epoch": 626.85,
      "learning_rate": 0.037341059443569136,
      "loss": 2.6102,
      "step": 389900
    },
    {
      "epoch": 626.88,
      "learning_rate": 0.03733784401270097,
      "loss": 2.5732,
      "step": 389920
    },
    {
      "epoch": 626.91,
      "learning_rate": 0.0373346285818328,
      "loss": 2.59,
      "step": 389940
    },
    {
      "epoch": 626.95,
      "learning_rate": 0.03733141315096464,
      "loss": 2.613,
      "step": 389960
    },
    {
      "epoch": 626.98,
      "learning_rate": 0.03732819772009647,
      "loss": 2.581,
      "step": 389980
    },
    {
      "epoch": 627.0,
      "eval_accuracy": {
        "accuracy": 0.4218300551970769
      },
      "eval_loss": 2.724581480026245,
      "eval_runtime": 2.8765,
      "eval_samples_per_second": 4471.739,
      "eval_steps_per_second": 69.876,
      "step": 389994
    },
    {
      "epoch": 627.01,
      "learning_rate": 0.0373249822892283,
      "loss": 2.6003,
      "step": 390000
    },
    {
      "epoch": 627.04,
      "learning_rate": 0.03732176685836013,
      "loss": 2.5799,
      "step": 390020
    },
    {
      "epoch": 627.07,
      "learning_rate": 0.037318551427491964,
      "loss": 2.5635,
      "step": 390040
    },
    {
      "epoch": 627.11,
      "learning_rate": 0.037315335996623795,
      "loss": 2.5668,
      "step": 390060
    },
    {
      "epoch": 627.14,
      "learning_rate": 0.037312120565755634,
      "loss": 2.5517,
      "step": 390080
    },
    {
      "epoch": 627.17,
      "learning_rate": 0.037308905134887466,
      "loss": 2.5952,
      "step": 390100
    },
    {
      "epoch": 627.2,
      "learning_rate": 0.0373056897040193,
      "loss": 2.6152,
      "step": 390120
    },
    {
      "epoch": 627.23,
      "learning_rate": 0.03730247427315113,
      "loss": 2.5535,
      "step": 390140
    },
    {
      "epoch": 627.27,
      "learning_rate": 0.03729925884228296,
      "loss": 2.584,
      "step": 390160
    },
    {
      "epoch": 627.3,
      "learning_rate": 0.03729604341141479,
      "loss": 2.5848,
      "step": 390180
    },
    {
      "epoch": 627.33,
      "learning_rate": 0.03729282798054663,
      "loss": 2.5813,
      "step": 390200
    },
    {
      "epoch": 627.36,
      "learning_rate": 0.03728961254967846,
      "loss": 2.5736,
      "step": 390220
    },
    {
      "epoch": 627.4,
      "learning_rate": 0.037286397118810294,
      "loss": 2.574,
      "step": 390240
    },
    {
      "epoch": 627.43,
      "learning_rate": 0.037283181687942125,
      "loss": 2.5908,
      "step": 390260
    },
    {
      "epoch": 627.46,
      "learning_rate": 0.03727996625707396,
      "loss": 2.5913,
      "step": 390280
    },
    {
      "epoch": 627.49,
      "learning_rate": 0.037276750826205796,
      "loss": 2.583,
      "step": 390300
    },
    {
      "epoch": 627.52,
      "learning_rate": 0.03727353539533763,
      "loss": 2.5853,
      "step": 390320
    },
    {
      "epoch": 627.56,
      "learning_rate": 0.03727031996446946,
      "loss": 2.5816,
      "step": 390340
    },
    {
      "epoch": 627.59,
      "learning_rate": 0.03726710453360129,
      "loss": 2.6016,
      "step": 390360
    },
    {
      "epoch": 627.62,
      "learning_rate": 0.03726388910273312,
      "loss": 2.5919,
      "step": 390380
    },
    {
      "epoch": 627.65,
      "learning_rate": 0.037260673671864954,
      "loss": 2.5789,
      "step": 390400
    },
    {
      "epoch": 627.68,
      "learning_rate": 0.03725745824099679,
      "loss": 2.5829,
      "step": 390420
    },
    {
      "epoch": 627.72,
      "learning_rate": 0.037254242810128624,
      "loss": 2.5861,
      "step": 390440
    },
    {
      "epoch": 627.75,
      "learning_rate": 0.037251027379260455,
      "loss": 2.6113,
      "step": 390460
    },
    {
      "epoch": 627.78,
      "learning_rate": 0.03724781194839229,
      "loss": 2.5593,
      "step": 390480
    },
    {
      "epoch": 627.81,
      "learning_rate": 0.03724459651752412,
      "loss": 2.5923,
      "step": 390500
    },
    {
      "epoch": 627.85,
      "learning_rate": 0.03724138108665595,
      "loss": 2.6041,
      "step": 390520
    },
    {
      "epoch": 627.88,
      "learning_rate": 0.03723816565578779,
      "loss": 2.5822,
      "step": 390540
    },
    {
      "epoch": 627.91,
      "learning_rate": 0.03723495022491962,
      "loss": 2.5888,
      "step": 390560
    },
    {
      "epoch": 627.94,
      "learning_rate": 0.03723173479405145,
      "loss": 2.5579,
      "step": 390580
    },
    {
      "epoch": 627.97,
      "learning_rate": 0.037228519363183284,
      "loss": 2.5649,
      "step": 390600
    },
    {
      "epoch": 628.0,
      "eval_accuracy": {
        "accuracy": 0.4255616885640986
      },
      "eval_loss": 2.699010133743286,
      "eval_runtime": 3.1749,
      "eval_samples_per_second": 4051.438,
      "eval_steps_per_second": 63.309,
      "step": 390616
    },
    {
      "epoch": 628.01,
      "learning_rate": 0.037225303932315115,
      "loss": 2.5653,
      "step": 390620
    },
    {
      "epoch": 628.04,
      "learning_rate": 0.037222088501446954,
      "loss": 2.5834,
      "step": 390640
    },
    {
      "epoch": 628.07,
      "learning_rate": 0.037218873070578785,
      "loss": 2.5669,
      "step": 390660
    },
    {
      "epoch": 628.1,
      "learning_rate": 0.03721565763971062,
      "loss": 2.568,
      "step": 390680
    },
    {
      "epoch": 628.14,
      "learning_rate": 0.03721244220884245,
      "loss": 2.5855,
      "step": 390700
    },
    {
      "epoch": 628.17,
      "learning_rate": 0.03720922677797428,
      "loss": 2.6106,
      "step": 390720
    },
    {
      "epoch": 628.2,
      "learning_rate": 0.037206011347106105,
      "loss": 2.5797,
      "step": 390740
    },
    {
      "epoch": 628.23,
      "learning_rate": 0.03720279591623795,
      "loss": 2.5772,
      "step": 390760
    },
    {
      "epoch": 628.26,
      "learning_rate": 0.03719958048536978,
      "loss": 2.5772,
      "step": 390780
    },
    {
      "epoch": 628.3,
      "learning_rate": 0.037196365054501614,
      "loss": 2.5869,
      "step": 390800
    },
    {
      "epoch": 628.33,
      "learning_rate": 0.037193149623633445,
      "loss": 2.6012,
      "step": 390820
    },
    {
      "epoch": 628.36,
      "learning_rate": 0.03718993419276528,
      "loss": 2.5746,
      "step": 390840
    },
    {
      "epoch": 628.39,
      "learning_rate": 0.037186718761897115,
      "loss": 2.5867,
      "step": 390860
    },
    {
      "epoch": 628.42,
      "learning_rate": 0.03718350333102895,
      "loss": 2.5663,
      "step": 390880
    },
    {
      "epoch": 628.46,
      "learning_rate": 0.03718028790016078,
      "loss": 2.5827,
      "step": 390900
    },
    {
      "epoch": 628.49,
      "learning_rate": 0.03717707246929261,
      "loss": 2.5914,
      "step": 390920
    },
    {
      "epoch": 628.52,
      "learning_rate": 0.03717385703842444,
      "loss": 2.5967,
      "step": 390940
    },
    {
      "epoch": 628.55,
      "learning_rate": 0.037170641607556267,
      "loss": 2.6032,
      "step": 390960
    },
    {
      "epoch": 628.59,
      "learning_rate": 0.03716742617668811,
      "loss": 2.5767,
      "step": 390980
    },
    {
      "epoch": 628.62,
      "learning_rate": 0.037164210745819944,
      "loss": 2.6104,
      "step": 391000
    },
    {
      "epoch": 628.65,
      "learning_rate": 0.037160995314951775,
      "loss": 2.5997,
      "step": 391020
    },
    {
      "epoch": 628.68,
      "learning_rate": 0.03715777988408361,
      "loss": 2.5525,
      "step": 391040
    },
    {
      "epoch": 628.71,
      "learning_rate": 0.03715456445321543,
      "loss": 2.5755,
      "step": 391060
    },
    {
      "epoch": 628.75,
      "learning_rate": 0.03715134902234726,
      "loss": 2.5655,
      "step": 391080
    },
    {
      "epoch": 628.78,
      "learning_rate": 0.03714813359147911,
      "loss": 2.5796,
      "step": 391100
    },
    {
      "epoch": 628.81,
      "learning_rate": 0.03714491816061094,
      "loss": 2.5908,
      "step": 391120
    },
    {
      "epoch": 628.84,
      "learning_rate": 0.03714186350128618,
      "loss": 2.5813,
      "step": 391140
    },
    {
      "epoch": 628.87,
      "learning_rate": 0.03713864807041801,
      "loss": 2.5765,
      "step": 391160
    },
    {
      "epoch": 628.91,
      "learning_rate": 0.03713543263954984,
      "loss": 2.5893,
      "step": 391180
    },
    {
      "epoch": 628.94,
      "learning_rate": 0.03713221720868167,
      "loss": 2.6114,
      "step": 391200
    },
    {
      "epoch": 628.97,
      "learning_rate": 0.0371290017778135,
      "loss": 2.5948,
      "step": 391220
    },
    {
      "epoch": 629.0,
      "eval_accuracy": {
        "accuracy": 0.4247065225841561
      },
      "eval_loss": 2.699894428253174,
      "eval_runtime": 3.3571,
      "eval_samples_per_second": 3831.569,
      "eval_steps_per_second": 59.873,
      "step": 391238
    },
    {
      "epoch": 629.0,
      "learning_rate": 0.03712578634694535,
      "loss": 2.5768,
      "step": 391240
    },
    {
      "epoch": 629.04,
      "learning_rate": 0.03712257091607718,
      "loss": 2.6059,
      "step": 391260
    },
    {
      "epoch": 629.07,
      "learning_rate": 0.037119355485209005,
      "loss": 2.5932,
      "step": 391280
    },
    {
      "epoch": 629.1,
      "learning_rate": 0.037116140054340836,
      "loss": 2.566,
      "step": 391300
    },
    {
      "epoch": 629.13,
      "learning_rate": 0.03711292462347267,
      "loss": 2.5663,
      "step": 391320
    },
    {
      "epoch": 629.16,
      "learning_rate": 0.03710970919260451,
      "loss": 2.5803,
      "step": 391340
    },
    {
      "epoch": 629.2,
      "learning_rate": 0.037106493761736345,
      "loss": 2.5634,
      "step": 391360
    },
    {
      "epoch": 629.23,
      "learning_rate": 0.03710327833086817,
      "loss": 2.569,
      "step": 391380
    },
    {
      "epoch": 629.26,
      "learning_rate": 0.0371000629,
      "loss": 2.6062,
      "step": 391400
    },
    {
      "epoch": 629.29,
      "learning_rate": 0.03709684746913183,
      "loss": 2.5878,
      "step": 391420
    },
    {
      "epoch": 629.32,
      "learning_rate": 0.037093632038263664,
      "loss": 2.5799,
      "step": 391440
    },
    {
      "epoch": 629.36,
      "learning_rate": 0.03709041660739551,
      "loss": 2.5708,
      "step": 391460
    },
    {
      "epoch": 629.39,
      "learning_rate": 0.037087201176527335,
      "loss": 2.5916,
      "step": 391480
    },
    {
      "epoch": 629.42,
      "learning_rate": 0.037083985745659166,
      "loss": 2.562,
      "step": 391500
    },
    {
      "epoch": 629.45,
      "learning_rate": 0.037080770314791,
      "loss": 2.5983,
      "step": 391520
    },
    {
      "epoch": 629.49,
      "learning_rate": 0.03707755488392283,
      "loss": 2.596,
      "step": 391540
    },
    {
      "epoch": 629.52,
      "learning_rate": 0.03707433945305466,
      "loss": 2.5932,
      "step": 391560
    },
    {
      "epoch": 629.55,
      "learning_rate": 0.03707112402218651,
      "loss": 2.5977,
      "step": 391580
    },
    {
      "epoch": 629.58,
      "learning_rate": 0.03706790859131833,
      "loss": 2.6034,
      "step": 391600
    },
    {
      "epoch": 629.61,
      "learning_rate": 0.03706469316045016,
      "loss": 2.5762,
      "step": 391620
    },
    {
      "epoch": 629.65,
      "learning_rate": 0.037061477729581994,
      "loss": 2.5951,
      "step": 391640
    },
    {
      "epoch": 629.68,
      "learning_rate": 0.037058262298713826,
      "loss": 2.5752,
      "step": 391660
    },
    {
      "epoch": 629.71,
      "learning_rate": 0.03705504686784567,
      "loss": 2.5737,
      "step": 391680
    },
    {
      "epoch": 629.74,
      "learning_rate": 0.037051831436977496,
      "loss": 2.5525,
      "step": 391700
    },
    {
      "epoch": 629.77,
      "learning_rate": 0.03704861600610933,
      "loss": 2.5942,
      "step": 391720
    },
    {
      "epoch": 629.81,
      "learning_rate": 0.03704540057524116,
      "loss": 2.5671,
      "step": 391740
    },
    {
      "epoch": 629.84,
      "learning_rate": 0.03704218514437299,
      "loss": 2.5685,
      "step": 391760
    },
    {
      "epoch": 629.87,
      "learning_rate": 0.03703896971350482,
      "loss": 2.565,
      "step": 391780
    },
    {
      "epoch": 629.9,
      "learning_rate": 0.03703575428263666,
      "loss": 2.5813,
      "step": 391800
    },
    {
      "epoch": 629.94,
      "learning_rate": 0.03703253885176849,
      "loss": 2.6003,
      "step": 391820
    },
    {
      "epoch": 629.97,
      "learning_rate": 0.037029323420900324,
      "loss": 2.5703,
      "step": 391840
    },
    {
      "epoch": 630.0,
      "learning_rate": 0.037026107990032156,
      "loss": 2.5946,
      "step": 391860
    },
    {
      "epoch": 630.0,
      "eval_accuracy": {
        "accuracy": 0.42618362745860217
      },
      "eval_loss": 2.7149498462677,
      "eval_runtime": 2.9144,
      "eval_samples_per_second": 4413.556,
      "eval_steps_per_second": 68.967,
      "step": 391860
    },
    {
      "epoch": 630.03,
      "learning_rate": 0.03702289255916399,
      "loss": 2.5717,
      "step": 391880
    },
    {
      "epoch": 630.06,
      "learning_rate": 0.03701967712829582,
      "loss": 2.5759,
      "step": 391900
    },
    {
      "epoch": 630.1,
      "learning_rate": 0.03701646169742766,
      "loss": 2.5663,
      "step": 391920
    },
    {
      "epoch": 630.13,
      "learning_rate": 0.03701324626655949,
      "loss": 2.5652,
      "step": 391940
    },
    {
      "epoch": 630.16,
      "learning_rate": 0.03701003083569132,
      "loss": 2.577,
      "step": 391960
    },
    {
      "epoch": 630.19,
      "learning_rate": 0.03700681540482315,
      "loss": 2.5814,
      "step": 391980
    },
    {
      "epoch": 630.23,
      "learning_rate": 0.037003599973954984,
      "loss": 2.5881,
      "step": 392000
    },
    {
      "epoch": 630.26,
      "learning_rate": 0.03700038454308682,
      "loss": 2.5693,
      "step": 392020
    },
    {
      "epoch": 630.29,
      "learning_rate": 0.036997169112218654,
      "loss": 2.5835,
      "step": 392040
    },
    {
      "epoch": 630.32,
      "learning_rate": 0.036993953681350486,
      "loss": 2.5791,
      "step": 392060
    },
    {
      "epoch": 630.35,
      "learning_rate": 0.03699073825048232,
      "loss": 2.5657,
      "step": 392080
    },
    {
      "epoch": 630.39,
      "learning_rate": 0.03698752281961415,
      "loss": 2.5844,
      "step": 392100
    },
    {
      "epoch": 630.42,
      "learning_rate": 0.03698430738874598,
      "loss": 2.5904,
      "step": 392120
    },
    {
      "epoch": 630.45,
      "learning_rate": 0.03698109195787782,
      "loss": 2.6153,
      "step": 392140
    },
    {
      "epoch": 630.48,
      "learning_rate": 0.03697787652700965,
      "loss": 2.5813,
      "step": 392160
    },
    {
      "epoch": 630.51,
      "learning_rate": 0.03697466109614148,
      "loss": 2.5733,
      "step": 392180
    },
    {
      "epoch": 630.55,
      "learning_rate": 0.036971445665273314,
      "loss": 2.5669,
      "step": 392200
    },
    {
      "epoch": 630.58,
      "learning_rate": 0.036968230234405146,
      "loss": 2.5894,
      "step": 392220
    },
    {
      "epoch": 630.61,
      "learning_rate": 0.03696501480353698,
      "loss": 2.5906,
      "step": 392240
    },
    {
      "epoch": 630.64,
      "learning_rate": 0.036961799372668816,
      "loss": 2.5822,
      "step": 392260
    },
    {
      "epoch": 630.68,
      "learning_rate": 0.03695858394180065,
      "loss": 2.5615,
      "step": 392280
    },
    {
      "epoch": 630.71,
      "learning_rate": 0.03695536851093248,
      "loss": 2.5863,
      "step": 392300
    },
    {
      "epoch": 630.74,
      "learning_rate": 0.03695215308006431,
      "loss": 2.5768,
      "step": 392320
    },
    {
      "epoch": 630.77,
      "learning_rate": 0.03694893764919614,
      "loss": 2.5784,
      "step": 392340
    },
    {
      "epoch": 630.8,
      "learning_rate": 0.03694572221832798,
      "loss": 2.5886,
      "step": 392360
    },
    {
      "epoch": 630.84,
      "learning_rate": 0.03694250678745981,
      "loss": 2.591,
      "step": 392380
    },
    {
      "epoch": 630.87,
      "learning_rate": 0.036939291356591644,
      "loss": 2.5739,
      "step": 392400
    },
    {
      "epoch": 630.9,
      "learning_rate": 0.036936075925723476,
      "loss": 2.5724,
      "step": 392420
    },
    {
      "epoch": 630.93,
      "learning_rate": 0.03693286049485531,
      "loss": 2.5967,
      "step": 392440
    },
    {
      "epoch": 630.96,
      "learning_rate": 0.03692964506398714,
      "loss": 2.5785,
      "step": 392460
    },
    {
      "epoch": 631.0,
      "learning_rate": 0.03692642963311898,
      "loss": 2.611,
      "step": 392480
    },
    {
      "epoch": 631.0,
      "eval_accuracy": {
        "accuracy": 0.4319365622327606
      },
      "eval_loss": 2.682830333709717,
      "eval_runtime": 3.338,
      "eval_samples_per_second": 3853.507,
      "eval_steps_per_second": 60.216,
      "step": 392482
    },
    {
      "epoch": 631.03,
      "learning_rate": 0.03692321420225081,
      "loss": 2.5823,
      "step": 392500
    },
    {
      "epoch": 631.06,
      "learning_rate": 0.03691999877138264,
      "loss": 2.5589,
      "step": 392520
    },
    {
      "epoch": 631.09,
      "learning_rate": 0.03691678334051447,
      "loss": 2.5715,
      "step": 392540
    },
    {
      "epoch": 631.13,
      "learning_rate": 0.036913567909646304,
      "loss": 2.5969,
      "step": 392560
    },
    {
      "epoch": 631.16,
      "learning_rate": 0.036910352478778136,
      "loss": 2.5894,
      "step": 392580
    },
    {
      "epoch": 631.19,
      "learning_rate": 0.036907137047909974,
      "loss": 2.5914,
      "step": 392600
    },
    {
      "epoch": 631.22,
      "learning_rate": 0.036903921617041806,
      "loss": 2.5812,
      "step": 392620
    },
    {
      "epoch": 631.25,
      "learning_rate": 0.03690070618617364,
      "loss": 2.5612,
      "step": 392640
    },
    {
      "epoch": 631.29,
      "learning_rate": 0.03689749075530547,
      "loss": 2.5808,
      "step": 392660
    },
    {
      "epoch": 631.32,
      "learning_rate": 0.0368942753244373,
      "loss": 2.5805,
      "step": 392680
    },
    {
      "epoch": 631.35,
      "learning_rate": 0.03689105989356914,
      "loss": 2.5935,
      "step": 392700
    },
    {
      "epoch": 631.38,
      "learning_rate": 0.03688784446270097,
      "loss": 2.5464,
      "step": 392720
    },
    {
      "epoch": 631.41,
      "learning_rate": 0.0368846290318328,
      "loss": 2.567,
      "step": 392740
    },
    {
      "epoch": 631.45,
      "learning_rate": 0.036881413600964634,
      "loss": 2.5745,
      "step": 392760
    },
    {
      "epoch": 631.48,
      "learning_rate": 0.036878198170096466,
      "loss": 2.573,
      "step": 392780
    },
    {
      "epoch": 631.51,
      "learning_rate": 0.0368749827392283,
      "loss": 2.5857,
      "step": 392800
    },
    {
      "epoch": 631.54,
      "learning_rate": 0.036871767308360136,
      "loss": 2.5786,
      "step": 392820
    },
    {
      "epoch": 631.58,
      "learning_rate": 0.03686855187749197,
      "loss": 2.597,
      "step": 392840
    },
    {
      "epoch": 631.61,
      "learning_rate": 0.0368653364466238,
      "loss": 2.5695,
      "step": 392860
    },
    {
      "epoch": 631.64,
      "learning_rate": 0.03686212101575563,
      "loss": 2.5965,
      "step": 392880
    },
    {
      "epoch": 631.67,
      "learning_rate": 0.03685890558488746,
      "loss": 2.5718,
      "step": 392900
    },
    {
      "epoch": 631.7,
      "learning_rate": 0.036855690154019294,
      "loss": 2.5858,
      "step": 392920
    },
    {
      "epoch": 631.74,
      "learning_rate": 0.03685247472315113,
      "loss": 2.576,
      "step": 392940
    },
    {
      "epoch": 631.77,
      "learning_rate": 0.036849259292282964,
      "loss": 2.5744,
      "step": 392960
    },
    {
      "epoch": 631.8,
      "learning_rate": 0.036846043861414796,
      "loss": 2.587,
      "step": 392980
    },
    {
      "epoch": 631.83,
      "learning_rate": 0.03684282843054663,
      "loss": 2.5852,
      "step": 393000
    },
    {
      "epoch": 631.86,
      "learning_rate": 0.03683961299967846,
      "loss": 2.5901,
      "step": 393020
    },
    {
      "epoch": 631.9,
      "learning_rate": 0.0368363975688103,
      "loss": 2.5762,
      "step": 393040
    },
    {
      "epoch": 631.93,
      "learning_rate": 0.03683318213794213,
      "loss": 2.5944,
      "step": 393060
    },
    {
      "epoch": 631.96,
      "learning_rate": 0.03682996670707396,
      "loss": 2.5583,
      "step": 393080
    },
    {
      "epoch": 631.99,
      "learning_rate": 0.03682675127620579,
      "loss": 2.5841,
      "step": 393100
    },
    {
      "epoch": 632.0,
      "eval_accuracy": {
        "accuracy": 0.4324807587654513
      },
      "eval_loss": 2.666574001312256,
      "eval_runtime": 3.2313,
      "eval_samples_per_second": 3980.731,
      "eval_steps_per_second": 62.204,
      "step": 393104
    },
    {
      "epoch": 632.03,
      "learning_rate": 0.036823535845337624,
      "loss": 2.5703,
      "step": 393120
    },
    {
      "epoch": 632.06,
      "learning_rate": 0.036820320414469455,
      "loss": 2.557,
      "step": 393140
    },
    {
      "epoch": 632.09,
      "learning_rate": 0.036817104983601294,
      "loss": 2.561,
      "step": 393160
    },
    {
      "epoch": 632.12,
      "learning_rate": 0.036813889552733126,
      "loss": 2.5475,
      "step": 393180
    },
    {
      "epoch": 632.15,
      "learning_rate": 0.03681067412186496,
      "loss": 2.581,
      "step": 393200
    },
    {
      "epoch": 632.19,
      "learning_rate": 0.03680745869099679,
      "loss": 2.5757,
      "step": 393220
    },
    {
      "epoch": 632.22,
      "learning_rate": 0.03680424326012862,
      "loss": 2.5781,
      "step": 393240
    },
    {
      "epoch": 632.25,
      "learning_rate": 0.03680102782926046,
      "loss": 2.5767,
      "step": 393260
    },
    {
      "epoch": 632.28,
      "learning_rate": 0.03679781239839229,
      "loss": 2.5588,
      "step": 393280
    },
    {
      "epoch": 632.32,
      "learning_rate": 0.03679459696752412,
      "loss": 2.5575,
      "step": 393300
    },
    {
      "epoch": 632.35,
      "learning_rate": 0.036791381536655954,
      "loss": 2.5912,
      "step": 393320
    },
    {
      "epoch": 632.38,
      "learning_rate": 0.036788166105787785,
      "loss": 2.571,
      "step": 393340
    },
    {
      "epoch": 632.41,
      "learning_rate": 0.03678495067491962,
      "loss": 2.5636,
      "step": 393360
    },
    {
      "epoch": 632.44,
      "learning_rate": 0.036781735244051456,
      "loss": 2.5645,
      "step": 393380
    },
    {
      "epoch": 632.48,
      "learning_rate": 0.03677851981318329,
      "loss": 2.5922,
      "step": 393400
    },
    {
      "epoch": 632.51,
      "learning_rate": 0.03677530438231512,
      "loss": 2.5966,
      "step": 393420
    },
    {
      "epoch": 632.54,
      "learning_rate": 0.03677208895144695,
      "loss": 2.5866,
      "step": 393440
    },
    {
      "epoch": 632.57,
      "learning_rate": 0.03676887352057878,
      "loss": 2.5768,
      "step": 393460
    },
    {
      "epoch": 632.6,
      "learning_rate": 0.03676565808971061,
      "loss": 2.5825,
      "step": 393480
    },
    {
      "epoch": 632.64,
      "learning_rate": 0.03676244265884245,
      "loss": 2.5961,
      "step": 393500
    },
    {
      "epoch": 632.67,
      "learning_rate": 0.036759227227974284,
      "loss": 2.602,
      "step": 393520
    },
    {
      "epoch": 632.7,
      "learning_rate": 0.036756011797106115,
      "loss": 2.6026,
      "step": 393540
    },
    {
      "epoch": 632.73,
      "learning_rate": 0.03675279636623795,
      "loss": 2.5534,
      "step": 393560
    },
    {
      "epoch": 632.77,
      "learning_rate": 0.03674958093536977,
      "loss": 2.5724,
      "step": 393580
    },
    {
      "epoch": 632.8,
      "learning_rate": 0.03674636550450162,
      "loss": 2.5829,
      "step": 393600
    },
    {
      "epoch": 632.83,
      "learning_rate": 0.03674315007363345,
      "loss": 2.5903,
      "step": 393620
    },
    {
      "epoch": 632.86,
      "learning_rate": 0.03673993464276528,
      "loss": 2.5865,
      "step": 393640
    },
    {
      "epoch": 632.89,
      "learning_rate": 0.03673671921189711,
      "loss": 2.5883,
      "step": 393660
    },
    {
      "epoch": 632.93,
      "learning_rate": 0.036733503781028944,
      "loss": 2.6089,
      "step": 393680
    },
    {
      "epoch": 632.96,
      "learning_rate": 0.03673028835016077,
      "loss": 2.5877,
      "step": 393700
    },
    {
      "epoch": 632.99,
      "learning_rate": 0.036727072919292614,
      "loss": 2.5833,
      "step": 393720
    },
    {
      "epoch": 633.0,
      "eval_accuracy": {
        "accuracy": 0.4324030164036383
      },
      "eval_loss": 2.6839375495910645,
      "eval_runtime": 3.1463,
      "eval_samples_per_second": 4088.337,
      "eval_steps_per_second": 63.885,
      "step": 393726
    },
    {
      "epoch": 633.02,
      "learning_rate": 0.036723857488424445,
      "loss": 2.564,
      "step": 393740
    },
    {
      "epoch": 633.05,
      "learning_rate": 0.03672064205755628,
      "loss": 2.5633,
      "step": 393760
    },
    {
      "epoch": 633.09,
      "learning_rate": 0.03671742662668811,
      "loss": 2.5607,
      "step": 393780
    },
    {
      "epoch": 633.12,
      "learning_rate": 0.03671421119581993,
      "loss": 2.5789,
      "step": 393800
    },
    {
      "epoch": 633.15,
      "learning_rate": 0.036710995764951765,
      "loss": 2.5797,
      "step": 393820
    },
    {
      "epoch": 633.18,
      "learning_rate": 0.03670778033408361,
      "loss": 2.5847,
      "step": 393840
    },
    {
      "epoch": 633.22,
      "learning_rate": 0.03670456490321544,
      "loss": 2.5982,
      "step": 393860
    },
    {
      "epoch": 633.25,
      "learning_rate": 0.036701349472347274,
      "loss": 2.591,
      "step": 393880
    },
    {
      "epoch": 633.28,
      "learning_rate": 0.0366981340414791,
      "loss": 2.5762,
      "step": 393900
    },
    {
      "epoch": 633.31,
      "learning_rate": 0.03669491861061093,
      "loss": 2.5654,
      "step": 393920
    },
    {
      "epoch": 633.34,
      "learning_rate": 0.036691703179742775,
      "loss": 2.5507,
      "step": 393940
    },
    {
      "epoch": 633.38,
      "learning_rate": 0.03668848774887461,
      "loss": 2.5733,
      "step": 393960
    },
    {
      "epoch": 633.41,
      "learning_rate": 0.03668527231800644,
      "loss": 2.5857,
      "step": 393980
    },
    {
      "epoch": 633.44,
      "learning_rate": 0.03668205688713827,
      "loss": 2.5686,
      "step": 394000
    },
    {
      "epoch": 633.47,
      "learning_rate": 0.036678841456270095,
      "loss": 2.5853,
      "step": 394020
    },
    {
      "epoch": 633.5,
      "learning_rate": 0.036675626025401926,
      "loss": 2.5814,
      "step": 394040
    },
    {
      "epoch": 633.54,
      "learning_rate": 0.03667241059453377,
      "loss": 2.576,
      "step": 394060
    },
    {
      "epoch": 633.57,
      "learning_rate": 0.036669195163665604,
      "loss": 2.6032,
      "step": 394080
    },
    {
      "epoch": 633.6,
      "learning_rate": 0.036665979732797435,
      "loss": 2.5957,
      "step": 394100
    },
    {
      "epoch": 633.63,
      "learning_rate": 0.03666276430192926,
      "loss": 2.5836,
      "step": 394120
    },
    {
      "epoch": 633.67,
      "learning_rate": 0.03665954887106109,
      "loss": 2.615,
      "step": 394140
    },
    {
      "epoch": 633.7,
      "learning_rate": 0.03665633344019292,
      "loss": 2.5818,
      "step": 394160
    },
    {
      "epoch": 633.73,
      "learning_rate": 0.03665311800932477,
      "loss": 2.5988,
      "step": 394180
    },
    {
      "epoch": 633.76,
      "learning_rate": 0.0366499025784566,
      "loss": 2.5711,
      "step": 394200
    },
    {
      "epoch": 633.79,
      "learning_rate": 0.036646687147588425,
      "loss": 2.5562,
      "step": 394220
    },
    {
      "epoch": 633.83,
      "learning_rate": 0.036643471716720256,
      "loss": 2.5806,
      "step": 394240
    },
    {
      "epoch": 633.86,
      "learning_rate": 0.03664025628585209,
      "loss": 2.5621,
      "step": 394260
    },
    {
      "epoch": 633.89,
      "learning_rate": 0.03663720162652733,
      "loss": 2.5859,
      "step": 394280
    },
    {
      "epoch": 633.92,
      "learning_rate": 0.03663398619565916,
      "loss": 2.6042,
      "step": 394300
    },
    {
      "epoch": 633.95,
      "learning_rate": 0.036630770764791,
      "loss": 2.5787,
      "step": 394320
    },
    {
      "epoch": 633.99,
      "learning_rate": 0.03662755533392283,
      "loss": 2.5763,
      "step": 394340
    },
    {
      "epoch": 634.0,
      "eval_accuracy": {
        "accuracy": 0.4269610510767317
      },
      "eval_loss": 2.6904051303863525,
      "eval_runtime": 3.1767,
      "eval_samples_per_second": 4049.186,
      "eval_steps_per_second": 63.273,
      "step": 394348
    },
    {
      "epoch": 634.02,
      "learning_rate": 0.036624339903054665,
      "loss": 2.5733,
      "step": 394360
    },
    {
      "epoch": 634.05,
      "learning_rate": 0.036621124472186496,
      "loss": 2.5928,
      "step": 394380
    },
    {
      "epoch": 634.08,
      "learning_rate": 0.03661790904131833,
      "loss": 2.59,
      "step": 394400
    },
    {
      "epoch": 634.12,
      "learning_rate": 0.03661469361045017,
      "loss": 2.6013,
      "step": 394420
    },
    {
      "epoch": 634.15,
      "learning_rate": 0.036611478179582,
      "loss": 2.5839,
      "step": 394440
    },
    {
      "epoch": 634.18,
      "learning_rate": 0.03660826274871383,
      "loss": 2.5631,
      "step": 394460
    },
    {
      "epoch": 634.21,
      "learning_rate": 0.03660504731784566,
      "loss": 2.5997,
      "step": 394480
    },
    {
      "epoch": 634.24,
      "learning_rate": 0.03660183188697749,
      "loss": 2.5701,
      "step": 394500
    },
    {
      "epoch": 634.28,
      "learning_rate": 0.036598616456109324,
      "loss": 2.5615,
      "step": 394520
    },
    {
      "epoch": 634.31,
      "learning_rate": 0.03659540102524116,
      "loss": 2.5719,
      "step": 394540
    },
    {
      "epoch": 634.34,
      "learning_rate": 0.036592185594372995,
      "loss": 2.5649,
      "step": 394560
    },
    {
      "epoch": 634.37,
      "learning_rate": 0.036588970163504826,
      "loss": 2.5651,
      "step": 394580
    },
    {
      "epoch": 634.41,
      "learning_rate": 0.03658575473263666,
      "loss": 2.555,
      "step": 394600
    },
    {
      "epoch": 634.44,
      "learning_rate": 0.03658253930176849,
      "loss": 2.585,
      "step": 394620
    },
    {
      "epoch": 634.47,
      "learning_rate": 0.03657932387090032,
      "loss": 2.6022,
      "step": 394640
    },
    {
      "epoch": 634.5,
      "learning_rate": 0.03657610844003216,
      "loss": 2.56,
      "step": 394660
    },
    {
      "epoch": 634.53,
      "learning_rate": 0.03657289300916399,
      "loss": 2.5867,
      "step": 394680
    },
    {
      "epoch": 634.57,
      "learning_rate": 0.03656967757829582,
      "loss": 2.5744,
      "step": 394700
    },
    {
      "epoch": 634.6,
      "learning_rate": 0.036566462147427654,
      "loss": 2.5511,
      "step": 394720
    },
    {
      "epoch": 634.63,
      "learning_rate": 0.036563246716559486,
      "loss": 2.5866,
      "step": 394740
    },
    {
      "epoch": 634.66,
      "learning_rate": 0.036560031285691325,
      "loss": 2.5931,
      "step": 394760
    },
    {
      "epoch": 634.69,
      "learning_rate": 0.036556815854823156,
      "loss": 2.5807,
      "step": 394780
    },
    {
      "epoch": 634.73,
      "learning_rate": 0.03655360042395499,
      "loss": 2.5754,
      "step": 394800
    },
    {
      "epoch": 634.76,
      "learning_rate": 0.03655038499308682,
      "loss": 2.5801,
      "step": 394820
    },
    {
      "epoch": 634.79,
      "learning_rate": 0.03654716956221865,
      "loss": 2.5647,
      "step": 394840
    },
    {
      "epoch": 634.82,
      "learning_rate": 0.03654395413135048,
      "loss": 2.5776,
      "step": 394860
    },
    {
      "epoch": 634.86,
      "learning_rate": 0.03654073870048232,
      "loss": 2.5884,
      "step": 394880
    },
    {
      "epoch": 634.89,
      "learning_rate": 0.03653752326961415,
      "loss": 2.5826,
      "step": 394900
    },
    {
      "epoch": 634.92,
      "learning_rate": 0.036534307838745984,
      "loss": 2.5976,
      "step": 394920
    },
    {
      "epoch": 634.95,
      "learning_rate": 0.036531092407877816,
      "loss": 2.5856,
      "step": 394940
    },
    {
      "epoch": 634.98,
      "learning_rate": 0.03652787697700965,
      "loss": 2.5928,
      "step": 394960
    },
    {
      "epoch": 635.0,
      "eval_accuracy": {
        "accuracy": 0.42711653580035763
      },
      "eval_loss": 2.71028208732605,
      "eval_runtime": 3.2423,
      "eval_samples_per_second": 3967.262,
      "eval_steps_per_second": 61.993,
      "step": 394970
    },
    {
      "epoch": 635.02,
      "learning_rate": 0.03652466154614148,
      "loss": 2.5293,
      "step": 394980
    },
    {
      "epoch": 635.05,
      "learning_rate": 0.03652144611527332,
      "loss": 2.5901,
      "step": 395000
    },
    {
      "epoch": 635.08,
      "learning_rate": 0.03651823068440515,
      "loss": 2.5917,
      "step": 395020
    },
    {
      "epoch": 635.11,
      "learning_rate": 0.03651501525353698,
      "loss": 2.5779,
      "step": 395040
    },
    {
      "epoch": 635.14,
      "learning_rate": 0.03651179982266881,
      "loss": 2.5576,
      "step": 395060
    },
    {
      "epoch": 635.18,
      "learning_rate": 0.036508584391800644,
      "loss": 2.5567,
      "step": 395080
    },
    {
      "epoch": 635.21,
      "learning_rate": 0.03650536896093248,
      "loss": 2.5782,
      "step": 395100
    },
    {
      "epoch": 635.24,
      "learning_rate": 0.036502153530064314,
      "loss": 2.5719,
      "step": 395120
    },
    {
      "epoch": 635.27,
      "learning_rate": 0.036498938099196146,
      "loss": 2.5798,
      "step": 395140
    },
    {
      "epoch": 635.31,
      "learning_rate": 0.03649572266832798,
      "loss": 2.5934,
      "step": 395160
    },
    {
      "epoch": 635.34,
      "learning_rate": 0.03649250723745981,
      "loss": 2.5942,
      "step": 395180
    },
    {
      "epoch": 635.37,
      "learning_rate": 0.03648929180659164,
      "loss": 2.5725,
      "step": 395200
    },
    {
      "epoch": 635.4,
      "learning_rate": 0.03648607637572348,
      "loss": 2.583,
      "step": 395220
    },
    {
      "epoch": 635.43,
      "learning_rate": 0.03648286094485531,
      "loss": 2.5719,
      "step": 395240
    },
    {
      "epoch": 635.47,
      "learning_rate": 0.03647964551398714,
      "loss": 2.5801,
      "step": 395260
    },
    {
      "epoch": 635.5,
      "learning_rate": 0.036476430083118974,
      "loss": 2.5819,
      "step": 395280
    },
    {
      "epoch": 635.53,
      "learning_rate": 0.036473214652250806,
      "loss": 2.5925,
      "step": 395300
    },
    {
      "epoch": 635.56,
      "learning_rate": 0.03646999922138264,
      "loss": 2.5837,
      "step": 395320
    },
    {
      "epoch": 635.59,
      "learning_rate": 0.036466783790514476,
      "loss": 2.5643,
      "step": 395340
    },
    {
      "epoch": 635.63,
      "learning_rate": 0.03646356835964631,
      "loss": 2.5795,
      "step": 395360
    },
    {
      "epoch": 635.66,
      "learning_rate": 0.03646035292877814,
      "loss": 2.5738,
      "step": 395380
    },
    {
      "epoch": 635.69,
      "learning_rate": 0.03645713749790997,
      "loss": 2.5952,
      "step": 395400
    },
    {
      "epoch": 635.72,
      "learning_rate": 0.0364539220670418,
      "loss": 2.5913,
      "step": 395420
    },
    {
      "epoch": 635.76,
      "learning_rate": 0.03645070663617364,
      "loss": 2.5693,
      "step": 395440
    },
    {
      "epoch": 635.79,
      "learning_rate": 0.03644749120530547,
      "loss": 2.566,
      "step": 395460
    },
    {
      "epoch": 635.82,
      "learning_rate": 0.036444275774437304,
      "loss": 2.5705,
      "step": 395480
    },
    {
      "epoch": 635.85,
      "learning_rate": 0.036441060343569136,
      "loss": 2.5587,
      "step": 395500
    },
    {
      "epoch": 635.88,
      "learning_rate": 0.03643784491270097,
      "loss": 2.5583,
      "step": 395520
    },
    {
      "epoch": 635.92,
      "learning_rate": 0.0364346294818328,
      "loss": 2.6046,
      "step": 395540
    },
    {
      "epoch": 635.95,
      "learning_rate": 0.03643141405096464,
      "loss": 2.5548,
      "step": 395560
    },
    {
      "epoch": 635.98,
      "learning_rate": 0.03642819862009647,
      "loss": 2.5846,
      "step": 395580
    },
    {
      "epoch": 636.0,
      "eval_accuracy": {
        "accuracy": 0.428127186503926
      },
      "eval_loss": 2.6861732006073,
      "eval_runtime": 3.122,
      "eval_samples_per_second": 4120.108,
      "eval_steps_per_second": 64.382,
      "step": 395592
    },
    {
      "epoch": 636.01,
      "learning_rate": 0.0364249831892283,
      "loss": 2.5873,
      "step": 395600
    },
    {
      "epoch": 636.05,
      "learning_rate": 0.03642176775836013,
      "loss": 2.5785,
      "step": 395620
    },
    {
      "epoch": 636.08,
      "learning_rate": 0.036418552327491964,
      "loss": 2.6011,
      "step": 395640
    },
    {
      "epoch": 636.11,
      "learning_rate": 0.036415336896623796,
      "loss": 2.6,
      "step": 395660
    },
    {
      "epoch": 636.14,
      "learning_rate": 0.036412121465755634,
      "loss": 2.5742,
      "step": 395680
    },
    {
      "epoch": 636.17,
      "learning_rate": 0.036408906034887466,
      "loss": 2.5712,
      "step": 395700
    },
    {
      "epoch": 636.21,
      "learning_rate": 0.0364056906040193,
      "loss": 2.5708,
      "step": 395720
    },
    {
      "epoch": 636.24,
      "learning_rate": 0.03640247517315113,
      "loss": 2.5913,
      "step": 395740
    },
    {
      "epoch": 636.27,
      "learning_rate": 0.03639925974228296,
      "loss": 2.5496,
      "step": 395760
    },
    {
      "epoch": 636.3,
      "learning_rate": 0.0363960443114148,
      "loss": 2.5927,
      "step": 395780
    },
    {
      "epoch": 636.33,
      "learning_rate": 0.03639282888054663,
      "loss": 2.5864,
      "step": 395800
    },
    {
      "epoch": 636.37,
      "learning_rate": 0.03638961344967846,
      "loss": 2.5813,
      "step": 395820
    },
    {
      "epoch": 636.4,
      "learning_rate": 0.036386398018810294,
      "loss": 2.5693,
      "step": 395840
    },
    {
      "epoch": 636.43,
      "learning_rate": 0.036383182587942126,
      "loss": 2.5741,
      "step": 395860
    },
    {
      "epoch": 636.46,
      "learning_rate": 0.03637996715707396,
      "loss": 2.568,
      "step": 395880
    },
    {
      "epoch": 636.5,
      "learning_rate": 0.036376751726205796,
      "loss": 2.5867,
      "step": 395900
    },
    {
      "epoch": 636.53,
      "learning_rate": 0.03637353629533763,
      "loss": 2.5812,
      "step": 395920
    },
    {
      "epoch": 636.56,
      "learning_rate": 0.03637032086446946,
      "loss": 2.5756,
      "step": 395940
    },
    {
      "epoch": 636.59,
      "learning_rate": 0.03636710543360129,
      "loss": 2.5625,
      "step": 395960
    },
    {
      "epoch": 636.62,
      "learning_rate": 0.03636389000273312,
      "loss": 2.6013,
      "step": 395980
    },
    {
      "epoch": 636.66,
      "learning_rate": 0.03636067457186496,
      "loss": 2.5835,
      "step": 396000
    },
    {
      "epoch": 636.69,
      "learning_rate": 0.03635745914099679,
      "loss": 2.5577,
      "step": 396020
    },
    {
      "epoch": 636.72,
      "learning_rate": 0.036354243710128624,
      "loss": 2.5619,
      "step": 396040
    },
    {
      "epoch": 636.75,
      "learning_rate": 0.036351028279260456,
      "loss": 2.5798,
      "step": 396060
    },
    {
      "epoch": 636.78,
      "learning_rate": 0.03634781284839229,
      "loss": 2.5749,
      "step": 396080
    },
    {
      "epoch": 636.82,
      "learning_rate": 0.03634459741752411,
      "loss": 2.5722,
      "step": 396100
    },
    {
      "epoch": 636.85,
      "learning_rate": 0.03634138198665596,
      "loss": 2.601,
      "step": 396120
    },
    {
      "epoch": 636.88,
      "learning_rate": 0.03633816655578779,
      "loss": 2.5736,
      "step": 396140
    },
    {
      "epoch": 636.91,
      "learning_rate": 0.03633495112491962,
      "loss": 2.5714,
      "step": 396160
    },
    {
      "epoch": 636.95,
      "learning_rate": 0.03633173569405145,
      "loss": 2.5972,
      "step": 396180
    },
    {
      "epoch": 636.98,
      "learning_rate": 0.036328520263183284,
      "loss": 2.597,
      "step": 396200
    },
    {
      "epoch": 637.0,
      "eval_accuracy": {
        "accuracy": 0.4291378372074944
      },
      "eval_loss": 2.6890347003936768,
      "eval_runtime": 3.0057,
      "eval_samples_per_second": 4279.466,
      "eval_steps_per_second": 66.872,
      "step": 396214
    },
    {
      "epoch": 637.01,
      "learning_rate": 0.03632530483231511,
      "loss": 2.5647,
      "step": 396220
    },
    {
      "epoch": 637.04,
      "learning_rate": 0.036322089401446954,
      "loss": 2.5846,
      "step": 396240
    },
    {
      "epoch": 637.07,
      "learning_rate": 0.036318873970578786,
      "loss": 2.5652,
      "step": 396260
    },
    {
      "epoch": 637.11,
      "learning_rate": 0.03631565853971062,
      "loss": 2.5707,
      "step": 396280
    },
    {
      "epoch": 637.14,
      "learning_rate": 0.03631244310884245,
      "loss": 2.5501,
      "step": 396300
    },
    {
      "epoch": 637.17,
      "learning_rate": 0.03630922767797427,
      "loss": 2.5736,
      "step": 396320
    },
    {
      "epoch": 637.2,
      "learning_rate": 0.03630601224710612,
      "loss": 2.5629,
      "step": 396340
    },
    {
      "epoch": 637.23,
      "learning_rate": 0.03630279681623795,
      "loss": 2.5835,
      "step": 396360
    },
    {
      "epoch": 637.27,
      "learning_rate": 0.03629958138536978,
      "loss": 2.5431,
      "step": 396380
    },
    {
      "epoch": 637.3,
      "learning_rate": 0.036296365954501614,
      "loss": 2.5838,
      "step": 396400
    },
    {
      "epoch": 637.33,
      "learning_rate": 0.03629331129517685,
      "loss": 2.5736,
      "step": 396420
    },
    {
      "epoch": 637.36,
      "learning_rate": 0.03629009586430868,
      "loss": 2.6117,
      "step": 396440
    },
    {
      "epoch": 637.4,
      "learning_rate": 0.03628688043344051,
      "loss": 2.5793,
      "step": 396460
    },
    {
      "epoch": 637.43,
      "learning_rate": 0.036283665002572345,
      "loss": 2.585,
      "step": 396480
    },
    {
      "epoch": 637.46,
      "learning_rate": 0.03628044957170419,
      "loss": 2.5626,
      "step": 396500
    },
    {
      "epoch": 637.49,
      "learning_rate": 0.036277234140836015,
      "loss": 2.5829,
      "step": 396520
    },
    {
      "epoch": 637.52,
      "learning_rate": 0.03627401870996785,
      "loss": 2.5712,
      "step": 396540
    },
    {
      "epoch": 637.56,
      "learning_rate": 0.03627080327909968,
      "loss": 2.5685,
      "step": 396560
    },
    {
      "epoch": 637.59,
      "learning_rate": 0.03626758784823151,
      "loss": 2.5661,
      "step": 396580
    },
    {
      "epoch": 637.62,
      "learning_rate": 0.036264372417363355,
      "loss": 2.5742,
      "step": 396600
    },
    {
      "epoch": 637.65,
      "learning_rate": 0.03626115698649519,
      "loss": 2.5731,
      "step": 396620
    },
    {
      "epoch": 637.68,
      "learning_rate": 0.03625794155562701,
      "loss": 2.57,
      "step": 396640
    },
    {
      "epoch": 637.72,
      "learning_rate": 0.03625472612475884,
      "loss": 2.577,
      "step": 396660
    },
    {
      "epoch": 637.75,
      "learning_rate": 0.036251510693890675,
      "loss": 2.571,
      "step": 396680
    },
    {
      "epoch": 637.78,
      "learning_rate": 0.036248295263022506,
      "loss": 2.5748,
      "step": 396700
    },
    {
      "epoch": 637.81,
      "learning_rate": 0.03624507983215435,
      "loss": 2.5695,
      "step": 396720
    },
    {
      "epoch": 637.85,
      "learning_rate": 0.03624186440128618,
      "loss": 2.5767,
      "step": 396740
    },
    {
      "epoch": 637.88,
      "learning_rate": 0.03623864897041801,
      "loss": 2.5568,
      "step": 396760
    },
    {
      "epoch": 637.91,
      "learning_rate": 0.03623543353954984,
      "loss": 2.5842,
      "step": 396780
    },
    {
      "epoch": 637.94,
      "learning_rate": 0.03623221810868167,
      "loss": 2.5694,
      "step": 396800
    },
    {
      "epoch": 637.97,
      "learning_rate": 0.03622900267781352,
      "loss": 2.5617,
      "step": 396820
    },
    {
      "epoch": 638.0,
      "eval_accuracy": {
        "accuracy": 0.4311591386146311
      },
      "eval_loss": 2.68441104888916,
      "eval_runtime": 3.0612,
      "eval_samples_per_second": 4201.988,
      "eval_steps_per_second": 65.661,
      "step": 396836
    },
    {
      "epoch": 638.01,
      "learning_rate": 0.03622578724694534,
      "loss": 2.5872,
      "step": 396840
    },
    {
      "epoch": 638.04,
      "learning_rate": 0.03622257181607717,
      "loss": 2.5589,
      "step": 396860
    },
    {
      "epoch": 638.07,
      "learning_rate": 0.036219356385209005,
      "loss": 2.5631,
      "step": 396880
    },
    {
      "epoch": 638.1,
      "learning_rate": 0.036216140954340836,
      "loss": 2.5823,
      "step": 396900
    },
    {
      "epoch": 638.14,
      "learning_rate": 0.03621292552347267,
      "loss": 2.5764,
      "step": 396920
    },
    {
      "epoch": 638.17,
      "learning_rate": 0.03620971009260451,
      "loss": 2.5788,
      "step": 396940
    },
    {
      "epoch": 638.2,
      "learning_rate": 0.03620649466173634,
      "loss": 2.5676,
      "step": 396960
    },
    {
      "epoch": 638.23,
      "learning_rate": 0.03620327923086817,
      "loss": 2.5503,
      "step": 396980
    },
    {
      "epoch": 638.26,
      "learning_rate": 0.0362000638,
      "loss": 2.5639,
      "step": 397000
    },
    {
      "epoch": 638.3,
      "learning_rate": 0.03619684836913183,
      "loss": 2.5641,
      "step": 397020
    },
    {
      "epoch": 638.33,
      "learning_rate": 0.036193632938263665,
      "loss": 2.5874,
      "step": 397040
    },
    {
      "epoch": 638.36,
      "learning_rate": 0.0361904175073955,
      "loss": 2.5815,
      "step": 397060
    },
    {
      "epoch": 638.39,
      "learning_rate": 0.036187202076527335,
      "loss": 2.5869,
      "step": 397080
    },
    {
      "epoch": 638.42,
      "learning_rate": 0.036183986645659166,
      "loss": 2.5797,
      "step": 397100
    },
    {
      "epoch": 638.46,
      "learning_rate": 0.036180771214791,
      "loss": 2.5542,
      "step": 397120
    },
    {
      "epoch": 638.49,
      "learning_rate": 0.03617755578392283,
      "loss": 2.5572,
      "step": 397140
    },
    {
      "epoch": 638.52,
      "learning_rate": 0.03617434035305467,
      "loss": 2.5636,
      "step": 397160
    },
    {
      "epoch": 638.55,
      "learning_rate": 0.0361711249221865,
      "loss": 2.5528,
      "step": 397180
    },
    {
      "epoch": 638.59,
      "learning_rate": 0.03616790949131833,
      "loss": 2.5766,
      "step": 397200
    },
    {
      "epoch": 638.62,
      "learning_rate": 0.03616469406045016,
      "loss": 2.5719,
      "step": 397220
    },
    {
      "epoch": 638.65,
      "learning_rate": 0.036161478629581995,
      "loss": 2.5568,
      "step": 397240
    },
    {
      "epoch": 638.68,
      "learning_rate": 0.036158263198713826,
      "loss": 2.5941,
      "step": 397260
    },
    {
      "epoch": 638.71,
      "learning_rate": 0.036155047767845665,
      "loss": 2.5778,
      "step": 397280
    },
    {
      "epoch": 638.75,
      "learning_rate": 0.036151832336977496,
      "loss": 2.5861,
      "step": 397300
    },
    {
      "epoch": 638.78,
      "learning_rate": 0.03614861690610933,
      "loss": 2.5767,
      "step": 397320
    },
    {
      "epoch": 638.81,
      "learning_rate": 0.03614540147524116,
      "loss": 2.5884,
      "step": 397340
    },
    {
      "epoch": 638.84,
      "learning_rate": 0.03614218604437299,
      "loss": 2.5923,
      "step": 397360
    },
    {
      "epoch": 638.87,
      "learning_rate": 0.03613897061350482,
      "loss": 2.5977,
      "step": 397380
    },
    {
      "epoch": 638.91,
      "learning_rate": 0.03613575518263666,
      "loss": 2.595,
      "step": 397400
    },
    {
      "epoch": 638.94,
      "learning_rate": 0.03613253975176849,
      "loss": 2.5638,
      "step": 397420
    },
    {
      "epoch": 638.97,
      "learning_rate": 0.036129324320900325,
      "loss": 2.5649,
      "step": 397440
    },
    {
      "epoch": 639.0,
      "eval_accuracy": {
        "accuracy": 0.42898235248386846
      },
      "eval_loss": 2.7018802165985107,
      "eval_runtime": 3.2531,
      "eval_samples_per_second": 3954.022,
      "eval_steps_per_second": 61.786,
      "step": 397458
    },
    {
      "epoch": 639.0,
      "learning_rate": 0.036126108890032156,
      "loss": 2.5748,
      "step": 397460
    },
    {
      "epoch": 639.04,
      "learning_rate": 0.03612289345916399,
      "loss": 2.5673,
      "step": 397480
    },
    {
      "epoch": 639.07,
      "learning_rate": 0.036119678028295826,
      "loss": 2.5925,
      "step": 397500
    },
    {
      "epoch": 639.1,
      "learning_rate": 0.03611646259742766,
      "loss": 2.5677,
      "step": 397520
    },
    {
      "epoch": 639.13,
      "learning_rate": 0.03611324716655949,
      "loss": 2.5782,
      "step": 397540
    },
    {
      "epoch": 639.16,
      "learning_rate": 0.03611003173569132,
      "loss": 2.5996,
      "step": 397560
    },
    {
      "epoch": 639.2,
      "learning_rate": 0.03610681630482315,
      "loss": 2.585,
      "step": 397580
    },
    {
      "epoch": 639.23,
      "learning_rate": 0.036103600873954984,
      "loss": 2.5826,
      "step": 397600
    },
    {
      "epoch": 639.26,
      "learning_rate": 0.03610038544308682,
      "loss": 2.5744,
      "step": 397620
    },
    {
      "epoch": 639.29,
      "learning_rate": 0.036097170012218655,
      "loss": 2.5772,
      "step": 397640
    },
    {
      "epoch": 639.32,
      "learning_rate": 0.036093954581350486,
      "loss": 2.5717,
      "step": 397660
    },
    {
      "epoch": 639.36,
      "learning_rate": 0.03609073915048232,
      "loss": 2.586,
      "step": 397680
    },
    {
      "epoch": 639.39,
      "learning_rate": 0.03608752371961415,
      "loss": 2.5732,
      "step": 397700
    },
    {
      "epoch": 639.42,
      "learning_rate": 0.03608430828874598,
      "loss": 2.5592,
      "step": 397720
    },
    {
      "epoch": 639.45,
      "learning_rate": 0.03608109285787782,
      "loss": 2.547,
      "step": 397740
    },
    {
      "epoch": 639.49,
      "learning_rate": 0.03607787742700965,
      "loss": 2.5896,
      "step": 397760
    },
    {
      "epoch": 639.52,
      "learning_rate": 0.03607466199614148,
      "loss": 2.5551,
      "step": 397780
    },
    {
      "epoch": 639.55,
      "learning_rate": 0.036071446565273314,
      "loss": 2.5844,
      "step": 397800
    },
    {
      "epoch": 639.58,
      "learning_rate": 0.036068231134405146,
      "loss": 2.5817,
      "step": 397820
    },
    {
      "epoch": 639.61,
      "learning_rate": 0.036065015703536984,
      "loss": 2.5708,
      "step": 397840
    },
    {
      "epoch": 639.65,
      "learning_rate": 0.036061800272668816,
      "loss": 2.5555,
      "step": 397860
    },
    {
      "epoch": 639.68,
      "learning_rate": 0.03605858484180065,
      "loss": 2.552,
      "step": 397880
    },
    {
      "epoch": 639.71,
      "learning_rate": 0.03605536941093248,
      "loss": 2.6109,
      "step": 397900
    },
    {
      "epoch": 639.74,
      "learning_rate": 0.03605215398006431,
      "loss": 2.5679,
      "step": 397920
    },
    {
      "epoch": 639.77,
      "learning_rate": 0.03604893854919614,
      "loss": 2.5786,
      "step": 397940
    },
    {
      "epoch": 639.81,
      "learning_rate": 0.03604572311832798,
      "loss": 2.5784,
      "step": 397960
    },
    {
      "epoch": 639.84,
      "learning_rate": 0.03604250768745981,
      "loss": 2.5583,
      "step": 397980
    },
    {
      "epoch": 639.87,
      "learning_rate": 0.036039292256591644,
      "loss": 2.5414,
      "step": 398000
    },
    {
      "epoch": 639.9,
      "learning_rate": 0.036036076825723476,
      "loss": 2.5683,
      "step": 398020
    },
    {
      "epoch": 639.94,
      "learning_rate": 0.03603286139485531,
      "loss": 2.5873,
      "step": 398040
    },
    {
      "epoch": 639.97,
      "learning_rate": 0.03602964596398714,
      "loss": 2.5735,
      "step": 398060
    },
    {
      "epoch": 640.0,
      "learning_rate": 0.03602643053311898,
      "loss": 2.5932,
      "step": 398080
    },
    {
      "epoch": 640.0,
      "eval_accuracy": {
        "accuracy": 0.4307704268055664
      },
      "eval_loss": 2.689033031463623,
      "eval_runtime": 2.9013,
      "eval_samples_per_second": 4433.552,
      "eval_steps_per_second": 69.28,
      "step": 398080
    },
    {
      "epoch": 640.03,
      "learning_rate": 0.03602321510225081,
      "loss": 2.5924,
      "step": 398100
    },
    {
      "epoch": 640.06,
      "learning_rate": 0.03601999967138264,
      "loss": 2.5862,
      "step": 398120
    },
    {
      "epoch": 640.1,
      "learning_rate": 0.03601678424051447,
      "loss": 2.5646,
      "step": 398140
    },
    {
      "epoch": 640.13,
      "learning_rate": 0.036013568809646304,
      "loss": 2.5653,
      "step": 398160
    },
    {
      "epoch": 640.16,
      "learning_rate": 0.03601035337877814,
      "loss": 2.5702,
      "step": 398180
    },
    {
      "epoch": 640.19,
      "learning_rate": 0.036007137947909974,
      "loss": 2.5656,
      "step": 398200
    },
    {
      "epoch": 640.23,
      "learning_rate": 0.036003922517041806,
      "loss": 2.5731,
      "step": 398220
    },
    {
      "epoch": 640.26,
      "learning_rate": 0.03600070708617364,
      "loss": 2.5809,
      "step": 398240
    },
    {
      "epoch": 640.29,
      "learning_rate": 0.03599749165530547,
      "loss": 2.5773,
      "step": 398260
    },
    {
      "epoch": 640.32,
      "learning_rate": 0.0359942762244373,
      "loss": 2.5522,
      "step": 398280
    },
    {
      "epoch": 640.35,
      "learning_rate": 0.03599106079356914,
      "loss": 2.5646,
      "step": 398300
    },
    {
      "epoch": 640.39,
      "learning_rate": 0.03598784536270097,
      "loss": 2.5758,
      "step": 398320
    },
    {
      "epoch": 640.42,
      "learning_rate": 0.0359846299318328,
      "loss": 2.5706,
      "step": 398340
    },
    {
      "epoch": 640.45,
      "learning_rate": 0.035981414500964634,
      "loss": 2.6056,
      "step": 398360
    },
    {
      "epoch": 640.48,
      "learning_rate": 0.035978199070096466,
      "loss": 2.5506,
      "step": 398380
    },
    {
      "epoch": 640.51,
      "learning_rate": 0.035974983639228304,
      "loss": 2.5709,
      "step": 398400
    },
    {
      "epoch": 640.55,
      "learning_rate": 0.035971768208360136,
      "loss": 2.5829,
      "step": 398420
    },
    {
      "epoch": 640.58,
      "learning_rate": 0.03596855277749197,
      "loss": 2.5699,
      "step": 398440
    },
    {
      "epoch": 640.61,
      "learning_rate": 0.0359653373466238,
      "loss": 2.5737,
      "step": 398460
    },
    {
      "epoch": 640.64,
      "learning_rate": 0.03596212191575563,
      "loss": 2.5668,
      "step": 398480
    },
    {
      "epoch": 640.68,
      "learning_rate": 0.03595890648488746,
      "loss": 2.5945,
      "step": 398500
    },
    {
      "epoch": 640.71,
      "learning_rate": 0.0359556910540193,
      "loss": 2.5691,
      "step": 398520
    },
    {
      "epoch": 640.74,
      "learning_rate": 0.03595247562315113,
      "loss": 2.5819,
      "step": 398540
    },
    {
      "epoch": 640.77,
      "learning_rate": 0.035949260192282964,
      "loss": 2.5675,
      "step": 398560
    },
    {
      "epoch": 640.8,
      "learning_rate": 0.035946044761414796,
      "loss": 2.5623,
      "step": 398580
    },
    {
      "epoch": 640.84,
      "learning_rate": 0.03594282933054663,
      "loss": 2.5479,
      "step": 398600
    },
    {
      "epoch": 640.87,
      "learning_rate": 0.03593961389967845,
      "loss": 2.576,
      "step": 398620
    },
    {
      "epoch": 640.9,
      "learning_rate": 0.0359363984688103,
      "loss": 2.5665,
      "step": 398640
    },
    {
      "epoch": 640.93,
      "learning_rate": 0.03593318303794213,
      "loss": 2.5678,
      "step": 398660
    },
    {
      "epoch": 640.96,
      "learning_rate": 0.03592996760707396,
      "loss": 2.5617,
      "step": 398680
    },
    {
      "epoch": 641.0,
      "learning_rate": 0.03592675217620579,
      "loss": 2.5778,
      "step": 398700
    },
    {
      "epoch": 641.0,
      "eval_accuracy": {
        "accuracy": 0.4342688330871492
      },
      "eval_loss": 2.676222562789917,
      "eval_runtime": 2.9138,
      "eval_samples_per_second": 4414.545,
      "eval_steps_per_second": 68.983,
      "step": 398702
    },
    {
      "epoch": 641.03,
      "learning_rate": 0.035923536745337624,
      "loss": 2.5549,
      "step": 398720
    },
    {
      "epoch": 641.06,
      "learning_rate": 0.03592032131446946,
      "loss": 2.5823,
      "step": 398740
    },
    {
      "epoch": 641.09,
      "learning_rate": 0.035917105883601294,
      "loss": 2.5771,
      "step": 398760
    },
    {
      "epoch": 641.13,
      "learning_rate": 0.035913890452733126,
      "loss": 2.5815,
      "step": 398780
    },
    {
      "epoch": 641.16,
      "learning_rate": 0.03591067502186496,
      "loss": 2.5436,
      "step": 398800
    },
    {
      "epoch": 641.19,
      "learning_rate": 0.03590745959099679,
      "loss": 2.5576,
      "step": 398820
    },
    {
      "epoch": 641.22,
      "learning_rate": 0.035904244160128614,
      "loss": 2.5409,
      "step": 398840
    },
    {
      "epoch": 641.25,
      "learning_rate": 0.03590102872926046,
      "loss": 2.5973,
      "step": 398860
    },
    {
      "epoch": 641.29,
      "learning_rate": 0.03589781329839229,
      "loss": 2.5976,
      "step": 398880
    },
    {
      "epoch": 641.32,
      "learning_rate": 0.03589459786752412,
      "loss": 2.5549,
      "step": 398900
    },
    {
      "epoch": 641.35,
      "learning_rate": 0.035891382436655954,
      "loss": 2.5708,
      "step": 398920
    },
    {
      "epoch": 641.38,
      "learning_rate": 0.03588816700578778,
      "loss": 2.5772,
      "step": 398940
    },
    {
      "epoch": 641.41,
      "learning_rate": 0.03588495157491961,
      "loss": 2.575,
      "step": 398960
    },
    {
      "epoch": 641.45,
      "learning_rate": 0.035881736144051456,
      "loss": 2.5919,
      "step": 398980
    },
    {
      "epoch": 641.48,
      "learning_rate": 0.03587852071318329,
      "loss": 2.5814,
      "step": 399000
    },
    {
      "epoch": 641.51,
      "learning_rate": 0.03587530528231512,
      "loss": 2.55,
      "step": 399020
    },
    {
      "epoch": 641.54,
      "learning_rate": 0.03587208985144695,
      "loss": 2.5724,
      "step": 399040
    },
    {
      "epoch": 641.58,
      "learning_rate": 0.035868874420578775,
      "loss": 2.5875,
      "step": 399060
    },
    {
      "epoch": 641.61,
      "learning_rate": 0.03586565898971062,
      "loss": 2.5993,
      "step": 399080
    },
    {
      "epoch": 641.64,
      "learning_rate": 0.03586244355884245,
      "loss": 2.5949,
      "step": 399100
    },
    {
      "epoch": 641.67,
      "learning_rate": 0.035859228127974284,
      "loss": 2.5681,
      "step": 399120
    },
    {
      "epoch": 641.7,
      "learning_rate": 0.035856012697106115,
      "loss": 2.5564,
      "step": 399140
    },
    {
      "epoch": 641.74,
      "learning_rate": 0.03585279726623794,
      "loss": 2.5776,
      "step": 399160
    },
    {
      "epoch": 641.77,
      "learning_rate": 0.03584958183536977,
      "loss": 2.5721,
      "step": 399180
    },
    {
      "epoch": 641.8,
      "learning_rate": 0.03584636640450162,
      "loss": 2.5844,
      "step": 399200
    },
    {
      "epoch": 641.83,
      "learning_rate": 0.03584315097363345,
      "loss": 2.5836,
      "step": 399220
    },
    {
      "epoch": 641.86,
      "learning_rate": 0.03583993554276528,
      "loss": 2.5928,
      "step": 399240
    },
    {
      "epoch": 641.9,
      "learning_rate": 0.03583672011189711,
      "loss": 2.5898,
      "step": 399260
    },
    {
      "epoch": 641.93,
      "learning_rate": 0.03583350468102894,
      "loss": 2.6008,
      "step": 399280
    },
    {
      "epoch": 641.96,
      "learning_rate": 0.03583028925016077,
      "loss": 2.5719,
      "step": 399300
    },
    {
      "epoch": 641.99,
      "learning_rate": 0.035827073819292614,
      "loss": 2.5718,
      "step": 399320
    },
    {
      "epoch": 642.0,
      "eval_accuracy": {
        "accuracy": 0.4323252740418254
      },
      "eval_loss": 2.6947290897369385,
      "eval_runtime": 3.2918,
      "eval_samples_per_second": 3907.555,
      "eval_steps_per_second": 61.06,
      "step": 399324
    },
    {
      "epoch": 642.03,
      "learning_rate": 0.035823858388424445,
      "loss": 2.594,
      "step": 399340
    },
    {
      "epoch": 642.06,
      "learning_rate": 0.03582064295755628,
      "loss": 2.5761,
      "step": 399360
    },
    {
      "epoch": 642.09,
      "learning_rate": 0.0358174275266881,
      "loss": 2.5879,
      "step": 399380
    },
    {
      "epoch": 642.12,
      "learning_rate": 0.03581421209581993,
      "loss": 2.595,
      "step": 399400
    },
    {
      "epoch": 642.15,
      "learning_rate": 0.03581099666495178,
      "loss": 2.5901,
      "step": 399420
    },
    {
      "epoch": 642.19,
      "learning_rate": 0.03580778123408361,
      "loss": 2.5771,
      "step": 399440
    },
    {
      "epoch": 642.22,
      "learning_rate": 0.03580456580321544,
      "loss": 2.5798,
      "step": 399460
    },
    {
      "epoch": 642.25,
      "learning_rate": 0.03580135037234727,
      "loss": 2.5623,
      "step": 399480
    },
    {
      "epoch": 642.28,
      "learning_rate": 0.0357981349414791,
      "loss": 2.5666,
      "step": 399500
    },
    {
      "epoch": 642.32,
      "learning_rate": 0.03579491951061093,
      "loss": 2.5748,
      "step": 399520
    },
    {
      "epoch": 642.35,
      "learning_rate": 0.035791704079742775,
      "loss": 2.5857,
      "step": 399540
    },
    {
      "epoch": 642.38,
      "learning_rate": 0.03578848864887461,
      "loss": 2.5643,
      "step": 399560
    },
    {
      "epoch": 642.41,
      "learning_rate": 0.03578527321800644,
      "loss": 2.5593,
      "step": 399580
    },
    {
      "epoch": 642.44,
      "learning_rate": 0.03578205778713826,
      "loss": 2.5893,
      "step": 399600
    },
    {
      "epoch": 642.48,
      "learning_rate": 0.035778842356270095,
      "loss": 2.5768,
      "step": 399620
    },
    {
      "epoch": 642.51,
      "learning_rate": 0.03577562692540193,
      "loss": 2.5869,
      "step": 399640
    },
    {
      "epoch": 642.54,
      "learning_rate": 0.03577241149453377,
      "loss": 2.5664,
      "step": 399660
    },
    {
      "epoch": 642.57,
      "learning_rate": 0.035769196063665604,
      "loss": 2.5348,
      "step": 399680
    },
    {
      "epoch": 642.6,
      "learning_rate": 0.03576598063279743,
      "loss": 2.5797,
      "step": 399700
    },
    {
      "epoch": 642.64,
      "learning_rate": 0.03576276520192926,
      "loss": 2.566,
      "step": 399720
    },
    {
      "epoch": 642.67,
      "learning_rate": 0.03575954977106109,
      "loss": 2.583,
      "step": 399740
    },
    {
      "epoch": 642.7,
      "learning_rate": 0.03575633434019294,
      "loss": 2.5812,
      "step": 399760
    },
    {
      "epoch": 642.73,
      "learning_rate": 0.03575311890932477,
      "loss": 2.5576,
      "step": 399780
    },
    {
      "epoch": 642.77,
      "learning_rate": 0.03574990347845659,
      "loss": 2.557,
      "step": 399800
    },
    {
      "epoch": 642.8,
      "learning_rate": 0.035746688047588425,
      "loss": 2.5711,
      "step": 399820
    },
    {
      "epoch": 642.83,
      "learning_rate": 0.03574347261672026,
      "loss": 2.5942,
      "step": 399840
    },
    {
      "epoch": 642.86,
      "learning_rate": 0.03574025718585209,
      "loss": 2.5749,
      "step": 399860
    },
    {
      "epoch": 642.89,
      "learning_rate": 0.035737041754983934,
      "loss": 2.5777,
      "step": 399880
    },
    {
      "epoch": 642.93,
      "learning_rate": 0.035733826324115765,
      "loss": 2.5914,
      "step": 399900
    },
    {
      "epoch": 642.96,
      "learning_rate": 0.03573061089324759,
      "loss": 2.5756,
      "step": 399920
    },
    {
      "epoch": 642.99,
      "learning_rate": 0.03572739546237942,
      "loss": 2.5506,
      "step": 399940
    },
    {
      "epoch": 643.0,
      "eval_accuracy": {
        "accuracy": 0.42478426494596905
      },
      "eval_loss": 2.686906576156616,
      "eval_runtime": 3.0815,
      "eval_samples_per_second": 4174.296,
      "eval_steps_per_second": 65.228,
      "step": 399946
    },
    {
      "epoch": 643.02,
      "learning_rate": 0.03572418003151125,
      "loss": 2.5827,
      "step": 399960
    },
    {
      "epoch": 643.05,
      "learning_rate": 0.035720964600643085,
      "loss": 2.5531,
      "step": 399980
    },
    {
      "epoch": 643.09,
      "learning_rate": 0.03571774916977493,
      "loss": 2.5694,
      "step": 400000
    },
    {
      "epoch": 643.12,
      "learning_rate": 0.035714533738906755,
      "loss": 2.564,
      "step": 400020
    },
    {
      "epoch": 643.15,
      "learning_rate": 0.03571131830803859,
      "loss": 2.5611,
      "step": 400040
    },
    {
      "epoch": 643.18,
      "learning_rate": 0.03570810287717042,
      "loss": 2.5537,
      "step": 400060
    },
    {
      "epoch": 643.22,
      "learning_rate": 0.03570488744630225,
      "loss": 2.5642,
      "step": 400080
    },
    {
      "epoch": 643.25,
      "learning_rate": 0.035701672015434095,
      "loss": 2.5545,
      "step": 400100
    },
    {
      "epoch": 643.28,
      "learning_rate": 0.03569845658456592,
      "loss": 2.545,
      "step": 400120
    },
    {
      "epoch": 643.31,
      "learning_rate": 0.03569524115369775,
      "loss": 2.5526,
      "step": 400140
    },
    {
      "epoch": 643.34,
      "learning_rate": 0.03569202572282958,
      "loss": 2.561,
      "step": 400160
    },
    {
      "epoch": 643.38,
      "learning_rate": 0.035688810291961415,
      "loss": 2.5775,
      "step": 400180
    },
    {
      "epoch": 643.41,
      "learning_rate": 0.035685594861093246,
      "loss": 2.5966,
      "step": 400200
    },
    {
      "epoch": 643.44,
      "learning_rate": 0.03568237943022509,
      "loss": 2.5951,
      "step": 400220
    },
    {
      "epoch": 643.47,
      "learning_rate": 0.035679163999356917,
      "loss": 2.5563,
      "step": 400240
    },
    {
      "epoch": 643.5,
      "learning_rate": 0.03567594856848875,
      "loss": 2.5754,
      "step": 400260
    },
    {
      "epoch": 643.54,
      "learning_rate": 0.03567273313762058,
      "loss": 2.5571,
      "step": 400280
    },
    {
      "epoch": 643.57,
      "learning_rate": 0.03566951770675241,
      "loss": 2.5656,
      "step": 400300
    },
    {
      "epoch": 643.6,
      "learning_rate": 0.03566630227588426,
      "loss": 2.5799,
      "step": 400320
    },
    {
      "epoch": 643.63,
      "learning_rate": 0.03566308684501608,
      "loss": 2.5753,
      "step": 400340
    },
    {
      "epoch": 643.67,
      "learning_rate": 0.03565987141414791,
      "loss": 2.5674,
      "step": 400360
    },
    {
      "epoch": 643.7,
      "learning_rate": 0.035656655983279745,
      "loss": 2.5912,
      "step": 400380
    },
    {
      "epoch": 643.73,
      "learning_rate": 0.035653440552411576,
      "loss": 2.5748,
      "step": 400400
    },
    {
      "epoch": 643.76,
      "learning_rate": 0.03565038589308682,
      "loss": 2.5818,
      "step": 400420
    },
    {
      "epoch": 643.79,
      "learning_rate": 0.03564717046221865,
      "loss": 2.5861,
      "step": 400440
    },
    {
      "epoch": 643.83,
      "learning_rate": 0.03564395503135048,
      "loss": 2.5736,
      "step": 400460
    },
    {
      "epoch": 643.86,
      "learning_rate": 0.03564073960048232,
      "loss": 2.5665,
      "step": 400480
    },
    {
      "epoch": 643.89,
      "learning_rate": 0.03563752416961415,
      "loss": 2.5819,
      "step": 400500
    },
    {
      "epoch": 643.92,
      "learning_rate": 0.035634308738745984,
      "loss": 2.5577,
      "step": 400520
    },
    {
      "epoch": 643.95,
      "learning_rate": 0.035631093307877816,
      "loss": 2.5637,
      "step": 400540
    },
    {
      "epoch": 643.99,
      "learning_rate": 0.03562787787700965,
      "loss": 2.5746,
      "step": 400560
    },
    {
      "epoch": 644.0,
      "eval_accuracy": {
        "accuracy": 0.42657233926766697
      },
      "eval_loss": 2.695042848587036,
      "eval_runtime": 3.0997,
      "eval_samples_per_second": 4149.792,
      "eval_steps_per_second": 64.846,
      "step": 400568
    },
    {
      "epoch": 644.02,
      "learning_rate": 0.035624662446141486,
      "loss": 2.5945,
      "step": 400580
    },
    {
      "epoch": 644.05,
      "learning_rate": 0.03562144701527332,
      "loss": 2.5739,
      "step": 400600
    },
    {
      "epoch": 644.08,
      "learning_rate": 0.03561823158440515,
      "loss": 2.579,
      "step": 400620
    },
    {
      "epoch": 644.12,
      "learning_rate": 0.03561501615353698,
      "loss": 2.565,
      "step": 400640
    },
    {
      "epoch": 644.15,
      "learning_rate": 0.03561180072266881,
      "loss": 2.5567,
      "step": 400660
    },
    {
      "epoch": 644.18,
      "learning_rate": 0.035608585291800644,
      "loss": 2.5843,
      "step": 400680
    },
    {
      "epoch": 644.21,
      "learning_rate": 0.03560536986093248,
      "loss": 2.5602,
      "step": 400700
    },
    {
      "epoch": 644.24,
      "learning_rate": 0.035602154430064314,
      "loss": 2.5752,
      "step": 400720
    },
    {
      "epoch": 644.28,
      "learning_rate": 0.035598938999196146,
      "loss": 2.5868,
      "step": 400740
    },
    {
      "epoch": 644.31,
      "learning_rate": 0.03559572356832798,
      "loss": 2.5667,
      "step": 400760
    },
    {
      "epoch": 644.34,
      "learning_rate": 0.03559250813745981,
      "loss": 2.5893,
      "step": 400780
    },
    {
      "epoch": 644.37,
      "learning_rate": 0.03558929270659164,
      "loss": 2.5665,
      "step": 400800
    },
    {
      "epoch": 644.41,
      "learning_rate": 0.03558607727572348,
      "loss": 2.5459,
      "step": 400820
    },
    {
      "epoch": 644.44,
      "learning_rate": 0.03558286184485531,
      "loss": 2.6081,
      "step": 400840
    },
    {
      "epoch": 644.47,
      "learning_rate": 0.03557964641398714,
      "loss": 2.5838,
      "step": 400860
    },
    {
      "epoch": 644.5,
      "learning_rate": 0.035576430983118974,
      "loss": 2.5759,
      "step": 400880
    },
    {
      "epoch": 644.53,
      "learning_rate": 0.035573215552250806,
      "loss": 2.5562,
      "step": 400900
    },
    {
      "epoch": 644.57,
      "learning_rate": 0.035570000121382644,
      "loss": 2.577,
      "step": 400920
    },
    {
      "epoch": 644.6,
      "learning_rate": 0.035566784690514476,
      "loss": 2.5668,
      "step": 400940
    },
    {
      "epoch": 644.63,
      "learning_rate": 0.03556356925964631,
      "loss": 2.5588,
      "step": 400960
    },
    {
      "epoch": 644.66,
      "learning_rate": 0.03556035382877814,
      "loss": 2.5813,
      "step": 400980
    },
    {
      "epoch": 644.69,
      "learning_rate": 0.03555713839790997,
      "loss": 2.5556,
      "step": 401000
    },
    {
      "epoch": 644.73,
      "learning_rate": 0.0355539229670418,
      "loss": 2.5601,
      "step": 401020
    },
    {
      "epoch": 644.76,
      "learning_rate": 0.03555070753617364,
      "loss": 2.5434,
      "step": 401040
    },
    {
      "epoch": 644.79,
      "learning_rate": 0.03554749210530547,
      "loss": 2.5635,
      "step": 401060
    },
    {
      "epoch": 644.82,
      "learning_rate": 0.035544276674437304,
      "loss": 2.563,
      "step": 401080
    },
    {
      "epoch": 644.86,
      "learning_rate": 0.035541061243569136,
      "loss": 2.5776,
      "step": 401100
    },
    {
      "epoch": 644.89,
      "learning_rate": 0.03553784581270097,
      "loss": 2.5666,
      "step": 401120
    },
    {
      "epoch": 644.92,
      "learning_rate": 0.035534630381832806,
      "loss": 2.5571,
      "step": 401140
    },
    {
      "epoch": 644.95,
      "learning_rate": 0.03553141495096464,
      "loss": 2.5758,
      "step": 401160
    },
    {
      "epoch": 644.98,
      "learning_rate": 0.03552819952009647,
      "loss": 2.5922,
      "step": 401180
    },
    {
      "epoch": 645.0,
      "eval_accuracy": {
        "accuracy": 0.4274275052476094
      },
      "eval_loss": 2.6723484992980957,
      "eval_runtime": 3.2087,
      "eval_samples_per_second": 4008.727,
      "eval_steps_per_second": 62.641,
      "step": 401190
    },
    {
      "epoch": 645.02,
      "learning_rate": 0.0355249840892283,
      "loss": 2.5715,
      "step": 401200
    },
    {
      "epoch": 645.05,
      "learning_rate": 0.03552176865836013,
      "loss": 2.5824,
      "step": 401220
    },
    {
      "epoch": 645.08,
      "learning_rate": 0.035518553227491964,
      "loss": 2.5537,
      "step": 401240
    },
    {
      "epoch": 645.11,
      "learning_rate": 0.0355153377966238,
      "loss": 2.5582,
      "step": 401260
    },
    {
      "epoch": 645.14,
      "learning_rate": 0.035512122365755634,
      "loss": 2.5664,
      "step": 401280
    },
    {
      "epoch": 645.18,
      "learning_rate": 0.035508906934887466,
      "loss": 2.5655,
      "step": 401300
    },
    {
      "epoch": 645.21,
      "learning_rate": 0.0355056915040193,
      "loss": 2.5773,
      "step": 401320
    },
    {
      "epoch": 645.24,
      "learning_rate": 0.03550247607315113,
      "loss": 2.5485,
      "step": 401340
    },
    {
      "epoch": 645.27,
      "learning_rate": 0.035499260642282954,
      "loss": 2.5912,
      "step": 401360
    },
    {
      "epoch": 645.31,
      "learning_rate": 0.0354960452114148,
      "loss": 2.5506,
      "step": 401380
    },
    {
      "epoch": 645.34,
      "learning_rate": 0.03549282978054663,
      "loss": 2.5682,
      "step": 401400
    },
    {
      "epoch": 645.37,
      "learning_rate": 0.03548961434967846,
      "loss": 2.5509,
      "step": 401420
    },
    {
      "epoch": 645.4,
      "learning_rate": 0.035486398918810294,
      "loss": 2.5867,
      "step": 401440
    },
    {
      "epoch": 645.43,
      "learning_rate": 0.035483183487942126,
      "loss": 2.5789,
      "step": 401460
    },
    {
      "epoch": 645.47,
      "learning_rate": 0.035479968057073964,
      "loss": 2.5526,
      "step": 401480
    },
    {
      "epoch": 645.5,
      "learning_rate": 0.035476752626205796,
      "loss": 2.5461,
      "step": 401500
    },
    {
      "epoch": 645.53,
      "learning_rate": 0.03547353719533763,
      "loss": 2.5554,
      "step": 401520
    },
    {
      "epoch": 645.56,
      "learning_rate": 0.03547032176446946,
      "loss": 2.5652,
      "step": 401540
    },
    {
      "epoch": 645.59,
      "learning_rate": 0.03546710633360129,
      "loss": 2.5746,
      "step": 401560
    },
    {
      "epoch": 645.63,
      "learning_rate": 0.035463890902733115,
      "loss": 2.5525,
      "step": 401580
    },
    {
      "epoch": 645.66,
      "learning_rate": 0.03546067547186496,
      "loss": 2.5614,
      "step": 401600
    },
    {
      "epoch": 645.69,
      "learning_rate": 0.03545746004099679,
      "loss": 2.5908,
      "step": 401620
    },
    {
      "epoch": 645.72,
      "learning_rate": 0.035454244610128624,
      "loss": 2.573,
      "step": 401640
    },
    {
      "epoch": 645.76,
      "learning_rate": 0.035451029179260456,
      "loss": 2.5566,
      "step": 401660
    },
    {
      "epoch": 645.79,
      "learning_rate": 0.03544797451993569,
      "loss": 2.579,
      "step": 401680
    },
    {
      "epoch": 645.82,
      "learning_rate": 0.035444759089067523,
      "loss": 2.5536,
      "step": 401700
    },
    {
      "epoch": 645.85,
      "learning_rate": 0.035441543658199355,
      "loss": 2.5694,
      "step": 401720
    },
    {
      "epoch": 645.88,
      "learning_rate": 0.0354383282273312,
      "loss": 2.5582,
      "step": 401740
    },
    {
      "epoch": 645.92,
      "learning_rate": 0.03543511279646303,
      "loss": 2.5619,
      "step": 401760
    },
    {
      "epoch": 645.95,
      "learning_rate": 0.03543189736559486,
      "loss": 2.5689,
      "step": 401780
    },
    {
      "epoch": 645.98,
      "learning_rate": 0.03542868193472669,
      "loss": 2.5806,
      "step": 401800
    },
    {
      "epoch": 646.0,
      "eval_accuracy": {
        "accuracy": 0.4275052476094224
      },
      "eval_loss": 2.7048189640045166,
      "eval_runtime": 3.1175,
      "eval_samples_per_second": 4126.048,
      "eval_steps_per_second": 64.475,
      "step": 401812
    },
    {
      "epoch": 646.01,
      "learning_rate": 0.03542546650385852,
      "loss": 2.5749,
      "step": 401820
    },
    {
      "epoch": 646.05,
      "learning_rate": 0.03542225107299035,
      "loss": 2.5637,
      "step": 401840
    },
    {
      "epoch": 646.08,
      "learning_rate": 0.0354190356421222,
      "loss": 2.5619,
      "step": 401860
    },
    {
      "epoch": 646.11,
      "learning_rate": 0.03541582021125403,
      "loss": 2.5647,
      "step": 401880
    },
    {
      "epoch": 646.14,
      "learning_rate": 0.03541260478038585,
      "loss": 2.572,
      "step": 401900
    },
    {
      "epoch": 646.17,
      "learning_rate": 0.035409389349517685,
      "loss": 2.5861,
      "step": 401920
    },
    {
      "epoch": 646.21,
      "learning_rate": 0.03540617391864952,
      "loss": 2.5812,
      "step": 401940
    },
    {
      "epoch": 646.24,
      "learning_rate": 0.03540295848778136,
      "loss": 2.5767,
      "step": 401960
    },
    {
      "epoch": 646.27,
      "learning_rate": 0.035399743056913194,
      "loss": 2.5648,
      "step": 401980
    },
    {
      "epoch": 646.3,
      "learning_rate": 0.03539652762604502,
      "loss": 2.5792,
      "step": 402000
    },
    {
      "epoch": 646.33,
      "learning_rate": 0.03539331219517685,
      "loss": 2.5724,
      "step": 402020
    },
    {
      "epoch": 646.37,
      "learning_rate": 0.03539009676430868,
      "loss": 2.5691,
      "step": 402040
    },
    {
      "epoch": 646.4,
      "learning_rate": 0.03538688133344051,
      "loss": 2.5675,
      "step": 402060
    },
    {
      "epoch": 646.43,
      "learning_rate": 0.03538366590257236,
      "loss": 2.5736,
      "step": 402080
    },
    {
      "epoch": 646.46,
      "learning_rate": 0.03538045047170418,
      "loss": 2.5546,
      "step": 402100
    },
    {
      "epoch": 646.5,
      "learning_rate": 0.035377235040836015,
      "loss": 2.5764,
      "step": 402120
    },
    {
      "epoch": 646.53,
      "learning_rate": 0.03537401960996785,
      "loss": 2.5782,
      "step": 402140
    },
    {
      "epoch": 646.56,
      "learning_rate": 0.03537080417909968,
      "loss": 2.5901,
      "step": 402160
    },
    {
      "epoch": 646.59,
      "learning_rate": 0.03536758874823151,
      "loss": 2.5729,
      "step": 402180
    },
    {
      "epoch": 646.62,
      "learning_rate": 0.035364373317363355,
      "loss": 2.5826,
      "step": 402200
    },
    {
      "epoch": 646.66,
      "learning_rate": 0.03536115788649518,
      "loss": 2.5695,
      "step": 402220
    },
    {
      "epoch": 646.69,
      "learning_rate": 0.03535794245562701,
      "loss": 2.5594,
      "step": 402240
    },
    {
      "epoch": 646.72,
      "learning_rate": 0.03535472702475884,
      "loss": 2.5728,
      "step": 402260
    },
    {
      "epoch": 646.75,
      "learning_rate": 0.035351511593890675,
      "loss": 2.5666,
      "step": 402280
    },
    {
      "epoch": 646.78,
      "learning_rate": 0.03534829616302252,
      "loss": 2.5671,
      "step": 402300
    },
    {
      "epoch": 646.82,
      "learning_rate": 0.035345080732154345,
      "loss": 2.5638,
      "step": 402320
    },
    {
      "epoch": 646.85,
      "learning_rate": 0.03534186530128618,
      "loss": 2.5491,
      "step": 402340
    },
    {
      "epoch": 646.88,
      "learning_rate": 0.03533864987041801,
      "loss": 2.5741,
      "step": 402360
    },
    {
      "epoch": 646.91,
      "learning_rate": 0.03533543443954984,
      "loss": 2.5598,
      "step": 402380
    },
    {
      "epoch": 646.95,
      "learning_rate": 0.03533221900868167,
      "loss": 2.5818,
      "step": 402400
    },
    {
      "epoch": 646.98,
      "learning_rate": 0.03532900357781351,
      "loss": 2.5688,
      "step": 402420
    },
    {
      "epoch": 647.0,
      "eval_accuracy": {
        "accuracy": 0.42991526082562387
      },
      "eval_loss": 2.6913530826568604,
      "eval_runtime": 3.2465,
      "eval_samples_per_second": 3962.105,
      "eval_steps_per_second": 61.913,
      "step": 402434
    },
    {
      "epoch": 647.01,
      "learning_rate": 0.03532578814694534,
      "loss": 2.5539,
      "step": 402440
    },
    {
      "epoch": 647.04,
      "learning_rate": 0.03532257271607717,
      "loss": 2.5579,
      "step": 402460
    },
    {
      "epoch": 647.07,
      "learning_rate": 0.035319357285209005,
      "loss": 2.5843,
      "step": 402480
    },
    {
      "epoch": 647.11,
      "learning_rate": 0.035316141854340836,
      "loss": 2.5847,
      "step": 402500
    },
    {
      "epoch": 647.14,
      "learning_rate": 0.03531292642347267,
      "loss": 2.5812,
      "step": 402520
    },
    {
      "epoch": 647.17,
      "learning_rate": 0.03530971099260451,
      "loss": 2.5734,
      "step": 402540
    },
    {
      "epoch": 647.2,
      "learning_rate": 0.03530649556173634,
      "loss": 2.5739,
      "step": 402560
    },
    {
      "epoch": 647.23,
      "learning_rate": 0.03530328013086817,
      "loss": 2.5515,
      "step": 402580
    },
    {
      "epoch": 647.27,
      "learning_rate": 0.0353000647,
      "loss": 2.555,
      "step": 402600
    },
    {
      "epoch": 647.3,
      "learning_rate": 0.03529684926913183,
      "loss": 2.5936,
      "step": 402620
    },
    {
      "epoch": 647.33,
      "learning_rate": 0.03529363383826367,
      "loss": 2.5566,
      "step": 402640
    },
    {
      "epoch": 647.36,
      "learning_rate": 0.0352904184073955,
      "loss": 2.5576,
      "step": 402660
    },
    {
      "epoch": 647.4,
      "learning_rate": 0.035287202976527335,
      "loss": 2.5544,
      "step": 402680
    },
    {
      "epoch": 647.43,
      "learning_rate": 0.035283987545659166,
      "loss": 2.5499,
      "step": 402700
    },
    {
      "epoch": 647.46,
      "learning_rate": 0.035280772114791,
      "loss": 2.5472,
      "step": 402720
    },
    {
      "epoch": 647.49,
      "learning_rate": 0.03527755668392283,
      "loss": 2.5799,
      "step": 402740
    },
    {
      "epoch": 647.52,
      "learning_rate": 0.03527434125305467,
      "loss": 2.559,
      "step": 402760
    },
    {
      "epoch": 647.56,
      "learning_rate": 0.0352711258221865,
      "loss": 2.5712,
      "step": 402780
    },
    {
      "epoch": 647.59,
      "learning_rate": 0.03526791039131833,
      "loss": 2.5523,
      "step": 402800
    },
    {
      "epoch": 647.62,
      "learning_rate": 0.03526469496045016,
      "loss": 2.5628,
      "step": 402820
    },
    {
      "epoch": 647.65,
      "learning_rate": 0.035261479529581995,
      "loss": 2.5896,
      "step": 402840
    },
    {
      "epoch": 647.68,
      "learning_rate": 0.035258264098713826,
      "loss": 2.5847,
      "step": 402860
    },
    {
      "epoch": 647.72,
      "learning_rate": 0.035255048667845665,
      "loss": 2.5621,
      "step": 402880
    },
    {
      "epoch": 647.75,
      "learning_rate": 0.035251833236977496,
      "loss": 2.5803,
      "step": 402900
    },
    {
      "epoch": 647.78,
      "learning_rate": 0.03524861780610933,
      "loss": 2.5716,
      "step": 402920
    },
    {
      "epoch": 647.81,
      "learning_rate": 0.03524540237524116,
      "loss": 2.5673,
      "step": 402940
    },
    {
      "epoch": 647.85,
      "learning_rate": 0.03524218694437299,
      "loss": 2.5501,
      "step": 402960
    },
    {
      "epoch": 647.88,
      "learning_rate": 0.03523897151350483,
      "loss": 2.5484,
      "step": 402980
    },
    {
      "epoch": 647.91,
      "learning_rate": 0.03523575608263666,
      "loss": 2.5656,
      "step": 403000
    },
    {
      "epoch": 647.94,
      "learning_rate": 0.03523254065176849,
      "loss": 2.5584,
      "step": 403020
    },
    {
      "epoch": 647.97,
      "learning_rate": 0.035229325220900325,
      "loss": 2.5814,
      "step": 403040
    },
    {
      "epoch": 648.0,
      "eval_accuracy": {
        "accuracy": 0.42493974966959497
      },
      "eval_loss": 2.690884828567505,
      "eval_runtime": 2.8903,
      "eval_samples_per_second": 4450.469,
      "eval_steps_per_second": 69.544,
      "step": 403056
    },
    {
      "epoch": 648.01,
      "learning_rate": 0.035226109790032156,
      "loss": 2.5866,
      "step": 403060
    },
    {
      "epoch": 648.04,
      "learning_rate": 0.03522289435916399,
      "loss": 2.5434,
      "step": 403080
    },
    {
      "epoch": 648.07,
      "learning_rate": 0.035219678928295826,
      "loss": 2.5706,
      "step": 403100
    },
    {
      "epoch": 648.1,
      "learning_rate": 0.03521646349742766,
      "loss": 2.5605,
      "step": 403120
    },
    {
      "epoch": 648.14,
      "learning_rate": 0.03521324806655949,
      "loss": 2.554,
      "step": 403140
    },
    {
      "epoch": 648.17,
      "learning_rate": 0.03521003263569132,
      "loss": 2.5653,
      "step": 403160
    },
    {
      "epoch": 648.2,
      "learning_rate": 0.03520681720482315,
      "loss": 2.5679,
      "step": 403180
    },
    {
      "epoch": 648.23,
      "learning_rate": 0.035203601773954984,
      "loss": 2.5678,
      "step": 403200
    },
    {
      "epoch": 648.26,
      "learning_rate": 0.03520038634308682,
      "loss": 2.5866,
      "step": 403220
    },
    {
      "epoch": 648.3,
      "learning_rate": 0.035197170912218655,
      "loss": 2.5777,
      "step": 403240
    },
    {
      "epoch": 648.33,
      "learning_rate": 0.035193955481350486,
      "loss": 2.5501,
      "step": 403260
    },
    {
      "epoch": 648.36,
      "learning_rate": 0.03519074005048232,
      "loss": 2.577,
      "step": 403280
    },
    {
      "epoch": 648.39,
      "learning_rate": 0.03518752461961415,
      "loss": 2.57,
      "step": 403300
    },
    {
      "epoch": 648.42,
      "learning_rate": 0.03518430918874599,
      "loss": 2.5888,
      "step": 403320
    },
    {
      "epoch": 648.46,
      "learning_rate": 0.03518109375787782,
      "loss": 2.5858,
      "step": 403340
    },
    {
      "epoch": 648.49,
      "learning_rate": 0.03517787832700965,
      "loss": 2.5625,
      "step": 403360
    },
    {
      "epoch": 648.52,
      "learning_rate": 0.03517466289614148,
      "loss": 2.5601,
      "step": 403380
    },
    {
      "epoch": 648.55,
      "learning_rate": 0.035171447465273314,
      "loss": 2.5869,
      "step": 403400
    },
    {
      "epoch": 648.59,
      "learning_rate": 0.035168232034405146,
      "loss": 2.5749,
      "step": 403420
    },
    {
      "epoch": 648.62,
      "learning_rate": 0.035165016603536985,
      "loss": 2.5468,
      "step": 403440
    },
    {
      "epoch": 648.65,
      "learning_rate": 0.035161801172668816,
      "loss": 2.5727,
      "step": 403460
    },
    {
      "epoch": 648.68,
      "learning_rate": 0.03515858574180065,
      "loss": 2.5657,
      "step": 403480
    },
    {
      "epoch": 648.71,
      "learning_rate": 0.03515537031093248,
      "loss": 2.5682,
      "step": 403500
    },
    {
      "epoch": 648.75,
      "learning_rate": 0.03515215488006431,
      "loss": 2.5675,
      "step": 403520
    },
    {
      "epoch": 648.78,
      "learning_rate": 0.03514893944919614,
      "loss": 2.57,
      "step": 403540
    },
    {
      "epoch": 648.81,
      "learning_rate": 0.03514572401832798,
      "loss": 2.5644,
      "step": 403560
    },
    {
      "epoch": 648.84,
      "learning_rate": 0.03514250858745981,
      "loss": 2.5877,
      "step": 403580
    },
    {
      "epoch": 648.87,
      "learning_rate": 0.035139293156591644,
      "loss": 2.5527,
      "step": 403600
    },
    {
      "epoch": 648.91,
      "learning_rate": 0.035136077725723476,
      "loss": 2.5674,
      "step": 403620
    },
    {
      "epoch": 648.94,
      "learning_rate": 0.03513286229485531,
      "loss": 2.5512,
      "step": 403640
    },
    {
      "epoch": 648.97,
      "learning_rate": 0.035129646863987146,
      "loss": 2.557,
      "step": 403660
    },
    {
      "epoch": 649.0,
      "eval_accuracy": {
        "accuracy": 0.42385135660421364
      },
      "eval_loss": 2.70459246635437,
      "eval_runtime": 3.1267,
      "eval_samples_per_second": 4113.952,
      "eval_steps_per_second": 64.286,
      "step": 403678
    },
    {
      "epoch": 649.0,
      "learning_rate": 0.03512643143311898,
      "loss": 2.5701,
      "step": 403680
    },
    {
      "epoch": 649.04,
      "learning_rate": 0.03512321600225081,
      "loss": 2.5612,
      "step": 403700
    },
    {
      "epoch": 649.07,
      "learning_rate": 0.03512000057138264,
      "loss": 2.5782,
      "step": 403720
    },
    {
      "epoch": 649.1,
      "learning_rate": 0.03511678514051447,
      "loss": 2.5497,
      "step": 403740
    },
    {
      "epoch": 649.13,
      "learning_rate": 0.035113569709646304,
      "loss": 2.5585,
      "step": 403760
    },
    {
      "epoch": 649.16,
      "learning_rate": 0.03511035427877814,
      "loss": 2.5546,
      "step": 403780
    },
    {
      "epoch": 649.2,
      "learning_rate": 0.035107138847909974,
      "loss": 2.5777,
      "step": 403800
    },
    {
      "epoch": 649.23,
      "learning_rate": 0.035103923417041806,
      "loss": 2.5679,
      "step": 403820
    },
    {
      "epoch": 649.26,
      "learning_rate": 0.03510070798617364,
      "loss": 2.5678,
      "step": 403840
    },
    {
      "epoch": 649.29,
      "learning_rate": 0.03509749255530547,
      "loss": 2.5736,
      "step": 403860
    },
    {
      "epoch": 649.32,
      "learning_rate": 0.03509427712443731,
      "loss": 2.5707,
      "step": 403880
    },
    {
      "epoch": 649.36,
      "learning_rate": 0.03509106169356914,
      "loss": 2.5718,
      "step": 403900
    },
    {
      "epoch": 649.39,
      "learning_rate": 0.03508784626270097,
      "loss": 2.5906,
      "step": 403920
    },
    {
      "epoch": 649.42,
      "learning_rate": 0.0350846308318328,
      "loss": 2.5587,
      "step": 403940
    },
    {
      "epoch": 649.45,
      "learning_rate": 0.035081415400964634,
      "loss": 2.5497,
      "step": 403960
    },
    {
      "epoch": 649.49,
      "learning_rate": 0.035078199970096466,
      "loss": 2.5653,
      "step": 403980
    },
    {
      "epoch": 649.52,
      "learning_rate": 0.035074984539228304,
      "loss": 2.5616,
      "step": 404000
    },
    {
      "epoch": 649.55,
      "learning_rate": 0.035071769108360136,
      "loss": 2.5954,
      "step": 404020
    },
    {
      "epoch": 649.58,
      "learning_rate": 0.03506855367749197,
      "loss": 2.5582,
      "step": 404040
    },
    {
      "epoch": 649.61,
      "learning_rate": 0.0350653382466238,
      "loss": 2.5501,
      "step": 404060
    },
    {
      "epoch": 649.65,
      "learning_rate": 0.03506212281575563,
      "loss": 2.539,
      "step": 404080
    },
    {
      "epoch": 649.68,
      "learning_rate": 0.035058907384887456,
      "loss": 2.5687,
      "step": 404100
    },
    {
      "epoch": 649.71,
      "learning_rate": 0.0350556919540193,
      "loss": 2.5675,
      "step": 404120
    },
    {
      "epoch": 649.74,
      "learning_rate": 0.03505247652315113,
      "loss": 2.5528,
      "step": 404140
    },
    {
      "epoch": 649.77,
      "learning_rate": 0.035049261092282964,
      "loss": 2.5989,
      "step": 404160
    },
    {
      "epoch": 649.81,
      "learning_rate": 0.035046045661414796,
      "loss": 2.5461,
      "step": 404180
    },
    {
      "epoch": 649.84,
      "learning_rate": 0.03504283023054662,
      "loss": 2.57,
      "step": 404200
    },
    {
      "epoch": 649.87,
      "learning_rate": 0.035039614799678466,
      "loss": 2.5487,
      "step": 404220
    },
    {
      "epoch": 649.9,
      "learning_rate": 0.0350363993688103,
      "loss": 2.5562,
      "step": 404240
    },
    {
      "epoch": 649.94,
      "learning_rate": 0.03503318393794213,
      "loss": 2.5808,
      "step": 404260
    },
    {
      "epoch": 649.97,
      "learning_rate": 0.03502996850707396,
      "loss": 2.5681,
      "step": 404280
    },
    {
      "epoch": 650.0,
      "learning_rate": 0.03502675307620579,
      "loss": 2.5677,
      "step": 404300
    },
    {
      "epoch": 650.0,
      "eval_accuracy": {
        "accuracy": 0.42734976288579646
      },
      "eval_loss": 2.681898832321167,
      "eval_runtime": 3.1416,
      "eval_samples_per_second": 4094.453,
      "eval_steps_per_second": 63.981,
      "step": 404300
    },
    {
      "epoch": 650.03,
      "learning_rate": 0.03502353764533762,
      "loss": 2.5521,
      "step": 404320
    },
    {
      "epoch": 650.06,
      "learning_rate": 0.03502032221446946,
      "loss": 2.5421,
      "step": 404340
    },
    {
      "epoch": 650.1,
      "learning_rate": 0.035017106783601294,
      "loss": 2.5508,
      "step": 404360
    },
    {
      "epoch": 650.13,
      "learning_rate": 0.035013891352733126,
      "loss": 2.5301,
      "step": 404380
    },
    {
      "epoch": 650.16,
      "learning_rate": 0.03501067592186496,
      "loss": 2.5767,
      "step": 404400
    },
    {
      "epoch": 650.19,
      "learning_rate": 0.03500746049099678,
      "loss": 2.5715,
      "step": 404420
    },
    {
      "epoch": 650.23,
      "learning_rate": 0.035004245060128614,
      "loss": 2.5789,
      "step": 404440
    },
    {
      "epoch": 650.26,
      "learning_rate": 0.03500102962926046,
      "loss": 2.5821,
      "step": 404460
    },
    {
      "epoch": 650.29,
      "learning_rate": 0.03499781419839229,
      "loss": 2.6003,
      "step": 404480
    },
    {
      "epoch": 650.32,
      "learning_rate": 0.03499459876752412,
      "loss": 2.5765,
      "step": 404500
    },
    {
      "epoch": 650.35,
      "learning_rate": 0.03499138333665595,
      "loss": 2.5663,
      "step": 404520
    },
    {
      "epoch": 650.39,
      "learning_rate": 0.03498816790578778,
      "loss": 2.5753,
      "step": 404540
    },
    {
      "epoch": 650.42,
      "learning_rate": 0.034984952474919624,
      "loss": 2.5707,
      "step": 404560
    },
    {
      "epoch": 650.45,
      "learning_rate": 0.034981737044051456,
      "loss": 2.5642,
      "step": 404580
    },
    {
      "epoch": 650.48,
      "learning_rate": 0.03497852161318329,
      "loss": 2.5583,
      "step": 404600
    },
    {
      "epoch": 650.51,
      "learning_rate": 0.03497530618231512,
      "loss": 2.5619,
      "step": 404620
    },
    {
      "epoch": 650.55,
      "learning_rate": 0.034972090751446944,
      "loss": 2.5405,
      "step": 404640
    },
    {
      "epoch": 650.58,
      "learning_rate": 0.034968875320578775,
      "loss": 2.5734,
      "step": 404660
    },
    {
      "epoch": 650.61,
      "learning_rate": 0.03496565988971062,
      "loss": 2.5685,
      "step": 404680
    },
    {
      "epoch": 650.64,
      "learning_rate": 0.03496244445884245,
      "loss": 2.5496,
      "step": 404700
    },
    {
      "epoch": 650.68,
      "learning_rate": 0.034959229027974284,
      "loss": 2.5554,
      "step": 404720
    },
    {
      "epoch": 650.71,
      "learning_rate": 0.03495601359710611,
      "loss": 2.5736,
      "step": 404740
    },
    {
      "epoch": 650.74,
      "learning_rate": 0.03495279816623794,
      "loss": 2.5712,
      "step": 404760
    },
    {
      "epoch": 650.77,
      "learning_rate": 0.03494958273536977,
      "loss": 2.5602,
      "step": 404780
    },
    {
      "epoch": 650.8,
      "learning_rate": 0.03494636730450162,
      "loss": 2.5801,
      "step": 404800
    },
    {
      "epoch": 650.84,
      "learning_rate": 0.03494315187363345,
      "loss": 2.5528,
      "step": 404820
    },
    {
      "epoch": 650.87,
      "learning_rate": 0.034939936442765274,
      "loss": 2.5523,
      "step": 404840
    },
    {
      "epoch": 650.9,
      "learning_rate": 0.034936721011897105,
      "loss": 2.5606,
      "step": 404860
    },
    {
      "epoch": 650.93,
      "learning_rate": 0.03493350558102894,
      "loss": 2.5657,
      "step": 404880
    },
    {
      "epoch": 650.96,
      "learning_rate": 0.03493029015016078,
      "loss": 2.5563,
      "step": 404900
    },
    {
      "epoch": 651.0,
      "learning_rate": 0.034927074719292614,
      "loss": 2.5497,
      "step": 404920
    },
    {
      "epoch": 651.0,
      "eval_accuracy": {
        "accuracy": 0.43185881987094765
      },
      "eval_loss": 2.67303729057312,
      "eval_runtime": 3.0402,
      "eval_samples_per_second": 4231.029,
      "eval_steps_per_second": 66.115,
      "step": 404922
    },
    {
      "epoch": 651.03,
      "learning_rate": 0.034923859288424446,
      "loss": 2.5424,
      "step": 404940
    },
    {
      "epoch": 651.06,
      "learning_rate": 0.03492064385755627,
      "loss": 2.5523,
      "step": 404960
    },
    {
      "epoch": 651.09,
      "learning_rate": 0.0349174284266881,
      "loss": 2.5641,
      "step": 404980
    },
    {
      "epoch": 651.13,
      "learning_rate": 0.034914212995819933,
      "loss": 2.5522,
      "step": 405000
    },
    {
      "epoch": 651.16,
      "learning_rate": 0.03491099756495178,
      "loss": 2.568,
      "step": 405020
    },
    {
      "epoch": 651.19,
      "learning_rate": 0.03490778213408361,
      "loss": 2.5744,
      "step": 405040
    },
    {
      "epoch": 651.22,
      "learning_rate": 0.034904566703215435,
      "loss": 2.5673,
      "step": 405060
    },
    {
      "epoch": 651.25,
      "learning_rate": 0.03490135127234727,
      "loss": 2.5542,
      "step": 405080
    },
    {
      "epoch": 651.29,
      "learning_rate": 0.0348981358414791,
      "loss": 2.5557,
      "step": 405100
    },
    {
      "epoch": 651.32,
      "learning_rate": 0.03489492041061093,
      "loss": 2.5637,
      "step": 405120
    },
    {
      "epoch": 651.35,
      "learning_rate": 0.034891704979742776,
      "loss": 2.5517,
      "step": 405140
    },
    {
      "epoch": 651.38,
      "learning_rate": 0.0348884895488746,
      "loss": 2.5521,
      "step": 405160
    },
    {
      "epoch": 651.41,
      "learning_rate": 0.03488527411800643,
      "loss": 2.5676,
      "step": 405180
    },
    {
      "epoch": 651.45,
      "learning_rate": 0.03488205868713826,
      "loss": 2.5424,
      "step": 405200
    },
    {
      "epoch": 651.48,
      "learning_rate": 0.034878843256270095,
      "loss": 2.5411,
      "step": 405220
    },
    {
      "epoch": 651.51,
      "learning_rate": 0.03487562782540194,
      "loss": 2.5679,
      "step": 405240
    },
    {
      "epoch": 651.54,
      "learning_rate": 0.03487241239453377,
      "loss": 2.559,
      "step": 405260
    },
    {
      "epoch": 651.58,
      "learning_rate": 0.0348691969636656,
      "loss": 2.5661,
      "step": 405280
    },
    {
      "epoch": 651.61,
      "learning_rate": 0.03486598153279743,
      "loss": 2.5733,
      "step": 405300
    },
    {
      "epoch": 651.64,
      "learning_rate": 0.03486276610192926,
      "loss": 2.5539,
      "step": 405320
    },
    {
      "epoch": 651.67,
      "learning_rate": 0.03485955067106109,
      "loss": 2.5375,
      "step": 405340
    },
    {
      "epoch": 651.7,
      "learning_rate": 0.03485633524019294,
      "loss": 2.5721,
      "step": 405360
    },
    {
      "epoch": 651.74,
      "learning_rate": 0.03485311980932476,
      "loss": 2.563,
      "step": 405380
    },
    {
      "epoch": 651.77,
      "learning_rate": 0.03484990437845659,
      "loss": 2.5937,
      "step": 405400
    },
    {
      "epoch": 651.8,
      "learning_rate": 0.034846688947588425,
      "loss": 2.5983,
      "step": 405420
    },
    {
      "epoch": 651.83,
      "learning_rate": 0.03484347351672026,
      "loss": 2.5719,
      "step": 405440
    },
    {
      "epoch": 651.86,
      "learning_rate": 0.0348402580858521,
      "loss": 2.5934,
      "step": 405460
    },
    {
      "epoch": 651.9,
      "learning_rate": 0.03483704265498393,
      "loss": 2.5753,
      "step": 405480
    },
    {
      "epoch": 651.93,
      "learning_rate": 0.03483382722411576,
      "loss": 2.5647,
      "step": 405500
    },
    {
      "epoch": 651.96,
      "learning_rate": 0.03483061179324759,
      "loss": 2.5686,
      "step": 405520
    },
    {
      "epoch": 651.99,
      "learning_rate": 0.03482739636237942,
      "loss": 2.5954,
      "step": 405540
    },
    {
      "epoch": 652.0,
      "eval_accuracy": {
        "accuracy": 0.43224753168001245
      },
      "eval_loss": 2.672705888748169,
      "eval_runtime": 3.0374,
      "eval_samples_per_second": 4234.869,
      "eval_steps_per_second": 66.175,
      "step": 405544
    },
    {
      "epoch": 652.03,
      "learning_rate": 0.03482418093151125,
      "loss": 2.5754,
      "step": 405560
    },
    {
      "epoch": 652.06,
      "learning_rate": 0.0348209655006431,
      "loss": 2.5917,
      "step": 405580
    },
    {
      "epoch": 652.09,
      "learning_rate": 0.03481775006977492,
      "loss": 2.5468,
      "step": 405600
    },
    {
      "epoch": 652.12,
      "learning_rate": 0.034814534638906755,
      "loss": 2.567,
      "step": 405620
    },
    {
      "epoch": 652.15,
      "learning_rate": 0.03481131920803859,
      "loss": 2.5389,
      "step": 405640
    },
    {
      "epoch": 652.19,
      "learning_rate": 0.03480810377717042,
      "loss": 2.5628,
      "step": 405660
    },
    {
      "epoch": 652.22,
      "learning_rate": 0.03480504911784566,
      "loss": 2.5326,
      "step": 405680
    },
    {
      "epoch": 652.25,
      "learning_rate": 0.03480183368697749,
      "loss": 2.5815,
      "step": 405700
    },
    {
      "epoch": 652.28,
      "learning_rate": 0.03479861825610933,
      "loss": 2.5837,
      "step": 405720
    },
    {
      "epoch": 652.32,
      "learning_rate": 0.03479540282524116,
      "loss": 2.571,
      "step": 405740
    },
    {
      "epoch": 652.35,
      "learning_rate": 0.034792187394372995,
      "loss": 2.5671,
      "step": 405760
    },
    {
      "epoch": 652.38,
      "learning_rate": 0.034788971963504826,
      "loss": 2.5519,
      "step": 405780
    },
    {
      "epoch": 652.41,
      "learning_rate": 0.03478575653263666,
      "loss": 2.5791,
      "step": 405800
    },
    {
      "epoch": 652.44,
      "learning_rate": 0.03478254110176849,
      "loss": 2.5532,
      "step": 405820
    },
    {
      "epoch": 652.48,
      "learning_rate": 0.03477932567090033,
      "loss": 2.5561,
      "step": 405840
    },
    {
      "epoch": 652.51,
      "learning_rate": 0.03477611024003216,
      "loss": 2.5706,
      "step": 405860
    },
    {
      "epoch": 652.54,
      "learning_rate": 0.03477289480916399,
      "loss": 2.5524,
      "step": 405880
    },
    {
      "epoch": 652.57,
      "learning_rate": 0.03476967937829582,
      "loss": 2.5667,
      "step": 405900
    },
    {
      "epoch": 652.6,
      "learning_rate": 0.034766463947427655,
      "loss": 2.5321,
      "step": 405920
    },
    {
      "epoch": 652.64,
      "learning_rate": 0.034763248516559486,
      "loss": 2.5752,
      "step": 405940
    },
    {
      "epoch": 652.67,
      "learning_rate": 0.034760033085691325,
      "loss": 2.5875,
      "step": 405960
    },
    {
      "epoch": 652.7,
      "learning_rate": 0.034756817654823156,
      "loss": 2.5651,
      "step": 405980
    },
    {
      "epoch": 652.73,
      "learning_rate": 0.03475360222395499,
      "loss": 2.5448,
      "step": 406000
    },
    {
      "epoch": 652.77,
      "learning_rate": 0.03475038679308682,
      "loss": 2.5846,
      "step": 406020
    },
    {
      "epoch": 652.8,
      "learning_rate": 0.03474717136221865,
      "loss": 2.5408,
      "step": 406040
    },
    {
      "epoch": 652.83,
      "learning_rate": 0.03474395593135049,
      "loss": 2.5603,
      "step": 406060
    },
    {
      "epoch": 652.86,
      "learning_rate": 0.03474074050048232,
      "loss": 2.5556,
      "step": 406080
    },
    {
      "epoch": 652.89,
      "learning_rate": 0.03473752506961415,
      "loss": 2.5701,
      "step": 406100
    },
    {
      "epoch": 652.93,
      "learning_rate": 0.034734309638745985,
      "loss": 2.5691,
      "step": 406120
    },
    {
      "epoch": 652.96,
      "learning_rate": 0.034731094207877816,
      "loss": 2.5619,
      "step": 406140
    },
    {
      "epoch": 652.99,
      "learning_rate": 0.03472787877700965,
      "loss": 2.5682,
      "step": 406160
    },
    {
      "epoch": 653.0,
      "eval_accuracy": {
        "accuracy": 0.4303817149965016
      },
      "eval_loss": 2.6879992485046387,
      "eval_runtime": 3.0602,
      "eval_samples_per_second": 4203.318,
      "eval_steps_per_second": 65.682,
      "step": 406166
    },
    {
      "epoch": 653.02,
      "learning_rate": 0.034724663346141486,
      "loss": 2.5755,
      "step": 406180
    },
    {
      "epoch": 653.05,
      "learning_rate": 0.03472144791527332,
      "loss": 2.5699,
      "step": 406200
    },
    {
      "epoch": 653.09,
      "learning_rate": 0.03471823248440515,
      "loss": 2.5612,
      "step": 406220
    },
    {
      "epoch": 653.12,
      "learning_rate": 0.03471501705353698,
      "loss": 2.5721,
      "step": 406240
    },
    {
      "epoch": 653.15,
      "learning_rate": 0.03471180162266881,
      "loss": 2.5599,
      "step": 406260
    },
    {
      "epoch": 653.18,
      "learning_rate": 0.03470858619180065,
      "loss": 2.5701,
      "step": 406280
    },
    {
      "epoch": 653.22,
      "learning_rate": 0.03470537076093248,
      "loss": 2.5423,
      "step": 406300
    },
    {
      "epoch": 653.25,
      "learning_rate": 0.034702155330064315,
      "loss": 2.5931,
      "step": 406320
    },
    {
      "epoch": 653.28,
      "learning_rate": 0.034698939899196146,
      "loss": 2.5692,
      "step": 406340
    },
    {
      "epoch": 653.31,
      "learning_rate": 0.03469572446832798,
      "loss": 2.5435,
      "step": 406360
    },
    {
      "epoch": 653.34,
      "learning_rate": 0.03469250903745981,
      "loss": 2.5645,
      "step": 406380
    },
    {
      "epoch": 653.38,
      "learning_rate": 0.03468929360659165,
      "loss": 2.5648,
      "step": 406400
    },
    {
      "epoch": 653.41,
      "learning_rate": 0.03468607817572348,
      "loss": 2.5448,
      "step": 406420
    },
    {
      "epoch": 653.44,
      "learning_rate": 0.03468286274485531,
      "loss": 2.5242,
      "step": 406440
    },
    {
      "epoch": 653.47,
      "learning_rate": 0.03467964731398714,
      "loss": 2.5466,
      "step": 406460
    },
    {
      "epoch": 653.5,
      "learning_rate": 0.034676431883118974,
      "loss": 2.5496,
      "step": 406480
    },
    {
      "epoch": 653.54,
      "learning_rate": 0.034673216452250806,
      "loss": 2.5577,
      "step": 406500
    },
    {
      "epoch": 653.57,
      "learning_rate": 0.034670001021382645,
      "loss": 2.5749,
      "step": 406520
    },
    {
      "epoch": 653.6,
      "learning_rate": 0.034666785590514476,
      "loss": 2.5771,
      "step": 406540
    },
    {
      "epoch": 653.63,
      "learning_rate": 0.03466357015964631,
      "loss": 2.5713,
      "step": 406560
    },
    {
      "epoch": 653.67,
      "learning_rate": 0.03466035472877814,
      "loss": 2.557,
      "step": 406580
    },
    {
      "epoch": 653.7,
      "learning_rate": 0.03465713929790997,
      "loss": 2.5371,
      "step": 406600
    },
    {
      "epoch": 653.73,
      "learning_rate": 0.03465392386704181,
      "loss": 2.5712,
      "step": 406620
    },
    {
      "epoch": 653.76,
      "learning_rate": 0.03465070843617364,
      "loss": 2.5628,
      "step": 406640
    },
    {
      "epoch": 653.79,
      "learning_rate": 0.03464749300530547,
      "loss": 2.5548,
      "step": 406660
    },
    {
      "epoch": 653.83,
      "learning_rate": 0.034644277574437304,
      "loss": 2.5692,
      "step": 406680
    },
    {
      "epoch": 653.86,
      "learning_rate": 0.034641062143569136,
      "loss": 2.5573,
      "step": 406700
    },
    {
      "epoch": 653.89,
      "learning_rate": 0.03463784671270096,
      "loss": 2.5544,
      "step": 406720
    },
    {
      "epoch": 653.92,
      "learning_rate": 0.034634631281832806,
      "loss": 2.5633,
      "step": 406740
    },
    {
      "epoch": 653.95,
      "learning_rate": 0.03463141585096464,
      "loss": 2.5775,
      "step": 406760
    },
    {
      "epoch": 653.99,
      "learning_rate": 0.03462820042009647,
      "loss": 2.5762,
      "step": 406780
    },
    {
      "epoch": 654.0,
      "eval_accuracy": {
        "accuracy": 0.42944880665474616
      },
      "eval_loss": 2.697598695755005,
      "eval_runtime": 2.8625,
      "eval_samples_per_second": 4493.626,
      "eval_steps_per_second": 70.218,
      "step": 406788
    },
    {
      "epoch": 654.02,
      "learning_rate": 0.0346249849892283,
      "loss": 2.5742,
      "step": 406800
    },
    {
      "epoch": 654.05,
      "learning_rate": 0.03462176955836013,
      "loss": 2.5609,
      "step": 406820
    },
    {
      "epoch": 654.08,
      "learning_rate": 0.03461855412749196,
      "loss": 2.5609,
      "step": 406840
    },
    {
      "epoch": 654.12,
      "learning_rate": 0.0346153386966238,
      "loss": 2.5369,
      "step": 406860
    },
    {
      "epoch": 654.15,
      "learning_rate": 0.034612123265755634,
      "loss": 2.5543,
      "step": 406880
    },
    {
      "epoch": 654.18,
      "learning_rate": 0.034608907834887466,
      "loss": 2.5655,
      "step": 406900
    },
    {
      "epoch": 654.21,
      "learning_rate": 0.0346056924040193,
      "loss": 2.5485,
      "step": 406920
    },
    {
      "epoch": 654.24,
      "learning_rate": 0.03460247697315112,
      "loss": 2.569,
      "step": 406940
    },
    {
      "epoch": 654.28,
      "learning_rate": 0.03459926154228297,
      "loss": 2.5621,
      "step": 406960
    },
    {
      "epoch": 654.31,
      "learning_rate": 0.0345960461114148,
      "loss": 2.5665,
      "step": 406980
    },
    {
      "epoch": 654.34,
      "learning_rate": 0.03459283068054663,
      "loss": 2.5718,
      "step": 407000
    },
    {
      "epoch": 654.37,
      "learning_rate": 0.03458961524967846,
      "loss": 2.56,
      "step": 407020
    },
    {
      "epoch": 654.41,
      "learning_rate": 0.03458639981881029,
      "loss": 2.5634,
      "step": 407040
    },
    {
      "epoch": 654.44,
      "learning_rate": 0.03458318438794212,
      "loss": 2.5549,
      "step": 407060
    },
    {
      "epoch": 654.47,
      "learning_rate": 0.034579968957073964,
      "loss": 2.5681,
      "step": 407080
    },
    {
      "epoch": 654.5,
      "learning_rate": 0.034576753526205796,
      "loss": 2.5501,
      "step": 407100
    },
    {
      "epoch": 654.53,
      "learning_rate": 0.03457353809533763,
      "loss": 2.5714,
      "step": 407120
    },
    {
      "epoch": 654.57,
      "learning_rate": 0.03457032266446946,
      "loss": 2.5535,
      "step": 407140
    },
    {
      "epoch": 654.6,
      "learning_rate": 0.034567107233601284,
      "loss": 2.5363,
      "step": 407160
    },
    {
      "epoch": 654.63,
      "learning_rate": 0.034563891802733115,
      "loss": 2.5681,
      "step": 407180
    },
    {
      "epoch": 654.66,
      "learning_rate": 0.03456067637186496,
      "loss": 2.5428,
      "step": 407200
    },
    {
      "epoch": 654.69,
      "learning_rate": 0.03455746094099679,
      "loss": 2.5598,
      "step": 407220
    },
    {
      "epoch": 654.73,
      "learning_rate": 0.034554245510128624,
      "loss": 2.5541,
      "step": 407240
    },
    {
      "epoch": 654.76,
      "learning_rate": 0.03455103007926045,
      "loss": 2.5798,
      "step": 407260
    },
    {
      "epoch": 654.79,
      "learning_rate": 0.03454781464839228,
      "loss": 2.5772,
      "step": 407280
    },
    {
      "epoch": 654.82,
      "learning_rate": 0.034544599217524126,
      "loss": 2.5578,
      "step": 407300
    },
    {
      "epoch": 654.86,
      "learning_rate": 0.03454138378665596,
      "loss": 2.5671,
      "step": 407320
    },
    {
      "epoch": 654.89,
      "learning_rate": 0.03453816835578779,
      "loss": 2.5324,
      "step": 407340
    },
    {
      "epoch": 654.92,
      "learning_rate": 0.034534952924919614,
      "loss": 2.5753,
      "step": 407360
    },
    {
      "epoch": 654.95,
      "learning_rate": 0.034531737494051445,
      "loss": 2.5777,
      "step": 407380
    },
    {
      "epoch": 654.98,
      "learning_rate": 0.03452852206318328,
      "loss": 2.5761,
      "step": 407400
    },
    {
      "epoch": 655.0,
      "eval_accuracy": {
        "accuracy": 0.42898235248386846
      },
      "eval_loss": 2.6730241775512695,
      "eval_runtime": 2.992,
      "eval_samples_per_second": 4299.202,
      "eval_steps_per_second": 67.18,
      "step": 407410
    },
    {
      "epoch": 655.02,
      "learning_rate": 0.03452530663231512,
      "loss": 2.5661,
      "step": 407420
    },
    {
      "epoch": 655.05,
      "learning_rate": 0.034522091201446954,
      "loss": 2.5638,
      "step": 407440
    },
    {
      "epoch": 655.08,
      "learning_rate": 0.034518875770578786,
      "loss": 2.5543,
      "step": 407460
    },
    {
      "epoch": 655.11,
      "learning_rate": 0.03451566033971061,
      "loss": 2.5528,
      "step": 407480
    },
    {
      "epoch": 655.14,
      "learning_rate": 0.03451244490884244,
      "loss": 2.5679,
      "step": 407500
    },
    {
      "epoch": 655.18,
      "learning_rate": 0.034509229477974274,
      "loss": 2.5532,
      "step": 407520
    },
    {
      "epoch": 655.21,
      "learning_rate": 0.03450601404710612,
      "loss": 2.5555,
      "step": 407540
    },
    {
      "epoch": 655.24,
      "learning_rate": 0.03450279861623795,
      "loss": 2.5481,
      "step": 407560
    },
    {
      "epoch": 655.27,
      "learning_rate": 0.034499583185369775,
      "loss": 2.5513,
      "step": 407580
    },
    {
      "epoch": 655.31,
      "learning_rate": 0.03449636775450161,
      "loss": 2.5948,
      "step": 407600
    },
    {
      "epoch": 655.34,
      "learning_rate": 0.03449315232363344,
      "loss": 2.5732,
      "step": 407620
    },
    {
      "epoch": 655.37,
      "learning_rate": 0.034489936892765284,
      "loss": 2.5508,
      "step": 407640
    },
    {
      "epoch": 655.4,
      "learning_rate": 0.034486721461897116,
      "loss": 2.541,
      "step": 407660
    },
    {
      "epoch": 655.43,
      "learning_rate": 0.03448366680257235,
      "loss": 2.5652,
      "step": 407680
    },
    {
      "epoch": 655.47,
      "learning_rate": 0.034480451371704184,
      "loss": 2.546,
      "step": 407700
    },
    {
      "epoch": 655.5,
      "learning_rate": 0.034477235940836015,
      "loss": 2.5514,
      "step": 407720
    },
    {
      "epoch": 655.53,
      "learning_rate": 0.03447402050996785,
      "loss": 2.5623,
      "step": 407740
    },
    {
      "epoch": 655.56,
      "learning_rate": 0.03447080507909968,
      "loss": 2.5613,
      "step": 407760
    },
    {
      "epoch": 655.59,
      "learning_rate": 0.03446758964823152,
      "loss": 2.5448,
      "step": 407780
    },
    {
      "epoch": 655.63,
      "learning_rate": 0.03446437421736335,
      "loss": 2.5378,
      "step": 407800
    },
    {
      "epoch": 655.66,
      "learning_rate": 0.03446115878649518,
      "loss": 2.5616,
      "step": 407820
    },
    {
      "epoch": 655.69,
      "learning_rate": 0.03445794335562701,
      "loss": 2.5454,
      "step": 407840
    },
    {
      "epoch": 655.72,
      "learning_rate": 0.03445472792475884,
      "loss": 2.5731,
      "step": 407860
    },
    {
      "epoch": 655.76,
      "learning_rate": 0.034451512493890675,
      "loss": 2.5608,
      "step": 407880
    },
    {
      "epoch": 655.79,
      "learning_rate": 0.034448297063022514,
      "loss": 2.5646,
      "step": 407900
    },
    {
      "epoch": 655.82,
      "learning_rate": 0.034445081632154345,
      "loss": 2.5687,
      "step": 407920
    },
    {
      "epoch": 655.85,
      "learning_rate": 0.03444186620128618,
      "loss": 2.5754,
      "step": 407940
    },
    {
      "epoch": 655.88,
      "learning_rate": 0.03443865077041801,
      "loss": 2.5464,
      "step": 407960
    },
    {
      "epoch": 655.92,
      "learning_rate": 0.03443543533954984,
      "loss": 2.5546,
      "step": 407980
    },
    {
      "epoch": 655.95,
      "learning_rate": 0.03443221990868167,
      "loss": 2.5525,
      "step": 408000
    },
    {
      "epoch": 655.98,
      "learning_rate": 0.03442900447781351,
      "loss": 2.5705,
      "step": 408020
    },
    {
      "epoch": 656.0,
      "eval_accuracy": {
        "accuracy": 0.42758298997123534
      },
      "eval_loss": 2.684300661087036,
      "eval_runtime": 4.0439,
      "eval_samples_per_second": 3180.815,
      "eval_steps_per_second": 49.704,
      "step": 408032
    },
    {
      "epoch": 656.01,
      "learning_rate": 0.03442578904694534,
      "loss": 2.5477,
      "step": 408040
    },
    {
      "epoch": 656.05,
      "learning_rate": 0.03442257361607717,
      "loss": 2.5476,
      "step": 408060
    },
    {
      "epoch": 656.08,
      "learning_rate": 0.034419358185209005,
      "loss": 2.5677,
      "step": 408080
    },
    {
      "epoch": 656.11,
      "learning_rate": 0.03441614275434084,
      "loss": 2.5558,
      "step": 408100
    },
    {
      "epoch": 656.14,
      "learning_rate": 0.034412927323472675,
      "loss": 2.5665,
      "step": 408120
    },
    {
      "epoch": 656.17,
      "learning_rate": 0.03440971189260451,
      "loss": 2.5741,
      "step": 408140
    },
    {
      "epoch": 656.21,
      "learning_rate": 0.03440649646173634,
      "loss": 2.5664,
      "step": 408160
    },
    {
      "epoch": 656.24,
      "learning_rate": 0.03440328103086817,
      "loss": 2.5424,
      "step": 408180
    },
    {
      "epoch": 656.27,
      "learning_rate": 0.0344000656,
      "loss": 2.552,
      "step": 408200
    },
    {
      "epoch": 656.3,
      "learning_rate": 0.03439685016913183,
      "loss": 2.566,
      "step": 408220
    },
    {
      "epoch": 656.33,
      "learning_rate": 0.03439363473826367,
      "loss": 2.5404,
      "step": 408240
    },
    {
      "epoch": 656.37,
      "learning_rate": 0.0343904193073955,
      "loss": 2.5529,
      "step": 408260
    },
    {
      "epoch": 656.4,
      "learning_rate": 0.034387203876527335,
      "loss": 2.5953,
      "step": 408280
    },
    {
      "epoch": 656.43,
      "learning_rate": 0.03438398844565917,
      "loss": 2.5518,
      "step": 408300
    },
    {
      "epoch": 656.46,
      "learning_rate": 0.034380773014791,
      "loss": 2.5605,
      "step": 408320
    },
    {
      "epoch": 656.5,
      "learning_rate": 0.03437755758392283,
      "loss": 2.5776,
      "step": 408340
    },
    {
      "epoch": 656.53,
      "learning_rate": 0.03437434215305467,
      "loss": 2.5446,
      "step": 408360
    },
    {
      "epoch": 656.56,
      "learning_rate": 0.0343711267221865,
      "loss": 2.5594,
      "step": 408380
    },
    {
      "epoch": 656.59,
      "learning_rate": 0.03436791129131833,
      "loss": 2.5545,
      "step": 408400
    },
    {
      "epoch": 656.62,
      "learning_rate": 0.03436469586045016,
      "loss": 2.5328,
      "step": 408420
    },
    {
      "epoch": 656.66,
      "learning_rate": 0.034361480429581995,
      "loss": 2.5488,
      "step": 408440
    },
    {
      "epoch": 656.69,
      "learning_rate": 0.03435826499871383,
      "loss": 2.5715,
      "step": 408460
    },
    {
      "epoch": 656.72,
      "learning_rate": 0.034355049567845665,
      "loss": 2.5622,
      "step": 408480
    },
    {
      "epoch": 656.75,
      "learning_rate": 0.0343518341369775,
      "loss": 2.5518,
      "step": 408500
    },
    {
      "epoch": 656.78,
      "learning_rate": 0.03434861870610933,
      "loss": 2.5605,
      "step": 408520
    },
    {
      "epoch": 656.82,
      "learning_rate": 0.03434540327524116,
      "loss": 2.5739,
      "step": 408540
    },
    {
      "epoch": 656.85,
      "learning_rate": 0.03434218784437299,
      "loss": 2.557,
      "step": 408560
    },
    {
      "epoch": 656.88,
      "learning_rate": 0.03433897241350483,
      "loss": 2.5458,
      "step": 408580
    },
    {
      "epoch": 656.91,
      "learning_rate": 0.03433575698263666,
      "loss": 2.5562,
      "step": 408600
    },
    {
      "epoch": 656.95,
      "learning_rate": 0.03433254155176849,
      "loss": 2.5749,
      "step": 408620
    },
    {
      "epoch": 656.98,
      "learning_rate": 0.034329326120900325,
      "loss": 2.5583,
      "step": 408640
    },
    {
      "epoch": 657.0,
      "eval_accuracy": {
        "accuracy": 0.436212392132473
      },
      "eval_loss": 2.6577181816101074,
      "eval_runtime": 3.3423,
      "eval_samples_per_second": 3848.555,
      "eval_steps_per_second": 60.138,
      "step": 408654
    },
    {
      "epoch": 657.01,
      "learning_rate": 0.034326110690032156,
      "loss": 2.5568,
      "step": 408660
    },
    {
      "epoch": 657.04,
      "learning_rate": 0.03432289525916399,
      "loss": 2.5567,
      "step": 408680
    },
    {
      "epoch": 657.07,
      "learning_rate": 0.034319679828295827,
      "loss": 2.578,
      "step": 408700
    },
    {
      "epoch": 657.11,
      "learning_rate": 0.03431646439742766,
      "loss": 2.5762,
      "step": 408720
    },
    {
      "epoch": 657.14,
      "learning_rate": 0.03431324896655949,
      "loss": 2.5807,
      "step": 408740
    },
    {
      "epoch": 657.17,
      "learning_rate": 0.03431003353569132,
      "loss": 2.5663,
      "step": 408760
    },
    {
      "epoch": 657.2,
      "learning_rate": 0.03430681810482315,
      "loss": 2.5665,
      "step": 408780
    },
    {
      "epoch": 657.23,
      "learning_rate": 0.03430360267395499,
      "loss": 2.5276,
      "step": 408800
    },
    {
      "epoch": 657.27,
      "learning_rate": 0.03430038724308682,
      "loss": 2.5452,
      "step": 408820
    },
    {
      "epoch": 657.3,
      "learning_rate": 0.034297171812218655,
      "loss": 2.5548,
      "step": 408840
    },
    {
      "epoch": 657.33,
      "learning_rate": 0.034293956381350486,
      "loss": 2.5586,
      "step": 408860
    },
    {
      "epoch": 657.36,
      "learning_rate": 0.03429074095048232,
      "loss": 2.563,
      "step": 408880
    },
    {
      "epoch": 657.4,
      "learning_rate": 0.03428752551961415,
      "loss": 2.5517,
      "step": 408900
    },
    {
      "epoch": 657.43,
      "learning_rate": 0.03428431008874599,
      "loss": 2.5529,
      "step": 408920
    },
    {
      "epoch": 657.46,
      "learning_rate": 0.03428109465787782,
      "loss": 2.5507,
      "step": 408940
    },
    {
      "epoch": 657.49,
      "learning_rate": 0.03427787922700965,
      "loss": 2.5577,
      "step": 408960
    },
    {
      "epoch": 657.52,
      "learning_rate": 0.03427466379614148,
      "loss": 2.5584,
      "step": 408980
    },
    {
      "epoch": 657.56,
      "learning_rate": 0.034271448365273315,
      "loss": 2.5598,
      "step": 409000
    },
    {
      "epoch": 657.59,
      "learning_rate": 0.03426823293440515,
      "loss": 2.5508,
      "step": 409020
    },
    {
      "epoch": 657.62,
      "learning_rate": 0.034265017503536985,
      "loss": 2.5453,
      "step": 409040
    },
    {
      "epoch": 657.65,
      "learning_rate": 0.034261802072668816,
      "loss": 2.5539,
      "step": 409060
    },
    {
      "epoch": 657.68,
      "learning_rate": 0.03425858664180065,
      "loss": 2.5463,
      "step": 409080
    },
    {
      "epoch": 657.72,
      "learning_rate": 0.03425537121093248,
      "loss": 2.5522,
      "step": 409100
    },
    {
      "epoch": 657.75,
      "learning_rate": 0.03425215578006431,
      "loss": 2.5753,
      "step": 409120
    },
    {
      "epoch": 657.78,
      "learning_rate": 0.03424894034919615,
      "loss": 2.5618,
      "step": 409140
    },
    {
      "epoch": 657.81,
      "learning_rate": 0.03424572491832798,
      "loss": 2.5838,
      "step": 409160
    },
    {
      "epoch": 657.85,
      "learning_rate": 0.03424250948745981,
      "loss": 2.5648,
      "step": 409180
    },
    {
      "epoch": 657.88,
      "learning_rate": 0.034239294056591645,
      "loss": 2.5672,
      "step": 409200
    },
    {
      "epoch": 657.91,
      "learning_rate": 0.034236078625723476,
      "loss": 2.5526,
      "step": 409220
    },
    {
      "epoch": 657.94,
      "learning_rate": 0.0342328631948553,
      "loss": 2.5599,
      "step": 409240
    },
    {
      "epoch": 657.97,
      "learning_rate": 0.034229647763987146,
      "loss": 2.5318,
      "step": 409260
    },
    {
      "epoch": 658.0,
      "eval_accuracy": {
        "accuracy": 0.4338023789162715
      },
      "eval_loss": 2.6829380989074707,
      "eval_runtime": 3.35,
      "eval_samples_per_second": 3839.652,
      "eval_steps_per_second": 59.999,
      "step": 409276
    },
    {
      "epoch": 658.01,
      "learning_rate": 0.03422643233311898,
      "loss": 2.5551,
      "step": 409280
    },
    {
      "epoch": 658.04,
      "learning_rate": 0.03422321690225081,
      "loss": 2.5766,
      "step": 409300
    },
    {
      "epoch": 658.07,
      "learning_rate": 0.03422000147138264,
      "loss": 2.5716,
      "step": 409320
    },
    {
      "epoch": 658.1,
      "learning_rate": 0.03421678604051447,
      "loss": 2.5412,
      "step": 409340
    },
    {
      "epoch": 658.14,
      "learning_rate": 0.03421357060964631,
      "loss": 2.5475,
      "step": 409360
    },
    {
      "epoch": 658.17,
      "learning_rate": 0.03421035517877814,
      "loss": 2.5587,
      "step": 409380
    },
    {
      "epoch": 658.2,
      "learning_rate": 0.034207139747909975,
      "loss": 2.5688,
      "step": 409400
    },
    {
      "epoch": 658.23,
      "learning_rate": 0.034203924317041806,
      "loss": 2.5534,
      "step": 409420
    },
    {
      "epoch": 658.26,
      "learning_rate": 0.03420070888617364,
      "loss": 2.5705,
      "step": 409440
    },
    {
      "epoch": 658.3,
      "learning_rate": 0.03419749345530546,
      "loss": 2.5572,
      "step": 409460
    },
    {
      "epoch": 658.33,
      "learning_rate": 0.03419427802443731,
      "loss": 2.5591,
      "step": 409480
    },
    {
      "epoch": 658.36,
      "learning_rate": 0.03419106259356914,
      "loss": 2.537,
      "step": 409500
    },
    {
      "epoch": 658.39,
      "learning_rate": 0.03418784716270097,
      "loss": 2.5502,
      "step": 409520
    },
    {
      "epoch": 658.42,
      "learning_rate": 0.0341846317318328,
      "loss": 2.5626,
      "step": 409540
    },
    {
      "epoch": 658.46,
      "learning_rate": 0.03418141630096463,
      "loss": 2.5542,
      "step": 409560
    },
    {
      "epoch": 658.49,
      "learning_rate": 0.03417820087009646,
      "loss": 2.5452,
      "step": 409580
    },
    {
      "epoch": 658.52,
      "learning_rate": 0.034174985439228305,
      "loss": 2.5421,
      "step": 409600
    },
    {
      "epoch": 658.55,
      "learning_rate": 0.034171770008360136,
      "loss": 2.558,
      "step": 409620
    },
    {
      "epoch": 658.59,
      "learning_rate": 0.03416855457749197,
      "loss": 2.5667,
      "step": 409640
    },
    {
      "epoch": 658.62,
      "learning_rate": 0.0341653391466238,
      "loss": 2.5352,
      "step": 409660
    },
    {
      "epoch": 658.65,
      "learning_rate": 0.034162284487299036,
      "loss": 2.5644,
      "step": 409680
    },
    {
      "epoch": 658.68,
      "learning_rate": 0.03415906905643087,
      "loss": 2.5527,
      "step": 409700
    },
    {
      "epoch": 658.71,
      "learning_rate": 0.0341558536255627,
      "loss": 2.5541,
      "step": 409720
    },
    {
      "epoch": 658.75,
      "learning_rate": 0.034152638194694544,
      "loss": 2.5435,
      "step": 409740
    },
    {
      "epoch": 658.78,
      "learning_rate": 0.034149422763826376,
      "loss": 2.5614,
      "step": 409760
    },
    {
      "epoch": 658.81,
      "learning_rate": 0.0341462073329582,
      "loss": 2.5673,
      "step": 409780
    },
    {
      "epoch": 658.84,
      "learning_rate": 0.03414299190209003,
      "loss": 2.5586,
      "step": 409800
    },
    {
      "epoch": 658.87,
      "learning_rate": 0.034139776471221864,
      "loss": 2.5663,
      "step": 409820
    },
    {
      "epoch": 658.91,
      "learning_rate": 0.03413656104035371,
      "loss": 2.5505,
      "step": 409840
    },
    {
      "epoch": 658.94,
      "learning_rate": 0.03413334560948554,
      "loss": 2.5706,
      "step": 409860
    },
    {
      "epoch": 658.97,
      "learning_rate": 0.034130130178617366,
      "loss": 2.5655,
      "step": 409880
    },
    {
      "epoch": 659.0,
      "eval_accuracy": {
        "accuracy": 0.4305371997201275
      },
      "eval_loss": 2.6700501441955566,
      "eval_runtime": 3.2401,
      "eval_samples_per_second": 3969.928,
      "eval_steps_per_second": 62.035,
      "step": 409898
    },
    {
      "epoch": 659.0,
      "learning_rate": 0.0341269147477492,
      "loss": 2.5496,
      "step": 409900
    },
    {
      "epoch": 659.04,
      "learning_rate": 0.03412369931688103,
      "loss": 2.5512,
      "step": 409920
    },
    {
      "epoch": 659.07,
      "learning_rate": 0.03412048388601286,
      "loss": 2.5447,
      "step": 409940
    },
    {
      "epoch": 659.1,
      "learning_rate": 0.034117268455144706,
      "loss": 2.5478,
      "step": 409960
    },
    {
      "epoch": 659.13,
      "learning_rate": 0.03411405302427653,
      "loss": 2.5411,
      "step": 409980
    },
    {
      "epoch": 659.16,
      "learning_rate": 0.03411083759340836,
      "loss": 2.5643,
      "step": 410000
    },
    {
      "epoch": 659.2,
      "learning_rate": 0.034107622162540194,
      "loss": 2.5477,
      "step": 410020
    },
    {
      "epoch": 659.23,
      "learning_rate": 0.034104406731672025,
      "loss": 2.5411,
      "step": 410040
    },
    {
      "epoch": 659.26,
      "learning_rate": 0.03410119130080386,
      "loss": 2.5405,
      "step": 410060
    },
    {
      "epoch": 659.29,
      "learning_rate": 0.0340979758699357,
      "loss": 2.5399,
      "step": 410080
    },
    {
      "epoch": 659.32,
      "learning_rate": 0.03409476043906753,
      "loss": 2.5247,
      "step": 410100
    },
    {
      "epoch": 659.36,
      "learning_rate": 0.03409154500819936,
      "loss": 2.5385,
      "step": 410120
    },
    {
      "epoch": 659.39,
      "learning_rate": 0.03408832957733119,
      "loss": 2.5621,
      "step": 410140
    },
    {
      "epoch": 659.42,
      "learning_rate": 0.03408511414646302,
      "loss": 2.5485,
      "step": 410160
    },
    {
      "epoch": 659.45,
      "learning_rate": 0.03408189871559487,
      "loss": 2.5588,
      "step": 410180
    },
    {
      "epoch": 659.49,
      "learning_rate": 0.03407868328472669,
      "loss": 2.5462,
      "step": 410200
    },
    {
      "epoch": 659.52,
      "learning_rate": 0.034075467853858524,
      "loss": 2.5509,
      "step": 410220
    },
    {
      "epoch": 659.55,
      "learning_rate": 0.034072252422990355,
      "loss": 2.5528,
      "step": 410240
    },
    {
      "epoch": 659.58,
      "learning_rate": 0.03406903699212219,
      "loss": 2.5506,
      "step": 410260
    },
    {
      "epoch": 659.61,
      "learning_rate": 0.03406582156125402,
      "loss": 2.5527,
      "step": 410280
    },
    {
      "epoch": 659.65,
      "learning_rate": 0.03406260613038586,
      "loss": 2.5785,
      "step": 410300
    },
    {
      "epoch": 659.68,
      "learning_rate": 0.03405939069951769,
      "loss": 2.5654,
      "step": 410320
    },
    {
      "epoch": 659.71,
      "learning_rate": 0.03405617526864952,
      "loss": 2.5592,
      "step": 410340
    },
    {
      "epoch": 659.74,
      "learning_rate": 0.03405295983778135,
      "loss": 2.559,
      "step": 410360
    },
    {
      "epoch": 659.77,
      "learning_rate": 0.034049744406913184,
      "loss": 2.554,
      "step": 410380
    },
    {
      "epoch": 659.81,
      "learning_rate": 0.034046528976045015,
      "loss": 2.5817,
      "step": 410400
    },
    {
      "epoch": 659.84,
      "learning_rate": 0.034043313545176854,
      "loss": 2.5346,
      "step": 410420
    },
    {
      "epoch": 659.87,
      "learning_rate": 0.034040098114308685,
      "loss": 2.576,
      "step": 410440
    },
    {
      "epoch": 659.9,
      "learning_rate": 0.03403688268344052,
      "loss": 2.5533,
      "step": 410460
    },
    {
      "epoch": 659.94,
      "learning_rate": 0.03403366725257235,
      "loss": 2.5805,
      "step": 410480
    },
    {
      "epoch": 659.97,
      "learning_rate": 0.03403045182170418,
      "loss": 2.579,
      "step": 410500
    },
    {
      "epoch": 660.0,
      "learning_rate": 0.03402723639083602,
      "loss": 2.579,
      "step": 410520
    },
    {
      "epoch": 660.0,
      "eval_accuracy": {
        "accuracy": 0.4320143045945736
      },
      "eval_loss": 2.6722018718719482,
      "eval_runtime": 3.8185,
      "eval_samples_per_second": 3368.618,
      "eval_steps_per_second": 52.639,
      "step": 410520
    },
    {
      "epoch": 660.03,
      "learning_rate": 0.03402402095996785,
      "loss": 2.5554,
      "step": 410540
    },
    {
      "epoch": 660.06,
      "learning_rate": 0.03402080552909968,
      "loss": 2.557,
      "step": 410560
    },
    {
      "epoch": 660.1,
      "learning_rate": 0.034017590098231514,
      "loss": 2.54,
      "step": 410580
    },
    {
      "epoch": 660.13,
      "learning_rate": 0.034014374667363345,
      "loss": 2.5617,
      "step": 410600
    },
    {
      "epoch": 660.16,
      "learning_rate": 0.03401115923649518,
      "loss": 2.5555,
      "step": 410620
    },
    {
      "epoch": 660.19,
      "learning_rate": 0.034007943805627015,
      "loss": 2.5393,
      "step": 410640
    },
    {
      "epoch": 660.23,
      "learning_rate": 0.03400472837475885,
      "loss": 2.5541,
      "step": 410660
    },
    {
      "epoch": 660.26,
      "learning_rate": 0.03400151294389068,
      "loss": 2.5687,
      "step": 410680
    },
    {
      "epoch": 660.29,
      "learning_rate": 0.03399829751302251,
      "loss": 2.5689,
      "step": 410700
    },
    {
      "epoch": 660.32,
      "learning_rate": 0.03399508208215434,
      "loss": 2.5377,
      "step": 410720
    },
    {
      "epoch": 660.35,
      "learning_rate": 0.03399186665128617,
      "loss": 2.5573,
      "step": 410740
    },
    {
      "epoch": 660.39,
      "learning_rate": 0.03398865122041801,
      "loss": 2.5575,
      "step": 410760
    },
    {
      "epoch": 660.42,
      "learning_rate": 0.033985435789549844,
      "loss": 2.5393,
      "step": 410780
    },
    {
      "epoch": 660.45,
      "learning_rate": 0.033982220358681675,
      "loss": 2.5684,
      "step": 410800
    },
    {
      "epoch": 660.48,
      "learning_rate": 0.03397900492781351,
      "loss": 2.5644,
      "step": 410820
    },
    {
      "epoch": 660.51,
      "learning_rate": 0.03397578949694534,
      "loss": 2.5444,
      "step": 410840
    },
    {
      "epoch": 660.55,
      "learning_rate": 0.03397257406607718,
      "loss": 2.5576,
      "step": 410860
    },
    {
      "epoch": 660.58,
      "learning_rate": 0.03396935863520901,
      "loss": 2.5555,
      "step": 410880
    },
    {
      "epoch": 660.61,
      "learning_rate": 0.03396614320434084,
      "loss": 2.5745,
      "step": 410900
    },
    {
      "epoch": 660.64,
      "learning_rate": 0.03396292777347267,
      "loss": 2.5331,
      "step": 410920
    },
    {
      "epoch": 660.68,
      "learning_rate": 0.0339597123426045,
      "loss": 2.5511,
      "step": 410940
    },
    {
      "epoch": 660.71,
      "learning_rate": 0.033956496911736335,
      "loss": 2.5517,
      "step": 410960
    },
    {
      "epoch": 660.74,
      "learning_rate": 0.033953281480868173,
      "loss": 2.548,
      "step": 410980
    },
    {
      "epoch": 660.77,
      "learning_rate": 0.033950066050000005,
      "loss": 2.5615,
      "step": 411000
    },
    {
      "epoch": 660.8,
      "learning_rate": 0.03394685061913184,
      "loss": 2.5749,
      "step": 411020
    },
    {
      "epoch": 660.84,
      "learning_rate": 0.03394363518826367,
      "loss": 2.5522,
      "step": 411040
    },
    {
      "epoch": 660.87,
      "learning_rate": 0.0339404197573955,
      "loss": 2.5687,
      "step": 411060
    },
    {
      "epoch": 660.9,
      "learning_rate": 0.03393720432652733,
      "loss": 2.551,
      "step": 411080
    },
    {
      "epoch": 660.93,
      "learning_rate": 0.03393398889565917,
      "loss": 2.576,
      "step": 411100
    },
    {
      "epoch": 660.96,
      "learning_rate": 0.033930773464791,
      "loss": 2.5784,
      "step": 411120
    },
    {
      "epoch": 661.0,
      "learning_rate": 0.03392755803392283,
      "loss": 2.5699,
      "step": 411140
    },
    {
      "epoch": 661.0,
      "eval_accuracy": {
        "accuracy": 0.4319365622327606
      },
      "eval_loss": 2.6654460430145264,
      "eval_runtime": 3.1214,
      "eval_samples_per_second": 4120.907,
      "eval_steps_per_second": 64.394,
      "step": 411142
    },
    {
      "epoch": 661.03,
      "learning_rate": 0.033924342603054665,
      "loss": 2.5543,
      "step": 411160
    },
    {
      "epoch": 661.06,
      "learning_rate": 0.0339211271721865,
      "loss": 2.5372,
      "step": 411180
    },
    {
      "epoch": 661.09,
      "learning_rate": 0.033917911741318335,
      "loss": 2.5533,
      "step": 411200
    },
    {
      "epoch": 661.13,
      "learning_rate": 0.03391469631045017,
      "loss": 2.5726,
      "step": 411220
    },
    {
      "epoch": 661.16,
      "learning_rate": 0.033911480879582,
      "loss": 2.5518,
      "step": 411240
    },
    {
      "epoch": 661.19,
      "learning_rate": 0.03390826544871383,
      "loss": 2.5561,
      "step": 411260
    },
    {
      "epoch": 661.22,
      "learning_rate": 0.03390505001784566,
      "loss": 2.5397,
      "step": 411280
    },
    {
      "epoch": 661.25,
      "learning_rate": 0.03390183458697749,
      "loss": 2.5533,
      "step": 411300
    },
    {
      "epoch": 661.29,
      "learning_rate": 0.03389861915610933,
      "loss": 2.5582,
      "step": 411320
    },
    {
      "epoch": 661.32,
      "learning_rate": 0.03389540372524116,
      "loss": 2.5521,
      "step": 411340
    },
    {
      "epoch": 661.35,
      "learning_rate": 0.033892188294372995,
      "loss": 2.5507,
      "step": 411360
    },
    {
      "epoch": 661.38,
      "learning_rate": 0.033888972863504827,
      "loss": 2.5665,
      "step": 411380
    },
    {
      "epoch": 661.41,
      "learning_rate": 0.03388575743263666,
      "loss": 2.5405,
      "step": 411400
    },
    {
      "epoch": 661.45,
      "learning_rate": 0.0338825420017685,
      "loss": 2.5427,
      "step": 411420
    },
    {
      "epoch": 661.48,
      "learning_rate": 0.03387932657090033,
      "loss": 2.5542,
      "step": 411440
    },
    {
      "epoch": 661.51,
      "learning_rate": 0.03387611114003216,
      "loss": 2.5608,
      "step": 411460
    },
    {
      "epoch": 661.54,
      "learning_rate": 0.03387289570916399,
      "loss": 2.5539,
      "step": 411480
    },
    {
      "epoch": 661.58,
      "learning_rate": 0.03386968027829582,
      "loss": 2.5627,
      "step": 411500
    },
    {
      "epoch": 661.61,
      "learning_rate": 0.033866464847427655,
      "loss": 2.5488,
      "step": 411520
    },
    {
      "epoch": 661.64,
      "learning_rate": 0.03386324941655949,
      "loss": 2.5658,
      "step": 411540
    },
    {
      "epoch": 661.67,
      "learning_rate": 0.033860033985691325,
      "loss": 2.549,
      "step": 411560
    },
    {
      "epoch": 661.7,
      "learning_rate": 0.033856818554823156,
      "loss": 2.5368,
      "step": 411580
    },
    {
      "epoch": 661.74,
      "learning_rate": 0.03385360312395499,
      "loss": 2.5642,
      "step": 411600
    },
    {
      "epoch": 661.77,
      "learning_rate": 0.03385038769308682,
      "loss": 2.5647,
      "step": 411620
    },
    {
      "epoch": 661.8,
      "learning_rate": 0.03384733303376206,
      "loss": 2.5778,
      "step": 411640
    },
    {
      "epoch": 661.83,
      "learning_rate": 0.03384411760289389,
      "loss": 2.5527,
      "step": 411660
    },
    {
      "epoch": 661.86,
      "learning_rate": 0.03384090217202573,
      "loss": 2.552,
      "step": 411680
    },
    {
      "epoch": 661.9,
      "learning_rate": 0.033837686741157565,
      "loss": 2.5713,
      "step": 411700
    },
    {
      "epoch": 661.93,
      "learning_rate": 0.033834471310289396,
      "loss": 2.5547,
      "step": 411720
    },
    {
      "epoch": 661.96,
      "learning_rate": 0.03383125587942123,
      "loss": 2.5577,
      "step": 411740
    },
    {
      "epoch": 661.99,
      "learning_rate": 0.03382804044855305,
      "loss": 2.5654,
      "step": 411760
    },
    {
      "epoch": 662.0,
      "eval_accuracy": {
        "accuracy": 0.43209204695638653
      },
      "eval_loss": 2.663510322570801,
      "eval_runtime": 2.9276,
      "eval_samples_per_second": 4393.638,
      "eval_steps_per_second": 68.656,
      "step": 411764
    },
    {
      "epoch": 662.03,
      "learning_rate": 0.033824825017684884,
      "loss": 2.567,
      "step": 411780
    },
    {
      "epoch": 662.06,
      "learning_rate": 0.03382160958681673,
      "loss": 2.5634,
      "step": 411800
    },
    {
      "epoch": 662.09,
      "learning_rate": 0.03381839415594856,
      "loss": 2.563,
      "step": 411820
    },
    {
      "epoch": 662.12,
      "learning_rate": 0.03381517872508039,
      "loss": 2.5633,
      "step": 411840
    },
    {
      "epoch": 662.15,
      "learning_rate": 0.03381196329421222,
      "loss": 2.5504,
      "step": 411860
    },
    {
      "epoch": 662.19,
      "learning_rate": 0.03380874786334405,
      "loss": 2.5354,
      "step": 411880
    },
    {
      "epoch": 662.22,
      "learning_rate": 0.03380553243247588,
      "loss": 2.5587,
      "step": 411900
    },
    {
      "epoch": 662.25,
      "learning_rate": 0.033802317001607726,
      "loss": 2.5494,
      "step": 411920
    },
    {
      "epoch": 662.28,
      "learning_rate": 0.03379910157073956,
      "loss": 2.5516,
      "step": 411940
    },
    {
      "epoch": 662.32,
      "learning_rate": 0.03379588613987139,
      "loss": 2.5597,
      "step": 411960
    },
    {
      "epoch": 662.35,
      "learning_rate": 0.033792670709003214,
      "loss": 2.564,
      "step": 411980
    },
    {
      "epoch": 662.38,
      "learning_rate": 0.033789455278135046,
      "loss": 2.5705,
      "step": 412000
    },
    {
      "epoch": 662.41,
      "learning_rate": 0.03378623984726689,
      "loss": 2.5589,
      "step": 412020
    },
    {
      "epoch": 662.44,
      "learning_rate": 0.03378302441639872,
      "loss": 2.5502,
      "step": 412040
    },
    {
      "epoch": 662.48,
      "learning_rate": 0.033779808985530554,
      "loss": 2.5563,
      "step": 412060
    },
    {
      "epoch": 662.51,
      "learning_rate": 0.03377659355466238,
      "loss": 2.5475,
      "step": 412080
    },
    {
      "epoch": 662.54,
      "learning_rate": 0.03377337812379421,
      "loss": 2.5553,
      "step": 412100
    },
    {
      "epoch": 662.57,
      "learning_rate": 0.03377016269292604,
      "loss": 2.5533,
      "step": 412120
    },
    {
      "epoch": 662.6,
      "learning_rate": 0.03376694726205789,
      "loss": 2.5444,
      "step": 412140
    },
    {
      "epoch": 662.64,
      "learning_rate": 0.03376373183118972,
      "loss": 2.5535,
      "step": 412160
    },
    {
      "epoch": 662.67,
      "learning_rate": 0.033760516400321544,
      "loss": 2.5394,
      "step": 412180
    },
    {
      "epoch": 662.7,
      "learning_rate": 0.033757300969453376,
      "loss": 2.5555,
      "step": 412200
    },
    {
      "epoch": 662.73,
      "learning_rate": 0.03375408553858521,
      "loss": 2.5641,
      "step": 412220
    },
    {
      "epoch": 662.77,
      "learning_rate": 0.03375087010771705,
      "loss": 2.5555,
      "step": 412240
    },
    {
      "epoch": 662.8,
      "learning_rate": 0.033747654676848884,
      "loss": 2.5595,
      "step": 412260
    },
    {
      "epoch": 662.83,
      "learning_rate": 0.033744439245980716,
      "loss": 2.5417,
      "step": 412280
    },
    {
      "epoch": 662.86,
      "learning_rate": 0.03374122381511254,
      "loss": 2.5709,
      "step": 412300
    },
    {
      "epoch": 662.89,
      "learning_rate": 0.03373800838424437,
      "loss": 2.5759,
      "step": 412320
    },
    {
      "epoch": 662.93,
      "learning_rate": 0.033734792953376204,
      "loss": 2.5386,
      "step": 412340
    },
    {
      "epoch": 662.96,
      "learning_rate": 0.03373157752250805,
      "loss": 2.5413,
      "step": 412360
    },
    {
      "epoch": 662.99,
      "learning_rate": 0.03372836209163988,
      "loss": 2.553,
      "step": 412380
    },
    {
      "epoch": 663.0,
      "eval_accuracy": {
        "accuracy": 0.43224753168001245
      },
      "eval_loss": 2.671142578125,
      "eval_runtime": 3.2527,
      "eval_samples_per_second": 3954.578,
      "eval_steps_per_second": 61.795,
      "step": 412386
    },
    {
      "epoch": 663.02,
      "learning_rate": 0.033725146660771706,
      "loss": 2.557,
      "step": 412400
    },
    {
      "epoch": 663.05,
      "learning_rate": 0.03372193122990354,
      "loss": 2.5353,
      "step": 412420
    },
    {
      "epoch": 663.09,
      "learning_rate": 0.03371871579903537,
      "loss": 2.571,
      "step": 412440
    },
    {
      "epoch": 663.12,
      "learning_rate": 0.0337155003681672,
      "loss": 2.5678,
      "step": 412460
    },
    {
      "epoch": 663.15,
      "learning_rate": 0.033712284937299046,
      "loss": 2.5559,
      "step": 412480
    },
    {
      "epoch": 663.18,
      "learning_rate": 0.03370906950643087,
      "loss": 2.5368,
      "step": 412500
    },
    {
      "epoch": 663.22,
      "learning_rate": 0.0337058540755627,
      "loss": 2.5487,
      "step": 412520
    },
    {
      "epoch": 663.25,
      "learning_rate": 0.033702638644694534,
      "loss": 2.5646,
      "step": 412540
    },
    {
      "epoch": 663.28,
      "learning_rate": 0.033699423213826366,
      "loss": 2.559,
      "step": 412560
    },
    {
      "epoch": 663.31,
      "learning_rate": 0.03369620778295821,
      "loss": 2.5442,
      "step": 412580
    },
    {
      "epoch": 663.34,
      "learning_rate": 0.03369299235209004,
      "loss": 2.5445,
      "step": 412600
    },
    {
      "epoch": 663.38,
      "learning_rate": 0.03368977692122187,
      "loss": 2.5459,
      "step": 412620
    },
    {
      "epoch": 663.41,
      "learning_rate": 0.0336865614903537,
      "loss": 2.554,
      "step": 412640
    },
    {
      "epoch": 663.44,
      "learning_rate": 0.03368334605948553,
      "loss": 2.5541,
      "step": 412660
    },
    {
      "epoch": 663.47,
      "learning_rate": 0.03368013062861736,
      "loss": 2.5391,
      "step": 412680
    },
    {
      "epoch": 663.5,
      "learning_rate": 0.03367691519774921,
      "loss": 2.5678,
      "step": 412700
    },
    {
      "epoch": 663.54,
      "learning_rate": 0.03367369976688103,
      "loss": 2.5864,
      "step": 412720
    },
    {
      "epoch": 663.57,
      "learning_rate": 0.033670484336012864,
      "loss": 2.5418,
      "step": 412740
    },
    {
      "epoch": 663.6,
      "learning_rate": 0.033667268905144696,
      "loss": 2.5543,
      "step": 412760
    },
    {
      "epoch": 663.63,
      "learning_rate": 0.03366405347427653,
      "loss": 2.5682,
      "step": 412780
    },
    {
      "epoch": 663.67,
      "learning_rate": 0.03366083804340836,
      "loss": 2.5755,
      "step": 412800
    },
    {
      "epoch": 663.7,
      "learning_rate": 0.0336576226125402,
      "loss": 2.5496,
      "step": 412820
    },
    {
      "epoch": 663.73,
      "learning_rate": 0.03365440718167203,
      "loss": 2.5282,
      "step": 412840
    },
    {
      "epoch": 663.76,
      "learning_rate": 0.03365119175080386,
      "loss": 2.5452,
      "step": 412860
    },
    {
      "epoch": 663.79,
      "learning_rate": 0.03364797631993569,
      "loss": 2.5502,
      "step": 412880
    },
    {
      "epoch": 663.83,
      "learning_rate": 0.033644760889067524,
      "loss": 2.5558,
      "step": 412900
    },
    {
      "epoch": 663.86,
      "learning_rate": 0.03364154545819937,
      "loss": 2.5599,
      "step": 412920
    },
    {
      "epoch": 663.89,
      "learning_rate": 0.033638330027331194,
      "loss": 2.5682,
      "step": 412940
    },
    {
      "epoch": 663.92,
      "learning_rate": 0.033635114596463025,
      "loss": 2.5633,
      "step": 412960
    },
    {
      "epoch": 663.95,
      "learning_rate": 0.03363189916559486,
      "loss": 2.5427,
      "step": 412980
    },
    {
      "epoch": 663.99,
      "learning_rate": 0.03362868373472669,
      "loss": 2.5753,
      "step": 413000
    },
    {
      "epoch": 664.0,
      "eval_accuracy": {
        "accuracy": 0.4250952343932209
      },
      "eval_loss": 2.680929660797119,
      "eval_runtime": 3.5506,
      "eval_samples_per_second": 3622.767,
      "eval_steps_per_second": 56.61,
      "step": 413008
    },
    {
      "epoch": 664.02,
      "learning_rate": 0.03362546830385852,
      "loss": 2.5601,
      "step": 413020
    },
    {
      "epoch": 664.05,
      "learning_rate": 0.03362225287299036,
      "loss": 2.5539,
      "step": 413040
    },
    {
      "epoch": 664.08,
      "learning_rate": 0.03361903744212219,
      "loss": 2.5498,
      "step": 413060
    },
    {
      "epoch": 664.12,
      "learning_rate": 0.03361582201125402,
      "loss": 2.5472,
      "step": 413080
    },
    {
      "epoch": 664.15,
      "learning_rate": 0.033612606580385854,
      "loss": 2.5519,
      "step": 413100
    },
    {
      "epoch": 664.18,
      "learning_rate": 0.033609391149517685,
      "loss": 2.5575,
      "step": 413120
    },
    {
      "epoch": 664.21,
      "learning_rate": 0.03360617571864952,
      "loss": 2.5513,
      "step": 413140
    },
    {
      "epoch": 664.24,
      "learning_rate": 0.033602960287781355,
      "loss": 2.5701,
      "step": 413160
    },
    {
      "epoch": 664.28,
      "learning_rate": 0.03359974485691319,
      "loss": 2.5574,
      "step": 413180
    },
    {
      "epoch": 664.31,
      "learning_rate": 0.03359652942604502,
      "loss": 2.5268,
      "step": 413200
    },
    {
      "epoch": 664.34,
      "learning_rate": 0.03359331399517685,
      "loss": 2.5477,
      "step": 413220
    },
    {
      "epoch": 664.37,
      "learning_rate": 0.03359009856430868,
      "loss": 2.5552,
      "step": 413240
    },
    {
      "epoch": 664.41,
      "learning_rate": 0.03358688313344052,
      "loss": 2.5464,
      "step": 413260
    },
    {
      "epoch": 664.44,
      "learning_rate": 0.03358366770257235,
      "loss": 2.55,
      "step": 413280
    },
    {
      "epoch": 664.47,
      "learning_rate": 0.033580452271704184,
      "loss": 2.5635,
      "step": 413300
    },
    {
      "epoch": 664.5,
      "learning_rate": 0.033577236840836015,
      "loss": 2.5667,
      "step": 413320
    },
    {
      "epoch": 664.53,
      "learning_rate": 0.03357402140996785,
      "loss": 2.5528,
      "step": 413340
    },
    {
      "epoch": 664.57,
      "learning_rate": 0.03357080597909968,
      "loss": 2.5642,
      "step": 413360
    },
    {
      "epoch": 664.6,
      "learning_rate": 0.03356759054823152,
      "loss": 2.5506,
      "step": 413380
    },
    {
      "epoch": 664.63,
      "learning_rate": 0.03356437511736335,
      "loss": 2.5425,
      "step": 413400
    },
    {
      "epoch": 664.66,
      "learning_rate": 0.03356115968649518,
      "loss": 2.5531,
      "step": 413420
    },
    {
      "epoch": 664.69,
      "learning_rate": 0.03355794425562701,
      "loss": 2.5488,
      "step": 413440
    },
    {
      "epoch": 664.73,
      "learning_rate": 0.033554728824758843,
      "loss": 2.557,
      "step": 413460
    },
    {
      "epoch": 664.76,
      "learning_rate": 0.033551513393890675,
      "loss": 2.5501,
      "step": 413480
    },
    {
      "epoch": 664.79,
      "learning_rate": 0.033548297963022514,
      "loss": 2.5656,
      "step": 413500
    },
    {
      "epoch": 664.82,
      "learning_rate": 0.033545082532154345,
      "loss": 2.5616,
      "step": 413520
    },
    {
      "epoch": 664.86,
      "learning_rate": 0.03354186710128618,
      "loss": 2.5469,
      "step": 413540
    },
    {
      "epoch": 664.89,
      "learning_rate": 0.03353865167041801,
      "loss": 2.5185,
      "step": 413560
    },
    {
      "epoch": 664.92,
      "learning_rate": 0.03353543623954984,
      "loss": 2.5495,
      "step": 413580
    },
    {
      "epoch": 664.95,
      "learning_rate": 0.03353222080868168,
      "loss": 2.552,
      "step": 413600
    },
    {
      "epoch": 664.98,
      "learning_rate": 0.03352900537781351,
      "loss": 2.5497,
      "step": 413620
    },
    {
      "epoch": 665.0,
      "eval_accuracy": {
        "accuracy": 0.434502060172588
      },
      "eval_loss": 2.6508448123931885,
      "eval_runtime": 3.3048,
      "eval_samples_per_second": 3892.208,
      "eval_steps_per_second": 60.82,
      "step": 413630
    },
    {
      "epoch": 665.02,
      "learning_rate": 0.03352578994694534,
      "loss": 2.5411,
      "step": 413640
    },
    {
      "epoch": 665.05,
      "learning_rate": 0.033522574516077173,
      "loss": 2.5244,
      "step": 413660
    },
    {
      "epoch": 665.08,
      "learning_rate": 0.033519359085209005,
      "loss": 2.5558,
      "step": 413680
    },
    {
      "epoch": 665.11,
      "learning_rate": 0.03351614365434084,
      "loss": 2.5492,
      "step": 413700
    },
    {
      "epoch": 665.14,
      "learning_rate": 0.033512928223472675,
      "loss": 2.5338,
      "step": 413720
    },
    {
      "epoch": 665.18,
      "learning_rate": 0.03350971279260451,
      "loss": 2.5592,
      "step": 413740
    },
    {
      "epoch": 665.21,
      "learning_rate": 0.03350649736173634,
      "loss": 2.5529,
      "step": 413760
    },
    {
      "epoch": 665.24,
      "learning_rate": 0.03350344270241158,
      "loss": 2.5554,
      "step": 413780
    },
    {
      "epoch": 665.27,
      "learning_rate": 0.03350022727154341,
      "loss": 2.539,
      "step": 413800
    },
    {
      "epoch": 665.31,
      "learning_rate": 0.033497011840675245,
      "loss": 2.5703,
      "step": 413820
    },
    {
      "epoch": 665.34,
      "learning_rate": 0.033493796409807076,
      "loss": 2.5898,
      "step": 413840
    },
    {
      "epoch": 665.37,
      "learning_rate": 0.033490580978938915,
      "loss": 2.5641,
      "step": 413860
    },
    {
      "epoch": 665.4,
      "learning_rate": 0.03348736554807075,
      "loss": 2.5512,
      "step": 413880
    },
    {
      "epoch": 665.43,
      "learning_rate": 0.03348415011720258,
      "loss": 2.5637,
      "step": 413900
    },
    {
      "epoch": 665.47,
      "learning_rate": 0.03348093468633441,
      "loss": 2.5664,
      "step": 413920
    },
    {
      "epoch": 665.5,
      "learning_rate": 0.03347771925546624,
      "loss": 2.5743,
      "step": 413940
    },
    {
      "epoch": 665.53,
      "learning_rate": 0.033474503824598066,
      "loss": 2.5707,
      "step": 413960
    },
    {
      "epoch": 665.56,
      "learning_rate": 0.03347128839372991,
      "loss": 2.5612,
      "step": 413980
    },
    {
      "epoch": 665.59,
      "learning_rate": 0.03346807296286174,
      "loss": 2.5542,
      "step": 414000
    },
    {
      "epoch": 665.63,
      "learning_rate": 0.033464857531993575,
      "loss": 2.5584,
      "step": 414020
    },
    {
      "epoch": 665.66,
      "learning_rate": 0.033461642101125406,
      "loss": 2.5395,
      "step": 414040
    },
    {
      "epoch": 665.69,
      "learning_rate": 0.03345842667025723,
      "loss": 2.546,
      "step": 414060
    },
    {
      "epoch": 665.72,
      "learning_rate": 0.03345521123938908,
      "loss": 2.5603,
      "step": 414080
    },
    {
      "epoch": 665.76,
      "learning_rate": 0.03345199580852091,
      "loss": 2.5238,
      "step": 414100
    },
    {
      "epoch": 665.79,
      "learning_rate": 0.03344878037765274,
      "loss": 2.5329,
      "step": 414120
    },
    {
      "epoch": 665.82,
      "learning_rate": 0.03344556494678457,
      "loss": 2.5425,
      "step": 414140
    },
    {
      "epoch": 665.85,
      "learning_rate": 0.0334423495159164,
      "loss": 2.5398,
      "step": 414160
    },
    {
      "epoch": 665.88,
      "learning_rate": 0.03343913408504823,
      "loss": 2.5338,
      "step": 414180
    },
    {
      "epoch": 665.92,
      "learning_rate": 0.03343591865418007,
      "loss": 2.5545,
      "step": 414200
    },
    {
      "epoch": 665.95,
      "learning_rate": 0.033432703223311905,
      "loss": 2.5579,
      "step": 414220
    },
    {
      "epoch": 665.98,
      "learning_rate": 0.033429487792443736,
      "loss": 2.5525,
      "step": 414240
    },
    {
      "epoch": 666.0,
      "eval_accuracy": {
        "accuracy": 0.432947212936329
      },
      "eval_loss": 2.645244598388672,
      "eval_runtime": 2.9752,
      "eval_samples_per_second": 4323.411,
      "eval_steps_per_second": 67.559,
      "step": 414252
    },
    {
      "epoch": 666.01,
      "learning_rate": 0.03342627236157557,
      "loss": 2.5603,
      "step": 414260
    },
    {
      "epoch": 666.05,
      "learning_rate": 0.03342305693070739,
      "loss": 2.5532,
      "step": 414280
    },
    {
      "epoch": 666.08,
      "learning_rate": 0.033419841499839224,
      "loss": 2.5321,
      "step": 414300
    },
    {
      "epoch": 666.11,
      "learning_rate": 0.03341662606897107,
      "loss": 2.5663,
      "step": 414320
    },
    {
      "epoch": 666.14,
      "learning_rate": 0.0334134106381029,
      "loss": 2.5551,
      "step": 414340
    },
    {
      "epoch": 666.17,
      "learning_rate": 0.03341019520723473,
      "loss": 2.5405,
      "step": 414360
    },
    {
      "epoch": 666.21,
      "learning_rate": 0.03340697977636656,
      "loss": 2.573,
      "step": 414380
    },
    {
      "epoch": 666.24,
      "learning_rate": 0.03340376434549839,
      "loss": 2.5332,
      "step": 414400
    },
    {
      "epoch": 666.27,
      "learning_rate": 0.033400548914630235,
      "loss": 2.5374,
      "step": 414420
    },
    {
      "epoch": 666.3,
      "learning_rate": 0.033397333483762066,
      "loss": 2.5579,
      "step": 414440
    },
    {
      "epoch": 666.33,
      "learning_rate": 0.0333941180528939,
      "loss": 2.541,
      "step": 414460
    },
    {
      "epoch": 666.37,
      "learning_rate": 0.03339090262202573,
      "loss": 2.5449,
      "step": 414480
    },
    {
      "epoch": 666.4,
      "learning_rate": 0.033387687191157554,
      "loss": 2.5732,
      "step": 414500
    },
    {
      "epoch": 666.43,
      "learning_rate": 0.033384471760289386,
      "loss": 2.5662,
      "step": 414520
    },
    {
      "epoch": 666.46,
      "learning_rate": 0.03338125632942123,
      "loss": 2.5546,
      "step": 414540
    },
    {
      "epoch": 666.5,
      "learning_rate": 0.03337804089855306,
      "loss": 2.5446,
      "step": 414560
    },
    {
      "epoch": 666.53,
      "learning_rate": 0.033374825467684895,
      "loss": 2.5588,
      "step": 414580
    },
    {
      "epoch": 666.56,
      "learning_rate": 0.03337161003681672,
      "loss": 2.5603,
      "step": 414600
    },
    {
      "epoch": 666.59,
      "learning_rate": 0.03336839460594855,
      "loss": 2.5563,
      "step": 414620
    },
    {
      "epoch": 666.62,
      "learning_rate": 0.03336517917508038,
      "loss": 2.5393,
      "step": 414640
    },
    {
      "epoch": 666.66,
      "learning_rate": 0.03336196374421223,
      "loss": 2.5626,
      "step": 414660
    },
    {
      "epoch": 666.69,
      "learning_rate": 0.03335874831334406,
      "loss": 2.5249,
      "step": 414680
    },
    {
      "epoch": 666.72,
      "learning_rate": 0.033355532882475884,
      "loss": 2.5402,
      "step": 414700
    },
    {
      "epoch": 666.75,
      "learning_rate": 0.033352317451607716,
      "loss": 2.5263,
      "step": 414720
    },
    {
      "epoch": 666.78,
      "learning_rate": 0.03334910202073955,
      "loss": 2.5398,
      "step": 414740
    },
    {
      "epoch": 666.82,
      "learning_rate": 0.03334588658987139,
      "loss": 2.5403,
      "step": 414760
    },
    {
      "epoch": 666.85,
      "learning_rate": 0.033342671159003225,
      "loss": 2.5292,
      "step": 414780
    },
    {
      "epoch": 666.88,
      "learning_rate": 0.033339455728135056,
      "loss": 2.5708,
      "step": 414800
    },
    {
      "epoch": 666.91,
      "learning_rate": 0.03333624029726688,
      "loss": 2.5472,
      "step": 414820
    },
    {
      "epoch": 666.95,
      "learning_rate": 0.03333302486639871,
      "loss": 2.5685,
      "step": 414840
    },
    {
      "epoch": 666.98,
      "learning_rate": 0.033329809435530544,
      "loss": 2.5799,
      "step": 414860
    },
    {
      "epoch": 667.0,
      "eval_accuracy": {
        "accuracy": 0.4328694705745161
      },
      "eval_loss": 2.6688642501831055,
      "eval_runtime": 2.9655,
      "eval_samples_per_second": 4337.478,
      "eval_steps_per_second": 67.778,
      "step": 414874
    },
    {
      "epoch": 667.01,
      "learning_rate": 0.03332659400466239,
      "loss": 2.5625,
      "step": 414880
    },
    {
      "epoch": 667.04,
      "learning_rate": 0.03332337857379422,
      "loss": 2.5485,
      "step": 414900
    },
    {
      "epoch": 667.07,
      "learning_rate": 0.033320163142926046,
      "loss": 2.5553,
      "step": 414920
    },
    {
      "epoch": 667.11,
      "learning_rate": 0.03331694771205788,
      "loss": 2.5602,
      "step": 414940
    },
    {
      "epoch": 667.14,
      "learning_rate": 0.03331373228118971,
      "loss": 2.55,
      "step": 414960
    },
    {
      "epoch": 667.17,
      "learning_rate": 0.033310516850321555,
      "loss": 2.559,
      "step": 414980
    },
    {
      "epoch": 667.2,
      "learning_rate": 0.033307301419453386,
      "loss": 2.5713,
      "step": 415000
    },
    {
      "epoch": 667.23,
      "learning_rate": 0.03330408598858521,
      "loss": 2.546,
      "step": 415020
    },
    {
      "epoch": 667.27,
      "learning_rate": 0.03330087055771704,
      "loss": 2.551,
      "step": 415040
    },
    {
      "epoch": 667.3,
      "learning_rate": 0.033297655126848874,
      "loss": 2.5492,
      "step": 415060
    },
    {
      "epoch": 667.33,
      "learning_rate": 0.033294439695980706,
      "loss": 2.5485,
      "step": 415080
    },
    {
      "epoch": 667.36,
      "learning_rate": 0.03329122426511255,
      "loss": 2.5366,
      "step": 415100
    },
    {
      "epoch": 667.4,
      "learning_rate": 0.03328800883424438,
      "loss": 2.561,
      "step": 415120
    },
    {
      "epoch": 667.43,
      "learning_rate": 0.03328479340337621,
      "loss": 2.5768,
      "step": 415140
    },
    {
      "epoch": 667.46,
      "learning_rate": 0.03328157797250804,
      "loss": 2.5422,
      "step": 415160
    },
    {
      "epoch": 667.49,
      "learning_rate": 0.03327836254163987,
      "loss": 2.5353,
      "step": 415180
    },
    {
      "epoch": 667.52,
      "learning_rate": 0.0332751471107717,
      "loss": 2.5207,
      "step": 415200
    },
    {
      "epoch": 667.56,
      "learning_rate": 0.03327193167990355,
      "loss": 2.5532,
      "step": 415220
    },
    {
      "epoch": 667.59,
      "learning_rate": 0.03326871624903537,
      "loss": 2.5881,
      "step": 415240
    },
    {
      "epoch": 667.62,
      "learning_rate": 0.033265500818167204,
      "loss": 2.5499,
      "step": 415260
    },
    {
      "epoch": 667.65,
      "learning_rate": 0.033262285387299036,
      "loss": 2.5587,
      "step": 415280
    },
    {
      "epoch": 667.68,
      "learning_rate": 0.03325906995643087,
      "loss": 2.5471,
      "step": 415300
    },
    {
      "epoch": 667.72,
      "learning_rate": 0.03325585452556271,
      "loss": 2.5429,
      "step": 415320
    },
    {
      "epoch": 667.75,
      "learning_rate": 0.03325263909469454,
      "loss": 2.5407,
      "step": 415340
    },
    {
      "epoch": 667.78,
      "learning_rate": 0.03324942366382637,
      "loss": 2.5641,
      "step": 415360
    },
    {
      "epoch": 667.81,
      "learning_rate": 0.0332462082329582,
      "loss": 2.543,
      "step": 415380
    },
    {
      "epoch": 667.85,
      "learning_rate": 0.03324299280209003,
      "loss": 2.5512,
      "step": 415400
    },
    {
      "epoch": 667.88,
      "learning_rate": 0.033239777371221864,
      "loss": 2.5614,
      "step": 415420
    },
    {
      "epoch": 667.91,
      "learning_rate": 0.03323656194035371,
      "loss": 2.5538,
      "step": 415440
    },
    {
      "epoch": 667.94,
      "learning_rate": 0.033233346509485534,
      "loss": 2.5513,
      "step": 415460
    },
    {
      "epoch": 667.97,
      "learning_rate": 0.033230131078617366,
      "loss": 2.5548,
      "step": 415480
    },
    {
      "epoch": 668.0,
      "eval_accuracy": {
        "accuracy": 0.42944880665474616
      },
      "eval_loss": 2.664910316467285,
      "eval_runtime": 2.995,
      "eval_samples_per_second": 4294.765,
      "eval_steps_per_second": 67.111,
      "step": 415496
    },
    {
      "epoch": 668.01,
      "learning_rate": 0.0332269156477492,
      "loss": 2.5361,
      "step": 415500
    },
    {
      "epoch": 668.04,
      "learning_rate": 0.03322370021688103,
      "loss": 2.5502,
      "step": 415520
    },
    {
      "epoch": 668.07,
      "learning_rate": 0.03322048478601286,
      "loss": 2.5337,
      "step": 415540
    },
    {
      "epoch": 668.1,
      "learning_rate": 0.0332172693551447,
      "loss": 2.5362,
      "step": 415560
    },
    {
      "epoch": 668.14,
      "learning_rate": 0.03321405392427653,
      "loss": 2.5635,
      "step": 415580
    },
    {
      "epoch": 668.17,
      "learning_rate": 0.03321083849340836,
      "loss": 2.5434,
      "step": 415600
    },
    {
      "epoch": 668.2,
      "learning_rate": 0.033207623062540194,
      "loss": 2.5547,
      "step": 415620
    },
    {
      "epoch": 668.23,
      "learning_rate": 0.033204407631672025,
      "loss": 2.5525,
      "step": 415640
    },
    {
      "epoch": 668.26,
      "learning_rate": 0.033201192200803864,
      "loss": 2.5425,
      "step": 415660
    },
    {
      "epoch": 668.3,
      "learning_rate": 0.033197976769935696,
      "loss": 2.5455,
      "step": 415680
    },
    {
      "epoch": 668.33,
      "learning_rate": 0.03319476133906753,
      "loss": 2.546,
      "step": 415700
    },
    {
      "epoch": 668.36,
      "learning_rate": 0.03319154590819936,
      "loss": 2.5292,
      "step": 415720
    },
    {
      "epoch": 668.39,
      "learning_rate": 0.03318833047733119,
      "loss": 2.582,
      "step": 415740
    },
    {
      "epoch": 668.42,
      "learning_rate": 0.03318511504646302,
      "loss": 2.5468,
      "step": 415760
    },
    {
      "epoch": 668.46,
      "learning_rate": 0.03318189961559486,
      "loss": 2.5572,
      "step": 415780
    },
    {
      "epoch": 668.49,
      "learning_rate": 0.03317868418472669,
      "loss": 2.5513,
      "step": 415800
    },
    {
      "epoch": 668.52,
      "learning_rate": 0.033175468753858524,
      "loss": 2.5537,
      "step": 415820
    },
    {
      "epoch": 668.55,
      "learning_rate": 0.033172253322990355,
      "loss": 2.5656,
      "step": 415840
    },
    {
      "epoch": 668.59,
      "learning_rate": 0.03316903789212219,
      "loss": 2.5535,
      "step": 415860
    },
    {
      "epoch": 668.62,
      "learning_rate": 0.03316582246125402,
      "loss": 2.5678,
      "step": 415880
    },
    {
      "epoch": 668.65,
      "learning_rate": 0.03316260703038586,
      "loss": 2.5415,
      "step": 415900
    },
    {
      "epoch": 668.68,
      "learning_rate": 0.03315939159951769,
      "loss": 2.5573,
      "step": 415920
    },
    {
      "epoch": 668.71,
      "learning_rate": 0.03315617616864952,
      "loss": 2.5632,
      "step": 415940
    },
    {
      "epoch": 668.75,
      "learning_rate": 0.03315296073778135,
      "loss": 2.5381,
      "step": 415960
    },
    {
      "epoch": 668.78,
      "learning_rate": 0.033149745306913184,
      "loss": 2.5457,
      "step": 415980
    },
    {
      "epoch": 668.81,
      "learning_rate": 0.03314652987604502,
      "loss": 2.5623,
      "step": 416000
    },
    {
      "epoch": 668.84,
      "learning_rate": 0.033143314445176854,
      "loss": 2.5576,
      "step": 416020
    },
    {
      "epoch": 668.87,
      "learning_rate": 0.033140099014308685,
      "loss": 2.5436,
      "step": 416040
    },
    {
      "epoch": 668.91,
      "learning_rate": 0.03313688358344052,
      "loss": 2.5425,
      "step": 416060
    },
    {
      "epoch": 668.94,
      "learning_rate": 0.03313366815257235,
      "loss": 2.54,
      "step": 416080
    },
    {
      "epoch": 668.97,
      "learning_rate": 0.03313045272170418,
      "loss": 2.5664,
      "step": 416100
    },
    {
      "epoch": 669.0,
      "eval_accuracy": {
        "accuracy": 0.42836041358936483
      },
      "eval_loss": 2.683856964111328,
      "eval_runtime": 3.0376,
      "eval_samples_per_second": 4234.581,
      "eval_steps_per_second": 66.17,
      "step": 416118
    },
    {
      "epoch": 669.0,
      "learning_rate": 0.03312723729083602,
      "loss": 2.5645,
      "step": 416120
    },
    {
      "epoch": 669.04,
      "learning_rate": 0.03312402185996785,
      "loss": 2.532,
      "step": 416140
    },
    {
      "epoch": 669.07,
      "learning_rate": 0.03312080642909968,
      "loss": 2.5484,
      "step": 416160
    },
    {
      "epoch": 669.1,
      "learning_rate": 0.033117590998231514,
      "loss": 2.5303,
      "step": 416180
    },
    {
      "epoch": 669.13,
      "learning_rate": 0.033114375567363345,
      "loss": 2.5447,
      "step": 416200
    },
    {
      "epoch": 669.16,
      "learning_rate": 0.03311116013649518,
      "loss": 2.5499,
      "step": 416220
    },
    {
      "epoch": 669.2,
      "learning_rate": 0.033107944705627015,
      "loss": 2.5485,
      "step": 416240
    },
    {
      "epoch": 669.23,
      "learning_rate": 0.03310472927475885,
      "loss": 2.5461,
      "step": 416260
    },
    {
      "epoch": 669.26,
      "learning_rate": 0.03310151384389068,
      "loss": 2.5422,
      "step": 416280
    },
    {
      "epoch": 669.29,
      "learning_rate": 0.03309829841302251,
      "loss": 2.5455,
      "step": 416300
    },
    {
      "epoch": 669.32,
      "learning_rate": 0.03309508298215434,
      "loss": 2.5404,
      "step": 416320
    },
    {
      "epoch": 669.36,
      "learning_rate": 0.03309186755128618,
      "loss": 2.5478,
      "step": 416340
    },
    {
      "epoch": 669.39,
      "learning_rate": 0.03308865212041801,
      "loss": 2.5509,
      "step": 416360
    },
    {
      "epoch": 669.42,
      "learning_rate": 0.033085436689549844,
      "loss": 2.568,
      "step": 416380
    },
    {
      "epoch": 669.45,
      "learning_rate": 0.033082221258681675,
      "loss": 2.5535,
      "step": 416400
    },
    {
      "epoch": 669.49,
      "learning_rate": 0.03307900582781351,
      "loss": 2.5453,
      "step": 416420
    },
    {
      "epoch": 669.52,
      "learning_rate": 0.03307579039694534,
      "loss": 2.5576,
      "step": 416440
    },
    {
      "epoch": 669.55,
      "learning_rate": 0.03307257496607718,
      "loss": 2.544,
      "step": 416460
    },
    {
      "epoch": 669.58,
      "learning_rate": 0.03306935953520901,
      "loss": 2.5353,
      "step": 416480
    },
    {
      "epoch": 669.61,
      "learning_rate": 0.03306614410434084,
      "loss": 2.5432,
      "step": 416500
    },
    {
      "epoch": 669.65,
      "learning_rate": 0.03306292867347267,
      "loss": 2.5515,
      "step": 416520
    },
    {
      "epoch": 669.68,
      "learning_rate": 0.0330597132426045,
      "loss": 2.5715,
      "step": 416540
    },
    {
      "epoch": 669.71,
      "learning_rate": 0.03305649781173634,
      "loss": 2.5502,
      "step": 416560
    },
    {
      "epoch": 669.74,
      "learning_rate": 0.033053282380868174,
      "loss": 2.5657,
      "step": 416580
    },
    {
      "epoch": 669.77,
      "learning_rate": 0.033050066950000005,
      "loss": 2.5251,
      "step": 416600
    },
    {
      "epoch": 669.81,
      "learning_rate": 0.03304685151913184,
      "loss": 2.564,
      "step": 416620
    },
    {
      "epoch": 669.84,
      "learning_rate": 0.03304363608826367,
      "loss": 2.5685,
      "step": 416640
    },
    {
      "epoch": 669.87,
      "learning_rate": 0.0330404206573955,
      "loss": 2.5396,
      "step": 416660
    },
    {
      "epoch": 669.9,
      "learning_rate": 0.03303720522652734,
      "loss": 2.5443,
      "step": 416680
    },
    {
      "epoch": 669.94,
      "learning_rate": 0.03303398979565917,
      "loss": 2.5406,
      "step": 416700
    },
    {
      "epoch": 669.97,
      "learning_rate": 0.033030774364791,
      "loss": 2.553,
      "step": 416720
    },
    {
      "epoch": 670.0,
      "learning_rate": 0.03302755893392283,
      "loss": 2.5505,
      "step": 416740
    },
    {
      "epoch": 670.0,
      "eval_accuracy": {
        "accuracy": 0.4319365622327606
      },
      "eval_loss": 2.658137083053589,
      "eval_runtime": 3.0685,
      "eval_samples_per_second": 4191.891,
      "eval_steps_per_second": 65.503,
      "step": 416740
    },
    {
      "epoch": 670.03,
      "learning_rate": 0.033024343503054665,
      "loss": 2.5547,
      "step": 416760
    },
    {
      "epoch": 670.06,
      "learning_rate": 0.0330211280721865,
      "loss": 2.556,
      "step": 416780
    },
    {
      "epoch": 670.1,
      "learning_rate": 0.033017912641318335,
      "loss": 2.5579,
      "step": 416800
    },
    {
      "epoch": 670.13,
      "learning_rate": 0.03301469721045017,
      "loss": 2.5667,
      "step": 416820
    },
    {
      "epoch": 670.16,
      "learning_rate": 0.033011481779582,
      "loss": 2.5204,
      "step": 416840
    },
    {
      "epoch": 670.19,
      "learning_rate": 0.03300826634871383,
      "loss": 2.5385,
      "step": 416860
    },
    {
      "epoch": 670.23,
      "learning_rate": 0.03300505091784566,
      "loss": 2.5627,
      "step": 416880
    },
    {
      "epoch": 670.26,
      "learning_rate": 0.0330018354869775,
      "loss": 2.5414,
      "step": 416900
    },
    {
      "epoch": 670.29,
      "learning_rate": 0.03299862005610933,
      "loss": 2.513,
      "step": 416920
    },
    {
      "epoch": 670.32,
      "learning_rate": 0.03299540462524116,
      "loss": 2.5301,
      "step": 416940
    },
    {
      "epoch": 670.35,
      "learning_rate": 0.032992189194372995,
      "loss": 2.5426,
      "step": 416960
    },
    {
      "epoch": 670.39,
      "learning_rate": 0.03298897376350483,
      "loss": 2.5571,
      "step": 416980
    },
    {
      "epoch": 670.42,
      "learning_rate": 0.03298575833263666,
      "loss": 2.5397,
      "step": 417000
    },
    {
      "epoch": 670.45,
      "learning_rate": 0.0329825429017685,
      "loss": 2.5344,
      "step": 417020
    },
    {
      "epoch": 670.48,
      "learning_rate": 0.03297932747090033,
      "loss": 2.5554,
      "step": 417040
    },
    {
      "epoch": 670.51,
      "learning_rate": 0.03297611204003216,
      "loss": 2.5408,
      "step": 417060
    },
    {
      "epoch": 670.55,
      "learning_rate": 0.03297289660916399,
      "loss": 2.5608,
      "step": 417080
    },
    {
      "epoch": 670.58,
      "learning_rate": 0.03296968117829582,
      "loss": 2.5484,
      "step": 417100
    },
    {
      "epoch": 670.61,
      "learning_rate": 0.032966465747427655,
      "loss": 2.5591,
      "step": 417120
    },
    {
      "epoch": 670.64,
      "learning_rate": 0.03296325031655949,
      "loss": 2.5616,
      "step": 417140
    },
    {
      "epoch": 670.68,
      "learning_rate": 0.032960034885691325,
      "loss": 2.5354,
      "step": 417160
    },
    {
      "epoch": 670.71,
      "learning_rate": 0.03295681945482316,
      "loss": 2.5412,
      "step": 417180
    },
    {
      "epoch": 670.74,
      "learning_rate": 0.03295360402395499,
      "loss": 2.5368,
      "step": 417200
    },
    {
      "epoch": 670.77,
      "learning_rate": 0.03295038859308682,
      "loss": 2.5514,
      "step": 417220
    },
    {
      "epoch": 670.8,
      "learning_rate": 0.03294717316221866,
      "loss": 2.5523,
      "step": 417240
    },
    {
      "epoch": 670.84,
      "learning_rate": 0.03294395773135049,
      "loss": 2.5627,
      "step": 417260
    },
    {
      "epoch": 670.87,
      "learning_rate": 0.03294074230048232,
      "loss": 2.5428,
      "step": 417280
    },
    {
      "epoch": 670.9,
      "learning_rate": 0.03293752686961415,
      "loss": 2.5506,
      "step": 417300
    },
    {
      "epoch": 670.93,
      "learning_rate": 0.032934311438745985,
      "loss": 2.5704,
      "step": 417320
    },
    {
      "epoch": 670.96,
      "learning_rate": 0.03293109600787781,
      "loss": 2.5286,
      "step": 417340
    },
    {
      "epoch": 671.0,
      "learning_rate": 0.032927880577009655,
      "loss": 2.5719,
      "step": 417360
    },
    {
      "epoch": 671.0,
      "eval_accuracy": {
        "accuracy": 0.4368343310269766
      },
      "eval_loss": 2.6720693111419678,
      "eval_runtime": 3.3006,
      "eval_samples_per_second": 3897.226,
      "eval_steps_per_second": 60.899,
      "step": 417362
    },
    {
      "epoch": 671.03,
      "learning_rate": 0.03292466514614149,
      "loss": 2.5446,
      "step": 417380
    },
    {
      "epoch": 671.06,
      "learning_rate": 0.03292144971527332,
      "loss": 2.5517,
      "step": 417400
    },
    {
      "epoch": 671.09,
      "learning_rate": 0.03291823428440515,
      "loss": 2.5419,
      "step": 417420
    },
    {
      "epoch": 671.13,
      "learning_rate": 0.03291501885353698,
      "loss": 2.5396,
      "step": 417440
    },
    {
      "epoch": 671.16,
      "learning_rate": 0.032911803422668806,
      "loss": 2.528,
      "step": 417460
    },
    {
      "epoch": 671.19,
      "learning_rate": 0.03290858799180065,
      "loss": 2.5295,
      "step": 417480
    },
    {
      "epoch": 671.22,
      "learning_rate": 0.03290537256093248,
      "loss": 2.553,
      "step": 417500
    },
    {
      "epoch": 671.25,
      "learning_rate": 0.032902157130064315,
      "loss": 2.5435,
      "step": 417520
    },
    {
      "epoch": 671.29,
      "learning_rate": 0.032898941699196146,
      "loss": 2.5493,
      "step": 417540
    },
    {
      "epoch": 671.32,
      "learning_rate": 0.03289572626832797,
      "loss": 2.5385,
      "step": 417560
    },
    {
      "epoch": 671.35,
      "learning_rate": 0.03289251083745982,
      "loss": 2.563,
      "step": 417580
    },
    {
      "epoch": 671.38,
      "learning_rate": 0.03288929540659165,
      "loss": 2.5329,
      "step": 417600
    },
    {
      "epoch": 671.41,
      "learning_rate": 0.03288607997572348,
      "loss": 2.5569,
      "step": 417620
    },
    {
      "epoch": 671.45,
      "learning_rate": 0.03288286454485531,
      "loss": 2.5215,
      "step": 417640
    },
    {
      "epoch": 671.48,
      "learning_rate": 0.032879649113987136,
      "loss": 2.5481,
      "step": 417660
    },
    {
      "epoch": 671.51,
      "learning_rate": 0.03287643368311897,
      "loss": 2.5245,
      "step": 417680
    },
    {
      "epoch": 671.54,
      "learning_rate": 0.03287321825225081,
      "loss": 2.5601,
      "step": 417700
    },
    {
      "epoch": 671.58,
      "learning_rate": 0.032870002821382645,
      "loss": 2.5342,
      "step": 417720
    },
    {
      "epoch": 671.61,
      "learning_rate": 0.032866787390514476,
      "loss": 2.5586,
      "step": 417740
    },
    {
      "epoch": 671.64,
      "learning_rate": 0.03286357195964631,
      "loss": 2.5422,
      "step": 417760
    },
    {
      "epoch": 671.67,
      "learning_rate": 0.032860517300321544,
      "loss": 2.5311,
      "step": 417780
    },
    {
      "epoch": 671.7,
      "learning_rate": 0.032857301869453376,
      "loss": 2.5413,
      "step": 417800
    },
    {
      "epoch": 671.74,
      "learning_rate": 0.03285408643858521,
      "loss": 2.5335,
      "step": 417820
    },
    {
      "epoch": 671.77,
      "learning_rate": 0.03285087100771705,
      "loss": 2.528,
      "step": 417840
    },
    {
      "epoch": 671.8,
      "learning_rate": 0.032847655576848885,
      "loss": 2.554,
      "step": 417860
    },
    {
      "epoch": 671.83,
      "learning_rate": 0.03284444014598071,
      "loss": 2.5339,
      "step": 417880
    },
    {
      "epoch": 671.86,
      "learning_rate": 0.03284122471511254,
      "loss": 2.5405,
      "step": 417900
    },
    {
      "epoch": 671.9,
      "learning_rate": 0.03283800928424437,
      "loss": 2.5392,
      "step": 417920
    },
    {
      "epoch": 671.93,
      "learning_rate": 0.032834793853376204,
      "loss": 2.5533,
      "step": 417940
    },
    {
      "epoch": 671.96,
      "learning_rate": 0.03283157842250805,
      "loss": 2.5425,
      "step": 417960
    },
    {
      "epoch": 671.99,
      "learning_rate": 0.032828362991639874,
      "loss": 2.5595,
      "step": 417980
    },
    {
      "epoch": 672.0,
      "eval_accuracy": {
        "accuracy": 0.43318044002176787
      },
      "eval_loss": 2.659647226333618,
      "eval_runtime": 3.0904,
      "eval_samples_per_second": 4162.284,
      "eval_steps_per_second": 65.041,
      "step": 417984
    },
    {
      "epoch": 672.03,
      "learning_rate": 0.032825147560771706,
      "loss": 2.5544,
      "step": 418000
    },
    {
      "epoch": 672.06,
      "learning_rate": 0.03282193212990354,
      "loss": 2.5486,
      "step": 418020
    },
    {
      "epoch": 672.09,
      "learning_rate": 0.03281871669903537,
      "loss": 2.5464,
      "step": 418040
    },
    {
      "epoch": 672.12,
      "learning_rate": 0.032815501268167215,
      "loss": 2.5472,
      "step": 418060
    },
    {
      "epoch": 672.15,
      "learning_rate": 0.03281228583729904,
      "loss": 2.5456,
      "step": 418080
    },
    {
      "epoch": 672.19,
      "learning_rate": 0.03280907040643087,
      "loss": 2.5302,
      "step": 418100
    },
    {
      "epoch": 672.22,
      "learning_rate": 0.0328058549755627,
      "loss": 2.5472,
      "step": 418120
    },
    {
      "epoch": 672.25,
      "learning_rate": 0.032802639544694534,
      "loss": 2.5351,
      "step": 418140
    },
    {
      "epoch": 672.28,
      "learning_rate": 0.032799424113826366,
      "loss": 2.575,
      "step": 418160
    },
    {
      "epoch": 672.32,
      "learning_rate": 0.03279620868295821,
      "loss": 2.5475,
      "step": 418180
    },
    {
      "epoch": 672.35,
      "learning_rate": 0.032792993252090036,
      "loss": 2.5652,
      "step": 418200
    },
    {
      "epoch": 672.38,
      "learning_rate": 0.03278977782122187,
      "loss": 2.5621,
      "step": 418220
    },
    {
      "epoch": 672.41,
      "learning_rate": 0.0327865623903537,
      "loss": 2.5316,
      "step": 418240
    },
    {
      "epoch": 672.44,
      "learning_rate": 0.03278334695948553,
      "loss": 2.5504,
      "step": 418260
    },
    {
      "epoch": 672.48,
      "learning_rate": 0.03278013152861736,
      "loss": 2.5402,
      "step": 418280
    },
    {
      "epoch": 672.51,
      "learning_rate": 0.0327769160977492,
      "loss": 2.5425,
      "step": 418300
    },
    {
      "epoch": 672.54,
      "learning_rate": 0.03277370066688103,
      "loss": 2.5437,
      "step": 418320
    },
    {
      "epoch": 672.57,
      "learning_rate": 0.032770485236012864,
      "loss": 2.5582,
      "step": 418340
    },
    {
      "epoch": 672.6,
      "learning_rate": 0.032767269805144696,
      "loss": 2.5669,
      "step": 418360
    },
    {
      "epoch": 672.64,
      "learning_rate": 0.03276405437427653,
      "loss": 2.5429,
      "step": 418380
    },
    {
      "epoch": 672.67,
      "learning_rate": 0.032760838943408366,
      "loss": 2.5552,
      "step": 418400
    },
    {
      "epoch": 672.7,
      "learning_rate": 0.0327576235125402,
      "loss": 2.5581,
      "step": 418420
    },
    {
      "epoch": 672.73,
      "learning_rate": 0.03275440808167203,
      "loss": 2.5504,
      "step": 418440
    },
    {
      "epoch": 672.77,
      "learning_rate": 0.03275119265080386,
      "loss": 2.537,
      "step": 418460
    },
    {
      "epoch": 672.8,
      "learning_rate": 0.03274797721993569,
      "loss": 2.5476,
      "step": 418480
    },
    {
      "epoch": 672.83,
      "learning_rate": 0.032744761789067524,
      "loss": 2.546,
      "step": 418500
    },
    {
      "epoch": 672.86,
      "learning_rate": 0.03274154635819936,
      "loss": 2.551,
      "step": 418520
    },
    {
      "epoch": 672.89,
      "learning_rate": 0.032738330927331194,
      "loss": 2.5531,
      "step": 418540
    },
    {
      "epoch": 672.93,
      "learning_rate": 0.032735115496463026,
      "loss": 2.5415,
      "step": 418560
    },
    {
      "epoch": 672.96,
      "learning_rate": 0.03273190006559486,
      "loss": 2.5371,
      "step": 418580
    },
    {
      "epoch": 672.99,
      "learning_rate": 0.03272868463472669,
      "loss": 2.556,
      "step": 418600
    },
    {
      "epoch": 673.0,
      "eval_accuracy": {
        "accuracy": 0.42851589831299075
      },
      "eval_loss": 2.6949961185455322,
      "eval_runtime": 2.8841,
      "eval_samples_per_second": 4459.919,
      "eval_steps_per_second": 69.692,
      "step": 418606
    },
    {
      "epoch": 673.02,
      "learning_rate": 0.03272546920385852,
      "loss": 2.5658,
      "step": 418620
    },
    {
      "epoch": 673.05,
      "learning_rate": 0.03272225377299036,
      "loss": 2.5474,
      "step": 418640
    },
    {
      "epoch": 673.09,
      "learning_rate": 0.03271903834212219,
      "loss": 2.5344,
      "step": 418660
    },
    {
      "epoch": 673.12,
      "learning_rate": 0.03271582291125402,
      "loss": 2.5532,
      "step": 418680
    },
    {
      "epoch": 673.15,
      "learning_rate": 0.032712607480385854,
      "loss": 2.5441,
      "step": 418700
    },
    {
      "epoch": 673.18,
      "learning_rate": 0.032709392049517685,
      "loss": 2.5486,
      "step": 418720
    },
    {
      "epoch": 673.22,
      "learning_rate": 0.032706176618649524,
      "loss": 2.5332,
      "step": 418740
    },
    {
      "epoch": 673.25,
      "learning_rate": 0.032702961187781356,
      "loss": 2.5519,
      "step": 418760
    },
    {
      "epoch": 673.28,
      "learning_rate": 0.03269974575691319,
      "loss": 2.5467,
      "step": 418780
    },
    {
      "epoch": 673.31,
      "learning_rate": 0.03269653032604502,
      "loss": 2.5289,
      "step": 418800
    },
    {
      "epoch": 673.34,
      "learning_rate": 0.03269331489517685,
      "loss": 2.5562,
      "step": 418820
    },
    {
      "epoch": 673.38,
      "learning_rate": 0.03269009946430868,
      "loss": 2.565,
      "step": 418840
    },
    {
      "epoch": 673.41,
      "learning_rate": 0.03268688403344052,
      "loss": 2.5439,
      "step": 418860
    },
    {
      "epoch": 673.44,
      "learning_rate": 0.03268366860257235,
      "loss": 2.5385,
      "step": 418880
    },
    {
      "epoch": 673.47,
      "learning_rate": 0.032680453171704184,
      "loss": 2.5608,
      "step": 418900
    },
    {
      "epoch": 673.5,
      "learning_rate": 0.032677237740836015,
      "loss": 2.5552,
      "step": 418920
    },
    {
      "epoch": 673.54,
      "learning_rate": 0.03267402230996785,
      "loss": 2.5432,
      "step": 418940
    },
    {
      "epoch": 673.57,
      "learning_rate": 0.03267080687909968,
      "loss": 2.5339,
      "step": 418960
    },
    {
      "epoch": 673.6,
      "learning_rate": 0.03266759144823152,
      "loss": 2.5599,
      "step": 418980
    },
    {
      "epoch": 673.63,
      "learning_rate": 0.03266437601736335,
      "loss": 2.5344,
      "step": 419000
    },
    {
      "epoch": 673.67,
      "learning_rate": 0.03266116058649518,
      "loss": 2.551,
      "step": 419020
    },
    {
      "epoch": 673.7,
      "learning_rate": 0.03265794515562701,
      "loss": 2.5337,
      "step": 419040
    },
    {
      "epoch": 673.73,
      "learning_rate": 0.032654729724758844,
      "loss": 2.5197,
      "step": 419060
    },
    {
      "epoch": 673.76,
      "learning_rate": 0.03265151429389068,
      "loss": 2.5513,
      "step": 419080
    },
    {
      "epoch": 673.79,
      "learning_rate": 0.032648298863022514,
      "loss": 2.552,
      "step": 419100
    },
    {
      "epoch": 673.83,
      "learning_rate": 0.032645083432154345,
      "loss": 2.5471,
      "step": 419120
    },
    {
      "epoch": 673.86,
      "learning_rate": 0.03264186800128618,
      "loss": 2.5482,
      "step": 419140
    },
    {
      "epoch": 673.89,
      "learning_rate": 0.03263865257041801,
      "loss": 2.5762,
      "step": 419160
    },
    {
      "epoch": 673.92,
      "learning_rate": 0.03263543713954984,
      "loss": 2.5545,
      "step": 419180
    },
    {
      "epoch": 673.95,
      "learning_rate": 0.03263222170868168,
      "loss": 2.5598,
      "step": 419200
    },
    {
      "epoch": 673.99,
      "learning_rate": 0.03262900627781351,
      "loss": 2.5613,
      "step": 419220
    },
    {
      "epoch": 674.0,
      "eval_accuracy": {
        "accuracy": 0.4239290989660266
      },
      "eval_loss": 2.6907548904418945,
      "eval_runtime": 3.1692,
      "eval_samples_per_second": 4058.724,
      "eval_steps_per_second": 63.422,
      "step": 419228
    },
    {
      "epoch": 674.02,
      "learning_rate": 0.03262579084694534,
      "loss": 2.5655,
      "step": 419240
    },
    {
      "epoch": 674.05,
      "learning_rate": 0.032622575416077174,
      "loss": 2.5442,
      "step": 419260
    },
    {
      "epoch": 674.08,
      "learning_rate": 0.032619359985209005,
      "loss": 2.5258,
      "step": 419280
    },
    {
      "epoch": 674.12,
      "learning_rate": 0.032616144554340844,
      "loss": 2.5398,
      "step": 419300
    },
    {
      "epoch": 674.15,
      "learning_rate": 0.032612929123472675,
      "loss": 2.5518,
      "step": 419320
    },
    {
      "epoch": 674.18,
      "learning_rate": 0.03260971369260451,
      "loss": 2.5374,
      "step": 419340
    },
    {
      "epoch": 674.21,
      "learning_rate": 0.03260649826173634,
      "loss": 2.5556,
      "step": 419360
    },
    {
      "epoch": 674.24,
      "learning_rate": 0.03260328283086817,
      "loss": 2.5371,
      "step": 419380
    },
    {
      "epoch": 674.28,
      "learning_rate": 0.0326000674,
      "loss": 2.543,
      "step": 419400
    },
    {
      "epoch": 674.31,
      "learning_rate": 0.03259685196913184,
      "loss": 2.5456,
      "step": 419420
    },
    {
      "epoch": 674.34,
      "learning_rate": 0.03259363653826367,
      "loss": 2.5298,
      "step": 419440
    },
    {
      "epoch": 674.37,
      "learning_rate": 0.032590421107395504,
      "loss": 2.5403,
      "step": 419460
    },
    {
      "epoch": 674.41,
      "learning_rate": 0.032587205676527335,
      "loss": 2.5403,
      "step": 419480
    },
    {
      "epoch": 674.44,
      "learning_rate": 0.03258399024565917,
      "loss": 2.5366,
      "step": 419500
    },
    {
      "epoch": 674.47,
      "learning_rate": 0.032580774814791,
      "loss": 2.5309,
      "step": 419520
    },
    {
      "epoch": 674.5,
      "learning_rate": 0.03257755938392284,
      "loss": 2.5524,
      "step": 419540
    },
    {
      "epoch": 674.53,
      "learning_rate": 0.03257434395305467,
      "loss": 2.5317,
      "step": 419560
    },
    {
      "epoch": 674.57,
      "learning_rate": 0.0325711285221865,
      "loss": 2.5675,
      "step": 419580
    },
    {
      "epoch": 674.6,
      "learning_rate": 0.03256791309131833,
      "loss": 2.5366,
      "step": 419600
    },
    {
      "epoch": 674.63,
      "learning_rate": 0.03256469766045016,
      "loss": 2.5456,
      "step": 419620
    },
    {
      "epoch": 674.66,
      "learning_rate": 0.032561482229582,
      "loss": 2.5172,
      "step": 419640
    },
    {
      "epoch": 674.69,
      "learning_rate": 0.032558266798713834,
      "loss": 2.5675,
      "step": 419660
    },
    {
      "epoch": 674.73,
      "learning_rate": 0.032555051367845665,
      "loss": 2.5574,
      "step": 419680
    },
    {
      "epoch": 674.76,
      "learning_rate": 0.0325518359369775,
      "loss": 2.5493,
      "step": 419700
    },
    {
      "epoch": 674.79,
      "learning_rate": 0.03254862050610933,
      "loss": 2.541,
      "step": 419720
    },
    {
      "epoch": 674.82,
      "learning_rate": 0.03254540507524116,
      "loss": 2.5154,
      "step": 419740
    },
    {
      "epoch": 674.86,
      "learning_rate": 0.032542189644373,
      "loss": 2.5613,
      "step": 419760
    },
    {
      "epoch": 674.89,
      "learning_rate": 0.03253913498504823,
      "loss": 2.5358,
      "step": 419780
    },
    {
      "epoch": 674.92,
      "learning_rate": 0.03253591955418007,
      "loss": 2.5437,
      "step": 419800
    },
    {
      "epoch": 674.95,
      "learning_rate": 0.032532704123311905,
      "loss": 2.5506,
      "step": 419820
    },
    {
      "epoch": 674.98,
      "learning_rate": 0.032529488692443737,
      "loss": 2.5617,
      "step": 419840
    },
    {
      "epoch": 675.0,
      "eval_accuracy": {
        "accuracy": 0.42874912539842963
      },
      "eval_loss": 2.6683194637298584,
      "eval_runtime": 3.4199,
      "eval_samples_per_second": 3761.209,
      "eval_steps_per_second": 58.773,
      "step": 419850
    },
    {
      "epoch": 675.02,
      "learning_rate": 0.03252627326157556,
      "loss": 2.5223,
      "step": 419860
    },
    {
      "epoch": 675.05,
      "learning_rate": 0.03252305783070739,
      "loss": 2.545,
      "step": 419880
    },
    {
      "epoch": 675.08,
      "learning_rate": 0.03251984239983924,
      "loss": 2.5221,
      "step": 419900
    },
    {
      "epoch": 675.11,
      "learning_rate": 0.03251662696897107,
      "loss": 2.5431,
      "step": 419920
    },
    {
      "epoch": 675.14,
      "learning_rate": 0.0325134115381029,
      "loss": 2.5445,
      "step": 419940
    },
    {
      "epoch": 675.18,
      "learning_rate": 0.032510196107234726,
      "loss": 2.5207,
      "step": 419960
    },
    {
      "epoch": 675.21,
      "learning_rate": 0.03250698067636656,
      "loss": 2.5364,
      "step": 419980
    },
    {
      "epoch": 675.24,
      "learning_rate": 0.03250376524549839,
      "loss": 2.5349,
      "step": 420000
    },
    {
      "epoch": 675.27,
      "learning_rate": 0.032500549814630235,
      "loss": 2.5498,
      "step": 420020
    },
    {
      "epoch": 675.31,
      "learning_rate": 0.032497334383762067,
      "loss": 2.568,
      "step": 420040
    },
    {
      "epoch": 675.34,
      "learning_rate": 0.0324941189528939,
      "loss": 2.5673,
      "step": 420060
    },
    {
      "epoch": 675.37,
      "learning_rate": 0.03249090352202572,
      "loss": 2.5459,
      "step": 420080
    },
    {
      "epoch": 675.4,
      "learning_rate": 0.032487688091157554,
      "loss": 2.538,
      "step": 420100
    },
    {
      "epoch": 675.43,
      "learning_rate": 0.0324844726602894,
      "loss": 2.5364,
      "step": 420120
    },
    {
      "epoch": 675.47,
      "learning_rate": 0.03248125722942123,
      "loss": 2.5314,
      "step": 420140
    },
    {
      "epoch": 675.5,
      "learning_rate": 0.03247804179855306,
      "loss": 2.5464,
      "step": 420160
    },
    {
      "epoch": 675.53,
      "learning_rate": 0.03247482636768489,
      "loss": 2.5452,
      "step": 420180
    },
    {
      "epoch": 675.56,
      "learning_rate": 0.03247161093681672,
      "loss": 2.5552,
      "step": 420200
    },
    {
      "epoch": 675.59,
      "learning_rate": 0.03246839550594855,
      "loss": 2.5357,
      "step": 420220
    },
    {
      "epoch": 675.63,
      "learning_rate": 0.032465180075080396,
      "loss": 2.528,
      "step": 420240
    },
    {
      "epoch": 675.66,
      "learning_rate": 0.03246196464421223,
      "loss": 2.5406,
      "step": 420260
    },
    {
      "epoch": 675.69,
      "learning_rate": 0.03245874921334405,
      "loss": 2.5327,
      "step": 420280
    },
    {
      "epoch": 675.72,
      "learning_rate": 0.032455533782475884,
      "loss": 2.5218,
      "step": 420300
    },
    {
      "epoch": 675.76,
      "learning_rate": 0.032452318351607716,
      "loss": 2.5329,
      "step": 420320
    },
    {
      "epoch": 675.79,
      "learning_rate": 0.03244910292073955,
      "loss": 2.5509,
      "step": 420340
    },
    {
      "epoch": 675.82,
      "learning_rate": 0.03244588748987139,
      "loss": 2.5362,
      "step": 420360
    },
    {
      "epoch": 675.85,
      "learning_rate": 0.032442672059003225,
      "loss": 2.5405,
      "step": 420380
    },
    {
      "epoch": 675.88,
      "learning_rate": 0.03243945662813505,
      "loss": 2.5337,
      "step": 420400
    },
    {
      "epoch": 675.92,
      "learning_rate": 0.03243624119726688,
      "loss": 2.5529,
      "step": 420420
    },
    {
      "epoch": 675.95,
      "learning_rate": 0.03243302576639871,
      "loss": 2.5601,
      "step": 420440
    },
    {
      "epoch": 675.98,
      "learning_rate": 0.032429971107073956,
      "loss": 2.5729,
      "step": 420460
    },
    {
      "epoch": 676.0,
      "eval_accuracy": {
        "accuracy": 0.4368343310269766
      },
      "eval_loss": 2.6541290283203125,
      "eval_runtime": 3.3617,
      "eval_samples_per_second": 3826.395,
      "eval_steps_per_second": 59.792,
      "step": 420472
    },
    {
      "epoch": 676.01,
      "learning_rate": 0.03242675567620579,
      "loss": 2.5276,
      "step": 420480
    },
    {
      "epoch": 676.05,
      "learning_rate": 0.032423540245337626,
      "loss": 2.5571,
      "step": 420500
    },
    {
      "epoch": 676.08,
      "learning_rate": 0.03242032481446946,
      "loss": 2.5714,
      "step": 420520
    },
    {
      "epoch": 676.11,
      "learning_rate": 0.03241710938360129,
      "loss": 2.5352,
      "step": 420540
    },
    {
      "epoch": 676.14,
      "learning_rate": 0.03241389395273312,
      "loss": 2.5384,
      "step": 420560
    },
    {
      "epoch": 676.17,
      "learning_rate": 0.03241067852186495,
      "loss": 2.5264,
      "step": 420580
    },
    {
      "epoch": 676.21,
      "learning_rate": 0.03240746309099679,
      "loss": 2.5295,
      "step": 420600
    },
    {
      "epoch": 676.24,
      "learning_rate": 0.03240424766012862,
      "loss": 2.5589,
      "step": 420620
    },
    {
      "epoch": 676.27,
      "learning_rate": 0.032401032229260454,
      "loss": 2.5672,
      "step": 420640
    },
    {
      "epoch": 676.3,
      "learning_rate": 0.032397816798392286,
      "loss": 2.5423,
      "step": 420660
    },
    {
      "epoch": 676.33,
      "learning_rate": 0.03239460136752412,
      "loss": 2.5221,
      "step": 420680
    },
    {
      "epoch": 676.37,
      "learning_rate": 0.03239138593665595,
      "loss": 2.5345,
      "step": 420700
    },
    {
      "epoch": 676.4,
      "learning_rate": 0.03238817050578779,
      "loss": 2.5579,
      "step": 420720
    },
    {
      "epoch": 676.43,
      "learning_rate": 0.03238495507491962,
      "loss": 2.5387,
      "step": 420740
    },
    {
      "epoch": 676.46,
      "learning_rate": 0.03238173964405145,
      "loss": 2.5411,
      "step": 420760
    },
    {
      "epoch": 676.5,
      "learning_rate": 0.03237852421318328,
      "loss": 2.5416,
      "step": 420780
    },
    {
      "epoch": 676.53,
      "learning_rate": 0.032375308782315114,
      "loss": 2.5529,
      "step": 420800
    },
    {
      "epoch": 676.56,
      "learning_rate": 0.032372093351446946,
      "loss": 2.5269,
      "step": 420820
    },
    {
      "epoch": 676.59,
      "learning_rate": 0.032368877920578784,
      "loss": 2.5425,
      "step": 420840
    },
    {
      "epoch": 676.62,
      "learning_rate": 0.032365662489710616,
      "loss": 2.5693,
      "step": 420860
    },
    {
      "epoch": 676.66,
      "learning_rate": 0.03236244705884245,
      "loss": 2.5216,
      "step": 420880
    },
    {
      "epoch": 676.69,
      "learning_rate": 0.03235923162797428,
      "loss": 2.5489,
      "step": 420900
    },
    {
      "epoch": 676.72,
      "learning_rate": 0.03235601619710611,
      "loss": 2.5529,
      "step": 420920
    },
    {
      "epoch": 676.75,
      "learning_rate": 0.03235280076623795,
      "loss": 2.5372,
      "step": 420940
    },
    {
      "epoch": 676.78,
      "learning_rate": 0.03234958533536978,
      "loss": 2.5482,
      "step": 420960
    },
    {
      "epoch": 676.82,
      "learning_rate": 0.03234636990450161,
      "loss": 2.5504,
      "step": 420980
    },
    {
      "epoch": 676.85,
      "learning_rate": 0.032343154473633444,
      "loss": 2.5387,
      "step": 421000
    },
    {
      "epoch": 676.88,
      "learning_rate": 0.032339939042765276,
      "loss": 2.5604,
      "step": 421020
    },
    {
      "epoch": 676.91,
      "learning_rate": 0.03233672361189711,
      "loss": 2.5378,
      "step": 421040
    },
    {
      "epoch": 676.95,
      "learning_rate": 0.032333508181028946,
      "loss": 2.541,
      "step": 421060
    },
    {
      "epoch": 676.98,
      "learning_rate": 0.03233029275016078,
      "loss": 2.5515,
      "step": 421080
    },
    {
      "epoch": 677.0,
      "eval_accuracy": {
        "accuracy": 0.43481302961983986
      },
      "eval_loss": 2.650134563446045,
      "eval_runtime": 3.2012,
      "eval_samples_per_second": 4018.153,
      "eval_steps_per_second": 62.789,
      "step": 421094
    },
    {
      "epoch": 677.01,
      "learning_rate": 0.03232707731929261,
      "loss": 2.5355,
      "step": 421100
    },
    {
      "epoch": 677.04,
      "learning_rate": 0.03232386188842444,
      "loss": 2.5649,
      "step": 421120
    },
    {
      "epoch": 677.07,
      "learning_rate": 0.03232064645755627,
      "loss": 2.5403,
      "step": 421140
    },
    {
      "epoch": 677.11,
      "learning_rate": 0.032317431026688104,
      "loss": 2.5397,
      "step": 421160
    },
    {
      "epoch": 677.14,
      "learning_rate": 0.03231421559581994,
      "loss": 2.5383,
      "step": 421180
    },
    {
      "epoch": 677.17,
      "learning_rate": 0.032311000164951774,
      "loss": 2.5341,
      "step": 421200
    },
    {
      "epoch": 677.2,
      "learning_rate": 0.032307784734083606,
      "loss": 2.529,
      "step": 421220
    },
    {
      "epoch": 677.23,
      "learning_rate": 0.03230456930321544,
      "loss": 2.5345,
      "step": 421240
    },
    {
      "epoch": 677.27,
      "learning_rate": 0.03230135387234727,
      "loss": 2.5233,
      "step": 421260
    },
    {
      "epoch": 677.3,
      "learning_rate": 0.03229813844147911,
      "loss": 2.5582,
      "step": 421280
    },
    {
      "epoch": 677.33,
      "learning_rate": 0.03229492301061094,
      "loss": 2.5264,
      "step": 421300
    },
    {
      "epoch": 677.36,
      "learning_rate": 0.03229170757974277,
      "loss": 2.5473,
      "step": 421320
    },
    {
      "epoch": 677.4,
      "learning_rate": 0.0322884921488746,
      "loss": 2.5366,
      "step": 421340
    },
    {
      "epoch": 677.43,
      "learning_rate": 0.032285276718006434,
      "loss": 2.5187,
      "step": 421360
    },
    {
      "epoch": 677.46,
      "learning_rate": 0.032282061287138265,
      "loss": 2.5283,
      "step": 421380
    },
    {
      "epoch": 677.49,
      "learning_rate": 0.032278845856270104,
      "loss": 2.5362,
      "step": 421400
    },
    {
      "epoch": 677.52,
      "learning_rate": 0.032275630425401935,
      "loss": 2.551,
      "step": 421420
    },
    {
      "epoch": 677.56,
      "learning_rate": 0.03227241499453377,
      "loss": 2.5602,
      "step": 421440
    },
    {
      "epoch": 677.59,
      "learning_rate": 0.0322691995636656,
      "loss": 2.5386,
      "step": 421460
    },
    {
      "epoch": 677.62,
      "learning_rate": 0.03226598413279743,
      "loss": 2.5561,
      "step": 421480
    },
    {
      "epoch": 677.65,
      "learning_rate": 0.03226276870192926,
      "loss": 2.5366,
      "step": 421500
    },
    {
      "epoch": 677.68,
      "learning_rate": 0.0322595532710611,
      "loss": 2.5522,
      "step": 421520
    },
    {
      "epoch": 677.72,
      "learning_rate": 0.03225633784019293,
      "loss": 2.5685,
      "step": 421540
    },
    {
      "epoch": 677.75,
      "learning_rate": 0.032253122409324764,
      "loss": 2.5313,
      "step": 421560
    },
    {
      "epoch": 677.78,
      "learning_rate": 0.032249906978456595,
      "loss": 2.554,
      "step": 421580
    },
    {
      "epoch": 677.81,
      "learning_rate": 0.03224669154758843,
      "loss": 2.5377,
      "step": 421600
    },
    {
      "epoch": 677.85,
      "learning_rate": 0.032243476116720265,
      "loss": 2.526,
      "step": 421620
    },
    {
      "epoch": 677.88,
      "learning_rate": 0.0322402606858521,
      "loss": 2.5378,
      "step": 421640
    },
    {
      "epoch": 677.91,
      "learning_rate": 0.03223704525498393,
      "loss": 2.5502,
      "step": 421660
    },
    {
      "epoch": 677.94,
      "learning_rate": 0.03223382982411576,
      "loss": 2.5466,
      "step": 421680
    },
    {
      "epoch": 677.97,
      "learning_rate": 0.03223061439324759,
      "loss": 2.5386,
      "step": 421700
    },
    {
      "epoch": 678.0,
      "eval_accuracy": {
        "accuracy": 0.437844981730545
      },
      "eval_loss": 2.6477255821228027,
      "eval_runtime": 3.2823,
      "eval_samples_per_second": 3918.874,
      "eval_steps_per_second": 61.237,
      "step": 421716
    },
    {
      "epoch": 678.01,
      "learning_rate": 0.032227398962379424,
      "loss": 2.5279,
      "step": 421720
    },
    {
      "epoch": 678.04,
      "learning_rate": 0.03222418353151126,
      "loss": 2.5282,
      "step": 421740
    },
    {
      "epoch": 678.07,
      "learning_rate": 0.032220968100643094,
      "loss": 2.5354,
      "step": 421760
    },
    {
      "epoch": 678.1,
      "learning_rate": 0.032217752669774925,
      "loss": 2.5411,
      "step": 421780
    },
    {
      "epoch": 678.14,
      "learning_rate": 0.03221453723890676,
      "loss": 2.5312,
      "step": 421800
    },
    {
      "epoch": 678.17,
      "learning_rate": 0.03221132180803859,
      "loss": 2.5401,
      "step": 421820
    },
    {
      "epoch": 678.2,
      "learning_rate": 0.03220810637717041,
      "loss": 2.5381,
      "step": 421840
    },
    {
      "epoch": 678.23,
      "learning_rate": 0.03220489094630226,
      "loss": 2.5405,
      "step": 421860
    },
    {
      "epoch": 678.26,
      "learning_rate": 0.03220167551543409,
      "loss": 2.5251,
      "step": 421880
    },
    {
      "epoch": 678.3,
      "learning_rate": 0.03219846008456592,
      "loss": 2.5302,
      "step": 421900
    },
    {
      "epoch": 678.33,
      "learning_rate": 0.032195244653697754,
      "loss": 2.5424,
      "step": 421920
    },
    {
      "epoch": 678.36,
      "learning_rate": 0.032192029222829585,
      "loss": 2.5397,
      "step": 421940
    },
    {
      "epoch": 678.39,
      "learning_rate": 0.032188813791961424,
      "loss": 2.5539,
      "step": 421960
    },
    {
      "epoch": 678.42,
      "learning_rate": 0.032185598361093255,
      "loss": 2.547,
      "step": 421980
    },
    {
      "epoch": 678.46,
      "learning_rate": 0.03218238293022509,
      "loss": 2.5404,
      "step": 422000
    },
    {
      "epoch": 678.49,
      "learning_rate": 0.03217916749935692,
      "loss": 2.5578,
      "step": 422020
    },
    {
      "epoch": 678.52,
      "learning_rate": 0.03217595206848875,
      "loss": 2.5235,
      "step": 422040
    },
    {
      "epoch": 678.55,
      "learning_rate": 0.032172736637620575,
      "loss": 2.5634,
      "step": 422060
    },
    {
      "epoch": 678.59,
      "learning_rate": 0.03216952120675242,
      "loss": 2.5299,
      "step": 422080
    },
    {
      "epoch": 678.62,
      "learning_rate": 0.03216630577588425,
      "loss": 2.5544,
      "step": 422100
    },
    {
      "epoch": 678.65,
      "learning_rate": 0.032163090345016083,
      "loss": 2.5227,
      "step": 422120
    },
    {
      "epoch": 678.68,
      "learning_rate": 0.032159874914147915,
      "loss": 2.5351,
      "step": 422140
    },
    {
      "epoch": 678.71,
      "learning_rate": 0.03215665948327974,
      "loss": 2.5429,
      "step": 422160
    },
    {
      "epoch": 678.75,
      "learning_rate": 0.03215344405241157,
      "loss": 2.5289,
      "step": 422180
    },
    {
      "epoch": 678.78,
      "learning_rate": 0.03215022862154342,
      "loss": 2.5463,
      "step": 422200
    },
    {
      "epoch": 678.81,
      "learning_rate": 0.03214701319067525,
      "loss": 2.5725,
      "step": 422220
    },
    {
      "epoch": 678.84,
      "learning_rate": 0.03214379775980708,
      "loss": 2.5326,
      "step": 422240
    },
    {
      "epoch": 678.87,
      "learning_rate": 0.03214058232893891,
      "loss": 2.5517,
      "step": 422260
    },
    {
      "epoch": 678.91,
      "learning_rate": 0.032137366898070736,
      "loss": 2.5218,
      "step": 422280
    },
    {
      "epoch": 678.94,
      "learning_rate": 0.03213415146720258,
      "loss": 2.5617,
      "step": 422300
    },
    {
      "epoch": 678.97,
      "learning_rate": 0.032130936036334413,
      "loss": 2.5588,
      "step": 422320
    },
    {
      "epoch": 679.0,
      "eval_accuracy": {
        "accuracy": 0.43255850112726424
      },
      "eval_loss": 2.66463303565979,
      "eval_runtime": 3.0217,
      "eval_samples_per_second": 4256.893,
      "eval_steps_per_second": 66.519,
      "step": 422338
    },
    {
      "epoch": 679.0,
      "learning_rate": 0.032127720605466245,
      "loss": 2.5523,
      "step": 422340
    },
    {
      "epoch": 679.04,
      "learning_rate": 0.03212450517459808,
      "loss": 2.5349,
      "step": 422360
    },
    {
      "epoch": 679.07,
      "learning_rate": 0.0321212897437299,
      "loss": 2.539,
      "step": 422380
    },
    {
      "epoch": 679.1,
      "learning_rate": 0.03211807431286173,
      "loss": 2.5496,
      "step": 422400
    },
    {
      "epoch": 679.13,
      "learning_rate": 0.03211485888199358,
      "loss": 2.5458,
      "step": 422420
    },
    {
      "epoch": 679.16,
      "learning_rate": 0.03211164345112541,
      "loss": 2.5299,
      "step": 422440
    },
    {
      "epoch": 679.2,
      "learning_rate": 0.03210842802025724,
      "loss": 2.5505,
      "step": 422460
    },
    {
      "epoch": 679.23,
      "learning_rate": 0.032105212589389066,
      "loss": 2.5239,
      "step": 422480
    },
    {
      "epoch": 679.26,
      "learning_rate": 0.0321019971585209,
      "loss": 2.5778,
      "step": 422500
    },
    {
      "epoch": 679.29,
      "learning_rate": 0.03209878172765274,
      "loss": 2.539,
      "step": 422520
    },
    {
      "epoch": 679.32,
      "learning_rate": 0.032095566296784575,
      "loss": 2.5558,
      "step": 422540
    },
    {
      "epoch": 679.36,
      "learning_rate": 0.03209235086591641,
      "loss": 2.5257,
      "step": 422560
    },
    {
      "epoch": 679.39,
      "learning_rate": 0.03208913543504824,
      "loss": 2.5568,
      "step": 422580
    },
    {
      "epoch": 679.42,
      "learning_rate": 0.03208592000418006,
      "loss": 2.5491,
      "step": 422600
    },
    {
      "epoch": 679.45,
      "learning_rate": 0.032082704573311895,
      "loss": 2.5541,
      "step": 422620
    },
    {
      "epoch": 679.49,
      "learning_rate": 0.03207948914244374,
      "loss": 2.5378,
      "step": 422640
    },
    {
      "epoch": 679.52,
      "learning_rate": 0.03207627371157557,
      "loss": 2.5588,
      "step": 422660
    },
    {
      "epoch": 679.55,
      "learning_rate": 0.0320730582807074,
      "loss": 2.5554,
      "step": 422680
    },
    {
      "epoch": 679.58,
      "learning_rate": 0.03206984284983923,
      "loss": 2.5252,
      "step": 422700
    },
    {
      "epoch": 679.61,
      "learning_rate": 0.03206662741897106,
      "loss": 2.552,
      "step": 422720
    },
    {
      "epoch": 679.65,
      "learning_rate": 0.03206341198810289,
      "loss": 2.5486,
      "step": 422740
    },
    {
      "epoch": 679.68,
      "learning_rate": 0.03206019655723474,
      "loss": 2.5569,
      "step": 422760
    },
    {
      "epoch": 679.71,
      "learning_rate": 0.03205698112636657,
      "loss": 2.538,
      "step": 422780
    },
    {
      "epoch": 679.74,
      "learning_rate": 0.03205376569549839,
      "loss": 2.5366,
      "step": 422800
    },
    {
      "epoch": 679.77,
      "learning_rate": 0.032050550264630225,
      "loss": 2.53,
      "step": 422820
    },
    {
      "epoch": 679.81,
      "learning_rate": 0.032047334833762056,
      "loss": 2.534,
      "step": 422840
    },
    {
      "epoch": 679.84,
      "learning_rate": 0.0320441194028939,
      "loss": 2.5544,
      "step": 422860
    },
    {
      "epoch": 679.87,
      "learning_rate": 0.03204090397202573,
      "loss": 2.5235,
      "step": 422880
    },
    {
      "epoch": 679.9,
      "learning_rate": 0.032037688541157565,
      "loss": 2.527,
      "step": 422900
    },
    {
      "epoch": 679.94,
      "learning_rate": 0.03203447311028939,
      "loss": 2.5431,
      "step": 422920
    },
    {
      "epoch": 679.97,
      "learning_rate": 0.03203125767942122,
      "loss": 2.5523,
      "step": 422940
    },
    {
      "epoch": 680.0,
      "learning_rate": 0.03202804224855305,
      "loss": 2.5609,
      "step": 422960
    },
    {
      "epoch": 680.0,
      "eval_accuracy": {
        "accuracy": 0.4307704268055664
      },
      "eval_loss": 2.6686806678771973,
      "eval_runtime": 3.056,
      "eval_samples_per_second": 4209.083,
      "eval_steps_per_second": 65.772,
      "step": 422960
    },
    {
      "epoch": 680.03,
      "learning_rate": 0.0320248268176849,
      "loss": 2.5617,
      "step": 422980
    },
    {
      "epoch": 680.06,
      "learning_rate": 0.03202161138681673,
      "loss": 2.5318,
      "step": 423000
    },
    {
      "epoch": 680.1,
      "learning_rate": 0.032018395955948555,
      "loss": 2.5257,
      "step": 423020
    },
    {
      "epoch": 680.13,
      "learning_rate": 0.032015180525080386,
      "loss": 2.5243,
      "step": 423040
    },
    {
      "epoch": 680.16,
      "learning_rate": 0.03201196509421222,
      "loss": 2.5266,
      "step": 423060
    },
    {
      "epoch": 680.19,
      "learning_rate": 0.03200874966334405,
      "loss": 2.5241,
      "step": 423080
    },
    {
      "epoch": 680.23,
      "learning_rate": 0.032005534232475895,
      "loss": 2.5286,
      "step": 423100
    },
    {
      "epoch": 680.26,
      "learning_rate": 0.03200231880160772,
      "loss": 2.5209,
      "step": 423120
    },
    {
      "epoch": 680.29,
      "learning_rate": 0.03199910337073955,
      "loss": 2.5137,
      "step": 423140
    },
    {
      "epoch": 680.32,
      "learning_rate": 0.03199588793987138,
      "loss": 2.5216,
      "step": 423160
    },
    {
      "epoch": 680.35,
      "learning_rate": 0.031992672509003214,
      "loss": 2.5431,
      "step": 423180
    },
    {
      "epoch": 680.39,
      "learning_rate": 0.03198945707813506,
      "loss": 2.5454,
      "step": 423200
    },
    {
      "epoch": 680.42,
      "learning_rate": 0.03198624164726689,
      "loss": 2.5397,
      "step": 423220
    },
    {
      "epoch": 680.45,
      "learning_rate": 0.031983026216398716,
      "loss": 2.548,
      "step": 423240
    },
    {
      "epoch": 680.48,
      "learning_rate": 0.03197981078553055,
      "loss": 2.5334,
      "step": 423260
    },
    {
      "epoch": 680.51,
      "learning_rate": 0.03197659535466238,
      "loss": 2.5414,
      "step": 423280
    },
    {
      "epoch": 680.55,
      "learning_rate": 0.03197337992379421,
      "loss": 2.5322,
      "step": 423300
    },
    {
      "epoch": 680.58,
      "learning_rate": 0.031970164492926056,
      "loss": 2.5268,
      "step": 423320
    },
    {
      "epoch": 680.61,
      "learning_rate": 0.03196694906205788,
      "loss": 2.5444,
      "step": 423340
    },
    {
      "epoch": 680.64,
      "learning_rate": 0.03196373363118971,
      "loss": 2.5536,
      "step": 423360
    },
    {
      "epoch": 680.68,
      "learning_rate": 0.031960518200321544,
      "loss": 2.5542,
      "step": 423380
    },
    {
      "epoch": 680.71,
      "learning_rate": 0.031957302769453376,
      "loss": 2.5503,
      "step": 423400
    },
    {
      "epoch": 680.74,
      "learning_rate": 0.03195408733858521,
      "loss": 2.563,
      "step": 423420
    },
    {
      "epoch": 680.77,
      "learning_rate": 0.031950871907717046,
      "loss": 2.5426,
      "step": 423440
    },
    {
      "epoch": 680.8,
      "learning_rate": 0.03194765647684888,
      "loss": 2.5489,
      "step": 423460
    },
    {
      "epoch": 680.84,
      "learning_rate": 0.03194444104598071,
      "loss": 2.5298,
      "step": 423480
    },
    {
      "epoch": 680.87,
      "learning_rate": 0.03194122561511254,
      "loss": 2.5488,
      "step": 423500
    },
    {
      "epoch": 680.9,
      "learning_rate": 0.03193801018424437,
      "loss": 2.5508,
      "step": 423520
    },
    {
      "epoch": 680.93,
      "learning_rate": 0.03193479475337622,
      "loss": 2.5483,
      "step": 423540
    },
    {
      "epoch": 680.96,
      "learning_rate": 0.03193157932250804,
      "loss": 2.5627,
      "step": 423560
    },
    {
      "epoch": 681.0,
      "learning_rate": 0.031928363891639874,
      "loss": 2.5485,
      "step": 423580
    },
    {
      "epoch": 681.0,
      "eval_accuracy": {
        "accuracy": 0.43535722615253053
      },
      "eval_loss": 2.6656508445739746,
      "eval_runtime": 4.023,
      "eval_samples_per_second": 3197.338,
      "eval_steps_per_second": 49.962,
      "step": 423582
    },
    {
      "epoch": 681.03,
      "learning_rate": 0.031925148460771706,
      "loss": 2.5404,
      "step": 423600
    },
    {
      "epoch": 681.06,
      "learning_rate": 0.03192193302990354,
      "loss": 2.5197,
      "step": 423620
    },
    {
      "epoch": 681.09,
      "learning_rate": 0.03191871759903537,
      "loss": 2.5316,
      "step": 423640
    },
    {
      "epoch": 681.13,
      "learning_rate": 0.03191550216816721,
      "loss": 2.5234,
      "step": 423660
    },
    {
      "epoch": 681.16,
      "learning_rate": 0.03191228673729904,
      "loss": 2.5331,
      "step": 423680
    },
    {
      "epoch": 681.19,
      "learning_rate": 0.03190907130643087,
      "loss": 2.5391,
      "step": 423700
    },
    {
      "epoch": 681.22,
      "learning_rate": 0.0319058558755627,
      "loss": 2.5497,
      "step": 423720
    },
    {
      "epoch": 681.25,
      "learning_rate": 0.031902640444694534,
      "loss": 2.543,
      "step": 423740
    },
    {
      "epoch": 681.29,
      "learning_rate": 0.031899425013826366,
      "loss": 2.5363,
      "step": 423760
    },
    {
      "epoch": 681.32,
      "learning_rate": 0.031896209582958204,
      "loss": 2.5426,
      "step": 423780
    },
    {
      "epoch": 681.35,
      "learning_rate": 0.031892994152090036,
      "loss": 2.5489,
      "step": 423800
    },
    {
      "epoch": 681.38,
      "learning_rate": 0.03188977872122187,
      "loss": 2.5318,
      "step": 423820
    },
    {
      "epoch": 681.41,
      "learning_rate": 0.0318865632903537,
      "loss": 2.5267,
      "step": 423840
    },
    {
      "epoch": 681.45,
      "learning_rate": 0.03188334785948553,
      "loss": 2.5274,
      "step": 423860
    },
    {
      "epoch": 681.48,
      "learning_rate": 0.03188013242861737,
      "loss": 2.5347,
      "step": 423880
    },
    {
      "epoch": 681.51,
      "learning_rate": 0.0318769169977492,
      "loss": 2.542,
      "step": 423900
    },
    {
      "epoch": 681.54,
      "learning_rate": 0.03187370156688103,
      "loss": 2.5555,
      "step": 423920
    },
    {
      "epoch": 681.58,
      "learning_rate": 0.031870486136012864,
      "loss": 2.5525,
      "step": 423940
    },
    {
      "epoch": 681.61,
      "learning_rate": 0.031867270705144696,
      "loss": 2.5772,
      "step": 423960
    },
    {
      "epoch": 681.64,
      "learning_rate": 0.03186405527427653,
      "loss": 2.5419,
      "step": 423980
    },
    {
      "epoch": 681.67,
      "learning_rate": 0.031860839843408366,
      "loss": 2.5438,
      "step": 424000
    },
    {
      "epoch": 681.7,
      "learning_rate": 0.0318576244125402,
      "loss": 2.5344,
      "step": 424020
    },
    {
      "epoch": 681.74,
      "learning_rate": 0.03185440898167203,
      "loss": 2.5324,
      "step": 424040
    },
    {
      "epoch": 681.77,
      "learning_rate": 0.03185119355080386,
      "loss": 2.5383,
      "step": 424060
    },
    {
      "epoch": 681.8,
      "learning_rate": 0.03184797811993569,
      "loss": 2.5444,
      "step": 424080
    },
    {
      "epoch": 681.83,
      "learning_rate": 0.031844762689067524,
      "loss": 2.5369,
      "step": 424100
    },
    {
      "epoch": 681.86,
      "learning_rate": 0.03184154725819936,
      "loss": 2.5393,
      "step": 424120
    },
    {
      "epoch": 681.9,
      "learning_rate": 0.031838331827331194,
      "loss": 2.5175,
      "step": 424140
    },
    {
      "epoch": 681.93,
      "learning_rate": 0.031835116396463026,
      "loss": 2.5358,
      "step": 424160
    },
    {
      "epoch": 681.96,
      "learning_rate": 0.03183190096559486,
      "loss": 2.5312,
      "step": 424180
    },
    {
      "epoch": 681.99,
      "learning_rate": 0.03182868553472669,
      "loss": 2.5261,
      "step": 424200
    },
    {
      "epoch": 682.0,
      "eval_accuracy": {
        "accuracy": 0.43854466298686157
      },
      "eval_loss": 2.648090124130249,
      "eval_runtime": 3.0764,
      "eval_samples_per_second": 4181.124,
      "eval_steps_per_second": 65.335,
      "step": 424204
    },
    {
      "epoch": 682.03,
      "learning_rate": 0.03182547010385853,
      "loss": 2.5538,
      "step": 424220
    },
    {
      "epoch": 682.06,
      "learning_rate": 0.03182225467299036,
      "loss": 2.5235,
      "step": 424240
    },
    {
      "epoch": 682.09,
      "learning_rate": 0.03181903924212219,
      "loss": 2.5424,
      "step": 424260
    },
    {
      "epoch": 682.12,
      "learning_rate": 0.03181582381125402,
      "loss": 2.523,
      "step": 424280
    },
    {
      "epoch": 682.15,
      "learning_rate": 0.031812608380385854,
      "loss": 2.5607,
      "step": 424300
    },
    {
      "epoch": 682.19,
      "learning_rate": 0.031809392949517686,
      "loss": 2.5389,
      "step": 424320
    },
    {
      "epoch": 682.22,
      "learning_rate": 0.031806177518649524,
      "loss": 2.565,
      "step": 424340
    },
    {
      "epoch": 682.25,
      "learning_rate": 0.031802962087781356,
      "loss": 2.5273,
      "step": 424360
    },
    {
      "epoch": 682.28,
      "learning_rate": 0.03179974665691319,
      "loss": 2.5138,
      "step": 424380
    },
    {
      "epoch": 682.32,
      "learning_rate": 0.03179653122604502,
      "loss": 2.5293,
      "step": 424400
    },
    {
      "epoch": 682.35,
      "learning_rate": 0.03179331579517685,
      "loss": 2.5539,
      "step": 424420
    },
    {
      "epoch": 682.38,
      "learning_rate": 0.03179010036430869,
      "loss": 2.5495,
      "step": 424440
    },
    {
      "epoch": 682.41,
      "learning_rate": 0.031787045704983925,
      "loss": 2.5244,
      "step": 424460
    },
    {
      "epoch": 682.44,
      "learning_rate": 0.031783830274115764,
      "loss": 2.5434,
      "step": 424480
    },
    {
      "epoch": 682.48,
      "learning_rate": 0.031780614843247595,
      "loss": 2.5281,
      "step": 424500
    },
    {
      "epoch": 682.51,
      "learning_rate": 0.03177739941237943,
      "loss": 2.5317,
      "step": 424520
    },
    {
      "epoch": 682.54,
      "learning_rate": 0.03177418398151126,
      "loss": 2.548,
      "step": 424540
    },
    {
      "epoch": 682.57,
      "learning_rate": 0.03177096855064309,
      "loss": 2.5639,
      "step": 424560
    },
    {
      "epoch": 682.6,
      "learning_rate": 0.031767753119774915,
      "loss": 2.5334,
      "step": 424580
    },
    {
      "epoch": 682.64,
      "learning_rate": 0.03176453768890676,
      "loss": 2.5494,
      "step": 424600
    },
    {
      "epoch": 682.67,
      "learning_rate": 0.03176132225803859,
      "loss": 2.5387,
      "step": 424620
    },
    {
      "epoch": 682.7,
      "learning_rate": 0.031758106827170424,
      "loss": 2.5461,
      "step": 424640
    },
    {
      "epoch": 682.73,
      "learning_rate": 0.031754891396302255,
      "loss": 2.5316,
      "step": 424660
    },
    {
      "epoch": 682.77,
      "learning_rate": 0.03175167596543408,
      "loss": 2.5391,
      "step": 424680
    },
    {
      "epoch": 682.8,
      "learning_rate": 0.031748460534565925,
      "loss": 2.5304,
      "step": 424700
    },
    {
      "epoch": 682.83,
      "learning_rate": 0.03174524510369776,
      "loss": 2.5476,
      "step": 424720
    },
    {
      "epoch": 682.86,
      "learning_rate": 0.03174202967282959,
      "loss": 2.5432,
      "step": 424740
    },
    {
      "epoch": 682.89,
      "learning_rate": 0.03173881424196142,
      "loss": 2.537,
      "step": 424760
    },
    {
      "epoch": 682.93,
      "learning_rate": 0.03173559881109325,
      "loss": 2.5359,
      "step": 424780
    },
    {
      "epoch": 682.96,
      "learning_rate": 0.03173238338022508,
      "loss": 2.5208,
      "step": 424800
    },
    {
      "epoch": 682.99,
      "learning_rate": 0.03172916794935692,
      "loss": 2.535,
      "step": 424820
    },
    {
      "epoch": 683.0,
      "eval_accuracy": {
        "accuracy": 0.43185881987094765
      },
      "eval_loss": 2.6678810119628906,
      "eval_runtime": 3.0506,
      "eval_samples_per_second": 4216.5,
      "eval_steps_per_second": 65.888,
      "step": 424826
    },
    {
      "epoch": 683.02,
      "learning_rate": 0.031725952518488754,
      "loss": 2.5391,
      "step": 424840
    },
    {
      "epoch": 683.05,
      "learning_rate": 0.031722737087620585,
      "loss": 2.5299,
      "step": 424860
    },
    {
      "epoch": 683.09,
      "learning_rate": 0.03171952165675242,
      "loss": 2.5296,
      "step": 424880
    },
    {
      "epoch": 683.12,
      "learning_rate": 0.03171630622588424,
      "loss": 2.5545,
      "step": 424900
    },
    {
      "epoch": 683.15,
      "learning_rate": 0.03171309079501607,
      "loss": 2.5448,
      "step": 424920
    },
    {
      "epoch": 683.18,
      "learning_rate": 0.03170987536414792,
      "loss": 2.5286,
      "step": 424940
    },
    {
      "epoch": 683.22,
      "learning_rate": 0.03170665993327975,
      "loss": 2.5595,
      "step": 424960
    },
    {
      "epoch": 683.25,
      "learning_rate": 0.03170344450241158,
      "loss": 2.5484,
      "step": 424980
    },
    {
      "epoch": 683.28,
      "learning_rate": 0.031700229071543407,
      "loss": 2.5188,
      "step": 425000
    },
    {
      "epoch": 683.31,
      "learning_rate": 0.03169701364067524,
      "loss": 2.5473,
      "step": 425020
    },
    {
      "epoch": 683.34,
      "learning_rate": 0.031693798209807084,
      "loss": 2.5482,
      "step": 425040
    },
    {
      "epoch": 683.38,
      "learning_rate": 0.031690582778938915,
      "loss": 2.5356,
      "step": 425060
    },
    {
      "epoch": 683.41,
      "learning_rate": 0.03168736734807075,
      "loss": 2.5463,
      "step": 425080
    },
    {
      "epoch": 683.44,
      "learning_rate": 0.03168415191720258,
      "loss": 2.5269,
      "step": 425100
    },
    {
      "epoch": 683.47,
      "learning_rate": 0.0316809364863344,
      "loss": 2.5399,
      "step": 425120
    },
    {
      "epoch": 683.5,
      "learning_rate": 0.031677721055466235,
      "loss": 2.5433,
      "step": 425140
    },
    {
      "epoch": 683.54,
      "learning_rate": 0.03167450562459808,
      "loss": 2.5405,
      "step": 425160
    },
    {
      "epoch": 683.57,
      "learning_rate": 0.03167129019372991,
      "loss": 2.5335,
      "step": 425180
    },
    {
      "epoch": 683.6,
      "learning_rate": 0.03166807476286174,
      "loss": 2.5448,
      "step": 425200
    },
    {
      "epoch": 683.63,
      "learning_rate": 0.03166485933199357,
      "loss": 2.5549,
      "step": 425220
    },
    {
      "epoch": 683.67,
      "learning_rate": 0.0316616439011254,
      "loss": 2.5434,
      "step": 425240
    },
    {
      "epoch": 683.7,
      "learning_rate": 0.031658428470257245,
      "loss": 2.5376,
      "step": 425260
    },
    {
      "epoch": 683.73,
      "learning_rate": 0.03165521303938908,
      "loss": 2.5264,
      "step": 425280
    },
    {
      "epoch": 683.76,
      "learning_rate": 0.03165199760852091,
      "loss": 2.5237,
      "step": 425300
    },
    {
      "epoch": 683.79,
      "learning_rate": 0.03164878217765273,
      "loss": 2.5491,
      "step": 425320
    },
    {
      "epoch": 683.83,
      "learning_rate": 0.031645566746784565,
      "loss": 2.5422,
      "step": 425340
    },
    {
      "epoch": 683.86,
      "learning_rate": 0.031642351315916396,
      "loss": 2.5467,
      "step": 425360
    },
    {
      "epoch": 683.89,
      "learning_rate": 0.03163913588504824,
      "loss": 2.5159,
      "step": 425380
    },
    {
      "epoch": 683.92,
      "learning_rate": 0.03163592045418007,
      "loss": 2.5285,
      "step": 425400
    },
    {
      "epoch": 683.95,
      "learning_rate": 0.031632705023311905,
      "loss": 2.5294,
      "step": 425420
    },
    {
      "epoch": 683.99,
      "learning_rate": 0.03162948959244373,
      "loss": 2.5462,
      "step": 425440
    },
    {
      "epoch": 684.0,
      "eval_accuracy": {
        "accuracy": 0.43652336157972477
      },
      "eval_loss": 2.659158706665039,
      "eval_runtime": 3.253,
      "eval_samples_per_second": 3954.222,
      "eval_steps_per_second": 61.79,
      "step": 425448
    },
    {
      "epoch": 684.02,
      "learning_rate": 0.03162627416157556,
      "loss": 2.5402,
      "step": 425460
    },
    {
      "epoch": 684.05,
      "learning_rate": 0.03162305873070739,
      "loss": 2.5428,
      "step": 425480
    },
    {
      "epoch": 684.08,
      "learning_rate": 0.03161984329983924,
      "loss": 2.5254,
      "step": 425500
    },
    {
      "epoch": 684.12,
      "learning_rate": 0.03161662786897107,
      "loss": 2.5455,
      "step": 425520
    },
    {
      "epoch": 684.15,
      "learning_rate": 0.031613573209646306,
      "loss": 2.5463,
      "step": 425540
    },
    {
      "epoch": 684.18,
      "learning_rate": 0.03161035777877814,
      "loss": 2.5307,
      "step": 425560
    },
    {
      "epoch": 684.21,
      "learning_rate": 0.03160714234790997,
      "loss": 2.5196,
      "step": 425580
    },
    {
      "epoch": 684.24,
      "learning_rate": 0.0316039269170418,
      "loss": 2.5288,
      "step": 425600
    },
    {
      "epoch": 684.28,
      "learning_rate": 0.03160071148617363,
      "loss": 2.5373,
      "step": 425620
    },
    {
      "epoch": 684.31,
      "learning_rate": 0.03159749605530547,
      "loss": 2.5351,
      "step": 425640
    },
    {
      "epoch": 684.34,
      "learning_rate": 0.0315942806244373,
      "loss": 2.523,
      "step": 425660
    },
    {
      "epoch": 684.37,
      "learning_rate": 0.031591065193569134,
      "loss": 2.5193,
      "step": 425680
    },
    {
      "epoch": 684.41,
      "learning_rate": 0.031587849762700966,
      "loss": 2.5449,
      "step": 425700
    },
    {
      "epoch": 684.44,
      "learning_rate": 0.0315846343318328,
      "loss": 2.5557,
      "step": 425720
    },
    {
      "epoch": 684.47,
      "learning_rate": 0.03158141890096463,
      "loss": 2.551,
      "step": 425740
    },
    {
      "epoch": 684.5,
      "learning_rate": 0.03157820347009647,
      "loss": 2.5299,
      "step": 425760
    },
    {
      "epoch": 684.53,
      "learning_rate": 0.0315749880392283,
      "loss": 2.5436,
      "step": 425780
    },
    {
      "epoch": 684.57,
      "learning_rate": 0.03157177260836013,
      "loss": 2.5411,
      "step": 425800
    },
    {
      "epoch": 684.6,
      "learning_rate": 0.03156855717749196,
      "loss": 2.5418,
      "step": 425820
    },
    {
      "epoch": 684.63,
      "learning_rate": 0.031565341746623794,
      "loss": 2.5393,
      "step": 425840
    },
    {
      "epoch": 684.66,
      "learning_rate": 0.03156212631575563,
      "loss": 2.5325,
      "step": 425860
    },
    {
      "epoch": 684.69,
      "learning_rate": 0.031558910884887464,
      "loss": 2.5264,
      "step": 425880
    },
    {
      "epoch": 684.73,
      "learning_rate": 0.031555695454019296,
      "loss": 2.5381,
      "step": 425900
    },
    {
      "epoch": 684.76,
      "learning_rate": 0.03155248002315113,
      "loss": 2.5513,
      "step": 425920
    },
    {
      "epoch": 684.79,
      "learning_rate": 0.03154926459228296,
      "loss": 2.524,
      "step": 425940
    },
    {
      "epoch": 684.82,
      "learning_rate": 0.03154604916141479,
      "loss": 2.5358,
      "step": 425960
    },
    {
      "epoch": 684.86,
      "learning_rate": 0.03154283373054663,
      "loss": 2.5715,
      "step": 425980
    },
    {
      "epoch": 684.89,
      "learning_rate": 0.03153961829967846,
      "loss": 2.5432,
      "step": 426000
    },
    {
      "epoch": 684.92,
      "learning_rate": 0.03153640286881029,
      "loss": 2.5188,
      "step": 426020
    },
    {
      "epoch": 684.95,
      "learning_rate": 0.031533187437942124,
      "loss": 2.5412,
      "step": 426040
    },
    {
      "epoch": 684.98,
      "learning_rate": 0.031529972007073956,
      "loss": 2.5491,
      "step": 426060
    },
    {
      "epoch": 685.0,
      "eval_accuracy": {
        "accuracy": 0.4382336935396097
      },
      "eval_loss": 2.6375815868377686,
      "eval_runtime": 4.0023,
      "eval_samples_per_second": 3213.881,
      "eval_steps_per_second": 50.221,
      "step": 426070
    },
    {
      "epoch": 685.02,
      "learning_rate": 0.031526756576205794,
      "loss": 2.5495,
      "step": 426080
    },
    {
      "epoch": 685.05,
      "learning_rate": 0.031523541145337626,
      "loss": 2.5573,
      "step": 426100
    },
    {
      "epoch": 685.08,
      "learning_rate": 0.03152032571446946,
      "loss": 2.5545,
      "step": 426120
    },
    {
      "epoch": 685.11,
      "learning_rate": 0.03151711028360129,
      "loss": 2.5173,
      "step": 426140
    },
    {
      "epoch": 685.14,
      "learning_rate": 0.03151389485273312,
      "loss": 2.517,
      "step": 426160
    },
    {
      "epoch": 685.18,
      "learning_rate": 0.03151067942186495,
      "loss": 2.5239,
      "step": 426180
    },
    {
      "epoch": 685.21,
      "learning_rate": 0.03150746399099679,
      "loss": 2.514,
      "step": 426200
    },
    {
      "epoch": 685.24,
      "learning_rate": 0.03150424856012862,
      "loss": 2.5453,
      "step": 426220
    },
    {
      "epoch": 685.27,
      "learning_rate": 0.031501033129260454,
      "loss": 2.5373,
      "step": 426240
    },
    {
      "epoch": 685.31,
      "learning_rate": 0.031497817698392286,
      "loss": 2.5292,
      "step": 426260
    },
    {
      "epoch": 685.34,
      "learning_rate": 0.03149460226752412,
      "loss": 2.522,
      "step": 426280
    },
    {
      "epoch": 685.37,
      "learning_rate": 0.03149138683665595,
      "loss": 2.5107,
      "step": 426300
    },
    {
      "epoch": 685.4,
      "learning_rate": 0.03148817140578779,
      "loss": 2.5228,
      "step": 426320
    },
    {
      "epoch": 685.43,
      "learning_rate": 0.03148495597491962,
      "loss": 2.5212,
      "step": 426340
    },
    {
      "epoch": 685.47,
      "learning_rate": 0.03148174054405145,
      "loss": 2.5396,
      "step": 426360
    },
    {
      "epoch": 685.5,
      "learning_rate": 0.03147852511318328,
      "loss": 2.541,
      "step": 426380
    },
    {
      "epoch": 685.53,
      "learning_rate": 0.031475309682315114,
      "loss": 2.5112,
      "step": 426400
    },
    {
      "epoch": 685.56,
      "learning_rate": 0.03147209425144695,
      "loss": 2.5256,
      "step": 426420
    },
    {
      "epoch": 685.59,
      "learning_rate": 0.031468878820578784,
      "loss": 2.5533,
      "step": 426440
    },
    {
      "epoch": 685.63,
      "learning_rate": 0.031465663389710616,
      "loss": 2.5675,
      "step": 426460
    },
    {
      "epoch": 685.66,
      "learning_rate": 0.03146244795884245,
      "loss": 2.5284,
      "step": 426480
    },
    {
      "epoch": 685.69,
      "learning_rate": 0.03145923252797428,
      "loss": 2.5495,
      "step": 426500
    },
    {
      "epoch": 685.72,
      "learning_rate": 0.03145601709710611,
      "loss": 2.543,
      "step": 426520
    },
    {
      "epoch": 685.76,
      "learning_rate": 0.03145280166623795,
      "loss": 2.5272,
      "step": 426540
    },
    {
      "epoch": 685.79,
      "learning_rate": 0.03144958623536978,
      "loss": 2.5349,
      "step": 426560
    },
    {
      "epoch": 685.82,
      "learning_rate": 0.03144637080450161,
      "loss": 2.5288,
      "step": 426580
    },
    {
      "epoch": 685.85,
      "learning_rate": 0.031443155373633444,
      "loss": 2.5362,
      "step": 426600
    },
    {
      "epoch": 685.88,
      "learning_rate": 0.031439939942765276,
      "loss": 2.5266,
      "step": 426620
    },
    {
      "epoch": 685.92,
      "learning_rate": 0.03143672451189711,
      "loss": 2.5388,
      "step": 426640
    },
    {
      "epoch": 685.95,
      "learning_rate": 0.031433509081028946,
      "loss": 2.543,
      "step": 426660
    },
    {
      "epoch": 685.98,
      "learning_rate": 0.03143029365016078,
      "loss": 2.5334,
      "step": 426680
    },
    {
      "epoch": 686.0,
      "eval_accuracy": {
        "accuracy": 0.43722304283604135
      },
      "eval_loss": 2.652646541595459,
      "eval_runtime": 3.3248,
      "eval_samples_per_second": 3868.81,
      "eval_steps_per_second": 60.455,
      "step": 426692
    },
    {
      "epoch": 686.01,
      "learning_rate": 0.03142707821929261,
      "loss": 2.5297,
      "step": 426700
    },
    {
      "epoch": 686.05,
      "learning_rate": 0.03142386278842444,
      "loss": 2.5421,
      "step": 426720
    },
    {
      "epoch": 686.08,
      "learning_rate": 0.03142064735755627,
      "loss": 2.55,
      "step": 426740
    },
    {
      "epoch": 686.11,
      "learning_rate": 0.03141743192668811,
      "loss": 2.5308,
      "step": 426760
    },
    {
      "epoch": 686.14,
      "learning_rate": 0.03141421649581994,
      "loss": 2.5476,
      "step": 426780
    },
    {
      "epoch": 686.17,
      "learning_rate": 0.031411001064951774,
      "loss": 2.5384,
      "step": 426800
    },
    {
      "epoch": 686.21,
      "learning_rate": 0.031407785634083606,
      "loss": 2.5319,
      "step": 426820
    },
    {
      "epoch": 686.24,
      "learning_rate": 0.03140457020321544,
      "loss": 2.527,
      "step": 426840
    },
    {
      "epoch": 686.27,
      "learning_rate": 0.03140135477234727,
      "loss": 2.5414,
      "step": 426860
    },
    {
      "epoch": 686.3,
      "learning_rate": 0.03139813934147911,
      "loss": 2.5221,
      "step": 426880
    },
    {
      "epoch": 686.33,
      "learning_rate": 0.03139492391061094,
      "loss": 2.5231,
      "step": 426900
    },
    {
      "epoch": 686.37,
      "learning_rate": 0.03139170847974277,
      "loss": 2.5506,
      "step": 426920
    },
    {
      "epoch": 686.4,
      "learning_rate": 0.0313884930488746,
      "loss": 2.5188,
      "step": 426940
    },
    {
      "epoch": 686.43,
      "learning_rate": 0.031385277618006434,
      "loss": 2.5228,
      "step": 426960
    },
    {
      "epoch": 686.46,
      "learning_rate": 0.031382062187138265,
      "loss": 2.5388,
      "step": 426980
    },
    {
      "epoch": 686.5,
      "learning_rate": 0.031378846756270104,
      "loss": 2.5159,
      "step": 427000
    },
    {
      "epoch": 686.53,
      "learning_rate": 0.031375631325401936,
      "loss": 2.5236,
      "step": 427020
    },
    {
      "epoch": 686.56,
      "learning_rate": 0.03137241589453377,
      "loss": 2.5274,
      "step": 427040
    },
    {
      "epoch": 686.59,
      "learning_rate": 0.0313692004636656,
      "loss": 2.5333,
      "step": 427060
    },
    {
      "epoch": 686.62,
      "learning_rate": 0.03136598503279743,
      "loss": 2.5292,
      "step": 427080
    },
    {
      "epoch": 686.66,
      "learning_rate": 0.03136276960192927,
      "loss": 2.5171,
      "step": 427100
    },
    {
      "epoch": 686.69,
      "learning_rate": 0.0313595541710611,
      "loss": 2.5491,
      "step": 427120
    },
    {
      "epoch": 686.72,
      "learning_rate": 0.03135633874019293,
      "loss": 2.5451,
      "step": 427140
    },
    {
      "epoch": 686.75,
      "learning_rate": 0.031353123309324764,
      "loss": 2.5496,
      "step": 427160
    },
    {
      "epoch": 686.78,
      "learning_rate": 0.031349907878456595,
      "loss": 2.5343,
      "step": 427180
    },
    {
      "epoch": 686.82,
      "learning_rate": 0.03134669244758842,
      "loss": 2.5435,
      "step": 427200
    },
    {
      "epoch": 686.85,
      "learning_rate": 0.031343477016720266,
      "loss": 2.5226,
      "step": 427220
    },
    {
      "epoch": 686.88,
      "learning_rate": 0.0313402615858521,
      "loss": 2.5163,
      "step": 427240
    },
    {
      "epoch": 686.91,
      "learning_rate": 0.03133704615498393,
      "loss": 2.5441,
      "step": 427260
    },
    {
      "epoch": 686.95,
      "learning_rate": 0.03133383072411576,
      "loss": 2.5288,
      "step": 427280
    },
    {
      "epoch": 686.98,
      "learning_rate": 0.03133061529324759,
      "loss": 2.5273,
      "step": 427300
    },
    {
      "epoch": 687.0,
      "eval_accuracy": {
        "accuracy": 0.4355127108761564
      },
      "eval_loss": 2.669722557067871,
      "eval_runtime": 3.0439,
      "eval_samples_per_second": 4225.793,
      "eval_steps_per_second": 66.033,
      "step": 427314
    },
    {
      "epoch": 687.01,
      "learning_rate": 0.03132739986237942,
      "loss": 2.5279,
      "step": 427320
    },
    {
      "epoch": 687.04,
      "learning_rate": 0.03132418443151126,
      "loss": 2.5389,
      "step": 427340
    },
    {
      "epoch": 687.07,
      "learning_rate": 0.031320969000643094,
      "loss": 2.5402,
      "step": 427360
    },
    {
      "epoch": 687.11,
      "learning_rate": 0.031317753569774925,
      "loss": 2.5533,
      "step": 427380
    },
    {
      "epoch": 687.14,
      "learning_rate": 0.03131453813890676,
      "loss": 2.5091,
      "step": 427400
    },
    {
      "epoch": 687.17,
      "learning_rate": 0.03131132270803858,
      "loss": 2.5199,
      "step": 427420
    },
    {
      "epoch": 687.2,
      "learning_rate": 0.03130810727717043,
      "loss": 2.5245,
      "step": 427440
    },
    {
      "epoch": 687.23,
      "learning_rate": 0.03130489184630226,
      "loss": 2.5306,
      "step": 427460
    },
    {
      "epoch": 687.27,
      "learning_rate": 0.03130167641543409,
      "loss": 2.5441,
      "step": 427480
    },
    {
      "epoch": 687.3,
      "learning_rate": 0.03129846098456592,
      "loss": 2.5243,
      "step": 427500
    },
    {
      "epoch": 687.33,
      "learning_rate": 0.03129524555369775,
      "loss": 2.5554,
      "step": 427520
    },
    {
      "epoch": 687.36,
      "learning_rate": 0.03129203012282958,
      "loss": 2.5333,
      "step": 427540
    },
    {
      "epoch": 687.4,
      "learning_rate": 0.031288814691961424,
      "loss": 2.5351,
      "step": 427560
    },
    {
      "epoch": 687.43,
      "learning_rate": 0.031285599261093255,
      "loss": 2.5337,
      "step": 427580
    },
    {
      "epoch": 687.46,
      "learning_rate": 0.03128238383022509,
      "loss": 2.5172,
      "step": 427600
    },
    {
      "epoch": 687.49,
      "learning_rate": 0.03127916839935692,
      "loss": 2.5244,
      "step": 427620
    },
    {
      "epoch": 687.52,
      "learning_rate": 0.03127595296848874,
      "loss": 2.5313,
      "step": 427640
    },
    {
      "epoch": 687.56,
      "learning_rate": 0.03127273753762059,
      "loss": 2.5469,
      "step": 427660
    },
    {
      "epoch": 687.59,
      "learning_rate": 0.03126952210675242,
      "loss": 2.5412,
      "step": 427680
    },
    {
      "epoch": 687.62,
      "learning_rate": 0.03126630667588425,
      "loss": 2.5655,
      "step": 427700
    },
    {
      "epoch": 687.65,
      "learning_rate": 0.031263091245016084,
      "loss": 2.5493,
      "step": 427720
    },
    {
      "epoch": 687.68,
      "learning_rate": 0.03125987581414791,
      "loss": 2.5381,
      "step": 427740
    },
    {
      "epoch": 687.72,
      "learning_rate": 0.03125666038327974,
      "loss": 2.5432,
      "step": 427760
    },
    {
      "epoch": 687.75,
      "learning_rate": 0.031253444952411585,
      "loss": 2.544,
      "step": 427780
    },
    {
      "epoch": 687.78,
      "learning_rate": 0.03125022952154342,
      "loss": 2.526,
      "step": 427800
    },
    {
      "epoch": 687.81,
      "learning_rate": 0.03124701409067524,
      "loss": 2.5176,
      "step": 427820
    },
    {
      "epoch": 687.85,
      "learning_rate": 0.031243798659807073,
      "loss": 2.5217,
      "step": 427840
    },
    {
      "epoch": 687.88,
      "learning_rate": 0.0312405832289389,
      "loss": 2.5529,
      "step": 427860
    },
    {
      "epoch": 687.91,
      "learning_rate": 0.031237367798070736,
      "loss": 2.5184,
      "step": 427880
    },
    {
      "epoch": 687.94,
      "learning_rate": 0.031234152367202575,
      "loss": 2.5403,
      "step": 427900
    },
    {
      "epoch": 687.97,
      "learning_rate": 0.031230936936334403,
      "loss": 2.5389,
      "step": 427920
    },
    {
      "epoch": 688.0,
      "eval_accuracy": {
        "accuracy": 0.4366788463033507
      },
      "eval_loss": 2.646348714828491,
      "eval_runtime": 3.0206,
      "eval_samples_per_second": 4258.448,
      "eval_steps_per_second": 66.543,
      "step": 427936
    },
    {
      "epoch": 688.01,
      "learning_rate": 0.031227721505466238,
      "loss": 2.5476,
      "step": 427940
    },
    {
      "epoch": 688.04,
      "learning_rate": 0.03122450607459807,
      "loss": 2.5303,
      "step": 427960
    },
    {
      "epoch": 688.07,
      "learning_rate": 0.0312212906437299,
      "loss": 2.5214,
      "step": 427980
    },
    {
      "epoch": 688.1,
      "learning_rate": 0.03121807521286174,
      "loss": 2.5276,
      "step": 428000
    },
    {
      "epoch": 688.14,
      "learning_rate": 0.03121485978199357,
      "loss": 2.5169,
      "step": 428020
    },
    {
      "epoch": 688.17,
      "learning_rate": 0.031211644351125403,
      "loss": 2.5195,
      "step": 428040
    },
    {
      "epoch": 688.2,
      "learning_rate": 0.03120842892025723,
      "loss": 2.5367,
      "step": 428060
    },
    {
      "epoch": 688.23,
      "learning_rate": 0.031205213489389066,
      "loss": 2.5408,
      "step": 428080
    },
    {
      "epoch": 688.26,
      "learning_rate": 0.03120199805852089,
      "loss": 2.5624,
      "step": 428100
    },
    {
      "epoch": 688.3,
      "learning_rate": 0.031198782627652733,
      "loss": 2.5322,
      "step": 428120
    },
    {
      "epoch": 688.33,
      "learning_rate": 0.031195567196784568,
      "loss": 2.5357,
      "step": 428140
    },
    {
      "epoch": 688.36,
      "learning_rate": 0.0311923517659164,
      "loss": 2.5267,
      "step": 428160
    },
    {
      "epoch": 688.39,
      "learning_rate": 0.03118913633504823,
      "loss": 2.5257,
      "step": 428180
    },
    {
      "epoch": 688.42,
      "learning_rate": 0.03118592090418006,
      "loss": 2.5438,
      "step": 428200
    },
    {
      "epoch": 688.46,
      "learning_rate": 0.03118270547331189,
      "loss": 2.55,
      "step": 428220
    },
    {
      "epoch": 688.49,
      "learning_rate": 0.031179490042443733,
      "loss": 2.5422,
      "step": 428240
    },
    {
      "epoch": 688.52,
      "learning_rate": 0.03117627461157556,
      "loss": 2.5434,
      "step": 428260
    },
    {
      "epoch": 688.55,
      "learning_rate": 0.031173059180707396,
      "loss": 2.5242,
      "step": 428280
    },
    {
      "epoch": 688.59,
      "learning_rate": 0.031169843749839228,
      "loss": 2.5385,
      "step": 428300
    },
    {
      "epoch": 688.62,
      "learning_rate": 0.03116662831897106,
      "loss": 2.5258,
      "step": 428320
    },
    {
      "epoch": 688.65,
      "learning_rate": 0.031163412888102898,
      "loss": 2.5257,
      "step": 428340
    },
    {
      "epoch": 688.68,
      "learning_rate": 0.03116019745723473,
      "loss": 2.525,
      "step": 428360
    },
    {
      "epoch": 688.71,
      "learning_rate": 0.03115698202636656,
      "loss": 2.5309,
      "step": 428380
    },
    {
      "epoch": 688.75,
      "learning_rate": 0.03115376659549839,
      "loss": 2.5181,
      "step": 428400
    },
    {
      "epoch": 688.78,
      "learning_rate": 0.03115055116463022,
      "loss": 2.5284,
      "step": 428420
    },
    {
      "epoch": 688.81,
      "learning_rate": 0.03114733573376205,
      "loss": 2.5527,
      "step": 428440
    },
    {
      "epoch": 688.84,
      "learning_rate": 0.03114412030289389,
      "loss": 2.54,
      "step": 428460
    },
    {
      "epoch": 688.87,
      "learning_rate": 0.031140904872025726,
      "loss": 2.526,
      "step": 428480
    },
    {
      "epoch": 688.91,
      "learning_rate": 0.031137689441157558,
      "loss": 2.5395,
      "step": 428500
    },
    {
      "epoch": 688.94,
      "learning_rate": 0.03113447401028939,
      "loss": 2.5352,
      "step": 428520
    },
    {
      "epoch": 688.97,
      "learning_rate": 0.031131258579421218,
      "loss": 2.5383,
      "step": 428540
    },
    {
      "epoch": 689.0,
      "eval_accuracy": {
        "accuracy": 0.43434657544896216
      },
      "eval_loss": 2.6553566455841064,
      "eval_runtime": 3.1053,
      "eval_samples_per_second": 4142.302,
      "eval_steps_per_second": 64.728,
      "step": 428558
    },
    {
      "epoch": 689.0,
      "learning_rate": 0.03112804314855305,
      "loss": 2.5455,
      "step": 428560
    },
    {
      "epoch": 689.04,
      "learning_rate": 0.03112482771768489,
      "loss": 2.5276,
      "step": 428580
    },
    {
      "epoch": 689.07,
      "learning_rate": 0.03112161228681672,
      "loss": 2.5381,
      "step": 428600
    },
    {
      "epoch": 689.1,
      "learning_rate": 0.031118396855948555,
      "loss": 2.5357,
      "step": 428620
    },
    {
      "epoch": 689.13,
      "learning_rate": 0.03111518142508038,
      "loss": 2.5397,
      "step": 428640
    },
    {
      "epoch": 689.16,
      "learning_rate": 0.031111965994212218,
      "loss": 2.5241,
      "step": 428660
    },
    {
      "epoch": 689.2,
      "learning_rate": 0.031108750563344056,
      "loss": 2.5366,
      "step": 428680
    },
    {
      "epoch": 689.23,
      "learning_rate": 0.031105535132475888,
      "loss": 2.5322,
      "step": 428700
    },
    {
      "epoch": 689.26,
      "learning_rate": 0.03110231970160772,
      "loss": 2.5382,
      "step": 428720
    },
    {
      "epoch": 689.29,
      "learning_rate": 0.031099104270739548,
      "loss": 2.5229,
      "step": 428740
    },
    {
      "epoch": 689.32,
      "learning_rate": 0.03109588883987138,
      "loss": 2.5276,
      "step": 428760
    },
    {
      "epoch": 689.36,
      "learning_rate": 0.031092673409003208,
      "loss": 2.5349,
      "step": 428780
    },
    {
      "epoch": 689.39,
      "learning_rate": 0.03108945797813505,
      "loss": 2.513,
      "step": 428800
    },
    {
      "epoch": 689.42,
      "learning_rate": 0.031086242547266885,
      "loss": 2.5204,
      "step": 428820
    },
    {
      "epoch": 689.45,
      "learning_rate": 0.031083027116398716,
      "loss": 2.5324,
      "step": 428840
    },
    {
      "epoch": 689.49,
      "learning_rate": 0.031079811685530548,
      "loss": 2.5191,
      "step": 428860
    },
    {
      "epoch": 689.52,
      "learning_rate": 0.031076596254662376,
      "loss": 2.5257,
      "step": 428880
    },
    {
      "epoch": 689.55,
      "learning_rate": 0.031073380823794208,
      "loss": 2.5357,
      "step": 428900
    },
    {
      "epoch": 689.58,
      "learning_rate": 0.03107016539292605,
      "loss": 2.5373,
      "step": 428920
    },
    {
      "epoch": 689.61,
      "learning_rate": 0.031066949962057878,
      "loss": 2.5712,
      "step": 428940
    },
    {
      "epoch": 689.65,
      "learning_rate": 0.03106373453118971,
      "loss": 2.5448,
      "step": 428960
    },
    {
      "epoch": 689.68,
      "learning_rate": 0.031060519100321538,
      "loss": 2.5718,
      "step": 428980
    },
    {
      "epoch": 689.71,
      "learning_rate": 0.031057303669453376,
      "loss": 2.5257,
      "step": 429000
    },
    {
      "epoch": 689.74,
      "learning_rate": 0.031054088238585215,
      "loss": 2.5183,
      "step": 429020
    },
    {
      "epoch": 689.77,
      "learning_rate": 0.031050872807717046,
      "loss": 2.5534,
      "step": 429040
    },
    {
      "epoch": 689.81,
      "learning_rate": 0.031047657376848878,
      "loss": 2.5495,
      "step": 429060
    },
    {
      "epoch": 689.84,
      "learning_rate": 0.031044441945980706,
      "loss": 2.5314,
      "step": 429080
    },
    {
      "epoch": 689.87,
      "learning_rate": 0.031041226515112538,
      "loss": 2.5296,
      "step": 429100
    },
    {
      "epoch": 689.9,
      "learning_rate": 0.031038011084244366,
      "loss": 2.5363,
      "step": 429120
    },
    {
      "epoch": 689.94,
      "learning_rate": 0.031034795653376208,
      "loss": 2.5316,
      "step": 429140
    },
    {
      "epoch": 689.97,
      "learning_rate": 0.031031580222508043,
      "loss": 2.5338,
      "step": 429160
    },
    {
      "epoch": 690.0,
      "learning_rate": 0.031028364791639867,
      "loss": 2.5401,
      "step": 429180
    },
    {
      "epoch": 690.0,
      "eval_accuracy": {
        "accuracy": 0.434579802534401
      },
      "eval_loss": 2.6444458961486816,
      "eval_runtime": 3.3557,
      "eval_samples_per_second": 3833.145,
      "eval_steps_per_second": 59.898,
      "step": 429180
    },
    {
      "epoch": 690.03,
      "learning_rate": 0.031025149360771706,
      "loss": 2.5343,
      "step": 429200
    },
    {
      "epoch": 690.06,
      "learning_rate": 0.031021933929903534,
      "loss": 2.5347,
      "step": 429220
    },
    {
      "epoch": 690.1,
      "learning_rate": 0.031018718499035366,
      "loss": 2.5011,
      "step": 429240
    },
    {
      "epoch": 690.13,
      "learning_rate": 0.031015503068167208,
      "loss": 2.5259,
      "step": 429260
    },
    {
      "epoch": 690.16,
      "learning_rate": 0.031012287637299036,
      "loss": 2.5223,
      "step": 429280
    },
    {
      "epoch": 690.19,
      "learning_rate": 0.031009072206430868,
      "loss": 2.5279,
      "step": 429300
    },
    {
      "epoch": 690.23,
      "learning_rate": 0.031005856775562696,
      "loss": 2.5343,
      "step": 429320
    },
    {
      "epoch": 690.26,
      "learning_rate": 0.031002641344694534,
      "loss": 2.5134,
      "step": 429340
    },
    {
      "epoch": 690.29,
      "learning_rate": 0.030999425913826373,
      "loss": 2.5181,
      "step": 429360
    },
    {
      "epoch": 690.32,
      "learning_rate": 0.030996210482958197,
      "loss": 2.5341,
      "step": 429380
    },
    {
      "epoch": 690.35,
      "learning_rate": 0.030992995052090036,
      "loss": 2.5266,
      "step": 429400
    },
    {
      "epoch": 690.39,
      "learning_rate": 0.030989779621221864,
      "loss": 2.534,
      "step": 429420
    },
    {
      "epoch": 690.42,
      "learning_rate": 0.030986564190353696,
      "loss": 2.5306,
      "step": 429440
    },
    {
      "epoch": 690.45,
      "learning_rate": 0.030983348759485524,
      "loss": 2.5109,
      "step": 429460
    },
    {
      "epoch": 690.48,
      "learning_rate": 0.030980133328617366,
      "loss": 2.5337,
      "step": 429480
    },
    {
      "epoch": 690.51,
      "learning_rate": 0.030976917897749198,
      "loss": 2.5264,
      "step": 429500
    },
    {
      "epoch": 690.55,
      "learning_rate": 0.030973702466881026,
      "loss": 2.5254,
      "step": 429520
    },
    {
      "epoch": 690.58,
      "learning_rate": 0.030970647807556276,
      "loss": 2.5491,
      "step": 429540
    },
    {
      "epoch": 690.61,
      "learning_rate": 0.030967432376688104,
      "loss": 2.5257,
      "step": 429560
    },
    {
      "epoch": 690.64,
      "learning_rate": 0.03096421694581993,
      "loss": 2.5195,
      "step": 429580
    },
    {
      "epoch": 690.68,
      "learning_rate": 0.030961001514951764,
      "loss": 2.5344,
      "step": 429600
    },
    {
      "epoch": 690.71,
      "learning_rate": 0.030957786084083606,
      "loss": 2.5287,
      "step": 429620
    },
    {
      "epoch": 690.74,
      "learning_rate": 0.030954570653215437,
      "loss": 2.5615,
      "step": 429640
    },
    {
      "epoch": 690.77,
      "learning_rate": 0.030951355222347265,
      "loss": 2.5317,
      "step": 429660
    },
    {
      "epoch": 690.8,
      "learning_rate": 0.030948139791479097,
      "loss": 2.5428,
      "step": 429680
    },
    {
      "epoch": 690.84,
      "learning_rate": 0.03094492436061093,
      "loss": 2.5226,
      "step": 429700
    },
    {
      "epoch": 690.87,
      "learning_rate": 0.030941708929742757,
      "loss": 2.5328,
      "step": 429720
    },
    {
      "epoch": 690.9,
      "learning_rate": 0.030938493498874606,
      "loss": 2.533,
      "step": 429740
    },
    {
      "epoch": 690.93,
      "learning_rate": 0.030935278068006434,
      "loss": 2.5306,
      "step": 429760
    },
    {
      "epoch": 690.96,
      "learning_rate": 0.03093206263713826,
      "loss": 2.5444,
      "step": 429780
    },
    {
      "epoch": 691.0,
      "learning_rate": 0.030928847206270094,
      "loss": 2.5355,
      "step": 429800
    },
    {
      "epoch": 691.0,
      "eval_accuracy": {
        "accuracy": 0.43434657544896216
      },
      "eval_loss": 2.6583645343780518,
      "eval_runtime": 2.974,
      "eval_samples_per_second": 4325.2,
      "eval_steps_per_second": 67.587,
      "step": 429802
    },
    {
      "epoch": 691.03,
      "learning_rate": 0.030925631775401925,
      "loss": 2.5099,
      "step": 429820
    },
    {
      "epoch": 691.06,
      "learning_rate": 0.030922416344533767,
      "loss": 2.5336,
      "step": 429840
    },
    {
      "epoch": 691.09,
      "learning_rate": 0.030919200913665595,
      "loss": 2.529,
      "step": 429860
    },
    {
      "epoch": 691.13,
      "learning_rate": 0.030915985482797434,
      "loss": 2.5394,
      "step": 429880
    },
    {
      "epoch": 691.16,
      "learning_rate": 0.03091277005192926,
      "loss": 2.5263,
      "step": 429900
    },
    {
      "epoch": 691.19,
      "learning_rate": 0.030909554621061087,
      "loss": 2.5183,
      "step": 429920
    },
    {
      "epoch": 691.22,
      "learning_rate": 0.030906339190192922,
      "loss": 2.5403,
      "step": 429940
    },
    {
      "epoch": 691.25,
      "learning_rate": 0.030903123759324764,
      "loss": 2.5502,
      "step": 429960
    },
    {
      "epoch": 691.29,
      "learning_rate": 0.030899908328456595,
      "loss": 2.5236,
      "step": 429980
    },
    {
      "epoch": 691.32,
      "learning_rate": 0.030896692897588424,
      "loss": 2.4919,
      "step": 430000
    },
    {
      "epoch": 691.35,
      "learning_rate": 0.030893477466720255,
      "loss": 2.5153,
      "step": 430020
    },
    {
      "epoch": 691.38,
      "learning_rate": 0.030890262035852087,
      "loss": 2.5328,
      "step": 430040
    },
    {
      "epoch": 691.41,
      "learning_rate": 0.030887046604983915,
      "loss": 2.5323,
      "step": 430060
    },
    {
      "epoch": 691.45,
      "learning_rate": 0.030883831174115764,
      "loss": 2.5298,
      "step": 430080
    },
    {
      "epoch": 691.48,
      "learning_rate": 0.03088061574324759,
      "loss": 2.5201,
      "step": 430100
    },
    {
      "epoch": 691.51,
      "learning_rate": 0.030877400312379417,
      "loss": 2.5253,
      "step": 430120
    },
    {
      "epoch": 691.54,
      "learning_rate": 0.030874184881511252,
      "loss": 2.5479,
      "step": 430140
    },
    {
      "epoch": 691.58,
      "learning_rate": 0.030870969450643083,
      "loss": 2.555,
      "step": 430160
    },
    {
      "epoch": 691.61,
      "learning_rate": 0.030867754019774925,
      "loss": 2.5287,
      "step": 430180
    },
    {
      "epoch": 691.64,
      "learning_rate": 0.030864538588906754,
      "loss": 2.5384,
      "step": 430200
    },
    {
      "epoch": 691.67,
      "learning_rate": 0.030861323158038585,
      "loss": 2.5311,
      "step": 430220
    },
    {
      "epoch": 691.7,
      "learning_rate": 0.030858107727170417,
      "loss": 2.5335,
      "step": 430240
    },
    {
      "epoch": 691.74,
      "learning_rate": 0.030854892296302245,
      "loss": 2.5623,
      "step": 430260
    },
    {
      "epoch": 691.77,
      "learning_rate": 0.03085167686543408,
      "loss": 2.5399,
      "step": 430280
    },
    {
      "epoch": 691.8,
      "learning_rate": 0.030848461434565922,
      "loss": 2.521,
      "step": 430300
    },
    {
      "epoch": 691.83,
      "learning_rate": 0.030845246003697747,
      "loss": 2.5276,
      "step": 430320
    },
    {
      "epoch": 691.86,
      "learning_rate": 0.030842030572829582,
      "loss": 2.549,
      "step": 430340
    },
    {
      "epoch": 691.9,
      "learning_rate": 0.030838815141961413,
      "loss": 2.5451,
      "step": 430360
    },
    {
      "epoch": 691.93,
      "learning_rate": 0.030835599711093245,
      "loss": 2.533,
      "step": 430380
    },
    {
      "epoch": 691.96,
      "learning_rate": 0.030832384280225084,
      "loss": 2.5314,
      "step": 430400
    },
    {
      "epoch": 691.99,
      "learning_rate": 0.030829168849356915,
      "loss": 2.5135,
      "step": 430420
    },
    {
      "epoch": 692.0,
      "eval_accuracy": {
        "accuracy": 0.4368343310269766
      },
      "eval_loss": 2.6535186767578125,
      "eval_runtime": 3.1133,
      "eval_samples_per_second": 4131.685,
      "eval_steps_per_second": 64.563,
      "step": 430424
    },
    {
      "epoch": 692.03,
      "learning_rate": 0.030825953418488747,
      "loss": 2.5479,
      "step": 430440
    },
    {
      "epoch": 692.06,
      "learning_rate": 0.030822737987620575,
      "loss": 2.5216,
      "step": 430460
    },
    {
      "epoch": 692.09,
      "learning_rate": 0.03081952255675241,
      "loss": 2.5048,
      "step": 430480
    },
    {
      "epoch": 692.12,
      "learning_rate": 0.03081630712588424,
      "loss": 2.5137,
      "step": 430500
    },
    {
      "epoch": 692.15,
      "learning_rate": 0.030813091695016084,
      "loss": 2.5473,
      "step": 430520
    },
    {
      "epoch": 692.19,
      "learning_rate": 0.030809876264147912,
      "loss": 2.5413,
      "step": 430540
    },
    {
      "epoch": 692.22,
      "learning_rate": 0.030806660833279743,
      "loss": 2.5145,
      "step": 430560
    },
    {
      "epoch": 692.25,
      "learning_rate": 0.030803445402411575,
      "loss": 2.5102,
      "step": 430580
    },
    {
      "epoch": 692.28,
      "learning_rate": 0.030800229971543403,
      "loss": 2.5346,
      "step": 430600
    },
    {
      "epoch": 692.32,
      "learning_rate": 0.030797014540675235,
      "loss": 2.5313,
      "step": 430620
    },
    {
      "epoch": 692.35,
      "learning_rate": 0.030793799109807077,
      "loss": 2.5405,
      "step": 430640
    },
    {
      "epoch": 692.38,
      "learning_rate": 0.030790583678938905,
      "loss": 2.5359,
      "step": 430660
    },
    {
      "epoch": 692.41,
      "learning_rate": 0.03078736824807074,
      "loss": 2.5508,
      "step": 430680
    },
    {
      "epoch": 692.44,
      "learning_rate": 0.03078415281720257,
      "loss": 2.531,
      "step": 430700
    },
    {
      "epoch": 692.48,
      "learning_rate": 0.030780937386334403,
      "loss": 2.5331,
      "step": 430720
    },
    {
      "epoch": 692.51,
      "learning_rate": 0.030777721955466242,
      "loss": 2.5082,
      "step": 430740
    },
    {
      "epoch": 692.54,
      "learning_rate": 0.030774506524598073,
      "loss": 2.5459,
      "step": 430760
    },
    {
      "epoch": 692.57,
      "learning_rate": 0.030771291093729905,
      "loss": 2.5287,
      "step": 430780
    },
    {
      "epoch": 692.6,
      "learning_rate": 0.030768075662861733,
      "loss": 2.5253,
      "step": 430800
    },
    {
      "epoch": 692.64,
      "learning_rate": 0.030764860231993568,
      "loss": 2.5304,
      "step": 430820
    },
    {
      "epoch": 692.67,
      "learning_rate": 0.030761644801125393,
      "loss": 2.5199,
      "step": 430840
    },
    {
      "epoch": 692.7,
      "learning_rate": 0.030758429370257235,
      "loss": 2.5342,
      "step": 430860
    },
    {
      "epoch": 692.73,
      "learning_rate": 0.03075521393938907,
      "loss": 2.554,
      "step": 430880
    },
    {
      "epoch": 692.77,
      "learning_rate": 0.0307519985085209,
      "loss": 2.5309,
      "step": 430900
    },
    {
      "epoch": 692.8,
      "learning_rate": 0.030748783077652733,
      "loss": 2.5363,
      "step": 430920
    },
    {
      "epoch": 692.83,
      "learning_rate": 0.03074556764678456,
      "loss": 2.5259,
      "step": 430940
    },
    {
      "epoch": 692.86,
      "learning_rate": 0.030742352215916393,
      "loss": 2.5147,
      "step": 430960
    },
    {
      "epoch": 692.89,
      "learning_rate": 0.030739136785048235,
      "loss": 2.5339,
      "step": 430980
    },
    {
      "epoch": 692.93,
      "learning_rate": 0.030735921354180063,
      "loss": 2.5501,
      "step": 431000
    },
    {
      "epoch": 692.96,
      "learning_rate": 0.030732705923311898,
      "loss": 2.5283,
      "step": 431020
    },
    {
      "epoch": 692.99,
      "learning_rate": 0.03072949049244373,
      "loss": 2.5277,
      "step": 431040
    },
    {
      "epoch": 693.0,
      "eval_accuracy": {
        "accuracy": 0.44095467620306306
      },
      "eval_loss": 2.634167432785034,
      "eval_runtime": 2.9844,
      "eval_samples_per_second": 4310.031,
      "eval_steps_per_second": 67.349,
      "step": 431046
    },
    {
      "epoch": 693.02,
      "learning_rate": 0.03072627506157556,
      "loss": 2.5293,
      "step": 431060
    },
    {
      "epoch": 693.05,
      "learning_rate": 0.0307230596307074,
      "loss": 2.5599,
      "step": 431080
    },
    {
      "epoch": 693.09,
      "learning_rate": 0.03071984419983923,
      "loss": 2.5208,
      "step": 431100
    },
    {
      "epoch": 693.12,
      "learning_rate": 0.030716628768971063,
      "loss": 2.529,
      "step": 431120
    },
    {
      "epoch": 693.15,
      "learning_rate": 0.03071341333810289,
      "loss": 2.5253,
      "step": 431140
    },
    {
      "epoch": 693.18,
      "learning_rate": 0.030710197907234723,
      "loss": 2.5277,
      "step": 431160
    },
    {
      "epoch": 693.22,
      "learning_rate": 0.03070698247636655,
      "loss": 2.5527,
      "step": 431180
    },
    {
      "epoch": 693.25,
      "learning_rate": 0.030703767045498393,
      "loss": 2.5419,
      "step": 431200
    },
    {
      "epoch": 693.28,
      "learning_rate": 0.030700551614630228,
      "loss": 2.5374,
      "step": 431220
    },
    {
      "epoch": 693.31,
      "learning_rate": 0.03069733618376206,
      "loss": 2.5173,
      "step": 431240
    },
    {
      "epoch": 693.34,
      "learning_rate": 0.03069412075289389,
      "loss": 2.5101,
      "step": 431260
    },
    {
      "epoch": 693.38,
      "learning_rate": 0.03069090532202572,
      "loss": 2.5102,
      "step": 431280
    },
    {
      "epoch": 693.41,
      "learning_rate": 0.03068768989115755,
      "loss": 2.503,
      "step": 431300
    },
    {
      "epoch": 693.44,
      "learning_rate": 0.030684474460289393,
      "loss": 2.5189,
      "step": 431320
    },
    {
      "epoch": 693.47,
      "learning_rate": 0.03068125902942122,
      "loss": 2.5324,
      "step": 431340
    },
    {
      "epoch": 693.5,
      "learning_rate": 0.030678043598553056,
      "loss": 2.5396,
      "step": 431360
    },
    {
      "epoch": 693.54,
      "learning_rate": 0.03067482816768488,
      "loss": 2.5404,
      "step": 431380
    },
    {
      "epoch": 693.57,
      "learning_rate": 0.03067161273681672,
      "loss": 2.5277,
      "step": 431400
    },
    {
      "epoch": 693.6,
      "learning_rate": 0.030668397305948558,
      "loss": 2.5403,
      "step": 431420
    },
    {
      "epoch": 693.63,
      "learning_rate": 0.03066518187508039,
      "loss": 2.542,
      "step": 431440
    },
    {
      "epoch": 693.67,
      "learning_rate": 0.03066196644421222,
      "loss": 2.5279,
      "step": 431460
    },
    {
      "epoch": 693.7,
      "learning_rate": 0.03065875101334405,
      "loss": 2.5156,
      "step": 431480
    },
    {
      "epoch": 693.73,
      "learning_rate": 0.03065553558247588,
      "loss": 2.5186,
      "step": 431500
    },
    {
      "epoch": 693.76,
      "learning_rate": 0.03065232015160771,
      "loss": 2.5469,
      "step": 431520
    },
    {
      "epoch": 693.79,
      "learning_rate": 0.03064926549228296,
      "loss": 2.5401,
      "step": 431540
    },
    {
      "epoch": 693.83,
      "learning_rate": 0.030646050061414798,
      "loss": 2.53,
      "step": 431560
    },
    {
      "epoch": 693.86,
      "learning_rate": 0.030642834630546623,
      "loss": 2.5195,
      "step": 431580
    },
    {
      "epoch": 693.89,
      "learning_rate": 0.03063961919967846,
      "loss": 2.5388,
      "step": 431600
    },
    {
      "epoch": 693.92,
      "learning_rate": 0.03063640376881029,
      "loss": 2.533,
      "step": 431620
    },
    {
      "epoch": 693.95,
      "learning_rate": 0.03063318833794212,
      "loss": 2.5312,
      "step": 431640
    },
    {
      "epoch": 693.99,
      "learning_rate": 0.03062997290707395,
      "loss": 2.5185,
      "step": 431660
    },
    {
      "epoch": 694.0,
      "eval_accuracy": {
        "accuracy": 0.43854466298686157
      },
      "eval_loss": 2.6398937702178955,
      "eval_runtime": 2.9319,
      "eval_samples_per_second": 4387.316,
      "eval_steps_per_second": 68.557,
      "step": 431668
    },
    {
      "epoch": 694.02,
      "learning_rate": 0.03062675747620579,
      "loss": 2.5306,
      "step": 431680
    },
    {
      "epoch": 694.05,
      "learning_rate": 0.030623542045337623,
      "loss": 2.5193,
      "step": 431700
    },
    {
      "epoch": 694.08,
      "learning_rate": 0.03062032661446945,
      "loss": 2.5487,
      "step": 431720
    },
    {
      "epoch": 694.12,
      "learning_rate": 0.03061711118360129,
      "loss": 2.533,
      "step": 431740
    },
    {
      "epoch": 694.15,
      "learning_rate": 0.030613895752733118,
      "loss": 2.5253,
      "step": 431760
    },
    {
      "epoch": 694.18,
      "learning_rate": 0.030610680321864942,
      "loss": 2.5073,
      "step": 431780
    },
    {
      "epoch": 694.21,
      "learning_rate": 0.03060746489099679,
      "loss": 2.5112,
      "step": 431800
    },
    {
      "epoch": 694.24,
      "learning_rate": 0.03060424946012862,
      "loss": 2.5335,
      "step": 431820
    },
    {
      "epoch": 694.28,
      "learning_rate": 0.03060103402926045,
      "loss": 2.5123,
      "step": 431840
    },
    {
      "epoch": 694.31,
      "learning_rate": 0.03059781859839228,
      "loss": 2.5263,
      "step": 431860
    },
    {
      "epoch": 694.34,
      "learning_rate": 0.03059460316752411,
      "loss": 2.5507,
      "step": 431880
    },
    {
      "epoch": 694.37,
      "learning_rate": 0.030591387736655953,
      "loss": 2.5292,
      "step": 431900
    },
    {
      "epoch": 694.41,
      "learning_rate": 0.03058817230578778,
      "loss": 2.531,
      "step": 431920
    },
    {
      "epoch": 694.44,
      "learning_rate": 0.03058495687491962,
      "loss": 2.536,
      "step": 431940
    },
    {
      "epoch": 694.47,
      "learning_rate": 0.030581741444051447,
      "loss": 2.5273,
      "step": 431960
    },
    {
      "epoch": 694.5,
      "learning_rate": 0.030578526013183272,
      "loss": 2.5204,
      "step": 431980
    },
    {
      "epoch": 694.53,
      "learning_rate": 0.030575310582315107,
      "loss": 2.5436,
      "step": 432000
    },
    {
      "epoch": 694.57,
      "learning_rate": 0.03057209515144695,
      "loss": 2.5365,
      "step": 432020
    },
    {
      "epoch": 694.6,
      "learning_rate": 0.03056887972057878,
      "loss": 2.5199,
      "step": 432040
    },
    {
      "epoch": 694.63,
      "learning_rate": 0.03056566428971061,
      "loss": 2.5482,
      "step": 432060
    },
    {
      "epoch": 694.66,
      "learning_rate": 0.030562448858842448,
      "loss": 2.5396,
      "step": 432080
    },
    {
      "epoch": 694.69,
      "learning_rate": 0.030559233427974272,
      "loss": 2.554,
      "step": 432100
    },
    {
      "epoch": 694.73,
      "learning_rate": 0.0305560179971061,
      "loss": 2.5158,
      "step": 432120
    },
    {
      "epoch": 694.76,
      "learning_rate": 0.03055280256623795,
      "loss": 2.5221,
      "step": 432140
    },
    {
      "epoch": 694.79,
      "learning_rate": 0.03054974790691319,
      "loss": 2.5286,
      "step": 432160
    },
    {
      "epoch": 694.82,
      "learning_rate": 0.03054653247604502,
      "loss": 2.5183,
      "step": 432180
    },
    {
      "epoch": 694.86,
      "learning_rate": 0.03054331704517685,
      "loss": 2.532,
      "step": 432200
    },
    {
      "epoch": 694.89,
      "learning_rate": 0.03054010161430868,
      "loss": 2.4976,
      "step": 432220
    },
    {
      "epoch": 694.92,
      "learning_rate": 0.030536886183440512,
      "loss": 2.5114,
      "step": 432240
    },
    {
      "epoch": 694.95,
      "learning_rate": 0.03053367075257234,
      "loss": 2.5313,
      "step": 432260
    },
    {
      "epoch": 694.98,
      "learning_rate": 0.03053045532170419,
      "loss": 2.5089,
      "step": 432280
    },
    {
      "epoch": 695.0,
      "eval_accuracy": {
        "accuracy": 0.43698981575060253
      },
      "eval_loss": 2.6390573978424072,
      "eval_runtime": 3.2988,
      "eval_samples_per_second": 3899.318,
      "eval_steps_per_second": 60.932,
      "step": 432290
    },
    {
      "epoch": 695.02,
      "learning_rate": 0.030527239890836014,
      "loss": 2.5419,
      "step": 432300
    },
    {
      "epoch": 695.05,
      "learning_rate": 0.030524024459967842,
      "loss": 2.5214,
      "step": 432320
    },
    {
      "epoch": 695.08,
      "learning_rate": 0.030520809029099677,
      "loss": 2.5208,
      "step": 432340
    },
    {
      "epoch": 695.11,
      "learning_rate": 0.03051759359823151,
      "loss": 2.5348,
      "step": 432360
    },
    {
      "epoch": 695.14,
      "learning_rate": 0.03051437816736335,
      "loss": 2.4959,
      "step": 432380
    },
    {
      "epoch": 695.18,
      "learning_rate": 0.03051116273649518,
      "loss": 2.5295,
      "step": 432400
    },
    {
      "epoch": 695.21,
      "learning_rate": 0.03050794730562701,
      "loss": 2.5369,
      "step": 432420
    },
    {
      "epoch": 695.24,
      "learning_rate": 0.030504731874758842,
      "loss": 2.5471,
      "step": 432440
    },
    {
      "epoch": 695.27,
      "learning_rate": 0.03050151644389067,
      "loss": 2.5407,
      "step": 432460
    },
    {
      "epoch": 695.31,
      "learning_rate": 0.030498301013022505,
      "loss": 2.5608,
      "step": 432480
    },
    {
      "epoch": 695.34,
      "learning_rate": 0.030495085582154347,
      "loss": 2.522,
      "step": 432500
    },
    {
      "epoch": 695.37,
      "learning_rate": 0.030491870151286172,
      "loss": 2.5348,
      "step": 432520
    },
    {
      "epoch": 695.4,
      "learning_rate": 0.030488654720418007,
      "loss": 2.526,
      "step": 432540
    },
    {
      "epoch": 695.43,
      "learning_rate": 0.03048543928954984,
      "loss": 2.5342,
      "step": 432560
    },
    {
      "epoch": 695.47,
      "learning_rate": 0.03048222385868167,
      "loss": 2.5187,
      "step": 432580
    },
    {
      "epoch": 695.5,
      "learning_rate": 0.0304790084278135,
      "loss": 2.5271,
      "step": 432600
    },
    {
      "epoch": 695.53,
      "learning_rate": 0.03047579299694534,
      "loss": 2.528,
      "step": 432620
    },
    {
      "epoch": 695.56,
      "learning_rate": 0.030472577566077172,
      "loss": 2.5219,
      "step": 432640
    },
    {
      "epoch": 695.59,
      "learning_rate": 0.030469362135209,
      "loss": 2.509,
      "step": 432660
    },
    {
      "epoch": 695.63,
      "learning_rate": 0.030466146704340835,
      "loss": 2.5091,
      "step": 432680
    },
    {
      "epoch": 695.66,
      "learning_rate": 0.030462931273472667,
      "loss": 2.5348,
      "step": 432700
    },
    {
      "epoch": 695.69,
      "learning_rate": 0.030459715842604502,
      "loss": 2.5311,
      "step": 432720
    },
    {
      "epoch": 695.72,
      "learning_rate": 0.030456500411736337,
      "loss": 2.5222,
      "step": 432740
    },
    {
      "epoch": 695.76,
      "learning_rate": 0.03045328498086817,
      "loss": 2.5134,
      "step": 432760
    },
    {
      "epoch": 695.79,
      "learning_rate": 0.03045006955,
      "loss": 2.5249,
      "step": 432780
    },
    {
      "epoch": 695.82,
      "learning_rate": 0.03044685411913183,
      "loss": 2.5375,
      "step": 432800
    },
    {
      "epoch": 695.85,
      "learning_rate": 0.03044363868826366,
      "loss": 2.5012,
      "step": 432820
    },
    {
      "epoch": 695.88,
      "learning_rate": 0.030440423257395502,
      "loss": 2.5333,
      "step": 432840
    },
    {
      "epoch": 695.92,
      "learning_rate": 0.03043720782652733,
      "loss": 2.5379,
      "step": 432860
    },
    {
      "epoch": 695.95,
      "learning_rate": 0.030433992395659165,
      "loss": 2.5273,
      "step": 432880
    },
    {
      "epoch": 695.98,
      "learning_rate": 0.030430776964790997,
      "loss": 2.5415,
      "step": 432900
    },
    {
      "epoch": 696.0,
      "eval_accuracy": {
        "accuracy": 0.4415766150975667
      },
      "eval_loss": 2.63187837600708,
      "eval_runtime": 3.4956,
      "eval_samples_per_second": 3679.821,
      "eval_steps_per_second": 57.502,
      "step": 432912
    },
    {
      "epoch": 696.01,
      "learning_rate": 0.03042756153392283,
      "loss": 2.5487,
      "step": 432920
    },
    {
      "epoch": 696.05,
      "learning_rate": 0.030424346103054657,
      "loss": 2.5243,
      "step": 432940
    },
    {
      "epoch": 696.08,
      "learning_rate": 0.0304211306721865,
      "loss": 2.5161,
      "step": 432960
    },
    {
      "epoch": 696.11,
      "learning_rate": 0.03041791524131833,
      "loss": 2.5357,
      "step": 432980
    },
    {
      "epoch": 696.14,
      "learning_rate": 0.03041469981045016,
      "loss": 2.529,
      "step": 433000
    },
    {
      "epoch": 696.17,
      "learning_rate": 0.030411484379581993,
      "loss": 2.5124,
      "step": 433020
    },
    {
      "epoch": 696.21,
      "learning_rate": 0.030408268948713818,
      "loss": 2.5229,
      "step": 433040
    },
    {
      "epoch": 696.24,
      "learning_rate": 0.03040505351784566,
      "loss": 2.5137,
      "step": 433060
    },
    {
      "epoch": 696.27,
      "learning_rate": 0.030401838086977495,
      "loss": 2.5131,
      "step": 433080
    },
    {
      "epoch": 696.3,
      "learning_rate": 0.030398622656109327,
      "loss": 2.5253,
      "step": 433100
    },
    {
      "epoch": 696.33,
      "learning_rate": 0.03039540722524116,
      "loss": 2.5426,
      "step": 433120
    },
    {
      "epoch": 696.37,
      "learning_rate": 0.030392191794372986,
      "loss": 2.532,
      "step": 433140
    },
    {
      "epoch": 696.4,
      "learning_rate": 0.030388976363504818,
      "loss": 2.5153,
      "step": 433160
    },
    {
      "epoch": 696.43,
      "learning_rate": 0.03038576093263666,
      "loss": 2.5147,
      "step": 433180
    },
    {
      "epoch": 696.46,
      "learning_rate": 0.030382545501768488,
      "loss": 2.5211,
      "step": 433200
    },
    {
      "epoch": 696.5,
      "learning_rate": 0.030379330070900323,
      "loss": 2.5369,
      "step": 433220
    },
    {
      "epoch": 696.53,
      "learning_rate": 0.030376114640032148,
      "loss": 2.5412,
      "step": 433240
    },
    {
      "epoch": 696.56,
      "learning_rate": 0.030372899209163987,
      "loss": 2.5274,
      "step": 433260
    },
    {
      "epoch": 696.59,
      "learning_rate": 0.030369683778295815,
      "loss": 2.5268,
      "step": 433280
    },
    {
      "epoch": 696.62,
      "learning_rate": 0.030366468347427657,
      "loss": 2.534,
      "step": 433300
    },
    {
      "epoch": 696.66,
      "learning_rate": 0.03036325291655949,
      "loss": 2.5375,
      "step": 433320
    },
    {
      "epoch": 696.69,
      "learning_rate": 0.030360037485691316,
      "loss": 2.5242,
      "step": 433340
    },
    {
      "epoch": 696.72,
      "learning_rate": 0.030356822054823148,
      "loss": 2.5293,
      "step": 433360
    },
    {
      "epoch": 696.75,
      "learning_rate": 0.030353606623954976,
      "loss": 2.5142,
      "step": 433380
    },
    {
      "epoch": 696.78,
      "learning_rate": 0.030350391193086818,
      "loss": 2.5248,
      "step": 433400
    },
    {
      "epoch": 696.82,
      "learning_rate": 0.030347175762218653,
      "loss": 2.543,
      "step": 433420
    },
    {
      "epoch": 696.85,
      "learning_rate": 0.030343960331350485,
      "loss": 2.5225,
      "step": 433440
    },
    {
      "epoch": 696.88,
      "learning_rate": 0.030340744900482317,
      "loss": 2.5266,
      "step": 433460
    },
    {
      "epoch": 696.91,
      "learning_rate": 0.030337529469614145,
      "loss": 2.5276,
      "step": 433480
    },
    {
      "epoch": 696.95,
      "learning_rate": 0.030334314038745976,
      "loss": 2.5506,
      "step": 433500
    },
    {
      "epoch": 696.98,
      "learning_rate": 0.03033109860787782,
      "loss": 2.5303,
      "step": 433520
    },
    {
      "epoch": 697.0,
      "eval_accuracy": {
        "accuracy": 0.43753401228329314
      },
      "eval_loss": 2.6639761924743652,
      "eval_runtime": 3.1213,
      "eval_samples_per_second": 4121.043,
      "eval_steps_per_second": 64.396,
      "step": 433534
    },
    {
      "epoch": 697.01,
      "learning_rate": 0.030327883177009646,
      "loss": 2.5358,
      "step": 433540
    },
    {
      "epoch": 697.04,
      "learning_rate": 0.030324667746141478,
      "loss": 2.5228,
      "step": 433560
    },
    {
      "epoch": 697.07,
      "learning_rate": 0.030321452315273306,
      "loss": 2.5548,
      "step": 433580
    },
    {
      "epoch": 697.11,
      "learning_rate": 0.030318236884405145,
      "loss": 2.5312,
      "step": 433600
    },
    {
      "epoch": 697.14,
      "learning_rate": 0.030315021453536983,
      "loss": 2.5205,
      "step": 433620
    },
    {
      "epoch": 697.17,
      "learning_rate": 0.030311806022668815,
      "loss": 2.5272,
      "step": 433640
    },
    {
      "epoch": 697.2,
      "learning_rate": 0.030308590591800647,
      "loss": 2.5283,
      "step": 433660
    },
    {
      "epoch": 697.23,
      "learning_rate": 0.030305375160932475,
      "loss": 2.5233,
      "step": 433680
    },
    {
      "epoch": 697.27,
      "learning_rate": 0.030302159730064306,
      "loss": 2.5237,
      "step": 433700
    },
    {
      "epoch": 697.3,
      "learning_rate": 0.030298944299196134,
      "loss": 2.5052,
      "step": 433720
    },
    {
      "epoch": 697.33,
      "learning_rate": 0.030295728868327976,
      "loss": 2.5082,
      "step": 433740
    },
    {
      "epoch": 697.36,
      "learning_rate": 0.03029251343745981,
      "loss": 2.5243,
      "step": 433760
    },
    {
      "epoch": 697.4,
      "learning_rate": 0.030289298006591636,
      "loss": 2.5389,
      "step": 433780
    },
    {
      "epoch": 697.43,
      "learning_rate": 0.030286082575723475,
      "loss": 2.5211,
      "step": 433800
    },
    {
      "epoch": 697.46,
      "learning_rate": 0.030282867144855303,
      "loss": 2.5107,
      "step": 433820
    },
    {
      "epoch": 697.49,
      "learning_rate": 0.030279651713987134,
      "loss": 2.5159,
      "step": 433840
    },
    {
      "epoch": 697.52,
      "learning_rate": 0.030276436283118977,
      "loss": 2.5257,
      "step": 433860
    },
    {
      "epoch": 697.56,
      "learning_rate": 0.030273220852250805,
      "loss": 2.5394,
      "step": 433880
    },
    {
      "epoch": 697.59,
      "learning_rate": 0.030270005421382636,
      "loss": 2.5286,
      "step": 433900
    },
    {
      "epoch": 697.62,
      "learning_rate": 0.030266789990514464,
      "loss": 2.5245,
      "step": 433920
    },
    {
      "epoch": 697.65,
      "learning_rate": 0.030263574559646303,
      "loss": 2.4913,
      "step": 433940
    },
    {
      "epoch": 697.68,
      "learning_rate": 0.03026035912877814,
      "loss": 2.5336,
      "step": 433960
    },
    {
      "epoch": 697.72,
      "learning_rate": 0.030257143697909973,
      "loss": 2.5403,
      "step": 433980
    },
    {
      "epoch": 697.75,
      "learning_rate": 0.030253928267041805,
      "loss": 2.5493,
      "step": 434000
    },
    {
      "epoch": 697.78,
      "learning_rate": 0.030250712836173633,
      "loss": 2.5402,
      "step": 434020
    },
    {
      "epoch": 697.81,
      "learning_rate": 0.030247497405305464,
      "loss": 2.5252,
      "step": 434040
    },
    {
      "epoch": 697.85,
      "learning_rate": 0.030244281974437293,
      "loss": 2.5496,
      "step": 434060
    },
    {
      "epoch": 697.88,
      "learning_rate": 0.030241066543569135,
      "loss": 2.5284,
      "step": 434080
    },
    {
      "epoch": 697.91,
      "learning_rate": 0.030237851112700966,
      "loss": 2.5205,
      "step": 434100
    },
    {
      "epoch": 697.94,
      "learning_rate": 0.030234635681832794,
      "loss": 2.5102,
      "step": 434120
    },
    {
      "epoch": 697.97,
      "learning_rate": 0.030231420250964633,
      "loss": 2.5124,
      "step": 434140
    },
    {
      "epoch": 698.0,
      "eval_accuracy": {
        "accuracy": 0.4328694705745161
      },
      "eval_loss": 2.654205322265625,
      "eval_runtime": 2.9925,
      "eval_samples_per_second": 4298.356,
      "eval_steps_per_second": 67.167,
      "step": 434156
    },
    {
      "epoch": 698.01,
      "learning_rate": 0.03022820482009646,
      "loss": 2.539,
      "step": 434160
    },
    {
      "epoch": 698.04,
      "learning_rate": 0.030224989389228286,
      "loss": 2.5321,
      "step": 434180
    },
    {
      "epoch": 698.07,
      "learning_rate": 0.030221773958360135,
      "loss": 2.5231,
      "step": 434200
    },
    {
      "epoch": 698.1,
      "learning_rate": 0.030218558527491963,
      "loss": 2.5301,
      "step": 434220
    },
    {
      "epoch": 698.14,
      "learning_rate": 0.030215343096623794,
      "loss": 2.5008,
      "step": 434240
    },
    {
      "epoch": 698.17,
      "learning_rate": 0.030212127665755623,
      "loss": 2.5291,
      "step": 434260
    },
    {
      "epoch": 698.2,
      "learning_rate": 0.03020891223488746,
      "loss": 2.508,
      "step": 434280
    },
    {
      "epoch": 698.23,
      "learning_rate": 0.0302056968040193,
      "loss": 2.5186,
      "step": 434300
    },
    {
      "epoch": 698.26,
      "learning_rate": 0.030202481373151124,
      "loss": 2.5173,
      "step": 434320
    },
    {
      "epoch": 698.3,
      "learning_rate": 0.030199265942282963,
      "loss": 2.5316,
      "step": 434340
    },
    {
      "epoch": 698.33,
      "learning_rate": 0.03019605051141479,
      "loss": 2.5025,
      "step": 434360
    },
    {
      "epoch": 698.36,
      "learning_rate": 0.030192835080546623,
      "loss": 2.5427,
      "step": 434380
    },
    {
      "epoch": 698.39,
      "learning_rate": 0.03018961964967845,
      "loss": 2.5213,
      "step": 434400
    },
    {
      "epoch": 698.42,
      "learning_rate": 0.030186404218810293,
      "loss": 2.5241,
      "step": 434420
    },
    {
      "epoch": 698.46,
      "learning_rate": 0.030183188787942124,
      "loss": 2.5206,
      "step": 434440
    },
    {
      "epoch": 698.49,
      "learning_rate": 0.030179973357073953,
      "loss": 2.5312,
      "step": 434460
    },
    {
      "epoch": 698.52,
      "learning_rate": 0.03017675792620579,
      "loss": 2.5341,
      "step": 434480
    },
    {
      "epoch": 698.55,
      "learning_rate": 0.030173542495337616,
      "loss": 2.5191,
      "step": 434500
    },
    {
      "epoch": 698.59,
      "learning_rate": 0.030170327064469444,
      "loss": 2.529,
      "step": 434520
    },
    {
      "epoch": 698.62,
      "learning_rate": 0.030167111633601293,
      "loss": 2.5316,
      "step": 434540
    },
    {
      "epoch": 698.65,
      "learning_rate": 0.03016389620273312,
      "loss": 2.511,
      "step": 434560
    },
    {
      "epoch": 698.68,
      "learning_rate": 0.030160680771864953,
      "loss": 2.5244,
      "step": 434580
    },
    {
      "epoch": 698.71,
      "learning_rate": 0.03015746534099678,
      "loss": 2.5305,
      "step": 434600
    },
    {
      "epoch": 698.75,
      "learning_rate": 0.030154249910128612,
      "loss": 2.5234,
      "step": 434620
    },
    {
      "epoch": 698.78,
      "learning_rate": 0.030151034479260454,
      "loss": 2.5508,
      "step": 434640
    },
    {
      "epoch": 698.81,
      "learning_rate": 0.030147819048392283,
      "loss": 2.5321,
      "step": 434660
    },
    {
      "epoch": 698.84,
      "learning_rate": 0.03014460361752412,
      "loss": 2.5361,
      "step": 434680
    },
    {
      "epoch": 698.87,
      "learning_rate": 0.03014138818665595,
      "loss": 2.5386,
      "step": 434700
    },
    {
      "epoch": 698.91,
      "learning_rate": 0.030138172755787774,
      "loss": 2.5125,
      "step": 434720
    },
    {
      "epoch": 698.94,
      "learning_rate": 0.03013495732491961,
      "loss": 2.5301,
      "step": 434740
    },
    {
      "epoch": 698.97,
      "learning_rate": 0.03013174189405145,
      "loss": 2.5524,
      "step": 434760
    },
    {
      "epoch": 699.0,
      "eval_accuracy": {
        "accuracy": 0.4335691518308326
      },
      "eval_loss": 2.6547303199768066,
      "eval_runtime": 3.4786,
      "eval_samples_per_second": 3697.701,
      "eval_steps_per_second": 57.781,
      "step": 434778
    },
    {
      "epoch": 699.0,
      "learning_rate": 0.030128526463183283,
      "loss": 2.5403,
      "step": 434780
    },
    {
      "epoch": 699.04,
      "learning_rate": 0.03012531103231511,
      "loss": 2.5393,
      "step": 434800
    },
    {
      "epoch": 699.07,
      "learning_rate": 0.03012209560144695,
      "loss": 2.5204,
      "step": 434820
    },
    {
      "epoch": 699.1,
      "learning_rate": 0.030118880170578774,
      "loss": 2.5085,
      "step": 434840
    },
    {
      "epoch": 699.13,
      "learning_rate": 0.030115664739710602,
      "loss": 2.5262,
      "step": 434860
    },
    {
      "epoch": 699.16,
      "learning_rate": 0.03011244930884245,
      "loss": 2.5313,
      "step": 434880
    },
    {
      "epoch": 699.2,
      "learning_rate": 0.03010923387797428,
      "loss": 2.5276,
      "step": 434900
    },
    {
      "epoch": 699.23,
      "learning_rate": 0.03010601844710611,
      "loss": 2.5086,
      "step": 434920
    },
    {
      "epoch": 699.26,
      "learning_rate": 0.03010280301623794,
      "loss": 2.5153,
      "step": 434940
    },
    {
      "epoch": 699.29,
      "learning_rate": 0.03009958758536977,
      "loss": 2.5107,
      "step": 434960
    },
    {
      "epoch": 699.32,
      "learning_rate": 0.030096372154501613,
      "loss": 2.5188,
      "step": 434980
    },
    {
      "epoch": 699.36,
      "learning_rate": 0.03009315672363344,
      "loss": 2.5321,
      "step": 435000
    },
    {
      "epoch": 699.39,
      "learning_rate": 0.03008994129276528,
      "loss": 2.5335,
      "step": 435020
    },
    {
      "epoch": 699.42,
      "learning_rate": 0.030086725861897104,
      "loss": 2.5335,
      "step": 435040
    },
    {
      "epoch": 699.45,
      "learning_rate": 0.030083510431028932,
      "loss": 2.5249,
      "step": 435060
    },
    {
      "epoch": 699.49,
      "learning_rate": 0.030080295000160767,
      "loss": 2.5114,
      "step": 435080
    },
    {
      "epoch": 699.52,
      "learning_rate": 0.03007707956929261,
      "loss": 2.5321,
      "step": 435100
    },
    {
      "epoch": 699.55,
      "learning_rate": 0.03007386413842444,
      "loss": 2.5261,
      "step": 435120
    },
    {
      "epoch": 699.58,
      "learning_rate": 0.03007064870755627,
      "loss": 2.5342,
      "step": 435140
    },
    {
      "epoch": 699.61,
      "learning_rate": 0.0300674332766881,
      "loss": 2.5303,
      "step": 435160
    },
    {
      "epoch": 699.65,
      "learning_rate": 0.030064217845819932,
      "loss": 2.5397,
      "step": 435180
    },
    {
      "epoch": 699.68,
      "learning_rate": 0.03006100241495176,
      "loss": 2.5076,
      "step": 435200
    },
    {
      "epoch": 699.71,
      "learning_rate": 0.03005778698408361,
      "loss": 2.5279,
      "step": 435220
    },
    {
      "epoch": 699.74,
      "learning_rate": 0.030054732324758845,
      "loss": 2.522,
      "step": 435240
    },
    {
      "epoch": 699.77,
      "learning_rate": 0.030051516893890674,
      "loss": 2.5247,
      "step": 435260
    },
    {
      "epoch": 699.81,
      "learning_rate": 0.03004830146302251,
      "loss": 2.517,
      "step": 435280
    },
    {
      "epoch": 699.84,
      "learning_rate": 0.03004508603215434,
      "loss": 2.5137,
      "step": 435300
    },
    {
      "epoch": 699.87,
      "learning_rate": 0.030041870601286172,
      "loss": 2.5055,
      "step": 435320
    },
    {
      "epoch": 699.9,
      "learning_rate": 0.030038655170418,
      "loss": 2.532,
      "step": 435340
    },
    {
      "epoch": 699.94,
      "learning_rate": 0.030035439739549842,
      "loss": 2.5349,
      "step": 435360
    },
    {
      "epoch": 699.97,
      "learning_rate": 0.030032224308681674,
      "loss": 2.542,
      "step": 435380
    },
    {
      "epoch": 700.0,
      "learning_rate": 0.030029008877813502,
      "loss": 2.5286,
      "step": 435400
    },
    {
      "epoch": 700.0,
      "eval_accuracy": {
        "accuracy": 0.4352017414289046
      },
      "eval_loss": 2.6388065814971924,
      "eval_runtime": 2.9835,
      "eval_samples_per_second": 4311.408,
      "eval_steps_per_second": 67.371,
      "step": 435400
    },
    {
      "epoch": 700.03,
      "learning_rate": 0.030025793446945337,
      "loss": 2.4968,
      "step": 435420
    },
    {
      "epoch": 700.06,
      "learning_rate": 0.03002257801607716,
      "loss": 2.5075,
      "step": 435440
    },
    {
      "epoch": 700.1,
      "learning_rate": 0.030019362585209004,
      "loss": 2.5171,
      "step": 435460
    },
    {
      "epoch": 700.13,
      "learning_rate": 0.03001614715434084,
      "loss": 2.5232,
      "step": 435480
    },
    {
      "epoch": 700.16,
      "learning_rate": 0.03001293172347267,
      "loss": 2.5266,
      "step": 435500
    },
    {
      "epoch": 700.19,
      "learning_rate": 0.030009716292604502,
      "loss": 2.535,
      "step": 435520
    },
    {
      "epoch": 700.23,
      "learning_rate": 0.03000650086173633,
      "loss": 2.5557,
      "step": 435540
    },
    {
      "epoch": 700.26,
      "learning_rate": 0.03000328543086816,
      "loss": 2.5384,
      "step": 435560
    },
    {
      "epoch": 700.29,
      "learning_rate": 0.030000070000000004,
      "loss": 2.5383,
      "step": 435580
    },
    {
      "epoch": 700.32,
      "learning_rate": 0.029996854569131832,
      "loss": 2.5313,
      "step": 435600
    },
    {
      "epoch": 700.35,
      "learning_rate": 0.029993639138263667,
      "loss": 2.5245,
      "step": 435620
    },
    {
      "epoch": 700.39,
      "learning_rate": 0.0299904237073955,
      "loss": 2.5486,
      "step": 435640
    },
    {
      "epoch": 700.42,
      "learning_rate": 0.02998720827652733,
      "loss": 2.5123,
      "step": 435660
    },
    {
      "epoch": 700.45,
      "learning_rate": 0.029983992845659158,
      "loss": 2.5384,
      "step": 435680
    },
    {
      "epoch": 700.48,
      "learning_rate": 0.029980777414791,
      "loss": 2.5307,
      "step": 435700
    },
    {
      "epoch": 700.51,
      "learning_rate": 0.029977561983922832,
      "loss": 2.5158,
      "step": 435720
    },
    {
      "epoch": 700.55,
      "learning_rate": 0.02997434655305466,
      "loss": 2.5057,
      "step": 435740
    },
    {
      "epoch": 700.58,
      "learning_rate": 0.02997113112218649,
      "loss": 2.5195,
      "step": 435760
    },
    {
      "epoch": 700.61,
      "learning_rate": 0.02996791569131832,
      "loss": 2.5382,
      "step": 435780
    },
    {
      "epoch": 700.64,
      "learning_rate": 0.029964700260450162,
      "loss": 2.5121,
      "step": 435800
    },
    {
      "epoch": 700.68,
      "learning_rate": 0.029961484829581997,
      "loss": 2.5287,
      "step": 435820
    },
    {
      "epoch": 700.71,
      "learning_rate": 0.02995826939871383,
      "loss": 2.5088,
      "step": 435840
    },
    {
      "epoch": 700.74,
      "learning_rate": 0.02995505396784566,
      "loss": 2.5245,
      "step": 435860
    },
    {
      "epoch": 700.77,
      "learning_rate": 0.029951838536977488,
      "loss": 2.5221,
      "step": 435880
    },
    {
      "epoch": 700.8,
      "learning_rate": 0.02994862310610932,
      "loss": 2.539,
      "step": 435900
    },
    {
      "epoch": 700.84,
      "learning_rate": 0.029945407675241162,
      "loss": 2.5223,
      "step": 435920
    },
    {
      "epoch": 700.87,
      "learning_rate": 0.02994219224437299,
      "loss": 2.5105,
      "step": 435940
    },
    {
      "epoch": 700.9,
      "learning_rate": 0.029938976813504825,
      "loss": 2.5113,
      "step": 435960
    },
    {
      "epoch": 700.93,
      "learning_rate": 0.02993576138263665,
      "loss": 2.5179,
      "step": 435980
    },
    {
      "epoch": 700.96,
      "learning_rate": 0.02993254595176849,
      "loss": 2.5307,
      "step": 436000
    },
    {
      "epoch": 701.0,
      "learning_rate": 0.029929330520900316,
      "loss": 2.5299,
      "step": 436020
    },
    {
      "epoch": 701.0,
      "eval_accuracy": {
        "accuracy": 0.43613464977066
      },
      "eval_loss": 2.651468515396118,
      "eval_runtime": 2.931,
      "eval_samples_per_second": 4388.551,
      "eval_steps_per_second": 68.576,
      "step": 436022
    },
    {
      "epoch": 701.03,
      "learning_rate": 0.02992611509003216,
      "loss": 2.5284,
      "step": 436040
    },
    {
      "epoch": 701.06,
      "learning_rate": 0.02992289965916399,
      "loss": 2.5322,
      "step": 436060
    },
    {
      "epoch": 701.09,
      "learning_rate": 0.029919684228295818,
      "loss": 2.4909,
      "step": 436080
    },
    {
      "epoch": 701.13,
      "learning_rate": 0.02991646879742765,
      "loss": 2.5223,
      "step": 436100
    },
    {
      "epoch": 701.16,
      "learning_rate": 0.029913253366559478,
      "loss": 2.5114,
      "step": 436120
    },
    {
      "epoch": 701.19,
      "learning_rate": 0.02991003793569132,
      "loss": 2.5292,
      "step": 436140
    },
    {
      "epoch": 701.22,
      "learning_rate": 0.029906822504823155,
      "loss": 2.5334,
      "step": 436160
    },
    {
      "epoch": 701.25,
      "learning_rate": 0.029903607073954987,
      "loss": 2.5373,
      "step": 436180
    },
    {
      "epoch": 701.29,
      "learning_rate": 0.02990039164308682,
      "loss": 2.5043,
      "step": 436200
    },
    {
      "epoch": 701.32,
      "learning_rate": 0.029897176212218646,
      "loss": 2.5366,
      "step": 436220
    },
    {
      "epoch": 701.35,
      "learning_rate": 0.029893960781350478,
      "loss": 2.5355,
      "step": 436240
    },
    {
      "epoch": 701.38,
      "learning_rate": 0.02989074535048232,
      "loss": 2.5476,
      "step": 436260
    },
    {
      "epoch": 701.41,
      "learning_rate": 0.029887529919614148,
      "loss": 2.5275,
      "step": 436280
    },
    {
      "epoch": 701.45,
      "learning_rate": 0.02988431448874598,
      "loss": 2.5282,
      "step": 436300
    },
    {
      "epoch": 701.48,
      "learning_rate": 0.029881099057877808,
      "loss": 2.5052,
      "step": 436320
    },
    {
      "epoch": 701.51,
      "learning_rate": 0.029877883627009647,
      "loss": 2.5071,
      "step": 436340
    },
    {
      "epoch": 701.54,
      "learning_rate": 0.029874668196141485,
      "loss": 2.5216,
      "step": 436360
    },
    {
      "epoch": 701.58,
      "learning_rate": 0.029871452765273317,
      "loss": 2.5227,
      "step": 436380
    },
    {
      "epoch": 701.61,
      "learning_rate": 0.02986823733440515,
      "loss": 2.4995,
      "step": 436400
    },
    {
      "epoch": 701.64,
      "learning_rate": 0.029865021903536976,
      "loss": 2.513,
      "step": 436420
    },
    {
      "epoch": 701.67,
      "learning_rate": 0.029861806472668808,
      "loss": 2.524,
      "step": 436440
    },
    {
      "epoch": 701.7,
      "learning_rate": 0.029858591041800636,
      "loss": 2.5313,
      "step": 436460
    },
    {
      "epoch": 701.74,
      "learning_rate": 0.029855375610932478,
      "loss": 2.5173,
      "step": 436480
    },
    {
      "epoch": 701.77,
      "learning_rate": 0.029852160180064313,
      "loss": 2.5202,
      "step": 436500
    },
    {
      "epoch": 701.8,
      "learning_rate": 0.029848944749196138,
      "loss": 2.5204,
      "step": 436520
    },
    {
      "epoch": 701.83,
      "learning_rate": 0.029845729318327976,
      "loss": 2.5263,
      "step": 436540
    },
    {
      "epoch": 701.86,
      "learning_rate": 0.029842513887459805,
      "loss": 2.5325,
      "step": 436560
    },
    {
      "epoch": 701.9,
      "learning_rate": 0.029839298456591636,
      "loss": 2.5156,
      "step": 436580
    },
    {
      "epoch": 701.93,
      "learning_rate": 0.029836083025723478,
      "loss": 2.5123,
      "step": 436600
    },
    {
      "epoch": 701.96,
      "learning_rate": 0.029832867594855306,
      "loss": 2.5133,
      "step": 436620
    },
    {
      "epoch": 701.99,
      "learning_rate": 0.029829652163987138,
      "loss": 2.5288,
      "step": 436640
    },
    {
      "epoch": 702.0,
      "eval_accuracy": {
        "accuracy": 0.4400995102231206
      },
      "eval_loss": 2.63087797164917,
      "eval_runtime": 3.0285,
      "eval_samples_per_second": 4247.319,
      "eval_steps_per_second": 66.37,
      "step": 436644
    },
    {
      "epoch": 702.03,
      "learning_rate": 0.029826436733118966,
      "loss": 2.5383,
      "step": 436660
    },
    {
      "epoch": 702.06,
      "learning_rate": 0.029823221302250805,
      "loss": 2.5254,
      "step": 436680
    },
    {
      "epoch": 702.09,
      "learning_rate": 0.029820005871382643,
      "loss": 2.5188,
      "step": 436700
    },
    {
      "epoch": 702.12,
      "learning_rate": 0.029816790440514468,
      "loss": 2.5089,
      "step": 436720
    },
    {
      "epoch": 702.15,
      "learning_rate": 0.029813575009646306,
      "loss": 2.5326,
      "step": 436740
    },
    {
      "epoch": 702.19,
      "learning_rate": 0.029810359578778135,
      "loss": 2.5117,
      "step": 436760
    },
    {
      "epoch": 702.22,
      "learning_rate": 0.029807144147909966,
      "loss": 2.5255,
      "step": 436780
    },
    {
      "epoch": 702.25,
      "learning_rate": 0.029803928717041794,
      "loss": 2.5363,
      "step": 436800
    },
    {
      "epoch": 702.28,
      "learning_rate": 0.029800713286173636,
      "loss": 2.5421,
      "step": 436820
    },
    {
      "epoch": 702.32,
      "learning_rate": 0.029797497855305468,
      "loss": 2.5036,
      "step": 436840
    },
    {
      "epoch": 702.35,
      "learning_rate": 0.029794282424437296,
      "loss": 2.5184,
      "step": 436860
    },
    {
      "epoch": 702.38,
      "learning_rate": 0.029791066993569135,
      "loss": 2.5029,
      "step": 436880
    },
    {
      "epoch": 702.41,
      "learning_rate": 0.029787851562700963,
      "loss": 2.515,
      "step": 436900
    },
    {
      "epoch": 702.44,
      "learning_rate": 0.029784636131832787,
      "loss": 2.5218,
      "step": 436920
    },
    {
      "epoch": 702.48,
      "learning_rate": 0.029781420700964636,
      "loss": 2.5056,
      "step": 436940
    },
    {
      "epoch": 702.51,
      "learning_rate": 0.029778205270096465,
      "loss": 2.5127,
      "step": 436960
    },
    {
      "epoch": 702.54,
      "learning_rate": 0.029774989839228296,
      "loss": 2.5469,
      "step": 436980
    },
    {
      "epoch": 702.57,
      "learning_rate": 0.029771774408360124,
      "loss": 2.5283,
      "step": 437000
    },
    {
      "epoch": 702.6,
      "learning_rate": 0.029768558977491963,
      "loss": 2.506,
      "step": 437020
    },
    {
      "epoch": 702.64,
      "learning_rate": 0.029765343546623798,
      "loss": 2.5126,
      "step": 437040
    },
    {
      "epoch": 702.67,
      "learning_rate": 0.029762128115755626,
      "loss": 2.5368,
      "step": 437060
    },
    {
      "epoch": 702.7,
      "learning_rate": 0.029758912684887465,
      "loss": 2.5384,
      "step": 437080
    },
    {
      "epoch": 702.73,
      "learning_rate": 0.029755697254019293,
      "loss": 2.5209,
      "step": 437100
    },
    {
      "epoch": 702.77,
      "learning_rate": 0.029752481823151124,
      "loss": 2.534,
      "step": 437120
    },
    {
      "epoch": 702.8,
      "learning_rate": 0.029749266392282953,
      "loss": 2.5105,
      "step": 437140
    },
    {
      "epoch": 702.83,
      "learning_rate": 0.029746050961414795,
      "loss": 2.5111,
      "step": 437160
    },
    {
      "epoch": 702.86,
      "learning_rate": 0.029742835530546626,
      "loss": 2.5201,
      "step": 437180
    },
    {
      "epoch": 702.89,
      "learning_rate": 0.029739620099678454,
      "loss": 2.5171,
      "step": 437200
    },
    {
      "epoch": 702.93,
      "learning_rate": 0.029736404668810293,
      "loss": 2.526,
      "step": 437220
    },
    {
      "epoch": 702.96,
      "learning_rate": 0.029733189237942118,
      "loss": 2.5384,
      "step": 437240
    },
    {
      "epoch": 702.99,
      "learning_rate": 0.029729973807073946,
      "loss": 2.5059,
      "step": 437260
    },
    {
      "epoch": 703.0,
      "eval_accuracy": {
        "accuracy": 0.436212392132473
      },
      "eval_loss": 2.651634693145752,
      "eval_runtime": 3.0307,
      "eval_samples_per_second": 4244.202,
      "eval_steps_per_second": 66.321,
      "step": 437266
    },
    {
      "epoch": 703.02,
      "learning_rate": 0.029726758376205795,
      "loss": 2.5366,
      "step": 437280
    },
    {
      "epoch": 703.05,
      "learning_rate": 0.029723542945337623,
      "loss": 2.5266,
      "step": 437300
    },
    {
      "epoch": 703.09,
      "learning_rate": 0.029720327514469454,
      "loss": 2.5085,
      "step": 437320
    },
    {
      "epoch": 703.12,
      "learning_rate": 0.029717112083601283,
      "loss": 2.5335,
      "step": 437340
    },
    {
      "epoch": 703.15,
      "learning_rate": 0.029713896652733114,
      "loss": 2.5193,
      "step": 437360
    },
    {
      "epoch": 703.18,
      "learning_rate": 0.029710681221864956,
      "loss": 2.5216,
      "step": 437380
    },
    {
      "epoch": 703.22,
      "learning_rate": 0.029707465790996784,
      "loss": 2.5244,
      "step": 437400
    },
    {
      "epoch": 703.25,
      "learning_rate": 0.029704250360128623,
      "loss": 2.5209,
      "step": 437420
    },
    {
      "epoch": 703.28,
      "learning_rate": 0.02970103492926045,
      "loss": 2.5156,
      "step": 437440
    },
    {
      "epoch": 703.31,
      "learning_rate": 0.029697819498392276,
      "loss": 2.516,
      "step": 437460
    },
    {
      "epoch": 703.34,
      "learning_rate": 0.02969460406752411,
      "loss": 2.5109,
      "step": 437480
    },
    {
      "epoch": 703.38,
      "learning_rate": 0.029691388636655953,
      "loss": 2.549,
      "step": 437500
    },
    {
      "epoch": 703.41,
      "learning_rate": 0.029688173205787784,
      "loss": 2.5346,
      "step": 437520
    },
    {
      "epoch": 703.44,
      "learning_rate": 0.029684957774919613,
      "loss": 2.5035,
      "step": 437540
    },
    {
      "epoch": 703.47,
      "learning_rate": 0.029681742344051444,
      "loss": 2.5069,
      "step": 437560
    },
    {
      "epoch": 703.5,
      "learning_rate": 0.029678526913183276,
      "loss": 2.5089,
      "step": 437580
    },
    {
      "epoch": 703.54,
      "learning_rate": 0.029675311482315104,
      "loss": 2.5314,
      "step": 437600
    },
    {
      "epoch": 703.57,
      "learning_rate": 0.029672096051446953,
      "loss": 2.5393,
      "step": 437620
    },
    {
      "epoch": 703.6,
      "learning_rate": 0.02966888062057878,
      "loss": 2.5226,
      "step": 437640
    },
    {
      "epoch": 703.63,
      "learning_rate": 0.029665665189710613,
      "loss": 2.5139,
      "step": 437660
    },
    {
      "epoch": 703.67,
      "learning_rate": 0.02966244975884244,
      "loss": 2.5124,
      "step": 437680
    },
    {
      "epoch": 703.7,
      "learning_rate": 0.029659234327974272,
      "loss": 2.546,
      "step": 437700
    },
    {
      "epoch": 703.73,
      "learning_rate": 0.029656018897106114,
      "loss": 2.517,
      "step": 437720
    },
    {
      "epoch": 703.76,
      "learning_rate": 0.029652803466237942,
      "loss": 2.5236,
      "step": 437740
    },
    {
      "epoch": 703.79,
      "learning_rate": 0.02964958803536978,
      "loss": 2.5414,
      "step": 437760
    },
    {
      "epoch": 703.83,
      "learning_rate": 0.029646372604501606,
      "loss": 2.5308,
      "step": 437780
    },
    {
      "epoch": 703.86,
      "learning_rate": 0.029643157173633434,
      "loss": 2.5231,
      "step": 437800
    },
    {
      "epoch": 703.89,
      "learning_rate": 0.02963994174276527,
      "loss": 2.5232,
      "step": 437820
    },
    {
      "epoch": 703.92,
      "learning_rate": 0.02963672631189711,
      "loss": 2.5138,
      "step": 437840
    },
    {
      "epoch": 703.95,
      "learning_rate": 0.029633510881028943,
      "loss": 2.5309,
      "step": 437860
    },
    {
      "epoch": 703.99,
      "learning_rate": 0.02963029545016077,
      "loss": 2.5031,
      "step": 437880
    },
    {
      "epoch": 704.0,
      "eval_accuracy": {
        "accuracy": 0.42991526082562387
      },
      "eval_loss": 2.6666359901428223,
      "eval_runtime": 3.0411,
      "eval_samples_per_second": 4229.731,
      "eval_steps_per_second": 66.095,
      "step": 437888
    },
    {
      "epoch": 704.02,
      "learning_rate": 0.029627080019292602,
      "loss": 2.5305,
      "step": 437900
    },
    {
      "epoch": 704.05,
      "learning_rate": 0.029623864588424434,
      "loss": 2.5277,
      "step": 437920
    },
    {
      "epoch": 704.08,
      "learning_rate": 0.029620649157556262,
      "loss": 2.5295,
      "step": 437940
    },
    {
      "epoch": 704.12,
      "learning_rate": 0.02961743372668811,
      "loss": 2.5007,
      "step": 437960
    },
    {
      "epoch": 704.15,
      "learning_rate": 0.02961421829581994,
      "loss": 2.521,
      "step": 437980
    },
    {
      "epoch": 704.18,
      "learning_rate": 0.029611002864951764,
      "loss": 2.5343,
      "step": 438000
    },
    {
      "epoch": 704.21,
      "learning_rate": 0.0296077874340836,
      "loss": 2.5158,
      "step": 438020
    },
    {
      "epoch": 704.24,
      "learning_rate": 0.02960457200321543,
      "loss": 2.5196,
      "step": 438040
    },
    {
      "epoch": 704.28,
      "learning_rate": 0.029601356572347273,
      "loss": 2.5163,
      "step": 438060
    },
    {
      "epoch": 704.31,
      "learning_rate": 0.0295981411414791,
      "loss": 2.5171,
      "step": 438080
    },
    {
      "epoch": 704.34,
      "learning_rate": 0.029594925710610932,
      "loss": 2.5214,
      "step": 438100
    },
    {
      "epoch": 704.37,
      "learning_rate": 0.029591710279742764,
      "loss": 2.5347,
      "step": 438120
    },
    {
      "epoch": 704.41,
      "learning_rate": 0.029588494848874592,
      "loss": 2.5001,
      "step": 438140
    },
    {
      "epoch": 704.44,
      "learning_rate": 0.029585279418006427,
      "loss": 2.5116,
      "step": 438160
    },
    {
      "epoch": 704.47,
      "learning_rate": 0.02958206398713827,
      "loss": 2.4989,
      "step": 438180
    },
    {
      "epoch": 704.5,
      "learning_rate": 0.029578848556270094,
      "loss": 2.521,
      "step": 438200
    },
    {
      "epoch": 704.53,
      "learning_rate": 0.02957563312540193,
      "loss": 2.5027,
      "step": 438220
    },
    {
      "epoch": 704.57,
      "learning_rate": 0.02957241769453376,
      "loss": 2.5095,
      "step": 438240
    },
    {
      "epoch": 704.6,
      "learning_rate": 0.029569202263665592,
      "loss": 2.5191,
      "step": 438260
    },
    {
      "epoch": 704.63,
      "learning_rate": 0.02956598683279743,
      "loss": 2.5026,
      "step": 438280
    },
    {
      "epoch": 704.66,
      "learning_rate": 0.02956277140192927,
      "loss": 2.5056,
      "step": 438300
    },
    {
      "epoch": 704.69,
      "learning_rate": 0.029559555971061094,
      "loss": 2.5266,
      "step": 438320
    },
    {
      "epoch": 704.73,
      "learning_rate": 0.029556340540192922,
      "loss": 2.5198,
      "step": 438340
    },
    {
      "epoch": 704.76,
      "learning_rate": 0.029553125109324757,
      "loss": 2.4896,
      "step": 438360
    },
    {
      "epoch": 704.79,
      "learning_rate": 0.02954990967845659,
      "loss": 2.5347,
      "step": 438380
    },
    {
      "epoch": 704.82,
      "learning_rate": 0.02954669424758843,
      "loss": 2.5153,
      "step": 438400
    },
    {
      "epoch": 704.86,
      "learning_rate": 0.02954347881672026,
      "loss": 2.5285,
      "step": 438420
    },
    {
      "epoch": 704.89,
      "learning_rate": 0.02954026338585209,
      "loss": 2.5356,
      "step": 438440
    },
    {
      "epoch": 704.92,
      "learning_rate": 0.029537047954983922,
      "loss": 2.5086,
      "step": 438460
    },
    {
      "epoch": 704.95,
      "learning_rate": 0.02953383252411575,
      "loss": 2.5352,
      "step": 438480
    },
    {
      "epoch": 704.98,
      "learning_rate": 0.029530617093247582,
      "loss": 2.5408,
      "step": 438500
    },
    {
      "epoch": 705.0,
      "eval_accuracy": {
        "accuracy": 0.43706755811241543
      },
      "eval_loss": 2.6367995738983154,
      "eval_runtime": 3.3672,
      "eval_samples_per_second": 3820.108,
      "eval_steps_per_second": 59.694,
      "step": 438510
    },
    {
      "epoch": 705.02,
      "learning_rate": 0.029527401662379424,
      "loss": 2.5478,
      "step": 438520
    },
    {
      "epoch": 705.05,
      "learning_rate": 0.029524186231511252,
      "loss": 2.5163,
      "step": 438540
    },
    {
      "epoch": 705.08,
      "learning_rate": 0.029520970800643087,
      "loss": 2.5086,
      "step": 438560
    },
    {
      "epoch": 705.11,
      "learning_rate": 0.02951775536977492,
      "loss": 2.523,
      "step": 438580
    },
    {
      "epoch": 705.14,
      "learning_rate": 0.02951453993890675,
      "loss": 2.5162,
      "step": 438600
    },
    {
      "epoch": 705.18,
      "learning_rate": 0.02951132450803859,
      "loss": 2.5196,
      "step": 438620
    },
    {
      "epoch": 705.21,
      "learning_rate": 0.02950810907717042,
      "loss": 2.524,
      "step": 438640
    },
    {
      "epoch": 705.24,
      "learning_rate": 0.029504893646302252,
      "loss": 2.511,
      "step": 438660
    },
    {
      "epoch": 705.27,
      "learning_rate": 0.02950167821543408,
      "loss": 2.5199,
      "step": 438680
    },
    {
      "epoch": 705.31,
      "learning_rate": 0.029498462784565915,
      "loss": 2.5269,
      "step": 438700
    },
    {
      "epoch": 705.34,
      "learning_rate": 0.02949524735369774,
      "loss": 2.5306,
      "step": 438720
    },
    {
      "epoch": 705.37,
      "learning_rate": 0.029492031922829582,
      "loss": 2.5008,
      "step": 438740
    },
    {
      "epoch": 705.4,
      "learning_rate": 0.029488816491961417,
      "loss": 2.517,
      "step": 438760
    },
    {
      "epoch": 705.43,
      "learning_rate": 0.02948560106109325,
      "loss": 2.5067,
      "step": 438780
    },
    {
      "epoch": 705.47,
      "learning_rate": 0.02948238563022508,
      "loss": 2.5182,
      "step": 438800
    },
    {
      "epoch": 705.5,
      "learning_rate": 0.02947917019935691,
      "loss": 2.5207,
      "step": 438820
    },
    {
      "epoch": 705.53,
      "learning_rate": 0.02947595476848874,
      "loss": 2.5203,
      "step": 438840
    },
    {
      "epoch": 705.56,
      "learning_rate": 0.029472739337620582,
      "loss": 2.5232,
      "step": 438860
    },
    {
      "epoch": 705.59,
      "learning_rate": 0.02946952390675241,
      "loss": 2.5199,
      "step": 438880
    },
    {
      "epoch": 705.63,
      "learning_rate": 0.029466308475884245,
      "loss": 2.5162,
      "step": 438900
    },
    {
      "epoch": 705.66,
      "learning_rate": 0.029463093045016077,
      "loss": 2.5084,
      "step": 438920
    },
    {
      "epoch": 705.69,
      "learning_rate": 0.02945987761414791,
      "loss": 2.5299,
      "step": 438940
    },
    {
      "epoch": 705.72,
      "learning_rate": 0.029456662183279747,
      "loss": 2.5049,
      "step": 438960
    },
    {
      "epoch": 705.76,
      "learning_rate": 0.02945344675241158,
      "loss": 2.533,
      "step": 438980
    },
    {
      "epoch": 705.79,
      "learning_rate": 0.02945023132154341,
      "loss": 2.5194,
      "step": 439000
    },
    {
      "epoch": 705.82,
      "learning_rate": 0.02944701589067524,
      "loss": 2.5072,
      "step": 439020
    },
    {
      "epoch": 705.85,
      "learning_rate": 0.02944380045980707,
      "loss": 2.5226,
      "step": 439040
    },
    {
      "epoch": 705.88,
      "learning_rate": 0.029440585028938898,
      "loss": 2.5261,
      "step": 439060
    },
    {
      "epoch": 705.92,
      "learning_rate": 0.02943736959807074,
      "loss": 2.5055,
      "step": 439080
    },
    {
      "epoch": 705.95,
      "learning_rate": 0.029434154167202575,
      "loss": 2.5208,
      "step": 439100
    },
    {
      "epoch": 705.98,
      "learning_rate": 0.029430938736334407,
      "loss": 2.494,
      "step": 439120
    },
    {
      "epoch": 706.0,
      "eval_accuracy": {
        "accuracy": 0.4392443442431781
      },
      "eval_loss": 2.629641532897949,
      "eval_runtime": 3.7012,
      "eval_samples_per_second": 3475.323,
      "eval_steps_per_second": 54.306,
      "step": 439132
    },
    {
      "epoch": 706.01,
      "learning_rate": 0.02942772330546624,
      "loss": 2.5262,
      "step": 439140
    },
    {
      "epoch": 706.05,
      "learning_rate": 0.029424507874598067,
      "loss": 2.5181,
      "step": 439160
    },
    {
      "epoch": 706.08,
      "learning_rate": 0.029421292443729898,
      "loss": 2.5249,
      "step": 439180
    },
    {
      "epoch": 706.11,
      "learning_rate": 0.02941807701286174,
      "loss": 2.5113,
      "step": 439200
    },
    {
      "epoch": 706.14,
      "learning_rate": 0.02941486158199357,
      "loss": 2.531,
      "step": 439220
    },
    {
      "epoch": 706.17,
      "learning_rate": 0.02941180692266881,
      "loss": 2.5147,
      "step": 439240
    },
    {
      "epoch": 706.21,
      "learning_rate": 0.02940859149180064,
      "loss": 2.5116,
      "step": 439260
    },
    {
      "epoch": 706.24,
      "learning_rate": 0.029405376060932478,
      "loss": 2.5327,
      "step": 439280
    },
    {
      "epoch": 706.27,
      "learning_rate": 0.029402160630064306,
      "loss": 2.5053,
      "step": 439300
    },
    {
      "epoch": 706.3,
      "learning_rate": 0.029398945199196138,
      "loss": 2.5132,
      "step": 439320
    },
    {
      "epoch": 706.33,
      "learning_rate": 0.02939572976832798,
      "loss": 2.5324,
      "step": 439340
    },
    {
      "epoch": 706.37,
      "learning_rate": 0.029392514337459808,
      "loss": 2.5096,
      "step": 439360
    },
    {
      "epoch": 706.4,
      "learning_rate": 0.02938929890659164,
      "loss": 2.5053,
      "step": 439380
    },
    {
      "epoch": 706.43,
      "learning_rate": 0.029386083475723468,
      "loss": 2.5237,
      "step": 439400
    },
    {
      "epoch": 706.46,
      "learning_rate": 0.029382868044855306,
      "loss": 2.5227,
      "step": 439420
    },
    {
      "epoch": 706.5,
      "learning_rate": 0.029379652613987145,
      "loss": 2.5194,
      "step": 439440
    },
    {
      "epoch": 706.53,
      "learning_rate": 0.02937643718311897,
      "loss": 2.5234,
      "step": 439460
    },
    {
      "epoch": 706.56,
      "learning_rate": 0.029373221752250808,
      "loss": 2.5181,
      "step": 439480
    },
    {
      "epoch": 706.59,
      "learning_rate": 0.029370006321382636,
      "loss": 2.5257,
      "step": 439500
    },
    {
      "epoch": 706.62,
      "learning_rate": 0.029366790890514468,
      "loss": 2.5103,
      "step": 439520
    },
    {
      "epoch": 706.66,
      "learning_rate": 0.029363575459646296,
      "loss": 2.5039,
      "step": 439540
    },
    {
      "epoch": 706.69,
      "learning_rate": 0.029360360028778138,
      "loss": 2.5072,
      "step": 439560
    },
    {
      "epoch": 706.72,
      "learning_rate": 0.02935714459790997,
      "loss": 2.5385,
      "step": 439580
    },
    {
      "epoch": 706.75,
      "learning_rate": 0.029353929167041798,
      "loss": 2.5328,
      "step": 439600
    },
    {
      "epoch": 706.78,
      "learning_rate": 0.029350713736173636,
      "loss": 2.5202,
      "step": 439620
    },
    {
      "epoch": 706.82,
      "learning_rate": 0.029347498305305465,
      "loss": 2.5085,
      "step": 439640
    },
    {
      "epoch": 706.85,
      "learning_rate": 0.02934428287443729,
      "loss": 2.5452,
      "step": 439660
    },
    {
      "epoch": 706.88,
      "learning_rate": 0.029341067443569138,
      "loss": 2.53,
      "step": 439680
    },
    {
      "epoch": 706.91,
      "learning_rate": 0.029337852012700966,
      "loss": 2.5095,
      "step": 439700
    },
    {
      "epoch": 706.95,
      "learning_rate": 0.029334636581832798,
      "loss": 2.4988,
      "step": 439720
    },
    {
      "epoch": 706.98,
      "learning_rate": 0.029331421150964626,
      "loss": 2.5177,
      "step": 439740
    },
    {
      "epoch": 707.0,
      "eval_accuracy": {
        "accuracy": 0.43465754489621394
      },
      "eval_loss": 2.642394781112671,
      "eval_runtime": 3.336,
      "eval_samples_per_second": 3855.783,
      "eval_steps_per_second": 60.251,
      "step": 439754
    },
    {
      "epoch": 707.01,
      "learning_rate": 0.029328205720096458,
      "loss": 2.5074,
      "step": 439760
    },
    {
      "epoch": 707.04,
      "learning_rate": 0.0293249902892283,
      "loss": 2.4899,
      "step": 439780
    },
    {
      "epoch": 707.07,
      "learning_rate": 0.029321774858360128,
      "loss": 2.5131,
      "step": 439800
    },
    {
      "epoch": 707.11,
      "learning_rate": 0.029318559427491966,
      "loss": 2.508,
      "step": 439820
    },
    {
      "epoch": 707.14,
      "learning_rate": 0.029315343996623795,
      "loss": 2.5207,
      "step": 439840
    },
    {
      "epoch": 707.17,
      "learning_rate": 0.029312128565755626,
      "loss": 2.5269,
      "step": 439860
    },
    {
      "epoch": 707.2,
      "learning_rate": 0.029308913134887454,
      "loss": 2.5341,
      "step": 439880
    },
    {
      "epoch": 707.23,
      "learning_rate": 0.029305697704019296,
      "loss": 2.5021,
      "step": 439900
    },
    {
      "epoch": 707.27,
      "learning_rate": 0.029302482273151128,
      "loss": 2.5209,
      "step": 439920
    },
    {
      "epoch": 707.3,
      "learning_rate": 0.029299266842282956,
      "loss": 2.5353,
      "step": 439940
    },
    {
      "epoch": 707.33,
      "learning_rate": 0.029296051411414795,
      "loss": 2.5069,
      "step": 439960
    },
    {
      "epoch": 707.36,
      "learning_rate": 0.02929283598054662,
      "loss": 2.5106,
      "step": 439980
    },
    {
      "epoch": 707.4,
      "learning_rate": 0.029289620549678447,
      "loss": 2.5001,
      "step": 440000
    },
    {
      "epoch": 707.43,
      "learning_rate": 0.029286405118810296,
      "loss": 2.5227,
      "step": 440020
    },
    {
      "epoch": 707.46,
      "learning_rate": 0.029283189687942125,
      "loss": 2.4929,
      "step": 440040
    },
    {
      "epoch": 707.49,
      "learning_rate": 0.029279974257073956,
      "loss": 2.5243,
      "step": 440060
    },
    {
      "epoch": 707.52,
      "learning_rate": 0.029276758826205784,
      "loss": 2.5289,
      "step": 440080
    },
    {
      "epoch": 707.56,
      "learning_rate": 0.029273543395337616,
      "loss": 2.5242,
      "step": 440100
    },
    {
      "epoch": 707.59,
      "learning_rate": 0.029270327964469458,
      "loss": 2.5279,
      "step": 440120
    },
    {
      "epoch": 707.62,
      "learning_rate": 0.029267112533601286,
      "loss": 2.5228,
      "step": 440140
    },
    {
      "epoch": 707.65,
      "learning_rate": 0.029263897102733125,
      "loss": 2.523,
      "step": 440160
    },
    {
      "epoch": 707.68,
      "learning_rate": 0.029260681671864953,
      "loss": 2.5474,
      "step": 440180
    },
    {
      "epoch": 707.72,
      "learning_rate": 0.029257466240996777,
      "loss": 2.5249,
      "step": 440200
    },
    {
      "epoch": 707.75,
      "learning_rate": 0.029254250810128613,
      "loss": 2.502,
      "step": 440220
    },
    {
      "epoch": 707.78,
      "learning_rate": 0.029251035379260455,
      "loss": 2.5386,
      "step": 440240
    },
    {
      "epoch": 707.81,
      "learning_rate": 0.029247819948392286,
      "loss": 2.5428,
      "step": 440260
    },
    {
      "epoch": 707.85,
      "learning_rate": 0.029244604517524114,
      "loss": 2.5,
      "step": 440280
    },
    {
      "epoch": 707.88,
      "learning_rate": 0.029241389086655946,
      "loss": 2.5099,
      "step": 440300
    },
    {
      "epoch": 707.91,
      "learning_rate": 0.029238173655787777,
      "loss": 2.4934,
      "step": 440320
    },
    {
      "epoch": 707.94,
      "learning_rate": 0.029234958224919606,
      "loss": 2.5326,
      "step": 440340
    },
    {
      "epoch": 707.97,
      "learning_rate": 0.029231742794051455,
      "loss": 2.5167,
      "step": 440360
    },
    {
      "epoch": 708.0,
      "eval_accuracy": {
        "accuracy": 0.43963305605224284
      },
      "eval_loss": 2.6415462493896484,
      "eval_runtime": 4.2709,
      "eval_samples_per_second": 3011.747,
      "eval_steps_per_second": 47.062,
      "step": 440376
    },
    {
      "epoch": 708.01,
      "learning_rate": 0.029228527363183283,
      "loss": 2.5153,
      "step": 440380
    },
    {
      "epoch": 708.04,
      "learning_rate": 0.029225311932315107,
      "loss": 2.5216,
      "step": 440400
    },
    {
      "epoch": 708.07,
      "learning_rate": 0.029222096501446942,
      "loss": 2.5167,
      "step": 440420
    },
    {
      "epoch": 708.1,
      "learning_rate": 0.029218881070578774,
      "loss": 2.5118,
      "step": 440440
    },
    {
      "epoch": 708.14,
      "learning_rate": 0.029215665639710616,
      "loss": 2.5212,
      "step": 440460
    },
    {
      "epoch": 708.17,
      "learning_rate": 0.029212450208842444,
      "loss": 2.5114,
      "step": 440480
    },
    {
      "epoch": 708.2,
      "learning_rate": 0.029209234777974283,
      "loss": 2.4985,
      "step": 440500
    },
    {
      "epoch": 708.23,
      "learning_rate": 0.029206019347106107,
      "loss": 2.5278,
      "step": 440520
    },
    {
      "epoch": 708.26,
      "learning_rate": 0.029202803916237936,
      "loss": 2.5135,
      "step": 440540
    },
    {
      "epoch": 708.3,
      "learning_rate": 0.02919958848536977,
      "loss": 2.5261,
      "step": 440560
    },
    {
      "epoch": 708.33,
      "learning_rate": 0.029196373054501613,
      "loss": 2.5151,
      "step": 440580
    },
    {
      "epoch": 708.36,
      "learning_rate": 0.029193157623633444,
      "loss": 2.5541,
      "step": 440600
    },
    {
      "epoch": 708.39,
      "learning_rate": 0.029189942192765272,
      "loss": 2.5189,
      "step": 440620
    },
    {
      "epoch": 708.42,
      "learning_rate": 0.029186726761897104,
      "loss": 2.5111,
      "step": 440640
    },
    {
      "epoch": 708.46,
      "learning_rate": 0.029183511331028936,
      "loss": 2.5174,
      "step": 440660
    },
    {
      "epoch": 708.49,
      "learning_rate": 0.029180295900160774,
      "loss": 2.5052,
      "step": 440680
    },
    {
      "epoch": 708.52,
      "learning_rate": 0.029177080469292613,
      "loss": 2.5293,
      "step": 440700
    },
    {
      "epoch": 708.55,
      "learning_rate": 0.029173865038424437,
      "loss": 2.5181,
      "step": 440720
    },
    {
      "epoch": 708.59,
      "learning_rate": 0.029170649607556266,
      "loss": 2.5181,
      "step": 440740
    },
    {
      "epoch": 708.62,
      "learning_rate": 0.0291674341766881,
      "loss": 2.5326,
      "step": 440760
    },
    {
      "epoch": 708.65,
      "learning_rate": 0.029164218745819932,
      "loss": 2.4923,
      "step": 440780
    },
    {
      "epoch": 708.68,
      "learning_rate": 0.029161003314951774,
      "loss": 2.5286,
      "step": 440800
    },
    {
      "epoch": 708.71,
      "learning_rate": 0.029157787884083602,
      "loss": 2.5238,
      "step": 440820
    },
    {
      "epoch": 708.75,
      "learning_rate": 0.029154572453215434,
      "loss": 2.4891,
      "step": 440840
    },
    {
      "epoch": 708.78,
      "learning_rate": 0.029151357022347266,
      "loss": 2.5437,
      "step": 440860
    },
    {
      "epoch": 708.81,
      "learning_rate": 0.029148141591479094,
      "loss": 2.5169,
      "step": 440880
    },
    {
      "epoch": 708.84,
      "learning_rate": 0.02914492616061093,
      "loss": 2.5173,
      "step": 440900
    },
    {
      "epoch": 708.87,
      "learning_rate": 0.02914171072974277,
      "loss": 2.5163,
      "step": 440920
    },
    {
      "epoch": 708.91,
      "learning_rate": 0.029138495298874596,
      "loss": 2.5056,
      "step": 440940
    },
    {
      "epoch": 708.94,
      "learning_rate": 0.02913527986800643,
      "loss": 2.5017,
      "step": 440960
    },
    {
      "epoch": 708.97,
      "learning_rate": 0.029132064437138262,
      "loss": 2.5086,
      "step": 440980
    },
    {
      "epoch": 709.0,
      "eval_accuracy": {
        "accuracy": 0.4390111171577393
      },
      "eval_loss": 2.6267120838165283,
      "eval_runtime": 3.1513,
      "eval_samples_per_second": 4081.746,
      "eval_steps_per_second": 63.782,
      "step": 440998
    },
    {
      "epoch": 709.0,
      "learning_rate": 0.029128849006270094,
      "loss": 2.5086,
      "step": 441000
    },
    {
      "epoch": 709.04,
      "learning_rate": 0.029125633575401932,
      "loss": 2.5052,
      "step": 441020
    },
    {
      "epoch": 709.07,
      "learning_rate": 0.029122418144533764,
      "loss": 2.5256,
      "step": 441040
    },
    {
      "epoch": 709.1,
      "learning_rate": 0.029119202713665596,
      "loss": 2.498,
      "step": 441060
    },
    {
      "epoch": 709.13,
      "learning_rate": 0.029115987282797424,
      "loss": 2.526,
      "step": 441080
    },
    {
      "epoch": 709.16,
      "learning_rate": 0.02911277185192926,
      "loss": 2.5193,
      "step": 441100
    },
    {
      "epoch": 709.2,
      "learning_rate": 0.02910955642106109,
      "loss": 2.5327,
      "step": 441120
    },
    {
      "epoch": 709.23,
      "learning_rate": 0.029106340990192932,
      "loss": 2.5092,
      "step": 441140
    },
    {
      "epoch": 709.26,
      "learning_rate": 0.02910312555932476,
      "loss": 2.5278,
      "step": 441160
    },
    {
      "epoch": 709.29,
      "learning_rate": 0.029099910128456592,
      "loss": 2.5378,
      "step": 441180
    },
    {
      "epoch": 709.32,
      "learning_rate": 0.029096694697588424,
      "loss": 2.5239,
      "step": 441200
    },
    {
      "epoch": 709.36,
      "learning_rate": 0.029093479266720252,
      "loss": 2.5356,
      "step": 441220
    },
    {
      "epoch": 709.39,
      "learning_rate": 0.029090424607395495,
      "loss": 2.5082,
      "step": 441240
    },
    {
      "epoch": 709.42,
      "learning_rate": 0.029087209176527323,
      "loss": 2.5094,
      "step": 441260
    },
    {
      "epoch": 709.45,
      "learning_rate": 0.029083993745659165,
      "loss": 2.5003,
      "step": 441280
    },
    {
      "epoch": 709.49,
      "learning_rate": 0.029080778314791,
      "loss": 2.5156,
      "step": 441300
    },
    {
      "epoch": 709.52,
      "learning_rate": 0.029077562883922832,
      "loss": 2.5145,
      "step": 441320
    },
    {
      "epoch": 709.55,
      "learning_rate": 0.029074347453054664,
      "loss": 2.5067,
      "step": 441340
    },
    {
      "epoch": 709.58,
      "learning_rate": 0.029071132022186492,
      "loss": 2.4978,
      "step": 441360
    },
    {
      "epoch": 709.61,
      "learning_rate": 0.029067916591318323,
      "loss": 2.5139,
      "step": 441380
    },
    {
      "epoch": 709.65,
      "learning_rate": 0.029064701160450165,
      "loss": 2.5038,
      "step": 441400
    },
    {
      "epoch": 709.68,
      "learning_rate": 0.029061485729581994,
      "loss": 2.5209,
      "step": 441420
    },
    {
      "epoch": 709.71,
      "learning_rate": 0.029058270298713825,
      "loss": 2.5336,
      "step": 441440
    },
    {
      "epoch": 709.74,
      "learning_rate": 0.029055215639389065,
      "loss": 2.5451,
      "step": 441460
    },
    {
      "epoch": 709.77,
      "learning_rate": 0.029052000208520903,
      "loss": 2.4899,
      "step": 441480
    },
    {
      "epoch": 709.81,
      "learning_rate": 0.02904878477765273,
      "loss": 2.5089,
      "step": 441500
    },
    {
      "epoch": 709.84,
      "learning_rate": 0.029045569346784563,
      "loss": 2.5025,
      "step": 441520
    },
    {
      "epoch": 709.87,
      "learning_rate": 0.029042353915916405,
      "loss": 2.5104,
      "step": 441540
    },
    {
      "epoch": 709.9,
      "learning_rate": 0.029039138485048233,
      "loss": 2.5398,
      "step": 441560
    },
    {
      "epoch": 709.94,
      "learning_rate": 0.029035923054180065,
      "loss": 2.5383,
      "step": 441580
    },
    {
      "epoch": 709.97,
      "learning_rate": 0.029032707623311893,
      "loss": 2.5094,
      "step": 441600
    },
    {
      "epoch": 710.0,
      "learning_rate": 0.02902949219244373,
      "loss": 2.5284,
      "step": 441620
    },
    {
      "epoch": 710.0,
      "eval_accuracy": {
        "accuracy": 0.4384669206250486
      },
      "eval_loss": 2.6460323333740234,
      "eval_runtime": 3.0388,
      "eval_samples_per_second": 4232.859,
      "eval_steps_per_second": 66.144,
      "step": 441620
    },
    {
      "epoch": 710.03,
      "learning_rate": 0.029026276761575556,
      "loss": 2.5314,
      "step": 441640
    },
    {
      "epoch": 710.06,
      "learning_rate": 0.029023061330707395,
      "loss": 2.5101,
      "step": 441660
    },
    {
      "epoch": 710.1,
      "learning_rate": 0.029019845899839233,
      "loss": 2.5136,
      "step": 441680
    },
    {
      "epoch": 710.13,
      "learning_rate": 0.02901663046897106,
      "loss": 2.4983,
      "step": 441700
    },
    {
      "epoch": 710.16,
      "learning_rate": 0.029013415038102893,
      "loss": 2.5195,
      "step": 441720
    },
    {
      "epoch": 710.19,
      "learning_rate": 0.02901019960723472,
      "loss": 2.5157,
      "step": 441740
    },
    {
      "epoch": 710.23,
      "learning_rate": 0.029006984176366563,
      "loss": 2.521,
      "step": 441760
    },
    {
      "epoch": 710.26,
      "learning_rate": 0.029003768745498395,
      "loss": 2.5065,
      "step": 441780
    },
    {
      "epoch": 710.29,
      "learning_rate": 0.029000553314630223,
      "loss": 2.5081,
      "step": 441800
    },
    {
      "epoch": 710.32,
      "learning_rate": 0.02899733788376206,
      "loss": 2.5134,
      "step": 441820
    },
    {
      "epoch": 710.35,
      "learning_rate": 0.02899412245289389,
      "loss": 2.5288,
      "step": 441840
    },
    {
      "epoch": 710.39,
      "learning_rate": 0.028990907022025714,
      "loss": 2.5156,
      "step": 441860
    },
    {
      "epoch": 710.42,
      "learning_rate": 0.028987691591157563,
      "loss": 2.5172,
      "step": 441880
    },
    {
      "epoch": 710.45,
      "learning_rate": 0.02898447616028939,
      "loss": 2.5164,
      "step": 441900
    },
    {
      "epoch": 710.48,
      "learning_rate": 0.028981260729421223,
      "loss": 2.5149,
      "step": 441920
    },
    {
      "epoch": 710.51,
      "learning_rate": 0.02897804529855305,
      "loss": 2.5057,
      "step": 441940
    },
    {
      "epoch": 710.55,
      "learning_rate": 0.028974829867684883,
      "loss": 2.5073,
      "step": 441960
    },
    {
      "epoch": 710.58,
      "learning_rate": 0.028971614436816714,
      "loss": 2.5233,
      "step": 441980
    },
    {
      "epoch": 710.61,
      "learning_rate": 0.028968399005948553,
      "loss": 2.5184,
      "step": 442000
    },
    {
      "epoch": 710.64,
      "learning_rate": 0.02896518357508039,
      "loss": 2.5076,
      "step": 442020
    },
    {
      "epoch": 710.68,
      "learning_rate": 0.02896196814421222,
      "loss": 2.5137,
      "step": 442040
    },
    {
      "epoch": 710.71,
      "learning_rate": 0.028958752713344044,
      "loss": 2.5146,
      "step": 442060
    },
    {
      "epoch": 710.74,
      "learning_rate": 0.02895553728247588,
      "loss": 2.5272,
      "step": 442080
    },
    {
      "epoch": 710.77,
      "learning_rate": 0.02895232185160772,
      "loss": 2.5166,
      "step": 442100
    },
    {
      "epoch": 710.8,
      "learning_rate": 0.028949106420739553,
      "loss": 2.5333,
      "step": 442120
    },
    {
      "epoch": 710.84,
      "learning_rate": 0.02894589098987138,
      "loss": 2.5167,
      "step": 442140
    },
    {
      "epoch": 710.87,
      "learning_rate": 0.02894267555900322,
      "loss": 2.5008,
      "step": 442160
    },
    {
      "epoch": 710.9,
      "learning_rate": 0.028939460128135044,
      "loss": 2.4971,
      "step": 442180
    },
    {
      "epoch": 710.93,
      "learning_rate": 0.028936244697266873,
      "loss": 2.5176,
      "step": 442200
    },
    {
      "epoch": 710.96,
      "learning_rate": 0.02893302926639872,
      "loss": 2.4926,
      "step": 442220
    },
    {
      "epoch": 711.0,
      "learning_rate": 0.02892981383553055,
      "loss": 2.5112,
      "step": 442240
    },
    {
      "epoch": 711.0,
      "eval_accuracy": {
        "accuracy": 0.4390888595195522
      },
      "eval_loss": 2.6163876056671143,
      "eval_runtime": 3.0558,
      "eval_samples_per_second": 4209.41,
      "eval_steps_per_second": 65.777,
      "step": 442242
    },
    {
      "epoch": 711.03,
      "learning_rate": 0.02892659840466238,
      "loss": 2.5071,
      "step": 442260
    },
    {
      "epoch": 711.06,
      "learning_rate": 0.02892338297379421,
      "loss": 2.4957,
      "step": 442280
    },
    {
      "epoch": 711.09,
      "learning_rate": 0.02892016754292604,
      "loss": 2.5182,
      "step": 442300
    },
    {
      "epoch": 711.13,
      "learning_rate": 0.028916952112057883,
      "loss": 2.4944,
      "step": 442320
    },
    {
      "epoch": 711.16,
      "learning_rate": 0.02891373668118971,
      "loss": 2.5472,
      "step": 442340
    },
    {
      "epoch": 711.19,
      "learning_rate": 0.02891052125032155,
      "loss": 2.5156,
      "step": 442360
    },
    {
      "epoch": 711.22,
      "learning_rate": 0.028907305819453374,
      "loss": 2.5016,
      "step": 442380
    },
    {
      "epoch": 711.25,
      "learning_rate": 0.028904090388585203,
      "loss": 2.5214,
      "step": 442400
    },
    {
      "epoch": 711.29,
      "learning_rate": 0.028900874957717038,
      "loss": 2.5301,
      "step": 442420
    },
    {
      "epoch": 711.32,
      "learning_rate": 0.02889765952684888,
      "loss": 2.5116,
      "step": 442440
    },
    {
      "epoch": 711.35,
      "learning_rate": 0.02889444409598071,
      "loss": 2.5145,
      "step": 442460
    },
    {
      "epoch": 711.38,
      "learning_rate": 0.02889122866511254,
      "loss": 2.5284,
      "step": 442480
    },
    {
      "epoch": 711.41,
      "learning_rate": 0.02888801323424437,
      "loss": 2.5361,
      "step": 442500
    },
    {
      "epoch": 711.45,
      "learning_rate": 0.028884797803376203,
      "loss": 2.5141,
      "step": 442520
    },
    {
      "epoch": 711.48,
      "learning_rate": 0.02888158237250803,
      "loss": 2.4966,
      "step": 442540
    },
    {
      "epoch": 711.51,
      "learning_rate": 0.02887836694163988,
      "loss": 2.5015,
      "step": 442560
    },
    {
      "epoch": 711.54,
      "learning_rate": 0.028875151510771708,
      "loss": 2.5115,
      "step": 442580
    },
    {
      "epoch": 711.58,
      "learning_rate": 0.028871936079903533,
      "loss": 2.5088,
      "step": 442600
    },
    {
      "epoch": 711.61,
      "learning_rate": 0.028868720649035368,
      "loss": 2.5081,
      "step": 442620
    },
    {
      "epoch": 711.64,
      "learning_rate": 0.0288655052181672,
      "loss": 2.5178,
      "step": 442640
    },
    {
      "epoch": 711.67,
      "learning_rate": 0.02886228978729904,
      "loss": 2.5073,
      "step": 442660
    },
    {
      "epoch": 711.7,
      "learning_rate": 0.02885907435643087,
      "loss": 2.508,
      "step": 442680
    },
    {
      "epoch": 711.74,
      "learning_rate": 0.0288558589255627,
      "loss": 2.5264,
      "step": 442700
    },
    {
      "epoch": 711.77,
      "learning_rate": 0.028852643494694533,
      "loss": 2.5047,
      "step": 442720
    },
    {
      "epoch": 711.8,
      "learning_rate": 0.02884942806382636,
      "loss": 2.5119,
      "step": 442740
    },
    {
      "epoch": 711.83,
      "learning_rate": 0.028846212632958196,
      "loss": 2.5153,
      "step": 442760
    },
    {
      "epoch": 711.86,
      "learning_rate": 0.028842997202090038,
      "loss": 2.5216,
      "step": 442780
    },
    {
      "epoch": 711.9,
      "learning_rate": 0.02883978177122187,
      "loss": 2.5203,
      "step": 442800
    },
    {
      "epoch": 711.93,
      "learning_rate": 0.028836566340353698,
      "loss": 2.5061,
      "step": 442820
    },
    {
      "epoch": 711.96,
      "learning_rate": 0.02883335090948553,
      "loss": 2.5157,
      "step": 442840
    },
    {
      "epoch": 711.99,
      "learning_rate": 0.02883013547861736,
      "loss": 2.5363,
      "step": 442860
    },
    {
      "epoch": 712.0,
      "eval_accuracy": {
        "accuracy": 0.4366011039415377
      },
      "eval_loss": 2.6369221210479736,
      "eval_runtime": 3.1766,
      "eval_samples_per_second": 4049.34,
      "eval_steps_per_second": 63.276,
      "step": 442864
    },
    {
      "epoch": 712.03,
      "learning_rate": 0.02882692004774919,
      "loss": 2.518,
      "step": 442880
    },
    {
      "epoch": 712.06,
      "learning_rate": 0.028823704616881038,
      "loss": 2.5079,
      "step": 442900
    },
    {
      "epoch": 712.09,
      "learning_rate": 0.028820489186012863,
      "loss": 2.5,
      "step": 442920
    },
    {
      "epoch": 712.12,
      "learning_rate": 0.02881727375514469,
      "loss": 2.5066,
      "step": 442940
    },
    {
      "epoch": 712.15,
      "learning_rate": 0.028814058324276526,
      "loss": 2.4854,
      "step": 442960
    },
    {
      "epoch": 712.19,
      "learning_rate": 0.028810842893408357,
      "loss": 2.5276,
      "step": 442980
    },
    {
      "epoch": 712.22,
      "learning_rate": 0.0288076274625402,
      "loss": 2.5038,
      "step": 443000
    },
    {
      "epoch": 712.25,
      "learning_rate": 0.028804412031672028,
      "loss": 2.5144,
      "step": 443020
    },
    {
      "epoch": 712.28,
      "learning_rate": 0.02880119660080386,
      "loss": 2.5151,
      "step": 443040
    },
    {
      "epoch": 712.32,
      "learning_rate": 0.02879798116993569,
      "loss": 2.5163,
      "step": 443060
    },
    {
      "epoch": 712.35,
      "learning_rate": 0.02879476573906752,
      "loss": 2.5092,
      "step": 443080
    },
    {
      "epoch": 712.38,
      "learning_rate": 0.028791550308199354,
      "loss": 2.5273,
      "step": 443100
    },
    {
      "epoch": 712.41,
      "learning_rate": 0.028788334877331196,
      "loss": 2.5249,
      "step": 443120
    },
    {
      "epoch": 712.44,
      "learning_rate": 0.02878511944646302,
      "loss": 2.5082,
      "step": 443140
    },
    {
      "epoch": 712.48,
      "learning_rate": 0.028781904015594856,
      "loss": 2.5337,
      "step": 443160
    },
    {
      "epoch": 712.51,
      "learning_rate": 0.028778688584726687,
      "loss": 2.5073,
      "step": 443180
    },
    {
      "epoch": 712.54,
      "learning_rate": 0.02877547315385852,
      "loss": 2.4908,
      "step": 443200
    },
    {
      "epoch": 712.57,
      "learning_rate": 0.028772257722990347,
      "loss": 2.5027,
      "step": 443220
    },
    {
      "epoch": 712.6,
      "learning_rate": 0.02876904229212219,
      "loss": 2.5014,
      "step": 443240
    },
    {
      "epoch": 712.64,
      "learning_rate": 0.02876582686125402,
      "loss": 2.5375,
      "step": 443260
    },
    {
      "epoch": 712.67,
      "learning_rate": 0.02876261143038585,
      "loss": 2.5192,
      "step": 443280
    },
    {
      "epoch": 712.7,
      "learning_rate": 0.028759395999517684,
      "loss": 2.5162,
      "step": 443300
    },
    {
      "epoch": 712.73,
      "learning_rate": 0.02875618056864951,
      "loss": 2.503,
      "step": 443320
    },
    {
      "epoch": 712.77,
      "learning_rate": 0.02875296513778135,
      "loss": 2.491,
      "step": 443340
    },
    {
      "epoch": 712.8,
      "learning_rate": 0.028749749706913186,
      "loss": 2.5177,
      "step": 443360
    },
    {
      "epoch": 712.83,
      "learning_rate": 0.028746534276045017,
      "loss": 2.524,
      "step": 443380
    },
    {
      "epoch": 712.86,
      "learning_rate": 0.02874331884517685,
      "loss": 2.5211,
      "step": 443400
    },
    {
      "epoch": 712.89,
      "learning_rate": 0.028740103414308677,
      "loss": 2.515,
      "step": 443420
    },
    {
      "epoch": 712.93,
      "learning_rate": 0.02873688798344051,
      "loss": 2.5147,
      "step": 443440
    },
    {
      "epoch": 712.96,
      "learning_rate": 0.02873367255257235,
      "loss": 2.5227,
      "step": 443460
    },
    {
      "epoch": 712.99,
      "learning_rate": 0.02873045712170418,
      "loss": 2.5113,
      "step": 443480
    },
    {
      "epoch": 713.0,
      "eval_accuracy": {
        "accuracy": 0.43838917826323565
      },
      "eval_loss": 2.621929883956909,
      "eval_runtime": 3.1205,
      "eval_samples_per_second": 4122.084,
      "eval_steps_per_second": 64.413,
      "step": 443486
    },
    {
      "epoch": 713.02,
      "learning_rate": 0.028727241690836014,
      "loss": 2.4895,
      "step": 443500
    },
    {
      "epoch": 713.05,
      "learning_rate": 0.028724026259967846,
      "loss": 2.5216,
      "step": 443520
    },
    {
      "epoch": 713.09,
      "learning_rate": 0.028720810829099677,
      "loss": 2.5034,
      "step": 443540
    },
    {
      "epoch": 713.12,
      "learning_rate": 0.028717595398231505,
      "loss": 2.499,
      "step": 443560
    },
    {
      "epoch": 713.15,
      "learning_rate": 0.028714379967363347,
      "loss": 2.4959,
      "step": 443580
    },
    {
      "epoch": 713.18,
      "learning_rate": 0.02871116453649518,
      "loss": 2.5039,
      "step": 443600
    },
    {
      "epoch": 713.22,
      "learning_rate": 0.028707949105627007,
      "loss": 2.4965,
      "step": 443620
    },
    {
      "epoch": 713.25,
      "learning_rate": 0.02870473367475884,
      "loss": 2.5,
      "step": 443640
    },
    {
      "epoch": 713.28,
      "learning_rate": 0.028701518243890667,
      "loss": 2.5349,
      "step": 443660
    },
    {
      "epoch": 713.31,
      "learning_rate": 0.02869830281302251,
      "loss": 2.5336,
      "step": 443680
    },
    {
      "epoch": 713.34,
      "learning_rate": 0.028695087382154344,
      "loss": 2.5136,
      "step": 443700
    },
    {
      "epoch": 713.38,
      "learning_rate": 0.028692032722829587,
      "loss": 2.532,
      "step": 443720
    },
    {
      "epoch": 713.41,
      "learning_rate": 0.02868881729196142,
      "loss": 2.5131,
      "step": 443740
    },
    {
      "epoch": 713.44,
      "learning_rate": 0.028685601861093247,
      "loss": 2.511,
      "step": 443760
    },
    {
      "epoch": 713.47,
      "learning_rate": 0.02868238643022508,
      "loss": 2.4877,
      "step": 443780
    },
    {
      "epoch": 713.5,
      "learning_rate": 0.028679170999356907,
      "loss": 2.5157,
      "step": 443800
    },
    {
      "epoch": 713.54,
      "learning_rate": 0.02867595556848875,
      "loss": 2.5141,
      "step": 443820
    },
    {
      "epoch": 713.57,
      "learning_rate": 0.028672740137620584,
      "loss": 2.5283,
      "step": 443840
    },
    {
      "epoch": 713.6,
      "learning_rate": 0.02866952470675241,
      "loss": 2.5146,
      "step": 443860
    },
    {
      "epoch": 713.63,
      "learning_rate": 0.028666309275884247,
      "loss": 2.5178,
      "step": 443880
    },
    {
      "epoch": 713.67,
      "learning_rate": 0.028663093845016075,
      "loss": 2.5182,
      "step": 443900
    },
    {
      "epoch": 713.7,
      "learning_rate": 0.028659878414147907,
      "loss": 2.5277,
      "step": 443920
    },
    {
      "epoch": 713.73,
      "learning_rate": 0.02865666298327975,
      "loss": 2.5151,
      "step": 443940
    },
    {
      "epoch": 713.76,
      "learning_rate": 0.028653447552411577,
      "loss": 2.523,
      "step": 443960
    },
    {
      "epoch": 713.79,
      "learning_rate": 0.02865023212154341,
      "loss": 2.5139,
      "step": 443980
    },
    {
      "epoch": 713.83,
      "learning_rate": 0.028647016690675237,
      "loss": 2.4962,
      "step": 444000
    },
    {
      "epoch": 713.86,
      "learning_rate": 0.028643801259807075,
      "loss": 2.4966,
      "step": 444020
    },
    {
      "epoch": 713.89,
      "learning_rate": 0.028640585828938903,
      "loss": 2.4982,
      "step": 444040
    },
    {
      "epoch": 713.92,
      "learning_rate": 0.02863737039807074,
      "loss": 2.5079,
      "step": 444060
    },
    {
      "epoch": 713.95,
      "learning_rate": 0.028634154967202577,
      "loss": 2.5126,
      "step": 444080
    },
    {
      "epoch": 713.99,
      "learning_rate": 0.028630939536334405,
      "loss": 2.5311,
      "step": 444100
    },
    {
      "epoch": 714.0,
      "eval_accuracy": {
        "accuracy": 0.43613464977066
      },
      "eval_loss": 2.6284632682800293,
      "eval_runtime": 3.2536,
      "eval_samples_per_second": 3953.471,
      "eval_steps_per_second": 61.778,
      "step": 444108
    },
    {
      "epoch": 714.02,
      "learning_rate": 0.028627724105466237,
      "loss": 2.5261,
      "step": 444120
    },
    {
      "epoch": 714.05,
      "learning_rate": 0.028624508674598065,
      "loss": 2.5299,
      "step": 444140
    },
    {
      "epoch": 714.08,
      "learning_rate": 0.028621293243729907,
      "loss": 2.5174,
      "step": 444160
    },
    {
      "epoch": 714.12,
      "learning_rate": 0.02861807781286174,
      "loss": 2.5104,
      "step": 444180
    },
    {
      "epoch": 714.15,
      "learning_rate": 0.028614862381993567,
      "loss": 2.5289,
      "step": 444200
    },
    {
      "epoch": 714.18,
      "learning_rate": 0.028611646951125405,
      "loss": 2.5126,
      "step": 444220
    },
    {
      "epoch": 714.21,
      "learning_rate": 0.028608431520257233,
      "loss": 2.484,
      "step": 444240
    },
    {
      "epoch": 714.24,
      "learning_rate": 0.028605216089389058,
      "loss": 2.5094,
      "step": 444260
    },
    {
      "epoch": 714.28,
      "learning_rate": 0.028602000658520907,
      "loss": 2.5117,
      "step": 444280
    },
    {
      "epoch": 714.31,
      "learning_rate": 0.028598785227652735,
      "loss": 2.5096,
      "step": 444300
    },
    {
      "epoch": 714.34,
      "learning_rate": 0.028595569796784567,
      "loss": 2.4948,
      "step": 444320
    },
    {
      "epoch": 714.37,
      "learning_rate": 0.028592354365916395,
      "loss": 2.5025,
      "step": 444340
    },
    {
      "epoch": 714.41,
      "learning_rate": 0.028589138935048233,
      "loss": 2.513,
      "step": 444360
    },
    {
      "epoch": 714.44,
      "learning_rate": 0.028585923504180058,
      "loss": 2.5103,
      "step": 444380
    },
    {
      "epoch": 714.47,
      "learning_rate": 0.028582708073311897,
      "loss": 2.5206,
      "step": 444400
    },
    {
      "epoch": 714.5,
      "learning_rate": 0.028579492642443735,
      "loss": 2.5086,
      "step": 444420
    },
    {
      "epoch": 714.53,
      "learning_rate": 0.028576277211575563,
      "loss": 2.4736,
      "step": 444440
    },
    {
      "epoch": 714.57,
      "learning_rate": 0.028573061780707395,
      "loss": 2.5206,
      "step": 444460
    },
    {
      "epoch": 714.6,
      "learning_rate": 0.028569846349839223,
      "loss": 2.5206,
      "step": 444480
    },
    {
      "epoch": 714.63,
      "learning_rate": 0.028566630918971065,
      "loss": 2.5358,
      "step": 444500
    },
    {
      "epoch": 714.66,
      "learning_rate": 0.028563415488102897,
      "loss": 2.4938,
      "step": 444520
    },
    {
      "epoch": 714.69,
      "learning_rate": 0.028560200057234725,
      "loss": 2.5033,
      "step": 444540
    },
    {
      "epoch": 714.73,
      "learning_rate": 0.028556984626366563,
      "loss": 2.5054,
      "step": 444560
    },
    {
      "epoch": 714.76,
      "learning_rate": 0.028553769195498388,
      "loss": 2.503,
      "step": 444580
    },
    {
      "epoch": 714.79,
      "learning_rate": 0.028550553764630216,
      "loss": 2.5212,
      "step": 444600
    },
    {
      "epoch": 714.82,
      "learning_rate": 0.028547338333762065,
      "loss": 2.5169,
      "step": 444620
    },
    {
      "epoch": 714.86,
      "learning_rate": 0.028544122902893893,
      "loss": 2.5235,
      "step": 444640
    },
    {
      "epoch": 714.89,
      "learning_rate": 0.028540907472025725,
      "loss": 2.5055,
      "step": 444660
    },
    {
      "epoch": 714.92,
      "learning_rate": 0.028537692041157553,
      "loss": 2.5351,
      "step": 444680
    },
    {
      "epoch": 714.95,
      "learning_rate": 0.028534476610289385,
      "loss": 2.5194,
      "step": 444700
    },
    {
      "epoch": 714.98,
      "learning_rate": 0.028531261179421227,
      "loss": 2.5189,
      "step": 444720
    },
    {
      "epoch": 715.0,
      "eval_accuracy": {
        "accuracy": 0.44289823524838684
      },
      "eval_loss": 2.6200335025787354,
      "eval_runtime": 3.112,
      "eval_samples_per_second": 4133.372,
      "eval_steps_per_second": 64.589,
      "step": 444730
    },
    {
      "epoch": 715.02,
      "learning_rate": 0.028528045748553055,
      "loss": 2.515,
      "step": 444740
    },
    {
      "epoch": 715.05,
      "learning_rate": 0.028524830317684893,
      "loss": 2.5345,
      "step": 444760
    },
    {
      "epoch": 715.08,
      "learning_rate": 0.02852161488681672,
      "loss": 2.5084,
      "step": 444780
    },
    {
      "epoch": 715.11,
      "learning_rate": 0.028518399455948546,
      "loss": 2.4991,
      "step": 444800
    },
    {
      "epoch": 715.14,
      "learning_rate": 0.02851518402508038,
      "loss": 2.4889,
      "step": 444820
    },
    {
      "epoch": 715.18,
      "learning_rate": 0.028511968594212223,
      "loss": 2.5326,
      "step": 444840
    },
    {
      "epoch": 715.21,
      "learning_rate": 0.028508753163344055,
      "loss": 2.5099,
      "step": 444860
    },
    {
      "epoch": 715.24,
      "learning_rate": 0.028505537732475883,
      "loss": 2.5072,
      "step": 444880
    },
    {
      "epoch": 715.27,
      "learning_rate": 0.028502322301607715,
      "loss": 2.5105,
      "step": 444900
    },
    {
      "epoch": 715.31,
      "learning_rate": 0.028499106870739546,
      "loss": 2.5016,
      "step": 444920
    },
    {
      "epoch": 715.34,
      "learning_rate": 0.028495891439871374,
      "loss": 2.518,
      "step": 444940
    },
    {
      "epoch": 715.37,
      "learning_rate": 0.028492676009003223,
      "loss": 2.4951,
      "step": 444960
    },
    {
      "epoch": 715.4,
      "learning_rate": 0.02848946057813505,
      "loss": 2.5115,
      "step": 444980
    },
    {
      "epoch": 715.43,
      "learning_rate": 0.028486245147266883,
      "loss": 2.5264,
      "step": 445000
    },
    {
      "epoch": 715.47,
      "learning_rate": 0.02848302971639871,
      "loss": 2.5056,
      "step": 445020
    },
    {
      "epoch": 715.5,
      "learning_rate": 0.028479814285530543,
      "loss": 2.5151,
      "step": 445040
    },
    {
      "epoch": 715.53,
      "learning_rate": 0.028476598854662385,
      "loss": 2.5211,
      "step": 445060
    },
    {
      "epoch": 715.56,
      "learning_rate": 0.028473383423794213,
      "loss": 2.5163,
      "step": 445080
    },
    {
      "epoch": 715.59,
      "learning_rate": 0.02847016799292605,
      "loss": 2.505,
      "step": 445100
    },
    {
      "epoch": 715.63,
      "learning_rate": 0.028466952562057876,
      "loss": 2.5246,
      "step": 445120
    },
    {
      "epoch": 715.66,
      "learning_rate": 0.028463737131189704,
      "loss": 2.5042,
      "step": 445140
    },
    {
      "epoch": 715.69,
      "learning_rate": 0.02846052170032154,
      "loss": 2.5117,
      "step": 445160
    },
    {
      "epoch": 715.72,
      "learning_rate": 0.02845730626945338,
      "loss": 2.4994,
      "step": 445180
    },
    {
      "epoch": 715.76,
      "learning_rate": 0.028454090838585213,
      "loss": 2.5116,
      "step": 445200
    },
    {
      "epoch": 715.79,
      "learning_rate": 0.02845087540771704,
      "loss": 2.4927,
      "step": 445220
    },
    {
      "epoch": 715.82,
      "learning_rate": 0.028447659976848873,
      "loss": 2.5074,
      "step": 445240
    },
    {
      "epoch": 715.85,
      "learning_rate": 0.028444444545980704,
      "loss": 2.5034,
      "step": 445260
    },
    {
      "epoch": 715.88,
      "learning_rate": 0.028441229115112533,
      "loss": 2.5197,
      "step": 445280
    },
    {
      "epoch": 715.92,
      "learning_rate": 0.02843801368424438,
      "loss": 2.5043,
      "step": 445300
    },
    {
      "epoch": 715.95,
      "learning_rate": 0.02843479825337621,
      "loss": 2.5049,
      "step": 445320
    },
    {
      "epoch": 715.98,
      "learning_rate": 0.028431582822508034,
      "loss": 2.5093,
      "step": 445340
    },
    {
      "epoch": 716.0,
      "eval_accuracy": {
        "accuracy": 0.4376117546451061
      },
      "eval_loss": 2.6197657585144043,
      "eval_runtime": 3.0535,
      "eval_samples_per_second": 4212.543,
      "eval_steps_per_second": 65.826,
      "step": 445352
    },
    {
      "epoch": 716.01,
      "learning_rate": 0.02842836739163987,
      "loss": 2.526,
      "step": 445360
    },
    {
      "epoch": 716.05,
      "learning_rate": 0.0284251519607717,
      "loss": 2.5154,
      "step": 445380
    },
    {
      "epoch": 716.08,
      "learning_rate": 0.028421936529903543,
      "loss": 2.5261,
      "step": 445400
    },
    {
      "epoch": 716.11,
      "learning_rate": 0.02841872109903537,
      "loss": 2.5045,
      "step": 445420
    },
    {
      "epoch": 716.14,
      "learning_rate": 0.028415505668167203,
      "loss": 2.5003,
      "step": 445440
    },
    {
      "epoch": 716.17,
      "learning_rate": 0.028412290237299034,
      "loss": 2.5077,
      "step": 445460
    },
    {
      "epoch": 716.21,
      "learning_rate": 0.028409074806430862,
      "loss": 2.5252,
      "step": 445480
    },
    {
      "epoch": 716.24,
      "learning_rate": 0.028405859375562698,
      "loss": 2.5146,
      "step": 445500
    },
    {
      "epoch": 716.27,
      "learning_rate": 0.02840264394469454,
      "loss": 2.502,
      "step": 445520
    },
    {
      "epoch": 716.3,
      "learning_rate": 0.028399428513826364,
      "loss": 2.5032,
      "step": 445540
    },
    {
      "epoch": 716.33,
      "learning_rate": 0.0283962130829582,
      "loss": 2.5099,
      "step": 445560
    },
    {
      "epoch": 716.37,
      "learning_rate": 0.02839299765209003,
      "loss": 2.5125,
      "step": 445580
    },
    {
      "epoch": 716.4,
      "learning_rate": 0.028389782221221863,
      "loss": 2.5054,
      "step": 445600
    },
    {
      "epoch": 716.43,
      "learning_rate": 0.02838656679035369,
      "loss": 2.4895,
      "step": 445620
    },
    {
      "epoch": 716.46,
      "learning_rate": 0.02838335135948554,
      "loss": 2.5034,
      "step": 445640
    },
    {
      "epoch": 716.5,
      "learning_rate": 0.028380135928617364,
      "loss": 2.5157,
      "step": 445660
    },
    {
      "epoch": 716.53,
      "learning_rate": 0.028376920497749192,
      "loss": 2.5132,
      "step": 445680
    },
    {
      "epoch": 716.56,
      "learning_rate": 0.028373705066881028,
      "loss": 2.5223,
      "step": 445700
    },
    {
      "epoch": 716.59,
      "learning_rate": 0.02837048963601286,
      "loss": 2.5006,
      "step": 445720
    },
    {
      "epoch": 716.62,
      "learning_rate": 0.0283672742051447,
      "loss": 2.4947,
      "step": 445740
    },
    {
      "epoch": 716.66,
      "learning_rate": 0.02836405877427653,
      "loss": 2.4962,
      "step": 445760
    },
    {
      "epoch": 716.69,
      "learning_rate": 0.02836084334340836,
      "loss": 2.5158,
      "step": 445780
    },
    {
      "epoch": 716.72,
      "learning_rate": 0.028357627912540193,
      "loss": 2.5104,
      "step": 445800
    },
    {
      "epoch": 716.75,
      "learning_rate": 0.02835441248167202,
      "loss": 2.5161,
      "step": 445820
    },
    {
      "epoch": 716.78,
      "learning_rate": 0.028351197050803852,
      "loss": 2.503,
      "step": 445840
    },
    {
      "epoch": 716.82,
      "learning_rate": 0.028347981619935694,
      "loss": 2.5248,
      "step": 445860
    },
    {
      "epoch": 716.85,
      "learning_rate": 0.028344766189067522,
      "loss": 2.5155,
      "step": 445880
    },
    {
      "epoch": 716.88,
      "learning_rate": 0.028341550758199358,
      "loss": 2.5145,
      "step": 445900
    },
    {
      "epoch": 716.91,
      "learning_rate": 0.02833833532733119,
      "loss": 2.5151,
      "step": 445920
    },
    {
      "epoch": 716.95,
      "learning_rate": 0.02833511989646302,
      "loss": 2.5288,
      "step": 445940
    },
    {
      "epoch": 716.98,
      "learning_rate": 0.02833190446559485,
      "loss": 2.5165,
      "step": 445960
    },
    {
      "epoch": 717.0,
      "eval_accuracy": {
        "accuracy": 0.4418098421830055
      },
      "eval_loss": 2.615098714828491,
      "eval_runtime": 3.1696,
      "eval_samples_per_second": 4058.183,
      "eval_steps_per_second": 63.414,
      "step": 445974
    },
    {
      "epoch": 717.01,
      "learning_rate": 0.02832868903472669,
      "loss": 2.5227,
      "step": 445980
    },
    {
      "epoch": 717.04,
      "learning_rate": 0.028325473603858523,
      "loss": 2.4963,
      "step": 446000
    },
    {
      "epoch": 717.07,
      "learning_rate": 0.02832225817299035,
      "loss": 2.5006,
      "step": 446020
    },
    {
      "epoch": 717.11,
      "learning_rate": 0.028319203513665597,
      "loss": 2.5034,
      "step": 446040
    },
    {
      "epoch": 717.14,
      "learning_rate": 0.028315988082797422,
      "loss": 2.4955,
      "step": 446060
    },
    {
      "epoch": 717.17,
      "learning_rate": 0.02831277265192926,
      "loss": 2.5123,
      "step": 446080
    },
    {
      "epoch": 717.2,
      "learning_rate": 0.02830955722106109,
      "loss": 2.5131,
      "step": 446100
    },
    {
      "epoch": 717.23,
      "learning_rate": 0.02830634179019293,
      "loss": 2.5144,
      "step": 446120
    },
    {
      "epoch": 717.27,
      "learning_rate": 0.028303126359324762,
      "loss": 2.5155,
      "step": 446140
    },
    {
      "epoch": 717.3,
      "learning_rate": 0.02829991092845659,
      "loss": 2.5163,
      "step": 446160
    },
    {
      "epoch": 717.33,
      "learning_rate": 0.028296695497588422,
      "loss": 2.4898,
      "step": 446180
    },
    {
      "epoch": 717.36,
      "learning_rate": 0.02829348006672025,
      "loss": 2.4905,
      "step": 446200
    },
    {
      "epoch": 717.4,
      "learning_rate": 0.028290264635852092,
      "loss": 2.5146,
      "step": 446220
    },
    {
      "epoch": 717.43,
      "learning_rate": 0.028287049204983927,
      "loss": 2.52,
      "step": 446240
    },
    {
      "epoch": 717.46,
      "learning_rate": 0.028283833774115752,
      "loss": 2.498,
      "step": 446260
    },
    {
      "epoch": 717.49,
      "learning_rate": 0.02828061834324759,
      "loss": 2.5006,
      "step": 446280
    },
    {
      "epoch": 717.52,
      "learning_rate": 0.02827740291237942,
      "loss": 2.5232,
      "step": 446300
    },
    {
      "epoch": 717.56,
      "learning_rate": 0.02827418748151125,
      "loss": 2.4883,
      "step": 446320
    },
    {
      "epoch": 717.59,
      "learning_rate": 0.028270972050643092,
      "loss": 2.4995,
      "step": 446340
    },
    {
      "epoch": 717.62,
      "learning_rate": 0.02826775661977492,
      "loss": 2.5143,
      "step": 446360
    },
    {
      "epoch": 717.65,
      "learning_rate": 0.028264541188906752,
      "loss": 2.5113,
      "step": 446380
    },
    {
      "epoch": 717.68,
      "learning_rate": 0.02826132575803858,
      "loss": 2.5102,
      "step": 446400
    },
    {
      "epoch": 717.72,
      "learning_rate": 0.02825811032717042,
      "loss": 2.5135,
      "step": 446420
    },
    {
      "epoch": 717.75,
      "learning_rate": 0.028254894896302247,
      "loss": 2.5258,
      "step": 446440
    },
    {
      "epoch": 717.78,
      "learning_rate": 0.02825167946543409,
      "loss": 2.5054,
      "step": 446460
    },
    {
      "epoch": 717.81,
      "learning_rate": 0.02824846403456592,
      "loss": 2.5163,
      "step": 446480
    },
    {
      "epoch": 717.85,
      "learning_rate": 0.02824524860369775,
      "loss": 2.5088,
      "step": 446500
    },
    {
      "epoch": 717.88,
      "learning_rate": 0.02824203317282958,
      "loss": 2.522,
      "step": 446520
    },
    {
      "epoch": 717.91,
      "learning_rate": 0.02823881774196141,
      "loss": 2.5405,
      "step": 446540
    },
    {
      "epoch": 717.94,
      "learning_rate": 0.02823560231109325,
      "loss": 2.5095,
      "step": 446560
    },
    {
      "epoch": 717.97,
      "learning_rate": 0.028232386880225082,
      "loss": 2.5189,
      "step": 446580
    },
    {
      "epoch": 718.0,
      "eval_accuracy": {
        "accuracy": 0.4435979165047034
      },
      "eval_loss": 2.618020534515381,
      "eval_runtime": 3.2135,
      "eval_samples_per_second": 4002.812,
      "eval_steps_per_second": 62.549,
      "step": 446596
    },
    {
      "epoch": 718.01,
      "learning_rate": 0.02822917144935691,
      "loss": 2.5273,
      "step": 446600
    },
    {
      "epoch": 718.04,
      "learning_rate": 0.02822595601848875,
      "loss": 2.5156,
      "step": 446620
    },
    {
      "epoch": 718.07,
      "learning_rate": 0.028222740587620577,
      "loss": 2.513,
      "step": 446640
    },
    {
      "epoch": 718.1,
      "learning_rate": 0.02821952515675241,
      "loss": 2.5362,
      "step": 446660
    },
    {
      "epoch": 718.14,
      "learning_rate": 0.02821630972588425,
      "loss": 2.4873,
      "step": 446680
    },
    {
      "epoch": 718.17,
      "learning_rate": 0.02821309429501608,
      "loss": 2.5026,
      "step": 446700
    },
    {
      "epoch": 718.2,
      "learning_rate": 0.02820987886414791,
      "loss": 2.5066,
      "step": 446720
    },
    {
      "epoch": 718.23,
      "learning_rate": 0.02820666343327974,
      "loss": 2.5199,
      "step": 446740
    },
    {
      "epoch": 718.26,
      "learning_rate": 0.028203448002411577,
      "loss": 2.5214,
      "step": 446760
    },
    {
      "epoch": 718.3,
      "learning_rate": 0.0282002325715434,
      "loss": 2.4989,
      "step": 446780
    },
    {
      "epoch": 718.33,
      "learning_rate": 0.02819701714067524,
      "loss": 2.5347,
      "step": 446800
    },
    {
      "epoch": 718.36,
      "learning_rate": 0.02819380170980708,
      "loss": 2.5055,
      "step": 446820
    },
    {
      "epoch": 718.39,
      "learning_rate": 0.028190586278938907,
      "loss": 2.5178,
      "step": 446840
    },
    {
      "epoch": 718.42,
      "learning_rate": 0.02818737084807074,
      "loss": 2.4986,
      "step": 446860
    },
    {
      "epoch": 718.46,
      "learning_rate": 0.028184155417202567,
      "loss": 2.5036,
      "step": 446880
    },
    {
      "epoch": 718.49,
      "learning_rate": 0.02818093998633441,
      "loss": 2.5052,
      "step": 446900
    },
    {
      "epoch": 718.52,
      "learning_rate": 0.02817772455546624,
      "loss": 2.5014,
      "step": 446920
    },
    {
      "epoch": 718.55,
      "learning_rate": 0.02817450912459807,
      "loss": 2.5216,
      "step": 446940
    },
    {
      "epoch": 718.59,
      "learning_rate": 0.028171293693729907,
      "loss": 2.4927,
      "step": 446960
    },
    {
      "epoch": 718.62,
      "learning_rate": 0.028168078262861735,
      "loss": 2.5182,
      "step": 446980
    },
    {
      "epoch": 718.65,
      "learning_rate": 0.02816486283199356,
      "loss": 2.508,
      "step": 447000
    },
    {
      "epoch": 718.68,
      "learning_rate": 0.02816164740112541,
      "loss": 2.5094,
      "step": 447020
    },
    {
      "epoch": 718.71,
      "learning_rate": 0.028158431970257237,
      "loss": 2.5308,
      "step": 447040
    },
    {
      "epoch": 718.75,
      "learning_rate": 0.02815521653938907,
      "loss": 2.4969,
      "step": 447060
    },
    {
      "epoch": 718.78,
      "learning_rate": 0.028152001108520897,
      "loss": 2.5101,
      "step": 447080
    },
    {
      "epoch": 718.81,
      "learning_rate": 0.028148785677652728,
      "loss": 2.5252,
      "step": 447100
    },
    {
      "epoch": 718.84,
      "learning_rate": 0.02814557024678456,
      "loss": 2.5088,
      "step": 447120
    },
    {
      "epoch": 718.87,
      "learning_rate": 0.0281423548159164,
      "loss": 2.5083,
      "step": 447140
    },
    {
      "epoch": 718.91,
      "learning_rate": 0.028139139385048237,
      "loss": 2.5077,
      "step": 447160
    },
    {
      "epoch": 718.94,
      "learning_rate": 0.028135923954180065,
      "loss": 2.5242,
      "step": 447180
    },
    {
      "epoch": 718.97,
      "learning_rate": 0.028132708523311897,
      "loss": 2.4941,
      "step": 447200
    },
    {
      "epoch": 719.0,
      "eval_accuracy": {
        "accuracy": 0.44243178107750913
      },
      "eval_loss": 2.606999397277832,
      "eval_runtime": 3.26,
      "eval_samples_per_second": 3945.676,
      "eval_steps_per_second": 61.656,
      "step": 447218
    },
    {
      "epoch": 719.0,
      "learning_rate": 0.028129493092443725,
      "loss": 2.4875,
      "step": 447220
    },
    {
      "epoch": 719.04,
      "learning_rate": 0.028126277661575567,
      "loss": 2.5084,
      "step": 447240
    },
    {
      "epoch": 719.07,
      "learning_rate": 0.0281230622307074,
      "loss": 2.4926,
      "step": 447260
    },
    {
      "epoch": 719.1,
      "learning_rate": 0.028119846799839227,
      "loss": 2.5074,
      "step": 447280
    },
    {
      "epoch": 719.13,
      "learning_rate": 0.028116631368971065,
      "loss": 2.5178,
      "step": 447300
    },
    {
      "epoch": 719.16,
      "learning_rate": 0.02811341593810289,
      "loss": 2.5209,
      "step": 447320
    },
    {
      "epoch": 719.2,
      "learning_rate": 0.028110200507234718,
      "loss": 2.5398,
      "step": 447340
    },
    {
      "epoch": 719.23,
      "learning_rate": 0.028106985076366567,
      "loss": 2.4997,
      "step": 447360
    },
    {
      "epoch": 719.26,
      "learning_rate": 0.028103769645498395,
      "loss": 2.5055,
      "step": 447380
    },
    {
      "epoch": 719.29,
      "learning_rate": 0.028100554214630227,
      "loss": 2.4947,
      "step": 447400
    },
    {
      "epoch": 719.32,
      "learning_rate": 0.028097338783762055,
      "loss": 2.4999,
      "step": 447420
    },
    {
      "epoch": 719.36,
      "learning_rate": 0.028094123352893886,
      "loss": 2.4941,
      "step": 447440
    },
    {
      "epoch": 719.39,
      "learning_rate": 0.02809090792202573,
      "loss": 2.515,
      "step": 447460
    },
    {
      "epoch": 719.42,
      "learning_rate": 0.028087692491157557,
      "loss": 2.5231,
      "step": 447480
    },
    {
      "epoch": 719.45,
      "learning_rate": 0.028084477060289395,
      "loss": 2.5144,
      "step": 447500
    },
    {
      "epoch": 719.49,
      "learning_rate": 0.028081261629421223,
      "loss": 2.508,
      "step": 447520
    },
    {
      "epoch": 719.52,
      "learning_rate": 0.028078046198553048,
      "loss": 2.5239,
      "step": 447540
    },
    {
      "epoch": 719.55,
      "learning_rate": 0.028074830767684883,
      "loss": 2.5063,
      "step": 447560
    },
    {
      "epoch": 719.58,
      "learning_rate": 0.028071615336816725,
      "loss": 2.4942,
      "step": 447580
    },
    {
      "epoch": 719.61,
      "learning_rate": 0.028068399905948557,
      "loss": 2.5112,
      "step": 447600
    },
    {
      "epoch": 719.65,
      "learning_rate": 0.028065184475080385,
      "loss": 2.4864,
      "step": 447620
    },
    {
      "epoch": 719.68,
      "learning_rate": 0.028061969044212216,
      "loss": 2.4951,
      "step": 447640
    },
    {
      "epoch": 719.71,
      "learning_rate": 0.028058753613344048,
      "loss": 2.4988,
      "step": 447660
    },
    {
      "epoch": 719.74,
      "learning_rate": 0.028055538182475876,
      "loss": 2.4983,
      "step": 447680
    },
    {
      "epoch": 719.77,
      "learning_rate": 0.028052322751607725,
      "loss": 2.5049,
      "step": 447700
    },
    {
      "epoch": 719.81,
      "learning_rate": 0.028049107320739553,
      "loss": 2.4944,
      "step": 447720
    },
    {
      "epoch": 719.84,
      "learning_rate": 0.028045891889871378,
      "loss": 2.5203,
      "step": 447740
    },
    {
      "epoch": 719.87,
      "learning_rate": 0.028042676459003213,
      "loss": 2.5227,
      "step": 447760
    },
    {
      "epoch": 719.9,
      "learning_rate": 0.028039461028135045,
      "loss": 2.4941,
      "step": 447780
    },
    {
      "epoch": 719.94,
      "learning_rate": 0.028036245597266887,
      "loss": 2.4998,
      "step": 447800
    },
    {
      "epoch": 719.97,
      "learning_rate": 0.028033030166398715,
      "loss": 2.479,
      "step": 447820
    },
    {
      "epoch": 720.0,
      "learning_rate": 0.028029814735530553,
      "loss": 2.487,
      "step": 447840
    },
    {
      "epoch": 720.0,
      "eval_accuracy": {
        "accuracy": 0.44515276374096246
      },
      "eval_loss": 2.5995569229125977,
      "eval_runtime": 3.2441,
      "eval_samples_per_second": 3965.103,
      "eval_steps_per_second": 61.96,
      "step": 447840
    },
    {
      "epoch": 720.03,
      "learning_rate": 0.028026599304662378,
      "loss": 2.5139,
      "step": 447860
    },
    {
      "epoch": 720.06,
      "learning_rate": 0.028023383873794206,
      "loss": 2.5076,
      "step": 447880
    },
    {
      "epoch": 720.1,
      "learning_rate": 0.02802016844292604,
      "loss": 2.4987,
      "step": 447900
    },
    {
      "epoch": 720.13,
      "learning_rate": 0.028016953012057883,
      "loss": 2.5103,
      "step": 447920
    },
    {
      "epoch": 720.16,
      "learning_rate": 0.028013737581189715,
      "loss": 2.4955,
      "step": 447940
    },
    {
      "epoch": 720.19,
      "learning_rate": 0.028010522150321543,
      "loss": 2.5087,
      "step": 447960
    },
    {
      "epoch": 720.23,
      "learning_rate": 0.028007306719453375,
      "loss": 2.4976,
      "step": 447980
    },
    {
      "epoch": 720.26,
      "learning_rate": 0.028004091288585206,
      "loss": 2.5044,
      "step": 448000
    },
    {
      "epoch": 720.29,
      "learning_rate": 0.028000875857717034,
      "loss": 2.4968,
      "step": 448020
    },
    {
      "epoch": 720.32,
      "learning_rate": 0.027997660426848883,
      "loss": 2.4977,
      "step": 448040
    },
    {
      "epoch": 720.35,
      "learning_rate": 0.027994444995980708,
      "loss": 2.5172,
      "step": 448060
    },
    {
      "epoch": 720.39,
      "learning_rate": 0.027991229565112536,
      "loss": 2.5054,
      "step": 448080
    },
    {
      "epoch": 720.42,
      "learning_rate": 0.02798801413424437,
      "loss": 2.489,
      "step": 448100
    },
    {
      "epoch": 720.45,
      "learning_rate": 0.027984798703376203,
      "loss": 2.5202,
      "step": 448120
    },
    {
      "epoch": 720.48,
      "learning_rate": 0.027981583272508045,
      "loss": 2.5256,
      "step": 448140
    },
    {
      "epoch": 720.51,
      "learning_rate": 0.027978367841639873,
      "loss": 2.5011,
      "step": 448160
    },
    {
      "epoch": 720.55,
      "learning_rate": 0.027975152410771705,
      "loss": 2.4936,
      "step": 448180
    },
    {
      "epoch": 720.58,
      "learning_rate": 0.027971936979903536,
      "loss": 2.5359,
      "step": 448200
    },
    {
      "epoch": 720.61,
      "learning_rate": 0.027968721549035364,
      "loss": 2.5107,
      "step": 448220
    },
    {
      "epoch": 720.64,
      "learning_rate": 0.0279655061181672,
      "loss": 2.5047,
      "step": 448240
    },
    {
      "epoch": 720.68,
      "learning_rate": 0.02796229068729904,
      "loss": 2.4884,
      "step": 448260
    },
    {
      "epoch": 720.71,
      "learning_rate": 0.027959075256430866,
      "loss": 2.4853,
      "step": 448280
    },
    {
      "epoch": 720.74,
      "learning_rate": 0.0279558598255627,
      "loss": 2.516,
      "step": 448300
    },
    {
      "epoch": 720.77,
      "learning_rate": 0.027952644394694533,
      "loss": 2.522,
      "step": 448320
    },
    {
      "epoch": 720.8,
      "learning_rate": 0.027949428963826364,
      "loss": 2.4969,
      "step": 448340
    },
    {
      "epoch": 720.84,
      "learning_rate": 0.027946213532958192,
      "loss": 2.5027,
      "step": 448360
    },
    {
      "epoch": 720.87,
      "learning_rate": 0.027942998102090034,
      "loss": 2.5174,
      "step": 448380
    },
    {
      "epoch": 720.9,
      "learning_rate": 0.027939782671221866,
      "loss": 2.5152,
      "step": 448400
    },
    {
      "epoch": 720.93,
      "learning_rate": 0.027936567240353694,
      "loss": 2.5082,
      "step": 448420
    },
    {
      "epoch": 720.96,
      "learning_rate": 0.02793335180948553,
      "loss": 2.5127,
      "step": 448440
    },
    {
      "epoch": 721.0,
      "learning_rate": 0.02793013637861736,
      "loss": 2.488,
      "step": 448460
    },
    {
      "epoch": 721.0,
      "eval_accuracy": {
        "accuracy": 0.43932208660499106
      },
      "eval_loss": 2.6172847747802734,
      "eval_runtime": 3.447,
      "eval_samples_per_second": 3731.643,
      "eval_steps_per_second": 58.311,
      "step": 448462
    },
    {
      "epoch": 721.03,
      "learning_rate": 0.027926920947749203,
      "loss": 2.5015,
      "step": 448480
    },
    {
      "epoch": 721.06,
      "learning_rate": 0.02792370551688103,
      "loss": 2.4981,
      "step": 448500
    },
    {
      "epoch": 721.09,
      "learning_rate": 0.027920490086012863,
      "loss": 2.5215,
      "step": 448520
    },
    {
      "epoch": 721.13,
      "learning_rate": 0.027917274655144694,
      "loss": 2.5114,
      "step": 448540
    },
    {
      "epoch": 721.16,
      "learning_rate": 0.027914059224276522,
      "loss": 2.5443,
      "step": 448560
    },
    {
      "epoch": 721.19,
      "learning_rate": 0.027910843793408354,
      "loss": 2.4999,
      "step": 448580
    },
    {
      "epoch": 721.22,
      "learning_rate": 0.027907628362540196,
      "loss": 2.492,
      "step": 448600
    },
    {
      "epoch": 721.25,
      "learning_rate": 0.027904412931672024,
      "loss": 2.5213,
      "step": 448620
    },
    {
      "epoch": 721.29,
      "learning_rate": 0.02790119750080386,
      "loss": 2.5018,
      "step": 448640
    },
    {
      "epoch": 721.32,
      "learning_rate": 0.02789798206993569,
      "loss": 2.5134,
      "step": 448660
    },
    {
      "epoch": 721.35,
      "learning_rate": 0.027894766639067523,
      "loss": 2.5209,
      "step": 448680
    },
    {
      "epoch": 721.38,
      "learning_rate": 0.02789155120819935,
      "loss": 2.5056,
      "step": 448700
    },
    {
      "epoch": 721.41,
      "learning_rate": 0.027888335777331193,
      "loss": 2.4919,
      "step": 448720
    },
    {
      "epoch": 721.45,
      "learning_rate": 0.027885120346463024,
      "loss": 2.4994,
      "step": 448740
    },
    {
      "epoch": 721.48,
      "learning_rate": 0.027881904915594852,
      "loss": 2.5016,
      "step": 448760
    },
    {
      "epoch": 721.51,
      "learning_rate": 0.027878689484726688,
      "loss": 2.5068,
      "step": 448780
    },
    {
      "epoch": 721.54,
      "learning_rate": 0.027875474053858512,
      "loss": 2.501,
      "step": 448800
    },
    {
      "epoch": 721.58,
      "learning_rate": 0.027872258622990354,
      "loss": 2.515,
      "step": 448820
    },
    {
      "epoch": 721.61,
      "learning_rate": 0.02786904319212219,
      "loss": 2.5197,
      "step": 448840
    },
    {
      "epoch": 721.64,
      "learning_rate": 0.02786582776125402,
      "loss": 2.4957,
      "step": 448860
    },
    {
      "epoch": 721.67,
      "learning_rate": 0.027862612330385852,
      "loss": 2.4983,
      "step": 448880
    },
    {
      "epoch": 721.7,
      "learning_rate": 0.02785939689951768,
      "loss": 2.5107,
      "step": 448900
    },
    {
      "epoch": 721.74,
      "learning_rate": 0.027856181468649512,
      "loss": 2.5012,
      "step": 448920
    },
    {
      "epoch": 721.77,
      "learning_rate": 0.027852966037781354,
      "loss": 2.5121,
      "step": 448940
    },
    {
      "epoch": 721.8,
      "learning_rate": 0.027849750606913182,
      "loss": 2.5101,
      "step": 448960
    },
    {
      "epoch": 721.83,
      "learning_rate": 0.027846535176045017,
      "loss": 2.5119,
      "step": 448980
    },
    {
      "epoch": 721.86,
      "learning_rate": 0.02784331974517685,
      "loss": 2.5219,
      "step": 449000
    },
    {
      "epoch": 721.9,
      "learning_rate": 0.02784010431430868,
      "loss": 2.522,
      "step": 449020
    },
    {
      "epoch": 721.93,
      "learning_rate": 0.02783688888344051,
      "loss": 2.5083,
      "step": 449040
    },
    {
      "epoch": 721.96,
      "learning_rate": 0.02783367345257235,
      "loss": 2.5009,
      "step": 449060
    },
    {
      "epoch": 721.99,
      "learning_rate": 0.027830458021704182,
      "loss": 2.4995,
      "step": 449080
    },
    {
      "epoch": 722.0,
      "eval_accuracy": {
        "accuracy": 0.43862240534867447
      },
      "eval_loss": 2.626722574234009,
      "eval_runtime": 3.1231,
      "eval_samples_per_second": 4118.624,
      "eval_steps_per_second": 64.359,
      "step": 449084
    },
    {
      "epoch": 722.03,
      "learning_rate": 0.02782724259083601,
      "loss": 2.5156,
      "step": 449100
    },
    {
      "epoch": 722.06,
      "learning_rate": 0.027824027159967842,
      "loss": 2.5057,
      "step": 449120
    },
    {
      "epoch": 722.09,
      "learning_rate": 0.02782081172909967,
      "loss": 2.5076,
      "step": 449140
    },
    {
      "epoch": 722.12,
      "learning_rate": 0.027817596298231512,
      "loss": 2.5199,
      "step": 449160
    },
    {
      "epoch": 722.15,
      "learning_rate": 0.027814380867363347,
      "loss": 2.5086,
      "step": 449180
    },
    {
      "epoch": 722.19,
      "learning_rate": 0.02781116543649518,
      "loss": 2.4915,
      "step": 449200
    },
    {
      "epoch": 722.22,
      "learning_rate": 0.02780795000562701,
      "loss": 2.5038,
      "step": 449220
    },
    {
      "epoch": 722.25,
      "learning_rate": 0.02780473457475884,
      "loss": 2.499,
      "step": 449240
    },
    {
      "epoch": 722.28,
      "learning_rate": 0.02780151914389067,
      "loss": 2.5119,
      "step": 449260
    },
    {
      "epoch": 722.32,
      "learning_rate": 0.027798303713022512,
      "loss": 2.5123,
      "step": 449280
    },
    {
      "epoch": 722.35,
      "learning_rate": 0.02779508828215434,
      "loss": 2.5001,
      "step": 449300
    },
    {
      "epoch": 722.38,
      "learning_rate": 0.027791872851286176,
      "loss": 2.4949,
      "step": 449320
    },
    {
      "epoch": 722.41,
      "learning_rate": 0.027788657420418,
      "loss": 2.4905,
      "step": 449340
    },
    {
      "epoch": 722.44,
      "learning_rate": 0.02778544198954984,
      "loss": 2.5037,
      "step": 449360
    },
    {
      "epoch": 722.48,
      "learning_rate": 0.027782226558681677,
      "loss": 2.5103,
      "step": 449380
    },
    {
      "epoch": 722.51,
      "learning_rate": 0.02777901112781351,
      "loss": 2.4984,
      "step": 449400
    },
    {
      "epoch": 722.54,
      "learning_rate": 0.02777579569694534,
      "loss": 2.5208,
      "step": 449420
    },
    {
      "epoch": 722.57,
      "learning_rate": 0.02777258026607717,
      "loss": 2.5184,
      "step": 449440
    },
    {
      "epoch": 722.6,
      "learning_rate": 0.027769364835209,
      "loss": 2.5043,
      "step": 449460
    },
    {
      "epoch": 722.64,
      "learning_rate": 0.02776614940434083,
      "loss": 2.4976,
      "step": 449480
    },
    {
      "epoch": 722.67,
      "learning_rate": 0.02776293397347267,
      "loss": 2.5095,
      "step": 449500
    },
    {
      "epoch": 722.7,
      "learning_rate": 0.027759718542604506,
      "loss": 2.4879,
      "step": 449520
    },
    {
      "epoch": 722.73,
      "learning_rate": 0.02775650311173633,
      "loss": 2.4808,
      "step": 449540
    },
    {
      "epoch": 722.77,
      "learning_rate": 0.02775328768086817,
      "loss": 2.5372,
      "step": 449560
    },
    {
      "epoch": 722.8,
      "learning_rate": 0.027750072249999997,
      "loss": 2.5223,
      "step": 449580
    },
    {
      "epoch": 722.83,
      "learning_rate": 0.02774685681913183,
      "loss": 2.5089,
      "step": 449600
    },
    {
      "epoch": 722.86,
      "learning_rate": 0.02774364138826367,
      "loss": 2.5048,
      "step": 449620
    },
    {
      "epoch": 722.89,
      "learning_rate": 0.0277404259573955,
      "loss": 2.5061,
      "step": 449640
    },
    {
      "epoch": 722.93,
      "learning_rate": 0.02773721052652733,
      "loss": 2.514,
      "step": 449660
    },
    {
      "epoch": 722.96,
      "learning_rate": 0.02773399509565916,
      "loss": 2.502,
      "step": 449680
    },
    {
      "epoch": 722.99,
      "learning_rate": 0.027730779664790997,
      "loss": 2.5177,
      "step": 449700
    },
    {
      "epoch": 723.0,
      "eval_accuracy": {
        "accuracy": 0.4404104796703724
      },
      "eval_loss": 2.609727382659912,
      "eval_runtime": 2.928,
      "eval_samples_per_second": 4393.05,
      "eval_steps_per_second": 68.647,
      "step": 449706
    },
    {
      "epoch": 723.02,
      "learning_rate": 0.027727564233922836,
      "loss": 2.5152,
      "step": 449720
    },
    {
      "epoch": 723.05,
      "learning_rate": 0.027724348803054667,
      "loss": 2.5027,
      "step": 449740
    },
    {
      "epoch": 723.09,
      "learning_rate": 0.0277211333721865,
      "loss": 2.504,
      "step": 449760
    },
    {
      "epoch": 723.12,
      "learning_rate": 0.027717917941318327,
      "loss": 2.4874,
      "step": 449780
    },
    {
      "epoch": 723.15,
      "learning_rate": 0.02771470251045016,
      "loss": 2.5,
      "step": 449800
    },
    {
      "epoch": 723.18,
      "learning_rate": 0.027711487079581987,
      "loss": 2.5058,
      "step": 449820
    },
    {
      "epoch": 723.22,
      "learning_rate": 0.02770827164871383,
      "loss": 2.5021,
      "step": 449840
    },
    {
      "epoch": 723.25,
      "learning_rate": 0.02770505621784566,
      "loss": 2.4901,
      "step": 449860
    },
    {
      "epoch": 723.28,
      "learning_rate": 0.02770184078697749,
      "loss": 2.5066,
      "step": 449880
    },
    {
      "epoch": 723.31,
      "learning_rate": 0.027698625356109327,
      "loss": 2.509,
      "step": 449900
    },
    {
      "epoch": 723.34,
      "learning_rate": 0.027695409925241155,
      "loss": 2.5042,
      "step": 449920
    },
    {
      "epoch": 723.38,
      "learning_rate": 0.027692194494372987,
      "loss": 2.5089,
      "step": 449940
    },
    {
      "epoch": 723.41,
      "learning_rate": 0.02768897906350483,
      "loss": 2.4964,
      "step": 449960
    },
    {
      "epoch": 723.44,
      "learning_rate": 0.027685763632636657,
      "loss": 2.5061,
      "step": 449980
    },
    {
      "epoch": 723.47,
      "learning_rate": 0.02768254820176849,
      "loss": 2.5218,
      "step": 450000
    },
    {
      "epoch": 723.5,
      "learning_rate": 0.027679332770900317,
      "loss": 2.5017,
      "step": 450020
    },
    {
      "epoch": 723.54,
      "learning_rate": 0.027676278111575567,
      "loss": 2.5114,
      "step": 450040
    },
    {
      "epoch": 723.57,
      "learning_rate": 0.02767306268070739,
      "loss": 2.5069,
      "step": 450060
    },
    {
      "epoch": 723.6,
      "learning_rate": 0.02766984724983922,
      "loss": 2.5026,
      "step": 450080
    },
    {
      "epoch": 723.63,
      "learning_rate": 0.02766663181897107,
      "loss": 2.5243,
      "step": 450100
    },
    {
      "epoch": 723.67,
      "learning_rate": 0.027663416388102897,
      "loss": 2.5082,
      "step": 450120
    },
    {
      "epoch": 723.7,
      "learning_rate": 0.02766020095723473,
      "loss": 2.5055,
      "step": 450140
    },
    {
      "epoch": 723.73,
      "learning_rate": 0.027656985526366556,
      "loss": 2.5104,
      "step": 450160
    },
    {
      "epoch": 723.76,
      "learning_rate": 0.027653770095498388,
      "loss": 2.5177,
      "step": 450180
    },
    {
      "epoch": 723.79,
      "learning_rate": 0.02765055466463023,
      "loss": 2.5012,
      "step": 450200
    },
    {
      "epoch": 723.83,
      "learning_rate": 0.027647339233762058,
      "loss": 2.5096,
      "step": 450220
    },
    {
      "epoch": 723.86,
      "learning_rate": 0.027644123802893897,
      "loss": 2.5023,
      "step": 450240
    },
    {
      "epoch": 723.89,
      "learning_rate": 0.02764090837202572,
      "loss": 2.496,
      "step": 450260
    },
    {
      "epoch": 723.92,
      "learning_rate": 0.02763769294115755,
      "loss": 2.4893,
      "step": 450280
    },
    {
      "epoch": 723.95,
      "learning_rate": 0.027634477510289385,
      "loss": 2.5019,
      "step": 450300
    },
    {
      "epoch": 723.99,
      "learning_rate": 0.027631262079421227,
      "loss": 2.4944,
      "step": 450320
    },
    {
      "epoch": 724.0,
      "eval_accuracy": {
        "accuracy": 0.4423540387156962
      },
      "eval_loss": 2.595219135284424,
      "eval_runtime": 3.117,
      "eval_samples_per_second": 4126.742,
      "eval_steps_per_second": 64.485,
      "step": 450328
    },
    {
      "epoch": 724.02,
      "learning_rate": 0.02762804664855306,
      "loss": 2.5036,
      "step": 450340
    },
    {
      "epoch": 724.05,
      "learning_rate": 0.027624831217684886,
      "loss": 2.5171,
      "step": 450360
    },
    {
      "epoch": 724.08,
      "learning_rate": 0.027621615786816718,
      "loss": 2.5032,
      "step": 450380
    },
    {
      "epoch": 724.12,
      "learning_rate": 0.02761840035594855,
      "loss": 2.5114,
      "step": 450400
    },
    {
      "epoch": 724.15,
      "learning_rate": 0.027615184925080378,
      "loss": 2.4928,
      "step": 450420
    },
    {
      "epoch": 724.18,
      "learning_rate": 0.027611969494212227,
      "loss": 2.4927,
      "step": 450440
    },
    {
      "epoch": 724.21,
      "learning_rate": 0.027608754063344055,
      "loss": 2.5023,
      "step": 450460
    },
    {
      "epoch": 724.24,
      "learning_rate": 0.02760553863247588,
      "loss": 2.5092,
      "step": 450480
    },
    {
      "epoch": 724.28,
      "learning_rate": 0.027602323201607715,
      "loss": 2.5103,
      "step": 450500
    },
    {
      "epoch": 724.31,
      "learning_rate": 0.027599107770739546,
      "loss": 2.5104,
      "step": 450520
    },
    {
      "epoch": 724.34,
      "learning_rate": 0.02759589233987139,
      "loss": 2.5006,
      "step": 450540
    },
    {
      "epoch": 724.37,
      "learning_rate": 0.027592676909003216,
      "loss": 2.4839,
      "step": 450560
    },
    {
      "epoch": 724.41,
      "learning_rate": 0.027589461478135048,
      "loss": 2.5047,
      "step": 450580
    },
    {
      "epoch": 724.44,
      "learning_rate": 0.02758624604726688,
      "loss": 2.4915,
      "step": 450600
    },
    {
      "epoch": 724.47,
      "learning_rate": 0.027583030616398708,
      "loss": 2.4909,
      "step": 450620
    },
    {
      "epoch": 724.5,
      "learning_rate": 0.027579815185530543,
      "loss": 2.4951,
      "step": 450640
    },
    {
      "epoch": 724.53,
      "learning_rate": 0.027576599754662385,
      "loss": 2.4976,
      "step": 450660
    },
    {
      "epoch": 724.57,
      "learning_rate": 0.027573384323794217,
      "loss": 2.5003,
      "step": 450680
    },
    {
      "epoch": 724.6,
      "learning_rate": 0.027570168892926045,
      "loss": 2.4921,
      "step": 450700
    },
    {
      "epoch": 724.63,
      "learning_rate": 0.027566953462057876,
      "loss": 2.529,
      "step": 450720
    },
    {
      "epoch": 724.66,
      "learning_rate": 0.027563738031189708,
      "loss": 2.5035,
      "step": 450740
    },
    {
      "epoch": 724.69,
      "learning_rate": 0.027560522600321536,
      "loss": 2.5126,
      "step": 450760
    },
    {
      "epoch": 724.73,
      "learning_rate": 0.027557307169453385,
      "loss": 2.5101,
      "step": 450780
    },
    {
      "epoch": 724.76,
      "learning_rate": 0.02755409173858521,
      "loss": 2.5115,
      "step": 450800
    },
    {
      "epoch": 724.79,
      "learning_rate": 0.027550876307717038,
      "loss": 2.5302,
      "step": 450820
    },
    {
      "epoch": 724.82,
      "learning_rate": 0.027547660876848873,
      "loss": 2.5172,
      "step": 450840
    },
    {
      "epoch": 724.86,
      "learning_rate": 0.027544445445980704,
      "loss": 2.4952,
      "step": 450860
    },
    {
      "epoch": 724.89,
      "learning_rate": 0.027541230015112547,
      "loss": 2.5048,
      "step": 450880
    },
    {
      "epoch": 724.92,
      "learning_rate": 0.027538014584244375,
      "loss": 2.5005,
      "step": 450900
    },
    {
      "epoch": 724.95,
      "learning_rate": 0.027534799153376206,
      "loss": 2.4994,
      "step": 450920
    },
    {
      "epoch": 724.98,
      "learning_rate": 0.027531583722508038,
      "loss": 2.5181,
      "step": 450940
    },
    {
      "epoch": 725.0,
      "eval_accuracy": {
        "accuracy": 0.44173209982119255
      },
      "eval_loss": 2.6117570400238037,
      "eval_runtime": 3.1974,
      "eval_samples_per_second": 4023.009,
      "eval_steps_per_second": 62.864,
      "step": 450950
    },
    {
      "epoch": 725.02,
      "learning_rate": 0.027528368291639866,
      "loss": 2.496,
      "step": 450960
    },
    {
      "epoch": 725.05,
      "learning_rate": 0.0275251528607717,
      "loss": 2.4702,
      "step": 450980
    },
    {
      "epoch": 725.08,
      "learning_rate": 0.027521937429903543,
      "loss": 2.5015,
      "step": 451000
    },
    {
      "epoch": 725.11,
      "learning_rate": 0.027518721999035368,
      "loss": 2.5067,
      "step": 451020
    },
    {
      "epoch": 725.14,
      "learning_rate": 0.027515506568167203,
      "loss": 2.5132,
      "step": 451040
    },
    {
      "epoch": 725.18,
      "learning_rate": 0.027512291137299034,
      "loss": 2.5032,
      "step": 451060
    },
    {
      "epoch": 725.21,
      "learning_rate": 0.027509075706430866,
      "loss": 2.5209,
      "step": 451080
    },
    {
      "epoch": 725.24,
      "learning_rate": 0.027505860275562694,
      "loss": 2.512,
      "step": 451100
    },
    {
      "epoch": 725.27,
      "learning_rate": 0.027502644844694536,
      "loss": 2.5065,
      "step": 451120
    },
    {
      "epoch": 725.31,
      "learning_rate": 0.027499429413826368,
      "loss": 2.5148,
      "step": 451140
    },
    {
      "epoch": 725.34,
      "learning_rate": 0.027496213982958196,
      "loss": 2.4997,
      "step": 451160
    },
    {
      "epoch": 725.37,
      "learning_rate": 0.02749299855209003,
      "loss": 2.5039,
      "step": 451180
    },
    {
      "epoch": 725.4,
      "learning_rate": 0.027489783121221863,
      "loss": 2.496,
      "step": 451200
    },
    {
      "epoch": 725.43,
      "learning_rate": 0.027486567690353698,
      "loss": 2.5128,
      "step": 451220
    },
    {
      "epoch": 725.47,
      "learning_rate": 0.027483352259485533,
      "loss": 2.5088,
      "step": 451240
    },
    {
      "epoch": 725.5,
      "learning_rate": 0.027480136828617364,
      "loss": 2.5089,
      "step": 451260
    },
    {
      "epoch": 725.53,
      "learning_rate": 0.027476921397749196,
      "loss": 2.5071,
      "step": 451280
    },
    {
      "epoch": 725.56,
      "learning_rate": 0.027473705966881024,
      "loss": 2.5024,
      "step": 451300
    },
    {
      "epoch": 725.59,
      "learning_rate": 0.027470490536012856,
      "loss": 2.5107,
      "step": 451320
    },
    {
      "epoch": 725.63,
      "learning_rate": 0.027467275105144698,
      "loss": 2.5021,
      "step": 451340
    },
    {
      "epoch": 725.66,
      "learning_rate": 0.027464059674276526,
      "loss": 2.5048,
      "step": 451360
    },
    {
      "epoch": 725.69,
      "learning_rate": 0.02746084424340836,
      "loss": 2.5024,
      "step": 451380
    },
    {
      "epoch": 725.72,
      "learning_rate": 0.027457628812540193,
      "loss": 2.5055,
      "step": 451400
    },
    {
      "epoch": 725.76,
      "learning_rate": 0.027454413381672024,
      "loss": 2.5164,
      "step": 451420
    },
    {
      "epoch": 725.79,
      "learning_rate": 0.027451197950803852,
      "loss": 2.5012,
      "step": 451440
    },
    {
      "epoch": 725.82,
      "learning_rate": 0.027447982519935694,
      "loss": 2.4831,
      "step": 451460
    },
    {
      "epoch": 725.85,
      "learning_rate": 0.027444767089067526,
      "loss": 2.5049,
      "step": 451480
    },
    {
      "epoch": 725.88,
      "learning_rate": 0.027441551658199354,
      "loss": 2.4903,
      "step": 451500
    },
    {
      "epoch": 725.92,
      "learning_rate": 0.02743833622733119,
      "loss": 2.5164,
      "step": 451520
    },
    {
      "epoch": 725.95,
      "learning_rate": 0.027435120796463014,
      "loss": 2.4983,
      "step": 451540
    },
    {
      "epoch": 725.98,
      "learning_rate": 0.027431905365594856,
      "loss": 2.5057,
      "step": 451560
    },
    {
      "epoch": 726.0,
      "eval_accuracy": {
        "accuracy": 0.4406437067558112
      },
      "eval_loss": 2.6284523010253906,
      "eval_runtime": 3.1153,
      "eval_samples_per_second": 4128.958,
      "eval_steps_per_second": 64.52,
      "step": 451572
    },
    {
      "epoch": 726.01,
      "learning_rate": 0.02742868993472669,
      "loss": 2.5284,
      "step": 451580
    },
    {
      "epoch": 726.05,
      "learning_rate": 0.027425474503858523,
      "loss": 2.5112,
      "step": 451600
    },
    {
      "epoch": 726.08,
      "learning_rate": 0.027422259072990354,
      "loss": 2.5045,
      "step": 451620
    },
    {
      "epoch": 726.11,
      "learning_rate": 0.027419043642122182,
      "loss": 2.5141,
      "step": 451640
    },
    {
      "epoch": 726.14,
      "learning_rate": 0.027415828211254014,
      "loss": 2.5051,
      "step": 451660
    },
    {
      "epoch": 726.17,
      "learning_rate": 0.027412612780385856,
      "loss": 2.4897,
      "step": 451680
    },
    {
      "epoch": 726.21,
      "learning_rate": 0.027409397349517684,
      "loss": 2.5066,
      "step": 451700
    },
    {
      "epoch": 726.24,
      "learning_rate": 0.02740618191864952,
      "loss": 2.4997,
      "step": 451720
    },
    {
      "epoch": 726.27,
      "learning_rate": 0.027402966487781344,
      "loss": 2.5076,
      "step": 451740
    },
    {
      "epoch": 726.3,
      "learning_rate": 0.027399751056913182,
      "loss": 2.5098,
      "step": 451760
    },
    {
      "epoch": 726.33,
      "learning_rate": 0.02739653562604502,
      "loss": 2.4946,
      "step": 451780
    },
    {
      "epoch": 726.37,
      "learning_rate": 0.027393320195176853,
      "loss": 2.4968,
      "step": 451800
    },
    {
      "epoch": 726.4,
      "learning_rate": 0.027390104764308684,
      "loss": 2.4943,
      "step": 451820
    },
    {
      "epoch": 726.43,
      "learning_rate": 0.027386889333440512,
      "loss": 2.5225,
      "step": 451840
    },
    {
      "epoch": 726.46,
      "learning_rate": 0.027383673902572344,
      "loss": 2.5217,
      "step": 451860
    },
    {
      "epoch": 726.5,
      "learning_rate": 0.027380458471704172,
      "loss": 2.5087,
      "step": 451880
    },
    {
      "epoch": 726.53,
      "learning_rate": 0.027377243040836014,
      "loss": 2.497,
      "step": 451900
    },
    {
      "epoch": 726.56,
      "learning_rate": 0.02737402760996785,
      "loss": 2.5094,
      "step": 451920
    },
    {
      "epoch": 726.59,
      "learning_rate": 0.02737081217909968,
      "loss": 2.5021,
      "step": 451940
    },
    {
      "epoch": 726.62,
      "learning_rate": 0.027367596748231512,
      "loss": 2.4922,
      "step": 451960
    },
    {
      "epoch": 726.66,
      "learning_rate": 0.02736438131736334,
      "loss": 2.506,
      "step": 451980
    },
    {
      "epoch": 726.69,
      "learning_rate": 0.027361165886495172,
      "loss": 2.4888,
      "step": 452000
    },
    {
      "epoch": 726.72,
      "learning_rate": 0.027357950455627014,
      "loss": 2.4915,
      "step": 452020
    },
    {
      "epoch": 726.75,
      "learning_rate": 0.027354895796302254,
      "loss": 2.4843,
      "step": 452040
    },
    {
      "epoch": 726.78,
      "learning_rate": 0.027351680365434086,
      "loss": 2.4729,
      "step": 452060
    },
    {
      "epoch": 726.82,
      "learning_rate": 0.027348464934565914,
      "loss": 2.4975,
      "step": 452080
    },
    {
      "epoch": 726.85,
      "learning_rate": 0.027345249503697752,
      "loss": 2.5183,
      "step": 452100
    },
    {
      "epoch": 726.88,
      "learning_rate": 0.02734203407282958,
      "loss": 2.5206,
      "step": 452120
    },
    {
      "epoch": 726.91,
      "learning_rate": 0.027338818641961405,
      "loss": 2.4955,
      "step": 452140
    },
    {
      "epoch": 726.95,
      "learning_rate": 0.027335603211093254,
      "loss": 2.4976,
      "step": 452160
    },
    {
      "epoch": 726.98,
      "learning_rate": 0.027332548551768494,
      "loss": 2.4951,
      "step": 452180
    },
    {
      "epoch": 727.0,
      "eval_accuracy": {
        "accuracy": 0.4432092046956387
      },
      "eval_loss": 2.6268515586853027,
      "eval_runtime": 3.0898,
      "eval_samples_per_second": 4163.087,
      "eval_steps_per_second": 65.053,
      "step": 452194
    },
    {
      "epoch": 727.01,
      "learning_rate": 0.027329333120900325,
      "loss": 2.5014,
      "step": 452200
    },
    {
      "epoch": 727.04,
      "learning_rate": 0.027326117690032153,
      "loss": 2.5126,
      "step": 452220
    },
    {
      "epoch": 727.07,
      "learning_rate": 0.027322902259163985,
      "loss": 2.4995,
      "step": 452240
    },
    {
      "epoch": 727.11,
      "learning_rate": 0.027319686828295817,
      "loss": 2.4777,
      "step": 452260
    },
    {
      "epoch": 727.14,
      "learning_rate": 0.027316471397427645,
      "loss": 2.4993,
      "step": 452280
    },
    {
      "epoch": 727.17,
      "learning_rate": 0.027313255966559494,
      "loss": 2.4703,
      "step": 452300
    },
    {
      "epoch": 727.2,
      "learning_rate": 0.027310040535691322,
      "loss": 2.4942,
      "step": 452320
    },
    {
      "epoch": 727.23,
      "learning_rate": 0.027306825104823153,
      "loss": 2.4635,
      "step": 452340
    },
    {
      "epoch": 727.27,
      "learning_rate": 0.02730360967395498,
      "loss": 2.5249,
      "step": 452360
    },
    {
      "epoch": 727.3,
      "learning_rate": 0.027300394243086813,
      "loss": 2.5081,
      "step": 452380
    },
    {
      "epoch": 727.33,
      "learning_rate": 0.027297178812218645,
      "loss": 2.5105,
      "step": 452400
    },
    {
      "epoch": 727.36,
      "learning_rate": 0.027293963381350483,
      "loss": 2.505,
      "step": 452420
    },
    {
      "epoch": 727.4,
      "learning_rate": 0.027290747950482322,
      "loss": 2.5019,
      "step": 452440
    },
    {
      "epoch": 727.43,
      "learning_rate": 0.027287532519614147,
      "loss": 2.5014,
      "step": 452460
    },
    {
      "epoch": 727.46,
      "learning_rate": 0.027284317088745975,
      "loss": 2.4975,
      "step": 452480
    },
    {
      "epoch": 727.49,
      "learning_rate": 0.02728110165787781,
      "loss": 2.5054,
      "step": 452500
    },
    {
      "epoch": 727.52,
      "learning_rate": 0.027277886227009652,
      "loss": 2.4852,
      "step": 452520
    },
    {
      "epoch": 727.56,
      "learning_rate": 0.027274670796141483,
      "loss": 2.5164,
      "step": 452540
    },
    {
      "epoch": 727.59,
      "learning_rate": 0.02727145536527331,
      "loss": 2.485,
      "step": 452560
    },
    {
      "epoch": 727.62,
      "learning_rate": 0.027268239934405143,
      "loss": 2.525,
      "step": 452580
    },
    {
      "epoch": 727.65,
      "learning_rate": 0.027265024503536975,
      "loss": 2.5249,
      "step": 452600
    },
    {
      "epoch": 727.68,
      "learning_rate": 0.027261809072668803,
      "loss": 2.5117,
      "step": 452620
    },
    {
      "epoch": 727.72,
      "learning_rate": 0.027258593641800652,
      "loss": 2.494,
      "step": 452640
    },
    {
      "epoch": 727.75,
      "learning_rate": 0.02725537821093248,
      "loss": 2.5128,
      "step": 452660
    },
    {
      "epoch": 727.78,
      "learning_rate": 0.027252162780064305,
      "loss": 2.498,
      "step": 452680
    },
    {
      "epoch": 727.81,
      "learning_rate": 0.02724894734919614,
      "loss": 2.4867,
      "step": 452700
    },
    {
      "epoch": 727.85,
      "learning_rate": 0.02724573191832797,
      "loss": 2.4812,
      "step": 452720
    },
    {
      "epoch": 727.88,
      "learning_rate": 0.027242516487459803,
      "loss": 2.5264,
      "step": 452740
    },
    {
      "epoch": 727.91,
      "learning_rate": 0.02723930105659164,
      "loss": 2.5276,
      "step": 452760
    },
    {
      "epoch": 727.94,
      "learning_rate": 0.027236085625723473,
      "loss": 2.5251,
      "step": 452780
    },
    {
      "epoch": 727.97,
      "learning_rate": 0.027232870194855305,
      "loss": 2.4768,
      "step": 452800
    },
    {
      "epoch": 728.0,
      "eval_accuracy": {
        "accuracy": 0.4425095234393221
      },
      "eval_loss": 2.612060785293579,
      "eval_runtime": 3.3735,
      "eval_samples_per_second": 3812.928,
      "eval_steps_per_second": 59.582,
      "step": 452816
    },
    {
      "epoch": 728.01,
      "learning_rate": 0.027229654763987133,
      "loss": 2.4935,
      "step": 452820
    },
    {
      "epoch": 728.04,
      "learning_rate": 0.027226439333118968,
      "loss": 2.5112,
      "step": 452840
    },
    {
      "epoch": 728.07,
      "learning_rate": 0.02722322390225081,
      "loss": 2.4705,
      "step": 452860
    },
    {
      "epoch": 728.1,
      "learning_rate": 0.027220008471382635,
      "loss": 2.4673,
      "step": 452880
    },
    {
      "epoch": 728.14,
      "learning_rate": 0.02721679304051447,
      "loss": 2.5394,
      "step": 452900
    },
    {
      "epoch": 728.17,
      "learning_rate": 0.0272135776096463,
      "loss": 2.5049,
      "step": 452920
    },
    {
      "epoch": 728.2,
      "learning_rate": 0.027210362178778133,
      "loss": 2.5004,
      "step": 452940
    },
    {
      "epoch": 728.23,
      "learning_rate": 0.02720714674790996,
      "loss": 2.5136,
      "step": 452960
    },
    {
      "epoch": 728.26,
      "learning_rate": 0.02720393131704181,
      "loss": 2.509,
      "step": 452980
    },
    {
      "epoch": 728.3,
      "learning_rate": 0.027200715886173635,
      "loss": 2.4998,
      "step": 453000
    },
    {
      "epoch": 728.33,
      "learning_rate": 0.027197500455305463,
      "loss": 2.4881,
      "step": 453020
    },
    {
      "epoch": 728.36,
      "learning_rate": 0.027194285024437298,
      "loss": 2.4867,
      "step": 453040
    },
    {
      "epoch": 728.39,
      "learning_rate": 0.02719106959356913,
      "loss": 2.4852,
      "step": 453060
    },
    {
      "epoch": 728.42,
      "learning_rate": 0.02718785416270096,
      "loss": 2.519,
      "step": 453080
    },
    {
      "epoch": 728.46,
      "learning_rate": 0.0271846387318328,
      "loss": 2.4783,
      "step": 453100
    },
    {
      "epoch": 728.49,
      "learning_rate": 0.02718142330096463,
      "loss": 2.5038,
      "step": 453120
    },
    {
      "epoch": 728.52,
      "learning_rate": 0.027178207870096463,
      "loss": 2.4972,
      "step": 453140
    },
    {
      "epoch": 728.55,
      "learning_rate": 0.02717499243922829,
      "loss": 2.4864,
      "step": 453160
    },
    {
      "epoch": 728.59,
      "learning_rate": 0.027171777008360126,
      "loss": 2.4965,
      "step": 453180
    },
    {
      "epoch": 728.62,
      "learning_rate": 0.027168561577491965,
      "loss": 2.5025,
      "step": 453200
    },
    {
      "epoch": 728.65,
      "learning_rate": 0.027165346146623793,
      "loss": 2.4937,
      "step": 453220
    },
    {
      "epoch": 728.68,
      "learning_rate": 0.027162130715755628,
      "loss": 2.5017,
      "step": 453240
    },
    {
      "epoch": 728.71,
      "learning_rate": 0.02715891528488746,
      "loss": 2.5027,
      "step": 453260
    },
    {
      "epoch": 728.75,
      "learning_rate": 0.02715569985401929,
      "loss": 2.5216,
      "step": 453280
    },
    {
      "epoch": 728.78,
      "learning_rate": 0.02715248442315112,
      "loss": 2.5013,
      "step": 453300
    },
    {
      "epoch": 728.81,
      "learning_rate": 0.02714926899228296,
      "loss": 2.5081,
      "step": 453320
    },
    {
      "epoch": 728.84,
      "learning_rate": 0.027146053561414793,
      "loss": 2.4875,
      "step": 453340
    },
    {
      "epoch": 728.87,
      "learning_rate": 0.02714283813054662,
      "loss": 2.509,
      "step": 453360
    },
    {
      "epoch": 728.91,
      "learning_rate": 0.027139622699678456,
      "loss": 2.4927,
      "step": 453380
    },
    {
      "epoch": 728.94,
      "learning_rate": 0.02713640726881028,
      "loss": 2.4853,
      "step": 453400
    },
    {
      "epoch": 728.97,
      "learning_rate": 0.027133191837942123,
      "loss": 2.5371,
      "step": 453420
    },
    {
      "epoch": 729.0,
      "eval_accuracy": {
        "accuracy": 0.4432092046956387
      },
      "eval_loss": 2.5968098640441895,
      "eval_runtime": 3.0736,
      "eval_samples_per_second": 4184.943,
      "eval_steps_per_second": 65.395,
      "step": 453438
    },
    {
      "epoch": 729.0,
      "learning_rate": 0.027129976407073958,
      "loss": 2.5109,
      "step": 453440
    },
    {
      "epoch": 729.04,
      "learning_rate": 0.02712676097620579,
      "loss": 2.5157,
      "step": 453460
    },
    {
      "epoch": 729.07,
      "learning_rate": 0.02712354554533762,
      "loss": 2.497,
      "step": 453480
    },
    {
      "epoch": 729.1,
      "learning_rate": 0.02712033011446945,
      "loss": 2.4822,
      "step": 453500
    },
    {
      "epoch": 729.13,
      "learning_rate": 0.02711711468360128,
      "loss": 2.4764,
      "step": 453520
    },
    {
      "epoch": 729.16,
      "learning_rate": 0.027113899252733123,
      "loss": 2.4708,
      "step": 453540
    },
    {
      "epoch": 729.2,
      "learning_rate": 0.02711068382186495,
      "loss": 2.5098,
      "step": 453560
    },
    {
      "epoch": 729.23,
      "learning_rate": 0.027107468390996786,
      "loss": 2.5,
      "step": 453580
    },
    {
      "epoch": 729.26,
      "learning_rate": 0.027104252960128618,
      "loss": 2.4933,
      "step": 453600
    },
    {
      "epoch": 729.29,
      "learning_rate": 0.02710103752926045,
      "loss": 2.4983,
      "step": 453620
    },
    {
      "epoch": 729.32,
      "learning_rate": 0.027097822098392278,
      "loss": 2.4885,
      "step": 453640
    },
    {
      "epoch": 729.36,
      "learning_rate": 0.02709460666752412,
      "loss": 2.5093,
      "step": 453660
    },
    {
      "epoch": 729.39,
      "learning_rate": 0.02709139123665595,
      "loss": 2.4946,
      "step": 453680
    },
    {
      "epoch": 729.42,
      "learning_rate": 0.02708817580578778,
      "loss": 2.5026,
      "step": 453700
    },
    {
      "epoch": 729.45,
      "learning_rate": 0.02708496037491961,
      "loss": 2.4995,
      "step": 453720
    },
    {
      "epoch": 729.49,
      "learning_rate": 0.02708174494405144,
      "loss": 2.5253,
      "step": 453740
    },
    {
      "epoch": 729.52,
      "learning_rate": 0.02707852951318328,
      "loss": 2.4754,
      "step": 453760
    },
    {
      "epoch": 729.55,
      "learning_rate": 0.027075314082315116,
      "loss": 2.4938,
      "step": 453780
    },
    {
      "epoch": 729.58,
      "learning_rate": 0.027072098651446948,
      "loss": 2.5005,
      "step": 453800
    },
    {
      "epoch": 729.61,
      "learning_rate": 0.02706888322057878,
      "loss": 2.5106,
      "step": 453820
    },
    {
      "epoch": 729.65,
      "learning_rate": 0.027065667789710608,
      "loss": 2.4982,
      "step": 453840
    },
    {
      "epoch": 729.68,
      "learning_rate": 0.02706245235884244,
      "loss": 2.5018,
      "step": 453860
    },
    {
      "epoch": 729.71,
      "learning_rate": 0.02705923692797428,
      "loss": 2.5259,
      "step": 453880
    },
    {
      "epoch": 729.74,
      "learning_rate": 0.02705602149710611,
      "loss": 2.5028,
      "step": 453900
    },
    {
      "epoch": 729.77,
      "learning_rate": 0.027052806066237944,
      "loss": 2.5014,
      "step": 453920
    },
    {
      "epoch": 729.81,
      "learning_rate": 0.02704959063536977,
      "loss": 2.5045,
      "step": 453940
    },
    {
      "epoch": 729.84,
      "learning_rate": 0.027046375204501608,
      "loss": 2.5177,
      "step": 453960
    },
    {
      "epoch": 729.87,
      "learning_rate": 0.027043159773633436,
      "loss": 2.5046,
      "step": 453980
    },
    {
      "epoch": 729.9,
      "learning_rate": 0.027039944342765278,
      "loss": 2.4995,
      "step": 454000
    },
    {
      "epoch": 729.94,
      "learning_rate": 0.02703672891189711,
      "loss": 2.496,
      "step": 454020
    },
    {
      "epoch": 729.97,
      "learning_rate": 0.027033513481028938,
      "loss": 2.4858,
      "step": 454040
    },
    {
      "epoch": 730.0,
      "learning_rate": 0.02703029805016077,
      "loss": 2.4946,
      "step": 454060
    },
    {
      "epoch": 730.0,
      "eval_accuracy": {
        "accuracy": 0.44188758454481847
      },
      "eval_loss": 2.611621141433716,
      "eval_runtime": 3.1028,
      "eval_samples_per_second": 4145.65,
      "eval_steps_per_second": 64.781,
      "step": 454060
    },
    {
      "epoch": 730.03,
      "learning_rate": 0.027027082619292597,
      "loss": 2.5094,
      "step": 454080
    },
    {
      "epoch": 730.06,
      "learning_rate": 0.02702386718842444,
      "loss": 2.5031,
      "step": 454100
    },
    {
      "epoch": 730.1,
      "learning_rate": 0.027020651757556274,
      "loss": 2.5062,
      "step": 454120
    },
    {
      "epoch": 730.13,
      "learning_rate": 0.027017436326688106,
      "loss": 2.5088,
      "step": 454140
    },
    {
      "epoch": 730.16,
      "learning_rate": 0.027014220895819938,
      "loss": 2.4949,
      "step": 454160
    },
    {
      "epoch": 730.19,
      "learning_rate": 0.027011005464951766,
      "loss": 2.4786,
      "step": 454180
    },
    {
      "epoch": 730.23,
      "learning_rate": 0.027007790034083597,
      "loss": 2.4883,
      "step": 454200
    },
    {
      "epoch": 730.26,
      "learning_rate": 0.02700457460321544,
      "loss": 2.5192,
      "step": 454220
    },
    {
      "epoch": 730.29,
      "learning_rate": 0.027001359172347267,
      "loss": 2.5132,
      "step": 454240
    },
    {
      "epoch": 730.32,
      "learning_rate": 0.0269981437414791,
      "loss": 2.4992,
      "step": 454260
    },
    {
      "epoch": 730.35,
      "learning_rate": 0.026994928310610927,
      "loss": 2.5067,
      "step": 454280
    },
    {
      "epoch": 730.39,
      "learning_rate": 0.026991712879742766,
      "loss": 2.5238,
      "step": 454300
    },
    {
      "epoch": 730.42,
      "learning_rate": 0.026988497448874594,
      "loss": 2.5036,
      "step": 454320
    },
    {
      "epoch": 730.45,
      "learning_rate": 0.026985282018006436,
      "loss": 2.4882,
      "step": 454340
    },
    {
      "epoch": 730.48,
      "learning_rate": 0.026982066587138268,
      "loss": 2.4946,
      "step": 454360
    },
    {
      "epoch": 730.51,
      "learning_rate": 0.026978851156270096,
      "loss": 2.4755,
      "step": 454380
    },
    {
      "epoch": 730.55,
      "learning_rate": 0.026975635725401927,
      "loss": 2.4951,
      "step": 454400
    },
    {
      "epoch": 730.58,
      "learning_rate": 0.026972420294533755,
      "loss": 2.5035,
      "step": 454420
    },
    {
      "epoch": 730.61,
      "learning_rate": 0.026969204863665597,
      "loss": 2.5125,
      "step": 454440
    },
    {
      "epoch": 730.64,
      "learning_rate": 0.026965989432797433,
      "loss": 2.5038,
      "step": 454460
    },
    {
      "epoch": 730.68,
      "learning_rate": 0.026962774001929257,
      "loss": 2.5094,
      "step": 454480
    },
    {
      "epoch": 730.71,
      "learning_rate": 0.026959558571061096,
      "loss": 2.4993,
      "step": 454500
    },
    {
      "epoch": 730.74,
      "learning_rate": 0.026956343140192924,
      "loss": 2.4975,
      "step": 454520
    },
    {
      "epoch": 730.77,
      "learning_rate": 0.026953127709324756,
      "loss": 2.5008,
      "step": 454540
    },
    {
      "epoch": 730.8,
      "learning_rate": 0.026949912278456598,
      "loss": 2.4983,
      "step": 454560
    },
    {
      "epoch": 730.84,
      "learning_rate": 0.026946696847588426,
      "loss": 2.5006,
      "step": 454580
    },
    {
      "epoch": 730.87,
      "learning_rate": 0.026943481416720257,
      "loss": 2.4741,
      "step": 454600
    },
    {
      "epoch": 730.9,
      "learning_rate": 0.026940265985852085,
      "loss": 2.4964,
      "step": 454620
    },
    {
      "epoch": 730.93,
      "learning_rate": 0.026937050554983924,
      "loss": 2.5023,
      "step": 454640
    },
    {
      "epoch": 730.96,
      "learning_rate": 0.02693399589565916,
      "loss": 2.4975,
      "step": 454660
    },
    {
      "epoch": 731.0,
      "learning_rate": 0.02693078046479099,
      "loss": 2.4941,
      "step": 454680
    },
    {
      "epoch": 731.0,
      "eval_accuracy": {
        "accuracy": 0.44305371997201276
      },
      "eval_loss": 2.6204333305358887,
      "eval_runtime": 3.0024,
      "eval_samples_per_second": 4284.26,
      "eval_steps_per_second": 66.947,
      "step": 454682
    },
    {
      "epoch": 731.03,
      "learning_rate": 0.026927565033922837,
      "loss": 2.4759,
      "step": 454700
    },
    {
      "epoch": 731.06,
      "learning_rate": 0.026924349603054665,
      "loss": 2.4759,
      "step": 454720
    },
    {
      "epoch": 731.09,
      "learning_rate": 0.026921134172186497,
      "loss": 2.4938,
      "step": 454740
    },
    {
      "epoch": 731.13,
      "learning_rate": 0.026917918741318325,
      "loss": 2.5047,
      "step": 454760
    },
    {
      "epoch": 731.16,
      "learning_rate": 0.026914703310450157,
      "loss": 2.4925,
      "step": 454780
    },
    {
      "epoch": 731.19,
      "learning_rate": 0.02691148787958199,
      "loss": 2.4978,
      "step": 454800
    },
    {
      "epoch": 731.22,
      "learning_rate": 0.026908272448713827,
      "loss": 2.4776,
      "step": 454820
    },
    {
      "epoch": 731.25,
      "learning_rate": 0.026905057017845666,
      "loss": 2.491,
      "step": 454840
    },
    {
      "epoch": 731.29,
      "learning_rate": 0.026901841586977494,
      "loss": 2.4956,
      "step": 454860
    },
    {
      "epoch": 731.32,
      "learning_rate": 0.02689862615610932,
      "loss": 2.5064,
      "step": 454880
    },
    {
      "epoch": 731.35,
      "learning_rate": 0.026895410725241153,
      "loss": 2.5025,
      "step": 454900
    },
    {
      "epoch": 731.38,
      "learning_rate": 0.026892195294372995,
      "loss": 2.5002,
      "step": 454920
    },
    {
      "epoch": 731.41,
      "learning_rate": 0.026888979863504827,
      "loss": 2.4934,
      "step": 454940
    },
    {
      "epoch": 731.45,
      "learning_rate": 0.026885764432636655,
      "loss": 2.4978,
      "step": 454960
    },
    {
      "epoch": 731.48,
      "learning_rate": 0.026882549001768487,
      "loss": 2.5112,
      "step": 454980
    },
    {
      "epoch": 731.51,
      "learning_rate": 0.02687933357090032,
      "loss": 2.4876,
      "step": 455000
    },
    {
      "epoch": 731.54,
      "learning_rate": 0.026876118140032147,
      "loss": 2.4926,
      "step": 455020
    },
    {
      "epoch": 731.58,
      "learning_rate": 0.026872902709163995,
      "loss": 2.4792,
      "step": 455040
    },
    {
      "epoch": 731.61,
      "learning_rate": 0.026869687278295824,
      "loss": 2.5051,
      "step": 455060
    },
    {
      "epoch": 731.64,
      "learning_rate": 0.02686647184742765,
      "loss": 2.5111,
      "step": 455080
    },
    {
      "epoch": 731.67,
      "learning_rate": 0.026863256416559483,
      "loss": 2.4996,
      "step": 455100
    },
    {
      "epoch": 731.7,
      "learning_rate": 0.026860040985691315,
      "loss": 2.4816,
      "step": 455120
    },
    {
      "epoch": 731.74,
      "learning_rate": 0.026856825554823147,
      "loss": 2.4933,
      "step": 455140
    },
    {
      "epoch": 731.77,
      "learning_rate": 0.026853610123954985,
      "loss": 2.4979,
      "step": 455160
    },
    {
      "epoch": 731.8,
      "learning_rate": 0.026850394693086824,
      "loss": 2.5056,
      "step": 455180
    },
    {
      "epoch": 731.83,
      "learning_rate": 0.02684717926221865,
      "loss": 2.5067,
      "step": 455200
    },
    {
      "epoch": 731.86,
      "learning_rate": 0.026843963831350477,
      "loss": 2.4978,
      "step": 455220
    },
    {
      "epoch": 731.9,
      "learning_rate": 0.02684074840048231,
      "loss": 2.5057,
      "step": 455240
    },
    {
      "epoch": 731.93,
      "learning_rate": 0.026837532969614154,
      "loss": 2.4854,
      "step": 455260
    },
    {
      "epoch": 731.96,
      "learning_rate": 0.026834317538745985,
      "loss": 2.4956,
      "step": 455280
    },
    {
      "epoch": 731.99,
      "learning_rate": 0.026831102107877813,
      "loss": 2.508,
      "step": 455300
    },
    {
      "epoch": 732.0,
      "eval_accuracy": {
        "accuracy": 0.43916660188136514
      },
      "eval_loss": 2.623154878616333,
      "eval_runtime": 2.9516,
      "eval_samples_per_second": 4357.963,
      "eval_steps_per_second": 68.098,
      "step": 455304
    },
    {
      "epoch": 732.03,
      "learning_rate": 0.026827886677009645,
      "loss": 2.5203,
      "step": 455320
    },
    {
      "epoch": 732.06,
      "learning_rate": 0.026824671246141477,
      "loss": 2.5024,
      "step": 455340
    },
    {
      "epoch": 732.09,
      "learning_rate": 0.026821455815273305,
      "loss": 2.4947,
      "step": 455360
    },
    {
      "epoch": 732.12,
      "learning_rate": 0.026818240384405154,
      "loss": 2.4824,
      "step": 455380
    },
    {
      "epoch": 732.15,
      "learning_rate": 0.02681502495353698,
      "loss": 2.4999,
      "step": 455400
    },
    {
      "epoch": 732.19,
      "learning_rate": 0.026811809522668806,
      "loss": 2.492,
      "step": 455420
    },
    {
      "epoch": 732.22,
      "learning_rate": 0.02680859409180064,
      "loss": 2.5052,
      "step": 455440
    },
    {
      "epoch": 732.25,
      "learning_rate": 0.026805378660932473,
      "loss": 2.5067,
      "step": 455460
    },
    {
      "epoch": 732.28,
      "learning_rate": 0.026802163230064305,
      "loss": 2.4825,
      "step": 455480
    },
    {
      "epoch": 732.32,
      "learning_rate": 0.026798947799196143,
      "loss": 2.4884,
      "step": 455500
    },
    {
      "epoch": 732.35,
      "learning_rate": 0.026795732368327975,
      "loss": 2.4914,
      "step": 455520
    },
    {
      "epoch": 732.38,
      "learning_rate": 0.026792516937459807,
      "loss": 2.4919,
      "step": 455540
    },
    {
      "epoch": 732.41,
      "learning_rate": 0.026789301506591635,
      "loss": 2.4941,
      "step": 455560
    },
    {
      "epoch": 732.44,
      "learning_rate": 0.02678608607572347,
      "loss": 2.4882,
      "step": 455580
    },
    {
      "epoch": 732.48,
      "learning_rate": 0.026782870644855312,
      "loss": 2.501,
      "step": 455600
    },
    {
      "epoch": 732.51,
      "learning_rate": 0.026779655213987136,
      "loss": 2.51,
      "step": 455620
    },
    {
      "epoch": 732.54,
      "learning_rate": 0.02677643978311897,
      "loss": 2.5013,
      "step": 455640
    },
    {
      "epoch": 732.57,
      "learning_rate": 0.026773224352250803,
      "loss": 2.4927,
      "step": 455660
    },
    {
      "epoch": 732.6,
      "learning_rate": 0.026770008921382635,
      "loss": 2.5024,
      "step": 455680
    },
    {
      "epoch": 732.64,
      "learning_rate": 0.026766793490514463,
      "loss": 2.4898,
      "step": 455700
    },
    {
      "epoch": 732.67,
      "learning_rate": 0.026763578059646305,
      "loss": 2.5135,
      "step": 455720
    },
    {
      "epoch": 732.7,
      "learning_rate": 0.026760362628778137,
      "loss": 2.5206,
      "step": 455740
    },
    {
      "epoch": 732.73,
      "learning_rate": 0.026757147197909965,
      "loss": 2.4901,
      "step": 455760
    },
    {
      "epoch": 732.77,
      "learning_rate": 0.0267539317670418,
      "loss": 2.4938,
      "step": 455780
    },
    {
      "epoch": 732.8,
      "learning_rate": 0.02675071633617363,
      "loss": 2.4957,
      "step": 455800
    },
    {
      "epoch": 732.83,
      "learning_rate": 0.026747500905305473,
      "loss": 2.4993,
      "step": 455820
    },
    {
      "epoch": 732.86,
      "learning_rate": 0.0267442854744373,
      "loss": 2.5108,
      "step": 455840
    },
    {
      "epoch": 732.89,
      "learning_rate": 0.026741070043569133,
      "loss": 2.4842,
      "step": 455860
    },
    {
      "epoch": 732.93,
      "learning_rate": 0.026737854612700965,
      "loss": 2.485,
      "step": 455880
    },
    {
      "epoch": 732.96,
      "learning_rate": 0.026734639181832793,
      "loss": 2.4973,
      "step": 455900
    },
    {
      "epoch": 732.99,
      "learning_rate": 0.026731423750964625,
      "loss": 2.5088,
      "step": 455920
    },
    {
      "epoch": 733.0,
      "eval_accuracy": {
        "accuracy": 0.4397107984140558
      },
      "eval_loss": 2.620882749557495,
      "eval_runtime": 3.0991,
      "eval_samples_per_second": 4150.541,
      "eval_steps_per_second": 64.857,
      "step": 455926
    },
    {
      "epoch": 733.02,
      "learning_rate": 0.026728208320096467,
      "loss": 2.4931,
      "step": 455940
    },
    {
      "epoch": 733.05,
      "learning_rate": 0.026724992889228295,
      "loss": 2.4982,
      "step": 455960
    },
    {
      "epoch": 733.09,
      "learning_rate": 0.02672177745836013,
      "loss": 2.5038,
      "step": 455980
    },
    {
      "epoch": 733.12,
      "learning_rate": 0.02671856202749196,
      "loss": 2.4796,
      "step": 456000
    },
    {
      "epoch": 733.15,
      "learning_rate": 0.026715346596623793,
      "loss": 2.4916,
      "step": 456020
    },
    {
      "epoch": 733.18,
      "learning_rate": 0.02671213116575562,
      "loss": 2.4943,
      "step": 456040
    },
    {
      "epoch": 733.22,
      "learning_rate": 0.026708915734887463,
      "loss": 2.5046,
      "step": 456060
    },
    {
      "epoch": 733.25,
      "learning_rate": 0.026705700304019295,
      "loss": 2.5152,
      "step": 456080
    },
    {
      "epoch": 733.28,
      "learning_rate": 0.026702484873151123,
      "loss": 2.5114,
      "step": 456100
    },
    {
      "epoch": 733.31,
      "learning_rate": 0.026699269442282958,
      "loss": 2.5108,
      "step": 456120
    },
    {
      "epoch": 733.34,
      "learning_rate": 0.026696054011414783,
      "loss": 2.5015,
      "step": 456140
    },
    {
      "epoch": 733.38,
      "learning_rate": 0.026692838580546625,
      "loss": 2.4984,
      "step": 456160
    },
    {
      "epoch": 733.41,
      "learning_rate": 0.02668962314967846,
      "loss": 2.4808,
      "step": 456180
    },
    {
      "epoch": 733.44,
      "learning_rate": 0.02668640771881029,
      "loss": 2.495,
      "step": 456200
    },
    {
      "epoch": 733.47,
      "learning_rate": 0.026683192287942123,
      "loss": 2.4897,
      "step": 456220
    },
    {
      "epoch": 733.5,
      "learning_rate": 0.02667997685707395,
      "loss": 2.4905,
      "step": 456240
    },
    {
      "epoch": 733.54,
      "learning_rate": 0.026676761426205783,
      "loss": 2.4991,
      "step": 456260
    },
    {
      "epoch": 733.57,
      "learning_rate": 0.026673545995337625,
      "loss": 2.4965,
      "step": 456280
    },
    {
      "epoch": 733.6,
      "learning_rate": 0.026670330564469453,
      "loss": 2.5091,
      "step": 456300
    },
    {
      "epoch": 733.63,
      "learning_rate": 0.026667115133601288,
      "loss": 2.5206,
      "step": 456320
    },
    {
      "epoch": 733.67,
      "learning_rate": 0.02666389970273312,
      "loss": 2.4972,
      "step": 456340
    },
    {
      "epoch": 733.7,
      "learning_rate": 0.02666068427186495,
      "loss": 2.4866,
      "step": 456360
    },
    {
      "epoch": 733.73,
      "learning_rate": 0.02665746884099678,
      "loss": 2.4903,
      "step": 456380
    },
    {
      "epoch": 733.76,
      "learning_rate": 0.02665425341012862,
      "loss": 2.5142,
      "step": 456400
    },
    {
      "epoch": 733.79,
      "learning_rate": 0.026651037979260453,
      "loss": 2.5041,
      "step": 456420
    },
    {
      "epoch": 733.83,
      "learning_rate": 0.02664782254839228,
      "loss": 2.4898,
      "step": 456440
    },
    {
      "epoch": 733.86,
      "learning_rate": 0.026644607117524113,
      "loss": 2.5012,
      "step": 456460
    },
    {
      "epoch": 733.89,
      "learning_rate": 0.02664139168665594,
      "loss": 2.487,
      "step": 456480
    },
    {
      "epoch": 733.92,
      "learning_rate": 0.026638176255787783,
      "loss": 2.4946,
      "step": 456500
    },
    {
      "epoch": 733.95,
      "learning_rate": 0.026634960824919618,
      "loss": 2.4915,
      "step": 456520
    },
    {
      "epoch": 733.99,
      "learning_rate": 0.02663174539405145,
      "loss": 2.5071,
      "step": 456540
    },
    {
      "epoch": 734.0,
      "eval_accuracy": {
        "accuracy": 0.4431314623338257
      },
      "eval_loss": 2.618861436843872,
      "eval_runtime": 3.0364,
      "eval_samples_per_second": 4236.203,
      "eval_steps_per_second": 66.196,
      "step": 456548
    },
    {
      "epoch": 734.02,
      "learning_rate": 0.02662852996318328,
      "loss": 2.5101,
      "step": 456560
    },
    {
      "epoch": 734.05,
      "learning_rate": 0.02662531453231511,
      "loss": 2.4778,
      "step": 456580
    },
    {
      "epoch": 734.08,
      "learning_rate": 0.02662209910144694,
      "loss": 2.4989,
      "step": 456600
    },
    {
      "epoch": 734.12,
      "learning_rate": 0.026618883670578783,
      "loss": 2.4973,
      "step": 456620
    },
    {
      "epoch": 734.15,
      "learning_rate": 0.02661566823971061,
      "loss": 2.5002,
      "step": 456640
    },
    {
      "epoch": 734.18,
      "learning_rate": 0.026612452808842446,
      "loss": 2.493,
      "step": 456660
    },
    {
      "epoch": 734.21,
      "learning_rate": 0.02660923737797427,
      "loss": 2.4887,
      "step": 456680
    },
    {
      "epoch": 734.24,
      "learning_rate": 0.02660602194710611,
      "loss": 2.5005,
      "step": 456700
    },
    {
      "epoch": 734.28,
      "learning_rate": 0.02660296728778135,
      "loss": 2.5229,
      "step": 456720
    },
    {
      "epoch": 734.31,
      "learning_rate": 0.02659975185691318,
      "loss": 2.4865,
      "step": 456740
    },
    {
      "epoch": 734.34,
      "learning_rate": 0.026596536426045023,
      "loss": 2.4956,
      "step": 456760
    },
    {
      "epoch": 734.37,
      "learning_rate": 0.02659332099517685,
      "loss": 2.4913,
      "step": 456780
    },
    {
      "epoch": 734.41,
      "learning_rate": 0.026590105564308682,
      "loss": 2.5055,
      "step": 456800
    },
    {
      "epoch": 734.44,
      "learning_rate": 0.02658689013344051,
      "loss": 2.5319,
      "step": 456820
    },
    {
      "epoch": 734.47,
      "learning_rate": 0.02658367470257235,
      "loss": 2.4919,
      "step": 456840
    },
    {
      "epoch": 734.5,
      "learning_rate": 0.026580459271704174,
      "loss": 2.5138,
      "step": 456860
    },
    {
      "epoch": 734.53,
      "learning_rate": 0.026577243840836012,
      "loss": 2.4934,
      "step": 456880
    },
    {
      "epoch": 734.57,
      "learning_rate": 0.02657402840996785,
      "loss": 2.4864,
      "step": 456900
    },
    {
      "epoch": 734.6,
      "learning_rate": 0.02657081297909968,
      "loss": 2.4899,
      "step": 456920
    },
    {
      "epoch": 734.63,
      "learning_rate": 0.02656759754823151,
      "loss": 2.5128,
      "step": 456940
    },
    {
      "epoch": 734.66,
      "learning_rate": 0.02656438211736334,
      "loss": 2.4959,
      "step": 456960
    },
    {
      "epoch": 734.69,
      "learning_rate": 0.02656116668649518,
      "loss": 2.5027,
      "step": 456980
    },
    {
      "epoch": 734.73,
      "learning_rate": 0.026557951255627012,
      "loss": 2.4872,
      "step": 457000
    },
    {
      "epoch": 734.76,
      "learning_rate": 0.02655473582475884,
      "loss": 2.4821,
      "step": 457020
    },
    {
      "epoch": 734.79,
      "learning_rate": 0.02655152039389068,
      "loss": 2.4948,
      "step": 457040
    },
    {
      "epoch": 734.82,
      "learning_rate": 0.026548304963022507,
      "loss": 2.4824,
      "step": 457060
    },
    {
      "epoch": 734.86,
      "learning_rate": 0.026545089532154332,
      "loss": 2.4676,
      "step": 457080
    },
    {
      "epoch": 734.89,
      "learning_rate": 0.02654187410128618,
      "loss": 2.4937,
      "step": 457100
    },
    {
      "epoch": 734.92,
      "learning_rate": 0.02653865867041801,
      "loss": 2.4941,
      "step": 457120
    },
    {
      "epoch": 734.95,
      "learning_rate": 0.02653544323954984,
      "loss": 2.503,
      "step": 457140
    },
    {
      "epoch": 734.98,
      "learning_rate": 0.02653222780868167,
      "loss": 2.5019,
      "step": 457160
    },
    {
      "epoch": 735.0,
      "eval_accuracy": {
        "accuracy": 0.442665008162948
      },
      "eval_loss": 2.6123740673065186,
      "eval_runtime": 3.3561,
      "eval_samples_per_second": 3832.761,
      "eval_steps_per_second": 59.892,
      "step": 457170
    },
    {
      "epoch": 735.02,
      "learning_rate": 0.0265290123778135,
      "loss": 2.4925,
      "step": 457180
    },
    {
      "epoch": 735.05,
      "learning_rate": 0.026525796946945332,
      "loss": 2.5108,
      "step": 457200
    },
    {
      "epoch": 735.08,
      "learning_rate": 0.02652258151607717,
      "loss": 2.483,
      "step": 457220
    },
    {
      "epoch": 735.11,
      "learning_rate": 0.02651936608520901,
      "loss": 2.4855,
      "step": 457240
    },
    {
      "epoch": 735.14,
      "learning_rate": 0.026516150654340837,
      "loss": 2.4813,
      "step": 457260
    },
    {
      "epoch": 735.18,
      "learning_rate": 0.026512935223472662,
      "loss": 2.4956,
      "step": 457280
    },
    {
      "epoch": 735.21,
      "learning_rate": 0.026509719792604497,
      "loss": 2.514,
      "step": 457300
    },
    {
      "epoch": 735.24,
      "learning_rate": 0.02650650436173634,
      "loss": 2.5064,
      "step": 457320
    },
    {
      "epoch": 735.27,
      "learning_rate": 0.02650328893086817,
      "loss": 2.474,
      "step": 457340
    },
    {
      "epoch": 735.31,
      "learning_rate": 0.0265000735,
      "loss": 2.4939,
      "step": 457360
    },
    {
      "epoch": 735.34,
      "learning_rate": 0.026496858069131837,
      "loss": 2.4815,
      "step": 457380
    },
    {
      "epoch": 735.37,
      "learning_rate": 0.026493642638263662,
      "loss": 2.5039,
      "step": 457400
    },
    {
      "epoch": 735.4,
      "learning_rate": 0.02649042720739549,
      "loss": 2.4836,
      "step": 457420
    },
    {
      "epoch": 735.43,
      "learning_rate": 0.02648721177652734,
      "loss": 2.4932,
      "step": 457440
    },
    {
      "epoch": 735.47,
      "learning_rate": 0.026483996345659167,
      "loss": 2.4679,
      "step": 457460
    },
    {
      "epoch": 735.5,
      "learning_rate": 0.026480780914791,
      "loss": 2.4912,
      "step": 457480
    },
    {
      "epoch": 735.53,
      "learning_rate": 0.026477565483922827,
      "loss": 2.5039,
      "step": 457500
    },
    {
      "epoch": 735.56,
      "learning_rate": 0.02647435005305466,
      "loss": 2.4815,
      "step": 457520
    },
    {
      "epoch": 735.59,
      "learning_rate": 0.02647113462218649,
      "loss": 2.5085,
      "step": 457540
    },
    {
      "epoch": 735.63,
      "learning_rate": 0.02646791919131833,
      "loss": 2.4889,
      "step": 457560
    },
    {
      "epoch": 735.66,
      "learning_rate": 0.026464703760450167,
      "loss": 2.48,
      "step": 457580
    },
    {
      "epoch": 735.69,
      "learning_rate": 0.026461488329581992,
      "loss": 2.4859,
      "step": 457600
    },
    {
      "epoch": 735.72,
      "learning_rate": 0.02645827289871382,
      "loss": 2.5038,
      "step": 457620
    },
    {
      "epoch": 735.76,
      "learning_rate": 0.026455057467845655,
      "loss": 2.509,
      "step": 457640
    },
    {
      "epoch": 735.79,
      "learning_rate": 0.026451842036977497,
      "loss": 2.4964,
      "step": 457660
    },
    {
      "epoch": 735.82,
      "learning_rate": 0.02644862660610933,
      "loss": 2.4896,
      "step": 457680
    },
    {
      "epoch": 735.85,
      "learning_rate": 0.026445411175241157,
      "loss": 2.4857,
      "step": 457700
    },
    {
      "epoch": 735.88,
      "learning_rate": 0.02644219574437299,
      "loss": 2.4987,
      "step": 457720
    },
    {
      "epoch": 735.92,
      "learning_rate": 0.02643898031350482,
      "loss": 2.482,
      "step": 457740
    },
    {
      "epoch": 735.95,
      "learning_rate": 0.02643576488263665,
      "loss": 2.4959,
      "step": 457760
    },
    {
      "epoch": 735.98,
      "learning_rate": 0.026432549451768497,
      "loss": 2.4875,
      "step": 457780
    },
    {
      "epoch": 736.0,
      "eval_accuracy": {
        "accuracy": 0.44188758454481847
      },
      "eval_loss": 2.6149356365203857,
      "eval_runtime": 3.1204,
      "eval_samples_per_second": 4122.287,
      "eval_steps_per_second": 64.416,
      "step": 457792
    },
    {
      "epoch": 736.01,
      "learning_rate": 0.026429334020900325,
      "loss": 2.4974,
      "step": 457800
    },
    {
      "epoch": 736.05,
      "learning_rate": 0.02642611859003215,
      "loss": 2.4623,
      "step": 457820
    },
    {
      "epoch": 736.08,
      "learning_rate": 0.026422903159163985,
      "loss": 2.4809,
      "step": 457840
    },
    {
      "epoch": 736.11,
      "learning_rate": 0.026419687728295817,
      "loss": 2.4898,
      "step": 457860
    },
    {
      "epoch": 736.14,
      "learning_rate": 0.02641647229742765,
      "loss": 2.5059,
      "step": 457880
    },
    {
      "epoch": 736.17,
      "learning_rate": 0.026413256866559487,
      "loss": 2.4874,
      "step": 457900
    },
    {
      "epoch": 736.21,
      "learning_rate": 0.02641004143569132,
      "loss": 2.4831,
      "step": 457920
    },
    {
      "epoch": 736.24,
      "learning_rate": 0.02640682600482315,
      "loss": 2.4684,
      "step": 457940
    },
    {
      "epoch": 736.27,
      "learning_rate": 0.026403610573954978,
      "loss": 2.4761,
      "step": 457960
    },
    {
      "epoch": 736.3,
      "learning_rate": 0.026400395143086813,
      "loss": 2.4771,
      "step": 457980
    },
    {
      "epoch": 736.33,
      "learning_rate": 0.026397179712218655,
      "loss": 2.4872,
      "step": 458000
    },
    {
      "epoch": 736.37,
      "learning_rate": 0.026393964281350487,
      "loss": 2.4953,
      "step": 458020
    },
    {
      "epoch": 736.4,
      "learning_rate": 0.026390748850482315,
      "loss": 2.4826,
      "step": 458040
    },
    {
      "epoch": 736.43,
      "learning_rate": 0.026387533419614147,
      "loss": 2.4963,
      "step": 458060
    },
    {
      "epoch": 736.46,
      "learning_rate": 0.02638431798874598,
      "loss": 2.5079,
      "step": 458080
    },
    {
      "epoch": 736.5,
      "learning_rate": 0.026381102557877806,
      "loss": 2.4974,
      "step": 458100
    },
    {
      "epoch": 736.53,
      "learning_rate": 0.026377887127009655,
      "loss": 2.5097,
      "step": 458120
    },
    {
      "epoch": 736.56,
      "learning_rate": 0.02637467169614148,
      "loss": 2.5061,
      "step": 458140
    },
    {
      "epoch": 736.59,
      "learning_rate": 0.026371456265273308,
      "loss": 2.4994,
      "step": 458160
    },
    {
      "epoch": 736.62,
      "learning_rate": 0.026368240834405143,
      "loss": 2.5151,
      "step": 458180
    },
    {
      "epoch": 736.66,
      "learning_rate": 0.026365025403536975,
      "loss": 2.5022,
      "step": 458200
    },
    {
      "epoch": 736.69,
      "learning_rate": 0.026361809972668807,
      "loss": 2.4875,
      "step": 458220
    },
    {
      "epoch": 736.72,
      "learning_rate": 0.026358594541800645,
      "loss": 2.4913,
      "step": 458240
    },
    {
      "epoch": 736.75,
      "learning_rate": 0.026355379110932477,
      "loss": 2.5171,
      "step": 458260
    },
    {
      "epoch": 736.78,
      "learning_rate": 0.02635216368006431,
      "loss": 2.4887,
      "step": 458280
    },
    {
      "epoch": 736.82,
      "learning_rate": 0.026348948249196136,
      "loss": 2.4988,
      "step": 458300
    },
    {
      "epoch": 736.85,
      "learning_rate": 0.02634573281832797,
      "loss": 2.5044,
      "step": 458320
    },
    {
      "epoch": 736.88,
      "learning_rate": 0.026342517387459814,
      "loss": 2.4936,
      "step": 458340
    },
    {
      "epoch": 736.91,
      "learning_rate": 0.026339301956591638,
      "loss": 2.4852,
      "step": 458360
    },
    {
      "epoch": 736.95,
      "learning_rate": 0.026336086525723473,
      "loss": 2.4938,
      "step": 458380
    },
    {
      "epoch": 736.98,
      "learning_rate": 0.026332871094855305,
      "loss": 2.4882,
      "step": 458400
    },
    {
      "epoch": 737.0,
      "eval_accuracy": {
        "accuracy": 0.44002176786130764
      },
      "eval_loss": 2.619569778442383,
      "eval_runtime": 3.0855,
      "eval_samples_per_second": 4168.832,
      "eval_steps_per_second": 65.143,
      "step": 458414
    },
    {
      "epoch": 737.01,
      "learning_rate": 0.026329655663987137,
      "loss": 2.5165,
      "step": 458420
    },
    {
      "epoch": 737.04,
      "learning_rate": 0.026326440233118965,
      "loss": 2.5166,
      "step": 458440
    },
    {
      "epoch": 737.07,
      "learning_rate": 0.026323224802250807,
      "loss": 2.4743,
      "step": 458460
    },
    {
      "epoch": 737.11,
      "learning_rate": 0.02632000937138264,
      "loss": 2.4636,
      "step": 458480
    },
    {
      "epoch": 737.14,
      "learning_rate": 0.026316793940514466,
      "loss": 2.5089,
      "step": 458500
    },
    {
      "epoch": 737.17,
      "learning_rate": 0.0263135785096463,
      "loss": 2.4838,
      "step": 458520
    },
    {
      "epoch": 737.2,
      "learning_rate": 0.026310363078778133,
      "loss": 2.481,
      "step": 458540
    },
    {
      "epoch": 737.23,
      "learning_rate": 0.026307147647909975,
      "loss": 2.5026,
      "step": 458560
    },
    {
      "epoch": 737.27,
      "learning_rate": 0.026303932217041803,
      "loss": 2.4875,
      "step": 458580
    },
    {
      "epoch": 737.3,
      "learning_rate": 0.026300716786173635,
      "loss": 2.5113,
      "step": 458600
    },
    {
      "epoch": 737.33,
      "learning_rate": 0.026297501355305467,
      "loss": 2.5017,
      "step": 458620
    },
    {
      "epoch": 737.36,
      "learning_rate": 0.026294285924437295,
      "loss": 2.4997,
      "step": 458640
    },
    {
      "epoch": 737.4,
      "learning_rate": 0.026291070493569126,
      "loss": 2.5088,
      "step": 458660
    },
    {
      "epoch": 737.43,
      "learning_rate": 0.02628785506270097,
      "loss": 2.4834,
      "step": 458680
    },
    {
      "epoch": 737.46,
      "learning_rate": 0.026284639631832796,
      "loss": 2.5021,
      "step": 458700
    },
    {
      "epoch": 737.49,
      "learning_rate": 0.02628142420096463,
      "loss": 2.5005,
      "step": 458720
    },
    {
      "epoch": 737.52,
      "learning_rate": 0.026278208770096463,
      "loss": 2.4879,
      "step": 458740
    },
    {
      "epoch": 737.56,
      "learning_rate": 0.026274993339228295,
      "loss": 2.4922,
      "step": 458760
    },
    {
      "epoch": 737.59,
      "learning_rate": 0.026271938679903534,
      "loss": 2.5032,
      "step": 458780
    },
    {
      "epoch": 737.62,
      "learning_rate": 0.026268723249035366,
      "loss": 2.4825,
      "step": 458800
    },
    {
      "epoch": 737.65,
      "learning_rate": 0.026265507818167208,
      "loss": 2.4893,
      "step": 458820
    },
    {
      "epoch": 737.68,
      "learning_rate": 0.026262292387299036,
      "loss": 2.48,
      "step": 458840
    },
    {
      "epoch": 737.72,
      "learning_rate": 0.026259076956430868,
      "loss": 2.4909,
      "step": 458860
    },
    {
      "epoch": 737.75,
      "learning_rate": 0.026255861525562696,
      "loss": 2.4916,
      "step": 458880
    },
    {
      "epoch": 737.78,
      "learning_rate": 0.026252646094694534,
      "loss": 2.4978,
      "step": 458900
    },
    {
      "epoch": 737.81,
      "learning_rate": 0.026249430663826363,
      "loss": 2.4783,
      "step": 458920
    },
    {
      "epoch": 737.85,
      "learning_rate": 0.026246215232958205,
      "loss": 2.4929,
      "step": 458940
    },
    {
      "epoch": 737.88,
      "learning_rate": 0.026242999802090036,
      "loss": 2.5025,
      "step": 458960
    },
    {
      "epoch": 737.91,
      "learning_rate": 0.026239784371221864,
      "loss": 2.5134,
      "step": 458980
    },
    {
      "epoch": 737.94,
      "learning_rate": 0.026236568940353696,
      "loss": 2.497,
      "step": 459000
    },
    {
      "epoch": 737.97,
      "learning_rate": 0.026233353509485524,
      "loss": 2.4866,
      "step": 459020
    },
    {
      "epoch": 738.0,
      "eval_accuracy": {
        "accuracy": 0.44079919147943714
      },
      "eval_loss": 2.59916353225708,
      "eval_runtime": 2.9663,
      "eval_samples_per_second": 4336.414,
      "eval_steps_per_second": 67.762,
      "step": 459036
    },
    {
      "epoch": 738.01,
      "learning_rate": 0.026230138078617363,
      "loss": 2.4896,
      "step": 459040
    },
    {
      "epoch": 738.04,
      "learning_rate": 0.0262269226477492,
      "loss": 2.4625,
      "step": 459060
    },
    {
      "epoch": 738.07,
      "learning_rate": 0.026223707216881026,
      "loss": 2.4951,
      "step": 459080
    },
    {
      "epoch": 738.1,
      "learning_rate": 0.026220491786012864,
      "loss": 2.4874,
      "step": 459100
    },
    {
      "epoch": 738.14,
      "learning_rate": 0.026217276355144693,
      "loss": 2.4906,
      "step": 459120
    },
    {
      "epoch": 738.17,
      "learning_rate": 0.026214060924276524,
      "loss": 2.4841,
      "step": 459140
    },
    {
      "epoch": 738.2,
      "learning_rate": 0.026210845493408366,
      "loss": 2.5062,
      "step": 459160
    },
    {
      "epoch": 738.23,
      "learning_rate": 0.026207630062540194,
      "loss": 2.4936,
      "step": 459180
    },
    {
      "epoch": 738.26,
      "learning_rate": 0.026204414631672026,
      "loss": 2.5044,
      "step": 459200
    },
    {
      "epoch": 738.3,
      "learning_rate": 0.026201199200803854,
      "loss": 2.4973,
      "step": 459220
    },
    {
      "epoch": 738.33,
      "learning_rate": 0.026197983769935693,
      "loss": 2.5033,
      "step": 459240
    },
    {
      "epoch": 738.36,
      "learning_rate": 0.02619476833906752,
      "loss": 2.5035,
      "step": 459260
    },
    {
      "epoch": 738.39,
      "learning_rate": 0.026191552908199363,
      "loss": 2.5064,
      "step": 459280
    },
    {
      "epoch": 738.42,
      "learning_rate": 0.026188337477331194,
      "loss": 2.4717,
      "step": 459300
    },
    {
      "epoch": 738.46,
      "learning_rate": 0.026185122046463023,
      "loss": 2.4909,
      "step": 459320
    },
    {
      "epoch": 738.49,
      "learning_rate": 0.026181906615594854,
      "loss": 2.5078,
      "step": 459340
    },
    {
      "epoch": 738.52,
      "learning_rate": 0.026178691184726682,
      "loss": 2.5041,
      "step": 459360
    },
    {
      "epoch": 738.55,
      "learning_rate": 0.026175475753858524,
      "loss": 2.5108,
      "step": 459380
    },
    {
      "epoch": 738.59,
      "learning_rate": 0.026172260322990356,
      "loss": 2.49,
      "step": 459400
    },
    {
      "epoch": 738.62,
      "learning_rate": 0.026169044892122184,
      "loss": 2.5082,
      "step": 459420
    },
    {
      "epoch": 738.65,
      "learning_rate": 0.026165829461254023,
      "loss": 2.489,
      "step": 459440
    },
    {
      "epoch": 738.68,
      "learning_rate": 0.02616261403038585,
      "loss": 2.4914,
      "step": 459460
    },
    {
      "epoch": 738.71,
      "learning_rate": 0.026159398599517675,
      "loss": 2.495,
      "step": 459480
    },
    {
      "epoch": 738.75,
      "learning_rate": 0.026156183168649524,
      "loss": 2.4951,
      "step": 459500
    },
    {
      "epoch": 738.78,
      "learning_rate": 0.026152967737781353,
      "loss": 2.4942,
      "step": 459520
    },
    {
      "epoch": 738.81,
      "learning_rate": 0.026149752306913184,
      "loss": 2.4978,
      "step": 459540
    },
    {
      "epoch": 738.84,
      "learning_rate": 0.026146536876045012,
      "loss": 2.4818,
      "step": 459560
    },
    {
      "epoch": 738.87,
      "learning_rate": 0.02614332144517685,
      "loss": 2.4766,
      "step": 459580
    },
    {
      "epoch": 738.91,
      "learning_rate": 0.026140106014308676,
      "loss": 2.4991,
      "step": 459600
    },
    {
      "epoch": 738.94,
      "learning_rate": 0.026136890583440514,
      "loss": 2.4845,
      "step": 459620
    },
    {
      "epoch": 738.97,
      "learning_rate": 0.026133675152572353,
      "loss": 2.5015,
      "step": 459640
    },
    {
      "epoch": 739.0,
      "eval_accuracy": {
        "accuracy": 0.44048822203218535
      },
      "eval_loss": 2.6005687713623047,
      "eval_runtime": 2.966,
      "eval_samples_per_second": 4336.759,
      "eval_steps_per_second": 67.767,
      "step": 459658
    },
    {
      "epoch": 739.0,
      "learning_rate": 0.02613045972170418,
      "loss": 2.4782,
      "step": 459660
    },
    {
      "epoch": 739.04,
      "learning_rate": 0.026127244290836012,
      "loss": 2.4674,
      "step": 459680
    },
    {
      "epoch": 739.07,
      "learning_rate": 0.02612402885996784,
      "loss": 2.4944,
      "step": 459700
    },
    {
      "epoch": 739.1,
      "learning_rate": 0.026120813429099683,
      "loss": 2.4841,
      "step": 459720
    },
    {
      "epoch": 739.13,
      "learning_rate": 0.026117597998231514,
      "loss": 2.498,
      "step": 459740
    },
    {
      "epoch": 739.16,
      "learning_rate": 0.026114382567363342,
      "loss": 2.4953,
      "step": 459760
    },
    {
      "epoch": 739.2,
      "learning_rate": 0.02611116713649518,
      "loss": 2.5052,
      "step": 459780
    },
    {
      "epoch": 739.23,
      "learning_rate": 0.026107951705627006,
      "loss": 2.4826,
      "step": 459800
    },
    {
      "epoch": 739.26,
      "learning_rate": 0.026104736274758834,
      "loss": 2.4984,
      "step": 459820
    },
    {
      "epoch": 739.29,
      "learning_rate": 0.026101520843890683,
      "loss": 2.4862,
      "step": 459840
    },
    {
      "epoch": 739.32,
      "learning_rate": 0.02609830541302251,
      "loss": 2.504,
      "step": 459860
    },
    {
      "epoch": 739.36,
      "learning_rate": 0.026095089982154342,
      "loss": 2.4982,
      "step": 459880
    },
    {
      "epoch": 739.39,
      "learning_rate": 0.02609187455128617,
      "loss": 2.4782,
      "step": 459900
    },
    {
      "epoch": 739.42,
      "learning_rate": 0.026088659120418002,
      "loss": 2.4863,
      "step": 459920
    },
    {
      "epoch": 739.45,
      "learning_rate": 0.026085443689549834,
      "loss": 2.4815,
      "step": 459940
    },
    {
      "epoch": 739.49,
      "learning_rate": 0.026082228258681672,
      "loss": 2.4823,
      "step": 459960
    },
    {
      "epoch": 739.52,
      "learning_rate": 0.02607901282781351,
      "loss": 2.4829,
      "step": 459980
    },
    {
      "epoch": 739.55,
      "learning_rate": 0.02607579739694534,
      "loss": 2.511,
      "step": 460000
    },
    {
      "epoch": 739.58,
      "learning_rate": 0.026072581966077164,
      "loss": 2.4699,
      "step": 460020
    },
    {
      "epoch": 739.61,
      "learning_rate": 0.026069366535209,
      "loss": 2.4761,
      "step": 460040
    },
    {
      "epoch": 739.65,
      "learning_rate": 0.02606615110434084,
      "loss": 2.4822,
      "step": 460060
    },
    {
      "epoch": 739.68,
      "learning_rate": 0.026062935673472672,
      "loss": 2.5018,
      "step": 460080
    },
    {
      "epoch": 739.71,
      "learning_rate": 0.0260597202426045,
      "loss": 2.4804,
      "step": 460100
    },
    {
      "epoch": 739.74,
      "learning_rate": 0.026056504811736332,
      "loss": 2.5048,
      "step": 460120
    },
    {
      "epoch": 739.77,
      "learning_rate": 0.026053289380868164,
      "loss": 2.4942,
      "step": 460140
    },
    {
      "epoch": 739.81,
      "learning_rate": 0.026050073949999992,
      "loss": 2.5031,
      "step": 460160
    },
    {
      "epoch": 739.84,
      "learning_rate": 0.02604685851913184,
      "loss": 2.4866,
      "step": 460180
    },
    {
      "epoch": 739.87,
      "learning_rate": 0.02604364308826367,
      "loss": 2.4885,
      "step": 460200
    },
    {
      "epoch": 739.9,
      "learning_rate": 0.0260404276573955,
      "loss": 2.4878,
      "step": 460220
    },
    {
      "epoch": 739.94,
      "learning_rate": 0.02603721222652733,
      "loss": 2.497,
      "step": 460240
    },
    {
      "epoch": 739.97,
      "learning_rate": 0.02603399679565916,
      "loss": 2.488,
      "step": 460260
    },
    {
      "epoch": 740.0,
      "learning_rate": 0.026030781364790992,
      "loss": 2.4743,
      "step": 460280
    },
    {
      "epoch": 740.0,
      "eval_accuracy": {
        "accuracy": 0.4457747026354661
      },
      "eval_loss": 2.5903663635253906,
      "eval_runtime": 2.9623,
      "eval_samples_per_second": 4342.257,
      "eval_steps_per_second": 67.853,
      "step": 460280
    },
    {
      "epoch": 740.03,
      "learning_rate": 0.02602756593392283,
      "loss": 2.4878,
      "step": 460300
    },
    {
      "epoch": 740.06,
      "learning_rate": 0.02602435050305467,
      "loss": 2.4901,
      "step": 460320
    },
    {
      "epoch": 740.1,
      "learning_rate": 0.026021135072186494,
      "loss": 2.4953,
      "step": 460340
    },
    {
      "epoch": 740.13,
      "learning_rate": 0.026017919641318322,
      "loss": 2.5084,
      "step": 460360
    },
    {
      "epoch": 740.16,
      "learning_rate": 0.026014704210450157,
      "loss": 2.4941,
      "step": 460380
    },
    {
      "epoch": 740.19,
      "learning_rate": 0.026011488779582,
      "loss": 2.4757,
      "step": 460400
    },
    {
      "epoch": 740.23,
      "learning_rate": 0.02600827334871383,
      "loss": 2.5173,
      "step": 460420
    },
    {
      "epoch": 740.26,
      "learning_rate": 0.02600505791784566,
      "loss": 2.5117,
      "step": 460440
    },
    {
      "epoch": 740.29,
      "learning_rate": 0.02600184248697749,
      "loss": 2.4937,
      "step": 460460
    },
    {
      "epoch": 740.32,
      "learning_rate": 0.025998627056109322,
      "loss": 2.5084,
      "step": 460480
    },
    {
      "epoch": 740.35,
      "learning_rate": 0.02599541162524115,
      "loss": 2.4848,
      "step": 460500
    },
    {
      "epoch": 740.39,
      "learning_rate": 0.025992196194373,
      "loss": 2.4836,
      "step": 460520
    },
    {
      "epoch": 740.42,
      "learning_rate": 0.025988980763504827,
      "loss": 2.4864,
      "step": 460540
    },
    {
      "epoch": 740.45,
      "learning_rate": 0.025985765332636652,
      "loss": 2.5013,
      "step": 460560
    },
    {
      "epoch": 740.48,
      "learning_rate": 0.025982549901768487,
      "loss": 2.4796,
      "step": 460580
    },
    {
      "epoch": 740.51,
      "learning_rate": 0.02597933447090032,
      "loss": 2.5032,
      "step": 460600
    },
    {
      "epoch": 740.55,
      "learning_rate": 0.02597611904003215,
      "loss": 2.511,
      "step": 460620
    },
    {
      "epoch": 740.58,
      "learning_rate": 0.02597290360916399,
      "loss": 2.4938,
      "step": 460640
    },
    {
      "epoch": 740.61,
      "learning_rate": 0.02596968817829582,
      "loss": 2.4731,
      "step": 460660
    },
    {
      "epoch": 740.64,
      "learning_rate": 0.025966472747427652,
      "loss": 2.4973,
      "step": 460680
    },
    {
      "epoch": 740.68,
      "learning_rate": 0.02596325731655948,
      "loss": 2.5068,
      "step": 460700
    },
    {
      "epoch": 740.71,
      "learning_rate": 0.025960041885691315,
      "loss": 2.4889,
      "step": 460720
    },
    {
      "epoch": 740.74,
      "learning_rate": 0.025956826454823157,
      "loss": 2.5067,
      "step": 460740
    },
    {
      "epoch": 740.77,
      "learning_rate": 0.02595361102395499,
      "loss": 2.4922,
      "step": 460760
    },
    {
      "epoch": 740.8,
      "learning_rate": 0.025950395593086817,
      "loss": 2.4821,
      "step": 460780
    },
    {
      "epoch": 740.84,
      "learning_rate": 0.02594718016221865,
      "loss": 2.4945,
      "step": 460800
    },
    {
      "epoch": 740.87,
      "learning_rate": 0.02594396473135048,
      "loss": 2.4692,
      "step": 460820
    },
    {
      "epoch": 740.9,
      "learning_rate": 0.025940749300482308,
      "loss": 2.4878,
      "step": 460840
    },
    {
      "epoch": 740.93,
      "learning_rate": 0.025937533869614157,
      "loss": 2.4789,
      "step": 460860
    },
    {
      "epoch": 740.96,
      "learning_rate": 0.025934318438745982,
      "loss": 2.4937,
      "step": 460880
    },
    {
      "epoch": 741.0,
      "learning_rate": 0.02593110300787781,
      "loss": 2.5023,
      "step": 460900
    },
    {
      "epoch": 741.0,
      "eval_accuracy": {
        "accuracy": 0.4427427505247609
      },
      "eval_loss": 2.6032156944274902,
      "eval_runtime": 2.9534,
      "eval_samples_per_second": 4355.302,
      "eval_steps_per_second": 68.057,
      "step": 460902
    },
    {
      "epoch": 741.03,
      "learning_rate": 0.025927887577009645,
      "loss": 2.4898,
      "step": 460920
    },
    {
      "epoch": 741.06,
      "learning_rate": 0.025924672146141477,
      "loss": 2.5021,
      "step": 460940
    },
    {
      "epoch": 741.09,
      "learning_rate": 0.02592145671527332,
      "loss": 2.4759,
      "step": 460960
    },
    {
      "epoch": 741.13,
      "learning_rate": 0.025918241284405147,
      "loss": 2.4782,
      "step": 460980
    },
    {
      "epoch": 741.16,
      "learning_rate": 0.02591502585353698,
      "loss": 2.4908,
      "step": 461000
    },
    {
      "epoch": 741.19,
      "learning_rate": 0.02591181042266881,
      "loss": 2.4907,
      "step": 461020
    },
    {
      "epoch": 741.22,
      "learning_rate": 0.025908594991800638,
      "loss": 2.4813,
      "step": 461040
    },
    {
      "epoch": 741.25,
      "learning_rate": 0.025905379560932473,
      "loss": 2.4829,
      "step": 461060
    },
    {
      "epoch": 741.29,
      "learning_rate": 0.025902164130064315,
      "loss": 2.4834,
      "step": 461080
    },
    {
      "epoch": 741.32,
      "learning_rate": 0.02589894869919614,
      "loss": 2.5034,
      "step": 461100
    },
    {
      "epoch": 741.35,
      "learning_rate": 0.025895733268327975,
      "loss": 2.4799,
      "step": 461120
    },
    {
      "epoch": 741.38,
      "learning_rate": 0.025892517837459807,
      "loss": 2.4956,
      "step": 461140
    },
    {
      "epoch": 741.41,
      "learning_rate": 0.02588930240659164,
      "loss": 2.4853,
      "step": 461160
    },
    {
      "epoch": 741.45,
      "learning_rate": 0.025886086975723466,
      "loss": 2.5041,
      "step": 461180
    },
    {
      "epoch": 741.48,
      "learning_rate": 0.02588287154485531,
      "loss": 2.4841,
      "step": 461200
    },
    {
      "epoch": 741.51,
      "learning_rate": 0.02587965611398714,
      "loss": 2.5141,
      "step": 461220
    },
    {
      "epoch": 741.54,
      "learning_rate": 0.025876440683118968,
      "loss": 2.4868,
      "step": 461240
    },
    {
      "epoch": 741.58,
      "learning_rate": 0.025873225252250803,
      "loss": 2.5053,
      "step": 461260
    },
    {
      "epoch": 741.61,
      "learning_rate": 0.025870009821382628,
      "loss": 2.4854,
      "step": 461280
    },
    {
      "epoch": 741.64,
      "learning_rate": 0.02586679439051447,
      "loss": 2.4814,
      "step": 461300
    },
    {
      "epoch": 741.67,
      "learning_rate": 0.025863578959646305,
      "loss": 2.4991,
      "step": 461320
    },
    {
      "epoch": 741.7,
      "learning_rate": 0.025860363528778137,
      "loss": 2.5084,
      "step": 461340
    },
    {
      "epoch": 741.74,
      "learning_rate": 0.025857148097909968,
      "loss": 2.4815,
      "step": 461360
    },
    {
      "epoch": 741.77,
      "learning_rate": 0.025853932667041796,
      "loss": 2.4683,
      "step": 461380
    },
    {
      "epoch": 741.8,
      "learning_rate": 0.025850717236173628,
      "loss": 2.4641,
      "step": 461400
    },
    {
      "epoch": 741.83,
      "learning_rate": 0.02584750180530547,
      "loss": 2.4756,
      "step": 461420
    },
    {
      "epoch": 741.86,
      "learning_rate": 0.025844286374437298,
      "loss": 2.4779,
      "step": 461440
    },
    {
      "epoch": 741.9,
      "learning_rate": 0.025841070943569133,
      "loss": 2.4903,
      "step": 461460
    },
    {
      "epoch": 741.93,
      "learning_rate": 0.025837855512700965,
      "loss": 2.4812,
      "step": 461480
    },
    {
      "epoch": 741.96,
      "learning_rate": 0.025834640081832796,
      "loss": 2.5116,
      "step": 461500
    },
    {
      "epoch": 741.99,
      "learning_rate": 0.025831424650964625,
      "loss": 2.514,
      "step": 461520
    },
    {
      "epoch": 742.0,
      "eval_accuracy": {
        "accuracy": 0.44429759776101996
      },
      "eval_loss": 2.6016845703125,
      "eval_runtime": 2.9957,
      "eval_samples_per_second": 4293.846,
      "eval_steps_per_second": 67.097,
      "step": 461524
    },
    {
      "epoch": 742.03,
      "learning_rate": 0.025828209220096467,
      "loss": 2.4949,
      "step": 461540
    },
    {
      "epoch": 742.06,
      "learning_rate": 0.025824993789228298,
      "loss": 2.4815,
      "step": 461560
    },
    {
      "epoch": 742.09,
      "learning_rate": 0.025821778358360126,
      "loss": 2.5073,
      "step": 461580
    },
    {
      "epoch": 742.12,
      "learning_rate": 0.025818562927491958,
      "loss": 2.4768,
      "step": 461600
    },
    {
      "epoch": 742.15,
      "learning_rate": 0.025815347496623786,
      "loss": 2.4879,
      "step": 461620
    },
    {
      "epoch": 742.19,
      "learning_rate": 0.025812132065755628,
      "loss": 2.5124,
      "step": 461640
    },
    {
      "epoch": 742.22,
      "learning_rate": 0.025808916634887463,
      "loss": 2.4733,
      "step": 461660
    },
    {
      "epoch": 742.25,
      "learning_rate": 0.025805701204019295,
      "loss": 2.4769,
      "step": 461680
    },
    {
      "epoch": 742.28,
      "learning_rate": 0.025802485773151126,
      "loss": 2.4989,
      "step": 461700
    },
    {
      "epoch": 742.32,
      "learning_rate": 0.025799270342282955,
      "loss": 2.4875,
      "step": 461720
    },
    {
      "epoch": 742.35,
      "learning_rate": 0.025796054911414786,
      "loss": 2.497,
      "step": 461740
    },
    {
      "epoch": 742.38,
      "learning_rate": 0.025792839480546628,
      "loss": 2.4916,
      "step": 461760
    },
    {
      "epoch": 742.41,
      "learning_rate": 0.025789624049678456,
      "loss": 2.4701,
      "step": 461780
    },
    {
      "epoch": 742.44,
      "learning_rate": 0.02578640861881029,
      "loss": 2.4845,
      "step": 461800
    },
    {
      "epoch": 742.48,
      "learning_rate": 0.025783193187942116,
      "loss": 2.4986,
      "step": 461820
    },
    {
      "epoch": 742.51,
      "learning_rate": 0.025779977757073955,
      "loss": 2.5011,
      "step": 461840
    },
    {
      "epoch": 742.54,
      "learning_rate": 0.025776762326205783,
      "loss": 2.4723,
      "step": 461860
    },
    {
      "epoch": 742.57,
      "learning_rate": 0.025773546895337625,
      "loss": 2.4918,
      "step": 461880
    },
    {
      "epoch": 742.6,
      "learning_rate": 0.025770331464469456,
      "loss": 2.4858,
      "step": 461900
    },
    {
      "epoch": 742.64,
      "learning_rate": 0.025767116033601285,
      "loss": 2.4889,
      "step": 461920
    },
    {
      "epoch": 742.67,
      "learning_rate": 0.025763900602733116,
      "loss": 2.4994,
      "step": 461940
    },
    {
      "epoch": 742.7,
      "learning_rate": 0.025760685171864944,
      "loss": 2.4846,
      "step": 461960
    },
    {
      "epoch": 742.73,
      "learning_rate": 0.025757469740996786,
      "loss": 2.5152,
      "step": 461980
    },
    {
      "epoch": 742.77,
      "learning_rate": 0.02575425431012862,
      "loss": 2.4813,
      "step": 462000
    },
    {
      "epoch": 742.8,
      "learning_rate": 0.025751038879260453,
      "loss": 2.5052,
      "step": 462020
    },
    {
      "epoch": 742.83,
      "learning_rate": 0.025747823448392285,
      "loss": 2.5103,
      "step": 462040
    },
    {
      "epoch": 742.86,
      "learning_rate": 0.025744608017524113,
      "loss": 2.4762,
      "step": 462060
    },
    {
      "epoch": 742.89,
      "learning_rate": 0.025741392586655944,
      "loss": 2.5053,
      "step": 462080
    },
    {
      "epoch": 742.93,
      "learning_rate": 0.025738177155787786,
      "loss": 2.4722,
      "step": 462100
    },
    {
      "epoch": 742.96,
      "learning_rate": 0.025734961724919615,
      "loss": 2.4803,
      "step": 462120
    },
    {
      "epoch": 742.99,
      "learning_rate": 0.025731746294051446,
      "loss": 2.4941,
      "step": 462140
    },
    {
      "epoch": 743.0,
      "eval_accuracy": {
        "accuracy": 0.44048822203218535
      },
      "eval_loss": 2.6122782230377197,
      "eval_runtime": 3.0265,
      "eval_samples_per_second": 4250.152,
      "eval_steps_per_second": 66.414,
      "step": 462146
    },
    {
      "epoch": 743.02,
      "learning_rate": 0.025728530863183274,
      "loss": 2.491,
      "step": 462160
    },
    {
      "epoch": 743.05,
      "learning_rate": 0.025725315432315113,
      "loss": 2.4771,
      "step": 462180
    },
    {
      "epoch": 743.09,
      "learning_rate": 0.02572210000144694,
      "loss": 2.4867,
      "step": 462200
    },
    {
      "epoch": 743.12,
      "learning_rate": 0.025718884570578783,
      "loss": 2.479,
      "step": 462220
    },
    {
      "epoch": 743.15,
      "learning_rate": 0.025715669139710615,
      "loss": 2.4725,
      "step": 462240
    },
    {
      "epoch": 743.18,
      "learning_rate": 0.025712453708842443,
      "loss": 2.4817,
      "step": 462260
    },
    {
      "epoch": 743.22,
      "learning_rate": 0.025709238277974274,
      "loss": 2.509,
      "step": 462280
    },
    {
      "epoch": 743.25,
      "learning_rate": 0.025706022847106103,
      "loss": 2.512,
      "step": 462300
    },
    {
      "epoch": 743.28,
      "learning_rate": 0.025702807416237945,
      "loss": 2.4723,
      "step": 462320
    },
    {
      "epoch": 743.31,
      "learning_rate": 0.02569959198536978,
      "loss": 2.5005,
      "step": 462340
    },
    {
      "epoch": 743.34,
      "learning_rate": 0.025696376554501604,
      "loss": 2.4803,
      "step": 462360
    },
    {
      "epoch": 743.38,
      "learning_rate": 0.025693161123633443,
      "loss": 2.4687,
      "step": 462380
    },
    {
      "epoch": 743.41,
      "learning_rate": 0.02568994569276527,
      "loss": 2.4797,
      "step": 462400
    },
    {
      "epoch": 743.44,
      "learning_rate": 0.025686730261897103,
      "loss": 2.4873,
      "step": 462420
    },
    {
      "epoch": 743.47,
      "learning_rate": 0.025683514831028945,
      "loss": 2.478,
      "step": 462440
    },
    {
      "epoch": 743.5,
      "learning_rate": 0.025680299400160773,
      "loss": 2.4837,
      "step": 462460
    },
    {
      "epoch": 743.54,
      "learning_rate": 0.025677083969292604,
      "loss": 2.4909,
      "step": 462480
    },
    {
      "epoch": 743.57,
      "learning_rate": 0.025673868538424433,
      "loss": 2.4767,
      "step": 462500
    },
    {
      "epoch": 743.6,
      "learning_rate": 0.02567065310755627,
      "loss": 2.4958,
      "step": 462520
    },
    {
      "epoch": 743.63,
      "learning_rate": 0.0256674376766881,
      "loss": 2.494,
      "step": 462540
    },
    {
      "epoch": 743.67,
      "learning_rate": 0.025664222245819934,
      "loss": 2.4945,
      "step": 462560
    },
    {
      "epoch": 743.7,
      "learning_rate": 0.025661006814951773,
      "loss": 2.4995,
      "step": 462580
    },
    {
      "epoch": 743.73,
      "learning_rate": 0.0256577913840836,
      "loss": 2.4896,
      "step": 462600
    },
    {
      "epoch": 743.76,
      "learning_rate": 0.025654575953215433,
      "loss": 2.4838,
      "step": 462620
    },
    {
      "epoch": 743.79,
      "learning_rate": 0.02565136052234726,
      "loss": 2.4897,
      "step": 462640
    },
    {
      "epoch": 743.83,
      "learning_rate": 0.025648145091479103,
      "loss": 2.4993,
      "step": 462660
    },
    {
      "epoch": 743.86,
      "learning_rate": 0.025644929660610934,
      "loss": 2.4816,
      "step": 462680
    },
    {
      "epoch": 743.89,
      "learning_rate": 0.025641714229742762,
      "loss": 2.4821,
      "step": 462700
    },
    {
      "epoch": 743.92,
      "learning_rate": 0.0256384987988746,
      "loss": 2.4777,
      "step": 462720
    },
    {
      "epoch": 743.95,
      "learning_rate": 0.02563528336800643,
      "loss": 2.5147,
      "step": 462740
    },
    {
      "epoch": 743.99,
      "learning_rate": 0.025632067937138254,
      "loss": 2.4693,
      "step": 462760
    },
    {
      "epoch": 744.0,
      "eval_accuracy": {
        "accuracy": 0.44212081163025735
      },
      "eval_loss": 2.6166136264801025,
      "eval_runtime": 3.0141,
      "eval_samples_per_second": 4267.631,
      "eval_steps_per_second": 66.687,
      "step": 462768
    },
    {
      "epoch": 744.02,
      "learning_rate": 0.0256290132778135,
      "loss": 2.4832,
      "step": 462780
    },
    {
      "epoch": 744.05,
      "learning_rate": 0.025625797846945342,
      "loss": 2.4748,
      "step": 462800
    },
    {
      "epoch": 744.08,
      "learning_rate": 0.025622582416077174,
      "loss": 2.475,
      "step": 462820
    },
    {
      "epoch": 744.12,
      "learning_rate": 0.025619366985209002,
      "loss": 2.4979,
      "step": 462840
    },
    {
      "epoch": 744.15,
      "learning_rate": 0.025616151554340834,
      "loss": 2.4826,
      "step": 462860
    },
    {
      "epoch": 744.18,
      "learning_rate": 0.025612936123472665,
      "loss": 2.5057,
      "step": 462880
    },
    {
      "epoch": 744.21,
      "learning_rate": 0.025609720692604494,
      "loss": 2.4936,
      "step": 462900
    },
    {
      "epoch": 744.24,
      "learning_rate": 0.025606505261736343,
      "loss": 2.4902,
      "step": 462920
    },
    {
      "epoch": 744.28,
      "learning_rate": 0.02560328983086817,
      "loss": 2.5002,
      "step": 462940
    },
    {
      "epoch": 744.31,
      "learning_rate": 0.025600074400000002,
      "loss": 2.4914,
      "step": 462960
    },
    {
      "epoch": 744.34,
      "learning_rate": 0.02559685896913183,
      "loss": 2.4833,
      "step": 462980
    },
    {
      "epoch": 744.37,
      "learning_rate": 0.025593643538263662,
      "loss": 2.4798,
      "step": 463000
    },
    {
      "epoch": 744.41,
      "learning_rate": 0.025590428107395494,
      "loss": 2.4552,
      "step": 463020
    },
    {
      "epoch": 744.44,
      "learning_rate": 0.025587212676527332,
      "loss": 2.4801,
      "step": 463040
    },
    {
      "epoch": 744.47,
      "learning_rate": 0.02558399724565917,
      "loss": 2.4959,
      "step": 463060
    },
    {
      "epoch": 744.5,
      "learning_rate": 0.025580781814790995,
      "loss": 2.4833,
      "step": 463080
    },
    {
      "epoch": 744.53,
      "learning_rate": 0.025577566383922824,
      "loss": 2.5001,
      "step": 463100
    },
    {
      "epoch": 744.57,
      "learning_rate": 0.02557435095305466,
      "loss": 2.4941,
      "step": 463120
    },
    {
      "epoch": 744.6,
      "learning_rate": 0.0255711355221865,
      "loss": 2.496,
      "step": 463140
    },
    {
      "epoch": 744.63,
      "learning_rate": 0.025567920091318332,
      "loss": 2.4748,
      "step": 463160
    },
    {
      "epoch": 744.66,
      "learning_rate": 0.02556470466045016,
      "loss": 2.4913,
      "step": 463180
    },
    {
      "epoch": 744.69,
      "learning_rate": 0.025561489229581992,
      "loss": 2.5098,
      "step": 463200
    },
    {
      "epoch": 744.73,
      "learning_rate": 0.025558273798713824,
      "loss": 2.4802,
      "step": 463220
    },
    {
      "epoch": 744.76,
      "learning_rate": 0.025555058367845652,
      "loss": 2.4917,
      "step": 463240
    },
    {
      "epoch": 744.79,
      "learning_rate": 0.0255518429369775,
      "loss": 2.4837,
      "step": 463260
    },
    {
      "epoch": 744.82,
      "learning_rate": 0.02554862750610933,
      "loss": 2.4916,
      "step": 463280
    },
    {
      "epoch": 744.86,
      "learning_rate": 0.025545412075241154,
      "loss": 2.4859,
      "step": 463300
    },
    {
      "epoch": 744.89,
      "learning_rate": 0.02554219664437299,
      "loss": 2.5068,
      "step": 463320
    },
    {
      "epoch": 744.92,
      "learning_rate": 0.02553898121350482,
      "loss": 2.4815,
      "step": 463340
    },
    {
      "epoch": 744.95,
      "learning_rate": 0.025535765782636652,
      "loss": 2.4693,
      "step": 463360
    },
    {
      "epoch": 744.98,
      "learning_rate": 0.02553255035176849,
      "loss": 2.5035,
      "step": 463380
    },
    {
      "epoch": 745.0,
      "eval_accuracy": {
        "accuracy": 0.44079919147943714
      },
      "eval_loss": 2.594111919403076,
      "eval_runtime": 3.1588,
      "eval_samples_per_second": 4072.144,
      "eval_steps_per_second": 63.632,
      "step": 463390
    },
    {
      "epoch": 745.02,
      "learning_rate": 0.025529334920900322,
      "loss": 2.5023,
      "step": 463400
    },
    {
      "epoch": 745.05,
      "learning_rate": 0.025526119490032154,
      "loss": 2.4894,
      "step": 463420
    },
    {
      "epoch": 745.08,
      "learning_rate": 0.025523064830707393,
      "loss": 2.4712,
      "step": 463440
    },
    {
      "epoch": 745.11,
      "learning_rate": 0.02551984939983923,
      "loss": 2.4828,
      "step": 463460
    },
    {
      "epoch": 745.14,
      "learning_rate": 0.025516633968971053,
      "loss": 2.4746,
      "step": 463480
    },
    {
      "epoch": 745.18,
      "learning_rate": 0.02551341853810289,
      "loss": 2.4925,
      "step": 463500
    },
    {
      "epoch": 745.21,
      "learning_rate": 0.02551020310723473,
      "loss": 2.5095,
      "step": 463520
    },
    {
      "epoch": 745.24,
      "learning_rate": 0.025506987676366562,
      "loss": 2.4936,
      "step": 463540
    },
    {
      "epoch": 745.27,
      "learning_rate": 0.025503772245498393,
      "loss": 2.4816,
      "step": 463560
    },
    {
      "epoch": 745.31,
      "learning_rate": 0.02550055681463022,
      "loss": 2.4815,
      "step": 463580
    },
    {
      "epoch": 745.34,
      "learning_rate": 0.025497341383762053,
      "loss": 2.4745,
      "step": 463600
    },
    {
      "epoch": 745.37,
      "learning_rate": 0.025494125952893895,
      "loss": 2.4772,
      "step": 463620
    },
    {
      "epoch": 745.4,
      "learning_rate": 0.025490910522025723,
      "loss": 2.4748,
      "step": 463640
    },
    {
      "epoch": 745.43,
      "learning_rate": 0.02548769509115756,
      "loss": 2.4903,
      "step": 463660
    },
    {
      "epoch": 745.47,
      "learning_rate": 0.02548447966028939,
      "loss": 2.4779,
      "step": 463680
    },
    {
      "epoch": 745.5,
      "learning_rate": 0.02548126422942122,
      "loss": 2.4822,
      "step": 463700
    },
    {
      "epoch": 745.53,
      "learning_rate": 0.02547804879855305,
      "loss": 2.5007,
      "step": 463720
    },
    {
      "epoch": 745.56,
      "learning_rate": 0.025474833367684892,
      "loss": 2.4724,
      "step": 463740
    },
    {
      "epoch": 745.59,
      "learning_rate": 0.025471617936816723,
      "loss": 2.4748,
      "step": 463760
    },
    {
      "epoch": 745.63,
      "learning_rate": 0.02546840250594855,
      "loss": 2.479,
      "step": 463780
    },
    {
      "epoch": 745.66,
      "learning_rate": 0.025465187075080383,
      "loss": 2.4855,
      "step": 463800
    },
    {
      "epoch": 745.69,
      "learning_rate": 0.02546197164421221,
      "loss": 2.4663,
      "step": 463820
    },
    {
      "epoch": 745.72,
      "learning_rate": 0.02545875621334405,
      "loss": 2.4842,
      "step": 463840
    },
    {
      "epoch": 745.76,
      "learning_rate": 0.02545554078247589,
      "loss": 2.5039,
      "step": 463860
    },
    {
      "epoch": 745.79,
      "learning_rate": 0.02545232535160772,
      "loss": 2.4856,
      "step": 463880
    },
    {
      "epoch": 745.82,
      "learning_rate": 0.02544910992073955,
      "loss": 2.4944,
      "step": 463900
    },
    {
      "epoch": 745.85,
      "learning_rate": 0.02544589448987138,
      "loss": 2.4913,
      "step": 463920
    },
    {
      "epoch": 745.88,
      "learning_rate": 0.02544267905900321,
      "loss": 2.4933,
      "step": 463940
    },
    {
      "epoch": 745.92,
      "learning_rate": 0.025439463628135053,
      "loss": 2.5071,
      "step": 463960
    },
    {
      "epoch": 745.95,
      "learning_rate": 0.02543624819726688,
      "loss": 2.4821,
      "step": 463980
    },
    {
      "epoch": 745.98,
      "learning_rate": 0.025433032766398717,
      "loss": 2.5098,
      "step": 464000
    },
    {
      "epoch": 746.0,
      "eval_accuracy": {
        "accuracy": 0.4422762963538832
      },
      "eval_loss": 2.6019115447998047,
      "eval_runtime": 2.9785,
      "eval_samples_per_second": 4318.557,
      "eval_steps_per_second": 67.483,
      "step": 464012
    },
    {
      "epoch": 746.01,
      "learning_rate": 0.02542981733553054,
      "loss": 2.5056,
      "step": 464020
    },
    {
      "epoch": 746.05,
      "learning_rate": 0.02542660190466238,
      "loss": 2.4708,
      "step": 464040
    },
    {
      "epoch": 746.08,
      "learning_rate": 0.025423386473794208,
      "loss": 2.4756,
      "step": 464060
    },
    {
      "epoch": 746.11,
      "learning_rate": 0.02542017104292605,
      "loss": 2.478,
      "step": 464080
    },
    {
      "epoch": 746.14,
      "learning_rate": 0.02541695561205788,
      "loss": 2.495,
      "step": 464100
    },
    {
      "epoch": 746.17,
      "learning_rate": 0.02541374018118971,
      "loss": 2.4919,
      "step": 464120
    },
    {
      "epoch": 746.21,
      "learning_rate": 0.02541052475032154,
      "loss": 2.4883,
      "step": 464140
    },
    {
      "epoch": 746.24,
      "learning_rate": 0.02540730931945337,
      "loss": 2.4871,
      "step": 464160
    },
    {
      "epoch": 746.27,
      "learning_rate": 0.025404093888585208,
      "loss": 2.4656,
      "step": 464180
    },
    {
      "epoch": 746.3,
      "learning_rate": 0.025400878457717047,
      "loss": 2.4768,
      "step": 464200
    },
    {
      "epoch": 746.33,
      "learning_rate": 0.02539766302684887,
      "loss": 2.4913,
      "step": 464220
    },
    {
      "epoch": 746.37,
      "learning_rate": 0.02539444759598071,
      "loss": 2.4785,
      "step": 464240
    },
    {
      "epoch": 746.4,
      "learning_rate": 0.025391232165112538,
      "loss": 2.4926,
      "step": 464260
    },
    {
      "epoch": 746.43,
      "learning_rate": 0.02538801673424437,
      "loss": 2.4835,
      "step": 464280
    },
    {
      "epoch": 746.46,
      "learning_rate": 0.02538480130337621,
      "loss": 2.4801,
      "step": 464300
    },
    {
      "epoch": 746.5,
      "learning_rate": 0.02538158587250804,
      "loss": 2.4745,
      "step": 464320
    },
    {
      "epoch": 746.53,
      "learning_rate": 0.02537837044163987,
      "loss": 2.4855,
      "step": 464340
    },
    {
      "epoch": 746.56,
      "learning_rate": 0.0253751550107717,
      "loss": 2.4895,
      "step": 464360
    },
    {
      "epoch": 746.59,
      "learning_rate": 0.025371939579903538,
      "loss": 2.4957,
      "step": 464380
    },
    {
      "epoch": 746.62,
      "learning_rate": 0.025368724149035366,
      "loss": 2.4783,
      "step": 464400
    },
    {
      "epoch": 746.66,
      "learning_rate": 0.025365508718167208,
      "loss": 2.4823,
      "step": 464420
    },
    {
      "epoch": 746.69,
      "learning_rate": 0.02536229328729904,
      "loss": 2.4803,
      "step": 464440
    },
    {
      "epoch": 746.72,
      "learning_rate": 0.025359077856430868,
      "loss": 2.4998,
      "step": 464460
    },
    {
      "epoch": 746.75,
      "learning_rate": 0.0253558624255627,
      "loss": 2.4878,
      "step": 464480
    },
    {
      "epoch": 746.78,
      "learning_rate": 0.025352646994694528,
      "loss": 2.4952,
      "step": 464500
    },
    {
      "epoch": 746.82,
      "learning_rate": 0.02534943156382637,
      "loss": 2.4795,
      "step": 464520
    },
    {
      "epoch": 746.85,
      "learning_rate": 0.0253462161329582,
      "loss": 2.4976,
      "step": 464540
    },
    {
      "epoch": 746.88,
      "learning_rate": 0.02534300070209003,
      "loss": 2.474,
      "step": 464560
    },
    {
      "epoch": 746.91,
      "learning_rate": 0.025339785271221868,
      "loss": 2.4805,
      "step": 464580
    },
    {
      "epoch": 746.95,
      "learning_rate": 0.025336569840353696,
      "loss": 2.4979,
      "step": 464600
    },
    {
      "epoch": 746.98,
      "learning_rate": 0.025333354409485528,
      "loss": 2.4927,
      "step": 464620
    },
    {
      "epoch": 747.0,
      "eval_accuracy": {
        "accuracy": 0.4418098421830055
      },
      "eval_loss": 2.5962073802948,
      "eval_runtime": 2.8701,
      "eval_samples_per_second": 4481.745,
      "eval_steps_per_second": 70.033,
      "step": 464634
    },
    {
      "epoch": 747.01,
      "learning_rate": 0.02533013897861737,
      "loss": 2.4916,
      "step": 464640
    },
    {
      "epoch": 747.04,
      "learning_rate": 0.025326923547749198,
      "loss": 2.5003,
      "step": 464660
    },
    {
      "epoch": 747.07,
      "learning_rate": 0.02532370811688103,
      "loss": 2.4881,
      "step": 464680
    },
    {
      "epoch": 747.11,
      "learning_rate": 0.025320492686012858,
      "loss": 2.482,
      "step": 464700
    },
    {
      "epoch": 747.14,
      "learning_rate": 0.025317277255144696,
      "loss": 2.4791,
      "step": 464720
    },
    {
      "epoch": 747.17,
      "learning_rate": 0.02531406182427652,
      "loss": 2.4786,
      "step": 464740
    },
    {
      "epoch": 747.2,
      "learning_rate": 0.02531084639340836,
      "loss": 2.4549,
      "step": 464760
    },
    {
      "epoch": 747.23,
      "learning_rate": 0.025307630962540198,
      "loss": 2.4727,
      "step": 464780
    },
    {
      "epoch": 747.27,
      "learning_rate": 0.025304415531672026,
      "loss": 2.4753,
      "step": 464800
    },
    {
      "epoch": 747.3,
      "learning_rate": 0.025301200100803858,
      "loss": 2.4929,
      "step": 464820
    },
    {
      "epoch": 747.33,
      "learning_rate": 0.025297984669935686,
      "loss": 2.4861,
      "step": 464840
    },
    {
      "epoch": 747.36,
      "learning_rate": 0.025294769239067528,
      "loss": 2.5057,
      "step": 464860
    },
    {
      "epoch": 747.4,
      "learning_rate": 0.02529155380819936,
      "loss": 2.4783,
      "step": 464880
    },
    {
      "epoch": 747.43,
      "learning_rate": 0.025288338377331188,
      "loss": 2.4891,
      "step": 464900
    },
    {
      "epoch": 747.46,
      "learning_rate": 0.025285122946463026,
      "loss": 2.4772,
      "step": 464920
    },
    {
      "epoch": 747.49,
      "learning_rate": 0.025281907515594854,
      "loss": 2.4949,
      "step": 464940
    },
    {
      "epoch": 747.52,
      "learning_rate": 0.02527869208472668,
      "loss": 2.4451,
      "step": 464960
    },
    {
      "epoch": 747.56,
      "learning_rate": 0.025275476653858528,
      "loss": 2.4904,
      "step": 464980
    },
    {
      "epoch": 747.59,
      "learning_rate": 0.025272261222990356,
      "loss": 2.4764,
      "step": 465000
    },
    {
      "epoch": 747.62,
      "learning_rate": 0.025269045792122188,
      "loss": 2.4909,
      "step": 465020
    },
    {
      "epoch": 747.65,
      "learning_rate": 0.025265830361254016,
      "loss": 2.4935,
      "step": 465040
    },
    {
      "epoch": 747.68,
      "learning_rate": 0.025262614930385847,
      "loss": 2.4892,
      "step": 465060
    },
    {
      "epoch": 747.72,
      "learning_rate": 0.02525939949951768,
      "loss": 2.4769,
      "step": 465080
    },
    {
      "epoch": 747.75,
      "learning_rate": 0.025256184068649518,
      "loss": 2.485,
      "step": 465100
    },
    {
      "epoch": 747.78,
      "learning_rate": 0.025252968637781356,
      "loss": 2.4877,
      "step": 465120
    },
    {
      "epoch": 747.81,
      "learning_rate": 0.025249753206913184,
      "loss": 2.5012,
      "step": 465140
    },
    {
      "epoch": 747.85,
      "learning_rate": 0.025246537776045016,
      "loss": 2.5114,
      "step": 465160
    },
    {
      "epoch": 747.88,
      "learning_rate": 0.025243322345176844,
      "loss": 2.4886,
      "step": 465180
    },
    {
      "epoch": 747.91,
      "learning_rate": 0.025240106914308686,
      "loss": 2.4834,
      "step": 465200
    },
    {
      "epoch": 747.94,
      "learning_rate": 0.025236891483440518,
      "loss": 2.4761,
      "step": 465220
    },
    {
      "epoch": 747.97,
      "learning_rate": 0.025233676052572346,
      "loss": 2.4876,
      "step": 465240
    },
    {
      "epoch": 748.0,
      "eval_accuracy": {
        "accuracy": 0.44126564565031484
      },
      "eval_loss": 2.6081771850585938,
      "eval_runtime": 3.1298,
      "eval_samples_per_second": 4109.868,
      "eval_steps_per_second": 64.222,
      "step": 465256
    },
    {
      "epoch": 748.01,
      "learning_rate": 0.025230460621704184,
      "loss": 2.4961,
      "step": 465260
    },
    {
      "epoch": 748.04,
      "learning_rate": 0.02522724519083601,
      "loss": 2.4927,
      "step": 465280
    },
    {
      "epoch": 748.07,
      "learning_rate": 0.025224029759967837,
      "loss": 2.4773,
      "step": 465300
    },
    {
      "epoch": 748.1,
      "learning_rate": 0.025220814329099686,
      "loss": 2.4747,
      "step": 465320
    },
    {
      "epoch": 748.14,
      "learning_rate": 0.025217598898231514,
      "loss": 2.4974,
      "step": 465340
    },
    {
      "epoch": 748.17,
      "learning_rate": 0.025214383467363346,
      "loss": 2.4697,
      "step": 465360
    },
    {
      "epoch": 748.2,
      "learning_rate": 0.025211168036495174,
      "loss": 2.4825,
      "step": 465380
    },
    {
      "epoch": 748.23,
      "learning_rate": 0.025207952605627006,
      "loss": 2.4902,
      "step": 465400
    },
    {
      "epoch": 748.26,
      "learning_rate": 0.025204737174758837,
      "loss": 2.4791,
      "step": 465420
    },
    {
      "epoch": 748.3,
      "learning_rate": 0.025201521743890676,
      "loss": 2.4848,
      "step": 465440
    },
    {
      "epoch": 748.33,
      "learning_rate": 0.025198306313022514,
      "loss": 2.5072,
      "step": 465460
    },
    {
      "epoch": 748.36,
      "learning_rate": 0.025195090882154342,
      "loss": 2.4788,
      "step": 465480
    },
    {
      "epoch": 748.39,
      "learning_rate": 0.025191875451286167,
      "loss": 2.4727,
      "step": 465500
    },
    {
      "epoch": 748.42,
      "learning_rate": 0.025188660020418002,
      "loss": 2.4612,
      "step": 465520
    },
    {
      "epoch": 748.46,
      "learning_rate": 0.025185444589549844,
      "loss": 2.4811,
      "step": 465540
    },
    {
      "epoch": 748.49,
      "learning_rate": 0.025182229158681676,
      "loss": 2.4809,
      "step": 465560
    },
    {
      "epoch": 748.52,
      "learning_rate": 0.025179013727813504,
      "loss": 2.4768,
      "step": 465580
    },
    {
      "epoch": 748.55,
      "learning_rate": 0.025175798296945336,
      "loss": 2.482,
      "step": 465600
    },
    {
      "epoch": 748.59,
      "learning_rate": 0.025172582866077167,
      "loss": 2.4886,
      "step": 465620
    },
    {
      "epoch": 748.62,
      "learning_rate": 0.025169367435208995,
      "loss": 2.4927,
      "step": 465640
    },
    {
      "epoch": 748.65,
      "learning_rate": 0.025166152004340844,
      "loss": 2.5033,
      "step": 465660
    },
    {
      "epoch": 748.68,
      "learning_rate": 0.025162936573472672,
      "loss": 2.497,
      "step": 465680
    },
    {
      "epoch": 748.71,
      "learning_rate": 0.025159721142604497,
      "loss": 2.5014,
      "step": 465700
    },
    {
      "epoch": 748.75,
      "learning_rate": 0.025156505711736332,
      "loss": 2.4807,
      "step": 465720
    },
    {
      "epoch": 748.78,
      "learning_rate": 0.025153290280868164,
      "loss": 2.473,
      "step": 465740
    },
    {
      "epoch": 748.81,
      "learning_rate": 0.025150074849999995,
      "loss": 2.488,
      "step": 465760
    },
    {
      "epoch": 748.84,
      "learning_rate": 0.025146859419131834,
      "loss": 2.4874,
      "step": 465780
    },
    {
      "epoch": 748.87,
      "learning_rate": 0.025143643988263673,
      "loss": 2.4585,
      "step": 465800
    },
    {
      "epoch": 748.91,
      "learning_rate": 0.025140428557395497,
      "loss": 2.486,
      "step": 465820
    },
    {
      "epoch": 748.94,
      "learning_rate": 0.025137213126527325,
      "loss": 2.4928,
      "step": 465840
    },
    {
      "epoch": 748.97,
      "learning_rate": 0.02513399769565916,
      "loss": 2.5103,
      "step": 465860
    },
    {
      "epoch": 749.0,
      "eval_accuracy": {
        "accuracy": 0.4392443442431781
      },
      "eval_loss": 2.599712371826172,
      "eval_runtime": 3.2476,
      "eval_samples_per_second": 3960.8,
      "eval_steps_per_second": 61.892,
      "step": 465878
    },
    {
      "epoch": 749.0,
      "learning_rate": 0.025130782264791002,
      "loss": 2.478,
      "step": 465880
    },
    {
      "epoch": 749.04,
      "learning_rate": 0.025127566833922834,
      "loss": 2.4932,
      "step": 465900
    },
    {
      "epoch": 749.07,
      "learning_rate": 0.025124351403054662,
      "loss": 2.4749,
      "step": 465920
    },
    {
      "epoch": 749.1,
      "learning_rate": 0.025121135972186494,
      "loss": 2.5066,
      "step": 465940
    },
    {
      "epoch": 749.13,
      "learning_rate": 0.025117920541318325,
      "loss": 2.4819,
      "step": 465960
    },
    {
      "epoch": 749.16,
      "learning_rate": 0.025114705110450154,
      "loss": 2.4785,
      "step": 465980
    },
    {
      "epoch": 749.2,
      "learning_rate": 0.025111489679582003,
      "loss": 2.4712,
      "step": 466000
    },
    {
      "epoch": 749.23,
      "learning_rate": 0.025108274248713827,
      "loss": 2.4886,
      "step": 466020
    },
    {
      "epoch": 749.26,
      "learning_rate": 0.025105058817845655,
      "loss": 2.4752,
      "step": 466040
    },
    {
      "epoch": 749.29,
      "learning_rate": 0.02510184338697749,
      "loss": 2.4864,
      "step": 466060
    },
    {
      "epoch": 749.32,
      "learning_rate": 0.025098627956109322,
      "loss": 2.478,
      "step": 466080
    },
    {
      "epoch": 749.36,
      "learning_rate": 0.025095412525241154,
      "loss": 2.4742,
      "step": 466100
    },
    {
      "epoch": 749.39,
      "learning_rate": 0.025092197094372992,
      "loss": 2.4972,
      "step": 466120
    },
    {
      "epoch": 749.42,
      "learning_rate": 0.025088981663504824,
      "loss": 2.4996,
      "step": 466140
    },
    {
      "epoch": 749.45,
      "learning_rate": 0.025085766232636655,
      "loss": 2.5018,
      "step": 466160
    },
    {
      "epoch": 749.49,
      "learning_rate": 0.025082550801768484,
      "loss": 2.4982,
      "step": 466180
    },
    {
      "epoch": 749.52,
      "learning_rate": 0.02507933537090032,
      "loss": 2.4862,
      "step": 466200
    },
    {
      "epoch": 749.55,
      "learning_rate": 0.02507611994003216,
      "loss": 2.4962,
      "step": 466220
    },
    {
      "epoch": 749.58,
      "learning_rate": 0.025072904509163985,
      "loss": 2.5028,
      "step": 466240
    },
    {
      "epoch": 749.61,
      "learning_rate": 0.02506968907829582,
      "loss": 2.478,
      "step": 466260
    },
    {
      "epoch": 749.65,
      "learning_rate": 0.025066473647427652,
      "loss": 2.4998,
      "step": 466280
    },
    {
      "epoch": 749.68,
      "learning_rate": 0.025063258216559484,
      "loss": 2.5014,
      "step": 466300
    },
    {
      "epoch": 749.71,
      "learning_rate": 0.025060042785691312,
      "loss": 2.4846,
      "step": 466320
    },
    {
      "epoch": 749.74,
      "learning_rate": 0.025056827354823154,
      "loss": 2.4782,
      "step": 466340
    },
    {
      "epoch": 749.77,
      "learning_rate": 0.025053611923954985,
      "loss": 2.4726,
      "step": 466360
    },
    {
      "epoch": 749.81,
      "learning_rate": 0.025050396493086814,
      "loss": 2.4808,
      "step": 466380
    },
    {
      "epoch": 749.84,
      "learning_rate": 0.02504718106221865,
      "loss": 2.4942,
      "step": 466400
    },
    {
      "epoch": 749.87,
      "learning_rate": 0.02504396563135048,
      "loss": 2.4647,
      "step": 466420
    },
    {
      "epoch": 749.9,
      "learning_rate": 0.025040750200482322,
      "loss": 2.5122,
      "step": 466440
    },
    {
      "epoch": 749.94,
      "learning_rate": 0.02503753476961415,
      "loss": 2.4668,
      "step": 466460
    },
    {
      "epoch": 749.97,
      "learning_rate": 0.025034319338745982,
      "loss": 2.4833,
      "step": 466480
    },
    {
      "epoch": 750.0,
      "learning_rate": 0.025031103907877814,
      "loss": 2.4719,
      "step": 466500
    },
    {
      "epoch": 750.0,
      "eval_accuracy": {
        "accuracy": 0.4481069734898546
      },
      "eval_loss": 2.5770809650421143,
      "eval_runtime": 3.0035,
      "eval_samples_per_second": 4282.65,
      "eval_steps_per_second": 66.922,
      "step": 466500
    },
    {
      "epoch": 750.03,
      "learning_rate": 0.02502788847700964,
      "loss": 2.4614,
      "step": 466520
    },
    {
      "epoch": 750.06,
      "learning_rate": 0.025024673046141473,
      "loss": 2.4711,
      "step": 466540
    },
    {
      "epoch": 750.1,
      "learning_rate": 0.025021457615273315,
      "loss": 2.481,
      "step": 466560
    },
    {
      "epoch": 750.13,
      "learning_rate": 0.025018242184405143,
      "loss": 2.4732,
      "step": 466580
    },
    {
      "epoch": 750.16,
      "learning_rate": 0.02501502675353698,
      "loss": 2.4808,
      "step": 466600
    },
    {
      "epoch": 750.19,
      "learning_rate": 0.02501181132266881,
      "loss": 2.4825,
      "step": 466620
    },
    {
      "epoch": 750.23,
      "learning_rate": 0.025008595891800642,
      "loss": 2.4789,
      "step": 466640
    },
    {
      "epoch": 750.26,
      "learning_rate": 0.02500538046093247,
      "loss": 2.508,
      "step": 466660
    },
    {
      "epoch": 750.29,
      "learning_rate": 0.025002165030064312,
      "loss": 2.4844,
      "step": 466680
    },
    {
      "epoch": 750.32,
      "learning_rate": 0.024998949599196144,
      "loss": 2.4713,
      "step": 466700
    },
    {
      "epoch": 750.35,
      "learning_rate": 0.024995734168327975,
      "loss": 2.4686,
      "step": 466720
    },
    {
      "epoch": 750.39,
      "learning_rate": 0.024992518737459807,
      "loss": 2.4741,
      "step": 466740
    },
    {
      "epoch": 750.42,
      "learning_rate": 0.024989303306591635,
      "loss": 2.4756,
      "step": 466760
    },
    {
      "epoch": 750.45,
      "learning_rate": 0.024986087875723477,
      "loss": 2.4837,
      "step": 466780
    },
    {
      "epoch": 750.48,
      "learning_rate": 0.02498287244485531,
      "loss": 2.5024,
      "step": 466800
    },
    {
      "epoch": 750.51,
      "learning_rate": 0.02497965701398714,
      "loss": 2.4692,
      "step": 466820
    },
    {
      "epoch": 750.55,
      "learning_rate": 0.024976441583118972,
      "loss": 2.4779,
      "step": 466840
    },
    {
      "epoch": 750.58,
      "learning_rate": 0.0249732261522508,
      "loss": 2.4972,
      "step": 466860
    },
    {
      "epoch": 750.61,
      "learning_rate": 0.02497001072138263,
      "loss": 2.4877,
      "step": 466880
    },
    {
      "epoch": 750.64,
      "learning_rate": 0.024966795290514474,
      "loss": 2.474,
      "step": 466900
    },
    {
      "epoch": 750.68,
      "learning_rate": 0.024963579859646305,
      "loss": 2.4628,
      "step": 466920
    },
    {
      "epoch": 750.71,
      "learning_rate": 0.024960364428778137,
      "loss": 2.4986,
      "step": 466940
    },
    {
      "epoch": 750.74,
      "learning_rate": 0.02495714899790997,
      "loss": 2.4939,
      "step": 466960
    },
    {
      "epoch": 750.77,
      "learning_rate": 0.024953933567041797,
      "loss": 2.4701,
      "step": 466980
    },
    {
      "epoch": 750.8,
      "learning_rate": 0.024950718136173628,
      "loss": 2.4797,
      "step": 467000
    },
    {
      "epoch": 750.84,
      "learning_rate": 0.02494750270530547,
      "loss": 2.4834,
      "step": 467020
    },
    {
      "epoch": 750.87,
      "learning_rate": 0.024944287274437302,
      "loss": 2.489,
      "step": 467040
    },
    {
      "epoch": 750.9,
      "learning_rate": 0.024941071843569133,
      "loss": 2.4649,
      "step": 467060
    },
    {
      "epoch": 750.93,
      "learning_rate": 0.02493785641270096,
      "loss": 2.4899,
      "step": 467080
    },
    {
      "epoch": 750.96,
      "learning_rate": 0.024934640981832793,
      "loss": 2.4837,
      "step": 467100
    },
    {
      "epoch": 751.0,
      "learning_rate": 0.024931425550964635,
      "loss": 2.4843,
      "step": 467120
    },
    {
      "epoch": 751.0,
      "eval_accuracy": {
        "accuracy": 0.44033273730855943
      },
      "eval_loss": 2.606766939163208,
      "eval_runtime": 2.9378,
      "eval_samples_per_second": 4378.375,
      "eval_steps_per_second": 68.417,
      "step": 467122
    },
    {
      "epoch": 751.03,
      "learning_rate": 0.024928210120096467,
      "loss": 2.4978,
      "step": 467140
    },
    {
      "epoch": 751.06,
      "learning_rate": 0.0249249946892283,
      "loss": 2.4785,
      "step": 467160
    },
    {
      "epoch": 751.09,
      "learning_rate": 0.024921779258360127,
      "loss": 2.4962,
      "step": 467180
    },
    {
      "epoch": 751.13,
      "learning_rate": 0.024918563827491958,
      "loss": 2.4997,
      "step": 467200
    },
    {
      "epoch": 751.16,
      "learning_rate": 0.02491534839662379,
      "loss": 2.4749,
      "step": 467220
    },
    {
      "epoch": 751.19,
      "learning_rate": 0.024912132965755632,
      "loss": 2.495,
      "step": 467240
    },
    {
      "epoch": 751.22,
      "learning_rate": 0.024908917534887463,
      "loss": 2.4836,
      "step": 467260
    },
    {
      "epoch": 751.25,
      "learning_rate": 0.024905702104019295,
      "loss": 2.4868,
      "step": 467280
    },
    {
      "epoch": 751.29,
      "learning_rate": 0.024902486673151123,
      "loss": 2.4853,
      "step": 467300
    },
    {
      "epoch": 751.32,
      "learning_rate": 0.024899271242282955,
      "loss": 2.4778,
      "step": 467320
    },
    {
      "epoch": 751.35,
      "learning_rate": 0.024896055811414786,
      "loss": 2.478,
      "step": 467340
    },
    {
      "epoch": 751.38,
      "learning_rate": 0.02489284038054663,
      "loss": 2.4737,
      "step": 467360
    },
    {
      "epoch": 751.41,
      "learning_rate": 0.02488962494967846,
      "loss": 2.4847,
      "step": 467380
    },
    {
      "epoch": 751.45,
      "learning_rate": 0.024886409518810288,
      "loss": 2.4942,
      "step": 467400
    },
    {
      "epoch": 751.48,
      "learning_rate": 0.02488319408794212,
      "loss": 2.4775,
      "step": 467420
    },
    {
      "epoch": 751.51,
      "learning_rate": 0.024880139428617363,
      "loss": 2.4808,
      "step": 467440
    },
    {
      "epoch": 751.54,
      "learning_rate": 0.024876923997749194,
      "loss": 2.4824,
      "step": 467460
    },
    {
      "epoch": 751.58,
      "learning_rate": 0.024873708566881023,
      "loss": 2.4637,
      "step": 467480
    },
    {
      "epoch": 751.61,
      "learning_rate": 0.024870493136012865,
      "loss": 2.4723,
      "step": 467500
    },
    {
      "epoch": 751.64,
      "learning_rate": 0.024867277705144696,
      "loss": 2.4901,
      "step": 467520
    },
    {
      "epoch": 751.67,
      "learning_rate": 0.024864062274276528,
      "loss": 2.4708,
      "step": 467540
    },
    {
      "epoch": 751.7,
      "learning_rate": 0.02486084684340836,
      "loss": 2.485,
      "step": 467560
    },
    {
      "epoch": 751.74,
      "learning_rate": 0.024857631412540188,
      "loss": 2.4881,
      "step": 467580
    },
    {
      "epoch": 751.77,
      "learning_rate": 0.02485441598167203,
      "loss": 2.4788,
      "step": 467600
    },
    {
      "epoch": 751.8,
      "learning_rate": 0.02485120055080386,
      "loss": 2.4871,
      "step": 467620
    },
    {
      "epoch": 751.83,
      "learning_rate": 0.024847985119935693,
      "loss": 2.4562,
      "step": 467640
    },
    {
      "epoch": 751.86,
      "learning_rate": 0.024844769689067524,
      "loss": 2.4679,
      "step": 467660
    },
    {
      "epoch": 751.9,
      "learning_rate": 0.024841554258199356,
      "loss": 2.4677,
      "step": 467680
    },
    {
      "epoch": 751.93,
      "learning_rate": 0.024838338827331184,
      "loss": 2.4824,
      "step": 467700
    },
    {
      "epoch": 751.96,
      "learning_rate": 0.024835123396463026,
      "loss": 2.4665,
      "step": 467720
    },
    {
      "epoch": 751.99,
      "learning_rate": 0.024831907965594858,
      "loss": 2.4925,
      "step": 467740
    },
    {
      "epoch": 752.0,
      "eval_accuracy": {
        "accuracy": 0.4465521262535956
      },
      "eval_loss": 2.5881056785583496,
      "eval_runtime": 3.0047,
      "eval_samples_per_second": 4280.973,
      "eval_steps_per_second": 66.895,
      "step": 467744
    },
    {
      "epoch": 752.03,
      "learning_rate": 0.02482869253472669,
      "loss": 2.4741,
      "step": 467760
    },
    {
      "epoch": 752.06,
      "learning_rate": 0.02482547710385852,
      "loss": 2.4948,
      "step": 467780
    },
    {
      "epoch": 752.09,
      "learning_rate": 0.02482226167299035,
      "loss": 2.4881,
      "step": 467800
    },
    {
      "epoch": 752.12,
      "learning_rate": 0.02481904624212218,
      "loss": 2.4571,
      "step": 467820
    },
    {
      "epoch": 752.15,
      "learning_rate": 0.024815830811254023,
      "loss": 2.4991,
      "step": 467840
    },
    {
      "epoch": 752.19,
      "learning_rate": 0.024812615380385854,
      "loss": 2.4921,
      "step": 467860
    },
    {
      "epoch": 752.22,
      "learning_rate": 0.024809399949517686,
      "loss": 2.4886,
      "step": 467880
    },
    {
      "epoch": 752.25,
      "learning_rate": 0.024806184518649514,
      "loss": 2.485,
      "step": 467900
    },
    {
      "epoch": 752.28,
      "learning_rate": 0.024802969087781346,
      "loss": 2.4841,
      "step": 467920
    },
    {
      "epoch": 752.32,
      "learning_rate": 0.024799753656913188,
      "loss": 2.4931,
      "step": 467940
    },
    {
      "epoch": 752.35,
      "learning_rate": 0.02479653822604502,
      "loss": 2.4571,
      "step": 467960
    },
    {
      "epoch": 752.38,
      "learning_rate": 0.02479332279517685,
      "loss": 2.4701,
      "step": 467980
    },
    {
      "epoch": 752.41,
      "learning_rate": 0.024790107364308683,
      "loss": 2.4855,
      "step": 468000
    },
    {
      "epoch": 752.44,
      "learning_rate": 0.02478689193344051,
      "loss": 2.497,
      "step": 468020
    },
    {
      "epoch": 752.48,
      "learning_rate": 0.024783676502572342,
      "loss": 2.4837,
      "step": 468040
    },
    {
      "epoch": 752.51,
      "learning_rate": 0.024780461071704184,
      "loss": 2.451,
      "step": 468060
    },
    {
      "epoch": 752.54,
      "learning_rate": 0.024777245640836016,
      "loss": 2.4768,
      "step": 468080
    },
    {
      "epoch": 752.57,
      "learning_rate": 0.024774030209967848,
      "loss": 2.4753,
      "step": 468100
    },
    {
      "epoch": 752.6,
      "learning_rate": 0.024770814779099676,
      "loss": 2.4802,
      "step": 468120
    },
    {
      "epoch": 752.64,
      "learning_rate": 0.024767599348231507,
      "loss": 2.4876,
      "step": 468140
    },
    {
      "epoch": 752.67,
      "learning_rate": 0.02476438391736334,
      "loss": 2.4668,
      "step": 468160
    },
    {
      "epoch": 752.7,
      "learning_rate": 0.02476116848649518,
      "loss": 2.4841,
      "step": 468180
    },
    {
      "epoch": 752.73,
      "learning_rate": 0.024757953055627013,
      "loss": 2.476,
      "step": 468200
    },
    {
      "epoch": 752.77,
      "learning_rate": 0.02475473762475884,
      "loss": 2.4876,
      "step": 468220
    },
    {
      "epoch": 752.8,
      "learning_rate": 0.024751522193890672,
      "loss": 2.4885,
      "step": 468240
    },
    {
      "epoch": 752.83,
      "learning_rate": 0.024748306763022504,
      "loss": 2.469,
      "step": 468260
    },
    {
      "epoch": 752.86,
      "learning_rate": 0.024745091332154346,
      "loss": 2.4598,
      "step": 468280
    },
    {
      "epoch": 752.89,
      "learning_rate": 0.024741875901286178,
      "loss": 2.488,
      "step": 468300
    },
    {
      "epoch": 752.93,
      "learning_rate": 0.02473866047041801,
      "loss": 2.4744,
      "step": 468320
    },
    {
      "epoch": 752.96,
      "learning_rate": 0.024735445039549837,
      "loss": 2.4846,
      "step": 468340
    },
    {
      "epoch": 752.99,
      "learning_rate": 0.02473222960868167,
      "loss": 2.4885,
      "step": 468360
    },
    {
      "epoch": 753.0,
      "eval_accuracy": {
        "accuracy": 0.44453082484645884
      },
      "eval_loss": 2.593981981277466,
      "eval_runtime": 3.2097,
      "eval_samples_per_second": 4007.532,
      "eval_steps_per_second": 62.623,
      "step": 468366
    },
    {
      "epoch": 753.02,
      "learning_rate": 0.0247290141778135,
      "loss": 2.4821,
      "step": 468380
    },
    {
      "epoch": 753.05,
      "learning_rate": 0.024725798746945343,
      "loss": 2.4803,
      "step": 468400
    },
    {
      "epoch": 753.09,
      "learning_rate": 0.024722583316077174,
      "loss": 2.4679,
      "step": 468420
    },
    {
      "epoch": 753.12,
      "learning_rate": 0.024719367885209002,
      "loss": 2.4817,
      "step": 468440
    },
    {
      "epoch": 753.15,
      "learning_rate": 0.024716152454340834,
      "loss": 2.4856,
      "step": 468460
    },
    {
      "epoch": 753.18,
      "learning_rate": 0.024712937023472666,
      "loss": 2.4687,
      "step": 468480
    },
    {
      "epoch": 753.22,
      "learning_rate": 0.024709721592604497,
      "loss": 2.5142,
      "step": 468500
    },
    {
      "epoch": 753.25,
      "learning_rate": 0.02470650616173634,
      "loss": 2.4709,
      "step": 468520
    },
    {
      "epoch": 753.28,
      "learning_rate": 0.024703290730868167,
      "loss": 2.4902,
      "step": 468540
    },
    {
      "epoch": 753.31,
      "learning_rate": 0.0247000753,
      "loss": 2.4827,
      "step": 468560
    },
    {
      "epoch": 753.34,
      "learning_rate": 0.02469685986913183,
      "loss": 2.4804,
      "step": 468580
    },
    {
      "epoch": 753.38,
      "learning_rate": 0.024693644438263662,
      "loss": 2.4678,
      "step": 468600
    },
    {
      "epoch": 753.41,
      "learning_rate": 0.024690429007395504,
      "loss": 2.4922,
      "step": 468620
    },
    {
      "epoch": 753.44,
      "learning_rate": 0.024687213576527336,
      "loss": 2.473,
      "step": 468640
    },
    {
      "epoch": 753.47,
      "learning_rate": 0.024683998145659164,
      "loss": 2.4594,
      "step": 468660
    },
    {
      "epoch": 753.5,
      "learning_rate": 0.024680782714790996,
      "loss": 2.4784,
      "step": 468680
    },
    {
      "epoch": 753.54,
      "learning_rate": 0.024677567283922827,
      "loss": 2.4722,
      "step": 468700
    },
    {
      "epoch": 753.57,
      "learning_rate": 0.02467435185305466,
      "loss": 2.4569,
      "step": 468720
    },
    {
      "epoch": 753.6,
      "learning_rate": 0.0246711364221865,
      "loss": 2.4765,
      "step": 468740
    },
    {
      "epoch": 753.63,
      "learning_rate": 0.02466792099131833,
      "loss": 2.4707,
      "step": 468760
    },
    {
      "epoch": 753.67,
      "learning_rate": 0.02466470556045016,
      "loss": 2.4984,
      "step": 468780
    },
    {
      "epoch": 753.7,
      "learning_rate": 0.024661490129581992,
      "loss": 2.4983,
      "step": 468800
    },
    {
      "epoch": 753.73,
      "learning_rate": 0.024658274698713824,
      "loss": 2.4944,
      "step": 468820
    },
    {
      "epoch": 753.76,
      "learning_rate": 0.024655059267845666,
      "loss": 2.4861,
      "step": 468840
    },
    {
      "epoch": 753.79,
      "learning_rate": 0.024651843836977494,
      "loss": 2.4884,
      "step": 468860
    },
    {
      "epoch": 753.83,
      "learning_rate": 0.024648628406109326,
      "loss": 2.4722,
      "step": 468880
    },
    {
      "epoch": 753.86,
      "learning_rate": 0.024645412975241157,
      "loss": 2.4714,
      "step": 468900
    },
    {
      "epoch": 753.89,
      "learning_rate": 0.02464219754437299,
      "loss": 2.4683,
      "step": 468920
    },
    {
      "epoch": 753.92,
      "learning_rate": 0.02463898211350482,
      "loss": 2.4716,
      "step": 468940
    },
    {
      "epoch": 753.95,
      "learning_rate": 0.024635766682636662,
      "loss": 2.4623,
      "step": 468960
    },
    {
      "epoch": 753.99,
      "learning_rate": 0.02463255125176849,
      "loss": 2.4854,
      "step": 468980
    },
    {
      "epoch": 754.0,
      "eval_accuracy": {
        "accuracy": 0.44662986861540854
      },
      "eval_loss": 2.590425968170166,
      "eval_runtime": 3.0719,
      "eval_samples_per_second": 4187.311,
      "eval_steps_per_second": 65.432,
      "step": 468988
    },
    {
      "epoch": 754.02,
      "learning_rate": 0.024629335820900322,
      "loss": 2.4845,
      "step": 469000
    },
    {
      "epoch": 754.05,
      "learning_rate": 0.024626120390032154,
      "loss": 2.4525,
      "step": 469020
    },
    {
      "epoch": 754.08,
      "learning_rate": 0.024622904959163985,
      "loss": 2.4592,
      "step": 469040
    },
    {
      "epoch": 754.12,
      "learning_rate": 0.024619689528295814,
      "loss": 2.4955,
      "step": 469060
    },
    {
      "epoch": 754.15,
      "learning_rate": 0.024616474097427656,
      "loss": 2.4832,
      "step": 469080
    },
    {
      "epoch": 754.18,
      "learning_rate": 0.024613258666559487,
      "loss": 2.478,
      "step": 469100
    },
    {
      "epoch": 754.21,
      "learning_rate": 0.02461004323569132,
      "loss": 2.4909,
      "step": 469120
    },
    {
      "epoch": 754.24,
      "learning_rate": 0.02460682780482315,
      "loss": 2.4903,
      "step": 469140
    },
    {
      "epoch": 754.28,
      "learning_rate": 0.024603612373954982,
      "loss": 2.486,
      "step": 469160
    },
    {
      "epoch": 754.31,
      "learning_rate": 0.02460039694308682,
      "loss": 2.4915,
      "step": 469180
    },
    {
      "epoch": 754.34,
      "learning_rate": 0.024597181512218652,
      "loss": 2.4635,
      "step": 469200
    },
    {
      "epoch": 754.37,
      "learning_rate": 0.024593966081350484,
      "loss": 2.4814,
      "step": 469220
    },
    {
      "epoch": 754.41,
      "learning_rate": 0.024590750650482315,
      "loss": 2.4782,
      "step": 469240
    },
    {
      "epoch": 754.44,
      "learning_rate": 0.024587535219614147,
      "loss": 2.4947,
      "step": 469260
    },
    {
      "epoch": 754.47,
      "learning_rate": 0.024584319788745975,
      "loss": 2.5053,
      "step": 469280
    },
    {
      "epoch": 754.5,
      "learning_rate": 0.024581104357877817,
      "loss": 2.4872,
      "step": 469300
    },
    {
      "epoch": 754.53,
      "learning_rate": 0.02457788892700965,
      "loss": 2.492,
      "step": 469320
    },
    {
      "epoch": 754.57,
      "learning_rate": 0.02457467349614148,
      "loss": 2.4745,
      "step": 469340
    },
    {
      "epoch": 754.6,
      "learning_rate": 0.024571458065273312,
      "loss": 2.4808,
      "step": 469360
    },
    {
      "epoch": 754.63,
      "learning_rate": 0.02456824263440514,
      "loss": 2.4772,
      "step": 469380
    },
    {
      "epoch": 754.66,
      "learning_rate": 0.02456502720353697,
      "loss": 2.4702,
      "step": 469400
    },
    {
      "epoch": 754.69,
      "learning_rate": 0.024561811772668814,
      "loss": 2.4735,
      "step": 469420
    },
    {
      "epoch": 754.73,
      "learning_rate": 0.024558757113344057,
      "loss": 2.4687,
      "step": 469440
    },
    {
      "epoch": 754.76,
      "learning_rate": 0.02455554168247589,
      "loss": 2.4808,
      "step": 469460
    },
    {
      "epoch": 754.79,
      "learning_rate": 0.024552326251607717,
      "loss": 2.4866,
      "step": 469480
    },
    {
      "epoch": 754.82,
      "learning_rate": 0.024549110820739548,
      "loss": 2.4595,
      "step": 469500
    },
    {
      "epoch": 754.86,
      "learning_rate": 0.02454589538987138,
      "loss": 2.4652,
      "step": 469520
    },
    {
      "epoch": 754.89,
      "learning_rate": 0.02454267995900321,
      "loss": 2.4765,
      "step": 469540
    },
    {
      "epoch": 754.92,
      "learning_rate": 0.024539464528135053,
      "loss": 2.4772,
      "step": 469560
    },
    {
      "epoch": 754.95,
      "learning_rate": 0.02453624909726688,
      "loss": 2.4792,
      "step": 469580
    },
    {
      "epoch": 754.98,
      "learning_rate": 0.024533033666398713,
      "loss": 2.4812,
      "step": 469600
    },
    {
      "epoch": 755.0,
      "eval_accuracy": {
        "accuracy": 0.44593018735909196
      },
      "eval_loss": 2.6001062393188477,
      "eval_runtime": 3.1139,
      "eval_samples_per_second": 4130.793,
      "eval_steps_per_second": 64.549,
      "step": 469610
    },
    {
      "epoch": 755.02,
      "learning_rate": 0.024529818235530545,
      "loss": 2.4867,
      "step": 469620
    },
    {
      "epoch": 755.05,
      "learning_rate": 0.024526602804662376,
      "loss": 2.4542,
      "step": 469640
    },
    {
      "epoch": 755.08,
      "learning_rate": 0.02452338737379422,
      "loss": 2.461,
      "step": 469660
    },
    {
      "epoch": 755.11,
      "learning_rate": 0.02452017194292605,
      "loss": 2.4847,
      "step": 469680
    },
    {
      "epoch": 755.14,
      "learning_rate": 0.024516956512057878,
      "loss": 2.4633,
      "step": 469700
    },
    {
      "epoch": 755.18,
      "learning_rate": 0.02451374108118971,
      "loss": 2.4668,
      "step": 469720
    },
    {
      "epoch": 755.21,
      "learning_rate": 0.02451052565032154,
      "loss": 2.4773,
      "step": 469740
    },
    {
      "epoch": 755.24,
      "learning_rate": 0.024507310219453373,
      "loss": 2.487,
      "step": 469760
    },
    {
      "epoch": 755.27,
      "learning_rate": 0.024504094788585215,
      "loss": 2.4662,
      "step": 469780
    },
    {
      "epoch": 755.31,
      "learning_rate": 0.024500879357717043,
      "loss": 2.4736,
      "step": 469800
    },
    {
      "epoch": 755.34,
      "learning_rate": 0.024497663926848875,
      "loss": 2.458,
      "step": 469820
    },
    {
      "epoch": 755.37,
      "learning_rate": 0.024494448495980706,
      "loss": 2.4721,
      "step": 469840
    },
    {
      "epoch": 755.4,
      "learning_rate": 0.024491233065112538,
      "loss": 2.4852,
      "step": 469860
    },
    {
      "epoch": 755.43,
      "learning_rate": 0.02448801763424437,
      "loss": 2.4596,
      "step": 469880
    },
    {
      "epoch": 755.47,
      "learning_rate": 0.02448480220337621,
      "loss": 2.4928,
      "step": 469900
    },
    {
      "epoch": 755.5,
      "learning_rate": 0.02448158677250804,
      "loss": 2.485,
      "step": 469920
    },
    {
      "epoch": 755.53,
      "learning_rate": 0.02447837134163987,
      "loss": 2.4759,
      "step": 469940
    },
    {
      "epoch": 755.56,
      "learning_rate": 0.024475155910771703,
      "loss": 2.4776,
      "step": 469960
    },
    {
      "epoch": 755.59,
      "learning_rate": 0.024471940479903535,
      "loss": 2.4895,
      "step": 469980
    },
    {
      "epoch": 755.63,
      "learning_rate": 0.024468725049035377,
      "loss": 2.4865,
      "step": 470000
    },
    {
      "epoch": 755.66,
      "learning_rate": 0.024465509618167205,
      "loss": 2.4776,
      "step": 470020
    },
    {
      "epoch": 755.69,
      "learning_rate": 0.024462294187299036,
      "loss": 2.4948,
      "step": 470040
    },
    {
      "epoch": 755.72,
      "learning_rate": 0.024459078756430868,
      "loss": 2.4456,
      "step": 470060
    },
    {
      "epoch": 755.76,
      "learning_rate": 0.0244558633255627,
      "loss": 2.4953,
      "step": 470080
    },
    {
      "epoch": 755.79,
      "learning_rate": 0.024452647894694528,
      "loss": 2.4726,
      "step": 470100
    },
    {
      "epoch": 755.82,
      "learning_rate": 0.02444943246382637,
      "loss": 2.4868,
      "step": 470120
    },
    {
      "epoch": 755.85,
      "learning_rate": 0.0244462170329582,
      "loss": 2.4842,
      "step": 470140
    },
    {
      "epoch": 755.88,
      "learning_rate": 0.024443001602090033,
      "loss": 2.4824,
      "step": 470160
    },
    {
      "epoch": 755.92,
      "learning_rate": 0.024439786171221865,
      "loss": 2.4654,
      "step": 470180
    },
    {
      "epoch": 755.95,
      "learning_rate": 0.024436570740353696,
      "loss": 2.4934,
      "step": 470200
    },
    {
      "epoch": 755.98,
      "learning_rate": 0.024433355309485524,
      "loss": 2.4615,
      "step": 470220
    },
    {
      "epoch": 756.0,
      "eval_accuracy": {
        "accuracy": 0.44530824846458833
      },
      "eval_loss": 2.595226287841797,
      "eval_runtime": 3.0547,
      "eval_samples_per_second": 4210.906,
      "eval_steps_per_second": 65.801,
      "step": 470232
    },
    {
      "epoch": 756.01,
      "learning_rate": 0.024430139878617366,
      "loss": 2.4853,
      "step": 470240
    },
    {
      "epoch": 756.05,
      "learning_rate": 0.024426924447749198,
      "loss": 2.4593,
      "step": 470260
    },
    {
      "epoch": 756.08,
      "learning_rate": 0.02442370901688103,
      "loss": 2.4714,
      "step": 470280
    },
    {
      "epoch": 756.11,
      "learning_rate": 0.02442049358601286,
      "loss": 2.4654,
      "step": 470300
    },
    {
      "epoch": 756.14,
      "learning_rate": 0.02441727815514469,
      "loss": 2.482,
      "step": 470320
    },
    {
      "epoch": 756.17,
      "learning_rate": 0.02441406272427653,
      "loss": 2.4543,
      "step": 470340
    },
    {
      "epoch": 756.21,
      "learning_rate": 0.024410847293408363,
      "loss": 2.5036,
      "step": 470360
    },
    {
      "epoch": 756.24,
      "learning_rate": 0.024407631862540195,
      "loss": 2.4866,
      "step": 470380
    },
    {
      "epoch": 756.27,
      "learning_rate": 0.024404416431672026,
      "loss": 2.4655,
      "step": 470400
    },
    {
      "epoch": 756.3,
      "learning_rate": 0.024401201000803854,
      "loss": 2.4641,
      "step": 470420
    },
    {
      "epoch": 756.33,
      "learning_rate": 0.024397985569935686,
      "loss": 2.4814,
      "step": 470440
    },
    {
      "epoch": 756.37,
      "learning_rate": 0.024394770139067528,
      "loss": 2.4706,
      "step": 470460
    },
    {
      "epoch": 756.4,
      "learning_rate": 0.02439155470819936,
      "loss": 2.4646,
      "step": 470480
    },
    {
      "epoch": 756.43,
      "learning_rate": 0.02438833927733119,
      "loss": 2.4733,
      "step": 470500
    },
    {
      "epoch": 756.46,
      "learning_rate": 0.024385123846463023,
      "loss": 2.4721,
      "step": 470520
    },
    {
      "epoch": 756.5,
      "learning_rate": 0.02438190841559485,
      "loss": 2.4812,
      "step": 470540
    },
    {
      "epoch": 756.53,
      "learning_rate": 0.024378692984726683,
      "loss": 2.4823,
      "step": 470560
    },
    {
      "epoch": 756.56,
      "learning_rate": 0.024375477553858525,
      "loss": 2.4626,
      "step": 470580
    },
    {
      "epoch": 756.59,
      "learning_rate": 0.024372262122990356,
      "loss": 2.4812,
      "step": 470600
    },
    {
      "epoch": 756.62,
      "learning_rate": 0.024369046692122188,
      "loss": 2.469,
      "step": 470620
    },
    {
      "epoch": 756.66,
      "learning_rate": 0.024365831261254016,
      "loss": 2.4965,
      "step": 470640
    },
    {
      "epoch": 756.69,
      "learning_rate": 0.024362615830385848,
      "loss": 2.4895,
      "step": 470660
    },
    {
      "epoch": 756.72,
      "learning_rate": 0.02435940039951769,
      "loss": 2.4827,
      "step": 470680
    },
    {
      "epoch": 756.75,
      "learning_rate": 0.02435618496864952,
      "loss": 2.4741,
      "step": 470700
    },
    {
      "epoch": 756.78,
      "learning_rate": 0.024352969537781353,
      "loss": 2.4709,
      "step": 470720
    },
    {
      "epoch": 756.82,
      "learning_rate": 0.02434975410691318,
      "loss": 2.482,
      "step": 470740
    },
    {
      "epoch": 756.85,
      "learning_rate": 0.024346538676045013,
      "loss": 2.4775,
      "step": 470760
    },
    {
      "epoch": 756.88,
      "learning_rate": 0.024343323245176844,
      "loss": 2.4847,
      "step": 470780
    },
    {
      "epoch": 756.91,
      "learning_rate": 0.024340107814308686,
      "loss": 2.4997,
      "step": 470800
    },
    {
      "epoch": 756.95,
      "learning_rate": 0.024336892383440518,
      "loss": 2.4901,
      "step": 470820
    },
    {
      "epoch": 756.98,
      "learning_rate": 0.02433367695257235,
      "loss": 2.4865,
      "step": 470840
    },
    {
      "epoch": 757.0,
      "eval_accuracy": {
        "accuracy": 0.44725180750991217
      },
      "eval_loss": 2.582385540008545,
      "eval_runtime": 3.1897,
      "eval_samples_per_second": 4032.724,
      "eval_steps_per_second": 63.016,
      "step": 470854
    },
    {
      "epoch": 757.01,
      "learning_rate": 0.024330461521704178,
      "loss": 2.4537,
      "step": 470860
    },
    {
      "epoch": 757.04,
      "learning_rate": 0.02432724609083601,
      "loss": 2.4825,
      "step": 470880
    },
    {
      "epoch": 757.07,
      "learning_rate": 0.02432403065996784,
      "loss": 2.4944,
      "step": 470900
    },
    {
      "epoch": 757.11,
      "learning_rate": 0.024320815229099683,
      "loss": 2.4852,
      "step": 470920
    },
    {
      "epoch": 757.14,
      "learning_rate": 0.024317599798231514,
      "loss": 2.4719,
      "step": 470940
    },
    {
      "epoch": 757.17,
      "learning_rate": 0.024314384367363343,
      "loss": 2.479,
      "step": 470960
    },
    {
      "epoch": 757.2,
      "learning_rate": 0.024311168936495174,
      "loss": 2.4828,
      "step": 470980
    },
    {
      "epoch": 757.23,
      "learning_rate": 0.024307953505627006,
      "loss": 2.4774,
      "step": 471000
    },
    {
      "epoch": 757.27,
      "learning_rate": 0.02430489884630225,
      "loss": 2.4714,
      "step": 471020
    },
    {
      "epoch": 757.3,
      "learning_rate": 0.024301683415434077,
      "loss": 2.494,
      "step": 471040
    },
    {
      "epoch": 757.33,
      "learning_rate": 0.02429846798456592,
      "loss": 2.4623,
      "step": 471060
    },
    {
      "epoch": 757.36,
      "learning_rate": 0.02429525255369775,
      "loss": 2.491,
      "step": 471080
    },
    {
      "epoch": 757.4,
      "learning_rate": 0.024292037122829582,
      "loss": 2.4648,
      "step": 471100
    },
    {
      "epoch": 757.43,
      "learning_rate": 0.024288821691961414,
      "loss": 2.4599,
      "step": 471120
    },
    {
      "epoch": 757.46,
      "learning_rate": 0.024285606261093242,
      "loss": 2.4787,
      "step": 471140
    },
    {
      "epoch": 757.49,
      "learning_rate": 0.024282390830225084,
      "loss": 2.4645,
      "step": 471160
    },
    {
      "epoch": 757.52,
      "learning_rate": 0.024279175399356916,
      "loss": 2.4651,
      "step": 471180
    },
    {
      "epoch": 757.56,
      "learning_rate": 0.024275959968488747,
      "loss": 2.4613,
      "step": 471200
    },
    {
      "epoch": 757.59,
      "learning_rate": 0.02427274453762058,
      "loss": 2.4774,
      "step": 471220
    },
    {
      "epoch": 757.62,
      "learning_rate": 0.02426952910675241,
      "loss": 2.4788,
      "step": 471240
    },
    {
      "epoch": 757.65,
      "learning_rate": 0.02426631367588424,
      "loss": 2.4869,
      "step": 471260
    },
    {
      "epoch": 757.68,
      "learning_rate": 0.02426309824501608,
      "loss": 2.4863,
      "step": 471280
    },
    {
      "epoch": 757.72,
      "learning_rate": 0.024259882814147912,
      "loss": 2.4899,
      "step": 471300
    },
    {
      "epoch": 757.75,
      "learning_rate": 0.024256667383279744,
      "loss": 2.494,
      "step": 471320
    },
    {
      "epoch": 757.78,
      "learning_rate": 0.024253451952411575,
      "loss": 2.4677,
      "step": 471340
    },
    {
      "epoch": 757.81,
      "learning_rate": 0.024250236521543404,
      "loss": 2.4557,
      "step": 471360
    },
    {
      "epoch": 757.85,
      "learning_rate": 0.024247021090675235,
      "loss": 2.4645,
      "step": 471380
    },
    {
      "epoch": 757.88,
      "learning_rate": 0.024243805659807077,
      "loss": 2.4708,
      "step": 471400
    },
    {
      "epoch": 757.91,
      "learning_rate": 0.02424059022893891,
      "loss": 2.4663,
      "step": 471420
    },
    {
      "epoch": 757.94,
      "learning_rate": 0.02423737479807074,
      "loss": 2.484,
      "step": 471440
    },
    {
      "epoch": 757.97,
      "learning_rate": 0.02423415936720257,
      "loss": 2.4415,
      "step": 471460
    },
    {
      "epoch": 758.0,
      "eval_accuracy": {
        "accuracy": 0.44616341444453084
      },
      "eval_loss": 2.581749200820923,
      "eval_runtime": 3.3153,
      "eval_samples_per_second": 3879.833,
      "eval_steps_per_second": 60.627,
      "step": 471476
    },
    {
      "epoch": 758.01,
      "learning_rate": 0.0242309439363344,
      "loss": 2.4911,
      "step": 471480
    },
    {
      "epoch": 758.04,
      "learning_rate": 0.024227728505466242,
      "loss": 2.492,
      "step": 471500
    },
    {
      "epoch": 758.07,
      "learning_rate": 0.024224513074598074,
      "loss": 2.4832,
      "step": 471520
    },
    {
      "epoch": 758.1,
      "learning_rate": 0.024221297643729905,
      "loss": 2.4849,
      "step": 471540
    },
    {
      "epoch": 758.14,
      "learning_rate": 0.024218082212861737,
      "loss": 2.4783,
      "step": 471560
    },
    {
      "epoch": 758.17,
      "learning_rate": 0.024214866781993565,
      "loss": 2.4738,
      "step": 471580
    },
    {
      "epoch": 758.2,
      "learning_rate": 0.024211651351125397,
      "loss": 2.465,
      "step": 471600
    },
    {
      "epoch": 758.23,
      "learning_rate": 0.02420843592025724,
      "loss": 2.4711,
      "step": 471620
    },
    {
      "epoch": 758.26,
      "learning_rate": 0.02420522048938907,
      "loss": 2.4732,
      "step": 471640
    },
    {
      "epoch": 758.3,
      "learning_rate": 0.024202005058520902,
      "loss": 2.4697,
      "step": 471660
    },
    {
      "epoch": 758.33,
      "learning_rate": 0.02419878962765273,
      "loss": 2.4737,
      "step": 471680
    },
    {
      "epoch": 758.36,
      "learning_rate": 0.024195574196784562,
      "loss": 2.482,
      "step": 471700
    },
    {
      "epoch": 758.39,
      "learning_rate": 0.024192358765916393,
      "loss": 2.5015,
      "step": 471720
    },
    {
      "epoch": 758.42,
      "learning_rate": 0.024189143335048235,
      "loss": 2.477,
      "step": 471740
    },
    {
      "epoch": 758.46,
      "learning_rate": 0.024185927904180067,
      "loss": 2.4698,
      "step": 471760
    },
    {
      "epoch": 758.49,
      "learning_rate": 0.0241827124733119,
      "loss": 2.4772,
      "step": 471780
    },
    {
      "epoch": 758.52,
      "learning_rate": 0.024179497042443727,
      "loss": 2.4755,
      "step": 471800
    },
    {
      "epoch": 758.55,
      "learning_rate": 0.02417628161157556,
      "loss": 2.4713,
      "step": 471820
    },
    {
      "epoch": 758.59,
      "learning_rate": 0.0241730661807074,
      "loss": 2.4764,
      "step": 471840
    },
    {
      "epoch": 758.62,
      "learning_rate": 0.024169850749839232,
      "loss": 2.4727,
      "step": 471860
    },
    {
      "epoch": 758.65,
      "learning_rate": 0.024166635318971064,
      "loss": 2.4791,
      "step": 471880
    },
    {
      "epoch": 758.68,
      "learning_rate": 0.024163419888102892,
      "loss": 2.4945,
      "step": 471900
    },
    {
      "epoch": 758.71,
      "learning_rate": 0.024160204457234723,
      "loss": 2.4722,
      "step": 471920
    },
    {
      "epoch": 758.75,
      "learning_rate": 0.024156989026366555,
      "loss": 2.486,
      "step": 471940
    },
    {
      "epoch": 758.78,
      "learning_rate": 0.024153773595498397,
      "loss": 2.4738,
      "step": 471960
    },
    {
      "epoch": 758.81,
      "learning_rate": 0.02415055816463023,
      "loss": 2.4808,
      "step": 471980
    },
    {
      "epoch": 758.84,
      "learning_rate": 0.024147342733762057,
      "loss": 2.4921,
      "step": 472000
    },
    {
      "epoch": 758.87,
      "learning_rate": 0.02414412730289389,
      "loss": 2.4657,
      "step": 472020
    },
    {
      "epoch": 758.91,
      "learning_rate": 0.02414091187202572,
      "loss": 2.4787,
      "step": 472040
    },
    {
      "epoch": 758.94,
      "learning_rate": 0.02413769644115755,
      "loss": 2.4628,
      "step": 472060
    },
    {
      "epoch": 758.97,
      "learning_rate": 0.024134481010289394,
      "loss": 2.4815,
      "step": 472080
    },
    {
      "epoch": 759.0,
      "eval_accuracy": {
        "accuracy": 0.44616341444453084
      },
      "eval_loss": 2.600436210632324,
      "eval_runtime": 2.9952,
      "eval_samples_per_second": 4294.529,
      "eval_steps_per_second": 67.107,
      "step": 472098
    },
    {
      "epoch": 759.0,
      "learning_rate": 0.024131265579421225,
      "loss": 2.4865,
      "step": 472100
    },
    {
      "epoch": 759.04,
      "learning_rate": 0.024128050148553053,
      "loss": 2.4864,
      "step": 472120
    },
    {
      "epoch": 759.07,
      "learning_rate": 0.024124834717684885,
      "loss": 2.477,
      "step": 472140
    },
    {
      "epoch": 759.1,
      "learning_rate": 0.024121619286816717,
      "loss": 2.4505,
      "step": 472160
    },
    {
      "epoch": 759.13,
      "learning_rate": 0.02411840385594856,
      "loss": 2.4502,
      "step": 472180
    },
    {
      "epoch": 759.16,
      "learning_rate": 0.02411518842508039,
      "loss": 2.4795,
      "step": 472200
    },
    {
      "epoch": 759.2,
      "learning_rate": 0.02411197299421222,
      "loss": 2.4941,
      "step": 472220
    },
    {
      "epoch": 759.23,
      "learning_rate": 0.02410875756334405,
      "loss": 2.4837,
      "step": 472240
    },
    {
      "epoch": 759.26,
      "learning_rate": 0.02410554213247588,
      "loss": 2.479,
      "step": 472260
    },
    {
      "epoch": 759.29,
      "learning_rate": 0.024102326701607713,
      "loss": 2.4763,
      "step": 472280
    },
    {
      "epoch": 759.32,
      "learning_rate": 0.024099111270739555,
      "loss": 2.4867,
      "step": 472300
    },
    {
      "epoch": 759.36,
      "learning_rate": 0.024095895839871383,
      "loss": 2.4561,
      "step": 472320
    },
    {
      "epoch": 759.39,
      "learning_rate": 0.024092680409003215,
      "loss": 2.4784,
      "step": 472340
    },
    {
      "epoch": 759.42,
      "learning_rate": 0.024089464978135047,
      "loss": 2.4886,
      "step": 472360
    },
    {
      "epoch": 759.45,
      "learning_rate": 0.024086249547266878,
      "loss": 2.4799,
      "step": 472380
    },
    {
      "epoch": 759.49,
      "learning_rate": 0.02408303411639872,
      "loss": 2.4919,
      "step": 472400
    },
    {
      "epoch": 759.52,
      "learning_rate": 0.024079818685530552,
      "loss": 2.4736,
      "step": 472420
    },
    {
      "epoch": 759.55,
      "learning_rate": 0.02407660325466238,
      "loss": 2.453,
      "step": 472440
    },
    {
      "epoch": 759.58,
      "learning_rate": 0.02407338782379421,
      "loss": 2.4801,
      "step": 472460
    },
    {
      "epoch": 759.61,
      "learning_rate": 0.024070172392926043,
      "loss": 2.4788,
      "step": 472480
    },
    {
      "epoch": 759.65,
      "learning_rate": 0.024066956962057875,
      "loss": 2.4802,
      "step": 472500
    },
    {
      "epoch": 759.68,
      "learning_rate": 0.024063741531189717,
      "loss": 2.4799,
      "step": 472520
    },
    {
      "epoch": 759.71,
      "learning_rate": 0.024060526100321545,
      "loss": 2.4762,
      "step": 472540
    },
    {
      "epoch": 759.74,
      "learning_rate": 0.024057310669453377,
      "loss": 2.4859,
      "step": 472560
    },
    {
      "epoch": 759.77,
      "learning_rate": 0.024054095238585208,
      "loss": 2.4611,
      "step": 472580
    },
    {
      "epoch": 759.81,
      "learning_rate": 0.02405087980771704,
      "loss": 2.4699,
      "step": 472600
    },
    {
      "epoch": 759.84,
      "learning_rate": 0.024047664376848868,
      "loss": 2.4843,
      "step": 472620
    },
    {
      "epoch": 759.87,
      "learning_rate": 0.02404444894598071,
      "loss": 2.4613,
      "step": 472640
    },
    {
      "epoch": 759.9,
      "learning_rate": 0.02404123351511254,
      "loss": 2.4973,
      "step": 472660
    },
    {
      "epoch": 759.94,
      "learning_rate": 0.024038018084244373,
      "loss": 2.4786,
      "step": 472680
    },
    {
      "epoch": 759.97,
      "learning_rate": 0.024034802653376205,
      "loss": 2.4772,
      "step": 472700
    },
    {
      "epoch": 760.0,
      "learning_rate": 0.024031587222508036,
      "loss": 2.455,
      "step": 472720
    },
    {
      "epoch": 760.0,
      "eval_accuracy": {
        "accuracy": 0.4497395630879266
      },
      "eval_loss": 2.5892202854156494,
      "eval_runtime": 3.0702,
      "eval_samples_per_second": 4189.64,
      "eval_steps_per_second": 65.468,
      "step": 472720
    },
    {
      "epoch": 760.03,
      "learning_rate": 0.02402837179163988,
      "loss": 2.4565,
      "step": 472740
    },
    {
      "epoch": 760.06,
      "learning_rate": 0.024025156360771707,
      "loss": 2.471,
      "step": 472760
    },
    {
      "epoch": 760.1,
      "learning_rate": 0.024021940929903538,
      "loss": 2.482,
      "step": 472780
    },
    {
      "epoch": 760.13,
      "learning_rate": 0.02401872549903537,
      "loss": 2.4786,
      "step": 472800
    },
    {
      "epoch": 760.16,
      "learning_rate": 0.0240155100681672,
      "loss": 2.4767,
      "step": 472820
    },
    {
      "epoch": 760.19,
      "learning_rate": 0.02401229463729903,
      "loss": 2.4599,
      "step": 472840
    },
    {
      "epoch": 760.23,
      "learning_rate": 0.02400907920643087,
      "loss": 2.4692,
      "step": 472860
    },
    {
      "epoch": 760.26,
      "learning_rate": 0.024005863775562703,
      "loss": 2.478,
      "step": 472880
    },
    {
      "epoch": 760.29,
      "learning_rate": 0.024002648344694535,
      "loss": 2.4756,
      "step": 472900
    },
    {
      "epoch": 760.32,
      "learning_rate": 0.023999432913826366,
      "loss": 2.4872,
      "step": 472920
    },
    {
      "epoch": 760.35,
      "learning_rate": 0.023996217482958195,
      "loss": 2.4746,
      "step": 472940
    },
    {
      "epoch": 760.39,
      "learning_rate": 0.023993002052090026,
      "loss": 2.4694,
      "step": 472960
    },
    {
      "epoch": 760.42,
      "learning_rate": 0.023989786621221868,
      "loss": 2.4749,
      "step": 472980
    },
    {
      "epoch": 760.45,
      "learning_rate": 0.0239865711903537,
      "loss": 2.4689,
      "step": 473000
    },
    {
      "epoch": 760.48,
      "learning_rate": 0.02398335575948553,
      "loss": 2.4808,
      "step": 473020
    },
    {
      "epoch": 760.51,
      "learning_rate": 0.023980140328617363,
      "loss": 2.4663,
      "step": 473040
    },
    {
      "epoch": 760.55,
      "learning_rate": 0.02397692489774919,
      "loss": 2.4662,
      "step": 473060
    },
    {
      "epoch": 760.58,
      "learning_rate": 0.023973709466881033,
      "loss": 2.4866,
      "step": 473080
    },
    {
      "epoch": 760.61,
      "learning_rate": 0.023970494036012865,
      "loss": 2.4776,
      "step": 473100
    },
    {
      "epoch": 760.64,
      "learning_rate": 0.023967278605144696,
      "loss": 2.4611,
      "step": 473120
    },
    {
      "epoch": 760.68,
      "learning_rate": 0.023964063174276528,
      "loss": 2.4703,
      "step": 473140
    },
    {
      "epoch": 760.71,
      "learning_rate": 0.023960847743408356,
      "loss": 2.4618,
      "step": 473160
    },
    {
      "epoch": 760.74,
      "learning_rate": 0.023957632312540188,
      "loss": 2.4749,
      "step": 473180
    },
    {
      "epoch": 760.77,
      "learning_rate": 0.02395441688167203,
      "loss": 2.4892,
      "step": 473200
    },
    {
      "epoch": 760.8,
      "learning_rate": 0.02395120145080386,
      "loss": 2.4747,
      "step": 473220
    },
    {
      "epoch": 760.84,
      "learning_rate": 0.023947986019935693,
      "loss": 2.4741,
      "step": 473240
    },
    {
      "epoch": 760.87,
      "learning_rate": 0.02394477058906752,
      "loss": 2.4776,
      "step": 473260
    },
    {
      "epoch": 760.9,
      "learning_rate": 0.023941555158199353,
      "loss": 2.4864,
      "step": 473280
    },
    {
      "epoch": 760.93,
      "learning_rate": 0.023938339727331184,
      "loss": 2.4638,
      "step": 473300
    },
    {
      "epoch": 760.96,
      "learning_rate": 0.023935124296463026,
      "loss": 2.4583,
      "step": 473320
    },
    {
      "epoch": 761.0,
      "learning_rate": 0.023931908865594858,
      "loss": 2.4671,
      "step": 473340
    },
    {
      "epoch": 761.0,
      "eval_accuracy": {
        "accuracy": 0.44872891238435825
      },
      "eval_loss": 2.579211473464966,
      "eval_runtime": 3.0153,
      "eval_samples_per_second": 4265.934,
      "eval_steps_per_second": 66.66,
      "step": 473342
    },
    {
      "epoch": 761.03,
      "learning_rate": 0.02392869343472669,
      "loss": 2.4861,
      "step": 473360
    },
    {
      "epoch": 761.06,
      "learning_rate": 0.023925478003858518,
      "loss": 2.4668,
      "step": 473380
    },
    {
      "epoch": 761.09,
      "learning_rate": 0.02392226257299035,
      "loss": 2.4795,
      "step": 473400
    },
    {
      "epoch": 761.13,
      "learning_rate": 0.02391904714212219,
      "loss": 2.463,
      "step": 473420
    },
    {
      "epoch": 761.16,
      "learning_rate": 0.023915831711254023,
      "loss": 2.467,
      "step": 473440
    },
    {
      "epoch": 761.19,
      "learning_rate": 0.023912616280385855,
      "loss": 2.4764,
      "step": 473460
    },
    {
      "epoch": 761.22,
      "learning_rate": 0.023909400849517683,
      "loss": 2.4746,
      "step": 473480
    },
    {
      "epoch": 761.25,
      "learning_rate": 0.023906185418649514,
      "loss": 2.4785,
      "step": 473500
    },
    {
      "epoch": 761.29,
      "learning_rate": 0.023902969987781346,
      "loss": 2.4792,
      "step": 473520
    },
    {
      "epoch": 761.32,
      "learning_rate": 0.023899754556913188,
      "loss": 2.4419,
      "step": 473540
    },
    {
      "epoch": 761.35,
      "learning_rate": 0.02389653912604502,
      "loss": 2.4661,
      "step": 473560
    },
    {
      "epoch": 761.38,
      "learning_rate": 0.023893323695176848,
      "loss": 2.4872,
      "step": 473580
    },
    {
      "epoch": 761.41,
      "learning_rate": 0.02389010826430868,
      "loss": 2.4694,
      "step": 473600
    },
    {
      "epoch": 761.45,
      "learning_rate": 0.02388689283344051,
      "loss": 2.4669,
      "step": 473620
    },
    {
      "epoch": 761.48,
      "learning_rate": 0.023883677402572343,
      "loss": 2.4638,
      "step": 473640
    },
    {
      "epoch": 761.51,
      "learning_rate": 0.023880461971704185,
      "loss": 2.48,
      "step": 473660
    },
    {
      "epoch": 761.54,
      "learning_rate": 0.023877246540836016,
      "loss": 2.4704,
      "step": 473680
    },
    {
      "epoch": 761.58,
      "learning_rate": 0.023874031109967844,
      "loss": 2.4779,
      "step": 473700
    },
    {
      "epoch": 761.61,
      "learning_rate": 0.023870815679099676,
      "loss": 2.473,
      "step": 473720
    },
    {
      "epoch": 761.64,
      "learning_rate": 0.023867600248231507,
      "loss": 2.4656,
      "step": 473740
    },
    {
      "epoch": 761.67,
      "learning_rate": 0.02386438481736335,
      "loss": 2.4607,
      "step": 473760
    },
    {
      "epoch": 761.7,
      "learning_rate": 0.02386116938649518,
      "loss": 2.4623,
      "step": 473780
    },
    {
      "epoch": 761.74,
      "learning_rate": 0.02385795395562701,
      "loss": 2.4649,
      "step": 473800
    },
    {
      "epoch": 761.77,
      "learning_rate": 0.02385473852475884,
      "loss": 2.4713,
      "step": 473820
    },
    {
      "epoch": 761.8,
      "learning_rate": 0.023851523093890672,
      "loss": 2.4734,
      "step": 473840
    },
    {
      "epoch": 761.83,
      "learning_rate": 0.023848307663022504,
      "loss": 2.4645,
      "step": 473860
    },
    {
      "epoch": 761.86,
      "learning_rate": 0.023845092232154346,
      "loss": 2.4564,
      "step": 473880
    },
    {
      "epoch": 761.9,
      "learning_rate": 0.023841876801286174,
      "loss": 2.4426,
      "step": 473900
    },
    {
      "epoch": 761.93,
      "learning_rate": 0.023838661370418006,
      "loss": 2.4928,
      "step": 473920
    },
    {
      "epoch": 761.96,
      "learning_rate": 0.023835445939549837,
      "loss": 2.4769,
      "step": 473940
    },
    {
      "epoch": 761.99,
      "learning_rate": 0.02383223050868167,
      "loss": 2.4697,
      "step": 473960
    },
    {
      "epoch": 762.0,
      "eval_accuracy": {
        "accuracy": 0.4464743838917826
      },
      "eval_loss": 2.585007905960083,
      "eval_runtime": 2.9524,
      "eval_samples_per_second": 4356.728,
      "eval_steps_per_second": 68.079,
      "step": 473964
    },
    {
      "epoch": 762.03,
      "learning_rate": 0.02382901507781351,
      "loss": 2.4864,
      "step": 473980
    },
    {
      "epoch": 762.06,
      "learning_rate": 0.023825799646945343,
      "loss": 2.4801,
      "step": 474000
    },
    {
      "epoch": 762.09,
      "learning_rate": 0.02382258421607717,
      "loss": 2.4962,
      "step": 474020
    },
    {
      "epoch": 762.12,
      "learning_rate": 0.023819368785209002,
      "loss": 2.4787,
      "step": 474040
    },
    {
      "epoch": 762.15,
      "learning_rate": 0.023816153354340834,
      "loss": 2.4598,
      "step": 474060
    },
    {
      "epoch": 762.19,
      "learning_rate": 0.023812937923472666,
      "loss": 2.469,
      "step": 474080
    },
    {
      "epoch": 762.22,
      "learning_rate": 0.023809722492604508,
      "loss": 2.4893,
      "step": 474100
    },
    {
      "epoch": 762.25,
      "learning_rate": 0.023806507061736336,
      "loss": 2.4675,
      "step": 474120
    },
    {
      "epoch": 762.28,
      "learning_rate": 0.023803291630868167,
      "loss": 2.4835,
      "step": 474140
    },
    {
      "epoch": 762.32,
      "learning_rate": 0.0238000762,
      "loss": 2.4499,
      "step": 474160
    },
    {
      "epoch": 762.35,
      "learning_rate": 0.02379686076913183,
      "loss": 2.473,
      "step": 474180
    },
    {
      "epoch": 762.38,
      "learning_rate": 0.023793645338263662,
      "loss": 2.4607,
      "step": 474200
    },
    {
      "epoch": 762.41,
      "learning_rate": 0.0237904299073955,
      "loss": 2.4591,
      "step": 474220
    },
    {
      "epoch": 762.44,
      "learning_rate": 0.023787214476527332,
      "loss": 2.448,
      "step": 474240
    },
    {
      "epoch": 762.48,
      "learning_rate": 0.023783999045659164,
      "loss": 2.4853,
      "step": 474260
    },
    {
      "epoch": 762.51,
      "learning_rate": 0.023780783614790996,
      "loss": 2.4723,
      "step": 474280
    },
    {
      "epoch": 762.54,
      "learning_rate": 0.023777568183922827,
      "loss": 2.4716,
      "step": 474300
    },
    {
      "epoch": 762.57,
      "learning_rate": 0.02377435275305467,
      "loss": 2.4784,
      "step": 474320
    },
    {
      "epoch": 762.6,
      "learning_rate": 0.023771137322186497,
      "loss": 2.4713,
      "step": 474340
    },
    {
      "epoch": 762.64,
      "learning_rate": 0.02376792189131833,
      "loss": 2.4881,
      "step": 474360
    },
    {
      "epoch": 762.67,
      "learning_rate": 0.02376470646045016,
      "loss": 2.4639,
      "step": 474380
    },
    {
      "epoch": 762.7,
      "learning_rate": 0.023761491029581992,
      "loss": 2.4683,
      "step": 474400
    },
    {
      "epoch": 762.73,
      "learning_rate": 0.02375827559871382,
      "loss": 2.4823,
      "step": 474420
    },
    {
      "epoch": 762.77,
      "learning_rate": 0.023755060167845662,
      "loss": 2.4767,
      "step": 474440
    },
    {
      "epoch": 762.8,
      "learning_rate": 0.023751844736977494,
      "loss": 2.4805,
      "step": 474460
    },
    {
      "epoch": 762.83,
      "learning_rate": 0.023748629306109326,
      "loss": 2.4852,
      "step": 474480
    },
    {
      "epoch": 762.86,
      "learning_rate": 0.023745413875241157,
      "loss": 2.4737,
      "step": 474500
    },
    {
      "epoch": 762.89,
      "learning_rate": 0.02374219844437299,
      "loss": 2.4683,
      "step": 474520
    },
    {
      "epoch": 762.93,
      "learning_rate": 0.023738983013504817,
      "loss": 2.4527,
      "step": 474540
    },
    {
      "epoch": 762.96,
      "learning_rate": 0.02373576758263666,
      "loss": 2.4768,
      "step": 474560
    },
    {
      "epoch": 762.99,
      "learning_rate": 0.02373255215176849,
      "loss": 2.4818,
      "step": 474580
    },
    {
      "epoch": 763.0,
      "eval_accuracy": {
        "accuracy": 0.447485034595351
      },
      "eval_loss": 2.5847291946411133,
      "eval_runtime": 3.0367,
      "eval_samples_per_second": 4235.914,
      "eval_steps_per_second": 66.191,
      "step": 474586
    },
    {
      "epoch": 763.02,
      "learning_rate": 0.023729336720900322,
      "loss": 2.4593,
      "step": 474600
    },
    {
      "epoch": 763.05,
      "learning_rate": 0.023726121290032154,
      "loss": 2.4691,
      "step": 474620
    },
    {
      "epoch": 763.09,
      "learning_rate": 0.023722905859163982,
      "loss": 2.4667,
      "step": 474640
    },
    {
      "epoch": 763.12,
      "learning_rate": 0.023719690428295824,
      "loss": 2.4835,
      "step": 474660
    },
    {
      "epoch": 763.15,
      "learning_rate": 0.023716474997427656,
      "loss": 2.477,
      "step": 474680
    },
    {
      "epoch": 763.18,
      "learning_rate": 0.023713259566559487,
      "loss": 2.4937,
      "step": 474700
    },
    {
      "epoch": 763.22,
      "learning_rate": 0.02371004413569132,
      "loss": 2.4603,
      "step": 474720
    },
    {
      "epoch": 763.25,
      "learning_rate": 0.023706828704823147,
      "loss": 2.4798,
      "step": 474740
    },
    {
      "epoch": 763.28,
      "learning_rate": 0.02370361327395498,
      "loss": 2.4526,
      "step": 474760
    },
    {
      "epoch": 763.31,
      "learning_rate": 0.02370039784308682,
      "loss": 2.4768,
      "step": 474780
    },
    {
      "epoch": 763.34,
      "learning_rate": 0.023697182412218652,
      "loss": 2.47,
      "step": 474800
    },
    {
      "epoch": 763.38,
      "learning_rate": 0.023693966981350484,
      "loss": 2.4595,
      "step": 474820
    },
    {
      "epoch": 763.41,
      "learning_rate": 0.023690751550482315,
      "loss": 2.4902,
      "step": 474840
    },
    {
      "epoch": 763.44,
      "learning_rate": 0.023687536119614144,
      "loss": 2.4801,
      "step": 474860
    },
    {
      "epoch": 763.47,
      "learning_rate": 0.023684320688745975,
      "loss": 2.4621,
      "step": 474880
    },
    {
      "epoch": 763.5,
      "learning_rate": 0.023681105257877817,
      "loss": 2.4656,
      "step": 474900
    },
    {
      "epoch": 763.54,
      "learning_rate": 0.02367788982700965,
      "loss": 2.465,
      "step": 474920
    },
    {
      "epoch": 763.57,
      "learning_rate": 0.02367467439614148,
      "loss": 2.4614,
      "step": 474940
    },
    {
      "epoch": 763.6,
      "learning_rate": 0.02367145896527331,
      "loss": 2.4532,
      "step": 474960
    },
    {
      "epoch": 763.63,
      "learning_rate": 0.02366824353440514,
      "loss": 2.4665,
      "step": 474980
    },
    {
      "epoch": 763.67,
      "learning_rate": 0.023665028103536982,
      "loss": 2.4751,
      "step": 475000
    },
    {
      "epoch": 763.7,
      "learning_rate": 0.023661973444212215,
      "loss": 2.494,
      "step": 475020
    },
    {
      "epoch": 763.73,
      "learning_rate": 0.023658758013344057,
      "loss": 2.4582,
      "step": 475040
    },
    {
      "epoch": 763.76,
      "learning_rate": 0.023655542582475885,
      "loss": 2.4773,
      "step": 475060
    },
    {
      "epoch": 763.79,
      "learning_rate": 0.023652327151607717,
      "loss": 2.4554,
      "step": 475080
    },
    {
      "epoch": 763.83,
      "learning_rate": 0.02364911172073955,
      "loss": 2.4626,
      "step": 475100
    },
    {
      "epoch": 763.86,
      "learning_rate": 0.02364589628987138,
      "loss": 2.4766,
      "step": 475120
    },
    {
      "epoch": 763.89,
      "learning_rate": 0.023642680859003222,
      "loss": 2.4629,
      "step": 475140
    },
    {
      "epoch": 763.92,
      "learning_rate": 0.02363946542813505,
      "loss": 2.49,
      "step": 475160
    },
    {
      "epoch": 763.95,
      "learning_rate": 0.02363624999726688,
      "loss": 2.4632,
      "step": 475180
    },
    {
      "epoch": 763.99,
      "learning_rate": 0.023633034566398713,
      "loss": 2.4678,
      "step": 475200
    },
    {
      "epoch": 764.0,
      "eval_accuracy": {
        "accuracy": 0.4467076109772215
      },
      "eval_loss": 2.578291416168213,
      "eval_runtime": 3.3589,
      "eval_samples_per_second": 3829.538,
      "eval_steps_per_second": 59.841,
      "step": 475208
    },
    {
      "epoch": 764.02,
      "learning_rate": 0.023629819135530545,
      "loss": 2.4695,
      "step": 475220
    },
    {
      "epoch": 764.05,
      "learning_rate": 0.023626603704662377,
      "loss": 2.4425,
      "step": 475240
    },
    {
      "epoch": 764.08,
      "learning_rate": 0.02362338827379422,
      "loss": 2.4378,
      "step": 475260
    },
    {
      "epoch": 764.12,
      "learning_rate": 0.023620172842926047,
      "loss": 2.4741,
      "step": 475280
    },
    {
      "epoch": 764.15,
      "learning_rate": 0.02361695741205788,
      "loss": 2.4705,
      "step": 475300
    },
    {
      "epoch": 764.18,
      "learning_rate": 0.02361374198118971,
      "loss": 2.4832,
      "step": 475320
    },
    {
      "epoch": 764.21,
      "learning_rate": 0.02361052655032154,
      "loss": 2.4657,
      "step": 475340
    },
    {
      "epoch": 764.24,
      "learning_rate": 0.02360731111945337,
      "loss": 2.4835,
      "step": 475360
    },
    {
      "epoch": 764.28,
      "learning_rate": 0.02360409568858521,
      "loss": 2.4759,
      "step": 475380
    },
    {
      "epoch": 764.31,
      "learning_rate": 0.023600880257717043,
      "loss": 2.4796,
      "step": 475400
    },
    {
      "epoch": 764.34,
      "learning_rate": 0.023597664826848875,
      "loss": 2.4724,
      "step": 475420
    },
    {
      "epoch": 764.37,
      "learning_rate": 0.023594449395980707,
      "loss": 2.4918,
      "step": 475440
    },
    {
      "epoch": 764.41,
      "learning_rate": 0.023591233965112535,
      "loss": 2.4745,
      "step": 475460
    },
    {
      "epoch": 764.44,
      "learning_rate": 0.023588018534244377,
      "loss": 2.4679,
      "step": 475480
    },
    {
      "epoch": 764.47,
      "learning_rate": 0.02358480310337621,
      "loss": 2.4539,
      "step": 475500
    },
    {
      "epoch": 764.5,
      "learning_rate": 0.02358158767250804,
      "loss": 2.4878,
      "step": 475520
    },
    {
      "epoch": 764.53,
      "learning_rate": 0.02357837224163987,
      "loss": 2.4614,
      "step": 475540
    },
    {
      "epoch": 764.57,
      "learning_rate": 0.023575156810771703,
      "loss": 2.481,
      "step": 475560
    },
    {
      "epoch": 764.6,
      "learning_rate": 0.02357194137990353,
      "loss": 2.4671,
      "step": 475580
    },
    {
      "epoch": 764.63,
      "learning_rate": 0.023568725949035373,
      "loss": 2.476,
      "step": 475600
    },
    {
      "epoch": 764.66,
      "learning_rate": 0.023565510518167205,
      "loss": 2.4684,
      "step": 475620
    },
    {
      "epoch": 764.69,
      "learning_rate": 0.023562295087299037,
      "loss": 2.4676,
      "step": 475640
    },
    {
      "epoch": 764.73,
      "learning_rate": 0.023559079656430868,
      "loss": 2.4652,
      "step": 475660
    },
    {
      "epoch": 764.76,
      "learning_rate": 0.023555864225562696,
      "loss": 2.4681,
      "step": 475680
    },
    {
      "epoch": 764.79,
      "learning_rate": 0.023552648794694528,
      "loss": 2.4711,
      "step": 475700
    },
    {
      "epoch": 764.82,
      "learning_rate": 0.02354943336382637,
      "loss": 2.4835,
      "step": 475720
    },
    {
      "epoch": 764.86,
      "learning_rate": 0.0235462179329582,
      "loss": 2.4715,
      "step": 475740
    },
    {
      "epoch": 764.89,
      "learning_rate": 0.023543002502090033,
      "loss": 2.4733,
      "step": 475760
    },
    {
      "epoch": 764.92,
      "learning_rate": 0.02353978707122186,
      "loss": 2.4657,
      "step": 475780
    },
    {
      "epoch": 764.95,
      "learning_rate": 0.023536571640353693,
      "loss": 2.4824,
      "step": 475800
    },
    {
      "epoch": 764.98,
      "learning_rate": 0.023533356209485535,
      "loss": 2.4604,
      "step": 475820
    },
    {
      "epoch": 765.0,
      "eval_accuracy": {
        "accuracy": 0.4436756588665164
      },
      "eval_loss": 2.5966107845306396,
      "eval_runtime": 3.3392,
      "eval_samples_per_second": 3852.097,
      "eval_steps_per_second": 60.194,
      "step": 475830
    },
    {
      "epoch": 765.02,
      "learning_rate": 0.023530140778617366,
      "loss": 2.4644,
      "step": 475840
    },
    {
      "epoch": 765.05,
      "learning_rate": 0.023526925347749198,
      "loss": 2.4483,
      "step": 475860
    },
    {
      "epoch": 765.08,
      "learning_rate": 0.02352370991688103,
      "loss": 2.4794,
      "step": 475880
    },
    {
      "epoch": 765.11,
      "learning_rate": 0.023520494486012858,
      "loss": 2.4568,
      "step": 475900
    },
    {
      "epoch": 765.14,
      "learning_rate": 0.02351727905514469,
      "loss": 2.4996,
      "step": 475920
    },
    {
      "epoch": 765.18,
      "learning_rate": 0.02351406362427653,
      "loss": 2.4702,
      "step": 475940
    },
    {
      "epoch": 765.21,
      "learning_rate": 0.023510848193408363,
      "loss": 2.4661,
      "step": 475960
    },
    {
      "epoch": 765.24,
      "learning_rate": 0.023507632762540195,
      "loss": 2.475,
      "step": 475980
    },
    {
      "epoch": 765.27,
      "learning_rate": 0.023504417331672023,
      "loss": 2.4577,
      "step": 476000
    },
    {
      "epoch": 765.31,
      "learning_rate": 0.023501201900803854,
      "loss": 2.4709,
      "step": 476020
    },
    {
      "epoch": 765.34,
      "learning_rate": 0.023497986469935686,
      "loss": 2.452,
      "step": 476040
    },
    {
      "epoch": 765.37,
      "learning_rate": 0.023494771039067528,
      "loss": 2.4421,
      "step": 476060
    },
    {
      "epoch": 765.4,
      "learning_rate": 0.02349155560819936,
      "loss": 2.4685,
      "step": 476080
    },
    {
      "epoch": 765.43,
      "learning_rate": 0.023488340177331188,
      "loss": 2.4681,
      "step": 476100
    },
    {
      "epoch": 765.47,
      "learning_rate": 0.02348512474646302,
      "loss": 2.4781,
      "step": 476120
    },
    {
      "epoch": 765.5,
      "learning_rate": 0.02348190931559485,
      "loss": 2.4658,
      "step": 476140
    },
    {
      "epoch": 765.53,
      "learning_rate": 0.023478693884726693,
      "loss": 2.455,
      "step": 476160
    },
    {
      "epoch": 765.56,
      "learning_rate": 0.023475478453858525,
      "loss": 2.4623,
      "step": 476180
    },
    {
      "epoch": 765.59,
      "learning_rate": 0.023472263022990356,
      "loss": 2.4773,
      "step": 476200
    },
    {
      "epoch": 765.63,
      "learning_rate": 0.023469047592122184,
      "loss": 2.4549,
      "step": 476220
    },
    {
      "epoch": 765.66,
      "learning_rate": 0.023465832161254016,
      "loss": 2.4713,
      "step": 476240
    },
    {
      "epoch": 765.69,
      "learning_rate": 0.023462616730385848,
      "loss": 2.4863,
      "step": 476260
    },
    {
      "epoch": 765.72,
      "learning_rate": 0.02345940129951769,
      "loss": 2.4576,
      "step": 476280
    },
    {
      "epoch": 765.76,
      "learning_rate": 0.02345618586864952,
      "loss": 2.4717,
      "step": 476300
    },
    {
      "epoch": 765.79,
      "learning_rate": 0.02345297043778135,
      "loss": 2.4837,
      "step": 476320
    },
    {
      "epoch": 765.82,
      "learning_rate": 0.02344975500691318,
      "loss": 2.4849,
      "step": 476340
    },
    {
      "epoch": 765.85,
      "learning_rate": 0.023446700347588424,
      "loss": 2.4715,
      "step": 476360
    },
    {
      "epoch": 765.88,
      "learning_rate": 0.023443484916720256,
      "loss": 2.472,
      "step": 476380
    },
    {
      "epoch": 765.92,
      "learning_rate": 0.023440269485852084,
      "loss": 2.4871,
      "step": 476400
    },
    {
      "epoch": 765.95,
      "learning_rate": 0.023437054054983926,
      "loss": 2.4746,
      "step": 476420
    },
    {
      "epoch": 765.98,
      "learning_rate": 0.023433838624115758,
      "loss": 2.49,
      "step": 476440
    },
    {
      "epoch": 766.0,
      "eval_accuracy": {
        "accuracy": 0.44872891238435825
      },
      "eval_loss": 2.5695266723632812,
      "eval_runtime": 3.2111,
      "eval_samples_per_second": 4005.73,
      "eval_steps_per_second": 62.594,
      "step": 476452
    },
    {
      "epoch": 766.01,
      "learning_rate": 0.02343062319324759,
      "loss": 2.4657,
      "step": 476460
    },
    {
      "epoch": 766.05,
      "learning_rate": 0.02342740776237942,
      "loss": 2.4685,
      "step": 476480
    },
    {
      "epoch": 766.08,
      "learning_rate": 0.023424192331511252,
      "loss": 2.4677,
      "step": 476500
    },
    {
      "epoch": 766.11,
      "learning_rate": 0.02342097690064308,
      "loss": 2.4613,
      "step": 476520
    },
    {
      "epoch": 766.14,
      "learning_rate": 0.023417761469774923,
      "loss": 2.4698,
      "step": 476540
    },
    {
      "epoch": 766.17,
      "learning_rate": 0.023414546038906754,
      "loss": 2.4951,
      "step": 476560
    },
    {
      "epoch": 766.21,
      "learning_rate": 0.023411330608038586,
      "loss": 2.4585,
      "step": 476580
    },
    {
      "epoch": 766.24,
      "learning_rate": 0.023408115177170417,
      "loss": 2.471,
      "step": 476600
    },
    {
      "epoch": 766.27,
      "learning_rate": 0.023404899746302246,
      "loss": 2.4689,
      "step": 476620
    },
    {
      "epoch": 766.3,
      "learning_rate": 0.023401684315434088,
      "loss": 2.4648,
      "step": 476640
    },
    {
      "epoch": 766.33,
      "learning_rate": 0.02339846888456592,
      "loss": 2.4748,
      "step": 476660
    },
    {
      "epoch": 766.37,
      "learning_rate": 0.02339525345369775,
      "loss": 2.4623,
      "step": 476680
    },
    {
      "epoch": 766.4,
      "learning_rate": 0.023392038022829582,
      "loss": 2.4808,
      "step": 476700
    },
    {
      "epoch": 766.43,
      "learning_rate": 0.02338882259196141,
      "loss": 2.4621,
      "step": 476720
    },
    {
      "epoch": 766.46,
      "learning_rate": 0.023385607161093242,
      "loss": 2.464,
      "step": 476740
    },
    {
      "epoch": 766.5,
      "learning_rate": 0.023382391730225084,
      "loss": 2.4769,
      "step": 476760
    },
    {
      "epoch": 766.53,
      "learning_rate": 0.023379176299356916,
      "loss": 2.4904,
      "step": 476780
    },
    {
      "epoch": 766.56,
      "learning_rate": 0.023375960868488747,
      "loss": 2.4684,
      "step": 476800
    },
    {
      "epoch": 766.59,
      "learning_rate": 0.02337274543762058,
      "loss": 2.4612,
      "step": 476820
    },
    {
      "epoch": 766.62,
      "learning_rate": 0.023369530006752407,
      "loss": 2.4929,
      "step": 476840
    },
    {
      "epoch": 766.66,
      "learning_rate": 0.02336631457588424,
      "loss": 2.4643,
      "step": 476860
    },
    {
      "epoch": 766.69,
      "learning_rate": 0.02336309914501608,
      "loss": 2.449,
      "step": 476880
    },
    {
      "epoch": 766.72,
      "learning_rate": 0.023359883714147912,
      "loss": 2.4733,
      "step": 476900
    },
    {
      "epoch": 766.75,
      "learning_rate": 0.023356668283279744,
      "loss": 2.4808,
      "step": 476920
    },
    {
      "epoch": 766.78,
      "learning_rate": 0.023353452852411572,
      "loss": 2.4649,
      "step": 476940
    },
    {
      "epoch": 766.82,
      "learning_rate": 0.023350237421543404,
      "loss": 2.4774,
      "step": 476960
    },
    {
      "epoch": 766.85,
      "learning_rate": 0.023347021990675246,
      "loss": 2.4757,
      "step": 476980
    },
    {
      "epoch": 766.88,
      "learning_rate": 0.023343806559807077,
      "loss": 2.4663,
      "step": 477000
    },
    {
      "epoch": 766.91,
      "learning_rate": 0.02334059112893891,
      "loss": 2.4643,
      "step": 477020
    },
    {
      "epoch": 766.95,
      "learning_rate": 0.023337375698070737,
      "loss": 2.4604,
      "step": 477040
    },
    {
      "epoch": 766.98,
      "learning_rate": 0.02333416026720257,
      "loss": 2.4543,
      "step": 477060
    },
    {
      "epoch": 767.0,
      "eval_accuracy": {
        "accuracy": 0.44694083806266033
      },
      "eval_loss": 2.5692343711853027,
      "eval_runtime": 3.073,
      "eval_samples_per_second": 4185.871,
      "eval_steps_per_second": 65.409,
      "step": 477074
    },
    {
      "epoch": 767.01,
      "learning_rate": 0.0233309448363344,
      "loss": 2.4755,
      "step": 477080
    },
    {
      "epoch": 767.04,
      "learning_rate": 0.023327729405466242,
      "loss": 2.4845,
      "step": 477100
    },
    {
      "epoch": 767.07,
      "learning_rate": 0.023324513974598074,
      "loss": 2.4857,
      "step": 477120
    },
    {
      "epoch": 767.11,
      "learning_rate": 0.023321298543729906,
      "loss": 2.4572,
      "step": 477140
    },
    {
      "epoch": 767.14,
      "learning_rate": 0.023318083112861734,
      "loss": 2.4752,
      "step": 477160
    },
    {
      "epoch": 767.17,
      "learning_rate": 0.023314867681993565,
      "loss": 2.4872,
      "step": 477180
    },
    {
      "epoch": 767.2,
      "learning_rate": 0.023311652251125397,
      "loss": 2.4474,
      "step": 477200
    },
    {
      "epoch": 767.23,
      "learning_rate": 0.02330843682025724,
      "loss": 2.4816,
      "step": 477220
    },
    {
      "epoch": 767.27,
      "learning_rate": 0.02330522138938907,
      "loss": 2.4648,
      "step": 477240
    },
    {
      "epoch": 767.3,
      "learning_rate": 0.0233020059585209,
      "loss": 2.4726,
      "step": 477260
    },
    {
      "epoch": 767.33,
      "learning_rate": 0.02329879052765273,
      "loss": 2.4686,
      "step": 477280
    },
    {
      "epoch": 767.36,
      "learning_rate": 0.023295575096784562,
      "loss": 2.472,
      "step": 477300
    },
    {
      "epoch": 767.4,
      "learning_rate": 0.023292359665916404,
      "loss": 2.4714,
      "step": 477320
    },
    {
      "epoch": 767.43,
      "learning_rate": 0.023289144235048236,
      "loss": 2.4606,
      "step": 477340
    },
    {
      "epoch": 767.46,
      "learning_rate": 0.023285928804180064,
      "loss": 2.4703,
      "step": 477360
    },
    {
      "epoch": 767.49,
      "learning_rate": 0.023282713373311895,
      "loss": 2.4802,
      "step": 477380
    },
    {
      "epoch": 767.52,
      "learning_rate": 0.023279497942443727,
      "loss": 2.4793,
      "step": 477400
    },
    {
      "epoch": 767.56,
      "learning_rate": 0.02327628251157556,
      "loss": 2.4766,
      "step": 477420
    },
    {
      "epoch": 767.59,
      "learning_rate": 0.0232730670807074,
      "loss": 2.4696,
      "step": 477440
    },
    {
      "epoch": 767.62,
      "learning_rate": 0.023269851649839232,
      "loss": 2.4592,
      "step": 477460
    },
    {
      "epoch": 767.65,
      "learning_rate": 0.02326663621897106,
      "loss": 2.4691,
      "step": 477480
    },
    {
      "epoch": 767.68,
      "learning_rate": 0.023263420788102892,
      "loss": 2.4542,
      "step": 477500
    },
    {
      "epoch": 767.72,
      "learning_rate": 0.023260205357234724,
      "loss": 2.4533,
      "step": 477520
    },
    {
      "epoch": 767.75,
      "learning_rate": 0.023256989926366566,
      "loss": 2.4598,
      "step": 477540
    },
    {
      "epoch": 767.78,
      "learning_rate": 0.023253774495498397,
      "loss": 2.4626,
      "step": 477560
    },
    {
      "epoch": 767.81,
      "learning_rate": 0.023250559064630225,
      "loss": 2.4942,
      "step": 477580
    },
    {
      "epoch": 767.85,
      "learning_rate": 0.023247343633762057,
      "loss": 2.4504,
      "step": 477600
    },
    {
      "epoch": 767.88,
      "learning_rate": 0.02324412820289389,
      "loss": 2.4679,
      "step": 477620
    },
    {
      "epoch": 767.91,
      "learning_rate": 0.02324091277202572,
      "loss": 2.4558,
      "step": 477640
    },
    {
      "epoch": 767.94,
      "learning_rate": 0.023237697341157562,
      "loss": 2.4644,
      "step": 477660
    },
    {
      "epoch": 767.97,
      "learning_rate": 0.02323448191028939,
      "loss": 2.4481,
      "step": 477680
    },
    {
      "epoch": 768.0,
      "eval_accuracy": {
        "accuracy": 0.44686309570084737
      },
      "eval_loss": 2.5783281326293945,
      "eval_runtime": 3.0319,
      "eval_samples_per_second": 4242.569,
      "eval_steps_per_second": 66.295,
      "step": 477696
    },
    {
      "epoch": 768.01,
      "learning_rate": 0.023231266479421222,
      "loss": 2.4649,
      "step": 477700
    },
    {
      "epoch": 768.04,
      "learning_rate": 0.023228051048553053,
      "loss": 2.4765,
      "step": 477720
    },
    {
      "epoch": 768.07,
      "learning_rate": 0.023224835617684885,
      "loss": 2.4607,
      "step": 477740
    },
    {
      "epoch": 768.1,
      "learning_rate": 0.023221620186816717,
      "loss": 2.4577,
      "step": 477760
    },
    {
      "epoch": 768.14,
      "learning_rate": 0.02321840475594856,
      "loss": 2.4768,
      "step": 477780
    },
    {
      "epoch": 768.17,
      "learning_rate": 0.023215189325080387,
      "loss": 2.4696,
      "step": 477800
    },
    {
      "epoch": 768.2,
      "learning_rate": 0.02321197389421222,
      "loss": 2.4784,
      "step": 477820
    },
    {
      "epoch": 768.23,
      "learning_rate": 0.02320875846334405,
      "loss": 2.4755,
      "step": 477840
    },
    {
      "epoch": 768.26,
      "learning_rate": 0.02320554303247588,
      "loss": 2.4716,
      "step": 477860
    },
    {
      "epoch": 768.3,
      "learning_rate": 0.023202327601607724,
      "loss": 2.4743,
      "step": 477880
    },
    {
      "epoch": 768.33,
      "learning_rate": 0.023199112170739552,
      "loss": 2.495,
      "step": 477900
    },
    {
      "epoch": 768.36,
      "learning_rate": 0.023195896739871383,
      "loss": 2.4914,
      "step": 477920
    },
    {
      "epoch": 768.39,
      "learning_rate": 0.023192681309003215,
      "loss": 2.4563,
      "step": 477940
    },
    {
      "epoch": 768.42,
      "learning_rate": 0.023189465878135047,
      "loss": 2.4819,
      "step": 477960
    },
    {
      "epoch": 768.46,
      "learning_rate": 0.023186250447266875,
      "loss": 2.4663,
      "step": 477980
    },
    {
      "epoch": 768.49,
      "learning_rate": 0.023183035016398717,
      "loss": 2.4609,
      "step": 478000
    },
    {
      "epoch": 768.52,
      "learning_rate": 0.02317981958553055,
      "loss": 2.4671,
      "step": 478020
    },
    {
      "epoch": 768.55,
      "learning_rate": 0.02317660415466238,
      "loss": 2.4729,
      "step": 478040
    },
    {
      "epoch": 768.59,
      "learning_rate": 0.02317338872379421,
      "loss": 2.4705,
      "step": 478060
    },
    {
      "epoch": 768.62,
      "learning_rate": 0.023170173292926043,
      "loss": 2.4668,
      "step": 478080
    },
    {
      "epoch": 768.65,
      "learning_rate": 0.02316695786205787,
      "loss": 2.4755,
      "step": 478100
    },
    {
      "epoch": 768.68,
      "learning_rate": 0.023163742431189713,
      "loss": 2.4568,
      "step": 478120
    },
    {
      "epoch": 768.71,
      "learning_rate": 0.023160527000321545,
      "loss": 2.4607,
      "step": 478140
    },
    {
      "epoch": 768.75,
      "learning_rate": 0.023157311569453377,
      "loss": 2.4487,
      "step": 478160
    },
    {
      "epoch": 768.78,
      "learning_rate": 0.02315409613858521,
      "loss": 2.4819,
      "step": 478180
    },
    {
      "epoch": 768.81,
      "learning_rate": 0.023150880707717036,
      "loss": 2.4699,
      "step": 478200
    },
    {
      "epoch": 768.84,
      "learning_rate": 0.02314766527684888,
      "loss": 2.4522,
      "step": 478220
    },
    {
      "epoch": 768.87,
      "learning_rate": 0.02314444984598071,
      "loss": 2.4905,
      "step": 478240
    },
    {
      "epoch": 768.91,
      "learning_rate": 0.02314123441511254,
      "loss": 2.4692,
      "step": 478260
    },
    {
      "epoch": 768.94,
      "learning_rate": 0.023138018984244373,
      "loss": 2.4724,
      "step": 478280
    },
    {
      "epoch": 768.97,
      "learning_rate": 0.0231348035533762,
      "loss": 2.4673,
      "step": 478300
    },
    {
      "epoch": 769.0,
      "eval_accuracy": {
        "accuracy": 0.44950633600248774
      },
      "eval_loss": 2.5794618129730225,
      "eval_runtime": 3.1095,
      "eval_samples_per_second": 4136.742,
      "eval_steps_per_second": 64.642,
      "step": 478318
    },
    {
      "epoch": 769.0,
      "learning_rate": 0.023131588122508033,
      "loss": 2.4607,
      "step": 478320
    },
    {
      "epoch": 769.04,
      "learning_rate": 0.023128372691639875,
      "loss": 2.4856,
      "step": 478340
    },
    {
      "epoch": 769.07,
      "learning_rate": 0.023125157260771707,
      "loss": 2.4622,
      "step": 478360
    },
    {
      "epoch": 769.1,
      "learning_rate": 0.02312194182990354,
      "loss": 2.4716,
      "step": 478380
    },
    {
      "epoch": 769.13,
      "learning_rate": 0.02311872639903537,
      "loss": 2.4543,
      "step": 478400
    },
    {
      "epoch": 769.16,
      "learning_rate": 0.023115510968167198,
      "loss": 2.4532,
      "step": 478420
    },
    {
      "epoch": 769.2,
      "learning_rate": 0.02311229553729903,
      "loss": 2.457,
      "step": 478440
    },
    {
      "epoch": 769.23,
      "learning_rate": 0.02310908010643087,
      "loss": 2.4728,
      "step": 478460
    },
    {
      "epoch": 769.26,
      "learning_rate": 0.023105864675562703,
      "loss": 2.4651,
      "step": 478480
    },
    {
      "epoch": 769.29,
      "learning_rate": 0.023102649244694535,
      "loss": 2.4647,
      "step": 478500
    },
    {
      "epoch": 769.32,
      "learning_rate": 0.023099433813826363,
      "loss": 2.4802,
      "step": 478520
    },
    {
      "epoch": 769.36,
      "learning_rate": 0.023096218382958195,
      "loss": 2.4592,
      "step": 478540
    },
    {
      "epoch": 769.39,
      "learning_rate": 0.023093002952090037,
      "loss": 2.4706,
      "step": 478560
    },
    {
      "epoch": 769.42,
      "learning_rate": 0.023089787521221868,
      "loss": 2.4626,
      "step": 478580
    },
    {
      "epoch": 769.45,
      "learning_rate": 0.0230865720903537,
      "loss": 2.4585,
      "step": 478600
    },
    {
      "epoch": 769.49,
      "learning_rate": 0.02308335665948553,
      "loss": 2.4588,
      "step": 478620
    },
    {
      "epoch": 769.52,
      "learning_rate": 0.02308014122861736,
      "loss": 2.4639,
      "step": 478640
    },
    {
      "epoch": 769.55,
      "learning_rate": 0.02307692579774919,
      "loss": 2.4679,
      "step": 478660
    },
    {
      "epoch": 769.58,
      "learning_rate": 0.023073710366881033,
      "loss": 2.4369,
      "step": 478680
    },
    {
      "epoch": 769.61,
      "learning_rate": 0.023070494936012865,
      "loss": 2.442,
      "step": 478700
    },
    {
      "epoch": 769.65,
      "learning_rate": 0.023067279505144696,
      "loss": 2.476,
      "step": 478720
    },
    {
      "epoch": 769.68,
      "learning_rate": 0.023064064074276525,
      "loss": 2.4637,
      "step": 478740
    },
    {
      "epoch": 769.71,
      "learning_rate": 0.023060848643408356,
      "loss": 2.4532,
      "step": 478760
    },
    {
      "epoch": 769.74,
      "learning_rate": 0.023057633212540188,
      "loss": 2.5043,
      "step": 478780
    },
    {
      "epoch": 769.77,
      "learning_rate": 0.02305441778167203,
      "loss": 2.4728,
      "step": 478800
    },
    {
      "epoch": 769.81,
      "learning_rate": 0.02305120235080386,
      "loss": 2.4662,
      "step": 478820
    },
    {
      "epoch": 769.84,
      "learning_rate": 0.02304798691993569,
      "loss": 2.4671,
      "step": 478840
    },
    {
      "epoch": 769.87,
      "learning_rate": 0.02304477148906752,
      "loss": 2.4518,
      "step": 478860
    },
    {
      "epoch": 769.9,
      "learning_rate": 0.023041556058199353,
      "loss": 2.4409,
      "step": 478880
    },
    {
      "epoch": 769.94,
      "learning_rate": 0.023038340627331195,
      "loss": 2.4777,
      "step": 478900
    },
    {
      "epoch": 769.97,
      "learning_rate": 0.023035125196463026,
      "loss": 2.4591,
      "step": 478920
    },
    {
      "epoch": 770.0,
      "learning_rate": 0.023031909765594858,
      "loss": 2.4431,
      "step": 478940
    },
    {
      "epoch": 770.0,
      "eval_accuracy": {
        "accuracy": 0.4435979165047034
      },
      "eval_loss": 2.5798542499542236,
      "eval_runtime": 3.0803,
      "eval_samples_per_second": 4175.872,
      "eval_steps_per_second": 65.253,
      "step": 478940
    },
    {
      "epoch": 770.03,
      "learning_rate": 0.023028694334726686,
      "loss": 2.4689,
      "step": 478960
    },
    {
      "epoch": 770.06,
      "learning_rate": 0.023025478903858518,
      "loss": 2.4713,
      "step": 478980
    },
    {
      "epoch": 770.1,
      "learning_rate": 0.02302226347299035,
      "loss": 2.4481,
      "step": 479000
    },
    {
      "epoch": 770.13,
      "learning_rate": 0.02301904804212219,
      "loss": 2.456,
      "step": 479020
    },
    {
      "epoch": 770.16,
      "learning_rate": 0.023015832611254023,
      "loss": 2.4572,
      "step": 479040
    },
    {
      "epoch": 770.19,
      "learning_rate": 0.02301261718038585,
      "loss": 2.4817,
      "step": 479060
    },
    {
      "epoch": 770.23,
      "learning_rate": 0.023009401749517683,
      "loss": 2.4559,
      "step": 479080
    },
    {
      "epoch": 770.26,
      "learning_rate": 0.023006186318649514,
      "loss": 2.473,
      "step": 479100
    },
    {
      "epoch": 770.29,
      "learning_rate": 0.023002970887781356,
      "loss": 2.4749,
      "step": 479120
    },
    {
      "epoch": 770.32,
      "learning_rate": 0.022999755456913188,
      "loss": 2.4699,
      "step": 479140
    },
    {
      "epoch": 770.35,
      "learning_rate": 0.022996540026045016,
      "loss": 2.4641,
      "step": 479160
    },
    {
      "epoch": 770.39,
      "learning_rate": 0.022993324595176848,
      "loss": 2.47,
      "step": 479180
    },
    {
      "epoch": 770.42,
      "learning_rate": 0.02299010916430868,
      "loss": 2.4565,
      "step": 479200
    },
    {
      "epoch": 770.45,
      "learning_rate": 0.02298689373344051,
      "loss": 2.4639,
      "step": 479220
    },
    {
      "epoch": 770.48,
      "learning_rate": 0.022983678302572353,
      "loss": 2.4556,
      "step": 479240
    },
    {
      "epoch": 770.51,
      "learning_rate": 0.022980462871704185,
      "loss": 2.4943,
      "step": 479260
    },
    {
      "epoch": 770.55,
      "learning_rate": 0.022977247440836013,
      "loss": 2.4658,
      "step": 479280
    },
    {
      "epoch": 770.58,
      "learning_rate": 0.022974032009967844,
      "loss": 2.466,
      "step": 479300
    },
    {
      "epoch": 770.61,
      "learning_rate": 0.022970816579099676,
      "loss": 2.4816,
      "step": 479320
    },
    {
      "epoch": 770.64,
      "learning_rate": 0.022967601148231508,
      "loss": 2.455,
      "step": 479340
    },
    {
      "epoch": 770.68,
      "learning_rate": 0.02296438571736335,
      "loss": 2.4392,
      "step": 479360
    },
    {
      "epoch": 770.71,
      "learning_rate": 0.02296133105803859,
      "loss": 2.4592,
      "step": 479380
    },
    {
      "epoch": 770.74,
      "learning_rate": 0.02295811562717042,
      "loss": 2.4807,
      "step": 479400
    },
    {
      "epoch": 770.77,
      "learning_rate": 0.022954900196302253,
      "loss": 2.4581,
      "step": 479420
    },
    {
      "epoch": 770.8,
      "learning_rate": 0.022951684765434084,
      "loss": 2.4698,
      "step": 479440
    },
    {
      "epoch": 770.84,
      "learning_rate": 0.022948469334565912,
      "loss": 2.4841,
      "step": 479460
    },
    {
      "epoch": 770.87,
      "learning_rate": 0.022945253903697744,
      "loss": 2.4574,
      "step": 479480
    },
    {
      "epoch": 770.9,
      "learning_rate": 0.022942038472829586,
      "loss": 2.4615,
      "step": 479500
    },
    {
      "epoch": 770.93,
      "learning_rate": 0.022938823041961418,
      "loss": 2.456,
      "step": 479520
    },
    {
      "epoch": 770.96,
      "learning_rate": 0.02293560761109325,
      "loss": 2.4645,
      "step": 479540
    },
    {
      "epoch": 771.0,
      "learning_rate": 0.022932392180225077,
      "loss": 2.4774,
      "step": 479560
    },
    {
      "epoch": 771.0,
      "eval_accuracy": {
        "accuracy": 0.44662986861540854
      },
      "eval_loss": 2.591461420059204,
      "eval_runtime": 3.0688,
      "eval_samples_per_second": 4191.475,
      "eval_steps_per_second": 65.497,
      "step": 479562
    },
    {
      "epoch": 771.03,
      "learning_rate": 0.02292917674935691,
      "loss": 2.46,
      "step": 479580
    },
    {
      "epoch": 771.06,
      "learning_rate": 0.02292596131848874,
      "loss": 2.4662,
      "step": 479600
    },
    {
      "epoch": 771.09,
      "learning_rate": 0.022922745887620583,
      "loss": 2.455,
      "step": 479620
    },
    {
      "epoch": 771.13,
      "learning_rate": 0.022919530456752414,
      "loss": 2.4724,
      "step": 479640
    },
    {
      "epoch": 771.16,
      "learning_rate": 0.022916315025884246,
      "loss": 2.467,
      "step": 479660
    },
    {
      "epoch": 771.19,
      "learning_rate": 0.022913099595016074,
      "loss": 2.4648,
      "step": 479680
    },
    {
      "epoch": 771.22,
      "learning_rate": 0.022909884164147905,
      "loss": 2.4897,
      "step": 479700
    },
    {
      "epoch": 771.25,
      "learning_rate": 0.022906668733279748,
      "loss": 2.4704,
      "step": 479720
    },
    {
      "epoch": 771.29,
      "learning_rate": 0.02290345330241158,
      "loss": 2.4656,
      "step": 479740
    },
    {
      "epoch": 771.32,
      "learning_rate": 0.02290023787154341,
      "loss": 2.4539,
      "step": 479760
    },
    {
      "epoch": 771.35,
      "learning_rate": 0.02289702244067524,
      "loss": 2.4627,
      "step": 479780
    },
    {
      "epoch": 771.38,
      "learning_rate": 0.02289380700980707,
      "loss": 2.4905,
      "step": 479800
    },
    {
      "epoch": 771.41,
      "learning_rate": 0.022890591578938902,
      "loss": 2.4547,
      "step": 479820
    },
    {
      "epoch": 771.45,
      "learning_rate": 0.022887376148070744,
      "loss": 2.4713,
      "step": 479840
    },
    {
      "epoch": 771.48,
      "learning_rate": 0.022884160717202576,
      "loss": 2.4566,
      "step": 479860
    },
    {
      "epoch": 771.51,
      "learning_rate": 0.022880945286334404,
      "loss": 2.4618,
      "step": 479880
    },
    {
      "epoch": 771.54,
      "learning_rate": 0.022877729855466235,
      "loss": 2.4633,
      "step": 479900
    },
    {
      "epoch": 771.58,
      "learning_rate": 0.022874514424598067,
      "loss": 2.4679,
      "step": 479920
    },
    {
      "epoch": 771.61,
      "learning_rate": 0.02287129899372991,
      "loss": 2.4639,
      "step": 479940
    },
    {
      "epoch": 771.64,
      "learning_rate": 0.02286808356286174,
      "loss": 2.4619,
      "step": 479960
    },
    {
      "epoch": 771.67,
      "learning_rate": 0.022864868131993572,
      "loss": 2.4567,
      "step": 479980
    },
    {
      "epoch": 771.7,
      "learning_rate": 0.0228616527011254,
      "loss": 2.4426,
      "step": 480000
    },
    {
      "epoch": 771.74,
      "learning_rate": 0.022858437270257232,
      "loss": 2.4786,
      "step": 480020
    },
    {
      "epoch": 771.77,
      "learning_rate": 0.022855221839389064,
      "loss": 2.4755,
      "step": 480040
    },
    {
      "epoch": 771.8,
      "learning_rate": 0.022852006408520906,
      "loss": 2.4622,
      "step": 480060
    },
    {
      "epoch": 771.83,
      "learning_rate": 0.022848790977652737,
      "loss": 2.4725,
      "step": 480080
    },
    {
      "epoch": 771.86,
      "learning_rate": 0.022845575546784565,
      "loss": 2.4671,
      "step": 480100
    },
    {
      "epoch": 771.9,
      "learning_rate": 0.022842360115916397,
      "loss": 2.4735,
      "step": 480120
    },
    {
      "epoch": 771.93,
      "learning_rate": 0.02283914468504823,
      "loss": 2.4795,
      "step": 480140
    },
    {
      "epoch": 771.96,
      "learning_rate": 0.02283592925418006,
      "loss": 2.4632,
      "step": 480160
    },
    {
      "epoch": 771.99,
      "learning_rate": 0.022832713823311902,
      "loss": 2.4677,
      "step": 480180
    },
    {
      "epoch": 772.0,
      "eval_accuracy": {
        "accuracy": 0.44678535333903446
      },
      "eval_loss": 2.5666561126708984,
      "eval_runtime": 3.07,
      "eval_samples_per_second": 4189.845,
      "eval_steps_per_second": 65.471,
      "step": 480184
    },
    {
      "epoch": 772.03,
      "learning_rate": 0.02282949839244373,
      "loss": 2.4697,
      "step": 480200
    },
    {
      "epoch": 772.06,
      "learning_rate": 0.022826282961575562,
      "loss": 2.4471,
      "step": 480220
    },
    {
      "epoch": 772.09,
      "learning_rate": 0.022823067530707394,
      "loss": 2.4694,
      "step": 480240
    },
    {
      "epoch": 772.12,
      "learning_rate": 0.022819852099839225,
      "loss": 2.4635,
      "step": 480260
    },
    {
      "epoch": 772.15,
      "learning_rate": 0.022816636668971067,
      "loss": 2.4751,
      "step": 480280
    },
    {
      "epoch": 772.19,
      "learning_rate": 0.0228134212381029,
      "loss": 2.4578,
      "step": 480300
    },
    {
      "epoch": 772.22,
      "learning_rate": 0.022810205807234727,
      "loss": 2.4718,
      "step": 480320
    },
    {
      "epoch": 772.25,
      "learning_rate": 0.02280699037636656,
      "loss": 2.4654,
      "step": 480340
    },
    {
      "epoch": 772.28,
      "learning_rate": 0.02280377494549839,
      "loss": 2.4665,
      "step": 480360
    },
    {
      "epoch": 772.32,
      "learning_rate": 0.022800559514630222,
      "loss": 2.4557,
      "step": 480380
    },
    {
      "epoch": 772.35,
      "learning_rate": 0.022797344083762064,
      "loss": 2.4642,
      "step": 480400
    },
    {
      "epoch": 772.38,
      "learning_rate": 0.022794128652893892,
      "loss": 2.4703,
      "step": 480420
    },
    {
      "epoch": 772.41,
      "learning_rate": 0.022790913222025724,
      "loss": 2.4638,
      "step": 480440
    },
    {
      "epoch": 772.44,
      "learning_rate": 0.022787697791157555,
      "loss": 2.4852,
      "step": 480460
    },
    {
      "epoch": 772.48,
      "learning_rate": 0.022784482360289387,
      "loss": 2.4554,
      "step": 480480
    },
    {
      "epoch": 772.51,
      "learning_rate": 0.02278126692942122,
      "loss": 2.4575,
      "step": 480500
    },
    {
      "epoch": 772.54,
      "learning_rate": 0.022778051498553057,
      "loss": 2.4681,
      "step": 480520
    },
    {
      "epoch": 772.57,
      "learning_rate": 0.02277483606768489,
      "loss": 2.4512,
      "step": 480540
    },
    {
      "epoch": 772.6,
      "learning_rate": 0.02277162063681672,
      "loss": 2.4655,
      "step": 480560
    },
    {
      "epoch": 772.64,
      "learning_rate": 0.022768405205948552,
      "loss": 2.4379,
      "step": 480580
    },
    {
      "epoch": 772.67,
      "learning_rate": 0.022765189775080383,
      "loss": 2.452,
      "step": 480600
    },
    {
      "epoch": 772.7,
      "learning_rate": 0.022761974344212225,
      "loss": 2.4674,
      "step": 480620
    },
    {
      "epoch": 772.73,
      "learning_rate": 0.022758758913344054,
      "loss": 2.4491,
      "step": 480640
    },
    {
      "epoch": 772.77,
      "learning_rate": 0.022755543482475885,
      "loss": 2.4552,
      "step": 480660
    },
    {
      "epoch": 772.8,
      "learning_rate": 0.022752328051607717,
      "loss": 2.4735,
      "step": 480680
    },
    {
      "epoch": 772.83,
      "learning_rate": 0.02274911262073955,
      "loss": 2.4747,
      "step": 480700
    },
    {
      "epoch": 772.86,
      "learning_rate": 0.022745897189871377,
      "loss": 2.4829,
      "step": 480720
    },
    {
      "epoch": 772.89,
      "learning_rate": 0.02274268175900322,
      "loss": 2.4871,
      "step": 480740
    },
    {
      "epoch": 772.93,
      "learning_rate": 0.02273946632813505,
      "loss": 2.471,
      "step": 480760
    },
    {
      "epoch": 772.96,
      "learning_rate": 0.022736250897266882,
      "loss": 2.4666,
      "step": 480780
    },
    {
      "epoch": 772.99,
      "learning_rate": 0.022733035466398713,
      "loss": 2.4497,
      "step": 480800
    },
    {
      "epoch": 773.0,
      "eval_accuracy": {
        "accuracy": 0.44686309570084737
      },
      "eval_loss": 2.571408987045288,
      "eval_runtime": 3.0537,
      "eval_samples_per_second": 4212.287,
      "eval_steps_per_second": 65.822,
      "step": 480806
    },
    {
      "epoch": 773.02,
      "learning_rate": 0.022729820035530545,
      "loss": 2.4549,
      "step": 480820
    },
    {
      "epoch": 773.05,
      "learning_rate": 0.022726604604662373,
      "loss": 2.4851,
      "step": 480840
    },
    {
      "epoch": 773.09,
      "learning_rate": 0.022723389173794215,
      "loss": 2.4531,
      "step": 480860
    },
    {
      "epoch": 773.12,
      "learning_rate": 0.022720173742926047,
      "loss": 2.4681,
      "step": 480880
    },
    {
      "epoch": 773.15,
      "learning_rate": 0.02271695831205788,
      "loss": 2.4744,
      "step": 480900
    },
    {
      "epoch": 773.18,
      "learning_rate": 0.02271374288118971,
      "loss": 2.452,
      "step": 480920
    },
    {
      "epoch": 773.22,
      "learning_rate": 0.022710527450321538,
      "loss": 2.4612,
      "step": 480940
    },
    {
      "epoch": 773.25,
      "learning_rate": 0.02270731201945338,
      "loss": 2.4461,
      "step": 480960
    },
    {
      "epoch": 773.28,
      "learning_rate": 0.022704096588585212,
      "loss": 2.4773,
      "step": 480980
    },
    {
      "epoch": 773.31,
      "learning_rate": 0.022700881157717043,
      "loss": 2.4736,
      "step": 481000
    },
    {
      "epoch": 773.34,
      "learning_rate": 0.022697665726848875,
      "loss": 2.4707,
      "step": 481020
    },
    {
      "epoch": 773.38,
      "learning_rate": 0.022694450295980703,
      "loss": 2.4696,
      "step": 481040
    },
    {
      "epoch": 773.41,
      "learning_rate": 0.022691234865112535,
      "loss": 2.4423,
      "step": 481060
    },
    {
      "epoch": 773.44,
      "learning_rate": 0.022688019434244377,
      "loss": 2.4575,
      "step": 481080
    },
    {
      "epoch": 773.47,
      "learning_rate": 0.02268480400337621,
      "loss": 2.4602,
      "step": 481100
    },
    {
      "epoch": 773.5,
      "learning_rate": 0.02268158857250804,
      "loss": 2.4741,
      "step": 481120
    },
    {
      "epoch": 773.54,
      "learning_rate": 0.02267837314163987,
      "loss": 2.4736,
      "step": 481140
    },
    {
      "epoch": 773.57,
      "learning_rate": 0.0226751577107717,
      "loss": 2.4472,
      "step": 481160
    },
    {
      "epoch": 773.6,
      "learning_rate": 0.02267194227990353,
      "loss": 2.4607,
      "step": 481180
    },
    {
      "epoch": 773.63,
      "learning_rate": 0.022668726849035373,
      "loss": 2.4681,
      "step": 481200
    },
    {
      "epoch": 773.67,
      "learning_rate": 0.022665511418167205,
      "loss": 2.4867,
      "step": 481220
    },
    {
      "epoch": 773.7,
      "learning_rate": 0.022662295987299037,
      "loss": 2.4548,
      "step": 481240
    },
    {
      "epoch": 773.73,
      "learning_rate": 0.022659080556430865,
      "loss": 2.4531,
      "step": 481260
    },
    {
      "epoch": 773.76,
      "learning_rate": 0.022655865125562696,
      "loss": 2.4527,
      "step": 481280
    },
    {
      "epoch": 773.79,
      "learning_rate": 0.02265264969469454,
      "loss": 2.4641,
      "step": 481300
    },
    {
      "epoch": 773.83,
      "learning_rate": 0.02264943426382637,
      "loss": 2.443,
      "step": 481320
    },
    {
      "epoch": 773.86,
      "learning_rate": 0.0226462188329582,
      "loss": 2.4534,
      "step": 481340
    },
    {
      "epoch": 773.89,
      "learning_rate": 0.02264300340209003,
      "loss": 2.4555,
      "step": 481360
    },
    {
      "epoch": 773.92,
      "learning_rate": 0.02263978797122186,
      "loss": 2.4769,
      "step": 481380
    },
    {
      "epoch": 773.95,
      "learning_rate": 0.022636572540353693,
      "loss": 2.4642,
      "step": 481400
    },
    {
      "epoch": 773.99,
      "learning_rate": 0.022633357109485535,
      "loss": 2.4558,
      "step": 481420
    },
    {
      "epoch": 774.0,
      "eval_accuracy": {
        "accuracy": 0.4476405193189769
      },
      "eval_loss": 2.5807785987854004,
      "eval_runtime": 3.0066,
      "eval_samples_per_second": 4278.274,
      "eval_steps_per_second": 66.853,
      "step": 481428
    },
    {
      "epoch": 774.02,
      "learning_rate": 0.022630141678617367,
      "loss": 2.4677,
      "step": 481440
    },
    {
      "epoch": 774.05,
      "learning_rate": 0.022626926247749198,
      "loss": 2.4611,
      "step": 481460
    },
    {
      "epoch": 774.08,
      "learning_rate": 0.022623710816881026,
      "loss": 2.468,
      "step": 481480
    },
    {
      "epoch": 774.12,
      "learning_rate": 0.022620495386012858,
      "loss": 2.4594,
      "step": 481500
    },
    {
      "epoch": 774.15,
      "learning_rate": 0.02261727995514469,
      "loss": 2.4438,
      "step": 481520
    },
    {
      "epoch": 774.18,
      "learning_rate": 0.02261406452427653,
      "loss": 2.4284,
      "step": 481540
    },
    {
      "epoch": 774.21,
      "learning_rate": 0.022610849093408363,
      "loss": 2.4473,
      "step": 481560
    },
    {
      "epoch": 774.24,
      "learning_rate": 0.02260763366254019,
      "loss": 2.4648,
      "step": 481580
    },
    {
      "epoch": 774.28,
      "learning_rate": 0.022604418231672023,
      "loss": 2.4659,
      "step": 481600
    },
    {
      "epoch": 774.31,
      "learning_rate": 0.022601202800803855,
      "loss": 2.465,
      "step": 481620
    },
    {
      "epoch": 774.34,
      "learning_rate": 0.022597987369935697,
      "loss": 2.4791,
      "step": 481640
    },
    {
      "epoch": 774.37,
      "learning_rate": 0.022594771939067528,
      "loss": 2.4508,
      "step": 481660
    },
    {
      "epoch": 774.41,
      "learning_rate": 0.022591556508199356,
      "loss": 2.4761,
      "step": 481680
    },
    {
      "epoch": 774.44,
      "learning_rate": 0.022588341077331188,
      "loss": 2.4655,
      "step": 481700
    },
    {
      "epoch": 774.47,
      "learning_rate": 0.02258512564646302,
      "loss": 2.46,
      "step": 481720
    },
    {
      "epoch": 774.5,
      "learning_rate": 0.022582070987138263,
      "loss": 2.4531,
      "step": 481740
    },
    {
      "epoch": 774.53,
      "learning_rate": 0.02257885555627009,
      "loss": 2.4801,
      "step": 481760
    },
    {
      "epoch": 774.57,
      "learning_rate": 0.022575640125401933,
      "loss": 2.4608,
      "step": 481780
    },
    {
      "epoch": 774.6,
      "learning_rate": 0.022572424694533764,
      "loss": 2.4449,
      "step": 481800
    },
    {
      "epoch": 774.63,
      "learning_rate": 0.022569209263665596,
      "loss": 2.4746,
      "step": 481820
    },
    {
      "epoch": 774.66,
      "learning_rate": 0.022565993832797428,
      "loss": 2.4791,
      "step": 481840
    },
    {
      "epoch": 774.69,
      "learning_rate": 0.02256277840192926,
      "loss": 2.4512,
      "step": 481860
    },
    {
      "epoch": 774.73,
      "learning_rate": 0.022559562971061087,
      "loss": 2.4555,
      "step": 481880
    },
    {
      "epoch": 774.76,
      "learning_rate": 0.02255634754019293,
      "loss": 2.4689,
      "step": 481900
    },
    {
      "epoch": 774.79,
      "learning_rate": 0.02255313210932476,
      "loss": 2.4573,
      "step": 481920
    },
    {
      "epoch": 774.82,
      "learning_rate": 0.022549916678456593,
      "loss": 2.4465,
      "step": 481940
    },
    {
      "epoch": 774.86,
      "learning_rate": 0.022546701247588424,
      "loss": 2.4882,
      "step": 481960
    },
    {
      "epoch": 774.89,
      "learning_rate": 0.022543485816720252,
      "loss": 2.4693,
      "step": 481980
    },
    {
      "epoch": 774.92,
      "learning_rate": 0.022540270385852084,
      "loss": 2.4527,
      "step": 482000
    },
    {
      "epoch": 774.95,
      "learning_rate": 0.022537054954983926,
      "loss": 2.4646,
      "step": 482020
    },
    {
      "epoch": 774.98,
      "learning_rate": 0.022533839524115758,
      "loss": 2.4345,
      "step": 482040
    },
    {
      "epoch": 775.0,
      "eval_accuracy": {
        "accuracy": 0.45230506102775403
      },
      "eval_loss": 2.562291145324707,
      "eval_runtime": 2.9943,
      "eval_samples_per_second": 4295.816,
      "eval_steps_per_second": 67.127,
      "step": 482050
    },
    {
      "epoch": 775.02,
      "learning_rate": 0.02253062409324759,
      "loss": 2.4575,
      "step": 482060
    },
    {
      "epoch": 775.05,
      "learning_rate": 0.022527408662379417,
      "loss": 2.4654,
      "step": 482080
    },
    {
      "epoch": 775.08,
      "learning_rate": 0.02252419323151125,
      "loss": 2.451,
      "step": 482100
    },
    {
      "epoch": 775.11,
      "learning_rate": 0.02252097780064309,
      "loss": 2.4581,
      "step": 482120
    },
    {
      "epoch": 775.14,
      "learning_rate": 0.022517762369774923,
      "loss": 2.4522,
      "step": 482140
    },
    {
      "epoch": 775.18,
      "learning_rate": 0.022514546938906754,
      "loss": 2.459,
      "step": 482160
    },
    {
      "epoch": 775.21,
      "learning_rate": 0.022511331508038586,
      "loss": 2.4755,
      "step": 482180
    },
    {
      "epoch": 775.24,
      "learning_rate": 0.022508116077170414,
      "loss": 2.4707,
      "step": 482200
    },
    {
      "epoch": 775.27,
      "learning_rate": 0.022504900646302246,
      "loss": 2.452,
      "step": 482220
    },
    {
      "epoch": 775.31,
      "learning_rate": 0.022501685215434088,
      "loss": 2.4574,
      "step": 482240
    },
    {
      "epoch": 775.34,
      "learning_rate": 0.02249846978456592,
      "loss": 2.4592,
      "step": 482260
    },
    {
      "epoch": 775.37,
      "learning_rate": 0.02249525435369775,
      "loss": 2.4676,
      "step": 482280
    },
    {
      "epoch": 775.4,
      "learning_rate": 0.02249203892282958,
      "loss": 2.4675,
      "step": 482300
    },
    {
      "epoch": 775.43,
      "learning_rate": 0.02248882349196141,
      "loss": 2.4613,
      "step": 482320
    },
    {
      "epoch": 775.47,
      "learning_rate": 0.022485608061093242,
      "loss": 2.4897,
      "step": 482340
    },
    {
      "epoch": 775.5,
      "learning_rate": 0.022482392630225084,
      "loss": 2.4427,
      "step": 482360
    },
    {
      "epoch": 775.53,
      "learning_rate": 0.022479177199356916,
      "loss": 2.4646,
      "step": 482380
    },
    {
      "epoch": 775.56,
      "learning_rate": 0.022475961768488744,
      "loss": 2.4886,
      "step": 482400
    },
    {
      "epoch": 775.59,
      "learning_rate": 0.022472746337620576,
      "loss": 2.4641,
      "step": 482420
    },
    {
      "epoch": 775.63,
      "learning_rate": 0.022469530906752407,
      "loss": 2.4469,
      "step": 482440
    },
    {
      "epoch": 775.66,
      "learning_rate": 0.02246631547588425,
      "loss": 2.448,
      "step": 482460
    },
    {
      "epoch": 775.69,
      "learning_rate": 0.02246310004501608,
      "loss": 2.4504,
      "step": 482480
    },
    {
      "epoch": 775.72,
      "learning_rate": 0.022459884614147912,
      "loss": 2.4701,
      "step": 482500
    },
    {
      "epoch": 775.76,
      "learning_rate": 0.02245666918327974,
      "loss": 2.4697,
      "step": 482520
    },
    {
      "epoch": 775.79,
      "learning_rate": 0.022453453752411572,
      "loss": 2.4514,
      "step": 482540
    },
    {
      "epoch": 775.82,
      "learning_rate": 0.022450238321543404,
      "loss": 2.4679,
      "step": 482560
    },
    {
      "epoch": 775.85,
      "learning_rate": 0.022447022890675246,
      "loss": 2.4549,
      "step": 482580
    },
    {
      "epoch": 775.88,
      "learning_rate": 0.022443807459807077,
      "loss": 2.464,
      "step": 482600
    },
    {
      "epoch": 775.92,
      "learning_rate": 0.022440592028938906,
      "loss": 2.4481,
      "step": 482620
    },
    {
      "epoch": 775.95,
      "learning_rate": 0.022437376598070737,
      "loss": 2.466,
      "step": 482640
    },
    {
      "epoch": 775.98,
      "learning_rate": 0.02243416116720257,
      "loss": 2.4597,
      "step": 482660
    },
    {
      "epoch": 776.0,
      "eval_accuracy": {
        "accuracy": 0.4484179429371064
      },
      "eval_loss": 2.5793187618255615,
      "eval_runtime": 3.1002,
      "eval_samples_per_second": 4149.084,
      "eval_steps_per_second": 64.834,
      "step": 482672
    },
    {
      "epoch": 776.01,
      "learning_rate": 0.02243094573633441,
      "loss": 2.4578,
      "step": 482680
    },
    {
      "epoch": 776.05,
      "learning_rate": 0.022427730305466242,
      "loss": 2.4467,
      "step": 482700
    },
    {
      "epoch": 776.08,
      "learning_rate": 0.02242451487459807,
      "loss": 2.4566,
      "step": 482720
    },
    {
      "epoch": 776.11,
      "learning_rate": 0.022421299443729902,
      "loss": 2.461,
      "step": 482740
    },
    {
      "epoch": 776.14,
      "learning_rate": 0.022418084012861734,
      "loss": 2.4531,
      "step": 482760
    },
    {
      "epoch": 776.17,
      "learning_rate": 0.022414868581993565,
      "loss": 2.4453,
      "step": 482780
    },
    {
      "epoch": 776.21,
      "learning_rate": 0.022411653151125407,
      "loss": 2.4581,
      "step": 482800
    },
    {
      "epoch": 776.24,
      "learning_rate": 0.02240843772025724,
      "loss": 2.4737,
      "step": 482820
    },
    {
      "epoch": 776.27,
      "learning_rate": 0.022405222289389067,
      "loss": 2.4612,
      "step": 482840
    },
    {
      "epoch": 776.3,
      "learning_rate": 0.0224020068585209,
      "loss": 2.4646,
      "step": 482860
    },
    {
      "epoch": 776.33,
      "learning_rate": 0.02239879142765273,
      "loss": 2.463,
      "step": 482880
    },
    {
      "epoch": 776.37,
      "learning_rate": 0.022395575996784562,
      "loss": 2.4436,
      "step": 482900
    },
    {
      "epoch": 776.4,
      "learning_rate": 0.022392360565916404,
      "loss": 2.4364,
      "step": 482920
    },
    {
      "epoch": 776.43,
      "learning_rate": 0.022389145135048232,
      "loss": 2.4604,
      "step": 482940
    },
    {
      "epoch": 776.46,
      "learning_rate": 0.022385929704180064,
      "loss": 2.4689,
      "step": 482960
    },
    {
      "epoch": 776.5,
      "learning_rate": 0.022382714273311895,
      "loss": 2.4501,
      "step": 482980
    },
    {
      "epoch": 776.53,
      "learning_rate": 0.022379498842443727,
      "loss": 2.4579,
      "step": 483000
    },
    {
      "epoch": 776.56,
      "learning_rate": 0.02237628341157557,
      "loss": 2.4757,
      "step": 483020
    },
    {
      "epoch": 776.59,
      "learning_rate": 0.022373067980707397,
      "loss": 2.459,
      "step": 483040
    },
    {
      "epoch": 776.62,
      "learning_rate": 0.02236985254983923,
      "loss": 2.4612,
      "step": 483060
    },
    {
      "epoch": 776.66,
      "learning_rate": 0.02236663711897106,
      "loss": 2.4813,
      "step": 483080
    },
    {
      "epoch": 776.69,
      "learning_rate": 0.022363421688102892,
      "loss": 2.4629,
      "step": 483100
    },
    {
      "epoch": 776.72,
      "learning_rate": 0.022360206257234724,
      "loss": 2.4662,
      "step": 483120
    },
    {
      "epoch": 776.75,
      "learning_rate": 0.022356990826366566,
      "loss": 2.4486,
      "step": 483140
    },
    {
      "epoch": 776.78,
      "learning_rate": 0.022353775395498394,
      "loss": 2.4656,
      "step": 483160
    },
    {
      "epoch": 776.82,
      "learning_rate": 0.022350559964630225,
      "loss": 2.4522,
      "step": 483180
    },
    {
      "epoch": 776.85,
      "learning_rate": 0.022347344533762057,
      "loss": 2.4678,
      "step": 483200
    },
    {
      "epoch": 776.88,
      "learning_rate": 0.02234412910289389,
      "loss": 2.4565,
      "step": 483220
    },
    {
      "epoch": 776.91,
      "learning_rate": 0.022340913672025717,
      "loss": 2.4836,
      "step": 483240
    },
    {
      "epoch": 776.95,
      "learning_rate": 0.02233769824115756,
      "loss": 2.4405,
      "step": 483260
    },
    {
      "epoch": 776.98,
      "learning_rate": 0.02233448281028939,
      "loss": 2.4737,
      "step": 483280
    },
    {
      "epoch": 777.0,
      "eval_accuracy": {
        "accuracy": 0.44593018735909196
      },
      "eval_loss": 2.5872585773468018,
      "eval_runtime": 3.0107,
      "eval_samples_per_second": 4272.406,
      "eval_steps_per_second": 66.762,
      "step": 483294
    },
    {
      "epoch": 777.01,
      "learning_rate": 0.022331267379421222,
      "loss": 2.4866,
      "step": 483300
    },
    {
      "epoch": 777.04,
      "learning_rate": 0.022328051948553054,
      "loss": 2.4647,
      "step": 483320
    },
    {
      "epoch": 777.07,
      "learning_rate": 0.022324836517684885,
      "loss": 2.4464,
      "step": 483340
    },
    {
      "epoch": 777.11,
      "learning_rate": 0.022321621086816724,
      "loss": 2.4623,
      "step": 483360
    },
    {
      "epoch": 777.14,
      "learning_rate": 0.022318405655948555,
      "loss": 2.4528,
      "step": 483380
    },
    {
      "epoch": 777.17,
      "learning_rate": 0.022315190225080387,
      "loss": 2.4812,
      "step": 483400
    },
    {
      "epoch": 777.2,
      "learning_rate": 0.02231197479421222,
      "loss": 2.4405,
      "step": 483420
    },
    {
      "epoch": 777.23,
      "learning_rate": 0.02230875936334405,
      "loss": 2.4486,
      "step": 483440
    },
    {
      "epoch": 777.27,
      "learning_rate": 0.02230554393247588,
      "loss": 2.4664,
      "step": 483460
    },
    {
      "epoch": 777.3,
      "learning_rate": 0.02230232850160772,
      "loss": 2.458,
      "step": 483480
    },
    {
      "epoch": 777.33,
      "learning_rate": 0.022299113070739552,
      "loss": 2.4515,
      "step": 483500
    },
    {
      "epoch": 777.36,
      "learning_rate": 0.022295897639871384,
      "loss": 2.4506,
      "step": 483520
    },
    {
      "epoch": 777.4,
      "learning_rate": 0.022292682209003215,
      "loss": 2.4725,
      "step": 483540
    },
    {
      "epoch": 777.43,
      "learning_rate": 0.022289466778135043,
      "loss": 2.4738,
      "step": 483560
    },
    {
      "epoch": 777.46,
      "learning_rate": 0.022286251347266875,
      "loss": 2.4255,
      "step": 483580
    },
    {
      "epoch": 777.49,
      "learning_rate": 0.022283035916398717,
      "loss": 2.4538,
      "step": 483600
    },
    {
      "epoch": 777.52,
      "learning_rate": 0.02227982048553055,
      "loss": 2.4421,
      "step": 483620
    },
    {
      "epoch": 777.56,
      "learning_rate": 0.02227660505466238,
      "loss": 2.4625,
      "step": 483640
    },
    {
      "epoch": 777.59,
      "learning_rate": 0.022273389623794212,
      "loss": 2.4482,
      "step": 483660
    },
    {
      "epoch": 777.62,
      "learning_rate": 0.02227017419292604,
      "loss": 2.4423,
      "step": 483680
    },
    {
      "epoch": 777.65,
      "learning_rate": 0.022266958762057882,
      "loss": 2.4716,
      "step": 483700
    },
    {
      "epoch": 777.68,
      "learning_rate": 0.022263743331189714,
      "loss": 2.4682,
      "step": 483720
    },
    {
      "epoch": 777.72,
      "learning_rate": 0.022260527900321545,
      "loss": 2.4658,
      "step": 483740
    },
    {
      "epoch": 777.75,
      "learning_rate": 0.022257312469453377,
      "loss": 2.4613,
      "step": 483760
    },
    {
      "epoch": 777.78,
      "learning_rate": 0.022254097038585205,
      "loss": 2.466,
      "step": 483780
    },
    {
      "epoch": 777.81,
      "learning_rate": 0.022250881607717037,
      "loss": 2.4494,
      "step": 483800
    },
    {
      "epoch": 777.85,
      "learning_rate": 0.02224766617684888,
      "loss": 2.4403,
      "step": 483820
    },
    {
      "epoch": 777.88,
      "learning_rate": 0.02224445074598071,
      "loss": 2.4635,
      "step": 483840
    },
    {
      "epoch": 777.91,
      "learning_rate": 0.022241235315112542,
      "loss": 2.4677,
      "step": 483860
    },
    {
      "epoch": 777.94,
      "learning_rate": 0.02223801988424437,
      "loss": 2.4832,
      "step": 483880
    },
    {
      "epoch": 777.97,
      "learning_rate": 0.0222348044533762,
      "loss": 2.4691,
      "step": 483900
    },
    {
      "epoch": 778.0,
      "eval_accuracy": {
        "accuracy": 0.45012827489699136
      },
      "eval_loss": 2.560167074203491,
      "eval_runtime": 3.1687,
      "eval_samples_per_second": 4059.448,
      "eval_steps_per_second": 63.434,
      "step": 483916
    },
    {
      "epoch": 778.01,
      "learning_rate": 0.022231589022508033,
      "loss": 2.4653,
      "step": 483920
    },
    {
      "epoch": 778.04,
      "learning_rate": 0.022228373591639875,
      "loss": 2.4612,
      "step": 483940
    },
    {
      "epoch": 778.07,
      "learning_rate": 0.022225158160771707,
      "loss": 2.4458,
      "step": 483960
    },
    {
      "epoch": 778.1,
      "learning_rate": 0.02222194272990354,
      "loss": 2.439,
      "step": 483980
    },
    {
      "epoch": 778.14,
      "learning_rate": 0.022218727299035367,
      "loss": 2.452,
      "step": 484000
    },
    {
      "epoch": 778.17,
      "learning_rate": 0.022215511868167198,
      "loss": 2.4501,
      "step": 484020
    },
    {
      "epoch": 778.2,
      "learning_rate": 0.02221229643729904,
      "loss": 2.448,
      "step": 484040
    },
    {
      "epoch": 778.23,
      "learning_rate": 0.022209081006430872,
      "loss": 2.4448,
      "step": 484060
    },
    {
      "epoch": 778.26,
      "learning_rate": 0.022205865575562703,
      "loss": 2.4391,
      "step": 484080
    },
    {
      "epoch": 778.3,
      "learning_rate": 0.02220265014469453,
      "loss": 2.471,
      "step": 484100
    },
    {
      "epoch": 778.33,
      "learning_rate": 0.022199434713826363,
      "loss": 2.4587,
      "step": 484120
    },
    {
      "epoch": 778.36,
      "learning_rate": 0.022196219282958195,
      "loss": 2.478,
      "step": 484140
    },
    {
      "epoch": 778.39,
      "learning_rate": 0.022193003852090037,
      "loss": 2.4607,
      "step": 484160
    },
    {
      "epoch": 778.42,
      "learning_rate": 0.02218978842122187,
      "loss": 2.4609,
      "step": 484180
    },
    {
      "epoch": 778.46,
      "learning_rate": 0.022186572990353697,
      "loss": 2.4448,
      "step": 484200
    },
    {
      "epoch": 778.49,
      "learning_rate": 0.022183357559485528,
      "loss": 2.4711,
      "step": 484220
    },
    {
      "epoch": 778.52,
      "learning_rate": 0.02218014212861736,
      "loss": 2.4647,
      "step": 484240
    },
    {
      "epoch": 778.55,
      "learning_rate": 0.02217692669774919,
      "loss": 2.4647,
      "step": 484260
    },
    {
      "epoch": 778.59,
      "learning_rate": 0.022173711266881033,
      "loss": 2.4634,
      "step": 484280
    },
    {
      "epoch": 778.62,
      "learning_rate": 0.022170495836012865,
      "loss": 2.4444,
      "step": 484300
    },
    {
      "epoch": 778.65,
      "learning_rate": 0.022167441176688105,
      "loss": 2.4444,
      "step": 484320
    },
    {
      "epoch": 778.68,
      "learning_rate": 0.022164225745819936,
      "loss": 2.4519,
      "step": 484340
    },
    {
      "epoch": 778.71,
      "learning_rate": 0.022161010314951768,
      "loss": 2.47,
      "step": 484360
    },
    {
      "epoch": 778.75,
      "learning_rate": 0.0221577948840836,
      "loss": 2.4588,
      "step": 484380
    },
    {
      "epoch": 778.78,
      "learning_rate": 0.022154579453215428,
      "loss": 2.4601,
      "step": 484400
    },
    {
      "epoch": 778.81,
      "learning_rate": 0.02215136402234727,
      "loss": 2.4333,
      "step": 484420
    },
    {
      "epoch": 778.84,
      "learning_rate": 0.0221481485914791,
      "loss": 2.4586,
      "step": 484440
    },
    {
      "epoch": 778.87,
      "learning_rate": 0.022144933160610933,
      "loss": 2.443,
      "step": 484460
    },
    {
      "epoch": 778.91,
      "learning_rate": 0.022141717729742764,
      "loss": 2.4873,
      "step": 484480
    },
    {
      "epoch": 778.94,
      "learning_rate": 0.022138502298874593,
      "loss": 2.456,
      "step": 484500
    },
    {
      "epoch": 778.97,
      "learning_rate": 0.022135286868006435,
      "loss": 2.4495,
      "step": 484520
    },
    {
      "epoch": 779.0,
      "eval_accuracy": {
        "accuracy": 0.4467076109772215
      },
      "eval_loss": 2.576032876968384,
      "eval_runtime": 2.9431,
      "eval_samples_per_second": 4370.625,
      "eval_steps_per_second": 68.296,
      "step": 484538
    },
    {
      "epoch": 779.0,
      "learning_rate": 0.022132071437138266,
      "loss": 2.4684,
      "step": 484540
    },
    {
      "epoch": 779.04,
      "learning_rate": 0.022128856006270098,
      "loss": 2.4556,
      "step": 484560
    },
    {
      "epoch": 779.07,
      "learning_rate": 0.02212564057540193,
      "loss": 2.4673,
      "step": 484580
    },
    {
      "epoch": 779.1,
      "learning_rate": 0.022122425144533758,
      "loss": 2.4539,
      "step": 484600
    },
    {
      "epoch": 779.13,
      "learning_rate": 0.02211920971366559,
      "loss": 2.4667,
      "step": 484620
    },
    {
      "epoch": 779.16,
      "learning_rate": 0.02211599428279743,
      "loss": 2.4631,
      "step": 484640
    },
    {
      "epoch": 779.2,
      "learning_rate": 0.022112778851929263,
      "loss": 2.4599,
      "step": 484660
    },
    {
      "epoch": 779.23,
      "learning_rate": 0.022109563421061094,
      "loss": 2.4654,
      "step": 484680
    },
    {
      "epoch": 779.26,
      "learning_rate": 0.022106347990192926,
      "loss": 2.4554,
      "step": 484700
    },
    {
      "epoch": 779.29,
      "learning_rate": 0.022103132559324754,
      "loss": 2.4629,
      "step": 484720
    },
    {
      "epoch": 779.32,
      "learning_rate": 0.022099917128456586,
      "loss": 2.4779,
      "step": 484740
    },
    {
      "epoch": 779.36,
      "learning_rate": 0.022096701697588428,
      "loss": 2.4554,
      "step": 484760
    },
    {
      "epoch": 779.39,
      "learning_rate": 0.02209348626672026,
      "loss": 2.4577,
      "step": 484780
    },
    {
      "epoch": 779.42,
      "learning_rate": 0.02209027083585209,
      "loss": 2.4618,
      "step": 484800
    },
    {
      "epoch": 779.45,
      "learning_rate": 0.02208705540498392,
      "loss": 2.4741,
      "step": 484820
    },
    {
      "epoch": 779.49,
      "learning_rate": 0.02208383997411575,
      "loss": 2.4426,
      "step": 484840
    },
    {
      "epoch": 779.52,
      "learning_rate": 0.022080624543247593,
      "loss": 2.4605,
      "step": 484860
    },
    {
      "epoch": 779.55,
      "learning_rate": 0.022077409112379424,
      "loss": 2.4579,
      "step": 484880
    },
    {
      "epoch": 779.58,
      "learning_rate": 0.022074193681511256,
      "loss": 2.4446,
      "step": 484900
    },
    {
      "epoch": 779.61,
      "learning_rate": 0.022070978250643084,
      "loss": 2.4649,
      "step": 484920
    },
    {
      "epoch": 779.65,
      "learning_rate": 0.022067762819774916,
      "loss": 2.4667,
      "step": 484940
    },
    {
      "epoch": 779.68,
      "learning_rate": 0.022064547388906747,
      "loss": 2.4471,
      "step": 484960
    },
    {
      "epoch": 779.71,
      "learning_rate": 0.02206133195803859,
      "loss": 2.4356,
      "step": 484980
    },
    {
      "epoch": 779.74,
      "learning_rate": 0.02205811652717042,
      "loss": 2.4498,
      "step": 485000
    },
    {
      "epoch": 779.77,
      "learning_rate": 0.022054901096302253,
      "loss": 2.4492,
      "step": 485020
    },
    {
      "epoch": 779.81,
      "learning_rate": 0.02205168566543408,
      "loss": 2.468,
      "step": 485040
    },
    {
      "epoch": 779.84,
      "learning_rate": 0.022048470234565912,
      "loss": 2.4643,
      "step": 485060
    },
    {
      "epoch": 779.87,
      "learning_rate": 0.022045254803697754,
      "loss": 2.463,
      "step": 485080
    },
    {
      "epoch": 779.9,
      "learning_rate": 0.022042039372829586,
      "loss": 2.4582,
      "step": 485100
    },
    {
      "epoch": 779.94,
      "learning_rate": 0.022038823941961418,
      "loss": 2.4638,
      "step": 485120
    },
    {
      "epoch": 779.97,
      "learning_rate": 0.022035608511093246,
      "loss": 2.4602,
      "step": 485140
    },
    {
      "epoch": 780.0,
      "learning_rate": 0.022032393080225077,
      "loss": 2.4557,
      "step": 485160
    },
    {
      "epoch": 780.0,
      "eval_accuracy": {
        "accuracy": 0.44826245821348054
      },
      "eval_loss": 2.582923650741577,
      "eval_runtime": 2.9572,
      "eval_samples_per_second": 4349.764,
      "eval_steps_per_second": 67.97,
      "step": 485160
    },
    {
      "epoch": 780.03,
      "learning_rate": 0.02202917764935691,
      "loss": 2.4497,
      "step": 485180
    },
    {
      "epoch": 780.06,
      "learning_rate": 0.02202596221848875,
      "loss": 2.4617,
      "step": 485200
    },
    {
      "epoch": 780.1,
      "learning_rate": 0.022022746787620583,
      "loss": 2.444,
      "step": 485220
    },
    {
      "epoch": 780.13,
      "learning_rate": 0.02201953135675241,
      "loss": 2.4342,
      "step": 485240
    },
    {
      "epoch": 780.16,
      "learning_rate": 0.022016315925884242,
      "loss": 2.4583,
      "step": 485260
    },
    {
      "epoch": 780.19,
      "learning_rate": 0.022013100495016074,
      "loss": 2.4595,
      "step": 485280
    },
    {
      "epoch": 780.23,
      "learning_rate": 0.022009885064147906,
      "loss": 2.4618,
      "step": 485300
    },
    {
      "epoch": 780.26,
      "learning_rate": 0.022006669633279748,
      "loss": 2.46,
      "step": 485320
    },
    {
      "epoch": 780.29,
      "learning_rate": 0.02200345420241158,
      "loss": 2.4596,
      "step": 485340
    },
    {
      "epoch": 780.32,
      "learning_rate": 0.022000238771543407,
      "loss": 2.4445,
      "step": 485360
    },
    {
      "epoch": 780.35,
      "learning_rate": 0.02199702334067524,
      "loss": 2.4401,
      "step": 485380
    },
    {
      "epoch": 780.39,
      "learning_rate": 0.02199380790980707,
      "loss": 2.4718,
      "step": 485400
    },
    {
      "epoch": 780.42,
      "learning_rate": 0.021990592478938913,
      "loss": 2.4467,
      "step": 485420
    },
    {
      "epoch": 780.45,
      "learning_rate": 0.021987377048070744,
      "loss": 2.4624,
      "step": 485440
    },
    {
      "epoch": 780.48,
      "learning_rate": 0.021984161617202572,
      "loss": 2.4588,
      "step": 485460
    },
    {
      "epoch": 780.51,
      "learning_rate": 0.021980946186334404,
      "loss": 2.4524,
      "step": 485480
    },
    {
      "epoch": 780.55,
      "learning_rate": 0.021977730755466236,
      "loss": 2.4685,
      "step": 485500
    },
    {
      "epoch": 780.58,
      "learning_rate": 0.021974515324598067,
      "loss": 2.4671,
      "step": 485520
    },
    {
      "epoch": 780.61,
      "learning_rate": 0.02197129989372991,
      "loss": 2.453,
      "step": 485540
    },
    {
      "epoch": 780.64,
      "learning_rate": 0.021968084462861737,
      "loss": 2.472,
      "step": 485560
    },
    {
      "epoch": 780.68,
      "learning_rate": 0.02196486903199357,
      "loss": 2.4517,
      "step": 485580
    },
    {
      "epoch": 780.71,
      "learning_rate": 0.0219616536011254,
      "loss": 2.4745,
      "step": 485600
    },
    {
      "epoch": 780.74,
      "learning_rate": 0.021958438170257232,
      "loss": 2.4513,
      "step": 485620
    },
    {
      "epoch": 780.77,
      "learning_rate": 0.021955222739389064,
      "loss": 2.4564,
      "step": 485640
    },
    {
      "epoch": 780.8,
      "learning_rate": 0.021952007308520906,
      "loss": 2.4698,
      "step": 485660
    },
    {
      "epoch": 780.84,
      "learning_rate": 0.021948791877652734,
      "loss": 2.4703,
      "step": 485680
    },
    {
      "epoch": 780.87,
      "learning_rate": 0.021945576446784566,
      "loss": 2.4697,
      "step": 485700
    },
    {
      "epoch": 780.9,
      "learning_rate": 0.021942361015916397,
      "loss": 2.4725,
      "step": 485720
    },
    {
      "epoch": 780.93,
      "learning_rate": 0.02193914558504823,
      "loss": 2.4653,
      "step": 485740
    },
    {
      "epoch": 780.96,
      "learning_rate": 0.02193593015418007,
      "loss": 2.4469,
      "step": 485760
    },
    {
      "epoch": 781.0,
      "learning_rate": 0.0219327147233119,
      "loss": 2.4543,
      "step": 485780
    },
    {
      "epoch": 781.0,
      "eval_accuracy": {
        "accuracy": 0.44888439710798417
      },
      "eval_loss": 2.5732994079589844,
      "eval_runtime": 2.9713,
      "eval_samples_per_second": 4329.15,
      "eval_steps_per_second": 67.648,
      "step": 485782
    },
    {
      "epoch": 781.03,
      "learning_rate": 0.02192949929244373,
      "loss": 2.4344,
      "step": 485800
    },
    {
      "epoch": 781.06,
      "learning_rate": 0.021926283861575562,
      "loss": 2.4535,
      "step": 485820
    },
    {
      "epoch": 781.09,
      "learning_rate": 0.021923068430707394,
      "loss": 2.4659,
      "step": 485840
    },
    {
      "epoch": 781.13,
      "learning_rate": 0.021919852999839225,
      "loss": 2.4611,
      "step": 485860
    },
    {
      "epoch": 781.16,
      "learning_rate": 0.021916637568971067,
      "loss": 2.4843,
      "step": 485880
    },
    {
      "epoch": 781.19,
      "learning_rate": 0.021913422138102896,
      "loss": 2.4414,
      "step": 485900
    },
    {
      "epoch": 781.22,
      "learning_rate": 0.021910206707234727,
      "loss": 2.4497,
      "step": 485920
    },
    {
      "epoch": 781.25,
      "learning_rate": 0.02190699127636656,
      "loss": 2.4591,
      "step": 485940
    },
    {
      "epoch": 781.29,
      "learning_rate": 0.02190377584549839,
      "loss": 2.4572,
      "step": 485960
    },
    {
      "epoch": 781.32,
      "learning_rate": 0.02190056041463022,
      "loss": 2.4388,
      "step": 485980
    },
    {
      "epoch": 781.35,
      "learning_rate": 0.02189734498376206,
      "loss": 2.4383,
      "step": 486000
    },
    {
      "epoch": 781.38,
      "learning_rate": 0.021894129552893892,
      "loss": 2.4609,
      "step": 486020
    },
    {
      "epoch": 781.41,
      "learning_rate": 0.021890914122025724,
      "loss": 2.4396,
      "step": 486040
    },
    {
      "epoch": 781.45,
      "learning_rate": 0.021887698691157555,
      "loss": 2.4575,
      "step": 486060
    },
    {
      "epoch": 781.48,
      "learning_rate": 0.021884483260289384,
      "loss": 2.4555,
      "step": 486080
    },
    {
      "epoch": 781.51,
      "learning_rate": 0.021881267829421226,
      "loss": 2.4726,
      "step": 486100
    },
    {
      "epoch": 781.54,
      "learning_rate": 0.021878052398553057,
      "loss": 2.4551,
      "step": 486120
    },
    {
      "epoch": 781.58,
      "learning_rate": 0.02187483696768489,
      "loss": 2.4653,
      "step": 486140
    },
    {
      "epoch": 781.61,
      "learning_rate": 0.02187162153681672,
      "loss": 2.4743,
      "step": 486160
    },
    {
      "epoch": 781.64,
      "learning_rate": 0.021868406105948552,
      "loss": 2.4553,
      "step": 486180
    },
    {
      "epoch": 781.67,
      "learning_rate": 0.02186519067508038,
      "loss": 2.4544,
      "step": 486200
    },
    {
      "epoch": 781.7,
      "learning_rate": 0.021861975244212222,
      "loss": 2.445,
      "step": 486220
    },
    {
      "epoch": 781.74,
      "learning_rate": 0.021858759813344054,
      "loss": 2.4604,
      "step": 486240
    },
    {
      "epoch": 781.77,
      "learning_rate": 0.021855544382475885,
      "loss": 2.4513,
      "step": 486260
    },
    {
      "epoch": 781.8,
      "learning_rate": 0.021852328951607717,
      "loss": 2.4414,
      "step": 486280
    },
    {
      "epoch": 781.83,
      "learning_rate": 0.021849113520739545,
      "loss": 2.4701,
      "step": 486300
    },
    {
      "epoch": 781.86,
      "learning_rate": 0.021845898089871377,
      "loss": 2.4587,
      "step": 486320
    },
    {
      "epoch": 781.9,
      "learning_rate": 0.02184268265900322,
      "loss": 2.4612,
      "step": 486340
    },
    {
      "epoch": 781.93,
      "learning_rate": 0.02183946722813505,
      "loss": 2.4669,
      "step": 486360
    },
    {
      "epoch": 781.96,
      "learning_rate": 0.021836251797266882,
      "loss": 2.4492,
      "step": 486380
    },
    {
      "epoch": 781.99,
      "learning_rate": 0.02183303636639871,
      "loss": 2.4783,
      "step": 486400
    },
    {
      "epoch": 782.0,
      "eval_accuracy": {
        "accuracy": 0.4495840783643007
      },
      "eval_loss": 2.572932004928589,
      "eval_runtime": 3.0571,
      "eval_samples_per_second": 4207.595,
      "eval_steps_per_second": 65.749,
      "step": 486404
    },
    {
      "epoch": 782.03,
      "learning_rate": 0.02182982093553054,
      "loss": 2.4404,
      "step": 486420
    },
    {
      "epoch": 782.06,
      "learning_rate": 0.021826605504662384,
      "loss": 2.4473,
      "step": 486440
    },
    {
      "epoch": 782.09,
      "learning_rate": 0.021823390073794215,
      "loss": 2.4528,
      "step": 486460
    },
    {
      "epoch": 782.12,
      "learning_rate": 0.021820174642926047,
      "loss": 2.4455,
      "step": 486480
    },
    {
      "epoch": 782.15,
      "learning_rate": 0.02181695921205788,
      "loss": 2.4722,
      "step": 486500
    },
    {
      "epoch": 782.19,
      "learning_rate": 0.021813743781189707,
      "loss": 2.4556,
      "step": 486520
    },
    {
      "epoch": 782.22,
      "learning_rate": 0.02181052835032154,
      "loss": 2.4528,
      "step": 486540
    },
    {
      "epoch": 782.25,
      "learning_rate": 0.02180731291945338,
      "loss": 2.4496,
      "step": 486560
    },
    {
      "epoch": 782.28,
      "learning_rate": 0.021804097488585212,
      "loss": 2.4406,
      "step": 486580
    },
    {
      "epoch": 782.32,
      "learning_rate": 0.021800882057717044,
      "loss": 2.4313,
      "step": 486600
    },
    {
      "epoch": 782.35,
      "learning_rate": 0.02179766662684887,
      "loss": 2.4673,
      "step": 486620
    },
    {
      "epoch": 782.38,
      "learning_rate": 0.021794451195980703,
      "loss": 2.4603,
      "step": 486640
    },
    {
      "epoch": 782.41,
      "learning_rate": 0.021791235765112535,
      "loss": 2.4305,
      "step": 486660
    },
    {
      "epoch": 782.44,
      "learning_rate": 0.021788020334244377,
      "loss": 2.4569,
      "step": 486680
    },
    {
      "epoch": 782.48,
      "learning_rate": 0.02178480490337621,
      "loss": 2.4529,
      "step": 486700
    },
    {
      "epoch": 782.51,
      "learning_rate": 0.021781750244051448,
      "loss": 2.445,
      "step": 486720
    },
    {
      "epoch": 782.54,
      "learning_rate": 0.02177853481318328,
      "loss": 2.4704,
      "step": 486740
    },
    {
      "epoch": 782.57,
      "learning_rate": 0.02177531938231511,
      "loss": 2.442,
      "step": 486760
    },
    {
      "epoch": 782.6,
      "learning_rate": 0.021772103951446943,
      "loss": 2.4561,
      "step": 486780
    },
    {
      "epoch": 782.64,
      "learning_rate": 0.02176888852057877,
      "loss": 2.4535,
      "step": 486800
    },
    {
      "epoch": 782.67,
      "learning_rate": 0.021765673089710613,
      "loss": 2.4821,
      "step": 486820
    },
    {
      "epoch": 782.7,
      "learning_rate": 0.021762457658842445,
      "loss": 2.4761,
      "step": 486840
    },
    {
      "epoch": 782.73,
      "learning_rate": 0.021759242227974276,
      "loss": 2.4611,
      "step": 486860
    },
    {
      "epoch": 782.77,
      "learning_rate": 0.021756026797106108,
      "loss": 2.4465,
      "step": 486880
    },
    {
      "epoch": 782.8,
      "learning_rate": 0.02175281136623794,
      "loss": 2.4624,
      "step": 486900
    },
    {
      "epoch": 782.83,
      "learning_rate": 0.02174959593536978,
      "loss": 2.4712,
      "step": 486920
    },
    {
      "epoch": 782.86,
      "learning_rate": 0.02174638050450161,
      "loss": 2.4666,
      "step": 486940
    },
    {
      "epoch": 782.89,
      "learning_rate": 0.02174316507363344,
      "loss": 2.4589,
      "step": 486960
    },
    {
      "epoch": 782.93,
      "learning_rate": 0.021739949642765273,
      "loss": 2.4606,
      "step": 486980
    },
    {
      "epoch": 782.96,
      "learning_rate": 0.021736734211897105,
      "loss": 2.4463,
      "step": 487000
    },
    {
      "epoch": 782.99,
      "learning_rate": 0.021733518781028933,
      "loss": 2.4521,
      "step": 487020
    },
    {
      "epoch": 783.0,
      "eval_accuracy": {
        "accuracy": 0.4492731089170489
      },
      "eval_loss": 2.5623602867126465,
      "eval_runtime": 2.998,
      "eval_samples_per_second": 4290.535,
      "eval_steps_per_second": 67.045,
      "step": 487026
    },
    {
      "epoch": 783.02,
      "learning_rate": 0.021730303350160775,
      "loss": 2.4718,
      "step": 487040
    },
    {
      "epoch": 783.05,
      "learning_rate": 0.021727087919292606,
      "loss": 2.4462,
      "step": 487060
    },
    {
      "epoch": 783.09,
      "learning_rate": 0.021723872488424438,
      "loss": 2.4315,
      "step": 487080
    },
    {
      "epoch": 783.12,
      "learning_rate": 0.02172065705755627,
      "loss": 2.4667,
      "step": 487100
    },
    {
      "epoch": 783.15,
      "learning_rate": 0.021717441626688098,
      "loss": 2.4757,
      "step": 487120
    },
    {
      "epoch": 783.18,
      "learning_rate": 0.02171422619581993,
      "loss": 2.4361,
      "step": 487140
    },
    {
      "epoch": 783.22,
      "learning_rate": 0.02171101076495177,
      "loss": 2.4452,
      "step": 487160
    },
    {
      "epoch": 783.25,
      "learning_rate": 0.021707795334083603,
      "loss": 2.4404,
      "step": 487180
    },
    {
      "epoch": 783.28,
      "learning_rate": 0.021704579903215435,
      "loss": 2.4595,
      "step": 487200
    },
    {
      "epoch": 783.31,
      "learning_rate": 0.021701364472347266,
      "loss": 2.4446,
      "step": 487220
    },
    {
      "epoch": 783.34,
      "learning_rate": 0.021698149041479094,
      "loss": 2.4634,
      "step": 487240
    },
    {
      "epoch": 783.38,
      "learning_rate": 0.021694933610610936,
      "loss": 2.4622,
      "step": 487260
    },
    {
      "epoch": 783.41,
      "learning_rate": 0.021691718179742768,
      "loss": 2.4582,
      "step": 487280
    },
    {
      "epoch": 783.44,
      "learning_rate": 0.0216885027488746,
      "loss": 2.4529,
      "step": 487300
    },
    {
      "epoch": 783.47,
      "learning_rate": 0.02168528731800643,
      "loss": 2.4564,
      "step": 487320
    },
    {
      "epoch": 783.5,
      "learning_rate": 0.02168207188713826,
      "loss": 2.4573,
      "step": 487340
    },
    {
      "epoch": 783.54,
      "learning_rate": 0.02167885645627009,
      "loss": 2.4846,
      "step": 487360
    },
    {
      "epoch": 783.57,
      "learning_rate": 0.021675641025401933,
      "loss": 2.45,
      "step": 487380
    },
    {
      "epoch": 783.6,
      "learning_rate": 0.021672425594533765,
      "loss": 2.4596,
      "step": 487400
    },
    {
      "epoch": 783.63,
      "learning_rate": 0.021669210163665596,
      "loss": 2.4579,
      "step": 487420
    },
    {
      "epoch": 783.67,
      "learning_rate": 0.021665994732797424,
      "loss": 2.4641,
      "step": 487440
    },
    {
      "epoch": 783.7,
      "learning_rate": 0.021662779301929256,
      "loss": 2.4659,
      "step": 487460
    },
    {
      "epoch": 783.73,
      "learning_rate": 0.021659563871061088,
      "loss": 2.4569,
      "step": 487480
    },
    {
      "epoch": 783.76,
      "learning_rate": 0.02165634844019293,
      "loss": 2.4489,
      "step": 487500
    },
    {
      "epoch": 783.79,
      "learning_rate": 0.02165313300932476,
      "loss": 2.4605,
      "step": 487520
    },
    {
      "epoch": 783.83,
      "learning_rate": 0.021649917578456593,
      "loss": 2.4523,
      "step": 487540
    },
    {
      "epoch": 783.86,
      "learning_rate": 0.02164670214758842,
      "loss": 2.4654,
      "step": 487560
    },
    {
      "epoch": 783.89,
      "learning_rate": 0.021643486716720253,
      "loss": 2.445,
      "step": 487580
    },
    {
      "epoch": 783.92,
      "learning_rate": 0.021640271285852095,
      "loss": 2.4481,
      "step": 487600
    },
    {
      "epoch": 783.95,
      "learning_rate": 0.021637055854983926,
      "loss": 2.4727,
      "step": 487620
    },
    {
      "epoch": 783.99,
      "learning_rate": 0.021633840424115758,
      "loss": 2.4557,
      "step": 487640
    },
    {
      "epoch": 784.0,
      "eval_accuracy": {
        "accuracy": 0.4516831221332504
      },
      "eval_loss": 2.563884735107422,
      "eval_runtime": 3.3281,
      "eval_samples_per_second": 3864.942,
      "eval_steps_per_second": 60.394,
      "step": 487648
    },
    {
      "epoch": 784.02,
      "learning_rate": 0.021630624993247586,
      "loss": 2.4726,
      "step": 487660
    },
    {
      "epoch": 784.05,
      "learning_rate": 0.021627409562379418,
      "loss": 2.4486,
      "step": 487680
    },
    {
      "epoch": 784.08,
      "learning_rate": 0.02162419413151125,
      "loss": 2.4487,
      "step": 487700
    },
    {
      "epoch": 784.12,
      "learning_rate": 0.02162097870064309,
      "loss": 2.4587,
      "step": 487720
    },
    {
      "epoch": 784.15,
      "learning_rate": 0.021617763269774923,
      "loss": 2.4614,
      "step": 487740
    },
    {
      "epoch": 784.18,
      "learning_rate": 0.021614547838906754,
      "loss": 2.4616,
      "step": 487760
    },
    {
      "epoch": 784.21,
      "learning_rate": 0.021611332408038583,
      "loss": 2.4461,
      "step": 487780
    },
    {
      "epoch": 784.24,
      "learning_rate": 0.021608116977170414,
      "loss": 2.4324,
      "step": 487800
    },
    {
      "epoch": 784.28,
      "learning_rate": 0.021604901546302256,
      "loss": 2.4568,
      "step": 487820
    },
    {
      "epoch": 784.31,
      "learning_rate": 0.021601686115434088,
      "loss": 2.4333,
      "step": 487840
    },
    {
      "epoch": 784.34,
      "learning_rate": 0.02159847068456592,
      "loss": 2.448,
      "step": 487860
    },
    {
      "epoch": 784.37,
      "learning_rate": 0.021595255253697748,
      "loss": 2.4511,
      "step": 487880
    },
    {
      "epoch": 784.41,
      "learning_rate": 0.02159203982282958,
      "loss": 2.4331,
      "step": 487900
    },
    {
      "epoch": 784.44,
      "learning_rate": 0.02158882439196141,
      "loss": 2.4426,
      "step": 487920
    },
    {
      "epoch": 784.47,
      "learning_rate": 0.021585608961093253,
      "loss": 2.4491,
      "step": 487940
    },
    {
      "epoch": 784.5,
      "learning_rate": 0.021582393530225084,
      "loss": 2.4492,
      "step": 487960
    },
    {
      "epoch": 784.53,
      "learning_rate": 0.021579178099356913,
      "loss": 2.4523,
      "step": 487980
    },
    {
      "epoch": 784.57,
      "learning_rate": 0.021575962668488744,
      "loss": 2.4548,
      "step": 488000
    },
    {
      "epoch": 784.6,
      "learning_rate": 0.021572747237620576,
      "loss": 2.4439,
      "step": 488020
    },
    {
      "epoch": 784.63,
      "learning_rate": 0.021569531806752407,
      "loss": 2.4712,
      "step": 488040
    },
    {
      "epoch": 784.66,
      "learning_rate": 0.02156631637588425,
      "loss": 2.4576,
      "step": 488060
    },
    {
      "epoch": 784.69,
      "learning_rate": 0.02156310094501608,
      "loss": 2.468,
      "step": 488080
    },
    {
      "epoch": 784.73,
      "learning_rate": 0.02155988551414791,
      "loss": 2.4584,
      "step": 488100
    },
    {
      "epoch": 784.76,
      "learning_rate": 0.02155667008327974,
      "loss": 2.4528,
      "step": 488120
    },
    {
      "epoch": 784.79,
      "learning_rate": 0.021553454652411572,
      "loss": 2.4702,
      "step": 488140
    },
    {
      "epoch": 784.82,
      "learning_rate": 0.021550239221543414,
      "loss": 2.4526,
      "step": 488160
    },
    {
      "epoch": 784.86,
      "learning_rate": 0.021547023790675246,
      "loss": 2.4567,
      "step": 488180
    },
    {
      "epoch": 784.89,
      "learning_rate": 0.021543808359807074,
      "loss": 2.4626,
      "step": 488200
    },
    {
      "epoch": 784.92,
      "learning_rate": 0.021540592928938906,
      "loss": 2.454,
      "step": 488220
    },
    {
      "epoch": 784.95,
      "learning_rate": 0.021537377498070737,
      "loss": 2.4537,
      "step": 488240
    },
    {
      "epoch": 784.98,
      "learning_rate": 0.02153416206720257,
      "loss": 2.4621,
      "step": 488260
    },
    {
      "epoch": 785.0,
      "eval_accuracy": {
        "accuracy": 0.4479514887662287
      },
      "eval_loss": 2.577207088470459,
      "eval_runtime": 3.3693,
      "eval_samples_per_second": 3817.716,
      "eval_steps_per_second": 59.656,
      "step": 488270
    },
    {
      "epoch": 785.02,
      "learning_rate": 0.02153094663633441,
      "loss": 2.4643,
      "step": 488280
    },
    {
      "epoch": 785.05,
      "learning_rate": 0.02152773120546624,
      "loss": 2.4398,
      "step": 488300
    },
    {
      "epoch": 785.08,
      "learning_rate": 0.02152451577459807,
      "loss": 2.4618,
      "step": 488320
    },
    {
      "epoch": 785.11,
      "learning_rate": 0.021521300343729902,
      "loss": 2.448,
      "step": 488340
    },
    {
      "epoch": 785.14,
      "learning_rate": 0.021518084912861734,
      "loss": 2.4378,
      "step": 488360
    },
    {
      "epoch": 785.18,
      "learning_rate": 0.021514869481993566,
      "loss": 2.473,
      "step": 488380
    },
    {
      "epoch": 785.21,
      "learning_rate": 0.021511654051125408,
      "loss": 2.4402,
      "step": 488400
    },
    {
      "epoch": 785.24,
      "learning_rate": 0.021508438620257236,
      "loss": 2.4463,
      "step": 488420
    },
    {
      "epoch": 785.27,
      "learning_rate": 0.021505223189389067,
      "loss": 2.4417,
      "step": 488440
    },
    {
      "epoch": 785.31,
      "learning_rate": 0.0215020077585209,
      "loss": 2.4418,
      "step": 488460
    },
    {
      "epoch": 785.34,
      "learning_rate": 0.02149879232765273,
      "loss": 2.4585,
      "step": 488480
    },
    {
      "epoch": 785.37,
      "learning_rate": 0.021495576896784573,
      "loss": 2.4773,
      "step": 488500
    },
    {
      "epoch": 785.4,
      "learning_rate": 0.0214923614659164,
      "loss": 2.4672,
      "step": 488520
    },
    {
      "epoch": 785.43,
      "learning_rate": 0.021489146035048232,
      "loss": 2.4802,
      "step": 488540
    },
    {
      "epoch": 785.47,
      "learning_rate": 0.021485930604180064,
      "loss": 2.4658,
      "step": 488560
    },
    {
      "epoch": 785.5,
      "learning_rate": 0.021482715173311896,
      "loss": 2.4373,
      "step": 488580
    },
    {
      "epoch": 785.53,
      "learning_rate": 0.021479499742443724,
      "loss": 2.4454,
      "step": 488600
    },
    {
      "epoch": 785.56,
      "learning_rate": 0.021476284311575566,
      "loss": 2.4517,
      "step": 488620
    },
    {
      "epoch": 785.59,
      "learning_rate": 0.021473068880707397,
      "loss": 2.4479,
      "step": 488640
    },
    {
      "epoch": 785.63,
      "learning_rate": 0.02146985344983923,
      "loss": 2.4428,
      "step": 488660
    },
    {
      "epoch": 785.66,
      "learning_rate": 0.02146663801897106,
      "loss": 2.4757,
      "step": 488680
    },
    {
      "epoch": 785.69,
      "learning_rate": 0.021463422588102892,
      "loss": 2.4506,
      "step": 488700
    },
    {
      "epoch": 785.72,
      "learning_rate": 0.02146020715723472,
      "loss": 2.4412,
      "step": 488720
    },
    {
      "epoch": 785.76,
      "learning_rate": 0.021456991726366562,
      "loss": 2.4473,
      "step": 488740
    },
    {
      "epoch": 785.79,
      "learning_rate": 0.021453776295498394,
      "loss": 2.4577,
      "step": 488760
    },
    {
      "epoch": 785.82,
      "learning_rate": 0.021450560864630226,
      "loss": 2.4423,
      "step": 488780
    },
    {
      "epoch": 785.85,
      "learning_rate": 0.021447345433762057,
      "loss": 2.4503,
      "step": 488800
    },
    {
      "epoch": 785.88,
      "learning_rate": 0.021444130002893885,
      "loss": 2.4548,
      "step": 488820
    },
    {
      "epoch": 785.92,
      "learning_rate": 0.021440914572025727,
      "loss": 2.4325,
      "step": 488840
    },
    {
      "epoch": 785.95,
      "learning_rate": 0.02143769914115756,
      "loss": 2.4213,
      "step": 488860
    },
    {
      "epoch": 785.98,
      "learning_rate": 0.02143448371028939,
      "loss": 2.4544,
      "step": 488880
    },
    {
      "epoch": 786.0,
      "eval_accuracy": {
        "accuracy": 0.4528492575604447
      },
      "eval_loss": 2.5660247802734375,
      "eval_runtime": 2.9741,
      "eval_samples_per_second": 4325.055,
      "eval_steps_per_second": 67.584,
      "step": 488892
    },
    {
      "epoch": 786.01,
      "learning_rate": 0.021431268279421222,
      "loss": 2.4524,
      "step": 488900
    },
    {
      "epoch": 786.05,
      "learning_rate": 0.02142805284855305,
      "loss": 2.4309,
      "step": 488920
    },
    {
      "epoch": 786.08,
      "learning_rate": 0.021424837417684882,
      "loss": 2.4575,
      "step": 488940
    },
    {
      "epoch": 786.11,
      "learning_rate": 0.021421621986816724,
      "loss": 2.4474,
      "step": 488960
    },
    {
      "epoch": 786.14,
      "learning_rate": 0.021418406555948555,
      "loss": 2.4262,
      "step": 488980
    },
    {
      "epoch": 786.17,
      "learning_rate": 0.021415191125080387,
      "loss": 2.4621,
      "step": 489000
    },
    {
      "epoch": 786.21,
      "learning_rate": 0.02141197569421222,
      "loss": 2.4701,
      "step": 489020
    },
    {
      "epoch": 786.24,
      "learning_rate": 0.021408760263344047,
      "loss": 2.4532,
      "step": 489040
    },
    {
      "epoch": 786.27,
      "learning_rate": 0.02140554483247588,
      "loss": 2.45,
      "step": 489060
    },
    {
      "epoch": 786.3,
      "learning_rate": 0.02140232940160772,
      "loss": 2.4628,
      "step": 489080
    },
    {
      "epoch": 786.33,
      "learning_rate": 0.021399113970739552,
      "loss": 2.4386,
      "step": 489100
    },
    {
      "epoch": 786.37,
      "learning_rate": 0.021395898539871384,
      "loss": 2.469,
      "step": 489120
    },
    {
      "epoch": 786.4,
      "learning_rate": 0.021392683109003212,
      "loss": 2.4507,
      "step": 489140
    },
    {
      "epoch": 786.43,
      "learning_rate": 0.021389467678135043,
      "loss": 2.4518,
      "step": 489160
    },
    {
      "epoch": 786.46,
      "learning_rate": 0.021386252247266885,
      "loss": 2.442,
      "step": 489180
    },
    {
      "epoch": 786.5,
      "learning_rate": 0.021383036816398717,
      "loss": 2.4542,
      "step": 489200
    },
    {
      "epoch": 786.53,
      "learning_rate": 0.02137982138553055,
      "loss": 2.4735,
      "step": 489220
    },
    {
      "epoch": 786.56,
      "learning_rate": 0.021376605954662377,
      "loss": 2.4671,
      "step": 489240
    },
    {
      "epoch": 786.59,
      "learning_rate": 0.02137339052379421,
      "loss": 2.4669,
      "step": 489260
    },
    {
      "epoch": 786.62,
      "learning_rate": 0.02137017509292604,
      "loss": 2.4406,
      "step": 489280
    },
    {
      "epoch": 786.66,
      "learning_rate": 0.021366959662057882,
      "loss": 2.4689,
      "step": 489300
    },
    {
      "epoch": 786.69,
      "learning_rate": 0.021363744231189714,
      "loss": 2.4587,
      "step": 489320
    },
    {
      "epoch": 786.72,
      "learning_rate": 0.021360528800321545,
      "loss": 2.4615,
      "step": 489340
    },
    {
      "epoch": 786.75,
      "learning_rate": 0.021357313369453373,
      "loss": 2.456,
      "step": 489360
    },
    {
      "epoch": 786.78,
      "learning_rate": 0.021354097938585205,
      "loss": 2.4625,
      "step": 489380
    },
    {
      "epoch": 786.82,
      "learning_rate": 0.021350882507717037,
      "loss": 2.4629,
      "step": 489400
    },
    {
      "epoch": 786.85,
      "learning_rate": 0.02134766707684888,
      "loss": 2.4413,
      "step": 489420
    },
    {
      "epoch": 786.88,
      "learning_rate": 0.02134445164598071,
      "loss": 2.4447,
      "step": 489440
    },
    {
      "epoch": 786.91,
      "learning_rate": 0.02134123621511254,
      "loss": 2.4357,
      "step": 489460
    },
    {
      "epoch": 786.95,
      "learning_rate": 0.02133802078424437,
      "loss": 2.4577,
      "step": 489480
    },
    {
      "epoch": 786.98,
      "learning_rate": 0.0213348053533762,
      "loss": 2.4399,
      "step": 489500
    },
    {
      "epoch": 787.0,
      "eval_accuracy": {
        "accuracy": 0.4530047422840706
      },
      "eval_loss": 2.5670831203460693,
      "eval_runtime": 3.3979,
      "eval_samples_per_second": 3785.524,
      "eval_steps_per_second": 59.153,
      "step": 489514
    },
    {
      "epoch": 787.01,
      "learning_rate": 0.021331589922508044,
      "loss": 2.4363,
      "step": 489520
    },
    {
      "epoch": 787.04,
      "learning_rate": 0.021328374491639875,
      "loss": 2.4586,
      "step": 489540
    },
    {
      "epoch": 787.07,
      "learning_rate": 0.021325159060771703,
      "loss": 2.4517,
      "step": 489560
    },
    {
      "epoch": 787.11,
      "learning_rate": 0.021321943629903535,
      "loss": 2.4497,
      "step": 489580
    },
    {
      "epoch": 787.14,
      "learning_rate": 0.021318728199035367,
      "loss": 2.4503,
      "step": 489600
    },
    {
      "epoch": 787.17,
      "learning_rate": 0.021315512768167198,
      "loss": 2.4522,
      "step": 489620
    },
    {
      "epoch": 787.2,
      "learning_rate": 0.02131229733729904,
      "loss": 2.4467,
      "step": 489640
    },
    {
      "epoch": 787.23,
      "learning_rate": 0.021309081906430872,
      "loss": 2.4481,
      "step": 489660
    },
    {
      "epoch": 787.27,
      "learning_rate": 0.0213058664755627,
      "loss": 2.4355,
      "step": 489680
    },
    {
      "epoch": 787.3,
      "learning_rate": 0.02130265104469453,
      "loss": 2.4466,
      "step": 489700
    },
    {
      "epoch": 787.33,
      "learning_rate": 0.021299435613826363,
      "loss": 2.4534,
      "step": 489720
    },
    {
      "epoch": 787.36,
      "learning_rate": 0.021296220182958205,
      "loss": 2.4608,
      "step": 489740
    },
    {
      "epoch": 787.4,
      "learning_rate": 0.021293004752090037,
      "loss": 2.4536,
      "step": 489760
    },
    {
      "epoch": 787.43,
      "learning_rate": 0.021289950092765277,
      "loss": 2.4441,
      "step": 489780
    },
    {
      "epoch": 787.46,
      "learning_rate": 0.021286734661897108,
      "loss": 2.4345,
      "step": 489800
    },
    {
      "epoch": 787.49,
      "learning_rate": 0.02128351923102894,
      "loss": 2.4397,
      "step": 489820
    },
    {
      "epoch": 787.52,
      "learning_rate": 0.02128030380016077,
      "loss": 2.4207,
      "step": 489840
    },
    {
      "epoch": 787.56,
      "learning_rate": 0.0212770883692926,
      "loss": 2.441,
      "step": 489860
    },
    {
      "epoch": 787.59,
      "learning_rate": 0.02127387293842443,
      "loss": 2.4706,
      "step": 489880
    },
    {
      "epoch": 787.62,
      "learning_rate": 0.021270657507556273,
      "loss": 2.4565,
      "step": 489900
    },
    {
      "epoch": 787.65,
      "learning_rate": 0.021267442076688105,
      "loss": 2.4575,
      "step": 489920
    },
    {
      "epoch": 787.68,
      "learning_rate": 0.021264226645819936,
      "loss": 2.4775,
      "step": 489940
    },
    {
      "epoch": 787.72,
      "learning_rate": 0.021261011214951768,
      "loss": 2.4528,
      "step": 489960
    },
    {
      "epoch": 787.75,
      "learning_rate": 0.021257795784083596,
      "loss": 2.4634,
      "step": 489980
    },
    {
      "epoch": 787.78,
      "learning_rate": 0.021254580353215438,
      "loss": 2.4483,
      "step": 490000
    },
    {
      "epoch": 787.81,
      "learning_rate": 0.02125136492234727,
      "loss": 2.4804,
      "step": 490020
    },
    {
      "epoch": 787.85,
      "learning_rate": 0.0212481494914791,
      "loss": 2.4576,
      "step": 490040
    },
    {
      "epoch": 787.88,
      "learning_rate": 0.021244934060610933,
      "loss": 2.4443,
      "step": 490060
    },
    {
      "epoch": 787.91,
      "learning_rate": 0.02124171862974276,
      "loss": 2.4378,
      "step": 490080
    },
    {
      "epoch": 787.94,
      "learning_rate": 0.021238503198874593,
      "loss": 2.4455,
      "step": 490100
    },
    {
      "epoch": 787.97,
      "learning_rate": 0.021235287768006435,
      "loss": 2.4551,
      "step": 490120
    },
    {
      "epoch": 788.0,
      "eval_accuracy": {
        "accuracy": 0.4479514887662287
      },
      "eval_loss": 2.5760538578033447,
      "eval_runtime": 3.0699,
      "eval_samples_per_second": 4190.039,
      "eval_steps_per_second": 65.474,
      "step": 490136
    },
    {
      "epoch": 788.01,
      "learning_rate": 0.021232072337138266,
      "loss": 2.4577,
      "step": 490140
    },
    {
      "epoch": 788.04,
      "learning_rate": 0.021228856906270098,
      "loss": 2.4592,
      "step": 490160
    },
    {
      "epoch": 788.07,
      "learning_rate": 0.021225641475401926,
      "loss": 2.4456,
      "step": 490180
    },
    {
      "epoch": 788.1,
      "learning_rate": 0.021222426044533758,
      "loss": 2.4508,
      "step": 490200
    },
    {
      "epoch": 788.14,
      "learning_rate": 0.0212192106136656,
      "loss": 2.4532,
      "step": 490220
    },
    {
      "epoch": 788.17,
      "learning_rate": 0.02121599518279743,
      "loss": 2.4405,
      "step": 490240
    },
    {
      "epoch": 788.2,
      "learning_rate": 0.021212779751929263,
      "loss": 2.4594,
      "step": 490260
    },
    {
      "epoch": 788.23,
      "learning_rate": 0.021209564321061095,
      "loss": 2.4498,
      "step": 490280
    },
    {
      "epoch": 788.26,
      "learning_rate": 0.021206348890192923,
      "loss": 2.4471,
      "step": 490300
    },
    {
      "epoch": 788.3,
      "learning_rate": 0.021203133459324754,
      "loss": 2.4431,
      "step": 490320
    },
    {
      "epoch": 788.33,
      "learning_rate": 0.021199918028456596,
      "loss": 2.4588,
      "step": 490340
    },
    {
      "epoch": 788.36,
      "learning_rate": 0.021196702597588428,
      "loss": 2.4367,
      "step": 490360
    },
    {
      "epoch": 788.39,
      "learning_rate": 0.02119348716672026,
      "loss": 2.4599,
      "step": 490380
    },
    {
      "epoch": 788.42,
      "learning_rate": 0.021190271735852088,
      "loss": 2.4666,
      "step": 490400
    },
    {
      "epoch": 788.46,
      "learning_rate": 0.02118705630498392,
      "loss": 2.4406,
      "step": 490420
    },
    {
      "epoch": 788.49,
      "learning_rate": 0.02118384087411575,
      "loss": 2.4583,
      "step": 490440
    },
    {
      "epoch": 788.52,
      "learning_rate": 0.021180625443247593,
      "loss": 2.4445,
      "step": 490460
    },
    {
      "epoch": 788.55,
      "learning_rate": 0.021177410012379425,
      "loss": 2.4542,
      "step": 490480
    },
    {
      "epoch": 788.59,
      "learning_rate": 0.021174194581511253,
      "loss": 2.4524,
      "step": 490500
    },
    {
      "epoch": 788.62,
      "learning_rate": 0.021170979150643084,
      "loss": 2.436,
      "step": 490520
    },
    {
      "epoch": 788.65,
      "learning_rate": 0.021167763719774916,
      "loss": 2.4513,
      "step": 490540
    },
    {
      "epoch": 788.68,
      "learning_rate": 0.021164548288906758,
      "loss": 2.4656,
      "step": 490560
    },
    {
      "epoch": 788.71,
      "learning_rate": 0.02116133285803859,
      "loss": 2.4463,
      "step": 490580
    },
    {
      "epoch": 788.75,
      "learning_rate": 0.02115811742717042,
      "loss": 2.4453,
      "step": 490600
    },
    {
      "epoch": 788.78,
      "learning_rate": 0.02115490199630225,
      "loss": 2.4249,
      "step": 490620
    },
    {
      "epoch": 788.81,
      "learning_rate": 0.02115168656543408,
      "loss": 2.4509,
      "step": 490640
    },
    {
      "epoch": 788.84,
      "learning_rate": 0.021148471134565913,
      "loss": 2.4612,
      "step": 490660
    },
    {
      "epoch": 788.87,
      "learning_rate": 0.021145255703697755,
      "loss": 2.4483,
      "step": 490680
    },
    {
      "epoch": 788.91,
      "learning_rate": 0.021142040272829586,
      "loss": 2.442,
      "step": 490700
    },
    {
      "epoch": 788.94,
      "learning_rate": 0.021138824841961414,
      "loss": 2.4461,
      "step": 490720
    },
    {
      "epoch": 788.97,
      "learning_rate": 0.021135609411093246,
      "loss": 2.4452,
      "step": 490740
    },
    {
      "epoch": 789.0,
      "eval_accuracy": {
        "accuracy": 0.44678535333903446
      },
      "eval_loss": 2.578585386276245,
      "eval_runtime": 3.1444,
      "eval_samples_per_second": 4090.825,
      "eval_steps_per_second": 63.924,
      "step": 490758
    },
    {
      "epoch": 789.0,
      "learning_rate": 0.021132393980225078,
      "loss": 2.4565,
      "step": 490760
    },
    {
      "epoch": 789.04,
      "learning_rate": 0.02112917854935691,
      "loss": 2.4593,
      "step": 490780
    },
    {
      "epoch": 789.07,
      "learning_rate": 0.02112596311848875,
      "loss": 2.4418,
      "step": 490800
    },
    {
      "epoch": 789.1,
      "learning_rate": 0.02112274768762058,
      "loss": 2.4704,
      "step": 490820
    },
    {
      "epoch": 789.13,
      "learning_rate": 0.02111953225675241,
      "loss": 2.4595,
      "step": 490840
    },
    {
      "epoch": 789.16,
      "learning_rate": 0.021116316825884242,
      "loss": 2.4278,
      "step": 490860
    },
    {
      "epoch": 789.2,
      "learning_rate": 0.021113101395016074,
      "loss": 2.4263,
      "step": 490880
    },
    {
      "epoch": 789.23,
      "learning_rate": 0.021109885964147916,
      "loss": 2.452,
      "step": 490900
    },
    {
      "epoch": 789.26,
      "learning_rate": 0.021106670533279748,
      "loss": 2.4382,
      "step": 490920
    },
    {
      "epoch": 789.29,
      "learning_rate": 0.021103455102411576,
      "loss": 2.4576,
      "step": 490940
    },
    {
      "epoch": 789.32,
      "learning_rate": 0.021100239671543407,
      "loss": 2.4362,
      "step": 490960
    },
    {
      "epoch": 789.36,
      "learning_rate": 0.02109702424067524,
      "loss": 2.4624,
      "step": 490980
    },
    {
      "epoch": 789.39,
      "learning_rate": 0.02109380880980707,
      "loss": 2.4404,
      "step": 491000
    },
    {
      "epoch": 789.42,
      "learning_rate": 0.021090593378938913,
      "loss": 2.4606,
      "step": 491020
    },
    {
      "epoch": 789.45,
      "learning_rate": 0.02108737794807074,
      "loss": 2.4637,
      "step": 491040
    },
    {
      "epoch": 789.49,
      "learning_rate": 0.021084162517202572,
      "loss": 2.4308,
      "step": 491060
    },
    {
      "epoch": 789.52,
      "learning_rate": 0.021080947086334404,
      "loss": 2.4452,
      "step": 491080
    },
    {
      "epoch": 789.55,
      "learning_rate": 0.021077731655466236,
      "loss": 2.4593,
      "step": 491100
    },
    {
      "epoch": 789.58,
      "learning_rate": 0.021074516224598064,
      "loss": 2.4323,
      "step": 491120
    },
    {
      "epoch": 789.61,
      "learning_rate": 0.021071300793729906,
      "loss": 2.4483,
      "step": 491140
    },
    {
      "epoch": 789.65,
      "learning_rate": 0.021068085362861737,
      "loss": 2.4367,
      "step": 491160
    },
    {
      "epoch": 789.68,
      "learning_rate": 0.02106486993199357,
      "loss": 2.4362,
      "step": 491180
    },
    {
      "epoch": 789.71,
      "learning_rate": 0.0210616545011254,
      "loss": 2.4505,
      "step": 491200
    },
    {
      "epoch": 789.74,
      "learning_rate": 0.021058439070257232,
      "loss": 2.4603,
      "step": 491220
    },
    {
      "epoch": 789.77,
      "learning_rate": 0.021055223639389074,
      "loss": 2.4579,
      "step": 491240
    },
    {
      "epoch": 789.81,
      "learning_rate": 0.021052008208520902,
      "loss": 2.4543,
      "step": 491260
    },
    {
      "epoch": 789.84,
      "learning_rate": 0.021048792777652734,
      "loss": 2.4519,
      "step": 491280
    },
    {
      "epoch": 789.87,
      "learning_rate": 0.021045577346784566,
      "loss": 2.4628,
      "step": 491300
    },
    {
      "epoch": 789.9,
      "learning_rate": 0.021042361915916397,
      "loss": 2.4668,
      "step": 491320
    },
    {
      "epoch": 789.94,
      "learning_rate": 0.021039146485048225,
      "loss": 2.4555,
      "step": 491340
    },
    {
      "epoch": 789.97,
      "learning_rate": 0.021035931054180067,
      "loss": 2.4551,
      "step": 491360
    },
    {
      "epoch": 790.0,
      "learning_rate": 0.0210327156233119,
      "loss": 2.4623,
      "step": 491380
    },
    {
      "epoch": 790.0,
      "eval_accuracy": {
        "accuracy": 0.44872891238435825
      },
      "eval_loss": 2.5983188152313232,
      "eval_runtime": 3.2995,
      "eval_samples_per_second": 3898.503,
      "eval_steps_per_second": 60.919,
      "step": 491380
    },
    {
      "epoch": 790.03,
      "learning_rate": 0.02102950019244373,
      "loss": 2.4502,
      "step": 491400
    },
    {
      "epoch": 790.06,
      "learning_rate": 0.021026284761575562,
      "loss": 2.4427,
      "step": 491420
    },
    {
      "epoch": 790.1,
      "learning_rate": 0.02102306933070739,
      "loss": 2.4417,
      "step": 491440
    },
    {
      "epoch": 790.13,
      "learning_rate": 0.021019853899839222,
      "loss": 2.4677,
      "step": 491460
    },
    {
      "epoch": 790.16,
      "learning_rate": 0.021016638468971064,
      "loss": 2.4582,
      "step": 491480
    },
    {
      "epoch": 790.19,
      "learning_rate": 0.021013423038102896,
      "loss": 2.4394,
      "step": 491500
    },
    {
      "epoch": 790.23,
      "learning_rate": 0.021010207607234727,
      "loss": 2.4563,
      "step": 491520
    },
    {
      "epoch": 790.26,
      "learning_rate": 0.02100699217636656,
      "loss": 2.4548,
      "step": 491540
    },
    {
      "epoch": 790.29,
      "learning_rate": 0.021003776745498387,
      "loss": 2.444,
      "step": 491560
    },
    {
      "epoch": 790.32,
      "learning_rate": 0.02100056131463023,
      "loss": 2.4556,
      "step": 491580
    },
    {
      "epoch": 790.35,
      "learning_rate": 0.02099734588376206,
      "loss": 2.4495,
      "step": 491600
    },
    {
      "epoch": 790.39,
      "learning_rate": 0.020994130452893892,
      "loss": 2.4481,
      "step": 491620
    },
    {
      "epoch": 790.42,
      "learning_rate": 0.020990915022025724,
      "loss": 2.454,
      "step": 491640
    },
    {
      "epoch": 790.45,
      "learning_rate": 0.020987699591157552,
      "loss": 2.4421,
      "step": 491660
    },
    {
      "epoch": 790.48,
      "learning_rate": 0.020984484160289384,
      "loss": 2.4343,
      "step": 491680
    },
    {
      "epoch": 790.51,
      "learning_rate": 0.020981268729421226,
      "loss": 2.4602,
      "step": 491700
    },
    {
      "epoch": 790.55,
      "learning_rate": 0.020978053298553057,
      "loss": 2.4648,
      "step": 491720
    },
    {
      "epoch": 790.58,
      "learning_rate": 0.02097483786768489,
      "loss": 2.4387,
      "step": 491740
    },
    {
      "epoch": 790.61,
      "learning_rate": 0.020971622436816717,
      "loss": 2.4496,
      "step": 491760
    },
    {
      "epoch": 790.64,
      "learning_rate": 0.02096840700594855,
      "loss": 2.4643,
      "step": 491780
    },
    {
      "epoch": 790.68,
      "learning_rate": 0.02096519157508038,
      "loss": 2.4519,
      "step": 491800
    },
    {
      "epoch": 790.71,
      "learning_rate": 0.020961976144212222,
      "loss": 2.4112,
      "step": 491820
    },
    {
      "epoch": 790.74,
      "learning_rate": 0.020958921484887465,
      "loss": 2.4532,
      "step": 491840
    },
    {
      "epoch": 790.77,
      "learning_rate": 0.020955706054019294,
      "loss": 2.4737,
      "step": 491860
    },
    {
      "epoch": 790.8,
      "learning_rate": 0.020952490623151125,
      "loss": 2.4582,
      "step": 491880
    },
    {
      "epoch": 790.84,
      "learning_rate": 0.020949275192282957,
      "loss": 2.4421,
      "step": 491900
    },
    {
      "epoch": 790.87,
      "learning_rate": 0.02094605976141479,
      "loss": 2.4582,
      "step": 491920
    },
    {
      "epoch": 790.9,
      "learning_rate": 0.02094284433054662,
      "loss": 2.441,
      "step": 491940
    },
    {
      "epoch": 790.93,
      "learning_rate": 0.020939628899678462,
      "loss": 2.4494,
      "step": 491960
    },
    {
      "epoch": 790.96,
      "learning_rate": 0.02093641346881029,
      "loss": 2.4592,
      "step": 491980
    },
    {
      "epoch": 791.0,
      "learning_rate": 0.020933198037942122,
      "loss": 2.4295,
      "step": 492000
    },
    {
      "epoch": 791.0,
      "eval_accuracy": {
        "accuracy": 0.45696960273653114
      },
      "eval_loss": 2.549828052520752,
      "eval_runtime": 3.197,
      "eval_samples_per_second": 4023.507,
      "eval_steps_per_second": 62.872,
      "step": 492002
    },
    {
      "epoch": 791.03,
      "learning_rate": 0.020929982607073953,
      "loss": 2.4527,
      "step": 492020
    },
    {
      "epoch": 791.06,
      "learning_rate": 0.020926767176205785,
      "loss": 2.4312,
      "step": 492040
    },
    {
      "epoch": 791.09,
      "learning_rate": 0.020923551745337627,
      "loss": 2.4514,
      "step": 492060
    },
    {
      "epoch": 791.13,
      "learning_rate": 0.020920336314469455,
      "loss": 2.4326,
      "step": 492080
    },
    {
      "epoch": 791.16,
      "learning_rate": 0.020917120883601287,
      "loss": 2.4616,
      "step": 492100
    },
    {
      "epoch": 791.19,
      "learning_rate": 0.02091390545273312,
      "loss": 2.47,
      "step": 492120
    },
    {
      "epoch": 791.22,
      "learning_rate": 0.02091069002186495,
      "loss": 2.4732,
      "step": 492140
    },
    {
      "epoch": 791.25,
      "learning_rate": 0.02090747459099678,
      "loss": 2.4192,
      "step": 492160
    },
    {
      "epoch": 791.29,
      "learning_rate": 0.02090425916012862,
      "loss": 2.4421,
      "step": 492180
    },
    {
      "epoch": 791.32,
      "learning_rate": 0.02090104372926045,
      "loss": 2.455,
      "step": 492200
    },
    {
      "epoch": 791.35,
      "learning_rate": 0.020897828298392283,
      "loss": 2.4532,
      "step": 492220
    },
    {
      "epoch": 791.38,
      "learning_rate": 0.020894612867524115,
      "loss": 2.4539,
      "step": 492240
    },
    {
      "epoch": 791.41,
      "learning_rate": 0.020891397436655947,
      "loss": 2.4517,
      "step": 492260
    },
    {
      "epoch": 791.45,
      "learning_rate": 0.020888182005787775,
      "loss": 2.463,
      "step": 492280
    },
    {
      "epoch": 791.48,
      "learning_rate": 0.020884966574919617,
      "loss": 2.4411,
      "step": 492300
    },
    {
      "epoch": 791.51,
      "learning_rate": 0.02088175114405145,
      "loss": 2.4624,
      "step": 492320
    },
    {
      "epoch": 791.54,
      "learning_rate": 0.02087853571318328,
      "loss": 2.4452,
      "step": 492340
    },
    {
      "epoch": 791.58,
      "learning_rate": 0.02087532028231511,
      "loss": 2.4455,
      "step": 492360
    },
    {
      "epoch": 791.61,
      "learning_rate": 0.02087210485144694,
      "loss": 2.4425,
      "step": 492380
    },
    {
      "epoch": 791.64,
      "learning_rate": 0.02086888942057878,
      "loss": 2.4455,
      "step": 492400
    },
    {
      "epoch": 791.67,
      "learning_rate": 0.020865673989710613,
      "loss": 2.4527,
      "step": 492420
    },
    {
      "epoch": 791.7,
      "learning_rate": 0.020862458558842445,
      "loss": 2.4604,
      "step": 492440
    },
    {
      "epoch": 791.74,
      "learning_rate": 0.020859243127974277,
      "loss": 2.452,
      "step": 492460
    },
    {
      "epoch": 791.77,
      "learning_rate": 0.020856027697106108,
      "loss": 2.4338,
      "step": 492480
    },
    {
      "epoch": 791.8,
      "learning_rate": 0.020852812266237936,
      "loss": 2.4392,
      "step": 492500
    },
    {
      "epoch": 791.83,
      "learning_rate": 0.02084959683536978,
      "loss": 2.4332,
      "step": 492520
    },
    {
      "epoch": 791.86,
      "learning_rate": 0.02084638140450161,
      "loss": 2.4362,
      "step": 492540
    },
    {
      "epoch": 791.9,
      "learning_rate": 0.02084316597363344,
      "loss": 2.4359,
      "step": 492560
    },
    {
      "epoch": 791.93,
      "learning_rate": 0.020839950542765273,
      "loss": 2.4517,
      "step": 492580
    },
    {
      "epoch": 791.96,
      "learning_rate": 0.0208367351118971,
      "loss": 2.4497,
      "step": 492600
    },
    {
      "epoch": 791.99,
      "learning_rate": 0.020833519681028933,
      "loss": 2.4444,
      "step": 492620
    },
    {
      "epoch": 792.0,
      "eval_accuracy": {
        "accuracy": 0.45059472906786907
      },
      "eval_loss": 2.5733747482299805,
      "eval_runtime": 4.1634,
      "eval_samples_per_second": 3089.567,
      "eval_steps_per_second": 48.278,
      "step": 492624
    },
    {
      "epoch": 792.03,
      "learning_rate": 0.020830304250160775,
      "loss": 2.4417,
      "step": 492640
    },
    {
      "epoch": 792.06,
      "learning_rate": 0.020827088819292607,
      "loss": 2.4633,
      "step": 492660
    },
    {
      "epoch": 792.09,
      "learning_rate": 0.020823873388424438,
      "loss": 2.4461,
      "step": 492680
    },
    {
      "epoch": 792.12,
      "learning_rate": 0.020820657957556266,
      "loss": 2.4499,
      "step": 492700
    },
    {
      "epoch": 792.15,
      "learning_rate": 0.020817442526688098,
      "loss": 2.4326,
      "step": 492720
    },
    {
      "epoch": 792.19,
      "learning_rate": 0.02081422709581994,
      "loss": 2.4374,
      "step": 492740
    },
    {
      "epoch": 792.22,
      "learning_rate": 0.02081101166495177,
      "loss": 2.4289,
      "step": 492760
    },
    {
      "epoch": 792.25,
      "learning_rate": 0.020807796234083603,
      "loss": 2.457,
      "step": 492780
    },
    {
      "epoch": 792.28,
      "learning_rate": 0.020804580803215435,
      "loss": 2.4538,
      "step": 492800
    },
    {
      "epoch": 792.32,
      "learning_rate": 0.020801365372347263,
      "loss": 2.4348,
      "step": 492820
    },
    {
      "epoch": 792.35,
      "learning_rate": 0.020798149941479094,
      "loss": 2.4541,
      "step": 492840
    },
    {
      "epoch": 792.38,
      "learning_rate": 0.020794934510610937,
      "loss": 2.434,
      "step": 492860
    },
    {
      "epoch": 792.41,
      "learning_rate": 0.020791719079742768,
      "loss": 2.4536,
      "step": 492880
    },
    {
      "epoch": 792.44,
      "learning_rate": 0.0207885036488746,
      "loss": 2.4359,
      "step": 492900
    },
    {
      "epoch": 792.48,
      "learning_rate": 0.020785288218006428,
      "loss": 2.4808,
      "step": 492920
    },
    {
      "epoch": 792.51,
      "learning_rate": 0.02078207278713826,
      "loss": 2.4799,
      "step": 492940
    },
    {
      "epoch": 792.54,
      "learning_rate": 0.0207788573562701,
      "loss": 2.4383,
      "step": 492960
    },
    {
      "epoch": 792.57,
      "learning_rate": 0.020775641925401933,
      "loss": 2.4488,
      "step": 492980
    },
    {
      "epoch": 792.6,
      "learning_rate": 0.020772426494533765,
      "loss": 2.442,
      "step": 493000
    },
    {
      "epoch": 792.64,
      "learning_rate": 0.020769211063665593,
      "loss": 2.4529,
      "step": 493020
    },
    {
      "epoch": 792.67,
      "learning_rate": 0.020765995632797424,
      "loss": 2.4491,
      "step": 493040
    },
    {
      "epoch": 792.7,
      "learning_rate": 0.020762780201929256,
      "loss": 2.4498,
      "step": 493060
    },
    {
      "epoch": 792.73,
      "learning_rate": 0.020759564771061098,
      "loss": 2.4388,
      "step": 493080
    },
    {
      "epoch": 792.77,
      "learning_rate": 0.02075634934019293,
      "loss": 2.4579,
      "step": 493100
    },
    {
      "epoch": 792.8,
      "learning_rate": 0.02075313390932476,
      "loss": 2.4454,
      "step": 493120
    },
    {
      "epoch": 792.83,
      "learning_rate": 0.02074991847845659,
      "loss": 2.4312,
      "step": 493140
    },
    {
      "epoch": 792.86,
      "learning_rate": 0.02074670304758842,
      "loss": 2.4569,
      "step": 493160
    },
    {
      "epoch": 792.89,
      "learning_rate": 0.020743487616720253,
      "loss": 2.4414,
      "step": 493180
    },
    {
      "epoch": 792.93,
      "learning_rate": 0.020740272185852095,
      "loss": 2.446,
      "step": 493200
    },
    {
      "epoch": 792.96,
      "learning_rate": 0.020737056754983926,
      "loss": 2.4717,
      "step": 493220
    },
    {
      "epoch": 792.99,
      "learning_rate": 0.020733841324115754,
      "loss": 2.4442,
      "step": 493240
    },
    {
      "epoch": 793.0,
      "eval_accuracy": {
        "accuracy": 0.4500505325351784
      },
      "eval_loss": 2.5820188522338867,
      "eval_runtime": 3.3996,
      "eval_samples_per_second": 3783.664,
      "eval_steps_per_second": 59.124,
      "step": 493246
    },
    {
      "epoch": 793.02,
      "learning_rate": 0.020730625893247586,
      "loss": 2.4518,
      "step": 493260
    },
    {
      "epoch": 793.05,
      "learning_rate": 0.020727410462379418,
      "loss": 2.4358,
      "step": 493280
    },
    {
      "epoch": 793.09,
      "learning_rate": 0.02072419503151126,
      "loss": 2.445,
      "step": 493300
    },
    {
      "epoch": 793.12,
      "learning_rate": 0.02072097960064309,
      "loss": 2.4565,
      "step": 493320
    },
    {
      "epoch": 793.15,
      "learning_rate": 0.02071776416977492,
      "loss": 2.4388,
      "step": 493340
    },
    {
      "epoch": 793.18,
      "learning_rate": 0.02071454873890675,
      "loss": 2.4275,
      "step": 493360
    },
    {
      "epoch": 793.22,
      "learning_rate": 0.020711333308038583,
      "loss": 2.466,
      "step": 493380
    },
    {
      "epoch": 793.25,
      "learning_rate": 0.020708117877170414,
      "loss": 2.4476,
      "step": 493400
    },
    {
      "epoch": 793.28,
      "learning_rate": 0.020704902446302256,
      "loss": 2.4491,
      "step": 493420
    },
    {
      "epoch": 793.31,
      "learning_rate": 0.020701687015434088,
      "loss": 2.4667,
      "step": 493440
    },
    {
      "epoch": 793.34,
      "learning_rate": 0.020698471584565916,
      "loss": 2.4483,
      "step": 493460
    },
    {
      "epoch": 793.38,
      "learning_rate": 0.020695256153697748,
      "loss": 2.4456,
      "step": 493480
    },
    {
      "epoch": 793.41,
      "learning_rate": 0.02069204072282958,
      "loss": 2.4613,
      "step": 493500
    },
    {
      "epoch": 793.44,
      "learning_rate": 0.02068882529196141,
      "loss": 2.4507,
      "step": 493520
    },
    {
      "epoch": 793.47,
      "learning_rate": 0.020685609861093253,
      "loss": 2.4348,
      "step": 493540
    },
    {
      "epoch": 793.5,
      "learning_rate": 0.02068239443022508,
      "loss": 2.4539,
      "step": 493560
    },
    {
      "epoch": 793.54,
      "learning_rate": 0.020679178999356913,
      "loss": 2.4336,
      "step": 493580
    },
    {
      "epoch": 793.57,
      "learning_rate": 0.020675963568488744,
      "loss": 2.4602,
      "step": 493600
    },
    {
      "epoch": 793.6,
      "learning_rate": 0.020672748137620576,
      "loss": 2.4439,
      "step": 493620
    },
    {
      "epoch": 793.63,
      "learning_rate": 0.020669532706752418,
      "loss": 2.4303,
      "step": 493640
    },
    {
      "epoch": 793.67,
      "learning_rate": 0.020666317275884246,
      "loss": 2.4637,
      "step": 493660
    },
    {
      "epoch": 793.7,
      "learning_rate": 0.020663101845016078,
      "loss": 2.4499,
      "step": 493680
    },
    {
      "epoch": 793.73,
      "learning_rate": 0.02065988641414791,
      "loss": 2.4531,
      "step": 493700
    },
    {
      "epoch": 793.76,
      "learning_rate": 0.02065667098327974,
      "loss": 2.4344,
      "step": 493720
    },
    {
      "epoch": 793.79,
      "learning_rate": 0.020653455552411572,
      "loss": 2.4622,
      "step": 493740
    },
    {
      "epoch": 793.83,
      "learning_rate": 0.020650240121543414,
      "loss": 2.4116,
      "step": 493760
    },
    {
      "epoch": 793.86,
      "learning_rate": 0.020647024690675243,
      "loss": 2.4393,
      "step": 493780
    },
    {
      "epoch": 793.89,
      "learning_rate": 0.020643809259807074,
      "loss": 2.4533,
      "step": 493800
    },
    {
      "epoch": 793.92,
      "learning_rate": 0.020640593828938906,
      "loss": 2.4609,
      "step": 493820
    },
    {
      "epoch": 793.95,
      "learning_rate": 0.020637378398070737,
      "loss": 2.4529,
      "step": 493840
    },
    {
      "epoch": 793.99,
      "learning_rate": 0.020634162967202566,
      "loss": 2.4294,
      "step": 493860
    },
    {
      "epoch": 794.0,
      "eval_accuracy": {
        "accuracy": 0.4512166679623727
      },
      "eval_loss": 2.5658841133117676,
      "eval_runtime": 3.2895,
      "eval_samples_per_second": 3910.338,
      "eval_steps_per_second": 61.104,
      "step": 493868
    },
    {
      "epoch": 794.02,
      "learning_rate": 0.020630947536334408,
      "loss": 2.459,
      "step": 493880
    },
    {
      "epoch": 794.05,
      "learning_rate": 0.02062773210546624,
      "loss": 2.4359,
      "step": 493900
    },
    {
      "epoch": 794.08,
      "learning_rate": 0.02062451667459807,
      "loss": 2.4311,
      "step": 493920
    },
    {
      "epoch": 794.12,
      "learning_rate": 0.020621301243729902,
      "loss": 2.4404,
      "step": 493940
    },
    {
      "epoch": 794.15,
      "learning_rate": 0.02061808581286173,
      "loss": 2.4255,
      "step": 493960
    },
    {
      "epoch": 794.18,
      "learning_rate": 0.020614870381993573,
      "loss": 2.4515,
      "step": 493980
    },
    {
      "epoch": 794.21,
      "learning_rate": 0.020611654951125404,
      "loss": 2.4512,
      "step": 494000
    },
    {
      "epoch": 794.24,
      "learning_rate": 0.020608439520257236,
      "loss": 2.4516,
      "step": 494020
    },
    {
      "epoch": 794.28,
      "learning_rate": 0.020605224089389067,
      "loss": 2.4226,
      "step": 494040
    },
    {
      "epoch": 794.31,
      "learning_rate": 0.0206020086585209,
      "loss": 2.4386,
      "step": 494060
    },
    {
      "epoch": 794.34,
      "learning_rate": 0.020598793227652727,
      "loss": 2.4385,
      "step": 494080
    },
    {
      "epoch": 794.37,
      "learning_rate": 0.02059557779678457,
      "loss": 2.444,
      "step": 494100
    },
    {
      "epoch": 794.41,
      "learning_rate": 0.0205923623659164,
      "loss": 2.4333,
      "step": 494120
    },
    {
      "epoch": 794.44,
      "learning_rate": 0.020589146935048232,
      "loss": 2.4488,
      "step": 494140
    },
    {
      "epoch": 794.47,
      "learning_rate": 0.020585931504180064,
      "loss": 2.4498,
      "step": 494160
    },
    {
      "epoch": 794.5,
      "learning_rate": 0.020582716073311892,
      "loss": 2.4508,
      "step": 494180
    },
    {
      "epoch": 794.53,
      "learning_rate": 0.020579500642443724,
      "loss": 2.455,
      "step": 494200
    },
    {
      "epoch": 794.57,
      "learning_rate": 0.020576285211575566,
      "loss": 2.443,
      "step": 494220
    },
    {
      "epoch": 794.6,
      "learning_rate": 0.020573069780707397,
      "loss": 2.4553,
      "step": 494240
    },
    {
      "epoch": 794.63,
      "learning_rate": 0.02056985434983923,
      "loss": 2.4478,
      "step": 494260
    },
    {
      "epoch": 794.66,
      "learning_rate": 0.020566638918971057,
      "loss": 2.4665,
      "step": 494280
    },
    {
      "epoch": 794.69,
      "learning_rate": 0.02056342348810289,
      "loss": 2.455,
      "step": 494300
    },
    {
      "epoch": 794.73,
      "learning_rate": 0.02056020805723473,
      "loss": 2.4442,
      "step": 494320
    },
    {
      "epoch": 794.76,
      "learning_rate": 0.020556992626366562,
      "loss": 2.4407,
      "step": 494340
    },
    {
      "epoch": 794.79,
      "learning_rate": 0.020553777195498394,
      "loss": 2.4642,
      "step": 494360
    },
    {
      "epoch": 794.82,
      "learning_rate": 0.020550561764630226,
      "loss": 2.4317,
      "step": 494380
    },
    {
      "epoch": 794.86,
      "learning_rate": 0.020547346333762054,
      "loss": 2.4533,
      "step": 494400
    },
    {
      "epoch": 794.89,
      "learning_rate": 0.020544130902893885,
      "loss": 2.4541,
      "step": 494420
    },
    {
      "epoch": 794.92,
      "learning_rate": 0.020540915472025727,
      "loss": 2.4305,
      "step": 494440
    },
    {
      "epoch": 794.95,
      "learning_rate": 0.02053770004115756,
      "loss": 2.4222,
      "step": 494460
    },
    {
      "epoch": 794.98,
      "learning_rate": 0.02053448461028939,
      "loss": 2.4447,
      "step": 494480
    },
    {
      "epoch": 795.0,
      "eval_accuracy": {
        "accuracy": 0.449117624193423
      },
      "eval_loss": 2.5610384941101074,
      "eval_runtime": 3.3456,
      "eval_samples_per_second": 3844.719,
      "eval_steps_per_second": 60.078,
      "step": 494490
    },
    {
      "epoch": 795.02,
      "learning_rate": 0.02053126917942122,
      "loss": 2.4365,
      "step": 494500
    },
    {
      "epoch": 795.05,
      "learning_rate": 0.02052805374855305,
      "loss": 2.4253,
      "step": 494520
    },
    {
      "epoch": 795.08,
      "learning_rate": 0.020524838317684882,
      "loss": 2.4559,
      "step": 494540
    },
    {
      "epoch": 795.11,
      "learning_rate": 0.020521622886816724,
      "loss": 2.4367,
      "step": 494560
    },
    {
      "epoch": 795.14,
      "learning_rate": 0.020518407455948556,
      "loss": 2.4462,
      "step": 494580
    },
    {
      "epoch": 795.18,
      "learning_rate": 0.020515192025080387,
      "loss": 2.4568,
      "step": 494600
    },
    {
      "epoch": 795.21,
      "learning_rate": 0.020511976594212215,
      "loss": 2.4348,
      "step": 494620
    },
    {
      "epoch": 795.24,
      "learning_rate": 0.020508761163344047,
      "loss": 2.4616,
      "step": 494640
    },
    {
      "epoch": 795.27,
      "learning_rate": 0.02050554573247589,
      "loss": 2.4349,
      "step": 494660
    },
    {
      "epoch": 795.31,
      "learning_rate": 0.02050233030160772,
      "loss": 2.4646,
      "step": 494680
    },
    {
      "epoch": 795.34,
      "learning_rate": 0.020499114870739552,
      "loss": 2.4519,
      "step": 494700
    },
    {
      "epoch": 795.37,
      "learning_rate": 0.02049589943987138,
      "loss": 2.432,
      "step": 494720
    },
    {
      "epoch": 795.4,
      "learning_rate": 0.020492684009003212,
      "loss": 2.4342,
      "step": 494740
    },
    {
      "epoch": 795.43,
      "learning_rate": 0.020489468578135044,
      "loss": 2.4259,
      "step": 494760
    },
    {
      "epoch": 795.47,
      "learning_rate": 0.020486253147266886,
      "loss": 2.4452,
      "step": 494780
    },
    {
      "epoch": 795.5,
      "learning_rate": 0.020483037716398717,
      "loss": 2.4416,
      "step": 494800
    },
    {
      "epoch": 795.53,
      "learning_rate": 0.020479822285530545,
      "loss": 2.447,
      "step": 494820
    },
    {
      "epoch": 795.56,
      "learning_rate": 0.020476606854662377,
      "loss": 2.4602,
      "step": 494840
    },
    {
      "epoch": 795.59,
      "learning_rate": 0.02047339142379421,
      "loss": 2.4515,
      "step": 494860
    },
    {
      "epoch": 795.63,
      "learning_rate": 0.02047017599292605,
      "loss": 2.4396,
      "step": 494880
    },
    {
      "epoch": 795.66,
      "learning_rate": 0.020466960562057882,
      "loss": 2.4319,
      "step": 494900
    },
    {
      "epoch": 795.69,
      "learning_rate": 0.020463745131189714,
      "loss": 2.4292,
      "step": 494920
    },
    {
      "epoch": 795.72,
      "learning_rate": 0.020460690471864953,
      "loss": 2.4468,
      "step": 494940
    },
    {
      "epoch": 795.76,
      "learning_rate": 0.020457475040996785,
      "loss": 2.4367,
      "step": 494960
    },
    {
      "epoch": 795.79,
      "learning_rate": 0.020454259610128617,
      "loss": 2.4511,
      "step": 494980
    },
    {
      "epoch": 795.82,
      "learning_rate": 0.02045104417926045,
      "loss": 2.4498,
      "step": 495000
    },
    {
      "epoch": 795.85,
      "learning_rate": 0.020447828748392276,
      "loss": 2.4609,
      "step": 495020
    },
    {
      "epoch": 795.88,
      "learning_rate": 0.02044461331752412,
      "loss": 2.4332,
      "step": 495040
    },
    {
      "epoch": 795.92,
      "learning_rate": 0.02044139788665595,
      "loss": 2.4361,
      "step": 495060
    },
    {
      "epoch": 795.95,
      "learning_rate": 0.02043818245578778,
      "loss": 2.4363,
      "step": 495080
    },
    {
      "epoch": 795.98,
      "learning_rate": 0.020434967024919613,
      "loss": 2.4537,
      "step": 495100
    },
    {
      "epoch": 796.0,
      "eval_accuracy": {
        "accuracy": 0.45160537977143744
      },
      "eval_loss": 2.5747153759002686,
      "eval_runtime": 3.0024,
      "eval_samples_per_second": 4284.206,
      "eval_steps_per_second": 66.946,
      "step": 495112
    },
    {
      "epoch": 796.01,
      "learning_rate": 0.02043175159405144,
      "loss": 2.4655,
      "step": 495120
    },
    {
      "epoch": 796.05,
      "learning_rate": 0.020428536163183283,
      "loss": 2.4538,
      "step": 495140
    },
    {
      "epoch": 796.08,
      "learning_rate": 0.020425320732315115,
      "loss": 2.4454,
      "step": 495160
    },
    {
      "epoch": 796.11,
      "learning_rate": 0.020422105301446947,
      "loss": 2.4276,
      "step": 495180
    },
    {
      "epoch": 796.14,
      "learning_rate": 0.02041888987057878,
      "loss": 2.4483,
      "step": 495200
    },
    {
      "epoch": 796.17,
      "learning_rate": 0.020415674439710606,
      "loss": 2.4284,
      "step": 495220
    },
    {
      "epoch": 796.21,
      "learning_rate": 0.020412459008842438,
      "loss": 2.4532,
      "step": 495240
    },
    {
      "epoch": 796.24,
      "learning_rate": 0.02040924357797428,
      "loss": 2.4523,
      "step": 495260
    },
    {
      "epoch": 796.27,
      "learning_rate": 0.02040602814710611,
      "loss": 2.4285,
      "step": 495280
    },
    {
      "epoch": 796.3,
      "learning_rate": 0.020402812716237943,
      "loss": 2.4412,
      "step": 495300
    },
    {
      "epoch": 796.33,
      "learning_rate": 0.020399597285369775,
      "loss": 2.4292,
      "step": 495320
    },
    {
      "epoch": 796.37,
      "learning_rate": 0.020396381854501603,
      "loss": 2.4564,
      "step": 495340
    },
    {
      "epoch": 796.4,
      "learning_rate": 0.020393166423633435,
      "loss": 2.4301,
      "step": 495360
    },
    {
      "epoch": 796.43,
      "learning_rate": 0.020389950992765277,
      "loss": 2.4425,
      "step": 495380
    },
    {
      "epoch": 796.46,
      "learning_rate": 0.02038673556189711,
      "loss": 2.4472,
      "step": 495400
    },
    {
      "epoch": 796.5,
      "learning_rate": 0.02038352013102894,
      "loss": 2.4521,
      "step": 495420
    },
    {
      "epoch": 796.53,
      "learning_rate": 0.020380304700160768,
      "loss": 2.4458,
      "step": 495440
    },
    {
      "epoch": 796.56,
      "learning_rate": 0.0203770892692926,
      "loss": 2.4304,
      "step": 495460
    },
    {
      "epoch": 796.59,
      "learning_rate": 0.02037387383842444,
      "loss": 2.4359,
      "step": 495480
    },
    {
      "epoch": 796.62,
      "learning_rate": 0.020370658407556273,
      "loss": 2.4514,
      "step": 495500
    },
    {
      "epoch": 796.66,
      "learning_rate": 0.020367442976688105,
      "loss": 2.451,
      "step": 495520
    },
    {
      "epoch": 796.69,
      "learning_rate": 0.020364227545819933,
      "loss": 2.46,
      "step": 495540
    },
    {
      "epoch": 796.72,
      "learning_rate": 0.020361012114951765,
      "loss": 2.4328,
      "step": 495560
    },
    {
      "epoch": 796.75,
      "learning_rate": 0.020357796684083596,
      "loss": 2.448,
      "step": 495580
    },
    {
      "epoch": 796.78,
      "learning_rate": 0.020354581253215438,
      "loss": 2.4422,
      "step": 495600
    },
    {
      "epoch": 796.82,
      "learning_rate": 0.02035136582234727,
      "loss": 2.4386,
      "step": 495620
    },
    {
      "epoch": 796.85,
      "learning_rate": 0.0203481503914791,
      "loss": 2.4369,
      "step": 495640
    },
    {
      "epoch": 796.88,
      "learning_rate": 0.02034493496061093,
      "loss": 2.457,
      "step": 495660
    },
    {
      "epoch": 796.91,
      "learning_rate": 0.02034171952974276,
      "loss": 2.4403,
      "step": 495680
    },
    {
      "epoch": 796.95,
      "learning_rate": 0.020338504098874603,
      "loss": 2.4355,
      "step": 495700
    },
    {
      "epoch": 796.98,
      "learning_rate": 0.020335288668006435,
      "loss": 2.4426,
      "step": 495720
    },
    {
      "epoch": 797.0,
      "eval_accuracy": {
        "accuracy": 0.4513721526859986
      },
      "eval_loss": 2.570970296859741,
      "eval_runtime": 3.5008,
      "eval_samples_per_second": 3674.352,
      "eval_steps_per_second": 57.416,
      "step": 495734
    },
    {
      "epoch": 797.01,
      "learning_rate": 0.020332073237138266,
      "loss": 2.4574,
      "step": 495740
    },
    {
      "epoch": 797.04,
      "learning_rate": 0.020328857806270095,
      "loss": 2.4515,
      "step": 495760
    },
    {
      "epoch": 797.07,
      "learning_rate": 0.020325642375401926,
      "loss": 2.4246,
      "step": 495780
    },
    {
      "epoch": 797.11,
      "learning_rate": 0.020322426944533758,
      "loss": 2.4253,
      "step": 495800
    },
    {
      "epoch": 797.14,
      "learning_rate": 0.0203192115136656,
      "loss": 2.4329,
      "step": 495820
    },
    {
      "epoch": 797.17,
      "learning_rate": 0.02031599608279743,
      "loss": 2.4311,
      "step": 495840
    },
    {
      "epoch": 797.2,
      "learning_rate": 0.02031278065192926,
      "loss": 2.4445,
      "step": 495860
    },
    {
      "epoch": 797.23,
      "learning_rate": 0.02030956522106109,
      "loss": 2.4535,
      "step": 495880
    },
    {
      "epoch": 797.27,
      "learning_rate": 0.020306349790192923,
      "loss": 2.4347,
      "step": 495900
    },
    {
      "epoch": 797.3,
      "learning_rate": 0.020303134359324754,
      "loss": 2.4334,
      "step": 495920
    },
    {
      "epoch": 797.33,
      "learning_rate": 0.020299918928456596,
      "loss": 2.4261,
      "step": 495940
    },
    {
      "epoch": 797.36,
      "learning_rate": 0.020296703497588428,
      "loss": 2.4462,
      "step": 495960
    },
    {
      "epoch": 797.4,
      "learning_rate": 0.020293488066720256,
      "loss": 2.4533,
      "step": 495980
    },
    {
      "epoch": 797.43,
      "learning_rate": 0.020290272635852088,
      "loss": 2.4481,
      "step": 496000
    },
    {
      "epoch": 797.46,
      "learning_rate": 0.02028705720498392,
      "loss": 2.4398,
      "step": 496020
    },
    {
      "epoch": 797.49,
      "learning_rate": 0.02028384177411576,
      "loss": 2.4476,
      "step": 496040
    },
    {
      "epoch": 797.52,
      "learning_rate": 0.020280626343247593,
      "loss": 2.4269,
      "step": 496060
    },
    {
      "epoch": 797.56,
      "learning_rate": 0.02027741091237942,
      "loss": 2.4551,
      "step": 496080
    },
    {
      "epoch": 797.59,
      "learning_rate": 0.020274195481511253,
      "loss": 2.4431,
      "step": 496100
    },
    {
      "epoch": 797.62,
      "learning_rate": 0.020270980050643084,
      "loss": 2.4384,
      "step": 496120
    },
    {
      "epoch": 797.65,
      "learning_rate": 0.020267764619774916,
      "loss": 2.4377,
      "step": 496140
    },
    {
      "epoch": 797.68,
      "learning_rate": 0.020264549188906758,
      "loss": 2.4387,
      "step": 496160
    },
    {
      "epoch": 797.72,
      "learning_rate": 0.020261333758038586,
      "loss": 2.4606,
      "step": 496180
    },
    {
      "epoch": 797.75,
      "learning_rate": 0.020258118327170418,
      "loss": 2.4497,
      "step": 496200
    },
    {
      "epoch": 797.78,
      "learning_rate": 0.02025490289630225,
      "loss": 2.4549,
      "step": 496220
    },
    {
      "epoch": 797.81,
      "learning_rate": 0.02025168746543408,
      "loss": 2.4274,
      "step": 496240
    },
    {
      "epoch": 797.85,
      "learning_rate": 0.020248472034565913,
      "loss": 2.4363,
      "step": 496260
    },
    {
      "epoch": 797.88,
      "learning_rate": 0.020245256603697755,
      "loss": 2.4582,
      "step": 496280
    },
    {
      "epoch": 797.91,
      "learning_rate": 0.020242041172829583,
      "loss": 2.4662,
      "step": 496300
    },
    {
      "epoch": 797.94,
      "learning_rate": 0.020238825741961414,
      "loss": 2.444,
      "step": 496320
    },
    {
      "epoch": 797.97,
      "learning_rate": 0.020235610311093246,
      "loss": 2.4268,
      "step": 496340
    },
    {
      "epoch": 798.0,
      "eval_accuracy": {
        "accuracy": 0.4513721526859986
      },
      "eval_loss": 2.5609655380249023,
      "eval_runtime": 3.1575,
      "eval_samples_per_second": 4073.803,
      "eval_steps_per_second": 63.658,
      "step": 496356
    },
    {
      "epoch": 798.01,
      "learning_rate": 0.020232394880225078,
      "loss": 2.4527,
      "step": 496360
    },
    {
      "epoch": 798.04,
      "learning_rate": 0.02022917944935692,
      "loss": 2.4202,
      "step": 496380
    },
    {
      "epoch": 798.07,
      "learning_rate": 0.020225964018488748,
      "loss": 2.4504,
      "step": 496400
    },
    {
      "epoch": 798.1,
      "learning_rate": 0.02022274858762058,
      "loss": 2.4443,
      "step": 496420
    },
    {
      "epoch": 798.14,
      "learning_rate": 0.02021953315675241,
      "loss": 2.4387,
      "step": 496440
    },
    {
      "epoch": 798.17,
      "learning_rate": 0.020216317725884243,
      "loss": 2.4407,
      "step": 496460
    },
    {
      "epoch": 798.2,
      "learning_rate": 0.020213102295016074,
      "loss": 2.4488,
      "step": 496480
    },
    {
      "epoch": 798.23,
      "learning_rate": 0.020209886864147913,
      "loss": 2.4597,
      "step": 496500
    },
    {
      "epoch": 798.26,
      "learning_rate": 0.020206671433279744,
      "loss": 2.4407,
      "step": 496520
    },
    {
      "epoch": 798.3,
      "learning_rate": 0.020203456002411576,
      "loss": 2.4325,
      "step": 496540
    },
    {
      "epoch": 798.33,
      "learning_rate": 0.020200240571543408,
      "loss": 2.4323,
      "step": 496560
    },
    {
      "epoch": 798.36,
      "learning_rate": 0.02019702514067524,
      "loss": 2.4488,
      "step": 496580
    },
    {
      "epoch": 798.39,
      "learning_rate": 0.020193809709807067,
      "loss": 2.4231,
      "step": 496600
    },
    {
      "epoch": 798.42,
      "learning_rate": 0.02019059427893891,
      "loss": 2.4437,
      "step": 496620
    },
    {
      "epoch": 798.46,
      "learning_rate": 0.02018737884807074,
      "loss": 2.4354,
      "step": 496640
    },
    {
      "epoch": 798.49,
      "learning_rate": 0.020184163417202573,
      "loss": 2.4427,
      "step": 496660
    },
    {
      "epoch": 798.52,
      "learning_rate": 0.020180947986334404,
      "loss": 2.4282,
      "step": 496680
    },
    {
      "epoch": 798.55,
      "learning_rate": 0.020177732555466232,
      "loss": 2.4211,
      "step": 496700
    },
    {
      "epoch": 798.59,
      "learning_rate": 0.020174517124598074,
      "loss": 2.4412,
      "step": 496720
    },
    {
      "epoch": 798.62,
      "learning_rate": 0.020171301693729906,
      "loss": 2.4531,
      "step": 496740
    },
    {
      "epoch": 798.65,
      "learning_rate": 0.020168086262861738,
      "loss": 2.4347,
      "step": 496760
    },
    {
      "epoch": 798.68,
      "learning_rate": 0.02016487083199357,
      "loss": 2.4621,
      "step": 496780
    },
    {
      "epoch": 798.71,
      "learning_rate": 0.0201616554011254,
      "loss": 2.4459,
      "step": 496800
    },
    {
      "epoch": 798.75,
      "learning_rate": 0.02015843997025723,
      "loss": 2.4325,
      "step": 496820
    },
    {
      "epoch": 798.78,
      "learning_rate": 0.02015522453938907,
      "loss": 2.4617,
      "step": 496840
    },
    {
      "epoch": 798.81,
      "learning_rate": 0.020152009108520903,
      "loss": 2.4406,
      "step": 496860
    },
    {
      "epoch": 798.84,
      "learning_rate": 0.020148793677652734,
      "loss": 2.4412,
      "step": 496880
    },
    {
      "epoch": 798.87,
      "learning_rate": 0.020145578246784566,
      "loss": 2.4445,
      "step": 496900
    },
    {
      "epoch": 798.91,
      "learning_rate": 0.020142362815916394,
      "loss": 2.4444,
      "step": 496920
    },
    {
      "epoch": 798.94,
      "learning_rate": 0.020139147385048226,
      "loss": 2.4448,
      "step": 496940
    },
    {
      "epoch": 798.97,
      "learning_rate": 0.020135931954180068,
      "loss": 2.425,
      "step": 496960
    },
    {
      "epoch": 799.0,
      "eval_accuracy": {
        "accuracy": 0.447485034595351
      },
      "eval_loss": 2.57826828956604,
      "eval_runtime": 3.5196,
      "eval_samples_per_second": 3654.65,
      "eval_steps_per_second": 57.108,
      "step": 496978
    },
    {
      "epoch": 799.0,
      "learning_rate": 0.0201327165233119,
      "loss": 2.4486,
      "step": 496980
    },
    {
      "epoch": 799.04,
      "learning_rate": 0.02012950109244373,
      "loss": 2.4487,
      "step": 497000
    },
    {
      "epoch": 799.07,
      "learning_rate": 0.02012628566157556,
      "loss": 2.4364,
      "step": 497020
    },
    {
      "epoch": 799.1,
      "learning_rate": 0.02012307023070739,
      "loss": 2.4527,
      "step": 497040
    },
    {
      "epoch": 799.13,
      "learning_rate": 0.020119854799839233,
      "loss": 2.4507,
      "step": 497060
    },
    {
      "epoch": 799.16,
      "learning_rate": 0.020116639368971064,
      "loss": 2.4481,
      "step": 497080
    },
    {
      "epoch": 799.2,
      "learning_rate": 0.020113423938102896,
      "loss": 2.4417,
      "step": 497100
    },
    {
      "epoch": 799.23,
      "learning_rate": 0.020110208507234727,
      "loss": 2.4404,
      "step": 497120
    },
    {
      "epoch": 799.26,
      "learning_rate": 0.020106993076366556,
      "loss": 2.4363,
      "step": 497140
    },
    {
      "epoch": 799.29,
      "learning_rate": 0.020103777645498387,
      "loss": 2.4521,
      "step": 497160
    },
    {
      "epoch": 799.32,
      "learning_rate": 0.02010056221463023,
      "loss": 2.4533,
      "step": 497180
    },
    {
      "epoch": 799.36,
      "learning_rate": 0.02009734678376206,
      "loss": 2.4462,
      "step": 497200
    },
    {
      "epoch": 799.39,
      "learning_rate": 0.020094131352893892,
      "loss": 2.4144,
      "step": 497220
    },
    {
      "epoch": 799.42,
      "learning_rate": 0.02009091592202572,
      "loss": 2.4462,
      "step": 497240
    },
    {
      "epoch": 799.45,
      "learning_rate": 0.020087700491157552,
      "loss": 2.4511,
      "step": 497260
    },
    {
      "epoch": 799.49,
      "learning_rate": 0.020084485060289394,
      "loss": 2.4174,
      "step": 497280
    },
    {
      "epoch": 799.52,
      "learning_rate": 0.020081269629421226,
      "loss": 2.4326,
      "step": 497300
    },
    {
      "epoch": 799.55,
      "learning_rate": 0.020078054198553057,
      "loss": 2.4269,
      "step": 497320
    },
    {
      "epoch": 799.58,
      "learning_rate": 0.020074838767684886,
      "loss": 2.4438,
      "step": 497340
    },
    {
      "epoch": 799.61,
      "learning_rate": 0.020071623336816717,
      "loss": 2.4439,
      "step": 497360
    },
    {
      "epoch": 799.65,
      "learning_rate": 0.02006840790594855,
      "loss": 2.4551,
      "step": 497380
    },
    {
      "epoch": 799.68,
      "learning_rate": 0.02006519247508039,
      "loss": 2.414,
      "step": 497400
    },
    {
      "epoch": 799.71,
      "learning_rate": 0.020061977044212222,
      "loss": 2.4251,
      "step": 497420
    },
    {
      "epoch": 799.74,
      "learning_rate": 0.020058761613344054,
      "loss": 2.4408,
      "step": 497440
    },
    {
      "epoch": 799.77,
      "learning_rate": 0.020055546182475882,
      "loss": 2.453,
      "step": 497460
    },
    {
      "epoch": 799.81,
      "learning_rate": 0.020052491523151125,
      "loss": 2.4238,
      "step": 497480
    },
    {
      "epoch": 799.84,
      "learning_rate": 0.020049276092282957,
      "loss": 2.4539,
      "step": 497500
    },
    {
      "epoch": 799.87,
      "learning_rate": 0.02004606066141479,
      "loss": 2.4457,
      "step": 497520
    },
    {
      "epoch": 799.9,
      "learning_rate": 0.02004284523054663,
      "loss": 2.4701,
      "step": 497540
    },
    {
      "epoch": 799.94,
      "learning_rate": 0.02003962979967846,
      "loss": 2.4604,
      "step": 497560
    },
    {
      "epoch": 799.97,
      "learning_rate": 0.02003641436881029,
      "loss": 2.4333,
      "step": 497580
    },
    {
      "epoch": 800.0,
      "learning_rate": 0.020033198937942122,
      "loss": 2.4634,
      "step": 497600
    },
    {
      "epoch": 800.0,
      "eval_accuracy": {
        "accuracy": 0.44903988183161003
      },
      "eval_loss": 2.560490608215332,
      "eval_runtime": 3.1631,
      "eval_samples_per_second": 4066.586,
      "eval_steps_per_second": 63.545,
      "step": 497600
    },
    {
      "epoch": 800.03,
      "learning_rate": 0.020029983507073953,
      "loss": 2.449,
      "step": 497620
    },
    {
      "epoch": 800.06,
      "learning_rate": 0.02002676807620578,
      "loss": 2.4387,
      "step": 497640
    },
    {
      "epoch": 800.1,
      "learning_rate": 0.020023552645337624,
      "loss": 2.4576,
      "step": 497660
    },
    {
      "epoch": 800.13,
      "learning_rate": 0.020020337214469455,
      "loss": 2.4274,
      "step": 497680
    },
    {
      "epoch": 800.16,
      "learning_rate": 0.020017121783601287,
      "loss": 2.4448,
      "step": 497700
    },
    {
      "epoch": 800.19,
      "learning_rate": 0.02001390635273312,
      "loss": 2.4412,
      "step": 497720
    },
    {
      "epoch": 800.23,
      "learning_rate": 0.020010690921864947,
      "loss": 2.4419,
      "step": 497740
    },
    {
      "epoch": 800.26,
      "learning_rate": 0.020007475490996778,
      "loss": 2.4437,
      "step": 497760
    },
    {
      "epoch": 800.29,
      "learning_rate": 0.02000426006012862,
      "loss": 2.433,
      "step": 497780
    },
    {
      "epoch": 800.32,
      "learning_rate": 0.020001044629260452,
      "loss": 2.4423,
      "step": 497800
    },
    {
      "epoch": 800.35,
      "learning_rate": 0.019997829198392283,
      "loss": 2.4332,
      "step": 497820
    },
    {
      "epoch": 800.39,
      "learning_rate": 0.019994613767524115,
      "loss": 2.4386,
      "step": 497840
    },
    {
      "epoch": 800.42,
      "learning_rate": 0.019991398336655943,
      "loss": 2.425,
      "step": 497860
    },
    {
      "epoch": 800.45,
      "learning_rate": 0.019988182905787785,
      "loss": 2.4448,
      "step": 497880
    },
    {
      "epoch": 800.48,
      "learning_rate": 0.019984967474919617,
      "loss": 2.4517,
      "step": 497900
    },
    {
      "epoch": 800.51,
      "learning_rate": 0.01998175204405145,
      "loss": 2.4361,
      "step": 497920
    },
    {
      "epoch": 800.55,
      "learning_rate": 0.01997853661318328,
      "loss": 2.4361,
      "step": 497940
    },
    {
      "epoch": 800.58,
      "learning_rate": 0.019975321182315108,
      "loss": 2.4395,
      "step": 497960
    },
    {
      "epoch": 800.61,
      "learning_rate": 0.01997210575144694,
      "loss": 2.4349,
      "step": 497980
    },
    {
      "epoch": 800.64,
      "learning_rate": 0.019968890320578782,
      "loss": 2.4396,
      "step": 498000
    },
    {
      "epoch": 800.68,
      "learning_rate": 0.019965674889710613,
      "loss": 2.4476,
      "step": 498020
    },
    {
      "epoch": 800.71,
      "learning_rate": 0.019962459458842445,
      "loss": 2.4556,
      "step": 498040
    },
    {
      "epoch": 800.74,
      "learning_rate": 0.019959244027974273,
      "loss": 2.4398,
      "step": 498060
    },
    {
      "epoch": 800.77,
      "learning_rate": 0.019956028597106105,
      "loss": 2.4296,
      "step": 498080
    },
    {
      "epoch": 800.8,
      "learning_rate": 0.019952813166237947,
      "loss": 2.4434,
      "step": 498100
    },
    {
      "epoch": 800.84,
      "learning_rate": 0.01994959773536978,
      "loss": 2.4379,
      "step": 498120
    },
    {
      "epoch": 800.87,
      "learning_rate": 0.01994638230450161,
      "loss": 2.4293,
      "step": 498140
    },
    {
      "epoch": 800.9,
      "learning_rate": 0.01994316687363344,
      "loss": 2.4422,
      "step": 498160
    },
    {
      "epoch": 800.93,
      "learning_rate": 0.01993995144276527,
      "loss": 2.4232,
      "step": 498180
    },
    {
      "epoch": 800.96,
      "learning_rate": 0.0199367360118971,
      "loss": 2.4315,
      "step": 498200
    },
    {
      "epoch": 801.0,
      "learning_rate": 0.019933520581028943,
      "loss": 2.4582,
      "step": 498220
    },
    {
      "epoch": 801.0,
      "eval_accuracy": {
        "accuracy": 0.45207183394231515
      },
      "eval_loss": 2.551743507385254,
      "eval_runtime": 3.0559,
      "eval_samples_per_second": 4209.295,
      "eval_steps_per_second": 65.775,
      "step": 498222
    },
    {
      "epoch": 801.03,
      "learning_rate": 0.019930305150160775,
      "loss": 2.4382,
      "step": 498240
    },
    {
      "epoch": 801.06,
      "learning_rate": 0.019927089719292607,
      "loss": 2.433,
      "step": 498260
    },
    {
      "epoch": 801.09,
      "learning_rate": 0.019923874288424435,
      "loss": 2.4304,
      "step": 498280
    },
    {
      "epoch": 801.13,
      "learning_rate": 0.019920658857556266,
      "loss": 2.4359,
      "step": 498300
    },
    {
      "epoch": 801.16,
      "learning_rate": 0.019917443426688098,
      "loss": 2.4362,
      "step": 498320
    },
    {
      "epoch": 801.19,
      "learning_rate": 0.01991422799581994,
      "loss": 2.4542,
      "step": 498340
    },
    {
      "epoch": 801.22,
      "learning_rate": 0.01991101256495177,
      "loss": 2.423,
      "step": 498360
    },
    {
      "epoch": 801.25,
      "learning_rate": 0.0199077971340836,
      "loss": 2.4333,
      "step": 498380
    },
    {
      "epoch": 801.29,
      "learning_rate": 0.01990458170321543,
      "loss": 2.4102,
      "step": 498400
    },
    {
      "epoch": 801.32,
      "learning_rate": 0.019901366272347263,
      "loss": 2.458,
      "step": 498420
    },
    {
      "epoch": 801.35,
      "learning_rate": 0.019898150841479105,
      "loss": 2.4374,
      "step": 498440
    },
    {
      "epoch": 801.38,
      "learning_rate": 0.019894935410610937,
      "loss": 2.4563,
      "step": 498460
    },
    {
      "epoch": 801.41,
      "learning_rate": 0.019891719979742768,
      "loss": 2.4252,
      "step": 498480
    },
    {
      "epoch": 801.45,
      "learning_rate": 0.019888504548874596,
      "loss": 2.427,
      "step": 498500
    },
    {
      "epoch": 801.48,
      "learning_rate": 0.019885289118006428,
      "loss": 2.4574,
      "step": 498520
    },
    {
      "epoch": 801.51,
      "learning_rate": 0.01988207368713826,
      "loss": 2.4507,
      "step": 498540
    },
    {
      "epoch": 801.54,
      "learning_rate": 0.0198788582562701,
      "loss": 2.4458,
      "step": 498560
    },
    {
      "epoch": 801.58,
      "learning_rate": 0.019875642825401933,
      "loss": 2.4379,
      "step": 498580
    },
    {
      "epoch": 801.61,
      "learning_rate": 0.01987242739453376,
      "loss": 2.447,
      "step": 498600
    },
    {
      "epoch": 801.64,
      "learning_rate": 0.019869211963665593,
      "loss": 2.4374,
      "step": 498620
    },
    {
      "epoch": 801.67,
      "learning_rate": 0.019865996532797425,
      "loss": 2.4454,
      "step": 498640
    },
    {
      "epoch": 801.7,
      "learning_rate": 0.019862781101929256,
      "loss": 2.4478,
      "step": 498660
    },
    {
      "epoch": 801.74,
      "learning_rate": 0.019859565671061098,
      "loss": 2.4505,
      "step": 498680
    },
    {
      "epoch": 801.77,
      "learning_rate": 0.019856350240192926,
      "loss": 2.4331,
      "step": 498700
    },
    {
      "epoch": 801.8,
      "learning_rate": 0.019853134809324758,
      "loss": 2.4502,
      "step": 498720
    },
    {
      "epoch": 801.83,
      "learning_rate": 0.01984991937845659,
      "loss": 2.4235,
      "step": 498740
    },
    {
      "epoch": 801.86,
      "learning_rate": 0.01984670394758842,
      "loss": 2.4295,
      "step": 498760
    },
    {
      "epoch": 801.9,
      "learning_rate": 0.019843488516720263,
      "loss": 2.4273,
      "step": 498780
    },
    {
      "epoch": 801.93,
      "learning_rate": 0.019840273085852095,
      "loss": 2.4522,
      "step": 498800
    },
    {
      "epoch": 801.96,
      "learning_rate": 0.019837057654983923,
      "loss": 2.4349,
      "step": 498820
    },
    {
      "epoch": 801.99,
      "learning_rate": 0.019833842224115755,
      "loss": 2.4284,
      "step": 498840
    },
    {
      "epoch": 802.0,
      "eval_accuracy": {
        "accuracy": 0.4561921791184016
      },
      "eval_loss": 2.5558135509490967,
      "eval_runtime": 3.1123,
      "eval_samples_per_second": 4132.99,
      "eval_steps_per_second": 64.583,
      "step": 498844
    },
    {
      "epoch": 802.03,
      "learning_rate": 0.019830626793247586,
      "loss": 2.45,
      "step": 498860
    },
    {
      "epoch": 802.06,
      "learning_rate": 0.019827411362379418,
      "loss": 2.4366,
      "step": 498880
    },
    {
      "epoch": 802.09,
      "learning_rate": 0.01982419593151126,
      "loss": 2.4445,
      "step": 498900
    },
    {
      "epoch": 802.12,
      "learning_rate": 0.019820980500643088,
      "loss": 2.4483,
      "step": 498920
    },
    {
      "epoch": 802.15,
      "learning_rate": 0.01981776506977492,
      "loss": 2.4271,
      "step": 498940
    },
    {
      "epoch": 802.19,
      "learning_rate": 0.01981454963890675,
      "loss": 2.4376,
      "step": 498960
    },
    {
      "epoch": 802.22,
      "learning_rate": 0.019811334208038583,
      "loss": 2.4398,
      "step": 498980
    },
    {
      "epoch": 802.25,
      "learning_rate": 0.019808118777170414,
      "loss": 2.4468,
      "step": 499000
    },
    {
      "epoch": 802.28,
      "learning_rate": 0.019804903346302253,
      "loss": 2.438,
      "step": 499020
    },
    {
      "epoch": 802.32,
      "learning_rate": 0.019801687915434085,
      "loss": 2.4216,
      "step": 499040
    },
    {
      "epoch": 802.35,
      "learning_rate": 0.019798472484565916,
      "loss": 2.4381,
      "step": 499060
    },
    {
      "epoch": 802.38,
      "learning_rate": 0.019795257053697748,
      "loss": 2.4421,
      "step": 499080
    },
    {
      "epoch": 802.41,
      "learning_rate": 0.01979204162282958,
      "loss": 2.426,
      "step": 499100
    },
    {
      "epoch": 802.44,
      "learning_rate": 0.01978882619196142,
      "loss": 2.4413,
      "step": 499120
    },
    {
      "epoch": 802.48,
      "learning_rate": 0.01978561076109325,
      "loss": 2.4391,
      "step": 499140
    },
    {
      "epoch": 802.51,
      "learning_rate": 0.01978239533022508,
      "loss": 2.4226,
      "step": 499160
    },
    {
      "epoch": 802.54,
      "learning_rate": 0.019779179899356913,
      "loss": 2.4362,
      "step": 499180
    },
    {
      "epoch": 802.57,
      "learning_rate": 0.019775964468488744,
      "loss": 2.4384,
      "step": 499200
    },
    {
      "epoch": 802.6,
      "learning_rate": 0.019772749037620573,
      "loss": 2.4572,
      "step": 499220
    },
    {
      "epoch": 802.64,
      "learning_rate": 0.019769533606752415,
      "loss": 2.4598,
      "step": 499240
    },
    {
      "epoch": 802.67,
      "learning_rate": 0.019766318175884246,
      "loss": 2.4409,
      "step": 499260
    },
    {
      "epoch": 802.7,
      "learning_rate": 0.019763102745016078,
      "loss": 2.4298,
      "step": 499280
    },
    {
      "epoch": 802.73,
      "learning_rate": 0.01975988731414791,
      "loss": 2.433,
      "step": 499300
    },
    {
      "epoch": 802.77,
      "learning_rate": 0.01975667188327974,
      "loss": 2.4377,
      "step": 499320
    },
    {
      "epoch": 802.8,
      "learning_rate": 0.01975345645241157,
      "loss": 2.439,
      "step": 499340
    },
    {
      "epoch": 802.83,
      "learning_rate": 0.01975024102154341,
      "loss": 2.4382,
      "step": 499360
    },
    {
      "epoch": 802.86,
      "learning_rate": 0.019747025590675243,
      "loss": 2.4294,
      "step": 499380
    },
    {
      "epoch": 802.89,
      "learning_rate": 0.019743810159807074,
      "loss": 2.4275,
      "step": 499400
    },
    {
      "epoch": 802.93,
      "learning_rate": 0.019740594728938906,
      "loss": 2.4434,
      "step": 499420
    },
    {
      "epoch": 802.96,
      "learning_rate": 0.019737379298070734,
      "loss": 2.4704,
      "step": 499440
    },
    {
      "epoch": 802.99,
      "learning_rate": 0.019734163867202576,
      "loss": 2.4416,
      "step": 499460
    },
    {
      "epoch": 803.0,
      "eval_accuracy": {
        "accuracy": 0.4505169867060561
      },
      "eval_loss": 2.5632591247558594,
      "eval_runtime": 3.0993,
      "eval_samples_per_second": 4150.293,
      "eval_steps_per_second": 64.853,
      "step": 499466
    },
    {
      "epoch": 803.02,
      "learning_rate": 0.019730948436334408,
      "loss": 2.4485,
      "step": 499480
    },
    {
      "epoch": 803.05,
      "learning_rate": 0.01972773300546624,
      "loss": 2.4393,
      "step": 499500
    },
    {
      "epoch": 803.09,
      "learning_rate": 0.01972451757459807,
      "loss": 2.4429,
      "step": 499520
    },
    {
      "epoch": 803.12,
      "learning_rate": 0.0197213021437299,
      "loss": 2.4471,
      "step": 499540
    },
    {
      "epoch": 803.15,
      "learning_rate": 0.01971808671286173,
      "loss": 2.4574,
      "step": 499560
    },
    {
      "epoch": 803.18,
      "learning_rate": 0.019715032053536974,
      "loss": 2.4213,
      "step": 499580
    },
    {
      "epoch": 803.22,
      "learning_rate": 0.019711816622668816,
      "loss": 2.4358,
      "step": 499600
    },
    {
      "epoch": 803.25,
      "learning_rate": 0.019708601191800647,
      "loss": 2.4261,
      "step": 499620
    },
    {
      "epoch": 803.28,
      "learning_rate": 0.019705385760932476,
      "loss": 2.4446,
      "step": 499640
    },
    {
      "epoch": 803.31,
      "learning_rate": 0.019702170330064307,
      "loss": 2.4462,
      "step": 499660
    },
    {
      "epoch": 803.34,
      "learning_rate": 0.01969895489919614,
      "loss": 2.4107,
      "step": 499680
    },
    {
      "epoch": 803.38,
      "learning_rate": 0.01969573946832797,
      "loss": 2.447,
      "step": 499700
    },
    {
      "epoch": 803.41,
      "learning_rate": 0.019692524037459812,
      "loss": 2.4626,
      "step": 499720
    },
    {
      "epoch": 803.44,
      "learning_rate": 0.019689308606591644,
      "loss": 2.4242,
      "step": 499740
    },
    {
      "epoch": 803.47,
      "learning_rate": 0.019686093175723472,
      "loss": 2.4387,
      "step": 499760
    },
    {
      "epoch": 803.5,
      "learning_rate": 0.019682877744855304,
      "loss": 2.4578,
      "step": 499780
    },
    {
      "epoch": 803.54,
      "learning_rate": 0.019679662313987135,
      "loss": 2.4567,
      "step": 499800
    },
    {
      "epoch": 803.57,
      "learning_rate": 0.019676446883118967,
      "loss": 2.426,
      "step": 499820
    },
    {
      "epoch": 803.6,
      "learning_rate": 0.01967323145225081,
      "loss": 2.4359,
      "step": 499840
    },
    {
      "epoch": 803.63,
      "learning_rate": 0.019670016021382637,
      "loss": 2.4301,
      "step": 499860
    },
    {
      "epoch": 803.67,
      "learning_rate": 0.01966680059051447,
      "loss": 2.4147,
      "step": 499880
    },
    {
      "epoch": 803.7,
      "learning_rate": 0.0196635851596463,
      "loss": 2.4307,
      "step": 499900
    },
    {
      "epoch": 803.73,
      "learning_rate": 0.019660369728778132,
      "loss": 2.4143,
      "step": 499920
    },
    {
      "epoch": 803.76,
      "learning_rate": 0.019657154297909974,
      "loss": 2.4301,
      "step": 499940
    },
    {
      "epoch": 803.79,
      "learning_rate": 0.019653938867041802,
      "loss": 2.4485,
      "step": 499960
    },
    {
      "epoch": 803.83,
      "learning_rate": 0.019650723436173634,
      "loss": 2.4353,
      "step": 499980
    },
    {
      "epoch": 803.86,
      "learning_rate": 0.019647508005305465,
      "loss": 2.4244,
      "step": 500000
    },
    {
      "epoch": 803.89,
      "learning_rate": 0.019644292574437297,
      "loss": 2.4429,
      "step": 500020
    },
    {
      "epoch": 803.92,
      "learning_rate": 0.01964107714356913,
      "loss": 2.4386,
      "step": 500040
    },
    {
      "epoch": 803.95,
      "learning_rate": 0.01963786171270097,
      "loss": 2.4475,
      "step": 500060
    },
    {
      "epoch": 803.99,
      "learning_rate": 0.0196346462818328,
      "loss": 2.4419,
      "step": 500080
    },
    {
      "epoch": 804.0,
      "eval_accuracy": {
        "accuracy": 0.4514498950478116
      },
      "eval_loss": 2.5554356575012207,
      "eval_runtime": 3.3346,
      "eval_samples_per_second": 3857.452,
      "eval_steps_per_second": 60.277,
      "step": 500088
    },
    {
      "epoch": 804.02,
      "learning_rate": 0.01963143085096463,
      "loss": 2.4195,
      "step": 500100
    },
    {
      "epoch": 804.05,
      "learning_rate": 0.019628215420096462,
      "loss": 2.4215,
      "step": 500120
    },
    {
      "epoch": 804.08,
      "learning_rate": 0.019624999989228294,
      "loss": 2.4267,
      "step": 500140
    },
    {
      "epoch": 804.12,
      "learning_rate": 0.019621784558360122,
      "loss": 2.4238,
      "step": 500160
    },
    {
      "epoch": 804.15,
      "learning_rate": 0.019618569127491964,
      "loss": 2.4534,
      "step": 500180
    },
    {
      "epoch": 804.18,
      "learning_rate": 0.019615353696623795,
      "loss": 2.4282,
      "step": 500200
    },
    {
      "epoch": 804.21,
      "learning_rate": 0.019612138265755627,
      "loss": 2.4284,
      "step": 500220
    },
    {
      "epoch": 804.24,
      "learning_rate": 0.01960892283488746,
      "loss": 2.4367,
      "step": 500240
    },
    {
      "epoch": 804.28,
      "learning_rate": 0.019605707404019287,
      "loss": 2.4317,
      "step": 500260
    },
    {
      "epoch": 804.31,
      "learning_rate": 0.01960249197315113,
      "loss": 2.4242,
      "step": 500280
    },
    {
      "epoch": 804.34,
      "learning_rate": 0.01959927654228296,
      "loss": 2.4416,
      "step": 500300
    },
    {
      "epoch": 804.37,
      "learning_rate": 0.019596061111414792,
      "loss": 2.4369,
      "step": 500320
    },
    {
      "epoch": 804.41,
      "learning_rate": 0.019592845680546624,
      "loss": 2.4272,
      "step": 500340
    },
    {
      "epoch": 804.44,
      "learning_rate": 0.019589630249678455,
      "loss": 2.4507,
      "step": 500360
    },
    {
      "epoch": 804.47,
      "learning_rate": 0.019586414818810283,
      "loss": 2.4533,
      "step": 500380
    },
    {
      "epoch": 804.5,
      "learning_rate": 0.019583199387942125,
      "loss": 2.4299,
      "step": 500400
    },
    {
      "epoch": 804.53,
      "learning_rate": 0.019579983957073957,
      "loss": 2.4333,
      "step": 500420
    },
    {
      "epoch": 804.57,
      "learning_rate": 0.01957676852620579,
      "loss": 2.4482,
      "step": 500440
    },
    {
      "epoch": 804.6,
      "learning_rate": 0.01957355309533762,
      "loss": 2.4376,
      "step": 500460
    },
    {
      "epoch": 804.63,
      "learning_rate": 0.01957033766446945,
      "loss": 2.4317,
      "step": 500480
    },
    {
      "epoch": 804.66,
      "learning_rate": 0.01956712223360128,
      "loss": 2.445,
      "step": 500500
    },
    {
      "epoch": 804.69,
      "learning_rate": 0.019563906802733122,
      "loss": 2.4423,
      "step": 500520
    },
    {
      "epoch": 804.73,
      "learning_rate": 0.019560691371864954,
      "loss": 2.449,
      "step": 500540
    },
    {
      "epoch": 804.76,
      "learning_rate": 0.019557475940996785,
      "loss": 2.439,
      "step": 500560
    },
    {
      "epoch": 804.79,
      "learning_rate": 0.019554260510128613,
      "loss": 2.4563,
      "step": 500580
    },
    {
      "epoch": 804.82,
      "learning_rate": 0.019551045079260445,
      "loss": 2.4615,
      "step": 500600
    },
    {
      "epoch": 804.86,
      "learning_rate": 0.019547829648392287,
      "loss": 2.4262,
      "step": 500620
    },
    {
      "epoch": 804.89,
      "learning_rate": 0.01954461421752412,
      "loss": 2.4253,
      "step": 500640
    },
    {
      "epoch": 804.92,
      "learning_rate": 0.01954139878665595,
      "loss": 2.437,
      "step": 500660
    },
    {
      "epoch": 804.95,
      "learning_rate": 0.019538183355787782,
      "loss": 2.423,
      "step": 500680
    },
    {
      "epoch": 804.98,
      "learning_rate": 0.01953496792491961,
      "loss": 2.4574,
      "step": 500700
    },
    {
      "epoch": 805.0,
      "eval_accuracy": {
        "accuracy": 0.4521495763041281
      },
      "eval_loss": 2.5438365936279297,
      "eval_runtime": 3.4161,
      "eval_samples_per_second": 3765.435,
      "eval_steps_per_second": 58.84,
      "step": 500710
    },
    {
      "epoch": 805.02,
      "learning_rate": 0.01953175249405144,
      "loss": 2.441,
      "step": 500720
    },
    {
      "epoch": 805.05,
      "learning_rate": 0.019528537063183284,
      "loss": 2.439,
      "step": 500740
    },
    {
      "epoch": 805.08,
      "learning_rate": 0.019525321632315115,
      "loss": 2.4294,
      "step": 500760
    },
    {
      "epoch": 805.11,
      "learning_rate": 0.019522106201446947,
      "loss": 2.4255,
      "step": 500780
    },
    {
      "epoch": 805.14,
      "learning_rate": 0.019518890770578775,
      "loss": 2.4377,
      "step": 500800
    },
    {
      "epoch": 805.18,
      "learning_rate": 0.019515675339710607,
      "loss": 2.4258,
      "step": 500820
    },
    {
      "epoch": 805.21,
      "learning_rate": 0.01951245990884245,
      "loss": 2.4235,
      "step": 500840
    },
    {
      "epoch": 805.24,
      "learning_rate": 0.01950924447797428,
      "loss": 2.4514,
      "step": 500860
    },
    {
      "epoch": 805.27,
      "learning_rate": 0.019506029047106112,
      "loss": 2.4449,
      "step": 500880
    },
    {
      "epoch": 805.31,
      "learning_rate": 0.01950281361623794,
      "loss": 2.4398,
      "step": 500900
    },
    {
      "epoch": 805.34,
      "learning_rate": 0.01949959818536977,
      "loss": 2.43,
      "step": 500920
    },
    {
      "epoch": 805.37,
      "learning_rate": 0.019496382754501603,
      "loss": 2.4291,
      "step": 500940
    },
    {
      "epoch": 805.4,
      "learning_rate": 0.019493167323633445,
      "loss": 2.4435,
      "step": 500960
    },
    {
      "epoch": 805.43,
      "learning_rate": 0.019489951892765277,
      "loss": 2.4366,
      "step": 500980
    },
    {
      "epoch": 805.47,
      "learning_rate": 0.01948673646189711,
      "loss": 2.4348,
      "step": 501000
    },
    {
      "epoch": 805.5,
      "learning_rate": 0.019483521031028937,
      "loss": 2.434,
      "step": 501020
    },
    {
      "epoch": 805.53,
      "learning_rate": 0.019480305600160768,
      "loss": 2.4422,
      "step": 501040
    },
    {
      "epoch": 805.56,
      "learning_rate": 0.0194770901692926,
      "loss": 2.4249,
      "step": 501060
    },
    {
      "epoch": 805.59,
      "learning_rate": 0.019473874738424442,
      "loss": 2.4357,
      "step": 501080
    },
    {
      "epoch": 805.63,
      "learning_rate": 0.019470659307556273,
      "loss": 2.4237,
      "step": 501100
    },
    {
      "epoch": 805.66,
      "learning_rate": 0.0194674438766881,
      "loss": 2.4351,
      "step": 501120
    },
    {
      "epoch": 805.69,
      "learning_rate": 0.019464228445819933,
      "loss": 2.409,
      "step": 501140
    },
    {
      "epoch": 805.72,
      "learning_rate": 0.019461013014951765,
      "loss": 2.4396,
      "step": 501160
    },
    {
      "epoch": 805.76,
      "learning_rate": 0.019457797584083607,
      "loss": 2.423,
      "step": 501180
    },
    {
      "epoch": 805.79,
      "learning_rate": 0.01945458215321544,
      "loss": 2.4316,
      "step": 501200
    },
    {
      "epoch": 805.82,
      "learning_rate": 0.019451366722347267,
      "loss": 2.4413,
      "step": 501220
    },
    {
      "epoch": 805.85,
      "learning_rate": 0.019448151291479098,
      "loss": 2.4505,
      "step": 501240
    },
    {
      "epoch": 805.88,
      "learning_rate": 0.01944493586061093,
      "loss": 2.4326,
      "step": 501260
    },
    {
      "epoch": 805.92,
      "learning_rate": 0.01944172042974276,
      "loss": 2.4483,
      "step": 501280
    },
    {
      "epoch": 805.95,
      "learning_rate": 0.019438504998874603,
      "loss": 2.4341,
      "step": 501300
    },
    {
      "epoch": 805.98,
      "learning_rate": 0.019435289568006435,
      "loss": 2.4523,
      "step": 501320
    },
    {
      "epoch": 806.0,
      "eval_accuracy": {
        "accuracy": 0.45393765062582603
      },
      "eval_loss": 2.5406334400177,
      "eval_runtime": 3.1765,
      "eval_samples_per_second": 4049.447,
      "eval_steps_per_second": 63.278,
      "step": 501332
    },
    {
      "epoch": 806.01,
      "learning_rate": 0.019432074137138263,
      "loss": 2.4584,
      "step": 501340
    },
    {
      "epoch": 806.05,
      "learning_rate": 0.019428858706270095,
      "loss": 2.4453,
      "step": 501360
    },
    {
      "epoch": 806.08,
      "learning_rate": 0.019425643275401926,
      "loss": 2.4336,
      "step": 501380
    },
    {
      "epoch": 806.11,
      "learning_rate": 0.019422427844533758,
      "loss": 2.4547,
      "step": 501400
    },
    {
      "epoch": 806.14,
      "learning_rate": 0.0194192124136656,
      "loss": 2.44,
      "step": 501420
    },
    {
      "epoch": 806.17,
      "learning_rate": 0.019415996982797428,
      "loss": 2.4302,
      "step": 501440
    },
    {
      "epoch": 806.21,
      "learning_rate": 0.01941278155192926,
      "loss": 2.4296,
      "step": 501460
    },
    {
      "epoch": 806.24,
      "learning_rate": 0.01940956612106109,
      "loss": 2.4207,
      "step": 501480
    },
    {
      "epoch": 806.27,
      "learning_rate": 0.019406350690192923,
      "loss": 2.4339,
      "step": 501500
    },
    {
      "epoch": 806.3,
      "learning_rate": 0.019403135259324765,
      "loss": 2.433,
      "step": 501520
    },
    {
      "epoch": 806.33,
      "learning_rate": 0.019399919828456593,
      "loss": 2.4327,
      "step": 501540
    },
    {
      "epoch": 806.37,
      "learning_rate": 0.019396704397588425,
      "loss": 2.4358,
      "step": 501560
    },
    {
      "epoch": 806.4,
      "learning_rate": 0.019393488966720256,
      "loss": 2.4392,
      "step": 501580
    },
    {
      "epoch": 806.43,
      "learning_rate": 0.019390273535852088,
      "loss": 2.4454,
      "step": 501600
    },
    {
      "epoch": 806.46,
      "learning_rate": 0.01938705810498392,
      "loss": 2.4289,
      "step": 501620
    },
    {
      "epoch": 806.5,
      "learning_rate": 0.01938384267411576,
      "loss": 2.4252,
      "step": 501640
    },
    {
      "epoch": 806.53,
      "learning_rate": 0.01938062724324759,
      "loss": 2.4402,
      "step": 501660
    },
    {
      "epoch": 806.56,
      "learning_rate": 0.01937741181237942,
      "loss": 2.431,
      "step": 501680
    },
    {
      "epoch": 806.59,
      "learning_rate": 0.019374196381511253,
      "loss": 2.448,
      "step": 501700
    },
    {
      "epoch": 806.62,
      "learning_rate": 0.019370980950643085,
      "loss": 2.4276,
      "step": 501720
    },
    {
      "epoch": 806.66,
      "learning_rate": 0.019367765519774913,
      "loss": 2.4394,
      "step": 501740
    },
    {
      "epoch": 806.69,
      "learning_rate": 0.019364550088906755,
      "loss": 2.4386,
      "step": 501760
    },
    {
      "epoch": 806.72,
      "learning_rate": 0.019361334658038586,
      "loss": 2.4255,
      "step": 501780
    },
    {
      "epoch": 806.75,
      "learning_rate": 0.019358119227170418,
      "loss": 2.4585,
      "step": 501800
    },
    {
      "epoch": 806.78,
      "learning_rate": 0.01935490379630225,
      "loss": 2.4397,
      "step": 501820
    },
    {
      "epoch": 806.82,
      "learning_rate": 0.01935168836543408,
      "loss": 2.4578,
      "step": 501840
    },
    {
      "epoch": 806.85,
      "learning_rate": 0.019348472934565923,
      "loss": 2.4381,
      "step": 501860
    },
    {
      "epoch": 806.88,
      "learning_rate": 0.01934525750369775,
      "loss": 2.4252,
      "step": 501880
    },
    {
      "epoch": 806.91,
      "learning_rate": 0.019342042072829583,
      "loss": 2.4471,
      "step": 501900
    },
    {
      "epoch": 806.95,
      "learning_rate": 0.019338826641961415,
      "loss": 2.4388,
      "step": 501920
    },
    {
      "epoch": 806.98,
      "learning_rate": 0.019335611211093246,
      "loss": 2.4347,
      "step": 501940
    },
    {
      "epoch": 807.0,
      "eval_accuracy": {
        "accuracy": 0.4521495763041281
      },
      "eval_loss": 2.5504038333892822,
      "eval_runtime": 3.2134,
      "eval_samples_per_second": 4002.951,
      "eval_steps_per_second": 62.551,
      "step": 501954
    },
    {
      "epoch": 807.01,
      "learning_rate": 0.019332395780225074,
      "loss": 2.4428,
      "step": 501960
    },
    {
      "epoch": 807.04,
      "learning_rate": 0.019329180349356916,
      "loss": 2.4453,
      "step": 501980
    },
    {
      "epoch": 807.07,
      "learning_rate": 0.019325964918488748,
      "loss": 2.4356,
      "step": 502000
    },
    {
      "epoch": 807.11,
      "learning_rate": 0.01932274948762058,
      "loss": 2.4354,
      "step": 502020
    },
    {
      "epoch": 807.14,
      "learning_rate": 0.01931953405675241,
      "loss": 2.4404,
      "step": 502040
    },
    {
      "epoch": 807.17,
      "learning_rate": 0.01931631862588424,
      "loss": 2.4302,
      "step": 502060
    },
    {
      "epoch": 807.2,
      "learning_rate": 0.01931310319501607,
      "loss": 2.4628,
      "step": 502080
    },
    {
      "epoch": 807.23,
      "learning_rate": 0.019309887764147913,
      "loss": 2.4426,
      "step": 502100
    },
    {
      "epoch": 807.27,
      "learning_rate": 0.019306672333279744,
      "loss": 2.4365,
      "step": 502120
    },
    {
      "epoch": 807.3,
      "learning_rate": 0.019303456902411576,
      "loss": 2.4165,
      "step": 502140
    },
    {
      "epoch": 807.33,
      "learning_rate": 0.019300241471543408,
      "loss": 2.4424,
      "step": 502160
    },
    {
      "epoch": 807.36,
      "learning_rate": 0.019297026040675236,
      "loss": 2.4109,
      "step": 502180
    },
    {
      "epoch": 807.4,
      "learning_rate": 0.019293810609807078,
      "loss": 2.4182,
      "step": 502200
    },
    {
      "epoch": 807.43,
      "learning_rate": 0.01929059517893891,
      "loss": 2.4344,
      "step": 502220
    },
    {
      "epoch": 807.46,
      "learning_rate": 0.01928737974807074,
      "loss": 2.4481,
      "step": 502240
    },
    {
      "epoch": 807.49,
      "learning_rate": 0.019284164317202573,
      "loss": 2.422,
      "step": 502260
    },
    {
      "epoch": 807.52,
      "learning_rate": 0.0192809488863344,
      "loss": 2.4214,
      "step": 502280
    },
    {
      "epoch": 807.56,
      "learning_rate": 0.019277733455466232,
      "loss": 2.4534,
      "step": 502300
    },
    {
      "epoch": 807.59,
      "learning_rate": 0.019274518024598074,
      "loss": 2.4435,
      "step": 502320
    },
    {
      "epoch": 807.62,
      "learning_rate": 0.019271302593729906,
      "loss": 2.441,
      "step": 502340
    },
    {
      "epoch": 807.65,
      "learning_rate": 0.019268087162861738,
      "loss": 2.4444,
      "step": 502360
    },
    {
      "epoch": 807.68,
      "learning_rate": 0.019264871731993566,
      "loss": 2.4384,
      "step": 502380
    },
    {
      "epoch": 807.72,
      "learning_rate": 0.019261656301125397,
      "loss": 2.4376,
      "step": 502400
    },
    {
      "epoch": 807.75,
      "learning_rate": 0.01925844087025723,
      "loss": 2.4355,
      "step": 502420
    },
    {
      "epoch": 807.78,
      "learning_rate": 0.01925522543938907,
      "loss": 2.4309,
      "step": 502440
    },
    {
      "epoch": 807.81,
      "learning_rate": 0.019252010008520903,
      "loss": 2.4279,
      "step": 502460
    },
    {
      "epoch": 807.85,
      "learning_rate": 0.019248794577652734,
      "loss": 2.4331,
      "step": 502480
    },
    {
      "epoch": 807.88,
      "learning_rate": 0.019245579146784562,
      "loss": 2.4271,
      "step": 502500
    },
    {
      "epoch": 807.91,
      "learning_rate": 0.019242363715916394,
      "loss": 2.4426,
      "step": 502520
    },
    {
      "epoch": 807.94,
      "learning_rate": 0.019239148285048236,
      "loss": 2.4327,
      "step": 502540
    },
    {
      "epoch": 807.97,
      "learning_rate": 0.019235932854180068,
      "loss": 2.4297,
      "step": 502560
    },
    {
      "epoch": 808.0,
      "eval_accuracy": {
        "accuracy": 0.45510378605302027
      },
      "eval_loss": 2.5576603412628174,
      "eval_runtime": 3.2904,
      "eval_samples_per_second": 3909.209,
      "eval_steps_per_second": 61.086,
      "step": 502576
    },
    {
      "epoch": 808.01,
      "learning_rate": 0.0192327174233119,
      "loss": 2.4414,
      "step": 502580
    },
    {
      "epoch": 808.04,
      "learning_rate": 0.019229501992443727,
      "loss": 2.4133,
      "step": 502600
    },
    {
      "epoch": 808.07,
      "learning_rate": 0.01922628656157556,
      "loss": 2.441,
      "step": 502620
    },
    {
      "epoch": 808.1,
      "learning_rate": 0.01922307113070739,
      "loss": 2.425,
      "step": 502640
    },
    {
      "epoch": 808.14,
      "learning_rate": 0.019219855699839233,
      "loss": 2.4255,
      "step": 502660
    },
    {
      "epoch": 808.17,
      "learning_rate": 0.019216640268971064,
      "loss": 2.4385,
      "step": 502680
    },
    {
      "epoch": 808.2,
      "learning_rate": 0.019213424838102892,
      "loss": 2.4384,
      "step": 502700
    },
    {
      "epoch": 808.23,
      "learning_rate": 0.019210209407234724,
      "loss": 2.4432,
      "step": 502720
    },
    {
      "epoch": 808.26,
      "learning_rate": 0.019206993976366556,
      "loss": 2.4409,
      "step": 502740
    },
    {
      "epoch": 808.3,
      "learning_rate": 0.019203778545498398,
      "loss": 2.4363,
      "step": 502760
    },
    {
      "epoch": 808.33,
      "learning_rate": 0.01920056311463023,
      "loss": 2.4164,
      "step": 502780
    },
    {
      "epoch": 808.36,
      "learning_rate": 0.01919734768376206,
      "loss": 2.4167,
      "step": 502800
    },
    {
      "epoch": 808.39,
      "learning_rate": 0.01919413225289389,
      "loss": 2.4306,
      "step": 502820
    },
    {
      "epoch": 808.42,
      "learning_rate": 0.01919091682202572,
      "loss": 2.4497,
      "step": 502840
    },
    {
      "epoch": 808.46,
      "learning_rate": 0.019187701391157552,
      "loss": 2.4405,
      "step": 502860
    },
    {
      "epoch": 808.49,
      "learning_rate": 0.019184485960289394,
      "loss": 2.4276,
      "step": 502880
    },
    {
      "epoch": 808.52,
      "learning_rate": 0.019181270529421226,
      "loss": 2.4396,
      "step": 502900
    },
    {
      "epoch": 808.55,
      "learning_rate": 0.019178055098553054,
      "loss": 2.4454,
      "step": 502920
    },
    {
      "epoch": 808.59,
      "learning_rate": 0.019174839667684886,
      "loss": 2.439,
      "step": 502940
    },
    {
      "epoch": 808.62,
      "learning_rate": 0.019171624236816717,
      "loss": 2.4114,
      "step": 502960
    },
    {
      "epoch": 808.65,
      "learning_rate": 0.01916840880594855,
      "loss": 2.4384,
      "step": 502980
    },
    {
      "epoch": 808.68,
      "learning_rate": 0.01916519337508039,
      "loss": 2.4327,
      "step": 503000
    },
    {
      "epoch": 808.71,
      "learning_rate": 0.01916197794421222,
      "loss": 2.4385,
      "step": 503020
    },
    {
      "epoch": 808.75,
      "learning_rate": 0.01915876251334405,
      "loss": 2.4343,
      "step": 503040
    },
    {
      "epoch": 808.78,
      "learning_rate": 0.019155547082475882,
      "loss": 2.4261,
      "step": 503060
    },
    {
      "epoch": 808.81,
      "learning_rate": 0.019152331651607714,
      "loss": 2.4376,
      "step": 503080
    },
    {
      "epoch": 808.84,
      "learning_rate": 0.019149116220739556,
      "loss": 2.4559,
      "step": 503100
    },
    {
      "epoch": 808.87,
      "learning_rate": 0.019145900789871387,
      "loss": 2.4297,
      "step": 503120
    },
    {
      "epoch": 808.91,
      "learning_rate": 0.019142685359003216,
      "loss": 2.4194,
      "step": 503140
    },
    {
      "epoch": 808.94,
      "learning_rate": 0.019139469928135047,
      "loss": 2.4222,
      "step": 503160
    },
    {
      "epoch": 808.97,
      "learning_rate": 0.01913625449726688,
      "loss": 2.4476,
      "step": 503180
    },
    {
      "epoch": 809.0,
      "eval_accuracy": {
        "accuracy": 0.45253828811319285
      },
      "eval_loss": 2.5609700679779053,
      "eval_runtime": 3.2126,
      "eval_samples_per_second": 4003.888,
      "eval_steps_per_second": 62.566,
      "step": 503198
    },
    {
      "epoch": 809.0,
      "learning_rate": 0.01913303906639871,
      "loss": 2.4299,
      "step": 503200
    },
    {
      "epoch": 809.04,
      "learning_rate": 0.019129823635530552,
      "loss": 2.4228,
      "step": 503220
    },
    {
      "epoch": 809.07,
      "learning_rate": 0.019126768976205792,
      "loss": 2.4595,
      "step": 503240
    },
    {
      "epoch": 809.1,
      "learning_rate": 0.019123553545337624,
      "loss": 2.4332,
      "step": 503260
    },
    {
      "epoch": 809.13,
      "learning_rate": 0.019120338114469455,
      "loss": 2.453,
      "step": 503280
    },
    {
      "epoch": 809.16,
      "learning_rate": 0.019117122683601287,
      "loss": 2.4462,
      "step": 503300
    },
    {
      "epoch": 809.2,
      "learning_rate": 0.019113907252733115,
      "loss": 2.4301,
      "step": 503320
    },
    {
      "epoch": 809.23,
      "learning_rate": 0.019110691821864947,
      "loss": 2.4614,
      "step": 503340
    },
    {
      "epoch": 809.26,
      "learning_rate": 0.01910747639099679,
      "loss": 2.4312,
      "step": 503360
    },
    {
      "epoch": 809.29,
      "learning_rate": 0.01910426096012862,
      "loss": 2.4187,
      "step": 503380
    },
    {
      "epoch": 809.32,
      "learning_rate": 0.019101045529260452,
      "loss": 2.4359,
      "step": 503400
    },
    {
      "epoch": 809.36,
      "learning_rate": 0.01909783009839228,
      "loss": 2.4258,
      "step": 503420
    },
    {
      "epoch": 809.39,
      "learning_rate": 0.01909461466752411,
      "loss": 2.4325,
      "step": 503440
    },
    {
      "epoch": 809.42,
      "learning_rate": 0.019091399236655943,
      "loss": 2.4238,
      "step": 503460
    },
    {
      "epoch": 809.45,
      "learning_rate": 0.019088183805787785,
      "loss": 2.4385,
      "step": 503480
    },
    {
      "epoch": 809.49,
      "learning_rate": 0.019084968374919617,
      "loss": 2.4532,
      "step": 503500
    },
    {
      "epoch": 809.52,
      "learning_rate": 0.01908175294405145,
      "loss": 2.4173,
      "step": 503520
    },
    {
      "epoch": 809.55,
      "learning_rate": 0.019078537513183277,
      "loss": 2.4176,
      "step": 503540
    },
    {
      "epoch": 809.58,
      "learning_rate": 0.01907532208231511,
      "loss": 2.4221,
      "step": 503560
    },
    {
      "epoch": 809.61,
      "learning_rate": 0.01907210665144695,
      "loss": 2.4197,
      "step": 503580
    },
    {
      "epoch": 809.65,
      "learning_rate": 0.019068891220578782,
      "loss": 2.4385,
      "step": 503600
    },
    {
      "epoch": 809.68,
      "learning_rate": 0.019065675789710614,
      "loss": 2.4157,
      "step": 503620
    },
    {
      "epoch": 809.71,
      "learning_rate": 0.01906246035884244,
      "loss": 2.425,
      "step": 503640
    },
    {
      "epoch": 809.74,
      "learning_rate": 0.019059244927974273,
      "loss": 2.4375,
      "step": 503660
    },
    {
      "epoch": 809.77,
      "learning_rate": 0.019056029497106105,
      "loss": 2.4299,
      "step": 503680
    },
    {
      "epoch": 809.81,
      "learning_rate": 0.019052814066237947,
      "loss": 2.4454,
      "step": 503700
    },
    {
      "epoch": 809.84,
      "learning_rate": 0.01904959863536978,
      "loss": 2.4345,
      "step": 503720
    },
    {
      "epoch": 809.87,
      "learning_rate": 0.019046383204501607,
      "loss": 2.4293,
      "step": 503740
    },
    {
      "epoch": 809.9,
      "learning_rate": 0.01904316777363344,
      "loss": 2.4327,
      "step": 503760
    },
    {
      "epoch": 809.94,
      "learning_rate": 0.01903995234276527,
      "loss": 2.4158,
      "step": 503780
    },
    {
      "epoch": 809.97,
      "learning_rate": 0.0190367369118971,
      "loss": 2.4328,
      "step": 503800
    },
    {
      "epoch": 810.0,
      "learning_rate": 0.019033521481028944,
      "loss": 2.4217,
      "step": 503820
    },
    {
      "epoch": 810.0,
      "eval_accuracy": {
        "accuracy": 0.4552592707766462
      },
      "eval_loss": 2.5559988021850586,
      "eval_runtime": 3.3238,
      "eval_samples_per_second": 3869.978,
      "eval_steps_per_second": 60.473,
      "step": 503820
    },
    {
      "epoch": 810.03,
      "learning_rate": 0.019030306050160775,
      "loss": 2.4189,
      "step": 503840
    },
    {
      "epoch": 810.06,
      "learning_rate": 0.019027090619292603,
      "loss": 2.4395,
      "step": 503860
    },
    {
      "epoch": 810.1,
      "learning_rate": 0.019023875188424435,
      "loss": 2.4247,
      "step": 503880
    },
    {
      "epoch": 810.13,
      "learning_rate": 0.019020659757556267,
      "loss": 2.4202,
      "step": 503900
    },
    {
      "epoch": 810.16,
      "learning_rate": 0.01901744432668811,
      "loss": 2.4332,
      "step": 503920
    },
    {
      "epoch": 810.19,
      "learning_rate": 0.01901422889581994,
      "loss": 2.4262,
      "step": 503940
    },
    {
      "epoch": 810.23,
      "learning_rate": 0.01901101346495177,
      "loss": 2.4161,
      "step": 503960
    },
    {
      "epoch": 810.26,
      "learning_rate": 0.0190077980340836,
      "loss": 2.4466,
      "step": 503980
    },
    {
      "epoch": 810.29,
      "learning_rate": 0.01900458260321543,
      "loss": 2.4145,
      "step": 504000
    },
    {
      "epoch": 810.32,
      "learning_rate": 0.019001367172347263,
      "loss": 2.4374,
      "step": 504020
    },
    {
      "epoch": 810.35,
      "learning_rate": 0.018998151741479105,
      "loss": 2.4366,
      "step": 504040
    },
    {
      "epoch": 810.39,
      "learning_rate": 0.018994936310610937,
      "loss": 2.4391,
      "step": 504060
    },
    {
      "epoch": 810.42,
      "learning_rate": 0.018991720879742765,
      "loss": 2.4146,
      "step": 504080
    },
    {
      "epoch": 810.45,
      "learning_rate": 0.018988505448874596,
      "loss": 2.4432,
      "step": 504100
    },
    {
      "epoch": 810.48,
      "learning_rate": 0.018985290018006428,
      "loss": 2.4177,
      "step": 504120
    },
    {
      "epoch": 810.51,
      "learning_rate": 0.01898207458713826,
      "loss": 2.4115,
      "step": 504140
    },
    {
      "epoch": 810.55,
      "learning_rate": 0.0189788591562701,
      "loss": 2.4439,
      "step": 504160
    },
    {
      "epoch": 810.58,
      "learning_rate": 0.01897564372540193,
      "loss": 2.4527,
      "step": 504180
    },
    {
      "epoch": 810.61,
      "learning_rate": 0.01897242829453376,
      "loss": 2.4432,
      "step": 504200
    },
    {
      "epoch": 810.64,
      "learning_rate": 0.018969212863665593,
      "loss": 2.4206,
      "step": 504220
    },
    {
      "epoch": 810.68,
      "learning_rate": 0.018965997432797425,
      "loss": 2.4362,
      "step": 504240
    },
    {
      "epoch": 810.71,
      "learning_rate": 0.018962782001929267,
      "loss": 2.4247,
      "step": 504260
    },
    {
      "epoch": 810.74,
      "learning_rate": 0.018959566571061095,
      "loss": 2.4341,
      "step": 504280
    },
    {
      "epoch": 810.77,
      "learning_rate": 0.018956351140192926,
      "loss": 2.4241,
      "step": 504300
    },
    {
      "epoch": 810.8,
      "learning_rate": 0.018953135709324758,
      "loss": 2.4331,
      "step": 504320
    },
    {
      "epoch": 810.84,
      "learning_rate": 0.01894992027845659,
      "loss": 2.4296,
      "step": 504340
    },
    {
      "epoch": 810.87,
      "learning_rate": 0.01894670484758842,
      "loss": 2.4383,
      "step": 504360
    },
    {
      "epoch": 810.9,
      "learning_rate": 0.018943489416720263,
      "loss": 2.4316,
      "step": 504380
    },
    {
      "epoch": 810.93,
      "learning_rate": 0.01894027398585209,
      "loss": 2.4537,
      "step": 504400
    },
    {
      "epoch": 810.96,
      "learning_rate": 0.018937058554983923,
      "loss": 2.4394,
      "step": 504420
    },
    {
      "epoch": 811.0,
      "learning_rate": 0.018933843124115755,
      "loss": 2.425,
      "step": 504440
    },
    {
      "epoch": 811.0,
      "eval_accuracy": {
        "accuracy": 0.454015392987639
      },
      "eval_loss": 2.5526130199432373,
      "eval_runtime": 3.1174,
      "eval_samples_per_second": 4126.148,
      "eval_steps_per_second": 64.476,
      "step": 504442
    },
    {
      "epoch": 811.03,
      "learning_rate": 0.018930627693247586,
      "loss": 2.4257,
      "step": 504460
    },
    {
      "epoch": 811.06,
      "learning_rate": 0.018927412262379414,
      "loss": 2.4052,
      "step": 504480
    },
    {
      "epoch": 811.09,
      "learning_rate": 0.018924196831511256,
      "loss": 2.4252,
      "step": 504500
    },
    {
      "epoch": 811.13,
      "learning_rate": 0.018920981400643088,
      "loss": 2.4485,
      "step": 504520
    },
    {
      "epoch": 811.16,
      "learning_rate": 0.01891776596977492,
      "loss": 2.4452,
      "step": 504540
    },
    {
      "epoch": 811.19,
      "learning_rate": 0.01891455053890675,
      "loss": 2.429,
      "step": 504560
    },
    {
      "epoch": 811.22,
      "learning_rate": 0.01891133510803858,
      "loss": 2.4221,
      "step": 504580
    },
    {
      "epoch": 811.25,
      "learning_rate": 0.01890811967717042,
      "loss": 2.4438,
      "step": 504600
    },
    {
      "epoch": 811.29,
      "learning_rate": 0.018904904246302253,
      "loss": 2.4333,
      "step": 504620
    },
    {
      "epoch": 811.32,
      "learning_rate": 0.018901688815434085,
      "loss": 2.4274,
      "step": 504640
    },
    {
      "epoch": 811.35,
      "learning_rate": 0.018898473384565916,
      "loss": 2.4531,
      "step": 504660
    },
    {
      "epoch": 811.38,
      "learning_rate": 0.018895257953697748,
      "loss": 2.4436,
      "step": 504680
    },
    {
      "epoch": 811.41,
      "learning_rate": 0.018892042522829576,
      "loss": 2.4396,
      "step": 504700
    },
    {
      "epoch": 811.45,
      "learning_rate": 0.018888827091961418,
      "loss": 2.4082,
      "step": 504720
    },
    {
      "epoch": 811.48,
      "learning_rate": 0.01888561166109325,
      "loss": 2.4195,
      "step": 504740
    },
    {
      "epoch": 811.51,
      "learning_rate": 0.01888239623022508,
      "loss": 2.4342,
      "step": 504760
    },
    {
      "epoch": 811.54,
      "learning_rate": 0.018879180799356913,
      "loss": 2.432,
      "step": 504780
    },
    {
      "epoch": 811.58,
      "learning_rate": 0.01887596536848874,
      "loss": 2.4305,
      "step": 504800
    },
    {
      "epoch": 811.61,
      "learning_rate": 0.018872749937620573,
      "loss": 2.4327,
      "step": 504820
    },
    {
      "epoch": 811.64,
      "learning_rate": 0.018869534506752415,
      "loss": 2.4364,
      "step": 504840
    },
    {
      "epoch": 811.67,
      "learning_rate": 0.018866319075884246,
      "loss": 2.4216,
      "step": 504860
    },
    {
      "epoch": 811.7,
      "learning_rate": 0.018863103645016078,
      "loss": 2.4362,
      "step": 504880
    },
    {
      "epoch": 811.74,
      "learning_rate": 0.018859888214147906,
      "loss": 2.4368,
      "step": 504900
    },
    {
      "epoch": 811.77,
      "learning_rate": 0.018856672783279738,
      "loss": 2.4353,
      "step": 504920
    },
    {
      "epoch": 811.8,
      "learning_rate": 0.01885345735241158,
      "loss": 2.432,
      "step": 504940
    },
    {
      "epoch": 811.83,
      "learning_rate": 0.01885024192154341,
      "loss": 2.4276,
      "step": 504960
    },
    {
      "epoch": 811.86,
      "learning_rate": 0.018847026490675243,
      "loss": 2.4328,
      "step": 504980
    },
    {
      "epoch": 811.9,
      "learning_rate": 0.018843811059807074,
      "loss": 2.4323,
      "step": 505000
    },
    {
      "epoch": 811.93,
      "learning_rate": 0.018840595628938903,
      "loss": 2.4201,
      "step": 505020
    },
    {
      "epoch": 811.96,
      "learning_rate": 0.018837380198070734,
      "loss": 2.4133,
      "step": 505040
    },
    {
      "epoch": 811.99,
      "learning_rate": 0.018834164767202576,
      "loss": 2.4278,
      "step": 505060
    },
    {
      "epoch": 812.0,
      "eval_accuracy": {
        "accuracy": 0.4597683277617974
      },
      "eval_loss": 2.543118715286255,
      "eval_runtime": 3.3362,
      "eval_samples_per_second": 3855.551,
      "eval_steps_per_second": 60.248,
      "step": 505064
    },
    {
      "epoch": 812.03,
      "learning_rate": 0.018830949336334408,
      "loss": 2.4349,
      "step": 505080
    },
    {
      "epoch": 812.06,
      "learning_rate": 0.01882773390546624,
      "loss": 2.4084,
      "step": 505100
    },
    {
      "epoch": 812.09,
      "learning_rate": 0.018824518474598068,
      "loss": 2.4148,
      "step": 505120
    },
    {
      "epoch": 812.12,
      "learning_rate": 0.0188213030437299,
      "loss": 2.4443,
      "step": 505140
    },
    {
      "epoch": 812.15,
      "learning_rate": 0.01881808761286174,
      "loss": 2.4232,
      "step": 505160
    },
    {
      "epoch": 812.19,
      "learning_rate": 0.018814872181993573,
      "loss": 2.4447,
      "step": 505180
    },
    {
      "epoch": 812.22,
      "learning_rate": 0.018811656751125404,
      "loss": 2.4332,
      "step": 505200
    },
    {
      "epoch": 812.25,
      "learning_rate": 0.018808441320257233,
      "loss": 2.4147,
      "step": 505220
    },
    {
      "epoch": 812.28,
      "learning_rate": 0.018805225889389064,
      "loss": 2.4231,
      "step": 505240
    },
    {
      "epoch": 812.32,
      "learning_rate": 0.018802010458520896,
      "loss": 2.4373,
      "step": 505260
    },
    {
      "epoch": 812.35,
      "learning_rate": 0.018798795027652738,
      "loss": 2.427,
      "step": 505280
    },
    {
      "epoch": 812.38,
      "learning_rate": 0.01879557959678457,
      "loss": 2.4485,
      "step": 505300
    },
    {
      "epoch": 812.41,
      "learning_rate": 0.0187923641659164,
      "loss": 2.4374,
      "step": 505320
    },
    {
      "epoch": 812.44,
      "learning_rate": 0.01878914873504823,
      "loss": 2.4164,
      "step": 505340
    },
    {
      "epoch": 812.48,
      "learning_rate": 0.01878593330418006,
      "loss": 2.435,
      "step": 505360
    },
    {
      "epoch": 812.51,
      "learning_rate": 0.018782717873311892,
      "loss": 2.4315,
      "step": 505380
    },
    {
      "epoch": 812.54,
      "learning_rate": 0.018779502442443734,
      "loss": 2.4282,
      "step": 505400
    },
    {
      "epoch": 812.57,
      "learning_rate": 0.018776287011575566,
      "loss": 2.4376,
      "step": 505420
    },
    {
      "epoch": 812.6,
      "learning_rate": 0.018773232352250806,
      "loss": 2.4219,
      "step": 505440
    },
    {
      "epoch": 812.64,
      "learning_rate": 0.018770016921382637,
      "loss": 2.4147,
      "step": 505460
    },
    {
      "epoch": 812.67,
      "learning_rate": 0.01876680149051447,
      "loss": 2.412,
      "step": 505480
    },
    {
      "epoch": 812.7,
      "learning_rate": 0.0187635860596463,
      "loss": 2.4269,
      "step": 505500
    },
    {
      "epoch": 812.73,
      "learning_rate": 0.01876037062877813,
      "loss": 2.4481,
      "step": 505520
    },
    {
      "epoch": 812.77,
      "learning_rate": 0.01875715519790997,
      "loss": 2.4292,
      "step": 505540
    },
    {
      "epoch": 812.8,
      "learning_rate": 0.018753939767041802,
      "loss": 2.4331,
      "step": 505560
    },
    {
      "epoch": 812.83,
      "learning_rate": 0.018750724336173634,
      "loss": 2.4478,
      "step": 505580
    },
    {
      "epoch": 812.86,
      "learning_rate": 0.018747508905305466,
      "loss": 2.4481,
      "step": 505600
    },
    {
      "epoch": 812.89,
      "learning_rate": 0.018744293474437294,
      "loss": 2.4398,
      "step": 505620
    },
    {
      "epoch": 812.93,
      "learning_rate": 0.018741078043569125,
      "loss": 2.4215,
      "step": 505640
    },
    {
      "epoch": 812.96,
      "learning_rate": 0.018737862612700967,
      "loss": 2.4294,
      "step": 505660
    },
    {
      "epoch": 812.99,
      "learning_rate": 0.0187346471818328,
      "loss": 2.4208,
      "step": 505680
    },
    {
      "epoch": 813.0,
      "eval_accuracy": {
        "accuracy": 0.4593018735909197
      },
      "eval_loss": 2.5422420501708984,
      "eval_runtime": 3.1061,
      "eval_samples_per_second": 4141.215,
      "eval_steps_per_second": 64.712,
      "step": 505686
    },
    {
      "epoch": 813.02,
      "learning_rate": 0.01873143175096463,
      "loss": 2.4468,
      "step": 505700
    },
    {
      "epoch": 813.05,
      "learning_rate": 0.018728216320096462,
      "loss": 2.4261,
      "step": 505720
    },
    {
      "epoch": 813.09,
      "learning_rate": 0.01872500088922829,
      "loss": 2.4363,
      "step": 505740
    },
    {
      "epoch": 813.12,
      "learning_rate": 0.018721785458360132,
      "loss": 2.4341,
      "step": 505760
    },
    {
      "epoch": 813.15,
      "learning_rate": 0.018718570027491964,
      "loss": 2.4242,
      "step": 505780
    },
    {
      "epoch": 813.18,
      "learning_rate": 0.018715354596623796,
      "loss": 2.4546,
      "step": 505800
    },
    {
      "epoch": 813.22,
      "learning_rate": 0.018712139165755627,
      "loss": 2.4169,
      "step": 505820
    },
    {
      "epoch": 813.25,
      "learning_rate": 0.018708923734887455,
      "loss": 2.4133,
      "step": 505840
    },
    {
      "epoch": 813.28,
      "learning_rate": 0.018705708304019287,
      "loss": 2.4134,
      "step": 505860
    },
    {
      "epoch": 813.31,
      "learning_rate": 0.01870249287315113,
      "loss": 2.4437,
      "step": 505880
    },
    {
      "epoch": 813.34,
      "learning_rate": 0.01869927744228296,
      "loss": 2.4217,
      "step": 505900
    },
    {
      "epoch": 813.38,
      "learning_rate": 0.018696062011414792,
      "loss": 2.423,
      "step": 505920
    },
    {
      "epoch": 813.41,
      "learning_rate": 0.018692846580546624,
      "loss": 2.4426,
      "step": 505940
    },
    {
      "epoch": 813.44,
      "learning_rate": 0.018689631149678452,
      "loss": 2.4565,
      "step": 505960
    },
    {
      "epoch": 813.47,
      "learning_rate": 0.018686415718810294,
      "loss": 2.4369,
      "step": 505980
    },
    {
      "epoch": 813.5,
      "learning_rate": 0.018683200287942126,
      "loss": 2.4464,
      "step": 506000
    },
    {
      "epoch": 813.54,
      "learning_rate": 0.018679984857073957,
      "loss": 2.4227,
      "step": 506020
    },
    {
      "epoch": 813.57,
      "learning_rate": 0.01867676942620579,
      "loss": 2.4506,
      "step": 506040
    },
    {
      "epoch": 813.6,
      "learning_rate": 0.018673553995337617,
      "loss": 2.43,
      "step": 506060
    },
    {
      "epoch": 813.63,
      "learning_rate": 0.01867033856446945,
      "loss": 2.4256,
      "step": 506080
    },
    {
      "epoch": 813.67,
      "learning_rate": 0.01866712313360129,
      "loss": 2.4025,
      "step": 506100
    },
    {
      "epoch": 813.7,
      "learning_rate": 0.018663907702733122,
      "loss": 2.4355,
      "step": 506120
    },
    {
      "epoch": 813.73,
      "learning_rate": 0.018660692271864954,
      "loss": 2.4199,
      "step": 506140
    },
    {
      "epoch": 813.76,
      "learning_rate": 0.018657476840996782,
      "loss": 2.4462,
      "step": 506160
    },
    {
      "epoch": 813.79,
      "learning_rate": 0.018654261410128613,
      "loss": 2.4116,
      "step": 506180
    },
    {
      "epoch": 813.83,
      "learning_rate": 0.018651045979260445,
      "loss": 2.4252,
      "step": 506200
    },
    {
      "epoch": 813.86,
      "learning_rate": 0.018647830548392287,
      "loss": 2.4197,
      "step": 506220
    },
    {
      "epoch": 813.89,
      "learning_rate": 0.01864461511752412,
      "loss": 2.4328,
      "step": 506240
    },
    {
      "epoch": 813.92,
      "learning_rate": 0.01864139968665595,
      "loss": 2.4241,
      "step": 506260
    },
    {
      "epoch": 813.95,
      "learning_rate": 0.01863818425578778,
      "loss": 2.4381,
      "step": 506280
    },
    {
      "epoch": 813.99,
      "learning_rate": 0.01863496882491961,
      "loss": 2.4147,
      "step": 506300
    },
    {
      "epoch": 814.0,
      "eval_accuracy": {
        "accuracy": 0.4521495763041281
      },
      "eval_loss": 2.5453078746795654,
      "eval_runtime": 3.0941,
      "eval_samples_per_second": 4157.245,
      "eval_steps_per_second": 64.962,
      "step": 506308
    },
    {
      "epoch": 814.02,
      "learning_rate": 0.018631753394051452,
      "loss": 2.4495,
      "step": 506320
    },
    {
      "epoch": 814.05,
      "learning_rate": 0.018628537963183284,
      "loss": 2.4379,
      "step": 506340
    },
    {
      "epoch": 814.08,
      "learning_rate": 0.018625322532315115,
      "loss": 2.3995,
      "step": 506360
    },
    {
      "epoch": 814.12,
      "learning_rate": 0.018622107101446943,
      "loss": 2.4273,
      "step": 506380
    },
    {
      "epoch": 814.15,
      "learning_rate": 0.018618891670578775,
      "loss": 2.4368,
      "step": 506400
    },
    {
      "epoch": 814.18,
      "learning_rate": 0.018615676239710607,
      "loss": 2.4367,
      "step": 506420
    },
    {
      "epoch": 814.21,
      "learning_rate": 0.01861246080884245,
      "loss": 2.4157,
      "step": 506440
    },
    {
      "epoch": 814.24,
      "learning_rate": 0.01860924537797428,
      "loss": 2.4396,
      "step": 506460
    },
    {
      "epoch": 814.28,
      "learning_rate": 0.01860602994710611,
      "loss": 2.4416,
      "step": 506480
    },
    {
      "epoch": 814.31,
      "learning_rate": 0.01860281451623794,
      "loss": 2.4347,
      "step": 506500
    },
    {
      "epoch": 814.34,
      "learning_rate": 0.01859959908536977,
      "loss": 2.4176,
      "step": 506520
    },
    {
      "epoch": 814.37,
      "learning_rate": 0.018596383654501603,
      "loss": 2.4303,
      "step": 506540
    },
    {
      "epoch": 814.41,
      "learning_rate": 0.018593168223633445,
      "loss": 2.4183,
      "step": 506560
    },
    {
      "epoch": 814.44,
      "learning_rate": 0.018589952792765277,
      "loss": 2.4348,
      "step": 506580
    },
    {
      "epoch": 814.47,
      "learning_rate": 0.018586737361897105,
      "loss": 2.4304,
      "step": 506600
    },
    {
      "epoch": 814.5,
      "learning_rate": 0.018583521931028937,
      "loss": 2.4279,
      "step": 506620
    },
    {
      "epoch": 814.53,
      "learning_rate": 0.018580306500160768,
      "loss": 2.4312,
      "step": 506640
    },
    {
      "epoch": 814.57,
      "learning_rate": 0.01857709106929261,
      "loss": 2.4248,
      "step": 506660
    },
    {
      "epoch": 814.6,
      "learning_rate": 0.018573875638424442,
      "loss": 2.4319,
      "step": 506680
    },
    {
      "epoch": 814.63,
      "learning_rate": 0.01857066020755627,
      "loss": 2.433,
      "step": 506700
    },
    {
      "epoch": 814.66,
      "learning_rate": 0.0185674447766881,
      "loss": 2.409,
      "step": 506720
    },
    {
      "epoch": 814.69,
      "learning_rate": 0.018564229345819933,
      "loss": 2.433,
      "step": 506740
    },
    {
      "epoch": 814.73,
      "learning_rate": 0.018561013914951765,
      "loss": 2.4223,
      "step": 506760
    },
    {
      "epoch": 814.76,
      "learning_rate": 0.018557798484083607,
      "loss": 2.4349,
      "step": 506780
    },
    {
      "epoch": 814.79,
      "learning_rate": 0.018554583053215435,
      "loss": 2.429,
      "step": 506800
    },
    {
      "epoch": 814.82,
      "learning_rate": 0.018551367622347267,
      "loss": 2.4567,
      "step": 506820
    },
    {
      "epoch": 814.86,
      "learning_rate": 0.018548152191479098,
      "loss": 2.445,
      "step": 506840
    },
    {
      "epoch": 814.89,
      "learning_rate": 0.01854493676061093,
      "loss": 2.4225,
      "step": 506860
    },
    {
      "epoch": 814.92,
      "learning_rate": 0.01854172132974276,
      "loss": 2.4205,
      "step": 506880
    },
    {
      "epoch": 814.95,
      "learning_rate": 0.018538505898874603,
      "loss": 2.4274,
      "step": 506900
    },
    {
      "epoch": 814.98,
      "learning_rate": 0.01853529046800643,
      "loss": 2.4219,
      "step": 506920
    },
    {
      "epoch": 815.0,
      "eval_accuracy": {
        "accuracy": 0.45626992148021456
      },
      "eval_loss": 2.5355918407440186,
      "eval_runtime": 3.0805,
      "eval_samples_per_second": 4175.646,
      "eval_steps_per_second": 65.25,
      "step": 506930
    },
    {
      "epoch": 815.02,
      "learning_rate": 0.018532075037138263,
      "loss": 2.4289,
      "step": 506940
    },
    {
      "epoch": 815.05,
      "learning_rate": 0.018528859606270095,
      "loss": 2.4344,
      "step": 506960
    },
    {
      "epoch": 815.08,
      "learning_rate": 0.018525644175401926,
      "loss": 2.438,
      "step": 506980
    },
    {
      "epoch": 815.11,
      "learning_rate": 0.01852242874453377,
      "loss": 2.4134,
      "step": 507000
    },
    {
      "epoch": 815.14,
      "learning_rate": 0.018519213313665597,
      "loss": 2.4338,
      "step": 507020
    },
    {
      "epoch": 815.18,
      "learning_rate": 0.018515997882797428,
      "loss": 2.4467,
      "step": 507040
    },
    {
      "epoch": 815.21,
      "learning_rate": 0.01851278245192926,
      "loss": 2.4134,
      "step": 507060
    },
    {
      "epoch": 815.24,
      "learning_rate": 0.01850956702106109,
      "loss": 2.4435,
      "step": 507080
    },
    {
      "epoch": 815.27,
      "learning_rate": 0.01850635159019292,
      "loss": 2.4327,
      "step": 507100
    },
    {
      "epoch": 815.31,
      "learning_rate": 0.01850313615932476,
      "loss": 2.4395,
      "step": 507120
    },
    {
      "epoch": 815.34,
      "learning_rate": 0.018499920728456593,
      "loss": 2.4131,
      "step": 507140
    },
    {
      "epoch": 815.37,
      "learning_rate": 0.018496705297588425,
      "loss": 2.4309,
      "step": 507160
    },
    {
      "epoch": 815.4,
      "learning_rate": 0.018493489866720256,
      "loss": 2.4249,
      "step": 507180
    },
    {
      "epoch": 815.43,
      "learning_rate": 0.018490274435852088,
      "loss": 2.4156,
      "step": 507200
    },
    {
      "epoch": 815.47,
      "learning_rate": 0.018487059004983916,
      "loss": 2.42,
      "step": 507220
    },
    {
      "epoch": 815.5,
      "learning_rate": 0.018483843574115758,
      "loss": 2.4151,
      "step": 507240
    },
    {
      "epoch": 815.53,
      "learning_rate": 0.01848062814324759,
      "loss": 2.437,
      "step": 507260
    },
    {
      "epoch": 815.56,
      "learning_rate": 0.01847741271237942,
      "loss": 2.4306,
      "step": 507280
    },
    {
      "epoch": 815.59,
      "learning_rate": 0.018474197281511253,
      "loss": 2.4286,
      "step": 507300
    },
    {
      "epoch": 815.63,
      "learning_rate": 0.01847098185064308,
      "loss": 2.4279,
      "step": 507320
    },
    {
      "epoch": 815.66,
      "learning_rate": 0.018467766419774923,
      "loss": 2.4268,
      "step": 507340
    },
    {
      "epoch": 815.69,
      "learning_rate": 0.018464550988906755,
      "loss": 2.4234,
      "step": 507360
    },
    {
      "epoch": 815.72,
      "learning_rate": 0.018461335558038586,
      "loss": 2.418,
      "step": 507380
    },
    {
      "epoch": 815.76,
      "learning_rate": 0.018458120127170418,
      "loss": 2.4139,
      "step": 507400
    },
    {
      "epoch": 815.79,
      "learning_rate": 0.018454904696302246,
      "loss": 2.4532,
      "step": 507420
    },
    {
      "epoch": 815.82,
      "learning_rate": 0.018451689265434078,
      "loss": 2.4217,
      "step": 507440
    },
    {
      "epoch": 815.85,
      "learning_rate": 0.01844847383456592,
      "loss": 2.4418,
      "step": 507460
    },
    {
      "epoch": 815.88,
      "learning_rate": 0.01844525840369775,
      "loss": 2.4133,
      "step": 507480
    },
    {
      "epoch": 815.92,
      "learning_rate": 0.018442042972829583,
      "loss": 2.4034,
      "step": 507500
    },
    {
      "epoch": 815.95,
      "learning_rate": 0.018438827541961415,
      "loss": 2.4376,
      "step": 507520
    },
    {
      "epoch": 815.98,
      "learning_rate": 0.018435612111093243,
      "loss": 2.4295,
      "step": 507540
    },
    {
      "epoch": 816.0,
      "eval_accuracy": {
        "accuracy": 0.4578247687164736
      },
      "eval_loss": 2.5443878173828125,
      "eval_runtime": 3.1071,
      "eval_samples_per_second": 4139.933,
      "eval_steps_per_second": 64.691,
      "step": 507552
    },
    {
      "epoch": 816.01,
      "learning_rate": 0.018432396680225074,
      "loss": 2.4224,
      "step": 507560
    },
    {
      "epoch": 816.05,
      "learning_rate": 0.018429181249356916,
      "loss": 2.4203,
      "step": 507580
    },
    {
      "epoch": 816.08,
      "learning_rate": 0.018425965818488748,
      "loss": 2.4491,
      "step": 507600
    },
    {
      "epoch": 816.11,
      "learning_rate": 0.01842275038762058,
      "loss": 2.4235,
      "step": 507620
    },
    {
      "epoch": 816.14,
      "learning_rate": 0.018419534956752408,
      "loss": 2.4163,
      "step": 507640
    },
    {
      "epoch": 816.17,
      "learning_rate": 0.01841631952588424,
      "loss": 2.4135,
      "step": 507660
    },
    {
      "epoch": 816.21,
      "learning_rate": 0.01841310409501608,
      "loss": 2.4104,
      "step": 507680
    },
    {
      "epoch": 816.24,
      "learning_rate": 0.018409888664147913,
      "loss": 2.4229,
      "step": 507700
    },
    {
      "epoch": 816.27,
      "learning_rate": 0.018406673233279745,
      "loss": 2.4287,
      "step": 507720
    },
    {
      "epoch": 816.3,
      "learning_rate": 0.018403457802411573,
      "loss": 2.4341,
      "step": 507740
    },
    {
      "epoch": 816.33,
      "learning_rate": 0.018400242371543404,
      "loss": 2.4284,
      "step": 507760
    },
    {
      "epoch": 816.37,
      "learning_rate": 0.018397026940675236,
      "loss": 2.4139,
      "step": 507780
    },
    {
      "epoch": 816.4,
      "learning_rate": 0.018393811509807078,
      "loss": 2.4323,
      "step": 507800
    },
    {
      "epoch": 816.43,
      "learning_rate": 0.01839059607893891,
      "loss": 2.4154,
      "step": 507820
    },
    {
      "epoch": 816.46,
      "learning_rate": 0.01838738064807074,
      "loss": 2.4368,
      "step": 507840
    },
    {
      "epoch": 816.5,
      "learning_rate": 0.01838416521720257,
      "loss": 2.4218,
      "step": 507860
    },
    {
      "epoch": 816.53,
      "learning_rate": 0.0183809497863344,
      "loss": 2.4259,
      "step": 507880
    },
    {
      "epoch": 816.56,
      "learning_rate": 0.018377734355466243,
      "loss": 2.4166,
      "step": 507900
    },
    {
      "epoch": 816.59,
      "learning_rate": 0.018374518924598075,
      "loss": 2.4295,
      "step": 507920
    },
    {
      "epoch": 816.62,
      "learning_rate": 0.018371303493729906,
      "loss": 2.4324,
      "step": 507940
    },
    {
      "epoch": 816.66,
      "learning_rate": 0.018368088062861734,
      "loss": 2.4338,
      "step": 507960
    },
    {
      "epoch": 816.69,
      "learning_rate": 0.018364872631993566,
      "loss": 2.4613,
      "step": 507980
    },
    {
      "epoch": 816.72,
      "learning_rate": 0.018361657201125398,
      "loss": 2.4166,
      "step": 508000
    },
    {
      "epoch": 816.75,
      "learning_rate": 0.01835844177025724,
      "loss": 2.4319,
      "step": 508020
    },
    {
      "epoch": 816.78,
      "learning_rate": 0.01835522633938907,
      "loss": 2.4348,
      "step": 508040
    },
    {
      "epoch": 816.82,
      "learning_rate": 0.0183520109085209,
      "loss": 2.4371,
      "step": 508060
    },
    {
      "epoch": 816.85,
      "learning_rate": 0.01834879547765273,
      "loss": 2.4409,
      "step": 508080
    },
    {
      "epoch": 816.88,
      "learning_rate": 0.018345580046784563,
      "loss": 2.4311,
      "step": 508100
    },
    {
      "epoch": 816.91,
      "learning_rate": 0.018342364615916394,
      "loss": 2.4224,
      "step": 508120
    },
    {
      "epoch": 816.95,
      "learning_rate": 0.018339149185048236,
      "loss": 2.4234,
      "step": 508140
    },
    {
      "epoch": 816.98,
      "learning_rate": 0.018335933754180068,
      "loss": 2.4185,
      "step": 508160
    },
    {
      "epoch": 817.0,
      "eval_accuracy": {
        "accuracy": 0.4557257249475239
      },
      "eval_loss": 2.5370869636535645,
      "eval_runtime": 3.0851,
      "eval_samples_per_second": 4169.381,
      "eval_steps_per_second": 65.152,
      "step": 508174
    },
    {
      "epoch": 817.01,
      "learning_rate": 0.018332718323311896,
      "loss": 2.4299,
      "step": 508180
    },
    {
      "epoch": 817.04,
      "learning_rate": 0.018329502892443728,
      "loss": 2.4201,
      "step": 508200
    },
    {
      "epoch": 817.07,
      "learning_rate": 0.01832628746157556,
      "loss": 2.4115,
      "step": 508220
    },
    {
      "epoch": 817.11,
      "learning_rate": 0.0183230720307074,
      "loss": 2.4304,
      "step": 508240
    },
    {
      "epoch": 817.14,
      "learning_rate": 0.018319856599839233,
      "loss": 2.4069,
      "step": 508260
    },
    {
      "epoch": 817.17,
      "learning_rate": 0.01831664116897106,
      "loss": 2.4399,
      "step": 508280
    },
    {
      "epoch": 817.2,
      "learning_rate": 0.018313425738102893,
      "loss": 2.4269,
      "step": 508300
    },
    {
      "epoch": 817.23,
      "learning_rate": 0.018310210307234724,
      "loss": 2.4278,
      "step": 508320
    },
    {
      "epoch": 817.27,
      "learning_rate": 0.018306994876366556,
      "loss": 2.4241,
      "step": 508340
    },
    {
      "epoch": 817.3,
      "learning_rate": 0.018303779445498398,
      "loss": 2.4325,
      "step": 508360
    },
    {
      "epoch": 817.33,
      "learning_rate": 0.018300564014630226,
      "loss": 2.4372,
      "step": 508380
    },
    {
      "epoch": 817.36,
      "learning_rate": 0.018297348583762058,
      "loss": 2.4292,
      "step": 508400
    },
    {
      "epoch": 817.4,
      "learning_rate": 0.01829413315289389,
      "loss": 2.4397,
      "step": 508420
    },
    {
      "epoch": 817.43,
      "learning_rate": 0.01829091772202572,
      "loss": 2.424,
      "step": 508440
    },
    {
      "epoch": 817.46,
      "learning_rate": 0.018287702291157552,
      "loss": 2.4265,
      "step": 508460
    },
    {
      "epoch": 817.49,
      "learning_rate": 0.018284486860289394,
      "loss": 2.4207,
      "step": 508480
    },
    {
      "epoch": 817.52,
      "learning_rate": 0.018281271429421223,
      "loss": 2.4253,
      "step": 508500
    },
    {
      "epoch": 817.56,
      "learning_rate": 0.018278055998553054,
      "loss": 2.4066,
      "step": 508520
    },
    {
      "epoch": 817.59,
      "learning_rate": 0.018274840567684886,
      "loss": 2.4354,
      "step": 508540
    },
    {
      "epoch": 817.62,
      "learning_rate": 0.018271625136816717,
      "loss": 2.4218,
      "step": 508560
    },
    {
      "epoch": 817.65,
      "learning_rate": 0.01826840970594856,
      "loss": 2.4206,
      "step": 508580
    },
    {
      "epoch": 817.68,
      "learning_rate": 0.018265194275080388,
      "loss": 2.4199,
      "step": 508600
    },
    {
      "epoch": 817.72,
      "learning_rate": 0.01826197884421222,
      "loss": 2.4462,
      "step": 508620
    },
    {
      "epoch": 817.75,
      "learning_rate": 0.01825876341334405,
      "loss": 2.4185,
      "step": 508640
    },
    {
      "epoch": 817.78,
      "learning_rate": 0.018255547982475882,
      "loss": 2.4165,
      "step": 508660
    },
    {
      "epoch": 817.81,
      "learning_rate": 0.018252332551607714,
      "loss": 2.4364,
      "step": 508680
    },
    {
      "epoch": 817.85,
      "learning_rate": 0.018249117120739556,
      "loss": 2.4327,
      "step": 508700
    },
    {
      "epoch": 817.88,
      "learning_rate": 0.018245901689871384,
      "loss": 2.4217,
      "step": 508720
    },
    {
      "epoch": 817.91,
      "learning_rate": 0.018242686259003216,
      "loss": 2.4202,
      "step": 508740
    },
    {
      "epoch": 817.94,
      "learning_rate": 0.018239470828135047,
      "loss": 2.4196,
      "step": 508760
    },
    {
      "epoch": 817.97,
      "learning_rate": 0.01823625539726688,
      "loss": 2.4349,
      "step": 508780
    },
    {
      "epoch": 818.0,
      "eval_accuracy": {
        "accuracy": 0.452382803389567
      },
      "eval_loss": 2.549670696258545,
      "eval_runtime": 3.1123,
      "eval_samples_per_second": 4132.942,
      "eval_steps_per_second": 64.582,
      "step": 508796
    },
    {
      "epoch": 818.01,
      "learning_rate": 0.018233039966398707,
      "loss": 2.4138,
      "step": 508800
    },
    {
      "epoch": 818.04,
      "learning_rate": 0.01822982453553055,
      "loss": 2.4399,
      "step": 508820
    },
    {
      "epoch": 818.07,
      "learning_rate": 0.01822660910466238,
      "loss": 2.4234,
      "step": 508840
    },
    {
      "epoch": 818.1,
      "learning_rate": 0.018223393673794212,
      "loss": 2.4269,
      "step": 508860
    },
    {
      "epoch": 818.14,
      "learning_rate": 0.018220178242926044,
      "loss": 2.4487,
      "step": 508880
    },
    {
      "epoch": 818.17,
      "learning_rate": 0.018216962812057872,
      "loss": 2.4164,
      "step": 508900
    },
    {
      "epoch": 818.2,
      "learning_rate": 0.018213747381189714,
      "loss": 2.4241,
      "step": 508920
    },
    {
      "epoch": 818.23,
      "learning_rate": 0.018210531950321546,
      "loss": 2.4217,
      "step": 508940
    },
    {
      "epoch": 818.26,
      "learning_rate": 0.018207316519453377,
      "loss": 2.432,
      "step": 508960
    },
    {
      "epoch": 818.3,
      "learning_rate": 0.01820410108858521,
      "loss": 2.416,
      "step": 508980
    },
    {
      "epoch": 818.33,
      "learning_rate": 0.01820088565771704,
      "loss": 2.4364,
      "step": 509000
    },
    {
      "epoch": 818.36,
      "learning_rate": 0.01819767022684887,
      "loss": 2.4407,
      "step": 509020
    },
    {
      "epoch": 818.39,
      "learning_rate": 0.01819445479598071,
      "loss": 2.4173,
      "step": 509040
    },
    {
      "epoch": 818.42,
      "learning_rate": 0.018191239365112542,
      "loss": 2.4428,
      "step": 509060
    },
    {
      "epoch": 818.46,
      "learning_rate": 0.018188023934244374,
      "loss": 2.4499,
      "step": 509080
    },
    {
      "epoch": 818.49,
      "learning_rate": 0.018184808503376206,
      "loss": 2.4207,
      "step": 509100
    },
    {
      "epoch": 818.52,
      "learning_rate": 0.018181593072508034,
      "loss": 2.4288,
      "step": 509120
    },
    {
      "epoch": 818.55,
      "learning_rate": 0.018178377641639865,
      "loss": 2.4335,
      "step": 509140
    },
    {
      "epoch": 818.59,
      "learning_rate": 0.018175162210771707,
      "loss": 2.4227,
      "step": 509160
    },
    {
      "epoch": 818.62,
      "learning_rate": 0.01817194677990354,
      "loss": 2.4059,
      "step": 509180
    },
    {
      "epoch": 818.65,
      "learning_rate": 0.01816873134903537,
      "loss": 2.4227,
      "step": 509200
    },
    {
      "epoch": 818.68,
      "learning_rate": 0.0181655159181672,
      "loss": 2.4061,
      "step": 509220
    },
    {
      "epoch": 818.71,
      "learning_rate": 0.01816230048729903,
      "loss": 2.4358,
      "step": 509240
    },
    {
      "epoch": 818.75,
      "learning_rate": 0.018159085056430872,
      "loss": 2.4364,
      "step": 509260
    },
    {
      "epoch": 818.78,
      "learning_rate": 0.018155869625562704,
      "loss": 2.427,
      "step": 509280
    },
    {
      "epoch": 818.81,
      "learning_rate": 0.018152654194694536,
      "loss": 2.4416,
      "step": 509300
    },
    {
      "epoch": 818.84,
      "learning_rate": 0.018149438763826367,
      "loss": 2.4115,
      "step": 509320
    },
    {
      "epoch": 818.87,
      "learning_rate": 0.018146223332958195,
      "loss": 2.4196,
      "step": 509340
    },
    {
      "epoch": 818.91,
      "learning_rate": 0.018143007902090027,
      "loss": 2.4228,
      "step": 509360
    },
    {
      "epoch": 818.94,
      "learning_rate": 0.01813979247122187,
      "loss": 2.4199,
      "step": 509380
    },
    {
      "epoch": 818.97,
      "learning_rate": 0.018136737811897112,
      "loss": 2.4143,
      "step": 509400
    },
    {
      "epoch": 819.0,
      "eval_accuracy": {
        "accuracy": 0.4543263624348908
      },
      "eval_loss": 2.548139810562134,
      "eval_runtime": 3.4808,
      "eval_samples_per_second": 3695.387,
      "eval_steps_per_second": 57.745,
      "step": 509418
    },
    {
      "epoch": 819.0,
      "learning_rate": 0.018133522381028944,
      "loss": 2.4205,
      "step": 509420
    },
    {
      "epoch": 819.04,
      "learning_rate": 0.018130306950160772,
      "loss": 2.4161,
      "step": 509440
    },
    {
      "epoch": 819.07,
      "learning_rate": 0.018127091519292603,
      "loss": 2.4425,
      "step": 509460
    },
    {
      "epoch": 819.1,
      "learning_rate": 0.018123876088424435,
      "loss": 2.4334,
      "step": 509480
    },
    {
      "epoch": 819.13,
      "learning_rate": 0.018120660657556267,
      "loss": 2.4526,
      "step": 509500
    },
    {
      "epoch": 819.16,
      "learning_rate": 0.01811744522668811,
      "loss": 2.4179,
      "step": 509520
    },
    {
      "epoch": 819.2,
      "learning_rate": 0.018114229795819937,
      "loss": 2.4269,
      "step": 509540
    },
    {
      "epoch": 819.23,
      "learning_rate": 0.01811101436495177,
      "loss": 2.4456,
      "step": 509560
    },
    {
      "epoch": 819.26,
      "learning_rate": 0.0181077989340836,
      "loss": 2.431,
      "step": 509580
    },
    {
      "epoch": 819.29,
      "learning_rate": 0.01810458350321543,
      "loss": 2.4092,
      "step": 509600
    },
    {
      "epoch": 819.32,
      "learning_rate": 0.01810136807234726,
      "loss": 2.4152,
      "step": 509620
    },
    {
      "epoch": 819.36,
      "learning_rate": 0.018098152641479102,
      "loss": 2.4121,
      "step": 509640
    },
    {
      "epoch": 819.39,
      "learning_rate": 0.018094937210610933,
      "loss": 2.4103,
      "step": 509660
    },
    {
      "epoch": 819.42,
      "learning_rate": 0.018091721779742765,
      "loss": 2.4244,
      "step": 509680
    },
    {
      "epoch": 819.45,
      "learning_rate": 0.018088506348874597,
      "loss": 2.4288,
      "step": 509700
    },
    {
      "epoch": 819.49,
      "learning_rate": 0.018085290918006428,
      "loss": 2.4128,
      "step": 509720
    },
    {
      "epoch": 819.52,
      "learning_rate": 0.01808207548713827,
      "loss": 2.4221,
      "step": 509740
    },
    {
      "epoch": 819.55,
      "learning_rate": 0.0180788600562701,
      "loss": 2.4103,
      "step": 509760
    },
    {
      "epoch": 819.58,
      "learning_rate": 0.01807564462540193,
      "loss": 2.4095,
      "step": 509780
    },
    {
      "epoch": 819.61,
      "learning_rate": 0.01807242919453376,
      "loss": 2.4131,
      "step": 509800
    },
    {
      "epoch": 819.65,
      "learning_rate": 0.018069213763665593,
      "loss": 2.4068,
      "step": 509820
    },
    {
      "epoch": 819.68,
      "learning_rate": 0.01806599833279742,
      "loss": 2.4126,
      "step": 509840
    },
    {
      "epoch": 819.71,
      "learning_rate": 0.018062782901929263,
      "loss": 2.4283,
      "step": 509860
    },
    {
      "epoch": 819.74,
      "learning_rate": 0.018059567471061095,
      "loss": 2.4186,
      "step": 509880
    },
    {
      "epoch": 819.77,
      "learning_rate": 0.018056352040192927,
      "loss": 2.4509,
      "step": 509900
    },
    {
      "epoch": 819.81,
      "learning_rate": 0.018053136609324758,
      "loss": 2.4233,
      "step": 509920
    },
    {
      "epoch": 819.84,
      "learning_rate": 0.018049921178456586,
      "loss": 2.4365,
      "step": 509940
    },
    {
      "epoch": 819.87,
      "learning_rate": 0.018046705747588418,
      "loss": 2.439,
      "step": 509960
    },
    {
      "epoch": 819.9,
      "learning_rate": 0.01804349031672026,
      "loss": 2.4168,
      "step": 509980
    },
    {
      "epoch": 819.94,
      "learning_rate": 0.01804027488585209,
      "loss": 2.4344,
      "step": 510000
    },
    {
      "epoch": 819.97,
      "learning_rate": 0.018037059454983923,
      "loss": 2.4203,
      "step": 510020
    },
    {
      "epoch": 820.0,
      "learning_rate": 0.018033844024115755,
      "loss": 2.443,
      "step": 510040
    },
    {
      "epoch": 820.0,
      "eval_accuracy": {
        "accuracy": 0.4540931353494519
      },
      "eval_loss": 2.537055015563965,
      "eval_runtime": 3.2485,
      "eval_samples_per_second": 3959.709,
      "eval_steps_per_second": 61.875,
      "step": 510040
    },
    {
      "epoch": 820.03,
      "learning_rate": 0.018030628593247583,
      "loss": 2.4088,
      "step": 510060
    },
    {
      "epoch": 820.06,
      "learning_rate": 0.018027413162379425,
      "loss": 2.4196,
      "step": 510080
    },
    {
      "epoch": 820.1,
      "learning_rate": 0.018024197731511257,
      "loss": 2.4186,
      "step": 510100
    },
    {
      "epoch": 820.13,
      "learning_rate": 0.018020982300643088,
      "loss": 2.4198,
      "step": 510120
    },
    {
      "epoch": 820.16,
      "learning_rate": 0.01801776686977492,
      "loss": 2.4429,
      "step": 510140
    },
    {
      "epoch": 820.19,
      "learning_rate": 0.018014551438906748,
      "loss": 2.4244,
      "step": 510160
    },
    {
      "epoch": 820.23,
      "learning_rate": 0.01801133600803858,
      "loss": 2.4234,
      "step": 510180
    },
    {
      "epoch": 820.26,
      "learning_rate": 0.01800812057717042,
      "loss": 2.4215,
      "step": 510200
    },
    {
      "epoch": 820.29,
      "learning_rate": 0.018004905146302253,
      "loss": 2.435,
      "step": 510220
    },
    {
      "epoch": 820.32,
      "learning_rate": 0.018001689715434085,
      "loss": 2.4202,
      "step": 510240
    },
    {
      "epoch": 820.35,
      "learning_rate": 0.017998474284565913,
      "loss": 2.4396,
      "step": 510260
    },
    {
      "epoch": 820.39,
      "learning_rate": 0.017995258853697745,
      "loss": 2.4194,
      "step": 510280
    },
    {
      "epoch": 820.42,
      "learning_rate": 0.017992043422829587,
      "loss": 2.4217,
      "step": 510300
    },
    {
      "epoch": 820.45,
      "learning_rate": 0.017988827991961418,
      "loss": 2.4166,
      "step": 510320
    },
    {
      "epoch": 820.48,
      "learning_rate": 0.01798561256109325,
      "loss": 2.4244,
      "step": 510340
    },
    {
      "epoch": 820.51,
      "learning_rate": 0.01798239713022508,
      "loss": 2.4294,
      "step": 510360
    },
    {
      "epoch": 820.55,
      "learning_rate": 0.01797918169935691,
      "loss": 2.4305,
      "step": 510380
    },
    {
      "epoch": 820.58,
      "learning_rate": 0.01797596626848874,
      "loss": 2.4226,
      "step": 510400
    },
    {
      "epoch": 820.61,
      "learning_rate": 0.017972750837620583,
      "loss": 2.4201,
      "step": 510420
    },
    {
      "epoch": 820.64,
      "learning_rate": 0.017969535406752415,
      "loss": 2.4367,
      "step": 510440
    },
    {
      "epoch": 820.68,
      "learning_rate": 0.017966319975884246,
      "loss": 2.4225,
      "step": 510460
    },
    {
      "epoch": 820.71,
      "learning_rate": 0.017963104545016075,
      "loss": 2.411,
      "step": 510480
    },
    {
      "epoch": 820.74,
      "learning_rate": 0.017959889114147906,
      "loss": 2.4085,
      "step": 510500
    },
    {
      "epoch": 820.77,
      "learning_rate": 0.017956673683279738,
      "loss": 2.4368,
      "step": 510520
    },
    {
      "epoch": 820.8,
      "learning_rate": 0.01795345825241158,
      "loss": 2.4432,
      "step": 510540
    },
    {
      "epoch": 820.84,
      "learning_rate": 0.01795024282154341,
      "loss": 2.4295,
      "step": 510560
    },
    {
      "epoch": 820.87,
      "learning_rate": 0.017947027390675243,
      "loss": 2.4249,
      "step": 510580
    },
    {
      "epoch": 820.9,
      "learning_rate": 0.01794381195980707,
      "loss": 2.4262,
      "step": 510600
    },
    {
      "epoch": 820.93,
      "learning_rate": 0.017940596528938903,
      "loss": 2.4267,
      "step": 510620
    },
    {
      "epoch": 820.96,
      "learning_rate": 0.017937381098070745,
      "loss": 2.4248,
      "step": 510640
    },
    {
      "epoch": 821.0,
      "learning_rate": 0.017934165667202576,
      "loss": 2.4287,
      "step": 510660
    },
    {
      "epoch": 821.0,
      "eval_accuracy": {
        "accuracy": 0.4575137992692218
      },
      "eval_loss": 2.534789562225342,
      "eval_runtime": 3.1632,
      "eval_samples_per_second": 4066.446,
      "eval_steps_per_second": 63.543,
      "step": 510662
    },
    {
      "epoch": 821.03,
      "learning_rate": 0.017930950236334408,
      "loss": 2.421,
      "step": 510680
    },
    {
      "epoch": 821.06,
      "learning_rate": 0.017927734805466236,
      "loss": 2.424,
      "step": 510700
    },
    {
      "epoch": 821.09,
      "learning_rate": 0.017924519374598068,
      "loss": 2.4253,
      "step": 510720
    },
    {
      "epoch": 821.13,
      "learning_rate": 0.0179213039437299,
      "loss": 2.4086,
      "step": 510740
    },
    {
      "epoch": 821.16,
      "learning_rate": 0.01791808851286174,
      "loss": 2.425,
      "step": 510760
    },
    {
      "epoch": 821.19,
      "learning_rate": 0.017914873081993573,
      "loss": 2.4143,
      "step": 510780
    },
    {
      "epoch": 821.22,
      "learning_rate": 0.0179116576511254,
      "loss": 2.4027,
      "step": 510800
    },
    {
      "epoch": 821.25,
      "learning_rate": 0.017908442220257233,
      "loss": 2.4238,
      "step": 510820
    },
    {
      "epoch": 821.29,
      "learning_rate": 0.017905226789389064,
      "loss": 2.4252,
      "step": 510840
    },
    {
      "epoch": 821.32,
      "learning_rate": 0.017902011358520896,
      "loss": 2.4226,
      "step": 510860
    },
    {
      "epoch": 821.35,
      "learning_rate": 0.017898795927652738,
      "loss": 2.4263,
      "step": 510880
    },
    {
      "epoch": 821.38,
      "learning_rate": 0.01789558049678457,
      "loss": 2.4169,
      "step": 510900
    },
    {
      "epoch": 821.41,
      "learning_rate": 0.017892365065916398,
      "loss": 2.442,
      "step": 510920
    },
    {
      "epoch": 821.45,
      "learning_rate": 0.01788914963504823,
      "loss": 2.4116,
      "step": 510940
    },
    {
      "epoch": 821.48,
      "learning_rate": 0.01788593420418006,
      "loss": 2.4211,
      "step": 510960
    },
    {
      "epoch": 821.51,
      "learning_rate": 0.017882718773311903,
      "loss": 2.411,
      "step": 510980
    },
    {
      "epoch": 821.54,
      "learning_rate": 0.017879503342443735,
      "loss": 2.418,
      "step": 511000
    },
    {
      "epoch": 821.58,
      "learning_rate": 0.017876287911575563,
      "loss": 2.4337,
      "step": 511020
    },
    {
      "epoch": 821.61,
      "learning_rate": 0.017873072480707394,
      "loss": 2.4091,
      "step": 511040
    },
    {
      "epoch": 821.64,
      "learning_rate": 0.017869857049839226,
      "loss": 2.4254,
      "step": 511060
    },
    {
      "epoch": 821.67,
      "learning_rate": 0.017866641618971058,
      "loss": 2.4169,
      "step": 511080
    },
    {
      "epoch": 821.7,
      "learning_rate": 0.0178634261881029,
      "loss": 2.4358,
      "step": 511100
    },
    {
      "epoch": 821.74,
      "learning_rate": 0.017860210757234728,
      "loss": 2.4386,
      "step": 511120
    },
    {
      "epoch": 821.77,
      "learning_rate": 0.01785699532636656,
      "loss": 2.424,
      "step": 511140
    },
    {
      "epoch": 821.8,
      "learning_rate": 0.01785377989549839,
      "loss": 2.4201,
      "step": 511160
    },
    {
      "epoch": 821.83,
      "learning_rate": 0.017850564464630223,
      "loss": 2.4219,
      "step": 511180
    },
    {
      "epoch": 821.86,
      "learning_rate": 0.017847349033762054,
      "loss": 2.4376,
      "step": 511200
    },
    {
      "epoch": 821.9,
      "learning_rate": 0.017844133602893896,
      "loss": 2.4212,
      "step": 511220
    },
    {
      "epoch": 821.93,
      "learning_rate": 0.017840918172025724,
      "loss": 2.4398,
      "step": 511240
    },
    {
      "epoch": 821.96,
      "learning_rate": 0.017837702741157556,
      "loss": 2.4114,
      "step": 511260
    },
    {
      "epoch": 821.99,
      "learning_rate": 0.017834487310289387,
      "loss": 2.4295,
      "step": 511280
    },
    {
      "epoch": 822.0,
      "eval_accuracy": {
        "accuracy": 0.45277151519863174
      },
      "eval_loss": 2.5517523288726807,
      "eval_runtime": 3.188,
      "eval_samples_per_second": 4034.872,
      "eval_steps_per_second": 63.05,
      "step": 511284
    },
    {
      "epoch": 822.03,
      "learning_rate": 0.01783127187942122,
      "loss": 2.4284,
      "step": 511300
    },
    {
      "epoch": 822.06,
      "learning_rate": 0.01782805644855306,
      "loss": 2.4124,
      "step": 511320
    },
    {
      "epoch": 822.09,
      "learning_rate": 0.01782484101768489,
      "loss": 2.4076,
      "step": 511340
    },
    {
      "epoch": 822.12,
      "learning_rate": 0.01782162558681672,
      "loss": 2.4106,
      "step": 511360
    },
    {
      "epoch": 822.15,
      "learning_rate": 0.017818410155948552,
      "loss": 2.4086,
      "step": 511380
    },
    {
      "epoch": 822.19,
      "learning_rate": 0.017815194725080384,
      "loss": 2.4095,
      "step": 511400
    },
    {
      "epoch": 822.22,
      "learning_rate": 0.017811979294212212,
      "loss": 2.4211,
      "step": 511420
    },
    {
      "epoch": 822.25,
      "learning_rate": 0.017808763863344054,
      "loss": 2.4214,
      "step": 511440
    },
    {
      "epoch": 822.28,
      "learning_rate": 0.017805548432475886,
      "loss": 2.4164,
      "step": 511460
    },
    {
      "epoch": 822.32,
      "learning_rate": 0.017802333001607717,
      "loss": 2.4244,
      "step": 511480
    },
    {
      "epoch": 822.35,
      "learning_rate": 0.01779911757073955,
      "loss": 2.4046,
      "step": 511500
    },
    {
      "epoch": 822.38,
      "learning_rate": 0.01779590213987138,
      "loss": 2.44,
      "step": 511520
    },
    {
      "epoch": 822.41,
      "learning_rate": 0.01779268670900321,
      "loss": 2.443,
      "step": 511540
    },
    {
      "epoch": 822.44,
      "learning_rate": 0.01778947127813505,
      "loss": 2.4108,
      "step": 511560
    },
    {
      "epoch": 822.48,
      "learning_rate": 0.017786255847266882,
      "loss": 2.4311,
      "step": 511580
    },
    {
      "epoch": 822.51,
      "learning_rate": 0.017783040416398714,
      "loss": 2.4385,
      "step": 511600
    },
    {
      "epoch": 822.54,
      "learning_rate": 0.017779824985530546,
      "loss": 2.4236,
      "step": 511620
    },
    {
      "epoch": 822.57,
      "learning_rate": 0.017776609554662374,
      "loss": 2.4472,
      "step": 511640
    },
    {
      "epoch": 822.6,
      "learning_rate": 0.017773394123794216,
      "loss": 2.409,
      "step": 511660
    },
    {
      "epoch": 822.64,
      "learning_rate": 0.017770178692926047,
      "loss": 2.4151,
      "step": 511680
    },
    {
      "epoch": 822.67,
      "learning_rate": 0.01776696326205788,
      "loss": 2.4305,
      "step": 511700
    },
    {
      "epoch": 822.7,
      "learning_rate": 0.01776374783118971,
      "loss": 2.4202,
      "step": 511720
    },
    {
      "epoch": 822.73,
      "learning_rate": 0.01776053240032154,
      "loss": 2.4186,
      "step": 511740
    },
    {
      "epoch": 822.77,
      "learning_rate": 0.01775731696945337,
      "loss": 2.4286,
      "step": 511760
    },
    {
      "epoch": 822.8,
      "learning_rate": 0.017754101538585212,
      "loss": 2.4151,
      "step": 511780
    },
    {
      "epoch": 822.83,
      "learning_rate": 0.017750886107717044,
      "loss": 2.4193,
      "step": 511800
    },
    {
      "epoch": 822.86,
      "learning_rate": 0.017747670676848876,
      "loss": 2.4325,
      "step": 511820
    },
    {
      "epoch": 822.89,
      "learning_rate": 0.017744455245980707,
      "loss": 2.4266,
      "step": 511840
    },
    {
      "epoch": 822.93,
      "learning_rate": 0.017741239815112535,
      "loss": 2.3999,
      "step": 511860
    },
    {
      "epoch": 822.96,
      "learning_rate": 0.017738024384244367,
      "loss": 2.4477,
      "step": 511880
    },
    {
      "epoch": 822.99,
      "learning_rate": 0.01773480895337621,
      "loss": 2.4465,
      "step": 511900
    },
    {
      "epoch": 823.0,
      "eval_accuracy": {
        "accuracy": 0.4547928166057685
      },
      "eval_loss": 2.5426833629608154,
      "eval_runtime": 3.1551,
      "eval_samples_per_second": 4076.887,
      "eval_steps_per_second": 63.706,
      "step": 511906
    },
    {
      "epoch": 823.02,
      "learning_rate": 0.01773159352250804,
      "loss": 2.4316,
      "step": 511920
    },
    {
      "epoch": 823.05,
      "learning_rate": 0.017728378091639872,
      "loss": 2.4278,
      "step": 511940
    },
    {
      "epoch": 823.09,
      "learning_rate": 0.0177251626607717,
      "loss": 2.4231,
      "step": 511960
    },
    {
      "epoch": 823.12,
      "learning_rate": 0.017721947229903532,
      "loss": 2.4342,
      "step": 511980
    },
    {
      "epoch": 823.15,
      "learning_rate": 0.017718731799035374,
      "loss": 2.4108,
      "step": 512000
    },
    {
      "epoch": 823.18,
      "learning_rate": 0.017715516368167206,
      "loss": 2.4126,
      "step": 512020
    },
    {
      "epoch": 823.22,
      "learning_rate": 0.017712300937299037,
      "loss": 2.403,
      "step": 512040
    },
    {
      "epoch": 823.25,
      "learning_rate": 0.017709085506430865,
      "loss": 2.4029,
      "step": 512060
    },
    {
      "epoch": 823.28,
      "learning_rate": 0.017705870075562697,
      "loss": 2.437,
      "step": 512080
    },
    {
      "epoch": 823.31,
      "learning_rate": 0.01770265464469453,
      "loss": 2.4331,
      "step": 512100
    },
    {
      "epoch": 823.34,
      "learning_rate": 0.01769943921382637,
      "loss": 2.425,
      "step": 512120
    },
    {
      "epoch": 823.38,
      "learning_rate": 0.017696223782958202,
      "loss": 2.4214,
      "step": 512140
    },
    {
      "epoch": 823.41,
      "learning_rate": 0.017693008352090034,
      "loss": 2.4159,
      "step": 512160
    },
    {
      "epoch": 823.44,
      "learning_rate": 0.017689792921221862,
      "loss": 2.4241,
      "step": 512180
    },
    {
      "epoch": 823.47,
      "learning_rate": 0.017686577490353694,
      "loss": 2.406,
      "step": 512200
    },
    {
      "epoch": 823.5,
      "learning_rate": 0.017683362059485536,
      "loss": 2.4033,
      "step": 512220
    },
    {
      "epoch": 823.54,
      "learning_rate": 0.017680146628617367,
      "loss": 2.4457,
      "step": 512240
    },
    {
      "epoch": 823.57,
      "learning_rate": 0.0176769311977492,
      "loss": 2.4038,
      "step": 512260
    },
    {
      "epoch": 823.6,
      "learning_rate": 0.017673715766881027,
      "loss": 2.4371,
      "step": 512280
    },
    {
      "epoch": 823.63,
      "learning_rate": 0.01767050033601286,
      "loss": 2.4333,
      "step": 512300
    },
    {
      "epoch": 823.67,
      "learning_rate": 0.01766728490514469,
      "loss": 2.4124,
      "step": 512320
    },
    {
      "epoch": 823.7,
      "learning_rate": 0.017664069474276532,
      "loss": 2.4521,
      "step": 512340
    },
    {
      "epoch": 823.73,
      "learning_rate": 0.017660854043408364,
      "loss": 2.4168,
      "step": 512360
    },
    {
      "epoch": 823.76,
      "learning_rate": 0.017657638612540192,
      "loss": 2.4363,
      "step": 512380
    },
    {
      "epoch": 823.79,
      "learning_rate": 0.017654423181672024,
      "loss": 2.4237,
      "step": 512400
    },
    {
      "epoch": 823.83,
      "learning_rate": 0.017651207750803855,
      "loss": 2.4272,
      "step": 512420
    },
    {
      "epoch": 823.86,
      "learning_rate": 0.017647992319935687,
      "loss": 2.4523,
      "step": 512440
    },
    {
      "epoch": 823.89,
      "learning_rate": 0.01764477688906753,
      "loss": 2.4211,
      "step": 512460
    },
    {
      "epoch": 823.92,
      "learning_rate": 0.01764156145819936,
      "loss": 2.4309,
      "step": 512480
    },
    {
      "epoch": 823.95,
      "learning_rate": 0.01763834602733119,
      "loss": 2.4208,
      "step": 512500
    },
    {
      "epoch": 823.99,
      "learning_rate": 0.01763513059646302,
      "loss": 2.4149,
      "step": 512520
    },
    {
      "epoch": 824.0,
      "eval_accuracy": {
        "accuracy": 0.4544818471585167
      },
      "eval_loss": 2.5423614978790283,
      "eval_runtime": 3.312,
      "eval_samples_per_second": 3883.807,
      "eval_steps_per_second": 60.689,
      "step": 512528
    },
    {
      "epoch": 824.02,
      "learning_rate": 0.017631915165594852,
      "loss": 2.4248,
      "step": 512540
    },
    {
      "epoch": 824.05,
      "learning_rate": 0.017628699734726694,
      "loss": 2.4285,
      "step": 512560
    },
    {
      "epoch": 824.08,
      "learning_rate": 0.017625484303858525,
      "loss": 2.4247,
      "step": 512580
    },
    {
      "epoch": 824.12,
      "learning_rate": 0.017622268872990354,
      "loss": 2.4136,
      "step": 512600
    },
    {
      "epoch": 824.15,
      "learning_rate": 0.017619053442122185,
      "loss": 2.4159,
      "step": 512620
    },
    {
      "epoch": 824.18,
      "learning_rate": 0.017615838011254017,
      "loss": 2.423,
      "step": 512640
    },
    {
      "epoch": 824.21,
      "learning_rate": 0.01761262258038585,
      "loss": 2.4156,
      "step": 512660
    },
    {
      "epoch": 824.24,
      "learning_rate": 0.01760940714951769,
      "loss": 2.4376,
      "step": 512680
    },
    {
      "epoch": 824.28,
      "learning_rate": 0.01760619171864952,
      "loss": 2.4208,
      "step": 512700
    },
    {
      "epoch": 824.31,
      "learning_rate": 0.01760297628778135,
      "loss": 2.4088,
      "step": 512720
    },
    {
      "epoch": 824.34,
      "learning_rate": 0.017599760856913182,
      "loss": 2.4063,
      "step": 512740
    },
    {
      "epoch": 824.37,
      "learning_rate": 0.017596545426045013,
      "loss": 2.4133,
      "step": 512760
    },
    {
      "epoch": 824.41,
      "learning_rate": 0.017593329995176845,
      "loss": 2.4128,
      "step": 512780
    },
    {
      "epoch": 824.44,
      "learning_rate": 0.017590114564308687,
      "loss": 2.4321,
      "step": 512800
    },
    {
      "epoch": 824.47,
      "learning_rate": 0.017586899133440515,
      "loss": 2.4162,
      "step": 512820
    },
    {
      "epoch": 824.5,
      "learning_rate": 0.017583683702572347,
      "loss": 2.3996,
      "step": 512840
    },
    {
      "epoch": 824.53,
      "learning_rate": 0.01758046827170418,
      "loss": 2.4305,
      "step": 512860
    },
    {
      "epoch": 824.57,
      "learning_rate": 0.01757725284083601,
      "loss": 2.4233,
      "step": 512880
    },
    {
      "epoch": 824.6,
      "learning_rate": 0.017574037409967852,
      "loss": 2.4194,
      "step": 512900
    },
    {
      "epoch": 824.63,
      "learning_rate": 0.01757082197909968,
      "loss": 2.4122,
      "step": 512920
    },
    {
      "epoch": 824.66,
      "learning_rate": 0.017567606548231512,
      "loss": 2.4169,
      "step": 512940
    },
    {
      "epoch": 824.69,
      "learning_rate": 0.017564391117363343,
      "loss": 2.4217,
      "step": 512960
    },
    {
      "epoch": 824.73,
      "learning_rate": 0.017561175686495175,
      "loss": 2.3996,
      "step": 512980
    },
    {
      "epoch": 824.76,
      "learning_rate": 0.017557960255627007,
      "loss": 2.4193,
      "step": 513000
    },
    {
      "epoch": 824.79,
      "learning_rate": 0.017554744824758845,
      "loss": 2.4057,
      "step": 513020
    },
    {
      "epoch": 824.82,
      "learning_rate": 0.017551529393890677,
      "loss": 2.4376,
      "step": 513040
    },
    {
      "epoch": 824.86,
      "learning_rate": 0.01754831396302251,
      "loss": 2.4321,
      "step": 513060
    },
    {
      "epoch": 824.89,
      "learning_rate": 0.01754509853215434,
      "loss": 2.4059,
      "step": 513080
    },
    {
      "epoch": 824.92,
      "learning_rate": 0.01754188310128617,
      "loss": 2.42,
      "step": 513100
    },
    {
      "epoch": 824.95,
      "learning_rate": 0.017538667670418,
      "loss": 2.4407,
      "step": 513120
    },
    {
      "epoch": 824.98,
      "learning_rate": 0.017535452239549842,
      "loss": 2.4324,
      "step": 513140
    },
    {
      "epoch": 825.0,
      "eval_accuracy": {
        "accuracy": 0.45580346730933685
      },
      "eval_loss": 2.534215211868286,
      "eval_runtime": 3.5347,
      "eval_samples_per_second": 3639.07,
      "eval_steps_per_second": 56.865,
      "step": 513150
    },
    {
      "epoch": 825.02,
      "learning_rate": 0.017532236808681673,
      "loss": 2.4169,
      "step": 513160
    },
    {
      "epoch": 825.05,
      "learning_rate": 0.017529021377813505,
      "loss": 2.4195,
      "step": 513180
    },
    {
      "epoch": 825.08,
      "learning_rate": 0.017525805946945337,
      "loss": 2.4158,
      "step": 513200
    },
    {
      "epoch": 825.11,
      "learning_rate": 0.017522590516077165,
      "loss": 2.4142,
      "step": 513220
    },
    {
      "epoch": 825.14,
      "learning_rate": 0.017519375085209007,
      "loss": 2.4052,
      "step": 513240
    },
    {
      "epoch": 825.18,
      "learning_rate": 0.01751615965434084,
      "loss": 2.4111,
      "step": 513260
    },
    {
      "epoch": 825.21,
      "learning_rate": 0.01751294422347267,
      "loss": 2.4313,
      "step": 513280
    },
    {
      "epoch": 825.24,
      "learning_rate": 0.0175097287926045,
      "loss": 2.4187,
      "step": 513300
    },
    {
      "epoch": 825.27,
      "learning_rate": 0.017506513361736333,
      "loss": 2.4177,
      "step": 513320
    },
    {
      "epoch": 825.31,
      "learning_rate": 0.01750329793086816,
      "loss": 2.4369,
      "step": 513340
    },
    {
      "epoch": 825.34,
      "learning_rate": 0.017500082500000003,
      "loss": 2.4422,
      "step": 513360
    },
    {
      "epoch": 825.37,
      "learning_rate": 0.017496867069131835,
      "loss": 2.4131,
      "step": 513380
    },
    {
      "epoch": 825.4,
      "learning_rate": 0.017493812409807078,
      "loss": 2.4104,
      "step": 513400
    },
    {
      "epoch": 825.43,
      "learning_rate": 0.01749059697893891,
      "loss": 2.43,
      "step": 513420
    },
    {
      "epoch": 825.47,
      "learning_rate": 0.017487381548070738,
      "loss": 2.4084,
      "step": 513440
    },
    {
      "epoch": 825.5,
      "learning_rate": 0.01748416611720257,
      "loss": 2.4324,
      "step": 513460
    },
    {
      "epoch": 825.53,
      "learning_rate": 0.0174809506863344,
      "loss": 2.4409,
      "step": 513480
    },
    {
      "epoch": 825.56,
      "learning_rate": 0.017477735255466243,
      "loss": 2.4156,
      "step": 513500
    },
    {
      "epoch": 825.59,
      "learning_rate": 0.017474519824598075,
      "loss": 2.4049,
      "step": 513520
    },
    {
      "epoch": 825.63,
      "learning_rate": 0.017471304393729903,
      "loss": 2.4121,
      "step": 513540
    },
    {
      "epoch": 825.66,
      "learning_rate": 0.017468088962861734,
      "loss": 2.4148,
      "step": 513560
    },
    {
      "epoch": 825.69,
      "learning_rate": 0.017464873531993566,
      "loss": 2.42,
      "step": 513580
    },
    {
      "epoch": 825.72,
      "learning_rate": 0.017461658101125398,
      "loss": 2.4194,
      "step": 513600
    },
    {
      "epoch": 825.76,
      "learning_rate": 0.01745844267025724,
      "loss": 2.4365,
      "step": 513620
    },
    {
      "epoch": 825.79,
      "learning_rate": 0.017455227239389068,
      "loss": 2.4092,
      "step": 513640
    },
    {
      "epoch": 825.82,
      "learning_rate": 0.0174520118085209,
      "loss": 2.4011,
      "step": 513660
    },
    {
      "epoch": 825.85,
      "learning_rate": 0.01744879637765273,
      "loss": 2.4317,
      "step": 513680
    },
    {
      "epoch": 825.88,
      "learning_rate": 0.017445580946784563,
      "loss": 2.3953,
      "step": 513700
    },
    {
      "epoch": 825.92,
      "learning_rate": 0.017442365515916405,
      "loss": 2.4194,
      "step": 513720
    },
    {
      "epoch": 825.95,
      "learning_rate": 0.017439150085048236,
      "loss": 2.4198,
      "step": 513740
    },
    {
      "epoch": 825.98,
      "learning_rate": 0.017435934654180064,
      "loss": 2.4182,
      "step": 513760
    },
    {
      "epoch": 826.0,
      "eval_accuracy": {
        "accuracy": 0.4596905853999845
      },
      "eval_loss": 2.535515069961548,
      "eval_runtime": 3.4607,
      "eval_samples_per_second": 3716.864,
      "eval_steps_per_second": 58.081,
      "step": 513772
    },
    {
      "epoch": 826.01,
      "learning_rate": 0.017432719223311896,
      "loss": 2.4266,
      "step": 513780
    },
    {
      "epoch": 826.05,
      "learning_rate": 0.017429503792443728,
      "loss": 2.3968,
      "step": 513800
    },
    {
      "epoch": 826.08,
      "learning_rate": 0.01742628836157556,
      "loss": 2.4267,
      "step": 513820
    },
    {
      "epoch": 826.11,
      "learning_rate": 0.0174230729307074,
      "loss": 2.4123,
      "step": 513840
    },
    {
      "epoch": 826.14,
      "learning_rate": 0.01741985749983923,
      "loss": 2.4258,
      "step": 513860
    },
    {
      "epoch": 826.17,
      "learning_rate": 0.01741664206897106,
      "loss": 2.4046,
      "step": 513880
    },
    {
      "epoch": 826.21,
      "learning_rate": 0.017413426638102893,
      "loss": 2.416,
      "step": 513900
    },
    {
      "epoch": 826.24,
      "learning_rate": 0.017410211207234724,
      "loss": 2.425,
      "step": 513920
    },
    {
      "epoch": 826.27,
      "learning_rate": 0.017406995776366552,
      "loss": 2.4072,
      "step": 513940
    },
    {
      "epoch": 826.3,
      "learning_rate": 0.017403780345498394,
      "loss": 2.4248,
      "step": 513960
    },
    {
      "epoch": 826.33,
      "learning_rate": 0.017400564914630226,
      "loss": 2.4193,
      "step": 513980
    },
    {
      "epoch": 826.37,
      "learning_rate": 0.017397349483762058,
      "loss": 2.4154,
      "step": 514000
    },
    {
      "epoch": 826.4,
      "learning_rate": 0.01739413405289389,
      "loss": 2.4166,
      "step": 514020
    },
    {
      "epoch": 826.43,
      "learning_rate": 0.01739091862202572,
      "loss": 2.4235,
      "step": 514040
    },
    {
      "epoch": 826.46,
      "learning_rate": 0.017387703191157563,
      "loss": 2.4287,
      "step": 514060
    },
    {
      "epoch": 826.5,
      "learning_rate": 0.01738448776028939,
      "loss": 2.4274,
      "step": 514080
    },
    {
      "epoch": 826.53,
      "learning_rate": 0.017381272329421223,
      "loss": 2.4091,
      "step": 514100
    },
    {
      "epoch": 826.56,
      "learning_rate": 0.017378056898553054,
      "loss": 2.4185,
      "step": 514120
    },
    {
      "epoch": 826.59,
      "learning_rate": 0.017374841467684886,
      "loss": 2.4104,
      "step": 514140
    },
    {
      "epoch": 826.62,
      "learning_rate": 0.017371626036816714,
      "loss": 2.4216,
      "step": 514160
    },
    {
      "epoch": 826.66,
      "learning_rate": 0.017368410605948556,
      "loss": 2.416,
      "step": 514180
    },
    {
      "epoch": 826.69,
      "learning_rate": 0.017365195175080388,
      "loss": 2.4183,
      "step": 514200
    },
    {
      "epoch": 826.72,
      "learning_rate": 0.01736197974421222,
      "loss": 2.4312,
      "step": 514220
    },
    {
      "epoch": 826.75,
      "learning_rate": 0.01735876431334405,
      "loss": 2.3967,
      "step": 514240
    },
    {
      "epoch": 826.78,
      "learning_rate": 0.01735554888247588,
      "loss": 2.4199,
      "step": 514260
    },
    {
      "epoch": 826.82,
      "learning_rate": 0.01735233345160771,
      "loss": 2.4264,
      "step": 514280
    },
    {
      "epoch": 826.85,
      "learning_rate": 0.017349118020739553,
      "loss": 2.4365,
      "step": 514300
    },
    {
      "epoch": 826.88,
      "learning_rate": 0.017345902589871384,
      "loss": 2.4332,
      "step": 514320
    },
    {
      "epoch": 826.91,
      "learning_rate": 0.017342687159003216,
      "loss": 2.3946,
      "step": 514340
    },
    {
      "epoch": 826.95,
      "learning_rate": 0.017339471728135047,
      "loss": 2.4227,
      "step": 514360
    },
    {
      "epoch": 826.98,
      "learning_rate": 0.017336417068810287,
      "loss": 2.4185,
      "step": 514380
    },
    {
      "epoch": 827.0,
      "eval_accuracy": {
        "accuracy": 0.4558812096711498
      },
      "eval_loss": 2.5318093299865723,
      "eval_runtime": 3.3932,
      "eval_samples_per_second": 3790.794,
      "eval_steps_per_second": 59.236,
      "step": 514394
    },
    {
      "epoch": 827.01,
      "learning_rate": 0.01733320163794212,
      "loss": 2.4194,
      "step": 514400
    },
    {
      "epoch": 827.04,
      "learning_rate": 0.01732998620707395,
      "loss": 2.4202,
      "step": 514420
    },
    {
      "epoch": 827.07,
      "learning_rate": 0.017326770776205792,
      "loss": 2.4098,
      "step": 514440
    },
    {
      "epoch": 827.11,
      "learning_rate": 0.017323555345337624,
      "loss": 2.431,
      "step": 514460
    },
    {
      "epoch": 827.14,
      "learning_rate": 0.017320339914469452,
      "loss": 2.4151,
      "step": 514480
    },
    {
      "epoch": 827.17,
      "learning_rate": 0.017317124483601284,
      "loss": 2.3939,
      "step": 514500
    },
    {
      "epoch": 827.2,
      "learning_rate": 0.017313909052733115,
      "loss": 2.4382,
      "step": 514520
    },
    {
      "epoch": 827.23,
      "learning_rate": 0.017310693621864957,
      "loss": 2.417,
      "step": 514540
    },
    {
      "epoch": 827.27,
      "learning_rate": 0.01730747819099679,
      "loss": 2.4325,
      "step": 514560
    },
    {
      "epoch": 827.3,
      "learning_rate": 0.017304262760128617,
      "loss": 2.4396,
      "step": 514580
    },
    {
      "epoch": 827.33,
      "learning_rate": 0.01730104732926045,
      "loss": 2.4301,
      "step": 514600
    },
    {
      "epoch": 827.36,
      "learning_rate": 0.01729783189839228,
      "loss": 2.4213,
      "step": 514620
    },
    {
      "epoch": 827.4,
      "learning_rate": 0.017294616467524112,
      "loss": 2.4294,
      "step": 514640
    },
    {
      "epoch": 827.43,
      "learning_rate": 0.017291401036655954,
      "loss": 2.4247,
      "step": 514660
    },
    {
      "epoch": 827.46,
      "learning_rate": 0.017288185605787782,
      "loss": 2.4088,
      "step": 514680
    },
    {
      "epoch": 827.49,
      "learning_rate": 0.017284970174919614,
      "loss": 2.4262,
      "step": 514700
    },
    {
      "epoch": 827.52,
      "learning_rate": 0.017281754744051445,
      "loss": 2.4227,
      "step": 514720
    },
    {
      "epoch": 827.56,
      "learning_rate": 0.017278539313183277,
      "loss": 2.4261,
      "step": 514740
    },
    {
      "epoch": 827.59,
      "learning_rate": 0.01727532388231511,
      "loss": 2.4053,
      "step": 514760
    },
    {
      "epoch": 827.62,
      "learning_rate": 0.01727210845144695,
      "loss": 2.4099,
      "step": 514780
    },
    {
      "epoch": 827.65,
      "learning_rate": 0.01726889302057878,
      "loss": 2.4263,
      "step": 514800
    },
    {
      "epoch": 827.68,
      "learning_rate": 0.01726567758971061,
      "loss": 2.3993,
      "step": 514820
    },
    {
      "epoch": 827.72,
      "learning_rate": 0.017262462158842442,
      "loss": 2.4094,
      "step": 514840
    },
    {
      "epoch": 827.75,
      "learning_rate": 0.017259246727974274,
      "loss": 2.4121,
      "step": 514860
    },
    {
      "epoch": 827.78,
      "learning_rate": 0.017256031297106116,
      "loss": 2.4126,
      "step": 514880
    },
    {
      "epoch": 827.81,
      "learning_rate": 0.017252815866237944,
      "loss": 2.4208,
      "step": 514900
    },
    {
      "epoch": 827.85,
      "learning_rate": 0.017249600435369775,
      "loss": 2.4279,
      "step": 514920
    },
    {
      "epoch": 827.88,
      "learning_rate": 0.017246385004501607,
      "loss": 2.4135,
      "step": 514940
    },
    {
      "epoch": 827.91,
      "learning_rate": 0.01724316957363344,
      "loss": 2.4014,
      "step": 514960
    },
    {
      "epoch": 827.94,
      "learning_rate": 0.01723995414276527,
      "loss": 2.4271,
      "step": 514980
    },
    {
      "epoch": 827.97,
      "learning_rate": 0.01723673871189711,
      "loss": 2.4124,
      "step": 515000
    },
    {
      "epoch": 828.0,
      "eval_accuracy": {
        "accuracy": 0.454015392987639
      },
      "eval_loss": 2.5427777767181396,
      "eval_runtime": 3.3831,
      "eval_samples_per_second": 3802.155,
      "eval_steps_per_second": 59.413,
      "step": 515016
    },
    {
      "epoch": 828.01,
      "learning_rate": 0.01723352328102894,
      "loss": 2.4175,
      "step": 515020
    },
    {
      "epoch": 828.04,
      "learning_rate": 0.017230307850160772,
      "loss": 2.4121,
      "step": 515040
    },
    {
      "epoch": 828.07,
      "learning_rate": 0.017227092419292604,
      "loss": 2.4074,
      "step": 515060
    },
    {
      "epoch": 828.1,
      "learning_rate": 0.017223876988424435,
      "loss": 2.4238,
      "step": 515080
    },
    {
      "epoch": 828.14,
      "learning_rate": 0.017220661557556263,
      "loss": 2.4116,
      "step": 515100
    },
    {
      "epoch": 828.17,
      "learning_rate": 0.017217446126688105,
      "loss": 2.415,
      "step": 515120
    },
    {
      "epoch": 828.2,
      "learning_rate": 0.017214230695819937,
      "loss": 2.4274,
      "step": 515140
    },
    {
      "epoch": 828.23,
      "learning_rate": 0.01721101526495177,
      "loss": 2.4096,
      "step": 515160
    },
    {
      "epoch": 828.26,
      "learning_rate": 0.0172077998340836,
      "loss": 2.4126,
      "step": 515180
    },
    {
      "epoch": 828.3,
      "learning_rate": 0.017204584403215428,
      "loss": 2.4083,
      "step": 515200
    },
    {
      "epoch": 828.33,
      "learning_rate": 0.01720136897234727,
      "loss": 2.4158,
      "step": 515220
    },
    {
      "epoch": 828.36,
      "learning_rate": 0.017198153541479102,
      "loss": 2.4054,
      "step": 515240
    },
    {
      "epoch": 828.39,
      "learning_rate": 0.017194938110610933,
      "loss": 2.4224,
      "step": 515260
    },
    {
      "epoch": 828.42,
      "learning_rate": 0.017191722679742765,
      "loss": 2.414,
      "step": 515280
    },
    {
      "epoch": 828.46,
      "learning_rate": 0.017188507248874597,
      "loss": 2.4321,
      "step": 515300
    },
    {
      "epoch": 828.49,
      "learning_rate": 0.017185291818006425,
      "loss": 2.4099,
      "step": 515320
    },
    {
      "epoch": 828.52,
      "learning_rate": 0.017182076387138267,
      "loss": 2.4127,
      "step": 515340
    },
    {
      "epoch": 828.55,
      "learning_rate": 0.0171788609562701,
      "loss": 2.4205,
      "step": 515360
    },
    {
      "epoch": 828.59,
      "learning_rate": 0.01717564552540193,
      "loss": 2.4092,
      "step": 515380
    },
    {
      "epoch": 828.62,
      "learning_rate": 0.01717243009453376,
      "loss": 2.4196,
      "step": 515400
    },
    {
      "epoch": 828.65,
      "learning_rate": 0.01716921466366559,
      "loss": 2.4381,
      "step": 515420
    },
    {
      "epoch": 828.68,
      "learning_rate": 0.017165999232797432,
      "loss": 2.4161,
      "step": 515440
    },
    {
      "epoch": 828.71,
      "learning_rate": 0.017162783801929263,
      "loss": 2.4101,
      "step": 515460
    },
    {
      "epoch": 828.75,
      "learning_rate": 0.017159568371061095,
      "loss": 2.407,
      "step": 515480
    },
    {
      "epoch": 828.78,
      "learning_rate": 0.017156352940192927,
      "loss": 2.4066,
      "step": 515500
    },
    {
      "epoch": 828.81,
      "learning_rate": 0.017153137509324755,
      "loss": 2.4217,
      "step": 515520
    },
    {
      "epoch": 828.84,
      "learning_rate": 0.017149922078456586,
      "loss": 2.4008,
      "step": 515540
    },
    {
      "epoch": 828.87,
      "learning_rate": 0.01714670664758843,
      "loss": 2.4061,
      "step": 515560
    },
    {
      "epoch": 828.91,
      "learning_rate": 0.01714349121672026,
      "loss": 2.4102,
      "step": 515580
    },
    {
      "epoch": 828.94,
      "learning_rate": 0.01714027578585209,
      "loss": 2.4144,
      "step": 515600
    },
    {
      "epoch": 828.97,
      "learning_rate": 0.017137060354983923,
      "loss": 2.4266,
      "step": 515620
    },
    {
      "epoch": 829.0,
      "eval_accuracy": {
        "accuracy": 0.4510611832387468
      },
      "eval_loss": 2.5494890213012695,
      "eval_runtime": 3.0723,
      "eval_samples_per_second": 4186.708,
      "eval_steps_per_second": 65.422,
      "step": 515638
    },
    {
      "epoch": 829.0,
      "learning_rate": 0.01713384492411575,
      "loss": 2.4465,
      "step": 515640
    },
    {
      "epoch": 829.04,
      "learning_rate": 0.017130629493247583,
      "loss": 2.4449,
      "step": 515660
    },
    {
      "epoch": 829.07,
      "learning_rate": 0.017127414062379425,
      "loss": 2.4165,
      "step": 515680
    },
    {
      "epoch": 829.1,
      "learning_rate": 0.017124198631511257,
      "loss": 2.3967,
      "step": 515700
    },
    {
      "epoch": 829.13,
      "learning_rate": 0.01712098320064309,
      "loss": 2.4378,
      "step": 515720
    },
    {
      "epoch": 829.16,
      "learning_rate": 0.017117767769774916,
      "loss": 2.4144,
      "step": 515740
    },
    {
      "epoch": 829.2,
      "learning_rate": 0.017114552338906748,
      "loss": 2.41,
      "step": 515760
    },
    {
      "epoch": 829.23,
      "learning_rate": 0.01711133690803859,
      "loss": 2.4153,
      "step": 515780
    },
    {
      "epoch": 829.26,
      "learning_rate": 0.01710812147717042,
      "loss": 2.4048,
      "step": 515800
    },
    {
      "epoch": 829.29,
      "learning_rate": 0.017104906046302253,
      "loss": 2.4077,
      "step": 515820
    },
    {
      "epoch": 829.32,
      "learning_rate": 0.01710169061543408,
      "loss": 2.3944,
      "step": 515840
    },
    {
      "epoch": 829.36,
      "learning_rate": 0.017098475184565913,
      "loss": 2.4044,
      "step": 515860
    },
    {
      "epoch": 829.39,
      "learning_rate": 0.017095259753697745,
      "loss": 2.4028,
      "step": 515880
    },
    {
      "epoch": 829.42,
      "learning_rate": 0.017092044322829587,
      "loss": 2.4169,
      "step": 515900
    },
    {
      "epoch": 829.45,
      "learning_rate": 0.01708882889196142,
      "loss": 2.4214,
      "step": 515920
    },
    {
      "epoch": 829.49,
      "learning_rate": 0.01708561346109325,
      "loss": 2.4183,
      "step": 515940
    },
    {
      "epoch": 829.52,
      "learning_rate": 0.017082398030225078,
      "loss": 2.4266,
      "step": 515960
    },
    {
      "epoch": 829.55,
      "learning_rate": 0.01707918259935691,
      "loss": 2.4448,
      "step": 515980
    },
    {
      "epoch": 829.58,
      "learning_rate": 0.01707596716848874,
      "loss": 2.4074,
      "step": 516000
    },
    {
      "epoch": 829.61,
      "learning_rate": 0.017072751737620583,
      "loss": 2.4294,
      "step": 516020
    },
    {
      "epoch": 829.65,
      "learning_rate": 0.017069536306752415,
      "loss": 2.4085,
      "step": 516040
    },
    {
      "epoch": 829.68,
      "learning_rate": 0.017066320875884243,
      "loss": 2.4248,
      "step": 516060
    },
    {
      "epoch": 829.71,
      "learning_rate": 0.017063105445016075,
      "loss": 2.4142,
      "step": 516080
    },
    {
      "epoch": 829.74,
      "learning_rate": 0.017059890014147906,
      "loss": 2.4139,
      "step": 516100
    },
    {
      "epoch": 829.77,
      "learning_rate": 0.017056674583279748,
      "loss": 2.419,
      "step": 516120
    },
    {
      "epoch": 829.81,
      "learning_rate": 0.01705345915241158,
      "loss": 2.4402,
      "step": 516140
    },
    {
      "epoch": 829.84,
      "learning_rate": 0.017050243721543408,
      "loss": 2.4112,
      "step": 516160
    },
    {
      "epoch": 829.87,
      "learning_rate": 0.01704702829067524,
      "loss": 2.4102,
      "step": 516180
    },
    {
      "epoch": 829.9,
      "learning_rate": 0.01704381285980707,
      "loss": 2.4107,
      "step": 516200
    },
    {
      "epoch": 829.94,
      "learning_rate": 0.017040597428938903,
      "loss": 2.4214,
      "step": 516220
    },
    {
      "epoch": 829.97,
      "learning_rate": 0.017037381998070745,
      "loss": 2.4025,
      "step": 516240
    },
    {
      "epoch": 830.0,
      "learning_rate": 0.017034166567202576,
      "loss": 2.4296,
      "step": 516260
    },
    {
      "epoch": 830.0,
      "eval_accuracy": {
        "accuracy": 0.45937961595273263
      },
      "eval_loss": 2.524353504180908,
      "eval_runtime": 3.3198,
      "eval_samples_per_second": 3874.646,
      "eval_steps_per_second": 60.546,
      "step": 516260
    },
    {
      "epoch": 830.03,
      "learning_rate": 0.017030951136334405,
      "loss": 2.4177,
      "step": 516280
    },
    {
      "epoch": 830.06,
      "learning_rate": 0.017027735705466236,
      "loss": 2.423,
      "step": 516300
    },
    {
      "epoch": 830.1,
      "learning_rate": 0.017024520274598068,
      "loss": 2.4254,
      "step": 516320
    },
    {
      "epoch": 830.13,
      "learning_rate": 0.0170213048437299,
      "loss": 2.4132,
      "step": 516340
    },
    {
      "epoch": 830.16,
      "learning_rate": 0.01701808941286174,
      "loss": 2.4403,
      "step": 516360
    },
    {
      "epoch": 830.19,
      "learning_rate": 0.01701487398199357,
      "loss": 2.4303,
      "step": 516380
    },
    {
      "epoch": 830.23,
      "learning_rate": 0.0170116585511254,
      "loss": 2.4189,
      "step": 516400
    },
    {
      "epoch": 830.26,
      "learning_rate": 0.017008443120257233,
      "loss": 2.4435,
      "step": 516420
    },
    {
      "epoch": 830.29,
      "learning_rate": 0.017005227689389064,
      "loss": 2.4176,
      "step": 516440
    },
    {
      "epoch": 830.32,
      "learning_rate": 0.017002012258520906,
      "loss": 2.4137,
      "step": 516460
    },
    {
      "epoch": 830.35,
      "learning_rate": 0.016998796827652735,
      "loss": 2.4019,
      "step": 516480
    },
    {
      "epoch": 830.39,
      "learning_rate": 0.016995581396784566,
      "loss": 2.4126,
      "step": 516500
    },
    {
      "epoch": 830.42,
      "learning_rate": 0.016992365965916398,
      "loss": 2.4088,
      "step": 516520
    },
    {
      "epoch": 830.45,
      "learning_rate": 0.01698915053504823,
      "loss": 2.4094,
      "step": 516540
    },
    {
      "epoch": 830.48,
      "learning_rate": 0.01698593510418006,
      "loss": 2.4082,
      "step": 516560
    },
    {
      "epoch": 830.51,
      "learning_rate": 0.016982719673311903,
      "loss": 2.4155,
      "step": 516580
    },
    {
      "epoch": 830.55,
      "learning_rate": 0.01697950424244373,
      "loss": 2.406,
      "step": 516600
    },
    {
      "epoch": 830.58,
      "learning_rate": 0.016976288811575563,
      "loss": 2.4236,
      "step": 516620
    },
    {
      "epoch": 830.61,
      "learning_rate": 0.016973073380707394,
      "loss": 2.3983,
      "step": 516640
    },
    {
      "epoch": 830.64,
      "learning_rate": 0.016969857949839226,
      "loss": 2.4144,
      "step": 516660
    },
    {
      "epoch": 830.68,
      "learning_rate": 0.016966642518971054,
      "loss": 2.4232,
      "step": 516680
    },
    {
      "epoch": 830.71,
      "learning_rate": 0.016963427088102896,
      "loss": 2.4176,
      "step": 516700
    },
    {
      "epoch": 830.74,
      "learning_rate": 0.016960211657234728,
      "loss": 2.4165,
      "step": 516720
    },
    {
      "epoch": 830.77,
      "learning_rate": 0.01695699622636656,
      "loss": 2.4125,
      "step": 516740
    },
    {
      "epoch": 830.8,
      "learning_rate": 0.01695378079549839,
      "loss": 2.4208,
      "step": 516760
    },
    {
      "epoch": 830.84,
      "learning_rate": 0.01695056536463022,
      "loss": 2.396,
      "step": 516780
    },
    {
      "epoch": 830.87,
      "learning_rate": 0.01694734993376206,
      "loss": 2.4113,
      "step": 516800
    },
    {
      "epoch": 830.9,
      "learning_rate": 0.016944134502893893,
      "loss": 2.4175,
      "step": 516820
    },
    {
      "epoch": 830.93,
      "learning_rate": 0.016940919072025724,
      "loss": 2.4198,
      "step": 516840
    },
    {
      "epoch": 830.96,
      "learning_rate": 0.016937703641157556,
      "loss": 2.4042,
      "step": 516860
    },
    {
      "epoch": 831.0,
      "learning_rate": 0.016934488210289388,
      "loss": 2.4063,
      "step": 516880
    },
    {
      "epoch": 831.0,
      "eval_accuracy": {
        "accuracy": 0.4614009173598694
      },
      "eval_loss": 2.5217103958129883,
      "eval_runtime": 3.4708,
      "eval_samples_per_second": 3706.071,
      "eval_steps_per_second": 57.912,
      "step": 516882
    },
    {
      "epoch": 831.03,
      "learning_rate": 0.016931272779421216,
      "loss": 2.4193,
      "step": 516900
    },
    {
      "epoch": 831.06,
      "learning_rate": 0.016928057348553058,
      "loss": 2.4084,
      "step": 516920
    },
    {
      "epoch": 831.09,
      "learning_rate": 0.01692484191768489,
      "loss": 2.4183,
      "step": 516940
    },
    {
      "epoch": 831.13,
      "learning_rate": 0.01692162648681672,
      "loss": 2.4462,
      "step": 516960
    },
    {
      "epoch": 831.16,
      "learning_rate": 0.016918411055948553,
      "loss": 2.4103,
      "step": 516980
    },
    {
      "epoch": 831.19,
      "learning_rate": 0.01691519562508038,
      "loss": 2.4201,
      "step": 517000
    },
    {
      "epoch": 831.22,
      "learning_rate": 0.016911980194212212,
      "loss": 2.4196,
      "step": 517020
    },
    {
      "epoch": 831.25,
      "learning_rate": 0.016908764763344054,
      "loss": 2.3964,
      "step": 517040
    },
    {
      "epoch": 831.29,
      "learning_rate": 0.016905549332475886,
      "loss": 2.4244,
      "step": 517060
    },
    {
      "epoch": 831.32,
      "learning_rate": 0.016902333901607718,
      "loss": 2.433,
      "step": 517080
    },
    {
      "epoch": 831.35,
      "learning_rate": 0.016899118470739546,
      "loss": 2.4231,
      "step": 517100
    },
    {
      "epoch": 831.38,
      "learning_rate": 0.016895903039871377,
      "loss": 2.4174,
      "step": 517120
    },
    {
      "epoch": 831.41,
      "learning_rate": 0.01689268760900322,
      "loss": 2.4148,
      "step": 517140
    },
    {
      "epoch": 831.45,
      "learning_rate": 0.01688947217813505,
      "loss": 2.4154,
      "step": 517160
    },
    {
      "epoch": 831.48,
      "learning_rate": 0.016886256747266883,
      "loss": 2.3998,
      "step": 517180
    },
    {
      "epoch": 831.51,
      "learning_rate": 0.016883041316398714,
      "loss": 2.3921,
      "step": 517200
    },
    {
      "epoch": 831.54,
      "learning_rate": 0.016879825885530542,
      "loss": 2.4315,
      "step": 517220
    },
    {
      "epoch": 831.58,
      "learning_rate": 0.016876610454662374,
      "loss": 2.4106,
      "step": 517240
    },
    {
      "epoch": 831.61,
      "learning_rate": 0.016873395023794216,
      "loss": 2.4494,
      "step": 517260
    },
    {
      "epoch": 831.64,
      "learning_rate": 0.016870179592926048,
      "loss": 2.4214,
      "step": 517280
    },
    {
      "epoch": 831.67,
      "learning_rate": 0.01686696416205788,
      "loss": 2.4118,
      "step": 517300
    },
    {
      "epoch": 831.7,
      "learning_rate": 0.016863748731189707,
      "loss": 2.4234,
      "step": 517320
    },
    {
      "epoch": 831.74,
      "learning_rate": 0.01686053330032154,
      "loss": 2.4247,
      "step": 517340
    },
    {
      "epoch": 831.77,
      "learning_rate": 0.01685731786945338,
      "loss": 2.4179,
      "step": 517360
    },
    {
      "epoch": 831.8,
      "learning_rate": 0.016854102438585213,
      "loss": 2.4295,
      "step": 517380
    },
    {
      "epoch": 831.83,
      "learning_rate": 0.016850887007717044,
      "loss": 2.4102,
      "step": 517400
    },
    {
      "epoch": 831.86,
      "learning_rate": 0.016847671576848876,
      "loss": 2.393,
      "step": 517420
    },
    {
      "epoch": 831.9,
      "learning_rate": 0.016844456145980704,
      "loss": 2.4113,
      "step": 517440
    },
    {
      "epoch": 831.93,
      "learning_rate": 0.016841240715112536,
      "loss": 2.4106,
      "step": 517460
    },
    {
      "epoch": 831.96,
      "learning_rate": 0.016838025284244378,
      "loss": 2.4228,
      "step": 517480
    },
    {
      "epoch": 831.99,
      "learning_rate": 0.01683480985337621,
      "loss": 2.4108,
      "step": 517500
    },
    {
      "epoch": 832.0,
      "eval_accuracy": {
        "accuracy": 0.46194511389256004
      },
      "eval_loss": 2.5169997215270996,
      "eval_runtime": 3.1446,
      "eval_samples_per_second": 4090.449,
      "eval_steps_per_second": 63.918,
      "step": 517504
    },
    {
      "epoch": 832.03,
      "learning_rate": 0.01683159442250804,
      "loss": 2.4042,
      "step": 517520
    },
    {
      "epoch": 832.06,
      "learning_rate": 0.01682837899163987,
      "loss": 2.4128,
      "step": 517540
    },
    {
      "epoch": 832.09,
      "learning_rate": 0.0168251635607717,
      "loss": 2.4087,
      "step": 517560
    },
    {
      "epoch": 832.12,
      "learning_rate": 0.016821948129903532,
      "loss": 2.3921,
      "step": 517580
    },
    {
      "epoch": 832.15,
      "learning_rate": 0.016818732699035374,
      "loss": 2.4122,
      "step": 517600
    },
    {
      "epoch": 832.19,
      "learning_rate": 0.016815517268167206,
      "loss": 2.3945,
      "step": 517620
    },
    {
      "epoch": 832.22,
      "learning_rate": 0.016812301837299034,
      "loss": 2.3956,
      "step": 517640
    },
    {
      "epoch": 832.25,
      "learning_rate": 0.016809086406430866,
      "loss": 2.4276,
      "step": 517660
    },
    {
      "epoch": 832.28,
      "learning_rate": 0.016805870975562697,
      "loss": 2.4268,
      "step": 517680
    },
    {
      "epoch": 832.32,
      "learning_rate": 0.01680281631623794,
      "loss": 2.4053,
      "step": 517700
    },
    {
      "epoch": 832.35,
      "learning_rate": 0.01679960088536977,
      "loss": 2.4173,
      "step": 517720
    },
    {
      "epoch": 832.38,
      "learning_rate": 0.01679638545450161,
      "loss": 2.422,
      "step": 517740
    },
    {
      "epoch": 832.41,
      "learning_rate": 0.016793170023633442,
      "loss": 2.3966,
      "step": 517760
    },
    {
      "epoch": 832.44,
      "learning_rate": 0.016789954592765274,
      "loss": 2.4246,
      "step": 517780
    },
    {
      "epoch": 832.48,
      "learning_rate": 0.016786739161897105,
      "loss": 2.4037,
      "step": 517800
    },
    {
      "epoch": 832.51,
      "learning_rate": 0.016783523731028937,
      "loss": 2.4314,
      "step": 517820
    },
    {
      "epoch": 832.54,
      "learning_rate": 0.016780308300160765,
      "loss": 2.4023,
      "step": 517840
    },
    {
      "epoch": 832.57,
      "learning_rate": 0.016777092869292607,
      "loss": 2.4239,
      "step": 517860
    },
    {
      "epoch": 832.6,
      "learning_rate": 0.01677387743842444,
      "loss": 2.3863,
      "step": 517880
    },
    {
      "epoch": 832.64,
      "learning_rate": 0.01677066200755627,
      "loss": 2.4345,
      "step": 517900
    },
    {
      "epoch": 832.67,
      "learning_rate": 0.016767446576688102,
      "loss": 2.4188,
      "step": 517920
    },
    {
      "epoch": 832.7,
      "learning_rate": 0.01676423114581993,
      "loss": 2.4108,
      "step": 517940
    },
    {
      "epoch": 832.73,
      "learning_rate": 0.016761015714951772,
      "loss": 2.4323,
      "step": 517960
    },
    {
      "epoch": 832.77,
      "learning_rate": 0.016757800284083604,
      "loss": 2.4048,
      "step": 517980
    },
    {
      "epoch": 832.8,
      "learning_rate": 0.016754584853215435,
      "loss": 2.4088,
      "step": 518000
    },
    {
      "epoch": 832.83,
      "learning_rate": 0.016751369422347267,
      "loss": 2.4285,
      "step": 518020
    },
    {
      "epoch": 832.86,
      "learning_rate": 0.016748153991479095,
      "loss": 2.4176,
      "step": 518040
    },
    {
      "epoch": 832.89,
      "learning_rate": 0.016744938560610927,
      "loss": 2.4181,
      "step": 518060
    },
    {
      "epoch": 832.93,
      "learning_rate": 0.01674172312974277,
      "loss": 2.424,
      "step": 518080
    },
    {
      "epoch": 832.96,
      "learning_rate": 0.0167385076988746,
      "loss": 2.4158,
      "step": 518100
    },
    {
      "epoch": 832.99,
      "learning_rate": 0.016735292268006432,
      "loss": 2.4182,
      "step": 518120
    },
    {
      "epoch": 833.0,
      "eval_accuracy": {
        "accuracy": 0.46023478193267514
      },
      "eval_loss": 2.521219491958618,
      "eval_runtime": 3.3353,
      "eval_samples_per_second": 3856.586,
      "eval_steps_per_second": 60.264,
      "step": 518126
    },
    {
      "epoch": 833.02,
      "learning_rate": 0.016732076837138263,
      "loss": 2.4093,
      "step": 518140
    },
    {
      "epoch": 833.05,
      "learning_rate": 0.01672886140627009,
      "loss": 2.4152,
      "step": 518160
    },
    {
      "epoch": 833.09,
      "learning_rate": 0.016725645975401934,
      "loss": 2.4156,
      "step": 518180
    },
    {
      "epoch": 833.12,
      "learning_rate": 0.016722430544533765,
      "loss": 2.4118,
      "step": 518200
    },
    {
      "epoch": 833.15,
      "learning_rate": 0.016719215113665597,
      "loss": 2.4141,
      "step": 518220
    },
    {
      "epoch": 833.18,
      "learning_rate": 0.01671599968279743,
      "loss": 2.4044,
      "step": 518240
    },
    {
      "epoch": 833.22,
      "learning_rate": 0.016712784251929257,
      "loss": 2.4102,
      "step": 518260
    },
    {
      "epoch": 833.25,
      "learning_rate": 0.016709568821061088,
      "loss": 2.3888,
      "step": 518280
    },
    {
      "epoch": 833.28,
      "learning_rate": 0.01670635339019293,
      "loss": 2.4061,
      "step": 518300
    },
    {
      "epoch": 833.31,
      "learning_rate": 0.016703137959324762,
      "loss": 2.4267,
      "step": 518320
    },
    {
      "epoch": 833.34,
      "learning_rate": 0.016699922528456593,
      "loss": 2.4234,
      "step": 518340
    },
    {
      "epoch": 833.38,
      "learning_rate": 0.01669670709758842,
      "loss": 2.4265,
      "step": 518360
    },
    {
      "epoch": 833.41,
      "learning_rate": 0.016693491666720253,
      "loss": 2.4232,
      "step": 518380
    },
    {
      "epoch": 833.44,
      "learning_rate": 0.016690276235852085,
      "loss": 2.4127,
      "step": 518400
    },
    {
      "epoch": 833.47,
      "learning_rate": 0.016687060804983927,
      "loss": 2.4022,
      "step": 518420
    },
    {
      "epoch": 833.5,
      "learning_rate": 0.01668384537411576,
      "loss": 2.4299,
      "step": 518440
    },
    {
      "epoch": 833.54,
      "learning_rate": 0.01668062994324759,
      "loss": 2.4129,
      "step": 518460
    },
    {
      "epoch": 833.57,
      "learning_rate": 0.016677414512379418,
      "loss": 2.4073,
      "step": 518480
    },
    {
      "epoch": 833.6,
      "learning_rate": 0.01667419908151125,
      "loss": 2.4152,
      "step": 518500
    },
    {
      "epoch": 833.63,
      "learning_rate": 0.016670983650643092,
      "loss": 2.4017,
      "step": 518520
    },
    {
      "epoch": 833.67,
      "learning_rate": 0.016667768219774923,
      "loss": 2.3952,
      "step": 518540
    },
    {
      "epoch": 833.7,
      "learning_rate": 0.016664552788906755,
      "loss": 2.4138,
      "step": 518560
    },
    {
      "epoch": 833.73,
      "learning_rate": 0.016661337358038583,
      "loss": 2.4277,
      "step": 518580
    },
    {
      "epoch": 833.76,
      "learning_rate": 0.016658121927170415,
      "loss": 2.4077,
      "step": 518600
    },
    {
      "epoch": 833.79,
      "learning_rate": 0.016654906496302246,
      "loss": 2.4092,
      "step": 518620
    },
    {
      "epoch": 833.83,
      "learning_rate": 0.01665169106543409,
      "loss": 2.4081,
      "step": 518640
    },
    {
      "epoch": 833.86,
      "learning_rate": 0.01664847563456592,
      "loss": 2.4352,
      "step": 518660
    },
    {
      "epoch": 833.89,
      "learning_rate": 0.016645260203697748,
      "loss": 2.4189,
      "step": 518680
    },
    {
      "epoch": 833.92,
      "learning_rate": 0.01664204477282958,
      "loss": 2.3977,
      "step": 518700
    },
    {
      "epoch": 833.95,
      "learning_rate": 0.01663882934196141,
      "loss": 2.4083,
      "step": 518720
    },
    {
      "epoch": 833.99,
      "learning_rate": 0.016635613911093243,
      "loss": 2.4049,
      "step": 518740
    },
    {
      "epoch": 834.0,
      "eval_accuracy": {
        "accuracy": 0.45953510067635855
      },
      "eval_loss": 2.5248146057128906,
      "eval_runtime": 4.0121,
      "eval_samples_per_second": 3206.063,
      "eval_steps_per_second": 50.099,
      "step": 518748
    },
    {
      "epoch": 834.02,
      "learning_rate": 0.016632398480225085,
      "loss": 2.4146,
      "step": 518760
    },
    {
      "epoch": 834.05,
      "learning_rate": 0.016629183049356917,
      "loss": 2.3948,
      "step": 518780
    },
    {
      "epoch": 834.08,
      "learning_rate": 0.016625967618488745,
      "loss": 2.4095,
      "step": 518800
    },
    {
      "epoch": 834.12,
      "learning_rate": 0.016622752187620576,
      "loss": 2.4229,
      "step": 518820
    },
    {
      "epoch": 834.15,
      "learning_rate": 0.016619536756752408,
      "loss": 2.3896,
      "step": 518840
    },
    {
      "epoch": 834.18,
      "learning_rate": 0.01661632132588425,
      "loss": 2.4033,
      "step": 518860
    },
    {
      "epoch": 834.21,
      "learning_rate": 0.01661310589501608,
      "loss": 2.4108,
      "step": 518880
    },
    {
      "epoch": 834.24,
      "learning_rate": 0.01660989046414791,
      "loss": 2.4375,
      "step": 518900
    },
    {
      "epoch": 834.28,
      "learning_rate": 0.01660667503327974,
      "loss": 2.4198,
      "step": 518920
    },
    {
      "epoch": 834.31,
      "learning_rate": 0.016603459602411573,
      "loss": 2.4088,
      "step": 518940
    },
    {
      "epoch": 834.34,
      "learning_rate": 0.016600244171543405,
      "loss": 2.4116,
      "step": 518960
    },
    {
      "epoch": 834.37,
      "learning_rate": 0.016597028740675247,
      "loss": 2.416,
      "step": 518980
    },
    {
      "epoch": 834.41,
      "learning_rate": 0.016593813309807075,
      "loss": 2.4066,
      "step": 519000
    },
    {
      "epoch": 834.44,
      "learning_rate": 0.016590597878938906,
      "loss": 2.4175,
      "step": 519020
    },
    {
      "epoch": 834.47,
      "learning_rate": 0.016587382448070738,
      "loss": 2.4191,
      "step": 519040
    },
    {
      "epoch": 834.5,
      "learning_rate": 0.01658416701720257,
      "loss": 2.4257,
      "step": 519060
    },
    {
      "epoch": 834.53,
      "learning_rate": 0.0165809515863344,
      "loss": 2.4241,
      "step": 519080
    },
    {
      "epoch": 834.57,
      "learning_rate": 0.016577736155466243,
      "loss": 2.4159,
      "step": 519100
    },
    {
      "epoch": 834.6,
      "learning_rate": 0.01657452072459807,
      "loss": 2.3868,
      "step": 519120
    },
    {
      "epoch": 834.63,
      "learning_rate": 0.016571305293729903,
      "loss": 2.3997,
      "step": 519140
    },
    {
      "epoch": 834.66,
      "learning_rate": 0.016568089862861735,
      "loss": 2.4016,
      "step": 519160
    },
    {
      "epoch": 834.69,
      "learning_rate": 0.016564874431993566,
      "loss": 2.4188,
      "step": 519180
    },
    {
      "epoch": 834.73,
      "learning_rate": 0.016561659001125408,
      "loss": 2.4232,
      "step": 519200
    },
    {
      "epoch": 834.76,
      "learning_rate": 0.016558443570257236,
      "loss": 2.4186,
      "step": 519220
    },
    {
      "epoch": 834.79,
      "learning_rate": 0.016555228139389068,
      "loss": 2.4269,
      "step": 519240
    },
    {
      "epoch": 834.82,
      "learning_rate": 0.0165520127085209,
      "loss": 2.4163,
      "step": 519260
    },
    {
      "epoch": 834.86,
      "learning_rate": 0.01654879727765273,
      "loss": 2.4119,
      "step": 519280
    },
    {
      "epoch": 834.89,
      "learning_rate": 0.016545581846784563,
      "loss": 2.4027,
      "step": 519300
    },
    {
      "epoch": 834.92,
      "learning_rate": 0.0165423664159164,
      "loss": 2.4204,
      "step": 519320
    },
    {
      "epoch": 834.95,
      "learning_rate": 0.016539150985048233,
      "loss": 2.4203,
      "step": 519340
    },
    {
      "epoch": 834.98,
      "learning_rate": 0.016535935554180065,
      "loss": 2.4302,
      "step": 519360
    },
    {
      "epoch": 835.0,
      "eval_accuracy": {
        "accuracy": 0.45580346730933685
      },
      "eval_loss": 2.5301501750946045,
      "eval_runtime": 2.9667,
      "eval_samples_per_second": 4335.797,
      "eval_steps_per_second": 67.752,
      "step": 519370
    },
    {
      "epoch": 835.02,
      "learning_rate": 0.016532720123311896,
      "loss": 2.4131,
      "step": 519380
    },
    {
      "epoch": 835.05,
      "learning_rate": 0.016529504692443728,
      "loss": 2.4071,
      "step": 519400
    },
    {
      "epoch": 835.08,
      "learning_rate": 0.016526289261575556,
      "loss": 2.4109,
      "step": 519420
    },
    {
      "epoch": 835.11,
      "learning_rate": 0.016523073830707398,
      "loss": 2.4029,
      "step": 519440
    },
    {
      "epoch": 835.14,
      "learning_rate": 0.01651985839983923,
      "loss": 2.4227,
      "step": 519460
    },
    {
      "epoch": 835.18,
      "learning_rate": 0.01651664296897106,
      "loss": 2.3988,
      "step": 519480
    },
    {
      "epoch": 835.21,
      "learning_rate": 0.016513427538102893,
      "loss": 2.4118,
      "step": 519500
    },
    {
      "epoch": 835.24,
      "learning_rate": 0.01651021210723472,
      "loss": 2.4065,
      "step": 519520
    },
    {
      "epoch": 835.27,
      "learning_rate": 0.016506996676366563,
      "loss": 2.3942,
      "step": 519540
    },
    {
      "epoch": 835.31,
      "learning_rate": 0.016503781245498395,
      "loss": 2.4014,
      "step": 519560
    },
    {
      "epoch": 835.34,
      "learning_rate": 0.016500565814630226,
      "loss": 2.4243,
      "step": 519580
    },
    {
      "epoch": 835.37,
      "learning_rate": 0.016497350383762058,
      "loss": 2.4152,
      "step": 519600
    },
    {
      "epoch": 835.4,
      "learning_rate": 0.01649413495289389,
      "loss": 2.4039,
      "step": 519620
    },
    {
      "epoch": 835.43,
      "learning_rate": 0.016490919522025718,
      "loss": 2.4038,
      "step": 519640
    },
    {
      "epoch": 835.47,
      "learning_rate": 0.01648770409115756,
      "loss": 2.4268,
      "step": 519660
    },
    {
      "epoch": 835.5,
      "learning_rate": 0.01648448866028939,
      "loss": 2.4395,
      "step": 519680
    },
    {
      "epoch": 835.53,
      "learning_rate": 0.016481273229421223,
      "loss": 2.41,
      "step": 519700
    },
    {
      "epoch": 835.56,
      "learning_rate": 0.016478057798553054,
      "loss": 2.4148,
      "step": 519720
    },
    {
      "epoch": 835.59,
      "learning_rate": 0.016474842367684882,
      "loss": 2.4216,
      "step": 519740
    },
    {
      "epoch": 835.63,
      "learning_rate": 0.016471626936816714,
      "loss": 2.4043,
      "step": 519760
    },
    {
      "epoch": 835.66,
      "learning_rate": 0.016468411505948556,
      "loss": 2.4147,
      "step": 519780
    },
    {
      "epoch": 835.69,
      "learning_rate": 0.016465196075080388,
      "loss": 2.4142,
      "step": 519800
    },
    {
      "epoch": 835.72,
      "learning_rate": 0.01646198064421222,
      "loss": 2.4106,
      "step": 519820
    },
    {
      "epoch": 835.76,
      "learning_rate": 0.016458765213344047,
      "loss": 2.4113,
      "step": 519840
    },
    {
      "epoch": 835.79,
      "learning_rate": 0.01645554978247588,
      "loss": 2.4319,
      "step": 519860
    },
    {
      "epoch": 835.82,
      "learning_rate": 0.01645233435160772,
      "loss": 2.4057,
      "step": 519880
    },
    {
      "epoch": 835.85,
      "learning_rate": 0.016449118920739553,
      "loss": 2.3877,
      "step": 519900
    },
    {
      "epoch": 835.88,
      "learning_rate": 0.016445903489871384,
      "loss": 2.4012,
      "step": 519920
    },
    {
      "epoch": 835.92,
      "learning_rate": 0.016442688059003216,
      "loss": 2.4045,
      "step": 519940
    },
    {
      "epoch": 835.95,
      "learning_rate": 0.016439472628135044,
      "loss": 2.428,
      "step": 519960
    },
    {
      "epoch": 835.98,
      "learning_rate": 0.016436257197266876,
      "loss": 2.4318,
      "step": 519980
    },
    {
      "epoch": 836.0,
      "eval_accuracy": {
        "accuracy": 0.4540931353494519
      },
      "eval_loss": 2.5383083820343018,
      "eval_runtime": 3.3941,
      "eval_samples_per_second": 3789.806,
      "eval_steps_per_second": 59.22,
      "step": 519992
    },
    {
      "epoch": 836.01,
      "learning_rate": 0.016433041766398718,
      "loss": 2.4086,
      "step": 520000
    },
    {
      "epoch": 836.05,
      "learning_rate": 0.01642982633553055,
      "loss": 2.3929,
      "step": 520020
    },
    {
      "epoch": 836.08,
      "learning_rate": 0.01642661090466238,
      "loss": 2.4061,
      "step": 520040
    },
    {
      "epoch": 836.11,
      "learning_rate": 0.01642339547379421,
      "loss": 2.4081,
      "step": 520060
    },
    {
      "epoch": 836.14,
      "learning_rate": 0.01642018004292604,
      "loss": 2.4048,
      "step": 520080
    },
    {
      "epoch": 836.17,
      "learning_rate": 0.016416964612057883,
      "loss": 2.4156,
      "step": 520100
    },
    {
      "epoch": 836.21,
      "learning_rate": 0.016413749181189714,
      "loss": 2.4101,
      "step": 520120
    },
    {
      "epoch": 836.24,
      "learning_rate": 0.016410533750321546,
      "loss": 2.4133,
      "step": 520140
    },
    {
      "epoch": 836.27,
      "learning_rate": 0.016407318319453374,
      "loss": 2.426,
      "step": 520160
    },
    {
      "epoch": 836.3,
      "learning_rate": 0.016404102888585206,
      "loss": 2.4081,
      "step": 520180
    },
    {
      "epoch": 836.33,
      "learning_rate": 0.016400887457717037,
      "loss": 2.406,
      "step": 520200
    },
    {
      "epoch": 836.37,
      "learning_rate": 0.01639767202684888,
      "loss": 2.4034,
      "step": 520220
    },
    {
      "epoch": 836.4,
      "learning_rate": 0.01639445659598071,
      "loss": 2.4118,
      "step": 520240
    },
    {
      "epoch": 836.43,
      "learning_rate": 0.016391241165112543,
      "loss": 2.4245,
      "step": 520260
    },
    {
      "epoch": 836.46,
      "learning_rate": 0.01638802573424437,
      "loss": 2.422,
      "step": 520280
    },
    {
      "epoch": 836.5,
      "learning_rate": 0.016384810303376202,
      "loss": 2.4185,
      "step": 520300
    },
    {
      "epoch": 836.53,
      "learning_rate": 0.016381594872508034,
      "loss": 2.3895,
      "step": 520320
    },
    {
      "epoch": 836.56,
      "learning_rate": 0.016378379441639876,
      "loss": 2.4086,
      "step": 520340
    },
    {
      "epoch": 836.59,
      "learning_rate": 0.016375164010771708,
      "loss": 2.4096,
      "step": 520360
    },
    {
      "epoch": 836.62,
      "learning_rate": 0.016371948579903536,
      "loss": 2.4085,
      "step": 520380
    },
    {
      "epoch": 836.66,
      "learning_rate": 0.016368733149035367,
      "loss": 2.413,
      "step": 520400
    },
    {
      "epoch": 836.69,
      "learning_rate": 0.0163655177181672,
      "loss": 2.4096,
      "step": 520420
    },
    {
      "epoch": 836.72,
      "learning_rate": 0.01636230228729904,
      "loss": 2.4117,
      "step": 520440
    },
    {
      "epoch": 836.75,
      "learning_rate": 0.016359086856430873,
      "loss": 2.4131,
      "step": 520460
    },
    {
      "epoch": 836.78,
      "learning_rate": 0.0163558714255627,
      "loss": 2.3972,
      "step": 520480
    },
    {
      "epoch": 836.82,
      "learning_rate": 0.016352655994694532,
      "loss": 2.4122,
      "step": 520500
    },
    {
      "epoch": 836.85,
      "learning_rate": 0.016349440563826364,
      "loss": 2.4068,
      "step": 520520
    },
    {
      "epoch": 836.88,
      "learning_rate": 0.016346225132958195,
      "loss": 2.3979,
      "step": 520540
    },
    {
      "epoch": 836.91,
      "learning_rate": 0.016343170473633435,
      "loss": 2.4307,
      "step": 520560
    },
    {
      "epoch": 836.95,
      "learning_rate": 0.016339955042765267,
      "loss": 2.4157,
      "step": 520580
    },
    {
      "epoch": 836.98,
      "learning_rate": 0.01633673961189711,
      "loss": 2.3985,
      "step": 520600
    },
    {
      "epoch": 837.0,
      "eval_accuracy": {
        "accuracy": 0.46388867293788383
      },
      "eval_loss": 2.517946720123291,
      "eval_runtime": 3.2029,
      "eval_samples_per_second": 4016.087,
      "eval_steps_per_second": 62.756,
      "step": 520614
    },
    {
      "epoch": 837.01,
      "learning_rate": 0.01633352418102894,
      "loss": 2.4054,
      "step": 520620
    },
    {
      "epoch": 837.04,
      "learning_rate": 0.016330308750160772,
      "loss": 2.4131,
      "step": 520640
    },
    {
      "epoch": 837.07,
      "learning_rate": 0.016327093319292604,
      "loss": 2.3956,
      "step": 520660
    },
    {
      "epoch": 837.11,
      "learning_rate": 0.016323877888424432,
      "loss": 2.3892,
      "step": 520680
    },
    {
      "epoch": 837.14,
      "learning_rate": 0.016320662457556274,
      "loss": 2.4173,
      "step": 520700
    },
    {
      "epoch": 837.17,
      "learning_rate": 0.016317447026688105,
      "loss": 2.4243,
      "step": 520720
    },
    {
      "epoch": 837.2,
      "learning_rate": 0.016314231595819937,
      "loss": 2.4067,
      "step": 520740
    },
    {
      "epoch": 837.23,
      "learning_rate": 0.01631101616495177,
      "loss": 2.4193,
      "step": 520760
    },
    {
      "epoch": 837.27,
      "learning_rate": 0.016307800734083597,
      "loss": 2.3967,
      "step": 520780
    },
    {
      "epoch": 837.3,
      "learning_rate": 0.01630458530321543,
      "loss": 2.3963,
      "step": 520800
    },
    {
      "epoch": 837.33,
      "learning_rate": 0.01630136987234727,
      "loss": 2.3962,
      "step": 520820
    },
    {
      "epoch": 837.36,
      "learning_rate": 0.016298154441479102,
      "loss": 2.3931,
      "step": 520840
    },
    {
      "epoch": 837.4,
      "learning_rate": 0.016294939010610934,
      "loss": 2.4071,
      "step": 520860
    },
    {
      "epoch": 837.43,
      "learning_rate": 0.016291723579742762,
      "loss": 2.4143,
      "step": 520880
    },
    {
      "epoch": 837.46,
      "learning_rate": 0.016288508148874593,
      "loss": 2.425,
      "step": 520900
    },
    {
      "epoch": 837.49,
      "learning_rate": 0.016285292718006435,
      "loss": 2.4082,
      "step": 520920
    },
    {
      "epoch": 837.52,
      "learning_rate": 0.016282077287138267,
      "loss": 2.3936,
      "step": 520940
    },
    {
      "epoch": 837.56,
      "learning_rate": 0.0162788618562701,
      "loss": 2.4031,
      "step": 520960
    },
    {
      "epoch": 837.59,
      "learning_rate": 0.01627564642540193,
      "loss": 2.4166,
      "step": 520980
    },
    {
      "epoch": 837.62,
      "learning_rate": 0.01627243099453376,
      "loss": 2.4099,
      "step": 521000
    },
    {
      "epoch": 837.65,
      "learning_rate": 0.01626921556366559,
      "loss": 2.4171,
      "step": 521020
    },
    {
      "epoch": 837.68,
      "learning_rate": 0.016266000132797432,
      "loss": 2.4075,
      "step": 521040
    },
    {
      "epoch": 837.72,
      "learning_rate": 0.016262784701929264,
      "loss": 2.4146,
      "step": 521060
    },
    {
      "epoch": 837.75,
      "learning_rate": 0.016259569271061095,
      "loss": 2.4149,
      "step": 521080
    },
    {
      "epoch": 837.78,
      "learning_rate": 0.016256353840192923,
      "loss": 2.3931,
      "step": 521100
    },
    {
      "epoch": 837.81,
      "learning_rate": 0.016253138409324755,
      "loss": 2.3956,
      "step": 521120
    },
    {
      "epoch": 837.85,
      "learning_rate": 0.016249922978456587,
      "loss": 2.4182,
      "step": 521140
    },
    {
      "epoch": 837.88,
      "learning_rate": 0.01624670754758843,
      "loss": 2.4139,
      "step": 521160
    },
    {
      "epoch": 837.91,
      "learning_rate": 0.01624349211672026,
      "loss": 2.395,
      "step": 521180
    },
    {
      "epoch": 837.94,
      "learning_rate": 0.01624027668585209,
      "loss": 2.4336,
      "step": 521200
    },
    {
      "epoch": 837.97,
      "learning_rate": 0.01623706125498392,
      "loss": 2.4124,
      "step": 521220
    },
    {
      "epoch": 838.0,
      "eval_accuracy": {
        "accuracy": 0.4534711964549483
      },
      "eval_loss": 2.538198947906494,
      "eval_runtime": 3.0138,
      "eval_samples_per_second": 4268.063,
      "eval_steps_per_second": 66.694,
      "step": 521236
    },
    {
      "epoch": 838.01,
      "learning_rate": 0.01623384582411575,
      "loss": 2.4138,
      "step": 521240
    },
    {
      "epoch": 838.04,
      "learning_rate": 0.016230630393247594,
      "loss": 2.4104,
      "step": 521260
    },
    {
      "epoch": 838.07,
      "learning_rate": 0.016227414962379425,
      "loss": 2.4272,
      "step": 521280
    },
    {
      "epoch": 838.1,
      "learning_rate": 0.016224199531511257,
      "loss": 2.4103,
      "step": 521300
    },
    {
      "epoch": 838.14,
      "learning_rate": 0.016220984100643085,
      "loss": 2.4044,
      "step": 521320
    },
    {
      "epoch": 838.17,
      "learning_rate": 0.016217768669774917,
      "loss": 2.3772,
      "step": 521340
    },
    {
      "epoch": 838.2,
      "learning_rate": 0.016214553238906748,
      "loss": 2.408,
      "step": 521360
    },
    {
      "epoch": 838.23,
      "learning_rate": 0.01621133780803859,
      "loss": 2.4035,
      "step": 521380
    },
    {
      "epoch": 838.26,
      "learning_rate": 0.016208122377170422,
      "loss": 2.4041,
      "step": 521400
    },
    {
      "epoch": 838.3,
      "learning_rate": 0.01620490694630225,
      "loss": 2.4103,
      "step": 521420
    },
    {
      "epoch": 838.33,
      "learning_rate": 0.01620169151543408,
      "loss": 2.4097,
      "step": 521440
    },
    {
      "epoch": 838.36,
      "learning_rate": 0.016198476084565913,
      "loss": 2.432,
      "step": 521460
    },
    {
      "epoch": 838.39,
      "learning_rate": 0.016195260653697745,
      "loss": 2.3973,
      "step": 521480
    },
    {
      "epoch": 838.42,
      "learning_rate": 0.016192045222829587,
      "loss": 2.428,
      "step": 521500
    },
    {
      "epoch": 838.46,
      "learning_rate": 0.016188829791961415,
      "loss": 2.4193,
      "step": 521520
    },
    {
      "epoch": 838.49,
      "learning_rate": 0.016185614361093247,
      "loss": 2.4129,
      "step": 521540
    },
    {
      "epoch": 838.52,
      "learning_rate": 0.016182398930225078,
      "loss": 2.4052,
      "step": 521560
    },
    {
      "epoch": 838.55,
      "learning_rate": 0.01617918349935691,
      "loss": 2.385,
      "step": 521580
    },
    {
      "epoch": 838.59,
      "learning_rate": 0.016175968068488752,
      "loss": 2.3969,
      "step": 521600
    },
    {
      "epoch": 838.62,
      "learning_rate": 0.016172752637620583,
      "loss": 2.3965,
      "step": 521620
    },
    {
      "epoch": 838.65,
      "learning_rate": 0.01616953720675241,
      "loss": 2.4194,
      "step": 521640
    },
    {
      "epoch": 838.68,
      "learning_rate": 0.016166321775884243,
      "loss": 2.4213,
      "step": 521660
    },
    {
      "epoch": 838.71,
      "learning_rate": 0.016163106345016075,
      "loss": 2.4228,
      "step": 521680
    },
    {
      "epoch": 838.75,
      "learning_rate": 0.016159890914147906,
      "loss": 2.4104,
      "step": 521700
    },
    {
      "epoch": 838.78,
      "learning_rate": 0.01615667548327975,
      "loss": 2.412,
      "step": 521720
    },
    {
      "epoch": 838.81,
      "learning_rate": 0.016153460052411577,
      "loss": 2.3988,
      "step": 521740
    },
    {
      "epoch": 838.84,
      "learning_rate": 0.016150244621543408,
      "loss": 2.4101,
      "step": 521760
    },
    {
      "epoch": 838.87,
      "learning_rate": 0.01614702919067524,
      "loss": 2.3825,
      "step": 521780
    },
    {
      "epoch": 838.91,
      "learning_rate": 0.01614381375980707,
      "loss": 2.415,
      "step": 521800
    },
    {
      "epoch": 838.94,
      "learning_rate": 0.016140598328938903,
      "loss": 2.4013,
      "step": 521820
    },
    {
      "epoch": 838.97,
      "learning_rate": 0.01613738289807074,
      "loss": 2.4178,
      "step": 521840
    },
    {
      "epoch": 839.0,
      "eval_accuracy": {
        "accuracy": 0.45937961595273263
      },
      "eval_loss": 2.531825542449951,
      "eval_runtime": 3.0877,
      "eval_samples_per_second": 4165.843,
      "eval_steps_per_second": 65.096,
      "step": 521858
    },
    {
      "epoch": 839.0,
      "learning_rate": 0.016134167467202573,
      "loss": 2.4138,
      "step": 521860
    },
    {
      "epoch": 839.04,
      "learning_rate": 0.016130952036334405,
      "loss": 2.4255,
      "step": 521880
    },
    {
      "epoch": 839.07,
      "learning_rate": 0.016127736605466236,
      "loss": 2.4118,
      "step": 521900
    },
    {
      "epoch": 839.1,
      "learning_rate": 0.016124521174598068,
      "loss": 2.4064,
      "step": 521920
    },
    {
      "epoch": 839.13,
      "learning_rate": 0.01612130574372991,
      "loss": 2.4082,
      "step": 521940
    },
    {
      "epoch": 839.16,
      "learning_rate": 0.016118090312861738,
      "loss": 2.3832,
      "step": 521960
    },
    {
      "epoch": 839.2,
      "learning_rate": 0.01611487488199357,
      "loss": 2.4088,
      "step": 521980
    },
    {
      "epoch": 839.23,
      "learning_rate": 0.0161116594511254,
      "loss": 2.3936,
      "step": 522000
    },
    {
      "epoch": 839.26,
      "learning_rate": 0.016108444020257233,
      "loss": 2.3991,
      "step": 522020
    },
    {
      "epoch": 839.29,
      "learning_rate": 0.01610522858938906,
      "loss": 2.4243,
      "step": 522040
    },
    {
      "epoch": 839.32,
      "learning_rate": 0.016102013158520903,
      "loss": 2.3991,
      "step": 522060
    },
    {
      "epoch": 839.36,
      "learning_rate": 0.016098797727652735,
      "loss": 2.4105,
      "step": 522080
    },
    {
      "epoch": 839.39,
      "learning_rate": 0.016095582296784566,
      "loss": 2.4217,
      "step": 522100
    },
    {
      "epoch": 839.42,
      "learning_rate": 0.016092366865916398,
      "loss": 2.3898,
      "step": 522120
    },
    {
      "epoch": 839.45,
      "learning_rate": 0.01608915143504823,
      "loss": 2.4187,
      "step": 522140
    },
    {
      "epoch": 839.49,
      "learning_rate": 0.016085936004180058,
      "loss": 2.4057,
      "step": 522160
    },
    {
      "epoch": 839.52,
      "learning_rate": 0.0160827205733119,
      "loss": 2.4149,
      "step": 522180
    },
    {
      "epoch": 839.55,
      "learning_rate": 0.01607950514244373,
      "loss": 2.4038,
      "step": 522200
    },
    {
      "epoch": 839.58,
      "learning_rate": 0.016076289711575563,
      "loss": 2.4089,
      "step": 522220
    },
    {
      "epoch": 839.61,
      "learning_rate": 0.016073074280707395,
      "loss": 2.4035,
      "step": 522240
    },
    {
      "epoch": 839.65,
      "learning_rate": 0.016069858849839223,
      "loss": 2.3892,
      "step": 522260
    },
    {
      "epoch": 839.68,
      "learning_rate": 0.016066643418971065,
      "loss": 2.3926,
      "step": 522280
    },
    {
      "epoch": 839.71,
      "learning_rate": 0.016063427988102896,
      "loss": 2.4016,
      "step": 522300
    },
    {
      "epoch": 839.74,
      "learning_rate": 0.016060212557234728,
      "loss": 2.4136,
      "step": 522320
    },
    {
      "epoch": 839.77,
      "learning_rate": 0.01605699712636656,
      "loss": 2.4109,
      "step": 522340
    },
    {
      "epoch": 839.81,
      "learning_rate": 0.016053781695498388,
      "loss": 2.4102,
      "step": 522360
    },
    {
      "epoch": 839.84,
      "learning_rate": 0.01605056626463022,
      "loss": 2.4091,
      "step": 522380
    },
    {
      "epoch": 839.87,
      "learning_rate": 0.01604735083376206,
      "loss": 2.4126,
      "step": 522400
    },
    {
      "epoch": 839.9,
      "learning_rate": 0.016044135402893893,
      "loss": 2.4054,
      "step": 522420
    },
    {
      "epoch": 839.94,
      "learning_rate": 0.016040919972025725,
      "loss": 2.4072,
      "step": 522440
    },
    {
      "epoch": 839.97,
      "learning_rate": 0.016037704541157556,
      "loss": 2.4232,
      "step": 522460
    },
    {
      "epoch": 840.0,
      "learning_rate": 0.016034489110289384,
      "loss": 2.4068,
      "step": 522480
    },
    {
      "epoch": 840.0,
      "eval_accuracy": {
        "accuracy": 0.45720282982196997
      },
      "eval_loss": 2.5274081230163574,
      "eval_runtime": 3.2031,
      "eval_samples_per_second": 4015.853,
      "eval_steps_per_second": 62.753,
      "step": 522480
    },
    {
      "epoch": 840.03,
      "learning_rate": 0.016031273679421226,
      "loss": 2.4098,
      "step": 522500
    },
    {
      "epoch": 840.06,
      "learning_rate": 0.016028058248553058,
      "loss": 2.406,
      "step": 522520
    },
    {
      "epoch": 840.1,
      "learning_rate": 0.01602484281768489,
      "loss": 2.4129,
      "step": 522540
    },
    {
      "epoch": 840.13,
      "learning_rate": 0.01602162738681672,
      "loss": 2.4144,
      "step": 522560
    },
    {
      "epoch": 840.16,
      "learning_rate": 0.01601841195594855,
      "loss": 2.4097,
      "step": 522580
    },
    {
      "epoch": 840.19,
      "learning_rate": 0.01601519652508038,
      "loss": 2.4168,
      "step": 522600
    },
    {
      "epoch": 840.23,
      "learning_rate": 0.016011981094212223,
      "loss": 2.4047,
      "step": 522620
    },
    {
      "epoch": 840.26,
      "learning_rate": 0.016008765663344054,
      "loss": 2.4218,
      "step": 522640
    },
    {
      "epoch": 840.29,
      "learning_rate": 0.016005550232475886,
      "loss": 2.4003,
      "step": 522660
    },
    {
      "epoch": 840.32,
      "learning_rate": 0.016002334801607714,
      "loss": 2.3995,
      "step": 522680
    },
    {
      "epoch": 840.35,
      "learning_rate": 0.015999119370739546,
      "loss": 2.3994,
      "step": 522700
    },
    {
      "epoch": 840.39,
      "learning_rate": 0.015995903939871377,
      "loss": 2.4202,
      "step": 522720
    },
    {
      "epoch": 840.42,
      "learning_rate": 0.01599268850900322,
      "loss": 2.4067,
      "step": 522740
    },
    {
      "epoch": 840.45,
      "learning_rate": 0.01598947307813505,
      "loss": 2.4165,
      "step": 522760
    },
    {
      "epoch": 840.48,
      "learning_rate": 0.015986257647266883,
      "loss": 2.41,
      "step": 522780
    },
    {
      "epoch": 840.51,
      "learning_rate": 0.01598304221639871,
      "loss": 2.3912,
      "step": 522800
    },
    {
      "epoch": 840.55,
      "learning_rate": 0.015979826785530542,
      "loss": 2.4104,
      "step": 522820
    },
    {
      "epoch": 840.58,
      "learning_rate": 0.015976611354662384,
      "loss": 2.4248,
      "step": 522840
    },
    {
      "epoch": 840.61,
      "learning_rate": 0.015973395923794216,
      "loss": 2.4044,
      "step": 522860
    },
    {
      "epoch": 840.64,
      "learning_rate": 0.015970180492926048,
      "loss": 2.3915,
      "step": 522880
    },
    {
      "epoch": 840.68,
      "learning_rate": 0.015966965062057876,
      "loss": 2.3958,
      "step": 522900
    },
    {
      "epoch": 840.71,
      "learning_rate": 0.015963749631189707,
      "loss": 2.4113,
      "step": 522920
    },
    {
      "epoch": 840.74,
      "learning_rate": 0.01596053420032154,
      "loss": 2.4209,
      "step": 522940
    },
    {
      "epoch": 840.77,
      "learning_rate": 0.01595731876945338,
      "loss": 2.3997,
      "step": 522960
    },
    {
      "epoch": 840.8,
      "learning_rate": 0.015954103338585213,
      "loss": 2.392,
      "step": 522980
    },
    {
      "epoch": 840.84,
      "learning_rate": 0.01595088790771704,
      "loss": 2.4058,
      "step": 523000
    },
    {
      "epoch": 840.87,
      "learning_rate": 0.015947672476848872,
      "loss": 2.4065,
      "step": 523020
    },
    {
      "epoch": 840.9,
      "learning_rate": 0.015944457045980704,
      "loss": 2.4028,
      "step": 523040
    },
    {
      "epoch": 840.93,
      "learning_rate": 0.015941241615112536,
      "loss": 2.4165,
      "step": 523060
    },
    {
      "epoch": 840.96,
      "learning_rate": 0.015938026184244378,
      "loss": 2.3983,
      "step": 523080
    },
    {
      "epoch": 841.0,
      "learning_rate": 0.01593481075337621,
      "loss": 2.4067,
      "step": 523100
    },
    {
      "epoch": 841.0,
      "eval_accuracy": {
        "accuracy": 0.45603669439477573
      },
      "eval_loss": 2.5388476848602295,
      "eval_runtime": 3.1389,
      "eval_samples_per_second": 4097.976,
      "eval_steps_per_second": 64.036,
      "step": 523102
    },
    {
      "epoch": 841.03,
      "learning_rate": 0.015931595322508037,
      "loss": 2.4198,
      "step": 523120
    },
    {
      "epoch": 841.06,
      "learning_rate": 0.01592837989163987,
      "loss": 2.4012,
      "step": 523140
    },
    {
      "epoch": 841.09,
      "learning_rate": 0.0159251644607717,
      "loss": 2.3974,
      "step": 523160
    },
    {
      "epoch": 841.13,
      "learning_rate": 0.015921949029903543,
      "loss": 2.3912,
      "step": 523180
    },
    {
      "epoch": 841.16,
      "learning_rate": 0.015918733599035374,
      "loss": 2.4055,
      "step": 523200
    },
    {
      "epoch": 841.19,
      "learning_rate": 0.015915518168167202,
      "loss": 2.4179,
      "step": 523220
    },
    {
      "epoch": 841.22,
      "learning_rate": 0.015912302737299034,
      "loss": 2.4103,
      "step": 523240
    },
    {
      "epoch": 841.25,
      "learning_rate": 0.015909087306430866,
      "loss": 2.4031,
      "step": 523260
    },
    {
      "epoch": 841.29,
      "learning_rate": 0.015905871875562697,
      "loss": 2.4119,
      "step": 523280
    },
    {
      "epoch": 841.32,
      "learning_rate": 0.01590265644469454,
      "loss": 2.4156,
      "step": 523300
    },
    {
      "epoch": 841.35,
      "learning_rate": 0.015899441013826367,
      "loss": 2.4084,
      "step": 523320
    },
    {
      "epoch": 841.38,
      "learning_rate": 0.0158962255829582,
      "loss": 2.4056,
      "step": 523340
    },
    {
      "epoch": 841.41,
      "learning_rate": 0.01589301015209003,
      "loss": 2.4166,
      "step": 523360
    },
    {
      "epoch": 841.45,
      "learning_rate": 0.015889794721221862,
      "loss": 2.4016,
      "step": 523380
    },
    {
      "epoch": 841.48,
      "learning_rate": 0.015886579290353694,
      "loss": 2.3918,
      "step": 523400
    },
    {
      "epoch": 841.51,
      "learning_rate": 0.015883524631028934,
      "loss": 2.3961,
      "step": 523420
    },
    {
      "epoch": 841.54,
      "learning_rate": 0.015880309200160776,
      "loss": 2.4239,
      "step": 523440
    },
    {
      "epoch": 841.58,
      "learning_rate": 0.015877093769292607,
      "loss": 2.4212,
      "step": 523460
    },
    {
      "epoch": 841.61,
      "learning_rate": 0.01587387833842444,
      "loss": 2.4159,
      "step": 523480
    },
    {
      "epoch": 841.64,
      "learning_rate": 0.01587066290755627,
      "loss": 2.4098,
      "step": 523500
    },
    {
      "epoch": 841.67,
      "learning_rate": 0.0158674474766881,
      "loss": 2.4003,
      "step": 523520
    },
    {
      "epoch": 841.7,
      "learning_rate": 0.01586423204581993,
      "loss": 2.3943,
      "step": 523540
    },
    {
      "epoch": 841.74,
      "learning_rate": 0.015861016614951772,
      "loss": 2.3906,
      "step": 523560
    },
    {
      "epoch": 841.77,
      "learning_rate": 0.015857801184083604,
      "loss": 2.415,
      "step": 523580
    },
    {
      "epoch": 841.8,
      "learning_rate": 0.015854585753215435,
      "loss": 2.4224,
      "step": 523600
    },
    {
      "epoch": 841.83,
      "learning_rate": 0.015851370322347264,
      "loss": 2.385,
      "step": 523620
    },
    {
      "epoch": 841.86,
      "learning_rate": 0.015848154891479095,
      "loss": 2.3952,
      "step": 523640
    },
    {
      "epoch": 841.9,
      "learning_rate": 0.015844939460610937,
      "loss": 2.4018,
      "step": 523660
    },
    {
      "epoch": 841.93,
      "learning_rate": 0.01584172402974277,
      "loss": 2.4088,
      "step": 523680
    },
    {
      "epoch": 841.96,
      "learning_rate": 0.0158385085988746,
      "loss": 2.4077,
      "step": 523700
    },
    {
      "epoch": 841.99,
      "learning_rate": 0.01583529316800643,
      "loss": 2.4085,
      "step": 523720
    },
    {
      "epoch": 842.0,
      "eval_accuracy": {
        "accuracy": 0.46093446318899167
      },
      "eval_loss": 2.517733335494995,
      "eval_runtime": 3.3256,
      "eval_samples_per_second": 3867.821,
      "eval_steps_per_second": 60.439,
      "step": 523724
    },
    {
      "epoch": 842.03,
      "learning_rate": 0.01583207773713826,
      "loss": 2.3842,
      "step": 523740
    },
    {
      "epoch": 842.06,
      "learning_rate": 0.01582886230627009,
      "loss": 2.3965,
      "step": 523760
    },
    {
      "epoch": 842.09,
      "learning_rate": 0.015825646875401934,
      "loss": 2.3996,
      "step": 523780
    },
    {
      "epoch": 842.12,
      "learning_rate": 0.015822431444533765,
      "loss": 2.4008,
      "step": 523800
    },
    {
      "epoch": 842.15,
      "learning_rate": 0.015819216013665597,
      "loss": 2.4015,
      "step": 523820
    },
    {
      "epoch": 842.19,
      "learning_rate": 0.015816000582797425,
      "loss": 2.4311,
      "step": 523840
    },
    {
      "epoch": 842.22,
      "learning_rate": 0.015812785151929257,
      "loss": 2.3908,
      "step": 523860
    },
    {
      "epoch": 842.25,
      "learning_rate": 0.01580956972106109,
      "loss": 2.4215,
      "step": 523880
    },
    {
      "epoch": 842.28,
      "learning_rate": 0.01580635429019293,
      "loss": 2.4052,
      "step": 523900
    },
    {
      "epoch": 842.32,
      "learning_rate": 0.015803138859324762,
      "loss": 2.4047,
      "step": 523920
    },
    {
      "epoch": 842.35,
      "learning_rate": 0.01579992342845659,
      "loss": 2.4058,
      "step": 523940
    },
    {
      "epoch": 842.38,
      "learning_rate": 0.01579670799758842,
      "loss": 2.3992,
      "step": 523960
    },
    {
      "epoch": 842.41,
      "learning_rate": 0.015793492566720253,
      "loss": 2.4142,
      "step": 523980
    },
    {
      "epoch": 842.44,
      "learning_rate": 0.015790277135852095,
      "loss": 2.4063,
      "step": 524000
    },
    {
      "epoch": 842.48,
      "learning_rate": 0.015787061704983927,
      "loss": 2.387,
      "step": 524020
    },
    {
      "epoch": 842.51,
      "learning_rate": 0.015783846274115755,
      "loss": 2.409,
      "step": 524040
    },
    {
      "epoch": 842.54,
      "learning_rate": 0.015780630843247587,
      "loss": 2.3911,
      "step": 524060
    },
    {
      "epoch": 842.57,
      "learning_rate": 0.01577741541237942,
      "loss": 2.4068,
      "step": 524080
    },
    {
      "epoch": 842.6,
      "learning_rate": 0.01577419998151125,
      "loss": 2.4192,
      "step": 524100
    },
    {
      "epoch": 842.64,
      "learning_rate": 0.015770984550643092,
      "loss": 2.3932,
      "step": 524120
    },
    {
      "epoch": 842.67,
      "learning_rate": 0.015767769119774924,
      "loss": 2.4039,
      "step": 524140
    },
    {
      "epoch": 842.7,
      "learning_rate": 0.01576455368890675,
      "loss": 2.4029,
      "step": 524160
    },
    {
      "epoch": 842.73,
      "learning_rate": 0.015761338258038583,
      "loss": 2.4127,
      "step": 524180
    },
    {
      "epoch": 842.77,
      "learning_rate": 0.015758122827170415,
      "loss": 2.4191,
      "step": 524200
    },
    {
      "epoch": 842.8,
      "learning_rate": 0.015754907396302247,
      "loss": 2.3944,
      "step": 524220
    },
    {
      "epoch": 842.83,
      "learning_rate": 0.01575169196543409,
      "loss": 2.4266,
      "step": 524240
    },
    {
      "epoch": 842.86,
      "learning_rate": 0.015748476534565917,
      "loss": 2.3938,
      "step": 524260
    },
    {
      "epoch": 842.89,
      "learning_rate": 0.01574526110369775,
      "loss": 2.4076,
      "step": 524280
    },
    {
      "epoch": 842.93,
      "learning_rate": 0.01574204567282958,
      "loss": 2.4072,
      "step": 524300
    },
    {
      "epoch": 842.96,
      "learning_rate": 0.01573883024196141,
      "loss": 2.3951,
      "step": 524320
    },
    {
      "epoch": 842.99,
      "learning_rate": 0.015735614811093254,
      "loss": 2.4074,
      "step": 524340
    },
    {
      "epoch": 843.0,
      "eval_accuracy": {
        "accuracy": 0.4586799346964161
      },
      "eval_loss": 2.524380683898926,
      "eval_runtime": 3.2479,
      "eval_samples_per_second": 3960.44,
      "eval_steps_per_second": 61.887,
      "step": 524346
    },
    {
      "epoch": 843.02,
      "learning_rate": 0.01573239938022508,
      "loss": 2.3973,
      "step": 524360
    },
    {
      "epoch": 843.05,
      "learning_rate": 0.015729183949356913,
      "loss": 2.3949,
      "step": 524380
    },
    {
      "epoch": 843.09,
      "learning_rate": 0.015725968518488745,
      "loss": 2.4251,
      "step": 524400
    },
    {
      "epoch": 843.12,
      "learning_rate": 0.015722753087620576,
      "loss": 2.3991,
      "step": 524420
    },
    {
      "epoch": 843.15,
      "learning_rate": 0.015719537656752408,
      "loss": 2.4144,
      "step": 524440
    },
    {
      "epoch": 843.18,
      "learning_rate": 0.01571632222588425,
      "loss": 2.395,
      "step": 524460
    },
    {
      "epoch": 843.22,
      "learning_rate": 0.01571310679501608,
      "loss": 2.4008,
      "step": 524480
    },
    {
      "epoch": 843.25,
      "learning_rate": 0.01570989136414791,
      "loss": 2.4072,
      "step": 524500
    },
    {
      "epoch": 843.28,
      "learning_rate": 0.01570667593327974,
      "loss": 2.4148,
      "step": 524520
    },
    {
      "epoch": 843.31,
      "learning_rate": 0.015703460502411573,
      "loss": 2.3976,
      "step": 524540
    },
    {
      "epoch": 843.34,
      "learning_rate": 0.0157002450715434,
      "loss": 2.4152,
      "step": 524560
    },
    {
      "epoch": 843.38,
      "learning_rate": 0.015697029640675243,
      "loss": 2.3966,
      "step": 524580
    },
    {
      "epoch": 843.41,
      "learning_rate": 0.015693814209807075,
      "loss": 2.4119,
      "step": 524600
    },
    {
      "epoch": 843.44,
      "learning_rate": 0.015690598778938906,
      "loss": 2.3928,
      "step": 524620
    },
    {
      "epoch": 843.47,
      "learning_rate": 0.015687383348070738,
      "loss": 2.4064,
      "step": 524640
    },
    {
      "epoch": 843.5,
      "learning_rate": 0.01568416791720257,
      "loss": 2.3949,
      "step": 524660
    },
    {
      "epoch": 843.54,
      "learning_rate": 0.01568095248633441,
      "loss": 2.4008,
      "step": 524680
    },
    {
      "epoch": 843.57,
      "learning_rate": 0.01567773705546624,
      "loss": 2.408,
      "step": 524700
    },
    {
      "epoch": 843.6,
      "learning_rate": 0.01567452162459807,
      "loss": 2.4199,
      "step": 524720
    },
    {
      "epoch": 843.63,
      "learning_rate": 0.015671306193729903,
      "loss": 2.4016,
      "step": 524740
    },
    {
      "epoch": 843.67,
      "learning_rate": 0.015668090762861735,
      "loss": 2.4118,
      "step": 524760
    },
    {
      "epoch": 843.7,
      "learning_rate": 0.015664875331993563,
      "loss": 2.3923,
      "step": 524780
    },
    {
      "epoch": 843.73,
      "learning_rate": 0.015661659901125405,
      "loss": 2.4026,
      "step": 524800
    },
    {
      "epoch": 843.76,
      "learning_rate": 0.015658444470257236,
      "loss": 2.409,
      "step": 524820
    },
    {
      "epoch": 843.79,
      "learning_rate": 0.015655229039389068,
      "loss": 2.3764,
      "step": 524840
    },
    {
      "epoch": 843.83,
      "learning_rate": 0.0156520136085209,
      "loss": 2.4127,
      "step": 524860
    },
    {
      "epoch": 843.86,
      "learning_rate": 0.015648798177652728,
      "loss": 2.4018,
      "step": 524880
    },
    {
      "epoch": 843.89,
      "learning_rate": 0.01564558274678456,
      "loss": 2.405,
      "step": 524900
    },
    {
      "epoch": 843.92,
      "learning_rate": 0.0156423673159164,
      "loss": 2.4038,
      "step": 524920
    },
    {
      "epoch": 843.95,
      "learning_rate": 0.015639151885048233,
      "loss": 2.4116,
      "step": 524940
    },
    {
      "epoch": 843.99,
      "learning_rate": 0.015635936454180065,
      "loss": 2.4017,
      "step": 524960
    },
    {
      "epoch": 844.0,
      "eval_accuracy": {
        "accuracy": 0.46093446318899167
      },
      "eval_loss": 2.512796401977539,
      "eval_runtime": 3.0802,
      "eval_samples_per_second": 4176.009,
      "eval_steps_per_second": 65.255,
      "step": 524968
    },
    {
      "epoch": 844.02,
      "learning_rate": 0.015632721023311896,
      "loss": 2.3984,
      "step": 524980
    },
    {
      "epoch": 844.05,
      "learning_rate": 0.015629505592443724,
      "loss": 2.39,
      "step": 525000
    },
    {
      "epoch": 844.08,
      "learning_rate": 0.015626290161575566,
      "loss": 2.4071,
      "step": 525020
    },
    {
      "epoch": 844.12,
      "learning_rate": 0.015623074730707398,
      "loss": 2.4077,
      "step": 525040
    },
    {
      "epoch": 844.15,
      "learning_rate": 0.01561985929983923,
      "loss": 2.4188,
      "step": 525060
    },
    {
      "epoch": 844.18,
      "learning_rate": 0.01561664386897106,
      "loss": 2.3937,
      "step": 525080
    },
    {
      "epoch": 844.21,
      "learning_rate": 0.015613428438102893,
      "loss": 2.4015,
      "step": 525100
    },
    {
      "epoch": 844.24,
      "learning_rate": 0.01561021300723472,
      "loss": 2.4142,
      "step": 525120
    },
    {
      "epoch": 844.28,
      "learning_rate": 0.015606997576366563,
      "loss": 2.3919,
      "step": 525140
    },
    {
      "epoch": 844.31,
      "learning_rate": 0.015603782145498395,
      "loss": 2.4012,
      "step": 525160
    },
    {
      "epoch": 844.34,
      "learning_rate": 0.015600566714630225,
      "loss": 2.3928,
      "step": 525180
    },
    {
      "epoch": 844.37,
      "learning_rate": 0.015597351283762058,
      "loss": 2.3999,
      "step": 525200
    },
    {
      "epoch": 844.41,
      "learning_rate": 0.015594135852893884,
      "loss": 2.3876,
      "step": 525220
    },
    {
      "epoch": 844.44,
      "learning_rate": 0.015590920422025728,
      "loss": 2.3964,
      "step": 525240
    },
    {
      "epoch": 844.47,
      "learning_rate": 0.01558770499115756,
      "loss": 2.4048,
      "step": 525260
    },
    {
      "epoch": 844.5,
      "learning_rate": 0.015584489560289391,
      "loss": 2.3962,
      "step": 525280
    },
    {
      "epoch": 844.53,
      "learning_rate": 0.015581274129421223,
      "loss": 2.3994,
      "step": 525300
    },
    {
      "epoch": 844.57,
      "learning_rate": 0.015578058698553053,
      "loss": 2.4062,
      "step": 525320
    },
    {
      "epoch": 844.6,
      "learning_rate": 0.015574843267684883,
      "loss": 2.4072,
      "step": 525340
    },
    {
      "epoch": 844.63,
      "learning_rate": 0.015571627836816725,
      "loss": 2.4123,
      "step": 525360
    },
    {
      "epoch": 844.66,
      "learning_rate": 0.015568412405948556,
      "loss": 2.4152,
      "step": 525380
    },
    {
      "epoch": 844.69,
      "learning_rate": 0.015565196975080388,
      "loss": 2.4109,
      "step": 525400
    },
    {
      "epoch": 844.73,
      "learning_rate": 0.015561981544212218,
      "loss": 2.4112,
      "step": 525420
    },
    {
      "epoch": 844.76,
      "learning_rate": 0.015558766113344048,
      "loss": 2.3983,
      "step": 525440
    },
    {
      "epoch": 844.79,
      "learning_rate": 0.015555550682475877,
      "loss": 2.3995,
      "step": 525460
    },
    {
      "epoch": 844.82,
      "learning_rate": 0.015552335251607721,
      "loss": 2.4074,
      "step": 525480
    },
    {
      "epoch": 844.86,
      "learning_rate": 0.015549119820739553,
      "loss": 2.4181,
      "step": 525500
    },
    {
      "epoch": 844.89,
      "learning_rate": 0.015545904389871383,
      "loss": 2.4032,
      "step": 525520
    },
    {
      "epoch": 844.92,
      "learning_rate": 0.015542688959003213,
      "loss": 2.3959,
      "step": 525540
    },
    {
      "epoch": 844.95,
      "learning_rate": 0.015539473528135042,
      "loss": 2.4119,
      "step": 525560
    },
    {
      "epoch": 844.98,
      "learning_rate": 0.015536258097266886,
      "loss": 2.411,
      "step": 525580
    },
    {
      "epoch": 845.0,
      "eval_accuracy": {
        "accuracy": 0.45937961595273263
      },
      "eval_loss": 2.5167908668518066,
      "eval_runtime": 3.0854,
      "eval_samples_per_second": 4169.04,
      "eval_steps_per_second": 65.146,
      "step": 525590
    },
    {
      "epoch": 845.02,
      "learning_rate": 0.015533042666398718,
      "loss": 2.4133,
      "step": 525600
    },
    {
      "epoch": 845.05,
      "learning_rate": 0.015529827235530548,
      "loss": 2.4104,
      "step": 525620
    },
    {
      "epoch": 845.08,
      "learning_rate": 0.015526611804662381,
      "loss": 2.4015,
      "step": 525640
    },
    {
      "epoch": 845.11,
      "learning_rate": 0.015523396373794207,
      "loss": 2.4057,
      "step": 525660
    },
    {
      "epoch": 845.14,
      "learning_rate": 0.01552018094292604,
      "loss": 2.41,
      "step": 525680
    },
    {
      "epoch": 845.18,
      "learning_rate": 0.015516965512057883,
      "loss": 2.4058,
      "step": 525700
    },
    {
      "epoch": 845.21,
      "learning_rate": 0.015513750081189713,
      "loss": 2.398,
      "step": 525720
    },
    {
      "epoch": 845.24,
      "learning_rate": 0.015510534650321546,
      "loss": 2.3959,
      "step": 525740
    },
    {
      "epoch": 845.27,
      "learning_rate": 0.015507319219453372,
      "loss": 2.3951,
      "step": 525760
    },
    {
      "epoch": 845.31,
      "learning_rate": 0.015504103788585206,
      "loss": 2.4123,
      "step": 525780
    },
    {
      "epoch": 845.34,
      "learning_rate": 0.015500888357717036,
      "loss": 2.4037,
      "step": 525800
    },
    {
      "epoch": 845.37,
      "learning_rate": 0.015497672926848878,
      "loss": 2.3919,
      "step": 525820
    },
    {
      "epoch": 845.4,
      "learning_rate": 0.015494457495980711,
      "loss": 2.4019,
      "step": 525840
    },
    {
      "epoch": 845.43,
      "learning_rate": 0.015491242065112541,
      "loss": 2.4079,
      "step": 525860
    },
    {
      "epoch": 845.47,
      "learning_rate": 0.01548802663424437,
      "loss": 2.4092,
      "step": 525880
    },
    {
      "epoch": 845.5,
      "learning_rate": 0.0154848112033762,
      "loss": 2.4017,
      "step": 525900
    },
    {
      "epoch": 845.53,
      "learning_rate": 0.015481595772508044,
      "loss": 2.4032,
      "step": 525920
    },
    {
      "epoch": 845.56,
      "learning_rate": 0.015478380341639876,
      "loss": 2.3887,
      "step": 525940
    },
    {
      "epoch": 845.59,
      "learning_rate": 0.015475164910771706,
      "loss": 2.398,
      "step": 525960
    },
    {
      "epoch": 845.63,
      "learning_rate": 0.015471949479903536,
      "loss": 2.3974,
      "step": 525980
    },
    {
      "epoch": 845.66,
      "learning_rate": 0.015468734049035366,
      "loss": 2.3961,
      "step": 526000
    },
    {
      "epoch": 845.69,
      "learning_rate": 0.015465518618167196,
      "loss": 2.4166,
      "step": 526020
    },
    {
      "epoch": 845.72,
      "learning_rate": 0.015462303187299041,
      "loss": 2.3926,
      "step": 526040
    },
    {
      "epoch": 845.76,
      "learning_rate": 0.015459087756430871,
      "loss": 2.4071,
      "step": 526060
    },
    {
      "epoch": 845.79,
      "learning_rate": 0.0154558723255627,
      "loss": 2.4042,
      "step": 526080
    },
    {
      "epoch": 845.82,
      "learning_rate": 0.01545265689469453,
      "loss": 2.4213,
      "step": 526100
    },
    {
      "epoch": 845.85,
      "learning_rate": 0.01544944146382636,
      "loss": 2.4084,
      "step": 526120
    },
    {
      "epoch": 845.88,
      "learning_rate": 0.015446226032958194,
      "loss": 2.402,
      "step": 526140
    },
    {
      "epoch": 845.92,
      "learning_rate": 0.015443010602090036,
      "loss": 2.4006,
      "step": 526160
    },
    {
      "epoch": 845.95,
      "learning_rate": 0.01543979517122187,
      "loss": 2.4149,
      "step": 526180
    },
    {
      "epoch": 845.98,
      "learning_rate": 0.015436579740353696,
      "loss": 2.3941,
      "step": 526200
    },
    {
      "epoch": 846.0,
      "eval_accuracy": {
        "accuracy": 0.4641219000233227
      },
      "eval_loss": 2.507554531097412,
      "eval_runtime": 3.1001,
      "eval_samples_per_second": 4149.187,
      "eval_steps_per_second": 64.836,
      "step": 526212
    },
    {
      "epoch": 846.01,
      "learning_rate": 0.015433364309485529,
      "loss": 2.4077,
      "step": 526220
    },
    {
      "epoch": 846.05,
      "learning_rate": 0.015430148878617359,
      "loss": 2.4219,
      "step": 526240
    },
    {
      "epoch": 846.08,
      "learning_rate": 0.015426933447749201,
      "loss": 2.4198,
      "step": 526260
    },
    {
      "epoch": 846.11,
      "learning_rate": 0.015423718016881034,
      "loss": 2.4039,
      "step": 526280
    },
    {
      "epoch": 846.14,
      "learning_rate": 0.01542050258601286,
      "loss": 2.3977,
      "step": 526300
    },
    {
      "epoch": 846.17,
      "learning_rate": 0.015417287155144694,
      "loss": 2.4057,
      "step": 526320
    },
    {
      "epoch": 846.21,
      "learning_rate": 0.015414071724276524,
      "loss": 2.3808,
      "step": 526340
    },
    {
      "epoch": 846.24,
      "learning_rate": 0.015410856293408354,
      "loss": 2.412,
      "step": 526360
    },
    {
      "epoch": 846.27,
      "learning_rate": 0.0154076408625402,
      "loss": 2.4044,
      "step": 526380
    },
    {
      "epoch": 846.3,
      "learning_rate": 0.015404425431672026,
      "loss": 2.3924,
      "step": 526400
    },
    {
      "epoch": 846.33,
      "learning_rate": 0.015401210000803859,
      "loss": 2.4067,
      "step": 526420
    },
    {
      "epoch": 846.37,
      "learning_rate": 0.015397994569935689,
      "loss": 2.4051,
      "step": 526440
    },
    {
      "epoch": 846.4,
      "learning_rate": 0.015394779139067519,
      "loss": 2.3927,
      "step": 526460
    },
    {
      "epoch": 846.43,
      "learning_rate": 0.015391563708199352,
      "loss": 2.4085,
      "step": 526480
    },
    {
      "epoch": 846.46,
      "learning_rate": 0.015388348277331194,
      "loss": 2.4117,
      "step": 526500
    },
    {
      "epoch": 846.5,
      "learning_rate": 0.015385132846463024,
      "loss": 2.4089,
      "step": 526520
    },
    {
      "epoch": 846.53,
      "learning_rate": 0.015381917415594854,
      "loss": 2.3794,
      "step": 526540
    },
    {
      "epoch": 846.56,
      "learning_rate": 0.015378701984726684,
      "loss": 2.3977,
      "step": 526560
    },
    {
      "epoch": 846.59,
      "learning_rate": 0.015375486553858517,
      "loss": 2.3916,
      "step": 526580
    },
    {
      "epoch": 846.62,
      "learning_rate": 0.015372271122990359,
      "loss": 2.399,
      "step": 526600
    },
    {
      "epoch": 846.66,
      "learning_rate": 0.015369055692122189,
      "loss": 2.3941,
      "step": 526620
    },
    {
      "epoch": 846.69,
      "learning_rate": 0.015365840261254019,
      "loss": 2.4114,
      "step": 526640
    },
    {
      "epoch": 846.72,
      "learning_rate": 0.015362624830385849,
      "loss": 2.3963,
      "step": 526660
    },
    {
      "epoch": 846.75,
      "learning_rate": 0.015359409399517682,
      "loss": 2.407,
      "step": 526680
    },
    {
      "epoch": 846.78,
      "learning_rate": 0.015356193968649512,
      "loss": 2.3835,
      "step": 526700
    },
    {
      "epoch": 846.82,
      "learning_rate": 0.015352978537781354,
      "loss": 2.413,
      "step": 526720
    },
    {
      "epoch": 846.85,
      "learning_rate": 0.015349763106913184,
      "loss": 2.4173,
      "step": 526740
    },
    {
      "epoch": 846.88,
      "learning_rate": 0.015346547676045014,
      "loss": 2.4028,
      "step": 526760
    },
    {
      "epoch": 846.91,
      "learning_rate": 0.015343332245176847,
      "loss": 2.3953,
      "step": 526780
    },
    {
      "epoch": 846.95,
      "learning_rate": 0.015340116814308677,
      "loss": 2.4033,
      "step": 526800
    },
    {
      "epoch": 846.98,
      "learning_rate": 0.015336901383440509,
      "loss": 2.4011,
      "step": 526820
    },
    {
      "epoch": 847.0,
      "eval_accuracy": {
        "accuracy": 0.4634222187670061
      },
      "eval_loss": 2.5216519832611084,
      "eval_runtime": 3.3646,
      "eval_samples_per_second": 3823.083,
      "eval_steps_per_second": 59.74,
      "step": 526834
    },
    {
      "epoch": 847.01,
      "learning_rate": 0.015333685952572349,
      "loss": 2.4139,
      "step": 526840
    },
    {
      "epoch": 847.04,
      "learning_rate": 0.015330470521704182,
      "loss": 2.408,
      "step": 526860
    },
    {
      "epoch": 847.07,
      "learning_rate": 0.015327255090836012,
      "loss": 2.4048,
      "step": 526880
    },
    {
      "epoch": 847.11,
      "learning_rate": 0.015324039659967842,
      "loss": 2.3989,
      "step": 526900
    },
    {
      "epoch": 847.14,
      "learning_rate": 0.015320824229099674,
      "loss": 2.4048,
      "step": 526920
    },
    {
      "epoch": 847.17,
      "learning_rate": 0.015317608798231514,
      "loss": 2.4089,
      "step": 526940
    },
    {
      "epoch": 847.2,
      "learning_rate": 0.015314393367363347,
      "loss": 2.4021,
      "step": 526960
    },
    {
      "epoch": 847.23,
      "learning_rate": 0.015311177936495177,
      "loss": 2.411,
      "step": 526980
    },
    {
      "epoch": 847.27,
      "learning_rate": 0.015307962505627007,
      "loss": 2.3746,
      "step": 527000
    },
    {
      "epoch": 847.3,
      "learning_rate": 0.015304747074758838,
      "loss": 2.3954,
      "step": 527020
    },
    {
      "epoch": 847.33,
      "learning_rate": 0.01530153164389067,
      "loss": 2.3932,
      "step": 527040
    },
    {
      "epoch": 847.36,
      "learning_rate": 0.015298316213022512,
      "loss": 2.4039,
      "step": 527060
    },
    {
      "epoch": 847.4,
      "learning_rate": 0.015295100782154342,
      "loss": 2.3816,
      "step": 527080
    },
    {
      "epoch": 847.43,
      "learning_rate": 0.015291885351286172,
      "loss": 2.3972,
      "step": 527100
    },
    {
      "epoch": 847.46,
      "learning_rate": 0.015288669920418005,
      "loss": 2.3902,
      "step": 527120
    },
    {
      "epoch": 847.49,
      "learning_rate": 0.015285454489549835,
      "loss": 2.397,
      "step": 527140
    },
    {
      "epoch": 847.52,
      "learning_rate": 0.015282239058681677,
      "loss": 2.3959,
      "step": 527160
    },
    {
      "epoch": 847.56,
      "learning_rate": 0.015279023627813507,
      "loss": 2.4176,
      "step": 527180
    },
    {
      "epoch": 847.59,
      "learning_rate": 0.015275808196945337,
      "loss": 2.3923,
      "step": 527200
    },
    {
      "epoch": 847.62,
      "learning_rate": 0.01527259276607717,
      "loss": 2.3929,
      "step": 527220
    },
    {
      "epoch": 847.65,
      "learning_rate": 0.015269377335209,
      "loss": 2.4148,
      "step": 527240
    },
    {
      "epoch": 847.68,
      "learning_rate": 0.015266161904340832,
      "loss": 2.3831,
      "step": 527260
    },
    {
      "epoch": 847.72,
      "learning_rate": 0.015262946473472672,
      "loss": 2.3935,
      "step": 527280
    },
    {
      "epoch": 847.75,
      "learning_rate": 0.015259731042604502,
      "loss": 2.3802,
      "step": 527300
    },
    {
      "epoch": 847.78,
      "learning_rate": 0.015256515611736335,
      "loss": 2.3945,
      "step": 527320
    },
    {
      "epoch": 847.81,
      "learning_rate": 0.015253300180868165,
      "loss": 2.405,
      "step": 527340
    },
    {
      "epoch": 847.85,
      "learning_rate": 0.015250084749999997,
      "loss": 2.3862,
      "step": 527360
    },
    {
      "epoch": 847.88,
      "learning_rate": 0.015246869319131828,
      "loss": 2.4197,
      "step": 527380
    },
    {
      "epoch": 847.91,
      "learning_rate": 0.01524365388826367,
      "loss": 2.4108,
      "step": 527400
    },
    {
      "epoch": 847.94,
      "learning_rate": 0.015240599228938912,
      "loss": 2.4313,
      "step": 527420
    },
    {
      "epoch": 847.97,
      "learning_rate": 0.015237383798070742,
      "loss": 2.3963,
      "step": 527440
    },
    {
      "epoch": 848.0,
      "eval_accuracy": {
        "accuracy": 0.45813573816372544
      },
      "eval_loss": 2.5268807411193848,
      "eval_runtime": 3.2043,
      "eval_samples_per_second": 4014.236,
      "eval_steps_per_second": 62.727,
      "step": 527456
    },
    {
      "epoch": 848.01,
      "learning_rate": 0.015234168367202573,
      "loss": 2.3921,
      "step": 527460
    },
    {
      "epoch": 848.04,
      "learning_rate": 0.015230952936334405,
      "loss": 2.3988,
      "step": 527480
    },
    {
      "epoch": 848.07,
      "learning_rate": 0.015227737505466236,
      "loss": 2.417,
      "step": 527500
    },
    {
      "epoch": 848.1,
      "learning_rate": 0.015224522074598066,
      "loss": 2.4001,
      "step": 527520
    },
    {
      "epoch": 848.14,
      "learning_rate": 0.015221306643729907,
      "loss": 2.4005,
      "step": 527540
    },
    {
      "epoch": 848.17,
      "learning_rate": 0.015218091212861738,
      "loss": 2.3893,
      "step": 527560
    },
    {
      "epoch": 848.2,
      "learning_rate": 0.01521487578199357,
      "loss": 2.393,
      "step": 527580
    },
    {
      "epoch": 848.23,
      "learning_rate": 0.015211660351125401,
      "loss": 2.3949,
      "step": 527600
    },
    {
      "epoch": 848.26,
      "learning_rate": 0.015208444920257231,
      "loss": 2.3985,
      "step": 527620
    },
    {
      "epoch": 848.3,
      "learning_rate": 0.015205229489389072,
      "loss": 2.4006,
      "step": 527640
    },
    {
      "epoch": 848.33,
      "learning_rate": 0.015202014058520903,
      "loss": 2.3975,
      "step": 527660
    },
    {
      "epoch": 848.36,
      "learning_rate": 0.015198798627652735,
      "loss": 2.3989,
      "step": 527680
    },
    {
      "epoch": 848.39,
      "learning_rate": 0.015195583196784566,
      "loss": 2.4033,
      "step": 527700
    },
    {
      "epoch": 848.42,
      "learning_rate": 0.015192367765916396,
      "loss": 2.3813,
      "step": 527720
    },
    {
      "epoch": 848.46,
      "learning_rate": 0.015189152335048226,
      "loss": 2.3865,
      "step": 527740
    },
    {
      "epoch": 848.49,
      "learning_rate": 0.015185936904180068,
      "loss": 2.3986,
      "step": 527760
    },
    {
      "epoch": 848.52,
      "learning_rate": 0.0151827214733119,
      "loss": 2.3956,
      "step": 527780
    },
    {
      "epoch": 848.55,
      "learning_rate": 0.015179506042443731,
      "loss": 2.4176,
      "step": 527800
    },
    {
      "epoch": 848.59,
      "learning_rate": 0.015176290611575561,
      "loss": 2.4186,
      "step": 527820
    },
    {
      "epoch": 848.62,
      "learning_rate": 0.015173075180707395,
      "loss": 2.4029,
      "step": 527840
    },
    {
      "epoch": 848.65,
      "learning_rate": 0.015169859749839221,
      "loss": 2.4006,
      "step": 527860
    },
    {
      "epoch": 848.68,
      "learning_rate": 0.015166644318971065,
      "loss": 2.4131,
      "step": 527880
    },
    {
      "epoch": 848.71,
      "learning_rate": 0.015163428888102896,
      "loss": 2.3939,
      "step": 527900
    },
    {
      "epoch": 848.75,
      "learning_rate": 0.015160213457234726,
      "loss": 2.4292,
      "step": 527920
    },
    {
      "epoch": 848.78,
      "learning_rate": 0.01515699802636656,
      "loss": 2.4062,
      "step": 527940
    },
    {
      "epoch": 848.81,
      "learning_rate": 0.015153782595498386,
      "loss": 2.4075,
      "step": 527960
    },
    {
      "epoch": 848.84,
      "learning_rate": 0.01515056716463023,
      "loss": 2.3826,
      "step": 527980
    },
    {
      "epoch": 848.87,
      "learning_rate": 0.015147351733762061,
      "loss": 2.3788,
      "step": 528000
    },
    {
      "epoch": 848.91,
      "learning_rate": 0.015144136302893891,
      "loss": 2.4085,
      "step": 528020
    },
    {
      "epoch": 848.94,
      "learning_rate": 0.015140920872025725,
      "loss": 2.412,
      "step": 528040
    },
    {
      "epoch": 848.97,
      "learning_rate": 0.015137705441157554,
      "loss": 2.3967,
      "step": 528060
    },
    {
      "epoch": 849.0,
      "eval_accuracy": {
        "accuracy": 0.4596905853999845
      },
      "eval_loss": 2.5058186054229736,
      "eval_runtime": 2.9895,
      "eval_samples_per_second": 4302.767,
      "eval_steps_per_second": 67.236,
      "step": 528078
    },
    {
      "epoch": 849.0,
      "learning_rate": 0.015134490010289384,
      "loss": 2.4145,
      "step": 528080
    },
    {
      "epoch": 849.04,
      "learning_rate": 0.015131274579421226,
      "loss": 2.3947,
      "step": 528100
    },
    {
      "epoch": 849.07,
      "learning_rate": 0.015128059148553058,
      "loss": 2.3984,
      "step": 528120
    },
    {
      "epoch": 849.1,
      "learning_rate": 0.01512484371768489,
      "loss": 2.3978,
      "step": 528140
    },
    {
      "epoch": 849.13,
      "learning_rate": 0.01512162828681672,
      "loss": 2.4094,
      "step": 528160
    },
    {
      "epoch": 849.16,
      "learning_rate": 0.01511841285594855,
      "loss": 2.3841,
      "step": 528180
    },
    {
      "epoch": 849.2,
      "learning_rate": 0.01511519742508038,
      "loss": 2.398,
      "step": 528200
    },
    {
      "epoch": 849.23,
      "learning_rate": 0.015111981994212223,
      "loss": 2.41,
      "step": 528220
    },
    {
      "epoch": 849.26,
      "learning_rate": 0.015108766563344055,
      "loss": 2.3952,
      "step": 528240
    },
    {
      "epoch": 849.29,
      "learning_rate": 0.015105551132475884,
      "loss": 2.3861,
      "step": 528260
    },
    {
      "epoch": 849.32,
      "learning_rate": 0.015102335701607714,
      "loss": 2.395,
      "step": 528280
    },
    {
      "epoch": 849.36,
      "learning_rate": 0.015099120270739544,
      "loss": 2.3946,
      "step": 528300
    },
    {
      "epoch": 849.39,
      "learning_rate": 0.015095904839871388,
      "loss": 2.4051,
      "step": 528320
    },
    {
      "epoch": 849.42,
      "learning_rate": 0.01509268940900322,
      "loss": 2.3814,
      "step": 528340
    },
    {
      "epoch": 849.45,
      "learning_rate": 0.01508947397813505,
      "loss": 2.3959,
      "step": 528360
    },
    {
      "epoch": 849.49,
      "learning_rate": 0.015086258547266883,
      "loss": 2.4038,
      "step": 528380
    },
    {
      "epoch": 849.52,
      "learning_rate": 0.01508304311639871,
      "loss": 2.3936,
      "step": 528400
    },
    {
      "epoch": 849.55,
      "learning_rate": 0.015079827685530543,
      "loss": 2.3992,
      "step": 528420
    },
    {
      "epoch": 849.58,
      "learning_rate": 0.015076612254662385,
      "loss": 2.4055,
      "step": 528440
    },
    {
      "epoch": 849.61,
      "learning_rate": 0.015073396823794214,
      "loss": 2.3969,
      "step": 528460
    },
    {
      "epoch": 849.65,
      "learning_rate": 0.015070181392926048,
      "loss": 2.3821,
      "step": 528480
    },
    {
      "epoch": 849.68,
      "learning_rate": 0.015066965962057874,
      "loss": 2.401,
      "step": 528500
    },
    {
      "epoch": 849.71,
      "learning_rate": 0.015063750531189708,
      "loss": 2.382,
      "step": 528520
    },
    {
      "epoch": 849.74,
      "learning_rate": 0.015060535100321537,
      "loss": 2.3983,
      "step": 528540
    },
    {
      "epoch": 849.77,
      "learning_rate": 0.01505731966945338,
      "loss": 2.4052,
      "step": 528560
    },
    {
      "epoch": 849.81,
      "learning_rate": 0.015054104238585213,
      "loss": 2.3966,
      "step": 528580
    },
    {
      "epoch": 849.84,
      "learning_rate": 0.01505088880771704,
      "loss": 2.4055,
      "step": 528600
    },
    {
      "epoch": 849.87,
      "learning_rate": 0.015047673376848873,
      "loss": 2.3923,
      "step": 528620
    },
    {
      "epoch": 849.9,
      "learning_rate": 0.015044457945980702,
      "loss": 2.3965,
      "step": 528640
    },
    {
      "epoch": 849.94,
      "learning_rate": 0.015041242515112544,
      "loss": 2.3997,
      "step": 528660
    },
    {
      "epoch": 849.97,
      "learning_rate": 0.015038027084244378,
      "loss": 2.4035,
      "step": 528680
    },
    {
      "epoch": 850.0,
      "learning_rate": 0.015034811653376208,
      "loss": 2.4037,
      "step": 528700
    },
    {
      "epoch": 850.0,
      "eval_accuracy": {
        "accuracy": 0.46287802223431546
      },
      "eval_loss": 2.5144548416137695,
      "eval_runtime": 3.1414,
      "eval_samples_per_second": 4094.708,
      "eval_steps_per_second": 63.985,
      "step": 528700
    },
    {
      "epoch": 850.03,
      "learning_rate": 0.015031596222508038,
      "loss": 2.4092,
      "step": 528720
    },
    {
      "epoch": 850.06,
      "learning_rate": 0.015028380791639867,
      "loss": 2.4094,
      "step": 528740
    },
    {
      "epoch": 850.1,
      "learning_rate": 0.015025165360771697,
      "loss": 2.4019,
      "step": 528760
    },
    {
      "epoch": 850.13,
      "learning_rate": 0.015021949929903543,
      "loss": 2.3945,
      "step": 528780
    },
    {
      "epoch": 850.16,
      "learning_rate": 0.015018734499035373,
      "loss": 2.3855,
      "step": 528800
    },
    {
      "epoch": 850.19,
      "learning_rate": 0.015015519068167203,
      "loss": 2.4027,
      "step": 528820
    },
    {
      "epoch": 850.23,
      "learning_rate": 0.015012303637299032,
      "loss": 2.3943,
      "step": 528840
    },
    {
      "epoch": 850.26,
      "learning_rate": 0.015009088206430862,
      "loss": 2.4045,
      "step": 528860
    },
    {
      "epoch": 850.29,
      "learning_rate": 0.015005872775562696,
      "loss": 2.4127,
      "step": 528880
    },
    {
      "epoch": 850.32,
      "learning_rate": 0.015002657344694538,
      "loss": 2.3836,
      "step": 528900
    },
    {
      "epoch": 850.35,
      "learning_rate": 0.014999441913826368,
      "loss": 2.3972,
      "step": 528920
    },
    {
      "epoch": 850.39,
      "learning_rate": 0.014996226482958197,
      "loss": 2.3876,
      "step": 528940
    },
    {
      "epoch": 850.42,
      "learning_rate": 0.014993011052090027,
      "loss": 2.3771,
      "step": 528960
    },
    {
      "epoch": 850.45,
      "learning_rate": 0.01498979562122186,
      "loss": 2.3907,
      "step": 528980
    },
    {
      "epoch": 850.48,
      "learning_rate": 0.014986580190353703,
      "loss": 2.401,
      "step": 529000
    },
    {
      "epoch": 850.51,
      "learning_rate": 0.014983364759485536,
      "loss": 2.3911,
      "step": 529020
    },
    {
      "epoch": 850.55,
      "learning_rate": 0.014980149328617362,
      "loss": 2.4218,
      "step": 529040
    },
    {
      "epoch": 850.58,
      "learning_rate": 0.014976933897749196,
      "loss": 2.3922,
      "step": 529060
    },
    {
      "epoch": 850.61,
      "learning_rate": 0.014973718466881026,
      "loss": 2.391,
      "step": 529080
    },
    {
      "epoch": 850.64,
      "learning_rate": 0.014970503036012855,
      "loss": 2.4076,
      "step": 529100
    },
    {
      "epoch": 850.68,
      "learning_rate": 0.014967287605144701,
      "loss": 2.3965,
      "step": 529120
    },
    {
      "epoch": 850.71,
      "learning_rate": 0.014964072174276527,
      "loss": 2.4027,
      "step": 529140
    },
    {
      "epoch": 850.74,
      "learning_rate": 0.01496085674340836,
      "loss": 2.3997,
      "step": 529160
    },
    {
      "epoch": 850.77,
      "learning_rate": 0.01495764131254019,
      "loss": 2.4114,
      "step": 529180
    },
    {
      "epoch": 850.8,
      "learning_rate": 0.01495442588167202,
      "loss": 2.4004,
      "step": 529200
    },
    {
      "epoch": 850.84,
      "learning_rate": 0.014951210450803852,
      "loss": 2.3912,
      "step": 529220
    },
    {
      "epoch": 850.87,
      "learning_rate": 0.014947995019935692,
      "loss": 2.4036,
      "step": 529240
    },
    {
      "epoch": 850.9,
      "learning_rate": 0.014944779589067526,
      "loss": 2.3975,
      "step": 529260
    },
    {
      "epoch": 850.93,
      "learning_rate": 0.014941564158199356,
      "loss": 2.3919,
      "step": 529280
    },
    {
      "epoch": 850.96,
      "learning_rate": 0.014938348727331185,
      "loss": 2.3905,
      "step": 529300
    },
    {
      "epoch": 851.0,
      "learning_rate": 0.014935133296463019,
      "loss": 2.3878,
      "step": 529320
    },
    {
      "epoch": 851.0,
      "eval_accuracy": {
        "accuracy": 0.46023478193267514
      },
      "eval_loss": 2.5166735649108887,
      "eval_runtime": 3.0074,
      "eval_samples_per_second": 4277.088,
      "eval_steps_per_second": 66.835,
      "step": 529322
    },
    {
      "epoch": 851.03,
      "learning_rate": 0.01493191786559486,
      "loss": 2.4003,
      "step": 529340
    },
    {
      "epoch": 851.06,
      "learning_rate": 0.01492870243472669,
      "loss": 2.4026,
      "step": 529360
    },
    {
      "epoch": 851.09,
      "learning_rate": 0.01492548700385852,
      "loss": 2.3998,
      "step": 529380
    },
    {
      "epoch": 851.13,
      "learning_rate": 0.01492227157299035,
      "loss": 2.38,
      "step": 529400
    },
    {
      "epoch": 851.16,
      "learning_rate": 0.014919216913665595,
      "loss": 2.4054,
      "step": 529420
    },
    {
      "epoch": 851.19,
      "learning_rate": 0.014916001482797425,
      "loss": 2.4084,
      "step": 529440
    },
    {
      "epoch": 851.22,
      "learning_rate": 0.014912786051929257,
      "loss": 2.4073,
      "step": 529460
    },
    {
      "epoch": 851.25,
      "learning_rate": 0.014909570621061097,
      "loss": 2.3884,
      "step": 529480
    },
    {
      "epoch": 851.29,
      "learning_rate": 0.014906355190192927,
      "loss": 2.3994,
      "step": 529500
    },
    {
      "epoch": 851.32,
      "learning_rate": 0.01490313975932476,
      "loss": 2.3933,
      "step": 529520
    },
    {
      "epoch": 851.35,
      "learning_rate": 0.01489992432845659,
      "loss": 2.3583,
      "step": 529540
    },
    {
      "epoch": 851.38,
      "learning_rate": 0.014896708897588422,
      "loss": 2.4066,
      "step": 529560
    },
    {
      "epoch": 851.41,
      "learning_rate": 0.014893493466720252,
      "loss": 2.4,
      "step": 529580
    },
    {
      "epoch": 851.45,
      "learning_rate": 0.014890278035852092,
      "loss": 2.3942,
      "step": 529600
    },
    {
      "epoch": 851.48,
      "learning_rate": 0.014887062604983925,
      "loss": 2.4029,
      "step": 529620
    },
    {
      "epoch": 851.51,
      "learning_rate": 0.014883847174115755,
      "loss": 2.4049,
      "step": 529640
    },
    {
      "epoch": 851.54,
      "learning_rate": 0.014880631743247587,
      "loss": 2.4037,
      "step": 529660
    },
    {
      "epoch": 851.58,
      "learning_rate": 0.014877416312379418,
      "loss": 2.3857,
      "step": 529680
    },
    {
      "epoch": 851.61,
      "learning_rate": 0.01487420088151125,
      "loss": 2.4038,
      "step": 529700
    },
    {
      "epoch": 851.64,
      "learning_rate": 0.01487098545064309,
      "loss": 2.3943,
      "step": 529720
    },
    {
      "epoch": 851.67,
      "learning_rate": 0.01486777001977492,
      "loss": 2.379,
      "step": 529740
    },
    {
      "epoch": 851.7,
      "learning_rate": 0.014864554588906752,
      "loss": 2.3914,
      "step": 529760
    },
    {
      "epoch": 851.74,
      "learning_rate": 0.014861339158038583,
      "loss": 2.4128,
      "step": 529780
    },
    {
      "epoch": 851.77,
      "learning_rate": 0.014858123727170415,
      "loss": 2.3763,
      "step": 529800
    },
    {
      "epoch": 851.8,
      "learning_rate": 0.014854908296302255,
      "loss": 2.3861,
      "step": 529820
    },
    {
      "epoch": 851.83,
      "learning_rate": 0.014851692865434085,
      "loss": 2.4162,
      "step": 529840
    },
    {
      "epoch": 851.86,
      "learning_rate": 0.014848477434565917,
      "loss": 2.3915,
      "step": 529860
    },
    {
      "epoch": 851.9,
      "learning_rate": 0.014845262003697748,
      "loss": 2.3904,
      "step": 529880
    },
    {
      "epoch": 851.93,
      "learning_rate": 0.01484204657282958,
      "loss": 2.4099,
      "step": 529900
    },
    {
      "epoch": 851.96,
      "learning_rate": 0.014838991913504821,
      "loss": 2.3987,
      "step": 529920
    },
    {
      "epoch": 851.99,
      "learning_rate": 0.014835776482636651,
      "loss": 2.4008,
      "step": 529940
    },
    {
      "epoch": 852.0,
      "eval_accuracy": {
        "accuracy": 0.4648993236414522
      },
      "eval_loss": 2.515120029449463,
      "eval_runtime": 3.1232,
      "eval_samples_per_second": 4118.575,
      "eval_steps_per_second": 64.358,
      "step": 529944
    },
    {
      "epoch": 852.03,
      "learning_rate": 0.014832561051768493,
      "loss": 2.3827,
      "step": 529960
    },
    {
      "epoch": 852.06,
      "learning_rate": 0.014829345620900325,
      "loss": 2.4153,
      "step": 529980
    },
    {
      "epoch": 852.09,
      "learning_rate": 0.014826130190032157,
      "loss": 2.4053,
      "step": 530000
    },
    {
      "epoch": 852.12,
      "learning_rate": 0.014822914759163986,
      "loss": 2.3938,
      "step": 530020
    },
    {
      "epoch": 852.15,
      "learning_rate": 0.014819699328295816,
      "loss": 2.4067,
      "step": 530040
    },
    {
      "epoch": 852.19,
      "learning_rate": 0.014816483897427646,
      "loss": 2.4054,
      "step": 530060
    },
    {
      "epoch": 852.22,
      "learning_rate": 0.01481326846655949,
      "loss": 2.3952,
      "step": 530080
    },
    {
      "epoch": 852.25,
      "learning_rate": 0.014810053035691322,
      "loss": 2.4096,
      "step": 530100
    },
    {
      "epoch": 852.28,
      "learning_rate": 0.014806837604823151,
      "loss": 2.3879,
      "step": 530120
    },
    {
      "epoch": 852.32,
      "learning_rate": 0.014803622173954985,
      "loss": 2.4135,
      "step": 530140
    },
    {
      "epoch": 852.35,
      "learning_rate": 0.014800406743086811,
      "loss": 2.3913,
      "step": 530160
    },
    {
      "epoch": 852.38,
      "learning_rate": 0.014797191312218645,
      "loss": 2.3976,
      "step": 530180
    },
    {
      "epoch": 852.41,
      "learning_rate": 0.014793975881350487,
      "loss": 2.3751,
      "step": 530200
    },
    {
      "epoch": 852.44,
      "learning_rate": 0.014790760450482316,
      "loss": 2.4098,
      "step": 530220
    },
    {
      "epoch": 852.48,
      "learning_rate": 0.01478754501961415,
      "loss": 2.3809,
      "step": 530240
    },
    {
      "epoch": 852.51,
      "learning_rate": 0.014784329588745976,
      "loss": 2.4049,
      "step": 530260
    },
    {
      "epoch": 852.54,
      "learning_rate": 0.01478111415787781,
      "loss": 2.3964,
      "step": 530280
    },
    {
      "epoch": 852.57,
      "learning_rate": 0.014777898727009652,
      "loss": 2.3932,
      "step": 530300
    },
    {
      "epoch": 852.6,
      "learning_rate": 0.014774683296141481,
      "loss": 2.3997,
      "step": 530320
    },
    {
      "epoch": 852.64,
      "learning_rate": 0.014771467865273315,
      "loss": 2.3902,
      "step": 530340
    },
    {
      "epoch": 852.67,
      "learning_rate": 0.014768252434405141,
      "loss": 2.4128,
      "step": 530360
    },
    {
      "epoch": 852.7,
      "learning_rate": 0.014765037003536974,
      "loss": 2.4052,
      "step": 530380
    },
    {
      "epoch": 852.73,
      "learning_rate": 0.014761821572668804,
      "loss": 2.4059,
      "step": 530400
    },
    {
      "epoch": 852.77,
      "learning_rate": 0.014758606141800648,
      "loss": 2.391,
      "step": 530420
    },
    {
      "epoch": 852.8,
      "learning_rate": 0.01475539071093248,
      "loss": 2.379,
      "step": 530440
    },
    {
      "epoch": 852.83,
      "learning_rate": 0.01475217528006431,
      "loss": 2.3858,
      "step": 530460
    },
    {
      "epoch": 852.86,
      "learning_rate": 0.01474895984919614,
      "loss": 2.3939,
      "step": 530480
    },
    {
      "epoch": 852.89,
      "learning_rate": 0.01474574441832797,
      "loss": 2.4034,
      "step": 530500
    },
    {
      "epoch": 852.93,
      "learning_rate": 0.0147425289874598,
      "loss": 2.3996,
      "step": 530520
    },
    {
      "epoch": 852.96,
      "learning_rate": 0.014739313556591645,
      "loss": 2.39,
      "step": 530540
    },
    {
      "epoch": 852.99,
      "learning_rate": 0.014736098125723475,
      "loss": 2.382,
      "step": 530560
    },
    {
      "epoch": 853.0,
      "eval_accuracy": {
        "accuracy": 0.4641219000233227
      },
      "eval_loss": 2.516509532928467,
      "eval_runtime": 3.3906,
      "eval_samples_per_second": 3793.688,
      "eval_steps_per_second": 59.281,
      "step": 530566
    },
    {
      "epoch": 853.02,
      "learning_rate": 0.014732882694855304,
      "loss": 2.3857,
      "step": 530580
    },
    {
      "epoch": 853.05,
      "learning_rate": 0.014729667263987134,
      "loss": 2.4145,
      "step": 530600
    },
    {
      "epoch": 853.09,
      "learning_rate": 0.014726451833118964,
      "loss": 2.3759,
      "step": 530620
    },
    {
      "epoch": 853.12,
      "learning_rate": 0.01472323640225081,
      "loss": 2.4063,
      "step": 530640
    },
    {
      "epoch": 853.15,
      "learning_rate": 0.01472002097138264,
      "loss": 2.3906,
      "step": 530660
    },
    {
      "epoch": 853.18,
      "learning_rate": 0.014716805540514473,
      "loss": 2.4029,
      "step": 530680
    },
    {
      "epoch": 853.22,
      "learning_rate": 0.0147135901096463,
      "loss": 2.4101,
      "step": 530700
    },
    {
      "epoch": 853.25,
      "learning_rate": 0.014710374678778133,
      "loss": 2.3951,
      "step": 530720
    },
    {
      "epoch": 853.28,
      "learning_rate": 0.014707159247909963,
      "loss": 2.377,
      "step": 530740
    },
    {
      "epoch": 853.31,
      "learning_rate": 0.014703943817041805,
      "loss": 2.383,
      "step": 530760
    },
    {
      "epoch": 853.34,
      "learning_rate": 0.014700728386173638,
      "loss": 2.3954,
      "step": 530780
    },
    {
      "epoch": 853.38,
      "learning_rate": 0.014697512955305464,
      "loss": 2.3954,
      "step": 530800
    },
    {
      "epoch": 853.41,
      "learning_rate": 0.014694297524437298,
      "loss": 2.4009,
      "step": 530820
    },
    {
      "epoch": 853.44,
      "learning_rate": 0.014691082093569128,
      "loss": 2.3865,
      "step": 530840
    },
    {
      "epoch": 853.47,
      "learning_rate": 0.014687866662700957,
      "loss": 2.4028,
      "step": 530860
    },
    {
      "epoch": 853.5,
      "learning_rate": 0.014684651231832803,
      "loss": 2.407,
      "step": 530880
    },
    {
      "epoch": 853.54,
      "learning_rate": 0.01468143580096463,
      "loss": 2.4019,
      "step": 530900
    },
    {
      "epoch": 853.57,
      "learning_rate": 0.014678220370096463,
      "loss": 2.3973,
      "step": 530920
    },
    {
      "epoch": 853.6,
      "learning_rate": 0.014675004939228293,
      "loss": 2.3856,
      "step": 530940
    },
    {
      "epoch": 853.63,
      "learning_rate": 0.014671789508360122,
      "loss": 2.4003,
      "step": 530960
    },
    {
      "epoch": 853.67,
      "learning_rate": 0.014668574077491968,
      "loss": 2.3941,
      "step": 530980
    },
    {
      "epoch": 853.7,
      "learning_rate": 0.014665358646623798,
      "loss": 2.3818,
      "step": 531000
    },
    {
      "epoch": 853.73,
      "learning_rate": 0.014662143215755628,
      "loss": 2.3842,
      "step": 531020
    },
    {
      "epoch": 853.76,
      "learning_rate": 0.014658927784887458,
      "loss": 2.4042,
      "step": 531040
    },
    {
      "epoch": 853.79,
      "learning_rate": 0.014655712354019287,
      "loss": 2.4112,
      "step": 531060
    },
    {
      "epoch": 853.83,
      "learning_rate": 0.01465249692315112,
      "loss": 2.4116,
      "step": 531080
    },
    {
      "epoch": 853.86,
      "learning_rate": 0.014649281492282963,
      "loss": 2.3868,
      "step": 531100
    },
    {
      "epoch": 853.89,
      "learning_rate": 0.014646066061414793,
      "loss": 2.4031,
      "step": 531120
    },
    {
      "epoch": 853.92,
      "learning_rate": 0.014642850630546623,
      "loss": 2.3866,
      "step": 531140
    },
    {
      "epoch": 853.95,
      "learning_rate": 0.014639635199678452,
      "loss": 2.3993,
      "step": 531160
    },
    {
      "epoch": 853.99,
      "learning_rate": 0.014636419768810286,
      "loss": 2.3893,
      "step": 531180
    },
    {
      "epoch": 854.0,
      "eval_accuracy": {
        "accuracy": 0.4633444764051932
      },
      "eval_loss": 2.5144355297088623,
      "eval_runtime": 3.5276,
      "eval_samples_per_second": 3646.343,
      "eval_steps_per_second": 56.979,
      "step": 531188
    },
    {
      "epoch": 854.02,
      "learning_rate": 0.014633204337942128,
      "loss": 2.3945,
      "step": 531200
    },
    {
      "epoch": 854.05,
      "learning_rate": 0.014629988907073958,
      "loss": 2.3986,
      "step": 531220
    },
    {
      "epoch": 854.08,
      "learning_rate": 0.014626773476205788,
      "loss": 2.3791,
      "step": 531240
    },
    {
      "epoch": 854.12,
      "learning_rate": 0.014623558045337617,
      "loss": 2.4178,
      "step": 531260
    },
    {
      "epoch": 854.15,
      "learning_rate": 0.01462034261446945,
      "loss": 2.395,
      "step": 531280
    },
    {
      "epoch": 854.18,
      "learning_rate": 0.01461712718360128,
      "loss": 2.3889,
      "step": 531300
    },
    {
      "epoch": 854.21,
      "learning_rate": 0.014613911752733126,
      "loss": 2.3916,
      "step": 531320
    },
    {
      "epoch": 854.24,
      "learning_rate": 0.014610696321864952,
      "loss": 2.3766,
      "step": 531340
    },
    {
      "epoch": 854.28,
      "learning_rate": 0.014607480890996786,
      "loss": 2.3895,
      "step": 531360
    },
    {
      "epoch": 854.31,
      "learning_rate": 0.014604265460128616,
      "loss": 2.4124,
      "step": 531380
    },
    {
      "epoch": 854.34,
      "learning_rate": 0.014601050029260446,
      "loss": 2.4156,
      "step": 531400
    },
    {
      "epoch": 854.37,
      "learning_rate": 0.014597834598392277,
      "loss": 2.3992,
      "step": 531420
    },
    {
      "epoch": 854.41,
      "learning_rate": 0.014594619167524117,
      "loss": 2.4056,
      "step": 531440
    },
    {
      "epoch": 854.44,
      "learning_rate": 0.01459140373665595,
      "loss": 2.3938,
      "step": 531460
    },
    {
      "epoch": 854.47,
      "learning_rate": 0.01458818830578778,
      "loss": 2.378,
      "step": 531480
    },
    {
      "epoch": 854.5,
      "learning_rate": 0.01458497287491961,
      "loss": 2.3737,
      "step": 531500
    },
    {
      "epoch": 854.53,
      "learning_rate": 0.014581757444051442,
      "loss": 2.4117,
      "step": 531520
    },
    {
      "epoch": 854.57,
      "learning_rate": 0.014578542013183282,
      "loss": 2.3837,
      "step": 531540
    },
    {
      "epoch": 854.6,
      "learning_rate": 0.014575326582315116,
      "loss": 2.411,
      "step": 531560
    },
    {
      "epoch": 854.63,
      "learning_rate": 0.014572111151446946,
      "loss": 2.3811,
      "step": 531580
    },
    {
      "epoch": 854.66,
      "learning_rate": 0.014568895720578776,
      "loss": 2.41,
      "step": 531600
    },
    {
      "epoch": 854.69,
      "learning_rate": 0.014565680289710609,
      "loss": 2.4017,
      "step": 531620
    },
    {
      "epoch": 854.73,
      "learning_rate": 0.014562464858842439,
      "loss": 2.3954,
      "step": 531640
    },
    {
      "epoch": 854.76,
      "learning_rate": 0.01455924942797428,
      "loss": 2.4118,
      "step": 531660
    },
    {
      "epoch": 854.79,
      "learning_rate": 0.01455603399710611,
      "loss": 2.3901,
      "step": 531680
    },
    {
      "epoch": 854.82,
      "learning_rate": 0.01455281856623794,
      "loss": 2.3944,
      "step": 531700
    },
    {
      "epoch": 854.86,
      "learning_rate": 0.014549603135369774,
      "loss": 2.392,
      "step": 531720
    },
    {
      "epoch": 854.89,
      "learning_rate": 0.014546387704501604,
      "loss": 2.3966,
      "step": 531740
    },
    {
      "epoch": 854.92,
      "learning_rate": 0.014543172273633435,
      "loss": 2.4087,
      "step": 531760
    },
    {
      "epoch": 854.95,
      "learning_rate": 0.014539956842765276,
      "loss": 2.4085,
      "step": 531780
    },
    {
      "epoch": 854.98,
      "learning_rate": 0.014536741411897106,
      "loss": 2.3847,
      "step": 531800
    },
    {
      "epoch": 855.0,
      "eval_accuracy": {
        "accuracy": 0.4584467076109772
      },
      "eval_loss": 2.5198729038238525,
      "eval_runtime": 3.3981,
      "eval_samples_per_second": 3785.311,
      "eval_steps_per_second": 59.15,
      "step": 531810
    },
    {
      "epoch": 855.02,
      "learning_rate": 0.014533525981028939,
      "loss": 2.4084,
      "step": 531820
    },
    {
      "epoch": 855.05,
      "learning_rate": 0.014530310550160769,
      "loss": 2.3961,
      "step": 531840
    },
    {
      "epoch": 855.08,
      "learning_rate": 0.0145270951192926,
      "loss": 2.3888,
      "step": 531860
    },
    {
      "epoch": 855.11,
      "learning_rate": 0.01452387968842444,
      "loss": 2.3916,
      "step": 531880
    },
    {
      "epoch": 855.14,
      "learning_rate": 0.01452066425755627,
      "loss": 2.3903,
      "step": 531900
    },
    {
      "epoch": 855.18,
      "learning_rate": 0.014517448826688104,
      "loss": 2.4083,
      "step": 531920
    },
    {
      "epoch": 855.21,
      "learning_rate": 0.014514233395819934,
      "loss": 2.4002,
      "step": 531940
    },
    {
      "epoch": 855.24,
      "learning_rate": 0.014511017964951765,
      "loss": 2.3941,
      "step": 531960
    },
    {
      "epoch": 855.27,
      "learning_rate": 0.014507802534083597,
      "loss": 2.3932,
      "step": 531980
    },
    {
      "epoch": 855.31,
      "learning_rate": 0.014504587103215439,
      "loss": 2.3897,
      "step": 532000
    },
    {
      "epoch": 855.34,
      "learning_rate": 0.014501371672347269,
      "loss": 2.3866,
      "step": 532020
    },
    {
      "epoch": 855.37,
      "learning_rate": 0.014498156241479099,
      "loss": 2.3978,
      "step": 532040
    },
    {
      "epoch": 855.4,
      "learning_rate": 0.01449494081061093,
      "loss": 2.3878,
      "step": 532060
    },
    {
      "epoch": 855.43,
      "learning_rate": 0.014491725379742762,
      "loss": 2.3853,
      "step": 532080
    },
    {
      "epoch": 855.47,
      "learning_rate": 0.014488509948874594,
      "loss": 2.3829,
      "step": 532100
    },
    {
      "epoch": 855.5,
      "learning_rate": 0.014485294518006434,
      "loss": 2.3828,
      "step": 532120
    },
    {
      "epoch": 855.53,
      "learning_rate": 0.014482079087138264,
      "loss": 2.3899,
      "step": 532140
    },
    {
      "epoch": 855.56,
      "learning_rate": 0.014478863656270095,
      "loss": 2.3923,
      "step": 532160
    },
    {
      "epoch": 855.59,
      "learning_rate": 0.014475648225401927,
      "loss": 2.4,
      "step": 532180
    },
    {
      "epoch": 855.63,
      "learning_rate": 0.014472432794533759,
      "loss": 2.4053,
      "step": 532200
    },
    {
      "epoch": 855.66,
      "learning_rate": 0.014469217363665599,
      "loss": 2.3904,
      "step": 532220
    },
    {
      "epoch": 855.69,
      "learning_rate": 0.014466001932797429,
      "loss": 2.4053,
      "step": 532240
    },
    {
      "epoch": 855.72,
      "learning_rate": 0.014462786501929262,
      "loss": 2.4094,
      "step": 532260
    },
    {
      "epoch": 855.76,
      "learning_rate": 0.014459571071061092,
      "loss": 2.3868,
      "step": 532280
    },
    {
      "epoch": 855.79,
      "learning_rate": 0.014456355640192924,
      "loss": 2.4093,
      "step": 532300
    },
    {
      "epoch": 855.82,
      "learning_rate": 0.014453140209324753,
      "loss": 2.3798,
      "step": 532320
    },
    {
      "epoch": 855.85,
      "learning_rate": 0.014449924778456594,
      "loss": 2.3792,
      "step": 532340
    },
    {
      "epoch": 855.88,
      "learning_rate": 0.014446709347588427,
      "loss": 2.3939,
      "step": 532360
    },
    {
      "epoch": 855.92,
      "learning_rate": 0.014443493916720257,
      "loss": 2.3878,
      "step": 532380
    },
    {
      "epoch": 855.95,
      "learning_rate": 0.014440278485852089,
      "loss": 2.4119,
      "step": 532400
    },
    {
      "epoch": 855.98,
      "learning_rate": 0.014437063054983918,
      "loss": 2.3909,
      "step": 532420
    },
    {
      "epoch": 856.0,
      "eval_accuracy": {
        "accuracy": 0.46427738474694863
      },
      "eval_loss": 2.500509023666382,
      "eval_runtime": 3.2771,
      "eval_samples_per_second": 3925.11,
      "eval_steps_per_second": 61.335,
      "step": 532432
    },
    {
      "epoch": 856.01,
      "learning_rate": 0.014433847624115752,
      "loss": 2.4039,
      "step": 532440
    },
    {
      "epoch": 856.05,
      "learning_rate": 0.014430632193247592,
      "loss": 2.39,
      "step": 532460
    },
    {
      "epoch": 856.08,
      "learning_rate": 0.014427416762379422,
      "loss": 2.3898,
      "step": 532480
    },
    {
      "epoch": 856.11,
      "learning_rate": 0.014424201331511254,
      "loss": 2.3841,
      "step": 532500
    },
    {
      "epoch": 856.14,
      "learning_rate": 0.014420985900643085,
      "loss": 2.4176,
      "step": 532520
    },
    {
      "epoch": 856.17,
      "learning_rate": 0.014417770469774917,
      "loss": 2.3916,
      "step": 532540
    },
    {
      "epoch": 856.21,
      "learning_rate": 0.014414555038906757,
      "loss": 2.3886,
      "step": 532560
    },
    {
      "epoch": 856.24,
      "learning_rate": 0.014411339608038587,
      "loss": 2.4129,
      "step": 532580
    },
    {
      "epoch": 856.27,
      "learning_rate": 0.014408124177170419,
      "loss": 2.3912,
      "step": 532600
    },
    {
      "epoch": 856.3,
      "learning_rate": 0.01440490874630225,
      "loss": 2.3933,
      "step": 532620
    },
    {
      "epoch": 856.33,
      "learning_rate": 0.014401693315434082,
      "loss": 2.4037,
      "step": 532640
    },
    {
      "epoch": 856.37,
      "learning_rate": 0.014398477884565912,
      "loss": 2.3792,
      "step": 532660
    },
    {
      "epoch": 856.4,
      "learning_rate": 0.014395262453697752,
      "loss": 2.393,
      "step": 532680
    },
    {
      "epoch": 856.43,
      "learning_rate": 0.014392047022829584,
      "loss": 2.3941,
      "step": 532700
    },
    {
      "epoch": 856.46,
      "learning_rate": 0.014388831591961415,
      "loss": 2.4033,
      "step": 532720
    },
    {
      "epoch": 856.5,
      "learning_rate": 0.014385616161093247,
      "loss": 2.4032,
      "step": 532740
    },
    {
      "epoch": 856.53,
      "learning_rate": 0.014382400730225077,
      "loss": 2.3899,
      "step": 532760
    },
    {
      "epoch": 856.56,
      "learning_rate": 0.01437918529935691,
      "loss": 2.3929,
      "step": 532780
    },
    {
      "epoch": 856.59,
      "learning_rate": 0.014375969868488749,
      "loss": 2.3937,
      "step": 532800
    },
    {
      "epoch": 856.62,
      "learning_rate": 0.01437275443762058,
      "loss": 2.397,
      "step": 532820
    },
    {
      "epoch": 856.66,
      "learning_rate": 0.014369539006752412,
      "loss": 2.4039,
      "step": 532840
    },
    {
      "epoch": 856.69,
      "learning_rate": 0.014366323575884242,
      "loss": 2.3962,
      "step": 532860
    },
    {
      "epoch": 856.72,
      "learning_rate": 0.014363108145016075,
      "loss": 2.4018,
      "step": 532880
    },
    {
      "epoch": 856.75,
      "learning_rate": 0.014359892714147915,
      "loss": 2.3745,
      "step": 532900
    },
    {
      "epoch": 856.78,
      "learning_rate": 0.014356677283279745,
      "loss": 2.4033,
      "step": 532920
    },
    {
      "epoch": 856.82,
      "learning_rate": 0.014353461852411577,
      "loss": 2.3963,
      "step": 532940
    },
    {
      "epoch": 856.85,
      "learning_rate": 0.014350246421543407,
      "loss": 2.3835,
      "step": 532960
    },
    {
      "epoch": 856.88,
      "learning_rate": 0.01434703099067524,
      "loss": 2.3934,
      "step": 532980
    },
    {
      "epoch": 856.91,
      "learning_rate": 0.014343815559807066,
      "loss": 2.3814,
      "step": 533000
    },
    {
      "epoch": 856.95,
      "learning_rate": 0.01434060012893891,
      "loss": 2.3813,
      "step": 533020
    },
    {
      "epoch": 856.98,
      "learning_rate": 0.014337384698070742,
      "loss": 2.385,
      "step": 533040
    },
    {
      "epoch": 857.0,
      "eval_accuracy": {
        "accuracy": 0.46637642851589833
      },
      "eval_loss": 2.497608184814453,
      "eval_runtime": 3.4459,
      "eval_samples_per_second": 3732.795,
      "eval_steps_per_second": 58.329,
      "step": 533054
    },
    {
      "epoch": 857.01,
      "learning_rate": 0.014334169267202572,
      "loss": 2.385,
      "step": 533060
    },
    {
      "epoch": 857.04,
      "learning_rate": 0.014330953836334405,
      "loss": 2.3939,
      "step": 533080
    },
    {
      "epoch": 857.07,
      "learning_rate": 0.014327738405466235,
      "loss": 2.3922,
      "step": 533100
    },
    {
      "epoch": 857.11,
      "learning_rate": 0.014324522974598075,
      "loss": 2.4059,
      "step": 533120
    },
    {
      "epoch": 857.14,
      "learning_rate": 0.014321307543729907,
      "loss": 2.3986,
      "step": 533140
    },
    {
      "epoch": 857.17,
      "learning_rate": 0.014318092112861738,
      "loss": 2.3963,
      "step": 533160
    },
    {
      "epoch": 857.2,
      "learning_rate": 0.01431487668199357,
      "loss": 2.394,
      "step": 533180
    },
    {
      "epoch": 857.23,
      "learning_rate": 0.0143116612511254,
      "loss": 2.389,
      "step": 533200
    },
    {
      "epoch": 857.27,
      "learning_rate": 0.01430844582025723,
      "loss": 2.3993,
      "step": 533220
    },
    {
      "epoch": 857.3,
      "learning_rate": 0.014305230389389072,
      "loss": 2.4007,
      "step": 533240
    },
    {
      "epoch": 857.33,
      "learning_rate": 0.014302014958520903,
      "loss": 2.3942,
      "step": 533260
    },
    {
      "epoch": 857.36,
      "learning_rate": 0.014298799527652735,
      "loss": 2.3866,
      "step": 533280
    },
    {
      "epoch": 857.4,
      "learning_rate": 0.014295584096784565,
      "loss": 2.408,
      "step": 533300
    },
    {
      "epoch": 857.43,
      "learning_rate": 0.014292368665916395,
      "loss": 2.3963,
      "step": 533320
    },
    {
      "epoch": 857.46,
      "learning_rate": 0.014289153235048225,
      "loss": 2.3905,
      "step": 533340
    },
    {
      "epoch": 857.49,
      "learning_rate": 0.014285937804180068,
      "loss": 2.3922,
      "step": 533360
    },
    {
      "epoch": 857.52,
      "learning_rate": 0.0142827223733119,
      "loss": 2.3976,
      "step": 533380
    },
    {
      "epoch": 857.56,
      "learning_rate": 0.01427950694244373,
      "loss": 2.4041,
      "step": 533400
    },
    {
      "epoch": 857.59,
      "learning_rate": 0.014276291511575563,
      "loss": 2.3939,
      "step": 533420
    },
    {
      "epoch": 857.62,
      "learning_rate": 0.01427307608070739,
      "loss": 2.4027,
      "step": 533440
    },
    {
      "epoch": 857.65,
      "learning_rate": 0.014269860649839233,
      "loss": 2.3823,
      "step": 533460
    },
    {
      "epoch": 857.68,
      "learning_rate": 0.014266645218971065,
      "loss": 2.3771,
      "step": 533480
    },
    {
      "epoch": 857.72,
      "learning_rate": 0.014263429788102895,
      "loss": 2.3925,
      "step": 533500
    },
    {
      "epoch": 857.75,
      "learning_rate": 0.014260214357234728,
      "loss": 2.4017,
      "step": 533520
    },
    {
      "epoch": 857.78,
      "learning_rate": 0.014256998926366555,
      "loss": 2.3759,
      "step": 533540
    },
    {
      "epoch": 857.81,
      "learning_rate": 0.014253783495498388,
      "loss": 2.3934,
      "step": 533560
    },
    {
      "epoch": 857.85,
      "learning_rate": 0.01425056806463023,
      "loss": 2.399,
      "step": 533580
    },
    {
      "epoch": 857.88,
      "learning_rate": 0.01424735263376206,
      "loss": 2.3853,
      "step": 533600
    },
    {
      "epoch": 857.91,
      "learning_rate": 0.014244137202893893,
      "loss": 2.3908,
      "step": 533620
    },
    {
      "epoch": 857.94,
      "learning_rate": 0.01424092177202572,
      "loss": 2.3855,
      "step": 533640
    },
    {
      "epoch": 857.97,
      "learning_rate": 0.014237706341157553,
      "loss": 2.3816,
      "step": 533660
    },
    {
      "epoch": 858.0,
      "eval_accuracy": {
        "accuracy": 0.4617118868071212
      },
      "eval_loss": 2.5199391841888428,
      "eval_runtime": 3.1589,
      "eval_samples_per_second": 4071.982,
      "eval_steps_per_second": 63.63,
      "step": 533676
    },
    {
      "epoch": 858.01,
      "learning_rate": 0.014234490910289383,
      "loss": 2.3958,
      "step": 533680
    },
    {
      "epoch": 858.04,
      "learning_rate": 0.014231275479421225,
      "loss": 2.389,
      "step": 533700
    },
    {
      "epoch": 858.07,
      "learning_rate": 0.014228060048553058,
      "loss": 2.4095,
      "step": 533720
    },
    {
      "epoch": 858.1,
      "learning_rate": 0.014224844617684888,
      "loss": 2.4121,
      "step": 533740
    },
    {
      "epoch": 858.14,
      "learning_rate": 0.014221629186816718,
      "loss": 2.3825,
      "step": 533760
    },
    {
      "epoch": 858.17,
      "learning_rate": 0.014218413755948548,
      "loss": 2.3846,
      "step": 533780
    },
    {
      "epoch": 858.2,
      "learning_rate": 0.014215198325080391,
      "loss": 2.3856,
      "step": 533800
    },
    {
      "epoch": 858.23,
      "learning_rate": 0.014211982894212223,
      "loss": 2.3823,
      "step": 533820
    },
    {
      "epoch": 858.26,
      "learning_rate": 0.014208767463344053,
      "loss": 2.4132,
      "step": 533840
    },
    {
      "epoch": 858.3,
      "learning_rate": 0.014205552032475883,
      "loss": 2.3786,
      "step": 533860
    },
    {
      "epoch": 858.33,
      "learning_rate": 0.014202336601607713,
      "loss": 2.3817,
      "step": 533880
    },
    {
      "epoch": 858.36,
      "learning_rate": 0.014199121170739543,
      "loss": 2.3895,
      "step": 533900
    },
    {
      "epoch": 858.39,
      "learning_rate": 0.014196066511414787,
      "loss": 2.395,
      "step": 533920
    },
    {
      "epoch": 858.42,
      "learning_rate": 0.01419285108054663,
      "loss": 2.3909,
      "step": 533940
    },
    {
      "epoch": 858.46,
      "learning_rate": 0.01418963564967846,
      "loss": 2.3815,
      "step": 533960
    },
    {
      "epoch": 858.49,
      "learning_rate": 0.01418642021881029,
      "loss": 2.3868,
      "step": 533980
    },
    {
      "epoch": 858.52,
      "learning_rate": 0.01418336555948553,
      "loss": 2.4096,
      "step": 534000
    },
    {
      "epoch": 858.55,
      "learning_rate": 0.014180150128617364,
      "loss": 2.3745,
      "step": 534020
    },
    {
      "epoch": 858.59,
      "learning_rate": 0.014176934697749194,
      "loss": 2.3911,
      "step": 534040
    },
    {
      "epoch": 858.62,
      "learning_rate": 0.014173719266881026,
      "loss": 2.3825,
      "step": 534060
    },
    {
      "epoch": 858.65,
      "learning_rate": 0.014170503836012855,
      "loss": 2.3708,
      "step": 534080
    },
    {
      "epoch": 858.68,
      "learning_rate": 0.014167288405144696,
      "loss": 2.4035,
      "step": 534100
    },
    {
      "epoch": 858.71,
      "learning_rate": 0.014164072974276529,
      "loss": 2.3868,
      "step": 534120
    },
    {
      "epoch": 858.75,
      "learning_rate": 0.014160857543408359,
      "loss": 2.3935,
      "step": 534140
    },
    {
      "epoch": 858.78,
      "learning_rate": 0.01415764211254019,
      "loss": 2.3991,
      "step": 534160
    },
    {
      "epoch": 858.81,
      "learning_rate": 0.014154426681672022,
      "loss": 2.3984,
      "step": 534180
    },
    {
      "epoch": 858.84,
      "learning_rate": 0.01415121125080386,
      "loss": 2.3727,
      "step": 534200
    },
    {
      "epoch": 858.87,
      "learning_rate": 0.014147995819935694,
      "loss": 2.408,
      "step": 534220
    },
    {
      "epoch": 858.91,
      "learning_rate": 0.014144780389067524,
      "loss": 2.3886,
      "step": 534240
    },
    {
      "epoch": 858.94,
      "learning_rate": 0.014141564958199355,
      "loss": 2.3947,
      "step": 534260
    },
    {
      "epoch": 858.97,
      "learning_rate": 0.014138349527331187,
      "loss": 2.3825,
      "step": 534280
    },
    {
      "epoch": 859.0,
      "eval_accuracy": {
        "accuracy": 0.45953510067635855
      },
      "eval_loss": 2.505744457244873,
      "eval_runtime": 3.3554,
      "eval_samples_per_second": 3833.57,
      "eval_steps_per_second": 59.904,
      "step": 534298
    },
    {
      "epoch": 859.0,
      "learning_rate": 0.014135134096463019,
      "loss": 2.3923,
      "step": 534300
    },
    {
      "epoch": 859.04,
      "learning_rate": 0.014131918665594859,
      "loss": 2.3979,
      "step": 534320
    },
    {
      "epoch": 859.07,
      "learning_rate": 0.014128703234726689,
      "loss": 2.3905,
      "step": 534340
    },
    {
      "epoch": 859.1,
      "learning_rate": 0.01412548780385852,
      "loss": 2.3748,
      "step": 534360
    },
    {
      "epoch": 859.13,
      "learning_rate": 0.014122272372990352,
      "loss": 2.3795,
      "step": 534380
    },
    {
      "epoch": 859.16,
      "learning_rate": 0.014119056942122184,
      "loss": 2.4033,
      "step": 534400
    },
    {
      "epoch": 859.2,
      "learning_rate": 0.014115841511254024,
      "loss": 2.3928,
      "step": 534420
    },
    {
      "epoch": 859.23,
      "learning_rate": 0.014112626080385854,
      "loss": 2.3971,
      "step": 534440
    },
    {
      "epoch": 859.26,
      "learning_rate": 0.014109410649517685,
      "loss": 2.4024,
      "step": 534460
    },
    {
      "epoch": 859.29,
      "learning_rate": 0.014106195218649517,
      "loss": 2.3912,
      "step": 534480
    },
    {
      "epoch": 859.32,
      "learning_rate": 0.014102979787781349,
      "loss": 2.3841,
      "step": 534500
    },
    {
      "epoch": 859.36,
      "learning_rate": 0.014099764356913179,
      "loss": 2.3908,
      "step": 534520
    },
    {
      "epoch": 859.39,
      "learning_rate": 0.014096548926045019,
      "loss": 2.3859,
      "step": 534540
    },
    {
      "epoch": 859.42,
      "learning_rate": 0.014093333495176852,
      "loss": 2.3922,
      "step": 534560
    },
    {
      "epoch": 859.45,
      "learning_rate": 0.014090118064308682,
      "loss": 2.3756,
      "step": 534580
    },
    {
      "epoch": 859.49,
      "learning_rate": 0.014086902633440514,
      "loss": 2.3805,
      "step": 534600
    },
    {
      "epoch": 859.52,
      "learning_rate": 0.014083687202572344,
      "loss": 2.3913,
      "step": 534620
    },
    {
      "epoch": 859.55,
      "learning_rate": 0.014080471771704177,
      "loss": 2.3873,
      "step": 534640
    },
    {
      "epoch": 859.58,
      "learning_rate": 0.014077256340836017,
      "loss": 2.4137,
      "step": 534660
    },
    {
      "epoch": 859.61,
      "learning_rate": 0.014074040909967847,
      "loss": 2.3705,
      "step": 534680
    },
    {
      "epoch": 859.65,
      "learning_rate": 0.014070825479099679,
      "loss": 2.3886,
      "step": 534700
    },
    {
      "epoch": 859.68,
      "learning_rate": 0.014067610048231509,
      "loss": 2.4025,
      "step": 534720
    },
    {
      "epoch": 859.71,
      "learning_rate": 0.014064394617363342,
      "loss": 2.3887,
      "step": 534740
    },
    {
      "epoch": 859.74,
      "learning_rate": 0.014061179186495182,
      "loss": 2.3981,
      "step": 534760
    },
    {
      "epoch": 859.77,
      "learning_rate": 0.014057963755627012,
      "loss": 2.3953,
      "step": 534780
    },
    {
      "epoch": 859.81,
      "learning_rate": 0.014054748324758844,
      "loss": 2.3745,
      "step": 534800
    },
    {
      "epoch": 859.84,
      "learning_rate": 0.014051532893890675,
      "loss": 2.3882,
      "step": 534820
    },
    {
      "epoch": 859.87,
      "learning_rate": 0.014048317463022507,
      "loss": 2.3935,
      "step": 534840
    },
    {
      "epoch": 859.9,
      "learning_rate": 0.014045102032154337,
      "loss": 2.3883,
      "step": 534860
    },
    {
      "epoch": 859.94,
      "learning_rate": 0.014041886601286177,
      "loss": 2.4101,
      "step": 534880
    },
    {
      "epoch": 859.97,
      "learning_rate": 0.014038671170418009,
      "loss": 2.398,
      "step": 534900
    },
    {
      "epoch": 860.0,
      "learning_rate": 0.01403545573954984,
      "loss": 2.3828,
      "step": 534920
    },
    {
      "epoch": 860.0,
      "eval_accuracy": {
        "accuracy": 0.458757677058229
      },
      "eval_loss": 2.504775285720825,
      "eval_runtime": 3.3245,
      "eval_samples_per_second": 3869.143,
      "eval_steps_per_second": 60.46,
      "step": 534920
    },
    {
      "epoch": 860.03,
      "learning_rate": 0.014032240308681672,
      "loss": 2.3759,
      "step": 534940
    },
    {
      "epoch": 860.06,
      "learning_rate": 0.014029024877813502,
      "loss": 2.3889,
      "step": 534960
    },
    {
      "epoch": 860.1,
      "learning_rate": 0.014025809446945332,
      "loss": 2.391,
      "step": 534980
    },
    {
      "epoch": 860.13,
      "learning_rate": 0.014022594016077174,
      "loss": 2.3738,
      "step": 535000
    },
    {
      "epoch": 860.16,
      "learning_rate": 0.014019378585209005,
      "loss": 2.3789,
      "step": 535020
    },
    {
      "epoch": 860.19,
      "learning_rate": 0.014016163154340837,
      "loss": 2.3889,
      "step": 535040
    },
    {
      "epoch": 860.23,
      "learning_rate": 0.014012947723472667,
      "loss": 2.4051,
      "step": 535060
    },
    {
      "epoch": 860.26,
      "learning_rate": 0.0140097322926045,
      "loss": 2.3761,
      "step": 535080
    },
    {
      "epoch": 860.29,
      "learning_rate": 0.014006516861736339,
      "loss": 2.3904,
      "step": 535100
    },
    {
      "epoch": 860.32,
      "learning_rate": 0.01400330143086817,
      "loss": 2.3884,
      "step": 535120
    },
    {
      "epoch": 860.35,
      "learning_rate": 0.014000086000000002,
      "loss": 2.4001,
      "step": 535140
    },
    {
      "epoch": 860.39,
      "learning_rate": 0.013996870569131832,
      "loss": 2.3799,
      "step": 535160
    },
    {
      "epoch": 860.42,
      "learning_rate": 0.013993655138263665,
      "loss": 2.3957,
      "step": 535180
    },
    {
      "epoch": 860.45,
      "learning_rate": 0.013990439707395491,
      "loss": 2.3852,
      "step": 535200
    },
    {
      "epoch": 860.48,
      "learning_rate": 0.013987224276527335,
      "loss": 2.3848,
      "step": 535220
    },
    {
      "epoch": 860.51,
      "learning_rate": 0.013984008845659167,
      "loss": 2.3909,
      "step": 535240
    },
    {
      "epoch": 860.55,
      "learning_rate": 0.013980793414790997,
      "loss": 2.3739,
      "step": 535260
    },
    {
      "epoch": 860.58,
      "learning_rate": 0.01397757798392283,
      "loss": 2.3968,
      "step": 535280
    },
    {
      "epoch": 860.61,
      "learning_rate": 0.013974362553054656,
      "loss": 2.4032,
      "step": 535300
    },
    {
      "epoch": 860.64,
      "learning_rate": 0.01397114712218649,
      "loss": 2.4063,
      "step": 535320
    },
    {
      "epoch": 860.68,
      "learning_rate": 0.013967931691318332,
      "loss": 2.3884,
      "step": 535340
    },
    {
      "epoch": 860.71,
      "learning_rate": 0.013964716260450162,
      "loss": 2.3973,
      "step": 535360
    },
    {
      "epoch": 860.74,
      "learning_rate": 0.013961500829581995,
      "loss": 2.3855,
      "step": 535380
    },
    {
      "epoch": 860.77,
      "learning_rate": 0.013958285398713825,
      "loss": 2.3887,
      "step": 535400
    },
    {
      "epoch": 860.8,
      "learning_rate": 0.013955069967845655,
      "loss": 2.3968,
      "step": 535420
    },
    {
      "epoch": 860.84,
      "learning_rate": 0.013951854536977497,
      "loss": 2.3873,
      "step": 535440
    },
    {
      "epoch": 860.87,
      "learning_rate": 0.013948639106109328,
      "loss": 2.3869,
      "step": 535460
    },
    {
      "epoch": 860.9,
      "learning_rate": 0.01394542367524116,
      "loss": 2.389,
      "step": 535480
    },
    {
      "epoch": 860.93,
      "learning_rate": 0.01394220824437299,
      "loss": 2.3929,
      "step": 535500
    },
    {
      "epoch": 860.96,
      "learning_rate": 0.01393899281350482,
      "loss": 2.3874,
      "step": 535520
    },
    {
      "epoch": 861.0,
      "learning_rate": 0.01393577738263665,
      "loss": 2.4117,
      "step": 535540
    },
    {
      "epoch": 861.0,
      "eval_accuracy": {
        "accuracy": 0.4566586332892793
      },
      "eval_loss": 2.5186526775360107,
      "eval_runtime": 3.1905,
      "eval_samples_per_second": 4031.692,
      "eval_steps_per_second": 63.0,
      "step": 535542
    },
    {
      "epoch": 861.03,
      "learning_rate": 0.013932561951768493,
      "loss": 2.3928,
      "step": 535560
    },
    {
      "epoch": 861.06,
      "learning_rate": 0.013929346520900325,
      "loss": 2.4044,
      "step": 535580
    },
    {
      "epoch": 861.09,
      "learning_rate": 0.013926131090032155,
      "loss": 2.3964,
      "step": 535600
    },
    {
      "epoch": 861.13,
      "learning_rate": 0.013922915659163985,
      "loss": 2.3961,
      "step": 535620
    },
    {
      "epoch": 861.16,
      "learning_rate": 0.013919700228295815,
      "loss": 2.3847,
      "step": 535640
    },
    {
      "epoch": 861.19,
      "learning_rate": 0.013916484797427645,
      "loss": 2.3933,
      "step": 535660
    },
    {
      "epoch": 861.22,
      "learning_rate": 0.01391326936655949,
      "loss": 2.3971,
      "step": 535680
    },
    {
      "epoch": 861.25,
      "learning_rate": 0.01391005393569132,
      "loss": 2.3796,
      "step": 535700
    },
    {
      "epoch": 861.29,
      "learning_rate": 0.013906838504823153,
      "loss": 2.3901,
      "step": 535720
    },
    {
      "epoch": 861.32,
      "learning_rate": 0.01390362307395498,
      "loss": 2.3865,
      "step": 535740
    },
    {
      "epoch": 861.35,
      "learning_rate": 0.013900407643086813,
      "loss": 2.3929,
      "step": 535760
    },
    {
      "epoch": 861.38,
      "learning_rate": 0.013897192212218655,
      "loss": 2.3974,
      "step": 535780
    },
    {
      "epoch": 861.41,
      "learning_rate": 0.013893976781350485,
      "loss": 2.3865,
      "step": 535800
    },
    {
      "epoch": 861.45,
      "learning_rate": 0.013890761350482318,
      "loss": 2.3682,
      "step": 535820
    },
    {
      "epoch": 861.48,
      "learning_rate": 0.013887545919614145,
      "loss": 2.3964,
      "step": 535840
    },
    {
      "epoch": 861.51,
      "learning_rate": 0.013884330488745978,
      "loss": 2.3681,
      "step": 535860
    },
    {
      "epoch": 861.54,
      "learning_rate": 0.013881115057877808,
      "loss": 2.3958,
      "step": 535880
    },
    {
      "epoch": 861.58,
      "learning_rate": 0.01387789962700965,
      "loss": 2.3827,
      "step": 535900
    },
    {
      "epoch": 861.61,
      "learning_rate": 0.013874684196141483,
      "loss": 2.3953,
      "step": 535920
    },
    {
      "epoch": 861.64,
      "learning_rate": 0.01387146876527331,
      "loss": 2.4062,
      "step": 535940
    },
    {
      "epoch": 861.67,
      "learning_rate": 0.013868253334405143,
      "loss": 2.3755,
      "step": 535960
    },
    {
      "epoch": 861.7,
      "learning_rate": 0.013865037903536973,
      "loss": 2.4027,
      "step": 535980
    },
    {
      "epoch": 861.74,
      "learning_rate": 0.013861822472668803,
      "loss": 2.3833,
      "step": 536000
    },
    {
      "epoch": 861.77,
      "learning_rate": 0.013858607041800648,
      "loss": 2.3919,
      "step": 536020
    },
    {
      "epoch": 861.8,
      "learning_rate": 0.013855391610932478,
      "loss": 2.3769,
      "step": 536040
    },
    {
      "epoch": 861.83,
      "learning_rate": 0.013852176180064308,
      "loss": 2.3837,
      "step": 536060
    },
    {
      "epoch": 861.86,
      "learning_rate": 0.013848960749196138,
      "loss": 2.4,
      "step": 536080
    },
    {
      "epoch": 861.9,
      "learning_rate": 0.013845745318327968,
      "loss": 2.3891,
      "step": 536100
    },
    {
      "epoch": 861.93,
      "learning_rate": 0.013842529887459813,
      "loss": 2.3879,
      "step": 536120
    },
    {
      "epoch": 861.96,
      "learning_rate": 0.013839314456591643,
      "loss": 2.3754,
      "step": 536140
    },
    {
      "epoch": 861.99,
      "learning_rate": 0.013836099025723473,
      "loss": 2.3934,
      "step": 536160
    },
    {
      "epoch": 862.0,
      "eval_accuracy": {
        "accuracy": 0.4630335069579414
      },
      "eval_loss": 2.50645112991333,
      "eval_runtime": 3.2532,
      "eval_samples_per_second": 3953.939,
      "eval_steps_per_second": 61.785,
      "step": 536164
    },
    {
      "epoch": 862.03,
      "learning_rate": 0.013832883594855303,
      "loss": 2.3719,
      "step": 536180
    },
    {
      "epoch": 862.06,
      "learning_rate": 0.013829668163987133,
      "loss": 2.3887,
      "step": 536200
    },
    {
      "epoch": 862.09,
      "learning_rate": 0.013826452733118966,
      "loss": 2.4073,
      "step": 536220
    },
    {
      "epoch": 862.12,
      "learning_rate": 0.013823237302250808,
      "loss": 2.3941,
      "step": 536240
    },
    {
      "epoch": 862.15,
      "learning_rate": 0.013820021871382638,
      "loss": 2.3846,
      "step": 536260
    },
    {
      "epoch": 862.19,
      "learning_rate": 0.013816806440514468,
      "loss": 2.3768,
      "step": 536280
    },
    {
      "epoch": 862.22,
      "learning_rate": 0.013813591009646301,
      "loss": 2.397,
      "step": 536300
    },
    {
      "epoch": 862.25,
      "learning_rate": 0.013810375578778131,
      "loss": 2.39,
      "step": 536320
    },
    {
      "epoch": 862.28,
      "learning_rate": 0.013807160147909973,
      "loss": 2.388,
      "step": 536340
    },
    {
      "epoch": 862.32,
      "learning_rate": 0.013803944717041806,
      "loss": 2.3947,
      "step": 536360
    },
    {
      "epoch": 862.35,
      "learning_rate": 0.013800729286173633,
      "loss": 2.3899,
      "step": 536380
    },
    {
      "epoch": 862.38,
      "learning_rate": 0.013797513855305466,
      "loss": 2.3815,
      "step": 536400
    },
    {
      "epoch": 862.41,
      "learning_rate": 0.013794298424437296,
      "loss": 2.3824,
      "step": 536420
    },
    {
      "epoch": 862.44,
      "learning_rate": 0.013791082993569126,
      "loss": 2.4001,
      "step": 536440
    },
    {
      "epoch": 862.48,
      "learning_rate": 0.013787867562700971,
      "loss": 2.3898,
      "step": 536460
    },
    {
      "epoch": 862.51,
      "learning_rate": 0.013784652131832798,
      "loss": 2.381,
      "step": 536480
    },
    {
      "epoch": 862.54,
      "learning_rate": 0.013781436700964631,
      "loss": 2.3918,
      "step": 536500
    },
    {
      "epoch": 862.57,
      "learning_rate": 0.013778221270096461,
      "loss": 2.3604,
      "step": 536520
    },
    {
      "epoch": 862.6,
      "learning_rate": 0.013775005839228291,
      "loss": 2.3891,
      "step": 536540
    },
    {
      "epoch": 862.64,
      "learning_rate": 0.013771790408360123,
      "loss": 2.3909,
      "step": 536560
    },
    {
      "epoch": 862.67,
      "learning_rate": 0.013768574977491963,
      "loss": 2.387,
      "step": 536580
    },
    {
      "epoch": 862.7,
      "learning_rate": 0.013765359546623796,
      "loss": 2.3873,
      "step": 536600
    },
    {
      "epoch": 862.73,
      "learning_rate": 0.013762144115755626,
      "loss": 2.4073,
      "step": 536620
    },
    {
      "epoch": 862.77,
      "learning_rate": 0.013758928684887456,
      "loss": 2.3775,
      "step": 536640
    },
    {
      "epoch": 862.8,
      "learning_rate": 0.01375571325401929,
      "loss": 2.3821,
      "step": 536660
    },
    {
      "epoch": 862.83,
      "learning_rate": 0.013752497823151131,
      "loss": 2.3907,
      "step": 536680
    },
    {
      "epoch": 862.86,
      "learning_rate": 0.013749282392282961,
      "loss": 2.3932,
      "step": 536700
    },
    {
      "epoch": 862.89,
      "learning_rate": 0.013746066961414791,
      "loss": 2.4075,
      "step": 536720
    },
    {
      "epoch": 862.93,
      "learning_rate": 0.013742851530546621,
      "loss": 2.3686,
      "step": 536740
    },
    {
      "epoch": 862.96,
      "learning_rate": 0.013739636099678454,
      "loss": 2.3903,
      "step": 536760
    },
    {
      "epoch": 862.99,
      "learning_rate": 0.013736420668810284,
      "loss": 2.378,
      "step": 536780
    },
    {
      "epoch": 863.0,
      "eval_accuracy": {
        "accuracy": 0.4681645028375962
      },
      "eval_loss": 2.4986989498138428,
      "eval_runtime": 3.6724,
      "eval_samples_per_second": 3502.618,
      "eval_steps_per_second": 54.733,
      "step": 536786
    },
    {
      "epoch": 863.02,
      "learning_rate": 0.013733205237942126,
      "loss": 2.3841,
      "step": 536800
    },
    {
      "epoch": 863.05,
      "learning_rate": 0.013729989807073956,
      "loss": 2.3845,
      "step": 536820
    },
    {
      "epoch": 863.09,
      "learning_rate": 0.013726774376205786,
      "loss": 2.3926,
      "step": 536840
    },
    {
      "epoch": 863.12,
      "learning_rate": 0.01372355894533762,
      "loss": 2.3983,
      "step": 536860
    },
    {
      "epoch": 863.15,
      "learning_rate": 0.013720343514469449,
      "loss": 2.3888,
      "step": 536880
    },
    {
      "epoch": 863.18,
      "learning_rate": 0.01371712808360128,
      "loss": 2.3624,
      "step": 536900
    },
    {
      "epoch": 863.22,
      "learning_rate": 0.013713912652733121,
      "loss": 2.3948,
      "step": 536920
    },
    {
      "epoch": 863.25,
      "learning_rate": 0.013710697221864954,
      "loss": 2.3975,
      "step": 536940
    },
    {
      "epoch": 863.28,
      "learning_rate": 0.013707481790996784,
      "loss": 2.3642,
      "step": 536960
    },
    {
      "epoch": 863.31,
      "learning_rate": 0.013704266360128614,
      "loss": 2.4031,
      "step": 536980
    },
    {
      "epoch": 863.34,
      "learning_rate": 0.013701050929260446,
      "loss": 2.3773,
      "step": 537000
    },
    {
      "epoch": 863.38,
      "learning_rate": 0.013697835498392286,
      "loss": 2.3898,
      "step": 537020
    },
    {
      "epoch": 863.41,
      "learning_rate": 0.01369462006752412,
      "loss": 2.3816,
      "step": 537040
    },
    {
      "epoch": 863.44,
      "learning_rate": 0.01369140463665595,
      "loss": 2.3805,
      "step": 537060
    },
    {
      "epoch": 863.47,
      "learning_rate": 0.013688189205787779,
      "loss": 2.3935,
      "step": 537080
    },
    {
      "epoch": 863.5,
      "learning_rate": 0.01368497377491961,
      "loss": 2.3781,
      "step": 537100
    },
    {
      "epoch": 863.54,
      "learning_rate": 0.013681758344051442,
      "loss": 2.3793,
      "step": 537120
    },
    {
      "epoch": 863.57,
      "learning_rate": 0.013678542913183284,
      "loss": 2.3825,
      "step": 537140
    },
    {
      "epoch": 863.6,
      "learning_rate": 0.013675327482315114,
      "loss": 2.3937,
      "step": 537160
    },
    {
      "epoch": 863.63,
      "learning_rate": 0.013672112051446944,
      "loss": 2.3747,
      "step": 537180
    },
    {
      "epoch": 863.67,
      "learning_rate": 0.013668896620578776,
      "loss": 2.3727,
      "step": 537200
    },
    {
      "epoch": 863.7,
      "learning_rate": 0.013665681189710607,
      "loss": 2.3816,
      "step": 537220
    },
    {
      "epoch": 863.73,
      "learning_rate": 0.013662465758842439,
      "loss": 2.3891,
      "step": 537240
    },
    {
      "epoch": 863.76,
      "learning_rate": 0.01365925032797428,
      "loss": 2.4071,
      "step": 537260
    },
    {
      "epoch": 863.79,
      "learning_rate": 0.013656034897106109,
      "loss": 2.3971,
      "step": 537280
    },
    {
      "epoch": 863.83,
      "learning_rate": 0.013652819466237942,
      "loss": 2.3869,
      "step": 537300
    },
    {
      "epoch": 863.86,
      "learning_rate": 0.013649604035369772,
      "loss": 2.3819,
      "step": 537320
    },
    {
      "epoch": 863.89,
      "learning_rate": 0.013646388604501604,
      "loss": 2.3867,
      "step": 537340
    },
    {
      "epoch": 863.92,
      "learning_rate": 0.013643173173633444,
      "loss": 2.3879,
      "step": 537360
    },
    {
      "epoch": 863.95,
      "learning_rate": 0.013639957742765274,
      "loss": 2.426,
      "step": 537380
    },
    {
      "epoch": 863.99,
      "learning_rate": 0.013636742311897107,
      "loss": 2.3839,
      "step": 537400
    },
    {
      "epoch": 864.0,
      "eval_accuracy": {
        "accuracy": 0.463655445852445
      },
      "eval_loss": 2.513822555541992,
      "eval_runtime": 3.0998,
      "eval_samples_per_second": 4149.613,
      "eval_steps_per_second": 64.843,
      "step": 537408
    },
    {
      "epoch": 864.02,
      "learning_rate": 0.013633526881028937,
      "loss": 2.3787,
      "step": 537420
    },
    {
      "epoch": 864.05,
      "learning_rate": 0.013630311450160769,
      "loss": 2.3744,
      "step": 537440
    },
    {
      "epoch": 864.08,
      "learning_rate": 0.01362725679083601,
      "loss": 2.3744,
      "step": 537460
    },
    {
      "epoch": 864.12,
      "learning_rate": 0.013624041359967844,
      "loss": 2.3801,
      "step": 537480
    },
    {
      "epoch": 864.15,
      "learning_rate": 0.013620825929099684,
      "loss": 2.3962,
      "step": 537500
    },
    {
      "epoch": 864.18,
      "learning_rate": 0.013617610498231514,
      "loss": 2.3882,
      "step": 537520
    },
    {
      "epoch": 864.21,
      "learning_rate": 0.013614395067363345,
      "loss": 2.393,
      "step": 537540
    },
    {
      "epoch": 864.24,
      "learning_rate": 0.013611179636495175,
      "loss": 2.396,
      "step": 537560
    },
    {
      "epoch": 864.28,
      "learning_rate": 0.013607964205627009,
      "loss": 2.4028,
      "step": 537580
    },
    {
      "epoch": 864.31,
      "learning_rate": 0.013604748774758839,
      "loss": 2.3975,
      "step": 537600
    },
    {
      "epoch": 864.34,
      "learning_rate": 0.013601533343890679,
      "loss": 2.3812,
      "step": 537620
    },
    {
      "epoch": 864.37,
      "learning_rate": 0.01359831791302251,
      "loss": 2.3921,
      "step": 537640
    },
    {
      "epoch": 864.41,
      "learning_rate": 0.013595102482154342,
      "loss": 2.3727,
      "step": 537660
    },
    {
      "epoch": 864.44,
      "learning_rate": 0.013591887051286174,
      "loss": 2.3829,
      "step": 537680
    },
    {
      "epoch": 864.47,
      "learning_rate": 0.013588671620418004,
      "loss": 2.3814,
      "step": 537700
    },
    {
      "epoch": 864.5,
      "learning_rate": 0.013585456189549833,
      "loss": 2.3984,
      "step": 537720
    },
    {
      "epoch": 864.53,
      "learning_rate": 0.013582240758681675,
      "loss": 2.3776,
      "step": 537740
    },
    {
      "epoch": 864.57,
      "learning_rate": 0.013579025327813507,
      "loss": 2.3786,
      "step": 537760
    },
    {
      "epoch": 864.6,
      "learning_rate": 0.013575809896945339,
      "loss": 2.3793,
      "step": 537780
    },
    {
      "epoch": 864.63,
      "learning_rate": 0.013572594466077169,
      "loss": 2.3978,
      "step": 537800
    },
    {
      "epoch": 864.66,
      "learning_rate": 0.013569379035208998,
      "loss": 2.3799,
      "step": 537820
    },
    {
      "epoch": 864.69,
      "learning_rate": 0.01356616360434084,
      "loss": 2.4008,
      "step": 537840
    },
    {
      "epoch": 864.73,
      "learning_rate": 0.013562948173472672,
      "loss": 2.3773,
      "step": 537860
    },
    {
      "epoch": 864.76,
      "learning_rate": 0.013559732742604504,
      "loss": 2.3952,
      "step": 537880
    },
    {
      "epoch": 864.79,
      "learning_rate": 0.013556517311736333,
      "loss": 2.3752,
      "step": 537900
    },
    {
      "epoch": 864.82,
      "learning_rate": 0.013553301880868167,
      "loss": 2.3885,
      "step": 537920
    },
    {
      "epoch": 864.86,
      "learning_rate": 0.013550086449999993,
      "loss": 2.3728,
      "step": 537940
    },
    {
      "epoch": 864.89,
      "learning_rate": 0.013546871019131837,
      "loss": 2.4056,
      "step": 537960
    },
    {
      "epoch": 864.92,
      "learning_rate": 0.013543655588263669,
      "loss": 2.3822,
      "step": 537980
    },
    {
      "epoch": 864.95,
      "learning_rate": 0.013540440157395498,
      "loss": 2.3814,
      "step": 538000
    },
    {
      "epoch": 864.98,
      "learning_rate": 0.013537224726527332,
      "loss": 2.3843,
      "step": 538020
    },
    {
      "epoch": 865.0,
      "eval_accuracy": {
        "accuracy": 0.4622560833398119
      },
      "eval_loss": 2.5021345615386963,
      "eval_runtime": 3.918,
      "eval_samples_per_second": 3283.088,
      "eval_steps_per_second": 51.302,
      "step": 538030
    },
    {
      "epoch": 865.02,
      "learning_rate": 0.013534009295659158,
      "loss": 2.3905,
      "step": 538040
    },
    {
      "epoch": 865.05,
      "learning_rate": 0.013530793864790992,
      "loss": 2.3841,
      "step": 538060
    },
    {
      "epoch": 865.08,
      "learning_rate": 0.013527578433922834,
      "loss": 2.3607,
      "step": 538080
    },
    {
      "epoch": 865.11,
      "learning_rate": 0.013524363003054663,
      "loss": 2.3845,
      "step": 538100
    },
    {
      "epoch": 865.14,
      "learning_rate": 0.013521147572186497,
      "loss": 2.3889,
      "step": 538120
    },
    {
      "epoch": 865.18,
      "learning_rate": 0.013517932141318323,
      "loss": 2.4037,
      "step": 538140
    },
    {
      "epoch": 865.21,
      "learning_rate": 0.013514716710450157,
      "loss": 2.3886,
      "step": 538160
    },
    {
      "epoch": 865.24,
      "learning_rate": 0.013511501279581999,
      "loss": 2.3759,
      "step": 538180
    },
    {
      "epoch": 865.27,
      "learning_rate": 0.013508285848713828,
      "loss": 2.3659,
      "step": 538200
    },
    {
      "epoch": 865.31,
      "learning_rate": 0.013505070417845662,
      "loss": 2.3881,
      "step": 538220
    },
    {
      "epoch": 865.34,
      "learning_rate": 0.013501854986977492,
      "loss": 2.3994,
      "step": 538240
    },
    {
      "epoch": 865.37,
      "learning_rate": 0.013498639556109322,
      "loss": 2.3977,
      "step": 538260
    },
    {
      "epoch": 865.4,
      "learning_rate": 0.013495424125241151,
      "loss": 2.3975,
      "step": 538280
    },
    {
      "epoch": 865.43,
      "learning_rate": 0.013492208694372995,
      "loss": 2.39,
      "step": 538300
    },
    {
      "epoch": 865.47,
      "learning_rate": 0.013488993263504827,
      "loss": 2.3897,
      "step": 538320
    },
    {
      "epoch": 865.5,
      "learning_rate": 0.013485777832636657,
      "loss": 2.3841,
      "step": 538340
    },
    {
      "epoch": 865.53,
      "learning_rate": 0.013482562401768487,
      "loss": 2.3884,
      "step": 538360
    },
    {
      "epoch": 865.56,
      "learning_rate": 0.013479346970900316,
      "loss": 2.3748,
      "step": 538380
    },
    {
      "epoch": 865.59,
      "learning_rate": 0.013476131540032146,
      "loss": 2.3794,
      "step": 538400
    },
    {
      "epoch": 865.63,
      "learning_rate": 0.013472916109163992,
      "loss": 2.392,
      "step": 538420
    },
    {
      "epoch": 865.66,
      "learning_rate": 0.013469700678295822,
      "loss": 2.3951,
      "step": 538440
    },
    {
      "epoch": 865.69,
      "learning_rate": 0.013466485247427652,
      "loss": 2.3857,
      "step": 538460
    },
    {
      "epoch": 865.72,
      "learning_rate": 0.013463269816559481,
      "loss": 2.3802,
      "step": 538480
    },
    {
      "epoch": 865.76,
      "learning_rate": 0.013460054385691315,
      "loss": 2.3636,
      "step": 538500
    },
    {
      "epoch": 865.79,
      "learning_rate": 0.013456838954823157,
      "loss": 2.3633,
      "step": 538520
    },
    {
      "epoch": 865.82,
      "learning_rate": 0.013453623523954987,
      "loss": 2.3817,
      "step": 538540
    },
    {
      "epoch": 865.85,
      "learning_rate": 0.01345040809308682,
      "loss": 2.4021,
      "step": 538560
    },
    {
      "epoch": 865.88,
      "learning_rate": 0.013447192662218646,
      "loss": 2.3783,
      "step": 538580
    },
    {
      "epoch": 865.92,
      "learning_rate": 0.01344397723135048,
      "loss": 2.3783,
      "step": 538600
    },
    {
      "epoch": 865.95,
      "learning_rate": 0.01344076180048231,
      "loss": 2.3735,
      "step": 538620
    },
    {
      "epoch": 865.98,
      "learning_rate": 0.013437546369614152,
      "loss": 2.3961,
      "step": 538640
    },
    {
      "epoch": 866.0,
      "eval_accuracy": {
        "accuracy": 0.46497706600326516
      },
      "eval_loss": 2.4987754821777344,
      "eval_runtime": 3.9677,
      "eval_samples_per_second": 3241.899,
      "eval_steps_per_second": 50.659,
      "step": 538652
    },
    {
      "epoch": 866.01,
      "learning_rate": 0.013434330938745985,
      "loss": 2.3992,
      "step": 538660
    },
    {
      "epoch": 866.05,
      "learning_rate": 0.013431115507877811,
      "loss": 2.3804,
      "step": 538680
    },
    {
      "epoch": 866.08,
      "learning_rate": 0.013427900077009645,
      "loss": 2.3978,
      "step": 538700
    },
    {
      "epoch": 866.11,
      "learning_rate": 0.013424684646141475,
      "loss": 2.3993,
      "step": 538720
    },
    {
      "epoch": 866.14,
      "learning_rate": 0.013421469215273317,
      "loss": 2.3961,
      "step": 538740
    },
    {
      "epoch": 866.17,
      "learning_rate": 0.01341825378440515,
      "loss": 2.3869,
      "step": 538760
    },
    {
      "epoch": 866.21,
      "learning_rate": 0.013415038353536976,
      "loss": 2.3649,
      "step": 538780
    },
    {
      "epoch": 866.24,
      "learning_rate": 0.01341182292266881,
      "loss": 2.383,
      "step": 538800
    },
    {
      "epoch": 866.27,
      "learning_rate": 0.01340860749180064,
      "loss": 2.3632,
      "step": 538820
    },
    {
      "epoch": 866.3,
      "learning_rate": 0.01340539206093247,
      "loss": 2.3675,
      "step": 538840
    },
    {
      "epoch": 866.33,
      "learning_rate": 0.013402176630064315,
      "loss": 2.3968,
      "step": 538860
    },
    {
      "epoch": 866.37,
      "learning_rate": 0.013398961199196145,
      "loss": 2.3884,
      "step": 538880
    },
    {
      "epoch": 866.4,
      "learning_rate": 0.013395745768327975,
      "loss": 2.3828,
      "step": 538900
    },
    {
      "epoch": 866.43,
      "learning_rate": 0.013392530337459805,
      "loss": 2.3764,
      "step": 538920
    },
    {
      "epoch": 866.46,
      "learning_rate": 0.013389314906591634,
      "loss": 2.3927,
      "step": 538940
    },
    {
      "epoch": 866.5,
      "learning_rate": 0.013386099475723468,
      "loss": 2.3931,
      "step": 538960
    },
    {
      "epoch": 866.53,
      "learning_rate": 0.01338288404485531,
      "loss": 2.3783,
      "step": 538980
    },
    {
      "epoch": 866.56,
      "learning_rate": 0.01337966861398714,
      "loss": 2.4012,
      "step": 539000
    },
    {
      "epoch": 866.59,
      "learning_rate": 0.01337645318311897,
      "loss": 2.378,
      "step": 539020
    },
    {
      "epoch": 866.62,
      "learning_rate": 0.0133732377522508,
      "loss": 2.3694,
      "step": 539040
    },
    {
      "epoch": 866.66,
      "learning_rate": 0.013370022321382633,
      "loss": 2.3813,
      "step": 539060
    },
    {
      "epoch": 866.69,
      "learning_rate": 0.013366806890514475,
      "loss": 2.3765,
      "step": 539080
    },
    {
      "epoch": 866.72,
      "learning_rate": 0.013363591459646305,
      "loss": 2.3743,
      "step": 539100
    },
    {
      "epoch": 866.75,
      "learning_rate": 0.013360376028778135,
      "loss": 2.3929,
      "step": 539120
    },
    {
      "epoch": 866.78,
      "learning_rate": 0.013357160597909968,
      "loss": 2.4026,
      "step": 539140
    },
    {
      "epoch": 866.82,
      "learning_rate": 0.013353945167041798,
      "loss": 2.3701,
      "step": 539160
    },
    {
      "epoch": 866.85,
      "learning_rate": 0.013350729736173628,
      "loss": 2.3761,
      "step": 539180
    },
    {
      "epoch": 866.88,
      "learning_rate": 0.013347514305305473,
      "loss": 2.3981,
      "step": 539200
    },
    {
      "epoch": 866.91,
      "learning_rate": 0.0133442988744373,
      "loss": 2.3772,
      "step": 539220
    },
    {
      "epoch": 866.95,
      "learning_rate": 0.013341083443569133,
      "loss": 2.3959,
      "step": 539240
    },
    {
      "epoch": 866.98,
      "learning_rate": 0.013337868012700963,
      "loss": 2.3894,
      "step": 539260
    },
    {
      "epoch": 867.0,
      "eval_accuracy": {
        "accuracy": 0.46280027987250255
      },
      "eval_loss": 2.5068774223327637,
      "eval_runtime": 3.3324,
      "eval_samples_per_second": 3859.972,
      "eval_steps_per_second": 60.317,
      "step": 539274
    },
    {
      "epoch": 867.01,
      "learning_rate": 0.013334652581832793,
      "loss": 2.3816,
      "step": 539280
    },
    {
      "epoch": 867.04,
      "learning_rate": 0.013331437150964624,
      "loss": 2.3896,
      "step": 539300
    },
    {
      "epoch": 867.07,
      "learning_rate": 0.013328221720096465,
      "loss": 2.3574,
      "step": 539320
    },
    {
      "epoch": 867.11,
      "learning_rate": 0.013325006289228298,
      "loss": 2.3776,
      "step": 539340
    },
    {
      "epoch": 867.14,
      "learning_rate": 0.013321790858360128,
      "loss": 2.3929,
      "step": 539360
    },
    {
      "epoch": 867.17,
      "learning_rate": 0.013318575427491958,
      "loss": 2.383,
      "step": 539380
    },
    {
      "epoch": 867.2,
      "learning_rate": 0.013315359996623791,
      "loss": 2.3811,
      "step": 539400
    },
    {
      "epoch": 867.23,
      "learning_rate": 0.01331214456575563,
      "loss": 2.3631,
      "step": 539420
    },
    {
      "epoch": 867.27,
      "learning_rate": 0.013308929134887463,
      "loss": 2.3686,
      "step": 539440
    },
    {
      "epoch": 867.3,
      "learning_rate": 0.013305713704019293,
      "loss": 2.3892,
      "step": 539460
    },
    {
      "epoch": 867.33,
      "learning_rate": 0.013302498273151123,
      "loss": 2.389,
      "step": 539480
    },
    {
      "epoch": 867.36,
      "learning_rate": 0.013299282842282956,
      "loss": 2.3865,
      "step": 539500
    },
    {
      "epoch": 867.4,
      "learning_rate": 0.013296067411414786,
      "loss": 2.3879,
      "step": 539520
    },
    {
      "epoch": 867.43,
      "learning_rate": 0.013292851980546628,
      "loss": 2.3928,
      "step": 539540
    },
    {
      "epoch": 867.46,
      "learning_rate": 0.013289636549678458,
      "loss": 2.3977,
      "step": 539560
    },
    {
      "epoch": 867.49,
      "learning_rate": 0.013286421118810288,
      "loss": 2.3911,
      "step": 539580
    },
    {
      "epoch": 867.52,
      "learning_rate": 0.013283205687942121,
      "loss": 2.3769,
      "step": 539600
    },
    {
      "epoch": 867.56,
      "learning_rate": 0.01327999025707395,
      "loss": 2.3933,
      "step": 539620
    },
    {
      "epoch": 867.59,
      "learning_rate": 0.013276774826205782,
      "loss": 2.4079,
      "step": 539640
    },
    {
      "epoch": 867.62,
      "learning_rate": 0.013273559395337623,
      "loss": 2.3787,
      "step": 539660
    },
    {
      "epoch": 867.65,
      "learning_rate": 0.013270343964469453,
      "loss": 2.3777,
      "step": 539680
    },
    {
      "epoch": 867.68,
      "learning_rate": 0.013267128533601286,
      "loss": 2.3882,
      "step": 539700
    },
    {
      "epoch": 867.72,
      "learning_rate": 0.013263913102733116,
      "loss": 2.3833,
      "step": 539720
    },
    {
      "epoch": 867.75,
      "learning_rate": 0.013260697671864947,
      "loss": 2.3638,
      "step": 539740
    },
    {
      "epoch": 867.78,
      "learning_rate": 0.013257482240996788,
      "loss": 2.3859,
      "step": 539760
    },
    {
      "epoch": 867.81,
      "learning_rate": 0.013254266810128621,
      "loss": 2.3737,
      "step": 539780
    },
    {
      "epoch": 867.85,
      "learning_rate": 0.013251051379260451,
      "loss": 2.3865,
      "step": 539800
    },
    {
      "epoch": 867.88,
      "learning_rate": 0.01324783594839228,
      "loss": 2.3846,
      "step": 539820
    },
    {
      "epoch": 867.91,
      "learning_rate": 0.013244620517524112,
      "loss": 2.3729,
      "step": 539840
    },
    {
      "epoch": 867.94,
      "learning_rate": 0.013241405086655944,
      "loss": 2.3891,
      "step": 539860
    },
    {
      "epoch": 867.97,
      "learning_rate": 0.013238189655787786,
      "loss": 2.3997,
      "step": 539880
    },
    {
      "epoch": 868.0,
      "eval_accuracy": {
        "accuracy": 0.46256705278706367
      },
      "eval_loss": 2.506908655166626,
      "eval_runtime": 3.1692,
      "eval_samples_per_second": 4058.732,
      "eval_steps_per_second": 63.423,
      "step": 539896
    },
    {
      "epoch": 868.01,
      "learning_rate": 0.013234974224919616,
      "loss": 2.3834,
      "step": 539900
    },
    {
      "epoch": 868.04,
      "learning_rate": 0.013231758794051446,
      "loss": 2.3846,
      "step": 539920
    },
    {
      "epoch": 868.07,
      "learning_rate": 0.013228543363183277,
      "loss": 2.3825,
      "step": 539940
    },
    {
      "epoch": 868.1,
      "learning_rate": 0.013225327932315109,
      "loss": 2.3915,
      "step": 539960
    },
    {
      "epoch": 868.14,
      "learning_rate": 0.01322211250144694,
      "loss": 2.3904,
      "step": 539980
    },
    {
      "epoch": 868.17,
      "learning_rate": 0.013218897070578781,
      "loss": 2.3959,
      "step": 540000
    },
    {
      "epoch": 868.2,
      "learning_rate": 0.01321568163971061,
      "loss": 2.368,
      "step": 540020
    },
    {
      "epoch": 868.23,
      "learning_rate": 0.013212466208842444,
      "loss": 2.3922,
      "step": 540040
    },
    {
      "epoch": 868.26,
      "learning_rate": 0.013209250777974274,
      "loss": 2.3872,
      "step": 540060
    },
    {
      "epoch": 868.3,
      "learning_rate": 0.013206035347106106,
      "loss": 2.3795,
      "step": 540080
    },
    {
      "epoch": 868.33,
      "learning_rate": 0.013202819916237946,
      "loss": 2.3682,
      "step": 540100
    },
    {
      "epoch": 868.36,
      "learning_rate": 0.013199604485369776,
      "loss": 2.3825,
      "step": 540120
    },
    {
      "epoch": 868.39,
      "learning_rate": 0.01319638905450161,
      "loss": 2.3853,
      "step": 540140
    },
    {
      "epoch": 868.42,
      "learning_rate": 0.013193173623633439,
      "loss": 2.3721,
      "step": 540160
    },
    {
      "epoch": 868.46,
      "learning_rate": 0.01318995819276527,
      "loss": 2.3773,
      "step": 540180
    },
    {
      "epoch": 868.49,
      "learning_rate": 0.0131867427618971,
      "loss": 2.3877,
      "step": 540200
    },
    {
      "epoch": 868.52,
      "learning_rate": 0.01318352733102894,
      "loss": 2.3669,
      "step": 540220
    },
    {
      "epoch": 868.55,
      "learning_rate": 0.013180311900160774,
      "loss": 2.3859,
      "step": 540240
    },
    {
      "epoch": 868.59,
      "learning_rate": 0.013177096469292604,
      "loss": 2.3934,
      "step": 540260
    },
    {
      "epoch": 868.62,
      "learning_rate": 0.013173881038424436,
      "loss": 2.3697,
      "step": 540280
    },
    {
      "epoch": 868.65,
      "learning_rate": 0.013170665607556266,
      "loss": 2.369,
      "step": 540300
    },
    {
      "epoch": 868.68,
      "learning_rate": 0.013167450176688099,
      "loss": 2.3677,
      "step": 540320
    },
    {
      "epoch": 868.71,
      "learning_rate": 0.01316423474581994,
      "loss": 2.3995,
      "step": 540340
    },
    {
      "epoch": 868.75,
      "learning_rate": 0.013161019314951769,
      "loss": 2.3913,
      "step": 540360
    },
    {
      "epoch": 868.78,
      "learning_rate": 0.0131578038840836,
      "loss": 2.3815,
      "step": 540380
    },
    {
      "epoch": 868.81,
      "learning_rate": 0.013154588453215432,
      "loss": 2.3864,
      "step": 540400
    },
    {
      "epoch": 868.84,
      "learning_rate": 0.013151373022347264,
      "loss": 2.3947,
      "step": 540420
    },
    {
      "epoch": 868.87,
      "learning_rate": 0.013148157591479104,
      "loss": 2.3675,
      "step": 540440
    },
    {
      "epoch": 868.91,
      "learning_rate": 0.013144942160610934,
      "loss": 2.3925,
      "step": 540460
    },
    {
      "epoch": 868.94,
      "learning_rate": 0.013141726729742766,
      "loss": 2.3772,
      "step": 540480
    },
    {
      "epoch": 868.97,
      "learning_rate": 0.013138511298874597,
      "loss": 2.3989,
      "step": 540500
    },
    {
      "epoch": 869.0,
      "eval_accuracy": {
        "accuracy": 0.466920625048589
      },
      "eval_loss": 2.4912126064300537,
      "eval_runtime": 3.1036,
      "eval_samples_per_second": 4144.494,
      "eval_steps_per_second": 64.763,
      "step": 540518
    },
    {
      "epoch": 869.0,
      "learning_rate": 0.013135295868006429,
      "loss": 2.3733,
      "step": 540520
    },
    {
      "epoch": 869.04,
      "learning_rate": 0.013132080437138259,
      "loss": 2.3752,
      "step": 540540
    },
    {
      "epoch": 869.07,
      "learning_rate": 0.013128865006270099,
      "loss": 2.3736,
      "step": 540560
    },
    {
      "epoch": 869.1,
      "learning_rate": 0.01312564957540193,
      "loss": 2.3721,
      "step": 540580
    },
    {
      "epoch": 869.13,
      "learning_rate": 0.013122434144533762,
      "loss": 2.3884,
      "step": 540600
    },
    {
      "epoch": 869.16,
      "learning_rate": 0.013119218713665594,
      "loss": 2.3921,
      "step": 540620
    },
    {
      "epoch": 869.2,
      "learning_rate": 0.013116003282797424,
      "loss": 2.3794,
      "step": 540640
    },
    {
      "epoch": 869.23,
      "learning_rate": 0.013112787851929264,
      "loss": 2.3787,
      "step": 540660
    },
    {
      "epoch": 869.26,
      "learning_rate": 0.013109572421061097,
      "loss": 2.3613,
      "step": 540680
    },
    {
      "epoch": 869.29,
      "learning_rate": 0.013106356990192927,
      "loss": 2.3912,
      "step": 540700
    },
    {
      "epoch": 869.32,
      "learning_rate": 0.013103141559324759,
      "loss": 2.384,
      "step": 540720
    },
    {
      "epoch": 869.36,
      "learning_rate": 0.013099926128456589,
      "loss": 2.3862,
      "step": 540740
    },
    {
      "epoch": 869.39,
      "learning_rate": 0.013096710697588422,
      "loss": 2.3827,
      "step": 540760
    },
    {
      "epoch": 869.42,
      "learning_rate": 0.013093495266720262,
      "loss": 2.3629,
      "step": 540780
    },
    {
      "epoch": 869.45,
      "learning_rate": 0.013090279835852092,
      "loss": 2.3788,
      "step": 540800
    },
    {
      "epoch": 869.49,
      "learning_rate": 0.013087064404983924,
      "loss": 2.3743,
      "step": 540820
    },
    {
      "epoch": 869.52,
      "learning_rate": 0.013083848974115754,
      "loss": 2.3797,
      "step": 540840
    },
    {
      "epoch": 869.55,
      "learning_rate": 0.013080633543247587,
      "loss": 2.3825,
      "step": 540860
    },
    {
      "epoch": 869.58,
      "learning_rate": 0.013077418112379413,
      "loss": 2.3954,
      "step": 540880
    },
    {
      "epoch": 869.61,
      "learning_rate": 0.013074202681511257,
      "loss": 2.3628,
      "step": 540900
    },
    {
      "epoch": 869.65,
      "learning_rate": 0.013070987250643089,
      "loss": 2.3992,
      "step": 540920
    },
    {
      "epoch": 869.68,
      "learning_rate": 0.01306777181977492,
      "loss": 2.3992,
      "step": 540940
    },
    {
      "epoch": 869.71,
      "learning_rate": 0.013064556388906752,
      "loss": 2.3862,
      "step": 540960
    },
    {
      "epoch": 869.74,
      "learning_rate": 0.013061340958038582,
      "loss": 2.3855,
      "step": 540980
    },
    {
      "epoch": 869.77,
      "learning_rate": 0.013058125527170422,
      "loss": 2.3954,
      "step": 541000
    },
    {
      "epoch": 869.81,
      "learning_rate": 0.013054910096302254,
      "loss": 2.3788,
      "step": 541020
    },
    {
      "epoch": 869.84,
      "learning_rate": 0.013051694665434085,
      "loss": 2.391,
      "step": 541040
    },
    {
      "epoch": 869.87,
      "learning_rate": 0.013048479234565917,
      "loss": 2.3807,
      "step": 541060
    },
    {
      "epoch": 869.9,
      "learning_rate": 0.013045263803697747,
      "loss": 2.387,
      "step": 541080
    },
    {
      "epoch": 869.94,
      "learning_rate": 0.013042048372829577,
      "loss": 2.4047,
      "step": 541100
    },
    {
      "epoch": 869.97,
      "learning_rate": 0.013038832941961419,
      "loss": 2.368,
      "step": 541120
    },
    {
      "epoch": 870.0,
      "learning_rate": 0.01303561751109325,
      "loss": 2.3808,
      "step": 541140
    },
    {
      "epoch": 870.0,
      "eval_accuracy": {
        "accuracy": 0.46762030630490553
      },
      "eval_loss": 2.492159366607666,
      "eval_runtime": 3.3281,
      "eval_samples_per_second": 3864.965,
      "eval_steps_per_second": 60.395,
      "step": 541140
    },
    {
      "epoch": 870.03,
      "learning_rate": 0.013032402080225082,
      "loss": 2.3954,
      "step": 541160
    },
    {
      "epoch": 870.06,
      "learning_rate": 0.013029186649356912,
      "loss": 2.3616,
      "step": 541180
    },
    {
      "epoch": 870.1,
      "learning_rate": 0.013025971218488742,
      "loss": 2.3723,
      "step": 541200
    },
    {
      "epoch": 870.13,
      "learning_rate": 0.013022755787620572,
      "loss": 2.3783,
      "step": 541220
    },
    {
      "epoch": 870.16,
      "learning_rate": 0.013019540356752415,
      "loss": 2.3933,
      "step": 541240
    },
    {
      "epoch": 870.19,
      "learning_rate": 0.013016324925884247,
      "loss": 2.3678,
      "step": 541260
    },
    {
      "epoch": 870.23,
      "learning_rate": 0.013013109495016077,
      "loss": 2.3836,
      "step": 541280
    },
    {
      "epoch": 870.26,
      "learning_rate": 0.01300989406414791,
      "loss": 2.3755,
      "step": 541300
    },
    {
      "epoch": 870.29,
      "learning_rate": 0.013006678633279737,
      "loss": 2.3893,
      "step": 541320
    },
    {
      "epoch": 870.32,
      "learning_rate": 0.01300346320241158,
      "loss": 2.3802,
      "step": 541340
    },
    {
      "epoch": 870.35,
      "learning_rate": 0.013000247771543412,
      "loss": 2.3931,
      "step": 541360
    },
    {
      "epoch": 870.39,
      "learning_rate": 0.012997032340675242,
      "loss": 2.3692,
      "step": 541380
    },
    {
      "epoch": 870.42,
      "learning_rate": 0.012993816909807075,
      "loss": 2.3749,
      "step": 541400
    },
    {
      "epoch": 870.45,
      "learning_rate": 0.012990601478938902,
      "loss": 2.386,
      "step": 541420
    },
    {
      "epoch": 870.48,
      "learning_rate": 0.012987386048070735,
      "loss": 2.3911,
      "step": 541440
    },
    {
      "epoch": 870.51,
      "learning_rate": 0.012984331388745976,
      "loss": 2.3736,
      "step": 541460
    },
    {
      "epoch": 870.55,
      "learning_rate": 0.012981115957877818,
      "loss": 2.3867,
      "step": 541480
    },
    {
      "epoch": 870.58,
      "learning_rate": 0.012977900527009652,
      "loss": 2.38,
      "step": 541500
    },
    {
      "epoch": 870.61,
      "learning_rate": 0.012974685096141478,
      "loss": 2.3904,
      "step": 541520
    },
    {
      "epoch": 870.64,
      "learning_rate": 0.012971469665273311,
      "loss": 2.3785,
      "step": 541540
    },
    {
      "epoch": 870.68,
      "learning_rate": 0.012968254234405141,
      "loss": 2.3837,
      "step": 541560
    },
    {
      "epoch": 870.71,
      "learning_rate": 0.012965038803536971,
      "loss": 2.3965,
      "step": 541580
    },
    {
      "epoch": 870.74,
      "learning_rate": 0.012961823372668817,
      "loss": 2.3968,
      "step": 541600
    },
    {
      "epoch": 870.77,
      "learning_rate": 0.012958607941800643,
      "loss": 2.3794,
      "step": 541620
    },
    {
      "epoch": 870.8,
      "learning_rate": 0.012955392510932476,
      "loss": 2.3915,
      "step": 541640
    },
    {
      "epoch": 870.84,
      "learning_rate": 0.012952177080064306,
      "loss": 2.3921,
      "step": 541660
    },
    {
      "epoch": 870.87,
      "learning_rate": 0.012948961649196136,
      "loss": 2.3812,
      "step": 541680
    },
    {
      "epoch": 870.9,
      "learning_rate": 0.01294574621832797,
      "loss": 2.3799,
      "step": 541700
    },
    {
      "epoch": 870.93,
      "learning_rate": 0.012942530787459812,
      "loss": 2.3837,
      "step": 541720
    },
    {
      "epoch": 870.96,
      "learning_rate": 0.012939315356591641,
      "loss": 2.37,
      "step": 541740
    },
    {
      "epoch": 871.0,
      "learning_rate": 0.012936099925723471,
      "loss": 2.3968,
      "step": 541760
    },
    {
      "epoch": 871.0,
      "eval_accuracy": {
        "accuracy": 0.466920625048589
      },
      "eval_loss": 2.495999813079834,
      "eval_runtime": 3.0528,
      "eval_samples_per_second": 4213.562,
      "eval_steps_per_second": 65.842,
      "step": 541762
    },
    {
      "epoch": 871.03,
      "learning_rate": 0.012932884494855301,
      "loss": 2.3737,
      "step": 541780
    },
    {
      "epoch": 871.06,
      "learning_rate": 0.012929669063987135,
      "loss": 2.3864,
      "step": 541800
    },
    {
      "epoch": 871.09,
      "learning_rate": 0.012926453633118977,
      "loss": 2.3993,
      "step": 541820
    },
    {
      "epoch": 871.13,
      "learning_rate": 0.012923238202250806,
      "loss": 2.3823,
      "step": 541840
    },
    {
      "epoch": 871.16,
      "learning_rate": 0.012920022771382636,
      "loss": 2.3863,
      "step": 541860
    },
    {
      "epoch": 871.19,
      "learning_rate": 0.012916807340514466,
      "loss": 2.3845,
      "step": 541880
    },
    {
      "epoch": 871.22,
      "learning_rate": 0.0129135919096463,
      "loss": 2.3515,
      "step": 541900
    },
    {
      "epoch": 871.25,
      "learning_rate": 0.01291037647877813,
      "loss": 2.3706,
      "step": 541920
    },
    {
      "epoch": 871.29,
      "learning_rate": 0.012907161047909971,
      "loss": 2.3701,
      "step": 541940
    },
    {
      "epoch": 871.32,
      "learning_rate": 0.012903945617041801,
      "loss": 2.3833,
      "step": 541960
    },
    {
      "epoch": 871.35,
      "learning_rate": 0.012900730186173635,
      "loss": 2.3868,
      "step": 541980
    },
    {
      "epoch": 871.38,
      "learning_rate": 0.012897514755305465,
      "loss": 2.371,
      "step": 542000
    },
    {
      "epoch": 871.41,
      "learning_rate": 0.012894299324437294,
      "loss": 2.3832,
      "step": 542020
    },
    {
      "epoch": 871.45,
      "learning_rate": 0.012891083893569126,
      "loss": 2.3666,
      "step": 542040
    },
    {
      "epoch": 871.48,
      "learning_rate": 0.012887868462700966,
      "loss": 2.3797,
      "step": 542060
    },
    {
      "epoch": 871.51,
      "learning_rate": 0.0128846530318328,
      "loss": 2.3592,
      "step": 542080
    },
    {
      "epoch": 871.54,
      "learning_rate": 0.01288143760096463,
      "loss": 2.3932,
      "step": 542100
    },
    {
      "epoch": 871.58,
      "learning_rate": 0.01287822217009646,
      "loss": 2.3895,
      "step": 542120
    },
    {
      "epoch": 871.61,
      "learning_rate": 0.012875006739228291,
      "loss": 2.396,
      "step": 542140
    },
    {
      "epoch": 871.64,
      "learning_rate": 0.012871791308360131,
      "loss": 2.3807,
      "step": 542160
    },
    {
      "epoch": 871.67,
      "learning_rate": 0.012868575877491965,
      "loss": 2.3815,
      "step": 542180
    },
    {
      "epoch": 871.7,
      "learning_rate": 0.012865360446623795,
      "loss": 2.3788,
      "step": 542200
    },
    {
      "epoch": 871.74,
      "learning_rate": 0.012862145015755624,
      "loss": 2.3726,
      "step": 542220
    },
    {
      "epoch": 871.77,
      "learning_rate": 0.012858929584887458,
      "loss": 2.3727,
      "step": 542240
    },
    {
      "epoch": 871.8,
      "learning_rate": 0.012855714154019288,
      "loss": 2.3727,
      "step": 542260
    },
    {
      "epoch": 871.83,
      "learning_rate": 0.01285249872315113,
      "loss": 2.3877,
      "step": 542280
    },
    {
      "epoch": 871.86,
      "learning_rate": 0.01284928329228296,
      "loss": 2.3895,
      "step": 542300
    },
    {
      "epoch": 871.9,
      "learning_rate": 0.01284606786141479,
      "loss": 2.3866,
      "step": 542320
    },
    {
      "epoch": 871.93,
      "learning_rate": 0.012842852430546623,
      "loss": 2.3876,
      "step": 542340
    },
    {
      "epoch": 871.96,
      "learning_rate": 0.012839636999678453,
      "loss": 2.3989,
      "step": 542360
    },
    {
      "epoch": 871.99,
      "learning_rate": 0.012836421568810284,
      "loss": 2.378,
      "step": 542380
    },
    {
      "epoch": 872.0,
      "eval_accuracy": {
        "accuracy": 0.4659099743450206
      },
      "eval_loss": 2.488546848297119,
      "eval_runtime": 3.3956,
      "eval_samples_per_second": 3788.18,
      "eval_steps_per_second": 59.195,
      "step": 542384
    },
    {
      "epoch": 872.03,
      "learning_rate": 0.012833206137942125,
      "loss": 2.4077,
      "step": 542400
    },
    {
      "epoch": 872.06,
      "learning_rate": 0.012829990707073954,
      "loss": 2.3671,
      "step": 542420
    },
    {
      "epoch": 872.09,
      "learning_rate": 0.012826775276205788,
      "loss": 2.3676,
      "step": 542440
    },
    {
      "epoch": 872.12,
      "learning_rate": 0.01282372061688103,
      "loss": 2.3864,
      "step": 542460
    },
    {
      "epoch": 872.15,
      "learning_rate": 0.01282050518601286,
      "loss": 2.3932,
      "step": 542480
    },
    {
      "epoch": 872.19,
      "learning_rate": 0.01281728975514469,
      "loss": 2.3897,
      "step": 542500
    },
    {
      "epoch": 872.22,
      "learning_rate": 0.012814074324276524,
      "loss": 2.3513,
      "step": 542520
    },
    {
      "epoch": 872.25,
      "learning_rate": 0.012810858893408364,
      "loss": 2.3853,
      "step": 542540
    },
    {
      "epoch": 872.28,
      "learning_rate": 0.012807643462540194,
      "loss": 2.3652,
      "step": 542560
    },
    {
      "epoch": 872.32,
      "learning_rate": 0.012804428031672026,
      "loss": 2.3896,
      "step": 542580
    },
    {
      "epoch": 872.35,
      "learning_rate": 0.012801212600803856,
      "loss": 2.391,
      "step": 542600
    },
    {
      "epoch": 872.38,
      "learning_rate": 0.012797997169935689,
      "loss": 2.3604,
      "step": 542620
    },
    {
      "epoch": 872.41,
      "learning_rate": 0.01279478173906753,
      "loss": 2.4008,
      "step": 542640
    },
    {
      "epoch": 872.44,
      "learning_rate": 0.01279156630819936,
      "loss": 2.3687,
      "step": 542660
    },
    {
      "epoch": 872.48,
      "learning_rate": 0.01278835087733119,
      "loss": 2.3742,
      "step": 542680
    },
    {
      "epoch": 872.51,
      "learning_rate": 0.012785135446463022,
      "loss": 2.3837,
      "step": 542700
    },
    {
      "epoch": 872.54,
      "learning_rate": 0.012781920015594854,
      "loss": 2.4064,
      "step": 542720
    },
    {
      "epoch": 872.57,
      "learning_rate": 0.012778704584726684,
      "loss": 2.3858,
      "step": 542740
    },
    {
      "epoch": 872.6,
      "learning_rate": 0.012775489153858524,
      "loss": 2.3838,
      "step": 542760
    },
    {
      "epoch": 872.64,
      "learning_rate": 0.012772273722990356,
      "loss": 2.3756,
      "step": 542780
    },
    {
      "epoch": 872.67,
      "learning_rate": 0.012769058292122187,
      "loss": 2.3808,
      "step": 542800
    },
    {
      "epoch": 872.7,
      "learning_rate": 0.012765842861254019,
      "loss": 2.3765,
      "step": 542820
    },
    {
      "epoch": 872.73,
      "learning_rate": 0.012762627430385849,
      "loss": 2.3945,
      "step": 542840
    },
    {
      "epoch": 872.77,
      "learning_rate": 0.012759411999517679,
      "loss": 2.3702,
      "step": 542860
    },
    {
      "epoch": 872.8,
      "learning_rate": 0.01275619656864952,
      "loss": 2.3774,
      "step": 542880
    },
    {
      "epoch": 872.83,
      "learning_rate": 0.012752981137781352,
      "loss": 2.3713,
      "step": 542900
    },
    {
      "epoch": 872.86,
      "learning_rate": 0.012749765706913184,
      "loss": 2.3725,
      "step": 542920
    },
    {
      "epoch": 872.89,
      "learning_rate": 0.012746550276045014,
      "loss": 2.3962,
      "step": 542940
    },
    {
      "epoch": 872.93,
      "learning_rate": 0.012743334845176847,
      "loss": 2.37,
      "step": 542960
    },
    {
      "epoch": 872.96,
      "learning_rate": 0.012740119414308687,
      "loss": 2.3861,
      "step": 542980
    },
    {
      "epoch": 872.99,
      "learning_rate": 0.012736903983440517,
      "loss": 2.3585,
      "step": 543000
    },
    {
      "epoch": 873.0,
      "eval_accuracy": {
        "accuracy": 0.46730933685765375
      },
      "eval_loss": 2.494063138961792,
      "eval_runtime": 3.3836,
      "eval_samples_per_second": 3801.627,
      "eval_steps_per_second": 59.405,
      "step": 543006
    },
    {
      "epoch": 873.02,
      "learning_rate": 0.012733688552572349,
      "loss": 2.3584,
      "step": 543020
    },
    {
      "epoch": 873.05,
      "learning_rate": 0.012730473121704179,
      "loss": 2.386,
      "step": 543040
    },
    {
      "epoch": 873.09,
      "learning_rate": 0.012727257690836012,
      "loss": 2.3736,
      "step": 543060
    },
    {
      "epoch": 873.12,
      "learning_rate": 0.012724042259967839,
      "loss": 2.3913,
      "step": 543080
    },
    {
      "epoch": 873.15,
      "learning_rate": 0.012720826829099682,
      "loss": 2.386,
      "step": 543100
    },
    {
      "epoch": 873.18,
      "learning_rate": 0.012717611398231514,
      "loss": 2.3767,
      "step": 543120
    },
    {
      "epoch": 873.22,
      "learning_rate": 0.012714395967363344,
      "loss": 2.3833,
      "step": 543140
    },
    {
      "epoch": 873.25,
      "learning_rate": 0.012711180536495177,
      "loss": 2.3679,
      "step": 543160
    },
    {
      "epoch": 873.28,
      "learning_rate": 0.012707965105627004,
      "loss": 2.3754,
      "step": 543180
    },
    {
      "epoch": 873.31,
      "learning_rate": 0.012704749674758837,
      "loss": 2.358,
      "step": 543200
    },
    {
      "epoch": 873.34,
      "learning_rate": 0.012701534243890679,
      "loss": 2.3781,
      "step": 543220
    },
    {
      "epoch": 873.38,
      "learning_rate": 0.012698318813022509,
      "loss": 2.3766,
      "step": 543240
    },
    {
      "epoch": 873.41,
      "learning_rate": 0.012695103382154342,
      "loss": 2.38,
      "step": 543260
    },
    {
      "epoch": 873.44,
      "learning_rate": 0.012691887951286172,
      "loss": 2.3538,
      "step": 543280
    },
    {
      "epoch": 873.47,
      "learning_rate": 0.012688672520418002,
      "loss": 2.3778,
      "step": 543300
    },
    {
      "epoch": 873.5,
      "learning_rate": 0.012685457089549844,
      "loss": 2.3702,
      "step": 543320
    },
    {
      "epoch": 873.54,
      "learning_rate": 0.012682241658681676,
      "loss": 2.3886,
      "step": 543340
    },
    {
      "epoch": 873.57,
      "learning_rate": 0.012679026227813507,
      "loss": 2.3793,
      "step": 543360
    },
    {
      "epoch": 873.6,
      "learning_rate": 0.012675810796945337,
      "loss": 2.3966,
      "step": 543380
    },
    {
      "epoch": 873.63,
      "learning_rate": 0.012672595366077167,
      "loss": 2.3901,
      "step": 543400
    },
    {
      "epoch": 873.67,
      "learning_rate": 0.012669379935208997,
      "loss": 2.3712,
      "step": 543420
    },
    {
      "epoch": 873.7,
      "learning_rate": 0.01266616450434084,
      "loss": 2.3836,
      "step": 543440
    },
    {
      "epoch": 873.73,
      "learning_rate": 0.012662949073472672,
      "loss": 2.388,
      "step": 543460
    },
    {
      "epoch": 873.76,
      "learning_rate": 0.012659733642604502,
      "loss": 2.3877,
      "step": 543480
    },
    {
      "epoch": 873.79,
      "learning_rate": 0.012656518211736332,
      "loss": 2.3658,
      "step": 543500
    },
    {
      "epoch": 873.83,
      "learning_rate": 0.012653302780868162,
      "loss": 2.3833,
      "step": 543520
    },
    {
      "epoch": 873.86,
      "learning_rate": 0.012650087349999995,
      "loss": 2.3873,
      "step": 543540
    },
    {
      "epoch": 873.89,
      "learning_rate": 0.012646871919131837,
      "loss": 2.3507,
      "step": 543560
    },
    {
      "epoch": 873.92,
      "learning_rate": 0.012643656488263667,
      "loss": 2.3813,
      "step": 543580
    },
    {
      "epoch": 873.95,
      "learning_rate": 0.0126404410573955,
      "loss": 2.3841,
      "step": 543600
    },
    {
      "epoch": 873.99,
      "learning_rate": 0.012637225626527327,
      "loss": 2.3865,
      "step": 543620
    },
    {
      "epoch": 874.0,
      "eval_accuracy": {
        "accuracy": 0.46940838062660345
      },
      "eval_loss": 2.488450765609741,
      "eval_runtime": 3.7275,
      "eval_samples_per_second": 3450.798,
      "eval_steps_per_second": 53.923,
      "step": 543628
    },
    {
      "epoch": 874.02,
      "learning_rate": 0.01263401019565916,
      "loss": 2.3687,
      "step": 543640
    },
    {
      "epoch": 874.05,
      "learning_rate": 0.012630794764791002,
      "loss": 2.3657,
      "step": 543660
    },
    {
      "epoch": 874.08,
      "learning_rate": 0.012627579333922832,
      "loss": 2.398,
      "step": 543680
    },
    {
      "epoch": 874.12,
      "learning_rate": 0.012624363903054665,
      "loss": 2.3833,
      "step": 543700
    },
    {
      "epoch": 874.15,
      "learning_rate": 0.012621148472186492,
      "loss": 2.3771,
      "step": 543720
    },
    {
      "epoch": 874.18,
      "learning_rate": 0.012617933041318325,
      "loss": 2.3654,
      "step": 543740
    },
    {
      "epoch": 874.21,
      "learning_rate": 0.012614717610450155,
      "loss": 2.3736,
      "step": 543760
    },
    {
      "epoch": 874.24,
      "learning_rate": 0.012611502179581997,
      "loss": 2.3552,
      "step": 543780
    },
    {
      "epoch": 874.28,
      "learning_rate": 0.01260828674871383,
      "loss": 2.3765,
      "step": 543800
    },
    {
      "epoch": 874.31,
      "learning_rate": 0.012605071317845657,
      "loss": 2.3683,
      "step": 543820
    },
    {
      "epoch": 874.34,
      "learning_rate": 0.01260185588697749,
      "loss": 2.3843,
      "step": 543840
    },
    {
      "epoch": 874.37,
      "learning_rate": 0.01259864045610932,
      "loss": 2.3988,
      "step": 543860
    },
    {
      "epoch": 874.41,
      "learning_rate": 0.01259542502524115,
      "loss": 2.3642,
      "step": 543880
    },
    {
      "epoch": 874.44,
      "learning_rate": 0.012592209594372995,
      "loss": 2.3631,
      "step": 543900
    },
    {
      "epoch": 874.47,
      "learning_rate": 0.012588994163504825,
      "loss": 2.3945,
      "step": 543920
    },
    {
      "epoch": 874.5,
      "learning_rate": 0.012585778732636655,
      "loss": 2.3877,
      "step": 543940
    },
    {
      "epoch": 874.53,
      "learning_rate": 0.012582563301768485,
      "loss": 2.3808,
      "step": 543960
    },
    {
      "epoch": 874.57,
      "learning_rate": 0.012579347870900315,
      "loss": 2.3792,
      "step": 543980
    },
    {
      "epoch": 874.6,
      "learning_rate": 0.01257613244003216,
      "loss": 2.3731,
      "step": 544000
    },
    {
      "epoch": 874.63,
      "learning_rate": 0.01257291700916399,
      "loss": 2.3861,
      "step": 544020
    },
    {
      "epoch": 874.66,
      "learning_rate": 0.01256970157829582,
      "loss": 2.3669,
      "step": 544040
    },
    {
      "epoch": 874.69,
      "learning_rate": 0.01256648614742765,
      "loss": 2.4045,
      "step": 544060
    },
    {
      "epoch": 874.73,
      "learning_rate": 0.01256327071655948,
      "loss": 2.3806,
      "step": 544080
    },
    {
      "epoch": 874.76,
      "learning_rate": 0.012560055285691313,
      "loss": 2.3782,
      "step": 544100
    },
    {
      "epoch": 874.79,
      "learning_rate": 0.012556839854823155,
      "loss": 2.3705,
      "step": 544120
    },
    {
      "epoch": 874.82,
      "learning_rate": 0.012553624423954985,
      "loss": 2.3884,
      "step": 544140
    },
    {
      "epoch": 874.86,
      "learning_rate": 0.012550408993086815,
      "loss": 2.3736,
      "step": 544160
    },
    {
      "epoch": 874.89,
      "learning_rate": 0.012547193562218648,
      "loss": 2.3639,
      "step": 544180
    },
    {
      "epoch": 874.92,
      "learning_rate": 0.012543978131350478,
      "loss": 2.3953,
      "step": 544200
    },
    {
      "epoch": 874.95,
      "learning_rate": 0.01254076270048232,
      "loss": 2.3918,
      "step": 544220
    },
    {
      "epoch": 874.98,
      "learning_rate": 0.012537547269614154,
      "loss": 2.3871,
      "step": 544240
    },
    {
      "epoch": 875.0,
      "eval_accuracy": {
        "accuracy": 0.4666873979631501
      },
      "eval_loss": 2.496631383895874,
      "eval_runtime": 3.1437,
      "eval_samples_per_second": 4091.679,
      "eval_steps_per_second": 63.937,
      "step": 544250
    },
    {
      "epoch": 875.02,
      "learning_rate": 0.01253433183874598,
      "loss": 2.3795,
      "step": 544260
    },
    {
      "epoch": 875.05,
      "learning_rate": 0.012531116407877813,
      "loss": 2.3805,
      "step": 544280
    },
    {
      "epoch": 875.08,
      "learning_rate": 0.012527900977009643,
      "loss": 2.3826,
      "step": 544300
    },
    {
      "epoch": 875.11,
      "learning_rate": 0.012524685546141473,
      "loss": 2.3829,
      "step": 544320
    },
    {
      "epoch": 875.14,
      "learning_rate": 0.012521470115273318,
      "loss": 2.3765,
      "step": 544340
    },
    {
      "epoch": 875.18,
      "learning_rate": 0.012518254684405145,
      "loss": 2.3729,
      "step": 544360
    },
    {
      "epoch": 875.21,
      "learning_rate": 0.012515039253536978,
      "loss": 2.3783,
      "step": 544380
    },
    {
      "epoch": 875.24,
      "learning_rate": 0.012511823822668808,
      "loss": 2.3867,
      "step": 544400
    },
    {
      "epoch": 875.27,
      "learning_rate": 0.012508608391800638,
      "loss": 2.3869,
      "step": 544420
    },
    {
      "epoch": 875.31,
      "learning_rate": 0.012505392960932471,
      "loss": 2.3488,
      "step": 544440
    },
    {
      "epoch": 875.34,
      "learning_rate": 0.01250217753006431,
      "loss": 2.3837,
      "step": 544460
    },
    {
      "epoch": 875.37,
      "learning_rate": 0.012498962099196143,
      "loss": 2.3737,
      "step": 544480
    },
    {
      "epoch": 875.4,
      "learning_rate": 0.012495746668327975,
      "loss": 2.3821,
      "step": 544500
    },
    {
      "epoch": 875.43,
      "learning_rate": 0.012492531237459805,
      "loss": 2.3975,
      "step": 544520
    },
    {
      "epoch": 875.47,
      "learning_rate": 0.012489315806591636,
      "loss": 2.3715,
      "step": 544540
    },
    {
      "epoch": 875.5,
      "learning_rate": 0.012486100375723478,
      "loss": 2.3956,
      "step": 544560
    },
    {
      "epoch": 875.53,
      "learning_rate": 0.012482884944855308,
      "loss": 2.3727,
      "step": 544580
    },
    {
      "epoch": 875.56,
      "learning_rate": 0.012479830285530551,
      "loss": 2.3864,
      "step": 544600
    },
    {
      "epoch": 875.59,
      "learning_rate": 0.012476614854662381,
      "loss": 2.3784,
      "step": 544620
    },
    {
      "epoch": 875.63,
      "learning_rate": 0.012473399423794213,
      "loss": 2.3823,
      "step": 544640
    },
    {
      "epoch": 875.66,
      "learning_rate": 0.012470183992926043,
      "loss": 2.3886,
      "step": 544660
    },
    {
      "epoch": 875.69,
      "learning_rate": 0.012466968562057874,
      "loss": 2.3919,
      "step": 544680
    },
    {
      "epoch": 875.72,
      "learning_rate": 0.012463753131189716,
      "loss": 2.354,
      "step": 544700
    },
    {
      "epoch": 875.76,
      "learning_rate": 0.012460537700321546,
      "loss": 2.3802,
      "step": 544720
    },
    {
      "epoch": 875.79,
      "learning_rate": 0.012457322269453378,
      "loss": 2.3649,
      "step": 544740
    },
    {
      "epoch": 875.82,
      "learning_rate": 0.012454106838585208,
      "loss": 2.3712,
      "step": 544760
    },
    {
      "epoch": 875.85,
      "learning_rate": 0.01245089140771704,
      "loss": 2.3663,
      "step": 544780
    },
    {
      "epoch": 875.88,
      "learning_rate": 0.01244767597684887,
      "loss": 2.3703,
      "step": 544800
    },
    {
      "epoch": 875.92,
      "learning_rate": 0.012444460545980711,
      "loss": 2.3645,
      "step": 544820
    },
    {
      "epoch": 875.95,
      "learning_rate": 0.012441245115112543,
      "loss": 2.3807,
      "step": 544840
    },
    {
      "epoch": 875.98,
      "learning_rate": 0.012438029684244374,
      "loss": 2.3858,
      "step": 544860
    },
    {
      "epoch": 876.0,
      "eval_accuracy": {
        "accuracy": 0.46707610977221486
      },
      "eval_loss": 2.4948441982269287,
      "eval_runtime": 3.3106,
      "eval_samples_per_second": 3885.436,
      "eval_steps_per_second": 60.715,
      "step": 544872
    },
    {
      "epoch": 876.01,
      "learning_rate": 0.012434814253376204,
      "loss": 2.3557,
      "step": 544880
    },
    {
      "epoch": 876.05,
      "learning_rate": 0.012431598822508036,
      "loss": 2.379,
      "step": 544900
    },
    {
      "epoch": 876.08,
      "learning_rate": 0.012428383391639866,
      "loss": 2.3725,
      "step": 544920
    },
    {
      "epoch": 876.11,
      "learning_rate": 0.012425167960771708,
      "loss": 2.3791,
      "step": 544940
    },
    {
      "epoch": 876.14,
      "learning_rate": 0.01242195252990354,
      "loss": 2.3814,
      "step": 544960
    },
    {
      "epoch": 876.17,
      "learning_rate": 0.01241873709903537,
      "loss": 2.3902,
      "step": 544980
    },
    {
      "epoch": 876.21,
      "learning_rate": 0.012415521668167201,
      "loss": 2.3847,
      "step": 545000
    },
    {
      "epoch": 876.24,
      "learning_rate": 0.01241230623729903,
      "loss": 2.3794,
      "step": 545020
    },
    {
      "epoch": 876.27,
      "learning_rate": 0.012409090806430873,
      "loss": 2.3603,
      "step": 545040
    },
    {
      "epoch": 876.3,
      "learning_rate": 0.012405875375562704,
      "loss": 2.3753,
      "step": 545060
    },
    {
      "epoch": 876.33,
      "learning_rate": 0.012402659944694534,
      "loss": 2.3766,
      "step": 545080
    },
    {
      "epoch": 876.37,
      "learning_rate": 0.012399444513826366,
      "loss": 2.3863,
      "step": 545100
    },
    {
      "epoch": 876.4,
      "learning_rate": 0.012396229082958196,
      "loss": 2.3817,
      "step": 545120
    },
    {
      "epoch": 876.43,
      "learning_rate": 0.012393013652090027,
      "loss": 2.3726,
      "step": 545140
    },
    {
      "epoch": 876.46,
      "learning_rate": 0.01238979822122187,
      "loss": 2.358,
      "step": 545160
    },
    {
      "epoch": 876.5,
      "learning_rate": 0.012386582790353701,
      "loss": 2.3628,
      "step": 545180
    },
    {
      "epoch": 876.53,
      "learning_rate": 0.012383367359485531,
      "loss": 2.3647,
      "step": 545200
    },
    {
      "epoch": 876.56,
      "learning_rate": 0.012380151928617363,
      "loss": 2.3715,
      "step": 545220
    },
    {
      "epoch": 876.59,
      "learning_rate": 0.012376936497749192,
      "loss": 2.3822,
      "step": 545240
    },
    {
      "epoch": 876.62,
      "learning_rate": 0.012373721066881024,
      "loss": 2.4028,
      "step": 545260
    },
    {
      "epoch": 876.66,
      "learning_rate": 0.012370505636012866,
      "loss": 2.3631,
      "step": 545280
    },
    {
      "epoch": 876.69,
      "learning_rate": 0.012367290205144696,
      "loss": 2.3877,
      "step": 545300
    },
    {
      "epoch": 876.72,
      "learning_rate": 0.012364074774276528,
      "loss": 2.3709,
      "step": 545320
    },
    {
      "epoch": 876.75,
      "learning_rate": 0.012360859343408357,
      "loss": 2.3546,
      "step": 545340
    },
    {
      "epoch": 876.78,
      "learning_rate": 0.012357643912540189,
      "loss": 2.386,
      "step": 545360
    },
    {
      "epoch": 876.82,
      "learning_rate": 0.012354428481672031,
      "loss": 2.38,
      "step": 545380
    },
    {
      "epoch": 876.85,
      "learning_rate": 0.012351213050803861,
      "loss": 2.381,
      "step": 545400
    },
    {
      "epoch": 876.88,
      "learning_rate": 0.012347997619935693,
      "loss": 2.381,
      "step": 545420
    },
    {
      "epoch": 876.91,
      "learning_rate": 0.012344782189067524,
      "loss": 2.3834,
      "step": 545440
    },
    {
      "epoch": 876.95,
      "learning_rate": 0.012341566758199354,
      "loss": 2.3709,
      "step": 545460
    },
    {
      "epoch": 876.98,
      "learning_rate": 0.012338351327331186,
      "loss": 2.3975,
      "step": 545480
    },
    {
      "epoch": 877.0,
      "eval_accuracy": {
        "accuracy": 0.46645417087771124
      },
      "eval_loss": 2.489574432373047,
      "eval_runtime": 3.2617,
      "eval_samples_per_second": 3943.597,
      "eval_steps_per_second": 61.623,
      "step": 545494
    },
    {
      "epoch": 877.01,
      "learning_rate": 0.012335135896463028,
      "loss": 2.3751,
      "step": 545500
    },
    {
      "epoch": 877.04,
      "learning_rate": 0.012331920465594857,
      "loss": 2.3633,
      "step": 545520
    },
    {
      "epoch": 877.07,
      "learning_rate": 0.012328705034726689,
      "loss": 2.3745,
      "step": 545540
    },
    {
      "epoch": 877.11,
      "learning_rate": 0.012325489603858519,
      "loss": 2.3768,
      "step": 545560
    },
    {
      "epoch": 877.14,
      "learning_rate": 0.01232227417299035,
      "loss": 2.3827,
      "step": 545580
    },
    {
      "epoch": 877.17,
      "learning_rate": 0.01231905874212218,
      "loss": 2.3932,
      "step": 545600
    },
    {
      "epoch": 877.2,
      "learning_rate": 0.012315843311254022,
      "loss": 2.3861,
      "step": 545620
    },
    {
      "epoch": 877.23,
      "learning_rate": 0.012312627880385854,
      "loss": 2.3769,
      "step": 545640
    },
    {
      "epoch": 877.27,
      "learning_rate": 0.012309412449517684,
      "loss": 2.3507,
      "step": 545660
    },
    {
      "epoch": 877.3,
      "learning_rate": 0.012306197018649516,
      "loss": 2.3641,
      "step": 545680
    },
    {
      "epoch": 877.33,
      "learning_rate": 0.012302981587781345,
      "loss": 2.3891,
      "step": 545700
    },
    {
      "epoch": 877.36,
      "learning_rate": 0.012299766156913187,
      "loss": 2.3657,
      "step": 545720
    },
    {
      "epoch": 877.4,
      "learning_rate": 0.012296550726045019,
      "loss": 2.391,
      "step": 545740
    },
    {
      "epoch": 877.43,
      "learning_rate": 0.01229333529517685,
      "loss": 2.3963,
      "step": 545760
    },
    {
      "epoch": 877.46,
      "learning_rate": 0.01229011986430868,
      "loss": 2.3559,
      "step": 545780
    },
    {
      "epoch": 877.49,
      "learning_rate": 0.012286904433440512,
      "loss": 2.3696,
      "step": 545800
    },
    {
      "epoch": 877.52,
      "learning_rate": 0.012283689002572342,
      "loss": 2.3715,
      "step": 545820
    },
    {
      "epoch": 877.56,
      "learning_rate": 0.012280473571704184,
      "loss": 2.3849,
      "step": 545840
    },
    {
      "epoch": 877.59,
      "learning_rate": 0.012277258140836016,
      "loss": 2.3825,
      "step": 545860
    },
    {
      "epoch": 877.62,
      "learning_rate": 0.012274042709967846,
      "loss": 2.3399,
      "step": 545880
    },
    {
      "epoch": 877.65,
      "learning_rate": 0.012270827279099677,
      "loss": 2.3677,
      "step": 545900
    },
    {
      "epoch": 877.68,
      "learning_rate": 0.012267611848231507,
      "loss": 2.3803,
      "step": 545920
    },
    {
      "epoch": 877.72,
      "learning_rate": 0.012264396417363339,
      "loss": 2.3996,
      "step": 545940
    },
    {
      "epoch": 877.75,
      "learning_rate": 0.01226118098649518,
      "loss": 2.3781,
      "step": 545960
    },
    {
      "epoch": 877.78,
      "learning_rate": 0.01225796555562701,
      "loss": 2.3624,
      "step": 545980
    },
    {
      "epoch": 877.81,
      "learning_rate": 0.012254750124758842,
      "loss": 2.3806,
      "step": 546000
    },
    {
      "epoch": 877.85,
      "learning_rate": 0.012251534693890672,
      "loss": 2.385,
      "step": 546020
    },
    {
      "epoch": 877.88,
      "learning_rate": 0.012248319263022504,
      "loss": 2.3839,
      "step": 546040
    },
    {
      "epoch": 877.91,
      "learning_rate": 0.012245103832154346,
      "loss": 2.3623,
      "step": 546060
    },
    {
      "epoch": 877.94,
      "learning_rate": 0.012241888401286177,
      "loss": 2.3611,
      "step": 546080
    },
    {
      "epoch": 877.97,
      "learning_rate": 0.012238672970418007,
      "loss": 2.3651,
      "step": 546100
    },
    {
      "epoch": 878.0,
      "eval_accuracy": {
        "accuracy": 0.46808676047578324
      },
      "eval_loss": 2.4935367107391357,
      "eval_runtime": 3.3607,
      "eval_samples_per_second": 3827.488,
      "eval_steps_per_second": 59.809,
      "step": 546116
    },
    {
      "epoch": 878.01,
      "learning_rate": 0.012235457539549839,
      "loss": 2.3744,
      "step": 546120
    },
    {
      "epoch": 878.04,
      "learning_rate": 0.012232242108681669,
      "loss": 2.3643,
      "step": 546140
    },
    {
      "epoch": 878.07,
      "learning_rate": 0.0122290266778135,
      "loss": 2.3653,
      "step": 546160
    },
    {
      "epoch": 878.1,
      "learning_rate": 0.012225811246945342,
      "loss": 2.3761,
      "step": 546180
    },
    {
      "epoch": 878.14,
      "learning_rate": 0.012222595816077172,
      "loss": 2.3667,
      "step": 546200
    },
    {
      "epoch": 878.17,
      "learning_rate": 0.012219380385209004,
      "loss": 2.3788,
      "step": 546220
    },
    {
      "epoch": 878.2,
      "learning_rate": 0.012216164954340834,
      "loss": 2.357,
      "step": 546240
    },
    {
      "epoch": 878.23,
      "learning_rate": 0.012212949523472665,
      "loss": 2.3927,
      "step": 546260
    },
    {
      "epoch": 878.26,
      "learning_rate": 0.012209734092604495,
      "loss": 2.3643,
      "step": 546280
    },
    {
      "epoch": 878.3,
      "learning_rate": 0.012206518661736337,
      "loss": 2.3708,
      "step": 546300
    },
    {
      "epoch": 878.33,
      "learning_rate": 0.012203303230868169,
      "loss": 2.397,
      "step": 546320
    },
    {
      "epoch": 878.36,
      "learning_rate": 0.012200087799999999,
      "loss": 2.3568,
      "step": 546340
    },
    {
      "epoch": 878.39,
      "learning_rate": 0.01219687236913183,
      "loss": 2.3807,
      "step": 546360
    },
    {
      "epoch": 878.42,
      "learning_rate": 0.012193656938263662,
      "loss": 2.3766,
      "step": 546380
    },
    {
      "epoch": 878.46,
      "learning_rate": 0.012190441507395504,
      "loss": 2.3533,
      "step": 546400
    },
    {
      "epoch": 878.49,
      "learning_rate": 0.012187226076527334,
      "loss": 2.3725,
      "step": 546420
    },
    {
      "epoch": 878.52,
      "learning_rate": 0.012184010645659165,
      "loss": 2.3807,
      "step": 546440
    },
    {
      "epoch": 878.55,
      "learning_rate": 0.012180795214790995,
      "loss": 2.3685,
      "step": 546460
    },
    {
      "epoch": 878.59,
      "learning_rate": 0.012177579783922827,
      "loss": 2.3841,
      "step": 546480
    },
    {
      "epoch": 878.62,
      "learning_rate": 0.012174364353054657,
      "loss": 2.3635,
      "step": 546500
    },
    {
      "epoch": 878.65,
      "learning_rate": 0.012171148922186499,
      "loss": 2.3712,
      "step": 546520
    },
    {
      "epoch": 878.68,
      "learning_rate": 0.01216793349131833,
      "loss": 2.3703,
      "step": 546540
    },
    {
      "epoch": 878.71,
      "learning_rate": 0.01216471806045016,
      "loss": 2.3762,
      "step": 546560
    },
    {
      "epoch": 878.75,
      "learning_rate": 0.012161502629581992,
      "loss": 2.3724,
      "step": 546580
    },
    {
      "epoch": 878.78,
      "learning_rate": 0.012158287198713822,
      "loss": 2.3847,
      "step": 546600
    },
    {
      "epoch": 878.81,
      "learning_rate": 0.012155071767845664,
      "loss": 2.4035,
      "step": 546620
    },
    {
      "epoch": 878.84,
      "learning_rate": 0.012151856336977495,
      "loss": 2.3738,
      "step": 546640
    },
    {
      "epoch": 878.87,
      "learning_rate": 0.012148640906109325,
      "loss": 2.3729,
      "step": 546660
    },
    {
      "epoch": 878.91,
      "learning_rate": 0.012145425475241157,
      "loss": 2.366,
      "step": 546680
    },
    {
      "epoch": 878.94,
      "learning_rate": 0.012142210044372988,
      "loss": 2.3883,
      "step": 546700
    },
    {
      "epoch": 878.97,
      "learning_rate": 0.012138994613504818,
      "loss": 2.374,
      "step": 546720
    },
    {
      "epoch": 879.0,
      "eval_accuracy": {
        "accuracy": 0.4655212625359558
      },
      "eval_loss": 2.4961416721343994,
      "eval_runtime": 3.5007,
      "eval_samples_per_second": 3674.386,
      "eval_steps_per_second": 57.417,
      "step": 546738
    },
    {
      "epoch": 879.0,
      "learning_rate": 0.01213577918263666,
      "loss": 2.3806,
      "step": 546740
    },
    {
      "epoch": 879.04,
      "learning_rate": 0.012132563751768492,
      "loss": 2.3736,
      "step": 546760
    },
    {
      "epoch": 879.07,
      "learning_rate": 0.012129348320900322,
      "loss": 2.3463,
      "step": 546780
    },
    {
      "epoch": 879.1,
      "learning_rate": 0.012126132890032153,
      "loss": 2.3565,
      "step": 546800
    },
    {
      "epoch": 879.13,
      "learning_rate": 0.012122917459163983,
      "loss": 2.3659,
      "step": 546820
    },
    {
      "epoch": 879.16,
      "learning_rate": 0.012119702028295815,
      "loss": 2.3604,
      "step": 546840
    },
    {
      "epoch": 879.2,
      "learning_rate": 0.012116486597427657,
      "loss": 2.3671,
      "step": 546860
    },
    {
      "epoch": 879.23,
      "learning_rate": 0.012113271166559487,
      "loss": 2.3692,
      "step": 546880
    },
    {
      "epoch": 879.26,
      "learning_rate": 0.012110055735691318,
      "loss": 2.3543,
      "step": 546900
    },
    {
      "epoch": 879.29,
      "learning_rate": 0.012106840304823148,
      "loss": 2.3999,
      "step": 546920
    },
    {
      "epoch": 879.32,
      "learning_rate": 0.01210362487395498,
      "loss": 2.3828,
      "step": 546940
    },
    {
      "epoch": 879.36,
      "learning_rate": 0.012100409443086822,
      "loss": 2.3545,
      "step": 546960
    },
    {
      "epoch": 879.39,
      "learning_rate": 0.012097194012218654,
      "loss": 2.3707,
      "step": 546980
    },
    {
      "epoch": 879.42,
      "learning_rate": 0.012093978581350483,
      "loss": 2.3816,
      "step": 547000
    },
    {
      "epoch": 879.45,
      "learning_rate": 0.012090763150482315,
      "loss": 2.3726,
      "step": 547020
    },
    {
      "epoch": 879.49,
      "learning_rate": 0.012087547719614145,
      "loss": 2.3821,
      "step": 547040
    },
    {
      "epoch": 879.52,
      "learning_rate": 0.012084332288745976,
      "loss": 2.3831,
      "step": 547060
    },
    {
      "epoch": 879.55,
      "learning_rate": 0.012081116857877819,
      "loss": 2.3711,
      "step": 547080
    },
    {
      "epoch": 879.58,
      "learning_rate": 0.012077901427009648,
      "loss": 2.3772,
      "step": 547100
    },
    {
      "epoch": 879.61,
      "learning_rate": 0.01207468599614148,
      "loss": 2.3926,
      "step": 547120
    },
    {
      "epoch": 879.65,
      "learning_rate": 0.01207147056527331,
      "loss": 2.3779,
      "step": 547140
    },
    {
      "epoch": 879.68,
      "learning_rate": 0.012068255134405141,
      "loss": 2.3718,
      "step": 547160
    },
    {
      "epoch": 879.71,
      "learning_rate": 0.012065039703536971,
      "loss": 2.3837,
      "step": 547180
    },
    {
      "epoch": 879.74,
      "learning_rate": 0.012061824272668813,
      "loss": 2.3792,
      "step": 547200
    },
    {
      "epoch": 879.77,
      "learning_rate": 0.012058608841800645,
      "loss": 2.377,
      "step": 547220
    },
    {
      "epoch": 879.81,
      "learning_rate": 0.012055393410932475,
      "loss": 2.3694,
      "step": 547240
    },
    {
      "epoch": 879.84,
      "learning_rate": 0.012052177980064306,
      "loss": 2.376,
      "step": 547260
    },
    {
      "epoch": 879.87,
      "learning_rate": 0.012048962549196138,
      "loss": 2.3771,
      "step": 547280
    },
    {
      "epoch": 879.9,
      "learning_rate": 0.01204574711832798,
      "loss": 2.3816,
      "step": 547300
    },
    {
      "epoch": 879.94,
      "learning_rate": 0.01204253168745981,
      "loss": 2.3769,
      "step": 547320
    },
    {
      "epoch": 879.97,
      "learning_rate": 0.012039316256591642,
      "loss": 2.3757,
      "step": 547340
    },
    {
      "epoch": 880.0,
      "learning_rate": 0.012036100825723471,
      "loss": 2.3756,
      "step": 547360
    },
    {
      "epoch": 880.0,
      "eval_accuracy": {
        "accuracy": 0.4662209437922724
      },
      "eval_loss": 2.492116689682007,
      "eval_runtime": 3.0849,
      "eval_samples_per_second": 4169.711,
      "eval_steps_per_second": 65.157,
      "step": 547360
    },
    {
      "epoch": 880.03,
      "learning_rate": 0.012032885394855303,
      "loss": 2.3776,
      "step": 547380
    },
    {
      "epoch": 880.06,
      "learning_rate": 0.012029669963987133,
      "loss": 2.3775,
      "step": 547400
    },
    {
      "epoch": 880.1,
      "learning_rate": 0.012026454533118975,
      "loss": 2.3671,
      "step": 547420
    },
    {
      "epoch": 880.13,
      "learning_rate": 0.012023239102250807,
      "loss": 2.3447,
      "step": 547440
    },
    {
      "epoch": 880.16,
      "learning_rate": 0.012020023671382636,
      "loss": 2.3818,
      "step": 547460
    },
    {
      "epoch": 880.19,
      "learning_rate": 0.012016808240514468,
      "loss": 2.3785,
      "step": 547480
    },
    {
      "epoch": 880.23,
      "learning_rate": 0.012013592809646298,
      "loss": 2.3646,
      "step": 547500
    },
    {
      "epoch": 880.26,
      "learning_rate": 0.01201037737877813,
      "loss": 2.3672,
      "step": 547520
    },
    {
      "epoch": 880.29,
      "learning_rate": 0.012007161947909972,
      "loss": 2.3864,
      "step": 547540
    },
    {
      "epoch": 880.32,
      "learning_rate": 0.012003946517041801,
      "loss": 2.3681,
      "step": 547560
    },
    {
      "epoch": 880.35,
      "learning_rate": 0.012000731086173633,
      "loss": 2.4081,
      "step": 547580
    },
    {
      "epoch": 880.39,
      "learning_rate": 0.011997515655305465,
      "loss": 2.3905,
      "step": 547600
    },
    {
      "epoch": 880.42,
      "learning_rate": 0.011994300224437295,
      "loss": 2.3735,
      "step": 547620
    },
    {
      "epoch": 880.45,
      "learning_rate": 0.011991084793569137,
      "loss": 2.383,
      "step": 547640
    },
    {
      "epoch": 880.48,
      "learning_rate": 0.011987869362700968,
      "loss": 2.3715,
      "step": 547660
    },
    {
      "epoch": 880.51,
      "learning_rate": 0.011984653931832798,
      "loss": 2.3746,
      "step": 547680
    },
    {
      "epoch": 880.55,
      "learning_rate": 0.01198143850096463,
      "loss": 2.3537,
      "step": 547700
    },
    {
      "epoch": 880.58,
      "learning_rate": 0.01197822307009646,
      "loss": 2.3847,
      "step": 547720
    },
    {
      "epoch": 880.61,
      "learning_rate": 0.011975007639228291,
      "loss": 2.385,
      "step": 547740
    },
    {
      "epoch": 880.64,
      "learning_rate": 0.011971792208360133,
      "loss": 2.3824,
      "step": 547760
    },
    {
      "epoch": 880.68,
      "learning_rate": 0.011968576777491963,
      "loss": 2.373,
      "step": 547780
    },
    {
      "epoch": 880.71,
      "learning_rate": 0.011965361346623795,
      "loss": 2.3591,
      "step": 547800
    },
    {
      "epoch": 880.74,
      "learning_rate": 0.011962145915755625,
      "loss": 2.371,
      "step": 547820
    },
    {
      "epoch": 880.77,
      "learning_rate": 0.011958930484887456,
      "loss": 2.3608,
      "step": 547840
    },
    {
      "epoch": 880.8,
      "learning_rate": 0.011955715054019288,
      "loss": 2.3757,
      "step": 547860
    },
    {
      "epoch": 880.84,
      "learning_rate": 0.011952499623151128,
      "loss": 2.3615,
      "step": 547880
    },
    {
      "epoch": 880.87,
      "learning_rate": 0.01194928419228296,
      "loss": 2.37,
      "step": 547900
    },
    {
      "epoch": 880.9,
      "learning_rate": 0.011946068761414791,
      "loss": 2.3602,
      "step": 547920
    },
    {
      "epoch": 880.93,
      "learning_rate": 0.011942853330546621,
      "loss": 2.3766,
      "step": 547940
    },
    {
      "epoch": 880.96,
      "learning_rate": 0.011939637899678453,
      "loss": 2.3686,
      "step": 547960
    },
    {
      "epoch": 881.0,
      "learning_rate": 0.011936422468810295,
      "loss": 2.3667,
      "step": 547980
    },
    {
      "epoch": 881.0,
      "eval_accuracy": {
        "accuracy": 0.46451061183238745
      },
      "eval_loss": 2.492155075073242,
      "eval_runtime": 3.1212,
      "eval_samples_per_second": 4121.17,
      "eval_steps_per_second": 64.398,
      "step": 547982
    },
    {
      "epoch": 881.03,
      "learning_rate": 0.011933207037942125,
      "loss": 2.3715,
      "step": 548000
    },
    {
      "epoch": 881.06,
      "learning_rate": 0.011929991607073956,
      "loss": 2.3559,
      "step": 548020
    },
    {
      "epoch": 881.09,
      "learning_rate": 0.011926936947749198,
      "loss": 2.3644,
      "step": 548040
    },
    {
      "epoch": 881.13,
      "learning_rate": 0.01192372151688103,
      "loss": 2.3733,
      "step": 548060
    },
    {
      "epoch": 881.16,
      "learning_rate": 0.01192050608601286,
      "loss": 2.3557,
      "step": 548080
    },
    {
      "epoch": 881.19,
      "learning_rate": 0.01191729065514469,
      "loss": 2.3933,
      "step": 548100
    },
    {
      "epoch": 881.22,
      "learning_rate": 0.011914075224276533,
      "loss": 2.3961,
      "step": 548120
    },
    {
      "epoch": 881.25,
      "learning_rate": 0.011910859793408363,
      "loss": 2.3604,
      "step": 548140
    },
    {
      "epoch": 881.29,
      "learning_rate": 0.011907644362540194,
      "loss": 2.3653,
      "step": 548160
    },
    {
      "epoch": 881.32,
      "learning_rate": 0.011904428931672024,
      "loss": 2.3426,
      "step": 548180
    },
    {
      "epoch": 881.35,
      "learning_rate": 0.011901213500803856,
      "loss": 2.3751,
      "step": 548200
    },
    {
      "epoch": 881.38,
      "learning_rate": 0.011897998069935686,
      "loss": 2.3764,
      "step": 548220
    },
    {
      "epoch": 881.41,
      "learning_rate": 0.011894782639067528,
      "loss": 2.3716,
      "step": 548240
    },
    {
      "epoch": 881.45,
      "learning_rate": 0.01189156720819936,
      "loss": 2.3648,
      "step": 548260
    },
    {
      "epoch": 881.48,
      "learning_rate": 0.01188835177733119,
      "loss": 2.3683,
      "step": 548280
    },
    {
      "epoch": 881.51,
      "learning_rate": 0.01188513634646302,
      "loss": 2.3693,
      "step": 548300
    },
    {
      "epoch": 881.54,
      "learning_rate": 0.011881920915594852,
      "loss": 2.3811,
      "step": 548320
    },
    {
      "epoch": 881.58,
      "learning_rate": 0.011878705484726682,
      "loss": 2.3519,
      "step": 548340
    },
    {
      "epoch": 881.61,
      "learning_rate": 0.011875490053858524,
      "loss": 2.3712,
      "step": 548360
    },
    {
      "epoch": 881.64,
      "learning_rate": 0.011872274622990356,
      "loss": 2.3699,
      "step": 548380
    },
    {
      "epoch": 881.67,
      "learning_rate": 0.011869059192122186,
      "loss": 2.3522,
      "step": 548400
    },
    {
      "epoch": 881.7,
      "learning_rate": 0.011865843761254017,
      "loss": 2.3694,
      "step": 548420
    },
    {
      "epoch": 881.74,
      "learning_rate": 0.011862628330385847,
      "loss": 2.3877,
      "step": 548440
    },
    {
      "epoch": 881.77,
      "learning_rate": 0.01185941289951769,
      "loss": 2.3582,
      "step": 548460
    },
    {
      "epoch": 881.8,
      "learning_rate": 0.01185619746864952,
      "loss": 2.388,
      "step": 548480
    },
    {
      "epoch": 881.83,
      "learning_rate": 0.01185298203778135,
      "loss": 2.3841,
      "step": 548500
    },
    {
      "epoch": 881.86,
      "learning_rate": 0.011849766606913182,
      "loss": 2.3847,
      "step": 548520
    },
    {
      "epoch": 881.9,
      "learning_rate": 0.011846551176045012,
      "loss": 2.3885,
      "step": 548540
    },
    {
      "epoch": 881.93,
      "learning_rate": 0.011843335745176844,
      "loss": 2.3786,
      "step": 548560
    },
    {
      "epoch": 881.96,
      "learning_rate": 0.011840120314308686,
      "loss": 2.3705,
      "step": 548580
    },
    {
      "epoch": 881.99,
      "learning_rate": 0.011836904883440517,
      "loss": 2.3672,
      "step": 548600
    },
    {
      "epoch": 882.0,
      "eval_accuracy": {
        "accuracy": 0.4680090181139703
      },
      "eval_loss": 2.492640972137451,
      "eval_runtime": 3.0501,
      "eval_samples_per_second": 4217.233,
      "eval_steps_per_second": 65.899,
      "step": 548604
    },
    {
      "epoch": 882.03,
      "learning_rate": 0.011833689452572347,
      "loss": 2.3652,
      "step": 548620
    },
    {
      "epoch": 882.06,
      "learning_rate": 0.011830474021704179,
      "loss": 2.368,
      "step": 548640
    },
    {
      "epoch": 882.09,
      "learning_rate": 0.011827258590836009,
      "loss": 2.3633,
      "step": 548660
    },
    {
      "epoch": 882.12,
      "learning_rate": 0.01182404315996784,
      "loss": 2.3851,
      "step": 548680
    },
    {
      "epoch": 882.15,
      "learning_rate": 0.011820827729099682,
      "loss": 2.3681,
      "step": 548700
    },
    {
      "epoch": 882.19,
      "learning_rate": 0.011817612298231512,
      "loss": 2.3643,
      "step": 548720
    },
    {
      "epoch": 882.22,
      "learning_rate": 0.011814396867363344,
      "loss": 2.372,
      "step": 548740
    },
    {
      "epoch": 882.25,
      "learning_rate": 0.011811181436495174,
      "loss": 2.3696,
      "step": 548760
    },
    {
      "epoch": 882.28,
      "learning_rate": 0.011807966005627005,
      "loss": 2.3642,
      "step": 548780
    },
    {
      "epoch": 882.32,
      "learning_rate": 0.011804750574758847,
      "loss": 2.3731,
      "step": 548800
    },
    {
      "epoch": 882.35,
      "learning_rate": 0.011801535143890677,
      "loss": 2.3795,
      "step": 548820
    },
    {
      "epoch": 882.38,
      "learning_rate": 0.011798319713022509,
      "loss": 2.3735,
      "step": 548840
    },
    {
      "epoch": 882.41,
      "learning_rate": 0.01179510428215434,
      "loss": 2.3769,
      "step": 548860
    },
    {
      "epoch": 882.44,
      "learning_rate": 0.01179188885128617,
      "loss": 2.3692,
      "step": 548880
    },
    {
      "epoch": 882.48,
      "learning_rate": 0.011788673420418002,
      "loss": 2.3657,
      "step": 548900
    },
    {
      "epoch": 882.51,
      "learning_rate": 0.011785457989549844,
      "loss": 2.3695,
      "step": 548920
    },
    {
      "epoch": 882.54,
      "learning_rate": 0.011782242558681674,
      "loss": 2.3662,
      "step": 548940
    },
    {
      "epoch": 882.57,
      "learning_rate": 0.011779027127813506,
      "loss": 2.3743,
      "step": 548960
    },
    {
      "epoch": 882.6,
      "learning_rate": 0.011775811696945335,
      "loss": 2.3706,
      "step": 548980
    },
    {
      "epoch": 882.64,
      "learning_rate": 0.011772596266077167,
      "loss": 2.3704,
      "step": 549000
    },
    {
      "epoch": 882.67,
      "learning_rate": 0.011769380835208997,
      "loss": 2.3684,
      "step": 549020
    },
    {
      "epoch": 882.7,
      "learning_rate": 0.011766165404340839,
      "loss": 2.3657,
      "step": 549040
    },
    {
      "epoch": 882.73,
      "learning_rate": 0.01176294997347267,
      "loss": 2.3717,
      "step": 549060
    },
    {
      "epoch": 882.77,
      "learning_rate": 0.0117597345426045,
      "loss": 2.3789,
      "step": 549080
    },
    {
      "epoch": 882.8,
      "learning_rate": 0.011756519111736332,
      "loss": 2.3613,
      "step": 549100
    },
    {
      "epoch": 882.83,
      "learning_rate": 0.011753303680868162,
      "loss": 2.3723,
      "step": 549120
    },
    {
      "epoch": 882.86,
      "learning_rate": 0.011750088250000004,
      "loss": 2.3655,
      "step": 549140
    },
    {
      "epoch": 882.89,
      "learning_rate": 0.011746872819131835,
      "loss": 2.3849,
      "step": 549160
    },
    {
      "epoch": 882.93,
      "learning_rate": 0.011743657388263667,
      "loss": 2.3731,
      "step": 549180
    },
    {
      "epoch": 882.96,
      "learning_rate": 0.011740441957395497,
      "loss": 2.3695,
      "step": 549200
    },
    {
      "epoch": 882.99,
      "learning_rate": 0.011737226526527329,
      "loss": 2.3753,
      "step": 549220
    },
    {
      "epoch": 883.0,
      "eval_accuracy": {
        "accuracy": 0.466920625048589
      },
      "eval_loss": 2.485379695892334,
      "eval_runtime": 3.1875,
      "eval_samples_per_second": 4035.48,
      "eval_steps_per_second": 63.059,
      "step": 549226
    },
    {
      "epoch": 883.02,
      "learning_rate": 0.011734011095659158,
      "loss": 2.3759,
      "step": 549240
    },
    {
      "epoch": 883.05,
      "learning_rate": 0.011730795664791,
      "loss": 2.3559,
      "step": 549260
    },
    {
      "epoch": 883.09,
      "learning_rate": 0.011727580233922832,
      "loss": 2.3816,
      "step": 549280
    },
    {
      "epoch": 883.12,
      "learning_rate": 0.011724364803054662,
      "loss": 2.3477,
      "step": 549300
    },
    {
      "epoch": 883.15,
      "learning_rate": 0.011721149372186494,
      "loss": 2.3779,
      "step": 549320
    },
    {
      "epoch": 883.18,
      "learning_rate": 0.011717933941318323,
      "loss": 2.3465,
      "step": 549340
    },
    {
      "epoch": 883.22,
      "learning_rate": 0.011714718510450165,
      "loss": 2.3592,
      "step": 549360
    },
    {
      "epoch": 883.25,
      "learning_rate": 0.011711503079581997,
      "loss": 2.3746,
      "step": 549380
    },
    {
      "epoch": 883.28,
      "learning_rate": 0.011708287648713827,
      "loss": 2.3572,
      "step": 549400
    },
    {
      "epoch": 883.31,
      "learning_rate": 0.011705072217845659,
      "loss": 2.3725,
      "step": 549420
    },
    {
      "epoch": 883.34,
      "learning_rate": 0.011701856786977488,
      "loss": 2.3788,
      "step": 549440
    },
    {
      "epoch": 883.38,
      "learning_rate": 0.01169864135610932,
      "loss": 2.377,
      "step": 549460
    },
    {
      "epoch": 883.41,
      "learning_rate": 0.011695425925241162,
      "loss": 2.3715,
      "step": 549480
    },
    {
      "epoch": 883.44,
      "learning_rate": 0.011692210494372994,
      "loss": 2.3911,
      "step": 549500
    },
    {
      "epoch": 883.47,
      "learning_rate": 0.011688995063504824,
      "loss": 2.3826,
      "step": 549520
    },
    {
      "epoch": 883.5,
      "learning_rate": 0.011685779632636655,
      "loss": 2.3784,
      "step": 549540
    },
    {
      "epoch": 883.54,
      "learning_rate": 0.011682564201768485,
      "loss": 2.3843,
      "step": 549560
    },
    {
      "epoch": 883.57,
      "learning_rate": 0.011679348770900317,
      "loss": 2.3656,
      "step": 549580
    },
    {
      "epoch": 883.6,
      "learning_rate": 0.011676133340032159,
      "loss": 2.3578,
      "step": 549600
    },
    {
      "epoch": 883.63,
      "learning_rate": 0.011672917909163989,
      "loss": 2.3827,
      "step": 549620
    },
    {
      "epoch": 883.67,
      "learning_rate": 0.01166970247829582,
      "loss": 2.373,
      "step": 549640
    },
    {
      "epoch": 883.7,
      "learning_rate": 0.01166648704742765,
      "loss": 2.3773,
      "step": 549660
    },
    {
      "epoch": 883.73,
      "learning_rate": 0.011663271616559482,
      "loss": 2.3728,
      "step": 549680
    },
    {
      "epoch": 883.76,
      "learning_rate": 0.011660056185691324,
      "loss": 2.3778,
      "step": 549700
    },
    {
      "epoch": 883.79,
      "learning_rate": 0.011656840754823154,
      "loss": 2.3491,
      "step": 549720
    },
    {
      "epoch": 883.83,
      "learning_rate": 0.011653625323954985,
      "loss": 2.3756,
      "step": 549740
    },
    {
      "epoch": 883.86,
      "learning_rate": 0.011650409893086815,
      "loss": 2.3704,
      "step": 549760
    },
    {
      "epoch": 883.89,
      "learning_rate": 0.011647194462218647,
      "loss": 2.3684,
      "step": 549780
    },
    {
      "epoch": 883.92,
      "learning_rate": 0.011643979031350478,
      "loss": 2.3771,
      "step": 549800
    },
    {
      "epoch": 883.95,
      "learning_rate": 0.01164076360048232,
      "loss": 2.3598,
      "step": 549820
    },
    {
      "epoch": 883.99,
      "learning_rate": 0.01163754816961415,
      "loss": 2.3662,
      "step": 549840
    },
    {
      "epoch": 884.0,
      "eval_accuracy": {
        "accuracy": 0.46583223198320767
      },
      "eval_loss": 2.494392156600952,
      "eval_runtime": 3.194,
      "eval_samples_per_second": 4027.255,
      "eval_steps_per_second": 62.931,
      "step": 549848
    },
    {
      "epoch": 884.02,
      "learning_rate": 0.011634332738745982,
      "loss": 2.3629,
      "step": 549860
    },
    {
      "epoch": 884.05,
      "learning_rate": 0.011631117307877812,
      "loss": 2.3694,
      "step": 549880
    },
    {
      "epoch": 884.08,
      "learning_rate": 0.011627901877009643,
      "loss": 2.3869,
      "step": 549900
    },
    {
      "epoch": 884.12,
      "learning_rate": 0.011624686446141473,
      "loss": 2.3866,
      "step": 549920
    },
    {
      "epoch": 884.15,
      "learning_rate": 0.011621471015273315,
      "loss": 2.3748,
      "step": 549940
    },
    {
      "epoch": 884.18,
      "learning_rate": 0.011618255584405147,
      "loss": 2.372,
      "step": 549960
    },
    {
      "epoch": 884.21,
      "learning_rate": 0.011615040153536977,
      "loss": 2.3483,
      "step": 549980
    },
    {
      "epoch": 884.24,
      "learning_rate": 0.011611824722668808,
      "loss": 2.3728,
      "step": 550000
    },
    {
      "epoch": 884.28,
      "learning_rate": 0.011608609291800638,
      "loss": 2.3527,
      "step": 550020
    },
    {
      "epoch": 884.31,
      "learning_rate": 0.01160539386093248,
      "loss": 2.3631,
      "step": 550040
    },
    {
      "epoch": 884.34,
      "learning_rate": 0.011602178430064312,
      "loss": 2.3701,
      "step": 550060
    },
    {
      "epoch": 884.37,
      "learning_rate": 0.011598962999196143,
      "loss": 2.3712,
      "step": 550080
    },
    {
      "epoch": 884.41,
      "learning_rate": 0.011595747568327973,
      "loss": 2.3798,
      "step": 550100
    },
    {
      "epoch": 884.44,
      "learning_rate": 0.011592532137459805,
      "loss": 2.3699,
      "step": 550120
    },
    {
      "epoch": 884.47,
      "learning_rate": 0.011589316706591635,
      "loss": 2.3525,
      "step": 550140
    },
    {
      "epoch": 884.5,
      "learning_rate": 0.011586101275723477,
      "loss": 2.3664,
      "step": 550160
    },
    {
      "epoch": 884.53,
      "learning_rate": 0.011582885844855308,
      "loss": 2.3725,
      "step": 550180
    },
    {
      "epoch": 884.57,
      "learning_rate": 0.011579670413987138,
      "loss": 2.3687,
      "step": 550200
    },
    {
      "epoch": 884.6,
      "learning_rate": 0.01157645498311897,
      "loss": 2.3635,
      "step": 550220
    },
    {
      "epoch": 884.63,
      "learning_rate": 0.0115732395522508,
      "loss": 2.3502,
      "step": 550240
    },
    {
      "epoch": 884.66,
      "learning_rate": 0.011570024121382631,
      "loss": 2.3708,
      "step": 550260
    },
    {
      "epoch": 884.69,
      "learning_rate": 0.011566808690514473,
      "loss": 2.3705,
      "step": 550280
    },
    {
      "epoch": 884.73,
      "learning_rate": 0.011563593259646303,
      "loss": 2.3654,
      "step": 550300
    },
    {
      "epoch": 884.76,
      "learning_rate": 0.011560377828778135,
      "loss": 2.379,
      "step": 550320
    },
    {
      "epoch": 884.79,
      "learning_rate": 0.011557162397909965,
      "loss": 2.3833,
      "step": 550340
    },
    {
      "epoch": 884.82,
      "learning_rate": 0.011553946967041796,
      "loss": 2.384,
      "step": 550360
    },
    {
      "epoch": 884.86,
      "learning_rate": 0.011550731536173638,
      "loss": 2.3646,
      "step": 550380
    },
    {
      "epoch": 884.89,
      "learning_rate": 0.01154751610530547,
      "loss": 2.3804,
      "step": 550400
    },
    {
      "epoch": 884.92,
      "learning_rate": 0.0115443006744373,
      "loss": 2.3721,
      "step": 550420
    },
    {
      "epoch": 884.95,
      "learning_rate": 0.011541085243569131,
      "loss": 2.374,
      "step": 550440
    },
    {
      "epoch": 884.98,
      "learning_rate": 0.011537869812700961,
      "loss": 2.3596,
      "step": 550460
    },
    {
      "epoch": 885.0,
      "eval_accuracy": {
        "accuracy": 0.46536577781232996
      },
      "eval_loss": 2.492962121963501,
      "eval_runtime": 2.9976,
      "eval_samples_per_second": 4291.092,
      "eval_steps_per_second": 67.054,
      "step": 550470
    },
    {
      "epoch": 885.02,
      "learning_rate": 0.011534654381832793,
      "loss": 2.3812,
      "step": 550480
    },
    {
      "epoch": 885.05,
      "learning_rate": 0.011531438950964635,
      "loss": 2.3574,
      "step": 550500
    },
    {
      "epoch": 885.08,
      "learning_rate": 0.011528223520096465,
      "loss": 2.3724,
      "step": 550520
    },
    {
      "epoch": 885.11,
      "learning_rate": 0.011525008089228296,
      "loss": 2.3779,
      "step": 550540
    },
    {
      "epoch": 885.14,
      "learning_rate": 0.011521792658360126,
      "loss": 2.3775,
      "step": 550560
    },
    {
      "epoch": 885.18,
      "learning_rate": 0.011518577227491958,
      "loss": 2.3729,
      "step": 550580
    },
    {
      "epoch": 885.21,
      "learning_rate": 0.011515361796623788,
      "loss": 2.3812,
      "step": 550600
    },
    {
      "epoch": 885.24,
      "learning_rate": 0.01151214636575563,
      "loss": 2.3756,
      "step": 550620
    },
    {
      "epoch": 885.27,
      "learning_rate": 0.011508930934887461,
      "loss": 2.3682,
      "step": 550640
    },
    {
      "epoch": 885.31,
      "learning_rate": 0.011505715504019291,
      "loss": 2.3625,
      "step": 550660
    },
    {
      "epoch": 885.34,
      "learning_rate": 0.011502500073151123,
      "loss": 2.3417,
      "step": 550680
    },
    {
      "epoch": 885.37,
      "learning_rate": 0.011499284642282954,
      "loss": 2.3722,
      "step": 550700
    },
    {
      "epoch": 885.4,
      "learning_rate": 0.011496069211414797,
      "loss": 2.3685,
      "step": 550720
    },
    {
      "epoch": 885.43,
      "learning_rate": 0.011492853780546626,
      "loss": 2.3729,
      "step": 550740
    },
    {
      "epoch": 885.47,
      "learning_rate": 0.011489638349678458,
      "loss": 2.3732,
      "step": 550760
    },
    {
      "epoch": 885.5,
      "learning_rate": 0.011486422918810288,
      "loss": 2.3759,
      "step": 550780
    },
    {
      "epoch": 885.53,
      "learning_rate": 0.01148320748794212,
      "loss": 2.3565,
      "step": 550800
    },
    {
      "epoch": 885.56,
      "learning_rate": 0.01147999205707395,
      "loss": 2.371,
      "step": 550820
    },
    {
      "epoch": 885.59,
      "learning_rate": 0.011476776626205791,
      "loss": 2.3646,
      "step": 550840
    },
    {
      "epoch": 885.63,
      "learning_rate": 0.011473561195337623,
      "loss": 2.3719,
      "step": 550860
    },
    {
      "epoch": 885.66,
      "learning_rate": 0.011470345764469453,
      "loss": 2.3577,
      "step": 550880
    },
    {
      "epoch": 885.69,
      "learning_rate": 0.011467130333601284,
      "loss": 2.3787,
      "step": 550900
    },
    {
      "epoch": 885.72,
      "learning_rate": 0.011463914902733114,
      "loss": 2.3608,
      "step": 550920
    },
    {
      "epoch": 885.76,
      "learning_rate": 0.011460699471864946,
      "loss": 2.3693,
      "step": 550940
    },
    {
      "epoch": 885.79,
      "learning_rate": 0.011457484040996788,
      "loss": 2.3617,
      "step": 550960
    },
    {
      "epoch": 885.82,
      "learning_rate": 0.011454268610128618,
      "loss": 2.384,
      "step": 550980
    },
    {
      "epoch": 885.85,
      "learning_rate": 0.01145105317926045,
      "loss": 2.3652,
      "step": 551000
    },
    {
      "epoch": 885.88,
      "learning_rate": 0.011447837748392281,
      "loss": 2.3754,
      "step": 551020
    },
    {
      "epoch": 885.92,
      "learning_rate": 0.011444622317524111,
      "loss": 2.3625,
      "step": 551040
    },
    {
      "epoch": 885.95,
      "learning_rate": 0.011441406886655953,
      "loss": 2.353,
      "step": 551060
    },
    {
      "epoch": 885.98,
      "learning_rate": 0.011438191455787785,
      "loss": 2.3494,
      "step": 551080
    },
    {
      "epoch": 886.0,
      "eval_accuracy": {
        "accuracy": 0.4704190313301718
      },
      "eval_loss": 2.4774763584136963,
      "eval_runtime": 3.1111,
      "eval_samples_per_second": 4134.542,
      "eval_steps_per_second": 64.607,
      "step": 551092
    },
    {
      "epoch": 886.01,
      "learning_rate": 0.011434976024919614,
      "loss": 2.3529,
      "step": 551100
    },
    {
      "epoch": 886.05,
      "learning_rate": 0.011431760594051446,
      "loss": 2.3773,
      "step": 551120
    },
    {
      "epoch": 886.08,
      "learning_rate": 0.011428545163183276,
      "loss": 2.3836,
      "step": 551140
    },
    {
      "epoch": 886.11,
      "learning_rate": 0.011425329732315108,
      "loss": 2.3723,
      "step": 551160
    },
    {
      "epoch": 886.14,
      "learning_rate": 0.01142211430144695,
      "loss": 2.3713,
      "step": 551180
    },
    {
      "epoch": 886.17,
      "learning_rate": 0.01141889887057878,
      "loss": 2.3579,
      "step": 551200
    },
    {
      "epoch": 886.21,
      "learning_rate": 0.011415683439710611,
      "loss": 2.3588,
      "step": 551220
    },
    {
      "epoch": 886.24,
      "learning_rate": 0.011412468008842441,
      "loss": 2.3761,
      "step": 551240
    },
    {
      "epoch": 886.27,
      "learning_rate": 0.011409413349517684,
      "loss": 2.3568,
      "step": 551260
    },
    {
      "epoch": 886.3,
      "learning_rate": 0.011406197918649514,
      "loss": 2.3719,
      "step": 551280
    },
    {
      "epoch": 886.33,
      "learning_rate": 0.011402982487781346,
      "loss": 2.3751,
      "step": 551300
    },
    {
      "epoch": 886.37,
      "learning_rate": 0.011399767056913188,
      "loss": 2.3617,
      "step": 551320
    },
    {
      "epoch": 886.4,
      "learning_rate": 0.011396551626045017,
      "loss": 2.3819,
      "step": 551340
    },
    {
      "epoch": 886.43,
      "learning_rate": 0.011393336195176849,
      "loss": 2.3739,
      "step": 551360
    },
    {
      "epoch": 886.46,
      "learning_rate": 0.01139012076430868,
      "loss": 2.3854,
      "step": 551380
    },
    {
      "epoch": 886.5,
      "learning_rate": 0.01138690533344051,
      "loss": 2.366,
      "step": 551400
    },
    {
      "epoch": 886.53,
      "learning_rate": 0.011383689902572342,
      "loss": 2.373,
      "step": 551420
    },
    {
      "epoch": 886.56,
      "learning_rate": 0.011380474471704184,
      "loss": 2.3612,
      "step": 551440
    },
    {
      "epoch": 886.59,
      "learning_rate": 0.011377259040836014,
      "loss": 2.3796,
      "step": 551460
    },
    {
      "epoch": 886.62,
      "learning_rate": 0.011374043609967846,
      "loss": 2.3561,
      "step": 551480
    },
    {
      "epoch": 886.66,
      "learning_rate": 0.011370828179099676,
      "loss": 2.3655,
      "step": 551500
    },
    {
      "epoch": 886.69,
      "learning_rate": 0.011367612748231507,
      "loss": 2.3742,
      "step": 551520
    },
    {
      "epoch": 886.72,
      "learning_rate": 0.01136439731736335,
      "loss": 2.3359,
      "step": 551540
    },
    {
      "epoch": 886.75,
      "learning_rate": 0.011361181886495179,
      "loss": 2.3587,
      "step": 551560
    },
    {
      "epoch": 886.78,
      "learning_rate": 0.01135796645562701,
      "loss": 2.3724,
      "step": 551580
    },
    {
      "epoch": 886.82,
      "learning_rate": 0.01135475102475884,
      "loss": 2.3764,
      "step": 551600
    },
    {
      "epoch": 886.85,
      "learning_rate": 0.011351535593890672,
      "loss": 2.3584,
      "step": 551620
    },
    {
      "epoch": 886.88,
      "learning_rate": 0.011348320163022502,
      "loss": 2.3621,
      "step": 551640
    },
    {
      "epoch": 886.91,
      "learning_rate": 0.011345104732154344,
      "loss": 2.3755,
      "step": 551660
    },
    {
      "epoch": 886.95,
      "learning_rate": 0.011341889301286176,
      "loss": 2.3515,
      "step": 551680
    },
    {
      "epoch": 886.98,
      "learning_rate": 0.011338673870418007,
      "loss": 2.3679,
      "step": 551700
    },
    {
      "epoch": 887.0,
      "eval_accuracy": {
        "accuracy": 0.4655990048977688
      },
      "eval_loss": 2.4929094314575195,
      "eval_runtime": 3.1473,
      "eval_samples_per_second": 4086.985,
      "eval_steps_per_second": 63.864,
      "step": 551714
    },
    {
      "epoch": 887.01,
      "learning_rate": 0.011335458439549837,
      "loss": 2.3658,
      "step": 551720
    },
    {
      "epoch": 887.04,
      "learning_rate": 0.011332243008681669,
      "loss": 2.366,
      "step": 551740
    },
    {
      "epoch": 887.07,
      "learning_rate": 0.01132902757781351,
      "loss": 2.3565,
      "step": 551760
    },
    {
      "epoch": 887.11,
      "learning_rate": 0.01132581214694534,
      "loss": 2.3683,
      "step": 551780
    },
    {
      "epoch": 887.14,
      "learning_rate": 0.011322596716077172,
      "loss": 2.36,
      "step": 551800
    },
    {
      "epoch": 887.17,
      "learning_rate": 0.011319381285209002,
      "loss": 2.3662,
      "step": 551820
    },
    {
      "epoch": 887.2,
      "learning_rate": 0.011316165854340834,
      "loss": 2.3736,
      "step": 551840
    },
    {
      "epoch": 887.23,
      "learning_rate": 0.011312950423472664,
      "loss": 2.379,
      "step": 551860
    },
    {
      "epoch": 887.27,
      "learning_rate": 0.011309734992604506,
      "loss": 2.3752,
      "step": 551880
    },
    {
      "epoch": 887.3,
      "learning_rate": 0.011306519561736337,
      "loss": 2.3708,
      "step": 551900
    },
    {
      "epoch": 887.33,
      "learning_rate": 0.011303304130868167,
      "loss": 2.3781,
      "step": 551920
    },
    {
      "epoch": 887.36,
      "learning_rate": 0.011300088699999999,
      "loss": 2.3677,
      "step": 551940
    },
    {
      "epoch": 887.4,
      "learning_rate": 0.011296873269131829,
      "loss": 2.3623,
      "step": 551960
    },
    {
      "epoch": 887.43,
      "learning_rate": 0.01129365783826366,
      "loss": 2.3539,
      "step": 551980
    },
    {
      "epoch": 887.46,
      "learning_rate": 0.011290442407395502,
      "loss": 2.3549,
      "step": 552000
    },
    {
      "epoch": 887.49,
      "learning_rate": 0.011287226976527334,
      "loss": 2.3795,
      "step": 552020
    },
    {
      "epoch": 887.52,
      "learning_rate": 0.011284011545659164,
      "loss": 2.3706,
      "step": 552040
    },
    {
      "epoch": 887.56,
      "learning_rate": 0.011280796114790995,
      "loss": 2.3729,
      "step": 552060
    },
    {
      "epoch": 887.59,
      "learning_rate": 0.011277580683922825,
      "loss": 2.367,
      "step": 552080
    },
    {
      "epoch": 887.62,
      "learning_rate": 0.011274365253054667,
      "loss": 2.3489,
      "step": 552100
    },
    {
      "epoch": 887.65,
      "learning_rate": 0.011271149822186499,
      "loss": 2.3673,
      "step": 552120
    },
    {
      "epoch": 887.68,
      "learning_rate": 0.011267934391318329,
      "loss": 2.376,
      "step": 552140
    },
    {
      "epoch": 887.72,
      "learning_rate": 0.01126471896045016,
      "loss": 2.3609,
      "step": 552160
    },
    {
      "epoch": 887.75,
      "learning_rate": 0.01126150352958199,
      "loss": 2.3692,
      "step": 552180
    },
    {
      "epoch": 887.78,
      "learning_rate": 0.011258288098713822,
      "loss": 2.3617,
      "step": 552200
    },
    {
      "epoch": 887.81,
      "learning_rate": 0.011255072667845664,
      "loss": 2.3495,
      "step": 552220
    },
    {
      "epoch": 887.85,
      "learning_rate": 0.011251857236977494,
      "loss": 2.3784,
      "step": 552240
    },
    {
      "epoch": 887.88,
      "learning_rate": 0.011248641806109325,
      "loss": 2.3727,
      "step": 552260
    },
    {
      "epoch": 887.91,
      "learning_rate": 0.011245426375241157,
      "loss": 2.3993,
      "step": 552280
    },
    {
      "epoch": 887.94,
      "learning_rate": 0.011242210944372987,
      "loss": 2.3599,
      "step": 552300
    },
    {
      "epoch": 887.97,
      "learning_rate": 0.011238995513504818,
      "loss": 2.3621,
      "step": 552320
    },
    {
      "epoch": 888.0,
      "eval_accuracy": {
        "accuracy": 0.473373241079064
      },
      "eval_loss": 2.4763050079345703,
      "eval_runtime": 3.497,
      "eval_samples_per_second": 3678.266,
      "eval_steps_per_second": 57.477,
      "step": 552336
    },
    {
      "epoch": 888.01,
      "learning_rate": 0.01123578008263666,
      "loss": 2.3775,
      "step": 552340
    },
    {
      "epoch": 888.04,
      "learning_rate": 0.01123256465176849,
      "loss": 2.3831,
      "step": 552360
    },
    {
      "epoch": 888.07,
      "learning_rate": 0.011229349220900322,
      "loss": 2.3647,
      "step": 552380
    },
    {
      "epoch": 888.1,
      "learning_rate": 0.011226133790032152,
      "loss": 2.3653,
      "step": 552400
    },
    {
      "epoch": 888.14,
      "learning_rate": 0.011222918359163983,
      "loss": 2.3616,
      "step": 552420
    },
    {
      "epoch": 888.17,
      "learning_rate": 0.011219702928295825,
      "loss": 2.3624,
      "step": 552440
    },
    {
      "epoch": 888.2,
      "learning_rate": 0.011216487497427655,
      "loss": 2.3791,
      "step": 552460
    },
    {
      "epoch": 888.23,
      "learning_rate": 0.011213272066559487,
      "loss": 2.3706,
      "step": 552480
    },
    {
      "epoch": 888.26,
      "learning_rate": 0.011210056635691317,
      "loss": 2.3606,
      "step": 552500
    },
    {
      "epoch": 888.3,
      "learning_rate": 0.011206841204823148,
      "loss": 2.3569,
      "step": 552520
    },
    {
      "epoch": 888.33,
      "learning_rate": 0.011203625773954978,
      "loss": 2.358,
      "step": 552540
    },
    {
      "epoch": 888.36,
      "learning_rate": 0.01120041034308682,
      "loss": 2.3524,
      "step": 552560
    },
    {
      "epoch": 888.39,
      "learning_rate": 0.011197194912218652,
      "loss": 2.3825,
      "step": 552580
    },
    {
      "epoch": 888.42,
      "learning_rate": 0.011193979481350484,
      "loss": 2.3619,
      "step": 552600
    },
    {
      "epoch": 888.46,
      "learning_rate": 0.011190764050482313,
      "loss": 2.3737,
      "step": 552620
    },
    {
      "epoch": 888.49,
      "learning_rate": 0.011187548619614145,
      "loss": 2.3888,
      "step": 552640
    },
    {
      "epoch": 888.52,
      "learning_rate": 0.011184333188745975,
      "loss": 2.3879,
      "step": 552660
    },
    {
      "epoch": 888.55,
      "learning_rate": 0.011181117757877817,
      "loss": 2.387,
      "step": 552680
    },
    {
      "epoch": 888.59,
      "learning_rate": 0.011177902327009649,
      "loss": 2.3493,
      "step": 552700
    },
    {
      "epoch": 888.62,
      "learning_rate": 0.011174686896141478,
      "loss": 2.3713,
      "step": 552720
    },
    {
      "epoch": 888.65,
      "learning_rate": 0.01117147146527331,
      "loss": 2.3657,
      "step": 552740
    },
    {
      "epoch": 888.68,
      "learning_rate": 0.01116825603440514,
      "loss": 2.3684,
      "step": 552760
    },
    {
      "epoch": 888.71,
      "learning_rate": 0.011165040603536982,
      "loss": 2.359,
      "step": 552780
    },
    {
      "epoch": 888.75,
      "learning_rate": 0.011161825172668813,
      "loss": 2.3624,
      "step": 552800
    },
    {
      "epoch": 888.78,
      "learning_rate": 0.011158609741800643,
      "loss": 2.3599,
      "step": 552820
    },
    {
      "epoch": 888.81,
      "learning_rate": 0.011155394310932475,
      "loss": 2.3534,
      "step": 552840
    },
    {
      "epoch": 888.84,
      "learning_rate": 0.011152178880064305,
      "loss": 2.3589,
      "step": 552860
    },
    {
      "epoch": 888.87,
      "learning_rate": 0.011148963449196136,
      "loss": 2.3678,
      "step": 552880
    },
    {
      "epoch": 888.91,
      "learning_rate": 0.011145748018327978,
      "loss": 2.3783,
      "step": 552900
    },
    {
      "epoch": 888.94,
      "learning_rate": 0.01114253258745981,
      "loss": 2.3595,
      "step": 552920
    },
    {
      "epoch": 888.97,
      "learning_rate": 0.01113931715659164,
      "loss": 2.3639,
      "step": 552940
    },
    {
      "epoch": 889.0,
      "eval_accuracy": {
        "accuracy": 0.4655212625359558
      },
      "eval_loss": 2.491152763366699,
      "eval_runtime": 2.9886,
      "eval_samples_per_second": 4304.039,
      "eval_steps_per_second": 67.256,
      "step": 552958
    },
    {
      "epoch": 889.0,
      "learning_rate": 0.011136101725723472,
      "loss": 2.365,
      "step": 552960
    },
    {
      "epoch": 889.04,
      "learning_rate": 0.011132886294855301,
      "loss": 2.3705,
      "step": 552980
    },
    {
      "epoch": 889.07,
      "learning_rate": 0.011129670863987133,
      "loss": 2.3502,
      "step": 553000
    },
    {
      "epoch": 889.1,
      "learning_rate": 0.011126455433118975,
      "loss": 2.3785,
      "step": 553020
    },
    {
      "epoch": 889.13,
      "learning_rate": 0.011123240002250805,
      "loss": 2.3679,
      "step": 553040
    },
    {
      "epoch": 889.16,
      "learning_rate": 0.011120024571382637,
      "loss": 2.3513,
      "step": 553060
    },
    {
      "epoch": 889.2,
      "learning_rate": 0.011116809140514466,
      "loss": 2.3858,
      "step": 553080
    },
    {
      "epoch": 889.23,
      "learning_rate": 0.011113593709646298,
      "loss": 2.362,
      "step": 553100
    },
    {
      "epoch": 889.26,
      "learning_rate": 0.01111037827877814,
      "loss": 2.3363,
      "step": 553120
    },
    {
      "epoch": 889.29,
      "learning_rate": 0.01110716284790997,
      "loss": 2.3735,
      "step": 553140
    },
    {
      "epoch": 889.32,
      "learning_rate": 0.011103947417041802,
      "loss": 2.3703,
      "step": 553160
    },
    {
      "epoch": 889.36,
      "learning_rate": 0.011100731986173631,
      "loss": 2.3562,
      "step": 553180
    },
    {
      "epoch": 889.39,
      "learning_rate": 0.011097516555305463,
      "loss": 2.3682,
      "step": 553200
    },
    {
      "epoch": 889.42,
      "learning_rate": 0.011094301124437295,
      "loss": 2.3601,
      "step": 553220
    },
    {
      "epoch": 889.45,
      "learning_rate": 0.011091085693569137,
      "loss": 2.3666,
      "step": 553240
    },
    {
      "epoch": 889.49,
      "learning_rate": 0.011087870262700967,
      "loss": 2.3781,
      "step": 553260
    },
    {
      "epoch": 889.52,
      "learning_rate": 0.011084654831832798,
      "loss": 2.3589,
      "step": 553280
    },
    {
      "epoch": 889.55,
      "learning_rate": 0.011081439400964628,
      "loss": 2.352,
      "step": 553300
    },
    {
      "epoch": 889.58,
      "learning_rate": 0.01107822397009646,
      "loss": 2.3625,
      "step": 553320
    },
    {
      "epoch": 889.61,
      "learning_rate": 0.01107500853922829,
      "loss": 2.351,
      "step": 553340
    },
    {
      "epoch": 889.65,
      "learning_rate": 0.011071793108360132,
      "loss": 2.3818,
      "step": 553360
    },
    {
      "epoch": 889.68,
      "learning_rate": 0.011068577677491963,
      "loss": 2.3803,
      "step": 553380
    },
    {
      "epoch": 889.71,
      "learning_rate": 0.011065362246623793,
      "loss": 2.3579,
      "step": 553400
    },
    {
      "epoch": 889.74,
      "learning_rate": 0.011062146815755625,
      "loss": 2.3621,
      "step": 553420
    },
    {
      "epoch": 889.77,
      "learning_rate": 0.011058931384887455,
      "loss": 2.3647,
      "step": 553440
    },
    {
      "epoch": 889.81,
      "learning_rate": 0.011055715954019297,
      "loss": 2.35,
      "step": 553460
    },
    {
      "epoch": 889.84,
      "learning_rate": 0.011052500523151128,
      "loss": 2.3672,
      "step": 553480
    },
    {
      "epoch": 889.87,
      "learning_rate": 0.01104928509228296,
      "loss": 2.3751,
      "step": 553500
    },
    {
      "epoch": 889.9,
      "learning_rate": 0.01104606966141479,
      "loss": 2.3676,
      "step": 553520
    },
    {
      "epoch": 889.94,
      "learning_rate": 0.011042854230546621,
      "loss": 2.3853,
      "step": 553540
    },
    {
      "epoch": 889.97,
      "learning_rate": 0.011039638799678451,
      "loss": 2.3528,
      "step": 553560
    },
    {
      "epoch": 890.0,
      "learning_rate": 0.011036423368810293,
      "loss": 2.3772,
      "step": 553580
    },
    {
      "epoch": 890.0,
      "eval_accuracy": {
        "accuracy": 0.46544352017414287
      },
      "eval_loss": 2.4918034076690674,
      "eval_runtime": 4.1529,
      "eval_samples_per_second": 3097.325,
      "eval_steps_per_second": 48.399,
      "step": 553580
    },
    {
      "epoch": 890.03,
      "learning_rate": 0.011033207937942125,
      "loss": 2.3644,
      "step": 553600
    },
    {
      "epoch": 890.06,
      "learning_rate": 0.011029992507073955,
      "loss": 2.3928,
      "step": 553620
    },
    {
      "epoch": 890.1,
      "learning_rate": 0.011026777076205786,
      "loss": 2.3562,
      "step": 553640
    },
    {
      "epoch": 890.13,
      "learning_rate": 0.011023561645337616,
      "loss": 2.3616,
      "step": 553660
    },
    {
      "epoch": 890.16,
      "learning_rate": 0.011020346214469458,
      "loss": 2.3708,
      "step": 553680
    },
    {
      "epoch": 890.19,
      "learning_rate": 0.01101713078360129,
      "loss": 2.356,
      "step": 553700
    },
    {
      "epoch": 890.23,
      "learning_rate": 0.01101391535273312,
      "loss": 2.3795,
      "step": 553720
    },
    {
      "epoch": 890.26,
      "learning_rate": 0.011010699921864951,
      "loss": 2.3624,
      "step": 553740
    },
    {
      "epoch": 890.29,
      "learning_rate": 0.011007484490996781,
      "loss": 2.3714,
      "step": 553760
    },
    {
      "epoch": 890.32,
      "learning_rate": 0.011004269060128613,
      "loss": 2.3466,
      "step": 553780
    },
    {
      "epoch": 890.35,
      "learning_rate": 0.011001053629260455,
      "loss": 2.3649,
      "step": 553800
    },
    {
      "epoch": 890.39,
      "learning_rate": 0.010997838198392286,
      "loss": 2.3458,
      "step": 553820
    },
    {
      "epoch": 890.42,
      "learning_rate": 0.010994622767524116,
      "loss": 2.3651,
      "step": 553840
    },
    {
      "epoch": 890.45,
      "learning_rate": 0.010991407336655948,
      "loss": 2.3716,
      "step": 553860
    },
    {
      "epoch": 890.48,
      "learning_rate": 0.010988191905787778,
      "loss": 2.3735,
      "step": 553880
    },
    {
      "epoch": 890.51,
      "learning_rate": 0.01098497647491961,
      "loss": 2.3693,
      "step": 553900
    },
    {
      "epoch": 890.55,
      "learning_rate": 0.010981761044051451,
      "loss": 2.3831,
      "step": 553920
    },
    {
      "epoch": 890.58,
      "learning_rate": 0.010978545613183281,
      "loss": 2.3439,
      "step": 553940
    },
    {
      "epoch": 890.61,
      "learning_rate": 0.010975330182315113,
      "loss": 2.3681,
      "step": 553960
    },
    {
      "epoch": 890.64,
      "learning_rate": 0.010972114751446943,
      "loss": 2.368,
      "step": 553980
    },
    {
      "epoch": 890.68,
      "learning_rate": 0.010968899320578774,
      "loss": 2.3625,
      "step": 554000
    },
    {
      "epoch": 890.71,
      "learning_rate": 0.010965683889710616,
      "loss": 2.3541,
      "step": 554020
    },
    {
      "epoch": 890.74,
      "learning_rate": 0.010962468458842446,
      "loss": 2.3754,
      "step": 554040
    },
    {
      "epoch": 890.77,
      "learning_rate": 0.010959253027974278,
      "loss": 2.3475,
      "step": 554060
    },
    {
      "epoch": 890.8,
      "learning_rate": 0.010956037597106108,
      "loss": 2.3659,
      "step": 554080
    },
    {
      "epoch": 890.84,
      "learning_rate": 0.01095282216623794,
      "loss": 2.3509,
      "step": 554100
    },
    {
      "epoch": 890.87,
      "learning_rate": 0.010949606735369771,
      "loss": 2.3627,
      "step": 554120
    },
    {
      "epoch": 890.9,
      "learning_rate": 0.010946391304501613,
      "loss": 2.3778,
      "step": 554140
    },
    {
      "epoch": 890.93,
      "learning_rate": 0.010943175873633443,
      "loss": 2.3673,
      "step": 554160
    },
    {
      "epoch": 890.96,
      "learning_rate": 0.010939960442765274,
      "loss": 2.3485,
      "step": 554180
    },
    {
      "epoch": 891.0,
      "learning_rate": 0.010936745011897104,
      "loss": 2.3756,
      "step": 554200
    },
    {
      "epoch": 891.0,
      "eval_accuracy": {
        "accuracy": 0.46583223198320767
      },
      "eval_loss": 2.480560541152954,
      "eval_runtime": 3.3462,
      "eval_samples_per_second": 3844.119,
      "eval_steps_per_second": 60.069,
      "step": 554202
    },
    {
      "epoch": 891.03,
      "learning_rate": 0.010933529581028936,
      "loss": 2.3545,
      "step": 554220
    },
    {
      "epoch": 891.06,
      "learning_rate": 0.010930314150160766,
      "loss": 2.3662,
      "step": 554240
    },
    {
      "epoch": 891.09,
      "learning_rate": 0.010927259490836009,
      "loss": 2.3814,
      "step": 554260
    },
    {
      "epoch": 891.13,
      "learning_rate": 0.010924044059967851,
      "loss": 2.3629,
      "step": 554280
    },
    {
      "epoch": 891.16,
      "learning_rate": 0.01092082862909968,
      "loss": 2.3546,
      "step": 554300
    },
    {
      "epoch": 891.19,
      "learning_rate": 0.010917613198231512,
      "loss": 2.3677,
      "step": 554320
    },
    {
      "epoch": 891.22,
      "learning_rate": 0.010914397767363342,
      "loss": 2.3632,
      "step": 554340
    },
    {
      "epoch": 891.25,
      "learning_rate": 0.010911182336495174,
      "loss": 2.362,
      "step": 554360
    },
    {
      "epoch": 891.29,
      "learning_rate": 0.010907966905627004,
      "loss": 2.3686,
      "step": 554380
    },
    {
      "epoch": 891.32,
      "learning_rate": 0.010904751474758846,
      "loss": 2.368,
      "step": 554400
    },
    {
      "epoch": 891.35,
      "learning_rate": 0.010901536043890677,
      "loss": 2.3681,
      "step": 554420
    },
    {
      "epoch": 891.38,
      "learning_rate": 0.010898320613022507,
      "loss": 2.3513,
      "step": 554440
    },
    {
      "epoch": 891.41,
      "learning_rate": 0.010895105182154339,
      "loss": 2.3593,
      "step": 554460
    },
    {
      "epoch": 891.45,
      "learning_rate": 0.01089188975128617,
      "loss": 2.3667,
      "step": 554480
    },
    {
      "epoch": 891.48,
      "learning_rate": 0.01088867432041801,
      "loss": 2.3832,
      "step": 554500
    },
    {
      "epoch": 891.51,
      "learning_rate": 0.010885458889549842,
      "loss": 2.3704,
      "step": 554520
    },
    {
      "epoch": 891.54,
      "learning_rate": 0.010882243458681674,
      "loss": 2.3624,
      "step": 554540
    },
    {
      "epoch": 891.58,
      "learning_rate": 0.010879028027813504,
      "loss": 2.3794,
      "step": 554560
    },
    {
      "epoch": 891.61,
      "learning_rate": 0.010875812596945336,
      "loss": 2.3538,
      "step": 554580
    },
    {
      "epoch": 891.64,
      "learning_rate": 0.010872597166077165,
      "loss": 2.3474,
      "step": 554600
    },
    {
      "epoch": 891.67,
      "learning_rate": 0.010869381735209007,
      "loss": 2.3484,
      "step": 554620
    },
    {
      "epoch": 891.7,
      "learning_rate": 0.010866166304340839,
      "loss": 2.3452,
      "step": 554640
    },
    {
      "epoch": 891.74,
      "learning_rate": 0.010862950873472669,
      "loss": 2.3431,
      "step": 554660
    },
    {
      "epoch": 891.77,
      "learning_rate": 0.0108597354426045,
      "loss": 2.3852,
      "step": 554680
    },
    {
      "epoch": 891.8,
      "learning_rate": 0.01085652001173633,
      "loss": 2.3715,
      "step": 554700
    },
    {
      "epoch": 891.83,
      "learning_rate": 0.010853304580868162,
      "loss": 2.3538,
      "step": 554720
    },
    {
      "epoch": 891.86,
      "learning_rate": 0.010850089150000004,
      "loss": 2.3621,
      "step": 554740
    },
    {
      "epoch": 891.9,
      "learning_rate": 0.010846873719131834,
      "loss": 2.3638,
      "step": 554760
    },
    {
      "epoch": 891.93,
      "learning_rate": 0.010843658288263665,
      "loss": 2.3484,
      "step": 554780
    },
    {
      "epoch": 891.96,
      "learning_rate": 0.010840442857395497,
      "loss": 2.3858,
      "step": 554800
    },
    {
      "epoch": 891.99,
      "learning_rate": 0.010837227426527327,
      "loss": 2.3652,
      "step": 554820
    },
    {
      "epoch": 892.0,
      "eval_accuracy": {
        "accuracy": 0.47135193967192723
      },
      "eval_loss": 2.484077215194702,
      "eval_runtime": 3.2658,
      "eval_samples_per_second": 3938.691,
      "eval_steps_per_second": 61.547,
      "step": 554824
    },
    {
      "epoch": 892.03,
      "learning_rate": 0.010834011995659169,
      "loss": 2.3804,
      "step": 554840
    },
    {
      "epoch": 892.06,
      "learning_rate": 0.010830796564791,
      "loss": 2.3666,
      "step": 554860
    },
    {
      "epoch": 892.09,
      "learning_rate": 0.01082758113392283,
      "loss": 2.3783,
      "step": 554880
    },
    {
      "epoch": 892.12,
      "learning_rate": 0.010824365703054662,
      "loss": 2.3652,
      "step": 554900
    },
    {
      "epoch": 892.15,
      "learning_rate": 0.010821150272186492,
      "loss": 2.3484,
      "step": 554920
    },
    {
      "epoch": 892.19,
      "learning_rate": 0.010817934841318324,
      "loss": 2.3721,
      "step": 554940
    },
    {
      "epoch": 892.22,
      "learning_rate": 0.010814719410450166,
      "loss": 2.3702,
      "step": 554960
    },
    {
      "epoch": 892.25,
      "learning_rate": 0.010811503979581995,
      "loss": 2.3479,
      "step": 554980
    },
    {
      "epoch": 892.28,
      "learning_rate": 0.010808288548713827,
      "loss": 2.3532,
      "step": 555000
    },
    {
      "epoch": 892.32,
      "learning_rate": 0.010805073117845657,
      "loss": 2.3468,
      "step": 555020
    },
    {
      "epoch": 892.35,
      "learning_rate": 0.010801857686977489,
      "loss": 2.3655,
      "step": 555040
    },
    {
      "epoch": 892.38,
      "learning_rate": 0.010798642256109318,
      "loss": 2.3636,
      "step": 555060
    },
    {
      "epoch": 892.41,
      "learning_rate": 0.01079542682524116,
      "loss": 2.3639,
      "step": 555080
    },
    {
      "epoch": 892.44,
      "learning_rate": 0.010792211394372992,
      "loss": 2.3712,
      "step": 555100
    },
    {
      "epoch": 892.48,
      "learning_rate": 0.010788995963504824,
      "loss": 2.3673,
      "step": 555120
    },
    {
      "epoch": 892.51,
      "learning_rate": 0.010785780532636654,
      "loss": 2.3786,
      "step": 555140
    },
    {
      "epoch": 892.54,
      "learning_rate": 0.010782565101768485,
      "loss": 2.3467,
      "step": 555160
    },
    {
      "epoch": 892.57,
      "learning_rate": 0.010779349670900327,
      "loss": 2.3844,
      "step": 555180
    },
    {
      "epoch": 892.6,
      "learning_rate": 0.010776134240032157,
      "loss": 2.3574,
      "step": 555200
    },
    {
      "epoch": 892.64,
      "learning_rate": 0.010772918809163989,
      "loss": 2.3628,
      "step": 555220
    },
    {
      "epoch": 892.67,
      "learning_rate": 0.010769703378295819,
      "loss": 2.3587,
      "step": 555240
    },
    {
      "epoch": 892.7,
      "learning_rate": 0.01076648794742765,
      "loss": 2.3455,
      "step": 555260
    },
    {
      "epoch": 892.73,
      "learning_rate": 0.01076327251655948,
      "loss": 2.3832,
      "step": 555280
    },
    {
      "epoch": 892.77,
      "learning_rate": 0.010760057085691322,
      "loss": 2.3535,
      "step": 555300
    },
    {
      "epoch": 892.8,
      "learning_rate": 0.010756841654823154,
      "loss": 2.37,
      "step": 555320
    },
    {
      "epoch": 892.83,
      "learning_rate": 0.010753626223954984,
      "loss": 2.3453,
      "step": 555340
    },
    {
      "epoch": 892.86,
      "learning_rate": 0.010750410793086815,
      "loss": 2.3705,
      "step": 555360
    },
    {
      "epoch": 892.89,
      "learning_rate": 0.010747195362218645,
      "loss": 2.3515,
      "step": 555380
    },
    {
      "epoch": 892.93,
      "learning_rate": 0.010743979931350477,
      "loss": 2.3608,
      "step": 555400
    },
    {
      "epoch": 892.96,
      "learning_rate": 0.010740764500482319,
      "loss": 2.355,
      "step": 555420
    },
    {
      "epoch": 892.99,
      "learning_rate": 0.01073754906961415,
      "loss": 2.3682,
      "step": 555440
    },
    {
      "epoch": 893.0,
      "eval_accuracy": {
        "accuracy": 0.4683977299230351
      },
      "eval_loss": 2.483933210372925,
      "eval_runtime": 2.9607,
      "eval_samples_per_second": 4344.57,
      "eval_steps_per_second": 67.889,
      "step": 555446
    },
    {
      "epoch": 893.02,
      "learning_rate": 0.01073433363874598,
      "loss": 2.3683,
      "step": 555460
    },
    {
      "epoch": 893.05,
      "learning_rate": 0.010731118207877812,
      "loss": 2.3457,
      "step": 555480
    },
    {
      "epoch": 893.09,
      "learning_rate": 0.010727902777009642,
      "loss": 2.3675,
      "step": 555500
    },
    {
      "epoch": 893.12,
      "learning_rate": 0.010724687346141484,
      "loss": 2.3524,
      "step": 555520
    },
    {
      "epoch": 893.15,
      "learning_rate": 0.010721471915273315,
      "loss": 2.3774,
      "step": 555540
    },
    {
      "epoch": 893.18,
      "learning_rate": 0.010718256484405145,
      "loss": 2.3757,
      "step": 555560
    },
    {
      "epoch": 893.22,
      "learning_rate": 0.010715041053536977,
      "loss": 2.3562,
      "step": 555580
    },
    {
      "epoch": 893.25,
      "learning_rate": 0.010711825622668807,
      "loss": 2.3639,
      "step": 555600
    },
    {
      "epoch": 893.28,
      "learning_rate": 0.010708610191800638,
      "loss": 2.3625,
      "step": 555620
    },
    {
      "epoch": 893.31,
      "learning_rate": 0.01070539476093248,
      "loss": 2.3482,
      "step": 555640
    },
    {
      "epoch": 893.34,
      "learning_rate": 0.01070217933006431,
      "loss": 2.3422,
      "step": 555660
    },
    {
      "epoch": 893.38,
      "learning_rate": 0.010698963899196142,
      "loss": 2.3583,
      "step": 555680
    },
    {
      "epoch": 893.41,
      "learning_rate": 0.010695748468327973,
      "loss": 2.3817,
      "step": 555700
    },
    {
      "epoch": 893.44,
      "learning_rate": 0.010692533037459803,
      "loss": 2.3616,
      "step": 555720
    },
    {
      "epoch": 893.47,
      "learning_rate": 0.010689317606591635,
      "loss": 2.3651,
      "step": 555740
    },
    {
      "epoch": 893.5,
      "learning_rate": 0.010686102175723477,
      "loss": 2.3588,
      "step": 555760
    },
    {
      "epoch": 893.54,
      "learning_rate": 0.010682886744855307,
      "loss": 2.3449,
      "step": 555780
    },
    {
      "epoch": 893.57,
      "learning_rate": 0.010679671313987138,
      "loss": 2.3717,
      "step": 555800
    },
    {
      "epoch": 893.6,
      "learning_rate": 0.010676455883118968,
      "loss": 2.3738,
      "step": 555820
    },
    {
      "epoch": 893.63,
      "learning_rate": 0.0106732404522508,
      "loss": 2.3631,
      "step": 555840
    },
    {
      "epoch": 893.67,
      "learning_rate": 0.010670025021382642,
      "loss": 2.3549,
      "step": 555860
    },
    {
      "epoch": 893.7,
      "learning_rate": 0.010666809590514472,
      "loss": 2.3486,
      "step": 555880
    },
    {
      "epoch": 893.73,
      "learning_rate": 0.010663594159646303,
      "loss": 2.3785,
      "step": 555900
    },
    {
      "epoch": 893.76,
      "learning_rate": 0.010660378728778133,
      "loss": 2.3638,
      "step": 555920
    },
    {
      "epoch": 893.79,
      "learning_rate": 0.010657163297909965,
      "loss": 2.3528,
      "step": 555940
    },
    {
      "epoch": 893.83,
      "learning_rate": 0.010653947867041795,
      "loss": 2.3574,
      "step": 555960
    },
    {
      "epoch": 893.86,
      "learning_rate": 0.010650732436173637,
      "loss": 2.3516,
      "step": 555980
    },
    {
      "epoch": 893.89,
      "learning_rate": 0.010647517005305468,
      "loss": 2.3714,
      "step": 556000
    },
    {
      "epoch": 893.92,
      "learning_rate": 0.0106443015744373,
      "loss": 2.3608,
      "step": 556020
    },
    {
      "epoch": 893.95,
      "learning_rate": 0.01064108614356913,
      "loss": 2.3736,
      "step": 556040
    },
    {
      "epoch": 893.99,
      "learning_rate": 0.010637870712700961,
      "loss": 2.3457,
      "step": 556060
    },
    {
      "epoch": 894.0,
      "eval_accuracy": {
        "accuracy": 0.4694861229884164
      },
      "eval_loss": 2.4746744632720947,
      "eval_runtime": 3.0662,
      "eval_samples_per_second": 4195.032,
      "eval_steps_per_second": 65.552,
      "step": 556068
    },
    {
      "epoch": 894.02,
      "learning_rate": 0.010634655281832791,
      "loss": 2.3753,
      "step": 556080
    },
    {
      "epoch": 894.05,
      "learning_rate": 0.010631439850964633,
      "loss": 2.3796,
      "step": 556100
    },
    {
      "epoch": 894.08,
      "learning_rate": 0.010628224420096465,
      "loss": 2.3635,
      "step": 556120
    },
    {
      "epoch": 894.12,
      "learning_rate": 0.010625008989228295,
      "loss": 2.3489,
      "step": 556140
    },
    {
      "epoch": 894.15,
      "learning_rate": 0.010621793558360126,
      "loss": 2.3597,
      "step": 556160
    },
    {
      "epoch": 894.18,
      "learning_rate": 0.010618578127491956,
      "loss": 2.3588,
      "step": 556180
    },
    {
      "epoch": 894.21,
      "learning_rate": 0.010615362696623798,
      "loss": 2.3438,
      "step": 556200
    },
    {
      "epoch": 894.24,
      "learning_rate": 0.01061214726575563,
      "loss": 2.3629,
      "step": 556220
    },
    {
      "epoch": 894.28,
      "learning_rate": 0.01060893183488746,
      "loss": 2.3651,
      "step": 556240
    },
    {
      "epoch": 894.31,
      "learning_rate": 0.010605716404019291,
      "loss": 2.3886,
      "step": 556260
    },
    {
      "epoch": 894.34,
      "learning_rate": 0.010602500973151121,
      "loss": 2.3665,
      "step": 556280
    },
    {
      "epoch": 894.37,
      "learning_rate": 0.010599285542282953,
      "loss": 2.3595,
      "step": 556300
    },
    {
      "epoch": 894.41,
      "learning_rate": 0.010596070111414795,
      "loss": 2.3645,
      "step": 556320
    },
    {
      "epoch": 894.44,
      "learning_rate": 0.010592854680546627,
      "loss": 2.3685,
      "step": 556340
    },
    {
      "epoch": 894.47,
      "learning_rate": 0.010589639249678456,
      "loss": 2.3656,
      "step": 556360
    },
    {
      "epoch": 894.5,
      "learning_rate": 0.010586423818810288,
      "loss": 2.3816,
      "step": 556380
    },
    {
      "epoch": 894.53,
      "learning_rate": 0.01058336915948553,
      "loss": 2.3486,
      "step": 556400
    },
    {
      "epoch": 894.57,
      "learning_rate": 0.010580153728617361,
      "loss": 2.372,
      "step": 556420
    },
    {
      "epoch": 894.6,
      "learning_rate": 0.010576938297749191,
      "loss": 2.3633,
      "step": 556440
    },
    {
      "epoch": 894.63,
      "learning_rate": 0.010573722866881033,
      "loss": 2.3519,
      "step": 556460
    },
    {
      "epoch": 894.66,
      "learning_rate": 0.010570507436012865,
      "loss": 2.3663,
      "step": 556480
    },
    {
      "epoch": 894.69,
      "learning_rate": 0.010567292005144694,
      "loss": 2.3618,
      "step": 556500
    },
    {
      "epoch": 894.73,
      "learning_rate": 0.010564076574276526,
      "loss": 2.3554,
      "step": 556520
    },
    {
      "epoch": 894.76,
      "learning_rate": 0.010560861143408356,
      "loss": 2.3508,
      "step": 556540
    },
    {
      "epoch": 894.79,
      "learning_rate": 0.010557645712540187,
      "loss": 2.3662,
      "step": 556560
    },
    {
      "epoch": 894.82,
      "learning_rate": 0.01055443028167203,
      "loss": 2.3852,
      "step": 556580
    },
    {
      "epoch": 894.86,
      "learning_rate": 0.01055121485080386,
      "loss": 2.3541,
      "step": 556600
    },
    {
      "epoch": 894.89,
      "learning_rate": 0.010547999419935691,
      "loss": 2.3503,
      "step": 556620
    },
    {
      "epoch": 894.92,
      "learning_rate": 0.010544783989067521,
      "loss": 2.364,
      "step": 556640
    },
    {
      "epoch": 894.95,
      "learning_rate": 0.010541568558199352,
      "loss": 2.3486,
      "step": 556660
    },
    {
      "epoch": 894.98,
      "learning_rate": 0.010538353127331195,
      "loss": 2.3431,
      "step": 556680
    },
    {
      "epoch": 895.0,
      "eval_accuracy": {
        "accuracy": 0.474928088315323
      },
      "eval_loss": 2.470209836959839,
      "eval_runtime": 3.1359,
      "eval_samples_per_second": 4101.832,
      "eval_steps_per_second": 64.096,
      "step": 556690
    },
    {
      "epoch": 895.02,
      "learning_rate": 0.010535137696463024,
      "loss": 2.3749,
      "step": 556700
    },
    {
      "epoch": 895.05,
      "learning_rate": 0.010531922265594856,
      "loss": 2.3531,
      "step": 556720
    },
    {
      "epoch": 895.08,
      "learning_rate": 0.010528706834726688,
      "loss": 2.3495,
      "step": 556740
    },
    {
      "epoch": 895.11,
      "learning_rate": 0.010525491403858517,
      "loss": 2.3803,
      "step": 556760
    },
    {
      "epoch": 895.14,
      "learning_rate": 0.010522275972990349,
      "loss": 2.3521,
      "step": 556780
    },
    {
      "epoch": 895.18,
      "learning_rate": 0.010519060542122191,
      "loss": 2.3489,
      "step": 556800
    },
    {
      "epoch": 895.21,
      "learning_rate": 0.010515845111254021,
      "loss": 2.3684,
      "step": 556820
    },
    {
      "epoch": 895.24,
      "learning_rate": 0.010512629680385853,
      "loss": 2.3462,
      "step": 556840
    },
    {
      "epoch": 895.27,
      "learning_rate": 0.010509414249517682,
      "loss": 2.3602,
      "step": 556860
    },
    {
      "epoch": 895.31,
      "learning_rate": 0.010506198818649514,
      "loss": 2.3668,
      "step": 556880
    },
    {
      "epoch": 895.34,
      "learning_rate": 0.010502983387781356,
      "loss": 2.3636,
      "step": 556900
    },
    {
      "epoch": 895.37,
      "learning_rate": 0.010499767956913186,
      "loss": 2.3747,
      "step": 556920
    },
    {
      "epoch": 895.4,
      "learning_rate": 0.010496552526045018,
      "loss": 2.3529,
      "step": 556940
    },
    {
      "epoch": 895.43,
      "learning_rate": 0.010493337095176847,
      "loss": 2.3663,
      "step": 556960
    },
    {
      "epoch": 895.47,
      "learning_rate": 0.010490121664308679,
      "loss": 2.3651,
      "step": 556980
    },
    {
      "epoch": 895.5,
      "learning_rate": 0.01048690623344051,
      "loss": 2.3719,
      "step": 557000
    },
    {
      "epoch": 895.53,
      "learning_rate": 0.010483690802572351,
      "loss": 2.3547,
      "step": 557020
    },
    {
      "epoch": 895.56,
      "learning_rate": 0.010480475371704183,
      "loss": 2.3529,
      "step": 557040
    },
    {
      "epoch": 895.59,
      "learning_rate": 0.010477259940836014,
      "loss": 2.3605,
      "step": 557060
    },
    {
      "epoch": 895.63,
      "learning_rate": 0.010474044509967844,
      "loss": 2.3568,
      "step": 557080
    },
    {
      "epoch": 895.66,
      "learning_rate": 0.010470829079099676,
      "loss": 2.3596,
      "step": 557100
    },
    {
      "epoch": 895.69,
      "learning_rate": 0.010467613648231506,
      "loss": 2.3578,
      "step": 557120
    },
    {
      "epoch": 895.72,
      "learning_rate": 0.010464398217363348,
      "loss": 2.363,
      "step": 557140
    },
    {
      "epoch": 895.76,
      "learning_rate": 0.01046118278649518,
      "loss": 2.3645,
      "step": 557160
    },
    {
      "epoch": 895.79,
      "learning_rate": 0.010457967355627009,
      "loss": 2.3582,
      "step": 557180
    },
    {
      "epoch": 895.82,
      "learning_rate": 0.01045475192475884,
      "loss": 2.3566,
      "step": 557200
    },
    {
      "epoch": 895.85,
      "learning_rate": 0.01045153649389067,
      "loss": 2.3535,
      "step": 557220
    },
    {
      "epoch": 895.88,
      "learning_rate": 0.010448321063022513,
      "loss": 2.3619,
      "step": 557240
    },
    {
      "epoch": 895.92,
      "learning_rate": 0.010445105632154344,
      "loss": 2.3652,
      "step": 557260
    },
    {
      "epoch": 895.95,
      "learning_rate": 0.010441890201286174,
      "loss": 2.3731,
      "step": 557280
    },
    {
      "epoch": 895.98,
      "learning_rate": 0.010438674770418006,
      "loss": 2.3523,
      "step": 557300
    },
    {
      "epoch": 896.0,
      "eval_accuracy": {
        "accuracy": 0.46645417087771124
      },
      "eval_loss": 2.480391263961792,
      "eval_runtime": 3.4081,
      "eval_samples_per_second": 3774.221,
      "eval_steps_per_second": 58.977,
      "step": 557312
    },
    {
      "epoch": 896.01,
      "learning_rate": 0.010435459339549837,
      "loss": 2.3562,
      "step": 557320
    },
    {
      "epoch": 896.05,
      "learning_rate": 0.010432243908681667,
      "loss": 2.3668,
      "step": 557340
    },
    {
      "epoch": 896.08,
      "learning_rate": 0.01042902847781351,
      "loss": 2.3533,
      "step": 557360
    },
    {
      "epoch": 896.11,
      "learning_rate": 0.01042581304694534,
      "loss": 2.3668,
      "step": 557380
    },
    {
      "epoch": 896.14,
      "learning_rate": 0.01042259761607717,
      "loss": 2.3622,
      "step": 557400
    },
    {
      "epoch": 896.17,
      "learning_rate": 0.010419382185209002,
      "loss": 2.3585,
      "step": 557420
    },
    {
      "epoch": 896.21,
      "learning_rate": 0.010416166754340832,
      "loss": 2.3614,
      "step": 557440
    },
    {
      "epoch": 896.24,
      "learning_rate": 0.010412951323472664,
      "loss": 2.3678,
      "step": 557460
    },
    {
      "epoch": 896.27,
      "learning_rate": 0.010409735892604506,
      "loss": 2.3762,
      "step": 557480
    },
    {
      "epoch": 896.3,
      "learning_rate": 0.010406520461736336,
      "loss": 2.3426,
      "step": 557500
    },
    {
      "epoch": 896.33,
      "learning_rate": 0.010403305030868167,
      "loss": 2.3544,
      "step": 557520
    },
    {
      "epoch": 896.37,
      "learning_rate": 0.010400089599999997,
      "loss": 2.3617,
      "step": 557540
    },
    {
      "epoch": 896.4,
      "learning_rate": 0.010396874169131829,
      "loss": 2.3451,
      "step": 557560
    },
    {
      "epoch": 896.43,
      "learning_rate": 0.01039365873826367,
      "loss": 2.3623,
      "step": 557580
    },
    {
      "epoch": 896.46,
      "learning_rate": 0.0103904433073955,
      "loss": 2.3537,
      "step": 557600
    },
    {
      "epoch": 896.5,
      "learning_rate": 0.010387227876527332,
      "loss": 2.3671,
      "step": 557620
    },
    {
      "epoch": 896.53,
      "learning_rate": 0.010384012445659164,
      "loss": 2.3592,
      "step": 557640
    },
    {
      "epoch": 896.56,
      "learning_rate": 0.010380797014790994,
      "loss": 2.3587,
      "step": 557660
    },
    {
      "epoch": 896.59,
      "learning_rate": 0.010377581583922825,
      "loss": 2.3714,
      "step": 557680
    },
    {
      "epoch": 896.62,
      "learning_rate": 0.010374366153054667,
      "loss": 2.3446,
      "step": 557700
    },
    {
      "epoch": 896.66,
      "learning_rate": 0.010371150722186497,
      "loss": 2.3452,
      "step": 557720
    },
    {
      "epoch": 896.69,
      "learning_rate": 0.010367935291318329,
      "loss": 2.344,
      "step": 557740
    },
    {
      "epoch": 896.72,
      "learning_rate": 0.010364719860450159,
      "loss": 2.3721,
      "step": 557760
    },
    {
      "epoch": 896.75,
      "learning_rate": 0.01036150442958199,
      "loss": 2.3641,
      "step": 557780
    },
    {
      "epoch": 896.78,
      "learning_rate": 0.01035828899871382,
      "loss": 2.3591,
      "step": 557800
    },
    {
      "epoch": 896.82,
      "learning_rate": 0.010355073567845662,
      "loss": 2.3473,
      "step": 557820
    },
    {
      "epoch": 896.85,
      "learning_rate": 0.010351858136977494,
      "loss": 2.3755,
      "step": 557840
    },
    {
      "epoch": 896.88,
      "learning_rate": 0.010348642706109324,
      "loss": 2.3561,
      "step": 557860
    },
    {
      "epoch": 896.91,
      "learning_rate": 0.010345427275241155,
      "loss": 2.3695,
      "step": 557880
    },
    {
      "epoch": 896.95,
      "learning_rate": 0.010342211844372987,
      "loss": 2.3505,
      "step": 557900
    },
    {
      "epoch": 896.98,
      "learning_rate": 0.010338996413504827,
      "loss": 2.3592,
      "step": 557920
    },
    {
      "epoch": 897.0,
      "eval_accuracy": {
        "accuracy": 0.47197387856643086
      },
      "eval_loss": 2.468503952026367,
      "eval_runtime": 3.2428,
      "eval_samples_per_second": 3966.657,
      "eval_steps_per_second": 61.984,
      "step": 557934
    },
    {
      "epoch": 897.01,
      "learning_rate": 0.010335780982636659,
      "loss": 2.3472,
      "step": 557940
    },
    {
      "epoch": 897.04,
      "learning_rate": 0.01033256555176849,
      "loss": 2.3668,
      "step": 557960
    },
    {
      "epoch": 897.07,
      "learning_rate": 0.01032935012090032,
      "loss": 2.377,
      "step": 557980
    },
    {
      "epoch": 897.11,
      "learning_rate": 0.010326134690032152,
      "loss": 2.3516,
      "step": 558000
    },
    {
      "epoch": 897.14,
      "learning_rate": 0.010322919259163982,
      "loss": 2.3471,
      "step": 558020
    },
    {
      "epoch": 897.17,
      "learning_rate": 0.010319703828295824,
      "loss": 2.3573,
      "step": 558040
    },
    {
      "epoch": 897.2,
      "learning_rate": 0.010316488397427655,
      "loss": 2.3642,
      "step": 558060
    },
    {
      "epoch": 897.23,
      "learning_rate": 0.010313272966559485,
      "loss": 2.3674,
      "step": 558080
    },
    {
      "epoch": 897.27,
      "learning_rate": 0.010310057535691317,
      "loss": 2.3599,
      "step": 558100
    },
    {
      "epoch": 897.3,
      "learning_rate": 0.010306842104823147,
      "loss": 2.3475,
      "step": 558120
    },
    {
      "epoch": 897.33,
      "learning_rate": 0.010303626673954978,
      "loss": 2.3658,
      "step": 558140
    },
    {
      "epoch": 897.36,
      "learning_rate": 0.01030041124308682,
      "loss": 2.3456,
      "step": 558160
    },
    {
      "epoch": 897.4,
      "learning_rate": 0.01029719581221865,
      "loss": 2.3612,
      "step": 558180
    },
    {
      "epoch": 897.43,
      "learning_rate": 0.010293980381350482,
      "loss": 2.3762,
      "step": 558200
    },
    {
      "epoch": 897.46,
      "learning_rate": 0.010290764950482314,
      "loss": 2.357,
      "step": 558220
    },
    {
      "epoch": 897.49,
      "learning_rate": 0.010287549519614143,
      "loss": 2.3467,
      "step": 558240
    },
    {
      "epoch": 897.52,
      "learning_rate": 0.010284334088745985,
      "loss": 2.3548,
      "step": 558260
    },
    {
      "epoch": 897.56,
      "learning_rate": 0.010281118657877817,
      "loss": 2.352,
      "step": 558280
    },
    {
      "epoch": 897.59,
      "learning_rate": 0.010277903227009647,
      "loss": 2.3611,
      "step": 558300
    },
    {
      "epoch": 897.62,
      "learning_rate": 0.010274687796141478,
      "loss": 2.3484,
      "step": 558320
    },
    {
      "epoch": 897.65,
      "learning_rate": 0.010271472365273308,
      "loss": 2.3329,
      "step": 558340
    },
    {
      "epoch": 897.68,
      "learning_rate": 0.01026825693440514,
      "loss": 2.3663,
      "step": 558360
    },
    {
      "epoch": 897.72,
      "learning_rate": 0.010265041503536982,
      "loss": 2.3665,
      "step": 558380
    },
    {
      "epoch": 897.75,
      "learning_rate": 0.010261826072668812,
      "loss": 2.3681,
      "step": 558400
    },
    {
      "epoch": 897.78,
      "learning_rate": 0.010258610641800643,
      "loss": 2.3526,
      "step": 558420
    },
    {
      "epoch": 897.81,
      "learning_rate": 0.010255395210932473,
      "loss": 2.3572,
      "step": 558440
    },
    {
      "epoch": 897.85,
      "learning_rate": 0.010252179780064305,
      "loss": 2.3451,
      "step": 558460
    },
    {
      "epoch": 897.88,
      "learning_rate": 0.010248964349196135,
      "loss": 2.3563,
      "step": 558480
    },
    {
      "epoch": 897.91,
      "learning_rate": 0.010245748918327977,
      "loss": 2.3441,
      "step": 558500
    },
    {
      "epoch": 897.94,
      "learning_rate": 0.010242533487459808,
      "loss": 2.3673,
      "step": 558520
    },
    {
      "epoch": 897.97,
      "learning_rate": 0.01023931805659164,
      "loss": 2.3435,
      "step": 558540
    },
    {
      "epoch": 898.0,
      "eval_accuracy": {
        "accuracy": 0.4678535333903444
      },
      "eval_loss": 2.4766833782196045,
      "eval_runtime": 3.3296,
      "eval_samples_per_second": 3863.221,
      "eval_steps_per_second": 60.368,
      "step": 558556
    },
    {
      "epoch": 898.01,
      "learning_rate": 0.01023610262572347,
      "loss": 2.3727,
      "step": 558560
    },
    {
      "epoch": 898.04,
      "learning_rate": 0.010232887194855302,
      "loss": 2.3552,
      "step": 558580
    },
    {
      "epoch": 898.07,
      "learning_rate": 0.010229671763987144,
      "loss": 2.3511,
      "step": 558600
    },
    {
      "epoch": 898.1,
      "learning_rate": 0.010226456333118973,
      "loss": 2.3481,
      "step": 558620
    },
    {
      "epoch": 898.14,
      "learning_rate": 0.010223240902250805,
      "loss": 2.3494,
      "step": 558640
    },
    {
      "epoch": 898.17,
      "learning_rate": 0.010220025471382635,
      "loss": 2.3425,
      "step": 558660
    },
    {
      "epoch": 898.2,
      "learning_rate": 0.010216810040514467,
      "loss": 2.3701,
      "step": 558680
    },
    {
      "epoch": 898.23,
      "learning_rate": 0.010213594609646296,
      "loss": 2.3626,
      "step": 558700
    },
    {
      "epoch": 898.26,
      "learning_rate": 0.010210379178778138,
      "loss": 2.3621,
      "step": 558720
    },
    {
      "epoch": 898.3,
      "learning_rate": 0.01020716374790997,
      "loss": 2.3423,
      "step": 558740
    },
    {
      "epoch": 898.33,
      "learning_rate": 0.0102039483170418,
      "loss": 2.3662,
      "step": 558760
    },
    {
      "epoch": 898.36,
      "learning_rate": 0.010200732886173632,
      "loss": 2.3628,
      "step": 558780
    },
    {
      "epoch": 898.39,
      "learning_rate": 0.010197517455305463,
      "loss": 2.3482,
      "step": 558800
    },
    {
      "epoch": 898.42,
      "learning_rate": 0.010194302024437303,
      "loss": 2.3546,
      "step": 558820
    },
    {
      "epoch": 898.46,
      "learning_rate": 0.010191086593569135,
      "loss": 2.3467,
      "step": 558840
    },
    {
      "epoch": 898.49,
      "learning_rate": 0.010187871162700967,
      "loss": 2.3676,
      "step": 558860
    },
    {
      "epoch": 898.52,
      "learning_rate": 0.010184655731832797,
      "loss": 2.3624,
      "step": 558880
    },
    {
      "epoch": 898.55,
      "learning_rate": 0.010181440300964628,
      "loss": 2.3382,
      "step": 558900
    },
    {
      "epoch": 898.59,
      "learning_rate": 0.010178224870096458,
      "loss": 2.3666,
      "step": 558920
    },
    {
      "epoch": 898.62,
      "learning_rate": 0.0101750094392283,
      "loss": 2.3505,
      "step": 558940
    },
    {
      "epoch": 898.65,
      "learning_rate": 0.010171794008360132,
      "loss": 2.3358,
      "step": 558960
    },
    {
      "epoch": 898.68,
      "learning_rate": 0.010168578577491962,
      "loss": 2.3597,
      "step": 558980
    },
    {
      "epoch": 898.71,
      "learning_rate": 0.010165363146623793,
      "loss": 2.3597,
      "step": 559000
    },
    {
      "epoch": 898.75,
      "learning_rate": 0.010162147715755623,
      "loss": 2.3541,
      "step": 559020
    },
    {
      "epoch": 898.78,
      "learning_rate": 0.010158932284887455,
      "loss": 2.3698,
      "step": 559040
    },
    {
      "epoch": 898.81,
      "learning_rate": 0.010155716854019297,
      "loss": 2.3622,
      "step": 559060
    },
    {
      "epoch": 898.84,
      "learning_rate": 0.010152501423151127,
      "loss": 2.3726,
      "step": 559080
    },
    {
      "epoch": 898.87,
      "learning_rate": 0.010149285992282958,
      "loss": 2.3547,
      "step": 559100
    },
    {
      "epoch": 898.91,
      "learning_rate": 0.01014607056141479,
      "loss": 2.3517,
      "step": 559120
    },
    {
      "epoch": 898.94,
      "learning_rate": 0.01014285513054662,
      "loss": 2.3629,
      "step": 559140
    },
    {
      "epoch": 898.97,
      "learning_rate": 0.010139639699678462,
      "loss": 2.3697,
      "step": 559160
    },
    {
      "epoch": 899.0,
      "eval_accuracy": {
        "accuracy": 0.4641219000233227
      },
      "eval_loss": 2.476350784301758,
      "eval_runtime": 3.2818,
      "eval_samples_per_second": 3919.513,
      "eval_steps_per_second": 61.247,
      "step": 559178
    },
    {
      "epoch": 899.0,
      "learning_rate": 0.010136424268810293,
      "loss": 2.3703,
      "step": 559180
    },
    {
      "epoch": 899.04,
      "learning_rate": 0.010133208837942123,
      "loss": 2.3688,
      "step": 559200
    },
    {
      "epoch": 899.07,
      "learning_rate": 0.010129993407073955,
      "loss": 2.3521,
      "step": 559220
    },
    {
      "epoch": 899.1,
      "learning_rate": 0.010126777976205785,
      "loss": 2.3658,
      "step": 559240
    },
    {
      "epoch": 899.13,
      "learning_rate": 0.010123562545337616,
      "loss": 2.3547,
      "step": 559260
    },
    {
      "epoch": 899.16,
      "learning_rate": 0.010120347114469458,
      "loss": 2.3503,
      "step": 559280
    },
    {
      "epoch": 899.2,
      "learning_rate": 0.010117131683601288,
      "loss": 2.3555,
      "step": 559300
    },
    {
      "epoch": 899.23,
      "learning_rate": 0.01011391625273312,
      "loss": 2.3618,
      "step": 559320
    },
    {
      "epoch": 899.26,
      "learning_rate": 0.01011070082186495,
      "loss": 2.3667,
      "step": 559340
    },
    {
      "epoch": 899.29,
      "learning_rate": 0.010107485390996781,
      "loss": 2.3534,
      "step": 559360
    },
    {
      "epoch": 899.32,
      "learning_rate": 0.010104269960128611,
      "loss": 2.3398,
      "step": 559380
    },
    {
      "epoch": 899.36,
      "learning_rate": 0.010101054529260453,
      "loss": 2.3575,
      "step": 559400
    },
    {
      "epoch": 899.39,
      "learning_rate": 0.010097839098392285,
      "loss": 2.3371,
      "step": 559420
    },
    {
      "epoch": 899.42,
      "learning_rate": 0.010094623667524116,
      "loss": 2.3548,
      "step": 559440
    },
    {
      "epoch": 899.45,
      "learning_rate": 0.010091408236655946,
      "loss": 2.3516,
      "step": 559460
    },
    {
      "epoch": 899.49,
      "learning_rate": 0.010088192805787778,
      "loss": 2.3598,
      "step": 559480
    },
    {
      "epoch": 899.52,
      "learning_rate": 0.01008497737491962,
      "loss": 2.3541,
      "step": 559500
    },
    {
      "epoch": 899.55,
      "learning_rate": 0.01008176194405145,
      "loss": 2.34,
      "step": 559520
    },
    {
      "epoch": 899.58,
      "learning_rate": 0.010078546513183281,
      "loss": 2.3723,
      "step": 559540
    },
    {
      "epoch": 899.61,
      "learning_rate": 0.010075331082315111,
      "loss": 2.3477,
      "step": 559560
    },
    {
      "epoch": 899.65,
      "learning_rate": 0.010072115651446943,
      "loss": 2.3432,
      "step": 559580
    },
    {
      "epoch": 899.68,
      "learning_rate": 0.010068900220578773,
      "loss": 2.3474,
      "step": 559600
    },
    {
      "epoch": 899.71,
      "learning_rate": 0.010065684789710615,
      "loss": 2.3572,
      "step": 559620
    },
    {
      "epoch": 899.74,
      "learning_rate": 0.010062469358842446,
      "loss": 2.3603,
      "step": 559640
    },
    {
      "epoch": 899.77,
      "learning_rate": 0.010059253927974276,
      "loss": 2.3534,
      "step": 559660
    },
    {
      "epoch": 899.81,
      "learning_rate": 0.010056038497106108,
      "loss": 2.38,
      "step": 559680
    },
    {
      "epoch": 899.84,
      "learning_rate": 0.010052823066237938,
      "loss": 2.3463,
      "step": 559700
    },
    {
      "epoch": 899.87,
      "learning_rate": 0.01004960763536977,
      "loss": 2.3653,
      "step": 559720
    },
    {
      "epoch": 899.9,
      "learning_rate": 0.010046392204501611,
      "loss": 2.3713,
      "step": 559740
    },
    {
      "epoch": 899.94,
      "learning_rate": 0.010043176773633443,
      "loss": 2.3625,
      "step": 559760
    },
    {
      "epoch": 899.97,
      "learning_rate": 0.010039961342765273,
      "loss": 2.3492,
      "step": 559780
    },
    {
      "epoch": 900.0,
      "learning_rate": 0.010036745911897104,
      "loss": 2.3661,
      "step": 559800
    },
    {
      "epoch": 900.0,
      "eval_accuracy": {
        "accuracy": 0.4738396952499417
      },
      "eval_loss": 2.468886137008667,
      "eval_runtime": 3.2784,
      "eval_samples_per_second": 3923.528,
      "eval_steps_per_second": 61.31,
      "step": 559800
    },
    {
      "epoch": 900.03,
      "learning_rate": 0.010033530481028934,
      "loss": 2.345,
      "step": 559820
    },
    {
      "epoch": 900.06,
      "learning_rate": 0.010030315050160776,
      "loss": 2.3486,
      "step": 559840
    },
    {
      "epoch": 900.1,
      "learning_rate": 0.010027099619292608,
      "loss": 2.3577,
      "step": 559860
    },
    {
      "epoch": 900.13,
      "learning_rate": 0.010023884188424438,
      "loss": 2.3657,
      "step": 559880
    },
    {
      "epoch": 900.16,
      "learning_rate": 0.01002066875755627,
      "loss": 2.3587,
      "step": 559900
    },
    {
      "epoch": 900.19,
      "learning_rate": 0.0100174533266881,
      "loss": 2.3393,
      "step": 559920
    },
    {
      "epoch": 900.23,
      "learning_rate": 0.010014237895819931,
      "loss": 2.3604,
      "step": 559940
    },
    {
      "epoch": 900.26,
      "learning_rate": 0.010011022464951773,
      "loss": 2.3671,
      "step": 559960
    },
    {
      "epoch": 900.29,
      "learning_rate": 0.010007807034083603,
      "loss": 2.3483,
      "step": 559980
    },
    {
      "epoch": 900.32,
      "learning_rate": 0.010004591603215434,
      "loss": 2.3722,
      "step": 560000
    },
    {
      "epoch": 900.35,
      "learning_rate": 0.010001376172347264,
      "loss": 2.3642,
      "step": 560020
    },
    {
      "epoch": 900.39,
      "learning_rate": 0.009998160741479096,
      "loss": 2.367,
      "step": 560040
    },
    {
      "epoch": 900.42,
      "learning_rate": 0.009994945310610927,
      "loss": 2.3692,
      "step": 560060
    },
    {
      "epoch": 900.45,
      "learning_rate": 0.00999172987974277,
      "loss": 2.3588,
      "step": 560080
    },
    {
      "epoch": 900.48,
      "learning_rate": 0.0099885144488746,
      "loss": 2.3462,
      "step": 560100
    },
    {
      "epoch": 900.51,
      "learning_rate": 0.009985299018006431,
      "loss": 2.3587,
      "step": 560120
    },
    {
      "epoch": 900.55,
      "learning_rate": 0.00998208358713826,
      "loss": 2.3629,
      "step": 560140
    },
    {
      "epoch": 900.58,
      "learning_rate": 0.009978868156270092,
      "loss": 2.3556,
      "step": 560160
    },
    {
      "epoch": 900.61,
      "learning_rate": 0.009975652725401934,
      "loss": 2.3427,
      "step": 560180
    },
    {
      "epoch": 900.64,
      "learning_rate": 0.009972437294533764,
      "loss": 2.3569,
      "step": 560200
    },
    {
      "epoch": 900.68,
      "learning_rate": 0.009969221863665596,
      "loss": 2.3512,
      "step": 560220
    },
    {
      "epoch": 900.71,
      "learning_rate": 0.009966006432797426,
      "loss": 2.356,
      "step": 560240
    },
    {
      "epoch": 900.74,
      "learning_rate": 0.009962791001929257,
      "loss": 2.3666,
      "step": 560260
    },
    {
      "epoch": 900.77,
      "learning_rate": 0.009959575571061087,
      "loss": 2.3509,
      "step": 560280
    },
    {
      "epoch": 900.8,
      "learning_rate": 0.00995636014019293,
      "loss": 2.3431,
      "step": 560300
    },
    {
      "epoch": 900.84,
      "learning_rate": 0.009953144709324761,
      "loss": 2.3439,
      "step": 560320
    },
    {
      "epoch": 900.87,
      "learning_rate": 0.009949929278456593,
      "loss": 2.3296,
      "step": 560340
    },
    {
      "epoch": 900.9,
      "learning_rate": 0.009946713847588422,
      "loss": 2.3628,
      "step": 560360
    },
    {
      "epoch": 900.93,
      "learning_rate": 0.009943498416720254,
      "loss": 2.3555,
      "step": 560380
    },
    {
      "epoch": 900.96,
      "learning_rate": 0.009940443757395495,
      "loss": 2.3523,
      "step": 560400
    },
    {
      "epoch": 901.0,
      "learning_rate": 0.009937228326527327,
      "loss": 2.3485,
      "step": 560420
    },
    {
      "epoch": 901.0,
      "eval_accuracy": {
        "accuracy": 0.471740651480992
      },
      "eval_loss": 2.4681501388549805,
      "eval_runtime": 3.6625,
      "eval_samples_per_second": 3512.101,
      "eval_steps_per_second": 54.881,
      "step": 560422
    },
    {
      "epoch": 901.03,
      "learning_rate": 0.009934012895659167,
      "loss": 2.347,
      "step": 560440
    },
    {
      "epoch": 901.06,
      "learning_rate": 0.009930797464790999,
      "loss": 2.3565,
      "step": 560460
    },
    {
      "epoch": 901.09,
      "learning_rate": 0.00992758203392283,
      "loss": 2.3514,
      "step": 560480
    },
    {
      "epoch": 901.13,
      "learning_rate": 0.00992436660305466,
      "loss": 2.3516,
      "step": 560500
    },
    {
      "epoch": 901.16,
      "learning_rate": 0.009921151172186492,
      "loss": 2.3628,
      "step": 560520
    },
    {
      "epoch": 901.19,
      "learning_rate": 0.009917935741318322,
      "loss": 2.3478,
      "step": 560540
    },
    {
      "epoch": 901.22,
      "learning_rate": 0.009914720310450164,
      "loss": 2.3606,
      "step": 560560
    },
    {
      "epoch": 901.25,
      "learning_rate": 0.009911504879581996,
      "loss": 2.3606,
      "step": 560580
    },
    {
      "epoch": 901.29,
      "learning_rate": 0.009908289448713825,
      "loss": 2.3538,
      "step": 560600
    },
    {
      "epoch": 901.32,
      "learning_rate": 0.009905074017845657,
      "loss": 2.3592,
      "step": 560620
    },
    {
      "epoch": 901.35,
      "learning_rate": 0.009902019358520898,
      "loss": 2.3478,
      "step": 560640
    },
    {
      "epoch": 901.38,
      "learning_rate": 0.00989880392765273,
      "loss": 2.3455,
      "step": 560660
    },
    {
      "epoch": 901.41,
      "learning_rate": 0.00989558849678456,
      "loss": 2.3492,
      "step": 560680
    },
    {
      "epoch": 901.45,
      "learning_rate": 0.009892373065916402,
      "loss": 2.3642,
      "step": 560700
    },
    {
      "epoch": 901.48,
      "learning_rate": 0.009889157635048234,
      "loss": 2.3821,
      "step": 560720
    },
    {
      "epoch": 901.51,
      "learning_rate": 0.009885942204180063,
      "loss": 2.3626,
      "step": 560740
    },
    {
      "epoch": 901.54,
      "learning_rate": 0.009882726773311895,
      "loss": 2.3364,
      "step": 560760
    },
    {
      "epoch": 901.58,
      "learning_rate": 0.009879511342443725,
      "loss": 2.3633,
      "step": 560780
    },
    {
      "epoch": 901.61,
      "learning_rate": 0.009876295911575567,
      "loss": 2.3441,
      "step": 560800
    },
    {
      "epoch": 901.64,
      "learning_rate": 0.009873080480707399,
      "loss": 2.3514,
      "step": 560820
    },
    {
      "epoch": 901.67,
      "learning_rate": 0.00986986504983923,
      "loss": 2.3412,
      "step": 560840
    },
    {
      "epoch": 901.7,
      "learning_rate": 0.00986664961897106,
      "loss": 2.3608,
      "step": 560860
    },
    {
      "epoch": 901.74,
      "learning_rate": 0.009863434188102892,
      "loss": 2.3338,
      "step": 560880
    },
    {
      "epoch": 901.77,
      "learning_rate": 0.009860218757234722,
      "loss": 2.3643,
      "step": 560900
    },
    {
      "epoch": 901.8,
      "learning_rate": 0.009857003326366564,
      "loss": 2.3326,
      "step": 560920
    },
    {
      "epoch": 901.83,
      "learning_rate": 0.009853787895498395,
      "loss": 2.3764,
      "step": 560940
    },
    {
      "epoch": 901.86,
      "learning_rate": 0.009850572464630225,
      "loss": 2.3579,
      "step": 560960
    },
    {
      "epoch": 901.9,
      "learning_rate": 0.009847357033762057,
      "loss": 2.3628,
      "step": 560980
    },
    {
      "epoch": 901.93,
      "learning_rate": 0.009844141602893887,
      "loss": 2.3662,
      "step": 561000
    },
    {
      "epoch": 901.96,
      "learning_rate": 0.009840926172025718,
      "loss": 2.3585,
      "step": 561020
    },
    {
      "epoch": 901.99,
      "learning_rate": 0.00983771074115756,
      "loss": 2.3469,
      "step": 561040
    },
    {
      "epoch": 902.0,
      "eval_accuracy": {
        "accuracy": 0.4725958174609345
      },
      "eval_loss": 2.4708473682403564,
      "eval_runtime": 3.153,
      "eval_samples_per_second": 4079.643,
      "eval_steps_per_second": 63.749,
      "step": 561044
    },
    {
      "epoch": 902.03,
      "learning_rate": 0.00983449531028939,
      "loss": 2.3439,
      "step": 561060
    },
    {
      "epoch": 902.06,
      "learning_rate": 0.009831279879421222,
      "loss": 2.3654,
      "step": 561080
    },
    {
      "epoch": 902.09,
      "learning_rate": 0.009828064448553052,
      "loss": 2.3549,
      "step": 561100
    },
    {
      "epoch": 902.12,
      "learning_rate": 0.009824849017684883,
      "loss": 2.3476,
      "step": 561120
    },
    {
      "epoch": 902.15,
      "learning_rate": 0.009821633586816725,
      "loss": 2.3602,
      "step": 561140
    },
    {
      "epoch": 902.19,
      "learning_rate": 0.009818418155948557,
      "loss": 2.3528,
      "step": 561160
    },
    {
      "epoch": 902.22,
      "learning_rate": 0.009815202725080387,
      "loss": 2.3538,
      "step": 561180
    },
    {
      "epoch": 902.25,
      "learning_rate": 0.009811987294212218,
      "loss": 2.3417,
      "step": 561200
    },
    {
      "epoch": 902.28,
      "learning_rate": 0.009808771863344048,
      "loss": 2.3303,
      "step": 561220
    },
    {
      "epoch": 902.32,
      "learning_rate": 0.00980555643247588,
      "loss": 2.3422,
      "step": 561240
    },
    {
      "epoch": 902.35,
      "learning_rate": 0.009802341001607722,
      "loss": 2.3462,
      "step": 561260
    },
    {
      "epoch": 902.38,
      "learning_rate": 0.009799125570739552,
      "loss": 2.3525,
      "step": 561280
    },
    {
      "epoch": 902.41,
      "learning_rate": 0.009795910139871383,
      "loss": 2.382,
      "step": 561300
    },
    {
      "epoch": 902.44,
      "learning_rate": 0.009792694709003213,
      "loss": 2.3443,
      "step": 561320
    },
    {
      "epoch": 902.48,
      "learning_rate": 0.009789479278135045,
      "loss": 2.3572,
      "step": 561340
    },
    {
      "epoch": 902.51,
      "learning_rate": 0.009786263847266875,
      "loss": 2.343,
      "step": 561360
    },
    {
      "epoch": 902.54,
      "learning_rate": 0.009783048416398717,
      "loss": 2.3687,
      "step": 561380
    },
    {
      "epoch": 902.57,
      "learning_rate": 0.009779832985530548,
      "loss": 2.3489,
      "step": 561400
    },
    {
      "epoch": 902.6,
      "learning_rate": 0.009776617554662378,
      "loss": 2.3548,
      "step": 561420
    },
    {
      "epoch": 902.64,
      "learning_rate": 0.00977340212379421,
      "loss": 2.3485,
      "step": 561440
    },
    {
      "epoch": 902.67,
      "learning_rate": 0.009770186692926041,
      "loss": 2.3575,
      "step": 561460
    },
    {
      "epoch": 902.7,
      "learning_rate": 0.009766971262057883,
      "loss": 2.3669,
      "step": 561480
    },
    {
      "epoch": 902.73,
      "learning_rate": 0.009763755831189713,
      "loss": 2.342,
      "step": 561500
    },
    {
      "epoch": 902.77,
      "learning_rate": 0.009760540400321545,
      "loss": 2.3719,
      "step": 561520
    },
    {
      "epoch": 902.8,
      "learning_rate": 0.009757324969453375,
      "loss": 2.3437,
      "step": 561540
    },
    {
      "epoch": 902.83,
      "learning_rate": 0.009754109538585206,
      "loss": 2.3393,
      "step": 561560
    },
    {
      "epoch": 902.86,
      "learning_rate": 0.009750894107717036,
      "loss": 2.3824,
      "step": 561580
    },
    {
      "epoch": 902.89,
      "learning_rate": 0.009747678676848878,
      "loss": 2.3488,
      "step": 561600
    },
    {
      "epoch": 902.93,
      "learning_rate": 0.00974446324598071,
      "loss": 2.3548,
      "step": 561620
    },
    {
      "epoch": 902.96,
      "learning_rate": 0.00974124781511254,
      "loss": 2.3692,
      "step": 561640
    },
    {
      "epoch": 902.99,
      "learning_rate": 0.009738032384244371,
      "loss": 2.3589,
      "step": 561660
    },
    {
      "epoch": 903.0,
      "eval_accuracy": {
        "accuracy": 0.4723625903754956
      },
      "eval_loss": 2.473635196685791,
      "eval_runtime": 3.1159,
      "eval_samples_per_second": 4128.155,
      "eval_steps_per_second": 64.507,
      "step": 561666
    },
    {
      "epoch": 903.02,
      "learning_rate": 0.009734816953376201,
      "loss": 2.341,
      "step": 561680
    },
    {
      "epoch": 903.05,
      "learning_rate": 0.009731601522508033,
      "loss": 2.3662,
      "step": 561700
    },
    {
      "epoch": 903.09,
      "learning_rate": 0.009728386091639875,
      "loss": 2.3435,
      "step": 561720
    },
    {
      "epoch": 903.12,
      "learning_rate": 0.009725170660771706,
      "loss": 2.3624,
      "step": 561740
    },
    {
      "epoch": 903.15,
      "learning_rate": 0.009721955229903536,
      "loss": 2.3693,
      "step": 561760
    },
    {
      "epoch": 903.18,
      "learning_rate": 0.009718739799035368,
      "loss": 2.3415,
      "step": 561780
    },
    {
      "epoch": 903.22,
      "learning_rate": 0.009715524368167198,
      "loss": 2.3638,
      "step": 561800
    },
    {
      "epoch": 903.25,
      "learning_rate": 0.00971230893729904,
      "loss": 2.3744,
      "step": 561820
    },
    {
      "epoch": 903.28,
      "learning_rate": 0.009709093506430871,
      "loss": 2.3312,
      "step": 561840
    },
    {
      "epoch": 903.31,
      "learning_rate": 0.009705878075562701,
      "loss": 2.3615,
      "step": 561860
    },
    {
      "epoch": 903.34,
      "learning_rate": 0.009702662644694533,
      "loss": 2.3363,
      "step": 561880
    },
    {
      "epoch": 903.38,
      "learning_rate": 0.009699447213826363,
      "loss": 2.3589,
      "step": 561900
    },
    {
      "epoch": 903.41,
      "learning_rate": 0.009696231782958194,
      "loss": 2.3489,
      "step": 561920
    },
    {
      "epoch": 903.44,
      "learning_rate": 0.009693016352090036,
      "loss": 2.355,
      "step": 561940
    },
    {
      "epoch": 903.47,
      "learning_rate": 0.009689800921221866,
      "loss": 2.3559,
      "step": 561960
    },
    {
      "epoch": 903.5,
      "learning_rate": 0.009686585490353698,
      "loss": 2.3666,
      "step": 561980
    },
    {
      "epoch": 903.54,
      "learning_rate": 0.009683370059485528,
      "loss": 2.3524,
      "step": 562000
    },
    {
      "epoch": 903.57,
      "learning_rate": 0.00968015462861736,
      "loss": 2.353,
      "step": 562020
    },
    {
      "epoch": 903.6,
      "learning_rate": 0.009676939197749191,
      "loss": 2.3551,
      "step": 562040
    },
    {
      "epoch": 903.63,
      "learning_rate": 0.009673723766881033,
      "loss": 2.3528,
      "step": 562060
    },
    {
      "epoch": 903.67,
      "learning_rate": 0.009670508336012863,
      "loss": 2.3587,
      "step": 562080
    },
    {
      "epoch": 903.7,
      "learning_rate": 0.009667292905144695,
      "loss": 2.3448,
      "step": 562100
    },
    {
      "epoch": 903.73,
      "learning_rate": 0.009664077474276524,
      "loss": 2.3455,
      "step": 562120
    },
    {
      "epoch": 903.76,
      "learning_rate": 0.009660862043408356,
      "loss": 2.3391,
      "step": 562140
    },
    {
      "epoch": 903.79,
      "learning_rate": 0.009657646612540198,
      "loss": 2.3564,
      "step": 562160
    },
    {
      "epoch": 903.83,
      "learning_rate": 0.009654431181672028,
      "loss": 2.3378,
      "step": 562180
    },
    {
      "epoch": 903.86,
      "learning_rate": 0.00965121575080386,
      "loss": 2.356,
      "step": 562200
    },
    {
      "epoch": 903.89,
      "learning_rate": 0.00964800031993569,
      "loss": 2.3456,
      "step": 562220
    },
    {
      "epoch": 903.92,
      "learning_rate": 0.009644784889067521,
      "loss": 2.3621,
      "step": 562240
    },
    {
      "epoch": 903.95,
      "learning_rate": 0.00964156945819935,
      "loss": 2.3481,
      "step": 562260
    },
    {
      "epoch": 903.99,
      "learning_rate": 0.009638354027331193,
      "loss": 2.363,
      "step": 562280
    },
    {
      "epoch": 904.0,
      "eval_accuracy": {
        "accuracy": 0.4666873979631501
      },
      "eval_loss": 2.475123167037964,
      "eval_runtime": 3.4511,
      "eval_samples_per_second": 3727.177,
      "eval_steps_per_second": 58.242,
      "step": 562288
    },
    {
      "epoch": 904.02,
      "learning_rate": 0.009635138596463024,
      "loss": 2.3779,
      "step": 562300
    },
    {
      "epoch": 904.05,
      "learning_rate": 0.009631923165594854,
      "loss": 2.357,
      "step": 562320
    },
    {
      "epoch": 904.08,
      "learning_rate": 0.009628707734726686,
      "loss": 2.3614,
      "step": 562340
    },
    {
      "epoch": 904.12,
      "learning_rate": 0.009625492303858518,
      "loss": 2.3566,
      "step": 562360
    },
    {
      "epoch": 904.15,
      "learning_rate": 0.00962227687299036,
      "loss": 2.3526,
      "step": 562380
    },
    {
      "epoch": 904.18,
      "learning_rate": 0.00961906144212219,
      "loss": 2.3492,
      "step": 562400
    },
    {
      "epoch": 904.21,
      "learning_rate": 0.009615846011254021,
      "loss": 2.366,
      "step": 562420
    },
    {
      "epoch": 904.24,
      "learning_rate": 0.009612630580385851,
      "loss": 2.3479,
      "step": 562440
    },
    {
      "epoch": 904.28,
      "learning_rate": 0.009609415149517683,
      "loss": 2.3464,
      "step": 562460
    },
    {
      "epoch": 904.31,
      "learning_rate": 0.009606199718649512,
      "loss": 2.346,
      "step": 562480
    },
    {
      "epoch": 904.34,
      "learning_rate": 0.009602984287781354,
      "loss": 2.3231,
      "step": 562500
    },
    {
      "epoch": 904.37,
      "learning_rate": 0.009599768856913186,
      "loss": 2.3561,
      "step": 562520
    },
    {
      "epoch": 904.41,
      "learning_rate": 0.009596553426045016,
      "loss": 2.3518,
      "step": 562540
    },
    {
      "epoch": 904.44,
      "learning_rate": 0.009593337995176848,
      "loss": 2.3549,
      "step": 562560
    },
    {
      "epoch": 904.47,
      "learning_rate": 0.009590122564308677,
      "loss": 2.3524,
      "step": 562580
    },
    {
      "epoch": 904.5,
      "learning_rate": 0.009586907133440509,
      "loss": 2.3547,
      "step": 562600
    },
    {
      "epoch": 904.53,
      "learning_rate": 0.009583691702572351,
      "loss": 2.3458,
      "step": 562620
    },
    {
      "epoch": 904.57,
      "learning_rate": 0.009580476271704181,
      "loss": 2.3717,
      "step": 562640
    },
    {
      "epoch": 904.6,
      "learning_rate": 0.009577260840836013,
      "loss": 2.3549,
      "step": 562660
    },
    {
      "epoch": 904.63,
      "learning_rate": 0.009574045409967844,
      "loss": 2.3534,
      "step": 562680
    },
    {
      "epoch": 904.66,
      "learning_rate": 0.009570829979099674,
      "loss": 2.3369,
      "step": 562700
    },
    {
      "epoch": 904.69,
      "learning_rate": 0.009567614548231516,
      "loss": 2.3658,
      "step": 562720
    },
    {
      "epoch": 904.73,
      "learning_rate": 0.009564399117363348,
      "loss": 2.3418,
      "step": 562740
    },
    {
      "epoch": 904.76,
      "learning_rate": 0.009561183686495178,
      "loss": 2.3525,
      "step": 562760
    },
    {
      "epoch": 904.79,
      "learning_rate": 0.00955796825562701,
      "loss": 2.3663,
      "step": 562780
    },
    {
      "epoch": 904.82,
      "learning_rate": 0.009554752824758839,
      "loss": 2.3513,
      "step": 562800
    },
    {
      "epoch": 904.86,
      "learning_rate": 0.00955153739389067,
      "loss": 2.372,
      "step": 562820
    },
    {
      "epoch": 904.89,
      "learning_rate": 0.009548321963022513,
      "loss": 2.3514,
      "step": 562840
    },
    {
      "epoch": 904.92,
      "learning_rate": 0.009545106532154343,
      "loss": 2.3427,
      "step": 562860
    },
    {
      "epoch": 904.95,
      "learning_rate": 0.009541891101286174,
      "loss": 2.3282,
      "step": 562880
    },
    {
      "epoch": 904.98,
      "learning_rate": 0.009538675670418004,
      "loss": 2.3448,
      "step": 562900
    },
    {
      "epoch": 905.0,
      "eval_accuracy": {
        "accuracy": 0.47422840705900643
      },
      "eval_loss": 2.463005781173706,
      "eval_runtime": 3.961,
      "eval_samples_per_second": 3247.375,
      "eval_steps_per_second": 50.744,
      "step": 562910
    },
    {
      "epoch": 905.02,
      "learning_rate": 0.009535460239549836,
      "loss": 2.3445,
      "step": 562920
    },
    {
      "epoch": 905.05,
      "learning_rate": 0.009532244808681667,
      "loss": 2.3382,
      "step": 562940
    },
    {
      "epoch": 905.08,
      "learning_rate": 0.00952902937781351,
      "loss": 2.3526,
      "step": 562960
    },
    {
      "epoch": 905.11,
      "learning_rate": 0.00952581394694534,
      "loss": 2.3455,
      "step": 562980
    },
    {
      "epoch": 905.14,
      "learning_rate": 0.00952259851607717,
      "loss": 2.3547,
      "step": 563000
    },
    {
      "epoch": 905.18,
      "learning_rate": 0.009519383085209,
      "loss": 2.3641,
      "step": 563020
    },
    {
      "epoch": 905.21,
      "learning_rate": 0.009516167654340832,
      "loss": 2.3519,
      "step": 563040
    },
    {
      "epoch": 905.24,
      "learning_rate": 0.009512952223472674,
      "loss": 2.3582,
      "step": 563060
    },
    {
      "epoch": 905.27,
      "learning_rate": 0.009509736792604504,
      "loss": 2.3556,
      "step": 563080
    },
    {
      "epoch": 905.31,
      "learning_rate": 0.009506521361736336,
      "loss": 2.3308,
      "step": 563100
    },
    {
      "epoch": 905.34,
      "learning_rate": 0.009503305930868166,
      "loss": 2.3479,
      "step": 563120
    },
    {
      "epoch": 905.37,
      "learning_rate": 0.009500090499999997,
      "loss": 2.3497,
      "step": 563140
    },
    {
      "epoch": 905.4,
      "learning_rate": 0.009496875069131827,
      "loss": 2.3331,
      "step": 563160
    },
    {
      "epoch": 905.43,
      "learning_rate": 0.009493659638263669,
      "loss": 2.3362,
      "step": 563180
    },
    {
      "epoch": 905.47,
      "learning_rate": 0.0094904442073955,
      "loss": 2.3488,
      "step": 563200
    },
    {
      "epoch": 905.5,
      "learning_rate": 0.00948722877652733,
      "loss": 2.3644,
      "step": 563220
    },
    {
      "epoch": 905.53,
      "learning_rate": 0.009484013345659162,
      "loss": 2.3338,
      "step": 563240
    },
    {
      "epoch": 905.56,
      "learning_rate": 0.009480797914790994,
      "loss": 2.3436,
      "step": 563260
    },
    {
      "epoch": 905.59,
      "learning_rate": 0.009477582483922824,
      "loss": 2.3584,
      "step": 563280
    },
    {
      "epoch": 905.63,
      "learning_rate": 0.009474367053054666,
      "loss": 2.3597,
      "step": 563300
    },
    {
      "epoch": 905.66,
      "learning_rate": 0.009471151622186497,
      "loss": 2.3549,
      "step": 563320
    },
    {
      "epoch": 905.69,
      "learning_rate": 0.009467936191318327,
      "loss": 2.3484,
      "step": 563340
    },
    {
      "epoch": 905.72,
      "learning_rate": 0.009464720760450159,
      "loss": 2.3627,
      "step": 563360
    },
    {
      "epoch": 905.76,
      "learning_rate": 0.009461505329581989,
      "loss": 2.3448,
      "step": 563380
    },
    {
      "epoch": 905.79,
      "learning_rate": 0.00945828989871383,
      "loss": 2.3535,
      "step": 563400
    },
    {
      "epoch": 905.82,
      "learning_rate": 0.009455074467845662,
      "loss": 2.3519,
      "step": 563420
    },
    {
      "epoch": 905.85,
      "learning_rate": 0.009451859036977492,
      "loss": 2.3628,
      "step": 563440
    },
    {
      "epoch": 905.88,
      "learning_rate": 0.009448643606109324,
      "loss": 2.3509,
      "step": 563460
    },
    {
      "epoch": 905.92,
      "learning_rate": 0.009445428175241154,
      "loss": 2.3546,
      "step": 563480
    },
    {
      "epoch": 905.95,
      "learning_rate": 0.009442212744372985,
      "loss": 2.3243,
      "step": 563500
    },
    {
      "epoch": 905.98,
      "learning_rate": 0.009438997313504827,
      "loss": 2.3656,
      "step": 563520
    },
    {
      "epoch": 906.0,
      "eval_accuracy": {
        "accuracy": 0.4700303195211071
      },
      "eval_loss": 2.4743804931640625,
      "eval_runtime": 3.2282,
      "eval_samples_per_second": 3984.53,
      "eval_steps_per_second": 62.263,
      "step": 563532
    },
    {
      "epoch": 906.01,
      "learning_rate": 0.009435781882636657,
      "loss": 2.3486,
      "step": 563540
    },
    {
      "epoch": 906.05,
      "learning_rate": 0.009432566451768489,
      "loss": 2.3489,
      "step": 563560
    },
    {
      "epoch": 906.08,
      "learning_rate": 0.00942935102090032,
      "loss": 2.3612,
      "step": 563580
    },
    {
      "epoch": 906.11,
      "learning_rate": 0.00942613559003215,
      "loss": 2.3444,
      "step": 563600
    },
    {
      "epoch": 906.14,
      "learning_rate": 0.009422920159163982,
      "loss": 2.359,
      "step": 563620
    },
    {
      "epoch": 906.17,
      "learning_rate": 0.009419704728295824,
      "loss": 2.3556,
      "step": 563640
    },
    {
      "epoch": 906.21,
      "learning_rate": 0.009416489297427654,
      "loss": 2.3447,
      "step": 563660
    },
    {
      "epoch": 906.24,
      "learning_rate": 0.009413273866559485,
      "loss": 2.3495,
      "step": 563680
    },
    {
      "epoch": 906.27,
      "learning_rate": 0.009410058435691315,
      "loss": 2.3478,
      "step": 563700
    },
    {
      "epoch": 906.3,
      "learning_rate": 0.009406843004823147,
      "loss": 2.3508,
      "step": 563720
    },
    {
      "epoch": 906.33,
      "learning_rate": 0.009403627573954989,
      "loss": 2.3726,
      "step": 563740
    },
    {
      "epoch": 906.37,
      "learning_rate": 0.009400412143086819,
      "loss": 2.3483,
      "step": 563760
    },
    {
      "epoch": 906.4,
      "learning_rate": 0.00939719671221865,
      "loss": 2.333,
      "step": 563780
    },
    {
      "epoch": 906.43,
      "learning_rate": 0.00939398128135048,
      "loss": 2.3448,
      "step": 563800
    },
    {
      "epoch": 906.46,
      "learning_rate": 0.009390765850482312,
      "loss": 2.3402,
      "step": 563820
    },
    {
      "epoch": 906.5,
      "learning_rate": 0.009387550419614143,
      "loss": 2.3667,
      "step": 563840
    },
    {
      "epoch": 906.53,
      "learning_rate": 0.009384334988745984,
      "loss": 2.3621,
      "step": 563860
    },
    {
      "epoch": 906.56,
      "learning_rate": 0.009381119557877815,
      "loss": 2.3372,
      "step": 563880
    },
    {
      "epoch": 906.59,
      "learning_rate": 0.009377904127009647,
      "loss": 2.3626,
      "step": 563900
    },
    {
      "epoch": 906.62,
      "learning_rate": 0.009374688696141477,
      "loss": 2.3425,
      "step": 563920
    },
    {
      "epoch": 906.66,
      "learning_rate": 0.009371473265273308,
      "loss": 2.3541,
      "step": 563940
    },
    {
      "epoch": 906.69,
      "learning_rate": 0.00936825783440515,
      "loss": 2.3461,
      "step": 563960
    },
    {
      "epoch": 906.72,
      "learning_rate": 0.00936504240353698,
      "loss": 2.3493,
      "step": 563980
    },
    {
      "epoch": 906.75,
      "learning_rate": 0.009361826972668812,
      "loss": 2.3624,
      "step": 564000
    },
    {
      "epoch": 906.78,
      "learning_rate": 0.009358611541800642,
      "loss": 2.3397,
      "step": 564020
    },
    {
      "epoch": 906.82,
      "learning_rate": 0.009355396110932473,
      "loss": 2.3596,
      "step": 564040
    },
    {
      "epoch": 906.85,
      "learning_rate": 0.009352180680064303,
      "loss": 2.3392,
      "step": 564060
    },
    {
      "epoch": 906.88,
      "learning_rate": 0.009349126020739547,
      "loss": 2.3354,
      "step": 564080
    },
    {
      "epoch": 906.91,
      "learning_rate": 0.009345910589871376,
      "loss": 2.3447,
      "step": 564100
    },
    {
      "epoch": 906.95,
      "learning_rate": 0.009342695159003218,
      "loss": 2.3583,
      "step": 564120
    },
    {
      "epoch": 906.98,
      "learning_rate": 0.00933947972813505,
      "loss": 2.356,
      "step": 564140
    },
    {
      "epoch": 907.0,
      "eval_accuracy": {
        "accuracy": 0.47135193967192723
      },
      "eval_loss": 2.4617791175842285,
      "eval_runtime": 3.1653,
      "eval_samples_per_second": 4063.754,
      "eval_steps_per_second": 63.501,
      "step": 564154
    },
    {
      "epoch": 907.01,
      "learning_rate": 0.00933626429726688,
      "loss": 2.3609,
      "step": 564160
    },
    {
      "epoch": 907.04,
      "learning_rate": 0.009333048866398711,
      "loss": 2.3577,
      "step": 564180
    },
    {
      "epoch": 907.07,
      "learning_rate": 0.009329833435530541,
      "loss": 2.3782,
      "step": 564200
    },
    {
      "epoch": 907.11,
      "learning_rate": 0.009326618004662383,
      "loss": 2.3276,
      "step": 564220
    },
    {
      "epoch": 907.14,
      "learning_rate": 0.009323402573794215,
      "loss": 2.3646,
      "step": 564240
    },
    {
      "epoch": 907.17,
      "learning_rate": 0.009320187142926047,
      "loss": 2.332,
      "step": 564260
    },
    {
      "epoch": 907.2,
      "learning_rate": 0.009316971712057876,
      "loss": 2.3417,
      "step": 564280
    },
    {
      "epoch": 907.23,
      "learning_rate": 0.009313756281189708,
      "loss": 2.3637,
      "step": 564300
    },
    {
      "epoch": 907.27,
      "learning_rate": 0.009310540850321538,
      "loss": 2.3433,
      "step": 564320
    },
    {
      "epoch": 907.3,
      "learning_rate": 0.00930732541945338,
      "loss": 2.3391,
      "step": 564340
    },
    {
      "epoch": 907.33,
      "learning_rate": 0.009304109988585212,
      "loss": 2.3523,
      "step": 564360
    },
    {
      "epoch": 907.36,
      "learning_rate": 0.009300894557717041,
      "loss": 2.3394,
      "step": 564380
    },
    {
      "epoch": 907.4,
      "learning_rate": 0.009297679126848873,
      "loss": 2.3616,
      "step": 564400
    },
    {
      "epoch": 907.43,
      "learning_rate": 0.009294463695980703,
      "loss": 2.3379,
      "step": 564420
    },
    {
      "epoch": 907.46,
      "learning_rate": 0.009291248265112535,
      "loss": 2.363,
      "step": 564440
    },
    {
      "epoch": 907.49,
      "learning_rate": 0.009288032834244377,
      "loss": 2.3331,
      "step": 564460
    },
    {
      "epoch": 907.52,
      "learning_rate": 0.009284817403376206,
      "loss": 2.3575,
      "step": 564480
    },
    {
      "epoch": 907.56,
      "learning_rate": 0.009281601972508038,
      "loss": 2.3519,
      "step": 564500
    },
    {
      "epoch": 907.59,
      "learning_rate": 0.009278386541639868,
      "loss": 2.3294,
      "step": 564520
    },
    {
      "epoch": 907.62,
      "learning_rate": 0.0092751711107717,
      "loss": 2.3518,
      "step": 564540
    },
    {
      "epoch": 907.65,
      "learning_rate": 0.009271955679903542,
      "loss": 2.3444,
      "step": 564560
    },
    {
      "epoch": 907.68,
      "learning_rate": 0.009268740249035373,
      "loss": 2.3466,
      "step": 564580
    },
    {
      "epoch": 907.72,
      "learning_rate": 0.009265524818167203,
      "loss": 2.3309,
      "step": 564600
    },
    {
      "epoch": 907.75,
      "learning_rate": 0.009262309387299035,
      "loss": 2.3497,
      "step": 564620
    },
    {
      "epoch": 907.78,
      "learning_rate": 0.009259093956430865,
      "loss": 2.3614,
      "step": 564640
    },
    {
      "epoch": 907.81,
      "learning_rate": 0.009255878525562696,
      "loss": 2.3666,
      "step": 564660
    },
    {
      "epoch": 907.85,
      "learning_rate": 0.009252663094694538,
      "loss": 2.355,
      "step": 564680
    },
    {
      "epoch": 907.88,
      "learning_rate": 0.009249447663826368,
      "loss": 2.3584,
      "step": 564700
    },
    {
      "epoch": 907.91,
      "learning_rate": 0.0092462322329582,
      "loss": 2.3646,
      "step": 564720
    },
    {
      "epoch": 907.94,
      "learning_rate": 0.00924301680209003,
      "loss": 2.3182,
      "step": 564740
    },
    {
      "epoch": 907.97,
      "learning_rate": 0.009239801371221861,
      "loss": 2.3454,
      "step": 564760
    },
    {
      "epoch": 908.0,
      "eval_accuracy": {
        "accuracy": 0.4712741973101143
      },
      "eval_loss": 2.4619600772857666,
      "eval_runtime": 3.4021,
      "eval_samples_per_second": 3780.908,
      "eval_steps_per_second": 59.081,
      "step": 564776
    },
    {
      "epoch": 908.01,
      "learning_rate": 0.009236585940353703,
      "loss": 2.3419,
      "step": 564780
    },
    {
      "epoch": 908.04,
      "learning_rate": 0.009233370509485533,
      "loss": 2.3623,
      "step": 564800
    },
    {
      "epoch": 908.07,
      "learning_rate": 0.009230155078617365,
      "loss": 2.3506,
      "step": 564820
    },
    {
      "epoch": 908.1,
      "learning_rate": 0.009226939647749196,
      "loss": 2.3301,
      "step": 564840
    },
    {
      "epoch": 908.14,
      "learning_rate": 0.009223724216881026,
      "loss": 2.3305,
      "step": 564860
    },
    {
      "epoch": 908.17,
      "learning_rate": 0.009220508786012858,
      "loss": 2.3386,
      "step": 564880
    },
    {
      "epoch": 908.2,
      "learning_rate": 0.0092172933551447,
      "loss": 2.3465,
      "step": 564900
    },
    {
      "epoch": 908.23,
      "learning_rate": 0.00921407792427653,
      "loss": 2.3567,
      "step": 564920
    },
    {
      "epoch": 908.26,
      "learning_rate": 0.009210862493408361,
      "loss": 2.3443,
      "step": 564940
    },
    {
      "epoch": 908.3,
      "learning_rate": 0.009207647062540191,
      "loss": 2.3445,
      "step": 564960
    },
    {
      "epoch": 908.33,
      "learning_rate": 0.009204431631672023,
      "loss": 2.3525,
      "step": 564980
    },
    {
      "epoch": 908.36,
      "learning_rate": 0.009201216200803853,
      "loss": 2.3385,
      "step": 565000
    },
    {
      "epoch": 908.39,
      "learning_rate": 0.009198000769935695,
      "loss": 2.3464,
      "step": 565020
    },
    {
      "epoch": 908.42,
      "learning_rate": 0.009194785339067526,
      "loss": 2.3658,
      "step": 565040
    },
    {
      "epoch": 908.46,
      "learning_rate": 0.009191569908199356,
      "loss": 2.3578,
      "step": 565060
    },
    {
      "epoch": 908.49,
      "learning_rate": 0.009188354477331188,
      "loss": 2.3408,
      "step": 565080
    },
    {
      "epoch": 908.52,
      "learning_rate": 0.009185139046463018,
      "loss": 2.3382,
      "step": 565100
    },
    {
      "epoch": 908.55,
      "learning_rate": 0.00918192361559486,
      "loss": 2.3432,
      "step": 565120
    },
    {
      "epoch": 908.59,
      "learning_rate": 0.009178708184726691,
      "loss": 2.359,
      "step": 565140
    },
    {
      "epoch": 908.62,
      "learning_rate": 0.009175492753858523,
      "loss": 2.3272,
      "step": 565160
    },
    {
      "epoch": 908.65,
      "learning_rate": 0.009172277322990353,
      "loss": 2.3554,
      "step": 565180
    },
    {
      "epoch": 908.68,
      "learning_rate": 0.009169061892122184,
      "loss": 2.3619,
      "step": 565200
    },
    {
      "epoch": 908.71,
      "learning_rate": 0.009165846461254014,
      "loss": 2.3747,
      "step": 565220
    },
    {
      "epoch": 908.75,
      "learning_rate": 0.009162631030385856,
      "loss": 2.3433,
      "step": 565240
    },
    {
      "epoch": 908.78,
      "learning_rate": 0.009159415599517688,
      "loss": 2.338,
      "step": 565260
    },
    {
      "epoch": 908.81,
      "learning_rate": 0.009156200168649518,
      "loss": 2.3621,
      "step": 565280
    },
    {
      "epoch": 908.84,
      "learning_rate": 0.00915298473778135,
      "loss": 2.3479,
      "step": 565300
    },
    {
      "epoch": 908.87,
      "learning_rate": 0.00914976930691318,
      "loss": 2.3473,
      "step": 565320
    },
    {
      "epoch": 908.91,
      "learning_rate": 0.00914655387604501,
      "loss": 2.3435,
      "step": 565340
    },
    {
      "epoch": 908.94,
      "learning_rate": 0.009143338445176853,
      "loss": 2.3526,
      "step": 565360
    },
    {
      "epoch": 908.97,
      "learning_rate": 0.009140123014308683,
      "loss": 2.3394,
      "step": 565380
    },
    {
      "epoch": 909.0,
      "eval_accuracy": {
        "accuracy": 0.4747726035916971
      },
      "eval_loss": 2.4678444862365723,
      "eval_runtime": 3.4514,
      "eval_samples_per_second": 3726.841,
      "eval_steps_per_second": 58.236,
      "step": 565398
    },
    {
      "epoch": 909.0,
      "learning_rate": 0.009136907583440514,
      "loss": 2.3447,
      "step": 565400
    },
    {
      "epoch": 909.04,
      "learning_rate": 0.009133692152572344,
      "loss": 2.3568,
      "step": 565420
    },
    {
      "epoch": 909.07,
      "learning_rate": 0.009130476721704176,
      "loss": 2.3465,
      "step": 565440
    },
    {
      "epoch": 909.1,
      "learning_rate": 0.009127261290836018,
      "loss": 2.3315,
      "step": 565460
    },
    {
      "epoch": 909.13,
      "learning_rate": 0.00912404585996785,
      "loss": 2.3313,
      "step": 565480
    },
    {
      "epoch": 909.16,
      "learning_rate": 0.00912083042909968,
      "loss": 2.3392,
      "step": 565500
    },
    {
      "epoch": 909.2,
      "learning_rate": 0.009117614998231511,
      "loss": 2.3427,
      "step": 565520
    },
    {
      "epoch": 909.23,
      "learning_rate": 0.00911439956736334,
      "loss": 2.361,
      "step": 565540
    },
    {
      "epoch": 909.26,
      "learning_rate": 0.009111184136495172,
      "loss": 2.3629,
      "step": 565560
    },
    {
      "epoch": 909.29,
      "learning_rate": 0.009107968705627014,
      "loss": 2.3351,
      "step": 565580
    },
    {
      "epoch": 909.32,
      "learning_rate": 0.009104753274758844,
      "loss": 2.3445,
      "step": 565600
    },
    {
      "epoch": 909.36,
      "learning_rate": 0.009101537843890676,
      "loss": 2.3468,
      "step": 565620
    },
    {
      "epoch": 909.39,
      "learning_rate": 0.009098322413022506,
      "loss": 2.3476,
      "step": 565640
    },
    {
      "epoch": 909.42,
      "learning_rate": 0.009095106982154337,
      "loss": 2.3515,
      "step": 565660
    },
    {
      "epoch": 909.45,
      "learning_rate": 0.009091891551286167,
      "loss": 2.3348,
      "step": 565680
    },
    {
      "epoch": 909.49,
      "learning_rate": 0.00908867612041801,
      "loss": 2.345,
      "step": 565700
    },
    {
      "epoch": 909.52,
      "learning_rate": 0.009085460689549841,
      "loss": 2.3452,
      "step": 565720
    },
    {
      "epoch": 909.55,
      "learning_rate": 0.00908224525868167,
      "loss": 2.3557,
      "step": 565740
    },
    {
      "epoch": 909.58,
      "learning_rate": 0.009079029827813502,
      "loss": 2.3505,
      "step": 565760
    },
    {
      "epoch": 909.61,
      "learning_rate": 0.009075814396945334,
      "loss": 2.3488,
      "step": 565780
    },
    {
      "epoch": 909.65,
      "learning_rate": 0.009072598966077176,
      "loss": 2.3493,
      "step": 565800
    },
    {
      "epoch": 909.68,
      "learning_rate": 0.009069383535209006,
      "loss": 2.3373,
      "step": 565820
    },
    {
      "epoch": 909.71,
      "learning_rate": 0.009066168104340838,
      "loss": 2.3537,
      "step": 565840
    },
    {
      "epoch": 909.74,
      "learning_rate": 0.009062952673472667,
      "loss": 2.3342,
      "step": 565860
    },
    {
      "epoch": 909.77,
      "learning_rate": 0.009059737242604499,
      "loss": 2.3521,
      "step": 565880
    },
    {
      "epoch": 909.81,
      "learning_rate": 0.009056521811736329,
      "loss": 2.3454,
      "step": 565900
    },
    {
      "epoch": 909.84,
      "learning_rate": 0.009053306380868171,
      "loss": 2.3657,
      "step": 565920
    },
    {
      "epoch": 909.87,
      "learning_rate": 0.009050090950000002,
      "loss": 2.3349,
      "step": 565940
    },
    {
      "epoch": 909.9,
      "learning_rate": 0.009046875519131832,
      "loss": 2.355,
      "step": 565960
    },
    {
      "epoch": 909.94,
      "learning_rate": 0.009043660088263664,
      "loss": 2.3601,
      "step": 565980
    },
    {
      "epoch": 909.97,
      "learning_rate": 0.009040444657395494,
      "loss": 2.3528,
      "step": 566000
    },
    {
      "epoch": 910.0,
      "learning_rate": 0.009037229226527325,
      "loss": 2.3494,
      "step": 566020
    },
    {
      "epoch": 910.0,
      "eval_accuracy": {
        "accuracy": 0.47360646816450286
      },
      "eval_loss": 2.4678518772125244,
      "eval_runtime": 3.356,
      "eval_samples_per_second": 3832.801,
      "eval_steps_per_second": 59.892,
      "step": 566020
    },
    {
      "epoch": 910.03,
      "learning_rate": 0.009034013795659167,
      "loss": 2.3317,
      "step": 566040
    },
    {
      "epoch": 910.06,
      "learning_rate": 0.009030798364790997,
      "loss": 2.347,
      "step": 566060
    },
    {
      "epoch": 910.1,
      "learning_rate": 0.009027582933922829,
      "loss": 2.3361,
      "step": 566080
    },
    {
      "epoch": 910.13,
      "learning_rate": 0.00902436750305466,
      "loss": 2.3415,
      "step": 566100
    },
    {
      "epoch": 910.16,
      "learning_rate": 0.00902115207218649,
      "loss": 2.3495,
      "step": 566120
    },
    {
      "epoch": 910.19,
      "learning_rate": 0.009017936641318332,
      "loss": 2.3481,
      "step": 566140
    },
    {
      "epoch": 910.23,
      "learning_rate": 0.009014721210450164,
      "loss": 2.3492,
      "step": 566160
    },
    {
      "epoch": 910.26,
      "learning_rate": 0.009011505779581994,
      "loss": 2.3594,
      "step": 566180
    },
    {
      "epoch": 910.29,
      "learning_rate": 0.009008290348713826,
      "loss": 2.3419,
      "step": 566200
    },
    {
      "epoch": 910.32,
      "learning_rate": 0.009005074917845655,
      "loss": 2.3504,
      "step": 566220
    },
    {
      "epoch": 910.35,
      "learning_rate": 0.009001859486977487,
      "loss": 2.3469,
      "step": 566240
    },
    {
      "epoch": 910.39,
      "learning_rate": 0.008998644056109329,
      "loss": 2.3405,
      "step": 566260
    },
    {
      "epoch": 910.42,
      "learning_rate": 0.008995428625241159,
      "loss": 2.3443,
      "step": 566280
    },
    {
      "epoch": 910.45,
      "learning_rate": 0.00899221319437299,
      "loss": 2.3552,
      "step": 566300
    },
    {
      "epoch": 910.48,
      "learning_rate": 0.00898899776350482,
      "loss": 2.3572,
      "step": 566320
    },
    {
      "epoch": 910.51,
      "learning_rate": 0.008985782332636652,
      "loss": 2.3433,
      "step": 566340
    },
    {
      "epoch": 910.55,
      "learning_rate": 0.008982566901768484,
      "loss": 2.3721,
      "step": 566360
    },
    {
      "epoch": 910.58,
      "learning_rate": 0.008979351470900326,
      "loss": 2.3496,
      "step": 566380
    },
    {
      "epoch": 910.61,
      "learning_rate": 0.008976136040032156,
      "loss": 2.3381,
      "step": 566400
    },
    {
      "epoch": 910.64,
      "learning_rate": 0.008972920609163987,
      "loss": 2.357,
      "step": 566420
    },
    {
      "epoch": 910.68,
      "learning_rate": 0.008969705178295817,
      "loss": 2.3662,
      "step": 566440
    },
    {
      "epoch": 910.71,
      "learning_rate": 0.008966489747427649,
      "loss": 2.3554,
      "step": 566460
    },
    {
      "epoch": 910.74,
      "learning_rate": 0.00896327431655949,
      "loss": 2.336,
      "step": 566480
    },
    {
      "epoch": 910.77,
      "learning_rate": 0.00896005888569132,
      "loss": 2.3319,
      "step": 566500
    },
    {
      "epoch": 910.8,
      "learning_rate": 0.008956843454823152,
      "loss": 2.3369,
      "step": 566520
    },
    {
      "epoch": 910.84,
      "learning_rate": 0.008953628023954982,
      "loss": 2.3452,
      "step": 566540
    },
    {
      "epoch": 910.87,
      "learning_rate": 0.008950412593086814,
      "loss": 2.3504,
      "step": 566560
    },
    {
      "epoch": 910.9,
      "learning_rate": 0.008947197162218644,
      "loss": 2.3495,
      "step": 566580
    },
    {
      "epoch": 910.93,
      "learning_rate": 0.008943981731350486,
      "loss": 2.3433,
      "step": 566600
    },
    {
      "epoch": 910.96,
      "learning_rate": 0.008940766300482317,
      "loss": 2.3342,
      "step": 566620
    },
    {
      "epoch": 911.0,
      "learning_rate": 0.008937550869614147,
      "loss": 2.3379,
      "step": 566640
    },
    {
      "epoch": 911.0,
      "eval_accuracy": {
        "accuracy": 0.4721293632900567
      },
      "eval_loss": 2.466259241104126,
      "eval_runtime": 3.1495,
      "eval_samples_per_second": 4084.097,
      "eval_steps_per_second": 63.819,
      "step": 566642
    },
    {
      "epoch": 911.03,
      "learning_rate": 0.008934335438745979,
      "loss": 2.3735,
      "step": 566660
    },
    {
      "epoch": 911.06,
      "learning_rate": 0.00893112000787781,
      "loss": 2.3271,
      "step": 566680
    },
    {
      "epoch": 911.09,
      "learning_rate": 0.008927904577009652,
      "loss": 2.3376,
      "step": 566700
    },
    {
      "epoch": 911.13,
      "learning_rate": 0.008924689146141482,
      "loss": 2.3518,
      "step": 566720
    },
    {
      "epoch": 911.16,
      "learning_rate": 0.008921473715273314,
      "loss": 2.344,
      "step": 566740
    },
    {
      "epoch": 911.19,
      "learning_rate": 0.008918258284405144,
      "loss": 2.3344,
      "step": 566760
    },
    {
      "epoch": 911.22,
      "learning_rate": 0.008915042853536975,
      "loss": 2.3412,
      "step": 566780
    },
    {
      "epoch": 911.25,
      "learning_rate": 0.008911827422668805,
      "loss": 2.3474,
      "step": 566800
    },
    {
      "epoch": 911.29,
      "learning_rate": 0.008908611991800647,
      "loss": 2.3401,
      "step": 566820
    },
    {
      "epoch": 911.32,
      "learning_rate": 0.008905396560932479,
      "loss": 2.3563,
      "step": 566840
    },
    {
      "epoch": 911.35,
      "learning_rate": 0.008902181130064309,
      "loss": 2.3804,
      "step": 566860
    },
    {
      "epoch": 911.38,
      "learning_rate": 0.00889896569919614,
      "loss": 2.355,
      "step": 566880
    },
    {
      "epoch": 911.41,
      "learning_rate": 0.00889575026832797,
      "loss": 2.3573,
      "step": 566900
    },
    {
      "epoch": 911.45,
      "learning_rate": 0.008892534837459802,
      "loss": 2.3441,
      "step": 566920
    },
    {
      "epoch": 911.48,
      "learning_rate": 0.008889319406591644,
      "loss": 2.3395,
      "step": 566940
    },
    {
      "epoch": 911.51,
      "learning_rate": 0.008886103975723474,
      "loss": 2.3439,
      "step": 566960
    },
    {
      "epoch": 911.54,
      "learning_rate": 0.008882888544855305,
      "loss": 2.3389,
      "step": 566980
    },
    {
      "epoch": 911.58,
      "learning_rate": 0.008879673113987137,
      "loss": 2.3744,
      "step": 567000
    },
    {
      "epoch": 911.61,
      "learning_rate": 0.008876457683118967,
      "loss": 2.3485,
      "step": 567020
    },
    {
      "epoch": 911.64,
      "learning_rate": 0.008873242252250809,
      "loss": 2.3317,
      "step": 567040
    },
    {
      "epoch": 911.67,
      "learning_rate": 0.00887002682138264,
      "loss": 2.3502,
      "step": 567060
    },
    {
      "epoch": 911.7,
      "learning_rate": 0.00886681139051447,
      "loss": 2.3454,
      "step": 567080
    },
    {
      "epoch": 911.74,
      "learning_rate": 0.008863595959646302,
      "loss": 2.3422,
      "step": 567100
    },
    {
      "epoch": 911.77,
      "learning_rate": 0.008860380528778132,
      "loss": 2.352,
      "step": 567120
    },
    {
      "epoch": 911.8,
      "learning_rate": 0.008857165097909963,
      "loss": 2.3363,
      "step": 567140
    },
    {
      "epoch": 911.83,
      "learning_rate": 0.008853949667041805,
      "loss": 2.3318,
      "step": 567160
    },
    {
      "epoch": 911.86,
      "learning_rate": 0.008850734236173635,
      "loss": 2.3551,
      "step": 567180
    },
    {
      "epoch": 911.9,
      "learning_rate": 0.008847518805305467,
      "loss": 2.3534,
      "step": 567200
    },
    {
      "epoch": 911.93,
      "learning_rate": 0.008844303374437297,
      "loss": 2.3437,
      "step": 567220
    },
    {
      "epoch": 911.96,
      "learning_rate": 0.008841087943569128,
      "loss": 2.3407,
      "step": 567240
    },
    {
      "epoch": 911.99,
      "learning_rate": 0.00883787251270096,
      "loss": 2.3331,
      "step": 567260
    },
    {
      "epoch": 912.0,
      "eval_accuracy": {
        "accuracy": 0.47197387856643086
      },
      "eval_loss": 2.469789505004883,
      "eval_runtime": 3.1237,
      "eval_samples_per_second": 4117.881,
      "eval_steps_per_second": 64.347,
      "step": 567264
    },
    {
      "epoch": 912.03,
      "learning_rate": 0.0088346570818328,
      "loss": 2.3335,
      "step": 567280
    },
    {
      "epoch": 912.06,
      "learning_rate": 0.008831441650964632,
      "loss": 2.343,
      "step": 567300
    },
    {
      "epoch": 912.09,
      "learning_rate": 0.008828226220096463,
      "loss": 2.3486,
      "step": 567320
    },
    {
      "epoch": 912.12,
      "learning_rate": 0.008825010789228293,
      "loss": 2.3301,
      "step": 567340
    },
    {
      "epoch": 912.15,
      "learning_rate": 0.008821795358360125,
      "loss": 2.3572,
      "step": 567360
    },
    {
      "epoch": 912.19,
      "learning_rate": 0.008818579927491967,
      "loss": 2.345,
      "step": 567380
    },
    {
      "epoch": 912.22,
      "learning_rate": 0.008815364496623797,
      "loss": 2.3456,
      "step": 567400
    },
    {
      "epoch": 912.25,
      "learning_rate": 0.008812149065755628,
      "loss": 2.3557,
      "step": 567420
    },
    {
      "epoch": 912.28,
      "learning_rate": 0.008808933634887458,
      "loss": 2.348,
      "step": 567440
    },
    {
      "epoch": 912.32,
      "learning_rate": 0.00880571820401929,
      "loss": 2.3434,
      "step": 567460
    },
    {
      "epoch": 912.35,
      "learning_rate": 0.00880250277315112,
      "loss": 2.3343,
      "step": 567480
    },
    {
      "epoch": 912.38,
      "learning_rate": 0.008799287342282962,
      "loss": 2.3225,
      "step": 567500
    },
    {
      "epoch": 912.41,
      "learning_rate": 0.008796071911414793,
      "loss": 2.347,
      "step": 567520
    },
    {
      "epoch": 912.44,
      "learning_rate": 0.008792856480546623,
      "loss": 2.3488,
      "step": 567540
    },
    {
      "epoch": 912.48,
      "learning_rate": 0.008789641049678455,
      "loss": 2.3558,
      "step": 567560
    },
    {
      "epoch": 912.51,
      "learning_rate": 0.008786425618810286,
      "loss": 2.3407,
      "step": 567580
    },
    {
      "epoch": 912.54,
      "learning_rate": 0.008783210187942116,
      "loss": 2.3603,
      "step": 567600
    },
    {
      "epoch": 912.57,
      "learning_rate": 0.008779994757073958,
      "loss": 2.355,
      "step": 567620
    },
    {
      "epoch": 912.6,
      "learning_rate": 0.00877677932620579,
      "loss": 2.3422,
      "step": 567640
    },
    {
      "epoch": 912.64,
      "learning_rate": 0.00877356389533762,
      "loss": 2.3304,
      "step": 567660
    },
    {
      "epoch": 912.67,
      "learning_rate": 0.008770348464469451,
      "loss": 2.3379,
      "step": 567680
    },
    {
      "epoch": 912.7,
      "learning_rate": 0.008767133033601281,
      "loss": 2.3452,
      "step": 567700
    },
    {
      "epoch": 912.73,
      "learning_rate": 0.008763917602733123,
      "loss": 2.3437,
      "step": 567720
    },
    {
      "epoch": 912.77,
      "learning_rate": 0.008760702171864955,
      "loss": 2.346,
      "step": 567740
    },
    {
      "epoch": 912.8,
      "learning_rate": 0.008757486740996785,
      "loss": 2.3519,
      "step": 567760
    },
    {
      "epoch": 912.83,
      "learning_rate": 0.008754271310128616,
      "loss": 2.3493,
      "step": 567780
    },
    {
      "epoch": 912.86,
      "learning_rate": 0.008751055879260446,
      "loss": 2.3608,
      "step": 567800
    },
    {
      "epoch": 912.89,
      "learning_rate": 0.008747840448392278,
      "loss": 2.3451,
      "step": 567820
    },
    {
      "epoch": 912.93,
      "learning_rate": 0.00874462501752412,
      "loss": 2.3344,
      "step": 567840
    },
    {
      "epoch": 912.96,
      "learning_rate": 0.00874140958665595,
      "loss": 2.3317,
      "step": 567860
    },
    {
      "epoch": 912.99,
      "learning_rate": 0.008738194155787781,
      "loss": 2.3348,
      "step": 567880
    },
    {
      "epoch": 913.0,
      "eval_accuracy": {
        "accuracy": 0.4753945424862007
      },
      "eval_loss": 2.4619951248168945,
      "eval_runtime": 3.0662,
      "eval_samples_per_second": 4195.038,
      "eval_steps_per_second": 65.553,
      "step": 567886
    },
    {
      "epoch": 913.02,
      "learning_rate": 0.008734978724919613,
      "loss": 2.3613,
      "step": 567900
    },
    {
      "epoch": 913.05,
      "learning_rate": 0.008731763294051443,
      "loss": 2.3442,
      "step": 567920
    },
    {
      "epoch": 913.09,
      "learning_rate": 0.008728547863183275,
      "loss": 2.3511,
      "step": 567940
    },
    {
      "epoch": 913.12,
      "learning_rate": 0.008725332432315117,
      "loss": 2.3331,
      "step": 567960
    },
    {
      "epoch": 913.15,
      "learning_rate": 0.008722117001446946,
      "loss": 2.3385,
      "step": 567980
    },
    {
      "epoch": 913.18,
      "learning_rate": 0.008718901570578778,
      "loss": 2.3703,
      "step": 568000
    },
    {
      "epoch": 913.22,
      "learning_rate": 0.008715686139710608,
      "loss": 2.3388,
      "step": 568020
    },
    {
      "epoch": 913.25,
      "learning_rate": 0.00871247070884244,
      "loss": 2.3484,
      "step": 568040
    },
    {
      "epoch": 913.28,
      "learning_rate": 0.008709255277974282,
      "loss": 2.3533,
      "step": 568060
    },
    {
      "epoch": 913.31,
      "learning_rate": 0.008706200618649513,
      "loss": 2.3497,
      "step": 568080
    },
    {
      "epoch": 913.34,
      "learning_rate": 0.008702985187781355,
      "loss": 2.3418,
      "step": 568100
    },
    {
      "epoch": 913.38,
      "learning_rate": 0.008699769756913184,
      "loss": 2.341,
      "step": 568120
    },
    {
      "epoch": 913.41,
      "learning_rate": 0.008696554326045016,
      "loss": 2.3316,
      "step": 568140
    },
    {
      "epoch": 913.44,
      "learning_rate": 0.008693338895176846,
      "loss": 2.3472,
      "step": 568160
    },
    {
      "epoch": 913.47,
      "learning_rate": 0.008690123464308678,
      "loss": 2.3442,
      "step": 568180
    },
    {
      "epoch": 913.5,
      "learning_rate": 0.00868690803344052,
      "loss": 2.3333,
      "step": 568200
    },
    {
      "epoch": 913.54,
      "learning_rate": 0.00868369260257235,
      "loss": 2.3511,
      "step": 568220
    },
    {
      "epoch": 913.57,
      "learning_rate": 0.008680477171704181,
      "loss": 2.3575,
      "step": 568240
    },
    {
      "epoch": 913.6,
      "learning_rate": 0.008677261740836013,
      "loss": 2.3545,
      "step": 568260
    },
    {
      "epoch": 913.63,
      "learning_rate": 0.008674046309967843,
      "loss": 2.333,
      "step": 568280
    },
    {
      "epoch": 913.67,
      "learning_rate": 0.008670830879099674,
      "loss": 2.3496,
      "step": 568300
    },
    {
      "epoch": 913.7,
      "learning_rate": 0.008667615448231516,
      "loss": 2.343,
      "step": 568320
    },
    {
      "epoch": 913.73,
      "learning_rate": 0.008664400017363346,
      "loss": 2.3531,
      "step": 568340
    },
    {
      "epoch": 913.76,
      "learning_rate": 0.008661184586495178,
      "loss": 2.3403,
      "step": 568360
    },
    {
      "epoch": 913.79,
      "learning_rate": 0.008657969155627008,
      "loss": 2.3157,
      "step": 568380
    },
    {
      "epoch": 913.83,
      "learning_rate": 0.00865475372475884,
      "loss": 2.3458,
      "step": 568400
    },
    {
      "epoch": 913.86,
      "learning_rate": 0.008651538293890669,
      "loss": 2.3343,
      "step": 568420
    },
    {
      "epoch": 913.89,
      "learning_rate": 0.008648322863022511,
      "loss": 2.3337,
      "step": 568440
    },
    {
      "epoch": 913.92,
      "learning_rate": 0.008645107432154343,
      "loss": 2.3375,
      "step": 568460
    },
    {
      "epoch": 913.95,
      "learning_rate": 0.008641892001286173,
      "loss": 2.355,
      "step": 568480
    },
    {
      "epoch": 913.99,
      "learning_rate": 0.008638676570418004,
      "loss": 2.357,
      "step": 568500
    },
    {
      "epoch": 914.0,
      "eval_accuracy": {
        "accuracy": 0.47275130218456035
      },
      "eval_loss": 2.4580161571502686,
      "eval_runtime": 3.4618,
      "eval_samples_per_second": 3715.72,
      "eval_steps_per_second": 58.063,
      "step": 568508
    },
    {
      "epoch": 914.02,
      "learning_rate": 0.008635461139549834,
      "loss": 2.3528,
      "step": 568520
    },
    {
      "epoch": 914.05,
      "learning_rate": 0.008632245708681676,
      "loss": 2.325,
      "step": 568540
    },
    {
      "epoch": 914.08,
      "learning_rate": 0.008629030277813508,
      "loss": 2.3492,
      "step": 568560
    },
    {
      "epoch": 914.12,
      "learning_rate": 0.00862581484694534,
      "loss": 2.3358,
      "step": 568580
    },
    {
      "epoch": 914.15,
      "learning_rate": 0.00862259941607717,
      "loss": 2.3379,
      "step": 568600
    },
    {
      "epoch": 914.18,
      "learning_rate": 0.008619383985209,
      "loss": 2.3409,
      "step": 568620
    },
    {
      "epoch": 914.21,
      "learning_rate": 0.00861616855434083,
      "loss": 2.3279,
      "step": 568640
    },
    {
      "epoch": 914.24,
      "learning_rate": 0.008612953123472673,
      "loss": 2.3537,
      "step": 568660
    },
    {
      "epoch": 914.28,
      "learning_rate": 0.008609737692604504,
      "loss": 2.344,
      "step": 568680
    },
    {
      "epoch": 914.31,
      "learning_rate": 0.008606522261736334,
      "loss": 2.3327,
      "step": 568700
    },
    {
      "epoch": 914.34,
      "learning_rate": 0.008603306830868166,
      "loss": 2.348,
      "step": 568720
    },
    {
      "epoch": 914.37,
      "learning_rate": 0.008600091399999996,
      "loss": 2.344,
      "step": 568740
    },
    {
      "epoch": 914.41,
      "learning_rate": 0.008596875969131827,
      "loss": 2.3502,
      "step": 568760
    },
    {
      "epoch": 914.44,
      "learning_rate": 0.00859366053826367,
      "loss": 2.3239,
      "step": 568780
    },
    {
      "epoch": 914.47,
      "learning_rate": 0.008590445107395499,
      "loss": 2.3279,
      "step": 568800
    },
    {
      "epoch": 914.5,
      "learning_rate": 0.00858722967652733,
      "loss": 2.3631,
      "step": 568820
    },
    {
      "epoch": 914.53,
      "learning_rate": 0.00858401424565916,
      "loss": 2.3358,
      "step": 568840
    },
    {
      "epoch": 914.57,
      "learning_rate": 0.008580798814790992,
      "loss": 2.3602,
      "step": 568860
    },
    {
      "epoch": 914.6,
      "learning_rate": 0.008577583383922834,
      "loss": 2.3364,
      "step": 568880
    },
    {
      "epoch": 914.63,
      "learning_rate": 0.008574367953054666,
      "loss": 2.3498,
      "step": 568900
    },
    {
      "epoch": 914.66,
      "learning_rate": 0.008571152522186496,
      "loss": 2.3397,
      "step": 568920
    },
    {
      "epoch": 914.69,
      "learning_rate": 0.008567937091318327,
      "loss": 2.3535,
      "step": 568940
    },
    {
      "epoch": 914.73,
      "learning_rate": 0.008564721660450157,
      "loss": 2.3382,
      "step": 568960
    },
    {
      "epoch": 914.76,
      "learning_rate": 0.008561506229581989,
      "loss": 2.3406,
      "step": 568980
    },
    {
      "epoch": 914.79,
      "learning_rate": 0.00855829079871383,
      "loss": 2.3482,
      "step": 569000
    },
    {
      "epoch": 914.82,
      "learning_rate": 0.00855507536784566,
      "loss": 2.355,
      "step": 569020
    },
    {
      "epoch": 914.86,
      "learning_rate": 0.008551859936977492,
      "loss": 2.3404,
      "step": 569040
    },
    {
      "epoch": 914.89,
      "learning_rate": 0.008548644506109322,
      "loss": 2.3336,
      "step": 569060
    },
    {
      "epoch": 914.92,
      "learning_rate": 0.008545429075241154,
      "loss": 2.3515,
      "step": 569080
    },
    {
      "epoch": 914.95,
      "learning_rate": 0.008542213644372984,
      "loss": 2.3379,
      "step": 569100
    },
    {
      "epoch": 914.98,
      "learning_rate": 0.008538998213504826,
      "loss": 2.35,
      "step": 569120
    },
    {
      "epoch": 915.0,
      "eval_accuracy": {
        "accuracy": 0.47135193967192723
      },
      "eval_loss": 2.4636669158935547,
      "eval_runtime": 3.1817,
      "eval_samples_per_second": 4042.792,
      "eval_steps_per_second": 63.174,
      "step": 569130
    },
    {
      "epoch": 915.02,
      "learning_rate": 0.008535782782636657,
      "loss": 2.349,
      "step": 569140
    },
    {
      "epoch": 915.05,
      "learning_rate": 0.008532567351768487,
      "loss": 2.3407,
      "step": 569160
    },
    {
      "epoch": 915.08,
      "learning_rate": 0.008529351920900319,
      "loss": 2.3289,
      "step": 569180
    },
    {
      "epoch": 915.11,
      "learning_rate": 0.00852613649003215,
      "loss": 2.3427,
      "step": 569200
    },
    {
      "epoch": 915.14,
      "learning_rate": 0.008522921059163992,
      "loss": 2.3332,
      "step": 569220
    },
    {
      "epoch": 915.18,
      "learning_rate": 0.008519705628295822,
      "loss": 2.3413,
      "step": 569240
    },
    {
      "epoch": 915.21,
      "learning_rate": 0.008516490197427654,
      "loss": 2.3514,
      "step": 569260
    },
    {
      "epoch": 915.24,
      "learning_rate": 0.008513274766559484,
      "loss": 2.3509,
      "step": 569280
    },
    {
      "epoch": 915.27,
      "learning_rate": 0.008510059335691315,
      "loss": 2.346,
      "step": 569300
    },
    {
      "epoch": 915.31,
      "learning_rate": 0.008506843904823145,
      "loss": 2.3249,
      "step": 569320
    },
    {
      "epoch": 915.34,
      "learning_rate": 0.008503628473954987,
      "loss": 2.3328,
      "step": 569340
    },
    {
      "epoch": 915.37,
      "learning_rate": 0.008500413043086819,
      "loss": 2.37,
      "step": 569360
    },
    {
      "epoch": 915.4,
      "learning_rate": 0.008497197612218649,
      "loss": 2.3442,
      "step": 569380
    },
    {
      "epoch": 915.43,
      "learning_rate": 0.00849398218135048,
      "loss": 2.3413,
      "step": 569400
    },
    {
      "epoch": 915.47,
      "learning_rate": 0.00849076675048231,
      "loss": 2.3445,
      "step": 569420
    },
    {
      "epoch": 915.5,
      "learning_rate": 0.008487551319614152,
      "loss": 2.3458,
      "step": 569440
    },
    {
      "epoch": 915.53,
      "learning_rate": 0.008484335888745984,
      "loss": 2.357,
      "step": 569460
    },
    {
      "epoch": 915.56,
      "learning_rate": 0.008481120457877816,
      "loss": 2.3463,
      "step": 569480
    },
    {
      "epoch": 915.59,
      "learning_rate": 0.008477905027009645,
      "loss": 2.3455,
      "step": 569500
    },
    {
      "epoch": 915.63,
      "learning_rate": 0.008474689596141477,
      "loss": 2.3228,
      "step": 569520
    },
    {
      "epoch": 915.66,
      "learning_rate": 0.008471474165273307,
      "loss": 2.3549,
      "step": 569540
    },
    {
      "epoch": 915.69,
      "learning_rate": 0.008468258734405149,
      "loss": 2.345,
      "step": 569560
    },
    {
      "epoch": 915.72,
      "learning_rate": 0.00846504330353698,
      "loss": 2.3546,
      "step": 569580
    },
    {
      "epoch": 915.76,
      "learning_rate": 0.00846182787266881,
      "loss": 2.3397,
      "step": 569600
    },
    {
      "epoch": 915.79,
      "learning_rate": 0.008458612441800642,
      "loss": 2.3381,
      "step": 569620
    },
    {
      "epoch": 915.82,
      "learning_rate": 0.008455397010932472,
      "loss": 2.3351,
      "step": 569640
    },
    {
      "epoch": 915.85,
      "learning_rate": 0.008452181580064303,
      "loss": 2.3396,
      "step": 569660
    },
    {
      "epoch": 915.88,
      "learning_rate": 0.008448966149196145,
      "loss": 2.3424,
      "step": 569680
    },
    {
      "epoch": 915.92,
      "learning_rate": 0.008445750718327975,
      "loss": 2.3393,
      "step": 569700
    },
    {
      "epoch": 915.95,
      "learning_rate": 0.008442535287459807,
      "loss": 2.3449,
      "step": 569720
    },
    {
      "epoch": 915.98,
      "learning_rate": 0.008439319856591637,
      "loss": 2.3239,
      "step": 569740
    },
    {
      "epoch": 916.0,
      "eval_accuracy": {
        "accuracy": 0.47150742439555315
      },
      "eval_loss": 2.457571268081665,
      "eval_runtime": 3.0893,
      "eval_samples_per_second": 4163.671,
      "eval_steps_per_second": 65.062,
      "step": 569752
    },
    {
      "epoch": 916.01,
      "learning_rate": 0.008436104425723468,
      "loss": 2.3368,
      "step": 569760
    },
    {
      "epoch": 916.05,
      "learning_rate": 0.00843288899485531,
      "loss": 2.341,
      "step": 569780
    },
    {
      "epoch": 916.08,
      "learning_rate": 0.008429673563987142,
      "loss": 2.3406,
      "step": 569800
    },
    {
      "epoch": 916.11,
      "learning_rate": 0.008426458133118972,
      "loss": 2.3594,
      "step": 569820
    },
    {
      "epoch": 916.14,
      "learning_rate": 0.008423242702250804,
      "loss": 2.3225,
      "step": 569840
    },
    {
      "epoch": 916.17,
      "learning_rate": 0.008420027271382633,
      "loss": 2.3245,
      "step": 569860
    },
    {
      "epoch": 916.21,
      "learning_rate": 0.008416811840514465,
      "loss": 2.3382,
      "step": 569880
    },
    {
      "epoch": 916.24,
      "learning_rate": 0.008413596409646307,
      "loss": 2.321,
      "step": 569900
    },
    {
      "epoch": 916.27,
      "learning_rate": 0.008410380978778137,
      "loss": 2.3232,
      "step": 569920
    },
    {
      "epoch": 916.3,
      "learning_rate": 0.008407165547909969,
      "loss": 2.3568,
      "step": 569940
    },
    {
      "epoch": 916.33,
      "learning_rate": 0.008403950117041798,
      "loss": 2.3419,
      "step": 569960
    },
    {
      "epoch": 916.37,
      "learning_rate": 0.00840073468617363,
      "loss": 2.3439,
      "step": 569980
    },
    {
      "epoch": 916.4,
      "learning_rate": 0.00839751925530546,
      "loss": 2.3497,
      "step": 570000
    },
    {
      "epoch": 916.43,
      "learning_rate": 0.008394303824437302,
      "loss": 2.3584,
      "step": 570020
    },
    {
      "epoch": 916.46,
      "learning_rate": 0.008391088393569134,
      "loss": 2.3492,
      "step": 570040
    },
    {
      "epoch": 916.5,
      "learning_rate": 0.008387872962700963,
      "loss": 2.331,
      "step": 570060
    },
    {
      "epoch": 916.53,
      "learning_rate": 0.008384818303376207,
      "loss": 2.3455,
      "step": 570080
    },
    {
      "epoch": 916.56,
      "learning_rate": 0.008381602872508036,
      "loss": 2.3378,
      "step": 570100
    },
    {
      "epoch": 916.59,
      "learning_rate": 0.008378387441639868,
      "loss": 2.3407,
      "step": 570120
    },
    {
      "epoch": 916.62,
      "learning_rate": 0.008375172010771698,
      "loss": 2.3438,
      "step": 570140
    },
    {
      "epoch": 916.66,
      "learning_rate": 0.00837195657990354,
      "loss": 2.3307,
      "step": 570160
    },
    {
      "epoch": 916.69,
      "learning_rate": 0.008368741149035372,
      "loss": 2.329,
      "step": 570180
    },
    {
      "epoch": 916.72,
      "learning_rate": 0.008365525718167203,
      "loss": 2.3401,
      "step": 570200
    },
    {
      "epoch": 916.75,
      "learning_rate": 0.008362310287299033,
      "loss": 2.353,
      "step": 570220
    },
    {
      "epoch": 916.78,
      "learning_rate": 0.008359094856430865,
      "loss": 2.3398,
      "step": 570240
    },
    {
      "epoch": 916.82,
      "learning_rate": 0.008355879425562707,
      "loss": 2.3346,
      "step": 570260
    },
    {
      "epoch": 916.85,
      "learning_rate": 0.008352663994694537,
      "loss": 2.3689,
      "step": 570280
    },
    {
      "epoch": 916.88,
      "learning_rate": 0.008349448563826368,
      "loss": 2.352,
      "step": 570300
    },
    {
      "epoch": 916.91,
      "learning_rate": 0.008346233132958198,
      "loss": 2.3393,
      "step": 570320
    },
    {
      "epoch": 916.95,
      "learning_rate": 0.00834301770209003,
      "loss": 2.3437,
      "step": 570340
    },
    {
      "epoch": 916.98,
      "learning_rate": 0.00833980227122186,
      "loss": 2.3423,
      "step": 570360
    },
    {
      "epoch": 917.0,
      "eval_accuracy": {
        "accuracy": 0.47018580424473294
      },
      "eval_loss": 2.458016872406006,
      "eval_runtime": 3.038,
      "eval_samples_per_second": 4234.081,
      "eval_steps_per_second": 66.163,
      "step": 570374
    },
    {
      "epoch": 917.01,
      "learning_rate": 0.008336586840353702,
      "loss": 2.3453,
      "step": 570380
    },
    {
      "epoch": 917.04,
      "learning_rate": 0.008333371409485533,
      "loss": 2.3432,
      "step": 570400
    },
    {
      "epoch": 917.07,
      "learning_rate": 0.008330155978617363,
      "loss": 2.3606,
      "step": 570420
    },
    {
      "epoch": 917.11,
      "learning_rate": 0.008326940547749195,
      "loss": 2.3283,
      "step": 570440
    },
    {
      "epoch": 917.14,
      "learning_rate": 0.008323725116881026,
      "loss": 2.3266,
      "step": 570460
    },
    {
      "epoch": 917.17,
      "learning_rate": 0.008320509686012856,
      "loss": 2.3314,
      "step": 570480
    },
    {
      "epoch": 917.2,
      "learning_rate": 0.008317294255144698,
      "loss": 2.3553,
      "step": 570500
    },
    {
      "epoch": 917.23,
      "learning_rate": 0.00831407882427653,
      "loss": 2.3494,
      "step": 570520
    },
    {
      "epoch": 917.27,
      "learning_rate": 0.00831086339340836,
      "loss": 2.3182,
      "step": 570540
    },
    {
      "epoch": 917.3,
      "learning_rate": 0.008307647962540191,
      "loss": 2.3384,
      "step": 570560
    },
    {
      "epoch": 917.33,
      "learning_rate": 0.008304432531672021,
      "loss": 2.3249,
      "step": 570580
    },
    {
      "epoch": 917.36,
      "learning_rate": 0.008301217100803863,
      "loss": 2.3542,
      "step": 570600
    },
    {
      "epoch": 917.4,
      "learning_rate": 0.008298001669935695,
      "loss": 2.3178,
      "step": 570620
    },
    {
      "epoch": 917.43,
      "learning_rate": 0.008294786239067525,
      "loss": 2.3347,
      "step": 570640
    },
    {
      "epoch": 917.46,
      "learning_rate": 0.008291570808199356,
      "loss": 2.3513,
      "step": 570660
    },
    {
      "epoch": 917.49,
      "learning_rate": 0.008288355377331186,
      "loss": 2.3534,
      "step": 570680
    },
    {
      "epoch": 917.52,
      "learning_rate": 0.008285139946463018,
      "loss": 2.349,
      "step": 570700
    },
    {
      "epoch": 917.56,
      "learning_rate": 0.00828192451559486,
      "loss": 2.3456,
      "step": 570720
    },
    {
      "epoch": 917.59,
      "learning_rate": 0.00827870908472669,
      "loss": 2.3445,
      "step": 570740
    },
    {
      "epoch": 917.62,
      "learning_rate": 0.008275493653858521,
      "loss": 2.3492,
      "step": 570760
    },
    {
      "epoch": 917.65,
      "learning_rate": 0.008272278222990353,
      "loss": 2.3395,
      "step": 570780
    },
    {
      "epoch": 917.68,
      "learning_rate": 0.008269062792122183,
      "loss": 2.3508,
      "step": 570800
    },
    {
      "epoch": 917.72,
      "learning_rate": 0.008265847361254014,
      "loss": 2.3401,
      "step": 570820
    },
    {
      "epoch": 917.75,
      "learning_rate": 0.008262631930385856,
      "loss": 2.3384,
      "step": 570840
    },
    {
      "epoch": 917.78,
      "learning_rate": 0.008259416499517686,
      "loss": 2.3264,
      "step": 570860
    },
    {
      "epoch": 917.81,
      "learning_rate": 0.008256201068649518,
      "loss": 2.3743,
      "step": 570880
    },
    {
      "epoch": 917.85,
      "learning_rate": 0.008252985637781348,
      "loss": 2.3465,
      "step": 570900
    },
    {
      "epoch": 917.88,
      "learning_rate": 0.00824977020691318,
      "loss": 2.352,
      "step": 570920
    },
    {
      "epoch": 917.91,
      "learning_rate": 0.008246554776045021,
      "loss": 2.3368,
      "step": 570940
    },
    {
      "epoch": 917.94,
      "learning_rate": 0.008243339345176851,
      "loss": 2.3215,
      "step": 570960
    },
    {
      "epoch": 917.97,
      "learning_rate": 0.008240123914308683,
      "loss": 2.3197,
      "step": 570980
    },
    {
      "epoch": 918.0,
      "eval_accuracy": {
        "accuracy": 0.47827100987328
      },
      "eval_loss": 2.461684465408325,
      "eval_runtime": 3.1026,
      "eval_samples_per_second": 4145.927,
      "eval_steps_per_second": 64.785,
      "step": 570996
    },
    {
      "epoch": 918.01,
      "learning_rate": 0.008236908483440513,
      "loss": 2.3415,
      "step": 571000
    },
    {
      "epoch": 918.04,
      "learning_rate": 0.008233693052572344,
      "loss": 2.3305,
      "step": 571020
    },
    {
      "epoch": 918.07,
      "learning_rate": 0.008230477621704174,
      "loss": 2.3525,
      "step": 571040
    },
    {
      "epoch": 918.1,
      "learning_rate": 0.008227262190836016,
      "loss": 2.3439,
      "step": 571060
    },
    {
      "epoch": 918.14,
      "learning_rate": 0.008224046759967848,
      "loss": 2.3406,
      "step": 571080
    },
    {
      "epoch": 918.17,
      "learning_rate": 0.00822083132909968,
      "loss": 2.3508,
      "step": 571100
    },
    {
      "epoch": 918.2,
      "learning_rate": 0.00821761589823151,
      "loss": 2.3527,
      "step": 571120
    },
    {
      "epoch": 918.23,
      "learning_rate": 0.008214400467363341,
      "loss": 2.3317,
      "step": 571140
    },
    {
      "epoch": 918.26,
      "learning_rate": 0.00821118503649517,
      "loss": 2.338,
      "step": 571160
    },
    {
      "epoch": 918.3,
      "learning_rate": 0.008207969605627013,
      "loss": 2.3344,
      "step": 571180
    },
    {
      "epoch": 918.33,
      "learning_rate": 0.008204754174758844,
      "loss": 2.3301,
      "step": 571200
    },
    {
      "epoch": 918.36,
      "learning_rate": 0.008201538743890674,
      "loss": 2.3476,
      "step": 571220
    },
    {
      "epoch": 918.39,
      "learning_rate": 0.008198323313022506,
      "loss": 2.3356,
      "step": 571240
    },
    {
      "epoch": 918.42,
      "learning_rate": 0.008195107882154336,
      "loss": 2.3439,
      "step": 571260
    },
    {
      "epoch": 918.46,
      "learning_rate": 0.008191892451286178,
      "loss": 2.3355,
      "step": 571280
    },
    {
      "epoch": 918.49,
      "learning_rate": 0.00818867702041801,
      "loss": 2.3309,
      "step": 571300
    },
    {
      "epoch": 918.52,
      "learning_rate": 0.00818546158954984,
      "loss": 2.331,
      "step": 571320
    },
    {
      "epoch": 918.55,
      "learning_rate": 0.008182246158681671,
      "loss": 2.3481,
      "step": 571340
    },
    {
      "epoch": 918.59,
      "learning_rate": 0.0081790307278135,
      "loss": 2.3519,
      "step": 571360
    },
    {
      "epoch": 918.62,
      "learning_rate": 0.008175815296945332,
      "loss": 2.3398,
      "step": 571380
    },
    {
      "epoch": 918.65,
      "learning_rate": 0.008172599866077174,
      "loss": 2.3311,
      "step": 571400
    },
    {
      "epoch": 918.68,
      "learning_rate": 0.008169384435209006,
      "loss": 2.3432,
      "step": 571420
    },
    {
      "epoch": 918.71,
      "learning_rate": 0.008166169004340836,
      "loss": 2.3594,
      "step": 571440
    },
    {
      "epoch": 918.75,
      "learning_rate": 0.008162953573472667,
      "loss": 2.3303,
      "step": 571460
    },
    {
      "epoch": 918.78,
      "learning_rate": 0.008159738142604497,
      "loss": 2.3472,
      "step": 571480
    },
    {
      "epoch": 918.81,
      "learning_rate": 0.008156522711736329,
      "loss": 2.3402,
      "step": 571500
    },
    {
      "epoch": 918.84,
      "learning_rate": 0.008153307280868171,
      "loss": 2.3465,
      "step": 571520
    },
    {
      "epoch": 918.87,
      "learning_rate": 0.008150091850000001,
      "loss": 2.341,
      "step": 571540
    },
    {
      "epoch": 918.91,
      "learning_rate": 0.008146876419131832,
      "loss": 2.3404,
      "step": 571560
    },
    {
      "epoch": 918.94,
      "learning_rate": 0.008143660988263662,
      "loss": 2.317,
      "step": 571580
    },
    {
      "epoch": 918.97,
      "learning_rate": 0.008140445557395494,
      "loss": 2.3397,
      "step": 571600
    },
    {
      "epoch": 919.0,
      "eval_accuracy": {
        "accuracy": 0.47617196610433027
      },
      "eval_loss": 2.4583895206451416,
      "eval_runtime": 3.0639,
      "eval_samples_per_second": 4198.271,
      "eval_steps_per_second": 65.603,
      "step": 571618
    },
    {
      "epoch": 919.0,
      "learning_rate": 0.008137230126527336,
      "loss": 2.3288,
      "step": 571620
    },
    {
      "epoch": 919.04,
      "learning_rate": 0.008134014695659166,
      "loss": 2.3461,
      "step": 571640
    },
    {
      "epoch": 919.07,
      "learning_rate": 0.008130799264790997,
      "loss": 2.3223,
      "step": 571660
    },
    {
      "epoch": 919.1,
      "learning_rate": 0.008127583833922829,
      "loss": 2.345,
      "step": 571680
    },
    {
      "epoch": 919.13,
      "learning_rate": 0.008124368403054659,
      "loss": 2.3367,
      "step": 571700
    },
    {
      "epoch": 919.16,
      "learning_rate": 0.00812115297218649,
      "loss": 2.3324,
      "step": 571720
    },
    {
      "epoch": 919.2,
      "learning_rate": 0.008117937541318333,
      "loss": 2.339,
      "step": 571740
    },
    {
      "epoch": 919.23,
      "learning_rate": 0.008114722110450162,
      "loss": 2.3351,
      "step": 571760
    },
    {
      "epoch": 919.26,
      "learning_rate": 0.008111506679581994,
      "loss": 2.3267,
      "step": 571780
    },
    {
      "epoch": 919.29,
      "learning_rate": 0.008108291248713824,
      "loss": 2.3424,
      "step": 571800
    },
    {
      "epoch": 919.32,
      "learning_rate": 0.008105075817845656,
      "loss": 2.3285,
      "step": 571820
    },
    {
      "epoch": 919.36,
      "learning_rate": 0.008101860386977498,
      "loss": 2.3514,
      "step": 571840
    },
    {
      "epoch": 919.39,
      "learning_rate": 0.008098644956109327,
      "loss": 2.3467,
      "step": 571860
    },
    {
      "epoch": 919.42,
      "learning_rate": 0.008095429525241159,
      "loss": 2.3193,
      "step": 571880
    },
    {
      "epoch": 919.45,
      "learning_rate": 0.008092214094372989,
      "loss": 2.3604,
      "step": 571900
    },
    {
      "epoch": 919.49,
      "learning_rate": 0.00808899866350482,
      "loss": 2.3431,
      "step": 571920
    },
    {
      "epoch": 919.52,
      "learning_rate": 0.00808578323263665,
      "loss": 2.3406,
      "step": 571940
    },
    {
      "epoch": 919.55,
      "learning_rate": 0.008082567801768492,
      "loss": 2.3378,
      "step": 571960
    },
    {
      "epoch": 919.58,
      "learning_rate": 0.008079352370900324,
      "loss": 2.3484,
      "step": 571980
    },
    {
      "epoch": 919.61,
      "learning_rate": 0.008076136940032156,
      "loss": 2.3386,
      "step": 572000
    },
    {
      "epoch": 919.65,
      "learning_rate": 0.008072921509163986,
      "loss": 2.3462,
      "step": 572020
    },
    {
      "epoch": 919.68,
      "learning_rate": 0.008069706078295817,
      "loss": 2.3524,
      "step": 572040
    },
    {
      "epoch": 919.71,
      "learning_rate": 0.008066490647427647,
      "loss": 2.3413,
      "step": 572060
    },
    {
      "epoch": 919.74,
      "learning_rate": 0.00806343598810289,
      "loss": 2.3203,
      "step": 572080
    },
    {
      "epoch": 919.77,
      "learning_rate": 0.00806022055723473,
      "loss": 2.3344,
      "step": 572100
    },
    {
      "epoch": 919.81,
      "learning_rate": 0.008057005126366562,
      "loss": 2.3375,
      "step": 572120
    },
    {
      "epoch": 919.84,
      "learning_rate": 0.008053789695498394,
      "loss": 2.3521,
      "step": 572140
    },
    {
      "epoch": 919.87,
      "learning_rate": 0.008050574264630224,
      "loss": 2.3372,
      "step": 572160
    },
    {
      "epoch": 919.9,
      "learning_rate": 0.008047358833762055,
      "loss": 2.3291,
      "step": 572180
    },
    {
      "epoch": 919.94,
      "learning_rate": 0.008044143402893885,
      "loss": 2.3407,
      "step": 572200
    },
    {
      "epoch": 919.97,
      "learning_rate": 0.008040927972025727,
      "loss": 2.3314,
      "step": 572220
    },
    {
      "epoch": 920.0,
      "learning_rate": 0.008037712541157559,
      "loss": 2.3381,
      "step": 572240
    },
    {
      "epoch": 920.0,
      "eval_accuracy": {
        "accuracy": 0.47718261680789864
      },
      "eval_loss": 2.4521260261535645,
      "eval_runtime": 3.0946,
      "eval_samples_per_second": 4156.569,
      "eval_steps_per_second": 64.951,
      "step": 572240
    },
    {
      "epoch": 920.03,
      "learning_rate": 0.008034497110289389,
      "loss": 2.3486,
      "step": 572260
    },
    {
      "epoch": 920.06,
      "learning_rate": 0.00803128167942122,
      "loss": 2.3405,
      "step": 572280
    },
    {
      "epoch": 920.1,
      "learning_rate": 0.00802806624855305,
      "loss": 2.3407,
      "step": 572300
    },
    {
      "epoch": 920.13,
      "learning_rate": 0.008024850817684882,
      "loss": 2.3347,
      "step": 572320
    },
    {
      "epoch": 920.16,
      "learning_rate": 0.008021635386816724,
      "loss": 2.3295,
      "step": 572340
    },
    {
      "epoch": 920.19,
      "learning_rate": 0.008018419955948554,
      "loss": 2.3515,
      "step": 572360
    },
    {
      "epoch": 920.23,
      "learning_rate": 0.008015204525080385,
      "loss": 2.3303,
      "step": 572380
    },
    {
      "epoch": 920.26,
      "learning_rate": 0.008011989094212217,
      "loss": 2.3368,
      "step": 572400
    },
    {
      "epoch": 920.29,
      "learning_rate": 0.008008773663344047,
      "loss": 2.3402,
      "step": 572420
    },
    {
      "epoch": 920.32,
      "learning_rate": 0.008005558232475889,
      "loss": 2.317,
      "step": 572440
    },
    {
      "epoch": 920.35,
      "learning_rate": 0.00800234280160772,
      "loss": 2.3478,
      "step": 572460
    },
    {
      "epoch": 920.39,
      "learning_rate": 0.00799912737073955,
      "loss": 2.3599,
      "step": 572480
    },
    {
      "epoch": 920.42,
      "learning_rate": 0.007995911939871382,
      "loss": 2.3472,
      "step": 572500
    },
    {
      "epoch": 920.45,
      "learning_rate": 0.007992696509003212,
      "loss": 2.3212,
      "step": 572520
    },
    {
      "epoch": 920.48,
      "learning_rate": 0.007989481078135043,
      "loss": 2.3475,
      "step": 572540
    },
    {
      "epoch": 920.51,
      "learning_rate": 0.007986265647266885,
      "loss": 2.3307,
      "step": 572560
    },
    {
      "epoch": 920.55,
      "learning_rate": 0.007983050216398715,
      "loss": 2.322,
      "step": 572580
    },
    {
      "epoch": 920.58,
      "learning_rate": 0.007979834785530547,
      "loss": 2.3341,
      "step": 572600
    },
    {
      "epoch": 920.61,
      "learning_rate": 0.007976619354662377,
      "loss": 2.3305,
      "step": 572620
    },
    {
      "epoch": 920.64,
      "learning_rate": 0.007973403923794208,
      "loss": 2.3475,
      "step": 572640
    },
    {
      "epoch": 920.68,
      "learning_rate": 0.00797018849292605,
      "loss": 2.3308,
      "step": 572660
    },
    {
      "epoch": 920.71,
      "learning_rate": 0.00796697306205788,
      "loss": 2.3366,
      "step": 572680
    },
    {
      "epoch": 920.74,
      "learning_rate": 0.007963757631189712,
      "loss": 2.3356,
      "step": 572700
    },
    {
      "epoch": 920.77,
      "learning_rate": 0.007960542200321543,
      "loss": 2.3293,
      "step": 572720
    },
    {
      "epoch": 920.8,
      "learning_rate": 0.007957326769453373,
      "loss": 2.3336,
      "step": 572740
    },
    {
      "epoch": 920.84,
      "learning_rate": 0.007954111338585205,
      "loss": 2.3246,
      "step": 572760
    },
    {
      "epoch": 920.87,
      "learning_rate": 0.007950895907717047,
      "loss": 2.3576,
      "step": 572780
    },
    {
      "epoch": 920.9,
      "learning_rate": 0.007947680476848877,
      "loss": 2.3464,
      "step": 572800
    },
    {
      "epoch": 920.93,
      "learning_rate": 0.007944465045980708,
      "loss": 2.3387,
      "step": 572820
    },
    {
      "epoch": 920.96,
      "learning_rate": 0.007941249615112538,
      "loss": 2.3423,
      "step": 572840
    },
    {
      "epoch": 921.0,
      "learning_rate": 0.00793803418424437,
      "loss": 2.339,
      "step": 572860
    },
    {
      "epoch": 921.0,
      "eval_accuracy": {
        "accuracy": 0.4747726035916971
      },
      "eval_loss": 2.460155725479126,
      "eval_runtime": 3.0849,
      "eval_samples_per_second": 4169.726,
      "eval_steps_per_second": 65.157,
      "step": 572862
    },
    {
      "epoch": 921.03,
      "learning_rate": 0.0079348187533762,
      "loss": 2.3508,
      "step": 572880
    },
    {
      "epoch": 921.06,
      "learning_rate": 0.007931603322508042,
      "loss": 2.3238,
      "step": 572900
    },
    {
      "epoch": 921.09,
      "learning_rate": 0.007928387891639873,
      "loss": 2.3439,
      "step": 572920
    },
    {
      "epoch": 921.13,
      "learning_rate": 0.007925172460771703,
      "loss": 2.337,
      "step": 572940
    },
    {
      "epoch": 921.16,
      "learning_rate": 0.007921957029903535,
      "loss": 2.3596,
      "step": 572960
    },
    {
      "epoch": 921.19,
      "learning_rate": 0.007918741599035366,
      "loss": 2.3445,
      "step": 572980
    },
    {
      "epoch": 921.22,
      "learning_rate": 0.007915526168167207,
      "loss": 2.3305,
      "step": 573000
    },
    {
      "epoch": 921.25,
      "learning_rate": 0.007912310737299038,
      "loss": 2.3551,
      "step": 573020
    },
    {
      "epoch": 921.29,
      "learning_rate": 0.00790909530643087,
      "loss": 2.335,
      "step": 573040
    },
    {
      "epoch": 921.32,
      "learning_rate": 0.0079058798755627,
      "loss": 2.319,
      "step": 573060
    },
    {
      "epoch": 921.35,
      "learning_rate": 0.007902664444694531,
      "loss": 2.3525,
      "step": 573080
    },
    {
      "epoch": 921.38,
      "learning_rate": 0.007899449013826361,
      "loss": 2.3368,
      "step": 573100
    },
    {
      "epoch": 921.41,
      "learning_rate": 0.007896233582958203,
      "loss": 2.3406,
      "step": 573120
    },
    {
      "epoch": 921.45,
      "learning_rate": 0.007893018152090035,
      "loss": 2.3553,
      "step": 573140
    },
    {
      "epoch": 921.48,
      "learning_rate": 0.007889802721221865,
      "loss": 2.3311,
      "step": 573160
    },
    {
      "epoch": 921.51,
      "learning_rate": 0.007886587290353696,
      "loss": 2.3359,
      "step": 573180
    },
    {
      "epoch": 921.54,
      "learning_rate": 0.007883371859485526,
      "loss": 2.3287,
      "step": 573200
    },
    {
      "epoch": 921.58,
      "learning_rate": 0.00788031720016077,
      "loss": 2.3325,
      "step": 573220
    },
    {
      "epoch": 921.61,
      "learning_rate": 0.0078771017692926,
      "loss": 2.3417,
      "step": 573240
    },
    {
      "epoch": 921.64,
      "learning_rate": 0.007873886338424441,
      "loss": 2.3301,
      "step": 573260
    },
    {
      "epoch": 921.67,
      "learning_rate": 0.007870670907556273,
      "loss": 2.3254,
      "step": 573280
    },
    {
      "epoch": 921.7,
      "learning_rate": 0.007867455476688103,
      "loss": 2.3198,
      "step": 573300
    },
    {
      "epoch": 921.74,
      "learning_rate": 0.007864240045819934,
      "loss": 2.3201,
      "step": 573320
    },
    {
      "epoch": 921.77,
      "learning_rate": 0.007861024614951764,
      "loss": 2.3391,
      "step": 573340
    },
    {
      "epoch": 921.8,
      "learning_rate": 0.007857809184083596,
      "loss": 2.3471,
      "step": 573360
    },
    {
      "epoch": 921.83,
      "learning_rate": 0.007854593753215438,
      "loss": 2.3402,
      "step": 573380
    },
    {
      "epoch": 921.86,
      "learning_rate": 0.00785137832234727,
      "loss": 2.333,
      "step": 573400
    },
    {
      "epoch": 921.9,
      "learning_rate": 0.0078481628914791,
      "loss": 2.3295,
      "step": 573420
    },
    {
      "epoch": 921.93,
      "learning_rate": 0.007844947460610931,
      "loss": 2.33,
      "step": 573440
    },
    {
      "epoch": 921.96,
      "learning_rate": 0.007841732029742761,
      "loss": 2.329,
      "step": 573460
    },
    {
      "epoch": 921.99,
      "learning_rate": 0.007838516598874603,
      "loss": 2.3511,
      "step": 573480
    },
    {
      "epoch": 922.0,
      "eval_accuracy": {
        "accuracy": 0.47407292233538056
      },
      "eval_loss": 2.460484027862549,
      "eval_runtime": 3.0348,
      "eval_samples_per_second": 4238.524,
      "eval_steps_per_second": 66.232,
      "step": 573484
    },
    {
      "epoch": 922.03,
      "learning_rate": 0.007835301168006435,
      "loss": 2.3513,
      "step": 573500
    },
    {
      "epoch": 922.06,
      "learning_rate": 0.007832085737138264,
      "loss": 2.3498,
      "step": 573520
    },
    {
      "epoch": 922.09,
      "learning_rate": 0.007828870306270096,
      "loss": 2.3452,
      "step": 573540
    },
    {
      "epoch": 922.12,
      "learning_rate": 0.007825654875401926,
      "loss": 2.3468,
      "step": 573560
    },
    {
      "epoch": 922.15,
      "learning_rate": 0.007822439444533758,
      "loss": 2.3256,
      "step": 573580
    },
    {
      "epoch": 922.19,
      "learning_rate": 0.0078192240136656,
      "loss": 2.3421,
      "step": 573600
    },
    {
      "epoch": 922.22,
      "learning_rate": 0.00781600858279743,
      "loss": 2.3269,
      "step": 573620
    },
    {
      "epoch": 922.25,
      "learning_rate": 0.007812793151929261,
      "loss": 2.3275,
      "step": 573640
    },
    {
      "epoch": 922.28,
      "learning_rate": 0.007809577721061093,
      "loss": 2.3369,
      "step": 573660
    },
    {
      "epoch": 922.32,
      "learning_rate": 0.0078063622901929225,
      "loss": 2.3242,
      "step": 573680
    },
    {
      "epoch": 922.35,
      "learning_rate": 0.007803146859324754,
      "loss": 2.3363,
      "step": 573700
    },
    {
      "epoch": 922.38,
      "learning_rate": 0.007799931428456596,
      "loss": 2.3495,
      "step": 573720
    },
    {
      "epoch": 922.41,
      "learning_rate": 0.007796715997588428,
      "loss": 2.3283,
      "step": 573740
    },
    {
      "epoch": 922.44,
      "learning_rate": 0.007793500566720258,
      "loss": 2.3281,
      "step": 573760
    },
    {
      "epoch": 922.48,
      "learning_rate": 0.0077902851358520875,
      "loss": 2.3432,
      "step": 573780
    },
    {
      "epoch": 922.51,
      "learning_rate": 0.007787069704983919,
      "loss": 2.3319,
      "step": 573800
    },
    {
      "epoch": 922.54,
      "learning_rate": 0.007783854274115761,
      "loss": 2.3219,
      "step": 573820
    },
    {
      "epoch": 922.57,
      "learning_rate": 0.007780638843247593,
      "loss": 2.3389,
      "step": 573840
    },
    {
      "epoch": 922.6,
      "learning_rate": 0.007777423412379424,
      "loss": 2.3279,
      "step": 573860
    },
    {
      "epoch": 922.64,
      "learning_rate": 0.007774207981511254,
      "loss": 2.3487,
      "step": 573880
    },
    {
      "epoch": 922.67,
      "learning_rate": 0.007770992550643084,
      "loss": 2.3225,
      "step": 573900
    },
    {
      "epoch": 922.7,
      "learning_rate": 0.007767777119774916,
      "loss": 2.3359,
      "step": 573920
    },
    {
      "epoch": 922.73,
      "learning_rate": 0.007764561688906758,
      "loss": 2.3296,
      "step": 573940
    },
    {
      "epoch": 922.77,
      "learning_rate": 0.007761346258038589,
      "loss": 2.346,
      "step": 573960
    },
    {
      "epoch": 922.8,
      "learning_rate": 0.007758130827170419,
      "loss": 2.3294,
      "step": 573980
    },
    {
      "epoch": 922.83,
      "learning_rate": 0.007754915396302249,
      "loss": 2.3591,
      "step": 574000
    },
    {
      "epoch": 922.86,
      "learning_rate": 0.007751699965434081,
      "loss": 2.3383,
      "step": 574020
    },
    {
      "epoch": 922.89,
      "learning_rate": 0.007748484534565911,
      "loss": 2.3331,
      "step": 574040
    },
    {
      "epoch": 922.93,
      "learning_rate": 0.007745269103697754,
      "loss": 2.3218,
      "step": 574060
    },
    {
      "epoch": 922.96,
      "learning_rate": 0.007742053672829584,
      "loss": 2.3285,
      "step": 574080
    },
    {
      "epoch": 922.99,
      "learning_rate": 0.007738838241961414,
      "loss": 2.347,
      "step": 574100
    },
    {
      "epoch": 923.0,
      "eval_accuracy": {
        "accuracy": 0.47485034595351006
      },
      "eval_loss": 2.4429824352264404,
      "eval_runtime": 3.0352,
      "eval_samples_per_second": 4237.984,
      "eval_steps_per_second": 66.224,
      "step": 574106
    },
    {
      "epoch": 923.02,
      "learning_rate": 0.007735622811093246,
      "loss": 2.3241,
      "step": 574120
    },
    {
      "epoch": 923.05,
      "learning_rate": 0.007732407380225077,
      "loss": 2.3419,
      "step": 574140
    },
    {
      "epoch": 923.09,
      "learning_rate": 0.007729191949356919,
      "loss": 2.3478,
      "step": 574160
    },
    {
      "epoch": 923.12,
      "learning_rate": 0.007725976518488751,
      "loss": 2.3298,
      "step": 574180
    },
    {
      "epoch": 923.15,
      "learning_rate": 0.007722761087620581,
      "loss": 2.3472,
      "step": 574200
    },
    {
      "epoch": 923.18,
      "learning_rate": 0.007719545656752411,
      "loss": 2.3409,
      "step": 574220
    },
    {
      "epoch": 923.22,
      "learning_rate": 0.007716330225884242,
      "loss": 2.3295,
      "step": 574240
    },
    {
      "epoch": 923.25,
      "learning_rate": 0.007713114795016073,
      "loss": 2.339,
      "step": 574260
    },
    {
      "epoch": 923.28,
      "learning_rate": 0.007709899364147916,
      "loss": 2.3416,
      "step": 574280
    },
    {
      "epoch": 923.31,
      "learning_rate": 0.007706683933279746,
      "loss": 2.3331,
      "step": 574300
    },
    {
      "epoch": 923.34,
      "learning_rate": 0.007703468502411576,
      "loss": 2.3277,
      "step": 574320
    },
    {
      "epoch": 923.38,
      "learning_rate": 0.007700253071543407,
      "loss": 2.3299,
      "step": 574340
    },
    {
      "epoch": 923.41,
      "learning_rate": 0.007697037640675238,
      "loss": 2.3333,
      "step": 574360
    },
    {
      "epoch": 923.44,
      "learning_rate": 0.007693822209807068,
      "loss": 2.3286,
      "step": 574380
    },
    {
      "epoch": 923.47,
      "learning_rate": 0.007690606778938911,
      "loss": 2.3255,
      "step": 574400
    },
    {
      "epoch": 923.5,
      "learning_rate": 0.007687391348070741,
      "loss": 2.3412,
      "step": 574420
    },
    {
      "epoch": 923.54,
      "learning_rate": 0.007684175917202572,
      "loss": 2.3229,
      "step": 574440
    },
    {
      "epoch": 923.57,
      "learning_rate": 0.007680960486334404,
      "loss": 2.3304,
      "step": 574460
    },
    {
      "epoch": 923.6,
      "learning_rate": 0.007677745055466235,
      "loss": 2.3429,
      "step": 574480
    },
    {
      "epoch": 923.63,
      "learning_rate": 0.0076745296245980775,
      "loss": 2.3431,
      "step": 574500
    },
    {
      "epoch": 923.67,
      "learning_rate": 0.007671314193729907,
      "loss": 2.3348,
      "step": 574520
    },
    {
      "epoch": 923.7,
      "learning_rate": 0.007668098762861737,
      "loss": 2.3152,
      "step": 574540
    },
    {
      "epoch": 923.73,
      "learning_rate": 0.007664883331993569,
      "loss": 2.326,
      "step": 574560
    },
    {
      "epoch": 923.76,
      "learning_rate": 0.0076616679011254,
      "loss": 2.3336,
      "step": 574580
    },
    {
      "epoch": 923.79,
      "learning_rate": 0.0076584524702572295,
      "loss": 2.3419,
      "step": 574600
    },
    {
      "epoch": 923.83,
      "learning_rate": 0.007655237039389072,
      "loss": 2.3285,
      "step": 574620
    },
    {
      "epoch": 923.86,
      "learning_rate": 0.007652021608520902,
      "loss": 2.3456,
      "step": 574640
    },
    {
      "epoch": 923.89,
      "learning_rate": 0.007648806177652734,
      "loss": 2.3418,
      "step": 574660
    },
    {
      "epoch": 923.92,
      "learning_rate": 0.007645590746784565,
      "loss": 2.3443,
      "step": 574680
    },
    {
      "epoch": 923.95,
      "learning_rate": 0.0076423753159163945,
      "loss": 2.3297,
      "step": 574700
    },
    {
      "epoch": 923.99,
      "learning_rate": 0.007639159885048226,
      "loss": 2.3266,
      "step": 574720
    },
    {
      "epoch": 924.0,
      "eval_accuracy": {
        "accuracy": 0.476638420275208
      },
      "eval_loss": 2.454216718673706,
      "eval_runtime": 3.2872,
      "eval_samples_per_second": 3913.071,
      "eval_steps_per_second": 61.146,
      "step": 574728
    },
    {
      "epoch": 924.02,
      "learning_rate": 0.007635944454180067,
      "loss": 2.3265,
      "step": 574740
    },
    {
      "epoch": 924.05,
      "learning_rate": 0.007632729023311899,
      "loss": 2.3545,
      "step": 574760
    },
    {
      "epoch": 924.08,
      "learning_rate": 0.0076295135924437305,
      "loss": 2.3438,
      "step": 574780
    },
    {
      "epoch": 924.12,
      "learning_rate": 0.007626298161575561,
      "loss": 2.3423,
      "step": 574800
    },
    {
      "epoch": 924.15,
      "learning_rate": 0.007623082730707391,
      "loss": 2.3408,
      "step": 574820
    },
    {
      "epoch": 924.18,
      "learning_rate": 0.007619867299839234,
      "loss": 2.337,
      "step": 574840
    },
    {
      "epoch": 924.21,
      "learning_rate": 0.007616651868971064,
      "loss": 2.3401,
      "step": 574860
    },
    {
      "epoch": 924.24,
      "learning_rate": 0.0076134364381028954,
      "loss": 2.3233,
      "step": 574880
    },
    {
      "epoch": 924.28,
      "learning_rate": 0.007610221007234726,
      "loss": 2.3219,
      "step": 574900
    },
    {
      "epoch": 924.31,
      "learning_rate": 0.007607005576366556,
      "loss": 2.3425,
      "step": 574920
    },
    {
      "epoch": 924.34,
      "learning_rate": 0.007603790145498388,
      "loss": 2.3393,
      "step": 574940
    },
    {
      "epoch": 924.37,
      "learning_rate": 0.007600574714630229,
      "loss": 2.3183,
      "step": 574960
    },
    {
      "epoch": 924.41,
      "learning_rate": 0.00759735928376206,
      "loss": 2.3358,
      "step": 574980
    },
    {
      "epoch": 924.44,
      "learning_rate": 0.007594143852893891,
      "loss": 2.3213,
      "step": 575000
    },
    {
      "epoch": 924.47,
      "learning_rate": 0.007590928422025721,
      "loss": 2.3332,
      "step": 575020
    },
    {
      "epoch": 924.5,
      "learning_rate": 0.007587712991157553,
      "loss": 2.3296,
      "step": 575040
    },
    {
      "epoch": 924.53,
      "learning_rate": 0.007584497560289394,
      "loss": 2.3154,
      "step": 575060
    },
    {
      "epoch": 924.57,
      "learning_rate": 0.007581282129421225,
      "loss": 2.3376,
      "step": 575080
    },
    {
      "epoch": 924.6,
      "learning_rate": 0.007578066698553057,
      "loss": 2.3323,
      "step": 575100
    },
    {
      "epoch": 924.63,
      "learning_rate": 0.007574851267684888,
      "loss": 2.3353,
      "step": 575120
    },
    {
      "epoch": 924.66,
      "learning_rate": 0.007571635836816718,
      "loss": 2.3372,
      "step": 575140
    },
    {
      "epoch": 924.69,
      "learning_rate": 0.007568420405948549,
      "loss": 2.3318,
      "step": 575160
    },
    {
      "epoch": 924.73,
      "learning_rate": 0.00756520497508039,
      "loss": 2.3325,
      "step": 575180
    },
    {
      "epoch": 924.76,
      "learning_rate": 0.007561989544212222,
      "loss": 2.3536,
      "step": 575200
    },
    {
      "epoch": 924.79,
      "learning_rate": 0.007558774113344053,
      "loss": 2.3358,
      "step": 575220
    },
    {
      "epoch": 924.82,
      "learning_rate": 0.007555558682475883,
      "loss": 2.3101,
      "step": 575240
    },
    {
      "epoch": 924.86,
      "learning_rate": 0.007552343251607714,
      "loss": 2.329,
      "step": 575260
    },
    {
      "epoch": 924.89,
      "learning_rate": 0.007549127820739545,
      "loss": 2.367,
      "step": 575280
    },
    {
      "epoch": 924.92,
      "learning_rate": 0.007545912389871387,
      "loss": 2.3351,
      "step": 575300
    },
    {
      "epoch": 924.95,
      "learning_rate": 0.007542696959003218,
      "loss": 2.3373,
      "step": 575320
    },
    {
      "epoch": 924.98,
      "learning_rate": 0.007539481528135048,
      "loss": 2.343,
      "step": 575340
    },
    {
      "epoch": 925.0,
      "eval_accuracy": {
        "accuracy": 0.4735287258026899
      },
      "eval_loss": 2.450148582458496,
      "eval_runtime": 3.2588,
      "eval_samples_per_second": 3947.168,
      "eval_steps_per_second": 61.679,
      "step": 575350
    },
    {
      "epoch": 925.02,
      "learning_rate": 0.007536266097266879,
      "loss": 2.3364,
      "step": 575360
    },
    {
      "epoch": 925.05,
      "learning_rate": 0.007533050666398711,
      "loss": 2.3482,
      "step": 575380
    },
    {
      "epoch": 925.08,
      "learning_rate": 0.007529835235530552,
      "loss": 2.3404,
      "step": 575400
    },
    {
      "epoch": 925.11,
      "learning_rate": 0.007526619804662384,
      "loss": 2.3294,
      "step": 575420
    },
    {
      "epoch": 925.14,
      "learning_rate": 0.007523404373794214,
      "loss": 2.3492,
      "step": 575440
    },
    {
      "epoch": 925.18,
      "learning_rate": 0.007520188942926044,
      "loss": 2.3211,
      "step": 575460
    },
    {
      "epoch": 925.21,
      "learning_rate": 0.007516973512057876,
      "loss": 2.3285,
      "step": 575480
    },
    {
      "epoch": 925.24,
      "learning_rate": 0.007513758081189707,
      "loss": 2.3473,
      "step": 575500
    },
    {
      "epoch": 925.27,
      "learning_rate": 0.007510542650321549,
      "loss": 2.3255,
      "step": 575520
    },
    {
      "epoch": 925.31,
      "learning_rate": 0.007507327219453379,
      "loss": 2.3368,
      "step": 575540
    },
    {
      "epoch": 925.34,
      "learning_rate": 0.007504111788585209,
      "loss": 2.3354,
      "step": 575560
    },
    {
      "epoch": 925.37,
      "learning_rate": 0.007500896357717041,
      "loss": 2.3296,
      "step": 575580
    },
    {
      "epoch": 925.4,
      "learning_rate": 0.007497680926848872,
      "loss": 2.335,
      "step": 575600
    },
    {
      "epoch": 925.43,
      "learning_rate": 0.007494465495980703,
      "loss": 2.3466,
      "step": 575620
    },
    {
      "epoch": 925.47,
      "learning_rate": 0.007491250065112544,
      "loss": 2.3416,
      "step": 575640
    },
    {
      "epoch": 925.5,
      "learning_rate": 0.007488195405787786,
      "loss": 2.3482,
      "step": 575660
    },
    {
      "epoch": 925.53,
      "learning_rate": 0.007484979974919617,
      "loss": 2.3323,
      "step": 575680
    },
    {
      "epoch": 925.56,
      "learning_rate": 0.007481764544051448,
      "loss": 2.3342,
      "step": 575700
    },
    {
      "epoch": 925.59,
      "learning_rate": 0.00747854911318328,
      "loss": 2.343,
      "step": 575720
    },
    {
      "epoch": 925.63,
      "learning_rate": 0.007475333682315111,
      "loss": 2.3235,
      "step": 575740
    },
    {
      "epoch": 925.66,
      "learning_rate": 0.007472118251446941,
      "loss": 2.3251,
      "step": 575760
    },
    {
      "epoch": 925.69,
      "learning_rate": 0.007468902820578782,
      "loss": 2.3241,
      "step": 575780
    },
    {
      "epoch": 925.72,
      "learning_rate": 0.007465687389710614,
      "loss": 2.335,
      "step": 575800
    },
    {
      "epoch": 925.76,
      "learning_rate": 0.007462471958842445,
      "loss": 2.32,
      "step": 575820
    },
    {
      "epoch": 925.79,
      "learning_rate": 0.007459256527974276,
      "loss": 2.3288,
      "step": 575840
    },
    {
      "epoch": 925.82,
      "learning_rate": 0.007456041097106106,
      "loss": 2.3264,
      "step": 575860
    },
    {
      "epoch": 925.85,
      "learning_rate": 0.007452825666237947,
      "loss": 2.3184,
      "step": 575880
    },
    {
      "epoch": 925.88,
      "learning_rate": 0.007449610235369779,
      "loss": 2.3653,
      "step": 575900
    },
    {
      "epoch": 925.92,
      "learning_rate": 0.00744639480450161,
      "loss": 2.3327,
      "step": 575920
    },
    {
      "epoch": 925.95,
      "learning_rate": 0.007443179373633441,
      "loss": 2.3253,
      "step": 575940
    },
    {
      "epoch": 925.98,
      "learning_rate": 0.007439963942765271,
      "loss": 2.3304,
      "step": 575960
    },
    {
      "epoch": 926.0,
      "eval_accuracy": {
        "accuracy": 0.47648293555158205
      },
      "eval_loss": 2.4505927562713623,
      "eval_runtime": 3.0597,
      "eval_samples_per_second": 4203.961,
      "eval_steps_per_second": 65.692,
      "step": 575972
    },
    {
      "epoch": 926.01,
      "learning_rate": 0.007436748511897101,
      "loss": 2.3266,
      "step": 575980
    },
    {
      "epoch": 926.05,
      "learning_rate": 0.007433533081028944,
      "loss": 2.3174,
      "step": 576000
    },
    {
      "epoch": 926.08,
      "learning_rate": 0.007430317650160775,
      "loss": 2.3348,
      "step": 576020
    },
    {
      "epoch": 926.11,
      "learning_rate": 0.007427102219292606,
      "loss": 2.3328,
      "step": 576040
    },
    {
      "epoch": 926.14,
      "learning_rate": 0.007423886788424438,
      "loss": 2.3394,
      "step": 576060
    },
    {
      "epoch": 926.17,
      "learning_rate": 0.007420671357556268,
      "loss": 2.3508,
      "step": 576080
    },
    {
      "epoch": 926.21,
      "learning_rate": 0.007417455926688098,
      "loss": 2.3508,
      "step": 576100
    },
    {
      "epoch": 926.24,
      "learning_rate": 0.0074142404958199406,
      "loss": 2.3473,
      "step": 576120
    },
    {
      "epoch": 926.27,
      "learning_rate": 0.007411025064951771,
      "loss": 2.3143,
      "step": 576140
    },
    {
      "epoch": 926.3,
      "learning_rate": 0.007407809634083603,
      "loss": 2.3156,
      "step": 576160
    },
    {
      "epoch": 926.33,
      "learning_rate": 0.007404594203215433,
      "loss": 2.3502,
      "step": 576180
    },
    {
      "epoch": 926.37,
      "learning_rate": 0.007401378772347263,
      "loss": 2.335,
      "step": 576200
    },
    {
      "epoch": 926.4,
      "learning_rate": 0.0073981633414791055,
      "loss": 2.3097,
      "step": 576220
    },
    {
      "epoch": 926.43,
      "learning_rate": 0.007394947910610936,
      "loss": 2.3369,
      "step": 576240
    },
    {
      "epoch": 926.46,
      "learning_rate": 0.007391732479742768,
      "loss": 2.3065,
      "step": 576260
    },
    {
      "epoch": 926.5,
      "learning_rate": 0.007388517048874598,
      "loss": 2.3414,
      "step": 576280
    },
    {
      "epoch": 926.53,
      "learning_rate": 0.007385301618006428,
      "loss": 2.3319,
      "step": 576300
    },
    {
      "epoch": 926.56,
      "learning_rate": 0.007382086187138259,
      "loss": 2.325,
      "step": 576320
    },
    {
      "epoch": 926.59,
      "learning_rate": 0.007378870756270101,
      "loss": 2.3094,
      "step": 576340
    },
    {
      "epoch": 926.62,
      "learning_rate": 0.007375655325401933,
      "loss": 2.3366,
      "step": 576360
    },
    {
      "epoch": 926.66,
      "learning_rate": 0.0073724398945337645,
      "loss": 2.3218,
      "step": 576380
    },
    {
      "epoch": 926.69,
      "learning_rate": 0.007369224463665594,
      "loss": 2.342,
      "step": 576400
    },
    {
      "epoch": 926.72,
      "learning_rate": 0.007366009032797424,
      "loss": 2.348,
      "step": 576420
    },
    {
      "epoch": 926.75,
      "learning_rate": 0.007362793601929256,
      "loss": 2.3348,
      "step": 576440
    },
    {
      "epoch": 926.78,
      "learning_rate": 0.007359578171061098,
      "loss": 2.3238,
      "step": 576460
    },
    {
      "epoch": 926.82,
      "learning_rate": 0.0073563627401929295,
      "loss": 2.3307,
      "step": 576480
    },
    {
      "epoch": 926.85,
      "learning_rate": 0.007353147309324759,
      "loss": 2.343,
      "step": 576500
    },
    {
      "epoch": 926.88,
      "learning_rate": 0.007349931878456589,
      "loss": 2.3193,
      "step": 576520
    },
    {
      "epoch": 926.91,
      "learning_rate": 0.007346716447588421,
      "loss": 2.346,
      "step": 576540
    },
    {
      "epoch": 926.95,
      "learning_rate": 0.007343501016720263,
      "loss": 2.336,
      "step": 576560
    },
    {
      "epoch": 926.98,
      "learning_rate": 0.0073402855858520945,
      "loss": 2.3433,
      "step": 576580
    },
    {
      "epoch": 927.0,
      "eval_accuracy": {
        "accuracy": 0.47570551193345256
      },
      "eval_loss": 2.4580118656158447,
      "eval_runtime": 4.2865,
      "eval_samples_per_second": 3000.803,
      "eval_steps_per_second": 46.891,
      "step": 576594
    },
    {
      "epoch": 927.01,
      "learning_rate": 0.007337070154983924,
      "loss": 2.3326,
      "step": 576600
    },
    {
      "epoch": 927.04,
      "learning_rate": 0.007333854724115754,
      "loss": 2.35,
      "step": 576620
    },
    {
      "epoch": 927.07,
      "learning_rate": 0.007330639293247586,
      "loss": 2.3183,
      "step": 576640
    },
    {
      "epoch": 927.11,
      "learning_rate": 0.0073274238623794175,
      "loss": 2.3405,
      "step": 576660
    },
    {
      "epoch": 927.14,
      "learning_rate": 0.0073242084315112595,
      "loss": 2.3175,
      "step": 576680
    },
    {
      "epoch": 927.17,
      "learning_rate": 0.007320993000643091,
      "loss": 2.3382,
      "step": 576700
    },
    {
      "epoch": 927.2,
      "learning_rate": 0.007317777569774921,
      "loss": 2.3192,
      "step": 576720
    },
    {
      "epoch": 927.23,
      "learning_rate": 0.007314562138906751,
      "loss": 2.3406,
      "step": 576740
    },
    {
      "epoch": 927.27,
      "learning_rate": 0.0073113467080385824,
      "loss": 2.3335,
      "step": 576760
    },
    {
      "epoch": 927.3,
      "learning_rate": 0.007308131277170413,
      "loss": 2.3305,
      "step": 576780
    },
    {
      "epoch": 927.33,
      "learning_rate": 0.007304915846302256,
      "loss": 2.3253,
      "step": 576800
    },
    {
      "epoch": 927.36,
      "learning_rate": 0.007301700415434086,
      "loss": 2.3371,
      "step": 576820
    },
    {
      "epoch": 927.4,
      "learning_rate": 0.007298484984565916,
      "loss": 2.3147,
      "step": 576840
    },
    {
      "epoch": 927.43,
      "learning_rate": 0.007295269553697747,
      "loss": 2.3402,
      "step": 576860
    },
    {
      "epoch": 927.46,
      "learning_rate": 0.007292054122829578,
      "loss": 2.3231,
      "step": 576880
    },
    {
      "epoch": 927.49,
      "learning_rate": 0.007288838691961421,
      "loss": 2.3301,
      "step": 576900
    },
    {
      "epoch": 927.52,
      "learning_rate": 0.007285623261093251,
      "loss": 2.3404,
      "step": 576920
    },
    {
      "epoch": 927.56,
      "learning_rate": 0.007282407830225081,
      "loss": 2.336,
      "step": 576940
    },
    {
      "epoch": 927.59,
      "learning_rate": 0.007279192399356912,
      "loss": 2.3379,
      "step": 576960
    },
    {
      "epoch": 927.62,
      "learning_rate": 0.007275976968488744,
      "loss": 2.3214,
      "step": 576980
    },
    {
      "epoch": 927.65,
      "learning_rate": 0.007272761537620575,
      "loss": 2.3469,
      "step": 577000
    },
    {
      "epoch": 927.68,
      "learning_rate": 0.007269546106752418,
      "loss": 2.3274,
      "step": 577020
    },
    {
      "epoch": 927.72,
      "learning_rate": 0.0072663306758842475,
      "loss": 2.3333,
      "step": 577040
    },
    {
      "epoch": 927.75,
      "learning_rate": 0.007263115245016077,
      "loss": 2.3318,
      "step": 577060
    },
    {
      "epoch": 927.78,
      "learning_rate": 0.007259899814147909,
      "loss": 2.3221,
      "step": 577080
    },
    {
      "epoch": 927.81,
      "learning_rate": 0.00725668438327974,
      "loss": 2.3364,
      "step": 577100
    },
    {
      "epoch": 927.85,
      "learning_rate": 0.00725346895241157,
      "loss": 2.3271,
      "step": 577120
    },
    {
      "epoch": 927.88,
      "learning_rate": 0.0072502535215434125,
      "loss": 2.3528,
      "step": 577140
    },
    {
      "epoch": 927.91,
      "learning_rate": 0.007247038090675242,
      "loss": 2.3406,
      "step": 577160
    },
    {
      "epoch": 927.94,
      "learning_rate": 0.007243822659807074,
      "loss": 2.3346,
      "step": 577180
    },
    {
      "epoch": 927.97,
      "learning_rate": 0.007240607228938905,
      "loss": 2.3368,
      "step": 577200
    },
    {
      "epoch": 928.0,
      "eval_accuracy": {
        "accuracy": 0.4772603591697116
      },
      "eval_loss": 2.452199697494507,
      "eval_runtime": 3.3345,
      "eval_samples_per_second": 3857.507,
      "eval_steps_per_second": 60.278,
      "step": 577216
    },
    {
      "epoch": 928.01,
      "learning_rate": 0.007237391798070735,
      "loss": 2.3236,
      "step": 577220
    },
    {
      "epoch": 928.04,
      "learning_rate": 0.0072341763672025775,
      "loss": 2.336,
      "step": 577240
    },
    {
      "epoch": 928.07,
      "learning_rate": 0.007230960936334407,
      "loss": 2.33,
      "step": 577260
    },
    {
      "epoch": 928.1,
      "learning_rate": 0.007227745505466239,
      "loss": 2.3293,
      "step": 577280
    },
    {
      "epoch": 928.14,
      "learning_rate": 0.007224530074598071,
      "loss": 2.3359,
      "step": 577300
    },
    {
      "epoch": 928.17,
      "learning_rate": 0.007221314643729901,
      "loss": 2.3265,
      "step": 577320
    },
    {
      "epoch": 928.2,
      "learning_rate": 0.007218099212861731,
      "loss": 2.3437,
      "step": 577340
    },
    {
      "epoch": 928.23,
      "learning_rate": 0.007214883781993574,
      "loss": 2.326,
      "step": 577360
    },
    {
      "epoch": 928.26,
      "learning_rate": 0.007211668351125404,
      "loss": 2.3336,
      "step": 577380
    },
    {
      "epoch": 928.3,
      "learning_rate": 0.007208452920257236,
      "loss": 2.3093,
      "step": 577400
    },
    {
      "epoch": 928.33,
      "learning_rate": 0.007205237489389066,
      "loss": 2.336,
      "step": 577420
    },
    {
      "epoch": 928.36,
      "learning_rate": 0.007202022058520896,
      "loss": 2.3343,
      "step": 577440
    },
    {
      "epoch": 928.39,
      "learning_rate": 0.007198806627652728,
      "loss": 2.3381,
      "step": 577460
    },
    {
      "epoch": 928.42,
      "learning_rate": 0.007195591196784569,
      "loss": 2.3341,
      "step": 577480
    },
    {
      "epoch": 928.46,
      "learning_rate": 0.007192375765916401,
      "loss": 2.3251,
      "step": 577500
    },
    {
      "epoch": 928.49,
      "learning_rate": 0.007189160335048231,
      "loss": 2.3333,
      "step": 577520
    },
    {
      "epoch": 928.52,
      "learning_rate": 0.007185944904180061,
      "loss": 2.3152,
      "step": 577540
    },
    {
      "epoch": 928.55,
      "learning_rate": 0.007182729473311893,
      "loss": 2.3341,
      "step": 577560
    },
    {
      "epoch": 928.59,
      "learning_rate": 0.007179514042443736,
      "loss": 2.3253,
      "step": 577580
    },
    {
      "epoch": 928.62,
      "learning_rate": 0.007176298611575566,
      "loss": 2.3277,
      "step": 577600
    },
    {
      "epoch": 928.65,
      "learning_rate": 0.007173083180707397,
      "loss": 2.3243,
      "step": 577620
    },
    {
      "epoch": 928.68,
      "learning_rate": 0.007169867749839228,
      "loss": 2.3526,
      "step": 577640
    },
    {
      "epoch": 928.71,
      "learning_rate": 0.007166652318971058,
      "loss": 2.337,
      "step": 577660
    },
    {
      "epoch": 928.75,
      "learning_rate": 0.007163436888102889,
      "loss": 2.3373,
      "step": 577680
    },
    {
      "epoch": 928.78,
      "learning_rate": 0.007160221457234731,
      "loss": 2.3247,
      "step": 577700
    },
    {
      "epoch": 928.81,
      "learning_rate": 0.007157006026366562,
      "loss": 2.327,
      "step": 577720
    },
    {
      "epoch": 928.84,
      "learning_rate": 0.007153790595498393,
      "loss": 2.3318,
      "step": 577740
    },
    {
      "epoch": 928.87,
      "learning_rate": 0.007150575164630223,
      "loss": 2.3337,
      "step": 577760
    },
    {
      "epoch": 928.91,
      "learning_rate": 0.007147359733762054,
      "loss": 2.3129,
      "step": 577780
    },
    {
      "epoch": 928.94,
      "learning_rate": 0.007144144302893896,
      "loss": 2.3453,
      "step": 577800
    },
    {
      "epoch": 928.97,
      "learning_rate": 0.007140928872025727,
      "loss": 2.3346,
      "step": 577820
    },
    {
      "epoch": 929.0,
      "eval_accuracy": {
        "accuracy": 0.4774935862551504
      },
      "eval_loss": 2.452629566192627,
      "eval_runtime": 3.4606,
      "eval_samples_per_second": 3716.95,
      "eval_steps_per_second": 58.082,
      "step": 577838
    },
    {
      "epoch": 929.0,
      "learning_rate": 0.007137713441157558,
      "loss": 2.3257,
      "step": 577840
    },
    {
      "epoch": 929.04,
      "learning_rate": 0.0071344980102893895,
      "loss": 2.3251,
      "step": 577860
    },
    {
      "epoch": 929.07,
      "learning_rate": 0.007131282579421219,
      "loss": 2.3221,
      "step": 577880
    },
    {
      "epoch": 929.1,
      "learning_rate": 0.007128067148553051,
      "loss": 2.3128,
      "step": 577900
    },
    {
      "epoch": 929.13,
      "learning_rate": 0.007124851717684892,
      "loss": 2.328,
      "step": 577920
    },
    {
      "epoch": 929.16,
      "learning_rate": 0.007121636286816724,
      "loss": 2.3079,
      "step": 577940
    },
    {
      "epoch": 929.2,
      "learning_rate": 0.0071184208559485545,
      "loss": 2.3225,
      "step": 577960
    },
    {
      "epoch": 929.23,
      "learning_rate": 0.007115205425080384,
      "loss": 2.3299,
      "step": 577980
    },
    {
      "epoch": 929.26,
      "learning_rate": 0.007111989994212216,
      "loss": 2.3337,
      "step": 578000
    },
    {
      "epoch": 929.29,
      "learning_rate": 0.007108774563344047,
      "loss": 2.3377,
      "step": 578020
    },
    {
      "epoch": 929.32,
      "learning_rate": 0.007105559132475889,
      "loss": 2.3263,
      "step": 578040
    },
    {
      "epoch": 929.36,
      "learning_rate": 0.0071023437016077195,
      "loss": 2.3295,
      "step": 578060
    },
    {
      "epoch": 929.39,
      "learning_rate": 0.007099128270739549,
      "loss": 2.327,
      "step": 578080
    },
    {
      "epoch": 929.42,
      "learning_rate": 0.007095912839871381,
      "loss": 2.3306,
      "step": 578100
    },
    {
      "epoch": 929.45,
      "learning_rate": 0.007092697409003212,
      "loss": 2.3212,
      "step": 578120
    },
    {
      "epoch": 929.49,
      "learning_rate": 0.007089481978135054,
      "loss": 2.3433,
      "step": 578140
    },
    {
      "epoch": 929.52,
      "learning_rate": 0.0070862665472668845,
      "loss": 2.3285,
      "step": 578160
    },
    {
      "epoch": 929.55,
      "learning_rate": 0.007083051116398716,
      "loss": 2.3134,
      "step": 578180
    },
    {
      "epoch": 929.58,
      "learning_rate": 0.007079835685530546,
      "loss": 2.3384,
      "step": 578200
    },
    {
      "epoch": 929.61,
      "learning_rate": 0.007076620254662378,
      "loss": 2.3454,
      "step": 578220
    },
    {
      "epoch": 929.65,
      "learning_rate": 0.007073404823794208,
      "loss": 2.3161,
      "step": 578240
    },
    {
      "epoch": 929.68,
      "learning_rate": 0.00707018939292605,
      "loss": 2.3326,
      "step": 578260
    },
    {
      "epoch": 929.71,
      "learning_rate": 0.007066973962057881,
      "loss": 2.3508,
      "step": 578280
    },
    {
      "epoch": 929.74,
      "learning_rate": 0.007063758531189711,
      "loss": 2.3203,
      "step": 578300
    },
    {
      "epoch": 929.77,
      "learning_rate": 0.007060543100321543,
      "loss": 2.3195,
      "step": 578320
    },
    {
      "epoch": 929.81,
      "learning_rate": 0.007057327669453373,
      "loss": 2.3347,
      "step": 578340
    },
    {
      "epoch": 929.84,
      "learning_rate": 0.007054112238585205,
      "loss": 2.3293,
      "step": 578360
    },
    {
      "epoch": 929.87,
      "learning_rate": 0.007050896807717046,
      "loss": 2.3327,
      "step": 578380
    },
    {
      "epoch": 929.9,
      "learning_rate": 0.007047681376848876,
      "loss": 2.3404,
      "step": 578400
    },
    {
      "epoch": 929.94,
      "learning_rate": 0.007044465945980708,
      "loss": 2.3341,
      "step": 578420
    },
    {
      "epoch": 929.97,
      "learning_rate": 0.007041250515112538,
      "loss": 2.3447,
      "step": 578440
    },
    {
      "epoch": 930.0,
      "learning_rate": 0.00703803508424437,
      "loss": 2.336,
      "step": 578460
    },
    {
      "epoch": 930.0,
      "eval_accuracy": {
        "accuracy": 0.4773381015315245
      },
      "eval_loss": 2.444546699523926,
      "eval_runtime": 3.4157,
      "eval_samples_per_second": 3765.818,
      "eval_steps_per_second": 58.845,
      "step": 578460
    },
    {
      "epoch": 930.03,
      "learning_rate": 0.007034819653376211,
      "loss": 2.318,
      "step": 578480
    },
    {
      "epoch": 930.06,
      "learning_rate": 0.007031604222508043,
      "loss": 2.3336,
      "step": 578500
    },
    {
      "epoch": 930.1,
      "learning_rate": 0.007028388791639873,
      "loss": 2.3191,
      "step": 578520
    },
    {
      "epoch": 930.13,
      "learning_rate": 0.007025173360771704,
      "loss": 2.3137,
      "step": 578540
    },
    {
      "epoch": 930.16,
      "learning_rate": 0.007021957929903535,
      "loss": 2.309,
      "step": 578560
    },
    {
      "epoch": 930.19,
      "learning_rate": 0.0070187424990353665,
      "loss": 2.329,
      "step": 578580
    },
    {
      "epoch": 930.23,
      "learning_rate": 0.007015527068167208,
      "loss": 2.3213,
      "step": 578600
    },
    {
      "epoch": 930.26,
      "learning_rate": 0.0070123116372990376,
      "loss": 2.329,
      "step": 578620
    },
    {
      "epoch": 930.29,
      "learning_rate": 0.007009096206430869,
      "loss": 2.3394,
      "step": 578640
    },
    {
      "epoch": 930.32,
      "learning_rate": 0.0070058807755627,
      "loss": 2.3352,
      "step": 578660
    },
    {
      "epoch": 930.35,
      "learning_rate": 0.0070026653446945315,
      "loss": 2.328,
      "step": 578680
    },
    {
      "epoch": 930.39,
      "learning_rate": 0.006999449913826361,
      "loss": 2.3308,
      "step": 578700
    },
    {
      "epoch": 930.42,
      "learning_rate": 0.0069962344829582026,
      "loss": 2.3365,
      "step": 578720
    },
    {
      "epoch": 930.45,
      "learning_rate": 0.006993019052090034,
      "loss": 2.3392,
      "step": 578740
    },
    {
      "epoch": 930.48,
      "learning_rate": 0.006989803621221865,
      "loss": 2.3336,
      "step": 578760
    },
    {
      "epoch": 930.51,
      "learning_rate": 0.0069865881903536965,
      "loss": 2.3397,
      "step": 578780
    },
    {
      "epoch": 930.55,
      "learning_rate": 0.006983372759485528,
      "loss": 2.3335,
      "step": 578800
    },
    {
      "epoch": 930.58,
      "learning_rate": 0.006980157328617369,
      "loss": 2.3195,
      "step": 578820
    },
    {
      "epoch": 930.61,
      "learning_rate": 0.006976941897749199,
      "loss": 2.326,
      "step": 578840
    },
    {
      "epoch": 930.64,
      "learning_rate": 0.006973726466881031,
      "loss": 2.3173,
      "step": 578860
    },
    {
      "epoch": 930.68,
      "learning_rate": 0.0069705110360128615,
      "loss": 2.3207,
      "step": 578880
    },
    {
      "epoch": 930.71,
      "learning_rate": 0.006967295605144693,
      "loss": 2.3329,
      "step": 578900
    },
    {
      "epoch": 930.74,
      "learning_rate": 0.006964080174276523,
      "loss": 2.3194,
      "step": 578920
    },
    {
      "epoch": 930.77,
      "learning_rate": 0.006960864743408364,
      "loss": 2.3408,
      "step": 578940
    },
    {
      "epoch": 930.8,
      "learning_rate": 0.006957649312540196,
      "loss": 2.322,
      "step": 578960
    },
    {
      "epoch": 930.84,
      "learning_rate": 0.0069544338816720265,
      "loss": 2.3183,
      "step": 578980
    },
    {
      "epoch": 930.87,
      "learning_rate": 0.006951218450803858,
      "loss": 2.3384,
      "step": 579000
    },
    {
      "epoch": 930.9,
      "learning_rate": 0.006948003019935688,
      "loss": 2.3475,
      "step": 579020
    },
    {
      "epoch": 930.93,
      "learning_rate": 0.00694478758906752,
      "loss": 2.3283,
      "step": 579040
    },
    {
      "epoch": 930.96,
      "learning_rate": 0.006941732929742761,
      "loss": 2.3409,
      "step": 579060
    },
    {
      "epoch": 931.0,
      "learning_rate": 0.006938517498874603,
      "loss": 2.3274,
      "step": 579080
    },
    {
      "epoch": 931.0,
      "eval_accuracy": {
        "accuracy": 0.47508357303894894
      },
      "eval_loss": 2.4451615810394287,
      "eval_runtime": 3.8272,
      "eval_samples_per_second": 3360.943,
      "eval_steps_per_second": 52.519,
      "step": 579082
    },
    {
      "epoch": 931.03,
      "learning_rate": 0.006935302068006435,
      "loss": 2.3308,
      "step": 579100
    },
    {
      "epoch": 931.06,
      "learning_rate": 0.0069320866371382645,
      "loss": 2.3311,
      "step": 579120
    },
    {
      "epoch": 931.09,
      "learning_rate": 0.006928871206270094,
      "loss": 2.3315,
      "step": 579140
    },
    {
      "epoch": 931.13,
      "learning_rate": 0.006925655775401926,
      "loss": 2.3332,
      "step": 579160
    },
    {
      "epoch": 931.16,
      "learning_rate": 0.006922440344533758,
      "loss": 2.3141,
      "step": 579180
    },
    {
      "epoch": 931.19,
      "learning_rate": 0.0069192249136656,
      "loss": 2.3199,
      "step": 579200
    },
    {
      "epoch": 931.22,
      "learning_rate": 0.006916009482797431,
      "loss": 2.303,
      "step": 579220
    },
    {
      "epoch": 931.25,
      "learning_rate": 0.006912794051929261,
      "loss": 2.3196,
      "step": 579240
    },
    {
      "epoch": 931.29,
      "learning_rate": 0.006909578621061091,
      "loss": 2.3398,
      "step": 579260
    },
    {
      "epoch": 931.32,
      "learning_rate": 0.006906363190192923,
      "loss": 2.3378,
      "step": 579280
    },
    {
      "epoch": 931.35,
      "learning_rate": 0.006903147759324765,
      "loss": 2.3219,
      "step": 579300
    },
    {
      "epoch": 931.38,
      "learning_rate": 0.006899932328456596,
      "loss": 2.3442,
      "step": 579320
    },
    {
      "epoch": 931.41,
      "learning_rate": 0.006896716897588426,
      "loss": 2.3191,
      "step": 579340
    },
    {
      "epoch": 931.45,
      "learning_rate": 0.006893501466720256,
      "loss": 2.331,
      "step": 579360
    },
    {
      "epoch": 931.48,
      "learning_rate": 0.006890286035852088,
      "loss": 2.3208,
      "step": 579380
    },
    {
      "epoch": 931.51,
      "learning_rate": 0.006887070604983918,
      "loss": 2.3255,
      "step": 579400
    },
    {
      "epoch": 931.54,
      "learning_rate": 0.006883855174115761,
      "loss": 2.3379,
      "step": 579420
    },
    {
      "epoch": 931.58,
      "learning_rate": 0.006880639743247591,
      "loss": 2.3227,
      "step": 579440
    },
    {
      "epoch": 931.61,
      "learning_rate": 0.006877424312379421,
      "loss": 2.3648,
      "step": 579460
    },
    {
      "epoch": 931.64,
      "learning_rate": 0.006874208881511253,
      "loss": 2.33,
      "step": 579480
    },
    {
      "epoch": 931.67,
      "learning_rate": 0.006870993450643084,
      "loss": 2.3128,
      "step": 579500
    },
    {
      "epoch": 931.7,
      "learning_rate": 0.006867778019774915,
      "loss": 2.3463,
      "step": 579520
    },
    {
      "epoch": 931.74,
      "learning_rate": 0.006864562588906758,
      "loss": 2.3016,
      "step": 579540
    },
    {
      "epoch": 931.77,
      "learning_rate": 0.006861347158038588,
      "loss": 2.3339,
      "step": 579560
    },
    {
      "epoch": 931.8,
      "learning_rate": 0.006858131727170418,
      "loss": 2.3337,
      "step": 579580
    },
    {
      "epoch": 931.83,
      "learning_rate": 0.006854916296302249,
      "loss": 2.3419,
      "step": 579600
    },
    {
      "epoch": 931.86,
      "learning_rate": 0.00685170086543408,
      "loss": 2.3085,
      "step": 579620
    },
    {
      "epoch": 931.9,
      "learning_rate": 0.006848485434565923,
      "loss": 2.3235,
      "step": 579640
    },
    {
      "epoch": 931.93,
      "learning_rate": 0.006845270003697753,
      "loss": 2.3387,
      "step": 579660
    },
    {
      "epoch": 931.96,
      "learning_rate": 0.006842054572829583,
      "loss": 2.3228,
      "step": 579680
    },
    {
      "epoch": 931.99,
      "learning_rate": 0.006838839141961414,
      "loss": 2.328,
      "step": 579700
    },
    {
      "epoch": 932.0,
      "eval_accuracy": {
        "accuracy": 0.4806032807276685
      },
      "eval_loss": 2.4350640773773193,
      "eval_runtime": 3.1354,
      "eval_samples_per_second": 4102.464,
      "eval_steps_per_second": 64.106,
      "step": 579704
    },
    {
      "epoch": 932.03,
      "learning_rate": 0.006835623711093245,
      "loss": 2.3236,
      "step": 579720
    },
    {
      "epoch": 932.06,
      "learning_rate": 0.0068324082802250765,
      "loss": 2.3336,
      "step": 579740
    },
    {
      "epoch": 932.09,
      "learning_rate": 0.006829192849356918,
      "loss": 2.3232,
      "step": 579760
    },
    {
      "epoch": 932.12,
      "learning_rate": 0.006825977418488749,
      "loss": 2.3283,
      "step": 579780
    },
    {
      "epoch": 932.15,
      "learning_rate": 0.006822761987620579,
      "loss": 2.3248,
      "step": 579800
    },
    {
      "epoch": 932.19,
      "learning_rate": 0.006819546556752411,
      "loss": 2.3183,
      "step": 579820
    },
    {
      "epoch": 932.22,
      "learning_rate": 0.0068163311258842415,
      "loss": 2.3335,
      "step": 579840
    },
    {
      "epoch": 932.25,
      "learning_rate": 0.006813115695016071,
      "loss": 2.3311,
      "step": 579860
    },
    {
      "epoch": 932.28,
      "learning_rate": 0.006809900264147914,
      "loss": 2.327,
      "step": 579880
    },
    {
      "epoch": 932.32,
      "learning_rate": 0.006806684833279744,
      "loss": 2.3321,
      "step": 579900
    },
    {
      "epoch": 932.35,
      "learning_rate": 0.006803469402411576,
      "loss": 2.3159,
      "step": 579920
    },
    {
      "epoch": 932.38,
      "learning_rate": 0.0068002539715434065,
      "loss": 2.3311,
      "step": 579940
    },
    {
      "epoch": 932.41,
      "learning_rate": 0.006797038540675236,
      "loss": 2.3213,
      "step": 579960
    },
    {
      "epoch": 932.44,
      "learning_rate": 0.006793823109807079,
      "loss": 2.3093,
      "step": 579980
    },
    {
      "epoch": 932.48,
      "learning_rate": 0.006790607678938909,
      "loss": 2.3369,
      "step": 580000
    },
    {
      "epoch": 932.51,
      "learning_rate": 0.006787392248070741,
      "loss": 2.3179,
      "step": 580020
    },
    {
      "epoch": 932.54,
      "learning_rate": 0.0067841768172025715,
      "loss": 2.3335,
      "step": 580040
    },
    {
      "epoch": 932.57,
      "learning_rate": 0.006780961386334403,
      "loss": 2.3359,
      "step": 580060
    },
    {
      "epoch": 932.6,
      "learning_rate": 0.006777745955466233,
      "loss": 2.3415,
      "step": 580080
    },
    {
      "epoch": 932.64,
      "learning_rate": 0.006774530524598076,
      "loss": 2.3418,
      "step": 580100
    },
    {
      "epoch": 932.67,
      "learning_rate": 0.006771315093729906,
      "loss": 2.3185,
      "step": 580120
    },
    {
      "epoch": 932.7,
      "learning_rate": 0.006768099662861737,
      "loss": 2.343,
      "step": 580140
    },
    {
      "epoch": 932.73,
      "learning_rate": 0.006764884231993568,
      "loss": 2.3287,
      "step": 580160
    },
    {
      "epoch": 932.77,
      "learning_rate": 0.006761668801125398,
      "loss": 2.3324,
      "step": 580180
    },
    {
      "epoch": 932.8,
      "learning_rate": 0.00675845337025723,
      "loss": 2.3203,
      "step": 580200
    },
    {
      "epoch": 932.83,
      "learning_rate": 0.006755237939389071,
      "loss": 2.3335,
      "step": 580220
    },
    {
      "epoch": 932.86,
      "learning_rate": 0.006752022508520902,
      "loss": 2.3165,
      "step": 580240
    },
    {
      "epoch": 932.89,
      "learning_rate": 0.006748807077652733,
      "loss": 2.3227,
      "step": 580260
    },
    {
      "epoch": 932.93,
      "learning_rate": 0.006745591646784563,
      "loss": 2.3347,
      "step": 580280
    },
    {
      "epoch": 932.96,
      "learning_rate": 0.006742376215916395,
      "loss": 2.3241,
      "step": 580300
    },
    {
      "epoch": 932.99,
      "learning_rate": 0.006739160785048236,
      "loss": 2.3202,
      "step": 580320
    },
    {
      "epoch": 933.0,
      "eval_accuracy": {
        "accuracy": 0.4786597216823447
      },
      "eval_loss": 2.4438018798828125,
      "eval_runtime": 3.2421,
      "eval_samples_per_second": 3967.465,
      "eval_steps_per_second": 61.996,
      "step": 580326
    },
    {
      "epoch": 933.02,
      "learning_rate": 0.006735945354180067,
      "loss": 2.3053,
      "step": 580340
    },
    {
      "epoch": 933.05,
      "learning_rate": 0.006732729923311898,
      "loss": 2.3378,
      "step": 580360
    },
    {
      "epoch": 933.09,
      "learning_rate": 0.00672951449244373,
      "loss": 2.3396,
      "step": 580380
    },
    {
      "epoch": 933.12,
      "learning_rate": 0.00672629906157556,
      "loss": 2.3217,
      "step": 580400
    },
    {
      "epoch": 933.15,
      "learning_rate": 0.006723083630707391,
      "loss": 2.329,
      "step": 580420
    },
    {
      "epoch": 933.18,
      "learning_rate": 0.006719868199839232,
      "loss": 2.3316,
      "step": 580440
    },
    {
      "epoch": 933.22,
      "learning_rate": 0.006716652768971064,
      "loss": 2.3329,
      "step": 580460
    },
    {
      "epoch": 933.25,
      "learning_rate": 0.006713437338102895,
      "loss": 2.3353,
      "step": 580480
    },
    {
      "epoch": 933.28,
      "learning_rate": 0.0067102219072347246,
      "loss": 2.342,
      "step": 580500
    },
    {
      "epoch": 933.31,
      "learning_rate": 0.006707006476366556,
      "loss": 2.3176,
      "step": 580520
    },
    {
      "epoch": 933.34,
      "learning_rate": 0.006703791045498397,
      "loss": 2.3306,
      "step": 580540
    },
    {
      "epoch": 933.38,
      "learning_rate": 0.006700575614630229,
      "loss": 2.3036,
      "step": 580560
    },
    {
      "epoch": 933.41,
      "learning_rate": 0.00669736018376206,
      "loss": 2.3186,
      "step": 580580
    },
    {
      "epoch": 933.44,
      "learning_rate": 0.0066941447528938896,
      "loss": 2.3208,
      "step": 580600
    },
    {
      "epoch": 933.47,
      "learning_rate": 0.006690929322025721,
      "loss": 2.3263,
      "step": 580620
    },
    {
      "epoch": 933.5,
      "learning_rate": 0.006687713891157552,
      "loss": 2.3272,
      "step": 580640
    },
    {
      "epoch": 933.54,
      "learning_rate": 0.006684498460289394,
      "loss": 2.3149,
      "step": 580660
    },
    {
      "epoch": 933.57,
      "learning_rate": 0.006681283029421225,
      "loss": 2.3304,
      "step": 580680
    },
    {
      "epoch": 933.6,
      "learning_rate": 0.006678067598553056,
      "loss": 2.3282,
      "step": 580700
    },
    {
      "epoch": 933.63,
      "learning_rate": 0.006674852167684886,
      "loss": 2.3272,
      "step": 580720
    },
    {
      "epoch": 933.67,
      "learning_rate": 0.006671636736816718,
      "loss": 2.326,
      "step": 580740
    },
    {
      "epoch": 933.7,
      "learning_rate": 0.0066684213059485485,
      "loss": 2.3198,
      "step": 580760
    },
    {
      "epoch": 933.73,
      "learning_rate": 0.0066652058750803905,
      "loss": 2.3242,
      "step": 580780
    },
    {
      "epoch": 933.76,
      "learning_rate": 0.006661990444212221,
      "loss": 2.3379,
      "step": 580800
    },
    {
      "epoch": 933.79,
      "learning_rate": 0.006658775013344051,
      "loss": 2.3272,
      "step": 580820
    },
    {
      "epoch": 933.83,
      "learning_rate": 0.006655559582475883,
      "loss": 2.3238,
      "step": 580840
    },
    {
      "epoch": 933.86,
      "learning_rate": 0.0066523441516077135,
      "loss": 2.3099,
      "step": 580860
    },
    {
      "epoch": 933.89,
      "learning_rate": 0.0066491287207395555,
      "loss": 2.3221,
      "step": 580880
    },
    {
      "epoch": 933.92,
      "learning_rate": 0.006645913289871386,
      "loss": 2.3187,
      "step": 580900
    },
    {
      "epoch": 933.95,
      "learning_rate": 0.006642697859003216,
      "loss": 2.3275,
      "step": 580920
    },
    {
      "epoch": 933.99,
      "learning_rate": 0.006639482428135048,
      "loss": 2.3286,
      "step": 580940
    },
    {
      "epoch": 934.0,
      "eval_accuracy": {
        "accuracy": 0.4794371453004742
      },
      "eval_loss": 2.43796968460083,
      "eval_runtime": 3.5468,
      "eval_samples_per_second": 3626.659,
      "eval_steps_per_second": 56.671,
      "step": 580948
    },
    {
      "epoch": 934.02,
      "learning_rate": 0.006636266997266879,
      "loss": 2.3419,
      "step": 580960
    },
    {
      "epoch": 934.05,
      "learning_rate": 0.00663305156639871,
      "loss": 2.3102,
      "step": 580980
    },
    {
      "epoch": 934.08,
      "learning_rate": 0.006629836135530552,
      "loss": 2.3351,
      "step": 581000
    },
    {
      "epoch": 934.12,
      "learning_rate": 0.006626620704662383,
      "loss": 2.3295,
      "step": 581020
    },
    {
      "epoch": 934.15,
      "learning_rate": 0.006623405273794213,
      "loss": 2.3145,
      "step": 581040
    },
    {
      "epoch": 934.18,
      "learning_rate": 0.006620189842926044,
      "loss": 2.3246,
      "step": 581060
    },
    {
      "epoch": 934.21,
      "learning_rate": 0.006616974412057875,
      "loss": 2.3292,
      "step": 581080
    },
    {
      "epoch": 934.24,
      "learning_rate": 0.006613758981189707,
      "loss": 2.3274,
      "step": 581100
    },
    {
      "epoch": 934.28,
      "learning_rate": 0.006610543550321548,
      "loss": 2.3232,
      "step": 581120
    },
    {
      "epoch": 934.31,
      "learning_rate": 0.006607328119453378,
      "loss": 2.3161,
      "step": 581140
    },
    {
      "epoch": 934.34,
      "learning_rate": 0.006604112688585209,
      "loss": 2.3203,
      "step": 581160
    },
    {
      "epoch": 934.37,
      "learning_rate": 0.00660089725771704,
      "loss": 2.3276,
      "step": 581180
    },
    {
      "epoch": 934.41,
      "learning_rate": 0.006597681826848872,
      "loss": 2.314,
      "step": 581200
    },
    {
      "epoch": 934.44,
      "learning_rate": 0.006594466395980713,
      "loss": 2.3328,
      "step": 581220
    },
    {
      "epoch": 934.47,
      "learning_rate": 0.006591250965112543,
      "loss": 2.3177,
      "step": 581240
    },
    {
      "epoch": 934.5,
      "learning_rate": 0.006588035534244374,
      "loss": 2.3285,
      "step": 581260
    },
    {
      "epoch": 934.53,
      "learning_rate": 0.006584820103376206,
      "loss": 2.3159,
      "step": 581280
    },
    {
      "epoch": 934.57,
      "learning_rate": 0.006581604672508037,
      "loss": 2.3372,
      "step": 581300
    },
    {
      "epoch": 934.6,
      "learning_rate": 0.006578389241639868,
      "loss": 2.3176,
      "step": 581320
    },
    {
      "epoch": 934.63,
      "learning_rate": 0.0065751738107717094,
      "loss": 2.3135,
      "step": 581340
    },
    {
      "epoch": 934.66,
      "learning_rate": 0.006571958379903539,
      "loss": 2.3084,
      "step": 581360
    },
    {
      "epoch": 934.69,
      "learning_rate": 0.006568742949035371,
      "loss": 2.3285,
      "step": 581380
    },
    {
      "epoch": 934.73,
      "learning_rate": 0.006565527518167202,
      "loss": 2.3456,
      "step": 581400
    },
    {
      "epoch": 934.76,
      "learning_rate": 0.006562312087299033,
      "loss": 2.3229,
      "step": 581420
    },
    {
      "epoch": 934.79,
      "learning_rate": 0.006559096656430863,
      "loss": 2.3294,
      "step": 581440
    },
    {
      "epoch": 934.82,
      "learning_rate": 0.006555881225562704,
      "loss": 2.3107,
      "step": 581460
    },
    {
      "epoch": 934.86,
      "learning_rate": 0.006552665794694536,
      "loss": 2.3271,
      "step": 581480
    },
    {
      "epoch": 934.89,
      "learning_rate": 0.006549450363826367,
      "loss": 2.3203,
      "step": 581500
    },
    {
      "epoch": 934.92,
      "learning_rate": 0.006546234932958198,
      "loss": 2.3427,
      "step": 581520
    },
    {
      "epoch": 934.95,
      "learning_rate": 0.006543019502090028,
      "loss": 2.3205,
      "step": 581540
    },
    {
      "epoch": 934.98,
      "learning_rate": 0.006539804071221869,
      "loss": 2.3457,
      "step": 581560
    },
    {
      "epoch": 935.0,
      "eval_accuracy": {
        "accuracy": 0.48114747726035917
      },
      "eval_loss": 2.442232370376587,
      "eval_runtime": 3.1586,
      "eval_samples_per_second": 4072.38,
      "eval_steps_per_second": 63.636,
      "step": 581570
    },
    {
      "epoch": 935.02,
      "learning_rate": 0.006536588640353701,
      "loss": 2.3398,
      "step": 581580
    },
    {
      "epoch": 935.05,
      "learning_rate": 0.0065333732094855325,
      "loss": 2.3075,
      "step": 581600
    },
    {
      "epoch": 935.08,
      "learning_rate": 0.006530157778617363,
      "loss": 2.3171,
      "step": 581620
    },
    {
      "epoch": 935.11,
      "learning_rate": 0.006526942347749195,
      "loss": 2.3215,
      "step": 581640
    },
    {
      "epoch": 935.14,
      "learning_rate": 0.006523726916881025,
      "loss": 2.3339,
      "step": 581660
    },
    {
      "epoch": 935.18,
      "learning_rate": 0.006520511486012866,
      "loss": 2.3396,
      "step": 581680
    },
    {
      "epoch": 935.21,
      "learning_rate": 0.0065172960551446975,
      "loss": 2.324,
      "step": 581700
    },
    {
      "epoch": 935.24,
      "learning_rate": 0.006514080624276528,
      "loss": 2.3167,
      "step": 581720
    },
    {
      "epoch": 935.27,
      "learning_rate": 0.00651086519340836,
      "loss": 2.3229,
      "step": 581740
    },
    {
      "epoch": 935.31,
      "learning_rate": 0.00650764976254019,
      "loss": 2.3099,
      "step": 581760
    },
    {
      "epoch": 935.34,
      "learning_rate": 0.00650443433167202,
      "loss": 2.3282,
      "step": 581780
    },
    {
      "epoch": 935.37,
      "learning_rate": 0.0065012189008038625,
      "loss": 2.321,
      "step": 581800
    },
    {
      "epoch": 935.4,
      "learning_rate": 0.006498003469935693,
      "loss": 2.3229,
      "step": 581820
    },
    {
      "epoch": 935.43,
      "learning_rate": 0.006494788039067525,
      "loss": 2.344,
      "step": 581840
    },
    {
      "epoch": 935.47,
      "learning_rate": 0.006491572608199355,
      "loss": 2.3156,
      "step": 581860
    },
    {
      "epoch": 935.5,
      "learning_rate": 0.006488357177331186,
      "loss": 2.3303,
      "step": 581880
    },
    {
      "epoch": 935.53,
      "learning_rate": 0.0064851417464630275,
      "loss": 2.3348,
      "step": 581900
    },
    {
      "epoch": 935.56,
      "learning_rate": 0.006481926315594859,
      "loss": 2.3193,
      "step": 581920
    },
    {
      "epoch": 935.59,
      "learning_rate": 0.00647871088472669,
      "loss": 2.3307,
      "step": 581940
    },
    {
      "epoch": 935.63,
      "learning_rate": 0.0064754954538585215,
      "loss": 2.3166,
      "step": 581960
    },
    {
      "epoch": 935.66,
      "learning_rate": 0.006472280022990351,
      "loss": 2.3341,
      "step": 581980
    },
    {
      "epoch": 935.69,
      "learning_rate": 0.006469064592122181,
      "loss": 2.3315,
      "step": 582000
    },
    {
      "epoch": 935.72,
      "learning_rate": 0.006465849161254024,
      "loss": 2.3232,
      "step": 582020
    },
    {
      "epoch": 935.76,
      "learning_rate": 0.006462633730385855,
      "loss": 2.3321,
      "step": 582040
    },
    {
      "epoch": 935.79,
      "learning_rate": 0.0064594182995176865,
      "loss": 2.3221,
      "step": 582060
    },
    {
      "epoch": 935.82,
      "learning_rate": 0.006456202868649516,
      "loss": 2.3177,
      "step": 582080
    },
    {
      "epoch": 935.85,
      "learning_rate": 0.006452987437781346,
      "loss": 2.3232,
      "step": 582100
    },
    {
      "epoch": 935.88,
      "learning_rate": 0.006449772006913189,
      "loss": 2.336,
      "step": 582120
    },
    {
      "epoch": 935.92,
      "learning_rate": 0.00644655657604502,
      "loss": 2.309,
      "step": 582140
    },
    {
      "epoch": 935.95,
      "learning_rate": 0.0064433411451768514,
      "loss": 2.3336,
      "step": 582160
    },
    {
      "epoch": 935.98,
      "learning_rate": 0.006440125714308681,
      "loss": 2.3035,
      "step": 582180
    },
    {
      "epoch": 936.0,
      "eval_accuracy": {
        "accuracy": 0.48184715851667576
      },
      "eval_loss": 2.432036876678467,
      "eval_runtime": 3.2394,
      "eval_samples_per_second": 3970.759,
      "eval_steps_per_second": 62.048,
      "step": 582192
    },
    {
      "epoch": 936.01,
      "learning_rate": 0.006436910283440513,
      "loss": 2.331,
      "step": 582200
    },
    {
      "epoch": 936.05,
      "learning_rate": 0.006433694852572343,
      "loss": 2.3175,
      "step": 582220
    },
    {
      "epoch": 936.08,
      "learning_rate": 0.006430479421704186,
      "loss": 2.3237,
      "step": 582240
    },
    {
      "epoch": 936.11,
      "learning_rate": 0.006427263990836016,
      "loss": 2.3134,
      "step": 582260
    },
    {
      "epoch": 936.14,
      "learning_rate": 0.006424048559967848,
      "loss": 2.3399,
      "step": 582280
    },
    {
      "epoch": 936.17,
      "learning_rate": 0.006420833129099678,
      "loss": 2.3354,
      "step": 582300
    },
    {
      "epoch": 936.21,
      "learning_rate": 0.006417617698231508,
      "loss": 2.3177,
      "step": 582320
    },
    {
      "epoch": 936.24,
      "learning_rate": 0.006414402267363339,
      "loss": 2.3338,
      "step": 582340
    },
    {
      "epoch": 936.27,
      "learning_rate": 0.006411186836495181,
      "loss": 2.3147,
      "step": 582360
    },
    {
      "epoch": 936.3,
      "learning_rate": 0.006407971405627013,
      "loss": 2.3316,
      "step": 582380
    },
    {
      "epoch": 936.33,
      "learning_rate": 0.006404755974758843,
      "loss": 2.3198,
      "step": 582400
    },
    {
      "epoch": 936.37,
      "learning_rate": 0.006401540543890673,
      "loss": 2.3114,
      "step": 582420
    },
    {
      "epoch": 936.4,
      "learning_rate": 0.006398325113022504,
      "loss": 2.3153,
      "step": 582440
    },
    {
      "epoch": 936.43,
      "learning_rate": 0.006395109682154346,
      "loss": 2.3137,
      "step": 582460
    },
    {
      "epoch": 936.46,
      "learning_rate": 0.006391894251286178,
      "loss": 2.3212,
      "step": 582480
    },
    {
      "epoch": 936.5,
      "learning_rate": 0.00638867882041801,
      "loss": 2.3288,
      "step": 582500
    },
    {
      "epoch": 936.53,
      "learning_rate": 0.0063854633895498395,
      "loss": 2.3347,
      "step": 582520
    },
    {
      "epoch": 936.56,
      "learning_rate": 0.006382247958681669,
      "loss": 2.3361,
      "step": 582540
    },
    {
      "epoch": 936.59,
      "learning_rate": 0.006379032527813501,
      "loss": 2.3221,
      "step": 582560
    },
    {
      "epoch": 936.62,
      "learning_rate": 0.006375817096945343,
      "loss": 2.3363,
      "step": 582580
    },
    {
      "epoch": 936.66,
      "learning_rate": 0.006372601666077175,
      "loss": 2.3328,
      "step": 582600
    },
    {
      "epoch": 936.69,
      "learning_rate": 0.0063693862352090045,
      "loss": 2.3288,
      "step": 582620
    },
    {
      "epoch": 936.72,
      "learning_rate": 0.006366170804340834,
      "loss": 2.3191,
      "step": 582640
    },
    {
      "epoch": 936.75,
      "learning_rate": 0.006362955373472666,
      "loss": 2.3096,
      "step": 582660
    },
    {
      "epoch": 936.78,
      "learning_rate": 0.006359739942604497,
      "loss": 2.315,
      "step": 582680
    },
    {
      "epoch": 936.82,
      "learning_rate": 0.00635652451173634,
      "loss": 2.3244,
      "step": 582700
    },
    {
      "epoch": 936.85,
      "learning_rate": 0.0063533090808681695,
      "loss": 2.3256,
      "step": 582720
    },
    {
      "epoch": 936.88,
      "learning_rate": 0.006350093649999999,
      "loss": 2.3229,
      "step": 582740
    },
    {
      "epoch": 936.91,
      "learning_rate": 0.006346878219131831,
      "loss": 2.3193,
      "step": 582760
    },
    {
      "epoch": 936.95,
      "learning_rate": 0.006343662788263663,
      "loss": 2.3332,
      "step": 582780
    },
    {
      "epoch": 936.98,
      "learning_rate": 0.006340447357395505,
      "loss": 2.3246,
      "step": 582800
    },
    {
      "epoch": 937.0,
      "eval_accuracy": {
        "accuracy": 0.47889294876778354
      },
      "eval_loss": 2.444904327392578,
      "eval_runtime": 3.226,
      "eval_samples_per_second": 3987.241,
      "eval_steps_per_second": 62.305,
      "step": 582814
    },
    {
      "epoch": 937.01,
      "learning_rate": 0.006337231926527336,
      "loss": 2.317,
      "step": 582820
    },
    {
      "epoch": 937.04,
      "learning_rate": 0.006334016495659166,
      "loss": 2.3415,
      "step": 582840
    },
    {
      "epoch": 937.07,
      "learning_rate": 0.006330801064790996,
      "loss": 2.3058,
      "step": 582860
    },
    {
      "epoch": 937.11,
      "learning_rate": 0.006327585633922828,
      "loss": 2.3359,
      "step": 582880
    },
    {
      "epoch": 937.14,
      "learning_rate": 0.006324370203054658,
      "loss": 2.3179,
      "step": 582900
    },
    {
      "epoch": 937.17,
      "learning_rate": 0.006321154772186501,
      "loss": 2.3331,
      "step": 582920
    },
    {
      "epoch": 937.2,
      "learning_rate": 0.006317939341318331,
      "loss": 2.3285,
      "step": 582940
    },
    {
      "epoch": 937.23,
      "learning_rate": 0.006314723910450161,
      "loss": 2.3248,
      "step": 582960
    },
    {
      "epoch": 937.27,
      "learning_rate": 0.006311508479581993,
      "loss": 2.3293,
      "step": 582980
    },
    {
      "epoch": 937.3,
      "learning_rate": 0.006308293048713823,
      "loss": 2.3137,
      "step": 583000
    },
    {
      "epoch": 937.33,
      "learning_rate": 0.006305077617845653,
      "loss": 2.3362,
      "step": 583020
    },
    {
      "epoch": 937.36,
      "learning_rate": 0.006301862186977496,
      "loss": 2.307,
      "step": 583040
    },
    {
      "epoch": 937.4,
      "learning_rate": 0.0062988075276527375,
      "loss": 2.3145,
      "step": 583060
    },
    {
      "epoch": 937.43,
      "learning_rate": 0.006295592096784569,
      "loss": 2.3101,
      "step": 583080
    },
    {
      "epoch": 937.46,
      "learning_rate": 0.0062923766659164,
      "loss": 2.3182,
      "step": 583100
    },
    {
      "epoch": 937.49,
      "learning_rate": 0.00628916123504823,
      "loss": 2.3296,
      "step": 583120
    },
    {
      "epoch": 937.52,
      "learning_rate": 0.006285945804180061,
      "loss": 2.3383,
      "step": 583140
    },
    {
      "epoch": 937.56,
      "learning_rate": 0.006282730373311893,
      "loss": 2.3104,
      "step": 583160
    },
    {
      "epoch": 937.59,
      "learning_rate": 0.006279514942443734,
      "loss": 2.2886,
      "step": 583180
    },
    {
      "epoch": 937.62,
      "learning_rate": 0.006276299511575566,
      "loss": 2.3362,
      "step": 583200
    },
    {
      "epoch": 937.65,
      "learning_rate": 0.0062730840807073964,
      "loss": 2.3136,
      "step": 583220
    },
    {
      "epoch": 937.68,
      "learning_rate": 0.006269868649839226,
      "loss": 2.3193,
      "step": 583240
    },
    {
      "epoch": 937.72,
      "learning_rate": 0.006266653218971058,
      "loss": 2.3407,
      "step": 583260
    },
    {
      "epoch": 937.75,
      "learning_rate": 0.006263437788102899,
      "loss": 2.3255,
      "step": 583280
    },
    {
      "epoch": 937.78,
      "learning_rate": 0.006260222357234731,
      "loss": 2.3255,
      "step": 583300
    },
    {
      "epoch": 937.81,
      "learning_rate": 0.0062570069263665614,
      "loss": 2.3366,
      "step": 583320
    },
    {
      "epoch": 937.85,
      "learning_rate": 0.006253791495498391,
      "loss": 2.3139,
      "step": 583340
    },
    {
      "epoch": 937.88,
      "learning_rate": 0.006250576064630223,
      "loss": 2.3318,
      "step": 583360
    },
    {
      "epoch": 937.91,
      "learning_rate": 0.006247360633762054,
      "loss": 2.3357,
      "step": 583380
    },
    {
      "epoch": 937.94,
      "learning_rate": 0.006244145202893896,
      "loss": 2.3124,
      "step": 583400
    },
    {
      "epoch": 937.97,
      "learning_rate": 0.006240929772025726,
      "loss": 2.3192,
      "step": 583420
    },
    {
      "epoch": 938.0,
      "eval_accuracy": {
        "accuracy": 0.47578325429526547
      },
      "eval_loss": 2.445007085800171,
      "eval_runtime": 3.0881,
      "eval_samples_per_second": 4165.321,
      "eval_steps_per_second": 65.088,
      "step": 583436
    },
    {
      "epoch": 938.01,
      "learning_rate": 0.006237714341157557,
      "loss": 2.319,
      "step": 583440
    },
    {
      "epoch": 938.04,
      "learning_rate": 0.006234498910289388,
      "loss": 2.3212,
      "step": 583460
    },
    {
      "epoch": 938.07,
      "learning_rate": 0.0062312834794212195,
      "loss": 2.3011,
      "step": 583480
    },
    {
      "epoch": 938.1,
      "learning_rate": 0.00622806804855305,
      "loss": 2.3181,
      "step": 583500
    },
    {
      "epoch": 938.14,
      "learning_rate": 0.006224852617684892,
      "loss": 2.3157,
      "step": 583520
    },
    {
      "epoch": 938.17,
      "learning_rate": 0.006221637186816723,
      "loss": 2.3208,
      "step": 583540
    },
    {
      "epoch": 938.2,
      "learning_rate": 0.006218421755948554,
      "loss": 2.3283,
      "step": 583560
    },
    {
      "epoch": 938.23,
      "learning_rate": 0.0062152063250803845,
      "loss": 2.3106,
      "step": 583580
    },
    {
      "epoch": 938.26,
      "learning_rate": 0.006211990894212215,
      "loss": 2.3296,
      "step": 583600
    },
    {
      "epoch": 938.3,
      "learning_rate": 0.006208775463344057,
      "loss": 2.3187,
      "step": 583620
    },
    {
      "epoch": 938.33,
      "learning_rate": 0.006205560032475888,
      "loss": 2.3282,
      "step": 583640
    },
    {
      "epoch": 938.36,
      "learning_rate": 0.006202344601607719,
      "loss": 2.3276,
      "step": 583660
    },
    {
      "epoch": 938.39,
      "learning_rate": 0.0061991291707395495,
      "loss": 2.3215,
      "step": 583680
    },
    {
      "epoch": 938.42,
      "learning_rate": 0.00619591373987138,
      "loss": 2.3269,
      "step": 583700
    },
    {
      "epoch": 938.46,
      "learning_rate": 0.0061928590805466225,
      "loss": 2.3116,
      "step": 583720
    },
    {
      "epoch": 938.49,
      "learning_rate": 0.006189643649678453,
      "loss": 2.3189,
      "step": 583740
    },
    {
      "epoch": 938.52,
      "learning_rate": 0.006186428218810295,
      "loss": 2.3215,
      "step": 583760
    },
    {
      "epoch": 938.55,
      "learning_rate": 0.006183212787942126,
      "loss": 2.3137,
      "step": 583780
    },
    {
      "epoch": 938.59,
      "learning_rate": 0.006179997357073957,
      "loss": 2.3215,
      "step": 583800
    },
    {
      "epoch": 938.62,
      "learning_rate": 0.0061767819262057875,
      "loss": 2.3239,
      "step": 583820
    },
    {
      "epoch": 938.65,
      "learning_rate": 0.006173566495337618,
      "loss": 2.3111,
      "step": 583840
    },
    {
      "epoch": 938.68,
      "learning_rate": 0.00617035106446945,
      "loss": 2.3394,
      "step": 583860
    },
    {
      "epoch": 938.71,
      "learning_rate": 0.006167135633601291,
      "loss": 2.3182,
      "step": 583880
    },
    {
      "epoch": 938.75,
      "learning_rate": 0.006163920202733123,
      "loss": 2.3292,
      "step": 583900
    },
    {
      "epoch": 938.78,
      "learning_rate": 0.006160704771864953,
      "loss": 2.3166,
      "step": 583920
    },
    {
      "epoch": 938.81,
      "learning_rate": 0.006157489340996784,
      "loss": 2.3303,
      "step": 583940
    },
    {
      "epoch": 938.84,
      "learning_rate": 0.006154273910128615,
      "loss": 2.3208,
      "step": 583960
    },
    {
      "epoch": 938.87,
      "learning_rate": 0.006151058479260446,
      "loss": 2.3279,
      "step": 583980
    },
    {
      "epoch": 938.91,
      "learning_rate": 0.006147843048392288,
      "loss": 2.3264,
      "step": 584000
    },
    {
      "epoch": 938.94,
      "learning_rate": 0.006144627617524118,
      "loss": 2.3292,
      "step": 584020
    },
    {
      "epoch": 938.97,
      "learning_rate": 0.006141412186655949,
      "loss": 2.3247,
      "step": 584040
    },
    {
      "epoch": 939.0,
      "eval_accuracy": {
        "accuracy": 0.47741584389333747
      },
      "eval_loss": 2.439903736114502,
      "eval_runtime": 3.8019,
      "eval_samples_per_second": 3383.319,
      "eval_steps_per_second": 52.868,
      "step": 584058
    },
    {
      "epoch": 939.0,
      "learning_rate": 0.00613819675578778,
      "loss": 2.3201,
      "step": 584060
    },
    {
      "epoch": 939.04,
      "learning_rate": 0.006134981324919611,
      "loss": 2.335,
      "step": 584080
    },
    {
      "epoch": 939.07,
      "learning_rate": 0.006131765894051453,
      "loss": 2.328,
      "step": 584100
    },
    {
      "epoch": 939.1,
      "learning_rate": 0.006128550463183283,
      "loss": 2.3063,
      "step": 584120
    },
    {
      "epoch": 939.13,
      "learning_rate": 0.006125335032315114,
      "loss": 2.3362,
      "step": 584140
    },
    {
      "epoch": 939.16,
      "learning_rate": 0.006122119601446945,
      "loss": 2.3188,
      "step": 584160
    },
    {
      "epoch": 939.2,
      "learning_rate": 0.0061189041705787765,
      "loss": 2.3183,
      "step": 584180
    },
    {
      "epoch": 939.23,
      "learning_rate": 0.006115688739710607,
      "loss": 2.3154,
      "step": 584200
    },
    {
      "epoch": 939.26,
      "learning_rate": 0.006112473308842449,
      "loss": 2.3254,
      "step": 584220
    },
    {
      "epoch": 939.29,
      "learning_rate": 0.00610925787797428,
      "loss": 2.34,
      "step": 584240
    },
    {
      "epoch": 939.32,
      "learning_rate": 0.006106042447106111,
      "loss": 2.3109,
      "step": 584260
    },
    {
      "epoch": 939.36,
      "learning_rate": 0.0061028270162379415,
      "loss": 2.3226,
      "step": 584280
    },
    {
      "epoch": 939.39,
      "learning_rate": 0.006099611585369772,
      "loss": 2.3219,
      "step": 584300
    },
    {
      "epoch": 939.42,
      "learning_rate": 0.006096396154501603,
      "loss": 2.3284,
      "step": 584320
    },
    {
      "epoch": 939.45,
      "learning_rate": 0.006093180723633445,
      "loss": 2.3329,
      "step": 584340
    },
    {
      "epoch": 939.49,
      "learning_rate": 0.006089965292765276,
      "loss": 2.3199,
      "step": 584360
    },
    {
      "epoch": 939.52,
      "learning_rate": 0.0060867498618971064,
      "loss": 2.3049,
      "step": 584380
    },
    {
      "epoch": 939.55,
      "learning_rate": 0.006083534431028937,
      "loss": 2.3116,
      "step": 584400
    },
    {
      "epoch": 939.58,
      "learning_rate": 0.006080319000160768,
      "loss": 2.304,
      "step": 584420
    },
    {
      "epoch": 939.61,
      "learning_rate": 0.00607710356929261,
      "loss": 2.3116,
      "step": 584440
    },
    {
      "epoch": 939.65,
      "learning_rate": 0.006073888138424441,
      "loss": 2.3026,
      "step": 584460
    },
    {
      "epoch": 939.68,
      "learning_rate": 0.006070672707556271,
      "loss": 2.3176,
      "step": 584480
    },
    {
      "epoch": 939.71,
      "learning_rate": 0.006067457276688103,
      "loss": 2.306,
      "step": 584500
    },
    {
      "epoch": 939.74,
      "learning_rate": 0.006064241845819934,
      "loss": 2.3232,
      "step": 584520
    },
    {
      "epoch": 939.77,
      "learning_rate": 0.0060610264149517645,
      "loss": 2.3129,
      "step": 584540
    },
    {
      "epoch": 939.81,
      "learning_rate": 0.0060578109840836065,
      "loss": 2.3049,
      "step": 584560
    },
    {
      "epoch": 939.84,
      "learning_rate": 0.006054595553215437,
      "loss": 2.3389,
      "step": 584580
    },
    {
      "epoch": 939.87,
      "learning_rate": 0.006051380122347268,
      "loss": 2.3278,
      "step": 584600
    },
    {
      "epoch": 939.9,
      "learning_rate": 0.006048164691479099,
      "loss": 2.3152,
      "step": 584620
    },
    {
      "epoch": 939.94,
      "learning_rate": 0.0060449492606109295,
      "loss": 2.3293,
      "step": 584640
    },
    {
      "epoch": 939.97,
      "learning_rate": 0.00604173382974276,
      "loss": 2.3412,
      "step": 584660
    },
    {
      "epoch": 940.0,
      "learning_rate": 0.006038518398874602,
      "loss": 2.3357,
      "step": 584680
    },
    {
      "epoch": 940.0,
      "eval_accuracy": {
        "accuracy": 0.48122521962217213
      },
      "eval_loss": 2.434617757797241,
      "eval_runtime": 3.0734,
      "eval_samples_per_second": 4185.23,
      "eval_steps_per_second": 65.399,
      "step": 584680
    },
    {
      "epoch": 940.03,
      "learning_rate": 0.006035302968006433,
      "loss": 2.3093,
      "step": 584700
    },
    {
      "epoch": 940.06,
      "learning_rate": 0.006032087537138264,
      "loss": 2.3202,
      "step": 584720
    },
    {
      "epoch": 940.1,
      "learning_rate": 0.0060288721062700945,
      "loss": 2.3276,
      "step": 584740
    },
    {
      "epoch": 940.13,
      "learning_rate": 0.006025656675401925,
      "loss": 2.3161,
      "step": 584760
    },
    {
      "epoch": 940.16,
      "learning_rate": 0.006022441244533767,
      "loss": 2.3235,
      "step": 584780
    },
    {
      "epoch": 940.19,
      "learning_rate": 0.006019225813665598,
      "loss": 2.3206,
      "step": 584800
    },
    {
      "epoch": 940.23,
      "learning_rate": 0.00601601038279743,
      "loss": 2.3133,
      "step": 584820
    },
    {
      "epoch": 940.26,
      "learning_rate": 0.00601279495192926,
      "loss": 2.3235,
      "step": 584840
    },
    {
      "epoch": 940.29,
      "learning_rate": 0.006009579521061091,
      "loss": 2.3296,
      "step": 584860
    },
    {
      "epoch": 940.32,
      "learning_rate": 0.006006364090192922,
      "loss": 2.3128,
      "step": 584880
    },
    {
      "epoch": 940.35,
      "learning_rate": 0.006003148659324764,
      "loss": 2.3063,
      "step": 584900
    },
    {
      "epoch": 940.39,
      "learning_rate": 0.005999933228456595,
      "loss": 2.3192,
      "step": 584920
    },
    {
      "epoch": 940.42,
      "learning_rate": 0.005996717797588425,
      "loss": 2.332,
      "step": 584940
    },
    {
      "epoch": 940.45,
      "learning_rate": 0.005993502366720256,
      "loss": 2.3196,
      "step": 584960
    },
    {
      "epoch": 940.48,
      "learning_rate": 0.005990286935852087,
      "loss": 2.3259,
      "step": 584980
    },
    {
      "epoch": 940.51,
      "learning_rate": 0.005987071504983918,
      "loss": 2.3199,
      "step": 585000
    },
    {
      "epoch": 940.55,
      "learning_rate": 0.00598385607411576,
      "loss": 2.3063,
      "step": 585020
    },
    {
      "epoch": 940.58,
      "learning_rate": 0.00598064064324759,
      "loss": 2.3187,
      "step": 585040
    },
    {
      "epoch": 940.61,
      "learning_rate": 0.005977425212379421,
      "loss": 2.3065,
      "step": 585060
    },
    {
      "epoch": 940.64,
      "learning_rate": 0.005974209781511253,
      "loss": 2.3232,
      "step": 585080
    },
    {
      "epoch": 940.68,
      "learning_rate": 0.0059709943506430834,
      "loss": 2.325,
      "step": 585100
    },
    {
      "epoch": 940.71,
      "learning_rate": 0.0059677789197749255,
      "loss": 2.3229,
      "step": 585120
    },
    {
      "epoch": 940.74,
      "learning_rate": 0.005964563488906756,
      "loss": 2.3085,
      "step": 585140
    },
    {
      "epoch": 940.77,
      "learning_rate": 0.005961348058038587,
      "loss": 2.3211,
      "step": 585160
    },
    {
      "epoch": 940.8,
      "learning_rate": 0.005958132627170418,
      "loss": 2.3176,
      "step": 585180
    },
    {
      "epoch": 940.84,
      "learning_rate": 0.0059549171963022484,
      "loss": 2.327,
      "step": 585200
    },
    {
      "epoch": 940.87,
      "learning_rate": 0.005951701765434079,
      "loss": 2.3199,
      "step": 585220
    },
    {
      "epoch": 940.9,
      "learning_rate": 0.005948486334565921,
      "loss": 2.3263,
      "step": 585240
    },
    {
      "epoch": 940.93,
      "learning_rate": 0.005945270903697752,
      "loss": 2.3224,
      "step": 585260
    },
    {
      "epoch": 940.96,
      "learning_rate": 0.005942055472829583,
      "loss": 2.3297,
      "step": 585280
    },
    {
      "epoch": 941.0,
      "learning_rate": 0.005938840041961413,
      "loss": 2.3219,
      "step": 585300
    },
    {
      "epoch": 941.0,
      "eval_accuracy": {
        "accuracy": 0.47788229806421517
      },
      "eval_loss": 2.4393155574798584,
      "eval_runtime": 3.0358,
      "eval_samples_per_second": 4237.132,
      "eval_steps_per_second": 66.21,
      "step": 585302
    },
    {
      "epoch": 941.03,
      "learning_rate": 0.005935624611093244,
      "loss": 2.3012,
      "step": 585320
    },
    {
      "epoch": 941.06,
      "learning_rate": 0.005932409180225075,
      "loss": 2.3268,
      "step": 585340
    },
    {
      "epoch": 941.09,
      "learning_rate": 0.005929193749356917,
      "loss": 2.3114,
      "step": 585360
    },
    {
      "epoch": 941.13,
      "learning_rate": 0.005925978318488748,
      "loss": 2.3173,
      "step": 585380
    },
    {
      "epoch": 941.16,
      "learning_rate": 0.005922762887620579,
      "loss": 2.332,
      "step": 585400
    },
    {
      "epoch": 941.19,
      "learning_rate": 0.00591954745675241,
      "loss": 2.3094,
      "step": 585420
    },
    {
      "epoch": 941.22,
      "learning_rate": 0.005916332025884241,
      "loss": 2.3175,
      "step": 585440
    },
    {
      "epoch": 941.25,
      "learning_rate": 0.005913116595016083,
      "loss": 2.3184,
      "step": 585460
    },
    {
      "epoch": 941.29,
      "learning_rate": 0.0059099011641479135,
      "loss": 2.329,
      "step": 585480
    },
    {
      "epoch": 941.32,
      "learning_rate": 0.005906685733279744,
      "loss": 2.3312,
      "step": 585500
    },
    {
      "epoch": 941.35,
      "learning_rate": 0.005903470302411575,
      "loss": 2.3136,
      "step": 585520
    },
    {
      "epoch": 941.38,
      "learning_rate": 0.005900254871543406,
      "loss": 2.3271,
      "step": 585540
    },
    {
      "epoch": 941.41,
      "learning_rate": 0.0058970394406752365,
      "loss": 2.3255,
      "step": 585560
    },
    {
      "epoch": 941.45,
      "learning_rate": 0.0058938240098070785,
      "loss": 2.3087,
      "step": 585580
    },
    {
      "epoch": 941.48,
      "learning_rate": 0.005890608578938909,
      "loss": 2.3251,
      "step": 585600
    },
    {
      "epoch": 941.51,
      "learning_rate": 0.00588739314807074,
      "loss": 2.3372,
      "step": 585620
    },
    {
      "epoch": 941.54,
      "learning_rate": 0.005884177717202571,
      "loss": 2.3184,
      "step": 585640
    },
    {
      "epoch": 941.58,
      "learning_rate": 0.0058809622863344015,
      "loss": 2.3144,
      "step": 585660
    },
    {
      "epoch": 941.61,
      "learning_rate": 0.0058777468554662435,
      "loss": 2.3263,
      "step": 585680
    },
    {
      "epoch": 941.64,
      "learning_rate": 0.005874531424598074,
      "loss": 2.3023,
      "step": 585700
    },
    {
      "epoch": 941.67,
      "learning_rate": 0.005871315993729906,
      "loss": 2.3408,
      "step": 585720
    },
    {
      "epoch": 941.7,
      "learning_rate": 0.005868100562861737,
      "loss": 2.337,
      "step": 585740
    },
    {
      "epoch": 941.74,
      "learning_rate": 0.005864885131993567,
      "loss": 2.3204,
      "step": 585760
    },
    {
      "epoch": 941.77,
      "learning_rate": 0.005861669701125398,
      "loss": 2.3344,
      "step": 585780
    },
    {
      "epoch": 941.8,
      "learning_rate": 0.00585845427025724,
      "loss": 2.304,
      "step": 585800
    },
    {
      "epoch": 941.83,
      "learning_rate": 0.005855238839389071,
      "loss": 2.3084,
      "step": 585820
    },
    {
      "epoch": 941.86,
      "learning_rate": 0.005852023408520902,
      "loss": 2.3193,
      "step": 585840
    },
    {
      "epoch": 941.9,
      "learning_rate": 0.005848807977652732,
      "loss": 2.2819,
      "step": 585860
    },
    {
      "epoch": 941.93,
      "learning_rate": 0.005845592546784563,
      "loss": 2.3282,
      "step": 585880
    },
    {
      "epoch": 941.96,
      "learning_rate": 0.005842377115916394,
      "loss": 2.3074,
      "step": 585900
    },
    {
      "epoch": 941.99,
      "learning_rate": 0.005839161685048236,
      "loss": 2.3152,
      "step": 585920
    },
    {
      "epoch": 942.0,
      "eval_accuracy": {
        "accuracy": 0.48169167379304983
      },
      "eval_loss": 2.4304800033569336,
      "eval_runtime": 3.3467,
      "eval_samples_per_second": 3843.531,
      "eval_steps_per_second": 60.06,
      "step": 585924
    },
    {
      "epoch": 942.03,
      "learning_rate": 0.005835946254180067,
      "loss": 2.3258,
      "step": 585940
    },
    {
      "epoch": 942.06,
      "learning_rate": 0.005832730823311897,
      "loss": 2.3244,
      "step": 585960
    },
    {
      "epoch": 942.09,
      "learning_rate": 0.005829515392443728,
      "loss": 2.3111,
      "step": 585980
    },
    {
      "epoch": 942.12,
      "learning_rate": 0.00582629996157556,
      "loss": 2.2891,
      "step": 586000
    },
    {
      "epoch": 942.15,
      "learning_rate": 0.005823084530707401,
      "loss": 2.3061,
      "step": 586020
    },
    {
      "epoch": 942.19,
      "learning_rate": 0.0058198690998392325,
      "loss": 2.3176,
      "step": 586040
    },
    {
      "epoch": 942.22,
      "learning_rate": 0.005816653668971063,
      "loss": 2.3025,
      "step": 586060
    },
    {
      "epoch": 942.25,
      "learning_rate": 0.005813438238102894,
      "loss": 2.3105,
      "step": 586080
    },
    {
      "epoch": 942.28,
      "learning_rate": 0.005810222807234725,
      "loss": 2.3338,
      "step": 586100
    },
    {
      "epoch": 942.32,
      "learning_rate": 0.005807007376366555,
      "loss": 2.3312,
      "step": 586120
    },
    {
      "epoch": 942.35,
      "learning_rate": 0.0058037919454983974,
      "loss": 2.3199,
      "step": 586140
    },
    {
      "epoch": 942.38,
      "learning_rate": 0.005800576514630228,
      "loss": 2.31,
      "step": 586160
    },
    {
      "epoch": 942.41,
      "learning_rate": 0.005797361083762059,
      "loss": 2.3245,
      "step": 586180
    },
    {
      "epoch": 942.44,
      "learning_rate": 0.00579414565289389,
      "loss": 2.328,
      "step": 586200
    },
    {
      "epoch": 942.48,
      "learning_rate": 0.00579093022202572,
      "loss": 2.3195,
      "step": 586220
    },
    {
      "epoch": 942.51,
      "learning_rate": 0.005787714791157551,
      "loss": 2.3272,
      "step": 586240
    },
    {
      "epoch": 942.54,
      "learning_rate": 0.005784499360289393,
      "loss": 2.3095,
      "step": 586260
    },
    {
      "epoch": 942.57,
      "learning_rate": 0.005781283929421224,
      "loss": 2.3141,
      "step": 586280
    },
    {
      "epoch": 942.6,
      "learning_rate": 0.0057780684985530555,
      "loss": 2.3155,
      "step": 586300
    },
    {
      "epoch": 942.64,
      "learning_rate": 0.005774853067684886,
      "loss": 2.3262,
      "step": 586320
    },
    {
      "epoch": 942.67,
      "learning_rate": 0.005771637636816717,
      "loss": 2.3316,
      "step": 586340
    },
    {
      "epoch": 942.7,
      "learning_rate": 0.005768422205948559,
      "loss": 2.3219,
      "step": 586360
    },
    {
      "epoch": 942.73,
      "learning_rate": 0.00576520677508039,
      "loss": 2.3302,
      "step": 586380
    },
    {
      "epoch": 942.77,
      "learning_rate": 0.0057619913442122205,
      "loss": 2.3102,
      "step": 586400
    },
    {
      "epoch": 942.8,
      "learning_rate": 0.005758775913344051,
      "loss": 2.3303,
      "step": 586420
    },
    {
      "epoch": 942.83,
      "learning_rate": 0.005755560482475882,
      "loss": 2.3132,
      "step": 586440
    },
    {
      "epoch": 942.86,
      "learning_rate": 0.005752345051607713,
      "loss": 2.3309,
      "step": 586460
    },
    {
      "epoch": 942.89,
      "learning_rate": 0.005749129620739555,
      "loss": 2.3147,
      "step": 586480
    },
    {
      "epoch": 942.93,
      "learning_rate": 0.0057459141898713855,
      "loss": 2.3095,
      "step": 586500
    },
    {
      "epoch": 942.96,
      "learning_rate": 0.005742698759003216,
      "loss": 2.3079,
      "step": 586520
    },
    {
      "epoch": 942.99,
      "learning_rate": 0.005739483328135047,
      "loss": 2.3229,
      "step": 586540
    },
    {
      "epoch": 943.0,
      "eval_accuracy": {
        "accuracy": 0.47974811474772605
      },
      "eval_loss": 2.432913064956665,
      "eval_runtime": 3.4598,
      "eval_samples_per_second": 3717.799,
      "eval_steps_per_second": 58.095,
      "step": 586546
    },
    {
      "epoch": 943.02,
      "learning_rate": 0.005736267897266878,
      "loss": 2.3261,
      "step": 586560
    },
    {
      "epoch": 943.05,
      "learning_rate": 0.005733052466398709,
      "loss": 2.3291,
      "step": 586580
    },
    {
      "epoch": 943.09,
      "learning_rate": 0.0057298370355305505,
      "loss": 2.3169,
      "step": 586600
    },
    {
      "epoch": 943.12,
      "learning_rate": 0.005726621604662382,
      "loss": 2.3267,
      "step": 586620
    },
    {
      "epoch": 943.15,
      "learning_rate": 0.005723406173794213,
      "loss": 2.3252,
      "step": 586640
    },
    {
      "epoch": 943.18,
      "learning_rate": 0.005720190742926044,
      "loss": 2.3235,
      "step": 586660
    },
    {
      "epoch": 943.22,
      "learning_rate": 0.005716975312057874,
      "loss": 2.315,
      "step": 586680
    },
    {
      "epoch": 943.25,
      "learning_rate": 0.005713759881189716,
      "loss": 2.3226,
      "step": 586700
    },
    {
      "epoch": 943.28,
      "learning_rate": 0.005710544450321547,
      "loss": 2.3177,
      "step": 586720
    },
    {
      "epoch": 943.31,
      "learning_rate": 0.005707329019453378,
      "loss": 2.2986,
      "step": 586740
    },
    {
      "epoch": 943.34,
      "learning_rate": 0.005704113588585209,
      "loss": 2.3129,
      "step": 586760
    },
    {
      "epoch": 943.38,
      "learning_rate": 0.005700898157717039,
      "loss": 2.3095,
      "step": 586780
    },
    {
      "epoch": 943.41,
      "learning_rate": 0.00569768272684887,
      "loss": 2.3038,
      "step": 586800
    },
    {
      "epoch": 943.44,
      "learning_rate": 0.005694467295980712,
      "loss": 2.3165,
      "step": 586820
    },
    {
      "epoch": 943.47,
      "learning_rate": 0.005691251865112543,
      "loss": 2.312,
      "step": 586840
    },
    {
      "epoch": 943.5,
      "learning_rate": 0.005688036434244374,
      "loss": 2.3157,
      "step": 586860
    },
    {
      "epoch": 943.54,
      "learning_rate": 0.005684821003376204,
      "loss": 2.3094,
      "step": 586880
    },
    {
      "epoch": 943.57,
      "learning_rate": 0.005681605572508036,
      "loss": 2.3198,
      "step": 586900
    },
    {
      "epoch": 943.6,
      "learning_rate": 0.005678390141639867,
      "loss": 2.3084,
      "step": 586920
    },
    {
      "epoch": 943.63,
      "learning_rate": 0.005675174710771709,
      "loss": 2.3102,
      "step": 586940
    },
    {
      "epoch": 943.67,
      "learning_rate": 0.0056719592799035394,
      "loss": 2.3162,
      "step": 586960
    },
    {
      "epoch": 943.7,
      "learning_rate": 0.00566874384903537,
      "loss": 2.3097,
      "step": 586980
    },
    {
      "epoch": 943.73,
      "learning_rate": 0.005665528418167201,
      "loss": 2.3272,
      "step": 587000
    },
    {
      "epoch": 943.76,
      "learning_rate": 0.005662473758842443,
      "loss": 2.3307,
      "step": 587020
    },
    {
      "epoch": 943.79,
      "learning_rate": 0.005659258327974274,
      "loss": 2.316,
      "step": 587040
    },
    {
      "epoch": 943.83,
      "learning_rate": 0.005656042897106105,
      "loss": 2.314,
      "step": 587060
    },
    {
      "epoch": 943.86,
      "learning_rate": 0.005652827466237947,
      "loss": 2.3242,
      "step": 587080
    },
    {
      "epoch": 943.89,
      "learning_rate": 0.0056496120353697775,
      "loss": 2.3153,
      "step": 587100
    },
    {
      "epoch": 943.92,
      "learning_rate": 0.005646396604501608,
      "loss": 2.3309,
      "step": 587120
    },
    {
      "epoch": 943.95,
      "learning_rate": 0.005643181173633439,
      "loss": 2.324,
      "step": 587140
    },
    {
      "epoch": 943.99,
      "learning_rate": 0.00563996574276527,
      "loss": 2.3106,
      "step": 587160
    },
    {
      "epoch": 944.0,
      "eval_accuracy": {
        "accuracy": 0.48122521962217213
      },
      "eval_loss": 2.4359755516052246,
      "eval_runtime": 3.2558,
      "eval_samples_per_second": 3950.763,
      "eval_steps_per_second": 61.735,
      "step": 587168
    },
    {
      "epoch": 944.02,
      "learning_rate": 0.005636750311897112,
      "loss": 2.3138,
      "step": 587180
    },
    {
      "epoch": 944.05,
      "learning_rate": 0.0056335348810289424,
      "loss": 2.3094,
      "step": 587200
    },
    {
      "epoch": 944.08,
      "learning_rate": 0.005630319450160773,
      "loss": 2.3178,
      "step": 587220
    },
    {
      "epoch": 944.12,
      "learning_rate": 0.005627104019292604,
      "loss": 2.3214,
      "step": 587240
    },
    {
      "epoch": 944.15,
      "learning_rate": 0.005623888588424435,
      "loss": 2.3233,
      "step": 587260
    },
    {
      "epoch": 944.18,
      "learning_rate": 0.005620673157556266,
      "loss": 2.3158,
      "step": 587280
    },
    {
      "epoch": 944.21,
      "learning_rate": 0.0056174577266881074,
      "loss": 2.3168,
      "step": 587300
    },
    {
      "epoch": 944.24,
      "learning_rate": 0.005614242295819939,
      "loss": 2.3079,
      "step": 587320
    },
    {
      "epoch": 944.28,
      "learning_rate": 0.00561102686495177,
      "loss": 2.3207,
      "step": 587340
    },
    {
      "epoch": 944.31,
      "learning_rate": 0.0056078114340836005,
      "loss": 2.3159,
      "step": 587360
    },
    {
      "epoch": 944.34,
      "learning_rate": 0.005604596003215431,
      "loss": 2.3086,
      "step": 587380
    },
    {
      "epoch": 944.37,
      "learning_rate": 0.005601380572347262,
      "loss": 2.3254,
      "step": 587400
    },
    {
      "epoch": 944.41,
      "learning_rate": 0.005598165141479104,
      "loss": 2.326,
      "step": 587420
    },
    {
      "epoch": 944.44,
      "learning_rate": 0.005594949710610935,
      "loss": 2.297,
      "step": 587440
    },
    {
      "epoch": 944.47,
      "learning_rate": 0.0055917342797427655,
      "loss": 2.3203,
      "step": 587460
    },
    {
      "epoch": 944.5,
      "learning_rate": 0.005588518848874596,
      "loss": 2.304,
      "step": 587480
    },
    {
      "epoch": 944.53,
      "learning_rate": 0.005585303418006427,
      "loss": 2.3262,
      "step": 587500
    },
    {
      "epoch": 944.57,
      "learning_rate": 0.005582087987138269,
      "loss": 2.314,
      "step": 587520
    },
    {
      "epoch": 944.6,
      "learning_rate": 0.0055788725562701,
      "loss": 2.3181,
      "step": 587540
    },
    {
      "epoch": 944.63,
      "learning_rate": 0.0055756571254019305,
      "loss": 2.3186,
      "step": 587560
    },
    {
      "epoch": 944.66,
      "learning_rate": 0.005572441694533761,
      "loss": 2.3208,
      "step": 587580
    },
    {
      "epoch": 944.69,
      "learning_rate": 0.005569226263665593,
      "loss": 2.3274,
      "step": 587600
    },
    {
      "epoch": 944.73,
      "learning_rate": 0.005566010832797424,
      "loss": 2.3026,
      "step": 587620
    },
    {
      "epoch": 944.76,
      "learning_rate": 0.005562795401929266,
      "loss": 2.3097,
      "step": 587640
    },
    {
      "epoch": 944.79,
      "learning_rate": 0.005559579971061096,
      "loss": 2.3185,
      "step": 587660
    },
    {
      "epoch": 944.82,
      "learning_rate": 0.005556364540192927,
      "loss": 2.313,
      "step": 587680
    },
    {
      "epoch": 944.86,
      "learning_rate": 0.005553149109324758,
      "loss": 2.3194,
      "step": 587700
    },
    {
      "epoch": 944.89,
      "learning_rate": 0.005549933678456589,
      "loss": 2.3287,
      "step": 587720
    },
    {
      "epoch": 944.92,
      "learning_rate": 0.005546718247588419,
      "loss": 2.3288,
      "step": 587740
    },
    {
      "epoch": 944.95,
      "learning_rate": 0.005543502816720261,
      "loss": 2.3068,
      "step": 587760
    },
    {
      "epoch": 944.98,
      "learning_rate": 0.005540287385852092,
      "loss": 2.3287,
      "step": 587780
    },
    {
      "epoch": 945.0,
      "eval_accuracy": {
        "accuracy": 0.4817694161548628
      },
      "eval_loss": 2.4413204193115234,
      "eval_runtime": 3.5894,
      "eval_samples_per_second": 3583.651,
      "eval_steps_per_second": 55.999,
      "step": 587790
    },
    {
      "epoch": 945.02,
      "learning_rate": 0.005537071954983923,
      "loss": 2.324,
      "step": 587800
    },
    {
      "epoch": 945.05,
      "learning_rate": 0.005533856524115754,
      "loss": 2.3095,
      "step": 587820
    },
    {
      "epoch": 945.08,
      "learning_rate": 0.005530641093247584,
      "loss": 2.3201,
      "step": 587840
    },
    {
      "epoch": 945.11,
      "learning_rate": 0.005527425662379426,
      "loss": 2.3242,
      "step": 587860
    },
    {
      "epoch": 945.14,
      "learning_rate": 0.005524210231511257,
      "loss": 2.313,
      "step": 587880
    },
    {
      "epoch": 945.18,
      "learning_rate": 0.005520994800643088,
      "loss": 2.3186,
      "step": 587900
    },
    {
      "epoch": 945.21,
      "learning_rate": 0.0055177793697749195,
      "loss": 2.3167,
      "step": 587920
    },
    {
      "epoch": 945.24,
      "learning_rate": 0.00551456393890675,
      "loss": 2.2952,
      "step": 587940
    },
    {
      "epoch": 945.27,
      "learning_rate": 0.005511348508038581,
      "loss": 2.3157,
      "step": 587960
    },
    {
      "epoch": 945.31,
      "learning_rate": 0.005508133077170423,
      "loss": 2.3182,
      "step": 587980
    },
    {
      "epoch": 945.34,
      "learning_rate": 0.005504917646302254,
      "loss": 2.3228,
      "step": 588000
    },
    {
      "epoch": 945.37,
      "learning_rate": 0.0055017022154340844,
      "loss": 2.3041,
      "step": 588020
    },
    {
      "epoch": 945.4,
      "learning_rate": 0.005498486784565915,
      "loss": 2.3052,
      "step": 588040
    },
    {
      "epoch": 945.43,
      "learning_rate": 0.005495271353697746,
      "loss": 2.3149,
      "step": 588060
    },
    {
      "epoch": 945.47,
      "learning_rate": 0.005492055922829588,
      "loss": 2.3195,
      "step": 588080
    },
    {
      "epoch": 945.5,
      "learning_rate": 0.005488840491961419,
      "loss": 2.3228,
      "step": 588100
    },
    {
      "epoch": 945.53,
      "learning_rate": 0.005485625061093249,
      "loss": 2.3299,
      "step": 588120
    },
    {
      "epoch": 945.56,
      "learning_rate": 0.00548240963022508,
      "loss": 2.3043,
      "step": 588140
    },
    {
      "epoch": 945.59,
      "learning_rate": 0.005479194199356911,
      "loss": 2.3335,
      "step": 588160
    },
    {
      "epoch": 945.63,
      "learning_rate": 0.005475978768488742,
      "loss": 2.3073,
      "step": 588180
    },
    {
      "epoch": 945.66,
      "learning_rate": 0.005472763337620584,
      "loss": 2.2941,
      "step": 588200
    },
    {
      "epoch": 945.69,
      "learning_rate": 0.005469547906752414,
      "loss": 2.3188,
      "step": 588220
    },
    {
      "epoch": 945.72,
      "learning_rate": 0.005466332475884246,
      "loss": 2.3129,
      "step": 588240
    },
    {
      "epoch": 945.76,
      "learning_rate": 0.005463117045016077,
      "loss": 2.2932,
      "step": 588260
    },
    {
      "epoch": 945.79,
      "learning_rate": 0.0054599016141479075,
      "loss": 2.3114,
      "step": 588280
    },
    {
      "epoch": 945.82,
      "learning_rate": 0.005456686183279738,
      "loss": 2.3303,
      "step": 588300
    },
    {
      "epoch": 945.85,
      "learning_rate": 0.00545347075241158,
      "loss": 2.3117,
      "step": 588320
    },
    {
      "epoch": 945.88,
      "learning_rate": 0.005450255321543411,
      "loss": 2.3115,
      "step": 588340
    },
    {
      "epoch": 945.92,
      "learning_rate": 0.005447039890675242,
      "loss": 2.3216,
      "step": 588360
    },
    {
      "epoch": 945.95,
      "learning_rate": 0.0054438244598070725,
      "loss": 2.3194,
      "step": 588380
    },
    {
      "epoch": 945.98,
      "learning_rate": 0.005440609028938903,
      "loss": 2.3253,
      "step": 588400
    },
    {
      "epoch": 946.0,
      "eval_accuracy": {
        "accuracy": 0.4837129752001866
      },
      "eval_loss": 2.430081605911255,
      "eval_runtime": 3.4732,
      "eval_samples_per_second": 3703.55,
      "eval_steps_per_second": 57.872,
      "step": 588412
    },
    {
      "epoch": 946.01,
      "learning_rate": 0.005437393598070745,
      "loss": 2.3288,
      "step": 588420
    },
    {
      "epoch": 946.05,
      "learning_rate": 0.005434178167202576,
      "loss": 2.3036,
      "step": 588440
    },
    {
      "epoch": 946.08,
      "learning_rate": 0.005430962736334407,
      "loss": 2.3199,
      "step": 588460
    },
    {
      "epoch": 946.11,
      "learning_rate": 0.0054277473054662375,
      "loss": 2.3171,
      "step": 588480
    },
    {
      "epoch": 946.14,
      "learning_rate": 0.005424531874598069,
      "loss": 2.3033,
      "step": 588500
    },
    {
      "epoch": 946.17,
      "learning_rate": 0.0054213164437299,
      "loss": 2.2967,
      "step": 588520
    },
    {
      "epoch": 946.21,
      "learning_rate": 0.005418101012861742,
      "loss": 2.3151,
      "step": 588540
    },
    {
      "epoch": 946.24,
      "learning_rate": 0.005414885581993573,
      "loss": 2.3055,
      "step": 588560
    },
    {
      "epoch": 946.27,
      "learning_rate": 0.005411670151125403,
      "loss": 2.313,
      "step": 588580
    },
    {
      "epoch": 946.3,
      "learning_rate": 0.005408454720257234,
      "loss": 2.3229,
      "step": 588600
    },
    {
      "epoch": 946.33,
      "learning_rate": 0.005405239289389065,
      "loss": 2.3138,
      "step": 588620
    },
    {
      "epoch": 946.37,
      "learning_rate": 0.005402023858520896,
      "loss": 2.3053,
      "step": 588640
    },
    {
      "epoch": 946.4,
      "learning_rate": 0.005398808427652738,
      "loss": 2.3359,
      "step": 588660
    },
    {
      "epoch": 946.43,
      "learning_rate": 0.005395592996784568,
      "loss": 2.3053,
      "step": 588680
    },
    {
      "epoch": 946.46,
      "learning_rate": 0.005392377565916399,
      "loss": 2.2984,
      "step": 588700
    },
    {
      "epoch": 946.5,
      "learning_rate": 0.00538916213504823,
      "loss": 2.3254,
      "step": 588720
    },
    {
      "epoch": 946.53,
      "learning_rate": 0.005385946704180061,
      "loss": 2.3251,
      "step": 588740
    },
    {
      "epoch": 946.56,
      "learning_rate": 0.005382731273311903,
      "loss": 2.3275,
      "step": 588760
    },
    {
      "epoch": 946.59,
      "learning_rate": 0.005379515842443733,
      "loss": 2.297,
      "step": 588780
    },
    {
      "epoch": 946.62,
      "learning_rate": 0.005376300411575564,
      "loss": 2.3229,
      "step": 588800
    },
    {
      "epoch": 946.66,
      "learning_rate": 0.005373084980707396,
      "loss": 2.3134,
      "step": 588820
    },
    {
      "epoch": 946.69,
      "learning_rate": 0.0053698695498392264,
      "loss": 2.3144,
      "step": 588840
    },
    {
      "epoch": 946.72,
      "learning_rate": 0.005366654118971057,
      "loss": 2.3089,
      "step": 588860
    },
    {
      "epoch": 946.75,
      "learning_rate": 0.005363438688102899,
      "loss": 2.3329,
      "step": 588880
    },
    {
      "epoch": 946.78,
      "learning_rate": 0.00536022325723473,
      "loss": 2.2962,
      "step": 588900
    },
    {
      "epoch": 946.82,
      "learning_rate": 0.005357007826366561,
      "loss": 2.328,
      "step": 588920
    },
    {
      "epoch": 946.85,
      "learning_rate": 0.005353792395498391,
      "loss": 2.3237,
      "step": 588940
    },
    {
      "epoch": 946.88,
      "learning_rate": 0.005350576964630222,
      "loss": 2.3201,
      "step": 588960
    },
    {
      "epoch": 946.91,
      "learning_rate": 0.005347361533762053,
      "loss": 2.3184,
      "step": 588980
    },
    {
      "epoch": 946.95,
      "learning_rate": 0.005344146102893895,
      "loss": 2.3222,
      "step": 589000
    },
    {
      "epoch": 946.98,
      "learning_rate": 0.005340930672025726,
      "loss": 2.3077,
      "step": 589020
    },
    {
      "epoch": 947.0,
      "eval_accuracy": {
        "accuracy": 0.4815361890694239
      },
      "eval_loss": 2.4343056678771973,
      "eval_runtime": 3.2367,
      "eval_samples_per_second": 3974.13,
      "eval_steps_per_second": 62.101,
      "step": 589034
    },
    {
      "epoch": 947.01,
      "learning_rate": 0.005337715241157556,
      "loss": 2.3009,
      "step": 589040
    },
    {
      "epoch": 947.04,
      "learning_rate": 0.005334499810289387,
      "loss": 2.3241,
      "step": 589060
    },
    {
      "epoch": 947.07,
      "learning_rate": 0.005331284379421218,
      "loss": 2.3301,
      "step": 589080
    },
    {
      "epoch": 947.11,
      "learning_rate": 0.00532806894855306,
      "loss": 2.3117,
      "step": 589100
    },
    {
      "epoch": 947.14,
      "learning_rate": 0.005324853517684891,
      "loss": 2.3044,
      "step": 589120
    },
    {
      "epoch": 947.17,
      "learning_rate": 0.005321638086816722,
      "loss": 2.3121,
      "step": 589140
    },
    {
      "epoch": 947.2,
      "learning_rate": 0.005318422655948553,
      "loss": 2.2952,
      "step": 589160
    },
    {
      "epoch": 947.23,
      "learning_rate": 0.005315207225080384,
      "loss": 2.3146,
      "step": 589180
    },
    {
      "epoch": 947.27,
      "learning_rate": 0.0053119917942122145,
      "loss": 2.3159,
      "step": 589200
    },
    {
      "epoch": 947.3,
      "learning_rate": 0.0053087763633440565,
      "loss": 2.3136,
      "step": 589220
    },
    {
      "epoch": 947.33,
      "learning_rate": 0.005305560932475887,
      "loss": 2.324,
      "step": 589240
    },
    {
      "epoch": 947.36,
      "learning_rate": 0.005302345501607718,
      "loss": 2.3093,
      "step": 589260
    },
    {
      "epoch": 947.4,
      "learning_rate": 0.005299130070739549,
      "loss": 2.3016,
      "step": 589280
    },
    {
      "epoch": 947.43,
      "learning_rate": 0.0052959146398713795,
      "loss": 2.3165,
      "step": 589300
    },
    {
      "epoch": 947.46,
      "learning_rate": 0.00529269920900321,
      "loss": 2.3062,
      "step": 589320
    },
    {
      "epoch": 947.49,
      "learning_rate": 0.005289483778135052,
      "loss": 2.3199,
      "step": 589340
    },
    {
      "epoch": 947.52,
      "learning_rate": 0.005286268347266883,
      "loss": 2.3059,
      "step": 589360
    },
    {
      "epoch": 947.56,
      "learning_rate": 0.005283052916398714,
      "loss": 2.3066,
      "step": 589380
    },
    {
      "epoch": 947.59,
      "learning_rate": 0.0052798374855305445,
      "loss": 2.315,
      "step": 589400
    },
    {
      "epoch": 947.62,
      "learning_rate": 0.005276622054662376,
      "loss": 2.3065,
      "step": 589420
    },
    {
      "epoch": 947.65,
      "learning_rate": 0.005273406623794217,
      "loss": 2.3255,
      "step": 589440
    },
    {
      "epoch": 947.68,
      "learning_rate": 0.005270191192926049,
      "loss": 2.3117,
      "step": 589460
    },
    {
      "epoch": 947.72,
      "learning_rate": 0.00526697576205788,
      "loss": 2.3131,
      "step": 589480
    },
    {
      "epoch": 947.75,
      "learning_rate": 0.00526376033118971,
      "loss": 2.3318,
      "step": 589500
    },
    {
      "epoch": 947.78,
      "learning_rate": 0.005260544900321541,
      "loss": 2.3117,
      "step": 589520
    },
    {
      "epoch": 947.81,
      "learning_rate": 0.005257329469453372,
      "loss": 2.3083,
      "step": 589540
    },
    {
      "epoch": 947.85,
      "learning_rate": 0.005254114038585214,
      "loss": 2.3179,
      "step": 589560
    },
    {
      "epoch": 947.88,
      "learning_rate": 0.005250898607717045,
      "loss": 2.3138,
      "step": 589580
    },
    {
      "epoch": 947.91,
      "learning_rate": 0.005247683176848875,
      "loss": 2.3032,
      "step": 589600
    },
    {
      "epoch": 947.94,
      "learning_rate": 0.005244467745980706,
      "loss": 2.3231,
      "step": 589620
    },
    {
      "epoch": 947.97,
      "learning_rate": 0.005241252315112537,
      "loss": 2.3149,
      "step": 589640
    },
    {
      "epoch": 948.0,
      "eval_accuracy": {
        "accuracy": 0.4834797481147477
      },
      "eval_loss": 2.43831205368042,
      "eval_runtime": 3.3123,
      "eval_samples_per_second": 3883.432,
      "eval_steps_per_second": 60.683,
      "step": 589656
    },
    {
      "epoch": 948.01,
      "learning_rate": 0.0052380368842443676,
      "loss": 2.3082,
      "step": 589660
    },
    {
      "epoch": 948.04,
      "learning_rate": 0.00523482145337621,
      "loss": 2.2909,
      "step": 589680
    },
    {
      "epoch": 948.07,
      "learning_rate": 0.00523160602250804,
      "loss": 2.3117,
      "step": 589700
    },
    {
      "epoch": 948.1,
      "learning_rate": 0.005228390591639872,
      "loss": 2.313,
      "step": 589720
    },
    {
      "epoch": 948.14,
      "learning_rate": 0.005225175160771703,
      "loss": 2.3134,
      "step": 589740
    },
    {
      "epoch": 948.17,
      "learning_rate": 0.005221959729903533,
      "loss": 2.3125,
      "step": 589760
    },
    {
      "epoch": 948.2,
      "learning_rate": 0.0052187442990353754,
      "loss": 2.3134,
      "step": 589780
    },
    {
      "epoch": 948.23,
      "learning_rate": 0.005215528868167206,
      "loss": 2.3225,
      "step": 589800
    },
    {
      "epoch": 948.26,
      "learning_rate": 0.005212313437299037,
      "loss": 2.331,
      "step": 589820
    },
    {
      "epoch": 948.3,
      "learning_rate": 0.005209098006430868,
      "loss": 2.3058,
      "step": 589840
    },
    {
      "epoch": 948.33,
      "learning_rate": 0.005205882575562698,
      "loss": 2.3125,
      "step": 589860
    },
    {
      "epoch": 948.36,
      "learning_rate": 0.005202667144694529,
      "loss": 2.2942,
      "step": 589880
    },
    {
      "epoch": 948.39,
      "learning_rate": 0.005199451713826371,
      "loss": 2.3201,
      "step": 589900
    },
    {
      "epoch": 948.42,
      "learning_rate": 0.005196236282958202,
      "loss": 2.3203,
      "step": 589920
    },
    {
      "epoch": 948.46,
      "learning_rate": 0.005193020852090033,
      "loss": 2.3179,
      "step": 589940
    },
    {
      "epoch": 948.49,
      "learning_rate": 0.005189805421221863,
      "loss": 2.3072,
      "step": 589960
    },
    {
      "epoch": 948.52,
      "learning_rate": 0.005186589990353694,
      "loss": 2.3186,
      "step": 589980
    },
    {
      "epoch": 948.55,
      "learning_rate": 0.005183374559485536,
      "loss": 2.3131,
      "step": 590000
    },
    {
      "epoch": 948.59,
      "learning_rate": 0.005180159128617367,
      "loss": 2.3125,
      "step": 590020
    },
    {
      "epoch": 948.62,
      "learning_rate": 0.0051769436977491985,
      "loss": 2.3131,
      "step": 590040
    },
    {
      "epoch": 948.65,
      "learning_rate": 0.005173728266881029,
      "loss": 2.318,
      "step": 590060
    },
    {
      "epoch": 948.68,
      "learning_rate": 0.00517051283601286,
      "loss": 2.3064,
      "step": 590080
    },
    {
      "epoch": 948.71,
      "learning_rate": 0.005167297405144691,
      "loss": 2.298,
      "step": 590100
    },
    {
      "epoch": 948.75,
      "learning_rate": 0.005164081974276533,
      "loss": 2.298,
      "step": 590120
    },
    {
      "epoch": 948.78,
      "learning_rate": 0.0051608665434083635,
      "loss": 2.3004,
      "step": 590140
    },
    {
      "epoch": 948.81,
      "learning_rate": 0.005157651112540194,
      "loss": 2.3155,
      "step": 590160
    },
    {
      "epoch": 948.84,
      "learning_rate": 0.005154435681672025,
      "loss": 2.3053,
      "step": 590180
    },
    {
      "epoch": 948.87,
      "learning_rate": 0.005151220250803856,
      "loss": 2.3101,
      "step": 590200
    },
    {
      "epoch": 948.91,
      "learning_rate": 0.0051480048199356865,
      "loss": 2.3214,
      "step": 590220
    },
    {
      "epoch": 948.94,
      "learning_rate": 0.0051447893890675285,
      "loss": 2.332,
      "step": 590240
    },
    {
      "epoch": 948.97,
      "learning_rate": 0.005141573958199359,
      "loss": 2.3266,
      "step": 590260
    },
    {
      "epoch": 949.0,
      "eval_accuracy": {
        "accuracy": 0.48099199253673325
      },
      "eval_loss": 2.4281907081604004,
      "eval_runtime": 3.2777,
      "eval_samples_per_second": 3924.351,
      "eval_steps_per_second": 61.323,
      "step": 590278
    },
    {
      "epoch": 949.0,
      "learning_rate": 0.00513835852733119,
      "loss": 2.3247,
      "step": 590280
    },
    {
      "epoch": 949.04,
      "learning_rate": 0.005135143096463021,
      "loss": 2.3237,
      "step": 590300
    },
    {
      "epoch": 949.07,
      "learning_rate": 0.005131927665594852,
      "loss": 2.3048,
      "step": 590320
    },
    {
      "epoch": 949.1,
      "learning_rate": 0.0051287122347266935,
      "loss": 2.3255,
      "step": 590340
    },
    {
      "epoch": 949.13,
      "learning_rate": 0.005125496803858525,
      "loss": 2.3086,
      "step": 590360
    },
    {
      "epoch": 949.16,
      "learning_rate": 0.005122281372990356,
      "loss": 2.3169,
      "step": 590380
    },
    {
      "epoch": 949.2,
      "learning_rate": 0.005119065942122187,
      "loss": 2.3139,
      "step": 590400
    },
    {
      "epoch": 949.23,
      "learning_rate": 0.005115850511254017,
      "loss": 2.3009,
      "step": 590420
    },
    {
      "epoch": 949.26,
      "learning_rate": 0.005112635080385848,
      "loss": 2.3156,
      "step": 590440
    },
    {
      "epoch": 949.29,
      "learning_rate": 0.00510941964951769,
      "loss": 2.3157,
      "step": 590460
    },
    {
      "epoch": 949.32,
      "learning_rate": 0.005106204218649521,
      "loss": 2.3004,
      "step": 590480
    },
    {
      "epoch": 949.36,
      "learning_rate": 0.005102988787781352,
      "loss": 2.3168,
      "step": 590500
    },
    {
      "epoch": 949.39,
      "learning_rate": 0.005099773356913182,
      "loss": 2.3098,
      "step": 590520
    },
    {
      "epoch": 949.42,
      "learning_rate": 0.005096557926045013,
      "loss": 2.3093,
      "step": 590540
    },
    {
      "epoch": 949.45,
      "learning_rate": 0.005093342495176844,
      "loss": 2.3059,
      "step": 590560
    },
    {
      "epoch": 949.49,
      "learning_rate": 0.005090127064308686,
      "loss": 2.3092,
      "step": 590580
    },
    {
      "epoch": 949.52,
      "learning_rate": 0.005086911633440517,
      "loss": 2.3084,
      "step": 590600
    },
    {
      "epoch": 949.55,
      "learning_rate": 0.005083696202572347,
      "loss": 2.3142,
      "step": 590620
    },
    {
      "epoch": 949.58,
      "learning_rate": 0.005080480771704179,
      "loss": 2.3098,
      "step": 590640
    },
    {
      "epoch": 949.61,
      "learning_rate": 0.00507726534083601,
      "loss": 2.3131,
      "step": 590660
    },
    {
      "epoch": 949.65,
      "learning_rate": 0.005074049909967852,
      "loss": 2.3023,
      "step": 590680
    },
    {
      "epoch": 949.68,
      "learning_rate": 0.005070995250643083,
      "loss": 2.3103,
      "step": 590700
    },
    {
      "epoch": 949.71,
      "learning_rate": 0.005067779819774924,
      "loss": 2.3334,
      "step": 590720
    },
    {
      "epoch": 949.74,
      "learning_rate": 0.0050645643889067555,
      "loss": 2.3183,
      "step": 590740
    },
    {
      "epoch": 949.77,
      "learning_rate": 0.005061348958038586,
      "loss": 2.3099,
      "step": 590760
    },
    {
      "epoch": 949.81,
      "learning_rate": 0.005058133527170417,
      "loss": 2.3108,
      "step": 590780
    },
    {
      "epoch": 949.84,
      "learning_rate": 0.005054918096302248,
      "loss": 2.2986,
      "step": 590800
    },
    {
      "epoch": 949.87,
      "learning_rate": 0.00505170266543409,
      "loss": 2.3112,
      "step": 590820
    },
    {
      "epoch": 949.9,
      "learning_rate": 0.0050484872345659204,
      "loss": 2.3133,
      "step": 590840
    },
    {
      "epoch": 949.94,
      "learning_rate": 0.005045271803697751,
      "loss": 2.304,
      "step": 590860
    },
    {
      "epoch": 949.97,
      "learning_rate": 0.005042056372829582,
      "loss": 2.3202,
      "step": 590880
    },
    {
      "epoch": 950.0,
      "learning_rate": 0.005038840941961413,
      "loss": 2.3218,
      "step": 590900
    },
    {
      "epoch": 950.0,
      "eval_accuracy": {
        "accuracy": 0.4796703723859131
      },
      "eval_loss": 2.4293980598449707,
      "eval_runtime": 3.5784,
      "eval_samples_per_second": 3594.633,
      "eval_steps_per_second": 56.17,
      "step": 590900
    },
    {
      "epoch": 950.03,
      "learning_rate": 0.005035625511093243,
      "loss": 2.322,
      "step": 590920
    },
    {
      "epoch": 950.06,
      "learning_rate": 0.0050324100802250854,
      "loss": 2.3016,
      "step": 590940
    },
    {
      "epoch": 950.1,
      "learning_rate": 0.005029194649356916,
      "loss": 2.3256,
      "step": 590960
    },
    {
      "epoch": 950.13,
      "learning_rate": 0.005025979218488747,
      "loss": 2.2876,
      "step": 590980
    },
    {
      "epoch": 950.16,
      "learning_rate": 0.005022763787620578,
      "loss": 2.3198,
      "step": 591000
    },
    {
      "epoch": 950.19,
      "learning_rate": 0.005019548356752409,
      "loss": 2.3088,
      "step": 591020
    },
    {
      "epoch": 950.23,
      "learning_rate": 0.00501633292588424,
      "loss": 2.3095,
      "step": 591040
    },
    {
      "epoch": 950.26,
      "learning_rate": 0.005013117495016082,
      "loss": 2.3243,
      "step": 591060
    },
    {
      "epoch": 950.29,
      "learning_rate": 0.005009902064147913,
      "loss": 2.3219,
      "step": 591080
    },
    {
      "epoch": 950.32,
      "learning_rate": 0.0050066866332797435,
      "loss": 2.2997,
      "step": 591100
    },
    {
      "epoch": 950.35,
      "learning_rate": 0.005003471202411574,
      "loss": 2.3218,
      "step": 591120
    },
    {
      "epoch": 950.39,
      "learning_rate": 0.005000255771543405,
      "loss": 2.2996,
      "step": 591140
    },
    {
      "epoch": 950.42,
      "learning_rate": 0.004997040340675247,
      "loss": 2.3074,
      "step": 591160
    },
    {
      "epoch": 950.45,
      "learning_rate": 0.004993824909807078,
      "loss": 2.3119,
      "step": 591180
    },
    {
      "epoch": 950.48,
      "learning_rate": 0.0049906094789389085,
      "loss": 2.3094,
      "step": 591200
    },
    {
      "epoch": 950.51,
      "learning_rate": 0.004987394048070739,
      "loss": 2.2809,
      "step": 591220
    },
    {
      "epoch": 950.55,
      "learning_rate": 0.00498417861720257,
      "loss": 2.3275,
      "step": 591240
    },
    {
      "epoch": 950.58,
      "learning_rate": 0.004980963186334401,
      "loss": 2.3157,
      "step": 591260
    },
    {
      "epoch": 950.61,
      "learning_rate": 0.004977747755466243,
      "loss": 2.3105,
      "step": 591280
    },
    {
      "epoch": 950.64,
      "learning_rate": 0.0049745323245980735,
      "loss": 2.3093,
      "step": 591300
    },
    {
      "epoch": 950.68,
      "learning_rate": 0.004971316893729904,
      "loss": 2.3011,
      "step": 591320
    },
    {
      "epoch": 950.71,
      "learning_rate": 0.004968101462861736,
      "loss": 2.3177,
      "step": 591340
    },
    {
      "epoch": 950.74,
      "learning_rate": 0.004964886031993567,
      "loss": 2.3186,
      "step": 591360
    },
    {
      "epoch": 950.77,
      "learning_rate": 0.004961670601125397,
      "loss": 2.316,
      "step": 591380
    },
    {
      "epoch": 950.8,
      "learning_rate": 0.004958455170257239,
      "loss": 2.3015,
      "step": 591400
    },
    {
      "epoch": 950.84,
      "learning_rate": 0.00495523973938907,
      "loss": 2.3259,
      "step": 591420
    },
    {
      "epoch": 950.87,
      "learning_rate": 0.004952024308520901,
      "loss": 2.3286,
      "step": 591440
    },
    {
      "epoch": 950.9,
      "learning_rate": 0.004948808877652732,
      "loss": 2.3149,
      "step": 591460
    },
    {
      "epoch": 950.93,
      "learning_rate": 0.004945593446784562,
      "loss": 2.3004,
      "step": 591480
    },
    {
      "epoch": 950.96,
      "learning_rate": 0.004942378015916404,
      "loss": 2.3148,
      "step": 591500
    },
    {
      "epoch": 951.0,
      "learning_rate": 0.004939162585048235,
      "loss": 2.2925,
      "step": 591520
    },
    {
      "epoch": 951.0,
      "eval_accuracy": {
        "accuracy": 0.4801368265567908
      },
      "eval_loss": 2.43119215965271,
      "eval_runtime": 3.4522,
      "eval_samples_per_second": 3726.05,
      "eval_steps_per_second": 58.224,
      "step": 591522
    },
    {
      "epoch": 951.03,
      "learning_rate": 0.004935947154180066,
      "loss": 2.3093,
      "step": 591540
    },
    {
      "epoch": 951.06,
      "learning_rate": 0.004932731723311897,
      "loss": 2.2896,
      "step": 591560
    },
    {
      "epoch": 951.09,
      "learning_rate": 0.004929516292443727,
      "loss": 2.3128,
      "step": 591580
    },
    {
      "epoch": 951.13,
      "learning_rate": 0.004926300861575559,
      "loss": 2.3416,
      "step": 591600
    },
    {
      "epoch": 951.16,
      "learning_rate": 0.0049230854307074,
      "loss": 2.3017,
      "step": 591620
    },
    {
      "epoch": 951.19,
      "learning_rate": 0.004919869999839232,
      "loss": 2.3118,
      "step": 591640
    },
    {
      "epoch": 951.22,
      "learning_rate": 0.0049166545689710624,
      "loss": 2.3102,
      "step": 591660
    },
    {
      "epoch": 951.25,
      "learning_rate": 0.004913439138102893,
      "loss": 2.3093,
      "step": 591680
    },
    {
      "epoch": 951.29,
      "learning_rate": 0.004910223707234724,
      "loss": 2.3146,
      "step": 591700
    },
    {
      "epoch": 951.32,
      "learning_rate": 0.004907008276366555,
      "loss": 2.3045,
      "step": 591720
    },
    {
      "epoch": 951.35,
      "learning_rate": 0.004903792845498397,
      "loss": 2.3092,
      "step": 591740
    },
    {
      "epoch": 951.38,
      "learning_rate": 0.004900577414630227,
      "loss": 2.3051,
      "step": 591760
    },
    {
      "epoch": 951.41,
      "learning_rate": 0.004897361983762058,
      "loss": 2.3321,
      "step": 591780
    },
    {
      "epoch": 951.45,
      "learning_rate": 0.004894146552893889,
      "loss": 2.323,
      "step": 591800
    },
    {
      "epoch": 951.48,
      "learning_rate": 0.00489093112202572,
      "loss": 2.3145,
      "step": 591820
    },
    {
      "epoch": 951.51,
      "learning_rate": 0.004887715691157562,
      "loss": 2.3123,
      "step": 591840
    },
    {
      "epoch": 951.54,
      "learning_rate": 0.004884500260289392,
      "loss": 2.3141,
      "step": 591860
    },
    {
      "epoch": 951.58,
      "learning_rate": 0.004881284829421223,
      "loss": 2.304,
      "step": 591880
    },
    {
      "epoch": 951.61,
      "learning_rate": 0.004878069398553054,
      "loss": 2.3059,
      "step": 591900
    },
    {
      "epoch": 951.64,
      "learning_rate": 0.0048748539676848855,
      "loss": 2.2973,
      "step": 591920
    },
    {
      "epoch": 951.67,
      "learning_rate": 0.004871638536816716,
      "loss": 2.3089,
      "step": 591940
    },
    {
      "epoch": 951.7,
      "learning_rate": 0.004868423105948558,
      "loss": 2.303,
      "step": 591960
    },
    {
      "epoch": 951.74,
      "learning_rate": 0.004865207675080389,
      "loss": 2.3081,
      "step": 591980
    },
    {
      "epoch": 951.77,
      "learning_rate": 0.00486199224421222,
      "loss": 2.3083,
      "step": 592000
    },
    {
      "epoch": 951.8,
      "learning_rate": 0.0048587768133440505,
      "loss": 2.3309,
      "step": 592020
    },
    {
      "epoch": 951.83,
      "learning_rate": 0.004855561382475881,
      "loss": 2.3098,
      "step": 592040
    },
    {
      "epoch": 951.86,
      "learning_rate": 0.004852345951607712,
      "loss": 2.3098,
      "step": 592060
    },
    {
      "epoch": 951.9,
      "learning_rate": 0.004849130520739554,
      "loss": 2.3213,
      "step": 592080
    },
    {
      "epoch": 951.93,
      "learning_rate": 0.004845915089871385,
      "loss": 2.3105,
      "step": 592100
    },
    {
      "epoch": 951.96,
      "learning_rate": 0.0048426996590032155,
      "loss": 2.2956,
      "step": 592120
    },
    {
      "epoch": 951.99,
      "learning_rate": 0.004839484228135046,
      "loss": 2.2981,
      "step": 592140
    },
    {
      "epoch": 952.0,
      "eval_accuracy": {
        "accuracy": 0.48565653424551036
      },
      "eval_loss": 2.4276652336120605,
      "eval_runtime": 3.0735,
      "eval_samples_per_second": 4185.165,
      "eval_steps_per_second": 65.398,
      "step": 592144
    },
    {
      "epoch": 952.03,
      "learning_rate": 0.004836268797266877,
      "loss": 2.3083,
      "step": 592160
    },
    {
      "epoch": 952.06,
      "learning_rate": 0.004833053366398719,
      "loss": 2.3051,
      "step": 592180
    },
    {
      "epoch": 952.09,
      "learning_rate": 0.00482983793553055,
      "loss": 2.3247,
      "step": 592200
    },
    {
      "epoch": 952.12,
      "learning_rate": 0.0048266225046623805,
      "loss": 2.3058,
      "step": 592220
    },
    {
      "epoch": 952.15,
      "learning_rate": 0.004823407073794212,
      "loss": 2.3196,
      "step": 592240
    },
    {
      "epoch": 952.19,
      "learning_rate": 0.004820191642926043,
      "loss": 2.3114,
      "step": 592260
    },
    {
      "epoch": 952.22,
      "learning_rate": 0.004816976212057874,
      "loss": 2.3122,
      "step": 592280
    },
    {
      "epoch": 952.25,
      "learning_rate": 0.004813760781189716,
      "loss": 2.303,
      "step": 592300
    },
    {
      "epoch": 952.28,
      "learning_rate": 0.004810545350321546,
      "loss": 2.3153,
      "step": 592320
    },
    {
      "epoch": 952.32,
      "learning_rate": 0.004807329919453377,
      "loss": 2.3095,
      "step": 592340
    },
    {
      "epoch": 952.35,
      "learning_rate": 0.004804114488585208,
      "loss": 2.309,
      "step": 592360
    },
    {
      "epoch": 952.38,
      "learning_rate": 0.004800899057717039,
      "loss": 2.3067,
      "step": 592380
    },
    {
      "epoch": 952.41,
      "learning_rate": 0.004797683626848869,
      "loss": 2.309,
      "step": 592400
    },
    {
      "epoch": 952.44,
      "learning_rate": 0.004794468195980711,
      "loss": 2.2998,
      "step": 592420
    },
    {
      "epoch": 952.48,
      "learning_rate": 0.004791252765112542,
      "loss": 2.2875,
      "step": 592440
    },
    {
      "epoch": 952.51,
      "learning_rate": 0.004788037334244373,
      "loss": 2.2943,
      "step": 592460
    },
    {
      "epoch": 952.54,
      "learning_rate": 0.004784821903376204,
      "loss": 2.3152,
      "step": 592480
    },
    {
      "epoch": 952.57,
      "learning_rate": 0.004781606472508034,
      "loss": 2.3012,
      "step": 592500
    },
    {
      "epoch": 952.6,
      "learning_rate": 0.004778391041639876,
      "loss": 2.3217,
      "step": 592520
    },
    {
      "epoch": 952.64,
      "learning_rate": 0.004775175610771707,
      "loss": 2.3074,
      "step": 592540
    },
    {
      "epoch": 952.67,
      "learning_rate": 0.004771960179903539,
      "loss": 2.31,
      "step": 592560
    },
    {
      "epoch": 952.7,
      "learning_rate": 0.004768744749035369,
      "loss": 2.3118,
      "step": 592580
    },
    {
      "epoch": 952.73,
      "learning_rate": 0.0047655293181672,
      "loss": 2.3017,
      "step": 592600
    },
    {
      "epoch": 952.77,
      "learning_rate": 0.004762313887299031,
      "loss": 2.3053,
      "step": 592620
    },
    {
      "epoch": 952.8,
      "learning_rate": 0.004759098456430873,
      "loss": 2.3204,
      "step": 592640
    },
    {
      "epoch": 952.83,
      "learning_rate": 0.004755883025562704,
      "loss": 2.3096,
      "step": 592660
    },
    {
      "epoch": 952.86,
      "learning_rate": 0.004752667594694534,
      "loss": 2.3214,
      "step": 592680
    },
    {
      "epoch": 952.89,
      "learning_rate": 0.004749452163826365,
      "loss": 2.3081,
      "step": 592700
    },
    {
      "epoch": 952.93,
      "learning_rate": 0.004746236732958196,
      "loss": 2.3178,
      "step": 592720
    },
    {
      "epoch": 952.96,
      "learning_rate": 0.004743021302090038,
      "loss": 2.3123,
      "step": 592740
    },
    {
      "epoch": 952.99,
      "learning_rate": 0.004739805871221869,
      "loss": 2.3028,
      "step": 592760
    },
    {
      "epoch": 953.0,
      "eval_accuracy": {
        "accuracy": 0.4824690974111793
      },
      "eval_loss": 2.422375440597534,
      "eval_runtime": 3.2618,
      "eval_samples_per_second": 3943.544,
      "eval_steps_per_second": 61.623,
      "step": 592766
    },
    {
      "epoch": 953.02,
      "learning_rate": 0.004736590440353699,
      "loss": 2.3099,
      "step": 592780
    },
    {
      "epoch": 953.05,
      "learning_rate": 0.00473337500948553,
      "loss": 2.327,
      "step": 592800
    },
    {
      "epoch": 953.09,
      "learning_rate": 0.004730159578617361,
      "loss": 2.3065,
      "step": 592820
    },
    {
      "epoch": 953.12,
      "learning_rate": 0.0047269441477491925,
      "loss": 2.3102,
      "step": 592840
    },
    {
      "epoch": 953.15,
      "learning_rate": 0.004723728716881034,
      "loss": 2.3042,
      "step": 592860
    },
    {
      "epoch": 953.18,
      "learning_rate": 0.004720513286012865,
      "loss": 2.3153,
      "step": 592880
    },
    {
      "epoch": 953.22,
      "learning_rate": 0.004717297855144696,
      "loss": 2.3011,
      "step": 592900
    },
    {
      "epoch": 953.25,
      "learning_rate": 0.004714082424276527,
      "loss": 2.3019,
      "step": 592920
    },
    {
      "epoch": 953.28,
      "learning_rate": 0.0047108669934083575,
      "loss": 2.299,
      "step": 592940
    },
    {
      "epoch": 953.31,
      "learning_rate": 0.004707651562540188,
      "loss": 2.3202,
      "step": 592960
    },
    {
      "epoch": 953.34,
      "learning_rate": 0.00470443613167203,
      "loss": 2.3155,
      "step": 592980
    },
    {
      "epoch": 953.38,
      "learning_rate": 0.004701220700803861,
      "loss": 2.3188,
      "step": 593000
    },
    {
      "epoch": 953.41,
      "learning_rate": 0.004698005269935692,
      "loss": 2.306,
      "step": 593020
    },
    {
      "epoch": 953.44,
      "learning_rate": 0.0046947898390675225,
      "loss": 2.2987,
      "step": 593040
    },
    {
      "epoch": 953.47,
      "learning_rate": 0.004691574408199353,
      "loss": 2.33,
      "step": 593060
    },
    {
      "epoch": 953.5,
      "learning_rate": 0.004688358977331195,
      "loss": 2.3072,
      "step": 593080
    },
    {
      "epoch": 953.54,
      "learning_rate": 0.004685143546463026,
      "loss": 2.3084,
      "step": 593100
    },
    {
      "epoch": 953.57,
      "learning_rate": 0.004681928115594857,
      "loss": 2.2905,
      "step": 593120
    },
    {
      "epoch": 953.6,
      "learning_rate": 0.004678712684726688,
      "loss": 2.3042,
      "step": 593140
    },
    {
      "epoch": 953.63,
      "learning_rate": 0.004675497253858519,
      "loss": 2.3047,
      "step": 593160
    },
    {
      "epoch": 953.67,
      "learning_rate": 0.00467228182299035,
      "loss": 2.316,
      "step": 593180
    },
    {
      "epoch": 953.7,
      "learning_rate": 0.004669066392122192,
      "loss": 2.3096,
      "step": 593200
    },
    {
      "epoch": 953.73,
      "learning_rate": 0.004665850961254023,
      "loss": 2.3047,
      "step": 593220
    },
    {
      "epoch": 953.76,
      "learning_rate": 0.004662635530385853,
      "loss": 2.2949,
      "step": 593240
    },
    {
      "epoch": 953.79,
      "learning_rate": 0.004659420099517684,
      "loss": 2.3158,
      "step": 593260
    },
    {
      "epoch": 953.83,
      "learning_rate": 0.004656204668649515,
      "loss": 2.2976,
      "step": 593280
    },
    {
      "epoch": 953.86,
      "learning_rate": 0.0046529892377813456,
      "loss": 2.3023,
      "step": 593300
    },
    {
      "epoch": 953.89,
      "learning_rate": 0.004649773806913188,
      "loss": 2.3119,
      "step": 593320
    },
    {
      "epoch": 953.92,
      "learning_rate": 0.004646558376045018,
      "loss": 2.3125,
      "step": 593340
    },
    {
      "epoch": 953.95,
      "learning_rate": 0.004643342945176849,
      "loss": 2.3266,
      "step": 593360
    },
    {
      "epoch": 953.99,
      "learning_rate": 0.00464012751430868,
      "loss": 2.3011,
      "step": 593380
    },
    {
      "epoch": 954.0,
      "eval_accuracy": {
        "accuracy": 0.4827023244966182
      },
      "eval_loss": 2.422279119491577,
      "eval_runtime": 3.1642,
      "eval_samples_per_second": 4065.227,
      "eval_steps_per_second": 63.524,
      "step": 593388
    },
    {
      "epoch": 954.02,
      "learning_rate": 0.0046369120834405106,
      "loss": 2.3085,
      "step": 593400
    },
    {
      "epoch": 954.05,
      "learning_rate": 0.004633696652572353,
      "loss": 2.3295,
      "step": 593420
    },
    {
      "epoch": 954.08,
      "learning_rate": 0.004630481221704183,
      "loss": 2.316,
      "step": 593440
    },
    {
      "epoch": 954.12,
      "learning_rate": 0.004627265790836015,
      "loss": 2.3167,
      "step": 593460
    },
    {
      "epoch": 954.15,
      "learning_rate": 0.004624050359967846,
      "loss": 2.2882,
      "step": 593480
    },
    {
      "epoch": 954.18,
      "learning_rate": 0.004620834929099676,
      "loss": 2.3074,
      "step": 593500
    },
    {
      "epoch": 954.21,
      "learning_rate": 0.004617619498231507,
      "loss": 2.2997,
      "step": 593520
    },
    {
      "epoch": 954.24,
      "learning_rate": 0.004614404067363349,
      "loss": 2.3035,
      "step": 593540
    },
    {
      "epoch": 954.28,
      "learning_rate": 0.00461118863649518,
      "loss": 2.3096,
      "step": 593560
    },
    {
      "epoch": 954.31,
      "learning_rate": 0.004608133977170422,
      "loss": 2.3091,
      "step": 593580
    },
    {
      "epoch": 954.34,
      "learning_rate": 0.004604918546302253,
      "loss": 2.2971,
      "step": 593600
    },
    {
      "epoch": 954.37,
      "learning_rate": 0.004601703115434084,
      "loss": 2.3185,
      "step": 593620
    },
    {
      "epoch": 954.41,
      "learning_rate": 0.004598487684565914,
      "loss": 2.3074,
      "step": 593640
    },
    {
      "epoch": 954.44,
      "learning_rate": 0.004595272253697745,
      "loss": 2.2919,
      "step": 593660
    },
    {
      "epoch": 954.47,
      "learning_rate": 0.004592056822829587,
      "loss": 2.3013,
      "step": 593680
    },
    {
      "epoch": 954.5,
      "learning_rate": 0.004588841391961418,
      "loss": 2.3088,
      "step": 593700
    },
    {
      "epoch": 954.53,
      "learning_rate": 0.004585625961093249,
      "loss": 2.3081,
      "step": 593720
    },
    {
      "epoch": 954.57,
      "learning_rate": 0.004582410530225079,
      "loss": 2.3204,
      "step": 593740
    },
    {
      "epoch": 954.6,
      "learning_rate": 0.00457919509935691,
      "loss": 2.3166,
      "step": 593760
    },
    {
      "epoch": 954.63,
      "learning_rate": 0.004575979668488741,
      "loss": 2.2998,
      "step": 593780
    },
    {
      "epoch": 954.66,
      "learning_rate": 0.004572764237620583,
      "loss": 2.3008,
      "step": 593800
    },
    {
      "epoch": 954.69,
      "learning_rate": 0.004569548806752414,
      "loss": 2.3226,
      "step": 593820
    },
    {
      "epoch": 954.73,
      "learning_rate": 0.004566333375884245,
      "loss": 2.2873,
      "step": 593840
    },
    {
      "epoch": 954.76,
      "learning_rate": 0.004563117945016076,
      "loss": 2.306,
      "step": 593860
    },
    {
      "epoch": 954.79,
      "learning_rate": 0.004559902514147907,
      "loss": 2.3142,
      "step": 593880
    },
    {
      "epoch": 954.82,
      "learning_rate": 0.004556687083279749,
      "loss": 2.2908,
      "step": 593900
    },
    {
      "epoch": 954.86,
      "learning_rate": 0.0045534716524115795,
      "loss": 2.3138,
      "step": 593920
    },
    {
      "epoch": 954.89,
      "learning_rate": 0.00455025622154341,
      "loss": 2.3154,
      "step": 593940
    },
    {
      "epoch": 954.92,
      "learning_rate": 0.004547040790675241,
      "loss": 2.3072,
      "step": 593960
    },
    {
      "epoch": 954.95,
      "learning_rate": 0.004543825359807072,
      "loss": 2.2982,
      "step": 593980
    },
    {
      "epoch": 954.98,
      "learning_rate": 0.0045406099289389025,
      "loss": 2.3126,
      "step": 594000
    },
    {
      "epoch": 955.0,
      "eval_accuracy": {
        "accuracy": 0.4808365078131074
      },
      "eval_loss": 2.4286844730377197,
      "eval_runtime": 3.7208,
      "eval_samples_per_second": 3457.072,
      "eval_steps_per_second": 54.021,
      "step": 594010
    },
    {
      "epoch": 955.02,
      "learning_rate": 0.0045373944980707445,
      "loss": 2.3159,
      "step": 594020
    },
    {
      "epoch": 955.05,
      "learning_rate": 0.004534179067202575,
      "loss": 2.3022,
      "step": 594040
    },
    {
      "epoch": 955.08,
      "learning_rate": 0.004530963636334406,
      "loss": 2.2945,
      "step": 594060
    },
    {
      "epoch": 955.11,
      "learning_rate": 0.004527748205466237,
      "loss": 2.3168,
      "step": 594080
    },
    {
      "epoch": 955.14,
      "learning_rate": 0.0045245327745980675,
      "loss": 2.3058,
      "step": 594100
    },
    {
      "epoch": 955.18,
      "learning_rate": 0.004521317343729899,
      "loss": 2.3038,
      "step": 594120
    },
    {
      "epoch": 955.21,
      "learning_rate": 0.00451810191286174,
      "loss": 2.2929,
      "step": 594140
    },
    {
      "epoch": 955.24,
      "learning_rate": 0.004514886481993572,
      "loss": 2.3192,
      "step": 594160
    },
    {
      "epoch": 955.27,
      "learning_rate": 0.004511671051125403,
      "loss": 2.3116,
      "step": 594180
    },
    {
      "epoch": 955.31,
      "learning_rate": 0.004508455620257233,
      "loss": 2.326,
      "step": 594200
    },
    {
      "epoch": 955.34,
      "learning_rate": 0.004505240189389064,
      "loss": 2.3025,
      "step": 594220
    },
    {
      "epoch": 955.37,
      "learning_rate": 0.004502024758520906,
      "loss": 2.2962,
      "step": 594240
    },
    {
      "epoch": 955.4,
      "learning_rate": 0.004498809327652737,
      "loss": 2.3128,
      "step": 594260
    },
    {
      "epoch": 955.43,
      "learning_rate": 0.004495593896784568,
      "loss": 2.3255,
      "step": 594280
    },
    {
      "epoch": 955.47,
      "learning_rate": 0.004492378465916398,
      "loss": 2.3095,
      "step": 594300
    },
    {
      "epoch": 955.5,
      "learning_rate": 0.004489163035048229,
      "loss": 2.3082,
      "step": 594320
    },
    {
      "epoch": 955.53,
      "learning_rate": 0.00448594760418006,
      "loss": 2.3047,
      "step": 594340
    },
    {
      "epoch": 955.56,
      "learning_rate": 0.004482732173311902,
      "loss": 2.307,
      "step": 594360
    },
    {
      "epoch": 955.59,
      "learning_rate": 0.004479516742443733,
      "loss": 2.3182,
      "step": 594380
    },
    {
      "epoch": 955.63,
      "learning_rate": 0.004476301311575563,
      "loss": 2.308,
      "step": 594400
    },
    {
      "epoch": 955.66,
      "learning_rate": 0.004473085880707394,
      "loss": 2.3066,
      "step": 594420
    },
    {
      "epoch": 955.69,
      "learning_rate": 0.004469870449839226,
      "loss": 2.298,
      "step": 594440
    },
    {
      "epoch": 955.72,
      "learning_rate": 0.004466655018971056,
      "loss": 2.2978,
      "step": 594460
    },
    {
      "epoch": 955.76,
      "learning_rate": 0.0044634395881028984,
      "loss": 2.3019,
      "step": 594480
    },
    {
      "epoch": 955.79,
      "learning_rate": 0.004460224157234729,
      "loss": 2.3123,
      "step": 594500
    },
    {
      "epoch": 955.82,
      "learning_rate": 0.00445700872636656,
      "loss": 2.3165,
      "step": 594520
    },
    {
      "epoch": 955.85,
      "learning_rate": 0.004453793295498391,
      "loss": 2.314,
      "step": 594540
    },
    {
      "epoch": 955.88,
      "learning_rate": 0.004450577864630221,
      "loss": 2.2935,
      "step": 594560
    },
    {
      "epoch": 955.92,
      "learning_rate": 0.0044473624337620634,
      "loss": 2.3138,
      "step": 594580
    },
    {
      "epoch": 955.95,
      "learning_rate": 0.004444147002893894,
      "loss": 2.2984,
      "step": 594600
    },
    {
      "epoch": 955.98,
      "learning_rate": 0.004440931572025725,
      "loss": 2.2909,
      "step": 594620
    },
    {
      "epoch": 956.0,
      "eval_accuracy": {
        "accuracy": 0.48301329394387
      },
      "eval_loss": 2.4179017543792725,
      "eval_runtime": 4.3057,
      "eval_samples_per_second": 2987.442,
      "eval_steps_per_second": 46.682,
      "step": 594632
    },
    {
      "epoch": 956.01,
      "learning_rate": 0.004437716141157556,
      "loss": 2.3082,
      "step": 594640
    },
    {
      "epoch": 956.05,
      "learning_rate": 0.004434500710289386,
      "loss": 2.3169,
      "step": 594660
    },
    {
      "epoch": 956.08,
      "learning_rate": 0.004431285279421217,
      "loss": 2.3124,
      "step": 594680
    },
    {
      "epoch": 956.11,
      "learning_rate": 0.004428069848553059,
      "loss": 2.3213,
      "step": 594700
    },
    {
      "epoch": 956.14,
      "learning_rate": 0.00442485441768489,
      "loss": 2.3006,
      "step": 594720
    },
    {
      "epoch": 956.17,
      "learning_rate": 0.004421638986816721,
      "loss": 2.3082,
      "step": 594740
    },
    {
      "epoch": 956.21,
      "learning_rate": 0.004418423555948552,
      "loss": 2.2999,
      "step": 594760
    },
    {
      "epoch": 956.24,
      "learning_rate": 0.004415208125080383,
      "loss": 2.3085,
      "step": 594780
    },
    {
      "epoch": 956.27,
      "learning_rate": 0.004411992694212214,
      "loss": 2.2948,
      "step": 594800
    },
    {
      "epoch": 956.3,
      "learning_rate": 0.004408777263344056,
      "loss": 2.2898,
      "step": 594820
    },
    {
      "epoch": 956.33,
      "learning_rate": 0.0044055618324758865,
      "loss": 2.3162,
      "step": 594840
    },
    {
      "epoch": 956.37,
      "learning_rate": 0.004402346401607717,
      "loss": 2.3016,
      "step": 594860
    },
    {
      "epoch": 956.4,
      "learning_rate": 0.004399130970739548,
      "loss": 2.2914,
      "step": 594880
    },
    {
      "epoch": 956.43,
      "learning_rate": 0.004395915539871379,
      "loss": 2.3056,
      "step": 594900
    },
    {
      "epoch": 956.46,
      "learning_rate": 0.004392700109003221,
      "loss": 2.2912,
      "step": 594920
    },
    {
      "epoch": 956.5,
      "learning_rate": 0.0043894846781350515,
      "loss": 2.2802,
      "step": 594940
    },
    {
      "epoch": 956.53,
      "learning_rate": 0.004386269247266882,
      "loss": 2.3175,
      "step": 594960
    },
    {
      "epoch": 956.56,
      "learning_rate": 0.004383053816398713,
      "loss": 2.2978,
      "step": 594980
    },
    {
      "epoch": 956.59,
      "learning_rate": 0.004379838385530544,
      "loss": 2.3036,
      "step": 595000
    },
    {
      "epoch": 956.62,
      "learning_rate": 0.004376622954662375,
      "loss": 2.2888,
      "step": 595020
    },
    {
      "epoch": 956.66,
      "learning_rate": 0.0043734075237942165,
      "loss": 2.3018,
      "step": 595040
    },
    {
      "epoch": 956.69,
      "learning_rate": 0.004370192092926048,
      "loss": 2.3196,
      "step": 595060
    },
    {
      "epoch": 956.72,
      "learning_rate": 0.004366976662057879,
      "loss": 2.3124,
      "step": 595080
    },
    {
      "epoch": 956.75,
      "learning_rate": 0.00436376123118971,
      "loss": 2.3337,
      "step": 595100
    },
    {
      "epoch": 956.78,
      "learning_rate": 0.00436054580032154,
      "loss": 2.306,
      "step": 595120
    },
    {
      "epoch": 956.82,
      "learning_rate": 0.004357330369453382,
      "loss": 2.3177,
      "step": 595140
    },
    {
      "epoch": 956.85,
      "learning_rate": 0.004354114938585213,
      "loss": 2.3068,
      "step": 595160
    },
    {
      "epoch": 956.88,
      "learning_rate": 0.004350899507717044,
      "loss": 2.3132,
      "step": 595180
    },
    {
      "epoch": 956.91,
      "learning_rate": 0.004347684076848875,
      "loss": 2.2966,
      "step": 595200
    },
    {
      "epoch": 956.95,
      "learning_rate": 0.004344468645980705,
      "loss": 2.3011,
      "step": 595220
    },
    {
      "epoch": 956.98,
      "learning_rate": 0.004341253215112536,
      "loss": 2.3026,
      "step": 595240
    },
    {
      "epoch": 957.0,
      "eval_accuracy": {
        "accuracy": 0.48487911062738087
      },
      "eval_loss": 2.4236419200897217,
      "eval_runtime": 3.3837,
      "eval_samples_per_second": 3801.41,
      "eval_steps_per_second": 59.402,
      "step": 595254
    },
    {
      "epoch": 957.01,
      "learning_rate": 0.004338037784244378,
      "loss": 2.3127,
      "step": 595260
    },
    {
      "epoch": 957.04,
      "learning_rate": 0.004334822353376209,
      "loss": 2.3241,
      "step": 595280
    },
    {
      "epoch": 957.07,
      "learning_rate": 0.00433160692250804,
      "loss": 2.2959,
      "step": 595300
    },
    {
      "epoch": 957.11,
      "learning_rate": 0.00432839149163987,
      "loss": 2.318,
      "step": 595320
    },
    {
      "epoch": 957.14,
      "learning_rate": 0.004325176060771702,
      "loss": 2.3116,
      "step": 595340
    },
    {
      "epoch": 957.17,
      "learning_rate": 0.004321960629903533,
      "loss": 2.2861,
      "step": 595360
    },
    {
      "epoch": 957.2,
      "learning_rate": 0.004318745199035375,
      "loss": 2.2958,
      "step": 595380
    },
    {
      "epoch": 957.23,
      "learning_rate": 0.004315529768167205,
      "loss": 2.3066,
      "step": 595400
    },
    {
      "epoch": 957.27,
      "learning_rate": 0.004312314337299036,
      "loss": 2.3247,
      "step": 595420
    },
    {
      "epoch": 957.3,
      "learning_rate": 0.004309098906430867,
      "loss": 2.2996,
      "step": 595440
    },
    {
      "epoch": 957.33,
      "learning_rate": 0.004305883475562698,
      "loss": 2.3002,
      "step": 595460
    },
    {
      "epoch": 957.36,
      "learning_rate": 0.00430266804469454,
      "loss": 2.3153,
      "step": 595480
    },
    {
      "epoch": 957.4,
      "learning_rate": 0.00429945261382637,
      "loss": 2.2979,
      "step": 595500
    },
    {
      "epoch": 957.43,
      "learning_rate": 0.004296237182958201,
      "loss": 2.3085,
      "step": 595520
    },
    {
      "epoch": 957.46,
      "learning_rate": 0.004293021752090032,
      "loss": 2.3102,
      "step": 595540
    },
    {
      "epoch": 957.49,
      "learning_rate": 0.004289806321221863,
      "loss": 2.3082,
      "step": 595560
    },
    {
      "epoch": 957.52,
      "learning_rate": 0.004286590890353693,
      "loss": 2.314,
      "step": 595580
    },
    {
      "epoch": 957.56,
      "learning_rate": 0.004283375459485535,
      "loss": 2.2933,
      "step": 595600
    },
    {
      "epoch": 957.59,
      "learning_rate": 0.004280160028617366,
      "loss": 2.3101,
      "step": 595620
    },
    {
      "epoch": 957.62,
      "learning_rate": 0.004276944597749197,
      "loss": 2.3057,
      "step": 595640
    },
    {
      "epoch": 957.65,
      "learning_rate": 0.0042737291668810285,
      "loss": 2.3016,
      "step": 595660
    },
    {
      "epoch": 957.68,
      "learning_rate": 0.004270513736012859,
      "loss": 2.2936,
      "step": 595680
    },
    {
      "epoch": 957.72,
      "learning_rate": 0.00426729830514469,
      "loss": 2.3136,
      "step": 595700
    },
    {
      "epoch": 957.75,
      "learning_rate": 0.004264082874276532,
      "loss": 2.3153,
      "step": 595720
    },
    {
      "epoch": 957.78,
      "learning_rate": 0.004260867443408363,
      "loss": 2.3022,
      "step": 595740
    },
    {
      "epoch": 957.81,
      "learning_rate": 0.0042576520125401935,
      "loss": 2.3003,
      "step": 595760
    },
    {
      "epoch": 957.85,
      "learning_rate": 0.004254436581672024,
      "loss": 2.3042,
      "step": 595780
    },
    {
      "epoch": 957.88,
      "learning_rate": 0.004251221150803855,
      "loss": 2.2873,
      "step": 595800
    },
    {
      "epoch": 957.91,
      "learning_rate": 0.004248005719935697,
      "loss": 2.2954,
      "step": 595820
    },
    {
      "epoch": 957.94,
      "learning_rate": 0.004244790289067528,
      "loss": 2.3056,
      "step": 595840
    },
    {
      "epoch": 957.97,
      "learning_rate": 0.0042415748581993585,
      "loss": 2.3028,
      "step": 595860
    },
    {
      "epoch": 958.0,
      "eval_accuracy": {
        "accuracy": 0.4851123377128197
      },
      "eval_loss": 2.4253387451171875,
      "eval_runtime": 3.4195,
      "eval_samples_per_second": 3761.642,
      "eval_steps_per_second": 58.78,
      "step": 595876
    },
    {
      "epoch": 958.01,
      "learning_rate": 0.004238359427331189,
      "loss": 2.296,
      "step": 595880
    },
    {
      "epoch": 958.04,
      "learning_rate": 0.00423514399646302,
      "loss": 2.3149,
      "step": 595900
    },
    {
      "epoch": 958.07,
      "learning_rate": 0.004231928565594851,
      "loss": 2.2867,
      "step": 595920
    },
    {
      "epoch": 958.1,
      "learning_rate": 0.004228713134726693,
      "loss": 2.3168,
      "step": 595940
    },
    {
      "epoch": 958.14,
      "learning_rate": 0.0042254977038585235,
      "loss": 2.2903,
      "step": 595960
    },
    {
      "epoch": 958.17,
      "learning_rate": 0.004222282272990355,
      "loss": 2.2926,
      "step": 595980
    },
    {
      "epoch": 958.2,
      "learning_rate": 0.004219066842122186,
      "loss": 2.304,
      "step": 596000
    },
    {
      "epoch": 958.23,
      "learning_rate": 0.004215851411254017,
      "loss": 2.3012,
      "step": 596020
    },
    {
      "epoch": 958.26,
      "learning_rate": 0.004212635980385847,
      "loss": 2.2983,
      "step": 596040
    },
    {
      "epoch": 958.3,
      "learning_rate": 0.004209420549517689,
      "loss": 2.3034,
      "step": 596060
    },
    {
      "epoch": 958.33,
      "learning_rate": 0.00420620511864952,
      "loss": 2.3086,
      "step": 596080
    },
    {
      "epoch": 958.36,
      "learning_rate": 0.004202989687781351,
      "loss": 2.3131,
      "step": 596100
    },
    {
      "epoch": 958.39,
      "learning_rate": 0.004199774256913182,
      "loss": 2.3057,
      "step": 596120
    },
    {
      "epoch": 958.42,
      "learning_rate": 0.004196558826045012,
      "loss": 2.3056,
      "step": 596140
    },
    {
      "epoch": 958.46,
      "learning_rate": 0.004193343395176854,
      "loss": 2.3252,
      "step": 596160
    },
    {
      "epoch": 958.49,
      "learning_rate": 0.004190127964308685,
      "loss": 2.2816,
      "step": 596180
    },
    {
      "epoch": 958.52,
      "learning_rate": 0.004186912533440516,
      "loss": 2.3216,
      "step": 596200
    },
    {
      "epoch": 958.55,
      "learning_rate": 0.0041836971025723466,
      "loss": 2.3138,
      "step": 596220
    },
    {
      "epoch": 958.59,
      "learning_rate": 0.004180481671704178,
      "loss": 2.2946,
      "step": 596240
    },
    {
      "epoch": 958.62,
      "learning_rate": 0.004177266240836009,
      "loss": 2.3071,
      "step": 596260
    },
    {
      "epoch": 958.65,
      "learning_rate": 0.004174050809967851,
      "loss": 2.3062,
      "step": 596280
    },
    {
      "epoch": 958.68,
      "learning_rate": 0.004170835379099682,
      "loss": 2.3154,
      "step": 596300
    },
    {
      "epoch": 958.71,
      "learning_rate": 0.004167619948231512,
      "loss": 2.3266,
      "step": 596320
    },
    {
      "epoch": 958.75,
      "learning_rate": 0.004164404517363343,
      "loss": 2.2837,
      "step": 596340
    },
    {
      "epoch": 958.78,
      "learning_rate": 0.004161189086495174,
      "loss": 2.2933,
      "step": 596360
    },
    {
      "epoch": 958.81,
      "learning_rate": 0.004157973655627005,
      "loss": 2.2954,
      "step": 596380
    },
    {
      "epoch": 958.84,
      "learning_rate": 0.004154758224758847,
      "loss": 2.298,
      "step": 596400
    },
    {
      "epoch": 958.87,
      "learning_rate": 0.004151542793890677,
      "loss": 2.309,
      "step": 596420
    },
    {
      "epoch": 958.91,
      "learning_rate": 0.004148327363022508,
      "loss": 2.3009,
      "step": 596440
    },
    {
      "epoch": 958.94,
      "learning_rate": 0.004145111932154339,
      "loss": 2.2897,
      "step": 596460
    },
    {
      "epoch": 958.97,
      "learning_rate": 0.00414189650128617,
      "loss": 2.3046,
      "step": 596480
    },
    {
      "epoch": 959.0,
      "eval_accuracy": {
        "accuracy": 0.48495685298919383
      },
      "eval_loss": 2.4222254753112793,
      "eval_runtime": 3.0829,
      "eval_samples_per_second": 4172.343,
      "eval_steps_per_second": 65.198,
      "step": 596498
    },
    {
      "epoch": 959.0,
      "learning_rate": 0.004138681070418012,
      "loss": 2.3009,
      "step": 596500
    },
    {
      "epoch": 959.04,
      "learning_rate": 0.004135465639549842,
      "loss": 2.3064,
      "step": 596520
    },
    {
      "epoch": 959.07,
      "learning_rate": 0.004132250208681673,
      "loss": 2.3312,
      "step": 596540
    },
    {
      "epoch": 959.1,
      "learning_rate": 0.004129034777813505,
      "loss": 2.3117,
      "step": 596560
    },
    {
      "epoch": 959.13,
      "learning_rate": 0.0041258193469453355,
      "loss": 2.2964,
      "step": 596580
    },
    {
      "epoch": 959.16,
      "learning_rate": 0.004122603916077166,
      "loss": 2.3119,
      "step": 596600
    },
    {
      "epoch": 959.2,
      "learning_rate": 0.004119388485209008,
      "loss": 2.2981,
      "step": 596620
    },
    {
      "epoch": 959.23,
      "learning_rate": 0.004116173054340839,
      "loss": 2.3077,
      "step": 596640
    },
    {
      "epoch": 959.26,
      "learning_rate": 0.00411295762347267,
      "loss": 2.2987,
      "step": 596660
    },
    {
      "epoch": 959.29,
      "learning_rate": 0.0041097421926045005,
      "loss": 2.2997,
      "step": 596680
    },
    {
      "epoch": 959.32,
      "learning_rate": 0.004106526761736331,
      "loss": 2.3056,
      "step": 596700
    },
    {
      "epoch": 959.36,
      "learning_rate": 0.004103311330868162,
      "loss": 2.306,
      "step": 596720
    },
    {
      "epoch": 959.39,
      "learning_rate": 0.004100095900000004,
      "loss": 2.2946,
      "step": 596740
    },
    {
      "epoch": 959.42,
      "learning_rate": 0.004096880469131835,
      "loss": 2.294,
      "step": 596760
    },
    {
      "epoch": 959.45,
      "learning_rate": 0.0040936650382636655,
      "loss": 2.2996,
      "step": 596780
    },
    {
      "epoch": 959.49,
      "learning_rate": 0.004090449607395496,
      "loss": 2.2927,
      "step": 596800
    },
    {
      "epoch": 959.52,
      "learning_rate": 0.004087234176527327,
      "loss": 2.3054,
      "step": 596820
    },
    {
      "epoch": 959.55,
      "learning_rate": 0.004084018745659169,
      "loss": 2.3047,
      "step": 596840
    },
    {
      "epoch": 959.58,
      "learning_rate": 0.004080803314791,
      "loss": 2.3063,
      "step": 596860
    },
    {
      "epoch": 959.61,
      "learning_rate": 0.004077587883922831,
      "loss": 2.3108,
      "step": 596880
    },
    {
      "epoch": 959.65,
      "learning_rate": 0.004074372453054662,
      "loss": 2.2976,
      "step": 596900
    },
    {
      "epoch": 959.68,
      "learning_rate": 0.004071157022186493,
      "loss": 2.3097,
      "step": 596920
    },
    {
      "epoch": 959.71,
      "learning_rate": 0.0040679415913183236,
      "loss": 2.3111,
      "step": 596940
    },
    {
      "epoch": 959.74,
      "learning_rate": 0.004064726160450166,
      "loss": 2.2841,
      "step": 596960
    },
    {
      "epoch": 959.77,
      "learning_rate": 0.004061510729581996,
      "loss": 2.3215,
      "step": 596980
    },
    {
      "epoch": 959.81,
      "learning_rate": 0.004058295298713827,
      "loss": 2.2825,
      "step": 597000
    },
    {
      "epoch": 959.84,
      "learning_rate": 0.004055079867845658,
      "loss": 2.3017,
      "step": 597020
    },
    {
      "epoch": 959.87,
      "learning_rate": 0.0040518644369774886,
      "loss": 2.2986,
      "step": 597040
    },
    {
      "epoch": 959.9,
      "learning_rate": 0.004048649006109331,
      "loss": 2.3063,
      "step": 597060
    },
    {
      "epoch": 959.94,
      "learning_rate": 0.004045433575241161,
      "loss": 2.2939,
      "step": 597080
    },
    {
      "epoch": 959.97,
      "learning_rate": 0.004042218144372992,
      "loss": 2.2957,
      "step": 597100
    },
    {
      "epoch": 960.0,
      "learning_rate": 0.004039002713504823,
      "loss": 2.3195,
      "step": 597120
    },
    {
      "epoch": 960.0,
      "eval_accuracy": {
        "accuracy": 0.4853455647982586
      },
      "eval_loss": 2.4161922931671143,
      "eval_runtime": 3.3917,
      "eval_samples_per_second": 3792.471,
      "eval_steps_per_second": 59.262,
      "step": 597120
    },
    {
      "epoch": 960.03,
      "learning_rate": 0.0040357872826366535,
      "loss": 2.2895,
      "step": 597140
    },
    {
      "epoch": 960.06,
      "learning_rate": 0.004032571851768485,
      "loss": 2.2923,
      "step": 597160
    },
    {
      "epoch": 960.1,
      "learning_rate": 0.004029356420900326,
      "loss": 2.2897,
      "step": 597180
    },
    {
      "epoch": 960.13,
      "learning_rate": 0.004026140990032158,
      "loss": 2.2997,
      "step": 597200
    },
    {
      "epoch": 960.16,
      "learning_rate": 0.004022925559163989,
      "loss": 2.312,
      "step": 597220
    },
    {
      "epoch": 960.19,
      "learning_rate": 0.004019710128295819,
      "loss": 2.2934,
      "step": 597240
    },
    {
      "epoch": 960.23,
      "learning_rate": 0.00401649469742765,
      "loss": 2.2967,
      "step": 597260
    },
    {
      "epoch": 960.26,
      "learning_rate": 0.004013279266559481,
      "loss": 2.309,
      "step": 597280
    },
    {
      "epoch": 960.29,
      "learning_rate": 0.004010063835691323,
      "loss": 2.2936,
      "step": 597300
    },
    {
      "epoch": 960.32,
      "learning_rate": 0.004006848404823154,
      "loss": 2.2999,
      "step": 597320
    },
    {
      "epoch": 960.35,
      "learning_rate": 0.004003632973954984,
      "loss": 2.3258,
      "step": 597340
    },
    {
      "epoch": 960.39,
      "learning_rate": 0.004000417543086815,
      "loss": 2.3176,
      "step": 597360
    },
    {
      "epoch": 960.42,
      "learning_rate": 0.003997202112218646,
      "loss": 2.3053,
      "step": 597380
    },
    {
      "epoch": 960.45,
      "learning_rate": 0.003993986681350488,
      "loss": 2.2918,
      "step": 597400
    },
    {
      "epoch": 960.48,
      "learning_rate": 0.003990771250482319,
      "loss": 2.3005,
      "step": 597420
    },
    {
      "epoch": 960.51,
      "learning_rate": 0.003987555819614149,
      "loss": 2.2975,
      "step": 597440
    },
    {
      "epoch": 960.55,
      "learning_rate": 0.00398434038874598,
      "loss": 2.2936,
      "step": 597460
    },
    {
      "epoch": 960.58,
      "learning_rate": 0.003981124957877812,
      "loss": 2.2871,
      "step": 597480
    },
    {
      "epoch": 960.61,
      "learning_rate": 0.0039779095270096425,
      "loss": 2.309,
      "step": 597500
    },
    {
      "epoch": 960.64,
      "learning_rate": 0.0039746940961414845,
      "loss": 2.297,
      "step": 597520
    },
    {
      "epoch": 960.68,
      "learning_rate": 0.003971478665273315,
      "loss": 2.3109,
      "step": 597540
    },
    {
      "epoch": 960.71,
      "learning_rate": 0.003968263234405146,
      "loss": 2.298,
      "step": 597560
    },
    {
      "epoch": 960.74,
      "learning_rate": 0.003965208575080388,
      "loss": 2.3078,
      "step": 597580
    },
    {
      "epoch": 960.77,
      "learning_rate": 0.003961993144212219,
      "loss": 2.314,
      "step": 597600
    },
    {
      "epoch": 960.8,
      "learning_rate": 0.00395877771334405,
      "loss": 2.2903,
      "step": 597620
    },
    {
      "epoch": 960.84,
      "learning_rate": 0.0039555622824758805,
      "loss": 2.3099,
      "step": 597640
    },
    {
      "epoch": 960.87,
      "learning_rate": 0.0039523468516077225,
      "loss": 2.3027,
      "step": 597660
    },
    {
      "epoch": 960.9,
      "learning_rate": 0.003949131420739553,
      "loss": 2.3058,
      "step": 597680
    },
    {
      "epoch": 960.93,
      "learning_rate": 0.003945915989871384,
      "loss": 2.2939,
      "step": 597700
    },
    {
      "epoch": 960.96,
      "learning_rate": 0.003942700559003215,
      "loss": 2.3099,
      "step": 597720
    },
    {
      "epoch": 961.0,
      "learning_rate": 0.0039394851281350455,
      "loss": 2.3171,
      "step": 597740
    },
    {
      "epoch": 961.0,
      "eval_accuracy": {
        "accuracy": 0.4873668662053953
      },
      "eval_loss": 2.4158952236175537,
      "eval_runtime": 3.2016,
      "eval_samples_per_second": 4017.626,
      "eval_steps_per_second": 62.78,
      "step": 597742
    },
    {
      "epoch": 961.03,
      "learning_rate": 0.003936269697266876,
      "loss": 2.3195,
      "step": 597760
    },
    {
      "epoch": 961.06,
      "learning_rate": 0.003933054266398718,
      "loss": 2.3123,
      "step": 597780
    },
    {
      "epoch": 961.09,
      "learning_rate": 0.003929838835530549,
      "loss": 2.3053,
      "step": 597800
    },
    {
      "epoch": 961.13,
      "learning_rate": 0.00392662340466238,
      "loss": 2.3041,
      "step": 597820
    },
    {
      "epoch": 961.16,
      "learning_rate": 0.0039234079737942105,
      "loss": 2.3244,
      "step": 597840
    },
    {
      "epoch": 961.19,
      "learning_rate": 0.003920192542926042,
      "loss": 2.2949,
      "step": 597860
    },
    {
      "epoch": 961.22,
      "learning_rate": 0.003916977112057883,
      "loss": 2.2917,
      "step": 597880
    },
    {
      "epoch": 961.25,
      "learning_rate": 0.003913761681189715,
      "loss": 2.2965,
      "step": 597900
    },
    {
      "epoch": 961.29,
      "learning_rate": 0.003910546250321546,
      "loss": 2.2965,
      "step": 597920
    },
    {
      "epoch": 961.32,
      "learning_rate": 0.003907491590996787,
      "loss": 2.283,
      "step": 597940
    },
    {
      "epoch": 961.35,
      "learning_rate": 0.0039042761601286178,
      "loss": 2.3005,
      "step": 597960
    },
    {
      "epoch": 961.38,
      "learning_rate": 0.0039010607292604485,
      "loss": 2.3229,
      "step": 597980
    },
    {
      "epoch": 961.41,
      "learning_rate": 0.003897845298392279,
      "loss": 2.2931,
      "step": 598000
    },
    {
      "epoch": 961.45,
      "learning_rate": 0.0038946298675241104,
      "loss": 2.2982,
      "step": 598020
    },
    {
      "epoch": 961.48,
      "learning_rate": 0.003891414436655952,
      "loss": 2.2978,
      "step": 598040
    },
    {
      "epoch": 961.51,
      "learning_rate": 0.0038881990057877836,
      "loss": 2.3065,
      "step": 598060
    },
    {
      "epoch": 961.54,
      "learning_rate": 0.0038849835749196135,
      "loss": 2.3078,
      "step": 598080
    },
    {
      "epoch": 961.58,
      "learning_rate": 0.0038817681440514447,
      "loss": 2.298,
      "step": 598100
    },
    {
      "epoch": 961.61,
      "learning_rate": 0.0038785527131832754,
      "loss": 2.2804,
      "step": 598120
    },
    {
      "epoch": 961.64,
      "learning_rate": 0.0038753372823151174,
      "loss": 2.3031,
      "step": 598140
    },
    {
      "epoch": 961.67,
      "learning_rate": 0.0038721218514469486,
      "loss": 2.2871,
      "step": 598160
    },
    {
      "epoch": 961.7,
      "learning_rate": 0.0038689064205787785,
      "loss": 2.308,
      "step": 598180
    },
    {
      "epoch": 961.74,
      "learning_rate": 0.00386569098971061,
      "loss": 2.3023,
      "step": 598200
    },
    {
      "epoch": 961.77,
      "learning_rate": 0.0038624755588424404,
      "loss": 2.307,
      "step": 598220
    },
    {
      "epoch": 961.8,
      "learning_rate": 0.0038592601279742716,
      "loss": 2.2919,
      "step": 598240
    },
    {
      "epoch": 961.83,
      "learning_rate": 0.0038560446971061136,
      "loss": 2.3261,
      "step": 598260
    },
    {
      "epoch": 961.86,
      "learning_rate": 0.0038528292662379443,
      "loss": 2.309,
      "step": 598280
    },
    {
      "epoch": 961.9,
      "learning_rate": 0.003849613835369775,
      "loss": 2.2827,
      "step": 598300
    },
    {
      "epoch": 961.93,
      "learning_rate": 0.0038463984045016054,
      "loss": 2.2882,
      "step": 598320
    },
    {
      "epoch": 961.96,
      "learning_rate": 0.003843182973633437,
      "loss": 2.3125,
      "step": 598340
    },
    {
      "epoch": 961.99,
      "learning_rate": 0.003839967542765268,
      "loss": 2.2915,
      "step": 598360
    },
    {
      "epoch": 962.0,
      "eval_accuracy": {
        "accuracy": 0.4791261758532224
      },
      "eval_loss": 2.4258060455322266,
      "eval_runtime": 3.164,
      "eval_samples_per_second": 4065.41,
      "eval_steps_per_second": 63.527,
      "step": 598364
    },
    {
      "epoch": 962.03,
      "learning_rate": 0.00383675211189711,
      "loss": 2.2973,
      "step": 598380
    },
    {
      "epoch": 962.06,
      "learning_rate": 0.00383353668102894,
      "loss": 2.2997,
      "step": 598400
    },
    {
      "epoch": 962.09,
      "learning_rate": 0.0038303212501607713,
      "loss": 2.307,
      "step": 598420
    },
    {
      "epoch": 962.12,
      "learning_rate": 0.003827105819292602,
      "loss": 2.2912,
      "step": 598440
    },
    {
      "epoch": 962.15,
      "learning_rate": 0.003823890388424433,
      "loss": 2.2901,
      "step": 598460
    },
    {
      "epoch": 962.19,
      "learning_rate": 0.003820674957556275,
      "loss": 2.3015,
      "step": 598480
    },
    {
      "epoch": 962.22,
      "learning_rate": 0.003817459526688106,
      "loss": 2.3075,
      "step": 598500
    },
    {
      "epoch": 962.25,
      "learning_rate": 0.0038142440958199367,
      "loss": 2.3188,
      "step": 598520
    },
    {
      "epoch": 962.28,
      "learning_rate": 0.003811028664951767,
      "loss": 2.3118,
      "step": 598540
    },
    {
      "epoch": 962.32,
      "learning_rate": 0.003807813234083598,
      "loss": 2.3014,
      "step": 598560
    },
    {
      "epoch": 962.35,
      "learning_rate": 0.003804597803215429,
      "loss": 2.2705,
      "step": 598580
    },
    {
      "epoch": 962.38,
      "learning_rate": 0.003801382372347271,
      "loss": 2.2996,
      "step": 598600
    },
    {
      "epoch": 962.41,
      "learning_rate": 0.0037981669414791017,
      "loss": 2.2952,
      "step": 598620
    },
    {
      "epoch": 962.44,
      "learning_rate": 0.003794951510610933,
      "loss": 2.3075,
      "step": 598640
    },
    {
      "epoch": 962.48,
      "learning_rate": 0.0037917360797427636,
      "loss": 2.3064,
      "step": 598660
    },
    {
      "epoch": 962.51,
      "learning_rate": 0.0037885206488745948,
      "loss": 2.3243,
      "step": 598680
    },
    {
      "epoch": 962.54,
      "learning_rate": 0.0037853052180064368,
      "loss": 2.3089,
      "step": 598700
    },
    {
      "epoch": 962.57,
      "learning_rate": 0.0037820897871382667,
      "loss": 2.2941,
      "step": 598720
    },
    {
      "epoch": 962.6,
      "learning_rate": 0.003778874356270098,
      "loss": 2.309,
      "step": 598740
    },
    {
      "epoch": 962.64,
      "learning_rate": 0.0037756589254019286,
      "loss": 2.3018,
      "step": 598760
    },
    {
      "epoch": 962.67,
      "learning_rate": 0.0037724434945337598,
      "loss": 2.2937,
      "step": 598780
    },
    {
      "epoch": 962.7,
      "learning_rate": 0.0037692280636655905,
      "loss": 2.3081,
      "step": 598800
    },
    {
      "epoch": 962.73,
      "learning_rate": 0.0037660126327974325,
      "loss": 2.3138,
      "step": 598820
    },
    {
      "epoch": 962.77,
      "learning_rate": 0.0037627972019292633,
      "loss": 2.3014,
      "step": 598840
    },
    {
      "epoch": 962.8,
      "learning_rate": 0.0037595817710610936,
      "loss": 2.3086,
      "step": 598860
    },
    {
      "epoch": 962.83,
      "learning_rate": 0.0037563663401929247,
      "loss": 2.2675,
      "step": 598880
    },
    {
      "epoch": 962.86,
      "learning_rate": 0.0037531509093247555,
      "loss": 2.2901,
      "step": 598900
    },
    {
      "epoch": 962.89,
      "learning_rate": 0.0037499354784565862,
      "loss": 2.3018,
      "step": 598920
    },
    {
      "epoch": 962.93,
      "learning_rate": 0.0037467200475884282,
      "loss": 2.2953,
      "step": 598940
    },
    {
      "epoch": 962.96,
      "learning_rate": 0.0037435046167202594,
      "loss": 2.3073,
      "step": 598960
    },
    {
      "epoch": 962.99,
      "learning_rate": 0.00374028918585209,
      "loss": 2.2796,
      "step": 598980
    },
    {
      "epoch": 963.0,
      "eval_accuracy": {
        "accuracy": 0.4872113814817694
      },
      "eval_loss": 2.4151878356933594,
      "eval_runtime": 3.2562,
      "eval_samples_per_second": 3950.335,
      "eval_steps_per_second": 61.729,
      "step": 598986
    },
    {
      "epoch": 963.02,
      "learning_rate": 0.0037370737549839213,
      "loss": 2.3277,
      "step": 599000
    },
    {
      "epoch": 963.05,
      "learning_rate": 0.0037338583241157512,
      "loss": 2.2976,
      "step": 599020
    },
    {
      "epoch": 963.09,
      "learning_rate": 0.0037306428932475932,
      "loss": 2.2898,
      "step": 599040
    },
    {
      "epoch": 963.12,
      "learning_rate": 0.0037274274623794244,
      "loss": 2.3055,
      "step": 599060
    },
    {
      "epoch": 963.15,
      "learning_rate": 0.003724212031511255,
      "loss": 2.3197,
      "step": 599080
    },
    {
      "epoch": 963.18,
      "learning_rate": 0.0037209966006430863,
      "loss": 2.2982,
      "step": 599100
    },
    {
      "epoch": 963.22,
      "learning_rate": 0.003717781169774917,
      "loss": 2.2956,
      "step": 599120
    },
    {
      "epoch": 963.25,
      "learning_rate": 0.003714565738906748,
      "loss": 2.2894,
      "step": 599140
    },
    {
      "epoch": 963.28,
      "learning_rate": 0.00371135030803859,
      "loss": 2.2948,
      "step": 599160
    },
    {
      "epoch": 963.31,
      "learning_rate": 0.00370813487717042,
      "loss": 2.2986,
      "step": 599180
    },
    {
      "epoch": 963.34,
      "learning_rate": 0.0037049194463022513,
      "loss": 2.3072,
      "step": 599200
    },
    {
      "epoch": 963.38,
      "learning_rate": 0.003701704015434082,
      "loss": 2.304,
      "step": 599220
    },
    {
      "epoch": 963.41,
      "learning_rate": 0.003698488584565913,
      "loss": 2.3069,
      "step": 599240
    },
    {
      "epoch": 963.44,
      "learning_rate": 0.003695273153697744,
      "loss": 2.3007,
      "step": 599260
    },
    {
      "epoch": 963.47,
      "learning_rate": 0.003692057722829586,
      "loss": 2.2981,
      "step": 599280
    },
    {
      "epoch": 963.5,
      "learning_rate": 0.0036888422919614168,
      "loss": 2.3104,
      "step": 599300
    },
    {
      "epoch": 963.54,
      "learning_rate": 0.003685626861093248,
      "loss": 2.3071,
      "step": 599320
    },
    {
      "epoch": 963.57,
      "learning_rate": 0.003682411430225078,
      "loss": 2.2878,
      "step": 599340
    },
    {
      "epoch": 963.6,
      "learning_rate": 0.003679195999356909,
      "loss": 2.3151,
      "step": 599360
    },
    {
      "epoch": 963.63,
      "learning_rate": 0.003675980568488751,
      "loss": 2.3064,
      "step": 599380
    },
    {
      "epoch": 963.67,
      "learning_rate": 0.0036727651376205817,
      "loss": 2.3163,
      "step": 599400
    },
    {
      "epoch": 963.7,
      "learning_rate": 0.003669549706752413,
      "loss": 2.292,
      "step": 599420
    },
    {
      "epoch": 963.73,
      "learning_rate": 0.0036663342758842437,
      "loss": 2.2801,
      "step": 599440
    },
    {
      "epoch": 963.76,
      "learning_rate": 0.0036631188450160744,
      "loss": 2.2989,
      "step": 599460
    },
    {
      "epoch": 963.79,
      "learning_rate": 0.0036599034141479047,
      "loss": 2.3028,
      "step": 599480
    },
    {
      "epoch": 963.83,
      "learning_rate": 0.0036566879832797467,
      "loss": 2.2847,
      "step": 599500
    },
    {
      "epoch": 963.86,
      "learning_rate": 0.003653472552411578,
      "loss": 2.2871,
      "step": 599520
    },
    {
      "epoch": 963.89,
      "learning_rate": 0.0036502571215434087,
      "loss": 2.2848,
      "step": 599540
    },
    {
      "epoch": 963.92,
      "learning_rate": 0.0036470416906752394,
      "loss": 2.3074,
      "step": 599560
    },
    {
      "epoch": 963.95,
      "learning_rate": 0.0036438262598070706,
      "loss": 2.3099,
      "step": 599580
    },
    {
      "epoch": 963.99,
      "learning_rate": 0.0036406108289389013,
      "loss": 2.281,
      "step": 599600
    },
    {
      "epoch": 964.0,
      "eval_accuracy": {
        "accuracy": 0.4869004120345176
      },
      "eval_loss": 2.4157357215881348,
      "eval_runtime": 3.1617,
      "eval_samples_per_second": 4068.319,
      "eval_steps_per_second": 63.572,
      "step": 599608
    },
    {
      "epoch": 964.02,
      "learning_rate": 0.0036373953980707433,
      "loss": 2.3051,
      "step": 599620
    },
    {
      "epoch": 964.05,
      "learning_rate": 0.0036341799672025745,
      "loss": 2.2819,
      "step": 599640
    },
    {
      "epoch": 964.08,
      "learning_rate": 0.0036309645363344044,
      "loss": 2.2958,
      "step": 599660
    },
    {
      "epoch": 964.12,
      "learning_rate": 0.003627749105466236,
      "loss": 2.2951,
      "step": 599680
    },
    {
      "epoch": 964.15,
      "learning_rate": 0.0036245336745980663,
      "loss": 2.3006,
      "step": 599700
    },
    {
      "epoch": 964.18,
      "learning_rate": 0.0036213182437299083,
      "loss": 2.2956,
      "step": 599720
    },
    {
      "epoch": 964.21,
      "learning_rate": 0.0036181028128617395,
      "loss": 2.2884,
      "step": 599740
    },
    {
      "epoch": 964.24,
      "learning_rate": 0.0036148873819935702,
      "loss": 2.2866,
      "step": 599760
    },
    {
      "epoch": 964.28,
      "learning_rate": 0.003611671951125401,
      "loss": 2.3035,
      "step": 599780
    },
    {
      "epoch": 964.31,
      "learning_rate": 0.0036084565202572313,
      "loss": 2.2879,
      "step": 599800
    },
    {
      "epoch": 964.34,
      "learning_rate": 0.003605241089389063,
      "loss": 2.2801,
      "step": 599820
    },
    {
      "epoch": 964.37,
      "learning_rate": 0.0036020256585209045,
      "loss": 2.3069,
      "step": 599840
    },
    {
      "epoch": 964.41,
      "learning_rate": 0.003598810227652736,
      "loss": 2.304,
      "step": 599860
    },
    {
      "epoch": 964.44,
      "learning_rate": 0.003595594796784566,
      "loss": 2.3024,
      "step": 599880
    },
    {
      "epoch": 964.47,
      "learning_rate": 0.003592379365916397,
      "loss": 2.2929,
      "step": 599900
    },
    {
      "epoch": 964.5,
      "learning_rate": 0.003589163935048228,
      "loss": 2.2938,
      "step": 599920
    },
    {
      "epoch": 964.53,
      "learning_rate": 0.003585948504180059,
      "loss": 2.3135,
      "step": 599940
    },
    {
      "epoch": 964.57,
      "learning_rate": 0.003582733073311901,
      "loss": 2.3063,
      "step": 599960
    },
    {
      "epoch": 964.6,
      "learning_rate": 0.003579517642443731,
      "loss": 2.3133,
      "step": 599980
    },
    {
      "epoch": 964.63,
      "learning_rate": 0.0035763022115755626,
      "loss": 2.3027,
      "step": 600000
    },
    {
      "epoch": 964.66,
      "learning_rate": 0.003573086780707393,
      "loss": 2.3095,
      "step": 600020
    },
    {
      "epoch": 964.69,
      "learning_rate": 0.003569871349839224,
      "loss": 2.3012,
      "step": 600040
    },
    {
      "epoch": 964.73,
      "learning_rate": 0.003566655918971066,
      "loss": 2.2974,
      "step": 600060
    },
    {
      "epoch": 964.76,
      "learning_rate": 0.003563440488102897,
      "loss": 2.2726,
      "step": 600080
    },
    {
      "epoch": 964.79,
      "learning_rate": 0.0035602250572347276,
      "loss": 2.3165,
      "step": 600100
    },
    {
      "epoch": 964.82,
      "learning_rate": 0.003557009626366558,
      "loss": 2.3019,
      "step": 600120
    },
    {
      "epoch": 964.86,
      "learning_rate": 0.0035537941954983895,
      "loss": 2.2985,
      "step": 600140
    },
    {
      "epoch": 964.89,
      "learning_rate": 0.0035505787646302207,
      "loss": 2.2891,
      "step": 600160
    },
    {
      "epoch": 964.92,
      "learning_rate": 0.0035473633337620627,
      "loss": 2.3206,
      "step": 600180
    },
    {
      "epoch": 964.95,
      "learning_rate": 0.0035441479028938926,
      "loss": 2.2843,
      "step": 600200
    },
    {
      "epoch": 964.98,
      "learning_rate": 0.0035409324720257237,
      "loss": 2.2897,
      "step": 600220
    },
    {
      "epoch": 965.0,
      "eval_accuracy": {
        "accuracy": 0.48682266967270466
      },
      "eval_loss": 2.4112424850463867,
      "eval_runtime": 3.1608,
      "eval_samples_per_second": 4069.522,
      "eval_steps_per_second": 63.591,
      "step": 600230
    },
    {
      "epoch": 965.02,
      "learning_rate": 0.0035377170411575545,
      "loss": 2.2975,
      "step": 600240
    },
    {
      "epoch": 965.05,
      "learning_rate": 0.0035345016102893857,
      "loss": 2.2925,
      "step": 600260
    },
    {
      "epoch": 965.08,
      "learning_rate": 0.0035312861794212277,
      "loss": 2.291,
      "step": 600280
    },
    {
      "epoch": 965.11,
      "learning_rate": 0.0035280707485530576,
      "loss": 2.2976,
      "step": 600300
    },
    {
      "epoch": 965.14,
      "learning_rate": 0.003524855317684889,
      "loss": 2.307,
      "step": 600320
    },
    {
      "epoch": 965.18,
      "learning_rate": 0.0035216398868167195,
      "loss": 2.2837,
      "step": 600340
    },
    {
      "epoch": 965.21,
      "learning_rate": 0.0035184244559485506,
      "loss": 2.3019,
      "step": 600360
    },
    {
      "epoch": 965.24,
      "learning_rate": 0.0035152090250803814,
      "loss": 2.2776,
      "step": 600380
    },
    {
      "epoch": 965.27,
      "learning_rate": 0.0035119935942122234,
      "loss": 2.2968,
      "step": 600400
    },
    {
      "epoch": 965.31,
      "learning_rate": 0.003508778163344054,
      "loss": 2.286,
      "step": 600420
    },
    {
      "epoch": 965.34,
      "learning_rate": 0.0035055627324758845,
      "loss": 2.2982,
      "step": 600440
    },
    {
      "epoch": 965.37,
      "learning_rate": 0.003502347301607716,
      "loss": 2.2972,
      "step": 600460
    },
    {
      "epoch": 965.4,
      "learning_rate": 0.0034991318707395472,
      "loss": 2.3104,
      "step": 600480
    },
    {
      "epoch": 965.43,
      "learning_rate": 0.003495916439871377,
      "loss": 2.2884,
      "step": 600500
    },
    {
      "epoch": 965.47,
      "learning_rate": 0.003492701009003219,
      "loss": 2.3168,
      "step": 600520
    },
    {
      "epoch": 965.5,
      "learning_rate": 0.0034894855781350503,
      "loss": 2.2927,
      "step": 600540
    },
    {
      "epoch": 965.53,
      "learning_rate": 0.003486270147266881,
      "loss": 2.305,
      "step": 600560
    },
    {
      "epoch": 965.56,
      "learning_rate": 0.0034830547163987122,
      "loss": 2.2865,
      "step": 600580
    },
    {
      "epoch": 965.59,
      "learning_rate": 0.003479839285530543,
      "loss": 2.2912,
      "step": 600600
    },
    {
      "epoch": 965.63,
      "learning_rate": 0.003476623854662384,
      "loss": 2.2916,
      "step": 600620
    },
    {
      "epoch": 965.66,
      "learning_rate": 0.0034734084237942157,
      "loss": 2.2942,
      "step": 600640
    },
    {
      "epoch": 965.69,
      "learning_rate": 0.003470192992926046,
      "loss": 2.3083,
      "step": 600660
    },
    {
      "epoch": 965.72,
      "learning_rate": 0.0034669775620578772,
      "loss": 2.3015,
      "step": 600680
    },
    {
      "epoch": 965.76,
      "learning_rate": 0.003463762131189708,
      "loss": 2.3219,
      "step": 600700
    },
    {
      "epoch": 965.79,
      "learning_rate": 0.0034605467003215387,
      "loss": 2.2884,
      "step": 600720
    },
    {
      "epoch": 965.82,
      "learning_rate": 0.0034573312694533807,
      "loss": 2.3035,
      "step": 600740
    },
    {
      "epoch": 965.85,
      "learning_rate": 0.003454115838585211,
      "loss": 2.2903,
      "step": 600760
    },
    {
      "epoch": 965.88,
      "learning_rate": 0.0034509004077170427,
      "loss": 2.2907,
      "step": 600780
    },
    {
      "epoch": 965.92,
      "learning_rate": 0.003447684976848874,
      "loss": 2.3046,
      "step": 600800
    },
    {
      "epoch": 965.95,
      "learning_rate": 0.0034444695459807037,
      "loss": 2.3108,
      "step": 600820
    },
    {
      "epoch": 965.98,
      "learning_rate": 0.003441254115112535,
      "loss": 2.2993,
      "step": 600840
    },
    {
      "epoch": 966.0,
      "eval_accuracy": {
        "accuracy": 0.4848013682655679
      },
      "eval_loss": 2.4202842712402344,
      "eval_runtime": 3.4068,
      "eval_samples_per_second": 3775.652,
      "eval_steps_per_second": 58.999,
      "step": 600852
    },
    {
      "epoch": 966.01,
      "learning_rate": 0.003438038684244377,
      "loss": 2.3036,
      "step": 600860
    },
    {
      "epoch": 966.05,
      "learning_rate": 0.0034348232533762076,
      "loss": 2.2971,
      "step": 600880
    },
    {
      "epoch": 966.08,
      "learning_rate": 0.003431607822508039,
      "loss": 2.3212,
      "step": 600900
    },
    {
      "epoch": 966.11,
      "learning_rate": 0.0034283923916398696,
      "loss": 2.2745,
      "step": 600920
    },
    {
      "epoch": 966.14,
      "learning_rate": 0.0034251769607717003,
      "loss": 2.2856,
      "step": 600940
    },
    {
      "epoch": 966.17,
      "learning_rate": 0.0034219615299035423,
      "loss": 2.2965,
      "step": 600960
    },
    {
      "epoch": 966.21,
      "learning_rate": 0.0034187460990353726,
      "loss": 2.3112,
      "step": 600980
    },
    {
      "epoch": 966.24,
      "learning_rate": 0.003415530668167204,
      "loss": 2.3131,
      "step": 601000
    },
    {
      "epoch": 966.27,
      "learning_rate": 0.0034123152372990346,
      "loss": 2.2901,
      "step": 601020
    },
    {
      "epoch": 966.3,
      "learning_rate": 0.0034090998064308653,
      "loss": 2.2941,
      "step": 601040
    },
    {
      "epoch": 966.33,
      "learning_rate": 0.0034058843755626965,
      "loss": 2.2985,
      "step": 601060
    },
    {
      "epoch": 966.37,
      "learning_rate": 0.0034026689446945385,
      "loss": 2.2812,
      "step": 601080
    },
    {
      "epoch": 966.4,
      "learning_rate": 0.0033994535138263692,
      "loss": 2.3057,
      "step": 601100
    },
    {
      "epoch": 966.43,
      "learning_rate": 0.0033962380829582004,
      "loss": 2.3047,
      "step": 601120
    },
    {
      "epoch": 966.46,
      "learning_rate": 0.0033930226520900303,
      "loss": 2.2872,
      "step": 601140
    },
    {
      "epoch": 966.5,
      "learning_rate": 0.0033898072212218615,
      "loss": 2.288,
      "step": 601160
    },
    {
      "epoch": 966.53,
      "learning_rate": 0.003386591790353692,
      "loss": 2.2822,
      "step": 601180
    },
    {
      "epoch": 966.56,
      "learning_rate": 0.0033833763594855342,
      "loss": 2.3078,
      "step": 601200
    },
    {
      "epoch": 966.59,
      "learning_rate": 0.0033801609286173654,
      "loss": 2.2893,
      "step": 601220
    },
    {
      "epoch": 966.62,
      "learning_rate": 0.003376945497749196,
      "loss": 2.2753,
      "step": 601240
    },
    {
      "epoch": 966.66,
      "learning_rate": 0.003373730066881027,
      "loss": 2.2983,
      "step": 601260
    },
    {
      "epoch": 966.69,
      "learning_rate": 0.003370514636012857,
      "loss": 2.3064,
      "step": 601280
    },
    {
      "epoch": 966.72,
      "learning_rate": 0.0033672992051446992,
      "loss": 2.3122,
      "step": 601300
    },
    {
      "epoch": 966.75,
      "learning_rate": 0.0033640837742765304,
      "loss": 2.2952,
      "step": 601320
    },
    {
      "epoch": 966.78,
      "learning_rate": 0.003360868343408361,
      "loss": 2.3013,
      "step": 601340
    },
    {
      "epoch": 966.82,
      "learning_rate": 0.003357652912540192,
      "loss": 2.2903,
      "step": 601360
    },
    {
      "epoch": 966.85,
      "learning_rate": 0.003354437481672023,
      "loss": 2.2874,
      "step": 601380
    },
    {
      "epoch": 966.88,
      "learning_rate": 0.003351222050803854,
      "loss": 2.2862,
      "step": 601400
    },
    {
      "epoch": 966.91,
      "learning_rate": 0.003348006619935696,
      "loss": 2.3068,
      "step": 601420
    },
    {
      "epoch": 966.95,
      "learning_rate": 0.003344791189067527,
      "loss": 2.2938,
      "step": 601440
    },
    {
      "epoch": 966.98,
      "learning_rate": 0.003341575758199357,
      "loss": 2.3051,
      "step": 601460
    },
    {
      "epoch": 967.0,
      "eval_accuracy": {
        "accuracy": 0.4855010495218845
      },
      "eval_loss": 2.41520094871521,
      "eval_runtime": 3.2993,
      "eval_samples_per_second": 3898.762,
      "eval_steps_per_second": 60.923,
      "step": 601474
    },
    {
      "epoch": 967.01,
      "learning_rate": 0.003338360327331188,
      "loss": 2.3121,
      "step": 601480
    },
    {
      "epoch": 967.04,
      "learning_rate": 0.003335144896463019,
      "loss": 2.2909,
      "step": 601500
    },
    {
      "epoch": 967.07,
      "learning_rate": 0.00333192946559485,
      "loss": 2.2838,
      "step": 601520
    },
    {
      "epoch": 967.11,
      "learning_rate": 0.003328714034726692,
      "loss": 2.2957,
      "step": 601540
    },
    {
      "epoch": 967.14,
      "learning_rate": 0.0033254986038585227,
      "loss": 2.2988,
      "step": 601560
    },
    {
      "epoch": 967.17,
      "learning_rate": 0.0033222831729903535,
      "loss": 2.2966,
      "step": 601580
    },
    {
      "epoch": 967.2,
      "learning_rate": 0.0033190677421221838,
      "loss": 2.3094,
      "step": 601600
    },
    {
      "epoch": 967.23,
      "learning_rate": 0.003315852311254015,
      "loss": 2.2922,
      "step": 601620
    },
    {
      "epoch": 967.27,
      "learning_rate": 0.003312636880385857,
      "loss": 2.2975,
      "step": 601640
    },
    {
      "epoch": 967.3,
      "learning_rate": 0.0033094214495176877,
      "loss": 2.3058,
      "step": 601660
    },
    {
      "epoch": 967.33,
      "learning_rate": 0.0033062060186495185,
      "loss": 2.2689,
      "step": 601680
    },
    {
      "epoch": 967.36,
      "learning_rate": 0.0033029905877813496,
      "loss": 2.2874,
      "step": 601700
    },
    {
      "epoch": 967.4,
      "learning_rate": 0.0032997751569131804,
      "loss": 2.2989,
      "step": 601720
    },
    {
      "epoch": 967.43,
      "learning_rate": 0.0032965597260450116,
      "loss": 2.3081,
      "step": 601740
    },
    {
      "epoch": 967.46,
      "learning_rate": 0.0032933442951768536,
      "loss": 2.3006,
      "step": 601760
    },
    {
      "epoch": 967.49,
      "learning_rate": 0.0032901288643086835,
      "loss": 2.2905,
      "step": 601780
    },
    {
      "epoch": 967.52,
      "learning_rate": 0.0032869134334405146,
      "loss": 2.2906,
      "step": 601800
    },
    {
      "epoch": 967.56,
      "learning_rate": 0.0032836980025723454,
      "loss": 2.2898,
      "step": 601820
    },
    {
      "epoch": 967.59,
      "learning_rate": 0.0032804825717041766,
      "loss": 2.292,
      "step": 601840
    },
    {
      "epoch": 967.62,
      "learning_rate": 0.0032772671408360073,
      "loss": 2.2985,
      "step": 601860
    },
    {
      "epoch": 967.65,
      "learning_rate": 0.0032740517099678493,
      "loss": 2.2833,
      "step": 601880
    },
    {
      "epoch": 967.68,
      "learning_rate": 0.00327083627909968,
      "loss": 2.2909,
      "step": 601900
    },
    {
      "epoch": 967.72,
      "learning_rate": 0.0032676208482315104,
      "loss": 2.304,
      "step": 601920
    },
    {
      "epoch": 967.75,
      "learning_rate": 0.003264566188906753,
      "loss": 2.299,
      "step": 601940
    },
    {
      "epoch": 967.78,
      "learning_rate": 0.003261350758038584,
      "loss": 2.3021,
      "step": 601960
    },
    {
      "epoch": 967.81,
      "learning_rate": 0.0032581353271704146,
      "loss": 2.2951,
      "step": 601980
    },
    {
      "epoch": 967.85,
      "learning_rate": 0.003254919896302245,
      "loss": 2.2872,
      "step": 602000
    },
    {
      "epoch": 967.88,
      "learning_rate": 0.003251704465434087,
      "loss": 2.3075,
      "step": 602020
    },
    {
      "epoch": 967.91,
      "learning_rate": 0.003248489034565918,
      "loss": 2.2941,
      "step": 602040
    },
    {
      "epoch": 967.94,
      "learning_rate": 0.0032454343752411604,
      "loss": 2.2945,
      "step": 602060
    },
    {
      "epoch": 967.97,
      "learning_rate": 0.003242218944372991,
      "loss": 2.306,
      "step": 602080
    },
    {
      "epoch": 968.0,
      "eval_accuracy": {
        "accuracy": 0.48635621550182695
      },
      "eval_loss": 2.4170022010803223,
      "eval_runtime": 3.3357,
      "eval_samples_per_second": 3856.184,
      "eval_steps_per_second": 60.258,
      "step": 602096
    },
    {
      "epoch": 968.01,
      "learning_rate": 0.0032390035135048214,
      "loss": 2.293,
      "step": 602100
    },
    {
      "epoch": 968.04,
      "learning_rate": 0.0032357880826366526,
      "loss": 2.3061,
      "step": 602120
    },
    {
      "epoch": 968.07,
      "learning_rate": 0.003232572651768484,
      "loss": 2.2948,
      "step": 602140
    },
    {
      "epoch": 968.1,
      "learning_rate": 0.0032293572209003253,
      "loss": 2.296,
      "step": 602160
    },
    {
      "epoch": 968.14,
      "learning_rate": 0.003226141790032156,
      "loss": 2.3033,
      "step": 602180
    },
    {
      "epoch": 968.17,
      "learning_rate": 0.0032229263591639873,
      "loss": 2.2874,
      "step": 602200
    },
    {
      "epoch": 968.2,
      "learning_rate": 0.003219710928295818,
      "loss": 2.281,
      "step": 602220
    },
    {
      "epoch": 968.23,
      "learning_rate": 0.003216495497427649,
      "loss": 2.2931,
      "step": 602240
    },
    {
      "epoch": 968.26,
      "learning_rate": 0.003213280066559491,
      "loss": 2.3059,
      "step": 602260
    },
    {
      "epoch": 968.3,
      "learning_rate": 0.003210064635691321,
      "loss": 2.2769,
      "step": 602280
    },
    {
      "epoch": 968.33,
      "learning_rate": 0.0032068492048231523,
      "loss": 2.291,
      "step": 602300
    },
    {
      "epoch": 968.36,
      "learning_rate": 0.003203633773954983,
      "loss": 2.294,
      "step": 602320
    },
    {
      "epoch": 968.39,
      "learning_rate": 0.003200418343086814,
      "loss": 2.2975,
      "step": 602340
    },
    {
      "epoch": 968.42,
      "learning_rate": 0.003197202912218645,
      "loss": 2.3059,
      "step": 602360
    },
    {
      "epoch": 968.46,
      "learning_rate": 0.003193987481350487,
      "loss": 2.29,
      "step": 602380
    },
    {
      "epoch": 968.49,
      "learning_rate": 0.0031907720504823177,
      "loss": 2.2965,
      "step": 602400
    },
    {
      "epoch": 968.52,
      "learning_rate": 0.003187556619614148,
      "loss": 2.2813,
      "step": 602420
    },
    {
      "epoch": 968.55,
      "learning_rate": 0.0031843411887459796,
      "loss": 2.3001,
      "step": 602440
    },
    {
      "epoch": 968.59,
      "learning_rate": 0.0031811257578778108,
      "loss": 2.3018,
      "step": 602460
    },
    {
      "epoch": 968.62,
      "learning_rate": 0.0031779103270096407,
      "loss": 2.2988,
      "step": 602480
    },
    {
      "epoch": 968.65,
      "learning_rate": 0.0031746948961414827,
      "loss": 2.303,
      "step": 602500
    },
    {
      "epoch": 968.68,
      "learning_rate": 0.003171479465273314,
      "loss": 2.3247,
      "step": 602520
    },
    {
      "epoch": 968.71,
      "learning_rate": 0.0031682640344051446,
      "loss": 2.2839,
      "step": 602540
    },
    {
      "epoch": 968.75,
      "learning_rate": 0.0031650486035369758,
      "loss": 2.2825,
      "step": 602560
    },
    {
      "epoch": 968.78,
      "learning_rate": 0.0031618331726688065,
      "loss": 2.291,
      "step": 602580
    },
    {
      "epoch": 968.81,
      "learning_rate": 0.0031586177418006477,
      "loss": 2.2845,
      "step": 602600
    },
    {
      "epoch": 968.84,
      "learning_rate": 0.0031554023109324793,
      "loss": 2.3129,
      "step": 602620
    },
    {
      "epoch": 968.87,
      "learning_rate": 0.0031521868800643096,
      "loss": 2.2937,
      "step": 602640
    },
    {
      "epoch": 968.91,
      "learning_rate": 0.0031489714491961408,
      "loss": 2.2874,
      "step": 602660
    },
    {
      "epoch": 968.94,
      "learning_rate": 0.0031457560183279715,
      "loss": 2.2813,
      "step": 602680
    },
    {
      "epoch": 968.97,
      "learning_rate": 0.0031425405874598022,
      "loss": 2.2871,
      "step": 602700
    },
    {
      "epoch": 969.0,
      "eval_accuracy": {
        "accuracy": 0.48612298841638807
      },
      "eval_loss": 2.4147889614105225,
      "eval_runtime": 3.1142,
      "eval_samples_per_second": 4130.492,
      "eval_steps_per_second": 64.544,
      "step": 602718
    },
    {
      "epoch": 969.0,
      "learning_rate": 0.0031393251565916443,
      "loss": 2.3076,
      "step": 602720
    },
    {
      "epoch": 969.04,
      "learning_rate": 0.0031361097257234746,
      "loss": 2.273,
      "step": 602740
    },
    {
      "epoch": 969.07,
      "learning_rate": 0.003132894294855306,
      "loss": 2.2971,
      "step": 602760
    },
    {
      "epoch": 969.1,
      "learning_rate": 0.0031296788639871374,
      "loss": 2.2925,
      "step": 602780
    },
    {
      "epoch": 969.13,
      "learning_rate": 0.0031264634331189672,
      "loss": 2.2981,
      "step": 602800
    },
    {
      "epoch": 969.16,
      "learning_rate": 0.0031232480022507984,
      "loss": 2.3071,
      "step": 602820
    },
    {
      "epoch": 969.2,
      "learning_rate": 0.0031200325713826404,
      "loss": 2.2915,
      "step": 602840
    },
    {
      "epoch": 969.23,
      "learning_rate": 0.003116817140514471,
      "loss": 2.3002,
      "step": 602860
    },
    {
      "epoch": 969.26,
      "learning_rate": 0.003113601709646302,
      "loss": 2.3186,
      "step": 602880
    },
    {
      "epoch": 969.29,
      "learning_rate": 0.003110386278778133,
      "loss": 2.2908,
      "step": 602900
    },
    {
      "epoch": 969.32,
      "learning_rate": 0.003107170847909964,
      "loss": 2.2812,
      "step": 602920
    },
    {
      "epoch": 969.36,
      "learning_rate": 0.003103955417041806,
      "loss": 2.2919,
      "step": 602940
    },
    {
      "epoch": 969.39,
      "learning_rate": 0.0031007399861736366,
      "loss": 2.2968,
      "step": 602960
    },
    {
      "epoch": 969.42,
      "learning_rate": 0.0030975245553054673,
      "loss": 2.2957,
      "step": 602980
    },
    {
      "epoch": 969.45,
      "learning_rate": 0.003094309124437298,
      "loss": 2.2909,
      "step": 603000
    },
    {
      "epoch": 969.49,
      "learning_rate": 0.003091093693569129,
      "loss": 2.2996,
      "step": 603020
    },
    {
      "epoch": 969.52,
      "learning_rate": 0.00308787826270096,
      "loss": 2.2951,
      "step": 603040
    },
    {
      "epoch": 969.55,
      "learning_rate": 0.0030846628318328016,
      "loss": 2.2968,
      "step": 603060
    },
    {
      "epoch": 969.58,
      "learning_rate": 0.0030814474009646328,
      "loss": 2.3056,
      "step": 603080
    },
    {
      "epoch": 969.61,
      "learning_rate": 0.0030782319700964635,
      "loss": 2.2986,
      "step": 603100
    },
    {
      "epoch": 969.65,
      "learning_rate": 0.0030750165392282943,
      "loss": 2.2854,
      "step": 603120
    },
    {
      "epoch": 969.68,
      "learning_rate": 0.003071801108360125,
      "loss": 2.2897,
      "step": 603140
    },
    {
      "epoch": 969.71,
      "learning_rate": 0.0030685856774919557,
      "loss": 2.2906,
      "step": 603160
    },
    {
      "epoch": 969.74,
      "learning_rate": 0.0030653702466237978,
      "loss": 2.2951,
      "step": 603180
    },
    {
      "epoch": 969.77,
      "learning_rate": 0.0030621548157556285,
      "loss": 2.3074,
      "step": 603200
    },
    {
      "epoch": 969.81,
      "learning_rate": 0.0030589393848874597,
      "loss": 2.2879,
      "step": 603220
    },
    {
      "epoch": 969.84,
      "learning_rate": 0.0030557239540192904,
      "loss": 2.2855,
      "step": 603240
    },
    {
      "epoch": 969.87,
      "learning_rate": 0.003052508523151121,
      "loss": 2.2724,
      "step": 603260
    },
    {
      "epoch": 969.9,
      "learning_rate": 0.003049293092282963,
      "loss": 2.2859,
      "step": 603280
    },
    {
      "epoch": 969.94,
      "learning_rate": 0.003046077661414794,
      "loss": 2.3093,
      "step": 603300
    },
    {
      "epoch": 969.97,
      "learning_rate": 0.0030428622305466247,
      "loss": 2.2943,
      "step": 603320
    },
    {
      "epoch": 970.0,
      "learning_rate": 0.0030396467996784554,
      "loss": 2.2836,
      "step": 603340
    },
    {
      "epoch": 970.0,
      "eval_accuracy": {
        "accuracy": 0.4855010495218845
      },
      "eval_loss": 2.411574363708496,
      "eval_runtime": 3.2022,
      "eval_samples_per_second": 4016.909,
      "eval_steps_per_second": 62.769,
      "step": 603340
    },
    {
      "epoch": 970.03,
      "learning_rate": 0.0030364313688102866,
      "loss": 2.3047,
      "step": 603360
    },
    {
      "epoch": 970.06,
      "learning_rate": 0.0030332159379421173,
      "loss": 2.2903,
      "step": 603380
    },
    {
      "epoch": 970.1,
      "learning_rate": 0.0030300005070739594,
      "loss": 2.2934,
      "step": 603400
    },
    {
      "epoch": 970.13,
      "learning_rate": 0.00302678507620579,
      "loss": 2.2837,
      "step": 603420
    },
    {
      "epoch": 970.16,
      "learning_rate": 0.003023569645337621,
      "loss": 2.2923,
      "step": 603440
    },
    {
      "epoch": 970.19,
      "learning_rate": 0.0030203542144694516,
      "loss": 2.2955,
      "step": 603460
    },
    {
      "epoch": 970.23,
      "learning_rate": 0.0030171387836012823,
      "loss": 2.2988,
      "step": 603480
    },
    {
      "epoch": 970.26,
      "learning_rate": 0.0030139233527331135,
      "loss": 2.3022,
      "step": 603500
    },
    {
      "epoch": 970.29,
      "learning_rate": 0.003010707921864955,
      "loss": 2.2777,
      "step": 603520
    },
    {
      "epoch": 970.32,
      "learning_rate": 0.0030074924909967863,
      "loss": 2.2959,
      "step": 603540
    },
    {
      "epoch": 970.35,
      "learning_rate": 0.003004277060128617,
      "loss": 2.2813,
      "step": 603560
    },
    {
      "epoch": 970.39,
      "learning_rate": 0.0030010616292604477,
      "loss": 2.2818,
      "step": 603580
    },
    {
      "epoch": 970.42,
      "learning_rate": 0.0029978461983922785,
      "loss": 2.2863,
      "step": 603600
    },
    {
      "epoch": 970.45,
      "learning_rate": 0.0029946307675241205,
      "loss": 2.2906,
      "step": 603620
    },
    {
      "epoch": 970.48,
      "learning_rate": 0.0029914153366559513,
      "loss": 2.2899,
      "step": 603640
    },
    {
      "epoch": 970.51,
      "learning_rate": 0.002988199905787782,
      "loss": 2.2917,
      "step": 603660
    },
    {
      "epoch": 970.55,
      "learning_rate": 0.002984984474919613,
      "loss": 2.2897,
      "step": 603680
    },
    {
      "epoch": 970.58,
      "learning_rate": 0.002981769044051444,
      "loss": 2.3016,
      "step": 603700
    },
    {
      "epoch": 970.61,
      "learning_rate": 0.0029785536131832747,
      "loss": 2.2892,
      "step": 603720
    },
    {
      "epoch": 970.64,
      "learning_rate": 0.0029753381823151167,
      "loss": 2.303,
      "step": 603740
    },
    {
      "epoch": 970.68,
      "learning_rate": 0.0029721227514469474,
      "loss": 2.3018,
      "step": 603760
    },
    {
      "epoch": 970.71,
      "learning_rate": 0.002968907320578778,
      "loss": 2.2682,
      "step": 603780
    },
    {
      "epoch": 970.74,
      "learning_rate": 0.0029656918897106093,
      "loss": 2.3046,
      "step": 603800
    },
    {
      "epoch": 970.77,
      "learning_rate": 0.00296247645884244,
      "loss": 2.3029,
      "step": 603820
    },
    {
      "epoch": 970.8,
      "learning_rate": 0.002959261027974282,
      "loss": 2.2967,
      "step": 603840
    },
    {
      "epoch": 970.84,
      "learning_rate": 0.002956045597106113,
      "loss": 2.3021,
      "step": 603860
    },
    {
      "epoch": 970.87,
      "learning_rate": 0.0029528301662379436,
      "loss": 2.2845,
      "step": 603880
    },
    {
      "epoch": 970.9,
      "learning_rate": 0.0029496147353697743,
      "loss": 2.3128,
      "step": 603900
    },
    {
      "epoch": 970.93,
      "learning_rate": 0.002946399304501605,
      "loss": 2.2871,
      "step": 603920
    },
    {
      "epoch": 970.96,
      "learning_rate": 0.0029431838736334363,
      "loss": 2.2869,
      "step": 603940
    },
    {
      "epoch": 971.0,
      "learning_rate": 0.002939968442765278,
      "loss": 2.2958,
      "step": 603960
    },
    {
      "epoch": 971.0,
      "eval_accuracy": {
        "accuracy": 0.48565653424551036
      },
      "eval_loss": 2.41336989402771,
      "eval_runtime": 3.1078,
      "eval_samples_per_second": 4138.948,
      "eval_steps_per_second": 64.676,
      "step": 603962
    },
    {
      "epoch": 971.03,
      "learning_rate": 0.002936753011897109,
      "loss": 2.2856,
      "step": 603980
    },
    {
      "epoch": 971.06,
      "learning_rate": 0.0029335375810289398,
      "loss": 2.2871,
      "step": 604000
    },
    {
      "epoch": 971.09,
      "learning_rate": 0.0029303221501607705,
      "loss": 2.289,
      "step": 604020
    },
    {
      "epoch": 971.13,
      "learning_rate": 0.0029271067192926012,
      "loss": 2.2972,
      "step": 604040
    },
    {
      "epoch": 971.16,
      "learning_rate": 0.002923891288424432,
      "loss": 2.2756,
      "step": 604060
    },
    {
      "epoch": 971.19,
      "learning_rate": 0.002920675857556274,
      "loss": 2.2908,
      "step": 604080
    },
    {
      "epoch": 971.22,
      "learning_rate": 0.0029174604266881047,
      "loss": 2.2999,
      "step": 604100
    },
    {
      "epoch": 971.25,
      "learning_rate": 0.002914244995819936,
      "loss": 2.2896,
      "step": 604120
    },
    {
      "epoch": 971.29,
      "learning_rate": 0.0029110295649517667,
      "loss": 2.3027,
      "step": 604140
    },
    {
      "epoch": 971.32,
      "learning_rate": 0.0029078141340835974,
      "loss": 2.2819,
      "step": 604160
    },
    {
      "epoch": 971.35,
      "learning_rate": 0.0029045987032154394,
      "loss": 2.2818,
      "step": 604180
    },
    {
      "epoch": 971.38,
      "learning_rate": 0.00290138327234727,
      "loss": 2.2699,
      "step": 604200
    },
    {
      "epoch": 971.41,
      "learning_rate": 0.002898167841479101,
      "loss": 2.2902,
      "step": 604220
    },
    {
      "epoch": 971.45,
      "learning_rate": 0.0028949524106109317,
      "loss": 2.3025,
      "step": 604240
    },
    {
      "epoch": 971.48,
      "learning_rate": 0.002891736979742763,
      "loss": 2.3092,
      "step": 604260
    },
    {
      "epoch": 971.51,
      "learning_rate": 0.0028885215488745936,
      "loss": 2.3138,
      "step": 604280
    },
    {
      "epoch": 971.54,
      "learning_rate": 0.0028853061180064356,
      "loss": 2.288,
      "step": 604300
    },
    {
      "epoch": 971.58,
      "learning_rate": 0.0028820906871382663,
      "loss": 2.2956,
      "step": 604320
    },
    {
      "epoch": 971.61,
      "learning_rate": 0.002878875256270097,
      "loss": 2.3005,
      "step": 604340
    },
    {
      "epoch": 971.64,
      "learning_rate": 0.002875659825401928,
      "loss": 2.3128,
      "step": 604360
    },
    {
      "epoch": 971.67,
      "learning_rate": 0.0028724443945337586,
      "loss": 2.287,
      "step": 604380
    },
    {
      "epoch": 971.7,
      "learning_rate": 0.0028692289636655897,
      "loss": 2.2906,
      "step": 604400
    },
    {
      "epoch": 971.74,
      "learning_rate": 0.0028660135327974313,
      "loss": 2.2811,
      "step": 604420
    },
    {
      "epoch": 971.77,
      "learning_rate": 0.0028627981019292625,
      "loss": 2.2959,
      "step": 604440
    },
    {
      "epoch": 971.8,
      "learning_rate": 0.0028595826710610932,
      "loss": 2.2855,
      "step": 604460
    },
    {
      "epoch": 971.83,
      "learning_rate": 0.002856367240192924,
      "loss": 2.2756,
      "step": 604480
    },
    {
      "epoch": 971.86,
      "learning_rate": 0.0028531518093247547,
      "loss": 2.293,
      "step": 604500
    },
    {
      "epoch": 971.9,
      "learning_rate": 0.0028499363784565968,
      "loss": 2.2944,
      "step": 604520
    },
    {
      "epoch": 971.93,
      "learning_rate": 0.0028467209475884275,
      "loss": 2.3013,
      "step": 604540
    },
    {
      "epoch": 971.96,
      "learning_rate": 0.0028435055167202582,
      "loss": 2.2965,
      "step": 604560
    },
    {
      "epoch": 971.99,
      "learning_rate": 0.0028402900858520894,
      "loss": 2.2864,
      "step": 604580
    },
    {
      "epoch": 972.0,
      "eval_accuracy": {
        "accuracy": 0.48651170022545287
      },
      "eval_loss": 2.4099719524383545,
      "eval_runtime": 3.0955,
      "eval_samples_per_second": 4155.327,
      "eval_steps_per_second": 64.932,
      "step": 604584
    },
    {
      "epoch": 972.03,
      "learning_rate": 0.00283707465498392,
      "loss": 2.2716,
      "step": 604600
    },
    {
      "epoch": 972.06,
      "learning_rate": 0.002833859224115751,
      "loss": 2.2978,
      "step": 604620
    },
    {
      "epoch": 972.09,
      "learning_rate": 0.002830643793247593,
      "loss": 2.3005,
      "step": 604640
    },
    {
      "epoch": 972.12,
      "learning_rate": 0.0028274283623794237,
      "loss": 2.2813,
      "step": 604660
    },
    {
      "epoch": 972.15,
      "learning_rate": 0.0028242129315112544,
      "loss": 2.2997,
      "step": 604680
    },
    {
      "epoch": 972.19,
      "learning_rate": 0.002820997500643085,
      "loss": 2.2856,
      "step": 604700
    },
    {
      "epoch": 972.22,
      "learning_rate": 0.0028177820697749163,
      "loss": 2.2782,
      "step": 604720
    },
    {
      "epoch": 972.25,
      "learning_rate": 0.002814566638906747,
      "loss": 2.2913,
      "step": 604740
    },
    {
      "epoch": 972.28,
      "learning_rate": 0.002811351208038589,
      "loss": 2.2986,
      "step": 604760
    },
    {
      "epoch": 972.32,
      "learning_rate": 0.00280813577717042,
      "loss": 2.2686,
      "step": 604780
    },
    {
      "epoch": 972.35,
      "learning_rate": 0.0028049203463022506,
      "loss": 2.2917,
      "step": 604800
    },
    {
      "epoch": 972.38,
      "learning_rate": 0.0028017049154340813,
      "loss": 2.2875,
      "step": 604820
    },
    {
      "epoch": 972.41,
      "learning_rate": 0.002798489484565912,
      "loss": 2.2895,
      "step": 604840
    },
    {
      "epoch": 972.44,
      "learning_rate": 0.002795274053697754,
      "loss": 2.2895,
      "step": 604860
    },
    {
      "epoch": 972.48,
      "learning_rate": 0.002792058622829585,
      "loss": 2.2933,
      "step": 604880
    },
    {
      "epoch": 972.51,
      "learning_rate": 0.002788843191961416,
      "loss": 2.3003,
      "step": 604900
    },
    {
      "epoch": 972.54,
      "learning_rate": 0.002785788532636658,
      "loss": 2.3034,
      "step": 604920
    },
    {
      "epoch": 972.57,
      "learning_rate": 0.0027825731017684886,
      "loss": 2.2876,
      "step": 604940
    },
    {
      "epoch": 972.6,
      "learning_rate": 0.0027793576709003198,
      "loss": 2.2996,
      "step": 604960
    },
    {
      "epoch": 972.64,
      "learning_rate": 0.0027761422400321505,
      "loss": 2.291,
      "step": 604980
    },
    {
      "epoch": 972.67,
      "learning_rate": 0.0027729268091639925,
      "loss": 2.2946,
      "step": 605000
    },
    {
      "epoch": 972.7,
      "learning_rate": 0.0027697113782958233,
      "loss": 2.2845,
      "step": 605020
    },
    {
      "epoch": 972.73,
      "learning_rate": 0.002766495947427654,
      "loss": 2.2822,
      "step": 605040
    },
    {
      "epoch": 972.77,
      "learning_rate": 0.0027632805165594848,
      "loss": 2.2947,
      "step": 605060
    },
    {
      "epoch": 972.8,
      "learning_rate": 0.0027600650856913155,
      "loss": 2.3081,
      "step": 605080
    },
    {
      "epoch": 972.83,
      "learning_rate": 0.0027568496548231467,
      "loss": 2.2885,
      "step": 605100
    },
    {
      "epoch": 972.86,
      "learning_rate": 0.0027536342239549883,
      "loss": 2.3026,
      "step": 605120
    },
    {
      "epoch": 972.89,
      "learning_rate": 0.0027504187930868194,
      "loss": 2.2839,
      "step": 605140
    },
    {
      "epoch": 972.93,
      "learning_rate": 0.00274720336221865,
      "loss": 2.2898,
      "step": 605160
    },
    {
      "epoch": 972.96,
      "learning_rate": 0.002743987931350481,
      "loss": 2.3,
      "step": 605180
    },
    {
      "epoch": 972.99,
      "learning_rate": 0.0027407725004823117,
      "loss": 2.2848,
      "step": 605200
    },
    {
      "epoch": 973.0,
      "eval_accuracy": {
        "accuracy": 0.4881442898235248
      },
      "eval_loss": 2.41105580329895,
      "eval_runtime": 3.2105,
      "eval_samples_per_second": 4006.563,
      "eval_steps_per_second": 62.607,
      "step": 605206
    },
    {
      "epoch": 973.02,
      "learning_rate": 0.0027375570696141424,
      "loss": 2.286,
      "step": 605220
    },
    {
      "epoch": 973.05,
      "learning_rate": 0.0027343416387459844,
      "loss": 2.2916,
      "step": 605240
    },
    {
      "epoch": 973.09,
      "learning_rate": 0.002731126207877815,
      "loss": 2.2848,
      "step": 605260
    },
    {
      "epoch": 973.12,
      "learning_rate": 0.0027279107770096464,
      "loss": 2.2995,
      "step": 605280
    },
    {
      "epoch": 973.15,
      "learning_rate": 0.002724695346141477,
      "loss": 2.2955,
      "step": 605300
    },
    {
      "epoch": 973.18,
      "learning_rate": 0.002721479915273308,
      "loss": 2.2984,
      "step": 605320
    },
    {
      "epoch": 973.22,
      "learning_rate": 0.00271826448440515,
      "loss": 2.2676,
      "step": 605340
    },
    {
      "epoch": 973.25,
      "learning_rate": 0.0027150490535369806,
      "loss": 2.2844,
      "step": 605360
    },
    {
      "epoch": 973.28,
      "learning_rate": 0.0027118336226688113,
      "loss": 2.2823,
      "step": 605380
    },
    {
      "epoch": 973.31,
      "learning_rate": 0.002708618191800642,
      "loss": 2.2922,
      "step": 605400
    },
    {
      "epoch": 973.34,
      "learning_rate": 0.0027054027609324733,
      "loss": 2.3084,
      "step": 605420
    },
    {
      "epoch": 973.38,
      "learning_rate": 0.002702187330064304,
      "loss": 2.2844,
      "step": 605440
    },
    {
      "epoch": 973.41,
      "learning_rate": 0.002698971899196146,
      "loss": 2.2705,
      "step": 605460
    },
    {
      "epoch": 973.44,
      "learning_rate": 0.0026957564683279768,
      "loss": 2.2869,
      "step": 605480
    },
    {
      "epoch": 973.47,
      "learning_rate": 0.0026925410374598075,
      "loss": 2.2982,
      "step": 605500
    },
    {
      "epoch": 973.5,
      "learning_rate": 0.0026893256065916383,
      "loss": 2.2854,
      "step": 605520
    },
    {
      "epoch": 973.54,
      "learning_rate": 0.002686110175723469,
      "loss": 2.2946,
      "step": 605540
    },
    {
      "epoch": 973.57,
      "learning_rate": 0.0026828947448553,
      "loss": 2.2861,
      "step": 605560
    },
    {
      "epoch": 973.6,
      "learning_rate": 0.0026796793139871418,
      "loss": 2.2899,
      "step": 605580
    },
    {
      "epoch": 973.63,
      "learning_rate": 0.002676463883118973,
      "loss": 2.3038,
      "step": 605600
    },
    {
      "epoch": 973.67,
      "learning_rate": 0.0026732484522508037,
      "loss": 2.2844,
      "step": 605620
    },
    {
      "epoch": 973.7,
      "learning_rate": 0.0026700330213826344,
      "loss": 2.285,
      "step": 605640
    },
    {
      "epoch": 973.73,
      "learning_rate": 0.002666817590514465,
      "loss": 2.3064,
      "step": 605660
    },
    {
      "epoch": 973.76,
      "learning_rate": 0.002663602159646307,
      "loss": 2.2779,
      "step": 605680
    },
    {
      "epoch": 973.79,
      "learning_rate": 0.002660386728778138,
      "loss": 2.3007,
      "step": 605700
    },
    {
      "epoch": 973.83,
      "learning_rate": 0.002657171297909969,
      "loss": 2.2973,
      "step": 605720
    },
    {
      "epoch": 973.86,
      "learning_rate": 0.0026539558670418,
      "loss": 2.3014,
      "step": 605740
    },
    {
      "epoch": 973.89,
      "learning_rate": 0.0026507404361736306,
      "loss": 2.2888,
      "step": 605760
    },
    {
      "epoch": 973.92,
      "learning_rate": 0.0026475250053054613,
      "loss": 2.3005,
      "step": 605780
    },
    {
      "epoch": 973.95,
      "learning_rate": 0.0026443095744373033,
      "loss": 2.2707,
      "step": 605800
    },
    {
      "epoch": 973.99,
      "learning_rate": 0.002641094143569134,
      "loss": 2.2924,
      "step": 605820
    },
    {
      "epoch": 974.0,
      "eval_accuracy": {
        "accuracy": 0.4900101065070357
      },
      "eval_loss": 2.4065160751342773,
      "eval_runtime": 3.2709,
      "eval_samples_per_second": 3932.563,
      "eval_steps_per_second": 61.451,
      "step": 605828
    },
    {
      "epoch": 974.02,
      "learning_rate": 0.002637878712700965,
      "loss": 2.2846,
      "step": 605840
    },
    {
      "epoch": 974.05,
      "learning_rate": 0.002634663281832796,
      "loss": 2.2807,
      "step": 605860
    },
    {
      "epoch": 974.08,
      "learning_rate": 0.0026314478509646268,
      "loss": 2.2942,
      "step": 605880
    },
    {
      "epoch": 974.12,
      "learning_rate": 0.0026282324200964575,
      "loss": 2.2883,
      "step": 605900
    },
    {
      "epoch": 974.15,
      "learning_rate": 0.0026250169892282995,
      "loss": 2.2908,
      "step": 605920
    },
    {
      "epoch": 974.18,
      "learning_rate": 0.0026218015583601303,
      "loss": 2.2925,
      "step": 605940
    },
    {
      "epoch": 974.21,
      "learning_rate": 0.002618586127491961,
      "loss": 2.2716,
      "step": 605960
    },
    {
      "epoch": 974.24,
      "learning_rate": 0.0026153706966237917,
      "loss": 2.2886,
      "step": 605980
    },
    {
      "epoch": 974.28,
      "learning_rate": 0.002612155265755623,
      "loss": 2.304,
      "step": 606000
    },
    {
      "epoch": 974.31,
      "learning_rate": 0.0026089398348874645,
      "loss": 2.2881,
      "step": 606020
    },
    {
      "epoch": 974.34,
      "learning_rate": 0.0026057244040192957,
      "loss": 2.2985,
      "step": 606040
    },
    {
      "epoch": 974.37,
      "learning_rate": 0.0026025089731511264,
      "loss": 2.309,
      "step": 606060
    },
    {
      "epoch": 974.41,
      "learning_rate": 0.002599293542282957,
      "loss": 2.2798,
      "step": 606080
    },
    {
      "epoch": 974.44,
      "learning_rate": 0.002596078111414788,
      "loss": 2.2895,
      "step": 606100
    },
    {
      "epoch": 974.47,
      "learning_rate": 0.0025928626805466187,
      "loss": 2.2715,
      "step": 606120
    },
    {
      "epoch": 974.5,
      "learning_rate": 0.0025896472496784607,
      "loss": 2.2918,
      "step": 606140
    },
    {
      "epoch": 974.53,
      "learning_rate": 0.0025864318188102914,
      "loss": 2.2902,
      "step": 606160
    },
    {
      "epoch": 974.57,
      "learning_rate": 0.0025832163879421226,
      "loss": 2.3233,
      "step": 606180
    },
    {
      "epoch": 974.6,
      "learning_rate": 0.0025800009570739533,
      "loss": 2.2863,
      "step": 606200
    },
    {
      "epoch": 974.63,
      "learning_rate": 0.002576785526205784,
      "loss": 2.3098,
      "step": 606220
    },
    {
      "epoch": 974.66,
      "learning_rate": 0.002573570095337626,
      "loss": 2.2931,
      "step": 606240
    },
    {
      "epoch": 974.69,
      "learning_rate": 0.002570354664469457,
      "loss": 2.2979,
      "step": 606260
    },
    {
      "epoch": 974.73,
      "learning_rate": 0.0025671392336012876,
      "loss": 2.2913,
      "step": 606280
    },
    {
      "epoch": 974.76,
      "learning_rate": 0.0025639238027331183,
      "loss": 2.2894,
      "step": 606300
    },
    {
      "epoch": 974.79,
      "learning_rate": 0.0025607083718649495,
      "loss": 2.2813,
      "step": 606320
    },
    {
      "epoch": 974.82,
      "learning_rate": 0.0025574929409967802,
      "loss": 2.2834,
      "step": 606340
    },
    {
      "epoch": 974.86,
      "learning_rate": 0.0025542775101286223,
      "loss": 2.2665,
      "step": 606360
    },
    {
      "epoch": 974.89,
      "learning_rate": 0.002551062079260453,
      "loss": 2.2874,
      "step": 606380
    },
    {
      "epoch": 974.92,
      "learning_rate": 0.0025478466483922838,
      "loss": 2.2961,
      "step": 606400
    },
    {
      "epoch": 974.95,
      "learning_rate": 0.0025446312175241145,
      "loss": 2.2922,
      "step": 606420
    },
    {
      "epoch": 974.98,
      "learning_rate": 0.0025414157866559452,
      "loss": 2.2569,
      "step": 606440
    },
    {
      "epoch": 975.0,
      "eval_accuracy": {
        "accuracy": 0.4880665474617119
      },
      "eval_loss": 2.408973455429077,
      "eval_runtime": 3.2365,
      "eval_samples_per_second": 3974.354,
      "eval_steps_per_second": 62.104,
      "step": 606450
    },
    {
      "epoch": 975.02,
      "learning_rate": 0.0025382003557877764,
      "loss": 2.2895,
      "step": 606460
    },
    {
      "epoch": 975.05,
      "learning_rate": 0.002534984924919618,
      "loss": 2.2895,
      "step": 606480
    },
    {
      "epoch": 975.08,
      "learning_rate": 0.002531769494051449,
      "loss": 2.2911,
      "step": 606500
    },
    {
      "epoch": 975.11,
      "learning_rate": 0.00252855406318328,
      "loss": 2.2829,
      "step": 606520
    },
    {
      "epoch": 975.14,
      "learning_rate": 0.0025253386323151107,
      "loss": 2.2981,
      "step": 606540
    },
    {
      "epoch": 975.18,
      "learning_rate": 0.0025221232014469414,
      "loss": 2.2681,
      "step": 606560
    },
    {
      "epoch": 975.21,
      "learning_rate": 0.0025189077705787834,
      "loss": 2.2843,
      "step": 606580
    },
    {
      "epoch": 975.24,
      "learning_rate": 0.002515692339710614,
      "loss": 2.2888,
      "step": 606600
    },
    {
      "epoch": 975.27,
      "learning_rate": 0.002512476908842445,
      "loss": 2.3085,
      "step": 606620
    },
    {
      "epoch": 975.31,
      "learning_rate": 0.002509261477974276,
      "loss": 2.2912,
      "step": 606640
    },
    {
      "epoch": 975.34,
      "learning_rate": 0.002506046047106107,
      "loss": 2.2924,
      "step": 606660
    },
    {
      "epoch": 975.37,
      "learning_rate": 0.0025028306162379376,
      "loss": 2.2857,
      "step": 606680
    },
    {
      "epoch": 975.4,
      "learning_rate": 0.0024996151853697796,
      "loss": 2.3025,
      "step": 606700
    },
    {
      "epoch": 975.43,
      "learning_rate": 0.0024963997545016103,
      "loss": 2.285,
      "step": 606720
    },
    {
      "epoch": 975.47,
      "learning_rate": 0.002493184323633441,
      "loss": 2.2822,
      "step": 606740
    },
    {
      "epoch": 975.5,
      "learning_rate": 0.002489968892765272,
      "loss": 2.2953,
      "step": 606760
    },
    {
      "epoch": 975.53,
      "learning_rate": 0.002486753461897103,
      "loss": 2.2936,
      "step": 606780
    },
    {
      "epoch": 975.56,
      "learning_rate": 0.0024835380310289337,
      "loss": 2.2855,
      "step": 606800
    },
    {
      "epoch": 975.59,
      "learning_rate": 0.0024803226001607758,
      "loss": 2.2933,
      "step": 606820
    },
    {
      "epoch": 975.63,
      "learning_rate": 0.0024771071692926065,
      "loss": 2.2667,
      "step": 606840
    },
    {
      "epoch": 975.66,
      "learning_rate": 0.0024738917384244372,
      "loss": 2.2728,
      "step": 606860
    },
    {
      "epoch": 975.69,
      "learning_rate": 0.002470676307556268,
      "loss": 2.277,
      "step": 606880
    },
    {
      "epoch": 975.72,
      "learning_rate": 0.0024674608766880987,
      "loss": 2.2951,
      "step": 606900
    },
    {
      "epoch": 975.76,
      "learning_rate": 0.0024642454458199408,
      "loss": 2.2704,
      "step": 606920
    },
    {
      "epoch": 975.79,
      "learning_rate": 0.0024610300149517715,
      "loss": 2.2884,
      "step": 606940
    },
    {
      "epoch": 975.82,
      "learning_rate": 0.0024578145840836027,
      "loss": 2.2907,
      "step": 606960
    },
    {
      "epoch": 975.85,
      "learning_rate": 0.0024545991532154334,
      "loss": 2.3027,
      "step": 606980
    },
    {
      "epoch": 975.88,
      "learning_rate": 0.002451383722347264,
      "loss": 2.286,
      "step": 607000
    },
    {
      "epoch": 975.92,
      "learning_rate": 0.002448168291479095,
      "loss": 2.2987,
      "step": 607020
    },
    {
      "epoch": 975.95,
      "learning_rate": 0.002444952860610937,
      "loss": 2.2978,
      "step": 607040
    },
    {
      "epoch": 975.98,
      "learning_rate": 0.0024417374297427677,
      "loss": 2.2654,
      "step": 607060
    },
    {
      "epoch": 976.0,
      "eval_accuracy": {
        "accuracy": 0.4882220321853378
      },
      "eval_loss": 2.406580686569214,
      "eval_runtime": 3.1679,
      "eval_samples_per_second": 4060.411,
      "eval_steps_per_second": 63.449,
      "step": 607072
    },
    {
      "epoch": 976.01,
      "learning_rate": 0.002438521998874599,
      "loss": 2.2933,
      "step": 607080
    },
    {
      "epoch": 976.05,
      "learning_rate": 0.0024353065680064296,
      "loss": 2.3091,
      "step": 607100
    },
    {
      "epoch": 976.08,
      "learning_rate": 0.0024320911371382603,
      "loss": 2.2927,
      "step": 607120
    },
    {
      "epoch": 976.11,
      "learning_rate": 0.002428875706270091,
      "loss": 2.2865,
      "step": 607140
    },
    {
      "epoch": 976.14,
      "learning_rate": 0.002425660275401933,
      "loss": 2.2899,
      "step": 607160
    },
    {
      "epoch": 976.17,
      "learning_rate": 0.002422444844533764,
      "loss": 2.2812,
      "step": 607180
    },
    {
      "epoch": 976.21,
      "learning_rate": 0.0024192294136655946,
      "loss": 2.2792,
      "step": 607200
    },
    {
      "epoch": 976.24,
      "learning_rate": 0.0024160139827974257,
      "loss": 2.2809,
      "step": 607220
    },
    {
      "epoch": 976.27,
      "learning_rate": 0.0024127985519292565,
      "loss": 2.2926,
      "step": 607240
    },
    {
      "epoch": 976.3,
      "learning_rate": 0.0024095831210610985,
      "loss": 2.2802,
      "step": 607260
    },
    {
      "epoch": 976.33,
      "learning_rate": 0.0024063676901929293,
      "loss": 2.2975,
      "step": 607280
    },
    {
      "epoch": 976.37,
      "learning_rate": 0.00240315225932476,
      "loss": 2.3057,
      "step": 607300
    },
    {
      "epoch": 976.4,
      "learning_rate": 0.0023999368284565907,
      "loss": 2.2755,
      "step": 607320
    },
    {
      "epoch": 976.43,
      "learning_rate": 0.0023967213975884215,
      "loss": 2.2995,
      "step": 607340
    },
    {
      "epoch": 976.46,
      "learning_rate": 0.0023935059667202527,
      "loss": 2.3038,
      "step": 607360
    },
    {
      "epoch": 976.5,
      "learning_rate": 0.0023902905358520942,
      "loss": 2.2819,
      "step": 607380
    },
    {
      "epoch": 976.53,
      "learning_rate": 0.0023870751049839254,
      "loss": 2.2862,
      "step": 607400
    },
    {
      "epoch": 976.56,
      "learning_rate": 0.002383859674115756,
      "loss": 2.2892,
      "step": 607420
    },
    {
      "epoch": 976.59,
      "learning_rate": 0.002380644243247587,
      "loss": 2.2945,
      "step": 607440
    },
    {
      "epoch": 976.62,
      "learning_rate": 0.0023774288123794176,
      "loss": 2.2742,
      "step": 607460
    },
    {
      "epoch": 976.66,
      "learning_rate": 0.0023742133815112484,
      "loss": 2.2851,
      "step": 607480
    },
    {
      "epoch": 976.69,
      "learning_rate": 0.0023709979506430904,
      "loss": 2.2833,
      "step": 607500
    },
    {
      "epoch": 976.72,
      "learning_rate": 0.002367782519774921,
      "loss": 2.2814,
      "step": 607520
    },
    {
      "epoch": 976.75,
      "learning_rate": 0.0023645670889067523,
      "loss": 2.2735,
      "step": 607540
    },
    {
      "epoch": 976.78,
      "learning_rate": 0.002361351658038583,
      "loss": 2.2739,
      "step": 607560
    },
    {
      "epoch": 976.82,
      "learning_rate": 0.002358136227170414,
      "loss": 2.2815,
      "step": 607580
    },
    {
      "epoch": 976.85,
      "learning_rate": 0.002354920796302256,
      "loss": 2.2913,
      "step": 607600
    },
    {
      "epoch": 976.88,
      "learning_rate": 0.0023517053654340866,
      "loss": 2.3103,
      "step": 607620
    },
    {
      "epoch": 976.91,
      "learning_rate": 0.0023484899345659173,
      "loss": 2.2739,
      "step": 607640
    },
    {
      "epoch": 976.95,
      "learning_rate": 0.002345274503697748,
      "loss": 2.2944,
      "step": 607660
    },
    {
      "epoch": 976.98,
      "learning_rate": 0.0023420590728295792,
      "loss": 2.2769,
      "step": 607680
    },
    {
      "epoch": 977.0,
      "eval_accuracy": {
        "accuracy": 0.49296431625592785
      },
      "eval_loss": 2.4035000801086426,
      "eval_runtime": 3.2256,
      "eval_samples_per_second": 3987.823,
      "eval_steps_per_second": 62.315,
      "step": 607694
    },
    {
      "epoch": 977.01,
      "learning_rate": 0.00233884364196141,
      "loss": 2.2977,
      "step": 607700
    },
    {
      "epoch": 977.04,
      "learning_rate": 0.002335628211093252,
      "loss": 2.2751,
      "step": 607720
    },
    {
      "epoch": 977.07,
      "learning_rate": 0.0023324127802250827,
      "loss": 2.2944,
      "step": 607740
    },
    {
      "epoch": 977.11,
      "learning_rate": 0.0023291973493569135,
      "loss": 2.3054,
      "step": 607760
    },
    {
      "epoch": 977.14,
      "learning_rate": 0.0023259819184887442,
      "loss": 2.2774,
      "step": 607780
    },
    {
      "epoch": 977.17,
      "learning_rate": 0.002322766487620575,
      "loss": 2.2889,
      "step": 607800
    },
    {
      "epoch": 977.2,
      "learning_rate": 0.002319551056752406,
      "loss": 2.2764,
      "step": 607820
    },
    {
      "epoch": 977.23,
      "learning_rate": 0.002316496397427648,
      "loss": 2.2906,
      "step": 607840
    },
    {
      "epoch": 977.27,
      "learning_rate": 0.00231328096655949,
      "loss": 2.2814,
      "step": 607860
    },
    {
      "epoch": 977.3,
      "learning_rate": 0.0023100655356913208,
      "loss": 2.2807,
      "step": 607880
    },
    {
      "epoch": 977.33,
      "learning_rate": 0.0023068501048231515,
      "loss": 2.2851,
      "step": 607900
    },
    {
      "epoch": 977.36,
      "learning_rate": 0.0023036346739549827,
      "loss": 2.2796,
      "step": 607920
    },
    {
      "epoch": 977.4,
      "learning_rate": 0.0023004192430868134,
      "loss": 2.272,
      "step": 607940
    },
    {
      "epoch": 977.43,
      "learning_rate": 0.002297203812218644,
      "loss": 2.2924,
      "step": 607960
    },
    {
      "epoch": 977.46,
      "learning_rate": 0.002293988381350486,
      "loss": 2.2884,
      "step": 607980
    },
    {
      "epoch": 977.49,
      "learning_rate": 0.002290772950482317,
      "loss": 2.2914,
      "step": 608000
    },
    {
      "epoch": 977.52,
      "learning_rate": 0.0022875575196141477,
      "loss": 2.2917,
      "step": 608020
    },
    {
      "epoch": 977.56,
      "learning_rate": 0.0022843420887459784,
      "loss": 2.3017,
      "step": 608040
    },
    {
      "epoch": 977.59,
      "learning_rate": 0.0022811266578778096,
      "loss": 2.2886,
      "step": 608060
    },
    {
      "epoch": 977.62,
      "learning_rate": 0.002277911227009651,
      "loss": 2.2754,
      "step": 608080
    },
    {
      "epoch": 977.65,
      "learning_rate": 0.0022746957961414824,
      "loss": 2.2885,
      "step": 608100
    },
    {
      "epoch": 977.68,
      "learning_rate": 0.002271480365273313,
      "loss": 2.2991,
      "step": 608120
    },
    {
      "epoch": 977.72,
      "learning_rate": 0.002268264934405144,
      "loss": 2.2785,
      "step": 608140
    },
    {
      "epoch": 977.75,
      "learning_rate": 0.0022650495035369746,
      "loss": 2.2919,
      "step": 608160
    },
    {
      "epoch": 977.78,
      "learning_rate": 0.0022618340726688053,
      "loss": 2.2962,
      "step": 608180
    },
    {
      "epoch": 977.81,
      "learning_rate": 0.0022586186418006473,
      "loss": 2.2839,
      "step": 608200
    },
    {
      "epoch": 977.85,
      "learning_rate": 0.002255403210932478,
      "loss": 2.2646,
      "step": 608220
    },
    {
      "epoch": 977.88,
      "learning_rate": 0.0022521877800643093,
      "loss": 2.2925,
      "step": 608240
    },
    {
      "epoch": 977.91,
      "learning_rate": 0.00224897234919614,
      "loss": 2.2837,
      "step": 608260
    },
    {
      "epoch": 977.94,
      "learning_rate": 0.0022457569183279708,
      "loss": 2.2784,
      "step": 608280
    },
    {
      "epoch": 977.97,
      "learning_rate": 0.0022425414874598015,
      "loss": 2.2961,
      "step": 608300
    },
    {
      "epoch": 978.0,
      "eval_accuracy": {
        "accuracy": 0.49039881831610044
      },
      "eval_loss": 2.3995988368988037,
      "eval_runtime": 3.2508,
      "eval_samples_per_second": 3956.851,
      "eval_steps_per_second": 61.831,
      "step": 608316
    },
    {
      "epoch": 978.01,
      "learning_rate": 0.0022393260565916435,
      "loss": 2.279,
      "step": 608320
    },
    {
      "epoch": 978.04,
      "learning_rate": 0.0022361106257234743,
      "loss": 2.2939,
      "step": 608340
    },
    {
      "epoch": 978.07,
      "learning_rate": 0.002232895194855305,
      "loss": 2.3042,
      "step": 608360
    },
    {
      "epoch": 978.1,
      "learning_rate": 0.002229679763987136,
      "loss": 2.2826,
      "step": 608380
    },
    {
      "epoch": 978.14,
      "learning_rate": 0.002226464333118967,
      "loss": 2.2999,
      "step": 608400
    },
    {
      "epoch": 978.17,
      "learning_rate": 0.002223248902250809,
      "loss": 2.2857,
      "step": 608420
    },
    {
      "epoch": 978.2,
      "learning_rate": 0.0022200334713826397,
      "loss": 2.2879,
      "step": 608440
    },
    {
      "epoch": 978.23,
      "learning_rate": 0.0022168180405144704,
      "loss": 2.2759,
      "step": 608460
    },
    {
      "epoch": 978.26,
      "learning_rate": 0.002213602609646301,
      "loss": 2.2662,
      "step": 608480
    },
    {
      "epoch": 978.3,
      "learning_rate": 0.002210387178778132,
      "loss": 2.2764,
      "step": 608500
    },
    {
      "epoch": 978.33,
      "learning_rate": 0.002207171747909963,
      "loss": 2.2991,
      "step": 608520
    },
    {
      "epoch": 978.36,
      "learning_rate": 0.0022039563170418047,
      "loss": 2.2946,
      "step": 608540
    },
    {
      "epoch": 978.39,
      "learning_rate": 0.002200740886173636,
      "loss": 2.2772,
      "step": 608560
    },
    {
      "epoch": 978.42,
      "learning_rate": 0.0021975254553054666,
      "loss": 2.2997,
      "step": 608580
    },
    {
      "epoch": 978.46,
      "learning_rate": 0.0021943100244372973,
      "loss": 2.2906,
      "step": 608600
    },
    {
      "epoch": 978.49,
      "learning_rate": 0.002191094593569128,
      "loss": 2.2746,
      "step": 608620
    },
    {
      "epoch": 978.52,
      "learning_rate": 0.002187879162700959,
      "loss": 2.2747,
      "step": 608640
    },
    {
      "epoch": 978.55,
      "learning_rate": 0.002184663731832801,
      "loss": 2.2739,
      "step": 608660
    },
    {
      "epoch": 978.59,
      "learning_rate": 0.0021814483009646316,
      "loss": 2.2714,
      "step": 608680
    },
    {
      "epoch": 978.62,
      "learning_rate": 0.0021782328700964628,
      "loss": 2.3057,
      "step": 608700
    },
    {
      "epoch": 978.65,
      "learning_rate": 0.0021750174392282935,
      "loss": 2.2786,
      "step": 608720
    },
    {
      "epoch": 978.68,
      "learning_rate": 0.0021718020083601242,
      "loss": 2.2698,
      "step": 608740
    },
    {
      "epoch": 978.71,
      "learning_rate": 0.0021685865774919663,
      "loss": 2.2969,
      "step": 608760
    },
    {
      "epoch": 978.75,
      "learning_rate": 0.002165371146623797,
      "loss": 2.2761,
      "step": 608780
    },
    {
      "epoch": 978.78,
      "learning_rate": 0.0021621557157556278,
      "loss": 2.2743,
      "step": 608800
    },
    {
      "epoch": 978.81,
      "learning_rate": 0.0021589402848874585,
      "loss": 2.2952,
      "step": 608820
    },
    {
      "epoch": 978.84,
      "learning_rate": 0.0021557248540192897,
      "loss": 2.2788,
      "step": 608840
    },
    {
      "epoch": 978.87,
      "learning_rate": 0.0021525094231511204,
      "loss": 2.2884,
      "step": 608860
    },
    {
      "epoch": 978.91,
      "learning_rate": 0.0021492939922829624,
      "loss": 2.2751,
      "step": 608880
    },
    {
      "epoch": 978.94,
      "learning_rate": 0.002146078561414793,
      "loss": 2.2958,
      "step": 608900
    },
    {
      "epoch": 978.97,
      "learning_rate": 0.002142863130546624,
      "loss": 2.3001,
      "step": 608920
    },
    {
      "epoch": 979.0,
      "eval_accuracy": {
        "accuracy": 0.49117624193423
      },
      "eval_loss": 2.4020273685455322,
      "eval_runtime": 3.1958,
      "eval_samples_per_second": 4024.94,
      "eval_steps_per_second": 62.895,
      "step": 608938
    },
    {
      "epoch": 979.0,
      "learning_rate": 0.0021396476996784547,
      "loss": 2.2789,
      "step": 608940
    },
    {
      "epoch": 979.04,
      "learning_rate": 0.0021364322688102854,
      "loss": 2.2974,
      "step": 608960
    },
    {
      "epoch": 979.07,
      "learning_rate": 0.0021332168379421274,
      "loss": 2.277,
      "step": 608980
    },
    {
      "epoch": 979.1,
      "learning_rate": 0.002130001407073958,
      "loss": 2.2886,
      "step": 609000
    },
    {
      "epoch": 979.13,
      "learning_rate": 0.0021267859762057893,
      "loss": 2.288,
      "step": 609020
    },
    {
      "epoch": 979.16,
      "learning_rate": 0.00212357054533762,
      "loss": 2.2695,
      "step": 609040
    },
    {
      "epoch": 979.2,
      "learning_rate": 0.002120355114469451,
      "loss": 2.2862,
      "step": 609060
    },
    {
      "epoch": 979.23,
      "learning_rate": 0.0021171396836012816,
      "loss": 2.2778,
      "step": 609080
    },
    {
      "epoch": 979.26,
      "learning_rate": 0.0021139242527331236,
      "loss": 2.2836,
      "step": 609100
    },
    {
      "epoch": 979.29,
      "learning_rate": 0.0021107088218649543,
      "loss": 2.2772,
      "step": 609120
    },
    {
      "epoch": 979.32,
      "learning_rate": 0.0021074933909967855,
      "loss": 2.2875,
      "step": 609140
    },
    {
      "epoch": 979.36,
      "learning_rate": 0.0021042779601286163,
      "loss": 2.2909,
      "step": 609160
    },
    {
      "epoch": 979.39,
      "learning_rate": 0.002101062529260447,
      "loss": 2.2883,
      "step": 609180
    },
    {
      "epoch": 979.42,
      "learning_rate": 0.0020978470983922777,
      "loss": 2.2745,
      "step": 609200
    },
    {
      "epoch": 979.45,
      "learning_rate": 0.0020946316675241198,
      "loss": 2.2912,
      "step": 609220
    },
    {
      "epoch": 979.49,
      "learning_rate": 0.0020914162366559505,
      "loss": 2.2943,
      "step": 609240
    },
    {
      "epoch": 979.52,
      "learning_rate": 0.0020882008057877812,
      "loss": 2.2946,
      "step": 609260
    },
    {
      "epoch": 979.55,
      "learning_rate": 0.0020849853749196124,
      "loss": 2.2627,
      "step": 609280
    },
    {
      "epoch": 979.58,
      "learning_rate": 0.002081769944051443,
      "loss": 2.2686,
      "step": 609300
    },
    {
      "epoch": 979.61,
      "learning_rate": 0.002078554513183285,
      "loss": 2.2951,
      "step": 609320
    },
    {
      "epoch": 979.65,
      "learning_rate": 0.002075339082315116,
      "loss": 2.2817,
      "step": 609340
    },
    {
      "epoch": 979.68,
      "learning_rate": 0.0020721236514469467,
      "loss": 2.2793,
      "step": 609360
    },
    {
      "epoch": 979.71,
      "learning_rate": 0.0020689082205787774,
      "loss": 2.3055,
      "step": 609380
    },
    {
      "epoch": 979.74,
      "learning_rate": 0.002065692789710608,
      "loss": 2.2928,
      "step": 609400
    },
    {
      "epoch": 979.77,
      "learning_rate": 0.0020624773588424393,
      "loss": 2.2684,
      "step": 609420
    },
    {
      "epoch": 979.81,
      "learning_rate": 0.002059261927974281,
      "loss": 2.2919,
      "step": 609440
    },
    {
      "epoch": 979.84,
      "learning_rate": 0.002056046497106112,
      "loss": 2.292,
      "step": 609460
    },
    {
      "epoch": 979.87,
      "learning_rate": 0.002052831066237943,
      "loss": 2.2897,
      "step": 609480
    },
    {
      "epoch": 979.9,
      "learning_rate": 0.0020496156353697736,
      "loss": 2.2807,
      "step": 609500
    },
    {
      "epoch": 979.94,
      "learning_rate": 0.0020464002045016043,
      "loss": 2.2912,
      "step": 609520
    },
    {
      "epoch": 979.97,
      "learning_rate": 0.002043184773633435,
      "loss": 2.275,
      "step": 609540
    },
    {
      "epoch": 980.0,
      "learning_rate": 0.002039969342765277,
      "loss": 2.2733,
      "step": 609560
    },
    {
      "epoch": 980.0,
      "eval_accuracy": {
        "accuracy": 0.49102075721060406
      },
      "eval_loss": 2.4022886753082275,
      "eval_runtime": 3.2531,
      "eval_samples_per_second": 3954.113,
      "eval_steps_per_second": 61.788,
      "step": 609560
    },
    {
      "epoch": 980.03,
      "learning_rate": 0.002036753911897108,
      "loss": 2.3009,
      "step": 609580
    },
    {
      "epoch": 980.06,
      "learning_rate": 0.002033538481028939,
      "loss": 2.304,
      "step": 609600
    },
    {
      "epoch": 980.1,
      "learning_rate": 0.0020303230501607697,
      "loss": 2.2805,
      "step": 609620
    },
    {
      "epoch": 980.13,
      "learning_rate": 0.0020271076192926005,
      "loss": 2.2804,
      "step": 609640
    },
    {
      "epoch": 980.16,
      "learning_rate": 0.0020238921884244425,
      "loss": 2.2856,
      "step": 609660
    },
    {
      "epoch": 980.19,
      "learning_rate": 0.0020206767575562733,
      "loss": 2.2727,
      "step": 609680
    },
    {
      "epoch": 980.23,
      "learning_rate": 0.002017461326688104,
      "loss": 2.286,
      "step": 609700
    },
    {
      "epoch": 980.26,
      "learning_rate": 0.0020142458958199347,
      "loss": 2.276,
      "step": 609720
    },
    {
      "epoch": 980.29,
      "learning_rate": 0.002011030464951766,
      "loss": 2.2797,
      "step": 609740
    },
    {
      "epoch": 980.32,
      "learning_rate": 0.0020078150340835967,
      "loss": 2.2596,
      "step": 609760
    },
    {
      "epoch": 980.35,
      "learning_rate": 0.0020045996032154387,
      "loss": 2.2748,
      "step": 609780
    },
    {
      "epoch": 980.39,
      "learning_rate": 0.0020013841723472694,
      "loss": 2.2625,
      "step": 609800
    },
    {
      "epoch": 980.42,
      "learning_rate": 0.0019981687414791,
      "loss": 2.2905,
      "step": 609820
    },
    {
      "epoch": 980.45,
      "learning_rate": 0.001994953310610931,
      "loss": 2.2665,
      "step": 609840
    },
    {
      "epoch": 980.48,
      "learning_rate": 0.0019917378797427616,
      "loss": 2.2728,
      "step": 609860
    },
    {
      "epoch": 980.51,
      "learning_rate": 0.001988522448874593,
      "loss": 2.2945,
      "step": 609880
    },
    {
      "epoch": 980.55,
      "learning_rate": 0.0019853070180064344,
      "loss": 2.2969,
      "step": 609900
    },
    {
      "epoch": 980.58,
      "learning_rate": 0.0019820915871382656,
      "loss": 2.2864,
      "step": 609920
    },
    {
      "epoch": 980.61,
      "learning_rate": 0.0019788761562700963,
      "loss": 2.2782,
      "step": 609940
    },
    {
      "epoch": 980.64,
      "learning_rate": 0.001975660725401927,
      "loss": 2.2803,
      "step": 609960
    },
    {
      "epoch": 980.68,
      "learning_rate": 0.001972445294533758,
      "loss": 2.2857,
      "step": 609980
    },
    {
      "epoch": 980.71,
      "learning_rate": 0.0019692298636656,
      "loss": 2.306,
      "step": 610000
    },
    {
      "epoch": 980.74,
      "learning_rate": 0.0019660144327974306,
      "loss": 2.2633,
      "step": 610020
    },
    {
      "epoch": 980.77,
      "learning_rate": 0.0019627990019292613,
      "loss": 2.2939,
      "step": 610040
    },
    {
      "epoch": 980.8,
      "learning_rate": 0.0019595835710610925,
      "loss": 2.2919,
      "step": 610060
    },
    {
      "epoch": 980.84,
      "learning_rate": 0.0019563681401929232,
      "loss": 2.2885,
      "step": 610080
    },
    {
      "epoch": 980.87,
      "learning_rate": 0.001953152709324754,
      "loss": 2.2838,
      "step": 610100
    },
    {
      "epoch": 980.9,
      "learning_rate": 0.0019499372784565962,
      "loss": 2.2795,
      "step": 610120
    },
    {
      "epoch": 980.93,
      "learning_rate": 0.0019467218475884267,
      "loss": 2.2763,
      "step": 610140
    },
    {
      "epoch": 980.96,
      "learning_rate": 0.0019435064167202577,
      "loss": 2.2999,
      "step": 610160
    },
    {
      "epoch": 981.0,
      "learning_rate": 0.0019402909858520887,
      "loss": 2.2873,
      "step": 610180
    },
    {
      "epoch": 981.0,
      "eval_accuracy": {
        "accuracy": 0.489543652336158
      },
      "eval_loss": 2.4031991958618164,
      "eval_runtime": 3.2866,
      "eval_samples_per_second": 3913.752,
      "eval_steps_per_second": 61.157,
      "step": 610182
    },
    {
      "epoch": 981.03,
      "learning_rate": 0.0019370755549839192,
      "loss": 2.2749,
      "step": 610200
    },
    {
      "epoch": 981.06,
      "learning_rate": 0.0019338601241157506,
      "loss": 2.2892,
      "step": 610220
    },
    {
      "epoch": 981.09,
      "learning_rate": 0.0019306446932475922,
      "loss": 2.2791,
      "step": 610240
    },
    {
      "epoch": 981.13,
      "learning_rate": 0.0019274292623794231,
      "loss": 2.2899,
      "step": 610260
    },
    {
      "epoch": 981.16,
      "learning_rate": 0.001924213831511254,
      "loss": 2.285,
      "step": 610280
    },
    {
      "epoch": 981.19,
      "learning_rate": 0.0019209984006430848,
      "loss": 2.2811,
      "step": 610300
    },
    {
      "epoch": 981.22,
      "learning_rate": 0.0019177829697749156,
      "loss": 2.2796,
      "step": 610320
    },
    {
      "epoch": 981.25,
      "learning_rate": 0.0019145675389067576,
      "loss": 2.2982,
      "step": 610340
    },
    {
      "epoch": 981.29,
      "learning_rate": 0.0019113521080385883,
      "loss": 2.2722,
      "step": 610360
    },
    {
      "epoch": 981.32,
      "learning_rate": 0.001908136677170419,
      "loss": 2.2706,
      "step": 610380
    },
    {
      "epoch": 981.35,
      "learning_rate": 0.0019049212463022498,
      "loss": 2.2918,
      "step": 610400
    },
    {
      "epoch": 981.38,
      "learning_rate": 0.0019017058154340808,
      "loss": 2.2875,
      "step": 610420
    },
    {
      "epoch": 981.41,
      "learning_rate": 0.0018984903845659117,
      "loss": 2.2842,
      "step": 610440
    },
    {
      "epoch": 981.45,
      "learning_rate": 0.0018952749536977533,
      "loss": 2.2732,
      "step": 610460
    },
    {
      "epoch": 981.48,
      "learning_rate": 0.0018920595228295843,
      "loss": 2.2802,
      "step": 610480
    },
    {
      "epoch": 981.51,
      "learning_rate": 0.0018888440919614152,
      "loss": 2.2812,
      "step": 610500
    },
    {
      "epoch": 981.54,
      "learning_rate": 0.0018856286610932458,
      "loss": 2.2884,
      "step": 610520
    },
    {
      "epoch": 981.58,
      "learning_rate": 0.0018824132302250772,
      "loss": 2.2663,
      "step": 610540
    },
    {
      "epoch": 981.61,
      "learning_rate": 0.0018791977993569077,
      "loss": 2.3048,
      "step": 610560
    },
    {
      "epoch": 981.64,
      "learning_rate": 0.0018759823684887497,
      "loss": 2.2617,
      "step": 610580
    },
    {
      "epoch": 981.67,
      "learning_rate": 0.0018727669376205807,
      "loss": 2.2758,
      "step": 610600
    },
    {
      "epoch": 981.7,
      "learning_rate": 0.0018695515067524114,
      "loss": 2.2696,
      "step": 610620
    },
    {
      "epoch": 981.74,
      "learning_rate": 0.0018663360758842422,
      "loss": 2.3015,
      "step": 610640
    },
    {
      "epoch": 981.77,
      "learning_rate": 0.001863120645016073,
      "loss": 2.2757,
      "step": 610660
    },
    {
      "epoch": 981.8,
      "learning_rate": 0.001859905214147915,
      "loss": 2.2786,
      "step": 610680
    },
    {
      "epoch": 981.83,
      "learning_rate": 0.0018566897832797459,
      "loss": 2.2805,
      "step": 610700
    },
    {
      "epoch": 981.86,
      "learning_rate": 0.0018534743524115764,
      "loss": 2.2821,
      "step": 610720
    },
    {
      "epoch": 981.9,
      "learning_rate": 0.0018502589215434074,
      "loss": 2.2919,
      "step": 610740
    },
    {
      "epoch": 981.93,
      "learning_rate": 0.0018470434906752383,
      "loss": 2.2865,
      "step": 610760
    },
    {
      "epoch": 981.96,
      "learning_rate": 0.0018438280598070688,
      "loss": 2.286,
      "step": 610780
    },
    {
      "epoch": 981.99,
      "learning_rate": 0.0018406126289389109,
      "loss": 2.2892,
      "step": 610800
    },
    {
      "epoch": 982.0,
      "eval_accuracy": {
        "accuracy": 0.4885330016325896
      },
      "eval_loss": 2.399144411087036,
      "eval_runtime": 3.1131,
      "eval_samples_per_second": 4131.919,
      "eval_steps_per_second": 64.566,
      "step": 610804
    },
    {
      "epoch": 982.03,
      "learning_rate": 0.0018373971980707418,
      "loss": 2.2841,
      "step": 610820
    },
    {
      "epoch": 982.06,
      "learning_rate": 0.0018341817672025728,
      "loss": 2.294,
      "step": 610840
    },
    {
      "epoch": 982.09,
      "learning_rate": 0.0018309663363344037,
      "loss": 2.2664,
      "step": 610860
    },
    {
      "epoch": 982.12,
      "learning_rate": 0.0018277509054662343,
      "loss": 2.2757,
      "step": 610880
    },
    {
      "epoch": 982.15,
      "learning_rate": 0.0018245354745980763,
      "loss": 2.3095,
      "step": 610900
    },
    {
      "epoch": 982.19,
      "learning_rate": 0.0018213200437299073,
      "loss": 2.2696,
      "step": 610920
    },
    {
      "epoch": 982.22,
      "learning_rate": 0.001818104612861738,
      "loss": 2.2714,
      "step": 610940
    },
    {
      "epoch": 982.25,
      "learning_rate": 0.0018148891819935687,
      "loss": 2.2669,
      "step": 610960
    },
    {
      "epoch": 982.28,
      "learning_rate": 0.0018116737511253995,
      "loss": 2.2689,
      "step": 610980
    },
    {
      "epoch": 982.32,
      "learning_rate": 0.0018084583202572304,
      "loss": 2.2944,
      "step": 611000
    },
    {
      "epoch": 982.35,
      "learning_rate": 0.0018052428893890725,
      "loss": 2.2848,
      "step": 611020
    },
    {
      "epoch": 982.38,
      "learning_rate": 0.001802027458520903,
      "loss": 2.2769,
      "step": 611040
    },
    {
      "epoch": 982.41,
      "learning_rate": 0.001798812027652734,
      "loss": 2.278,
      "step": 611060
    },
    {
      "epoch": 982.44,
      "learning_rate": 0.001795596596784565,
      "loss": 2.2972,
      "step": 611080
    },
    {
      "epoch": 982.48,
      "learning_rate": 0.0017923811659163954,
      "loss": 2.294,
      "step": 611100
    },
    {
      "epoch": 982.51,
      "learning_rate": 0.0017891657350482268,
      "loss": 2.2747,
      "step": 611120
    },
    {
      "epoch": 982.54,
      "learning_rate": 0.0017859503041800684,
      "loss": 2.2875,
      "step": 611140
    },
    {
      "epoch": 982.57,
      "learning_rate": 0.0017827348733118994,
      "loss": 2.2958,
      "step": 611160
    },
    {
      "epoch": 982.6,
      "learning_rate": 0.0017795194424437303,
      "loss": 2.2893,
      "step": 611180
    },
    {
      "epoch": 982.64,
      "learning_rate": 0.0017763040115755609,
      "loss": 2.294,
      "step": 611200
    },
    {
      "epoch": 982.67,
      "learning_rate": 0.0017730885807073918,
      "loss": 2.2841,
      "step": 611220
    },
    {
      "epoch": 982.7,
      "learning_rate": 0.0017698731498392338,
      "loss": 2.2712,
      "step": 611240
    },
    {
      "epoch": 982.73,
      "learning_rate": 0.0017666577189710646,
      "loss": 2.2658,
      "step": 611260
    },
    {
      "epoch": 982.77,
      "learning_rate": 0.0017634422881028953,
      "loss": 2.2711,
      "step": 611280
    },
    {
      "epoch": 982.8,
      "learning_rate": 0.001760226857234726,
      "loss": 2.2928,
      "step": 611300
    },
    {
      "epoch": 982.83,
      "learning_rate": 0.001757011426366557,
      "loss": 2.2779,
      "step": 611320
    },
    {
      "epoch": 982.86,
      "learning_rate": 0.001753795995498388,
      "loss": 2.2626,
      "step": 611340
    },
    {
      "epoch": 982.89,
      "learning_rate": 0.0017505805646302296,
      "loss": 2.2863,
      "step": 611360
    },
    {
      "epoch": 982.93,
      "learning_rate": 0.0017473651337620605,
      "loss": 2.291,
      "step": 611380
    },
    {
      "epoch": 982.96,
      "learning_rate": 0.0017441497028938915,
      "loss": 2.2937,
      "step": 611400
    },
    {
      "epoch": 982.99,
      "learning_rate": 0.001740934272025722,
      "loss": 2.2742,
      "step": 611420
    },
    {
      "epoch": 983.0,
      "eval_accuracy": {
        "accuracy": 0.4904765606779134
      },
      "eval_loss": 2.39902400970459,
      "eval_runtime": 3.3237,
      "eval_samples_per_second": 3870.041,
      "eval_steps_per_second": 60.474,
      "step": 611426
    },
    {
      "epoch": 983.02,
      "learning_rate": 0.0017377188411575534,
      "loss": 2.2812,
      "step": 611440
    },
    {
      "epoch": 983.05,
      "learning_rate": 0.001734503410289384,
      "loss": 2.277,
      "step": 611460
    },
    {
      "epoch": 983.09,
      "learning_rate": 0.001731287979421226,
      "loss": 2.2851,
      "step": 611480
    },
    {
      "epoch": 983.12,
      "learning_rate": 0.001728072548553057,
      "loss": 2.291,
      "step": 611500
    },
    {
      "epoch": 983.15,
      "learning_rate": 0.0017248571176848877,
      "loss": 2.2872,
      "step": 611520
    },
    {
      "epoch": 983.18,
      "learning_rate": 0.0017216416868167184,
      "loss": 2.2823,
      "step": 611540
    },
    {
      "epoch": 983.22,
      "learning_rate": 0.0017184262559485491,
      "loss": 2.2734,
      "step": 611560
    },
    {
      "epoch": 983.25,
      "learning_rate": 0.0017152108250803912,
      "loss": 2.2847,
      "step": 611580
    },
    {
      "epoch": 983.28,
      "learning_rate": 0.001711995394212222,
      "loss": 2.29,
      "step": 611600
    },
    {
      "epoch": 983.31,
      "learning_rate": 0.0017087799633440526,
      "loss": 2.2874,
      "step": 611620
    },
    {
      "epoch": 983.34,
      "learning_rate": 0.0017055645324758836,
      "loss": 2.2879,
      "step": 611640
    },
    {
      "epoch": 983.38,
      "learning_rate": 0.0017023491016077146,
      "loss": 2.2843,
      "step": 611660
    },
    {
      "epoch": 983.41,
      "learning_rate": 0.001699133670739545,
      "loss": 2.2765,
      "step": 611680
    },
    {
      "epoch": 983.44,
      "learning_rate": 0.0016959182398713871,
      "loss": 2.2722,
      "step": 611700
    },
    {
      "epoch": 983.47,
      "learning_rate": 0.001692702809003218,
      "loss": 2.2794,
      "step": 611720
    },
    {
      "epoch": 983.5,
      "learning_rate": 0.0016894873781350486,
      "loss": 2.2953,
      "step": 611740
    },
    {
      "epoch": 983.54,
      "learning_rate": 0.00168627194726688,
      "loss": 2.2896,
      "step": 611760
    },
    {
      "epoch": 983.57,
      "learning_rate": 0.0016830565163987105,
      "loss": 2.2683,
      "step": 611780
    },
    {
      "epoch": 983.6,
      "learning_rate": 0.0016798410855305415,
      "loss": 2.2846,
      "step": 611800
    },
    {
      "epoch": 983.63,
      "learning_rate": 0.0016766256546623835,
      "loss": 2.2731,
      "step": 611820
    },
    {
      "epoch": 983.67,
      "learning_rate": 0.0016735709953376251,
      "loss": 2.2759,
      "step": 611840
    },
    {
      "epoch": 983.7,
      "learning_rate": 0.0016703555644694565,
      "loss": 2.2746,
      "step": 611860
    },
    {
      "epoch": 983.73,
      "learning_rate": 0.001667140133601287,
      "loss": 2.279,
      "step": 611880
    },
    {
      "epoch": 983.76,
      "learning_rate": 0.001663924702733118,
      "loss": 2.2874,
      "step": 611900
    },
    {
      "epoch": 983.79,
      "learning_rate": 0.0016607092718649488,
      "loss": 2.2734,
      "step": 611920
    },
    {
      "epoch": 983.83,
      "learning_rate": 0.0016574938409967795,
      "loss": 2.2645,
      "step": 611940
    },
    {
      "epoch": 983.86,
      "learning_rate": 0.0016542784101286215,
      "loss": 2.2807,
      "step": 611960
    },
    {
      "epoch": 983.89,
      "learning_rate": 0.0016510629792604523,
      "loss": 2.2896,
      "step": 611980
    },
    {
      "epoch": 983.92,
      "learning_rate": 0.0016478475483922832,
      "loss": 2.2696,
      "step": 612000
    },
    {
      "epoch": 983.95,
      "learning_rate": 0.0016446321175241137,
      "loss": 2.2778,
      "step": 612020
    },
    {
      "epoch": 983.99,
      "learning_rate": 0.0016414166866559447,
      "loss": 2.2852,
      "step": 612040
    },
    {
      "epoch": 984.0,
      "eval_accuracy": {
        "accuracy": 0.489543652336158
      },
      "eval_loss": 2.398980140686035,
      "eval_runtime": 3.1732,
      "eval_samples_per_second": 4053.637,
      "eval_steps_per_second": 63.343,
      "step": 612048
    },
    {
      "epoch": 984.02,
      "learning_rate": 0.0016382012557877867,
      "loss": 2.2631,
      "step": 612060
    },
    {
      "epoch": 984.05,
      "learning_rate": 0.0016349858249196177,
      "loss": 2.2758,
      "step": 612080
    },
    {
      "epoch": 984.08,
      "learning_rate": 0.0016317703940514482,
      "loss": 2.2682,
      "step": 612100
    },
    {
      "epoch": 984.12,
      "learning_rate": 0.0016285549631832792,
      "loss": 2.2759,
      "step": 612120
    },
    {
      "epoch": 984.15,
      "learning_rate": 0.0016253395323151101,
      "loss": 2.2744,
      "step": 612140
    },
    {
      "epoch": 984.18,
      "learning_rate": 0.001622124101446941,
      "loss": 2.2924,
      "step": 612160
    },
    {
      "epoch": 984.21,
      "learning_rate": 0.001618908670578783,
      "loss": 2.29,
      "step": 612180
    },
    {
      "epoch": 984.24,
      "learning_rate": 0.0016156932397106136,
      "loss": 2.2978,
      "step": 612200
    },
    {
      "epoch": 984.28,
      "learning_rate": 0.0016124778088424446,
      "loss": 2.2906,
      "step": 612220
    },
    {
      "epoch": 984.31,
      "learning_rate": 0.0016092623779742753,
      "loss": 2.2608,
      "step": 612240
    },
    {
      "epoch": 984.34,
      "learning_rate": 0.001606046947106106,
      "loss": 2.3163,
      "step": 612260
    },
    {
      "epoch": 984.37,
      "learning_rate": 0.0016028315162379368,
      "loss": 2.2788,
      "step": 612280
    },
    {
      "epoch": 984.41,
      "learning_rate": 0.0015996160853697788,
      "loss": 2.2677,
      "step": 612300
    },
    {
      "epoch": 984.44,
      "learning_rate": 0.0015964006545016098,
      "loss": 2.2794,
      "step": 612320
    },
    {
      "epoch": 984.47,
      "learning_rate": 0.0015931852236334403,
      "loss": 2.2725,
      "step": 612340
    },
    {
      "epoch": 984.5,
      "learning_rate": 0.0015899697927652713,
      "loss": 2.3014,
      "step": 612360
    },
    {
      "epoch": 984.53,
      "learning_rate": 0.0015867543618971022,
      "loss": 2.2779,
      "step": 612380
    },
    {
      "epoch": 984.57,
      "learning_rate": 0.0015835389310289443,
      "loss": 2.2758,
      "step": 612400
    },
    {
      "epoch": 984.6,
      "learning_rate": 0.0015803235001607748,
      "loss": 2.2844,
      "step": 612420
    },
    {
      "epoch": 984.63,
      "learning_rate": 0.0015771080692926057,
      "loss": 2.2861,
      "step": 612440
    },
    {
      "epoch": 984.66,
      "learning_rate": 0.0015738926384244367,
      "loss": 2.2654,
      "step": 612460
    },
    {
      "epoch": 984.69,
      "learning_rate": 0.0015706772075562677,
      "loss": 2.2866,
      "step": 612480
    },
    {
      "epoch": 984.73,
      "learning_rate": 0.0015674617766880984,
      "loss": 2.2828,
      "step": 612500
    },
    {
      "epoch": 984.76,
      "learning_rate": 0.0015642463458199402,
      "loss": 2.2617,
      "step": 612520
    },
    {
      "epoch": 984.79,
      "learning_rate": 0.0015610309149517712,
      "loss": 2.2708,
      "step": 612540
    },
    {
      "epoch": 984.82,
      "learning_rate": 0.001557815484083602,
      "loss": 2.2871,
      "step": 612560
    },
    {
      "epoch": 984.86,
      "learning_rate": 0.0015546000532154327,
      "loss": 2.2762,
      "step": 612580
    },
    {
      "epoch": 984.89,
      "learning_rate": 0.0015513846223472636,
      "loss": 2.2661,
      "step": 612600
    },
    {
      "epoch": 984.92,
      "learning_rate": 0.0015481691914790944,
      "loss": 2.2956,
      "step": 612620
    },
    {
      "epoch": 984.95,
      "learning_rate": 0.0015449537606109364,
      "loss": 2.2684,
      "step": 612640
    },
    {
      "epoch": 984.98,
      "learning_rate": 0.0015417383297427671,
      "loss": 2.2712,
      "step": 612660
    },
    {
      "epoch": 985.0,
      "eval_accuracy": {
        "accuracy": 0.4914094690196688
      },
      "eval_loss": 2.40053129196167,
      "eval_runtime": 3.1718,
      "eval_samples_per_second": 4055.429,
      "eval_steps_per_second": 63.371,
      "step": 612670
    },
    {
      "epoch": 985.02,
      "learning_rate": 0.001538522898874598,
      "loss": 2.2843,
      "step": 612680
    },
    {
      "epoch": 985.05,
      "learning_rate": 0.0015353074680064288,
      "loss": 2.2638,
      "step": 612700
    },
    {
      "epoch": 985.08,
      "learning_rate": 0.0015320920371382598,
      "loss": 2.2711,
      "step": 612720
    },
    {
      "epoch": 985.11,
      "learning_rate": 0.0015288766062701016,
      "loss": 2.2677,
      "step": 612740
    },
    {
      "epoch": 985.14,
      "learning_rate": 0.0015256611754019325,
      "loss": 2.2738,
      "step": 612760
    },
    {
      "epoch": 985.18,
      "learning_rate": 0.0015224457445337633,
      "loss": 2.2709,
      "step": 612780
    },
    {
      "epoch": 985.21,
      "learning_rate": 0.001519230313665594,
      "loss": 2.2799,
      "step": 612800
    },
    {
      "epoch": 985.24,
      "learning_rate": 0.001516014882797425,
      "loss": 2.2814,
      "step": 612820
    },
    {
      "epoch": 985.27,
      "learning_rate": 0.0015127994519292557,
      "loss": 2.2813,
      "step": 612840
    },
    {
      "epoch": 985.31,
      "learning_rate": 0.0015095840210610978,
      "loss": 2.2892,
      "step": 612860
    },
    {
      "epoch": 985.34,
      "learning_rate": 0.0015063685901929285,
      "loss": 2.2759,
      "step": 612880
    },
    {
      "epoch": 985.37,
      "learning_rate": 0.0015031531593247595,
      "loss": 2.2798,
      "step": 612900
    },
    {
      "epoch": 985.4,
      "learning_rate": 0.0014999377284565902,
      "loss": 2.2755,
      "step": 612920
    },
    {
      "epoch": 985.43,
      "learning_rate": 0.001496722297588421,
      "loss": 2.2774,
      "step": 612940
    },
    {
      "epoch": 985.47,
      "learning_rate": 0.001493506866720252,
      "loss": 2.273,
      "step": 612960
    },
    {
      "epoch": 985.5,
      "learning_rate": 0.0014902914358520937,
      "loss": 2.2806,
      "step": 612980
    },
    {
      "epoch": 985.53,
      "learning_rate": 0.0014870760049839247,
      "loss": 2.2912,
      "step": 613000
    },
    {
      "epoch": 985.56,
      "learning_rate": 0.0014838605741157554,
      "loss": 2.2955,
      "step": 613020
    },
    {
      "epoch": 985.59,
      "learning_rate": 0.0014806451432475864,
      "loss": 2.2899,
      "step": 613040
    },
    {
      "epoch": 985.63,
      "learning_rate": 0.0014774297123794171,
      "loss": 2.302,
      "step": 613060
    },
    {
      "epoch": 985.66,
      "learning_rate": 0.0014742142815112591,
      "loss": 2.2836,
      "step": 613080
    },
    {
      "epoch": 985.69,
      "learning_rate": 0.0014709988506430899,
      "loss": 2.268,
      "step": 613100
    },
    {
      "epoch": 985.72,
      "learning_rate": 0.0014677834197749206,
      "loss": 2.248,
      "step": 613120
    },
    {
      "epoch": 985.76,
      "learning_rate": 0.0014645679889067516,
      "loss": 2.2808,
      "step": 613140
    },
    {
      "epoch": 985.79,
      "learning_rate": 0.0014613525580385823,
      "loss": 2.2793,
      "step": 613160
    },
    {
      "epoch": 985.82,
      "learning_rate": 0.0014581371271704133,
      "loss": 2.2723,
      "step": 613180
    },
    {
      "epoch": 985.85,
      "learning_rate": 0.001454921696302255,
      "loss": 2.2884,
      "step": 613200
    },
    {
      "epoch": 985.88,
      "learning_rate": 0.001451706265434086,
      "loss": 2.276,
      "step": 613220
    },
    {
      "epoch": 985.92,
      "learning_rate": 0.0014484908345659168,
      "loss": 2.2888,
      "step": 613240
    },
    {
      "epoch": 985.95,
      "learning_rate": 0.0014452754036977475,
      "loss": 2.2854,
      "step": 613260
    },
    {
      "epoch": 985.98,
      "learning_rate": 0.0014420599728295785,
      "loss": 2.2808,
      "step": 613280
    },
    {
      "epoch": 986.0,
      "eval_accuracy": {
        "accuracy": 0.49203140791417244
      },
      "eval_loss": 2.396307945251465,
      "eval_runtime": 3.5791,
      "eval_samples_per_second": 3593.928,
      "eval_steps_per_second": 56.159,
      "step": 613292
    },
    {
      "epoch": 986.01,
      "learning_rate": 0.0014388445419614203,
      "loss": 2.2733,
      "step": 613300
    },
    {
      "epoch": 986.05,
      "learning_rate": 0.0014356291110932512,
      "loss": 2.2859,
      "step": 613320
    },
    {
      "epoch": 986.08,
      "learning_rate": 0.001432413680225082,
      "loss": 2.2814,
      "step": 613340
    },
    {
      "epoch": 986.11,
      "learning_rate": 0.001429198249356913,
      "loss": 2.2883,
      "step": 613360
    },
    {
      "epoch": 986.14,
      "learning_rate": 0.0014259828184887437,
      "loss": 2.2651,
      "step": 613380
    },
    {
      "epoch": 986.17,
      "learning_rate": 0.0014227673876205747,
      "loss": 2.2819,
      "step": 613400
    },
    {
      "epoch": 986.21,
      "learning_rate": 0.0014195519567524165,
      "loss": 2.2731,
      "step": 613420
    },
    {
      "epoch": 986.24,
      "learning_rate": 0.0014163365258842474,
      "loss": 2.2593,
      "step": 613440
    },
    {
      "epoch": 986.27,
      "learning_rate": 0.0014131210950160782,
      "loss": 2.2752,
      "step": 613460
    },
    {
      "epoch": 986.3,
      "learning_rate": 0.001409905664147909,
      "loss": 2.271,
      "step": 613480
    },
    {
      "epoch": 986.33,
      "learning_rate": 0.0014066902332797399,
      "loss": 2.2711,
      "step": 613500
    },
    {
      "epoch": 986.37,
      "learning_rate": 0.0014034748024115706,
      "loss": 2.2705,
      "step": 613520
    },
    {
      "epoch": 986.4,
      "learning_rate": 0.0014004201430868127,
      "loss": 2.2755,
      "step": 613540
    },
    {
      "epoch": 986.43,
      "learning_rate": 0.0013972047122186547,
      "loss": 2.2594,
      "step": 613560
    },
    {
      "epoch": 986.46,
      "learning_rate": 0.0013939892813504854,
      "loss": 2.2786,
      "step": 613580
    },
    {
      "epoch": 986.5,
      "learning_rate": 0.0013907738504823164,
      "loss": 2.2797,
      "step": 613600
    },
    {
      "epoch": 986.53,
      "learning_rate": 0.0013875584196141471,
      "loss": 2.286,
      "step": 613620
    },
    {
      "epoch": 986.56,
      "learning_rate": 0.0013843429887459779,
      "loss": 2.2702,
      "step": 613640
    },
    {
      "epoch": 986.59,
      "learning_rate": 0.0013811275578778088,
      "loss": 2.284,
      "step": 613660
    },
    {
      "epoch": 986.62,
      "learning_rate": 0.0013779121270096506,
      "loss": 2.2816,
      "step": 613680
    },
    {
      "epoch": 986.66,
      "learning_rate": 0.0013746966961414816,
      "loss": 2.3014,
      "step": 613700
    },
    {
      "epoch": 986.69,
      "learning_rate": 0.0013714812652733123,
      "loss": 2.2882,
      "step": 613720
    },
    {
      "epoch": 986.72,
      "learning_rate": 0.0013682658344051433,
      "loss": 2.2853,
      "step": 613740
    },
    {
      "epoch": 986.75,
      "learning_rate": 0.001365050403536974,
      "loss": 2.2626,
      "step": 613760
    },
    {
      "epoch": 986.78,
      "learning_rate": 0.0013618349726688048,
      "loss": 2.2785,
      "step": 613780
    },
    {
      "epoch": 986.82,
      "learning_rate": 0.0013586195418006468,
      "loss": 2.2759,
      "step": 613800
    },
    {
      "epoch": 986.85,
      "learning_rate": 0.0013554041109324776,
      "loss": 2.2946,
      "step": 613820
    },
    {
      "epoch": 986.88,
      "learning_rate": 0.0013521886800643085,
      "loss": 2.2787,
      "step": 613840
    },
    {
      "epoch": 986.91,
      "learning_rate": 0.0013489732491961393,
      "loss": 2.2853,
      "step": 613860
    },
    {
      "epoch": 986.95,
      "learning_rate": 0.0013457578183279702,
      "loss": 2.2693,
      "step": 613880
    },
    {
      "epoch": 986.98,
      "learning_rate": 0.001342542387459812,
      "loss": 2.2733,
      "step": 613900
    },
    {
      "epoch": 987.0,
      "eval_accuracy": {
        "accuracy": 0.4933530280649926
      },
      "eval_loss": 2.3969767093658447,
      "eval_runtime": 3.0833,
      "eval_samples_per_second": 4171.84,
      "eval_steps_per_second": 65.19,
      "step": 613914
    },
    {
      "epoch": 987.01,
      "learning_rate": 0.001339326956591643,
      "loss": 2.2828,
      "step": 613920
    },
    {
      "epoch": 987.04,
      "learning_rate": 0.0013361115257234737,
      "loss": 2.3005,
      "step": 613940
    },
    {
      "epoch": 987.07,
      "learning_rate": 0.0013328960948553045,
      "loss": 2.2757,
      "step": 613960
    },
    {
      "epoch": 987.11,
      "learning_rate": 0.0013296806639871354,
      "loss": 2.2708,
      "step": 613980
    },
    {
      "epoch": 987.14,
      "learning_rate": 0.0013264652331189662,
      "loss": 2.2808,
      "step": 614000
    },
    {
      "epoch": 987.17,
      "learning_rate": 0.0013232498022508082,
      "loss": 2.2925,
      "step": 614020
    },
    {
      "epoch": 987.2,
      "learning_rate": 0.001320034371382639,
      "loss": 2.2717,
      "step": 614040
    },
    {
      "epoch": 987.23,
      "learning_rate": 0.0013168189405144699,
      "loss": 2.2759,
      "step": 614060
    },
    {
      "epoch": 987.27,
      "learning_rate": 0.0013136035096463006,
      "loss": 2.2752,
      "step": 614080
    },
    {
      "epoch": 987.3,
      "learning_rate": 0.0013103880787781316,
      "loss": 2.2845,
      "step": 614100
    },
    {
      "epoch": 987.33,
      "learning_rate": 0.0013071726479099734,
      "loss": 2.27,
      "step": 614120
    },
    {
      "epoch": 987.36,
      "learning_rate": 0.0013039572170418044,
      "loss": 2.2872,
      "step": 614140
    },
    {
      "epoch": 987.4,
      "learning_rate": 0.001300741786173635,
      "loss": 2.2818,
      "step": 614160
    },
    {
      "epoch": 987.43,
      "learning_rate": 0.0012975263553054658,
      "loss": 2.2753,
      "step": 614180
    },
    {
      "epoch": 987.46,
      "learning_rate": 0.0012943109244372968,
      "loss": 2.2715,
      "step": 614200
    },
    {
      "epoch": 987.49,
      "learning_rate": 0.0012910954935691275,
      "loss": 2.2764,
      "step": 614220
    },
    {
      "epoch": 987.52,
      "learning_rate": 0.0012878800627009696,
      "loss": 2.2794,
      "step": 614240
    },
    {
      "epoch": 987.56,
      "learning_rate": 0.0012846646318328003,
      "loss": 2.2582,
      "step": 614260
    },
    {
      "epoch": 987.59,
      "learning_rate": 0.0012814492009646313,
      "loss": 2.2707,
      "step": 614280
    },
    {
      "epoch": 987.62,
      "learning_rate": 0.001278233770096462,
      "loss": 2.2637,
      "step": 614300
    },
    {
      "epoch": 987.65,
      "learning_rate": 0.0012750183392282927,
      "loss": 2.2711,
      "step": 614320
    },
    {
      "epoch": 987.68,
      "learning_rate": 0.0012718029083601237,
      "loss": 2.2853,
      "step": 614340
    },
    {
      "epoch": 987.72,
      "learning_rate": 0.0012685874774919655,
      "loss": 2.2929,
      "step": 614360
    },
    {
      "epoch": 987.75,
      "learning_rate": 0.0012653720466237965,
      "loss": 2.2832,
      "step": 614380
    },
    {
      "epoch": 987.78,
      "learning_rate": 0.0012621566157556272,
      "loss": 2.2822,
      "step": 614400
    },
    {
      "epoch": 987.81,
      "learning_rate": 0.0012589411848874582,
      "loss": 2.2663,
      "step": 614420
    },
    {
      "epoch": 987.85,
      "learning_rate": 0.001255725754019289,
      "loss": 2.2704,
      "step": 614440
    },
    {
      "epoch": 987.88,
      "learning_rate": 0.001252510323151131,
      "loss": 2.2677,
      "step": 614460
    },
    {
      "epoch": 987.91,
      "learning_rate": 0.0012492948922829617,
      "loss": 2.2794,
      "step": 614480
    },
    {
      "epoch": 987.94,
      "learning_rate": 0.0012460794614147924,
      "loss": 2.2695,
      "step": 614500
    },
    {
      "epoch": 987.97,
      "learning_rate": 0.0012428640305466234,
      "loss": 2.2791,
      "step": 614520
    },
    {
      "epoch": 988.0,
      "eval_accuracy": {
        "accuracy": 0.4919536655523595
      },
      "eval_loss": 2.396674633026123,
      "eval_runtime": 3.2538,
      "eval_samples_per_second": 3953.2,
      "eval_steps_per_second": 61.774,
      "step": 614536
    },
    {
      "epoch": 988.01,
      "learning_rate": 0.0012396485996784541,
      "loss": 2.2706,
      "step": 614540
    },
    {
      "epoch": 988.04,
      "learning_rate": 0.001236433168810285,
      "loss": 2.2814,
      "step": 614560
    },
    {
      "epoch": 988.07,
      "learning_rate": 0.0012332177379421269,
      "loss": 2.2877,
      "step": 614580
    },
    {
      "epoch": 988.1,
      "learning_rate": 0.0012300023070739578,
      "loss": 2.2873,
      "step": 614600
    },
    {
      "epoch": 988.14,
      "learning_rate": 0.0012267868762057886,
      "loss": 2.2658,
      "step": 614620
    },
    {
      "epoch": 988.17,
      "learning_rate": 0.0012235714453376193,
      "loss": 2.2892,
      "step": 614640
    },
    {
      "epoch": 988.2,
      "learning_rate": 0.0012203560144694503,
      "loss": 2.2908,
      "step": 614660
    },
    {
      "epoch": 988.23,
      "learning_rate": 0.001217140583601281,
      "loss": 2.278,
      "step": 614680
    },
    {
      "epoch": 988.26,
      "learning_rate": 0.001213925152733123,
      "loss": 2.2636,
      "step": 614700
    },
    {
      "epoch": 988.3,
      "learning_rate": 0.0012107097218649538,
      "loss": 2.2714,
      "step": 614720
    },
    {
      "epoch": 988.33,
      "learning_rate": 0.0012074942909967848,
      "loss": 2.2543,
      "step": 614740
    },
    {
      "epoch": 988.36,
      "learning_rate": 0.0012042788601286155,
      "loss": 2.2691,
      "step": 614760
    },
    {
      "epoch": 988.39,
      "learning_rate": 0.0012010634292604465,
      "loss": 2.2931,
      "step": 614780
    },
    {
      "epoch": 988.42,
      "learning_rate": 0.0011978479983922883,
      "loss": 2.2662,
      "step": 614800
    },
    {
      "epoch": 988.46,
      "learning_rate": 0.0011946325675241192,
      "loss": 2.2745,
      "step": 614820
    },
    {
      "epoch": 988.49,
      "learning_rate": 0.00119141713665595,
      "loss": 2.2703,
      "step": 614840
    },
    {
      "epoch": 988.52,
      "learning_rate": 0.0011882017057877807,
      "loss": 2.2611,
      "step": 614860
    },
    {
      "epoch": 988.55,
      "learning_rate": 0.0011849862749196117,
      "loss": 2.2704,
      "step": 614880
    },
    {
      "epoch": 988.59,
      "learning_rate": 0.0011817708440514424,
      "loss": 2.2869,
      "step": 614900
    },
    {
      "epoch": 988.62,
      "learning_rate": 0.0011785554131832844,
      "loss": 2.2504,
      "step": 614920
    },
    {
      "epoch": 988.65,
      "learning_rate": 0.0011753399823151152,
      "loss": 2.2781,
      "step": 614940
    },
    {
      "epoch": 988.68,
      "learning_rate": 0.0011721245514469461,
      "loss": 2.2938,
      "step": 614960
    },
    {
      "epoch": 988.71,
      "learning_rate": 0.0011689091205787769,
      "loss": 2.283,
      "step": 614980
    },
    {
      "epoch": 988.75,
      "learning_rate": 0.0011656936897106076,
      "loss": 2.2906,
      "step": 615000
    },
    {
      "epoch": 988.78,
      "learning_rate": 0.0011624782588424386,
      "loss": 2.2659,
      "step": 615020
    },
    {
      "epoch": 988.81,
      "learning_rate": 0.0011592628279742804,
      "loss": 2.2753,
      "step": 615040
    },
    {
      "epoch": 988.84,
      "learning_rate": 0.0011560473971061113,
      "loss": 2.269,
      "step": 615060
    },
    {
      "epoch": 988.87,
      "learning_rate": 0.001152831966237942,
      "loss": 2.2714,
      "step": 615080
    },
    {
      "epoch": 988.91,
      "learning_rate": 0.001149616535369773,
      "loss": 2.2866,
      "step": 615100
    },
    {
      "epoch": 988.94,
      "learning_rate": 0.0011464011045016038,
      "loss": 2.2823,
      "step": 615120
    },
    {
      "epoch": 988.97,
      "learning_rate": 0.0011431856736334458,
      "loss": 2.2709,
      "step": 615140
    },
    {
      "epoch": 989.0,
      "eval_accuracy": {
        "accuracy": 0.48962139469797095
      },
      "eval_loss": 2.394656181335449,
      "eval_runtime": 3.1381,
      "eval_samples_per_second": 4099.036,
      "eval_steps_per_second": 64.052,
      "step": 615158
    },
    {
      "epoch": 989.0,
      "learning_rate": 0.0011399702427652765,
      "loss": 2.273,
      "step": 615160
    },
    {
      "epoch": 989.04,
      "learning_rate": 0.0011367548118971073,
      "loss": 2.2877,
      "step": 615180
    },
    {
      "epoch": 989.07,
      "learning_rate": 0.0011335393810289382,
      "loss": 2.2869,
      "step": 615200
    },
    {
      "epoch": 989.1,
      "learning_rate": 0.001130323950160769,
      "loss": 2.2761,
      "step": 615220
    },
    {
      "epoch": 989.13,
      "learning_rate": 0.0011271085192926,
      "loss": 2.2659,
      "step": 615240
    },
    {
      "epoch": 989.16,
      "learning_rate": 0.0011238930884244418,
      "loss": 2.2492,
      "step": 615260
    },
    {
      "epoch": 989.2,
      "learning_rate": 0.0011206776575562727,
      "loss": 2.2691,
      "step": 615280
    },
    {
      "epoch": 989.23,
      "learning_rate": 0.0011174622266881035,
      "loss": 2.281,
      "step": 615300
    },
    {
      "epoch": 989.26,
      "learning_rate": 0.0011142467958199342,
      "loss": 2.2839,
      "step": 615320
    },
    {
      "epoch": 989.29,
      "learning_rate": 0.0011110313649517652,
      "loss": 2.277,
      "step": 615340
    },
    {
      "epoch": 989.32,
      "learning_rate": 0.001107815934083596,
      "loss": 2.2815,
      "step": 615360
    },
    {
      "epoch": 989.36,
      "learning_rate": 0.001104600503215438,
      "loss": 2.2671,
      "step": 615380
    },
    {
      "epoch": 989.39,
      "learning_rate": 0.0011013850723472687,
      "loss": 2.2636,
      "step": 615400
    },
    {
      "epoch": 989.42,
      "learning_rate": 0.0010981696414790996,
      "loss": 2.269,
      "step": 615420
    },
    {
      "epoch": 989.45,
      "learning_rate": 0.0010949542106109304,
      "loss": 2.2744,
      "step": 615440
    },
    {
      "epoch": 989.49,
      "learning_rate": 0.0010917387797427613,
      "loss": 2.2765,
      "step": 615460
    },
    {
      "epoch": 989.52,
      "learning_rate": 0.0010885233488746031,
      "loss": 2.2848,
      "step": 615480
    },
    {
      "epoch": 989.55,
      "learning_rate": 0.001085307918006434,
      "loss": 2.2668,
      "step": 615500
    },
    {
      "epoch": 989.58,
      "learning_rate": 0.0010820924871382648,
      "loss": 2.2552,
      "step": 615520
    },
    {
      "epoch": 989.61,
      "learning_rate": 0.0010788770562700956,
      "loss": 2.269,
      "step": 615540
    },
    {
      "epoch": 989.65,
      "learning_rate": 0.0010756616254019265,
      "loss": 2.2576,
      "step": 615560
    },
    {
      "epoch": 989.68,
      "learning_rate": 0.0010724461945337573,
      "loss": 2.281,
      "step": 615580
    },
    {
      "epoch": 989.71,
      "learning_rate": 0.0010692307636655993,
      "loss": 2.2793,
      "step": 615600
    },
    {
      "epoch": 989.74,
      "learning_rate": 0.00106601533279743,
      "loss": 2.2875,
      "step": 615620
    },
    {
      "epoch": 989.77,
      "learning_rate": 0.001062799901929261,
      "loss": 2.2901,
      "step": 615640
    },
    {
      "epoch": 989.81,
      "learning_rate": 0.0010595844710610917,
      "loss": 2.2762,
      "step": 615660
    },
    {
      "epoch": 989.84,
      "learning_rate": 0.0010563690401929225,
      "loss": 2.2947,
      "step": 615680
    },
    {
      "epoch": 989.87,
      "learning_rate": 0.0010531536093247534,
      "loss": 2.2776,
      "step": 615700
    },
    {
      "epoch": 989.9,
      "learning_rate": 0.0010499381784565952,
      "loss": 2.2724,
      "step": 615720
    },
    {
      "epoch": 989.94,
      "learning_rate": 0.0010467227475884262,
      "loss": 2.2674,
      "step": 615740
    },
    {
      "epoch": 989.97,
      "learning_rate": 0.001043507316720257,
      "loss": 2.2772,
      "step": 615760
    },
    {
      "epoch": 990.0,
      "learning_rate": 0.001040291885852088,
      "loss": 2.2885,
      "step": 615780
    },
    {
      "epoch": 990.0,
      "eval_accuracy": {
        "accuracy": 0.4928865738941149
      },
      "eval_loss": 2.3924503326416016,
      "eval_runtime": 3.2905,
      "eval_samples_per_second": 3909.139,
      "eval_steps_per_second": 61.085,
      "step": 615780
    },
    {
      "epoch": 990.03,
      "learning_rate": 0.0010370764549839187,
      "loss": 2.2959,
      "step": 615800
    },
    {
      "epoch": 990.06,
      "learning_rate": 0.0010338610241157607,
      "loss": 2.2655,
      "step": 615820
    },
    {
      "epoch": 990.1,
      "learning_rate": 0.0010306455932475914,
      "loss": 2.2815,
      "step": 615840
    },
    {
      "epoch": 990.13,
      "learning_rate": 0.0010274301623794222,
      "loss": 2.2806,
      "step": 615860
    },
    {
      "epoch": 990.16,
      "learning_rate": 0.0010242147315112531,
      "loss": 2.2792,
      "step": 615880
    },
    {
      "epoch": 990.19,
      "learning_rate": 0.0010209993006430839,
      "loss": 2.2866,
      "step": 615900
    },
    {
      "epoch": 990.23,
      "learning_rate": 0.0010177838697749148,
      "loss": 2.2837,
      "step": 615920
    },
    {
      "epoch": 990.26,
      "learning_rate": 0.0010145684389067566,
      "loss": 2.256,
      "step": 615940
    },
    {
      "epoch": 990.29,
      "learning_rate": 0.0010113530080385876,
      "loss": 2.2732,
      "step": 615960
    },
    {
      "epoch": 990.32,
      "learning_rate": 0.0010081375771704183,
      "loss": 2.2693,
      "step": 615980
    },
    {
      "epoch": 990.35,
      "learning_rate": 0.001004922146302249,
      "loss": 2.2581,
      "step": 616000
    },
    {
      "epoch": 990.39,
      "learning_rate": 0.00100170671543408,
      "loss": 2.2787,
      "step": 616020
    },
    {
      "epoch": 990.42,
      "learning_rate": 0.0009984912845659218,
      "loss": 2.2525,
      "step": 616040
    },
    {
      "epoch": 990.45,
      "learning_rate": 0.0009954366252411528,
      "loss": 2.2617,
      "step": 616060
    },
    {
      "epoch": 990.48,
      "learning_rate": 0.0009922211943729949,
      "loss": 2.2523,
      "step": 616080
    },
    {
      "epoch": 990.51,
      "learning_rate": 0.0009890057635048256,
      "loss": 2.2889,
      "step": 616100
    },
    {
      "epoch": 990.55,
      "learning_rate": 0.0009857903326366566,
      "loss": 2.2969,
      "step": 616120
    },
    {
      "epoch": 990.58,
      "learning_rate": 0.0009825749017684873,
      "loss": 2.289,
      "step": 616140
    },
    {
      "epoch": 990.61,
      "learning_rate": 0.0009793594709003183,
      "loss": 2.2577,
      "step": 616160
    },
    {
      "epoch": 990.64,
      "learning_rate": 0.000976144040032149,
      "loss": 2.2688,
      "step": 616180
    },
    {
      "epoch": 990.68,
      "learning_rate": 0.0009729286091639908,
      "loss": 2.2881,
      "step": 616200
    },
    {
      "epoch": 990.71,
      "learning_rate": 0.0009697131782958218,
      "loss": 2.2768,
      "step": 616220
    },
    {
      "epoch": 990.74,
      "learning_rate": 0.0009664977474276525,
      "loss": 2.2754,
      "step": 616240
    },
    {
      "epoch": 990.77,
      "learning_rate": 0.0009632823165594833,
      "loss": 2.2747,
      "step": 616260
    },
    {
      "epoch": 990.8,
      "learning_rate": 0.0009600668856913141,
      "loss": 2.2804,
      "step": 616280
    },
    {
      "epoch": 990.84,
      "learning_rate": 0.0009568514548231561,
      "loss": 2.2715,
      "step": 616300
    },
    {
      "epoch": 990.87,
      "learning_rate": 0.0009536360239549869,
      "loss": 2.269,
      "step": 616320
    },
    {
      "epoch": 990.9,
      "learning_rate": 0.0009504205930868176,
      "loss": 2.2765,
      "step": 616340
    },
    {
      "epoch": 990.93,
      "learning_rate": 0.0009472051622186486,
      "loss": 2.2666,
      "step": 616360
    },
    {
      "epoch": 990.96,
      "learning_rate": 0.0009439897313504794,
      "loss": 2.2649,
      "step": 616380
    },
    {
      "epoch": 991.0,
      "learning_rate": 0.0009407743004823102,
      "loss": 2.2785,
      "step": 616400
    },
    {
      "epoch": 991.0,
      "eval_accuracy": {
        "accuracy": 0.4933530280649926
      },
      "eval_loss": 2.392476797103882,
      "eval_runtime": 3.1613,
      "eval_samples_per_second": 4068.956,
      "eval_steps_per_second": 63.582,
      "step": 616402
    },
    {
      "epoch": 991.03,
      "learning_rate": 0.0009375588696141522,
      "loss": 2.2852,
      "step": 616420
    },
    {
      "epoch": 991.06,
      "learning_rate": 0.0009343434387459829,
      "loss": 2.2863,
      "step": 616440
    },
    {
      "epoch": 991.09,
      "learning_rate": 0.0009311280078778137,
      "loss": 2.2707,
      "step": 616460
    },
    {
      "epoch": 991.13,
      "learning_rate": 0.0009279125770096446,
      "loss": 2.2778,
      "step": 616480
    },
    {
      "epoch": 991.16,
      "learning_rate": 0.0009246971461414756,
      "loss": 2.2617,
      "step": 616500
    },
    {
      "epoch": 991.19,
      "learning_rate": 0.0009214817152733174,
      "loss": 2.261,
      "step": 616520
    },
    {
      "epoch": 991.22,
      "learning_rate": 0.0009182662844051484,
      "loss": 2.2739,
      "step": 616540
    },
    {
      "epoch": 991.25,
      "learning_rate": 0.0009150508535369791,
      "loss": 2.2602,
      "step": 616560
    },
    {
      "epoch": 991.29,
      "learning_rate": 0.0009118354226688099,
      "loss": 2.2793,
      "step": 616580
    },
    {
      "epoch": 991.32,
      "learning_rate": 0.0009086199918006407,
      "loss": 2.2877,
      "step": 616600
    },
    {
      "epoch": 991.35,
      "learning_rate": 0.0009054045609324714,
      "loss": 2.2672,
      "step": 616620
    },
    {
      "epoch": 991.38,
      "learning_rate": 0.0009021891300643135,
      "loss": 2.2716,
      "step": 616640
    },
    {
      "epoch": 991.41,
      "learning_rate": 0.0008989736991961442,
      "loss": 2.2858,
      "step": 616660
    },
    {
      "epoch": 991.45,
      "learning_rate": 0.0008957582683279752,
      "loss": 2.2532,
      "step": 616680
    },
    {
      "epoch": 991.48,
      "learning_rate": 0.000892542837459806,
      "loss": 2.2653,
      "step": 616700
    },
    {
      "epoch": 991.51,
      "learning_rate": 0.0008893274065916367,
      "loss": 2.2797,
      "step": 616720
    },
    {
      "epoch": 991.54,
      "learning_rate": 0.0008861119757234677,
      "loss": 2.2833,
      "step": 616740
    },
    {
      "epoch": 991.58,
      "learning_rate": 0.0008828965448553095,
      "loss": 2.2781,
      "step": 616760
    },
    {
      "epoch": 991.61,
      "learning_rate": 0.0008796811139871405,
      "loss": 2.2753,
      "step": 616780
    },
    {
      "epoch": 991.64,
      "learning_rate": 0.0008764656831189712,
      "loss": 2.2608,
      "step": 616800
    },
    {
      "epoch": 991.67,
      "learning_rate": 0.0008732502522508022,
      "loss": 2.2762,
      "step": 616820
    },
    {
      "epoch": 991.7,
      "learning_rate": 0.0008700348213826329,
      "loss": 2.2674,
      "step": 616840
    },
    {
      "epoch": 991.74,
      "learning_rate": 0.0008668193905144749,
      "loss": 2.2914,
      "step": 616860
    },
    {
      "epoch": 991.77,
      "learning_rate": 0.0008636039596463057,
      "loss": 2.2836,
      "step": 616880
    },
    {
      "epoch": 991.8,
      "learning_rate": 0.0008603885287781365,
      "loss": 2.2517,
      "step": 616900
    },
    {
      "epoch": 991.83,
      "learning_rate": 0.0008571730979099673,
      "loss": 2.2692,
      "step": 616920
    },
    {
      "epoch": 991.86,
      "learning_rate": 0.0008539576670417982,
      "loss": 2.2742,
      "step": 616940
    },
    {
      "epoch": 991.9,
      "learning_rate": 0.000850742236173629,
      "loss": 2.2663,
      "step": 616960
    },
    {
      "epoch": 991.93,
      "learning_rate": 0.000847526805305471,
      "loss": 2.2825,
      "step": 616980
    },
    {
      "epoch": 991.96,
      "learning_rate": 0.0008443113744373017,
      "loss": 2.2677,
      "step": 617000
    },
    {
      "epoch": 991.99,
      "learning_rate": 0.0008410959435691326,
      "loss": 2.2758,
      "step": 617020
    },
    {
      "epoch": 992.0,
      "eval_accuracy": {
        "accuracy": 0.4940527093213092
      },
      "eval_loss": 2.390468120574951,
      "eval_runtime": 3.3487,
      "eval_samples_per_second": 3841.176,
      "eval_steps_per_second": 60.023,
      "step": 617024
    },
    {
      "epoch": 992.03,
      "learning_rate": 0.0008378805127009633,
      "loss": 2.2672,
      "step": 617040
    },
    {
      "epoch": 992.06,
      "learning_rate": 0.0008346650818327943,
      "loss": 2.2655,
      "step": 617060
    },
    {
      "epoch": 992.09,
      "learning_rate": 0.0008314496509646252,
      "loss": 2.2693,
      "step": 617080
    },
    {
      "epoch": 992.12,
      "learning_rate": 0.000828234220096467,
      "loss": 2.2755,
      "step": 617100
    },
    {
      "epoch": 992.15,
      "learning_rate": 0.000825018789228298,
      "loss": 2.2816,
      "step": 617120
    },
    {
      "epoch": 992.19,
      "learning_rate": 0.0008218033583601288,
      "loss": 2.285,
      "step": 617140
    },
    {
      "epoch": 992.22,
      "learning_rate": 0.0008185879274919595,
      "loss": 2.2731,
      "step": 617160
    },
    {
      "epoch": 992.25,
      "learning_rate": 0.0008153724966237903,
      "loss": 2.2841,
      "step": 617180
    },
    {
      "epoch": 992.28,
      "learning_rate": 0.0008121570657556323,
      "loss": 2.2573,
      "step": 617200
    },
    {
      "epoch": 992.32,
      "learning_rate": 0.0008089416348874631,
      "loss": 2.2608,
      "step": 617220
    },
    {
      "epoch": 992.35,
      "learning_rate": 0.0008057262040192939,
      "loss": 2.2666,
      "step": 617240
    },
    {
      "epoch": 992.38,
      "learning_rate": 0.0008025107731511248,
      "loss": 2.2898,
      "step": 617260
    },
    {
      "epoch": 992.41,
      "learning_rate": 0.0007992953422829557,
      "loss": 2.2844,
      "step": 617280
    },
    {
      "epoch": 992.44,
      "learning_rate": 0.0007960799114147864,
      "loss": 2.2976,
      "step": 617300
    },
    {
      "epoch": 992.48,
      "learning_rate": 0.0007928644805466284,
      "loss": 2.2436,
      "step": 617320
    },
    {
      "epoch": 992.51,
      "learning_rate": 0.0007896490496784592,
      "loss": 2.2821,
      "step": 617340
    },
    {
      "epoch": 992.54,
      "learning_rate": 0.0007864336188102899,
      "loss": 2.258,
      "step": 617360
    },
    {
      "epoch": 992.57,
      "learning_rate": 0.0007832181879421209,
      "loss": 2.2609,
      "step": 617380
    },
    {
      "epoch": 992.6,
      "learning_rate": 0.0007800027570739517,
      "loss": 2.2703,
      "step": 617400
    },
    {
      "epoch": 992.64,
      "learning_rate": 0.0007767873262057826,
      "loss": 2.2762,
      "step": 617420
    },
    {
      "epoch": 992.67,
      "learning_rate": 0.0007735718953376245,
      "loss": 2.272,
      "step": 617440
    },
    {
      "epoch": 992.7,
      "learning_rate": 0.0007703564644694553,
      "loss": 2.2664,
      "step": 617460
    },
    {
      "epoch": 992.73,
      "learning_rate": 0.0007671410336012861,
      "loss": 2.2836,
      "step": 617480
    },
    {
      "epoch": 992.77,
      "learning_rate": 0.0007639256027331169,
      "loss": 2.2571,
      "step": 617500
    },
    {
      "epoch": 992.8,
      "learning_rate": 0.0007607101718649478,
      "loss": 2.2541,
      "step": 617520
    },
    {
      "epoch": 992.83,
      "learning_rate": 0.0007574947409967897,
      "loss": 2.2702,
      "step": 617540
    },
    {
      "epoch": 992.86,
      "learning_rate": 0.0007542793101286205,
      "loss": 2.2748,
      "step": 617560
    },
    {
      "epoch": 992.89,
      "learning_rate": 0.0007510638792604514,
      "loss": 2.2824,
      "step": 617580
    },
    {
      "epoch": 992.93,
      "learning_rate": 0.0007478484483922822,
      "loss": 2.2782,
      "step": 617600
    },
    {
      "epoch": 992.96,
      "learning_rate": 0.0007446330175241131,
      "loss": 2.2852,
      "step": 617620
    },
    {
      "epoch": 992.99,
      "learning_rate": 0.0007414175866559438,
      "loss": 2.2629,
      "step": 617640
    },
    {
      "epoch": 993.0,
      "eval_accuracy": {
        "accuracy": 0.4925756044468631
      },
      "eval_loss": 2.388892412185669,
      "eval_runtime": 3.113,
      "eval_samples_per_second": 4132.083,
      "eval_steps_per_second": 64.569,
      "step": 617646
    },
    {
      "epoch": 993.02,
      "learning_rate": 0.0007382021557877859,
      "loss": 2.2708,
      "step": 617660
    },
    {
      "epoch": 993.05,
      "learning_rate": 0.0007349867249196166,
      "loss": 2.2584,
      "step": 617680
    },
    {
      "epoch": 993.09,
      "learning_rate": 0.0007317712940514475,
      "loss": 2.2654,
      "step": 617700
    },
    {
      "epoch": 993.12,
      "learning_rate": 0.0007285558631832783,
      "loss": 2.282,
      "step": 617720
    },
    {
      "epoch": 993.15,
      "learning_rate": 0.0007253404323151092,
      "loss": 2.2561,
      "step": 617740
    },
    {
      "epoch": 993.18,
      "learning_rate": 0.00072212500144694,
      "loss": 2.2798,
      "step": 617760
    },
    {
      "epoch": 993.22,
      "learning_rate": 0.0007189095705787819,
      "loss": 2.2644,
      "step": 617780
    },
    {
      "epoch": 993.25,
      "learning_rate": 0.0007156941397106128,
      "loss": 2.2715,
      "step": 617800
    },
    {
      "epoch": 993.28,
      "learning_rate": 0.0007124787088424435,
      "loss": 2.2833,
      "step": 617820
    },
    {
      "epoch": 993.31,
      "learning_rate": 0.0007092632779742744,
      "loss": 2.2692,
      "step": 617840
    },
    {
      "epoch": 993.34,
      "learning_rate": 0.0007060478471061052,
      "loss": 2.2693,
      "step": 617860
    },
    {
      "epoch": 993.38,
      "learning_rate": 0.0007028324162379471,
      "loss": 2.2681,
      "step": 617880
    },
    {
      "epoch": 993.41,
      "learning_rate": 0.000699616985369778,
      "loss": 2.2612,
      "step": 617900
    },
    {
      "epoch": 993.44,
      "learning_rate": 0.0006964015545016088,
      "loss": 2.2716,
      "step": 617920
    },
    {
      "epoch": 993.47,
      "learning_rate": 0.0006931861236334397,
      "loss": 2.2617,
      "step": 617940
    },
    {
      "epoch": 993.5,
      "learning_rate": 0.0006899706927652705,
      "loss": 2.3016,
      "step": 617960
    },
    {
      "epoch": 993.54,
      "learning_rate": 0.0006867552618971013,
      "loss": 2.2622,
      "step": 617980
    },
    {
      "epoch": 993.57,
      "learning_rate": 0.0006835398310289433,
      "loss": 2.2709,
      "step": 618000
    },
    {
      "epoch": 993.6,
      "learning_rate": 0.000680324400160774,
      "loss": 2.2914,
      "step": 618020
    },
    {
      "epoch": 993.63,
      "learning_rate": 0.0006771089692926049,
      "loss": 2.2761,
      "step": 618040
    },
    {
      "epoch": 993.67,
      "learning_rate": 0.0006738935384244357,
      "loss": 2.2752,
      "step": 618060
    },
    {
      "epoch": 993.7,
      "learning_rate": 0.0006706781075562666,
      "loss": 2.2828,
      "step": 618080
    },
    {
      "epoch": 993.73,
      "learning_rate": 0.0006674626766880974,
      "loss": 2.2758,
      "step": 618100
    },
    {
      "epoch": 993.76,
      "learning_rate": 0.0006642472458199394,
      "loss": 2.2591,
      "step": 618120
    },
    {
      "epoch": 993.79,
      "learning_rate": 0.0006610318149517702,
      "loss": 2.2765,
      "step": 618140
    },
    {
      "epoch": 993.83,
      "learning_rate": 0.000657816384083601,
      "loss": 2.2572,
      "step": 618160
    },
    {
      "epoch": 993.86,
      "learning_rate": 0.0006546009532154318,
      "loss": 2.2717,
      "step": 618180
    },
    {
      "epoch": 993.89,
      "learning_rate": 0.0006513855223472627,
      "loss": 2.2581,
      "step": 618200
    },
    {
      "epoch": 993.92,
      "learning_rate": 0.0006481700914791046,
      "loss": 2.2741,
      "step": 618220
    },
    {
      "epoch": 993.95,
      "learning_rate": 0.0006449546606109354,
      "loss": 2.2719,
      "step": 618240
    },
    {
      "epoch": 993.99,
      "learning_rate": 0.0006417392297427663,
      "loss": 2.2739,
      "step": 618260
    },
    {
      "epoch": 994.0,
      "eval_accuracy": {
        "accuracy": 0.49428593640674806
      },
      "eval_loss": 2.3898873329162598,
      "eval_runtime": 3.2089,
      "eval_samples_per_second": 4008.537,
      "eval_steps_per_second": 62.638,
      "step": 618268
    },
    {
      "epoch": 994.02,
      "learning_rate": 0.0006385237988745971,
      "loss": 2.2841,
      "step": 618280
    },
    {
      "epoch": 994.05,
      "learning_rate": 0.000635308368006428,
      "loss": 2.2752,
      "step": 618300
    },
    {
      "epoch": 994.08,
      "learning_rate": 0.0006320929371382587,
      "loss": 2.2822,
      "step": 618320
    },
    {
      "epoch": 994.12,
      "learning_rate": 0.0006288775062701007,
      "loss": 2.262,
      "step": 618340
    },
    {
      "epoch": 994.15,
      "learning_rate": 0.0006256620754019315,
      "loss": 2.2668,
      "step": 618360
    },
    {
      "epoch": 994.18,
      "learning_rate": 0.0006224466445337623,
      "loss": 2.2808,
      "step": 618380
    },
    {
      "epoch": 994.21,
      "learning_rate": 0.0006192312136655932,
      "loss": 2.2552,
      "step": 618400
    },
    {
      "epoch": 994.24,
      "learning_rate": 0.000616015782797424,
      "loss": 2.2542,
      "step": 618420
    },
    {
      "epoch": 994.28,
      "learning_rate": 0.0006128003519292659,
      "loss": 2.2993,
      "step": 618440
    },
    {
      "epoch": 994.31,
      "learning_rate": 0.0006095849210610968,
      "loss": 2.2626,
      "step": 618460
    },
    {
      "epoch": 994.34,
      "learning_rate": 0.0006063694901929276,
      "loss": 2.2904,
      "step": 618480
    },
    {
      "epoch": 994.37,
      "learning_rate": 0.0006031540593247584,
      "loss": 2.2833,
      "step": 618500
    },
    {
      "epoch": 994.41,
      "learning_rate": 0.0005999386284565892,
      "loss": 2.2766,
      "step": 618520
    },
    {
      "epoch": 994.44,
      "learning_rate": 0.0005967231975884201,
      "loss": 2.2606,
      "step": 618540
    },
    {
      "epoch": 994.47,
      "learning_rate": 0.000593507766720262,
      "loss": 2.2487,
      "step": 618560
    },
    {
      "epoch": 994.5,
      "learning_rate": 0.0005902923358520928,
      "loss": 2.2749,
      "step": 618580
    },
    {
      "epoch": 994.53,
      "learning_rate": 0.0005870769049839237,
      "loss": 2.285,
      "step": 618600
    },
    {
      "epoch": 994.57,
      "learning_rate": 0.0005838614741157545,
      "loss": 2.277,
      "step": 618620
    },
    {
      "epoch": 994.6,
      "learning_rate": 0.0005806460432475854,
      "loss": 2.2661,
      "step": 618640
    },
    {
      "epoch": 994.63,
      "learning_rate": 0.0005774306123794161,
      "loss": 2.2583,
      "step": 618660
    },
    {
      "epoch": 994.66,
      "learning_rate": 0.0005742151815112582,
      "loss": 2.2639,
      "step": 618680
    },
    {
      "epoch": 994.69,
      "learning_rate": 0.0005709997506430889,
      "loss": 2.2536,
      "step": 618700
    },
    {
      "epoch": 994.73,
      "learning_rate": 0.0005677843197749198,
      "loss": 2.2694,
      "step": 618720
    },
    {
      "epoch": 994.76,
      "learning_rate": 0.0005645688889067506,
      "loss": 2.2737,
      "step": 618740
    },
    {
      "epoch": 994.79,
      "learning_rate": 0.0005613534580385815,
      "loss": 2.2508,
      "step": 618760
    },
    {
      "epoch": 994.82,
      "learning_rate": 0.0005581380271704234,
      "loss": 2.2648,
      "step": 618780
    },
    {
      "epoch": 994.86,
      "learning_rate": 0.0005549225963022542,
      "loss": 2.2958,
      "step": 618800
    },
    {
      "epoch": 994.89,
      "learning_rate": 0.0005517071654340851,
      "loss": 2.2513,
      "step": 618820
    },
    {
      "epoch": 994.92,
      "learning_rate": 0.0005484917345659158,
      "loss": 2.2714,
      "step": 618840
    },
    {
      "epoch": 994.95,
      "learning_rate": 0.0005452763036977467,
      "loss": 2.2764,
      "step": 618860
    },
    {
      "epoch": 994.98,
      "learning_rate": 0.0005420608728295775,
      "loss": 2.27,
      "step": 618880
    },
    {
      "epoch": 995.0,
      "eval_accuracy": {
        "accuracy": 0.49436367876856097
      },
      "eval_loss": 2.388411521911621,
      "eval_runtime": 3.3459,
      "eval_samples_per_second": 3844.358,
      "eval_steps_per_second": 60.073,
      "step": 618890
    },
    {
      "epoch": 995.02,
      "learning_rate": 0.0005388454419614194,
      "loss": 2.2572,
      "step": 618900
    },
    {
      "epoch": 995.05,
      "learning_rate": 0.0005356300110932503,
      "loss": 2.2764,
      "step": 618920
    },
    {
      "epoch": 995.08,
      "learning_rate": 0.0005324145802250811,
      "loss": 2.2593,
      "step": 618940
    },
    {
      "epoch": 995.11,
      "learning_rate": 0.000529199149356912,
      "loss": 2.2771,
      "step": 618960
    },
    {
      "epoch": 995.14,
      "learning_rate": 0.0005259837184887428,
      "loss": 2.2708,
      "step": 618980
    },
    {
      "epoch": 995.18,
      "learning_rate": 0.0005227682876205736,
      "loss": 2.2837,
      "step": 619000
    },
    {
      "epoch": 995.21,
      "learning_rate": 0.0005195528567524156,
      "loss": 2.2608,
      "step": 619020
    },
    {
      "epoch": 995.24,
      "learning_rate": 0.0005163374258842463,
      "loss": 2.2792,
      "step": 619040
    },
    {
      "epoch": 995.27,
      "learning_rate": 0.0005131219950160772,
      "loss": 2.2682,
      "step": 619060
    },
    {
      "epoch": 995.31,
      "learning_rate": 0.000509906564147908,
      "loss": 2.2952,
      "step": 619080
    },
    {
      "epoch": 995.34,
      "learning_rate": 0.0005066911332797389,
      "loss": 2.2449,
      "step": 619100
    },
    {
      "epoch": 995.37,
      "learning_rate": 0.0005034757024115808,
      "loss": 2.2761,
      "step": 619120
    },
    {
      "epoch": 995.4,
      "learning_rate": 0.0005002602715434117,
      "loss": 2.2754,
      "step": 619140
    },
    {
      "epoch": 995.43,
      "learning_rate": 0.0004970448406752425,
      "loss": 2.2707,
      "step": 619160
    },
    {
      "epoch": 995.47,
      "learning_rate": 0.0004938294098070732,
      "loss": 2.2682,
      "step": 619180
    },
    {
      "epoch": 995.5,
      "learning_rate": 0.0004906139789389041,
      "loss": 2.2712,
      "step": 619200
    },
    {
      "epoch": 995.53,
      "learning_rate": 0.000487398548070735,
      "loss": 2.2804,
      "step": 619220
    },
    {
      "epoch": 995.56,
      "learning_rate": 0.0004841831172025769,
      "loss": 2.2745,
      "step": 619240
    },
    {
      "epoch": 995.59,
      "learning_rate": 0.00048096768633440777,
      "loss": 2.259,
      "step": 619260
    },
    {
      "epoch": 995.63,
      "learning_rate": 0.00047775225546623857,
      "loss": 2.2709,
      "step": 619280
    },
    {
      "epoch": 995.66,
      "learning_rate": 0.0004745368245980695,
      "loss": 2.2537,
      "step": 619300
    },
    {
      "epoch": 995.69,
      "learning_rate": 0.00047132139372990027,
      "loss": 2.2506,
      "step": 619320
    },
    {
      "epoch": 995.72,
      "learning_rate": 0.00046810596286173107,
      "loss": 2.2784,
      "step": 619340
    },
    {
      "epoch": 995.76,
      "learning_rate": 0.00046489053199357303,
      "loss": 2.2719,
      "step": 619360
    },
    {
      "epoch": 995.79,
      "learning_rate": 0.00046167510112540383,
      "loss": 2.266,
      "step": 619380
    },
    {
      "epoch": 995.82,
      "learning_rate": 0.0004584596702572347,
      "loss": 2.2585,
      "step": 619400
    },
    {
      "epoch": 995.85,
      "learning_rate": 0.0004552442393890655,
      "loss": 2.2889,
      "step": 619420
    },
    {
      "epoch": 995.88,
      "learning_rate": 0.00045202880852089644,
      "loss": 2.2689,
      "step": 619440
    },
    {
      "epoch": 995.92,
      "learning_rate": 0.00044881337765273824,
      "loss": 2.2645,
      "step": 619460
    },
    {
      "epoch": 995.95,
      "learning_rate": 0.0004455979467845692,
      "loss": 2.2737,
      "step": 619480
    },
    {
      "epoch": 995.98,
      "learning_rate": 0.00044238251591639994,
      "loss": 2.2532,
      "step": 619500
    },
    {
      "epoch": 996.0,
      "eval_accuracy": {
        "accuracy": 0.49319754334136673
      },
      "eval_loss": 2.388231039047241,
      "eval_runtime": 3.5022,
      "eval_samples_per_second": 3672.843,
      "eval_steps_per_second": 57.393,
      "step": 619512
    },
    {
      "epoch": 996.01,
      "learning_rate": 0.00043916708504823074,
      "loss": 2.2632,
      "step": 619520
    },
    {
      "epoch": 996.05,
      "learning_rate": 0.00043595165418006164,
      "loss": 2.2585,
      "step": 619540
    },
    {
      "epoch": 996.08,
      "learning_rate": 0.0004327362233118924,
      "loss": 2.2784,
      "step": 619560
    },
    {
      "epoch": 996.11,
      "learning_rate": 0.0004295207924437344,
      "loss": 2.278,
      "step": 619580
    },
    {
      "epoch": 996.14,
      "learning_rate": 0.00042630536157556515,
      "loss": 2.2705,
      "step": 619600
    },
    {
      "epoch": 996.17,
      "learning_rate": 0.0004230899307073961,
      "loss": 2.2747,
      "step": 619620
    },
    {
      "epoch": 996.21,
      "learning_rate": 0.0004198744998392269,
      "loss": 2.2644,
      "step": 619640
    },
    {
      "epoch": 996.24,
      "learning_rate": 0.00041665906897105765,
      "loss": 2.2618,
      "step": 619660
    },
    {
      "epoch": 996.27,
      "learning_rate": 0.00041344363810288855,
      "loss": 2.2758,
      "step": 619680
    },
    {
      "epoch": 996.3,
      "learning_rate": 0.0004102282072347304,
      "loss": 2.2765,
      "step": 619700
    },
    {
      "epoch": 996.33,
      "learning_rate": 0.0004070127763665613,
      "loss": 2.2692,
      "step": 619720
    },
    {
      "epoch": 996.37,
      "learning_rate": 0.00040379734549839206,
      "loss": 2.2765,
      "step": 619740
    },
    {
      "epoch": 996.4,
      "learning_rate": 0.000400581914630223,
      "loss": 2.2675,
      "step": 619760
    },
    {
      "epoch": 996.43,
      "learning_rate": 0.0003973664837620538,
      "loss": 2.2622,
      "step": 619780
    },
    {
      "epoch": 996.46,
      "learning_rate": 0.0003941510528938958,
      "loss": 2.2544,
      "step": 619800
    },
    {
      "epoch": 996.5,
      "learning_rate": 0.0003909356220257266,
      "loss": 2.2639,
      "step": 619820
    },
    {
      "epoch": 996.53,
      "learning_rate": 0.0003877201911575574,
      "loss": 2.2782,
      "step": 619840
    },
    {
      "epoch": 996.56,
      "learning_rate": 0.0003845047602893882,
      "loss": 2.2727,
      "step": 619860
    },
    {
      "epoch": 996.59,
      "learning_rate": 0.0003812893294212191,
      "loss": 2.2827,
      "step": 619880
    },
    {
      "epoch": 996.62,
      "learning_rate": 0.0003780738985530499,
      "loss": 2.2759,
      "step": 619900
    },
    {
      "epoch": 996.66,
      "learning_rate": 0.00037485846768489184,
      "loss": 2.2577,
      "step": 619920
    },
    {
      "epoch": 996.69,
      "learning_rate": 0.00037164303681672264,
      "loss": 2.2703,
      "step": 619940
    },
    {
      "epoch": 996.72,
      "learning_rate": 0.0003684276059485535,
      "loss": 2.2673,
      "step": 619960
    },
    {
      "epoch": 996.75,
      "learning_rate": 0.00036521217508038434,
      "loss": 2.2706,
      "step": 619980
    },
    {
      "epoch": 996.78,
      "learning_rate": 0.00036199674421221514,
      "loss": 2.2772,
      "step": 620000
    },
    {
      "epoch": 996.82,
      "learning_rate": 0.000358781313344046,
      "loss": 2.2539,
      "step": 620020
    },
    {
      "epoch": 996.85,
      "learning_rate": 0.0003555658824758879,
      "loss": 2.2487,
      "step": 620040
    },
    {
      "epoch": 996.88,
      "learning_rate": 0.00035251122315112997,
      "loss": 2.276,
      "step": 620060
    },
    {
      "epoch": 996.91,
      "learning_rate": 0.0003492957922829608,
      "loss": 2.2804,
      "step": 620080
    },
    {
      "epoch": 996.95,
      "learning_rate": 0.0003460803614147916,
      "loss": 2.2433,
      "step": 620100
    },
    {
      "epoch": 996.98,
      "learning_rate": 0.00034286493054662247,
      "loss": 2.2618,
      "step": 620120
    },
    {
      "epoch": 997.0,
      "eval_accuracy": {
        "accuracy": 0.4925756044468631
      },
      "eval_loss": 2.3866477012634277,
      "eval_runtime": 3.1772,
      "eval_samples_per_second": 4048.576,
      "eval_steps_per_second": 63.264,
      "step": 620134
    },
    {
      "epoch": 997.01,
      "learning_rate": 0.0003396494996784533,
      "loss": 2.2754,
      "step": 620140
    },
    {
      "epoch": 997.04,
      "learning_rate": 0.0003364340688102841,
      "loss": 2.265,
      "step": 620160
    },
    {
      "epoch": 997.07,
      "learning_rate": 0.0003332186379421261,
      "loss": 2.2859,
      "step": 620180
    },
    {
      "epoch": 997.11,
      "learning_rate": 0.0003300032070739569,
      "loss": 2.2583,
      "step": 620200
    },
    {
      "epoch": 997.14,
      "learning_rate": 0.00032678777620578773,
      "loss": 2.2792,
      "step": 620220
    },
    {
      "epoch": 997.17,
      "learning_rate": 0.0003235723453376186,
      "loss": 2.2623,
      "step": 620240
    },
    {
      "epoch": 997.2,
      "learning_rate": 0.0003203569144694494,
      "loss": 2.2563,
      "step": 620260
    },
    {
      "epoch": 997.23,
      "learning_rate": 0.00031714148360129134,
      "loss": 2.2728,
      "step": 620280
    },
    {
      "epoch": 997.27,
      "learning_rate": 0.00031392605273312214,
      "loss": 2.2709,
      "step": 620300
    },
    {
      "epoch": 997.3,
      "learning_rate": 0.000310710621864953,
      "loss": 2.2797,
      "step": 620320
    },
    {
      "epoch": 997.33,
      "learning_rate": 0.0003074951909967838,
      "loss": 2.2782,
      "step": 620340
    },
    {
      "epoch": 997.36,
      "learning_rate": 0.00030427976012861464,
      "loss": 2.2736,
      "step": 620360
    },
    {
      "epoch": 997.4,
      "learning_rate": 0.0003010643292604455,
      "loss": 2.2654,
      "step": 620380
    },
    {
      "epoch": 997.43,
      "learning_rate": 0.0002978488983922874,
      "loss": 2.2613,
      "step": 620400
    },
    {
      "epoch": 997.46,
      "learning_rate": 0.00029463346752411825,
      "loss": 2.2709,
      "step": 620420
    },
    {
      "epoch": 997.49,
      "learning_rate": 0.00029141803665594905,
      "loss": 2.2721,
      "step": 620440
    },
    {
      "epoch": 997.52,
      "learning_rate": 0.0002882026057877799,
      "loss": 2.2554,
      "step": 620460
    },
    {
      "epoch": 997.56,
      "learning_rate": 0.00028498717491961075,
      "loss": 2.2531,
      "step": 620480
    },
    {
      "epoch": 997.59,
      "learning_rate": 0.00028177174405144155,
      "loss": 2.2785,
      "step": 620500
    },
    {
      "epoch": 997.62,
      "learning_rate": 0.0002785563131832835,
      "loss": 2.2493,
      "step": 620520
    },
    {
      "epoch": 997.65,
      "learning_rate": 0.0002753408823151143,
      "loss": 2.2487,
      "step": 620540
    },
    {
      "epoch": 997.68,
      "learning_rate": 0.00027212545144694516,
      "loss": 2.2658,
      "step": 620560
    },
    {
      "epoch": 997.72,
      "learning_rate": 0.000268910020578776,
      "loss": 2.2616,
      "step": 620580
    },
    {
      "epoch": 997.75,
      "learning_rate": 0.0002656945897106068,
      "loss": 2.2539,
      "step": 620600
    },
    {
      "epoch": 997.78,
      "learning_rate": 0.0002624791588424488,
      "loss": 2.2596,
      "step": 620620
    },
    {
      "epoch": 997.81,
      "learning_rate": 0.00025926372797427957,
      "loss": 2.2677,
      "step": 620640
    },
    {
      "epoch": 997.85,
      "learning_rate": 0.0002560482971061104,
      "loss": 2.2692,
      "step": 620660
    },
    {
      "epoch": 997.88,
      "learning_rate": 0.0002528328662379413,
      "loss": 2.2714,
      "step": 620680
    },
    {
      "epoch": 997.91,
      "learning_rate": 0.00024961743536977207,
      "loss": 2.2751,
      "step": 620700
    },
    {
      "epoch": 997.94,
      "learning_rate": 0.0002464020045016029,
      "loss": 2.2691,
      "step": 620720
    },
    {
      "epoch": 997.97,
      "learning_rate": 0.00024318657363344483,
      "loss": 2.2803,
      "step": 620740
    },
    {
      "epoch": 998.0,
      "eval_accuracy": {
        "accuracy": 0.4930420586177408
      },
      "eval_loss": 2.387406349182129,
      "eval_runtime": 3.3316,
      "eval_samples_per_second": 3860.946,
      "eval_steps_per_second": 60.332,
      "step": 620756
    },
    {
      "epoch": 998.01,
      "learning_rate": 0.00023997114276527569,
      "loss": 2.2777,
      "step": 620760
    },
    {
      "epoch": 998.04,
      "learning_rate": 0.0002367557118971065,
      "loss": 2.2725,
      "step": 620780
    },
    {
      "epoch": 998.07,
      "learning_rate": 0.00023354028102893733,
      "loss": 2.2576,
      "step": 620800
    },
    {
      "epoch": 998.1,
      "learning_rate": 0.00023032485016076816,
      "loss": 2.2686,
      "step": 620820
    },
    {
      "epoch": 998.14,
      "learning_rate": 0.00022710941929259898,
      "loss": 2.251,
      "step": 620840
    },
    {
      "epoch": 998.17,
      "learning_rate": 0.00022389398842444092,
      "loss": 2.2704,
      "step": 620860
    },
    {
      "epoch": 998.2,
      "learning_rate": 0.00022067855755627174,
      "loss": 2.2815,
      "step": 620880
    },
    {
      "epoch": 998.23,
      "learning_rate": 0.0002176238982315138,
      "loss": 2.2752,
      "step": 620900
    },
    {
      "epoch": 998.26,
      "learning_rate": 0.00021440846736334466,
      "loss": 2.2671,
      "step": 620920
    },
    {
      "epoch": 998.3,
      "learning_rate": 0.0002111930364951755,
      "loss": 2.2526,
      "step": 620940
    },
    {
      "epoch": 998.33,
      "learning_rate": 0.0002079776056270063,
      "loss": 2.2692,
      "step": 620960
    },
    {
      "epoch": 998.36,
      "learning_rate": 0.00020476217475883714,
      "loss": 2.2537,
      "step": 620980
    },
    {
      "epoch": 998.39,
      "learning_rate": 0.00020154674389067907,
      "loss": 2.2691,
      "step": 621000
    },
    {
      "epoch": 998.42,
      "learning_rate": 0.0001983313130225099,
      "loss": 2.2434,
      "step": 621020
    },
    {
      "epoch": 998.46,
      "learning_rate": 0.00019511588215434075,
      "loss": 2.2724,
      "step": 621040
    },
    {
      "epoch": 998.49,
      "learning_rate": 0.00019190045128617157,
      "loss": 2.2632,
      "step": 621060
    },
    {
      "epoch": 998.52,
      "learning_rate": 0.0001886850204180024,
      "loss": 2.2528,
      "step": 621080
    },
    {
      "epoch": 998.55,
      "learning_rate": 0.00018546958954984434,
      "loss": 2.2575,
      "step": 621100
    },
    {
      "epoch": 998.59,
      "learning_rate": 0.0001822541586816752,
      "loss": 2.2691,
      "step": 621120
    },
    {
      "epoch": 998.62,
      "learning_rate": 0.000179038727813506,
      "loss": 2.2686,
      "step": 621140
    },
    {
      "epoch": 998.65,
      "learning_rate": 0.00017582329694533684,
      "loss": 2.2626,
      "step": 621160
    },
    {
      "epoch": 998.68,
      "learning_rate": 0.00017260786607716766,
      "loss": 2.2808,
      "step": 621180
    },
    {
      "epoch": 998.71,
      "learning_rate": 0.0001693924352089985,
      "loss": 2.2699,
      "step": 621200
    },
    {
      "epoch": 998.75,
      "learning_rate": 0.00016617700434084042,
      "loss": 2.2522,
      "step": 621220
    },
    {
      "epoch": 998.78,
      "learning_rate": 0.00016296157347267127,
      "loss": 2.2695,
      "step": 621240
    },
    {
      "epoch": 998.81,
      "learning_rate": 0.0001597461426045021,
      "loss": 2.2779,
      "step": 621260
    },
    {
      "epoch": 998.84,
      "learning_rate": 0.00015653071173633292,
      "loss": 2.2475,
      "step": 621280
    },
    {
      "epoch": 998.87,
      "learning_rate": 0.00015331528086816375,
      "loss": 2.2856,
      "step": 621300
    },
    {
      "epoch": 998.91,
      "learning_rate": 0.0001500998499999946,
      "loss": 2.2897,
      "step": 621320
    },
    {
      "epoch": 998.94,
      "learning_rate": 0.0001468844191318365,
      "loss": 2.2762,
      "step": 621340
    },
    {
      "epoch": 998.97,
      "learning_rate": 0.00014366898826366736,
      "loss": 2.2654,
      "step": 621360
    },
    {
      "epoch": 999.0,
      "eval_accuracy": {
        "accuracy": 0.4935085127886185
      },
      "eval_loss": 2.3847908973693848,
      "eval_runtime": 3.2516,
      "eval_samples_per_second": 3955.856,
      "eval_steps_per_second": 61.815,
      "step": 621378
    },
    {
      "epoch": 999.0,
      "learning_rate": 0.00014045355739549818,
      "loss": 2.2713,
      "step": 621380
    },
    {
      "epoch": 999.04,
      "learning_rate": 0.000137238126527329,
      "loss": 2.2719,
      "step": 621400
    },
    {
      "epoch": 999.07,
      "learning_rate": 0.00013402269565915983,
      "loss": 2.2549,
      "step": 621420
    },
    {
      "epoch": 999.1,
      "learning_rate": 0.00013080726479100177,
      "loss": 2.2727,
      "step": 621440
    },
    {
      "epoch": 999.13,
      "learning_rate": 0.00012759183392283262,
      "loss": 2.2584,
      "step": 621460
    },
    {
      "epoch": 999.16,
      "learning_rate": 0.00012437640305466345,
      "loss": 2.2668,
      "step": 621480
    },
    {
      "epoch": 999.2,
      "learning_rate": 0.00012116097218649427,
      "loss": 2.277,
      "step": 621500
    },
    {
      "epoch": 999.23,
      "learning_rate": 0.00011794554131832512,
      "loss": 2.2501,
      "step": 621520
    },
    {
      "epoch": 999.26,
      "learning_rate": 0.00011473011045015592,
      "loss": 2.258,
      "step": 621540
    },
    {
      "epoch": 999.29,
      "learning_rate": 0.00011151467958199788,
      "loss": 2.2671,
      "step": 621560
    },
    {
      "epoch": 999.32,
      "learning_rate": 0.00010829924871382868,
      "loss": 2.2833,
      "step": 621580
    },
    {
      "epoch": 999.36,
      "learning_rate": 0.00010508381784565953,
      "loss": 2.2722,
      "step": 621600
    },
    {
      "epoch": 999.39,
      "learning_rate": 0.00010186838697749034,
      "loss": 2.2606,
      "step": 621620
    },
    {
      "epoch": 999.42,
      "learning_rate": 9.86529561093212e-05,
      "loss": 2.2621,
      "step": 621640
    },
    {
      "epoch": 999.45,
      "learning_rate": 9.543752524115202e-05,
      "loss": 2.2625,
      "step": 621660
    },
    {
      "epoch": 999.49,
      "learning_rate": 9.222209437299396e-05,
      "loss": 2.2758,
      "step": 621680
    },
    {
      "epoch": 999.52,
      "learning_rate": 8.90066635048248e-05,
      "loss": 2.2663,
      "step": 621700
    },
    {
      "epoch": 999.55,
      "learning_rate": 8.579123263665562e-05,
      "loss": 2.2572,
      "step": 621720
    },
    {
      "epoch": 999.58,
      "learning_rate": 8.257580176848646e-05,
      "loss": 2.2834,
      "step": 621740
    },
    {
      "epoch": 999.61,
      "learning_rate": 7.936037090031728e-05,
      "loss": 2.2569,
      "step": 621760
    },
    {
      "epoch": 999.65,
      "learning_rate": 7.614494003215922e-05,
      "loss": 2.2703,
      "step": 621780
    },
    {
      "epoch": 999.68,
      "learning_rate": 7.292950916399004e-05,
      "loss": 2.2722,
      "step": 621800
    },
    {
      "epoch": 999.71,
      "learning_rate": 6.971407829582088e-05,
      "loss": 2.2597,
      "step": 621820
    },
    {
      "epoch": 999.74,
      "learning_rate": 6.64986474276517e-05,
      "loss": 2.2577,
      "step": 621840
    },
    {
      "epoch": 999.77,
      "learning_rate": 6.328321655948254e-05,
      "loss": 2.271,
      "step": 621860
    },
    {
      "epoch": 999.81,
      "learning_rate": 6.006778569131337e-05,
      "loss": 2.2551,
      "step": 621880
    },
    {
      "epoch": 999.84,
      "learning_rate": 5.68523548231553e-05,
      "loss": 2.2701,
      "step": 621900
    },
    {
      "epoch": 999.87,
      "learning_rate": 5.363692395498614e-05,
      "loss": 2.2501,
      "step": 621920
    },
    {
      "epoch": 999.9,
      "learning_rate": 5.0421493086816966e-05,
      "loss": 2.2636,
      "step": 621940
    },
    {
      "epoch": 999.94,
      "learning_rate": 4.72060622186478e-05,
      "loss": 2.2574,
      "step": 621960
    },
    {
      "epoch": 999.97,
      "learning_rate": 4.399063135047863e-05,
      "loss": 2.2668,
      "step": 621980
    },
    {
      "epoch": 1000.0,
      "learning_rate": 4.077520048232056e-05,
      "loss": 2.2755,
      "step": 622000
    },
    {
      "epoch": 1000.0,
      "eval_accuracy": {
        "accuracy": 0.49389722459768326
      },
      "eval_loss": 2.3844196796417236,
      "eval_runtime": 3.2804,
      "eval_samples_per_second": 3921.109,
      "eval_steps_per_second": 61.272,
      "step": 622000
    }
  ],
  "max_steps": 622000,
  "num_train_epochs": 1000,
  "total_flos": 0.0,
  "trial_name": null,
  "trial_params": null
}
