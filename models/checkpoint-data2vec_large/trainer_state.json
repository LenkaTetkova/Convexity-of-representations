{
  "best_metric": 0.8012474775314331,
  "best_model_checkpoint": "/scratch/project_465000484/tetkoval/models_data2vec_large1/data2vec_large/checkpoint-620000",
  "epoch": 1000.0,
  "global_step": 620000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03,
      "learning_rate": 0.0999967741967742,
      "loss": 14.4115,
      "step": 20
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.09999354839354839,
      "loss": 12.4266,
      "step": 40
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.09999032259032259,
      "loss": 7.619,
      "step": 60
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.09998709678709679,
      "loss": 5.8728,
      "step": 80
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.09998387098387097,
      "loss": 5.0959,
      "step": 100
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.09998064518064517,
      "loss": 4.5936,
      "step": 120
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.09997741937741937,
      "loss": 4.2977,
      "step": 140
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.09997419357419354,
      "loss": 3.9853,
      "step": 160
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.09997096777096774,
      "loss": 3.7379,
      "step": 180
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.09996774196774194,
      "loss": 3.485,
      "step": 200
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.09996451616451613,
      "loss": 3.3108,
      "step": 220
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.09996129036129033,
      "loss": 3.1381,
      "step": 240
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.09995806455806452,
      "loss": 2.9651,
      "step": 260
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.09995483875483871,
      "loss": 2.837,
      "step": 280
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.09995161295161291,
      "loss": 2.7077,
      "step": 300
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.09994838714838711,
      "loss": 2.6154,
      "step": 320
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.09994516134516129,
      "loss": 2.5022,
      "step": 340
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.09994193554193549,
      "loss": 2.4615,
      "step": 360
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.09993870973870969,
      "loss": 2.3833,
      "step": 380
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.09993548393548388,
      "loss": 2.3263,
      "step": 400
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.09993225813225808,
      "loss": 2.2948,
      "step": 420
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.09992903232903227,
      "loss": 2.2459,
      "step": 440
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.09992580652580646,
      "loss": 2.2232,
      "step": 460
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.09992258072258065,
      "loss": 2.198,
      "step": 480
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.09991935491935484,
      "loss": 2.1361,
      "step": 500
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.09991612911612903,
      "loss": 2.1083,
      "step": 520
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.09991290331290323,
      "loss": 2.0867,
      "step": 540
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.09990967750967743,
      "loss": 2.0283,
      "step": 560
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.09990645170645161,
      "loss": 2.0138,
      "step": 580
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.09990322590322581,
      "loss": 2.0046,
      "step": 600
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.09990000010000001,
      "loss": 2.0504,
      "step": 620
    },
    {
      "epoch": 1.0,
      "eval_accuracy": {
        "accuracy": 0.5837171181016314
      },
      "eval_loss": 2.002906322479248,
      "eval_runtime": 23.9401,
      "eval_samples_per_second": 535.127,
      "eval_steps_per_second": 8.396,
      "step": 620
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0998967742967742,
      "loss": 2.0001,
      "step": 640
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0998935484935484,
      "loss": 1.9075,
      "step": 660
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0998903226903226,
      "loss": 1.8717,
      "step": 680
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.09988709688709678,
      "loss": 1.8802,
      "step": 700
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.09988387108387098,
      "loss": 1.8579,
      "step": 720
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.09988064528064518,
      "loss": 1.8135,
      "step": 740
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.09987741947741936,
      "loss": 1.7854,
      "step": 760
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.09987419367419355,
      "loss": 1.7973,
      "step": 780
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.09987096787096775,
      "loss": 1.8367,
      "step": 800
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.09986774206774193,
      "loss": 1.7986,
      "step": 820
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.09986451626451613,
      "loss": 1.7846,
      "step": 840
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.09986129046129033,
      "loss": 1.7579,
      "step": 860
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.09985806465806452,
      "loss": 1.784,
      "step": 880
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.09985483885483872,
      "loss": 1.7588,
      "step": 900
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.09985161305161291,
      "loss": 1.7637,
      "step": 920
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0998483872483871,
      "loss": 1.7703,
      "step": 940
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0998451614451613,
      "loss": 1.7278,
      "step": 960
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0998419356419355,
      "loss": 1.7467,
      "step": 980
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.09983870983870968,
      "loss": 1.6926,
      "step": 1000
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.09983548403548388,
      "loss": 1.6887,
      "step": 1020
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.09983225823225807,
      "loss": 1.6977,
      "step": 1040
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.09982903242903227,
      "loss": 1.6863,
      "step": 1060
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.09982580662580647,
      "loss": 1.6924,
      "step": 1080
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.09982258082258065,
      "loss": 1.6905,
      "step": 1100
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.09981935501935484,
      "loss": 1.6765,
      "step": 1120
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.09981612921612903,
      "loss": 1.6925,
      "step": 1140
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.09981290341290323,
      "loss": 1.7139,
      "step": 1160
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.09980967760967742,
      "loss": 1.7514,
      "step": 1180
    },
    {
      "epoch": 1.94,
      "learning_rate": 0.09980645180645162,
      "loss": 1.6445,
      "step": 1200
    },
    {
      "epoch": 1.97,
      "learning_rate": 0.09980322600322582,
      "loss": 1.6502,
      "step": 1220
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.0998000002,
      "loss": 1.6868,
      "step": 1240
    },
    {
      "epoch": 2.0,
      "eval_accuracy": {
        "accuracy": 0.6201701662633674
      },
      "eval_loss": 1.7443848848342896,
      "eval_runtime": 2.5904,
      "eval_samples_per_second": 4945.642,
      "eval_steps_per_second": 77.595,
      "step": 1240
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.0997967743967742,
      "loss": 1.7277,
      "step": 1260
    },
    {
      "epoch": 2.06,
      "learning_rate": 0.0997935485935484,
      "loss": 1.6481,
      "step": 1280
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.09979032279032259,
      "loss": 1.6246,
      "step": 1300
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.09978709698709678,
      "loss": 1.5947,
      "step": 1320
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.09978387118387097,
      "loss": 1.6237,
      "step": 1340
    },
    {
      "epoch": 2.19,
      "learning_rate": 0.09978064538064517,
      "loss": 1.6133,
      "step": 1360
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.09977741957741937,
      "loss": 1.5458,
      "step": 1380
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.09977419377419355,
      "loss": 1.5797,
      "step": 1400
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.09977096797096774,
      "loss": 1.5851,
      "step": 1420
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.09976774216774194,
      "loss": 1.6235,
      "step": 1440
    },
    {
      "epoch": 2.35,
      "learning_rate": 0.09976451636451614,
      "loss": 1.5878,
      "step": 1460
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.09976129056129032,
      "loss": 1.6035,
      "step": 1480
    },
    {
      "epoch": 2.42,
      "learning_rate": 0.09975806475806452,
      "loss": 1.6457,
      "step": 1500
    },
    {
      "epoch": 2.45,
      "learning_rate": 0.09975483895483872,
      "loss": 1.5648,
      "step": 1520
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.0997516131516129,
      "loss": 1.5922,
      "step": 1540
    },
    {
      "epoch": 2.52,
      "learning_rate": 0.0997483873483871,
      "loss": 1.5693,
      "step": 1560
    },
    {
      "epoch": 2.55,
      "learning_rate": 0.09974516154516129,
      "loss": 1.5668,
      "step": 1580
    },
    {
      "epoch": 2.58,
      "learning_rate": 0.09974193574193549,
      "loss": 1.5822,
      "step": 1600
    },
    {
      "epoch": 2.61,
      "learning_rate": 0.09973870993870969,
      "loss": 1.5801,
      "step": 1620
    },
    {
      "epoch": 2.65,
      "learning_rate": 0.09973548413548387,
      "loss": 1.5779,
      "step": 1640
    },
    {
      "epoch": 2.68,
      "learning_rate": 0.09973225833225807,
      "loss": 1.598,
      "step": 1660
    },
    {
      "epoch": 2.71,
      "learning_rate": 0.09972903252903227,
      "loss": 1.5696,
      "step": 1680
    },
    {
      "epoch": 2.74,
      "learning_rate": 0.09972580672580646,
      "loss": 1.5691,
      "step": 1700
    },
    {
      "epoch": 2.77,
      "learning_rate": 0.09972258092258064,
      "loss": 1.602,
      "step": 1720
    },
    {
      "epoch": 2.81,
      "learning_rate": 0.09971935511935484,
      "loss": 1.6075,
      "step": 1740
    },
    {
      "epoch": 2.84,
      "learning_rate": 0.09971612931612904,
      "loss": 1.5613,
      "step": 1760
    },
    {
      "epoch": 2.87,
      "learning_rate": 0.09971290351290323,
      "loss": 1.5644,
      "step": 1780
    },
    {
      "epoch": 2.9,
      "learning_rate": 0.09970967770967742,
      "loss": 1.5492,
      "step": 1800
    },
    {
      "epoch": 2.94,
      "learning_rate": 0.09970645190645162,
      "loss": 1.5498,
      "step": 1820
    },
    {
      "epoch": 2.97,
      "learning_rate": 0.09970322610322581,
      "loss": 1.5343,
      "step": 1840
    },
    {
      "epoch": 3.0,
      "learning_rate": 0.09970000030000001,
      "loss": 1.5535,
      "step": 1860
    },
    {
      "epoch": 3.0,
      "eval_accuracy": {
        "accuracy": 0.6460073374443838
      },
      "eval_loss": 1.6164740324020386,
      "eval_runtime": 2.5227,
      "eval_samples_per_second": 5078.198,
      "eval_steps_per_second": 79.675,
      "step": 1860
    },
    {
      "epoch": 3.03,
      "learning_rate": 0.0996967744967742,
      "loss": 1.5837,
      "step": 1880
    },
    {
      "epoch": 3.06,
      "learning_rate": 0.09969354869354839,
      "loss": 1.5564,
      "step": 1900
    },
    {
      "epoch": 3.1,
      "learning_rate": 0.09969032289032259,
      "loss": 1.6128,
      "step": 1920
    },
    {
      "epoch": 3.13,
      "learning_rate": 0.09968709708709678,
      "loss": 1.606,
      "step": 1940
    },
    {
      "epoch": 3.16,
      "learning_rate": 0.09968387128387098,
      "loss": 1.5812,
      "step": 1960
    },
    {
      "epoch": 3.19,
      "learning_rate": 0.09968064548064517,
      "loss": 1.5428,
      "step": 1980
    },
    {
      "epoch": 3.23,
      "learning_rate": 0.09967741967741936,
      "loss": 1.5631,
      "step": 2000
    },
    {
      "epoch": 3.26,
      "learning_rate": 0.09967419387419356,
      "loss": 1.5534,
      "step": 2020
    },
    {
      "epoch": 3.29,
      "learning_rate": 0.09967096807096774,
      "loss": 1.5181,
      "step": 2040
    },
    {
      "epoch": 3.32,
      "learning_rate": 0.09966774226774194,
      "loss": 1.502,
      "step": 2060
    },
    {
      "epoch": 3.35,
      "learning_rate": 0.09966451646451613,
      "loss": 1.5516,
      "step": 2080
    },
    {
      "epoch": 3.39,
      "learning_rate": 0.09966129066129033,
      "loss": 1.5214,
      "step": 2100
    },
    {
      "epoch": 3.42,
      "learning_rate": 0.09965806485806451,
      "loss": 1.4868,
      "step": 2120
    },
    {
      "epoch": 3.45,
      "learning_rate": 0.09965483905483871,
      "loss": 1.5044,
      "step": 2140
    },
    {
      "epoch": 3.48,
      "learning_rate": 0.09965161325161291,
      "loss": 1.5176,
      "step": 2160
    },
    {
      "epoch": 3.52,
      "learning_rate": 0.0996483874483871,
      "loss": 1.4998,
      "step": 2180
    },
    {
      "epoch": 3.55,
      "learning_rate": 0.0996451616451613,
      "loss": 1.5015,
      "step": 2200
    },
    {
      "epoch": 3.58,
      "learning_rate": 0.0996419358419355,
      "loss": 1.5164,
      "step": 2220
    },
    {
      "epoch": 3.61,
      "learning_rate": 0.09963871003870968,
      "loss": 1.5278,
      "step": 2240
    },
    {
      "epoch": 3.65,
      "learning_rate": 0.09963548423548388,
      "loss": 1.5598,
      "step": 2260
    },
    {
      "epoch": 3.68,
      "learning_rate": 0.09963225843225808,
      "loss": 1.5752,
      "step": 2280
    },
    {
      "epoch": 3.71,
      "learning_rate": 0.09962903262903226,
      "loss": 1.4923,
      "step": 2300
    },
    {
      "epoch": 3.74,
      "learning_rate": 0.09962580682580646,
      "loss": 1.4957,
      "step": 2320
    },
    {
      "epoch": 3.77,
      "learning_rate": 0.09962258102258065,
      "loss": 1.4913,
      "step": 2340
    },
    {
      "epoch": 3.81,
      "learning_rate": 0.09961935521935485,
      "loss": 1.512,
      "step": 2360
    },
    {
      "epoch": 3.84,
      "learning_rate": 0.09961612941612903,
      "loss": 1.5003,
      "step": 2380
    },
    {
      "epoch": 3.87,
      "learning_rate": 0.09961290361290323,
      "loss": 1.5447,
      "step": 2400
    },
    {
      "epoch": 3.9,
      "learning_rate": 0.09960967780967742,
      "loss": 1.5204,
      "step": 2420
    },
    {
      "epoch": 3.94,
      "learning_rate": 0.09960645200645162,
      "loss": 1.4992,
      "step": 2440
    },
    {
      "epoch": 3.97,
      "learning_rate": 0.09960322620322581,
      "loss": 1.4907,
      "step": 2460
    },
    {
      "epoch": 4.0,
      "learning_rate": 0.0996000004,
      "loss": 1.5183,
      "step": 2480
    },
    {
      "epoch": 4.0,
      "eval_accuracy": {
        "accuracy": 0.653032550152213
      },
      "eval_loss": 1.618455171585083,
      "eval_runtime": 2.6291,
      "eval_samples_per_second": 4872.796,
      "eval_steps_per_second": 76.452,
      "step": 2480
    },
    {
      "epoch": 4.03,
      "learning_rate": 0.0995967745967742,
      "loss": 1.554,
      "step": 2500
    },
    {
      "epoch": 4.06,
      "learning_rate": 0.0995935487935484,
      "loss": 1.4902,
      "step": 2520
    },
    {
      "epoch": 4.1,
      "learning_rate": 0.09959032299032258,
      "loss": 1.4434,
      "step": 2540
    },
    {
      "epoch": 4.13,
      "learning_rate": 0.09958709718709678,
      "loss": 1.4633,
      "step": 2560
    },
    {
      "epoch": 4.16,
      "learning_rate": 0.09958387138387098,
      "loss": 1.58,
      "step": 2580
    },
    {
      "epoch": 4.19,
      "learning_rate": 0.09958064558064517,
      "loss": 1.5205,
      "step": 2600
    },
    {
      "epoch": 4.23,
      "learning_rate": 0.09957741977741937,
      "loss": 1.4705,
      "step": 2620
    },
    {
      "epoch": 4.26,
      "learning_rate": 0.09957419397419356,
      "loss": 1.4564,
      "step": 2640
    },
    {
      "epoch": 4.29,
      "learning_rate": 0.09957096817096774,
      "loss": 1.4541,
      "step": 2660
    },
    {
      "epoch": 4.32,
      "learning_rate": 0.09956774236774193,
      "loss": 1.4699,
      "step": 2680
    },
    {
      "epoch": 4.35,
      "learning_rate": 0.09956451656451613,
      "loss": 1.4872,
      "step": 2700
    },
    {
      "epoch": 4.39,
      "learning_rate": 0.09956129076129032,
      "loss": 1.4848,
      "step": 2720
    },
    {
      "epoch": 4.42,
      "learning_rate": 0.09955806495806452,
      "loss": 1.4743,
      "step": 2740
    },
    {
      "epoch": 4.45,
      "learning_rate": 0.09955483915483872,
      "loss": 1.484,
      "step": 2760
    },
    {
      "epoch": 4.48,
      "learning_rate": 0.0995516133516129,
      "loss": 1.4589,
      "step": 2780
    },
    {
      "epoch": 4.52,
      "learning_rate": 0.0995483875483871,
      "loss": 1.4709,
      "step": 2800
    },
    {
      "epoch": 4.55,
      "learning_rate": 0.0995451617451613,
      "loss": 1.5092,
      "step": 2820
    },
    {
      "epoch": 4.58,
      "learning_rate": 0.09954193594193549,
      "loss": 1.4998,
      "step": 2840
    },
    {
      "epoch": 4.61,
      "learning_rate": 0.09953871013870969,
      "loss": 1.5076,
      "step": 2860
    },
    {
      "epoch": 4.65,
      "learning_rate": 0.09953548433548388,
      "loss": 1.5235,
      "step": 2880
    },
    {
      "epoch": 4.68,
      "learning_rate": 0.09953225853225807,
      "loss": 1.5255,
      "step": 2900
    },
    {
      "epoch": 4.71,
      "learning_rate": 0.09952903272903227,
      "loss": 1.5363,
      "step": 2920
    },
    {
      "epoch": 4.74,
      "learning_rate": 0.09952580692580647,
      "loss": 1.5129,
      "step": 2940
    },
    {
      "epoch": 4.77,
      "learning_rate": 0.09952258112258064,
      "loss": 1.4991,
      "step": 2960
    },
    {
      "epoch": 4.81,
      "learning_rate": 0.09951935531935484,
      "loss": 1.4994,
      "step": 2980
    },
    {
      "epoch": 4.84,
      "learning_rate": 0.09951612951612904,
      "loss": 1.4667,
      "step": 3000
    },
    {
      "epoch": 4.87,
      "learning_rate": 0.09951290371290322,
      "loss": 1.4983,
      "step": 3020
    },
    {
      "epoch": 4.9,
      "learning_rate": 0.09950967790967742,
      "loss": 1.4568,
      "step": 3040
    },
    {
      "epoch": 4.94,
      "learning_rate": 0.09950645210645162,
      "loss": 1.4705,
      "step": 3060
    },
    {
      "epoch": 4.97,
      "learning_rate": 0.0995032263032258,
      "loss": 1.5287,
      "step": 3080
    },
    {
      "epoch": 5.0,
      "learning_rate": 0.0995000005,
      "loss": 1.4952,
      "step": 3100
    },
    {
      "epoch": 5.0,
      "eval_accuracy": {
        "accuracy": 0.6680196705955819
      },
      "eval_loss": 1.55625581741333,
      "eval_runtime": 2.6541,
      "eval_samples_per_second": 4826.914,
      "eval_steps_per_second": 75.733,
      "step": 3100
    },
    {
      "epoch": 5.03,
      "learning_rate": 0.0994967746967742,
      "loss": 1.5154,
      "step": 3120
    },
    {
      "epoch": 5.06,
      "learning_rate": 0.09949354889354839,
      "loss": 1.4494,
      "step": 3140
    },
    {
      "epoch": 5.1,
      "learning_rate": 0.09949032309032259,
      "loss": 1.4784,
      "step": 3160
    },
    {
      "epoch": 5.13,
      "learning_rate": 0.09948709728709679,
      "loss": 1.398,
      "step": 3180
    },
    {
      "epoch": 5.16,
      "learning_rate": 0.09948387148387097,
      "loss": 1.3959,
      "step": 3200
    },
    {
      "epoch": 5.19,
      "learning_rate": 0.09948064568064517,
      "loss": 1.4404,
      "step": 3220
    },
    {
      "epoch": 5.23,
      "learning_rate": 0.09947741987741937,
      "loss": 1.4918,
      "step": 3240
    },
    {
      "epoch": 5.26,
      "learning_rate": 0.09947419407419356,
      "loss": 1.4833,
      "step": 3260
    },
    {
      "epoch": 5.29,
      "learning_rate": 0.09947096827096774,
      "loss": 1.4685,
      "step": 3280
    },
    {
      "epoch": 5.32,
      "learning_rate": 0.09946774246774194,
      "loss": 1.495,
      "step": 3300
    },
    {
      "epoch": 5.35,
      "learning_rate": 0.09946451666451613,
      "loss": 1.516,
      "step": 3320
    },
    {
      "epoch": 5.39,
      "learning_rate": 0.09946129086129032,
      "loss": 1.51,
      "step": 3340
    },
    {
      "epoch": 5.42,
      "learning_rate": 0.09945806505806452,
      "loss": 1.5023,
      "step": 3360
    },
    {
      "epoch": 5.45,
      "learning_rate": 0.09945483925483871,
      "loss": 1.4514,
      "step": 3380
    },
    {
      "epoch": 5.48,
      "learning_rate": 0.09945161345161291,
      "loss": 1.4375,
      "step": 3400
    },
    {
      "epoch": 5.52,
      "learning_rate": 0.09944838764838711,
      "loss": 1.4725,
      "step": 3420
    },
    {
      "epoch": 5.55,
      "learning_rate": 0.09944516184516129,
      "loss": 1.5403,
      "step": 3440
    },
    {
      "epoch": 5.58,
      "learning_rate": 0.09944193604193549,
      "loss": 1.4617,
      "step": 3460
    },
    {
      "epoch": 5.61,
      "learning_rate": 0.09943871023870969,
      "loss": 1.438,
      "step": 3480
    },
    {
      "epoch": 5.65,
      "learning_rate": 0.09943548443548388,
      "loss": 1.4518,
      "step": 3500
    },
    {
      "epoch": 5.68,
      "learning_rate": 0.09943225863225807,
      "loss": 1.4636,
      "step": 3520
    },
    {
      "epoch": 5.71,
      "learning_rate": 0.09942903282903227,
      "loss": 1.4485,
      "step": 3540
    },
    {
      "epoch": 5.74,
      "learning_rate": 0.09942580702580646,
      "loss": 1.4371,
      "step": 3560
    },
    {
      "epoch": 5.77,
      "learning_rate": 0.09942258122258066,
      "loss": 1.4566,
      "step": 3580
    },
    {
      "epoch": 5.81,
      "learning_rate": 0.09941935541935484,
      "loss": 1.4475,
      "step": 3600
    },
    {
      "epoch": 5.84,
      "learning_rate": 0.09941612961612903,
      "loss": 1.4735,
      "step": 3620
    },
    {
      "epoch": 5.87,
      "learning_rate": 0.09941290381290323,
      "loss": 1.5172,
      "step": 3640
    },
    {
      "epoch": 5.9,
      "learning_rate": 0.09940967800967743,
      "loss": 1.4155,
      "step": 3660
    },
    {
      "epoch": 5.94,
      "learning_rate": 0.09940645220645161,
      "loss": 1.4313,
      "step": 3680
    },
    {
      "epoch": 5.97,
      "learning_rate": 0.09940322640322581,
      "loss": 1.4133,
      "step": 3700
    },
    {
      "epoch": 6.0,
      "learning_rate": 0.09940000060000001,
      "loss": 1.467,
      "step": 3720
    },
    {
      "epoch": 6.0,
      "eval_accuracy": {
        "accuracy": 0.6656779330263055
      },
      "eval_loss": 1.5661180019378662,
      "eval_runtime": 3.2252,
      "eval_samples_per_second": 3972.191,
      "eval_steps_per_second": 62.322,
      "step": 3720
    },
    {
      "epoch": 6.03,
      "learning_rate": 0.0993967747967742,
      "loss": 1.5107,
      "step": 3740
    },
    {
      "epoch": 6.06,
      "learning_rate": 0.0993935489935484,
      "loss": 1.4845,
      "step": 3760
    },
    {
      "epoch": 6.1,
      "learning_rate": 0.0993903231903226,
      "loss": 1.4296,
      "step": 3780
    },
    {
      "epoch": 6.13,
      "learning_rate": 0.09938709738709678,
      "loss": 1.4334,
      "step": 3800
    },
    {
      "epoch": 6.16,
      "learning_rate": 0.09938387158387098,
      "loss": 1.4594,
      "step": 3820
    },
    {
      "epoch": 6.19,
      "learning_rate": 0.09938064578064518,
      "loss": 1.39,
      "step": 3840
    },
    {
      "epoch": 6.23,
      "learning_rate": 0.09937741997741936,
      "loss": 1.4295,
      "step": 3860
    },
    {
      "epoch": 6.26,
      "learning_rate": 0.09937419417419356,
      "loss": 1.4155,
      "step": 3880
    },
    {
      "epoch": 6.29,
      "learning_rate": 0.09937096837096775,
      "loss": 1.4647,
      "step": 3900
    },
    {
      "epoch": 6.32,
      "learning_rate": 0.09936774256774193,
      "loss": 1.4685,
      "step": 3920
    },
    {
      "epoch": 6.35,
      "learning_rate": 0.09936451676451613,
      "loss": 1.4241,
      "step": 3940
    },
    {
      "epoch": 6.39,
      "learning_rate": 0.09936129096129033,
      "loss": 1.3996,
      "step": 3960
    },
    {
      "epoch": 6.42,
      "learning_rate": 0.09935806515806452,
      "loss": 1.4232,
      "step": 3980
    },
    {
      "epoch": 6.45,
      "learning_rate": 0.09935483935483871,
      "loss": 1.4249,
      "step": 4000
    },
    {
      "epoch": 6.48,
      "learning_rate": 0.09935161355161291,
      "loss": 1.4325,
      "step": 4020
    },
    {
      "epoch": 6.52,
      "learning_rate": 0.0993483877483871,
      "loss": 1.3866,
      "step": 4040
    },
    {
      "epoch": 6.55,
      "learning_rate": 0.0993451619451613,
      "loss": 1.4203,
      "step": 4060
    },
    {
      "epoch": 6.58,
      "learning_rate": 0.0993419361419355,
      "loss": 1.3968,
      "step": 4080
    },
    {
      "epoch": 6.61,
      "learning_rate": 0.09933871033870968,
      "loss": 1.4454,
      "step": 4100
    },
    {
      "epoch": 6.65,
      "learning_rate": 0.09933548453548388,
      "loss": 1.4539,
      "step": 4120
    },
    {
      "epoch": 6.68,
      "learning_rate": 0.09933225873225808,
      "loss": 1.4135,
      "step": 4140
    },
    {
      "epoch": 6.71,
      "learning_rate": 0.09932903292903227,
      "loss": 1.4262,
      "step": 4160
    },
    {
      "epoch": 6.74,
      "learning_rate": 0.09932580712580646,
      "loss": 1.4269,
      "step": 4180
    },
    {
      "epoch": 6.77,
      "learning_rate": 0.09932258132258065,
      "loss": 1.4116,
      "step": 4200
    },
    {
      "epoch": 6.81,
      "learning_rate": 0.09931935551935483,
      "loss": 1.4022,
      "step": 4220
    },
    {
      "epoch": 6.84,
      "learning_rate": 0.09931612971612903,
      "loss": 1.4313,
      "step": 4240
    },
    {
      "epoch": 6.87,
      "learning_rate": 0.09931290391290323,
      "loss": 1.4133,
      "step": 4260
    },
    {
      "epoch": 6.9,
      "learning_rate": 0.09930967810967742,
      "loss": 1.4144,
      "step": 4280
    },
    {
      "epoch": 6.94,
      "learning_rate": 0.09930645230645162,
      "loss": 1.4029,
      "step": 4300
    },
    {
      "epoch": 6.97,
      "learning_rate": 0.09930322650322582,
      "loss": 1.4323,
      "step": 4320
    },
    {
      "epoch": 7.0,
      "learning_rate": 0.0993000007,
      "loss": 1.4808,
      "step": 4340
    },
    {
      "epoch": 7.0,
      "eval_accuracy": {
        "accuracy": 0.6752009991413629
      },
      "eval_loss": 1.588139295578003,
      "eval_runtime": 6.3818,
      "eval_samples_per_second": 2007.423,
      "eval_steps_per_second": 31.496,
      "step": 4340
    },
    {
      "epoch": 7.03,
      "learning_rate": 0.0992967748967742,
      "loss": 1.5576,
      "step": 4360
    },
    {
      "epoch": 7.06,
      "learning_rate": 0.0992935490935484,
      "loss": 1.5034,
      "step": 4380
    },
    {
      "epoch": 7.1,
      "learning_rate": 0.09929032329032259,
      "loss": 1.4813,
      "step": 4400
    },
    {
      "epoch": 7.13,
      "learning_rate": 0.09928709748709678,
      "loss": 1.3486,
      "step": 4420
    },
    {
      "epoch": 7.16,
      "learning_rate": 0.09928387168387097,
      "loss": 1.4166,
      "step": 4440
    },
    {
      "epoch": 7.19,
      "learning_rate": 0.09928064588064517,
      "loss": 1.4292,
      "step": 4460
    },
    {
      "epoch": 7.23,
      "learning_rate": 0.09927742007741937,
      "loss": 1.4711,
      "step": 4480
    },
    {
      "epoch": 7.26,
      "learning_rate": 0.09927419427419355,
      "loss": 1.4542,
      "step": 4500
    },
    {
      "epoch": 7.29,
      "learning_rate": 0.09927096847096774,
      "loss": 1.4508,
      "step": 4520
    },
    {
      "epoch": 7.32,
      "learning_rate": 0.09926774266774194,
      "loss": 1.4336,
      "step": 4540
    },
    {
      "epoch": 7.35,
      "learning_rate": 0.09926451686451614,
      "loss": 1.389,
      "step": 4560
    },
    {
      "epoch": 7.39,
      "learning_rate": 0.09926129106129032,
      "loss": 1.3973,
      "step": 4580
    },
    {
      "epoch": 7.42,
      "learning_rate": 0.09925806525806452,
      "loss": 1.4174,
      "step": 4600
    },
    {
      "epoch": 7.45,
      "learning_rate": 0.09925483945483872,
      "loss": 1.4091,
      "step": 4620
    },
    {
      "epoch": 7.48,
      "learning_rate": 0.0992516136516129,
      "loss": 1.4123,
      "step": 4640
    },
    {
      "epoch": 7.52,
      "learning_rate": 0.0992483878483871,
      "loss": 1.4199,
      "step": 4660
    },
    {
      "epoch": 7.55,
      "learning_rate": 0.0992451620451613,
      "loss": 1.4473,
      "step": 4680
    },
    {
      "epoch": 7.58,
      "learning_rate": 0.09924193624193549,
      "loss": 1.3996,
      "step": 4700
    },
    {
      "epoch": 7.61,
      "learning_rate": 0.09923871043870969,
      "loss": 1.4326,
      "step": 4720
    },
    {
      "epoch": 7.65,
      "learning_rate": 0.09923548463548387,
      "loss": 1.3697,
      "step": 4740
    },
    {
      "epoch": 7.68,
      "learning_rate": 0.09923225883225807,
      "loss": 1.3931,
      "step": 4760
    },
    {
      "epoch": 7.71,
      "learning_rate": 0.09922903302903227,
      "loss": 1.4357,
      "step": 4780
    },
    {
      "epoch": 7.74,
      "learning_rate": 0.09922580722580646,
      "loss": 1.4352,
      "step": 4800
    },
    {
      "epoch": 7.77,
      "learning_rate": 0.09922258142258066,
      "loss": 1.3991,
      "step": 4820
    },
    {
      "epoch": 7.81,
      "learning_rate": 0.09921935561935484,
      "loss": 1.4191,
      "step": 4840
    },
    {
      "epoch": 7.84,
      "learning_rate": 0.09921612981612904,
      "loss": 1.4218,
      "step": 4860
    },
    {
      "epoch": 7.87,
      "learning_rate": 0.09921290401290322,
      "loss": 1.415,
      "step": 4880
    },
    {
      "epoch": 7.9,
      "learning_rate": 0.09920967820967742,
      "loss": 1.4201,
      "step": 4900
    },
    {
      "epoch": 7.94,
      "learning_rate": 0.09920645240645162,
      "loss": 1.4266,
      "step": 4920
    },
    {
      "epoch": 7.97,
      "learning_rate": 0.09920322660322581,
      "loss": 1.4105,
      "step": 4940
    },
    {
      "epoch": 8.0,
      "learning_rate": 0.09920000080000001,
      "loss": 1.4108,
      "step": 4960
    },
    {
      "epoch": 8.0,
      "eval_accuracy": {
        "accuracy": 0.6804308797127468
      },
      "eval_loss": 1.5135067701339722,
      "eval_runtime": 4.2541,
      "eval_samples_per_second": 3011.471,
      "eval_steps_per_second": 47.249,
      "step": 4960
    },
    {
      "epoch": 8.03,
      "learning_rate": 0.09919677499677419,
      "loss": 1.4324,
      "step": 4980
    },
    {
      "epoch": 8.06,
      "learning_rate": 0.09919354919354839,
      "loss": 1.3785,
      "step": 5000
    },
    {
      "epoch": 8.1,
      "learning_rate": 0.09919032339032259,
      "loss": 1.3933,
      "step": 5020
    },
    {
      "epoch": 8.13,
      "learning_rate": 0.09918709758709678,
      "loss": 1.4005,
      "step": 5040
    },
    {
      "epoch": 8.16,
      "learning_rate": 0.09918387178387097,
      "loss": 1.3962,
      "step": 5060
    },
    {
      "epoch": 8.19,
      "learning_rate": 0.09918064598064517,
      "loss": 1.4044,
      "step": 5080
    },
    {
      "epoch": 8.23,
      "learning_rate": 0.09917742017741936,
      "loss": 1.3978,
      "step": 5100
    },
    {
      "epoch": 8.26,
      "learning_rate": 0.09917419437419356,
      "loss": 1.3822,
      "step": 5120
    },
    {
      "epoch": 8.29,
      "learning_rate": 0.09917096857096774,
      "loss": 1.3737,
      "step": 5140
    },
    {
      "epoch": 8.32,
      "learning_rate": 0.09916774276774194,
      "loss": 1.3464,
      "step": 5160
    },
    {
      "epoch": 8.35,
      "learning_rate": 0.09916451696451613,
      "loss": 1.3379,
      "step": 5180
    },
    {
      "epoch": 8.39,
      "learning_rate": 0.09916129116129033,
      "loss": 1.3394,
      "step": 5200
    },
    {
      "epoch": 8.42,
      "learning_rate": 0.09915806535806453,
      "loss": 1.396,
      "step": 5220
    },
    {
      "epoch": 8.45,
      "learning_rate": 0.09915483955483871,
      "loss": 1.4132,
      "step": 5240
    },
    {
      "epoch": 8.48,
      "learning_rate": 0.09915161375161291,
      "loss": 1.4734,
      "step": 5260
    },
    {
      "epoch": 8.52,
      "learning_rate": 0.0991483879483871,
      "loss": 1.4954,
      "step": 5280
    },
    {
      "epoch": 8.55,
      "learning_rate": 0.0991451621451613,
      "loss": 1.4786,
      "step": 5300
    },
    {
      "epoch": 8.58,
      "learning_rate": 0.0991419363419355,
      "loss": 1.4217,
      "step": 5320
    },
    {
      "epoch": 8.61,
      "learning_rate": 0.09913871053870968,
      "loss": 1.4164,
      "step": 5340
    },
    {
      "epoch": 8.65,
      "learning_rate": 0.09913548473548388,
      "loss": 1.4037,
      "step": 5360
    },
    {
      "epoch": 8.68,
      "learning_rate": 0.09913225893225808,
      "loss": 1.3741,
      "step": 5380
    },
    {
      "epoch": 8.71,
      "learning_rate": 0.09912903312903226,
      "loss": 1.3824,
      "step": 5400
    },
    {
      "epoch": 8.74,
      "learning_rate": 0.09912580732580646,
      "loss": 1.3945,
      "step": 5420
    },
    {
      "epoch": 8.77,
      "learning_rate": 0.09912258152258066,
      "loss": 1.4103,
      "step": 5440
    },
    {
      "epoch": 8.81,
      "learning_rate": 0.09911935571935485,
      "loss": 1.3959,
      "step": 5460
    },
    {
      "epoch": 8.84,
      "learning_rate": 0.09911612991612903,
      "loss": 1.4145,
      "step": 5480
    },
    {
      "epoch": 8.87,
      "learning_rate": 0.09911290411290323,
      "loss": 1.3998,
      "step": 5500
    },
    {
      "epoch": 8.9,
      "learning_rate": 0.09910967830967742,
      "loss": 1.4106,
      "step": 5520
    },
    {
      "epoch": 8.94,
      "learning_rate": 0.09910645250645161,
      "loss": 1.3997,
      "step": 5540
    },
    {
      "epoch": 8.97,
      "learning_rate": 0.09910322670322581,
      "loss": 1.379,
      "step": 5560
    },
    {
      "epoch": 9.0,
      "learning_rate": 0.0991000009,
      "loss": 1.3878,
      "step": 5580
    },
    {
      "epoch": 9.0,
      "eval_accuracy": {
        "accuracy": 0.6808211693076263
      },
      "eval_loss": 1.5550634860992432,
      "eval_runtime": 2.4941,
      "eval_samples_per_second": 5136.583,
      "eval_steps_per_second": 80.591,
      "step": 5580
    },
    {
      "epoch": 9.03,
      "learning_rate": 0.0990967750967742,
      "loss": 1.4647,
      "step": 5600
    },
    {
      "epoch": 9.06,
      "learning_rate": 0.0990935492935484,
      "loss": 1.4648,
      "step": 5620
    },
    {
      "epoch": 9.1,
      "learning_rate": 0.09909032349032258,
      "loss": 1.4255,
      "step": 5640
    },
    {
      "epoch": 9.13,
      "learning_rate": 0.09908709768709678,
      "loss": 1.3806,
      "step": 5660
    },
    {
      "epoch": 9.16,
      "learning_rate": 0.09908387188387098,
      "loss": 1.3816,
      "step": 5680
    },
    {
      "epoch": 9.19,
      "learning_rate": 0.09908064608064517,
      "loss": 1.3675,
      "step": 5700
    },
    {
      "epoch": 9.23,
      "learning_rate": 0.09907742027741936,
      "loss": 1.4268,
      "step": 5720
    },
    {
      "epoch": 9.26,
      "learning_rate": 0.09907419447419356,
      "loss": 1.4501,
      "step": 5740
    },
    {
      "epoch": 9.29,
      "learning_rate": 0.09907096867096775,
      "loss": 1.3808,
      "step": 5760
    },
    {
      "epoch": 9.32,
      "learning_rate": 0.09906774286774193,
      "loss": 1.3934,
      "step": 5780
    },
    {
      "epoch": 9.35,
      "learning_rate": 0.09906451706451613,
      "loss": 1.4411,
      "step": 5800
    },
    {
      "epoch": 9.39,
      "learning_rate": 0.09906129126129032,
      "loss": 1.3691,
      "step": 5820
    },
    {
      "epoch": 9.42,
      "learning_rate": 0.09905806545806452,
      "loss": 1.3719,
      "step": 5840
    },
    {
      "epoch": 9.45,
      "learning_rate": 0.09905483965483872,
      "loss": 1.4212,
      "step": 5860
    },
    {
      "epoch": 9.48,
      "learning_rate": 0.0990516138516129,
      "loss": 1.3723,
      "step": 5880
    },
    {
      "epoch": 9.52,
      "learning_rate": 0.0990483880483871,
      "loss": 1.3711,
      "step": 5900
    },
    {
      "epoch": 9.55,
      "learning_rate": 0.0990451622451613,
      "loss": 1.3894,
      "step": 5920
    },
    {
      "epoch": 9.58,
      "learning_rate": 0.09904193644193549,
      "loss": 1.3546,
      "step": 5940
    },
    {
      "epoch": 9.61,
      "learning_rate": 0.09903871063870968,
      "loss": 1.3508,
      "step": 5960
    },
    {
      "epoch": 9.65,
      "learning_rate": 0.09903548483548388,
      "loss": 1.3883,
      "step": 5980
    },
    {
      "epoch": 9.68,
      "learning_rate": 0.09903225903225807,
      "loss": 1.4134,
      "step": 6000
    },
    {
      "epoch": 9.71,
      "learning_rate": 0.09902903322903227,
      "loss": 1.4072,
      "step": 6020
    },
    {
      "epoch": 9.74,
      "learning_rate": 0.09902580742580647,
      "loss": 1.3888,
      "step": 6040
    },
    {
      "epoch": 9.77,
      "learning_rate": 0.09902258162258065,
      "loss": 1.3979,
      "step": 6060
    },
    {
      "epoch": 9.81,
      "learning_rate": 0.09901935581935484,
      "loss": 1.3875,
      "step": 6080
    },
    {
      "epoch": 9.84,
      "learning_rate": 0.09901613001612904,
      "loss": 1.3756,
      "step": 6100
    },
    {
      "epoch": 9.87,
      "learning_rate": 0.09901290421290322,
      "loss": 1.3958,
      "step": 6120
    },
    {
      "epoch": 9.9,
      "learning_rate": 0.09900967840967742,
      "loss": 1.3876,
      "step": 6140
    },
    {
      "epoch": 9.94,
      "learning_rate": 0.09900645260645162,
      "loss": 1.3802,
      "step": 6160
    },
    {
      "epoch": 9.97,
      "learning_rate": 0.0990032268032258,
      "loss": 1.385,
      "step": 6180
    },
    {
      "epoch": 10.0,
      "learning_rate": 0.099000001,
      "loss": 1.4323,
      "step": 6200
    },
    {
      "epoch": 10.0,
      "eval_accuracy": {
        "accuracy": 0.6994770119428616
      },
      "eval_loss": 1.4788246154785156,
      "eval_runtime": 2.4677,
      "eval_samples_per_second": 5191.469,
      "eval_steps_per_second": 81.452,
      "step": 6200
    },
    {
      "epoch": 10.03,
      "learning_rate": 0.0989967751967742,
      "loss": 1.4495,
      "step": 6220
    },
    {
      "epoch": 10.06,
      "learning_rate": 0.09899354939354839,
      "loss": 1.3578,
      "step": 6240
    },
    {
      "epoch": 10.1,
      "learning_rate": 0.09899032359032259,
      "loss": 1.3425,
      "step": 6260
    },
    {
      "epoch": 10.13,
      "learning_rate": 0.09898709778709679,
      "loss": 1.3531,
      "step": 6280
    },
    {
      "epoch": 10.16,
      "learning_rate": 0.09898387198387097,
      "loss": 1.33,
      "step": 6300
    },
    {
      "epoch": 10.19,
      "learning_rate": 0.09898064618064517,
      "loss": 1.3625,
      "step": 6320
    },
    {
      "epoch": 10.23,
      "learning_rate": 0.09897742037741937,
      "loss": 1.3231,
      "step": 6340
    },
    {
      "epoch": 10.26,
      "learning_rate": 0.09897419457419356,
      "loss": 1.3764,
      "step": 6360
    },
    {
      "epoch": 10.29,
      "learning_rate": 0.09897096877096774,
      "loss": 1.3762,
      "step": 6380
    },
    {
      "epoch": 10.32,
      "learning_rate": 0.09896774296774194,
      "loss": 1.3542,
      "step": 6400
    },
    {
      "epoch": 10.35,
      "learning_rate": 0.09896451716451612,
      "loss": 1.3626,
      "step": 6420
    },
    {
      "epoch": 10.39,
      "learning_rate": 0.09896129136129032,
      "loss": 1.3619,
      "step": 6440
    },
    {
      "epoch": 10.42,
      "learning_rate": 0.09895806555806452,
      "loss": 1.3845,
      "step": 6460
    },
    {
      "epoch": 10.45,
      "learning_rate": 0.09895483975483871,
      "loss": 1.3297,
      "step": 6480
    },
    {
      "epoch": 10.48,
      "learning_rate": 0.09895161395161291,
      "loss": 1.3851,
      "step": 6500
    },
    {
      "epoch": 10.52,
      "learning_rate": 0.0989483881483871,
      "loss": 1.3895,
      "step": 6520
    },
    {
      "epoch": 10.55,
      "learning_rate": 0.09894516234516129,
      "loss": 1.3796,
      "step": 6540
    },
    {
      "epoch": 10.58,
      "learning_rate": 0.09894193654193549,
      "loss": 1.4449,
      "step": 6560
    },
    {
      "epoch": 10.61,
      "learning_rate": 0.09893871073870969,
      "loss": 1.4137,
      "step": 6580
    },
    {
      "epoch": 10.65,
      "learning_rate": 0.09893548493548388,
      "loss": 1.3655,
      "step": 6600
    },
    {
      "epoch": 10.68,
      "learning_rate": 0.09893225913225807,
      "loss": 1.3623,
      "step": 6620
    },
    {
      "epoch": 10.71,
      "learning_rate": 0.09892903332903227,
      "loss": 1.3469,
      "step": 6640
    },
    {
      "epoch": 10.74,
      "learning_rate": 0.09892580752580646,
      "loss": 1.3588,
      "step": 6660
    },
    {
      "epoch": 10.77,
      "learning_rate": 0.09892258172258066,
      "loss": 1.3789,
      "step": 6680
    },
    {
      "epoch": 10.81,
      "learning_rate": 0.09891935591935484,
      "loss": 1.364,
      "step": 6700
    },
    {
      "epoch": 10.84,
      "learning_rate": 0.09891613011612903,
      "loss": 1.3651,
      "step": 6720
    },
    {
      "epoch": 10.87,
      "learning_rate": 0.09891290431290323,
      "loss": 1.3776,
      "step": 6740
    },
    {
      "epoch": 10.9,
      "learning_rate": 0.09890967850967743,
      "loss": 1.3466,
      "step": 6760
    },
    {
      "epoch": 10.94,
      "learning_rate": 0.09890645270645161,
      "loss": 1.3511,
      "step": 6780
    },
    {
      "epoch": 10.97,
      "learning_rate": 0.09890322690322581,
      "loss": 1.3521,
      "step": 6800
    },
    {
      "epoch": 11.0,
      "learning_rate": 0.09890000110000001,
      "loss": 1.373,
      "step": 6820
    },
    {
      "epoch": 11.0,
      "eval_accuracy": {
        "accuracy": 0.686831629068769
      },
      "eval_loss": 1.5398774147033691,
      "eval_runtime": 3.7967,
      "eval_samples_per_second": 3374.267,
      "eval_steps_per_second": 52.941,
      "step": 6820
    },
    {
      "epoch": 11.03,
      "learning_rate": 0.0988967752967742,
      "loss": 1.4398,
      "step": 6840
    },
    {
      "epoch": 11.06,
      "learning_rate": 0.0988935494935484,
      "loss": 1.3572,
      "step": 6860
    },
    {
      "epoch": 11.1,
      "learning_rate": 0.09889032369032259,
      "loss": 1.3144,
      "step": 6880
    },
    {
      "epoch": 11.13,
      "learning_rate": 0.09888709788709678,
      "loss": 1.3524,
      "step": 6900
    },
    {
      "epoch": 11.16,
      "learning_rate": 0.09888387208387098,
      "loss": 1.3672,
      "step": 6920
    },
    {
      "epoch": 11.19,
      "learning_rate": 0.09888064628064518,
      "loss": 1.3807,
      "step": 6940
    },
    {
      "epoch": 11.23,
      "learning_rate": 0.09887742047741936,
      "loss": 1.3606,
      "step": 6960
    },
    {
      "epoch": 11.26,
      "learning_rate": 0.09887419467419356,
      "loss": 1.3553,
      "step": 6980
    },
    {
      "epoch": 11.29,
      "learning_rate": 0.09887096887096776,
      "loss": 1.4554,
      "step": 7000
    },
    {
      "epoch": 11.32,
      "learning_rate": 0.09886774306774193,
      "loss": 1.42,
      "step": 7020
    },
    {
      "epoch": 11.35,
      "learning_rate": 0.09886451726451613,
      "loss": 1.3568,
      "step": 7040
    },
    {
      "epoch": 11.39,
      "learning_rate": 0.09886129146129033,
      "loss": 1.3067,
      "step": 7060
    },
    {
      "epoch": 11.42,
      "learning_rate": 0.09885806565806451,
      "loss": 1.3711,
      "step": 7080
    },
    {
      "epoch": 11.45,
      "learning_rate": 0.09885483985483871,
      "loss": 1.3511,
      "step": 7100
    },
    {
      "epoch": 11.48,
      "learning_rate": 0.09885161405161291,
      "loss": 1.3515,
      "step": 7120
    },
    {
      "epoch": 11.52,
      "learning_rate": 0.0988483882483871,
      "loss": 1.3659,
      "step": 7140
    },
    {
      "epoch": 11.55,
      "learning_rate": 0.0988451624451613,
      "loss": 1.3624,
      "step": 7160
    },
    {
      "epoch": 11.58,
      "learning_rate": 0.0988419366419355,
      "loss": 1.3534,
      "step": 7180
    },
    {
      "epoch": 11.61,
      "learning_rate": 0.09883871083870968,
      "loss": 1.3418,
      "step": 7200
    },
    {
      "epoch": 11.65,
      "learning_rate": 0.09883548503548388,
      "loss": 1.3922,
      "step": 7220
    },
    {
      "epoch": 11.68,
      "learning_rate": 0.09883225923225808,
      "loss": 1.3636,
      "step": 7240
    },
    {
      "epoch": 11.71,
      "learning_rate": 0.09882903342903226,
      "loss": 1.368,
      "step": 7260
    },
    {
      "epoch": 11.74,
      "learning_rate": 0.09882580762580646,
      "loss": 1.3801,
      "step": 7280
    },
    {
      "epoch": 11.77,
      "learning_rate": 0.09882258182258065,
      "loss": 1.3173,
      "step": 7300
    },
    {
      "epoch": 11.81,
      "learning_rate": 0.09881935601935483,
      "loss": 1.3234,
      "step": 7320
    },
    {
      "epoch": 11.84,
      "learning_rate": 0.09881613021612903,
      "loss": 1.34,
      "step": 7340
    },
    {
      "epoch": 11.87,
      "learning_rate": 0.09881290441290323,
      "loss": 1.343,
      "step": 7360
    },
    {
      "epoch": 11.9,
      "learning_rate": 0.09880967860967742,
      "loss": 1.3755,
      "step": 7380
    },
    {
      "epoch": 11.94,
      "learning_rate": 0.09880645280645162,
      "loss": 1.3837,
      "step": 7400
    },
    {
      "epoch": 11.97,
      "learning_rate": 0.09880322700322582,
      "loss": 1.367,
      "step": 7420
    },
    {
      "epoch": 12.0,
      "learning_rate": 0.0988000012,
      "loss": 1.3791,
      "step": 7440
    },
    {
      "epoch": 12.0,
      "eval_accuracy": {
        "accuracy": 0.687456092420576
      },
      "eval_loss": 1.528671383857727,
      "eval_runtime": 2.5399,
      "eval_samples_per_second": 5043.827,
      "eval_steps_per_second": 79.136,
      "step": 7440
    },
    {
      "epoch": 12.03,
      "learning_rate": 0.0987967753967742,
      "loss": 1.3905,
      "step": 7460
    },
    {
      "epoch": 12.06,
      "learning_rate": 0.0987935495935484,
      "loss": 1.3022,
      "step": 7480
    },
    {
      "epoch": 12.1,
      "learning_rate": 0.09879032379032258,
      "loss": 1.3202,
      "step": 7500
    },
    {
      "epoch": 12.13,
      "learning_rate": 0.09878709798709678,
      "loss": 1.3765,
      "step": 7520
    },
    {
      "epoch": 12.16,
      "learning_rate": 0.09878387218387098,
      "loss": 1.3778,
      "step": 7540
    },
    {
      "epoch": 12.19,
      "learning_rate": 0.09878064638064517,
      "loss": 1.3285,
      "step": 7560
    },
    {
      "epoch": 12.23,
      "learning_rate": 0.09877742057741937,
      "loss": 1.3219,
      "step": 7580
    },
    {
      "epoch": 12.26,
      "learning_rate": 0.09877419477419355,
      "loss": 1.3275,
      "step": 7600
    },
    {
      "epoch": 12.29,
      "learning_rate": 0.09877096897096775,
      "loss": 1.3245,
      "step": 7620
    },
    {
      "epoch": 12.32,
      "learning_rate": 0.09876774316774194,
      "loss": 1.2986,
      "step": 7640
    },
    {
      "epoch": 12.35,
      "learning_rate": 0.09876451736451614,
      "loss": 1.3534,
      "step": 7660
    },
    {
      "epoch": 12.39,
      "learning_rate": 0.09876129156129032,
      "loss": 1.39,
      "step": 7680
    },
    {
      "epoch": 12.42,
      "learning_rate": 0.09875806575806452,
      "loss": 1.3092,
      "step": 7700
    },
    {
      "epoch": 12.45,
      "learning_rate": 0.09875483995483872,
      "loss": 1.3411,
      "step": 7720
    },
    {
      "epoch": 12.48,
      "learning_rate": 0.0987516141516129,
      "loss": 1.3573,
      "step": 7740
    },
    {
      "epoch": 12.52,
      "learning_rate": 0.0987483883483871,
      "loss": 1.3515,
      "step": 7760
    },
    {
      "epoch": 12.55,
      "learning_rate": 0.0987451625451613,
      "loss": 1.3331,
      "step": 7780
    },
    {
      "epoch": 12.58,
      "learning_rate": 0.09874193674193549,
      "loss": 1.3563,
      "step": 7800
    },
    {
      "epoch": 12.61,
      "learning_rate": 0.09873871093870969,
      "loss": 1.3441,
      "step": 7820
    },
    {
      "epoch": 12.65,
      "learning_rate": 0.09873548513548387,
      "loss": 1.3893,
      "step": 7840
    },
    {
      "epoch": 12.68,
      "learning_rate": 0.09873225933225807,
      "loss": 1.3764,
      "step": 7860
    },
    {
      "epoch": 12.71,
      "learning_rate": 0.09872903352903227,
      "loss": 1.3037,
      "step": 7880
    },
    {
      "epoch": 12.74,
      "learning_rate": 0.09872580772580646,
      "loss": 1.3382,
      "step": 7900
    },
    {
      "epoch": 12.77,
      "learning_rate": 0.09872258192258065,
      "loss": 1.3478,
      "step": 7920
    },
    {
      "epoch": 12.81,
      "learning_rate": 0.09871935611935484,
      "loss": 1.3491,
      "step": 7940
    },
    {
      "epoch": 12.84,
      "learning_rate": 0.09871613031612904,
      "loss": 1.3504,
      "step": 7960
    },
    {
      "epoch": 12.87,
      "learning_rate": 0.09871290451290322,
      "loss": 1.3539,
      "step": 7980
    },
    {
      "epoch": 12.9,
      "learning_rate": 0.09870967870967742,
      "loss": 1.3471,
      "step": 8000
    },
    {
      "epoch": 12.94,
      "learning_rate": 0.09870645290645162,
      "loss": 1.3509,
      "step": 8020
    },
    {
      "epoch": 12.97,
      "learning_rate": 0.09870322710322581,
      "loss": 1.3607,
      "step": 8040
    },
    {
      "epoch": 13.0,
      "learning_rate": 0.0987000013,
      "loss": 1.3858,
      "step": 8060
    },
    {
      "epoch": 13.0,
      "eval_accuracy": {
        "accuracy": 0.6898758879088284
      },
      "eval_loss": 1.529740571975708,
      "eval_runtime": 2.9573,
      "eval_samples_per_second": 4332.028,
      "eval_steps_per_second": 67.968,
      "step": 8060
    },
    {
      "epoch": 13.03,
      "learning_rate": 0.09869677549677419,
      "loss": 1.3943,
      "step": 8080
    },
    {
      "epoch": 13.06,
      "learning_rate": 0.09869354969354839,
      "loss": 1.337,
      "step": 8100
    },
    {
      "epoch": 13.1,
      "learning_rate": 0.09869032389032259,
      "loss": 1.3183,
      "step": 8120
    },
    {
      "epoch": 13.13,
      "learning_rate": 0.09868709808709678,
      "loss": 1.3359,
      "step": 8140
    },
    {
      "epoch": 13.16,
      "learning_rate": 0.09868387228387097,
      "loss": 1.3358,
      "step": 8160
    },
    {
      "epoch": 13.19,
      "learning_rate": 0.09868064648064517,
      "loss": 1.308,
      "step": 8180
    },
    {
      "epoch": 13.23,
      "learning_rate": 0.09867742067741936,
      "loss": 1.2585,
      "step": 8200
    },
    {
      "epoch": 13.26,
      "learning_rate": 0.09867419487419356,
      "loss": 1.3029,
      "step": 8220
    },
    {
      "epoch": 13.29,
      "learning_rate": 0.09867096907096776,
      "loss": 1.3158,
      "step": 8240
    },
    {
      "epoch": 13.32,
      "learning_rate": 0.09866774326774194,
      "loss": 1.357,
      "step": 8260
    },
    {
      "epoch": 13.35,
      "learning_rate": 0.09866451746451613,
      "loss": 1.3255,
      "step": 8280
    },
    {
      "epoch": 13.39,
      "learning_rate": 0.09866129166129033,
      "loss": 1.2896,
      "step": 8300
    },
    {
      "epoch": 13.42,
      "learning_rate": 0.09865806585806453,
      "loss": 1.3304,
      "step": 8320
    },
    {
      "epoch": 13.45,
      "learning_rate": 0.09865484005483871,
      "loss": 1.3572,
      "step": 8340
    },
    {
      "epoch": 13.48,
      "learning_rate": 0.09865161425161291,
      "loss": 1.3945,
      "step": 8360
    },
    {
      "epoch": 13.52,
      "learning_rate": 0.0986483884483871,
      "loss": 1.3879,
      "step": 8380
    },
    {
      "epoch": 13.55,
      "learning_rate": 0.0986451626451613,
      "loss": 1.3569,
      "step": 8400
    },
    {
      "epoch": 13.58,
      "learning_rate": 0.09864193684193549,
      "loss": 1.3487,
      "step": 8420
    },
    {
      "epoch": 13.61,
      "learning_rate": 0.09863871103870968,
      "loss": 1.3829,
      "step": 8440
    },
    {
      "epoch": 13.65,
      "learning_rate": 0.09863548523548388,
      "loss": 1.4003,
      "step": 8460
    },
    {
      "epoch": 13.68,
      "learning_rate": 0.09863225943225808,
      "loss": 1.3741,
      "step": 8480
    },
    {
      "epoch": 13.71,
      "learning_rate": 0.09862903362903226,
      "loss": 1.3573,
      "step": 8500
    },
    {
      "epoch": 13.74,
      "learning_rate": 0.09862580782580646,
      "loss": 1.359,
      "step": 8520
    },
    {
      "epoch": 13.77,
      "learning_rate": 0.09862258202258066,
      "loss": 1.3364,
      "step": 8540
    },
    {
      "epoch": 13.81,
      "learning_rate": 0.09861935621935485,
      "loss": 1.3026,
      "step": 8560
    },
    {
      "epoch": 13.84,
      "learning_rate": 0.09861613041612903,
      "loss": 1.3351,
      "step": 8580
    },
    {
      "epoch": 13.87,
      "learning_rate": 0.09861290461290323,
      "loss": 1.3271,
      "step": 8600
    },
    {
      "epoch": 13.9,
      "learning_rate": 0.09860967880967741,
      "loss": 1.3157,
      "step": 8620
    },
    {
      "epoch": 13.94,
      "learning_rate": 0.09860645300645161,
      "loss": 1.3512,
      "step": 8640
    },
    {
      "epoch": 13.97,
      "learning_rate": 0.09860322720322581,
      "loss": 1.3892,
      "step": 8660
    },
    {
      "epoch": 14.0,
      "learning_rate": 0.0986000014,
      "loss": 1.3372,
      "step": 8680
    },
    {
      "epoch": 14.0,
      "eval_accuracy": {
        "accuracy": 0.6908125829365389
      },
      "eval_loss": 1.4853019714355469,
      "eval_runtime": 2.5418,
      "eval_samples_per_second": 5040.123,
      "eval_steps_per_second": 79.078,
      "step": 8680
    },
    {
      "epoch": 14.03,
      "learning_rate": 0.0985967755967742,
      "loss": 1.3546,
      "step": 8700
    },
    {
      "epoch": 14.06,
      "learning_rate": 0.0985935497935484,
      "loss": 1.3334,
      "step": 8720
    },
    {
      "epoch": 14.1,
      "learning_rate": 0.09859032399032258,
      "loss": 1.3471,
      "step": 8740
    },
    {
      "epoch": 14.13,
      "learning_rate": 0.09858709818709678,
      "loss": 1.3513,
      "step": 8760
    },
    {
      "epoch": 14.16,
      "learning_rate": 0.09858387238387098,
      "loss": 1.3163,
      "step": 8780
    },
    {
      "epoch": 14.19,
      "learning_rate": 0.09858064658064516,
      "loss": 1.2931,
      "step": 8800
    },
    {
      "epoch": 14.23,
      "learning_rate": 0.09857742077741936,
      "loss": 1.3187,
      "step": 8820
    },
    {
      "epoch": 14.26,
      "learning_rate": 0.09857419497419356,
      "loss": 1.3342,
      "step": 8840
    },
    {
      "epoch": 14.29,
      "learning_rate": 0.09857096917096775,
      "loss": 1.3118,
      "step": 8860
    },
    {
      "epoch": 14.32,
      "learning_rate": 0.09856774336774193,
      "loss": 1.3007,
      "step": 8880
    },
    {
      "epoch": 14.35,
      "learning_rate": 0.09856451756451613,
      "loss": 1.3355,
      "step": 8900
    },
    {
      "epoch": 14.39,
      "learning_rate": 0.09856129176129032,
      "loss": 1.3125,
      "step": 8920
    },
    {
      "epoch": 14.42,
      "learning_rate": 0.09855806595806452,
      "loss": 1.3024,
      "step": 8940
    },
    {
      "epoch": 14.45,
      "learning_rate": 0.09855484015483872,
      "loss": 1.3291,
      "step": 8960
    },
    {
      "epoch": 14.48,
      "learning_rate": 0.0985516143516129,
      "loss": 1.3628,
      "step": 8980
    },
    {
      "epoch": 14.52,
      "learning_rate": 0.0985483885483871,
      "loss": 1.3166,
      "step": 9000
    },
    {
      "epoch": 14.55,
      "learning_rate": 0.0985451627451613,
      "loss": 1.3751,
      "step": 9020
    },
    {
      "epoch": 14.58,
      "learning_rate": 0.09854193694193548,
      "loss": 1.3451,
      "step": 9040
    },
    {
      "epoch": 14.61,
      "learning_rate": 0.09853871113870968,
      "loss": 1.3175,
      "step": 9060
    },
    {
      "epoch": 14.65,
      "learning_rate": 0.09853548533548388,
      "loss": 1.2912,
      "step": 9080
    },
    {
      "epoch": 14.68,
      "learning_rate": 0.09853225953225807,
      "loss": 1.351,
      "step": 9100
    },
    {
      "epoch": 14.71,
      "learning_rate": 0.09852903372903227,
      "loss": 1.3372,
      "step": 9120
    },
    {
      "epoch": 14.74,
      "learning_rate": 0.09852580792580647,
      "loss": 1.3269,
      "step": 9140
    },
    {
      "epoch": 14.77,
      "learning_rate": 0.09852258212258065,
      "loss": 1.3691,
      "step": 9160
    },
    {
      "epoch": 14.81,
      "learning_rate": 0.09851935631935485,
      "loss": 1.3765,
      "step": 9180
    },
    {
      "epoch": 14.84,
      "learning_rate": 0.09851613051612904,
      "loss": 1.3253,
      "step": 9200
    },
    {
      "epoch": 14.87,
      "learning_rate": 0.09851290471290322,
      "loss": 1.3312,
      "step": 9220
    },
    {
      "epoch": 14.9,
      "learning_rate": 0.09850967890967742,
      "loss": 1.3383,
      "step": 9240
    },
    {
      "epoch": 14.94,
      "learning_rate": 0.09850645310645162,
      "loss": 1.3438,
      "step": 9260
    },
    {
      "epoch": 14.97,
      "learning_rate": 0.0985032273032258,
      "loss": 1.3325,
      "step": 9280
    },
    {
      "epoch": 15.0,
      "learning_rate": 0.0985000015,
      "loss": 1.3613,
      "step": 9300
    },
    {
      "epoch": 15.0,
      "eval_accuracy": {
        "accuracy": 0.6887050191241901
      },
      "eval_loss": 1.564130187034607,
      "eval_runtime": 2.6084,
      "eval_samples_per_second": 4911.374,
      "eval_steps_per_second": 77.058,
      "step": 9300
    },
    {
      "epoch": 15.03,
      "learning_rate": 0.0984967756967742,
      "loss": 1.3648,
      "step": 9320
    },
    {
      "epoch": 15.06,
      "learning_rate": 0.09849354989354839,
      "loss": 1.2959,
      "step": 9340
    },
    {
      "epoch": 15.1,
      "learning_rate": 0.09849032409032259,
      "loss": 1.2948,
      "step": 9360
    },
    {
      "epoch": 15.13,
      "learning_rate": 0.09848709828709679,
      "loss": 1.2963,
      "step": 9380
    },
    {
      "epoch": 15.16,
      "learning_rate": 0.09848387248387097,
      "loss": 1.2891,
      "step": 9400
    },
    {
      "epoch": 15.19,
      "learning_rate": 0.09848064668064517,
      "loss": 1.2869,
      "step": 9420
    },
    {
      "epoch": 15.23,
      "learning_rate": 0.09847742087741937,
      "loss": 1.3347,
      "step": 9440
    },
    {
      "epoch": 15.26,
      "learning_rate": 0.09847419507419355,
      "loss": 1.337,
      "step": 9460
    },
    {
      "epoch": 15.29,
      "learning_rate": 0.09847096927096775,
      "loss": 1.3124,
      "step": 9480
    },
    {
      "epoch": 15.32,
      "learning_rate": 0.09846774346774194,
      "loss": 1.325,
      "step": 9500
    },
    {
      "epoch": 15.35,
      "learning_rate": 0.09846451766451612,
      "loss": 1.3414,
      "step": 9520
    },
    {
      "epoch": 15.39,
      "learning_rate": 0.09846129186129032,
      "loss": 1.2958,
      "step": 9540
    },
    {
      "epoch": 15.42,
      "learning_rate": 0.09845806605806452,
      "loss": 1.2894,
      "step": 9560
    },
    {
      "epoch": 15.45,
      "learning_rate": 0.09845484025483871,
      "loss": 1.2893,
      "step": 9580
    },
    {
      "epoch": 15.48,
      "learning_rate": 0.0984516144516129,
      "loss": 1.3313,
      "step": 9600
    },
    {
      "epoch": 15.52,
      "learning_rate": 0.0984483886483871,
      "loss": 1.3275,
      "step": 9620
    },
    {
      "epoch": 15.55,
      "learning_rate": 0.09844516284516129,
      "loss": 1.329,
      "step": 9640
    },
    {
      "epoch": 15.58,
      "learning_rate": 0.09844193704193549,
      "loss": 1.3007,
      "step": 9660
    },
    {
      "epoch": 15.61,
      "learning_rate": 0.09843871123870969,
      "loss": 1.296,
      "step": 9680
    },
    {
      "epoch": 15.65,
      "learning_rate": 0.09843548543548387,
      "loss": 1.3018,
      "step": 9700
    },
    {
      "epoch": 15.68,
      "learning_rate": 0.09843225963225807,
      "loss": 1.2885,
      "step": 9720
    },
    {
      "epoch": 15.71,
      "learning_rate": 0.09842903382903227,
      "loss": 1.3058,
      "step": 9740
    },
    {
      "epoch": 15.74,
      "learning_rate": 0.09842580802580646,
      "loss": 1.3304,
      "step": 9760
    },
    {
      "epoch": 15.77,
      "learning_rate": 0.09842258222258066,
      "loss": 1.3674,
      "step": 9780
    },
    {
      "epoch": 15.81,
      "learning_rate": 0.09841935641935484,
      "loss": 1.312,
      "step": 9800
    },
    {
      "epoch": 15.84,
      "learning_rate": 0.09841613061612903,
      "loss": 1.3186,
      "step": 9820
    },
    {
      "epoch": 15.87,
      "learning_rate": 0.09841290481290323,
      "loss": 1.3416,
      "step": 9840
    },
    {
      "epoch": 15.9,
      "learning_rate": 0.09840967900967743,
      "loss": 1.328,
      "step": 9860
    },
    {
      "epoch": 15.94,
      "learning_rate": 0.09840645320645161,
      "loss": 1.3298,
      "step": 9880
    },
    {
      "epoch": 15.97,
      "learning_rate": 0.09840322740322581,
      "loss": 1.3594,
      "step": 9900
    },
    {
      "epoch": 16.0,
      "learning_rate": 0.09840000160000001,
      "loss": 1.3114,
      "step": 9920
    },
    {
      "epoch": 16.0,
      "eval_accuracy": {
        "accuracy": 0.6934665521817188
      },
      "eval_loss": 1.5399287939071655,
      "eval_runtime": 3.3799,
      "eval_samples_per_second": 3790.317,
      "eval_steps_per_second": 59.469,
      "step": 9920
    },
    {
      "epoch": 16.03,
      "learning_rate": 0.0983967757967742,
      "loss": 1.3323,
      "step": 9940
    },
    {
      "epoch": 16.06,
      "learning_rate": 0.0983935499935484,
      "loss": 1.3077,
      "step": 9960
    },
    {
      "epoch": 16.1,
      "learning_rate": 0.09839032419032259,
      "loss": 1.2845,
      "step": 9980
    },
    {
      "epoch": 16.13,
      "learning_rate": 0.09838709838709678,
      "loss": 1.2638,
      "step": 10000
    },
    {
      "epoch": 16.16,
      "learning_rate": 0.09838387258387098,
      "loss": 1.2435,
      "step": 10020
    },
    {
      "epoch": 16.19,
      "learning_rate": 0.09838064678064518,
      "loss": 1.303,
      "step": 10040
    },
    {
      "epoch": 16.23,
      "learning_rate": 0.09837742097741936,
      "loss": 1.3003,
      "step": 10060
    },
    {
      "epoch": 16.26,
      "learning_rate": 0.09837419517419356,
      "loss": 1.2859,
      "step": 10080
    },
    {
      "epoch": 16.29,
      "learning_rate": 0.09837096937096776,
      "loss": 1.3414,
      "step": 10100
    },
    {
      "epoch": 16.32,
      "learning_rate": 0.09836774356774194,
      "loss": 1.3701,
      "step": 10120
    },
    {
      "epoch": 16.35,
      "learning_rate": 0.09836451776451613,
      "loss": 1.2933,
      "step": 10140
    },
    {
      "epoch": 16.39,
      "learning_rate": 0.09836129196129033,
      "loss": 1.3103,
      "step": 10160
    },
    {
      "epoch": 16.42,
      "learning_rate": 0.09835806615806451,
      "loss": 1.3106,
      "step": 10180
    },
    {
      "epoch": 16.45,
      "learning_rate": 0.09835484035483871,
      "loss": 1.3106,
      "step": 10200
    },
    {
      "epoch": 16.48,
      "learning_rate": 0.09835161455161291,
      "loss": 1.2926,
      "step": 10220
    },
    {
      "epoch": 16.52,
      "learning_rate": 0.0983483887483871,
      "loss": 1.3119,
      "step": 10240
    },
    {
      "epoch": 16.55,
      "learning_rate": 0.0983451629451613,
      "loss": 1.3123,
      "step": 10260
    },
    {
      "epoch": 16.58,
      "learning_rate": 0.0983419371419355,
      "loss": 1.3158,
      "step": 10280
    },
    {
      "epoch": 16.61,
      "learning_rate": 0.09833871133870968,
      "loss": 1.2859,
      "step": 10300
    },
    {
      "epoch": 16.65,
      "learning_rate": 0.09833548553548388,
      "loss": 1.3309,
      "step": 10320
    },
    {
      "epoch": 16.68,
      "learning_rate": 0.09833225973225808,
      "loss": 1.3214,
      "step": 10340
    },
    {
      "epoch": 16.71,
      "learning_rate": 0.09832903392903226,
      "loss": 1.2983,
      "step": 10360
    },
    {
      "epoch": 16.74,
      "learning_rate": 0.09832580812580646,
      "loss": 1.319,
      "step": 10380
    },
    {
      "epoch": 16.77,
      "learning_rate": 0.09832258232258065,
      "loss": 1.3527,
      "step": 10400
    },
    {
      "epoch": 16.81,
      "learning_rate": 0.09831935651935485,
      "loss": 1.2524,
      "step": 10420
    },
    {
      "epoch": 16.84,
      "learning_rate": 0.09831613071612903,
      "loss": 1.3012,
      "step": 10440
    },
    {
      "epoch": 16.87,
      "learning_rate": 0.09831290491290323,
      "loss": 1.3255,
      "step": 10460
    },
    {
      "epoch": 16.9,
      "learning_rate": 0.09830967910967742,
      "loss": 1.3176,
      "step": 10480
    },
    {
      "epoch": 16.94,
      "learning_rate": 0.09830645330645162,
      "loss": 1.3821,
      "step": 10500
    },
    {
      "epoch": 16.97,
      "learning_rate": 0.09830322750322582,
      "loss": 1.3781,
      "step": 10520
    },
    {
      "epoch": 17.0,
      "learning_rate": 0.0983000017,
      "loss": 1.316,
      "step": 10540
    },
    {
      "epoch": 17.0,
      "eval_accuracy": {
        "accuracy": 0.6876902661775037
      },
      "eval_loss": 1.5025585889816284,
      "eval_runtime": 2.599,
      "eval_samples_per_second": 4929.234,
      "eval_steps_per_second": 77.338,
      "step": 10540
    },
    {
      "epoch": 17.03,
      "learning_rate": 0.0982967758967742,
      "loss": 1.3475,
      "step": 10560
    },
    {
      "epoch": 17.06,
      "learning_rate": 0.0982935500935484,
      "loss": 1.3053,
      "step": 10580
    },
    {
      "epoch": 17.1,
      "learning_rate": 0.09829032429032258,
      "loss": 1.3172,
      "step": 10600
    },
    {
      "epoch": 17.13,
      "learning_rate": 0.09828709848709678,
      "loss": 1.3304,
      "step": 10620
    },
    {
      "epoch": 17.16,
      "learning_rate": 0.09828387268387098,
      "loss": 1.3261,
      "step": 10640
    },
    {
      "epoch": 17.19,
      "learning_rate": 0.09828064688064517,
      "loss": 1.3318,
      "step": 10660
    },
    {
      "epoch": 17.23,
      "learning_rate": 0.09827742107741937,
      "loss": 1.2961,
      "step": 10680
    },
    {
      "epoch": 17.26,
      "learning_rate": 0.09827419527419355,
      "loss": 1.2739,
      "step": 10700
    },
    {
      "epoch": 17.29,
      "learning_rate": 0.09827096947096775,
      "loss": 1.3019,
      "step": 10720
    },
    {
      "epoch": 17.32,
      "learning_rate": 0.09826774366774194,
      "loss": 1.2928,
      "step": 10740
    },
    {
      "epoch": 17.35,
      "learning_rate": 0.09826451786451613,
      "loss": 1.3169,
      "step": 10760
    },
    {
      "epoch": 17.39,
      "learning_rate": 0.09826129206129032,
      "loss": 1.3028,
      "step": 10780
    },
    {
      "epoch": 17.42,
      "learning_rate": 0.09825806625806452,
      "loss": 1.2945,
      "step": 10800
    },
    {
      "epoch": 17.45,
      "learning_rate": 0.09825484045483872,
      "loss": 1.3297,
      "step": 10820
    },
    {
      "epoch": 17.48,
      "learning_rate": 0.0982516146516129,
      "loss": 1.3104,
      "step": 10840
    },
    {
      "epoch": 17.52,
      "learning_rate": 0.0982483888483871,
      "loss": 1.322,
      "step": 10860
    },
    {
      "epoch": 17.55,
      "learning_rate": 0.0982451630451613,
      "loss": 1.298,
      "step": 10880
    },
    {
      "epoch": 17.58,
      "learning_rate": 0.09824193724193549,
      "loss": 1.3026,
      "step": 10900
    },
    {
      "epoch": 17.61,
      "learning_rate": 0.09823871143870969,
      "loss": 1.2942,
      "step": 10920
    },
    {
      "epoch": 17.65,
      "learning_rate": 0.09823548563548387,
      "loss": 1.3217,
      "step": 10940
    },
    {
      "epoch": 17.68,
      "learning_rate": 0.09823225983225807,
      "loss": 1.2701,
      "step": 10960
    },
    {
      "epoch": 17.71,
      "learning_rate": 0.09822903402903227,
      "loss": 1.3125,
      "step": 10980
    },
    {
      "epoch": 17.74,
      "learning_rate": 0.09822580822580645,
      "loss": 1.322,
      "step": 11000
    },
    {
      "epoch": 17.77,
      "learning_rate": 0.09822258242258065,
      "loss": 1.3201,
      "step": 11020
    },
    {
      "epoch": 17.81,
      "learning_rate": 0.09821935661935485,
      "loss": 1.3266,
      "step": 11040
    },
    {
      "epoch": 17.84,
      "learning_rate": 0.09821613081612904,
      "loss": 1.337,
      "step": 11060
    },
    {
      "epoch": 17.87,
      "learning_rate": 0.09821290501290322,
      "loss": 1.309,
      "step": 11080
    },
    {
      "epoch": 17.9,
      "learning_rate": 0.09820967920967742,
      "loss": 1.2596,
      "step": 11100
    },
    {
      "epoch": 17.94,
      "learning_rate": 0.09820645340645162,
      "loss": 1.3086,
      "step": 11120
    },
    {
      "epoch": 17.97,
      "learning_rate": 0.0982032276032258,
      "loss": 1.3155,
      "step": 11140
    },
    {
      "epoch": 18.0,
      "learning_rate": 0.0982000018,
      "loss": 1.3159,
      "step": 11160
    },
    {
      "epoch": 18.0,
      "eval_accuracy": {
        "accuracy": 0.6985403169151511
      },
      "eval_loss": 1.487196922302246,
      "eval_runtime": 2.4788,
      "eval_samples_per_second": 5168.232,
      "eval_steps_per_second": 81.088,
      "step": 11160
    },
    {
      "epoch": 18.03,
      "learning_rate": 0.0981967759967742,
      "loss": 1.3327,
      "step": 11180
    },
    {
      "epoch": 18.06,
      "learning_rate": 0.09819355019354839,
      "loss": 1.3689,
      "step": 11200
    },
    {
      "epoch": 18.1,
      "learning_rate": 0.09819032439032259,
      "loss": 1.3022,
      "step": 11220
    },
    {
      "epoch": 18.13,
      "learning_rate": 0.09818709858709677,
      "loss": 1.2921,
      "step": 11240
    },
    {
      "epoch": 18.16,
      "learning_rate": 0.09818387278387097,
      "loss": 1.2963,
      "step": 11260
    },
    {
      "epoch": 18.19,
      "learning_rate": 0.09818064698064517,
      "loss": 1.2885,
      "step": 11280
    },
    {
      "epoch": 18.23,
      "learning_rate": 0.09817742117741936,
      "loss": 1.2365,
      "step": 11300
    },
    {
      "epoch": 18.26,
      "learning_rate": 0.09817419537419356,
      "loss": 1.2381,
      "step": 11320
    },
    {
      "epoch": 18.29,
      "learning_rate": 0.09817096957096776,
      "loss": 1.3111,
      "step": 11340
    },
    {
      "epoch": 18.32,
      "learning_rate": 0.09816774376774194,
      "loss": 1.3643,
      "step": 11360
    },
    {
      "epoch": 18.35,
      "learning_rate": 0.09816451796451613,
      "loss": 1.3164,
      "step": 11380
    },
    {
      "epoch": 18.39,
      "learning_rate": 0.09816129216129033,
      "loss": 1.2683,
      "step": 11400
    },
    {
      "epoch": 18.42,
      "learning_rate": 0.09815806635806452,
      "loss": 1.2896,
      "step": 11420
    },
    {
      "epoch": 18.45,
      "learning_rate": 0.09815484055483871,
      "loss": 1.2881,
      "step": 11440
    },
    {
      "epoch": 18.48,
      "learning_rate": 0.09815161475161291,
      "loss": 1.2828,
      "step": 11460
    },
    {
      "epoch": 18.52,
      "learning_rate": 0.0981483889483871,
      "loss": 1.3201,
      "step": 11480
    },
    {
      "epoch": 18.55,
      "learning_rate": 0.0981451631451613,
      "loss": 1.3235,
      "step": 11500
    },
    {
      "epoch": 18.58,
      "learning_rate": 0.09814193734193549,
      "loss": 1.3904,
      "step": 11520
    },
    {
      "epoch": 18.61,
      "learning_rate": 0.09813871153870968,
      "loss": 1.3015,
      "step": 11540
    },
    {
      "epoch": 18.65,
      "learning_rate": 0.09813548573548388,
      "loss": 1.2827,
      "step": 11560
    },
    {
      "epoch": 18.68,
      "learning_rate": 0.09813225993225808,
      "loss": 1.2601,
      "step": 11580
    },
    {
      "epoch": 18.71,
      "learning_rate": 0.09812903412903226,
      "loss": 1.319,
      "step": 11600
    },
    {
      "epoch": 18.74,
      "learning_rate": 0.09812580832580646,
      "loss": 1.2496,
      "step": 11620
    },
    {
      "epoch": 18.77,
      "learning_rate": 0.09812258252258066,
      "loss": 1.3034,
      "step": 11640
    },
    {
      "epoch": 18.81,
      "learning_rate": 0.09811935671935484,
      "loss": 1.3214,
      "step": 11660
    },
    {
      "epoch": 18.84,
      "learning_rate": 0.09811613091612903,
      "loss": 1.3139,
      "step": 11680
    },
    {
      "epoch": 18.87,
      "learning_rate": 0.09811290511290323,
      "loss": 1.3137,
      "step": 11700
    },
    {
      "epoch": 18.9,
      "learning_rate": 0.09810967930967743,
      "loss": 1.3313,
      "step": 11720
    },
    {
      "epoch": 18.94,
      "learning_rate": 0.09810645350645161,
      "loss": 1.3467,
      "step": 11740
    },
    {
      "epoch": 18.97,
      "learning_rate": 0.09810322770322581,
      "loss": 1.2738,
      "step": 11760
    },
    {
      "epoch": 19.0,
      "learning_rate": 0.0981000019,
      "loss": 1.3152,
      "step": 11780
    },
    {
      "epoch": 19.0,
      "eval_accuracy": {
        "accuracy": 0.7036921395675592
      },
      "eval_loss": 1.4793964624404907,
      "eval_runtime": 3.9778,
      "eval_samples_per_second": 3220.653,
      "eval_steps_per_second": 50.531,
      "step": 11780
    },
    {
      "epoch": 19.03,
      "learning_rate": 0.0980967760967742,
      "loss": 1.3547,
      "step": 11800
    },
    {
      "epoch": 19.06,
      "learning_rate": 0.0980935502935484,
      "loss": 1.3044,
      "step": 11820
    },
    {
      "epoch": 19.1,
      "learning_rate": 0.09809032449032258,
      "loss": 1.2654,
      "step": 11840
    },
    {
      "epoch": 19.13,
      "learning_rate": 0.09808709868709678,
      "loss": 1.3094,
      "step": 11860
    },
    {
      "epoch": 19.16,
      "learning_rate": 0.09808387288387098,
      "loss": 1.269,
      "step": 11880
    },
    {
      "epoch": 19.19,
      "learning_rate": 0.09808064708064516,
      "loss": 1.2785,
      "step": 11900
    },
    {
      "epoch": 19.23,
      "learning_rate": 0.09807742127741936,
      "loss": 1.3177,
      "step": 11920
    },
    {
      "epoch": 19.26,
      "learning_rate": 0.09807419547419356,
      "loss": 1.3599,
      "step": 11940
    },
    {
      "epoch": 19.29,
      "learning_rate": 0.09807096967096775,
      "loss": 1.3314,
      "step": 11960
    },
    {
      "epoch": 19.32,
      "learning_rate": 0.09806774386774193,
      "loss": 1.2878,
      "step": 11980
    },
    {
      "epoch": 19.35,
      "learning_rate": 0.09806451806451613,
      "loss": 1.3145,
      "step": 12000
    },
    {
      "epoch": 19.39,
      "learning_rate": 0.09806129226129032,
      "loss": 1.2969,
      "step": 12020
    },
    {
      "epoch": 19.42,
      "learning_rate": 0.09805806645806452,
      "loss": 1.3008,
      "step": 12040
    },
    {
      "epoch": 19.45,
      "learning_rate": 0.09805484065483872,
      "loss": 1.2496,
      "step": 12060
    },
    {
      "epoch": 19.48,
      "learning_rate": 0.0980516148516129,
      "loss": 1.2452,
      "step": 12080
    },
    {
      "epoch": 19.52,
      "learning_rate": 0.0980483890483871,
      "loss": 1.2867,
      "step": 12100
    },
    {
      "epoch": 19.55,
      "learning_rate": 0.0980451632451613,
      "loss": 1.2712,
      "step": 12120
    },
    {
      "epoch": 19.58,
      "learning_rate": 0.09804193744193548,
      "loss": 1.2579,
      "step": 12140
    },
    {
      "epoch": 19.61,
      "learning_rate": 0.09803871163870968,
      "loss": 1.259,
      "step": 12160
    },
    {
      "epoch": 19.65,
      "learning_rate": 0.09803548583548388,
      "loss": 1.2734,
      "step": 12180
    },
    {
      "epoch": 19.68,
      "learning_rate": 0.09803226003225807,
      "loss": 1.3095,
      "step": 12200
    },
    {
      "epoch": 19.71,
      "learning_rate": 0.09802903422903227,
      "loss": 1.2691,
      "step": 12220
    },
    {
      "epoch": 19.74,
      "learning_rate": 0.09802580842580647,
      "loss": 1.2728,
      "step": 12240
    },
    {
      "epoch": 19.77,
      "learning_rate": 0.09802258262258065,
      "loss": 1.2762,
      "step": 12260
    },
    {
      "epoch": 19.81,
      "learning_rate": 0.09801935681935485,
      "loss": 1.3135,
      "step": 12280
    },
    {
      "epoch": 19.84,
      "learning_rate": 0.09801613101612904,
      "loss": 1.321,
      "step": 12300
    },
    {
      "epoch": 19.87,
      "learning_rate": 0.09801290521290322,
      "loss": 1.3086,
      "step": 12320
    },
    {
      "epoch": 19.9,
      "learning_rate": 0.09800967940967742,
      "loss": 1.3029,
      "step": 12340
    },
    {
      "epoch": 19.94,
      "learning_rate": 0.09800645360645162,
      "loss": 1.3045,
      "step": 12360
    },
    {
      "epoch": 19.97,
      "learning_rate": 0.0980032278032258,
      "loss": 1.3184,
      "step": 12380
    },
    {
      "epoch": 20.0,
      "learning_rate": 0.098000002,
      "loss": 1.2968,
      "step": 12400
    },
    {
      "epoch": 20.0,
      "eval_accuracy": {
        "accuracy": 0.7018968074311139
      },
      "eval_loss": 1.4991536140441895,
      "eval_runtime": 2.9429,
      "eval_samples_per_second": 4353.149,
      "eval_steps_per_second": 68.299,
      "step": 12400
    },
    {
      "epoch": 20.03,
      "learning_rate": 0.0979967761967742,
      "loss": 1.3647,
      "step": 12420
    },
    {
      "epoch": 20.06,
      "learning_rate": 0.09799355039354839,
      "loss": 1.2884,
      "step": 12440
    },
    {
      "epoch": 20.1,
      "learning_rate": 0.09799032459032259,
      "loss": 1.2792,
      "step": 12460
    },
    {
      "epoch": 20.13,
      "learning_rate": 0.09798709878709679,
      "loss": 1.2808,
      "step": 12480
    },
    {
      "epoch": 20.16,
      "learning_rate": 0.09798387298387097,
      "loss": 1.2579,
      "step": 12500
    },
    {
      "epoch": 20.19,
      "learning_rate": 0.09798064718064517,
      "loss": 1.2701,
      "step": 12520
    },
    {
      "epoch": 20.23,
      "learning_rate": 0.09797742137741937,
      "loss": 1.3205,
      "step": 12540
    },
    {
      "epoch": 20.26,
      "learning_rate": 0.09797419557419355,
      "loss": 1.2869,
      "step": 12560
    },
    {
      "epoch": 20.29,
      "learning_rate": 0.09797096977096775,
      "loss": 1.2924,
      "step": 12580
    },
    {
      "epoch": 20.32,
      "learning_rate": 0.09796774396774195,
      "loss": 1.2707,
      "step": 12600
    },
    {
      "epoch": 20.35,
      "learning_rate": 0.09796451816451612,
      "loss": 1.2456,
      "step": 12620
    },
    {
      "epoch": 20.39,
      "learning_rate": 0.09796129236129032,
      "loss": 1.2806,
      "step": 12640
    },
    {
      "epoch": 20.42,
      "learning_rate": 0.09795806655806452,
      "loss": 1.2782,
      "step": 12660
    },
    {
      "epoch": 20.45,
      "learning_rate": 0.0979548407548387,
      "loss": 1.2342,
      "step": 12680
    },
    {
      "epoch": 20.48,
      "learning_rate": 0.0979516149516129,
      "loss": 1.2389,
      "step": 12700
    },
    {
      "epoch": 20.52,
      "learning_rate": 0.0979483891483871,
      "loss": 1.2577,
      "step": 12720
    },
    {
      "epoch": 20.55,
      "learning_rate": 0.09794516334516129,
      "loss": 1.3008,
      "step": 12740
    },
    {
      "epoch": 20.58,
      "learning_rate": 0.09794193754193549,
      "loss": 1.2724,
      "step": 12760
    },
    {
      "epoch": 20.61,
      "learning_rate": 0.09793871173870969,
      "loss": 1.2793,
      "step": 12780
    },
    {
      "epoch": 20.65,
      "learning_rate": 0.09793548593548387,
      "loss": 1.2557,
      "step": 12800
    },
    {
      "epoch": 20.68,
      "learning_rate": 0.09793226013225807,
      "loss": 1.3118,
      "step": 12820
    },
    {
      "epoch": 20.71,
      "learning_rate": 0.09792903432903227,
      "loss": 1.3062,
      "step": 12840
    },
    {
      "epoch": 20.74,
      "learning_rate": 0.09792580852580646,
      "loss": 1.2644,
      "step": 12860
    },
    {
      "epoch": 20.77,
      "learning_rate": 0.09792258272258066,
      "loss": 1.2734,
      "step": 12880
    },
    {
      "epoch": 20.81,
      "learning_rate": 0.09791935691935486,
      "loss": 1.2763,
      "step": 12900
    },
    {
      "epoch": 20.84,
      "learning_rate": 0.09791613111612903,
      "loss": 1.2942,
      "step": 12920
    },
    {
      "epoch": 20.87,
      "learning_rate": 0.09791290531290323,
      "loss": 1.3633,
      "step": 12940
    },
    {
      "epoch": 20.9,
      "learning_rate": 0.09790967950967742,
      "loss": 1.3143,
      "step": 12960
    },
    {
      "epoch": 20.94,
      "learning_rate": 0.09790645370645161,
      "loss": 1.3596,
      "step": 12980
    },
    {
      "epoch": 20.97,
      "learning_rate": 0.09790322790322581,
      "loss": 1.3371,
      "step": 13000
    },
    {
      "epoch": 21.0,
      "learning_rate": 0.09790000210000001,
      "loss": 1.2943,
      "step": 13020
    },
    {
      "epoch": 21.0,
      "eval_accuracy": {
        "accuracy": 0.7007259386464757
      },
      "eval_loss": 1.4700740575790405,
      "eval_runtime": 3.0594,
      "eval_samples_per_second": 4187.364,
      "eval_steps_per_second": 65.698,
      "step": 13020
    },
    {
      "epoch": 21.03,
      "learning_rate": 0.0978967762967742,
      "loss": 1.3415,
      "step": 13040
    },
    {
      "epoch": 21.06,
      "learning_rate": 0.09789355049354839,
      "loss": 1.2435,
      "step": 13060
    },
    {
      "epoch": 21.1,
      "learning_rate": 0.09789032469032259,
      "loss": 1.2408,
      "step": 13080
    },
    {
      "epoch": 21.13,
      "learning_rate": 0.09788709888709678,
      "loss": 1.2143,
      "step": 13100
    },
    {
      "epoch": 21.16,
      "learning_rate": 0.09788387308387098,
      "loss": 1.2501,
      "step": 13120
    },
    {
      "epoch": 21.19,
      "learning_rate": 0.09788064728064517,
      "loss": 1.2775,
      "step": 13140
    },
    {
      "epoch": 21.23,
      "learning_rate": 0.09787742147741936,
      "loss": 1.2926,
      "step": 13160
    },
    {
      "epoch": 21.26,
      "learning_rate": 0.09787419567419356,
      "loss": 1.2964,
      "step": 13180
    },
    {
      "epoch": 21.29,
      "learning_rate": 0.09787096987096776,
      "loss": 1.2633,
      "step": 13200
    },
    {
      "epoch": 21.32,
      "learning_rate": 0.09786774406774194,
      "loss": 1.3012,
      "step": 13220
    },
    {
      "epoch": 21.35,
      "learning_rate": 0.09786451826451613,
      "loss": 1.3089,
      "step": 13240
    },
    {
      "epoch": 21.39,
      "learning_rate": 0.09786129246129033,
      "loss": 1.3229,
      "step": 13260
    },
    {
      "epoch": 21.42,
      "learning_rate": 0.09785806665806451,
      "loss": 1.3128,
      "step": 13280
    },
    {
      "epoch": 21.45,
      "learning_rate": 0.09785484085483871,
      "loss": 1.3199,
      "step": 13300
    },
    {
      "epoch": 21.48,
      "learning_rate": 0.09785161505161291,
      "loss": 1.2751,
      "step": 13320
    },
    {
      "epoch": 21.52,
      "learning_rate": 0.0978483892483871,
      "loss": 1.2691,
      "step": 13340
    },
    {
      "epoch": 21.55,
      "learning_rate": 0.0978451634451613,
      "loss": 1.2709,
      "step": 13360
    },
    {
      "epoch": 21.58,
      "learning_rate": 0.0978419376419355,
      "loss": 1.2977,
      "step": 13380
    },
    {
      "epoch": 21.61,
      "learning_rate": 0.09783871183870968,
      "loss": 1.3299,
      "step": 13400
    },
    {
      "epoch": 21.65,
      "learning_rate": 0.09783548603548388,
      "loss": 1.3085,
      "step": 13420
    },
    {
      "epoch": 21.68,
      "learning_rate": 0.09783226023225808,
      "loss": 1.2867,
      "step": 13440
    },
    {
      "epoch": 21.71,
      "learning_rate": 0.09782903442903226,
      "loss": 1.284,
      "step": 13460
    },
    {
      "epoch": 21.74,
      "learning_rate": 0.09782580862580646,
      "loss": 1.291,
      "step": 13480
    },
    {
      "epoch": 21.77,
      "learning_rate": 0.09782258282258066,
      "loss": 1.3126,
      "step": 13500
    },
    {
      "epoch": 21.81,
      "learning_rate": 0.09781935701935485,
      "loss": 1.2697,
      "step": 13520
    },
    {
      "epoch": 21.84,
      "learning_rate": 0.09781613121612905,
      "loss": 1.2758,
      "step": 13540
    },
    {
      "epoch": 21.87,
      "learning_rate": 0.09781290541290323,
      "loss": 1.3133,
      "step": 13560
    },
    {
      "epoch": 21.9,
      "learning_rate": 0.09780967960967742,
      "loss": 1.2964,
      "step": 13580
    },
    {
      "epoch": 21.94,
      "learning_rate": 0.09780645380645162,
      "loss": 1.3034,
      "step": 13600
    },
    {
      "epoch": 21.97,
      "learning_rate": 0.09780322800322581,
      "loss": 1.2519,
      "step": 13620
    },
    {
      "epoch": 22.0,
      "learning_rate": 0.0978000022,
      "loss": 1.3174,
      "step": 13640
    },
    {
      "epoch": 22.0,
      "eval_accuracy": {
        "accuracy": 0.7104831785184607
      },
      "eval_loss": 1.4566495418548584,
      "eval_runtime": 3.5602,
      "eval_samples_per_second": 3598.428,
      "eval_steps_per_second": 56.458,
      "step": 13640
    },
    {
      "epoch": 22.03,
      "learning_rate": 0.0977967763967742,
      "loss": 1.2995,
      "step": 13660
    },
    {
      "epoch": 22.06,
      "learning_rate": 0.0977935505935484,
      "loss": 1.2847,
      "step": 13680
    },
    {
      "epoch": 22.1,
      "learning_rate": 0.09779032479032258,
      "loss": 1.2877,
      "step": 13700
    },
    {
      "epoch": 22.13,
      "learning_rate": 0.09778709898709678,
      "loss": 1.242,
      "step": 13720
    },
    {
      "epoch": 22.16,
      "learning_rate": 0.09778387318387098,
      "loss": 1.2953,
      "step": 13740
    },
    {
      "epoch": 22.19,
      "learning_rate": 0.09778064738064517,
      "loss": 1.2841,
      "step": 13760
    },
    {
      "epoch": 22.23,
      "learning_rate": 0.09777742157741937,
      "loss": 1.2944,
      "step": 13780
    },
    {
      "epoch": 22.26,
      "learning_rate": 0.09777419577419355,
      "loss": 1.2354,
      "step": 13800
    },
    {
      "epoch": 22.29,
      "learning_rate": 0.09777096997096775,
      "loss": 1.2798,
      "step": 13820
    },
    {
      "epoch": 22.32,
      "learning_rate": 0.09776774416774195,
      "loss": 1.316,
      "step": 13840
    },
    {
      "epoch": 22.35,
      "learning_rate": 0.09776451836451613,
      "loss": 1.277,
      "step": 13860
    },
    {
      "epoch": 22.39,
      "learning_rate": 0.09776129256129032,
      "loss": 1.2152,
      "step": 13880
    },
    {
      "epoch": 22.42,
      "learning_rate": 0.09775806675806452,
      "loss": 1.2971,
      "step": 13900
    },
    {
      "epoch": 22.45,
      "learning_rate": 0.09775484095483872,
      "loss": 1.2904,
      "step": 13920
    },
    {
      "epoch": 22.48,
      "learning_rate": 0.0977516151516129,
      "loss": 1.3191,
      "step": 13940
    },
    {
      "epoch": 22.52,
      "learning_rate": 0.0977483893483871,
      "loss": 1.2769,
      "step": 13960
    },
    {
      "epoch": 22.55,
      "learning_rate": 0.0977451635451613,
      "loss": 1.2713,
      "step": 13980
    },
    {
      "epoch": 22.58,
      "learning_rate": 0.09774193774193549,
      "loss": 1.2925,
      "step": 14000
    },
    {
      "epoch": 22.61,
      "learning_rate": 0.09773871193870969,
      "loss": 1.2862,
      "step": 14020
    },
    {
      "epoch": 22.65,
      "learning_rate": 0.09773548613548388,
      "loss": 1.2992,
      "step": 14040
    },
    {
      "epoch": 22.68,
      "learning_rate": 0.09773226033225807,
      "loss": 1.2636,
      "step": 14060
    },
    {
      "epoch": 22.71,
      "learning_rate": 0.09772903452903227,
      "loss": 1.2639,
      "step": 14080
    },
    {
      "epoch": 22.74,
      "learning_rate": 0.09772580872580645,
      "loss": 1.2665,
      "step": 14100
    },
    {
      "epoch": 22.77,
      "learning_rate": 0.09772258292258065,
      "loss": 1.2929,
      "step": 14120
    },
    {
      "epoch": 22.81,
      "learning_rate": 0.09771935711935485,
      "loss": 1.2917,
      "step": 14140
    },
    {
      "epoch": 22.84,
      "learning_rate": 0.09771613131612904,
      "loss": 1.2851,
      "step": 14160
    },
    {
      "epoch": 22.87,
      "learning_rate": 0.09771306680306452,
      "loss": 1.3254,
      "step": 14180
    },
    {
      "epoch": 22.9,
      "learning_rate": 0.09770984099983872,
      "loss": 1.3202,
      "step": 14200
    },
    {
      "epoch": 22.94,
      "learning_rate": 0.09770661519661292,
      "loss": 1.3064,
      "step": 14220
    },
    {
      "epoch": 22.97,
      "learning_rate": 0.0977033893933871,
      "loss": 1.2875,
      "step": 14240
    },
    {
      "epoch": 23.0,
      "learning_rate": 0.0977001635901613,
      "loss": 1.3418,
      "step": 14260
    },
    {
      "epoch": 23.0,
      "eval_accuracy": {
        "accuracy": 0.7088439622199673
      },
      "eval_loss": 1.4840004444122314,
      "eval_runtime": 2.9312,
      "eval_samples_per_second": 4370.592,
      "eval_steps_per_second": 68.573,
      "step": 14260
    },
    {
      "epoch": 23.03,
      "learning_rate": 0.0976969377869355,
      "loss": 1.3161,
      "step": 14280
    },
    {
      "epoch": 23.06,
      "learning_rate": 0.09769371198370967,
      "loss": 1.2493,
      "step": 14300
    },
    {
      "epoch": 23.1,
      "learning_rate": 0.09769048618048387,
      "loss": 1.2537,
      "step": 14320
    },
    {
      "epoch": 23.13,
      "learning_rate": 0.09768726037725807,
      "loss": 1.2851,
      "step": 14340
    },
    {
      "epoch": 23.16,
      "learning_rate": 0.09768403457403226,
      "loss": 1.2398,
      "step": 14360
    },
    {
      "epoch": 23.19,
      "learning_rate": 0.09768080877080645,
      "loss": 1.241,
      "step": 14380
    },
    {
      "epoch": 23.23,
      "learning_rate": 0.09767758296758065,
      "loss": 1.2148,
      "step": 14400
    },
    {
      "epoch": 23.26,
      "learning_rate": 0.09767435716435484,
      "loss": 1.2295,
      "step": 14420
    },
    {
      "epoch": 23.29,
      "learning_rate": 0.09767113136112904,
      "loss": 1.2372,
      "step": 14440
    },
    {
      "epoch": 23.32,
      "learning_rate": 0.09766790555790324,
      "loss": 1.2217,
      "step": 14460
    },
    {
      "epoch": 23.35,
      "learning_rate": 0.09766467975467742,
      "loss": 1.2808,
      "step": 14480
    },
    {
      "epoch": 23.39,
      "learning_rate": 0.09766145395145162,
      "loss": 1.2587,
      "step": 14500
    },
    {
      "epoch": 23.42,
      "learning_rate": 0.09765822814822582,
      "loss": 1.2463,
      "step": 14520
    },
    {
      "epoch": 23.45,
      "learning_rate": 0.097655002345,
      "loss": 1.2383,
      "step": 14540
    },
    {
      "epoch": 23.48,
      "learning_rate": 0.0976517765417742,
      "loss": 1.2766,
      "step": 14560
    },
    {
      "epoch": 23.52,
      "learning_rate": 0.0976485507385484,
      "loss": 1.3053,
      "step": 14580
    },
    {
      "epoch": 23.55,
      "learning_rate": 0.09764532493532259,
      "loss": 1.2338,
      "step": 14600
    },
    {
      "epoch": 23.58,
      "learning_rate": 0.09764209913209677,
      "loss": 1.2694,
      "step": 14620
    },
    {
      "epoch": 23.61,
      "learning_rate": 0.09763887332887097,
      "loss": 1.2787,
      "step": 14640
    },
    {
      "epoch": 23.65,
      "learning_rate": 0.09763564752564516,
      "loss": 1.2633,
      "step": 14660
    },
    {
      "epoch": 23.68,
      "learning_rate": 0.09763242172241936,
      "loss": 1.2929,
      "step": 14680
    },
    {
      "epoch": 23.71,
      "learning_rate": 0.09762919591919356,
      "loss": 1.2879,
      "step": 14700
    },
    {
      "epoch": 23.74,
      "learning_rate": 0.09762597011596774,
      "loss": 1.2605,
      "step": 14720
    },
    {
      "epoch": 23.77,
      "learning_rate": 0.09762274431274194,
      "loss": 1.2815,
      "step": 14740
    },
    {
      "epoch": 23.81,
      "learning_rate": 0.09761951850951614,
      "loss": 1.304,
      "step": 14760
    },
    {
      "epoch": 23.84,
      "learning_rate": 0.09761629270629033,
      "loss": 1.2707,
      "step": 14780
    },
    {
      "epoch": 23.87,
      "learning_rate": 0.09761306690306452,
      "loss": 1.2779,
      "step": 14800
    },
    {
      "epoch": 23.9,
      "learning_rate": 0.09760984109983872,
      "loss": 1.2947,
      "step": 14820
    },
    {
      "epoch": 23.94,
      "learning_rate": 0.09760661529661291,
      "loss": 1.3075,
      "step": 14840
    },
    {
      "epoch": 23.97,
      "learning_rate": 0.09760338949338711,
      "loss": 1.3175,
      "step": 14860
    },
    {
      "epoch": 24.0,
      "learning_rate": 0.09760016369016129,
      "loss": 1.3448,
      "step": 14880
    },
    {
      "epoch": 24.0,
      "eval_accuracy": {
        "accuracy": 0.7042385450003903
      },
      "eval_loss": 1.509899377822876,
      "eval_runtime": 2.8948,
      "eval_samples_per_second": 4425.464,
      "eval_steps_per_second": 69.434,
      "step": 14880
    },
    {
      "epoch": 24.03,
      "learning_rate": 0.09759693788693549,
      "loss": 1.3211,
      "step": 14900
    },
    {
      "epoch": 24.06,
      "learning_rate": 0.09759371208370969,
      "loss": 1.239,
      "step": 14920
    },
    {
      "epoch": 24.1,
      "learning_rate": 0.09759048628048388,
      "loss": 1.2347,
      "step": 14940
    },
    {
      "epoch": 24.13,
      "learning_rate": 0.09758726047725806,
      "loss": 1.2521,
      "step": 14960
    },
    {
      "epoch": 24.16,
      "learning_rate": 0.09758403467403226,
      "loss": 1.2648,
      "step": 14980
    },
    {
      "epoch": 24.19,
      "learning_rate": 0.09758080887080646,
      "loss": 1.2812,
      "step": 15000
    },
    {
      "epoch": 24.23,
      "learning_rate": 0.09757758306758064,
      "loss": 1.2758,
      "step": 15020
    },
    {
      "epoch": 24.26,
      "learning_rate": 0.09757435726435484,
      "loss": 1.2826,
      "step": 15040
    },
    {
      "epoch": 24.29,
      "learning_rate": 0.09757113146112904,
      "loss": 1.2333,
      "step": 15060
    },
    {
      "epoch": 24.32,
      "learning_rate": 0.09756790565790323,
      "loss": 1.2204,
      "step": 15080
    },
    {
      "epoch": 24.35,
      "learning_rate": 0.09756467985467743,
      "loss": 1.2223,
      "step": 15100
    },
    {
      "epoch": 24.39,
      "learning_rate": 0.09756145405145163,
      "loss": 1.2521,
      "step": 15120
    },
    {
      "epoch": 24.42,
      "learning_rate": 0.09755822824822581,
      "loss": 1.2394,
      "step": 15140
    },
    {
      "epoch": 24.45,
      "learning_rate": 0.09755500244500001,
      "loss": 1.2039,
      "step": 15160
    },
    {
      "epoch": 24.48,
      "learning_rate": 0.0975517766417742,
      "loss": 1.2429,
      "step": 15180
    },
    {
      "epoch": 24.52,
      "learning_rate": 0.0975485508385484,
      "loss": 1.2764,
      "step": 15200
    },
    {
      "epoch": 24.55,
      "learning_rate": 0.0975453250353226,
      "loss": 1.2819,
      "step": 15220
    },
    {
      "epoch": 24.58,
      "learning_rate": 0.09754209923209678,
      "loss": 1.2667,
      "step": 15240
    },
    {
      "epoch": 24.61,
      "learning_rate": 0.09753887342887096,
      "loss": 1.2303,
      "step": 15260
    },
    {
      "epoch": 24.65,
      "learning_rate": 0.09753564762564516,
      "loss": 1.2599,
      "step": 15280
    },
    {
      "epoch": 24.68,
      "learning_rate": 0.09753242182241936,
      "loss": 1.2633,
      "step": 15300
    },
    {
      "epoch": 24.71,
      "learning_rate": 0.09752919601919355,
      "loss": 1.2738,
      "step": 15320
    },
    {
      "epoch": 24.74,
      "learning_rate": 0.09752597021596775,
      "loss": 1.3133,
      "step": 15340
    },
    {
      "epoch": 24.77,
      "learning_rate": 0.09752274441274195,
      "loss": 1.2882,
      "step": 15360
    },
    {
      "epoch": 24.81,
      "learning_rate": 0.09751951860951613,
      "loss": 1.2675,
      "step": 15380
    },
    {
      "epoch": 24.84,
      "learning_rate": 0.09751629280629033,
      "loss": 1.2734,
      "step": 15400
    },
    {
      "epoch": 24.87,
      "learning_rate": 0.09751306700306452,
      "loss": 1.2776,
      "step": 15420
    },
    {
      "epoch": 24.9,
      "learning_rate": 0.09750984119983871,
      "loss": 1.2632,
      "step": 15440
    },
    {
      "epoch": 24.94,
      "learning_rate": 0.09750661539661291,
      "loss": 1.2532,
      "step": 15460
    },
    {
      "epoch": 24.97,
      "learning_rate": 0.0975033895933871,
      "loss": 1.2309,
      "step": 15480
    },
    {
      "epoch": 25.0,
      "learning_rate": 0.0975001637901613,
      "loss": 1.2845,
      "step": 15500
    },
    {
      "epoch": 25.0,
      "eval_accuracy": {
        "accuracy": 0.699867301537741
      },
      "eval_loss": 1.5072802305221558,
      "eval_runtime": 3.4738,
      "eval_samples_per_second": 3687.923,
      "eval_steps_per_second": 57.862,
      "step": 15500
    },
    {
      "epoch": 25.03,
      "learning_rate": 0.0974969379869355,
      "loss": 1.373,
      "step": 15520
    },
    {
      "epoch": 25.06,
      "learning_rate": 0.09749371218370968,
      "loss": 1.2796,
      "step": 15540
    },
    {
      "epoch": 25.1,
      "learning_rate": 0.09749048638048387,
      "loss": 1.2477,
      "step": 15560
    },
    {
      "epoch": 25.13,
      "learning_rate": 0.09748726057725807,
      "loss": 1.2238,
      "step": 15580
    },
    {
      "epoch": 25.16,
      "learning_rate": 0.09748403477403227,
      "loss": 1.2605,
      "step": 15600
    },
    {
      "epoch": 25.19,
      "learning_rate": 0.09748080897080645,
      "loss": 1.2233,
      "step": 15620
    },
    {
      "epoch": 25.23,
      "learning_rate": 0.09747758316758065,
      "loss": 1.2585,
      "step": 15640
    },
    {
      "epoch": 25.26,
      "learning_rate": 0.09747435736435485,
      "loss": 1.31,
      "step": 15660
    },
    {
      "epoch": 25.29,
      "learning_rate": 0.09747113156112903,
      "loss": 1.3142,
      "step": 15680
    },
    {
      "epoch": 25.32,
      "learning_rate": 0.09746790575790323,
      "loss": 1.2994,
      "step": 15700
    },
    {
      "epoch": 25.35,
      "learning_rate": 0.09746467995467742,
      "loss": 1.2588,
      "step": 15720
    },
    {
      "epoch": 25.39,
      "learning_rate": 0.09746145415145162,
      "loss": 1.3012,
      "step": 15740
    },
    {
      "epoch": 25.42,
      "learning_rate": 0.09745822834822582,
      "loss": 1.2668,
      "step": 15760
    },
    {
      "epoch": 25.45,
      "learning_rate": 0.097455002545,
      "loss": 1.2741,
      "step": 15780
    },
    {
      "epoch": 25.48,
      "learning_rate": 0.0974517767417742,
      "loss": 1.2253,
      "step": 15800
    },
    {
      "epoch": 25.52,
      "learning_rate": 0.0974485509385484,
      "loss": 1.2506,
      "step": 15820
    },
    {
      "epoch": 25.55,
      "learning_rate": 0.09744532513532259,
      "loss": 1.2331,
      "step": 15840
    },
    {
      "epoch": 25.58,
      "learning_rate": 0.09744209933209678,
      "loss": 1.2332,
      "step": 15860
    },
    {
      "epoch": 25.61,
      "learning_rate": 0.09743887352887097,
      "loss": 1.2278,
      "step": 15880
    },
    {
      "epoch": 25.65,
      "learning_rate": 0.09743564772564517,
      "loss": 1.2733,
      "step": 15900
    },
    {
      "epoch": 25.68,
      "learning_rate": 0.09743242192241935,
      "loss": 1.2924,
      "step": 15920
    },
    {
      "epoch": 25.71,
      "learning_rate": 0.09742919611919355,
      "loss": 1.266,
      "step": 15940
    },
    {
      "epoch": 25.74,
      "learning_rate": 0.09742597031596774,
      "loss": 1.31,
      "step": 15960
    },
    {
      "epoch": 25.77,
      "learning_rate": 0.09742274451274194,
      "loss": 1.319,
      "step": 15980
    },
    {
      "epoch": 25.81,
      "learning_rate": 0.09741951870951614,
      "loss": 1.2537,
      "step": 16000
    },
    {
      "epoch": 25.84,
      "learning_rate": 0.09741629290629032,
      "loss": 1.32,
      "step": 16020
    },
    {
      "epoch": 25.87,
      "learning_rate": 0.09741306710306452,
      "loss": 1.3091,
      "step": 16040
    },
    {
      "epoch": 25.9,
      "learning_rate": 0.09740984129983872,
      "loss": 1.2968,
      "step": 16060
    },
    {
      "epoch": 25.94,
      "learning_rate": 0.0974066154966129,
      "loss": 1.2801,
      "step": 16080
    },
    {
      "epoch": 25.97,
      "learning_rate": 0.0974033896933871,
      "loss": 1.3018,
      "step": 16100
    },
    {
      "epoch": 26.0,
      "learning_rate": 0.0974001638901613,
      "loss": 1.2596,
      "step": 16120
    },
    {
      "epoch": 26.0,
      "eval_accuracy": {
        "accuracy": 0.7133713215205683
      },
      "eval_loss": 1.4401921033859253,
      "eval_runtime": 2.4603,
      "eval_samples_per_second": 5207.029,
      "eval_steps_per_second": 81.696,
      "step": 16120
    },
    {
      "epoch": 26.03,
      "learning_rate": 0.09739693808693549,
      "loss": 1.2571,
      "step": 16140
    },
    {
      "epoch": 26.06,
      "learning_rate": 0.09739371228370969,
      "loss": 1.199,
      "step": 16160
    },
    {
      "epoch": 26.1,
      "learning_rate": 0.09739048648048387,
      "loss": 1.2355,
      "step": 16180
    },
    {
      "epoch": 26.13,
      "learning_rate": 0.09738726067725807,
      "loss": 1.2294,
      "step": 16200
    },
    {
      "epoch": 26.16,
      "learning_rate": 0.09738403487403226,
      "loss": 1.2023,
      "step": 16220
    },
    {
      "epoch": 26.19,
      "learning_rate": 0.09738080907080646,
      "loss": 1.2215,
      "step": 16240
    },
    {
      "epoch": 26.23,
      "learning_rate": 0.09737758326758064,
      "loss": 1.2016,
      "step": 16260
    },
    {
      "epoch": 26.26,
      "learning_rate": 0.09737435746435484,
      "loss": 1.2219,
      "step": 16280
    },
    {
      "epoch": 26.29,
      "learning_rate": 0.09737113166112904,
      "loss": 1.2557,
      "step": 16300
    },
    {
      "epoch": 26.32,
      "learning_rate": 0.09736790585790323,
      "loss": 1.2224,
      "step": 16320
    },
    {
      "epoch": 26.35,
      "learning_rate": 0.09736468005467742,
      "loss": 1.2397,
      "step": 16340
    },
    {
      "epoch": 26.39,
      "learning_rate": 0.09736145425145162,
      "loss": 1.2134,
      "step": 16360
    },
    {
      "epoch": 26.42,
      "learning_rate": 0.09735822844822581,
      "loss": 1.2297,
      "step": 16380
    },
    {
      "epoch": 26.45,
      "learning_rate": 0.09735500264500001,
      "loss": 1.2373,
      "step": 16400
    },
    {
      "epoch": 26.48,
      "learning_rate": 0.0973517768417742,
      "loss": 1.2272,
      "step": 16420
    },
    {
      "epoch": 26.52,
      "learning_rate": 0.09734855103854839,
      "loss": 1.2527,
      "step": 16440
    },
    {
      "epoch": 26.55,
      "learning_rate": 0.09734564781564516,
      "loss": 1.2702,
      "step": 16460
    },
    {
      "epoch": 26.58,
      "learning_rate": 0.09734242201241936,
      "loss": 1.3248,
      "step": 16480
    },
    {
      "epoch": 26.61,
      "learning_rate": 0.09733919620919355,
      "loss": 1.2992,
      "step": 16500
    },
    {
      "epoch": 26.65,
      "learning_rate": 0.09733597040596774,
      "loss": 1.2348,
      "step": 16520
    },
    {
      "epoch": 26.68,
      "learning_rate": 0.09733274460274194,
      "loss": 1.2358,
      "step": 16540
    },
    {
      "epoch": 26.71,
      "learning_rate": 0.09732951879951614,
      "loss": 1.2449,
      "step": 16560
    },
    {
      "epoch": 26.74,
      "learning_rate": 0.09732629299629032,
      "loss": 1.2289,
      "step": 16580
    },
    {
      "epoch": 26.77,
      "learning_rate": 0.09732306719306452,
      "loss": 1.2367,
      "step": 16600
    },
    {
      "epoch": 26.81,
      "learning_rate": 0.09731984138983872,
      "loss": 1.2439,
      "step": 16620
    },
    {
      "epoch": 26.84,
      "learning_rate": 0.0973166155866129,
      "loss": 1.2483,
      "step": 16640
    },
    {
      "epoch": 26.87,
      "learning_rate": 0.0973133897833871,
      "loss": 1.2517,
      "step": 16660
    },
    {
      "epoch": 26.9,
      "learning_rate": 0.0973101639801613,
      "loss": 1.2325,
      "step": 16680
    },
    {
      "epoch": 26.94,
      "learning_rate": 0.09730693817693549,
      "loss": 1.2171,
      "step": 16700
    },
    {
      "epoch": 26.97,
      "learning_rate": 0.09730371237370969,
      "loss": 1.2539,
      "step": 16720
    },
    {
      "epoch": 27.0,
      "learning_rate": 0.09730048657048389,
      "loss": 1.2579,
      "step": 16740
    },
    {
      "epoch": 27.0,
      "eval_accuracy": {
        "accuracy": 0.6964327531028023
      },
      "eval_loss": 1.544113278388977,
      "eval_runtime": 2.5068,
      "eval_samples_per_second": 5110.482,
      "eval_steps_per_second": 80.182,
      "step": 16740
    },
    {
      "epoch": 27.03,
      "learning_rate": 0.09729726076725806,
      "loss": 1.3099,
      "step": 16760
    },
    {
      "epoch": 27.06,
      "learning_rate": 0.09729403496403226,
      "loss": 1.259,
      "step": 16780
    },
    {
      "epoch": 27.1,
      "learning_rate": 0.09729080916080646,
      "loss": 1.2396,
      "step": 16800
    },
    {
      "epoch": 27.13,
      "learning_rate": 0.09728758335758064,
      "loss": 1.2458,
      "step": 16820
    },
    {
      "epoch": 27.16,
      "learning_rate": 0.09728435755435484,
      "loss": 1.2091,
      "step": 16840
    },
    {
      "epoch": 27.19,
      "learning_rate": 0.09728113175112904,
      "loss": 1.2273,
      "step": 16860
    },
    {
      "epoch": 27.23,
      "learning_rate": 0.09727790594790323,
      "loss": 1.2831,
      "step": 16880
    },
    {
      "epoch": 27.26,
      "learning_rate": 0.09727468014467743,
      "loss": 1.2957,
      "step": 16900
    },
    {
      "epoch": 27.29,
      "learning_rate": 0.09727145434145162,
      "loss": 1.2197,
      "step": 16920
    },
    {
      "epoch": 27.32,
      "learning_rate": 0.09726822853822581,
      "loss": 1.2105,
      "step": 16940
    },
    {
      "epoch": 27.35,
      "learning_rate": 0.09726500273500001,
      "loss": 1.1987,
      "step": 16960
    },
    {
      "epoch": 27.39,
      "learning_rate": 0.09726177693177421,
      "loss": 1.2447,
      "step": 16980
    },
    {
      "epoch": 27.42,
      "learning_rate": 0.09725855112854839,
      "loss": 1.2314,
      "step": 17000
    },
    {
      "epoch": 27.45,
      "learning_rate": 0.09725532532532259,
      "loss": 1.2191,
      "step": 17020
    },
    {
      "epoch": 27.48,
      "learning_rate": 0.09725209952209678,
      "loss": 1.1941,
      "step": 17040
    },
    {
      "epoch": 27.52,
      "learning_rate": 0.09724887371887098,
      "loss": 1.2103,
      "step": 17060
    },
    {
      "epoch": 27.55,
      "learning_rate": 0.09724564791564516,
      "loss": 1.2146,
      "step": 17080
    },
    {
      "epoch": 27.58,
      "learning_rate": 0.09724242211241936,
      "loss": 1.2329,
      "step": 17100
    },
    {
      "epoch": 27.61,
      "learning_rate": 0.09723919630919355,
      "loss": 1.2614,
      "step": 17120
    },
    {
      "epoch": 27.65,
      "learning_rate": 0.09723597050596774,
      "loss": 1.2611,
      "step": 17140
    },
    {
      "epoch": 27.68,
      "learning_rate": 0.09723274470274194,
      "loss": 1.2716,
      "step": 17160
    },
    {
      "epoch": 27.71,
      "learning_rate": 0.09722951889951613,
      "loss": 1.2767,
      "step": 17180
    },
    {
      "epoch": 27.74,
      "learning_rate": 0.09722629309629033,
      "loss": 1.2854,
      "step": 17200
    },
    {
      "epoch": 27.77,
      "learning_rate": 0.09722306729306453,
      "loss": 1.2962,
      "step": 17220
    },
    {
      "epoch": 27.81,
      "learning_rate": 0.09721984148983871,
      "loss": 1.2863,
      "step": 17240
    },
    {
      "epoch": 27.84,
      "learning_rate": 0.09721661568661291,
      "loss": 1.2611,
      "step": 17260
    },
    {
      "epoch": 27.87,
      "learning_rate": 0.09721338988338711,
      "loss": 1.2511,
      "step": 17280
    },
    {
      "epoch": 27.9,
      "learning_rate": 0.0972101640801613,
      "loss": 1.276,
      "step": 17300
    },
    {
      "epoch": 27.94,
      "learning_rate": 0.0972069382769355,
      "loss": 1.2873,
      "step": 17320
    },
    {
      "epoch": 27.97,
      "learning_rate": 0.09720371247370968,
      "loss": 1.2879,
      "step": 17340
    },
    {
      "epoch": 28.0,
      "learning_rate": 0.09720048667048388,
      "loss": 1.2695,
      "step": 17360
    },
    {
      "epoch": 28.0,
      "eval_accuracy": {
        "accuracy": 0.7142299586293029
      },
      "eval_loss": 1.4295088052749634,
      "eval_runtime": 2.9945,
      "eval_samples_per_second": 4278.197,
      "eval_steps_per_second": 67.123,
      "step": 17360
    },
    {
      "epoch": 28.03,
      "learning_rate": 0.09719726086725808,
      "loss": 1.2962,
      "step": 17380
    },
    {
      "epoch": 28.06,
      "learning_rate": 0.09719403506403226,
      "loss": 1.2544,
      "step": 17400
    },
    {
      "epoch": 28.1,
      "learning_rate": 0.09719080926080645,
      "loss": 1.2507,
      "step": 17420
    },
    {
      "epoch": 28.13,
      "learning_rate": 0.09718758345758065,
      "loss": 1.2152,
      "step": 17440
    },
    {
      "epoch": 28.16,
      "learning_rate": 0.09718435765435485,
      "loss": 1.2276,
      "step": 17460
    },
    {
      "epoch": 28.19,
      "learning_rate": 0.09718113185112903,
      "loss": 1.2294,
      "step": 17480
    },
    {
      "epoch": 28.23,
      "learning_rate": 0.09717790604790323,
      "loss": 1.232,
      "step": 17500
    },
    {
      "epoch": 28.26,
      "learning_rate": 0.09717468024467743,
      "loss": 1.2239,
      "step": 17520
    },
    {
      "epoch": 28.29,
      "learning_rate": 0.09717145444145162,
      "loss": 1.2393,
      "step": 17540
    },
    {
      "epoch": 28.32,
      "learning_rate": 0.09716822863822581,
      "loss": 1.2433,
      "step": 17560
    },
    {
      "epoch": 28.35,
      "learning_rate": 0.097165002835,
      "loss": 1.2286,
      "step": 17580
    },
    {
      "epoch": 28.39,
      "learning_rate": 0.0971617770317742,
      "loss": 1.1964,
      "step": 17600
    },
    {
      "epoch": 28.42,
      "learning_rate": 0.0971585512285484,
      "loss": 1.2412,
      "step": 17620
    },
    {
      "epoch": 28.45,
      "learning_rate": 0.09715532542532258,
      "loss": 1.2402,
      "step": 17640
    },
    {
      "epoch": 28.48,
      "learning_rate": 0.09715209962209678,
      "loss": 1.22,
      "step": 17660
    },
    {
      "epoch": 28.52,
      "learning_rate": 0.09714887381887098,
      "loss": 1.2111,
      "step": 17680
    },
    {
      "epoch": 28.55,
      "learning_rate": 0.09714564801564517,
      "loss": 1.241,
      "step": 17700
    },
    {
      "epoch": 28.58,
      "learning_rate": 0.09714242221241935,
      "loss": 1.2435,
      "step": 17720
    },
    {
      "epoch": 28.61,
      "learning_rate": 0.09713919640919355,
      "loss": 1.2402,
      "step": 17740
    },
    {
      "epoch": 28.65,
      "learning_rate": 0.09713597060596775,
      "loss": 1.2626,
      "step": 17760
    },
    {
      "epoch": 28.68,
      "learning_rate": 0.09713274480274194,
      "loss": 1.2444,
      "step": 17780
    },
    {
      "epoch": 28.71,
      "learning_rate": 0.09712951899951613,
      "loss": 1.2806,
      "step": 17800
    },
    {
      "epoch": 28.74,
      "learning_rate": 0.09712629319629033,
      "loss": 1.2794,
      "step": 17820
    },
    {
      "epoch": 28.77,
      "learning_rate": 0.09712306739306452,
      "loss": 1.2572,
      "step": 17840
    },
    {
      "epoch": 28.81,
      "learning_rate": 0.09711984158983872,
      "loss": 1.2665,
      "step": 17860
    },
    {
      "epoch": 28.84,
      "learning_rate": 0.0971166157866129,
      "loss": 1.2411,
      "step": 17880
    },
    {
      "epoch": 28.87,
      "learning_rate": 0.0971133899833871,
      "loss": 1.2597,
      "step": 17900
    },
    {
      "epoch": 28.9,
      "learning_rate": 0.0971101641801613,
      "loss": 1.2726,
      "step": 17920
    },
    {
      "epoch": 28.94,
      "learning_rate": 0.09710693837693549,
      "loss": 1.2407,
      "step": 17940
    },
    {
      "epoch": 28.97,
      "learning_rate": 0.09710371257370969,
      "loss": 1.2511,
      "step": 17960
    },
    {
      "epoch": 29.0,
      "learning_rate": 0.09710048677048388,
      "loss": 1.2634,
      "step": 17980
    },
    {
      "epoch": 29.0,
      "eval_accuracy": {
        "accuracy": 0.7164936382796034
      },
      "eval_loss": 1.3885774612426758,
      "eval_runtime": 2.4669,
      "eval_samples_per_second": 5193.147,
      "eval_steps_per_second": 81.479,
      "step": 17980
    },
    {
      "epoch": 29.03,
      "learning_rate": 0.09709726096725807,
      "loss": 1.2751,
      "step": 18000
    },
    {
      "epoch": 29.06,
      "learning_rate": 0.09709403516403226,
      "loss": 1.1871,
      "step": 18020
    },
    {
      "epoch": 29.1,
      "learning_rate": 0.09709080936080645,
      "loss": 1.186,
      "step": 18040
    },
    {
      "epoch": 29.13,
      "learning_rate": 0.09708758355758065,
      "loss": 1.1867,
      "step": 18060
    },
    {
      "epoch": 29.16,
      "learning_rate": 0.09708435775435484,
      "loss": 1.2176,
      "step": 18080
    },
    {
      "epoch": 29.19,
      "learning_rate": 0.09708113195112904,
      "loss": 1.2182,
      "step": 18100
    },
    {
      "epoch": 29.23,
      "learning_rate": 0.09707790614790322,
      "loss": 1.2404,
      "step": 18120
    },
    {
      "epoch": 29.26,
      "learning_rate": 0.09707468034467742,
      "loss": 1.2077,
      "step": 18140
    },
    {
      "epoch": 29.29,
      "learning_rate": 0.09707145454145162,
      "loss": 1.2277,
      "step": 18160
    },
    {
      "epoch": 29.32,
      "learning_rate": 0.0970682287382258,
      "loss": 1.2614,
      "step": 18180
    },
    {
      "epoch": 29.35,
      "learning_rate": 0.097065002935,
      "loss": 1.2114,
      "step": 18200
    },
    {
      "epoch": 29.39,
      "learning_rate": 0.0970617771317742,
      "loss": 1.2014,
      "step": 18220
    },
    {
      "epoch": 29.42,
      "learning_rate": 0.09705855132854839,
      "loss": 1.2074,
      "step": 18240
    },
    {
      "epoch": 29.45,
      "learning_rate": 0.09705532552532259,
      "loss": 1.2359,
      "step": 18260
    },
    {
      "epoch": 29.48,
      "learning_rate": 0.09705209972209679,
      "loss": 1.2414,
      "step": 18280
    },
    {
      "epoch": 29.52,
      "learning_rate": 0.09704887391887097,
      "loss": 1.2328,
      "step": 18300
    },
    {
      "epoch": 29.55,
      "learning_rate": 0.09704564811564517,
      "loss": 1.2571,
      "step": 18320
    },
    {
      "epoch": 29.58,
      "learning_rate": 0.09704242231241936,
      "loss": 1.2306,
      "step": 18340
    },
    {
      "epoch": 29.61,
      "learning_rate": 0.09703919650919356,
      "loss": 1.2429,
      "step": 18360
    },
    {
      "epoch": 29.65,
      "learning_rate": 0.09703597070596774,
      "loss": 1.2185,
      "step": 18380
    },
    {
      "epoch": 29.68,
      "learning_rate": 0.09703274490274194,
      "loss": 1.2021,
      "step": 18400
    },
    {
      "epoch": 29.71,
      "learning_rate": 0.09702951909951613,
      "loss": 1.2273,
      "step": 18420
    },
    {
      "epoch": 29.74,
      "learning_rate": 0.09702629329629033,
      "loss": 1.2275,
      "step": 18440
    },
    {
      "epoch": 29.77,
      "learning_rate": 0.09702306749306452,
      "loss": 1.2269,
      "step": 18460
    },
    {
      "epoch": 29.81,
      "learning_rate": 0.09701984168983871,
      "loss": 1.2382,
      "step": 18480
    },
    {
      "epoch": 29.84,
      "learning_rate": 0.09701661588661291,
      "loss": 1.2243,
      "step": 18500
    },
    {
      "epoch": 29.87,
      "learning_rate": 0.09701339008338711,
      "loss": 1.2404,
      "step": 18520
    },
    {
      "epoch": 29.9,
      "learning_rate": 0.09701016428016129,
      "loss": 1.2664,
      "step": 18540
    },
    {
      "epoch": 29.94,
      "learning_rate": 0.09700693847693549,
      "loss": 1.2634,
      "step": 18560
    },
    {
      "epoch": 29.97,
      "learning_rate": 0.09700371267370969,
      "loss": 1.2432,
      "step": 18580
    },
    {
      "epoch": 30.0,
      "learning_rate": 0.09700048687048388,
      "loss": 1.2541,
      "step": 18600
    },
    {
      "epoch": 30.0,
      "eval_accuracy": {
        "accuracy": 0.7086097884630396
      },
      "eval_loss": 1.4751837253570557,
      "eval_runtime": 2.9321,
      "eval_samples_per_second": 4369.224,
      "eval_steps_per_second": 68.552,
      "step": 18600
    },
    {
      "epoch": 30.03,
      "learning_rate": 0.09699726106725808,
      "loss": 1.275,
      "step": 18620
    },
    {
      "epoch": 30.06,
      "learning_rate": 0.09699403526403226,
      "loss": 1.2328,
      "step": 18640
    },
    {
      "epoch": 30.1,
      "learning_rate": 0.09699080946080645,
      "loss": 1.1994,
      "step": 18660
    },
    {
      "epoch": 30.13,
      "learning_rate": 0.09698758365758064,
      "loss": 1.2137,
      "step": 18680
    },
    {
      "epoch": 30.16,
      "learning_rate": 0.09698435785435484,
      "loss": 1.2054,
      "step": 18700
    },
    {
      "epoch": 30.19,
      "learning_rate": 0.09698113205112903,
      "loss": 1.2387,
      "step": 18720
    },
    {
      "epoch": 30.23,
      "learning_rate": 0.09697790624790323,
      "loss": 1.224,
      "step": 18740
    },
    {
      "epoch": 30.26,
      "learning_rate": 0.09697468044467743,
      "loss": 1.2641,
      "step": 18760
    },
    {
      "epoch": 30.29,
      "learning_rate": 0.09697145464145161,
      "loss": 1.2322,
      "step": 18780
    },
    {
      "epoch": 30.32,
      "learning_rate": 0.09696822883822581,
      "loss": 1.2378,
      "step": 18800
    },
    {
      "epoch": 30.35,
      "learning_rate": 0.09696500303500001,
      "loss": 1.2221,
      "step": 18820
    },
    {
      "epoch": 30.39,
      "learning_rate": 0.0969617772317742,
      "loss": 1.2333,
      "step": 18840
    },
    {
      "epoch": 30.42,
      "learning_rate": 0.0969585514285484,
      "loss": 1.2122,
      "step": 18860
    },
    {
      "epoch": 30.45,
      "learning_rate": 0.0969553256253226,
      "loss": 1.2127,
      "step": 18880
    },
    {
      "epoch": 30.48,
      "learning_rate": 0.09695209982209678,
      "loss": 1.18,
      "step": 18900
    },
    {
      "epoch": 30.52,
      "learning_rate": 0.09694887401887098,
      "loss": 1.2495,
      "step": 18920
    },
    {
      "epoch": 30.55,
      "learning_rate": 0.09694564821564516,
      "loss": 1.265,
      "step": 18940
    },
    {
      "epoch": 30.58,
      "learning_rate": 0.09694258370258065,
      "loss": 1.253,
      "step": 18960
    },
    {
      "epoch": 30.61,
      "learning_rate": 0.09693935789935484,
      "loss": 1.264,
      "step": 18980
    },
    {
      "epoch": 30.65,
      "learning_rate": 0.09693613209612904,
      "loss": 1.2059,
      "step": 19000
    },
    {
      "epoch": 30.68,
      "learning_rate": 0.09693290629290323,
      "loss": 1.2259,
      "step": 19020
    },
    {
      "epoch": 30.71,
      "learning_rate": 0.09692968048967743,
      "loss": 1.2395,
      "step": 19040
    },
    {
      "epoch": 30.74,
      "learning_rate": 0.09692645468645163,
      "loss": 1.2764,
      "step": 19060
    },
    {
      "epoch": 30.77,
      "learning_rate": 0.09692322888322581,
      "loss": 1.2748,
      "step": 19080
    },
    {
      "epoch": 30.81,
      "learning_rate": 0.09692000308,
      "loss": 1.2624,
      "step": 19100
    },
    {
      "epoch": 30.84,
      "learning_rate": 0.0969167772767742,
      "loss": 1.2202,
      "step": 19120
    },
    {
      "epoch": 30.87,
      "learning_rate": 0.0969135514735484,
      "loss": 1.2725,
      "step": 19140
    },
    {
      "epoch": 30.9,
      "learning_rate": 0.09691032567032258,
      "loss": 1.2366,
      "step": 19160
    },
    {
      "epoch": 30.94,
      "learning_rate": 0.09690709986709678,
      "loss": 1.2545,
      "step": 19180
    },
    {
      "epoch": 30.97,
      "learning_rate": 0.09690387406387097,
      "loss": 1.2632,
      "step": 19200
    },
    {
      "epoch": 31.0,
      "learning_rate": 0.09690064826064516,
      "loss": 1.274,
      "step": 19220
    },
    {
      "epoch": 31.0,
      "eval_accuracy": {
        "accuracy": 0.7062680508937632
      },
      "eval_loss": 1.5316194295883179,
      "eval_runtime": 3.3573,
      "eval_samples_per_second": 3815.904,
      "eval_steps_per_second": 59.87,
      "step": 19220
    },
    {
      "epoch": 31.03,
      "learning_rate": 0.09689742245741936,
      "loss": 1.2958,
      "step": 19240
    },
    {
      "epoch": 31.06,
      "learning_rate": 0.09689419665419355,
      "loss": 1.2204,
      "step": 19260
    },
    {
      "epoch": 31.1,
      "learning_rate": 0.09689097085096775,
      "loss": 1.1936,
      "step": 19280
    },
    {
      "epoch": 31.13,
      "learning_rate": 0.09688774504774195,
      "loss": 1.19,
      "step": 19300
    },
    {
      "epoch": 31.16,
      "learning_rate": 0.09688451924451613,
      "loss": 1.2259,
      "step": 19320
    },
    {
      "epoch": 31.19,
      "learning_rate": 0.09688129344129033,
      "loss": 1.2151,
      "step": 19340
    },
    {
      "epoch": 31.23,
      "learning_rate": 0.09687806763806453,
      "loss": 1.1837,
      "step": 19360
    },
    {
      "epoch": 31.26,
      "learning_rate": 0.09687484183483872,
      "loss": 1.2146,
      "step": 19380
    },
    {
      "epoch": 31.29,
      "learning_rate": 0.09687161603161291,
      "loss": 1.2022,
      "step": 19400
    },
    {
      "epoch": 31.32,
      "learning_rate": 0.0968683902283871,
      "loss": 1.2049,
      "step": 19420
    },
    {
      "epoch": 31.35,
      "learning_rate": 0.0968651644251613,
      "loss": 1.2589,
      "step": 19440
    },
    {
      "epoch": 31.39,
      "learning_rate": 0.09686193862193548,
      "loss": 1.2601,
      "step": 19460
    },
    {
      "epoch": 31.42,
      "learning_rate": 0.09685871281870968,
      "loss": 1.2366,
      "step": 19480
    },
    {
      "epoch": 31.45,
      "learning_rate": 0.09685548701548387,
      "loss": 1.2127,
      "step": 19500
    },
    {
      "epoch": 31.48,
      "learning_rate": 0.09685226121225807,
      "loss": 1.2136,
      "step": 19520
    },
    {
      "epoch": 31.52,
      "learning_rate": 0.09684903540903227,
      "loss": 1.2169,
      "step": 19540
    },
    {
      "epoch": 31.55,
      "learning_rate": 0.09684580960580645,
      "loss": 1.2018,
      "step": 19560
    },
    {
      "epoch": 31.58,
      "learning_rate": 0.09684258380258065,
      "loss": 1.2052,
      "step": 19580
    },
    {
      "epoch": 31.61,
      "learning_rate": 0.09683935799935485,
      "loss": 1.2726,
      "step": 19600
    },
    {
      "epoch": 31.65,
      "learning_rate": 0.09683613219612903,
      "loss": 1.2095,
      "step": 19620
    },
    {
      "epoch": 31.68,
      "learning_rate": 0.09683290639290323,
      "loss": 1.2524,
      "step": 19640
    },
    {
      "epoch": 31.71,
      "learning_rate": 0.09682968058967743,
      "loss": 1.2312,
      "step": 19660
    },
    {
      "epoch": 31.74,
      "learning_rate": 0.09682645478645162,
      "loss": 1.2433,
      "step": 19680
    },
    {
      "epoch": 31.77,
      "learning_rate": 0.09682322898322582,
      "loss": 1.2366,
      "step": 19700
    },
    {
      "epoch": 31.81,
      "learning_rate": 0.09682000318,
      "loss": 1.2693,
      "step": 19720
    },
    {
      "epoch": 31.84,
      "learning_rate": 0.09681677737677419,
      "loss": 1.247,
      "step": 19740
    },
    {
      "epoch": 31.87,
      "learning_rate": 0.09681355157354839,
      "loss": 1.2482,
      "step": 19760
    },
    {
      "epoch": 31.9,
      "learning_rate": 0.09681032577032259,
      "loss": 1.2191,
      "step": 19780
    },
    {
      "epoch": 31.94,
      "learning_rate": 0.09680709996709677,
      "loss": 1.249,
      "step": 19800
    },
    {
      "epoch": 31.97,
      "learning_rate": 0.09680387416387097,
      "loss": 1.2871,
      "step": 19820
    },
    {
      "epoch": 32.0,
      "learning_rate": 0.09680064836064517,
      "loss": 1.2603,
      "step": 19840
    },
    {
      "epoch": 32.0,
      "eval_accuracy": {
        "accuracy": 0.7150885957380376
      },
      "eval_loss": 1.4167088270187378,
      "eval_runtime": 2.5142,
      "eval_samples_per_second": 5095.377,
      "eval_steps_per_second": 79.945,
      "step": 19840
    },
    {
      "epoch": 32.03,
      "learning_rate": 0.09679742255741935,
      "loss": 1.2613,
      "step": 19860
    },
    {
      "epoch": 32.06,
      "learning_rate": 0.09679419675419355,
      "loss": 1.2223,
      "step": 19880
    },
    {
      "epoch": 32.1,
      "learning_rate": 0.09679097095096775,
      "loss": 1.171,
      "step": 19900
    },
    {
      "epoch": 32.13,
      "learning_rate": 0.09678774514774194,
      "loss": 1.1633,
      "step": 19920
    },
    {
      "epoch": 32.16,
      "learning_rate": 0.09678451934451614,
      "loss": 1.2226,
      "step": 19940
    },
    {
      "epoch": 32.19,
      "learning_rate": 0.09678129354129034,
      "loss": 1.2161,
      "step": 19960
    },
    {
      "epoch": 32.23,
      "learning_rate": 0.09677806773806452,
      "loss": 1.2215,
      "step": 19980
    },
    {
      "epoch": 32.26,
      "learning_rate": 0.09677484193483872,
      "loss": 1.2473,
      "step": 20000
    },
    {
      "epoch": 32.29,
      "learning_rate": 0.0967716161316129,
      "loss": 1.2823,
      "step": 20020
    },
    {
      "epoch": 32.32,
      "learning_rate": 0.09676839032838709,
      "loss": 1.2527,
      "step": 20040
    },
    {
      "epoch": 32.35,
      "learning_rate": 0.09676516452516129,
      "loss": 1.2066,
      "step": 20060
    },
    {
      "epoch": 32.39,
      "learning_rate": 0.09676193872193549,
      "loss": 1.2234,
      "step": 20080
    },
    {
      "epoch": 32.42,
      "learning_rate": 0.09675871291870967,
      "loss": 1.2232,
      "step": 20100
    },
    {
      "epoch": 32.45,
      "learning_rate": 0.09675548711548387,
      "loss": 1.2251,
      "step": 20120
    },
    {
      "epoch": 32.48,
      "learning_rate": 0.09675226131225807,
      "loss": 1.2001,
      "step": 20140
    },
    {
      "epoch": 32.52,
      "learning_rate": 0.09674903550903226,
      "loss": 1.2116,
      "step": 20160
    },
    {
      "epoch": 32.55,
      "learning_rate": 0.09674580970580646,
      "loss": 1.2084,
      "step": 20180
    },
    {
      "epoch": 32.58,
      "learning_rate": 0.09674258390258066,
      "loss": 1.2223,
      "step": 20200
    },
    {
      "epoch": 32.61,
      "learning_rate": 0.09673935809935484,
      "loss": 1.2223,
      "step": 20220
    },
    {
      "epoch": 32.65,
      "learning_rate": 0.09673613229612904,
      "loss": 1.2282,
      "step": 20240
    },
    {
      "epoch": 32.68,
      "learning_rate": 0.09673290649290324,
      "loss": 1.2263,
      "step": 20260
    },
    {
      "epoch": 32.71,
      "learning_rate": 0.09672968068967742,
      "loss": 1.231,
      "step": 20280
    },
    {
      "epoch": 32.74,
      "learning_rate": 0.09672645488645162,
      "loss": 1.1809,
      "step": 20300
    },
    {
      "epoch": 32.77,
      "learning_rate": 0.09672322908322581,
      "loss": 1.2167,
      "step": 20320
    },
    {
      "epoch": 32.81,
      "learning_rate": 0.09672000328,
      "loss": 1.2649,
      "step": 20340
    },
    {
      "epoch": 32.84,
      "learning_rate": 0.0967167774767742,
      "loss": 1.2914,
      "step": 20360
    },
    {
      "epoch": 32.87,
      "learning_rate": 0.09671355167354839,
      "loss": 1.2427,
      "step": 20380
    },
    {
      "epoch": 32.9,
      "learning_rate": 0.09671032587032258,
      "loss": 1.2287,
      "step": 20400
    },
    {
      "epoch": 32.94,
      "learning_rate": 0.09670710006709678,
      "loss": 1.2438,
      "step": 20420
    },
    {
      "epoch": 32.97,
      "learning_rate": 0.09670387426387098,
      "loss": 1.2413,
      "step": 20440
    },
    {
      "epoch": 33.0,
      "learning_rate": 0.09670064846064516,
      "loss": 1.2166,
      "step": 20460
    },
    {
      "epoch": 33.0,
      "eval_accuracy": {
        "accuracy": 0.7100148310046054
      },
      "eval_loss": 1.4907383918762207,
      "eval_runtime": 2.5942,
      "eval_samples_per_second": 4938.343,
      "eval_steps_per_second": 77.481,
      "step": 20460
    },
    {
      "epoch": 33.03,
      "learning_rate": 0.09669742265741936,
      "loss": 1.3044,
      "step": 20480
    },
    {
      "epoch": 33.06,
      "learning_rate": 0.09669419685419356,
      "loss": 1.2517,
      "step": 20500
    },
    {
      "epoch": 33.1,
      "learning_rate": 0.09669097105096774,
      "loss": 1.2205,
      "step": 20520
    },
    {
      "epoch": 33.13,
      "learning_rate": 0.09668774524774194,
      "loss": 1.2105,
      "step": 20540
    },
    {
      "epoch": 33.16,
      "learning_rate": 0.09668451944451614,
      "loss": 1.2004,
      "step": 20560
    },
    {
      "epoch": 33.19,
      "learning_rate": 0.09668129364129033,
      "loss": 1.1907,
      "step": 20580
    },
    {
      "epoch": 33.23,
      "learning_rate": 0.09667806783806453,
      "loss": 1.2095,
      "step": 20600
    },
    {
      "epoch": 33.26,
      "learning_rate": 0.09667484203483873,
      "loss": 1.2005,
      "step": 20620
    },
    {
      "epoch": 33.29,
      "learning_rate": 0.09667161623161291,
      "loss": 1.1808,
      "step": 20640
    },
    {
      "epoch": 33.32,
      "learning_rate": 0.0966683904283871,
      "loss": 1.1983,
      "step": 20660
    },
    {
      "epoch": 33.35,
      "learning_rate": 0.0966651646251613,
      "loss": 1.2049,
      "step": 20680
    },
    {
      "epoch": 33.39,
      "learning_rate": 0.09666193882193548,
      "loss": 1.224,
      "step": 20700
    },
    {
      "epoch": 33.42,
      "learning_rate": 0.09665871301870968,
      "loss": 1.252,
      "step": 20720
    },
    {
      "epoch": 33.45,
      "learning_rate": 0.09665548721548388,
      "loss": 1.2268,
      "step": 20740
    },
    {
      "epoch": 33.48,
      "learning_rate": 0.09665226141225806,
      "loss": 1.213,
      "step": 20760
    },
    {
      "epoch": 33.52,
      "learning_rate": 0.09664903560903226,
      "loss": 1.1938,
      "step": 20780
    },
    {
      "epoch": 33.55,
      "learning_rate": 0.09664580980580646,
      "loss": 1.1995,
      "step": 20800
    },
    {
      "epoch": 33.58,
      "learning_rate": 0.09664258400258065,
      "loss": 1.2568,
      "step": 20820
    },
    {
      "epoch": 33.61,
      "learning_rate": 0.09663935819935485,
      "loss": 1.2273,
      "step": 20840
    },
    {
      "epoch": 33.65,
      "learning_rate": 0.09663613239612905,
      "loss": 1.2545,
      "step": 20860
    },
    {
      "epoch": 33.68,
      "learning_rate": 0.09663290659290323,
      "loss": 1.2255,
      "step": 20880
    },
    {
      "epoch": 33.71,
      "learning_rate": 0.09662968078967743,
      "loss": 1.2775,
      "step": 20900
    },
    {
      "epoch": 33.74,
      "learning_rate": 0.09662645498645163,
      "loss": 1.2272,
      "step": 20920
    },
    {
      "epoch": 33.77,
      "learning_rate": 0.09662322918322581,
      "loss": 1.2405,
      "step": 20940
    },
    {
      "epoch": 33.81,
      "learning_rate": 0.09662000338,
      "loss": 1.2001,
      "step": 20960
    },
    {
      "epoch": 33.84,
      "learning_rate": 0.0966167775767742,
      "loss": 1.2141,
      "step": 20980
    },
    {
      "epoch": 33.87,
      "learning_rate": 0.09661355177354838,
      "loss": 1.2055,
      "step": 21000
    },
    {
      "epoch": 33.9,
      "learning_rate": 0.09661032597032258,
      "loss": 1.2457,
      "step": 21020
    },
    {
      "epoch": 33.94,
      "learning_rate": 0.09660710016709678,
      "loss": 1.2292,
      "step": 21040
    },
    {
      "epoch": 33.97,
      "learning_rate": 0.09660387436387097,
      "loss": 1.2567,
      "step": 21060
    },
    {
      "epoch": 34.0,
      "learning_rate": 0.09660064856064517,
      "loss": 1.2464,
      "step": 21080
    },
    {
      "epoch": 34.0,
      "eval_accuracy": {
        "accuracy": 0.715478885332917
      },
      "eval_loss": 1.475043773651123,
      "eval_runtime": 2.6098,
      "eval_samples_per_second": 4908.727,
      "eval_steps_per_second": 77.016,
      "step": 21080
    },
    {
      "epoch": 34.03,
      "learning_rate": 0.09659742275741937,
      "loss": 1.2897,
      "step": 21100
    },
    {
      "epoch": 34.06,
      "learning_rate": 0.09659419695419355,
      "loss": 1.1906,
      "step": 21120
    },
    {
      "epoch": 34.1,
      "learning_rate": 0.09659097115096775,
      "loss": 1.1551,
      "step": 21140
    },
    {
      "epoch": 34.13,
      "learning_rate": 0.09658774534774195,
      "loss": 1.1638,
      "step": 21160
    },
    {
      "epoch": 34.16,
      "learning_rate": 0.09658451954451613,
      "loss": 1.1866,
      "step": 21180
    },
    {
      "epoch": 34.19,
      "learning_rate": 0.09658129374129033,
      "loss": 1.2069,
      "step": 21200
    },
    {
      "epoch": 34.23,
      "learning_rate": 0.09657806793806453,
      "loss": 1.1832,
      "step": 21220
    },
    {
      "epoch": 34.26,
      "learning_rate": 0.09657484213483872,
      "loss": 1.1745,
      "step": 21240
    },
    {
      "epoch": 34.29,
      "learning_rate": 0.0965716163316129,
      "loss": 1.1934,
      "step": 21260
    },
    {
      "epoch": 34.32,
      "learning_rate": 0.0965683905283871,
      "loss": 1.2456,
      "step": 21280
    },
    {
      "epoch": 34.35,
      "learning_rate": 0.09656516472516129,
      "loss": 1.2596,
      "step": 21300
    },
    {
      "epoch": 34.39,
      "learning_rate": 0.09656193892193549,
      "loss": 1.2462,
      "step": 21320
    },
    {
      "epoch": 34.42,
      "learning_rate": 0.09655871311870969,
      "loss": 1.259,
      "step": 21340
    },
    {
      "epoch": 34.45,
      "learning_rate": 0.09655548731548387,
      "loss": 1.2778,
      "step": 21360
    },
    {
      "epoch": 34.48,
      "learning_rate": 0.09655226151225807,
      "loss": 1.221,
      "step": 21380
    },
    {
      "epoch": 34.52,
      "learning_rate": 0.09654903570903227,
      "loss": 1.1861,
      "step": 21400
    },
    {
      "epoch": 34.55,
      "learning_rate": 0.09654580990580645,
      "loss": 1.2688,
      "step": 21420
    },
    {
      "epoch": 34.58,
      "learning_rate": 0.09654258410258065,
      "loss": 1.2552,
      "step": 21440
    },
    {
      "epoch": 34.61,
      "learning_rate": 0.09653935829935485,
      "loss": 1.2749,
      "step": 21460
    },
    {
      "epoch": 34.65,
      "learning_rate": 0.09653613249612904,
      "loss": 1.2339,
      "step": 21480
    },
    {
      "epoch": 34.68,
      "learning_rate": 0.09653290669290324,
      "loss": 1.2002,
      "step": 21500
    },
    {
      "epoch": 34.71,
      "learning_rate": 0.09652968088967742,
      "loss": 1.1862,
      "step": 21520
    },
    {
      "epoch": 34.74,
      "learning_rate": 0.09652645508645162,
      "loss": 1.2804,
      "step": 21540
    },
    {
      "epoch": 34.77,
      "learning_rate": 0.09652322928322582,
      "loss": 1.248,
      "step": 21560
    },
    {
      "epoch": 34.81,
      "learning_rate": 0.09652000348,
      "loss": 1.2457,
      "step": 21580
    },
    {
      "epoch": 34.84,
      "learning_rate": 0.09651677767677419,
      "loss": 1.2175,
      "step": 21600
    },
    {
      "epoch": 34.87,
      "learning_rate": 0.09651355187354839,
      "loss": 1.1995,
      "step": 21620
    },
    {
      "epoch": 34.9,
      "learning_rate": 0.09651032607032259,
      "loss": 1.2079,
      "step": 21640
    },
    {
      "epoch": 34.94,
      "learning_rate": 0.09650710026709677,
      "loss": 1.2267,
      "step": 21660
    },
    {
      "epoch": 34.97,
      "learning_rate": 0.09650387446387097,
      "loss": 1.2151,
      "step": 21680
    },
    {
      "epoch": 35.0,
      "learning_rate": 0.09650064866064517,
      "loss": 1.2049,
      "step": 21700
    },
    {
      "epoch": 35.0,
      "eval_accuracy": {
        "accuracy": 0.7138396690344235
      },
      "eval_loss": 1.460149884223938,
      "eval_runtime": 2.5754,
      "eval_samples_per_second": 4974.29,
      "eval_steps_per_second": 78.045,
      "step": 21700
    },
    {
      "epoch": 35.03,
      "learning_rate": 0.09649742285741936,
      "loss": 1.2533,
      "step": 21720
    },
    {
      "epoch": 35.06,
      "learning_rate": 0.09649419705419356,
      "loss": 1.2161,
      "step": 21740
    },
    {
      "epoch": 35.1,
      "learning_rate": 0.09649097125096776,
      "loss": 1.2099,
      "step": 21760
    },
    {
      "epoch": 35.13,
      "learning_rate": 0.09648774544774194,
      "loss": 1.1989,
      "step": 21780
    },
    {
      "epoch": 35.16,
      "learning_rate": 0.09648451964451614,
      "loss": 1.202,
      "step": 21800
    },
    {
      "epoch": 35.19,
      "learning_rate": 0.09648129384129032,
      "loss": 1.1858,
      "step": 21820
    },
    {
      "epoch": 35.23,
      "learning_rate": 0.09647806803806452,
      "loss": 1.1807,
      "step": 21840
    },
    {
      "epoch": 35.26,
      "learning_rate": 0.09647484223483872,
      "loss": 1.1841,
      "step": 21860
    },
    {
      "epoch": 35.29,
      "learning_rate": 0.09647161643161291,
      "loss": 1.2183,
      "step": 21880
    },
    {
      "epoch": 35.32,
      "learning_rate": 0.0964683906283871,
      "loss": 1.1807,
      "step": 21900
    },
    {
      "epoch": 35.35,
      "learning_rate": 0.09646516482516129,
      "loss": 1.1852,
      "step": 21920
    },
    {
      "epoch": 35.39,
      "learning_rate": 0.09646193902193549,
      "loss": 1.1339,
      "step": 21940
    },
    {
      "epoch": 35.42,
      "learning_rate": 0.09645871321870968,
      "loss": 1.189,
      "step": 21960
    },
    {
      "epoch": 35.45,
      "learning_rate": 0.09645548741548388,
      "loss": 1.2097,
      "step": 21980
    },
    {
      "epoch": 35.48,
      "learning_rate": 0.09645226161225808,
      "loss": 1.192,
      "step": 22000
    },
    {
      "epoch": 35.52,
      "learning_rate": 0.09644903580903226,
      "loss": 1.2512,
      "step": 22020
    },
    {
      "epoch": 35.55,
      "learning_rate": 0.09644581000580646,
      "loss": 1.2424,
      "step": 22040
    },
    {
      "epoch": 35.58,
      "learning_rate": 0.09644258420258064,
      "loss": 1.2849,
      "step": 22060
    },
    {
      "epoch": 35.61,
      "learning_rate": 0.09643935839935484,
      "loss": 1.249,
      "step": 22080
    },
    {
      "epoch": 35.65,
      "learning_rate": 0.09643613259612904,
      "loss": 1.2605,
      "step": 22100
    },
    {
      "epoch": 35.68,
      "learning_rate": 0.09643290679290323,
      "loss": 1.2236,
      "step": 22120
    },
    {
      "epoch": 35.71,
      "learning_rate": 0.09642968098967743,
      "loss": 1.2006,
      "step": 22140
    },
    {
      "epoch": 35.74,
      "learning_rate": 0.09642645518645163,
      "loss": 1.2311,
      "step": 22160
    },
    {
      "epoch": 35.77,
      "learning_rate": 0.09642322938322581,
      "loss": 1.2598,
      "step": 22180
    },
    {
      "epoch": 35.81,
      "learning_rate": 0.09642000358,
      "loss": 1.2207,
      "step": 22200
    },
    {
      "epoch": 35.84,
      "learning_rate": 0.0964167777767742,
      "loss": 1.2353,
      "step": 22220
    },
    {
      "epoch": 35.87,
      "learning_rate": 0.0964135519735484,
      "loss": 1.292,
      "step": 22240
    },
    {
      "epoch": 35.9,
      "learning_rate": 0.09641032617032258,
      "loss": 1.256,
      "step": 22260
    },
    {
      "epoch": 35.94,
      "learning_rate": 0.09640710036709678,
      "loss": 1.195,
      "step": 22280
    },
    {
      "epoch": 35.97,
      "learning_rate": 0.09640387456387098,
      "loss": 1.2169,
      "step": 22300
    },
    {
      "epoch": 36.0,
      "learning_rate": 0.09640064876064516,
      "loss": 1.223,
      "step": 22320
    },
    {
      "epoch": 36.0,
      "eval_accuracy": {
        "accuracy": 0.7141519007103271
      },
      "eval_loss": 1.4425981044769287,
      "eval_runtime": 2.9076,
      "eval_samples_per_second": 4406.066,
      "eval_steps_per_second": 69.13,
      "step": 22320
    },
    {
      "epoch": 36.03,
      "learning_rate": 0.09639742295741936,
      "loss": 1.2587,
      "step": 22340
    },
    {
      "epoch": 36.06,
      "learning_rate": 0.09639419715419355,
      "loss": 1.2347,
      "step": 22360
    },
    {
      "epoch": 36.1,
      "learning_rate": 0.09639097135096775,
      "loss": 1.2284,
      "step": 22380
    },
    {
      "epoch": 36.13,
      "learning_rate": 0.09638774554774195,
      "loss": 1.2116,
      "step": 22400
    },
    {
      "epoch": 36.16,
      "learning_rate": 0.09638451974451613,
      "loss": 1.1915,
      "step": 22420
    },
    {
      "epoch": 36.19,
      "learning_rate": 0.09638129394129033,
      "loss": 1.2472,
      "step": 22440
    },
    {
      "epoch": 36.23,
      "learning_rate": 0.09637806813806453,
      "loss": 1.2137,
      "step": 22460
    },
    {
      "epoch": 36.26,
      "learning_rate": 0.09637484233483871,
      "loss": 1.1772,
      "step": 22480
    },
    {
      "epoch": 36.29,
      "learning_rate": 0.0963716165316129,
      "loss": 1.1939,
      "step": 22500
    },
    {
      "epoch": 36.32,
      "learning_rate": 0.0963683907283871,
      "loss": 1.2032,
      "step": 22520
    },
    {
      "epoch": 36.35,
      "learning_rate": 0.0963651649251613,
      "loss": 1.2609,
      "step": 22540
    },
    {
      "epoch": 36.39,
      "learning_rate": 0.09636193912193548,
      "loss": 1.2296,
      "step": 22560
    },
    {
      "epoch": 36.42,
      "learning_rate": 0.09635871331870968,
      "loss": 1.1804,
      "step": 22580
    },
    {
      "epoch": 36.45,
      "learning_rate": 0.09635548751548387,
      "loss": 1.2571,
      "step": 22600
    },
    {
      "epoch": 36.48,
      "learning_rate": 0.09635226171225807,
      "loss": 1.2414,
      "step": 22620
    },
    {
      "epoch": 36.52,
      "learning_rate": 0.09634903590903227,
      "loss": 1.2659,
      "step": 22640
    },
    {
      "epoch": 36.55,
      "learning_rate": 0.09634581010580645,
      "loss": 1.202,
      "step": 22660
    },
    {
      "epoch": 36.58,
      "learning_rate": 0.09634258430258065,
      "loss": 1.2353,
      "step": 22680
    },
    {
      "epoch": 36.61,
      "learning_rate": 0.09633935849935485,
      "loss": 1.212,
      "step": 22700
    },
    {
      "epoch": 36.65,
      "learning_rate": 0.09633613269612903,
      "loss": 1.2047,
      "step": 22720
    },
    {
      "epoch": 36.68,
      "learning_rate": 0.09633290689290323,
      "loss": 1.1875,
      "step": 22740
    },
    {
      "epoch": 36.71,
      "learning_rate": 0.09632968108967743,
      "loss": 1.1689,
      "step": 22760
    },
    {
      "epoch": 36.74,
      "learning_rate": 0.09632645528645162,
      "loss": 1.2059,
      "step": 22780
    },
    {
      "epoch": 36.77,
      "learning_rate": 0.09632322948322582,
      "loss": 1.2121,
      "step": 22800
    },
    {
      "epoch": 36.81,
      "learning_rate": 0.09632000368000002,
      "loss": 1.1828,
      "step": 22820
    },
    {
      "epoch": 36.84,
      "learning_rate": 0.0963167778767742,
      "loss": 1.2272,
      "step": 22840
    },
    {
      "epoch": 36.87,
      "learning_rate": 0.09631355207354839,
      "loss": 1.209,
      "step": 22860
    },
    {
      "epoch": 36.9,
      "learning_rate": 0.09631032627032259,
      "loss": 1.1887,
      "step": 22880
    },
    {
      "epoch": 36.94,
      "learning_rate": 0.09630710046709677,
      "loss": 1.2368,
      "step": 22900
    },
    {
      "epoch": 36.97,
      "learning_rate": 0.09630387466387097,
      "loss": 1.2313,
      "step": 22920
    },
    {
      "epoch": 37.0,
      "learning_rate": 0.09630064886064517,
      "loss": 1.1861,
      "step": 22940
    },
    {
      "epoch": 37.0,
      "eval_accuracy": {
        "accuracy": 0.7164936382796034
      },
      "eval_loss": 1.438773274421692,
      "eval_runtime": 3.8495,
      "eval_samples_per_second": 3327.953,
      "eval_steps_per_second": 52.214,
      "step": 22940
    },
    {
      "epoch": 37.03,
      "learning_rate": 0.09629742305741935,
      "loss": 1.2369,
      "step": 22960
    },
    {
      "epoch": 37.06,
      "learning_rate": 0.09629419725419355,
      "loss": 1.1652,
      "step": 22980
    },
    {
      "epoch": 37.1,
      "learning_rate": 0.09629097145096775,
      "loss": 1.2,
      "step": 23000
    },
    {
      "epoch": 37.13,
      "learning_rate": 0.09628774564774194,
      "loss": 1.2146,
      "step": 23020
    },
    {
      "epoch": 37.16,
      "learning_rate": 0.09628451984451614,
      "loss": 1.1822,
      "step": 23040
    },
    {
      "epoch": 37.19,
      "learning_rate": 0.09628129404129034,
      "loss": 1.2037,
      "step": 23060
    },
    {
      "epoch": 37.23,
      "learning_rate": 0.09627822952822582,
      "loss": 1.1821,
      "step": 23080
    },
    {
      "epoch": 37.26,
      "learning_rate": 0.096275003725,
      "loss": 1.2077,
      "step": 23100
    },
    {
      "epoch": 37.29,
      "learning_rate": 0.0962717779217742,
      "loss": 1.1849,
      "step": 23120
    },
    {
      "epoch": 37.32,
      "learning_rate": 0.09626855211854839,
      "loss": 1.2071,
      "step": 23140
    },
    {
      "epoch": 37.35,
      "learning_rate": 0.09626532631532259,
      "loss": 1.204,
      "step": 23160
    },
    {
      "epoch": 37.39,
      "learning_rate": 0.09626210051209678,
      "loss": 1.1932,
      "step": 23180
    },
    {
      "epoch": 37.42,
      "learning_rate": 0.09625887470887097,
      "loss": 1.1934,
      "step": 23200
    },
    {
      "epoch": 37.45,
      "learning_rate": 0.09625564890564517,
      "loss": 1.2373,
      "step": 23220
    },
    {
      "epoch": 37.48,
      "learning_rate": 0.09625242310241937,
      "loss": 1.2299,
      "step": 23240
    },
    {
      "epoch": 37.52,
      "learning_rate": 0.09624919729919355,
      "loss": 1.2325,
      "step": 23260
    },
    {
      "epoch": 37.55,
      "learning_rate": 0.09624597149596774,
      "loss": 1.2035,
      "step": 23280
    },
    {
      "epoch": 37.58,
      "learning_rate": 0.09624274569274194,
      "loss": 1.2466,
      "step": 23300
    },
    {
      "epoch": 37.61,
      "learning_rate": 0.09623951988951614,
      "loss": 1.2267,
      "step": 23320
    },
    {
      "epoch": 37.65,
      "learning_rate": 0.09623629408629032,
      "loss": 1.2047,
      "step": 23340
    },
    {
      "epoch": 37.68,
      "learning_rate": 0.09623306828306452,
      "loss": 1.2206,
      "step": 23360
    },
    {
      "epoch": 37.71,
      "learning_rate": 0.09622984247983872,
      "loss": 1.2167,
      "step": 23380
    },
    {
      "epoch": 37.74,
      "learning_rate": 0.0962266166766129,
      "loss": 1.1758,
      "step": 23400
    },
    {
      "epoch": 37.77,
      "learning_rate": 0.0962233908733871,
      "loss": 1.2128,
      "step": 23420
    },
    {
      "epoch": 37.81,
      "learning_rate": 0.09622016507016129,
      "loss": 1.2327,
      "step": 23440
    },
    {
      "epoch": 37.84,
      "learning_rate": 0.09621693926693549,
      "loss": 1.1815,
      "step": 23460
    },
    {
      "epoch": 37.87,
      "learning_rate": 0.09621371346370969,
      "loss": 1.1908,
      "step": 23480
    },
    {
      "epoch": 37.9,
      "learning_rate": 0.09621048766048387,
      "loss": 1.2722,
      "step": 23500
    },
    {
      "epoch": 37.94,
      "learning_rate": 0.09620726185725807,
      "loss": 1.241,
      "step": 23520
    },
    {
      "epoch": 37.97,
      "learning_rate": 0.09620403605403227,
      "loss": 1.237,
      "step": 23540
    },
    {
      "epoch": 38.0,
      "learning_rate": 0.09620081025080646,
      "loss": 1.2875,
      "step": 23560
    },
    {
      "epoch": 38.0,
      "eval_accuracy": {
        "accuracy": 0.715478885332917
      },
      "eval_loss": 1.5096009969711304,
      "eval_runtime": 2.4893,
      "eval_samples_per_second": 5146.434,
      "eval_steps_per_second": 80.746,
      "step": 23560
    },
    {
      "epoch": 38.03,
      "learning_rate": 0.09619758444758064,
      "loss": 1.2978,
      "step": 23580
    },
    {
      "epoch": 38.06,
      "learning_rate": 0.09619435864435484,
      "loss": 1.1948,
      "step": 23600
    },
    {
      "epoch": 38.1,
      "learning_rate": 0.09619113284112904,
      "loss": 1.1804,
      "step": 23620
    },
    {
      "epoch": 38.13,
      "learning_rate": 0.09618790703790323,
      "loss": 1.1749,
      "step": 23640
    },
    {
      "epoch": 38.16,
      "learning_rate": 0.09618468123467742,
      "loss": 1.1799,
      "step": 23660
    },
    {
      "epoch": 38.19,
      "learning_rate": 0.09618145543145161,
      "loss": 1.2049,
      "step": 23680
    },
    {
      "epoch": 38.23,
      "learning_rate": 0.09617822962822581,
      "loss": 1.1681,
      "step": 23700
    },
    {
      "epoch": 38.26,
      "learning_rate": 0.09617500382500001,
      "loss": 1.1781,
      "step": 23720
    },
    {
      "epoch": 38.29,
      "learning_rate": 0.09617177802177419,
      "loss": 1.1857,
      "step": 23740
    },
    {
      "epoch": 38.32,
      "learning_rate": 0.09616855221854839,
      "loss": 1.173,
      "step": 23760
    },
    {
      "epoch": 38.35,
      "learning_rate": 0.09616532641532259,
      "loss": 1.2163,
      "step": 23780
    },
    {
      "epoch": 38.39,
      "learning_rate": 0.09616210061209678,
      "loss": 1.226,
      "step": 23800
    },
    {
      "epoch": 38.42,
      "learning_rate": 0.09615887480887098,
      "loss": 1.2053,
      "step": 23820
    },
    {
      "epoch": 38.45,
      "learning_rate": 0.09615564900564517,
      "loss": 1.1942,
      "step": 23840
    },
    {
      "epoch": 38.48,
      "learning_rate": 0.09615242320241936,
      "loss": 1.1927,
      "step": 23860
    },
    {
      "epoch": 38.52,
      "learning_rate": 0.09614919739919356,
      "loss": 1.1887,
      "step": 23880
    },
    {
      "epoch": 38.55,
      "learning_rate": 0.09614597159596776,
      "loss": 1.2292,
      "step": 23900
    },
    {
      "epoch": 38.58,
      "learning_rate": 0.09614274579274194,
      "loss": 1.2472,
      "step": 23920
    },
    {
      "epoch": 38.61,
      "learning_rate": 0.09613951998951613,
      "loss": 1.2049,
      "step": 23940
    },
    {
      "epoch": 38.65,
      "learning_rate": 0.09613629418629033,
      "loss": 1.215,
      "step": 23960
    },
    {
      "epoch": 38.68,
      "learning_rate": 0.09613306838306451,
      "loss": 1.1757,
      "step": 23980
    },
    {
      "epoch": 38.71,
      "learning_rate": 0.09612984257983871,
      "loss": 1.1832,
      "step": 24000
    },
    {
      "epoch": 38.74,
      "learning_rate": 0.09612661677661291,
      "loss": 1.1992,
      "step": 24020
    },
    {
      "epoch": 38.77,
      "learning_rate": 0.0961233909733871,
      "loss": 1.2464,
      "step": 24040
    },
    {
      "epoch": 38.81,
      "learning_rate": 0.0961201651701613,
      "loss": 1.2766,
      "step": 24060
    },
    {
      "epoch": 38.84,
      "learning_rate": 0.0961169393669355,
      "loss": 1.1639,
      "step": 24080
    },
    {
      "epoch": 38.87,
      "learning_rate": 0.09611371356370968,
      "loss": 1.2293,
      "step": 24100
    },
    {
      "epoch": 38.9,
      "learning_rate": 0.09611048776048388,
      "loss": 1.1855,
      "step": 24120
    },
    {
      "epoch": 38.94,
      "learning_rate": 0.09610726195725808,
      "loss": 1.1923,
      "step": 24140
    },
    {
      "epoch": 38.97,
      "learning_rate": 0.09610403615403226,
      "loss": 1.2055,
      "step": 24160
    },
    {
      "epoch": 39.0,
      "learning_rate": 0.09610081035080646,
      "loss": 1.2081,
      "step": 24180
    },
    {
      "epoch": 39.0,
      "eval_accuracy": {
        "accuracy": 0.7069705721645461
      },
      "eval_loss": 1.5075150728225708,
      "eval_runtime": 2.6228,
      "eval_samples_per_second": 4884.501,
      "eval_steps_per_second": 76.636,
      "step": 24180
    },
    {
      "epoch": 39.03,
      "learning_rate": 0.09609758454758066,
      "loss": 1.2659,
      "step": 24200
    },
    {
      "epoch": 39.06,
      "learning_rate": 0.09609435874435483,
      "loss": 1.197,
      "step": 24220
    },
    {
      "epoch": 39.1,
      "learning_rate": 0.09609113294112903,
      "loss": 1.2305,
      "step": 24240
    },
    {
      "epoch": 39.13,
      "learning_rate": 0.09608790713790323,
      "loss": 1.2321,
      "step": 24260
    },
    {
      "epoch": 39.16,
      "learning_rate": 0.09608468133467742,
      "loss": 1.2133,
      "step": 24280
    },
    {
      "epoch": 39.19,
      "learning_rate": 0.09608145553145161,
      "loss": 1.2035,
      "step": 24300
    },
    {
      "epoch": 39.23,
      "learning_rate": 0.09607822972822581,
      "loss": 1.2253,
      "step": 24320
    },
    {
      "epoch": 39.26,
      "learning_rate": 0.096075003925,
      "loss": 1.1576,
      "step": 24340
    },
    {
      "epoch": 39.29,
      "learning_rate": 0.0960717781217742,
      "loss": 1.2014,
      "step": 24360
    },
    {
      "epoch": 39.32,
      "learning_rate": 0.0960685523185484,
      "loss": 1.1788,
      "step": 24380
    },
    {
      "epoch": 39.35,
      "learning_rate": 0.09606532651532258,
      "loss": 1.1964,
      "step": 24400
    },
    {
      "epoch": 39.39,
      "learning_rate": 0.09606210071209678,
      "loss": 1.1767,
      "step": 24420
    },
    {
      "epoch": 39.42,
      "learning_rate": 0.09605887490887098,
      "loss": 1.1699,
      "step": 24440
    },
    {
      "epoch": 39.45,
      "learning_rate": 0.09605564910564517,
      "loss": 1.1802,
      "step": 24460
    },
    {
      "epoch": 39.48,
      "learning_rate": 0.09605242330241937,
      "loss": 1.1887,
      "step": 24480
    },
    {
      "epoch": 39.52,
      "learning_rate": 0.09604919749919356,
      "loss": 1.1524,
      "step": 24500
    },
    {
      "epoch": 39.55,
      "learning_rate": 0.09604597169596774,
      "loss": 1.2021,
      "step": 24520
    },
    {
      "epoch": 39.58,
      "learning_rate": 0.09604274589274193,
      "loss": 1.2183,
      "step": 24540
    },
    {
      "epoch": 39.61,
      "learning_rate": 0.09603952008951613,
      "loss": 1.211,
      "step": 24560
    },
    {
      "epoch": 39.65,
      "learning_rate": 0.09603629428629032,
      "loss": 1.2279,
      "step": 24580
    },
    {
      "epoch": 39.68,
      "learning_rate": 0.09603306848306452,
      "loss": 1.208,
      "step": 24600
    },
    {
      "epoch": 39.71,
      "learning_rate": 0.09602984267983872,
      "loss": 1.18,
      "step": 24620
    },
    {
      "epoch": 39.74,
      "learning_rate": 0.0960266168766129,
      "loss": 1.173,
      "step": 24640
    },
    {
      "epoch": 39.77,
      "learning_rate": 0.0960233910733871,
      "loss": 1.21,
      "step": 24660
    },
    {
      "epoch": 39.81,
      "learning_rate": 0.0960201652701613,
      "loss": 1.2085,
      "step": 24680
    },
    {
      "epoch": 39.84,
      "learning_rate": 0.09601693946693549,
      "loss": 1.2128,
      "step": 24700
    },
    {
      "epoch": 39.87,
      "learning_rate": 0.09601371366370968,
      "loss": 1.207,
      "step": 24720
    },
    {
      "epoch": 39.9,
      "learning_rate": 0.09601048786048388,
      "loss": 1.2146,
      "step": 24740
    },
    {
      "epoch": 39.94,
      "learning_rate": 0.09600726205725807,
      "loss": 1.2014,
      "step": 24760
    },
    {
      "epoch": 39.97,
      "learning_rate": 0.09600403625403227,
      "loss": 1.2257,
      "step": 24780
    },
    {
      "epoch": 40.0,
      "learning_rate": 0.09600081045080647,
      "loss": 1.2256,
      "step": 24800
    },
    {
      "epoch": 40.0,
      "eval_accuracy": {
        "accuracy": 0.7192256654437593
      },
      "eval_loss": 1.4259426593780518,
      "eval_runtime": 2.5079,
      "eval_samples_per_second": 5108.254,
      "eval_steps_per_second": 80.147,
      "step": 24800
    },
    {
      "epoch": 40.03,
      "learning_rate": 0.09599758464758064,
      "loss": 1.2257,
      "step": 24820
    },
    {
      "epoch": 40.06,
      "learning_rate": 0.09599435884435484,
      "loss": 1.2196,
      "step": 24840
    },
    {
      "epoch": 40.1,
      "learning_rate": 0.09599113304112904,
      "loss": 1.1945,
      "step": 24860
    },
    {
      "epoch": 40.13,
      "learning_rate": 0.09598790723790322,
      "loss": 1.1764,
      "step": 24880
    },
    {
      "epoch": 40.16,
      "learning_rate": 0.09598468143467742,
      "loss": 1.1749,
      "step": 24900
    },
    {
      "epoch": 40.19,
      "learning_rate": 0.09598145563145162,
      "loss": 1.2029,
      "step": 24920
    },
    {
      "epoch": 40.23,
      "learning_rate": 0.0959782298282258,
      "loss": 1.1899,
      "step": 24940
    },
    {
      "epoch": 40.26,
      "learning_rate": 0.095975004025,
      "loss": 1.1511,
      "step": 24960
    },
    {
      "epoch": 40.29,
      "learning_rate": 0.0959717782217742,
      "loss": 1.2035,
      "step": 24980
    },
    {
      "epoch": 40.32,
      "learning_rate": 0.09596855241854839,
      "loss": 1.2044,
      "step": 25000
    },
    {
      "epoch": 40.35,
      "learning_rate": 0.09596532661532259,
      "loss": 1.191,
      "step": 25020
    },
    {
      "epoch": 40.39,
      "learning_rate": 0.09596210081209679,
      "loss": 1.1815,
      "step": 25040
    },
    {
      "epoch": 40.42,
      "learning_rate": 0.09595887500887097,
      "loss": 1.2284,
      "step": 25060
    },
    {
      "epoch": 40.45,
      "learning_rate": 0.09595564920564517,
      "loss": 1.2489,
      "step": 25080
    },
    {
      "epoch": 40.48,
      "learning_rate": 0.09595242340241937,
      "loss": 1.2503,
      "step": 25100
    },
    {
      "epoch": 40.52,
      "learning_rate": 0.09594919759919356,
      "loss": 1.2487,
      "step": 25120
    },
    {
      "epoch": 40.55,
      "learning_rate": 0.09594597179596775,
      "loss": 1.1986,
      "step": 25140
    },
    {
      "epoch": 40.58,
      "learning_rate": 0.09594274599274194,
      "loss": 1.2068,
      "step": 25160
    },
    {
      "epoch": 40.61,
      "learning_rate": 0.09593952018951613,
      "loss": 1.1761,
      "step": 25180
    },
    {
      "epoch": 40.65,
      "learning_rate": 0.09593645567645162,
      "loss": 1.2487,
      "step": 25200
    },
    {
      "epoch": 40.68,
      "learning_rate": 0.09593322987322582,
      "loss": 1.2248,
      "step": 25220
    },
    {
      "epoch": 40.71,
      "learning_rate": 0.09593000407,
      "loss": 1.1907,
      "step": 25240
    },
    {
      "epoch": 40.74,
      "learning_rate": 0.0959267782667742,
      "loss": 1.1949,
      "step": 25260
    },
    {
      "epoch": 40.77,
      "learning_rate": 0.0959235524635484,
      "loss": 1.2039,
      "step": 25280
    },
    {
      "epoch": 40.81,
      "learning_rate": 0.09592032666032257,
      "loss": 1.223,
      "step": 25300
    },
    {
      "epoch": 40.84,
      "learning_rate": 0.09591710085709677,
      "loss": 1.1841,
      "step": 25320
    },
    {
      "epoch": 40.87,
      "learning_rate": 0.09591387505387097,
      "loss": 1.1854,
      "step": 25340
    },
    {
      "epoch": 40.9,
      "learning_rate": 0.09591064925064516,
      "loss": 1.1578,
      "step": 25360
    },
    {
      "epoch": 40.94,
      "learning_rate": 0.09590742344741936,
      "loss": 1.2057,
      "step": 25380
    },
    {
      "epoch": 40.97,
      "learning_rate": 0.09590419764419356,
      "loss": 1.2388,
      "step": 25400
    },
    {
      "epoch": 41.0,
      "learning_rate": 0.09590097184096774,
      "loss": 1.2315,
      "step": 25420
    },
    {
      "epoch": 41.0,
      "eval_accuracy": {
        "accuracy": 0.7099367730856295
      },
      "eval_loss": 1.5046573877334595,
      "eval_runtime": 2.9955,
      "eval_samples_per_second": 4276.737,
      "eval_steps_per_second": 67.1,
      "step": 25420
    },
    {
      "epoch": 41.03,
      "learning_rate": 0.09589774603774194,
      "loss": 1.2205,
      "step": 25440
    },
    {
      "epoch": 41.06,
      "learning_rate": 0.09589452023451614,
      "loss": 1.1693,
      "step": 25460
    },
    {
      "epoch": 41.1,
      "learning_rate": 0.09589129443129032,
      "loss": 1.1967,
      "step": 25480
    },
    {
      "epoch": 41.13,
      "learning_rate": 0.09588806862806452,
      "loss": 1.173,
      "step": 25500
    },
    {
      "epoch": 41.16,
      "learning_rate": 0.09588484282483872,
      "loss": 1.166,
      "step": 25520
    },
    {
      "epoch": 41.19,
      "learning_rate": 0.09588161702161291,
      "loss": 1.2062,
      "step": 25540
    },
    {
      "epoch": 41.23,
      "learning_rate": 0.09587839121838711,
      "loss": 1.1801,
      "step": 25560
    },
    {
      "epoch": 41.26,
      "learning_rate": 0.0958751654151613,
      "loss": 1.1916,
      "step": 25580
    },
    {
      "epoch": 41.29,
      "learning_rate": 0.09587193961193548,
      "loss": 1.191,
      "step": 25600
    },
    {
      "epoch": 41.32,
      "learning_rate": 0.09586871380870968,
      "loss": 1.2128,
      "step": 25620
    },
    {
      "epoch": 41.35,
      "learning_rate": 0.09586548800548388,
      "loss": 1.1911,
      "step": 25640
    },
    {
      "epoch": 41.39,
      "learning_rate": 0.09586226220225806,
      "loss": 1.1966,
      "step": 25660
    },
    {
      "epoch": 41.42,
      "learning_rate": 0.09585903639903226,
      "loss": 1.1743,
      "step": 25680
    },
    {
      "epoch": 41.45,
      "learning_rate": 0.09585581059580646,
      "loss": 1.2033,
      "step": 25700
    },
    {
      "epoch": 41.48,
      "learning_rate": 0.09585258479258064,
      "loss": 1.2082,
      "step": 25720
    },
    {
      "epoch": 41.52,
      "learning_rate": 0.09584935898935484,
      "loss": 1.2214,
      "step": 25740
    },
    {
      "epoch": 41.55,
      "learning_rate": 0.09584613318612904,
      "loss": 1.183,
      "step": 25760
    },
    {
      "epoch": 41.58,
      "learning_rate": 0.09584290738290323,
      "loss": 1.1939,
      "step": 25780
    },
    {
      "epoch": 41.61,
      "learning_rate": 0.09583968157967743,
      "loss": 1.2021,
      "step": 25800
    },
    {
      "epoch": 41.65,
      "learning_rate": 0.09583645577645163,
      "loss": 1.2311,
      "step": 25820
    },
    {
      "epoch": 41.68,
      "learning_rate": 0.09583322997322581,
      "loss": 1.2088,
      "step": 25840
    },
    {
      "epoch": 41.71,
      "learning_rate": 0.09583000417000001,
      "loss": 1.182,
      "step": 25860
    },
    {
      "epoch": 41.74,
      "learning_rate": 0.09582677836677421,
      "loss": 1.1826,
      "step": 25880
    },
    {
      "epoch": 41.77,
      "learning_rate": 0.09582355256354838,
      "loss": 1.1898,
      "step": 25900
    },
    {
      "epoch": 41.81,
      "learning_rate": 0.09582032676032258,
      "loss": 1.2316,
      "step": 25920
    },
    {
      "epoch": 41.84,
      "learning_rate": 0.09581710095709678,
      "loss": 1.2151,
      "step": 25940
    },
    {
      "epoch": 41.87,
      "learning_rate": 0.09581387515387096,
      "loss": 1.2325,
      "step": 25960
    },
    {
      "epoch": 41.9,
      "learning_rate": 0.09581064935064516,
      "loss": 1.2336,
      "step": 25980
    },
    {
      "epoch": 41.94,
      "learning_rate": 0.09580742354741936,
      "loss": 1.1926,
      "step": 26000
    },
    {
      "epoch": 41.97,
      "learning_rate": 0.09580419774419355,
      "loss": 1.2095,
      "step": 26020
    },
    {
      "epoch": 42.0,
      "learning_rate": 0.09580097194096775,
      "loss": 1.2368,
      "step": 26040
    },
    {
      "epoch": 42.0,
      "eval_accuracy": {
        "accuracy": 0.7060338771368355
      },
      "eval_loss": 1.5638298988342285,
      "eval_runtime": 2.9707,
      "eval_samples_per_second": 4312.431,
      "eval_steps_per_second": 67.66,
      "step": 26040
    },
    {
      "epoch": 42.03,
      "learning_rate": 0.09579774613774195,
      "loss": 1.3168,
      "step": 26060
    },
    {
      "epoch": 42.06,
      "learning_rate": 0.09579452033451613,
      "loss": 1.2012,
      "step": 26080
    },
    {
      "epoch": 42.1,
      "learning_rate": 0.09579129453129033,
      "loss": 1.1937,
      "step": 26100
    },
    {
      "epoch": 42.13,
      "learning_rate": 0.09578806872806453,
      "loss": 1.2155,
      "step": 26120
    },
    {
      "epoch": 42.16,
      "learning_rate": 0.09578484292483871,
      "loss": 1.2155,
      "step": 26140
    },
    {
      "epoch": 42.19,
      "learning_rate": 0.09578161712161291,
      "loss": 1.229,
      "step": 26160
    },
    {
      "epoch": 42.23,
      "learning_rate": 0.09577839131838711,
      "loss": 1.17,
      "step": 26180
    },
    {
      "epoch": 42.26,
      "learning_rate": 0.0957751655151613,
      "loss": 1.1782,
      "step": 26200
    },
    {
      "epoch": 42.29,
      "learning_rate": 0.0957719397119355,
      "loss": 1.2191,
      "step": 26220
    },
    {
      "epoch": 42.32,
      "learning_rate": 0.09576871390870968,
      "loss": 1.192,
      "step": 26240
    },
    {
      "epoch": 42.35,
      "learning_rate": 0.09576548810548387,
      "loss": 1.2268,
      "step": 26260
    },
    {
      "epoch": 42.39,
      "learning_rate": 0.09576226230225807,
      "loss": 1.1439,
      "step": 26280
    },
    {
      "epoch": 42.42,
      "learning_rate": 0.09575903649903227,
      "loss": 1.1565,
      "step": 26300
    },
    {
      "epoch": 42.45,
      "learning_rate": 0.09575581069580645,
      "loss": 1.1904,
      "step": 26320
    },
    {
      "epoch": 42.48,
      "learning_rate": 0.09575258489258065,
      "loss": 1.1883,
      "step": 26340
    },
    {
      "epoch": 42.52,
      "learning_rate": 0.09574935908935485,
      "loss": 1.1843,
      "step": 26360
    },
    {
      "epoch": 42.55,
      "learning_rate": 0.09574613328612903,
      "loss": 1.2111,
      "step": 26380
    },
    {
      "epoch": 42.58,
      "learning_rate": 0.09574290748290323,
      "loss": 1.1657,
      "step": 26400
    },
    {
      "epoch": 42.61,
      "learning_rate": 0.09573968167967743,
      "loss": 1.2113,
      "step": 26420
    },
    {
      "epoch": 42.65,
      "learning_rate": 0.09573645587645162,
      "loss": 1.2004,
      "step": 26440
    },
    {
      "epoch": 42.68,
      "learning_rate": 0.09573323007322582,
      "loss": 1.2163,
      "step": 26460
    },
    {
      "epoch": 42.71,
      "learning_rate": 0.09573000427000002,
      "loss": 1.214,
      "step": 26480
    },
    {
      "epoch": 42.74,
      "learning_rate": 0.0957267784667742,
      "loss": 1.2192,
      "step": 26500
    },
    {
      "epoch": 42.77,
      "learning_rate": 0.0957235526635484,
      "loss": 1.2321,
      "step": 26520
    },
    {
      "epoch": 42.81,
      "learning_rate": 0.09572032686032259,
      "loss": 1.2257,
      "step": 26540
    },
    {
      "epoch": 42.84,
      "learning_rate": 0.09571710105709677,
      "loss": 1.2058,
      "step": 26560
    },
    {
      "epoch": 42.87,
      "learning_rate": 0.09571387525387097,
      "loss": 1.2433,
      "step": 26580
    },
    {
      "epoch": 42.9,
      "learning_rate": 0.09571064945064517,
      "loss": 1.2009,
      "step": 26600
    },
    {
      "epoch": 42.94,
      "learning_rate": 0.09570742364741935,
      "loss": 1.1657,
      "step": 26620
    },
    {
      "epoch": 42.97,
      "learning_rate": 0.09570419784419355,
      "loss": 1.1747,
      "step": 26640
    },
    {
      "epoch": 43.0,
      "learning_rate": 0.09570097204096775,
      "loss": 1.1814,
      "step": 26660
    },
    {
      "epoch": 43.0,
      "eval_accuracy": {
        "accuracy": 0.7230505034735774
      },
      "eval_loss": 1.4391087293624878,
      "eval_runtime": 4.5175,
      "eval_samples_per_second": 2835.838,
      "eval_steps_per_second": 44.493,
      "step": 26660
    },
    {
      "epoch": 43.03,
      "learning_rate": 0.09569774623774194,
      "loss": 1.1907,
      "step": 26680
    },
    {
      "epoch": 43.06,
      "learning_rate": 0.09569452043451614,
      "loss": 1.155,
      "step": 26700
    },
    {
      "epoch": 43.1,
      "learning_rate": 0.09569129463129034,
      "loss": 1.173,
      "step": 26720
    },
    {
      "epoch": 43.13,
      "learning_rate": 0.09568806882806452,
      "loss": 1.1713,
      "step": 26740
    },
    {
      "epoch": 43.16,
      "learning_rate": 0.09568484302483872,
      "loss": 1.1683,
      "step": 26760
    },
    {
      "epoch": 43.19,
      "learning_rate": 0.09568161722161292,
      "loss": 1.1484,
      "step": 26780
    },
    {
      "epoch": 43.23,
      "learning_rate": 0.0956783914183871,
      "loss": 1.1448,
      "step": 26800
    },
    {
      "epoch": 43.26,
      "learning_rate": 0.0956751656151613,
      "loss": 1.1981,
      "step": 26820
    },
    {
      "epoch": 43.29,
      "learning_rate": 0.09567193981193549,
      "loss": 1.1787,
      "step": 26840
    },
    {
      "epoch": 43.32,
      "learning_rate": 0.09566871400870967,
      "loss": 1.175,
      "step": 26860
    },
    {
      "epoch": 43.35,
      "learning_rate": 0.09566548820548387,
      "loss": 1.2107,
      "step": 26880
    },
    {
      "epoch": 43.39,
      "learning_rate": 0.09566226240225807,
      "loss": 1.2258,
      "step": 26900
    },
    {
      "epoch": 43.42,
      "learning_rate": 0.09565903659903226,
      "loss": 1.2493,
      "step": 26920
    },
    {
      "epoch": 43.45,
      "learning_rate": 0.09565581079580646,
      "loss": 1.1916,
      "step": 26940
    },
    {
      "epoch": 43.48,
      "learning_rate": 0.09565258499258066,
      "loss": 1.1937,
      "step": 26960
    },
    {
      "epoch": 43.52,
      "learning_rate": 0.09564935918935484,
      "loss": 1.2016,
      "step": 26980
    },
    {
      "epoch": 43.55,
      "learning_rate": 0.09564613338612904,
      "loss": 1.2074,
      "step": 27000
    },
    {
      "epoch": 43.58,
      "learning_rate": 0.09564290758290324,
      "loss": 1.1926,
      "step": 27020
    },
    {
      "epoch": 43.61,
      "learning_rate": 0.09563968177967742,
      "loss": 1.223,
      "step": 27040
    },
    {
      "epoch": 43.65,
      "learning_rate": 0.09563645597645162,
      "loss": 1.1697,
      "step": 27060
    },
    {
      "epoch": 43.68,
      "learning_rate": 0.09563323017322581,
      "loss": 1.2162,
      "step": 27080
    },
    {
      "epoch": 43.71,
      "learning_rate": 0.09563000437000001,
      "loss": 1.2594,
      "step": 27100
    },
    {
      "epoch": 43.74,
      "learning_rate": 0.0956267785667742,
      "loss": 1.2055,
      "step": 27120
    },
    {
      "epoch": 43.77,
      "learning_rate": 0.09562355276354839,
      "loss": 1.176,
      "step": 27140
    },
    {
      "epoch": 43.81,
      "learning_rate": 0.09562032696032258,
      "loss": 1.1553,
      "step": 27160
    },
    {
      "epoch": 43.84,
      "learning_rate": 0.09561710115709678,
      "loss": 1.1662,
      "step": 27180
    },
    {
      "epoch": 43.87,
      "learning_rate": 0.09561387535387098,
      "loss": 1.1846,
      "step": 27200
    },
    {
      "epoch": 43.9,
      "learning_rate": 0.09561064955064516,
      "loss": 1.1858,
      "step": 27220
    },
    {
      "epoch": 43.94,
      "learning_rate": 0.09560742374741936,
      "loss": 1.2012,
      "step": 27240
    },
    {
      "epoch": 43.97,
      "learning_rate": 0.09560419794419356,
      "loss": 1.2021,
      "step": 27260
    },
    {
      "epoch": 44.0,
      "learning_rate": 0.09560113343112903,
      "loss": 1.2118,
      "step": 27280
    },
    {
      "epoch": 44.0,
      "eval_accuracy": {
        "accuracy": 0.7225821559597221
      },
      "eval_loss": 1.4319432973861694,
      "eval_runtime": 2.9269,
      "eval_samples_per_second": 4376.981,
      "eval_steps_per_second": 68.673,
      "step": 27280
    },
    {
      "epoch": 44.03,
      "learning_rate": 0.09559790762790323,
      "loss": 1.1702,
      "step": 27300
    },
    {
      "epoch": 44.06,
      "learning_rate": 0.09559468182467742,
      "loss": 1.176,
      "step": 27320
    },
    {
      "epoch": 44.1,
      "learning_rate": 0.09559145602145161,
      "loss": 1.1692,
      "step": 27340
    },
    {
      "epoch": 44.13,
      "learning_rate": 0.09558823021822581,
      "loss": 1.1902,
      "step": 27360
    },
    {
      "epoch": 44.16,
      "learning_rate": 0.09558500441500001,
      "loss": 1.1891,
      "step": 27380
    },
    {
      "epoch": 44.19,
      "learning_rate": 0.09558177861177419,
      "loss": 1.1925,
      "step": 27400
    },
    {
      "epoch": 44.23,
      "learning_rate": 0.09557855280854839,
      "loss": 1.1625,
      "step": 27420
    },
    {
      "epoch": 44.26,
      "learning_rate": 0.09557532700532259,
      "loss": 1.1822,
      "step": 27440
    },
    {
      "epoch": 44.29,
      "learning_rate": 0.09557210120209678,
      "loss": 1.2029,
      "step": 27460
    },
    {
      "epoch": 44.32,
      "learning_rate": 0.09556887539887098,
      "loss": 1.1428,
      "step": 27480
    },
    {
      "epoch": 44.35,
      "learning_rate": 0.09556564959564517,
      "loss": 1.1876,
      "step": 27500
    },
    {
      "epoch": 44.39,
      "learning_rate": 0.09556242379241936,
      "loss": 1.1717,
      "step": 27520
    },
    {
      "epoch": 44.42,
      "learning_rate": 0.09555919798919356,
      "loss": 1.1712,
      "step": 27540
    },
    {
      "epoch": 44.45,
      "learning_rate": 0.09555597218596776,
      "loss": 1.1634,
      "step": 27560
    },
    {
      "epoch": 44.48,
      "learning_rate": 0.09555274638274194,
      "loss": 1.1471,
      "step": 27580
    },
    {
      "epoch": 44.52,
      "learning_rate": 0.09554952057951614,
      "loss": 1.1613,
      "step": 27600
    },
    {
      "epoch": 44.55,
      "learning_rate": 0.09554629477629033,
      "loss": 1.1488,
      "step": 27620
    },
    {
      "epoch": 44.58,
      "learning_rate": 0.09554306897306451,
      "loss": 1.1648,
      "step": 27640
    },
    {
      "epoch": 44.61,
      "learning_rate": 0.09553984316983871,
      "loss": 1.1536,
      "step": 27660
    },
    {
      "epoch": 44.65,
      "learning_rate": 0.09553661736661291,
      "loss": 1.1828,
      "step": 27680
    },
    {
      "epoch": 44.68,
      "learning_rate": 0.0955333915633871,
      "loss": 1.2069,
      "step": 27700
    },
    {
      "epoch": 44.71,
      "learning_rate": 0.0955301657601613,
      "loss": 1.2267,
      "step": 27720
    },
    {
      "epoch": 44.74,
      "learning_rate": 0.0955269399569355,
      "loss": 1.1977,
      "step": 27740
    },
    {
      "epoch": 44.77,
      "learning_rate": 0.09552371415370968,
      "loss": 1.2185,
      "step": 27760
    },
    {
      "epoch": 44.81,
      "learning_rate": 0.09552048835048388,
      "loss": 1.229,
      "step": 27780
    },
    {
      "epoch": 44.84,
      "learning_rate": 0.09551726254725808,
      "loss": 1.1931,
      "step": 27800
    },
    {
      "epoch": 44.87,
      "learning_rate": 0.09551403674403226,
      "loss": 1.1839,
      "step": 27820
    },
    {
      "epoch": 44.9,
      "learning_rate": 0.09551081094080646,
      "loss": 1.1624,
      "step": 27840
    },
    {
      "epoch": 44.94,
      "learning_rate": 0.09550758513758066,
      "loss": 1.1981,
      "step": 27860
    },
    {
      "epoch": 44.97,
      "learning_rate": 0.09550435933435485,
      "loss": 1.1918,
      "step": 27880
    },
    {
      "epoch": 45.0,
      "learning_rate": 0.09550113353112905,
      "loss": 1.2229,
      "step": 27900
    },
    {
      "epoch": 45.0,
      "eval_accuracy": {
        "accuracy": 0.7218015767699633
      },
      "eval_loss": 1.429758906364441,
      "eval_runtime": 3.9055,
      "eval_samples_per_second": 3280.21,
      "eval_steps_per_second": 51.465,
      "step": 27900
    },
    {
      "epoch": 45.03,
      "learning_rate": 0.09549790772790323,
      "loss": 1.2428,
      "step": 27920
    },
    {
      "epoch": 45.06,
      "learning_rate": 0.09549468192467742,
      "loss": 1.1808,
      "step": 27940
    },
    {
      "epoch": 45.1,
      "learning_rate": 0.09549145612145161,
      "loss": 1.1695,
      "step": 27960
    },
    {
      "epoch": 45.13,
      "learning_rate": 0.09548823031822581,
      "loss": 1.1643,
      "step": 27980
    },
    {
      "epoch": 45.16,
      "learning_rate": 0.095485004515,
      "loss": 1.2011,
      "step": 28000
    },
    {
      "epoch": 45.19,
      "learning_rate": 0.0954817787117742,
      "loss": 1.1623,
      "step": 28020
    },
    {
      "epoch": 45.23,
      "learning_rate": 0.0954785529085484,
      "loss": 1.1856,
      "step": 28040
    },
    {
      "epoch": 45.26,
      "learning_rate": 0.09547532710532258,
      "loss": 1.1628,
      "step": 28060
    },
    {
      "epoch": 45.29,
      "learning_rate": 0.09547210130209678,
      "loss": 1.1682,
      "step": 28080
    },
    {
      "epoch": 45.32,
      "learning_rate": 0.09546887549887098,
      "loss": 1.1701,
      "step": 28100
    },
    {
      "epoch": 45.35,
      "learning_rate": 0.09546564969564517,
      "loss": 1.1518,
      "step": 28120
    },
    {
      "epoch": 45.39,
      "learning_rate": 0.09546242389241937,
      "loss": 1.1617,
      "step": 28140
    },
    {
      "epoch": 45.42,
      "learning_rate": 0.09545919808919355,
      "loss": 1.172,
      "step": 28160
    },
    {
      "epoch": 45.45,
      "learning_rate": 0.09545597228596775,
      "loss": 1.1506,
      "step": 28180
    },
    {
      "epoch": 45.48,
      "learning_rate": 0.09545274648274195,
      "loss": 1.213,
      "step": 28200
    },
    {
      "epoch": 45.52,
      "learning_rate": 0.09544952067951613,
      "loss": 1.1768,
      "step": 28220
    },
    {
      "epoch": 45.55,
      "learning_rate": 0.09544629487629032,
      "loss": 1.1828,
      "step": 28240
    },
    {
      "epoch": 45.58,
      "learning_rate": 0.09544306907306452,
      "loss": 1.157,
      "step": 28260
    },
    {
      "epoch": 45.61,
      "learning_rate": 0.09543984326983872,
      "loss": 1.1791,
      "step": 28280
    },
    {
      "epoch": 45.65,
      "learning_rate": 0.0954366174666129,
      "loss": 1.183,
      "step": 28300
    },
    {
      "epoch": 45.68,
      "learning_rate": 0.0954333916633871,
      "loss": 1.1956,
      "step": 28320
    },
    {
      "epoch": 45.71,
      "learning_rate": 0.0954301658601613,
      "loss": 1.188,
      "step": 28340
    },
    {
      "epoch": 45.74,
      "learning_rate": 0.09542694005693549,
      "loss": 1.2046,
      "step": 28360
    },
    {
      "epoch": 45.77,
      "learning_rate": 0.09542371425370968,
      "loss": 1.1594,
      "step": 28380
    },
    {
      "epoch": 45.81,
      "learning_rate": 0.09542048845048388,
      "loss": 1.179,
      "step": 28400
    },
    {
      "epoch": 45.84,
      "learning_rate": 0.09541726264725807,
      "loss": 1.192,
      "step": 28420
    },
    {
      "epoch": 45.87,
      "learning_rate": 0.09541403684403227,
      "loss": 1.1706,
      "step": 28440
    },
    {
      "epoch": 45.9,
      "learning_rate": 0.09541081104080645,
      "loss": 1.1848,
      "step": 28460
    },
    {
      "epoch": 45.94,
      "learning_rate": 0.09540758523758065,
      "loss": 1.1543,
      "step": 28480
    },
    {
      "epoch": 45.97,
      "learning_rate": 0.09540435943435485,
      "loss": 1.1715,
      "step": 28500
    },
    {
      "epoch": 46.0,
      "learning_rate": 0.09540113363112904,
      "loss": 1.1703,
      "step": 28520
    },
    {
      "epoch": 46.0,
      "eval_accuracy": {
        "accuracy": 0.7127468581687613
      },
      "eval_loss": 1.481650948524475,
      "eval_runtime": 2.4923,
      "eval_samples_per_second": 5140.227,
      "eval_steps_per_second": 80.648,
      "step": 28520
    },
    {
      "epoch": 46.03,
      "learning_rate": 0.09539790782790324,
      "loss": 1.2236,
      "step": 28540
    },
    {
      "epoch": 46.06,
      "learning_rate": 0.09539468202467742,
      "loss": 1.2104,
      "step": 28560
    },
    {
      "epoch": 46.1,
      "learning_rate": 0.09539145622145162,
      "loss": 1.1827,
      "step": 28580
    },
    {
      "epoch": 46.13,
      "learning_rate": 0.0953882304182258,
      "loss": 1.2002,
      "step": 28600
    },
    {
      "epoch": 46.16,
      "learning_rate": 0.095385004615,
      "loss": 1.1965,
      "step": 28620
    },
    {
      "epoch": 46.19,
      "learning_rate": 0.0953817788117742,
      "loss": 1.202,
      "step": 28640
    },
    {
      "epoch": 46.23,
      "learning_rate": 0.09537855300854839,
      "loss": 1.1599,
      "step": 28660
    },
    {
      "epoch": 46.26,
      "learning_rate": 0.09537532720532259,
      "loss": 1.128,
      "step": 28680
    },
    {
      "epoch": 46.29,
      "learning_rate": 0.09537210140209677,
      "loss": 1.1822,
      "step": 28700
    },
    {
      "epoch": 46.32,
      "learning_rate": 0.09536887559887097,
      "loss": 1.1268,
      "step": 28720
    },
    {
      "epoch": 46.35,
      "learning_rate": 0.09536564979564517,
      "loss": 1.1271,
      "step": 28740
    },
    {
      "epoch": 46.39,
      "learning_rate": 0.09536242399241936,
      "loss": 1.1666,
      "step": 28760
    },
    {
      "epoch": 46.42,
      "learning_rate": 0.09535919818919356,
      "loss": 1.1508,
      "step": 28780
    },
    {
      "epoch": 46.45,
      "learning_rate": 0.09535597238596775,
      "loss": 1.141,
      "step": 28800
    },
    {
      "epoch": 46.48,
      "learning_rate": 0.09535274658274194,
      "loss": 1.1379,
      "step": 28820
    },
    {
      "epoch": 46.52,
      "learning_rate": 0.09534952077951614,
      "loss": 1.1927,
      "step": 28840
    },
    {
      "epoch": 46.55,
      "learning_rate": 0.09534629497629032,
      "loss": 1.1995,
      "step": 28860
    },
    {
      "epoch": 46.58,
      "learning_rate": 0.09534306917306452,
      "loss": 1.1631,
      "step": 28880
    },
    {
      "epoch": 46.61,
      "learning_rate": 0.09533984336983871,
      "loss": 1.1679,
      "step": 28900
    },
    {
      "epoch": 46.65,
      "learning_rate": 0.09533661756661291,
      "loss": 1.1656,
      "step": 28920
    },
    {
      "epoch": 46.68,
      "learning_rate": 0.09533339176338711,
      "loss": 1.186,
      "step": 28940
    },
    {
      "epoch": 46.71,
      "learning_rate": 0.09533016596016129,
      "loss": 1.1828,
      "step": 28960
    },
    {
      "epoch": 46.74,
      "learning_rate": 0.09532694015693549,
      "loss": 1.1971,
      "step": 28980
    },
    {
      "epoch": 46.77,
      "learning_rate": 0.09532371435370968,
      "loss": 1.1686,
      "step": 29000
    },
    {
      "epoch": 46.81,
      "learning_rate": 0.09532048855048388,
      "loss": 1.1924,
      "step": 29020
    },
    {
      "epoch": 46.84,
      "learning_rate": 0.09531726274725807,
      "loss": 1.2049,
      "step": 29040
    },
    {
      "epoch": 46.87,
      "learning_rate": 0.09531403694403226,
      "loss": 1.1743,
      "step": 29060
    },
    {
      "epoch": 46.9,
      "learning_rate": 0.09531081114080646,
      "loss": 1.2112,
      "step": 29080
    },
    {
      "epoch": 46.94,
      "learning_rate": 0.09530758533758066,
      "loss": 1.1832,
      "step": 29100
    },
    {
      "epoch": 46.97,
      "learning_rate": 0.09530435953435484,
      "loss": 1.2123,
      "step": 29120
    },
    {
      "epoch": 47.0,
      "learning_rate": 0.09530113373112904,
      "loss": 1.1672,
      "step": 29140
    },
    {
      "epoch": 47.0,
      "eval_accuracy": {
        "accuracy": 0.7272656310982749
      },
      "eval_loss": 1.373637080192566,
      "eval_runtime": 2.8566,
      "eval_samples_per_second": 4484.78,
      "eval_steps_per_second": 70.365,
      "step": 29140
    },
    {
      "epoch": 47.03,
      "learning_rate": 0.09529790792790323,
      "loss": 1.1988,
      "step": 29160
    },
    {
      "epoch": 47.06,
      "learning_rate": 0.09529468212467743,
      "loss": 1.1773,
      "step": 29180
    },
    {
      "epoch": 47.1,
      "learning_rate": 0.09529145632145161,
      "loss": 1.1487,
      "step": 29200
    },
    {
      "epoch": 47.13,
      "learning_rate": 0.09528823051822581,
      "loss": 1.1629,
      "step": 29220
    },
    {
      "epoch": 47.16,
      "learning_rate": 0.095285004715,
      "loss": 1.1493,
      "step": 29240
    },
    {
      "epoch": 47.19,
      "learning_rate": 0.0952817789117742,
      "loss": 1.1606,
      "step": 29260
    },
    {
      "epoch": 47.23,
      "learning_rate": 0.0952785531085484,
      "loss": 1.166,
      "step": 29280
    },
    {
      "epoch": 47.26,
      "learning_rate": 0.09527532730532258,
      "loss": 1.1861,
      "step": 29300
    },
    {
      "epoch": 47.29,
      "learning_rate": 0.09527226279225806,
      "loss": 1.1824,
      "step": 29320
    },
    {
      "epoch": 47.32,
      "learning_rate": 0.09526903698903226,
      "loss": 1.2063,
      "step": 29340
    },
    {
      "epoch": 47.35,
      "learning_rate": 0.09526581118580646,
      "loss": 1.1628,
      "step": 29360
    },
    {
      "epoch": 47.39,
      "learning_rate": 0.09526258538258064,
      "loss": 1.2215,
      "step": 29380
    },
    {
      "epoch": 47.42,
      "learning_rate": 0.09525935957935484,
      "loss": 1.1867,
      "step": 29400
    },
    {
      "epoch": 47.45,
      "learning_rate": 0.09525613377612904,
      "loss": 1.1825,
      "step": 29420
    },
    {
      "epoch": 47.48,
      "learning_rate": 0.09525290797290323,
      "loss": 1.1842,
      "step": 29440
    },
    {
      "epoch": 47.52,
      "learning_rate": 0.09524968216967743,
      "loss": 1.1621,
      "step": 29460
    },
    {
      "epoch": 47.55,
      "learning_rate": 0.09524645636645163,
      "loss": 1.1656,
      "step": 29480
    },
    {
      "epoch": 47.58,
      "learning_rate": 0.09524323056322581,
      "loss": 1.1792,
      "step": 29500
    },
    {
      "epoch": 47.61,
      "learning_rate": 0.09524000476000001,
      "loss": 1.178,
      "step": 29520
    },
    {
      "epoch": 47.65,
      "learning_rate": 0.0952367789567742,
      "loss": 1.1939,
      "step": 29540
    },
    {
      "epoch": 47.68,
      "learning_rate": 0.0952335531535484,
      "loss": 1.1967,
      "step": 29560
    },
    {
      "epoch": 47.71,
      "learning_rate": 0.0952303273503226,
      "loss": 1.1596,
      "step": 29580
    },
    {
      "epoch": 47.74,
      "learning_rate": 0.09522710154709678,
      "loss": 1.174,
      "step": 29600
    },
    {
      "epoch": 47.77,
      "learning_rate": 0.09522387574387096,
      "loss": 1.1729,
      "step": 29620
    },
    {
      "epoch": 47.81,
      "learning_rate": 0.09522064994064516,
      "loss": 1.1563,
      "step": 29640
    },
    {
      "epoch": 47.84,
      "learning_rate": 0.09521742413741936,
      "loss": 1.1395,
      "step": 29660
    },
    {
      "epoch": 47.87,
      "learning_rate": 0.09521419833419355,
      "loss": 1.1806,
      "step": 29680
    },
    {
      "epoch": 47.9,
      "learning_rate": 0.09521097253096775,
      "loss": 1.2022,
      "step": 29700
    },
    {
      "epoch": 47.94,
      "learning_rate": 0.09520774672774195,
      "loss": 1.2286,
      "step": 29720
    },
    {
      "epoch": 47.97,
      "learning_rate": 0.09520452092451613,
      "loss": 1.2202,
      "step": 29740
    },
    {
      "epoch": 48.0,
      "learning_rate": 0.09520129512129033,
      "loss": 1.2007,
      "step": 29760
    },
    {
      "epoch": 48.0,
      "eval_accuracy": {
        "accuracy": 0.7240652564202639
      },
      "eval_loss": 1.4274448156356812,
      "eval_runtime": 2.7897,
      "eval_samples_per_second": 4592.328,
      "eval_steps_per_second": 72.052,
      "step": 29760
    },
    {
      "epoch": 48.03,
      "learning_rate": 0.09519806931806452,
      "loss": 1.2084,
      "step": 29780
    },
    {
      "epoch": 48.06,
      "learning_rate": 0.09519484351483871,
      "loss": 1.1846,
      "step": 29800
    },
    {
      "epoch": 48.1,
      "learning_rate": 0.09519161771161291,
      "loss": 1.1184,
      "step": 29820
    },
    {
      "epoch": 48.13,
      "learning_rate": 0.0951883919083871,
      "loss": 1.1586,
      "step": 29840
    },
    {
      "epoch": 48.16,
      "learning_rate": 0.0951851661051613,
      "loss": 1.178,
      "step": 29860
    },
    {
      "epoch": 48.19,
      "learning_rate": 0.0951819403019355,
      "loss": 1.1887,
      "step": 29880
    },
    {
      "epoch": 48.23,
      "learning_rate": 0.09517871449870968,
      "loss": 1.1798,
      "step": 29900
    },
    {
      "epoch": 48.26,
      "learning_rate": 0.09517548869548388,
      "loss": 1.1248,
      "step": 29920
    },
    {
      "epoch": 48.29,
      "learning_rate": 0.09517226289225807,
      "loss": 1.1361,
      "step": 29940
    },
    {
      "epoch": 48.32,
      "learning_rate": 0.09516903708903227,
      "loss": 1.159,
      "step": 29960
    },
    {
      "epoch": 48.35,
      "learning_rate": 0.09516581128580645,
      "loss": 1.1713,
      "step": 29980
    },
    {
      "epoch": 48.39,
      "learning_rate": 0.09516258548258065,
      "loss": 1.1613,
      "step": 30000
    },
    {
      "epoch": 48.42,
      "learning_rate": 0.09515935967935485,
      "loss": 1.1899,
      "step": 30020
    },
    {
      "epoch": 48.45,
      "learning_rate": 0.09515613387612903,
      "loss": 1.1886,
      "step": 30040
    },
    {
      "epoch": 48.48,
      "learning_rate": 0.09515290807290323,
      "loss": 1.1525,
      "step": 30060
    },
    {
      "epoch": 48.52,
      "learning_rate": 0.09514968226967742,
      "loss": 1.1715,
      "step": 30080
    },
    {
      "epoch": 48.55,
      "learning_rate": 0.09514645646645162,
      "loss": 1.1759,
      "step": 30100
    },
    {
      "epoch": 48.58,
      "learning_rate": 0.09514323066322582,
      "loss": 1.1896,
      "step": 30120
    },
    {
      "epoch": 48.61,
      "learning_rate": 0.09514000486,
      "loss": 1.1507,
      "step": 30140
    },
    {
      "epoch": 48.65,
      "learning_rate": 0.0951367790567742,
      "loss": 1.2017,
      "step": 30160
    },
    {
      "epoch": 48.68,
      "learning_rate": 0.0951335532535484,
      "loss": 1.1628,
      "step": 30180
    },
    {
      "epoch": 48.71,
      "learning_rate": 0.09513032745032259,
      "loss": 1.1743,
      "step": 30200
    },
    {
      "epoch": 48.74,
      "learning_rate": 0.09512710164709678,
      "loss": 1.1996,
      "step": 30220
    },
    {
      "epoch": 48.77,
      "learning_rate": 0.09512387584387097,
      "loss": 1.2093,
      "step": 30240
    },
    {
      "epoch": 48.81,
      "learning_rate": 0.09512065004064517,
      "loss": 1.1874,
      "step": 30260
    },
    {
      "epoch": 48.84,
      "learning_rate": 0.09511742423741935,
      "loss": 1.1672,
      "step": 30280
    },
    {
      "epoch": 48.87,
      "learning_rate": 0.09511419843419355,
      "loss": 1.1843,
      "step": 30300
    },
    {
      "epoch": 48.9,
      "learning_rate": 0.09511097263096774,
      "loss": 1.1851,
      "step": 30320
    },
    {
      "epoch": 48.94,
      "learning_rate": 0.09510774682774194,
      "loss": 1.1769,
      "step": 30340
    },
    {
      "epoch": 48.97,
      "learning_rate": 0.09510452102451614,
      "loss": 1.1589,
      "step": 30360
    },
    {
      "epoch": 49.0,
      "learning_rate": 0.09510129522129032,
      "loss": 1.214,
      "step": 30380
    },
    {
      "epoch": 49.0,
      "eval_accuracy": {
        "accuracy": 0.711575989384123
      },
      "eval_loss": 1.498718500137329,
      "eval_runtime": 2.6041,
      "eval_samples_per_second": 4919.517,
      "eval_steps_per_second": 77.185,
      "step": 30380
    },
    {
      "epoch": 49.03,
      "learning_rate": 0.09509806941806452,
      "loss": 1.248,
      "step": 30400
    },
    {
      "epoch": 49.06,
      "learning_rate": 0.09509484361483872,
      "loss": 1.1806,
      "step": 30420
    },
    {
      "epoch": 49.1,
      "learning_rate": 0.0950916178116129,
      "loss": 1.1643,
      "step": 30440
    },
    {
      "epoch": 49.13,
      "learning_rate": 0.0950883920083871,
      "loss": 1.1597,
      "step": 30460
    },
    {
      "epoch": 49.16,
      "learning_rate": 0.0950851662051613,
      "loss": 1.1751,
      "step": 30480
    },
    {
      "epoch": 49.19,
      "learning_rate": 0.09508194040193549,
      "loss": 1.2042,
      "step": 30500
    },
    {
      "epoch": 49.23,
      "learning_rate": 0.09507871459870969,
      "loss": 1.2081,
      "step": 30520
    },
    {
      "epoch": 49.26,
      "learning_rate": 0.09507548879548387,
      "loss": 1.1703,
      "step": 30540
    },
    {
      "epoch": 49.29,
      "learning_rate": 0.09507226299225807,
      "loss": 1.1742,
      "step": 30560
    },
    {
      "epoch": 49.32,
      "learning_rate": 0.09506903718903226,
      "loss": 1.1389,
      "step": 30580
    },
    {
      "epoch": 49.35,
      "learning_rate": 0.09506581138580646,
      "loss": 1.1362,
      "step": 30600
    },
    {
      "epoch": 49.39,
      "learning_rate": 0.09506258558258064,
      "loss": 1.1665,
      "step": 30620
    },
    {
      "epoch": 49.42,
      "learning_rate": 0.09505935977935484,
      "loss": 1.1698,
      "step": 30640
    },
    {
      "epoch": 49.45,
      "learning_rate": 0.09505613397612904,
      "loss": 1.1917,
      "step": 30660
    },
    {
      "epoch": 49.48,
      "learning_rate": 0.09505290817290322,
      "loss": 1.1475,
      "step": 30680
    },
    {
      "epoch": 49.52,
      "learning_rate": 0.09504968236967742,
      "loss": 1.1807,
      "step": 30700
    },
    {
      "epoch": 49.55,
      "learning_rate": 0.09504645656645162,
      "loss": 1.1925,
      "step": 30720
    },
    {
      "epoch": 49.58,
      "learning_rate": 0.09504323076322581,
      "loss": 1.1703,
      "step": 30740
    },
    {
      "epoch": 49.61,
      "learning_rate": 0.09504000496000001,
      "loss": 1.1903,
      "step": 30760
    },
    {
      "epoch": 49.65,
      "learning_rate": 0.0950367791567742,
      "loss": 1.2089,
      "step": 30780
    },
    {
      "epoch": 49.68,
      "learning_rate": 0.09503355335354839,
      "loss": 1.1989,
      "step": 30800
    },
    {
      "epoch": 49.71,
      "learning_rate": 0.09503032755032259,
      "loss": 1.2105,
      "step": 30820
    },
    {
      "epoch": 49.74,
      "learning_rate": 0.09502710174709679,
      "loss": 1.1982,
      "step": 30840
    },
    {
      "epoch": 49.77,
      "learning_rate": 0.09502387594387098,
      "loss": 1.176,
      "step": 30860
    },
    {
      "epoch": 49.81,
      "learning_rate": 0.09502065014064516,
      "loss": 1.1363,
      "step": 30880
    },
    {
      "epoch": 49.84,
      "learning_rate": 0.09501742433741936,
      "loss": 1.1797,
      "step": 30900
    },
    {
      "epoch": 49.87,
      "learning_rate": 0.09501419853419354,
      "loss": 1.2229,
      "step": 30920
    },
    {
      "epoch": 49.9,
      "learning_rate": 0.09501097273096774,
      "loss": 1.1765,
      "step": 30940
    },
    {
      "epoch": 49.94,
      "learning_rate": 0.09500774692774194,
      "loss": 1.1478,
      "step": 30960
    },
    {
      "epoch": 49.97,
      "learning_rate": 0.09500452112451613,
      "loss": 1.1797,
      "step": 30980
    },
    {
      "epoch": 50.0,
      "learning_rate": 0.09500129532129033,
      "loss": 1.1973,
      "step": 31000
    },
    {
      "epoch": 50.0,
      "eval_accuracy": {
        "accuracy": 0.7192256654437593
      },
      "eval_loss": 1.4576855897903442,
      "eval_runtime": 2.7529,
      "eval_samples_per_second": 4653.615,
      "eval_steps_per_second": 73.014,
      "step": 31000
    },
    {
      "epoch": 50.03,
      "learning_rate": 0.09499806951806453,
      "loss": 1.2279,
      "step": 31020
    },
    {
      "epoch": 50.06,
      "learning_rate": 0.09499484371483871,
      "loss": 1.1706,
      "step": 31040
    },
    {
      "epoch": 50.1,
      "learning_rate": 0.09499161791161291,
      "loss": 1.1446,
      "step": 31060
    },
    {
      "epoch": 50.13,
      "learning_rate": 0.09498839210838711,
      "loss": 1.1274,
      "step": 31080
    },
    {
      "epoch": 50.16,
      "learning_rate": 0.0949851663051613,
      "loss": 1.1698,
      "step": 31100
    },
    {
      "epoch": 50.19,
      "learning_rate": 0.0949819405019355,
      "loss": 1.1858,
      "step": 31120
    },
    {
      "epoch": 50.23,
      "learning_rate": 0.0949787146987097,
      "loss": 1.1652,
      "step": 31140
    },
    {
      "epoch": 50.26,
      "learning_rate": 0.09497548889548388,
      "loss": 1.1695,
      "step": 31160
    },
    {
      "epoch": 50.29,
      "learning_rate": 0.09497226309225806,
      "loss": 1.1669,
      "step": 31180
    },
    {
      "epoch": 50.32,
      "learning_rate": 0.09496903728903226,
      "loss": 1.1653,
      "step": 31200
    },
    {
      "epoch": 50.35,
      "learning_rate": 0.09496581148580645,
      "loss": 1.1619,
      "step": 31220
    },
    {
      "epoch": 50.39,
      "learning_rate": 0.09496258568258065,
      "loss": 1.1558,
      "step": 31240
    },
    {
      "epoch": 50.42,
      "learning_rate": 0.09495935987935485,
      "loss": 1.1553,
      "step": 31260
    },
    {
      "epoch": 50.45,
      "learning_rate": 0.09495613407612903,
      "loss": 1.1786,
      "step": 31280
    },
    {
      "epoch": 50.48,
      "learning_rate": 0.09495290827290323,
      "loss": 1.1864,
      "step": 31300
    },
    {
      "epoch": 50.52,
      "learning_rate": 0.09494968246967743,
      "loss": 1.1721,
      "step": 31320
    },
    {
      "epoch": 50.55,
      "learning_rate": 0.09494645666645161,
      "loss": 1.1391,
      "step": 31340
    },
    {
      "epoch": 50.58,
      "learning_rate": 0.09494323086322581,
      "loss": 1.1609,
      "step": 31360
    },
    {
      "epoch": 50.61,
      "learning_rate": 0.09494000506000001,
      "loss": 1.1846,
      "step": 31380
    },
    {
      "epoch": 50.65,
      "learning_rate": 0.0949367792567742,
      "loss": 1.1886,
      "step": 31400
    },
    {
      "epoch": 50.68,
      "learning_rate": 0.0949335534535484,
      "loss": 1.152,
      "step": 31420
    },
    {
      "epoch": 50.71,
      "learning_rate": 0.0949303276503226,
      "loss": 1.1601,
      "step": 31440
    },
    {
      "epoch": 50.74,
      "learning_rate": 0.09492710184709678,
      "loss": 1.1749,
      "step": 31460
    },
    {
      "epoch": 50.77,
      "learning_rate": 0.09492387604387097,
      "loss": 1.2251,
      "step": 31480
    },
    {
      "epoch": 50.81,
      "learning_rate": 0.09492065024064517,
      "loss": 1.2032,
      "step": 31500
    },
    {
      "epoch": 50.84,
      "learning_rate": 0.09491742443741935,
      "loss": 1.1974,
      "step": 31520
    },
    {
      "epoch": 50.87,
      "learning_rate": 0.09491419863419355,
      "loss": 1.201,
      "step": 31540
    },
    {
      "epoch": 50.9,
      "learning_rate": 0.09491097283096775,
      "loss": 1.1857,
      "step": 31560
    },
    {
      "epoch": 50.94,
      "learning_rate": 0.09490774702774193,
      "loss": 1.2001,
      "step": 31580
    },
    {
      "epoch": 50.97,
      "learning_rate": 0.09490452122451613,
      "loss": 1.1698,
      "step": 31600
    },
    {
      "epoch": 51.0,
      "learning_rate": 0.09490145671145161,
      "loss": 1.1919,
      "step": 31620
    },
    {
      "epoch": 51.0,
      "eval_accuracy": {
        "accuracy": 0.7238310826633362
      },
      "eval_loss": 1.4454004764556885,
      "eval_runtime": 2.5419,
      "eval_samples_per_second": 5039.961,
      "eval_steps_per_second": 79.075,
      "step": 31620
    },
    {
      "epoch": 51.03,
      "learning_rate": 0.09489823090822581,
      "loss": 1.1643,
      "step": 31640
    },
    {
      "epoch": 51.06,
      "learning_rate": 0.094895005105,
      "loss": 1.1466,
      "step": 31660
    },
    {
      "epoch": 51.1,
      "learning_rate": 0.0948917793017742,
      "loss": 1.1272,
      "step": 31680
    },
    {
      "epoch": 51.13,
      "learning_rate": 0.09488855349854838,
      "loss": 1.1404,
      "step": 31700
    },
    {
      "epoch": 51.16,
      "learning_rate": 0.09488532769532258,
      "loss": 1.1482,
      "step": 31720
    },
    {
      "epoch": 51.19,
      "learning_rate": 0.09488210189209678,
      "loss": 1.1419,
      "step": 31740
    },
    {
      "epoch": 51.23,
      "learning_rate": 0.09487887608887097,
      "loss": 1.16,
      "step": 31760
    },
    {
      "epoch": 51.26,
      "learning_rate": 0.09487565028564517,
      "loss": 1.1532,
      "step": 31780
    },
    {
      "epoch": 51.29,
      "learning_rate": 0.09487242448241937,
      "loss": 1.1689,
      "step": 31800
    },
    {
      "epoch": 51.32,
      "learning_rate": 0.09486919867919355,
      "loss": 1.1755,
      "step": 31820
    },
    {
      "epoch": 51.35,
      "learning_rate": 0.09486597287596775,
      "loss": 1.1815,
      "step": 31840
    },
    {
      "epoch": 51.39,
      "learning_rate": 0.09486274707274195,
      "loss": 1.133,
      "step": 31860
    },
    {
      "epoch": 51.42,
      "learning_rate": 0.09485952126951613,
      "loss": 1.1344,
      "step": 31880
    },
    {
      "epoch": 51.45,
      "learning_rate": 0.09485629546629033,
      "loss": 1.1778,
      "step": 31900
    },
    {
      "epoch": 51.48,
      "learning_rate": 0.09485306966306452,
      "loss": 1.1747,
      "step": 31920
    },
    {
      "epoch": 51.52,
      "learning_rate": 0.0948498438598387,
      "loss": 1.1423,
      "step": 31940
    },
    {
      "epoch": 51.55,
      "learning_rate": 0.0948466180566129,
      "loss": 1.1455,
      "step": 31960
    },
    {
      "epoch": 51.58,
      "learning_rate": 0.0948433922533871,
      "loss": 1.1437,
      "step": 31980
    },
    {
      "epoch": 51.61,
      "learning_rate": 0.09484016645016129,
      "loss": 1.1349,
      "step": 32000
    },
    {
      "epoch": 51.65,
      "learning_rate": 0.09483694064693549,
      "loss": 1.1755,
      "step": 32020
    },
    {
      "epoch": 51.68,
      "learning_rate": 0.09483371484370968,
      "loss": 1.1823,
      "step": 32040
    },
    {
      "epoch": 51.71,
      "learning_rate": 0.09483048904048387,
      "loss": 1.1689,
      "step": 32060
    },
    {
      "epoch": 51.74,
      "learning_rate": 0.09482726323725807,
      "loss": 1.1664,
      "step": 32080
    },
    {
      "epoch": 51.77,
      "learning_rate": 0.09482403743403227,
      "loss": 1.1727,
      "step": 32100
    },
    {
      "epoch": 51.81,
      "learning_rate": 0.09482081163080645,
      "loss": 1.2189,
      "step": 32120
    },
    {
      "epoch": 51.84,
      "learning_rate": 0.09481758582758065,
      "loss": 1.1886,
      "step": 32140
    },
    {
      "epoch": 51.87,
      "learning_rate": 0.09481436002435485,
      "loss": 1.1655,
      "step": 32160
    },
    {
      "epoch": 51.9,
      "learning_rate": 0.09481113422112904,
      "loss": 1.1577,
      "step": 32180
    },
    {
      "epoch": 51.94,
      "learning_rate": 0.09480790841790324,
      "loss": 1.1692,
      "step": 32200
    },
    {
      "epoch": 51.97,
      "learning_rate": 0.09480468261467744,
      "loss": 1.1908,
      "step": 32220
    },
    {
      "epoch": 52.0,
      "learning_rate": 0.09480145681145162,
      "loss": 1.2077,
      "step": 32240
    },
    {
      "epoch": 52.0,
      "eval_accuracy": {
        "accuracy": 0.7202404183904457
      },
      "eval_loss": 1.488730549812317,
      "eval_runtime": 3.237,
      "eval_samples_per_second": 3957.684,
      "eval_steps_per_second": 62.095,
      "step": 32240
    },
    {
      "epoch": 52.03,
      "learning_rate": 0.0947982310082258,
      "loss": 1.2439,
      "step": 32260
    },
    {
      "epoch": 52.06,
      "learning_rate": 0.094795005205,
      "loss": 1.215,
      "step": 32280
    },
    {
      "epoch": 52.1,
      "learning_rate": 0.09479177940177419,
      "loss": 1.1274,
      "step": 32300
    },
    {
      "epoch": 52.13,
      "learning_rate": 0.09478855359854839,
      "loss": 1.1555,
      "step": 32320
    },
    {
      "epoch": 52.16,
      "learning_rate": 0.09478532779532259,
      "loss": 1.169,
      "step": 32340
    },
    {
      "epoch": 52.19,
      "learning_rate": 0.09478210199209677,
      "loss": 1.1498,
      "step": 32360
    },
    {
      "epoch": 52.23,
      "learning_rate": 0.09477887618887097,
      "loss": 1.1462,
      "step": 32380
    },
    {
      "epoch": 52.26,
      "learning_rate": 0.09477565038564517,
      "loss": 1.1628,
      "step": 32400
    },
    {
      "epoch": 52.29,
      "learning_rate": 0.09477242458241936,
      "loss": 1.1558,
      "step": 32420
    },
    {
      "epoch": 52.32,
      "learning_rate": 0.09476919877919356,
      "loss": 1.1372,
      "step": 32440
    },
    {
      "epoch": 52.35,
      "learning_rate": 0.09476597297596775,
      "loss": 1.1984,
      "step": 32460
    },
    {
      "epoch": 52.39,
      "learning_rate": 0.09476274717274194,
      "loss": 1.1649,
      "step": 32480
    },
    {
      "epoch": 52.42,
      "learning_rate": 0.09475952136951614,
      "loss": 1.1347,
      "step": 32500
    },
    {
      "epoch": 52.45,
      "learning_rate": 0.09475629556629034,
      "loss": 1.1896,
      "step": 32520
    },
    {
      "epoch": 52.48,
      "learning_rate": 0.09475306976306452,
      "loss": 1.1745,
      "step": 32540
    },
    {
      "epoch": 52.52,
      "learning_rate": 0.09474984395983871,
      "loss": 1.1402,
      "step": 32560
    },
    {
      "epoch": 52.55,
      "learning_rate": 0.09474661815661291,
      "loss": 1.1795,
      "step": 32580
    },
    {
      "epoch": 52.58,
      "learning_rate": 0.0947433923533871,
      "loss": 1.1436,
      "step": 32600
    },
    {
      "epoch": 52.61,
      "learning_rate": 0.09474016655016129,
      "loss": 1.1569,
      "step": 32620
    },
    {
      "epoch": 52.65,
      "learning_rate": 0.09473694074693549,
      "loss": 1.1165,
      "step": 32640
    },
    {
      "epoch": 52.68,
      "learning_rate": 0.09473371494370968,
      "loss": 1.1572,
      "step": 32660
    },
    {
      "epoch": 52.71,
      "learning_rate": 0.09473048914048388,
      "loss": 1.1908,
      "step": 32680
    },
    {
      "epoch": 52.74,
      "learning_rate": 0.09472726333725807,
      "loss": 1.2018,
      "step": 32700
    },
    {
      "epoch": 52.77,
      "learning_rate": 0.09472403753403226,
      "loss": 1.1769,
      "step": 32720
    },
    {
      "epoch": 52.81,
      "learning_rate": 0.09472081173080646,
      "loss": 1.1974,
      "step": 32740
    },
    {
      "epoch": 52.84,
      "learning_rate": 0.09471758592758066,
      "loss": 1.1501,
      "step": 32760
    },
    {
      "epoch": 52.87,
      "learning_rate": 0.09471436012435484,
      "loss": 1.1526,
      "step": 32780
    },
    {
      "epoch": 52.9,
      "learning_rate": 0.09471113432112904,
      "loss": 1.2038,
      "step": 32800
    },
    {
      "epoch": 52.94,
      "learning_rate": 0.09470790851790324,
      "loss": 1.1857,
      "step": 32820
    },
    {
      "epoch": 52.97,
      "learning_rate": 0.09470468271467743,
      "loss": 1.1729,
      "step": 32840
    },
    {
      "epoch": 53.0,
      "learning_rate": 0.09470145691145161,
      "loss": 1.1654,
      "step": 32860
    },
    {
      "epoch": 53.0,
      "eval_accuracy": {
        "accuracy": 0.7129810319256888
      },
      "eval_loss": 1.4504578113555908,
      "eval_runtime": 2.6506,
      "eval_samples_per_second": 4833.213,
      "eval_steps_per_second": 75.831,
      "step": 32860
    },
    {
      "epoch": 53.03,
      "learning_rate": 0.09469823110822581,
      "loss": 1.1847,
      "step": 32880
    },
    {
      "epoch": 53.06,
      "learning_rate": 0.094695005305,
      "loss": 1.1799,
      "step": 32900
    },
    {
      "epoch": 53.1,
      "learning_rate": 0.0946917795017742,
      "loss": 1.1341,
      "step": 32920
    },
    {
      "epoch": 53.13,
      "learning_rate": 0.0946885536985484,
      "loss": 1.1256,
      "step": 32940
    },
    {
      "epoch": 53.16,
      "learning_rate": 0.09468532789532258,
      "loss": 1.14,
      "step": 32960
    },
    {
      "epoch": 53.19,
      "learning_rate": 0.09468210209209678,
      "loss": 1.136,
      "step": 32980
    },
    {
      "epoch": 53.23,
      "learning_rate": 0.09467887628887098,
      "loss": 1.1571,
      "step": 33000
    },
    {
      "epoch": 53.26,
      "learning_rate": 0.09467565048564516,
      "loss": 1.1211,
      "step": 33020
    },
    {
      "epoch": 53.29,
      "learning_rate": 0.09467242468241936,
      "loss": 1.1223,
      "step": 33040
    },
    {
      "epoch": 53.32,
      "learning_rate": 0.09466919887919356,
      "loss": 1.1324,
      "step": 33060
    },
    {
      "epoch": 53.35,
      "learning_rate": 0.09466597307596775,
      "loss": 1.1703,
      "step": 33080
    },
    {
      "epoch": 53.39,
      "learning_rate": 0.09466274727274195,
      "loss": 1.1738,
      "step": 33100
    },
    {
      "epoch": 53.42,
      "learning_rate": 0.09465952146951614,
      "loss": 1.1647,
      "step": 33120
    },
    {
      "epoch": 53.45,
      "learning_rate": 0.09465629566629033,
      "loss": 1.1778,
      "step": 33140
    },
    {
      "epoch": 53.48,
      "learning_rate": 0.09465306986306453,
      "loss": 1.1782,
      "step": 33160
    },
    {
      "epoch": 53.52,
      "learning_rate": 0.09464984405983871,
      "loss": 1.1611,
      "step": 33180
    },
    {
      "epoch": 53.55,
      "learning_rate": 0.0946466182566129,
      "loss": 1.1685,
      "step": 33200
    },
    {
      "epoch": 53.58,
      "learning_rate": 0.0946433924533871,
      "loss": 1.1463,
      "step": 33220
    },
    {
      "epoch": 53.61,
      "learning_rate": 0.0946401666501613,
      "loss": 1.1746,
      "step": 33240
    },
    {
      "epoch": 53.65,
      "learning_rate": 0.09463694084693548,
      "loss": 1.2051,
      "step": 33260
    },
    {
      "epoch": 53.68,
      "learning_rate": 0.09463371504370968,
      "loss": 1.1375,
      "step": 33280
    },
    {
      "epoch": 53.71,
      "learning_rate": 0.09463048924048388,
      "loss": 1.1546,
      "step": 33300
    },
    {
      "epoch": 53.74,
      "learning_rate": 0.09462726343725807,
      "loss": 1.1737,
      "step": 33320
    },
    {
      "epoch": 53.77,
      "learning_rate": 0.09462403763403227,
      "loss": 1.1285,
      "step": 33340
    },
    {
      "epoch": 53.81,
      "learning_rate": 0.09462081183080646,
      "loss": 1.1545,
      "step": 33360
    },
    {
      "epoch": 53.84,
      "learning_rate": 0.09461758602758065,
      "loss": 1.1606,
      "step": 33380
    },
    {
      "epoch": 53.87,
      "learning_rate": 0.09461436022435485,
      "loss": 1.181,
      "step": 33400
    },
    {
      "epoch": 53.9,
      "learning_rate": 0.09461113442112905,
      "loss": 1.1416,
      "step": 33420
    },
    {
      "epoch": 53.94,
      "learning_rate": 0.09460790861790323,
      "loss": 1.1905,
      "step": 33440
    },
    {
      "epoch": 53.97,
      "learning_rate": 0.09460468281467743,
      "loss": 1.2116,
      "step": 33460
    },
    {
      "epoch": 54.0,
      "learning_rate": 0.09460145701145162,
      "loss": 1.1421,
      "step": 33480
    },
    {
      "epoch": 54.0,
      "eval_accuracy": {
        "accuracy": 0.7295293107485754
      },
      "eval_loss": 1.4135273694992065,
      "eval_runtime": 2.9244,
      "eval_samples_per_second": 4380.749,
      "eval_steps_per_second": 68.732,
      "step": 33480
    },
    {
      "epoch": 54.03,
      "learning_rate": 0.0945982312082258,
      "loss": 1.1832,
      "step": 33500
    },
    {
      "epoch": 54.06,
      "learning_rate": 0.094595005405,
      "loss": 1.1877,
      "step": 33520
    },
    {
      "epoch": 54.1,
      "learning_rate": 0.0945917796017742,
      "loss": 1.136,
      "step": 33540
    },
    {
      "epoch": 54.13,
      "learning_rate": 0.09458855379854839,
      "loss": 1.1169,
      "step": 33560
    },
    {
      "epoch": 54.16,
      "learning_rate": 0.09458532799532259,
      "loss": 1.1012,
      "step": 33580
    },
    {
      "epoch": 54.19,
      "learning_rate": 0.09458210219209678,
      "loss": 1.1655,
      "step": 33600
    },
    {
      "epoch": 54.23,
      "learning_rate": 0.09457887638887097,
      "loss": 1.1527,
      "step": 33620
    },
    {
      "epoch": 54.26,
      "learning_rate": 0.09457565058564517,
      "loss": 1.1361,
      "step": 33640
    },
    {
      "epoch": 54.29,
      "learning_rate": 0.09457242478241937,
      "loss": 1.171,
      "step": 33660
    },
    {
      "epoch": 54.32,
      "learning_rate": 0.09456919897919355,
      "loss": 1.1571,
      "step": 33680
    },
    {
      "epoch": 54.35,
      "learning_rate": 0.09456597317596775,
      "loss": 1.1757,
      "step": 33700
    },
    {
      "epoch": 54.39,
      "learning_rate": 0.09456274737274194,
      "loss": 1.1612,
      "step": 33720
    },
    {
      "epoch": 54.42,
      "learning_rate": 0.09455952156951614,
      "loss": 1.1242,
      "step": 33740
    },
    {
      "epoch": 54.45,
      "learning_rate": 0.09455629576629034,
      "loss": 1.1375,
      "step": 33760
    },
    {
      "epoch": 54.48,
      "learning_rate": 0.09455306996306452,
      "loss": 1.1622,
      "step": 33780
    },
    {
      "epoch": 54.52,
      "learning_rate": 0.0945498441598387,
      "loss": 1.1409,
      "step": 33800
    },
    {
      "epoch": 54.55,
      "learning_rate": 0.0945466183566129,
      "loss": 1.128,
      "step": 33820
    },
    {
      "epoch": 54.58,
      "learning_rate": 0.0945433925533871,
      "loss": 1.1271,
      "step": 33840
    },
    {
      "epoch": 54.61,
      "learning_rate": 0.09454016675016129,
      "loss": 1.1359,
      "step": 33860
    },
    {
      "epoch": 54.65,
      "learning_rate": 0.09453710223709678,
      "loss": 1.1532,
      "step": 33880
    },
    {
      "epoch": 54.68,
      "learning_rate": 0.09453387643387098,
      "loss": 1.1531,
      "step": 33900
    },
    {
      "epoch": 54.71,
      "learning_rate": 0.09453065063064517,
      "loss": 1.1747,
      "step": 33920
    },
    {
      "epoch": 54.74,
      "learning_rate": 0.09452742482741935,
      "loss": 1.1125,
      "step": 33940
    },
    {
      "epoch": 54.77,
      "learning_rate": 0.09452419902419355,
      "loss": 1.1141,
      "step": 33960
    },
    {
      "epoch": 54.81,
      "learning_rate": 0.09452097322096774,
      "loss": 1.1607,
      "step": 33980
    },
    {
      "epoch": 54.84,
      "learning_rate": 0.09451774741774194,
      "loss": 1.1475,
      "step": 34000
    },
    {
      "epoch": 54.87,
      "learning_rate": 0.09451452161451614,
      "loss": 1.1657,
      "step": 34020
    },
    {
      "epoch": 54.9,
      "learning_rate": 0.09451129581129032,
      "loss": 1.1796,
      "step": 34040
    },
    {
      "epoch": 54.94,
      "learning_rate": 0.09450807000806452,
      "loss": 1.1702,
      "step": 34060
    },
    {
      "epoch": 54.97,
      "learning_rate": 0.09450484420483872,
      "loss": 1.22,
      "step": 34080
    },
    {
      "epoch": 55.0,
      "learning_rate": 0.0945016184016129,
      "loss": 1.1639,
      "step": 34100
    },
    {
      "epoch": 55.0,
      "eval_accuracy": {
        "accuracy": 0.7281242682070096
      },
      "eval_loss": 1.3807390928268433,
      "eval_runtime": 2.5557,
      "eval_samples_per_second": 5012.746,
      "eval_steps_per_second": 78.648,
      "step": 34100
    },
    {
      "epoch": 55.03,
      "learning_rate": 0.0944983925983871,
      "loss": 1.173,
      "step": 34120
    },
    {
      "epoch": 55.06,
      "learning_rate": 0.0944951667951613,
      "loss": 1.1079,
      "step": 34140
    },
    {
      "epoch": 55.1,
      "learning_rate": 0.09449194099193549,
      "loss": 1.1151,
      "step": 34160
    },
    {
      "epoch": 55.13,
      "learning_rate": 0.09448871518870969,
      "loss": 1.1425,
      "step": 34180
    },
    {
      "epoch": 55.16,
      "learning_rate": 0.09448548938548389,
      "loss": 1.1704,
      "step": 34200
    },
    {
      "epoch": 55.19,
      "learning_rate": 0.09448226358225807,
      "loss": 1.1649,
      "step": 34220
    },
    {
      "epoch": 55.23,
      "learning_rate": 0.09447903777903226,
      "loss": 1.1392,
      "step": 34240
    },
    {
      "epoch": 55.26,
      "learning_rate": 0.09447581197580646,
      "loss": 1.1832,
      "step": 34260
    },
    {
      "epoch": 55.29,
      "learning_rate": 0.09447258617258064,
      "loss": 1.1271,
      "step": 34280
    },
    {
      "epoch": 55.32,
      "learning_rate": 0.09446936036935484,
      "loss": 1.1664,
      "step": 34300
    },
    {
      "epoch": 55.35,
      "learning_rate": 0.09446613456612904,
      "loss": 1.1637,
      "step": 34320
    },
    {
      "epoch": 55.39,
      "learning_rate": 0.09446290876290322,
      "loss": 1.1481,
      "step": 34340
    },
    {
      "epoch": 55.42,
      "learning_rate": 0.09445968295967742,
      "loss": 1.1677,
      "step": 34360
    },
    {
      "epoch": 55.45,
      "learning_rate": 0.09445645715645162,
      "loss": 1.1347,
      "step": 34380
    },
    {
      "epoch": 55.48,
      "learning_rate": 0.09445323135322581,
      "loss": 1.1534,
      "step": 34400
    },
    {
      "epoch": 55.52,
      "learning_rate": 0.09445000555000001,
      "loss": 1.192,
      "step": 34420
    },
    {
      "epoch": 55.55,
      "learning_rate": 0.0944467797467742,
      "loss": 1.1956,
      "step": 34440
    },
    {
      "epoch": 55.58,
      "learning_rate": 0.09444355394354839,
      "loss": 1.1676,
      "step": 34460
    },
    {
      "epoch": 55.61,
      "learning_rate": 0.09444032814032259,
      "loss": 1.1661,
      "step": 34480
    },
    {
      "epoch": 55.65,
      "learning_rate": 0.09443710233709679,
      "loss": 1.1504,
      "step": 34500
    },
    {
      "epoch": 55.68,
      "learning_rate": 0.09443387653387098,
      "loss": 1.1767,
      "step": 34520
    },
    {
      "epoch": 55.71,
      "learning_rate": 0.09443065073064517,
      "loss": 1.1739,
      "step": 34540
    },
    {
      "epoch": 55.74,
      "learning_rate": 0.09442742492741936,
      "loss": 1.1354,
      "step": 34560
    },
    {
      "epoch": 55.77,
      "learning_rate": 0.09442419912419354,
      "loss": 1.1559,
      "step": 34580
    },
    {
      "epoch": 55.81,
      "learning_rate": 0.09442097332096774,
      "loss": 1.1622,
      "step": 34600
    },
    {
      "epoch": 55.84,
      "learning_rate": 0.09441774751774194,
      "loss": 1.1511,
      "step": 34620
    },
    {
      "epoch": 55.87,
      "learning_rate": 0.09441452171451613,
      "loss": 1.1808,
      "step": 34640
    },
    {
      "epoch": 55.9,
      "learning_rate": 0.09441129591129033,
      "loss": 1.1759,
      "step": 34660
    },
    {
      "epoch": 55.94,
      "learning_rate": 0.09440807010806453,
      "loss": 1.1759,
      "step": 34680
    },
    {
      "epoch": 55.97,
      "learning_rate": 0.09440484430483871,
      "loss": 1.1542,
      "step": 34700
    },
    {
      "epoch": 56.0,
      "learning_rate": 0.09440161850161291,
      "loss": 1.174,
      "step": 34720
    },
    {
      "epoch": 56.0,
      "eval_accuracy": {
        "accuracy": 0.7150885957380376
      },
      "eval_loss": 1.5283948183059692,
      "eval_runtime": 2.9313,
      "eval_samples_per_second": 4370.392,
      "eval_steps_per_second": 68.57,
      "step": 34720
    },
    {
      "epoch": 56.03,
      "learning_rate": 0.09439839269838711,
      "loss": 1.2595,
      "step": 34740
    },
    {
      "epoch": 56.06,
      "learning_rate": 0.0943951668951613,
      "loss": 1.1724,
      "step": 34760
    },
    {
      "epoch": 56.1,
      "learning_rate": 0.0943919410919355,
      "loss": 1.1372,
      "step": 34780
    },
    {
      "epoch": 56.13,
      "learning_rate": 0.09438871528870968,
      "loss": 1.1455,
      "step": 34800
    },
    {
      "epoch": 56.16,
      "learning_rate": 0.09438548948548388,
      "loss": 1.1639,
      "step": 34820
    },
    {
      "epoch": 56.19,
      "learning_rate": 0.09438226368225808,
      "loss": 1.1677,
      "step": 34840
    },
    {
      "epoch": 56.23,
      "learning_rate": 0.09437903787903226,
      "loss": 1.1503,
      "step": 34860
    },
    {
      "epoch": 56.26,
      "learning_rate": 0.09437581207580645,
      "loss": 1.128,
      "step": 34880
    },
    {
      "epoch": 56.29,
      "learning_rate": 0.09437258627258065,
      "loss": 1.1556,
      "step": 34900
    },
    {
      "epoch": 56.32,
      "learning_rate": 0.09436936046935485,
      "loss": 1.1756,
      "step": 34920
    },
    {
      "epoch": 56.35,
      "learning_rate": 0.09436613466612903,
      "loss": 1.1453,
      "step": 34940
    },
    {
      "epoch": 56.39,
      "learning_rate": 0.09436290886290323,
      "loss": 1.1431,
      "step": 34960
    },
    {
      "epoch": 56.42,
      "learning_rate": 0.09435968305967743,
      "loss": 1.1453,
      "step": 34980
    },
    {
      "epoch": 56.45,
      "learning_rate": 0.09435645725645161,
      "loss": 1.1612,
      "step": 35000
    },
    {
      "epoch": 56.48,
      "learning_rate": 0.09435323145322581,
      "loss": 1.1625,
      "step": 35020
    },
    {
      "epoch": 56.52,
      "learning_rate": 0.09435000565000001,
      "loss": 1.1784,
      "step": 35040
    },
    {
      "epoch": 56.55,
      "learning_rate": 0.0943467798467742,
      "loss": 1.162,
      "step": 35060
    },
    {
      "epoch": 56.58,
      "learning_rate": 0.0943435540435484,
      "loss": 1.1206,
      "step": 35080
    },
    {
      "epoch": 56.61,
      "learning_rate": 0.09434032824032258,
      "loss": 1.1227,
      "step": 35100
    },
    {
      "epoch": 56.65,
      "learning_rate": 0.09433710243709678,
      "loss": 1.1262,
      "step": 35120
    },
    {
      "epoch": 56.68,
      "learning_rate": 0.09433387663387098,
      "loss": 1.1575,
      "step": 35140
    },
    {
      "epoch": 56.71,
      "learning_rate": 0.09433065083064517,
      "loss": 1.159,
      "step": 35160
    },
    {
      "epoch": 56.74,
      "learning_rate": 0.09432742502741935,
      "loss": 1.1475,
      "step": 35180
    },
    {
      "epoch": 56.77,
      "learning_rate": 0.09432419922419355,
      "loss": 1.155,
      "step": 35200
    },
    {
      "epoch": 56.81,
      "learning_rate": 0.09432097342096775,
      "loss": 1.1208,
      "step": 35220
    },
    {
      "epoch": 56.84,
      "learning_rate": 0.09431774761774193,
      "loss": 1.1685,
      "step": 35240
    },
    {
      "epoch": 56.87,
      "learning_rate": 0.09431452181451613,
      "loss": 1.1559,
      "step": 35260
    },
    {
      "epoch": 56.9,
      "learning_rate": 0.09431129601129033,
      "loss": 1.162,
      "step": 35280
    },
    {
      "epoch": 56.94,
      "learning_rate": 0.09430807020806452,
      "loss": 1.1754,
      "step": 35300
    },
    {
      "epoch": 56.97,
      "learning_rate": 0.09430484440483872,
      "loss": 1.149,
      "step": 35320
    },
    {
      "epoch": 57.0,
      "learning_rate": 0.0943016186016129,
      "loss": 1.1475,
      "step": 35340
    },
    {
      "epoch": 57.0,
      "eval_accuracy": {
        "accuracy": 0.7171181016314105
      },
      "eval_loss": 1.527474284172058,
      "eval_runtime": 2.9752,
      "eval_samples_per_second": 4305.959,
      "eval_steps_per_second": 67.559,
      "step": 35340
    },
    {
      "epoch": 57.03,
      "learning_rate": 0.0942983927983871,
      "loss": 1.222,
      "step": 35360
    },
    {
      "epoch": 57.06,
      "learning_rate": 0.0942951669951613,
      "loss": 1.1438,
      "step": 35380
    },
    {
      "epoch": 57.1,
      "learning_rate": 0.09429194119193549,
      "loss": 1.1194,
      "step": 35400
    },
    {
      "epoch": 57.13,
      "learning_rate": 0.09428871538870968,
      "loss": 1.1052,
      "step": 35420
    },
    {
      "epoch": 57.16,
      "learning_rate": 0.09428548958548388,
      "loss": 1.1463,
      "step": 35440
    },
    {
      "epoch": 57.19,
      "learning_rate": 0.09428226378225807,
      "loss": 1.1091,
      "step": 35460
    },
    {
      "epoch": 57.23,
      "learning_rate": 0.09427903797903227,
      "loss": 1.1182,
      "step": 35480
    },
    {
      "epoch": 57.26,
      "learning_rate": 0.09427581217580647,
      "loss": 1.1037,
      "step": 35500
    },
    {
      "epoch": 57.29,
      "learning_rate": 0.09427258637258065,
      "loss": 1.1672,
      "step": 35520
    },
    {
      "epoch": 57.32,
      "learning_rate": 0.09426936056935484,
      "loss": 1.1301,
      "step": 35540
    },
    {
      "epoch": 57.35,
      "learning_rate": 0.09426613476612904,
      "loss": 1.1414,
      "step": 35560
    },
    {
      "epoch": 57.39,
      "learning_rate": 0.09426290896290324,
      "loss": 1.1318,
      "step": 35580
    },
    {
      "epoch": 57.42,
      "learning_rate": 0.09425968315967742,
      "loss": 1.1337,
      "step": 35600
    },
    {
      "epoch": 57.45,
      "learning_rate": 0.09425645735645162,
      "loss": 1.1432,
      "step": 35620
    },
    {
      "epoch": 57.48,
      "learning_rate": 0.0942532315532258,
      "loss": 1.1499,
      "step": 35640
    },
    {
      "epoch": 57.52,
      "learning_rate": 0.09425000575,
      "loss": 1.2042,
      "step": 35660
    },
    {
      "epoch": 57.55,
      "learning_rate": 0.0942467799467742,
      "loss": 1.1381,
      "step": 35680
    },
    {
      "epoch": 57.58,
      "learning_rate": 0.09424355414354839,
      "loss": 1.1563,
      "step": 35700
    },
    {
      "epoch": 57.61,
      "learning_rate": 0.09424032834032259,
      "loss": 1.1956,
      "step": 35720
    },
    {
      "epoch": 57.65,
      "learning_rate": 0.09423710253709679,
      "loss": 1.2116,
      "step": 35740
    },
    {
      "epoch": 57.68,
      "learning_rate": 0.09423387673387097,
      "loss": 1.1596,
      "step": 35760
    },
    {
      "epoch": 57.71,
      "learning_rate": 0.09423065093064517,
      "loss": 1.146,
      "step": 35780
    },
    {
      "epoch": 57.74,
      "learning_rate": 0.09422742512741937,
      "loss": 1.19,
      "step": 35800
    },
    {
      "epoch": 57.77,
      "learning_rate": 0.09422419932419356,
      "loss": 1.1655,
      "step": 35820
    },
    {
      "epoch": 57.81,
      "learning_rate": 0.09422097352096774,
      "loss": 1.1947,
      "step": 35840
    },
    {
      "epoch": 57.84,
      "learning_rate": 0.09421774771774194,
      "loss": 1.1988,
      "step": 35860
    },
    {
      "epoch": 57.87,
      "learning_rate": 0.09421452191451613,
      "loss": 1.1955,
      "step": 35880
    },
    {
      "epoch": 57.9,
      "learning_rate": 0.09421129611129032,
      "loss": 1.1979,
      "step": 35900
    },
    {
      "epoch": 57.94,
      "learning_rate": 0.09420807030806452,
      "loss": 1.155,
      "step": 35920
    },
    {
      "epoch": 57.97,
      "learning_rate": 0.09420484450483871,
      "loss": 1.1236,
      "step": 35940
    },
    {
      "epoch": 58.0,
      "learning_rate": 0.09420177999177419,
      "loss": 1.1637,
      "step": 35960
    },
    {
      "epoch": 58.0,
      "eval_accuracy": {
        "accuracy": 0.7324955116696589
      },
      "eval_loss": 1.4014488458633423,
      "eval_runtime": 2.5084,
      "eval_samples_per_second": 5107.168,
      "eval_steps_per_second": 80.13,
      "step": 35960
    },
    {
      "epoch": 58.03,
      "learning_rate": 0.09419855418854839,
      "loss": 1.1606,
      "step": 35980
    },
    {
      "epoch": 58.06,
      "learning_rate": 0.09419532838532259,
      "loss": 1.1456,
      "step": 36000
    },
    {
      "epoch": 58.1,
      "learning_rate": 0.09419210258209677,
      "loss": 1.1284,
      "step": 36020
    },
    {
      "epoch": 58.13,
      "learning_rate": 0.09418887677887097,
      "loss": 1.1203,
      "step": 36040
    },
    {
      "epoch": 58.16,
      "learning_rate": 0.09418565097564517,
      "loss": 1.0981,
      "step": 36060
    },
    {
      "epoch": 58.19,
      "learning_rate": 0.09418242517241936,
      "loss": 1.1171,
      "step": 36080
    },
    {
      "epoch": 58.23,
      "learning_rate": 0.09417919936919356,
      "loss": 1.1775,
      "step": 36100
    },
    {
      "epoch": 58.26,
      "learning_rate": 0.09417597356596775,
      "loss": 1.1739,
      "step": 36120
    },
    {
      "epoch": 58.29,
      "learning_rate": 0.09417274776274194,
      "loss": 1.135,
      "step": 36140
    },
    {
      "epoch": 58.32,
      "learning_rate": 0.09416952195951614,
      "loss": 1.1315,
      "step": 36160
    },
    {
      "epoch": 58.35,
      "learning_rate": 0.09416629615629032,
      "loss": 1.1514,
      "step": 36180
    },
    {
      "epoch": 58.39,
      "learning_rate": 0.09416307035306452,
      "loss": 1.1338,
      "step": 36200
    },
    {
      "epoch": 58.42,
      "learning_rate": 0.09415984454983872,
      "loss": 1.1507,
      "step": 36220
    },
    {
      "epoch": 58.45,
      "learning_rate": 0.09415661874661291,
      "loss": 1.1525,
      "step": 36240
    },
    {
      "epoch": 58.48,
      "learning_rate": 0.0941533929433871,
      "loss": 1.1435,
      "step": 36260
    },
    {
      "epoch": 58.52,
      "learning_rate": 0.09415016714016129,
      "loss": 1.1275,
      "step": 36280
    },
    {
      "epoch": 58.55,
      "learning_rate": 0.09414694133693549,
      "loss": 1.1599,
      "step": 36300
    },
    {
      "epoch": 58.58,
      "learning_rate": 0.09414371553370968,
      "loss": 1.1926,
      "step": 36320
    },
    {
      "epoch": 58.61,
      "learning_rate": 0.09414048973048388,
      "loss": 1.1615,
      "step": 36340
    },
    {
      "epoch": 58.65,
      "learning_rate": 0.09413726392725807,
      "loss": 1.1484,
      "step": 36360
    },
    {
      "epoch": 58.68,
      "learning_rate": 0.09413403812403226,
      "loss": 1.1618,
      "step": 36380
    },
    {
      "epoch": 58.71,
      "learning_rate": 0.09413081232080646,
      "loss": 1.1386,
      "step": 36400
    },
    {
      "epoch": 58.74,
      "learning_rate": 0.09412758651758064,
      "loss": 1.1386,
      "step": 36420
    },
    {
      "epoch": 58.77,
      "learning_rate": 0.09412436071435484,
      "loss": 1.1112,
      "step": 36440
    },
    {
      "epoch": 58.81,
      "learning_rate": 0.09412113491112904,
      "loss": 1.1316,
      "step": 36460
    },
    {
      "epoch": 58.84,
      "learning_rate": 0.09411790910790323,
      "loss": 1.1353,
      "step": 36480
    },
    {
      "epoch": 58.87,
      "learning_rate": 0.09411468330467743,
      "loss": 1.1651,
      "step": 36500
    },
    {
      "epoch": 58.9,
      "learning_rate": 0.09411145750145163,
      "loss": 1.1859,
      "step": 36520
    },
    {
      "epoch": 58.94,
      "learning_rate": 0.09410823169822581,
      "loss": 1.1618,
      "step": 36540
    },
    {
      "epoch": 58.97,
      "learning_rate": 0.094105005895,
      "loss": 1.17,
      "step": 36560
    },
    {
      "epoch": 59.0,
      "learning_rate": 0.0941017800917742,
      "loss": 1.1792,
      "step": 36580
    },
    {
      "epoch": 59.0,
      "eval_accuracy": {
        "accuracy": 0.7242994301771915
      },
      "eval_loss": 1.4330732822418213,
      "eval_runtime": 2.5472,
      "eval_samples_per_second": 5029.499,
      "eval_steps_per_second": 78.911,
      "step": 36580
    },
    {
      "epoch": 59.03,
      "learning_rate": 0.0940985542885484,
      "loss": 1.197,
      "step": 36600
    },
    {
      "epoch": 59.06,
      "learning_rate": 0.09409532848532258,
      "loss": 1.1349,
      "step": 36620
    },
    {
      "epoch": 59.1,
      "learning_rate": 0.09409210268209678,
      "loss": 1.1148,
      "step": 36640
    },
    {
      "epoch": 59.13,
      "learning_rate": 0.09408887687887098,
      "loss": 1.1349,
      "step": 36660
    },
    {
      "epoch": 59.16,
      "learning_rate": 0.09408565107564516,
      "loss": 1.1421,
      "step": 36680
    },
    {
      "epoch": 59.19,
      "learning_rate": 0.09408242527241936,
      "loss": 1.1567,
      "step": 36700
    },
    {
      "epoch": 59.23,
      "learning_rate": 0.09407919946919355,
      "loss": 1.158,
      "step": 36720
    },
    {
      "epoch": 59.26,
      "learning_rate": 0.09407597366596775,
      "loss": 1.156,
      "step": 36740
    },
    {
      "epoch": 59.29,
      "learning_rate": 0.09407274786274195,
      "loss": 1.1577,
      "step": 36760
    },
    {
      "epoch": 59.32,
      "learning_rate": 0.09406952205951613,
      "loss": 1.1485,
      "step": 36780
    },
    {
      "epoch": 59.35,
      "learning_rate": 0.09406629625629033,
      "loss": 1.1413,
      "step": 36800
    },
    {
      "epoch": 59.39,
      "learning_rate": 0.09406307045306453,
      "loss": 1.1315,
      "step": 36820
    },
    {
      "epoch": 59.42,
      "learning_rate": 0.09405984464983871,
      "loss": 1.1104,
      "step": 36840
    },
    {
      "epoch": 59.45,
      "learning_rate": 0.09405661884661291,
      "loss": 1.1524,
      "step": 36860
    },
    {
      "epoch": 59.48,
      "learning_rate": 0.09405339304338711,
      "loss": 1.146,
      "step": 36880
    },
    {
      "epoch": 59.52,
      "learning_rate": 0.0940501672401613,
      "loss": 1.1408,
      "step": 36900
    },
    {
      "epoch": 59.55,
      "learning_rate": 0.09404694143693548,
      "loss": 1.1459,
      "step": 36920
    },
    {
      "epoch": 59.58,
      "learning_rate": 0.09404371563370968,
      "loss": 1.1714,
      "step": 36940
    },
    {
      "epoch": 59.61,
      "learning_rate": 0.09404048983048387,
      "loss": 1.1473,
      "step": 36960
    },
    {
      "epoch": 59.65,
      "learning_rate": 0.09403726402725807,
      "loss": 1.1292,
      "step": 36980
    },
    {
      "epoch": 59.68,
      "learning_rate": 0.09403403822403227,
      "loss": 1.1543,
      "step": 37000
    },
    {
      "epoch": 59.71,
      "learning_rate": 0.09403081242080645,
      "loss": 1.1328,
      "step": 37020
    },
    {
      "epoch": 59.74,
      "learning_rate": 0.09402758661758065,
      "loss": 1.1509,
      "step": 37040
    },
    {
      "epoch": 59.77,
      "learning_rate": 0.09402436081435485,
      "loss": 1.1546,
      "step": 37060
    },
    {
      "epoch": 59.81,
      "learning_rate": 0.09402113501112903,
      "loss": 1.1453,
      "step": 37080
    },
    {
      "epoch": 59.84,
      "learning_rate": 0.09401790920790323,
      "loss": 1.1879,
      "step": 37100
    },
    {
      "epoch": 59.87,
      "learning_rate": 0.09401468340467743,
      "loss": 1.1792,
      "step": 37120
    },
    {
      "epoch": 59.9,
      "learning_rate": 0.09401145760145162,
      "loss": 1.1941,
      "step": 37140
    },
    {
      "epoch": 59.94,
      "learning_rate": 0.09400823179822582,
      "loss": 1.1311,
      "step": 37160
    },
    {
      "epoch": 59.97,
      "learning_rate": 0.09400500599500002,
      "loss": 1.1073,
      "step": 37180
    },
    {
      "epoch": 60.0,
      "learning_rate": 0.09400178019177419,
      "loss": 1.1421,
      "step": 37200
    },
    {
      "epoch": 60.0,
      "eval_accuracy": {
        "accuracy": 0.7229724455546015
      },
      "eval_loss": 1.4467895030975342,
      "eval_runtime": 2.5558,
      "eval_samples_per_second": 5012.6,
      "eval_steps_per_second": 78.646,
      "step": 37200
    },
    {
      "epoch": 60.03,
      "learning_rate": 0.09399855438854839,
      "loss": 1.2066,
      "step": 37220
    },
    {
      "epoch": 60.06,
      "learning_rate": 0.09399532858532259,
      "loss": 1.1431,
      "step": 37240
    },
    {
      "epoch": 60.1,
      "learning_rate": 0.09399210278209677,
      "loss": 1.1174,
      "step": 37260
    },
    {
      "epoch": 60.13,
      "learning_rate": 0.09398887697887097,
      "loss": 1.1315,
      "step": 37280
    },
    {
      "epoch": 60.16,
      "learning_rate": 0.09398565117564517,
      "loss": 1.1078,
      "step": 37300
    },
    {
      "epoch": 60.19,
      "learning_rate": 0.09398242537241935,
      "loss": 1.143,
      "step": 37320
    },
    {
      "epoch": 60.23,
      "learning_rate": 0.09397919956919355,
      "loss": 1.1497,
      "step": 37340
    },
    {
      "epoch": 60.26,
      "learning_rate": 0.09397597376596775,
      "loss": 1.1229,
      "step": 37360
    },
    {
      "epoch": 60.29,
      "learning_rate": 0.09397274796274194,
      "loss": 1.1211,
      "step": 37380
    },
    {
      "epoch": 60.32,
      "learning_rate": 0.09396952215951614,
      "loss": 1.1474,
      "step": 37400
    },
    {
      "epoch": 60.35,
      "learning_rate": 0.09396629635629034,
      "loss": 1.1318,
      "step": 37420
    },
    {
      "epoch": 60.39,
      "learning_rate": 0.09396307055306452,
      "loss": 1.1366,
      "step": 37440
    },
    {
      "epoch": 60.42,
      "learning_rate": 0.09395984474983872,
      "loss": 1.1517,
      "step": 37460
    },
    {
      "epoch": 60.45,
      "learning_rate": 0.09395661894661292,
      "loss": 1.1541,
      "step": 37480
    },
    {
      "epoch": 60.48,
      "learning_rate": 0.09395339314338709,
      "loss": 1.1532,
      "step": 37500
    },
    {
      "epoch": 60.52,
      "learning_rate": 0.09395016734016129,
      "loss": 1.093,
      "step": 37520
    },
    {
      "epoch": 60.55,
      "learning_rate": 0.09394694153693549,
      "loss": 1.1333,
      "step": 37540
    },
    {
      "epoch": 60.58,
      "learning_rate": 0.09394371573370967,
      "loss": 1.1366,
      "step": 37560
    },
    {
      "epoch": 60.61,
      "learning_rate": 0.09394048993048387,
      "loss": 1.1513,
      "step": 37580
    },
    {
      "epoch": 60.65,
      "learning_rate": 0.09393726412725807,
      "loss": 1.1716,
      "step": 37600
    },
    {
      "epoch": 60.68,
      "learning_rate": 0.09393403832403226,
      "loss": 1.1594,
      "step": 37620
    },
    {
      "epoch": 60.71,
      "learning_rate": 0.09393081252080646,
      "loss": 1.1606,
      "step": 37640
    },
    {
      "epoch": 60.74,
      "learning_rate": 0.09392758671758066,
      "loss": 1.1348,
      "step": 37660
    },
    {
      "epoch": 60.77,
      "learning_rate": 0.09392436091435484,
      "loss": 1.134,
      "step": 37680
    },
    {
      "epoch": 60.81,
      "learning_rate": 0.09392113511112904,
      "loss": 1.142,
      "step": 37700
    },
    {
      "epoch": 60.84,
      "learning_rate": 0.09391790930790324,
      "loss": 1.1532,
      "step": 37720
    },
    {
      "epoch": 60.87,
      "learning_rate": 0.09391468350467742,
      "loss": 1.1524,
      "step": 37740
    },
    {
      "epoch": 60.9,
      "learning_rate": 0.09391145770145162,
      "loss": 1.1183,
      "step": 37760
    },
    {
      "epoch": 60.94,
      "learning_rate": 0.09390823189822582,
      "loss": 1.1482,
      "step": 37780
    },
    {
      "epoch": 60.97,
      "learning_rate": 0.09390500609500001,
      "loss": 1.1726,
      "step": 37800
    },
    {
      "epoch": 61.0,
      "learning_rate": 0.0939017802917742,
      "loss": 1.1567,
      "step": 37820
    },
    {
      "epoch": 61.0,
      "eval_accuracy": {
        "accuracy": 0.7225040980407462
      },
      "eval_loss": 1.4717060327529907,
      "eval_runtime": 2.5957,
      "eval_samples_per_second": 4935.518,
      "eval_steps_per_second": 77.437,
      "step": 37820
    },
    {
      "epoch": 61.03,
      "learning_rate": 0.09389855448854839,
      "loss": 1.2334,
      "step": 37840
    },
    {
      "epoch": 61.06,
      "learning_rate": 0.09389532868532258,
      "loss": 1.1591,
      "step": 37860
    },
    {
      "epoch": 61.1,
      "learning_rate": 0.09389210288209678,
      "loss": 1.1553,
      "step": 37880
    },
    {
      "epoch": 61.13,
      "learning_rate": 0.09388887707887097,
      "loss": 1.1066,
      "step": 37900
    },
    {
      "epoch": 61.16,
      "learning_rate": 0.09388565127564516,
      "loss": 1.119,
      "step": 37920
    },
    {
      "epoch": 61.19,
      "learning_rate": 0.09388242547241936,
      "loss": 1.1041,
      "step": 37940
    },
    {
      "epoch": 61.23,
      "learning_rate": 0.09387919966919356,
      "loss": 1.1356,
      "step": 37960
    },
    {
      "epoch": 61.26,
      "learning_rate": 0.09387597386596774,
      "loss": 1.0973,
      "step": 37980
    },
    {
      "epoch": 61.29,
      "learning_rate": 0.09387274806274194,
      "loss": 1.1325,
      "step": 38000
    },
    {
      "epoch": 61.32,
      "learning_rate": 0.09386952225951614,
      "loss": 1.1229,
      "step": 38020
    },
    {
      "epoch": 61.35,
      "learning_rate": 0.09386629645629033,
      "loss": 1.1038,
      "step": 38040
    },
    {
      "epoch": 61.39,
      "learning_rate": 0.09386307065306453,
      "loss": 1.1188,
      "step": 38060
    },
    {
      "epoch": 61.42,
      "learning_rate": 0.09386000614000001,
      "loss": 1.144,
      "step": 38080
    },
    {
      "epoch": 61.45,
      "learning_rate": 0.09385678033677419,
      "loss": 1.1287,
      "step": 38100
    },
    {
      "epoch": 61.48,
      "learning_rate": 0.09385355453354839,
      "loss": 1.1413,
      "step": 38120
    },
    {
      "epoch": 61.52,
      "learning_rate": 0.09385032873032259,
      "loss": 1.1449,
      "step": 38140
    },
    {
      "epoch": 61.55,
      "learning_rate": 0.09384710292709678,
      "loss": 1.1201,
      "step": 38160
    },
    {
      "epoch": 61.58,
      "learning_rate": 0.09384387712387098,
      "loss": 1.1331,
      "step": 38180
    },
    {
      "epoch": 61.61,
      "learning_rate": 0.09384065132064517,
      "loss": 1.156,
      "step": 38200
    },
    {
      "epoch": 61.65,
      "learning_rate": 0.09383742551741936,
      "loss": 1.1354,
      "step": 38220
    },
    {
      "epoch": 61.68,
      "learning_rate": 0.09383419971419356,
      "loss": 1.1785,
      "step": 38240
    },
    {
      "epoch": 61.71,
      "learning_rate": 0.09383097391096776,
      "loss": 1.1502,
      "step": 38260
    },
    {
      "epoch": 61.74,
      "learning_rate": 0.09382774810774193,
      "loss": 1.1405,
      "step": 38280
    },
    {
      "epoch": 61.77,
      "learning_rate": 0.09382452230451613,
      "loss": 1.1932,
      "step": 38300
    },
    {
      "epoch": 61.81,
      "learning_rate": 0.09382129650129033,
      "loss": 1.1626,
      "step": 38320
    },
    {
      "epoch": 61.84,
      "learning_rate": 0.09381807069806451,
      "loss": 1.1874,
      "step": 38340
    },
    {
      "epoch": 61.87,
      "learning_rate": 0.09381484489483871,
      "loss": 1.166,
      "step": 38360
    },
    {
      "epoch": 61.9,
      "learning_rate": 0.09381161909161291,
      "loss": 1.1497,
      "step": 38380
    },
    {
      "epoch": 61.94,
      "learning_rate": 0.0938083932883871,
      "loss": 1.1631,
      "step": 38400
    },
    {
      "epoch": 61.97,
      "learning_rate": 0.0938051674851613,
      "loss": 1.1508,
      "step": 38420
    },
    {
      "epoch": 62.0,
      "learning_rate": 0.0938019416819355,
      "loss": 1.1444,
      "step": 38440
    },
    {
      "epoch": 62.0,
      "eval_accuracy": {
        "accuracy": 0.7261728202326126
      },
      "eval_loss": 1.439597249031067,
      "eval_runtime": 2.6323,
      "eval_samples_per_second": 4866.823,
      "eval_steps_per_second": 76.359,
      "step": 38440
    },
    {
      "epoch": 62.03,
      "learning_rate": 0.09379871587870968,
      "loss": 1.1921,
      "step": 38460
    },
    {
      "epoch": 62.06,
      "learning_rate": 0.09379549007548388,
      "loss": 1.1035,
      "step": 38480
    },
    {
      "epoch": 62.1,
      "learning_rate": 0.09379226427225808,
      "loss": 1.103,
      "step": 38500
    },
    {
      "epoch": 62.13,
      "learning_rate": 0.09378903846903226,
      "loss": 1.1126,
      "step": 38520
    },
    {
      "epoch": 62.16,
      "learning_rate": 0.09378581266580646,
      "loss": 1.1455,
      "step": 38540
    },
    {
      "epoch": 62.19,
      "learning_rate": 0.09378258686258066,
      "loss": 1.1418,
      "step": 38560
    },
    {
      "epoch": 62.23,
      "learning_rate": 0.09377936105935483,
      "loss": 1.1358,
      "step": 38580
    },
    {
      "epoch": 62.26,
      "learning_rate": 0.09377613525612903,
      "loss": 1.1409,
      "step": 38600
    },
    {
      "epoch": 62.29,
      "learning_rate": 0.09377290945290323,
      "loss": 1.1119,
      "step": 38620
    },
    {
      "epoch": 62.32,
      "learning_rate": 0.09376968364967742,
      "loss": 1.1437,
      "step": 38640
    },
    {
      "epoch": 62.35,
      "learning_rate": 0.09376645784645161,
      "loss": 1.1706,
      "step": 38660
    },
    {
      "epoch": 62.39,
      "learning_rate": 0.09376323204322581,
      "loss": 1.1484,
      "step": 38680
    },
    {
      "epoch": 62.42,
      "learning_rate": 0.09376000624,
      "loss": 1.1558,
      "step": 38700
    },
    {
      "epoch": 62.45,
      "learning_rate": 0.0937567804367742,
      "loss": 1.1768,
      "step": 38720
    },
    {
      "epoch": 62.48,
      "learning_rate": 0.0937535546335484,
      "loss": 1.145,
      "step": 38740
    },
    {
      "epoch": 62.52,
      "learning_rate": 0.09375032883032258,
      "loss": 1.1435,
      "step": 38760
    },
    {
      "epoch": 62.55,
      "learning_rate": 0.09374710302709678,
      "loss": 1.1504,
      "step": 38780
    },
    {
      "epoch": 62.58,
      "learning_rate": 0.09374387722387098,
      "loss": 1.127,
      "step": 38800
    },
    {
      "epoch": 62.61,
      "learning_rate": 0.09374065142064517,
      "loss": 1.1611,
      "step": 38820
    },
    {
      "epoch": 62.65,
      "learning_rate": 0.09373742561741936,
      "loss": 1.1627,
      "step": 38840
    },
    {
      "epoch": 62.68,
      "learning_rate": 0.09373419981419356,
      "loss": 1.1381,
      "step": 38860
    },
    {
      "epoch": 62.71,
      "learning_rate": 0.09373097401096774,
      "loss": 1.1449,
      "step": 38880
    },
    {
      "epoch": 62.74,
      "learning_rate": 0.09372774820774195,
      "loss": 1.165,
      "step": 38900
    },
    {
      "epoch": 62.77,
      "learning_rate": 0.09372452240451613,
      "loss": 1.1685,
      "step": 38920
    },
    {
      "epoch": 62.81,
      "learning_rate": 0.09372129660129032,
      "loss": 1.1756,
      "step": 38940
    },
    {
      "epoch": 62.84,
      "learning_rate": 0.09371807079806452,
      "loss": 1.1438,
      "step": 38960
    },
    {
      "epoch": 62.87,
      "learning_rate": 0.09371484499483872,
      "loss": 1.1593,
      "step": 38980
    },
    {
      "epoch": 62.9,
      "learning_rate": 0.0937116191916129,
      "loss": 1.1669,
      "step": 39000
    },
    {
      "epoch": 62.94,
      "learning_rate": 0.0937083933883871,
      "loss": 1.1481,
      "step": 39020
    },
    {
      "epoch": 62.97,
      "learning_rate": 0.0937051675851613,
      "loss": 1.1521,
      "step": 39040
    },
    {
      "epoch": 63.0,
      "learning_rate": 0.09370194178193549,
      "loss": 1.1661,
      "step": 39060
    },
    {
      "epoch": 63.0,
      "eval_accuracy": {
        "accuracy": 0.718132854578097
      },
      "eval_loss": 1.4846115112304688,
      "eval_runtime": 2.5238,
      "eval_samples_per_second": 5076.016,
      "eval_steps_per_second": 79.641,
      "step": 39060
    },
    {
      "epoch": 63.03,
      "learning_rate": 0.09369871597870968,
      "loss": 1.1443,
      "step": 39080
    },
    {
      "epoch": 63.06,
      "learning_rate": 0.09369549017548388,
      "loss": 1.1281,
      "step": 39100
    },
    {
      "epoch": 63.1,
      "learning_rate": 0.09369226437225807,
      "loss": 1.1539,
      "step": 39120
    },
    {
      "epoch": 63.13,
      "learning_rate": 0.09368903856903227,
      "loss": 1.1123,
      "step": 39140
    },
    {
      "epoch": 63.16,
      "learning_rate": 0.09368581276580647,
      "loss": 1.1033,
      "step": 39160
    },
    {
      "epoch": 63.19,
      "learning_rate": 0.09368258696258064,
      "loss": 1.0841,
      "step": 39180
    },
    {
      "epoch": 63.23,
      "learning_rate": 0.09367936115935485,
      "loss": 1.0968,
      "step": 39200
    },
    {
      "epoch": 63.26,
      "learning_rate": 0.09367613535612904,
      "loss": 1.1386,
      "step": 39220
    },
    {
      "epoch": 63.29,
      "learning_rate": 0.09367290955290322,
      "loss": 1.1102,
      "step": 39240
    },
    {
      "epoch": 63.32,
      "learning_rate": 0.09366968374967742,
      "loss": 1.1279,
      "step": 39260
    },
    {
      "epoch": 63.35,
      "learning_rate": 0.09366645794645162,
      "loss": 1.1218,
      "step": 39280
    },
    {
      "epoch": 63.39,
      "learning_rate": 0.0936632321432258,
      "loss": 1.1236,
      "step": 39300
    },
    {
      "epoch": 63.42,
      "learning_rate": 0.09366000634,
      "loss": 1.1595,
      "step": 39320
    },
    {
      "epoch": 63.45,
      "learning_rate": 0.0936567805367742,
      "loss": 1.1382,
      "step": 39340
    },
    {
      "epoch": 63.48,
      "learning_rate": 0.09365355473354839,
      "loss": 1.1543,
      "step": 39360
    },
    {
      "epoch": 63.52,
      "learning_rate": 0.09365032893032259,
      "loss": 1.1276,
      "step": 39380
    },
    {
      "epoch": 63.55,
      "learning_rate": 0.09364710312709679,
      "loss": 1.1321,
      "step": 39400
    },
    {
      "epoch": 63.58,
      "learning_rate": 0.09364387732387097,
      "loss": 1.1469,
      "step": 39420
    },
    {
      "epoch": 63.61,
      "learning_rate": 0.09364065152064517,
      "loss": 1.1288,
      "step": 39440
    },
    {
      "epoch": 63.65,
      "learning_rate": 0.09363742571741937,
      "loss": 1.1312,
      "step": 39460
    },
    {
      "epoch": 63.68,
      "learning_rate": 0.09363419991419356,
      "loss": 1.1275,
      "step": 39480
    },
    {
      "epoch": 63.71,
      "learning_rate": 0.09363097411096775,
      "loss": 1.1418,
      "step": 39500
    },
    {
      "epoch": 63.74,
      "learning_rate": 0.09362774830774194,
      "loss": 1.1507,
      "step": 39520
    },
    {
      "epoch": 63.77,
      "learning_rate": 0.09362452250451613,
      "loss": 1.1339,
      "step": 39540
    },
    {
      "epoch": 63.81,
      "learning_rate": 0.09362129670129032,
      "loss": 1.1609,
      "step": 39560
    },
    {
      "epoch": 63.84,
      "learning_rate": 0.09361807089806452,
      "loss": 1.1667,
      "step": 39580
    },
    {
      "epoch": 63.87,
      "learning_rate": 0.09361484509483871,
      "loss": 1.1353,
      "step": 39600
    },
    {
      "epoch": 63.9,
      "learning_rate": 0.09361161929161291,
      "loss": 1.1383,
      "step": 39620
    },
    {
      "epoch": 63.94,
      "learning_rate": 0.0936083934883871,
      "loss": 1.1405,
      "step": 39640
    },
    {
      "epoch": 63.97,
      "learning_rate": 0.09360516768516129,
      "loss": 1.1159,
      "step": 39660
    },
    {
      "epoch": 64.0,
      "learning_rate": 0.09360194188193549,
      "loss": 1.1632,
      "step": 39680
    },
    {
      "epoch": 64.0,
      "eval_accuracy": {
        "accuracy": 0.723987198501288
      },
      "eval_loss": 1.4510958194732666,
      "eval_runtime": 2.4913,
      "eval_samples_per_second": 5142.235,
      "eval_steps_per_second": 80.68,
      "step": 39680
    },
    {
      "epoch": 64.03,
      "learning_rate": 0.09359871607870969,
      "loss": 1.1739,
      "step": 39700
    },
    {
      "epoch": 64.06,
      "learning_rate": 0.09359549027548388,
      "loss": 1.1089,
      "step": 39720
    },
    {
      "epoch": 64.1,
      "learning_rate": 0.09359226447225807,
      "loss": 1.1248,
      "step": 39740
    },
    {
      "epoch": 64.13,
      "learning_rate": 0.09358903866903227,
      "loss": 1.1269,
      "step": 39760
    },
    {
      "epoch": 64.16,
      "learning_rate": 0.09358581286580646,
      "loss": 1.1128,
      "step": 39780
    },
    {
      "epoch": 64.19,
      "learning_rate": 0.09358258706258066,
      "loss": 1.1153,
      "step": 39800
    },
    {
      "epoch": 64.23,
      "learning_rate": 0.09357936125935484,
      "loss": 1.1303,
      "step": 39820
    },
    {
      "epoch": 64.26,
      "learning_rate": 0.09357613545612903,
      "loss": 1.0977,
      "step": 39840
    },
    {
      "epoch": 64.29,
      "learning_rate": 0.09357290965290323,
      "loss": 1.0833,
      "step": 39860
    },
    {
      "epoch": 64.32,
      "learning_rate": 0.09356968384967743,
      "loss": 1.0847,
      "step": 39880
    },
    {
      "epoch": 64.35,
      "learning_rate": 0.09356645804645161,
      "loss": 1.0972,
      "step": 39900
    },
    {
      "epoch": 64.39,
      "learning_rate": 0.09356323224322581,
      "loss": 1.1588,
      "step": 39920
    },
    {
      "epoch": 64.42,
      "learning_rate": 0.09356000644000001,
      "loss": 1.1704,
      "step": 39940
    },
    {
      "epoch": 64.45,
      "learning_rate": 0.0935567806367742,
      "loss": 1.1363,
      "step": 39960
    },
    {
      "epoch": 64.48,
      "learning_rate": 0.0935535548335484,
      "loss": 1.1495,
      "step": 39980
    },
    {
      "epoch": 64.52,
      "learning_rate": 0.0935503290303226,
      "loss": 1.1976,
      "step": 40000
    },
    {
      "epoch": 64.55,
      "learning_rate": 0.09354710322709678,
      "loss": 1.1638,
      "step": 40020
    },
    {
      "epoch": 64.58,
      "learning_rate": 0.09354387742387098,
      "loss": 1.1441,
      "step": 40040
    },
    {
      "epoch": 64.61,
      "learning_rate": 0.09354065162064518,
      "loss": 1.1693,
      "step": 40060
    },
    {
      "epoch": 64.65,
      "learning_rate": 0.09353742581741936,
      "loss": 1.1256,
      "step": 40080
    },
    {
      "epoch": 64.68,
      "learning_rate": 0.09353420001419356,
      "loss": 1.1638,
      "step": 40100
    },
    {
      "epoch": 64.71,
      "learning_rate": 0.09353097421096775,
      "loss": 1.1031,
      "step": 40120
    },
    {
      "epoch": 64.74,
      "learning_rate": 0.09352774840774195,
      "loss": 1.1474,
      "step": 40140
    },
    {
      "epoch": 64.77,
      "learning_rate": 0.09352452260451613,
      "loss": 1.1963,
      "step": 40160
    },
    {
      "epoch": 64.81,
      "learning_rate": 0.09352129680129033,
      "loss": 1.152,
      "step": 40180
    },
    {
      "epoch": 64.84,
      "learning_rate": 0.09351807099806451,
      "loss": 1.1455,
      "step": 40200
    },
    {
      "epoch": 64.87,
      "learning_rate": 0.09351484519483871,
      "loss": 1.1802,
      "step": 40220
    },
    {
      "epoch": 64.9,
      "learning_rate": 0.09351161939161291,
      "loss": 1.1706,
      "step": 40240
    },
    {
      "epoch": 64.94,
      "learning_rate": 0.0935083935883871,
      "loss": 1.1351,
      "step": 40260
    },
    {
      "epoch": 64.97,
      "learning_rate": 0.0935051677851613,
      "loss": 1.1382,
      "step": 40280
    },
    {
      "epoch": 65.0,
      "learning_rate": 0.09350210327209678,
      "loss": 1.1301,
      "step": 40300
    },
    {
      "epoch": 65.0,
      "eval_accuracy": {
        "accuracy": 0.728514557801889
      },
      "eval_loss": 1.3848990201950073,
      "eval_runtime": 2.8065,
      "eval_samples_per_second": 4564.743,
      "eval_steps_per_second": 71.619,
      "step": 40300
    },
    {
      "epoch": 65.03,
      "learning_rate": 0.09349887746887096,
      "loss": 1.1191,
      "step": 40320
    },
    {
      "epoch": 65.06,
      "learning_rate": 0.09349565166564516,
      "loss": 1.1154,
      "step": 40340
    },
    {
      "epoch": 65.1,
      "learning_rate": 0.09349242586241936,
      "loss": 1.1356,
      "step": 40360
    },
    {
      "epoch": 65.13,
      "learning_rate": 0.09348920005919355,
      "loss": 1.1026,
      "step": 40380
    },
    {
      "epoch": 65.16,
      "learning_rate": 0.09348597425596775,
      "loss": 1.15,
      "step": 40400
    },
    {
      "epoch": 65.19,
      "learning_rate": 0.09348274845274195,
      "loss": 1.1708,
      "step": 40420
    },
    {
      "epoch": 65.23,
      "learning_rate": 0.09347952264951613,
      "loss": 1.1136,
      "step": 40440
    },
    {
      "epoch": 65.26,
      "learning_rate": 0.09347629684629033,
      "loss": 1.0665,
      "step": 40460
    },
    {
      "epoch": 65.29,
      "learning_rate": 0.09347307104306453,
      "loss": 1.054,
      "step": 40480
    },
    {
      "epoch": 65.32,
      "learning_rate": 0.09346984523983871,
      "loss": 1.1048,
      "step": 40500
    },
    {
      "epoch": 65.35,
      "learning_rate": 0.09346661943661291,
      "loss": 1.1563,
      "step": 40520
    },
    {
      "epoch": 65.39,
      "learning_rate": 0.09346339363338711,
      "loss": 1.1639,
      "step": 40540
    },
    {
      "epoch": 65.42,
      "learning_rate": 0.0934601678301613,
      "loss": 1.1714,
      "step": 40560
    },
    {
      "epoch": 65.45,
      "learning_rate": 0.0934569420269355,
      "loss": 1.153,
      "step": 40580
    },
    {
      "epoch": 65.48,
      "learning_rate": 0.09345371622370968,
      "loss": 1.1335,
      "step": 40600
    },
    {
      "epoch": 65.52,
      "learning_rate": 0.09345049042048387,
      "loss": 1.1139,
      "step": 40620
    },
    {
      "epoch": 65.55,
      "learning_rate": 0.09344726461725807,
      "loss": 1.1294,
      "step": 40640
    },
    {
      "epoch": 65.58,
      "learning_rate": 0.09344403881403227,
      "loss": 1.1594,
      "step": 40660
    },
    {
      "epoch": 65.61,
      "learning_rate": 0.09344081301080645,
      "loss": 1.1503,
      "step": 40680
    },
    {
      "epoch": 65.65,
      "learning_rate": 0.09343758720758065,
      "loss": 1.1151,
      "step": 40700
    },
    {
      "epoch": 65.68,
      "learning_rate": 0.09343436140435485,
      "loss": 1.1751,
      "step": 40720
    },
    {
      "epoch": 65.71,
      "learning_rate": 0.09343113560112903,
      "loss": 1.1462,
      "step": 40740
    },
    {
      "epoch": 65.74,
      "learning_rate": 0.09342790979790323,
      "loss": 1.1598,
      "step": 40760
    },
    {
      "epoch": 65.77,
      "learning_rate": 0.09342468399467743,
      "loss": 1.1313,
      "step": 40780
    },
    {
      "epoch": 65.81,
      "learning_rate": 0.09342145819145162,
      "loss": 1.1437,
      "step": 40800
    },
    {
      "epoch": 65.84,
      "learning_rate": 0.09341823238822582,
      "loss": 1.1251,
      "step": 40820
    },
    {
      "epoch": 65.87,
      "learning_rate": 0.09341500658500002,
      "loss": 1.1247,
      "step": 40840
    },
    {
      "epoch": 65.9,
      "learning_rate": 0.0934117807817742,
      "loss": 1.1376,
      "step": 40860
    },
    {
      "epoch": 65.94,
      "learning_rate": 0.0934085549785484,
      "loss": 1.157,
      "step": 40880
    },
    {
      "epoch": 65.97,
      "learning_rate": 0.09340532917532259,
      "loss": 1.1244,
      "step": 40900
    },
    {
      "epoch": 66.0,
      "learning_rate": 0.09340210337209677,
      "loss": 1.1396,
      "step": 40920
    },
    {
      "epoch": 66.0,
      "eval_accuracy": {
        "accuracy": 0.7306221216142378
      },
      "eval_loss": 1.3859057426452637,
      "eval_runtime": 3.5587,
      "eval_samples_per_second": 3599.936,
      "eval_steps_per_second": 56.482,
      "step": 40920
    },
    {
      "epoch": 66.03,
      "learning_rate": 0.09339887756887097,
      "loss": 1.1367,
      "step": 40940
    },
    {
      "epoch": 66.06,
      "learning_rate": 0.09339565176564517,
      "loss": 1.1271,
      "step": 40960
    },
    {
      "epoch": 66.1,
      "learning_rate": 0.09339242596241935,
      "loss": 1.1086,
      "step": 40980
    },
    {
      "epoch": 66.13,
      "learning_rate": 0.09338920015919355,
      "loss": 1.1228,
      "step": 41000
    },
    {
      "epoch": 66.16,
      "learning_rate": 0.09338597435596775,
      "loss": 1.1255,
      "step": 41020
    },
    {
      "epoch": 66.19,
      "learning_rate": 0.09338274855274194,
      "loss": 1.1184,
      "step": 41040
    },
    {
      "epoch": 66.23,
      "learning_rate": 0.09337952274951614,
      "loss": 1.1008,
      "step": 41060
    },
    {
      "epoch": 66.26,
      "learning_rate": 0.09337629694629034,
      "loss": 1.0895,
      "step": 41080
    },
    {
      "epoch": 66.29,
      "learning_rate": 0.09337307114306452,
      "loss": 1.0837,
      "step": 41100
    },
    {
      "epoch": 66.32,
      "learning_rate": 0.09336984533983872,
      "loss": 1.1096,
      "step": 41120
    },
    {
      "epoch": 66.35,
      "learning_rate": 0.09336661953661292,
      "loss": 1.1157,
      "step": 41140
    },
    {
      "epoch": 66.39,
      "learning_rate": 0.0933633937333871,
      "loss": 1.1125,
      "step": 41160
    },
    {
      "epoch": 66.42,
      "learning_rate": 0.0933601679301613,
      "loss": 1.1645,
      "step": 41180
    },
    {
      "epoch": 66.45,
      "learning_rate": 0.09335694212693549,
      "loss": 1.1374,
      "step": 41200
    },
    {
      "epoch": 66.48,
      "learning_rate": 0.09335371632370969,
      "loss": 1.1548,
      "step": 41220
    },
    {
      "epoch": 66.52,
      "learning_rate": 0.09335049052048387,
      "loss": 1.1435,
      "step": 41240
    },
    {
      "epoch": 66.55,
      "learning_rate": 0.09334726471725807,
      "loss": 1.1277,
      "step": 41260
    },
    {
      "epoch": 66.58,
      "learning_rate": 0.09334403891403226,
      "loss": 1.0895,
      "step": 41280
    },
    {
      "epoch": 66.61,
      "learning_rate": 0.09334081311080646,
      "loss": 1.1683,
      "step": 41300
    },
    {
      "epoch": 66.65,
      "learning_rate": 0.09333758730758066,
      "loss": 1.1594,
      "step": 41320
    },
    {
      "epoch": 66.68,
      "learning_rate": 0.09333436150435484,
      "loss": 1.1553,
      "step": 41340
    },
    {
      "epoch": 66.71,
      "learning_rate": 0.09333113570112904,
      "loss": 1.1714,
      "step": 41360
    },
    {
      "epoch": 66.74,
      "learning_rate": 0.09332790989790324,
      "loss": 1.1734,
      "step": 41380
    },
    {
      "epoch": 66.77,
      "learning_rate": 0.09332468409467742,
      "loss": 1.1446,
      "step": 41400
    },
    {
      "epoch": 66.81,
      "learning_rate": 0.09332145829145162,
      "loss": 1.121,
      "step": 41420
    },
    {
      "epoch": 66.84,
      "learning_rate": 0.09331823248822581,
      "loss": 1.1149,
      "step": 41440
    },
    {
      "epoch": 66.87,
      "learning_rate": 0.09331500668500001,
      "loss": 1.1218,
      "step": 41460
    },
    {
      "epoch": 66.9,
      "learning_rate": 0.0933117808817742,
      "loss": 1.1296,
      "step": 41480
    },
    {
      "epoch": 66.94,
      "learning_rate": 0.09330855507854839,
      "loss": 1.1333,
      "step": 41500
    },
    {
      "epoch": 66.97,
      "learning_rate": 0.09330532927532259,
      "loss": 1.1634,
      "step": 41520
    },
    {
      "epoch": 67.0,
      "learning_rate": 0.09330210347209678,
      "loss": 1.1419,
      "step": 41540
    },
    {
      "epoch": 67.0,
      "eval_accuracy": {
        "accuracy": 0.7261728202326126
      },
      "eval_loss": 1.4231979846954346,
      "eval_runtime": 2.6825,
      "eval_samples_per_second": 4775.716,
      "eval_steps_per_second": 74.929,
      "step": 41540
    },
    {
      "epoch": 67.03,
      "learning_rate": 0.09329887766887097,
      "loss": 1.1752,
      "step": 41560
    },
    {
      "epoch": 67.06,
      "learning_rate": 0.09329565186564516,
      "loss": 1.1349,
      "step": 41580
    },
    {
      "epoch": 67.1,
      "learning_rate": 0.09329242606241936,
      "loss": 1.1161,
      "step": 41600
    },
    {
      "epoch": 67.13,
      "learning_rate": 0.09328920025919356,
      "loss": 1.1402,
      "step": 41620
    },
    {
      "epoch": 67.16,
      "learning_rate": 0.09328597445596774,
      "loss": 1.155,
      "step": 41640
    },
    {
      "epoch": 67.19,
      "learning_rate": 0.09328274865274194,
      "loss": 1.1897,
      "step": 41660
    },
    {
      "epoch": 67.23,
      "learning_rate": 0.09327952284951613,
      "loss": 1.147,
      "step": 41680
    },
    {
      "epoch": 67.26,
      "learning_rate": 0.09327629704629033,
      "loss": 1.1345,
      "step": 41700
    },
    {
      "epoch": 67.29,
      "learning_rate": 0.09327307124306453,
      "loss": 1.1017,
      "step": 41720
    },
    {
      "epoch": 67.32,
      "learning_rate": 0.09326984543983871,
      "loss": 1.1205,
      "step": 41740
    },
    {
      "epoch": 67.35,
      "learning_rate": 0.09326661963661291,
      "loss": 1.0986,
      "step": 41760
    },
    {
      "epoch": 67.39,
      "learning_rate": 0.09326339383338711,
      "loss": 1.0774,
      "step": 41780
    },
    {
      "epoch": 67.42,
      "learning_rate": 0.0932601680301613,
      "loss": 1.1125,
      "step": 41800
    },
    {
      "epoch": 67.45,
      "learning_rate": 0.0932569422269355,
      "loss": 1.1373,
      "step": 41820
    },
    {
      "epoch": 67.48,
      "learning_rate": 0.09325371642370968,
      "loss": 1.0928,
      "step": 41840
    },
    {
      "epoch": 67.52,
      "learning_rate": 0.09325049062048388,
      "loss": 1.1063,
      "step": 41860
    },
    {
      "epoch": 67.55,
      "learning_rate": 0.09324726481725806,
      "loss": 1.1456,
      "step": 41880
    },
    {
      "epoch": 67.58,
      "learning_rate": 0.09324403901403226,
      "loss": 1.1603,
      "step": 41900
    },
    {
      "epoch": 67.61,
      "learning_rate": 0.09324081321080646,
      "loss": 1.148,
      "step": 41920
    },
    {
      "epoch": 67.65,
      "learning_rate": 0.09323758740758065,
      "loss": 1.2035,
      "step": 41940
    },
    {
      "epoch": 67.68,
      "learning_rate": 0.09323436160435485,
      "loss": 1.1703,
      "step": 41960
    },
    {
      "epoch": 67.71,
      "learning_rate": 0.09323113580112903,
      "loss": 1.1323,
      "step": 41980
    },
    {
      "epoch": 67.74,
      "learning_rate": 0.09322790999790323,
      "loss": 1.1655,
      "step": 42000
    },
    {
      "epoch": 67.77,
      "learning_rate": 0.09322468419467743,
      "loss": 1.1158,
      "step": 42020
    },
    {
      "epoch": 67.81,
      "learning_rate": 0.09322145839145161,
      "loss": 1.1338,
      "step": 42040
    },
    {
      "epoch": 67.84,
      "learning_rate": 0.09321823258822581,
      "loss": 1.1254,
      "step": 42060
    },
    {
      "epoch": 67.87,
      "learning_rate": 0.09321500678500001,
      "loss": 1.158,
      "step": 42080
    },
    {
      "epoch": 67.9,
      "learning_rate": 0.0932117809817742,
      "loss": 1.1438,
      "step": 42100
    },
    {
      "epoch": 67.94,
      "learning_rate": 0.0932085551785484,
      "loss": 1.1432,
      "step": 42120
    },
    {
      "epoch": 67.97,
      "learning_rate": 0.09320532937532258,
      "loss": 1.1197,
      "step": 42140
    },
    {
      "epoch": 68.0,
      "learning_rate": 0.09320210357209678,
      "loss": 1.0961,
      "step": 42160
    },
    {
      "epoch": 68.0,
      "eval_accuracy": {
        "accuracy": 0.7276559206931543
      },
      "eval_loss": 1.4156924486160278,
      "eval_runtime": 2.6407,
      "eval_samples_per_second": 4851.412,
      "eval_steps_per_second": 76.117,
      "step": 42160
    },
    {
      "epoch": 68.03,
      "learning_rate": 0.09319887776887097,
      "loss": 1.1478,
      "step": 42180
    },
    {
      "epoch": 68.06,
      "learning_rate": 0.09319565196564517,
      "loss": 1.144,
      "step": 42200
    },
    {
      "epoch": 68.1,
      "learning_rate": 0.09319242616241935,
      "loss": 1.1209,
      "step": 42220
    },
    {
      "epoch": 68.13,
      "learning_rate": 0.09318920035919355,
      "loss": 1.1259,
      "step": 42240
    },
    {
      "epoch": 68.16,
      "learning_rate": 0.09318597455596775,
      "loss": 1.1247,
      "step": 42260
    },
    {
      "epoch": 68.19,
      "learning_rate": 0.09318274875274193,
      "loss": 1.1039,
      "step": 42280
    },
    {
      "epoch": 68.23,
      "learning_rate": 0.09317952294951613,
      "loss": 1.1407,
      "step": 42300
    },
    {
      "epoch": 68.26,
      "learning_rate": 0.09317629714629033,
      "loss": 1.1172,
      "step": 42320
    },
    {
      "epoch": 68.29,
      "learning_rate": 0.09317307134306452,
      "loss": 1.1185,
      "step": 42340
    },
    {
      "epoch": 68.32,
      "learning_rate": 0.09317000683,
      "loss": 1.1484,
      "step": 42360
    },
    {
      "epoch": 68.35,
      "learning_rate": 0.0931667810267742,
      "loss": 1.152,
      "step": 42380
    },
    {
      "epoch": 68.39,
      "learning_rate": 0.0931635552235484,
      "loss": 1.1423,
      "step": 42400
    },
    {
      "epoch": 68.42,
      "learning_rate": 0.09316032942032258,
      "loss": 1.0922,
      "step": 42420
    },
    {
      "epoch": 68.45,
      "learning_rate": 0.09315710361709678,
      "loss": 1.1223,
      "step": 42440
    },
    {
      "epoch": 68.48,
      "learning_rate": 0.09315387781387098,
      "loss": 1.1261,
      "step": 42460
    },
    {
      "epoch": 68.52,
      "learning_rate": 0.09315065201064517,
      "loss": 1.1751,
      "step": 42480
    },
    {
      "epoch": 68.55,
      "learning_rate": 0.09314742620741936,
      "loss": 1.0881,
      "step": 42500
    },
    {
      "epoch": 68.58,
      "learning_rate": 0.09314420040419355,
      "loss": 1.1374,
      "step": 42520
    },
    {
      "epoch": 68.61,
      "learning_rate": 0.09314097460096775,
      "loss": 1.1234,
      "step": 42540
    },
    {
      "epoch": 68.65,
      "learning_rate": 0.09313774879774195,
      "loss": 1.1316,
      "step": 42560
    },
    {
      "epoch": 68.68,
      "learning_rate": 0.09313452299451613,
      "loss": 1.1193,
      "step": 42580
    },
    {
      "epoch": 68.71,
      "learning_rate": 0.09313129719129033,
      "loss": 1.2037,
      "step": 42600
    },
    {
      "epoch": 68.74,
      "learning_rate": 0.09312807138806452,
      "loss": 1.1667,
      "step": 42620
    },
    {
      "epoch": 68.77,
      "learning_rate": 0.09312484558483872,
      "loss": 1.1498,
      "step": 42640
    },
    {
      "epoch": 68.81,
      "learning_rate": 0.0931216197816129,
      "loss": 1.157,
      "step": 42660
    },
    {
      "epoch": 68.84,
      "learning_rate": 0.0931183939783871,
      "loss": 1.1521,
      "step": 42680
    },
    {
      "epoch": 68.87,
      "learning_rate": 0.0931151681751613,
      "loss": 1.1017,
      "step": 42700
    },
    {
      "epoch": 68.9,
      "learning_rate": 0.09311194237193549,
      "loss": 1.1281,
      "step": 42720
    },
    {
      "epoch": 68.94,
      "learning_rate": 0.09310871656870968,
      "loss": 1.1353,
      "step": 42740
    },
    {
      "epoch": 68.97,
      "learning_rate": 0.09310549076548388,
      "loss": 1.0872,
      "step": 42760
    },
    {
      "epoch": 69.0,
      "learning_rate": 0.09310226496225807,
      "loss": 1.067,
      "step": 42780
    },
    {
      "epoch": 69.0,
      "eval_accuracy": {
        "accuracy": 0.7277339786121302
      },
      "eval_loss": 1.4394416809082031,
      "eval_runtime": 2.5685,
      "eval_samples_per_second": 4987.696,
      "eval_steps_per_second": 78.255,
      "step": 42780
    },
    {
      "epoch": 69.03,
      "learning_rate": 0.09309903915903227,
      "loss": 1.1847,
      "step": 42800
    },
    {
      "epoch": 69.06,
      "learning_rate": 0.09309581335580645,
      "loss": 1.1238,
      "step": 42820
    },
    {
      "epoch": 69.1,
      "learning_rate": 0.09309258755258065,
      "loss": 1.1022,
      "step": 42840
    },
    {
      "epoch": 69.13,
      "learning_rate": 0.09308936174935485,
      "loss": 1.0988,
      "step": 42860
    },
    {
      "epoch": 69.16,
      "learning_rate": 0.09308613594612904,
      "loss": 1.0961,
      "step": 42880
    },
    {
      "epoch": 69.19,
      "learning_rate": 0.09308291014290324,
      "loss": 1.1017,
      "step": 42900
    },
    {
      "epoch": 69.23,
      "learning_rate": 0.09307968433967742,
      "loss": 1.137,
      "step": 42920
    },
    {
      "epoch": 69.26,
      "learning_rate": 0.09307645853645162,
      "loss": 1.125,
      "step": 42940
    },
    {
      "epoch": 69.29,
      "learning_rate": 0.0930732327332258,
      "loss": 1.0878,
      "step": 42960
    },
    {
      "epoch": 69.32,
      "learning_rate": 0.09307000693,
      "loss": 1.1249,
      "step": 42980
    },
    {
      "epoch": 69.35,
      "learning_rate": 0.0930667811267742,
      "loss": 1.1015,
      "step": 43000
    },
    {
      "epoch": 69.39,
      "learning_rate": 0.09306355532354839,
      "loss": 1.1214,
      "step": 43020
    },
    {
      "epoch": 69.42,
      "learning_rate": 0.09306032952032259,
      "loss": 1.1242,
      "step": 43040
    },
    {
      "epoch": 69.45,
      "learning_rate": 0.09305710371709677,
      "loss": 1.1474,
      "step": 43060
    },
    {
      "epoch": 69.48,
      "learning_rate": 0.09305387791387097,
      "loss": 1.1608,
      "step": 43080
    },
    {
      "epoch": 69.52,
      "learning_rate": 0.09305065211064517,
      "loss": 1.1274,
      "step": 43100
    },
    {
      "epoch": 69.55,
      "learning_rate": 0.09304742630741936,
      "loss": 1.1535,
      "step": 43120
    },
    {
      "epoch": 69.58,
      "learning_rate": 0.09304420050419356,
      "loss": 1.1248,
      "step": 43140
    },
    {
      "epoch": 69.61,
      "learning_rate": 0.09304097470096775,
      "loss": 1.1164,
      "step": 43160
    },
    {
      "epoch": 69.65,
      "learning_rate": 0.09303774889774194,
      "loss": 1.0938,
      "step": 43180
    },
    {
      "epoch": 69.68,
      "learning_rate": 0.09303452309451614,
      "loss": 1.1459,
      "step": 43200
    },
    {
      "epoch": 69.71,
      "learning_rate": 0.09303129729129032,
      "loss": 1.1584,
      "step": 43220
    },
    {
      "epoch": 69.74,
      "learning_rate": 0.09302807148806452,
      "loss": 1.1566,
      "step": 43240
    },
    {
      "epoch": 69.77,
      "learning_rate": 0.09302484568483871,
      "loss": 1.1224,
      "step": 43260
    },
    {
      "epoch": 69.81,
      "learning_rate": 0.09302161988161291,
      "loss": 1.1336,
      "step": 43280
    },
    {
      "epoch": 69.84,
      "learning_rate": 0.09301839407838709,
      "loss": 1.1423,
      "step": 43300
    },
    {
      "epoch": 69.87,
      "learning_rate": 0.09301516827516129,
      "loss": 1.1607,
      "step": 43320
    },
    {
      "epoch": 69.9,
      "learning_rate": 0.09301194247193549,
      "loss": 1.1252,
      "step": 43340
    },
    {
      "epoch": 69.94,
      "learning_rate": 0.09300871666870968,
      "loss": 1.0945,
      "step": 43360
    },
    {
      "epoch": 69.97,
      "learning_rate": 0.09300549086548388,
      "loss": 1.1236,
      "step": 43380
    },
    {
      "epoch": 70.0,
      "learning_rate": 0.09300226506225807,
      "loss": 1.0924,
      "step": 43400
    },
    {
      "epoch": 70.0,
      "eval_accuracy": {
        "accuracy": 0.7287487315588166
      },
      "eval_loss": 1.4182242155075073,
      "eval_runtime": 3.136,
      "eval_samples_per_second": 4085.16,
      "eval_steps_per_second": 64.095,
      "step": 43400
    },
    {
      "epoch": 70.03,
      "learning_rate": 0.09299903925903226,
      "loss": 1.1136,
      "step": 43420
    },
    {
      "epoch": 70.06,
      "learning_rate": 0.09299581345580646,
      "loss": 1.1161,
      "step": 43440
    },
    {
      "epoch": 70.1,
      "learning_rate": 0.09299258765258066,
      "loss": 1.0954,
      "step": 43460
    },
    {
      "epoch": 70.13,
      "learning_rate": 0.09298936184935484,
      "loss": 1.1234,
      "step": 43480
    },
    {
      "epoch": 70.16,
      "learning_rate": 0.09298613604612904,
      "loss": 1.1228,
      "step": 43500
    },
    {
      "epoch": 70.19,
      "learning_rate": 0.09298291024290323,
      "loss": 1.117,
      "step": 43520
    },
    {
      "epoch": 70.23,
      "learning_rate": 0.09297968443967743,
      "loss": 1.1168,
      "step": 43540
    },
    {
      "epoch": 70.26,
      "learning_rate": 0.09297645863645161,
      "loss": 1.1409,
      "step": 43560
    },
    {
      "epoch": 70.29,
      "learning_rate": 0.09297323283322581,
      "loss": 1.1528,
      "step": 43580
    },
    {
      "epoch": 70.32,
      "learning_rate": 0.09297000703,
      "loss": 1.1291,
      "step": 43600
    },
    {
      "epoch": 70.35,
      "learning_rate": 0.0929667812267742,
      "loss": 1.1316,
      "step": 43620
    },
    {
      "epoch": 70.39,
      "learning_rate": 0.0929635554235484,
      "loss": 1.1231,
      "step": 43640
    },
    {
      "epoch": 70.42,
      "learning_rate": 0.09296032962032258,
      "loss": 1.1041,
      "step": 43660
    },
    {
      "epoch": 70.45,
      "learning_rate": 0.09295710381709678,
      "loss": 1.1333,
      "step": 43680
    },
    {
      "epoch": 70.48,
      "learning_rate": 0.09295387801387098,
      "loss": 1.1242,
      "step": 43700
    },
    {
      "epoch": 70.52,
      "learning_rate": 0.09295065221064516,
      "loss": 1.0802,
      "step": 43720
    },
    {
      "epoch": 70.55,
      "learning_rate": 0.09294742640741936,
      "loss": 1.1181,
      "step": 43740
    },
    {
      "epoch": 70.58,
      "learning_rate": 0.09294420060419356,
      "loss": 1.0839,
      "step": 43760
    },
    {
      "epoch": 70.61,
      "learning_rate": 0.09294097480096775,
      "loss": 1.0998,
      "step": 43780
    },
    {
      "epoch": 70.65,
      "learning_rate": 0.09293774899774195,
      "loss": 1.0986,
      "step": 43800
    },
    {
      "epoch": 70.68,
      "learning_rate": 0.09293452319451613,
      "loss": 1.1431,
      "step": 43820
    },
    {
      "epoch": 70.71,
      "learning_rate": 0.09293129739129033,
      "loss": 1.1503,
      "step": 43840
    },
    {
      "epoch": 70.74,
      "learning_rate": 0.09292807158806451,
      "loss": 1.0912,
      "step": 43860
    },
    {
      "epoch": 70.77,
      "learning_rate": 0.09292484578483871,
      "loss": 1.1144,
      "step": 43880
    },
    {
      "epoch": 70.81,
      "learning_rate": 0.0929216199816129,
      "loss": 1.1215,
      "step": 43900
    },
    {
      "epoch": 70.84,
      "learning_rate": 0.0929183941783871,
      "loss": 1.1306,
      "step": 43920
    },
    {
      "epoch": 70.87,
      "learning_rate": 0.0929151683751613,
      "loss": 1.1297,
      "step": 43940
    },
    {
      "epoch": 70.9,
      "learning_rate": 0.09291194257193548,
      "loss": 1.1356,
      "step": 43960
    },
    {
      "epoch": 70.94,
      "learning_rate": 0.09290871676870968,
      "loss": 1.1328,
      "step": 43980
    },
    {
      "epoch": 70.97,
      "learning_rate": 0.09290549096548388,
      "loss": 1.14,
      "step": 44000
    },
    {
      "epoch": 71.0,
      "learning_rate": 0.09290226516225807,
      "loss": 1.1287,
      "step": 44020
    },
    {
      "epoch": 71.0,
      "eval_accuracy": {
        "accuracy": 0.7288267894777926
      },
      "eval_loss": 1.4055895805358887,
      "eval_runtime": 3.3461,
      "eval_samples_per_second": 3828.6,
      "eval_steps_per_second": 60.069,
      "step": 44020
    },
    {
      "epoch": 71.03,
      "learning_rate": 0.09289903935903226,
      "loss": 1.1278,
      "step": 44040
    },
    {
      "epoch": 71.06,
      "learning_rate": 0.09289581355580646,
      "loss": 1.1434,
      "step": 44060
    },
    {
      "epoch": 71.1,
      "learning_rate": 0.09289258775258065,
      "loss": 1.1297,
      "step": 44080
    },
    {
      "epoch": 71.13,
      "learning_rate": 0.09288936194935485,
      "loss": 1.1256,
      "step": 44100
    },
    {
      "epoch": 71.16,
      "learning_rate": 0.09288613614612905,
      "loss": 1.0997,
      "step": 44120
    },
    {
      "epoch": 71.19,
      "learning_rate": 0.09288291034290323,
      "loss": 1.0928,
      "step": 44140
    },
    {
      "epoch": 71.23,
      "learning_rate": 0.09287968453967742,
      "loss": 1.0877,
      "step": 44160
    },
    {
      "epoch": 71.26,
      "learning_rate": 0.09287645873645162,
      "loss": 1.1206,
      "step": 44180
    },
    {
      "epoch": 71.29,
      "learning_rate": 0.0928732329332258,
      "loss": 1.1364,
      "step": 44200
    },
    {
      "epoch": 71.32,
      "learning_rate": 0.09287000713,
      "loss": 1.092,
      "step": 44220
    },
    {
      "epoch": 71.35,
      "learning_rate": 0.0928667813267742,
      "loss": 1.0919,
      "step": 44240
    },
    {
      "epoch": 71.39,
      "learning_rate": 0.09286355552354839,
      "loss": 1.0982,
      "step": 44260
    },
    {
      "epoch": 71.42,
      "learning_rate": 0.09286032972032258,
      "loss": 1.075,
      "step": 44280
    },
    {
      "epoch": 71.45,
      "learning_rate": 0.09285710391709678,
      "loss": 1.123,
      "step": 44300
    },
    {
      "epoch": 71.48,
      "learning_rate": 0.09285387811387097,
      "loss": 1.095,
      "step": 44320
    },
    {
      "epoch": 71.52,
      "learning_rate": 0.09285065231064517,
      "loss": 1.1236,
      "step": 44340
    },
    {
      "epoch": 71.55,
      "learning_rate": 0.09284742650741937,
      "loss": 1.1345,
      "step": 44360
    },
    {
      "epoch": 71.58,
      "learning_rate": 0.09284420070419355,
      "loss": 1.1222,
      "step": 44380
    },
    {
      "epoch": 71.61,
      "learning_rate": 0.09284097490096775,
      "loss": 1.0983,
      "step": 44400
    },
    {
      "epoch": 71.65,
      "learning_rate": 0.09283774909774195,
      "loss": 1.107,
      "step": 44420
    },
    {
      "epoch": 71.68,
      "learning_rate": 0.09283452329451614,
      "loss": 1.1499,
      "step": 44440
    },
    {
      "epoch": 71.71,
      "learning_rate": 0.09283129749129032,
      "loss": 1.1093,
      "step": 44460
    },
    {
      "epoch": 71.74,
      "learning_rate": 0.09282807168806452,
      "loss": 1.1183,
      "step": 44480
    },
    {
      "epoch": 71.77,
      "learning_rate": 0.0928248458848387,
      "loss": 1.0992,
      "step": 44500
    },
    {
      "epoch": 71.81,
      "learning_rate": 0.0928216200816129,
      "loss": 1.1181,
      "step": 44520
    },
    {
      "epoch": 71.84,
      "learning_rate": 0.0928183942783871,
      "loss": 1.1394,
      "step": 44540
    },
    {
      "epoch": 71.87,
      "learning_rate": 0.09281516847516129,
      "loss": 1.1337,
      "step": 44560
    },
    {
      "epoch": 71.9,
      "learning_rate": 0.09281194267193549,
      "loss": 1.1296,
      "step": 44580
    },
    {
      "epoch": 71.94,
      "learning_rate": 0.09280871686870969,
      "loss": 1.1689,
      "step": 44600
    },
    {
      "epoch": 71.97,
      "learning_rate": 0.09280565235564517,
      "loss": 1.1343,
      "step": 44620
    },
    {
      "epoch": 72.0,
      "learning_rate": 0.09280242655241935,
      "loss": 1.1413,
      "step": 44640
    },
    {
      "epoch": 72.0,
      "eval_accuracy": {
        "accuracy": 0.7273436890172508
      },
      "eval_loss": 1.4893027544021606,
      "eval_runtime": 3.1561,
      "eval_samples_per_second": 4059.167,
      "eval_steps_per_second": 63.687,
      "step": 44640
    },
    {
      "epoch": 72.03,
      "learning_rate": 0.09279920074919355,
      "loss": 1.1879,
      "step": 44660
    },
    {
      "epoch": 72.06,
      "learning_rate": 0.09279597494596774,
      "loss": 1.1008,
      "step": 44680
    },
    {
      "epoch": 72.1,
      "learning_rate": 0.09279274914274194,
      "loss": 1.0942,
      "step": 44700
    },
    {
      "epoch": 72.13,
      "learning_rate": 0.09278952333951614,
      "loss": 1.1118,
      "step": 44720
    },
    {
      "epoch": 72.16,
      "learning_rate": 0.09278629753629032,
      "loss": 1.1186,
      "step": 44740
    },
    {
      "epoch": 72.19,
      "learning_rate": 0.09278307173306452,
      "loss": 1.1125,
      "step": 44760
    },
    {
      "epoch": 72.23,
      "learning_rate": 0.09277984592983872,
      "loss": 1.1283,
      "step": 44780
    },
    {
      "epoch": 72.26,
      "learning_rate": 0.0927766201266129,
      "loss": 1.1058,
      "step": 44800
    },
    {
      "epoch": 72.29,
      "learning_rate": 0.0927733943233871,
      "loss": 1.1029,
      "step": 44820
    },
    {
      "epoch": 72.32,
      "learning_rate": 0.0927701685201613,
      "loss": 1.1014,
      "step": 44840
    },
    {
      "epoch": 72.35,
      "learning_rate": 0.09276694271693549,
      "loss": 1.1234,
      "step": 44860
    },
    {
      "epoch": 72.39,
      "learning_rate": 0.09276371691370969,
      "loss": 1.1086,
      "step": 44880
    },
    {
      "epoch": 72.42,
      "learning_rate": 0.09276049111048387,
      "loss": 1.1438,
      "step": 44900
    },
    {
      "epoch": 72.45,
      "learning_rate": 0.09275726530725807,
      "loss": 1.1177,
      "step": 44920
    },
    {
      "epoch": 72.48,
      "learning_rate": 0.09275403950403226,
      "loss": 1.0924,
      "step": 44940
    },
    {
      "epoch": 72.52,
      "learning_rate": 0.09275081370080646,
      "loss": 1.1133,
      "step": 44960
    },
    {
      "epoch": 72.55,
      "learning_rate": 0.09274758789758064,
      "loss": 1.1177,
      "step": 44980
    },
    {
      "epoch": 72.58,
      "learning_rate": 0.09274436209435484,
      "loss": 1.129,
      "step": 45000
    },
    {
      "epoch": 72.61,
      "learning_rate": 0.09274113629112904,
      "loss": 1.1244,
      "step": 45020
    },
    {
      "epoch": 72.65,
      "learning_rate": 0.09273791048790322,
      "loss": 1.0934,
      "step": 45040
    },
    {
      "epoch": 72.68,
      "learning_rate": 0.09273468468467742,
      "loss": 1.1452,
      "step": 45060
    },
    {
      "epoch": 72.71,
      "learning_rate": 0.09273145888145162,
      "loss": 1.1344,
      "step": 45080
    },
    {
      "epoch": 72.74,
      "learning_rate": 0.09272823307822581,
      "loss": 1.1311,
      "step": 45100
    },
    {
      "epoch": 72.77,
      "learning_rate": 0.09272500727500001,
      "loss": 1.1979,
      "step": 45120
    },
    {
      "epoch": 72.81,
      "learning_rate": 0.0927217814717742,
      "loss": 1.1596,
      "step": 45140
    },
    {
      "epoch": 72.84,
      "learning_rate": 0.09271855566854839,
      "loss": 1.163,
      "step": 45160
    },
    {
      "epoch": 72.87,
      "learning_rate": 0.09271532986532259,
      "loss": 1.1177,
      "step": 45180
    },
    {
      "epoch": 72.9,
      "learning_rate": 0.09271210406209679,
      "loss": 1.0846,
      "step": 45200
    },
    {
      "epoch": 72.94,
      "learning_rate": 0.09270887825887097,
      "loss": 1.1019,
      "step": 45220
    },
    {
      "epoch": 72.97,
      "learning_rate": 0.09270565245564516,
      "loss": 1.1204,
      "step": 45240
    },
    {
      "epoch": 73.0,
      "learning_rate": 0.09270242665241936,
      "loss": 1.1666,
      "step": 45260
    },
    {
      "epoch": 73.0,
      "eval_accuracy": {
        "accuracy": 0.7274217469362266
      },
      "eval_loss": 1.4862561225891113,
      "eval_runtime": 10.7393,
      "eval_samples_per_second": 1192.91,
      "eval_steps_per_second": 18.716,
      "step": 45260
    },
    {
      "epoch": 73.03,
      "learning_rate": 0.09269920084919354,
      "loss": 1.1837,
      "step": 45280
    },
    {
      "epoch": 73.06,
      "learning_rate": 0.09269597504596774,
      "loss": 1.0969,
      "step": 45300
    },
    {
      "epoch": 73.1,
      "learning_rate": 0.09269274924274194,
      "loss": 1.1089,
      "step": 45320
    },
    {
      "epoch": 73.13,
      "learning_rate": 0.09268952343951613,
      "loss": 1.0927,
      "step": 45340
    },
    {
      "epoch": 73.16,
      "learning_rate": 0.09268629763629033,
      "loss": 1.1219,
      "step": 45360
    },
    {
      "epoch": 73.19,
      "learning_rate": 0.09268307183306453,
      "loss": 1.1,
      "step": 45380
    },
    {
      "epoch": 73.23,
      "learning_rate": 0.09267984602983871,
      "loss": 1.1008,
      "step": 45400
    },
    {
      "epoch": 73.26,
      "learning_rate": 0.09267662022661291,
      "loss": 1.1053,
      "step": 45420
    },
    {
      "epoch": 73.29,
      "learning_rate": 0.09267339442338711,
      "loss": 1.125,
      "step": 45440
    },
    {
      "epoch": 73.32,
      "learning_rate": 0.0926701686201613,
      "loss": 1.143,
      "step": 45460
    },
    {
      "epoch": 73.35,
      "learning_rate": 0.0926669428169355,
      "loss": 1.1047,
      "step": 45480
    },
    {
      "epoch": 73.39,
      "learning_rate": 0.09266371701370969,
      "loss": 1.0945,
      "step": 45500
    },
    {
      "epoch": 73.42,
      "learning_rate": 0.09266049121048388,
      "loss": 1.0742,
      "step": 45520
    },
    {
      "epoch": 73.45,
      "learning_rate": 0.09265726540725806,
      "loss": 1.0749,
      "step": 45540
    },
    {
      "epoch": 73.48,
      "learning_rate": 0.09265403960403226,
      "loss": 1.1025,
      "step": 45560
    },
    {
      "epoch": 73.52,
      "learning_rate": 0.09265081380080645,
      "loss": 1.1298,
      "step": 45580
    },
    {
      "epoch": 73.55,
      "learning_rate": 0.09264758799758065,
      "loss": 1.085,
      "step": 45600
    },
    {
      "epoch": 73.58,
      "learning_rate": 0.09264436219435485,
      "loss": 1.1311,
      "step": 45620
    },
    {
      "epoch": 73.61,
      "learning_rate": 0.09264113639112903,
      "loss": 1.1075,
      "step": 45640
    },
    {
      "epoch": 73.65,
      "learning_rate": 0.09263791058790323,
      "loss": 1.0746,
      "step": 45660
    },
    {
      "epoch": 73.68,
      "learning_rate": 0.09263468478467743,
      "loss": 1.1083,
      "step": 45680
    },
    {
      "epoch": 73.71,
      "learning_rate": 0.09263145898145161,
      "loss": 1.1014,
      "step": 45700
    },
    {
      "epoch": 73.74,
      "learning_rate": 0.09262823317822581,
      "loss": 1.1122,
      "step": 45720
    },
    {
      "epoch": 73.77,
      "learning_rate": 0.09262500737500001,
      "loss": 1.1089,
      "step": 45740
    },
    {
      "epoch": 73.81,
      "learning_rate": 0.0926217815717742,
      "loss": 1.1218,
      "step": 45760
    },
    {
      "epoch": 73.84,
      "learning_rate": 0.0926185557685484,
      "loss": 1.1311,
      "step": 45780
    },
    {
      "epoch": 73.87,
      "learning_rate": 0.0926153299653226,
      "loss": 1.113,
      "step": 45800
    },
    {
      "epoch": 73.9,
      "learning_rate": 0.09261210416209678,
      "loss": 1.1255,
      "step": 45820
    },
    {
      "epoch": 73.94,
      "learning_rate": 0.09260887835887097,
      "loss": 1.1148,
      "step": 45840
    },
    {
      "epoch": 73.97,
      "learning_rate": 0.09260565255564518,
      "loss": 1.1188,
      "step": 45860
    },
    {
      "epoch": 74.0,
      "learning_rate": 0.09260242675241935,
      "loss": 1.0917,
      "step": 45880
    },
    {
      "epoch": 74.0,
      "eval_accuracy": {
        "accuracy": 0.7271095152603232
      },
      "eval_loss": 1.4377607107162476,
      "eval_runtime": 2.8837,
      "eval_samples_per_second": 4442.565,
      "eval_steps_per_second": 69.702,
      "step": 45880
    },
    {
      "epoch": 74.03,
      "learning_rate": 0.09259920094919355,
      "loss": 1.1532,
      "step": 45900
    },
    {
      "epoch": 74.06,
      "learning_rate": 0.09259597514596775,
      "loss": 1.0597,
      "step": 45920
    },
    {
      "epoch": 74.1,
      "learning_rate": 0.09259274934274193,
      "loss": 1.0814,
      "step": 45940
    },
    {
      "epoch": 74.13,
      "learning_rate": 0.09258952353951613,
      "loss": 1.0904,
      "step": 45960
    },
    {
      "epoch": 74.16,
      "learning_rate": 0.09258629773629033,
      "loss": 1.105,
      "step": 45980
    },
    {
      "epoch": 74.19,
      "learning_rate": 0.09258307193306452,
      "loss": 1.0839,
      "step": 46000
    },
    {
      "epoch": 74.23,
      "learning_rate": 0.09257984612983872,
      "loss": 1.0909,
      "step": 46020
    },
    {
      "epoch": 74.26,
      "learning_rate": 0.09257662032661292,
      "loss": 1.1297,
      "step": 46040
    },
    {
      "epoch": 74.29,
      "learning_rate": 0.0925733945233871,
      "loss": 1.1353,
      "step": 46060
    },
    {
      "epoch": 74.32,
      "learning_rate": 0.0925701687201613,
      "loss": 1.1246,
      "step": 46080
    },
    {
      "epoch": 74.35,
      "learning_rate": 0.0925669429169355,
      "loss": 1.1101,
      "step": 46100
    },
    {
      "epoch": 74.39,
      "learning_rate": 0.09256371711370968,
      "loss": 1.0978,
      "step": 46120
    },
    {
      "epoch": 74.42,
      "learning_rate": 0.09256049131048387,
      "loss": 1.1045,
      "step": 46140
    },
    {
      "epoch": 74.45,
      "learning_rate": 0.09255726550725808,
      "loss": 1.121,
      "step": 46160
    },
    {
      "epoch": 74.48,
      "learning_rate": 0.09255403970403225,
      "loss": 1.0785,
      "step": 46180
    },
    {
      "epoch": 74.52,
      "learning_rate": 0.09255081390080645,
      "loss": 1.1036,
      "step": 46200
    },
    {
      "epoch": 74.55,
      "learning_rate": 0.09254758809758065,
      "loss": 1.0979,
      "step": 46220
    },
    {
      "epoch": 74.58,
      "learning_rate": 0.09254436229435484,
      "loss": 1.1121,
      "step": 46240
    },
    {
      "epoch": 74.61,
      "learning_rate": 0.09254113649112904,
      "loss": 1.1033,
      "step": 46260
    },
    {
      "epoch": 74.65,
      "learning_rate": 0.09253791068790324,
      "loss": 1.1042,
      "step": 46280
    },
    {
      "epoch": 74.68,
      "learning_rate": 0.09253468488467742,
      "loss": 1.1372,
      "step": 46300
    },
    {
      "epoch": 74.71,
      "learning_rate": 0.09253145908145162,
      "loss": 1.1217,
      "step": 46320
    },
    {
      "epoch": 74.74,
      "learning_rate": 0.09252823327822582,
      "loss": 1.1678,
      "step": 46340
    },
    {
      "epoch": 74.77,
      "learning_rate": 0.092525007475,
      "loss": 1.1212,
      "step": 46360
    },
    {
      "epoch": 74.81,
      "learning_rate": 0.0925217816717742,
      "loss": 1.1631,
      "step": 46380
    },
    {
      "epoch": 74.84,
      "learning_rate": 0.0925185558685484,
      "loss": 1.1641,
      "step": 46400
    },
    {
      "epoch": 74.87,
      "learning_rate": 0.09251533006532259,
      "loss": 1.143,
      "step": 46420
    },
    {
      "epoch": 74.9,
      "learning_rate": 0.09251210426209679,
      "loss": 1.1007,
      "step": 46440
    },
    {
      "epoch": 74.94,
      "learning_rate": 0.09250887845887097,
      "loss": 1.1297,
      "step": 46460
    },
    {
      "epoch": 74.97,
      "learning_rate": 0.09250565265564516,
      "loss": 1.1004,
      "step": 46480
    },
    {
      "epoch": 75.0,
      "learning_rate": 0.09250242685241936,
      "loss": 1.121,
      "step": 46500
    },
    {
      "epoch": 75.0,
      "eval_accuracy": {
        "accuracy": 0.7301537741003825
      },
      "eval_loss": 1.3890368938446045,
      "eval_runtime": 3.4244,
      "eval_samples_per_second": 3741.138,
      "eval_steps_per_second": 58.697,
      "step": 46500
    },
    {
      "epoch": 75.03,
      "learning_rate": 0.09249920104919356,
      "loss": 1.15,
      "step": 46520
    },
    {
      "epoch": 75.06,
      "learning_rate": 0.09249597524596774,
      "loss": 1.1263,
      "step": 46540
    },
    {
      "epoch": 75.1,
      "learning_rate": 0.09249274944274194,
      "loss": 1.1096,
      "step": 46560
    },
    {
      "epoch": 75.13,
      "learning_rate": 0.09248952363951614,
      "loss": 1.1183,
      "step": 46580
    },
    {
      "epoch": 75.16,
      "learning_rate": 0.09248629783629032,
      "loss": 1.0845,
      "step": 46600
    },
    {
      "epoch": 75.19,
      "learning_rate": 0.09248307203306452,
      "loss": 1.074,
      "step": 46620
    },
    {
      "epoch": 75.23,
      "learning_rate": 0.09247984622983872,
      "loss": 1.0666,
      "step": 46640
    },
    {
      "epoch": 75.26,
      "learning_rate": 0.09247662042661291,
      "loss": 1.0902,
      "step": 46660
    },
    {
      "epoch": 75.29,
      "learning_rate": 0.0924733946233871,
      "loss": 1.1078,
      "step": 46680
    },
    {
      "epoch": 75.32,
      "learning_rate": 0.09247016882016129,
      "loss": 1.1156,
      "step": 46700
    },
    {
      "epoch": 75.35,
      "learning_rate": 0.09246694301693549,
      "loss": 1.1238,
      "step": 46720
    },
    {
      "epoch": 75.39,
      "learning_rate": 0.09246371721370969,
      "loss": 1.099,
      "step": 46740
    },
    {
      "epoch": 75.42,
      "learning_rate": 0.09246049141048387,
      "loss": 1.075,
      "step": 46760
    },
    {
      "epoch": 75.45,
      "learning_rate": 0.09245726560725806,
      "loss": 1.0971,
      "step": 46780
    },
    {
      "epoch": 75.48,
      "learning_rate": 0.09245403980403226,
      "loss": 1.123,
      "step": 46800
    },
    {
      "epoch": 75.52,
      "learning_rate": 0.09245081400080646,
      "loss": 1.1245,
      "step": 46820
    },
    {
      "epoch": 75.55,
      "learning_rate": 0.09244758819758064,
      "loss": 1.0822,
      "step": 46840
    },
    {
      "epoch": 75.58,
      "learning_rate": 0.09244436239435484,
      "loss": 1.1147,
      "step": 46860
    },
    {
      "epoch": 75.61,
      "learning_rate": 0.09244113659112904,
      "loss": 1.1416,
      "step": 46880
    },
    {
      "epoch": 75.65,
      "learning_rate": 0.09243791078790323,
      "loss": 1.1226,
      "step": 46900
    },
    {
      "epoch": 75.68,
      "learning_rate": 0.09243468498467743,
      "loss": 1.1337,
      "step": 46920
    },
    {
      "epoch": 75.71,
      "learning_rate": 0.09243145918145163,
      "loss": 1.1395,
      "step": 46940
    },
    {
      "epoch": 75.74,
      "learning_rate": 0.09242823337822581,
      "loss": 1.1243,
      "step": 46960
    },
    {
      "epoch": 75.77,
      "learning_rate": 0.09242516886516129,
      "loss": 1.1813,
      "step": 46980
    },
    {
      "epoch": 75.81,
      "learning_rate": 0.09242194306193549,
      "loss": 1.1642,
      "step": 47000
    },
    {
      "epoch": 75.84,
      "learning_rate": 0.09241871725870968,
      "loss": 1.1198,
      "step": 47020
    },
    {
      "epoch": 75.87,
      "learning_rate": 0.09241549145548388,
      "loss": 1.1118,
      "step": 47040
    },
    {
      "epoch": 75.9,
      "learning_rate": 0.09241226565225807,
      "loss": 1.0954,
      "step": 47060
    },
    {
      "epoch": 75.94,
      "learning_rate": 0.09240903984903226,
      "loss": 1.1159,
      "step": 47080
    },
    {
      "epoch": 75.97,
      "learning_rate": 0.09240581404580646,
      "loss": 1.0977,
      "step": 47100
    },
    {
      "epoch": 76.0,
      "learning_rate": 0.09240258824258066,
      "loss": 1.1005,
      "step": 47120
    },
    {
      "epoch": 76.0,
      "eval_accuracy": {
        "accuracy": 0.7206307079853251
      },
      "eval_loss": 1.4553661346435547,
      "eval_runtime": 2.5446,
      "eval_samples_per_second": 5034.5,
      "eval_steps_per_second": 78.99,
      "step": 47120
    },
    {
      "epoch": 76.03,
      "learning_rate": 0.09239936243935484,
      "loss": 1.1597,
      "step": 47140
    },
    {
      "epoch": 76.06,
      "learning_rate": 0.09239613663612904,
      "loss": 1.1023,
      "step": 47160
    },
    {
      "epoch": 76.1,
      "learning_rate": 0.09239291083290324,
      "loss": 1.0881,
      "step": 47180
    },
    {
      "epoch": 76.13,
      "learning_rate": 0.09238968502967743,
      "loss": 1.0871,
      "step": 47200
    },
    {
      "epoch": 76.16,
      "learning_rate": 0.09238645922645161,
      "loss": 1.1045,
      "step": 47220
    },
    {
      "epoch": 76.19,
      "learning_rate": 0.09238323342322582,
      "loss": 1.1178,
      "step": 47240
    },
    {
      "epoch": 76.23,
      "learning_rate": 0.09238000762,
      "loss": 1.111,
      "step": 47260
    },
    {
      "epoch": 76.26,
      "learning_rate": 0.0923767818167742,
      "loss": 1.0991,
      "step": 47280
    },
    {
      "epoch": 76.29,
      "learning_rate": 0.0923735560135484,
      "loss": 1.1038,
      "step": 47300
    },
    {
      "epoch": 76.32,
      "learning_rate": 0.09237033021032258,
      "loss": 1.1038,
      "step": 47320
    },
    {
      "epoch": 76.35,
      "learning_rate": 0.09236710440709678,
      "loss": 1.1115,
      "step": 47340
    },
    {
      "epoch": 76.39,
      "learning_rate": 0.09236387860387098,
      "loss": 1.1118,
      "step": 47360
    },
    {
      "epoch": 76.42,
      "learning_rate": 0.09236065280064516,
      "loss": 1.1308,
      "step": 47380
    },
    {
      "epoch": 76.45,
      "learning_rate": 0.09235742699741936,
      "loss": 1.1632,
      "step": 47400
    },
    {
      "epoch": 76.48,
      "learning_rate": 0.09235420119419356,
      "loss": 1.0836,
      "step": 47420
    },
    {
      "epoch": 76.52,
      "learning_rate": 0.09235097539096775,
      "loss": 1.1226,
      "step": 47440
    },
    {
      "epoch": 76.55,
      "learning_rate": 0.09234774958774195,
      "loss": 1.1086,
      "step": 47460
    },
    {
      "epoch": 76.58,
      "learning_rate": 0.09234452378451614,
      "loss": 1.1041,
      "step": 47480
    },
    {
      "epoch": 76.61,
      "learning_rate": 0.09234129798129033,
      "loss": 1.1263,
      "step": 47500
    },
    {
      "epoch": 76.65,
      "learning_rate": 0.09233807217806453,
      "loss": 1.1227,
      "step": 47520
    },
    {
      "epoch": 76.68,
      "learning_rate": 0.09233484637483871,
      "loss": 1.1251,
      "step": 47540
    },
    {
      "epoch": 76.71,
      "learning_rate": 0.0923316205716129,
      "loss": 1.1382,
      "step": 47560
    },
    {
      "epoch": 76.74,
      "learning_rate": 0.0923283947683871,
      "loss": 1.0999,
      "step": 47580
    },
    {
      "epoch": 76.77,
      "learning_rate": 0.0923251689651613,
      "loss": 1.134,
      "step": 47600
    },
    {
      "epoch": 76.81,
      "learning_rate": 0.09232194316193548,
      "loss": 1.1412,
      "step": 47620
    },
    {
      "epoch": 76.84,
      "learning_rate": 0.09231871735870968,
      "loss": 1.1262,
      "step": 47640
    },
    {
      "epoch": 76.87,
      "learning_rate": 0.09231549155548388,
      "loss": 1.0835,
      "step": 47660
    },
    {
      "epoch": 76.9,
      "learning_rate": 0.09231226575225807,
      "loss": 1.1116,
      "step": 47680
    },
    {
      "epoch": 76.94,
      "learning_rate": 0.09230903994903226,
      "loss": 1.0968,
      "step": 47700
    },
    {
      "epoch": 76.97,
      "learning_rate": 0.09230581414580646,
      "loss": 1.1336,
      "step": 47720
    },
    {
      "epoch": 77.0,
      "learning_rate": 0.09230258834258065,
      "loss": 1.1157,
      "step": 47740
    },
    {
      "epoch": 77.0,
      "eval_accuracy": {
        "accuracy": 0.733119975021466
      },
      "eval_loss": 1.4040613174438477,
      "eval_runtime": 3.0378,
      "eval_samples_per_second": 4217.129,
      "eval_steps_per_second": 66.165,
      "step": 47740
    },
    {
      "epoch": 77.03,
      "learning_rate": 0.09229936253935485,
      "loss": 1.1391,
      "step": 47760
    },
    {
      "epoch": 77.06,
      "learning_rate": 0.09229613673612903,
      "loss": 1.1251,
      "step": 47780
    },
    {
      "epoch": 77.1,
      "learning_rate": 0.09229291093290323,
      "loss": 1.0861,
      "step": 47800
    },
    {
      "epoch": 77.13,
      "learning_rate": 0.09228968512967743,
      "loss": 1.0689,
      "step": 47820
    },
    {
      "epoch": 77.16,
      "learning_rate": 0.09228645932645162,
      "loss": 1.0896,
      "step": 47840
    },
    {
      "epoch": 77.19,
      "learning_rate": 0.0922832335232258,
      "loss": 1.0789,
      "step": 47860
    },
    {
      "epoch": 77.23,
      "learning_rate": 0.09228000772,
      "loss": 1.1089,
      "step": 47880
    },
    {
      "epoch": 77.26,
      "learning_rate": 0.0922767819167742,
      "loss": 1.0846,
      "step": 47900
    },
    {
      "epoch": 77.29,
      "learning_rate": 0.09227355611354839,
      "loss": 1.0817,
      "step": 47920
    },
    {
      "epoch": 77.32,
      "learning_rate": 0.09227033031032258,
      "loss": 1.1111,
      "step": 47940
    },
    {
      "epoch": 77.35,
      "learning_rate": 0.09226710450709678,
      "loss": 1.1065,
      "step": 47960
    },
    {
      "epoch": 77.39,
      "learning_rate": 0.09226387870387097,
      "loss": 1.1008,
      "step": 47980
    },
    {
      "epoch": 77.42,
      "learning_rate": 0.09226065290064517,
      "loss": 1.1001,
      "step": 48000
    },
    {
      "epoch": 77.45,
      "learning_rate": 0.09225742709741937,
      "loss": 1.1382,
      "step": 48020
    },
    {
      "epoch": 77.48,
      "learning_rate": 0.09225420129419355,
      "loss": 1.0833,
      "step": 48040
    },
    {
      "epoch": 77.52,
      "learning_rate": 0.09225097549096775,
      "loss": 1.1082,
      "step": 48060
    },
    {
      "epoch": 77.55,
      "learning_rate": 0.09224774968774194,
      "loss": 1.1,
      "step": 48080
    },
    {
      "epoch": 77.58,
      "learning_rate": 0.09224452388451614,
      "loss": 1.1191,
      "step": 48100
    },
    {
      "epoch": 77.61,
      "learning_rate": 0.09224129808129033,
      "loss": 1.1303,
      "step": 48120
    },
    {
      "epoch": 77.65,
      "learning_rate": 0.09223807227806452,
      "loss": 1.1299,
      "step": 48140
    },
    {
      "epoch": 77.68,
      "learning_rate": 0.0922348464748387,
      "loss": 1.1333,
      "step": 48160
    },
    {
      "epoch": 77.71,
      "learning_rate": 0.09223162067161292,
      "loss": 1.1119,
      "step": 48180
    },
    {
      "epoch": 77.74,
      "learning_rate": 0.0922283948683871,
      "loss": 1.1278,
      "step": 48200
    },
    {
      "epoch": 77.77,
      "learning_rate": 0.09222516906516129,
      "loss": 1.1144,
      "step": 48220
    },
    {
      "epoch": 77.81,
      "learning_rate": 0.09222194326193549,
      "loss": 1.0991,
      "step": 48240
    },
    {
      "epoch": 77.84,
      "learning_rate": 0.09221871745870969,
      "loss": 1.1252,
      "step": 48260
    },
    {
      "epoch": 77.87,
      "learning_rate": 0.09221549165548387,
      "loss": 1.107,
      "step": 48280
    },
    {
      "epoch": 77.9,
      "learning_rate": 0.09221226585225807,
      "loss": 1.1277,
      "step": 48300
    },
    {
      "epoch": 77.94,
      "learning_rate": 0.09220904004903226,
      "loss": 1.135,
      "step": 48320
    },
    {
      "epoch": 77.97,
      "learning_rate": 0.09220581424580646,
      "loss": 1.0999,
      "step": 48340
    },
    {
      "epoch": 78.0,
      "learning_rate": 0.09220258844258065,
      "loss": 1.1476,
      "step": 48360
    },
    {
      "epoch": 78.0,
      "eval_accuracy": {
        "accuracy": 0.7309343532901413
      },
      "eval_loss": 1.4070488214492798,
      "eval_runtime": 2.6972,
      "eval_samples_per_second": 4749.685,
      "eval_steps_per_second": 74.521,
      "step": 48360
    },
    {
      "epoch": 78.03,
      "learning_rate": 0.09219936263935484,
      "loss": 1.183,
      "step": 48380
    },
    {
      "epoch": 78.06,
      "learning_rate": 0.09219613683612904,
      "loss": 1.1253,
      "step": 48400
    },
    {
      "epoch": 78.1,
      "learning_rate": 0.09219291103290324,
      "loss": 1.1308,
      "step": 48420
    },
    {
      "epoch": 78.13,
      "learning_rate": 0.09218968522967742,
      "loss": 1.0676,
      "step": 48440
    },
    {
      "epoch": 78.16,
      "learning_rate": 0.09218645942645161,
      "loss": 1.0562,
      "step": 48460
    },
    {
      "epoch": 78.19,
      "learning_rate": 0.09218323362322582,
      "loss": 1.0854,
      "step": 48480
    },
    {
      "epoch": 78.23,
      "learning_rate": 0.09218000782,
      "loss": 1.0777,
      "step": 48500
    },
    {
      "epoch": 78.26,
      "learning_rate": 0.09217678201677419,
      "loss": 1.0938,
      "step": 48520
    },
    {
      "epoch": 78.29,
      "learning_rate": 0.09217355621354839,
      "loss": 1.1114,
      "step": 48540
    },
    {
      "epoch": 78.32,
      "learning_rate": 0.09217033041032259,
      "loss": 1.109,
      "step": 48560
    },
    {
      "epoch": 78.35,
      "learning_rate": 0.09216710460709678,
      "loss": 1.1002,
      "step": 48580
    },
    {
      "epoch": 78.39,
      "learning_rate": 0.09216387880387097,
      "loss": 1.0899,
      "step": 48600
    },
    {
      "epoch": 78.42,
      "learning_rate": 0.09216065300064516,
      "loss": 1.0922,
      "step": 48620
    },
    {
      "epoch": 78.45,
      "learning_rate": 0.09215742719741936,
      "loss": 1.0952,
      "step": 48640
    },
    {
      "epoch": 78.48,
      "learning_rate": 0.09215420139419356,
      "loss": 1.1154,
      "step": 48660
    },
    {
      "epoch": 78.52,
      "learning_rate": 0.09215097559096774,
      "loss": 1.0735,
      "step": 48680
    },
    {
      "epoch": 78.55,
      "learning_rate": 0.09214774978774194,
      "loss": 1.1098,
      "step": 48700
    },
    {
      "epoch": 78.58,
      "learning_rate": 0.09214452398451614,
      "loss": 1.1155,
      "step": 48720
    },
    {
      "epoch": 78.61,
      "learning_rate": 0.09214129818129033,
      "loss": 1.1371,
      "step": 48740
    },
    {
      "epoch": 78.65,
      "learning_rate": 0.09213807237806453,
      "loss": 1.0988,
      "step": 48760
    },
    {
      "epoch": 78.68,
      "learning_rate": 0.09213484657483872,
      "loss": 1.12,
      "step": 48780
    },
    {
      "epoch": 78.71,
      "learning_rate": 0.09213162077161291,
      "loss": 1.0874,
      "step": 48800
    },
    {
      "epoch": 78.74,
      "learning_rate": 0.0921283949683871,
      "loss": 1.1054,
      "step": 48820
    },
    {
      "epoch": 78.77,
      "learning_rate": 0.0921251691651613,
      "loss": 1.1236,
      "step": 48840
    },
    {
      "epoch": 78.81,
      "learning_rate": 0.09212194336193548,
      "loss": 1.1285,
      "step": 48860
    },
    {
      "epoch": 78.84,
      "learning_rate": 0.09211871755870968,
      "loss": 1.1172,
      "step": 48880
    },
    {
      "epoch": 78.87,
      "learning_rate": 0.09211549175548388,
      "loss": 1.1346,
      "step": 48900
    },
    {
      "epoch": 78.9,
      "learning_rate": 0.09211226595225806,
      "loss": 1.1204,
      "step": 48920
    },
    {
      "epoch": 78.94,
      "learning_rate": 0.09210904014903226,
      "loss": 1.1236,
      "step": 48940
    },
    {
      "epoch": 78.97,
      "learning_rate": 0.09210581434580646,
      "loss": 1.1187,
      "step": 48960
    },
    {
      "epoch": 79.0,
      "learning_rate": 0.09210274983274194,
      "loss": 1.1058,
      "step": 48980
    },
    {
      "epoch": 79.0,
      "eval_accuracy": {
        "accuracy": 0.735617828428694
      },
      "eval_loss": 1.3538758754730225,
      "eval_runtime": 2.557,
      "eval_samples_per_second": 5010.259,
      "eval_steps_per_second": 78.609,
      "step": 48980
    },
    {
      "epoch": 79.03,
      "learning_rate": 0.09209952402951613,
      "loss": 1.1206,
      "step": 49000
    },
    {
      "epoch": 79.06,
      "learning_rate": 0.09209629822629033,
      "loss": 1.1254,
      "step": 49020
    },
    {
      "epoch": 79.1,
      "learning_rate": 0.09209307242306453,
      "loss": 1.0811,
      "step": 49040
    },
    {
      "epoch": 79.13,
      "learning_rate": 0.09208984661983871,
      "loss": 1.0684,
      "step": 49060
    },
    {
      "epoch": 79.16,
      "learning_rate": 0.09208662081661291,
      "loss": 1.0852,
      "step": 49080
    },
    {
      "epoch": 79.19,
      "learning_rate": 0.09208339501338711,
      "loss": 1.1211,
      "step": 49100
    },
    {
      "epoch": 79.23,
      "learning_rate": 0.0920801692101613,
      "loss": 1.1089,
      "step": 49120
    },
    {
      "epoch": 79.26,
      "learning_rate": 0.0920769434069355,
      "loss": 1.0829,
      "step": 49140
    },
    {
      "epoch": 79.29,
      "learning_rate": 0.09207371760370968,
      "loss": 1.1233,
      "step": 49160
    },
    {
      "epoch": 79.32,
      "learning_rate": 0.09207049180048388,
      "loss": 1.1173,
      "step": 49180
    },
    {
      "epoch": 79.35,
      "learning_rate": 0.09206726599725808,
      "loss": 1.0667,
      "step": 49200
    },
    {
      "epoch": 79.39,
      "learning_rate": 0.09206404019403226,
      "loss": 1.1121,
      "step": 49220
    },
    {
      "epoch": 79.42,
      "learning_rate": 0.09206081439080645,
      "loss": 1.0851,
      "step": 49240
    },
    {
      "epoch": 79.45,
      "learning_rate": 0.09205758858758065,
      "loss": 1.1038,
      "step": 49260
    },
    {
      "epoch": 79.48,
      "learning_rate": 0.09205436278435485,
      "loss": 1.1245,
      "step": 49280
    },
    {
      "epoch": 79.52,
      "learning_rate": 0.09205113698112903,
      "loss": 1.1177,
      "step": 49300
    },
    {
      "epoch": 79.55,
      "learning_rate": 0.09204791117790323,
      "loss": 1.0709,
      "step": 49320
    },
    {
      "epoch": 79.58,
      "learning_rate": 0.09204468537467743,
      "loss": 1.0832,
      "step": 49340
    },
    {
      "epoch": 79.61,
      "learning_rate": 0.09204145957145161,
      "loss": 1.0867,
      "step": 49360
    },
    {
      "epoch": 79.65,
      "learning_rate": 0.09203823376822581,
      "loss": 1.0831,
      "step": 49380
    },
    {
      "epoch": 79.68,
      "learning_rate": 0.092035007965,
      "loss": 1.0999,
      "step": 49400
    },
    {
      "epoch": 79.71,
      "learning_rate": 0.0920317821617742,
      "loss": 1.0862,
      "step": 49420
    },
    {
      "epoch": 79.74,
      "learning_rate": 0.0920285563585484,
      "loss": 1.0806,
      "step": 49440
    },
    {
      "epoch": 79.77,
      "learning_rate": 0.09202533055532258,
      "loss": 1.0773,
      "step": 49460
    },
    {
      "epoch": 79.81,
      "learning_rate": 0.09202210475209678,
      "loss": 1.1207,
      "step": 49480
    },
    {
      "epoch": 79.84,
      "learning_rate": 0.09201887894887098,
      "loss": 1.1244,
      "step": 49500
    },
    {
      "epoch": 79.87,
      "learning_rate": 0.09201565314564517,
      "loss": 1.1154,
      "step": 49520
    },
    {
      "epoch": 79.9,
      "learning_rate": 0.09201242734241935,
      "loss": 1.1511,
      "step": 49540
    },
    {
      "epoch": 79.94,
      "learning_rate": 0.09200920153919356,
      "loss": 1.134,
      "step": 49560
    },
    {
      "epoch": 79.97,
      "learning_rate": 0.09200597573596775,
      "loss": 1.1199,
      "step": 49580
    },
    {
      "epoch": 80.0,
      "learning_rate": 0.09200274993274193,
      "loss": 1.1196,
      "step": 49600
    },
    {
      "epoch": 80.0,
      "eval_accuracy": {
        "accuracy": 0.727187573179299
      },
      "eval_loss": 1.3984856605529785,
      "eval_runtime": 3.946,
      "eval_samples_per_second": 3246.614,
      "eval_steps_per_second": 50.938,
      "step": 49600
    },
    {
      "epoch": 80.03,
      "learning_rate": 0.09199952412951613,
      "loss": 1.1677,
      "step": 49620
    },
    {
      "epoch": 80.06,
      "learning_rate": 0.09199629832629033,
      "loss": 1.0601,
      "step": 49640
    },
    {
      "epoch": 80.1,
      "learning_rate": 0.09199307252306452,
      "loss": 1.054,
      "step": 49660
    },
    {
      "epoch": 80.13,
      "learning_rate": 0.09198984671983872,
      "loss": 1.0612,
      "step": 49680
    },
    {
      "epoch": 80.16,
      "learning_rate": 0.0919866209166129,
      "loss": 1.1026,
      "step": 49700
    },
    {
      "epoch": 80.19,
      "learning_rate": 0.0919833951133871,
      "loss": 1.1045,
      "step": 49720
    },
    {
      "epoch": 80.23,
      "learning_rate": 0.0919801693101613,
      "loss": 1.0836,
      "step": 49740
    },
    {
      "epoch": 80.26,
      "learning_rate": 0.09197694350693549,
      "loss": 1.12,
      "step": 49760
    },
    {
      "epoch": 80.29,
      "learning_rate": 0.09197371770370968,
      "loss": 1.1119,
      "step": 49780
    },
    {
      "epoch": 80.32,
      "learning_rate": 0.09197049190048388,
      "loss": 1.1002,
      "step": 49800
    },
    {
      "epoch": 80.35,
      "learning_rate": 0.09196726609725807,
      "loss": 1.1117,
      "step": 49820
    },
    {
      "epoch": 80.39,
      "learning_rate": 0.09196404029403227,
      "loss": 1.1073,
      "step": 49840
    },
    {
      "epoch": 80.42,
      "learning_rate": 0.09196081449080647,
      "loss": 1.081,
      "step": 49860
    },
    {
      "epoch": 80.45,
      "learning_rate": 0.09195758868758065,
      "loss": 1.0755,
      "step": 49880
    },
    {
      "epoch": 80.48,
      "learning_rate": 0.09195436288435484,
      "loss": 1.0939,
      "step": 49900
    },
    {
      "epoch": 80.52,
      "learning_rate": 0.09195113708112904,
      "loss": 1.0943,
      "step": 49920
    },
    {
      "epoch": 80.55,
      "learning_rate": 0.09194791127790322,
      "loss": 1.1344,
      "step": 49940
    },
    {
      "epoch": 80.58,
      "learning_rate": 0.09194468547467742,
      "loss": 1.124,
      "step": 49960
    },
    {
      "epoch": 80.61,
      "learning_rate": 0.09194145967145162,
      "loss": 1.1008,
      "step": 49980
    },
    {
      "epoch": 80.65,
      "learning_rate": 0.0919382338682258,
      "loss": 1.0816,
      "step": 50000
    },
    {
      "epoch": 80.68,
      "learning_rate": 0.091935008065,
      "loss": 1.1097,
      "step": 50020
    },
    {
      "epoch": 80.71,
      "learning_rate": 0.0919317822617742,
      "loss": 1.1196,
      "step": 50040
    },
    {
      "epoch": 80.74,
      "learning_rate": 0.09192855645854839,
      "loss": 1.1771,
      "step": 50060
    },
    {
      "epoch": 80.77,
      "learning_rate": 0.09192533065532259,
      "loss": 1.1286,
      "step": 50080
    },
    {
      "epoch": 80.81,
      "learning_rate": 0.09192210485209679,
      "loss": 1.1319,
      "step": 50100
    },
    {
      "epoch": 80.84,
      "learning_rate": 0.09191887904887097,
      "loss": 1.0986,
      "step": 50120
    },
    {
      "epoch": 80.87,
      "learning_rate": 0.09191565324564517,
      "loss": 1.0849,
      "step": 50140
    },
    {
      "epoch": 80.9,
      "learning_rate": 0.09191242744241937,
      "loss": 1.1353,
      "step": 50160
    },
    {
      "epoch": 80.94,
      "learning_rate": 0.09190920163919356,
      "loss": 1.1459,
      "step": 50180
    },
    {
      "epoch": 80.97,
      "learning_rate": 0.09190597583596774,
      "loss": 1.1542,
      "step": 50200
    },
    {
      "epoch": 81.0,
      "learning_rate": 0.09190275003274194,
      "loss": 1.1603,
      "step": 50220
    },
    {
      "epoch": 81.0,
      "eval_accuracy": {
        "accuracy": 0.7315588166419483
      },
      "eval_loss": 1.3936576843261719,
      "eval_runtime": 3.3062,
      "eval_samples_per_second": 3874.882,
      "eval_steps_per_second": 60.796,
      "step": 50220
    },
    {
      "epoch": 81.03,
      "learning_rate": 0.09189952422951612,
      "loss": 1.1348,
      "step": 50240
    },
    {
      "epoch": 81.06,
      "learning_rate": 0.09189629842629032,
      "loss": 1.0794,
      "step": 50260
    },
    {
      "epoch": 81.1,
      "learning_rate": 0.09189307262306452,
      "loss": 1.0828,
      "step": 50280
    },
    {
      "epoch": 81.13,
      "learning_rate": 0.09188984681983871,
      "loss": 1.0859,
      "step": 50300
    },
    {
      "epoch": 81.16,
      "learning_rate": 0.09188662101661291,
      "loss": 1.0809,
      "step": 50320
    },
    {
      "epoch": 81.19,
      "learning_rate": 0.0918833952133871,
      "loss": 1.0938,
      "step": 50340
    },
    {
      "epoch": 81.23,
      "learning_rate": 0.09188016941016129,
      "loss": 1.1226,
      "step": 50360
    },
    {
      "epoch": 81.26,
      "learning_rate": 0.09187694360693549,
      "loss": 1.1239,
      "step": 50380
    },
    {
      "epoch": 81.29,
      "learning_rate": 0.09187371780370969,
      "loss": 1.1039,
      "step": 50400
    },
    {
      "epoch": 81.32,
      "learning_rate": 0.09187049200048387,
      "loss": 1.0812,
      "step": 50420
    },
    {
      "epoch": 81.35,
      "learning_rate": 0.09186726619725807,
      "loss": 1.0955,
      "step": 50440
    },
    {
      "epoch": 81.39,
      "learning_rate": 0.09186404039403227,
      "loss": 1.0817,
      "step": 50460
    },
    {
      "epoch": 81.42,
      "learning_rate": 0.09186081459080644,
      "loss": 1.095,
      "step": 50480
    },
    {
      "epoch": 81.45,
      "learning_rate": 0.09185758878758066,
      "loss": 1.1193,
      "step": 50500
    },
    {
      "epoch": 81.48,
      "learning_rate": 0.09185436298435484,
      "loss": 1.1084,
      "step": 50520
    },
    {
      "epoch": 81.52,
      "learning_rate": 0.09185113718112903,
      "loss": 1.08,
      "step": 50540
    },
    {
      "epoch": 81.55,
      "learning_rate": 0.09184791137790323,
      "loss": 1.0794,
      "step": 50560
    },
    {
      "epoch": 81.58,
      "learning_rate": 0.09184468557467743,
      "loss": 1.0737,
      "step": 50580
    },
    {
      "epoch": 81.61,
      "learning_rate": 0.09184145977145161,
      "loss": 1.1253,
      "step": 50600
    },
    {
      "epoch": 81.65,
      "learning_rate": 0.09183823396822581,
      "loss": 1.1309,
      "step": 50620
    },
    {
      "epoch": 81.68,
      "learning_rate": 0.09183500816500001,
      "loss": 1.1182,
      "step": 50640
    },
    {
      "epoch": 81.71,
      "learning_rate": 0.0918317823617742,
      "loss": 1.1314,
      "step": 50660
    },
    {
      "epoch": 81.74,
      "learning_rate": 0.0918285565585484,
      "loss": 1.088,
      "step": 50680
    },
    {
      "epoch": 81.77,
      "learning_rate": 0.09182533075532259,
      "loss": 1.1281,
      "step": 50700
    },
    {
      "epoch": 81.81,
      "learning_rate": 0.09182210495209678,
      "loss": 1.0998,
      "step": 50720
    },
    {
      "epoch": 81.84,
      "learning_rate": 0.09181887914887098,
      "loss": 1.1021,
      "step": 50740
    },
    {
      "epoch": 81.87,
      "learning_rate": 0.09181565334564518,
      "loss": 1.0943,
      "step": 50760
    },
    {
      "epoch": 81.9,
      "learning_rate": 0.09181242754241935,
      "loss": 1.1161,
      "step": 50780
    },
    {
      "epoch": 81.94,
      "learning_rate": 0.09180920173919356,
      "loss": 1.1202,
      "step": 50800
    },
    {
      "epoch": 81.97,
      "learning_rate": 0.09180597593596775,
      "loss": 1.1389,
      "step": 50820
    },
    {
      "epoch": 82.0,
      "learning_rate": 0.09180275013274193,
      "loss": 1.1398,
      "step": 50840
    },
    {
      "epoch": 82.0,
      "eval_accuracy": {
        "accuracy": 0.7323393958317072
      },
      "eval_loss": 1.4142283201217651,
      "eval_runtime": 2.6266,
      "eval_samples_per_second": 4877.397,
      "eval_steps_per_second": 76.525,
      "step": 50840
    },
    {
      "epoch": 82.03,
      "learning_rate": 0.09179952432951613,
      "loss": 1.1614,
      "step": 50860
    },
    {
      "epoch": 82.06,
      "learning_rate": 0.09179629852629033,
      "loss": 1.0739,
      "step": 50880
    },
    {
      "epoch": 82.1,
      "learning_rate": 0.09179307272306451,
      "loss": 1.0871,
      "step": 50900
    },
    {
      "epoch": 82.13,
      "learning_rate": 0.09178984691983871,
      "loss": 1.1122,
      "step": 50920
    },
    {
      "epoch": 82.16,
      "learning_rate": 0.09178662111661291,
      "loss": 1.0786,
      "step": 50940
    },
    {
      "epoch": 82.19,
      "learning_rate": 0.0917833953133871,
      "loss": 1.0592,
      "step": 50960
    },
    {
      "epoch": 82.23,
      "learning_rate": 0.0917801695101613,
      "loss": 1.0578,
      "step": 50980
    },
    {
      "epoch": 82.26,
      "learning_rate": 0.0917769437069355,
      "loss": 1.0849,
      "step": 51000
    },
    {
      "epoch": 82.29,
      "learning_rate": 0.09177371790370968,
      "loss": 1.1022,
      "step": 51020
    },
    {
      "epoch": 82.32,
      "learning_rate": 0.09177049210048388,
      "loss": 1.075,
      "step": 51040
    },
    {
      "epoch": 82.35,
      "learning_rate": 0.09176726629725808,
      "loss": 1.0667,
      "step": 51060
    },
    {
      "epoch": 82.39,
      "learning_rate": 0.09176404049403226,
      "loss": 1.1117,
      "step": 51080
    },
    {
      "epoch": 82.42,
      "learning_rate": 0.09176081469080646,
      "loss": 1.1119,
      "step": 51100
    },
    {
      "epoch": 82.45,
      "learning_rate": 0.09175758888758065,
      "loss": 1.091,
      "step": 51120
    },
    {
      "epoch": 82.48,
      "learning_rate": 0.09175436308435483,
      "loss": 1.0686,
      "step": 51140
    },
    {
      "epoch": 82.52,
      "learning_rate": 0.09175113728112903,
      "loss": 1.0513,
      "step": 51160
    },
    {
      "epoch": 82.55,
      "learning_rate": 0.09174791147790323,
      "loss": 1.0539,
      "step": 51180
    },
    {
      "epoch": 82.58,
      "learning_rate": 0.09174468567467742,
      "loss": 1.0669,
      "step": 51200
    },
    {
      "epoch": 82.61,
      "learning_rate": 0.09174145987145162,
      "loss": 1.0932,
      "step": 51220
    },
    {
      "epoch": 82.65,
      "learning_rate": 0.09173823406822582,
      "loss": 1.0948,
      "step": 51240
    },
    {
      "epoch": 82.68,
      "learning_rate": 0.0917351695551613,
      "loss": 1.0643,
      "step": 51260
    },
    {
      "epoch": 82.71,
      "learning_rate": 0.09173194375193548,
      "loss": 1.0773,
      "step": 51280
    },
    {
      "epoch": 82.74,
      "learning_rate": 0.09172871794870968,
      "loss": 1.106,
      "step": 51300
    },
    {
      "epoch": 82.77,
      "learning_rate": 0.09172549214548387,
      "loss": 1.098,
      "step": 51320
    },
    {
      "epoch": 82.81,
      "learning_rate": 0.09172226634225807,
      "loss": 1.1194,
      "step": 51340
    },
    {
      "epoch": 82.84,
      "learning_rate": 0.09171904053903226,
      "loss": 1.1369,
      "step": 51360
    },
    {
      "epoch": 82.87,
      "learning_rate": 0.09171581473580645,
      "loss": 1.1324,
      "step": 51380
    },
    {
      "epoch": 82.9,
      "learning_rate": 0.09171258893258065,
      "loss": 1.1224,
      "step": 51400
    },
    {
      "epoch": 82.94,
      "learning_rate": 0.09170936312935485,
      "loss": 1.1114,
      "step": 51420
    },
    {
      "epoch": 82.97,
      "learning_rate": 0.09170613732612903,
      "loss": 1.0961,
      "step": 51440
    },
    {
      "epoch": 83.0,
      "learning_rate": 0.09170291152290323,
      "loss": 1.1048,
      "step": 51460
    },
    {
      "epoch": 83.0,
      "eval_accuracy": {
        "accuracy": 0.723909140582312
      },
      "eval_loss": 1.439064383506775,
      "eval_runtime": 3.3173,
      "eval_samples_per_second": 3861.908,
      "eval_steps_per_second": 60.592,
      "step": 51460
    },
    {
      "epoch": 83.03,
      "learning_rate": 0.09169968571967743,
      "loss": 1.1553,
      "step": 51480
    },
    {
      "epoch": 83.06,
      "learning_rate": 0.09169645991645162,
      "loss": 1.0664,
      "step": 51500
    },
    {
      "epoch": 83.1,
      "learning_rate": 0.09169323411322582,
      "loss": 1.073,
      "step": 51520
    },
    {
      "epoch": 83.13,
      "learning_rate": 0.09169000831000002,
      "loss": 1.0663,
      "step": 51540
    },
    {
      "epoch": 83.16,
      "learning_rate": 0.09168678250677419,
      "loss": 1.0915,
      "step": 51560
    },
    {
      "epoch": 83.19,
      "learning_rate": 0.09168355670354839,
      "loss": 1.1276,
      "step": 51580
    },
    {
      "epoch": 83.23,
      "learning_rate": 0.09168033090032258,
      "loss": 1.1122,
      "step": 51600
    },
    {
      "epoch": 83.26,
      "learning_rate": 0.09167710509709677,
      "loss": 1.0738,
      "step": 51620
    },
    {
      "epoch": 83.29,
      "learning_rate": 0.09167387929387097,
      "loss": 1.0722,
      "step": 51640
    },
    {
      "epoch": 83.32,
      "learning_rate": 0.09167065349064517,
      "loss": 1.0884,
      "step": 51660
    },
    {
      "epoch": 83.35,
      "learning_rate": 0.09166742768741935,
      "loss": 1.0773,
      "step": 51680
    },
    {
      "epoch": 83.39,
      "learning_rate": 0.09166420188419355,
      "loss": 1.0819,
      "step": 51700
    },
    {
      "epoch": 83.42,
      "learning_rate": 0.09166097608096775,
      "loss": 1.1096,
      "step": 51720
    },
    {
      "epoch": 83.45,
      "learning_rate": 0.09165775027774194,
      "loss": 1.1398,
      "step": 51740
    },
    {
      "epoch": 83.48,
      "learning_rate": 0.09165452447451614,
      "loss": 1.0965,
      "step": 51760
    },
    {
      "epoch": 83.52,
      "learning_rate": 0.09165129867129033,
      "loss": 1.1049,
      "step": 51780
    },
    {
      "epoch": 83.55,
      "learning_rate": 0.09164807286806452,
      "loss": 1.0853,
      "step": 51800
    },
    {
      "epoch": 83.58,
      "learning_rate": 0.09164484706483872,
      "loss": 1.0787,
      "step": 51820
    },
    {
      "epoch": 83.61,
      "learning_rate": 0.09164162126161292,
      "loss": 1.0848,
      "step": 51840
    },
    {
      "epoch": 83.65,
      "learning_rate": 0.09163839545838709,
      "loss": 1.1121,
      "step": 51860
    },
    {
      "epoch": 83.68,
      "learning_rate": 0.0916351696551613,
      "loss": 1.0988,
      "step": 51880
    },
    {
      "epoch": 83.71,
      "learning_rate": 0.09163194385193549,
      "loss": 1.1061,
      "step": 51900
    },
    {
      "epoch": 83.74,
      "learning_rate": 0.09162871804870967,
      "loss": 1.1092,
      "step": 51920
    },
    {
      "epoch": 83.77,
      "learning_rate": 0.09162549224548387,
      "loss": 1.0842,
      "step": 51940
    },
    {
      "epoch": 83.81,
      "learning_rate": 0.09162226644225807,
      "loss": 1.1118,
      "step": 51960
    },
    {
      "epoch": 83.84,
      "learning_rate": 0.09161904063903226,
      "loss": 1.1175,
      "step": 51980
    },
    {
      "epoch": 83.87,
      "learning_rate": 0.09161581483580646,
      "loss": 1.086,
      "step": 52000
    },
    {
      "epoch": 83.9,
      "learning_rate": 0.09161258903258065,
      "loss": 1.1051,
      "step": 52020
    },
    {
      "epoch": 83.94,
      "learning_rate": 0.09160936322935484,
      "loss": 1.1342,
      "step": 52040
    },
    {
      "epoch": 83.97,
      "learning_rate": 0.09160613742612904,
      "loss": 1.1381,
      "step": 52060
    },
    {
      "epoch": 84.0,
      "learning_rate": 0.09160291162290324,
      "loss": 1.1207,
      "step": 52080
    },
    {
      "epoch": 84.0,
      "eval_accuracy": {
        "accuracy": 0.7266411677464679
      },
      "eval_loss": 1.4408509731292725,
      "eval_runtime": 3.8835,
      "eval_samples_per_second": 3298.804,
      "eval_steps_per_second": 51.757,
      "step": 52080
    },
    {
      "epoch": 84.03,
      "learning_rate": 0.09159968581967742,
      "loss": 1.1358,
      "step": 52100
    },
    {
      "epoch": 84.06,
      "learning_rate": 0.09159646001645162,
      "loss": 1.0776,
      "step": 52120
    },
    {
      "epoch": 84.1,
      "learning_rate": 0.09159323421322582,
      "loss": 1.1008,
      "step": 52140
    },
    {
      "epoch": 84.13,
      "learning_rate": 0.09159000841,
      "loss": 1.0942,
      "step": 52160
    },
    {
      "epoch": 84.16,
      "learning_rate": 0.0915867826067742,
      "loss": 1.069,
      "step": 52180
    },
    {
      "epoch": 84.19,
      "learning_rate": 0.09158355680354839,
      "loss": 1.0967,
      "step": 52200
    },
    {
      "epoch": 84.23,
      "learning_rate": 0.09158033100032258,
      "loss": 1.0903,
      "step": 52220
    },
    {
      "epoch": 84.26,
      "learning_rate": 0.09157710519709678,
      "loss": 1.1048,
      "step": 52240
    },
    {
      "epoch": 84.29,
      "learning_rate": 0.09157387939387097,
      "loss": 1.0723,
      "step": 52260
    },
    {
      "epoch": 84.32,
      "learning_rate": 0.09157065359064516,
      "loss": 1.0518,
      "step": 52280
    },
    {
      "epoch": 84.35,
      "learning_rate": 0.09156742778741936,
      "loss": 1.0875,
      "step": 52300
    },
    {
      "epoch": 84.39,
      "learning_rate": 0.09156420198419356,
      "loss": 1.0718,
      "step": 52320
    },
    {
      "epoch": 84.42,
      "learning_rate": 0.09156097618096774,
      "loss": 1.0782,
      "step": 52340
    },
    {
      "epoch": 84.45,
      "learning_rate": 0.09155775037774194,
      "loss": 1.096,
      "step": 52360
    },
    {
      "epoch": 84.48,
      "learning_rate": 0.09155452457451614,
      "loss": 1.0803,
      "step": 52380
    },
    {
      "epoch": 84.52,
      "learning_rate": 0.09155129877129033,
      "loss": 1.077,
      "step": 52400
    },
    {
      "epoch": 84.55,
      "learning_rate": 0.09154807296806453,
      "loss": 1.0997,
      "step": 52420
    },
    {
      "epoch": 84.58,
      "learning_rate": 0.09154484716483872,
      "loss": 1.1019,
      "step": 52440
    },
    {
      "epoch": 84.61,
      "learning_rate": 0.09154162136161291,
      "loss": 1.0967,
      "step": 52460
    },
    {
      "epoch": 84.65,
      "learning_rate": 0.09153839555838711,
      "loss": 1.0695,
      "step": 52480
    },
    {
      "epoch": 84.68,
      "learning_rate": 0.0915351697551613,
      "loss": 1.1147,
      "step": 52500
    },
    {
      "epoch": 84.71,
      "learning_rate": 0.09153194395193548,
      "loss": 1.1249,
      "step": 52520
    },
    {
      "epoch": 84.74,
      "learning_rate": 0.09152871814870968,
      "loss": 1.1391,
      "step": 52540
    },
    {
      "epoch": 84.77,
      "learning_rate": 0.09152549234548388,
      "loss": 1.171,
      "step": 52560
    },
    {
      "epoch": 84.81,
      "learning_rate": 0.09152226654225806,
      "loss": 1.1339,
      "step": 52580
    },
    {
      "epoch": 84.84,
      "learning_rate": 0.09151904073903226,
      "loss": 1.096,
      "step": 52600
    },
    {
      "epoch": 84.87,
      "learning_rate": 0.09151581493580646,
      "loss": 1.0867,
      "step": 52620
    },
    {
      "epoch": 84.9,
      "learning_rate": 0.09151258913258065,
      "loss": 1.0705,
      "step": 52640
    },
    {
      "epoch": 84.94,
      "learning_rate": 0.09150936332935485,
      "loss": 1.0622,
      "step": 52660
    },
    {
      "epoch": 84.97,
      "learning_rate": 0.09150613752612904,
      "loss": 1.1223,
      "step": 52680
    },
    {
      "epoch": 85.0,
      "learning_rate": 0.09150291172290323,
      "loss": 1.0989,
      "step": 52700
    },
    {
      "epoch": 85.0,
      "eval_accuracy": {
        "accuracy": 0.7335102646163453
      },
      "eval_loss": 1.3345928192138672,
      "eval_runtime": 2.6392,
      "eval_samples_per_second": 4854.069,
      "eval_steps_per_second": 76.159,
      "step": 52700
    },
    {
      "epoch": 85.03,
      "learning_rate": 0.09149968591967743,
      "loss": 1.1074,
      "step": 52720
    },
    {
      "epoch": 85.06,
      "learning_rate": 0.09149646011645163,
      "loss": 1.0753,
      "step": 52740
    },
    {
      "epoch": 85.1,
      "learning_rate": 0.09149323431322581,
      "loss": 1.0705,
      "step": 52760
    },
    {
      "epoch": 85.13,
      "learning_rate": 0.09149000851000001,
      "loss": 1.0811,
      "step": 52780
    },
    {
      "epoch": 85.16,
      "learning_rate": 0.0914867827067742,
      "loss": 1.1082,
      "step": 52800
    },
    {
      "epoch": 85.19,
      "learning_rate": 0.0914835569035484,
      "loss": 1.0908,
      "step": 52820
    },
    {
      "epoch": 85.23,
      "learning_rate": 0.09148033110032258,
      "loss": 1.1007,
      "step": 52840
    },
    {
      "epoch": 85.26,
      "learning_rate": 0.09147710529709678,
      "loss": 1.0607,
      "step": 52860
    },
    {
      "epoch": 85.29,
      "learning_rate": 0.09147387949387097,
      "loss": 1.0661,
      "step": 52880
    },
    {
      "epoch": 85.32,
      "learning_rate": 0.09147065369064517,
      "loss": 1.114,
      "step": 52900
    },
    {
      "epoch": 85.35,
      "learning_rate": 0.09146742788741936,
      "loss": 1.0415,
      "step": 52920
    },
    {
      "epoch": 85.39,
      "learning_rate": 0.09146420208419355,
      "loss": 1.036,
      "step": 52940
    },
    {
      "epoch": 85.42,
      "learning_rate": 0.09146097628096775,
      "loss": 1.0781,
      "step": 52960
    },
    {
      "epoch": 85.45,
      "learning_rate": 0.09145775047774195,
      "loss": 1.0625,
      "step": 52980
    },
    {
      "epoch": 85.48,
      "learning_rate": 0.09145452467451613,
      "loss": 1.0783,
      "step": 53000
    },
    {
      "epoch": 85.52,
      "learning_rate": 0.09145129887129033,
      "loss": 1.0872,
      "step": 53020
    },
    {
      "epoch": 85.55,
      "learning_rate": 0.09144807306806453,
      "loss": 1.0929,
      "step": 53040
    },
    {
      "epoch": 85.58,
      "learning_rate": 0.09144484726483872,
      "loss": 1.0749,
      "step": 53060
    },
    {
      "epoch": 85.61,
      "learning_rate": 0.09144162146161292,
      "loss": 1.095,
      "step": 53080
    },
    {
      "epoch": 85.65,
      "learning_rate": 0.0914383956583871,
      "loss": 1.083,
      "step": 53100
    },
    {
      "epoch": 85.68,
      "learning_rate": 0.0914351698551613,
      "loss": 1.0867,
      "step": 53120
    },
    {
      "epoch": 85.71,
      "learning_rate": 0.09143194405193548,
      "loss": 1.1202,
      "step": 53140
    },
    {
      "epoch": 85.74,
      "learning_rate": 0.09142871824870968,
      "loss": 1.1472,
      "step": 53160
    },
    {
      "epoch": 85.77,
      "learning_rate": 0.09142549244548387,
      "loss": 1.1595,
      "step": 53180
    },
    {
      "epoch": 85.81,
      "learning_rate": 0.09142226664225807,
      "loss": 1.1065,
      "step": 53200
    },
    {
      "epoch": 85.84,
      "learning_rate": 0.09141904083903227,
      "loss": 1.1071,
      "step": 53220
    },
    {
      "epoch": 85.87,
      "learning_rate": 0.09141581503580645,
      "loss": 1.1019,
      "step": 53240
    },
    {
      "epoch": 85.9,
      "learning_rate": 0.09141258923258065,
      "loss": 1.1019,
      "step": 53260
    },
    {
      "epoch": 85.94,
      "learning_rate": 0.09140936342935485,
      "loss": 1.1204,
      "step": 53280
    },
    {
      "epoch": 85.97,
      "learning_rate": 0.09140613762612904,
      "loss": 1.1125,
      "step": 53300
    },
    {
      "epoch": 86.0,
      "learning_rate": 0.09140307311306452,
      "loss": 1.1107,
      "step": 53320
    },
    {
      "epoch": 86.0,
      "eval_accuracy": {
        "accuracy": 0.740925766919054
      },
      "eval_loss": 1.3465250730514526,
      "eval_runtime": 2.5555,
      "eval_samples_per_second": 5013.106,
      "eval_steps_per_second": 78.654,
      "step": 53320
    },
    {
      "epoch": 86.03,
      "learning_rate": 0.09139984730983872,
      "loss": 1.117,
      "step": 53340
    },
    {
      "epoch": 86.06,
      "learning_rate": 0.0913966215066129,
      "loss": 1.0719,
      "step": 53360
    },
    {
      "epoch": 86.1,
      "learning_rate": 0.0913933957033871,
      "loss": 1.0634,
      "step": 53380
    },
    {
      "epoch": 86.13,
      "learning_rate": 0.0913901699001613,
      "loss": 1.0873,
      "step": 53400
    },
    {
      "epoch": 86.16,
      "learning_rate": 0.09138694409693549,
      "loss": 1.0986,
      "step": 53420
    },
    {
      "epoch": 86.19,
      "learning_rate": 0.09138371829370968,
      "loss": 1.0968,
      "step": 53440
    },
    {
      "epoch": 86.23,
      "learning_rate": 0.09138049249048388,
      "loss": 1.0911,
      "step": 53460
    },
    {
      "epoch": 86.26,
      "learning_rate": 0.09137726668725807,
      "loss": 1.0926,
      "step": 53480
    },
    {
      "epoch": 86.29,
      "learning_rate": 0.09137404088403227,
      "loss": 1.0826,
      "step": 53500
    },
    {
      "epoch": 86.32,
      "learning_rate": 0.09137081508080647,
      "loss": 1.0793,
      "step": 53520
    },
    {
      "epoch": 86.35,
      "learning_rate": 0.09136758927758065,
      "loss": 1.066,
      "step": 53540
    },
    {
      "epoch": 86.39,
      "learning_rate": 0.09136436347435485,
      "loss": 1.0572,
      "step": 53560
    },
    {
      "epoch": 86.42,
      "learning_rate": 0.09136113767112904,
      "loss": 1.0817,
      "step": 53580
    },
    {
      "epoch": 86.45,
      "learning_rate": 0.09135791186790322,
      "loss": 1.1133,
      "step": 53600
    },
    {
      "epoch": 86.48,
      "learning_rate": 0.09135468606467742,
      "loss": 1.0718,
      "step": 53620
    },
    {
      "epoch": 86.52,
      "learning_rate": 0.09135146026145162,
      "loss": 1.1227,
      "step": 53640
    },
    {
      "epoch": 86.55,
      "learning_rate": 0.0913482344582258,
      "loss": 1.1045,
      "step": 53660
    },
    {
      "epoch": 86.58,
      "learning_rate": 0.091345008655,
      "loss": 1.1132,
      "step": 53680
    },
    {
      "epoch": 86.61,
      "learning_rate": 0.0913417828517742,
      "loss": 1.099,
      "step": 53700
    },
    {
      "epoch": 86.65,
      "learning_rate": 0.09133855704854839,
      "loss": 1.093,
      "step": 53720
    },
    {
      "epoch": 86.68,
      "learning_rate": 0.09133533124532259,
      "loss": 1.0872,
      "step": 53740
    },
    {
      "epoch": 86.71,
      "learning_rate": 0.09133210544209679,
      "loss": 1.1442,
      "step": 53760
    },
    {
      "epoch": 86.74,
      "learning_rate": 0.09132887963887097,
      "loss": 1.1354,
      "step": 53780
    },
    {
      "epoch": 86.77,
      "learning_rate": 0.09132565383564517,
      "loss": 1.0834,
      "step": 53800
    },
    {
      "epoch": 86.81,
      "learning_rate": 0.09132242803241937,
      "loss": 1.1396,
      "step": 53820
    },
    {
      "epoch": 86.84,
      "learning_rate": 0.09131920222919356,
      "loss": 1.1308,
      "step": 53840
    },
    {
      "epoch": 86.87,
      "learning_rate": 0.09131597642596775,
      "loss": 1.1214,
      "step": 53860
    },
    {
      "epoch": 86.9,
      "learning_rate": 0.09131275062274194,
      "loss": 1.0779,
      "step": 53880
    },
    {
      "epoch": 86.94,
      "learning_rate": 0.09130952481951612,
      "loss": 1.0415,
      "step": 53900
    },
    {
      "epoch": 86.97,
      "learning_rate": 0.09130629901629032,
      "loss": 1.1024,
      "step": 53920
    },
    {
      "epoch": 87.0,
      "learning_rate": 0.09130307321306452,
      "loss": 1.1438,
      "step": 53940
    },
    {
      "epoch": 87.0,
      "eval_accuracy": {
        "accuracy": 0.7317149324799
      },
      "eval_loss": 1.414244532585144,
      "eval_runtime": 2.8918,
      "eval_samples_per_second": 4430.108,
      "eval_steps_per_second": 69.507,
      "step": 53940
    },
    {
      "epoch": 87.03,
      "learning_rate": 0.09129984740983871,
      "loss": 1.1137,
      "step": 53960
    },
    {
      "epoch": 87.06,
      "learning_rate": 0.09129662160661291,
      "loss": 1.1079,
      "step": 53980
    },
    {
      "epoch": 87.1,
      "learning_rate": 0.0912933958033871,
      "loss": 1.0523,
      "step": 54000
    },
    {
      "epoch": 87.13,
      "learning_rate": 0.09129017000016129,
      "loss": 1.0519,
      "step": 54020
    },
    {
      "epoch": 87.16,
      "learning_rate": 0.09128694419693549,
      "loss": 1.0567,
      "step": 54040
    },
    {
      "epoch": 87.19,
      "learning_rate": 0.09128371839370969,
      "loss": 1.0609,
      "step": 54060
    },
    {
      "epoch": 87.23,
      "learning_rate": 0.09128049259048387,
      "loss": 1.0861,
      "step": 54080
    },
    {
      "epoch": 87.26,
      "learning_rate": 0.09127726678725807,
      "loss": 1.0932,
      "step": 54100
    },
    {
      "epoch": 87.29,
      "learning_rate": 0.09127404098403227,
      "loss": 1.0759,
      "step": 54120
    },
    {
      "epoch": 87.32,
      "learning_rate": 0.09127081518080646,
      "loss": 1.1006,
      "step": 54140
    },
    {
      "epoch": 87.35,
      "learning_rate": 0.09126758937758066,
      "loss": 1.0721,
      "step": 54160
    },
    {
      "epoch": 87.39,
      "learning_rate": 0.09126436357435484,
      "loss": 1.0739,
      "step": 54180
    },
    {
      "epoch": 87.42,
      "learning_rate": 0.09126113777112904,
      "loss": 1.0496,
      "step": 54200
    },
    {
      "epoch": 87.45,
      "learning_rate": 0.09125791196790323,
      "loss": 1.0549,
      "step": 54220
    },
    {
      "epoch": 87.48,
      "learning_rate": 0.09125468616467743,
      "loss": 1.078,
      "step": 54240
    },
    {
      "epoch": 87.52,
      "learning_rate": 0.09125146036145161,
      "loss": 1.1294,
      "step": 54260
    },
    {
      "epoch": 87.55,
      "learning_rate": 0.09124823455822581,
      "loss": 1.1112,
      "step": 54280
    },
    {
      "epoch": 87.58,
      "learning_rate": 0.09124500875500001,
      "loss": 1.1124,
      "step": 54300
    },
    {
      "epoch": 87.61,
      "learning_rate": 0.0912417829517742,
      "loss": 1.097,
      "step": 54320
    },
    {
      "epoch": 87.65,
      "learning_rate": 0.0912385571485484,
      "loss": 1.0857,
      "step": 54340
    },
    {
      "epoch": 87.68,
      "learning_rate": 0.09123533134532259,
      "loss": 1.1067,
      "step": 54360
    },
    {
      "epoch": 87.71,
      "learning_rate": 0.09123210554209678,
      "loss": 1.1151,
      "step": 54380
    },
    {
      "epoch": 87.74,
      "learning_rate": 0.09122887973887098,
      "loss": 1.1073,
      "step": 54400
    },
    {
      "epoch": 87.77,
      "learning_rate": 0.09122565393564516,
      "loss": 1.0702,
      "step": 54420
    },
    {
      "epoch": 87.81,
      "learning_rate": 0.09122242813241936,
      "loss": 1.0756,
      "step": 54440
    },
    {
      "epoch": 87.84,
      "learning_rate": 0.09121920232919356,
      "loss": 1.0877,
      "step": 54460
    },
    {
      "epoch": 87.87,
      "learning_rate": 0.09121597652596775,
      "loss": 1.0611,
      "step": 54480
    },
    {
      "epoch": 87.9,
      "learning_rate": 0.09121275072274194,
      "loss": 1.0955,
      "step": 54500
    },
    {
      "epoch": 87.94,
      "learning_rate": 0.09120952491951613,
      "loss": 1.0662,
      "step": 54520
    },
    {
      "epoch": 87.97,
      "learning_rate": 0.09120629911629033,
      "loss": 1.1118,
      "step": 54540
    },
    {
      "epoch": 88.0,
      "learning_rate": 0.09120307331306451,
      "loss": 1.126,
      "step": 54560
    },
    {
      "epoch": 88.0,
      "eval_accuracy": {
        "accuracy": 0.7224260401217704
      },
      "eval_loss": 1.4275023937225342,
      "eval_runtime": 2.6252,
      "eval_samples_per_second": 4880.086,
      "eval_steps_per_second": 76.567,
      "step": 54560
    },
    {
      "epoch": 88.03,
      "learning_rate": 0.09119984750983871,
      "loss": 1.1556,
      "step": 54580
    },
    {
      "epoch": 88.06,
      "learning_rate": 0.09119662170661291,
      "loss": 1.0668,
      "step": 54600
    },
    {
      "epoch": 88.1,
      "learning_rate": 0.0911933959033871,
      "loss": 1.0297,
      "step": 54620
    },
    {
      "epoch": 88.13,
      "learning_rate": 0.0911901701001613,
      "loss": 1.0858,
      "step": 54640
    },
    {
      "epoch": 88.16,
      "learning_rate": 0.0911869442969355,
      "loss": 1.0585,
      "step": 54660
    },
    {
      "epoch": 88.19,
      "learning_rate": 0.09118371849370968,
      "loss": 1.1046,
      "step": 54680
    },
    {
      "epoch": 88.23,
      "learning_rate": 0.09118049269048388,
      "loss": 1.0883,
      "step": 54700
    },
    {
      "epoch": 88.26,
      "learning_rate": 0.09117726688725807,
      "loss": 1.0941,
      "step": 54720
    },
    {
      "epoch": 88.29,
      "learning_rate": 0.09117404108403226,
      "loss": 1.0828,
      "step": 54740
    },
    {
      "epoch": 88.32,
      "learning_rate": 0.09117081528080646,
      "loss": 1.0757,
      "step": 54760
    },
    {
      "epoch": 88.35,
      "learning_rate": 0.09116758947758065,
      "loss": 1.0875,
      "step": 54780
    },
    {
      "epoch": 88.39,
      "learning_rate": 0.09116436367435485,
      "loss": 1.1109,
      "step": 54800
    },
    {
      "epoch": 88.42,
      "learning_rate": 0.09116113787112903,
      "loss": 1.0672,
      "step": 54820
    },
    {
      "epoch": 88.45,
      "learning_rate": 0.09115791206790323,
      "loss": 1.0824,
      "step": 54840
    },
    {
      "epoch": 88.48,
      "learning_rate": 0.09115468626467742,
      "loss": 1.1011,
      "step": 54860
    },
    {
      "epoch": 88.52,
      "learning_rate": 0.09115146046145162,
      "loss": 1.097,
      "step": 54880
    },
    {
      "epoch": 88.55,
      "learning_rate": 0.09114823465822582,
      "loss": 1.0986,
      "step": 54900
    },
    {
      "epoch": 88.58,
      "learning_rate": 0.091145008855,
      "loss": 1.0655,
      "step": 54920
    },
    {
      "epoch": 88.61,
      "learning_rate": 0.0911417830517742,
      "loss": 1.081,
      "step": 54940
    },
    {
      "epoch": 88.65,
      "learning_rate": 0.09113855724854839,
      "loss": 1.0782,
      "step": 54960
    },
    {
      "epoch": 88.68,
      "learning_rate": 0.09113533144532258,
      "loss": 1.0765,
      "step": 54980
    },
    {
      "epoch": 88.71,
      "learning_rate": 0.09113210564209678,
      "loss": 1.1032,
      "step": 55000
    },
    {
      "epoch": 88.74,
      "learning_rate": 0.09112887983887097,
      "loss": 1.084,
      "step": 55020
    },
    {
      "epoch": 88.77,
      "learning_rate": 0.09112565403564517,
      "loss": 1.0776,
      "step": 55040
    },
    {
      "epoch": 88.81,
      "learning_rate": 0.09112242823241937,
      "loss": 1.0919,
      "step": 55060
    },
    {
      "epoch": 88.84,
      "learning_rate": 0.09111920242919355,
      "loss": 1.1365,
      "step": 55080
    },
    {
      "epoch": 88.87,
      "learning_rate": 0.09111597662596775,
      "loss": 1.0763,
      "step": 55100
    },
    {
      "epoch": 88.9,
      "learning_rate": 0.09111275082274194,
      "loss": 1.1234,
      "step": 55120
    },
    {
      "epoch": 88.94,
      "learning_rate": 0.09110952501951614,
      "loss": 1.0964,
      "step": 55140
    },
    {
      "epoch": 88.97,
      "learning_rate": 0.09110629921629032,
      "loss": 1.0894,
      "step": 55160
    },
    {
      "epoch": 89.0,
      "learning_rate": 0.09110307341306452,
      "loss": 1.1469,
      "step": 55180
    },
    {
      "epoch": 89.0,
      "eval_accuracy": {
        "accuracy": 0.7218796346889392
      },
      "eval_loss": 1.481079339981079,
      "eval_runtime": 2.6451,
      "eval_samples_per_second": 4843.38,
      "eval_steps_per_second": 75.991,
      "step": 55180
    },
    {
      "epoch": 89.03,
      "learning_rate": 0.09109984760983872,
      "loss": 1.1692,
      "step": 55200
    },
    {
      "epoch": 89.06,
      "learning_rate": 0.0910966218066129,
      "loss": 1.0931,
      "step": 55220
    },
    {
      "epoch": 89.1,
      "learning_rate": 0.0910933960033871,
      "loss": 1.0632,
      "step": 55240
    },
    {
      "epoch": 89.13,
      "learning_rate": 0.09109017020016129,
      "loss": 1.0635,
      "step": 55260
    },
    {
      "epoch": 89.16,
      "learning_rate": 0.09108694439693549,
      "loss": 1.0796,
      "step": 55280
    },
    {
      "epoch": 89.19,
      "learning_rate": 0.09108371859370969,
      "loss": 1.0913,
      "step": 55300
    },
    {
      "epoch": 89.23,
      "learning_rate": 0.09108049279048387,
      "loss": 1.0514,
      "step": 55320
    },
    {
      "epoch": 89.26,
      "learning_rate": 0.09107726698725807,
      "loss": 1.0707,
      "step": 55340
    },
    {
      "epoch": 89.29,
      "learning_rate": 0.09107404118403227,
      "loss": 1.0682,
      "step": 55360
    },
    {
      "epoch": 89.32,
      "learning_rate": 0.09107081538080646,
      "loss": 1.0993,
      "step": 55380
    },
    {
      "epoch": 89.35,
      "learning_rate": 0.09106758957758065,
      "loss": 1.042,
      "step": 55400
    },
    {
      "epoch": 89.39,
      "learning_rate": 0.09106436377435484,
      "loss": 1.061,
      "step": 55420
    },
    {
      "epoch": 89.42,
      "learning_rate": 0.09106113797112904,
      "loss": 1.0539,
      "step": 55440
    },
    {
      "epoch": 89.45,
      "learning_rate": 0.09105791216790322,
      "loss": 1.1097,
      "step": 55460
    },
    {
      "epoch": 89.48,
      "learning_rate": 0.09105468636467742,
      "loss": 1.1172,
      "step": 55480
    },
    {
      "epoch": 89.52,
      "learning_rate": 0.09105146056145161,
      "loss": 1.0716,
      "step": 55500
    },
    {
      "epoch": 89.55,
      "learning_rate": 0.09104823475822581,
      "loss": 1.051,
      "step": 55520
    },
    {
      "epoch": 89.58,
      "learning_rate": 0.091045008955,
      "loss": 1.0473,
      "step": 55540
    },
    {
      "epoch": 89.61,
      "learning_rate": 0.09104178315177419,
      "loss": 1.1281,
      "step": 55560
    },
    {
      "epoch": 89.65,
      "learning_rate": 0.09103871863870969,
      "loss": 1.1495,
      "step": 55580
    },
    {
      "epoch": 89.68,
      "learning_rate": 0.09103549283548387,
      "loss": 1.0915,
      "step": 55600
    },
    {
      "epoch": 89.71,
      "learning_rate": 0.09103226703225807,
      "loss": 1.099,
      "step": 55620
    },
    {
      "epoch": 89.74,
      "learning_rate": 0.09102904122903226,
      "loss": 1.0939,
      "step": 55640
    },
    {
      "epoch": 89.77,
      "learning_rate": 0.09102581542580646,
      "loss": 1.1156,
      "step": 55660
    },
    {
      "epoch": 89.81,
      "learning_rate": 0.09102258962258065,
      "loss": 1.1151,
      "step": 55680
    },
    {
      "epoch": 89.84,
      "learning_rate": 0.09101936381935484,
      "loss": 1.1028,
      "step": 55700
    },
    {
      "epoch": 89.87,
      "learning_rate": 0.09101613801612904,
      "loss": 1.0645,
      "step": 55720
    },
    {
      "epoch": 89.9,
      "learning_rate": 0.09101291221290324,
      "loss": 1.0915,
      "step": 55740
    },
    {
      "epoch": 89.94,
      "learning_rate": 0.09100968640967742,
      "loss": 1.0903,
      "step": 55760
    },
    {
      "epoch": 89.97,
      "learning_rate": 0.09100646060645162,
      "loss": 1.108,
      "step": 55780
    },
    {
      "epoch": 90.0,
      "learning_rate": 0.09100323480322581,
      "loss": 1.0608,
      "step": 55800
    },
    {
      "epoch": 90.0,
      "eval_accuracy": {
        "accuracy": 0.7230505034735774
      },
      "eval_loss": 1.436532974243164,
      "eval_runtime": 2.5685,
      "eval_samples_per_second": 4987.679,
      "eval_steps_per_second": 78.255,
      "step": 55800
    },
    {
      "epoch": 90.03,
      "learning_rate": 0.091000009,
      "loss": 1.1416,
      "step": 55820
    },
    {
      "epoch": 90.06,
      "learning_rate": 0.0909967831967742,
      "loss": 1.0659,
      "step": 55840
    },
    {
      "epoch": 90.1,
      "learning_rate": 0.09099355739354839,
      "loss": 1.083,
      "step": 55860
    },
    {
      "epoch": 90.13,
      "learning_rate": 0.09099033159032259,
      "loss": 1.1023,
      "step": 55880
    },
    {
      "epoch": 90.16,
      "learning_rate": 0.09098710578709678,
      "loss": 1.0907,
      "step": 55900
    },
    {
      "epoch": 90.19,
      "learning_rate": 0.09098387998387097,
      "loss": 1.0953,
      "step": 55920
    },
    {
      "epoch": 90.23,
      "learning_rate": 0.09098065418064516,
      "loss": 1.1195,
      "step": 55940
    },
    {
      "epoch": 90.26,
      "learning_rate": 0.09097742837741936,
      "loss": 1.0909,
      "step": 55960
    },
    {
      "epoch": 90.29,
      "learning_rate": 0.09097420257419356,
      "loss": 1.0634,
      "step": 55980
    },
    {
      "epoch": 90.32,
      "learning_rate": 0.09097097677096774,
      "loss": 1.0765,
      "step": 56000
    },
    {
      "epoch": 90.35,
      "learning_rate": 0.09096775096774194,
      "loss": 1.0791,
      "step": 56020
    },
    {
      "epoch": 90.39,
      "learning_rate": 0.09096452516451613,
      "loss": 1.0815,
      "step": 56040
    },
    {
      "epoch": 90.42,
      "learning_rate": 0.09096129936129033,
      "loss": 1.0503,
      "step": 56060
    },
    {
      "epoch": 90.45,
      "learning_rate": 0.09095807355806453,
      "loss": 1.0706,
      "step": 56080
    },
    {
      "epoch": 90.48,
      "learning_rate": 0.09095484775483871,
      "loss": 1.0906,
      "step": 56100
    },
    {
      "epoch": 90.52,
      "learning_rate": 0.09095162195161291,
      "loss": 1.0696,
      "step": 56120
    },
    {
      "epoch": 90.55,
      "learning_rate": 0.09094839614838711,
      "loss": 1.0598,
      "step": 56140
    },
    {
      "epoch": 90.58,
      "learning_rate": 0.0909451703451613,
      "loss": 1.0598,
      "step": 56160
    },
    {
      "epoch": 90.61,
      "learning_rate": 0.0909419445419355,
      "loss": 1.0745,
      "step": 56180
    },
    {
      "epoch": 90.65,
      "learning_rate": 0.09093871873870968,
      "loss": 1.0618,
      "step": 56200
    },
    {
      "epoch": 90.68,
      "learning_rate": 0.09093549293548388,
      "loss": 1.0842,
      "step": 56220
    },
    {
      "epoch": 90.71,
      "learning_rate": 0.09093226713225806,
      "loss": 1.1005,
      "step": 56240
    },
    {
      "epoch": 90.74,
      "learning_rate": 0.09092904132903226,
      "loss": 1.1188,
      "step": 56260
    },
    {
      "epoch": 90.77,
      "learning_rate": 0.09092581552580646,
      "loss": 1.0917,
      "step": 56280
    },
    {
      "epoch": 90.81,
      "learning_rate": 0.09092258972258065,
      "loss": 1.0867,
      "step": 56300
    },
    {
      "epoch": 90.84,
      "learning_rate": 0.09091936391935485,
      "loss": 1.1502,
      "step": 56320
    },
    {
      "epoch": 90.87,
      "learning_rate": 0.09091613811612903,
      "loss": 1.1651,
      "step": 56340
    },
    {
      "epoch": 90.9,
      "learning_rate": 0.09091291231290323,
      "loss": 1.103,
      "step": 56360
    },
    {
      "epoch": 90.94,
      "learning_rate": 0.09090968650967743,
      "loss": 1.1139,
      "step": 56380
    },
    {
      "epoch": 90.97,
      "learning_rate": 0.09090646070645161,
      "loss": 1.0928,
      "step": 56400
    },
    {
      "epoch": 91.0,
      "learning_rate": 0.09090323490322581,
      "loss": 1.0957,
      "step": 56420
    },
    {
      "epoch": 91.0,
      "eval_accuracy": {
        "accuracy": 0.7246897197720709
      },
      "eval_loss": 1.465917706489563,
      "eval_runtime": 2.7221,
      "eval_samples_per_second": 4706.318,
      "eval_steps_per_second": 73.84,
      "step": 56420
    },
    {
      "epoch": 91.03,
      "learning_rate": 0.09090000910000001,
      "loss": 1.1031,
      "step": 56440
    },
    {
      "epoch": 91.06,
      "learning_rate": 0.0908967832967742,
      "loss": 1.0461,
      "step": 56460
    },
    {
      "epoch": 91.1,
      "learning_rate": 0.0908935574935484,
      "loss": 1.0622,
      "step": 56480
    },
    {
      "epoch": 91.13,
      "learning_rate": 0.09089033169032258,
      "loss": 1.0549,
      "step": 56500
    },
    {
      "epoch": 91.16,
      "learning_rate": 0.09088710588709678,
      "loss": 1.0716,
      "step": 56520
    },
    {
      "epoch": 91.19,
      "learning_rate": 0.09088388008387097,
      "loss": 1.0977,
      "step": 56540
    },
    {
      "epoch": 91.23,
      "learning_rate": 0.09088065428064517,
      "loss": 1.0395,
      "step": 56560
    },
    {
      "epoch": 91.26,
      "learning_rate": 0.09087742847741935,
      "loss": 1.0825,
      "step": 56580
    },
    {
      "epoch": 91.29,
      "learning_rate": 0.09087420267419355,
      "loss": 1.0618,
      "step": 56600
    },
    {
      "epoch": 91.32,
      "learning_rate": 0.09087097687096775,
      "loss": 1.0609,
      "step": 56620
    },
    {
      "epoch": 91.35,
      "learning_rate": 0.09086775106774193,
      "loss": 1.0933,
      "step": 56640
    },
    {
      "epoch": 91.39,
      "learning_rate": 0.09086452526451613,
      "loss": 1.0689,
      "step": 56660
    },
    {
      "epoch": 91.42,
      "learning_rate": 0.09086129946129033,
      "loss": 1.0463,
      "step": 56680
    },
    {
      "epoch": 91.45,
      "learning_rate": 0.09085807365806452,
      "loss": 1.0511,
      "step": 56700
    },
    {
      "epoch": 91.48,
      "learning_rate": 0.09085484785483872,
      "loss": 1.1176,
      "step": 56720
    },
    {
      "epoch": 91.52,
      "learning_rate": 0.09085162205161292,
      "loss": 1.0918,
      "step": 56740
    },
    {
      "epoch": 91.55,
      "learning_rate": 0.0908483962483871,
      "loss": 1.1034,
      "step": 56760
    },
    {
      "epoch": 91.58,
      "learning_rate": 0.0908451704451613,
      "loss": 1.0372,
      "step": 56780
    },
    {
      "epoch": 91.61,
      "learning_rate": 0.0908419446419355,
      "loss": 1.0684,
      "step": 56800
    },
    {
      "epoch": 91.65,
      "learning_rate": 0.09083871883870968,
      "loss": 1.1131,
      "step": 56820
    },
    {
      "epoch": 91.68,
      "learning_rate": 0.09083549303548387,
      "loss": 1.0652,
      "step": 56840
    },
    {
      "epoch": 91.71,
      "learning_rate": 0.09083226723225807,
      "loss": 1.0701,
      "step": 56860
    },
    {
      "epoch": 91.74,
      "learning_rate": 0.09082904142903225,
      "loss": 1.1057,
      "step": 56880
    },
    {
      "epoch": 91.77,
      "learning_rate": 0.09082581562580645,
      "loss": 1.1299,
      "step": 56900
    },
    {
      "epoch": 91.81,
      "learning_rate": 0.09082258982258065,
      "loss": 1.1347,
      "step": 56920
    },
    {
      "epoch": 91.84,
      "learning_rate": 0.09081936401935484,
      "loss": 1.1058,
      "step": 56940
    },
    {
      "epoch": 91.87,
      "learning_rate": 0.09081613821612904,
      "loss": 1.0967,
      "step": 56960
    },
    {
      "epoch": 91.9,
      "learning_rate": 0.09081291241290324,
      "loss": 1.0852,
      "step": 56980
    },
    {
      "epoch": 91.94,
      "learning_rate": 0.09080968660967742,
      "loss": 1.1098,
      "step": 57000
    },
    {
      "epoch": 91.97,
      "learning_rate": 0.09080646080645162,
      "loss": 1.1162,
      "step": 57020
    },
    {
      "epoch": 92.0,
      "learning_rate": 0.09080323500322582,
      "loss": 1.0819,
      "step": 57040
    },
    {
      "epoch": 92.0,
      "eval_accuracy": {
        "accuracy": 0.7238310826633362
      },
      "eval_loss": 1.4373791217803955,
      "eval_runtime": 2.8727,
      "eval_samples_per_second": 4459.572,
      "eval_steps_per_second": 69.969,
      "step": 57040
    },
    {
      "epoch": 92.03,
      "learning_rate": 0.0908000092,
      "loss": 1.0979,
      "step": 57060
    },
    {
      "epoch": 92.06,
      "learning_rate": 0.0907967833967742,
      "loss": 1.0524,
      "step": 57080
    },
    {
      "epoch": 92.1,
      "learning_rate": 0.0907935575935484,
      "loss": 1.0123,
      "step": 57100
    },
    {
      "epoch": 92.13,
      "learning_rate": 0.09079033179032259,
      "loss": 1.0543,
      "step": 57120
    },
    {
      "epoch": 92.16,
      "learning_rate": 0.09078710598709677,
      "loss": 1.1098,
      "step": 57140
    },
    {
      "epoch": 92.19,
      "learning_rate": 0.09078388018387097,
      "loss": 1.1117,
      "step": 57160
    },
    {
      "epoch": 92.23,
      "learning_rate": 0.09078065438064516,
      "loss": 1.0873,
      "step": 57180
    },
    {
      "epoch": 92.26,
      "learning_rate": 0.09077742857741936,
      "loss": 1.1172,
      "step": 57200
    },
    {
      "epoch": 92.29,
      "learning_rate": 0.09077420277419355,
      "loss": 1.1244,
      "step": 57220
    },
    {
      "epoch": 92.32,
      "learning_rate": 0.09077097697096774,
      "loss": 1.0885,
      "step": 57240
    },
    {
      "epoch": 92.35,
      "learning_rate": 0.09076775116774194,
      "loss": 1.0678,
      "step": 57260
    },
    {
      "epoch": 92.39,
      "learning_rate": 0.09076452536451614,
      "loss": 1.0719,
      "step": 57280
    },
    {
      "epoch": 92.42,
      "learning_rate": 0.09076129956129032,
      "loss": 1.1038,
      "step": 57300
    },
    {
      "epoch": 92.45,
      "learning_rate": 0.09075807375806452,
      "loss": 1.0668,
      "step": 57320
    },
    {
      "epoch": 92.48,
      "learning_rate": 0.09075484795483872,
      "loss": 1.05,
      "step": 57340
    },
    {
      "epoch": 92.52,
      "learning_rate": 0.0907516221516129,
      "loss": 1.077,
      "step": 57360
    },
    {
      "epoch": 92.55,
      "learning_rate": 0.0907483963483871,
      "loss": 1.0763,
      "step": 57380
    },
    {
      "epoch": 92.58,
      "learning_rate": 0.0907451705451613,
      "loss": 1.0607,
      "step": 57400
    },
    {
      "epoch": 92.61,
      "learning_rate": 0.09074194474193549,
      "loss": 1.0601,
      "step": 57420
    },
    {
      "epoch": 92.65,
      "learning_rate": 0.09073871893870968,
      "loss": 1.0707,
      "step": 57440
    },
    {
      "epoch": 92.68,
      "learning_rate": 0.09073549313548389,
      "loss": 1.0763,
      "step": 57460
    },
    {
      "epoch": 92.71,
      "learning_rate": 0.09073226733225806,
      "loss": 1.0792,
      "step": 57480
    },
    {
      "epoch": 92.74,
      "learning_rate": 0.09072904152903226,
      "loss": 1.1006,
      "step": 57500
    },
    {
      "epoch": 92.77,
      "learning_rate": 0.09072581572580646,
      "loss": 1.0851,
      "step": 57520
    },
    {
      "epoch": 92.81,
      "learning_rate": 0.09072258992258064,
      "loss": 1.1001,
      "step": 57540
    },
    {
      "epoch": 92.84,
      "learning_rate": 0.09071936411935484,
      "loss": 1.1115,
      "step": 57560
    },
    {
      "epoch": 92.87,
      "learning_rate": 0.09071613831612904,
      "loss": 1.1201,
      "step": 57580
    },
    {
      "epoch": 92.9,
      "learning_rate": 0.09071291251290323,
      "loss": 1.1005,
      "step": 57600
    },
    {
      "epoch": 92.94,
      "learning_rate": 0.09070968670967743,
      "loss": 1.1159,
      "step": 57620
    },
    {
      "epoch": 92.97,
      "learning_rate": 0.09070646090645162,
      "loss": 1.0912,
      "step": 57640
    },
    {
      "epoch": 93.0,
      "learning_rate": 0.09070339639338709,
      "loss": 1.0752,
      "step": 57660
    },
    {
      "epoch": 93.0,
      "eval_accuracy": {
        "accuracy": 0.7361642338615253
      },
      "eval_loss": 1.3807677030563354,
      "eval_runtime": 2.9262,
      "eval_samples_per_second": 4378.008,
      "eval_steps_per_second": 68.689,
      "step": 57660
    },
    {
      "epoch": 93.03,
      "learning_rate": 0.09070017059016129,
      "loss": 1.0769,
      "step": 57680
    },
    {
      "epoch": 93.06,
      "learning_rate": 0.09069694478693549,
      "loss": 1.0588,
      "step": 57700
    },
    {
      "epoch": 93.1,
      "learning_rate": 0.09069371898370968,
      "loss": 1.0685,
      "step": 57720
    },
    {
      "epoch": 93.13,
      "learning_rate": 0.09069049318048387,
      "loss": 1.0841,
      "step": 57740
    },
    {
      "epoch": 93.16,
      "learning_rate": 0.09068726737725807,
      "loss": 1.0473,
      "step": 57760
    },
    {
      "epoch": 93.19,
      "learning_rate": 0.09068404157403226,
      "loss": 1.0092,
      "step": 57780
    },
    {
      "epoch": 93.23,
      "learning_rate": 0.09068081577080646,
      "loss": 1.0358,
      "step": 57800
    },
    {
      "epoch": 93.26,
      "learning_rate": 0.09067758996758066,
      "loss": 1.072,
      "step": 57820
    },
    {
      "epoch": 93.29,
      "learning_rate": 0.09067436416435484,
      "loss": 1.072,
      "step": 57840
    },
    {
      "epoch": 93.32,
      "learning_rate": 0.09067113836112904,
      "loss": 1.0638,
      "step": 57860
    },
    {
      "epoch": 93.35,
      "learning_rate": 0.09066791255790323,
      "loss": 1.0718,
      "step": 57880
    },
    {
      "epoch": 93.39,
      "learning_rate": 0.09066468675467743,
      "loss": 1.085,
      "step": 57900
    },
    {
      "epoch": 93.42,
      "learning_rate": 0.09066146095145161,
      "loss": 1.0542,
      "step": 57920
    },
    {
      "epoch": 93.45,
      "learning_rate": 0.09065823514822581,
      "loss": 1.093,
      "step": 57940
    },
    {
      "epoch": 93.48,
      "learning_rate": 0.090655009345,
      "loss": 1.0604,
      "step": 57960
    },
    {
      "epoch": 93.52,
      "learning_rate": 0.0906517835417742,
      "loss": 1.0884,
      "step": 57980
    },
    {
      "epoch": 93.55,
      "learning_rate": 0.0906485577385484,
      "loss": 1.1072,
      "step": 58000
    },
    {
      "epoch": 93.58,
      "learning_rate": 0.09064533193532258,
      "loss": 1.0755,
      "step": 58020
    },
    {
      "epoch": 93.61,
      "learning_rate": 0.09064210613209678,
      "loss": 1.0756,
      "step": 58040
    },
    {
      "epoch": 93.65,
      "learning_rate": 0.09063888032887098,
      "loss": 1.1073,
      "step": 58060
    },
    {
      "epoch": 93.68,
      "learning_rate": 0.09063565452564516,
      "loss": 1.146,
      "step": 58080
    },
    {
      "epoch": 93.71,
      "learning_rate": 0.09063242872241936,
      "loss": 1.0795,
      "step": 58100
    },
    {
      "epoch": 93.74,
      "learning_rate": 0.09062920291919356,
      "loss": 1.0822,
      "step": 58120
    },
    {
      "epoch": 93.77,
      "learning_rate": 0.09062597711596775,
      "loss": 1.0873,
      "step": 58140
    },
    {
      "epoch": 93.81,
      "learning_rate": 0.09062275131274194,
      "loss": 1.0569,
      "step": 58160
    },
    {
      "epoch": 93.84,
      "learning_rate": 0.09061952550951614,
      "loss": 1.1156,
      "step": 58180
    },
    {
      "epoch": 93.87,
      "learning_rate": 0.09061629970629033,
      "loss": 1.1279,
      "step": 58200
    },
    {
      "epoch": 93.9,
      "learning_rate": 0.09061307390306451,
      "loss": 1.0549,
      "step": 58220
    },
    {
      "epoch": 93.94,
      "learning_rate": 0.09060984809983871,
      "loss": 1.075,
      "step": 58240
    },
    {
      "epoch": 93.97,
      "learning_rate": 0.0906066222966129,
      "loss": 1.109,
      "step": 58260
    },
    {
      "epoch": 94.0,
      "learning_rate": 0.0906033964933871,
      "loss": 1.0923,
      "step": 58280
    },
    {
      "epoch": 94.0,
      "eval_accuracy": {
        "accuracy": 0.7284364998829131
      },
      "eval_loss": 1.3918904066085815,
      "eval_runtime": 2.8078,
      "eval_samples_per_second": 4562.662,
      "eval_steps_per_second": 71.587,
      "step": 58280
    },
    {
      "epoch": 94.03,
      "learning_rate": 0.0906001706901613,
      "loss": 1.1106,
      "step": 58300
    },
    {
      "epoch": 94.06,
      "learning_rate": 0.09059694488693548,
      "loss": 1.1078,
      "step": 58320
    },
    {
      "epoch": 94.1,
      "learning_rate": 0.09059371908370968,
      "loss": 1.0875,
      "step": 58340
    },
    {
      "epoch": 94.13,
      "learning_rate": 0.09059049328048388,
      "loss": 1.0533,
      "step": 58360
    },
    {
      "epoch": 94.16,
      "learning_rate": 0.09058726747725807,
      "loss": 1.0363,
      "step": 58380
    },
    {
      "epoch": 94.19,
      "learning_rate": 0.09058404167403226,
      "loss": 1.0543,
      "step": 58400
    },
    {
      "epoch": 94.23,
      "learning_rate": 0.09058081587080646,
      "loss": 1.0903,
      "step": 58420
    },
    {
      "epoch": 94.26,
      "learning_rate": 0.09057759006758065,
      "loss": 1.0803,
      "step": 58440
    },
    {
      "epoch": 94.29,
      "learning_rate": 0.09057436426435485,
      "loss": 1.0719,
      "step": 58460
    },
    {
      "epoch": 94.32,
      "learning_rate": 0.09057113846112905,
      "loss": 1.0526,
      "step": 58480
    },
    {
      "epoch": 94.35,
      "learning_rate": 0.09056791265790323,
      "loss": 1.0697,
      "step": 58500
    },
    {
      "epoch": 94.39,
      "learning_rate": 0.09056468685467742,
      "loss": 1.1114,
      "step": 58520
    },
    {
      "epoch": 94.42,
      "learning_rate": 0.09056146105145162,
      "loss": 1.0765,
      "step": 58540
    },
    {
      "epoch": 94.45,
      "learning_rate": 0.0905582352482258,
      "loss": 1.0718,
      "step": 58560
    },
    {
      "epoch": 94.48,
      "learning_rate": 0.090555009445,
      "loss": 1.0492,
      "step": 58580
    },
    {
      "epoch": 94.52,
      "learning_rate": 0.0905517836417742,
      "loss": 1.0785,
      "step": 58600
    },
    {
      "epoch": 94.55,
      "learning_rate": 0.09054855783854839,
      "loss": 1.0867,
      "step": 58620
    },
    {
      "epoch": 94.58,
      "learning_rate": 0.09054533203532258,
      "loss": 1.0847,
      "step": 58640
    },
    {
      "epoch": 94.61,
      "learning_rate": 0.09054210623209678,
      "loss": 1.0835,
      "step": 58660
    },
    {
      "epoch": 94.65,
      "learning_rate": 0.09053888042887097,
      "loss": 1.0777,
      "step": 58680
    },
    {
      "epoch": 94.68,
      "learning_rate": 0.09053565462564517,
      "loss": 1.0749,
      "step": 58700
    },
    {
      "epoch": 94.71,
      "learning_rate": 0.09053242882241937,
      "loss": 1.0631,
      "step": 58720
    },
    {
      "epoch": 94.74,
      "learning_rate": 0.09052920301919355,
      "loss": 1.059,
      "step": 58740
    },
    {
      "epoch": 94.77,
      "learning_rate": 0.09052597721596775,
      "loss": 1.09,
      "step": 58760
    },
    {
      "epoch": 94.81,
      "learning_rate": 0.09052275141274195,
      "loss": 1.1156,
      "step": 58780
    },
    {
      "epoch": 94.84,
      "learning_rate": 0.09051952560951614,
      "loss": 1.0751,
      "step": 58800
    },
    {
      "epoch": 94.87,
      "learning_rate": 0.09051629980629032,
      "loss": 1.0895,
      "step": 58820
    },
    {
      "epoch": 94.9,
      "learning_rate": 0.09051307400306453,
      "loss": 1.0964,
      "step": 58840
    },
    {
      "epoch": 94.94,
      "learning_rate": 0.0905098481998387,
      "loss": 1.0965,
      "step": 58860
    },
    {
      "epoch": 94.97,
      "learning_rate": 0.0905066223966129,
      "loss": 1.1254,
      "step": 58880
    },
    {
      "epoch": 95.0,
      "learning_rate": 0.0905033965933871,
      "loss": 1.0891,
      "step": 58900
    },
    {
      "epoch": 95.0,
      "eval_accuracy": {
        "accuracy": 0.7277339786121302
      },
      "eval_loss": 1.4327921867370605,
      "eval_runtime": 2.5838,
      "eval_samples_per_second": 4958.225,
      "eval_steps_per_second": 77.793,
      "step": 58900
    },
    {
      "epoch": 95.03,
      "learning_rate": 0.09050017079016129,
      "loss": 1.1572,
      "step": 58920
    },
    {
      "epoch": 95.06,
      "learning_rate": 0.09049694498693549,
      "loss": 1.0911,
      "step": 58940
    },
    {
      "epoch": 95.1,
      "learning_rate": 0.09049371918370969,
      "loss": 1.0468,
      "step": 58960
    },
    {
      "epoch": 95.13,
      "learning_rate": 0.09049049338048387,
      "loss": 1.0199,
      "step": 58980
    },
    {
      "epoch": 95.16,
      "learning_rate": 0.09048726757725807,
      "loss": 1.029,
      "step": 59000
    },
    {
      "epoch": 95.19,
      "learning_rate": 0.09048404177403227,
      "loss": 1.0338,
      "step": 59020
    },
    {
      "epoch": 95.23,
      "learning_rate": 0.09048081597080646,
      "loss": 1.0607,
      "step": 59040
    },
    {
      "epoch": 95.26,
      "learning_rate": 0.09047759016758065,
      "loss": 1.0661,
      "step": 59060
    },
    {
      "epoch": 95.29,
      "learning_rate": 0.09047436436435485,
      "loss": 1.0952,
      "step": 59080
    },
    {
      "epoch": 95.32,
      "learning_rate": 0.09047113856112904,
      "loss": 1.0886,
      "step": 59100
    },
    {
      "epoch": 95.35,
      "learning_rate": 0.09046791275790324,
      "loss": 1.0738,
      "step": 59120
    },
    {
      "epoch": 95.39,
      "learning_rate": 0.09046468695467744,
      "loss": 1.0645,
      "step": 59140
    },
    {
      "epoch": 95.42,
      "learning_rate": 0.09046146115145161,
      "loss": 1.0836,
      "step": 59160
    },
    {
      "epoch": 95.45,
      "learning_rate": 0.09045823534822581,
      "loss": 1.0739,
      "step": 59180
    },
    {
      "epoch": 95.48,
      "learning_rate": 0.090455009545,
      "loss": 1.0709,
      "step": 59200
    },
    {
      "epoch": 95.52,
      "learning_rate": 0.09045178374177419,
      "loss": 1.0746,
      "step": 59220
    },
    {
      "epoch": 95.55,
      "learning_rate": 0.09044855793854839,
      "loss": 1.1156,
      "step": 59240
    },
    {
      "epoch": 95.58,
      "learning_rate": 0.09044533213532259,
      "loss": 1.1015,
      "step": 59260
    },
    {
      "epoch": 95.61,
      "learning_rate": 0.09044210633209677,
      "loss": 1.1431,
      "step": 59280
    },
    {
      "epoch": 95.65,
      "learning_rate": 0.09043888052887097,
      "loss": 1.0876,
      "step": 59300
    },
    {
      "epoch": 95.68,
      "learning_rate": 0.09043565472564517,
      "loss": 1.0444,
      "step": 59320
    },
    {
      "epoch": 95.71,
      "learning_rate": 0.09043242892241936,
      "loss": 1.0365,
      "step": 59340
    },
    {
      "epoch": 95.74,
      "learning_rate": 0.09042920311919356,
      "loss": 1.0715,
      "step": 59360
    },
    {
      "epoch": 95.77,
      "learning_rate": 0.09042597731596776,
      "loss": 1.0743,
      "step": 59380
    },
    {
      "epoch": 95.81,
      "learning_rate": 0.09042275151274194,
      "loss": 1.1033,
      "step": 59400
    },
    {
      "epoch": 95.84,
      "learning_rate": 0.09041952570951614,
      "loss": 1.0894,
      "step": 59420
    },
    {
      "epoch": 95.87,
      "learning_rate": 0.09041629990629033,
      "loss": 1.1259,
      "step": 59440
    },
    {
      "epoch": 95.9,
      "learning_rate": 0.09041307410306451,
      "loss": 1.1071,
      "step": 59460
    },
    {
      "epoch": 95.94,
      "learning_rate": 0.09040984829983871,
      "loss": 1.1214,
      "step": 59480
    },
    {
      "epoch": 95.97,
      "learning_rate": 0.09040662249661291,
      "loss": 1.0729,
      "step": 59500
    },
    {
      "epoch": 96.0,
      "learning_rate": 0.0904033966933871,
      "loss": 1.0766,
      "step": 59520
    },
    {
      "epoch": 96.0,
      "eval_accuracy": {
        "accuracy": 0.720708765904301
      },
      "eval_loss": 1.4642759561538696,
      "eval_runtime": 2.6712,
      "eval_samples_per_second": 4795.905,
      "eval_steps_per_second": 75.246,
      "step": 59520
    },
    {
      "epoch": 96.03,
      "learning_rate": 0.0904001708901613,
      "loss": 1.1442,
      "step": 59540
    },
    {
      "epoch": 96.06,
      "learning_rate": 0.09039694508693549,
      "loss": 1.0159,
      "step": 59560
    },
    {
      "epoch": 96.1,
      "learning_rate": 0.09039371928370968,
      "loss": 1.0364,
      "step": 59580
    },
    {
      "epoch": 96.13,
      "learning_rate": 0.09039049348048388,
      "loss": 1.0417,
      "step": 59600
    },
    {
      "epoch": 96.16,
      "learning_rate": 0.09038726767725808,
      "loss": 1.0575,
      "step": 59620
    },
    {
      "epoch": 96.19,
      "learning_rate": 0.09038404187403226,
      "loss": 1.0576,
      "step": 59640
    },
    {
      "epoch": 96.23,
      "learning_rate": 0.09038081607080646,
      "loss": 1.0451,
      "step": 59660
    },
    {
      "epoch": 96.26,
      "learning_rate": 0.09037759026758066,
      "loss": 1.0594,
      "step": 59680
    },
    {
      "epoch": 96.29,
      "learning_rate": 0.09037436446435484,
      "loss": 1.0721,
      "step": 59700
    },
    {
      "epoch": 96.32,
      "learning_rate": 0.09037113866112904,
      "loss": 1.0615,
      "step": 59720
    },
    {
      "epoch": 96.35,
      "learning_rate": 0.09036791285790323,
      "loss": 1.0496,
      "step": 59740
    },
    {
      "epoch": 96.39,
      "learning_rate": 0.09036468705467741,
      "loss": 1.062,
      "step": 59760
    },
    {
      "epoch": 96.42,
      "learning_rate": 0.09036146125145163,
      "loss": 1.079,
      "step": 59780
    },
    {
      "epoch": 96.45,
      "learning_rate": 0.09035823544822581,
      "loss": 1.0755,
      "step": 59800
    },
    {
      "epoch": 96.48,
      "learning_rate": 0.090355009645,
      "loss": 1.0723,
      "step": 59820
    },
    {
      "epoch": 96.52,
      "learning_rate": 0.0903517838417742,
      "loss": 1.1048,
      "step": 59840
    },
    {
      "epoch": 96.55,
      "learning_rate": 0.0903485580385484,
      "loss": 1.0736,
      "step": 59860
    },
    {
      "epoch": 96.58,
      "learning_rate": 0.09034533223532258,
      "loss": 1.0931,
      "step": 59880
    },
    {
      "epoch": 96.61,
      "learning_rate": 0.09034210643209678,
      "loss": 1.0859,
      "step": 59900
    },
    {
      "epoch": 96.65,
      "learning_rate": 0.09033888062887098,
      "loss": 1.0512,
      "step": 59920
    },
    {
      "epoch": 96.68,
      "learning_rate": 0.09033565482564516,
      "loss": 1.0621,
      "step": 59940
    },
    {
      "epoch": 96.71,
      "learning_rate": 0.09033242902241936,
      "loss": 1.0666,
      "step": 59960
    },
    {
      "epoch": 96.74,
      "learning_rate": 0.09032920321919355,
      "loss": 1.0651,
      "step": 59980
    },
    {
      "epoch": 96.77,
      "learning_rate": 0.09032597741596775,
      "loss": 1.0894,
      "step": 60000
    },
    {
      "epoch": 96.81,
      "learning_rate": 0.09032275161274195,
      "loss": 1.0924,
      "step": 60020
    },
    {
      "epoch": 96.84,
      "learning_rate": 0.09031952580951613,
      "loss": 1.0873,
      "step": 60040
    },
    {
      "epoch": 96.87,
      "learning_rate": 0.09031630000629032,
      "loss": 1.0696,
      "step": 60060
    },
    {
      "epoch": 96.9,
      "learning_rate": 0.09031307420306453,
      "loss": 1.0538,
      "step": 60080
    },
    {
      "epoch": 96.94,
      "learning_rate": 0.09030984839983872,
      "loss": 1.0609,
      "step": 60100
    },
    {
      "epoch": 96.97,
      "learning_rate": 0.0903066225966129,
      "loss": 1.1183,
      "step": 60120
    },
    {
      "epoch": 97.0,
      "learning_rate": 0.0903035580835484,
      "loss": 1.1256,
      "step": 60140
    },
    {
      "epoch": 97.0,
      "eval_accuracy": {
        "accuracy": 0.7316368745609242
      },
      "eval_loss": 1.3848488330841064,
      "eval_runtime": 2.9464,
      "eval_samples_per_second": 4347.978,
      "eval_steps_per_second": 68.218,
      "step": 60140
    },
    {
      "epoch": 97.03,
      "learning_rate": 0.0903003322803226,
      "loss": 1.0907,
      "step": 60160
    },
    {
      "epoch": 97.06,
      "learning_rate": 0.09029710647709678,
      "loss": 1.0707,
      "step": 60180
    },
    {
      "epoch": 97.1,
      "learning_rate": 0.09029388067387097,
      "loss": 1.0503,
      "step": 60200
    },
    {
      "epoch": 97.13,
      "learning_rate": 0.09029065487064518,
      "loss": 1.0487,
      "step": 60220
    },
    {
      "epoch": 97.16,
      "learning_rate": 0.09028742906741935,
      "loss": 1.061,
      "step": 60240
    },
    {
      "epoch": 97.19,
      "learning_rate": 0.09028420326419355,
      "loss": 1.0176,
      "step": 60260
    },
    {
      "epoch": 97.23,
      "learning_rate": 0.09028097746096775,
      "loss": 1.0417,
      "step": 60280
    },
    {
      "epoch": 97.26,
      "learning_rate": 0.09027775165774193,
      "loss": 1.0482,
      "step": 60300
    },
    {
      "epoch": 97.29,
      "learning_rate": 0.09027452585451613,
      "loss": 1.058,
      "step": 60320
    },
    {
      "epoch": 97.32,
      "learning_rate": 0.09027130005129033,
      "loss": 1.0765,
      "step": 60340
    },
    {
      "epoch": 97.35,
      "learning_rate": 0.09026807424806452,
      "loss": 1.0859,
      "step": 60360
    },
    {
      "epoch": 97.39,
      "learning_rate": 0.09026484844483872,
      "loss": 1.0535,
      "step": 60380
    },
    {
      "epoch": 97.42,
      "learning_rate": 0.09026162264161292,
      "loss": 1.0804,
      "step": 60400
    },
    {
      "epoch": 97.45,
      "learning_rate": 0.0902583968383871,
      "loss": 1.0659,
      "step": 60420
    },
    {
      "epoch": 97.48,
      "learning_rate": 0.0902551710351613,
      "loss": 1.1121,
      "step": 60440
    },
    {
      "epoch": 97.52,
      "learning_rate": 0.0902519452319355,
      "loss": 1.0424,
      "step": 60460
    },
    {
      "epoch": 97.55,
      "learning_rate": 0.09024871942870968,
      "loss": 1.0512,
      "step": 60480
    },
    {
      "epoch": 97.58,
      "learning_rate": 0.09024549362548388,
      "loss": 1.1098,
      "step": 60500
    },
    {
      "epoch": 97.61,
      "learning_rate": 0.09024226782225807,
      "loss": 1.099,
      "step": 60520
    },
    {
      "epoch": 97.65,
      "learning_rate": 0.09023904201903225,
      "loss": 1.0588,
      "step": 60540
    },
    {
      "epoch": 97.68,
      "learning_rate": 0.09023581621580645,
      "loss": 1.0622,
      "step": 60560
    },
    {
      "epoch": 97.71,
      "learning_rate": 0.09023259041258065,
      "loss": 1.0414,
      "step": 60580
    },
    {
      "epoch": 97.74,
      "learning_rate": 0.09022936460935484,
      "loss": 1.0701,
      "step": 60600
    },
    {
      "epoch": 97.77,
      "learning_rate": 0.09022613880612904,
      "loss": 1.0771,
      "step": 60620
    },
    {
      "epoch": 97.81,
      "learning_rate": 0.09022291300290324,
      "loss": 1.1475,
      "step": 60640
    },
    {
      "epoch": 97.84,
      "learning_rate": 0.09021968719967742,
      "loss": 1.0693,
      "step": 60660
    },
    {
      "epoch": 97.87,
      "learning_rate": 0.09021646139645162,
      "loss": 1.1078,
      "step": 60680
    },
    {
      "epoch": 97.9,
      "learning_rate": 0.09021323559322582,
      "loss": 1.1259,
      "step": 60700
    },
    {
      "epoch": 97.94,
      "learning_rate": 0.09021000979,
      "loss": 1.0895,
      "step": 60720
    },
    {
      "epoch": 97.97,
      "learning_rate": 0.0902067839867742,
      "loss": 1.0958,
      "step": 60740
    },
    {
      "epoch": 98.0,
      "learning_rate": 0.0902035581835484,
      "loss": 1.1068,
      "step": 60760
    },
    {
      "epoch": 98.0,
      "eval_accuracy": {
        "accuracy": 0.7195378971196628
      },
      "eval_loss": 1.5062365531921387,
      "eval_runtime": 2.684,
      "eval_samples_per_second": 4773.146,
      "eval_steps_per_second": 74.889,
      "step": 60760
    },
    {
      "epoch": 98.03,
      "learning_rate": 0.09020033238032259,
      "loss": 1.181,
      "step": 60780
    },
    {
      "epoch": 98.06,
      "learning_rate": 0.09019710657709679,
      "loss": 1.0545,
      "step": 60800
    },
    {
      "epoch": 98.1,
      "learning_rate": 0.09019388077387097,
      "loss": 1.026,
      "step": 60820
    },
    {
      "epoch": 98.13,
      "learning_rate": 0.09019065497064516,
      "loss": 1.0581,
      "step": 60840
    },
    {
      "epoch": 98.16,
      "learning_rate": 0.09018742916741936,
      "loss": 1.0658,
      "step": 60860
    },
    {
      "epoch": 98.19,
      "learning_rate": 0.09018420336419355,
      "loss": 1.0505,
      "step": 60880
    },
    {
      "epoch": 98.23,
      "learning_rate": 0.09018097756096774,
      "loss": 1.0331,
      "step": 60900
    },
    {
      "epoch": 98.26,
      "learning_rate": 0.09017775175774194,
      "loss": 1.0586,
      "step": 60920
    },
    {
      "epoch": 98.29,
      "learning_rate": 0.09017452595451614,
      "loss": 1.0605,
      "step": 60940
    },
    {
      "epoch": 98.32,
      "learning_rate": 0.09017130015129032,
      "loss": 1.1006,
      "step": 60960
    },
    {
      "epoch": 98.35,
      "learning_rate": 0.09016807434806452,
      "loss": 1.1047,
      "step": 60980
    },
    {
      "epoch": 98.39,
      "learning_rate": 0.09016484854483872,
      "loss": 1.0396,
      "step": 61000
    },
    {
      "epoch": 98.42,
      "learning_rate": 0.0901616227416129,
      "loss": 1.0732,
      "step": 61020
    },
    {
      "epoch": 98.45,
      "learning_rate": 0.0901583969383871,
      "loss": 1.0628,
      "step": 61040
    },
    {
      "epoch": 98.48,
      "learning_rate": 0.09015517113516129,
      "loss": 1.0582,
      "step": 61060
    },
    {
      "epoch": 98.52,
      "learning_rate": 0.09015194533193549,
      "loss": 1.0192,
      "step": 61080
    },
    {
      "epoch": 98.55,
      "learning_rate": 0.09014871952870969,
      "loss": 1.0354,
      "step": 61100
    },
    {
      "epoch": 98.58,
      "learning_rate": 0.09014549372548387,
      "loss": 1.0376,
      "step": 61120
    },
    {
      "epoch": 98.61,
      "learning_rate": 0.09014226792225806,
      "loss": 1.0779,
      "step": 61140
    },
    {
      "epoch": 98.65,
      "learning_rate": 0.09013904211903227,
      "loss": 1.1119,
      "step": 61160
    },
    {
      "epoch": 98.68,
      "learning_rate": 0.09013581631580646,
      "loss": 1.0719,
      "step": 61180
    },
    {
      "epoch": 98.71,
      "learning_rate": 0.09013259051258064,
      "loss": 1.1126,
      "step": 61200
    },
    {
      "epoch": 98.74,
      "learning_rate": 0.09012936470935484,
      "loss": 1.1041,
      "step": 61220
    },
    {
      "epoch": 98.77,
      "learning_rate": 0.09012613890612904,
      "loss": 1.0629,
      "step": 61240
    },
    {
      "epoch": 98.81,
      "learning_rate": 0.09012291310290323,
      "loss": 1.0817,
      "step": 61260
    },
    {
      "epoch": 98.84,
      "learning_rate": 0.09011968729967743,
      "loss": 1.0694,
      "step": 61280
    },
    {
      "epoch": 98.87,
      "learning_rate": 0.09011646149645162,
      "loss": 1.1257,
      "step": 61300
    },
    {
      "epoch": 98.9,
      "learning_rate": 0.09011323569322581,
      "loss": 1.1025,
      "step": 61320
    },
    {
      "epoch": 98.94,
      "learning_rate": 0.09011000989000001,
      "loss": 1.0713,
      "step": 61340
    },
    {
      "epoch": 98.97,
      "learning_rate": 0.0901067840867742,
      "loss": 1.07,
      "step": 61360
    },
    {
      "epoch": 99.0,
      "learning_rate": 0.0901035582835484,
      "loss": 1.0463,
      "step": 61380
    },
    {
      "epoch": 99.0,
      "eval_accuracy": {
        "accuracy": 0.7299976582624307
      },
      "eval_loss": 1.3879131078720093,
      "eval_runtime": 3.8156,
      "eval_samples_per_second": 3357.538,
      "eval_steps_per_second": 52.679,
      "step": 61380
    },
    {
      "epoch": 99.03,
      "learning_rate": 0.09010033248032259,
      "loss": 1.0982,
      "step": 61400
    },
    {
      "epoch": 99.06,
      "learning_rate": 0.09009710667709678,
      "loss": 1.0492,
      "step": 61420
    },
    {
      "epoch": 99.1,
      "learning_rate": 0.09009388087387098,
      "loss": 1.044,
      "step": 61440
    },
    {
      "epoch": 99.13,
      "learning_rate": 0.09009065507064518,
      "loss": 1.031,
      "step": 61460
    },
    {
      "epoch": 99.16,
      "learning_rate": 0.09008742926741936,
      "loss": 1.0448,
      "step": 61480
    },
    {
      "epoch": 99.19,
      "learning_rate": 0.09008420346419355,
      "loss": 1.0097,
      "step": 61500
    },
    {
      "epoch": 99.23,
      "learning_rate": 0.09008097766096775,
      "loss": 1.0309,
      "step": 61520
    },
    {
      "epoch": 99.26,
      "learning_rate": 0.09007775185774194,
      "loss": 1.0403,
      "step": 61540
    },
    {
      "epoch": 99.29,
      "learning_rate": 0.09007452605451613,
      "loss": 1.0705,
      "step": 61560
    },
    {
      "epoch": 99.32,
      "learning_rate": 0.09007130025129033,
      "loss": 1.0463,
      "step": 61580
    },
    {
      "epoch": 99.35,
      "learning_rate": 0.09006807444806451,
      "loss": 1.0601,
      "step": 61600
    },
    {
      "epoch": 99.39,
      "learning_rate": 0.09006484864483871,
      "loss": 1.063,
      "step": 61620
    },
    {
      "epoch": 99.42,
      "learning_rate": 0.09006162284161291,
      "loss": 1.0671,
      "step": 61640
    },
    {
      "epoch": 99.45,
      "learning_rate": 0.0900583970383871,
      "loss": 1.0738,
      "step": 61660
    },
    {
      "epoch": 99.48,
      "learning_rate": 0.0900551712351613,
      "loss": 1.0479,
      "step": 61680
    },
    {
      "epoch": 99.52,
      "learning_rate": 0.0900519454319355,
      "loss": 1.0708,
      "step": 61700
    },
    {
      "epoch": 99.55,
      "learning_rate": 0.09004871962870968,
      "loss": 1.0837,
      "step": 61720
    },
    {
      "epoch": 99.58,
      "learning_rate": 0.09004549382548388,
      "loss": 1.0915,
      "step": 61740
    },
    {
      "epoch": 99.61,
      "learning_rate": 0.09004226802225808,
      "loss": 1.0801,
      "step": 61760
    },
    {
      "epoch": 99.65,
      "learning_rate": 0.09003904221903226,
      "loss": 1.0809,
      "step": 61780
    },
    {
      "epoch": 99.68,
      "learning_rate": 0.09003581641580645,
      "loss": 1.0584,
      "step": 61800
    },
    {
      "epoch": 99.71,
      "learning_rate": 0.09003259061258065,
      "loss": 1.0444,
      "step": 61820
    },
    {
      "epoch": 99.74,
      "learning_rate": 0.09002936480935485,
      "loss": 1.0675,
      "step": 61840
    },
    {
      "epoch": 99.77,
      "learning_rate": 0.09002613900612903,
      "loss": 1.1207,
      "step": 61860
    },
    {
      "epoch": 99.81,
      "learning_rate": 0.09002291320290323,
      "loss": 1.1189,
      "step": 61880
    },
    {
      "epoch": 99.84,
      "learning_rate": 0.09001968739967742,
      "loss": 1.0809,
      "step": 61900
    },
    {
      "epoch": 99.87,
      "learning_rate": 0.09001646159645162,
      "loss": 1.0972,
      "step": 61920
    },
    {
      "epoch": 99.9,
      "learning_rate": 0.09001323579322582,
      "loss": 1.1432,
      "step": 61940
    },
    {
      "epoch": 99.94,
      "learning_rate": 0.09001000999,
      "loss": 1.0876,
      "step": 61960
    },
    {
      "epoch": 99.97,
      "learning_rate": 0.0900067841867742,
      "loss": 1.0736,
      "step": 61980
    },
    {
      "epoch": 100.0,
      "learning_rate": 0.0900035583835484,
      "loss": 1.0735,
      "step": 62000
    },
    {
      "epoch": 100.0,
      "eval_accuracy": {
        "accuracy": 0.7314807587229725
      },
      "eval_loss": 1.4308534860610962,
      "eval_runtime": 3.6601,
      "eval_samples_per_second": 3500.197,
      "eval_steps_per_second": 54.917,
      "step": 62000
    },
    {
      "epoch": 100.03,
      "learning_rate": 0.09000033258032258,
      "loss": 1.115,
      "step": 62020
    },
    {
      "epoch": 100.06,
      "learning_rate": 0.08999710677709678,
      "loss": 1.0707,
      "step": 62040
    },
    {
      "epoch": 100.1,
      "learning_rate": 0.08999388097387098,
      "loss": 1.0498,
      "step": 62060
    },
    {
      "epoch": 100.13,
      "learning_rate": 0.08999065517064517,
      "loss": 1.0485,
      "step": 62080
    },
    {
      "epoch": 100.16,
      "learning_rate": 0.08998742936741937,
      "loss": 1.0426,
      "step": 62100
    },
    {
      "epoch": 100.19,
      "learning_rate": 0.08998420356419355,
      "loss": 1.0495,
      "step": 62120
    },
    {
      "epoch": 100.23,
      "learning_rate": 0.08998097776096774,
      "loss": 1.0557,
      "step": 62140
    },
    {
      "epoch": 100.26,
      "learning_rate": 0.08997791324790323,
      "loss": 1.0808,
      "step": 62160
    },
    {
      "epoch": 100.29,
      "learning_rate": 0.08997468744467743,
      "loss": 1.0486,
      "step": 62180
    },
    {
      "epoch": 100.32,
      "learning_rate": 0.08997146164145162,
      "loss": 1.0656,
      "step": 62200
    },
    {
      "epoch": 100.35,
      "learning_rate": 0.0899682358382258,
      "loss": 1.0483,
      "step": 62220
    },
    {
      "epoch": 100.39,
      "learning_rate": 0.08996501003500001,
      "loss": 1.0773,
      "step": 62240
    },
    {
      "epoch": 100.42,
      "learning_rate": 0.0899617842317742,
      "loss": 1.072,
      "step": 62260
    },
    {
      "epoch": 100.45,
      "learning_rate": 0.08995855842854839,
      "loss": 1.07,
      "step": 62280
    },
    {
      "epoch": 100.48,
      "learning_rate": 0.08995533262532258,
      "loss": 1.0442,
      "step": 62300
    },
    {
      "epoch": 100.52,
      "learning_rate": 0.08995210682209678,
      "loss": 1.1049,
      "step": 62320
    },
    {
      "epoch": 100.55,
      "learning_rate": 0.08994888101887097,
      "loss": 1.0835,
      "step": 62340
    },
    {
      "epoch": 100.58,
      "learning_rate": 0.08994565521564517,
      "loss": 1.1123,
      "step": 62360
    },
    {
      "epoch": 100.61,
      "learning_rate": 0.08994242941241937,
      "loss": 1.1117,
      "step": 62380
    },
    {
      "epoch": 100.65,
      "learning_rate": 0.08993920360919355,
      "loss": 1.0964,
      "step": 62400
    },
    {
      "epoch": 100.68,
      "learning_rate": 0.08993597780596775,
      "loss": 1.1077,
      "step": 62420
    },
    {
      "epoch": 100.71,
      "learning_rate": 0.08993275200274194,
      "loss": 1.0697,
      "step": 62440
    },
    {
      "epoch": 100.74,
      "learning_rate": 0.08992952619951614,
      "loss": 1.0419,
      "step": 62460
    },
    {
      "epoch": 100.77,
      "learning_rate": 0.08992630039629033,
      "loss": 1.0689,
      "step": 62480
    },
    {
      "epoch": 100.81,
      "learning_rate": 0.08992307459306452,
      "loss": 1.0513,
      "step": 62500
    },
    {
      "epoch": 100.84,
      "learning_rate": 0.0899198487898387,
      "loss": 1.0573,
      "step": 62520
    },
    {
      "epoch": 100.87,
      "learning_rate": 0.08991662298661292,
      "loss": 1.0815,
      "step": 62540
    },
    {
      "epoch": 100.9,
      "learning_rate": 0.0899133971833871,
      "loss": 1.0878,
      "step": 62560
    },
    {
      "epoch": 100.94,
      "learning_rate": 0.08991017138016129,
      "loss": 1.071,
      "step": 62580
    },
    {
      "epoch": 100.97,
      "learning_rate": 0.08990694557693549,
      "loss": 1.1063,
      "step": 62600
    },
    {
      "epoch": 101.0,
      "learning_rate": 0.08990371977370969,
      "loss": 1.0894,
      "step": 62620
    },
    {
      "epoch": 101.0,
      "eval_accuracy": {
        "accuracy": 0.7307001795332136
      },
      "eval_loss": 1.4003866910934448,
      "eval_runtime": 2.5883,
      "eval_samples_per_second": 4949.672,
      "eval_steps_per_second": 77.659,
      "step": 62620
    },
    {
      "epoch": 101.03,
      "learning_rate": 0.08990049397048387,
      "loss": 1.1001,
      "step": 62640
    },
    {
      "epoch": 101.06,
      "learning_rate": 0.08989726816725807,
      "loss": 1.0547,
      "step": 62660
    },
    {
      "epoch": 101.1,
      "learning_rate": 0.08989404236403226,
      "loss": 1.0255,
      "step": 62680
    },
    {
      "epoch": 101.13,
      "learning_rate": 0.08989081656080646,
      "loss": 1.081,
      "step": 62700
    },
    {
      "epoch": 101.16,
      "learning_rate": 0.08988759075758065,
      "loss": 1.065,
      "step": 62720
    },
    {
      "epoch": 101.19,
      "learning_rate": 0.08988436495435484,
      "loss": 1.0924,
      "step": 62740
    },
    {
      "epoch": 101.23,
      "learning_rate": 0.08988113915112904,
      "loss": 1.0692,
      "step": 62760
    },
    {
      "epoch": 101.26,
      "learning_rate": 0.08987791334790324,
      "loss": 1.0871,
      "step": 62780
    },
    {
      "epoch": 101.29,
      "learning_rate": 0.08987468754467742,
      "loss": 1.0924,
      "step": 62800
    },
    {
      "epoch": 101.32,
      "learning_rate": 0.08987146174145162,
      "loss": 1.0876,
      "step": 62820
    },
    {
      "epoch": 101.35,
      "learning_rate": 0.08986823593822582,
      "loss": 1.0703,
      "step": 62840
    },
    {
      "epoch": 101.39,
      "learning_rate": 0.089865010135,
      "loss": 1.0286,
      "step": 62860
    },
    {
      "epoch": 101.42,
      "learning_rate": 0.08986178433177419,
      "loss": 1.0255,
      "step": 62880
    },
    {
      "epoch": 101.45,
      "learning_rate": 0.08985855852854839,
      "loss": 1.0156,
      "step": 62900
    },
    {
      "epoch": 101.48,
      "learning_rate": 0.08985533272532259,
      "loss": 1.0323,
      "step": 62920
    },
    {
      "epoch": 101.52,
      "learning_rate": 0.08985210692209677,
      "loss": 1.0409,
      "step": 62940
    },
    {
      "epoch": 101.55,
      "learning_rate": 0.08984888111887097,
      "loss": 1.0668,
      "step": 62960
    },
    {
      "epoch": 101.58,
      "learning_rate": 0.08984565531564516,
      "loss": 1.041,
      "step": 62980
    },
    {
      "epoch": 101.61,
      "learning_rate": 0.08984242951241936,
      "loss": 1.0783,
      "step": 63000
    },
    {
      "epoch": 101.65,
      "learning_rate": 0.08983920370919356,
      "loss": 1.0245,
      "step": 63020
    },
    {
      "epoch": 101.68,
      "learning_rate": 0.08983597790596774,
      "loss": 1.0645,
      "step": 63040
    },
    {
      "epoch": 101.71,
      "learning_rate": 0.08983275210274194,
      "loss": 1.0796,
      "step": 63060
    },
    {
      "epoch": 101.74,
      "learning_rate": 0.08982952629951614,
      "loss": 1.0867,
      "step": 63080
    },
    {
      "epoch": 101.77,
      "learning_rate": 0.08982630049629033,
      "loss": 1.0856,
      "step": 63100
    },
    {
      "epoch": 101.81,
      "learning_rate": 0.08982307469306453,
      "loss": 1.0762,
      "step": 63120
    },
    {
      "epoch": 101.84,
      "learning_rate": 0.08981984888983872,
      "loss": 1.0603,
      "step": 63140
    },
    {
      "epoch": 101.87,
      "learning_rate": 0.08981662308661291,
      "loss": 1.0864,
      "step": 63160
    },
    {
      "epoch": 101.9,
      "learning_rate": 0.0898133972833871,
      "loss": 1.0875,
      "step": 63180
    },
    {
      "epoch": 101.94,
      "learning_rate": 0.0898101714801613,
      "loss": 1.1018,
      "step": 63200
    },
    {
      "epoch": 101.97,
      "learning_rate": 0.08980694567693548,
      "loss": 1.0839,
      "step": 63220
    },
    {
      "epoch": 102.0,
      "learning_rate": 0.08980371987370968,
      "loss": 1.0694,
      "step": 63240
    },
    {
      "epoch": 102.0,
      "eval_accuracy": {
        "accuracy": 0.7311685270470689
      },
      "eval_loss": 1.3933711051940918,
      "eval_runtime": 2.8902,
      "eval_samples_per_second": 4432.514,
      "eval_steps_per_second": 69.545,
      "step": 63240
    },
    {
      "epoch": 102.03,
      "learning_rate": 0.08980049407048388,
      "loss": 1.084,
      "step": 63260
    },
    {
      "epoch": 102.06,
      "learning_rate": 0.08979726826725806,
      "loss": 1.0446,
      "step": 63280
    },
    {
      "epoch": 102.1,
      "learning_rate": 0.08979404246403226,
      "loss": 1.0458,
      "step": 63300
    },
    {
      "epoch": 102.13,
      "learning_rate": 0.08979081666080646,
      "loss": 1.0641,
      "step": 63320
    },
    {
      "epoch": 102.16,
      "learning_rate": 0.08978759085758065,
      "loss": 1.0772,
      "step": 63340
    },
    {
      "epoch": 102.19,
      "learning_rate": 0.08978436505435484,
      "loss": 1.0442,
      "step": 63360
    },
    {
      "epoch": 102.23,
      "learning_rate": 0.08978113925112904,
      "loss": 1.0572,
      "step": 63380
    },
    {
      "epoch": 102.26,
      "learning_rate": 0.08977791344790323,
      "loss": 1.0787,
      "step": 63400
    },
    {
      "epoch": 102.29,
      "learning_rate": 0.08977468764467743,
      "loss": 1.0531,
      "step": 63420
    },
    {
      "epoch": 102.32,
      "learning_rate": 0.08977146184145163,
      "loss": 1.0744,
      "step": 63440
    },
    {
      "epoch": 102.35,
      "learning_rate": 0.08976823603822581,
      "loss": 1.0766,
      "step": 63460
    },
    {
      "epoch": 102.39,
      "learning_rate": 0.08976501023500001,
      "loss": 1.0402,
      "step": 63480
    },
    {
      "epoch": 102.42,
      "learning_rate": 0.0897617844317742,
      "loss": 1.0411,
      "step": 63500
    },
    {
      "epoch": 102.45,
      "learning_rate": 0.08975855862854838,
      "loss": 1.0782,
      "step": 63520
    },
    {
      "epoch": 102.48,
      "learning_rate": 0.08975533282532258,
      "loss": 1.0736,
      "step": 63540
    },
    {
      "epoch": 102.52,
      "learning_rate": 0.08975210702209678,
      "loss": 1.0494,
      "step": 63560
    },
    {
      "epoch": 102.55,
      "learning_rate": 0.08974888121887097,
      "loss": 1.0513,
      "step": 63580
    },
    {
      "epoch": 102.58,
      "learning_rate": 0.08974565541564516,
      "loss": 1.032,
      "step": 63600
    },
    {
      "epoch": 102.61,
      "learning_rate": 0.08974242961241936,
      "loss": 1.0611,
      "step": 63620
    },
    {
      "epoch": 102.65,
      "learning_rate": 0.08973920380919355,
      "loss": 1.0892,
      "step": 63640
    },
    {
      "epoch": 102.68,
      "learning_rate": 0.08973597800596775,
      "loss": 1.1257,
      "step": 63660
    },
    {
      "epoch": 102.71,
      "learning_rate": 0.08973275220274195,
      "loss": 1.1113,
      "step": 63680
    },
    {
      "epoch": 102.74,
      "learning_rate": 0.08972952639951613,
      "loss": 1.0825,
      "step": 63700
    },
    {
      "epoch": 102.77,
      "learning_rate": 0.08972630059629033,
      "loss": 1.0491,
      "step": 63720
    },
    {
      "epoch": 102.81,
      "learning_rate": 0.08972307479306453,
      "loss": 1.0413,
      "step": 63740
    },
    {
      "epoch": 102.84,
      "learning_rate": 0.08971984898983872,
      "loss": 1.0572,
      "step": 63760
    },
    {
      "epoch": 102.87,
      "learning_rate": 0.08971662318661291,
      "loss": 1.0707,
      "step": 63780
    },
    {
      "epoch": 102.9,
      "learning_rate": 0.0897133973833871,
      "loss": 1.0778,
      "step": 63800
    },
    {
      "epoch": 102.94,
      "learning_rate": 0.08971017158016129,
      "loss": 1.0793,
      "step": 63820
    },
    {
      "epoch": 102.97,
      "learning_rate": 0.08970694577693548,
      "loss": 1.081,
      "step": 63840
    },
    {
      "epoch": 103.0,
      "learning_rate": 0.08970371997370968,
      "loss": 1.0725,
      "step": 63860
    },
    {
      "epoch": 103.0,
      "eval_accuracy": {
        "accuracy": 0.7305440636952619
      },
      "eval_loss": 1.3762059211730957,
      "eval_runtime": 2.8596,
      "eval_samples_per_second": 4480.036,
      "eval_steps_per_second": 70.29,
      "step": 63860
    },
    {
      "epoch": 103.03,
      "learning_rate": 0.08970049417048387,
      "loss": 1.0788,
      "step": 63880
    },
    {
      "epoch": 103.06,
      "learning_rate": 0.08969726836725807,
      "loss": 1.0701,
      "step": 63900
    },
    {
      "epoch": 103.1,
      "learning_rate": 0.08969404256403227,
      "loss": 1.081,
      "step": 63920
    },
    {
      "epoch": 103.13,
      "learning_rate": 0.08969081676080645,
      "loss": 1.061,
      "step": 63940
    },
    {
      "epoch": 103.16,
      "learning_rate": 0.08968759095758065,
      "loss": 1.0614,
      "step": 63960
    },
    {
      "epoch": 103.19,
      "learning_rate": 0.08968436515435485,
      "loss": 1.0439,
      "step": 63980
    },
    {
      "epoch": 103.23,
      "learning_rate": 0.08968113935112904,
      "loss": 1.0624,
      "step": 64000
    },
    {
      "epoch": 103.26,
      "learning_rate": 0.08967791354790323,
      "loss": 1.0753,
      "step": 64020
    },
    {
      "epoch": 103.29,
      "learning_rate": 0.08967468774467743,
      "loss": 1.101,
      "step": 64040
    },
    {
      "epoch": 103.32,
      "learning_rate": 0.08967146194145162,
      "loss": 1.0928,
      "step": 64060
    },
    {
      "epoch": 103.35,
      "learning_rate": 0.08966823613822582,
      "loss": 1.0152,
      "step": 64080
    },
    {
      "epoch": 103.39,
      "learning_rate": 0.089665010335,
      "loss": 1.0185,
      "step": 64100
    },
    {
      "epoch": 103.42,
      "learning_rate": 0.08966178453177419,
      "loss": 1.0591,
      "step": 64120
    },
    {
      "epoch": 103.45,
      "learning_rate": 0.08965855872854839,
      "loss": 1.0511,
      "step": 64140
    },
    {
      "epoch": 103.48,
      "learning_rate": 0.08965533292532259,
      "loss": 1.0317,
      "step": 64160
    },
    {
      "epoch": 103.52,
      "learning_rate": 0.08965210712209677,
      "loss": 1.0449,
      "step": 64180
    },
    {
      "epoch": 103.55,
      "learning_rate": 0.08964888131887097,
      "loss": 1.0313,
      "step": 64200
    },
    {
      "epoch": 103.58,
      "learning_rate": 0.08964565551564517,
      "loss": 1.0302,
      "step": 64220
    },
    {
      "epoch": 103.61,
      "learning_rate": 0.08964242971241936,
      "loss": 1.0907,
      "step": 64240
    },
    {
      "epoch": 103.65,
      "learning_rate": 0.08963920390919355,
      "loss": 1.087,
      "step": 64260
    },
    {
      "epoch": 103.68,
      "learning_rate": 0.08963597810596775,
      "loss": 1.0852,
      "step": 64280
    },
    {
      "epoch": 103.71,
      "learning_rate": 0.08963275230274194,
      "loss": 1.0735,
      "step": 64300
    },
    {
      "epoch": 103.74,
      "learning_rate": 0.08962952649951614,
      "loss": 1.0789,
      "step": 64320
    },
    {
      "epoch": 103.77,
      "learning_rate": 0.08962630069629034,
      "loss": 1.0864,
      "step": 64340
    },
    {
      "epoch": 103.81,
      "learning_rate": 0.08962307489306452,
      "loss": 1.0467,
      "step": 64360
    },
    {
      "epoch": 103.84,
      "learning_rate": 0.08961984908983872,
      "loss": 1.0709,
      "step": 64380
    },
    {
      "epoch": 103.87,
      "learning_rate": 0.0896166232866129,
      "loss": 1.068,
      "step": 64400
    },
    {
      "epoch": 103.9,
      "learning_rate": 0.0896133974833871,
      "loss": 1.0951,
      "step": 64420
    },
    {
      "epoch": 103.94,
      "learning_rate": 0.08961017168016129,
      "loss": 1.0779,
      "step": 64440
    },
    {
      "epoch": 103.97,
      "learning_rate": 0.08960710716709679,
      "loss": 1.0831,
      "step": 64460
    },
    {
      "epoch": 104.0,
      "learning_rate": 0.08960388136387097,
      "loss": 1.067,
      "step": 64480
    },
    {
      "epoch": 104.0,
      "eval_accuracy": {
        "accuracy": 0.7410038248380298
      },
      "eval_loss": 1.3975645303726196,
      "eval_runtime": 2.8038,
      "eval_samples_per_second": 4569.218,
      "eval_steps_per_second": 71.689,
      "step": 64480
    },
    {
      "epoch": 104.03,
      "learning_rate": 0.08960081685080645,
      "loss": 1.1292,
      "step": 64500
    },
    {
      "epoch": 104.06,
      "learning_rate": 0.08959759104758065,
      "loss": 1.1363,
      "step": 64520
    },
    {
      "epoch": 104.1,
      "learning_rate": 0.08959436524435485,
      "loss": 1.0629,
      "step": 64540
    },
    {
      "epoch": 104.13,
      "learning_rate": 0.08959113944112904,
      "loss": 1.0447,
      "step": 64560
    },
    {
      "epoch": 104.16,
      "learning_rate": 0.08958791363790324,
      "loss": 1.0253,
      "step": 64580
    },
    {
      "epoch": 104.19,
      "learning_rate": 0.08958468783467742,
      "loss": 1.0301,
      "step": 64600
    },
    {
      "epoch": 104.23,
      "learning_rate": 0.08958146203145162,
      "loss": 1.056,
      "step": 64620
    },
    {
      "epoch": 104.26,
      "learning_rate": 0.08957823622822582,
      "loss": 1.0384,
      "step": 64640
    },
    {
      "epoch": 104.29,
      "learning_rate": 0.089575010425,
      "loss": 1.0574,
      "step": 64660
    },
    {
      "epoch": 104.32,
      "learning_rate": 0.08957178462177419,
      "loss": 1.0245,
      "step": 64680
    },
    {
      "epoch": 104.35,
      "learning_rate": 0.0895685588185484,
      "loss": 1.0506,
      "step": 64700
    },
    {
      "epoch": 104.39,
      "learning_rate": 0.08956533301532259,
      "loss": 1.0709,
      "step": 64720
    },
    {
      "epoch": 104.42,
      "learning_rate": 0.08956210721209677,
      "loss": 1.0618,
      "step": 64740
    },
    {
      "epoch": 104.45,
      "learning_rate": 0.08955888140887097,
      "loss": 1.0573,
      "step": 64760
    },
    {
      "epoch": 104.48,
      "learning_rate": 0.08955565560564517,
      "loss": 1.0322,
      "step": 64780
    },
    {
      "epoch": 104.52,
      "learning_rate": 0.08955242980241936,
      "loss": 1.0431,
      "step": 64800
    },
    {
      "epoch": 104.55,
      "learning_rate": 0.08954920399919356,
      "loss": 1.0656,
      "step": 64820
    },
    {
      "epoch": 104.58,
      "learning_rate": 0.08954597819596774,
      "loss": 1.0685,
      "step": 64840
    },
    {
      "epoch": 104.61,
      "learning_rate": 0.08954275239274194,
      "loss": 1.0601,
      "step": 64860
    },
    {
      "epoch": 104.65,
      "learning_rate": 0.08953952658951614,
      "loss": 1.0809,
      "step": 64880
    },
    {
      "epoch": 104.68,
      "learning_rate": 0.08953630078629032,
      "loss": 1.0796,
      "step": 64900
    },
    {
      "epoch": 104.71,
      "learning_rate": 0.08953307498306452,
      "loss": 1.0405,
      "step": 64920
    },
    {
      "epoch": 104.74,
      "learning_rate": 0.08952984917983872,
      "loss": 1.0427,
      "step": 64940
    },
    {
      "epoch": 104.77,
      "learning_rate": 0.08952662337661291,
      "loss": 1.0735,
      "step": 64960
    },
    {
      "epoch": 104.81,
      "learning_rate": 0.08952339757338709,
      "loss": 1.0928,
      "step": 64980
    },
    {
      "epoch": 104.84,
      "learning_rate": 0.0895201717701613,
      "loss": 1.0713,
      "step": 65000
    },
    {
      "epoch": 104.87,
      "learning_rate": 0.08951694596693549,
      "loss": 1.069,
      "step": 65020
    },
    {
      "epoch": 104.9,
      "learning_rate": 0.08951372016370968,
      "loss": 1.0839,
      "step": 65040
    },
    {
      "epoch": 104.94,
      "learning_rate": 0.08951049436048387,
      "loss": 1.0782,
      "step": 65060
    },
    {
      "epoch": 104.97,
      "learning_rate": 0.08950726855725807,
      "loss": 1.0804,
      "step": 65080
    },
    {
      "epoch": 105.0,
      "learning_rate": 0.08950404275403226,
      "loss": 1.0808,
      "step": 65100
    },
    {
      "epoch": 105.0,
      "eval_accuracy": {
        "accuracy": 0.7307782374521895
      },
      "eval_loss": 1.4317530393600464,
      "eval_runtime": 2.6815,
      "eval_samples_per_second": 4777.506,
      "eval_steps_per_second": 74.957,
      "step": 65100
    },
    {
      "epoch": 105.03,
      "learning_rate": 0.08950081695080646,
      "loss": 1.0906,
      "step": 65120
    },
    {
      "epoch": 105.06,
      "learning_rate": 0.08949759114758064,
      "loss": 1.078,
      "step": 65140
    },
    {
      "epoch": 105.1,
      "learning_rate": 0.08949436534435484,
      "loss": 1.0671,
      "step": 65160
    },
    {
      "epoch": 105.13,
      "learning_rate": 0.08949113954112904,
      "loss": 1.0403,
      "step": 65180
    },
    {
      "epoch": 105.16,
      "learning_rate": 0.08948791373790323,
      "loss": 1.0264,
      "step": 65200
    },
    {
      "epoch": 105.19,
      "learning_rate": 0.08948468793467743,
      "loss": 1.0377,
      "step": 65220
    },
    {
      "epoch": 105.23,
      "learning_rate": 0.08948146213145163,
      "loss": 1.0791,
      "step": 65240
    },
    {
      "epoch": 105.26,
      "learning_rate": 0.08947823632822581,
      "loss": 1.0693,
      "step": 65260
    },
    {
      "epoch": 105.29,
      "learning_rate": 0.08947501052500001,
      "loss": 1.0708,
      "step": 65280
    },
    {
      "epoch": 105.32,
      "learning_rate": 0.08947178472177421,
      "loss": 1.0299,
      "step": 65300
    },
    {
      "epoch": 105.35,
      "learning_rate": 0.0894685589185484,
      "loss": 1.0422,
      "step": 65320
    },
    {
      "epoch": 105.39,
      "learning_rate": 0.08946533311532258,
      "loss": 1.0522,
      "step": 65340
    },
    {
      "epoch": 105.42,
      "learning_rate": 0.08946210731209678,
      "loss": 1.0619,
      "step": 65360
    },
    {
      "epoch": 105.45,
      "learning_rate": 0.08945888150887096,
      "loss": 1.037,
      "step": 65380
    },
    {
      "epoch": 105.48,
      "learning_rate": 0.08945565570564516,
      "loss": 1.0484,
      "step": 65400
    },
    {
      "epoch": 105.52,
      "learning_rate": 0.08945242990241936,
      "loss": 1.0742,
      "step": 65420
    },
    {
      "epoch": 105.55,
      "learning_rate": 0.08944920409919355,
      "loss": 1.0608,
      "step": 65440
    },
    {
      "epoch": 105.58,
      "learning_rate": 0.08944597829596775,
      "loss": 1.0635,
      "step": 65460
    },
    {
      "epoch": 105.61,
      "learning_rate": 0.08944275249274194,
      "loss": 1.0514,
      "step": 65480
    },
    {
      "epoch": 105.65,
      "learning_rate": 0.08943952668951613,
      "loss": 1.0718,
      "step": 65500
    },
    {
      "epoch": 105.68,
      "learning_rate": 0.08943630088629033,
      "loss": 1.0667,
      "step": 65520
    },
    {
      "epoch": 105.71,
      "learning_rate": 0.08943307508306453,
      "loss": 1.0604,
      "step": 65540
    },
    {
      "epoch": 105.74,
      "learning_rate": 0.08942984927983871,
      "loss": 1.0678,
      "step": 65560
    },
    {
      "epoch": 105.77,
      "learning_rate": 0.08942662347661291,
      "loss": 1.0719,
      "step": 65580
    },
    {
      "epoch": 105.81,
      "learning_rate": 0.08942339767338711,
      "loss": 1.0994,
      "step": 65600
    },
    {
      "epoch": 105.84,
      "learning_rate": 0.0894201718701613,
      "loss": 1.0543,
      "step": 65620
    },
    {
      "epoch": 105.87,
      "learning_rate": 0.08941694606693548,
      "loss": 1.066,
      "step": 65640
    },
    {
      "epoch": 105.9,
      "learning_rate": 0.08941372026370968,
      "loss": 1.0958,
      "step": 65660
    },
    {
      "epoch": 105.94,
      "learning_rate": 0.08941049446048387,
      "loss": 1.075,
      "step": 65680
    },
    {
      "epoch": 105.97,
      "learning_rate": 0.08940726865725807,
      "loss": 1.1033,
      "step": 65700
    },
    {
      "epoch": 106.0,
      "learning_rate": 0.08940404285403226,
      "loss": 1.0679,
      "step": 65720
    },
    {
      "epoch": 106.0,
      "eval_accuracy": {
        "accuracy": 0.7392865506205605
      },
      "eval_loss": 1.3762118816375732,
      "eval_runtime": 4.8867,
      "eval_samples_per_second": 2621.589,
      "eval_steps_per_second": 41.132,
      "step": 65720
    },
    {
      "epoch": 106.03,
      "learning_rate": 0.08940081705080645,
      "loss": 1.0685,
      "step": 65740
    },
    {
      "epoch": 106.06,
      "learning_rate": 0.08939759124758065,
      "loss": 1.079,
      "step": 65760
    },
    {
      "epoch": 106.1,
      "learning_rate": 0.08939436544435485,
      "loss": 1.0587,
      "step": 65780
    },
    {
      "epoch": 106.13,
      "learning_rate": 0.08939113964112903,
      "loss": 1.0972,
      "step": 65800
    },
    {
      "epoch": 106.16,
      "learning_rate": 0.08938791383790323,
      "loss": 1.0841,
      "step": 65820
    },
    {
      "epoch": 106.19,
      "learning_rate": 0.08938468803467743,
      "loss": 1.0137,
      "step": 65840
    },
    {
      "epoch": 106.23,
      "learning_rate": 0.08938146223145162,
      "loss": 1.0506,
      "step": 65860
    },
    {
      "epoch": 106.26,
      "learning_rate": 0.08937823642822582,
      "loss": 1.043,
      "step": 65880
    },
    {
      "epoch": 106.29,
      "learning_rate": 0.08937501062500001,
      "loss": 1.067,
      "step": 65900
    },
    {
      "epoch": 106.32,
      "learning_rate": 0.08937178482177419,
      "loss": 1.0611,
      "step": 65920
    },
    {
      "epoch": 106.35,
      "learning_rate": 0.0893685590185484,
      "loss": 1.0421,
      "step": 65940
    },
    {
      "epoch": 106.39,
      "learning_rate": 0.08936533321532258,
      "loss": 1.0552,
      "step": 65960
    },
    {
      "epoch": 106.42,
      "learning_rate": 0.08936210741209677,
      "loss": 1.0533,
      "step": 65980
    },
    {
      "epoch": 106.45,
      "learning_rate": 0.08935888160887097,
      "loss": 1.0679,
      "step": 66000
    },
    {
      "epoch": 106.48,
      "learning_rate": 0.08935565580564517,
      "loss": 1.0807,
      "step": 66020
    },
    {
      "epoch": 106.52,
      "learning_rate": 0.08935243000241935,
      "loss": 1.0578,
      "step": 66040
    },
    {
      "epoch": 106.55,
      "learning_rate": 0.08934920419919355,
      "loss": 1.0603,
      "step": 66060
    },
    {
      "epoch": 106.58,
      "learning_rate": 0.08934597839596775,
      "loss": 1.047,
      "step": 66080
    },
    {
      "epoch": 106.61,
      "learning_rate": 0.08934275259274194,
      "loss": 1.0658,
      "step": 66100
    },
    {
      "epoch": 106.65,
      "learning_rate": 0.08933952678951614,
      "loss": 1.0434,
      "step": 66120
    },
    {
      "epoch": 106.68,
      "learning_rate": 0.08933630098629033,
      "loss": 1.0639,
      "step": 66140
    },
    {
      "epoch": 106.71,
      "learning_rate": 0.08933307518306452,
      "loss": 1.0867,
      "step": 66160
    },
    {
      "epoch": 106.74,
      "learning_rate": 0.08932984937983872,
      "loss": 1.0843,
      "step": 66180
    },
    {
      "epoch": 106.77,
      "learning_rate": 0.08932662357661292,
      "loss": 1.0959,
      "step": 66200
    },
    {
      "epoch": 106.81,
      "learning_rate": 0.0893233977733871,
      "loss": 1.0725,
      "step": 66220
    },
    {
      "epoch": 106.84,
      "learning_rate": 0.0893201719701613,
      "loss": 1.0488,
      "step": 66240
    },
    {
      "epoch": 106.87,
      "learning_rate": 0.08931694616693549,
      "loss": 1.0735,
      "step": 66260
    },
    {
      "epoch": 106.9,
      "learning_rate": 0.08931372036370967,
      "loss": 1.0681,
      "step": 66280
    },
    {
      "epoch": 106.94,
      "learning_rate": 0.08931049456048387,
      "loss": 1.0649,
      "step": 66300
    },
    {
      "epoch": 106.97,
      "learning_rate": 0.08930726875725807,
      "loss": 1.0549,
      "step": 66320
    },
    {
      "epoch": 107.0,
      "learning_rate": 0.08930404295403226,
      "loss": 1.0666,
      "step": 66340
    },
    {
      "epoch": 107.0,
      "eval_accuracy": {
        "accuracy": 0.7321832799937553
      },
      "eval_loss": 1.3917350769042969,
      "eval_runtime": 2.8023,
      "eval_samples_per_second": 4571.682,
      "eval_steps_per_second": 71.728,
      "step": 66340
    },
    {
      "epoch": 107.03,
      "learning_rate": 0.08930081715080646,
      "loss": 1.1254,
      "step": 66360
    },
    {
      "epoch": 107.06,
      "learning_rate": 0.08929759134758065,
      "loss": 1.0642,
      "step": 66380
    },
    {
      "epoch": 107.1,
      "learning_rate": 0.08929436554435484,
      "loss": 1.0342,
      "step": 66400
    },
    {
      "epoch": 107.13,
      "learning_rate": 0.08929113974112904,
      "loss": 1.0544,
      "step": 66420
    },
    {
      "epoch": 107.16,
      "learning_rate": 0.08928791393790324,
      "loss": 1.0214,
      "step": 66440
    },
    {
      "epoch": 107.19,
      "learning_rate": 0.08928468813467742,
      "loss": 1.0381,
      "step": 66460
    },
    {
      "epoch": 107.23,
      "learning_rate": 0.08928146233145162,
      "loss": 1.0537,
      "step": 66480
    },
    {
      "epoch": 107.26,
      "learning_rate": 0.08927823652822582,
      "loss": 1.0807,
      "step": 66500
    },
    {
      "epoch": 107.29,
      "learning_rate": 0.089275010725,
      "loss": 1.1075,
      "step": 66520
    },
    {
      "epoch": 107.32,
      "learning_rate": 0.0892717849217742,
      "loss": 1.0778,
      "step": 66540
    },
    {
      "epoch": 107.35,
      "learning_rate": 0.08926855911854839,
      "loss": 1.0396,
      "step": 66560
    },
    {
      "epoch": 107.39,
      "learning_rate": 0.08926533331532258,
      "loss": 1.0624,
      "step": 66580
    },
    {
      "epoch": 107.42,
      "learning_rate": 0.08926210751209677,
      "loss": 1.0204,
      "step": 66600
    },
    {
      "epoch": 107.45,
      "learning_rate": 0.08925888170887097,
      "loss": 1.0728,
      "step": 66620
    },
    {
      "epoch": 107.48,
      "learning_rate": 0.08925565590564516,
      "loss": 1.0451,
      "step": 66640
    },
    {
      "epoch": 107.52,
      "learning_rate": 0.08925243010241936,
      "loss": 1.0611,
      "step": 66660
    },
    {
      "epoch": 107.55,
      "learning_rate": 0.08924920429919356,
      "loss": 1.077,
      "step": 66680
    },
    {
      "epoch": 107.58,
      "learning_rate": 0.08924597849596774,
      "loss": 1.0969,
      "step": 66700
    },
    {
      "epoch": 107.61,
      "learning_rate": 0.08924275269274194,
      "loss": 1.0935,
      "step": 66720
    },
    {
      "epoch": 107.65,
      "learning_rate": 0.08923952688951614,
      "loss": 1.0783,
      "step": 66740
    },
    {
      "epoch": 107.68,
      "learning_rate": 0.08923630108629033,
      "loss": 1.059,
      "step": 66760
    },
    {
      "epoch": 107.71,
      "learning_rate": 0.08923307528306453,
      "loss": 1.0713,
      "step": 66780
    },
    {
      "epoch": 107.74,
      "learning_rate": 0.08922984947983872,
      "loss": 1.0457,
      "step": 66800
    },
    {
      "epoch": 107.77,
      "learning_rate": 0.08922662367661291,
      "loss": 1.0697,
      "step": 66820
    },
    {
      "epoch": 107.81,
      "learning_rate": 0.08922339787338711,
      "loss": 1.0744,
      "step": 66840
    },
    {
      "epoch": 107.84,
      "learning_rate": 0.0892201720701613,
      "loss": 1.0601,
      "step": 66860
    },
    {
      "epoch": 107.87,
      "learning_rate": 0.08921694626693549,
      "loss": 1.055,
      "step": 66880
    },
    {
      "epoch": 107.9,
      "learning_rate": 0.08921372046370968,
      "loss": 1.0606,
      "step": 66900
    },
    {
      "epoch": 107.94,
      "learning_rate": 0.08921049466048388,
      "loss": 1.0672,
      "step": 66920
    },
    {
      "epoch": 107.97,
      "learning_rate": 0.08920726885725806,
      "loss": 1.0574,
      "step": 66940
    },
    {
      "epoch": 108.0,
      "learning_rate": 0.08920404305403226,
      "loss": 1.0646,
      "step": 66960
    },
    {
      "epoch": 108.0,
      "eval_accuracy": {
        "accuracy": 0.7266411677464679
      },
      "eval_loss": 1.4583463668823242,
      "eval_runtime": 2.5396,
      "eval_samples_per_second": 5044.533,
      "eval_steps_per_second": 79.147,
      "step": 66960
    },
    {
      "epoch": 108.03,
      "learning_rate": 0.08920081725080646,
      "loss": 1.1014,
      "step": 66980
    },
    {
      "epoch": 108.06,
      "learning_rate": 0.08919759144758065,
      "loss": 1.0277,
      "step": 67000
    },
    {
      "epoch": 108.1,
      "learning_rate": 0.08919436564435484,
      "loss": 1.0162,
      "step": 67020
    },
    {
      "epoch": 108.13,
      "learning_rate": 0.08919113984112904,
      "loss": 1.0177,
      "step": 67040
    },
    {
      "epoch": 108.16,
      "learning_rate": 0.08918791403790323,
      "loss": 0.9963,
      "step": 67060
    },
    {
      "epoch": 108.19,
      "learning_rate": 0.08918468823467743,
      "loss": 1.0216,
      "step": 67080
    },
    {
      "epoch": 108.23,
      "learning_rate": 0.08918146243145163,
      "loss": 1.0641,
      "step": 67100
    },
    {
      "epoch": 108.26,
      "learning_rate": 0.08917823662822581,
      "loss": 1.0699,
      "step": 67120
    },
    {
      "epoch": 108.29,
      "learning_rate": 0.08917501082500001,
      "loss": 1.0636,
      "step": 67140
    },
    {
      "epoch": 108.32,
      "learning_rate": 0.0891717850217742,
      "loss": 1.0576,
      "step": 67160
    },
    {
      "epoch": 108.35,
      "learning_rate": 0.0891685592185484,
      "loss": 1.0582,
      "step": 67180
    },
    {
      "epoch": 108.39,
      "learning_rate": 0.08916533341532258,
      "loss": 1.0359,
      "step": 67200
    },
    {
      "epoch": 108.42,
      "learning_rate": 0.08916210761209678,
      "loss": 1.0661,
      "step": 67220
    },
    {
      "epoch": 108.45,
      "learning_rate": 0.08915888180887097,
      "loss": 1.0589,
      "step": 67240
    },
    {
      "epoch": 108.48,
      "learning_rate": 0.08915565600564516,
      "loss": 1.048,
      "step": 67260
    },
    {
      "epoch": 108.52,
      "learning_rate": 0.08915243020241936,
      "loss": 1.0637,
      "step": 67280
    },
    {
      "epoch": 108.55,
      "learning_rate": 0.08914920439919355,
      "loss": 1.0553,
      "step": 67300
    },
    {
      "epoch": 108.58,
      "learning_rate": 0.08914597859596775,
      "loss": 1.0453,
      "step": 67320
    },
    {
      "epoch": 108.61,
      "learning_rate": 0.08914275279274195,
      "loss": 1.0432,
      "step": 67340
    },
    {
      "epoch": 108.65,
      "learning_rate": 0.08913952698951613,
      "loss": 1.0572,
      "step": 67360
    },
    {
      "epoch": 108.68,
      "learning_rate": 0.08913630118629033,
      "loss": 1.0622,
      "step": 67380
    },
    {
      "epoch": 108.71,
      "learning_rate": 0.08913307538306453,
      "loss": 1.0627,
      "step": 67400
    },
    {
      "epoch": 108.74,
      "learning_rate": 0.08912984957983872,
      "loss": 1.0453,
      "step": 67420
    },
    {
      "epoch": 108.77,
      "learning_rate": 0.08912662377661291,
      "loss": 1.0565,
      "step": 67440
    },
    {
      "epoch": 108.81,
      "learning_rate": 0.0891233979733871,
      "loss": 1.0384,
      "step": 67460
    },
    {
      "epoch": 108.84,
      "learning_rate": 0.0891201721701613,
      "loss": 1.0555,
      "step": 67480
    },
    {
      "epoch": 108.87,
      "learning_rate": 0.08911694636693548,
      "loss": 1.0614,
      "step": 67500
    },
    {
      "epoch": 108.9,
      "learning_rate": 0.08911372056370968,
      "loss": 1.0912,
      "step": 67520
    },
    {
      "epoch": 108.94,
      "learning_rate": 0.08911049476048387,
      "loss": 1.0598,
      "step": 67540
    },
    {
      "epoch": 108.97,
      "learning_rate": 0.08910726895725807,
      "loss": 1.0628,
      "step": 67560
    },
    {
      "epoch": 109.0,
      "learning_rate": 0.08910404315403227,
      "loss": 1.0755,
      "step": 67580
    },
    {
      "epoch": 109.0,
      "eval_accuracy": {
        "accuracy": 0.7302318320193584
      },
      "eval_loss": 1.4263874292373657,
      "eval_runtime": 3.6209,
      "eval_samples_per_second": 3538.032,
      "eval_steps_per_second": 55.51,
      "step": 67580
    },
    {
      "epoch": 109.03,
      "learning_rate": 0.08910081735080645,
      "loss": 1.0838,
      "step": 67600
    },
    {
      "epoch": 109.06,
      "learning_rate": 0.08909759154758065,
      "loss": 1.0465,
      "step": 67620
    },
    {
      "epoch": 109.1,
      "learning_rate": 0.08909436574435485,
      "loss": 1.0145,
      "step": 67640
    },
    {
      "epoch": 109.13,
      "learning_rate": 0.08909113994112904,
      "loss": 1.0319,
      "step": 67660
    },
    {
      "epoch": 109.16,
      "learning_rate": 0.08908791413790323,
      "loss": 1.0621,
      "step": 67680
    },
    {
      "epoch": 109.19,
      "learning_rate": 0.08908468833467742,
      "loss": 1.0821,
      "step": 67700
    },
    {
      "epoch": 109.23,
      "learning_rate": 0.08908146253145162,
      "loss": 1.0434,
      "step": 67720
    },
    {
      "epoch": 109.26,
      "learning_rate": 0.08907823672822582,
      "loss": 1.0099,
      "step": 67740
    },
    {
      "epoch": 109.29,
      "learning_rate": 0.089075010925,
      "loss": 1.0443,
      "step": 67760
    },
    {
      "epoch": 109.32,
      "learning_rate": 0.0890717851217742,
      "loss": 1.0991,
      "step": 67780
    },
    {
      "epoch": 109.35,
      "learning_rate": 0.08906855931854839,
      "loss": 1.0461,
      "step": 67800
    },
    {
      "epoch": 109.39,
      "learning_rate": 0.08906533351532259,
      "loss": 1.0447,
      "step": 67820
    },
    {
      "epoch": 109.42,
      "learning_rate": 0.08906210771209677,
      "loss": 1.016,
      "step": 67840
    },
    {
      "epoch": 109.45,
      "learning_rate": 0.08905888190887097,
      "loss": 1.0661,
      "step": 67860
    },
    {
      "epoch": 109.48,
      "learning_rate": 0.08905565610564517,
      "loss": 1.0442,
      "step": 67880
    },
    {
      "epoch": 109.52,
      "learning_rate": 0.08905243030241936,
      "loss": 1.0801,
      "step": 67900
    },
    {
      "epoch": 109.55,
      "learning_rate": 0.08904920449919355,
      "loss": 1.0652,
      "step": 67920
    },
    {
      "epoch": 109.58,
      "learning_rate": 0.08904597869596775,
      "loss": 1.0412,
      "step": 67940
    },
    {
      "epoch": 109.61,
      "learning_rate": 0.08904275289274194,
      "loss": 1.0646,
      "step": 67960
    },
    {
      "epoch": 109.65,
      "learning_rate": 0.08903952708951614,
      "loss": 1.06,
      "step": 67980
    },
    {
      "epoch": 109.68,
      "learning_rate": 0.08903630128629032,
      "loss": 1.0725,
      "step": 68000
    },
    {
      "epoch": 109.71,
      "learning_rate": 0.08903307548306452,
      "loss": 1.0668,
      "step": 68020
    },
    {
      "epoch": 109.74,
      "learning_rate": 0.08902984967983872,
      "loss": 1.0722,
      "step": 68040
    },
    {
      "epoch": 109.77,
      "learning_rate": 0.0890266238766129,
      "loss": 1.0834,
      "step": 68060
    },
    {
      "epoch": 109.81,
      "learning_rate": 0.0890233980733871,
      "loss": 1.0647,
      "step": 68080
    },
    {
      "epoch": 109.84,
      "learning_rate": 0.08902017227016129,
      "loss": 1.0793,
      "step": 68100
    },
    {
      "epoch": 109.87,
      "learning_rate": 0.08901694646693549,
      "loss": 1.0461,
      "step": 68120
    },
    {
      "epoch": 109.9,
      "learning_rate": 0.08901372066370968,
      "loss": 1.0298,
      "step": 68140
    },
    {
      "epoch": 109.94,
      "learning_rate": 0.08901049486048387,
      "loss": 1.0354,
      "step": 68160
    },
    {
      "epoch": 109.97,
      "learning_rate": 0.08900726905725807,
      "loss": 1.0409,
      "step": 68180
    },
    {
      "epoch": 110.0,
      "learning_rate": 0.08900404325403226,
      "loss": 1.0638,
      "step": 68200
    },
    {
      "epoch": 110.0,
      "eval_accuracy": {
        "accuracy": 0.7302318320193584
      },
      "eval_loss": 1.409935474395752,
      "eval_runtime": 2.6612,
      "eval_samples_per_second": 4813.944,
      "eval_steps_per_second": 75.529,
      "step": 68200
    },
    {
      "epoch": 110.03,
      "learning_rate": 0.08900081745080646,
      "loss": 1.1163,
      "step": 68220
    },
    {
      "epoch": 110.06,
      "learning_rate": 0.08899759164758064,
      "loss": 1.0576,
      "step": 68240
    },
    {
      "epoch": 110.1,
      "learning_rate": 0.08899436584435484,
      "loss": 1.0194,
      "step": 68260
    },
    {
      "epoch": 110.13,
      "learning_rate": 0.08899114004112904,
      "loss": 1.0269,
      "step": 68280
    },
    {
      "epoch": 110.16,
      "learning_rate": 0.08898791423790323,
      "loss": 1.0322,
      "step": 68300
    },
    {
      "epoch": 110.19,
      "learning_rate": 0.08898468843467743,
      "loss": 1.0367,
      "step": 68320
    },
    {
      "epoch": 110.23,
      "learning_rate": 0.08898146263145162,
      "loss": 1.0381,
      "step": 68340
    },
    {
      "epoch": 110.26,
      "learning_rate": 0.08897823682822581,
      "loss": 1.0686,
      "step": 68360
    },
    {
      "epoch": 110.29,
      "learning_rate": 0.08897501102500001,
      "loss": 1.0677,
      "step": 68380
    },
    {
      "epoch": 110.32,
      "learning_rate": 0.08897178522177421,
      "loss": 1.0466,
      "step": 68400
    },
    {
      "epoch": 110.35,
      "learning_rate": 0.08896855941854839,
      "loss": 1.0589,
      "step": 68420
    },
    {
      "epoch": 110.39,
      "learning_rate": 0.08896533361532258,
      "loss": 1.0834,
      "step": 68440
    },
    {
      "epoch": 110.42,
      "learning_rate": 0.08896210781209678,
      "loss": 1.0414,
      "step": 68460
    },
    {
      "epoch": 110.45,
      "learning_rate": 0.08895888200887098,
      "loss": 1.0758,
      "step": 68480
    },
    {
      "epoch": 110.48,
      "learning_rate": 0.08895565620564516,
      "loss": 1.0473,
      "step": 68500
    },
    {
      "epoch": 110.52,
      "learning_rate": 0.08895243040241936,
      "loss": 1.0241,
      "step": 68520
    },
    {
      "epoch": 110.55,
      "learning_rate": 0.08894920459919355,
      "loss": 1.0584,
      "step": 68540
    },
    {
      "epoch": 110.58,
      "learning_rate": 0.08894597879596775,
      "loss": 1.0863,
      "step": 68560
    },
    {
      "epoch": 110.61,
      "learning_rate": 0.08894275299274194,
      "loss": 1.0634,
      "step": 68580
    },
    {
      "epoch": 110.65,
      "learning_rate": 0.08893968847967743,
      "loss": 1.0708,
      "step": 68600
    },
    {
      "epoch": 110.68,
      "learning_rate": 0.08893646267645161,
      "loss": 1.0744,
      "step": 68620
    },
    {
      "epoch": 110.71,
      "learning_rate": 0.08893323687322581,
      "loss": 1.0544,
      "step": 68640
    },
    {
      "epoch": 110.74,
      "learning_rate": 0.08893001107000001,
      "loss": 1.0933,
      "step": 68660
    },
    {
      "epoch": 110.77,
      "learning_rate": 0.0889267852667742,
      "loss": 1.0615,
      "step": 68680
    },
    {
      "epoch": 110.81,
      "learning_rate": 0.0889235594635484,
      "loss": 1.059,
      "step": 68700
    },
    {
      "epoch": 110.84,
      "learning_rate": 0.08892033366032259,
      "loss": 1.0917,
      "step": 68720
    },
    {
      "epoch": 110.87,
      "learning_rate": 0.08891710785709678,
      "loss": 1.0625,
      "step": 68740
    },
    {
      "epoch": 110.9,
      "learning_rate": 0.08891388205387098,
      "loss": 1.0694,
      "step": 68760
    },
    {
      "epoch": 110.94,
      "learning_rate": 0.08891065625064516,
      "loss": 1.0722,
      "step": 68780
    },
    {
      "epoch": 110.97,
      "learning_rate": 0.08890743044741936,
      "loss": 1.087,
      "step": 68800
    },
    {
      "epoch": 111.0,
      "learning_rate": 0.08890420464419356,
      "loss": 1.0613,
      "step": 68820
    },
    {
      "epoch": 111.0,
      "eval_accuracy": {
        "accuracy": 0.7264069939895402
      },
      "eval_loss": 1.4417133331298828,
      "eval_runtime": 2.7312,
      "eval_samples_per_second": 4690.66,
      "eval_steps_per_second": 73.595,
      "step": 68820
    },
    {
      "epoch": 111.03,
      "learning_rate": 0.08890097884096775,
      "loss": 1.1413,
      "step": 68840
    },
    {
      "epoch": 111.06,
      "learning_rate": 0.08889775303774194,
      "loss": 1.0613,
      "step": 68860
    },
    {
      "epoch": 111.1,
      "learning_rate": 0.08889452723451613,
      "loss": 1.0233,
      "step": 68880
    },
    {
      "epoch": 111.13,
      "learning_rate": 0.08889130143129033,
      "loss": 1.0121,
      "step": 68900
    },
    {
      "epoch": 111.16,
      "learning_rate": 0.08888807562806451,
      "loss": 1.0491,
      "step": 68920
    },
    {
      "epoch": 111.19,
      "learning_rate": 0.08888484982483871,
      "loss": 1.0345,
      "step": 68940
    },
    {
      "epoch": 111.23,
      "learning_rate": 0.08888162402161291,
      "loss": 1.0287,
      "step": 68960
    },
    {
      "epoch": 111.26,
      "learning_rate": 0.0888783982183871,
      "loss": 1.0125,
      "step": 68980
    },
    {
      "epoch": 111.29,
      "learning_rate": 0.0888751724151613,
      "loss": 1.038,
      "step": 69000
    },
    {
      "epoch": 111.32,
      "learning_rate": 0.0888719466119355,
      "loss": 1.0776,
      "step": 69020
    },
    {
      "epoch": 111.35,
      "learning_rate": 0.08886872080870968,
      "loss": 1.044,
      "step": 69040
    },
    {
      "epoch": 111.39,
      "learning_rate": 0.08886549500548388,
      "loss": 1.0536,
      "step": 69060
    },
    {
      "epoch": 111.42,
      "learning_rate": 0.08886226920225807,
      "loss": 1.0389,
      "step": 69080
    },
    {
      "epoch": 111.45,
      "learning_rate": 0.08885904339903226,
      "loss": 1.0421,
      "step": 69100
    },
    {
      "epoch": 111.48,
      "learning_rate": 0.08885581759580646,
      "loss": 1.0623,
      "step": 69120
    },
    {
      "epoch": 111.52,
      "learning_rate": 0.08885259179258065,
      "loss": 1.0237,
      "step": 69140
    },
    {
      "epoch": 111.55,
      "learning_rate": 0.08884936598935485,
      "loss": 1.0301,
      "step": 69160
    },
    {
      "epoch": 111.58,
      "learning_rate": 0.08884614018612903,
      "loss": 1.0271,
      "step": 69180
    },
    {
      "epoch": 111.61,
      "learning_rate": 0.08884291438290323,
      "loss": 1.0353,
      "step": 69200
    },
    {
      "epoch": 111.65,
      "learning_rate": 0.08883968857967742,
      "loss": 1.0608,
      "step": 69220
    },
    {
      "epoch": 111.68,
      "learning_rate": 0.08883646277645162,
      "loss": 1.0778,
      "step": 69240
    },
    {
      "epoch": 111.71,
      "learning_rate": 0.08883323697322582,
      "loss": 1.1006,
      "step": 69260
    },
    {
      "epoch": 111.74,
      "learning_rate": 0.08883001117,
      "loss": 1.0376,
      "step": 69280
    },
    {
      "epoch": 111.77,
      "learning_rate": 0.0888267853667742,
      "loss": 1.044,
      "step": 69300
    },
    {
      "epoch": 111.81,
      "learning_rate": 0.08882355956354838,
      "loss": 1.053,
      "step": 69320
    },
    {
      "epoch": 111.84,
      "learning_rate": 0.08882033376032258,
      "loss": 1.045,
      "step": 69340
    },
    {
      "epoch": 111.87,
      "learning_rate": 0.08881710795709678,
      "loss": 1.068,
      "step": 69360
    },
    {
      "epoch": 111.9,
      "learning_rate": 0.08881388215387097,
      "loss": 1.0691,
      "step": 69380
    },
    {
      "epoch": 111.94,
      "learning_rate": 0.08881065635064517,
      "loss": 1.0618,
      "step": 69400
    },
    {
      "epoch": 111.97,
      "learning_rate": 0.08880743054741937,
      "loss": 1.1029,
      "step": 69420
    },
    {
      "epoch": 112.0,
      "learning_rate": 0.08880420474419355,
      "loss": 1.063,
      "step": 69440
    },
    {
      "epoch": 112.0,
      "eval_accuracy": {
        "accuracy": 0.729139021153696
      },
      "eval_loss": 1.4083290100097656,
      "eval_runtime": 2.5929,
      "eval_samples_per_second": 4940.728,
      "eval_steps_per_second": 77.518,
      "step": 69440
    },
    {
      "epoch": 112.03,
      "learning_rate": 0.08880097894096775,
      "loss": 1.0829,
      "step": 69460
    },
    {
      "epoch": 112.06,
      "learning_rate": 0.08879775313774194,
      "loss": 1.0521,
      "step": 69480
    },
    {
      "epoch": 112.1,
      "learning_rate": 0.08879452733451614,
      "loss": 1.0428,
      "step": 69500
    },
    {
      "epoch": 112.13,
      "learning_rate": 0.08879130153129032,
      "loss": 1.0227,
      "step": 69520
    },
    {
      "epoch": 112.16,
      "learning_rate": 0.08878807572806452,
      "loss": 1.0349,
      "step": 69540
    },
    {
      "epoch": 112.19,
      "learning_rate": 0.08878484992483872,
      "loss": 1.0812,
      "step": 69560
    },
    {
      "epoch": 112.23,
      "learning_rate": 0.0887816241216129,
      "loss": 1.0308,
      "step": 69580
    },
    {
      "epoch": 112.26,
      "learning_rate": 0.0887783983183871,
      "loss": 1.0243,
      "step": 69600
    },
    {
      "epoch": 112.29,
      "learning_rate": 0.08877517251516129,
      "loss": 1.0525,
      "step": 69620
    },
    {
      "epoch": 112.32,
      "learning_rate": 0.08877194671193549,
      "loss": 1.0573,
      "step": 69640
    },
    {
      "epoch": 112.35,
      "learning_rate": 0.08876872090870969,
      "loss": 1.0517,
      "step": 69660
    },
    {
      "epoch": 112.39,
      "learning_rate": 0.08876549510548387,
      "loss": 1.056,
      "step": 69680
    },
    {
      "epoch": 112.42,
      "learning_rate": 0.08876226930225807,
      "loss": 1.0605,
      "step": 69700
    },
    {
      "epoch": 112.45,
      "learning_rate": 0.08875904349903227,
      "loss": 1.0467,
      "step": 69720
    },
    {
      "epoch": 112.48,
      "learning_rate": 0.08875581769580645,
      "loss": 1.0666,
      "step": 69740
    },
    {
      "epoch": 112.52,
      "learning_rate": 0.08875259189258065,
      "loss": 1.0932,
      "step": 69760
    },
    {
      "epoch": 112.55,
      "learning_rate": 0.08874936608935485,
      "loss": 1.0518,
      "step": 69780
    },
    {
      "epoch": 112.58,
      "learning_rate": 0.08874614028612904,
      "loss": 1.0641,
      "step": 69800
    },
    {
      "epoch": 112.61,
      "learning_rate": 0.08874291448290322,
      "loss": 1.0339,
      "step": 69820
    },
    {
      "epoch": 112.65,
      "learning_rate": 0.08873968867967742,
      "loss": 1.074,
      "step": 69840
    },
    {
      "epoch": 112.68,
      "learning_rate": 0.08873646287645161,
      "loss": 1.0339,
      "step": 69860
    },
    {
      "epoch": 112.71,
      "learning_rate": 0.0887332370732258,
      "loss": 1.0412,
      "step": 69880
    },
    {
      "epoch": 112.74,
      "learning_rate": 0.08873001127,
      "loss": 1.0944,
      "step": 69900
    },
    {
      "epoch": 112.77,
      "learning_rate": 0.08872678546677419,
      "loss": 1.0817,
      "step": 69920
    },
    {
      "epoch": 112.81,
      "learning_rate": 0.08872355966354839,
      "loss": 1.0294,
      "step": 69940
    },
    {
      "epoch": 112.84,
      "learning_rate": 0.08872033386032259,
      "loss": 1.0246,
      "step": 69960
    },
    {
      "epoch": 112.87,
      "learning_rate": 0.08871710805709677,
      "loss": 1.0369,
      "step": 69980
    },
    {
      "epoch": 112.9,
      "learning_rate": 0.08871388225387097,
      "loss": 1.0255,
      "step": 70000
    },
    {
      "epoch": 112.94,
      "learning_rate": 0.08871065645064517,
      "loss": 1.0231,
      "step": 70020
    },
    {
      "epoch": 112.97,
      "learning_rate": 0.08870743064741936,
      "loss": 1.0771,
      "step": 70040
    },
    {
      "epoch": 113.0,
      "learning_rate": 0.08870420484419356,
      "loss": 1.0854,
      "step": 70060
    },
    {
      "epoch": 113.0,
      "eval_accuracy": {
        "accuracy": 0.7266411677464679
      },
      "eval_loss": 1.4402378797531128,
      "eval_runtime": 3.2981,
      "eval_samples_per_second": 3884.355,
      "eval_steps_per_second": 60.944,
      "step": 70060
    },
    {
      "epoch": 113.03,
      "learning_rate": 0.08870097904096776,
      "loss": 1.1222,
      "step": 70080
    },
    {
      "epoch": 113.06,
      "learning_rate": 0.08869775323774194,
      "loss": 1.0647,
      "step": 70100
    },
    {
      "epoch": 113.1,
      "learning_rate": 0.08869452743451613,
      "loss": 1.0277,
      "step": 70120
    },
    {
      "epoch": 113.13,
      "learning_rate": 0.08869130163129033,
      "loss": 1.007,
      "step": 70140
    },
    {
      "epoch": 113.16,
      "learning_rate": 0.08868807582806451,
      "loss": 1.0423,
      "step": 70160
    },
    {
      "epoch": 113.19,
      "learning_rate": 0.08868485002483871,
      "loss": 1.0629,
      "step": 70180
    },
    {
      "epoch": 113.23,
      "learning_rate": 0.08868162422161291,
      "loss": 1.0609,
      "step": 70200
    },
    {
      "epoch": 113.26,
      "learning_rate": 0.0886783984183871,
      "loss": 1.0527,
      "step": 70220
    },
    {
      "epoch": 113.29,
      "learning_rate": 0.0886751726151613,
      "loss": 1.0687,
      "step": 70240
    },
    {
      "epoch": 113.32,
      "learning_rate": 0.08867194681193549,
      "loss": 1.0473,
      "step": 70260
    },
    {
      "epoch": 113.35,
      "learning_rate": 0.08866872100870968,
      "loss": 1.0502,
      "step": 70280
    },
    {
      "epoch": 113.39,
      "learning_rate": 0.08866549520548388,
      "loss": 1.0632,
      "step": 70300
    },
    {
      "epoch": 113.42,
      "learning_rate": 0.08866226940225808,
      "loss": 1.0356,
      "step": 70320
    },
    {
      "epoch": 113.45,
      "learning_rate": 0.08865904359903226,
      "loss": 1.0573,
      "step": 70340
    },
    {
      "epoch": 113.48,
      "learning_rate": 0.08865581779580646,
      "loss": 1.0353,
      "step": 70360
    },
    {
      "epoch": 113.52,
      "learning_rate": 0.08865259199258066,
      "loss": 1.0271,
      "step": 70380
    },
    {
      "epoch": 113.55,
      "learning_rate": 0.08864936618935484,
      "loss": 1.0501,
      "step": 70400
    },
    {
      "epoch": 113.58,
      "learning_rate": 0.08864614038612903,
      "loss": 1.0872,
      "step": 70420
    },
    {
      "epoch": 113.61,
      "learning_rate": 0.08864291458290324,
      "loss": 1.0841,
      "step": 70440
    },
    {
      "epoch": 113.65,
      "learning_rate": 0.08863968877967741,
      "loss": 1.0662,
      "step": 70460
    },
    {
      "epoch": 113.68,
      "learning_rate": 0.08863646297645161,
      "loss": 1.0269,
      "step": 70480
    },
    {
      "epoch": 113.71,
      "learning_rate": 0.08863323717322581,
      "loss": 1.0255,
      "step": 70500
    },
    {
      "epoch": 113.74,
      "learning_rate": 0.08863001137,
      "loss": 1.04,
      "step": 70520
    },
    {
      "epoch": 113.77,
      "learning_rate": 0.0886267855667742,
      "loss": 1.0272,
      "step": 70540
    },
    {
      "epoch": 113.81,
      "learning_rate": 0.0886235597635484,
      "loss": 1.0344,
      "step": 70560
    },
    {
      "epoch": 113.84,
      "learning_rate": 0.08862033396032258,
      "loss": 1.0512,
      "step": 70580
    },
    {
      "epoch": 113.87,
      "learning_rate": 0.08861710815709678,
      "loss": 1.0386,
      "step": 70600
    },
    {
      "epoch": 113.9,
      "learning_rate": 0.08861388235387098,
      "loss": 1.0398,
      "step": 70620
    },
    {
      "epoch": 113.94,
      "learning_rate": 0.08861065655064516,
      "loss": 1.0371,
      "step": 70640
    },
    {
      "epoch": 113.97,
      "learning_rate": 0.08860743074741936,
      "loss": 1.0776,
      "step": 70660
    },
    {
      "epoch": 114.0,
      "learning_rate": 0.08860436623435484,
      "loss": 1.0818,
      "step": 70680
    },
    {
      "epoch": 114.0,
      "eval_accuracy": {
        "accuracy": 0.7423308094606198
      },
      "eval_loss": 1.392169713973999,
      "eval_runtime": 2.7435,
      "eval_samples_per_second": 4669.546,
      "eval_steps_per_second": 73.263,
      "step": 70680
    },
    {
      "epoch": 114.03,
      "learning_rate": 0.08860114043112903,
      "loss": 1.0498,
      "step": 70700
    },
    {
      "epoch": 114.06,
      "learning_rate": 0.08859791462790323,
      "loss": 1.016,
      "step": 70720
    },
    {
      "epoch": 114.1,
      "learning_rate": 0.08859468882467743,
      "loss": 1.0311,
      "step": 70740
    },
    {
      "epoch": 114.13,
      "learning_rate": 0.08859146302145161,
      "loss": 1.0295,
      "step": 70760
    },
    {
      "epoch": 114.16,
      "learning_rate": 0.08858823721822581,
      "loss": 1.0296,
      "step": 70780
    },
    {
      "epoch": 114.19,
      "learning_rate": 0.08858501141500001,
      "loss": 1.0341,
      "step": 70800
    },
    {
      "epoch": 114.23,
      "learning_rate": 0.0885817856117742,
      "loss": 1.0469,
      "step": 70820
    },
    {
      "epoch": 114.26,
      "learning_rate": 0.0885785598085484,
      "loss": 1.0638,
      "step": 70840
    },
    {
      "epoch": 114.29,
      "learning_rate": 0.0885753340053226,
      "loss": 1.0424,
      "step": 70860
    },
    {
      "epoch": 114.32,
      "learning_rate": 0.08857210820209678,
      "loss": 1.0197,
      "step": 70880
    },
    {
      "epoch": 114.35,
      "learning_rate": 0.08856888239887097,
      "loss": 1.0176,
      "step": 70900
    },
    {
      "epoch": 114.39,
      "learning_rate": 0.08856565659564516,
      "loss": 1.0219,
      "step": 70920
    },
    {
      "epoch": 114.42,
      "learning_rate": 0.08856243079241935,
      "loss": 1.0164,
      "step": 70940
    },
    {
      "epoch": 114.45,
      "learning_rate": 0.08855920498919355,
      "loss": 1.0259,
      "step": 70960
    },
    {
      "epoch": 114.48,
      "learning_rate": 0.08855597918596775,
      "loss": 1.0446,
      "step": 70980
    },
    {
      "epoch": 114.52,
      "learning_rate": 0.08855275338274193,
      "loss": 1.0327,
      "step": 71000
    },
    {
      "epoch": 114.55,
      "learning_rate": 0.08854952757951613,
      "loss": 1.0456,
      "step": 71020
    },
    {
      "epoch": 114.58,
      "learning_rate": 0.08854630177629033,
      "loss": 1.0587,
      "step": 71040
    },
    {
      "epoch": 114.61,
      "learning_rate": 0.08854307597306452,
      "loss": 1.0861,
      "step": 71060
    },
    {
      "epoch": 114.65,
      "learning_rate": 0.08853985016983872,
      "loss": 1.0883,
      "step": 71080
    },
    {
      "epoch": 114.68,
      "learning_rate": 0.08853662436661291,
      "loss": 1.0536,
      "step": 71100
    },
    {
      "epoch": 114.71,
      "learning_rate": 0.0885333985633871,
      "loss": 1.0713,
      "step": 71120
    },
    {
      "epoch": 114.74,
      "learning_rate": 0.0885301727601613,
      "loss": 1.036,
      "step": 71140
    },
    {
      "epoch": 114.77,
      "learning_rate": 0.0885269469569355,
      "loss": 1.0756,
      "step": 71160
    },
    {
      "epoch": 114.81,
      "learning_rate": 0.08852372115370968,
      "loss": 1.0465,
      "step": 71180
    },
    {
      "epoch": 114.84,
      "learning_rate": 0.08852049535048387,
      "loss": 1.0581,
      "step": 71200
    },
    {
      "epoch": 114.87,
      "learning_rate": 0.08851726954725807,
      "loss": 1.0331,
      "step": 71220
    },
    {
      "epoch": 114.9,
      "learning_rate": 0.08851404374403225,
      "loss": 1.0371,
      "step": 71240
    },
    {
      "epoch": 114.94,
      "learning_rate": 0.08851081794080645,
      "loss": 1.0393,
      "step": 71260
    },
    {
      "epoch": 114.97,
      "learning_rate": 0.08850759213758065,
      "loss": 1.0364,
      "step": 71280
    },
    {
      "epoch": 115.0,
      "learning_rate": 0.08850436633435484,
      "loss": 1.0485,
      "step": 71300
    },
    {
      "epoch": 115.0,
      "eval_accuracy": {
        "accuracy": 0.7327296854265866
      },
      "eval_loss": 1.4167219400405884,
      "eval_runtime": 2.6838,
      "eval_samples_per_second": 4773.433,
      "eval_steps_per_second": 74.893,
      "step": 71300
    },
    {
      "epoch": 115.03,
      "learning_rate": 0.08850114053112904,
      "loss": 1.1085,
      "step": 71320
    },
    {
      "epoch": 115.06,
      "learning_rate": 0.08849791472790323,
      "loss": 1.0411,
      "step": 71340
    },
    {
      "epoch": 115.1,
      "learning_rate": 0.08849468892467742,
      "loss": 1.0272,
      "step": 71360
    },
    {
      "epoch": 115.13,
      "learning_rate": 0.08849146312145162,
      "loss": 1.009,
      "step": 71380
    },
    {
      "epoch": 115.16,
      "learning_rate": 0.08848823731822582,
      "loss": 1.0539,
      "step": 71400
    },
    {
      "epoch": 115.19,
      "learning_rate": 0.088485011515,
      "loss": 1.0329,
      "step": 71420
    },
    {
      "epoch": 115.23,
      "learning_rate": 0.0884817857117742,
      "loss": 1.0578,
      "step": 71440
    },
    {
      "epoch": 115.26,
      "learning_rate": 0.0884785599085484,
      "loss": 1.0732,
      "step": 71460
    },
    {
      "epoch": 115.29,
      "learning_rate": 0.08847533410532259,
      "loss": 1.0583,
      "step": 71480
    },
    {
      "epoch": 115.32,
      "learning_rate": 0.08847210830209677,
      "loss": 1.0258,
      "step": 71500
    },
    {
      "epoch": 115.35,
      "learning_rate": 0.08846888249887098,
      "loss": 1.0049,
      "step": 71520
    },
    {
      "epoch": 115.39,
      "learning_rate": 0.08846565669564516,
      "loss": 1.0155,
      "step": 71540
    },
    {
      "epoch": 115.42,
      "learning_rate": 0.08846243089241936,
      "loss": 1.0103,
      "step": 71560
    },
    {
      "epoch": 115.45,
      "learning_rate": 0.08845920508919355,
      "loss": 1.0562,
      "step": 71580
    },
    {
      "epoch": 115.48,
      "learning_rate": 0.08845597928596774,
      "loss": 1.0696,
      "step": 71600
    },
    {
      "epoch": 115.52,
      "learning_rate": 0.08845275348274194,
      "loss": 1.078,
      "step": 71620
    },
    {
      "epoch": 115.55,
      "learning_rate": 0.08844952767951614,
      "loss": 1.0414,
      "step": 71640
    },
    {
      "epoch": 115.58,
      "learning_rate": 0.08844630187629032,
      "loss": 1.0445,
      "step": 71660
    },
    {
      "epoch": 115.61,
      "learning_rate": 0.08844307607306452,
      "loss": 1.0327,
      "step": 71680
    },
    {
      "epoch": 115.65,
      "learning_rate": 0.08843985026983872,
      "loss": 1.0307,
      "step": 71700
    },
    {
      "epoch": 115.68,
      "learning_rate": 0.0884366244666129,
      "loss": 1.0322,
      "step": 71720
    },
    {
      "epoch": 115.71,
      "learning_rate": 0.0884333986633871,
      "loss": 1.0992,
      "step": 71740
    },
    {
      "epoch": 115.74,
      "learning_rate": 0.0884301728601613,
      "loss": 1.0639,
      "step": 71760
    },
    {
      "epoch": 115.77,
      "learning_rate": 0.08842694705693549,
      "loss": 1.0716,
      "step": 71780
    },
    {
      "epoch": 115.81,
      "learning_rate": 0.08842372125370968,
      "loss": 1.0546,
      "step": 71800
    },
    {
      "epoch": 115.84,
      "learning_rate": 0.08842049545048389,
      "loss": 1.0369,
      "step": 71820
    },
    {
      "epoch": 115.87,
      "learning_rate": 0.08841726964725806,
      "loss": 1.0401,
      "step": 71840
    },
    {
      "epoch": 115.9,
      "learning_rate": 0.08841404384403226,
      "loss": 1.0432,
      "step": 71860
    },
    {
      "epoch": 115.94,
      "learning_rate": 0.08841081804080646,
      "loss": 1.0343,
      "step": 71880
    },
    {
      "epoch": 115.97,
      "learning_rate": 0.08840759223758064,
      "loss": 1.0871,
      "step": 71900
    },
    {
      "epoch": 116.0,
      "learning_rate": 0.08840436643435484,
      "loss": 1.0701,
      "step": 71920
    },
    {
      "epoch": 116.0,
      "eval_accuracy": {
        "accuracy": 0.726563109827492
      },
      "eval_loss": 1.4058973789215088,
      "eval_runtime": 3.0232,
      "eval_samples_per_second": 4237.559,
      "eval_steps_per_second": 66.486,
      "step": 71920
    },
    {
      "epoch": 116.03,
      "learning_rate": 0.08840114063112904,
      "loss": 1.0594,
      "step": 71940
    },
    {
      "epoch": 116.06,
      "learning_rate": 0.08839791482790323,
      "loss": 1.0366,
      "step": 71960
    },
    {
      "epoch": 116.1,
      "learning_rate": 0.08839468902467743,
      "loss": 1.0092,
      "step": 71980
    },
    {
      "epoch": 116.13,
      "learning_rate": 0.08839146322145162,
      "loss": 1.0267,
      "step": 72000
    },
    {
      "epoch": 116.16,
      "learning_rate": 0.08838823741822581,
      "loss": 1.0608,
      "step": 72020
    },
    {
      "epoch": 116.19,
      "learning_rate": 0.08838501161500001,
      "loss": 0.9983,
      "step": 72040
    },
    {
      "epoch": 116.23,
      "learning_rate": 0.08838178581177421,
      "loss": 1.0468,
      "step": 72060
    },
    {
      "epoch": 116.26,
      "learning_rate": 0.08837856000854839,
      "loss": 1.048,
      "step": 72080
    },
    {
      "epoch": 116.29,
      "learning_rate": 0.08837533420532259,
      "loss": 1.0634,
      "step": 72100
    },
    {
      "epoch": 116.32,
      "learning_rate": 0.08837210840209679,
      "loss": 1.0224,
      "step": 72120
    },
    {
      "epoch": 116.35,
      "learning_rate": 0.08836888259887096,
      "loss": 1.0579,
      "step": 72140
    },
    {
      "epoch": 116.39,
      "learning_rate": 0.08836565679564516,
      "loss": 1.062,
      "step": 72160
    },
    {
      "epoch": 116.42,
      "learning_rate": 0.08836243099241936,
      "loss": 1.0774,
      "step": 72180
    },
    {
      "epoch": 116.45,
      "learning_rate": 0.08835920518919355,
      "loss": 1.032,
      "step": 72200
    },
    {
      "epoch": 116.48,
      "learning_rate": 0.08835597938596775,
      "loss": 1.0518,
      "step": 72220
    },
    {
      "epoch": 116.52,
      "learning_rate": 0.08835275358274194,
      "loss": 1.048,
      "step": 72240
    },
    {
      "epoch": 116.55,
      "learning_rate": 0.08834952777951613,
      "loss": 1.0639,
      "step": 72260
    },
    {
      "epoch": 116.58,
      "learning_rate": 0.08834630197629033,
      "loss": 1.0506,
      "step": 72280
    },
    {
      "epoch": 116.61,
      "learning_rate": 0.08834307617306453,
      "loss": 1.063,
      "step": 72300
    },
    {
      "epoch": 116.65,
      "learning_rate": 0.08833985036983871,
      "loss": 1.0804,
      "step": 72320
    },
    {
      "epoch": 116.68,
      "learning_rate": 0.08833662456661291,
      "loss": 1.0755,
      "step": 72340
    },
    {
      "epoch": 116.71,
      "learning_rate": 0.08833339876338711,
      "loss": 1.0914,
      "step": 72360
    },
    {
      "epoch": 116.74,
      "learning_rate": 0.0883301729601613,
      "loss": 1.0361,
      "step": 72380
    },
    {
      "epoch": 116.77,
      "learning_rate": 0.0883269471569355,
      "loss": 1.0515,
      "step": 72400
    },
    {
      "epoch": 116.81,
      "learning_rate": 0.0883237213537097,
      "loss": 1.0628,
      "step": 72420
    },
    {
      "epoch": 116.84,
      "learning_rate": 0.08832049555048387,
      "loss": 1.036,
      "step": 72440
    },
    {
      "epoch": 116.87,
      "learning_rate": 0.08831726974725806,
      "loss": 1.026,
      "step": 72460
    },
    {
      "epoch": 116.9,
      "learning_rate": 0.08831404394403226,
      "loss": 1.0584,
      "step": 72480
    },
    {
      "epoch": 116.94,
      "learning_rate": 0.08831081814080645,
      "loss": 1.0375,
      "step": 72500
    },
    {
      "epoch": 116.97,
      "learning_rate": 0.08830759233758065,
      "loss": 1.0338,
      "step": 72520
    },
    {
      "epoch": 117.0,
      "learning_rate": 0.08830436653435485,
      "loss": 1.0393,
      "step": 72540
    },
    {
      "epoch": 117.0,
      "eval_accuracy": {
        "accuracy": 0.7273436890172508
      },
      "eval_loss": 1.458359718322754,
      "eval_runtime": 2.6616,
      "eval_samples_per_second": 4813.287,
      "eval_steps_per_second": 75.519,
      "step": 72540
    },
    {
      "epoch": 117.03,
      "learning_rate": 0.08830114073112903,
      "loss": 1.0771,
      "step": 72560
    },
    {
      "epoch": 117.06,
      "learning_rate": 0.08829791492790323,
      "loss": 1.0368,
      "step": 72580
    },
    {
      "epoch": 117.1,
      "learning_rate": 0.08829468912467743,
      "loss": 1.033,
      "step": 72600
    },
    {
      "epoch": 117.13,
      "learning_rate": 0.08829146332145162,
      "loss": 1.0432,
      "step": 72620
    },
    {
      "epoch": 117.16,
      "learning_rate": 0.08828823751822582,
      "loss": 1.0436,
      "step": 72640
    },
    {
      "epoch": 117.19,
      "learning_rate": 0.08828501171500001,
      "loss": 1.0355,
      "step": 72660
    },
    {
      "epoch": 117.23,
      "learning_rate": 0.0882817859117742,
      "loss": 1.0719,
      "step": 72680
    },
    {
      "epoch": 117.26,
      "learning_rate": 0.0882785601085484,
      "loss": 1.0533,
      "step": 72700
    },
    {
      "epoch": 117.29,
      "learning_rate": 0.08827533430532258,
      "loss": 1.0226,
      "step": 72720
    },
    {
      "epoch": 117.32,
      "learning_rate": 0.08827210850209677,
      "loss": 1.0373,
      "step": 72740
    },
    {
      "epoch": 117.35,
      "learning_rate": 0.08826888269887098,
      "loss": 1.0349,
      "step": 72760
    },
    {
      "epoch": 117.39,
      "learning_rate": 0.08826565689564517,
      "loss": 1.0102,
      "step": 72780
    },
    {
      "epoch": 117.42,
      "learning_rate": 0.08826243109241935,
      "loss": 1.0173,
      "step": 72800
    },
    {
      "epoch": 117.45,
      "learning_rate": 0.08825920528919355,
      "loss": 1.0398,
      "step": 72820
    },
    {
      "epoch": 117.48,
      "learning_rate": 0.08825597948596775,
      "loss": 1.0747,
      "step": 72840
    },
    {
      "epoch": 117.52,
      "learning_rate": 0.08825275368274194,
      "loss": 1.0197,
      "step": 72860
    },
    {
      "epoch": 117.55,
      "learning_rate": 0.08824952787951613,
      "loss": 1.0397,
      "step": 72880
    },
    {
      "epoch": 117.58,
      "learning_rate": 0.08824630207629033,
      "loss": 1.0333,
      "step": 72900
    },
    {
      "epoch": 117.61,
      "learning_rate": 0.08824307627306452,
      "loss": 1.062,
      "step": 72920
    },
    {
      "epoch": 117.65,
      "learning_rate": 0.08823985046983872,
      "loss": 1.0566,
      "step": 72940
    },
    {
      "epoch": 117.68,
      "learning_rate": 0.08823662466661292,
      "loss": 1.0615,
      "step": 72960
    },
    {
      "epoch": 117.71,
      "learning_rate": 0.0882333988633871,
      "loss": 1.075,
      "step": 72980
    },
    {
      "epoch": 117.74,
      "learning_rate": 0.0882301730601613,
      "loss": 1.0494,
      "step": 73000
    },
    {
      "epoch": 117.77,
      "learning_rate": 0.08822694725693549,
      "loss": 1.0456,
      "step": 73020
    },
    {
      "epoch": 117.81,
      "learning_rate": 0.08822372145370969,
      "loss": 1.0855,
      "step": 73040
    },
    {
      "epoch": 117.84,
      "learning_rate": 0.08822049565048388,
      "loss": 1.0478,
      "step": 73060
    },
    {
      "epoch": 117.87,
      "learning_rate": 0.08821726984725807,
      "loss": 1.0544,
      "step": 73080
    },
    {
      "epoch": 117.9,
      "learning_rate": 0.08821404404403226,
      "loss": 1.0794,
      "step": 73100
    },
    {
      "epoch": 117.94,
      "learning_rate": 0.08821097953096775,
      "loss": 1.0542,
      "step": 73120
    },
    {
      "epoch": 117.97,
      "learning_rate": 0.08820775372774195,
      "loss": 1.0433,
      "step": 73140
    },
    {
      "epoch": 118.0,
      "learning_rate": 0.08820452792451614,
      "loss": 1.0682,
      "step": 73160
    },
    {
      "epoch": 118.0,
      "eval_accuracy": {
        "accuracy": 0.7275778627741785
      },
      "eval_loss": 1.3988829851150513,
      "eval_runtime": 2.6895,
      "eval_samples_per_second": 4763.273,
      "eval_steps_per_second": 74.734,
      "step": 73160
    },
    {
      "epoch": 118.03,
      "learning_rate": 0.08820130212129033,
      "loss": 1.0652,
      "step": 73180
    },
    {
      "epoch": 118.06,
      "learning_rate": 0.08819807631806453,
      "loss": 1.0054,
      "step": 73200
    },
    {
      "epoch": 118.1,
      "learning_rate": 0.0881948505148387,
      "loss": 1.0327,
      "step": 73220
    },
    {
      "epoch": 118.13,
      "learning_rate": 0.0881916247116129,
      "loss": 1.0211,
      "step": 73240
    },
    {
      "epoch": 118.16,
      "learning_rate": 0.0881883989083871,
      "loss": 1.0148,
      "step": 73260
    },
    {
      "epoch": 118.19,
      "learning_rate": 0.08818517310516129,
      "loss": 1.0464,
      "step": 73280
    },
    {
      "epoch": 118.23,
      "learning_rate": 0.08818194730193549,
      "loss": 1.0083,
      "step": 73300
    },
    {
      "epoch": 118.26,
      "learning_rate": 0.08817872149870969,
      "loss": 1.0034,
      "step": 73320
    },
    {
      "epoch": 118.29,
      "learning_rate": 0.08817549569548387,
      "loss": 0.9899,
      "step": 73340
    },
    {
      "epoch": 118.32,
      "learning_rate": 0.08817226989225807,
      "loss": 0.9907,
      "step": 73360
    },
    {
      "epoch": 118.35,
      "learning_rate": 0.08816904408903227,
      "loss": 1.0029,
      "step": 73380
    },
    {
      "epoch": 118.39,
      "learning_rate": 0.08816581828580645,
      "loss": 1.0213,
      "step": 73400
    },
    {
      "epoch": 118.42,
      "learning_rate": 0.08816259248258065,
      "loss": 1.0297,
      "step": 73420
    },
    {
      "epoch": 118.45,
      "learning_rate": 0.08815936667935485,
      "loss": 1.063,
      "step": 73440
    },
    {
      "epoch": 118.48,
      "learning_rate": 0.08815614087612904,
      "loss": 1.0341,
      "step": 73460
    },
    {
      "epoch": 118.52,
      "learning_rate": 0.08815291507290324,
      "loss": 1.0244,
      "step": 73480
    },
    {
      "epoch": 118.55,
      "learning_rate": 0.08814968926967744,
      "loss": 1.0548,
      "step": 73500
    },
    {
      "epoch": 118.58,
      "learning_rate": 0.08814646346645161,
      "loss": 1.0567,
      "step": 73520
    },
    {
      "epoch": 118.61,
      "learning_rate": 0.0881432376632258,
      "loss": 1.018,
      "step": 73540
    },
    {
      "epoch": 118.65,
      "learning_rate": 0.08814001186,
      "loss": 1.0497,
      "step": 73560
    },
    {
      "epoch": 118.68,
      "learning_rate": 0.08813678605677419,
      "loss": 1.0698,
      "step": 73580
    },
    {
      "epoch": 118.71,
      "learning_rate": 0.08813356025354839,
      "loss": 1.0412,
      "step": 73600
    },
    {
      "epoch": 118.74,
      "learning_rate": 0.08813033445032259,
      "loss": 1.034,
      "step": 73620
    },
    {
      "epoch": 118.77,
      "learning_rate": 0.08812710864709677,
      "loss": 1.0367,
      "step": 73640
    },
    {
      "epoch": 118.81,
      "learning_rate": 0.08812388284387097,
      "loss": 1.0685,
      "step": 73660
    },
    {
      "epoch": 118.84,
      "learning_rate": 0.08812065704064517,
      "loss": 1.0739,
      "step": 73680
    },
    {
      "epoch": 118.87,
      "learning_rate": 0.08811743123741936,
      "loss": 1.07,
      "step": 73700
    },
    {
      "epoch": 118.9,
      "learning_rate": 0.08811420543419356,
      "loss": 1.0871,
      "step": 73720
    },
    {
      "epoch": 118.94,
      "learning_rate": 0.08811097963096776,
      "loss": 1.1009,
      "step": 73740
    },
    {
      "epoch": 118.97,
      "learning_rate": 0.08810775382774194,
      "loss": 1.087,
      "step": 73760
    },
    {
      "epoch": 119.0,
      "learning_rate": 0.08810452802451614,
      "loss": 1.0581,
      "step": 73780
    },
    {
      "epoch": 119.0,
      "eval_accuracy": {
        "accuracy": 0.7333541487783936
      },
      "eval_loss": 1.366278052330017,
      "eval_runtime": 2.9978,
      "eval_samples_per_second": 4273.417,
      "eval_steps_per_second": 67.048,
      "step": 73780
    },
    {
      "epoch": 119.03,
      "learning_rate": 0.08810130222129033,
      "loss": 1.0629,
      "step": 73800
    },
    {
      "epoch": 119.06,
      "learning_rate": 0.08809807641806451,
      "loss": 1.0108,
      "step": 73820
    },
    {
      "epoch": 119.1,
      "learning_rate": 0.08809485061483872,
      "loss": 1.0116,
      "step": 73840
    },
    {
      "epoch": 119.13,
      "learning_rate": 0.08809162481161291,
      "loss": 1.0241,
      "step": 73860
    },
    {
      "epoch": 119.16,
      "learning_rate": 0.0880883990083871,
      "loss": 1.0371,
      "step": 73880
    },
    {
      "epoch": 119.19,
      "learning_rate": 0.0880851732051613,
      "loss": 1.0349,
      "step": 73900
    },
    {
      "epoch": 119.23,
      "learning_rate": 0.08808194740193549,
      "loss": 1.0241,
      "step": 73920
    },
    {
      "epoch": 119.26,
      "learning_rate": 0.08807872159870968,
      "loss": 1.0443,
      "step": 73940
    },
    {
      "epoch": 119.29,
      "learning_rate": 0.08807549579548388,
      "loss": 1.0366,
      "step": 73960
    },
    {
      "epoch": 119.32,
      "learning_rate": 0.08807226999225808,
      "loss": 1.0332,
      "step": 73980
    },
    {
      "epoch": 119.35,
      "learning_rate": 0.08806904418903226,
      "loss": 1.0282,
      "step": 74000
    },
    {
      "epoch": 119.39,
      "learning_rate": 0.08806581838580646,
      "loss": 1.036,
      "step": 74020
    },
    {
      "epoch": 119.42,
      "learning_rate": 0.08806259258258066,
      "loss": 1.0586,
      "step": 74040
    },
    {
      "epoch": 119.45,
      "learning_rate": 0.08805936677935484,
      "loss": 1.0194,
      "step": 74060
    },
    {
      "epoch": 119.48,
      "learning_rate": 0.08805614097612904,
      "loss": 1.0652,
      "step": 74080
    },
    {
      "epoch": 119.52,
      "learning_rate": 0.08805291517290323,
      "loss": 1.0493,
      "step": 74100
    },
    {
      "epoch": 119.55,
      "learning_rate": 0.08804968936967741,
      "loss": 1.0548,
      "step": 74120
    },
    {
      "epoch": 119.58,
      "learning_rate": 0.08804646356645163,
      "loss": 1.0352,
      "step": 74140
    },
    {
      "epoch": 119.61,
      "learning_rate": 0.08804323776322581,
      "loss": 1.036,
      "step": 74160
    },
    {
      "epoch": 119.65,
      "learning_rate": 0.08804001196,
      "loss": 1.0439,
      "step": 74180
    },
    {
      "epoch": 119.68,
      "learning_rate": 0.0880367861567742,
      "loss": 1.0267,
      "step": 74200
    },
    {
      "epoch": 119.71,
      "learning_rate": 0.0880335603535484,
      "loss": 1.063,
      "step": 74220
    },
    {
      "epoch": 119.74,
      "learning_rate": 0.08803033455032258,
      "loss": 1.0657,
      "step": 74240
    },
    {
      "epoch": 119.77,
      "learning_rate": 0.08802710874709678,
      "loss": 1.0603,
      "step": 74260
    },
    {
      "epoch": 119.81,
      "learning_rate": 0.08802388294387098,
      "loss": 1.0461,
      "step": 74280
    },
    {
      "epoch": 119.84,
      "learning_rate": 0.08802065714064516,
      "loss": 1.0445,
      "step": 74300
    },
    {
      "epoch": 119.87,
      "learning_rate": 0.08801743133741936,
      "loss": 1.0709,
      "step": 74320
    },
    {
      "epoch": 119.9,
      "learning_rate": 0.08801420553419355,
      "loss": 1.0509,
      "step": 74340
    },
    {
      "epoch": 119.94,
      "learning_rate": 0.08801097973096775,
      "loss": 1.0274,
      "step": 74360
    },
    {
      "epoch": 119.97,
      "learning_rate": 0.08800775392774195,
      "loss": 1.0092,
      "step": 74380
    },
    {
      "epoch": 120.0,
      "learning_rate": 0.08800452812451613,
      "loss": 1.0312,
      "step": 74400
    },
    {
      "epoch": 120.0,
      "eval_accuracy": {
        "accuracy": 0.7398329560533916
      },
      "eval_loss": 1.3834689855575562,
      "eval_runtime": 3.375,
      "eval_samples_per_second": 3795.805,
      "eval_steps_per_second": 59.555,
      "step": 74400
    },
    {
      "epoch": 120.03,
      "learning_rate": 0.08800130232129033,
      "loss": 1.0847,
      "step": 74420
    },
    {
      "epoch": 120.06,
      "learning_rate": 0.08799807651806453,
      "loss": 1.0384,
      "step": 74440
    },
    {
      "epoch": 120.1,
      "learning_rate": 0.08799485071483872,
      "loss": 0.9943,
      "step": 74460
    },
    {
      "epoch": 120.13,
      "learning_rate": 0.0879916249116129,
      "loss": 1.0075,
      "step": 74480
    },
    {
      "epoch": 120.16,
      "learning_rate": 0.0879883991083871,
      "loss": 0.9918,
      "step": 74500
    },
    {
      "epoch": 120.19,
      "learning_rate": 0.0879851733051613,
      "loss": 1.0153,
      "step": 74520
    },
    {
      "epoch": 120.23,
      "learning_rate": 0.08798194750193548,
      "loss": 1.0475,
      "step": 74540
    },
    {
      "epoch": 120.26,
      "learning_rate": 0.08797872169870968,
      "loss": 0.9847,
      "step": 74560
    },
    {
      "epoch": 120.29,
      "learning_rate": 0.08797549589548388,
      "loss": 1.0419,
      "step": 74580
    },
    {
      "epoch": 120.32,
      "learning_rate": 0.08797227009225807,
      "loss": 1.0789,
      "step": 74600
    },
    {
      "epoch": 120.35,
      "learning_rate": 0.08796904428903227,
      "loss": 1.0357,
      "step": 74620
    },
    {
      "epoch": 120.39,
      "learning_rate": 0.08796581848580645,
      "loss": 1.0691,
      "step": 74640
    },
    {
      "epoch": 120.42,
      "learning_rate": 0.08796259268258065,
      "loss": 1.0613,
      "step": 74660
    },
    {
      "epoch": 120.45,
      "learning_rate": 0.08795936687935485,
      "loss": 1.0615,
      "step": 74680
    },
    {
      "epoch": 120.48,
      "learning_rate": 0.08795614107612904,
      "loss": 1.0252,
      "step": 74700
    },
    {
      "epoch": 120.52,
      "learning_rate": 0.08795291527290323,
      "loss": 1.015,
      "step": 74720
    },
    {
      "epoch": 120.55,
      "learning_rate": 0.08794968946967743,
      "loss": 1.0374,
      "step": 74740
    },
    {
      "epoch": 120.58,
      "learning_rate": 0.08794646366645162,
      "loss": 1.0326,
      "step": 74760
    },
    {
      "epoch": 120.61,
      "learning_rate": 0.0879432378632258,
      "loss": 1.0505,
      "step": 74780
    },
    {
      "epoch": 120.65,
      "learning_rate": 0.08794001206,
      "loss": 1.0596,
      "step": 74800
    },
    {
      "epoch": 120.68,
      "learning_rate": 0.0879367862567742,
      "loss": 1.058,
      "step": 74820
    },
    {
      "epoch": 120.71,
      "learning_rate": 0.08793356045354839,
      "loss": 1.0351,
      "step": 74840
    },
    {
      "epoch": 120.74,
      "learning_rate": 0.08793033465032259,
      "loss": 1.037,
      "step": 74860
    },
    {
      "epoch": 120.77,
      "learning_rate": 0.08792710884709677,
      "loss": 1.0254,
      "step": 74880
    },
    {
      "epoch": 120.81,
      "learning_rate": 0.08792388304387097,
      "loss": 1.0829,
      "step": 74900
    },
    {
      "epoch": 120.84,
      "learning_rate": 0.08792065724064517,
      "loss": 1.0386,
      "step": 74920
    },
    {
      "epoch": 120.87,
      "learning_rate": 0.08791743143741935,
      "loss": 1.0658,
      "step": 74940
    },
    {
      "epoch": 120.9,
      "learning_rate": 0.08791420563419355,
      "loss": 1.0424,
      "step": 74960
    },
    {
      "epoch": 120.94,
      "learning_rate": 0.08791097983096775,
      "loss": 1.0581,
      "step": 74980
    },
    {
      "epoch": 120.97,
      "learning_rate": 0.08790775402774194,
      "loss": 1.0526,
      "step": 75000
    },
    {
      "epoch": 121.0,
      "learning_rate": 0.08790452822451614,
      "loss": 1.0692,
      "step": 75020
    },
    {
      "epoch": 121.0,
      "eval_accuracy": {
        "accuracy": 0.7264850519085161
      },
      "eval_loss": 1.436961054801941,
      "eval_runtime": 2.952,
      "eval_samples_per_second": 4339.746,
      "eval_steps_per_second": 68.089,
      "step": 75020
    },
    {
      "epoch": 121.03,
      "learning_rate": 0.08790130242129034,
      "loss": 1.1231,
      "step": 75040
    },
    {
      "epoch": 121.06,
      "learning_rate": 0.08789807661806452,
      "loss": 1.0544,
      "step": 75060
    },
    {
      "epoch": 121.1,
      "learning_rate": 0.08789485081483872,
      "loss": 0.9825,
      "step": 75080
    },
    {
      "epoch": 121.13,
      "learning_rate": 0.0878916250116129,
      "loss": 1.01,
      "step": 75100
    },
    {
      "epoch": 121.16,
      "learning_rate": 0.0878883992083871,
      "loss": 1.0317,
      "step": 75120
    },
    {
      "epoch": 121.19,
      "learning_rate": 0.08788517340516129,
      "loss": 1.0438,
      "step": 75140
    },
    {
      "epoch": 121.23,
      "learning_rate": 0.08788194760193549,
      "loss": 1.053,
      "step": 75160
    },
    {
      "epoch": 121.26,
      "learning_rate": 0.08787872179870967,
      "loss": 1.1156,
      "step": 75180
    },
    {
      "epoch": 121.29,
      "learning_rate": 0.08787549599548387,
      "loss": 1.0581,
      "step": 75200
    },
    {
      "epoch": 121.32,
      "learning_rate": 0.08787227019225807,
      "loss": 1.0366,
      "step": 75220
    },
    {
      "epoch": 121.35,
      "learning_rate": 0.08786904438903226,
      "loss": 1.0179,
      "step": 75240
    },
    {
      "epoch": 121.39,
      "learning_rate": 0.08786581858580646,
      "loss": 1.0303,
      "step": 75260
    },
    {
      "epoch": 121.42,
      "learning_rate": 0.08786259278258066,
      "loss": 1.0404,
      "step": 75280
    },
    {
      "epoch": 121.45,
      "learning_rate": 0.08785936697935484,
      "loss": 1.0479,
      "step": 75300
    },
    {
      "epoch": 121.48,
      "learning_rate": 0.08785614117612904,
      "loss": 1.0297,
      "step": 75320
    },
    {
      "epoch": 121.52,
      "learning_rate": 0.08785291537290324,
      "loss": 1.0323,
      "step": 75340
    },
    {
      "epoch": 121.55,
      "learning_rate": 0.08784968956967742,
      "loss": 1.0646,
      "step": 75360
    },
    {
      "epoch": 121.58,
      "learning_rate": 0.08784646376645162,
      "loss": 1.0254,
      "step": 75380
    },
    {
      "epoch": 121.61,
      "learning_rate": 0.08784323796322581,
      "loss": 1.0272,
      "step": 75400
    },
    {
      "epoch": 121.65,
      "learning_rate": 0.08784001216,
      "loss": 1.0528,
      "step": 75420
    },
    {
      "epoch": 121.68,
      "learning_rate": 0.0878367863567742,
      "loss": 1.0385,
      "step": 75440
    },
    {
      "epoch": 121.71,
      "learning_rate": 0.08783356055354839,
      "loss": 1.0178,
      "step": 75460
    },
    {
      "epoch": 121.74,
      "learning_rate": 0.08783033475032258,
      "loss": 1.0554,
      "step": 75480
    },
    {
      "epoch": 121.77,
      "learning_rate": 0.08782710894709678,
      "loss": 1.0388,
      "step": 75500
    },
    {
      "epoch": 121.81,
      "learning_rate": 0.08782388314387098,
      "loss": 1.0612,
      "step": 75520
    },
    {
      "epoch": 121.84,
      "learning_rate": 0.08782065734064516,
      "loss": 1.0438,
      "step": 75540
    },
    {
      "epoch": 121.87,
      "learning_rate": 0.08781743153741936,
      "loss": 1.0614,
      "step": 75560
    },
    {
      "epoch": 121.9,
      "learning_rate": 0.08781420573419356,
      "loss": 1.0565,
      "step": 75580
    },
    {
      "epoch": 121.94,
      "learning_rate": 0.08781097993096774,
      "loss": 1.0215,
      "step": 75600
    },
    {
      "epoch": 121.97,
      "learning_rate": 0.08780775412774194,
      "loss": 1.0046,
      "step": 75620
    },
    {
      "epoch": 122.0,
      "learning_rate": 0.08780468961467743,
      "loss": 1.0716,
      "step": 75640
    },
    {
      "epoch": 122.0,
      "eval_accuracy": {
        "accuracy": 0.7412379985949574
      },
      "eval_loss": 1.3333640098571777,
      "eval_runtime": 2.6362,
      "eval_samples_per_second": 4859.625,
      "eval_steps_per_second": 76.246,
      "step": 75640
    },
    {
      "epoch": 122.03,
      "learning_rate": 0.08780146381145162,
      "loss": 1.0331,
      "step": 75660
    },
    {
      "epoch": 122.06,
      "learning_rate": 0.08779823800822581,
      "loss": 1.02,
      "step": 75680
    },
    {
      "epoch": 122.1,
      "learning_rate": 0.08779501220500001,
      "loss": 1.0257,
      "step": 75700
    },
    {
      "epoch": 122.13,
      "learning_rate": 0.0877917864017742,
      "loss": 1.0061,
      "step": 75720
    },
    {
      "epoch": 122.16,
      "learning_rate": 0.08778856059854839,
      "loss": 1.0155,
      "step": 75740
    },
    {
      "epoch": 122.19,
      "learning_rate": 0.08778533479532259,
      "loss": 1.0088,
      "step": 75760
    },
    {
      "epoch": 122.23,
      "learning_rate": 0.08778210899209678,
      "loss": 1.0372,
      "step": 75780
    },
    {
      "epoch": 122.26,
      "learning_rate": 0.08777888318887098,
      "loss": 0.9892,
      "step": 75800
    },
    {
      "epoch": 122.29,
      "learning_rate": 0.08777565738564518,
      "loss": 1.0267,
      "step": 75820
    },
    {
      "epoch": 122.32,
      "learning_rate": 0.08777243158241936,
      "loss": 1.0303,
      "step": 75840
    },
    {
      "epoch": 122.35,
      "learning_rate": 0.08776920577919355,
      "loss": 1.0552,
      "step": 75860
    },
    {
      "epoch": 122.39,
      "learning_rate": 0.08776597997596775,
      "loss": 1.0646,
      "step": 75880
    },
    {
      "epoch": 122.42,
      "learning_rate": 0.08776275417274194,
      "loss": 1.0599,
      "step": 75900
    },
    {
      "epoch": 122.45,
      "learning_rate": 0.08775952836951613,
      "loss": 1.0328,
      "step": 75920
    },
    {
      "epoch": 122.48,
      "learning_rate": 0.08775630256629033,
      "loss": 1.0094,
      "step": 75940
    },
    {
      "epoch": 122.52,
      "learning_rate": 0.08775307676306451,
      "loss": 1.0609,
      "step": 75960
    },
    {
      "epoch": 122.55,
      "learning_rate": 0.08774985095983871,
      "loss": 1.0249,
      "step": 75980
    },
    {
      "epoch": 122.58,
      "learning_rate": 0.08774662515661291,
      "loss": 1.054,
      "step": 76000
    },
    {
      "epoch": 122.61,
      "learning_rate": 0.0877433993533871,
      "loss": 1.0508,
      "step": 76020
    },
    {
      "epoch": 122.65,
      "learning_rate": 0.0877401735501613,
      "loss": 1.0167,
      "step": 76040
    },
    {
      "epoch": 122.68,
      "learning_rate": 0.0877369477469355,
      "loss": 1.0243,
      "step": 76060
    },
    {
      "epoch": 122.71,
      "learning_rate": 0.08773372194370968,
      "loss": 1.0304,
      "step": 76080
    },
    {
      "epoch": 122.74,
      "learning_rate": 0.08773049614048388,
      "loss": 1.049,
      "step": 76100
    },
    {
      "epoch": 122.77,
      "learning_rate": 0.08772727033725808,
      "loss": 1.0072,
      "step": 76120
    },
    {
      "epoch": 122.81,
      "learning_rate": 0.08772404453403226,
      "loss": 1.0478,
      "step": 76140
    },
    {
      "epoch": 122.84,
      "learning_rate": 0.08772081873080646,
      "loss": 1.0481,
      "step": 76160
    },
    {
      "epoch": 122.87,
      "learning_rate": 0.08771759292758065,
      "loss": 1.0789,
      "step": 76180
    },
    {
      "epoch": 122.9,
      "learning_rate": 0.08771436712435485,
      "loss": 1.0477,
      "step": 76200
    },
    {
      "epoch": 122.94,
      "learning_rate": 0.08771114132112903,
      "loss": 1.0264,
      "step": 76220
    },
    {
      "epoch": 122.97,
      "learning_rate": 0.08770791551790323,
      "loss": 1.0569,
      "step": 76240
    },
    {
      "epoch": 123.0,
      "learning_rate": 0.08770468971467742,
      "loss": 1.025,
      "step": 76260
    },
    {
      "epoch": 123.0,
      "eval_accuracy": {
        "accuracy": 0.7399890718913433
      },
      "eval_loss": 1.368003010749817,
      "eval_runtime": 2.9451,
      "eval_samples_per_second": 4349.988,
      "eval_steps_per_second": 68.25,
      "step": 76260
    },
    {
      "epoch": 123.03,
      "learning_rate": 0.08770146391145162,
      "loss": 1.0537,
      "step": 76280
    },
    {
      "epoch": 123.06,
      "learning_rate": 0.08769823810822582,
      "loss": 0.9954,
      "step": 76300
    },
    {
      "epoch": 123.1,
      "learning_rate": 0.087695012305,
      "loss": 1.0045,
      "step": 76320
    },
    {
      "epoch": 123.13,
      "learning_rate": 0.0876917865017742,
      "loss": 1.0106,
      "step": 76340
    },
    {
      "epoch": 123.16,
      "learning_rate": 0.0876885606985484,
      "loss": 1.0043,
      "step": 76360
    },
    {
      "epoch": 123.19,
      "learning_rate": 0.08768533489532258,
      "loss": 1.0134,
      "step": 76380
    },
    {
      "epoch": 123.23,
      "learning_rate": 0.08768210909209678,
      "loss": 1.0119,
      "step": 76400
    },
    {
      "epoch": 123.26,
      "learning_rate": 0.08767888328887098,
      "loss": 1.0233,
      "step": 76420
    },
    {
      "epoch": 123.29,
      "learning_rate": 0.08767565748564517,
      "loss": 1.047,
      "step": 76440
    },
    {
      "epoch": 123.32,
      "learning_rate": 0.08767243168241937,
      "loss": 1.0412,
      "step": 76460
    },
    {
      "epoch": 123.35,
      "learning_rate": 0.08766920587919355,
      "loss": 1.0293,
      "step": 76480
    },
    {
      "epoch": 123.39,
      "learning_rate": 0.08766598007596774,
      "loss": 1.045,
      "step": 76500
    },
    {
      "epoch": 123.42,
      "learning_rate": 0.08766275427274194,
      "loss": 1.0403,
      "step": 76520
    },
    {
      "epoch": 123.45,
      "learning_rate": 0.08765952846951613,
      "loss": 1.0542,
      "step": 76540
    },
    {
      "epoch": 123.48,
      "learning_rate": 0.08765630266629032,
      "loss": 1.0503,
      "step": 76560
    },
    {
      "epoch": 123.52,
      "learning_rate": 0.08765307686306452,
      "loss": 1.0293,
      "step": 76580
    },
    {
      "epoch": 123.55,
      "learning_rate": 0.08764985105983872,
      "loss": 1.0107,
      "step": 76600
    },
    {
      "epoch": 123.58,
      "learning_rate": 0.0876466252566129,
      "loss": 0.9933,
      "step": 76620
    },
    {
      "epoch": 123.61,
      "learning_rate": 0.0876433994533871,
      "loss": 1.0393,
      "step": 76640
    },
    {
      "epoch": 123.65,
      "learning_rate": 0.0876401736501613,
      "loss": 1.0432,
      "step": 76660
    },
    {
      "epoch": 123.68,
      "learning_rate": 0.08763694784693549,
      "loss": 1.0615,
      "step": 76680
    },
    {
      "epoch": 123.71,
      "learning_rate": 0.08763372204370969,
      "loss": 1.0647,
      "step": 76700
    },
    {
      "epoch": 123.74,
      "learning_rate": 0.08763049624048388,
      "loss": 1.0859,
      "step": 76720
    },
    {
      "epoch": 123.77,
      "learning_rate": 0.08762727043725807,
      "loss": 1.0387,
      "step": 76740
    },
    {
      "epoch": 123.81,
      "learning_rate": 0.08762404463403227,
      "loss": 1.0239,
      "step": 76760
    },
    {
      "epoch": 123.84,
      "learning_rate": 0.08762081883080645,
      "loss": 1.0478,
      "step": 76780
    },
    {
      "epoch": 123.87,
      "learning_rate": 0.08761759302758064,
      "loss": 1.0529,
      "step": 76800
    },
    {
      "epoch": 123.9,
      "learning_rate": 0.08761436722435484,
      "loss": 1.0718,
      "step": 76820
    },
    {
      "epoch": 123.94,
      "learning_rate": 0.08761114142112904,
      "loss": 1.0267,
      "step": 76840
    },
    {
      "epoch": 123.97,
      "learning_rate": 0.08760791561790322,
      "loss": 1.013,
      "step": 76860
    },
    {
      "epoch": 124.0,
      "learning_rate": 0.08760468981467742,
      "loss": 1.0215,
      "step": 76880
    },
    {
      "epoch": 124.0,
      "eval_accuracy": {
        "accuracy": 0.7435797361642339
      },
      "eval_loss": 1.3294568061828613,
      "eval_runtime": 3.9351,
      "eval_samples_per_second": 3255.57,
      "eval_steps_per_second": 51.079,
      "step": 76880
    },
    {
      "epoch": 124.03,
      "learning_rate": 0.08760146401145162,
      "loss": 1.0488,
      "step": 76900
    },
    {
      "epoch": 124.06,
      "learning_rate": 0.0875982382082258,
      "loss": 1.0158,
      "step": 76920
    },
    {
      "epoch": 124.1,
      "learning_rate": 0.087595012405,
      "loss": 1.0205,
      "step": 76940
    },
    {
      "epoch": 124.13,
      "learning_rate": 0.0875917866017742,
      "loss": 1.0029,
      "step": 76960
    },
    {
      "epoch": 124.16,
      "learning_rate": 0.08758856079854839,
      "loss": 1.0159,
      "step": 76980
    },
    {
      "epoch": 124.19,
      "learning_rate": 0.08758533499532259,
      "loss": 0.9995,
      "step": 77000
    },
    {
      "epoch": 124.23,
      "learning_rate": 0.08758210919209679,
      "loss": 1.0569,
      "step": 77020
    },
    {
      "epoch": 124.26,
      "learning_rate": 0.08757888338887097,
      "loss": 1.0465,
      "step": 77040
    },
    {
      "epoch": 124.29,
      "learning_rate": 0.08757565758564517,
      "loss": 1.0511,
      "step": 77060
    },
    {
      "epoch": 124.32,
      "learning_rate": 0.08757243178241936,
      "loss": 1.0359,
      "step": 77080
    },
    {
      "epoch": 124.35,
      "learning_rate": 0.08756920597919354,
      "loss": 1.0282,
      "step": 77100
    },
    {
      "epoch": 124.39,
      "learning_rate": 0.08756598017596774,
      "loss": 1.0125,
      "step": 77120
    },
    {
      "epoch": 124.42,
      "learning_rate": 0.08756275437274194,
      "loss": 1.0173,
      "step": 77140
    },
    {
      "epoch": 124.45,
      "learning_rate": 0.08755952856951613,
      "loss": 1.0302,
      "step": 77160
    },
    {
      "epoch": 124.48,
      "learning_rate": 0.08755630276629033,
      "loss": 1.0162,
      "step": 77180
    },
    {
      "epoch": 124.52,
      "learning_rate": 0.08755307696306452,
      "loss": 1.0397,
      "step": 77200
    },
    {
      "epoch": 124.55,
      "learning_rate": 0.08754985115983871,
      "loss": 1.0174,
      "step": 77220
    },
    {
      "epoch": 124.58,
      "learning_rate": 0.08754662535661291,
      "loss": 1.0538,
      "step": 77240
    },
    {
      "epoch": 124.61,
      "learning_rate": 0.08754339955338711,
      "loss": 1.0116,
      "step": 77260
    },
    {
      "epoch": 124.65,
      "learning_rate": 0.0875401737501613,
      "loss": 1.0379,
      "step": 77280
    },
    {
      "epoch": 124.68,
      "learning_rate": 0.08753694794693549,
      "loss": 1.0458,
      "step": 77300
    },
    {
      "epoch": 124.71,
      "learning_rate": 0.08753372214370969,
      "loss": 1.051,
      "step": 77320
    },
    {
      "epoch": 124.74,
      "learning_rate": 0.08753049634048388,
      "loss": 1.0316,
      "step": 77340
    },
    {
      "epoch": 124.77,
      "learning_rate": 0.08752727053725808,
      "loss": 1.0387,
      "step": 77360
    },
    {
      "epoch": 124.81,
      "learning_rate": 0.08752404473403226,
      "loss": 1.0523,
      "step": 77380
    },
    {
      "epoch": 124.84,
      "learning_rate": 0.08752081893080646,
      "loss": 1.0415,
      "step": 77400
    },
    {
      "epoch": 124.87,
      "learning_rate": 0.08751759312758065,
      "loss": 1.0112,
      "step": 77420
    },
    {
      "epoch": 124.9,
      "learning_rate": 0.08751436732435484,
      "loss": 1.049,
      "step": 77440
    },
    {
      "epoch": 124.94,
      "learning_rate": 0.08751114152112903,
      "loss": 1.0438,
      "step": 77460
    },
    {
      "epoch": 124.97,
      "learning_rate": 0.08750791571790323,
      "loss": 1.033,
      "step": 77480
    },
    {
      "epoch": 125.0,
      "learning_rate": 0.08750468991467743,
      "loss": 1.0643,
      "step": 77500
    },
    {
      "epoch": 125.0,
      "eval_accuracy": {
        "accuracy": 0.7319491062368277
      },
      "eval_loss": 1.4356331825256348,
      "eval_runtime": 4.0797,
      "eval_samples_per_second": 3140.153,
      "eval_steps_per_second": 49.268,
      "step": 77500
    },
    {
      "epoch": 125.03,
      "learning_rate": 0.08750146411145161,
      "loss": 1.0498,
      "step": 77520
    },
    {
      "epoch": 125.06,
      "learning_rate": 0.08749823830822581,
      "loss": 1.0219,
      "step": 77540
    },
    {
      "epoch": 125.1,
      "learning_rate": 0.08749501250500001,
      "loss": 1.066,
      "step": 77560
    },
    {
      "epoch": 125.13,
      "learning_rate": 0.0874917867017742,
      "loss": 1.0381,
      "step": 77580
    },
    {
      "epoch": 125.16,
      "learning_rate": 0.0874885608985484,
      "loss": 1.0201,
      "step": 77600
    },
    {
      "epoch": 125.19,
      "learning_rate": 0.0874853350953226,
      "loss": 1.0045,
      "step": 77620
    },
    {
      "epoch": 125.23,
      "learning_rate": 0.08748210929209678,
      "loss": 0.988,
      "step": 77640
    },
    {
      "epoch": 125.26,
      "learning_rate": 0.08747888348887098,
      "loss": 1.0384,
      "step": 77660
    },
    {
      "epoch": 125.29,
      "learning_rate": 0.08747565768564516,
      "loss": 1.0318,
      "step": 77680
    },
    {
      "epoch": 125.32,
      "learning_rate": 0.08747243188241936,
      "loss": 1.0182,
      "step": 77700
    },
    {
      "epoch": 125.35,
      "learning_rate": 0.08746920607919355,
      "loss": 1.0138,
      "step": 77720
    },
    {
      "epoch": 125.39,
      "learning_rate": 0.08746598027596775,
      "loss": 0.9886,
      "step": 77740
    },
    {
      "epoch": 125.42,
      "learning_rate": 0.08746275447274193,
      "loss": 1.0311,
      "step": 77760
    },
    {
      "epoch": 125.45,
      "learning_rate": 0.08745968995967743,
      "loss": 1.0258,
      "step": 77780
    },
    {
      "epoch": 125.48,
      "learning_rate": 0.08745646415645163,
      "loss": 1.0115,
      "step": 77800
    },
    {
      "epoch": 125.52,
      "learning_rate": 0.08745323835322581,
      "loss": 1.028,
      "step": 77820
    },
    {
      "epoch": 125.55,
      "learning_rate": 0.08745001255000001,
      "loss": 1.0467,
      "step": 77840
    },
    {
      "epoch": 125.58,
      "learning_rate": 0.0874467867467742,
      "loss": 1.046,
      "step": 77860
    },
    {
      "epoch": 125.61,
      "learning_rate": 0.0874435609435484,
      "loss": 1.0409,
      "step": 77880
    },
    {
      "epoch": 125.65,
      "learning_rate": 0.08744033514032258,
      "loss": 1.0361,
      "step": 77900
    },
    {
      "epoch": 125.68,
      "learning_rate": 0.08743710933709678,
      "loss": 1.0115,
      "step": 77920
    },
    {
      "epoch": 125.71,
      "learning_rate": 0.08743388353387097,
      "loss": 1.0467,
      "step": 77940
    },
    {
      "epoch": 125.74,
      "learning_rate": 0.08743065773064516,
      "loss": 1.024,
      "step": 77960
    },
    {
      "epoch": 125.77,
      "learning_rate": 0.08742743192741936,
      "loss": 1.0131,
      "step": 77980
    },
    {
      "epoch": 125.81,
      "learning_rate": 0.08742420612419355,
      "loss": 1.0513,
      "step": 78000
    },
    {
      "epoch": 125.84,
      "learning_rate": 0.08742098032096775,
      "loss": 1.0602,
      "step": 78020
    },
    {
      "epoch": 125.87,
      "learning_rate": 0.08741775451774195,
      "loss": 1.0645,
      "step": 78040
    },
    {
      "epoch": 125.9,
      "learning_rate": 0.08741452871451613,
      "loss": 1.0671,
      "step": 78060
    },
    {
      "epoch": 125.94,
      "learning_rate": 0.08741130291129033,
      "loss": 1.0526,
      "step": 78080
    },
    {
      "epoch": 125.97,
      "learning_rate": 0.08740807710806453,
      "loss": 1.0422,
      "step": 78100
    },
    {
      "epoch": 126.0,
      "learning_rate": 0.0874048513048387,
      "loss": 1.0846,
      "step": 78120
    },
    {
      "epoch": 126.0,
      "eval_accuracy": {
        "accuracy": 0.7267192256654438
      },
      "eval_loss": 1.428201675415039,
      "eval_runtime": 2.8065,
      "eval_samples_per_second": 4564.697,
      "eval_steps_per_second": 71.618,
      "step": 78120
    },
    {
      "epoch": 126.03,
      "learning_rate": 0.08740162550161291,
      "loss": 1.091,
      "step": 78140
    },
    {
      "epoch": 126.06,
      "learning_rate": 0.0873983996983871,
      "loss": 1.0236,
      "step": 78160
    },
    {
      "epoch": 126.1,
      "learning_rate": 0.0873951738951613,
      "loss": 0.9926,
      "step": 78180
    },
    {
      "epoch": 126.13,
      "learning_rate": 0.08739194809193548,
      "loss": 1.0081,
      "step": 78200
    },
    {
      "epoch": 126.16,
      "learning_rate": 0.08738872228870968,
      "loss": 1.0562,
      "step": 78220
    },
    {
      "epoch": 126.19,
      "learning_rate": 0.08738549648548387,
      "loss": 1.0352,
      "step": 78240
    },
    {
      "epoch": 126.23,
      "learning_rate": 0.08738227068225807,
      "loss": 1.0094,
      "step": 78260
    },
    {
      "epoch": 126.26,
      "learning_rate": 0.08737904487903227,
      "loss": 1.0268,
      "step": 78280
    },
    {
      "epoch": 126.29,
      "learning_rate": 0.08737581907580645,
      "loss": 1.0442,
      "step": 78300
    },
    {
      "epoch": 126.32,
      "learning_rate": 0.08737259327258065,
      "loss": 1.0349,
      "step": 78320
    },
    {
      "epoch": 126.35,
      "learning_rate": 0.08736936746935485,
      "loss": 1.0318,
      "step": 78340
    },
    {
      "epoch": 126.39,
      "learning_rate": 0.08736614166612904,
      "loss": 1.0272,
      "step": 78360
    },
    {
      "epoch": 126.42,
      "learning_rate": 0.08736291586290323,
      "loss": 0.997,
      "step": 78380
    },
    {
      "epoch": 126.45,
      "learning_rate": 0.08735969005967743,
      "loss": 1.0539,
      "step": 78400
    },
    {
      "epoch": 126.48,
      "learning_rate": 0.08735646425645162,
      "loss": 1.0027,
      "step": 78420
    },
    {
      "epoch": 126.52,
      "learning_rate": 0.08735323845322582,
      "loss": 1.0026,
      "step": 78440
    },
    {
      "epoch": 126.55,
      "learning_rate": 0.08735001265,
      "loss": 1.0308,
      "step": 78460
    },
    {
      "epoch": 126.58,
      "learning_rate": 0.0873467868467742,
      "loss": 1.0504,
      "step": 78480
    },
    {
      "epoch": 126.61,
      "learning_rate": 0.08734356104354839,
      "loss": 1.0444,
      "step": 78500
    },
    {
      "epoch": 126.65,
      "learning_rate": 0.08734033524032259,
      "loss": 1.0213,
      "step": 78520
    },
    {
      "epoch": 126.68,
      "learning_rate": 0.08733710943709677,
      "loss": 1.0722,
      "step": 78540
    },
    {
      "epoch": 126.71,
      "learning_rate": 0.08733388363387097,
      "loss": 1.0395,
      "step": 78560
    },
    {
      "epoch": 126.74,
      "learning_rate": 0.08733065783064517,
      "loss": 1.0563,
      "step": 78580
    },
    {
      "epoch": 126.77,
      "learning_rate": 0.08732743202741935,
      "loss": 1.0416,
      "step": 78600
    },
    {
      "epoch": 126.81,
      "learning_rate": 0.08732420622419355,
      "loss": 1.0698,
      "step": 78620
    },
    {
      "epoch": 126.84,
      "learning_rate": 0.08732098042096775,
      "loss": 1.0809,
      "step": 78640
    },
    {
      "epoch": 126.87,
      "learning_rate": 0.08731775461774194,
      "loss": 1.0669,
      "step": 78660
    },
    {
      "epoch": 126.9,
      "learning_rate": 0.08731452881451614,
      "loss": 1.0241,
      "step": 78680
    },
    {
      "epoch": 126.94,
      "learning_rate": 0.08731130301129034,
      "loss": 1.0127,
      "step": 78700
    },
    {
      "epoch": 126.97,
      "learning_rate": 0.08730807720806452,
      "loss": 1.0194,
      "step": 78720
    },
    {
      "epoch": 127.0,
      "learning_rate": 0.08730485140483872,
      "loss": 1.0055,
      "step": 78740
    },
    {
      "epoch": 127.0,
      "eval_accuracy": {
        "accuracy": 0.7463898212473655
      },
      "eval_loss": 1.3143197298049927,
      "eval_runtime": 3.4781,
      "eval_samples_per_second": 3683.297,
      "eval_steps_per_second": 57.79,
      "step": 78740
    },
    {
      "epoch": 127.03,
      "learning_rate": 0.0873016256016129,
      "loss": 1.0347,
      "step": 78760
    },
    {
      "epoch": 127.06,
      "learning_rate": 0.0872983997983871,
      "loss": 1.0182,
      "step": 78780
    },
    {
      "epoch": 127.1,
      "learning_rate": 0.08729517399516129,
      "loss": 1.0041,
      "step": 78800
    },
    {
      "epoch": 127.13,
      "learning_rate": 0.08729194819193549,
      "loss": 1.0457,
      "step": 78820
    },
    {
      "epoch": 127.16,
      "learning_rate": 0.08728872238870967,
      "loss": 1.0199,
      "step": 78840
    },
    {
      "epoch": 127.19,
      "learning_rate": 0.08728549658548387,
      "loss": 1.018,
      "step": 78860
    },
    {
      "epoch": 127.23,
      "learning_rate": 0.08728227078225807,
      "loss": 1.014,
      "step": 78880
    },
    {
      "epoch": 127.26,
      "learning_rate": 0.08727904497903226,
      "loss": 1.0084,
      "step": 78900
    },
    {
      "epoch": 127.29,
      "learning_rate": 0.08727581917580646,
      "loss": 1.0004,
      "step": 78920
    },
    {
      "epoch": 127.32,
      "learning_rate": 0.08727259337258066,
      "loss": 1.0511,
      "step": 78940
    },
    {
      "epoch": 127.35,
      "learning_rate": 0.08726936756935484,
      "loss": 1.0406,
      "step": 78960
    },
    {
      "epoch": 127.39,
      "learning_rate": 0.08726614176612904,
      "loss": 1.0052,
      "step": 78980
    },
    {
      "epoch": 127.42,
      "learning_rate": 0.08726291596290324,
      "loss": 1.0201,
      "step": 79000
    },
    {
      "epoch": 127.45,
      "learning_rate": 0.08725969015967742,
      "loss": 1.0096,
      "step": 79020
    },
    {
      "epoch": 127.48,
      "learning_rate": 0.08725646435645162,
      "loss": 1.0748,
      "step": 79040
    },
    {
      "epoch": 127.52,
      "learning_rate": 0.08725323855322581,
      "loss": 1.0175,
      "step": 79060
    },
    {
      "epoch": 127.55,
      "learning_rate": 0.08725001275000001,
      "loss": 1.0405,
      "step": 79080
    },
    {
      "epoch": 127.58,
      "learning_rate": 0.0872467869467742,
      "loss": 1.0154,
      "step": 79100
    },
    {
      "epoch": 127.61,
      "learning_rate": 0.08724356114354839,
      "loss": 1.0298,
      "step": 79120
    },
    {
      "epoch": 127.65,
      "learning_rate": 0.08724033534032258,
      "loss": 1.0116,
      "step": 79140
    },
    {
      "epoch": 127.68,
      "learning_rate": 0.08723710953709678,
      "loss": 1.0242,
      "step": 79160
    },
    {
      "epoch": 127.71,
      "learning_rate": 0.08723388373387098,
      "loss": 1.0439,
      "step": 79180
    },
    {
      "epoch": 127.74,
      "learning_rate": 0.08723065793064516,
      "loss": 1.0454,
      "step": 79200
    },
    {
      "epoch": 127.77,
      "learning_rate": 0.08722743212741936,
      "loss": 1.0494,
      "step": 79220
    },
    {
      "epoch": 127.81,
      "learning_rate": 0.08722420632419356,
      "loss": 1.043,
      "step": 79240
    },
    {
      "epoch": 127.84,
      "learning_rate": 0.08722098052096774,
      "loss": 1.0469,
      "step": 79260
    },
    {
      "epoch": 127.87,
      "learning_rate": 0.08721775471774194,
      "loss": 1.0123,
      "step": 79280
    },
    {
      "epoch": 127.9,
      "learning_rate": 0.08721452891451614,
      "loss": 1.0381,
      "step": 79300
    },
    {
      "epoch": 127.94,
      "learning_rate": 0.08721130311129033,
      "loss": 1.0726,
      "step": 79320
    },
    {
      "epoch": 127.97,
      "learning_rate": 0.08720807730806453,
      "loss": 1.0724,
      "step": 79340
    },
    {
      "epoch": 128.0,
      "learning_rate": 0.08720485150483871,
      "loss": 1.0974,
      "step": 79360
    },
    {
      "epoch": 128.0,
      "eval_accuracy": {
        "accuracy": 0.7328858012645383
      },
      "eval_loss": 1.4169061183929443,
      "eval_runtime": 2.6793,
      "eval_samples_per_second": 4781.455,
      "eval_steps_per_second": 75.019,
      "step": 79360
    },
    {
      "epoch": 128.03,
      "learning_rate": 0.08720162570161291,
      "loss": 1.0973,
      "step": 79380
    },
    {
      "epoch": 128.06,
      "learning_rate": 0.0871983998983871,
      "loss": 1.0506,
      "step": 79400
    },
    {
      "epoch": 128.1,
      "learning_rate": 0.0871951740951613,
      "loss": 1.0367,
      "step": 79420
    },
    {
      "epoch": 128.13,
      "learning_rate": 0.08719194829193548,
      "loss": 1.0384,
      "step": 79440
    },
    {
      "epoch": 128.16,
      "learning_rate": 0.08718872248870968,
      "loss": 1.0365,
      "step": 79460
    },
    {
      "epoch": 128.19,
      "learning_rate": 0.08718549668548388,
      "loss": 1.0288,
      "step": 79480
    },
    {
      "epoch": 128.23,
      "learning_rate": 0.08718227088225806,
      "loss": 1.023,
      "step": 79500
    },
    {
      "epoch": 128.26,
      "learning_rate": 0.08717904507903226,
      "loss": 0.9814,
      "step": 79520
    },
    {
      "epoch": 128.29,
      "learning_rate": 0.08717581927580646,
      "loss": 1.007,
      "step": 79540
    },
    {
      "epoch": 128.32,
      "learning_rate": 0.08717259347258065,
      "loss": 1.0432,
      "step": 79560
    },
    {
      "epoch": 128.35,
      "learning_rate": 0.08716936766935485,
      "loss": 1.0382,
      "step": 79580
    },
    {
      "epoch": 128.39,
      "learning_rate": 0.08716614186612905,
      "loss": 1.0419,
      "step": 79600
    },
    {
      "epoch": 128.42,
      "learning_rate": 0.08716291606290323,
      "loss": 1.0442,
      "step": 79620
    },
    {
      "epoch": 128.45,
      "learning_rate": 0.08715969025967743,
      "loss": 1.0331,
      "step": 79640
    },
    {
      "epoch": 128.48,
      "learning_rate": 0.08715646445645162,
      "loss": 1.0208,
      "step": 79660
    },
    {
      "epoch": 128.52,
      "learning_rate": 0.08715323865322581,
      "loss": 1.0034,
      "step": 79680
    },
    {
      "epoch": 128.55,
      "learning_rate": 0.08715001285,
      "loss": 1.0038,
      "step": 79700
    },
    {
      "epoch": 128.58,
      "learning_rate": 0.0871467870467742,
      "loss": 1.0225,
      "step": 79720
    },
    {
      "epoch": 128.61,
      "learning_rate": 0.08714356124354838,
      "loss": 1.028,
      "step": 79740
    },
    {
      "epoch": 128.65,
      "learning_rate": 0.08714033544032258,
      "loss": 1.0065,
      "step": 79760
    },
    {
      "epoch": 128.68,
      "learning_rate": 0.08713710963709678,
      "loss": 1.0067,
      "step": 79780
    },
    {
      "epoch": 128.71,
      "learning_rate": 0.08713404512403226,
      "loss": 1.0409,
      "step": 79800
    },
    {
      "epoch": 128.74,
      "learning_rate": 0.08713081932080646,
      "loss": 1.0103,
      "step": 79820
    },
    {
      "epoch": 128.77,
      "learning_rate": 0.08712759351758065,
      "loss": 1.0256,
      "step": 79840
    },
    {
      "epoch": 128.81,
      "learning_rate": 0.08712436771435485,
      "loss": 1.0247,
      "step": 79860
    },
    {
      "epoch": 128.84,
      "learning_rate": 0.08712114191112903,
      "loss": 1.0291,
      "step": 79880
    },
    {
      "epoch": 128.87,
      "learning_rate": 0.08711791610790323,
      "loss": 1.0302,
      "step": 79900
    },
    {
      "epoch": 128.9,
      "learning_rate": 0.08711469030467742,
      "loss": 0.9911,
      "step": 79920
    },
    {
      "epoch": 128.94,
      "learning_rate": 0.08711146450145162,
      "loss": 1.0185,
      "step": 79940
    },
    {
      "epoch": 128.97,
      "learning_rate": 0.08710823869822581,
      "loss": 1.038,
      "step": 79960
    },
    {
      "epoch": 129.0,
      "learning_rate": 0.087105012895,
      "loss": 1.064,
      "step": 79980
    },
    {
      "epoch": 129.0,
      "eval_accuracy": {
        "accuracy": 0.7300757161814067
      },
      "eval_loss": 1.4122153520584106,
      "eval_runtime": 10.5449,
      "eval_samples_per_second": 1214.901,
      "eval_steps_per_second": 19.061,
      "step": 79980
    },
    {
      "epoch": 129.03,
      "learning_rate": 0.0871017870917742,
      "loss": 1.0762,
      "step": 80000
    },
    {
      "epoch": 129.06,
      "learning_rate": 0.0870985612885484,
      "loss": 1.0602,
      "step": 80020
    },
    {
      "epoch": 129.1,
      "learning_rate": 0.08709533548532258,
      "loss": 1.0446,
      "step": 80040
    },
    {
      "epoch": 129.13,
      "learning_rate": 0.08709210968209678,
      "loss": 1.0179,
      "step": 80060
    },
    {
      "epoch": 129.16,
      "learning_rate": 0.08708888387887098,
      "loss": 0.9769,
      "step": 80080
    },
    {
      "epoch": 129.19,
      "learning_rate": 0.08708565807564517,
      "loss": 1.0229,
      "step": 80100
    },
    {
      "epoch": 129.23,
      "learning_rate": 0.08708243227241937,
      "loss": 1.0149,
      "step": 80120
    },
    {
      "epoch": 129.26,
      "learning_rate": 0.08707920646919355,
      "loss": 1.0098,
      "step": 80140
    },
    {
      "epoch": 129.29,
      "learning_rate": 0.08707598066596775,
      "loss": 1.0377,
      "step": 80160
    },
    {
      "epoch": 129.32,
      "learning_rate": 0.08707275486274194,
      "loss": 1.0251,
      "step": 80180
    },
    {
      "epoch": 129.35,
      "learning_rate": 0.08706952905951613,
      "loss": 1.0164,
      "step": 80200
    },
    {
      "epoch": 129.39,
      "learning_rate": 0.08706630325629032,
      "loss": 1.0094,
      "step": 80220
    },
    {
      "epoch": 129.42,
      "learning_rate": 0.08706307745306452,
      "loss": 0.9983,
      "step": 80240
    },
    {
      "epoch": 129.45,
      "learning_rate": 0.08705985164983872,
      "loss": 1.0154,
      "step": 80260
    },
    {
      "epoch": 129.48,
      "learning_rate": 0.0870566258466129,
      "loss": 1.0361,
      "step": 80280
    },
    {
      "epoch": 129.52,
      "learning_rate": 0.0870534000433871,
      "loss": 1.016,
      "step": 80300
    },
    {
      "epoch": 129.55,
      "learning_rate": 0.0870501742401613,
      "loss": 1.0139,
      "step": 80320
    },
    {
      "epoch": 129.58,
      "learning_rate": 0.08704694843693549,
      "loss": 1.0412,
      "step": 80340
    },
    {
      "epoch": 129.61,
      "learning_rate": 0.08704372263370969,
      "loss": 1.0273,
      "step": 80360
    },
    {
      "epoch": 129.65,
      "learning_rate": 0.08704049683048388,
      "loss": 1.0586,
      "step": 80380
    },
    {
      "epoch": 129.68,
      "learning_rate": 0.08703727102725807,
      "loss": 1.0338,
      "step": 80400
    },
    {
      "epoch": 129.71,
      "learning_rate": 0.08703404522403227,
      "loss": 0.9873,
      "step": 80420
    },
    {
      "epoch": 129.74,
      "learning_rate": 0.08703081942080645,
      "loss": 0.9872,
      "step": 80440
    },
    {
      "epoch": 129.77,
      "learning_rate": 0.08702759361758065,
      "loss": 1.0391,
      "step": 80460
    },
    {
      "epoch": 129.81,
      "learning_rate": 0.08702436781435484,
      "loss": 1.0434,
      "step": 80480
    },
    {
      "epoch": 129.84,
      "learning_rate": 0.08702114201112904,
      "loss": 1.0612,
      "step": 80500
    },
    {
      "epoch": 129.87,
      "learning_rate": 0.08701791620790322,
      "loss": 1.0514,
      "step": 80520
    },
    {
      "epoch": 129.9,
      "learning_rate": 0.08701469040467742,
      "loss": 1.0665,
      "step": 80540
    },
    {
      "epoch": 129.94,
      "learning_rate": 0.08701146460145162,
      "loss": 1.0168,
      "step": 80560
    },
    {
      "epoch": 129.97,
      "learning_rate": 0.0870082387982258,
      "loss": 1.0422,
      "step": 80580
    },
    {
      "epoch": 130.0,
      "learning_rate": 0.087005012995,
      "loss": 1.0285,
      "step": 80600
    },
    {
      "epoch": 130.0,
      "eval_accuracy": {
        "accuracy": 0.729217079072672
      },
      "eval_loss": 1.402111291885376,
      "eval_runtime": 2.662,
      "eval_samples_per_second": 4812.51,
      "eval_steps_per_second": 75.507,
      "step": 80600
    },
    {
      "epoch": 130.03,
      "learning_rate": 0.0870017871917742,
      "loss": 1.0482,
      "step": 80620
    },
    {
      "epoch": 130.06,
      "learning_rate": 0.08699856138854839,
      "loss": 1.0061,
      "step": 80640
    },
    {
      "epoch": 130.1,
      "learning_rate": 0.08699533558532259,
      "loss": 0.9994,
      "step": 80660
    },
    {
      "epoch": 130.13,
      "learning_rate": 0.08699210978209679,
      "loss": 1.0082,
      "step": 80680
    },
    {
      "epoch": 130.16,
      "learning_rate": 0.08698888397887097,
      "loss": 1.0028,
      "step": 80700
    },
    {
      "epoch": 130.19,
      "learning_rate": 0.08698565817564517,
      "loss": 1.0167,
      "step": 80720
    },
    {
      "epoch": 130.23,
      "learning_rate": 0.08698243237241936,
      "loss": 1.0387,
      "step": 80740
    },
    {
      "epoch": 130.26,
      "learning_rate": 0.08697920656919356,
      "loss": 1.0229,
      "step": 80760
    },
    {
      "epoch": 130.29,
      "learning_rate": 0.08697598076596774,
      "loss": 1.0233,
      "step": 80780
    },
    {
      "epoch": 130.32,
      "learning_rate": 0.08697275496274194,
      "loss": 1.0201,
      "step": 80800
    },
    {
      "epoch": 130.35,
      "learning_rate": 0.08696952915951613,
      "loss": 0.9986,
      "step": 80820
    },
    {
      "epoch": 130.39,
      "learning_rate": 0.08696630335629033,
      "loss": 1.0175,
      "step": 80840
    },
    {
      "epoch": 130.42,
      "learning_rate": 0.08696307755306452,
      "loss": 1.0164,
      "step": 80860
    },
    {
      "epoch": 130.45,
      "learning_rate": 0.08695985174983871,
      "loss": 1.0379,
      "step": 80880
    },
    {
      "epoch": 130.48,
      "learning_rate": 0.08695662594661291,
      "loss": 1.0292,
      "step": 80900
    },
    {
      "epoch": 130.52,
      "learning_rate": 0.08695340014338711,
      "loss": 1.0089,
      "step": 80920
    },
    {
      "epoch": 130.55,
      "learning_rate": 0.0869501743401613,
      "loss": 1.0468,
      "step": 80940
    },
    {
      "epoch": 130.58,
      "learning_rate": 0.08694694853693549,
      "loss": 1.0709,
      "step": 80960
    },
    {
      "epoch": 130.61,
      "learning_rate": 0.08694372273370968,
      "loss": 1.0467,
      "step": 80980
    },
    {
      "epoch": 130.65,
      "learning_rate": 0.08694049693048388,
      "loss": 1.0249,
      "step": 81000
    },
    {
      "epoch": 130.68,
      "learning_rate": 0.08693727112725808,
      "loss": 0.988,
      "step": 81020
    },
    {
      "epoch": 130.71,
      "learning_rate": 0.08693404532403226,
      "loss": 1.0473,
      "step": 81040
    },
    {
      "epoch": 130.74,
      "learning_rate": 0.08693081952080646,
      "loss": 1.0038,
      "step": 81060
    },
    {
      "epoch": 130.77,
      "learning_rate": 0.08692759371758065,
      "loss": 1.0245,
      "step": 81080
    },
    {
      "epoch": 130.81,
      "learning_rate": 0.08692436791435484,
      "loss": 1.045,
      "step": 81100
    },
    {
      "epoch": 130.84,
      "learning_rate": 0.08692114211112903,
      "loss": 1.0357,
      "step": 81120
    },
    {
      "epoch": 130.87,
      "learning_rate": 0.08691791630790323,
      "loss": 1.0412,
      "step": 81140
    },
    {
      "epoch": 130.9,
      "learning_rate": 0.08691469050467743,
      "loss": 1.0263,
      "step": 81160
    },
    {
      "epoch": 130.94,
      "learning_rate": 0.08691146470145161,
      "loss": 1.0012,
      "step": 81180
    },
    {
      "epoch": 130.97,
      "learning_rate": 0.08690823889822581,
      "loss": 1.0168,
      "step": 81200
    },
    {
      "epoch": 131.0,
      "learning_rate": 0.08690501309500001,
      "loss": 1.0443,
      "step": 81220
    },
    {
      "epoch": 131.0,
      "eval_accuracy": {
        "accuracy": 0.726563109827492
      },
      "eval_loss": 1.4638689756393433,
      "eval_runtime": 2.7558,
      "eval_samples_per_second": 4648.713,
      "eval_steps_per_second": 72.937,
      "step": 81220
    },
    {
      "epoch": 131.03,
      "learning_rate": 0.0869017872917742,
      "loss": 1.1018,
      "step": 81240
    },
    {
      "epoch": 131.06,
      "learning_rate": 0.0868985614885484,
      "loss": 1.0659,
      "step": 81260
    },
    {
      "epoch": 131.1,
      "learning_rate": 0.08689533568532258,
      "loss": 1.0352,
      "step": 81280
    },
    {
      "epoch": 131.13,
      "learning_rate": 0.08689210988209678,
      "loss": 1.0036,
      "step": 81300
    },
    {
      "epoch": 131.16,
      "learning_rate": 0.08688888407887098,
      "loss": 1.0132,
      "step": 81320
    },
    {
      "epoch": 131.19,
      "learning_rate": 0.08688565827564516,
      "loss": 1.0182,
      "step": 81340
    },
    {
      "epoch": 131.23,
      "learning_rate": 0.08688243247241936,
      "loss": 1.0311,
      "step": 81360
    },
    {
      "epoch": 131.26,
      "learning_rate": 0.08687920666919355,
      "loss": 1.0423,
      "step": 81380
    },
    {
      "epoch": 131.29,
      "learning_rate": 0.08687598086596775,
      "loss": 1.0396,
      "step": 81400
    },
    {
      "epoch": 131.32,
      "learning_rate": 0.08687275506274193,
      "loss": 1.0443,
      "step": 81420
    },
    {
      "epoch": 131.35,
      "learning_rate": 0.08686952925951615,
      "loss": 1.0244,
      "step": 81440
    },
    {
      "epoch": 131.39,
      "learning_rate": 0.08686630345629033,
      "loss": 1.0416,
      "step": 81460
    },
    {
      "epoch": 131.42,
      "learning_rate": 0.08686307765306452,
      "loss": 0.9892,
      "step": 81480
    },
    {
      "epoch": 131.45,
      "learning_rate": 0.08685985184983872,
      "loss": 1.0277,
      "step": 81500
    },
    {
      "epoch": 131.48,
      "learning_rate": 0.0868566260466129,
      "loss": 1.0691,
      "step": 81520
    },
    {
      "epoch": 131.52,
      "learning_rate": 0.0868534002433871,
      "loss": 1.0224,
      "step": 81540
    },
    {
      "epoch": 131.55,
      "learning_rate": 0.0868501744401613,
      "loss": 1.0279,
      "step": 81560
    },
    {
      "epoch": 131.58,
      "learning_rate": 0.08684694863693548,
      "loss": 1.0437,
      "step": 81580
    },
    {
      "epoch": 131.61,
      "learning_rate": 0.08684372283370968,
      "loss": 1.0247,
      "step": 81600
    },
    {
      "epoch": 131.65,
      "learning_rate": 0.08684049703048388,
      "loss": 1.0726,
      "step": 81620
    },
    {
      "epoch": 131.68,
      "learning_rate": 0.08683727122725807,
      "loss": 1.0562,
      "step": 81640
    },
    {
      "epoch": 131.71,
      "learning_rate": 0.08683404542403227,
      "loss": 1.0564,
      "step": 81660
    },
    {
      "epoch": 131.74,
      "learning_rate": 0.08683081962080645,
      "loss": 1.0226,
      "step": 81680
    },
    {
      "epoch": 131.77,
      "learning_rate": 0.08682759381758065,
      "loss": 1.005,
      "step": 81700
    },
    {
      "epoch": 131.81,
      "learning_rate": 0.08682436801435484,
      "loss": 1.0039,
      "step": 81720
    },
    {
      "epoch": 131.84,
      "learning_rate": 0.08682114221112905,
      "loss": 1.0088,
      "step": 81740
    },
    {
      "epoch": 131.87,
      "learning_rate": 0.08681791640790322,
      "loss": 1.0339,
      "step": 81760
    },
    {
      "epoch": 131.9,
      "learning_rate": 0.08681469060467742,
      "loss": 1.0381,
      "step": 81780
    },
    {
      "epoch": 131.94,
      "learning_rate": 0.08681146480145162,
      "loss": 1.0351,
      "step": 81800
    },
    {
      "epoch": 131.97,
      "learning_rate": 0.0868082389982258,
      "loss": 1.0697,
      "step": 81820
    },
    {
      "epoch": 132.0,
      "learning_rate": 0.0868051744851613,
      "loss": 1.0335,
      "step": 81840
    },
    {
      "epoch": 132.0,
      "eval_accuracy": {
        "accuracy": 0.7434236203262821
      },
      "eval_loss": 1.3190324306488037,
      "eval_runtime": 2.9544,
      "eval_samples_per_second": 4336.264,
      "eval_steps_per_second": 68.034,
      "step": 81840
    },
    {
      "epoch": 132.03,
      "learning_rate": 0.08680194868193548,
      "loss": 1.0152,
      "step": 81860
    },
    {
      "epoch": 132.06,
      "learning_rate": 0.08679872287870968,
      "loss": 1.0149,
      "step": 81880
    },
    {
      "epoch": 132.1,
      "learning_rate": 0.08679549707548387,
      "loss": 1.0258,
      "step": 81900
    },
    {
      "epoch": 132.13,
      "learning_rate": 0.08679227127225807,
      "loss": 1.0089,
      "step": 81920
    },
    {
      "epoch": 132.16,
      "learning_rate": 0.08678904546903227,
      "loss": 1.0234,
      "step": 81940
    },
    {
      "epoch": 132.19,
      "learning_rate": 0.08678581966580645,
      "loss": 1.0243,
      "step": 81960
    },
    {
      "epoch": 132.23,
      "learning_rate": 0.08678259386258065,
      "loss": 1.0178,
      "step": 81980
    },
    {
      "epoch": 132.26,
      "learning_rate": 0.08677936805935485,
      "loss": 1.0225,
      "step": 82000
    },
    {
      "epoch": 132.29,
      "learning_rate": 0.08677614225612904,
      "loss": 1.0237,
      "step": 82020
    },
    {
      "epoch": 132.32,
      "learning_rate": 0.08677291645290323,
      "loss": 0.9986,
      "step": 82040
    },
    {
      "epoch": 132.35,
      "learning_rate": 0.08676969064967742,
      "loss": 1.0305,
      "step": 82060
    },
    {
      "epoch": 132.39,
      "learning_rate": 0.08676646484645162,
      "loss": 0.998,
      "step": 82080
    },
    {
      "epoch": 132.42,
      "learning_rate": 0.08676323904322582,
      "loss": 1.0027,
      "step": 82100
    },
    {
      "epoch": 132.45,
      "learning_rate": 0.08676001324,
      "loss": 1.0034,
      "step": 82120
    },
    {
      "epoch": 132.48,
      "learning_rate": 0.0867567874367742,
      "loss": 0.9941,
      "step": 82140
    },
    {
      "epoch": 132.52,
      "learning_rate": 0.08675356163354839,
      "loss": 1.0123,
      "step": 82160
    },
    {
      "epoch": 132.55,
      "learning_rate": 0.08675033583032259,
      "loss": 1.0028,
      "step": 82180
    },
    {
      "epoch": 132.58,
      "learning_rate": 0.08674711002709677,
      "loss": 0.9935,
      "step": 82200
    },
    {
      "epoch": 132.61,
      "learning_rate": 0.08674388422387097,
      "loss": 0.9861,
      "step": 82220
    },
    {
      "epoch": 132.65,
      "learning_rate": 0.08674065842064517,
      "loss": 1.0017,
      "step": 82240
    },
    {
      "epoch": 132.68,
      "learning_rate": 0.08673743261741935,
      "loss": 1.0315,
      "step": 82260
    },
    {
      "epoch": 132.71,
      "learning_rate": 0.08673420681419355,
      "loss": 1.0391,
      "step": 82280
    },
    {
      "epoch": 132.74,
      "learning_rate": 0.08673098101096775,
      "loss": 1.0134,
      "step": 82300
    },
    {
      "epoch": 132.77,
      "learning_rate": 0.08672775520774194,
      "loss": 1.0237,
      "step": 82320
    },
    {
      "epoch": 132.81,
      "learning_rate": 0.08672452940451614,
      "loss": 1.0438,
      "step": 82340
    },
    {
      "epoch": 132.84,
      "learning_rate": 0.08672130360129032,
      "loss": 1.0488,
      "step": 82360
    },
    {
      "epoch": 132.87,
      "learning_rate": 0.08671807779806452,
      "loss": 1.0243,
      "step": 82380
    },
    {
      "epoch": 132.9,
      "learning_rate": 0.08671485199483872,
      "loss": 1.0424,
      "step": 82400
    },
    {
      "epoch": 132.94,
      "learning_rate": 0.0867116261916129,
      "loss": 1.0388,
      "step": 82420
    },
    {
      "epoch": 132.97,
      "learning_rate": 0.0867084003883871,
      "loss": 1.0672,
      "step": 82440
    },
    {
      "epoch": 133.0,
      "learning_rate": 0.08670517458516129,
      "loss": 1.0758,
      "step": 82460
    },
    {
      "epoch": 133.0,
      "eval_accuracy": {
        "accuracy": 0.7292951369916478
      },
      "eval_loss": 1.4117149114608765,
      "eval_runtime": 2.8205,
      "eval_samples_per_second": 4542.125,
      "eval_steps_per_second": 71.264,
      "step": 82460
    },
    {
      "epoch": 133.03,
      "learning_rate": 0.08670194878193549,
      "loss": 1.0615,
      "step": 82480
    },
    {
      "epoch": 133.06,
      "learning_rate": 0.08669872297870967,
      "loss": 1.0231,
      "step": 82500
    },
    {
      "epoch": 133.1,
      "learning_rate": 0.08669549717548387,
      "loss": 1.0017,
      "step": 82520
    },
    {
      "epoch": 133.13,
      "learning_rate": 0.08669227137225807,
      "loss": 0.9901,
      "step": 82540
    },
    {
      "epoch": 133.16,
      "learning_rate": 0.08668904556903226,
      "loss": 1.0089,
      "step": 82560
    },
    {
      "epoch": 133.19,
      "learning_rate": 0.08668581976580646,
      "loss": 1.0417,
      "step": 82580
    },
    {
      "epoch": 133.23,
      "learning_rate": 0.08668259396258064,
      "loss": 1.0359,
      "step": 82600
    },
    {
      "epoch": 133.26,
      "learning_rate": 0.08667936815935484,
      "loss": 1.0364,
      "step": 82620
    },
    {
      "epoch": 133.29,
      "learning_rate": 0.08667614235612904,
      "loss": 1.0541,
      "step": 82640
    },
    {
      "epoch": 133.32,
      "learning_rate": 0.08667291655290323,
      "loss": 1.0408,
      "step": 82660
    },
    {
      "epoch": 133.35,
      "learning_rate": 0.08666969074967742,
      "loss": 1.0153,
      "step": 82680
    },
    {
      "epoch": 133.39,
      "learning_rate": 0.08666646494645162,
      "loss": 1.0216,
      "step": 82700
    },
    {
      "epoch": 133.42,
      "learning_rate": 0.08666323914322581,
      "loss": 1.0035,
      "step": 82720
    },
    {
      "epoch": 133.45,
      "learning_rate": 0.08666001334000001,
      "loss": 1.0083,
      "step": 82740
    },
    {
      "epoch": 133.48,
      "learning_rate": 0.0866567875367742,
      "loss": 1.0138,
      "step": 82760
    },
    {
      "epoch": 133.52,
      "learning_rate": 0.08665356173354839,
      "loss": 1.0146,
      "step": 82780
    },
    {
      "epoch": 133.55,
      "learning_rate": 0.08665033593032258,
      "loss": 1.005,
      "step": 82800
    },
    {
      "epoch": 133.58,
      "learning_rate": 0.08664711012709679,
      "loss": 1.0458,
      "step": 82820
    },
    {
      "epoch": 133.61,
      "learning_rate": 0.08664388432387096,
      "loss": 1.0097,
      "step": 82840
    },
    {
      "epoch": 133.65,
      "learning_rate": 0.08664065852064516,
      "loss": 1.0311,
      "step": 82860
    },
    {
      "epoch": 133.68,
      "learning_rate": 0.08663743271741936,
      "loss": 1.0073,
      "step": 82880
    },
    {
      "epoch": 133.71,
      "learning_rate": 0.08663420691419355,
      "loss": 1.0156,
      "step": 82900
    },
    {
      "epoch": 133.74,
      "learning_rate": 0.08663098111096774,
      "loss": 1.0378,
      "step": 82920
    },
    {
      "epoch": 133.77,
      "learning_rate": 0.08662775530774194,
      "loss": 1.0407,
      "step": 82940
    },
    {
      "epoch": 133.81,
      "learning_rate": 0.08662452950451613,
      "loss": 1.0429,
      "step": 82960
    },
    {
      "epoch": 133.84,
      "learning_rate": 0.08662130370129033,
      "loss": 1.0246,
      "step": 82980
    },
    {
      "epoch": 133.87,
      "learning_rate": 0.08661807789806453,
      "loss": 1.0211,
      "step": 83000
    },
    {
      "epoch": 133.9,
      "learning_rate": 0.08661485209483871,
      "loss": 1.0232,
      "step": 83020
    },
    {
      "epoch": 133.94,
      "learning_rate": 0.08661162629161291,
      "loss": 1.0061,
      "step": 83040
    },
    {
      "epoch": 133.97,
      "learning_rate": 0.08660840048838711,
      "loss": 1.0068,
      "step": 83060
    },
    {
      "epoch": 134.0,
      "learning_rate": 0.0866051746851613,
      "loss": 1.0274,
      "step": 83080
    },
    {
      "epoch": 134.0,
      "eval_accuracy": {
        "accuracy": 0.7390523768636328
      },
      "eval_loss": 1.3579856157302856,
      "eval_runtime": 2.6461,
      "eval_samples_per_second": 4841.464,
      "eval_steps_per_second": 75.961,
      "step": 83080
    },
    {
      "epoch": 134.03,
      "learning_rate": 0.08660194888193548,
      "loss": 1.0517,
      "step": 83100
    },
    {
      "epoch": 134.06,
      "learning_rate": 0.0865987230787097,
      "loss": 1.0183,
      "step": 83120
    },
    {
      "epoch": 134.1,
      "learning_rate": 0.08659549727548387,
      "loss": 1.0398,
      "step": 83140
    },
    {
      "epoch": 134.13,
      "learning_rate": 0.08659227147225806,
      "loss": 1.0173,
      "step": 83160
    },
    {
      "epoch": 134.16,
      "learning_rate": 0.08658904566903226,
      "loss": 1.0181,
      "step": 83180
    },
    {
      "epoch": 134.19,
      "learning_rate": 0.08658581986580645,
      "loss": 1.0144,
      "step": 83200
    },
    {
      "epoch": 134.23,
      "learning_rate": 0.08658259406258065,
      "loss": 1.0361,
      "step": 83220
    },
    {
      "epoch": 134.26,
      "learning_rate": 0.08657936825935485,
      "loss": 1.0132,
      "step": 83240
    },
    {
      "epoch": 134.29,
      "learning_rate": 0.08657614245612903,
      "loss": 1.0155,
      "step": 83260
    },
    {
      "epoch": 134.32,
      "learning_rate": 0.08657291665290323,
      "loss": 1.0143,
      "step": 83280
    },
    {
      "epoch": 134.35,
      "learning_rate": 0.08656969084967743,
      "loss": 1.0056,
      "step": 83300
    },
    {
      "epoch": 134.39,
      "learning_rate": 0.08656646504645162,
      "loss": 0.9962,
      "step": 83320
    },
    {
      "epoch": 134.42,
      "learning_rate": 0.08656323924322581,
      "loss": 1.0234,
      "step": 83340
    },
    {
      "epoch": 134.45,
      "learning_rate": 0.08656001344000001,
      "loss": 1.0238,
      "step": 83360
    },
    {
      "epoch": 134.48,
      "learning_rate": 0.0865567876367742,
      "loss": 1.0147,
      "step": 83380
    },
    {
      "epoch": 134.52,
      "learning_rate": 0.08655356183354838,
      "loss": 0.9882,
      "step": 83400
    },
    {
      "epoch": 134.55,
      "learning_rate": 0.0865503360303226,
      "loss": 1.0215,
      "step": 83420
    },
    {
      "epoch": 134.58,
      "learning_rate": 0.08654711022709677,
      "loss": 1.019,
      "step": 83440
    },
    {
      "epoch": 134.61,
      "learning_rate": 0.08654388442387097,
      "loss": 1.0291,
      "step": 83460
    },
    {
      "epoch": 134.65,
      "learning_rate": 0.08654065862064517,
      "loss": 1.0126,
      "step": 83480
    },
    {
      "epoch": 134.68,
      "learning_rate": 0.08653743281741935,
      "loss": 1.0176,
      "step": 83500
    },
    {
      "epoch": 134.71,
      "learning_rate": 0.08653420701419355,
      "loss": 1.0403,
      "step": 83520
    },
    {
      "epoch": 134.74,
      "learning_rate": 0.08653098121096775,
      "loss": 1.0573,
      "step": 83540
    },
    {
      "epoch": 134.77,
      "learning_rate": 0.08652775540774194,
      "loss": 1.0492,
      "step": 83560
    },
    {
      "epoch": 134.81,
      "learning_rate": 0.08652452960451613,
      "loss": 1.0227,
      "step": 83580
    },
    {
      "epoch": 134.84,
      "learning_rate": 0.08652130380129033,
      "loss": 1.0599,
      "step": 83600
    },
    {
      "epoch": 134.87,
      "learning_rate": 0.08651807799806452,
      "loss": 1.0464,
      "step": 83620
    },
    {
      "epoch": 134.9,
      "learning_rate": 0.08651485219483872,
      "loss": 1.0135,
      "step": 83640
    },
    {
      "epoch": 134.94,
      "learning_rate": 0.08651162639161292,
      "loss": 1.0085,
      "step": 83660
    },
    {
      "epoch": 134.97,
      "learning_rate": 0.0865084005883871,
      "loss": 1.0343,
      "step": 83680
    },
    {
      "epoch": 135.0,
      "learning_rate": 0.08650517478516129,
      "loss": 1.0532,
      "step": 83700
    },
    {
      "epoch": 135.0,
      "eval_accuracy": {
        "accuracy": 0.7406915931621263
      },
      "eval_loss": 1.3351417779922485,
      "eval_runtime": 2.8419,
      "eval_samples_per_second": 4507.924,
      "eval_steps_per_second": 70.728,
      "step": 83700
    },
    {
      "epoch": 135.03,
      "learning_rate": 0.0865019489819355,
      "loss": 1.0529,
      "step": 83720
    },
    {
      "epoch": 135.06,
      "learning_rate": 0.08649872317870967,
      "loss": 0.9997,
      "step": 83740
    },
    {
      "epoch": 135.1,
      "learning_rate": 0.08649549737548388,
      "loss": 1.0017,
      "step": 83760
    },
    {
      "epoch": 135.13,
      "learning_rate": 0.08649227157225807,
      "loss": 1.0079,
      "step": 83780
    },
    {
      "epoch": 135.16,
      "learning_rate": 0.08648904576903226,
      "loss": 1.0052,
      "step": 83800
    },
    {
      "epoch": 135.19,
      "learning_rate": 0.08648581996580645,
      "loss": 0.9753,
      "step": 83820
    },
    {
      "epoch": 135.23,
      "learning_rate": 0.08648259416258065,
      "loss": 1.0018,
      "step": 83840
    },
    {
      "epoch": 135.26,
      "learning_rate": 0.08647936835935484,
      "loss": 1.0087,
      "step": 83860
    },
    {
      "epoch": 135.29,
      "learning_rate": 0.08647614255612904,
      "loss": 1.0178,
      "step": 83880
    },
    {
      "epoch": 135.32,
      "learning_rate": 0.08647291675290324,
      "loss": 1.0459,
      "step": 83900
    },
    {
      "epoch": 135.35,
      "learning_rate": 0.08646969094967742,
      "loss": 0.9954,
      "step": 83920
    },
    {
      "epoch": 135.39,
      "learning_rate": 0.08646646514645162,
      "loss": 0.9996,
      "step": 83940
    },
    {
      "epoch": 135.42,
      "learning_rate": 0.08646323934322582,
      "loss": 1.0257,
      "step": 83960
    },
    {
      "epoch": 135.45,
      "learning_rate": 0.08646001354,
      "loss": 1.0145,
      "step": 83980
    },
    {
      "epoch": 135.48,
      "learning_rate": 0.08645678773677419,
      "loss": 1.0346,
      "step": 84000
    },
    {
      "epoch": 135.52,
      "learning_rate": 0.0864535619335484,
      "loss": 1.0349,
      "step": 84020
    },
    {
      "epoch": 135.55,
      "learning_rate": 0.08645033613032257,
      "loss": 0.9996,
      "step": 84040
    },
    {
      "epoch": 135.58,
      "learning_rate": 0.08644711032709679,
      "loss": 0.9917,
      "step": 84060
    },
    {
      "epoch": 135.61,
      "learning_rate": 0.08644388452387097,
      "loss": 1.061,
      "step": 84080
    },
    {
      "epoch": 135.65,
      "learning_rate": 0.08644065872064516,
      "loss": 1.0262,
      "step": 84100
    },
    {
      "epoch": 135.68,
      "learning_rate": 0.08643743291741936,
      "loss": 1.035,
      "step": 84120
    },
    {
      "epoch": 135.71,
      "learning_rate": 0.08643420711419356,
      "loss": 1.0414,
      "step": 84140
    },
    {
      "epoch": 135.74,
      "learning_rate": 0.08643098131096774,
      "loss": 1.0329,
      "step": 84160
    },
    {
      "epoch": 135.77,
      "learning_rate": 0.08642775550774194,
      "loss": 1.0133,
      "step": 84180
    },
    {
      "epoch": 135.81,
      "learning_rate": 0.08642452970451614,
      "loss": 1.0026,
      "step": 84200
    },
    {
      "epoch": 135.84,
      "learning_rate": 0.08642130390129033,
      "loss": 1.0158,
      "step": 84220
    },
    {
      "epoch": 135.87,
      "learning_rate": 0.08641807809806452,
      "loss": 1.0145,
      "step": 84240
    },
    {
      "epoch": 135.9,
      "learning_rate": 0.08641485229483872,
      "loss": 1.0464,
      "step": 84260
    },
    {
      "epoch": 135.94,
      "learning_rate": 0.08641162649161291,
      "loss": 1.0558,
      "step": 84280
    },
    {
      "epoch": 135.97,
      "learning_rate": 0.08640840068838711,
      "loss": 1.0557,
      "step": 84300
    },
    {
      "epoch": 136.0,
      "learning_rate": 0.08640533617532259,
      "loss": 1.0404,
      "step": 84320
    },
    {
      "epoch": 136.0,
      "eval_accuracy": {
        "accuracy": 0.7367886972133323
      },
      "eval_loss": 1.350436806678772,
      "eval_runtime": 2.6305,
      "eval_samples_per_second": 4870.257,
      "eval_steps_per_second": 76.413,
      "step": 84320
    },
    {
      "epoch": 136.03,
      "learning_rate": 0.08640211037209677,
      "loss": 1.0166,
      "step": 84340
    },
    {
      "epoch": 136.06,
      "learning_rate": 0.08639888456887097,
      "loss": 1.0128,
      "step": 84360
    },
    {
      "epoch": 136.1,
      "learning_rate": 0.08639565876564517,
      "loss": 0.9802,
      "step": 84380
    },
    {
      "epoch": 136.13,
      "learning_rate": 0.08639243296241936,
      "loss": 0.958,
      "step": 84400
    },
    {
      "epoch": 136.16,
      "learning_rate": 0.08638920715919356,
      "loss": 0.9846,
      "step": 84420
    },
    {
      "epoch": 136.19,
      "learning_rate": 0.08638598135596776,
      "loss": 0.9502,
      "step": 84440
    },
    {
      "epoch": 136.23,
      "learning_rate": 0.08638275555274194,
      "loss": 1.0081,
      "step": 84460
    },
    {
      "epoch": 136.26,
      "learning_rate": 0.08637952974951613,
      "loss": 0.9945,
      "step": 84480
    },
    {
      "epoch": 136.29,
      "learning_rate": 0.08637630394629034,
      "loss": 1.002,
      "step": 84500
    },
    {
      "epoch": 136.32,
      "learning_rate": 0.08637307814306451,
      "loss": 1.0036,
      "step": 84520
    },
    {
      "epoch": 136.35,
      "learning_rate": 0.08636985233983871,
      "loss": 1.0031,
      "step": 84540
    },
    {
      "epoch": 136.39,
      "learning_rate": 0.08636662653661291,
      "loss": 0.9975,
      "step": 84560
    },
    {
      "epoch": 136.42,
      "learning_rate": 0.0863634007333871,
      "loss": 1.0347,
      "step": 84580
    },
    {
      "epoch": 136.45,
      "learning_rate": 0.0863601749301613,
      "loss": 1.0226,
      "step": 84600
    },
    {
      "epoch": 136.48,
      "learning_rate": 0.08635694912693549,
      "loss": 1.0015,
      "step": 84620
    },
    {
      "epoch": 136.52,
      "learning_rate": 0.08635372332370968,
      "loss": 1.0165,
      "step": 84640
    },
    {
      "epoch": 136.55,
      "learning_rate": 0.08635049752048388,
      "loss": 1.0036,
      "step": 84660
    },
    {
      "epoch": 136.58,
      "learning_rate": 0.08634727171725808,
      "loss": 0.9783,
      "step": 84680
    },
    {
      "epoch": 136.61,
      "learning_rate": 0.08634404591403226,
      "loss": 1.011,
      "step": 84700
    },
    {
      "epoch": 136.65,
      "learning_rate": 0.08634082011080646,
      "loss": 1.0005,
      "step": 84720
    },
    {
      "epoch": 136.68,
      "learning_rate": 0.08633759430758066,
      "loss": 1.0228,
      "step": 84740
    },
    {
      "epoch": 136.71,
      "learning_rate": 0.08633436850435484,
      "loss": 1.0262,
      "step": 84760
    },
    {
      "epoch": 136.74,
      "learning_rate": 0.08633114270112903,
      "loss": 1.0419,
      "step": 84780
    },
    {
      "epoch": 136.77,
      "learning_rate": 0.08632791689790324,
      "loss": 1.0401,
      "step": 84800
    },
    {
      "epoch": 136.81,
      "learning_rate": 0.08632469109467741,
      "loss": 1.0526,
      "step": 84820
    },
    {
      "epoch": 136.84,
      "learning_rate": 0.08632146529145161,
      "loss": 1.0193,
      "step": 84840
    },
    {
      "epoch": 136.87,
      "learning_rate": 0.08631823948822581,
      "loss": 1.0233,
      "step": 84860
    },
    {
      "epoch": 136.9,
      "learning_rate": 0.086315013685,
      "loss": 1.0311,
      "step": 84880
    },
    {
      "epoch": 136.94,
      "learning_rate": 0.0863117878817742,
      "loss": 1.0346,
      "step": 84900
    },
    {
      "epoch": 136.97,
      "learning_rate": 0.0863085620785484,
      "loss": 1.0316,
      "step": 84920
    },
    {
      "epoch": 137.0,
      "learning_rate": 0.08630533627532258,
      "loss": 1.0227,
      "step": 84940
    },
    {
      "epoch": 137.0,
      "eval_accuracy": {
        "accuracy": 0.7386620872687534
      },
      "eval_loss": 1.3513740301132202,
      "eval_runtime": 2.7692,
      "eval_samples_per_second": 4626.17,
      "eval_steps_per_second": 72.583,
      "step": 84940
    },
    {
      "epoch": 137.03,
      "learning_rate": 0.08630211047209678,
      "loss": 1.046,
      "step": 84960
    },
    {
      "epoch": 137.06,
      "learning_rate": 0.08629888466887098,
      "loss": 1.0137,
      "step": 84980
    },
    {
      "epoch": 137.1,
      "learning_rate": 0.08629565886564516,
      "loss": 1.0373,
      "step": 85000
    },
    {
      "epoch": 137.13,
      "learning_rate": 0.08629243306241936,
      "loss": 1.0222,
      "step": 85020
    },
    {
      "epoch": 137.16,
      "learning_rate": 0.08628920725919356,
      "loss": 0.9843,
      "step": 85040
    },
    {
      "epoch": 137.19,
      "learning_rate": 0.08628598145596775,
      "loss": 1.0051,
      "step": 85060
    },
    {
      "epoch": 137.23,
      "learning_rate": 0.08628275565274193,
      "loss": 0.9894,
      "step": 85080
    },
    {
      "epoch": 137.26,
      "learning_rate": 0.08627952984951615,
      "loss": 1.0088,
      "step": 85100
    },
    {
      "epoch": 137.29,
      "learning_rate": 0.08627630404629032,
      "loss": 1.0186,
      "step": 85120
    },
    {
      "epoch": 137.32,
      "learning_rate": 0.08627307824306453,
      "loss": 1.0225,
      "step": 85140
    },
    {
      "epoch": 137.35,
      "learning_rate": 0.08626985243983872,
      "loss": 0.99,
      "step": 85160
    },
    {
      "epoch": 137.39,
      "learning_rate": 0.0862666266366129,
      "loss": 1.0016,
      "step": 85180
    },
    {
      "epoch": 137.42,
      "learning_rate": 0.0862634008333871,
      "loss": 1.0113,
      "step": 85200
    },
    {
      "epoch": 137.45,
      "learning_rate": 0.0862601750301613,
      "loss": 1.0175,
      "step": 85220
    },
    {
      "epoch": 137.48,
      "learning_rate": 0.08625694922693548,
      "loss": 1.0317,
      "step": 85240
    },
    {
      "epoch": 137.52,
      "learning_rate": 0.08625372342370968,
      "loss": 1.0049,
      "step": 85260
    },
    {
      "epoch": 137.55,
      "learning_rate": 0.08625049762048388,
      "loss": 1.0195,
      "step": 85280
    },
    {
      "epoch": 137.58,
      "learning_rate": 0.08624727181725807,
      "loss": 1.0266,
      "step": 85300
    },
    {
      "epoch": 137.61,
      "learning_rate": 0.08624404601403227,
      "loss": 1.0105,
      "step": 85320
    },
    {
      "epoch": 137.65,
      "learning_rate": 0.08624082021080647,
      "loss": 1.0188,
      "step": 85340
    },
    {
      "epoch": 137.68,
      "learning_rate": 0.08623759440758065,
      "loss": 0.9976,
      "step": 85360
    },
    {
      "epoch": 137.71,
      "learning_rate": 0.08623436860435485,
      "loss": 1.0366,
      "step": 85380
    },
    {
      "epoch": 137.74,
      "learning_rate": 0.08623114280112905,
      "loss": 1.0444,
      "step": 85400
    },
    {
      "epoch": 137.77,
      "learning_rate": 0.08622791699790322,
      "loss": 1.0455,
      "step": 85420
    },
    {
      "epoch": 137.81,
      "learning_rate": 0.08622469119467743,
      "loss": 1.0498,
      "step": 85440
    },
    {
      "epoch": 137.84,
      "learning_rate": 0.08622146539145162,
      "loss": 1.0298,
      "step": 85460
    },
    {
      "epoch": 137.87,
      "learning_rate": 0.0862182395882258,
      "loss": 1.0445,
      "step": 85480
    },
    {
      "epoch": 137.9,
      "learning_rate": 0.086215013785,
      "loss": 1.0301,
      "step": 85500
    },
    {
      "epoch": 137.94,
      "learning_rate": 0.0862117879817742,
      "loss": 0.9941,
      "step": 85520
    },
    {
      "epoch": 137.97,
      "learning_rate": 0.08620856217854839,
      "loss": 1.0372,
      "step": 85540
    },
    {
      "epoch": 138.0,
      "learning_rate": 0.08620533637532259,
      "loss": 0.9786,
      "step": 85560
    },
    {
      "epoch": 138.0,
      "eval_accuracy": {
        "accuracy": 0.7328858012645383
      },
      "eval_loss": 1.3938575983047485,
      "eval_runtime": 2.981,
      "eval_samples_per_second": 4297.509,
      "eval_steps_per_second": 67.426,
      "step": 85560
    },
    {
      "epoch": 138.03,
      "learning_rate": 0.08620211057209679,
      "loss": 1.0726,
      "step": 85580
    },
    {
      "epoch": 138.06,
      "learning_rate": 0.08619888476887097,
      "loss": 0.994,
      "step": 85600
    },
    {
      "epoch": 138.1,
      "learning_rate": 0.08619565896564517,
      "loss": 1.013,
      "step": 85620
    },
    {
      "epoch": 138.13,
      "learning_rate": 0.08619243316241937,
      "loss": 0.9879,
      "step": 85640
    },
    {
      "epoch": 138.16,
      "learning_rate": 0.08618920735919355,
      "loss": 0.9717,
      "step": 85660
    },
    {
      "epoch": 138.19,
      "learning_rate": 0.08618598155596775,
      "loss": 0.9654,
      "step": 85680
    },
    {
      "epoch": 138.23,
      "learning_rate": 0.08618275575274195,
      "loss": 1.0076,
      "step": 85700
    },
    {
      "epoch": 138.26,
      "learning_rate": 0.08617952994951612,
      "loss": 1.0019,
      "step": 85720
    },
    {
      "epoch": 138.29,
      "learning_rate": 0.08617630414629034,
      "loss": 1.0143,
      "step": 85740
    },
    {
      "epoch": 138.32,
      "learning_rate": 0.08617307834306452,
      "loss": 0.9967,
      "step": 85760
    },
    {
      "epoch": 138.35,
      "learning_rate": 0.0861698525398387,
      "loss": 1.0201,
      "step": 85780
    },
    {
      "epoch": 138.39,
      "learning_rate": 0.0861666267366129,
      "loss": 1.0332,
      "step": 85800
    },
    {
      "epoch": 138.42,
      "learning_rate": 0.0861634009333871,
      "loss": 1.0468,
      "step": 85820
    },
    {
      "epoch": 138.45,
      "learning_rate": 0.08616017513016129,
      "loss": 1.0096,
      "step": 85840
    },
    {
      "epoch": 138.48,
      "learning_rate": 0.08615694932693549,
      "loss": 1.006,
      "step": 85860
    },
    {
      "epoch": 138.52,
      "learning_rate": 0.08615372352370969,
      "loss": 1.0341,
      "step": 85880
    },
    {
      "epoch": 138.55,
      "learning_rate": 0.08615049772048387,
      "loss": 1.0315,
      "step": 85900
    },
    {
      "epoch": 138.58,
      "learning_rate": 0.08614727191725807,
      "loss": 1.0507,
      "step": 85920
    },
    {
      "epoch": 138.61,
      "learning_rate": 0.08614404611403227,
      "loss": 1.0387,
      "step": 85940
    },
    {
      "epoch": 138.65,
      "learning_rate": 0.08614082031080646,
      "loss": 1.0411,
      "step": 85960
    },
    {
      "epoch": 138.68,
      "learning_rate": 0.08613759450758066,
      "loss": 1.0424,
      "step": 85980
    },
    {
      "epoch": 138.71,
      "learning_rate": 0.08613436870435484,
      "loss": 1.0264,
      "step": 86000
    },
    {
      "epoch": 138.74,
      "learning_rate": 0.08613114290112903,
      "loss": 1.018,
      "step": 86020
    },
    {
      "epoch": 138.77,
      "learning_rate": 0.08612791709790324,
      "loss": 1.048,
      "step": 86040
    },
    {
      "epoch": 138.81,
      "learning_rate": 0.08612469129467742,
      "loss": 1.0142,
      "step": 86060
    },
    {
      "epoch": 138.84,
      "learning_rate": 0.08612146549145162,
      "loss": 1.0023,
      "step": 86080
    },
    {
      "epoch": 138.87,
      "learning_rate": 0.08611823968822581,
      "loss": 0.9895,
      "step": 86100
    },
    {
      "epoch": 138.9,
      "learning_rate": 0.08611501388500001,
      "loss": 1.0064,
      "step": 86120
    },
    {
      "epoch": 138.94,
      "learning_rate": 0.0861117880817742,
      "loss": 1.0283,
      "step": 86140
    },
    {
      "epoch": 138.97,
      "learning_rate": 0.08610856227854839,
      "loss": 1.0124,
      "step": 86160
    },
    {
      "epoch": 139.0,
      "learning_rate": 0.08610533647532259,
      "loss": 1.0072,
      "step": 86180
    },
    {
      "epoch": 139.0,
      "eval_accuracy": {
        "accuracy": 0.7300757161814067
      },
      "eval_loss": 1.4098458290100098,
      "eval_runtime": 4.7853,
      "eval_samples_per_second": 2677.14,
      "eval_steps_per_second": 42.003,
      "step": 86180
    },
    {
      "epoch": 139.03,
      "learning_rate": 0.08610211067209678,
      "loss": 1.0511,
      "step": 86200
    },
    {
      "epoch": 139.06,
      "learning_rate": 0.08609888486887098,
      "loss": 1.0137,
      "step": 86220
    },
    {
      "epoch": 139.1,
      "learning_rate": 0.08609565906564517,
      "loss": 0.9903,
      "step": 86240
    },
    {
      "epoch": 139.13,
      "learning_rate": 0.08609243326241936,
      "loss": 0.9935,
      "step": 86260
    },
    {
      "epoch": 139.16,
      "learning_rate": 0.08608920745919356,
      "loss": 1.0233,
      "step": 86280
    },
    {
      "epoch": 139.19,
      "learning_rate": 0.08608598165596774,
      "loss": 1.0333,
      "step": 86300
    },
    {
      "epoch": 139.23,
      "learning_rate": 0.08608275585274193,
      "loss": 1.0441,
      "step": 86320
    },
    {
      "epoch": 139.26,
      "learning_rate": 0.08607953004951614,
      "loss": 1.0268,
      "step": 86340
    },
    {
      "epoch": 139.29,
      "learning_rate": 0.08607630424629033,
      "loss": 1.0012,
      "step": 86360
    },
    {
      "epoch": 139.32,
      "learning_rate": 0.08607307844306453,
      "loss": 1.0507,
      "step": 86380
    },
    {
      "epoch": 139.35,
      "learning_rate": 0.08606985263983871,
      "loss": 1.0196,
      "step": 86400
    },
    {
      "epoch": 139.39,
      "learning_rate": 0.08606662683661291,
      "loss": 1.0216,
      "step": 86420
    },
    {
      "epoch": 139.42,
      "learning_rate": 0.0860634010333871,
      "loss": 1.0054,
      "step": 86440
    },
    {
      "epoch": 139.45,
      "learning_rate": 0.0860601752301613,
      "loss": 1.0133,
      "step": 86460
    },
    {
      "epoch": 139.48,
      "learning_rate": 0.0860569494269355,
      "loss": 1.027,
      "step": 86480
    },
    {
      "epoch": 139.52,
      "learning_rate": 0.08605372362370968,
      "loss": 1.0098,
      "step": 86500
    },
    {
      "epoch": 139.55,
      "learning_rate": 0.08605049782048388,
      "loss": 1.0128,
      "step": 86520
    },
    {
      "epoch": 139.58,
      "learning_rate": 0.08604727201725806,
      "loss": 0.9735,
      "step": 86540
    },
    {
      "epoch": 139.61,
      "learning_rate": 0.08604404621403226,
      "loss": 1.0327,
      "step": 86560
    },
    {
      "epoch": 139.65,
      "learning_rate": 0.08604082041080646,
      "loss": 1.0346,
      "step": 86580
    },
    {
      "epoch": 139.68,
      "learning_rate": 0.08603759460758065,
      "loss": 1.0311,
      "step": 86600
    },
    {
      "epoch": 139.71,
      "learning_rate": 0.08603436880435485,
      "loss": 1.0294,
      "step": 86620
    },
    {
      "epoch": 139.74,
      "learning_rate": 0.08603114300112905,
      "loss": 1.0595,
      "step": 86640
    },
    {
      "epoch": 139.77,
      "learning_rate": 0.08602791719790323,
      "loss": 1.0034,
      "step": 86660
    },
    {
      "epoch": 139.81,
      "learning_rate": 0.08602469139467743,
      "loss": 1.0517,
      "step": 86680
    },
    {
      "epoch": 139.84,
      "learning_rate": 0.08602146559145162,
      "loss": 1.0672,
      "step": 86700
    },
    {
      "epoch": 139.87,
      "learning_rate": 0.08601823978822581,
      "loss": 1.0645,
      "step": 86720
    },
    {
      "epoch": 139.9,
      "learning_rate": 0.086015013985,
      "loss": 1.0171,
      "step": 86740
    },
    {
      "epoch": 139.94,
      "learning_rate": 0.0860117881817742,
      "loss": 1.0066,
      "step": 86760
    },
    {
      "epoch": 139.97,
      "learning_rate": 0.08600856237854838,
      "loss": 1.0306,
      "step": 86780
    },
    {
      "epoch": 140.0,
      "learning_rate": 0.08600549786548387,
      "loss": 1.0014,
      "step": 86800
    },
    {
      "epoch": 140.0,
      "eval_accuracy": {
        "accuracy": 0.7449847787057997
      },
      "eval_loss": 1.2917360067367554,
      "eval_runtime": 2.6977,
      "eval_samples_per_second": 4748.934,
      "eval_steps_per_second": 74.509,
      "step": 86800
    },
    {
      "epoch": 140.03,
      "learning_rate": 0.08600227206225808,
      "loss": 1.0014,
      "step": 86820
    },
    {
      "epoch": 140.06,
      "learning_rate": 0.08599904625903226,
      "loss": 1.0087,
      "step": 86840
    },
    {
      "epoch": 140.1,
      "learning_rate": 0.08599582045580645,
      "loss": 0.9997,
      "step": 86860
    },
    {
      "epoch": 140.13,
      "learning_rate": 0.08599259465258065,
      "loss": 0.9983,
      "step": 86880
    },
    {
      "epoch": 140.16,
      "learning_rate": 0.08598936884935485,
      "loss": 0.9989,
      "step": 86900
    },
    {
      "epoch": 140.19,
      "learning_rate": 0.08598614304612903,
      "loss": 1.0097,
      "step": 86920
    },
    {
      "epoch": 140.23,
      "learning_rate": 0.08598291724290323,
      "loss": 0.9877,
      "step": 86940
    },
    {
      "epoch": 140.26,
      "learning_rate": 0.08597969143967743,
      "loss": 1.0229,
      "step": 86960
    },
    {
      "epoch": 140.29,
      "learning_rate": 0.08597646563645162,
      "loss": 0.9878,
      "step": 86980
    },
    {
      "epoch": 140.32,
      "learning_rate": 0.08597323983322581,
      "loss": 0.9627,
      "step": 87000
    },
    {
      "epoch": 140.35,
      "learning_rate": 0.08597001403000001,
      "loss": 0.9708,
      "step": 87020
    },
    {
      "epoch": 140.39,
      "learning_rate": 0.0859667882267742,
      "loss": 0.9985,
      "step": 87040
    },
    {
      "epoch": 140.42,
      "learning_rate": 0.0859635624235484,
      "loss": 1.0052,
      "step": 87060
    },
    {
      "epoch": 140.45,
      "learning_rate": 0.08596033662032258,
      "loss": 1.0326,
      "step": 87080
    },
    {
      "epoch": 140.48,
      "learning_rate": 0.08595711081709677,
      "loss": 1.0006,
      "step": 87100
    },
    {
      "epoch": 140.52,
      "learning_rate": 0.08595388501387098,
      "loss": 1.0003,
      "step": 87120
    },
    {
      "epoch": 140.55,
      "learning_rate": 0.08595065921064517,
      "loss": 0.9927,
      "step": 87140
    },
    {
      "epoch": 140.58,
      "learning_rate": 0.08594743340741935,
      "loss": 1.0067,
      "step": 87160
    },
    {
      "epoch": 140.61,
      "learning_rate": 0.08594420760419355,
      "loss": 1.0018,
      "step": 87180
    },
    {
      "epoch": 140.65,
      "learning_rate": 0.08594098180096775,
      "loss": 1.0091,
      "step": 87200
    },
    {
      "epoch": 140.68,
      "learning_rate": 0.08593775599774194,
      "loss": 1.0347,
      "step": 87220
    },
    {
      "epoch": 140.71,
      "learning_rate": 0.08593453019451613,
      "loss": 1.0308,
      "step": 87240
    },
    {
      "epoch": 140.74,
      "learning_rate": 0.08593130439129033,
      "loss": 1.0145,
      "step": 87260
    },
    {
      "epoch": 140.77,
      "learning_rate": 0.08592807858806452,
      "loss": 1.0502,
      "step": 87280
    },
    {
      "epoch": 140.81,
      "learning_rate": 0.08592485278483872,
      "loss": 1.0216,
      "step": 87300
    },
    {
      "epoch": 140.84,
      "learning_rate": 0.08592162698161292,
      "loss": 1.0051,
      "step": 87320
    },
    {
      "epoch": 140.87,
      "learning_rate": 0.0859184011783871,
      "loss": 0.9914,
      "step": 87340
    },
    {
      "epoch": 140.9,
      "learning_rate": 0.0859151753751613,
      "loss": 0.9941,
      "step": 87360
    },
    {
      "epoch": 140.94,
      "learning_rate": 0.08591194957193549,
      "loss": 1.0333,
      "step": 87380
    },
    {
      "epoch": 140.97,
      "learning_rate": 0.08590872376870967,
      "loss": 1.0278,
      "step": 87400
    },
    {
      "epoch": 141.0,
      "learning_rate": 0.08590549796548388,
      "loss": 1.0183,
      "step": 87420
    },
    {
      "epoch": 141.0,
      "eval_accuracy": {
        "accuracy": 0.7366325813753806
      },
      "eval_loss": 1.389380931854248,
      "eval_runtime": 2.9357,
      "eval_samples_per_second": 4363.877,
      "eval_steps_per_second": 68.468,
      "step": 87420
    },
    {
      "epoch": 141.03,
      "learning_rate": 0.08590227216225807,
      "loss": 1.0727,
      "step": 87440
    },
    {
      "epoch": 141.06,
      "learning_rate": 0.08589904635903227,
      "loss": 0.9758,
      "step": 87460
    },
    {
      "epoch": 141.1,
      "learning_rate": 0.08589582055580645,
      "loss": 1.0216,
      "step": 87480
    },
    {
      "epoch": 141.13,
      "learning_rate": 0.08589259475258065,
      "loss": 1.0205,
      "step": 87500
    },
    {
      "epoch": 141.16,
      "learning_rate": 0.08588936894935484,
      "loss": 0.9867,
      "step": 87520
    },
    {
      "epoch": 141.19,
      "learning_rate": 0.08588614314612904,
      "loss": 0.9948,
      "step": 87540
    },
    {
      "epoch": 141.23,
      "learning_rate": 0.08588291734290324,
      "loss": 0.981,
      "step": 87560
    },
    {
      "epoch": 141.26,
      "learning_rate": 0.08587969153967742,
      "loss": 0.9828,
      "step": 87580
    },
    {
      "epoch": 141.29,
      "learning_rate": 0.08587646573645162,
      "loss": 1.0033,
      "step": 87600
    },
    {
      "epoch": 141.32,
      "learning_rate": 0.0858732399332258,
      "loss": 1.0442,
      "step": 87620
    },
    {
      "epoch": 141.35,
      "learning_rate": 0.08587001413,
      "loss": 1.0073,
      "step": 87640
    },
    {
      "epoch": 141.39,
      "learning_rate": 0.0858667883267742,
      "loss": 1.0247,
      "step": 87660
    },
    {
      "epoch": 141.42,
      "learning_rate": 0.08586356252354839,
      "loss": 1.0398,
      "step": 87680
    },
    {
      "epoch": 141.45,
      "learning_rate": 0.08586033672032259,
      "loss": 1.0303,
      "step": 87700
    },
    {
      "epoch": 141.48,
      "learning_rate": 0.08585711091709679,
      "loss": 0.997,
      "step": 87720
    },
    {
      "epoch": 141.52,
      "learning_rate": 0.08585388511387097,
      "loss": 1.0074,
      "step": 87740
    },
    {
      "epoch": 141.55,
      "learning_rate": 0.08585065931064517,
      "loss": 1.0361,
      "step": 87760
    },
    {
      "epoch": 141.58,
      "learning_rate": 0.08584743350741936,
      "loss": 1.0332,
      "step": 87780
    },
    {
      "epoch": 141.61,
      "learning_rate": 0.08584420770419356,
      "loss": 1.0181,
      "step": 87800
    },
    {
      "epoch": 141.65,
      "learning_rate": 0.08584098190096774,
      "loss": 1.0063,
      "step": 87820
    },
    {
      "epoch": 141.68,
      "learning_rate": 0.08583775609774194,
      "loss": 1.0157,
      "step": 87840
    },
    {
      "epoch": 141.71,
      "learning_rate": 0.08583453029451613,
      "loss": 0.9939,
      "step": 87860
    },
    {
      "epoch": 141.74,
      "learning_rate": 0.08583130449129033,
      "loss": 0.9993,
      "step": 87880
    },
    {
      "epoch": 141.77,
      "learning_rate": 0.08582807868806452,
      "loss": 1.0264,
      "step": 87900
    },
    {
      "epoch": 141.81,
      "learning_rate": 0.08582485288483871,
      "loss": 1.0298,
      "step": 87920
    },
    {
      "epoch": 141.84,
      "learning_rate": 0.08582162708161291,
      "loss": 1.0434,
      "step": 87940
    },
    {
      "epoch": 141.87,
      "learning_rate": 0.08581840127838711,
      "loss": 1.0325,
      "step": 87960
    },
    {
      "epoch": 141.9,
      "learning_rate": 0.08581517547516129,
      "loss": 1.0497,
      "step": 87980
    },
    {
      "epoch": 141.94,
      "learning_rate": 0.08581194967193549,
      "loss": 1.0356,
      "step": 88000
    },
    {
      "epoch": 141.97,
      "learning_rate": 0.08580872386870969,
      "loss": 1.0427,
      "step": 88020
    },
    {
      "epoch": 142.0,
      "learning_rate": 0.08580549806548388,
      "loss": 1.0319,
      "step": 88040
    },
    {
      "epoch": 142.0,
      "eval_accuracy": {
        "accuracy": 0.740925766919054
      },
      "eval_loss": 1.3445875644683838,
      "eval_runtime": 3.6522,
      "eval_samples_per_second": 3507.717,
      "eval_steps_per_second": 55.035,
      "step": 88040
    },
    {
      "epoch": 142.03,
      "learning_rate": 0.08580227226225808,
      "loss": 1.03,
      "step": 88060
    },
    {
      "epoch": 142.06,
      "learning_rate": 0.08579904645903226,
      "loss": 1.0412,
      "step": 88080
    },
    {
      "epoch": 142.1,
      "learning_rate": 0.08579582065580646,
      "loss": 1.0298,
      "step": 88100
    },
    {
      "epoch": 142.13,
      "learning_rate": 0.08579259485258064,
      "loss": 1.022,
      "step": 88120
    },
    {
      "epoch": 142.16,
      "learning_rate": 0.08578936904935484,
      "loss": 0.995,
      "step": 88140
    },
    {
      "epoch": 142.19,
      "learning_rate": 0.08578614324612903,
      "loss": 1.0064,
      "step": 88160
    },
    {
      "epoch": 142.23,
      "learning_rate": 0.08578291744290323,
      "loss": 0.9901,
      "step": 88180
    },
    {
      "epoch": 142.26,
      "learning_rate": 0.08577969163967743,
      "loss": 0.9938,
      "step": 88200
    },
    {
      "epoch": 142.29,
      "learning_rate": 0.08577646583645161,
      "loss": 0.9877,
      "step": 88220
    },
    {
      "epoch": 142.32,
      "learning_rate": 0.08577324003322581,
      "loss": 1.0163,
      "step": 88240
    },
    {
      "epoch": 142.35,
      "learning_rate": 0.08577001423000001,
      "loss": 1.0,
      "step": 88260
    },
    {
      "epoch": 142.39,
      "learning_rate": 0.0857667884267742,
      "loss": 1.0282,
      "step": 88280
    },
    {
      "epoch": 142.42,
      "learning_rate": 0.0857635626235484,
      "loss": 1.0143,
      "step": 88300
    },
    {
      "epoch": 142.45,
      "learning_rate": 0.0857603368203226,
      "loss": 1.0008,
      "step": 88320
    },
    {
      "epoch": 142.48,
      "learning_rate": 0.08575711101709678,
      "loss": 0.9915,
      "step": 88340
    },
    {
      "epoch": 142.52,
      "learning_rate": 0.08575388521387098,
      "loss": 1.042,
      "step": 88360
    },
    {
      "epoch": 142.55,
      "learning_rate": 0.08575065941064516,
      "loss": 1.0364,
      "step": 88380
    },
    {
      "epoch": 142.58,
      "learning_rate": 0.08574743360741936,
      "loss": 1.0092,
      "step": 88400
    },
    {
      "epoch": 142.61,
      "learning_rate": 0.08574420780419355,
      "loss": 0.9909,
      "step": 88420
    },
    {
      "epoch": 142.65,
      "learning_rate": 0.08574098200096775,
      "loss": 1.0157,
      "step": 88440
    },
    {
      "epoch": 142.68,
      "learning_rate": 0.08573775619774193,
      "loss": 1.0104,
      "step": 88460
    },
    {
      "epoch": 142.71,
      "learning_rate": 0.08573453039451613,
      "loss": 1.0248,
      "step": 88480
    },
    {
      "epoch": 142.74,
      "learning_rate": 0.08573130459129033,
      "loss": 1.0223,
      "step": 88500
    },
    {
      "epoch": 142.77,
      "learning_rate": 0.08572807878806452,
      "loss": 0.9991,
      "step": 88520
    },
    {
      "epoch": 142.81,
      "learning_rate": 0.08572485298483871,
      "loss": 0.9985,
      "step": 88540
    },
    {
      "epoch": 142.84,
      "learning_rate": 0.08572162718161291,
      "loss": 1.0355,
      "step": 88560
    },
    {
      "epoch": 142.87,
      "learning_rate": 0.0857184013783871,
      "loss": 1.033,
      "step": 88580
    },
    {
      "epoch": 142.9,
      "learning_rate": 0.0857151755751613,
      "loss": 1.0296,
      "step": 88600
    },
    {
      "epoch": 142.94,
      "learning_rate": 0.0857119497719355,
      "loss": 1.0442,
      "step": 88620
    },
    {
      "epoch": 142.97,
      "learning_rate": 0.08570872396870968,
      "loss": 1.0136,
      "step": 88640
    },
    {
      "epoch": 143.0,
      "learning_rate": 0.08570549816548388,
      "loss": 1.014,
      "step": 88660
    },
    {
      "epoch": 143.0,
      "eval_accuracy": {
        "accuracy": 0.7338224962922488
      },
      "eval_loss": 1.3534914255142212,
      "eval_runtime": 2.7719,
      "eval_samples_per_second": 4621.736,
      "eval_steps_per_second": 72.513,
      "step": 88660
    },
    {
      "epoch": 143.03,
      "learning_rate": 0.08570227236225807,
      "loss": 1.0329,
      "step": 88680
    },
    {
      "epoch": 143.06,
      "learning_rate": 0.08569904655903227,
      "loss": 0.9986,
      "step": 88700
    },
    {
      "epoch": 143.1,
      "learning_rate": 0.08569582075580645,
      "loss": 1.0197,
      "step": 88720
    },
    {
      "epoch": 143.13,
      "learning_rate": 0.08569259495258065,
      "loss": 1.0194,
      "step": 88740
    },
    {
      "epoch": 143.16,
      "learning_rate": 0.08568936914935484,
      "loss": 0.9927,
      "step": 88760
    },
    {
      "epoch": 143.19,
      "learning_rate": 0.08568614334612903,
      "loss": 0.9849,
      "step": 88780
    },
    {
      "epoch": 143.23,
      "learning_rate": 0.08568291754290323,
      "loss": 0.9781,
      "step": 88800
    },
    {
      "epoch": 143.26,
      "learning_rate": 0.08567969173967742,
      "loss": 1.0016,
      "step": 88820
    },
    {
      "epoch": 143.29,
      "learning_rate": 0.08567662722661291,
      "loss": 1.0103,
      "step": 88840
    },
    {
      "epoch": 143.32,
      "learning_rate": 0.0856734014233871,
      "loss": 0.9964,
      "step": 88860
    },
    {
      "epoch": 143.35,
      "learning_rate": 0.0856701756201613,
      "loss": 0.9943,
      "step": 88880
    },
    {
      "epoch": 143.39,
      "learning_rate": 0.08566694981693548,
      "loss": 0.969,
      "step": 88900
    },
    {
      "epoch": 143.42,
      "learning_rate": 0.08566372401370968,
      "loss": 0.9875,
      "step": 88920
    },
    {
      "epoch": 143.45,
      "learning_rate": 0.08566049821048387,
      "loss": 0.9991,
      "step": 88940
    },
    {
      "epoch": 143.48,
      "learning_rate": 0.08565727240725807,
      "loss": 1.0218,
      "step": 88960
    },
    {
      "epoch": 143.52,
      "learning_rate": 0.08565404660403227,
      "loss": 1.0269,
      "step": 88980
    },
    {
      "epoch": 143.55,
      "learning_rate": 0.08565082080080645,
      "loss": 1.0141,
      "step": 89000
    },
    {
      "epoch": 143.58,
      "learning_rate": 0.08564759499758065,
      "loss": 1.0168,
      "step": 89020
    },
    {
      "epoch": 143.61,
      "learning_rate": 0.08564436919435485,
      "loss": 1.0325,
      "step": 89040
    },
    {
      "epoch": 143.65,
      "learning_rate": 0.08564114339112903,
      "loss": 1.0036,
      "step": 89060
    },
    {
      "epoch": 143.68,
      "learning_rate": 0.08563791758790323,
      "loss": 1.0354,
      "step": 89080
    },
    {
      "epoch": 143.71,
      "learning_rate": 0.08563469178467743,
      "loss": 0.975,
      "step": 89100
    },
    {
      "epoch": 143.74,
      "learning_rate": 0.08563146598145162,
      "loss": 0.9819,
      "step": 89120
    },
    {
      "epoch": 143.77,
      "learning_rate": 0.08562824017822582,
      "loss": 0.9978,
      "step": 89140
    },
    {
      "epoch": 143.81,
      "learning_rate": 0.085625014375,
      "loss": 1.0171,
      "step": 89160
    },
    {
      "epoch": 143.84,
      "learning_rate": 0.0856217885717742,
      "loss": 1.0179,
      "step": 89180
    },
    {
      "epoch": 143.87,
      "learning_rate": 0.08561856276854839,
      "loss": 1.005,
      "step": 89200
    },
    {
      "epoch": 143.9,
      "learning_rate": 0.08561533696532259,
      "loss": 1.0332,
      "step": 89220
    },
    {
      "epoch": 143.94,
      "learning_rate": 0.08561211116209677,
      "loss": 0.9959,
      "step": 89240
    },
    {
      "epoch": 143.97,
      "learning_rate": 0.08560888535887097,
      "loss": 1.0181,
      "step": 89260
    },
    {
      "epoch": 144.0,
      "learning_rate": 0.08560565955564517,
      "loss": 1.0441,
      "step": 89280
    },
    {
      "epoch": 144.0,
      "eval_accuracy": {
        "accuracy": 0.7322613379127313
      },
      "eval_loss": 1.3813492059707642,
      "eval_runtime": 2.6811,
      "eval_samples_per_second": 4778.268,
      "eval_steps_per_second": 74.969,
      "step": 89280
    },
    {
      "epoch": 144.03,
      "learning_rate": 0.08560243375241935,
      "loss": 1.0397,
      "step": 89300
    },
    {
      "epoch": 144.06,
      "learning_rate": 0.08559920794919355,
      "loss": 0.9734,
      "step": 89320
    },
    {
      "epoch": 144.1,
      "learning_rate": 0.08559598214596775,
      "loss": 0.9866,
      "step": 89340
    },
    {
      "epoch": 144.13,
      "learning_rate": 0.08559275634274194,
      "loss": 0.9706,
      "step": 89360
    },
    {
      "epoch": 144.16,
      "learning_rate": 0.08558953053951614,
      "loss": 1.0327,
      "step": 89380
    },
    {
      "epoch": 144.19,
      "learning_rate": 0.08558630473629034,
      "loss": 0.9989,
      "step": 89400
    },
    {
      "epoch": 144.23,
      "learning_rate": 0.08558307893306452,
      "loss": 1.0183,
      "step": 89420
    },
    {
      "epoch": 144.26,
      "learning_rate": 0.08557985312983872,
      "loss": 1.0236,
      "step": 89440
    },
    {
      "epoch": 144.29,
      "learning_rate": 0.0855766273266129,
      "loss": 1.0075,
      "step": 89460
    },
    {
      "epoch": 144.32,
      "learning_rate": 0.08557340152338709,
      "loss": 1.0202,
      "step": 89480
    },
    {
      "epoch": 144.35,
      "learning_rate": 0.08557017572016129,
      "loss": 1.0571,
      "step": 89500
    },
    {
      "epoch": 144.39,
      "learning_rate": 0.08556694991693549,
      "loss": 1.0437,
      "step": 89520
    },
    {
      "epoch": 144.42,
      "learning_rate": 0.08556372411370967,
      "loss": 1.006,
      "step": 89540
    },
    {
      "epoch": 144.45,
      "learning_rate": 0.08556049831048387,
      "loss": 1.0054,
      "step": 89560
    },
    {
      "epoch": 144.48,
      "learning_rate": 0.08555727250725807,
      "loss": 1.0066,
      "step": 89580
    },
    {
      "epoch": 144.52,
      "learning_rate": 0.08555404670403226,
      "loss": 0.9951,
      "step": 89600
    },
    {
      "epoch": 144.55,
      "learning_rate": 0.08555082090080646,
      "loss": 1.0186,
      "step": 89620
    },
    {
      "epoch": 144.58,
      "learning_rate": 0.08554759509758066,
      "loss": 1.0532,
      "step": 89640
    },
    {
      "epoch": 144.61,
      "learning_rate": 0.08554436929435484,
      "loss": 1.0177,
      "step": 89660
    },
    {
      "epoch": 144.65,
      "learning_rate": 0.08554114349112904,
      "loss": 1.0171,
      "step": 89680
    },
    {
      "epoch": 144.68,
      "learning_rate": 0.08553791768790324,
      "loss": 1.0147,
      "step": 89700
    },
    {
      "epoch": 144.71,
      "learning_rate": 0.08553469188467742,
      "loss": 0.9932,
      "step": 89720
    },
    {
      "epoch": 144.74,
      "learning_rate": 0.08553146608145162,
      "loss": 0.9995,
      "step": 89740
    },
    {
      "epoch": 144.77,
      "learning_rate": 0.08552824027822581,
      "loss": 1.0241,
      "step": 89760
    },
    {
      "epoch": 144.81,
      "learning_rate": 0.08552501447500001,
      "loss": 1.0109,
      "step": 89780
    },
    {
      "epoch": 144.84,
      "learning_rate": 0.0855217886717742,
      "loss": 1.0035,
      "step": 89800
    },
    {
      "epoch": 144.87,
      "learning_rate": 0.08551856286854839,
      "loss": 1.0414,
      "step": 89820
    },
    {
      "epoch": 144.9,
      "learning_rate": 0.08551533706532258,
      "loss": 1.0299,
      "step": 89840
    },
    {
      "epoch": 144.94,
      "learning_rate": 0.08551211126209678,
      "loss": 1.0108,
      "step": 89860
    },
    {
      "epoch": 144.97,
      "learning_rate": 0.08550888545887098,
      "loss": 1.0195,
      "step": 89880
    },
    {
      "epoch": 145.0,
      "learning_rate": 0.08550565965564516,
      "loss": 1.0283,
      "step": 89900
    },
    {
      "epoch": 145.0,
      "eval_accuracy": {
        "accuracy": 0.7342908438061041
      },
      "eval_loss": 1.3516367673873901,
      "eval_runtime": 3.6808,
      "eval_samples_per_second": 3480.531,
      "eval_steps_per_second": 54.608,
      "step": 89900
    },
    {
      "epoch": 145.03,
      "learning_rate": 0.08550243385241936,
      "loss": 1.0499,
      "step": 89920
    },
    {
      "epoch": 145.06,
      "learning_rate": 0.08549920804919356,
      "loss": 0.998,
      "step": 89940
    },
    {
      "epoch": 145.1,
      "learning_rate": 0.08549598224596774,
      "loss": 1.0353,
      "step": 89960
    },
    {
      "epoch": 145.13,
      "learning_rate": 0.08549275644274194,
      "loss": 0.9973,
      "step": 89980
    },
    {
      "epoch": 145.16,
      "learning_rate": 0.08548953063951614,
      "loss": 1.0058,
      "step": 90000
    },
    {
      "epoch": 145.19,
      "learning_rate": 0.08548630483629033,
      "loss": 1.0007,
      "step": 90020
    },
    {
      "epoch": 145.23,
      "learning_rate": 0.08548307903306453,
      "loss": 1.0214,
      "step": 90040
    },
    {
      "epoch": 145.26,
      "learning_rate": 0.08547985322983871,
      "loss": 1.0298,
      "step": 90060
    },
    {
      "epoch": 145.29,
      "learning_rate": 0.08547662742661291,
      "loss": 1.0469,
      "step": 90080
    },
    {
      "epoch": 145.32,
      "learning_rate": 0.0854734016233871,
      "loss": 1.0102,
      "step": 90100
    },
    {
      "epoch": 145.35,
      "learning_rate": 0.0854701758201613,
      "loss": 0.9826,
      "step": 90120
    },
    {
      "epoch": 145.39,
      "learning_rate": 0.08546695001693548,
      "loss": 1.0332,
      "step": 90140
    },
    {
      "epoch": 145.42,
      "learning_rate": 0.08546372421370968,
      "loss": 1.0298,
      "step": 90160
    },
    {
      "epoch": 145.45,
      "learning_rate": 0.08546049841048388,
      "loss": 1.0114,
      "step": 90180
    },
    {
      "epoch": 145.48,
      "learning_rate": 0.08545727260725806,
      "loss": 1.0003,
      "step": 90200
    },
    {
      "epoch": 145.52,
      "learning_rate": 0.08545404680403226,
      "loss": 1.0006,
      "step": 90220
    },
    {
      "epoch": 145.55,
      "learning_rate": 0.08545082100080646,
      "loss": 1.019,
      "step": 90240
    },
    {
      "epoch": 145.58,
      "learning_rate": 0.08544759519758065,
      "loss": 0.9978,
      "step": 90260
    },
    {
      "epoch": 145.61,
      "learning_rate": 0.08544436939435485,
      "loss": 0.9922,
      "step": 90280
    },
    {
      "epoch": 145.65,
      "learning_rate": 0.08544114359112905,
      "loss": 1.0054,
      "step": 90300
    },
    {
      "epoch": 145.68,
      "learning_rate": 0.08543791778790323,
      "loss": 1.0107,
      "step": 90320
    },
    {
      "epoch": 145.71,
      "learning_rate": 0.08543469198467743,
      "loss": 0.9826,
      "step": 90340
    },
    {
      "epoch": 145.74,
      "learning_rate": 0.08543146618145162,
      "loss": 1.0343,
      "step": 90360
    },
    {
      "epoch": 145.77,
      "learning_rate": 0.08542824037822581,
      "loss": 1.0189,
      "step": 90380
    },
    {
      "epoch": 145.81,
      "learning_rate": 0.085425014575,
      "loss": 1.0476,
      "step": 90400
    },
    {
      "epoch": 145.84,
      "learning_rate": 0.0854217887717742,
      "loss": 1.0203,
      "step": 90420
    },
    {
      "epoch": 145.87,
      "learning_rate": 0.08541856296854838,
      "loss": 0.9855,
      "step": 90440
    },
    {
      "epoch": 145.9,
      "learning_rate": 0.08541533716532258,
      "loss": 1.0045,
      "step": 90460
    },
    {
      "epoch": 145.94,
      "learning_rate": 0.08541211136209678,
      "loss": 1.0184,
      "step": 90480
    },
    {
      "epoch": 145.97,
      "learning_rate": 0.08540888555887097,
      "loss": 1.05,
      "step": 90500
    },
    {
      "epoch": 146.0,
      "learning_rate": 0.08540565975564517,
      "loss": 1.0374,
      "step": 90520
    },
    {
      "epoch": 146.0,
      "eval_accuracy": {
        "accuracy": 0.7350714229958629
      },
      "eval_loss": 1.4074921607971191,
      "eval_runtime": 2.7318,
      "eval_samples_per_second": 4689.567,
      "eval_steps_per_second": 73.578,
      "step": 90520
    },
    {
      "epoch": 146.03,
      "learning_rate": 0.08540243395241937,
      "loss": 1.0581,
      "step": 90540
    },
    {
      "epoch": 146.06,
      "learning_rate": 0.08539920814919355,
      "loss": 1.0291,
      "step": 90560
    },
    {
      "epoch": 146.1,
      "learning_rate": 0.08539598234596775,
      "loss": 0.9853,
      "step": 90580
    },
    {
      "epoch": 146.13,
      "learning_rate": 0.08539275654274195,
      "loss": 0.9926,
      "step": 90600
    },
    {
      "epoch": 146.16,
      "learning_rate": 0.08538953073951613,
      "loss": 0.9903,
      "step": 90620
    },
    {
      "epoch": 146.19,
      "learning_rate": 0.08538630493629033,
      "loss": 0.9877,
      "step": 90640
    },
    {
      "epoch": 146.23,
      "learning_rate": 0.08538307913306452,
      "loss": 0.9886,
      "step": 90660
    },
    {
      "epoch": 146.26,
      "learning_rate": 0.08537985332983872,
      "loss": 0.9813,
      "step": 90680
    },
    {
      "epoch": 146.29,
      "learning_rate": 0.0853766275266129,
      "loss": 1.0238,
      "step": 90700
    },
    {
      "epoch": 146.32,
      "learning_rate": 0.08537340172338712,
      "loss": 1.0043,
      "step": 90720
    },
    {
      "epoch": 146.35,
      "learning_rate": 0.08537017592016129,
      "loss": 1.0031,
      "step": 90740
    },
    {
      "epoch": 146.39,
      "learning_rate": 0.08536695011693549,
      "loss": 0.9945,
      "step": 90760
    },
    {
      "epoch": 146.42,
      "learning_rate": 0.08536372431370969,
      "loss": 0.9986,
      "step": 90780
    },
    {
      "epoch": 146.45,
      "learning_rate": 0.08536049851048387,
      "loss": 1.0225,
      "step": 90800
    },
    {
      "epoch": 146.48,
      "learning_rate": 0.08535727270725807,
      "loss": 0.9781,
      "step": 90820
    },
    {
      "epoch": 146.52,
      "learning_rate": 0.08535404690403227,
      "loss": 1.0179,
      "step": 90840
    },
    {
      "epoch": 146.55,
      "learning_rate": 0.08535082110080645,
      "loss": 1.0099,
      "step": 90860
    },
    {
      "epoch": 146.58,
      "learning_rate": 0.08534759529758065,
      "loss": 1.0227,
      "step": 90880
    },
    {
      "epoch": 146.61,
      "learning_rate": 0.08534436949435485,
      "loss": 0.9824,
      "step": 90900
    },
    {
      "epoch": 146.65,
      "learning_rate": 0.08534130498129032,
      "loss": 1.0271,
      "step": 90920
    },
    {
      "epoch": 146.68,
      "learning_rate": 0.08533807917806452,
      "loss": 1.0541,
      "step": 90940
    },
    {
      "epoch": 146.71,
      "learning_rate": 0.08533485337483872,
      "loss": 1.0293,
      "step": 90960
    },
    {
      "epoch": 146.74,
      "learning_rate": 0.0853316275716129,
      "loss": 1.0303,
      "step": 90980
    },
    {
      "epoch": 146.77,
      "learning_rate": 0.0853284017683871,
      "loss": 1.0173,
      "step": 91000
    },
    {
      "epoch": 146.81,
      "learning_rate": 0.0853251759651613,
      "loss": 1.0126,
      "step": 91020
    },
    {
      "epoch": 146.84,
      "learning_rate": 0.08532195016193549,
      "loss": 1.013,
      "step": 91040
    },
    {
      "epoch": 146.87,
      "learning_rate": 0.08531872435870969,
      "loss": 1.0078,
      "step": 91060
    },
    {
      "epoch": 146.9,
      "learning_rate": 0.08531549855548388,
      "loss": 1.0133,
      "step": 91080
    },
    {
      "epoch": 146.94,
      "learning_rate": 0.08531227275225806,
      "loss": 1.0123,
      "step": 91100
    },
    {
      "epoch": 146.97,
      "learning_rate": 0.08530904694903227,
      "loss": 0.9843,
      "step": 91120
    },
    {
      "epoch": 147.0,
      "learning_rate": 0.08530582114580645,
      "loss": 0.9985,
      "step": 91140
    },
    {
      "epoch": 147.0,
      "eval_accuracy": {
        "accuracy": 0.7329638591835141
      },
      "eval_loss": 1.381394624710083,
      "eval_runtime": 2.5743,
      "eval_samples_per_second": 4976.521,
      "eval_steps_per_second": 78.08,
      "step": 91140
    },
    {
      "epoch": 147.03,
      "learning_rate": 0.08530259534258065,
      "loss": 1.0256,
      "step": 91160
    },
    {
      "epoch": 147.06,
      "learning_rate": 0.08529936953935484,
      "loss": 0.9714,
      "step": 91180
    },
    {
      "epoch": 147.1,
      "learning_rate": 0.08529614373612904,
      "loss": 0.995,
      "step": 91200
    },
    {
      "epoch": 147.13,
      "learning_rate": 0.08529291793290322,
      "loss": 1.0058,
      "step": 91220
    },
    {
      "epoch": 147.16,
      "learning_rate": 0.08528969212967742,
      "loss": 0.9897,
      "step": 91240
    },
    {
      "epoch": 147.19,
      "learning_rate": 0.08528646632645162,
      "loss": 0.9646,
      "step": 91260
    },
    {
      "epoch": 147.23,
      "learning_rate": 0.0852832405232258,
      "loss": 0.9894,
      "step": 91280
    },
    {
      "epoch": 147.26,
      "learning_rate": 0.08528001472,
      "loss": 1.0009,
      "step": 91300
    },
    {
      "epoch": 147.29,
      "learning_rate": 0.0852767889167742,
      "loss": 1.0009,
      "step": 91320
    },
    {
      "epoch": 147.32,
      "learning_rate": 0.08527356311354839,
      "loss": 1.0031,
      "step": 91340
    },
    {
      "epoch": 147.35,
      "learning_rate": 0.08527033731032259,
      "loss": 1.002,
      "step": 91360
    },
    {
      "epoch": 147.39,
      "learning_rate": 0.08526711150709679,
      "loss": 0.9973,
      "step": 91380
    },
    {
      "epoch": 147.42,
      "learning_rate": 0.08526388570387097,
      "loss": 0.9717,
      "step": 91400
    },
    {
      "epoch": 147.45,
      "learning_rate": 0.08526065990064517,
      "loss": 1.0107,
      "step": 91420
    },
    {
      "epoch": 147.48,
      "learning_rate": 0.08525743409741936,
      "loss": 1.0272,
      "step": 91440
    },
    {
      "epoch": 147.52,
      "learning_rate": 0.08525420829419356,
      "loss": 1.049,
      "step": 91460
    },
    {
      "epoch": 147.55,
      "learning_rate": 0.08525098249096774,
      "loss": 1.0354,
      "step": 91480
    },
    {
      "epoch": 147.58,
      "learning_rate": 0.08524775668774194,
      "loss": 1.0167,
      "step": 91500
    },
    {
      "epoch": 147.61,
      "learning_rate": 0.08524453088451613,
      "loss": 1.0444,
      "step": 91520
    },
    {
      "epoch": 147.65,
      "learning_rate": 0.08524130508129033,
      "loss": 0.9971,
      "step": 91540
    },
    {
      "epoch": 147.68,
      "learning_rate": 0.08523807927806452,
      "loss": 1.0239,
      "step": 91560
    },
    {
      "epoch": 147.71,
      "learning_rate": 0.08523485347483871,
      "loss": 1.009,
      "step": 91580
    },
    {
      "epoch": 147.74,
      "learning_rate": 0.08523162767161291,
      "loss": 0.9891,
      "step": 91600
    },
    {
      "epoch": 147.77,
      "learning_rate": 0.08522840186838711,
      "loss": 1.0026,
      "step": 91620
    },
    {
      "epoch": 147.81,
      "learning_rate": 0.08522517606516129,
      "loss": 1.0309,
      "step": 91640
    },
    {
      "epoch": 147.84,
      "learning_rate": 0.08522195026193549,
      "loss": 1.0219,
      "step": 91660
    },
    {
      "epoch": 147.87,
      "learning_rate": 0.08521872445870969,
      "loss": 1.004,
      "step": 91680
    },
    {
      "epoch": 147.9,
      "learning_rate": 0.08521549865548388,
      "loss": 1.0051,
      "step": 91700
    },
    {
      "epoch": 147.94,
      "learning_rate": 0.08521227285225808,
      "loss": 1.0272,
      "step": 91720
    },
    {
      "epoch": 147.97,
      "learning_rate": 0.08520904704903226,
      "loss": 1.0119,
      "step": 91740
    },
    {
      "epoch": 148.0,
      "learning_rate": 0.08520582124580646,
      "loss": 1.01,
      "step": 91760
    },
    {
      "epoch": 148.0,
      "eval_accuracy": {
        "accuracy": 0.738271797673874
      },
      "eval_loss": 1.3326035737991333,
      "eval_runtime": 2.662,
      "eval_samples_per_second": 4812.476,
      "eval_steps_per_second": 75.506,
      "step": 91760
    },
    {
      "epoch": 148.03,
      "learning_rate": 0.08520259544258064,
      "loss": 1.0048,
      "step": 91780
    },
    {
      "epoch": 148.06,
      "learning_rate": 0.08519936963935484,
      "loss": 1.0068,
      "step": 91800
    },
    {
      "epoch": 148.1,
      "learning_rate": 0.08519614383612903,
      "loss": 1.0145,
      "step": 91820
    },
    {
      "epoch": 148.13,
      "learning_rate": 0.08519291803290323,
      "loss": 0.9884,
      "step": 91840
    },
    {
      "epoch": 148.16,
      "learning_rate": 0.08518969222967743,
      "loss": 0.984,
      "step": 91860
    },
    {
      "epoch": 148.19,
      "learning_rate": 0.08518646642645161,
      "loss": 0.9722,
      "step": 91880
    },
    {
      "epoch": 148.23,
      "learning_rate": 0.08518324062322581,
      "loss": 0.9608,
      "step": 91900
    },
    {
      "epoch": 148.26,
      "learning_rate": 0.08518001482000001,
      "loss": 0.9972,
      "step": 91920
    },
    {
      "epoch": 148.29,
      "learning_rate": 0.0851767890167742,
      "loss": 1.0147,
      "step": 91940
    },
    {
      "epoch": 148.32,
      "learning_rate": 0.0851735632135484,
      "loss": 0.9763,
      "step": 91960
    },
    {
      "epoch": 148.35,
      "learning_rate": 0.0851703374103226,
      "loss": 1.0169,
      "step": 91980
    },
    {
      "epoch": 148.39,
      "learning_rate": 0.08516711160709678,
      "loss": 1.012,
      "step": 92000
    },
    {
      "epoch": 148.42,
      "learning_rate": 0.08516388580387098,
      "loss": 0.9935,
      "step": 92020
    },
    {
      "epoch": 148.45,
      "learning_rate": 0.08516066000064516,
      "loss": 0.983,
      "step": 92040
    },
    {
      "epoch": 148.48,
      "learning_rate": 0.08515743419741936,
      "loss": 1.005,
      "step": 92060
    },
    {
      "epoch": 148.52,
      "learning_rate": 0.08515420839419355,
      "loss": 0.9848,
      "step": 92080
    },
    {
      "epoch": 148.55,
      "learning_rate": 0.08515098259096775,
      "loss": 1.0035,
      "step": 92100
    },
    {
      "epoch": 148.58,
      "learning_rate": 0.08514775678774193,
      "loss": 1.0291,
      "step": 92120
    },
    {
      "epoch": 148.61,
      "learning_rate": 0.08514453098451613,
      "loss": 1.0143,
      "step": 92140
    },
    {
      "epoch": 148.65,
      "learning_rate": 0.08514130518129033,
      "loss": 0.9866,
      "step": 92160
    },
    {
      "epoch": 148.68,
      "learning_rate": 0.08513807937806452,
      "loss": 1.0116,
      "step": 92180
    },
    {
      "epoch": 148.71,
      "learning_rate": 0.08513485357483871,
      "loss": 0.996,
      "step": 92200
    },
    {
      "epoch": 148.74,
      "learning_rate": 0.08513162777161291,
      "loss": 1.0166,
      "step": 92220
    },
    {
      "epoch": 148.77,
      "learning_rate": 0.0851284019683871,
      "loss": 0.9796,
      "step": 92240
    },
    {
      "epoch": 148.81,
      "learning_rate": 0.0851251761651613,
      "loss": 1.0121,
      "step": 92260
    },
    {
      "epoch": 148.84,
      "learning_rate": 0.0851219503619355,
      "loss": 1.0286,
      "step": 92280
    },
    {
      "epoch": 148.87,
      "learning_rate": 0.08511872455870968,
      "loss": 1.0208,
      "step": 92300
    },
    {
      "epoch": 148.9,
      "learning_rate": 0.08511549875548388,
      "loss": 0.9935,
      "step": 92320
    },
    {
      "epoch": 148.94,
      "learning_rate": 0.08511227295225807,
      "loss": 1.0245,
      "step": 92340
    },
    {
      "epoch": 148.97,
      "learning_rate": 0.08510904714903227,
      "loss": 1.0293,
      "step": 92360
    },
    {
      "epoch": 149.0,
      "learning_rate": 0.08510582134580645,
      "loss": 1.0183,
      "step": 92380
    },
    {
      "epoch": 149.0,
      "eval_accuracy": {
        "accuracy": 0.7319491062368277
      },
      "eval_loss": 1.3954085111618042,
      "eval_runtime": 2.6386,
      "eval_samples_per_second": 4855.162,
      "eval_steps_per_second": 76.176,
      "step": 92380
    },
    {
      "epoch": 149.03,
      "learning_rate": 0.08510259554258065,
      "loss": 1.0651,
      "step": 92400
    },
    {
      "epoch": 149.06,
      "learning_rate": 0.08509936973935484,
      "loss": 1.0181,
      "step": 92420
    },
    {
      "epoch": 149.1,
      "learning_rate": 0.08509614393612903,
      "loss": 0.994,
      "step": 92440
    },
    {
      "epoch": 149.13,
      "learning_rate": 0.08509291813290323,
      "loss": 0.9972,
      "step": 92460
    },
    {
      "epoch": 149.16,
      "learning_rate": 0.08508969232967742,
      "loss": 0.9736,
      "step": 92480
    },
    {
      "epoch": 149.19,
      "learning_rate": 0.08508646652645162,
      "loss": 1.0257,
      "step": 92500
    },
    {
      "epoch": 149.23,
      "learning_rate": 0.08508324072322582,
      "loss": 1.0121,
      "step": 92520
    },
    {
      "epoch": 149.26,
      "learning_rate": 0.08508001492,
      "loss": 1.0097,
      "step": 92540
    },
    {
      "epoch": 149.29,
      "learning_rate": 0.0850767891167742,
      "loss": 0.963,
      "step": 92560
    },
    {
      "epoch": 149.32,
      "learning_rate": 0.0850735633135484,
      "loss": 0.9856,
      "step": 92580
    },
    {
      "epoch": 149.35,
      "learning_rate": 0.08507033751032259,
      "loss": 0.9792,
      "step": 92600
    },
    {
      "epoch": 149.39,
      "learning_rate": 0.08506711170709678,
      "loss": 0.9786,
      "step": 92620
    },
    {
      "epoch": 149.42,
      "learning_rate": 0.08506388590387097,
      "loss": 0.9825,
      "step": 92640
    },
    {
      "epoch": 149.45,
      "learning_rate": 0.08506066010064517,
      "loss": 1.0202,
      "step": 92660
    },
    {
      "epoch": 149.48,
      "learning_rate": 0.08505743429741935,
      "loss": 0.9977,
      "step": 92680
    },
    {
      "epoch": 149.52,
      "learning_rate": 0.08505420849419355,
      "loss": 0.9907,
      "step": 92700
    },
    {
      "epoch": 149.55,
      "learning_rate": 0.08505098269096774,
      "loss": 0.9691,
      "step": 92720
    },
    {
      "epoch": 149.58,
      "learning_rate": 0.08504775688774194,
      "loss": 1.0144,
      "step": 92740
    },
    {
      "epoch": 149.61,
      "learning_rate": 0.08504453108451614,
      "loss": 1.0043,
      "step": 92760
    },
    {
      "epoch": 149.65,
      "learning_rate": 0.08504130528129032,
      "loss": 1.0112,
      "step": 92780
    },
    {
      "epoch": 149.68,
      "learning_rate": 0.08503807947806452,
      "loss": 1.0301,
      "step": 92800
    },
    {
      "epoch": 149.71,
      "learning_rate": 0.08503485367483872,
      "loss": 0.9961,
      "step": 92820
    },
    {
      "epoch": 149.74,
      "learning_rate": 0.0850316278716129,
      "loss": 0.9615,
      "step": 92840
    },
    {
      "epoch": 149.77,
      "learning_rate": 0.0850284020683871,
      "loss": 0.9844,
      "step": 92860
    },
    {
      "epoch": 149.81,
      "learning_rate": 0.08502517626516129,
      "loss": 0.9868,
      "step": 92880
    },
    {
      "epoch": 149.84,
      "learning_rate": 0.08502195046193549,
      "loss": 1.0128,
      "step": 92900
    },
    {
      "epoch": 149.87,
      "learning_rate": 0.08501872465870969,
      "loss": 1.0197,
      "step": 92920
    },
    {
      "epoch": 149.9,
      "learning_rate": 0.08501549885548387,
      "loss": 1.015,
      "step": 92940
    },
    {
      "epoch": 149.94,
      "learning_rate": 0.08501227305225807,
      "loss": 1.033,
      "step": 92960
    },
    {
      "epoch": 149.97,
      "learning_rate": 0.08500904724903226,
      "loss": 1.0024,
      "step": 92980
    },
    {
      "epoch": 150.0,
      "learning_rate": 0.08500598273596775,
      "loss": 1.024,
      "step": 93000
    },
    {
      "epoch": 150.0,
      "eval_accuracy": {
        "accuracy": 0.7395207243774881
      },
      "eval_loss": 1.3269912004470825,
      "eval_runtime": 2.962,
      "eval_samples_per_second": 4325.067,
      "eval_steps_per_second": 67.859,
      "step": 93000
    },
    {
      "epoch": 150.03,
      "learning_rate": 0.08500275693274194,
      "loss": 1.0057,
      "step": 93020
    },
    {
      "epoch": 150.06,
      "learning_rate": 0.08499953112951614,
      "loss": 0.974,
      "step": 93040
    },
    {
      "epoch": 150.1,
      "learning_rate": 0.08499630532629034,
      "loss": 0.974,
      "step": 93060
    },
    {
      "epoch": 150.13,
      "learning_rate": 0.08499307952306452,
      "loss": 0.9725,
      "step": 93080
    },
    {
      "epoch": 150.16,
      "learning_rate": 0.08498985371983872,
      "loss": 0.9962,
      "step": 93100
    },
    {
      "epoch": 150.19,
      "learning_rate": 0.0849866279166129,
      "loss": 1.0179,
      "step": 93120
    },
    {
      "epoch": 150.23,
      "learning_rate": 0.0849834021133871,
      "loss": 0.9829,
      "step": 93140
    },
    {
      "epoch": 150.26,
      "learning_rate": 0.08498017631016129,
      "loss": 0.9797,
      "step": 93160
    },
    {
      "epoch": 150.29,
      "learning_rate": 0.08497695050693549,
      "loss": 0.9827,
      "step": 93180
    },
    {
      "epoch": 150.32,
      "learning_rate": 0.08497372470370967,
      "loss": 0.9992,
      "step": 93200
    },
    {
      "epoch": 150.35,
      "learning_rate": 0.08497049890048387,
      "loss": 1.0145,
      "step": 93220
    },
    {
      "epoch": 150.39,
      "learning_rate": 0.08496727309725807,
      "loss": 0.9941,
      "step": 93240
    },
    {
      "epoch": 150.42,
      "learning_rate": 0.08496404729403226,
      "loss": 0.9995,
      "step": 93260
    },
    {
      "epoch": 150.45,
      "learning_rate": 0.08496082149080646,
      "loss": 1.0068,
      "step": 93280
    },
    {
      "epoch": 150.48,
      "learning_rate": 0.08495759568758066,
      "loss": 1.0011,
      "step": 93300
    },
    {
      "epoch": 150.52,
      "learning_rate": 0.08495436988435484,
      "loss": 0.9741,
      "step": 93320
    },
    {
      "epoch": 150.55,
      "learning_rate": 0.08495114408112904,
      "loss": 0.9951,
      "step": 93340
    },
    {
      "epoch": 150.58,
      "learning_rate": 0.08494791827790324,
      "loss": 1.0,
      "step": 93360
    },
    {
      "epoch": 150.61,
      "learning_rate": 0.08494469247467742,
      "loss": 0.9809,
      "step": 93380
    },
    {
      "epoch": 150.65,
      "learning_rate": 0.08494146667145162,
      "loss": 0.9929,
      "step": 93400
    },
    {
      "epoch": 150.68,
      "learning_rate": 0.08493824086822581,
      "loss": 0.9855,
      "step": 93420
    },
    {
      "epoch": 150.71,
      "learning_rate": 0.08493501506500001,
      "loss": 1.0111,
      "step": 93440
    },
    {
      "epoch": 150.74,
      "learning_rate": 0.0849317892617742,
      "loss": 0.9939,
      "step": 93460
    },
    {
      "epoch": 150.77,
      "learning_rate": 0.08492856345854839,
      "loss": 1.0227,
      "step": 93480
    },
    {
      "epoch": 150.81,
      "learning_rate": 0.08492533765532258,
      "loss": 0.9922,
      "step": 93500
    },
    {
      "epoch": 150.84,
      "learning_rate": 0.08492211185209678,
      "loss": 1.0247,
      "step": 93520
    },
    {
      "epoch": 150.87,
      "learning_rate": 0.08491888604887098,
      "loss": 1.02,
      "step": 93540
    },
    {
      "epoch": 150.9,
      "learning_rate": 0.08491566024564516,
      "loss": 1.0275,
      "step": 93560
    },
    {
      "epoch": 150.94,
      "learning_rate": 0.08491243444241936,
      "loss": 1.0162,
      "step": 93580
    },
    {
      "epoch": 150.97,
      "learning_rate": 0.08490920863919356,
      "loss": 1.045,
      "step": 93600
    },
    {
      "epoch": 151.0,
      "learning_rate": 0.08490598283596774,
      "loss": 1.0442,
      "step": 93620
    },
    {
      "epoch": 151.0,
      "eval_accuracy": {
        "accuracy": 0.7325735695886347
      },
      "eval_loss": 1.431789517402649,
      "eval_runtime": 3.6093,
      "eval_samples_per_second": 3549.49,
      "eval_steps_per_second": 55.69,
      "step": 93620
    },
    {
      "epoch": 151.03,
      "learning_rate": 0.08490275703274194,
      "loss": 1.0674,
      "step": 93640
    },
    {
      "epoch": 151.06,
      "learning_rate": 0.08489953122951614,
      "loss": 0.991,
      "step": 93660
    },
    {
      "epoch": 151.1,
      "learning_rate": 0.08489630542629033,
      "loss": 0.9744,
      "step": 93680
    },
    {
      "epoch": 151.13,
      "learning_rate": 0.08489307962306453,
      "loss": 0.9964,
      "step": 93700
    },
    {
      "epoch": 151.16,
      "learning_rate": 0.08488985381983871,
      "loss": 1.0062,
      "step": 93720
    },
    {
      "epoch": 151.19,
      "learning_rate": 0.08488662801661291,
      "loss": 0.9755,
      "step": 93740
    },
    {
      "epoch": 151.23,
      "learning_rate": 0.0848834022133871,
      "loss": 0.9801,
      "step": 93760
    },
    {
      "epoch": 151.26,
      "learning_rate": 0.0848801764101613,
      "loss": 0.9917,
      "step": 93780
    },
    {
      "epoch": 151.29,
      "learning_rate": 0.08487695060693548,
      "loss": 1.0132,
      "step": 93800
    },
    {
      "epoch": 151.32,
      "learning_rate": 0.08487372480370968,
      "loss": 1.0397,
      "step": 93820
    },
    {
      "epoch": 151.35,
      "learning_rate": 0.08487049900048388,
      "loss": 0.9725,
      "step": 93840
    },
    {
      "epoch": 151.39,
      "learning_rate": 0.08486727319725806,
      "loss": 0.9754,
      "step": 93860
    },
    {
      "epoch": 151.42,
      "learning_rate": 0.08486404739403226,
      "loss": 1.0047,
      "step": 93880
    },
    {
      "epoch": 151.45,
      "learning_rate": 0.08486082159080646,
      "loss": 1.0135,
      "step": 93900
    },
    {
      "epoch": 151.48,
      "learning_rate": 0.08485759578758065,
      "loss": 1.0295,
      "step": 93920
    },
    {
      "epoch": 151.52,
      "learning_rate": 0.08485436998435485,
      "loss": 0.9998,
      "step": 93940
    },
    {
      "epoch": 151.55,
      "learning_rate": 0.08485114418112903,
      "loss": 0.9971,
      "step": 93960
    },
    {
      "epoch": 151.58,
      "learning_rate": 0.08484791837790323,
      "loss": 0.9996,
      "step": 93980
    },
    {
      "epoch": 151.61,
      "learning_rate": 0.08484469257467743,
      "loss": 1.0153,
      "step": 94000
    },
    {
      "epoch": 151.65,
      "learning_rate": 0.08484146677145162,
      "loss": 1.0508,
      "step": 94020
    },
    {
      "epoch": 151.68,
      "learning_rate": 0.08483824096822581,
      "loss": 1.0346,
      "step": 94040
    },
    {
      "epoch": 151.71,
      "learning_rate": 0.084835015165,
      "loss": 1.0192,
      "step": 94060
    },
    {
      "epoch": 151.74,
      "learning_rate": 0.0848317893617742,
      "loss": 1.0086,
      "step": 94080
    },
    {
      "epoch": 151.77,
      "learning_rate": 0.08482856355854838,
      "loss": 0.9864,
      "step": 94100
    },
    {
      "epoch": 151.81,
      "learning_rate": 0.08482533775532258,
      "loss": 0.9789,
      "step": 94120
    },
    {
      "epoch": 151.84,
      "learning_rate": 0.08482211195209678,
      "loss": 1.0239,
      "step": 94140
    },
    {
      "epoch": 151.87,
      "learning_rate": 0.08481888614887097,
      "loss": 1.0261,
      "step": 94160
    },
    {
      "epoch": 151.9,
      "learning_rate": 0.08481566034564517,
      "loss": 1.004,
      "step": 94180
    },
    {
      "epoch": 151.94,
      "learning_rate": 0.08481243454241937,
      "loss": 1.0224,
      "step": 94200
    },
    {
      "epoch": 151.97,
      "learning_rate": 0.08480920873919355,
      "loss": 1.0183,
      "step": 94220
    },
    {
      "epoch": 152.0,
      "learning_rate": 0.08480598293596775,
      "loss": 1.0033,
      "step": 94240
    },
    {
      "epoch": 152.0,
      "eval_accuracy": {
        "accuracy": 0.7312465849660448
      },
      "eval_loss": 1.3807015419006348,
      "eval_runtime": 2.7221,
      "eval_samples_per_second": 4706.3,
      "eval_steps_per_second": 73.84,
      "step": 94240
    },
    {
      "epoch": 152.03,
      "learning_rate": 0.08480275713274193,
      "loss": 1.0774,
      "step": 94260
    },
    {
      "epoch": 152.06,
      "learning_rate": 0.08479953132951613,
      "loss": 1.0608,
      "step": 94280
    },
    {
      "epoch": 152.1,
      "learning_rate": 0.08479630552629033,
      "loss": 1.0284,
      "step": 94300
    },
    {
      "epoch": 152.13,
      "learning_rate": 0.08479307972306452,
      "loss": 0.9918,
      "step": 94320
    },
    {
      "epoch": 152.16,
      "learning_rate": 0.08478985391983872,
      "loss": 0.9509,
      "step": 94340
    },
    {
      "epoch": 152.19,
      "learning_rate": 0.0847866281166129,
      "loss": 0.9444,
      "step": 94360
    },
    {
      "epoch": 152.23,
      "learning_rate": 0.0847834023133871,
      "loss": 0.9599,
      "step": 94380
    },
    {
      "epoch": 152.26,
      "learning_rate": 0.08478017651016129,
      "loss": 0.9865,
      "step": 94400
    },
    {
      "epoch": 152.29,
      "learning_rate": 0.0847769507069355,
      "loss": 0.9933,
      "step": 94420
    },
    {
      "epoch": 152.32,
      "learning_rate": 0.08477372490370969,
      "loss": 0.9926,
      "step": 94440
    },
    {
      "epoch": 152.35,
      "learning_rate": 0.08477049910048387,
      "loss": 0.9988,
      "step": 94460
    },
    {
      "epoch": 152.39,
      "learning_rate": 0.08476727329725807,
      "loss": 0.9801,
      "step": 94480
    },
    {
      "epoch": 152.42,
      "learning_rate": 0.08476404749403225,
      "loss": 0.9877,
      "step": 94500
    },
    {
      "epoch": 152.45,
      "learning_rate": 0.08476082169080645,
      "loss": 0.9675,
      "step": 94520
    },
    {
      "epoch": 152.48,
      "learning_rate": 0.08475759588758065,
      "loss": 1.0213,
      "step": 94540
    },
    {
      "epoch": 152.52,
      "learning_rate": 0.08475437008435484,
      "loss": 1.0004,
      "step": 94560
    },
    {
      "epoch": 152.55,
      "learning_rate": 0.08475114428112904,
      "loss": 0.9873,
      "step": 94580
    },
    {
      "epoch": 152.58,
      "learning_rate": 0.08474791847790324,
      "loss": 0.9686,
      "step": 94600
    },
    {
      "epoch": 152.61,
      "learning_rate": 0.08474469267467742,
      "loss": 1.0194,
      "step": 94620
    },
    {
      "epoch": 152.65,
      "learning_rate": 0.08474146687145162,
      "loss": 1.0154,
      "step": 94640
    },
    {
      "epoch": 152.68,
      "learning_rate": 0.08473824106822582,
      "loss": 1.0209,
      "step": 94660
    },
    {
      "epoch": 152.71,
      "learning_rate": 0.084735015265,
      "loss": 1.0363,
      "step": 94680
    },
    {
      "epoch": 152.74,
      "learning_rate": 0.08473178946177419,
      "loss": 1.0419,
      "step": 94700
    },
    {
      "epoch": 152.77,
      "learning_rate": 0.0847285636585484,
      "loss": 1.0088,
      "step": 94720
    },
    {
      "epoch": 152.81,
      "learning_rate": 0.08472533785532259,
      "loss": 0.9995,
      "step": 94740
    },
    {
      "epoch": 152.84,
      "learning_rate": 0.08472211205209677,
      "loss": 1.0106,
      "step": 94760
    },
    {
      "epoch": 152.87,
      "learning_rate": 0.08471888624887097,
      "loss": 1.0106,
      "step": 94780
    },
    {
      "epoch": 152.9,
      "learning_rate": 0.08471566044564516,
      "loss": 1.0098,
      "step": 94800
    },
    {
      "epoch": 152.94,
      "learning_rate": 0.08471243464241936,
      "loss": 1.0257,
      "step": 94820
    },
    {
      "epoch": 152.97,
      "learning_rate": 0.08470920883919356,
      "loss": 1.0136,
      "step": 94840
    },
    {
      "epoch": 153.0,
      "learning_rate": 0.08470598303596774,
      "loss": 0.9906,
      "step": 94860
    },
    {
      "epoch": 153.0,
      "eval_accuracy": {
        "accuracy": 0.7335883225353212
      },
      "eval_loss": 1.3857985734939575,
      "eval_runtime": 2.6756,
      "eval_samples_per_second": 4788.151,
      "eval_steps_per_second": 75.124,
      "step": 94860
    },
    {
      "epoch": 153.03,
      "learning_rate": 0.08470275723274194,
      "loss": 1.0144,
      "step": 94880
    },
    {
      "epoch": 153.06,
      "learning_rate": 0.08469953142951614,
      "loss": 0.9557,
      "step": 94900
    },
    {
      "epoch": 153.1,
      "learning_rate": 0.08469630562629032,
      "loss": 0.9634,
      "step": 94920
    },
    {
      "epoch": 153.13,
      "learning_rate": 0.08469307982306452,
      "loss": 0.9674,
      "step": 94940
    },
    {
      "epoch": 153.16,
      "learning_rate": 0.08468985401983872,
      "loss": 0.9621,
      "step": 94960
    },
    {
      "epoch": 153.19,
      "learning_rate": 0.08468662821661291,
      "loss": 0.9962,
      "step": 94980
    },
    {
      "epoch": 153.23,
      "learning_rate": 0.0846834024133871,
      "loss": 1.0076,
      "step": 95000
    },
    {
      "epoch": 153.26,
      "learning_rate": 0.0846801766101613,
      "loss": 0.9899,
      "step": 95020
    },
    {
      "epoch": 153.29,
      "learning_rate": 0.08467695080693548,
      "loss": 1.0119,
      "step": 95040
    },
    {
      "epoch": 153.32,
      "learning_rate": 0.08467372500370968,
      "loss": 1.0252,
      "step": 95060
    },
    {
      "epoch": 153.35,
      "learning_rate": 0.08467049920048388,
      "loss": 1.0441,
      "step": 95080
    },
    {
      "epoch": 153.39,
      "learning_rate": 0.08466743468741936,
      "loss": 1.0425,
      "step": 95100
    },
    {
      "epoch": 153.42,
      "learning_rate": 0.08466420888419356,
      "loss": 1.0306,
      "step": 95120
    },
    {
      "epoch": 153.45,
      "learning_rate": 0.08466098308096774,
      "loss": 1.0318,
      "step": 95140
    },
    {
      "epoch": 153.48,
      "learning_rate": 0.08465775727774194,
      "loss": 1.0299,
      "step": 95160
    },
    {
      "epoch": 153.52,
      "learning_rate": 0.08465453147451613,
      "loss": 1.0095,
      "step": 95180
    },
    {
      "epoch": 153.55,
      "learning_rate": 0.08465130567129033,
      "loss": 0.9957,
      "step": 95200
    },
    {
      "epoch": 153.58,
      "learning_rate": 0.08464824115822582,
      "loss": 1.0389,
      "step": 95220
    },
    {
      "epoch": 153.61,
      "learning_rate": 0.084645015355,
      "loss": 1.0237,
      "step": 95240
    },
    {
      "epoch": 153.65,
      "learning_rate": 0.0846417895517742,
      "loss": 0.9854,
      "step": 95260
    },
    {
      "epoch": 153.68,
      "learning_rate": 0.08463856374854839,
      "loss": 0.9919,
      "step": 95280
    },
    {
      "epoch": 153.71,
      "learning_rate": 0.08463533794532259,
      "loss": 0.9937,
      "step": 95300
    },
    {
      "epoch": 153.74,
      "learning_rate": 0.08463211214209677,
      "loss": 1.043,
      "step": 95320
    },
    {
      "epoch": 153.77,
      "learning_rate": 0.08462888633887097,
      "loss": 1.0063,
      "step": 95340
    },
    {
      "epoch": 153.81,
      "learning_rate": 0.08462566053564516,
      "loss": 1.0224,
      "step": 95360
    },
    {
      "epoch": 153.84,
      "learning_rate": 0.08462243473241936,
      "loss": 1.0258,
      "step": 95380
    },
    {
      "epoch": 153.87,
      "learning_rate": 0.08461920892919356,
      "loss": 0.9786,
      "step": 95400
    },
    {
      "epoch": 153.9,
      "learning_rate": 0.08461598312596774,
      "loss": 0.9933,
      "step": 95420
    },
    {
      "epoch": 153.94,
      "learning_rate": 0.08461275732274194,
      "loss": 1.0202,
      "step": 95440
    },
    {
      "epoch": 153.97,
      "learning_rate": 0.08460953151951614,
      "loss": 1.0344,
      "step": 95460
    },
    {
      "epoch": 154.0,
      "learning_rate": 0.08460630571629033,
      "loss": 1.0228,
      "step": 95480
    },
    {
      "epoch": 154.0,
      "eval_accuracy": {
        "accuracy": 0.7287487315588166
      },
      "eval_loss": 1.435250163078308,
      "eval_runtime": 3.6203,
      "eval_samples_per_second": 3538.633,
      "eval_steps_per_second": 55.52,
      "step": 95480
    },
    {
      "epoch": 154.03,
      "learning_rate": 0.08460307991306452,
      "loss": 1.0559,
      "step": 95500
    },
    {
      "epoch": 154.06,
      "learning_rate": 0.08459985410983872,
      "loss": 0.9761,
      "step": 95520
    },
    {
      "epoch": 154.1,
      "learning_rate": 0.08459662830661291,
      "loss": 0.9926,
      "step": 95540
    },
    {
      "epoch": 154.13,
      "learning_rate": 0.08459340250338711,
      "loss": 0.9666,
      "step": 95560
    },
    {
      "epoch": 154.16,
      "learning_rate": 0.0845901767001613,
      "loss": 0.9833,
      "step": 95580
    },
    {
      "epoch": 154.19,
      "learning_rate": 0.08458695089693549,
      "loss": 0.9921,
      "step": 95600
    },
    {
      "epoch": 154.23,
      "learning_rate": 0.08458372509370968,
      "loss": 1.0197,
      "step": 95620
    },
    {
      "epoch": 154.26,
      "learning_rate": 0.08458049929048388,
      "loss": 0.981,
      "step": 95640
    },
    {
      "epoch": 154.29,
      "learning_rate": 0.08457727348725806,
      "loss": 1.0103,
      "step": 95660
    },
    {
      "epoch": 154.32,
      "learning_rate": 0.08457404768403226,
      "loss": 1.0338,
      "step": 95680
    },
    {
      "epoch": 154.35,
      "learning_rate": 0.08457082188080646,
      "loss": 0.9962,
      "step": 95700
    },
    {
      "epoch": 154.39,
      "learning_rate": 0.08456759607758065,
      "loss": 0.9827,
      "step": 95720
    },
    {
      "epoch": 154.42,
      "learning_rate": 0.08456437027435484,
      "loss": 0.9816,
      "step": 95740
    },
    {
      "epoch": 154.45,
      "learning_rate": 0.08456114447112904,
      "loss": 0.9711,
      "step": 95760
    },
    {
      "epoch": 154.48,
      "learning_rate": 0.08455791866790323,
      "loss": 1.0134,
      "step": 95780
    },
    {
      "epoch": 154.52,
      "learning_rate": 0.08455469286467743,
      "loss": 1.0334,
      "step": 95800
    },
    {
      "epoch": 154.55,
      "learning_rate": 0.08455146706145163,
      "loss": 1.0142,
      "step": 95820
    },
    {
      "epoch": 154.58,
      "learning_rate": 0.08454824125822581,
      "loss": 1.0108,
      "step": 95840
    },
    {
      "epoch": 154.61,
      "learning_rate": 0.08454501545500001,
      "loss": 0.9959,
      "step": 95860
    },
    {
      "epoch": 154.65,
      "learning_rate": 0.0845417896517742,
      "loss": 1.0268,
      "step": 95880
    },
    {
      "epoch": 154.68,
      "learning_rate": 0.0845385638485484,
      "loss": 0.9923,
      "step": 95900
    },
    {
      "epoch": 154.71,
      "learning_rate": 0.08453533804532258,
      "loss": 0.9693,
      "step": 95920
    },
    {
      "epoch": 154.74,
      "learning_rate": 0.08453211224209678,
      "loss": 0.9915,
      "step": 95940
    },
    {
      "epoch": 154.77,
      "learning_rate": 0.08452888643887096,
      "loss": 0.9942,
      "step": 95960
    },
    {
      "epoch": 154.81,
      "learning_rate": 0.08452566063564516,
      "loss": 0.9888,
      "step": 95980
    },
    {
      "epoch": 154.84,
      "learning_rate": 0.08452243483241936,
      "loss": 1.0245,
      "step": 96000
    },
    {
      "epoch": 154.87,
      "learning_rate": 0.08451920902919355,
      "loss": 1.0101,
      "step": 96020
    },
    {
      "epoch": 154.9,
      "learning_rate": 0.08451598322596775,
      "loss": 1.0154,
      "step": 96040
    },
    {
      "epoch": 154.94,
      "learning_rate": 0.08451275742274195,
      "loss": 1.0022,
      "step": 96060
    },
    {
      "epoch": 154.97,
      "learning_rate": 0.08450953161951613,
      "loss": 0.9983,
      "step": 96080
    },
    {
      "epoch": 155.0,
      "learning_rate": 0.08450630581629033,
      "loss": 1.0262,
      "step": 96100
    },
    {
      "epoch": 155.0,
      "eval_accuracy": {
        "accuracy": 0.7287487315588166
      },
      "eval_loss": 1.4184497594833374,
      "eval_runtime": 2.7131,
      "eval_samples_per_second": 4721.987,
      "eval_steps_per_second": 74.086,
      "step": 96100
    },
    {
      "epoch": 155.03,
      "learning_rate": 0.08450308001306452,
      "loss": 1.0308,
      "step": 96120
    },
    {
      "epoch": 155.06,
      "learning_rate": 0.08449985420983872,
      "loss": 0.9969,
      "step": 96140
    },
    {
      "epoch": 155.1,
      "learning_rate": 0.08449662840661291,
      "loss": 0.9916,
      "step": 96160
    },
    {
      "epoch": 155.13,
      "learning_rate": 0.0844934026033871,
      "loss": 0.9766,
      "step": 96180
    },
    {
      "epoch": 155.16,
      "learning_rate": 0.0844901768001613,
      "loss": 0.9935,
      "step": 96200
    },
    {
      "epoch": 155.19,
      "learning_rate": 0.08448695099693548,
      "loss": 1.0206,
      "step": 96220
    },
    {
      "epoch": 155.23,
      "learning_rate": 0.08448372519370968,
      "loss": 0.986,
      "step": 96240
    },
    {
      "epoch": 155.26,
      "learning_rate": 0.08448049939048387,
      "loss": 0.9874,
      "step": 96260
    },
    {
      "epoch": 155.29,
      "learning_rate": 0.08447727358725807,
      "loss": 0.9631,
      "step": 96280
    },
    {
      "epoch": 155.32,
      "learning_rate": 0.08447404778403227,
      "loss": 0.9751,
      "step": 96300
    },
    {
      "epoch": 155.35,
      "learning_rate": 0.08447082198080645,
      "loss": 0.9904,
      "step": 96320
    },
    {
      "epoch": 155.39,
      "learning_rate": 0.08446759617758065,
      "loss": 1.0035,
      "step": 96340
    },
    {
      "epoch": 155.42,
      "learning_rate": 0.08446437037435485,
      "loss": 0.9798,
      "step": 96360
    },
    {
      "epoch": 155.45,
      "learning_rate": 0.08446114457112903,
      "loss": 0.9839,
      "step": 96380
    },
    {
      "epoch": 155.48,
      "learning_rate": 0.08445791876790323,
      "loss": 0.9829,
      "step": 96400
    },
    {
      "epoch": 155.52,
      "learning_rate": 0.08445469296467742,
      "loss": 0.9939,
      "step": 96420
    },
    {
      "epoch": 155.55,
      "learning_rate": 0.08445146716145162,
      "loss": 0.9647,
      "step": 96440
    },
    {
      "epoch": 155.58,
      "learning_rate": 0.08444824135822582,
      "loss": 0.9857,
      "step": 96460
    },
    {
      "epoch": 155.61,
      "learning_rate": 0.084445015555,
      "loss": 0.9843,
      "step": 96480
    },
    {
      "epoch": 155.65,
      "learning_rate": 0.0844417897517742,
      "loss": 1.0011,
      "step": 96500
    },
    {
      "epoch": 155.68,
      "learning_rate": 0.08443856394854839,
      "loss": 1.0373,
      "step": 96520
    },
    {
      "epoch": 155.71,
      "learning_rate": 0.08443533814532259,
      "loss": 1.0118,
      "step": 96540
    },
    {
      "epoch": 155.74,
      "learning_rate": 0.08443211234209677,
      "loss": 1.0157,
      "step": 96560
    },
    {
      "epoch": 155.77,
      "learning_rate": 0.08442888653887097,
      "loss": 1.0075,
      "step": 96580
    },
    {
      "epoch": 155.81,
      "learning_rate": 0.08442566073564517,
      "loss": 0.9523,
      "step": 96600
    },
    {
      "epoch": 155.84,
      "learning_rate": 0.08442243493241935,
      "loss": 1.0442,
      "step": 96620
    },
    {
      "epoch": 155.87,
      "learning_rate": 0.08441920912919355,
      "loss": 1.0026,
      "step": 96640
    },
    {
      "epoch": 155.9,
      "learning_rate": 0.08441598332596774,
      "loss": 1.0206,
      "step": 96660
    },
    {
      "epoch": 155.94,
      "learning_rate": 0.08441275752274194,
      "loss": 1.0349,
      "step": 96680
    },
    {
      "epoch": 155.97,
      "learning_rate": 0.08440953171951614,
      "loss": 1.0018,
      "step": 96700
    },
    {
      "epoch": 156.0,
      "learning_rate": 0.08440630591629032,
      "loss": 1.0148,
      "step": 96720
    },
    {
      "epoch": 156.0,
      "eval_accuracy": {
        "accuracy": 0.7380376239169464
      },
      "eval_loss": 1.3358200788497925,
      "eval_runtime": 2.6382,
      "eval_samples_per_second": 4855.914,
      "eval_steps_per_second": 76.188,
      "step": 96720
    },
    {
      "epoch": 156.03,
      "learning_rate": 0.08440308011306452,
      "loss": 1.0127,
      "step": 96740
    },
    {
      "epoch": 156.06,
      "learning_rate": 0.08439985430983872,
      "loss": 0.9602,
      "step": 96760
    },
    {
      "epoch": 156.1,
      "learning_rate": 0.0843966285066129,
      "loss": 0.9729,
      "step": 96780
    },
    {
      "epoch": 156.13,
      "learning_rate": 0.0843934027033871,
      "loss": 0.9666,
      "step": 96800
    },
    {
      "epoch": 156.16,
      "learning_rate": 0.08439017690016129,
      "loss": 0.9907,
      "step": 96820
    },
    {
      "epoch": 156.19,
      "learning_rate": 0.08438695109693549,
      "loss": 0.9906,
      "step": 96840
    },
    {
      "epoch": 156.23,
      "learning_rate": 0.08438372529370967,
      "loss": 0.9805,
      "step": 96860
    },
    {
      "epoch": 156.26,
      "learning_rate": 0.08438049949048389,
      "loss": 1.0157,
      "step": 96880
    },
    {
      "epoch": 156.29,
      "learning_rate": 0.08437727368725807,
      "loss": 1.0085,
      "step": 96900
    },
    {
      "epoch": 156.32,
      "learning_rate": 0.08437404788403226,
      "loss": 1.022,
      "step": 96920
    },
    {
      "epoch": 156.35,
      "learning_rate": 0.08437082208080646,
      "loss": 1.022,
      "step": 96940
    },
    {
      "epoch": 156.39,
      "learning_rate": 0.08436759627758064,
      "loss": 1.0189,
      "step": 96960
    },
    {
      "epoch": 156.42,
      "learning_rate": 0.08436437047435484,
      "loss": 0.9793,
      "step": 96980
    },
    {
      "epoch": 156.45,
      "learning_rate": 0.08436114467112904,
      "loss": 1.028,
      "step": 97000
    },
    {
      "epoch": 156.48,
      "learning_rate": 0.08435791886790323,
      "loss": 0.9999,
      "step": 97020
    },
    {
      "epoch": 156.52,
      "learning_rate": 0.08435469306467742,
      "loss": 0.9896,
      "step": 97040
    },
    {
      "epoch": 156.55,
      "learning_rate": 0.08435146726145162,
      "loss": 0.9949,
      "step": 97060
    },
    {
      "epoch": 156.58,
      "learning_rate": 0.08434824145822581,
      "loss": 1.0155,
      "step": 97080
    },
    {
      "epoch": 156.61,
      "learning_rate": 0.08434501565500001,
      "loss": 1.0061,
      "step": 97100
    },
    {
      "epoch": 156.65,
      "learning_rate": 0.08434178985177421,
      "loss": 0.9927,
      "step": 97120
    },
    {
      "epoch": 156.68,
      "learning_rate": 0.08433856404854839,
      "loss": 1.0021,
      "step": 97140
    },
    {
      "epoch": 156.71,
      "learning_rate": 0.08433533824532258,
      "loss": 0.9877,
      "step": 97160
    },
    {
      "epoch": 156.74,
      "learning_rate": 0.08433211244209679,
      "loss": 0.9974,
      "step": 97180
    },
    {
      "epoch": 156.77,
      "learning_rate": 0.08432888663887096,
      "loss": 1.0252,
      "step": 97200
    },
    {
      "epoch": 156.81,
      "learning_rate": 0.08432566083564516,
      "loss": 0.9954,
      "step": 97220
    },
    {
      "epoch": 156.84,
      "learning_rate": 0.08432243503241936,
      "loss": 1.0017,
      "step": 97240
    },
    {
      "epoch": 156.87,
      "learning_rate": 0.08431920922919355,
      "loss": 1.0473,
      "step": 97260
    },
    {
      "epoch": 156.9,
      "learning_rate": 0.08431598342596774,
      "loss": 1.0214,
      "step": 97280
    },
    {
      "epoch": 156.94,
      "learning_rate": 0.08431275762274194,
      "loss": 1.0175,
      "step": 97300
    },
    {
      "epoch": 156.97,
      "learning_rate": 0.08430953181951613,
      "loss": 1.0085,
      "step": 97320
    },
    {
      "epoch": 157.0,
      "learning_rate": 0.08430630601629033,
      "loss": 0.9914,
      "step": 97340
    },
    {
      "epoch": 157.0,
      "eval_accuracy": {
        "accuracy": 0.7462337054094138
      },
      "eval_loss": 1.2991654872894287,
      "eval_runtime": 3.5311,
      "eval_samples_per_second": 3628.062,
      "eval_steps_per_second": 56.923,
      "step": 97340
    },
    {
      "epoch": 157.03,
      "learning_rate": 0.08430308021306453,
      "loss": 0.9942,
      "step": 97360
    },
    {
      "epoch": 157.06,
      "learning_rate": 0.08429985440983871,
      "loss": 0.9821,
      "step": 97380
    },
    {
      "epoch": 157.1,
      "learning_rate": 0.08429662860661291,
      "loss": 0.9937,
      "step": 97400
    },
    {
      "epoch": 157.13,
      "learning_rate": 0.08429340280338711,
      "loss": 0.9945,
      "step": 97420
    },
    {
      "epoch": 157.16,
      "learning_rate": 0.0842901770001613,
      "loss": 0.9937,
      "step": 97440
    },
    {
      "epoch": 157.19,
      "learning_rate": 0.08428695119693548,
      "loss": 0.9657,
      "step": 97460
    },
    {
      "epoch": 157.23,
      "learning_rate": 0.0842837253937097,
      "loss": 0.9549,
      "step": 97480
    },
    {
      "epoch": 157.26,
      "learning_rate": 0.08428049959048386,
      "loss": 0.9639,
      "step": 97500
    },
    {
      "epoch": 157.29,
      "learning_rate": 0.08427727378725806,
      "loss": 0.9527,
      "step": 97520
    },
    {
      "epoch": 157.32,
      "learning_rate": 0.08427404798403226,
      "loss": 0.9743,
      "step": 97540
    },
    {
      "epoch": 157.35,
      "learning_rate": 0.08427082218080645,
      "loss": 0.9879,
      "step": 97560
    },
    {
      "epoch": 157.39,
      "learning_rate": 0.08426759637758065,
      "loss": 1.012,
      "step": 97580
    },
    {
      "epoch": 157.42,
      "learning_rate": 0.08426437057435485,
      "loss": 1.0243,
      "step": 97600
    },
    {
      "epoch": 157.45,
      "learning_rate": 0.08426114477112903,
      "loss": 0.9982,
      "step": 97620
    },
    {
      "epoch": 157.48,
      "learning_rate": 0.08425791896790323,
      "loss": 0.971,
      "step": 97640
    },
    {
      "epoch": 157.52,
      "learning_rate": 0.08425469316467743,
      "loss": 0.99,
      "step": 97660
    },
    {
      "epoch": 157.55,
      "learning_rate": 0.08425146736145162,
      "loss": 0.963,
      "step": 97680
    },
    {
      "epoch": 157.58,
      "learning_rate": 0.08424824155822581,
      "loss": 0.992,
      "step": 97700
    },
    {
      "epoch": 157.61,
      "learning_rate": 0.08424501575500001,
      "loss": 0.9858,
      "step": 97720
    },
    {
      "epoch": 157.65,
      "learning_rate": 0.0842417899517742,
      "loss": 1.0094,
      "step": 97740
    },
    {
      "epoch": 157.68,
      "learning_rate": 0.08423856414854838,
      "loss": 0.9974,
      "step": 97760
    },
    {
      "epoch": 157.71,
      "learning_rate": 0.0842353383453226,
      "loss": 1.0003,
      "step": 97780
    },
    {
      "epoch": 157.74,
      "learning_rate": 0.08423211254209677,
      "loss": 1.0268,
      "step": 97800
    },
    {
      "epoch": 157.77,
      "learning_rate": 0.08422888673887098,
      "loss": 0.9937,
      "step": 97820
    },
    {
      "epoch": 157.81,
      "learning_rate": 0.08422566093564517,
      "loss": 0.9925,
      "step": 97840
    },
    {
      "epoch": 157.84,
      "learning_rate": 0.08422243513241935,
      "loss": 1.0323,
      "step": 97860
    },
    {
      "epoch": 157.87,
      "learning_rate": 0.08421920932919355,
      "loss": 0.9839,
      "step": 97880
    },
    {
      "epoch": 157.9,
      "learning_rate": 0.08421598352596775,
      "loss": 1.0005,
      "step": 97900
    },
    {
      "epoch": 157.94,
      "learning_rate": 0.08421275772274193,
      "loss": 1.018,
      "step": 97920
    },
    {
      "epoch": 157.97,
      "learning_rate": 0.08420953191951613,
      "loss": 1.0466,
      "step": 97940
    },
    {
      "epoch": 158.0,
      "learning_rate": 0.08420630611629033,
      "loss": 1.0465,
      "step": 97960
    },
    {
      "epoch": 158.0,
      "eval_accuracy": {
        "accuracy": 0.7331980329404418
      },
      "eval_loss": 1.384851098060608,
      "eval_runtime": 3.1635,
      "eval_samples_per_second": 4049.626,
      "eval_steps_per_second": 63.537,
      "step": 97960
    },
    {
      "epoch": 158.03,
      "learning_rate": 0.08420308031306452,
      "loss": 1.0268,
      "step": 97980
    },
    {
      "epoch": 158.06,
      "learning_rate": 0.08419985450983872,
      "loss": 0.9959,
      "step": 98000
    },
    {
      "epoch": 158.1,
      "learning_rate": 0.08419662870661292,
      "loss": 0.9975,
      "step": 98020
    },
    {
      "epoch": 158.13,
      "learning_rate": 0.0841934029033871,
      "loss": 0.9594,
      "step": 98040
    },
    {
      "epoch": 158.16,
      "learning_rate": 0.08419017710016129,
      "loss": 0.9558,
      "step": 98060
    },
    {
      "epoch": 158.19,
      "learning_rate": 0.0841869512969355,
      "loss": 0.991,
      "step": 98080
    },
    {
      "epoch": 158.23,
      "learning_rate": 0.08418372549370967,
      "loss": 0.9433,
      "step": 98100
    },
    {
      "epoch": 158.26,
      "learning_rate": 0.08418049969048388,
      "loss": 0.979,
      "step": 98120
    },
    {
      "epoch": 158.29,
      "learning_rate": 0.08417727388725807,
      "loss": 1.0058,
      "step": 98140
    },
    {
      "epoch": 158.32,
      "learning_rate": 0.08417404808403225,
      "loss": 0.9894,
      "step": 98160
    },
    {
      "epoch": 158.35,
      "learning_rate": 0.08417082228080645,
      "loss": 0.965,
      "step": 98180
    },
    {
      "epoch": 158.39,
      "learning_rate": 0.08416759647758065,
      "loss": 0.9981,
      "step": 98200
    },
    {
      "epoch": 158.42,
      "learning_rate": 0.08416437067435484,
      "loss": 1.0171,
      "step": 98220
    },
    {
      "epoch": 158.45,
      "learning_rate": 0.08416114487112904,
      "loss": 1.0001,
      "step": 98240
    },
    {
      "epoch": 158.48,
      "learning_rate": 0.08415791906790324,
      "loss": 0.9828,
      "step": 98260
    },
    {
      "epoch": 158.52,
      "learning_rate": 0.08415469326467742,
      "loss": 0.9712,
      "step": 98280
    },
    {
      "epoch": 158.55,
      "learning_rate": 0.08415146746145162,
      "loss": 1.0078,
      "step": 98300
    },
    {
      "epoch": 158.58,
      "learning_rate": 0.08414824165822582,
      "loss": 0.9918,
      "step": 98320
    },
    {
      "epoch": 158.61,
      "learning_rate": 0.084145015855,
      "loss": 1.0,
      "step": 98340
    },
    {
      "epoch": 158.65,
      "learning_rate": 0.0841417900517742,
      "loss": 1.0062,
      "step": 98360
    },
    {
      "epoch": 158.68,
      "learning_rate": 0.0841385642485484,
      "loss": 1.026,
      "step": 98380
    },
    {
      "epoch": 158.71,
      "learning_rate": 0.08413533844532257,
      "loss": 0.9933,
      "step": 98400
    },
    {
      "epoch": 158.74,
      "learning_rate": 0.08413211264209679,
      "loss": 0.9837,
      "step": 98420
    },
    {
      "epoch": 158.77,
      "learning_rate": 0.08412888683887097,
      "loss": 0.9975,
      "step": 98440
    },
    {
      "epoch": 158.81,
      "learning_rate": 0.08412566103564516,
      "loss": 1.0341,
      "step": 98460
    },
    {
      "epoch": 158.84,
      "learning_rate": 0.08412243523241936,
      "loss": 0.9907,
      "step": 98480
    },
    {
      "epoch": 158.87,
      "learning_rate": 0.08411920942919356,
      "loss": 1.0058,
      "step": 98500
    },
    {
      "epoch": 158.9,
      "learning_rate": 0.08411598362596774,
      "loss": 0.9782,
      "step": 98520
    },
    {
      "epoch": 158.94,
      "learning_rate": 0.08411275782274194,
      "loss": 0.9954,
      "step": 98540
    },
    {
      "epoch": 158.97,
      "learning_rate": 0.08410953201951614,
      "loss": 1.0205,
      "step": 98560
    },
    {
      "epoch": 159.0,
      "learning_rate": 0.08410630621629032,
      "loss": 1.0278,
      "step": 98580
    },
    {
      "epoch": 159.0,
      "eval_accuracy": {
        "accuracy": 0.7403013035672469
      },
      "eval_loss": 1.3288445472717285,
      "eval_runtime": 2.6811,
      "eval_samples_per_second": 4778.204,
      "eval_steps_per_second": 74.968,
      "step": 98580
    },
    {
      "epoch": 159.03,
      "learning_rate": 0.08410308041306452,
      "loss": 1.0193,
      "step": 98600
    },
    {
      "epoch": 159.06,
      "learning_rate": 0.08409985460983872,
      "loss": 0.9964,
      "step": 98620
    },
    {
      "epoch": 159.1,
      "learning_rate": 0.08409662880661291,
      "loss": 1.0014,
      "step": 98640
    },
    {
      "epoch": 159.13,
      "learning_rate": 0.08409340300338711,
      "loss": 0.9895,
      "step": 98660
    },
    {
      "epoch": 159.16,
      "learning_rate": 0.0840901772001613,
      "loss": 0.9584,
      "step": 98680
    },
    {
      "epoch": 159.19,
      "learning_rate": 0.08408695139693548,
      "loss": 0.9545,
      "step": 98700
    },
    {
      "epoch": 159.23,
      "learning_rate": 0.08408372559370969,
      "loss": 0.9662,
      "step": 98720
    },
    {
      "epoch": 159.26,
      "learning_rate": 0.08408049979048388,
      "loss": 0.9725,
      "step": 98740
    },
    {
      "epoch": 159.29,
      "learning_rate": 0.08407727398725806,
      "loss": 0.9825,
      "step": 98760
    },
    {
      "epoch": 159.32,
      "learning_rate": 0.08407404818403226,
      "loss": 0.935,
      "step": 98780
    },
    {
      "epoch": 159.35,
      "learning_rate": 0.08407082238080646,
      "loss": 0.9844,
      "step": 98800
    },
    {
      "epoch": 159.39,
      "learning_rate": 0.08406759657758064,
      "loss": 1.0189,
      "step": 98820
    },
    {
      "epoch": 159.42,
      "learning_rate": 0.08406437077435484,
      "loss": 0.9903,
      "step": 98840
    },
    {
      "epoch": 159.45,
      "learning_rate": 0.08406114497112904,
      "loss": 1.0041,
      "step": 98860
    },
    {
      "epoch": 159.48,
      "learning_rate": 0.08405791916790323,
      "loss": 0.9817,
      "step": 98880
    },
    {
      "epoch": 159.52,
      "learning_rate": 0.08405469336467743,
      "loss": 0.9938,
      "step": 98900
    },
    {
      "epoch": 159.55,
      "learning_rate": 0.08405146756145163,
      "loss": 0.9944,
      "step": 98920
    },
    {
      "epoch": 159.58,
      "learning_rate": 0.08404824175822581,
      "loss": 0.995,
      "step": 98940
    },
    {
      "epoch": 159.61,
      "learning_rate": 0.08404501595500001,
      "loss": 0.9705,
      "step": 98960
    },
    {
      "epoch": 159.65,
      "learning_rate": 0.0840417901517742,
      "loss": 0.992,
      "step": 98980
    },
    {
      "epoch": 159.68,
      "learning_rate": 0.08403856434854838,
      "loss": 1.0059,
      "step": 99000
    },
    {
      "epoch": 159.71,
      "learning_rate": 0.0840353385453226,
      "loss": 1.014,
      "step": 99020
    },
    {
      "epoch": 159.74,
      "learning_rate": 0.08403211274209678,
      "loss": 1.0252,
      "step": 99040
    },
    {
      "epoch": 159.77,
      "learning_rate": 0.08402888693887098,
      "loss": 1.0262,
      "step": 99060
    },
    {
      "epoch": 159.81,
      "learning_rate": 0.08402566113564516,
      "loss": 0.989,
      "step": 99080
    },
    {
      "epoch": 159.84,
      "learning_rate": 0.08402243533241936,
      "loss": 0.9949,
      "step": 99100
    },
    {
      "epoch": 159.87,
      "learning_rate": 0.08401920952919355,
      "loss": 1.0124,
      "step": 99120
    },
    {
      "epoch": 159.9,
      "learning_rate": 0.08401598372596775,
      "loss": 1.0245,
      "step": 99140
    },
    {
      "epoch": 159.94,
      "learning_rate": 0.08401275792274195,
      "loss": 0.994,
      "step": 99160
    },
    {
      "epoch": 159.97,
      "learning_rate": 0.08400953211951613,
      "loss": 0.9872,
      "step": 99180
    },
    {
      "epoch": 160.0,
      "learning_rate": 0.08400630631629033,
      "loss": 0.9975,
      "step": 99200
    },
    {
      "epoch": 160.0,
      "eval_accuracy": {
        "accuracy": 0.7353836546717665
      },
      "eval_loss": 1.3662326335906982,
      "eval_runtime": 2.9279,
      "eval_samples_per_second": 4375.479,
      "eval_steps_per_second": 68.65,
      "step": 99200
    },
    {
      "epoch": 160.03,
      "learning_rate": 0.08400308051306453,
      "loss": 1.0001,
      "step": 99220
    },
    {
      "epoch": 160.06,
      "learning_rate": 0.08399985470983871,
      "loss": 0.954,
      "step": 99240
    },
    {
      "epoch": 160.1,
      "learning_rate": 0.08399662890661291,
      "loss": 0.9412,
      "step": 99260
    },
    {
      "epoch": 160.13,
      "learning_rate": 0.0839934031033871,
      "loss": 0.9742,
      "step": 99280
    },
    {
      "epoch": 160.16,
      "learning_rate": 0.0839901773001613,
      "loss": 0.9734,
      "step": 99300
    },
    {
      "epoch": 160.19,
      "learning_rate": 0.0839869514969355,
      "loss": 0.997,
      "step": 99320
    },
    {
      "epoch": 160.23,
      "learning_rate": 0.08398372569370968,
      "loss": 1.0226,
      "step": 99340
    },
    {
      "epoch": 160.26,
      "learning_rate": 0.08398049989048388,
      "loss": 0.9831,
      "step": 99360
    },
    {
      "epoch": 160.29,
      "learning_rate": 0.08397743537741936,
      "loss": 0.9579,
      "step": 99380
    },
    {
      "epoch": 160.32,
      "learning_rate": 0.08397420957419356,
      "loss": 0.9837,
      "step": 99400
    },
    {
      "epoch": 160.35,
      "learning_rate": 0.08397098377096775,
      "loss": 0.9826,
      "step": 99420
    },
    {
      "epoch": 160.39,
      "learning_rate": 0.08396775796774195,
      "loss": 1.0182,
      "step": 99440
    },
    {
      "epoch": 160.42,
      "learning_rate": 0.08396453216451615,
      "loss": 1.0386,
      "step": 99460
    },
    {
      "epoch": 160.45,
      "learning_rate": 0.08396130636129032,
      "loss": 0.9839,
      "step": 99480
    },
    {
      "epoch": 160.48,
      "learning_rate": 0.08395808055806453,
      "loss": 1.0043,
      "step": 99500
    },
    {
      "epoch": 160.52,
      "learning_rate": 0.08395485475483871,
      "loss": 1.0048,
      "step": 99520
    },
    {
      "epoch": 160.55,
      "learning_rate": 0.0839516289516129,
      "loss": 0.968,
      "step": 99540
    },
    {
      "epoch": 160.58,
      "learning_rate": 0.0839484031483871,
      "loss": 0.9997,
      "step": 99560
    },
    {
      "epoch": 160.61,
      "learning_rate": 0.0839451773451613,
      "loss": 1.0507,
      "step": 99580
    },
    {
      "epoch": 160.65,
      "learning_rate": 0.08394195154193548,
      "loss": 1.018,
      "step": 99600
    },
    {
      "epoch": 160.68,
      "learning_rate": 0.08393872573870968,
      "loss": 1.0037,
      "step": 99620
    },
    {
      "epoch": 160.71,
      "learning_rate": 0.08393549993548388,
      "loss": 1.0053,
      "step": 99640
    },
    {
      "epoch": 160.74,
      "learning_rate": 0.08393227413225807,
      "loss": 1.0275,
      "step": 99660
    },
    {
      "epoch": 160.77,
      "learning_rate": 0.08392904832903227,
      "loss": 1.0292,
      "step": 99680
    },
    {
      "epoch": 160.81,
      "learning_rate": 0.08392582252580646,
      "loss": 1.0231,
      "step": 99700
    },
    {
      "epoch": 160.84,
      "learning_rate": 0.08392259672258065,
      "loss": 1.0093,
      "step": 99720
    },
    {
      "epoch": 160.87,
      "learning_rate": 0.08391937091935485,
      "loss": 1.0027,
      "step": 99740
    },
    {
      "epoch": 160.9,
      "learning_rate": 0.08391614511612905,
      "loss": 0.9818,
      "step": 99760
    },
    {
      "epoch": 160.94,
      "learning_rate": 0.08391291931290322,
      "loss": 0.9953,
      "step": 99780
    },
    {
      "epoch": 160.97,
      "learning_rate": 0.08390969350967743,
      "loss": 0.9878,
      "step": 99800
    },
    {
      "epoch": 161.0,
      "learning_rate": 0.08390646770645162,
      "loss": 0.9906,
      "step": 99820
    },
    {
      "epoch": 161.0,
      "eval_accuracy": {
        "accuracy": 0.7387401451877293
      },
      "eval_loss": 1.3582854270935059,
      "eval_runtime": 3.0426,
      "eval_samples_per_second": 4210.602,
      "eval_steps_per_second": 66.063,
      "step": 99820
    },
    {
      "epoch": 161.03,
      "learning_rate": 0.0839032419032258,
      "loss": 1.0239,
      "step": 99840
    },
    {
      "epoch": 161.06,
      "learning_rate": 0.0839000161,
      "loss": 0.9982,
      "step": 99860
    },
    {
      "epoch": 161.1,
      "learning_rate": 0.0838967902967742,
      "loss": 0.9593,
      "step": 99880
    },
    {
      "epoch": 161.13,
      "learning_rate": 0.08389356449354839,
      "loss": 0.9679,
      "step": 99900
    },
    {
      "epoch": 161.16,
      "learning_rate": 0.08389033869032259,
      "loss": 0.9573,
      "step": 99920
    },
    {
      "epoch": 161.19,
      "learning_rate": 0.08388711288709678,
      "loss": 0.9818,
      "step": 99940
    },
    {
      "epoch": 161.23,
      "learning_rate": 0.08388388708387097,
      "loss": 0.987,
      "step": 99960
    },
    {
      "epoch": 161.26,
      "learning_rate": 0.08388066128064517,
      "loss": 0.9935,
      "step": 99980
    },
    {
      "epoch": 161.29,
      "learning_rate": 0.08387743547741937,
      "loss": 0.9754,
      "step": 100000
    },
    {
      "epoch": 161.32,
      "learning_rate": 0.08387420967419355,
      "loss": 1.0037,
      "step": 100020
    },
    {
      "epoch": 161.35,
      "learning_rate": 0.08387098387096775,
      "loss": 1.0063,
      "step": 100040
    },
    {
      "epoch": 161.39,
      "learning_rate": 0.08386775806774194,
      "loss": 0.9787,
      "step": 100060
    },
    {
      "epoch": 161.42,
      "learning_rate": 0.08386453226451612,
      "loss": 1.0319,
      "step": 100080
    },
    {
      "epoch": 161.45,
      "learning_rate": 0.08386130646129034,
      "loss": 1.0073,
      "step": 100100
    },
    {
      "epoch": 161.48,
      "learning_rate": 0.08385808065806452,
      "loss": 1.0042,
      "step": 100120
    },
    {
      "epoch": 161.52,
      "learning_rate": 0.08385485485483872,
      "loss": 0.9582,
      "step": 100140
    },
    {
      "epoch": 161.55,
      "learning_rate": 0.0838516290516129,
      "loss": 1.0112,
      "step": 100160
    },
    {
      "epoch": 161.58,
      "learning_rate": 0.0838484032483871,
      "loss": 0.9947,
      "step": 100180
    },
    {
      "epoch": 161.61,
      "learning_rate": 0.08384517744516129,
      "loss": 1.0116,
      "step": 100200
    },
    {
      "epoch": 161.65,
      "learning_rate": 0.08384195164193549,
      "loss": 0.9873,
      "step": 100220
    },
    {
      "epoch": 161.68,
      "learning_rate": 0.08383872583870969,
      "loss": 0.9762,
      "step": 100240
    },
    {
      "epoch": 161.71,
      "learning_rate": 0.08383550003548387,
      "loss": 1.0129,
      "step": 100260
    },
    {
      "epoch": 161.74,
      "learning_rate": 0.08383227423225807,
      "loss": 1.0004,
      "step": 100280
    },
    {
      "epoch": 161.77,
      "learning_rate": 0.08382904842903227,
      "loss": 1.0182,
      "step": 100300
    },
    {
      "epoch": 161.81,
      "learning_rate": 0.08382582262580646,
      "loss": 0.9923,
      "step": 100320
    },
    {
      "epoch": 161.84,
      "learning_rate": 0.08382259682258066,
      "loss": 1.0024,
      "step": 100340
    },
    {
      "epoch": 161.87,
      "learning_rate": 0.08381937101935484,
      "loss": 0.9839,
      "step": 100360
    },
    {
      "epoch": 161.9,
      "learning_rate": 0.08381614521612903,
      "loss": 1.0112,
      "step": 100380
    },
    {
      "epoch": 161.94,
      "learning_rate": 0.08381291941290324,
      "loss": 1.0206,
      "step": 100400
    },
    {
      "epoch": 161.97,
      "learning_rate": 0.08380969360967742,
      "loss": 1.0355,
      "step": 100420
    },
    {
      "epoch": 162.0,
      "learning_rate": 0.08380646780645162,
      "loss": 1.0185,
      "step": 100440
    },
    {
      "epoch": 162.0,
      "eval_accuracy": {
        "accuracy": 0.7414721723518851
      },
      "eval_loss": 1.34432053565979,
      "eval_runtime": 2.9425,
      "eval_samples_per_second": 4353.79,
      "eval_steps_per_second": 68.309,
      "step": 100440
    },
    {
      "epoch": 162.03,
      "learning_rate": 0.08380324200322581,
      "loss": 1.0001,
      "step": 100460
    },
    {
      "epoch": 162.06,
      "learning_rate": 0.08380001620000001,
      "loss": 0.9894,
      "step": 100480
    },
    {
      "epoch": 162.1,
      "learning_rate": 0.08379679039677419,
      "loss": 0.9405,
      "step": 100500
    },
    {
      "epoch": 162.13,
      "learning_rate": 0.08379356459354839,
      "loss": 0.9763,
      "step": 100520
    },
    {
      "epoch": 162.16,
      "learning_rate": 0.08379033879032259,
      "loss": 0.9674,
      "step": 100540
    },
    {
      "epoch": 162.19,
      "learning_rate": 0.08378711298709678,
      "loss": 0.956,
      "step": 100560
    },
    {
      "epoch": 162.23,
      "learning_rate": 0.08378388718387098,
      "loss": 0.9491,
      "step": 100580
    },
    {
      "epoch": 162.26,
      "learning_rate": 0.08378066138064516,
      "loss": 0.9886,
      "step": 100600
    },
    {
      "epoch": 162.29,
      "learning_rate": 0.08377743557741936,
      "loss": 0.9811,
      "step": 100620
    },
    {
      "epoch": 162.32,
      "learning_rate": 0.08377420977419356,
      "loss": 0.9912,
      "step": 100640
    },
    {
      "epoch": 162.35,
      "learning_rate": 0.08377098397096774,
      "loss": 1.0116,
      "step": 100660
    },
    {
      "epoch": 162.39,
      "learning_rate": 0.08376775816774194,
      "loss": 0.9976,
      "step": 100680
    },
    {
      "epoch": 162.42,
      "learning_rate": 0.08376453236451614,
      "loss": 0.9698,
      "step": 100700
    },
    {
      "epoch": 162.45,
      "learning_rate": 0.08376130656129033,
      "loss": 0.9597,
      "step": 100720
    },
    {
      "epoch": 162.48,
      "learning_rate": 0.08375808075806453,
      "loss": 0.979,
      "step": 100740
    },
    {
      "epoch": 162.52,
      "learning_rate": 0.08375485495483871,
      "loss": 1.0208,
      "step": 100760
    },
    {
      "epoch": 162.55,
      "learning_rate": 0.08375162915161291,
      "loss": 1.0121,
      "step": 100780
    },
    {
      "epoch": 162.58,
      "learning_rate": 0.0837484033483871,
      "loss": 1.0178,
      "step": 100800
    },
    {
      "epoch": 162.61,
      "learning_rate": 0.0837451775451613,
      "loss": 0.9757,
      "step": 100820
    },
    {
      "epoch": 162.65,
      "learning_rate": 0.0837419517419355,
      "loss": 0.9994,
      "step": 100840
    },
    {
      "epoch": 162.68,
      "learning_rate": 0.08373872593870968,
      "loss": 1.0087,
      "step": 100860
    },
    {
      "epoch": 162.71,
      "learning_rate": 0.08373550013548388,
      "loss": 0.991,
      "step": 100880
    },
    {
      "epoch": 162.74,
      "learning_rate": 0.08373227433225806,
      "loss": 0.9962,
      "step": 100900
    },
    {
      "epoch": 162.77,
      "learning_rate": 0.08372904852903226,
      "loss": 1.0174,
      "step": 100920
    },
    {
      "epoch": 162.81,
      "learning_rate": 0.08372582272580646,
      "loss": 0.9901,
      "step": 100940
    },
    {
      "epoch": 162.84,
      "learning_rate": 0.08372259692258065,
      "loss": 1.0041,
      "step": 100960
    },
    {
      "epoch": 162.87,
      "learning_rate": 0.08371937111935485,
      "loss": 1.0265,
      "step": 100980
    },
    {
      "epoch": 162.9,
      "learning_rate": 0.08371614531612905,
      "loss": 0.9966,
      "step": 101000
    },
    {
      "epoch": 162.94,
      "learning_rate": 0.08371291951290323,
      "loss": 1.0037,
      "step": 101020
    },
    {
      "epoch": 162.97,
      "learning_rate": 0.08370969370967743,
      "loss": 0.9508,
      "step": 101040
    },
    {
      "epoch": 163.0,
      "learning_rate": 0.08370646790645161,
      "loss": 0.9808,
      "step": 101060
    },
    {
      "epoch": 163.0,
      "eval_accuracy": {
        "accuracy": 0.7417063461088127
      },
      "eval_loss": 1.3153595924377441,
      "eval_runtime": 3.7318,
      "eval_samples_per_second": 3432.943,
      "eval_steps_per_second": 53.862,
      "step": 101060
    },
    {
      "epoch": 163.03,
      "learning_rate": 0.08370324210322581,
      "loss": 1.063,
      "step": 101080
    },
    {
      "epoch": 163.06,
      "learning_rate": 0.0837000163,
      "loss": 0.9796,
      "step": 101100
    },
    {
      "epoch": 163.1,
      "learning_rate": 0.0836967904967742,
      "loss": 0.977,
      "step": 101120
    },
    {
      "epoch": 163.13,
      "learning_rate": 0.08369356469354838,
      "loss": 0.9936,
      "step": 101140
    },
    {
      "epoch": 163.16,
      "learning_rate": 0.08369033889032258,
      "loss": 0.9642,
      "step": 101160
    },
    {
      "epoch": 163.19,
      "learning_rate": 0.08368711308709678,
      "loss": 0.9685,
      "step": 101180
    },
    {
      "epoch": 163.23,
      "learning_rate": 0.08368388728387097,
      "loss": 0.9937,
      "step": 101200
    },
    {
      "epoch": 163.26,
      "learning_rate": 0.08368066148064517,
      "loss": 0.9773,
      "step": 101220
    },
    {
      "epoch": 163.29,
      "learning_rate": 0.08367743567741937,
      "loss": 0.9861,
      "step": 101240
    },
    {
      "epoch": 163.32,
      "learning_rate": 0.08367420987419355,
      "loss": 0.9986,
      "step": 101260
    },
    {
      "epoch": 163.35,
      "learning_rate": 0.08367098407096775,
      "loss": 0.9984,
      "step": 101280
    },
    {
      "epoch": 163.39,
      "learning_rate": 0.08366775826774195,
      "loss": 0.9712,
      "step": 101300
    },
    {
      "epoch": 163.42,
      "learning_rate": 0.08366453246451613,
      "loss": 0.975,
      "step": 101320
    },
    {
      "epoch": 163.45,
      "learning_rate": 0.08366130666129033,
      "loss": 1.0019,
      "step": 101340
    },
    {
      "epoch": 163.48,
      "learning_rate": 0.08365808085806452,
      "loss": 0.9728,
      "step": 101360
    },
    {
      "epoch": 163.52,
      "learning_rate": 0.08365485505483872,
      "loss": 0.9741,
      "step": 101380
    },
    {
      "epoch": 163.55,
      "learning_rate": 0.0836516292516129,
      "loss": 0.9931,
      "step": 101400
    },
    {
      "epoch": 163.58,
      "learning_rate": 0.0836484034483871,
      "loss": 0.9723,
      "step": 101420
    },
    {
      "epoch": 163.61,
      "learning_rate": 0.08364517764516129,
      "loss": 1.0097,
      "step": 101440
    },
    {
      "epoch": 163.65,
      "learning_rate": 0.08364195184193549,
      "loss": 1.0043,
      "step": 101460
    },
    {
      "epoch": 163.68,
      "learning_rate": 0.08363872603870968,
      "loss": 0.9808,
      "step": 101480
    },
    {
      "epoch": 163.71,
      "learning_rate": 0.08363550023548387,
      "loss": 0.9874,
      "step": 101500
    },
    {
      "epoch": 163.74,
      "learning_rate": 0.08363227443225807,
      "loss": 0.9799,
      "step": 101520
    },
    {
      "epoch": 163.77,
      "learning_rate": 0.08362904862903227,
      "loss": 0.9728,
      "step": 101540
    },
    {
      "epoch": 163.81,
      "learning_rate": 0.08362582282580645,
      "loss": 0.991,
      "step": 101560
    },
    {
      "epoch": 163.84,
      "learning_rate": 0.08362259702258065,
      "loss": 1.0038,
      "step": 101580
    },
    {
      "epoch": 163.87,
      "learning_rate": 0.08361937121935485,
      "loss": 1.0045,
      "step": 101600
    },
    {
      "epoch": 163.9,
      "learning_rate": 0.08361614541612904,
      "loss": 1.0147,
      "step": 101620
    },
    {
      "epoch": 163.94,
      "learning_rate": 0.08361291961290324,
      "loss": 1.0041,
      "step": 101640
    },
    {
      "epoch": 163.97,
      "learning_rate": 0.08360969380967742,
      "loss": 1.0009,
      "step": 101660
    },
    {
      "epoch": 164.0,
      "learning_rate": 0.08360646800645162,
      "loss": 0.9847,
      "step": 101680
    },
    {
      "epoch": 164.0,
      "eval_accuracy": {
        "accuracy": 0.740925766919054
      },
      "eval_loss": 1.395556092262268,
      "eval_runtime": 2.8847,
      "eval_samples_per_second": 4441.063,
      "eval_steps_per_second": 69.679,
      "step": 101680
    },
    {
      "epoch": 164.03,
      "learning_rate": 0.0836034034933871,
      "loss": 1.0471,
      "step": 101700
    },
    {
      "epoch": 164.06,
      "learning_rate": 0.0836001776901613,
      "loss": 0.9561,
      "step": 101720
    },
    {
      "epoch": 164.1,
      "learning_rate": 0.08359695188693549,
      "loss": 1.0044,
      "step": 101740
    },
    {
      "epoch": 164.13,
      "learning_rate": 0.08359372608370969,
      "loss": 0.969,
      "step": 101760
    },
    {
      "epoch": 164.16,
      "learning_rate": 0.08359050028048388,
      "loss": 1.0096,
      "step": 101780
    },
    {
      "epoch": 164.19,
      "learning_rate": 0.08358727447725807,
      "loss": 0.9657,
      "step": 101800
    },
    {
      "epoch": 164.23,
      "learning_rate": 0.08358404867403227,
      "loss": 0.9577,
      "step": 101820
    },
    {
      "epoch": 164.26,
      "learning_rate": 0.08358082287080645,
      "loss": 0.9658,
      "step": 101840
    },
    {
      "epoch": 164.29,
      "learning_rate": 0.08357759706758065,
      "loss": 0.9827,
      "step": 101860
    },
    {
      "epoch": 164.32,
      "learning_rate": 0.08357437126435484,
      "loss": 1.007,
      "step": 101880
    },
    {
      "epoch": 164.35,
      "learning_rate": 0.08357114546112904,
      "loss": 0.9994,
      "step": 101900
    },
    {
      "epoch": 164.39,
      "learning_rate": 0.08356791965790324,
      "loss": 0.9738,
      "step": 101920
    },
    {
      "epoch": 164.42,
      "learning_rate": 0.08356469385467742,
      "loss": 0.982,
      "step": 101940
    },
    {
      "epoch": 164.45,
      "learning_rate": 0.08356146805145162,
      "loss": 0.9383,
      "step": 101960
    },
    {
      "epoch": 164.48,
      "learning_rate": 0.0835582422482258,
      "loss": 0.9654,
      "step": 101980
    },
    {
      "epoch": 164.52,
      "learning_rate": 0.083555016445,
      "loss": 1.0234,
      "step": 102000
    },
    {
      "epoch": 164.55,
      "learning_rate": 0.0835517906417742,
      "loss": 0.9848,
      "step": 102020
    },
    {
      "epoch": 164.58,
      "learning_rate": 0.08354856483854839,
      "loss": 0.9755,
      "step": 102040
    },
    {
      "epoch": 164.61,
      "learning_rate": 0.08354533903532259,
      "loss": 1.0071,
      "step": 102060
    },
    {
      "epoch": 164.65,
      "learning_rate": 0.08354211323209679,
      "loss": 1.0215,
      "step": 102080
    },
    {
      "epoch": 164.68,
      "learning_rate": 0.08353888742887097,
      "loss": 1.0193,
      "step": 102100
    },
    {
      "epoch": 164.71,
      "learning_rate": 0.08353566162564517,
      "loss": 0.9899,
      "step": 102120
    },
    {
      "epoch": 164.74,
      "learning_rate": 0.08353243582241936,
      "loss": 1.0108,
      "step": 102140
    },
    {
      "epoch": 164.77,
      "learning_rate": 0.08352921001919356,
      "loss": 0.9784,
      "step": 102160
    },
    {
      "epoch": 164.81,
      "learning_rate": 0.08352598421596774,
      "loss": 0.9954,
      "step": 102180
    },
    {
      "epoch": 164.84,
      "learning_rate": 0.08352275841274194,
      "loss": 1.0138,
      "step": 102200
    },
    {
      "epoch": 164.87,
      "learning_rate": 0.08351953260951613,
      "loss": 0.9843,
      "step": 102220
    },
    {
      "epoch": 164.9,
      "learning_rate": 0.08351630680629032,
      "loss": 0.9855,
      "step": 102240
    },
    {
      "epoch": 164.94,
      "learning_rate": 0.08351308100306452,
      "loss": 0.9901,
      "step": 102260
    },
    {
      "epoch": 164.97,
      "learning_rate": 0.08350985519983871,
      "loss": 0.9917,
      "step": 102280
    },
    {
      "epoch": 165.0,
      "learning_rate": 0.08350662939661291,
      "loss": 0.997,
      "step": 102300
    },
    {
      "epoch": 165.0,
      "eval_accuracy": {
        "accuracy": 0.7341347279681524
      },
      "eval_loss": 1.361232876777649,
      "eval_runtime": 2.6477,
      "eval_samples_per_second": 4838.609,
      "eval_steps_per_second": 75.916,
      "step": 102300
    },
    {
      "epoch": 165.03,
      "learning_rate": 0.08350340359338711,
      "loss": 0.9936,
      "step": 102320
    },
    {
      "epoch": 165.06,
      "learning_rate": 0.08350017779016129,
      "loss": 0.9563,
      "step": 102340
    },
    {
      "epoch": 165.1,
      "learning_rate": 0.08349695198693549,
      "loss": 0.9995,
      "step": 102360
    },
    {
      "epoch": 165.13,
      "learning_rate": 0.08349372618370969,
      "loss": 1.0036,
      "step": 102380
    },
    {
      "epoch": 165.16,
      "learning_rate": 0.08349050038048388,
      "loss": 0.9766,
      "step": 102400
    },
    {
      "epoch": 165.19,
      "learning_rate": 0.08348727457725807,
      "loss": 0.9855,
      "step": 102420
    },
    {
      "epoch": 165.23,
      "learning_rate": 0.08348404877403226,
      "loss": 0.972,
      "step": 102440
    },
    {
      "epoch": 165.26,
      "learning_rate": 0.08348082297080646,
      "loss": 0.9528,
      "step": 102460
    },
    {
      "epoch": 165.29,
      "learning_rate": 0.08347759716758064,
      "loss": 1.0062,
      "step": 102480
    },
    {
      "epoch": 165.32,
      "learning_rate": 0.08347437136435484,
      "loss": 0.9579,
      "step": 102500
    },
    {
      "epoch": 165.35,
      "learning_rate": 0.08347114556112903,
      "loss": 0.9778,
      "step": 102520
    },
    {
      "epoch": 165.39,
      "learning_rate": 0.08346791975790323,
      "loss": 0.9493,
      "step": 102540
    },
    {
      "epoch": 165.42,
      "learning_rate": 0.08346469395467743,
      "loss": 0.9847,
      "step": 102560
    },
    {
      "epoch": 165.45,
      "learning_rate": 0.08346146815145161,
      "loss": 0.9805,
      "step": 102580
    },
    {
      "epoch": 165.48,
      "learning_rate": 0.08345824234822581,
      "loss": 0.9614,
      "step": 102600
    },
    {
      "epoch": 165.52,
      "learning_rate": 0.08345501654500001,
      "loss": 0.9653,
      "step": 102620
    },
    {
      "epoch": 165.55,
      "learning_rate": 0.0834517907417742,
      "loss": 1.0083,
      "step": 102640
    },
    {
      "epoch": 165.58,
      "learning_rate": 0.0834485649385484,
      "loss": 0.9743,
      "step": 102660
    },
    {
      "epoch": 165.61,
      "learning_rate": 0.0834453391353226,
      "loss": 1.0019,
      "step": 102680
    },
    {
      "epoch": 165.65,
      "learning_rate": 0.08344211333209678,
      "loss": 0.9908,
      "step": 102700
    },
    {
      "epoch": 165.68,
      "learning_rate": 0.08343888752887098,
      "loss": 0.9869,
      "step": 102720
    },
    {
      "epoch": 165.71,
      "learning_rate": 0.08343566172564516,
      "loss": 0.988,
      "step": 102740
    },
    {
      "epoch": 165.74,
      "learning_rate": 0.08343243592241936,
      "loss": 0.9546,
      "step": 102760
    },
    {
      "epoch": 165.77,
      "learning_rate": 0.08342921011919355,
      "loss": 0.9953,
      "step": 102780
    },
    {
      "epoch": 165.81,
      "learning_rate": 0.08342598431596775,
      "loss": 0.9797,
      "step": 102800
    },
    {
      "epoch": 165.84,
      "learning_rate": 0.08342275851274193,
      "loss": 1.0019,
      "step": 102820
    },
    {
      "epoch": 165.87,
      "learning_rate": 0.08341953270951613,
      "loss": 1.0177,
      "step": 102840
    },
    {
      "epoch": 165.9,
      "learning_rate": 0.08341630690629033,
      "loss": 0.9807,
      "step": 102860
    },
    {
      "epoch": 165.94,
      "learning_rate": 0.08341308110306452,
      "loss": 0.9689,
      "step": 102880
    },
    {
      "epoch": 165.97,
      "learning_rate": 0.08340985529983871,
      "loss": 0.9863,
      "step": 102900
    },
    {
      "epoch": 166.0,
      "learning_rate": 0.08340662949661291,
      "loss": 0.9873,
      "step": 102920
    },
    {
      "epoch": 166.0,
      "eval_accuracy": {
        "accuracy": 0.7405354773241746
      },
      "eval_loss": 1.3327668905258179,
      "eval_runtime": 3.1932,
      "eval_samples_per_second": 4011.988,
      "eval_steps_per_second": 62.947,
      "step": 102920
    },
    {
      "epoch": 166.03,
      "learning_rate": 0.0834034036933871,
      "loss": 0.9874,
      "step": 102940
    },
    {
      "epoch": 166.06,
      "learning_rate": 0.0834001778901613,
      "loss": 0.9724,
      "step": 102960
    },
    {
      "epoch": 166.1,
      "learning_rate": 0.0833969520869355,
      "loss": 0.9561,
      "step": 102980
    },
    {
      "epoch": 166.13,
      "learning_rate": 0.08339372628370968,
      "loss": 0.949,
      "step": 103000
    },
    {
      "epoch": 166.16,
      "learning_rate": 0.08339050048048388,
      "loss": 0.9738,
      "step": 103020
    },
    {
      "epoch": 166.19,
      "learning_rate": 0.08338727467725807,
      "loss": 0.9785,
      "step": 103040
    },
    {
      "epoch": 166.23,
      "learning_rate": 0.08338404887403227,
      "loss": 0.9575,
      "step": 103060
    },
    {
      "epoch": 166.26,
      "learning_rate": 0.08338082307080645,
      "loss": 0.9935,
      "step": 103080
    },
    {
      "epoch": 166.29,
      "learning_rate": 0.08337759726758065,
      "loss": 0.9973,
      "step": 103100
    },
    {
      "epoch": 166.32,
      "learning_rate": 0.08337437146435484,
      "loss": 0.9817,
      "step": 103120
    },
    {
      "epoch": 166.35,
      "learning_rate": 0.08337114566112903,
      "loss": 0.9696,
      "step": 103140
    },
    {
      "epoch": 166.39,
      "learning_rate": 0.08336791985790323,
      "loss": 0.9646,
      "step": 103160
    },
    {
      "epoch": 166.42,
      "learning_rate": 0.08336469405467742,
      "loss": 0.9752,
      "step": 103180
    },
    {
      "epoch": 166.45,
      "learning_rate": 0.08336146825145162,
      "loss": 0.993,
      "step": 103200
    },
    {
      "epoch": 166.48,
      "learning_rate": 0.08335824244822582,
      "loss": 1.0167,
      "step": 103220
    },
    {
      "epoch": 166.52,
      "learning_rate": 0.083355016645,
      "loss": 1.0135,
      "step": 103240
    },
    {
      "epoch": 166.55,
      "learning_rate": 0.0833517908417742,
      "loss": 0.9863,
      "step": 103260
    },
    {
      "epoch": 166.58,
      "learning_rate": 0.0833485650385484,
      "loss": 0.9772,
      "step": 103280
    },
    {
      "epoch": 166.61,
      "learning_rate": 0.08334533923532259,
      "loss": 0.9677,
      "step": 103300
    },
    {
      "epoch": 166.65,
      "learning_rate": 0.08334211343209678,
      "loss": 0.985,
      "step": 103320
    },
    {
      "epoch": 166.68,
      "learning_rate": 0.08333888762887097,
      "loss": 1.0057,
      "step": 103340
    },
    {
      "epoch": 166.71,
      "learning_rate": 0.08333566182564517,
      "loss": 0.9826,
      "step": 103360
    },
    {
      "epoch": 166.74,
      "learning_rate": 0.08333243602241935,
      "loss": 1.0272,
      "step": 103380
    },
    {
      "epoch": 166.77,
      "learning_rate": 0.08332921021919355,
      "loss": 0.9763,
      "step": 103400
    },
    {
      "epoch": 166.81,
      "learning_rate": 0.08332598441596774,
      "loss": 1.0069,
      "step": 103420
    },
    {
      "epoch": 166.84,
      "learning_rate": 0.08332275861274194,
      "loss": 0.9745,
      "step": 103440
    },
    {
      "epoch": 166.87,
      "learning_rate": 0.08331953280951614,
      "loss": 0.9998,
      "step": 103460
    },
    {
      "epoch": 166.9,
      "learning_rate": 0.08331630700629032,
      "loss": 0.9893,
      "step": 103480
    },
    {
      "epoch": 166.94,
      "learning_rate": 0.08331308120306452,
      "loss": 1.0307,
      "step": 103500
    },
    {
      "epoch": 166.97,
      "learning_rate": 0.08330985539983872,
      "loss": 0.9975,
      "step": 103520
    },
    {
      "epoch": 167.0,
      "learning_rate": 0.0833066295966129,
      "loss": 0.9983,
      "step": 103540
    },
    {
      "epoch": 167.0,
      "eval_accuracy": {
        "accuracy": 0.7347591913199594
      },
      "eval_loss": 1.3519275188446045,
      "eval_runtime": 2.8331,
      "eval_samples_per_second": 4521.942,
      "eval_steps_per_second": 70.948,
      "step": 103540
    },
    {
      "epoch": 167.03,
      "learning_rate": 0.0833034037933871,
      "loss": 0.9957,
      "step": 103560
    },
    {
      "epoch": 167.06,
      "learning_rate": 0.0833001779901613,
      "loss": 0.9612,
      "step": 103580
    },
    {
      "epoch": 167.1,
      "learning_rate": 0.08329695218693549,
      "loss": 0.9758,
      "step": 103600
    },
    {
      "epoch": 167.13,
      "learning_rate": 0.08329372638370969,
      "loss": 0.9512,
      "step": 103620
    },
    {
      "epoch": 167.16,
      "learning_rate": 0.08329050058048387,
      "loss": 0.9843,
      "step": 103640
    },
    {
      "epoch": 167.19,
      "learning_rate": 0.08328727477725807,
      "loss": 0.954,
      "step": 103660
    },
    {
      "epoch": 167.23,
      "learning_rate": 0.08328404897403226,
      "loss": 0.9851,
      "step": 103680
    },
    {
      "epoch": 167.26,
      "learning_rate": 0.08328082317080647,
      "loss": 0.9895,
      "step": 103700
    },
    {
      "epoch": 167.29,
      "learning_rate": 0.08327759736758064,
      "loss": 0.9845,
      "step": 103720
    },
    {
      "epoch": 167.32,
      "learning_rate": 0.08327437156435484,
      "loss": 1.0173,
      "step": 103740
    },
    {
      "epoch": 167.35,
      "learning_rate": 0.08327114576112904,
      "loss": 0.9853,
      "step": 103760
    },
    {
      "epoch": 167.39,
      "learning_rate": 0.08326791995790322,
      "loss": 0.9736,
      "step": 103780
    },
    {
      "epoch": 167.42,
      "learning_rate": 0.08326469415467742,
      "loss": 0.9737,
      "step": 103800
    },
    {
      "epoch": 167.45,
      "learning_rate": 0.08326146835145162,
      "loss": 0.9713,
      "step": 103820
    },
    {
      "epoch": 167.48,
      "learning_rate": 0.08325824254822581,
      "loss": 0.986,
      "step": 103840
    },
    {
      "epoch": 167.52,
      "learning_rate": 0.08325501674500001,
      "loss": 0.9786,
      "step": 103860
    },
    {
      "epoch": 167.55,
      "learning_rate": 0.0832517909417742,
      "loss": 0.9654,
      "step": 103880
    },
    {
      "epoch": 167.58,
      "learning_rate": 0.08324856513854839,
      "loss": 0.9673,
      "step": 103900
    },
    {
      "epoch": 167.61,
      "learning_rate": 0.08324533933532259,
      "loss": 0.9584,
      "step": 103920
    },
    {
      "epoch": 167.65,
      "learning_rate": 0.08324211353209679,
      "loss": 0.9472,
      "step": 103940
    },
    {
      "epoch": 167.68,
      "learning_rate": 0.08323888772887097,
      "loss": 0.9649,
      "step": 103960
    },
    {
      "epoch": 167.71,
      "learning_rate": 0.08323566192564516,
      "loss": 0.989,
      "step": 103980
    },
    {
      "epoch": 167.74,
      "learning_rate": 0.08323243612241936,
      "loss": 0.9705,
      "step": 104000
    },
    {
      "epoch": 167.77,
      "learning_rate": 0.08322921031919354,
      "loss": 0.9808,
      "step": 104020
    },
    {
      "epoch": 167.81,
      "learning_rate": 0.08322598451596774,
      "loss": 0.9922,
      "step": 104040
    },
    {
      "epoch": 167.84,
      "learning_rate": 0.08322275871274194,
      "loss": 0.9594,
      "step": 104060
    },
    {
      "epoch": 167.87,
      "learning_rate": 0.08321953290951613,
      "loss": 0.9582,
      "step": 104080
    },
    {
      "epoch": 167.9,
      "learning_rate": 0.08321630710629033,
      "loss": 0.9938,
      "step": 104100
    },
    {
      "epoch": 167.94,
      "learning_rate": 0.08321308130306453,
      "loss": 0.9719,
      "step": 104120
    },
    {
      "epoch": 167.97,
      "learning_rate": 0.08320985549983871,
      "loss": 0.9843,
      "step": 104140
    },
    {
      "epoch": 168.0,
      "learning_rate": 0.08320679098677419,
      "loss": 1.0323,
      "step": 104160
    },
    {
      "epoch": 168.0,
      "eval_accuracy": {
        "accuracy": 0.7349933650768871
      },
      "eval_loss": 1.3892760276794434,
      "eval_runtime": 2.774,
      "eval_samples_per_second": 4618.32,
      "eval_steps_per_second": 72.46,
      "step": 104160
    },
    {
      "epoch": 168.03,
      "learning_rate": 0.08320356518354839,
      "loss": 1.0003,
      "step": 104180
    },
    {
      "epoch": 168.06,
      "learning_rate": 0.08320033938032258,
      "loss": 0.9841,
      "step": 104200
    },
    {
      "epoch": 168.1,
      "learning_rate": 0.08319711357709678,
      "loss": 0.9749,
      "step": 104220
    },
    {
      "epoch": 168.13,
      "learning_rate": 0.08319388777387098,
      "loss": 0.9616,
      "step": 104240
    },
    {
      "epoch": 168.16,
      "learning_rate": 0.08319066197064516,
      "loss": 0.939,
      "step": 104260
    },
    {
      "epoch": 168.19,
      "learning_rate": 0.08318743616741936,
      "loss": 0.9447,
      "step": 104280
    },
    {
      "epoch": 168.23,
      "learning_rate": 0.08318421036419356,
      "loss": 0.9836,
      "step": 104300
    },
    {
      "epoch": 168.26,
      "learning_rate": 0.08318098456096774,
      "loss": 0.9654,
      "step": 104320
    },
    {
      "epoch": 168.29,
      "learning_rate": 0.08317775875774194,
      "loss": 0.9643,
      "step": 104340
    },
    {
      "epoch": 168.32,
      "learning_rate": 0.08317453295451614,
      "loss": 0.9749,
      "step": 104360
    },
    {
      "epoch": 168.35,
      "learning_rate": 0.08317130715129033,
      "loss": 0.9751,
      "step": 104380
    },
    {
      "epoch": 168.39,
      "learning_rate": 0.08316808134806453,
      "loss": 1.0364,
      "step": 104400
    },
    {
      "epoch": 168.42,
      "learning_rate": 0.08316485554483871,
      "loss": 1.0205,
      "step": 104420
    },
    {
      "epoch": 168.45,
      "learning_rate": 0.08316162974161291,
      "loss": 1.0225,
      "step": 104440
    },
    {
      "epoch": 168.48,
      "learning_rate": 0.0831584039383871,
      "loss": 0.9669,
      "step": 104460
    },
    {
      "epoch": 168.52,
      "learning_rate": 0.0831551781351613,
      "loss": 0.9541,
      "step": 104480
    },
    {
      "epoch": 168.55,
      "learning_rate": 0.08315195233193548,
      "loss": 0.9447,
      "step": 104500
    },
    {
      "epoch": 168.58,
      "learning_rate": 0.08314872652870968,
      "loss": 0.972,
      "step": 104520
    },
    {
      "epoch": 168.61,
      "learning_rate": 0.08314550072548388,
      "loss": 0.9994,
      "step": 104540
    },
    {
      "epoch": 168.65,
      "learning_rate": 0.08314227492225806,
      "loss": 1.0133,
      "step": 104560
    },
    {
      "epoch": 168.68,
      "learning_rate": 0.08313904911903226,
      "loss": 0.9832,
      "step": 104580
    },
    {
      "epoch": 168.71,
      "learning_rate": 0.08313582331580646,
      "loss": 1.0108,
      "step": 104600
    },
    {
      "epoch": 168.74,
      "learning_rate": 0.08313259751258065,
      "loss": 0.958,
      "step": 104620
    },
    {
      "epoch": 168.77,
      "learning_rate": 0.08312937170935485,
      "loss": 0.9864,
      "step": 104640
    },
    {
      "epoch": 168.81,
      "learning_rate": 0.08312614590612905,
      "loss": 0.9861,
      "step": 104660
    },
    {
      "epoch": 168.84,
      "learning_rate": 0.08312292010290323,
      "loss": 1.0074,
      "step": 104680
    },
    {
      "epoch": 168.87,
      "learning_rate": 0.08311969429967743,
      "loss": 1.0152,
      "step": 104700
    },
    {
      "epoch": 168.9,
      "learning_rate": 0.08311646849645161,
      "loss": 0.9981,
      "step": 104720
    },
    {
      "epoch": 168.94,
      "learning_rate": 0.08311324269322581,
      "loss": 1.0049,
      "step": 104740
    },
    {
      "epoch": 168.97,
      "learning_rate": 0.08311001689,
      "loss": 1.0027,
      "step": 104760
    },
    {
      "epoch": 169.0,
      "learning_rate": 0.08310679108677421,
      "loss": 0.9663,
      "step": 104780
    },
    {
      "epoch": 169.0,
      "eval_accuracy": {
        "accuracy": 0.7378034501600187
      },
      "eval_loss": 1.3032723665237427,
      "eval_runtime": 2.85,
      "eval_samples_per_second": 4495.015,
      "eval_steps_per_second": 70.525,
      "step": 104780
    },
    {
      "epoch": 169.03,
      "learning_rate": 0.08310356528354838,
      "loss": 0.9648,
      "step": 104800
    },
    {
      "epoch": 169.06,
      "learning_rate": 0.08310033948032258,
      "loss": 0.9483,
      "step": 104820
    },
    {
      "epoch": 169.1,
      "learning_rate": 0.08309711367709678,
      "loss": 0.9694,
      "step": 104840
    },
    {
      "epoch": 169.13,
      "learning_rate": 0.08309388787387097,
      "loss": 0.9492,
      "step": 104860
    },
    {
      "epoch": 169.16,
      "learning_rate": 0.08309066207064517,
      "loss": 0.9465,
      "step": 104880
    },
    {
      "epoch": 169.19,
      "learning_rate": 0.08308743626741937,
      "loss": 0.9579,
      "step": 104900
    },
    {
      "epoch": 169.23,
      "learning_rate": 0.08308421046419355,
      "loss": 0.9677,
      "step": 104920
    },
    {
      "epoch": 169.26,
      "learning_rate": 0.08308098466096775,
      "loss": 0.9632,
      "step": 104940
    },
    {
      "epoch": 169.29,
      "learning_rate": 0.08307775885774195,
      "loss": 0.9446,
      "step": 104960
    },
    {
      "epoch": 169.32,
      "learning_rate": 0.08307453305451613,
      "loss": 0.9594,
      "step": 104980
    },
    {
      "epoch": 169.35,
      "learning_rate": 0.08307130725129033,
      "loss": 0.9865,
      "step": 105000
    },
    {
      "epoch": 169.39,
      "learning_rate": 0.08306808144806452,
      "loss": 0.9868,
      "step": 105020
    },
    {
      "epoch": 169.42,
      "learning_rate": 0.08306485564483872,
      "loss": 0.9804,
      "step": 105040
    },
    {
      "epoch": 169.45,
      "learning_rate": 0.0830616298416129,
      "loss": 1.0012,
      "step": 105060
    },
    {
      "epoch": 169.48,
      "learning_rate": 0.0830584040383871,
      "loss": 0.9605,
      "step": 105080
    },
    {
      "epoch": 169.52,
      "learning_rate": 0.08305517823516129,
      "loss": 0.9974,
      "step": 105100
    },
    {
      "epoch": 169.55,
      "learning_rate": 0.08305195243193549,
      "loss": 1.0052,
      "step": 105120
    },
    {
      "epoch": 169.58,
      "learning_rate": 0.08304872662870968,
      "loss": 0.9523,
      "step": 105140
    },
    {
      "epoch": 169.61,
      "learning_rate": 0.08304550082548387,
      "loss": 0.9798,
      "step": 105160
    },
    {
      "epoch": 169.65,
      "learning_rate": 0.08304227502225807,
      "loss": 1.0065,
      "step": 105180
    },
    {
      "epoch": 169.68,
      "learning_rate": 0.08303904921903227,
      "loss": 1.0309,
      "step": 105200
    },
    {
      "epoch": 169.71,
      "learning_rate": 0.08303582341580645,
      "loss": 0.9848,
      "step": 105220
    },
    {
      "epoch": 169.74,
      "learning_rate": 0.08303259761258065,
      "loss": 1.0137,
      "step": 105240
    },
    {
      "epoch": 169.77,
      "learning_rate": 0.08302937180935485,
      "loss": 1.0017,
      "step": 105260
    },
    {
      "epoch": 169.81,
      "learning_rate": 0.08302614600612904,
      "loss": 1.013,
      "step": 105280
    },
    {
      "epoch": 169.84,
      "learning_rate": 0.08302292020290324,
      "loss": 0.9985,
      "step": 105300
    },
    {
      "epoch": 169.87,
      "learning_rate": 0.08301969439967744,
      "loss": 0.9822,
      "step": 105320
    },
    {
      "epoch": 169.9,
      "learning_rate": 0.08301646859645162,
      "loss": 0.9639,
      "step": 105340
    },
    {
      "epoch": 169.94,
      "learning_rate": 0.0830132427932258,
      "loss": 0.9805,
      "step": 105360
    },
    {
      "epoch": 169.97,
      "learning_rate": 0.08301001699,
      "loss": 0.9889,
      "step": 105380
    },
    {
      "epoch": 170.0,
      "learning_rate": 0.08300679118677419,
      "loss": 1.0087,
      "step": 105400
    },
    {
      "epoch": 170.0,
      "eval_accuracy": {
        "accuracy": 0.7404574194051986
      },
      "eval_loss": 1.3407561779022217,
      "eval_runtime": 3.0048,
      "eval_samples_per_second": 4263.478,
      "eval_steps_per_second": 66.892,
      "step": 105400
    },
    {
      "epoch": 170.03,
      "learning_rate": 0.08300356538354839,
      "loss": 1.0502,
      "step": 105420
    },
    {
      "epoch": 170.06,
      "learning_rate": 0.08300033958032259,
      "loss": 0.9813,
      "step": 105440
    },
    {
      "epoch": 170.1,
      "learning_rate": 0.08299711377709677,
      "loss": 0.9621,
      "step": 105460
    },
    {
      "epoch": 170.13,
      "learning_rate": 0.08299388797387097,
      "loss": 0.969,
      "step": 105480
    },
    {
      "epoch": 170.16,
      "learning_rate": 0.08299066217064517,
      "loss": 0.9615,
      "step": 105500
    },
    {
      "epoch": 170.19,
      "learning_rate": 0.08298743636741936,
      "loss": 0.9622,
      "step": 105520
    },
    {
      "epoch": 170.23,
      "learning_rate": 0.08298421056419356,
      "loss": 0.9575,
      "step": 105540
    },
    {
      "epoch": 170.26,
      "learning_rate": 0.08298098476096775,
      "loss": 0.9549,
      "step": 105560
    },
    {
      "epoch": 170.29,
      "learning_rate": 0.08297775895774194,
      "loss": 0.975,
      "step": 105580
    },
    {
      "epoch": 170.32,
      "learning_rate": 0.08297453315451614,
      "loss": 0.9992,
      "step": 105600
    },
    {
      "epoch": 170.35,
      "learning_rate": 0.08297130735129032,
      "loss": 1.009,
      "step": 105620
    },
    {
      "epoch": 170.39,
      "learning_rate": 0.08296808154806452,
      "loss": 0.9808,
      "step": 105640
    },
    {
      "epoch": 170.42,
      "learning_rate": 0.08296485574483871,
      "loss": 0.9682,
      "step": 105660
    },
    {
      "epoch": 170.45,
      "learning_rate": 0.08296162994161291,
      "loss": 0.9778,
      "step": 105680
    },
    {
      "epoch": 170.48,
      "learning_rate": 0.08295840413838709,
      "loss": 0.9854,
      "step": 105700
    },
    {
      "epoch": 170.52,
      "learning_rate": 0.08295517833516129,
      "loss": 0.9944,
      "step": 105720
    },
    {
      "epoch": 170.55,
      "learning_rate": 0.08295195253193549,
      "loss": 0.9781,
      "step": 105740
    },
    {
      "epoch": 170.58,
      "learning_rate": 0.08294872672870968,
      "loss": 1.0161,
      "step": 105760
    },
    {
      "epoch": 170.61,
      "learning_rate": 0.08294550092548388,
      "loss": 0.9844,
      "step": 105780
    },
    {
      "epoch": 170.65,
      "learning_rate": 0.08294227512225807,
      "loss": 0.9646,
      "step": 105800
    },
    {
      "epoch": 170.68,
      "learning_rate": 0.08293904931903226,
      "loss": 0.9839,
      "step": 105820
    },
    {
      "epoch": 170.71,
      "learning_rate": 0.08293582351580646,
      "loss": 0.9756,
      "step": 105840
    },
    {
      "epoch": 170.74,
      "learning_rate": 0.08293259771258066,
      "loss": 0.9857,
      "step": 105860
    },
    {
      "epoch": 170.77,
      "learning_rate": 0.08292937190935484,
      "loss": 0.9478,
      "step": 105880
    },
    {
      "epoch": 170.81,
      "learning_rate": 0.08292614610612904,
      "loss": 0.9866,
      "step": 105900
    },
    {
      "epoch": 170.84,
      "learning_rate": 0.08292292030290323,
      "loss": 1.012,
      "step": 105920
    },
    {
      "epoch": 170.87,
      "learning_rate": 0.08291969449967743,
      "loss": 1.0405,
      "step": 105940
    },
    {
      "epoch": 170.9,
      "learning_rate": 0.08291646869645161,
      "loss": 1.0567,
      "step": 105960
    },
    {
      "epoch": 170.94,
      "learning_rate": 0.08291324289322581,
      "loss": 1.0425,
      "step": 105980
    },
    {
      "epoch": 170.97,
      "learning_rate": 0.08291001709,
      "loss": 0.981,
      "step": 106000
    },
    {
      "epoch": 171.0,
      "learning_rate": 0.08290679128677421,
      "loss": 1.0136,
      "step": 106020
    },
    {
      "epoch": 171.0,
      "eval_accuracy": {
        "accuracy": 0.7282023261259855
      },
      "eval_loss": 1.4236502647399902,
      "eval_runtime": 3.7344,
      "eval_samples_per_second": 3430.558,
      "eval_steps_per_second": 53.824,
      "step": 106020
    },
    {
      "epoch": 171.03,
      "learning_rate": 0.0829035654835484,
      "loss": 1.0281,
      "step": 106040
    },
    {
      "epoch": 171.06,
      "learning_rate": 0.08290033968032258,
      "loss": 0.9553,
      "step": 106060
    },
    {
      "epoch": 171.1,
      "learning_rate": 0.08289711387709678,
      "loss": 0.9664,
      "step": 106080
    },
    {
      "epoch": 171.13,
      "learning_rate": 0.08289388807387098,
      "loss": 0.9635,
      "step": 106100
    },
    {
      "epoch": 171.16,
      "learning_rate": 0.08289066227064516,
      "loss": 0.9165,
      "step": 106120
    },
    {
      "epoch": 171.19,
      "learning_rate": 0.08288743646741936,
      "loss": 0.945,
      "step": 106140
    },
    {
      "epoch": 171.23,
      "learning_rate": 0.08288421066419355,
      "loss": 0.9702,
      "step": 106160
    },
    {
      "epoch": 171.26,
      "learning_rate": 0.08288098486096775,
      "loss": 0.9746,
      "step": 106180
    },
    {
      "epoch": 171.29,
      "learning_rate": 0.08287775905774195,
      "loss": 0.9703,
      "step": 106200
    },
    {
      "epoch": 171.32,
      "learning_rate": 0.08287453325451613,
      "loss": 0.9795,
      "step": 106220
    },
    {
      "epoch": 171.35,
      "learning_rate": 0.08287130745129033,
      "loss": 0.9547,
      "step": 106240
    },
    {
      "epoch": 171.39,
      "learning_rate": 0.08286808164806453,
      "loss": 0.9574,
      "step": 106260
    },
    {
      "epoch": 171.42,
      "learning_rate": 0.08286485584483871,
      "loss": 0.989,
      "step": 106280
    },
    {
      "epoch": 171.45,
      "learning_rate": 0.0828616300416129,
      "loss": 0.9781,
      "step": 106300
    },
    {
      "epoch": 171.48,
      "learning_rate": 0.08285840423838711,
      "loss": 0.9702,
      "step": 106320
    },
    {
      "epoch": 171.52,
      "learning_rate": 0.0828551784351613,
      "loss": 1.0053,
      "step": 106340
    },
    {
      "epoch": 171.55,
      "learning_rate": 0.08285195263193548,
      "loss": 0.9929,
      "step": 106360
    },
    {
      "epoch": 171.58,
      "learning_rate": 0.08284872682870968,
      "loss": 0.981,
      "step": 106380
    },
    {
      "epoch": 171.61,
      "learning_rate": 0.08284550102548388,
      "loss": 0.9874,
      "step": 106400
    },
    {
      "epoch": 171.65,
      "learning_rate": 0.08284227522225807,
      "loss": 0.9625,
      "step": 106420
    },
    {
      "epoch": 171.68,
      "learning_rate": 0.08283904941903227,
      "loss": 0.9697,
      "step": 106440
    },
    {
      "epoch": 171.71,
      "learning_rate": 0.08283582361580645,
      "loss": 0.973,
      "step": 106460
    },
    {
      "epoch": 171.74,
      "learning_rate": 0.08283259781258065,
      "loss": 0.9821,
      "step": 106480
    },
    {
      "epoch": 171.77,
      "learning_rate": 0.08282937200935485,
      "loss": 0.9762,
      "step": 106500
    },
    {
      "epoch": 171.81,
      "learning_rate": 0.08282614620612903,
      "loss": 0.981,
      "step": 106520
    },
    {
      "epoch": 171.84,
      "learning_rate": 0.08282292040290323,
      "loss": 0.9734,
      "step": 106540
    },
    {
      "epoch": 171.87,
      "learning_rate": 0.08281969459967743,
      "loss": 0.9793,
      "step": 106560
    },
    {
      "epoch": 171.9,
      "learning_rate": 0.08281646879645162,
      "loss": 0.9679,
      "step": 106580
    },
    {
      "epoch": 171.94,
      "learning_rate": 0.0828132429932258,
      "loss": 0.9894,
      "step": 106600
    },
    {
      "epoch": 171.97,
      "learning_rate": 0.08281001719000002,
      "loss": 0.9909,
      "step": 106620
    },
    {
      "epoch": 172.0,
      "learning_rate": 0.0828069526769355,
      "loss": 1.0009,
      "step": 106640
    },
    {
      "epoch": 172.0,
      "eval_accuracy": {
        "accuracy": 0.7472484583561002
      },
      "eval_loss": 1.282447099685669,
      "eval_runtime": 2.8401,
      "eval_samples_per_second": 4510.811,
      "eval_steps_per_second": 70.773,
      "step": 106640
    },
    {
      "epoch": 172.03,
      "learning_rate": 0.08280372687370968,
      "loss": 0.9606,
      "step": 106660
    },
    {
      "epoch": 172.06,
      "learning_rate": 0.08280050107048388,
      "loss": 0.9406,
      "step": 106680
    },
    {
      "epoch": 172.1,
      "learning_rate": 0.08279727526725807,
      "loss": 0.9276,
      "step": 106700
    },
    {
      "epoch": 172.13,
      "learning_rate": 0.08279404946403227,
      "loss": 0.9482,
      "step": 106720
    },
    {
      "epoch": 172.16,
      "learning_rate": 0.08279082366080645,
      "loss": 0.9522,
      "step": 106740
    },
    {
      "epoch": 172.19,
      "learning_rate": 0.08278759785758065,
      "loss": 1.0046,
      "step": 106760
    },
    {
      "epoch": 172.23,
      "learning_rate": 0.08278437205435484,
      "loss": 0.9911,
      "step": 106780
    },
    {
      "epoch": 172.26,
      "learning_rate": 0.08278114625112903,
      "loss": 0.9803,
      "step": 106800
    },
    {
      "epoch": 172.29,
      "learning_rate": 0.08277792044790323,
      "loss": 0.9738,
      "step": 106820
    },
    {
      "epoch": 172.32,
      "learning_rate": 0.08277469464467742,
      "loss": 1.004,
      "step": 106840
    },
    {
      "epoch": 172.35,
      "learning_rate": 0.08277146884145162,
      "loss": 0.9645,
      "step": 106860
    },
    {
      "epoch": 172.39,
      "learning_rate": 0.08276824303822582,
      "loss": 0.9779,
      "step": 106880
    },
    {
      "epoch": 172.42,
      "learning_rate": 0.082765017235,
      "loss": 1.0217,
      "step": 106900
    },
    {
      "epoch": 172.45,
      "learning_rate": 0.0827617914317742,
      "loss": 0.9915,
      "step": 106920
    },
    {
      "epoch": 172.48,
      "learning_rate": 0.0827585656285484,
      "loss": 1.0093,
      "step": 106940
    },
    {
      "epoch": 172.52,
      "learning_rate": 0.08275533982532259,
      "loss": 0.9638,
      "step": 106960
    },
    {
      "epoch": 172.55,
      "learning_rate": 0.08275211402209678,
      "loss": 0.9838,
      "step": 106980
    },
    {
      "epoch": 172.58,
      "learning_rate": 0.08274888821887097,
      "loss": 0.9716,
      "step": 107000
    },
    {
      "epoch": 172.61,
      "learning_rate": 0.08274566241564517,
      "loss": 0.9886,
      "step": 107020
    },
    {
      "epoch": 172.65,
      "learning_rate": 0.08274243661241935,
      "loss": 0.9792,
      "step": 107040
    },
    {
      "epoch": 172.68,
      "learning_rate": 0.08273921080919355,
      "loss": 0.9399,
      "step": 107060
    },
    {
      "epoch": 172.71,
      "learning_rate": 0.08273598500596774,
      "loss": 0.9762,
      "step": 107080
    },
    {
      "epoch": 172.74,
      "learning_rate": 0.08273275920274195,
      "loss": 0.9765,
      "step": 107100
    },
    {
      "epoch": 172.77,
      "learning_rate": 0.08272953339951614,
      "loss": 0.9512,
      "step": 107120
    },
    {
      "epoch": 172.81,
      "learning_rate": 0.08272630759629032,
      "loss": 0.9475,
      "step": 107140
    },
    {
      "epoch": 172.84,
      "learning_rate": 0.08272308179306452,
      "loss": 0.994,
      "step": 107160
    },
    {
      "epoch": 172.87,
      "learning_rate": 0.08271985598983872,
      "loss": 1.0021,
      "step": 107180
    },
    {
      "epoch": 172.9,
      "learning_rate": 0.0827166301866129,
      "loss": 0.9837,
      "step": 107200
    },
    {
      "epoch": 172.94,
      "learning_rate": 0.0827134043833871,
      "loss": 1.0344,
      "step": 107220
    },
    {
      "epoch": 172.97,
      "learning_rate": 0.08271017858016129,
      "loss": 1.0221,
      "step": 107240
    },
    {
      "epoch": 173.0,
      "learning_rate": 0.08270695277693549,
      "loss": 1.0271,
      "step": 107260
    },
    {
      "epoch": 173.0,
      "eval_accuracy": {
        "accuracy": 0.7367886972133323
      },
      "eval_loss": 1.3772296905517578,
      "eval_runtime": 3.6087,
      "eval_samples_per_second": 3550.048,
      "eval_steps_per_second": 55.699,
      "step": 107260
    },
    {
      "epoch": 173.03,
      "learning_rate": 0.08270372697370969,
      "loss": 1.0247,
      "step": 107280
    },
    {
      "epoch": 173.06,
      "learning_rate": 0.08270050117048387,
      "loss": 1.0009,
      "step": 107300
    },
    {
      "epoch": 173.1,
      "learning_rate": 0.08269727536725807,
      "loss": 0.9595,
      "step": 107320
    },
    {
      "epoch": 173.13,
      "learning_rate": 0.08269404956403226,
      "loss": 0.9453,
      "step": 107340
    },
    {
      "epoch": 173.16,
      "learning_rate": 0.08269082376080646,
      "loss": 0.9541,
      "step": 107360
    },
    {
      "epoch": 173.19,
      "learning_rate": 0.08268759795758064,
      "loss": 0.945,
      "step": 107380
    },
    {
      "epoch": 173.23,
      "learning_rate": 0.08268437215435485,
      "loss": 0.9329,
      "step": 107400
    },
    {
      "epoch": 173.26,
      "learning_rate": 0.08268114635112904,
      "loss": 0.9829,
      "step": 107420
    },
    {
      "epoch": 173.29,
      "learning_rate": 0.08267792054790322,
      "loss": 0.9602,
      "step": 107440
    },
    {
      "epoch": 173.32,
      "learning_rate": 0.08267469474467742,
      "loss": 0.964,
      "step": 107460
    },
    {
      "epoch": 173.35,
      "learning_rate": 0.08267146894145162,
      "loss": 0.9974,
      "step": 107480
    },
    {
      "epoch": 173.39,
      "learning_rate": 0.08266824313822581,
      "loss": 0.9865,
      "step": 107500
    },
    {
      "epoch": 173.42,
      "learning_rate": 0.08266501733500001,
      "loss": 0.9539,
      "step": 107520
    },
    {
      "epoch": 173.45,
      "learning_rate": 0.08266179153177419,
      "loss": 0.9566,
      "step": 107540
    },
    {
      "epoch": 173.48,
      "learning_rate": 0.08265856572854839,
      "loss": 0.9966,
      "step": 107560
    },
    {
      "epoch": 173.52,
      "learning_rate": 0.08265533992532259,
      "loss": 0.9947,
      "step": 107580
    },
    {
      "epoch": 173.55,
      "learning_rate": 0.08265211412209678,
      "loss": 0.9715,
      "step": 107600
    },
    {
      "epoch": 173.58,
      "learning_rate": 0.08264888831887097,
      "loss": 0.9863,
      "step": 107620
    },
    {
      "epoch": 173.61,
      "learning_rate": 0.08264566251564517,
      "loss": 0.9918,
      "step": 107640
    },
    {
      "epoch": 173.65,
      "learning_rate": 0.08264243671241936,
      "loss": 0.9602,
      "step": 107660
    },
    {
      "epoch": 173.68,
      "learning_rate": 0.08263921090919354,
      "loss": 0.9906,
      "step": 107680
    },
    {
      "epoch": 173.71,
      "learning_rate": 0.08263598510596776,
      "loss": 1.0051,
      "step": 107700
    },
    {
      "epoch": 173.74,
      "learning_rate": 0.08263275930274194,
      "loss": 0.9757,
      "step": 107720
    },
    {
      "epoch": 173.77,
      "learning_rate": 0.08262953349951613,
      "loss": 0.9832,
      "step": 107740
    },
    {
      "epoch": 173.81,
      "learning_rate": 0.08262630769629033,
      "loss": 0.9845,
      "step": 107760
    },
    {
      "epoch": 173.84,
      "learning_rate": 0.08262308189306451,
      "loss": 0.9717,
      "step": 107780
    },
    {
      "epoch": 173.87,
      "learning_rate": 0.08261985608983871,
      "loss": 1.0019,
      "step": 107800
    },
    {
      "epoch": 173.9,
      "learning_rate": 0.08261663028661291,
      "loss": 0.9812,
      "step": 107820
    },
    {
      "epoch": 173.94,
      "learning_rate": 0.0826134044833871,
      "loss": 0.9739,
      "step": 107840
    },
    {
      "epoch": 173.97,
      "learning_rate": 0.0826101786801613,
      "loss": 0.9532,
      "step": 107860
    },
    {
      "epoch": 174.0,
      "learning_rate": 0.0826069528769355,
      "loss": 0.988,
      "step": 107880
    },
    {
      "epoch": 174.0,
      "eval_accuracy": {
        "accuracy": 0.7275778627741785
      },
      "eval_loss": 1.38138747215271,
      "eval_runtime": 2.6977,
      "eval_samples_per_second": 4748.884,
      "eval_steps_per_second": 74.508,
      "step": 107880
    },
    {
      "epoch": 174.03,
      "learning_rate": 0.08260372707370968,
      "loss": 1.0457,
      "step": 107900
    },
    {
      "epoch": 174.06,
      "learning_rate": 0.08260050127048388,
      "loss": 0.9443,
      "step": 107920
    },
    {
      "epoch": 174.1,
      "learning_rate": 0.08259727546725808,
      "loss": 0.9437,
      "step": 107940
    },
    {
      "epoch": 174.13,
      "learning_rate": 0.08259404966403226,
      "loss": 0.9395,
      "step": 107960
    },
    {
      "epoch": 174.16,
      "learning_rate": 0.08259082386080645,
      "loss": 0.9477,
      "step": 107980
    },
    {
      "epoch": 174.19,
      "learning_rate": 0.08258759805758066,
      "loss": 0.9557,
      "step": 108000
    },
    {
      "epoch": 174.23,
      "learning_rate": 0.08258437225435485,
      "loss": 0.9796,
      "step": 108020
    },
    {
      "epoch": 174.26,
      "learning_rate": 0.08258114645112903,
      "loss": 1.0063,
      "step": 108040
    },
    {
      "epoch": 174.29,
      "learning_rate": 0.08257792064790323,
      "loss": 0.9562,
      "step": 108060
    },
    {
      "epoch": 174.32,
      "learning_rate": 0.08257469484467742,
      "loss": 0.9518,
      "step": 108080
    },
    {
      "epoch": 174.35,
      "learning_rate": 0.08257146904145161,
      "loss": 0.9385,
      "step": 108100
    },
    {
      "epoch": 174.39,
      "learning_rate": 0.08256824323822581,
      "loss": 0.9686,
      "step": 108120
    },
    {
      "epoch": 174.42,
      "learning_rate": 0.082565017435,
      "loss": 0.9903,
      "step": 108140
    },
    {
      "epoch": 174.45,
      "learning_rate": 0.0825617916317742,
      "loss": 0.999,
      "step": 108160
    },
    {
      "epoch": 174.48,
      "learning_rate": 0.0825585658285484,
      "loss": 0.9476,
      "step": 108180
    },
    {
      "epoch": 174.52,
      "learning_rate": 0.08255534002532258,
      "loss": 0.9851,
      "step": 108200
    },
    {
      "epoch": 174.55,
      "learning_rate": 0.08255211422209678,
      "loss": 0.9538,
      "step": 108220
    },
    {
      "epoch": 174.58,
      "learning_rate": 0.08254888841887098,
      "loss": 0.9904,
      "step": 108240
    },
    {
      "epoch": 174.61,
      "learning_rate": 0.08254566261564517,
      "loss": 1.0,
      "step": 108260
    },
    {
      "epoch": 174.65,
      "learning_rate": 0.08254243681241935,
      "loss": 0.9922,
      "step": 108280
    },
    {
      "epoch": 174.68,
      "learning_rate": 0.08253921100919356,
      "loss": 1.0296,
      "step": 108300
    },
    {
      "epoch": 174.71,
      "learning_rate": 0.08253598520596774,
      "loss": 0.9608,
      "step": 108320
    },
    {
      "epoch": 174.74,
      "learning_rate": 0.08253275940274195,
      "loss": 0.9902,
      "step": 108340
    },
    {
      "epoch": 174.77,
      "learning_rate": 0.08252953359951613,
      "loss": 0.9785,
      "step": 108360
    },
    {
      "epoch": 174.81,
      "learning_rate": 0.08252630779629032,
      "loss": 0.97,
      "step": 108380
    },
    {
      "epoch": 174.84,
      "learning_rate": 0.08252308199306452,
      "loss": 0.9907,
      "step": 108400
    },
    {
      "epoch": 174.87,
      "learning_rate": 0.08251985618983872,
      "loss": 0.9849,
      "step": 108420
    },
    {
      "epoch": 174.9,
      "learning_rate": 0.0825166303866129,
      "loss": 0.9733,
      "step": 108440
    },
    {
      "epoch": 174.94,
      "learning_rate": 0.0825134045833871,
      "loss": 0.9772,
      "step": 108460
    },
    {
      "epoch": 174.97,
      "learning_rate": 0.0825101787801613,
      "loss": 0.983,
      "step": 108480
    },
    {
      "epoch": 175.0,
      "learning_rate": 0.08250695297693549,
      "loss": 0.9642,
      "step": 108500
    },
    {
      "epoch": 175.0,
      "eval_accuracy": {
        "accuracy": 0.7379595659979705
      },
      "eval_loss": 1.323494553565979,
      "eval_runtime": 2.8807,
      "eval_samples_per_second": 4447.242,
      "eval_steps_per_second": 69.776,
      "step": 108500
    },
    {
      "epoch": 175.03,
      "learning_rate": 0.08250372717370968,
      "loss": 0.986,
      "step": 108520
    },
    {
      "epoch": 175.06,
      "learning_rate": 0.08250050137048388,
      "loss": 0.9417,
      "step": 108540
    },
    {
      "epoch": 175.1,
      "learning_rate": 0.08249727556725807,
      "loss": 0.9293,
      "step": 108560
    },
    {
      "epoch": 175.13,
      "learning_rate": 0.08249404976403227,
      "loss": 0.9533,
      "step": 108580
    },
    {
      "epoch": 175.16,
      "learning_rate": 0.08249082396080647,
      "loss": 0.9698,
      "step": 108600
    },
    {
      "epoch": 175.19,
      "learning_rate": 0.08248759815758064,
      "loss": 0.9456,
      "step": 108620
    },
    {
      "epoch": 175.23,
      "learning_rate": 0.08248437235435485,
      "loss": 0.9764,
      "step": 108640
    },
    {
      "epoch": 175.26,
      "learning_rate": 0.08248114655112904,
      "loss": 0.9517,
      "step": 108660
    },
    {
      "epoch": 175.29,
      "learning_rate": 0.08247792074790322,
      "loss": 0.9478,
      "step": 108680
    },
    {
      "epoch": 175.32,
      "learning_rate": 0.08247469494467742,
      "loss": 0.9576,
      "step": 108700
    },
    {
      "epoch": 175.35,
      "learning_rate": 0.08247146914145162,
      "loss": 0.972,
      "step": 108720
    },
    {
      "epoch": 175.39,
      "learning_rate": 0.0824682433382258,
      "loss": 0.9746,
      "step": 108740
    },
    {
      "epoch": 175.42,
      "learning_rate": 0.082465017535,
      "loss": 0.96,
      "step": 108760
    },
    {
      "epoch": 175.45,
      "learning_rate": 0.0824617917317742,
      "loss": 0.9734,
      "step": 108780
    },
    {
      "epoch": 175.48,
      "learning_rate": 0.08245856592854839,
      "loss": 0.9656,
      "step": 108800
    },
    {
      "epoch": 175.52,
      "learning_rate": 0.08245550141548387,
      "loss": 0.9741,
      "step": 108820
    },
    {
      "epoch": 175.55,
      "learning_rate": 0.08245227561225807,
      "loss": 0.9703,
      "step": 108840
    },
    {
      "epoch": 175.58,
      "learning_rate": 0.08244904980903225,
      "loss": 0.9913,
      "step": 108860
    },
    {
      "epoch": 175.61,
      "learning_rate": 0.08244582400580645,
      "loss": 0.9777,
      "step": 108880
    },
    {
      "epoch": 175.65,
      "learning_rate": 0.08244259820258065,
      "loss": 0.9805,
      "step": 108900
    },
    {
      "epoch": 175.68,
      "learning_rate": 0.08243937239935484,
      "loss": 0.9845,
      "step": 108920
    },
    {
      "epoch": 175.71,
      "learning_rate": 0.08243614659612904,
      "loss": 0.9673,
      "step": 108940
    },
    {
      "epoch": 175.74,
      "learning_rate": 0.08243292079290324,
      "loss": 0.993,
      "step": 108960
    },
    {
      "epoch": 175.77,
      "learning_rate": 0.08242969498967742,
      "loss": 0.9911,
      "step": 108980
    },
    {
      "epoch": 175.81,
      "learning_rate": 0.08242646918645162,
      "loss": 0.9871,
      "step": 109000
    },
    {
      "epoch": 175.84,
      "learning_rate": 0.08242324338322582,
      "loss": 0.9836,
      "step": 109020
    },
    {
      "epoch": 175.87,
      "learning_rate": 0.08242001758,
      "loss": 1.0004,
      "step": 109040
    },
    {
      "epoch": 175.9,
      "learning_rate": 0.08241679177677419,
      "loss": 1.0052,
      "step": 109060
    },
    {
      "epoch": 175.94,
      "learning_rate": 0.0824135659735484,
      "loss": 0.974,
      "step": 109080
    },
    {
      "epoch": 175.97,
      "learning_rate": 0.08241034017032259,
      "loss": 0.975,
      "step": 109100
    },
    {
      "epoch": 176.0,
      "learning_rate": 0.08240711436709677,
      "loss": 0.9894,
      "step": 109120
    },
    {
      "epoch": 176.0,
      "eval_accuracy": {
        "accuracy": 0.7385840293497775
      },
      "eval_loss": 1.3348249197006226,
      "eval_runtime": 3.0989,
      "eval_samples_per_second": 4134.026,
      "eval_steps_per_second": 64.861,
      "step": 109120
    },
    {
      "epoch": 176.03,
      "learning_rate": 0.08240388856387097,
      "loss": 0.9835,
      "step": 109140
    },
    {
      "epoch": 176.06,
      "learning_rate": 0.08240066276064516,
      "loss": 0.9444,
      "step": 109160
    },
    {
      "epoch": 176.1,
      "learning_rate": 0.08239743695741936,
      "loss": 0.9719,
      "step": 109180
    },
    {
      "epoch": 176.13,
      "learning_rate": 0.08239421115419356,
      "loss": 0.9629,
      "step": 109200
    },
    {
      "epoch": 176.16,
      "learning_rate": 0.08239098535096774,
      "loss": 0.9441,
      "step": 109220
    },
    {
      "epoch": 176.19,
      "learning_rate": 0.08238775954774194,
      "loss": 0.9463,
      "step": 109240
    },
    {
      "epoch": 176.23,
      "learning_rate": 0.08238453374451614,
      "loss": 0.961,
      "step": 109260
    },
    {
      "epoch": 176.26,
      "learning_rate": 0.08238130794129032,
      "loss": 0.93,
      "step": 109280
    },
    {
      "epoch": 176.29,
      "learning_rate": 0.08237808213806452,
      "loss": 0.9541,
      "step": 109300
    },
    {
      "epoch": 176.32,
      "learning_rate": 0.08237485633483872,
      "loss": 0.9904,
      "step": 109320
    },
    {
      "epoch": 176.35,
      "learning_rate": 0.08237163053161291,
      "loss": 1.0175,
      "step": 109340
    },
    {
      "epoch": 176.39,
      "learning_rate": 0.08236840472838709,
      "loss": 0.9565,
      "step": 109360
    },
    {
      "epoch": 176.42,
      "learning_rate": 0.0823651789251613,
      "loss": 0.9794,
      "step": 109380
    },
    {
      "epoch": 176.45,
      "learning_rate": 0.08236195312193548,
      "loss": 1.0053,
      "step": 109400
    },
    {
      "epoch": 176.48,
      "learning_rate": 0.08235872731870969,
      "loss": 0.9781,
      "step": 109420
    },
    {
      "epoch": 176.52,
      "learning_rate": 0.08235550151548388,
      "loss": 0.9793,
      "step": 109440
    },
    {
      "epoch": 176.55,
      "learning_rate": 0.08235227571225806,
      "loss": 0.9933,
      "step": 109460
    },
    {
      "epoch": 176.58,
      "learning_rate": 0.08234904990903226,
      "loss": 0.9902,
      "step": 109480
    },
    {
      "epoch": 176.61,
      "learning_rate": 0.08234582410580646,
      "loss": 1.0155,
      "step": 109500
    },
    {
      "epoch": 176.65,
      "learning_rate": 0.08234259830258064,
      "loss": 0.9545,
      "step": 109520
    },
    {
      "epoch": 176.68,
      "learning_rate": 0.08233937249935484,
      "loss": 0.9802,
      "step": 109540
    },
    {
      "epoch": 176.71,
      "learning_rate": 0.08233614669612904,
      "loss": 0.9827,
      "step": 109560
    },
    {
      "epoch": 176.74,
      "learning_rate": 0.08233292089290323,
      "loss": 0.9654,
      "step": 109580
    },
    {
      "epoch": 176.77,
      "learning_rate": 0.08232969508967743,
      "loss": 0.9955,
      "step": 109600
    },
    {
      "epoch": 176.81,
      "learning_rate": 0.08232646928645163,
      "loss": 0.9773,
      "step": 109620
    },
    {
      "epoch": 176.84,
      "learning_rate": 0.08232324348322581,
      "loss": 1.0057,
      "step": 109640
    },
    {
      "epoch": 176.87,
      "learning_rate": 0.08232001768,
      "loss": 0.9923,
      "step": 109660
    },
    {
      "epoch": 176.9,
      "learning_rate": 0.08231679187677421,
      "loss": 0.9572,
      "step": 109680
    },
    {
      "epoch": 176.94,
      "learning_rate": 0.08231356607354838,
      "loss": 0.9642,
      "step": 109700
    },
    {
      "epoch": 176.97,
      "learning_rate": 0.0823103402703226,
      "loss": 0.9906,
      "step": 109720
    },
    {
      "epoch": 177.0,
      "learning_rate": 0.08230711446709678,
      "loss": 0.9973,
      "step": 109740
    },
    {
      "epoch": 177.0,
      "eval_accuracy": {
        "accuracy": 0.7328077433455624
      },
      "eval_loss": 1.3850387334823608,
      "eval_runtime": 2.8248,
      "eval_samples_per_second": 4535.214,
      "eval_steps_per_second": 71.156,
      "step": 109740
    },
    {
      "epoch": 177.03,
      "learning_rate": 0.08230388866387096,
      "loss": 1.0297,
      "step": 109760
    },
    {
      "epoch": 177.06,
      "learning_rate": 0.08230066286064516,
      "loss": 0.9757,
      "step": 109780
    },
    {
      "epoch": 177.1,
      "learning_rate": 0.08229743705741936,
      "loss": 0.9754,
      "step": 109800
    },
    {
      "epoch": 177.13,
      "learning_rate": 0.08229421125419355,
      "loss": 0.9489,
      "step": 109820
    },
    {
      "epoch": 177.16,
      "learning_rate": 0.08229098545096775,
      "loss": 0.9735,
      "step": 109840
    },
    {
      "epoch": 177.19,
      "learning_rate": 0.08228775964774195,
      "loss": 0.952,
      "step": 109860
    },
    {
      "epoch": 177.23,
      "learning_rate": 0.08228453384451613,
      "loss": 1.0059,
      "step": 109880
    },
    {
      "epoch": 177.26,
      "learning_rate": 0.08228130804129033,
      "loss": 0.9851,
      "step": 109900
    },
    {
      "epoch": 177.29,
      "learning_rate": 0.08227808223806453,
      "loss": 0.9736,
      "step": 109920
    },
    {
      "epoch": 177.32,
      "learning_rate": 0.08227485643483871,
      "loss": 0.9829,
      "step": 109940
    },
    {
      "epoch": 177.35,
      "learning_rate": 0.08227163063161291,
      "loss": 1.0061,
      "step": 109960
    },
    {
      "epoch": 177.39,
      "learning_rate": 0.08226840482838711,
      "loss": 0.9699,
      "step": 109980
    },
    {
      "epoch": 177.42,
      "learning_rate": 0.08226517902516128,
      "loss": 0.9408,
      "step": 110000
    },
    {
      "epoch": 177.45,
      "learning_rate": 0.0822619532219355,
      "loss": 0.9757,
      "step": 110020
    },
    {
      "epoch": 177.48,
      "learning_rate": 0.08225872741870968,
      "loss": 1.0104,
      "step": 110040
    },
    {
      "epoch": 177.52,
      "learning_rate": 0.08225550161548387,
      "loss": 0.9986,
      "step": 110060
    },
    {
      "epoch": 177.55,
      "learning_rate": 0.08225227581225807,
      "loss": 0.99,
      "step": 110080
    },
    {
      "epoch": 177.58,
      "learning_rate": 0.08224905000903227,
      "loss": 1.0156,
      "step": 110100
    },
    {
      "epoch": 177.61,
      "learning_rate": 0.08224582420580645,
      "loss": 1.0121,
      "step": 110120
    },
    {
      "epoch": 177.65,
      "learning_rate": 0.08224259840258065,
      "loss": 0.9532,
      "step": 110140
    },
    {
      "epoch": 177.68,
      "learning_rate": 0.08223937259935485,
      "loss": 0.9766,
      "step": 110160
    },
    {
      "epoch": 177.71,
      "learning_rate": 0.08223614679612903,
      "loss": 0.9687,
      "step": 110180
    },
    {
      "epoch": 177.74,
      "learning_rate": 0.08223292099290323,
      "loss": 0.978,
      "step": 110200
    },
    {
      "epoch": 177.77,
      "learning_rate": 0.08222969518967743,
      "loss": 0.9606,
      "step": 110220
    },
    {
      "epoch": 177.81,
      "learning_rate": 0.08222646938645162,
      "loss": 0.9726,
      "step": 110240
    },
    {
      "epoch": 177.84,
      "learning_rate": 0.08222324358322582,
      "loss": 0.9826,
      "step": 110260
    },
    {
      "epoch": 177.87,
      "learning_rate": 0.08222001778000002,
      "loss": 1.0094,
      "step": 110280
    },
    {
      "epoch": 177.9,
      "learning_rate": 0.08221679197677419,
      "loss": 1.0073,
      "step": 110300
    },
    {
      "epoch": 177.94,
      "learning_rate": 0.0822135661735484,
      "loss": 0.9712,
      "step": 110320
    },
    {
      "epoch": 177.97,
      "learning_rate": 0.08221034037032258,
      "loss": 1.0068,
      "step": 110340
    },
    {
      "epoch": 178.0,
      "learning_rate": 0.08220711456709677,
      "loss": 0.9892,
      "step": 110360
    },
    {
      "epoch": 178.0,
      "eval_accuracy": {
        "accuracy": 0.7379595659979705
      },
      "eval_loss": 1.3409391641616821,
      "eval_runtime": 2.8655,
      "eval_samples_per_second": 4470.767,
      "eval_steps_per_second": 70.145,
      "step": 110360
    },
    {
      "epoch": 178.03,
      "learning_rate": 0.08220388876387097,
      "loss": 0.9778,
      "step": 110380
    },
    {
      "epoch": 178.06,
      "learning_rate": 0.08220066296064517,
      "loss": 0.9754,
      "step": 110400
    },
    {
      "epoch": 178.1,
      "learning_rate": 0.08219743715741935,
      "loss": 0.98,
      "step": 110420
    },
    {
      "epoch": 178.13,
      "learning_rate": 0.08219421135419355,
      "loss": 0.9297,
      "step": 110440
    },
    {
      "epoch": 178.16,
      "learning_rate": 0.08219098555096775,
      "loss": 0.9408,
      "step": 110460
    },
    {
      "epoch": 178.19,
      "learning_rate": 0.08218775974774194,
      "loss": 0.9535,
      "step": 110480
    },
    {
      "epoch": 178.23,
      "learning_rate": 0.08218453394451614,
      "loss": 0.9593,
      "step": 110500
    },
    {
      "epoch": 178.26,
      "learning_rate": 0.08218130814129034,
      "loss": 0.9792,
      "step": 110520
    },
    {
      "epoch": 178.29,
      "learning_rate": 0.08217808233806452,
      "loss": 0.9918,
      "step": 110540
    },
    {
      "epoch": 178.32,
      "learning_rate": 0.08217485653483872,
      "loss": 0.9782,
      "step": 110560
    },
    {
      "epoch": 178.35,
      "learning_rate": 0.08217163073161292,
      "loss": 1.006,
      "step": 110580
    },
    {
      "epoch": 178.39,
      "learning_rate": 0.08216840492838709,
      "loss": 0.9773,
      "step": 110600
    },
    {
      "epoch": 178.42,
      "learning_rate": 0.0821651791251613,
      "loss": 0.976,
      "step": 110620
    },
    {
      "epoch": 178.45,
      "learning_rate": 0.08216195332193549,
      "loss": 0.9592,
      "step": 110640
    },
    {
      "epoch": 178.48,
      "learning_rate": 0.08215872751870969,
      "loss": 0.9797,
      "step": 110660
    },
    {
      "epoch": 178.52,
      "learning_rate": 0.08215550171548387,
      "loss": 0.9831,
      "step": 110680
    },
    {
      "epoch": 178.55,
      "learning_rate": 0.08215227591225807,
      "loss": 0.9703,
      "step": 110700
    },
    {
      "epoch": 178.58,
      "learning_rate": 0.08214905010903226,
      "loss": 0.9705,
      "step": 110720
    },
    {
      "epoch": 178.61,
      "learning_rate": 0.08214582430580646,
      "loss": 0.9641,
      "step": 110740
    },
    {
      "epoch": 178.65,
      "learning_rate": 0.08214259850258065,
      "loss": 0.9666,
      "step": 110760
    },
    {
      "epoch": 178.68,
      "learning_rate": 0.08213937269935484,
      "loss": 0.9398,
      "step": 110780
    },
    {
      "epoch": 178.71,
      "learning_rate": 0.08213614689612904,
      "loss": 1.0103,
      "step": 110800
    },
    {
      "epoch": 178.74,
      "learning_rate": 0.08213292109290324,
      "loss": 1.0054,
      "step": 110820
    },
    {
      "epoch": 178.77,
      "learning_rate": 0.08212969528967742,
      "loss": 0.9783,
      "step": 110840
    },
    {
      "epoch": 178.81,
      "learning_rate": 0.08212646948645162,
      "loss": 0.9922,
      "step": 110860
    },
    {
      "epoch": 178.84,
      "learning_rate": 0.08212324368322582,
      "loss": 1.018,
      "step": 110880
    },
    {
      "epoch": 178.87,
      "learning_rate": 0.08212001788,
      "loss": 0.9899,
      "step": 110900
    },
    {
      "epoch": 178.9,
      "learning_rate": 0.0821167920767742,
      "loss": 0.9715,
      "step": 110920
    },
    {
      "epoch": 178.94,
      "learning_rate": 0.08211356627354839,
      "loss": 1.0033,
      "step": 110940
    },
    {
      "epoch": 178.97,
      "learning_rate": 0.08211034047032259,
      "loss": 0.9955,
      "step": 110960
    },
    {
      "epoch": 179.0,
      "learning_rate": 0.08210727595725807,
      "loss": 0.9812,
      "step": 110980
    },
    {
      "epoch": 179.0,
      "eval_accuracy": {
        "accuracy": 0.7389743189446569
      },
      "eval_loss": 1.3214830160140991,
      "eval_runtime": 3.1448,
      "eval_samples_per_second": 4073.746,
      "eval_steps_per_second": 63.916,
      "step": 110980
    },
    {
      "epoch": 179.03,
      "learning_rate": 0.08210405015403227,
      "loss": 0.9765,
      "step": 111000
    },
    {
      "epoch": 179.06,
      "learning_rate": 0.08210082435080646,
      "loss": 0.9593,
      "step": 111020
    },
    {
      "epoch": 179.1,
      "learning_rate": 0.08209759854758066,
      "loss": 0.9636,
      "step": 111040
    },
    {
      "epoch": 179.13,
      "learning_rate": 0.08209437274435485,
      "loss": 0.9573,
      "step": 111060
    },
    {
      "epoch": 179.16,
      "learning_rate": 0.08209114694112903,
      "loss": 0.9389,
      "step": 111080
    },
    {
      "epoch": 179.19,
      "learning_rate": 0.08208792113790324,
      "loss": 0.9337,
      "step": 111100
    },
    {
      "epoch": 179.23,
      "learning_rate": 0.08208469533467742,
      "loss": 0.9737,
      "step": 111120
    },
    {
      "epoch": 179.26,
      "learning_rate": 0.08208146953145161,
      "loss": 0.9649,
      "step": 111140
    },
    {
      "epoch": 179.29,
      "learning_rate": 0.08207824372822581,
      "loss": 0.9808,
      "step": 111160
    },
    {
      "epoch": 179.32,
      "learning_rate": 0.08207501792500001,
      "loss": 0.9718,
      "step": 111180
    },
    {
      "epoch": 179.35,
      "learning_rate": 0.08207179212177419,
      "loss": 0.9596,
      "step": 111200
    },
    {
      "epoch": 179.39,
      "learning_rate": 0.08206856631854839,
      "loss": 0.9896,
      "step": 111220
    },
    {
      "epoch": 179.42,
      "learning_rate": 0.08206534051532259,
      "loss": 0.9605,
      "step": 111240
    },
    {
      "epoch": 179.45,
      "learning_rate": 0.08206211471209678,
      "loss": 0.9855,
      "step": 111260
    },
    {
      "epoch": 179.48,
      "learning_rate": 0.08205888890887097,
      "loss": 1.0045,
      "step": 111280
    },
    {
      "epoch": 179.52,
      "learning_rate": 0.08205566310564517,
      "loss": 0.9637,
      "step": 111300
    },
    {
      "epoch": 179.55,
      "learning_rate": 0.08205243730241936,
      "loss": 0.9834,
      "step": 111320
    },
    {
      "epoch": 179.58,
      "learning_rate": 0.08204921149919356,
      "loss": 0.984,
      "step": 111340
    },
    {
      "epoch": 179.61,
      "learning_rate": 0.08204598569596776,
      "loss": 0.9695,
      "step": 111360
    },
    {
      "epoch": 179.65,
      "learning_rate": 0.08204275989274193,
      "loss": 0.9658,
      "step": 111380
    },
    {
      "epoch": 179.68,
      "learning_rate": 0.08203953408951614,
      "loss": 0.9789,
      "step": 111400
    },
    {
      "epoch": 179.71,
      "learning_rate": 0.08203630828629033,
      "loss": 0.9692,
      "step": 111420
    },
    {
      "epoch": 179.74,
      "learning_rate": 0.08203308248306451,
      "loss": 0.956,
      "step": 111440
    },
    {
      "epoch": 179.77,
      "learning_rate": 0.08202985667983871,
      "loss": 0.9643,
      "step": 111460
    },
    {
      "epoch": 179.81,
      "learning_rate": 0.08202663087661291,
      "loss": 0.9396,
      "step": 111480
    },
    {
      "epoch": 179.84,
      "learning_rate": 0.0820234050733871,
      "loss": 0.9974,
      "step": 111500
    },
    {
      "epoch": 179.87,
      "learning_rate": 0.0820201792701613,
      "loss": 0.9845,
      "step": 111520
    },
    {
      "epoch": 179.9,
      "learning_rate": 0.0820169534669355,
      "loss": 0.9831,
      "step": 111540
    },
    {
      "epoch": 179.94,
      "learning_rate": 0.08201372766370968,
      "loss": 0.9617,
      "step": 111560
    },
    {
      "epoch": 179.97,
      "learning_rate": 0.08201050186048388,
      "loss": 0.9598,
      "step": 111580
    },
    {
      "epoch": 180.0,
      "learning_rate": 0.08200727605725808,
      "loss": 0.9646,
      "step": 111600
    },
    {
      "epoch": 180.0,
      "eval_accuracy": {
        "accuracy": 0.7296073686675513
      },
      "eval_loss": 1.392513632774353,
      "eval_runtime": 2.8429,
      "eval_samples_per_second": 4506.286,
      "eval_steps_per_second": 70.702,
      "step": 111600
    },
    {
      "epoch": 180.03,
      "learning_rate": 0.08200405025403226,
      "loss": 1.0063,
      "step": 111620
    },
    {
      "epoch": 180.06,
      "learning_rate": 0.08200082445080646,
      "loss": 0.9536,
      "step": 111640
    },
    {
      "epoch": 180.1,
      "learning_rate": 0.08199759864758066,
      "loss": 0.9794,
      "step": 111660
    },
    {
      "epoch": 180.13,
      "learning_rate": 0.08199437284435483,
      "loss": 0.9559,
      "step": 111680
    },
    {
      "epoch": 180.16,
      "learning_rate": 0.08199114704112904,
      "loss": 0.9781,
      "step": 111700
    },
    {
      "epoch": 180.19,
      "learning_rate": 0.08198792123790323,
      "loss": 0.9394,
      "step": 111720
    },
    {
      "epoch": 180.23,
      "learning_rate": 0.08198469543467743,
      "loss": 0.9419,
      "step": 111740
    },
    {
      "epoch": 180.26,
      "learning_rate": 0.08198146963145161,
      "loss": 0.9416,
      "step": 111760
    },
    {
      "epoch": 180.29,
      "learning_rate": 0.08197824382822581,
      "loss": 0.9775,
      "step": 111780
    },
    {
      "epoch": 180.32,
      "learning_rate": 0.081975018025,
      "loss": 0.9738,
      "step": 111800
    },
    {
      "epoch": 180.35,
      "learning_rate": 0.0819717922217742,
      "loss": 0.9953,
      "step": 111820
    },
    {
      "epoch": 180.39,
      "learning_rate": 0.0819685664185484,
      "loss": 0.9795,
      "step": 111840
    },
    {
      "epoch": 180.42,
      "learning_rate": 0.08196534061532258,
      "loss": 0.9865,
      "step": 111860
    },
    {
      "epoch": 180.45,
      "learning_rate": 0.08196211481209678,
      "loss": 0.9732,
      "step": 111880
    },
    {
      "epoch": 180.48,
      "learning_rate": 0.08195888900887098,
      "loss": 0.9574,
      "step": 111900
    },
    {
      "epoch": 180.52,
      "learning_rate": 0.08195566320564517,
      "loss": 0.9568,
      "step": 111920
    },
    {
      "epoch": 180.55,
      "learning_rate": 0.08195243740241936,
      "loss": 0.9391,
      "step": 111940
    },
    {
      "epoch": 180.58,
      "learning_rate": 0.08194921159919356,
      "loss": 0.9531,
      "step": 111960
    },
    {
      "epoch": 180.61,
      "learning_rate": 0.08194598579596774,
      "loss": 0.9743,
      "step": 111980
    },
    {
      "epoch": 180.65,
      "learning_rate": 0.08194275999274195,
      "loss": 0.9584,
      "step": 112000
    },
    {
      "epoch": 180.68,
      "learning_rate": 0.08193953418951613,
      "loss": 0.956,
      "step": 112020
    },
    {
      "epoch": 180.71,
      "learning_rate": 0.08193630838629033,
      "loss": 0.9699,
      "step": 112040
    },
    {
      "epoch": 180.74,
      "learning_rate": 0.08193308258306452,
      "loss": 0.9884,
      "step": 112060
    },
    {
      "epoch": 180.77,
      "learning_rate": 0.08192985677983872,
      "loss": 0.9835,
      "step": 112080
    },
    {
      "epoch": 180.81,
      "learning_rate": 0.0819266309766129,
      "loss": 0.9921,
      "step": 112100
    },
    {
      "epoch": 180.84,
      "learning_rate": 0.0819234051733871,
      "loss": 1.0048,
      "step": 112120
    },
    {
      "epoch": 180.87,
      "learning_rate": 0.0819201793701613,
      "loss": 0.9984,
      "step": 112140
    },
    {
      "epoch": 180.9,
      "learning_rate": 0.08191695356693549,
      "loss": 0.9924,
      "step": 112160
    },
    {
      "epoch": 180.94,
      "learning_rate": 0.08191372776370968,
      "loss": 0.9734,
      "step": 112180
    },
    {
      "epoch": 180.97,
      "learning_rate": 0.08191050196048388,
      "loss": 0.9759,
      "step": 112200
    },
    {
      "epoch": 181.0,
      "learning_rate": 0.08190727615725807,
      "loss": 0.9753,
      "step": 112220
    },
    {
      "epoch": 181.0,
      "eval_accuracy": {
        "accuracy": 0.7407696510811022
      },
      "eval_loss": 1.3462427854537964,
      "eval_runtime": 2.6506,
      "eval_samples_per_second": 4833.261,
      "eval_steps_per_second": 75.832,
      "step": 112220
    },
    {
      "epoch": 181.03,
      "learning_rate": 0.08190405035403227,
      "loss": 0.9901,
      "step": 112240
    },
    {
      "epoch": 181.06,
      "learning_rate": 0.08190082455080645,
      "loss": 0.959,
      "step": 112260
    },
    {
      "epoch": 181.1,
      "learning_rate": 0.08189759874758065,
      "loss": 0.9554,
      "step": 112280
    },
    {
      "epoch": 181.13,
      "learning_rate": 0.08189437294435485,
      "loss": 0.9474,
      "step": 112300
    },
    {
      "epoch": 181.16,
      "learning_rate": 0.08189114714112904,
      "loss": 0.9432,
      "step": 112320
    },
    {
      "epoch": 181.19,
      "learning_rate": 0.08188792133790324,
      "loss": 0.9689,
      "step": 112340
    },
    {
      "epoch": 181.23,
      "learning_rate": 0.08188469553467742,
      "loss": 0.9701,
      "step": 112360
    },
    {
      "epoch": 181.26,
      "learning_rate": 0.08188146973145162,
      "loss": 0.956,
      "step": 112380
    },
    {
      "epoch": 181.29,
      "learning_rate": 0.0818782439282258,
      "loss": 0.9671,
      "step": 112400
    },
    {
      "epoch": 181.32,
      "learning_rate": 0.081875018125,
      "loss": 0.9632,
      "step": 112420
    },
    {
      "epoch": 181.35,
      "learning_rate": 0.0818717923217742,
      "loss": 0.9567,
      "step": 112440
    },
    {
      "epoch": 181.39,
      "learning_rate": 0.08186856651854839,
      "loss": 0.9379,
      "step": 112460
    },
    {
      "epoch": 181.42,
      "learning_rate": 0.08186534071532259,
      "loss": 0.9506,
      "step": 112480
    },
    {
      "epoch": 181.45,
      "learning_rate": 0.08186211491209679,
      "loss": 0.9625,
      "step": 112500
    },
    {
      "epoch": 181.48,
      "learning_rate": 0.08185888910887097,
      "loss": 0.9689,
      "step": 112520
    },
    {
      "epoch": 181.52,
      "learning_rate": 0.08185566330564517,
      "loss": 0.9676,
      "step": 112540
    },
    {
      "epoch": 181.55,
      "learning_rate": 0.08185243750241936,
      "loss": 0.9722,
      "step": 112560
    },
    {
      "epoch": 181.58,
      "learning_rate": 0.08184921169919356,
      "loss": 0.9599,
      "step": 112580
    },
    {
      "epoch": 181.61,
      "learning_rate": 0.08184598589596775,
      "loss": 0.9409,
      "step": 112600
    },
    {
      "epoch": 181.65,
      "learning_rate": 0.08184276009274194,
      "loss": 0.9642,
      "step": 112620
    },
    {
      "epoch": 181.68,
      "learning_rate": 0.08183953428951614,
      "loss": 0.965,
      "step": 112640
    },
    {
      "epoch": 181.71,
      "learning_rate": 0.08183630848629032,
      "loss": 1.0139,
      "step": 112660
    },
    {
      "epoch": 181.74,
      "learning_rate": 0.08183308268306452,
      "loss": 0.985,
      "step": 112680
    },
    {
      "epoch": 181.77,
      "learning_rate": 0.08182985687983871,
      "loss": 0.9751,
      "step": 112700
    },
    {
      "epoch": 181.81,
      "learning_rate": 0.08182663107661291,
      "loss": 0.9993,
      "step": 112720
    },
    {
      "epoch": 181.84,
      "learning_rate": 0.0818234052733871,
      "loss": 0.9728,
      "step": 112740
    },
    {
      "epoch": 181.87,
      "learning_rate": 0.08182017947016129,
      "loss": 0.9723,
      "step": 112760
    },
    {
      "epoch": 181.9,
      "learning_rate": 0.08181695366693549,
      "loss": 0.9931,
      "step": 112780
    },
    {
      "epoch": 181.94,
      "learning_rate": 0.08181372786370968,
      "loss": 0.9866,
      "step": 112800
    },
    {
      "epoch": 181.97,
      "learning_rate": 0.08181050206048388,
      "loss": 0.9792,
      "step": 112820
    },
    {
      "epoch": 182.0,
      "learning_rate": 0.08180727625725807,
      "loss": 0.9744,
      "step": 112840
    },
    {
      "epoch": 182.0,
      "eval_accuracy": {
        "accuracy": 0.7419405198657404
      },
      "eval_loss": 1.3336631059646606,
      "eval_runtime": 2.8141,
      "eval_samples_per_second": 4552.498,
      "eval_steps_per_second": 71.427,
      "step": 112840
    },
    {
      "epoch": 182.03,
      "learning_rate": 0.08180405045403226,
      "loss": 0.9896,
      "step": 112860
    },
    {
      "epoch": 182.06,
      "learning_rate": 0.08180082465080646,
      "loss": 0.931,
      "step": 112880
    },
    {
      "epoch": 182.1,
      "learning_rate": 0.08179759884758066,
      "loss": 0.9378,
      "step": 112900
    },
    {
      "epoch": 182.13,
      "learning_rate": 0.08179437304435484,
      "loss": 0.9327,
      "step": 112920
    },
    {
      "epoch": 182.16,
      "learning_rate": 0.08179114724112904,
      "loss": 0.9324,
      "step": 112940
    },
    {
      "epoch": 182.19,
      "learning_rate": 0.08178792143790323,
      "loss": 0.9436,
      "step": 112960
    },
    {
      "epoch": 182.23,
      "learning_rate": 0.08178469563467743,
      "loss": 0.9401,
      "step": 112980
    },
    {
      "epoch": 182.26,
      "learning_rate": 0.08178146983145161,
      "loss": 0.9323,
      "step": 113000
    },
    {
      "epoch": 182.29,
      "learning_rate": 0.08177824402822581,
      "loss": 0.9679,
      "step": 113020
    },
    {
      "epoch": 182.32,
      "learning_rate": 0.08177501822500001,
      "loss": 0.9885,
      "step": 113040
    },
    {
      "epoch": 182.35,
      "learning_rate": 0.0817717924217742,
      "loss": 0.9488,
      "step": 113060
    },
    {
      "epoch": 182.39,
      "learning_rate": 0.0817685666185484,
      "loss": 0.9758,
      "step": 113080
    },
    {
      "epoch": 182.42,
      "learning_rate": 0.08176534081532258,
      "loss": 0.9829,
      "step": 113100
    },
    {
      "epoch": 182.45,
      "learning_rate": 0.08176211501209678,
      "loss": 1.0039,
      "step": 113120
    },
    {
      "epoch": 182.48,
      "learning_rate": 0.08175888920887098,
      "loss": 0.9388,
      "step": 113140
    },
    {
      "epoch": 182.52,
      "learning_rate": 0.08175566340564516,
      "loss": 0.9591,
      "step": 113160
    },
    {
      "epoch": 182.55,
      "learning_rate": 0.08175243760241936,
      "loss": 0.9699,
      "step": 113180
    },
    {
      "epoch": 182.58,
      "learning_rate": 0.08174921179919356,
      "loss": 0.9742,
      "step": 113200
    },
    {
      "epoch": 182.61,
      "learning_rate": 0.08174598599596775,
      "loss": 0.9745,
      "step": 113220
    },
    {
      "epoch": 182.65,
      "learning_rate": 0.08174276019274195,
      "loss": 0.9749,
      "step": 113240
    },
    {
      "epoch": 182.68,
      "learning_rate": 0.08173969567967743,
      "loss": 0.9751,
      "step": 113260
    },
    {
      "epoch": 182.71,
      "learning_rate": 0.08173646987645163,
      "loss": 1.0105,
      "step": 113280
    },
    {
      "epoch": 182.74,
      "learning_rate": 0.08173324407322581,
      "loss": 0.9768,
      "step": 113300
    },
    {
      "epoch": 182.77,
      "learning_rate": 0.08173001827000001,
      "loss": 0.9798,
      "step": 113320
    },
    {
      "epoch": 182.81,
      "learning_rate": 0.0817267924667742,
      "loss": 0.986,
      "step": 113340
    },
    {
      "epoch": 182.84,
      "learning_rate": 0.0817235666635484,
      "loss": 0.9415,
      "step": 113360
    },
    {
      "epoch": 182.87,
      "learning_rate": 0.0817203408603226,
      "loss": 0.9476,
      "step": 113380
    },
    {
      "epoch": 182.9,
      "learning_rate": 0.08171711505709678,
      "loss": 0.9918,
      "step": 113400
    },
    {
      "epoch": 182.94,
      "learning_rate": 0.08171388925387098,
      "loss": 0.972,
      "step": 113420
    },
    {
      "epoch": 182.97,
      "learning_rate": 0.08171066345064516,
      "loss": 1.0039,
      "step": 113440
    },
    {
      "epoch": 183.0,
      "learning_rate": 0.08170743764741936,
      "loss": 0.998,
      "step": 113460
    },
    {
      "epoch": 183.0,
      "eval_accuracy": {
        "accuracy": 0.7360861759425493
      },
      "eval_loss": 1.3609641790390015,
      "eval_runtime": 2.8477,
      "eval_samples_per_second": 4498.659,
      "eval_steps_per_second": 70.582,
      "step": 113460
    },
    {
      "epoch": 183.03,
      "learning_rate": 0.08170421184419355,
      "loss": 0.9756,
      "step": 113480
    },
    {
      "epoch": 183.06,
      "learning_rate": 0.08170098604096775,
      "loss": 0.9581,
      "step": 113500
    },
    {
      "epoch": 183.1,
      "learning_rate": 0.08169776023774195,
      "loss": 0.9545,
      "step": 113520
    },
    {
      "epoch": 183.13,
      "learning_rate": 0.08169453443451613,
      "loss": 0.9516,
      "step": 113540
    },
    {
      "epoch": 183.16,
      "learning_rate": 0.08169130863129033,
      "loss": 0.9352,
      "step": 113560
    },
    {
      "epoch": 183.19,
      "learning_rate": 0.08168808282806453,
      "loss": 0.9441,
      "step": 113580
    },
    {
      "epoch": 183.23,
      "learning_rate": 0.08168485702483871,
      "loss": 0.9614,
      "step": 113600
    },
    {
      "epoch": 183.26,
      "learning_rate": 0.08168163122161291,
      "loss": 0.9448,
      "step": 113620
    },
    {
      "epoch": 183.29,
      "learning_rate": 0.0816784054183871,
      "loss": 0.9593,
      "step": 113640
    },
    {
      "epoch": 183.32,
      "learning_rate": 0.0816751796151613,
      "loss": 0.957,
      "step": 113660
    },
    {
      "epoch": 183.35,
      "learning_rate": 0.0816719538119355,
      "loss": 0.9801,
      "step": 113680
    },
    {
      "epoch": 183.39,
      "learning_rate": 0.08166872800870968,
      "loss": 0.9653,
      "step": 113700
    },
    {
      "epoch": 183.42,
      "learning_rate": 0.08166550220548388,
      "loss": 0.9751,
      "step": 113720
    },
    {
      "epoch": 183.45,
      "learning_rate": 0.08166227640225807,
      "loss": 0.9521,
      "step": 113740
    },
    {
      "epoch": 183.48,
      "learning_rate": 0.08165905059903227,
      "loss": 0.9731,
      "step": 113760
    },
    {
      "epoch": 183.52,
      "learning_rate": 0.08165582479580645,
      "loss": 0.9853,
      "step": 113780
    },
    {
      "epoch": 183.55,
      "learning_rate": 0.08165259899258065,
      "loss": 1.0147,
      "step": 113800
    },
    {
      "epoch": 183.58,
      "learning_rate": 0.08164937318935485,
      "loss": 0.9563,
      "step": 113820
    },
    {
      "epoch": 183.61,
      "learning_rate": 0.08164614738612903,
      "loss": 0.9516,
      "step": 113840
    },
    {
      "epoch": 183.65,
      "learning_rate": 0.08164292158290323,
      "loss": 0.9582,
      "step": 113860
    },
    {
      "epoch": 183.68,
      "learning_rate": 0.08163969577967742,
      "loss": 0.9725,
      "step": 113880
    },
    {
      "epoch": 183.71,
      "learning_rate": 0.08163646997645162,
      "loss": 0.9902,
      "step": 113900
    },
    {
      "epoch": 183.74,
      "learning_rate": 0.08163324417322582,
      "loss": 0.9776,
      "step": 113920
    },
    {
      "epoch": 183.77,
      "learning_rate": 0.08163001837,
      "loss": 0.9874,
      "step": 113940
    },
    {
      "epoch": 183.81,
      "learning_rate": 0.0816267925667742,
      "loss": 0.9545,
      "step": 113960
    },
    {
      "epoch": 183.84,
      "learning_rate": 0.0816235667635484,
      "loss": 0.969,
      "step": 113980
    },
    {
      "epoch": 183.87,
      "learning_rate": 0.08162034096032258,
      "loss": 0.9827,
      "step": 114000
    },
    {
      "epoch": 183.9,
      "learning_rate": 0.08161711515709678,
      "loss": 0.9914,
      "step": 114020
    },
    {
      "epoch": 183.94,
      "learning_rate": 0.08161388935387097,
      "loss": 0.9588,
      "step": 114040
    },
    {
      "epoch": 183.97,
      "learning_rate": 0.08161066355064517,
      "loss": 0.9603,
      "step": 114060
    },
    {
      "epoch": 184.0,
      "learning_rate": 0.08160743774741935,
      "loss": 0.9985,
      "step": 114080
    },
    {
      "epoch": 184.0,
      "eval_accuracy": {
        "accuracy": 0.7333541487783936
      },
      "eval_loss": 1.3705034255981445,
      "eval_runtime": 2.7514,
      "eval_samples_per_second": 4656.135,
      "eval_steps_per_second": 73.053,
      "step": 114080
    },
    {
      "epoch": 184.03,
      "learning_rate": 0.08160421194419355,
      "loss": 0.9828,
      "step": 114100
    },
    {
      "epoch": 184.06,
      "learning_rate": 0.08160098614096775,
      "loss": 0.9413,
      "step": 114120
    },
    {
      "epoch": 184.1,
      "learning_rate": 0.08159776033774194,
      "loss": 0.9465,
      "step": 114140
    },
    {
      "epoch": 184.13,
      "learning_rate": 0.08159453453451614,
      "loss": 0.9399,
      "step": 114160
    },
    {
      "epoch": 184.16,
      "learning_rate": 0.08159130873129032,
      "loss": 0.9572,
      "step": 114180
    },
    {
      "epoch": 184.19,
      "learning_rate": 0.08158808292806452,
      "loss": 0.9443,
      "step": 114200
    },
    {
      "epoch": 184.23,
      "learning_rate": 0.08158485712483872,
      "loss": 0.9599,
      "step": 114220
    },
    {
      "epoch": 184.26,
      "learning_rate": 0.0815816313216129,
      "loss": 0.9584,
      "step": 114240
    },
    {
      "epoch": 184.29,
      "learning_rate": 0.0815784055183871,
      "loss": 0.9809,
      "step": 114260
    },
    {
      "epoch": 184.32,
      "learning_rate": 0.0815751797151613,
      "loss": 0.9617,
      "step": 114280
    },
    {
      "epoch": 184.35,
      "learning_rate": 0.08157195391193549,
      "loss": 0.9578,
      "step": 114300
    },
    {
      "epoch": 184.39,
      "learning_rate": 0.08156872810870969,
      "loss": 0.9589,
      "step": 114320
    },
    {
      "epoch": 184.42,
      "learning_rate": 0.08156550230548387,
      "loss": 0.9941,
      "step": 114340
    },
    {
      "epoch": 184.45,
      "learning_rate": 0.08156227650225807,
      "loss": 0.9772,
      "step": 114360
    },
    {
      "epoch": 184.48,
      "learning_rate": 0.08155905069903226,
      "loss": 0.9925,
      "step": 114380
    },
    {
      "epoch": 184.52,
      "learning_rate": 0.08155582489580646,
      "loss": 0.985,
      "step": 114400
    },
    {
      "epoch": 184.55,
      "learning_rate": 0.08155259909258064,
      "loss": 0.9695,
      "step": 114420
    },
    {
      "epoch": 184.58,
      "learning_rate": 0.08154937328935484,
      "loss": 0.9547,
      "step": 114440
    },
    {
      "epoch": 184.61,
      "learning_rate": 0.08154614748612904,
      "loss": 0.9704,
      "step": 114460
    },
    {
      "epoch": 184.65,
      "learning_rate": 0.08154292168290322,
      "loss": 0.9788,
      "step": 114480
    },
    {
      "epoch": 184.68,
      "learning_rate": 0.08153969587967742,
      "loss": 0.966,
      "step": 114500
    },
    {
      "epoch": 184.71,
      "learning_rate": 0.08153647007645162,
      "loss": 0.988,
      "step": 114520
    },
    {
      "epoch": 184.74,
      "learning_rate": 0.08153324427322581,
      "loss": 0.9804,
      "step": 114540
    },
    {
      "epoch": 184.77,
      "learning_rate": 0.08153001847,
      "loss": 0.9574,
      "step": 114560
    },
    {
      "epoch": 184.81,
      "learning_rate": 0.0815267926667742,
      "loss": 0.9431,
      "step": 114580
    },
    {
      "epoch": 184.84,
      "learning_rate": 0.08152356686354839,
      "loss": 0.9658,
      "step": 114600
    },
    {
      "epoch": 184.87,
      "learning_rate": 0.08152034106032259,
      "loss": 0.9878,
      "step": 114620
    },
    {
      "epoch": 184.9,
      "learning_rate": 0.08151711525709678,
      "loss": 1.008,
      "step": 114640
    },
    {
      "epoch": 184.94,
      "learning_rate": 0.08151388945387097,
      "loss": 0.9704,
      "step": 114660
    },
    {
      "epoch": 184.97,
      "learning_rate": 0.08151066365064516,
      "loss": 0.957,
      "step": 114680
    },
    {
      "epoch": 185.0,
      "learning_rate": 0.08150743784741936,
      "loss": 0.9769,
      "step": 114700
    },
    {
      "epoch": 185.0,
      "eval_accuracy": {
        "accuracy": 0.7453750683006791
      },
      "eval_loss": 1.3262834548950195,
      "eval_runtime": 2.9237,
      "eval_samples_per_second": 4381.776,
      "eval_steps_per_second": 68.749,
      "step": 114700
    },
    {
      "epoch": 185.03,
      "learning_rate": 0.08150421204419354,
      "loss": 0.964,
      "step": 114720
    },
    {
      "epoch": 185.06,
      "learning_rate": 0.08150098624096774,
      "loss": 0.9955,
      "step": 114740
    },
    {
      "epoch": 185.1,
      "learning_rate": 0.08149776043774194,
      "loss": 0.9771,
      "step": 114760
    },
    {
      "epoch": 185.13,
      "learning_rate": 0.08149453463451613,
      "loss": 0.962,
      "step": 114780
    },
    {
      "epoch": 185.16,
      "learning_rate": 0.08149130883129033,
      "loss": 0.9573,
      "step": 114800
    },
    {
      "epoch": 185.19,
      "learning_rate": 0.08148808302806453,
      "loss": 0.9867,
      "step": 114820
    },
    {
      "epoch": 185.23,
      "learning_rate": 0.08148485722483871,
      "loss": 0.9651,
      "step": 114840
    },
    {
      "epoch": 185.26,
      "learning_rate": 0.08148163142161291,
      "loss": 0.9615,
      "step": 114860
    },
    {
      "epoch": 185.29,
      "learning_rate": 0.08147840561838711,
      "loss": 0.9538,
      "step": 114880
    },
    {
      "epoch": 185.32,
      "learning_rate": 0.0814751798151613,
      "loss": 0.954,
      "step": 114900
    },
    {
      "epoch": 185.35,
      "learning_rate": 0.0814719540119355,
      "loss": 0.9526,
      "step": 114920
    },
    {
      "epoch": 185.39,
      "learning_rate": 0.08146872820870968,
      "loss": 0.9501,
      "step": 114940
    },
    {
      "epoch": 185.42,
      "learning_rate": 0.08146550240548388,
      "loss": 0.9727,
      "step": 114960
    },
    {
      "epoch": 185.45,
      "learning_rate": 0.08146227660225806,
      "loss": 0.9668,
      "step": 114980
    },
    {
      "epoch": 185.48,
      "learning_rate": 0.08145905079903226,
      "loss": 0.9693,
      "step": 115000
    },
    {
      "epoch": 185.52,
      "learning_rate": 0.08145582499580645,
      "loss": 0.9967,
      "step": 115020
    },
    {
      "epoch": 185.55,
      "learning_rate": 0.08145259919258065,
      "loss": 0.9543,
      "step": 115040
    },
    {
      "epoch": 185.58,
      "learning_rate": 0.08144937338935485,
      "loss": 0.954,
      "step": 115060
    },
    {
      "epoch": 185.61,
      "learning_rate": 0.08144614758612903,
      "loss": 0.9539,
      "step": 115080
    },
    {
      "epoch": 185.65,
      "learning_rate": 0.08144292178290323,
      "loss": 0.9901,
      "step": 115100
    },
    {
      "epoch": 185.68,
      "learning_rate": 0.08143969597967743,
      "loss": 0.9795,
      "step": 115120
    },
    {
      "epoch": 185.71,
      "learning_rate": 0.08143647017645161,
      "loss": 0.9777,
      "step": 115140
    },
    {
      "epoch": 185.74,
      "learning_rate": 0.08143324437322581,
      "loss": 0.9828,
      "step": 115160
    },
    {
      "epoch": 185.77,
      "learning_rate": 0.08143001857000001,
      "loss": 0.9662,
      "step": 115180
    },
    {
      "epoch": 185.81,
      "learning_rate": 0.0814267927667742,
      "loss": 0.9759,
      "step": 115200
    },
    {
      "epoch": 185.84,
      "learning_rate": 0.0814235669635484,
      "loss": 0.9932,
      "step": 115220
    },
    {
      "epoch": 185.87,
      "learning_rate": 0.08142034116032258,
      "loss": 0.9973,
      "step": 115240
    },
    {
      "epoch": 185.9,
      "learning_rate": 0.08141711535709678,
      "loss": 0.9617,
      "step": 115260
    },
    {
      "epoch": 185.94,
      "learning_rate": 0.08141388955387097,
      "loss": 0.965,
      "step": 115280
    },
    {
      "epoch": 185.97,
      "learning_rate": 0.08141066375064518,
      "loss": 0.9947,
      "step": 115300
    },
    {
      "epoch": 186.0,
      "learning_rate": 0.08140743794741935,
      "loss": 0.9961,
      "step": 115320
    },
    {
      "epoch": 186.0,
      "eval_accuracy": {
        "accuracy": 0.7427210990554992
      },
      "eval_loss": 1.3184343576431274,
      "eval_runtime": 3.0032,
      "eval_samples_per_second": 4265.779,
      "eval_steps_per_second": 66.929,
      "step": 115320
    },
    {
      "epoch": 186.03,
      "learning_rate": 0.08140421214419355,
      "loss": 0.969,
      "step": 115340
    },
    {
      "epoch": 186.06,
      "learning_rate": 0.08140098634096775,
      "loss": 0.9717,
      "step": 115360
    },
    {
      "epoch": 186.1,
      "learning_rate": 0.08139776053774193,
      "loss": 0.9354,
      "step": 115380
    },
    {
      "epoch": 186.13,
      "learning_rate": 0.08139453473451613,
      "loss": 0.9233,
      "step": 115400
    },
    {
      "epoch": 186.16,
      "learning_rate": 0.08139130893129033,
      "loss": 0.9319,
      "step": 115420
    },
    {
      "epoch": 186.19,
      "learning_rate": 0.08138808312806452,
      "loss": 0.9768,
      "step": 115440
    },
    {
      "epoch": 186.23,
      "learning_rate": 0.08138485732483872,
      "loss": 0.9728,
      "step": 115460
    },
    {
      "epoch": 186.26,
      "learning_rate": 0.08138163152161292,
      "loss": 0.9674,
      "step": 115480
    },
    {
      "epoch": 186.29,
      "learning_rate": 0.0813784057183871,
      "loss": 0.9472,
      "step": 115500
    },
    {
      "epoch": 186.32,
      "learning_rate": 0.0813751799151613,
      "loss": 0.9448,
      "step": 115520
    },
    {
      "epoch": 186.35,
      "learning_rate": 0.0813719541119355,
      "loss": 0.9771,
      "step": 115540
    },
    {
      "epoch": 186.39,
      "learning_rate": 0.08136872830870968,
      "loss": 0.983,
      "step": 115560
    },
    {
      "epoch": 186.42,
      "learning_rate": 0.08136550250548387,
      "loss": 0.9425,
      "step": 115580
    },
    {
      "epoch": 186.45,
      "learning_rate": 0.08136227670225808,
      "loss": 0.9427,
      "step": 115600
    },
    {
      "epoch": 186.48,
      "learning_rate": 0.08135905089903225,
      "loss": 0.9319,
      "step": 115620
    },
    {
      "epoch": 186.52,
      "learning_rate": 0.08135582509580645,
      "loss": 0.9487,
      "step": 115640
    },
    {
      "epoch": 186.55,
      "learning_rate": 0.08135259929258065,
      "loss": 0.9421,
      "step": 115660
    },
    {
      "epoch": 186.58,
      "learning_rate": 0.08134937348935484,
      "loss": 0.9615,
      "step": 115680
    },
    {
      "epoch": 186.61,
      "learning_rate": 0.08134614768612904,
      "loss": 0.9721,
      "step": 115700
    },
    {
      "epoch": 186.65,
      "learning_rate": 0.08134292188290324,
      "loss": 0.9721,
      "step": 115720
    },
    {
      "epoch": 186.68,
      "learning_rate": 0.08133969607967742,
      "loss": 0.9314,
      "step": 115740
    },
    {
      "epoch": 186.71,
      "learning_rate": 0.08133647027645162,
      "loss": 0.9619,
      "step": 115760
    },
    {
      "epoch": 186.74,
      "learning_rate": 0.08133324447322582,
      "loss": 0.9757,
      "step": 115780
    },
    {
      "epoch": 186.77,
      "learning_rate": 0.08133001867,
      "loss": 0.958,
      "step": 115800
    },
    {
      "epoch": 186.81,
      "learning_rate": 0.0813267928667742,
      "loss": 0.9781,
      "step": 115820
    },
    {
      "epoch": 186.84,
      "learning_rate": 0.0813235670635484,
      "loss": 0.9521,
      "step": 115840
    },
    {
      "epoch": 186.87,
      "learning_rate": 0.08132034126032259,
      "loss": 0.9345,
      "step": 115860
    },
    {
      "epoch": 186.9,
      "learning_rate": 0.08131711545709677,
      "loss": 0.9718,
      "step": 115880
    },
    {
      "epoch": 186.94,
      "learning_rate": 0.08131388965387099,
      "loss": 0.9725,
      "step": 115900
    },
    {
      "epoch": 186.97,
      "learning_rate": 0.08131066385064516,
      "loss": 0.9523,
      "step": 115920
    },
    {
      "epoch": 187.0,
      "learning_rate": 0.08130759933758065,
      "loss": 0.9922,
      "step": 115940
    },
    {
      "epoch": 187.0,
      "eval_accuracy": {
        "accuracy": 0.7462337054094138
      },
      "eval_loss": 1.2817240953445435,
      "eval_runtime": 2.678,
      "eval_samples_per_second": 4783.848,
      "eval_steps_per_second": 75.057,
      "step": 115940
    },
    {
      "epoch": 187.03,
      "learning_rate": 0.08130437353435485,
      "loss": 0.9545,
      "step": 115960
    },
    {
      "epoch": 187.06,
      "learning_rate": 0.08130114773112904,
      "loss": 0.973,
      "step": 115980
    },
    {
      "epoch": 187.1,
      "learning_rate": 0.08129792192790324,
      "loss": 0.9536,
      "step": 116000
    },
    {
      "epoch": 187.13,
      "learning_rate": 0.08129469612467742,
      "loss": 0.9565,
      "step": 116020
    },
    {
      "epoch": 187.16,
      "learning_rate": 0.08129147032145162,
      "loss": 0.938,
      "step": 116040
    },
    {
      "epoch": 187.19,
      "learning_rate": 0.0812882445182258,
      "loss": 0.9205,
      "step": 116060
    },
    {
      "epoch": 187.23,
      "learning_rate": 0.081285018715,
      "loss": 0.9178,
      "step": 116080
    },
    {
      "epoch": 187.26,
      "learning_rate": 0.08128179291177419,
      "loss": 0.9405,
      "step": 116100
    },
    {
      "epoch": 187.29,
      "learning_rate": 0.08127856710854839,
      "loss": 0.9534,
      "step": 116120
    },
    {
      "epoch": 187.32,
      "learning_rate": 0.08127534130532259,
      "loss": 0.9425,
      "step": 116140
    },
    {
      "epoch": 187.35,
      "learning_rate": 0.08127211550209677,
      "loss": 0.9567,
      "step": 116160
    },
    {
      "epoch": 187.39,
      "learning_rate": 0.08126888969887097,
      "loss": 0.9515,
      "step": 116180
    },
    {
      "epoch": 187.42,
      "learning_rate": 0.08126566389564517,
      "loss": 0.9745,
      "step": 116200
    },
    {
      "epoch": 187.45,
      "learning_rate": 0.08126243809241936,
      "loss": 0.9531,
      "step": 116220
    },
    {
      "epoch": 187.48,
      "learning_rate": 0.08125921228919356,
      "loss": 0.9713,
      "step": 116240
    },
    {
      "epoch": 187.52,
      "learning_rate": 0.08125598648596775,
      "loss": 0.9969,
      "step": 116260
    },
    {
      "epoch": 187.55,
      "learning_rate": 0.08125276068274194,
      "loss": 0.9969,
      "step": 116280
    },
    {
      "epoch": 187.58,
      "learning_rate": 0.08124953487951614,
      "loss": 0.97,
      "step": 116300
    },
    {
      "epoch": 187.61,
      "learning_rate": 0.08124630907629032,
      "loss": 0.9689,
      "step": 116320
    },
    {
      "epoch": 187.65,
      "learning_rate": 0.08124308327306452,
      "loss": 0.9788,
      "step": 116340
    },
    {
      "epoch": 187.68,
      "learning_rate": 0.08123985746983871,
      "loss": 0.9606,
      "step": 116360
    },
    {
      "epoch": 187.71,
      "learning_rate": 0.08123663166661292,
      "loss": 0.9558,
      "step": 116380
    },
    {
      "epoch": 187.74,
      "learning_rate": 0.08123340586338709,
      "loss": 0.9527,
      "step": 116400
    },
    {
      "epoch": 187.77,
      "learning_rate": 0.08123018006016129,
      "loss": 0.962,
      "step": 116420
    },
    {
      "epoch": 187.81,
      "learning_rate": 0.08122695425693549,
      "loss": 0.9558,
      "step": 116440
    },
    {
      "epoch": 187.84,
      "learning_rate": 0.08122372845370968,
      "loss": 0.9707,
      "step": 116460
    },
    {
      "epoch": 187.87,
      "learning_rate": 0.08122050265048388,
      "loss": 0.9418,
      "step": 116480
    },
    {
      "epoch": 187.9,
      "learning_rate": 0.08121727684725807,
      "loss": 1.0107,
      "step": 116500
    },
    {
      "epoch": 187.94,
      "learning_rate": 0.08121405104403226,
      "loss": 0.9601,
      "step": 116520
    },
    {
      "epoch": 187.97,
      "learning_rate": 0.08121082524080646,
      "loss": 0.9508,
      "step": 116540
    },
    {
      "epoch": 188.0,
      "learning_rate": 0.08120759943758066,
      "loss": 0.9644,
      "step": 116560
    },
    {
      "epoch": 188.0,
      "eval_accuracy": {
        "accuracy": 0.7366325813753806
      },
      "eval_loss": 1.352504014968872,
      "eval_runtime": 2.8359,
      "eval_samples_per_second": 4517.444,
      "eval_steps_per_second": 70.877,
      "step": 116560
    },
    {
      "epoch": 188.03,
      "learning_rate": 0.08120437363435484,
      "loss": 1.0112,
      "step": 116580
    },
    {
      "epoch": 188.06,
      "learning_rate": 0.08120114783112904,
      "loss": 0.9825,
      "step": 116600
    },
    {
      "epoch": 188.1,
      "learning_rate": 0.08119792202790323,
      "loss": 0.9468,
      "step": 116620
    },
    {
      "epoch": 188.13,
      "learning_rate": 0.08119469622467743,
      "loss": 0.9315,
      "step": 116640
    },
    {
      "epoch": 188.16,
      "learning_rate": 0.08119147042145161,
      "loss": 0.9395,
      "step": 116660
    },
    {
      "epoch": 188.19,
      "learning_rate": 0.08118824461822582,
      "loss": 0.9689,
      "step": 116680
    },
    {
      "epoch": 188.23,
      "learning_rate": 0.081185018815,
      "loss": 0.9531,
      "step": 116700
    },
    {
      "epoch": 188.26,
      "learning_rate": 0.0811817930117742,
      "loss": 0.976,
      "step": 116720
    },
    {
      "epoch": 188.29,
      "learning_rate": 0.0811785672085484,
      "loss": 0.9506,
      "step": 116740
    },
    {
      "epoch": 188.32,
      "learning_rate": 0.08117534140532258,
      "loss": 0.9421,
      "step": 116760
    },
    {
      "epoch": 188.35,
      "learning_rate": 0.08117211560209678,
      "loss": 0.9674,
      "step": 116780
    },
    {
      "epoch": 188.39,
      "learning_rate": 0.08116888979887098,
      "loss": 0.9179,
      "step": 116800
    },
    {
      "epoch": 188.42,
      "learning_rate": 0.08116566399564516,
      "loss": 0.9649,
      "step": 116820
    },
    {
      "epoch": 188.45,
      "learning_rate": 0.08116243819241936,
      "loss": 0.977,
      "step": 116840
    },
    {
      "epoch": 188.48,
      "learning_rate": 0.08115921238919356,
      "loss": 0.9693,
      "step": 116860
    },
    {
      "epoch": 188.52,
      "learning_rate": 0.08115598658596775,
      "loss": 0.9775,
      "step": 116880
    },
    {
      "epoch": 188.55,
      "learning_rate": 0.08115276078274195,
      "loss": 0.9669,
      "step": 116900
    },
    {
      "epoch": 188.58,
      "learning_rate": 0.08114953497951614,
      "loss": 0.9605,
      "step": 116920
    },
    {
      "epoch": 188.61,
      "learning_rate": 0.08114630917629033,
      "loss": 0.9813,
      "step": 116940
    },
    {
      "epoch": 188.65,
      "learning_rate": 0.08114308337306451,
      "loss": 0.9632,
      "step": 116960
    },
    {
      "epoch": 188.68,
      "learning_rate": 0.08113985756983873,
      "loss": 1.0106,
      "step": 116980
    },
    {
      "epoch": 188.71,
      "learning_rate": 0.0811366317666129,
      "loss": 0.9718,
      "step": 117000
    },
    {
      "epoch": 188.74,
      "learning_rate": 0.0811334059633871,
      "loss": 0.9688,
      "step": 117020
    },
    {
      "epoch": 188.77,
      "learning_rate": 0.0811301801601613,
      "loss": 1.0001,
      "step": 117040
    },
    {
      "epoch": 188.81,
      "learning_rate": 0.08112695435693548,
      "loss": 0.9706,
      "step": 117060
    },
    {
      "epoch": 188.84,
      "learning_rate": 0.08112372855370968,
      "loss": 0.9498,
      "step": 117080
    },
    {
      "epoch": 188.87,
      "learning_rate": 0.08112050275048388,
      "loss": 0.949,
      "step": 117100
    },
    {
      "epoch": 188.9,
      "learning_rate": 0.08111727694725807,
      "loss": 0.9449,
      "step": 117120
    },
    {
      "epoch": 188.94,
      "learning_rate": 0.08111405114403226,
      "loss": 0.9681,
      "step": 117140
    },
    {
      "epoch": 188.97,
      "learning_rate": 0.08111082534080646,
      "loss": 0.9746,
      "step": 117160
    },
    {
      "epoch": 189.0,
      "learning_rate": 0.08110759953758065,
      "loss": 0.9883,
      "step": 117180
    },
    {
      "epoch": 189.0,
      "eval_accuracy": {
        "accuracy": 0.7361642338615253
      },
      "eval_loss": 1.3818185329437256,
      "eval_runtime": 2.8393,
      "eval_samples_per_second": 4512.092,
      "eval_steps_per_second": 70.793,
      "step": 117180
    },
    {
      "epoch": 189.03,
      "learning_rate": 0.08110437373435485,
      "loss": 1.0008,
      "step": 117200
    },
    {
      "epoch": 189.06,
      "learning_rate": 0.08110114793112905,
      "loss": 0.9414,
      "step": 117220
    },
    {
      "epoch": 189.1,
      "learning_rate": 0.08109792212790323,
      "loss": 0.9319,
      "step": 117240
    },
    {
      "epoch": 189.13,
      "learning_rate": 0.08109469632467742,
      "loss": 0.9569,
      "step": 117260
    },
    {
      "epoch": 189.16,
      "learning_rate": 0.08109147052145162,
      "loss": 0.9323,
      "step": 117280
    },
    {
      "epoch": 189.19,
      "learning_rate": 0.0810882447182258,
      "loss": 0.9661,
      "step": 117300
    },
    {
      "epoch": 189.23,
      "learning_rate": 0.081085018915,
      "loss": 0.9492,
      "step": 117320
    },
    {
      "epoch": 189.26,
      "learning_rate": 0.0810817931117742,
      "loss": 0.9274,
      "step": 117340
    },
    {
      "epoch": 189.29,
      "learning_rate": 0.08107856730854839,
      "loss": 1.0035,
      "step": 117360
    },
    {
      "epoch": 189.32,
      "learning_rate": 0.08107534150532258,
      "loss": 0.9553,
      "step": 117380
    },
    {
      "epoch": 189.35,
      "learning_rate": 0.08107211570209678,
      "loss": 0.973,
      "step": 117400
    },
    {
      "epoch": 189.39,
      "learning_rate": 0.08106888989887097,
      "loss": 0.9415,
      "step": 117420
    },
    {
      "epoch": 189.42,
      "learning_rate": 0.08106566409564517,
      "loss": 0.9386,
      "step": 117440
    },
    {
      "epoch": 189.45,
      "learning_rate": 0.08106243829241937,
      "loss": 0.9454,
      "step": 117460
    },
    {
      "epoch": 189.48,
      "learning_rate": 0.08105921248919355,
      "loss": 0.9765,
      "step": 117480
    },
    {
      "epoch": 189.52,
      "learning_rate": 0.08105598668596775,
      "loss": 0.9488,
      "step": 117500
    },
    {
      "epoch": 189.55,
      "learning_rate": 0.08105276088274195,
      "loss": 0.964,
      "step": 117520
    },
    {
      "epoch": 189.58,
      "learning_rate": 0.08104953507951614,
      "loss": 0.9318,
      "step": 117540
    },
    {
      "epoch": 189.61,
      "learning_rate": 0.08104630927629032,
      "loss": 0.992,
      "step": 117560
    },
    {
      "epoch": 189.65,
      "learning_rate": 0.08104308347306452,
      "loss": 0.9585,
      "step": 117580
    },
    {
      "epoch": 189.68,
      "learning_rate": 0.0810398576698387,
      "loss": 0.9383,
      "step": 117600
    },
    {
      "epoch": 189.71,
      "learning_rate": 0.08103663186661292,
      "loss": 0.9621,
      "step": 117620
    },
    {
      "epoch": 189.74,
      "learning_rate": 0.0810334060633871,
      "loss": 0.9573,
      "step": 117640
    },
    {
      "epoch": 189.77,
      "learning_rate": 0.08103018026016129,
      "loss": 0.9703,
      "step": 117660
    },
    {
      "epoch": 189.81,
      "learning_rate": 0.08102695445693549,
      "loss": 0.9439,
      "step": 117680
    },
    {
      "epoch": 189.84,
      "learning_rate": 0.08102372865370969,
      "loss": 0.97,
      "step": 117700
    },
    {
      "epoch": 189.87,
      "learning_rate": 0.08102050285048387,
      "loss": 0.9599,
      "step": 117720
    },
    {
      "epoch": 189.9,
      "learning_rate": 0.08101727704725807,
      "loss": 0.9824,
      "step": 117740
    },
    {
      "epoch": 189.94,
      "learning_rate": 0.08101405124403227,
      "loss": 0.9786,
      "step": 117760
    },
    {
      "epoch": 189.97,
      "learning_rate": 0.08101082544080646,
      "loss": 0.9916,
      "step": 117780
    },
    {
      "epoch": 190.0,
      "learning_rate": 0.08100759963758065,
      "loss": 0.9828,
      "step": 117800
    },
    {
      "epoch": 190.0,
      "eval_accuracy": {
        "accuracy": 0.7373351026461634
      },
      "eval_loss": 1.366626262664795,
      "eval_runtime": 2.7228,
      "eval_samples_per_second": 4705.129,
      "eval_steps_per_second": 73.822,
      "step": 117800
    },
    {
      "epoch": 190.03,
      "learning_rate": 0.08100437383435484,
      "loss": 1.0,
      "step": 117820
    },
    {
      "epoch": 190.06,
      "learning_rate": 0.08100114803112904,
      "loss": 0.97,
      "step": 117840
    },
    {
      "epoch": 190.1,
      "learning_rate": 0.08099792222790324,
      "loss": 0.945,
      "step": 117860
    },
    {
      "epoch": 190.13,
      "learning_rate": 0.08099469642467742,
      "loss": 0.926,
      "step": 117880
    },
    {
      "epoch": 190.16,
      "learning_rate": 0.08099147062145161,
      "loss": 0.9331,
      "step": 117900
    },
    {
      "epoch": 190.19,
      "learning_rate": 0.08098824481822582,
      "loss": 0.9394,
      "step": 117920
    },
    {
      "epoch": 190.23,
      "learning_rate": 0.080985019015,
      "loss": 0.9749,
      "step": 117940
    },
    {
      "epoch": 190.26,
      "learning_rate": 0.08098179321177419,
      "loss": 0.9679,
      "step": 117960
    },
    {
      "epoch": 190.29,
      "learning_rate": 0.08097856740854839,
      "loss": 0.9633,
      "step": 117980
    },
    {
      "epoch": 190.32,
      "learning_rate": 0.08097534160532259,
      "loss": 0.9755,
      "step": 118000
    },
    {
      "epoch": 190.35,
      "learning_rate": 0.08097211580209678,
      "loss": 0.9641,
      "step": 118020
    },
    {
      "epoch": 190.39,
      "learning_rate": 0.08096888999887097,
      "loss": 0.9228,
      "step": 118040
    },
    {
      "epoch": 190.42,
      "learning_rate": 0.08096566419564517,
      "loss": 0.9293,
      "step": 118060
    },
    {
      "epoch": 190.45,
      "learning_rate": 0.08096243839241936,
      "loss": 0.9723,
      "step": 118080
    },
    {
      "epoch": 190.48,
      "learning_rate": 0.08095921258919356,
      "loss": 0.9431,
      "step": 118100
    },
    {
      "epoch": 190.52,
      "learning_rate": 0.08095598678596774,
      "loss": 0.9468,
      "step": 118120
    },
    {
      "epoch": 190.55,
      "learning_rate": 0.08095276098274194,
      "loss": 0.9369,
      "step": 118140
    },
    {
      "epoch": 190.58,
      "learning_rate": 0.08094953517951614,
      "loss": 0.9377,
      "step": 118160
    },
    {
      "epoch": 190.61,
      "learning_rate": 0.08094630937629033,
      "loss": 0.962,
      "step": 118180
    },
    {
      "epoch": 190.65,
      "learning_rate": 0.08094308357306451,
      "loss": 0.9472,
      "step": 118200
    },
    {
      "epoch": 190.68,
      "learning_rate": 0.08093985776983872,
      "loss": 1.0049,
      "step": 118220
    },
    {
      "epoch": 190.71,
      "learning_rate": 0.08093663196661291,
      "loss": 0.9776,
      "step": 118240
    },
    {
      "epoch": 190.74,
      "learning_rate": 0.0809334061633871,
      "loss": 0.9859,
      "step": 118260
    },
    {
      "epoch": 190.77,
      "learning_rate": 0.0809301803601613,
      "loss": 0.9646,
      "step": 118280
    },
    {
      "epoch": 190.81,
      "learning_rate": 0.0809269545569355,
      "loss": 0.9467,
      "step": 118300
    },
    {
      "epoch": 190.84,
      "learning_rate": 0.08092372875370968,
      "loss": 0.918,
      "step": 118320
    },
    {
      "epoch": 190.87,
      "learning_rate": 0.08092050295048388,
      "loss": 0.9489,
      "step": 118340
    },
    {
      "epoch": 190.9,
      "learning_rate": 0.08091727714725806,
      "loss": 0.9595,
      "step": 118360
    },
    {
      "epoch": 190.94,
      "learning_rate": 0.08091405134403226,
      "loss": 0.9634,
      "step": 118380
    },
    {
      "epoch": 190.97,
      "learning_rate": 0.08091082554080646,
      "loss": 0.9919,
      "step": 118400
    },
    {
      "epoch": 191.0,
      "learning_rate": 0.08090776102774194,
      "loss": 0.9671,
      "step": 118420
    },
    {
      "epoch": 191.0,
      "eval_accuracy": {
        "accuracy": 0.7506830067910389
      },
      "eval_loss": 1.2571450471878052,
      "eval_runtime": 3.1494,
      "eval_samples_per_second": 4067.806,
      "eval_steps_per_second": 63.822,
      "step": 118420
    },
    {
      "epoch": 191.03,
      "learning_rate": 0.08090453522451613,
      "loss": 0.9273,
      "step": 118440
    },
    {
      "epoch": 191.06,
      "learning_rate": 0.08090130942129033,
      "loss": 0.922,
      "step": 118460
    },
    {
      "epoch": 191.1,
      "learning_rate": 0.08089808361806453,
      "loss": 0.9468,
      "step": 118480
    },
    {
      "epoch": 191.13,
      "learning_rate": 0.08089485781483871,
      "loss": 0.9612,
      "step": 118500
    },
    {
      "epoch": 191.16,
      "learning_rate": 0.08089163201161291,
      "loss": 0.9655,
      "step": 118520
    },
    {
      "epoch": 191.19,
      "learning_rate": 0.08088840620838711,
      "loss": 0.9352,
      "step": 118540
    },
    {
      "epoch": 191.23,
      "learning_rate": 0.0808851804051613,
      "loss": 0.968,
      "step": 118560
    },
    {
      "epoch": 191.26,
      "learning_rate": 0.0808819546019355,
      "loss": 0.9299,
      "step": 118580
    },
    {
      "epoch": 191.29,
      "learning_rate": 0.08087872879870969,
      "loss": 0.9146,
      "step": 118600
    },
    {
      "epoch": 191.32,
      "learning_rate": 0.08087550299548388,
      "loss": 0.9179,
      "step": 118620
    },
    {
      "epoch": 191.35,
      "learning_rate": 0.08087227719225806,
      "loss": 0.9302,
      "step": 118640
    },
    {
      "epoch": 191.39,
      "learning_rate": 0.08086905138903226,
      "loss": 0.9554,
      "step": 118660
    },
    {
      "epoch": 191.42,
      "learning_rate": 0.08086582558580645,
      "loss": 0.9411,
      "step": 118680
    },
    {
      "epoch": 191.45,
      "learning_rate": 0.08086259978258066,
      "loss": 0.9678,
      "step": 118700
    },
    {
      "epoch": 191.48,
      "learning_rate": 0.08085937397935485,
      "loss": 0.9811,
      "step": 118720
    },
    {
      "epoch": 191.52,
      "learning_rate": 0.08085614817612903,
      "loss": 0.9512,
      "step": 118740
    },
    {
      "epoch": 191.55,
      "learning_rate": 0.08085292237290323,
      "loss": 0.9494,
      "step": 118760
    },
    {
      "epoch": 191.58,
      "learning_rate": 0.08084969656967743,
      "loss": 0.9563,
      "step": 118780
    },
    {
      "epoch": 191.61,
      "learning_rate": 0.08084647076645161,
      "loss": 0.949,
      "step": 118800
    },
    {
      "epoch": 191.65,
      "learning_rate": 0.08084324496322581,
      "loss": 0.9652,
      "step": 118820
    },
    {
      "epoch": 191.68,
      "learning_rate": 0.08084001916000001,
      "loss": 0.9768,
      "step": 118840
    },
    {
      "epoch": 191.71,
      "learning_rate": 0.0808367933567742,
      "loss": 0.9579,
      "step": 118860
    },
    {
      "epoch": 191.74,
      "learning_rate": 0.0808335675535484,
      "loss": 0.9429,
      "step": 118880
    },
    {
      "epoch": 191.77,
      "learning_rate": 0.08083034175032258,
      "loss": 0.981,
      "step": 118900
    },
    {
      "epoch": 191.81,
      "learning_rate": 0.08082711594709678,
      "loss": 1.0036,
      "step": 118920
    },
    {
      "epoch": 191.84,
      "learning_rate": 0.08082389014387097,
      "loss": 0.9883,
      "step": 118940
    },
    {
      "epoch": 191.87,
      "learning_rate": 0.08082066434064517,
      "loss": 0.9847,
      "step": 118960
    },
    {
      "epoch": 191.9,
      "learning_rate": 0.08081743853741935,
      "loss": 0.9775,
      "step": 118980
    },
    {
      "epoch": 191.94,
      "learning_rate": 0.08081421273419356,
      "loss": 0.9962,
      "step": 119000
    },
    {
      "epoch": 191.97,
      "learning_rate": 0.08081098693096775,
      "loss": 0.9833,
      "step": 119020
    },
    {
      "epoch": 192.0,
      "learning_rate": 0.08080776112774193,
      "loss": 0.9872,
      "step": 119040
    },
    {
      "epoch": 192.0,
      "eval_accuracy": {
        "accuracy": 0.7350714229958629
      },
      "eval_loss": 1.3637093305587769,
      "eval_runtime": 2.8372,
      "eval_samples_per_second": 4515.38,
      "eval_steps_per_second": 70.845,
      "step": 119040
    },
    {
      "epoch": 192.03,
      "learning_rate": 0.08080453532451613,
      "loss": 1.0056,
      "step": 119060
    },
    {
      "epoch": 192.06,
      "learning_rate": 0.08080130952129033,
      "loss": 0.9432,
      "step": 119080
    },
    {
      "epoch": 192.1,
      "learning_rate": 0.08079808371806452,
      "loss": 0.9805,
      "step": 119100
    },
    {
      "epoch": 192.13,
      "learning_rate": 0.08079485791483872,
      "loss": 0.9483,
      "step": 119120
    },
    {
      "epoch": 192.16,
      "learning_rate": 0.08079163211161292,
      "loss": 0.9471,
      "step": 119140
    },
    {
      "epoch": 192.19,
      "learning_rate": 0.0807884063083871,
      "loss": 0.9728,
      "step": 119160
    },
    {
      "epoch": 192.23,
      "learning_rate": 0.0807851805051613,
      "loss": 0.9393,
      "step": 119180
    },
    {
      "epoch": 192.26,
      "learning_rate": 0.08078195470193548,
      "loss": 0.9675,
      "step": 119200
    },
    {
      "epoch": 192.29,
      "learning_rate": 0.08077872889870968,
      "loss": 0.9409,
      "step": 119220
    },
    {
      "epoch": 192.32,
      "learning_rate": 0.08077550309548388,
      "loss": 0.9622,
      "step": 119240
    },
    {
      "epoch": 192.35,
      "learning_rate": 0.08077227729225807,
      "loss": 0.9627,
      "step": 119260
    },
    {
      "epoch": 192.39,
      "learning_rate": 0.08076905148903225,
      "loss": 0.9721,
      "step": 119280
    },
    {
      "epoch": 192.42,
      "learning_rate": 0.08076582568580647,
      "loss": 0.9454,
      "step": 119300
    },
    {
      "epoch": 192.45,
      "learning_rate": 0.08076259988258065,
      "loss": 0.9897,
      "step": 119320
    },
    {
      "epoch": 192.48,
      "learning_rate": 0.08075937407935484,
      "loss": 0.9538,
      "step": 119340
    },
    {
      "epoch": 192.52,
      "learning_rate": 0.08075614827612904,
      "loss": 0.967,
      "step": 119360
    },
    {
      "epoch": 192.55,
      "learning_rate": 0.08075292247290324,
      "loss": 0.9548,
      "step": 119380
    },
    {
      "epoch": 192.58,
      "learning_rate": 0.08074969666967742,
      "loss": 0.9458,
      "step": 119400
    },
    {
      "epoch": 192.61,
      "learning_rate": 0.08074647086645162,
      "loss": 0.9443,
      "step": 119420
    },
    {
      "epoch": 192.65,
      "learning_rate": 0.0807432450632258,
      "loss": 0.9202,
      "step": 119440
    },
    {
      "epoch": 192.68,
      "learning_rate": 0.08074001926,
      "loss": 0.9435,
      "step": 119460
    },
    {
      "epoch": 192.71,
      "learning_rate": 0.0807367934567742,
      "loss": 0.9482,
      "step": 119480
    },
    {
      "epoch": 192.74,
      "learning_rate": 0.08073356765354839,
      "loss": 0.9634,
      "step": 119500
    },
    {
      "epoch": 192.77,
      "learning_rate": 0.08073034185032259,
      "loss": 0.9568,
      "step": 119520
    },
    {
      "epoch": 192.81,
      "learning_rate": 0.08072711604709679,
      "loss": 0.9503,
      "step": 119540
    },
    {
      "epoch": 192.84,
      "learning_rate": 0.08072389024387097,
      "loss": 0.9639,
      "step": 119560
    },
    {
      "epoch": 192.87,
      "learning_rate": 0.08072066444064516,
      "loss": 0.9796,
      "step": 119580
    },
    {
      "epoch": 192.9,
      "learning_rate": 0.08071743863741937,
      "loss": 0.9664,
      "step": 119600
    },
    {
      "epoch": 192.94,
      "learning_rate": 0.08071421283419355,
      "loss": 0.9534,
      "step": 119620
    },
    {
      "epoch": 192.97,
      "learning_rate": 0.08071098703096774,
      "loss": 0.9469,
      "step": 119640
    },
    {
      "epoch": 193.0,
      "learning_rate": 0.08070776122774194,
      "loss": 0.9546,
      "step": 119660
    },
    {
      "epoch": 193.0,
      "eval_accuracy": {
        "accuracy": 0.7417844040277887
      },
      "eval_loss": 1.313646674156189,
      "eval_runtime": 2.624,
      "eval_samples_per_second": 4882.198,
      "eval_steps_per_second": 76.6,
      "step": 119660
    },
    {
      "epoch": 193.03,
      "learning_rate": 0.08070453542451614,
      "loss": 0.995,
      "step": 119680
    },
    {
      "epoch": 193.06,
      "learning_rate": 0.08070130962129032,
      "loss": 0.9664,
      "step": 119700
    },
    {
      "epoch": 193.1,
      "learning_rate": 0.08069808381806452,
      "loss": 0.9573,
      "step": 119720
    },
    {
      "epoch": 193.13,
      "learning_rate": 0.08069485801483871,
      "loss": 0.9407,
      "step": 119740
    },
    {
      "epoch": 193.16,
      "learning_rate": 0.08069163221161291,
      "loss": 0.9346,
      "step": 119760
    },
    {
      "epoch": 193.19,
      "learning_rate": 0.0806884064083871,
      "loss": 0.9371,
      "step": 119780
    },
    {
      "epoch": 193.23,
      "learning_rate": 0.08068518060516129,
      "loss": 0.9209,
      "step": 119800
    },
    {
      "epoch": 193.26,
      "learning_rate": 0.08068195480193549,
      "loss": 0.9337,
      "step": 119820
    },
    {
      "epoch": 193.29,
      "learning_rate": 0.08067872899870969,
      "loss": 0.952,
      "step": 119840
    },
    {
      "epoch": 193.32,
      "learning_rate": 0.08067550319548387,
      "loss": 0.9627,
      "step": 119860
    },
    {
      "epoch": 193.35,
      "learning_rate": 0.08067227739225806,
      "loss": 0.9579,
      "step": 119880
    },
    {
      "epoch": 193.39,
      "learning_rate": 0.08066905158903227,
      "loss": 0.9514,
      "step": 119900
    },
    {
      "epoch": 193.42,
      "learning_rate": 0.08066582578580646,
      "loss": 0.9208,
      "step": 119920
    },
    {
      "epoch": 193.45,
      "learning_rate": 0.08066259998258066,
      "loss": 0.9411,
      "step": 119940
    },
    {
      "epoch": 193.48,
      "learning_rate": 0.08065937417935484,
      "loss": 0.9491,
      "step": 119960
    },
    {
      "epoch": 193.52,
      "learning_rate": 0.08065614837612903,
      "loss": 0.9295,
      "step": 119980
    },
    {
      "epoch": 193.55,
      "learning_rate": 0.08065292257290323,
      "loss": 0.9209,
      "step": 120000
    },
    {
      "epoch": 193.58,
      "learning_rate": 0.08064969676967743,
      "loss": 0.9631,
      "step": 120020
    },
    {
      "epoch": 193.61,
      "learning_rate": 0.08064647096645161,
      "loss": 0.9712,
      "step": 120040
    },
    {
      "epoch": 193.65,
      "learning_rate": 0.08064324516322581,
      "loss": 0.9649,
      "step": 120060
    },
    {
      "epoch": 193.68,
      "learning_rate": 0.08064001936000001,
      "loss": 0.9643,
      "step": 120080
    },
    {
      "epoch": 193.71,
      "learning_rate": 0.0806367935567742,
      "loss": 0.9646,
      "step": 120100
    },
    {
      "epoch": 193.74,
      "learning_rate": 0.0806335677535484,
      "loss": 0.9773,
      "step": 120120
    },
    {
      "epoch": 193.77,
      "learning_rate": 0.08063034195032259,
      "loss": 0.9776,
      "step": 120140
    },
    {
      "epoch": 193.81,
      "learning_rate": 0.08062711614709678,
      "loss": 0.9892,
      "step": 120160
    },
    {
      "epoch": 193.84,
      "learning_rate": 0.08062389034387098,
      "loss": 0.978,
      "step": 120180
    },
    {
      "epoch": 193.87,
      "learning_rate": 0.08062066454064518,
      "loss": 0.9645,
      "step": 120200
    },
    {
      "epoch": 193.9,
      "learning_rate": 0.08061743873741935,
      "loss": 0.9667,
      "step": 120220
    },
    {
      "epoch": 193.94,
      "learning_rate": 0.08061421293419356,
      "loss": 0.9479,
      "step": 120240
    },
    {
      "epoch": 193.97,
      "learning_rate": 0.08061098713096775,
      "loss": 0.9643,
      "step": 120260
    },
    {
      "epoch": 194.0,
      "learning_rate": 0.08060776132774193,
      "loss": 0.9428,
      "step": 120280
    },
    {
      "epoch": 194.0,
      "eval_accuracy": {
        "accuracy": 0.7445164311919444
      },
      "eval_loss": 1.292154312133789,
      "eval_runtime": 2.7881,
      "eval_samples_per_second": 4594.843,
      "eval_steps_per_second": 72.091,
      "step": 120280
    },
    {
      "epoch": 194.03,
      "learning_rate": 0.08060453552451613,
      "loss": 0.9675,
      "step": 120300
    },
    {
      "epoch": 194.06,
      "learning_rate": 0.08060130972129033,
      "loss": 0.9745,
      "step": 120320
    },
    {
      "epoch": 194.1,
      "learning_rate": 0.08059808391806451,
      "loss": 0.9114,
      "step": 120340
    },
    {
      "epoch": 194.13,
      "learning_rate": 0.08059485811483871,
      "loss": 0.9292,
      "step": 120360
    },
    {
      "epoch": 194.16,
      "learning_rate": 0.08059163231161291,
      "loss": 0.9363,
      "step": 120380
    },
    {
      "epoch": 194.19,
      "learning_rate": 0.0805884065083871,
      "loss": 0.9219,
      "step": 120400
    },
    {
      "epoch": 194.23,
      "learning_rate": 0.0805851807051613,
      "loss": 0.9531,
      "step": 120420
    },
    {
      "epoch": 194.26,
      "learning_rate": 0.0805819549019355,
      "loss": 0.9269,
      "step": 120440
    },
    {
      "epoch": 194.29,
      "learning_rate": 0.08057872909870968,
      "loss": 0.9577,
      "step": 120460
    },
    {
      "epoch": 194.32,
      "learning_rate": 0.08057550329548388,
      "loss": 0.9539,
      "step": 120480
    },
    {
      "epoch": 194.35,
      "learning_rate": 0.08057227749225808,
      "loss": 0.9837,
      "step": 120500
    },
    {
      "epoch": 194.39,
      "learning_rate": 0.08056905168903225,
      "loss": 0.97,
      "step": 120520
    },
    {
      "epoch": 194.42,
      "learning_rate": 0.08056582588580646,
      "loss": 0.9664,
      "step": 120540
    },
    {
      "epoch": 194.45,
      "learning_rate": 0.08056260008258065,
      "loss": 0.9281,
      "step": 120560
    },
    {
      "epoch": 194.48,
      "learning_rate": 0.08055937427935483,
      "loss": 0.9626,
      "step": 120580
    },
    {
      "epoch": 194.52,
      "learning_rate": 0.08055614847612903,
      "loss": 0.9321,
      "step": 120600
    },
    {
      "epoch": 194.55,
      "learning_rate": 0.08055292267290323,
      "loss": 0.9679,
      "step": 120620
    },
    {
      "epoch": 194.58,
      "learning_rate": 0.08054969686967742,
      "loss": 0.9806,
      "step": 120640
    },
    {
      "epoch": 194.61,
      "learning_rate": 0.08054647106645162,
      "loss": 0.935,
      "step": 120660
    },
    {
      "epoch": 194.65,
      "learning_rate": 0.08054324526322582,
      "loss": 0.928,
      "step": 120680
    },
    {
      "epoch": 194.68,
      "learning_rate": 0.08054001946,
      "loss": 0.9242,
      "step": 120700
    },
    {
      "epoch": 194.71,
      "learning_rate": 0.0805367936567742,
      "loss": 0.9532,
      "step": 120720
    },
    {
      "epoch": 194.74,
      "learning_rate": 0.0805335678535484,
      "loss": 0.9564,
      "step": 120740
    },
    {
      "epoch": 194.77,
      "learning_rate": 0.08053034205032258,
      "loss": 0.9659,
      "step": 120760
    },
    {
      "epoch": 194.81,
      "learning_rate": 0.08052711624709678,
      "loss": 0.9594,
      "step": 120780
    },
    {
      "epoch": 194.84,
      "learning_rate": 0.08052389044387098,
      "loss": 0.9824,
      "step": 120800
    },
    {
      "epoch": 194.87,
      "learning_rate": 0.08052066464064515,
      "loss": 0.9812,
      "step": 120820
    },
    {
      "epoch": 194.9,
      "learning_rate": 0.08051743883741937,
      "loss": 0.9755,
      "step": 120840
    },
    {
      "epoch": 194.94,
      "learning_rate": 0.08051437432435485,
      "loss": 0.9903,
      "step": 120860
    },
    {
      "epoch": 194.97,
      "learning_rate": 0.08051114852112903,
      "loss": 0.9816,
      "step": 120880
    },
    {
      "epoch": 195.0,
      "learning_rate": 0.08050792271790323,
      "loss": 0.9936,
      "step": 120900
    },
    {
      "epoch": 195.0,
      "eval_accuracy": {
        "accuracy": 0.7431113886503786
      },
      "eval_loss": 1.2975555658340454,
      "eval_runtime": 2.6949,
      "eval_samples_per_second": 4753.786,
      "eval_steps_per_second": 74.585,
      "step": 120900
    },
    {
      "epoch": 195.03,
      "learning_rate": 0.08050469691467743,
      "loss": 0.9693,
      "step": 120920
    },
    {
      "epoch": 195.06,
      "learning_rate": 0.08050147111145162,
      "loss": 0.9386,
      "step": 120940
    },
    {
      "epoch": 195.1,
      "learning_rate": 0.0804982453082258,
      "loss": 0.9362,
      "step": 120960
    },
    {
      "epoch": 195.13,
      "learning_rate": 0.08049501950500002,
      "loss": 0.9348,
      "step": 120980
    },
    {
      "epoch": 195.16,
      "learning_rate": 0.0804917937017742,
      "loss": 0.9328,
      "step": 121000
    },
    {
      "epoch": 195.19,
      "learning_rate": 0.0804885678985484,
      "loss": 0.97,
      "step": 121020
    },
    {
      "epoch": 195.23,
      "learning_rate": 0.08048534209532258,
      "loss": 0.9816,
      "step": 121040
    },
    {
      "epoch": 195.26,
      "learning_rate": 0.08048211629209677,
      "loss": 0.9483,
      "step": 121060
    },
    {
      "epoch": 195.29,
      "learning_rate": 0.08047889048887097,
      "loss": 0.9234,
      "step": 121080
    },
    {
      "epoch": 195.32,
      "learning_rate": 0.08047566468564517,
      "loss": 0.9426,
      "step": 121100
    },
    {
      "epoch": 195.35,
      "learning_rate": 0.08047243888241935,
      "loss": 0.9238,
      "step": 121120
    },
    {
      "epoch": 195.39,
      "learning_rate": 0.08046921307919355,
      "loss": 0.9614,
      "step": 121140
    },
    {
      "epoch": 195.42,
      "learning_rate": 0.08046598727596775,
      "loss": 0.9698,
      "step": 121160
    },
    {
      "epoch": 195.45,
      "learning_rate": 0.08046276147274194,
      "loss": 0.9767,
      "step": 121180
    },
    {
      "epoch": 195.48,
      "learning_rate": 0.08045953566951614,
      "loss": 0.9774,
      "step": 121200
    },
    {
      "epoch": 195.52,
      "learning_rate": 0.08045630986629033,
      "loss": 0.9274,
      "step": 121220
    },
    {
      "epoch": 195.55,
      "learning_rate": 0.08045308406306452,
      "loss": 0.9302,
      "step": 121240
    },
    {
      "epoch": 195.58,
      "learning_rate": 0.0804498582598387,
      "loss": 0.936,
      "step": 121260
    },
    {
      "epoch": 195.61,
      "learning_rate": 0.08044663245661292,
      "loss": 0.9587,
      "step": 121280
    },
    {
      "epoch": 195.65,
      "learning_rate": 0.08044340665338709,
      "loss": 0.9699,
      "step": 121300
    },
    {
      "epoch": 195.68,
      "learning_rate": 0.0804401808501613,
      "loss": 0.9854,
      "step": 121320
    },
    {
      "epoch": 195.71,
      "learning_rate": 0.08043695504693549,
      "loss": 0.9645,
      "step": 121340
    },
    {
      "epoch": 195.74,
      "learning_rate": 0.08043372924370967,
      "loss": 0.9574,
      "step": 121360
    },
    {
      "epoch": 195.77,
      "learning_rate": 0.08043050344048387,
      "loss": 0.9614,
      "step": 121380
    },
    {
      "epoch": 195.81,
      "learning_rate": 0.08042727763725807,
      "loss": 0.9583,
      "step": 121400
    },
    {
      "epoch": 195.84,
      "learning_rate": 0.08042405183403226,
      "loss": 0.9627,
      "step": 121420
    },
    {
      "epoch": 195.87,
      "learning_rate": 0.08042082603080646,
      "loss": 0.9608,
      "step": 121440
    },
    {
      "epoch": 195.9,
      "learning_rate": 0.08041760022758065,
      "loss": 0.9556,
      "step": 121460
    },
    {
      "epoch": 195.94,
      "learning_rate": 0.08041437442435484,
      "loss": 0.9554,
      "step": 121480
    },
    {
      "epoch": 195.97,
      "learning_rate": 0.08041114862112904,
      "loss": 0.9621,
      "step": 121500
    },
    {
      "epoch": 196.0,
      "learning_rate": 0.08040792281790324,
      "loss": 0.9502,
      "step": 121520
    },
    {
      "epoch": 196.0,
      "eval_accuracy": {
        "accuracy": 0.7383498555928499
      },
      "eval_loss": 1.3209458589553833,
      "eval_runtime": 3.243,
      "eval_samples_per_second": 3950.34,
      "eval_steps_per_second": 61.979,
      "step": 121520
    },
    {
      "epoch": 196.03,
      "learning_rate": 0.08040469701467742,
      "loss": 0.987,
      "step": 121540
    },
    {
      "epoch": 196.06,
      "learning_rate": 0.08040147121145162,
      "loss": 0.9579,
      "step": 121560
    },
    {
      "epoch": 196.1,
      "learning_rate": 0.08039824540822582,
      "loss": 0.9559,
      "step": 121580
    },
    {
      "epoch": 196.13,
      "learning_rate": 0.08039501960499999,
      "loss": 0.9571,
      "step": 121600
    },
    {
      "epoch": 196.16,
      "learning_rate": 0.0803917938017742,
      "loss": 0.9423,
      "step": 121620
    },
    {
      "epoch": 196.19,
      "learning_rate": 0.08038856799854839,
      "loss": 0.9273,
      "step": 121640
    },
    {
      "epoch": 196.23,
      "learning_rate": 0.08038534219532258,
      "loss": 0.9384,
      "step": 121660
    },
    {
      "epoch": 196.26,
      "learning_rate": 0.08038211639209678,
      "loss": 0.9374,
      "step": 121680
    },
    {
      "epoch": 196.29,
      "learning_rate": 0.08037889058887097,
      "loss": 0.9354,
      "step": 121700
    },
    {
      "epoch": 196.32,
      "learning_rate": 0.08037566478564516,
      "loss": 0.9433,
      "step": 121720
    },
    {
      "epoch": 196.35,
      "learning_rate": 0.08037243898241936,
      "loss": 0.944,
      "step": 121740
    },
    {
      "epoch": 196.39,
      "learning_rate": 0.08036921317919356,
      "loss": 0.9661,
      "step": 121760
    },
    {
      "epoch": 196.42,
      "learning_rate": 0.08036598737596774,
      "loss": 0.9791,
      "step": 121780
    },
    {
      "epoch": 196.45,
      "learning_rate": 0.08036276157274194,
      "loss": 0.9456,
      "step": 121800
    },
    {
      "epoch": 196.48,
      "learning_rate": 0.08035953576951614,
      "loss": 0.9732,
      "step": 121820
    },
    {
      "epoch": 196.52,
      "learning_rate": 0.08035630996629033,
      "loss": 0.9591,
      "step": 121840
    },
    {
      "epoch": 196.55,
      "learning_rate": 0.08035308416306453,
      "loss": 0.9521,
      "step": 121860
    },
    {
      "epoch": 196.58,
      "learning_rate": 0.08034985835983872,
      "loss": 0.957,
      "step": 121880
    },
    {
      "epoch": 196.61,
      "learning_rate": 0.0803466325566129,
      "loss": 0.985,
      "step": 121900
    },
    {
      "epoch": 196.65,
      "learning_rate": 0.08034340675338711,
      "loss": 0.916,
      "step": 121920
    },
    {
      "epoch": 196.68,
      "learning_rate": 0.0803401809501613,
      "loss": 0.9167,
      "step": 121940
    },
    {
      "epoch": 196.71,
      "learning_rate": 0.08033695514693548,
      "loss": 0.9506,
      "step": 121960
    },
    {
      "epoch": 196.74,
      "learning_rate": 0.08033372934370968,
      "loss": 0.9462,
      "step": 121980
    },
    {
      "epoch": 196.77,
      "learning_rate": 0.08033050354048388,
      "loss": 0.9653,
      "step": 122000
    },
    {
      "epoch": 196.81,
      "learning_rate": 0.08032727773725806,
      "loss": 0.9521,
      "step": 122020
    },
    {
      "epoch": 196.84,
      "learning_rate": 0.08032405193403226,
      "loss": 0.9963,
      "step": 122040
    },
    {
      "epoch": 196.87,
      "learning_rate": 0.08032082613080646,
      "loss": 0.9733,
      "step": 122060
    },
    {
      "epoch": 196.9,
      "learning_rate": 0.08031760032758065,
      "loss": 0.9902,
      "step": 122080
    },
    {
      "epoch": 196.94,
      "learning_rate": 0.08031437452435485,
      "loss": 0.9791,
      "step": 122100
    },
    {
      "epoch": 196.97,
      "learning_rate": 0.08031114872112904,
      "loss": 0.9356,
      "step": 122120
    },
    {
      "epoch": 197.0,
      "learning_rate": 0.08030792291790323,
      "loss": 0.9554,
      "step": 122140
    },
    {
      "epoch": 197.0,
      "eval_accuracy": {
        "accuracy": 0.746155647490438
      },
      "eval_loss": 1.3076502084732056,
      "eval_runtime": 2.7624,
      "eval_samples_per_second": 4637.573,
      "eval_steps_per_second": 72.762,
      "step": 122140
    },
    {
      "epoch": 197.03,
      "learning_rate": 0.08030469711467743,
      "loss": 0.9867,
      "step": 122160
    },
    {
      "epoch": 197.06,
      "learning_rate": 0.08030147131145163,
      "loss": 0.9539,
      "step": 122180
    },
    {
      "epoch": 197.1,
      "learning_rate": 0.0802982455082258,
      "loss": 0.9823,
      "step": 122200
    },
    {
      "epoch": 197.13,
      "learning_rate": 0.08029501970500001,
      "loss": 0.9459,
      "step": 122220
    },
    {
      "epoch": 197.16,
      "learning_rate": 0.0802917939017742,
      "loss": 0.9378,
      "step": 122240
    },
    {
      "epoch": 197.19,
      "learning_rate": 0.0802885680985484,
      "loss": 0.9312,
      "step": 122260
    },
    {
      "epoch": 197.23,
      "learning_rate": 0.08028534229532258,
      "loss": 0.9351,
      "step": 122280
    },
    {
      "epoch": 197.26,
      "learning_rate": 0.08028211649209678,
      "loss": 0.9426,
      "step": 122300
    },
    {
      "epoch": 197.29,
      "learning_rate": 0.08027889068887097,
      "loss": 0.9591,
      "step": 122320
    },
    {
      "epoch": 197.32,
      "learning_rate": 0.08027566488564516,
      "loss": 0.9472,
      "step": 122340
    },
    {
      "epoch": 197.35,
      "learning_rate": 0.08027243908241936,
      "loss": 0.9641,
      "step": 122360
    },
    {
      "epoch": 197.39,
      "learning_rate": 0.08026921327919355,
      "loss": 0.9562,
      "step": 122380
    },
    {
      "epoch": 197.42,
      "learning_rate": 0.08026598747596775,
      "loss": 0.969,
      "step": 122400
    },
    {
      "epoch": 197.45,
      "learning_rate": 0.08026276167274195,
      "loss": 0.9641,
      "step": 122420
    },
    {
      "epoch": 197.48,
      "learning_rate": 0.08025953586951613,
      "loss": 0.9648,
      "step": 122440
    },
    {
      "epoch": 197.52,
      "learning_rate": 0.08025631006629033,
      "loss": 0.99,
      "step": 122460
    },
    {
      "epoch": 197.55,
      "learning_rate": 0.08025308426306453,
      "loss": 0.9397,
      "step": 122480
    },
    {
      "epoch": 197.58,
      "learning_rate": 0.08024985845983872,
      "loss": 0.9566,
      "step": 122500
    },
    {
      "epoch": 197.61,
      "learning_rate": 0.08024663265661292,
      "loss": 0.9379,
      "step": 122520
    },
    {
      "epoch": 197.65,
      "learning_rate": 0.0802434068533871,
      "loss": 0.9499,
      "step": 122540
    },
    {
      "epoch": 197.68,
      "learning_rate": 0.0802401810501613,
      "loss": 0.9684,
      "step": 122560
    },
    {
      "epoch": 197.71,
      "learning_rate": 0.08023695524693548,
      "loss": 0.9724,
      "step": 122580
    },
    {
      "epoch": 197.74,
      "learning_rate": 0.08023372944370968,
      "loss": 0.9745,
      "step": 122600
    },
    {
      "epoch": 197.77,
      "learning_rate": 0.08023050364048387,
      "loss": 0.9669,
      "step": 122620
    },
    {
      "epoch": 197.81,
      "learning_rate": 0.08022727783725807,
      "loss": 0.9612,
      "step": 122640
    },
    {
      "epoch": 197.84,
      "learning_rate": 0.08022405203403227,
      "loss": 0.9775,
      "step": 122660
    },
    {
      "epoch": 197.87,
      "learning_rate": 0.08022082623080645,
      "loss": 0.974,
      "step": 122680
    },
    {
      "epoch": 197.9,
      "learning_rate": 0.08021760042758065,
      "loss": 0.953,
      "step": 122700
    },
    {
      "epoch": 197.94,
      "learning_rate": 0.08021437462435485,
      "loss": 0.9791,
      "step": 122720
    },
    {
      "epoch": 197.97,
      "learning_rate": 0.08021114882112904,
      "loss": 0.9659,
      "step": 122740
    },
    {
      "epoch": 198.0,
      "learning_rate": 0.08020792301790323,
      "loss": 0.9678,
      "step": 122760
    },
    {
      "epoch": 198.0,
      "eval_accuracy": {
        "accuracy": 0.7424869252985715
      },
      "eval_loss": 1.3183221817016602,
      "eval_runtime": 3.8598,
      "eval_samples_per_second": 3319.085,
      "eval_steps_per_second": 52.075,
      "step": 122760
    },
    {
      "epoch": 198.03,
      "learning_rate": 0.08020469721467743,
      "loss": 0.9517,
      "step": 122780
    },
    {
      "epoch": 198.06,
      "learning_rate": 0.08020147141145162,
      "loss": 0.9515,
      "step": 122800
    },
    {
      "epoch": 198.1,
      "learning_rate": 0.08019824560822582,
      "loss": 0.9458,
      "step": 122820
    },
    {
      "epoch": 198.13,
      "learning_rate": 0.080195019805,
      "loss": 0.9574,
      "step": 122840
    },
    {
      "epoch": 198.16,
      "learning_rate": 0.0801917940017742,
      "loss": 0.9236,
      "step": 122860
    },
    {
      "epoch": 198.19,
      "learning_rate": 0.08018856819854839,
      "loss": 0.9247,
      "step": 122880
    },
    {
      "epoch": 198.23,
      "learning_rate": 0.08018534239532259,
      "loss": 0.9532,
      "step": 122900
    },
    {
      "epoch": 198.26,
      "learning_rate": 0.08018211659209677,
      "loss": 0.9394,
      "step": 122920
    },
    {
      "epoch": 198.29,
      "learning_rate": 0.08017889078887097,
      "loss": 0.9291,
      "step": 122940
    },
    {
      "epoch": 198.32,
      "learning_rate": 0.08017566498564517,
      "loss": 0.9413,
      "step": 122960
    },
    {
      "epoch": 198.35,
      "learning_rate": 0.08017243918241936,
      "loss": 0.9481,
      "step": 122980
    },
    {
      "epoch": 198.39,
      "learning_rate": 0.08016921337919355,
      "loss": 0.956,
      "step": 123000
    },
    {
      "epoch": 198.42,
      "learning_rate": 0.08016598757596775,
      "loss": 0.9401,
      "step": 123020
    },
    {
      "epoch": 198.45,
      "learning_rate": 0.08016276177274194,
      "loss": 0.9748,
      "step": 123040
    },
    {
      "epoch": 198.48,
      "learning_rate": 0.08015953596951614,
      "loss": 0.9702,
      "step": 123060
    },
    {
      "epoch": 198.52,
      "learning_rate": 0.08015631016629034,
      "loss": 0.9509,
      "step": 123080
    },
    {
      "epoch": 198.55,
      "learning_rate": 0.08015308436306452,
      "loss": 0.9713,
      "step": 123100
    },
    {
      "epoch": 198.58,
      "learning_rate": 0.08014985855983872,
      "loss": 0.9775,
      "step": 123120
    },
    {
      "epoch": 198.61,
      "learning_rate": 0.0801466327566129,
      "loss": 0.9623,
      "step": 123140
    },
    {
      "epoch": 198.65,
      "learning_rate": 0.0801434069533871,
      "loss": 0.9416,
      "step": 123160
    },
    {
      "epoch": 198.68,
      "learning_rate": 0.08014018115016129,
      "loss": 0.9647,
      "step": 123180
    },
    {
      "epoch": 198.71,
      "learning_rate": 0.08013695534693549,
      "loss": 0.9554,
      "step": 123200
    },
    {
      "epoch": 198.74,
      "learning_rate": 0.08013372954370968,
      "loss": 0.979,
      "step": 123220
    },
    {
      "epoch": 198.77,
      "learning_rate": 0.08013050374048387,
      "loss": 0.9821,
      "step": 123240
    },
    {
      "epoch": 198.81,
      "learning_rate": 0.08012727793725807,
      "loss": 0.9524,
      "step": 123260
    },
    {
      "epoch": 198.84,
      "learning_rate": 0.08012405213403226,
      "loss": 0.9548,
      "step": 123280
    },
    {
      "epoch": 198.87,
      "learning_rate": 0.08012082633080646,
      "loss": 0.9535,
      "step": 123300
    },
    {
      "epoch": 198.9,
      "learning_rate": 0.08011760052758066,
      "loss": 0.9538,
      "step": 123320
    },
    {
      "epoch": 198.94,
      "learning_rate": 0.08011437472435484,
      "loss": 0.9383,
      "step": 123340
    },
    {
      "epoch": 198.97,
      "learning_rate": 0.08011114892112904,
      "loss": 0.9449,
      "step": 123360
    },
    {
      "epoch": 199.0,
      "learning_rate": 0.08010808440806452,
      "loss": 0.94,
      "step": 123380
    },
    {
      "epoch": 199.0,
      "eval_accuracy": {
        "accuracy": 0.7432675044883303
      },
      "eval_loss": 1.30653715133667,
      "eval_runtime": 2.9911,
      "eval_samples_per_second": 4283.097,
      "eval_steps_per_second": 67.2,
      "step": 123380
    },
    {
      "epoch": 199.03,
      "learning_rate": 0.08010485860483871,
      "loss": 0.9132,
      "step": 123400
    },
    {
      "epoch": 199.06,
      "learning_rate": 0.08010163280161291,
      "loss": 0.919,
      "step": 123420
    },
    {
      "epoch": 199.1,
      "learning_rate": 0.0800984069983871,
      "loss": 0.9511,
      "step": 123440
    },
    {
      "epoch": 199.13,
      "learning_rate": 0.08009518119516129,
      "loss": 0.9382,
      "step": 123460
    },
    {
      "epoch": 199.16,
      "learning_rate": 0.08009195539193549,
      "loss": 0.9453,
      "step": 123480
    },
    {
      "epoch": 199.19,
      "learning_rate": 0.08008872958870969,
      "loss": 0.9533,
      "step": 123500
    },
    {
      "epoch": 199.23,
      "learning_rate": 0.08008550378548387,
      "loss": 0.9441,
      "step": 123520
    },
    {
      "epoch": 199.26,
      "learning_rate": 0.08008227798225807,
      "loss": 0.9623,
      "step": 123540
    },
    {
      "epoch": 199.29,
      "learning_rate": 0.08007905217903227,
      "loss": 0.9383,
      "step": 123560
    },
    {
      "epoch": 199.32,
      "learning_rate": 0.08007582637580644,
      "loss": 0.9537,
      "step": 123580
    },
    {
      "epoch": 199.35,
      "learning_rate": 0.08007260057258066,
      "loss": 0.9581,
      "step": 123600
    },
    {
      "epoch": 199.39,
      "learning_rate": 0.08006937476935484,
      "loss": 0.991,
      "step": 123620
    },
    {
      "epoch": 199.42,
      "learning_rate": 0.08006614896612904,
      "loss": 0.9534,
      "step": 123640
    },
    {
      "epoch": 199.45,
      "learning_rate": 0.08006292316290323,
      "loss": 0.9737,
      "step": 123660
    },
    {
      "epoch": 199.48,
      "learning_rate": 0.08005969735967743,
      "loss": 0.9594,
      "step": 123680
    },
    {
      "epoch": 199.52,
      "learning_rate": 0.08005647155645161,
      "loss": 0.9632,
      "step": 123700
    },
    {
      "epoch": 199.55,
      "learning_rate": 0.08005324575322581,
      "loss": 0.961,
      "step": 123720
    },
    {
      "epoch": 199.58,
      "learning_rate": 0.08005001995000001,
      "loss": 0.9783,
      "step": 123740
    },
    {
      "epoch": 199.61,
      "learning_rate": 0.0800467941467742,
      "loss": 0.9688,
      "step": 123760
    },
    {
      "epoch": 199.65,
      "learning_rate": 0.0800435683435484,
      "loss": 0.9495,
      "step": 123780
    },
    {
      "epoch": 199.68,
      "learning_rate": 0.08004034254032259,
      "loss": 0.9781,
      "step": 123800
    },
    {
      "epoch": 199.71,
      "learning_rate": 0.08003711673709678,
      "loss": 0.954,
      "step": 123820
    },
    {
      "epoch": 199.74,
      "learning_rate": 0.08003389093387098,
      "loss": 0.9649,
      "step": 123840
    },
    {
      "epoch": 199.77,
      "learning_rate": 0.08003066513064518,
      "loss": 0.9584,
      "step": 123860
    },
    {
      "epoch": 199.81,
      "learning_rate": 0.08002743932741936,
      "loss": 0.9734,
      "step": 123880
    },
    {
      "epoch": 199.84,
      "learning_rate": 0.08002421352419356,
      "loss": 0.9707,
      "step": 123900
    },
    {
      "epoch": 199.87,
      "learning_rate": 0.08002098772096775,
      "loss": 0.9766,
      "step": 123920
    },
    {
      "epoch": 199.9,
      "learning_rate": 0.08001776191774194,
      "loss": 0.986,
      "step": 123940
    },
    {
      "epoch": 199.94,
      "learning_rate": 0.08001453611451613,
      "loss": 0.9761,
      "step": 123960
    },
    {
      "epoch": 199.97,
      "learning_rate": 0.08001131031129033,
      "loss": 0.9825,
      "step": 123980
    },
    {
      "epoch": 200.0,
      "learning_rate": 0.08000808450806451,
      "loss": 0.9372,
      "step": 124000
    },
    {
      "epoch": 200.0,
      "eval_accuracy": {
        "accuracy": 0.7437358520021856
      },
      "eval_loss": 1.3309450149536133,
      "eval_runtime": 2.8049,
      "eval_samples_per_second": 4567.333,
      "eval_steps_per_second": 71.66,
      "step": 124000
    },
    {
      "epoch": 200.03,
      "learning_rate": 0.08000485870483871,
      "loss": 0.9825,
      "step": 124020
    },
    {
      "epoch": 200.06,
      "learning_rate": 0.08000163290161291,
      "loss": 0.9281,
      "step": 124040
    },
    {
      "epoch": 200.1,
      "learning_rate": 0.0799984070983871,
      "loss": 0.9645,
      "step": 124060
    },
    {
      "epoch": 200.13,
      "learning_rate": 0.0799951812951613,
      "loss": 0.9427,
      "step": 124080
    },
    {
      "epoch": 200.16,
      "learning_rate": 0.0799919554919355,
      "loss": 0.9542,
      "step": 124100
    },
    {
      "epoch": 200.19,
      "learning_rate": 0.07998872968870968,
      "loss": 0.9597,
      "step": 124120
    },
    {
      "epoch": 200.23,
      "learning_rate": 0.07998550388548388,
      "loss": 0.9488,
      "step": 124140
    },
    {
      "epoch": 200.26,
      "learning_rate": 0.07998227808225808,
      "loss": 0.9355,
      "step": 124160
    },
    {
      "epoch": 200.29,
      "learning_rate": 0.07997905227903226,
      "loss": 0.9832,
      "step": 124180
    },
    {
      "epoch": 200.32,
      "learning_rate": 0.07997582647580646,
      "loss": 0.9296,
      "step": 124200
    },
    {
      "epoch": 200.35,
      "learning_rate": 0.07997260067258065,
      "loss": 0.9555,
      "step": 124220
    },
    {
      "epoch": 200.39,
      "learning_rate": 0.07996937486935485,
      "loss": 0.9537,
      "step": 124240
    },
    {
      "epoch": 200.42,
      "learning_rate": 0.07996614906612903,
      "loss": 0.9387,
      "step": 124260
    },
    {
      "epoch": 200.45,
      "learning_rate": 0.07996292326290323,
      "loss": 0.919,
      "step": 124280
    },
    {
      "epoch": 200.48,
      "learning_rate": 0.07995969745967742,
      "loss": 0.9347,
      "step": 124300
    },
    {
      "epoch": 200.52,
      "learning_rate": 0.07995647165645162,
      "loss": 0.9779,
      "step": 124320
    },
    {
      "epoch": 200.55,
      "learning_rate": 0.07995324585322582,
      "loss": 0.9526,
      "step": 124340
    },
    {
      "epoch": 200.58,
      "learning_rate": 0.07995002005,
      "loss": 0.955,
      "step": 124360
    },
    {
      "epoch": 200.61,
      "learning_rate": 0.0799467942467742,
      "loss": 0.9725,
      "step": 124380
    },
    {
      "epoch": 200.65,
      "learning_rate": 0.0799435684435484,
      "loss": 0.963,
      "step": 124400
    },
    {
      "epoch": 200.68,
      "learning_rate": 0.07994034264032258,
      "loss": 0.9543,
      "step": 124420
    },
    {
      "epoch": 200.71,
      "learning_rate": 0.07993711683709678,
      "loss": 0.927,
      "step": 124440
    },
    {
      "epoch": 200.74,
      "learning_rate": 0.07993389103387097,
      "loss": 0.9615,
      "step": 124460
    },
    {
      "epoch": 200.77,
      "learning_rate": 0.07993066523064517,
      "loss": 0.9763,
      "step": 124480
    },
    {
      "epoch": 200.81,
      "learning_rate": 0.07992743942741937,
      "loss": 0.9637,
      "step": 124500
    },
    {
      "epoch": 200.84,
      "learning_rate": 0.07992421362419355,
      "loss": 0.9572,
      "step": 124520
    },
    {
      "epoch": 200.87,
      "learning_rate": 0.07992098782096775,
      "loss": 0.9644,
      "step": 124540
    },
    {
      "epoch": 200.9,
      "learning_rate": 0.07991776201774194,
      "loss": 0.9554,
      "step": 124560
    },
    {
      "epoch": 200.94,
      "learning_rate": 0.07991453621451614,
      "loss": 0.9461,
      "step": 124580
    },
    {
      "epoch": 200.97,
      "learning_rate": 0.07991131041129032,
      "loss": 0.9716,
      "step": 124600
    },
    {
      "epoch": 201.0,
      "learning_rate": 0.07990808460806452,
      "loss": 0.9577,
      "step": 124620
    },
    {
      "epoch": 201.0,
      "eval_accuracy": {
        "accuracy": 0.7412379985949574
      },
      "eval_loss": 1.3221670389175415,
      "eval_runtime": 2.7264,
      "eval_samples_per_second": 4698.932,
      "eval_steps_per_second": 73.725,
      "step": 124620
    },
    {
      "epoch": 201.03,
      "learning_rate": 0.07990485880483872,
      "loss": 0.9864,
      "step": 124640
    },
    {
      "epoch": 201.06,
      "learning_rate": 0.0799016330016129,
      "loss": 0.9162,
      "step": 124660
    },
    {
      "epoch": 201.1,
      "learning_rate": 0.0798984071983871,
      "loss": 0.8895,
      "step": 124680
    },
    {
      "epoch": 201.13,
      "learning_rate": 0.0798951813951613,
      "loss": 0.9398,
      "step": 124700
    },
    {
      "epoch": 201.16,
      "learning_rate": 0.07989195559193549,
      "loss": 0.9626,
      "step": 124720
    },
    {
      "epoch": 201.19,
      "learning_rate": 0.07988872978870969,
      "loss": 0.9256,
      "step": 124740
    },
    {
      "epoch": 201.23,
      "learning_rate": 0.07988550398548387,
      "loss": 0.9498,
      "step": 124760
    },
    {
      "epoch": 201.26,
      "learning_rate": 0.07988227818225807,
      "loss": 0.9506,
      "step": 124780
    },
    {
      "epoch": 201.29,
      "learning_rate": 0.07987905237903227,
      "loss": 0.9172,
      "step": 124800
    },
    {
      "epoch": 201.32,
      "learning_rate": 0.07987582657580646,
      "loss": 0.9693,
      "step": 124820
    },
    {
      "epoch": 201.35,
      "learning_rate": 0.07987260077258065,
      "loss": 0.9383,
      "step": 124840
    },
    {
      "epoch": 201.39,
      "learning_rate": 0.07986937496935484,
      "loss": 0.9209,
      "step": 124860
    },
    {
      "epoch": 201.42,
      "learning_rate": 0.07986614916612904,
      "loss": 0.9548,
      "step": 124880
    },
    {
      "epoch": 201.45,
      "learning_rate": 0.07986292336290322,
      "loss": 0.9492,
      "step": 124900
    },
    {
      "epoch": 201.48,
      "learning_rate": 0.07985969755967742,
      "loss": 0.9665,
      "step": 124920
    },
    {
      "epoch": 201.52,
      "learning_rate": 0.07985647175645162,
      "loss": 0.9451,
      "step": 124940
    },
    {
      "epoch": 201.55,
      "learning_rate": 0.07985324595322581,
      "loss": 0.975,
      "step": 124960
    },
    {
      "epoch": 201.58,
      "learning_rate": 0.07985002015,
      "loss": 0.979,
      "step": 124980
    },
    {
      "epoch": 201.61,
      "learning_rate": 0.07984679434677419,
      "loss": 0.9589,
      "step": 125000
    },
    {
      "epoch": 201.65,
      "learning_rate": 0.07984356854354839,
      "loss": 0.9513,
      "step": 125020
    },
    {
      "epoch": 201.68,
      "learning_rate": 0.07984034274032259,
      "loss": 0.9623,
      "step": 125040
    },
    {
      "epoch": 201.71,
      "learning_rate": 0.07983711693709677,
      "loss": 0.9382,
      "step": 125060
    },
    {
      "epoch": 201.74,
      "learning_rate": 0.07983389113387097,
      "loss": 0.9603,
      "step": 125080
    },
    {
      "epoch": 201.77,
      "learning_rate": 0.07983066533064517,
      "loss": 0.9433,
      "step": 125100
    },
    {
      "epoch": 201.81,
      "learning_rate": 0.07982743952741936,
      "loss": 0.9784,
      "step": 125120
    },
    {
      "epoch": 201.84,
      "learning_rate": 0.07982421372419356,
      "loss": 0.9483,
      "step": 125140
    },
    {
      "epoch": 201.87,
      "learning_rate": 0.07982098792096774,
      "loss": 0.9292,
      "step": 125160
    },
    {
      "epoch": 201.9,
      "learning_rate": 0.07981776211774194,
      "loss": 0.9587,
      "step": 125180
    },
    {
      "epoch": 201.94,
      "learning_rate": 0.07981453631451613,
      "loss": 0.9765,
      "step": 125200
    },
    {
      "epoch": 201.97,
      "learning_rate": 0.07981131051129033,
      "loss": 0.9816,
      "step": 125220
    },
    {
      "epoch": 202.0,
      "learning_rate": 0.07980808470806451,
      "loss": 0.9719,
      "step": 125240
    },
    {
      "epoch": 202.0,
      "eval_accuracy": {
        "accuracy": 0.7339786121302007
      },
      "eval_loss": 1.3492746353149414,
      "eval_runtime": 2.8492,
      "eval_samples_per_second": 4496.312,
      "eval_steps_per_second": 70.546,
      "step": 125240
    },
    {
      "epoch": 202.03,
      "learning_rate": 0.07980485890483871,
      "loss": 0.9992,
      "step": 125260
    },
    {
      "epoch": 202.06,
      "learning_rate": 0.07980163310161291,
      "loss": 0.933,
      "step": 125280
    },
    {
      "epoch": 202.1,
      "learning_rate": 0.0797984072983871,
      "loss": 0.923,
      "step": 125300
    },
    {
      "epoch": 202.13,
      "learning_rate": 0.0797951814951613,
      "loss": 0.9015,
      "step": 125320
    },
    {
      "epoch": 202.16,
      "learning_rate": 0.07979195569193549,
      "loss": 0.8995,
      "step": 125340
    },
    {
      "epoch": 202.19,
      "learning_rate": 0.07978872988870968,
      "loss": 0.9381,
      "step": 125360
    },
    {
      "epoch": 202.23,
      "learning_rate": 0.07978550408548388,
      "loss": 0.943,
      "step": 125380
    },
    {
      "epoch": 202.26,
      "learning_rate": 0.07978227828225808,
      "loss": 0.9426,
      "step": 125400
    },
    {
      "epoch": 202.29,
      "learning_rate": 0.07977905247903226,
      "loss": 0.9294,
      "step": 125420
    },
    {
      "epoch": 202.32,
      "learning_rate": 0.07977582667580646,
      "loss": 0.9124,
      "step": 125440
    },
    {
      "epoch": 202.35,
      "learning_rate": 0.07977260087258065,
      "loss": 0.9392,
      "step": 125460
    },
    {
      "epoch": 202.39,
      "learning_rate": 0.07976937506935484,
      "loss": 0.9593,
      "step": 125480
    },
    {
      "epoch": 202.42,
      "learning_rate": 0.07976614926612903,
      "loss": 0.9305,
      "step": 125500
    },
    {
      "epoch": 202.45,
      "learning_rate": 0.07976292346290324,
      "loss": 0.9202,
      "step": 125520
    },
    {
      "epoch": 202.48,
      "learning_rate": 0.07975969765967741,
      "loss": 0.9386,
      "step": 125540
    },
    {
      "epoch": 202.52,
      "learning_rate": 0.07975647185645161,
      "loss": 0.9502,
      "step": 125560
    },
    {
      "epoch": 202.55,
      "learning_rate": 0.07975324605322581,
      "loss": 0.939,
      "step": 125580
    },
    {
      "epoch": 202.58,
      "learning_rate": 0.07975002025,
      "loss": 0.9524,
      "step": 125600
    },
    {
      "epoch": 202.61,
      "learning_rate": 0.0797467944467742,
      "loss": 0.9548,
      "step": 125620
    },
    {
      "epoch": 202.65,
      "learning_rate": 0.0797435686435484,
      "loss": 0.9894,
      "step": 125640
    },
    {
      "epoch": 202.68,
      "learning_rate": 0.07974034284032258,
      "loss": 0.9581,
      "step": 125660
    },
    {
      "epoch": 202.71,
      "learning_rate": 0.07973711703709678,
      "loss": 0.9659,
      "step": 125680
    },
    {
      "epoch": 202.74,
      "learning_rate": 0.07973389123387098,
      "loss": 0.9605,
      "step": 125700
    },
    {
      "epoch": 202.77,
      "learning_rate": 0.07973066543064516,
      "loss": 0.9643,
      "step": 125720
    },
    {
      "epoch": 202.81,
      "learning_rate": 0.07972743962741936,
      "loss": 0.9723,
      "step": 125740
    },
    {
      "epoch": 202.84,
      "learning_rate": 0.07972421382419355,
      "loss": 0.9669,
      "step": 125760
    },
    {
      "epoch": 202.87,
      "learning_rate": 0.07972098802096775,
      "loss": 0.9464,
      "step": 125780
    },
    {
      "epoch": 202.9,
      "learning_rate": 0.07971776221774193,
      "loss": 0.9472,
      "step": 125800
    },
    {
      "epoch": 202.94,
      "learning_rate": 0.07971469770467743,
      "loss": 0.9568,
      "step": 125820
    },
    {
      "epoch": 202.97,
      "learning_rate": 0.07971147190145161,
      "loss": 0.9565,
      "step": 125840
    },
    {
      "epoch": 203.0,
      "learning_rate": 0.07970824609822581,
      "loss": 0.9566,
      "step": 125860
    },
    {
      "epoch": 203.0,
      "eval_accuracy": {
        "accuracy": 0.7385059714308017
      },
      "eval_loss": 1.3220748901367188,
      "eval_runtime": 2.5984,
      "eval_samples_per_second": 4930.365,
      "eval_steps_per_second": 77.356,
      "step": 125860
    },
    {
      "epoch": 203.03,
      "learning_rate": 0.07970502029500001,
      "loss": 0.9697,
      "step": 125880
    },
    {
      "epoch": 203.06,
      "learning_rate": 0.0797017944917742,
      "loss": 0.914,
      "step": 125900
    },
    {
      "epoch": 203.1,
      "learning_rate": 0.0796985686885484,
      "loss": 0.9115,
      "step": 125920
    },
    {
      "epoch": 203.13,
      "learning_rate": 0.07969534288532258,
      "loss": 0.9408,
      "step": 125940
    },
    {
      "epoch": 203.16,
      "learning_rate": 0.07969211708209678,
      "loss": 0.9529,
      "step": 125960
    },
    {
      "epoch": 203.19,
      "learning_rate": 0.07968889127887097,
      "loss": 0.9278,
      "step": 125980
    },
    {
      "epoch": 203.23,
      "learning_rate": 0.07968566547564516,
      "loss": 0.9313,
      "step": 126000
    },
    {
      "epoch": 203.26,
      "learning_rate": 0.07968243967241936,
      "loss": 0.935,
      "step": 126020
    },
    {
      "epoch": 203.29,
      "learning_rate": 0.07967921386919355,
      "loss": 0.9517,
      "step": 126040
    },
    {
      "epoch": 203.32,
      "learning_rate": 0.07967598806596775,
      "loss": 0.9605,
      "step": 126060
    },
    {
      "epoch": 203.35,
      "learning_rate": 0.07967276226274193,
      "loss": 0.9422,
      "step": 126080
    },
    {
      "epoch": 203.39,
      "learning_rate": 0.07966953645951613,
      "loss": 0.9554,
      "step": 126100
    },
    {
      "epoch": 203.42,
      "learning_rate": 0.07966631065629033,
      "loss": 0.9775,
      "step": 126120
    },
    {
      "epoch": 203.45,
      "learning_rate": 0.07966308485306452,
      "loss": 0.9523,
      "step": 126140
    },
    {
      "epoch": 203.48,
      "learning_rate": 0.07965985904983872,
      "loss": 0.9125,
      "step": 126160
    },
    {
      "epoch": 203.52,
      "learning_rate": 0.07965663324661292,
      "loss": 0.938,
      "step": 126180
    },
    {
      "epoch": 203.55,
      "learning_rate": 0.0796534074433871,
      "loss": 0.989,
      "step": 126200
    },
    {
      "epoch": 203.58,
      "learning_rate": 0.0796501816401613,
      "loss": 0.9597,
      "step": 126220
    },
    {
      "epoch": 203.61,
      "learning_rate": 0.07964695583693548,
      "loss": 0.9573,
      "step": 126240
    },
    {
      "epoch": 203.65,
      "learning_rate": 0.07964373003370968,
      "loss": 0.9731,
      "step": 126260
    },
    {
      "epoch": 203.68,
      "learning_rate": 0.07964050423048387,
      "loss": 0.9392,
      "step": 126280
    },
    {
      "epoch": 203.71,
      "learning_rate": 0.07963727842725807,
      "loss": 0.9447,
      "step": 126300
    },
    {
      "epoch": 203.74,
      "learning_rate": 0.07963405262403225,
      "loss": 0.9395,
      "step": 126320
    },
    {
      "epoch": 203.77,
      "learning_rate": 0.07963082682080645,
      "loss": 0.9409,
      "step": 126340
    },
    {
      "epoch": 203.81,
      "learning_rate": 0.07962760101758065,
      "loss": 0.9698,
      "step": 126360
    },
    {
      "epoch": 203.84,
      "learning_rate": 0.07962437521435484,
      "loss": 0.9456,
      "step": 126380
    },
    {
      "epoch": 203.87,
      "learning_rate": 0.07962114941112904,
      "loss": 0.9492,
      "step": 126400
    },
    {
      "epoch": 203.9,
      "learning_rate": 0.07961792360790323,
      "loss": 0.9911,
      "step": 126420
    },
    {
      "epoch": 203.94,
      "learning_rate": 0.07961469780467742,
      "loss": 0.9612,
      "step": 126440
    },
    {
      "epoch": 203.97,
      "learning_rate": 0.07961147200145162,
      "loss": 0.9655,
      "step": 126460
    },
    {
      "epoch": 204.0,
      "learning_rate": 0.07960824619822582,
      "loss": 0.9792,
      "step": 126480
    },
    {
      "epoch": 204.0,
      "eval_accuracy": {
        "accuracy": 0.7392865506205605
      },
      "eval_loss": 1.343556523323059,
      "eval_runtime": 2.6125,
      "eval_samples_per_second": 4903.81,
      "eval_steps_per_second": 76.939,
      "step": 126480
    },
    {
      "epoch": 204.03,
      "learning_rate": 0.079605020395,
      "loss": 0.991,
      "step": 126500
    },
    {
      "epoch": 204.06,
      "learning_rate": 0.0796017945917742,
      "loss": 0.9197,
      "step": 126520
    },
    {
      "epoch": 204.1,
      "learning_rate": 0.07959856878854839,
      "loss": 0.9166,
      "step": 126540
    },
    {
      "epoch": 204.13,
      "learning_rate": 0.07959534298532259,
      "loss": 0.9378,
      "step": 126560
    },
    {
      "epoch": 204.16,
      "learning_rate": 0.07959211718209677,
      "loss": 0.9595,
      "step": 126580
    },
    {
      "epoch": 204.19,
      "learning_rate": 0.07958889137887097,
      "loss": 0.9262,
      "step": 126600
    },
    {
      "epoch": 204.23,
      "learning_rate": 0.07958566557564516,
      "loss": 0.9329,
      "step": 126620
    },
    {
      "epoch": 204.26,
      "learning_rate": 0.07958243977241936,
      "loss": 0.9543,
      "step": 126640
    },
    {
      "epoch": 204.29,
      "learning_rate": 0.07957921396919355,
      "loss": 0.9596,
      "step": 126660
    },
    {
      "epoch": 204.32,
      "learning_rate": 0.07957598816596774,
      "loss": 0.9409,
      "step": 126680
    },
    {
      "epoch": 204.35,
      "learning_rate": 0.07957276236274194,
      "loss": 0.9367,
      "step": 126700
    },
    {
      "epoch": 204.39,
      "learning_rate": 0.07956953655951614,
      "loss": 0.95,
      "step": 126720
    },
    {
      "epoch": 204.42,
      "learning_rate": 0.07956631075629032,
      "loss": 0.9649,
      "step": 126740
    },
    {
      "epoch": 204.45,
      "learning_rate": 0.07956308495306452,
      "loss": 0.9314,
      "step": 126760
    },
    {
      "epoch": 204.48,
      "learning_rate": 0.07955985914983872,
      "loss": 0.9378,
      "step": 126780
    },
    {
      "epoch": 204.52,
      "learning_rate": 0.0795566333466129,
      "loss": 0.9429,
      "step": 126800
    },
    {
      "epoch": 204.55,
      "learning_rate": 0.0795534075433871,
      "loss": 0.9317,
      "step": 126820
    },
    {
      "epoch": 204.58,
      "learning_rate": 0.07955018174016129,
      "loss": 0.9505,
      "step": 126840
    },
    {
      "epoch": 204.61,
      "learning_rate": 0.07954695593693549,
      "loss": 0.9227,
      "step": 126860
    },
    {
      "epoch": 204.65,
      "learning_rate": 0.07954373013370968,
      "loss": 0.9666,
      "step": 126880
    },
    {
      "epoch": 204.68,
      "learning_rate": 0.07954050433048389,
      "loss": 0.9682,
      "step": 126900
    },
    {
      "epoch": 204.71,
      "learning_rate": 0.07953727852725806,
      "loss": 0.9606,
      "step": 126920
    },
    {
      "epoch": 204.74,
      "learning_rate": 0.07953405272403226,
      "loss": 0.9485,
      "step": 126940
    },
    {
      "epoch": 204.77,
      "learning_rate": 0.07953082692080646,
      "loss": 0.9453,
      "step": 126960
    },
    {
      "epoch": 204.81,
      "learning_rate": 0.07952760111758064,
      "loss": 0.9572,
      "step": 126980
    },
    {
      "epoch": 204.84,
      "learning_rate": 0.07952437531435484,
      "loss": 0.9669,
      "step": 127000
    },
    {
      "epoch": 204.87,
      "learning_rate": 0.07952114951112904,
      "loss": 0.9444,
      "step": 127020
    },
    {
      "epoch": 204.9,
      "learning_rate": 0.07951792370790323,
      "loss": 0.9535,
      "step": 127040
    },
    {
      "epoch": 204.94,
      "learning_rate": 0.07951469790467743,
      "loss": 0.9325,
      "step": 127060
    },
    {
      "epoch": 204.97,
      "learning_rate": 0.07951147210145162,
      "loss": 0.9527,
      "step": 127080
    },
    {
      "epoch": 205.0,
      "learning_rate": 0.07950824629822581,
      "loss": 0.9546,
      "step": 127100
    },
    {
      "epoch": 205.0,
      "eval_accuracy": {
        "accuracy": 0.7377253922410428
      },
      "eval_loss": 1.3344529867172241,
      "eval_runtime": 3.1289,
      "eval_samples_per_second": 4094.357,
      "eval_steps_per_second": 64.239,
      "step": 127100
    },
    {
      "epoch": 205.03,
      "learning_rate": 0.07950502049500001,
      "loss": 0.971,
      "step": 127120
    },
    {
      "epoch": 205.06,
      "learning_rate": 0.07950179469177421,
      "loss": 0.9561,
      "step": 127140
    },
    {
      "epoch": 205.1,
      "learning_rate": 0.0794985688885484,
      "loss": 0.9473,
      "step": 127160
    },
    {
      "epoch": 205.13,
      "learning_rate": 0.07949534308532258,
      "loss": 0.9339,
      "step": 127180
    },
    {
      "epoch": 205.16,
      "learning_rate": 0.07949211728209679,
      "loss": 0.9273,
      "step": 127200
    },
    {
      "epoch": 205.19,
      "learning_rate": 0.07948889147887096,
      "loss": 0.9298,
      "step": 127220
    },
    {
      "epoch": 205.23,
      "learning_rate": 0.07948566567564516,
      "loss": 0.9449,
      "step": 127240
    },
    {
      "epoch": 205.26,
      "learning_rate": 0.07948243987241936,
      "loss": 0.9373,
      "step": 127260
    },
    {
      "epoch": 205.29,
      "learning_rate": 0.07947921406919355,
      "loss": 0.9491,
      "step": 127280
    },
    {
      "epoch": 205.32,
      "learning_rate": 0.07947598826596775,
      "loss": 0.9449,
      "step": 127300
    },
    {
      "epoch": 205.35,
      "learning_rate": 0.07947276246274194,
      "loss": 0.9505,
      "step": 127320
    },
    {
      "epoch": 205.39,
      "learning_rate": 0.07946953665951613,
      "loss": 0.9346,
      "step": 127340
    },
    {
      "epoch": 205.42,
      "learning_rate": 0.07946631085629033,
      "loss": 0.9504,
      "step": 127360
    },
    {
      "epoch": 205.45,
      "learning_rate": 0.07946308505306453,
      "loss": 0.955,
      "step": 127380
    },
    {
      "epoch": 205.48,
      "learning_rate": 0.07945985924983871,
      "loss": 0.9486,
      "step": 127400
    },
    {
      "epoch": 205.52,
      "learning_rate": 0.07945663344661291,
      "loss": 0.9574,
      "step": 127420
    },
    {
      "epoch": 205.55,
      "learning_rate": 0.07945340764338711,
      "loss": 0.9258,
      "step": 127440
    },
    {
      "epoch": 205.58,
      "learning_rate": 0.0794501818401613,
      "loss": 0.9451,
      "step": 127460
    },
    {
      "epoch": 205.61,
      "learning_rate": 0.07944695603693548,
      "loss": 0.9749,
      "step": 127480
    },
    {
      "epoch": 205.65,
      "learning_rate": 0.0794437302337097,
      "loss": 1.0072,
      "step": 127500
    },
    {
      "epoch": 205.68,
      "learning_rate": 0.07944050443048387,
      "loss": 0.9712,
      "step": 127520
    },
    {
      "epoch": 205.71,
      "learning_rate": 0.07943727862725806,
      "loss": 0.9498,
      "step": 127540
    },
    {
      "epoch": 205.74,
      "learning_rate": 0.07943405282403226,
      "loss": 0.9695,
      "step": 127560
    },
    {
      "epoch": 205.77,
      "learning_rate": 0.07943082702080645,
      "loss": 0.9403,
      "step": 127580
    },
    {
      "epoch": 205.81,
      "learning_rate": 0.07942760121758065,
      "loss": 0.9412,
      "step": 127600
    },
    {
      "epoch": 205.84,
      "learning_rate": 0.07942437541435485,
      "loss": 0.9172,
      "step": 127620
    },
    {
      "epoch": 205.87,
      "learning_rate": 0.07942114961112903,
      "loss": 0.9457,
      "step": 127640
    },
    {
      "epoch": 205.9,
      "learning_rate": 0.07941792380790323,
      "loss": 0.9527,
      "step": 127660
    },
    {
      "epoch": 205.94,
      "learning_rate": 0.07941469800467743,
      "loss": 0.9662,
      "step": 127680
    },
    {
      "epoch": 205.97,
      "learning_rate": 0.07941147220145162,
      "loss": 0.9535,
      "step": 127700
    },
    {
      "epoch": 206.0,
      "learning_rate": 0.07940824639822582,
      "loss": 0.9517,
      "step": 127720
    },
    {
      "epoch": 206.0,
      "eval_accuracy": {
        "accuracy": 0.7488096167356179
      },
      "eval_loss": 1.2899869680404663,
      "eval_runtime": 2.6876,
      "eval_samples_per_second": 4766.744,
      "eval_steps_per_second": 74.789,
      "step": 127720
    },
    {
      "epoch": 206.03,
      "learning_rate": 0.07940502059500001,
      "loss": 0.9743,
      "step": 127740
    },
    {
      "epoch": 206.06,
      "learning_rate": 0.0794017947917742,
      "loss": 0.9286,
      "step": 127760
    },
    {
      "epoch": 206.1,
      "learning_rate": 0.07939856898854838,
      "loss": 0.9504,
      "step": 127780
    },
    {
      "epoch": 206.13,
      "learning_rate": 0.0793953431853226,
      "loss": 0.935,
      "step": 127800
    },
    {
      "epoch": 206.16,
      "learning_rate": 0.07939211738209677,
      "loss": 0.9411,
      "step": 127820
    },
    {
      "epoch": 206.19,
      "learning_rate": 0.07938889157887098,
      "loss": 0.9415,
      "step": 127840
    },
    {
      "epoch": 206.23,
      "learning_rate": 0.07938566577564517,
      "loss": 0.9362,
      "step": 127860
    },
    {
      "epoch": 206.26,
      "learning_rate": 0.07938243997241935,
      "loss": 0.8918,
      "step": 127880
    },
    {
      "epoch": 206.29,
      "learning_rate": 0.07937921416919355,
      "loss": 0.9308,
      "step": 127900
    },
    {
      "epoch": 206.32,
      "learning_rate": 0.07937598836596775,
      "loss": 0.9083,
      "step": 127920
    },
    {
      "epoch": 206.35,
      "learning_rate": 0.07937276256274194,
      "loss": 0.9309,
      "step": 127940
    },
    {
      "epoch": 206.39,
      "learning_rate": 0.07936953675951613,
      "loss": 0.9238,
      "step": 127960
    },
    {
      "epoch": 206.42,
      "learning_rate": 0.07936631095629033,
      "loss": 0.9137,
      "step": 127980
    },
    {
      "epoch": 206.45,
      "learning_rate": 0.07936308515306452,
      "loss": 0.9737,
      "step": 128000
    },
    {
      "epoch": 206.48,
      "learning_rate": 0.07935985934983872,
      "loss": 0.9663,
      "step": 128020
    },
    {
      "epoch": 206.52,
      "learning_rate": 0.07935663354661292,
      "loss": 0.9553,
      "step": 128040
    },
    {
      "epoch": 206.55,
      "learning_rate": 0.0793534077433871,
      "loss": 0.9355,
      "step": 128060
    },
    {
      "epoch": 206.58,
      "learning_rate": 0.07935018194016129,
      "loss": 0.9287,
      "step": 128080
    },
    {
      "epoch": 206.61,
      "learning_rate": 0.0793469561369355,
      "loss": 0.9216,
      "step": 128100
    },
    {
      "epoch": 206.65,
      "learning_rate": 0.07934373033370967,
      "loss": 0.9562,
      "step": 128120
    },
    {
      "epoch": 206.68,
      "learning_rate": 0.07934050453048389,
      "loss": 0.939,
      "step": 128140
    },
    {
      "epoch": 206.71,
      "learning_rate": 0.07933727872725807,
      "loss": 0.9351,
      "step": 128160
    },
    {
      "epoch": 206.74,
      "learning_rate": 0.07933405292403226,
      "loss": 0.9284,
      "step": 128180
    },
    {
      "epoch": 206.77,
      "learning_rate": 0.07933082712080645,
      "loss": 0.9787,
      "step": 128200
    },
    {
      "epoch": 206.81,
      "learning_rate": 0.07932760131758065,
      "loss": 0.9589,
      "step": 128220
    },
    {
      "epoch": 206.84,
      "learning_rate": 0.07932437551435484,
      "loss": 0.9728,
      "step": 128240
    },
    {
      "epoch": 206.87,
      "learning_rate": 0.07932114971112904,
      "loss": 0.937,
      "step": 128260
    },
    {
      "epoch": 206.9,
      "learning_rate": 0.07931792390790324,
      "loss": 0.9573,
      "step": 128280
    },
    {
      "epoch": 206.94,
      "learning_rate": 0.07931469810467742,
      "loss": 0.9556,
      "step": 128300
    },
    {
      "epoch": 206.97,
      "learning_rate": 0.07931147230145162,
      "loss": 0.9574,
      "step": 128320
    },
    {
      "epoch": 207.0,
      "learning_rate": 0.0793084077883871,
      "loss": 0.985,
      "step": 128340
    },
    {
      "epoch": 207.0,
      "eval_accuracy": {
        "accuracy": 0.7442822574350167
      },
      "eval_loss": 1.3030403852462769,
      "eval_runtime": 2.772,
      "eval_samples_per_second": 4621.5,
      "eval_steps_per_second": 72.51,
      "step": 128340
    },
    {
      "epoch": 207.03,
      "learning_rate": 0.07930518198516129,
      "loss": 0.9248,
      "step": 128360
    },
    {
      "epoch": 207.06,
      "learning_rate": 0.07930195618193549,
      "loss": 0.943,
      "step": 128380
    },
    {
      "epoch": 207.1,
      "learning_rate": 0.07929873037870969,
      "loss": 0.9456,
      "step": 128400
    },
    {
      "epoch": 207.13,
      "learning_rate": 0.07929550457548387,
      "loss": 0.9554,
      "step": 128420
    },
    {
      "epoch": 207.16,
      "learning_rate": 0.07929227877225807,
      "loss": 0.9213,
      "step": 128440
    },
    {
      "epoch": 207.19,
      "learning_rate": 0.07928905296903227,
      "loss": 0.956,
      "step": 128460
    },
    {
      "epoch": 207.23,
      "learning_rate": 0.07928582716580646,
      "loss": 0.9578,
      "step": 128480
    },
    {
      "epoch": 207.26,
      "learning_rate": 0.07928260136258065,
      "loss": 0.9306,
      "step": 128500
    },
    {
      "epoch": 207.29,
      "learning_rate": 0.07927937555935485,
      "loss": 0.9327,
      "step": 128520
    },
    {
      "epoch": 207.32,
      "learning_rate": 0.07927614975612904,
      "loss": 0.9617,
      "step": 128540
    },
    {
      "epoch": 207.35,
      "learning_rate": 0.07927292395290322,
      "loss": 0.9332,
      "step": 128560
    },
    {
      "epoch": 207.39,
      "learning_rate": 0.07926969814967744,
      "loss": 0.9465,
      "step": 128580
    },
    {
      "epoch": 207.42,
      "learning_rate": 0.07926647234645161,
      "loss": 0.9762,
      "step": 128600
    },
    {
      "epoch": 207.45,
      "learning_rate": 0.07926324654322581,
      "loss": 0.9419,
      "step": 128620
    },
    {
      "epoch": 207.48,
      "learning_rate": 0.07926002074,
      "loss": 0.9362,
      "step": 128640
    },
    {
      "epoch": 207.52,
      "learning_rate": 0.07925679493677419,
      "loss": 0.9329,
      "step": 128660
    },
    {
      "epoch": 207.55,
      "learning_rate": 0.07925356913354839,
      "loss": 0.9501,
      "step": 128680
    },
    {
      "epoch": 207.58,
      "learning_rate": 0.07925034333032259,
      "loss": 0.923,
      "step": 128700
    },
    {
      "epoch": 207.61,
      "learning_rate": 0.07924711752709677,
      "loss": 0.955,
      "step": 128720
    },
    {
      "epoch": 207.65,
      "learning_rate": 0.07924389172387097,
      "loss": 0.9574,
      "step": 128740
    },
    {
      "epoch": 207.68,
      "learning_rate": 0.07924066592064517,
      "loss": 0.9606,
      "step": 128760
    },
    {
      "epoch": 207.71,
      "learning_rate": 0.07923744011741936,
      "loss": 0.97,
      "step": 128780
    },
    {
      "epoch": 207.74,
      "learning_rate": 0.07923421431419356,
      "loss": 0.9443,
      "step": 128800
    },
    {
      "epoch": 207.77,
      "learning_rate": 0.07923098851096776,
      "loss": 0.9275,
      "step": 128820
    },
    {
      "epoch": 207.81,
      "learning_rate": 0.07922776270774194,
      "loss": 0.9113,
      "step": 128840
    },
    {
      "epoch": 207.84,
      "learning_rate": 0.07922453690451613,
      "loss": 0.9703,
      "step": 128860
    },
    {
      "epoch": 207.87,
      "learning_rate": 0.07922131110129034,
      "loss": 0.9575,
      "step": 128880
    },
    {
      "epoch": 207.9,
      "learning_rate": 0.07921808529806451,
      "loss": 0.9537,
      "step": 128900
    },
    {
      "epoch": 207.94,
      "learning_rate": 0.07921485949483871,
      "loss": 0.9425,
      "step": 128920
    },
    {
      "epoch": 207.97,
      "learning_rate": 0.07921163369161291,
      "loss": 0.9281,
      "step": 128940
    },
    {
      "epoch": 208.0,
      "learning_rate": 0.0792084078883871,
      "loss": 0.9332,
      "step": 128960
    },
    {
      "epoch": 208.0,
      "eval_accuracy": {
        "accuracy": 0.7394426664585122
      },
      "eval_loss": 1.3070874214172363,
      "eval_runtime": 3.0669,
      "eval_samples_per_second": 4177.121,
      "eval_steps_per_second": 65.538,
      "step": 128960
    },
    {
      "epoch": 208.03,
      "learning_rate": 0.0792051820851613,
      "loss": 0.9484,
      "step": 128980
    },
    {
      "epoch": 208.06,
      "learning_rate": 0.07920195628193549,
      "loss": 0.9493,
      "step": 129000
    },
    {
      "epoch": 208.1,
      "learning_rate": 0.07919873047870968,
      "loss": 0.9443,
      "step": 129020
    },
    {
      "epoch": 208.13,
      "learning_rate": 0.07919550467548388,
      "loss": 0.9388,
      "step": 129040
    },
    {
      "epoch": 208.16,
      "learning_rate": 0.07919227887225808,
      "loss": 0.9406,
      "step": 129060
    },
    {
      "epoch": 208.19,
      "learning_rate": 0.07918905306903226,
      "loss": 0.9116,
      "step": 129080
    },
    {
      "epoch": 208.23,
      "learning_rate": 0.07918582726580646,
      "loss": 0.948,
      "step": 129100
    },
    {
      "epoch": 208.26,
      "learning_rate": 0.07918260146258066,
      "loss": 0.9331,
      "step": 129120
    },
    {
      "epoch": 208.29,
      "learning_rate": 0.07917937565935484,
      "loss": 0.9256,
      "step": 129140
    },
    {
      "epoch": 208.32,
      "learning_rate": 0.07917614985612903,
      "loss": 0.9325,
      "step": 129160
    },
    {
      "epoch": 208.35,
      "learning_rate": 0.07917292405290324,
      "loss": 0.9499,
      "step": 129180
    },
    {
      "epoch": 208.39,
      "learning_rate": 0.07916969824967741,
      "loss": 0.9404,
      "step": 129200
    },
    {
      "epoch": 208.42,
      "learning_rate": 0.07916647244645163,
      "loss": 0.9223,
      "step": 129220
    },
    {
      "epoch": 208.45,
      "learning_rate": 0.07916324664322581,
      "loss": 0.9391,
      "step": 129240
    },
    {
      "epoch": 208.48,
      "learning_rate": 0.07916002084,
      "loss": 0.9488,
      "step": 129260
    },
    {
      "epoch": 208.52,
      "learning_rate": 0.0791567950367742,
      "loss": 0.9507,
      "step": 129280
    },
    {
      "epoch": 208.55,
      "learning_rate": 0.0791535692335484,
      "loss": 0.9269,
      "step": 129300
    },
    {
      "epoch": 208.58,
      "learning_rate": 0.07915034343032258,
      "loss": 0.9589,
      "step": 129320
    },
    {
      "epoch": 208.61,
      "learning_rate": 0.07914711762709678,
      "loss": 0.9222,
      "step": 129340
    },
    {
      "epoch": 208.65,
      "learning_rate": 0.07914389182387098,
      "loss": 0.92,
      "step": 129360
    },
    {
      "epoch": 208.68,
      "learning_rate": 0.07914066602064516,
      "loss": 0.9364,
      "step": 129380
    },
    {
      "epoch": 208.71,
      "learning_rate": 0.07913744021741936,
      "loss": 0.9741,
      "step": 129400
    },
    {
      "epoch": 208.74,
      "learning_rate": 0.07913421441419356,
      "loss": 0.9559,
      "step": 129420
    },
    {
      "epoch": 208.77,
      "learning_rate": 0.07913098861096775,
      "loss": 0.9207,
      "step": 129440
    },
    {
      "epoch": 208.81,
      "learning_rate": 0.07912776280774193,
      "loss": 0.9354,
      "step": 129460
    },
    {
      "epoch": 208.84,
      "learning_rate": 0.07912453700451613,
      "loss": 0.9354,
      "step": 129480
    },
    {
      "epoch": 208.87,
      "learning_rate": 0.07912131120129032,
      "loss": 0.9292,
      "step": 129500
    },
    {
      "epoch": 208.9,
      "learning_rate": 0.07911808539806453,
      "loss": 0.9301,
      "step": 129520
    },
    {
      "epoch": 208.94,
      "learning_rate": 0.07911485959483872,
      "loss": 0.9636,
      "step": 129540
    },
    {
      "epoch": 208.97,
      "learning_rate": 0.0791116337916129,
      "loss": 0.9501,
      "step": 129560
    },
    {
      "epoch": 209.0,
      "learning_rate": 0.0791084079883871,
      "loss": 0.9929,
      "step": 129580
    },
    {
      "epoch": 209.0,
      "eval_accuracy": {
        "accuracy": 0.7345250175630318
      },
      "eval_loss": 1.3295190334320068,
      "eval_runtime": 2.7581,
      "eval_samples_per_second": 4644.83,
      "eval_steps_per_second": 72.876,
      "step": 129580
    },
    {
      "epoch": 209.03,
      "learning_rate": 0.0791051821851613,
      "loss": 0.9978,
      "step": 129600
    },
    {
      "epoch": 209.06,
      "learning_rate": 0.07910195638193548,
      "loss": 0.931,
      "step": 129620
    },
    {
      "epoch": 209.1,
      "learning_rate": 0.07909873057870968,
      "loss": 0.8803,
      "step": 129640
    },
    {
      "epoch": 209.13,
      "learning_rate": 0.07909550477548388,
      "loss": 0.9333,
      "step": 129660
    },
    {
      "epoch": 209.16,
      "learning_rate": 0.07909227897225807,
      "loss": 0.9388,
      "step": 129680
    },
    {
      "epoch": 209.19,
      "learning_rate": 0.07908905316903227,
      "loss": 0.9243,
      "step": 129700
    },
    {
      "epoch": 209.23,
      "learning_rate": 0.07908582736580647,
      "loss": 0.9177,
      "step": 129720
    },
    {
      "epoch": 209.26,
      "learning_rate": 0.07908260156258065,
      "loss": 0.9547,
      "step": 129740
    },
    {
      "epoch": 209.29,
      "learning_rate": 0.07907937575935485,
      "loss": 0.953,
      "step": 129760
    },
    {
      "epoch": 209.32,
      "learning_rate": 0.07907614995612904,
      "loss": 0.9329,
      "step": 129780
    },
    {
      "epoch": 209.35,
      "learning_rate": 0.07907292415290322,
      "loss": 0.9346,
      "step": 129800
    },
    {
      "epoch": 209.39,
      "learning_rate": 0.07906969834967743,
      "loss": 0.9347,
      "step": 129820
    },
    {
      "epoch": 209.42,
      "learning_rate": 0.07906647254645162,
      "loss": 0.9304,
      "step": 129840
    },
    {
      "epoch": 209.45,
      "learning_rate": 0.0790632467432258,
      "loss": 0.9237,
      "step": 129860
    },
    {
      "epoch": 209.48,
      "learning_rate": 0.07906002094,
      "loss": 0.9453,
      "step": 129880
    },
    {
      "epoch": 209.52,
      "learning_rate": 0.0790567951367742,
      "loss": 0.9356,
      "step": 129900
    },
    {
      "epoch": 209.55,
      "learning_rate": 0.07905356933354839,
      "loss": 0.9823,
      "step": 129920
    },
    {
      "epoch": 209.58,
      "learning_rate": 0.07905034353032259,
      "loss": 0.9412,
      "step": 129940
    },
    {
      "epoch": 209.61,
      "learning_rate": 0.07904711772709679,
      "loss": 0.9507,
      "step": 129960
    },
    {
      "epoch": 209.65,
      "learning_rate": 0.07904389192387097,
      "loss": 0.965,
      "step": 129980
    },
    {
      "epoch": 209.68,
      "learning_rate": 0.07904066612064517,
      "loss": 0.9697,
      "step": 130000
    },
    {
      "epoch": 209.71,
      "learning_rate": 0.07903744031741936,
      "loss": 0.9355,
      "step": 130020
    },
    {
      "epoch": 209.74,
      "learning_rate": 0.07903421451419355,
      "loss": 0.9777,
      "step": 130040
    },
    {
      "epoch": 209.77,
      "learning_rate": 0.07903098871096775,
      "loss": 0.9448,
      "step": 130060
    },
    {
      "epoch": 209.81,
      "learning_rate": 0.07902776290774194,
      "loss": 0.9517,
      "step": 130080
    },
    {
      "epoch": 209.84,
      "learning_rate": 0.07902453710451612,
      "loss": 0.9274,
      "step": 130100
    },
    {
      "epoch": 209.87,
      "learning_rate": 0.07902131130129034,
      "loss": 0.9566,
      "step": 130120
    },
    {
      "epoch": 209.9,
      "learning_rate": 0.07901808549806452,
      "loss": 0.9282,
      "step": 130140
    },
    {
      "epoch": 209.94,
      "learning_rate": 0.07901485969483872,
      "loss": 0.9581,
      "step": 130160
    },
    {
      "epoch": 209.97,
      "learning_rate": 0.0790116338916129,
      "loss": 0.952,
      "step": 130180
    },
    {
      "epoch": 210.0,
      "learning_rate": 0.0790084080883871,
      "loss": 0.9451,
      "step": 130200
    },
    {
      "epoch": 210.0,
      "eval_accuracy": {
        "accuracy": 0.7417063461088127
      },
      "eval_loss": 1.3467812538146973,
      "eval_runtime": 2.756,
      "eval_samples_per_second": 4648.361,
      "eval_steps_per_second": 72.931,
      "step": 130200
    },
    {
      "epoch": 210.03,
      "learning_rate": 0.07900518228516129,
      "loss": 0.9542,
      "step": 130220
    },
    {
      "epoch": 210.06,
      "learning_rate": 0.07900195648193549,
      "loss": 0.9352,
      "step": 130240
    },
    {
      "epoch": 210.1,
      "learning_rate": 0.07899873067870967,
      "loss": 0.9423,
      "step": 130260
    },
    {
      "epoch": 210.13,
      "learning_rate": 0.07899550487548387,
      "loss": 0.9443,
      "step": 130280
    },
    {
      "epoch": 210.16,
      "learning_rate": 0.07899227907225807,
      "loss": 0.9048,
      "step": 130300
    },
    {
      "epoch": 210.19,
      "learning_rate": 0.07898905326903226,
      "loss": 0.9194,
      "step": 130320
    },
    {
      "epoch": 210.23,
      "learning_rate": 0.07898582746580646,
      "loss": 0.9483,
      "step": 130340
    },
    {
      "epoch": 210.26,
      "learning_rate": 0.07898260166258066,
      "loss": 0.9031,
      "step": 130360
    },
    {
      "epoch": 210.29,
      "learning_rate": 0.07897937585935484,
      "loss": 0.9218,
      "step": 130380
    },
    {
      "epoch": 210.32,
      "learning_rate": 0.07897615005612903,
      "loss": 0.9277,
      "step": 130400
    },
    {
      "epoch": 210.35,
      "learning_rate": 0.07897292425290324,
      "loss": 0.9464,
      "step": 130420
    },
    {
      "epoch": 210.39,
      "learning_rate": 0.07896969844967743,
      "loss": 0.9481,
      "step": 130440
    },
    {
      "epoch": 210.42,
      "learning_rate": 0.07896647264645162,
      "loss": 0.9411,
      "step": 130460
    },
    {
      "epoch": 210.45,
      "learning_rate": 0.07896324684322581,
      "loss": 0.9374,
      "step": 130480
    },
    {
      "epoch": 210.48,
      "learning_rate": 0.07896002104000001,
      "loss": 0.9423,
      "step": 130500
    },
    {
      "epoch": 210.52,
      "learning_rate": 0.07895695652693549,
      "loss": 0.9471,
      "step": 130520
    },
    {
      "epoch": 210.55,
      "learning_rate": 0.07895373072370968,
      "loss": 0.916,
      "step": 130540
    },
    {
      "epoch": 210.58,
      "learning_rate": 0.07895050492048387,
      "loss": 0.9013,
      "step": 130560
    },
    {
      "epoch": 210.61,
      "learning_rate": 0.07894727911725806,
      "loss": 0.9253,
      "step": 130580
    },
    {
      "epoch": 210.65,
      "learning_rate": 0.07894405331403227,
      "loss": 0.9927,
      "step": 130600
    },
    {
      "epoch": 210.68,
      "learning_rate": 0.07894082751080646,
      "loss": 0.9367,
      "step": 130620
    },
    {
      "epoch": 210.71,
      "learning_rate": 0.07893760170758064,
      "loss": 0.9529,
      "step": 130640
    },
    {
      "epoch": 210.74,
      "learning_rate": 0.07893437590435484,
      "loss": 0.9522,
      "step": 130660
    },
    {
      "epoch": 210.77,
      "learning_rate": 0.07893115010112904,
      "loss": 0.9516,
      "step": 130680
    },
    {
      "epoch": 210.81,
      "learning_rate": 0.07892792429790323,
      "loss": 0.9438,
      "step": 130700
    },
    {
      "epoch": 210.84,
      "learning_rate": 0.07892469849467743,
      "loss": 0.9491,
      "step": 130720
    },
    {
      "epoch": 210.87,
      "learning_rate": 0.07892147269145162,
      "loss": 0.9622,
      "step": 130740
    },
    {
      "epoch": 210.9,
      "learning_rate": 0.07891824688822581,
      "loss": 0.9344,
      "step": 130760
    },
    {
      "epoch": 210.94,
      "learning_rate": 0.07891502108500001,
      "loss": 0.9551,
      "step": 130780
    },
    {
      "epoch": 210.97,
      "learning_rate": 0.07891179528177421,
      "loss": 0.9541,
      "step": 130800
    },
    {
      "epoch": 211.0,
      "learning_rate": 0.0789085694785484,
      "loss": 0.9487,
      "step": 130820
    },
    {
      "epoch": 211.0,
      "eval_accuracy": {
        "accuracy": 0.7299196003434548
      },
      "eval_loss": 1.3631504774093628,
      "eval_runtime": 2.6352,
      "eval_samples_per_second": 4861.423,
      "eval_steps_per_second": 76.274,
      "step": 130820
    },
    {
      "epoch": 211.03,
      "learning_rate": 0.07890534367532259,
      "loss": 0.9638,
      "step": 130840
    },
    {
      "epoch": 211.06,
      "learning_rate": 0.07890211787209678,
      "loss": 0.9344,
      "step": 130860
    },
    {
      "epoch": 211.1,
      "learning_rate": 0.07889889206887096,
      "loss": 0.9192,
      "step": 130880
    },
    {
      "epoch": 211.13,
      "learning_rate": 0.07889566626564518,
      "loss": 0.9223,
      "step": 130900
    },
    {
      "epoch": 211.16,
      "learning_rate": 0.07889244046241936,
      "loss": 0.9204,
      "step": 130920
    },
    {
      "epoch": 211.19,
      "learning_rate": 0.07888921465919355,
      "loss": 0.9326,
      "step": 130940
    },
    {
      "epoch": 211.23,
      "learning_rate": 0.07888598885596775,
      "loss": 0.935,
      "step": 130960
    },
    {
      "epoch": 211.26,
      "learning_rate": 0.07888276305274194,
      "loss": 0.9246,
      "step": 130980
    },
    {
      "epoch": 211.29,
      "learning_rate": 0.07887953724951613,
      "loss": 0.9372,
      "step": 131000
    },
    {
      "epoch": 211.32,
      "learning_rate": 0.07887631144629033,
      "loss": 0.9173,
      "step": 131020
    },
    {
      "epoch": 211.35,
      "learning_rate": 0.07887308564306453,
      "loss": 0.9333,
      "step": 131040
    },
    {
      "epoch": 211.39,
      "learning_rate": 0.07886985983983871,
      "loss": 0.9386,
      "step": 131060
    },
    {
      "epoch": 211.42,
      "learning_rate": 0.07886663403661291,
      "loss": 0.9668,
      "step": 131080
    },
    {
      "epoch": 211.45,
      "learning_rate": 0.0788634082333871,
      "loss": 0.9417,
      "step": 131100
    },
    {
      "epoch": 211.48,
      "learning_rate": 0.0788601824301613,
      "loss": 0.9394,
      "step": 131120
    },
    {
      "epoch": 211.52,
      "learning_rate": 0.0788569566269355,
      "loss": 0.9859,
      "step": 131140
    },
    {
      "epoch": 211.55,
      "learning_rate": 0.07885373082370968,
      "loss": 0.9254,
      "step": 131160
    },
    {
      "epoch": 211.58,
      "learning_rate": 0.07885050502048387,
      "loss": 0.9536,
      "step": 131180
    },
    {
      "epoch": 211.61,
      "learning_rate": 0.07884727921725808,
      "loss": 0.9493,
      "step": 131200
    },
    {
      "epoch": 211.65,
      "learning_rate": 0.07884405341403226,
      "loss": 0.9429,
      "step": 131220
    },
    {
      "epoch": 211.68,
      "learning_rate": 0.07884082761080645,
      "loss": 0.9696,
      "step": 131240
    },
    {
      "epoch": 211.71,
      "learning_rate": 0.07883760180758065,
      "loss": 0.9499,
      "step": 131260
    },
    {
      "epoch": 211.74,
      "learning_rate": 0.07883437600435485,
      "loss": 0.9391,
      "step": 131280
    },
    {
      "epoch": 211.77,
      "learning_rate": 0.07883115020112903,
      "loss": 0.9351,
      "step": 131300
    },
    {
      "epoch": 211.81,
      "learning_rate": 0.07882792439790323,
      "loss": 0.9384,
      "step": 131320
    },
    {
      "epoch": 211.84,
      "learning_rate": 0.07882469859467742,
      "loss": 0.9624,
      "step": 131340
    },
    {
      "epoch": 211.87,
      "learning_rate": 0.07882147279145162,
      "loss": 0.9489,
      "step": 131360
    },
    {
      "epoch": 211.9,
      "learning_rate": 0.07881824698822582,
      "loss": 0.9314,
      "step": 131380
    },
    {
      "epoch": 211.94,
      "learning_rate": 0.078815021185,
      "loss": 0.9466,
      "step": 131400
    },
    {
      "epoch": 211.97,
      "learning_rate": 0.0788117953817742,
      "loss": 0.9407,
      "step": 131420
    },
    {
      "epoch": 212.0,
      "learning_rate": 0.0788085695785484,
      "loss": 0.9359,
      "step": 131440
    },
    {
      "epoch": 212.0,
      "eval_accuracy": {
        "accuracy": 0.7433455624073062
      },
      "eval_loss": 1.3481272459030151,
      "eval_runtime": 2.9949,
      "eval_samples_per_second": 4277.554,
      "eval_steps_per_second": 67.113,
      "step": 131440
    },
    {
      "epoch": 212.03,
      "learning_rate": 0.07880534377532258,
      "loss": 1.0134,
      "step": 131460
    },
    {
      "epoch": 212.06,
      "learning_rate": 0.07880211797209677,
      "loss": 0.9489,
      "step": 131480
    },
    {
      "epoch": 212.1,
      "learning_rate": 0.07879889216887098,
      "loss": 0.936,
      "step": 131500
    },
    {
      "epoch": 212.13,
      "learning_rate": 0.07879566636564517,
      "loss": 0.9515,
      "step": 131520
    },
    {
      "epoch": 212.16,
      "learning_rate": 0.07879244056241937,
      "loss": 0.9487,
      "step": 131540
    },
    {
      "epoch": 212.19,
      "learning_rate": 0.07878921475919355,
      "loss": 0.9506,
      "step": 131560
    },
    {
      "epoch": 212.23,
      "learning_rate": 0.07878598895596775,
      "loss": 0.9129,
      "step": 131580
    },
    {
      "epoch": 212.26,
      "learning_rate": 0.07878276315274194,
      "loss": 0.9629,
      "step": 131600
    },
    {
      "epoch": 212.29,
      "learning_rate": 0.07877953734951613,
      "loss": 0.9339,
      "step": 131620
    },
    {
      "epoch": 212.32,
      "learning_rate": 0.07877631154629032,
      "loss": 0.928,
      "step": 131640
    },
    {
      "epoch": 212.35,
      "learning_rate": 0.07877308574306452,
      "loss": 0.9488,
      "step": 131660
    },
    {
      "epoch": 212.39,
      "learning_rate": 0.07876985993983872,
      "loss": 0.934,
      "step": 131680
    },
    {
      "epoch": 212.42,
      "learning_rate": 0.0787666341366129,
      "loss": 0.9468,
      "step": 131700
    },
    {
      "epoch": 212.45,
      "learning_rate": 0.0787634083333871,
      "loss": 0.9562,
      "step": 131720
    },
    {
      "epoch": 212.48,
      "learning_rate": 0.0787601825301613,
      "loss": 0.944,
      "step": 131740
    },
    {
      "epoch": 212.52,
      "learning_rate": 0.07875695672693549,
      "loss": 0.9399,
      "step": 131760
    },
    {
      "epoch": 212.55,
      "learning_rate": 0.07875373092370967,
      "loss": 0.9273,
      "step": 131780
    },
    {
      "epoch": 212.58,
      "learning_rate": 0.07875050512048389,
      "loss": 0.9491,
      "step": 131800
    },
    {
      "epoch": 212.61,
      "learning_rate": 0.07874727931725807,
      "loss": 0.9439,
      "step": 131820
    },
    {
      "epoch": 212.65,
      "learning_rate": 0.07874405351403227,
      "loss": 0.9225,
      "step": 131840
    },
    {
      "epoch": 212.68,
      "learning_rate": 0.07874082771080645,
      "loss": 0.9251,
      "step": 131860
    },
    {
      "epoch": 212.71,
      "learning_rate": 0.07873760190758064,
      "loss": 0.9447,
      "step": 131880
    },
    {
      "epoch": 212.74,
      "learning_rate": 0.07873437610435484,
      "loss": 0.9689,
      "step": 131900
    },
    {
      "epoch": 212.77,
      "learning_rate": 0.07873115030112904,
      "loss": 0.9381,
      "step": 131920
    },
    {
      "epoch": 212.81,
      "learning_rate": 0.07872792449790322,
      "loss": 0.968,
      "step": 131940
    },
    {
      "epoch": 212.84,
      "learning_rate": 0.07872469869467742,
      "loss": 0.9545,
      "step": 131960
    },
    {
      "epoch": 212.87,
      "learning_rate": 0.07872147289145162,
      "loss": 0.9329,
      "step": 131980
    },
    {
      "epoch": 212.9,
      "learning_rate": 0.0787182470882258,
      "loss": 0.9477,
      "step": 132000
    },
    {
      "epoch": 212.94,
      "learning_rate": 0.078715021285,
      "loss": 0.9934,
      "step": 132020
    },
    {
      "epoch": 212.97,
      "learning_rate": 0.0787117954817742,
      "loss": 0.9564,
      "step": 132040
    },
    {
      "epoch": 213.0,
      "learning_rate": 0.07870856967854839,
      "loss": 0.9493,
      "step": 132060
    },
    {
      "epoch": 213.0,
      "eval_accuracy": {
        "accuracy": 0.7350714229958629
      },
      "eval_loss": 1.3469198942184448,
      "eval_runtime": 3.2016,
      "eval_samples_per_second": 4001.481,
      "eval_steps_per_second": 62.782,
      "step": 132060
    },
    {
      "epoch": 213.03,
      "learning_rate": 0.07870534387532259,
      "loss": 0.9758,
      "step": 132080
    },
    {
      "epoch": 213.06,
      "learning_rate": 0.07870211807209679,
      "loss": 0.9447,
      "step": 132100
    },
    {
      "epoch": 213.1,
      "learning_rate": 0.07869889226887097,
      "loss": 0.9388,
      "step": 132120
    },
    {
      "epoch": 213.13,
      "learning_rate": 0.07869566646564517,
      "loss": 0.9344,
      "step": 132140
    },
    {
      "epoch": 213.16,
      "learning_rate": 0.07869244066241936,
      "loss": 0.9336,
      "step": 132160
    },
    {
      "epoch": 213.19,
      "learning_rate": 0.07868921485919354,
      "loss": 0.9292,
      "step": 132180
    },
    {
      "epoch": 213.23,
      "learning_rate": 0.07868598905596774,
      "loss": 0.9211,
      "step": 132200
    },
    {
      "epoch": 213.26,
      "learning_rate": 0.07868276325274194,
      "loss": 0.9496,
      "step": 132220
    },
    {
      "epoch": 213.29,
      "learning_rate": 0.07867953744951613,
      "loss": 0.9409,
      "step": 132240
    },
    {
      "epoch": 213.32,
      "learning_rate": 0.07867631164629033,
      "loss": 0.9305,
      "step": 132260
    },
    {
      "epoch": 213.35,
      "learning_rate": 0.07867308584306452,
      "loss": 0.9635,
      "step": 132280
    },
    {
      "epoch": 213.39,
      "learning_rate": 0.07866986003983871,
      "loss": 0.9102,
      "step": 132300
    },
    {
      "epoch": 213.42,
      "learning_rate": 0.07866663423661291,
      "loss": 0.9359,
      "step": 132320
    },
    {
      "epoch": 213.45,
      "learning_rate": 0.07866340843338711,
      "loss": 0.9196,
      "step": 132340
    },
    {
      "epoch": 213.48,
      "learning_rate": 0.0786601826301613,
      "loss": 0.9421,
      "step": 132360
    },
    {
      "epoch": 213.52,
      "learning_rate": 0.07865695682693549,
      "loss": 0.9249,
      "step": 132380
    },
    {
      "epoch": 213.55,
      "learning_rate": 0.07865373102370969,
      "loss": 0.924,
      "step": 132400
    },
    {
      "epoch": 213.58,
      "learning_rate": 0.07865050522048386,
      "loss": 0.9158,
      "step": 132420
    },
    {
      "epoch": 213.61,
      "learning_rate": 0.07864727941725808,
      "loss": 0.9494,
      "step": 132440
    },
    {
      "epoch": 213.65,
      "learning_rate": 0.07864405361403226,
      "loss": 0.9535,
      "step": 132460
    },
    {
      "epoch": 213.68,
      "learning_rate": 0.07864082781080645,
      "loss": 0.9581,
      "step": 132480
    },
    {
      "epoch": 213.71,
      "learning_rate": 0.07863760200758065,
      "loss": 0.951,
      "step": 132500
    },
    {
      "epoch": 213.74,
      "learning_rate": 0.07863437620435484,
      "loss": 0.9507,
      "step": 132520
    },
    {
      "epoch": 213.77,
      "learning_rate": 0.07863115040112903,
      "loss": 0.9565,
      "step": 132540
    },
    {
      "epoch": 213.81,
      "learning_rate": 0.07862792459790323,
      "loss": 0.9347,
      "step": 132560
    },
    {
      "epoch": 213.84,
      "learning_rate": 0.07862469879467743,
      "loss": 0.9505,
      "step": 132580
    },
    {
      "epoch": 213.87,
      "learning_rate": 0.07862147299145161,
      "loss": 0.9373,
      "step": 132600
    },
    {
      "epoch": 213.9,
      "learning_rate": 0.07861824718822581,
      "loss": 0.9318,
      "step": 132620
    },
    {
      "epoch": 213.94,
      "learning_rate": 0.07861502138500001,
      "loss": 0.9727,
      "step": 132640
    },
    {
      "epoch": 213.97,
      "learning_rate": 0.0786117955817742,
      "loss": 0.9242,
      "step": 132660
    },
    {
      "epoch": 214.0,
      "learning_rate": 0.07860873106870968,
      "loss": 0.9448,
      "step": 132680
    },
    {
      "epoch": 214.0,
      "eval_accuracy": {
        "accuracy": 0.7400671298103193
      },
      "eval_loss": 1.3422538042068481,
      "eval_runtime": 2.9849,
      "eval_samples_per_second": 4291.939,
      "eval_steps_per_second": 67.339,
      "step": 132680
    },
    {
      "epoch": 214.03,
      "learning_rate": 0.07860550526548388,
      "loss": 0.9428,
      "step": 132700
    },
    {
      "epoch": 214.06,
      "learning_rate": 0.07860227946225806,
      "loss": 0.9277,
      "step": 132720
    },
    {
      "epoch": 214.1,
      "learning_rate": 0.07859905365903226,
      "loss": 0.9285,
      "step": 132740
    },
    {
      "epoch": 214.13,
      "learning_rate": 0.07859582785580646,
      "loss": 0.9013,
      "step": 132760
    },
    {
      "epoch": 214.16,
      "learning_rate": 0.07859260205258065,
      "loss": 0.8975,
      "step": 132780
    },
    {
      "epoch": 214.19,
      "learning_rate": 0.07858937624935484,
      "loss": 0.8999,
      "step": 132800
    },
    {
      "epoch": 214.23,
      "learning_rate": 0.07858615044612904,
      "loss": 0.8988,
      "step": 132820
    },
    {
      "epoch": 214.26,
      "learning_rate": 0.07858292464290323,
      "loss": 0.9426,
      "step": 132840
    },
    {
      "epoch": 214.29,
      "learning_rate": 0.07857969883967741,
      "loss": 0.9096,
      "step": 132860
    },
    {
      "epoch": 214.32,
      "learning_rate": 0.07857647303645163,
      "loss": 0.8859,
      "step": 132880
    },
    {
      "epoch": 214.35,
      "learning_rate": 0.07857324723322581,
      "loss": 0.9311,
      "step": 132900
    },
    {
      "epoch": 214.39,
      "learning_rate": 0.07857002143000001,
      "loss": 0.955,
      "step": 132920
    },
    {
      "epoch": 214.42,
      "learning_rate": 0.0785667956267742,
      "loss": 0.9605,
      "step": 132940
    },
    {
      "epoch": 214.45,
      "learning_rate": 0.07856356982354838,
      "loss": 0.9348,
      "step": 132960
    },
    {
      "epoch": 214.48,
      "learning_rate": 0.07856034402032258,
      "loss": 0.9273,
      "step": 132980
    },
    {
      "epoch": 214.52,
      "learning_rate": 0.07855711821709678,
      "loss": 0.8851,
      "step": 133000
    },
    {
      "epoch": 214.55,
      "learning_rate": 0.07855389241387097,
      "loss": 0.9402,
      "step": 133020
    },
    {
      "epoch": 214.58,
      "learning_rate": 0.07855066661064516,
      "loss": 0.9266,
      "step": 133040
    },
    {
      "epoch": 214.61,
      "learning_rate": 0.07854744080741936,
      "loss": 0.9205,
      "step": 133060
    },
    {
      "epoch": 214.65,
      "learning_rate": 0.07854421500419355,
      "loss": 0.9429,
      "step": 133080
    },
    {
      "epoch": 214.68,
      "learning_rate": 0.07854098920096775,
      "loss": 0.9417,
      "step": 133100
    },
    {
      "epoch": 214.71,
      "learning_rate": 0.07853776339774195,
      "loss": 0.9211,
      "step": 133120
    },
    {
      "epoch": 214.74,
      "learning_rate": 0.07853453759451613,
      "loss": 0.9304,
      "step": 133140
    },
    {
      "epoch": 214.77,
      "learning_rate": 0.07853131179129033,
      "loss": 0.9582,
      "step": 133160
    },
    {
      "epoch": 214.81,
      "learning_rate": 0.07852808598806453,
      "loss": 0.9424,
      "step": 133180
    },
    {
      "epoch": 214.84,
      "learning_rate": 0.07852486018483872,
      "loss": 0.9444,
      "step": 133200
    },
    {
      "epoch": 214.87,
      "learning_rate": 0.07852163438161291,
      "loss": 0.9178,
      "step": 133220
    },
    {
      "epoch": 214.9,
      "learning_rate": 0.0785184085783871,
      "loss": 0.9055,
      "step": 133240
    },
    {
      "epoch": 214.94,
      "learning_rate": 0.07851518277516129,
      "loss": 0.9606,
      "step": 133260
    },
    {
      "epoch": 214.97,
      "learning_rate": 0.07851195697193548,
      "loss": 0.9529,
      "step": 133280
    },
    {
      "epoch": 215.0,
      "learning_rate": 0.07850873116870968,
      "loss": 0.9384,
      "step": 133300
    },
    {
      "epoch": 215.0,
      "eval_accuracy": {
        "accuracy": 0.7426430411365234
      },
      "eval_loss": 1.3256701231002808,
      "eval_runtime": 2.8663,
      "eval_samples_per_second": 4469.59,
      "eval_steps_per_second": 70.126,
      "step": 133300
    },
    {
      "epoch": 215.03,
      "learning_rate": 0.07850550536548387,
      "loss": 0.9848,
      "step": 133320
    },
    {
      "epoch": 215.06,
      "learning_rate": 0.07850227956225807,
      "loss": 0.9031,
      "step": 133340
    },
    {
      "epoch": 215.1,
      "learning_rate": 0.07849905375903227,
      "loss": 0.8986,
      "step": 133360
    },
    {
      "epoch": 215.13,
      "learning_rate": 0.07849582795580645,
      "loss": 0.9162,
      "step": 133380
    },
    {
      "epoch": 215.16,
      "learning_rate": 0.07849260215258065,
      "loss": 0.8994,
      "step": 133400
    },
    {
      "epoch": 215.19,
      "learning_rate": 0.07848937634935485,
      "loss": 0.947,
      "step": 133420
    },
    {
      "epoch": 215.23,
      "learning_rate": 0.07848615054612904,
      "loss": 0.9389,
      "step": 133440
    },
    {
      "epoch": 215.26,
      "learning_rate": 0.07848292474290323,
      "loss": 0.9289,
      "step": 133460
    },
    {
      "epoch": 215.29,
      "learning_rate": 0.07847969893967743,
      "loss": 0.9191,
      "step": 133480
    },
    {
      "epoch": 215.32,
      "learning_rate": 0.0784764731364516,
      "loss": 0.8987,
      "step": 133500
    },
    {
      "epoch": 215.35,
      "learning_rate": 0.07847324733322582,
      "loss": 0.9246,
      "step": 133520
    },
    {
      "epoch": 215.39,
      "learning_rate": 0.07847002153,
      "loss": 0.9406,
      "step": 133540
    },
    {
      "epoch": 215.42,
      "learning_rate": 0.07846679572677419,
      "loss": 0.9151,
      "step": 133560
    },
    {
      "epoch": 215.45,
      "learning_rate": 0.07846356992354839,
      "loss": 0.9256,
      "step": 133580
    },
    {
      "epoch": 215.48,
      "learning_rate": 0.07846034412032259,
      "loss": 0.9177,
      "step": 133600
    },
    {
      "epoch": 215.52,
      "learning_rate": 0.07845711831709677,
      "loss": 0.9551,
      "step": 133620
    },
    {
      "epoch": 215.55,
      "learning_rate": 0.07845389251387097,
      "loss": 0.9543,
      "step": 133640
    },
    {
      "epoch": 215.58,
      "learning_rate": 0.07845066671064517,
      "loss": 0.9233,
      "step": 133660
    },
    {
      "epoch": 215.61,
      "learning_rate": 0.07844744090741936,
      "loss": 0.9019,
      "step": 133680
    },
    {
      "epoch": 215.65,
      "learning_rate": 0.07844421510419355,
      "loss": 0.9275,
      "step": 133700
    },
    {
      "epoch": 215.68,
      "learning_rate": 0.07844098930096775,
      "loss": 0.9247,
      "step": 133720
    },
    {
      "epoch": 215.71,
      "learning_rate": 0.07843776349774194,
      "loss": 0.9198,
      "step": 133740
    },
    {
      "epoch": 215.74,
      "learning_rate": 0.07843453769451614,
      "loss": 0.9466,
      "step": 133760
    },
    {
      "epoch": 215.77,
      "learning_rate": 0.07843131189129034,
      "loss": 0.9419,
      "step": 133780
    },
    {
      "epoch": 215.81,
      "learning_rate": 0.07842808608806451,
      "loss": 0.9499,
      "step": 133800
    },
    {
      "epoch": 215.84,
      "learning_rate": 0.07842486028483872,
      "loss": 0.9216,
      "step": 133820
    },
    {
      "epoch": 215.87,
      "learning_rate": 0.0784216344816129,
      "loss": 0.9448,
      "step": 133840
    },
    {
      "epoch": 215.9,
      "learning_rate": 0.0784184086783871,
      "loss": 0.9629,
      "step": 133860
    },
    {
      "epoch": 215.94,
      "learning_rate": 0.07841518287516129,
      "loss": 0.9546,
      "step": 133880
    },
    {
      "epoch": 215.97,
      "learning_rate": 0.07841195707193549,
      "loss": 0.9356,
      "step": 133900
    },
    {
      "epoch": 216.0,
      "learning_rate": 0.07840873126870967,
      "loss": 0.9606,
      "step": 133920
    },
    {
      "epoch": 216.0,
      "eval_accuracy": {
        "accuracy": 0.7406135352431504
      },
      "eval_loss": 1.302077293395996,
      "eval_runtime": 2.6866,
      "eval_samples_per_second": 4768.409,
      "eval_steps_per_second": 74.815,
      "step": 133920
    },
    {
      "epoch": 216.03,
      "learning_rate": 0.07840550546548387,
      "loss": 0.9556,
      "step": 133940
    },
    {
      "epoch": 216.06,
      "learning_rate": 0.07840227966225807,
      "loss": 0.9335,
      "step": 133960
    },
    {
      "epoch": 216.1,
      "learning_rate": 0.07839905385903226,
      "loss": 0.9334,
      "step": 133980
    },
    {
      "epoch": 216.13,
      "learning_rate": 0.07839582805580646,
      "loss": 0.9169,
      "step": 134000
    },
    {
      "epoch": 216.16,
      "learning_rate": 0.07839260225258066,
      "loss": 0.9186,
      "step": 134020
    },
    {
      "epoch": 216.19,
      "learning_rate": 0.07838937644935484,
      "loss": 0.9334,
      "step": 134040
    },
    {
      "epoch": 216.23,
      "learning_rate": 0.07838615064612904,
      "loss": 0.9332,
      "step": 134060
    },
    {
      "epoch": 216.26,
      "learning_rate": 0.07838292484290324,
      "loss": 0.9387,
      "step": 134080
    },
    {
      "epoch": 216.29,
      "learning_rate": 0.07837969903967741,
      "loss": 0.9366,
      "step": 134100
    },
    {
      "epoch": 216.32,
      "learning_rate": 0.07837647323645162,
      "loss": 0.9111,
      "step": 134120
    },
    {
      "epoch": 216.35,
      "learning_rate": 0.07837324743322581,
      "loss": 0.896,
      "step": 134140
    },
    {
      "epoch": 216.39,
      "learning_rate": 0.07837002163000001,
      "loss": 0.9278,
      "step": 134160
    },
    {
      "epoch": 216.42,
      "learning_rate": 0.0783667958267742,
      "loss": 0.9339,
      "step": 134180
    },
    {
      "epoch": 216.45,
      "learning_rate": 0.07836357002354839,
      "loss": 0.949,
      "step": 134200
    },
    {
      "epoch": 216.48,
      "learning_rate": 0.07836034422032258,
      "loss": 0.9445,
      "step": 134220
    },
    {
      "epoch": 216.52,
      "learning_rate": 0.07835711841709678,
      "loss": 0.9124,
      "step": 134240
    },
    {
      "epoch": 216.55,
      "learning_rate": 0.07835389261387098,
      "loss": 0.9528,
      "step": 134260
    },
    {
      "epoch": 216.58,
      "learning_rate": 0.07835066681064516,
      "loss": 0.9101,
      "step": 134280
    },
    {
      "epoch": 216.61,
      "learning_rate": 0.07834744100741936,
      "loss": 0.9081,
      "step": 134300
    },
    {
      "epoch": 216.65,
      "learning_rate": 0.07834421520419356,
      "loss": 0.907,
      "step": 134320
    },
    {
      "epoch": 216.68,
      "learning_rate": 0.07834098940096774,
      "loss": 0.9172,
      "step": 134340
    },
    {
      "epoch": 216.71,
      "learning_rate": 0.07833776359774194,
      "loss": 0.9285,
      "step": 134360
    },
    {
      "epoch": 216.74,
      "learning_rate": 0.07833453779451614,
      "loss": 0.9629,
      "step": 134380
    },
    {
      "epoch": 216.77,
      "learning_rate": 0.07833131199129033,
      "loss": 0.9359,
      "step": 134400
    },
    {
      "epoch": 216.81,
      "learning_rate": 0.07832808618806453,
      "loss": 0.9542,
      "step": 134420
    },
    {
      "epoch": 216.84,
      "learning_rate": 0.07832486038483871,
      "loss": 0.9444,
      "step": 134440
    },
    {
      "epoch": 216.87,
      "learning_rate": 0.07832163458161291,
      "loss": 0.9313,
      "step": 134460
    },
    {
      "epoch": 216.9,
      "learning_rate": 0.0783184087783871,
      "loss": 0.9331,
      "step": 134480
    },
    {
      "epoch": 216.94,
      "learning_rate": 0.0783151829751613,
      "loss": 0.9359,
      "step": 134500
    },
    {
      "epoch": 216.97,
      "learning_rate": 0.07831195717193548,
      "loss": 0.9446,
      "step": 134520
    },
    {
      "epoch": 217.0,
      "learning_rate": 0.07830873136870968,
      "loss": 0.9557,
      "step": 134540
    },
    {
      "epoch": 217.0,
      "eval_accuracy": {
        "accuracy": 0.7324955116696589
      },
      "eval_loss": 1.4157977104187012,
      "eval_runtime": 3.1449,
      "eval_samples_per_second": 4073.633,
      "eval_steps_per_second": 63.914,
      "step": 134540
    },
    {
      "epoch": 217.03,
      "learning_rate": 0.07830550556548388,
      "loss": 1.0072,
      "step": 134560
    },
    {
      "epoch": 217.06,
      "learning_rate": 0.07830227976225806,
      "loss": 0.9302,
      "step": 134580
    },
    {
      "epoch": 217.1,
      "learning_rate": 0.07829905395903226,
      "loss": 0.9067,
      "step": 134600
    },
    {
      "epoch": 217.13,
      "learning_rate": 0.07829582815580646,
      "loss": 0.8925,
      "step": 134620
    },
    {
      "epoch": 217.16,
      "learning_rate": 0.07829260235258065,
      "loss": 0.9269,
      "step": 134640
    },
    {
      "epoch": 217.19,
      "learning_rate": 0.07828937654935485,
      "loss": 0.9236,
      "step": 134660
    },
    {
      "epoch": 217.23,
      "learning_rate": 0.07828615074612905,
      "loss": 0.9326,
      "step": 134680
    },
    {
      "epoch": 217.26,
      "learning_rate": 0.07828292494290323,
      "loss": 0.9311,
      "step": 134700
    },
    {
      "epoch": 217.29,
      "learning_rate": 0.07827969913967743,
      "loss": 0.9365,
      "step": 134720
    },
    {
      "epoch": 217.32,
      "learning_rate": 0.07827647333645162,
      "loss": 0.9508,
      "step": 134740
    },
    {
      "epoch": 217.35,
      "learning_rate": 0.07827324753322581,
      "loss": 0.9303,
      "step": 134760
    },
    {
      "epoch": 217.39,
      "learning_rate": 0.07827002173,
      "loss": 0.9386,
      "step": 134780
    },
    {
      "epoch": 217.42,
      "learning_rate": 0.0782667959267742,
      "loss": 0.9285,
      "step": 134800
    },
    {
      "epoch": 217.45,
      "learning_rate": 0.07826357012354838,
      "loss": 0.9122,
      "step": 134820
    },
    {
      "epoch": 217.48,
      "learning_rate": 0.07826034432032258,
      "loss": 0.9408,
      "step": 134840
    },
    {
      "epoch": 217.52,
      "learning_rate": 0.07825711851709678,
      "loss": 0.963,
      "step": 134860
    },
    {
      "epoch": 217.55,
      "learning_rate": 0.07825389271387097,
      "loss": 0.9514,
      "step": 134880
    },
    {
      "epoch": 217.58,
      "learning_rate": 0.07825066691064517,
      "loss": 0.9489,
      "step": 134900
    },
    {
      "epoch": 217.61,
      "learning_rate": 0.07824744110741937,
      "loss": 0.9788,
      "step": 134920
    },
    {
      "epoch": 217.65,
      "learning_rate": 0.07824421530419355,
      "loss": 0.9563,
      "step": 134940
    },
    {
      "epoch": 217.68,
      "learning_rate": 0.07824098950096775,
      "loss": 0.9207,
      "step": 134960
    },
    {
      "epoch": 217.71,
      "learning_rate": 0.07823776369774195,
      "loss": 0.9635,
      "step": 134980
    },
    {
      "epoch": 217.74,
      "learning_rate": 0.07823453789451613,
      "loss": 0.9691,
      "step": 135000
    },
    {
      "epoch": 217.77,
      "learning_rate": 0.07823147338145162,
      "loss": 0.9659,
      "step": 135020
    },
    {
      "epoch": 217.81,
      "learning_rate": 0.07822824757822582,
      "loss": 0.9498,
      "step": 135040
    },
    {
      "epoch": 217.84,
      "learning_rate": 0.078225021775,
      "loss": 0.9328,
      "step": 135060
    },
    {
      "epoch": 217.87,
      "learning_rate": 0.0782217959717742,
      "loss": 0.9372,
      "step": 135080
    },
    {
      "epoch": 217.9,
      "learning_rate": 0.0782185701685484,
      "loss": 0.9187,
      "step": 135100
    },
    {
      "epoch": 217.94,
      "learning_rate": 0.07821534436532258,
      "loss": 0.9196,
      "step": 135120
    },
    {
      "epoch": 217.97,
      "learning_rate": 0.07821211856209678,
      "loss": 0.9402,
      "step": 135140
    },
    {
      "epoch": 218.0,
      "learning_rate": 0.07820889275887098,
      "loss": 0.9527,
      "step": 135160
    },
    {
      "epoch": 218.0,
      "eval_accuracy": {
        "accuracy": 0.7381937397548981
      },
      "eval_loss": 1.2970829010009766,
      "eval_runtime": 2.7062,
      "eval_samples_per_second": 4733.983,
      "eval_steps_per_second": 74.274,
      "step": 135160
    },
    {
      "epoch": 218.03,
      "learning_rate": 0.07820566695564515,
      "loss": 1.0013,
      "step": 135180
    },
    {
      "epoch": 218.06,
      "learning_rate": 0.07820244115241937,
      "loss": 0.9344,
      "step": 135200
    },
    {
      "epoch": 218.1,
      "learning_rate": 0.07819921534919355,
      "loss": 0.9072,
      "step": 135220
    },
    {
      "epoch": 218.13,
      "learning_rate": 0.07819598954596775,
      "loss": 0.9278,
      "step": 135240
    },
    {
      "epoch": 218.16,
      "learning_rate": 0.07819276374274194,
      "loss": 0.9229,
      "step": 135260
    },
    {
      "epoch": 218.19,
      "learning_rate": 0.07818953793951613,
      "loss": 0.9451,
      "step": 135280
    },
    {
      "epoch": 218.23,
      "learning_rate": 0.07818631213629032,
      "loss": 0.9201,
      "step": 135300
    },
    {
      "epoch": 218.26,
      "learning_rate": 0.07818308633306452,
      "loss": 0.9045,
      "step": 135320
    },
    {
      "epoch": 218.29,
      "learning_rate": 0.07817986052983872,
      "loss": 0.9276,
      "step": 135340
    },
    {
      "epoch": 218.32,
      "learning_rate": 0.0781766347266129,
      "loss": 0.9112,
      "step": 135360
    },
    {
      "epoch": 218.35,
      "learning_rate": 0.0781734089233871,
      "loss": 0.9372,
      "step": 135380
    },
    {
      "epoch": 218.39,
      "learning_rate": 0.0781701831201613,
      "loss": 0.9115,
      "step": 135400
    },
    {
      "epoch": 218.42,
      "learning_rate": 0.07816695731693549,
      "loss": 0.9168,
      "step": 135420
    },
    {
      "epoch": 218.45,
      "learning_rate": 0.07816373151370969,
      "loss": 0.9124,
      "step": 135440
    },
    {
      "epoch": 218.48,
      "learning_rate": 0.07816050571048389,
      "loss": 0.9357,
      "step": 135460
    },
    {
      "epoch": 218.52,
      "learning_rate": 0.07815727990725807,
      "loss": 0.9423,
      "step": 135480
    },
    {
      "epoch": 218.55,
      "learning_rate": 0.07815405410403227,
      "loss": 0.9292,
      "step": 135500
    },
    {
      "epoch": 218.58,
      "learning_rate": 0.07815082830080645,
      "loss": 0.9288,
      "step": 135520
    },
    {
      "epoch": 218.61,
      "learning_rate": 0.07814760249758065,
      "loss": 0.9345,
      "step": 135540
    },
    {
      "epoch": 218.65,
      "learning_rate": 0.07814437669435484,
      "loss": 0.9633,
      "step": 135560
    },
    {
      "epoch": 218.68,
      "learning_rate": 0.07814115089112904,
      "loss": 0.9306,
      "step": 135580
    },
    {
      "epoch": 218.71,
      "learning_rate": 0.07813792508790322,
      "loss": 0.9152,
      "step": 135600
    },
    {
      "epoch": 218.74,
      "learning_rate": 0.07813469928467742,
      "loss": 0.9395,
      "step": 135620
    },
    {
      "epoch": 218.77,
      "learning_rate": 0.07813147348145162,
      "loss": 0.9394,
      "step": 135640
    },
    {
      "epoch": 218.81,
      "learning_rate": 0.0781282476782258,
      "loss": 0.9341,
      "step": 135660
    },
    {
      "epoch": 218.84,
      "learning_rate": 0.078125021875,
      "loss": 0.9269,
      "step": 135680
    },
    {
      "epoch": 218.87,
      "learning_rate": 0.0781217960717742,
      "loss": 0.9932,
      "step": 135700
    },
    {
      "epoch": 218.9,
      "learning_rate": 0.07811857026854839,
      "loss": 0.9641,
      "step": 135720
    },
    {
      "epoch": 218.94,
      "learning_rate": 0.07811534446532259,
      "loss": 0.8995,
      "step": 135740
    },
    {
      "epoch": 218.97,
      "learning_rate": 0.07811211866209679,
      "loss": 0.9057,
      "step": 135760
    },
    {
      "epoch": 219.0,
      "learning_rate": 0.07810889285887097,
      "loss": 0.9579,
      "step": 135780
    },
    {
      "epoch": 219.0,
      "eval_accuracy": {
        "accuracy": 0.7368667551323081
      },
      "eval_loss": 1.331472635269165,
      "eval_runtime": 2.8382,
      "eval_samples_per_second": 4513.854,
      "eval_steps_per_second": 70.821,
      "step": 135780
    },
    {
      "epoch": 219.03,
      "learning_rate": 0.07810566705564517,
      "loss": 0.9643,
      "step": 135800
    },
    {
      "epoch": 219.06,
      "learning_rate": 0.07810244125241936,
      "loss": 0.9265,
      "step": 135820
    },
    {
      "epoch": 219.1,
      "learning_rate": 0.07809921544919356,
      "loss": 0.9274,
      "step": 135840
    },
    {
      "epoch": 219.13,
      "learning_rate": 0.07809598964596774,
      "loss": 0.9133,
      "step": 135860
    },
    {
      "epoch": 219.16,
      "learning_rate": 0.07809276384274194,
      "loss": 0.9572,
      "step": 135880
    },
    {
      "epoch": 219.19,
      "learning_rate": 0.07808953803951613,
      "loss": 0.9465,
      "step": 135900
    },
    {
      "epoch": 219.23,
      "learning_rate": 0.07808631223629033,
      "loss": 0.939,
      "step": 135920
    },
    {
      "epoch": 219.26,
      "learning_rate": 0.07808308643306452,
      "loss": 0.9163,
      "step": 135940
    },
    {
      "epoch": 219.29,
      "learning_rate": 0.07807986062983871,
      "loss": 0.9345,
      "step": 135960
    },
    {
      "epoch": 219.32,
      "learning_rate": 0.07807663482661291,
      "loss": 0.9029,
      "step": 135980
    },
    {
      "epoch": 219.35,
      "learning_rate": 0.07807340902338711,
      "loss": 0.9209,
      "step": 136000
    },
    {
      "epoch": 219.39,
      "learning_rate": 0.0780701832201613,
      "loss": 0.9592,
      "step": 136020
    },
    {
      "epoch": 219.42,
      "learning_rate": 0.07806695741693549,
      "loss": 0.9172,
      "step": 136040
    },
    {
      "epoch": 219.45,
      "learning_rate": 0.07806373161370969,
      "loss": 0.9455,
      "step": 136060
    },
    {
      "epoch": 219.48,
      "learning_rate": 0.07806050581048388,
      "loss": 0.949,
      "step": 136080
    },
    {
      "epoch": 219.52,
      "learning_rate": 0.07805728000725808,
      "loss": 0.9444,
      "step": 136100
    },
    {
      "epoch": 219.55,
      "learning_rate": 0.07805405420403226,
      "loss": 0.9565,
      "step": 136120
    },
    {
      "epoch": 219.58,
      "learning_rate": 0.07805082840080646,
      "loss": 0.9199,
      "step": 136140
    },
    {
      "epoch": 219.61,
      "learning_rate": 0.07804760259758065,
      "loss": 0.9182,
      "step": 136160
    },
    {
      "epoch": 219.65,
      "learning_rate": 0.07804437679435484,
      "loss": 0.9453,
      "step": 136180
    },
    {
      "epoch": 219.68,
      "learning_rate": 0.07804115099112903,
      "loss": 0.9378,
      "step": 136200
    },
    {
      "epoch": 219.71,
      "learning_rate": 0.07803792518790323,
      "loss": 0.9428,
      "step": 136220
    },
    {
      "epoch": 219.74,
      "learning_rate": 0.07803469938467743,
      "loss": 0.9316,
      "step": 136240
    },
    {
      "epoch": 219.77,
      "learning_rate": 0.07803147358145161,
      "loss": 0.9498,
      "step": 136260
    },
    {
      "epoch": 219.81,
      "learning_rate": 0.07802824777822581,
      "loss": 0.9541,
      "step": 136280
    },
    {
      "epoch": 219.84,
      "learning_rate": 0.07802502197500001,
      "loss": 0.932,
      "step": 136300
    },
    {
      "epoch": 219.87,
      "learning_rate": 0.0780217961717742,
      "loss": 0.9306,
      "step": 136320
    },
    {
      "epoch": 219.9,
      "learning_rate": 0.0780185703685484,
      "loss": 0.9307,
      "step": 136340
    },
    {
      "epoch": 219.94,
      "learning_rate": 0.07801534456532258,
      "loss": 0.95,
      "step": 136360
    },
    {
      "epoch": 219.97,
      "learning_rate": 0.07801211876209678,
      "loss": 0.9642,
      "step": 136380
    },
    {
      "epoch": 220.0,
      "learning_rate": 0.07800889295887098,
      "loss": 0.9525,
      "step": 136400
    },
    {
      "epoch": 220.0,
      "eval_accuracy": {
        "accuracy": 0.7400671298103193
      },
      "eval_loss": 1.3338909149169922,
      "eval_runtime": 2.9426,
      "eval_samples_per_second": 4353.57,
      "eval_steps_per_second": 68.306,
      "step": 136400
    },
    {
      "epoch": 220.03,
      "learning_rate": 0.07800566715564516,
      "loss": 0.9617,
      "step": 136420
    },
    {
      "epoch": 220.06,
      "learning_rate": 0.07800244135241936,
      "loss": 0.9194,
      "step": 136440
    },
    {
      "epoch": 220.1,
      "learning_rate": 0.07799921554919355,
      "loss": 0.9177,
      "step": 136460
    },
    {
      "epoch": 220.13,
      "learning_rate": 0.07799598974596775,
      "loss": 0.9206,
      "step": 136480
    },
    {
      "epoch": 220.16,
      "learning_rate": 0.07799276394274193,
      "loss": 0.9175,
      "step": 136500
    },
    {
      "epoch": 220.19,
      "learning_rate": 0.07798953813951613,
      "loss": 0.9023,
      "step": 136520
    },
    {
      "epoch": 220.23,
      "learning_rate": 0.07798631233629033,
      "loss": 0.9172,
      "step": 136540
    },
    {
      "epoch": 220.26,
      "learning_rate": 0.07798308653306452,
      "loss": 0.9467,
      "step": 136560
    },
    {
      "epoch": 220.29,
      "learning_rate": 0.07797986072983872,
      "loss": 0.9123,
      "step": 136580
    },
    {
      "epoch": 220.32,
      "learning_rate": 0.07797663492661291,
      "loss": 0.9181,
      "step": 136600
    },
    {
      "epoch": 220.35,
      "learning_rate": 0.0779734091233871,
      "loss": 0.9246,
      "step": 136620
    },
    {
      "epoch": 220.39,
      "learning_rate": 0.0779701833201613,
      "loss": 0.9271,
      "step": 136640
    },
    {
      "epoch": 220.42,
      "learning_rate": 0.07796695751693548,
      "loss": 0.9367,
      "step": 136660
    },
    {
      "epoch": 220.45,
      "learning_rate": 0.07796373171370968,
      "loss": 0.934,
      "step": 136680
    },
    {
      "epoch": 220.48,
      "learning_rate": 0.07796050591048388,
      "loss": 0.9531,
      "step": 136700
    },
    {
      "epoch": 220.52,
      "learning_rate": 0.07795728010725807,
      "loss": 0.9314,
      "step": 136720
    },
    {
      "epoch": 220.55,
      "learning_rate": 0.07795405430403227,
      "loss": 0.9599,
      "step": 136740
    },
    {
      "epoch": 220.58,
      "learning_rate": 0.07795082850080645,
      "loss": 0.9161,
      "step": 136760
    },
    {
      "epoch": 220.61,
      "learning_rate": 0.07794760269758065,
      "loss": 0.9226,
      "step": 136780
    },
    {
      "epoch": 220.65,
      "learning_rate": 0.07794437689435484,
      "loss": 0.8949,
      "step": 136800
    },
    {
      "epoch": 220.68,
      "learning_rate": 0.07794115109112904,
      "loss": 0.9036,
      "step": 136820
    },
    {
      "epoch": 220.71,
      "learning_rate": 0.07793792528790323,
      "loss": 0.9284,
      "step": 136840
    },
    {
      "epoch": 220.74,
      "learning_rate": 0.07793469948467742,
      "loss": 0.9334,
      "step": 136860
    },
    {
      "epoch": 220.77,
      "learning_rate": 0.07793147368145162,
      "loss": 0.9528,
      "step": 136880
    },
    {
      "epoch": 220.81,
      "learning_rate": 0.0779282478782258,
      "loss": 0.9475,
      "step": 136900
    },
    {
      "epoch": 220.84,
      "learning_rate": 0.077925022075,
      "loss": 0.9442,
      "step": 136920
    },
    {
      "epoch": 220.87,
      "learning_rate": 0.0779217962717742,
      "loss": 0.934,
      "step": 136940
    },
    {
      "epoch": 220.9,
      "learning_rate": 0.07791857046854839,
      "loss": 0.9758,
      "step": 136960
    },
    {
      "epoch": 220.94,
      "learning_rate": 0.07791534466532259,
      "loss": 0.9522,
      "step": 136980
    },
    {
      "epoch": 220.97,
      "learning_rate": 0.07791211886209679,
      "loss": 0.9187,
      "step": 137000
    },
    {
      "epoch": 221.0,
      "learning_rate": 0.07790889305887097,
      "loss": 0.93,
      "step": 137020
    },
    {
      "epoch": 221.0,
      "eval_accuracy": {
        "accuracy": 0.7403013035672469
      },
      "eval_loss": 1.3580126762390137,
      "eval_runtime": 2.7365,
      "eval_samples_per_second": 4681.536,
      "eval_steps_per_second": 73.452,
      "step": 137020
    },
    {
      "epoch": 221.03,
      "learning_rate": 0.07790566725564517,
      "loss": 0.9574,
      "step": 137040
    },
    {
      "epoch": 221.06,
      "learning_rate": 0.07790244145241935,
      "loss": 0.9193,
      "step": 137060
    },
    {
      "epoch": 221.1,
      "learning_rate": 0.07789921564919355,
      "loss": 0.9266,
      "step": 137080
    },
    {
      "epoch": 221.13,
      "learning_rate": 0.07789598984596774,
      "loss": 0.9458,
      "step": 137100
    },
    {
      "epoch": 221.16,
      "learning_rate": 0.07789276404274194,
      "loss": 0.9572,
      "step": 137120
    },
    {
      "epoch": 221.19,
      "learning_rate": 0.07788953823951614,
      "loss": 0.9526,
      "step": 137140
    },
    {
      "epoch": 221.23,
      "learning_rate": 0.07788631243629032,
      "loss": 0.9417,
      "step": 137160
    },
    {
      "epoch": 221.26,
      "learning_rate": 0.07788308663306452,
      "loss": 0.9162,
      "step": 137180
    },
    {
      "epoch": 221.29,
      "learning_rate": 0.0778798608298387,
      "loss": 0.8994,
      "step": 137200
    },
    {
      "epoch": 221.32,
      "learning_rate": 0.0778766350266129,
      "loss": 0.9123,
      "step": 137220
    },
    {
      "epoch": 221.35,
      "learning_rate": 0.0778734092233871,
      "loss": 0.9516,
      "step": 137240
    },
    {
      "epoch": 221.39,
      "learning_rate": 0.07787018342016129,
      "loss": 0.9448,
      "step": 137260
    },
    {
      "epoch": 221.42,
      "learning_rate": 0.07786695761693549,
      "loss": 0.9203,
      "step": 137280
    },
    {
      "epoch": 221.45,
      "learning_rate": 0.07786373181370969,
      "loss": 0.9468,
      "step": 137300
    },
    {
      "epoch": 221.48,
      "learning_rate": 0.07786050601048387,
      "loss": 0.931,
      "step": 137320
    },
    {
      "epoch": 221.52,
      "learning_rate": 0.07785728020725807,
      "loss": 0.9233,
      "step": 137340
    },
    {
      "epoch": 221.55,
      "learning_rate": 0.07785405440403226,
      "loss": 0.9533,
      "step": 137360
    },
    {
      "epoch": 221.58,
      "learning_rate": 0.07785082860080646,
      "loss": 0.9418,
      "step": 137380
    },
    {
      "epoch": 221.61,
      "learning_rate": 0.07784760279758064,
      "loss": 0.925,
      "step": 137400
    },
    {
      "epoch": 221.65,
      "learning_rate": 0.07784437699435486,
      "loss": 0.9429,
      "step": 137420
    },
    {
      "epoch": 221.68,
      "learning_rate": 0.07784115119112903,
      "loss": 0.9457,
      "step": 137440
    },
    {
      "epoch": 221.71,
      "learning_rate": 0.07783792538790323,
      "loss": 0.9443,
      "step": 137460
    },
    {
      "epoch": 221.74,
      "learning_rate": 0.07783469958467742,
      "loss": 0.9642,
      "step": 137480
    },
    {
      "epoch": 221.77,
      "learning_rate": 0.07783147378145161,
      "loss": 0.9587,
      "step": 137500
    },
    {
      "epoch": 221.81,
      "learning_rate": 0.07782824797822581,
      "loss": 0.9727,
      "step": 137520
    },
    {
      "epoch": 221.84,
      "learning_rate": 0.07782502217500001,
      "loss": 0.9713,
      "step": 137540
    },
    {
      "epoch": 221.87,
      "learning_rate": 0.0778217963717742,
      "loss": 0.9364,
      "step": 137560
    },
    {
      "epoch": 221.9,
      "learning_rate": 0.07781857056854839,
      "loss": 0.9238,
      "step": 137580
    },
    {
      "epoch": 221.94,
      "learning_rate": 0.07781534476532259,
      "loss": 0.9279,
      "step": 137600
    },
    {
      "epoch": 221.97,
      "learning_rate": 0.07781211896209678,
      "loss": 0.9301,
      "step": 137620
    },
    {
      "epoch": 222.0,
      "learning_rate": 0.07780905444903226,
      "loss": 0.9322,
      "step": 137640
    },
    {
      "epoch": 222.0,
      "eval_accuracy": {
        "accuracy": 0.7463117633283897
      },
      "eval_loss": 1.2879081964492798,
      "eval_runtime": 2.848,
      "eval_samples_per_second": 4498.296,
      "eval_steps_per_second": 70.577,
      "step": 137640
    },
    {
      "epoch": 222.03,
      "learning_rate": 0.07780582864580646,
      "loss": 0.9096,
      "step": 137660
    },
    {
      "epoch": 222.06,
      "learning_rate": 0.07780260284258066,
      "loss": 0.9198,
      "step": 137680
    },
    {
      "epoch": 222.1,
      "learning_rate": 0.07779937703935484,
      "loss": 0.9211,
      "step": 137700
    },
    {
      "epoch": 222.13,
      "learning_rate": 0.07779615123612904,
      "loss": 0.9383,
      "step": 137720
    },
    {
      "epoch": 222.16,
      "learning_rate": 0.07779292543290323,
      "loss": 0.9314,
      "step": 137740
    },
    {
      "epoch": 222.19,
      "learning_rate": 0.07778969962967743,
      "loss": 0.9064,
      "step": 137760
    },
    {
      "epoch": 222.23,
      "learning_rate": 0.07778647382645162,
      "loss": 0.9259,
      "step": 137780
    },
    {
      "epoch": 222.26,
      "learning_rate": 0.07778324802322581,
      "loss": 0.9258,
      "step": 137800
    },
    {
      "epoch": 222.29,
      "learning_rate": 0.07778002222000001,
      "loss": 0.9182,
      "step": 137820
    },
    {
      "epoch": 222.32,
      "learning_rate": 0.0777767964167742,
      "loss": 0.9174,
      "step": 137840
    },
    {
      "epoch": 222.35,
      "learning_rate": 0.07777357061354839,
      "loss": 0.8942,
      "step": 137860
    },
    {
      "epoch": 222.39,
      "learning_rate": 0.07777034481032258,
      "loss": 0.8988,
      "step": 137880
    },
    {
      "epoch": 222.42,
      "learning_rate": 0.07776711900709678,
      "loss": 0.9145,
      "step": 137900
    },
    {
      "epoch": 222.45,
      "learning_rate": 0.07776389320387098,
      "loss": 0.9163,
      "step": 137920
    },
    {
      "epoch": 222.48,
      "learning_rate": 0.07776066740064516,
      "loss": 0.9146,
      "step": 137940
    },
    {
      "epoch": 222.52,
      "learning_rate": 0.07775744159741936,
      "loss": 0.9151,
      "step": 137960
    },
    {
      "epoch": 222.55,
      "learning_rate": 0.07775421579419355,
      "loss": 0.9466,
      "step": 137980
    },
    {
      "epoch": 222.58,
      "learning_rate": 0.07775098999096774,
      "loss": 0.9483,
      "step": 138000
    },
    {
      "epoch": 222.61,
      "learning_rate": 0.07774776418774194,
      "loss": 0.922,
      "step": 138020
    },
    {
      "epoch": 222.65,
      "learning_rate": 0.07774453838451613,
      "loss": 0.9564,
      "step": 138040
    },
    {
      "epoch": 222.68,
      "learning_rate": 0.07774131258129033,
      "loss": 0.9246,
      "step": 138060
    },
    {
      "epoch": 222.71,
      "learning_rate": 0.07773808677806453,
      "loss": 0.9853,
      "step": 138080
    },
    {
      "epoch": 222.74,
      "learning_rate": 0.07773486097483871,
      "loss": 0.9558,
      "step": 138100
    },
    {
      "epoch": 222.77,
      "learning_rate": 0.07773163517161291,
      "loss": 0.9375,
      "step": 138120
    },
    {
      "epoch": 222.81,
      "learning_rate": 0.0777284093683871,
      "loss": 0.9635,
      "step": 138140
    },
    {
      "epoch": 222.84,
      "learning_rate": 0.0777251835651613,
      "loss": 0.9738,
      "step": 138160
    },
    {
      "epoch": 222.87,
      "learning_rate": 0.07772195776193548,
      "loss": 0.9583,
      "step": 138180
    },
    {
      "epoch": 222.9,
      "learning_rate": 0.07771873195870968,
      "loss": 0.9604,
      "step": 138200
    },
    {
      "epoch": 222.94,
      "learning_rate": 0.07771550615548388,
      "loss": 0.9447,
      "step": 138220
    },
    {
      "epoch": 222.97,
      "learning_rate": 0.07771228035225806,
      "loss": 0.9456,
      "step": 138240
    },
    {
      "epoch": 223.0,
      "learning_rate": 0.07770905454903226,
      "loss": 0.9192,
      "step": 138260
    },
    {
      "epoch": 223.0,
      "eval_accuracy": {
        "accuracy": 0.751307470142846
      },
      "eval_loss": 1.262393832206726,
      "eval_runtime": 2.8568,
      "eval_samples_per_second": 4484.357,
      "eval_steps_per_second": 70.358,
      "step": 138260
    },
    {
      "epoch": 223.03,
      "learning_rate": 0.07770582874580645,
      "loss": 0.9555,
      "step": 138280
    },
    {
      "epoch": 223.06,
      "learning_rate": 0.07770260294258065,
      "loss": 0.8998,
      "step": 138300
    },
    {
      "epoch": 223.1,
      "learning_rate": 0.07769937713935485,
      "loss": 0.9369,
      "step": 138320
    },
    {
      "epoch": 223.13,
      "learning_rate": 0.07769615133612903,
      "loss": 0.9304,
      "step": 138340
    },
    {
      "epoch": 223.16,
      "learning_rate": 0.07769292553290323,
      "loss": 0.9059,
      "step": 138360
    },
    {
      "epoch": 223.19,
      "learning_rate": 0.07768969972967743,
      "loss": 0.9258,
      "step": 138380
    },
    {
      "epoch": 223.23,
      "learning_rate": 0.07768647392645162,
      "loss": 0.9237,
      "step": 138400
    },
    {
      "epoch": 223.26,
      "learning_rate": 0.07768324812322581,
      "loss": 0.9391,
      "step": 138420
    },
    {
      "epoch": 223.29,
      "learning_rate": 0.07768002232,
      "loss": 0.9176,
      "step": 138440
    },
    {
      "epoch": 223.32,
      "learning_rate": 0.0776767965167742,
      "loss": 0.9291,
      "step": 138460
    },
    {
      "epoch": 223.35,
      "learning_rate": 0.07767357071354838,
      "loss": 0.9077,
      "step": 138480
    },
    {
      "epoch": 223.39,
      "learning_rate": 0.0776703449103226,
      "loss": 0.9025,
      "step": 138500
    },
    {
      "epoch": 223.42,
      "learning_rate": 0.07766711910709677,
      "loss": 0.9423,
      "step": 138520
    },
    {
      "epoch": 223.45,
      "learning_rate": 0.07766389330387097,
      "loss": 0.9288,
      "step": 138540
    },
    {
      "epoch": 223.48,
      "learning_rate": 0.07766066750064517,
      "loss": 0.9195,
      "step": 138560
    },
    {
      "epoch": 223.52,
      "learning_rate": 0.07765744169741935,
      "loss": 0.9363,
      "step": 138580
    },
    {
      "epoch": 223.55,
      "learning_rate": 0.07765421589419355,
      "loss": 0.931,
      "step": 138600
    },
    {
      "epoch": 223.58,
      "learning_rate": 0.07765099009096775,
      "loss": 0.9285,
      "step": 138620
    },
    {
      "epoch": 223.61,
      "learning_rate": 0.07764776428774194,
      "loss": 0.9458,
      "step": 138640
    },
    {
      "epoch": 223.65,
      "learning_rate": 0.07764453848451613,
      "loss": 0.9441,
      "step": 138660
    },
    {
      "epoch": 223.68,
      "learning_rate": 0.07764131268129033,
      "loss": 0.9497,
      "step": 138680
    },
    {
      "epoch": 223.71,
      "learning_rate": 0.07763808687806452,
      "loss": 0.9434,
      "step": 138700
    },
    {
      "epoch": 223.74,
      "learning_rate": 0.07763486107483872,
      "loss": 0.9484,
      "step": 138720
    },
    {
      "epoch": 223.77,
      "learning_rate": 0.0776316352716129,
      "loss": 0.9342,
      "step": 138740
    },
    {
      "epoch": 223.81,
      "learning_rate": 0.0776284094683871,
      "loss": 0.9439,
      "step": 138760
    },
    {
      "epoch": 223.84,
      "learning_rate": 0.07762518366516129,
      "loss": 0.9453,
      "step": 138780
    },
    {
      "epoch": 223.87,
      "learning_rate": 0.0776219578619355,
      "loss": 0.9702,
      "step": 138800
    },
    {
      "epoch": 223.9,
      "learning_rate": 0.07761873205870967,
      "loss": 0.9458,
      "step": 138820
    },
    {
      "epoch": 223.94,
      "learning_rate": 0.07761550625548387,
      "loss": 0.9236,
      "step": 138840
    },
    {
      "epoch": 223.97,
      "learning_rate": 0.07761228045225807,
      "loss": 0.9333,
      "step": 138860
    },
    {
      "epoch": 224.0,
      "learning_rate": 0.07760905464903226,
      "loss": 0.9706,
      "step": 138880
    },
    {
      "epoch": 224.0,
      "eval_accuracy": {
        "accuracy": 0.7368667551323081
      },
      "eval_loss": 1.3696396350860596,
      "eval_runtime": 2.9809,
      "eval_samples_per_second": 4297.729,
      "eval_steps_per_second": 67.43,
      "step": 138880
    },
    {
      "epoch": 224.03,
      "learning_rate": 0.07760582884580645,
      "loss": 0.9859,
      "step": 138900
    },
    {
      "epoch": 224.06,
      "learning_rate": 0.07760260304258065,
      "loss": 0.8971,
      "step": 138920
    },
    {
      "epoch": 224.1,
      "learning_rate": 0.07759937723935484,
      "loss": 0.9013,
      "step": 138940
    },
    {
      "epoch": 224.13,
      "learning_rate": 0.07759615143612904,
      "loss": 0.9246,
      "step": 138960
    },
    {
      "epoch": 224.16,
      "learning_rate": 0.07759292563290324,
      "loss": 0.9041,
      "step": 138980
    },
    {
      "epoch": 224.19,
      "learning_rate": 0.07758969982967742,
      "loss": 0.9046,
      "step": 139000
    },
    {
      "epoch": 224.23,
      "learning_rate": 0.07758647402645162,
      "loss": 0.9244,
      "step": 139020
    },
    {
      "epoch": 224.26,
      "learning_rate": 0.07758324822322582,
      "loss": 0.9074,
      "step": 139040
    },
    {
      "epoch": 224.29,
      "learning_rate": 0.07758002242,
      "loss": 0.9224,
      "step": 139060
    },
    {
      "epoch": 224.32,
      "learning_rate": 0.07757679661677419,
      "loss": 0.9588,
      "step": 139080
    },
    {
      "epoch": 224.35,
      "learning_rate": 0.0775735708135484,
      "loss": 0.8975,
      "step": 139100
    },
    {
      "epoch": 224.39,
      "learning_rate": 0.07757034501032258,
      "loss": 0.9411,
      "step": 139120
    },
    {
      "epoch": 224.42,
      "learning_rate": 0.07756711920709677,
      "loss": 0.9249,
      "step": 139140
    },
    {
      "epoch": 224.45,
      "learning_rate": 0.07756389340387097,
      "loss": 0.9416,
      "step": 139160
    },
    {
      "epoch": 224.48,
      "learning_rate": 0.07756066760064516,
      "loss": 0.9112,
      "step": 139180
    },
    {
      "epoch": 224.52,
      "learning_rate": 0.07755744179741936,
      "loss": 0.9247,
      "step": 139200
    },
    {
      "epoch": 224.55,
      "learning_rate": 0.07755421599419356,
      "loss": 0.9603,
      "step": 139220
    },
    {
      "epoch": 224.58,
      "learning_rate": 0.07755099019096774,
      "loss": 0.9514,
      "step": 139240
    },
    {
      "epoch": 224.61,
      "learning_rate": 0.07754776438774194,
      "loss": 0.9277,
      "step": 139260
    },
    {
      "epoch": 224.65,
      "learning_rate": 0.07754453858451614,
      "loss": 0.9139,
      "step": 139280
    },
    {
      "epoch": 224.68,
      "learning_rate": 0.07754131278129033,
      "loss": 0.948,
      "step": 139300
    },
    {
      "epoch": 224.71,
      "learning_rate": 0.07753808697806452,
      "loss": 0.9365,
      "step": 139320
    },
    {
      "epoch": 224.74,
      "learning_rate": 0.07753486117483872,
      "loss": 0.9352,
      "step": 139340
    },
    {
      "epoch": 224.77,
      "learning_rate": 0.07753163537161291,
      "loss": 0.9373,
      "step": 139360
    },
    {
      "epoch": 224.81,
      "learning_rate": 0.0775284095683871,
      "loss": 0.927,
      "step": 139380
    },
    {
      "epoch": 224.84,
      "learning_rate": 0.0775251837651613,
      "loss": 0.9375,
      "step": 139400
    },
    {
      "epoch": 224.87,
      "learning_rate": 0.07752195796193548,
      "loss": 0.9624,
      "step": 139420
    },
    {
      "epoch": 224.9,
      "learning_rate": 0.07751873215870968,
      "loss": 0.9477,
      "step": 139440
    },
    {
      "epoch": 224.94,
      "learning_rate": 0.07751550635548388,
      "loss": 0.9293,
      "step": 139460
    },
    {
      "epoch": 224.97,
      "learning_rate": 0.07751228055225806,
      "loss": 0.9085,
      "step": 139480
    },
    {
      "epoch": 225.0,
      "learning_rate": 0.07750905474903226,
      "loss": 0.9435,
      "step": 139500
    },
    {
      "epoch": 225.0,
      "eval_accuracy": {
        "accuracy": 0.7427991569744751
      },
      "eval_loss": 1.2972946166992188,
      "eval_runtime": 2.8862,
      "eval_samples_per_second": 4438.719,
      "eval_steps_per_second": 69.642,
      "step": 139500
    },
    {
      "epoch": 225.03,
      "learning_rate": 0.07750582894580646,
      "loss": 0.9342,
      "step": 139520
    },
    {
      "epoch": 225.06,
      "learning_rate": 0.07750260314258064,
      "loss": 0.9027,
      "step": 139540
    },
    {
      "epoch": 225.1,
      "learning_rate": 0.07749937733935484,
      "loss": 0.911,
      "step": 139560
    },
    {
      "epoch": 225.13,
      "learning_rate": 0.07749615153612904,
      "loss": 0.9105,
      "step": 139580
    },
    {
      "epoch": 225.16,
      "learning_rate": 0.07749292573290323,
      "loss": 0.921,
      "step": 139600
    },
    {
      "epoch": 225.19,
      "learning_rate": 0.07748969992967743,
      "loss": 0.9211,
      "step": 139620
    },
    {
      "epoch": 225.23,
      "learning_rate": 0.07748647412645163,
      "loss": 0.9545,
      "step": 139640
    },
    {
      "epoch": 225.26,
      "learning_rate": 0.07748324832322581,
      "loss": 0.9438,
      "step": 139660
    },
    {
      "epoch": 225.29,
      "learning_rate": 0.07748002252,
      "loss": 0.9251,
      "step": 139680
    },
    {
      "epoch": 225.32,
      "learning_rate": 0.07747679671677421,
      "loss": 0.9409,
      "step": 139700
    },
    {
      "epoch": 225.35,
      "learning_rate": 0.07747357091354838,
      "loss": 0.9041,
      "step": 139720
    },
    {
      "epoch": 225.39,
      "learning_rate": 0.0774703451103226,
      "loss": 0.9182,
      "step": 139740
    },
    {
      "epoch": 225.42,
      "learning_rate": 0.07746711930709678,
      "loss": 0.9341,
      "step": 139760
    },
    {
      "epoch": 225.45,
      "learning_rate": 0.07746389350387096,
      "loss": 0.9329,
      "step": 139780
    },
    {
      "epoch": 225.48,
      "learning_rate": 0.07746066770064516,
      "loss": 0.9251,
      "step": 139800
    },
    {
      "epoch": 225.52,
      "learning_rate": 0.07745744189741936,
      "loss": 0.9331,
      "step": 139820
    },
    {
      "epoch": 225.55,
      "learning_rate": 0.07745421609419355,
      "loss": 0.9237,
      "step": 139840
    },
    {
      "epoch": 225.58,
      "learning_rate": 0.07745099029096775,
      "loss": 0.9105,
      "step": 139860
    },
    {
      "epoch": 225.61,
      "learning_rate": 0.07744776448774195,
      "loss": 0.9148,
      "step": 139880
    },
    {
      "epoch": 225.65,
      "learning_rate": 0.07744453868451613,
      "loss": 0.9052,
      "step": 139900
    },
    {
      "epoch": 225.68,
      "learning_rate": 0.07744131288129033,
      "loss": 0.912,
      "step": 139920
    },
    {
      "epoch": 225.71,
      "learning_rate": 0.07743808707806453,
      "loss": 0.9132,
      "step": 139940
    },
    {
      "epoch": 225.74,
      "learning_rate": 0.07743486127483871,
      "loss": 0.9411,
      "step": 139960
    },
    {
      "epoch": 225.77,
      "learning_rate": 0.07743163547161291,
      "loss": 0.9571,
      "step": 139980
    },
    {
      "epoch": 225.81,
      "learning_rate": 0.07742840966838711,
      "loss": 0.9423,
      "step": 140000
    },
    {
      "epoch": 225.84,
      "learning_rate": 0.07742518386516128,
      "loss": 0.9391,
      "step": 140020
    },
    {
      "epoch": 225.87,
      "learning_rate": 0.0774219580619355,
      "loss": 0.9286,
      "step": 140040
    },
    {
      "epoch": 225.9,
      "learning_rate": 0.07741873225870968,
      "loss": 0.9146,
      "step": 140060
    },
    {
      "epoch": 225.94,
      "learning_rate": 0.07741550645548387,
      "loss": 0.9218,
      "step": 140080
    },
    {
      "epoch": 225.97,
      "learning_rate": 0.07741228065225807,
      "loss": 0.9324,
      "step": 140100
    },
    {
      "epoch": 226.0,
      "learning_rate": 0.07740921613919356,
      "loss": 0.9374,
      "step": 140120
    },
    {
      "epoch": 226.0,
      "eval_accuracy": {
        "accuracy": 0.7477948637889313
      },
      "eval_loss": 1.2800912857055664,
      "eval_runtime": 3.5526,
      "eval_samples_per_second": 3606.134,
      "eval_steps_per_second": 56.579,
      "step": 140120
    },
    {
      "epoch": 226.03,
      "learning_rate": 0.07740599033596775,
      "loss": 0.9458,
      "step": 140140
    },
    {
      "epoch": 226.06,
      "learning_rate": 0.07740276453274193,
      "loss": 0.9422,
      "step": 140160
    },
    {
      "epoch": 226.1,
      "learning_rate": 0.07739953872951615,
      "loss": 0.9087,
      "step": 140180
    },
    {
      "epoch": 226.13,
      "learning_rate": 0.07739631292629032,
      "loss": 0.8941,
      "step": 140200
    },
    {
      "epoch": 226.16,
      "learning_rate": 0.07739308712306452,
      "loss": 0.9153,
      "step": 140220
    },
    {
      "epoch": 226.19,
      "learning_rate": 0.07738986131983872,
      "loss": 0.9159,
      "step": 140240
    },
    {
      "epoch": 226.23,
      "learning_rate": 0.0773866355166129,
      "loss": 0.9091,
      "step": 140260
    },
    {
      "epoch": 226.26,
      "learning_rate": 0.0773834097133871,
      "loss": 0.9435,
      "step": 140280
    },
    {
      "epoch": 226.29,
      "learning_rate": 0.0773801839101613,
      "loss": 0.9122,
      "step": 140300
    },
    {
      "epoch": 226.32,
      "learning_rate": 0.07737695810693548,
      "loss": 0.9328,
      "step": 140320
    },
    {
      "epoch": 226.35,
      "learning_rate": 0.07737373230370968,
      "loss": 0.9665,
      "step": 140340
    },
    {
      "epoch": 226.39,
      "learning_rate": 0.07737050650048388,
      "loss": 0.9202,
      "step": 140360
    },
    {
      "epoch": 226.42,
      "learning_rate": 0.07736728069725807,
      "loss": 0.9382,
      "step": 140380
    },
    {
      "epoch": 226.45,
      "learning_rate": 0.07736405489403227,
      "loss": 0.932,
      "step": 140400
    },
    {
      "epoch": 226.48,
      "learning_rate": 0.07736082909080647,
      "loss": 0.9269,
      "step": 140420
    },
    {
      "epoch": 226.52,
      "learning_rate": 0.07735760328758065,
      "loss": 0.9321,
      "step": 140440
    },
    {
      "epoch": 226.55,
      "learning_rate": 0.07735437748435484,
      "loss": 0.9291,
      "step": 140460
    },
    {
      "epoch": 226.58,
      "learning_rate": 0.07735115168112905,
      "loss": 0.9075,
      "step": 140480
    },
    {
      "epoch": 226.61,
      "learning_rate": 0.07734792587790322,
      "loss": 0.9172,
      "step": 140500
    },
    {
      "epoch": 226.65,
      "learning_rate": 0.07734470007467742,
      "loss": 0.9348,
      "step": 140520
    },
    {
      "epoch": 226.68,
      "learning_rate": 0.07734147427145162,
      "loss": 0.9458,
      "step": 140540
    },
    {
      "epoch": 226.71,
      "learning_rate": 0.0773382484682258,
      "loss": 0.8994,
      "step": 140560
    },
    {
      "epoch": 226.74,
      "learning_rate": 0.077335022665,
      "loss": 0.9254,
      "step": 140580
    },
    {
      "epoch": 226.77,
      "learning_rate": 0.0773317968617742,
      "loss": 0.9252,
      "step": 140600
    },
    {
      "epoch": 226.81,
      "learning_rate": 0.07732857105854839,
      "loss": 0.9006,
      "step": 140620
    },
    {
      "epoch": 226.84,
      "learning_rate": 0.07732534525532259,
      "loss": 0.9044,
      "step": 140640
    },
    {
      "epoch": 226.87,
      "learning_rate": 0.07732211945209679,
      "loss": 0.9345,
      "step": 140660
    },
    {
      "epoch": 226.9,
      "learning_rate": 0.07731889364887097,
      "loss": 0.9285,
      "step": 140680
    },
    {
      "epoch": 226.94,
      "learning_rate": 0.07731566784564517,
      "loss": 0.9377,
      "step": 140700
    },
    {
      "epoch": 226.97,
      "learning_rate": 0.07731244204241937,
      "loss": 0.9031,
      "step": 140720
    },
    {
      "epoch": 227.0,
      "learning_rate": 0.07730921623919355,
      "loss": 0.9175,
      "step": 140740
    },
    {
      "epoch": 227.0,
      "eval_accuracy": {
        "accuracy": 0.739598782296464
      },
      "eval_loss": 1.3119087219238281,
      "eval_runtime": 2.7779,
      "eval_samples_per_second": 4611.748,
      "eval_steps_per_second": 72.357,
      "step": 140740
    },
    {
      "epoch": 227.03,
      "learning_rate": 0.07730599043596774,
      "loss": 0.9326,
      "step": 140760
    },
    {
      "epoch": 227.06,
      "learning_rate": 0.07730276463274195,
      "loss": 0.8925,
      "step": 140780
    },
    {
      "epoch": 227.1,
      "learning_rate": 0.07729953882951612,
      "loss": 0.9069,
      "step": 140800
    },
    {
      "epoch": 227.13,
      "learning_rate": 0.07729631302629034,
      "loss": 0.9356,
      "step": 140820
    },
    {
      "epoch": 227.16,
      "learning_rate": 0.07729308722306452,
      "loss": 0.8787,
      "step": 140840
    },
    {
      "epoch": 227.19,
      "learning_rate": 0.0772898614198387,
      "loss": 0.8956,
      "step": 140860
    },
    {
      "epoch": 227.23,
      "learning_rate": 0.0772866356166129,
      "loss": 0.9206,
      "step": 140880
    },
    {
      "epoch": 227.26,
      "learning_rate": 0.0772834098133871,
      "loss": 0.9299,
      "step": 140900
    },
    {
      "epoch": 227.29,
      "learning_rate": 0.07728018401016129,
      "loss": 0.9256,
      "step": 140920
    },
    {
      "epoch": 227.32,
      "learning_rate": 0.07727695820693549,
      "loss": 0.9235,
      "step": 140940
    },
    {
      "epoch": 227.35,
      "learning_rate": 0.07727373240370969,
      "loss": 0.9261,
      "step": 140960
    },
    {
      "epoch": 227.39,
      "learning_rate": 0.07727050660048387,
      "loss": 0.9206,
      "step": 140980
    },
    {
      "epoch": 227.42,
      "learning_rate": 0.07726728079725807,
      "loss": 0.9051,
      "step": 141000
    },
    {
      "epoch": 227.45,
      "learning_rate": 0.07726405499403227,
      "loss": 0.9191,
      "step": 141020
    },
    {
      "epoch": 227.48,
      "learning_rate": 0.07726082919080646,
      "loss": 0.952,
      "step": 141040
    },
    {
      "epoch": 227.52,
      "learning_rate": 0.07725760338758064,
      "loss": 0.9423,
      "step": 141060
    },
    {
      "epoch": 227.55,
      "learning_rate": 0.07725437758435486,
      "loss": 0.9266,
      "step": 141080
    },
    {
      "epoch": 227.58,
      "learning_rate": 0.07725115178112903,
      "loss": 0.9382,
      "step": 141100
    },
    {
      "epoch": 227.61,
      "learning_rate": 0.07724792597790324,
      "loss": 0.9386,
      "step": 141120
    },
    {
      "epoch": 227.65,
      "learning_rate": 0.07724470017467742,
      "loss": 0.9404,
      "step": 141140
    },
    {
      "epoch": 227.68,
      "learning_rate": 0.07724147437145161,
      "loss": 0.9177,
      "step": 141160
    },
    {
      "epoch": 227.71,
      "learning_rate": 0.07723824856822581,
      "loss": 0.9155,
      "step": 141180
    },
    {
      "epoch": 227.74,
      "learning_rate": 0.07723502276500001,
      "loss": 0.9446,
      "step": 141200
    },
    {
      "epoch": 227.77,
      "learning_rate": 0.0772317969617742,
      "loss": 0.9521,
      "step": 141220
    },
    {
      "epoch": 227.81,
      "learning_rate": 0.07722857115854839,
      "loss": 0.9535,
      "step": 141240
    },
    {
      "epoch": 227.84,
      "learning_rate": 0.07722534535532259,
      "loss": 0.9151,
      "step": 141260
    },
    {
      "epoch": 227.87,
      "learning_rate": 0.07722211955209678,
      "loss": 0.9107,
      "step": 141280
    },
    {
      "epoch": 227.9,
      "learning_rate": 0.07721889374887098,
      "loss": 0.9409,
      "step": 141300
    },
    {
      "epoch": 227.94,
      "learning_rate": 0.07721566794564517,
      "loss": 0.9382,
      "step": 141320
    },
    {
      "epoch": 227.97,
      "learning_rate": 0.07721244214241936,
      "loss": 0.946,
      "step": 141340
    },
    {
      "epoch": 228.0,
      "learning_rate": 0.07720921633919356,
      "loss": 0.9441,
      "step": 141360
    },
    {
      "epoch": 228.0,
      "eval_accuracy": {
        "accuracy": 0.7347591913199594
      },
      "eval_loss": 1.3366832733154297,
      "eval_runtime": 2.9567,
      "eval_samples_per_second": 4332.883,
      "eval_steps_per_second": 67.981,
      "step": 141360
    },
    {
      "epoch": 228.03,
      "learning_rate": 0.07720599053596774,
      "loss": 0.9787,
      "step": 141380
    },
    {
      "epoch": 228.06,
      "learning_rate": 0.07720276473274193,
      "loss": 0.9143,
      "step": 141400
    },
    {
      "epoch": 228.1,
      "learning_rate": 0.07719953892951614,
      "loss": 0.9337,
      "step": 141420
    },
    {
      "epoch": 228.13,
      "learning_rate": 0.07719631312629033,
      "loss": 0.931,
      "step": 141440
    },
    {
      "epoch": 228.16,
      "learning_rate": 0.07719308732306451,
      "loss": 0.9263,
      "step": 141460
    },
    {
      "epoch": 228.19,
      "learning_rate": 0.07718986151983871,
      "loss": 0.8888,
      "step": 141480
    },
    {
      "epoch": 228.23,
      "learning_rate": 0.07718663571661291,
      "loss": 0.929,
      "step": 141500
    },
    {
      "epoch": 228.26,
      "learning_rate": 0.0771834099133871,
      "loss": 0.9091,
      "step": 141520
    },
    {
      "epoch": 228.29,
      "learning_rate": 0.0771801841101613,
      "loss": 0.9041,
      "step": 141540
    },
    {
      "epoch": 228.32,
      "learning_rate": 0.0771769583069355,
      "loss": 0.9045,
      "step": 141560
    },
    {
      "epoch": 228.35,
      "learning_rate": 0.07717373250370968,
      "loss": 0.9153,
      "step": 141580
    },
    {
      "epoch": 228.39,
      "learning_rate": 0.07717050670048388,
      "loss": 0.9269,
      "step": 141600
    },
    {
      "epoch": 228.42,
      "learning_rate": 0.07716728089725808,
      "loss": 0.955,
      "step": 141620
    },
    {
      "epoch": 228.45,
      "learning_rate": 0.07716405509403226,
      "loss": 0.9054,
      "step": 141640
    },
    {
      "epoch": 228.48,
      "learning_rate": 0.07716082929080646,
      "loss": 0.9148,
      "step": 141660
    },
    {
      "epoch": 228.52,
      "learning_rate": 0.07715760348758065,
      "loss": 0.937,
      "step": 141680
    },
    {
      "epoch": 228.55,
      "learning_rate": 0.07715437768435483,
      "loss": 0.9281,
      "step": 141700
    },
    {
      "epoch": 228.58,
      "learning_rate": 0.07715115188112905,
      "loss": 0.924,
      "step": 141720
    },
    {
      "epoch": 228.61,
      "learning_rate": 0.07714792607790323,
      "loss": 0.925,
      "step": 141740
    },
    {
      "epoch": 228.65,
      "learning_rate": 0.07714470027467742,
      "loss": 0.9262,
      "step": 141760
    },
    {
      "epoch": 228.68,
      "learning_rate": 0.07714147447145162,
      "loss": 0.9452,
      "step": 141780
    },
    {
      "epoch": 228.71,
      "learning_rate": 0.07713824866822581,
      "loss": 0.9273,
      "step": 141800
    },
    {
      "epoch": 228.74,
      "learning_rate": 0.077135022865,
      "loss": 0.9462,
      "step": 141820
    },
    {
      "epoch": 228.77,
      "learning_rate": 0.0771317970617742,
      "loss": 0.9616,
      "step": 141840
    },
    {
      "epoch": 228.81,
      "learning_rate": 0.0771285712585484,
      "loss": 0.9279,
      "step": 141860
    },
    {
      "epoch": 228.84,
      "learning_rate": 0.07712534545532258,
      "loss": 0.9334,
      "step": 141880
    },
    {
      "epoch": 228.87,
      "learning_rate": 0.07712211965209678,
      "loss": 0.9105,
      "step": 141900
    },
    {
      "epoch": 228.9,
      "learning_rate": 0.07711889384887097,
      "loss": 0.9502,
      "step": 141920
    },
    {
      "epoch": 228.94,
      "learning_rate": 0.07711566804564517,
      "loss": 0.9446,
      "step": 141940
    },
    {
      "epoch": 228.97,
      "learning_rate": 0.07711244224241937,
      "loss": 0.9473,
      "step": 141960
    },
    {
      "epoch": 229.0,
      "learning_rate": 0.07710921643919355,
      "loss": 0.9389,
      "step": 141980
    },
    {
      "epoch": 229.0,
      "eval_accuracy": {
        "accuracy": 0.7390523768636328
      },
      "eval_loss": 1.3107869625091553,
      "eval_runtime": 2.6782,
      "eval_samples_per_second": 4783.502,
      "eval_steps_per_second": 75.051,
      "step": 141980
    },
    {
      "epoch": 229.03,
      "learning_rate": 0.07710599063596774,
      "loss": 0.9907,
      "step": 142000
    },
    {
      "epoch": 229.06,
      "learning_rate": 0.07710276483274195,
      "loss": 0.9361,
      "step": 142020
    },
    {
      "epoch": 229.1,
      "learning_rate": 0.07709953902951613,
      "loss": 0.9128,
      "step": 142040
    },
    {
      "epoch": 229.13,
      "learning_rate": 0.07709631322629033,
      "loss": 0.903,
      "step": 142060
    },
    {
      "epoch": 229.16,
      "learning_rate": 0.07709308742306452,
      "loss": 0.9149,
      "step": 142080
    },
    {
      "epoch": 229.19,
      "learning_rate": 0.07708986161983872,
      "loss": 0.9146,
      "step": 142100
    },
    {
      "epoch": 229.23,
      "learning_rate": 0.0770866358166129,
      "loss": 0.907,
      "step": 142120
    },
    {
      "epoch": 229.26,
      "learning_rate": 0.0770834100133871,
      "loss": 0.9189,
      "step": 142140
    },
    {
      "epoch": 229.29,
      "learning_rate": 0.0770801842101613,
      "loss": 0.9356,
      "step": 142160
    },
    {
      "epoch": 229.32,
      "learning_rate": 0.07707695840693549,
      "loss": 0.941,
      "step": 142180
    },
    {
      "epoch": 229.35,
      "learning_rate": 0.07707373260370969,
      "loss": 0.929,
      "step": 142200
    },
    {
      "epoch": 229.39,
      "learning_rate": 0.07707050680048387,
      "loss": 0.9185,
      "step": 142220
    },
    {
      "epoch": 229.42,
      "learning_rate": 0.07706728099725807,
      "loss": 0.9218,
      "step": 142240
    },
    {
      "epoch": 229.45,
      "learning_rate": 0.07706405519403227,
      "loss": 0.9314,
      "step": 142260
    },
    {
      "epoch": 229.48,
      "learning_rate": 0.07706082939080645,
      "loss": 0.9351,
      "step": 142280
    },
    {
      "epoch": 229.52,
      "learning_rate": 0.07705760358758065,
      "loss": 0.9133,
      "step": 142300
    },
    {
      "epoch": 229.55,
      "learning_rate": 0.07705437778435485,
      "loss": 0.9134,
      "step": 142320
    },
    {
      "epoch": 229.58,
      "learning_rate": 0.07705115198112904,
      "loss": 0.9066,
      "step": 142340
    },
    {
      "epoch": 229.61,
      "learning_rate": 0.07704792617790324,
      "loss": 0.9102,
      "step": 142360
    },
    {
      "epoch": 229.65,
      "learning_rate": 0.07704470037467742,
      "loss": 0.9124,
      "step": 142380
    },
    {
      "epoch": 229.68,
      "learning_rate": 0.07704147457145162,
      "loss": 0.9025,
      "step": 142400
    },
    {
      "epoch": 229.71,
      "learning_rate": 0.0770382487682258,
      "loss": 0.9134,
      "step": 142420
    },
    {
      "epoch": 229.74,
      "learning_rate": 0.077035022965,
      "loss": 0.9391,
      "step": 142440
    },
    {
      "epoch": 229.77,
      "learning_rate": 0.07703179716177419,
      "loss": 0.9307,
      "step": 142460
    },
    {
      "epoch": 229.81,
      "learning_rate": 0.07702857135854839,
      "loss": 0.9197,
      "step": 142480
    },
    {
      "epoch": 229.84,
      "learning_rate": 0.07702534555532259,
      "loss": 0.9467,
      "step": 142500
    },
    {
      "epoch": 229.87,
      "learning_rate": 0.07702211975209677,
      "loss": 0.9441,
      "step": 142520
    },
    {
      "epoch": 229.9,
      "learning_rate": 0.07701889394887097,
      "loss": 0.9396,
      "step": 142540
    },
    {
      "epoch": 229.94,
      "learning_rate": 0.07701566814564517,
      "loss": 0.906,
      "step": 142560
    },
    {
      "epoch": 229.97,
      "learning_rate": 0.07701244234241936,
      "loss": 0.9196,
      "step": 142580
    },
    {
      "epoch": 230.0,
      "learning_rate": 0.07700921653919356,
      "loss": 0.921,
      "step": 142600
    },
    {
      "epoch": 230.0,
      "eval_accuracy": {
        "accuracy": 0.7393646085395363
      },
      "eval_loss": 1.3287159204483032,
      "eval_runtime": 2.7797,
      "eval_samples_per_second": 4608.768,
      "eval_steps_per_second": 72.31,
      "step": 142600
    },
    {
      "epoch": 230.03,
      "learning_rate": 0.07700599073596776,
      "loss": 0.9839,
      "step": 142620
    },
    {
      "epoch": 230.06,
      "learning_rate": 0.07700276493274194,
      "loss": 0.9351,
      "step": 142640
    },
    {
      "epoch": 230.1,
      "learning_rate": 0.07699953912951614,
      "loss": 0.9442,
      "step": 142660
    },
    {
      "epoch": 230.13,
      "learning_rate": 0.07699631332629032,
      "loss": 0.9267,
      "step": 142680
    },
    {
      "epoch": 230.16,
      "learning_rate": 0.07699308752306452,
      "loss": 0.9078,
      "step": 142700
    },
    {
      "epoch": 230.19,
      "learning_rate": 0.07698986171983871,
      "loss": 0.9254,
      "step": 142720
    },
    {
      "epoch": 230.23,
      "learning_rate": 0.07698663591661291,
      "loss": 0.8999,
      "step": 142740
    },
    {
      "epoch": 230.26,
      "learning_rate": 0.0769834101133871,
      "loss": 0.9114,
      "step": 142760
    },
    {
      "epoch": 230.29,
      "learning_rate": 0.07698018431016129,
      "loss": 0.8916,
      "step": 142780
    },
    {
      "epoch": 230.32,
      "learning_rate": 0.07697695850693549,
      "loss": 0.8688,
      "step": 142800
    },
    {
      "epoch": 230.35,
      "learning_rate": 0.07697373270370968,
      "loss": 0.9146,
      "step": 142820
    },
    {
      "epoch": 230.39,
      "learning_rate": 0.07697050690048388,
      "loss": 0.8898,
      "step": 142840
    },
    {
      "epoch": 230.42,
      "learning_rate": 0.07696728109725808,
      "loss": 0.9085,
      "step": 142860
    },
    {
      "epoch": 230.45,
      "learning_rate": 0.07696405529403226,
      "loss": 0.932,
      "step": 142880
    },
    {
      "epoch": 230.48,
      "learning_rate": 0.07696082949080646,
      "loss": 0.9187,
      "step": 142900
    },
    {
      "epoch": 230.52,
      "learning_rate": 0.07695760368758066,
      "loss": 0.9222,
      "step": 142920
    },
    {
      "epoch": 230.55,
      "learning_rate": 0.07695437788435484,
      "loss": 0.9115,
      "step": 142940
    },
    {
      "epoch": 230.58,
      "learning_rate": 0.07695115208112904,
      "loss": 0.8978,
      "step": 142960
    },
    {
      "epoch": 230.61,
      "learning_rate": 0.07694792627790323,
      "loss": 0.9212,
      "step": 142980
    },
    {
      "epoch": 230.65,
      "learning_rate": 0.07694470047467743,
      "loss": 0.9564,
      "step": 143000
    },
    {
      "epoch": 230.68,
      "learning_rate": 0.07694147467145161,
      "loss": 0.9259,
      "step": 143020
    },
    {
      "epoch": 230.71,
      "learning_rate": 0.07693824886822581,
      "loss": 0.9228,
      "step": 143040
    },
    {
      "epoch": 230.74,
      "learning_rate": 0.076935023065,
      "loss": 0.9015,
      "step": 143060
    },
    {
      "epoch": 230.77,
      "learning_rate": 0.0769317972617742,
      "loss": 0.9206,
      "step": 143080
    },
    {
      "epoch": 230.81,
      "learning_rate": 0.0769285714585484,
      "loss": 0.9361,
      "step": 143100
    },
    {
      "epoch": 230.84,
      "learning_rate": 0.07692534565532258,
      "loss": 0.9308,
      "step": 143120
    },
    {
      "epoch": 230.87,
      "learning_rate": 0.07692211985209678,
      "loss": 0.9322,
      "step": 143140
    },
    {
      "epoch": 230.9,
      "learning_rate": 0.07691889404887098,
      "loss": 0.9233,
      "step": 143160
    },
    {
      "epoch": 230.94,
      "learning_rate": 0.07691566824564516,
      "loss": 0.9459,
      "step": 143180
    },
    {
      "epoch": 230.97,
      "learning_rate": 0.07691244244241936,
      "loss": 0.9236,
      "step": 143200
    },
    {
      "epoch": 231.0,
      "learning_rate": 0.07690937792935484,
      "loss": 0.9532,
      "step": 143220
    },
    {
      "epoch": 231.0,
      "eval_accuracy": {
        "accuracy": 0.7420185777847162
      },
      "eval_loss": 1.317610502243042,
      "eval_runtime": 2.7023,
      "eval_samples_per_second": 4740.848,
      "eval_steps_per_second": 74.382,
      "step": 143220
    },
    {
      "epoch": 231.03,
      "learning_rate": 0.07690615212612904,
      "loss": 0.9052,
      "step": 143240
    },
    {
      "epoch": 231.06,
      "learning_rate": 0.07690292632290323,
      "loss": 0.8739,
      "step": 143260
    },
    {
      "epoch": 231.1,
      "learning_rate": 0.07689970051967743,
      "loss": 0.8946,
      "step": 143280
    },
    {
      "epoch": 231.13,
      "learning_rate": 0.07689647471645161,
      "loss": 0.9104,
      "step": 143300
    },
    {
      "epoch": 231.16,
      "learning_rate": 0.07689324891322581,
      "loss": 0.9096,
      "step": 143320
    },
    {
      "epoch": 231.19,
      "learning_rate": 0.07689002311000001,
      "loss": 0.9016,
      "step": 143340
    },
    {
      "epoch": 231.23,
      "learning_rate": 0.0768867973067742,
      "loss": 0.9126,
      "step": 143360
    },
    {
      "epoch": 231.26,
      "learning_rate": 0.07688357150354838,
      "loss": 0.9142,
      "step": 143380
    },
    {
      "epoch": 231.29,
      "learning_rate": 0.0768803457003226,
      "loss": 0.9231,
      "step": 143400
    },
    {
      "epoch": 231.32,
      "learning_rate": 0.07687711989709678,
      "loss": 0.9039,
      "step": 143420
    },
    {
      "epoch": 231.35,
      "learning_rate": 0.07687389409387098,
      "loss": 0.9275,
      "step": 143440
    },
    {
      "epoch": 231.39,
      "learning_rate": 0.07687066829064516,
      "loss": 0.9128,
      "step": 143460
    },
    {
      "epoch": 231.42,
      "learning_rate": 0.07686744248741936,
      "loss": 0.8963,
      "step": 143480
    },
    {
      "epoch": 231.45,
      "learning_rate": 0.07686421668419355,
      "loss": 0.9324,
      "step": 143500
    },
    {
      "epoch": 231.48,
      "learning_rate": 0.07686099088096775,
      "loss": 0.9091,
      "step": 143520
    },
    {
      "epoch": 231.52,
      "learning_rate": 0.07685776507774193,
      "loss": 0.9208,
      "step": 143540
    },
    {
      "epoch": 231.55,
      "learning_rate": 0.07685453927451613,
      "loss": 0.9151,
      "step": 143560
    },
    {
      "epoch": 231.58,
      "learning_rate": 0.07685131347129033,
      "loss": 0.9185,
      "step": 143580
    },
    {
      "epoch": 231.61,
      "learning_rate": 0.07684808766806452,
      "loss": 0.9214,
      "step": 143600
    },
    {
      "epoch": 231.65,
      "learning_rate": 0.07684486186483871,
      "loss": 0.9165,
      "step": 143620
    },
    {
      "epoch": 231.68,
      "learning_rate": 0.07684163606161291,
      "loss": 0.9484,
      "step": 143640
    },
    {
      "epoch": 231.71,
      "learning_rate": 0.0768384102583871,
      "loss": 0.933,
      "step": 143660
    },
    {
      "epoch": 231.74,
      "learning_rate": 0.0768351844551613,
      "loss": 0.9617,
      "step": 143680
    },
    {
      "epoch": 231.77,
      "learning_rate": 0.0768319586519355,
      "loss": 0.9318,
      "step": 143700
    },
    {
      "epoch": 231.81,
      "learning_rate": 0.07682873284870968,
      "loss": 0.9525,
      "step": 143720
    },
    {
      "epoch": 231.84,
      "learning_rate": 0.07682550704548388,
      "loss": 0.9499,
      "step": 143740
    },
    {
      "epoch": 231.87,
      "learning_rate": 0.07682228124225807,
      "loss": 0.9478,
      "step": 143760
    },
    {
      "epoch": 231.9,
      "learning_rate": 0.07681905543903227,
      "loss": 0.9571,
      "step": 143780
    },
    {
      "epoch": 231.94,
      "learning_rate": 0.07681582963580645,
      "loss": 0.953,
      "step": 143800
    },
    {
      "epoch": 231.97,
      "learning_rate": 0.07681260383258065,
      "loss": 0.9249,
      "step": 143820
    },
    {
      "epoch": 232.0,
      "learning_rate": 0.07680937802935484,
      "loss": 0.9314,
      "step": 143840
    },
    {
      "epoch": 232.0,
      "eval_accuracy": {
        "accuracy": 0.748731558816642
      },
      "eval_loss": 1.2554516792297363,
      "eval_runtime": 2.6461,
      "eval_samples_per_second": 4841.504,
      "eval_steps_per_second": 75.961,
      "step": 143840
    },
    {
      "epoch": 232.03,
      "learning_rate": 0.07680615222612903,
      "loss": 0.9558,
      "step": 143860
    },
    {
      "epoch": 232.06,
      "learning_rate": 0.07680292642290323,
      "loss": 0.9116,
      "step": 143880
    },
    {
      "epoch": 232.1,
      "learning_rate": 0.07679970061967742,
      "loss": 0.9255,
      "step": 143900
    },
    {
      "epoch": 232.13,
      "learning_rate": 0.07679647481645162,
      "loss": 0.9395,
      "step": 143920
    },
    {
      "epoch": 232.16,
      "learning_rate": 0.07679324901322582,
      "loss": 0.9171,
      "step": 143940
    },
    {
      "epoch": 232.19,
      "learning_rate": 0.07679002321,
      "loss": 0.9103,
      "step": 143960
    },
    {
      "epoch": 232.23,
      "learning_rate": 0.0767867974067742,
      "loss": 0.9111,
      "step": 143980
    },
    {
      "epoch": 232.26,
      "learning_rate": 0.0767835716035484,
      "loss": 0.9127,
      "step": 144000
    },
    {
      "epoch": 232.29,
      "learning_rate": 0.07678034580032259,
      "loss": 0.9288,
      "step": 144020
    },
    {
      "epoch": 232.32,
      "learning_rate": 0.07677711999709678,
      "loss": 0.9119,
      "step": 144040
    },
    {
      "epoch": 232.35,
      "learning_rate": 0.07677389419387097,
      "loss": 0.9048,
      "step": 144060
    },
    {
      "epoch": 232.39,
      "learning_rate": 0.07677066839064516,
      "loss": 0.9041,
      "step": 144080
    },
    {
      "epoch": 232.42,
      "learning_rate": 0.07676744258741935,
      "loss": 0.8942,
      "step": 144100
    },
    {
      "epoch": 232.45,
      "learning_rate": 0.07676421678419355,
      "loss": 0.8978,
      "step": 144120
    },
    {
      "epoch": 232.48,
      "learning_rate": 0.07676099098096774,
      "loss": 0.9313,
      "step": 144140
    },
    {
      "epoch": 232.52,
      "learning_rate": 0.07675776517774194,
      "loss": 0.9146,
      "step": 144160
    },
    {
      "epoch": 232.55,
      "learning_rate": 0.07675453937451614,
      "loss": 0.9182,
      "step": 144180
    },
    {
      "epoch": 232.58,
      "learning_rate": 0.07675131357129032,
      "loss": 0.9293,
      "step": 144200
    },
    {
      "epoch": 232.61,
      "learning_rate": 0.07674808776806452,
      "loss": 0.9077,
      "step": 144220
    },
    {
      "epoch": 232.65,
      "learning_rate": 0.07674486196483872,
      "loss": 0.9249,
      "step": 144240
    },
    {
      "epoch": 232.68,
      "learning_rate": 0.0767416361616129,
      "loss": 0.9374,
      "step": 144260
    },
    {
      "epoch": 232.71,
      "learning_rate": 0.0767384103583871,
      "loss": 0.9131,
      "step": 144280
    },
    {
      "epoch": 232.74,
      "learning_rate": 0.0767351845551613,
      "loss": 0.92,
      "step": 144300
    },
    {
      "epoch": 232.77,
      "learning_rate": 0.07673195875193549,
      "loss": 0.9074,
      "step": 144320
    },
    {
      "epoch": 232.81,
      "learning_rate": 0.07672873294870969,
      "loss": 0.9185,
      "step": 144340
    },
    {
      "epoch": 232.84,
      "learning_rate": 0.07672550714548387,
      "loss": 0.9394,
      "step": 144360
    },
    {
      "epoch": 232.87,
      "learning_rate": 0.07672228134225807,
      "loss": 0.932,
      "step": 144380
    },
    {
      "epoch": 232.9,
      "learning_rate": 0.07671905553903226,
      "loss": 0.913,
      "step": 144400
    },
    {
      "epoch": 232.94,
      "learning_rate": 0.07671582973580646,
      "loss": 0.9298,
      "step": 144420
    },
    {
      "epoch": 232.97,
      "learning_rate": 0.07671260393258064,
      "loss": 0.9004,
      "step": 144440
    },
    {
      "epoch": 233.0,
      "learning_rate": 0.07670937812935484,
      "loss": 0.9152,
      "step": 144460
    },
    {
      "epoch": 233.0,
      "eval_accuracy": {
        "accuracy": 0.7472484583561002
      },
      "eval_loss": 1.282846212387085,
      "eval_runtime": 3.1832,
      "eval_samples_per_second": 4024.596,
      "eval_steps_per_second": 63.144,
      "step": 144460
    },
    {
      "epoch": 233.03,
      "learning_rate": 0.07670615232612904,
      "loss": 0.9835,
      "step": 144480
    },
    {
      "epoch": 233.06,
      "learning_rate": 0.07670292652290323,
      "loss": 0.9246,
      "step": 144500
    },
    {
      "epoch": 233.1,
      "learning_rate": 0.07669970071967742,
      "loss": 0.8833,
      "step": 144520
    },
    {
      "epoch": 233.13,
      "learning_rate": 0.07669647491645162,
      "loss": 0.9116,
      "step": 144540
    },
    {
      "epoch": 233.16,
      "learning_rate": 0.07669324911322581,
      "loss": 0.8809,
      "step": 144560
    },
    {
      "epoch": 233.19,
      "learning_rate": 0.07669002331000001,
      "loss": 0.9149,
      "step": 144580
    },
    {
      "epoch": 233.23,
      "learning_rate": 0.0766867975067742,
      "loss": 0.9293,
      "step": 144600
    },
    {
      "epoch": 233.26,
      "learning_rate": 0.07668357170354839,
      "loss": 0.9194,
      "step": 144620
    },
    {
      "epoch": 233.29,
      "learning_rate": 0.07668034590032259,
      "loss": 0.9084,
      "step": 144640
    },
    {
      "epoch": 233.32,
      "learning_rate": 0.07667712009709678,
      "loss": 0.9277,
      "step": 144660
    },
    {
      "epoch": 233.35,
      "learning_rate": 0.07667389429387098,
      "loss": 0.9407,
      "step": 144680
    },
    {
      "epoch": 233.39,
      "learning_rate": 0.07667066849064516,
      "loss": 0.9113,
      "step": 144700
    },
    {
      "epoch": 233.42,
      "learning_rate": 0.07666744268741936,
      "loss": 0.9226,
      "step": 144720
    },
    {
      "epoch": 233.45,
      "learning_rate": 0.07666421688419355,
      "loss": 0.9121,
      "step": 144740
    },
    {
      "epoch": 233.48,
      "learning_rate": 0.07666099108096774,
      "loss": 0.9416,
      "step": 144760
    },
    {
      "epoch": 233.52,
      "learning_rate": 0.07665776527774194,
      "loss": 0.9315,
      "step": 144780
    },
    {
      "epoch": 233.55,
      "learning_rate": 0.07665453947451613,
      "loss": 0.8928,
      "step": 144800
    },
    {
      "epoch": 233.58,
      "learning_rate": 0.07665131367129033,
      "loss": 0.8883,
      "step": 144820
    },
    {
      "epoch": 233.61,
      "learning_rate": 0.07664808786806453,
      "loss": 0.9465,
      "step": 144840
    },
    {
      "epoch": 233.65,
      "learning_rate": 0.07664486206483871,
      "loss": 0.9256,
      "step": 144860
    },
    {
      "epoch": 233.68,
      "learning_rate": 0.07664163626161291,
      "loss": 0.919,
      "step": 144880
    },
    {
      "epoch": 233.71,
      "learning_rate": 0.07663841045838711,
      "loss": 0.9168,
      "step": 144900
    },
    {
      "epoch": 233.74,
      "learning_rate": 0.0766351846551613,
      "loss": 0.9252,
      "step": 144920
    },
    {
      "epoch": 233.77,
      "learning_rate": 0.0766319588519355,
      "loss": 0.9093,
      "step": 144940
    },
    {
      "epoch": 233.81,
      "learning_rate": 0.07662873304870968,
      "loss": 0.9201,
      "step": 144960
    },
    {
      "epoch": 233.84,
      "learning_rate": 0.07662550724548388,
      "loss": 0.9052,
      "step": 144980
    },
    {
      "epoch": 233.87,
      "learning_rate": 0.07662228144225806,
      "loss": 0.9245,
      "step": 145000
    },
    {
      "epoch": 233.9,
      "learning_rate": 0.07661905563903226,
      "loss": 0.8889,
      "step": 145020
    },
    {
      "epoch": 233.94,
      "learning_rate": 0.07661582983580645,
      "loss": 0.9228,
      "step": 145040
    },
    {
      "epoch": 233.97,
      "learning_rate": 0.07661260403258065,
      "loss": 0.9134,
      "step": 145060
    },
    {
      "epoch": 234.0,
      "learning_rate": 0.07660937822935485,
      "loss": 0.9205,
      "step": 145080
    },
    {
      "epoch": 234.0,
      "eval_accuracy": {
        "accuracy": 0.742174693622668
      },
      "eval_loss": 1.3125700950622559,
      "eval_runtime": 2.7178,
      "eval_samples_per_second": 4713.743,
      "eval_steps_per_second": 73.957,
      "step": 145080
    },
    {
      "epoch": 234.03,
      "learning_rate": 0.07660615242612903,
      "loss": 0.9304,
      "step": 145100
    },
    {
      "epoch": 234.06,
      "learning_rate": 0.07660292662290323,
      "loss": 0.8932,
      "step": 145120
    },
    {
      "epoch": 234.1,
      "learning_rate": 0.07659970081967743,
      "loss": 0.9145,
      "step": 145140
    },
    {
      "epoch": 234.13,
      "learning_rate": 0.07659647501645162,
      "loss": 0.9226,
      "step": 145160
    },
    {
      "epoch": 234.16,
      "learning_rate": 0.07659324921322581,
      "loss": 0.9171,
      "step": 145180
    },
    {
      "epoch": 234.19,
      "learning_rate": 0.07659002341000001,
      "loss": 0.9333,
      "step": 145200
    },
    {
      "epoch": 234.23,
      "learning_rate": 0.0765867976067742,
      "loss": 0.943,
      "step": 145220
    },
    {
      "epoch": 234.26,
      "learning_rate": 0.0765835718035484,
      "loss": 0.8918,
      "step": 145240
    },
    {
      "epoch": 234.29,
      "learning_rate": 0.07658034600032258,
      "loss": 0.9051,
      "step": 145260
    },
    {
      "epoch": 234.32,
      "learning_rate": 0.07657712019709678,
      "loss": 0.9247,
      "step": 145280
    },
    {
      "epoch": 234.35,
      "learning_rate": 0.07657389439387097,
      "loss": 0.9117,
      "step": 145300
    },
    {
      "epoch": 234.39,
      "learning_rate": 0.07657066859064517,
      "loss": 0.9082,
      "step": 145320
    },
    {
      "epoch": 234.42,
      "learning_rate": 0.07656744278741935,
      "loss": 0.898,
      "step": 145340
    },
    {
      "epoch": 234.45,
      "learning_rate": 0.07656421698419355,
      "loss": 0.9547,
      "step": 145360
    },
    {
      "epoch": 234.48,
      "learning_rate": 0.07656099118096775,
      "loss": 0.9369,
      "step": 145380
    },
    {
      "epoch": 234.52,
      "learning_rate": 0.07655776537774193,
      "loss": 0.9209,
      "step": 145400
    },
    {
      "epoch": 234.55,
      "learning_rate": 0.07655453957451613,
      "loss": 0.9075,
      "step": 145420
    },
    {
      "epoch": 234.58,
      "learning_rate": 0.07655131377129033,
      "loss": 0.9052,
      "step": 145440
    },
    {
      "epoch": 234.61,
      "learning_rate": 0.07654808796806452,
      "loss": 0.911,
      "step": 145460
    },
    {
      "epoch": 234.65,
      "learning_rate": 0.07654486216483872,
      "loss": 0.919,
      "step": 145480
    },
    {
      "epoch": 234.68,
      "learning_rate": 0.07654163636161292,
      "loss": 0.9359,
      "step": 145500
    },
    {
      "epoch": 234.71,
      "learning_rate": 0.0765384105583871,
      "loss": 0.9125,
      "step": 145520
    },
    {
      "epoch": 234.74,
      "learning_rate": 0.0765351847551613,
      "loss": 0.918,
      "step": 145540
    },
    {
      "epoch": 234.77,
      "learning_rate": 0.07653195895193549,
      "loss": 0.9171,
      "step": 145560
    },
    {
      "epoch": 234.81,
      "learning_rate": 0.07652873314870969,
      "loss": 0.9161,
      "step": 145580
    },
    {
      "epoch": 234.84,
      "learning_rate": 0.07652550734548387,
      "loss": 0.9124,
      "step": 145600
    },
    {
      "epoch": 234.87,
      "learning_rate": 0.07652228154225807,
      "loss": 0.9195,
      "step": 145620
    },
    {
      "epoch": 234.9,
      "learning_rate": 0.07651905573903225,
      "loss": 0.9382,
      "step": 145640
    },
    {
      "epoch": 234.94,
      "learning_rate": 0.07651582993580645,
      "loss": 0.9349,
      "step": 145660
    },
    {
      "epoch": 234.97,
      "learning_rate": 0.07651260413258065,
      "loss": 0.9455,
      "step": 145680
    },
    {
      "epoch": 235.0,
      "learning_rate": 0.07650953961951612,
      "loss": 0.9314,
      "step": 145700
    },
    {
      "epoch": 235.0,
      "eval_accuracy": {
        "accuracy": 0.7477948637889313
      },
      "eval_loss": 1.2435449361801147,
      "eval_runtime": 2.8369,
      "eval_samples_per_second": 4515.861,
      "eval_steps_per_second": 70.852,
      "step": 145700
    },
    {
      "epoch": 235.03,
      "learning_rate": 0.07650631381629033,
      "loss": 0.893,
      "step": 145720
    },
    {
      "epoch": 235.06,
      "learning_rate": 0.07650308801306452,
      "loss": 0.8811,
      "step": 145740
    },
    {
      "epoch": 235.1,
      "learning_rate": 0.07649986220983872,
      "loss": 0.913,
      "step": 145760
    },
    {
      "epoch": 235.13,
      "learning_rate": 0.0764966364066129,
      "loss": 0.9152,
      "step": 145780
    },
    {
      "epoch": 235.16,
      "learning_rate": 0.0764934106033871,
      "loss": 0.8888,
      "step": 145800
    },
    {
      "epoch": 235.19,
      "learning_rate": 0.07649018480016129,
      "loss": 0.9049,
      "step": 145820
    },
    {
      "epoch": 235.23,
      "learning_rate": 0.07648695899693549,
      "loss": 0.9159,
      "step": 145840
    },
    {
      "epoch": 235.26,
      "learning_rate": 0.07648373319370969,
      "loss": 0.9066,
      "step": 145860
    },
    {
      "epoch": 235.29,
      "learning_rate": 0.07648050739048387,
      "loss": 0.9192,
      "step": 145880
    },
    {
      "epoch": 235.32,
      "learning_rate": 0.07647728158725807,
      "loss": 0.8997,
      "step": 145900
    },
    {
      "epoch": 235.35,
      "learning_rate": 0.07647405578403227,
      "loss": 0.9085,
      "step": 145920
    },
    {
      "epoch": 235.39,
      "learning_rate": 0.07647082998080645,
      "loss": 0.9363,
      "step": 145940
    },
    {
      "epoch": 235.42,
      "learning_rate": 0.07646760417758065,
      "loss": 0.9393,
      "step": 145960
    },
    {
      "epoch": 235.45,
      "learning_rate": 0.07646437837435485,
      "loss": 0.9422,
      "step": 145980
    },
    {
      "epoch": 235.48,
      "learning_rate": 0.07646115257112904,
      "loss": 0.9102,
      "step": 146000
    },
    {
      "epoch": 235.52,
      "learning_rate": 0.07645792676790324,
      "loss": 0.9111,
      "step": 146020
    },
    {
      "epoch": 235.55,
      "learning_rate": 0.07645470096467742,
      "loss": 0.8998,
      "step": 146040
    },
    {
      "epoch": 235.58,
      "learning_rate": 0.07645147516145162,
      "loss": 0.9279,
      "step": 146060
    },
    {
      "epoch": 235.61,
      "learning_rate": 0.0764482493582258,
      "loss": 0.9162,
      "step": 146080
    },
    {
      "epoch": 235.65,
      "learning_rate": 0.076445023555,
      "loss": 0.932,
      "step": 146100
    },
    {
      "epoch": 235.68,
      "learning_rate": 0.07644179775177419,
      "loss": 0.9027,
      "step": 146120
    },
    {
      "epoch": 235.71,
      "learning_rate": 0.07643857194854839,
      "loss": 0.902,
      "step": 146140
    },
    {
      "epoch": 235.74,
      "learning_rate": 0.07643534614532259,
      "loss": 0.9187,
      "step": 146160
    },
    {
      "epoch": 235.77,
      "learning_rate": 0.07643212034209677,
      "loss": 0.9162,
      "step": 146180
    },
    {
      "epoch": 235.81,
      "learning_rate": 0.07642889453887097,
      "loss": 0.9111,
      "step": 146200
    },
    {
      "epoch": 235.84,
      "learning_rate": 0.07642566873564517,
      "loss": 0.9213,
      "step": 146220
    },
    {
      "epoch": 235.87,
      "learning_rate": 0.07642244293241936,
      "loss": 0.9364,
      "step": 146240
    },
    {
      "epoch": 235.9,
      "learning_rate": 0.07641921712919356,
      "loss": 0.9325,
      "step": 146260
    },
    {
      "epoch": 235.94,
      "learning_rate": 0.07641599132596776,
      "loss": 0.9481,
      "step": 146280
    },
    {
      "epoch": 235.97,
      "learning_rate": 0.07641276552274194,
      "loss": 0.9201,
      "step": 146300
    },
    {
      "epoch": 236.0,
      "learning_rate": 0.07640953971951614,
      "loss": 0.9377,
      "step": 146320
    },
    {
      "epoch": 236.0,
      "eval_accuracy": {
        "accuracy": 0.7405354773241746
      },
      "eval_loss": 1.3217800855636597,
      "eval_runtime": 2.823,
      "eval_samples_per_second": 4538.07,
      "eval_steps_per_second": 71.201,
      "step": 146320
    },
    {
      "epoch": 236.03,
      "learning_rate": 0.07640631391629032,
      "loss": 0.9361,
      "step": 146340
    },
    {
      "epoch": 236.06,
      "learning_rate": 0.07640308811306452,
      "loss": 0.9199,
      "step": 146360
    },
    {
      "epoch": 236.1,
      "learning_rate": 0.07639986230983871,
      "loss": 0.9445,
      "step": 146380
    },
    {
      "epoch": 236.13,
      "learning_rate": 0.07639663650661291,
      "loss": 0.921,
      "step": 146400
    },
    {
      "epoch": 236.16,
      "learning_rate": 0.0763934107033871,
      "loss": 0.8873,
      "step": 146420
    },
    {
      "epoch": 236.19,
      "learning_rate": 0.07639018490016129,
      "loss": 0.8716,
      "step": 146440
    },
    {
      "epoch": 236.23,
      "learning_rate": 0.07638695909693549,
      "loss": 0.9309,
      "step": 146460
    },
    {
      "epoch": 236.26,
      "learning_rate": 0.07638373329370968,
      "loss": 0.9066,
      "step": 146480
    },
    {
      "epoch": 236.29,
      "learning_rate": 0.07638050749048388,
      "loss": 0.9074,
      "step": 146500
    },
    {
      "epoch": 236.32,
      "learning_rate": 0.07637728168725808,
      "loss": 0.8948,
      "step": 146520
    },
    {
      "epoch": 236.35,
      "learning_rate": 0.07637405588403226,
      "loss": 0.9154,
      "step": 146540
    },
    {
      "epoch": 236.39,
      "learning_rate": 0.07637083008080646,
      "loss": 0.9054,
      "step": 146560
    },
    {
      "epoch": 236.42,
      "learning_rate": 0.07636760427758066,
      "loss": 0.9525,
      "step": 146580
    },
    {
      "epoch": 236.45,
      "learning_rate": 0.07636437847435484,
      "loss": 0.9394,
      "step": 146600
    },
    {
      "epoch": 236.48,
      "learning_rate": 0.07636115267112904,
      "loss": 0.9255,
      "step": 146620
    },
    {
      "epoch": 236.52,
      "learning_rate": 0.07635792686790323,
      "loss": 0.9295,
      "step": 146640
    },
    {
      "epoch": 236.55,
      "learning_rate": 0.07635470106467743,
      "loss": 0.9094,
      "step": 146660
    },
    {
      "epoch": 236.58,
      "learning_rate": 0.07635147526145161,
      "loss": 0.9331,
      "step": 146680
    },
    {
      "epoch": 236.61,
      "learning_rate": 0.07634824945822581,
      "loss": 0.9122,
      "step": 146700
    },
    {
      "epoch": 236.65,
      "learning_rate": 0.076345023655,
      "loss": 0.8927,
      "step": 146720
    },
    {
      "epoch": 236.68,
      "learning_rate": 0.0763417978517742,
      "loss": 0.9,
      "step": 146740
    },
    {
      "epoch": 236.71,
      "learning_rate": 0.0763385720485484,
      "loss": 0.9321,
      "step": 146760
    },
    {
      "epoch": 236.74,
      "learning_rate": 0.07633534624532258,
      "loss": 0.9132,
      "step": 146780
    },
    {
      "epoch": 236.77,
      "learning_rate": 0.07633212044209678,
      "loss": 0.9339,
      "step": 146800
    },
    {
      "epoch": 236.81,
      "learning_rate": 0.07632889463887098,
      "loss": 0.9277,
      "step": 146820
    },
    {
      "epoch": 236.84,
      "learning_rate": 0.07632566883564516,
      "loss": 0.915,
      "step": 146840
    },
    {
      "epoch": 236.87,
      "learning_rate": 0.07632244303241936,
      "loss": 0.9226,
      "step": 146860
    },
    {
      "epoch": 236.9,
      "learning_rate": 0.07631921722919356,
      "loss": 0.9299,
      "step": 146880
    },
    {
      "epoch": 236.94,
      "learning_rate": 0.07631599142596775,
      "loss": 0.931,
      "step": 146900
    },
    {
      "epoch": 236.97,
      "learning_rate": 0.07631276562274195,
      "loss": 0.9099,
      "step": 146920
    },
    {
      "epoch": 237.0,
      "learning_rate": 0.07630953981951613,
      "loss": 0.9289,
      "step": 146940
    },
    {
      "epoch": 237.0,
      "eval_accuracy": {
        "accuracy": 0.7407696510811022
      },
      "eval_loss": 1.3102742433547974,
      "eval_runtime": 2.6626,
      "eval_samples_per_second": 4811.408,
      "eval_steps_per_second": 75.489,
      "step": 146940
    },
    {
      "epoch": 237.03,
      "learning_rate": 0.07630631401629033,
      "loss": 0.9786,
      "step": 146960
    },
    {
      "epoch": 237.06,
      "learning_rate": 0.07630308821306452,
      "loss": 0.9144,
      "step": 146980
    },
    {
      "epoch": 237.1,
      "learning_rate": 0.07629986240983871,
      "loss": 0.9253,
      "step": 147000
    },
    {
      "epoch": 237.13,
      "learning_rate": 0.0762966366066129,
      "loss": 0.901,
      "step": 147020
    },
    {
      "epoch": 237.16,
      "learning_rate": 0.0762934108033871,
      "loss": 0.9047,
      "step": 147040
    },
    {
      "epoch": 237.19,
      "learning_rate": 0.0762901850001613,
      "loss": 0.9328,
      "step": 147060
    },
    {
      "epoch": 237.23,
      "learning_rate": 0.07628695919693548,
      "loss": 0.8928,
      "step": 147080
    },
    {
      "epoch": 237.26,
      "learning_rate": 0.07628373339370968,
      "loss": 0.8909,
      "step": 147100
    },
    {
      "epoch": 237.29,
      "learning_rate": 0.07628050759048388,
      "loss": 0.8927,
      "step": 147120
    },
    {
      "epoch": 237.32,
      "learning_rate": 0.07627728178725807,
      "loss": 0.8946,
      "step": 147140
    },
    {
      "epoch": 237.35,
      "learning_rate": 0.07627405598403227,
      "loss": 0.9028,
      "step": 147160
    },
    {
      "epoch": 237.39,
      "learning_rate": 0.07627083018080646,
      "loss": 0.9386,
      "step": 147180
    },
    {
      "epoch": 237.42,
      "learning_rate": 0.07626760437758065,
      "loss": 0.9081,
      "step": 147200
    },
    {
      "epoch": 237.45,
      "learning_rate": 0.07626437857435485,
      "loss": 0.9212,
      "step": 147220
    },
    {
      "epoch": 237.48,
      "learning_rate": 0.07626115277112903,
      "loss": 0.9132,
      "step": 147240
    },
    {
      "epoch": 237.52,
      "learning_rate": 0.07625792696790323,
      "loss": 0.9041,
      "step": 147260
    },
    {
      "epoch": 237.55,
      "learning_rate": 0.07625470116467742,
      "loss": 0.9238,
      "step": 147280
    },
    {
      "epoch": 237.58,
      "learning_rate": 0.07625147536145162,
      "loss": 0.9395,
      "step": 147300
    },
    {
      "epoch": 237.61,
      "learning_rate": 0.0762482495582258,
      "loss": 0.9227,
      "step": 147320
    },
    {
      "epoch": 237.65,
      "learning_rate": 0.076245023755,
      "loss": 0.9365,
      "step": 147340
    },
    {
      "epoch": 237.68,
      "learning_rate": 0.0762417979517742,
      "loss": 0.9315,
      "step": 147360
    },
    {
      "epoch": 237.71,
      "learning_rate": 0.07623857214854839,
      "loss": 0.9358,
      "step": 147380
    },
    {
      "epoch": 237.74,
      "learning_rate": 0.07623534634532259,
      "loss": 0.9165,
      "step": 147400
    },
    {
      "epoch": 237.77,
      "learning_rate": 0.07623212054209678,
      "loss": 0.9468,
      "step": 147420
    },
    {
      "epoch": 237.81,
      "learning_rate": 0.07622889473887097,
      "loss": 0.9544,
      "step": 147440
    },
    {
      "epoch": 237.84,
      "learning_rate": 0.07622566893564517,
      "loss": 0.9334,
      "step": 147460
    },
    {
      "epoch": 237.87,
      "learning_rate": 0.07622244313241935,
      "loss": 0.9177,
      "step": 147480
    },
    {
      "epoch": 237.9,
      "learning_rate": 0.07621921732919355,
      "loss": 0.9483,
      "step": 147500
    },
    {
      "epoch": 237.94,
      "learning_rate": 0.07621599152596775,
      "loss": 0.9191,
      "step": 147520
    },
    {
      "epoch": 237.97,
      "learning_rate": 0.07621276572274194,
      "loss": 0.9217,
      "step": 147540
    },
    {
      "epoch": 238.0,
      "learning_rate": 0.07620953991951614,
      "loss": 0.9584,
      "step": 147560
    },
    {
      "epoch": 238.0,
      "eval_accuracy": {
        "accuracy": 0.7349933650768871
      },
      "eval_loss": 1.3405818939208984,
      "eval_runtime": 2.8983,
      "eval_samples_per_second": 4420.196,
      "eval_steps_per_second": 69.351,
      "step": 147560
    },
    {
      "epoch": 238.03,
      "learning_rate": 0.07620631411629032,
      "loss": 0.9586,
      "step": 147580
    },
    {
      "epoch": 238.06,
      "learning_rate": 0.07620308831306452,
      "loss": 0.9099,
      "step": 147600
    },
    {
      "epoch": 238.1,
      "learning_rate": 0.0761998625098387,
      "loss": 0.8864,
      "step": 147620
    },
    {
      "epoch": 238.13,
      "learning_rate": 0.07619663670661292,
      "loss": 0.8691,
      "step": 147640
    },
    {
      "epoch": 238.16,
      "learning_rate": 0.0761934109033871,
      "loss": 0.9047,
      "step": 147660
    },
    {
      "epoch": 238.19,
      "learning_rate": 0.07619018510016129,
      "loss": 0.8888,
      "step": 147680
    },
    {
      "epoch": 238.23,
      "learning_rate": 0.07618695929693549,
      "loss": 0.8947,
      "step": 147700
    },
    {
      "epoch": 238.26,
      "learning_rate": 0.07618373349370969,
      "loss": 0.9032,
      "step": 147720
    },
    {
      "epoch": 238.29,
      "learning_rate": 0.07618050769048387,
      "loss": 0.9207,
      "step": 147740
    },
    {
      "epoch": 238.32,
      "learning_rate": 0.07617728188725807,
      "loss": 0.9472,
      "step": 147760
    },
    {
      "epoch": 238.35,
      "learning_rate": 0.07617405608403226,
      "loss": 0.9008,
      "step": 147780
    },
    {
      "epoch": 238.39,
      "learning_rate": 0.07617083028080646,
      "loss": 0.9056,
      "step": 147800
    },
    {
      "epoch": 238.42,
      "learning_rate": 0.07616760447758066,
      "loss": 0.9263,
      "step": 147820
    },
    {
      "epoch": 238.45,
      "learning_rate": 0.07616437867435484,
      "loss": 0.9421,
      "step": 147840
    },
    {
      "epoch": 238.48,
      "learning_rate": 0.07616115287112904,
      "loss": 0.9049,
      "step": 147860
    },
    {
      "epoch": 238.52,
      "learning_rate": 0.07615792706790322,
      "loss": 0.9115,
      "step": 147880
    },
    {
      "epoch": 238.55,
      "learning_rate": 0.07615470126467742,
      "loss": 0.9373,
      "step": 147900
    },
    {
      "epoch": 238.58,
      "learning_rate": 0.07615147546145161,
      "loss": 0.9105,
      "step": 147920
    },
    {
      "epoch": 238.61,
      "learning_rate": 0.07614824965822582,
      "loss": 0.9034,
      "step": 147940
    },
    {
      "epoch": 238.65,
      "learning_rate": 0.07614502385500001,
      "loss": 0.9107,
      "step": 147960
    },
    {
      "epoch": 238.68,
      "learning_rate": 0.07614179805177419,
      "loss": 0.921,
      "step": 147980
    },
    {
      "epoch": 238.71,
      "learning_rate": 0.07613857224854839,
      "loss": 0.924,
      "step": 148000
    },
    {
      "epoch": 238.74,
      "learning_rate": 0.07613534644532258,
      "loss": 0.9164,
      "step": 148020
    },
    {
      "epoch": 238.77,
      "learning_rate": 0.07613212064209678,
      "loss": 0.9064,
      "step": 148040
    },
    {
      "epoch": 238.81,
      "learning_rate": 0.07612889483887098,
      "loss": 0.9297,
      "step": 148060
    },
    {
      "epoch": 238.84,
      "learning_rate": 0.07612566903564516,
      "loss": 0.9142,
      "step": 148080
    },
    {
      "epoch": 238.87,
      "learning_rate": 0.07612244323241936,
      "loss": 0.9055,
      "step": 148100
    },
    {
      "epoch": 238.9,
      "learning_rate": 0.07611937871935484,
      "loss": 0.9212,
      "step": 148120
    },
    {
      "epoch": 238.94,
      "learning_rate": 0.07611615291612904,
      "loss": 0.9001,
      "step": 148140
    },
    {
      "epoch": 238.97,
      "learning_rate": 0.07611292711290323,
      "loss": 0.9011,
      "step": 148160
    },
    {
      "epoch": 239.0,
      "learning_rate": 0.07610970130967742,
      "loss": 0.926,
      "step": 148180
    },
    {
      "epoch": 239.0,
      "eval_accuracy": {
        "accuracy": 0.740925766919054
      },
      "eval_loss": 1.3191099166870117,
      "eval_runtime": 4.0648,
      "eval_samples_per_second": 3151.659,
      "eval_steps_per_second": 49.448,
      "step": 148180
    },
    {
      "epoch": 239.03,
      "learning_rate": 0.07610647550645162,
      "loss": 0.9455,
      "step": 148200
    },
    {
      "epoch": 239.06,
      "learning_rate": 0.07610324970322581,
      "loss": 0.879,
      "step": 148220
    },
    {
      "epoch": 239.1,
      "learning_rate": 0.07610002390000001,
      "loss": 0.8923,
      "step": 148240
    },
    {
      "epoch": 239.13,
      "learning_rate": 0.0760967980967742,
      "loss": 0.8842,
      "step": 148260
    },
    {
      "epoch": 239.16,
      "learning_rate": 0.07609357229354839,
      "loss": 0.8954,
      "step": 148280
    },
    {
      "epoch": 239.19,
      "learning_rate": 0.07609034649032259,
      "loss": 0.8932,
      "step": 148300
    },
    {
      "epoch": 239.23,
      "learning_rate": 0.07608712068709678,
      "loss": 0.9014,
      "step": 148320
    },
    {
      "epoch": 239.26,
      "learning_rate": 0.07608389488387098,
      "loss": 0.9031,
      "step": 148340
    },
    {
      "epoch": 239.29,
      "learning_rate": 0.07608066908064516,
      "loss": 0.9265,
      "step": 148360
    },
    {
      "epoch": 239.32,
      "learning_rate": 0.07607744327741936,
      "loss": 0.9167,
      "step": 148380
    },
    {
      "epoch": 239.35,
      "learning_rate": 0.07607421747419355,
      "loss": 0.8837,
      "step": 148400
    },
    {
      "epoch": 239.39,
      "learning_rate": 0.07607099167096774,
      "loss": 0.9022,
      "step": 148420
    },
    {
      "epoch": 239.42,
      "learning_rate": 0.07606776586774194,
      "loss": 0.9112,
      "step": 148440
    },
    {
      "epoch": 239.45,
      "learning_rate": 0.07606454006451613,
      "loss": 0.9207,
      "step": 148460
    },
    {
      "epoch": 239.48,
      "learning_rate": 0.07606131426129033,
      "loss": 0.9422,
      "step": 148480
    },
    {
      "epoch": 239.52,
      "learning_rate": 0.07605808845806453,
      "loss": 0.9231,
      "step": 148500
    },
    {
      "epoch": 239.55,
      "learning_rate": 0.07605486265483871,
      "loss": 0.9049,
      "step": 148520
    },
    {
      "epoch": 239.58,
      "learning_rate": 0.07605163685161291,
      "loss": 0.8995,
      "step": 148540
    },
    {
      "epoch": 239.61,
      "learning_rate": 0.0760484110483871,
      "loss": 0.8991,
      "step": 148560
    },
    {
      "epoch": 239.65,
      "learning_rate": 0.0760451852451613,
      "loss": 0.9139,
      "step": 148580
    },
    {
      "epoch": 239.68,
      "learning_rate": 0.0760419594419355,
      "loss": 0.9108,
      "step": 148600
    },
    {
      "epoch": 239.71,
      "learning_rate": 0.07603873363870968,
      "loss": 0.9019,
      "step": 148620
    },
    {
      "epoch": 239.74,
      "learning_rate": 0.07603550783548388,
      "loss": 0.9403,
      "step": 148640
    },
    {
      "epoch": 239.77,
      "learning_rate": 0.07603228203225806,
      "loss": 0.9228,
      "step": 148660
    },
    {
      "epoch": 239.81,
      "learning_rate": 0.07602905622903226,
      "loss": 0.9082,
      "step": 148680
    },
    {
      "epoch": 239.84,
      "learning_rate": 0.07602583042580645,
      "loss": 0.9394,
      "step": 148700
    },
    {
      "epoch": 239.87,
      "learning_rate": 0.07602260462258065,
      "loss": 0.9529,
      "step": 148720
    },
    {
      "epoch": 239.9,
      "learning_rate": 0.07601937881935485,
      "loss": 0.9604,
      "step": 148740
    },
    {
      "epoch": 239.94,
      "learning_rate": 0.07601615301612903,
      "loss": 0.9471,
      "step": 148760
    },
    {
      "epoch": 239.97,
      "learning_rate": 0.07601292721290323,
      "loss": 0.8953,
      "step": 148780
    },
    {
      "epoch": 240.0,
      "learning_rate": 0.07600970140967743,
      "loss": 0.9361,
      "step": 148800
    },
    {
      "epoch": 240.0,
      "eval_accuracy": {
        "accuracy": 0.7406915931621263
      },
      "eval_loss": 1.3159235715866089,
      "eval_runtime": 2.9413,
      "eval_samples_per_second": 4355.503,
      "eval_steps_per_second": 68.336,
      "step": 148800
    },
    {
      "epoch": 240.03,
      "learning_rate": 0.07600647560645162,
      "loss": 0.9559,
      "step": 148820
    },
    {
      "epoch": 240.06,
      "learning_rate": 0.07600324980322581,
      "loss": 0.9017,
      "step": 148840
    },
    {
      "epoch": 240.1,
      "learning_rate": 0.076000024,
      "loss": 0.8953,
      "step": 148860
    },
    {
      "epoch": 240.13,
      "learning_rate": 0.0759967981967742,
      "loss": 0.8989,
      "step": 148880
    },
    {
      "epoch": 240.16,
      "learning_rate": 0.0759935723935484,
      "loss": 0.9126,
      "step": 148900
    },
    {
      "epoch": 240.19,
      "learning_rate": 0.07599034659032258,
      "loss": 0.9156,
      "step": 148920
    },
    {
      "epoch": 240.23,
      "learning_rate": 0.07598712078709678,
      "loss": 0.8972,
      "step": 148940
    },
    {
      "epoch": 240.26,
      "learning_rate": 0.07598389498387097,
      "loss": 0.9471,
      "step": 148960
    },
    {
      "epoch": 240.29,
      "learning_rate": 0.07598066918064517,
      "loss": 0.918,
      "step": 148980
    },
    {
      "epoch": 240.32,
      "learning_rate": 0.07597744337741935,
      "loss": 0.8931,
      "step": 149000
    },
    {
      "epoch": 240.35,
      "learning_rate": 0.07597421757419356,
      "loss": 0.8851,
      "step": 149020
    },
    {
      "epoch": 240.39,
      "learning_rate": 0.07597099177096775,
      "loss": 0.8636,
      "step": 149040
    },
    {
      "epoch": 240.42,
      "learning_rate": 0.07596776596774193,
      "loss": 0.9116,
      "step": 149060
    },
    {
      "epoch": 240.45,
      "learning_rate": 0.07596454016451613,
      "loss": 0.9304,
      "step": 149080
    },
    {
      "epoch": 240.48,
      "learning_rate": 0.07596131436129032,
      "loss": 0.9202,
      "step": 149100
    },
    {
      "epoch": 240.52,
      "learning_rate": 0.07595808855806452,
      "loss": 0.9451,
      "step": 149120
    },
    {
      "epoch": 240.55,
      "learning_rate": 0.07595486275483872,
      "loss": 0.9575,
      "step": 149140
    },
    {
      "epoch": 240.58,
      "learning_rate": 0.0759516369516129,
      "loss": 0.9317,
      "step": 149160
    },
    {
      "epoch": 240.61,
      "learning_rate": 0.0759484111483871,
      "loss": 0.9359,
      "step": 149180
    },
    {
      "epoch": 240.65,
      "learning_rate": 0.0759451853451613,
      "loss": 0.9411,
      "step": 149200
    },
    {
      "epoch": 240.68,
      "learning_rate": 0.07594195954193549,
      "loss": 0.9453,
      "step": 149220
    },
    {
      "epoch": 240.71,
      "learning_rate": 0.07593873373870969,
      "loss": 0.9208,
      "step": 149240
    },
    {
      "epoch": 240.74,
      "learning_rate": 0.07593550793548388,
      "loss": 0.9051,
      "step": 149260
    },
    {
      "epoch": 240.77,
      "learning_rate": 0.07593228213225807,
      "loss": 0.918,
      "step": 149280
    },
    {
      "epoch": 240.81,
      "learning_rate": 0.07592905632903225,
      "loss": 0.9067,
      "step": 149300
    },
    {
      "epoch": 240.84,
      "learning_rate": 0.07592583052580647,
      "loss": 0.9115,
      "step": 149320
    },
    {
      "epoch": 240.87,
      "learning_rate": 0.07592260472258065,
      "loss": 0.9411,
      "step": 149340
    },
    {
      "epoch": 240.9,
      "learning_rate": 0.07591937891935484,
      "loss": 0.9266,
      "step": 149360
    },
    {
      "epoch": 240.94,
      "learning_rate": 0.07591615311612904,
      "loss": 0.8872,
      "step": 149380
    },
    {
      "epoch": 240.97,
      "learning_rate": 0.07591292731290322,
      "loss": 0.921,
      "step": 149400
    },
    {
      "epoch": 241.0,
      "learning_rate": 0.07590970150967742,
      "loss": 0.9248,
      "step": 149420
    },
    {
      "epoch": 241.0,
      "eval_accuracy": {
        "accuracy": 0.7410818827570057
      },
      "eval_loss": 1.2819480895996094,
      "eval_runtime": 2.7656,
      "eval_samples_per_second": 4632.242,
      "eval_steps_per_second": 72.678,
      "step": 149420
    },
    {
      "epoch": 241.03,
      "learning_rate": 0.07590647570645162,
      "loss": 0.9582,
      "step": 149440
    },
    {
      "epoch": 241.06,
      "learning_rate": 0.0759032499032258,
      "loss": 0.9122,
      "step": 149460
    },
    {
      "epoch": 241.1,
      "learning_rate": 0.0759000241,
      "loss": 0.9202,
      "step": 149480
    },
    {
      "epoch": 241.13,
      "learning_rate": 0.0758967982967742,
      "loss": 0.8935,
      "step": 149500
    },
    {
      "epoch": 241.16,
      "learning_rate": 0.07589357249354839,
      "loss": 0.8897,
      "step": 149520
    },
    {
      "epoch": 241.19,
      "learning_rate": 0.07589034669032259,
      "loss": 0.9063,
      "step": 149540
    },
    {
      "epoch": 241.23,
      "learning_rate": 0.07588712088709679,
      "loss": 0.8814,
      "step": 149560
    },
    {
      "epoch": 241.26,
      "learning_rate": 0.07588389508387097,
      "loss": 0.9164,
      "step": 149580
    },
    {
      "epoch": 241.29,
      "learning_rate": 0.07588066928064516,
      "loss": 0.9366,
      "step": 149600
    },
    {
      "epoch": 241.32,
      "learning_rate": 0.07587744347741937,
      "loss": 0.9111,
      "step": 149620
    },
    {
      "epoch": 241.35,
      "learning_rate": 0.07587421767419354,
      "loss": 0.8945,
      "step": 149640
    },
    {
      "epoch": 241.39,
      "learning_rate": 0.07587099187096774,
      "loss": 0.896,
      "step": 149660
    },
    {
      "epoch": 241.42,
      "learning_rate": 0.07586776606774194,
      "loss": 0.9406,
      "step": 149680
    },
    {
      "epoch": 241.45,
      "learning_rate": 0.07586454026451613,
      "loss": 0.9347,
      "step": 149700
    },
    {
      "epoch": 241.48,
      "learning_rate": 0.07586131446129032,
      "loss": 0.9231,
      "step": 149720
    },
    {
      "epoch": 241.52,
      "learning_rate": 0.07585808865806452,
      "loss": 0.9208,
      "step": 149740
    },
    {
      "epoch": 241.55,
      "learning_rate": 0.07585486285483871,
      "loss": 0.9203,
      "step": 149760
    },
    {
      "epoch": 241.58,
      "learning_rate": 0.07585163705161291,
      "loss": 0.929,
      "step": 149780
    },
    {
      "epoch": 241.61,
      "learning_rate": 0.07584841124838711,
      "loss": 0.9235,
      "step": 149800
    },
    {
      "epoch": 241.65,
      "learning_rate": 0.07584518544516129,
      "loss": 0.9035,
      "step": 149820
    },
    {
      "epoch": 241.68,
      "learning_rate": 0.07584195964193549,
      "loss": 0.8954,
      "step": 149840
    },
    {
      "epoch": 241.71,
      "learning_rate": 0.07583873383870969,
      "loss": 0.9359,
      "step": 149860
    },
    {
      "epoch": 241.74,
      "learning_rate": 0.07583550803548388,
      "loss": 0.9291,
      "step": 149880
    },
    {
      "epoch": 241.77,
      "learning_rate": 0.07583228223225806,
      "loss": 0.9347,
      "step": 149900
    },
    {
      "epoch": 241.81,
      "learning_rate": 0.07582905642903227,
      "loss": 0.9202,
      "step": 149920
    },
    {
      "epoch": 241.84,
      "learning_rate": 0.07582583062580645,
      "loss": 0.9234,
      "step": 149940
    },
    {
      "epoch": 241.87,
      "learning_rate": 0.07582260482258066,
      "loss": 0.9343,
      "step": 149960
    },
    {
      "epoch": 241.9,
      "learning_rate": 0.07581937901935484,
      "loss": 0.9057,
      "step": 149980
    },
    {
      "epoch": 241.94,
      "learning_rate": 0.07581615321612903,
      "loss": 0.9037,
      "step": 150000
    },
    {
      "epoch": 241.97,
      "learning_rate": 0.07581292741290323,
      "loss": 0.9295,
      "step": 150020
    },
    {
      "epoch": 242.0,
      "learning_rate": 0.07580970160967743,
      "loss": 0.9311,
      "step": 150040
    },
    {
      "epoch": 242.0,
      "eval_accuracy": {
        "accuracy": 0.7363984076184529
      },
      "eval_loss": 1.3342500925064087,
      "eval_runtime": 2.8162,
      "eval_samples_per_second": 4549.114,
      "eval_steps_per_second": 71.374,
      "step": 150040
    },
    {
      "epoch": 242.03,
      "learning_rate": 0.07580647580645161,
      "loss": 0.973,
      "step": 150060
    },
    {
      "epoch": 242.06,
      "learning_rate": 0.07580325000322581,
      "loss": 0.9036,
      "step": 150080
    },
    {
      "epoch": 242.1,
      "learning_rate": 0.07580002420000001,
      "loss": 0.8735,
      "step": 150100
    },
    {
      "epoch": 242.13,
      "learning_rate": 0.0757967983967742,
      "loss": 0.8898,
      "step": 150120
    },
    {
      "epoch": 242.16,
      "learning_rate": 0.0757935725935484,
      "loss": 0.8663,
      "step": 150140
    },
    {
      "epoch": 242.19,
      "learning_rate": 0.0757903467903226,
      "loss": 0.8777,
      "step": 150160
    },
    {
      "epoch": 242.23,
      "learning_rate": 0.07578712098709678,
      "loss": 0.8747,
      "step": 150180
    },
    {
      "epoch": 242.26,
      "learning_rate": 0.07578389518387096,
      "loss": 0.8873,
      "step": 150200
    },
    {
      "epoch": 242.29,
      "learning_rate": 0.07578066938064518,
      "loss": 0.8888,
      "step": 150220
    },
    {
      "epoch": 242.32,
      "learning_rate": 0.07577744357741935,
      "loss": 0.9126,
      "step": 150240
    },
    {
      "epoch": 242.35,
      "learning_rate": 0.07577421777419356,
      "loss": 0.8927,
      "step": 150260
    },
    {
      "epoch": 242.39,
      "learning_rate": 0.07577099197096775,
      "loss": 0.9178,
      "step": 150280
    },
    {
      "epoch": 242.42,
      "learning_rate": 0.07576776616774193,
      "loss": 0.8982,
      "step": 150300
    },
    {
      "epoch": 242.45,
      "learning_rate": 0.07576454036451613,
      "loss": 0.9481,
      "step": 150320
    },
    {
      "epoch": 242.48,
      "learning_rate": 0.07576131456129033,
      "loss": 0.9256,
      "step": 150340
    },
    {
      "epoch": 242.52,
      "learning_rate": 0.07575808875806452,
      "loss": 0.9034,
      "step": 150360
    },
    {
      "epoch": 242.55,
      "learning_rate": 0.07575486295483871,
      "loss": 0.9234,
      "step": 150380
    },
    {
      "epoch": 242.58,
      "learning_rate": 0.07575163715161291,
      "loss": 0.9307,
      "step": 150400
    },
    {
      "epoch": 242.61,
      "learning_rate": 0.0757484113483871,
      "loss": 0.915,
      "step": 150420
    },
    {
      "epoch": 242.65,
      "learning_rate": 0.0757451855451613,
      "loss": 0.9298,
      "step": 150440
    },
    {
      "epoch": 242.68,
      "learning_rate": 0.0757419597419355,
      "loss": 0.911,
      "step": 150460
    },
    {
      "epoch": 242.71,
      "learning_rate": 0.07573873393870968,
      "loss": 0.9095,
      "step": 150480
    },
    {
      "epoch": 242.74,
      "learning_rate": 0.07573550813548388,
      "loss": 0.9294,
      "step": 150500
    },
    {
      "epoch": 242.77,
      "learning_rate": 0.07573228233225808,
      "loss": 0.9165,
      "step": 150520
    },
    {
      "epoch": 242.81,
      "learning_rate": 0.07572905652903225,
      "loss": 0.9352,
      "step": 150540
    },
    {
      "epoch": 242.84,
      "learning_rate": 0.07572583072580646,
      "loss": 0.943,
      "step": 150560
    },
    {
      "epoch": 242.87,
      "learning_rate": 0.07572260492258065,
      "loss": 0.8981,
      "step": 150580
    },
    {
      "epoch": 242.9,
      "learning_rate": 0.07571937911935483,
      "loss": 0.9104,
      "step": 150600
    },
    {
      "epoch": 242.94,
      "learning_rate": 0.07571615331612903,
      "loss": 0.9135,
      "step": 150620
    },
    {
      "epoch": 242.97,
      "learning_rate": 0.07571292751290323,
      "loss": 0.9252,
      "step": 150640
    },
    {
      "epoch": 243.0,
      "learning_rate": 0.07570986299983871,
      "loss": 0.9474,
      "step": 150660
    },
    {
      "epoch": 243.0,
      "eval_accuracy": {
        "accuracy": 0.7424869252985715
      },
      "eval_loss": 1.3018347024917603,
      "eval_runtime": 3.0009,
      "eval_samples_per_second": 4269.025,
      "eval_steps_per_second": 66.979,
      "step": 150660
    },
    {
      "epoch": 243.03,
      "learning_rate": 0.0757066371966129,
      "loss": 0.8936,
      "step": 150680
    },
    {
      "epoch": 243.06,
      "learning_rate": 0.07570341139338711,
      "loss": 0.8707,
      "step": 150700
    },
    {
      "epoch": 243.1,
      "learning_rate": 0.07570018559016128,
      "loss": 0.8985,
      "step": 150720
    },
    {
      "epoch": 243.13,
      "learning_rate": 0.07569695978693548,
      "loss": 0.8871,
      "step": 150740
    },
    {
      "epoch": 243.16,
      "learning_rate": 0.07569373398370968,
      "loss": 0.8801,
      "step": 150760
    },
    {
      "epoch": 243.19,
      "learning_rate": 0.07569050818048387,
      "loss": 0.9017,
      "step": 150780
    },
    {
      "epoch": 243.23,
      "learning_rate": 0.07568728237725807,
      "loss": 0.9237,
      "step": 150800
    },
    {
      "epoch": 243.26,
      "learning_rate": 0.07568405657403227,
      "loss": 0.9119,
      "step": 150820
    },
    {
      "epoch": 243.29,
      "learning_rate": 0.07568083077080645,
      "loss": 0.9062,
      "step": 150840
    },
    {
      "epoch": 243.32,
      "learning_rate": 0.07567760496758065,
      "loss": 0.9287,
      "step": 150860
    },
    {
      "epoch": 243.35,
      "learning_rate": 0.07567437916435485,
      "loss": 0.9219,
      "step": 150880
    },
    {
      "epoch": 243.39,
      "learning_rate": 0.07567115336112903,
      "loss": 0.9168,
      "step": 150900
    },
    {
      "epoch": 243.42,
      "learning_rate": 0.07566792755790323,
      "loss": 0.9456,
      "step": 150920
    },
    {
      "epoch": 243.45,
      "learning_rate": 0.07566470175467743,
      "loss": 0.9133,
      "step": 150940
    },
    {
      "epoch": 243.48,
      "learning_rate": 0.07566147595145162,
      "loss": 0.8907,
      "step": 150960
    },
    {
      "epoch": 243.52,
      "learning_rate": 0.0756582501482258,
      "loss": 0.8883,
      "step": 150980
    },
    {
      "epoch": 243.55,
      "learning_rate": 0.07565502434500002,
      "loss": 0.9183,
      "step": 151000
    },
    {
      "epoch": 243.58,
      "learning_rate": 0.07565179854177419,
      "loss": 0.9226,
      "step": 151020
    },
    {
      "epoch": 243.61,
      "learning_rate": 0.07564857273854839,
      "loss": 0.8984,
      "step": 151040
    },
    {
      "epoch": 243.65,
      "learning_rate": 0.07564534693532259,
      "loss": 0.9098,
      "step": 151060
    },
    {
      "epoch": 243.68,
      "learning_rate": 0.07564212113209677,
      "loss": 0.9235,
      "step": 151080
    },
    {
      "epoch": 243.71,
      "learning_rate": 0.07563889532887097,
      "loss": 0.9455,
      "step": 151100
    },
    {
      "epoch": 243.74,
      "learning_rate": 0.07563566952564517,
      "loss": 0.9657,
      "step": 151120
    },
    {
      "epoch": 243.77,
      "learning_rate": 0.07563244372241935,
      "loss": 0.9177,
      "step": 151140
    },
    {
      "epoch": 243.81,
      "learning_rate": 0.07562921791919355,
      "loss": 0.9294,
      "step": 151160
    },
    {
      "epoch": 243.84,
      "learning_rate": 0.07562599211596775,
      "loss": 0.9387,
      "step": 151180
    },
    {
      "epoch": 243.87,
      "learning_rate": 0.07562276631274194,
      "loss": 0.9062,
      "step": 151200
    },
    {
      "epoch": 243.9,
      "learning_rate": 0.07561954050951614,
      "loss": 0.9124,
      "step": 151220
    },
    {
      "epoch": 243.94,
      "learning_rate": 0.07561631470629034,
      "loss": 0.9111,
      "step": 151240
    },
    {
      "epoch": 243.97,
      "learning_rate": 0.07561308890306452,
      "loss": 0.9179,
      "step": 151260
    },
    {
      "epoch": 244.0,
      "learning_rate": 0.0756098630998387,
      "loss": 0.9184,
      "step": 151280
    },
    {
      "epoch": 244.0,
      "eval_accuracy": {
        "accuracy": 0.7420185777847162
      },
      "eval_loss": 1.2914355993270874,
      "eval_runtime": 2.6526,
      "eval_samples_per_second": 4829.635,
      "eval_steps_per_second": 75.775,
      "step": 151280
    },
    {
      "epoch": 244.03,
      "learning_rate": 0.07560663729661292,
      "loss": 0.9573,
      "step": 151300
    },
    {
      "epoch": 244.06,
      "learning_rate": 0.07560341149338709,
      "loss": 0.8842,
      "step": 151320
    },
    {
      "epoch": 244.1,
      "learning_rate": 0.0756001856901613,
      "loss": 0.8854,
      "step": 151340
    },
    {
      "epoch": 244.13,
      "learning_rate": 0.07559695988693549,
      "loss": 0.9053,
      "step": 151360
    },
    {
      "epoch": 244.16,
      "learning_rate": 0.07559373408370967,
      "loss": 0.915,
      "step": 151380
    },
    {
      "epoch": 244.19,
      "learning_rate": 0.07559050828048387,
      "loss": 0.9037,
      "step": 151400
    },
    {
      "epoch": 244.23,
      "learning_rate": 0.07558728247725807,
      "loss": 0.903,
      "step": 151420
    },
    {
      "epoch": 244.26,
      "learning_rate": 0.07558405667403226,
      "loss": 0.8943,
      "step": 151440
    },
    {
      "epoch": 244.29,
      "learning_rate": 0.07558083087080646,
      "loss": 0.8736,
      "step": 151460
    },
    {
      "epoch": 244.32,
      "learning_rate": 0.07557760506758066,
      "loss": 0.9191,
      "step": 151480
    },
    {
      "epoch": 244.35,
      "learning_rate": 0.07557437926435484,
      "loss": 0.8907,
      "step": 151500
    },
    {
      "epoch": 244.39,
      "learning_rate": 0.07557115346112904,
      "loss": 0.9091,
      "step": 151520
    },
    {
      "epoch": 244.42,
      "learning_rate": 0.07556792765790324,
      "loss": 0.9218,
      "step": 151540
    },
    {
      "epoch": 244.45,
      "learning_rate": 0.07556470185467742,
      "loss": 0.9277,
      "step": 151560
    },
    {
      "epoch": 244.48,
      "learning_rate": 0.07556147605145162,
      "loss": 0.9063,
      "step": 151580
    },
    {
      "epoch": 244.52,
      "learning_rate": 0.07555825024822582,
      "loss": 0.8902,
      "step": 151600
    },
    {
      "epoch": 244.55,
      "learning_rate": 0.075555024445,
      "loss": 0.9012,
      "step": 151620
    },
    {
      "epoch": 244.58,
      "learning_rate": 0.0755517986417742,
      "loss": 0.9004,
      "step": 151640
    },
    {
      "epoch": 244.61,
      "learning_rate": 0.07554857283854839,
      "loss": 0.918,
      "step": 151660
    },
    {
      "epoch": 244.65,
      "learning_rate": 0.07554534703532258,
      "loss": 0.9243,
      "step": 151680
    },
    {
      "epoch": 244.68,
      "learning_rate": 0.07554212123209678,
      "loss": 0.9346,
      "step": 151700
    },
    {
      "epoch": 244.71,
      "learning_rate": 0.07553889542887098,
      "loss": 0.9073,
      "step": 151720
    },
    {
      "epoch": 244.74,
      "learning_rate": 0.07553566962564516,
      "loss": 0.911,
      "step": 151740
    },
    {
      "epoch": 244.77,
      "learning_rate": 0.07553244382241936,
      "loss": 0.9179,
      "step": 151760
    },
    {
      "epoch": 244.81,
      "learning_rate": 0.07552921801919356,
      "loss": 0.9232,
      "step": 151780
    },
    {
      "epoch": 244.84,
      "learning_rate": 0.07552599221596774,
      "loss": 0.9194,
      "step": 151800
    },
    {
      "epoch": 244.87,
      "learning_rate": 0.07552276641274194,
      "loss": 0.8994,
      "step": 151820
    },
    {
      "epoch": 244.9,
      "learning_rate": 0.07551954060951614,
      "loss": 0.9432,
      "step": 151840
    },
    {
      "epoch": 244.94,
      "learning_rate": 0.07551631480629033,
      "loss": 0.9039,
      "step": 151860
    },
    {
      "epoch": 244.97,
      "learning_rate": 0.07551308900306453,
      "loss": 0.9173,
      "step": 151880
    },
    {
      "epoch": 245.0,
      "learning_rate": 0.07550986319983873,
      "loss": 0.9226,
      "step": 151900
    },
    {
      "epoch": 245.0,
      "eval_accuracy": {
        "accuracy": 0.7435797361642339
      },
      "eval_loss": 1.3168355226516724,
      "eval_runtime": 2.732,
      "eval_samples_per_second": 4689.277,
      "eval_steps_per_second": 73.573,
      "step": 151900
    },
    {
      "epoch": 245.03,
      "learning_rate": 0.0755066373966129,
      "loss": 0.981,
      "step": 151920
    },
    {
      "epoch": 245.06,
      "learning_rate": 0.07550341159338711,
      "loss": 0.9316,
      "step": 151940
    },
    {
      "epoch": 245.1,
      "learning_rate": 0.0755001857901613,
      "loss": 0.892,
      "step": 151960
    },
    {
      "epoch": 245.13,
      "learning_rate": 0.07549695998693548,
      "loss": 0.9179,
      "step": 151980
    },
    {
      "epoch": 245.16,
      "learning_rate": 0.07549373418370968,
      "loss": 0.8946,
      "step": 152000
    },
    {
      "epoch": 245.19,
      "learning_rate": 0.07549050838048388,
      "loss": 0.9127,
      "step": 152020
    },
    {
      "epoch": 245.23,
      "learning_rate": 0.07548728257725806,
      "loss": 0.9011,
      "step": 152040
    },
    {
      "epoch": 245.26,
      "learning_rate": 0.07548405677403226,
      "loss": 0.9026,
      "step": 152060
    },
    {
      "epoch": 245.29,
      "learning_rate": 0.07548083097080646,
      "loss": 0.906,
      "step": 152080
    },
    {
      "epoch": 245.32,
      "learning_rate": 0.07547760516758065,
      "loss": 0.9197,
      "step": 152100
    },
    {
      "epoch": 245.35,
      "learning_rate": 0.07547437936435485,
      "loss": 0.9041,
      "step": 152120
    },
    {
      "epoch": 245.39,
      "learning_rate": 0.07547115356112905,
      "loss": 0.9202,
      "step": 152140
    },
    {
      "epoch": 245.42,
      "learning_rate": 0.07546792775790323,
      "loss": 0.906,
      "step": 152160
    },
    {
      "epoch": 245.45,
      "learning_rate": 0.07546470195467743,
      "loss": 0.89,
      "step": 152180
    },
    {
      "epoch": 245.48,
      "learning_rate": 0.07546147615145163,
      "loss": 0.8772,
      "step": 152200
    },
    {
      "epoch": 245.52,
      "learning_rate": 0.0754582503482258,
      "loss": 0.8962,
      "step": 152220
    },
    {
      "epoch": 245.55,
      "learning_rate": 0.07545502454500001,
      "loss": 0.9168,
      "step": 152240
    },
    {
      "epoch": 245.58,
      "learning_rate": 0.0754517987417742,
      "loss": 0.8861,
      "step": 152260
    },
    {
      "epoch": 245.61,
      "learning_rate": 0.0754485729385484,
      "loss": 0.9234,
      "step": 152280
    },
    {
      "epoch": 245.65,
      "learning_rate": 0.07544534713532258,
      "loss": 0.9265,
      "step": 152300
    },
    {
      "epoch": 245.68,
      "learning_rate": 0.07544212133209678,
      "loss": 0.9128,
      "step": 152320
    },
    {
      "epoch": 245.71,
      "learning_rate": 0.07543889552887097,
      "loss": 0.9274,
      "step": 152340
    },
    {
      "epoch": 245.74,
      "learning_rate": 0.07543566972564517,
      "loss": 0.9343,
      "step": 152360
    },
    {
      "epoch": 245.77,
      "learning_rate": 0.07543244392241936,
      "loss": 0.9358,
      "step": 152380
    },
    {
      "epoch": 245.81,
      "learning_rate": 0.07542921811919355,
      "loss": 0.9304,
      "step": 152400
    },
    {
      "epoch": 245.84,
      "learning_rate": 0.07542599231596775,
      "loss": 0.9154,
      "step": 152420
    },
    {
      "epoch": 245.87,
      "learning_rate": 0.07542276651274195,
      "loss": 0.9444,
      "step": 152440
    },
    {
      "epoch": 245.9,
      "learning_rate": 0.07541954070951613,
      "loss": 0.9363,
      "step": 152460
    },
    {
      "epoch": 245.94,
      "learning_rate": 0.07541631490629033,
      "loss": 0.9387,
      "step": 152480
    },
    {
      "epoch": 245.97,
      "learning_rate": 0.07541308910306452,
      "loss": 0.9046,
      "step": 152500
    },
    {
      "epoch": 246.0,
      "learning_rate": 0.0754098632998387,
      "loss": 0.8964,
      "step": 152520
    },
    {
      "epoch": 246.0,
      "eval_accuracy": {
        "accuracy": 0.746077589571462
      },
      "eval_loss": 1.269355058670044,
      "eval_runtime": 3.0591,
      "eval_samples_per_second": 4187.876,
      "eval_steps_per_second": 65.706,
      "step": 152520
    },
    {
      "epoch": 246.03,
      "learning_rate": 0.07540663749661292,
      "loss": 0.9027,
      "step": 152540
    },
    {
      "epoch": 246.06,
      "learning_rate": 0.0754034116933871,
      "loss": 0.8908,
      "step": 152560
    },
    {
      "epoch": 246.1,
      "learning_rate": 0.0754001858901613,
      "loss": 0.8797,
      "step": 152580
    },
    {
      "epoch": 246.13,
      "learning_rate": 0.07539696008693549,
      "loss": 0.874,
      "step": 152600
    },
    {
      "epoch": 246.16,
      "learning_rate": 0.07539373428370968,
      "loss": 0.8937,
      "step": 152620
    },
    {
      "epoch": 246.19,
      "learning_rate": 0.07539050848048387,
      "loss": 0.8762,
      "step": 152640
    },
    {
      "epoch": 246.23,
      "learning_rate": 0.07538728267725807,
      "loss": 0.8961,
      "step": 152660
    },
    {
      "epoch": 246.26,
      "learning_rate": 0.07538405687403227,
      "loss": 0.8809,
      "step": 152680
    },
    {
      "epoch": 246.29,
      "learning_rate": 0.07538083107080645,
      "loss": 0.8931,
      "step": 152700
    },
    {
      "epoch": 246.32,
      "learning_rate": 0.07537760526758065,
      "loss": 0.8903,
      "step": 152720
    },
    {
      "epoch": 246.35,
      "learning_rate": 0.07537437946435485,
      "loss": 0.9527,
      "step": 152740
    },
    {
      "epoch": 246.39,
      "learning_rate": 0.07537115366112904,
      "loss": 0.9171,
      "step": 152760
    },
    {
      "epoch": 246.42,
      "learning_rate": 0.07536792785790324,
      "loss": 0.9111,
      "step": 152780
    },
    {
      "epoch": 246.45,
      "learning_rate": 0.07536470205467742,
      "loss": 0.9063,
      "step": 152800
    },
    {
      "epoch": 246.48,
      "learning_rate": 0.07536147625145162,
      "loss": 0.9084,
      "step": 152820
    },
    {
      "epoch": 246.52,
      "learning_rate": 0.07535825044822582,
      "loss": 0.9033,
      "step": 152840
    },
    {
      "epoch": 246.55,
      "learning_rate": 0.075355024645,
      "loss": 0.9065,
      "step": 152860
    },
    {
      "epoch": 246.58,
      "learning_rate": 0.0753517988417742,
      "loss": 0.917,
      "step": 152880
    },
    {
      "epoch": 246.61,
      "learning_rate": 0.07534857303854839,
      "loss": 0.8988,
      "step": 152900
    },
    {
      "epoch": 246.65,
      "learning_rate": 0.07534534723532259,
      "loss": 0.9004,
      "step": 152920
    },
    {
      "epoch": 246.68,
      "learning_rate": 0.07534212143209677,
      "loss": 0.9148,
      "step": 152940
    },
    {
      "epoch": 246.71,
      "learning_rate": 0.07533889562887097,
      "loss": 0.943,
      "step": 152960
    },
    {
      "epoch": 246.74,
      "learning_rate": 0.07533566982564517,
      "loss": 0.9042,
      "step": 152980
    },
    {
      "epoch": 246.77,
      "learning_rate": 0.07533260531258064,
      "loss": 0.8935,
      "step": 153000
    },
    {
      "epoch": 246.81,
      "learning_rate": 0.07532937950935485,
      "loss": 0.9312,
      "step": 153020
    },
    {
      "epoch": 246.84,
      "learning_rate": 0.07532615370612904,
      "loss": 0.9046,
      "step": 153040
    },
    {
      "epoch": 246.87,
      "learning_rate": 0.07532292790290322,
      "loss": 0.9146,
      "step": 153060
    },
    {
      "epoch": 246.9,
      "learning_rate": 0.07531970209967742,
      "loss": 0.9153,
      "step": 153080
    },
    {
      "epoch": 246.94,
      "learning_rate": 0.07531647629645162,
      "loss": 0.9343,
      "step": 153100
    },
    {
      "epoch": 246.97,
      "learning_rate": 0.0753132504932258,
      "loss": 0.9318,
      "step": 153120
    },
    {
      "epoch": 247.0,
      "learning_rate": 0.07531002469,
      "loss": 0.9259,
      "step": 153140
    },
    {
      "epoch": 247.0,
      "eval_accuracy": {
        "accuracy": 0.7431113886503786
      },
      "eval_loss": 1.3041682243347168,
      "eval_runtime": 3.0418,
      "eval_samples_per_second": 4211.65,
      "eval_steps_per_second": 66.079,
      "step": 153140
    },
    {
      "epoch": 247.03,
      "learning_rate": 0.0753067988867742,
      "loss": 0.9438,
      "step": 153160
    },
    {
      "epoch": 247.06,
      "learning_rate": 0.07530357308354839,
      "loss": 0.9163,
      "step": 153180
    },
    {
      "epoch": 247.1,
      "learning_rate": 0.07530034728032259,
      "loss": 0.9008,
      "step": 153200
    },
    {
      "epoch": 247.13,
      "learning_rate": 0.07529712147709679,
      "loss": 0.898,
      "step": 153220
    },
    {
      "epoch": 247.16,
      "learning_rate": 0.07529389567387097,
      "loss": 0.9022,
      "step": 153240
    },
    {
      "epoch": 247.19,
      "learning_rate": 0.07529066987064517,
      "loss": 0.8741,
      "step": 153260
    },
    {
      "epoch": 247.23,
      "learning_rate": 0.07528744406741937,
      "loss": 0.8872,
      "step": 153280
    },
    {
      "epoch": 247.26,
      "learning_rate": 0.07528421826419354,
      "loss": 0.8858,
      "step": 153300
    },
    {
      "epoch": 247.29,
      "learning_rate": 0.07528099246096775,
      "loss": 0.946,
      "step": 153320
    },
    {
      "epoch": 247.32,
      "learning_rate": 0.07527776665774194,
      "loss": 0.8954,
      "step": 153340
    },
    {
      "epoch": 247.35,
      "learning_rate": 0.07527454085451613,
      "loss": 0.8839,
      "step": 153360
    },
    {
      "epoch": 247.39,
      "learning_rate": 0.07527131505129032,
      "loss": 0.9115,
      "step": 153380
    },
    {
      "epoch": 247.42,
      "learning_rate": 0.07526808924806452,
      "loss": 0.9362,
      "step": 153400
    },
    {
      "epoch": 247.45,
      "learning_rate": 0.07526486344483871,
      "loss": 0.9198,
      "step": 153420
    },
    {
      "epoch": 247.48,
      "learning_rate": 0.07526163764161291,
      "loss": 0.9177,
      "step": 153440
    },
    {
      "epoch": 247.52,
      "learning_rate": 0.07525841183838711,
      "loss": 0.8958,
      "step": 153460
    },
    {
      "epoch": 247.55,
      "learning_rate": 0.07525518603516129,
      "loss": 0.9009,
      "step": 153480
    },
    {
      "epoch": 247.58,
      "learning_rate": 0.07525196023193549,
      "loss": 0.9394,
      "step": 153500
    },
    {
      "epoch": 247.61,
      "learning_rate": 0.07524873442870969,
      "loss": 0.9392,
      "step": 153520
    },
    {
      "epoch": 247.65,
      "learning_rate": 0.07524550862548388,
      "loss": 0.9227,
      "step": 153540
    },
    {
      "epoch": 247.68,
      "learning_rate": 0.07524228282225807,
      "loss": 0.904,
      "step": 153560
    },
    {
      "epoch": 247.71,
      "learning_rate": 0.07523905701903226,
      "loss": 0.9085,
      "step": 153580
    },
    {
      "epoch": 247.74,
      "learning_rate": 0.07523583121580645,
      "loss": 0.8983,
      "step": 153600
    },
    {
      "epoch": 247.77,
      "learning_rate": 0.07523260541258066,
      "loss": 0.9161,
      "step": 153620
    },
    {
      "epoch": 247.81,
      "learning_rate": 0.07522937960935484,
      "loss": 0.9276,
      "step": 153640
    },
    {
      "epoch": 247.84,
      "learning_rate": 0.07522615380612904,
      "loss": 0.9231,
      "step": 153660
    },
    {
      "epoch": 247.87,
      "learning_rate": 0.07522292800290323,
      "loss": 0.8931,
      "step": 153680
    },
    {
      "epoch": 247.9,
      "learning_rate": 0.07521970219967743,
      "loss": 0.9105,
      "step": 153700
    },
    {
      "epoch": 247.94,
      "learning_rate": 0.07521647639645161,
      "loss": 0.9109,
      "step": 153720
    },
    {
      "epoch": 247.97,
      "learning_rate": 0.07521325059322581,
      "loss": 0.9013,
      "step": 153740
    },
    {
      "epoch": 248.0,
      "learning_rate": 0.07521002479000001,
      "loss": 0.9286,
      "step": 153760
    },
    {
      "epoch": 248.0,
      "eval_accuracy": {
        "accuracy": 0.744750604948872
      },
      "eval_loss": 1.293518304824829,
      "eval_runtime": 2.7798,
      "eval_samples_per_second": 4608.666,
      "eval_steps_per_second": 72.308,
      "step": 153760
    },
    {
      "epoch": 248.03,
      "learning_rate": 0.0752067989867742,
      "loss": 0.95,
      "step": 153780
    },
    {
      "epoch": 248.06,
      "learning_rate": 0.0752035731835484,
      "loss": 0.8755,
      "step": 153800
    },
    {
      "epoch": 248.1,
      "learning_rate": 0.0752003473803226,
      "loss": 0.8974,
      "step": 153820
    },
    {
      "epoch": 248.13,
      "learning_rate": 0.07519712157709678,
      "loss": 0.8823,
      "step": 153840
    },
    {
      "epoch": 248.16,
      "learning_rate": 0.07519389577387098,
      "loss": 0.8646,
      "step": 153860
    },
    {
      "epoch": 248.19,
      "learning_rate": 0.07519066997064516,
      "loss": 0.9133,
      "step": 153880
    },
    {
      "epoch": 248.23,
      "learning_rate": 0.07518744416741936,
      "loss": 0.9224,
      "step": 153900
    },
    {
      "epoch": 248.26,
      "learning_rate": 0.07518421836419356,
      "loss": 0.887,
      "step": 153920
    },
    {
      "epoch": 248.29,
      "learning_rate": 0.07518099256096775,
      "loss": 0.8944,
      "step": 153940
    },
    {
      "epoch": 248.32,
      "learning_rate": 0.07517776675774195,
      "loss": 0.9035,
      "step": 153960
    },
    {
      "epoch": 248.35,
      "learning_rate": 0.07517454095451613,
      "loss": 0.9109,
      "step": 153980
    },
    {
      "epoch": 248.39,
      "learning_rate": 0.07517131515129033,
      "loss": 0.8965,
      "step": 154000
    },
    {
      "epoch": 248.42,
      "learning_rate": 0.07516808934806452,
      "loss": 0.909,
      "step": 154020
    },
    {
      "epoch": 248.45,
      "learning_rate": 0.07516486354483871,
      "loss": 0.895,
      "step": 154040
    },
    {
      "epoch": 248.48,
      "learning_rate": 0.07516163774161291,
      "loss": 0.9229,
      "step": 154060
    },
    {
      "epoch": 248.52,
      "learning_rate": 0.0751584119383871,
      "loss": 0.9341,
      "step": 154080
    },
    {
      "epoch": 248.55,
      "learning_rate": 0.0751551861351613,
      "loss": 0.9221,
      "step": 154100
    },
    {
      "epoch": 248.58,
      "learning_rate": 0.07515196033193548,
      "loss": 0.9264,
      "step": 154120
    },
    {
      "epoch": 248.61,
      "learning_rate": 0.07514873452870968,
      "loss": 0.9146,
      "step": 154140
    },
    {
      "epoch": 248.65,
      "learning_rate": 0.07514550872548388,
      "loss": 0.9032,
      "step": 154160
    },
    {
      "epoch": 248.68,
      "learning_rate": 0.07514228292225807,
      "loss": 0.9052,
      "step": 154180
    },
    {
      "epoch": 248.71,
      "learning_rate": 0.07513905711903227,
      "loss": 0.9032,
      "step": 154200
    },
    {
      "epoch": 248.74,
      "learning_rate": 0.07513583131580646,
      "loss": 0.9148,
      "step": 154220
    },
    {
      "epoch": 248.77,
      "learning_rate": 0.07513260551258065,
      "loss": 0.8885,
      "step": 154240
    },
    {
      "epoch": 248.81,
      "learning_rate": 0.07512937970935485,
      "loss": 0.9159,
      "step": 154260
    },
    {
      "epoch": 248.84,
      "learning_rate": 0.07512615390612903,
      "loss": 0.9354,
      "step": 154280
    },
    {
      "epoch": 248.87,
      "learning_rate": 0.07512292810290323,
      "loss": 0.9037,
      "step": 154300
    },
    {
      "epoch": 248.9,
      "learning_rate": 0.07511970229967742,
      "loss": 0.9287,
      "step": 154320
    },
    {
      "epoch": 248.94,
      "learning_rate": 0.07511647649645162,
      "loss": 0.9432,
      "step": 154340
    },
    {
      "epoch": 248.97,
      "learning_rate": 0.07511325069322582,
      "loss": 0.9124,
      "step": 154360
    },
    {
      "epoch": 249.0,
      "learning_rate": 0.07511002489,
      "loss": 0.9133,
      "step": 154380
    },
    {
      "epoch": 249.0,
      "eval_accuracy": {
        "accuracy": 0.7474826321130279
      },
      "eval_loss": 1.274279236793518,
      "eval_runtime": 2.6716,
      "eval_samples_per_second": 4795.257,
      "eval_steps_per_second": 75.236,
      "step": 154380
    },
    {
      "epoch": 249.03,
      "learning_rate": 0.0751067990867742,
      "loss": 0.9508,
      "step": 154400
    },
    {
      "epoch": 249.06,
      "learning_rate": 0.07510357328354839,
      "loss": 0.9114,
      "step": 154420
    },
    {
      "epoch": 249.1,
      "learning_rate": 0.07510034748032259,
      "loss": 0.8805,
      "step": 154440
    },
    {
      "epoch": 249.13,
      "learning_rate": 0.07509712167709678,
      "loss": 0.8638,
      "step": 154460
    },
    {
      "epoch": 249.16,
      "learning_rate": 0.07509389587387097,
      "loss": 0.8932,
      "step": 154480
    },
    {
      "epoch": 249.19,
      "learning_rate": 0.07509067007064517,
      "loss": 0.8746,
      "step": 154500
    },
    {
      "epoch": 249.23,
      "learning_rate": 0.07508744426741937,
      "loss": 0.8782,
      "step": 154520
    },
    {
      "epoch": 249.26,
      "learning_rate": 0.07508421846419355,
      "loss": 0.9069,
      "step": 154540
    },
    {
      "epoch": 249.29,
      "learning_rate": 0.07508099266096775,
      "loss": 0.9164,
      "step": 154560
    },
    {
      "epoch": 249.32,
      "learning_rate": 0.07507776685774194,
      "loss": 0.9072,
      "step": 154580
    },
    {
      "epoch": 249.35,
      "learning_rate": 0.07507454105451614,
      "loss": 0.9169,
      "step": 154600
    },
    {
      "epoch": 249.39,
      "learning_rate": 0.07507131525129032,
      "loss": 0.9214,
      "step": 154620
    },
    {
      "epoch": 249.42,
      "learning_rate": 0.07506808944806452,
      "loss": 0.8981,
      "step": 154640
    },
    {
      "epoch": 249.45,
      "learning_rate": 0.0750648636448387,
      "loss": 0.9109,
      "step": 154660
    },
    {
      "epoch": 249.48,
      "learning_rate": 0.0750616378416129,
      "loss": 0.9177,
      "step": 154680
    },
    {
      "epoch": 249.52,
      "learning_rate": 0.0750584120383871,
      "loss": 0.9126,
      "step": 154700
    },
    {
      "epoch": 249.55,
      "learning_rate": 0.07505518623516129,
      "loss": 0.9276,
      "step": 154720
    },
    {
      "epoch": 249.58,
      "learning_rate": 0.07505196043193549,
      "loss": 0.9157,
      "step": 154740
    },
    {
      "epoch": 249.61,
      "learning_rate": 0.07504873462870969,
      "loss": 0.9266,
      "step": 154760
    },
    {
      "epoch": 249.65,
      "learning_rate": 0.07504550882548387,
      "loss": 0.9032,
      "step": 154780
    },
    {
      "epoch": 249.68,
      "learning_rate": 0.07504228302225807,
      "loss": 0.9194,
      "step": 154800
    },
    {
      "epoch": 249.71,
      "learning_rate": 0.07503905721903227,
      "loss": 0.914,
      "step": 154820
    },
    {
      "epoch": 249.74,
      "learning_rate": 0.07503583141580646,
      "loss": 0.9082,
      "step": 154840
    },
    {
      "epoch": 249.77,
      "learning_rate": 0.07503260561258066,
      "loss": 0.9123,
      "step": 154860
    },
    {
      "epoch": 249.81,
      "learning_rate": 0.07502937980935484,
      "loss": 0.9157,
      "step": 154880
    },
    {
      "epoch": 249.84,
      "learning_rate": 0.07502615400612904,
      "loss": 0.9241,
      "step": 154900
    },
    {
      "epoch": 249.87,
      "learning_rate": 0.07502292820290322,
      "loss": 0.9268,
      "step": 154920
    },
    {
      "epoch": 249.9,
      "learning_rate": 0.07501970239967742,
      "loss": 0.9451,
      "step": 154940
    },
    {
      "epoch": 249.94,
      "learning_rate": 0.07501647659645161,
      "loss": 0.9138,
      "step": 154960
    },
    {
      "epoch": 249.97,
      "learning_rate": 0.07501325079322581,
      "loss": 0.915,
      "step": 154980
    },
    {
      "epoch": 250.0,
      "learning_rate": 0.0750101862801613,
      "loss": 0.9101,
      "step": 155000
    },
    {
      "epoch": 250.0,
      "eval_accuracy": {
        "accuracy": 0.7509171805479666
      },
      "eval_loss": 1.2389668226242065,
      "eval_runtime": 2.9298,
      "eval_samples_per_second": 4372.662,
      "eval_steps_per_second": 68.605,
      "step": 155000
    },
    {
      "epoch": 250.03,
      "learning_rate": 0.07500696047693549,
      "loss": 0.8973,
      "step": 155020
    },
    {
      "epoch": 250.06,
      "learning_rate": 0.07500373467370969,
      "loss": 0.891,
      "step": 155040
    },
    {
      "epoch": 250.1,
      "learning_rate": 0.07500050887048387,
      "loss": 0.8905,
      "step": 155060
    },
    {
      "epoch": 250.13,
      "learning_rate": 0.07499728306725807,
      "loss": 0.8713,
      "step": 155080
    },
    {
      "epoch": 250.16,
      "learning_rate": 0.07499405726403226,
      "loss": 0.924,
      "step": 155100
    },
    {
      "epoch": 250.19,
      "learning_rate": 0.07499083146080646,
      "loss": 0.9045,
      "step": 155120
    },
    {
      "epoch": 250.23,
      "learning_rate": 0.07498760565758066,
      "loss": 0.9081,
      "step": 155140
    },
    {
      "epoch": 250.26,
      "learning_rate": 0.07498437985435484,
      "loss": 0.9091,
      "step": 155160
    },
    {
      "epoch": 250.29,
      "learning_rate": 0.07498115405112904,
      "loss": 0.8958,
      "step": 155180
    },
    {
      "epoch": 250.32,
      "learning_rate": 0.07497792824790322,
      "loss": 0.9076,
      "step": 155200
    },
    {
      "epoch": 250.35,
      "learning_rate": 0.07497470244467742,
      "loss": 0.8771,
      "step": 155220
    },
    {
      "epoch": 250.39,
      "learning_rate": 0.07497147664145162,
      "loss": 0.8945,
      "step": 155240
    },
    {
      "epoch": 250.42,
      "learning_rate": 0.07496825083822581,
      "loss": 0.8992,
      "step": 155260
    },
    {
      "epoch": 250.45,
      "learning_rate": 0.074965025035,
      "loss": 0.9224,
      "step": 155280
    },
    {
      "epoch": 250.48,
      "learning_rate": 0.0749617992317742,
      "loss": 0.9164,
      "step": 155300
    },
    {
      "epoch": 250.52,
      "learning_rate": 0.07495857342854839,
      "loss": 0.8845,
      "step": 155320
    },
    {
      "epoch": 250.55,
      "learning_rate": 0.07495534762532259,
      "loss": 0.8853,
      "step": 155340
    },
    {
      "epoch": 250.58,
      "learning_rate": 0.07495212182209678,
      "loss": 0.8964,
      "step": 155360
    },
    {
      "epoch": 250.61,
      "learning_rate": 0.07494889601887098,
      "loss": 0.8917,
      "step": 155380
    },
    {
      "epoch": 250.65,
      "learning_rate": 0.07494567021564516,
      "loss": 0.9082,
      "step": 155400
    },
    {
      "epoch": 250.68,
      "learning_rate": 0.07494244441241936,
      "loss": 0.9279,
      "step": 155420
    },
    {
      "epoch": 250.71,
      "learning_rate": 0.07493921860919356,
      "loss": 0.9285,
      "step": 155440
    },
    {
      "epoch": 250.74,
      "learning_rate": 0.07493599280596774,
      "loss": 0.9359,
      "step": 155460
    },
    {
      "epoch": 250.77,
      "learning_rate": 0.07493276700274194,
      "loss": 0.9129,
      "step": 155480
    },
    {
      "epoch": 250.81,
      "learning_rate": 0.07492954119951613,
      "loss": 0.9274,
      "step": 155500
    },
    {
      "epoch": 250.84,
      "learning_rate": 0.07492631539629033,
      "loss": 0.935,
      "step": 155520
    },
    {
      "epoch": 250.87,
      "learning_rate": 0.07492308959306453,
      "loss": 0.937,
      "step": 155540
    },
    {
      "epoch": 250.9,
      "learning_rate": 0.07491986378983871,
      "loss": 0.9107,
      "step": 155560
    },
    {
      "epoch": 250.94,
      "learning_rate": 0.0749166379866129,
      "loss": 0.9336,
      "step": 155580
    },
    {
      "epoch": 250.97,
      "learning_rate": 0.07491341218338711,
      "loss": 0.9264,
      "step": 155600
    },
    {
      "epoch": 251.0,
      "learning_rate": 0.0749101863801613,
      "loss": 0.931,
      "step": 155620
    },
    {
      "epoch": 251.0,
      "eval_accuracy": {
        "accuracy": 0.740847709000078
      },
      "eval_loss": 1.3156116008758545,
      "eval_runtime": 2.8121,
      "eval_samples_per_second": 4555.69,
      "eval_steps_per_second": 71.477,
      "step": 155620
    },
    {
      "epoch": 251.03,
      "learning_rate": 0.0749069605769355,
      "loss": 0.9604,
      "step": 155640
    },
    {
      "epoch": 251.06,
      "learning_rate": 0.07490373477370968,
      "loss": 0.9207,
      "step": 155660
    },
    {
      "epoch": 251.1,
      "learning_rate": 0.07490050897048388,
      "loss": 0.8683,
      "step": 155680
    },
    {
      "epoch": 251.13,
      "learning_rate": 0.07489728316725806,
      "loss": 0.9016,
      "step": 155700
    },
    {
      "epoch": 251.16,
      "learning_rate": 0.07489405736403226,
      "loss": 0.9156,
      "step": 155720
    },
    {
      "epoch": 251.19,
      "learning_rate": 0.07489083156080645,
      "loss": 0.8873,
      "step": 155740
    },
    {
      "epoch": 251.23,
      "learning_rate": 0.07488760575758065,
      "loss": 0.9045,
      "step": 155760
    },
    {
      "epoch": 251.26,
      "learning_rate": 0.07488437995435485,
      "loss": 0.9108,
      "step": 155780
    },
    {
      "epoch": 251.29,
      "learning_rate": 0.07488115415112903,
      "loss": 0.8802,
      "step": 155800
    },
    {
      "epoch": 251.32,
      "learning_rate": 0.07487792834790323,
      "loss": 0.8917,
      "step": 155820
    },
    {
      "epoch": 251.35,
      "learning_rate": 0.07487470254467743,
      "loss": 0.915,
      "step": 155840
    },
    {
      "epoch": 251.39,
      "learning_rate": 0.07487147674145161,
      "loss": 0.8758,
      "step": 155860
    },
    {
      "epoch": 251.42,
      "learning_rate": 0.0748682509382258,
      "loss": 0.9012,
      "step": 155880
    },
    {
      "epoch": 251.45,
      "learning_rate": 0.07486502513500001,
      "loss": 0.9009,
      "step": 155900
    },
    {
      "epoch": 251.48,
      "learning_rate": 0.0748617993317742,
      "loss": 0.8932,
      "step": 155920
    },
    {
      "epoch": 251.52,
      "learning_rate": 0.0748585735285484,
      "loss": 0.9389,
      "step": 155940
    },
    {
      "epoch": 251.55,
      "learning_rate": 0.07485534772532258,
      "loss": 0.9461,
      "step": 155960
    },
    {
      "epoch": 251.58,
      "learning_rate": 0.07485212192209678,
      "loss": 0.9099,
      "step": 155980
    },
    {
      "epoch": 251.61,
      "learning_rate": 0.07484889611887097,
      "loss": 0.9003,
      "step": 156000
    },
    {
      "epoch": 251.65,
      "learning_rate": 0.07484567031564518,
      "loss": 0.8929,
      "step": 156020
    },
    {
      "epoch": 251.68,
      "learning_rate": 0.07484244451241935,
      "loss": 0.8834,
      "step": 156040
    },
    {
      "epoch": 251.71,
      "learning_rate": 0.07483921870919355,
      "loss": 0.9037,
      "step": 156060
    },
    {
      "epoch": 251.74,
      "learning_rate": 0.07483599290596775,
      "loss": 0.897,
      "step": 156080
    },
    {
      "epoch": 251.77,
      "learning_rate": 0.07483276710274193,
      "loss": 0.8977,
      "step": 156100
    },
    {
      "epoch": 251.81,
      "learning_rate": 0.07482954129951613,
      "loss": 0.896,
      "step": 156120
    },
    {
      "epoch": 251.84,
      "learning_rate": 0.07482631549629033,
      "loss": 0.9188,
      "step": 156140
    },
    {
      "epoch": 251.87,
      "learning_rate": 0.07482308969306452,
      "loss": 0.9209,
      "step": 156160
    },
    {
      "epoch": 251.9,
      "learning_rate": 0.07481986388983872,
      "loss": 0.9287,
      "step": 156180
    },
    {
      "epoch": 251.94,
      "learning_rate": 0.07481663808661292,
      "loss": 0.898,
      "step": 156200
    },
    {
      "epoch": 251.97,
      "learning_rate": 0.0748134122833871,
      "loss": 0.926,
      "step": 156220
    },
    {
      "epoch": 252.0,
      "learning_rate": 0.0748101864801613,
      "loss": 0.9128,
      "step": 156240
    },
    {
      "epoch": 252.0,
      "eval_accuracy": {
        "accuracy": 0.7483412692217626
      },
      "eval_loss": 1.2598785161972046,
      "eval_runtime": 2.6933,
      "eval_samples_per_second": 4756.566,
      "eval_steps_per_second": 74.629,
      "step": 156240
    },
    {
      "epoch": 252.03,
      "learning_rate": 0.07480696067693549,
      "loss": 0.9219,
      "step": 156260
    },
    {
      "epoch": 252.06,
      "learning_rate": 0.07480373487370968,
      "loss": 0.8953,
      "step": 156280
    },
    {
      "epoch": 252.1,
      "learning_rate": 0.07480050907048387,
      "loss": 0.8972,
      "step": 156300
    },
    {
      "epoch": 252.13,
      "learning_rate": 0.07479728326725808,
      "loss": 0.8999,
      "step": 156320
    },
    {
      "epoch": 252.16,
      "learning_rate": 0.07479405746403225,
      "loss": 0.8887,
      "step": 156340
    },
    {
      "epoch": 252.19,
      "learning_rate": 0.07479083166080645,
      "loss": 0.8881,
      "step": 156360
    },
    {
      "epoch": 252.23,
      "learning_rate": 0.07478760585758065,
      "loss": 0.9024,
      "step": 156380
    },
    {
      "epoch": 252.26,
      "learning_rate": 0.07478438005435484,
      "loss": 0.8918,
      "step": 156400
    },
    {
      "epoch": 252.29,
      "learning_rate": 0.07478115425112904,
      "loss": 0.9052,
      "step": 156420
    },
    {
      "epoch": 252.32,
      "learning_rate": 0.07477792844790324,
      "loss": 0.9041,
      "step": 156440
    },
    {
      "epoch": 252.35,
      "learning_rate": 0.07477470264467742,
      "loss": 0.8876,
      "step": 156460
    },
    {
      "epoch": 252.39,
      "learning_rate": 0.07477147684145162,
      "loss": 0.8751,
      "step": 156480
    },
    {
      "epoch": 252.42,
      "learning_rate": 0.07476825103822582,
      "loss": 0.9148,
      "step": 156500
    },
    {
      "epoch": 252.45,
      "learning_rate": 0.07476502523499999,
      "loss": 0.9021,
      "step": 156520
    },
    {
      "epoch": 252.48,
      "learning_rate": 0.0747617994317742,
      "loss": 0.8895,
      "step": 156540
    },
    {
      "epoch": 252.52,
      "learning_rate": 0.07475857362854839,
      "loss": 0.8931,
      "step": 156560
    },
    {
      "epoch": 252.55,
      "learning_rate": 0.07475534782532259,
      "loss": 0.9144,
      "step": 156580
    },
    {
      "epoch": 252.58,
      "learning_rate": 0.07475212202209677,
      "loss": 0.8896,
      "step": 156600
    },
    {
      "epoch": 252.61,
      "learning_rate": 0.07474889621887099,
      "loss": 0.8849,
      "step": 156620
    },
    {
      "epoch": 252.65,
      "learning_rate": 0.07474567041564516,
      "loss": 0.9071,
      "step": 156640
    },
    {
      "epoch": 252.68,
      "learning_rate": 0.07474244461241936,
      "loss": 0.9007,
      "step": 156660
    },
    {
      "epoch": 252.71,
      "learning_rate": 0.07473921880919356,
      "loss": 0.8791,
      "step": 156680
    },
    {
      "epoch": 252.74,
      "learning_rate": 0.07473599300596774,
      "loss": 0.901,
      "step": 156700
    },
    {
      "epoch": 252.77,
      "learning_rate": 0.07473276720274194,
      "loss": 0.9244,
      "step": 156720
    },
    {
      "epoch": 252.81,
      "learning_rate": 0.07472954139951614,
      "loss": 0.9296,
      "step": 156740
    },
    {
      "epoch": 252.84,
      "learning_rate": 0.07472631559629032,
      "loss": 0.9321,
      "step": 156760
    },
    {
      "epoch": 252.87,
      "learning_rate": 0.07472308979306452,
      "loss": 0.9117,
      "step": 156780
    },
    {
      "epoch": 252.9,
      "learning_rate": 0.07471986398983872,
      "loss": 0.9112,
      "step": 156800
    },
    {
      "epoch": 252.94,
      "learning_rate": 0.0747166381866129,
      "loss": 0.8922,
      "step": 156820
    },
    {
      "epoch": 252.97,
      "learning_rate": 0.0747134123833871,
      "loss": 0.9183,
      "step": 156840
    },
    {
      "epoch": 253.0,
      "learning_rate": 0.07471018658016129,
      "loss": 0.9179,
      "step": 156860
    },
    {
      "epoch": 253.0,
      "eval_accuracy": {
        "accuracy": 0.746155647490438
      },
      "eval_loss": 1.282758355140686,
      "eval_runtime": 3.6401,
      "eval_samples_per_second": 3519.406,
      "eval_steps_per_second": 55.218,
      "step": 156860
    },
    {
      "epoch": 253.03,
      "learning_rate": 0.07470696077693549,
      "loss": 0.9109,
      "step": 156880
    },
    {
      "epoch": 253.06,
      "learning_rate": 0.07470373497370968,
      "loss": 0.9024,
      "step": 156900
    },
    {
      "epoch": 253.1,
      "learning_rate": 0.07470050917048389,
      "loss": 0.8803,
      "step": 156920
    },
    {
      "epoch": 253.13,
      "learning_rate": 0.07469728336725806,
      "loss": 0.886,
      "step": 156940
    },
    {
      "epoch": 253.16,
      "learning_rate": 0.07469405756403227,
      "loss": 0.8737,
      "step": 156960
    },
    {
      "epoch": 253.19,
      "learning_rate": 0.07469083176080646,
      "loss": 0.8894,
      "step": 156980
    },
    {
      "epoch": 253.23,
      "learning_rate": 0.07468760595758064,
      "loss": 0.9288,
      "step": 157000
    },
    {
      "epoch": 253.26,
      "learning_rate": 0.07468438015435484,
      "loss": 0.9261,
      "step": 157020
    },
    {
      "epoch": 253.29,
      "learning_rate": 0.07468115435112904,
      "loss": 0.8969,
      "step": 157040
    },
    {
      "epoch": 253.32,
      "learning_rate": 0.07467792854790323,
      "loss": 0.8819,
      "step": 157060
    },
    {
      "epoch": 253.35,
      "learning_rate": 0.07467470274467743,
      "loss": 0.9135,
      "step": 157080
    },
    {
      "epoch": 253.39,
      "learning_rate": 0.07467147694145163,
      "loss": 0.87,
      "step": 157100
    },
    {
      "epoch": 253.42,
      "learning_rate": 0.0746682511382258,
      "loss": 0.8915,
      "step": 157120
    },
    {
      "epoch": 253.45,
      "learning_rate": 0.07466502533500001,
      "loss": 0.8978,
      "step": 157140
    },
    {
      "epoch": 253.48,
      "learning_rate": 0.0746617995317742,
      "loss": 0.9042,
      "step": 157160
    },
    {
      "epoch": 253.52,
      "learning_rate": 0.0746585737285484,
      "loss": 0.895,
      "step": 157180
    },
    {
      "epoch": 253.55,
      "learning_rate": 0.07465534792532258,
      "loss": 0.8798,
      "step": 157200
    },
    {
      "epoch": 253.58,
      "learning_rate": 0.07465212212209679,
      "loss": 0.8952,
      "step": 157220
    },
    {
      "epoch": 253.61,
      "learning_rate": 0.07464889631887096,
      "loss": 0.8927,
      "step": 157240
    },
    {
      "epoch": 253.65,
      "learning_rate": 0.07464567051564518,
      "loss": 0.8744,
      "step": 157260
    },
    {
      "epoch": 253.68,
      "learning_rate": 0.07464244471241936,
      "loss": 0.8685,
      "step": 157280
    },
    {
      "epoch": 253.71,
      "learning_rate": 0.07463921890919355,
      "loss": 0.938,
      "step": 157300
    },
    {
      "epoch": 253.74,
      "learning_rate": 0.07463599310596775,
      "loss": 0.8968,
      "step": 157320
    },
    {
      "epoch": 253.77,
      "learning_rate": 0.07463276730274195,
      "loss": 0.9048,
      "step": 157340
    },
    {
      "epoch": 253.81,
      "learning_rate": 0.07462954149951613,
      "loss": 0.8912,
      "step": 157360
    },
    {
      "epoch": 253.84,
      "learning_rate": 0.07462631569629033,
      "loss": 0.9007,
      "step": 157380
    },
    {
      "epoch": 253.87,
      "learning_rate": 0.07462308989306453,
      "loss": 0.9245,
      "step": 157400
    },
    {
      "epoch": 253.9,
      "learning_rate": 0.07461986408983871,
      "loss": 0.9226,
      "step": 157420
    },
    {
      "epoch": 253.94,
      "learning_rate": 0.07461663828661291,
      "loss": 0.9128,
      "step": 157440
    },
    {
      "epoch": 253.97,
      "learning_rate": 0.0746134124833871,
      "loss": 0.9043,
      "step": 157460
    },
    {
      "epoch": 254.0,
      "learning_rate": 0.0746101866801613,
      "loss": 0.8859,
      "step": 157480
    },
    {
      "epoch": 254.0,
      "eval_accuracy": {
        "accuracy": 0.7467801108422449
      },
      "eval_loss": 1.2737743854522705,
      "eval_runtime": 2.7765,
      "eval_samples_per_second": 4614.084,
      "eval_steps_per_second": 72.393,
      "step": 157480
    },
    {
      "epoch": 254.03,
      "learning_rate": 0.07460696087693548,
      "loss": 0.9215,
      "step": 157500
    },
    {
      "epoch": 254.06,
      "learning_rate": 0.07460373507370968,
      "loss": 0.8736,
      "step": 157520
    },
    {
      "epoch": 254.1,
      "learning_rate": 0.07460050927048387,
      "loss": 0.8867,
      "step": 157540
    },
    {
      "epoch": 254.13,
      "learning_rate": 0.07459728346725808,
      "loss": 0.893,
      "step": 157560
    },
    {
      "epoch": 254.16,
      "learning_rate": 0.07459405766403227,
      "loss": 0.8726,
      "step": 157580
    },
    {
      "epoch": 254.19,
      "learning_rate": 0.07459083186080645,
      "loss": 0.8748,
      "step": 157600
    },
    {
      "epoch": 254.23,
      "learning_rate": 0.07458760605758065,
      "loss": 0.906,
      "step": 157620
    },
    {
      "epoch": 254.26,
      "learning_rate": 0.07458438025435485,
      "loss": 0.8848,
      "step": 157640
    },
    {
      "epoch": 254.29,
      "learning_rate": 0.07458115445112903,
      "loss": 0.8725,
      "step": 157660
    },
    {
      "epoch": 254.32,
      "learning_rate": 0.07457792864790323,
      "loss": 0.8695,
      "step": 157680
    },
    {
      "epoch": 254.35,
      "learning_rate": 0.07457470284467743,
      "loss": 0.8845,
      "step": 157700
    },
    {
      "epoch": 254.39,
      "learning_rate": 0.07457147704145162,
      "loss": 0.8711,
      "step": 157720
    },
    {
      "epoch": 254.42,
      "learning_rate": 0.07456825123822582,
      "loss": 0.8867,
      "step": 157740
    },
    {
      "epoch": 254.45,
      "learning_rate": 0.074565025435,
      "loss": 0.888,
      "step": 157760
    },
    {
      "epoch": 254.48,
      "learning_rate": 0.0745617996317742,
      "loss": 0.8883,
      "step": 157780
    },
    {
      "epoch": 254.52,
      "learning_rate": 0.07455857382854839,
      "loss": 0.9043,
      "step": 157800
    },
    {
      "epoch": 254.55,
      "learning_rate": 0.07455534802532258,
      "loss": 0.8912,
      "step": 157820
    },
    {
      "epoch": 254.58,
      "learning_rate": 0.07455212222209677,
      "loss": 0.9359,
      "step": 157840
    },
    {
      "epoch": 254.61,
      "learning_rate": 0.07454889641887098,
      "loss": 0.9267,
      "step": 157860
    },
    {
      "epoch": 254.65,
      "learning_rate": 0.07454567061564517,
      "loss": 0.8939,
      "step": 157880
    },
    {
      "epoch": 254.68,
      "learning_rate": 0.07454244481241935,
      "loss": 0.8797,
      "step": 157900
    },
    {
      "epoch": 254.71,
      "learning_rate": 0.07453921900919355,
      "loss": 0.9176,
      "step": 157920
    },
    {
      "epoch": 254.74,
      "learning_rate": 0.07453599320596775,
      "loss": 0.8681,
      "step": 157940
    },
    {
      "epoch": 254.77,
      "learning_rate": 0.07453276740274194,
      "loss": 0.9059,
      "step": 157960
    },
    {
      "epoch": 254.81,
      "learning_rate": 0.07452954159951614,
      "loss": 0.8897,
      "step": 157980
    },
    {
      "epoch": 254.84,
      "learning_rate": 0.07452631579629033,
      "loss": 0.9089,
      "step": 158000
    },
    {
      "epoch": 254.87,
      "learning_rate": 0.07452308999306452,
      "loss": 0.9205,
      "step": 158020
    },
    {
      "epoch": 254.9,
      "learning_rate": 0.07451986418983872,
      "loss": 0.9165,
      "step": 158040
    },
    {
      "epoch": 254.94,
      "learning_rate": 0.0745166383866129,
      "loss": 0.9042,
      "step": 158060
    },
    {
      "epoch": 254.97,
      "learning_rate": 0.0745134125833871,
      "loss": 0.88,
      "step": 158080
    },
    {
      "epoch": 255.0,
      "learning_rate": 0.07451034807032259,
      "loss": 0.9072,
      "step": 158100
    },
    {
      "epoch": 255.0,
      "eval_accuracy": {
        "accuracy": 0.7484193271407384
      },
      "eval_loss": 1.2612518072128296,
      "eval_runtime": 2.7916,
      "eval_samples_per_second": 4589.086,
      "eval_steps_per_second": 72.001,
      "step": 158100
    },
    {
      "epoch": 255.03,
      "learning_rate": 0.07450712226709678,
      "loss": 0.8802,
      "step": 158120
    },
    {
      "epoch": 255.06,
      "learning_rate": 0.07450389646387097,
      "loss": 0.9064,
      "step": 158140
    },
    {
      "epoch": 255.1,
      "learning_rate": 0.07450067066064517,
      "loss": 0.8801,
      "step": 158160
    },
    {
      "epoch": 255.13,
      "learning_rate": 0.07449744485741937,
      "loss": 0.8935,
      "step": 158180
    },
    {
      "epoch": 255.16,
      "learning_rate": 0.07449421905419354,
      "loss": 0.8859,
      "step": 158200
    },
    {
      "epoch": 255.19,
      "learning_rate": 0.07449099325096775,
      "loss": 0.8713,
      "step": 158220
    },
    {
      "epoch": 255.23,
      "learning_rate": 0.07448776744774194,
      "loss": 0.8866,
      "step": 158240
    },
    {
      "epoch": 255.26,
      "learning_rate": 0.07448454164451614,
      "loss": 0.8987,
      "step": 158260
    },
    {
      "epoch": 255.29,
      "learning_rate": 0.07448131584129032,
      "loss": 0.8988,
      "step": 158280
    },
    {
      "epoch": 255.32,
      "learning_rate": 0.07447809003806453,
      "loss": 0.8912,
      "step": 158300
    },
    {
      "epoch": 255.35,
      "learning_rate": 0.0744748642348387,
      "loss": 0.9167,
      "step": 158320
    },
    {
      "epoch": 255.39,
      "learning_rate": 0.07447163843161292,
      "loss": 0.8739,
      "step": 158340
    },
    {
      "epoch": 255.42,
      "learning_rate": 0.0744684126283871,
      "loss": 0.8933,
      "step": 158360
    },
    {
      "epoch": 255.45,
      "learning_rate": 0.07446518682516129,
      "loss": 0.9092,
      "step": 158380
    },
    {
      "epoch": 255.48,
      "learning_rate": 0.07446196102193549,
      "loss": 0.9152,
      "step": 158400
    },
    {
      "epoch": 255.52,
      "learning_rate": 0.07445873521870969,
      "loss": 0.9338,
      "step": 158420
    },
    {
      "epoch": 255.55,
      "learning_rate": 0.07445550941548387,
      "loss": 0.8972,
      "step": 158440
    },
    {
      "epoch": 255.58,
      "learning_rate": 0.07445228361225807,
      "loss": 0.907,
      "step": 158460
    },
    {
      "epoch": 255.61,
      "learning_rate": 0.07444905780903227,
      "loss": 0.9005,
      "step": 158480
    },
    {
      "epoch": 255.65,
      "learning_rate": 0.07444583200580646,
      "loss": 0.9122,
      "step": 158500
    },
    {
      "epoch": 255.68,
      "learning_rate": 0.07444260620258066,
      "loss": 0.9107,
      "step": 158520
    },
    {
      "epoch": 255.71,
      "learning_rate": 0.07443938039935484,
      "loss": 0.9285,
      "step": 158540
    },
    {
      "epoch": 255.74,
      "learning_rate": 0.07443615459612904,
      "loss": 0.8988,
      "step": 158560
    },
    {
      "epoch": 255.77,
      "learning_rate": 0.07443292879290322,
      "loss": 0.9105,
      "step": 158580
    },
    {
      "epoch": 255.81,
      "learning_rate": 0.07442970298967742,
      "loss": 0.9203,
      "step": 158600
    },
    {
      "epoch": 255.84,
      "learning_rate": 0.07442647718645161,
      "loss": 0.8881,
      "step": 158620
    },
    {
      "epoch": 255.87,
      "learning_rate": 0.07442325138322582,
      "loss": 0.9055,
      "step": 158640
    },
    {
      "epoch": 255.9,
      "learning_rate": 0.07442002558000001,
      "loss": 0.9062,
      "step": 158660
    },
    {
      "epoch": 255.94,
      "learning_rate": 0.07441679977677419,
      "loss": 0.9149,
      "step": 158680
    },
    {
      "epoch": 255.97,
      "learning_rate": 0.07441357397354839,
      "loss": 0.9092,
      "step": 158700
    },
    {
      "epoch": 256.0,
      "learning_rate": 0.07441034817032259,
      "loss": 0.9333,
      "step": 158720
    },
    {
      "epoch": 256.0,
      "eval_accuracy": {
        "accuracy": 0.7482632113027866
      },
      "eval_loss": 1.2766664028167725,
      "eval_runtime": 2.6523,
      "eval_samples_per_second": 4830.171,
      "eval_steps_per_second": 75.784,
      "step": 158720
    },
    {
      "epoch": 256.03,
      "learning_rate": 0.07440712236709678,
      "loss": 0.9639,
      "step": 158740
    },
    {
      "epoch": 256.06,
      "learning_rate": 0.07440389656387097,
      "loss": 0.8756,
      "step": 158760
    },
    {
      "epoch": 256.1,
      "learning_rate": 0.07440067076064517,
      "loss": 0.8661,
      "step": 158780
    },
    {
      "epoch": 256.13,
      "learning_rate": 0.07439744495741936,
      "loss": 0.8588,
      "step": 158800
    },
    {
      "epoch": 256.16,
      "learning_rate": 0.07439421915419356,
      "loss": 0.8988,
      "step": 158820
    },
    {
      "epoch": 256.19,
      "learning_rate": 0.07439099335096774,
      "loss": 0.8902,
      "step": 158840
    },
    {
      "epoch": 256.23,
      "learning_rate": 0.07438776754774194,
      "loss": 0.8894,
      "step": 158860
    },
    {
      "epoch": 256.26,
      "learning_rate": 0.07438454174451613,
      "loss": 0.8821,
      "step": 158880
    },
    {
      "epoch": 256.29,
      "learning_rate": 0.07438131594129033,
      "loss": 0.8882,
      "step": 158900
    },
    {
      "epoch": 256.32,
      "learning_rate": 0.07437809013806451,
      "loss": 0.8971,
      "step": 158920
    },
    {
      "epoch": 256.35,
      "learning_rate": 0.07437486433483873,
      "loss": 0.8893,
      "step": 158940
    },
    {
      "epoch": 256.39,
      "learning_rate": 0.07437163853161291,
      "loss": 0.8927,
      "step": 158960
    },
    {
      "epoch": 256.42,
      "learning_rate": 0.0743684127283871,
      "loss": 0.9387,
      "step": 158980
    },
    {
      "epoch": 256.45,
      "learning_rate": 0.0743651869251613,
      "loss": 0.9292,
      "step": 159000
    },
    {
      "epoch": 256.48,
      "learning_rate": 0.0743619611219355,
      "loss": 0.9057,
      "step": 159020
    },
    {
      "epoch": 256.52,
      "learning_rate": 0.07435873531870968,
      "loss": 0.9063,
      "step": 159040
    },
    {
      "epoch": 256.55,
      "learning_rate": 0.07435550951548388,
      "loss": 0.8995,
      "step": 159060
    },
    {
      "epoch": 256.58,
      "learning_rate": 0.07435228371225808,
      "loss": 0.8847,
      "step": 159080
    },
    {
      "epoch": 256.61,
      "learning_rate": 0.07434905790903226,
      "loss": 0.8824,
      "step": 159100
    },
    {
      "epoch": 256.65,
      "learning_rate": 0.07434583210580646,
      "loss": 0.8837,
      "step": 159120
    },
    {
      "epoch": 256.68,
      "learning_rate": 0.07434260630258065,
      "loss": 0.8989,
      "step": 159140
    },
    {
      "epoch": 256.71,
      "learning_rate": 0.07433938049935485,
      "loss": 0.9128,
      "step": 159160
    },
    {
      "epoch": 256.74,
      "learning_rate": 0.07433615469612903,
      "loss": 0.9155,
      "step": 159180
    },
    {
      "epoch": 256.77,
      "learning_rate": 0.07433292889290323,
      "loss": 0.888,
      "step": 159200
    },
    {
      "epoch": 256.81,
      "learning_rate": 0.07432970308967742,
      "loss": 0.8878,
      "step": 159220
    },
    {
      "epoch": 256.84,
      "learning_rate": 0.07432647728645163,
      "loss": 0.9387,
      "step": 159240
    },
    {
      "epoch": 256.87,
      "learning_rate": 0.07432325148322581,
      "loss": 0.8991,
      "step": 159260
    },
    {
      "epoch": 256.9,
      "learning_rate": 0.07432002568000001,
      "loss": 0.8864,
      "step": 159280
    },
    {
      "epoch": 256.94,
      "learning_rate": 0.0743167998767742,
      "loss": 0.921,
      "step": 159300
    },
    {
      "epoch": 256.97,
      "learning_rate": 0.0743135740735484,
      "loss": 0.9255,
      "step": 159320
    },
    {
      "epoch": 257.0,
      "learning_rate": 0.07431034827032258,
      "loss": 0.8911,
      "step": 159340
    },
    {
      "epoch": 257.0,
      "eval_accuracy": {
        "accuracy": 0.7456872999765827
      },
      "eval_loss": 1.2988520860671997,
      "eval_runtime": 2.7484,
      "eval_samples_per_second": 4661.255,
      "eval_steps_per_second": 73.133,
      "step": 159340
    },
    {
      "epoch": 257.03,
      "learning_rate": 0.07430712246709678,
      "loss": 0.9313,
      "step": 159360
    },
    {
      "epoch": 257.06,
      "learning_rate": 0.07430389666387098,
      "loss": 0.9084,
      "step": 159380
    },
    {
      "epoch": 257.1,
      "learning_rate": 0.07430067086064517,
      "loss": 0.8811,
      "step": 159400
    },
    {
      "epoch": 257.13,
      "learning_rate": 0.07429744505741936,
      "loss": 0.8531,
      "step": 159420
    },
    {
      "epoch": 257.16,
      "learning_rate": 0.07429421925419355,
      "loss": 0.8692,
      "step": 159440
    },
    {
      "epoch": 257.19,
      "learning_rate": 0.07429099345096775,
      "loss": 0.8828,
      "step": 159460
    },
    {
      "epoch": 257.23,
      "learning_rate": 0.07428776764774193,
      "loss": 0.8994,
      "step": 159480
    },
    {
      "epoch": 257.26,
      "learning_rate": 0.07428454184451613,
      "loss": 0.8824,
      "step": 159500
    },
    {
      "epoch": 257.29,
      "learning_rate": 0.07428131604129032,
      "loss": 0.8945,
      "step": 159520
    },
    {
      "epoch": 257.32,
      "learning_rate": 0.07427809023806453,
      "loss": 0.8827,
      "step": 159540
    },
    {
      "epoch": 257.35,
      "learning_rate": 0.07427486443483872,
      "loss": 0.9193,
      "step": 159560
    },
    {
      "epoch": 257.39,
      "learning_rate": 0.07427163863161292,
      "loss": 0.9086,
      "step": 159580
    },
    {
      "epoch": 257.42,
      "learning_rate": 0.0742684128283871,
      "loss": 0.8884,
      "step": 159600
    },
    {
      "epoch": 257.45,
      "learning_rate": 0.0742651870251613,
      "loss": 0.9444,
      "step": 159620
    },
    {
      "epoch": 257.48,
      "learning_rate": 0.07426196122193549,
      "loss": 0.9249,
      "step": 159640
    },
    {
      "epoch": 257.52,
      "learning_rate": 0.07425873541870968,
      "loss": 0.8997,
      "step": 159660
    },
    {
      "epoch": 257.55,
      "learning_rate": 0.07425550961548387,
      "loss": 0.9038,
      "step": 159680
    },
    {
      "epoch": 257.58,
      "learning_rate": 0.07425228381225807,
      "loss": 0.8918,
      "step": 159700
    },
    {
      "epoch": 257.61,
      "learning_rate": 0.07424905800903227,
      "loss": 0.884,
      "step": 159720
    },
    {
      "epoch": 257.65,
      "learning_rate": 0.07424583220580645,
      "loss": 0.8914,
      "step": 159740
    },
    {
      "epoch": 257.68,
      "learning_rate": 0.07424260640258065,
      "loss": 0.8838,
      "step": 159760
    },
    {
      "epoch": 257.71,
      "learning_rate": 0.07423938059935484,
      "loss": 0.9029,
      "step": 159780
    },
    {
      "epoch": 257.74,
      "learning_rate": 0.07423615479612904,
      "loss": 0.9199,
      "step": 159800
    },
    {
      "epoch": 257.77,
      "learning_rate": 0.07423292899290322,
      "loss": 0.9221,
      "step": 159820
    },
    {
      "epoch": 257.81,
      "learning_rate": 0.07422970318967743,
      "loss": 0.9295,
      "step": 159840
    },
    {
      "epoch": 257.84,
      "learning_rate": 0.07422647738645162,
      "loss": 0.9198,
      "step": 159860
    },
    {
      "epoch": 257.87,
      "learning_rate": 0.07422325158322582,
      "loss": 0.8869,
      "step": 159880
    },
    {
      "epoch": 257.9,
      "learning_rate": 0.07422002578,
      "loss": 0.8819,
      "step": 159900
    },
    {
      "epoch": 257.94,
      "learning_rate": 0.07421679997677419,
      "loss": 0.9244,
      "step": 159920
    },
    {
      "epoch": 257.97,
      "learning_rate": 0.07421357417354839,
      "loss": 0.9423,
      "step": 159940
    },
    {
      "epoch": 258.0,
      "learning_rate": 0.07421034837032259,
      "loss": 0.9022,
      "step": 159960
    },
    {
      "epoch": 258.0,
      "eval_accuracy": {
        "accuracy": 0.7452189524627273
      },
      "eval_loss": 1.2471469640731812,
      "eval_runtime": 2.6795,
      "eval_samples_per_second": 4781.182,
      "eval_steps_per_second": 75.015,
      "step": 159960
    },
    {
      "epoch": 258.03,
      "learning_rate": 0.07420712256709677,
      "loss": 0.874,
      "step": 159980
    },
    {
      "epoch": 258.06,
      "learning_rate": 0.07420389676387097,
      "loss": 0.861,
      "step": 160000
    },
    {
      "epoch": 258.1,
      "learning_rate": 0.07420067096064517,
      "loss": 0.8576,
      "step": 160020
    },
    {
      "epoch": 258.13,
      "learning_rate": 0.07419744515741936,
      "loss": 0.8784,
      "step": 160040
    },
    {
      "epoch": 258.16,
      "learning_rate": 0.07419421935419356,
      "loss": 0.9253,
      "step": 160060
    },
    {
      "epoch": 258.19,
      "learning_rate": 0.07419099355096774,
      "loss": 0.9242,
      "step": 160080
    },
    {
      "epoch": 258.23,
      "learning_rate": 0.07418776774774194,
      "loss": 0.8917,
      "step": 160100
    },
    {
      "epoch": 258.26,
      "learning_rate": 0.07418454194451612,
      "loss": 0.8828,
      "step": 160120
    },
    {
      "epoch": 258.29,
      "learning_rate": 0.07418131614129034,
      "loss": 0.8836,
      "step": 160140
    },
    {
      "epoch": 258.32,
      "learning_rate": 0.07417809033806452,
      "loss": 0.881,
      "step": 160160
    },
    {
      "epoch": 258.35,
      "learning_rate": 0.07417486453483872,
      "loss": 0.9158,
      "step": 160180
    },
    {
      "epoch": 258.39,
      "learning_rate": 0.07417163873161291,
      "loss": 0.893,
      "step": 160200
    },
    {
      "epoch": 258.42,
      "learning_rate": 0.07416841292838709,
      "loss": 0.8819,
      "step": 160220
    },
    {
      "epoch": 258.45,
      "learning_rate": 0.07416518712516129,
      "loss": 0.9067,
      "step": 160240
    },
    {
      "epoch": 258.48,
      "learning_rate": 0.07416196132193549,
      "loss": 0.8856,
      "step": 160260
    },
    {
      "epoch": 258.52,
      "learning_rate": 0.07415873551870968,
      "loss": 0.9012,
      "step": 160280
    },
    {
      "epoch": 258.55,
      "learning_rate": 0.07415550971548387,
      "loss": 0.9412,
      "step": 160300
    },
    {
      "epoch": 258.58,
      "learning_rate": 0.07415228391225807,
      "loss": 0.9383,
      "step": 160320
    },
    {
      "epoch": 258.61,
      "learning_rate": 0.07414905810903226,
      "loss": 0.9333,
      "step": 160340
    },
    {
      "epoch": 258.65,
      "learning_rate": 0.07414583230580646,
      "loss": 0.897,
      "step": 160360
    },
    {
      "epoch": 258.68,
      "learning_rate": 0.07414260650258064,
      "loss": 0.8863,
      "step": 160380
    },
    {
      "epoch": 258.71,
      "learning_rate": 0.07413954198951614,
      "loss": 0.9176,
      "step": 160400
    },
    {
      "epoch": 258.74,
      "learning_rate": 0.07413631618629032,
      "loss": 0.9029,
      "step": 160420
    },
    {
      "epoch": 258.77,
      "learning_rate": 0.07413309038306452,
      "loss": 0.9271,
      "step": 160440
    },
    {
      "epoch": 258.81,
      "learning_rate": 0.07412986457983872,
      "loss": 0.9248,
      "step": 160460
    },
    {
      "epoch": 258.84,
      "learning_rate": 0.07412663877661291,
      "loss": 0.9393,
      "step": 160480
    },
    {
      "epoch": 258.87,
      "learning_rate": 0.0741234129733871,
      "loss": 0.9296,
      "step": 160500
    },
    {
      "epoch": 258.9,
      "learning_rate": 0.07412018717016129,
      "loss": 0.912,
      "step": 160520
    },
    {
      "epoch": 258.94,
      "learning_rate": 0.07411696136693549,
      "loss": 0.8998,
      "step": 160540
    },
    {
      "epoch": 258.97,
      "learning_rate": 0.07411373556370968,
      "loss": 0.8918,
      "step": 160560
    },
    {
      "epoch": 259.0,
      "learning_rate": 0.07411050976048388,
      "loss": 0.8855,
      "step": 160580
    },
    {
      "epoch": 259.0,
      "eval_accuracy": {
        "accuracy": 0.7390523768636328
      },
      "eval_loss": 1.2812566757202148,
      "eval_runtime": 2.6941,
      "eval_samples_per_second": 4755.225,
      "eval_steps_per_second": 74.608,
      "step": 160580
    },
    {
      "epoch": 259.03,
      "learning_rate": 0.07410728395725806,
      "loss": 0.9394,
      "step": 160600
    },
    {
      "epoch": 259.06,
      "learning_rate": 0.07410405815403227,
      "loss": 0.8958,
      "step": 160620
    },
    {
      "epoch": 259.1,
      "learning_rate": 0.07410083235080646,
      "loss": 0.8608,
      "step": 160640
    },
    {
      "epoch": 259.13,
      "learning_rate": 0.07409760654758066,
      "loss": 0.8573,
      "step": 160660
    },
    {
      "epoch": 259.16,
      "learning_rate": 0.07409438074435484,
      "loss": 0.8932,
      "step": 160680
    },
    {
      "epoch": 259.19,
      "learning_rate": 0.07409115494112904,
      "loss": 0.8952,
      "step": 160700
    },
    {
      "epoch": 259.23,
      "learning_rate": 0.07408792913790323,
      "loss": 0.8887,
      "step": 160720
    },
    {
      "epoch": 259.26,
      "learning_rate": 0.07408470333467743,
      "loss": 0.9066,
      "step": 160740
    },
    {
      "epoch": 259.29,
      "learning_rate": 0.07408147753145161,
      "loss": 0.9395,
      "step": 160760
    },
    {
      "epoch": 259.32,
      "learning_rate": 0.07407825172822581,
      "loss": 0.9062,
      "step": 160780
    },
    {
      "epoch": 259.35,
      "learning_rate": 0.07407502592500001,
      "loss": 0.8928,
      "step": 160800
    },
    {
      "epoch": 259.39,
      "learning_rate": 0.0740718001217742,
      "loss": 0.9073,
      "step": 160820
    },
    {
      "epoch": 259.42,
      "learning_rate": 0.0740685743185484,
      "loss": 0.8773,
      "step": 160840
    },
    {
      "epoch": 259.45,
      "learning_rate": 0.07406534851532258,
      "loss": 0.8741,
      "step": 160860
    },
    {
      "epoch": 259.48,
      "learning_rate": 0.07406212271209678,
      "loss": 0.8897,
      "step": 160880
    },
    {
      "epoch": 259.52,
      "learning_rate": 0.07405889690887096,
      "loss": 0.8945,
      "step": 160900
    },
    {
      "epoch": 259.55,
      "learning_rate": 0.07405567110564518,
      "loss": 0.9148,
      "step": 160920
    },
    {
      "epoch": 259.58,
      "learning_rate": 0.07405244530241936,
      "loss": 0.8718,
      "step": 160940
    },
    {
      "epoch": 259.61,
      "learning_rate": 0.07404921949919356,
      "loss": 0.8858,
      "step": 160960
    },
    {
      "epoch": 259.65,
      "learning_rate": 0.07404599369596775,
      "loss": 0.8854,
      "step": 160980
    },
    {
      "epoch": 259.68,
      "learning_rate": 0.07404276789274195,
      "loss": 0.8957,
      "step": 161000
    },
    {
      "epoch": 259.71,
      "learning_rate": 0.07403954208951613,
      "loss": 0.9013,
      "step": 161020
    },
    {
      "epoch": 259.74,
      "learning_rate": 0.07403631628629033,
      "loss": 0.8804,
      "step": 161040
    },
    {
      "epoch": 259.77,
      "learning_rate": 0.07403309048306451,
      "loss": 0.8836,
      "step": 161060
    },
    {
      "epoch": 259.81,
      "learning_rate": 0.07402986467983871,
      "loss": 0.8922,
      "step": 161080
    },
    {
      "epoch": 259.84,
      "learning_rate": 0.07402663887661291,
      "loss": 0.9121,
      "step": 161100
    },
    {
      "epoch": 259.87,
      "learning_rate": 0.0740234130733871,
      "loss": 0.9239,
      "step": 161120
    },
    {
      "epoch": 259.9,
      "learning_rate": 0.0740201872701613,
      "loss": 0.8969,
      "step": 161140
    },
    {
      "epoch": 259.94,
      "learning_rate": 0.07401696146693548,
      "loss": 0.9187,
      "step": 161160
    },
    {
      "epoch": 259.97,
      "learning_rate": 0.07401373566370968,
      "loss": 0.9138,
      "step": 161180
    },
    {
      "epoch": 260.0,
      "learning_rate": 0.07401050986048387,
      "loss": 0.901,
      "step": 161200
    },
    {
      "epoch": 260.0,
      "eval_accuracy": {
        "accuracy": 0.7384279135118258
      },
      "eval_loss": 1.2911009788513184,
      "eval_runtime": 2.925,
      "eval_samples_per_second": 4379.891,
      "eval_steps_per_second": 68.719,
      "step": 161200
    },
    {
      "epoch": 260.03,
      "learning_rate": 0.07400728405725808,
      "loss": 0.9416,
      "step": 161220
    },
    {
      "epoch": 260.06,
      "learning_rate": 0.07400405825403227,
      "loss": 0.9096,
      "step": 161240
    },
    {
      "epoch": 260.1,
      "learning_rate": 0.07400083245080646,
      "loss": 0.8743,
      "step": 161260
    },
    {
      "epoch": 260.13,
      "learning_rate": 0.07399760664758065,
      "loss": 0.8571,
      "step": 161280
    },
    {
      "epoch": 260.16,
      "learning_rate": 0.07399438084435483,
      "loss": 0.9026,
      "step": 161300
    },
    {
      "epoch": 260.19,
      "learning_rate": 0.07399115504112903,
      "loss": 0.9052,
      "step": 161320
    },
    {
      "epoch": 260.23,
      "learning_rate": 0.07398792923790323,
      "loss": 0.884,
      "step": 161340
    },
    {
      "epoch": 260.26,
      "learning_rate": 0.07398470343467742,
      "loss": 0.8722,
      "step": 161360
    },
    {
      "epoch": 260.29,
      "learning_rate": 0.07398147763145162,
      "loss": 0.8754,
      "step": 161380
    },
    {
      "epoch": 260.32,
      "learning_rate": 0.07397825182822582,
      "loss": 0.8587,
      "step": 161400
    },
    {
      "epoch": 260.35,
      "learning_rate": 0.073975026025,
      "loss": 0.8689,
      "step": 161420
    },
    {
      "epoch": 260.39,
      "learning_rate": 0.0739718002217742,
      "loss": 0.8866,
      "step": 161440
    },
    {
      "epoch": 260.42,
      "learning_rate": 0.07396857441854839,
      "loss": 0.9042,
      "step": 161460
    },
    {
      "epoch": 260.45,
      "learning_rate": 0.07396534861532258,
      "loss": 0.9265,
      "step": 161480
    },
    {
      "epoch": 260.48,
      "learning_rate": 0.07396212281209677,
      "loss": 0.9248,
      "step": 161500
    },
    {
      "epoch": 260.52,
      "learning_rate": 0.07395889700887098,
      "loss": 0.9008,
      "step": 161520
    },
    {
      "epoch": 260.55,
      "learning_rate": 0.07395567120564515,
      "loss": 0.8905,
      "step": 161540
    },
    {
      "epoch": 260.58,
      "learning_rate": 0.07395244540241937,
      "loss": 0.8848,
      "step": 161560
    },
    {
      "epoch": 260.61,
      "learning_rate": 0.07394921959919355,
      "loss": 0.9013,
      "step": 161580
    },
    {
      "epoch": 260.65,
      "learning_rate": 0.07394599379596775,
      "loss": 0.924,
      "step": 161600
    },
    {
      "epoch": 260.68,
      "learning_rate": 0.07394276799274194,
      "loss": 0.9481,
      "step": 161620
    },
    {
      "epoch": 260.71,
      "learning_rate": 0.07393954218951614,
      "loss": 0.9047,
      "step": 161640
    },
    {
      "epoch": 260.74,
      "learning_rate": 0.07393631638629032,
      "loss": 0.9093,
      "step": 161660
    },
    {
      "epoch": 260.77,
      "learning_rate": 0.07393309058306452,
      "loss": 0.9038,
      "step": 161680
    },
    {
      "epoch": 260.81,
      "learning_rate": 0.07392986477983872,
      "loss": 0.8873,
      "step": 161700
    },
    {
      "epoch": 260.84,
      "learning_rate": 0.0739266389766129,
      "loss": 0.9215,
      "step": 161720
    },
    {
      "epoch": 260.87,
      "learning_rate": 0.0739234131733871,
      "loss": 0.927,
      "step": 161740
    },
    {
      "epoch": 260.9,
      "learning_rate": 0.07392018737016129,
      "loss": 0.9054,
      "step": 161760
    },
    {
      "epoch": 260.94,
      "learning_rate": 0.07391696156693549,
      "loss": 0.8768,
      "step": 161780
    },
    {
      "epoch": 260.97,
      "learning_rate": 0.07391373576370967,
      "loss": 0.8612,
      "step": 161800
    },
    {
      "epoch": 261.0,
      "learning_rate": 0.07391050996048389,
      "loss": 0.9117,
      "step": 161820
    },
    {
      "epoch": 261.0,
      "eval_accuracy": {
        "accuracy": 0.7458434158145344
      },
      "eval_loss": 1.2901347875595093,
      "eval_runtime": 2.9251,
      "eval_samples_per_second": 4379.617,
      "eval_steps_per_second": 68.715,
      "step": 161820
    },
    {
      "epoch": 261.03,
      "learning_rate": 0.07390728415725806,
      "loss": 0.9301,
      "step": 161840
    },
    {
      "epoch": 261.06,
      "learning_rate": 0.07390405835403227,
      "loss": 0.8985,
      "step": 161860
    },
    {
      "epoch": 261.1,
      "learning_rate": 0.07390083255080646,
      "loss": 0.8968,
      "step": 161880
    },
    {
      "epoch": 261.13,
      "learning_rate": 0.07389760674758065,
      "loss": 0.8645,
      "step": 161900
    },
    {
      "epoch": 261.16,
      "learning_rate": 0.07389438094435484,
      "loss": 0.9022,
      "step": 161920
    },
    {
      "epoch": 261.19,
      "learning_rate": 0.07389115514112904,
      "loss": 0.9036,
      "step": 161940
    },
    {
      "epoch": 261.23,
      "learning_rate": 0.07388792933790322,
      "loss": 0.93,
      "step": 161960
    },
    {
      "epoch": 261.26,
      "learning_rate": 0.07388470353467742,
      "loss": 0.9094,
      "step": 161980
    },
    {
      "epoch": 261.29,
      "learning_rate": 0.07388147773145162,
      "loss": 0.8656,
      "step": 162000
    },
    {
      "epoch": 261.32,
      "learning_rate": 0.07387825192822581,
      "loss": 0.8652,
      "step": 162020
    },
    {
      "epoch": 261.35,
      "learning_rate": 0.073875026125,
      "loss": 0.891,
      "step": 162040
    },
    {
      "epoch": 261.39,
      "learning_rate": 0.0738718003217742,
      "loss": 0.8762,
      "step": 162060
    },
    {
      "epoch": 261.42,
      "learning_rate": 0.07386857451854839,
      "loss": 0.8776,
      "step": 162080
    },
    {
      "epoch": 261.45,
      "learning_rate": 0.07386534871532258,
      "loss": 0.8826,
      "step": 162100
    },
    {
      "epoch": 261.48,
      "learning_rate": 0.07386212291209679,
      "loss": 0.8727,
      "step": 162120
    },
    {
      "epoch": 261.52,
      "learning_rate": 0.07385889710887096,
      "loss": 0.8958,
      "step": 162140
    },
    {
      "epoch": 261.55,
      "learning_rate": 0.07385567130564517,
      "loss": 0.8975,
      "step": 162160
    },
    {
      "epoch": 261.58,
      "learning_rate": 0.07385244550241936,
      "loss": 0.8698,
      "step": 162180
    },
    {
      "epoch": 261.61,
      "learning_rate": 0.07384921969919356,
      "loss": 0.8971,
      "step": 162200
    },
    {
      "epoch": 261.65,
      "learning_rate": 0.07384599389596774,
      "loss": 0.8959,
      "step": 162220
    },
    {
      "epoch": 261.68,
      "learning_rate": 0.07384276809274194,
      "loss": 0.9082,
      "step": 162240
    },
    {
      "epoch": 261.71,
      "learning_rate": 0.07383954228951613,
      "loss": 0.9062,
      "step": 162260
    },
    {
      "epoch": 261.74,
      "learning_rate": 0.07383631648629033,
      "loss": 0.9052,
      "step": 162280
    },
    {
      "epoch": 261.77,
      "learning_rate": 0.07383309068306453,
      "loss": 0.9033,
      "step": 162300
    },
    {
      "epoch": 261.81,
      "learning_rate": 0.07382986487983871,
      "loss": 0.9008,
      "step": 162320
    },
    {
      "epoch": 261.84,
      "learning_rate": 0.07382663907661291,
      "loss": 0.8937,
      "step": 162340
    },
    {
      "epoch": 261.87,
      "learning_rate": 0.07382341327338711,
      "loss": 0.8745,
      "step": 162360
    },
    {
      "epoch": 261.9,
      "learning_rate": 0.0738201874701613,
      "loss": 0.899,
      "step": 162380
    },
    {
      "epoch": 261.94,
      "learning_rate": 0.07381696166693548,
      "loss": 0.9048,
      "step": 162400
    },
    {
      "epoch": 261.97,
      "learning_rate": 0.07381373586370969,
      "loss": 0.9191,
      "step": 162420
    },
    {
      "epoch": 262.0,
      "learning_rate": 0.07381051006048386,
      "loss": 0.8753,
      "step": 162440
    },
    {
      "epoch": 262.0,
      "eval_accuracy": {
        "accuracy": 0.7427991569744751
      },
      "eval_loss": 1.2755517959594727,
      "eval_runtime": 2.9565,
      "eval_samples_per_second": 4333.108,
      "eval_steps_per_second": 67.985,
      "step": 162440
    },
    {
      "epoch": 262.03,
      "learning_rate": 0.07380728425725808,
      "loss": 0.9139,
      "step": 162460
    },
    {
      "epoch": 262.06,
      "learning_rate": 0.07380405845403226,
      "loss": 0.8905,
      "step": 162480
    },
    {
      "epoch": 262.1,
      "learning_rate": 0.07380083265080646,
      "loss": 0.8721,
      "step": 162500
    },
    {
      "epoch": 262.13,
      "learning_rate": 0.07379760684758065,
      "loss": 0.9,
      "step": 162520
    },
    {
      "epoch": 262.16,
      "learning_rate": 0.07379438104435485,
      "loss": 0.8934,
      "step": 162540
    },
    {
      "epoch": 262.19,
      "learning_rate": 0.07379115524112903,
      "loss": 0.8822,
      "step": 162560
    },
    {
      "epoch": 262.23,
      "learning_rate": 0.07378792943790323,
      "loss": 0.868,
      "step": 162580
    },
    {
      "epoch": 262.26,
      "learning_rate": 0.07378470363467743,
      "loss": 0.8722,
      "step": 162600
    },
    {
      "epoch": 262.29,
      "learning_rate": 0.07378147783145161,
      "loss": 0.8773,
      "step": 162620
    },
    {
      "epoch": 262.32,
      "learning_rate": 0.07377825202822581,
      "loss": 0.8576,
      "step": 162640
    },
    {
      "epoch": 262.35,
      "learning_rate": 0.07377502622500001,
      "loss": 0.8788,
      "step": 162660
    },
    {
      "epoch": 262.39,
      "learning_rate": 0.0737718004217742,
      "loss": 0.9067,
      "step": 162680
    },
    {
      "epoch": 262.42,
      "learning_rate": 0.07376857461854838,
      "loss": 0.867,
      "step": 162700
    },
    {
      "epoch": 262.45,
      "learning_rate": 0.0737653488153226,
      "loss": 0.9024,
      "step": 162720
    },
    {
      "epoch": 262.48,
      "learning_rate": 0.07376212301209677,
      "loss": 0.9038,
      "step": 162740
    },
    {
      "epoch": 262.52,
      "learning_rate": 0.07375889720887098,
      "loss": 0.904,
      "step": 162760
    },
    {
      "epoch": 262.55,
      "learning_rate": 0.07375567140564517,
      "loss": 0.9049,
      "step": 162780
    },
    {
      "epoch": 262.58,
      "learning_rate": 0.07375244560241936,
      "loss": 0.8874,
      "step": 162800
    },
    {
      "epoch": 262.61,
      "learning_rate": 0.07374921979919355,
      "loss": 0.8758,
      "step": 162820
    },
    {
      "epoch": 262.65,
      "learning_rate": 0.07374599399596775,
      "loss": 0.9041,
      "step": 162840
    },
    {
      "epoch": 262.68,
      "learning_rate": 0.07374276819274193,
      "loss": 0.9148,
      "step": 162860
    },
    {
      "epoch": 262.71,
      "learning_rate": 0.07373954238951613,
      "loss": 0.8835,
      "step": 162880
    },
    {
      "epoch": 262.74,
      "learning_rate": 0.07373631658629033,
      "loss": 0.9028,
      "step": 162900
    },
    {
      "epoch": 262.77,
      "learning_rate": 0.07373309078306452,
      "loss": 0.8907,
      "step": 162920
    },
    {
      "epoch": 262.81,
      "learning_rate": 0.07372986497983872,
      "loss": 0.8909,
      "step": 162940
    },
    {
      "epoch": 262.84,
      "learning_rate": 0.07372663917661292,
      "loss": 0.9117,
      "step": 162960
    },
    {
      "epoch": 262.87,
      "learning_rate": 0.0737234133733871,
      "loss": 0.9381,
      "step": 162980
    },
    {
      "epoch": 262.9,
      "learning_rate": 0.0737201875701613,
      "loss": 0.9195,
      "step": 163000
    },
    {
      "epoch": 262.94,
      "learning_rate": 0.0737169617669355,
      "loss": 0.9222,
      "step": 163020
    },
    {
      "epoch": 262.97,
      "learning_rate": 0.07371373596370967,
      "loss": 0.9106,
      "step": 163040
    },
    {
      "epoch": 263.0,
      "learning_rate": 0.07371067145064517,
      "loss": 0.9182,
      "step": 163060
    },
    {
      "epoch": 263.0,
      "eval_accuracy": {
        "accuracy": 0.7488876746545937
      },
      "eval_loss": 1.2366660833358765,
      "eval_runtime": 2.9148,
      "eval_samples_per_second": 4395.171,
      "eval_steps_per_second": 68.959,
      "step": 163060
    },
    {
      "epoch": 263.03,
      "learning_rate": 0.07370744564741936,
      "loss": 0.8704,
      "step": 163080
    },
    {
      "epoch": 263.06,
      "learning_rate": 0.07370421984419355,
      "loss": 0.8731,
      "step": 163100
    },
    {
      "epoch": 263.1,
      "learning_rate": 0.07370099404096775,
      "loss": 0.851,
      "step": 163120
    },
    {
      "epoch": 263.13,
      "learning_rate": 0.07369776823774195,
      "loss": 0.8572,
      "step": 163140
    },
    {
      "epoch": 263.16,
      "learning_rate": 0.07369454243451613,
      "loss": 0.8602,
      "step": 163160
    },
    {
      "epoch": 263.19,
      "learning_rate": 0.07369131663129032,
      "loss": 0.8999,
      "step": 163180
    },
    {
      "epoch": 263.23,
      "learning_rate": 0.07368809082806453,
      "loss": 0.8977,
      "step": 163200
    },
    {
      "epoch": 263.26,
      "learning_rate": 0.0736848650248387,
      "loss": 0.8777,
      "step": 163220
    },
    {
      "epoch": 263.29,
      "learning_rate": 0.07368163922161292,
      "loss": 0.8812,
      "step": 163240
    },
    {
      "epoch": 263.32,
      "learning_rate": 0.0736784134183871,
      "loss": 0.8747,
      "step": 163260
    },
    {
      "epoch": 263.35,
      "learning_rate": 0.0736751876151613,
      "loss": 0.8667,
      "step": 163280
    },
    {
      "epoch": 263.39,
      "learning_rate": 0.07367196181193549,
      "loss": 0.8946,
      "step": 163300
    },
    {
      "epoch": 263.42,
      "learning_rate": 0.07366873600870968,
      "loss": 0.9212,
      "step": 163320
    },
    {
      "epoch": 263.45,
      "learning_rate": 0.07366551020548387,
      "loss": 0.9142,
      "step": 163340
    },
    {
      "epoch": 263.48,
      "learning_rate": 0.07366228440225807,
      "loss": 0.8968,
      "step": 163360
    },
    {
      "epoch": 263.52,
      "learning_rate": 0.07365905859903227,
      "loss": 0.8856,
      "step": 163380
    },
    {
      "epoch": 263.55,
      "learning_rate": 0.07365583279580645,
      "loss": 0.8691,
      "step": 163400
    },
    {
      "epoch": 263.58,
      "learning_rate": 0.07365260699258065,
      "loss": 0.868,
      "step": 163420
    },
    {
      "epoch": 263.61,
      "learning_rate": 0.07364938118935485,
      "loss": 0.8787,
      "step": 163440
    },
    {
      "epoch": 263.65,
      "learning_rate": 0.07364615538612904,
      "loss": 0.8605,
      "step": 163460
    },
    {
      "epoch": 263.68,
      "learning_rate": 0.07364292958290322,
      "loss": 0.8587,
      "step": 163480
    },
    {
      "epoch": 263.71,
      "learning_rate": 0.07363970377967743,
      "loss": 0.9013,
      "step": 163500
    },
    {
      "epoch": 263.74,
      "learning_rate": 0.0736364779764516,
      "loss": 0.9185,
      "step": 163520
    },
    {
      "epoch": 263.77,
      "learning_rate": 0.07363325217322582,
      "loss": 0.9027,
      "step": 163540
    },
    {
      "epoch": 263.81,
      "learning_rate": 0.07363002637,
      "loss": 0.9219,
      "step": 163560
    },
    {
      "epoch": 263.84,
      "learning_rate": 0.0736268005667742,
      "loss": 0.8876,
      "step": 163580
    },
    {
      "epoch": 263.87,
      "learning_rate": 0.07362357476354839,
      "loss": 0.9461,
      "step": 163600
    },
    {
      "epoch": 263.9,
      "learning_rate": 0.07362034896032259,
      "loss": 0.9151,
      "step": 163620
    },
    {
      "epoch": 263.94,
      "learning_rate": 0.07361712315709677,
      "loss": 0.9353,
      "step": 163640
    },
    {
      "epoch": 263.97,
      "learning_rate": 0.07361389735387097,
      "loss": 0.9034,
      "step": 163660
    },
    {
      "epoch": 264.0,
      "learning_rate": 0.07361067155064517,
      "loss": 0.9294,
      "step": 163680
    },
    {
      "epoch": 264.0,
      "eval_accuracy": {
        "accuracy": 0.7442822574350167
      },
      "eval_loss": 1.2960220575332642,
      "eval_runtime": 2.7865,
      "eval_samples_per_second": 4597.587,
      "eval_steps_per_second": 72.134,
      "step": 163680
    },
    {
      "epoch": 264.03,
      "learning_rate": 0.07360744574741936,
      "loss": 0.9654,
      "step": 163700
    },
    {
      "epoch": 264.06,
      "learning_rate": 0.07360421994419356,
      "loss": 0.9284,
      "step": 163720
    },
    {
      "epoch": 264.1,
      "learning_rate": 0.07360099414096775,
      "loss": 0.9085,
      "step": 163740
    },
    {
      "epoch": 264.13,
      "learning_rate": 0.07359776833774194,
      "loss": 0.8794,
      "step": 163760
    },
    {
      "epoch": 264.16,
      "learning_rate": 0.07359454253451612,
      "loss": 0.8655,
      "step": 163780
    },
    {
      "epoch": 264.19,
      "learning_rate": 0.07359131673129034,
      "loss": 0.8686,
      "step": 163800
    },
    {
      "epoch": 264.23,
      "learning_rate": 0.07358809092806451,
      "loss": 0.875,
      "step": 163820
    },
    {
      "epoch": 264.26,
      "learning_rate": 0.07358486512483872,
      "loss": 0.8512,
      "step": 163840
    },
    {
      "epoch": 264.29,
      "learning_rate": 0.07358163932161291,
      "loss": 0.8467,
      "step": 163860
    },
    {
      "epoch": 264.32,
      "learning_rate": 0.0735784135183871,
      "loss": 0.8513,
      "step": 163880
    },
    {
      "epoch": 264.35,
      "learning_rate": 0.07357518771516129,
      "loss": 0.8522,
      "step": 163900
    },
    {
      "epoch": 264.39,
      "learning_rate": 0.07357196191193549,
      "loss": 0.8668,
      "step": 163920
    },
    {
      "epoch": 264.42,
      "learning_rate": 0.07356873610870968,
      "loss": 0.8741,
      "step": 163940
    },
    {
      "epoch": 264.45,
      "learning_rate": 0.07356551030548387,
      "loss": 0.8951,
      "step": 163960
    },
    {
      "epoch": 264.48,
      "learning_rate": 0.07356228450225807,
      "loss": 0.8996,
      "step": 163980
    },
    {
      "epoch": 264.52,
      "learning_rate": 0.07355905869903226,
      "loss": 0.9075,
      "step": 164000
    },
    {
      "epoch": 264.55,
      "learning_rate": 0.07355583289580646,
      "loss": 0.9104,
      "step": 164020
    },
    {
      "epoch": 264.58,
      "learning_rate": 0.07355260709258066,
      "loss": 0.8879,
      "step": 164040
    },
    {
      "epoch": 264.61,
      "learning_rate": 0.07354938128935484,
      "loss": 0.9129,
      "step": 164060
    },
    {
      "epoch": 264.65,
      "learning_rate": 0.07354615548612903,
      "loss": 0.9053,
      "step": 164080
    },
    {
      "epoch": 264.68,
      "learning_rate": 0.07354292968290324,
      "loss": 0.9139,
      "step": 164100
    },
    {
      "epoch": 264.71,
      "learning_rate": 0.07353970387967741,
      "loss": 0.91,
      "step": 164120
    },
    {
      "epoch": 264.74,
      "learning_rate": 0.07353647807645163,
      "loss": 0.8871,
      "step": 164140
    },
    {
      "epoch": 264.77,
      "learning_rate": 0.07353325227322581,
      "loss": 0.9309,
      "step": 164160
    },
    {
      "epoch": 264.81,
      "learning_rate": 0.07353002647000001,
      "loss": 0.8802,
      "step": 164180
    },
    {
      "epoch": 264.84,
      "learning_rate": 0.0735268006667742,
      "loss": 0.9114,
      "step": 164200
    },
    {
      "epoch": 264.87,
      "learning_rate": 0.0735235748635484,
      "loss": 0.9161,
      "step": 164220
    },
    {
      "epoch": 264.9,
      "learning_rate": 0.07352034906032258,
      "loss": 0.9267,
      "step": 164240
    },
    {
      "epoch": 264.94,
      "learning_rate": 0.07351712325709678,
      "loss": 0.9116,
      "step": 164260
    },
    {
      "epoch": 264.97,
      "learning_rate": 0.07351389745387098,
      "loss": 0.9189,
      "step": 164280
    },
    {
      "epoch": 265.0,
      "learning_rate": 0.07351067165064516,
      "loss": 0.917,
      "step": 164300
    },
    {
      "epoch": 265.0,
      "eval_accuracy": {
        "accuracy": 0.7362422917805012
      },
      "eval_loss": 1.3136699199676514,
      "eval_runtime": 2.7581,
      "eval_samples_per_second": 4644.785,
      "eval_steps_per_second": 72.875,
      "step": 164300
    },
    {
      "epoch": 265.03,
      "learning_rate": 0.07350744584741936,
      "loss": 0.9308,
      "step": 164320
    },
    {
      "epoch": 265.06,
      "learning_rate": 0.07350422004419356,
      "loss": 0.8766,
      "step": 164340
    },
    {
      "epoch": 265.1,
      "learning_rate": 0.07350099424096775,
      "loss": 0.8825,
      "step": 164360
    },
    {
      "epoch": 265.13,
      "learning_rate": 0.07349776843774194,
      "loss": 0.8807,
      "step": 164380
    },
    {
      "epoch": 265.16,
      "learning_rate": 0.07349454263451614,
      "loss": 0.8508,
      "step": 164400
    },
    {
      "epoch": 265.19,
      "learning_rate": 0.07349131683129032,
      "loss": 0.8431,
      "step": 164420
    },
    {
      "epoch": 265.23,
      "learning_rate": 0.07348809102806453,
      "loss": 0.8875,
      "step": 164440
    },
    {
      "epoch": 265.26,
      "learning_rate": 0.07348486522483871,
      "loss": 0.8739,
      "step": 164460
    },
    {
      "epoch": 265.29,
      "learning_rate": 0.07348163942161291,
      "loss": 0.882,
      "step": 164480
    },
    {
      "epoch": 265.32,
      "learning_rate": 0.0734784136183871,
      "loss": 0.8718,
      "step": 164500
    },
    {
      "epoch": 265.35,
      "learning_rate": 0.0734751878151613,
      "loss": 0.8843,
      "step": 164520
    },
    {
      "epoch": 265.39,
      "learning_rate": 0.07347196201193548,
      "loss": 0.9124,
      "step": 164540
    },
    {
      "epoch": 265.42,
      "learning_rate": 0.07346873620870968,
      "loss": 0.8812,
      "step": 164560
    },
    {
      "epoch": 265.45,
      "learning_rate": 0.07346551040548388,
      "loss": 0.8958,
      "step": 164580
    },
    {
      "epoch": 265.48,
      "learning_rate": 0.07346228460225807,
      "loss": 0.8785,
      "step": 164600
    },
    {
      "epoch": 265.52,
      "learning_rate": 0.07345905879903226,
      "loss": 0.8879,
      "step": 164620
    },
    {
      "epoch": 265.55,
      "learning_rate": 0.07345583299580646,
      "loss": 0.8984,
      "step": 164640
    },
    {
      "epoch": 265.58,
      "learning_rate": 0.07345260719258065,
      "loss": 0.8759,
      "step": 164660
    },
    {
      "epoch": 265.61,
      "learning_rate": 0.07344938138935485,
      "loss": 0.8653,
      "step": 164680
    },
    {
      "epoch": 265.65,
      "learning_rate": 0.07344615558612903,
      "loss": 0.8771,
      "step": 164700
    },
    {
      "epoch": 265.68,
      "learning_rate": 0.07344292978290322,
      "loss": 0.8859,
      "step": 164720
    },
    {
      "epoch": 265.71,
      "learning_rate": 0.07343970397967743,
      "loss": 0.8816,
      "step": 164740
    },
    {
      "epoch": 265.74,
      "learning_rate": 0.07343647817645162,
      "loss": 0.8661,
      "step": 164760
    },
    {
      "epoch": 265.77,
      "learning_rate": 0.07343325237322582,
      "loss": 0.8884,
      "step": 164780
    },
    {
      "epoch": 265.81,
      "learning_rate": 0.07343002657,
      "loss": 0.8818,
      "step": 164800
    },
    {
      "epoch": 265.84,
      "learning_rate": 0.0734268007667742,
      "loss": 0.904,
      "step": 164820
    },
    {
      "epoch": 265.87,
      "learning_rate": 0.07342357496354839,
      "loss": 0.9278,
      "step": 164840
    },
    {
      "epoch": 265.9,
      "learning_rate": 0.07342034916032258,
      "loss": 0.9202,
      "step": 164860
    },
    {
      "epoch": 265.94,
      "learning_rate": 0.07341712335709678,
      "loss": 0.9278,
      "step": 164880
    },
    {
      "epoch": 265.97,
      "learning_rate": 0.07341389755387097,
      "loss": 0.9026,
      "step": 164900
    },
    {
      "epoch": 266.0,
      "learning_rate": 0.07341067175064517,
      "loss": 0.9036,
      "step": 164920
    },
    {
      "epoch": 266.0,
      "eval_accuracy": {
        "accuracy": 0.7464678791663414
      },
      "eval_loss": 1.2409439086914062,
      "eval_runtime": 2.9107,
      "eval_samples_per_second": 4401.302,
      "eval_steps_per_second": 69.055,
      "step": 164920
    },
    {
      "epoch": 266.03,
      "learning_rate": 0.07340744594741935,
      "loss": 0.8754,
      "step": 164940
    },
    {
      "epoch": 266.06,
      "learning_rate": 0.07340422014419355,
      "loss": 0.8756,
      "step": 164960
    },
    {
      "epoch": 266.1,
      "learning_rate": 0.07340099434096775,
      "loss": 0.8766,
      "step": 164980
    },
    {
      "epoch": 266.13,
      "learning_rate": 0.07339776853774194,
      "loss": 0.8842,
      "step": 165000
    },
    {
      "epoch": 266.16,
      "learning_rate": 0.07339454273451612,
      "loss": 0.8696,
      "step": 165020
    },
    {
      "epoch": 266.19,
      "learning_rate": 0.07339131693129033,
      "loss": 0.8718,
      "step": 165040
    },
    {
      "epoch": 266.23,
      "learning_rate": 0.07338809112806452,
      "loss": 0.8716,
      "step": 165060
    },
    {
      "epoch": 266.26,
      "learning_rate": 0.07338486532483872,
      "loss": 0.8677,
      "step": 165080
    },
    {
      "epoch": 266.29,
      "learning_rate": 0.0733816395216129,
      "loss": 0.8841,
      "step": 165100
    },
    {
      "epoch": 266.32,
      "learning_rate": 0.0733784137183871,
      "loss": 0.8792,
      "step": 165120
    },
    {
      "epoch": 266.35,
      "learning_rate": 0.07337518791516129,
      "loss": 0.8699,
      "step": 165140
    },
    {
      "epoch": 266.39,
      "learning_rate": 0.0733719621119355,
      "loss": 0.8564,
      "step": 165160
    },
    {
      "epoch": 266.42,
      "learning_rate": 0.07336873630870969,
      "loss": 0.8869,
      "step": 165180
    },
    {
      "epoch": 266.45,
      "learning_rate": 0.07336567179564515,
      "loss": 0.9111,
      "step": 165200
    },
    {
      "epoch": 266.48,
      "learning_rate": 0.07336244599241937,
      "loss": 0.9014,
      "step": 165220
    },
    {
      "epoch": 266.52,
      "learning_rate": 0.07335922018919355,
      "loss": 0.9087,
      "step": 165240
    },
    {
      "epoch": 266.55,
      "learning_rate": 0.07335599438596775,
      "loss": 0.9172,
      "step": 165260
    },
    {
      "epoch": 266.58,
      "learning_rate": 0.07335276858274194,
      "loss": 0.9261,
      "step": 165280
    },
    {
      "epoch": 266.61,
      "learning_rate": 0.07334954277951614,
      "loss": 0.9054,
      "step": 165300
    },
    {
      "epoch": 266.65,
      "learning_rate": 0.07334631697629032,
      "loss": 0.9035,
      "step": 165320
    },
    {
      "epoch": 266.68,
      "learning_rate": 0.07334309117306452,
      "loss": 0.8941,
      "step": 165340
    },
    {
      "epoch": 266.71,
      "learning_rate": 0.07333986536983872,
      "loss": 0.8861,
      "step": 165360
    },
    {
      "epoch": 266.74,
      "learning_rate": 0.0733366395666129,
      "loss": 0.9182,
      "step": 165380
    },
    {
      "epoch": 266.77,
      "learning_rate": 0.0733334137633871,
      "loss": 0.9042,
      "step": 165400
    },
    {
      "epoch": 266.81,
      "learning_rate": 0.0733301879601613,
      "loss": 0.8987,
      "step": 165420
    },
    {
      "epoch": 266.84,
      "learning_rate": 0.07332696215693549,
      "loss": 0.8834,
      "step": 165440
    },
    {
      "epoch": 266.87,
      "learning_rate": 0.07332373635370969,
      "loss": 0.9009,
      "step": 165460
    },
    {
      "epoch": 266.9,
      "learning_rate": 0.07332051055048389,
      "loss": 0.8947,
      "step": 165480
    },
    {
      "epoch": 266.94,
      "learning_rate": 0.07331728474725806,
      "loss": 0.9111,
      "step": 165500
    },
    {
      "epoch": 266.97,
      "learning_rate": 0.07331405894403227,
      "loss": 0.9232,
      "step": 165520
    },
    {
      "epoch": 267.0,
      "learning_rate": 0.07331083314080646,
      "loss": 0.9373,
      "step": 165540
    },
    {
      "epoch": 267.0,
      "eval_accuracy": {
        "accuracy": 0.7438139099211615
      },
      "eval_loss": 1.2731133699417114,
      "eval_runtime": 2.7789,
      "eval_samples_per_second": 4610.097,
      "eval_steps_per_second": 72.331,
      "step": 165540
    },
    {
      "epoch": 267.03,
      "learning_rate": 0.07330760733758065,
      "loss": 0.924,
      "step": 165560
    },
    {
      "epoch": 267.06,
      "learning_rate": 0.07330438153435484,
      "loss": 0.8937,
      "step": 165580
    },
    {
      "epoch": 267.1,
      "learning_rate": 0.07330115573112904,
      "loss": 0.8791,
      "step": 165600
    },
    {
      "epoch": 267.13,
      "learning_rate": 0.07329792992790322,
      "loss": 0.8794,
      "step": 165620
    },
    {
      "epoch": 267.16,
      "learning_rate": 0.07329470412467742,
      "loss": 0.8735,
      "step": 165640
    },
    {
      "epoch": 267.19,
      "learning_rate": 0.07329147832145162,
      "loss": 0.8797,
      "step": 165660
    },
    {
      "epoch": 267.23,
      "learning_rate": 0.07328825251822581,
      "loss": 0.8819,
      "step": 165680
    },
    {
      "epoch": 267.26,
      "learning_rate": 0.073285026715,
      "loss": 0.8905,
      "step": 165700
    },
    {
      "epoch": 267.29,
      "learning_rate": 0.0732818009117742,
      "loss": 0.8934,
      "step": 165720
    },
    {
      "epoch": 267.32,
      "learning_rate": 0.07327857510854839,
      "loss": 0.8951,
      "step": 165740
    },
    {
      "epoch": 267.35,
      "learning_rate": 0.07327534930532259,
      "loss": 0.8894,
      "step": 165760
    },
    {
      "epoch": 267.39,
      "learning_rate": 0.07327212350209678,
      "loss": 0.8527,
      "step": 165780
    },
    {
      "epoch": 267.42,
      "learning_rate": 0.07326889769887096,
      "loss": 0.8484,
      "step": 165800
    },
    {
      "epoch": 267.45,
      "learning_rate": 0.07326567189564517,
      "loss": 0.8685,
      "step": 165820
    },
    {
      "epoch": 267.48,
      "learning_rate": 0.07326244609241936,
      "loss": 0.8726,
      "step": 165840
    },
    {
      "epoch": 267.52,
      "learning_rate": 0.07325922028919356,
      "loss": 0.8985,
      "step": 165860
    },
    {
      "epoch": 267.55,
      "learning_rate": 0.07325599448596774,
      "loss": 0.9128,
      "step": 165880
    },
    {
      "epoch": 267.58,
      "learning_rate": 0.07325276868274194,
      "loss": 0.8807,
      "step": 165900
    },
    {
      "epoch": 267.61,
      "learning_rate": 0.07324954287951613,
      "loss": 0.8773,
      "step": 165920
    },
    {
      "epoch": 267.65,
      "learning_rate": 0.07324631707629033,
      "loss": 0.8828,
      "step": 165940
    },
    {
      "epoch": 267.68,
      "learning_rate": 0.07324309127306453,
      "loss": 0.8941,
      "step": 165960
    },
    {
      "epoch": 267.71,
      "learning_rate": 0.07323986546983871,
      "loss": 0.9007,
      "step": 165980
    },
    {
      "epoch": 267.74,
      "learning_rate": 0.07323663966661291,
      "loss": 0.8864,
      "step": 166000
    },
    {
      "epoch": 267.77,
      "learning_rate": 0.0732334138633871,
      "loss": 0.8967,
      "step": 166020
    },
    {
      "epoch": 267.81,
      "learning_rate": 0.0732301880601613,
      "loss": 0.9086,
      "step": 166040
    },
    {
      "epoch": 267.84,
      "learning_rate": 0.0732269622569355,
      "loss": 0.8575,
      "step": 166060
    },
    {
      "epoch": 267.87,
      "learning_rate": 0.07322373645370968,
      "loss": 0.8894,
      "step": 166080
    },
    {
      "epoch": 267.9,
      "learning_rate": 0.07322051065048386,
      "loss": 0.9161,
      "step": 166100
    },
    {
      "epoch": 267.94,
      "learning_rate": 0.07321728484725808,
      "loss": 0.9039,
      "step": 166120
    },
    {
      "epoch": 267.97,
      "learning_rate": 0.07321405904403226,
      "loss": 0.8932,
      "step": 166140
    },
    {
      "epoch": 268.0,
      "learning_rate": 0.07321083324080646,
      "loss": 0.87,
      "step": 166160
    },
    {
      "epoch": 268.0,
      "eval_accuracy": {
        "accuracy": 0.7438139099211615
      },
      "eval_loss": 1.2637876272201538,
      "eval_runtime": 2.6806,
      "eval_samples_per_second": 4779.205,
      "eval_steps_per_second": 74.984,
      "step": 166160
    },
    {
      "epoch": 268.03,
      "learning_rate": 0.07320760743758065,
      "loss": 0.879,
      "step": 166180
    },
    {
      "epoch": 268.06,
      "learning_rate": 0.07320438163435485,
      "loss": 0.9116,
      "step": 166200
    },
    {
      "epoch": 268.1,
      "learning_rate": 0.07320115583112903,
      "loss": 0.8734,
      "step": 166220
    },
    {
      "epoch": 268.13,
      "learning_rate": 0.07319793002790324,
      "loss": 0.867,
      "step": 166240
    },
    {
      "epoch": 268.16,
      "learning_rate": 0.07319470422467743,
      "loss": 0.8621,
      "step": 166260
    },
    {
      "epoch": 268.19,
      "learning_rate": 0.07319147842145161,
      "loss": 0.8655,
      "step": 166280
    },
    {
      "epoch": 268.23,
      "learning_rate": 0.07318825261822581,
      "loss": 0.8612,
      "step": 166300
    },
    {
      "epoch": 268.26,
      "learning_rate": 0.073185026815,
      "loss": 0.8781,
      "step": 166320
    },
    {
      "epoch": 268.29,
      "learning_rate": 0.0731818010117742,
      "loss": 0.8514,
      "step": 166340
    },
    {
      "epoch": 268.32,
      "learning_rate": 0.0731785752085484,
      "loss": 0.8991,
      "step": 166360
    },
    {
      "epoch": 268.35,
      "learning_rate": 0.07317534940532258,
      "loss": 0.891,
      "step": 166380
    },
    {
      "epoch": 268.39,
      "learning_rate": 0.07317212360209677,
      "loss": 0.888,
      "step": 166400
    },
    {
      "epoch": 268.42,
      "learning_rate": 0.07316889779887098,
      "loss": 0.8981,
      "step": 166420
    },
    {
      "epoch": 268.45,
      "learning_rate": 0.07316567199564517,
      "loss": 0.8638,
      "step": 166440
    },
    {
      "epoch": 268.48,
      "learning_rate": 0.07316244619241936,
      "loss": 0.8531,
      "step": 166460
    },
    {
      "epoch": 268.52,
      "learning_rate": 0.07315922038919355,
      "loss": 0.8934,
      "step": 166480
    },
    {
      "epoch": 268.55,
      "learning_rate": 0.07315599458596775,
      "loss": 0.8993,
      "step": 166500
    },
    {
      "epoch": 268.58,
      "learning_rate": 0.07315276878274193,
      "loss": 0.9186,
      "step": 166520
    },
    {
      "epoch": 268.61,
      "learning_rate": 0.07314954297951615,
      "loss": 0.9102,
      "step": 166540
    },
    {
      "epoch": 268.65,
      "learning_rate": 0.07314631717629032,
      "loss": 0.8909,
      "step": 166560
    },
    {
      "epoch": 268.68,
      "learning_rate": 0.07314309137306452,
      "loss": 0.88,
      "step": 166580
    },
    {
      "epoch": 268.71,
      "learning_rate": 0.07313986556983872,
      "loss": 0.8779,
      "step": 166600
    },
    {
      "epoch": 268.74,
      "learning_rate": 0.0731366397666129,
      "loss": 0.9087,
      "step": 166620
    },
    {
      "epoch": 268.77,
      "learning_rate": 0.0731334139633871,
      "loss": 0.9151,
      "step": 166640
    },
    {
      "epoch": 268.81,
      "learning_rate": 0.0731301881601613,
      "loss": 0.8771,
      "step": 166660
    },
    {
      "epoch": 268.84,
      "learning_rate": 0.07312696235693548,
      "loss": 0.8936,
      "step": 166680
    },
    {
      "epoch": 268.87,
      "learning_rate": 0.07312373655370968,
      "loss": 0.8606,
      "step": 166700
    },
    {
      "epoch": 268.9,
      "learning_rate": 0.07312051075048388,
      "loss": 0.8992,
      "step": 166720
    },
    {
      "epoch": 268.94,
      "learning_rate": 0.07311728494725807,
      "loss": 0.9102,
      "step": 166740
    },
    {
      "epoch": 268.97,
      "learning_rate": 0.07311405914403227,
      "loss": 0.9044,
      "step": 166760
    },
    {
      "epoch": 269.0,
      "learning_rate": 0.07311083334080645,
      "loss": 0.895,
      "step": 166780
    },
    {
      "epoch": 269.0,
      "eval_accuracy": {
        "accuracy": 0.7520099914136289
      },
      "eval_loss": 1.2423819303512573,
      "eval_runtime": 2.7476,
      "eval_samples_per_second": 4662.681,
      "eval_steps_per_second": 73.156,
      "step": 166780
    },
    {
      "epoch": 269.03,
      "learning_rate": 0.07310760753758065,
      "loss": 0.9025,
      "step": 166800
    },
    {
      "epoch": 269.06,
      "learning_rate": 0.07310438173435484,
      "loss": 0.8597,
      "step": 166820
    },
    {
      "epoch": 269.1,
      "learning_rate": 0.07310115593112905,
      "loss": 0.8654,
      "step": 166840
    },
    {
      "epoch": 269.13,
      "learning_rate": 0.07309793012790322,
      "loss": 0.8859,
      "step": 166860
    },
    {
      "epoch": 269.16,
      "learning_rate": 0.07309470432467742,
      "loss": 0.8636,
      "step": 166880
    },
    {
      "epoch": 269.19,
      "learning_rate": 0.07309147852145162,
      "loss": 0.8759,
      "step": 166900
    },
    {
      "epoch": 269.23,
      "learning_rate": 0.0730882527182258,
      "loss": 0.8972,
      "step": 166920
    },
    {
      "epoch": 269.26,
      "learning_rate": 0.073085026915,
      "loss": 0.9105,
      "step": 166940
    },
    {
      "epoch": 269.29,
      "learning_rate": 0.0730818011117742,
      "loss": 0.8891,
      "step": 166960
    },
    {
      "epoch": 269.32,
      "learning_rate": 0.07307857530854839,
      "loss": 0.876,
      "step": 166980
    },
    {
      "epoch": 269.35,
      "learning_rate": 0.07307534950532259,
      "loss": 0.8827,
      "step": 167000
    },
    {
      "epoch": 269.39,
      "learning_rate": 0.07307212370209679,
      "loss": 0.8638,
      "step": 167020
    },
    {
      "epoch": 269.42,
      "learning_rate": 0.07306889789887097,
      "loss": 0.8806,
      "step": 167040
    },
    {
      "epoch": 269.45,
      "learning_rate": 0.07306567209564517,
      "loss": 0.8657,
      "step": 167060
    },
    {
      "epoch": 269.48,
      "learning_rate": 0.07306244629241936,
      "loss": 0.8793,
      "step": 167080
    },
    {
      "epoch": 269.52,
      "learning_rate": 0.07305922048919355,
      "loss": 0.9113,
      "step": 167100
    },
    {
      "epoch": 269.55,
      "learning_rate": 0.07305599468596774,
      "loss": 0.8945,
      "step": 167120
    },
    {
      "epoch": 269.58,
      "learning_rate": 0.07305276888274195,
      "loss": 0.8859,
      "step": 167140
    },
    {
      "epoch": 269.61,
      "learning_rate": 0.07304954307951612,
      "loss": 0.8821,
      "step": 167160
    },
    {
      "epoch": 269.65,
      "learning_rate": 0.07304631727629032,
      "loss": 0.8926,
      "step": 167180
    },
    {
      "epoch": 269.68,
      "learning_rate": 0.07304309147306452,
      "loss": 0.8959,
      "step": 167200
    },
    {
      "epoch": 269.71,
      "learning_rate": 0.07303986566983871,
      "loss": 0.8712,
      "step": 167220
    },
    {
      "epoch": 269.74,
      "learning_rate": 0.0730366398666129,
      "loss": 0.8673,
      "step": 167240
    },
    {
      "epoch": 269.77,
      "learning_rate": 0.0730334140633871,
      "loss": 0.909,
      "step": 167260
    },
    {
      "epoch": 269.81,
      "learning_rate": 0.07303018826016129,
      "loss": 0.9093,
      "step": 167280
    },
    {
      "epoch": 269.84,
      "learning_rate": 0.07302696245693549,
      "loss": 0.8717,
      "step": 167300
    },
    {
      "epoch": 269.87,
      "learning_rate": 0.07302373665370969,
      "loss": 0.9038,
      "step": 167320
    },
    {
      "epoch": 269.9,
      "learning_rate": 0.07302051085048387,
      "loss": 0.9158,
      "step": 167340
    },
    {
      "epoch": 269.94,
      "learning_rate": 0.07301728504725807,
      "loss": 0.8822,
      "step": 167360
    },
    {
      "epoch": 269.97,
      "learning_rate": 0.07301405924403226,
      "loss": 0.898,
      "step": 167380
    },
    {
      "epoch": 270.0,
      "learning_rate": 0.07301099473096774,
      "loss": 0.9043,
      "step": 167400
    },
    {
      "epoch": 270.0,
      "eval_accuracy": {
        "accuracy": 0.7455311841386308
      },
      "eval_loss": 1.260434627532959,
      "eval_runtime": 2.8778,
      "eval_samples_per_second": 4451.665,
      "eval_steps_per_second": 69.845,
      "step": 167400
    },
    {
      "epoch": 270.03,
      "learning_rate": 0.07300776892774194,
      "loss": 0.8656,
      "step": 167420
    },
    {
      "epoch": 270.06,
      "learning_rate": 0.07300454312451614,
      "loss": 0.8824,
      "step": 167440
    },
    {
      "epoch": 270.1,
      "learning_rate": 0.07300131732129032,
      "loss": 0.8751,
      "step": 167460
    },
    {
      "epoch": 270.13,
      "learning_rate": 0.07299809151806451,
      "loss": 0.8777,
      "step": 167480
    },
    {
      "epoch": 270.16,
      "learning_rate": 0.07299486571483872,
      "loss": 0.8908,
      "step": 167500
    },
    {
      "epoch": 270.19,
      "learning_rate": 0.07299163991161291,
      "loss": 0.8918,
      "step": 167520
    },
    {
      "epoch": 270.23,
      "learning_rate": 0.0729884141083871,
      "loss": 0.859,
      "step": 167540
    },
    {
      "epoch": 270.26,
      "learning_rate": 0.07298518830516129,
      "loss": 0.8647,
      "step": 167560
    },
    {
      "epoch": 270.29,
      "learning_rate": 0.07298196250193549,
      "loss": 0.8542,
      "step": 167580
    },
    {
      "epoch": 270.32,
      "learning_rate": 0.07297873669870968,
      "loss": 0.8796,
      "step": 167600
    },
    {
      "epoch": 270.35,
      "learning_rate": 0.07297551089548389,
      "loss": 0.8876,
      "step": 167620
    },
    {
      "epoch": 270.39,
      "learning_rate": 0.07297228509225806,
      "loss": 0.8998,
      "step": 167640
    },
    {
      "epoch": 270.42,
      "learning_rate": 0.07296905928903226,
      "loss": 0.8786,
      "step": 167660
    },
    {
      "epoch": 270.45,
      "learning_rate": 0.07296583348580646,
      "loss": 0.8919,
      "step": 167680
    },
    {
      "epoch": 270.48,
      "learning_rate": 0.07296260768258064,
      "loss": 0.9039,
      "step": 167700
    },
    {
      "epoch": 270.52,
      "learning_rate": 0.07295938187935484,
      "loss": 0.901,
      "step": 167720
    },
    {
      "epoch": 270.55,
      "learning_rate": 0.07295615607612904,
      "loss": 0.877,
      "step": 167740
    },
    {
      "epoch": 270.58,
      "learning_rate": 0.07295293027290323,
      "loss": 0.9271,
      "step": 167760
    },
    {
      "epoch": 270.61,
      "learning_rate": 0.07294970446967743,
      "loss": 0.8833,
      "step": 167780
    },
    {
      "epoch": 270.65,
      "learning_rate": 0.07294647866645163,
      "loss": 0.8846,
      "step": 167800
    },
    {
      "epoch": 270.68,
      "learning_rate": 0.07294325286322581,
      "loss": 0.9009,
      "step": 167820
    },
    {
      "epoch": 270.71,
      "learning_rate": 0.07294002706000001,
      "loss": 0.9168,
      "step": 167840
    },
    {
      "epoch": 270.74,
      "learning_rate": 0.0729368012567742,
      "loss": 0.892,
      "step": 167860
    },
    {
      "epoch": 270.77,
      "learning_rate": 0.0729335754535484,
      "loss": 0.8966,
      "step": 167880
    },
    {
      "epoch": 270.81,
      "learning_rate": 0.07293034965032258,
      "loss": 0.8709,
      "step": 167900
    },
    {
      "epoch": 270.84,
      "learning_rate": 0.07292712384709679,
      "loss": 0.8858,
      "step": 167920
    },
    {
      "epoch": 270.87,
      "learning_rate": 0.07292389804387096,
      "loss": 0.8691,
      "step": 167940
    },
    {
      "epoch": 270.9,
      "learning_rate": 0.07292067224064516,
      "loss": 0.9013,
      "step": 167960
    },
    {
      "epoch": 270.94,
      "learning_rate": 0.07291744643741936,
      "loss": 0.9001,
      "step": 167980
    },
    {
      "epoch": 270.97,
      "learning_rate": 0.07291422063419355,
      "loss": 0.9206,
      "step": 168000
    },
    {
      "epoch": 271.0,
      "learning_rate": 0.07291099483096775,
      "loss": 0.9019,
      "step": 168020
    },
    {
      "epoch": 271.0,
      "eval_accuracy": {
        "accuracy": 0.749980485520256
      },
      "eval_loss": 1.2359182834625244,
      "eval_runtime": 2.8188,
      "eval_samples_per_second": 4544.868,
      "eval_steps_per_second": 71.307,
      "step": 168020
    },
    {
      "epoch": 271.03,
      "learning_rate": 0.07290776902774194,
      "loss": 0.9163,
      "step": 168040
    },
    {
      "epoch": 271.06,
      "learning_rate": 0.07290454322451613,
      "loss": 0.8816,
      "step": 168060
    },
    {
      "epoch": 271.1,
      "learning_rate": 0.07290131742129033,
      "loss": 0.8548,
      "step": 168080
    },
    {
      "epoch": 271.13,
      "learning_rate": 0.07289809161806453,
      "loss": 0.8889,
      "step": 168100
    },
    {
      "epoch": 271.16,
      "learning_rate": 0.07289486581483871,
      "loss": 0.883,
      "step": 168120
    },
    {
      "epoch": 271.19,
      "learning_rate": 0.07289164001161291,
      "loss": 0.874,
      "step": 168140
    },
    {
      "epoch": 271.23,
      "learning_rate": 0.0728884142083871,
      "loss": 0.8789,
      "step": 168160
    },
    {
      "epoch": 271.26,
      "learning_rate": 0.0728851884051613,
      "loss": 0.8669,
      "step": 168180
    },
    {
      "epoch": 271.29,
      "learning_rate": 0.07288196260193548,
      "loss": 0.8903,
      "step": 168200
    },
    {
      "epoch": 271.32,
      "learning_rate": 0.0728787367987097,
      "loss": 0.8739,
      "step": 168220
    },
    {
      "epoch": 271.35,
      "learning_rate": 0.07287551099548387,
      "loss": 0.8751,
      "step": 168240
    },
    {
      "epoch": 271.39,
      "learning_rate": 0.07287228519225807,
      "loss": 0.8896,
      "step": 168260
    },
    {
      "epoch": 271.42,
      "learning_rate": 0.07286905938903226,
      "loss": 0.8835,
      "step": 168280
    },
    {
      "epoch": 271.45,
      "learning_rate": 0.07286583358580645,
      "loss": 0.8816,
      "step": 168300
    },
    {
      "epoch": 271.48,
      "learning_rate": 0.07286260778258065,
      "loss": 0.898,
      "step": 168320
    },
    {
      "epoch": 271.52,
      "learning_rate": 0.07285938197935485,
      "loss": 0.8887,
      "step": 168340
    },
    {
      "epoch": 271.55,
      "learning_rate": 0.07285615617612903,
      "loss": 0.8927,
      "step": 168360
    },
    {
      "epoch": 271.58,
      "learning_rate": 0.07285293037290323,
      "loss": 0.8683,
      "step": 168380
    },
    {
      "epoch": 271.61,
      "learning_rate": 0.07284970456967743,
      "loss": 0.8895,
      "step": 168400
    },
    {
      "epoch": 271.65,
      "learning_rate": 0.07284647876645162,
      "loss": 0.8775,
      "step": 168420
    },
    {
      "epoch": 271.68,
      "learning_rate": 0.07284325296322582,
      "loss": 0.8453,
      "step": 168440
    },
    {
      "epoch": 271.71,
      "learning_rate": 0.07284002716,
      "loss": 0.8509,
      "step": 168460
    },
    {
      "epoch": 271.74,
      "learning_rate": 0.0728368013567742,
      "loss": 0.9025,
      "step": 168480
    },
    {
      "epoch": 271.77,
      "learning_rate": 0.07283357555354839,
      "loss": 0.8952,
      "step": 168500
    },
    {
      "epoch": 271.81,
      "learning_rate": 0.0728303497503226,
      "loss": 0.9052,
      "step": 168520
    },
    {
      "epoch": 271.84,
      "learning_rate": 0.07282712394709677,
      "loss": 0.915,
      "step": 168540
    },
    {
      "epoch": 271.87,
      "learning_rate": 0.07282389814387098,
      "loss": 0.9076,
      "step": 168560
    },
    {
      "epoch": 271.9,
      "learning_rate": 0.07282067234064517,
      "loss": 0.9041,
      "step": 168580
    },
    {
      "epoch": 271.94,
      "learning_rate": 0.07281744653741935,
      "loss": 0.9058,
      "step": 168600
    },
    {
      "epoch": 271.97,
      "learning_rate": 0.07281422073419355,
      "loss": 0.91,
      "step": 168620
    },
    {
      "epoch": 272.0,
      "learning_rate": 0.07281099493096775,
      "loss": 0.9019,
      "step": 168640
    },
    {
      "epoch": 272.0,
      "eval_accuracy": {
        "accuracy": 0.7457653578955585
      },
      "eval_loss": 1.255910038948059,
      "eval_runtime": 2.7362,
      "eval_samples_per_second": 4682.121,
      "eval_steps_per_second": 73.461,
      "step": 168640
    },
    {
      "epoch": 272.03,
      "learning_rate": 0.07280776912774194,
      "loss": 0.9161,
      "step": 168660
    },
    {
      "epoch": 272.06,
      "learning_rate": 0.07280454332451614,
      "loss": 0.8644,
      "step": 168680
    },
    {
      "epoch": 272.1,
      "learning_rate": 0.07280131752129033,
      "loss": 0.8797,
      "step": 168700
    },
    {
      "epoch": 272.13,
      "learning_rate": 0.0727980917180645,
      "loss": 0.8591,
      "step": 168720
    },
    {
      "epoch": 272.16,
      "learning_rate": 0.07279486591483872,
      "loss": 0.8571,
      "step": 168740
    },
    {
      "epoch": 272.19,
      "learning_rate": 0.0727916401116129,
      "loss": 0.8763,
      "step": 168760
    },
    {
      "epoch": 272.23,
      "learning_rate": 0.0727884143083871,
      "loss": 0.8624,
      "step": 168780
    },
    {
      "epoch": 272.26,
      "learning_rate": 0.07278518850516129,
      "loss": 0.8639,
      "step": 168800
    },
    {
      "epoch": 272.29,
      "learning_rate": 0.0727819627019355,
      "loss": 0.8593,
      "step": 168820
    },
    {
      "epoch": 272.32,
      "learning_rate": 0.07277873689870967,
      "loss": 0.8689,
      "step": 168840
    },
    {
      "epoch": 272.35,
      "learning_rate": 0.07277551109548389,
      "loss": 0.8862,
      "step": 168860
    },
    {
      "epoch": 272.39,
      "learning_rate": 0.07277228529225807,
      "loss": 0.8687,
      "step": 168880
    },
    {
      "epoch": 272.42,
      "learning_rate": 0.07276905948903226,
      "loss": 0.9015,
      "step": 168900
    },
    {
      "epoch": 272.45,
      "learning_rate": 0.07276583368580646,
      "loss": 0.8965,
      "step": 168920
    },
    {
      "epoch": 272.48,
      "learning_rate": 0.07276260788258065,
      "loss": 0.9012,
      "step": 168940
    },
    {
      "epoch": 272.52,
      "learning_rate": 0.07275938207935484,
      "loss": 0.9052,
      "step": 168960
    },
    {
      "epoch": 272.55,
      "learning_rate": 0.07275615627612904,
      "loss": 0.9179,
      "step": 168980
    },
    {
      "epoch": 272.58,
      "learning_rate": 0.07275293047290324,
      "loss": 0.8974,
      "step": 169000
    },
    {
      "epoch": 272.61,
      "learning_rate": 0.07274970466967742,
      "loss": 0.8547,
      "step": 169020
    },
    {
      "epoch": 272.65,
      "learning_rate": 0.07274647886645162,
      "loss": 0.8838,
      "step": 169040
    },
    {
      "epoch": 272.68,
      "learning_rate": 0.07274325306322581,
      "loss": 0.913,
      "step": 169060
    },
    {
      "epoch": 272.71,
      "learning_rate": 0.07274002726,
      "loss": 0.8897,
      "step": 169080
    },
    {
      "epoch": 272.74,
      "learning_rate": 0.07273680145677419,
      "loss": 0.8886,
      "step": 169100
    },
    {
      "epoch": 272.77,
      "learning_rate": 0.0727335756535484,
      "loss": 0.9005,
      "step": 169120
    },
    {
      "epoch": 272.81,
      "learning_rate": 0.07273034985032258,
      "loss": 0.8916,
      "step": 169140
    },
    {
      "epoch": 272.84,
      "learning_rate": 0.07272712404709679,
      "loss": 0.8952,
      "step": 169160
    },
    {
      "epoch": 272.87,
      "learning_rate": 0.07272389824387097,
      "loss": 0.9214,
      "step": 169180
    },
    {
      "epoch": 272.9,
      "learning_rate": 0.07272067244064516,
      "loss": 0.8898,
      "step": 169200
    },
    {
      "epoch": 272.94,
      "learning_rate": 0.07271744663741936,
      "loss": 0.8745,
      "step": 169220
    },
    {
      "epoch": 272.97,
      "learning_rate": 0.07271422083419356,
      "loss": 0.9247,
      "step": 169240
    },
    {
      "epoch": 273.0,
      "learning_rate": 0.07271099503096774,
      "loss": 0.8877,
      "step": 169260
    },
    {
      "epoch": 273.0,
      "eval_accuracy": {
        "accuracy": 0.7429552728124268
      },
      "eval_loss": 1.2749103307724,
      "eval_runtime": 3.4565,
      "eval_samples_per_second": 3706.298,
      "eval_steps_per_second": 58.15,
      "step": 169260
    },
    {
      "epoch": 273.03,
      "learning_rate": 0.07270776922774194,
      "loss": 0.9206,
      "step": 169280
    },
    {
      "epoch": 273.06,
      "learning_rate": 0.07270454342451614,
      "loss": 0.8981,
      "step": 169300
    },
    {
      "epoch": 273.1,
      "learning_rate": 0.07270131762129033,
      "loss": 0.8693,
      "step": 169320
    },
    {
      "epoch": 273.13,
      "learning_rate": 0.07269809181806453,
      "loss": 0.8564,
      "step": 169340
    },
    {
      "epoch": 273.16,
      "learning_rate": 0.07269486601483871,
      "loss": 0.8547,
      "step": 169360
    },
    {
      "epoch": 273.19,
      "learning_rate": 0.07269164021161291,
      "loss": 0.8721,
      "step": 169380
    },
    {
      "epoch": 273.23,
      "learning_rate": 0.0726884144083871,
      "loss": 0.8697,
      "step": 169400
    },
    {
      "epoch": 273.26,
      "learning_rate": 0.07268518860516131,
      "loss": 0.8591,
      "step": 169420
    },
    {
      "epoch": 273.29,
      "learning_rate": 0.07268196280193548,
      "loss": 0.8827,
      "step": 169440
    },
    {
      "epoch": 273.32,
      "learning_rate": 0.07267873699870969,
      "loss": 0.8855,
      "step": 169460
    },
    {
      "epoch": 273.35,
      "learning_rate": 0.07267551119548388,
      "loss": 0.8526,
      "step": 169480
    },
    {
      "epoch": 273.39,
      "learning_rate": 0.07267228539225806,
      "loss": 0.8812,
      "step": 169500
    },
    {
      "epoch": 273.42,
      "learning_rate": 0.07266905958903226,
      "loss": 0.884,
      "step": 169520
    },
    {
      "epoch": 273.45,
      "learning_rate": 0.07266583378580646,
      "loss": 0.8768,
      "step": 169540
    },
    {
      "epoch": 273.48,
      "learning_rate": 0.07266260798258065,
      "loss": 0.8619,
      "step": 169560
    },
    {
      "epoch": 273.52,
      "learning_rate": 0.07265938217935484,
      "loss": 0.895,
      "step": 169580
    },
    {
      "epoch": 273.55,
      "learning_rate": 0.07265615637612904,
      "loss": 0.9024,
      "step": 169600
    },
    {
      "epoch": 273.58,
      "learning_rate": 0.07265293057290323,
      "loss": 0.9211,
      "step": 169620
    },
    {
      "epoch": 273.61,
      "learning_rate": 0.07264970476967743,
      "loss": 0.9123,
      "step": 169640
    },
    {
      "epoch": 273.65,
      "learning_rate": 0.07264647896645161,
      "loss": 0.9166,
      "step": 169660
    },
    {
      "epoch": 273.68,
      "learning_rate": 0.07264325316322581,
      "loss": 0.8748,
      "step": 169680
    },
    {
      "epoch": 273.71,
      "learning_rate": 0.07264002736,
      "loss": 0.8804,
      "step": 169700
    },
    {
      "epoch": 273.74,
      "learning_rate": 0.0726368015567742,
      "loss": 0.9094,
      "step": 169720
    },
    {
      "epoch": 273.77,
      "learning_rate": 0.07263357575354838,
      "loss": 0.8991,
      "step": 169740
    },
    {
      "epoch": 273.81,
      "learning_rate": 0.0726303499503226,
      "loss": 0.8983,
      "step": 169760
    },
    {
      "epoch": 273.84,
      "learning_rate": 0.07262712414709678,
      "loss": 0.8846,
      "step": 169780
    },
    {
      "epoch": 273.87,
      "learning_rate": 0.07262389834387098,
      "loss": 0.8958,
      "step": 169800
    },
    {
      "epoch": 273.9,
      "learning_rate": 0.07262067254064516,
      "loss": 0.8768,
      "step": 169820
    },
    {
      "epoch": 273.94,
      "learning_rate": 0.07261744673741936,
      "loss": 0.8783,
      "step": 169840
    },
    {
      "epoch": 273.97,
      "learning_rate": 0.07261422093419355,
      "loss": 0.8936,
      "step": 169860
    },
    {
      "epoch": 274.0,
      "learning_rate": 0.07261115642112903,
      "loss": 0.8989,
      "step": 169880
    },
    {
      "epoch": 274.0,
      "eval_accuracy": {
        "accuracy": 0.7495121380064007
      },
      "eval_loss": 1.231026530265808,
      "eval_runtime": 2.9605,
      "eval_samples_per_second": 4327.242,
      "eval_steps_per_second": 67.893,
      "step": 169880
    },
    {
      "epoch": 274.03,
      "learning_rate": 0.07260793061790324,
      "loss": 0.8619,
      "step": 169900
    },
    {
      "epoch": 274.06,
      "learning_rate": 0.07260470481467741,
      "loss": 0.8597,
      "step": 169920
    },
    {
      "epoch": 274.1,
      "learning_rate": 0.07260147901145163,
      "loss": 0.8664,
      "step": 169940
    },
    {
      "epoch": 274.13,
      "learning_rate": 0.07259825320822581,
      "loss": 0.9094,
      "step": 169960
    },
    {
      "epoch": 274.16,
      "learning_rate": 0.072595027405,
      "loss": 0.8831,
      "step": 169980
    },
    {
      "epoch": 274.19,
      "learning_rate": 0.0725918016017742,
      "loss": 0.8636,
      "step": 170000
    },
    {
      "epoch": 274.23,
      "learning_rate": 0.0725885757985484,
      "loss": 0.8729,
      "step": 170020
    },
    {
      "epoch": 274.26,
      "learning_rate": 0.07258534999532258,
      "loss": 0.8789,
      "step": 170040
    },
    {
      "epoch": 274.29,
      "learning_rate": 0.07258212419209678,
      "loss": 0.8699,
      "step": 170060
    },
    {
      "epoch": 274.32,
      "learning_rate": 0.07257889838887098,
      "loss": 0.8744,
      "step": 170080
    },
    {
      "epoch": 274.35,
      "learning_rate": 0.07257567258564517,
      "loss": 0.8927,
      "step": 170100
    },
    {
      "epoch": 274.39,
      "learning_rate": 0.07257244678241936,
      "loss": 0.8801,
      "step": 170120
    },
    {
      "epoch": 274.42,
      "learning_rate": 0.07256922097919355,
      "loss": 0.8695,
      "step": 170140
    },
    {
      "epoch": 274.45,
      "learning_rate": 0.07256599517596775,
      "loss": 0.862,
      "step": 170160
    },
    {
      "epoch": 274.48,
      "learning_rate": 0.07256276937274193,
      "loss": 0.8698,
      "step": 170180
    },
    {
      "epoch": 274.52,
      "learning_rate": 0.07255954356951615,
      "loss": 0.9045,
      "step": 170200
    },
    {
      "epoch": 274.55,
      "learning_rate": 0.07255631776629032,
      "loss": 0.8816,
      "step": 170220
    },
    {
      "epoch": 274.58,
      "learning_rate": 0.07255309196306453,
      "loss": 0.8654,
      "step": 170240
    },
    {
      "epoch": 274.61,
      "learning_rate": 0.07254986615983872,
      "loss": 0.8737,
      "step": 170260
    },
    {
      "epoch": 274.65,
      "learning_rate": 0.0725466403566129,
      "loss": 0.8936,
      "step": 170280
    },
    {
      "epoch": 274.68,
      "learning_rate": 0.0725434145533871,
      "loss": 0.897,
      "step": 170300
    },
    {
      "epoch": 274.71,
      "learning_rate": 0.0725401887501613,
      "loss": 0.9012,
      "step": 170320
    },
    {
      "epoch": 274.74,
      "learning_rate": 0.07253696294693548,
      "loss": 0.8812,
      "step": 170340
    },
    {
      "epoch": 274.77,
      "learning_rate": 0.07253373714370968,
      "loss": 0.9204,
      "step": 170360
    },
    {
      "epoch": 274.81,
      "learning_rate": 0.07253051134048388,
      "loss": 0.9178,
      "step": 170380
    },
    {
      "epoch": 274.84,
      "learning_rate": 0.07252728553725807,
      "loss": 0.898,
      "step": 170400
    },
    {
      "epoch": 274.87,
      "learning_rate": 0.07252405973403227,
      "loss": 0.883,
      "step": 170420
    },
    {
      "epoch": 274.9,
      "learning_rate": 0.07252083393080645,
      "loss": 0.8714,
      "step": 170440
    },
    {
      "epoch": 274.94,
      "learning_rate": 0.07251760812758065,
      "loss": 0.8915,
      "step": 170460
    },
    {
      "epoch": 274.97,
      "learning_rate": 0.07251438232435484,
      "loss": 0.8827,
      "step": 170480
    },
    {
      "epoch": 275.0,
      "learning_rate": 0.07251115652112905,
      "loss": 0.9151,
      "step": 170500
    },
    {
      "epoch": 275.0,
      "eval_accuracy": {
        "accuracy": 0.7385059714308017
      },
      "eval_loss": 1.317624807357788,
      "eval_runtime": 2.6686,
      "eval_samples_per_second": 4800.634,
      "eval_steps_per_second": 75.32,
      "step": 170500
    },
    {
      "epoch": 275.03,
      "learning_rate": 0.07250793071790322,
      "loss": 0.9396,
      "step": 170520
    },
    {
      "epoch": 275.06,
      "learning_rate": 0.07250470491467743,
      "loss": 0.873,
      "step": 170540
    },
    {
      "epoch": 275.1,
      "learning_rate": 0.07250147911145162,
      "loss": 0.8755,
      "step": 170560
    },
    {
      "epoch": 275.13,
      "learning_rate": 0.0724982533082258,
      "loss": 0.8763,
      "step": 170580
    },
    {
      "epoch": 275.16,
      "learning_rate": 0.072495027505,
      "loss": 0.8658,
      "step": 170600
    },
    {
      "epoch": 275.19,
      "learning_rate": 0.0724918017017742,
      "loss": 0.8628,
      "step": 170620
    },
    {
      "epoch": 275.23,
      "learning_rate": 0.07248857589854839,
      "loss": 0.874,
      "step": 170640
    },
    {
      "epoch": 275.26,
      "learning_rate": 0.07248535009532259,
      "loss": 0.85,
      "step": 170660
    },
    {
      "epoch": 275.29,
      "learning_rate": 0.07248212429209679,
      "loss": 0.871,
      "step": 170680
    },
    {
      "epoch": 275.32,
      "learning_rate": 0.07247889848887097,
      "loss": 0.8783,
      "step": 170700
    },
    {
      "epoch": 275.35,
      "learning_rate": 0.07247567268564517,
      "loss": 0.8568,
      "step": 170720
    },
    {
      "epoch": 275.39,
      "learning_rate": 0.07247244688241936,
      "loss": 0.9054,
      "step": 170740
    },
    {
      "epoch": 275.42,
      "learning_rate": 0.07246922107919355,
      "loss": 0.8926,
      "step": 170760
    },
    {
      "epoch": 275.45,
      "learning_rate": 0.07246599527596774,
      "loss": 0.9104,
      "step": 170780
    },
    {
      "epoch": 275.48,
      "learning_rate": 0.07246276947274194,
      "loss": 0.8927,
      "step": 170800
    },
    {
      "epoch": 275.52,
      "learning_rate": 0.07245954366951612,
      "loss": 0.9028,
      "step": 170820
    },
    {
      "epoch": 275.55,
      "learning_rate": 0.07245631786629034,
      "loss": 0.8962,
      "step": 170840
    },
    {
      "epoch": 275.58,
      "learning_rate": 0.07245309206306452,
      "loss": 0.882,
      "step": 170860
    },
    {
      "epoch": 275.61,
      "learning_rate": 0.07244986625983872,
      "loss": 0.8866,
      "step": 170880
    },
    {
      "epoch": 275.65,
      "learning_rate": 0.0724466404566129,
      "loss": 0.8852,
      "step": 170900
    },
    {
      "epoch": 275.68,
      "learning_rate": 0.0724434146533871,
      "loss": 0.8753,
      "step": 170920
    },
    {
      "epoch": 275.71,
      "learning_rate": 0.07244018885016129,
      "loss": 0.8757,
      "step": 170940
    },
    {
      "epoch": 275.74,
      "learning_rate": 0.07243696304693549,
      "loss": 0.9158,
      "step": 170960
    },
    {
      "epoch": 275.77,
      "learning_rate": 0.07243373724370969,
      "loss": 0.9255,
      "step": 170980
    },
    {
      "epoch": 275.81,
      "learning_rate": 0.07243051144048387,
      "loss": 0.8993,
      "step": 171000
    },
    {
      "epoch": 275.84,
      "learning_rate": 0.07242728563725807,
      "loss": 0.9096,
      "step": 171020
    },
    {
      "epoch": 275.87,
      "learning_rate": 0.07242405983403226,
      "loss": 0.8984,
      "step": 171040
    },
    {
      "epoch": 275.9,
      "learning_rate": 0.07242083403080646,
      "loss": 0.875,
      "step": 171060
    },
    {
      "epoch": 275.94,
      "learning_rate": 0.07241760822758064,
      "loss": 0.8857,
      "step": 171080
    },
    {
      "epoch": 275.97,
      "learning_rate": 0.07241438242435484,
      "loss": 0.8714,
      "step": 171100
    },
    {
      "epoch": 276.0,
      "learning_rate": 0.07241115662112903,
      "loss": 0.9032,
      "step": 171120
    },
    {
      "epoch": 276.0,
      "eval_accuracy": {
        "accuracy": 0.7436577940832098
      },
      "eval_loss": 1.2600843906402588,
      "eval_runtime": 3.0335,
      "eval_samples_per_second": 4223.212,
      "eval_steps_per_second": 66.261,
      "step": 171120
    },
    {
      "epoch": 276.03,
      "learning_rate": 0.07240793081790324,
      "loss": 0.9125,
      "step": 171140
    },
    {
      "epoch": 276.06,
      "learning_rate": 0.07240470501467743,
      "loss": 0.8763,
      "step": 171160
    },
    {
      "epoch": 276.1,
      "learning_rate": 0.07240147921145162,
      "loss": 0.876,
      "step": 171180
    },
    {
      "epoch": 276.13,
      "learning_rate": 0.07239825340822581,
      "loss": 0.8584,
      "step": 171200
    },
    {
      "epoch": 276.16,
      "learning_rate": 0.07239502760500001,
      "loss": 0.8503,
      "step": 171220
    },
    {
      "epoch": 276.19,
      "learning_rate": 0.0723918018017742,
      "loss": 0.8826,
      "step": 171240
    },
    {
      "epoch": 276.23,
      "learning_rate": 0.0723885759985484,
      "loss": 0.8822,
      "step": 171260
    },
    {
      "epoch": 276.26,
      "learning_rate": 0.07238535019532259,
      "loss": 0.8761,
      "step": 171280
    },
    {
      "epoch": 276.29,
      "learning_rate": 0.07238212439209678,
      "loss": 0.8528,
      "step": 171300
    },
    {
      "epoch": 276.32,
      "learning_rate": 0.07237889858887098,
      "loss": 0.8802,
      "step": 171320
    },
    {
      "epoch": 276.35,
      "learning_rate": 0.07237567278564516,
      "loss": 0.8507,
      "step": 171340
    },
    {
      "epoch": 276.39,
      "learning_rate": 0.07237244698241936,
      "loss": 0.8928,
      "step": 171360
    },
    {
      "epoch": 276.42,
      "learning_rate": 0.07236922117919355,
      "loss": 0.9079,
      "step": 171380
    },
    {
      "epoch": 276.45,
      "learning_rate": 0.07236599537596775,
      "loss": 0.8614,
      "step": 171400
    },
    {
      "epoch": 276.48,
      "learning_rate": 0.07236276957274193,
      "loss": 0.8795,
      "step": 171420
    },
    {
      "epoch": 276.52,
      "learning_rate": 0.07235954376951614,
      "loss": 0.8819,
      "step": 171440
    },
    {
      "epoch": 276.55,
      "learning_rate": 0.07235631796629033,
      "loss": 0.8805,
      "step": 171460
    },
    {
      "epoch": 276.58,
      "learning_rate": 0.07235309216306453,
      "loss": 0.9058,
      "step": 171480
    },
    {
      "epoch": 276.61,
      "learning_rate": 0.07234986635983871,
      "loss": 0.8806,
      "step": 171500
    },
    {
      "epoch": 276.65,
      "learning_rate": 0.07234664055661291,
      "loss": 0.8829,
      "step": 171520
    },
    {
      "epoch": 276.68,
      "learning_rate": 0.0723434147533871,
      "loss": 0.8661,
      "step": 171540
    },
    {
      "epoch": 276.71,
      "learning_rate": 0.0723401889501613,
      "loss": 0.8807,
      "step": 171560
    },
    {
      "epoch": 276.74,
      "learning_rate": 0.07233696314693548,
      "loss": 0.9271,
      "step": 171580
    },
    {
      "epoch": 276.77,
      "learning_rate": 0.07233373734370968,
      "loss": 0.9031,
      "step": 171600
    },
    {
      "epoch": 276.81,
      "learning_rate": 0.07233051154048388,
      "loss": 0.899,
      "step": 171620
    },
    {
      "epoch": 276.84,
      "learning_rate": 0.07232728573725807,
      "loss": 0.898,
      "step": 171640
    },
    {
      "epoch": 276.87,
      "learning_rate": 0.07232405993403226,
      "loss": 0.8864,
      "step": 171660
    },
    {
      "epoch": 276.9,
      "learning_rate": 0.07232083413080645,
      "loss": 0.9115,
      "step": 171680
    },
    {
      "epoch": 276.94,
      "learning_rate": 0.07231760832758065,
      "loss": 0.8797,
      "step": 171700
    },
    {
      "epoch": 276.97,
      "learning_rate": 0.07231438252435483,
      "loss": 0.8896,
      "step": 171720
    },
    {
      "epoch": 277.0,
      "learning_rate": 0.07231115672112905,
      "loss": 0.908,
      "step": 171740
    },
    {
      "epoch": 277.0,
      "eval_accuracy": {
        "accuracy": 0.7453750683006791
      },
      "eval_loss": 1.2617913484573364,
      "eval_runtime": 2.9128,
      "eval_samples_per_second": 4398.165,
      "eval_steps_per_second": 69.006,
      "step": 171740
    },
    {
      "epoch": 277.03,
      "learning_rate": 0.07230793091790323,
      "loss": 0.9245,
      "step": 171760
    },
    {
      "epoch": 277.06,
      "learning_rate": 0.07230470511467743,
      "loss": 0.9142,
      "step": 171780
    },
    {
      "epoch": 277.1,
      "learning_rate": 0.07230147931145162,
      "loss": 0.8504,
      "step": 171800
    },
    {
      "epoch": 277.13,
      "learning_rate": 0.07229825350822582,
      "loss": 0.8741,
      "step": 171820
    },
    {
      "epoch": 277.16,
      "learning_rate": 0.072295027705,
      "loss": 0.8849,
      "step": 171840
    },
    {
      "epoch": 277.19,
      "learning_rate": 0.0722918019017742,
      "loss": 0.8862,
      "step": 171860
    },
    {
      "epoch": 277.23,
      "learning_rate": 0.07228857609854838,
      "loss": 0.8782,
      "step": 171880
    },
    {
      "epoch": 277.26,
      "learning_rate": 0.07228535029532258,
      "loss": 0.8963,
      "step": 171900
    },
    {
      "epoch": 277.29,
      "learning_rate": 0.07228212449209678,
      "loss": 0.8887,
      "step": 171920
    },
    {
      "epoch": 277.32,
      "learning_rate": 0.07227889868887097,
      "loss": 0.8952,
      "step": 171940
    },
    {
      "epoch": 277.35,
      "learning_rate": 0.07227567288564517,
      "loss": 0.8565,
      "step": 171960
    },
    {
      "epoch": 277.39,
      "learning_rate": 0.07227244708241935,
      "loss": 0.8844,
      "step": 171980
    },
    {
      "epoch": 277.42,
      "learning_rate": 0.07226922127919355,
      "loss": 0.8713,
      "step": 172000
    },
    {
      "epoch": 277.45,
      "learning_rate": 0.07226599547596774,
      "loss": 0.9011,
      "step": 172020
    },
    {
      "epoch": 277.48,
      "learning_rate": 0.07226276967274195,
      "loss": 0.8895,
      "step": 172040
    },
    {
      "epoch": 277.52,
      "learning_rate": 0.07225954386951614,
      "loss": 0.8998,
      "step": 172060
    },
    {
      "epoch": 277.55,
      "learning_rate": 0.07225631806629033,
      "loss": 0.9015,
      "step": 172080
    },
    {
      "epoch": 277.58,
      "learning_rate": 0.07225309226306452,
      "loss": 0.8859,
      "step": 172100
    },
    {
      "epoch": 277.61,
      "learning_rate": 0.07224986645983872,
      "loss": 0.8992,
      "step": 172120
    },
    {
      "epoch": 277.65,
      "learning_rate": 0.0722466406566129,
      "loss": 0.8656,
      "step": 172140
    },
    {
      "epoch": 277.68,
      "learning_rate": 0.0722434148533871,
      "loss": 0.8916,
      "step": 172160
    },
    {
      "epoch": 277.71,
      "learning_rate": 0.07224018905016129,
      "loss": 0.8915,
      "step": 172180
    },
    {
      "epoch": 277.74,
      "learning_rate": 0.07223696324693549,
      "loss": 0.8981,
      "step": 172200
    },
    {
      "epoch": 277.77,
      "learning_rate": 0.07223373744370969,
      "loss": 0.8794,
      "step": 172220
    },
    {
      "epoch": 277.81,
      "learning_rate": 0.07223051164048387,
      "loss": 0.884,
      "step": 172240
    },
    {
      "epoch": 277.84,
      "learning_rate": 0.07222728583725807,
      "loss": 0.8881,
      "step": 172260
    },
    {
      "epoch": 277.87,
      "learning_rate": 0.07222406003403227,
      "loss": 0.8882,
      "step": 172280
    },
    {
      "epoch": 277.9,
      "learning_rate": 0.07222083423080645,
      "loss": 0.8741,
      "step": 172300
    },
    {
      "epoch": 277.94,
      "learning_rate": 0.07221760842758064,
      "loss": 0.8601,
      "step": 172320
    },
    {
      "epoch": 277.97,
      "learning_rate": 0.07221438262435485,
      "loss": 0.8931,
      "step": 172340
    },
    {
      "epoch": 278.0,
      "learning_rate": 0.07221115682112904,
      "loss": 0.8778,
      "step": 172360
    },
    {
      "epoch": 278.0,
      "eval_accuracy": {
        "accuracy": 0.7429552728124268
      },
      "eval_loss": 1.3166462182998657,
      "eval_runtime": 2.9055,
      "eval_samples_per_second": 4409.258,
      "eval_steps_per_second": 69.18,
      "step": 172360
    },
    {
      "epoch": 278.03,
      "learning_rate": 0.07220793101790324,
      "loss": 0.9088,
      "step": 172380
    },
    {
      "epoch": 278.06,
      "learning_rate": 0.07220470521467742,
      "loss": 0.8973,
      "step": 172400
    },
    {
      "epoch": 278.1,
      "learning_rate": 0.07220147941145162,
      "loss": 0.8765,
      "step": 172420
    },
    {
      "epoch": 278.13,
      "learning_rate": 0.07219825360822581,
      "loss": 0.8831,
      "step": 172440
    },
    {
      "epoch": 278.16,
      "learning_rate": 0.072195027805,
      "loss": 0.8489,
      "step": 172460
    },
    {
      "epoch": 278.19,
      "learning_rate": 0.07219180200177419,
      "loss": 0.9103,
      "step": 172480
    },
    {
      "epoch": 278.23,
      "learning_rate": 0.07218857619854839,
      "loss": 0.9156,
      "step": 172500
    },
    {
      "epoch": 278.26,
      "learning_rate": 0.07218535039532259,
      "loss": 0.8589,
      "step": 172520
    },
    {
      "epoch": 278.29,
      "learning_rate": 0.07218212459209677,
      "loss": 0.8988,
      "step": 172540
    },
    {
      "epoch": 278.32,
      "learning_rate": 0.07217889878887097,
      "loss": 0.9023,
      "step": 172560
    },
    {
      "epoch": 278.35,
      "learning_rate": 0.07217567298564517,
      "loss": 0.8968,
      "step": 172580
    },
    {
      "epoch": 278.39,
      "learning_rate": 0.07217244718241936,
      "loss": 0.8705,
      "step": 172600
    },
    {
      "epoch": 278.42,
      "learning_rate": 0.07216922137919354,
      "loss": 0.8653,
      "step": 172620
    },
    {
      "epoch": 278.45,
      "learning_rate": 0.07216599557596776,
      "loss": 0.8506,
      "step": 172640
    },
    {
      "epoch": 278.48,
      "learning_rate": 0.07216276977274193,
      "loss": 0.8581,
      "step": 172660
    },
    {
      "epoch": 278.52,
      "learning_rate": 0.07215954396951614,
      "loss": 0.8737,
      "step": 172680
    },
    {
      "epoch": 278.55,
      "learning_rate": 0.07215631816629033,
      "loss": 0.8622,
      "step": 172700
    },
    {
      "epoch": 278.58,
      "learning_rate": 0.07215309236306452,
      "loss": 0.8615,
      "step": 172720
    },
    {
      "epoch": 278.61,
      "learning_rate": 0.07214986655983871,
      "loss": 0.8884,
      "step": 172740
    },
    {
      "epoch": 278.65,
      "learning_rate": 0.07214664075661291,
      "loss": 0.8726,
      "step": 172760
    },
    {
      "epoch": 278.68,
      "learning_rate": 0.0721434149533871,
      "loss": 0.89,
      "step": 172780
    },
    {
      "epoch": 278.71,
      "learning_rate": 0.0721401891501613,
      "loss": 0.8714,
      "step": 172800
    },
    {
      "epoch": 278.74,
      "learning_rate": 0.07213696334693549,
      "loss": 0.8735,
      "step": 172820
    },
    {
      "epoch": 278.77,
      "learning_rate": 0.07213373754370968,
      "loss": 0.8604,
      "step": 172840
    },
    {
      "epoch": 278.81,
      "learning_rate": 0.07213051174048388,
      "loss": 0.881,
      "step": 172860
    },
    {
      "epoch": 278.84,
      "learning_rate": 0.07212728593725808,
      "loss": 0.8963,
      "step": 172880
    },
    {
      "epoch": 278.87,
      "learning_rate": 0.07212406013403226,
      "loss": 0.9041,
      "step": 172900
    },
    {
      "epoch": 278.9,
      "learning_rate": 0.07212083433080645,
      "loss": 0.88,
      "step": 172920
    },
    {
      "epoch": 278.94,
      "learning_rate": 0.07211760852758066,
      "loss": 0.8852,
      "step": 172940
    },
    {
      "epoch": 278.97,
      "learning_rate": 0.07211438272435483,
      "loss": 0.905,
      "step": 172960
    },
    {
      "epoch": 279.0,
      "learning_rate": 0.07211115692112904,
      "loss": 0.8786,
      "step": 172980
    },
    {
      "epoch": 279.0,
      "eval_accuracy": {
        "accuracy": 0.7452189524627273
      },
      "eval_loss": 1.267132043838501,
      "eval_runtime": 2.725,
      "eval_samples_per_second": 4701.225,
      "eval_steps_per_second": 73.761,
      "step": 172980
    },
    {
      "epoch": 279.03,
      "learning_rate": 0.07210793111790323,
      "loss": 0.8789,
      "step": 173000
    },
    {
      "epoch": 279.06,
      "learning_rate": 0.07210470531467743,
      "loss": 0.84,
      "step": 173020
    },
    {
      "epoch": 279.1,
      "learning_rate": 0.07210147951145161,
      "loss": 0.857,
      "step": 173040
    },
    {
      "epoch": 279.13,
      "learning_rate": 0.07209825370822581,
      "loss": 0.8599,
      "step": 173060
    },
    {
      "epoch": 279.16,
      "learning_rate": 0.072095027905,
      "loss": 0.8443,
      "step": 173080
    },
    {
      "epoch": 279.19,
      "learning_rate": 0.0720918021017742,
      "loss": 0.8645,
      "step": 173100
    },
    {
      "epoch": 279.23,
      "learning_rate": 0.0720885762985484,
      "loss": 0.8598,
      "step": 173120
    },
    {
      "epoch": 279.26,
      "learning_rate": 0.07208535049532258,
      "loss": 0.864,
      "step": 173140
    },
    {
      "epoch": 279.29,
      "learning_rate": 0.07208212469209678,
      "loss": 0.8797,
      "step": 173160
    },
    {
      "epoch": 279.32,
      "learning_rate": 0.07207889888887098,
      "loss": 0.9054,
      "step": 173180
    },
    {
      "epoch": 279.35,
      "learning_rate": 0.07207567308564516,
      "loss": 0.8881,
      "step": 173200
    },
    {
      "epoch": 279.39,
      "learning_rate": 0.07207244728241935,
      "loss": 0.8988,
      "step": 173220
    },
    {
      "epoch": 279.42,
      "learning_rate": 0.07206922147919356,
      "loss": 0.9015,
      "step": 173240
    },
    {
      "epoch": 279.45,
      "learning_rate": 0.07206599567596773,
      "loss": 0.8849,
      "step": 173260
    },
    {
      "epoch": 279.48,
      "learning_rate": 0.07206276987274195,
      "loss": 0.876,
      "step": 173280
    },
    {
      "epoch": 279.52,
      "learning_rate": 0.07205954406951613,
      "loss": 0.8692,
      "step": 173300
    },
    {
      "epoch": 279.55,
      "learning_rate": 0.07205631826629033,
      "loss": 0.8599,
      "step": 173320
    },
    {
      "epoch": 279.58,
      "learning_rate": 0.07205309246306452,
      "loss": 0.8644,
      "step": 173340
    },
    {
      "epoch": 279.61,
      "learning_rate": 0.07204986665983872,
      "loss": 0.8669,
      "step": 173360
    },
    {
      "epoch": 279.65,
      "learning_rate": 0.0720466408566129,
      "loss": 0.8598,
      "step": 173380
    },
    {
      "epoch": 279.68,
      "learning_rate": 0.0720434150533871,
      "loss": 0.8637,
      "step": 173400
    },
    {
      "epoch": 279.71,
      "learning_rate": 0.0720401892501613,
      "loss": 0.8856,
      "step": 173420
    },
    {
      "epoch": 279.74,
      "learning_rate": 0.07203696344693548,
      "loss": 0.8857,
      "step": 173440
    },
    {
      "epoch": 279.77,
      "learning_rate": 0.07203373764370968,
      "loss": 0.8792,
      "step": 173460
    },
    {
      "epoch": 279.81,
      "learning_rate": 0.07203051184048388,
      "loss": 0.8997,
      "step": 173480
    },
    {
      "epoch": 279.84,
      "learning_rate": 0.07202728603725807,
      "loss": 0.8825,
      "step": 173500
    },
    {
      "epoch": 279.87,
      "learning_rate": 0.07202406023403227,
      "loss": 0.882,
      "step": 173520
    },
    {
      "epoch": 279.9,
      "learning_rate": 0.07202083443080647,
      "loss": 0.9189,
      "step": 173540
    },
    {
      "epoch": 279.94,
      "learning_rate": 0.07201760862758064,
      "loss": 0.9346,
      "step": 173560
    },
    {
      "epoch": 279.97,
      "learning_rate": 0.07201438282435485,
      "loss": 0.8945,
      "step": 173580
    },
    {
      "epoch": 280.0,
      "learning_rate": 0.07201115702112904,
      "loss": 0.8671,
      "step": 173600
    },
    {
      "epoch": 280.0,
      "eval_accuracy": {
        "accuracy": 0.7399890718913433
      },
      "eval_loss": 1.296852469444275,
      "eval_runtime": 2.9007,
      "eval_samples_per_second": 4416.588,
      "eval_steps_per_second": 69.295,
      "step": 173600
    },
    {
      "epoch": 280.03,
      "learning_rate": 0.07200793121790323,
      "loss": 0.9169,
      "step": 173620
    },
    {
      "epoch": 280.06,
      "learning_rate": 0.07200470541467742,
      "loss": 0.8588,
      "step": 173640
    },
    {
      "epoch": 280.1,
      "learning_rate": 0.07200147961145162,
      "loss": 0.864,
      "step": 173660
    },
    {
      "epoch": 280.13,
      "learning_rate": 0.0719982538082258,
      "loss": 0.8523,
      "step": 173680
    },
    {
      "epoch": 280.16,
      "learning_rate": 0.071995028005,
      "loss": 0.8632,
      "step": 173700
    },
    {
      "epoch": 280.19,
      "learning_rate": 0.0719918022017742,
      "loss": 0.8518,
      "step": 173720
    },
    {
      "epoch": 280.23,
      "learning_rate": 0.07198857639854839,
      "loss": 0.858,
      "step": 173740
    },
    {
      "epoch": 280.26,
      "learning_rate": 0.07198535059532259,
      "loss": 0.8687,
      "step": 173760
    },
    {
      "epoch": 280.29,
      "learning_rate": 0.07198212479209679,
      "loss": 0.8731,
      "step": 173780
    },
    {
      "epoch": 280.32,
      "learning_rate": 0.07197889898887097,
      "loss": 0.8558,
      "step": 173800
    },
    {
      "epoch": 280.35,
      "learning_rate": 0.07197567318564517,
      "loss": 0.8786,
      "step": 173820
    },
    {
      "epoch": 280.39,
      "learning_rate": 0.07197244738241937,
      "loss": 0.8625,
      "step": 173840
    },
    {
      "epoch": 280.42,
      "learning_rate": 0.07196922157919354,
      "loss": 0.87,
      "step": 173860
    },
    {
      "epoch": 280.45,
      "learning_rate": 0.07196599577596775,
      "loss": 0.8691,
      "step": 173880
    },
    {
      "epoch": 280.48,
      "learning_rate": 0.07196293126290323,
      "loss": 0.8701,
      "step": 173900
    },
    {
      "epoch": 280.52,
      "learning_rate": 0.07195970545967742,
      "loss": 0.8758,
      "step": 173920
    },
    {
      "epoch": 280.55,
      "learning_rate": 0.07195647965645162,
      "loss": 0.8494,
      "step": 173940
    },
    {
      "epoch": 280.58,
      "learning_rate": 0.07195325385322582,
      "loss": 0.8885,
      "step": 173960
    },
    {
      "epoch": 280.61,
      "learning_rate": 0.07195002805,
      "loss": 0.8851,
      "step": 173980
    },
    {
      "epoch": 280.65,
      "learning_rate": 0.07194696353693548,
      "loss": 0.889,
      "step": 174000
    },
    {
      "epoch": 280.68,
      "learning_rate": 0.07194373773370968,
      "loss": 0.856,
      "step": 174020
    },
    {
      "epoch": 280.71,
      "learning_rate": 0.07194051193048387,
      "loss": 0.8597,
      "step": 174040
    },
    {
      "epoch": 280.74,
      "learning_rate": 0.07193728612725807,
      "loss": 0.8671,
      "step": 174060
    },
    {
      "epoch": 280.77,
      "learning_rate": 0.07193406032403227,
      "loss": 0.8874,
      "step": 174080
    },
    {
      "epoch": 280.81,
      "learning_rate": 0.07193083452080645,
      "loss": 0.9218,
      "step": 174100
    },
    {
      "epoch": 280.84,
      "learning_rate": 0.07192760871758065,
      "loss": 0.902,
      "step": 174120
    },
    {
      "epoch": 280.87,
      "learning_rate": 0.07192438291435484,
      "loss": 0.8987,
      "step": 174140
    },
    {
      "epoch": 280.9,
      "learning_rate": 0.07192115711112904,
      "loss": 0.8988,
      "step": 174160
    },
    {
      "epoch": 280.94,
      "learning_rate": 0.07191793130790322,
      "loss": 0.8828,
      "step": 174180
    },
    {
      "epoch": 280.97,
      "learning_rate": 0.07191470550467743,
      "loss": 0.8722,
      "step": 174200
    },
    {
      "epoch": 281.0,
      "learning_rate": 0.07191147970145162,
      "loss": 0.8875,
      "step": 174220
    },
    {
      "epoch": 281.0,
      "eval_accuracy": {
        "accuracy": 0.7431894465693545
      },
      "eval_loss": 1.2638477087020874,
      "eval_runtime": 2.8703,
      "eval_samples_per_second": 4463.225,
      "eval_steps_per_second": 70.026,
      "step": 174220
    },
    {
      "epoch": 281.03,
      "learning_rate": 0.07190825389822582,
      "loss": 0.899,
      "step": 174240
    },
    {
      "epoch": 281.06,
      "learning_rate": 0.071905028095,
      "loss": 0.8884,
      "step": 174260
    },
    {
      "epoch": 281.1,
      "learning_rate": 0.07190180229177419,
      "loss": 0.8791,
      "step": 174280
    },
    {
      "epoch": 281.13,
      "learning_rate": 0.07189857648854839,
      "loss": 0.9006,
      "step": 174300
    },
    {
      "epoch": 281.16,
      "learning_rate": 0.07189535068532259,
      "loss": 0.9034,
      "step": 174320
    },
    {
      "epoch": 281.19,
      "learning_rate": 0.07189212488209677,
      "loss": 0.8673,
      "step": 174340
    },
    {
      "epoch": 281.23,
      "learning_rate": 0.07188889907887097,
      "loss": 0.8623,
      "step": 174360
    },
    {
      "epoch": 281.26,
      "learning_rate": 0.07188567327564517,
      "loss": 0.8774,
      "step": 174380
    },
    {
      "epoch": 281.29,
      "learning_rate": 0.07188244747241936,
      "loss": 0.9095,
      "step": 174400
    },
    {
      "epoch": 281.32,
      "learning_rate": 0.07187922166919355,
      "loss": 0.8541,
      "step": 174420
    },
    {
      "epoch": 281.35,
      "learning_rate": 0.07187599586596774,
      "loss": 0.8704,
      "step": 174440
    },
    {
      "epoch": 281.39,
      "learning_rate": 0.07187277006274194,
      "loss": 0.8521,
      "step": 174460
    },
    {
      "epoch": 281.42,
      "learning_rate": 0.07186954425951612,
      "loss": 0.8763,
      "step": 174480
    },
    {
      "epoch": 281.45,
      "learning_rate": 0.07186631845629034,
      "loss": 0.8638,
      "step": 174500
    },
    {
      "epoch": 281.48,
      "learning_rate": 0.07186309265306452,
      "loss": 0.8927,
      "step": 174520
    },
    {
      "epoch": 281.52,
      "learning_rate": 0.07185986684983872,
      "loss": 0.8637,
      "step": 174540
    },
    {
      "epoch": 281.55,
      "learning_rate": 0.0718566410466129,
      "loss": 0.8839,
      "step": 174560
    },
    {
      "epoch": 281.58,
      "learning_rate": 0.0718534152433871,
      "loss": 0.8995,
      "step": 174580
    },
    {
      "epoch": 281.61,
      "learning_rate": 0.07185018944016129,
      "loss": 0.8917,
      "step": 174600
    },
    {
      "epoch": 281.65,
      "learning_rate": 0.07184696363693549,
      "loss": 0.8718,
      "step": 174620
    },
    {
      "epoch": 281.68,
      "learning_rate": 0.07184373783370968,
      "loss": 0.8622,
      "step": 174640
    },
    {
      "epoch": 281.71,
      "learning_rate": 0.07184051203048387,
      "loss": 0.8629,
      "step": 174660
    },
    {
      "epoch": 281.74,
      "learning_rate": 0.07183728622725807,
      "loss": 0.8964,
      "step": 174680
    },
    {
      "epoch": 281.77,
      "learning_rate": 0.07183406042403226,
      "loss": 0.8846,
      "step": 174700
    },
    {
      "epoch": 281.81,
      "learning_rate": 0.07183083462080646,
      "loss": 0.8941,
      "step": 174720
    },
    {
      "epoch": 281.84,
      "learning_rate": 0.07182760881758066,
      "loss": 0.8968,
      "step": 174740
    },
    {
      "epoch": 281.87,
      "learning_rate": 0.07182438301435484,
      "loss": 0.8843,
      "step": 174760
    },
    {
      "epoch": 281.9,
      "learning_rate": 0.07182115721112903,
      "loss": 0.8976,
      "step": 174780
    },
    {
      "epoch": 281.94,
      "learning_rate": 0.07181793140790324,
      "loss": 0.8949,
      "step": 174800
    },
    {
      "epoch": 281.97,
      "learning_rate": 0.07181470560467741,
      "loss": 0.8992,
      "step": 174820
    },
    {
      "epoch": 282.0,
      "learning_rate": 0.07181147980145162,
      "loss": 0.9,
      "step": 174840
    },
    {
      "epoch": 282.0,
      "eval_accuracy": {
        "accuracy": 0.7462337054094138
      },
      "eval_loss": 1.2441333532333374,
      "eval_runtime": 2.7275,
      "eval_samples_per_second": 4697.026,
      "eval_steps_per_second": 73.695,
      "step": 174840
    },
    {
      "epoch": 282.03,
      "learning_rate": 0.07180825399822581,
      "loss": 0.8999,
      "step": 174860
    },
    {
      "epoch": 282.06,
      "learning_rate": 0.07180502819500001,
      "loss": 0.8685,
      "step": 174880
    },
    {
      "epoch": 282.1,
      "learning_rate": 0.0718018023917742,
      "loss": 0.8468,
      "step": 174900
    },
    {
      "epoch": 282.13,
      "learning_rate": 0.0717985765885484,
      "loss": 0.8429,
      "step": 174920
    },
    {
      "epoch": 282.16,
      "learning_rate": 0.07179535078532258,
      "loss": 0.8553,
      "step": 174940
    },
    {
      "epoch": 282.19,
      "learning_rate": 0.07179212498209678,
      "loss": 0.873,
      "step": 174960
    },
    {
      "epoch": 282.23,
      "learning_rate": 0.07178889917887098,
      "loss": 0.8626,
      "step": 174980
    },
    {
      "epoch": 282.26,
      "learning_rate": 0.07178567337564516,
      "loss": 0.8669,
      "step": 175000
    },
    {
      "epoch": 282.29,
      "learning_rate": 0.07178244757241936,
      "loss": 0.8578,
      "step": 175020
    },
    {
      "epoch": 282.32,
      "learning_rate": 0.07177922176919356,
      "loss": 0.8888,
      "step": 175040
    },
    {
      "epoch": 282.35,
      "learning_rate": 0.07177599596596775,
      "loss": 0.8806,
      "step": 175060
    },
    {
      "epoch": 282.39,
      "learning_rate": 0.07177277016274193,
      "loss": 0.8765,
      "step": 175080
    },
    {
      "epoch": 282.42,
      "learning_rate": 0.07176954435951614,
      "loss": 0.883,
      "step": 175100
    },
    {
      "epoch": 282.45,
      "learning_rate": 0.07176631855629031,
      "loss": 0.8824,
      "step": 175120
    },
    {
      "epoch": 282.48,
      "learning_rate": 0.07176309275306453,
      "loss": 0.8569,
      "step": 175140
    },
    {
      "epoch": 282.52,
      "learning_rate": 0.07175986694983871,
      "loss": 0.8557,
      "step": 175160
    },
    {
      "epoch": 282.55,
      "learning_rate": 0.07175664114661291,
      "loss": 0.8868,
      "step": 175180
    },
    {
      "epoch": 282.58,
      "learning_rate": 0.0717534153433871,
      "loss": 0.8951,
      "step": 175200
    },
    {
      "epoch": 282.61,
      "learning_rate": 0.0717501895401613,
      "loss": 0.8753,
      "step": 175220
    },
    {
      "epoch": 282.65,
      "learning_rate": 0.07174696373693548,
      "loss": 0.8532,
      "step": 175240
    },
    {
      "epoch": 282.68,
      "learning_rate": 0.07174373793370968,
      "loss": 0.8555,
      "step": 175260
    },
    {
      "epoch": 282.71,
      "learning_rate": 0.07174051213048388,
      "loss": 0.8664,
      "step": 175280
    },
    {
      "epoch": 282.74,
      "learning_rate": 0.07173728632725807,
      "loss": 0.8623,
      "step": 175300
    },
    {
      "epoch": 282.77,
      "learning_rate": 0.07173406052403226,
      "loss": 0.8927,
      "step": 175320
    },
    {
      "epoch": 282.81,
      "learning_rate": 0.07173083472080646,
      "loss": 0.886,
      "step": 175340
    },
    {
      "epoch": 282.84,
      "learning_rate": 0.07172760891758065,
      "loss": 0.8838,
      "step": 175360
    },
    {
      "epoch": 282.87,
      "learning_rate": 0.07172438311435483,
      "loss": 0.8598,
      "step": 175380
    },
    {
      "epoch": 282.9,
      "learning_rate": 0.07172115731112905,
      "loss": 0.8731,
      "step": 175400
    },
    {
      "epoch": 282.94,
      "learning_rate": 0.07171793150790322,
      "loss": 0.8957,
      "step": 175420
    },
    {
      "epoch": 282.97,
      "learning_rate": 0.07171470570467743,
      "loss": 0.9114,
      "step": 175440
    },
    {
      "epoch": 283.0,
      "learning_rate": 0.07171147990145162,
      "loss": 0.899,
      "step": 175460
    },
    {
      "epoch": 283.0,
      "eval_accuracy": {
        "accuracy": 0.7433455624073062
      },
      "eval_loss": 1.2817984819412231,
      "eval_runtime": 2.7853,
      "eval_samples_per_second": 4599.497,
      "eval_steps_per_second": 72.164,
      "step": 175460
    },
    {
      "epoch": 283.03,
      "learning_rate": 0.07170825409822582,
      "loss": 0.8919,
      "step": 175480
    },
    {
      "epoch": 283.06,
      "learning_rate": 0.071705028295,
      "loss": 0.8914,
      "step": 175500
    },
    {
      "epoch": 283.1,
      "learning_rate": 0.0717018024917742,
      "loss": 0.8655,
      "step": 175520
    },
    {
      "epoch": 283.13,
      "learning_rate": 0.07169857668854838,
      "loss": 0.8552,
      "step": 175540
    },
    {
      "epoch": 283.16,
      "learning_rate": 0.07169535088532258,
      "loss": 0.8646,
      "step": 175560
    },
    {
      "epoch": 283.19,
      "learning_rate": 0.07169212508209678,
      "loss": 0.8945,
      "step": 175580
    },
    {
      "epoch": 283.23,
      "learning_rate": 0.07168889927887097,
      "loss": 0.8662,
      "step": 175600
    },
    {
      "epoch": 283.26,
      "learning_rate": 0.07168567347564517,
      "loss": 0.896,
      "step": 175620
    },
    {
      "epoch": 283.29,
      "learning_rate": 0.07168244767241937,
      "loss": 0.8913,
      "step": 175640
    },
    {
      "epoch": 283.32,
      "learning_rate": 0.07167922186919355,
      "loss": 0.8417,
      "step": 175660
    },
    {
      "epoch": 283.35,
      "learning_rate": 0.07167599606596774,
      "loss": 0.8682,
      "step": 175680
    },
    {
      "epoch": 283.39,
      "learning_rate": 0.07167277026274195,
      "loss": 0.8963,
      "step": 175700
    },
    {
      "epoch": 283.42,
      "learning_rate": 0.07166954445951612,
      "loss": 0.8651,
      "step": 175720
    },
    {
      "epoch": 283.45,
      "learning_rate": 0.07166631865629033,
      "loss": 0.8407,
      "step": 175740
    },
    {
      "epoch": 283.48,
      "learning_rate": 0.07166309285306452,
      "loss": 0.8742,
      "step": 175760
    },
    {
      "epoch": 283.52,
      "learning_rate": 0.07165986704983872,
      "loss": 0.8756,
      "step": 175780
    },
    {
      "epoch": 283.55,
      "learning_rate": 0.0716566412466129,
      "loss": 0.8671,
      "step": 175800
    },
    {
      "epoch": 283.58,
      "learning_rate": 0.0716534154433871,
      "loss": 0.9116,
      "step": 175820
    },
    {
      "epoch": 283.61,
      "learning_rate": 0.07165018964016129,
      "loss": 0.8696,
      "step": 175840
    },
    {
      "epoch": 283.65,
      "learning_rate": 0.07164696383693549,
      "loss": 0.8629,
      "step": 175860
    },
    {
      "epoch": 283.68,
      "learning_rate": 0.07164373803370969,
      "loss": 0.8783,
      "step": 175880
    },
    {
      "epoch": 283.71,
      "learning_rate": 0.07164051223048387,
      "loss": 0.8546,
      "step": 175900
    },
    {
      "epoch": 283.74,
      "learning_rate": 0.07163728642725807,
      "loss": 0.8662,
      "step": 175920
    },
    {
      "epoch": 283.77,
      "learning_rate": 0.07163406062403227,
      "loss": 0.8929,
      "step": 175940
    },
    {
      "epoch": 283.81,
      "learning_rate": 0.07163083482080645,
      "loss": 0.8666,
      "step": 175960
    },
    {
      "epoch": 283.84,
      "learning_rate": 0.07162760901758065,
      "loss": 0.8904,
      "step": 175980
    },
    {
      "epoch": 283.87,
      "learning_rate": 0.07162438321435485,
      "loss": 0.8876,
      "step": 176000
    },
    {
      "epoch": 283.9,
      "learning_rate": 0.07162115741112902,
      "loss": 0.882,
      "step": 176020
    },
    {
      "epoch": 283.94,
      "learning_rate": 0.07161793160790324,
      "loss": 0.8916,
      "step": 176040
    },
    {
      "epoch": 283.97,
      "learning_rate": 0.07161470580467742,
      "loss": 0.9203,
      "step": 176060
    },
    {
      "epoch": 284.0,
      "learning_rate": 0.07161148000145162,
      "loss": 0.8727,
      "step": 176080
    },
    {
      "epoch": 284.0,
      "eval_accuracy": {
        "accuracy": 0.7465459370853174
      },
      "eval_loss": 1.2308987379074097,
      "eval_runtime": 2.8339,
      "eval_samples_per_second": 4520.638,
      "eval_steps_per_second": 70.927,
      "step": 176080
    },
    {
      "epoch": 284.03,
      "learning_rate": 0.07160825419822581,
      "loss": 0.894,
      "step": 176100
    },
    {
      "epoch": 284.06,
      "learning_rate": 0.071605028395,
      "loss": 0.8665,
      "step": 176120
    },
    {
      "epoch": 284.1,
      "learning_rate": 0.07160180259177419,
      "loss": 0.8867,
      "step": 176140
    },
    {
      "epoch": 284.13,
      "learning_rate": 0.07159857678854839,
      "loss": 0.874,
      "step": 176160
    },
    {
      "epoch": 284.16,
      "learning_rate": 0.07159535098532259,
      "loss": 0.8799,
      "step": 176180
    },
    {
      "epoch": 284.19,
      "learning_rate": 0.07159212518209677,
      "loss": 0.8683,
      "step": 176200
    },
    {
      "epoch": 284.23,
      "learning_rate": 0.07158889937887097,
      "loss": 0.8549,
      "step": 176220
    },
    {
      "epoch": 284.26,
      "learning_rate": 0.07158567357564517,
      "loss": 0.8691,
      "step": 176240
    },
    {
      "epoch": 284.29,
      "learning_rate": 0.07158244777241936,
      "loss": 0.8823,
      "step": 176260
    },
    {
      "epoch": 284.32,
      "learning_rate": 0.07157922196919356,
      "loss": 0.8719,
      "step": 176280
    },
    {
      "epoch": 284.35,
      "learning_rate": 0.07157599616596776,
      "loss": 0.8699,
      "step": 176300
    },
    {
      "epoch": 284.39,
      "learning_rate": 0.07157277036274193,
      "loss": 0.8649,
      "step": 176320
    },
    {
      "epoch": 284.42,
      "learning_rate": 0.07156954455951614,
      "loss": 0.8535,
      "step": 176340
    },
    {
      "epoch": 284.45,
      "learning_rate": 0.07156631875629033,
      "loss": 0.893,
      "step": 176360
    },
    {
      "epoch": 284.48,
      "learning_rate": 0.07156309295306452,
      "loss": 0.886,
      "step": 176380
    },
    {
      "epoch": 284.52,
      "learning_rate": 0.07155986714983871,
      "loss": 0.8659,
      "step": 176400
    },
    {
      "epoch": 284.55,
      "learning_rate": 0.07155664134661291,
      "loss": 0.8572,
      "step": 176420
    },
    {
      "epoch": 284.58,
      "learning_rate": 0.0715534155433871,
      "loss": 0.8813,
      "step": 176440
    },
    {
      "epoch": 284.61,
      "learning_rate": 0.0715501897401613,
      "loss": 0.8856,
      "step": 176460
    },
    {
      "epoch": 284.65,
      "learning_rate": 0.07154696393693549,
      "loss": 0.8688,
      "step": 176480
    },
    {
      "epoch": 284.68,
      "learning_rate": 0.07154373813370968,
      "loss": 0.9055,
      "step": 176500
    },
    {
      "epoch": 284.71,
      "learning_rate": 0.07154051233048388,
      "loss": 0.8794,
      "step": 176520
    },
    {
      "epoch": 284.74,
      "learning_rate": 0.07153728652725808,
      "loss": 0.8872,
      "step": 176540
    },
    {
      "epoch": 284.77,
      "learning_rate": 0.07153406072403226,
      "loss": 0.8703,
      "step": 176560
    },
    {
      "epoch": 284.81,
      "learning_rate": 0.07153083492080646,
      "loss": 0.9056,
      "step": 176580
    },
    {
      "epoch": 284.84,
      "learning_rate": 0.07152760911758065,
      "loss": 0.8999,
      "step": 176600
    },
    {
      "epoch": 284.87,
      "learning_rate": 0.07152438331435483,
      "loss": 0.89,
      "step": 176620
    },
    {
      "epoch": 284.9,
      "learning_rate": 0.07152115751112904,
      "loss": 0.9066,
      "step": 176640
    },
    {
      "epoch": 284.94,
      "learning_rate": 0.07151793170790323,
      "loss": 0.9118,
      "step": 176660
    },
    {
      "epoch": 284.97,
      "learning_rate": 0.07151470590467743,
      "loss": 0.8761,
      "step": 176680
    },
    {
      "epoch": 285.0,
      "learning_rate": 0.07151164139161291,
      "loss": 0.878,
      "step": 176700
    },
    {
      "epoch": 285.0,
      "eval_accuracy": {
        "accuracy": 0.75255639684646
      },
      "eval_loss": 1.2293901443481445,
      "eval_runtime": 2.7607,
      "eval_samples_per_second": 4640.568,
      "eval_steps_per_second": 72.809,
      "step": 176700
    },
    {
      "epoch": 285.03,
      "learning_rate": 0.07150841558838711,
      "loss": 0.8463,
      "step": 176720
    },
    {
      "epoch": 285.06,
      "learning_rate": 0.0715051897851613,
      "loss": 0.8682,
      "step": 176740
    },
    {
      "epoch": 285.1,
      "learning_rate": 0.07150196398193548,
      "loss": 0.8551,
      "step": 176760
    },
    {
      "epoch": 285.13,
      "learning_rate": 0.07149873817870969,
      "loss": 0.8839,
      "step": 176780
    },
    {
      "epoch": 285.16,
      "learning_rate": 0.07149551237548386,
      "loss": 0.8718,
      "step": 176800
    },
    {
      "epoch": 285.19,
      "learning_rate": 0.07149228657225808,
      "loss": 0.8713,
      "step": 176820
    },
    {
      "epoch": 285.23,
      "learning_rate": 0.07148906076903226,
      "loss": 0.8937,
      "step": 176840
    },
    {
      "epoch": 285.26,
      "learning_rate": 0.07148583496580646,
      "loss": 0.8757,
      "step": 176860
    },
    {
      "epoch": 285.29,
      "learning_rate": 0.07148260916258065,
      "loss": 0.8605,
      "step": 176880
    },
    {
      "epoch": 285.32,
      "learning_rate": 0.07147938335935484,
      "loss": 0.8606,
      "step": 176900
    },
    {
      "epoch": 285.35,
      "learning_rate": 0.07147615755612903,
      "loss": 0.8734,
      "step": 176920
    },
    {
      "epoch": 285.39,
      "learning_rate": 0.07147293175290323,
      "loss": 0.8895,
      "step": 176940
    },
    {
      "epoch": 285.42,
      "learning_rate": 0.07146970594967743,
      "loss": 0.8934,
      "step": 176960
    },
    {
      "epoch": 285.45,
      "learning_rate": 0.07146648014645161,
      "loss": 0.8658,
      "step": 176980
    },
    {
      "epoch": 285.48,
      "learning_rate": 0.07146325434322581,
      "loss": 0.8955,
      "step": 177000
    },
    {
      "epoch": 285.52,
      "learning_rate": 0.07146002854000001,
      "loss": 0.8836,
      "step": 177020
    },
    {
      "epoch": 285.55,
      "learning_rate": 0.0714568027367742,
      "loss": 0.8864,
      "step": 177040
    },
    {
      "epoch": 285.58,
      "learning_rate": 0.0714535769335484,
      "loss": 0.8936,
      "step": 177060
    },
    {
      "epoch": 285.61,
      "learning_rate": 0.0714503511303226,
      "loss": 0.861,
      "step": 177080
    },
    {
      "epoch": 285.65,
      "learning_rate": 0.07144712532709677,
      "loss": 0.8791,
      "step": 177100
    },
    {
      "epoch": 285.68,
      "learning_rate": 0.07144389952387098,
      "loss": 0.8885,
      "step": 177120
    },
    {
      "epoch": 285.71,
      "learning_rate": 0.07144067372064516,
      "loss": 0.8954,
      "step": 177140
    },
    {
      "epoch": 285.74,
      "learning_rate": 0.07143744791741936,
      "loss": 0.8582,
      "step": 177160
    },
    {
      "epoch": 285.77,
      "learning_rate": 0.07143422211419355,
      "loss": 0.8679,
      "step": 177180
    },
    {
      "epoch": 285.81,
      "learning_rate": 0.07143099631096775,
      "loss": 0.864,
      "step": 177200
    },
    {
      "epoch": 285.84,
      "learning_rate": 0.07142777050774193,
      "loss": 0.8714,
      "step": 177220
    },
    {
      "epoch": 285.87,
      "learning_rate": 0.07142454470451613,
      "loss": 0.8882,
      "step": 177240
    },
    {
      "epoch": 285.9,
      "learning_rate": 0.07142131890129033,
      "loss": 0.9024,
      "step": 177260
    },
    {
      "epoch": 285.94,
      "learning_rate": 0.07141809309806452,
      "loss": 0.866,
      "step": 177280
    },
    {
      "epoch": 285.97,
      "learning_rate": 0.07141486729483872,
      "loss": 0.8816,
      "step": 177300
    },
    {
      "epoch": 286.0,
      "learning_rate": 0.07141164149161291,
      "loss": 0.8855,
      "step": 177320
    },
    {
      "epoch": 286.0,
      "eval_accuracy": {
        "accuracy": 0.7507610647100148
      },
      "eval_loss": 1.227033257484436,
      "eval_runtime": 3.3123,
      "eval_samples_per_second": 3867.702,
      "eval_steps_per_second": 60.683,
      "step": 177320
    },
    {
      "epoch": 286.03,
      "learning_rate": 0.0714084156883871,
      "loss": 0.9014,
      "step": 177340
    },
    {
      "epoch": 286.06,
      "learning_rate": 0.0714051898851613,
      "loss": 0.881,
      "step": 177360
    },
    {
      "epoch": 286.1,
      "learning_rate": 0.0714019640819355,
      "loss": 0.8733,
      "step": 177380
    },
    {
      "epoch": 286.13,
      "learning_rate": 0.07139873827870967,
      "loss": 0.8569,
      "step": 177400
    },
    {
      "epoch": 286.16,
      "learning_rate": 0.07139551247548388,
      "loss": 0.8577,
      "step": 177420
    },
    {
      "epoch": 286.19,
      "learning_rate": 0.07139228667225807,
      "loss": 0.8556,
      "step": 177440
    },
    {
      "epoch": 286.23,
      "learning_rate": 0.07138906086903227,
      "loss": 0.8532,
      "step": 177460
    },
    {
      "epoch": 286.26,
      "learning_rate": 0.07138583506580645,
      "loss": 0.8521,
      "step": 177480
    },
    {
      "epoch": 286.29,
      "learning_rate": 0.07138260926258065,
      "loss": 0.849,
      "step": 177500
    },
    {
      "epoch": 286.32,
      "learning_rate": 0.07137938345935484,
      "loss": 0.8467,
      "step": 177520
    },
    {
      "epoch": 286.35,
      "learning_rate": 0.07137615765612904,
      "loss": 0.8719,
      "step": 177540
    },
    {
      "epoch": 286.39,
      "learning_rate": 0.07137293185290323,
      "loss": 0.8792,
      "step": 177560
    },
    {
      "epoch": 286.42,
      "learning_rate": 0.07136970604967742,
      "loss": 0.8742,
      "step": 177580
    },
    {
      "epoch": 286.45,
      "learning_rate": 0.07136648024645162,
      "loss": 0.8685,
      "step": 177600
    },
    {
      "epoch": 286.48,
      "learning_rate": 0.07136325444322582,
      "loss": 0.8875,
      "step": 177620
    },
    {
      "epoch": 286.52,
      "learning_rate": 0.07136002864,
      "loss": 0.8803,
      "step": 177640
    },
    {
      "epoch": 286.55,
      "learning_rate": 0.0713568028367742,
      "loss": 0.8742,
      "step": 177660
    },
    {
      "epoch": 286.58,
      "learning_rate": 0.07135357703354839,
      "loss": 0.8654,
      "step": 177680
    },
    {
      "epoch": 286.61,
      "learning_rate": 0.07135035123032257,
      "loss": 0.8824,
      "step": 177700
    },
    {
      "epoch": 286.65,
      "learning_rate": 0.07134712542709679,
      "loss": 0.8728,
      "step": 177720
    },
    {
      "epoch": 286.68,
      "learning_rate": 0.07134389962387097,
      "loss": 0.9253,
      "step": 177740
    },
    {
      "epoch": 286.71,
      "learning_rate": 0.07134067382064517,
      "loss": 0.8632,
      "step": 177760
    },
    {
      "epoch": 286.74,
      "learning_rate": 0.07133744801741936,
      "loss": 0.8657,
      "step": 177780
    },
    {
      "epoch": 286.77,
      "learning_rate": 0.07133422221419355,
      "loss": 0.8647,
      "step": 177800
    },
    {
      "epoch": 286.81,
      "learning_rate": 0.07133099641096774,
      "loss": 0.8651,
      "step": 177820
    },
    {
      "epoch": 286.84,
      "learning_rate": 0.07132777060774194,
      "loss": 0.8874,
      "step": 177840
    },
    {
      "epoch": 286.87,
      "learning_rate": 0.07132454480451614,
      "loss": 0.8625,
      "step": 177860
    },
    {
      "epoch": 286.9,
      "learning_rate": 0.07132131900129032,
      "loss": 0.8866,
      "step": 177880
    },
    {
      "epoch": 286.94,
      "learning_rate": 0.07131809319806452,
      "loss": 0.8786,
      "step": 177900
    },
    {
      "epoch": 286.97,
      "learning_rate": 0.07131486739483872,
      "loss": 0.9047,
      "step": 177920
    },
    {
      "epoch": 287.0,
      "learning_rate": 0.0713116415916129,
      "loss": 0.8905,
      "step": 177940
    },
    {
      "epoch": 287.0,
      "eval_accuracy": {
        "accuracy": 0.7479509796268832
      },
      "eval_loss": 1.2784984111785889,
      "eval_runtime": 2.7193,
      "eval_samples_per_second": 4711.225,
      "eval_steps_per_second": 73.917,
      "step": 177940
    },
    {
      "epoch": 287.03,
      "learning_rate": 0.0713084157883871,
      "loss": 0.9114,
      "step": 177960
    },
    {
      "epoch": 287.06,
      "learning_rate": 0.07130518998516129,
      "loss": 0.8991,
      "step": 177980
    },
    {
      "epoch": 287.1,
      "learning_rate": 0.07130196418193548,
      "loss": 0.8651,
      "step": 178000
    },
    {
      "epoch": 287.13,
      "learning_rate": 0.07129873837870969,
      "loss": 0.8591,
      "step": 178020
    },
    {
      "epoch": 287.16,
      "learning_rate": 0.07129551257548387,
      "loss": 0.8762,
      "step": 178040
    },
    {
      "epoch": 287.19,
      "learning_rate": 0.07129228677225807,
      "loss": 0.855,
      "step": 178060
    },
    {
      "epoch": 287.23,
      "learning_rate": 0.07128906096903226,
      "loss": 0.8398,
      "step": 178080
    },
    {
      "epoch": 287.26,
      "learning_rate": 0.07128583516580646,
      "loss": 0.8621,
      "step": 178100
    },
    {
      "epoch": 287.29,
      "learning_rate": 0.07128260936258064,
      "loss": 0.876,
      "step": 178120
    },
    {
      "epoch": 287.32,
      "learning_rate": 0.07127938355935486,
      "loss": 0.8692,
      "step": 178140
    },
    {
      "epoch": 287.35,
      "learning_rate": 0.07127615775612904,
      "loss": 0.8977,
      "step": 178160
    },
    {
      "epoch": 287.39,
      "learning_rate": 0.07127293195290323,
      "loss": 0.8736,
      "step": 178180
    },
    {
      "epoch": 287.42,
      "learning_rate": 0.07126970614967743,
      "loss": 0.8863,
      "step": 178200
    },
    {
      "epoch": 287.45,
      "learning_rate": 0.07126648034645161,
      "loss": 0.8921,
      "step": 178220
    },
    {
      "epoch": 287.48,
      "learning_rate": 0.07126325454322581,
      "loss": 0.8894,
      "step": 178240
    },
    {
      "epoch": 287.52,
      "learning_rate": 0.07126002874000001,
      "loss": 0.8761,
      "step": 178260
    },
    {
      "epoch": 287.55,
      "learning_rate": 0.0712568029367742,
      "loss": 0.8696,
      "step": 178280
    },
    {
      "epoch": 287.58,
      "learning_rate": 0.0712535771335484,
      "loss": 0.8613,
      "step": 178300
    },
    {
      "epoch": 287.61,
      "learning_rate": 0.07125035133032259,
      "loss": 0.8724,
      "step": 178320
    },
    {
      "epoch": 287.65,
      "learning_rate": 0.07124712552709678,
      "loss": 0.859,
      "step": 178340
    },
    {
      "epoch": 287.68,
      "learning_rate": 0.07124389972387098,
      "loss": 0.8832,
      "step": 178360
    },
    {
      "epoch": 287.71,
      "learning_rate": 0.07124067392064516,
      "loss": 0.8842,
      "step": 178380
    },
    {
      "epoch": 287.74,
      "learning_rate": 0.07123744811741936,
      "loss": 0.884,
      "step": 178400
    },
    {
      "epoch": 287.77,
      "learning_rate": 0.07123422231419355,
      "loss": 0.8789,
      "step": 178420
    },
    {
      "epoch": 287.81,
      "learning_rate": 0.07123099651096776,
      "loss": 0.9002,
      "step": 178440
    },
    {
      "epoch": 287.84,
      "learning_rate": 0.07122777070774194,
      "loss": 0.8458,
      "step": 178460
    },
    {
      "epoch": 287.87,
      "learning_rate": 0.07122454490451613,
      "loss": 0.8516,
      "step": 178480
    },
    {
      "epoch": 287.9,
      "learning_rate": 0.07122131910129033,
      "loss": 0.8609,
      "step": 178500
    },
    {
      "epoch": 287.94,
      "learning_rate": 0.07121809329806451,
      "loss": 0.9014,
      "step": 178520
    },
    {
      "epoch": 287.97,
      "learning_rate": 0.07121486749483871,
      "loss": 0.8859,
      "step": 178540
    },
    {
      "epoch": 288.0,
      "learning_rate": 0.07121164169161291,
      "loss": 0.8623,
      "step": 178560
    },
    {
      "epoch": 288.0,
      "eval_accuracy": {
        "accuracy": 0.7391304347826086
      },
      "eval_loss": 1.288456916809082,
      "eval_runtime": 2.7226,
      "eval_samples_per_second": 4705.406,
      "eval_steps_per_second": 73.826,
      "step": 178560
    },
    {
      "epoch": 288.03,
      "learning_rate": 0.0712084158883871,
      "loss": 0.9009,
      "step": 178580
    },
    {
      "epoch": 288.06,
      "learning_rate": 0.0712051900851613,
      "loss": 0.846,
      "step": 178600
    },
    {
      "epoch": 288.1,
      "learning_rate": 0.0712019642819355,
      "loss": 0.8351,
      "step": 178620
    },
    {
      "epoch": 288.13,
      "learning_rate": 0.07119873847870968,
      "loss": 0.8711,
      "step": 178640
    },
    {
      "epoch": 288.16,
      "learning_rate": 0.07119551267548388,
      "loss": 0.8619,
      "step": 178660
    },
    {
      "epoch": 288.19,
      "learning_rate": 0.07119228687225806,
      "loss": 0.8868,
      "step": 178680
    },
    {
      "epoch": 288.23,
      "learning_rate": 0.07118906106903226,
      "loss": 0.8528,
      "step": 178700
    },
    {
      "epoch": 288.26,
      "learning_rate": 0.07118583526580645,
      "loss": 0.8963,
      "step": 178720
    },
    {
      "epoch": 288.29,
      "learning_rate": 0.07118260946258066,
      "loss": 0.8854,
      "step": 178740
    },
    {
      "epoch": 288.32,
      "learning_rate": 0.07117938365935483,
      "loss": 0.8681,
      "step": 178760
    },
    {
      "epoch": 288.35,
      "learning_rate": 0.07117615785612903,
      "loss": 0.8621,
      "step": 178780
    },
    {
      "epoch": 288.39,
      "learning_rate": 0.07117293205290323,
      "loss": 0.8739,
      "step": 178800
    },
    {
      "epoch": 288.42,
      "learning_rate": 0.07116970624967742,
      "loss": 0.8751,
      "step": 178820
    },
    {
      "epoch": 288.45,
      "learning_rate": 0.07116648044645162,
      "loss": 0.8909,
      "step": 178840
    },
    {
      "epoch": 288.48,
      "learning_rate": 0.07116325464322582,
      "loss": 0.8893,
      "step": 178860
    },
    {
      "epoch": 288.52,
      "learning_rate": 0.07116002884,
      "loss": 0.8381,
      "step": 178880
    },
    {
      "epoch": 288.55,
      "learning_rate": 0.0711568030367742,
      "loss": 0.8701,
      "step": 178900
    },
    {
      "epoch": 288.58,
      "learning_rate": 0.0711535772335484,
      "loss": 0.8771,
      "step": 178920
    },
    {
      "epoch": 288.61,
      "learning_rate": 0.07115035143032258,
      "loss": 0.8811,
      "step": 178940
    },
    {
      "epoch": 288.65,
      "learning_rate": 0.07114712562709678,
      "loss": 0.9132,
      "step": 178960
    },
    {
      "epoch": 288.68,
      "learning_rate": 0.07114389982387097,
      "loss": 0.8704,
      "step": 178980
    },
    {
      "epoch": 288.71,
      "learning_rate": 0.07114067402064517,
      "loss": 0.8709,
      "step": 179000
    },
    {
      "epoch": 288.74,
      "learning_rate": 0.07113744821741935,
      "loss": 0.8665,
      "step": 179020
    },
    {
      "epoch": 288.77,
      "learning_rate": 0.07113422241419357,
      "loss": 0.8774,
      "step": 179040
    },
    {
      "epoch": 288.81,
      "learning_rate": 0.07113099661096774,
      "loss": 0.8561,
      "step": 179060
    },
    {
      "epoch": 288.84,
      "learning_rate": 0.07112777080774195,
      "loss": 0.8659,
      "step": 179080
    },
    {
      "epoch": 288.87,
      "learning_rate": 0.07112454500451613,
      "loss": 0.8407,
      "step": 179100
    },
    {
      "epoch": 288.9,
      "learning_rate": 0.07112131920129032,
      "loss": 0.8695,
      "step": 179120
    },
    {
      "epoch": 288.94,
      "learning_rate": 0.07111809339806452,
      "loss": 0.8821,
      "step": 179140
    },
    {
      "epoch": 288.97,
      "learning_rate": 0.07111486759483872,
      "loss": 0.8885,
      "step": 179160
    },
    {
      "epoch": 289.0,
      "learning_rate": 0.0711118030817742,
      "loss": 0.886,
      "step": 179180
    },
    {
      "epoch": 289.0,
      "eval_accuracy": {
        "accuracy": 0.7438139099211615
      },
      "eval_loss": 1.2374811172485352,
      "eval_runtime": 2.8174,
      "eval_samples_per_second": 4547.078,
      "eval_steps_per_second": 71.342,
      "step": 179180
    },
    {
      "epoch": 289.03,
      "learning_rate": 0.07110857727854838,
      "loss": 0.8644,
      "step": 179200
    },
    {
      "epoch": 289.06,
      "learning_rate": 0.0711053514753226,
      "loss": 0.8624,
      "step": 179220
    },
    {
      "epoch": 289.1,
      "learning_rate": 0.07110212567209678,
      "loss": 0.8465,
      "step": 179240
    },
    {
      "epoch": 289.13,
      "learning_rate": 0.07109889986887097,
      "loss": 0.845,
      "step": 179260
    },
    {
      "epoch": 289.16,
      "learning_rate": 0.07109567406564517,
      "loss": 0.8694,
      "step": 179280
    },
    {
      "epoch": 289.19,
      "learning_rate": 0.07109244826241935,
      "loss": 0.8649,
      "step": 179300
    },
    {
      "epoch": 289.23,
      "learning_rate": 0.07108922245919355,
      "loss": 0.8796,
      "step": 179320
    },
    {
      "epoch": 289.26,
      "learning_rate": 0.07108599665596775,
      "loss": 0.8514,
      "step": 179340
    },
    {
      "epoch": 289.29,
      "learning_rate": 0.07108277085274194,
      "loss": 0.8619,
      "step": 179360
    },
    {
      "epoch": 289.32,
      "learning_rate": 0.07107954504951614,
      "loss": 0.8746,
      "step": 179380
    },
    {
      "epoch": 289.35,
      "learning_rate": 0.07107631924629033,
      "loss": 0.8939,
      "step": 179400
    },
    {
      "epoch": 289.39,
      "learning_rate": 0.07107309344306452,
      "loss": 0.8545,
      "step": 179420
    },
    {
      "epoch": 289.42,
      "learning_rate": 0.07106986763983872,
      "loss": 0.8626,
      "step": 179440
    },
    {
      "epoch": 289.45,
      "learning_rate": 0.0710666418366129,
      "loss": 0.8702,
      "step": 179460
    },
    {
      "epoch": 289.48,
      "learning_rate": 0.0710634160333871,
      "loss": 0.8735,
      "step": 179480
    },
    {
      "epoch": 289.52,
      "learning_rate": 0.07106019023016129,
      "loss": 0.8518,
      "step": 179500
    },
    {
      "epoch": 289.55,
      "learning_rate": 0.0710569644269355,
      "loss": 0.859,
      "step": 179520
    },
    {
      "epoch": 289.58,
      "learning_rate": 0.07105373862370969,
      "loss": 0.8547,
      "step": 179540
    },
    {
      "epoch": 289.61,
      "learning_rate": 0.07105051282048387,
      "loss": 0.8714,
      "step": 179560
    },
    {
      "epoch": 289.65,
      "learning_rate": 0.07104728701725807,
      "loss": 0.8642,
      "step": 179580
    },
    {
      "epoch": 289.68,
      "learning_rate": 0.07104406121403226,
      "loss": 0.8968,
      "step": 179600
    },
    {
      "epoch": 289.71,
      "learning_rate": 0.07104083541080645,
      "loss": 0.8889,
      "step": 179620
    },
    {
      "epoch": 289.74,
      "learning_rate": 0.07103760960758065,
      "loss": 0.9028,
      "step": 179640
    },
    {
      "epoch": 289.77,
      "learning_rate": 0.07103438380435484,
      "loss": 0.8941,
      "step": 179660
    },
    {
      "epoch": 289.81,
      "learning_rate": 0.07103115800112904,
      "loss": 0.9039,
      "step": 179680
    },
    {
      "epoch": 289.84,
      "learning_rate": 0.07102793219790324,
      "loss": 0.8805,
      "step": 179700
    },
    {
      "epoch": 289.87,
      "learning_rate": 0.07102470639467742,
      "loss": 0.8929,
      "step": 179720
    },
    {
      "epoch": 289.9,
      "learning_rate": 0.07102148059145162,
      "loss": 0.8913,
      "step": 179740
    },
    {
      "epoch": 289.94,
      "learning_rate": 0.07101825478822581,
      "loss": 0.906,
      "step": 179760
    },
    {
      "epoch": 289.97,
      "learning_rate": 0.071015028985,
      "loss": 0.8969,
      "step": 179780
    },
    {
      "epoch": 290.0,
      "learning_rate": 0.07101180318177419,
      "loss": 0.8877,
      "step": 179800
    },
    {
      "epoch": 290.0,
      "eval_accuracy": {
        "accuracy": 0.7473265162750761
      },
      "eval_loss": 1.2341781854629517,
      "eval_runtime": 2.7884,
      "eval_samples_per_second": 4594.372,
      "eval_steps_per_second": 72.084,
      "step": 179800
    },
    {
      "epoch": 290.03,
      "learning_rate": 0.0710085773785484,
      "loss": 0.9058,
      "step": 179820
    },
    {
      "epoch": 290.06,
      "learning_rate": 0.07100535157532258,
      "loss": 0.8577,
      "step": 179840
    },
    {
      "epoch": 290.1,
      "learning_rate": 0.07100212577209677,
      "loss": 0.8616,
      "step": 179860
    },
    {
      "epoch": 290.13,
      "learning_rate": 0.07099889996887097,
      "loss": 0.8691,
      "step": 179880
    },
    {
      "epoch": 290.16,
      "learning_rate": 0.07099567416564516,
      "loss": 0.8438,
      "step": 179900
    },
    {
      "epoch": 290.19,
      "learning_rate": 0.07099244836241936,
      "loss": 0.834,
      "step": 179920
    },
    {
      "epoch": 290.23,
      "learning_rate": 0.07098922255919356,
      "loss": 0.8447,
      "step": 179940
    },
    {
      "epoch": 290.26,
      "learning_rate": 0.07098599675596774,
      "loss": 0.85,
      "step": 179960
    },
    {
      "epoch": 290.29,
      "learning_rate": 0.07098277095274194,
      "loss": 0.8299,
      "step": 179980
    },
    {
      "epoch": 290.32,
      "learning_rate": 0.07097954514951614,
      "loss": 0.8576,
      "step": 180000
    },
    {
      "epoch": 290.35,
      "learning_rate": 0.07097631934629033,
      "loss": 0.882,
      "step": 180020
    },
    {
      "epoch": 290.39,
      "learning_rate": 0.07097309354306452,
      "loss": 0.8502,
      "step": 180040
    },
    {
      "epoch": 290.42,
      "learning_rate": 0.07096986773983871,
      "loss": 0.8556,
      "step": 180060
    },
    {
      "epoch": 290.45,
      "learning_rate": 0.07096664193661291,
      "loss": 0.839,
      "step": 180080
    },
    {
      "epoch": 290.48,
      "learning_rate": 0.0709634161333871,
      "loss": 0.8586,
      "step": 180100
    },
    {
      "epoch": 290.52,
      "learning_rate": 0.07096019033016131,
      "loss": 0.8917,
      "step": 180120
    },
    {
      "epoch": 290.55,
      "learning_rate": 0.07095696452693548,
      "loss": 0.8703,
      "step": 180140
    },
    {
      "epoch": 290.58,
      "learning_rate": 0.07095373872370968,
      "loss": 0.862,
      "step": 180160
    },
    {
      "epoch": 290.61,
      "learning_rate": 0.07095051292048388,
      "loss": 0.8724,
      "step": 180180
    },
    {
      "epoch": 290.65,
      "learning_rate": 0.07094728711725806,
      "loss": 0.9193,
      "step": 180200
    },
    {
      "epoch": 290.68,
      "learning_rate": 0.07094406131403226,
      "loss": 0.9005,
      "step": 180220
    },
    {
      "epoch": 290.71,
      "learning_rate": 0.07094083551080646,
      "loss": 0.8956,
      "step": 180240
    },
    {
      "epoch": 290.74,
      "learning_rate": 0.07093760970758065,
      "loss": 0.888,
      "step": 180260
    },
    {
      "epoch": 290.77,
      "learning_rate": 0.07093438390435484,
      "loss": 0.8739,
      "step": 180280
    },
    {
      "epoch": 290.81,
      "learning_rate": 0.07093115810112904,
      "loss": 0.868,
      "step": 180300
    },
    {
      "epoch": 290.84,
      "learning_rate": 0.07092793229790323,
      "loss": 0.8749,
      "step": 180320
    },
    {
      "epoch": 290.87,
      "learning_rate": 0.07092470649467743,
      "loss": 0.8961,
      "step": 180340
    },
    {
      "epoch": 290.9,
      "learning_rate": 0.07092148069145161,
      "loss": 0.8899,
      "step": 180360
    },
    {
      "epoch": 290.94,
      "learning_rate": 0.07091825488822581,
      "loss": 0.9073,
      "step": 180380
    },
    {
      "epoch": 290.97,
      "learning_rate": 0.070915029085,
      "loss": 0.8852,
      "step": 180400
    },
    {
      "epoch": 291.0,
      "learning_rate": 0.07091180328177421,
      "loss": 0.9021,
      "step": 180420
    },
    {
      "epoch": 291.0,
      "eval_accuracy": {
        "accuracy": 0.755834829443447
      },
      "eval_loss": 1.2296147346496582,
      "eval_runtime": 3.6817,
      "eval_samples_per_second": 3479.645,
      "eval_steps_per_second": 54.594,
      "step": 180420
    },
    {
      "epoch": 291.03,
      "learning_rate": 0.07090857747854838,
      "loss": 0.9215,
      "step": 180440
    },
    {
      "epoch": 291.06,
      "learning_rate": 0.0709053516753226,
      "loss": 0.856,
      "step": 180460
    },
    {
      "epoch": 291.1,
      "learning_rate": 0.07090212587209678,
      "loss": 0.8708,
      "step": 180480
    },
    {
      "epoch": 291.13,
      "learning_rate": 0.07089890006887097,
      "loss": 0.8545,
      "step": 180500
    },
    {
      "epoch": 291.16,
      "learning_rate": 0.07089567426564516,
      "loss": 0.8653,
      "step": 180520
    },
    {
      "epoch": 291.19,
      "learning_rate": 0.07089244846241936,
      "loss": 0.8844,
      "step": 180540
    },
    {
      "epoch": 291.23,
      "learning_rate": 0.07088922265919355,
      "loss": 0.8585,
      "step": 180560
    },
    {
      "epoch": 291.26,
      "learning_rate": 0.07088599685596775,
      "loss": 0.8468,
      "step": 180580
    },
    {
      "epoch": 291.29,
      "learning_rate": 0.07088277105274195,
      "loss": 0.8601,
      "step": 180600
    },
    {
      "epoch": 291.32,
      "learning_rate": 0.07087954524951613,
      "loss": 0.8524,
      "step": 180620
    },
    {
      "epoch": 291.35,
      "learning_rate": 0.07087631944629033,
      "loss": 0.8599,
      "step": 180640
    },
    {
      "epoch": 291.39,
      "learning_rate": 0.07087309364306452,
      "loss": 0.8564,
      "step": 180660
    },
    {
      "epoch": 291.42,
      "learning_rate": 0.07086986783983872,
      "loss": 0.8815,
      "step": 180680
    },
    {
      "epoch": 291.45,
      "learning_rate": 0.0708666420366129,
      "loss": 0.8689,
      "step": 180700
    },
    {
      "epoch": 291.48,
      "learning_rate": 0.07086341623338711,
      "loss": 0.8708,
      "step": 180720
    },
    {
      "epoch": 291.52,
      "learning_rate": 0.07086019043016129,
      "loss": 0.8821,
      "step": 180740
    },
    {
      "epoch": 291.55,
      "learning_rate": 0.0708569646269355,
      "loss": 0.8583,
      "step": 180760
    },
    {
      "epoch": 291.58,
      "learning_rate": 0.07085373882370968,
      "loss": 0.8674,
      "step": 180780
    },
    {
      "epoch": 291.61,
      "learning_rate": 0.07085051302048387,
      "loss": 0.8574,
      "step": 180800
    },
    {
      "epoch": 291.65,
      "learning_rate": 0.07084728721725807,
      "loss": 0.8468,
      "step": 180820
    },
    {
      "epoch": 291.68,
      "learning_rate": 0.07084406141403227,
      "loss": 0.8733,
      "step": 180840
    },
    {
      "epoch": 291.71,
      "learning_rate": 0.07084083561080645,
      "loss": 0.885,
      "step": 180860
    },
    {
      "epoch": 291.74,
      "learning_rate": 0.07083760980758065,
      "loss": 0.8761,
      "step": 180880
    },
    {
      "epoch": 291.77,
      "learning_rate": 0.07083438400435485,
      "loss": 0.8896,
      "step": 180900
    },
    {
      "epoch": 291.81,
      "learning_rate": 0.07083115820112904,
      "loss": 0.9057,
      "step": 180920
    },
    {
      "epoch": 291.84,
      "learning_rate": 0.07082793239790323,
      "loss": 0.884,
      "step": 180940
    },
    {
      "epoch": 291.87,
      "learning_rate": 0.07082470659467742,
      "loss": 0.8802,
      "step": 180960
    },
    {
      "epoch": 291.9,
      "learning_rate": 0.07082148079145162,
      "loss": 0.8851,
      "step": 180980
    },
    {
      "epoch": 291.94,
      "learning_rate": 0.0708182549882258,
      "loss": 0.8789,
      "step": 181000
    },
    {
      "epoch": 291.97,
      "learning_rate": 0.07081502918500002,
      "loss": 0.8848,
      "step": 181020
    },
    {
      "epoch": 292.0,
      "learning_rate": 0.07081180338177419,
      "loss": 0.8863,
      "step": 181040
    },
    {
      "epoch": 292.0,
      "eval_accuracy": {
        "accuracy": 0.7385059714308017
      },
      "eval_loss": 1.2807551622390747,
      "eval_runtime": 3.0082,
      "eval_samples_per_second": 4258.648,
      "eval_steps_per_second": 66.817,
      "step": 181040
    },
    {
      "epoch": 292.03,
      "learning_rate": 0.0708085775785484,
      "loss": 0.9167,
      "step": 181060
    },
    {
      "epoch": 292.06,
      "learning_rate": 0.07080535177532259,
      "loss": 0.8887,
      "step": 181080
    },
    {
      "epoch": 292.1,
      "learning_rate": 0.07080212597209677,
      "loss": 0.8625,
      "step": 181100
    },
    {
      "epoch": 292.13,
      "learning_rate": 0.07079890016887097,
      "loss": 0.864,
      "step": 181120
    },
    {
      "epoch": 292.16,
      "learning_rate": 0.07079567436564517,
      "loss": 0.882,
      "step": 181140
    },
    {
      "epoch": 292.19,
      "learning_rate": 0.07079244856241936,
      "loss": 0.8859,
      "step": 181160
    },
    {
      "epoch": 292.23,
      "learning_rate": 0.07078922275919355,
      "loss": 0.893,
      "step": 181180
    },
    {
      "epoch": 292.26,
      "learning_rate": 0.07078599695596775,
      "loss": 0.8544,
      "step": 181200
    },
    {
      "epoch": 292.29,
      "learning_rate": 0.07078277115274194,
      "loss": 0.8651,
      "step": 181220
    },
    {
      "epoch": 292.32,
      "learning_rate": 0.07077954534951614,
      "loss": 0.8512,
      "step": 181240
    },
    {
      "epoch": 292.35,
      "learning_rate": 0.07077631954629032,
      "loss": 0.8599,
      "step": 181260
    },
    {
      "epoch": 292.39,
      "learning_rate": 0.07077309374306452,
      "loss": 0.8559,
      "step": 181280
    },
    {
      "epoch": 292.42,
      "learning_rate": 0.07076986793983871,
      "loss": 0.8248,
      "step": 181300
    },
    {
      "epoch": 292.45,
      "learning_rate": 0.07076664213661292,
      "loss": 0.8542,
      "step": 181320
    },
    {
      "epoch": 292.48,
      "learning_rate": 0.07076341633338709,
      "loss": 0.8576,
      "step": 181340
    },
    {
      "epoch": 292.52,
      "learning_rate": 0.0707601905301613,
      "loss": 0.8691,
      "step": 181360
    },
    {
      "epoch": 292.55,
      "learning_rate": 0.07075696472693549,
      "loss": 0.8558,
      "step": 181380
    },
    {
      "epoch": 292.58,
      "learning_rate": 0.07075373892370969,
      "loss": 0.8605,
      "step": 181400
    },
    {
      "epoch": 292.61,
      "learning_rate": 0.07075051312048387,
      "loss": 0.895,
      "step": 181420
    },
    {
      "epoch": 292.65,
      "learning_rate": 0.07074728731725807,
      "loss": 0.9055,
      "step": 181440
    },
    {
      "epoch": 292.68,
      "learning_rate": 0.07074406151403226,
      "loss": 0.8861,
      "step": 181460
    },
    {
      "epoch": 292.71,
      "learning_rate": 0.07074083571080646,
      "loss": 0.9061,
      "step": 181480
    },
    {
      "epoch": 292.74,
      "learning_rate": 0.07073760990758066,
      "loss": 0.8748,
      "step": 181500
    },
    {
      "epoch": 292.77,
      "learning_rate": 0.07073438410435484,
      "loss": 0.887,
      "step": 181520
    },
    {
      "epoch": 292.81,
      "learning_rate": 0.07073115830112904,
      "loss": 0.9067,
      "step": 181540
    },
    {
      "epoch": 292.84,
      "learning_rate": 0.07072793249790323,
      "loss": 0.8793,
      "step": 181560
    },
    {
      "epoch": 292.87,
      "learning_rate": 0.07072470669467742,
      "loss": 0.9025,
      "step": 181580
    },
    {
      "epoch": 292.9,
      "learning_rate": 0.07072148089145161,
      "loss": 0.8824,
      "step": 181600
    },
    {
      "epoch": 292.94,
      "learning_rate": 0.07071825508822581,
      "loss": 0.8731,
      "step": 181620
    },
    {
      "epoch": 292.97,
      "learning_rate": 0.070715029285,
      "loss": 0.8906,
      "step": 181640
    },
    {
      "epoch": 293.0,
      "learning_rate": 0.07071196477193549,
      "loss": 0.8574,
      "step": 181660
    },
    {
      "epoch": 293.0,
      "eval_accuracy": {
        "accuracy": 0.7523222230895324
      },
      "eval_loss": 1.2262814044952393,
      "eval_runtime": 2.6587,
      "eval_samples_per_second": 4818.459,
      "eval_steps_per_second": 75.6,
      "step": 181660
    },
    {
      "epoch": 293.03,
      "learning_rate": 0.07070873896870969,
      "loss": 0.8404,
      "step": 181680
    },
    {
      "epoch": 293.06,
      "learning_rate": 0.07070551316548387,
      "loss": 0.8191,
      "step": 181700
    },
    {
      "epoch": 293.1,
      "learning_rate": 0.07070228736225807,
      "loss": 0.8536,
      "step": 181720
    },
    {
      "epoch": 293.13,
      "learning_rate": 0.07069906155903226,
      "loss": 0.8793,
      "step": 181740
    },
    {
      "epoch": 293.16,
      "learning_rate": 0.07069583575580646,
      "loss": 0.8541,
      "step": 181760
    },
    {
      "epoch": 293.19,
      "learning_rate": 0.07069260995258064,
      "loss": 0.8597,
      "step": 181780
    },
    {
      "epoch": 293.23,
      "learning_rate": 0.07068938414935486,
      "loss": 0.8583,
      "step": 181800
    },
    {
      "epoch": 293.26,
      "learning_rate": 0.07068615834612903,
      "loss": 0.8789,
      "step": 181820
    },
    {
      "epoch": 293.29,
      "learning_rate": 0.07068293254290324,
      "loss": 0.8769,
      "step": 181840
    },
    {
      "epoch": 293.32,
      "learning_rate": 0.07067970673967743,
      "loss": 0.8701,
      "step": 181860
    },
    {
      "epoch": 293.35,
      "learning_rate": 0.07067648093645161,
      "loss": 0.8717,
      "step": 181880
    },
    {
      "epoch": 293.39,
      "learning_rate": 0.07067325513322581,
      "loss": 0.8339,
      "step": 181900
    },
    {
      "epoch": 293.42,
      "learning_rate": 0.07067002933000001,
      "loss": 0.8379,
      "step": 181920
    },
    {
      "epoch": 293.45,
      "learning_rate": 0.0706668035267742,
      "loss": 0.8752,
      "step": 181940
    },
    {
      "epoch": 293.48,
      "learning_rate": 0.0706635777235484,
      "loss": 0.8543,
      "step": 181960
    },
    {
      "epoch": 293.52,
      "learning_rate": 0.07066035192032259,
      "loss": 0.8792,
      "step": 181980
    },
    {
      "epoch": 293.55,
      "learning_rate": 0.07065712611709678,
      "loss": 0.8561,
      "step": 182000
    },
    {
      "epoch": 293.58,
      "learning_rate": 0.07065390031387098,
      "loss": 0.8673,
      "step": 182020
    },
    {
      "epoch": 293.61,
      "learning_rate": 0.07065067451064516,
      "loss": 0.8525,
      "step": 182040
    },
    {
      "epoch": 293.65,
      "learning_rate": 0.07064744870741936,
      "loss": 0.8704,
      "step": 182060
    },
    {
      "epoch": 293.68,
      "learning_rate": 0.07064422290419355,
      "loss": 0.9016,
      "step": 182080
    },
    {
      "epoch": 293.71,
      "learning_rate": 0.07064099710096776,
      "loss": 0.9008,
      "step": 182100
    },
    {
      "epoch": 293.74,
      "learning_rate": 0.07063777129774193,
      "loss": 0.8843,
      "step": 182120
    },
    {
      "epoch": 293.77,
      "learning_rate": 0.07063454549451614,
      "loss": 0.8601,
      "step": 182140
    },
    {
      "epoch": 293.81,
      "learning_rate": 0.07063131969129033,
      "loss": 0.8917,
      "step": 182160
    },
    {
      "epoch": 293.84,
      "learning_rate": 0.07062809388806451,
      "loss": 0.857,
      "step": 182180
    },
    {
      "epoch": 293.87,
      "learning_rate": 0.07062486808483871,
      "loss": 0.8747,
      "step": 182200
    },
    {
      "epoch": 293.9,
      "learning_rate": 0.07062164228161291,
      "loss": 0.8954,
      "step": 182220
    },
    {
      "epoch": 293.94,
      "learning_rate": 0.0706184164783871,
      "loss": 0.8912,
      "step": 182240
    },
    {
      "epoch": 293.97,
      "learning_rate": 0.0706151906751613,
      "loss": 0.9112,
      "step": 182260
    },
    {
      "epoch": 294.0,
      "learning_rate": 0.0706119648719355,
      "loss": 0.8752,
      "step": 182280
    },
    {
      "epoch": 294.0,
      "eval_accuracy": {
        "accuracy": 0.7380376239169464
      },
      "eval_loss": 1.300214409828186,
      "eval_runtime": 2.7928,
      "eval_samples_per_second": 4587.219,
      "eval_steps_per_second": 71.972,
      "step": 182280
    },
    {
      "epoch": 294.03,
      "learning_rate": 0.07060873906870968,
      "loss": 0.8817,
      "step": 182300
    },
    {
      "epoch": 294.06,
      "learning_rate": 0.07060551326548388,
      "loss": 0.8368,
      "step": 182320
    },
    {
      "epoch": 294.1,
      "learning_rate": 0.07060228746225806,
      "loss": 0.8362,
      "step": 182340
    },
    {
      "epoch": 294.13,
      "learning_rate": 0.07059906165903226,
      "loss": 0.8381,
      "step": 182360
    },
    {
      "epoch": 294.16,
      "learning_rate": 0.07059583585580645,
      "loss": 0.8504,
      "step": 182380
    },
    {
      "epoch": 294.19,
      "learning_rate": 0.07059261005258066,
      "loss": 0.8558,
      "step": 182400
    },
    {
      "epoch": 294.23,
      "learning_rate": 0.07058938424935483,
      "loss": 0.9029,
      "step": 182420
    },
    {
      "epoch": 294.26,
      "learning_rate": 0.07058615844612905,
      "loss": 0.907,
      "step": 182440
    },
    {
      "epoch": 294.29,
      "learning_rate": 0.07058293264290323,
      "loss": 0.8794,
      "step": 182460
    },
    {
      "epoch": 294.32,
      "learning_rate": 0.07057970683967742,
      "loss": 0.8538,
      "step": 182480
    },
    {
      "epoch": 294.35,
      "learning_rate": 0.07057648103645162,
      "loss": 0.8688,
      "step": 182500
    },
    {
      "epoch": 294.39,
      "learning_rate": 0.07057325523322582,
      "loss": 0.8412,
      "step": 182520
    },
    {
      "epoch": 294.42,
      "learning_rate": 0.07057002943,
      "loss": 0.8521,
      "step": 182540
    },
    {
      "epoch": 294.45,
      "learning_rate": 0.0705668036267742,
      "loss": 0.8627,
      "step": 182560
    },
    {
      "epoch": 294.48,
      "learning_rate": 0.0705635778235484,
      "loss": 0.8864,
      "step": 182580
    },
    {
      "epoch": 294.52,
      "learning_rate": 0.07056035202032258,
      "loss": 0.8751,
      "step": 182600
    },
    {
      "epoch": 294.55,
      "learning_rate": 0.07055712621709678,
      "loss": 0.8826,
      "step": 182620
    },
    {
      "epoch": 294.58,
      "learning_rate": 0.07055390041387097,
      "loss": 0.8691,
      "step": 182640
    },
    {
      "epoch": 294.61,
      "learning_rate": 0.07055067461064517,
      "loss": 0.869,
      "step": 182660
    },
    {
      "epoch": 294.65,
      "learning_rate": 0.07054744880741935,
      "loss": 0.8638,
      "step": 182680
    },
    {
      "epoch": 294.68,
      "learning_rate": 0.07054422300419355,
      "loss": 0.8638,
      "step": 182700
    },
    {
      "epoch": 294.71,
      "learning_rate": 0.07054099720096774,
      "loss": 0.8551,
      "step": 182720
    },
    {
      "epoch": 294.74,
      "learning_rate": 0.07053777139774195,
      "loss": 0.8655,
      "step": 182740
    },
    {
      "epoch": 294.77,
      "learning_rate": 0.07053454559451613,
      "loss": 0.8701,
      "step": 182760
    },
    {
      "epoch": 294.81,
      "learning_rate": 0.07053131979129033,
      "loss": 0.8727,
      "step": 182780
    },
    {
      "epoch": 294.84,
      "learning_rate": 0.07052809398806452,
      "loss": 0.8666,
      "step": 182800
    },
    {
      "epoch": 294.87,
      "learning_rate": 0.07052486818483872,
      "loss": 0.8707,
      "step": 182820
    },
    {
      "epoch": 294.9,
      "learning_rate": 0.0705216423816129,
      "loss": 0.8583,
      "step": 182840
    },
    {
      "epoch": 294.94,
      "learning_rate": 0.0705184165783871,
      "loss": 0.8759,
      "step": 182860
    },
    {
      "epoch": 294.97,
      "learning_rate": 0.0705151907751613,
      "loss": 0.8861,
      "step": 182880
    },
    {
      "epoch": 295.0,
      "learning_rate": 0.07051196497193549,
      "loss": 0.8753,
      "step": 182900
    },
    {
      "epoch": 295.0,
      "eval_accuracy": {
        "accuracy": 0.7450628366247756
      },
      "eval_loss": 1.2603209018707275,
      "eval_runtime": 2.6713,
      "eval_samples_per_second": 4795.878,
      "eval_steps_per_second": 75.246,
      "step": 182900
    },
    {
      "epoch": 295.03,
      "learning_rate": 0.07050873916870969,
      "loss": 0.8815,
      "step": 182920
    },
    {
      "epoch": 295.06,
      "learning_rate": 0.07050551336548389,
      "loss": 0.8488,
      "step": 182940
    },
    {
      "epoch": 295.1,
      "learning_rate": 0.07050228756225807,
      "loss": 0.85,
      "step": 182960
    },
    {
      "epoch": 295.13,
      "learning_rate": 0.07049906175903226,
      "loss": 0.8617,
      "step": 182980
    },
    {
      "epoch": 295.16,
      "learning_rate": 0.07049583595580645,
      "loss": 0.861,
      "step": 183000
    },
    {
      "epoch": 295.19,
      "learning_rate": 0.07049261015258064,
      "loss": 0.8423,
      "step": 183020
    },
    {
      "epoch": 295.23,
      "learning_rate": 0.07048938434935485,
      "loss": 0.8699,
      "step": 183040
    },
    {
      "epoch": 295.26,
      "learning_rate": 0.07048615854612904,
      "loss": 0.8562,
      "step": 183060
    },
    {
      "epoch": 295.29,
      "learning_rate": 0.07048293274290324,
      "loss": 0.8507,
      "step": 183080
    },
    {
      "epoch": 295.32,
      "learning_rate": 0.07047970693967742,
      "loss": 0.8519,
      "step": 183100
    },
    {
      "epoch": 295.35,
      "learning_rate": 0.07047648113645162,
      "loss": 0.8778,
      "step": 183120
    },
    {
      "epoch": 295.39,
      "learning_rate": 0.0704732553332258,
      "loss": 0.845,
      "step": 183140
    },
    {
      "epoch": 295.42,
      "learning_rate": 0.07047002953,
      "loss": 0.8723,
      "step": 183160
    },
    {
      "epoch": 295.45,
      "learning_rate": 0.0704668037267742,
      "loss": 0.8734,
      "step": 183180
    },
    {
      "epoch": 295.48,
      "learning_rate": 0.07046357792354839,
      "loss": 0.8732,
      "step": 183200
    },
    {
      "epoch": 295.52,
      "learning_rate": 0.07046035212032259,
      "loss": 0.8644,
      "step": 183220
    },
    {
      "epoch": 295.55,
      "learning_rate": 0.07045712631709677,
      "loss": 0.8891,
      "step": 183240
    },
    {
      "epoch": 295.58,
      "learning_rate": 0.07045390051387097,
      "loss": 0.8895,
      "step": 183260
    },
    {
      "epoch": 295.61,
      "learning_rate": 0.07045067471064516,
      "loss": 0.9121,
      "step": 183280
    },
    {
      "epoch": 295.65,
      "learning_rate": 0.07044744890741936,
      "loss": 0.8834,
      "step": 183300
    },
    {
      "epoch": 295.68,
      "learning_rate": 0.07044422310419354,
      "loss": 0.8783,
      "step": 183320
    },
    {
      "epoch": 295.71,
      "learning_rate": 0.07044099730096776,
      "loss": 0.8915,
      "step": 183340
    },
    {
      "epoch": 295.74,
      "learning_rate": 0.07043777149774194,
      "loss": 0.8871,
      "step": 183360
    },
    {
      "epoch": 295.77,
      "learning_rate": 0.07043454569451614,
      "loss": 0.8529,
      "step": 183380
    },
    {
      "epoch": 295.81,
      "learning_rate": 0.07043131989129033,
      "loss": 0.8684,
      "step": 183400
    },
    {
      "epoch": 295.84,
      "learning_rate": 0.07042809408806452,
      "loss": 0.8526,
      "step": 183420
    },
    {
      "epoch": 295.87,
      "learning_rate": 0.07042486828483871,
      "loss": 0.8696,
      "step": 183440
    },
    {
      "epoch": 295.9,
      "learning_rate": 0.07042164248161291,
      "loss": 0.8791,
      "step": 183460
    },
    {
      "epoch": 295.94,
      "learning_rate": 0.07041841667838711,
      "loss": 0.8811,
      "step": 183480
    },
    {
      "epoch": 295.97,
      "learning_rate": 0.0704151908751613,
      "loss": 0.8714,
      "step": 183500
    },
    {
      "epoch": 296.0,
      "learning_rate": 0.07041196507193549,
      "loss": 0.9,
      "step": 183520
    },
    {
      "epoch": 296.0,
      "eval_accuracy": {
        "accuracy": 0.7413160565139333
      },
      "eval_loss": 1.2630292177200317,
      "eval_runtime": 2.8017,
      "eval_samples_per_second": 4572.659,
      "eval_steps_per_second": 71.743,
      "step": 183520
    },
    {
      "epoch": 296.03,
      "learning_rate": 0.07040873926870968,
      "loss": 0.913,
      "step": 183540
    },
    {
      "epoch": 296.06,
      "learning_rate": 0.07040551346548388,
      "loss": 0.8669,
      "step": 183560
    },
    {
      "epoch": 296.1,
      "learning_rate": 0.07040228766225806,
      "loss": 0.8579,
      "step": 183580
    },
    {
      "epoch": 296.13,
      "learning_rate": 0.07039906185903226,
      "loss": 0.8405,
      "step": 183600
    },
    {
      "epoch": 296.16,
      "learning_rate": 0.07039583605580645,
      "loss": 0.8581,
      "step": 183620
    },
    {
      "epoch": 296.19,
      "learning_rate": 0.07039261025258066,
      "loss": 0.8582,
      "step": 183640
    },
    {
      "epoch": 296.23,
      "learning_rate": 0.07038938444935484,
      "loss": 0.8528,
      "step": 183660
    },
    {
      "epoch": 296.26,
      "learning_rate": 0.07038615864612904,
      "loss": 0.8664,
      "step": 183680
    },
    {
      "epoch": 296.29,
      "learning_rate": 0.07038293284290323,
      "loss": 0.9038,
      "step": 183700
    },
    {
      "epoch": 296.32,
      "learning_rate": 0.07037970703967743,
      "loss": 0.8678,
      "step": 183720
    },
    {
      "epoch": 296.35,
      "learning_rate": 0.07037648123645161,
      "loss": 0.8564,
      "step": 183740
    },
    {
      "epoch": 296.39,
      "learning_rate": 0.07037325543322581,
      "loss": 0.8878,
      "step": 183760
    },
    {
      "epoch": 296.42,
      "learning_rate": 0.07037002963,
      "loss": 0.87,
      "step": 183780
    },
    {
      "epoch": 296.45,
      "learning_rate": 0.0703668038267742,
      "loss": 0.8813,
      "step": 183800
    },
    {
      "epoch": 296.48,
      "learning_rate": 0.0703635780235484,
      "loss": 0.8886,
      "step": 183820
    },
    {
      "epoch": 296.52,
      "learning_rate": 0.07036035222032258,
      "loss": 0.8664,
      "step": 183840
    },
    {
      "epoch": 296.55,
      "learning_rate": 0.07035712641709678,
      "loss": 0.8671,
      "step": 183860
    },
    {
      "epoch": 296.58,
      "learning_rate": 0.07035390061387096,
      "loss": 0.8679,
      "step": 183880
    },
    {
      "epoch": 296.61,
      "learning_rate": 0.07035067481064516,
      "loss": 0.8777,
      "step": 183900
    },
    {
      "epoch": 296.65,
      "learning_rate": 0.07034744900741935,
      "loss": 0.8543,
      "step": 183920
    },
    {
      "epoch": 296.68,
      "learning_rate": 0.07034422320419356,
      "loss": 0.88,
      "step": 183940
    },
    {
      "epoch": 296.71,
      "learning_rate": 0.07034099740096775,
      "loss": 0.8537,
      "step": 183960
    },
    {
      "epoch": 296.74,
      "learning_rate": 0.07033777159774195,
      "loss": 0.8547,
      "step": 183980
    },
    {
      "epoch": 296.77,
      "learning_rate": 0.07033454579451613,
      "loss": 0.8837,
      "step": 184000
    },
    {
      "epoch": 296.81,
      "learning_rate": 0.07033131999129033,
      "loss": 0.8875,
      "step": 184020
    },
    {
      "epoch": 296.84,
      "learning_rate": 0.07032809418806452,
      "loss": 0.87,
      "step": 184040
    },
    {
      "epoch": 296.87,
      "learning_rate": 0.07032486838483872,
      "loss": 0.8727,
      "step": 184060
    },
    {
      "epoch": 296.9,
      "learning_rate": 0.0703216425816129,
      "loss": 0.8606,
      "step": 184080
    },
    {
      "epoch": 296.94,
      "learning_rate": 0.0703184167783871,
      "loss": 0.867,
      "step": 184100
    },
    {
      "epoch": 296.97,
      "learning_rate": 0.0703151909751613,
      "loss": 0.9045,
      "step": 184120
    },
    {
      "epoch": 297.0,
      "learning_rate": 0.07031212646209678,
      "loss": 0.8597,
      "step": 184140
    },
    {
      "epoch": 297.0,
      "eval_accuracy": {
        "accuracy": 0.7490437904925454
      },
      "eval_loss": 1.2287496328353882,
      "eval_runtime": 2.7586,
      "eval_samples_per_second": 4644.059,
      "eval_steps_per_second": 72.864,
      "step": 184140
    },
    {
      "epoch": 297.03,
      "learning_rate": 0.07030890065887098,
      "loss": 0.8569,
      "step": 184160
    },
    {
      "epoch": 297.06,
      "learning_rate": 0.07030567485564516,
      "loss": 0.85,
      "step": 184180
    },
    {
      "epoch": 297.1,
      "learning_rate": 0.07030244905241936,
      "loss": 0.8584,
      "step": 184200
    },
    {
      "epoch": 297.13,
      "learning_rate": 0.07029922324919355,
      "loss": 0.8566,
      "step": 184220
    },
    {
      "epoch": 297.16,
      "learning_rate": 0.07029599744596775,
      "loss": 0.8659,
      "step": 184240
    },
    {
      "epoch": 297.19,
      "learning_rate": 0.07029277164274195,
      "loss": 0.8612,
      "step": 184260
    },
    {
      "epoch": 297.23,
      "learning_rate": 0.07028954583951613,
      "loss": 0.8501,
      "step": 184280
    },
    {
      "epoch": 297.26,
      "learning_rate": 0.07028632003629033,
      "loss": 0.8332,
      "step": 184300
    },
    {
      "epoch": 297.29,
      "learning_rate": 0.07028309423306452,
      "loss": 0.8642,
      "step": 184320
    },
    {
      "epoch": 297.32,
      "learning_rate": 0.07027986842983872,
      "loss": 0.8871,
      "step": 184340
    },
    {
      "epoch": 297.35,
      "learning_rate": 0.0702766426266129,
      "loss": 0.8523,
      "step": 184360
    },
    {
      "epoch": 297.39,
      "learning_rate": 0.0702734168233871,
      "loss": 0.824,
      "step": 184380
    },
    {
      "epoch": 297.42,
      "learning_rate": 0.07027019102016129,
      "loss": 0.8472,
      "step": 184400
    },
    {
      "epoch": 297.45,
      "learning_rate": 0.0702669652169355,
      "loss": 0.8552,
      "step": 184420
    },
    {
      "epoch": 297.48,
      "learning_rate": 0.07026373941370968,
      "loss": 0.86,
      "step": 184440
    },
    {
      "epoch": 297.52,
      "learning_rate": 0.07026051361048388,
      "loss": 0.8975,
      "step": 184460
    },
    {
      "epoch": 297.55,
      "learning_rate": 0.07025728780725807,
      "loss": 0.8687,
      "step": 184480
    },
    {
      "epoch": 297.58,
      "learning_rate": 0.07025406200403227,
      "loss": 0.859,
      "step": 184500
    },
    {
      "epoch": 297.61,
      "learning_rate": 0.07025083620080645,
      "loss": 0.8583,
      "step": 184520
    },
    {
      "epoch": 297.65,
      "learning_rate": 0.07024761039758065,
      "loss": 0.8925,
      "step": 184540
    },
    {
      "epoch": 297.68,
      "learning_rate": 0.07024438459435485,
      "loss": 0.8951,
      "step": 184560
    },
    {
      "epoch": 297.71,
      "learning_rate": 0.07024115879112904,
      "loss": 0.9079,
      "step": 184580
    },
    {
      "epoch": 297.74,
      "learning_rate": 0.07023793298790323,
      "loss": 0.8586,
      "step": 184600
    },
    {
      "epoch": 297.77,
      "learning_rate": 0.07023470718467742,
      "loss": 0.8843,
      "step": 184620
    },
    {
      "epoch": 297.81,
      "learning_rate": 0.07023148138145162,
      "loss": 0.9016,
      "step": 184640
    },
    {
      "epoch": 297.84,
      "learning_rate": 0.0702282555782258,
      "loss": 0.8704,
      "step": 184660
    },
    {
      "epoch": 297.87,
      "learning_rate": 0.070225029775,
      "loss": 0.8813,
      "step": 184680
    },
    {
      "epoch": 297.9,
      "learning_rate": 0.07022180397177419,
      "loss": 0.8902,
      "step": 184700
    },
    {
      "epoch": 297.94,
      "learning_rate": 0.0702185781685484,
      "loss": 0.8921,
      "step": 184720
    },
    {
      "epoch": 297.97,
      "learning_rate": 0.07021535236532259,
      "loss": 0.9287,
      "step": 184740
    },
    {
      "epoch": 298.0,
      "learning_rate": 0.07021212656209679,
      "loss": 0.8723,
      "step": 184760
    },
    {
      "epoch": 298.0,
      "eval_accuracy": {
        "accuracy": 0.7378034501600187
      },
      "eval_loss": 1.2848576307296753,
      "eval_runtime": 2.7257,
      "eval_samples_per_second": 4700.003,
      "eval_steps_per_second": 73.741,
      "step": 184760
    },
    {
      "epoch": 298.03,
      "learning_rate": 0.07020890075887097,
      "loss": 0.8954,
      "step": 184780
    },
    {
      "epoch": 298.06,
      "learning_rate": 0.07020567495564517,
      "loss": 0.8624,
      "step": 184800
    },
    {
      "epoch": 298.1,
      "learning_rate": 0.07020244915241936,
      "loss": 0.8461,
      "step": 184820
    },
    {
      "epoch": 298.13,
      "learning_rate": 0.07019922334919355,
      "loss": 0.8493,
      "step": 184840
    },
    {
      "epoch": 298.16,
      "learning_rate": 0.07019599754596774,
      "loss": 0.8417,
      "step": 184860
    },
    {
      "epoch": 298.19,
      "learning_rate": 0.07019277174274194,
      "loss": 0.8105,
      "step": 184880
    },
    {
      "epoch": 298.23,
      "learning_rate": 0.07018954593951614,
      "loss": 0.8556,
      "step": 184900
    },
    {
      "epoch": 298.26,
      "learning_rate": 0.07018632013629032,
      "loss": 0.8679,
      "step": 184920
    },
    {
      "epoch": 298.29,
      "learning_rate": 0.07018309433306452,
      "loss": 0.8794,
      "step": 184940
    },
    {
      "epoch": 298.32,
      "learning_rate": 0.07017986852983871,
      "loss": 0.8577,
      "step": 184960
    },
    {
      "epoch": 298.35,
      "learning_rate": 0.0701766427266129,
      "loss": 0.858,
      "step": 184980
    },
    {
      "epoch": 298.39,
      "learning_rate": 0.07017341692338709,
      "loss": 0.8968,
      "step": 185000
    },
    {
      "epoch": 298.42,
      "learning_rate": 0.0701701911201613,
      "loss": 0.8693,
      "step": 185020
    },
    {
      "epoch": 298.45,
      "learning_rate": 0.07016696531693549,
      "loss": 0.8813,
      "step": 185040
    },
    {
      "epoch": 298.48,
      "learning_rate": 0.07016373951370969,
      "loss": 0.8403,
      "step": 185060
    },
    {
      "epoch": 298.52,
      "learning_rate": 0.07016051371048387,
      "loss": 0.8449,
      "step": 185080
    },
    {
      "epoch": 298.55,
      "learning_rate": 0.07015728790725807,
      "loss": 0.855,
      "step": 185100
    },
    {
      "epoch": 298.58,
      "learning_rate": 0.07015406210403226,
      "loss": 0.8486,
      "step": 185120
    },
    {
      "epoch": 298.61,
      "learning_rate": 0.07015083630080646,
      "loss": 0.8665,
      "step": 185140
    },
    {
      "epoch": 298.65,
      "learning_rate": 0.07014761049758064,
      "loss": 0.865,
      "step": 185160
    },
    {
      "epoch": 298.68,
      "learning_rate": 0.07014438469435484,
      "loss": 0.8725,
      "step": 185180
    },
    {
      "epoch": 298.71,
      "learning_rate": 0.07014115889112904,
      "loss": 0.88,
      "step": 185200
    },
    {
      "epoch": 298.74,
      "learning_rate": 0.07013793308790323,
      "loss": 0.857,
      "step": 185220
    },
    {
      "epoch": 298.77,
      "learning_rate": 0.07013470728467742,
      "loss": 0.8833,
      "step": 185240
    },
    {
      "epoch": 298.81,
      "learning_rate": 0.07013148148145162,
      "loss": 0.8786,
      "step": 185260
    },
    {
      "epoch": 298.84,
      "learning_rate": 0.07012825567822581,
      "loss": 0.8692,
      "step": 185280
    },
    {
      "epoch": 298.87,
      "learning_rate": 0.070125029875,
      "loss": 0.8814,
      "step": 185300
    },
    {
      "epoch": 298.9,
      "learning_rate": 0.07012180407177421,
      "loss": 0.8832,
      "step": 185320
    },
    {
      "epoch": 298.94,
      "learning_rate": 0.07011857826854839,
      "loss": 0.853,
      "step": 185340
    },
    {
      "epoch": 298.97,
      "learning_rate": 0.07011535246532259,
      "loss": 0.8731,
      "step": 185360
    },
    {
      "epoch": 299.0,
      "learning_rate": 0.07011212666209678,
      "loss": 0.8347,
      "step": 185380
    },
    {
      "epoch": 299.0,
      "eval_accuracy": {
        "accuracy": 0.7479509796268832
      },
      "eval_loss": 1.2320746183395386,
      "eval_runtime": 2.8653,
      "eval_samples_per_second": 4471.019,
      "eval_steps_per_second": 70.149,
      "step": 185380
    },
    {
      "epoch": 299.03,
      "learning_rate": 0.07010890085887098,
      "loss": 0.9103,
      "step": 185400
    },
    {
      "epoch": 299.06,
      "learning_rate": 0.07010567505564516,
      "loss": 0.8586,
      "step": 185420
    },
    {
      "epoch": 299.1,
      "learning_rate": 0.07010244925241936,
      "loss": 0.8469,
      "step": 185440
    },
    {
      "epoch": 299.13,
      "learning_rate": 0.07009922344919355,
      "loss": 0.861,
      "step": 185460
    },
    {
      "epoch": 299.16,
      "learning_rate": 0.07009599764596774,
      "loss": 0.8614,
      "step": 185480
    },
    {
      "epoch": 299.19,
      "learning_rate": 0.07009277184274194,
      "loss": 0.8554,
      "step": 185500
    },
    {
      "epoch": 299.23,
      "learning_rate": 0.07008954603951613,
      "loss": 0.8551,
      "step": 185520
    },
    {
      "epoch": 299.26,
      "learning_rate": 0.07008632023629033,
      "loss": 0.8694,
      "step": 185540
    },
    {
      "epoch": 299.29,
      "learning_rate": 0.07008309443306453,
      "loss": 0.8679,
      "step": 185560
    },
    {
      "epoch": 299.32,
      "learning_rate": 0.07007986862983871,
      "loss": 0.8842,
      "step": 185580
    },
    {
      "epoch": 299.35,
      "learning_rate": 0.0700766428266129,
      "loss": 0.8883,
      "step": 185600
    },
    {
      "epoch": 299.39,
      "learning_rate": 0.07007341702338711,
      "loss": 0.8683,
      "step": 185620
    },
    {
      "epoch": 299.42,
      "learning_rate": 0.0700701912201613,
      "loss": 0.8591,
      "step": 185640
    },
    {
      "epoch": 299.45,
      "learning_rate": 0.0700669654169355,
      "loss": 0.8681,
      "step": 185660
    },
    {
      "epoch": 299.48,
      "learning_rate": 0.07006373961370968,
      "loss": 0.8712,
      "step": 185680
    },
    {
      "epoch": 299.52,
      "learning_rate": 0.07006051381048388,
      "loss": 0.8774,
      "step": 185700
    },
    {
      "epoch": 299.55,
      "learning_rate": 0.07005728800725806,
      "loss": 0.8544,
      "step": 185720
    },
    {
      "epoch": 299.58,
      "learning_rate": 0.07005406220403226,
      "loss": 0.8691,
      "step": 185740
    },
    {
      "epoch": 299.61,
      "learning_rate": 0.07005083640080645,
      "loss": 0.8553,
      "step": 185760
    },
    {
      "epoch": 299.65,
      "learning_rate": 0.07004761059758065,
      "loss": 0.8927,
      "step": 185780
    },
    {
      "epoch": 299.68,
      "learning_rate": 0.07004438479435485,
      "loss": 0.8863,
      "step": 185800
    },
    {
      "epoch": 299.71,
      "learning_rate": 0.07004115899112903,
      "loss": 0.8732,
      "step": 185820
    },
    {
      "epoch": 299.74,
      "learning_rate": 0.07003793318790323,
      "loss": 0.8669,
      "step": 185840
    },
    {
      "epoch": 299.77,
      "learning_rate": 0.07003470738467743,
      "loss": 0.8638,
      "step": 185860
    },
    {
      "epoch": 299.81,
      "learning_rate": 0.07003148158145162,
      "loss": 0.8436,
      "step": 185880
    },
    {
      "epoch": 299.84,
      "learning_rate": 0.0700282557782258,
      "loss": 0.8647,
      "step": 185900
    },
    {
      "epoch": 299.87,
      "learning_rate": 0.07002502997500001,
      "loss": 0.8549,
      "step": 185920
    },
    {
      "epoch": 299.9,
      "learning_rate": 0.07002180417177419,
      "loss": 0.8603,
      "step": 185940
    },
    {
      "epoch": 299.94,
      "learning_rate": 0.0700185783685484,
      "loss": 0.8577,
      "step": 185960
    },
    {
      "epoch": 299.97,
      "learning_rate": 0.07001535256532258,
      "loss": 0.8517,
      "step": 185980
    },
    {
      "epoch": 300.0,
      "learning_rate": 0.07001212676209678,
      "loss": 0.9063,
      "step": 186000
    },
    {
      "epoch": 300.0,
      "eval_accuracy": {
        "accuracy": 0.7397548981344158
      },
      "eval_loss": 1.2823492288589478,
      "eval_runtime": 2.7709,
      "eval_samples_per_second": 4623.436,
      "eval_steps_per_second": 72.54,
      "step": 186000
    },
    {
      "epoch": 300.03,
      "learning_rate": 0.07000890095887097,
      "loss": 0.9304,
      "step": 186020
    },
    {
      "epoch": 300.06,
      "learning_rate": 0.07000567515564518,
      "loss": 0.8766,
      "step": 186040
    },
    {
      "epoch": 300.1,
      "learning_rate": 0.07000244935241935,
      "loss": 0.8596,
      "step": 186060
    },
    {
      "epoch": 300.13,
      "learning_rate": 0.06999922354919355,
      "loss": 0.8503,
      "step": 186080
    },
    {
      "epoch": 300.16,
      "learning_rate": 0.06999599774596775,
      "loss": 0.8501,
      "step": 186100
    },
    {
      "epoch": 300.19,
      "learning_rate": 0.06999277194274194,
      "loss": 0.867,
      "step": 186120
    },
    {
      "epoch": 300.23,
      "learning_rate": 0.06998954613951613,
      "loss": 0.8366,
      "step": 186140
    },
    {
      "epoch": 300.26,
      "learning_rate": 0.06998632033629033,
      "loss": 0.849,
      "step": 186160
    },
    {
      "epoch": 300.29,
      "learning_rate": 0.06998309453306452,
      "loss": 0.8398,
      "step": 186180
    },
    {
      "epoch": 300.32,
      "learning_rate": 0.0699798687298387,
      "loss": 0.8698,
      "step": 186200
    },
    {
      "epoch": 300.35,
      "learning_rate": 0.06997664292661292,
      "loss": 0.8505,
      "step": 186220
    },
    {
      "epoch": 300.39,
      "learning_rate": 0.06997341712338709,
      "loss": 0.8573,
      "step": 186240
    },
    {
      "epoch": 300.42,
      "learning_rate": 0.0699701913201613,
      "loss": 0.8626,
      "step": 186260
    },
    {
      "epoch": 300.45,
      "learning_rate": 0.06996696551693549,
      "loss": 0.8561,
      "step": 186280
    },
    {
      "epoch": 300.48,
      "learning_rate": 0.06996373971370969,
      "loss": 0.8598,
      "step": 186300
    },
    {
      "epoch": 300.52,
      "learning_rate": 0.06996051391048387,
      "loss": 0.8722,
      "step": 186320
    },
    {
      "epoch": 300.55,
      "learning_rate": 0.06995728810725808,
      "loss": 0.8363,
      "step": 186340
    },
    {
      "epoch": 300.58,
      "learning_rate": 0.06995406230403226,
      "loss": 0.8942,
      "step": 186360
    },
    {
      "epoch": 300.61,
      "learning_rate": 0.06995083650080645,
      "loss": 0.8776,
      "step": 186380
    },
    {
      "epoch": 300.65,
      "learning_rate": 0.06994761069758065,
      "loss": 0.8761,
      "step": 186400
    },
    {
      "epoch": 300.68,
      "learning_rate": 0.06994438489435484,
      "loss": 0.8634,
      "step": 186420
    },
    {
      "epoch": 300.71,
      "learning_rate": 0.06994115909112904,
      "loss": 0.8582,
      "step": 186440
    },
    {
      "epoch": 300.74,
      "learning_rate": 0.06993793328790324,
      "loss": 0.8496,
      "step": 186460
    },
    {
      "epoch": 300.77,
      "learning_rate": 0.06993470748467742,
      "loss": 0.8572,
      "step": 186480
    },
    {
      "epoch": 300.81,
      "learning_rate": 0.06993148168145162,
      "loss": 0.8909,
      "step": 186500
    },
    {
      "epoch": 300.84,
      "learning_rate": 0.06992825587822582,
      "loss": 0.8606,
      "step": 186520
    },
    {
      "epoch": 300.87,
      "learning_rate": 0.06992503007499999,
      "loss": 0.8603,
      "step": 186540
    },
    {
      "epoch": 300.9,
      "learning_rate": 0.0699218042717742,
      "loss": 0.8907,
      "step": 186560
    },
    {
      "epoch": 300.94,
      "learning_rate": 0.06991857846854839,
      "loss": 0.8889,
      "step": 186580
    },
    {
      "epoch": 300.97,
      "learning_rate": 0.06991535266532259,
      "loss": 0.8838,
      "step": 186600
    },
    {
      "epoch": 301.0,
      "learning_rate": 0.06991212686209677,
      "loss": 0.8499,
      "step": 186620
    },
    {
      "epoch": 301.0,
      "eval_accuracy": {
        "accuracy": 0.7401451877292952
      },
      "eval_loss": 1.292454719543457,
      "eval_runtime": 2.7185,
      "eval_samples_per_second": 4712.525,
      "eval_steps_per_second": 73.938,
      "step": 186620
    },
    {
      "epoch": 301.03,
      "learning_rate": 0.06990890105887097,
      "loss": 0.9035,
      "step": 186640
    },
    {
      "epoch": 301.06,
      "learning_rate": 0.06990567525564516,
      "loss": 0.8514,
      "step": 186660
    },
    {
      "epoch": 301.1,
      "learning_rate": 0.06990244945241936,
      "loss": 0.8531,
      "step": 186680
    },
    {
      "epoch": 301.13,
      "learning_rate": 0.06989922364919356,
      "loss": 0.8475,
      "step": 186700
    },
    {
      "epoch": 301.16,
      "learning_rate": 0.06989599784596774,
      "loss": 0.8521,
      "step": 186720
    },
    {
      "epoch": 301.19,
      "learning_rate": 0.06989277204274194,
      "loss": 0.8673,
      "step": 186740
    },
    {
      "epoch": 301.23,
      "learning_rate": 0.06988954623951614,
      "loss": 0.8627,
      "step": 186760
    },
    {
      "epoch": 301.26,
      "learning_rate": 0.06988632043629033,
      "loss": 0.8495,
      "step": 186780
    },
    {
      "epoch": 301.29,
      "learning_rate": 0.06988309463306452,
      "loss": 0.85,
      "step": 186800
    },
    {
      "epoch": 301.32,
      "learning_rate": 0.06987986882983872,
      "loss": 0.845,
      "step": 186820
    },
    {
      "epoch": 301.35,
      "learning_rate": 0.0698766430266129,
      "loss": 0.8427,
      "step": 186840
    },
    {
      "epoch": 301.39,
      "learning_rate": 0.06987341722338711,
      "loss": 0.84,
      "step": 186860
    },
    {
      "epoch": 301.42,
      "learning_rate": 0.06987019142016129,
      "loss": 0.8723,
      "step": 186880
    },
    {
      "epoch": 301.45,
      "learning_rate": 0.06986696561693549,
      "loss": 0.863,
      "step": 186900
    },
    {
      "epoch": 301.48,
      "learning_rate": 0.06986373981370968,
      "loss": 0.8587,
      "step": 186920
    },
    {
      "epoch": 301.52,
      "learning_rate": 0.06986051401048388,
      "loss": 0.8833,
      "step": 186940
    },
    {
      "epoch": 301.55,
      "learning_rate": 0.06985728820725806,
      "loss": 0.863,
      "step": 186960
    },
    {
      "epoch": 301.58,
      "learning_rate": 0.06985406240403226,
      "loss": 0.8695,
      "step": 186980
    },
    {
      "epoch": 301.61,
      "learning_rate": 0.06985083660080646,
      "loss": 0.8808,
      "step": 187000
    },
    {
      "epoch": 301.65,
      "learning_rate": 0.06984761079758064,
      "loss": 0.8761,
      "step": 187020
    },
    {
      "epoch": 301.68,
      "learning_rate": 0.06984438499435484,
      "loss": 0.9125,
      "step": 187040
    },
    {
      "epoch": 301.71,
      "learning_rate": 0.06984115919112904,
      "loss": 0.8885,
      "step": 187060
    },
    {
      "epoch": 301.74,
      "learning_rate": 0.06983793338790323,
      "loss": 0.8717,
      "step": 187080
    },
    {
      "epoch": 301.77,
      "learning_rate": 0.06983470758467743,
      "loss": 0.8396,
      "step": 187100
    },
    {
      "epoch": 301.81,
      "learning_rate": 0.06983148178145163,
      "loss": 0.864,
      "step": 187120
    },
    {
      "epoch": 301.84,
      "learning_rate": 0.0698282559782258,
      "loss": 0.8813,
      "step": 187140
    },
    {
      "epoch": 301.87,
      "learning_rate": 0.06982503017500001,
      "loss": 0.8912,
      "step": 187160
    },
    {
      "epoch": 301.9,
      "learning_rate": 0.0698218043717742,
      "loss": 0.8903,
      "step": 187180
    },
    {
      "epoch": 301.94,
      "learning_rate": 0.0698185785685484,
      "loss": 0.8623,
      "step": 187200
    },
    {
      "epoch": 301.97,
      "learning_rate": 0.06981535276532258,
      "loss": 0.8392,
      "step": 187220
    },
    {
      "epoch": 302.0,
      "learning_rate": 0.06981228825225808,
      "loss": 0.8556,
      "step": 187240
    },
    {
      "epoch": 302.0,
      "eval_accuracy": {
        "accuracy": 0.7550542502536882
      },
      "eval_loss": 1.2035969495773315,
      "eval_runtime": 2.6506,
      "eval_samples_per_second": 4833.16,
      "eval_steps_per_second": 75.831,
      "step": 187240
    },
    {
      "epoch": 302.03,
      "learning_rate": 0.06980906244903226,
      "loss": 0.8302,
      "step": 187260
    },
    {
      "epoch": 302.06,
      "learning_rate": 0.06980583664580645,
      "loss": 0.8376,
      "step": 187280
    },
    {
      "epoch": 302.1,
      "learning_rate": 0.06980261084258066,
      "loss": 0.8463,
      "step": 187300
    },
    {
      "epoch": 302.13,
      "learning_rate": 0.06979938503935483,
      "loss": 0.8744,
      "step": 187320
    },
    {
      "epoch": 302.16,
      "learning_rate": 0.06979615923612904,
      "loss": 0.8611,
      "step": 187340
    },
    {
      "epoch": 302.19,
      "learning_rate": 0.06979293343290323,
      "loss": 0.8503,
      "step": 187360
    },
    {
      "epoch": 302.23,
      "learning_rate": 0.06978970762967743,
      "loss": 0.8561,
      "step": 187380
    },
    {
      "epoch": 302.26,
      "learning_rate": 0.06978648182645161,
      "loss": 0.8725,
      "step": 187400
    },
    {
      "epoch": 302.29,
      "learning_rate": 0.06978325602322583,
      "loss": 0.8385,
      "step": 187420
    },
    {
      "epoch": 302.32,
      "learning_rate": 0.06978003022,
      "loss": 0.8637,
      "step": 187440
    },
    {
      "epoch": 302.35,
      "learning_rate": 0.0697768044167742,
      "loss": 0.8473,
      "step": 187460
    },
    {
      "epoch": 302.39,
      "learning_rate": 0.0697735786135484,
      "loss": 0.8526,
      "step": 187480
    },
    {
      "epoch": 302.42,
      "learning_rate": 0.06977035281032258,
      "loss": 0.8499,
      "step": 187500
    },
    {
      "epoch": 302.45,
      "learning_rate": 0.06976712700709678,
      "loss": 0.8646,
      "step": 187520
    },
    {
      "epoch": 302.48,
      "learning_rate": 0.06976390120387098,
      "loss": 0.8632,
      "step": 187540
    },
    {
      "epoch": 302.52,
      "learning_rate": 0.06976067540064516,
      "loss": 0.8377,
      "step": 187560
    },
    {
      "epoch": 302.55,
      "learning_rate": 0.06975744959741936,
      "loss": 0.8315,
      "step": 187580
    },
    {
      "epoch": 302.58,
      "learning_rate": 0.06975422379419356,
      "loss": 0.8602,
      "step": 187600
    },
    {
      "epoch": 302.61,
      "learning_rate": 0.06975099799096773,
      "loss": 0.8842,
      "step": 187620
    },
    {
      "epoch": 302.65,
      "learning_rate": 0.06974777218774195,
      "loss": 0.9045,
      "step": 187640
    },
    {
      "epoch": 302.68,
      "learning_rate": 0.06974454638451613,
      "loss": 0.8618,
      "step": 187660
    },
    {
      "epoch": 302.71,
      "learning_rate": 0.06974132058129033,
      "loss": 0.8546,
      "step": 187680
    },
    {
      "epoch": 302.74,
      "learning_rate": 0.06973809477806452,
      "loss": 0.8624,
      "step": 187700
    },
    {
      "epoch": 302.77,
      "learning_rate": 0.06973486897483872,
      "loss": 0.8723,
      "step": 187720
    },
    {
      "epoch": 302.81,
      "learning_rate": 0.0697316431716129,
      "loss": 0.8518,
      "step": 187740
    },
    {
      "epoch": 302.84,
      "learning_rate": 0.0697284173683871,
      "loss": 0.844,
      "step": 187760
    },
    {
      "epoch": 302.87,
      "learning_rate": 0.0697251915651613,
      "loss": 0.8645,
      "step": 187780
    },
    {
      "epoch": 302.9,
      "learning_rate": 0.06972196576193548,
      "loss": 0.8788,
      "step": 187800
    },
    {
      "epoch": 302.94,
      "learning_rate": 0.06971873995870968,
      "loss": 0.8803,
      "step": 187820
    },
    {
      "epoch": 302.97,
      "learning_rate": 0.06971551415548388,
      "loss": 0.862,
      "step": 187840
    },
    {
      "epoch": 303.0,
      "learning_rate": 0.06971228835225807,
      "loss": 0.864,
      "step": 187860
    },
    {
      "epoch": 303.0,
      "eval_accuracy": {
        "accuracy": 0.7452970103817033
      },
      "eval_loss": 1.2579493522644043,
      "eval_runtime": 2.6414,
      "eval_samples_per_second": 4850.027,
      "eval_steps_per_second": 76.095,
      "step": 187860
    },
    {
      "epoch": 303.03,
      "learning_rate": 0.06970906254903227,
      "loss": 0.9004,
      "step": 187880
    },
    {
      "epoch": 303.06,
      "learning_rate": 0.06970583674580647,
      "loss": 0.8694,
      "step": 187900
    },
    {
      "epoch": 303.1,
      "learning_rate": 0.06970261094258064,
      "loss": 0.8028,
      "step": 187920
    },
    {
      "epoch": 303.13,
      "learning_rate": 0.06969938513935485,
      "loss": 0.8268,
      "step": 187940
    },
    {
      "epoch": 303.16,
      "learning_rate": 0.06969615933612903,
      "loss": 0.8413,
      "step": 187960
    },
    {
      "epoch": 303.19,
      "learning_rate": 0.06969293353290323,
      "loss": 0.8578,
      "step": 187980
    },
    {
      "epoch": 303.23,
      "learning_rate": 0.06968970772967742,
      "loss": 0.8531,
      "step": 188000
    },
    {
      "epoch": 303.26,
      "learning_rate": 0.06968648192645162,
      "loss": 0.8802,
      "step": 188020
    },
    {
      "epoch": 303.29,
      "learning_rate": 0.0696832561232258,
      "loss": 0.8709,
      "step": 188040
    },
    {
      "epoch": 303.32,
      "learning_rate": 0.06968003032,
      "loss": 0.8422,
      "step": 188060
    },
    {
      "epoch": 303.35,
      "learning_rate": 0.0696768045167742,
      "loss": 0.8855,
      "step": 188080
    },
    {
      "epoch": 303.39,
      "learning_rate": 0.06967357871354839,
      "loss": 0.8772,
      "step": 188100
    },
    {
      "epoch": 303.42,
      "learning_rate": 0.06967035291032259,
      "loss": 0.8802,
      "step": 188120
    },
    {
      "epoch": 303.45,
      "learning_rate": 0.06966712710709679,
      "loss": 0.8652,
      "step": 188140
    },
    {
      "epoch": 303.48,
      "learning_rate": 0.06966390130387097,
      "loss": 0.8695,
      "step": 188160
    },
    {
      "epoch": 303.52,
      "learning_rate": 0.06966067550064517,
      "loss": 0.8514,
      "step": 188180
    },
    {
      "epoch": 303.55,
      "learning_rate": 0.06965744969741937,
      "loss": 0.8888,
      "step": 188200
    },
    {
      "epoch": 303.58,
      "learning_rate": 0.06965422389419354,
      "loss": 0.8611,
      "step": 188220
    },
    {
      "epoch": 303.61,
      "learning_rate": 0.06965099809096775,
      "loss": 0.8552,
      "step": 188240
    },
    {
      "epoch": 303.65,
      "learning_rate": 0.06964777228774194,
      "loss": 0.8347,
      "step": 188260
    },
    {
      "epoch": 303.68,
      "learning_rate": 0.06964454648451614,
      "loss": 0.8599,
      "step": 188280
    },
    {
      "epoch": 303.71,
      "learning_rate": 0.06964132068129032,
      "loss": 0.8796,
      "step": 188300
    },
    {
      "epoch": 303.74,
      "learning_rate": 0.06963809487806452,
      "loss": 0.8668,
      "step": 188320
    },
    {
      "epoch": 303.77,
      "learning_rate": 0.0696348690748387,
      "loss": 0.8899,
      "step": 188340
    },
    {
      "epoch": 303.81,
      "learning_rate": 0.06963164327161292,
      "loss": 0.8918,
      "step": 188360
    },
    {
      "epoch": 303.84,
      "learning_rate": 0.0696284174683871,
      "loss": 0.8442,
      "step": 188380
    },
    {
      "epoch": 303.87,
      "learning_rate": 0.06962519166516129,
      "loss": 0.8854,
      "step": 188400
    },
    {
      "epoch": 303.9,
      "learning_rate": 0.06962196586193549,
      "loss": 0.8589,
      "step": 188420
    },
    {
      "epoch": 303.94,
      "learning_rate": 0.06961874005870969,
      "loss": 0.8436,
      "step": 188440
    },
    {
      "epoch": 303.97,
      "learning_rate": 0.06961551425548387,
      "loss": 0.8438,
      "step": 188460
    },
    {
      "epoch": 304.0,
      "learning_rate": 0.06961228845225807,
      "loss": 0.8562,
      "step": 188480
    },
    {
      "epoch": 304.0,
      "eval_accuracy": {
        "accuracy": 0.7397548981344158
      },
      "eval_loss": 1.2560735940933228,
      "eval_runtime": 2.6499,
      "eval_samples_per_second": 4834.6,
      "eval_steps_per_second": 75.853,
      "step": 188480
    },
    {
      "epoch": 304.03,
      "learning_rate": 0.06960906264903227,
      "loss": 0.8998,
      "step": 188500
    },
    {
      "epoch": 304.06,
      "learning_rate": 0.06960583684580644,
      "loss": 0.8463,
      "step": 188520
    },
    {
      "epoch": 304.1,
      "learning_rate": 0.06960261104258066,
      "loss": 0.8455,
      "step": 188540
    },
    {
      "epoch": 304.13,
      "learning_rate": 0.06959938523935484,
      "loss": 0.8356,
      "step": 188560
    },
    {
      "epoch": 304.16,
      "learning_rate": 0.06959615943612904,
      "loss": 0.8248,
      "step": 188580
    },
    {
      "epoch": 304.19,
      "learning_rate": 0.06959293363290323,
      "loss": 0.8272,
      "step": 188600
    },
    {
      "epoch": 304.23,
      "learning_rate": 0.06958970782967742,
      "loss": 0.8432,
      "step": 188620
    },
    {
      "epoch": 304.26,
      "learning_rate": 0.06958648202645161,
      "loss": 0.8691,
      "step": 188640
    },
    {
      "epoch": 304.29,
      "learning_rate": 0.06958325622322582,
      "loss": 0.8612,
      "step": 188660
    },
    {
      "epoch": 304.32,
      "learning_rate": 0.06958003042000001,
      "loss": 0.8634,
      "step": 188680
    },
    {
      "epoch": 304.35,
      "learning_rate": 0.0695768046167742,
      "loss": 0.8618,
      "step": 188700
    },
    {
      "epoch": 304.39,
      "learning_rate": 0.06957357881354839,
      "loss": 0.8628,
      "step": 188720
    },
    {
      "epoch": 304.42,
      "learning_rate": 0.06957035301032259,
      "loss": 0.8567,
      "step": 188740
    },
    {
      "epoch": 304.45,
      "learning_rate": 0.06956712720709678,
      "loss": 0.8711,
      "step": 188760
    },
    {
      "epoch": 304.48,
      "learning_rate": 0.06956390140387098,
      "loss": 0.8746,
      "step": 188780
    },
    {
      "epoch": 304.52,
      "learning_rate": 0.06956067560064516,
      "loss": 0.8337,
      "step": 188800
    },
    {
      "epoch": 304.55,
      "learning_rate": 0.06955744979741936,
      "loss": 0.8602,
      "step": 188820
    },
    {
      "epoch": 304.58,
      "learning_rate": 0.06955422399419356,
      "loss": 0.8711,
      "step": 188840
    },
    {
      "epoch": 304.61,
      "learning_rate": 0.06955099819096774,
      "loss": 0.8665,
      "step": 188860
    },
    {
      "epoch": 304.65,
      "learning_rate": 0.06954777238774194,
      "loss": 0.8649,
      "step": 188880
    },
    {
      "epoch": 304.68,
      "learning_rate": 0.06954454658451613,
      "loss": 0.8639,
      "step": 188900
    },
    {
      "epoch": 304.71,
      "learning_rate": 0.06954132078129033,
      "loss": 0.8846,
      "step": 188920
    },
    {
      "epoch": 304.74,
      "learning_rate": 0.06953809497806451,
      "loss": 0.8907,
      "step": 188940
    },
    {
      "epoch": 304.77,
      "learning_rate": 0.06953486917483873,
      "loss": 0.8685,
      "step": 188960
    },
    {
      "epoch": 304.81,
      "learning_rate": 0.06953164337161291,
      "loss": 0.8984,
      "step": 188980
    },
    {
      "epoch": 304.84,
      "learning_rate": 0.0695284175683871,
      "loss": 0.8942,
      "step": 189000
    },
    {
      "epoch": 304.87,
      "learning_rate": 0.0695251917651613,
      "loss": 0.8781,
      "step": 189020
    },
    {
      "epoch": 304.9,
      "learning_rate": 0.0695219659619355,
      "loss": 0.8832,
      "step": 189040
    },
    {
      "epoch": 304.94,
      "learning_rate": 0.06951874015870968,
      "loss": 0.8511,
      "step": 189060
    },
    {
      "epoch": 304.97,
      "learning_rate": 0.06951551435548388,
      "loss": 0.858,
      "step": 189080
    },
    {
      "epoch": 305.0,
      "learning_rate": 0.06951228855225806,
      "loss": 0.8881,
      "step": 189100
    },
    {
      "epoch": 305.0,
      "eval_accuracy": {
        "accuracy": 0.7431113886503786
      },
      "eval_loss": 1.2771022319793701,
      "eval_runtime": 3.0408,
      "eval_samples_per_second": 4213.013,
      "eval_steps_per_second": 66.101,
      "step": 189100
    },
    {
      "epoch": 305.03,
      "learning_rate": 0.06950906274903226,
      "loss": 0.8989,
      "step": 189120
    },
    {
      "epoch": 305.06,
      "learning_rate": 0.06950583694580646,
      "loss": 0.8432,
      "step": 189140
    },
    {
      "epoch": 305.1,
      "learning_rate": 0.06950261114258065,
      "loss": 0.8473,
      "step": 189160
    },
    {
      "epoch": 305.13,
      "learning_rate": 0.06949938533935485,
      "loss": 0.8503,
      "step": 189180
    },
    {
      "epoch": 305.16,
      "learning_rate": 0.06949615953612903,
      "loss": 0.8506,
      "step": 189200
    },
    {
      "epoch": 305.19,
      "learning_rate": 0.06949293373290323,
      "loss": 0.8452,
      "step": 189220
    },
    {
      "epoch": 305.23,
      "learning_rate": 0.06948970792967742,
      "loss": 0.8391,
      "step": 189240
    },
    {
      "epoch": 305.26,
      "learning_rate": 0.06948648212645163,
      "loss": 0.8596,
      "step": 189260
    },
    {
      "epoch": 305.29,
      "learning_rate": 0.06948325632322581,
      "loss": 0.8761,
      "step": 189280
    },
    {
      "epoch": 305.32,
      "learning_rate": 0.06948003052,
      "loss": 0.8731,
      "step": 189300
    },
    {
      "epoch": 305.35,
      "learning_rate": 0.0694768047167742,
      "loss": 0.8588,
      "step": 189320
    },
    {
      "epoch": 305.39,
      "learning_rate": 0.06947357891354838,
      "loss": 0.8468,
      "step": 189340
    },
    {
      "epoch": 305.42,
      "learning_rate": 0.06947035311032258,
      "loss": 0.8678,
      "step": 189360
    },
    {
      "epoch": 305.45,
      "learning_rate": 0.06946712730709678,
      "loss": 0.8518,
      "step": 189380
    },
    {
      "epoch": 305.48,
      "learning_rate": 0.06946390150387097,
      "loss": 0.8653,
      "step": 189400
    },
    {
      "epoch": 305.52,
      "learning_rate": 0.06946067570064517,
      "loss": 0.8616,
      "step": 189420
    },
    {
      "epoch": 305.55,
      "learning_rate": 0.06945744989741937,
      "loss": 0.8573,
      "step": 189440
    },
    {
      "epoch": 305.58,
      "learning_rate": 0.06945422409419355,
      "loss": 0.8647,
      "step": 189460
    },
    {
      "epoch": 305.61,
      "learning_rate": 0.06945099829096775,
      "loss": 0.8513,
      "step": 189480
    },
    {
      "epoch": 305.65,
      "learning_rate": 0.06944777248774194,
      "loss": 0.8817,
      "step": 189500
    },
    {
      "epoch": 305.68,
      "learning_rate": 0.06944454668451613,
      "loss": 0.8799,
      "step": 189520
    },
    {
      "epoch": 305.71,
      "learning_rate": 0.06944132088129032,
      "loss": 0.8586,
      "step": 189540
    },
    {
      "epoch": 305.74,
      "learning_rate": 0.06943809507806453,
      "loss": 0.8402,
      "step": 189560
    },
    {
      "epoch": 305.77,
      "learning_rate": 0.06943486927483872,
      "loss": 0.8711,
      "step": 189580
    },
    {
      "epoch": 305.81,
      "learning_rate": 0.06943164347161292,
      "loss": 0.8647,
      "step": 189600
    },
    {
      "epoch": 305.84,
      "learning_rate": 0.0694284176683871,
      "loss": 0.8623,
      "step": 189620
    },
    {
      "epoch": 305.87,
      "learning_rate": 0.06942519186516129,
      "loss": 0.8666,
      "step": 189640
    },
    {
      "epoch": 305.9,
      "learning_rate": 0.06942196606193549,
      "loss": 0.8715,
      "step": 189660
    },
    {
      "epoch": 305.94,
      "learning_rate": 0.06941874025870969,
      "loss": 0.8696,
      "step": 189680
    },
    {
      "epoch": 305.97,
      "learning_rate": 0.06941551445548387,
      "loss": 0.8702,
      "step": 189700
    },
    {
      "epoch": 306.0,
      "learning_rate": 0.06941228865225807,
      "loss": 0.8851,
      "step": 189720
    },
    {
      "epoch": 306.0,
      "eval_accuracy": {
        "accuracy": 0.7509171805479666
      },
      "eval_loss": 1.264772891998291,
      "eval_runtime": 2.6829,
      "eval_samples_per_second": 4775.026,
      "eval_steps_per_second": 74.918,
      "step": 189720
    },
    {
      "epoch": 306.03,
      "learning_rate": 0.06940906284903227,
      "loss": 0.8636,
      "step": 189740
    },
    {
      "epoch": 306.06,
      "learning_rate": 0.06940583704580645,
      "loss": 0.8411,
      "step": 189760
    },
    {
      "epoch": 306.1,
      "learning_rate": 0.06940261124258065,
      "loss": 0.8427,
      "step": 189780
    },
    {
      "epoch": 306.13,
      "learning_rate": 0.06939938543935484,
      "loss": 0.8543,
      "step": 189800
    },
    {
      "epoch": 306.16,
      "learning_rate": 0.06939615963612904,
      "loss": 0.8464,
      "step": 189820
    },
    {
      "epoch": 306.19,
      "learning_rate": 0.06939293383290322,
      "loss": 0.8261,
      "step": 189840
    },
    {
      "epoch": 306.23,
      "learning_rate": 0.06938970802967744,
      "loss": 0.8576,
      "step": 189860
    },
    {
      "epoch": 306.26,
      "learning_rate": 0.0693864822264516,
      "loss": 0.8593,
      "step": 189880
    },
    {
      "epoch": 306.29,
      "learning_rate": 0.06938325642322582,
      "loss": 0.8251,
      "step": 189900
    },
    {
      "epoch": 306.32,
      "learning_rate": 0.06938003062,
      "loss": 0.8539,
      "step": 189920
    },
    {
      "epoch": 306.35,
      "learning_rate": 0.06937680481677419,
      "loss": 0.8574,
      "step": 189940
    },
    {
      "epoch": 306.39,
      "learning_rate": 0.06937357901354839,
      "loss": 0.8612,
      "step": 189960
    },
    {
      "epoch": 306.42,
      "learning_rate": 0.06937035321032259,
      "loss": 0.8533,
      "step": 189980
    },
    {
      "epoch": 306.45,
      "learning_rate": 0.06936712740709677,
      "loss": 0.8627,
      "step": 190000
    },
    {
      "epoch": 306.48,
      "learning_rate": 0.06936390160387097,
      "loss": 0.8927,
      "step": 190020
    },
    {
      "epoch": 306.52,
      "learning_rate": 0.06936067580064517,
      "loss": 0.8622,
      "step": 190040
    },
    {
      "epoch": 306.55,
      "learning_rate": 0.06935744999741936,
      "loss": 0.8432,
      "step": 190060
    },
    {
      "epoch": 306.58,
      "learning_rate": 0.06935422419419356,
      "loss": 0.8598,
      "step": 190080
    },
    {
      "epoch": 306.61,
      "learning_rate": 0.06935099839096774,
      "loss": 0.872,
      "step": 190100
    },
    {
      "epoch": 306.65,
      "learning_rate": 0.06934777258774194,
      "loss": 0.861,
      "step": 190120
    },
    {
      "epoch": 306.68,
      "learning_rate": 0.06934454678451613,
      "loss": 0.8629,
      "step": 190140
    },
    {
      "epoch": 306.71,
      "learning_rate": 0.06934132098129034,
      "loss": 0.8837,
      "step": 190160
    },
    {
      "epoch": 306.74,
      "learning_rate": 0.06933809517806451,
      "loss": 0.8752,
      "step": 190180
    },
    {
      "epoch": 306.77,
      "learning_rate": 0.06933486937483872,
      "loss": 0.8775,
      "step": 190200
    },
    {
      "epoch": 306.81,
      "learning_rate": 0.06933164357161291,
      "loss": 0.8889,
      "step": 190220
    },
    {
      "epoch": 306.84,
      "learning_rate": 0.0693284177683871,
      "loss": 0.8659,
      "step": 190240
    },
    {
      "epoch": 306.87,
      "learning_rate": 0.06932519196516129,
      "loss": 0.8914,
      "step": 190260
    },
    {
      "epoch": 306.9,
      "learning_rate": 0.06932196616193549,
      "loss": 0.885,
      "step": 190280
    },
    {
      "epoch": 306.94,
      "learning_rate": 0.06931874035870968,
      "loss": 0.8724,
      "step": 190300
    },
    {
      "epoch": 306.97,
      "learning_rate": 0.06931551455548388,
      "loss": 0.8675,
      "step": 190320
    },
    {
      "epoch": 307.0,
      "learning_rate": 0.06931228875225807,
      "loss": 0.85,
      "step": 190340
    },
    {
      "epoch": 307.0,
      "eval_accuracy": {
        "accuracy": 0.7453750683006791
      },
      "eval_loss": 1.279363751411438,
      "eval_runtime": 2.7259,
      "eval_samples_per_second": 4699.788,
      "eval_steps_per_second": 73.738,
      "step": 190340
    },
    {
      "epoch": 307.03,
      "learning_rate": 0.06930906294903226,
      "loss": 0.9049,
      "step": 190360
    },
    {
      "epoch": 307.06,
      "learning_rate": 0.06930583714580646,
      "loss": 0.845,
      "step": 190380
    },
    {
      "epoch": 307.1,
      "learning_rate": 0.06930261134258064,
      "loss": 0.8595,
      "step": 190400
    },
    {
      "epoch": 307.13,
      "learning_rate": 0.06929938553935484,
      "loss": 0.8708,
      "step": 190420
    },
    {
      "epoch": 307.16,
      "learning_rate": 0.06929615973612903,
      "loss": 0.8625,
      "step": 190440
    },
    {
      "epoch": 307.19,
      "learning_rate": 0.06929293393290324,
      "loss": 0.8574,
      "step": 190460
    },
    {
      "epoch": 307.23,
      "learning_rate": 0.06928970812967741,
      "loss": 0.8536,
      "step": 190480
    },
    {
      "epoch": 307.26,
      "learning_rate": 0.06928648232645163,
      "loss": 0.8614,
      "step": 190500
    },
    {
      "epoch": 307.29,
      "learning_rate": 0.06928325652322581,
      "loss": 0.8526,
      "step": 190520
    },
    {
      "epoch": 307.32,
      "learning_rate": 0.06928003072000001,
      "loss": 0.8509,
      "step": 190540
    },
    {
      "epoch": 307.35,
      "learning_rate": 0.0692768049167742,
      "loss": 0.8581,
      "step": 190560
    },
    {
      "epoch": 307.39,
      "learning_rate": 0.0692735791135484,
      "loss": 0.84,
      "step": 190580
    },
    {
      "epoch": 307.42,
      "learning_rate": 0.06927035331032258,
      "loss": 0.8572,
      "step": 190600
    },
    {
      "epoch": 307.45,
      "learning_rate": 0.06926712750709678,
      "loss": 0.8396,
      "step": 190620
    },
    {
      "epoch": 307.48,
      "learning_rate": 0.06926390170387098,
      "loss": 0.8525,
      "step": 190640
    },
    {
      "epoch": 307.52,
      "learning_rate": 0.06926067590064516,
      "loss": 0.8592,
      "step": 190660
    },
    {
      "epoch": 307.55,
      "learning_rate": 0.06925745009741936,
      "loss": 0.834,
      "step": 190680
    },
    {
      "epoch": 307.58,
      "learning_rate": 0.06925422429419355,
      "loss": 0.8781,
      "step": 190700
    },
    {
      "epoch": 307.61,
      "learning_rate": 0.06925099849096775,
      "loss": 0.8696,
      "step": 190720
    },
    {
      "epoch": 307.65,
      "learning_rate": 0.06924777268774193,
      "loss": 0.8669,
      "step": 190740
    },
    {
      "epoch": 307.68,
      "learning_rate": 0.06924454688451614,
      "loss": 0.8651,
      "step": 190760
    },
    {
      "epoch": 307.71,
      "learning_rate": 0.06924132108129032,
      "loss": 0.8483,
      "step": 190780
    },
    {
      "epoch": 307.74,
      "learning_rate": 0.06923809527806453,
      "loss": 0.8677,
      "step": 190800
    },
    {
      "epoch": 307.77,
      "learning_rate": 0.06923486947483871,
      "loss": 0.8676,
      "step": 190820
    },
    {
      "epoch": 307.81,
      "learning_rate": 0.06923164367161291,
      "loss": 0.8641,
      "step": 190840
    },
    {
      "epoch": 307.84,
      "learning_rate": 0.0692284178683871,
      "loss": 0.882,
      "step": 190860
    },
    {
      "epoch": 307.87,
      "learning_rate": 0.0692251920651613,
      "loss": 0.8845,
      "step": 190880
    },
    {
      "epoch": 307.9,
      "learning_rate": 0.06922196626193548,
      "loss": 0.8667,
      "step": 190900
    },
    {
      "epoch": 307.94,
      "learning_rate": 0.06921874045870968,
      "loss": 0.8759,
      "step": 190920
    },
    {
      "epoch": 307.97,
      "learning_rate": 0.06921551465548388,
      "loss": 0.877,
      "step": 190940
    },
    {
      "epoch": 308.0,
      "learning_rate": 0.06921245014241935,
      "loss": 0.8947,
      "step": 190960
    },
    {
      "epoch": 308.0,
      "eval_accuracy": {
        "accuracy": 0.746155647490438
      },
      "eval_loss": 1.23933744430542,
      "eval_runtime": 2.6509,
      "eval_samples_per_second": 4832.666,
      "eval_steps_per_second": 75.823,
      "step": 190960
    },
    {
      "epoch": 308.03,
      "learning_rate": 0.06920922433919356,
      "loss": 0.8635,
      "step": 190980
    },
    {
      "epoch": 308.06,
      "learning_rate": 0.06920599853596775,
      "loss": 0.8743,
      "step": 191000
    },
    {
      "epoch": 308.1,
      "learning_rate": 0.06920277273274193,
      "loss": 0.8613,
      "step": 191020
    },
    {
      "epoch": 308.13,
      "learning_rate": 0.06919954692951613,
      "loss": 0.8464,
      "step": 191040
    },
    {
      "epoch": 308.16,
      "learning_rate": 0.06919632112629033,
      "loss": 0.8482,
      "step": 191060
    },
    {
      "epoch": 308.19,
      "learning_rate": 0.06919309532306452,
      "loss": 0.8437,
      "step": 191080
    },
    {
      "epoch": 308.23,
      "learning_rate": 0.06918986951983871,
      "loss": 0.8409,
      "step": 191100
    },
    {
      "epoch": 308.26,
      "learning_rate": 0.06918664371661291,
      "loss": 0.8449,
      "step": 191120
    },
    {
      "epoch": 308.29,
      "learning_rate": 0.0691834179133871,
      "loss": 0.8753,
      "step": 191140
    },
    {
      "epoch": 308.32,
      "learning_rate": 0.0691801921101613,
      "loss": 0.8627,
      "step": 191160
    },
    {
      "epoch": 308.35,
      "learning_rate": 0.06917696630693548,
      "loss": 0.8481,
      "step": 191180
    },
    {
      "epoch": 308.39,
      "learning_rate": 0.06917374050370968,
      "loss": 0.8453,
      "step": 191200
    },
    {
      "epoch": 308.42,
      "learning_rate": 0.06917051470048387,
      "loss": 0.8638,
      "step": 191220
    },
    {
      "epoch": 308.45,
      "learning_rate": 0.06916728889725808,
      "loss": 0.8687,
      "step": 191240
    },
    {
      "epoch": 308.48,
      "learning_rate": 0.06916406309403225,
      "loss": 0.8748,
      "step": 191260
    },
    {
      "epoch": 308.52,
      "learning_rate": 0.06916083729080647,
      "loss": 0.879,
      "step": 191280
    },
    {
      "epoch": 308.55,
      "learning_rate": 0.06915761148758065,
      "loss": 0.8678,
      "step": 191300
    },
    {
      "epoch": 308.58,
      "learning_rate": 0.06915438568435484,
      "loss": 0.8679,
      "step": 191320
    },
    {
      "epoch": 308.61,
      "learning_rate": 0.06915115988112903,
      "loss": 0.8597,
      "step": 191340
    },
    {
      "epoch": 308.65,
      "learning_rate": 0.06914793407790323,
      "loss": 0.8567,
      "step": 191360
    },
    {
      "epoch": 308.68,
      "learning_rate": 0.06914470827467742,
      "loss": 0.8711,
      "step": 191380
    },
    {
      "epoch": 308.71,
      "learning_rate": 0.06914148247145162,
      "loss": 0.8698,
      "step": 191400
    },
    {
      "epoch": 308.74,
      "learning_rate": 0.06913825666822582,
      "loss": 0.8383,
      "step": 191420
    },
    {
      "epoch": 308.77,
      "learning_rate": 0.069135030865,
      "loss": 0.8518,
      "step": 191440
    },
    {
      "epoch": 308.81,
      "learning_rate": 0.0691318050617742,
      "loss": 0.8798,
      "step": 191460
    },
    {
      "epoch": 308.84,
      "learning_rate": 0.06912857925854839,
      "loss": 0.8951,
      "step": 191480
    },
    {
      "epoch": 308.87,
      "learning_rate": 0.06912535345532259,
      "loss": 0.8737,
      "step": 191500
    },
    {
      "epoch": 308.9,
      "learning_rate": 0.06912212765209677,
      "loss": 0.8783,
      "step": 191520
    },
    {
      "epoch": 308.94,
      "learning_rate": 0.06911890184887098,
      "loss": 0.8811,
      "step": 191540
    },
    {
      "epoch": 308.97,
      "learning_rate": 0.06911567604564516,
      "loss": 0.8758,
      "step": 191560
    },
    {
      "epoch": 309.0,
      "learning_rate": 0.06911245024241937,
      "loss": 0.8862,
      "step": 191580
    },
    {
      "epoch": 309.0,
      "eval_accuracy": {
        "accuracy": 0.7470142845991726
      },
      "eval_loss": 1.2297874689102173,
      "eval_runtime": 3.8754,
      "eval_samples_per_second": 3305.748,
      "eval_steps_per_second": 51.866,
      "step": 191580
    },
    {
      "epoch": 309.03,
      "learning_rate": 0.06910922443919355,
      "loss": 0.8727,
      "step": 191600
    },
    {
      "epoch": 309.06,
      "learning_rate": 0.06910599863596774,
      "loss": 0.8359,
      "step": 191620
    },
    {
      "epoch": 309.1,
      "learning_rate": 0.06910277283274194,
      "loss": 0.847,
      "step": 191640
    },
    {
      "epoch": 309.13,
      "learning_rate": 0.06909954702951614,
      "loss": 0.8551,
      "step": 191660
    },
    {
      "epoch": 309.16,
      "learning_rate": 0.06909632122629032,
      "loss": 0.819,
      "step": 191680
    },
    {
      "epoch": 309.19,
      "learning_rate": 0.06909309542306452,
      "loss": 0.8459,
      "step": 191700
    },
    {
      "epoch": 309.23,
      "learning_rate": 0.06908986961983872,
      "loss": 0.8486,
      "step": 191720
    },
    {
      "epoch": 309.26,
      "learning_rate": 0.0690866438166129,
      "loss": 0.8525,
      "step": 191740
    },
    {
      "epoch": 309.29,
      "learning_rate": 0.0690834180133871,
      "loss": 0.8546,
      "step": 191760
    },
    {
      "epoch": 309.32,
      "learning_rate": 0.06908019221016129,
      "loss": 0.8272,
      "step": 191780
    },
    {
      "epoch": 309.35,
      "learning_rate": 0.06907696640693549,
      "loss": 0.8464,
      "step": 191800
    },
    {
      "epoch": 309.39,
      "learning_rate": 0.06907374060370967,
      "loss": 0.8883,
      "step": 191820
    },
    {
      "epoch": 309.42,
      "learning_rate": 0.06907051480048389,
      "loss": 0.8718,
      "step": 191840
    },
    {
      "epoch": 309.45,
      "learning_rate": 0.06906728899725806,
      "loss": 0.875,
      "step": 191860
    },
    {
      "epoch": 309.48,
      "learning_rate": 0.06906406319403227,
      "loss": 0.8429,
      "step": 191880
    },
    {
      "epoch": 309.52,
      "learning_rate": 0.06906083739080646,
      "loss": 0.87,
      "step": 191900
    },
    {
      "epoch": 309.55,
      "learning_rate": 0.06905761158758066,
      "loss": 0.8731,
      "step": 191920
    },
    {
      "epoch": 309.58,
      "learning_rate": 0.06905438578435484,
      "loss": 0.8698,
      "step": 191940
    },
    {
      "epoch": 309.61,
      "learning_rate": 0.06905115998112904,
      "loss": 0.8658,
      "step": 191960
    },
    {
      "epoch": 309.65,
      "learning_rate": 0.06904793417790323,
      "loss": 0.8571,
      "step": 191980
    },
    {
      "epoch": 309.68,
      "learning_rate": 0.06904470837467742,
      "loss": 0.8421,
      "step": 192000
    },
    {
      "epoch": 309.71,
      "learning_rate": 0.06904148257145162,
      "loss": 0.8716,
      "step": 192020
    },
    {
      "epoch": 309.74,
      "learning_rate": 0.06903825676822581,
      "loss": 0.8613,
      "step": 192040
    },
    {
      "epoch": 309.77,
      "learning_rate": 0.06903503096500001,
      "loss": 0.8503,
      "step": 192060
    },
    {
      "epoch": 309.81,
      "learning_rate": 0.0690318051617742,
      "loss": 0.8496,
      "step": 192080
    },
    {
      "epoch": 309.84,
      "learning_rate": 0.06902857935854839,
      "loss": 0.8455,
      "step": 192100
    },
    {
      "epoch": 309.87,
      "learning_rate": 0.06902535355532258,
      "loss": 0.8301,
      "step": 192120
    },
    {
      "epoch": 309.9,
      "learning_rate": 0.06902212775209679,
      "loss": 0.8456,
      "step": 192140
    },
    {
      "epoch": 309.94,
      "learning_rate": 0.06901890194887096,
      "loss": 0.8694,
      "step": 192160
    },
    {
      "epoch": 309.97,
      "learning_rate": 0.06901567614564517,
      "loss": 0.8716,
      "step": 192180
    },
    {
      "epoch": 310.0,
      "learning_rate": 0.06901245034241936,
      "loss": 0.8772,
      "step": 192200
    },
    {
      "epoch": 310.0,
      "eval_accuracy": {
        "accuracy": 0.7397548981344158
      },
      "eval_loss": 1.2855846881866455,
      "eval_runtime": 2.9279,
      "eval_samples_per_second": 4375.52,
      "eval_steps_per_second": 68.65,
      "step": 192200
    },
    {
      "epoch": 310.03,
      "learning_rate": 0.06900922453919356,
      "loss": 0.8734,
      "step": 192220
    },
    {
      "epoch": 310.06,
      "learning_rate": 0.06900599873596774,
      "loss": 0.8374,
      "step": 192240
    },
    {
      "epoch": 310.1,
      "learning_rate": 0.06900277293274194,
      "loss": 0.8222,
      "step": 192260
    },
    {
      "epoch": 310.13,
      "learning_rate": 0.06899954712951613,
      "loss": 0.8249,
      "step": 192280
    },
    {
      "epoch": 310.16,
      "learning_rate": 0.06899632132629033,
      "loss": 0.853,
      "step": 192300
    },
    {
      "epoch": 310.19,
      "learning_rate": 0.06899309552306453,
      "loss": 0.8565,
      "step": 192320
    },
    {
      "epoch": 310.23,
      "learning_rate": 0.06898986971983871,
      "loss": 0.8603,
      "step": 192340
    },
    {
      "epoch": 310.26,
      "learning_rate": 0.06898664391661291,
      "loss": 0.8548,
      "step": 192360
    },
    {
      "epoch": 310.29,
      "learning_rate": 0.06898341811338711,
      "loss": 0.841,
      "step": 192380
    },
    {
      "epoch": 310.32,
      "learning_rate": 0.0689801923101613,
      "loss": 0.8586,
      "step": 192400
    },
    {
      "epoch": 310.35,
      "learning_rate": 0.06897696650693548,
      "loss": 0.8473,
      "step": 192420
    },
    {
      "epoch": 310.39,
      "learning_rate": 0.0689737407037097,
      "loss": 0.8461,
      "step": 192440
    },
    {
      "epoch": 310.42,
      "learning_rate": 0.06897051490048386,
      "loss": 0.8644,
      "step": 192460
    },
    {
      "epoch": 310.45,
      "learning_rate": 0.06896728909725808,
      "loss": 0.8524,
      "step": 192480
    },
    {
      "epoch": 310.48,
      "learning_rate": 0.06896406329403226,
      "loss": 0.8729,
      "step": 192500
    },
    {
      "epoch": 310.52,
      "learning_rate": 0.06896083749080646,
      "loss": 0.8602,
      "step": 192520
    },
    {
      "epoch": 310.55,
      "learning_rate": 0.06895761168758065,
      "loss": 0.8531,
      "step": 192540
    },
    {
      "epoch": 310.58,
      "learning_rate": 0.06895438588435485,
      "loss": 0.8709,
      "step": 192560
    },
    {
      "epoch": 310.61,
      "learning_rate": 0.06895116008112903,
      "loss": 0.8512,
      "step": 192580
    },
    {
      "epoch": 310.65,
      "learning_rate": 0.06894793427790323,
      "loss": 0.8671,
      "step": 192600
    },
    {
      "epoch": 310.68,
      "learning_rate": 0.06894470847467743,
      "loss": 0.8678,
      "step": 192620
    },
    {
      "epoch": 310.71,
      "learning_rate": 0.06894148267145161,
      "loss": 0.8719,
      "step": 192640
    },
    {
      "epoch": 310.74,
      "learning_rate": 0.06893825686822581,
      "loss": 0.8775,
      "step": 192660
    },
    {
      "epoch": 310.77,
      "learning_rate": 0.06893503106500001,
      "loss": 0.8566,
      "step": 192680
    },
    {
      "epoch": 310.81,
      "learning_rate": 0.0689318052617742,
      "loss": 0.8773,
      "step": 192700
    },
    {
      "epoch": 310.84,
      "learning_rate": 0.06892857945854838,
      "loss": 0.8676,
      "step": 192720
    },
    {
      "epoch": 310.87,
      "learning_rate": 0.06892535365532258,
      "loss": 0.8827,
      "step": 192740
    },
    {
      "epoch": 310.9,
      "learning_rate": 0.06892212785209677,
      "loss": 0.8781,
      "step": 192760
    },
    {
      "epoch": 310.94,
      "learning_rate": 0.06891890204887098,
      "loss": 0.8356,
      "step": 192780
    },
    {
      "epoch": 310.97,
      "learning_rate": 0.06891567624564517,
      "loss": 0.8687,
      "step": 192800
    },
    {
      "epoch": 311.0,
      "learning_rate": 0.06891245044241937,
      "loss": 0.8869,
      "step": 192820
    },
    {
      "epoch": 311.0,
      "eval_accuracy": {
        "accuracy": 0.745453126219655
      },
      "eval_loss": 1.2741602659225464,
      "eval_runtime": 2.7591,
      "eval_samples_per_second": 4643.223,
      "eval_steps_per_second": 72.851,
      "step": 192820
    },
    {
      "epoch": 311.03,
      "learning_rate": 0.06890922463919355,
      "loss": 0.8971,
      "step": 192840
    },
    {
      "epoch": 311.06,
      "learning_rate": 0.06890599883596775,
      "loss": 0.8395,
      "step": 192860
    },
    {
      "epoch": 311.1,
      "learning_rate": 0.06890277303274193,
      "loss": 0.8321,
      "step": 192880
    },
    {
      "epoch": 311.13,
      "learning_rate": 0.06889954722951613,
      "loss": 0.8275,
      "step": 192900
    },
    {
      "epoch": 311.16,
      "learning_rate": 0.06889632142629033,
      "loss": 0.8323,
      "step": 192920
    },
    {
      "epoch": 311.19,
      "learning_rate": 0.06889309562306452,
      "loss": 0.8604,
      "step": 192940
    },
    {
      "epoch": 311.23,
      "learning_rate": 0.06888986981983872,
      "loss": 0.8491,
      "step": 192960
    },
    {
      "epoch": 311.26,
      "learning_rate": 0.06888664401661292,
      "loss": 0.864,
      "step": 192980
    },
    {
      "epoch": 311.29,
      "learning_rate": 0.0688834182133871,
      "loss": 0.8433,
      "step": 193000
    },
    {
      "epoch": 311.32,
      "learning_rate": 0.06888019241016129,
      "loss": 0.8586,
      "step": 193020
    },
    {
      "epoch": 311.35,
      "learning_rate": 0.06887696660693549,
      "loss": 0.8612,
      "step": 193040
    },
    {
      "epoch": 311.39,
      "learning_rate": 0.06887374080370967,
      "loss": 0.8762,
      "step": 193060
    },
    {
      "epoch": 311.42,
      "learning_rate": 0.06887051500048388,
      "loss": 0.8629,
      "step": 193080
    },
    {
      "epoch": 311.45,
      "learning_rate": 0.06886728919725807,
      "loss": 0.8398,
      "step": 193100
    },
    {
      "epoch": 311.48,
      "learning_rate": 0.06886406339403227,
      "loss": 0.8717,
      "step": 193120
    },
    {
      "epoch": 311.52,
      "learning_rate": 0.06886083759080645,
      "loss": 0.8278,
      "step": 193140
    },
    {
      "epoch": 311.55,
      "learning_rate": 0.06885761178758065,
      "loss": 0.8721,
      "step": 193160
    },
    {
      "epoch": 311.58,
      "learning_rate": 0.06885438598435484,
      "loss": 0.8551,
      "step": 193180
    },
    {
      "epoch": 311.61,
      "learning_rate": 0.06885116018112904,
      "loss": 0.8531,
      "step": 193200
    },
    {
      "epoch": 311.65,
      "learning_rate": 0.06884793437790324,
      "loss": 0.8553,
      "step": 193220
    },
    {
      "epoch": 311.68,
      "learning_rate": 0.06884470857467742,
      "loss": 0.878,
      "step": 193240
    },
    {
      "epoch": 311.71,
      "learning_rate": 0.06884148277145162,
      "loss": 0.8935,
      "step": 193260
    },
    {
      "epoch": 311.74,
      "learning_rate": 0.0688382569682258,
      "loss": 0.8764,
      "step": 193280
    },
    {
      "epoch": 311.77,
      "learning_rate": 0.068835031165,
      "loss": 0.8732,
      "step": 193300
    },
    {
      "epoch": 311.81,
      "learning_rate": 0.0688318053617742,
      "loss": 0.8718,
      "step": 193320
    },
    {
      "epoch": 311.84,
      "learning_rate": 0.06882857955854839,
      "loss": 0.8814,
      "step": 193340
    },
    {
      "epoch": 311.87,
      "learning_rate": 0.06882535375532257,
      "loss": 0.8812,
      "step": 193360
    },
    {
      "epoch": 311.9,
      "learning_rate": 0.06882212795209679,
      "loss": 0.845,
      "step": 193380
    },
    {
      "epoch": 311.94,
      "learning_rate": 0.06881890214887097,
      "loss": 0.8323,
      "step": 193400
    },
    {
      "epoch": 311.97,
      "learning_rate": 0.06881567634564517,
      "loss": 0.818,
      "step": 193420
    },
    {
      "epoch": 312.0,
      "learning_rate": 0.06881261183258065,
      "loss": 0.8506,
      "step": 193440
    },
    {
      "epoch": 312.0,
      "eval_accuracy": {
        "accuracy": 0.7586449145265787
      },
      "eval_loss": 1.1663693189620972,
      "eval_runtime": 3.8569,
      "eval_samples_per_second": 3321.575,
      "eval_steps_per_second": 52.114,
      "step": 193440
    },
    {
      "epoch": 312.03,
      "learning_rate": 0.06880938602935485,
      "loss": 0.8294,
      "step": 193460
    },
    {
      "epoch": 312.06,
      "learning_rate": 0.06880616022612904,
      "loss": 0.8334,
      "step": 193480
    },
    {
      "epoch": 312.1,
      "learning_rate": 0.06880293442290322,
      "loss": 0.8238,
      "step": 193500
    },
    {
      "epoch": 312.13,
      "learning_rate": 0.06879970861967744,
      "loss": 0.8183,
      "step": 193520
    },
    {
      "epoch": 312.16,
      "learning_rate": 0.0687964828164516,
      "loss": 0.8516,
      "step": 193540
    },
    {
      "epoch": 312.19,
      "learning_rate": 0.06879325701322582,
      "loss": 0.8528,
      "step": 193560
    },
    {
      "epoch": 312.23,
      "learning_rate": 0.06879003121,
      "loss": 0.8506,
      "step": 193580
    },
    {
      "epoch": 312.26,
      "learning_rate": 0.0687868054067742,
      "loss": 0.8508,
      "step": 193600
    },
    {
      "epoch": 312.29,
      "learning_rate": 0.06878357960354839,
      "loss": 0.8422,
      "step": 193620
    },
    {
      "epoch": 312.32,
      "learning_rate": 0.06878035380032259,
      "loss": 0.8595,
      "step": 193640
    },
    {
      "epoch": 312.35,
      "learning_rate": 0.06877712799709677,
      "loss": 0.8505,
      "step": 193660
    },
    {
      "epoch": 312.39,
      "learning_rate": 0.06877390219387097,
      "loss": 0.8406,
      "step": 193680
    },
    {
      "epoch": 312.42,
      "learning_rate": 0.06877067639064517,
      "loss": 0.8451,
      "step": 193700
    },
    {
      "epoch": 312.45,
      "learning_rate": 0.06876745058741936,
      "loss": 0.8478,
      "step": 193720
    },
    {
      "epoch": 312.48,
      "learning_rate": 0.06876422478419356,
      "loss": 0.881,
      "step": 193740
    },
    {
      "epoch": 312.52,
      "learning_rate": 0.06876099898096776,
      "loss": 0.8656,
      "step": 193760
    },
    {
      "epoch": 312.55,
      "learning_rate": 0.06875777317774194,
      "loss": 0.8587,
      "step": 193780
    },
    {
      "epoch": 312.58,
      "learning_rate": 0.06875454737451613,
      "loss": 0.8824,
      "step": 193800
    },
    {
      "epoch": 312.61,
      "learning_rate": 0.06875132157129032,
      "loss": 0.8663,
      "step": 193820
    },
    {
      "epoch": 312.65,
      "learning_rate": 0.06874809576806451,
      "loss": 0.8484,
      "step": 193840
    },
    {
      "epoch": 312.68,
      "learning_rate": 0.06874486996483872,
      "loss": 0.8733,
      "step": 193860
    },
    {
      "epoch": 312.71,
      "learning_rate": 0.06874164416161291,
      "loss": 0.8557,
      "step": 193880
    },
    {
      "epoch": 312.74,
      "learning_rate": 0.06873841835838711,
      "loss": 0.8604,
      "step": 193900
    },
    {
      "epoch": 312.77,
      "learning_rate": 0.06873519255516129,
      "loss": 0.8592,
      "step": 193920
    },
    {
      "epoch": 312.81,
      "learning_rate": 0.06873196675193549,
      "loss": 0.8649,
      "step": 193940
    },
    {
      "epoch": 312.84,
      "learning_rate": 0.06872874094870968,
      "loss": 0.8625,
      "step": 193960
    },
    {
      "epoch": 312.87,
      "learning_rate": 0.06872551514548388,
      "loss": 0.87,
      "step": 193980
    },
    {
      "epoch": 312.9,
      "learning_rate": 0.06872228934225807,
      "loss": 0.873,
      "step": 194000
    },
    {
      "epoch": 312.94,
      "learning_rate": 0.06871906353903226,
      "loss": 0.8628,
      "step": 194020
    },
    {
      "epoch": 312.97,
      "learning_rate": 0.06871583773580646,
      "loss": 0.8554,
      "step": 194040
    },
    {
      "epoch": 313.0,
      "learning_rate": 0.06871261193258066,
      "loss": 0.8684,
      "step": 194060
    },
    {
      "epoch": 313.0,
      "eval_accuracy": {
        "accuracy": 0.7501366013582078
      },
      "eval_loss": 1.2303056716918945,
      "eval_runtime": 2.6989,
      "eval_samples_per_second": 4746.692,
      "eval_steps_per_second": 74.474,
      "step": 194060
    },
    {
      "epoch": 313.03,
      "learning_rate": 0.06870938612935484,
      "loss": 0.8809,
      "step": 194080
    },
    {
      "epoch": 313.06,
      "learning_rate": 0.06870616032612903,
      "loss": 0.8523,
      "step": 194100
    },
    {
      "epoch": 313.1,
      "learning_rate": 0.06870293452290323,
      "loss": 0.8094,
      "step": 194120
    },
    {
      "epoch": 313.13,
      "learning_rate": 0.06869970871967741,
      "loss": 0.8339,
      "step": 194140
    },
    {
      "epoch": 313.16,
      "learning_rate": 0.06869648291645163,
      "loss": 0.8123,
      "step": 194160
    },
    {
      "epoch": 313.19,
      "learning_rate": 0.06869325711322581,
      "loss": 0.8255,
      "step": 194180
    },
    {
      "epoch": 313.23,
      "learning_rate": 0.06869003131000001,
      "loss": 0.8394,
      "step": 194200
    },
    {
      "epoch": 313.26,
      "learning_rate": 0.0686868055067742,
      "loss": 0.8548,
      "step": 194220
    },
    {
      "epoch": 313.29,
      "learning_rate": 0.0686835797035484,
      "loss": 0.8668,
      "step": 194240
    },
    {
      "epoch": 313.32,
      "learning_rate": 0.06868035390032258,
      "loss": 0.828,
      "step": 194260
    },
    {
      "epoch": 313.35,
      "learning_rate": 0.06867712809709678,
      "loss": 0.8495,
      "step": 194280
    },
    {
      "epoch": 313.39,
      "learning_rate": 0.06867390229387098,
      "loss": 0.8842,
      "step": 194300
    },
    {
      "epoch": 313.42,
      "learning_rate": 0.06867067649064516,
      "loss": 0.8652,
      "step": 194320
    },
    {
      "epoch": 313.45,
      "learning_rate": 0.06866745068741936,
      "loss": 0.8579,
      "step": 194340
    },
    {
      "epoch": 313.48,
      "learning_rate": 0.06866422488419355,
      "loss": 0.8601,
      "step": 194360
    },
    {
      "epoch": 313.52,
      "learning_rate": 0.06866099908096775,
      "loss": 0.8493,
      "step": 194380
    },
    {
      "epoch": 313.55,
      "learning_rate": 0.06865777327774195,
      "loss": 0.8561,
      "step": 194400
    },
    {
      "epoch": 313.58,
      "learning_rate": 0.06865454747451613,
      "loss": 0.8643,
      "step": 194420
    },
    {
      "epoch": 313.61,
      "learning_rate": 0.06865132167129032,
      "loss": 0.8708,
      "step": 194440
    },
    {
      "epoch": 313.65,
      "learning_rate": 0.06864809586806453,
      "loss": 0.8464,
      "step": 194460
    },
    {
      "epoch": 313.68,
      "learning_rate": 0.06864487006483871,
      "loss": 0.8762,
      "step": 194480
    },
    {
      "epoch": 313.71,
      "learning_rate": 0.06864164426161291,
      "loss": 0.8625,
      "step": 194500
    },
    {
      "epoch": 313.74,
      "learning_rate": 0.0686384184583871,
      "loss": 0.8751,
      "step": 194520
    },
    {
      "epoch": 313.77,
      "learning_rate": 0.0686351926551613,
      "loss": 0.8576,
      "step": 194540
    },
    {
      "epoch": 313.81,
      "learning_rate": 0.06863196685193548,
      "loss": 0.8568,
      "step": 194560
    },
    {
      "epoch": 313.84,
      "learning_rate": 0.06862874104870968,
      "loss": 0.871,
      "step": 194580
    },
    {
      "epoch": 313.87,
      "learning_rate": 0.06862551524548388,
      "loss": 0.8871,
      "step": 194600
    },
    {
      "epoch": 313.9,
      "learning_rate": 0.06862228944225807,
      "loss": 0.8897,
      "step": 194620
    },
    {
      "epoch": 313.94,
      "learning_rate": 0.06861906363903227,
      "loss": 0.8895,
      "step": 194640
    },
    {
      "epoch": 313.97,
      "learning_rate": 0.06861583783580645,
      "loss": 0.8782,
      "step": 194660
    },
    {
      "epoch": 314.0,
      "learning_rate": 0.06861261203258065,
      "loss": 0.8493,
      "step": 194680
    },
    {
      "epoch": 314.0,
      "eval_accuracy": {
        "accuracy": 0.745453126219655
      },
      "eval_loss": 1.2262942790985107,
      "eval_runtime": 4.099,
      "eval_samples_per_second": 3125.372,
      "eval_steps_per_second": 49.036,
      "step": 194680
    },
    {
      "epoch": 314.03,
      "learning_rate": 0.06860938622935485,
      "loss": 0.8808,
      "step": 194700
    },
    {
      "epoch": 314.06,
      "learning_rate": 0.06860616042612903,
      "loss": 0.8594,
      "step": 194720
    },
    {
      "epoch": 314.1,
      "learning_rate": 0.06860293462290322,
      "loss": 0.8489,
      "step": 194740
    },
    {
      "epoch": 314.13,
      "learning_rate": 0.06859970881967743,
      "loss": 0.8332,
      "step": 194760
    },
    {
      "epoch": 314.16,
      "learning_rate": 0.06859648301645162,
      "loss": 0.8186,
      "step": 194780
    },
    {
      "epoch": 314.19,
      "learning_rate": 0.06859325721322582,
      "loss": 0.8326,
      "step": 194800
    },
    {
      "epoch": 314.23,
      "learning_rate": 0.06859003141,
      "loss": 0.85,
      "step": 194820
    },
    {
      "epoch": 314.26,
      "learning_rate": 0.0685868056067742,
      "loss": 0.8242,
      "step": 194840
    },
    {
      "epoch": 314.29,
      "learning_rate": 0.06858357980354839,
      "loss": 0.845,
      "step": 194860
    },
    {
      "epoch": 314.32,
      "learning_rate": 0.06858035400032259,
      "loss": 0.8556,
      "step": 194880
    },
    {
      "epoch": 314.35,
      "learning_rate": 0.06857712819709677,
      "loss": 0.857,
      "step": 194900
    },
    {
      "epoch": 314.39,
      "learning_rate": 0.06857390239387097,
      "loss": 0.8646,
      "step": 194920
    },
    {
      "epoch": 314.42,
      "learning_rate": 0.06857067659064517,
      "loss": 0.8467,
      "step": 194940
    },
    {
      "epoch": 314.45,
      "learning_rate": 0.06856745078741935,
      "loss": 0.8561,
      "step": 194960
    },
    {
      "epoch": 314.48,
      "learning_rate": 0.06856422498419355,
      "loss": 0.8469,
      "step": 194980
    },
    {
      "epoch": 314.52,
      "learning_rate": 0.06856099918096775,
      "loss": 0.8657,
      "step": 195000
    },
    {
      "epoch": 314.55,
      "learning_rate": 0.06855777337774194,
      "loss": 0.8643,
      "step": 195020
    },
    {
      "epoch": 314.58,
      "learning_rate": 0.06855454757451612,
      "loss": 0.8485,
      "step": 195040
    },
    {
      "epoch": 314.61,
      "learning_rate": 0.06855132177129034,
      "loss": 0.855,
      "step": 195060
    },
    {
      "epoch": 314.65,
      "learning_rate": 0.06854809596806452,
      "loss": 0.8447,
      "step": 195080
    },
    {
      "epoch": 314.68,
      "learning_rate": 0.06854487016483872,
      "loss": 0.8563,
      "step": 195100
    },
    {
      "epoch": 314.71,
      "learning_rate": 0.0685416443616129,
      "loss": 0.8668,
      "step": 195120
    },
    {
      "epoch": 314.74,
      "learning_rate": 0.0685384185583871,
      "loss": 0.8617,
      "step": 195140
    },
    {
      "epoch": 314.77,
      "learning_rate": 0.06853519275516129,
      "loss": 0.863,
      "step": 195160
    },
    {
      "epoch": 314.81,
      "learning_rate": 0.0685319669519355,
      "loss": 0.8715,
      "step": 195180
    },
    {
      "epoch": 314.84,
      "learning_rate": 0.06852874114870967,
      "loss": 0.8835,
      "step": 195200
    },
    {
      "epoch": 314.87,
      "learning_rate": 0.06852551534548387,
      "loss": 0.8756,
      "step": 195220
    },
    {
      "epoch": 314.9,
      "learning_rate": 0.06852228954225807,
      "loss": 0.8564,
      "step": 195240
    },
    {
      "epoch": 314.94,
      "learning_rate": 0.06851906373903226,
      "loss": 0.84,
      "step": 195260
    },
    {
      "epoch": 314.97,
      "learning_rate": 0.06851583793580646,
      "loss": 0.8388,
      "step": 195280
    },
    {
      "epoch": 315.0,
      "learning_rate": 0.06851261213258066,
      "loss": 0.8452,
      "step": 195300
    },
    {
      "epoch": 315.0,
      "eval_accuracy": {
        "accuracy": 0.7499024276012801
      },
      "eval_loss": 1.235155701637268,
      "eval_runtime": 2.666,
      "eval_samples_per_second": 4805.259,
      "eval_steps_per_second": 75.393,
      "step": 195300
    },
    {
      "epoch": 315.03,
      "learning_rate": 0.06850938632935484,
      "loss": 0.8672,
      "step": 195320
    },
    {
      "epoch": 315.06,
      "learning_rate": 0.06850616052612903,
      "loss": 0.8592,
      "step": 195340
    },
    {
      "epoch": 315.1,
      "learning_rate": 0.06850293472290324,
      "loss": 0.8478,
      "step": 195360
    },
    {
      "epoch": 315.13,
      "learning_rate": 0.06849970891967742,
      "loss": 0.8157,
      "step": 195380
    },
    {
      "epoch": 315.16,
      "learning_rate": 0.06849648311645162,
      "loss": 0.7992,
      "step": 195400
    },
    {
      "epoch": 315.19,
      "learning_rate": 0.06849325731322581,
      "loss": 0.8115,
      "step": 195420
    },
    {
      "epoch": 315.23,
      "learning_rate": 0.06849003151000001,
      "loss": 0.8347,
      "step": 195440
    },
    {
      "epoch": 315.26,
      "learning_rate": 0.06848680570677419,
      "loss": 0.8456,
      "step": 195460
    },
    {
      "epoch": 315.29,
      "learning_rate": 0.0684835799035484,
      "loss": 0.8699,
      "step": 195480
    },
    {
      "epoch": 315.32,
      "learning_rate": 0.06848035410032258,
      "loss": 0.852,
      "step": 195500
    },
    {
      "epoch": 315.35,
      "learning_rate": 0.06847712829709678,
      "loss": 0.8799,
      "step": 195520
    },
    {
      "epoch": 315.39,
      "learning_rate": 0.06847390249387098,
      "loss": 0.8475,
      "step": 195540
    },
    {
      "epoch": 315.42,
      "learning_rate": 0.06847067669064516,
      "loss": 0.8525,
      "step": 195560
    },
    {
      "epoch": 315.45,
      "learning_rate": 0.06846745088741936,
      "loss": 0.8359,
      "step": 195580
    },
    {
      "epoch": 315.48,
      "learning_rate": 0.06846422508419356,
      "loss": 0.8647,
      "step": 195600
    },
    {
      "epoch": 315.52,
      "learning_rate": 0.06846099928096774,
      "loss": 0.8807,
      "step": 195620
    },
    {
      "epoch": 315.55,
      "learning_rate": 0.06845777347774194,
      "loss": 0.8721,
      "step": 195640
    },
    {
      "epoch": 315.58,
      "learning_rate": 0.06845454767451614,
      "loss": 0.8281,
      "step": 195660
    },
    {
      "epoch": 315.61,
      "learning_rate": 0.06845132187129031,
      "loss": 0.8625,
      "step": 195680
    },
    {
      "epoch": 315.65,
      "learning_rate": 0.06844809606806453,
      "loss": 0.8516,
      "step": 195700
    },
    {
      "epoch": 315.68,
      "learning_rate": 0.06844487026483871,
      "loss": 0.8592,
      "step": 195720
    },
    {
      "epoch": 315.71,
      "learning_rate": 0.06844164446161291,
      "loss": 0.8828,
      "step": 195740
    },
    {
      "epoch": 315.74,
      "learning_rate": 0.0684384186583871,
      "loss": 0.8377,
      "step": 195760
    },
    {
      "epoch": 315.77,
      "learning_rate": 0.06843519285516131,
      "loss": 0.856,
      "step": 195780
    },
    {
      "epoch": 315.81,
      "learning_rate": 0.06843196705193548,
      "loss": 0.8631,
      "step": 195800
    },
    {
      "epoch": 315.84,
      "learning_rate": 0.06842874124870968,
      "loss": 0.9082,
      "step": 195820
    },
    {
      "epoch": 315.87,
      "learning_rate": 0.06842551544548388,
      "loss": 0.8607,
      "step": 195840
    },
    {
      "epoch": 315.9,
      "learning_rate": 0.06842228964225806,
      "loss": 0.8716,
      "step": 195860
    },
    {
      "epoch": 315.94,
      "learning_rate": 0.06841906383903226,
      "loss": 0.8418,
      "step": 195880
    },
    {
      "epoch": 315.97,
      "learning_rate": 0.06841583803580646,
      "loss": 0.8607,
      "step": 195900
    },
    {
      "epoch": 316.0,
      "learning_rate": 0.06841277352274194,
      "loss": 0.8312,
      "step": 195920
    },
    {
      "epoch": 316.0,
      "eval_accuracy": {
        "accuracy": 0.756459292795254
      },
      "eval_loss": 1.1991626024246216,
      "eval_runtime": 3.0563,
      "eval_samples_per_second": 4191.621,
      "eval_steps_per_second": 65.765,
      "step": 195920
    },
    {
      "epoch": 316.03,
      "learning_rate": 0.06840954771951613,
      "loss": 0.8323,
      "step": 195940
    },
    {
      "epoch": 316.06,
      "learning_rate": 0.06840632191629033,
      "loss": 0.8364,
      "step": 195960
    },
    {
      "epoch": 316.1,
      "learning_rate": 0.06840309611306451,
      "loss": 0.8291,
      "step": 195980
    },
    {
      "epoch": 316.13,
      "learning_rate": 0.06839987030983871,
      "loss": 0.8329,
      "step": 196000
    },
    {
      "epoch": 316.16,
      "learning_rate": 0.06839664450661291,
      "loss": 0.8311,
      "step": 196020
    },
    {
      "epoch": 316.19,
      "learning_rate": 0.0683934187033871,
      "loss": 0.833,
      "step": 196040
    },
    {
      "epoch": 316.23,
      "learning_rate": 0.0683901929001613,
      "loss": 0.8637,
      "step": 196060
    },
    {
      "epoch": 316.26,
      "learning_rate": 0.0683869670969355,
      "loss": 0.8592,
      "step": 196080
    },
    {
      "epoch": 316.29,
      "learning_rate": 0.06838374129370968,
      "loss": 0.8606,
      "step": 196100
    },
    {
      "epoch": 316.32,
      "learning_rate": 0.06838051549048386,
      "loss": 0.8591,
      "step": 196120
    },
    {
      "epoch": 316.35,
      "learning_rate": 0.06837728968725808,
      "loss": 0.8652,
      "step": 196140
    },
    {
      "epoch": 316.39,
      "learning_rate": 0.06837406388403226,
      "loss": 0.8265,
      "step": 196160
    },
    {
      "epoch": 316.42,
      "learning_rate": 0.06837083808080646,
      "loss": 0.8724,
      "step": 196180
    },
    {
      "epoch": 316.45,
      "learning_rate": 0.06836761227758065,
      "loss": 0.8846,
      "step": 196200
    },
    {
      "epoch": 316.48,
      "learning_rate": 0.06836438647435485,
      "loss": 0.8475,
      "step": 196220
    },
    {
      "epoch": 316.52,
      "learning_rate": 0.06836116067112903,
      "loss": 0.8284,
      "step": 196240
    },
    {
      "epoch": 316.55,
      "learning_rate": 0.06835793486790323,
      "loss": 0.816,
      "step": 196260
    },
    {
      "epoch": 316.58,
      "learning_rate": 0.06835470906467742,
      "loss": 0.8343,
      "step": 196280
    },
    {
      "epoch": 316.61,
      "learning_rate": 0.06835148326145161,
      "loss": 0.8532,
      "step": 196300
    },
    {
      "epoch": 316.65,
      "learning_rate": 0.06834825745822581,
      "loss": 0.8566,
      "step": 196320
    },
    {
      "epoch": 316.68,
      "learning_rate": 0.068345031655,
      "loss": 0.8347,
      "step": 196340
    },
    {
      "epoch": 316.71,
      "learning_rate": 0.0683418058517742,
      "loss": 0.8431,
      "step": 196360
    },
    {
      "epoch": 316.74,
      "learning_rate": 0.0683385800485484,
      "loss": 0.8736,
      "step": 196380
    },
    {
      "epoch": 316.77,
      "learning_rate": 0.06833535424532258,
      "loss": 0.8563,
      "step": 196400
    },
    {
      "epoch": 316.81,
      "learning_rate": 0.06833212844209677,
      "loss": 0.8553,
      "step": 196420
    },
    {
      "epoch": 316.84,
      "learning_rate": 0.06832890263887098,
      "loss": 0.8542,
      "step": 196440
    },
    {
      "epoch": 316.87,
      "learning_rate": 0.06832567683564517,
      "loss": 0.9009,
      "step": 196460
    },
    {
      "epoch": 316.9,
      "learning_rate": 0.06832245103241937,
      "loss": 0.8771,
      "step": 196480
    },
    {
      "epoch": 316.94,
      "learning_rate": 0.06831922522919355,
      "loss": 0.8836,
      "step": 196500
    },
    {
      "epoch": 316.97,
      "learning_rate": 0.06831599942596775,
      "loss": 0.859,
      "step": 196520
    },
    {
      "epoch": 317.0,
      "learning_rate": 0.06831277362274193,
      "loss": 0.8708,
      "step": 196540
    },
    {
      "epoch": 317.0,
      "eval_accuracy": {
        "accuracy": 0.7438919678401373
      },
      "eval_loss": 1.2439771890640259,
      "eval_runtime": 2.7535,
      "eval_samples_per_second": 4652.595,
      "eval_steps_per_second": 72.998,
      "step": 196540
    },
    {
      "epoch": 317.03,
      "learning_rate": 0.06830954781951615,
      "loss": 0.8852,
      "step": 196560
    },
    {
      "epoch": 317.06,
      "learning_rate": 0.06830632201629032,
      "loss": 0.8437,
      "step": 196580
    },
    {
      "epoch": 317.1,
      "learning_rate": 0.06830309621306452,
      "loss": 0.8428,
      "step": 196600
    },
    {
      "epoch": 317.13,
      "learning_rate": 0.06829987040983872,
      "loss": 0.8485,
      "step": 196620
    },
    {
      "epoch": 317.16,
      "learning_rate": 0.0682966446066129,
      "loss": 0.8314,
      "step": 196640
    },
    {
      "epoch": 317.19,
      "learning_rate": 0.0682934188033871,
      "loss": 0.838,
      "step": 196660
    },
    {
      "epoch": 317.23,
      "learning_rate": 0.0682901930001613,
      "loss": 0.8397,
      "step": 196680
    },
    {
      "epoch": 317.26,
      "learning_rate": 0.06828696719693549,
      "loss": 0.8517,
      "step": 196700
    },
    {
      "epoch": 317.29,
      "learning_rate": 0.06828374139370968,
      "loss": 0.8542,
      "step": 196720
    },
    {
      "epoch": 317.32,
      "learning_rate": 0.06828051559048388,
      "loss": 0.8457,
      "step": 196740
    },
    {
      "epoch": 317.35,
      "learning_rate": 0.06827728978725806,
      "loss": 0.8203,
      "step": 196760
    },
    {
      "epoch": 317.39,
      "learning_rate": 0.06827406398403227,
      "loss": 0.7899,
      "step": 196780
    },
    {
      "epoch": 317.42,
      "learning_rate": 0.06827083818080645,
      "loss": 0.8433,
      "step": 196800
    },
    {
      "epoch": 317.45,
      "learning_rate": 0.06826761237758065,
      "loss": 0.8191,
      "step": 196820
    },
    {
      "epoch": 317.48,
      "learning_rate": 0.06826438657435484,
      "loss": 0.8257,
      "step": 196840
    },
    {
      "epoch": 317.52,
      "learning_rate": 0.06826116077112905,
      "loss": 0.8249,
      "step": 196860
    },
    {
      "epoch": 317.55,
      "learning_rate": 0.06825793496790322,
      "loss": 0.8271,
      "step": 196880
    },
    {
      "epoch": 317.58,
      "learning_rate": 0.06825470916467742,
      "loss": 0.8592,
      "step": 196900
    },
    {
      "epoch": 317.61,
      "learning_rate": 0.06825148336145162,
      "loss": 0.855,
      "step": 196920
    },
    {
      "epoch": 317.65,
      "learning_rate": 0.0682482575582258,
      "loss": 0.8588,
      "step": 196940
    },
    {
      "epoch": 317.68,
      "learning_rate": 0.068245031755,
      "loss": 0.8592,
      "step": 196960
    },
    {
      "epoch": 317.71,
      "learning_rate": 0.0682418059517742,
      "loss": 0.8433,
      "step": 196980
    },
    {
      "epoch": 317.74,
      "learning_rate": 0.06823858014854839,
      "loss": 0.8639,
      "step": 197000
    },
    {
      "epoch": 317.77,
      "learning_rate": 0.06823535434532259,
      "loss": 0.8581,
      "step": 197020
    },
    {
      "epoch": 317.81,
      "learning_rate": 0.06823212854209679,
      "loss": 0.8806,
      "step": 197040
    },
    {
      "epoch": 317.84,
      "learning_rate": 0.06822890273887096,
      "loss": 0.8697,
      "step": 197060
    },
    {
      "epoch": 317.87,
      "learning_rate": 0.06822567693564517,
      "loss": 0.9,
      "step": 197080
    },
    {
      "epoch": 317.9,
      "learning_rate": 0.06822245113241936,
      "loss": 0.8701,
      "step": 197100
    },
    {
      "epoch": 317.94,
      "learning_rate": 0.06821922532919356,
      "loss": 0.9034,
      "step": 197120
    },
    {
      "epoch": 317.97,
      "learning_rate": 0.06821599952596774,
      "loss": 0.8776,
      "step": 197140
    },
    {
      "epoch": 318.0,
      "learning_rate": 0.06821277372274195,
      "loss": 0.8535,
      "step": 197160
    },
    {
      "epoch": 318.0,
      "eval_accuracy": {
        "accuracy": 0.7515416438997736
      },
      "eval_loss": 1.22243332862854,
      "eval_runtime": 2.8158,
      "eval_samples_per_second": 4549.634,
      "eval_steps_per_second": 71.382,
      "step": 197160
    },
    {
      "epoch": 318.03,
      "learning_rate": 0.06820954791951613,
      "loss": 0.8887,
      "step": 197180
    },
    {
      "epoch": 318.06,
      "learning_rate": 0.06820632211629032,
      "loss": 0.8481,
      "step": 197200
    },
    {
      "epoch": 318.1,
      "learning_rate": 0.06820309631306452,
      "loss": 0.8347,
      "step": 197220
    },
    {
      "epoch": 318.13,
      "learning_rate": 0.06819987050983871,
      "loss": 0.8301,
      "step": 197240
    },
    {
      "epoch": 318.16,
      "learning_rate": 0.06819664470661291,
      "loss": 0.8368,
      "step": 197260
    },
    {
      "epoch": 318.19,
      "learning_rate": 0.0681934189033871,
      "loss": 0.853,
      "step": 197280
    },
    {
      "epoch": 318.23,
      "learning_rate": 0.06819019310016129,
      "loss": 0.8553,
      "step": 197300
    },
    {
      "epoch": 318.26,
      "learning_rate": 0.06818696729693549,
      "loss": 0.8106,
      "step": 197320
    },
    {
      "epoch": 318.29,
      "learning_rate": 0.06818374149370969,
      "loss": 0.8379,
      "step": 197340
    },
    {
      "epoch": 318.32,
      "learning_rate": 0.06818051569048386,
      "loss": 0.8425,
      "step": 197360
    },
    {
      "epoch": 318.35,
      "learning_rate": 0.06817728988725807,
      "loss": 0.8432,
      "step": 197380
    },
    {
      "epoch": 318.39,
      "learning_rate": 0.06817406408403226,
      "loss": 0.87,
      "step": 197400
    },
    {
      "epoch": 318.42,
      "learning_rate": 0.06817083828080646,
      "loss": 0.865,
      "step": 197420
    },
    {
      "epoch": 318.45,
      "learning_rate": 0.06816761247758064,
      "loss": 0.8617,
      "step": 197440
    },
    {
      "epoch": 318.48,
      "learning_rate": 0.06816438667435486,
      "loss": 0.843,
      "step": 197460
    },
    {
      "epoch": 318.52,
      "learning_rate": 0.06816116087112903,
      "loss": 0.8361,
      "step": 197480
    },
    {
      "epoch": 318.55,
      "learning_rate": 0.06815793506790324,
      "loss": 0.8596,
      "step": 197500
    },
    {
      "epoch": 318.58,
      "learning_rate": 0.06815470926467743,
      "loss": 0.8739,
      "step": 197520
    },
    {
      "epoch": 318.61,
      "learning_rate": 0.06815148346145161,
      "loss": 0.881,
      "step": 197540
    },
    {
      "epoch": 318.65,
      "learning_rate": 0.06814825765822581,
      "loss": 0.8492,
      "step": 197560
    },
    {
      "epoch": 318.68,
      "learning_rate": 0.06814503185500001,
      "loss": 0.8575,
      "step": 197580
    },
    {
      "epoch": 318.71,
      "learning_rate": 0.0681418060517742,
      "loss": 0.8512,
      "step": 197600
    },
    {
      "epoch": 318.74,
      "learning_rate": 0.0681385802485484,
      "loss": 0.885,
      "step": 197620
    },
    {
      "epoch": 318.77,
      "learning_rate": 0.0681353544453226,
      "loss": 0.8616,
      "step": 197640
    },
    {
      "epoch": 318.81,
      "learning_rate": 0.06813212864209676,
      "loss": 0.8833,
      "step": 197660
    },
    {
      "epoch": 318.84,
      "learning_rate": 0.06812890283887098,
      "loss": 0.8735,
      "step": 197680
    },
    {
      "epoch": 318.87,
      "learning_rate": 0.06812567703564516,
      "loss": 0.862,
      "step": 197700
    },
    {
      "epoch": 318.9,
      "learning_rate": 0.06812245123241936,
      "loss": 0.8696,
      "step": 197720
    },
    {
      "epoch": 318.94,
      "learning_rate": 0.06811922542919355,
      "loss": 0.8469,
      "step": 197740
    },
    {
      "epoch": 318.97,
      "learning_rate": 0.06811599962596775,
      "loss": 0.8674,
      "step": 197760
    },
    {
      "epoch": 319.0,
      "learning_rate": 0.06811277382274193,
      "loss": 0.84,
      "step": 197780
    },
    {
      "epoch": 319.0,
      "eval_accuracy": {
        "accuracy": 0.7505268909530872
      },
      "eval_loss": 1.2305973768234253,
      "eval_runtime": 3.0063,
      "eval_samples_per_second": 4261.434,
      "eval_steps_per_second": 66.86,
      "step": 197780
    },
    {
      "epoch": 319.03,
      "learning_rate": 0.06810954801951614,
      "loss": 0.8885,
      "step": 197800
    },
    {
      "epoch": 319.06,
      "learning_rate": 0.06810632221629033,
      "loss": 0.8276,
      "step": 197820
    },
    {
      "epoch": 319.1,
      "learning_rate": 0.06810309641306452,
      "loss": 0.8566,
      "step": 197840
    },
    {
      "epoch": 319.13,
      "learning_rate": 0.06809987060983871,
      "loss": 0.8327,
      "step": 197860
    },
    {
      "epoch": 319.16,
      "learning_rate": 0.06809664480661291,
      "loss": 0.8535,
      "step": 197880
    },
    {
      "epoch": 319.19,
      "learning_rate": 0.0680934190033871,
      "loss": 0.835,
      "step": 197900
    },
    {
      "epoch": 319.23,
      "learning_rate": 0.0680901932001613,
      "loss": 0.8374,
      "step": 197920
    },
    {
      "epoch": 319.26,
      "learning_rate": 0.0680869673969355,
      "loss": 0.8274,
      "step": 197940
    },
    {
      "epoch": 319.29,
      "learning_rate": 0.06808374159370968,
      "loss": 0.8185,
      "step": 197960
    },
    {
      "epoch": 319.32,
      "learning_rate": 0.06808051579048388,
      "loss": 0.8218,
      "step": 197980
    },
    {
      "epoch": 319.35,
      "learning_rate": 0.06807728998725807,
      "loss": 0.8332,
      "step": 198000
    },
    {
      "epoch": 319.39,
      "learning_rate": 0.06807406418403227,
      "loss": 0.7977,
      "step": 198020
    },
    {
      "epoch": 319.42,
      "learning_rate": 0.06807083838080645,
      "loss": 0.8607,
      "step": 198040
    },
    {
      "epoch": 319.45,
      "learning_rate": 0.06806761257758065,
      "loss": 0.8624,
      "step": 198060
    },
    {
      "epoch": 319.48,
      "learning_rate": 0.06806438677435483,
      "loss": 0.8475,
      "step": 198080
    },
    {
      "epoch": 319.52,
      "learning_rate": 0.06806116097112905,
      "loss": 0.8502,
      "step": 198100
    },
    {
      "epoch": 319.55,
      "learning_rate": 0.06805793516790323,
      "loss": 0.8695,
      "step": 198120
    },
    {
      "epoch": 319.58,
      "learning_rate": 0.06805470936467742,
      "loss": 0.8504,
      "step": 198140
    },
    {
      "epoch": 319.61,
      "learning_rate": 0.06805148356145162,
      "loss": 0.8565,
      "step": 198160
    },
    {
      "epoch": 319.65,
      "learning_rate": 0.06804825775822582,
      "loss": 0.8787,
      "step": 198180
    },
    {
      "epoch": 319.68,
      "learning_rate": 0.068045031955,
      "loss": 0.8502,
      "step": 198200
    },
    {
      "epoch": 319.71,
      "learning_rate": 0.0680418061517742,
      "loss": 0.8483,
      "step": 198220
    },
    {
      "epoch": 319.74,
      "learning_rate": 0.0680385803485484,
      "loss": 0.8613,
      "step": 198240
    },
    {
      "epoch": 319.77,
      "learning_rate": 0.06803535454532258,
      "loss": 0.8483,
      "step": 198260
    },
    {
      "epoch": 319.81,
      "learning_rate": 0.06803212874209678,
      "loss": 0.8535,
      "step": 198280
    },
    {
      "epoch": 319.84,
      "learning_rate": 0.06802890293887097,
      "loss": 0.8735,
      "step": 198300
    },
    {
      "epoch": 319.87,
      "learning_rate": 0.06802567713564517,
      "loss": 0.8766,
      "step": 198320
    },
    {
      "epoch": 319.9,
      "learning_rate": 0.06802245133241935,
      "loss": 0.8506,
      "step": 198340
    },
    {
      "epoch": 319.94,
      "learning_rate": 0.06801922552919355,
      "loss": 0.8551,
      "step": 198360
    },
    {
      "epoch": 319.97,
      "learning_rate": 0.06801599972596774,
      "loss": 0.8328,
      "step": 198380
    },
    {
      "epoch": 320.0,
      "learning_rate": 0.06801293521290323,
      "loss": 0.8364,
      "step": 198400
    },
    {
      "epoch": 320.0,
      "eval_accuracy": {
        "accuracy": 0.7528686285223636
      },
      "eval_loss": 1.2045249938964844,
      "eval_runtime": 2.722,
      "eval_samples_per_second": 4706.514,
      "eval_steps_per_second": 73.844,
      "step": 198400
    },
    {
      "epoch": 320.03,
      "learning_rate": 0.06800970940967743,
      "loss": 0.8345,
      "step": 198420
    },
    {
      "epoch": 320.06,
      "learning_rate": 0.0680064836064516,
      "loss": 0.8228,
      "step": 198440
    },
    {
      "epoch": 320.1,
      "learning_rate": 0.06800325780322582,
      "loss": 0.8292,
      "step": 198460
    },
    {
      "epoch": 320.13,
      "learning_rate": 0.068000032,
      "loss": 0.8383,
      "step": 198480
    },
    {
      "epoch": 320.16,
      "learning_rate": 0.0679968061967742,
      "loss": 0.845,
      "step": 198500
    },
    {
      "epoch": 320.19,
      "learning_rate": 0.06799358039354839,
      "loss": 0.8381,
      "step": 198520
    },
    {
      "epoch": 320.23,
      "learning_rate": 0.0679903545903226,
      "loss": 0.828,
      "step": 198540
    },
    {
      "epoch": 320.26,
      "learning_rate": 0.06798712878709677,
      "loss": 0.8295,
      "step": 198560
    },
    {
      "epoch": 320.29,
      "learning_rate": 0.06798390298387097,
      "loss": 0.8197,
      "step": 198580
    },
    {
      "epoch": 320.32,
      "learning_rate": 0.06798067718064517,
      "loss": 0.849,
      "step": 198600
    },
    {
      "epoch": 320.35,
      "learning_rate": 0.06797745137741935,
      "loss": 0.843,
      "step": 198620
    },
    {
      "epoch": 320.39,
      "learning_rate": 0.06797422557419355,
      "loss": 0.8532,
      "step": 198640
    },
    {
      "epoch": 320.42,
      "learning_rate": 0.06797099977096775,
      "loss": 0.8357,
      "step": 198660
    },
    {
      "epoch": 320.45,
      "learning_rate": 0.06796777396774194,
      "loss": 0.8385,
      "step": 198680
    },
    {
      "epoch": 320.48,
      "learning_rate": 0.06796454816451614,
      "loss": 0.8544,
      "step": 198700
    },
    {
      "epoch": 320.52,
      "learning_rate": 0.06796132236129034,
      "loss": 0.8702,
      "step": 198720
    },
    {
      "epoch": 320.55,
      "learning_rate": 0.0679580965580645,
      "loss": 0.831,
      "step": 198740
    },
    {
      "epoch": 320.58,
      "learning_rate": 0.06795487075483872,
      "loss": 0.8609,
      "step": 198760
    },
    {
      "epoch": 320.61,
      "learning_rate": 0.0679516449516129,
      "loss": 0.8525,
      "step": 198780
    },
    {
      "epoch": 320.65,
      "learning_rate": 0.0679484191483871,
      "loss": 0.8898,
      "step": 198800
    },
    {
      "epoch": 320.68,
      "learning_rate": 0.06794519334516129,
      "loss": 0.8718,
      "step": 198820
    },
    {
      "epoch": 320.71,
      "learning_rate": 0.06794196754193549,
      "loss": 0.8723,
      "step": 198840
    },
    {
      "epoch": 320.74,
      "learning_rate": 0.06793874173870967,
      "loss": 0.8435,
      "step": 198860
    },
    {
      "epoch": 320.77,
      "learning_rate": 0.06793551593548389,
      "loss": 0.8495,
      "step": 198880
    },
    {
      "epoch": 320.81,
      "learning_rate": 0.06793229013225807,
      "loss": 0.8682,
      "step": 198900
    },
    {
      "epoch": 320.84,
      "learning_rate": 0.06792906432903226,
      "loss": 0.8331,
      "step": 198920
    },
    {
      "epoch": 320.87,
      "learning_rate": 0.06792583852580646,
      "loss": 0.8533,
      "step": 198940
    },
    {
      "epoch": 320.9,
      "learning_rate": 0.06792261272258066,
      "loss": 0.8431,
      "step": 198960
    },
    {
      "epoch": 320.94,
      "learning_rate": 0.06791938691935484,
      "loss": 0.8754,
      "step": 198980
    },
    {
      "epoch": 320.97,
      "learning_rate": 0.06791616111612904,
      "loss": 0.8729,
      "step": 199000
    },
    {
      "epoch": 321.0,
      "learning_rate": 0.06791293531290324,
      "loss": 0.8448,
      "step": 199020
    },
    {
      "epoch": 321.0,
      "eval_accuracy": {
        "accuracy": 0.7479509796268832
      },
      "eval_loss": 1.2344071865081787,
      "eval_runtime": 2.9711,
      "eval_samples_per_second": 4311.937,
      "eval_steps_per_second": 67.653,
      "step": 199020
    },
    {
      "epoch": 321.03,
      "learning_rate": 0.06790970950967742,
      "loss": 0.8623,
      "step": 199040
    },
    {
      "epoch": 321.06,
      "learning_rate": 0.06790648370645162,
      "loss": 0.8279,
      "step": 199060
    },
    {
      "epoch": 321.1,
      "learning_rate": 0.06790325790322581,
      "loss": 0.849,
      "step": 199080
    },
    {
      "epoch": 321.13,
      "learning_rate": 0.06790003210000001,
      "loss": 0.8363,
      "step": 199100
    },
    {
      "epoch": 321.16,
      "learning_rate": 0.06789680629677419,
      "loss": 0.85,
      "step": 199120
    },
    {
      "epoch": 321.19,
      "learning_rate": 0.06789358049354839,
      "loss": 0.8274,
      "step": 199140
    },
    {
      "epoch": 321.23,
      "learning_rate": 0.06789035469032258,
      "loss": 0.821,
      "step": 199160
    },
    {
      "epoch": 321.26,
      "learning_rate": 0.06788712888709679,
      "loss": 0.8441,
      "step": 199180
    },
    {
      "epoch": 321.29,
      "learning_rate": 0.06788390308387098,
      "loss": 0.8418,
      "step": 199200
    },
    {
      "epoch": 321.32,
      "learning_rate": 0.06788067728064516,
      "loss": 0.8473,
      "step": 199220
    },
    {
      "epoch": 321.35,
      "learning_rate": 0.06787745147741936,
      "loss": 0.8509,
      "step": 199240
    },
    {
      "epoch": 321.39,
      "learning_rate": 0.06787422567419356,
      "loss": 0.8411,
      "step": 199260
    },
    {
      "epoch": 321.42,
      "learning_rate": 0.06787099987096774,
      "loss": 0.8515,
      "step": 199280
    },
    {
      "epoch": 321.45,
      "learning_rate": 0.06786777406774194,
      "loss": 0.8403,
      "step": 199300
    },
    {
      "epoch": 321.48,
      "learning_rate": 0.06786454826451614,
      "loss": 0.8441,
      "step": 199320
    },
    {
      "epoch": 321.52,
      "learning_rate": 0.06786132246129033,
      "loss": 0.8421,
      "step": 199340
    },
    {
      "epoch": 321.55,
      "learning_rate": 0.06785809665806453,
      "loss": 0.8759,
      "step": 199360
    },
    {
      "epoch": 321.58,
      "learning_rate": 0.06785487085483871,
      "loss": 0.8578,
      "step": 199380
    },
    {
      "epoch": 321.61,
      "learning_rate": 0.06785164505161291,
      "loss": 0.8656,
      "step": 199400
    },
    {
      "epoch": 321.65,
      "learning_rate": 0.0678484192483871,
      "loss": 0.8538,
      "step": 199420
    },
    {
      "epoch": 321.68,
      "learning_rate": 0.0678451934451613,
      "loss": 0.8736,
      "step": 199440
    },
    {
      "epoch": 321.71,
      "learning_rate": 0.06784196764193548,
      "loss": 0.8456,
      "step": 199460
    },
    {
      "epoch": 321.74,
      "learning_rate": 0.06783874183870969,
      "loss": 0.8488,
      "step": 199480
    },
    {
      "epoch": 321.77,
      "learning_rate": 0.06783551603548388,
      "loss": 0.8701,
      "step": 199500
    },
    {
      "epoch": 321.81,
      "learning_rate": 0.06783229023225806,
      "loss": 0.8828,
      "step": 199520
    },
    {
      "epoch": 321.84,
      "learning_rate": 0.06782906442903226,
      "loss": 0.8484,
      "step": 199540
    },
    {
      "epoch": 321.87,
      "learning_rate": 0.06782583862580646,
      "loss": 0.8786,
      "step": 199560
    },
    {
      "epoch": 321.9,
      "learning_rate": 0.06782261282258065,
      "loss": 0.8532,
      "step": 199580
    },
    {
      "epoch": 321.94,
      "learning_rate": 0.06781938701935485,
      "loss": 0.8719,
      "step": 199600
    },
    {
      "epoch": 321.97,
      "learning_rate": 0.06781616121612905,
      "loss": 0.8472,
      "step": 199620
    },
    {
      "epoch": 322.0,
      "learning_rate": 0.06781293541290323,
      "loss": 0.8486,
      "step": 199640
    },
    {
      "epoch": 322.0,
      "eval_accuracy": {
        "accuracy": 0.7450628366247756
      },
      "eval_loss": 1.270404577255249,
      "eval_runtime": 2.8224,
      "eval_samples_per_second": 4538.997,
      "eval_steps_per_second": 71.215,
      "step": 199640
    },
    {
      "epoch": 322.03,
      "learning_rate": 0.06780970960967743,
      "loss": 0.921,
      "step": 199660
    },
    {
      "epoch": 322.06,
      "learning_rate": 0.06780648380645161,
      "loss": 0.8587,
      "step": 199680
    },
    {
      "epoch": 322.1,
      "learning_rate": 0.06780325800322581,
      "loss": 0.8255,
      "step": 199700
    },
    {
      "epoch": 322.13,
      "learning_rate": 0.0678000322,
      "loss": 0.8385,
      "step": 199720
    },
    {
      "epoch": 322.16,
      "learning_rate": 0.0677968063967742,
      "loss": 0.8508,
      "step": 199740
    },
    {
      "epoch": 322.19,
      "learning_rate": 0.06779358059354838,
      "loss": 0.8569,
      "step": 199760
    },
    {
      "epoch": 322.23,
      "learning_rate": 0.0677903547903226,
      "loss": 0.8614,
      "step": 199780
    },
    {
      "epoch": 322.26,
      "learning_rate": 0.06778712898709678,
      "loss": 0.8288,
      "step": 199800
    },
    {
      "epoch": 322.29,
      "learning_rate": 0.06778390318387098,
      "loss": 0.835,
      "step": 199820
    },
    {
      "epoch": 322.32,
      "learning_rate": 0.06778067738064517,
      "loss": 0.8478,
      "step": 199840
    },
    {
      "epoch": 322.35,
      "learning_rate": 0.06777745157741936,
      "loss": 0.8496,
      "step": 199860
    },
    {
      "epoch": 322.39,
      "learning_rate": 0.06777422577419355,
      "loss": 0.8361,
      "step": 199880
    },
    {
      "epoch": 322.42,
      "learning_rate": 0.06777099997096775,
      "loss": 0.8529,
      "step": 199900
    },
    {
      "epoch": 322.45,
      "learning_rate": 0.06776777416774193,
      "loss": 0.8326,
      "step": 199920
    },
    {
      "epoch": 322.48,
      "learning_rate": 0.06776454836451613,
      "loss": 0.8414,
      "step": 199940
    },
    {
      "epoch": 322.52,
      "learning_rate": 0.06776132256129033,
      "loss": 0.8245,
      "step": 199960
    },
    {
      "epoch": 322.55,
      "learning_rate": 0.06775809675806452,
      "loss": 0.8695,
      "step": 199980
    },
    {
      "epoch": 322.58,
      "learning_rate": 0.06775487095483872,
      "loss": 0.846,
      "step": 200000
    },
    {
      "epoch": 322.61,
      "learning_rate": 0.0677516451516129,
      "loss": 0.8078,
      "step": 200020
    },
    {
      "epoch": 322.65,
      "learning_rate": 0.0677484193483871,
      "loss": 0.8358,
      "step": 200040
    },
    {
      "epoch": 322.68,
      "learning_rate": 0.06774519354516129,
      "loss": 0.8359,
      "step": 200060
    },
    {
      "epoch": 322.71,
      "learning_rate": 0.0677419677419355,
      "loss": 0.8379,
      "step": 200080
    },
    {
      "epoch": 322.74,
      "learning_rate": 0.06773874193870968,
      "loss": 0.8384,
      "step": 200100
    },
    {
      "epoch": 322.77,
      "learning_rate": 0.06773551613548388,
      "loss": 0.8477,
      "step": 200120
    },
    {
      "epoch": 322.81,
      "learning_rate": 0.06773229033225807,
      "loss": 0.8358,
      "step": 200140
    },
    {
      "epoch": 322.84,
      "learning_rate": 0.06772906452903225,
      "loss": 0.8409,
      "step": 200160
    },
    {
      "epoch": 322.87,
      "learning_rate": 0.06772583872580645,
      "loss": 0.8265,
      "step": 200180
    },
    {
      "epoch": 322.9,
      "learning_rate": 0.06772261292258065,
      "loss": 0.8429,
      "step": 200200
    },
    {
      "epoch": 322.94,
      "learning_rate": 0.06771938711935484,
      "loss": 0.8596,
      "step": 200220
    },
    {
      "epoch": 322.97,
      "learning_rate": 0.06771616131612904,
      "loss": 0.8573,
      "step": 200240
    },
    {
      "epoch": 323.0,
      "learning_rate": 0.06771293551290324,
      "loss": 0.8341,
      "step": 200260
    },
    {
      "epoch": 323.0,
      "eval_accuracy": {
        "accuracy": 0.7490437904925454
      },
      "eval_loss": 1.2093896865844727,
      "eval_runtime": 2.8364,
      "eval_samples_per_second": 4516.695,
      "eval_steps_per_second": 70.865,
      "step": 200260
    },
    {
      "epoch": 323.03,
      "learning_rate": 0.06770970970967742,
      "loss": 0.8759,
      "step": 200280
    },
    {
      "epoch": 323.06,
      "learning_rate": 0.06770648390645162,
      "loss": 0.8391,
      "step": 200300
    },
    {
      "epoch": 323.1,
      "learning_rate": 0.0677032581032258,
      "loss": 0.8531,
      "step": 200320
    },
    {
      "epoch": 323.13,
      "learning_rate": 0.0677000323,
      "loss": 0.8347,
      "step": 200340
    },
    {
      "epoch": 323.16,
      "learning_rate": 0.06769680649677419,
      "loss": 0.8401,
      "step": 200360
    },
    {
      "epoch": 323.19,
      "learning_rate": 0.0676935806935484,
      "loss": 0.8321,
      "step": 200380
    },
    {
      "epoch": 323.23,
      "learning_rate": 0.06769035489032259,
      "loss": 0.8211,
      "step": 200400
    },
    {
      "epoch": 323.26,
      "learning_rate": 0.06768712908709679,
      "loss": 0.8527,
      "step": 200420
    },
    {
      "epoch": 323.29,
      "learning_rate": 0.06768390328387097,
      "loss": 0.8121,
      "step": 200440
    },
    {
      "epoch": 323.32,
      "learning_rate": 0.06768067748064516,
      "loss": 0.8452,
      "step": 200460
    },
    {
      "epoch": 323.35,
      "learning_rate": 0.06767745167741936,
      "loss": 0.845,
      "step": 200480
    },
    {
      "epoch": 323.39,
      "learning_rate": 0.06767422587419356,
      "loss": 0.8207,
      "step": 200500
    },
    {
      "epoch": 323.42,
      "learning_rate": 0.06767100007096774,
      "loss": 0.8342,
      "step": 200520
    },
    {
      "epoch": 323.45,
      "learning_rate": 0.06766777426774194,
      "loss": 0.8183,
      "step": 200540
    },
    {
      "epoch": 323.48,
      "learning_rate": 0.06766454846451614,
      "loss": 0.8462,
      "step": 200560
    },
    {
      "epoch": 323.52,
      "learning_rate": 0.06766132266129032,
      "loss": 0.829,
      "step": 200580
    },
    {
      "epoch": 323.55,
      "learning_rate": 0.06765809685806452,
      "loss": 0.8551,
      "step": 200600
    },
    {
      "epoch": 323.58,
      "learning_rate": 0.06765487105483871,
      "loss": 0.8436,
      "step": 200620
    },
    {
      "epoch": 323.61,
      "learning_rate": 0.06765164525161291,
      "loss": 0.8278,
      "step": 200640
    },
    {
      "epoch": 323.65,
      "learning_rate": 0.06764841944838709,
      "loss": 0.8427,
      "step": 200660
    },
    {
      "epoch": 323.68,
      "learning_rate": 0.0676451936451613,
      "loss": 0.8477,
      "step": 200680
    },
    {
      "epoch": 323.71,
      "learning_rate": 0.06764196784193548,
      "loss": 0.8779,
      "step": 200700
    },
    {
      "epoch": 323.74,
      "learning_rate": 0.06763874203870969,
      "loss": 0.8664,
      "step": 200720
    },
    {
      "epoch": 323.77,
      "learning_rate": 0.06763551623548388,
      "loss": 0.8387,
      "step": 200740
    },
    {
      "epoch": 323.81,
      "learning_rate": 0.06763229043225806,
      "loss": 0.8403,
      "step": 200760
    },
    {
      "epoch": 323.84,
      "learning_rate": 0.06762906462903226,
      "loss": 0.8757,
      "step": 200780
    },
    {
      "epoch": 323.87,
      "learning_rate": 0.06762583882580646,
      "loss": 0.8669,
      "step": 200800
    },
    {
      "epoch": 323.9,
      "learning_rate": 0.06762261302258064,
      "loss": 0.8664,
      "step": 200820
    },
    {
      "epoch": 323.94,
      "learning_rate": 0.06761938721935484,
      "loss": 0.8462,
      "step": 200840
    },
    {
      "epoch": 323.97,
      "learning_rate": 0.06761616141612904,
      "loss": 0.8131,
      "step": 200860
    },
    {
      "epoch": 324.0,
      "learning_rate": 0.06761293561290323,
      "loss": 0.8285,
      "step": 200880
    },
    {
      "epoch": 324.0,
      "eval_accuracy": {
        "accuracy": 0.7556006556865194
      },
      "eval_loss": 1.1801446676254272,
      "eval_runtime": 2.7948,
      "eval_samples_per_second": 4583.899,
      "eval_steps_per_second": 71.92,
      "step": 200880
    },
    {
      "epoch": 324.03,
      "learning_rate": 0.06760970980967743,
      "loss": 0.8541,
      "step": 200900
    },
    {
      "epoch": 324.06,
      "learning_rate": 0.06760648400645161,
      "loss": 0.8181,
      "step": 200920
    },
    {
      "epoch": 324.1,
      "learning_rate": 0.06760325820322581,
      "loss": 0.8169,
      "step": 200940
    },
    {
      "epoch": 324.13,
      "learning_rate": 0.0676000324,
      "loss": 0.8101,
      "step": 200960
    },
    {
      "epoch": 324.16,
      "learning_rate": 0.06759680659677421,
      "loss": 0.8173,
      "step": 200980
    },
    {
      "epoch": 324.19,
      "learning_rate": 0.06759358079354838,
      "loss": 0.8179,
      "step": 201000
    },
    {
      "epoch": 324.23,
      "learning_rate": 0.0675903549903226,
      "loss": 0.8338,
      "step": 201020
    },
    {
      "epoch": 324.26,
      "learning_rate": 0.06758712918709678,
      "loss": 0.8416,
      "step": 201040
    },
    {
      "epoch": 324.29,
      "learning_rate": 0.06758390338387098,
      "loss": 0.8376,
      "step": 201060
    },
    {
      "epoch": 324.32,
      "learning_rate": 0.06758067758064516,
      "loss": 0.8289,
      "step": 201080
    },
    {
      "epoch": 324.35,
      "learning_rate": 0.06757745177741936,
      "loss": 0.814,
      "step": 201100
    },
    {
      "epoch": 324.39,
      "learning_rate": 0.06757422597419355,
      "loss": 0.862,
      "step": 201120
    },
    {
      "epoch": 324.42,
      "learning_rate": 0.06757100017096775,
      "loss": 0.8724,
      "step": 201140
    },
    {
      "epoch": 324.45,
      "learning_rate": 0.06756777436774195,
      "loss": 0.8235,
      "step": 201160
    },
    {
      "epoch": 324.48,
      "learning_rate": 0.06756454856451613,
      "loss": 0.8283,
      "step": 201180
    },
    {
      "epoch": 324.52,
      "learning_rate": 0.06756132276129033,
      "loss": 0.8403,
      "step": 201200
    },
    {
      "epoch": 324.55,
      "learning_rate": 0.06755809695806453,
      "loss": 0.8266,
      "step": 201220
    },
    {
      "epoch": 324.58,
      "learning_rate": 0.06755487115483871,
      "loss": 0.835,
      "step": 201240
    },
    {
      "epoch": 324.61,
      "learning_rate": 0.0675516453516129,
      "loss": 0.8174,
      "step": 201260
    },
    {
      "epoch": 324.65,
      "learning_rate": 0.06754841954838711,
      "loss": 0.8206,
      "step": 201280
    },
    {
      "epoch": 324.68,
      "learning_rate": 0.06754519374516128,
      "loss": 0.8521,
      "step": 201300
    },
    {
      "epoch": 324.71,
      "learning_rate": 0.0675419679419355,
      "loss": 0.8563,
      "step": 201320
    },
    {
      "epoch": 324.74,
      "learning_rate": 0.06753874213870968,
      "loss": 0.8653,
      "step": 201340
    },
    {
      "epoch": 324.77,
      "learning_rate": 0.06753551633548388,
      "loss": 0.847,
      "step": 201360
    },
    {
      "epoch": 324.81,
      "learning_rate": 0.06753229053225807,
      "loss": 0.8478,
      "step": 201380
    },
    {
      "epoch": 324.84,
      "learning_rate": 0.06752906472903226,
      "loss": 0.8603,
      "step": 201400
    },
    {
      "epoch": 324.87,
      "learning_rate": 0.06752583892580645,
      "loss": 0.8808,
      "step": 201420
    },
    {
      "epoch": 324.9,
      "learning_rate": 0.06752261312258065,
      "loss": 0.8708,
      "step": 201440
    },
    {
      "epoch": 324.94,
      "learning_rate": 0.06751938731935485,
      "loss": 0.8449,
      "step": 201460
    },
    {
      "epoch": 324.97,
      "learning_rate": 0.06751616151612903,
      "loss": 0.8512,
      "step": 201480
    },
    {
      "epoch": 325.0,
      "learning_rate": 0.06751309700306453,
      "loss": 0.8489,
      "step": 201500
    },
    {
      "epoch": 325.0,
      "eval_accuracy": {
        "accuracy": 0.752634454765436
      },
      "eval_loss": 1.200246810913086,
      "eval_runtime": 2.7217,
      "eval_samples_per_second": 4706.976,
      "eval_steps_per_second": 73.851,
      "step": 201500
    },
    {
      "epoch": 325.03,
      "learning_rate": 0.06750987119983871,
      "loss": 0.8196,
      "step": 201520
    },
    {
      "epoch": 325.06,
      "learning_rate": 0.0675066453966129,
      "loss": 0.841,
      "step": 201540
    },
    {
      "epoch": 325.1,
      "learning_rate": 0.0675034195933871,
      "loss": 0.8175,
      "step": 201560
    },
    {
      "epoch": 325.13,
      "learning_rate": 0.0675001937901613,
      "loss": 0.8295,
      "step": 201580
    },
    {
      "epoch": 325.16,
      "learning_rate": 0.06749696798693548,
      "loss": 0.8234,
      "step": 201600
    },
    {
      "epoch": 325.19,
      "learning_rate": 0.06749374218370968,
      "loss": 0.8497,
      "step": 201620
    },
    {
      "epoch": 325.23,
      "learning_rate": 0.06749051638048388,
      "loss": 0.8643,
      "step": 201640
    },
    {
      "epoch": 325.26,
      "learning_rate": 0.06748729057725807,
      "loss": 0.8585,
      "step": 201660
    },
    {
      "epoch": 325.29,
      "learning_rate": 0.06748406477403227,
      "loss": 0.8618,
      "step": 201680
    },
    {
      "epoch": 325.32,
      "learning_rate": 0.06748083897080645,
      "loss": 0.8589,
      "step": 201700
    },
    {
      "epoch": 325.35,
      "learning_rate": 0.06747761316758065,
      "loss": 0.8546,
      "step": 201720
    },
    {
      "epoch": 325.39,
      "learning_rate": 0.06747438736435483,
      "loss": 0.8609,
      "step": 201740
    },
    {
      "epoch": 325.42,
      "learning_rate": 0.06747116156112905,
      "loss": 0.8556,
      "step": 201760
    },
    {
      "epoch": 325.45,
      "learning_rate": 0.06746793575790322,
      "loss": 0.8403,
      "step": 201780
    },
    {
      "epoch": 325.48,
      "learning_rate": 0.06746470995467743,
      "loss": 0.8551,
      "step": 201800
    },
    {
      "epoch": 325.52,
      "learning_rate": 0.06746148415145162,
      "loss": 0.8372,
      "step": 201820
    },
    {
      "epoch": 325.55,
      "learning_rate": 0.0674582583482258,
      "loss": 0.8445,
      "step": 201840
    },
    {
      "epoch": 325.58,
      "learning_rate": 0.067455032545,
      "loss": 0.8312,
      "step": 201860
    },
    {
      "epoch": 325.61,
      "learning_rate": 0.0674518067417742,
      "loss": 0.8584,
      "step": 201880
    },
    {
      "epoch": 325.65,
      "learning_rate": 0.06744858093854839,
      "loss": 0.8507,
      "step": 201900
    },
    {
      "epoch": 325.68,
      "learning_rate": 0.06744535513532258,
      "loss": 0.8625,
      "step": 201920
    },
    {
      "epoch": 325.71,
      "learning_rate": 0.06744212933209678,
      "loss": 0.8526,
      "step": 201940
    },
    {
      "epoch": 325.74,
      "learning_rate": 0.06743890352887097,
      "loss": 0.8634,
      "step": 201960
    },
    {
      "epoch": 325.77,
      "learning_rate": 0.06743567772564517,
      "loss": 0.8644,
      "step": 201980
    },
    {
      "epoch": 325.81,
      "learning_rate": 0.06743245192241935,
      "loss": 0.8797,
      "step": 202000
    },
    {
      "epoch": 325.84,
      "learning_rate": 0.06742922611919355,
      "loss": 0.8491,
      "step": 202020
    },
    {
      "epoch": 325.87,
      "learning_rate": 0.06742600031596774,
      "loss": 0.848,
      "step": 202040
    },
    {
      "epoch": 325.9,
      "learning_rate": 0.06742277451274195,
      "loss": 0.8117,
      "step": 202060
    },
    {
      "epoch": 325.94,
      "learning_rate": 0.06741954870951612,
      "loss": 0.8245,
      "step": 202080
    },
    {
      "epoch": 325.97,
      "learning_rate": 0.06741632290629034,
      "loss": 0.8423,
      "step": 202100
    },
    {
      "epoch": 326.0,
      "learning_rate": 0.06741309710306452,
      "loss": 0.8535,
      "step": 202120
    },
    {
      "epoch": 326.0,
      "eval_accuracy": {
        "accuracy": 0.7403793614862227
      },
      "eval_loss": 1.2802541255950928,
      "eval_runtime": 2.6781,
      "eval_samples_per_second": 4783.604,
      "eval_steps_per_second": 75.053,
      "step": 202120
    },
    {
      "epoch": 326.03,
      "learning_rate": 0.06740987129983872,
      "loss": 0.8664,
      "step": 202140
    },
    {
      "epoch": 326.06,
      "learning_rate": 0.0674066454966129,
      "loss": 0.8297,
      "step": 202160
    },
    {
      "epoch": 326.1,
      "learning_rate": 0.0674034196933871,
      "loss": 0.7987,
      "step": 202180
    },
    {
      "epoch": 326.13,
      "learning_rate": 0.06740019389016129,
      "loss": 0.8153,
      "step": 202200
    },
    {
      "epoch": 326.16,
      "learning_rate": 0.06739696808693549,
      "loss": 0.8372,
      "step": 202220
    },
    {
      "epoch": 326.19,
      "learning_rate": 0.06739374228370969,
      "loss": 0.8377,
      "step": 202240
    },
    {
      "epoch": 326.23,
      "learning_rate": 0.06739051648048387,
      "loss": 0.8243,
      "step": 202260
    },
    {
      "epoch": 326.26,
      "learning_rate": 0.06738729067725807,
      "loss": 0.843,
      "step": 202280
    },
    {
      "epoch": 326.29,
      "learning_rate": 0.06738406487403226,
      "loss": 0.8359,
      "step": 202300
    },
    {
      "epoch": 326.32,
      "learning_rate": 0.06738083907080646,
      "loss": 0.8448,
      "step": 202320
    },
    {
      "epoch": 326.35,
      "learning_rate": 0.06737761326758064,
      "loss": 0.8369,
      "step": 202340
    },
    {
      "epoch": 326.39,
      "learning_rate": 0.06737438746435485,
      "loss": 0.8559,
      "step": 202360
    },
    {
      "epoch": 326.42,
      "learning_rate": 0.06737116166112903,
      "loss": 0.8395,
      "step": 202380
    },
    {
      "epoch": 326.45,
      "learning_rate": 0.06736793585790324,
      "loss": 0.8382,
      "step": 202400
    },
    {
      "epoch": 326.48,
      "learning_rate": 0.06736471005467742,
      "loss": 0.865,
      "step": 202420
    },
    {
      "epoch": 326.52,
      "learning_rate": 0.06736148425145162,
      "loss": 0.8465,
      "step": 202440
    },
    {
      "epoch": 326.55,
      "learning_rate": 0.06735825844822581,
      "loss": 0.797,
      "step": 202460
    },
    {
      "epoch": 326.58,
      "learning_rate": 0.06735503264500001,
      "loss": 0.8235,
      "step": 202480
    },
    {
      "epoch": 326.61,
      "learning_rate": 0.06735180684177419,
      "loss": 0.8648,
      "step": 202500
    },
    {
      "epoch": 326.65,
      "learning_rate": 0.06734858103854839,
      "loss": 0.8575,
      "step": 202520
    },
    {
      "epoch": 326.68,
      "learning_rate": 0.06734535523532259,
      "loss": 0.8507,
      "step": 202540
    },
    {
      "epoch": 326.71,
      "learning_rate": 0.06734212943209678,
      "loss": 0.8358,
      "step": 202560
    },
    {
      "epoch": 326.74,
      "learning_rate": 0.06733890362887097,
      "loss": 0.8311,
      "step": 202580
    },
    {
      "epoch": 326.77,
      "learning_rate": 0.06733567782564517,
      "loss": 0.8543,
      "step": 202600
    },
    {
      "epoch": 326.81,
      "learning_rate": 0.06733245202241936,
      "loss": 0.8544,
      "step": 202620
    },
    {
      "epoch": 326.84,
      "learning_rate": 0.06732922621919354,
      "loss": 0.8722,
      "step": 202640
    },
    {
      "epoch": 326.87,
      "learning_rate": 0.06732600041596776,
      "loss": 0.8645,
      "step": 202660
    },
    {
      "epoch": 326.9,
      "learning_rate": 0.06732277461274193,
      "loss": 0.8615,
      "step": 202680
    },
    {
      "epoch": 326.94,
      "learning_rate": 0.06731954880951614,
      "loss": 0.8507,
      "step": 202700
    },
    {
      "epoch": 326.97,
      "learning_rate": 0.06731632300629033,
      "loss": 0.8502,
      "step": 202720
    },
    {
      "epoch": 327.0,
      "learning_rate": 0.06731309720306453,
      "loss": 0.8328,
      "step": 202740
    },
    {
      "epoch": 327.0,
      "eval_accuracy": {
        "accuracy": 0.7517758176567013
      },
      "eval_loss": 1.2038904428482056,
      "eval_runtime": 2.7137,
      "eval_samples_per_second": 4720.926,
      "eval_steps_per_second": 74.07,
      "step": 202740
    },
    {
      "epoch": 327.03,
      "learning_rate": 0.06730987139983871,
      "loss": 0.8364,
      "step": 202760
    },
    {
      "epoch": 327.06,
      "learning_rate": 0.06730664559661291,
      "loss": 0.8304,
      "step": 202780
    },
    {
      "epoch": 327.1,
      "learning_rate": 0.0673034197933871,
      "loss": 0.8499,
      "step": 202800
    },
    {
      "epoch": 327.13,
      "learning_rate": 0.0673001939901613,
      "loss": 0.8506,
      "step": 202820
    },
    {
      "epoch": 327.16,
      "learning_rate": 0.0672969681869355,
      "loss": 0.8254,
      "step": 202840
    },
    {
      "epoch": 327.19,
      "learning_rate": 0.06729374238370968,
      "loss": 0.8357,
      "step": 202860
    },
    {
      "epoch": 327.23,
      "learning_rate": 0.06729051658048388,
      "loss": 0.8158,
      "step": 202880
    },
    {
      "epoch": 327.26,
      "learning_rate": 0.06728729077725808,
      "loss": 0.8092,
      "step": 202900
    },
    {
      "epoch": 327.29,
      "learning_rate": 0.06728406497403226,
      "loss": 0.8188,
      "step": 202920
    },
    {
      "epoch": 327.32,
      "learning_rate": 0.06728083917080645,
      "loss": 0.858,
      "step": 202940
    },
    {
      "epoch": 327.35,
      "learning_rate": 0.06727761336758066,
      "loss": 0.8701,
      "step": 202960
    },
    {
      "epoch": 327.39,
      "learning_rate": 0.06727438756435483,
      "loss": 0.8289,
      "step": 202980
    },
    {
      "epoch": 327.42,
      "learning_rate": 0.06727116176112904,
      "loss": 0.8297,
      "step": 203000
    },
    {
      "epoch": 327.45,
      "learning_rate": 0.06726793595790323,
      "loss": 0.8531,
      "step": 203020
    },
    {
      "epoch": 327.48,
      "learning_rate": 0.06726471015467743,
      "loss": 0.8441,
      "step": 203040
    },
    {
      "epoch": 327.52,
      "learning_rate": 0.06726148435145161,
      "loss": 0.8409,
      "step": 203060
    },
    {
      "epoch": 327.55,
      "learning_rate": 0.06725825854822581,
      "loss": 0.8537,
      "step": 203080
    },
    {
      "epoch": 327.58,
      "learning_rate": 0.067255032745,
      "loss": 0.8519,
      "step": 203100
    },
    {
      "epoch": 327.61,
      "learning_rate": 0.0672518069417742,
      "loss": 0.8542,
      "step": 203120
    },
    {
      "epoch": 327.65,
      "learning_rate": 0.0672485811385484,
      "loss": 0.8504,
      "step": 203140
    },
    {
      "epoch": 327.68,
      "learning_rate": 0.06724535533532258,
      "loss": 0.8602,
      "step": 203160
    },
    {
      "epoch": 327.71,
      "learning_rate": 0.06724212953209678,
      "loss": 0.8547,
      "step": 203180
    },
    {
      "epoch": 327.74,
      "learning_rate": 0.06723890372887098,
      "loss": 0.8721,
      "step": 203200
    },
    {
      "epoch": 327.77,
      "learning_rate": 0.06723567792564517,
      "loss": 0.8474,
      "step": 203220
    },
    {
      "epoch": 327.81,
      "learning_rate": 0.06723245212241935,
      "loss": 0.8489,
      "step": 203240
    },
    {
      "epoch": 327.84,
      "learning_rate": 0.06722922631919356,
      "loss": 0.8384,
      "step": 203260
    },
    {
      "epoch": 327.87,
      "learning_rate": 0.06722600051596773,
      "loss": 0.8416,
      "step": 203280
    },
    {
      "epoch": 327.9,
      "learning_rate": 0.06722277471274195,
      "loss": 0.8326,
      "step": 203300
    },
    {
      "epoch": 327.94,
      "learning_rate": 0.06721954890951613,
      "loss": 0.8906,
      "step": 203320
    },
    {
      "epoch": 327.97,
      "learning_rate": 0.06721632310629033,
      "loss": 0.8816,
      "step": 203340
    },
    {
      "epoch": 328.0,
      "learning_rate": 0.06721309730306452,
      "loss": 0.845,
      "step": 203360
    },
    {
      "epoch": 328.0,
      "eval_accuracy": {
        "accuracy": 0.751307470142846
      },
      "eval_loss": 1.2083866596221924,
      "eval_runtime": 2.7224,
      "eval_samples_per_second": 4705.745,
      "eval_steps_per_second": 73.831,
      "step": 203360
    },
    {
      "epoch": 328.03,
      "learning_rate": 0.06720987149983872,
      "loss": 0.8638,
      "step": 203380
    },
    {
      "epoch": 328.06,
      "learning_rate": 0.0672066456966129,
      "loss": 0.8396,
      "step": 203400
    },
    {
      "epoch": 328.1,
      "learning_rate": 0.0672034198933871,
      "loss": 0.8366,
      "step": 203420
    },
    {
      "epoch": 328.13,
      "learning_rate": 0.0672001940901613,
      "loss": 0.8309,
      "step": 203440
    },
    {
      "epoch": 328.16,
      "learning_rate": 0.06719696828693549,
      "loss": 0.8386,
      "step": 203460
    },
    {
      "epoch": 328.19,
      "learning_rate": 0.06719374248370968,
      "loss": 0.8216,
      "step": 203480
    },
    {
      "epoch": 328.23,
      "learning_rate": 0.06719051668048388,
      "loss": 0.8247,
      "step": 203500
    },
    {
      "epoch": 328.26,
      "learning_rate": 0.06718729087725807,
      "loss": 0.8336,
      "step": 203520
    },
    {
      "epoch": 328.29,
      "learning_rate": 0.06718406507403227,
      "loss": 0.8139,
      "step": 203540
    },
    {
      "epoch": 328.32,
      "learning_rate": 0.06718083927080645,
      "loss": 0.8256,
      "step": 203560
    },
    {
      "epoch": 328.35,
      "learning_rate": 0.06717761346758064,
      "loss": 0.8247,
      "step": 203580
    },
    {
      "epoch": 328.39,
      "learning_rate": 0.06717438766435485,
      "loss": 0.8412,
      "step": 203600
    },
    {
      "epoch": 328.42,
      "learning_rate": 0.06717116186112904,
      "loss": 0.795,
      "step": 203620
    },
    {
      "epoch": 328.45,
      "learning_rate": 0.06716793605790324,
      "loss": 0.8299,
      "step": 203640
    },
    {
      "epoch": 328.48,
      "learning_rate": 0.06716471025467742,
      "loss": 0.8458,
      "step": 203660
    },
    {
      "epoch": 328.52,
      "learning_rate": 0.06716148445145162,
      "loss": 0.8554,
      "step": 203680
    },
    {
      "epoch": 328.55,
      "learning_rate": 0.0671582586482258,
      "loss": 0.8525,
      "step": 203700
    },
    {
      "epoch": 328.58,
      "learning_rate": 0.067155032845,
      "loss": 0.8586,
      "step": 203720
    },
    {
      "epoch": 328.61,
      "learning_rate": 0.0671518070417742,
      "loss": 0.8518,
      "step": 203740
    },
    {
      "epoch": 328.65,
      "learning_rate": 0.06714858123854839,
      "loss": 0.8439,
      "step": 203760
    },
    {
      "epoch": 328.68,
      "learning_rate": 0.06714535543532259,
      "loss": 0.8416,
      "step": 203780
    },
    {
      "epoch": 328.71,
      "learning_rate": 0.06714212963209679,
      "loss": 0.8329,
      "step": 203800
    },
    {
      "epoch": 328.74,
      "learning_rate": 0.06713890382887097,
      "loss": 0.83,
      "step": 203820
    },
    {
      "epoch": 328.77,
      "learning_rate": 0.06713567802564517,
      "loss": 0.821,
      "step": 203840
    },
    {
      "epoch": 328.81,
      "learning_rate": 0.06713245222241936,
      "loss": 0.8521,
      "step": 203860
    },
    {
      "epoch": 328.84,
      "learning_rate": 0.06712922641919354,
      "loss": 0.8424,
      "step": 203880
    },
    {
      "epoch": 328.87,
      "learning_rate": 0.06712600061596775,
      "loss": 0.8607,
      "step": 203900
    },
    {
      "epoch": 328.9,
      "learning_rate": 0.06712277481274194,
      "loss": 0.8473,
      "step": 203920
    },
    {
      "epoch": 328.94,
      "learning_rate": 0.06711954900951614,
      "loss": 0.8428,
      "step": 203940
    },
    {
      "epoch": 328.97,
      "learning_rate": 0.06711632320629032,
      "loss": 0.8749,
      "step": 203960
    },
    {
      "epoch": 329.0,
      "learning_rate": 0.06711325869322582,
      "loss": 0.8557,
      "step": 203980
    },
    {
      "epoch": 329.0,
      "eval_accuracy": {
        "accuracy": 0.7546639606588088
      },
      "eval_loss": 1.1849991083145142,
      "eval_runtime": 2.797,
      "eval_samples_per_second": 4580.218,
      "eval_steps_per_second": 71.862,
      "step": 203980
    },
    {
      "epoch": 329.03,
      "learning_rate": 0.06711003289,
      "loss": 0.8347,
      "step": 204000
    },
    {
      "epoch": 329.06,
      "learning_rate": 0.06710680708677419,
      "loss": 0.8211,
      "step": 204020
    },
    {
      "epoch": 329.1,
      "learning_rate": 0.0671035812835484,
      "loss": 0.8211,
      "step": 204040
    },
    {
      "epoch": 329.13,
      "learning_rate": 0.06710035548032257,
      "loss": 0.8243,
      "step": 204060
    },
    {
      "epoch": 329.16,
      "learning_rate": 0.06709712967709679,
      "loss": 0.8521,
      "step": 204080
    },
    {
      "epoch": 329.19,
      "learning_rate": 0.06709390387387097,
      "loss": 0.8308,
      "step": 204100
    },
    {
      "epoch": 329.23,
      "learning_rate": 0.06709067807064517,
      "loss": 0.8456,
      "step": 204120
    },
    {
      "epoch": 329.26,
      "learning_rate": 0.06708745226741936,
      "loss": 0.8182,
      "step": 204140
    },
    {
      "epoch": 329.29,
      "learning_rate": 0.06708422646419356,
      "loss": 0.8366,
      "step": 204160
    },
    {
      "epoch": 329.32,
      "learning_rate": 0.06708100066096774,
      "loss": 0.8446,
      "step": 204180
    },
    {
      "epoch": 329.35,
      "learning_rate": 0.06707777485774194,
      "loss": 0.8485,
      "step": 204200
    },
    {
      "epoch": 329.39,
      "learning_rate": 0.06707454905451614,
      "loss": 0.8196,
      "step": 204220
    },
    {
      "epoch": 329.42,
      "learning_rate": 0.06707132325129032,
      "loss": 0.8276,
      "step": 204240
    },
    {
      "epoch": 329.45,
      "learning_rate": 0.06706809744806452,
      "loss": 0.8578,
      "step": 204260
    },
    {
      "epoch": 329.48,
      "learning_rate": 0.06706487164483872,
      "loss": 0.831,
      "step": 204280
    },
    {
      "epoch": 329.52,
      "learning_rate": 0.06706164584161291,
      "loss": 0.8249,
      "step": 204300
    },
    {
      "epoch": 329.55,
      "learning_rate": 0.06705842003838709,
      "loss": 0.833,
      "step": 204320
    },
    {
      "epoch": 329.58,
      "learning_rate": 0.0670551942351613,
      "loss": 0.8571,
      "step": 204340
    },
    {
      "epoch": 329.61,
      "learning_rate": 0.06705196843193548,
      "loss": 0.8473,
      "step": 204360
    },
    {
      "epoch": 329.65,
      "learning_rate": 0.06704874262870969,
      "loss": 0.8347,
      "step": 204380
    },
    {
      "epoch": 329.68,
      "learning_rate": 0.06704551682548388,
      "loss": 0.8588,
      "step": 204400
    },
    {
      "epoch": 329.71,
      "learning_rate": 0.06704229102225807,
      "loss": 0.8376,
      "step": 204420
    },
    {
      "epoch": 329.74,
      "learning_rate": 0.06703906521903226,
      "loss": 0.8605,
      "step": 204440
    },
    {
      "epoch": 329.77,
      "learning_rate": 0.06703583941580646,
      "loss": 0.8329,
      "step": 204460
    },
    {
      "epoch": 329.81,
      "learning_rate": 0.06703261361258064,
      "loss": 0.8287,
      "step": 204480
    },
    {
      "epoch": 329.84,
      "learning_rate": 0.06702938780935484,
      "loss": 0.8655,
      "step": 204500
    },
    {
      "epoch": 329.87,
      "learning_rate": 0.06702616200612904,
      "loss": 0.8665,
      "step": 204520
    },
    {
      "epoch": 329.9,
      "learning_rate": 0.06702293620290323,
      "loss": 0.833,
      "step": 204540
    },
    {
      "epoch": 329.94,
      "learning_rate": 0.06701971039967743,
      "loss": 0.8321,
      "step": 204560
    },
    {
      "epoch": 329.97,
      "learning_rate": 0.06701648459645163,
      "loss": 0.8657,
      "step": 204580
    },
    {
      "epoch": 330.0,
      "learning_rate": 0.06701325879322581,
      "loss": 0.8528,
      "step": 204600
    },
    {
      "epoch": 330.0,
      "eval_accuracy": {
        "accuracy": 0.740847709000078
      },
      "eval_loss": 1.2747207880020142,
      "eval_runtime": 2.6998,
      "eval_samples_per_second": 4745.226,
      "eval_steps_per_second": 74.451,
      "step": 204600
    },
    {
      "epoch": 330.03,
      "learning_rate": 0.06701003299,
      "loss": 0.8687,
      "step": 204620
    },
    {
      "epoch": 330.06,
      "learning_rate": 0.0670068071867742,
      "loss": 0.8079,
      "step": 204640
    },
    {
      "epoch": 330.1,
      "learning_rate": 0.06700358138354838,
      "loss": 0.828,
      "step": 204660
    },
    {
      "epoch": 330.13,
      "learning_rate": 0.0670003555803226,
      "loss": 0.8538,
      "step": 204680
    },
    {
      "epoch": 330.16,
      "learning_rate": 0.06699712977709678,
      "loss": 0.8207,
      "step": 204700
    },
    {
      "epoch": 330.19,
      "learning_rate": 0.06699390397387098,
      "loss": 0.7947,
      "step": 204720
    },
    {
      "epoch": 330.23,
      "learning_rate": 0.06699067817064516,
      "loss": 0.8303,
      "step": 204740
    },
    {
      "epoch": 330.26,
      "learning_rate": 0.06698745236741936,
      "loss": 0.8232,
      "step": 204760
    },
    {
      "epoch": 330.29,
      "learning_rate": 0.06698422656419355,
      "loss": 0.834,
      "step": 204780
    },
    {
      "epoch": 330.32,
      "learning_rate": 0.06698100076096775,
      "loss": 0.8533,
      "step": 204800
    },
    {
      "epoch": 330.35,
      "learning_rate": 0.06697777495774195,
      "loss": 0.8376,
      "step": 204820
    },
    {
      "epoch": 330.39,
      "learning_rate": 0.06697454915451613,
      "loss": 0.8392,
      "step": 204840
    },
    {
      "epoch": 330.42,
      "learning_rate": 0.06697132335129033,
      "loss": 0.8402,
      "step": 204860
    },
    {
      "epoch": 330.45,
      "learning_rate": 0.06696809754806453,
      "loss": 0.8303,
      "step": 204880
    },
    {
      "epoch": 330.48,
      "learning_rate": 0.06696487174483871,
      "loss": 0.8181,
      "step": 204900
    },
    {
      "epoch": 330.52,
      "learning_rate": 0.06696164594161291,
      "loss": 0.8086,
      "step": 204920
    },
    {
      "epoch": 330.55,
      "learning_rate": 0.0669584201383871,
      "loss": 0.8626,
      "step": 204940
    },
    {
      "epoch": 330.58,
      "learning_rate": 0.06695519433516128,
      "loss": 0.8379,
      "step": 204960
    },
    {
      "epoch": 330.61,
      "learning_rate": 0.0669519685319355,
      "loss": 0.8547,
      "step": 204980
    },
    {
      "epoch": 330.65,
      "learning_rate": 0.06694874272870968,
      "loss": 0.869,
      "step": 205000
    },
    {
      "epoch": 330.68,
      "learning_rate": 0.06694551692548388,
      "loss": 0.8452,
      "step": 205020
    },
    {
      "epoch": 330.71,
      "learning_rate": 0.06694229112225807,
      "loss": 0.8384,
      "step": 205040
    },
    {
      "epoch": 330.74,
      "learning_rate": 0.06693906531903226,
      "loss": 0.8452,
      "step": 205060
    },
    {
      "epoch": 330.77,
      "learning_rate": 0.06693583951580645,
      "loss": 0.854,
      "step": 205080
    },
    {
      "epoch": 330.81,
      "learning_rate": 0.06693261371258065,
      "loss": 0.8369,
      "step": 205100
    },
    {
      "epoch": 330.84,
      "learning_rate": 0.06692938790935485,
      "loss": 0.8463,
      "step": 205120
    },
    {
      "epoch": 330.87,
      "learning_rate": 0.06692616210612903,
      "loss": 0.8762,
      "step": 205140
    },
    {
      "epoch": 330.9,
      "learning_rate": 0.06692293630290323,
      "loss": 0.8585,
      "step": 205160
    },
    {
      "epoch": 330.94,
      "learning_rate": 0.06691971049967742,
      "loss": 0.8572,
      "step": 205180
    },
    {
      "epoch": 330.97,
      "learning_rate": 0.06691648469645162,
      "loss": 0.8354,
      "step": 205200
    },
    {
      "epoch": 331.0,
      "learning_rate": 0.06691325889322582,
      "loss": 0.8596,
      "step": 205220
    },
    {
      "epoch": 331.0,
      "eval_accuracy": {
        "accuracy": 0.7475606900320038
      },
      "eval_loss": 1.2442094087600708,
      "eval_runtime": 2.7153,
      "eval_samples_per_second": 4718.045,
      "eval_steps_per_second": 74.024,
      "step": 205220
    },
    {
      "epoch": 331.03,
      "learning_rate": 0.06691003309,
      "loss": 0.8625,
      "step": 205240
    },
    {
      "epoch": 331.06,
      "learning_rate": 0.06690680728677419,
      "loss": 0.8649,
      "step": 205260
    },
    {
      "epoch": 331.1,
      "learning_rate": 0.0669035814835484,
      "loss": 0.837,
      "step": 205280
    },
    {
      "epoch": 331.13,
      "learning_rate": 0.06690035568032258,
      "loss": 0.8377,
      "step": 205300
    },
    {
      "epoch": 331.16,
      "learning_rate": 0.06689712987709678,
      "loss": 0.8369,
      "step": 205320
    },
    {
      "epoch": 331.19,
      "learning_rate": 0.06689390407387097,
      "loss": 0.8283,
      "step": 205340
    },
    {
      "epoch": 331.23,
      "learning_rate": 0.06689067827064517,
      "loss": 0.8362,
      "step": 205360
    },
    {
      "epoch": 331.26,
      "learning_rate": 0.06688745246741935,
      "loss": 0.8162,
      "step": 205380
    },
    {
      "epoch": 331.29,
      "learning_rate": 0.06688422666419355,
      "loss": 0.8182,
      "step": 205400
    },
    {
      "epoch": 331.32,
      "learning_rate": 0.06688100086096775,
      "loss": 0.8137,
      "step": 205420
    },
    {
      "epoch": 331.35,
      "learning_rate": 0.06687777505774194,
      "loss": 0.8273,
      "step": 205440
    },
    {
      "epoch": 331.39,
      "learning_rate": 0.06687454925451614,
      "loss": 0.8407,
      "step": 205460
    },
    {
      "epoch": 331.42,
      "learning_rate": 0.06687132345129032,
      "loss": 0.8589,
      "step": 205480
    },
    {
      "epoch": 331.45,
      "learning_rate": 0.06686809764806452,
      "loss": 0.8588,
      "step": 205500
    },
    {
      "epoch": 331.48,
      "learning_rate": 0.06686487184483872,
      "loss": 0.8542,
      "step": 205520
    },
    {
      "epoch": 331.52,
      "learning_rate": 0.0668616460416129,
      "loss": 0.83,
      "step": 205540
    },
    {
      "epoch": 331.55,
      "learning_rate": 0.06685842023838709,
      "loss": 0.8649,
      "step": 205560
    },
    {
      "epoch": 331.58,
      "learning_rate": 0.0668551944351613,
      "loss": 0.8316,
      "step": 205580
    },
    {
      "epoch": 331.61,
      "learning_rate": 0.06685196863193549,
      "loss": 0.8642,
      "step": 205600
    },
    {
      "epoch": 331.65,
      "learning_rate": 0.06684874282870969,
      "loss": 0.8354,
      "step": 205620
    },
    {
      "epoch": 331.68,
      "learning_rate": 0.06684551702548387,
      "loss": 0.8409,
      "step": 205640
    },
    {
      "epoch": 331.71,
      "learning_rate": 0.06684229122225807,
      "loss": 0.8398,
      "step": 205660
    },
    {
      "epoch": 331.74,
      "learning_rate": 0.06683906541903226,
      "loss": 0.8568,
      "step": 205680
    },
    {
      "epoch": 331.77,
      "learning_rate": 0.06683583961580647,
      "loss": 0.8763,
      "step": 205700
    },
    {
      "epoch": 331.81,
      "learning_rate": 0.06683261381258064,
      "loss": 0.8535,
      "step": 205720
    },
    {
      "epoch": 331.84,
      "learning_rate": 0.06682938800935484,
      "loss": 0.859,
      "step": 205740
    },
    {
      "epoch": 331.87,
      "learning_rate": 0.06682616220612904,
      "loss": 0.877,
      "step": 205760
    },
    {
      "epoch": 331.9,
      "learning_rate": 0.06682293640290322,
      "loss": 0.8416,
      "step": 205780
    },
    {
      "epoch": 331.94,
      "learning_rate": 0.06681971059967742,
      "loss": 0.8575,
      "step": 205800
    },
    {
      "epoch": 331.97,
      "learning_rate": 0.06681648479645162,
      "loss": 0.8404,
      "step": 205820
    },
    {
      "epoch": 332.0,
      "learning_rate": 0.06681325899322581,
      "loss": 0.8233,
      "step": 205840
    },
    {
      "epoch": 332.0,
      "eval_accuracy": {
        "accuracy": 0.7427991569744751
      },
      "eval_loss": 1.2444226741790771,
      "eval_runtime": 2.9746,
      "eval_samples_per_second": 4306.814,
      "eval_steps_per_second": 67.572,
      "step": 205840
    },
    {
      "epoch": 332.03,
      "learning_rate": 0.06681003319,
      "loss": 0.8377,
      "step": 205860
    },
    {
      "epoch": 332.06,
      "learning_rate": 0.0668068073867742,
      "loss": 0.8125,
      "step": 205880
    },
    {
      "epoch": 332.1,
      "learning_rate": 0.06680358158354839,
      "loss": 0.8336,
      "step": 205900
    },
    {
      "epoch": 332.13,
      "learning_rate": 0.06680035578032259,
      "loss": 0.8175,
      "step": 205920
    },
    {
      "epoch": 332.16,
      "learning_rate": 0.06679712997709678,
      "loss": 0.8187,
      "step": 205940
    },
    {
      "epoch": 332.19,
      "learning_rate": 0.06679390417387097,
      "loss": 0.8192,
      "step": 205960
    },
    {
      "epoch": 332.23,
      "learning_rate": 0.06679067837064516,
      "loss": 0.8449,
      "step": 205980
    },
    {
      "epoch": 332.26,
      "learning_rate": 0.06678745256741937,
      "loss": 0.8362,
      "step": 206000
    },
    {
      "epoch": 332.29,
      "learning_rate": 0.06678422676419354,
      "loss": 0.8315,
      "step": 206020
    },
    {
      "epoch": 332.32,
      "learning_rate": 0.06678100096096774,
      "loss": 0.8463,
      "step": 206040
    },
    {
      "epoch": 332.35,
      "learning_rate": 0.06677777515774194,
      "loss": 0.8255,
      "step": 206060
    },
    {
      "epoch": 332.39,
      "learning_rate": 0.06677454935451613,
      "loss": 0.8351,
      "step": 206080
    },
    {
      "epoch": 332.42,
      "learning_rate": 0.06677132355129033,
      "loss": 0.8449,
      "step": 206100
    },
    {
      "epoch": 332.45,
      "learning_rate": 0.06676809774806453,
      "loss": 0.8458,
      "step": 206120
    },
    {
      "epoch": 332.48,
      "learning_rate": 0.06676487194483871,
      "loss": 0.8583,
      "step": 206140
    },
    {
      "epoch": 332.52,
      "learning_rate": 0.06676164614161291,
      "loss": 0.8682,
      "step": 206160
    },
    {
      "epoch": 332.55,
      "learning_rate": 0.06675842033838711,
      "loss": 0.8299,
      "step": 206180
    },
    {
      "epoch": 332.58,
      "learning_rate": 0.0667551945351613,
      "loss": 0.8352,
      "step": 206200
    },
    {
      "epoch": 332.61,
      "learning_rate": 0.0667519687319355,
      "loss": 0.8547,
      "step": 206220
    },
    {
      "epoch": 332.65,
      "learning_rate": 0.06674874292870968,
      "loss": 0.8464,
      "step": 206240
    },
    {
      "epoch": 332.68,
      "learning_rate": 0.06674567841564516,
      "loss": 0.8498,
      "step": 206260
    },
    {
      "epoch": 332.71,
      "learning_rate": 0.06674245261241936,
      "loss": 0.8515,
      "step": 206280
    },
    {
      "epoch": 332.74,
      "learning_rate": 0.06673922680919356,
      "loss": 0.8545,
      "step": 206300
    },
    {
      "epoch": 332.77,
      "learning_rate": 0.06673600100596774,
      "loss": 0.8268,
      "step": 206320
    },
    {
      "epoch": 332.81,
      "learning_rate": 0.06673277520274193,
      "loss": 0.8419,
      "step": 206340
    },
    {
      "epoch": 332.84,
      "learning_rate": 0.06672954939951614,
      "loss": 0.8536,
      "step": 206360
    },
    {
      "epoch": 332.87,
      "learning_rate": 0.06672632359629033,
      "loss": 0.8494,
      "step": 206380
    },
    {
      "epoch": 332.9,
      "learning_rate": 0.06672309779306453,
      "loss": 0.8447,
      "step": 206400
    },
    {
      "epoch": 332.94,
      "learning_rate": 0.06671987198983871,
      "loss": 0.8515,
      "step": 206420
    },
    {
      "epoch": 332.97,
      "learning_rate": 0.06671664618661291,
      "loss": 0.8692,
      "step": 206440
    },
    {
      "epoch": 333.0,
      "learning_rate": 0.0667134203833871,
      "loss": 0.8871,
      "step": 206460
    },
    {
      "epoch": 333.0,
      "eval_accuracy": {
        "accuracy": 0.747404574194052
      },
      "eval_loss": 1.2593579292297363,
      "eval_runtime": 2.7021,
      "eval_samples_per_second": 4741.124,
      "eval_steps_per_second": 74.387,
      "step": 206460
    },
    {
      "epoch": 333.03,
      "learning_rate": 0.0667101945801613,
      "loss": 0.8415,
      "step": 206480
    },
    {
      "epoch": 333.06,
      "learning_rate": 0.0667069687769355,
      "loss": 0.8301,
      "step": 206500
    },
    {
      "epoch": 333.1,
      "learning_rate": 0.06670374297370968,
      "loss": 0.847,
      "step": 206520
    },
    {
      "epoch": 333.13,
      "learning_rate": 0.06670051717048388,
      "loss": 0.8475,
      "step": 206540
    },
    {
      "epoch": 333.16,
      "learning_rate": 0.06669729136725806,
      "loss": 0.8231,
      "step": 206560
    },
    {
      "epoch": 333.19,
      "learning_rate": 0.06669406556403226,
      "loss": 0.832,
      "step": 206580
    },
    {
      "epoch": 333.23,
      "learning_rate": 0.06669083976080646,
      "loss": 0.8424,
      "step": 206600
    },
    {
      "epoch": 333.26,
      "learning_rate": 0.06668761395758065,
      "loss": 0.8308,
      "step": 206620
    },
    {
      "epoch": 333.29,
      "learning_rate": 0.06668438815435483,
      "loss": 0.8623,
      "step": 206640
    },
    {
      "epoch": 333.32,
      "learning_rate": 0.06668116235112904,
      "loss": 0.8362,
      "step": 206660
    },
    {
      "epoch": 333.35,
      "learning_rate": 0.06667793654790323,
      "loss": 0.8348,
      "step": 206680
    },
    {
      "epoch": 333.39,
      "learning_rate": 0.06667471074467743,
      "loss": 0.8543,
      "step": 206700
    },
    {
      "epoch": 333.42,
      "learning_rate": 0.06667148494145161,
      "loss": 0.8584,
      "step": 206720
    },
    {
      "epoch": 333.45,
      "learning_rate": 0.06666825913822581,
      "loss": 0.8353,
      "step": 206740
    },
    {
      "epoch": 333.48,
      "learning_rate": 0.066665033335,
      "loss": 0.8158,
      "step": 206760
    },
    {
      "epoch": 333.52,
      "learning_rate": 0.06666180753177421,
      "loss": 0.8376,
      "step": 206780
    },
    {
      "epoch": 333.55,
      "learning_rate": 0.06665858172854838,
      "loss": 0.8567,
      "step": 206800
    },
    {
      "epoch": 333.58,
      "learning_rate": 0.06665535592532258,
      "loss": 0.825,
      "step": 206820
    },
    {
      "epoch": 333.61,
      "learning_rate": 0.06665213012209678,
      "loss": 0.8589,
      "step": 206840
    },
    {
      "epoch": 333.65,
      "learning_rate": 0.06664890431887097,
      "loss": 0.8423,
      "step": 206860
    },
    {
      "epoch": 333.68,
      "learning_rate": 0.06664567851564517,
      "loss": 0.8243,
      "step": 206880
    },
    {
      "epoch": 333.71,
      "learning_rate": 0.06664245271241936,
      "loss": 0.8286,
      "step": 206900
    },
    {
      "epoch": 333.74,
      "learning_rate": 0.06663922690919355,
      "loss": 0.8467,
      "step": 206920
    },
    {
      "epoch": 333.77,
      "learning_rate": 0.06663600110596773,
      "loss": 0.8403,
      "step": 206940
    },
    {
      "epoch": 333.81,
      "learning_rate": 0.06663277530274195,
      "loss": 0.8488,
      "step": 206960
    },
    {
      "epoch": 333.84,
      "learning_rate": 0.06662954949951613,
      "loss": 0.8544,
      "step": 206980
    },
    {
      "epoch": 333.87,
      "learning_rate": 0.06662632369629033,
      "loss": 0.8733,
      "step": 207000
    },
    {
      "epoch": 333.9,
      "learning_rate": 0.06662309789306452,
      "loss": 0.8752,
      "step": 207020
    },
    {
      "epoch": 333.94,
      "learning_rate": 0.06661987208983872,
      "loss": 0.8391,
      "step": 207040
    },
    {
      "epoch": 333.97,
      "learning_rate": 0.0666166462866129,
      "loss": 0.8439,
      "step": 207060
    },
    {
      "epoch": 334.0,
      "learning_rate": 0.06661342048338711,
      "loss": 0.8359,
      "step": 207080
    },
    {
      "epoch": 334.0,
      "eval_accuracy": {
        "accuracy": 0.7521661072515806
      },
      "eval_loss": 1.2092502117156982,
      "eval_runtime": 2.9027,
      "eval_samples_per_second": 4413.458,
      "eval_steps_per_second": 69.246,
      "step": 207080
    },
    {
      "epoch": 334.03,
      "learning_rate": 0.06661019468016129,
      "loss": 0.8602,
      "step": 207100
    },
    {
      "epoch": 334.06,
      "learning_rate": 0.06660696887693549,
      "loss": 0.8173,
      "step": 207120
    },
    {
      "epoch": 334.1,
      "learning_rate": 0.06660374307370968,
      "loss": 0.8214,
      "step": 207140
    },
    {
      "epoch": 334.13,
      "learning_rate": 0.06660051727048387,
      "loss": 0.82,
      "step": 207160
    },
    {
      "epoch": 334.16,
      "learning_rate": 0.06659729146725807,
      "loss": 0.8246,
      "step": 207180
    },
    {
      "epoch": 334.19,
      "learning_rate": 0.06659406566403227,
      "loss": 0.8269,
      "step": 207200
    },
    {
      "epoch": 334.23,
      "learning_rate": 0.06659083986080645,
      "loss": 0.8289,
      "step": 207220
    },
    {
      "epoch": 334.26,
      "learning_rate": 0.06658761405758065,
      "loss": 0.8486,
      "step": 207240
    },
    {
      "epoch": 334.29,
      "learning_rate": 0.06658438825435485,
      "loss": 0.8527,
      "step": 207260
    },
    {
      "epoch": 334.32,
      "learning_rate": 0.06658116245112904,
      "loss": 0.8501,
      "step": 207280
    },
    {
      "epoch": 334.35,
      "learning_rate": 0.06657793664790324,
      "loss": 0.8264,
      "step": 207300
    },
    {
      "epoch": 334.39,
      "learning_rate": 0.06657471084467742,
      "loss": 0.8082,
      "step": 207320
    },
    {
      "epoch": 334.42,
      "learning_rate": 0.06657148504145162,
      "loss": 0.8459,
      "step": 207340
    },
    {
      "epoch": 334.45,
      "learning_rate": 0.0665682592382258,
      "loss": 0.8275,
      "step": 207360
    },
    {
      "epoch": 334.48,
      "learning_rate": 0.06656503343500002,
      "loss": 0.8397,
      "step": 207380
    },
    {
      "epoch": 334.52,
      "learning_rate": 0.06656180763177419,
      "loss": 0.8553,
      "step": 207400
    },
    {
      "epoch": 334.55,
      "learning_rate": 0.06655858182854839,
      "loss": 0.8555,
      "step": 207420
    },
    {
      "epoch": 334.58,
      "learning_rate": 0.06655535602532259,
      "loss": 0.8305,
      "step": 207440
    },
    {
      "epoch": 334.61,
      "learning_rate": 0.06655213022209677,
      "loss": 0.8302,
      "step": 207460
    },
    {
      "epoch": 334.65,
      "learning_rate": 0.06654890441887097,
      "loss": 0.8523,
      "step": 207480
    },
    {
      "epoch": 334.68,
      "learning_rate": 0.06654567861564517,
      "loss": 0.8522,
      "step": 207500
    },
    {
      "epoch": 334.71,
      "learning_rate": 0.06654245281241936,
      "loss": 0.886,
      "step": 207520
    },
    {
      "epoch": 334.74,
      "learning_rate": 0.06653922700919356,
      "loss": 0.8546,
      "step": 207540
    },
    {
      "epoch": 334.77,
      "learning_rate": 0.06653600120596775,
      "loss": 0.8409,
      "step": 207560
    },
    {
      "epoch": 334.81,
      "learning_rate": 0.06653277540274194,
      "loss": 0.8614,
      "step": 207580
    },
    {
      "epoch": 334.84,
      "learning_rate": 0.06652954959951614,
      "loss": 0.8376,
      "step": 207600
    },
    {
      "epoch": 334.87,
      "learning_rate": 0.06652632379629032,
      "loss": 0.8548,
      "step": 207620
    },
    {
      "epoch": 334.9,
      "learning_rate": 0.06652309799306452,
      "loss": 0.8595,
      "step": 207640
    },
    {
      "epoch": 334.94,
      "learning_rate": 0.06651987218983871,
      "loss": 0.8773,
      "step": 207660
    },
    {
      "epoch": 334.97,
      "learning_rate": 0.06651664638661292,
      "loss": 0.875,
      "step": 207680
    },
    {
      "epoch": 335.0,
      "learning_rate": 0.06651342058338709,
      "loss": 0.8568,
      "step": 207700
    },
    {
      "epoch": 335.0,
      "eval_accuracy": {
        "accuracy": 0.7470923425181485
      },
      "eval_loss": 1.2336480617523193,
      "eval_runtime": 2.714,
      "eval_samples_per_second": 4720.363,
      "eval_steps_per_second": 74.061,
      "step": 207700
    },
    {
      "epoch": 335.03,
      "learning_rate": 0.06651019478016129,
      "loss": 0.8776,
      "step": 207720
    },
    {
      "epoch": 335.06,
      "learning_rate": 0.06650696897693549,
      "loss": 0.8352,
      "step": 207740
    },
    {
      "epoch": 335.1,
      "learning_rate": 0.06650374317370968,
      "loss": 0.8217,
      "step": 207760
    },
    {
      "epoch": 335.13,
      "learning_rate": 0.06650051737048387,
      "loss": 0.8513,
      "step": 207780
    },
    {
      "epoch": 335.16,
      "learning_rate": 0.06649729156725807,
      "loss": 0.8205,
      "step": 207800
    },
    {
      "epoch": 335.19,
      "learning_rate": 0.06649406576403226,
      "loss": 0.8338,
      "step": 207820
    },
    {
      "epoch": 335.23,
      "learning_rate": 0.06649083996080646,
      "loss": 0.8004,
      "step": 207840
    },
    {
      "epoch": 335.26,
      "learning_rate": 0.06648761415758066,
      "loss": 0.8421,
      "step": 207860
    },
    {
      "epoch": 335.29,
      "learning_rate": 0.06648438835435483,
      "loss": 0.829,
      "step": 207880
    },
    {
      "epoch": 335.32,
      "learning_rate": 0.06648116255112904,
      "loss": 0.8499,
      "step": 207900
    },
    {
      "epoch": 335.35,
      "learning_rate": 0.06647793674790323,
      "loss": 0.8367,
      "step": 207920
    },
    {
      "epoch": 335.39,
      "learning_rate": 0.06647471094467743,
      "loss": 0.8375,
      "step": 207940
    },
    {
      "epoch": 335.42,
      "learning_rate": 0.06647148514145161,
      "loss": 0.8468,
      "step": 207960
    },
    {
      "epoch": 335.45,
      "learning_rate": 0.06646825933822582,
      "loss": 0.8507,
      "step": 207980
    },
    {
      "epoch": 335.48,
      "learning_rate": 0.066465033535,
      "loss": 0.8464,
      "step": 208000
    },
    {
      "epoch": 335.52,
      "learning_rate": 0.06646180773177421,
      "loss": 0.8635,
      "step": 208020
    },
    {
      "epoch": 335.55,
      "learning_rate": 0.0664585819285484,
      "loss": 0.8486,
      "step": 208040
    },
    {
      "epoch": 335.58,
      "learning_rate": 0.06645535612532258,
      "loss": 0.8208,
      "step": 208060
    },
    {
      "epoch": 335.61,
      "learning_rate": 0.06645213032209678,
      "loss": 0.8262,
      "step": 208080
    },
    {
      "epoch": 335.65,
      "learning_rate": 0.06644890451887098,
      "loss": 0.8597,
      "step": 208100
    },
    {
      "epoch": 335.68,
      "learning_rate": 0.06644567871564516,
      "loss": 0.8522,
      "step": 208120
    },
    {
      "epoch": 335.71,
      "learning_rate": 0.06644245291241936,
      "loss": 0.8453,
      "step": 208140
    },
    {
      "epoch": 335.74,
      "learning_rate": 0.06643922710919356,
      "loss": 0.8532,
      "step": 208160
    },
    {
      "epoch": 335.77,
      "learning_rate": 0.06643600130596775,
      "loss": 0.8596,
      "step": 208180
    },
    {
      "epoch": 335.81,
      "learning_rate": 0.06643277550274194,
      "loss": 0.8486,
      "step": 208200
    },
    {
      "epoch": 335.84,
      "learning_rate": 0.06642954969951613,
      "loss": 0.83,
      "step": 208220
    },
    {
      "epoch": 335.87,
      "learning_rate": 0.06642632389629033,
      "loss": 0.834,
      "step": 208240
    },
    {
      "epoch": 335.9,
      "learning_rate": 0.06642309809306451,
      "loss": 0.8595,
      "step": 208260
    },
    {
      "epoch": 335.94,
      "learning_rate": 0.06641987228983873,
      "loss": 0.8522,
      "step": 208280
    },
    {
      "epoch": 335.97,
      "learning_rate": 0.0664166464866129,
      "loss": 0.8473,
      "step": 208300
    },
    {
      "epoch": 336.0,
      "learning_rate": 0.0664135819735484,
      "loss": 0.8534,
      "step": 208320
    },
    {
      "epoch": 336.0,
      "eval_accuracy": {
        "accuracy": 0.7491999063304973
      },
      "eval_loss": 1.2212283611297607,
      "eval_runtime": 2.7272,
      "eval_samples_per_second": 4697.455,
      "eval_steps_per_second": 73.701,
      "step": 208320
    },
    {
      "epoch": 336.03,
      "learning_rate": 0.0664103561703226,
      "loss": 0.8255,
      "step": 208340
    },
    {
      "epoch": 336.06,
      "learning_rate": 0.06640713036709678,
      "loss": 0.82,
      "step": 208360
    },
    {
      "epoch": 336.1,
      "learning_rate": 0.06640390456387098,
      "loss": 0.8352,
      "step": 208380
    },
    {
      "epoch": 336.13,
      "learning_rate": 0.06640067876064516,
      "loss": 0.8147,
      "step": 208400
    },
    {
      "epoch": 336.16,
      "learning_rate": 0.06639745295741936,
      "loss": 0.8274,
      "step": 208420
    },
    {
      "epoch": 336.19,
      "learning_rate": 0.06639422715419355,
      "loss": 0.8159,
      "step": 208440
    },
    {
      "epoch": 336.23,
      "learning_rate": 0.06639100135096776,
      "loss": 0.829,
      "step": 208460
    },
    {
      "epoch": 336.26,
      "learning_rate": 0.06638777554774193,
      "loss": 0.8361,
      "step": 208480
    },
    {
      "epoch": 336.29,
      "learning_rate": 0.06638454974451613,
      "loss": 0.806,
      "step": 208500
    },
    {
      "epoch": 336.32,
      "learning_rate": 0.06638132394129033,
      "loss": 0.8108,
      "step": 208520
    },
    {
      "epoch": 336.35,
      "learning_rate": 0.06637809813806451,
      "loss": 0.8324,
      "step": 208540
    },
    {
      "epoch": 336.39,
      "learning_rate": 0.06637487233483871,
      "loss": 0.8326,
      "step": 208560
    },
    {
      "epoch": 336.42,
      "learning_rate": 0.06637164653161291,
      "loss": 0.8397,
      "step": 208580
    },
    {
      "epoch": 336.45,
      "learning_rate": 0.0663684207283871,
      "loss": 0.8366,
      "step": 208600
    },
    {
      "epoch": 336.48,
      "learning_rate": 0.0663651949251613,
      "loss": 0.8495,
      "step": 208620
    },
    {
      "epoch": 336.52,
      "learning_rate": 0.0663619691219355,
      "loss": 0.8429,
      "step": 208640
    },
    {
      "epoch": 336.55,
      "learning_rate": 0.06635874331870968,
      "loss": 0.8395,
      "step": 208660
    },
    {
      "epoch": 336.58,
      "learning_rate": 0.06635551751548388,
      "loss": 0.843,
      "step": 208680
    },
    {
      "epoch": 336.61,
      "learning_rate": 0.06635229171225807,
      "loss": 0.8414,
      "step": 208700
    },
    {
      "epoch": 336.65,
      "learning_rate": 0.06634906590903226,
      "loss": 0.8525,
      "step": 208720
    },
    {
      "epoch": 336.68,
      "learning_rate": 0.06634584010580645,
      "loss": 0.8394,
      "step": 208740
    },
    {
      "epoch": 336.71,
      "learning_rate": 0.06634261430258066,
      "loss": 0.8565,
      "step": 208760
    },
    {
      "epoch": 336.74,
      "learning_rate": 0.06633938849935483,
      "loss": 0.8385,
      "step": 208780
    },
    {
      "epoch": 336.77,
      "learning_rate": 0.06633616269612903,
      "loss": 0.8558,
      "step": 208800
    },
    {
      "epoch": 336.81,
      "learning_rate": 0.06633293689290323,
      "loss": 0.8373,
      "step": 208820
    },
    {
      "epoch": 336.84,
      "learning_rate": 0.06632971108967742,
      "loss": 0.8584,
      "step": 208840
    },
    {
      "epoch": 336.87,
      "learning_rate": 0.06632648528645162,
      "loss": 0.8346,
      "step": 208860
    },
    {
      "epoch": 336.9,
      "learning_rate": 0.06632325948322582,
      "loss": 0.8285,
      "step": 208880
    },
    {
      "epoch": 336.94,
      "learning_rate": 0.06632003368,
      "loss": 0.8216,
      "step": 208900
    },
    {
      "epoch": 336.97,
      "learning_rate": 0.0663168078767742,
      "loss": 0.8459,
      "step": 208920
    },
    {
      "epoch": 337.0,
      "learning_rate": 0.0663135820735484,
      "loss": 0.8587,
      "step": 208940
    },
    {
      "epoch": 337.0,
      "eval_accuracy": {
        "accuracy": 0.7551323081726641
      },
      "eval_loss": 1.1914921998977661,
      "eval_runtime": 2.9889,
      "eval_samples_per_second": 4286.179,
      "eval_steps_per_second": 67.249,
      "step": 208940
    },
    {
      "epoch": 337.03,
      "learning_rate": 0.06631035627032257,
      "loss": 0.8464,
      "step": 208960
    },
    {
      "epoch": 337.06,
      "learning_rate": 0.06630713046709678,
      "loss": 0.8115,
      "step": 208980
    },
    {
      "epoch": 337.1,
      "learning_rate": 0.06630390466387097,
      "loss": 0.8337,
      "step": 209000
    },
    {
      "epoch": 337.13,
      "learning_rate": 0.06630067886064517,
      "loss": 0.8228,
      "step": 209020
    },
    {
      "epoch": 337.16,
      "learning_rate": 0.06629745305741935,
      "loss": 0.839,
      "step": 209040
    },
    {
      "epoch": 337.19,
      "learning_rate": 0.06629422725419357,
      "loss": 0.83,
      "step": 209060
    },
    {
      "epoch": 337.23,
      "learning_rate": 0.06629100145096774,
      "loss": 0.8381,
      "step": 209080
    },
    {
      "epoch": 337.26,
      "learning_rate": 0.06628777564774195,
      "loss": 0.8464,
      "step": 209100
    },
    {
      "epoch": 337.29,
      "learning_rate": 0.06628454984451614,
      "loss": 0.8452,
      "step": 209120
    },
    {
      "epoch": 337.32,
      "learning_rate": 0.06628132404129032,
      "loss": 0.8035,
      "step": 209140
    },
    {
      "epoch": 337.35,
      "learning_rate": 0.06627809823806452,
      "loss": 0.8517,
      "step": 209160
    },
    {
      "epoch": 337.39,
      "learning_rate": 0.06627487243483872,
      "loss": 0.8428,
      "step": 209180
    },
    {
      "epoch": 337.42,
      "learning_rate": 0.0662716466316129,
      "loss": 0.8577,
      "step": 209200
    },
    {
      "epoch": 337.45,
      "learning_rate": 0.0662684208283871,
      "loss": 0.8527,
      "step": 209220
    },
    {
      "epoch": 337.48,
      "learning_rate": 0.0662651950251613,
      "loss": 0.8157,
      "step": 209240
    },
    {
      "epoch": 337.52,
      "learning_rate": 0.06626196922193547,
      "loss": 0.8117,
      "step": 209260
    },
    {
      "epoch": 337.55,
      "learning_rate": 0.06625874341870969,
      "loss": 0.8212,
      "step": 209280
    },
    {
      "epoch": 337.58,
      "learning_rate": 0.06625551761548387,
      "loss": 0.8451,
      "step": 209300
    },
    {
      "epoch": 337.61,
      "learning_rate": 0.06625229181225807,
      "loss": 0.8412,
      "step": 209320
    },
    {
      "epoch": 337.65,
      "learning_rate": 0.06624906600903226,
      "loss": 0.844,
      "step": 209340
    },
    {
      "epoch": 337.68,
      "learning_rate": 0.06624584020580647,
      "loss": 0.8237,
      "step": 209360
    },
    {
      "epoch": 337.71,
      "learning_rate": 0.06624261440258064,
      "loss": 0.8546,
      "step": 209380
    },
    {
      "epoch": 337.74,
      "learning_rate": 0.06623938859935485,
      "loss": 0.8556,
      "step": 209400
    },
    {
      "epoch": 337.77,
      "learning_rate": 0.06623616279612904,
      "loss": 0.8165,
      "step": 209420
    },
    {
      "epoch": 337.81,
      "learning_rate": 0.06623293699290322,
      "loss": 0.8047,
      "step": 209440
    },
    {
      "epoch": 337.84,
      "learning_rate": 0.06622971118967742,
      "loss": 0.8556,
      "step": 209460
    },
    {
      "epoch": 337.87,
      "learning_rate": 0.06622648538645162,
      "loss": 0.8709,
      "step": 209480
    },
    {
      "epoch": 337.9,
      "learning_rate": 0.06622325958322581,
      "loss": 0.8515,
      "step": 209500
    },
    {
      "epoch": 337.94,
      "learning_rate": 0.06622003378,
      "loss": 0.842,
      "step": 209520
    },
    {
      "epoch": 337.97,
      "learning_rate": 0.0662168079767742,
      "loss": 0.8584,
      "step": 209540
    },
    {
      "epoch": 338.0,
      "learning_rate": 0.06621358217354839,
      "loss": 0.8423,
      "step": 209560
    },
    {
      "epoch": 338.0,
      "eval_accuracy": {
        "accuracy": 0.7481851533838108
      },
      "eval_loss": 1.2227015495300293,
      "eval_runtime": 2.7419,
      "eval_samples_per_second": 4672.365,
      "eval_steps_per_second": 73.308,
      "step": 209560
    },
    {
      "epoch": 338.03,
      "learning_rate": 0.06621035637032259,
      "loss": 0.8471,
      "step": 209580
    },
    {
      "epoch": 338.06,
      "learning_rate": 0.06620713056709678,
      "loss": 0.839,
      "step": 209600
    },
    {
      "epoch": 338.1,
      "learning_rate": 0.06620390476387097,
      "loss": 0.807,
      "step": 209620
    },
    {
      "epoch": 338.13,
      "learning_rate": 0.06620067896064516,
      "loss": 0.8144,
      "step": 209640
    },
    {
      "epoch": 338.16,
      "learning_rate": 0.06619745315741936,
      "loss": 0.8221,
      "step": 209660
    },
    {
      "epoch": 338.19,
      "learning_rate": 0.06619422735419354,
      "loss": 0.8164,
      "step": 209680
    },
    {
      "epoch": 338.23,
      "learning_rate": 0.06619100155096776,
      "loss": 0.8277,
      "step": 209700
    },
    {
      "epoch": 338.26,
      "learning_rate": 0.06618777574774194,
      "loss": 0.8287,
      "step": 209720
    },
    {
      "epoch": 338.29,
      "learning_rate": 0.06618454994451613,
      "loss": 0.8234,
      "step": 209740
    },
    {
      "epoch": 338.32,
      "learning_rate": 0.06618132414129033,
      "loss": 0.8084,
      "step": 209760
    },
    {
      "epoch": 338.35,
      "learning_rate": 0.06617809833806453,
      "loss": 0.8371,
      "step": 209780
    },
    {
      "epoch": 338.39,
      "learning_rate": 0.06617487253483871,
      "loss": 0.854,
      "step": 209800
    },
    {
      "epoch": 338.42,
      "learning_rate": 0.06617164673161291,
      "loss": 0.8515,
      "step": 209820
    },
    {
      "epoch": 338.45,
      "learning_rate": 0.06616842092838711,
      "loss": 0.8338,
      "step": 209840
    },
    {
      "epoch": 338.48,
      "learning_rate": 0.0661651951251613,
      "loss": 0.8409,
      "step": 209860
    },
    {
      "epoch": 338.52,
      "learning_rate": 0.0661619693219355,
      "loss": 0.8273,
      "step": 209880
    },
    {
      "epoch": 338.55,
      "learning_rate": 0.06615874351870968,
      "loss": 0.8441,
      "step": 209900
    },
    {
      "epoch": 338.58,
      "learning_rate": 0.06615551771548388,
      "loss": 0.8474,
      "step": 209920
    },
    {
      "epoch": 338.61,
      "learning_rate": 0.06615229191225806,
      "loss": 0.8412,
      "step": 209940
    },
    {
      "epoch": 338.65,
      "learning_rate": 0.06614906610903226,
      "loss": 0.8614,
      "step": 209960
    },
    {
      "epoch": 338.68,
      "learning_rate": 0.06614584030580645,
      "loss": 0.8362,
      "step": 209980
    },
    {
      "epoch": 338.71,
      "learning_rate": 0.06614261450258066,
      "loss": 0.8571,
      "step": 210000
    },
    {
      "epoch": 338.74,
      "learning_rate": 0.06613938869935485,
      "loss": 0.8513,
      "step": 210020
    },
    {
      "epoch": 338.77,
      "learning_rate": 0.06613616289612903,
      "loss": 0.8587,
      "step": 210040
    },
    {
      "epoch": 338.81,
      "learning_rate": 0.06613293709290323,
      "loss": 0.8534,
      "step": 210060
    },
    {
      "epoch": 338.84,
      "learning_rate": 0.06612971128967743,
      "loss": 0.8161,
      "step": 210080
    },
    {
      "epoch": 338.87,
      "learning_rate": 0.06612648548645161,
      "loss": 0.8191,
      "step": 210100
    },
    {
      "epoch": 338.9,
      "learning_rate": 0.06612325968322581,
      "loss": 0.8376,
      "step": 210120
    },
    {
      "epoch": 338.94,
      "learning_rate": 0.06612003388000001,
      "loss": 0.8499,
      "step": 210140
    },
    {
      "epoch": 338.97,
      "learning_rate": 0.0661168080767742,
      "loss": 0.8511,
      "step": 210160
    },
    {
      "epoch": 339.0,
      "learning_rate": 0.0661135822735484,
      "loss": 0.8597,
      "step": 210180
    },
    {
      "epoch": 339.0,
      "eval_accuracy": {
        "accuracy": 0.7469362266801967
      },
      "eval_loss": 1.2282594442367554,
      "eval_runtime": 2.9331,
      "eval_samples_per_second": 4367.781,
      "eval_steps_per_second": 68.529,
      "step": 210180
    },
    {
      "epoch": 339.03,
      "learning_rate": 0.06611035647032258,
      "loss": 0.868,
      "step": 210200
    },
    {
      "epoch": 339.06,
      "learning_rate": 0.06610713066709678,
      "loss": 0.8291,
      "step": 210220
    },
    {
      "epoch": 339.1,
      "learning_rate": 0.06610390486387097,
      "loss": 0.8178,
      "step": 210240
    },
    {
      "epoch": 339.13,
      "learning_rate": 0.06610067906064516,
      "loss": 0.837,
      "step": 210260
    },
    {
      "epoch": 339.16,
      "learning_rate": 0.06609745325741935,
      "loss": 0.8477,
      "step": 210280
    },
    {
      "epoch": 339.19,
      "learning_rate": 0.06609422745419356,
      "loss": 0.8282,
      "step": 210300
    },
    {
      "epoch": 339.23,
      "learning_rate": 0.06609100165096775,
      "loss": 0.8374,
      "step": 210320
    },
    {
      "epoch": 339.26,
      "learning_rate": 0.06608777584774195,
      "loss": 0.8087,
      "step": 210340
    },
    {
      "epoch": 339.29,
      "learning_rate": 0.06608455004451613,
      "loss": 0.847,
      "step": 210360
    },
    {
      "epoch": 339.32,
      "learning_rate": 0.06608132424129033,
      "loss": 0.8402,
      "step": 210380
    },
    {
      "epoch": 339.35,
      "learning_rate": 0.06607809843806452,
      "loss": 0.8569,
      "step": 210400
    },
    {
      "epoch": 339.39,
      "learning_rate": 0.06607487263483872,
      "loss": 0.8173,
      "step": 210420
    },
    {
      "epoch": 339.42,
      "learning_rate": 0.06607164683161292,
      "loss": 0.8451,
      "step": 210440
    },
    {
      "epoch": 339.45,
      "learning_rate": 0.0660684210283871,
      "loss": 0.8435,
      "step": 210460
    },
    {
      "epoch": 339.48,
      "learning_rate": 0.0660651952251613,
      "loss": 0.838,
      "step": 210480
    },
    {
      "epoch": 339.52,
      "learning_rate": 0.06606196942193548,
      "loss": 0.8494,
      "step": 210500
    },
    {
      "epoch": 339.55,
      "learning_rate": 0.06605874361870968,
      "loss": 0.8245,
      "step": 210520
    },
    {
      "epoch": 339.58,
      "learning_rate": 0.06605551781548387,
      "loss": 0.8405,
      "step": 210540
    },
    {
      "epoch": 339.61,
      "learning_rate": 0.06605229201225807,
      "loss": 0.8254,
      "step": 210560
    },
    {
      "epoch": 339.65,
      "learning_rate": 0.06604906620903225,
      "loss": 0.837,
      "step": 210580
    },
    {
      "epoch": 339.68,
      "learning_rate": 0.06604584040580647,
      "loss": 0.853,
      "step": 210600
    },
    {
      "epoch": 339.71,
      "learning_rate": 0.06604261460258065,
      "loss": 0.8499,
      "step": 210620
    },
    {
      "epoch": 339.74,
      "learning_rate": 0.06603938879935485,
      "loss": 0.8429,
      "step": 210640
    },
    {
      "epoch": 339.77,
      "learning_rate": 0.06603616299612904,
      "loss": 0.8188,
      "step": 210660
    },
    {
      "epoch": 339.81,
      "learning_rate": 0.06603293719290323,
      "loss": 0.8429,
      "step": 210680
    },
    {
      "epoch": 339.84,
      "learning_rate": 0.06602971138967742,
      "loss": 0.8331,
      "step": 210700
    },
    {
      "epoch": 339.87,
      "learning_rate": 0.06602648558645162,
      "loss": 0.8433,
      "step": 210720
    },
    {
      "epoch": 339.9,
      "learning_rate": 0.0660232597832258,
      "loss": 0.8537,
      "step": 210740
    },
    {
      "epoch": 339.94,
      "learning_rate": 0.06602003398,
      "loss": 0.8213,
      "step": 210760
    },
    {
      "epoch": 339.97,
      "learning_rate": 0.0660168081767742,
      "loss": 0.8294,
      "step": 210780
    },
    {
      "epoch": 340.0,
      "learning_rate": 0.06601358237354839,
      "loss": 0.8223,
      "step": 210800
    },
    {
      "epoch": 340.0,
      "eval_accuracy": {
        "accuracy": 0.7470923425181485
      },
      "eval_loss": 1.2393664121627808,
      "eval_runtime": 2.8811,
      "eval_samples_per_second": 4446.499,
      "eval_steps_per_second": 69.764,
      "step": 210800
    },
    {
      "epoch": 340.03,
      "learning_rate": 0.06601035657032259,
      "loss": 0.8607,
      "step": 210820
    },
    {
      "epoch": 340.06,
      "learning_rate": 0.06600713076709677,
      "loss": 0.8273,
      "step": 210840
    },
    {
      "epoch": 340.1,
      "learning_rate": 0.06600390496387097,
      "loss": 0.8035,
      "step": 210860
    },
    {
      "epoch": 340.13,
      "learning_rate": 0.06600067916064516,
      "loss": 0.8358,
      "step": 210880
    },
    {
      "epoch": 340.16,
      "learning_rate": 0.06599745335741937,
      "loss": 0.8208,
      "step": 210900
    },
    {
      "epoch": 340.19,
      "learning_rate": 0.06599422755419355,
      "loss": 0.8257,
      "step": 210920
    },
    {
      "epoch": 340.23,
      "learning_rate": 0.06599100175096775,
      "loss": 0.8124,
      "step": 210940
    },
    {
      "epoch": 340.26,
      "learning_rate": 0.06598777594774194,
      "loss": 0.812,
      "step": 210960
    },
    {
      "epoch": 340.29,
      "learning_rate": 0.06598455014451614,
      "loss": 0.8165,
      "step": 210980
    },
    {
      "epoch": 340.32,
      "learning_rate": 0.06598132434129032,
      "loss": 0.7999,
      "step": 211000
    },
    {
      "epoch": 340.35,
      "learning_rate": 0.06597809853806452,
      "loss": 0.8093,
      "step": 211020
    },
    {
      "epoch": 340.39,
      "learning_rate": 0.06597487273483871,
      "loss": 0.8383,
      "step": 211040
    },
    {
      "epoch": 340.42,
      "learning_rate": 0.0659716469316129,
      "loss": 0.8415,
      "step": 211060
    },
    {
      "epoch": 340.45,
      "learning_rate": 0.0659684211283871,
      "loss": 0.8416,
      "step": 211080
    },
    {
      "epoch": 340.48,
      "learning_rate": 0.06596519532516129,
      "loss": 0.8507,
      "step": 211100
    },
    {
      "epoch": 340.52,
      "learning_rate": 0.06596196952193549,
      "loss": 0.8383,
      "step": 211120
    },
    {
      "epoch": 340.55,
      "learning_rate": 0.06595874371870968,
      "loss": 0.8484,
      "step": 211140
    },
    {
      "epoch": 340.58,
      "learning_rate": 0.06595551791548387,
      "loss": 0.8195,
      "step": 211160
    },
    {
      "epoch": 340.61,
      "learning_rate": 0.06595229211225806,
      "loss": 0.8305,
      "step": 211180
    },
    {
      "epoch": 340.65,
      "learning_rate": 0.06594906630903227,
      "loss": 0.8393,
      "step": 211200
    },
    {
      "epoch": 340.68,
      "learning_rate": 0.06594584050580646,
      "loss": 0.8309,
      "step": 211220
    },
    {
      "epoch": 340.71,
      "learning_rate": 0.06594261470258066,
      "loss": 0.824,
      "step": 211240
    },
    {
      "epoch": 340.74,
      "learning_rate": 0.06593938889935484,
      "loss": 0.8285,
      "step": 211260
    },
    {
      "epoch": 340.77,
      "learning_rate": 0.06593616309612903,
      "loss": 0.8311,
      "step": 211280
    },
    {
      "epoch": 340.81,
      "learning_rate": 0.06593293729290323,
      "loss": 0.8547,
      "step": 211300
    },
    {
      "epoch": 340.84,
      "learning_rate": 0.06592971148967743,
      "loss": 0.8411,
      "step": 211320
    },
    {
      "epoch": 340.87,
      "learning_rate": 0.06592648568645161,
      "loss": 0.8265,
      "step": 211340
    },
    {
      "epoch": 340.9,
      "learning_rate": 0.06592325988322581,
      "loss": 0.8416,
      "step": 211360
    },
    {
      "epoch": 340.94,
      "learning_rate": 0.06592003408000001,
      "loss": 0.8413,
      "step": 211380
    },
    {
      "epoch": 340.97,
      "learning_rate": 0.0659168082767742,
      "loss": 0.8426,
      "step": 211400
    },
    {
      "epoch": 341.0,
      "learning_rate": 0.06591374376370969,
      "loss": 0.86,
      "step": 211420
    },
    {
      "epoch": 341.0,
      "eval_accuracy": {
        "accuracy": 0.752634454765436
      },
      "eval_loss": 1.1906899213790894,
      "eval_runtime": 2.8569,
      "eval_samples_per_second": 4484.282,
      "eval_steps_per_second": 70.357,
      "step": 211420
    },
    {
      "epoch": 341.03,
      "learning_rate": 0.06591051796048387,
      "loss": 0.8158,
      "step": 211440
    },
    {
      "epoch": 341.06,
      "learning_rate": 0.06590729215725807,
      "loss": 0.8159,
      "step": 211460
    },
    {
      "epoch": 341.1,
      "learning_rate": 0.06590406635403226,
      "loss": 0.826,
      "step": 211480
    },
    {
      "epoch": 341.13,
      "learning_rate": 0.06590084055080646,
      "loss": 0.8182,
      "step": 211500
    },
    {
      "epoch": 341.16,
      "learning_rate": 0.06589761474758066,
      "loss": 0.8342,
      "step": 211520
    },
    {
      "epoch": 341.19,
      "learning_rate": 0.06589438894435484,
      "loss": 0.8418,
      "step": 211540
    },
    {
      "epoch": 341.23,
      "learning_rate": 0.06589116314112904,
      "loss": 0.8481,
      "step": 211560
    },
    {
      "epoch": 341.26,
      "learning_rate": 0.06588793733790323,
      "loss": 0.8142,
      "step": 211580
    },
    {
      "epoch": 341.29,
      "learning_rate": 0.06588471153467743,
      "loss": 0.8268,
      "step": 211600
    },
    {
      "epoch": 341.32,
      "learning_rate": 0.06588148573145161,
      "loss": 0.8342,
      "step": 211620
    },
    {
      "epoch": 341.35,
      "learning_rate": 0.06587825992822581,
      "loss": 0.8153,
      "step": 211640
    },
    {
      "epoch": 341.39,
      "learning_rate": 0.065875034125,
      "loss": 0.8313,
      "step": 211660
    },
    {
      "epoch": 341.42,
      "learning_rate": 0.06587180832177421,
      "loss": 0.8458,
      "step": 211680
    },
    {
      "epoch": 341.45,
      "learning_rate": 0.0658685825185484,
      "loss": 0.8526,
      "step": 211700
    },
    {
      "epoch": 341.48,
      "learning_rate": 0.06586535671532259,
      "loss": 0.8503,
      "step": 211720
    },
    {
      "epoch": 341.52,
      "learning_rate": 0.06586213091209678,
      "loss": 0.8245,
      "step": 211740
    },
    {
      "epoch": 341.55,
      "learning_rate": 0.06585890510887098,
      "loss": 0.8008,
      "step": 211760
    },
    {
      "epoch": 341.58,
      "learning_rate": 0.06585567930564516,
      "loss": 0.8456,
      "step": 211780
    },
    {
      "epoch": 341.61,
      "learning_rate": 0.06585245350241936,
      "loss": 0.8224,
      "step": 211800
    },
    {
      "epoch": 341.65,
      "learning_rate": 0.06584922769919355,
      "loss": 0.8242,
      "step": 211820
    },
    {
      "epoch": 341.68,
      "learning_rate": 0.06584600189596775,
      "loss": 0.8252,
      "step": 211840
    },
    {
      "epoch": 341.71,
      "learning_rate": 0.06584277609274194,
      "loss": 0.8422,
      "step": 211860
    },
    {
      "epoch": 341.74,
      "learning_rate": 0.06583955028951613,
      "loss": 0.8282,
      "step": 211880
    },
    {
      "epoch": 341.77,
      "learning_rate": 0.06583632448629033,
      "loss": 0.8251,
      "step": 211900
    },
    {
      "epoch": 341.81,
      "learning_rate": 0.06583309868306451,
      "loss": 0.8208,
      "step": 211920
    },
    {
      "epoch": 341.84,
      "learning_rate": 0.06582987287983871,
      "loss": 0.8377,
      "step": 211940
    },
    {
      "epoch": 341.87,
      "learning_rate": 0.0658266470766129,
      "loss": 0.8567,
      "step": 211960
    },
    {
      "epoch": 341.9,
      "learning_rate": 0.06582342127338711,
      "loss": 0.844,
      "step": 211980
    },
    {
      "epoch": 341.94,
      "learning_rate": 0.0658201954701613,
      "loss": 0.8229,
      "step": 212000
    },
    {
      "epoch": 341.97,
      "learning_rate": 0.0658169696669355,
      "loss": 0.813,
      "step": 212020
    },
    {
      "epoch": 342.0,
      "learning_rate": 0.06581374386370968,
      "loss": 0.8396,
      "step": 212040
    },
    {
      "epoch": 342.0,
      "eval_accuracy": {
        "accuracy": 0.7474826321130279
      },
      "eval_loss": 1.2465295791625977,
      "eval_runtime": 2.8866,
      "eval_samples_per_second": 4438.097,
      "eval_steps_per_second": 69.632,
      "step": 212040
    },
    {
      "epoch": 342.03,
      "learning_rate": 0.06581051806048388,
      "loss": 0.8578,
      "step": 212060
    },
    {
      "epoch": 342.06,
      "learning_rate": 0.06580729225725807,
      "loss": 0.8304,
      "step": 212080
    },
    {
      "epoch": 342.1,
      "learning_rate": 0.06580406645403226,
      "loss": 0.8128,
      "step": 212100
    },
    {
      "epoch": 342.13,
      "learning_rate": 0.06580084065080645,
      "loss": 0.8031,
      "step": 212120
    },
    {
      "epoch": 342.16,
      "learning_rate": 0.06579761484758065,
      "loss": 0.8101,
      "step": 212140
    },
    {
      "epoch": 342.19,
      "learning_rate": 0.06579438904435485,
      "loss": 0.8381,
      "step": 212160
    },
    {
      "epoch": 342.23,
      "learning_rate": 0.06579116324112903,
      "loss": 0.835,
      "step": 212180
    },
    {
      "epoch": 342.26,
      "learning_rate": 0.06578793743790323,
      "loss": 0.8199,
      "step": 212200
    },
    {
      "epoch": 342.29,
      "learning_rate": 0.06578471163467742,
      "loss": 0.8156,
      "step": 212220
    },
    {
      "epoch": 342.32,
      "learning_rate": 0.06578148583145162,
      "loss": 0.817,
      "step": 212240
    },
    {
      "epoch": 342.35,
      "learning_rate": 0.0657782600282258,
      "loss": 0.8137,
      "step": 212260
    },
    {
      "epoch": 342.39,
      "learning_rate": 0.06577503422500001,
      "loss": 0.8458,
      "step": 212280
    },
    {
      "epoch": 342.42,
      "learning_rate": 0.0657718084217742,
      "loss": 0.8183,
      "step": 212300
    },
    {
      "epoch": 342.45,
      "learning_rate": 0.0657685826185484,
      "loss": 0.8441,
      "step": 212320
    },
    {
      "epoch": 342.48,
      "learning_rate": 0.06576535681532258,
      "loss": 0.8397,
      "step": 212340
    },
    {
      "epoch": 342.52,
      "learning_rate": 0.06576213101209677,
      "loss": 0.8334,
      "step": 212360
    },
    {
      "epoch": 342.55,
      "learning_rate": 0.06575890520887097,
      "loss": 0.8521,
      "step": 212380
    },
    {
      "epoch": 342.58,
      "learning_rate": 0.06575567940564517,
      "loss": 0.8583,
      "step": 212400
    },
    {
      "epoch": 342.61,
      "learning_rate": 0.06575245360241935,
      "loss": 0.8353,
      "step": 212420
    },
    {
      "epoch": 342.65,
      "learning_rate": 0.06574922779919355,
      "loss": 0.8349,
      "step": 212440
    },
    {
      "epoch": 342.68,
      "learning_rate": 0.06574600199596775,
      "loss": 0.8243,
      "step": 212460
    },
    {
      "epoch": 342.71,
      "learning_rate": 0.06574277619274194,
      "loss": 0.825,
      "step": 212480
    },
    {
      "epoch": 342.74,
      "learning_rate": 0.06573955038951614,
      "loss": 0.8506,
      "step": 212500
    },
    {
      "epoch": 342.77,
      "learning_rate": 0.06573632458629032,
      "loss": 0.8542,
      "step": 212520
    },
    {
      "epoch": 342.81,
      "learning_rate": 0.06573309878306452,
      "loss": 0.8333,
      "step": 212540
    },
    {
      "epoch": 342.84,
      "learning_rate": 0.0657298729798387,
      "loss": 0.8546,
      "step": 212560
    },
    {
      "epoch": 342.87,
      "learning_rate": 0.06572664717661292,
      "loss": 0.8578,
      "step": 212580
    },
    {
      "epoch": 342.9,
      "learning_rate": 0.0657234213733871,
      "loss": 0.8702,
      "step": 212600
    },
    {
      "epoch": 342.94,
      "learning_rate": 0.0657201955701613,
      "loss": 0.8701,
      "step": 212620
    },
    {
      "epoch": 342.97,
      "learning_rate": 0.06571696976693549,
      "loss": 0.8346,
      "step": 212640
    },
    {
      "epoch": 343.0,
      "learning_rate": 0.06571374396370969,
      "loss": 0.841,
      "step": 212660
    },
    {
      "epoch": 343.0,
      "eval_accuracy": {
        "accuracy": 0.7550542502536882
      },
      "eval_loss": 1.1671416759490967,
      "eval_runtime": 2.942,
      "eval_samples_per_second": 4354.453,
      "eval_steps_per_second": 68.32,
      "step": 212660
    },
    {
      "epoch": 343.03,
      "learning_rate": 0.06571051816048387,
      "loss": 0.8385,
      "step": 212680
    },
    {
      "epoch": 343.06,
      "learning_rate": 0.06570729235725807,
      "loss": 0.8113,
      "step": 212700
    },
    {
      "epoch": 343.1,
      "learning_rate": 0.06570406655403226,
      "loss": 0.8059,
      "step": 212720
    },
    {
      "epoch": 343.13,
      "learning_rate": 0.06570084075080646,
      "loss": 0.8329,
      "step": 212740
    },
    {
      "epoch": 343.16,
      "learning_rate": 0.06569761494758065,
      "loss": 0.8149,
      "step": 212760
    },
    {
      "epoch": 343.19,
      "learning_rate": 0.06569438914435484,
      "loss": 0.813,
      "step": 212780
    },
    {
      "epoch": 343.23,
      "learning_rate": 0.06569116334112904,
      "loss": 0.8332,
      "step": 212800
    },
    {
      "epoch": 343.26,
      "learning_rate": 0.06568793753790324,
      "loss": 0.8556,
      "step": 212820
    },
    {
      "epoch": 343.29,
      "learning_rate": 0.06568471173467742,
      "loss": 0.8374,
      "step": 212840
    },
    {
      "epoch": 343.32,
      "learning_rate": 0.06568148593145161,
      "loss": 0.7894,
      "step": 212860
    },
    {
      "epoch": 343.35,
      "learning_rate": 0.06567826012822582,
      "loss": 0.8026,
      "step": 212880
    },
    {
      "epoch": 343.39,
      "learning_rate": 0.06567503432499999,
      "loss": 0.8395,
      "step": 212900
    },
    {
      "epoch": 343.42,
      "learning_rate": 0.0656718085217742,
      "loss": 0.8472,
      "step": 212920
    },
    {
      "epoch": 343.45,
      "learning_rate": 0.06566858271854839,
      "loss": 0.8235,
      "step": 212940
    },
    {
      "epoch": 343.48,
      "learning_rate": 0.06566535691532259,
      "loss": 0.8285,
      "step": 212960
    },
    {
      "epoch": 343.52,
      "learning_rate": 0.06566213111209677,
      "loss": 0.8255,
      "step": 212980
    },
    {
      "epoch": 343.55,
      "learning_rate": 0.06565890530887097,
      "loss": 0.8153,
      "step": 213000
    },
    {
      "epoch": 343.58,
      "learning_rate": 0.06565567950564516,
      "loss": 0.8142,
      "step": 213020
    },
    {
      "epoch": 343.61,
      "learning_rate": 0.06565245370241936,
      "loss": 0.8188,
      "step": 213040
    },
    {
      "epoch": 343.65,
      "learning_rate": 0.06564922789919356,
      "loss": 0.8644,
      "step": 213060
    },
    {
      "epoch": 343.68,
      "learning_rate": 0.06564600209596774,
      "loss": 0.8512,
      "step": 213080
    },
    {
      "epoch": 343.71,
      "learning_rate": 0.06564277629274194,
      "loss": 0.8157,
      "step": 213100
    },
    {
      "epoch": 343.74,
      "learning_rate": 0.06563955048951614,
      "loss": 0.8203,
      "step": 213120
    },
    {
      "epoch": 343.77,
      "learning_rate": 0.06563632468629033,
      "loss": 0.8412,
      "step": 213140
    },
    {
      "epoch": 343.81,
      "learning_rate": 0.06563309888306451,
      "loss": 0.8179,
      "step": 213160
    },
    {
      "epoch": 343.84,
      "learning_rate": 0.06562987307983872,
      "loss": 0.8264,
      "step": 213180
    },
    {
      "epoch": 343.87,
      "learning_rate": 0.0656266472766129,
      "loss": 0.8441,
      "step": 213200
    },
    {
      "epoch": 343.9,
      "learning_rate": 0.06562342147338711,
      "loss": 0.847,
      "step": 213220
    },
    {
      "epoch": 343.94,
      "learning_rate": 0.0656201956701613,
      "loss": 0.8618,
      "step": 213240
    },
    {
      "epoch": 343.97,
      "learning_rate": 0.06561696986693549,
      "loss": 0.8341,
      "step": 213260
    },
    {
      "epoch": 344.0,
      "learning_rate": 0.06561374406370968,
      "loss": 0.854,
      "step": 213280
    },
    {
      "epoch": 344.0,
      "eval_accuracy": {
        "accuracy": 0.7471704004371243
      },
      "eval_loss": 1.2372339963912964,
      "eval_runtime": 2.7416,
      "eval_samples_per_second": 4672.742,
      "eval_steps_per_second": 73.314,
      "step": 213280
    },
    {
      "epoch": 344.03,
      "learning_rate": 0.06561051826048388,
      "loss": 0.8631,
      "step": 213300
    },
    {
      "epoch": 344.06,
      "learning_rate": 0.06560729245725806,
      "loss": 0.8053,
      "step": 213320
    },
    {
      "epoch": 344.1,
      "learning_rate": 0.06560406665403226,
      "loss": 0.8148,
      "step": 213340
    },
    {
      "epoch": 344.13,
      "learning_rate": 0.06560084085080646,
      "loss": 0.8015,
      "step": 213360
    },
    {
      "epoch": 344.16,
      "learning_rate": 0.06559761504758065,
      "loss": 0.822,
      "step": 213380
    },
    {
      "epoch": 344.19,
      "learning_rate": 0.06559438924435484,
      "loss": 0.7922,
      "step": 213400
    },
    {
      "epoch": 344.23,
      "learning_rate": 0.06559116344112904,
      "loss": 0.8001,
      "step": 213420
    },
    {
      "epoch": 344.26,
      "learning_rate": 0.06558793763790323,
      "loss": 0.8123,
      "step": 213440
    },
    {
      "epoch": 344.29,
      "learning_rate": 0.06558471183467741,
      "loss": 0.7913,
      "step": 213460
    },
    {
      "epoch": 344.32,
      "learning_rate": 0.06558148603145163,
      "loss": 0.7972,
      "step": 213480
    },
    {
      "epoch": 344.35,
      "learning_rate": 0.0655782602282258,
      "loss": 0.8132,
      "step": 213500
    },
    {
      "epoch": 344.39,
      "learning_rate": 0.06557503442500001,
      "loss": 0.8146,
      "step": 213520
    },
    {
      "epoch": 344.42,
      "learning_rate": 0.0655718086217742,
      "loss": 0.8139,
      "step": 213540
    },
    {
      "epoch": 344.45,
      "learning_rate": 0.0655685828185484,
      "loss": 0.8496,
      "step": 213560
    },
    {
      "epoch": 344.48,
      "learning_rate": 0.06556535701532258,
      "loss": 0.818,
      "step": 213580
    },
    {
      "epoch": 344.52,
      "learning_rate": 0.06556213121209678,
      "loss": 0.8417,
      "step": 213600
    },
    {
      "epoch": 344.55,
      "learning_rate": 0.06555890540887097,
      "loss": 0.8193,
      "step": 213620
    },
    {
      "epoch": 344.58,
      "learning_rate": 0.06555567960564516,
      "loss": 0.8236,
      "step": 213640
    },
    {
      "epoch": 344.61,
      "learning_rate": 0.06555245380241936,
      "loss": 0.8372,
      "step": 213660
    },
    {
      "epoch": 344.65,
      "learning_rate": 0.06554922799919355,
      "loss": 0.8436,
      "step": 213680
    },
    {
      "epoch": 344.68,
      "learning_rate": 0.06554600219596775,
      "loss": 0.8328,
      "step": 213700
    },
    {
      "epoch": 344.71,
      "learning_rate": 0.06554277639274195,
      "loss": 0.816,
      "step": 213720
    },
    {
      "epoch": 344.74,
      "learning_rate": 0.06553955058951613,
      "loss": 0.831,
      "step": 213740
    },
    {
      "epoch": 344.77,
      "learning_rate": 0.06553632478629032,
      "loss": 0.8291,
      "step": 213760
    },
    {
      "epoch": 344.81,
      "learning_rate": 0.06553309898306453,
      "loss": 0.8334,
      "step": 213780
    },
    {
      "epoch": 344.84,
      "learning_rate": 0.0655298731798387,
      "loss": 0.8554,
      "step": 213800
    },
    {
      "epoch": 344.87,
      "learning_rate": 0.06552664737661291,
      "loss": 0.8861,
      "step": 213820
    },
    {
      "epoch": 344.9,
      "learning_rate": 0.0655234215733871,
      "loss": 0.8619,
      "step": 213840
    },
    {
      "epoch": 344.94,
      "learning_rate": 0.0655201957701613,
      "loss": 0.8555,
      "step": 213860
    },
    {
      "epoch": 344.97,
      "learning_rate": 0.06551696996693548,
      "loss": 0.8653,
      "step": 213880
    },
    {
      "epoch": 345.0,
      "learning_rate": 0.06551390545387097,
      "loss": 0.877,
      "step": 213900
    },
    {
      "epoch": 345.0,
      "eval_accuracy": {
        "accuracy": 0.7482632113027866
      },
      "eval_loss": 1.2170897722244263,
      "eval_runtime": 2.7905,
      "eval_samples_per_second": 4590.952,
      "eval_steps_per_second": 72.03,
      "step": 213900
    },
    {
      "epoch": 345.03,
      "learning_rate": 0.06551067965064516,
      "loss": 0.8562,
      "step": 213920
    },
    {
      "epoch": 345.06,
      "learning_rate": 0.06550745384741935,
      "loss": 0.8325,
      "step": 213940
    },
    {
      "epoch": 345.1,
      "learning_rate": 0.06550422804419356,
      "loss": 0.8163,
      "step": 213960
    },
    {
      "epoch": 345.13,
      "learning_rate": 0.06550100224096773,
      "loss": 0.8008,
      "step": 213980
    },
    {
      "epoch": 345.16,
      "learning_rate": 0.06549777643774195,
      "loss": 0.8075,
      "step": 214000
    },
    {
      "epoch": 345.19,
      "learning_rate": 0.06549455063451613,
      "loss": 0.7987,
      "step": 214020
    },
    {
      "epoch": 345.23,
      "learning_rate": 0.06549132483129033,
      "loss": 0.8249,
      "step": 214040
    },
    {
      "epoch": 345.26,
      "learning_rate": 0.06548809902806452,
      "loss": 0.8358,
      "step": 214060
    },
    {
      "epoch": 345.29,
      "learning_rate": 0.06548487322483872,
      "loss": 0.7958,
      "step": 214080
    },
    {
      "epoch": 345.32,
      "learning_rate": 0.0654816474216129,
      "loss": 0.8189,
      "step": 214100
    },
    {
      "epoch": 345.35,
      "learning_rate": 0.0654784216183871,
      "loss": 0.8018,
      "step": 214120
    },
    {
      "epoch": 345.39,
      "learning_rate": 0.0654751958151613,
      "loss": 0.8251,
      "step": 214140
    },
    {
      "epoch": 345.42,
      "learning_rate": 0.06547197001193548,
      "loss": 0.8143,
      "step": 214160
    },
    {
      "epoch": 345.45,
      "learning_rate": 0.06546874420870968,
      "loss": 0.8439,
      "step": 214180
    },
    {
      "epoch": 345.48,
      "learning_rate": 0.06546551840548388,
      "loss": 0.8363,
      "step": 214200
    },
    {
      "epoch": 345.52,
      "learning_rate": 0.06546229260225807,
      "loss": 0.849,
      "step": 214220
    },
    {
      "epoch": 345.55,
      "learning_rate": 0.06545906679903225,
      "loss": 0.8404,
      "step": 214240
    },
    {
      "epoch": 345.58,
      "learning_rate": 0.06545584099580647,
      "loss": 0.8238,
      "step": 214260
    },
    {
      "epoch": 345.61,
      "learning_rate": 0.06545261519258064,
      "loss": 0.8639,
      "step": 214280
    },
    {
      "epoch": 345.65,
      "learning_rate": 0.06544938938935485,
      "loss": 0.819,
      "step": 214300
    },
    {
      "epoch": 345.68,
      "learning_rate": 0.06544616358612904,
      "loss": 0.8285,
      "step": 214320
    },
    {
      "epoch": 345.71,
      "learning_rate": 0.06544293778290323,
      "loss": 0.8278,
      "step": 214340
    },
    {
      "epoch": 345.74,
      "learning_rate": 0.06543971197967742,
      "loss": 0.8601,
      "step": 214360
    },
    {
      "epoch": 345.77,
      "learning_rate": 0.06543648617645162,
      "loss": 0.8572,
      "step": 214380
    },
    {
      "epoch": 345.81,
      "learning_rate": 0.0654332603732258,
      "loss": 0.8365,
      "step": 214400
    },
    {
      "epoch": 345.84,
      "learning_rate": 0.06543003457,
      "loss": 0.8379,
      "step": 214420
    },
    {
      "epoch": 345.87,
      "learning_rate": 0.0654268087667742,
      "loss": 0.8562,
      "step": 214440
    },
    {
      "epoch": 345.9,
      "learning_rate": 0.06542358296354839,
      "loss": 0.8587,
      "step": 214460
    },
    {
      "epoch": 345.94,
      "learning_rate": 0.06542035716032259,
      "loss": 0.8321,
      "step": 214480
    },
    {
      "epoch": 345.97,
      "learning_rate": 0.06541713135709679,
      "loss": 0.8588,
      "step": 214500
    },
    {
      "epoch": 346.0,
      "learning_rate": 0.06541390555387097,
      "loss": 0.8651,
      "step": 214520
    },
    {
      "epoch": 346.0,
      "eval_accuracy": {
        "accuracy": 0.744828662867848
      },
      "eval_loss": 1.2417068481445312,
      "eval_runtime": 2.9349,
      "eval_samples_per_second": 4365.111,
      "eval_steps_per_second": 68.487,
      "step": 214520
    },
    {
      "epoch": 346.03,
      "learning_rate": 0.06541067975064516,
      "loss": 0.8516,
      "step": 214540
    },
    {
      "epoch": 346.06,
      "learning_rate": 0.06540745394741937,
      "loss": 0.8236,
      "step": 214560
    },
    {
      "epoch": 346.1,
      "learning_rate": 0.06540422814419354,
      "loss": 0.8117,
      "step": 214580
    },
    {
      "epoch": 346.13,
      "learning_rate": 0.06540100234096775,
      "loss": 0.8059,
      "step": 214600
    },
    {
      "epoch": 346.16,
      "learning_rate": 0.06539777653774194,
      "loss": 0.8098,
      "step": 214620
    },
    {
      "epoch": 346.19,
      "learning_rate": 0.06539455073451614,
      "loss": 0.8168,
      "step": 214640
    },
    {
      "epoch": 346.23,
      "learning_rate": 0.06539132493129032,
      "loss": 0.8211,
      "step": 214660
    },
    {
      "epoch": 346.26,
      "learning_rate": 0.06538809912806452,
      "loss": 0.8033,
      "step": 214680
    },
    {
      "epoch": 346.29,
      "learning_rate": 0.06538487332483871,
      "loss": 0.8176,
      "step": 214700
    },
    {
      "epoch": 346.32,
      "learning_rate": 0.0653816475216129,
      "loss": 0.8269,
      "step": 214720
    },
    {
      "epoch": 346.35,
      "learning_rate": 0.0653784217183871,
      "loss": 0.8244,
      "step": 214740
    },
    {
      "epoch": 346.39,
      "learning_rate": 0.06537519591516129,
      "loss": 0.8168,
      "step": 214760
    },
    {
      "epoch": 346.42,
      "learning_rate": 0.06537197011193549,
      "loss": 0.8215,
      "step": 214780
    },
    {
      "epoch": 346.45,
      "learning_rate": 0.06536874430870969,
      "loss": 0.8387,
      "step": 214800
    },
    {
      "epoch": 346.48,
      "learning_rate": 0.06536551850548387,
      "loss": 0.8139,
      "step": 214820
    },
    {
      "epoch": 346.52,
      "learning_rate": 0.06536229270225806,
      "loss": 0.8229,
      "step": 214840
    },
    {
      "epoch": 346.55,
      "learning_rate": 0.06535906689903227,
      "loss": 0.8401,
      "step": 214860
    },
    {
      "epoch": 346.58,
      "learning_rate": 0.06535584109580644,
      "loss": 0.8225,
      "step": 214880
    },
    {
      "epoch": 346.61,
      "learning_rate": 0.06535261529258066,
      "loss": 0.8229,
      "step": 214900
    },
    {
      "epoch": 346.65,
      "learning_rate": 0.06534938948935484,
      "loss": 0.8211,
      "step": 214920
    },
    {
      "epoch": 346.68,
      "learning_rate": 0.06534616368612904,
      "loss": 0.8525,
      "step": 214940
    },
    {
      "epoch": 346.71,
      "learning_rate": 0.06534293788290323,
      "loss": 0.8203,
      "step": 214960
    },
    {
      "epoch": 346.74,
      "learning_rate": 0.06533971207967743,
      "loss": 0.841,
      "step": 214980
    },
    {
      "epoch": 346.77,
      "learning_rate": 0.06533648627645161,
      "loss": 0.8499,
      "step": 215000
    },
    {
      "epoch": 346.81,
      "learning_rate": 0.06533326047322581,
      "loss": 0.8413,
      "step": 215020
    },
    {
      "epoch": 346.84,
      "learning_rate": 0.06533003467000001,
      "loss": 0.8326,
      "step": 215040
    },
    {
      "epoch": 346.87,
      "learning_rate": 0.0653268088667742,
      "loss": 0.8403,
      "step": 215060
    },
    {
      "epoch": 346.9,
      "learning_rate": 0.0653235830635484,
      "loss": 0.8258,
      "step": 215080
    },
    {
      "epoch": 346.94,
      "learning_rate": 0.06532035726032259,
      "loss": 0.8263,
      "step": 215100
    },
    {
      "epoch": 346.97,
      "learning_rate": 0.06531713145709678,
      "loss": 0.8088,
      "step": 215120
    },
    {
      "epoch": 347.0,
      "learning_rate": 0.06531390565387098,
      "loss": 0.8316,
      "step": 215140
    },
    {
      "epoch": 347.0,
      "eval_accuracy": {
        "accuracy": 0.7540394973070018
      },
      "eval_loss": 1.2047545909881592,
      "eval_runtime": 3.1837,
      "eval_samples_per_second": 4023.951,
      "eval_steps_per_second": 63.134,
      "step": 215140
    },
    {
      "epoch": 347.03,
      "learning_rate": 0.06531067985064518,
      "loss": 0.8547,
      "step": 215160
    },
    {
      "epoch": 347.06,
      "learning_rate": 0.06530745404741935,
      "loss": 0.812,
      "step": 215180
    },
    {
      "epoch": 347.1,
      "learning_rate": 0.06530422824419356,
      "loss": 0.8249,
      "step": 215200
    },
    {
      "epoch": 347.13,
      "learning_rate": 0.06530100244096775,
      "loss": 0.8377,
      "step": 215220
    },
    {
      "epoch": 347.16,
      "learning_rate": 0.06529777663774194,
      "loss": 0.8315,
      "step": 215240
    },
    {
      "epoch": 347.19,
      "learning_rate": 0.06529455083451613,
      "loss": 0.8327,
      "step": 215260
    },
    {
      "epoch": 347.23,
      "learning_rate": 0.06529132503129033,
      "loss": 0.8195,
      "step": 215280
    },
    {
      "epoch": 347.26,
      "learning_rate": 0.06528809922806451,
      "loss": 0.8214,
      "step": 215300
    },
    {
      "epoch": 347.29,
      "learning_rate": 0.06528487342483871,
      "loss": 0.8139,
      "step": 215320
    },
    {
      "epoch": 347.32,
      "learning_rate": 0.06528164762161291,
      "loss": 0.8344,
      "step": 215340
    },
    {
      "epoch": 347.35,
      "learning_rate": 0.0652784218183871,
      "loss": 0.8496,
      "step": 215360
    },
    {
      "epoch": 347.39,
      "learning_rate": 0.0652751960151613,
      "loss": 0.8384,
      "step": 215380
    },
    {
      "epoch": 347.42,
      "learning_rate": 0.0652719702119355,
      "loss": 0.8112,
      "step": 215400
    },
    {
      "epoch": 347.45,
      "learning_rate": 0.06526874440870968,
      "loss": 0.7998,
      "step": 215420
    },
    {
      "epoch": 347.48,
      "learning_rate": 0.06526551860548388,
      "loss": 0.8115,
      "step": 215440
    },
    {
      "epoch": 347.52,
      "learning_rate": 0.06526229280225808,
      "loss": 0.8067,
      "step": 215460
    },
    {
      "epoch": 347.55,
      "learning_rate": 0.06525906699903225,
      "loss": 0.82,
      "step": 215480
    },
    {
      "epoch": 347.58,
      "learning_rate": 0.06525584119580646,
      "loss": 0.8193,
      "step": 215500
    },
    {
      "epoch": 347.61,
      "learning_rate": 0.06525261539258065,
      "loss": 0.853,
      "step": 215520
    },
    {
      "epoch": 347.65,
      "learning_rate": 0.06524938958935485,
      "loss": 0.8366,
      "step": 215540
    },
    {
      "epoch": 347.68,
      "learning_rate": 0.06524616378612903,
      "loss": 0.8345,
      "step": 215560
    },
    {
      "epoch": 347.71,
      "learning_rate": 0.06524293798290323,
      "loss": 0.8348,
      "step": 215580
    },
    {
      "epoch": 347.74,
      "learning_rate": 0.06523971217967742,
      "loss": 0.8483,
      "step": 215600
    },
    {
      "epoch": 347.77,
      "learning_rate": 0.06523648637645162,
      "loss": 0.8359,
      "step": 215620
    },
    {
      "epoch": 347.81,
      "learning_rate": 0.06523326057322582,
      "loss": 0.8347,
      "step": 215640
    },
    {
      "epoch": 347.84,
      "learning_rate": 0.06523003477,
      "loss": 0.8362,
      "step": 215660
    },
    {
      "epoch": 347.87,
      "learning_rate": 0.0652268089667742,
      "loss": 0.8171,
      "step": 215680
    },
    {
      "epoch": 347.9,
      "learning_rate": 0.0652235831635484,
      "loss": 0.8111,
      "step": 215700
    },
    {
      "epoch": 347.94,
      "learning_rate": 0.06522035736032258,
      "loss": 0.8261,
      "step": 215720
    },
    {
      "epoch": 347.97,
      "learning_rate": 0.06521713155709678,
      "loss": 0.8377,
      "step": 215740
    },
    {
      "epoch": 348.0,
      "learning_rate": 0.06521390575387097,
      "loss": 0.8083,
      "step": 215760
    },
    {
      "epoch": 348.0,
      "eval_accuracy": {
        "accuracy": 0.7481070954648349
      },
      "eval_loss": 1.197674036026001,
      "eval_runtime": 2.9075,
      "eval_samples_per_second": 4406.196,
      "eval_steps_per_second": 69.132,
      "step": 215760
    },
    {
      "epoch": 348.03,
      "learning_rate": 0.06521067995064515,
      "loss": 0.8196,
      "step": 215780
    },
    {
      "epoch": 348.06,
      "learning_rate": 0.06520745414741937,
      "loss": 0.7992,
      "step": 215800
    },
    {
      "epoch": 348.1,
      "learning_rate": 0.06520422834419355,
      "loss": 0.8211,
      "step": 215820
    },
    {
      "epoch": 348.13,
      "learning_rate": 0.06520100254096775,
      "loss": 0.823,
      "step": 215840
    },
    {
      "epoch": 348.16,
      "learning_rate": 0.06519777673774194,
      "loss": 0.8265,
      "step": 215860
    },
    {
      "epoch": 348.19,
      "learning_rate": 0.06519455093451614,
      "loss": 0.8161,
      "step": 215880
    },
    {
      "epoch": 348.23,
      "learning_rate": 0.06519132513129032,
      "loss": 0.8073,
      "step": 215900
    },
    {
      "epoch": 348.26,
      "learning_rate": 0.06518809932806452,
      "loss": 0.8288,
      "step": 215920
    },
    {
      "epoch": 348.29,
      "learning_rate": 0.06518487352483872,
      "loss": 0.8168,
      "step": 215940
    },
    {
      "epoch": 348.32,
      "learning_rate": 0.0651816477216129,
      "loss": 0.8285,
      "step": 215960
    },
    {
      "epoch": 348.35,
      "learning_rate": 0.0651784219183871,
      "loss": 0.8288,
      "step": 215980
    },
    {
      "epoch": 348.39,
      "learning_rate": 0.0651751961151613,
      "loss": 0.7994,
      "step": 216000
    },
    {
      "epoch": 348.42,
      "learning_rate": 0.06517197031193549,
      "loss": 0.8159,
      "step": 216020
    },
    {
      "epoch": 348.45,
      "learning_rate": 0.06516874450870969,
      "loss": 0.8378,
      "step": 216040
    },
    {
      "epoch": 348.48,
      "learning_rate": 0.06516551870548387,
      "loss": 0.8289,
      "step": 216060
    },
    {
      "epoch": 348.52,
      "learning_rate": 0.06516229290225806,
      "loss": 0.834,
      "step": 216080
    },
    {
      "epoch": 348.55,
      "learning_rate": 0.06515906709903227,
      "loss": 0.8445,
      "step": 216100
    },
    {
      "epoch": 348.58,
      "learning_rate": 0.06515584129580645,
      "loss": 0.8568,
      "step": 216120
    },
    {
      "epoch": 348.61,
      "learning_rate": 0.06515261549258065,
      "loss": 0.8634,
      "step": 216140
    },
    {
      "epoch": 348.65,
      "learning_rate": 0.06514938968935484,
      "loss": 0.8629,
      "step": 216160
    },
    {
      "epoch": 348.68,
      "learning_rate": 0.06514616388612904,
      "loss": 0.8366,
      "step": 216180
    },
    {
      "epoch": 348.71,
      "learning_rate": 0.06514293808290322,
      "loss": 0.8314,
      "step": 216200
    },
    {
      "epoch": 348.74,
      "learning_rate": 0.06513971227967744,
      "loss": 0.8126,
      "step": 216220
    },
    {
      "epoch": 348.77,
      "learning_rate": 0.06513648647645162,
      "loss": 0.8296,
      "step": 216240
    },
    {
      "epoch": 348.81,
      "learning_rate": 0.0651332606732258,
      "loss": 0.8339,
      "step": 216260
    },
    {
      "epoch": 348.84,
      "learning_rate": 0.06513003487,
      "loss": 0.8499,
      "step": 216280
    },
    {
      "epoch": 348.87,
      "learning_rate": 0.06512680906677419,
      "loss": 0.8376,
      "step": 216300
    },
    {
      "epoch": 348.9,
      "learning_rate": 0.06512358326354839,
      "loss": 0.8259,
      "step": 216320
    },
    {
      "epoch": 348.94,
      "learning_rate": 0.06512035746032259,
      "loss": 0.822,
      "step": 216340
    },
    {
      "epoch": 348.97,
      "learning_rate": 0.06511713165709677,
      "loss": 0.8603,
      "step": 216360
    },
    {
      "epoch": 349.0,
      "learning_rate": 0.06511406714403226,
      "loss": 0.8288,
      "step": 216380
    },
    {
      "epoch": 349.0,
      "eval_accuracy": {
        "accuracy": 0.7545078448208571
      },
      "eval_loss": 1.186051607131958,
      "eval_runtime": 2.8904,
      "eval_samples_per_second": 4432.302,
      "eval_steps_per_second": 69.541,
      "step": 216380
    },
    {
      "epoch": 349.03,
      "learning_rate": 0.06511084134080646,
      "loss": 0.8429,
      "step": 216400
    },
    {
      "epoch": 349.06,
      "learning_rate": 0.06510761553758065,
      "loss": 0.8349,
      "step": 216420
    },
    {
      "epoch": 349.1,
      "learning_rate": 0.06510438973435484,
      "loss": 0.816,
      "step": 216440
    },
    {
      "epoch": 349.13,
      "learning_rate": 0.06510116393112904,
      "loss": 0.829,
      "step": 216460
    },
    {
      "epoch": 349.16,
      "learning_rate": 0.06509793812790324,
      "loss": 0.833,
      "step": 216480
    },
    {
      "epoch": 349.19,
      "learning_rate": 0.06509471232467742,
      "loss": 0.798,
      "step": 216500
    },
    {
      "epoch": 349.23,
      "learning_rate": 0.06509148652145162,
      "loss": 0.8087,
      "step": 216520
    },
    {
      "epoch": 349.26,
      "learning_rate": 0.06508826071822582,
      "loss": 0.7963,
      "step": 216540
    },
    {
      "epoch": 349.29,
      "learning_rate": 0.06508503491499999,
      "loss": 0.8178,
      "step": 216560
    },
    {
      "epoch": 349.32,
      "learning_rate": 0.0650818091117742,
      "loss": 0.8256,
      "step": 216580
    },
    {
      "epoch": 349.35,
      "learning_rate": 0.06507858330854839,
      "loss": 0.8259,
      "step": 216600
    },
    {
      "epoch": 349.39,
      "learning_rate": 0.06507535750532259,
      "loss": 0.8184,
      "step": 216620
    },
    {
      "epoch": 349.42,
      "learning_rate": 0.06507213170209677,
      "loss": 0.8348,
      "step": 216640
    },
    {
      "epoch": 349.45,
      "learning_rate": 0.06506890589887097,
      "loss": 0.821,
      "step": 216660
    },
    {
      "epoch": 349.48,
      "learning_rate": 0.06506568009564516,
      "loss": 0.8161,
      "step": 216680
    },
    {
      "epoch": 349.52,
      "learning_rate": 0.06506245429241936,
      "loss": 0.8243,
      "step": 216700
    },
    {
      "epoch": 349.55,
      "learning_rate": 0.06505922848919356,
      "loss": 0.8562,
      "step": 216720
    },
    {
      "epoch": 349.58,
      "learning_rate": 0.06505600268596774,
      "loss": 0.8165,
      "step": 216740
    },
    {
      "epoch": 349.61,
      "learning_rate": 0.06505277688274194,
      "loss": 0.8387,
      "step": 216760
    },
    {
      "epoch": 349.65,
      "learning_rate": 0.06504955107951614,
      "loss": 0.815,
      "step": 216780
    },
    {
      "epoch": 349.68,
      "learning_rate": 0.06504632527629033,
      "loss": 0.8283,
      "step": 216800
    },
    {
      "epoch": 349.71,
      "learning_rate": 0.06504309947306453,
      "loss": 0.8379,
      "step": 216820
    },
    {
      "epoch": 349.74,
      "learning_rate": 0.06503987366983871,
      "loss": 0.8365,
      "step": 216840
    },
    {
      "epoch": 349.77,
      "learning_rate": 0.0650366478666129,
      "loss": 0.846,
      "step": 216860
    },
    {
      "epoch": 349.81,
      "learning_rate": 0.06503342206338711,
      "loss": 0.8264,
      "step": 216880
    },
    {
      "epoch": 349.84,
      "learning_rate": 0.0650301962601613,
      "loss": 0.826,
      "step": 216900
    },
    {
      "epoch": 349.87,
      "learning_rate": 0.06502697045693549,
      "loss": 0.836,
      "step": 216920
    },
    {
      "epoch": 349.9,
      "learning_rate": 0.06502374465370968,
      "loss": 0.8386,
      "step": 216940
    },
    {
      "epoch": 349.94,
      "learning_rate": 0.06502051885048388,
      "loss": 0.8493,
      "step": 216960
    },
    {
      "epoch": 349.97,
      "learning_rate": 0.06501729304725806,
      "loss": 0.8364,
      "step": 216980
    },
    {
      "epoch": 350.0,
      "learning_rate": 0.06501406724403226,
      "loss": 0.8457,
      "step": 217000
    },
    {
      "epoch": 350.0,
      "eval_accuracy": {
        "accuracy": 0.7544297869018812
      },
      "eval_loss": 1.1924363374710083,
      "eval_runtime": 2.9644,
      "eval_samples_per_second": 4321.589,
      "eval_steps_per_second": 67.804,
      "step": 217000
    },
    {
      "epoch": 350.03,
      "learning_rate": 0.06501084144080646,
      "loss": 0.854,
      "step": 217020
    },
    {
      "epoch": 350.06,
      "learning_rate": 0.06500761563758065,
      "loss": 0.8094,
      "step": 217040
    },
    {
      "epoch": 350.1,
      "learning_rate": 0.06500438983435484,
      "loss": 0.8196,
      "step": 217060
    },
    {
      "epoch": 350.13,
      "learning_rate": 0.06500116403112904,
      "loss": 0.8258,
      "step": 217080
    },
    {
      "epoch": 350.16,
      "learning_rate": 0.06499793822790323,
      "loss": 0.831,
      "step": 217100
    },
    {
      "epoch": 350.19,
      "learning_rate": 0.06499471242467743,
      "loss": 0.8244,
      "step": 217120
    },
    {
      "epoch": 350.23,
      "learning_rate": 0.06499148662145161,
      "loss": 0.7981,
      "step": 217140
    },
    {
      "epoch": 350.26,
      "learning_rate": 0.0649882608182258,
      "loss": 0.8214,
      "step": 217160
    },
    {
      "epoch": 350.29,
      "learning_rate": 0.06498503501500001,
      "loss": 0.8328,
      "step": 217180
    },
    {
      "epoch": 350.32,
      "learning_rate": 0.0649818092117742,
      "loss": 0.852,
      "step": 217200
    },
    {
      "epoch": 350.35,
      "learning_rate": 0.0649785834085484,
      "loss": 0.8202,
      "step": 217220
    },
    {
      "epoch": 350.39,
      "learning_rate": 0.06497535760532258,
      "loss": 0.8394,
      "step": 217240
    },
    {
      "epoch": 350.42,
      "learning_rate": 0.06497213180209678,
      "loss": 0.8323,
      "step": 217260
    },
    {
      "epoch": 350.45,
      "learning_rate": 0.06496890599887097,
      "loss": 0.806,
      "step": 217280
    },
    {
      "epoch": 350.48,
      "learning_rate": 0.06496568019564518,
      "loss": 0.8061,
      "step": 217300
    },
    {
      "epoch": 350.52,
      "learning_rate": 0.06496245439241936,
      "loss": 0.8287,
      "step": 217320
    },
    {
      "epoch": 350.55,
      "learning_rate": 0.06495922858919355,
      "loss": 0.8444,
      "step": 217340
    },
    {
      "epoch": 350.58,
      "learning_rate": 0.06495600278596775,
      "loss": 0.8387,
      "step": 217360
    },
    {
      "epoch": 350.61,
      "learning_rate": 0.06495277698274193,
      "loss": 0.8496,
      "step": 217380
    },
    {
      "epoch": 350.65,
      "learning_rate": 0.06494955117951613,
      "loss": 0.8302,
      "step": 217400
    },
    {
      "epoch": 350.68,
      "learning_rate": 0.06494632537629033,
      "loss": 0.8391,
      "step": 217420
    },
    {
      "epoch": 350.71,
      "learning_rate": 0.06494309957306452,
      "loss": 0.8209,
      "step": 217440
    },
    {
      "epoch": 350.74,
      "learning_rate": 0.06493987376983872,
      "loss": 0.8284,
      "step": 217460
    },
    {
      "epoch": 350.77,
      "learning_rate": 0.06493664796661291,
      "loss": 0.8283,
      "step": 217480
    },
    {
      "epoch": 350.81,
      "learning_rate": 0.0649334221633871,
      "loss": 0.8236,
      "step": 217500
    },
    {
      "epoch": 350.84,
      "learning_rate": 0.0649301963601613,
      "loss": 0.8479,
      "step": 217520
    },
    {
      "epoch": 350.87,
      "learning_rate": 0.06492697055693548,
      "loss": 0.8326,
      "step": 217540
    },
    {
      "epoch": 350.9,
      "learning_rate": 0.06492374475370968,
      "loss": 0.8562,
      "step": 217560
    },
    {
      "epoch": 350.94,
      "learning_rate": 0.06492051895048387,
      "loss": 0.8292,
      "step": 217580
    },
    {
      "epoch": 350.97,
      "learning_rate": 0.06491729314725808,
      "loss": 0.8275,
      "step": 217600
    },
    {
      "epoch": 351.0,
      "learning_rate": 0.06491406734403227,
      "loss": 0.8447,
      "step": 217620
    },
    {
      "epoch": 351.0,
      "eval_accuracy": {
        "accuracy": 0.741550230270861
      },
      "eval_loss": 1.233413577079773,
      "eval_runtime": 2.7682,
      "eval_samples_per_second": 4627.853,
      "eval_steps_per_second": 72.609,
      "step": 217620
    },
    {
      "epoch": 351.03,
      "learning_rate": 0.06491084154080645,
      "loss": 0.8533,
      "step": 217640
    },
    {
      "epoch": 351.06,
      "learning_rate": 0.06490761573758065,
      "loss": 0.8406,
      "step": 217660
    },
    {
      "epoch": 351.1,
      "learning_rate": 0.06490438993435484,
      "loss": 0.8317,
      "step": 217680
    },
    {
      "epoch": 351.13,
      "learning_rate": 0.06490116413112904,
      "loss": 0.8229,
      "step": 217700
    },
    {
      "epoch": 351.16,
      "learning_rate": 0.06489793832790323,
      "loss": 0.8295,
      "step": 217720
    },
    {
      "epoch": 351.19,
      "learning_rate": 0.06489471252467742,
      "loss": 0.8271,
      "step": 217740
    },
    {
      "epoch": 351.23,
      "learning_rate": 0.06489148672145162,
      "loss": 0.8283,
      "step": 217760
    },
    {
      "epoch": 351.26,
      "learning_rate": 0.06488826091822582,
      "loss": 0.8269,
      "step": 217780
    },
    {
      "epoch": 351.29,
      "learning_rate": 0.064885035115,
      "loss": 0.8169,
      "step": 217800
    },
    {
      "epoch": 351.32,
      "learning_rate": 0.0648818093117742,
      "loss": 0.8393,
      "step": 217820
    },
    {
      "epoch": 351.35,
      "learning_rate": 0.06487858350854839,
      "loss": 0.8283,
      "step": 217840
    },
    {
      "epoch": 351.39,
      "learning_rate": 0.06487535770532259,
      "loss": 0.8114,
      "step": 217860
    },
    {
      "epoch": 351.42,
      "learning_rate": 0.06487213190209677,
      "loss": 0.8197,
      "step": 217880
    },
    {
      "epoch": 351.45,
      "learning_rate": 0.06486890609887098,
      "loss": 0.8385,
      "step": 217900
    },
    {
      "epoch": 351.48,
      "learning_rate": 0.06486568029564516,
      "loss": 0.8541,
      "step": 217920
    },
    {
      "epoch": 351.52,
      "learning_rate": 0.06486245449241936,
      "loss": 0.8258,
      "step": 217940
    },
    {
      "epoch": 351.55,
      "learning_rate": 0.06485922868919355,
      "loss": 0.8519,
      "step": 217960
    },
    {
      "epoch": 351.58,
      "learning_rate": 0.06485600288596774,
      "loss": 0.852,
      "step": 217980
    },
    {
      "epoch": 351.61,
      "learning_rate": 0.06485277708274194,
      "loss": 0.8417,
      "step": 218000
    },
    {
      "epoch": 351.65,
      "learning_rate": 0.06484955127951614,
      "loss": 0.8393,
      "step": 218020
    },
    {
      "epoch": 351.68,
      "learning_rate": 0.06484632547629032,
      "loss": 0.8219,
      "step": 218040
    },
    {
      "epoch": 351.71,
      "learning_rate": 0.06484309967306452,
      "loss": 0.8545,
      "step": 218060
    },
    {
      "epoch": 351.74,
      "learning_rate": 0.06483987386983872,
      "loss": 0.8602,
      "step": 218080
    },
    {
      "epoch": 351.77,
      "learning_rate": 0.0648366480666129,
      "loss": 0.8441,
      "step": 218100
    },
    {
      "epoch": 351.81,
      "learning_rate": 0.0648334222633871,
      "loss": 0.8418,
      "step": 218120
    },
    {
      "epoch": 351.84,
      "learning_rate": 0.06483019646016129,
      "loss": 0.8244,
      "step": 218140
    },
    {
      "epoch": 351.87,
      "learning_rate": 0.06482697065693549,
      "loss": 0.8341,
      "step": 218160
    },
    {
      "epoch": 351.9,
      "learning_rate": 0.06482374485370967,
      "loss": 0.8272,
      "step": 218180
    },
    {
      "epoch": 351.94,
      "learning_rate": 0.06482051905048389,
      "loss": 0.838,
      "step": 218200
    },
    {
      "epoch": 351.97,
      "learning_rate": 0.06481729324725806,
      "loss": 0.8552,
      "step": 218220
    },
    {
      "epoch": 352.0,
      "learning_rate": 0.06481406744403226,
      "loss": 0.8446,
      "step": 218240
    },
    {
      "epoch": 352.0,
      "eval_accuracy": {
        "accuracy": 0.7530247443603153
      },
      "eval_loss": 1.1917953491210938,
      "eval_runtime": 3.2189,
      "eval_samples_per_second": 3979.941,
      "eval_steps_per_second": 62.444,
      "step": 218240
    },
    {
      "epoch": 352.03,
      "learning_rate": 0.06481084164080646,
      "loss": 0.8374,
      "step": 218260
    },
    {
      "epoch": 352.06,
      "learning_rate": 0.06480761583758064,
      "loss": 0.8268,
      "step": 218280
    },
    {
      "epoch": 352.1,
      "learning_rate": 0.06480439003435484,
      "loss": 0.8338,
      "step": 218300
    },
    {
      "epoch": 352.13,
      "learning_rate": 0.06480116423112904,
      "loss": 0.8245,
      "step": 218320
    },
    {
      "epoch": 352.16,
      "learning_rate": 0.06479793842790323,
      "loss": 0.8262,
      "step": 218340
    },
    {
      "epoch": 352.19,
      "learning_rate": 0.06479471262467743,
      "loss": 0.8203,
      "step": 218360
    },
    {
      "epoch": 352.23,
      "learning_rate": 0.06479148682145162,
      "loss": 0.8128,
      "step": 218380
    },
    {
      "epoch": 352.26,
      "learning_rate": 0.06478826101822581,
      "loss": 0.8332,
      "step": 218400
    },
    {
      "epoch": 352.29,
      "learning_rate": 0.06478503521500001,
      "loss": 0.8195,
      "step": 218420
    },
    {
      "epoch": 352.32,
      "learning_rate": 0.0647818094117742,
      "loss": 0.7921,
      "step": 218440
    },
    {
      "epoch": 352.35,
      "learning_rate": 0.06477858360854839,
      "loss": 0.803,
      "step": 218460
    },
    {
      "epoch": 352.39,
      "learning_rate": 0.06477535780532258,
      "loss": 0.8313,
      "step": 218480
    },
    {
      "epoch": 352.42,
      "learning_rate": 0.06477213200209679,
      "loss": 0.8275,
      "step": 218500
    },
    {
      "epoch": 352.45,
      "learning_rate": 0.06476890619887096,
      "loss": 0.8102,
      "step": 218520
    },
    {
      "epoch": 352.48,
      "learning_rate": 0.06476568039564518,
      "loss": 0.8111,
      "step": 218540
    },
    {
      "epoch": 352.52,
      "learning_rate": 0.06476245459241936,
      "loss": 0.8181,
      "step": 218560
    },
    {
      "epoch": 352.55,
      "learning_rate": 0.06475922878919355,
      "loss": 0.8038,
      "step": 218580
    },
    {
      "epoch": 352.58,
      "learning_rate": 0.06475600298596774,
      "loss": 0.8332,
      "step": 218600
    },
    {
      "epoch": 352.61,
      "learning_rate": 0.06475277718274194,
      "loss": 0.8183,
      "step": 218620
    },
    {
      "epoch": 352.65,
      "learning_rate": 0.06474955137951613,
      "loss": 0.814,
      "step": 218640
    },
    {
      "epoch": 352.68,
      "learning_rate": 0.06474632557629033,
      "loss": 0.837,
      "step": 218660
    },
    {
      "epoch": 352.71,
      "learning_rate": 0.06474309977306453,
      "loss": 0.8328,
      "step": 218680
    },
    {
      "epoch": 352.74,
      "learning_rate": 0.06473987396983871,
      "loss": 0.8308,
      "step": 218700
    },
    {
      "epoch": 352.77,
      "learning_rate": 0.06473664816661291,
      "loss": 0.8246,
      "step": 218720
    },
    {
      "epoch": 352.81,
      "learning_rate": 0.0647334223633871,
      "loss": 0.857,
      "step": 218740
    },
    {
      "epoch": 352.84,
      "learning_rate": 0.0647301965601613,
      "loss": 0.8731,
      "step": 218760
    },
    {
      "epoch": 352.87,
      "learning_rate": 0.06472697075693548,
      "loss": 0.844,
      "step": 218780
    },
    {
      "epoch": 352.9,
      "learning_rate": 0.0647237449537097,
      "loss": 0.8479,
      "step": 218800
    },
    {
      "epoch": 352.94,
      "learning_rate": 0.06472051915048387,
      "loss": 0.8525,
      "step": 218820
    },
    {
      "epoch": 352.97,
      "learning_rate": 0.06471729334725808,
      "loss": 0.8268,
      "step": 218840
    },
    {
      "epoch": 353.0,
      "learning_rate": 0.06471422883419356,
      "loss": 0.8237,
      "step": 218860
    },
    {
      "epoch": 353.0,
      "eval_accuracy": {
        "accuracy": 0.7516977597377253
      },
      "eval_loss": 1.2075929641723633,
      "eval_runtime": 2.7555,
      "eval_samples_per_second": 4649.276,
      "eval_steps_per_second": 72.945,
      "step": 218860
    },
    {
      "epoch": 353.03,
      "learning_rate": 0.06471100303096775,
      "loss": 0.8294,
      "step": 218880
    },
    {
      "epoch": 353.06,
      "learning_rate": 0.06470777722774194,
      "loss": 0.8176,
      "step": 218900
    },
    {
      "epoch": 353.1,
      "learning_rate": 0.06470455142451613,
      "loss": 0.7758,
      "step": 218920
    },
    {
      "epoch": 353.13,
      "learning_rate": 0.06470132562129033,
      "loss": 0.7962,
      "step": 218940
    },
    {
      "epoch": 353.16,
      "learning_rate": 0.06469809981806451,
      "loss": 0.8193,
      "step": 218960
    },
    {
      "epoch": 353.19,
      "learning_rate": 0.06469487401483873,
      "loss": 0.8217,
      "step": 218980
    },
    {
      "epoch": 353.23,
      "learning_rate": 0.0646916482116129,
      "loss": 0.8056,
      "step": 219000
    },
    {
      "epoch": 353.26,
      "learning_rate": 0.0646884224083871,
      "loss": 0.8207,
      "step": 219020
    },
    {
      "epoch": 353.29,
      "learning_rate": 0.0646851966051613,
      "loss": 0.8112,
      "step": 219040
    },
    {
      "epoch": 353.32,
      "learning_rate": 0.06468197080193548,
      "loss": 0.8356,
      "step": 219060
    },
    {
      "epoch": 353.35,
      "learning_rate": 0.06467874499870968,
      "loss": 0.8372,
      "step": 219080
    },
    {
      "epoch": 353.39,
      "learning_rate": 0.06467551919548388,
      "loss": 0.7969,
      "step": 219100
    },
    {
      "epoch": 353.42,
      "learning_rate": 0.06467229339225807,
      "loss": 0.7928,
      "step": 219120
    },
    {
      "epoch": 353.45,
      "learning_rate": 0.06466906758903226,
      "loss": 0.8256,
      "step": 219140
    },
    {
      "epoch": 353.48,
      "learning_rate": 0.06466584178580646,
      "loss": 0.8134,
      "step": 219160
    },
    {
      "epoch": 353.52,
      "learning_rate": 0.06466261598258065,
      "loss": 0.8319,
      "step": 219180
    },
    {
      "epoch": 353.55,
      "learning_rate": 0.06465939017935485,
      "loss": 0.8336,
      "step": 219200
    },
    {
      "epoch": 353.58,
      "learning_rate": 0.06465616437612903,
      "loss": 0.8415,
      "step": 219220
    },
    {
      "epoch": 353.61,
      "learning_rate": 0.06465293857290323,
      "loss": 0.8347,
      "step": 219240
    },
    {
      "epoch": 353.65,
      "learning_rate": 0.06464971276967742,
      "loss": 0.8379,
      "step": 219260
    },
    {
      "epoch": 353.68,
      "learning_rate": 0.06464648696645163,
      "loss": 0.8298,
      "step": 219280
    },
    {
      "epoch": 353.71,
      "learning_rate": 0.0646432611632258,
      "loss": 0.8329,
      "step": 219300
    },
    {
      "epoch": 353.74,
      "learning_rate": 0.06464003536,
      "loss": 0.8198,
      "step": 219320
    },
    {
      "epoch": 353.77,
      "learning_rate": 0.0646368095567742,
      "loss": 0.8257,
      "step": 219340
    },
    {
      "epoch": 353.81,
      "learning_rate": 0.06463358375354838,
      "loss": 0.845,
      "step": 219360
    },
    {
      "epoch": 353.84,
      "learning_rate": 0.06463035795032258,
      "loss": 0.8383,
      "step": 219380
    },
    {
      "epoch": 353.87,
      "learning_rate": 0.06462713214709678,
      "loss": 0.8335,
      "step": 219400
    },
    {
      "epoch": 353.9,
      "learning_rate": 0.06462390634387097,
      "loss": 0.8169,
      "step": 219420
    },
    {
      "epoch": 353.94,
      "learning_rate": 0.06462068054064517,
      "loss": 0.8345,
      "step": 219440
    },
    {
      "epoch": 353.97,
      "learning_rate": 0.06461745473741937,
      "loss": 0.8209,
      "step": 219460
    },
    {
      "epoch": 354.0,
      "learning_rate": 0.06461422893419355,
      "loss": 0.8369,
      "step": 219480
    },
    {
      "epoch": 354.0,
      "eval_accuracy": {
        "accuracy": 0.7499024276012801
      },
      "eval_loss": 1.197920322418213,
      "eval_runtime": 2.7521,
      "eval_samples_per_second": 4655.054,
      "eval_steps_per_second": 73.036,
      "step": 219480
    },
    {
      "epoch": 354.03,
      "learning_rate": 0.06461100313096775,
      "loss": 0.8397,
      "step": 219500
    },
    {
      "epoch": 354.06,
      "learning_rate": 0.06460777732774194,
      "loss": 0.8124,
      "step": 219520
    },
    {
      "epoch": 354.1,
      "learning_rate": 0.06460455152451614,
      "loss": 0.8063,
      "step": 219540
    },
    {
      "epoch": 354.13,
      "learning_rate": 0.06460132572129032,
      "loss": 0.81,
      "step": 219560
    },
    {
      "epoch": 354.16,
      "learning_rate": 0.06459809991806453,
      "loss": 0.8129,
      "step": 219580
    },
    {
      "epoch": 354.19,
      "learning_rate": 0.0645948741148387,
      "loss": 0.8026,
      "step": 219600
    },
    {
      "epoch": 354.23,
      "learning_rate": 0.06459164831161292,
      "loss": 0.801,
      "step": 219620
    },
    {
      "epoch": 354.26,
      "learning_rate": 0.0645884225083871,
      "loss": 0.8182,
      "step": 219640
    },
    {
      "epoch": 354.29,
      "learning_rate": 0.06458519670516129,
      "loss": 0.8297,
      "step": 219660
    },
    {
      "epoch": 354.32,
      "learning_rate": 0.06458197090193549,
      "loss": 0.8378,
      "step": 219680
    },
    {
      "epoch": 354.35,
      "learning_rate": 0.06457874509870969,
      "loss": 0.8269,
      "step": 219700
    },
    {
      "epoch": 354.39,
      "learning_rate": 0.06457551929548387,
      "loss": 0.8377,
      "step": 219720
    },
    {
      "epoch": 354.42,
      "learning_rate": 0.06457229349225807,
      "loss": 0.8393,
      "step": 219740
    },
    {
      "epoch": 354.45,
      "learning_rate": 0.06456906768903227,
      "loss": 0.8359,
      "step": 219760
    },
    {
      "epoch": 354.48,
      "learning_rate": 0.06456584188580645,
      "loss": 0.8335,
      "step": 219780
    },
    {
      "epoch": 354.52,
      "learning_rate": 0.06456261608258065,
      "loss": 0.8232,
      "step": 219800
    },
    {
      "epoch": 354.55,
      "learning_rate": 0.06455939027935484,
      "loss": 0.8072,
      "step": 219820
    },
    {
      "epoch": 354.58,
      "learning_rate": 0.06455616447612904,
      "loss": 0.8118,
      "step": 219840
    },
    {
      "epoch": 354.61,
      "learning_rate": 0.06455293867290322,
      "loss": 0.8244,
      "step": 219860
    },
    {
      "epoch": 354.65,
      "learning_rate": 0.06454971286967744,
      "loss": 0.8034,
      "step": 219880
    },
    {
      "epoch": 354.68,
      "learning_rate": 0.06454648706645161,
      "loss": 0.8096,
      "step": 219900
    },
    {
      "epoch": 354.71,
      "learning_rate": 0.06454326126322582,
      "loss": 0.8487,
      "step": 219920
    },
    {
      "epoch": 354.74,
      "learning_rate": 0.06454003546,
      "loss": 0.8496,
      "step": 219940
    },
    {
      "epoch": 354.77,
      "learning_rate": 0.06453680965677419,
      "loss": 0.8404,
      "step": 219960
    },
    {
      "epoch": 354.81,
      "learning_rate": 0.06453358385354839,
      "loss": 0.8352,
      "step": 219980
    },
    {
      "epoch": 354.84,
      "learning_rate": 0.06453035805032259,
      "loss": 0.8473,
      "step": 220000
    },
    {
      "epoch": 354.87,
      "learning_rate": 0.06452713224709677,
      "loss": 0.832,
      "step": 220020
    },
    {
      "epoch": 354.9,
      "learning_rate": 0.06452390644387097,
      "loss": 0.8268,
      "step": 220040
    },
    {
      "epoch": 354.94,
      "learning_rate": 0.06452068064064517,
      "loss": 0.8363,
      "step": 220060
    },
    {
      "epoch": 354.97,
      "learning_rate": 0.06451745483741936,
      "loss": 0.8192,
      "step": 220080
    },
    {
      "epoch": 355.0,
      "learning_rate": 0.06451422903419356,
      "loss": 0.8601,
      "step": 220100
    },
    {
      "epoch": 355.0,
      "eval_accuracy": {
        "accuracy": 0.7483412692217626
      },
      "eval_loss": 1.2220863103866577,
      "eval_runtime": 2.6728,
      "eval_samples_per_second": 4793.104,
      "eval_steps_per_second": 75.202,
      "step": 220100
    },
    {
      "epoch": 355.03,
      "learning_rate": 0.06451100323096774,
      "loss": 0.8769,
      "step": 220120
    },
    {
      "epoch": 355.06,
      "learning_rate": 0.06450777742774194,
      "loss": 0.81,
      "step": 220140
    },
    {
      "epoch": 355.1,
      "learning_rate": 0.06450455162451613,
      "loss": 0.834,
      "step": 220160
    },
    {
      "epoch": 355.13,
      "learning_rate": 0.06450132582129034,
      "loss": 0.8142,
      "step": 220180
    },
    {
      "epoch": 355.16,
      "learning_rate": 0.06449810001806451,
      "loss": 0.8164,
      "step": 220200
    },
    {
      "epoch": 355.19,
      "learning_rate": 0.06449487421483872,
      "loss": 0.8156,
      "step": 220220
    },
    {
      "epoch": 355.23,
      "learning_rate": 0.06449164841161291,
      "loss": 0.7936,
      "step": 220240
    },
    {
      "epoch": 355.26,
      "learning_rate": 0.0644884226083871,
      "loss": 0.8135,
      "step": 220260
    },
    {
      "epoch": 355.29,
      "learning_rate": 0.0644851968051613,
      "loss": 0.8312,
      "step": 220280
    },
    {
      "epoch": 355.32,
      "learning_rate": 0.06448197100193549,
      "loss": 0.7969,
      "step": 220300
    },
    {
      "epoch": 355.35,
      "learning_rate": 0.06447874519870968,
      "loss": 0.7922,
      "step": 220320
    },
    {
      "epoch": 355.39,
      "learning_rate": 0.06447551939548388,
      "loss": 0.8298,
      "step": 220340
    },
    {
      "epoch": 355.42,
      "learning_rate": 0.06447229359225808,
      "loss": 0.8463,
      "step": 220360
    },
    {
      "epoch": 355.45,
      "learning_rate": 0.06446906778903226,
      "loss": 0.8182,
      "step": 220380
    },
    {
      "epoch": 355.48,
      "learning_rate": 0.06446584198580646,
      "loss": 0.8026,
      "step": 220400
    },
    {
      "epoch": 355.52,
      "learning_rate": 0.06446261618258065,
      "loss": 0.8133,
      "step": 220420
    },
    {
      "epoch": 355.55,
      "learning_rate": 0.06445939037935484,
      "loss": 0.8131,
      "step": 220440
    },
    {
      "epoch": 355.58,
      "learning_rate": 0.06445616457612903,
      "loss": 0.8438,
      "step": 220460
    },
    {
      "epoch": 355.61,
      "learning_rate": 0.06445293877290324,
      "loss": 0.8203,
      "step": 220480
    },
    {
      "epoch": 355.65,
      "learning_rate": 0.06444971296967741,
      "loss": 0.8236,
      "step": 220500
    },
    {
      "epoch": 355.68,
      "learning_rate": 0.06444648716645163,
      "loss": 0.8367,
      "step": 220520
    },
    {
      "epoch": 355.71,
      "learning_rate": 0.06444326136322581,
      "loss": 0.8503,
      "step": 220540
    },
    {
      "epoch": 355.74,
      "learning_rate": 0.06444003556,
      "loss": 0.8442,
      "step": 220560
    },
    {
      "epoch": 355.77,
      "learning_rate": 0.0644368097567742,
      "loss": 0.8513,
      "step": 220580
    },
    {
      "epoch": 355.81,
      "learning_rate": 0.0644335839535484,
      "loss": 0.8233,
      "step": 220600
    },
    {
      "epoch": 355.84,
      "learning_rate": 0.06443035815032258,
      "loss": 0.8232,
      "step": 220620
    },
    {
      "epoch": 355.87,
      "learning_rate": 0.06442713234709678,
      "loss": 0.8435,
      "step": 220640
    },
    {
      "epoch": 355.9,
      "learning_rate": 0.06442390654387098,
      "loss": 0.84,
      "step": 220660
    },
    {
      "epoch": 355.94,
      "learning_rate": 0.06442068074064516,
      "loss": 0.8064,
      "step": 220680
    },
    {
      "epoch": 355.97,
      "learning_rate": 0.06441745493741936,
      "loss": 0.7987,
      "step": 220700
    },
    {
      "epoch": 356.0,
      "learning_rate": 0.06441422913419355,
      "loss": 0.8144,
      "step": 220720
    },
    {
      "epoch": 356.0,
      "eval_accuracy": {
        "accuracy": 0.7550542502536882
      },
      "eval_loss": 1.189578652381897,
      "eval_runtime": 2.8384,
      "eval_samples_per_second": 4513.518,
      "eval_steps_per_second": 70.815,
      "step": 220720
    },
    {
      "epoch": 356.03,
      "learning_rate": 0.06441100333096775,
      "loss": 0.8333,
      "step": 220740
    },
    {
      "epoch": 356.06,
      "learning_rate": 0.06440777752774193,
      "loss": 0.8327,
      "step": 220760
    },
    {
      "epoch": 356.1,
      "learning_rate": 0.06440455172451613,
      "loss": 0.8054,
      "step": 220780
    },
    {
      "epoch": 356.13,
      "learning_rate": 0.06440132592129032,
      "loss": 0.8006,
      "step": 220800
    },
    {
      "epoch": 356.16,
      "learning_rate": 0.06439810011806453,
      "loss": 0.8149,
      "step": 220820
    },
    {
      "epoch": 356.19,
      "learning_rate": 0.06439487431483872,
      "loss": 0.8126,
      "step": 220840
    },
    {
      "epoch": 356.23,
      "learning_rate": 0.06439164851161291,
      "loss": 0.8077,
      "step": 220860
    },
    {
      "epoch": 356.26,
      "learning_rate": 0.0643884227083871,
      "loss": 0.8194,
      "step": 220880
    },
    {
      "epoch": 356.29,
      "learning_rate": 0.0643851969051613,
      "loss": 0.7979,
      "step": 220900
    },
    {
      "epoch": 356.32,
      "learning_rate": 0.06438197110193548,
      "loss": 0.8284,
      "step": 220920
    },
    {
      "epoch": 356.35,
      "learning_rate": 0.06437874529870968,
      "loss": 0.8055,
      "step": 220940
    },
    {
      "epoch": 356.39,
      "learning_rate": 0.06437551949548388,
      "loss": 0.8045,
      "step": 220960
    },
    {
      "epoch": 356.42,
      "learning_rate": 0.06437229369225807,
      "loss": 0.8288,
      "step": 220980
    },
    {
      "epoch": 356.45,
      "learning_rate": 0.06436906788903227,
      "loss": 0.8014,
      "step": 221000
    },
    {
      "epoch": 356.48,
      "learning_rate": 0.06436584208580647,
      "loss": 0.8233,
      "step": 221020
    },
    {
      "epoch": 356.52,
      "learning_rate": 0.06436261628258065,
      "loss": 0.8116,
      "step": 221040
    },
    {
      "epoch": 356.55,
      "learning_rate": 0.06435939047935484,
      "loss": 0.816,
      "step": 221060
    },
    {
      "epoch": 356.58,
      "learning_rate": 0.06435616467612904,
      "loss": 0.8033,
      "step": 221080
    },
    {
      "epoch": 356.61,
      "learning_rate": 0.06435293887290322,
      "loss": 0.8504,
      "step": 221100
    },
    {
      "epoch": 356.65,
      "learning_rate": 0.06434971306967743,
      "loss": 0.8456,
      "step": 221120
    },
    {
      "epoch": 356.68,
      "learning_rate": 0.06434648726645162,
      "loss": 0.8434,
      "step": 221140
    },
    {
      "epoch": 356.71,
      "learning_rate": 0.06434326146322582,
      "loss": 0.8414,
      "step": 221160
    },
    {
      "epoch": 356.74,
      "learning_rate": 0.06434003566,
      "loss": 0.8333,
      "step": 221180
    },
    {
      "epoch": 356.77,
      "learning_rate": 0.0643368098567742,
      "loss": 0.8369,
      "step": 221200
    },
    {
      "epoch": 356.81,
      "learning_rate": 0.06433358405354839,
      "loss": 0.8233,
      "step": 221220
    },
    {
      "epoch": 356.84,
      "learning_rate": 0.06433035825032259,
      "loss": 0.8175,
      "step": 221240
    },
    {
      "epoch": 356.87,
      "learning_rate": 0.06432713244709679,
      "loss": 0.8266,
      "step": 221260
    },
    {
      "epoch": 356.9,
      "learning_rate": 0.06432390664387097,
      "loss": 0.8447,
      "step": 221280
    },
    {
      "epoch": 356.94,
      "learning_rate": 0.06432068084064517,
      "loss": 0.8216,
      "step": 221300
    },
    {
      "epoch": 356.97,
      "learning_rate": 0.06431745503741935,
      "loss": 0.8266,
      "step": 221320
    },
    {
      "epoch": 357.0,
      "learning_rate": 0.06431439052435484,
      "loss": 0.8365,
      "step": 221340
    },
    {
      "epoch": 357.0,
      "eval_accuracy": {
        "accuracy": 0.7573959878229647
      },
      "eval_loss": 1.1822654008865356,
      "eval_runtime": 3.1267,
      "eval_samples_per_second": 4097.306,
      "eval_steps_per_second": 64.285,
      "step": 221340
    },
    {
      "epoch": 357.03,
      "learning_rate": 0.06431116472112904,
      "loss": 0.8418,
      "step": 221360
    },
    {
      "epoch": 357.06,
      "learning_rate": 0.06430793891790323,
      "loss": 0.8092,
      "step": 221380
    },
    {
      "epoch": 357.1,
      "learning_rate": 0.06430471311467742,
      "loss": 0.8305,
      "step": 221400
    },
    {
      "epoch": 357.13,
      "learning_rate": 0.06430148731145162,
      "loss": 0.7989,
      "step": 221420
    },
    {
      "epoch": 357.16,
      "learning_rate": 0.06429826150822582,
      "loss": 0.8187,
      "step": 221440
    },
    {
      "epoch": 357.19,
      "learning_rate": 0.064295035705,
      "loss": 0.8308,
      "step": 221460
    },
    {
      "epoch": 357.23,
      "learning_rate": 0.0642918099017742,
      "loss": 0.8196,
      "step": 221480
    },
    {
      "epoch": 357.26,
      "learning_rate": 0.06428858409854839,
      "loss": 0.8192,
      "step": 221500
    },
    {
      "epoch": 357.29,
      "learning_rate": 0.06428535829532259,
      "loss": 0.8137,
      "step": 221520
    },
    {
      "epoch": 357.32,
      "learning_rate": 0.06428213249209677,
      "loss": 0.8145,
      "step": 221540
    },
    {
      "epoch": 357.35,
      "learning_rate": 0.06427890668887098,
      "loss": 0.7837,
      "step": 221560
    },
    {
      "epoch": 357.39,
      "learning_rate": 0.06427568088564516,
      "loss": 0.7944,
      "step": 221580
    },
    {
      "epoch": 357.42,
      "learning_rate": 0.06427245508241937,
      "loss": 0.7927,
      "step": 221600
    },
    {
      "epoch": 357.45,
      "learning_rate": 0.06426922927919355,
      "loss": 0.806,
      "step": 221620
    },
    {
      "epoch": 357.48,
      "learning_rate": 0.06426600347596774,
      "loss": 0.8411,
      "step": 221640
    },
    {
      "epoch": 357.52,
      "learning_rate": 0.06426277767274194,
      "loss": 0.795,
      "step": 221660
    },
    {
      "epoch": 357.55,
      "learning_rate": 0.06425955186951614,
      "loss": 0.8028,
      "step": 221680
    },
    {
      "epoch": 357.58,
      "learning_rate": 0.06425632606629032,
      "loss": 0.8266,
      "step": 221700
    },
    {
      "epoch": 357.61,
      "learning_rate": 0.06425310026306452,
      "loss": 0.8529,
      "step": 221720
    },
    {
      "epoch": 357.65,
      "learning_rate": 0.06424987445983872,
      "loss": 0.8488,
      "step": 221740
    },
    {
      "epoch": 357.68,
      "learning_rate": 0.0642466486566129,
      "loss": 0.8428,
      "step": 221760
    },
    {
      "epoch": 357.71,
      "learning_rate": 0.0642434228533871,
      "loss": 0.8444,
      "step": 221780
    },
    {
      "epoch": 357.74,
      "learning_rate": 0.06424019705016129,
      "loss": 0.8406,
      "step": 221800
    },
    {
      "epoch": 357.77,
      "learning_rate": 0.06423697124693549,
      "loss": 0.8225,
      "step": 221820
    },
    {
      "epoch": 357.81,
      "learning_rate": 0.06423374544370967,
      "loss": 0.8477,
      "step": 221840
    },
    {
      "epoch": 357.84,
      "learning_rate": 0.06423051964048387,
      "loss": 0.8136,
      "step": 221860
    },
    {
      "epoch": 357.87,
      "learning_rate": 0.06422729383725806,
      "loss": 0.8285,
      "step": 221880
    },
    {
      "epoch": 357.9,
      "learning_rate": 0.06422406803403227,
      "loss": 0.8342,
      "step": 221900
    },
    {
      "epoch": 357.94,
      "learning_rate": 0.06422084223080646,
      "loss": 0.8426,
      "step": 221920
    },
    {
      "epoch": 357.97,
      "learning_rate": 0.06421761642758066,
      "loss": 0.8404,
      "step": 221940
    },
    {
      "epoch": 358.0,
      "learning_rate": 0.06421439062435484,
      "loss": 0.8373,
      "step": 221960
    },
    {
      "epoch": 358.0,
      "eval_accuracy": {
        "accuracy": 0.7463898212473655
      },
      "eval_loss": 1.2089812755584717,
      "eval_runtime": 3.2366,
      "eval_samples_per_second": 3958.134,
      "eval_steps_per_second": 62.102,
      "step": 221960
    },
    {
      "epoch": 358.03,
      "learning_rate": 0.06421116482112904,
      "loss": 0.827,
      "step": 221980
    },
    {
      "epoch": 358.06,
      "learning_rate": 0.06420793901790323,
      "loss": 0.8371,
      "step": 222000
    },
    {
      "epoch": 358.1,
      "learning_rate": 0.06420471321467743,
      "loss": 0.8205,
      "step": 222020
    },
    {
      "epoch": 358.13,
      "learning_rate": 0.06420148741145162,
      "loss": 0.825,
      "step": 222040
    },
    {
      "epoch": 358.16,
      "learning_rate": 0.06419826160822581,
      "loss": 0.8225,
      "step": 222060
    },
    {
      "epoch": 358.19,
      "learning_rate": 0.06419503580500001,
      "loss": 0.8166,
      "step": 222080
    },
    {
      "epoch": 358.23,
      "learning_rate": 0.06419181000177421,
      "loss": 0.8525,
      "step": 222100
    },
    {
      "epoch": 358.26,
      "learning_rate": 0.06418858419854839,
      "loss": 0.8342,
      "step": 222120
    },
    {
      "epoch": 358.29,
      "learning_rate": 0.06418535839532258,
      "loss": 0.8083,
      "step": 222140
    },
    {
      "epoch": 358.32,
      "learning_rate": 0.06418213259209678,
      "loss": 0.8218,
      "step": 222160
    },
    {
      "epoch": 358.35,
      "learning_rate": 0.06417890678887096,
      "loss": 0.8251,
      "step": 222180
    },
    {
      "epoch": 358.39,
      "learning_rate": 0.06417568098564518,
      "loss": 0.832,
      "step": 222200
    },
    {
      "epoch": 358.42,
      "learning_rate": 0.06417245518241936,
      "loss": 0.8399,
      "step": 222220
    },
    {
      "epoch": 358.45,
      "learning_rate": 0.06416922937919356,
      "loss": 0.8155,
      "step": 222240
    },
    {
      "epoch": 358.48,
      "learning_rate": 0.06416600357596774,
      "loss": 0.8264,
      "step": 222260
    },
    {
      "epoch": 358.52,
      "learning_rate": 0.06416277777274194,
      "loss": 0.8283,
      "step": 222280
    },
    {
      "epoch": 358.55,
      "learning_rate": 0.06415955196951613,
      "loss": 0.8177,
      "step": 222300
    },
    {
      "epoch": 358.58,
      "learning_rate": 0.06415632616629033,
      "loss": 0.8379,
      "step": 222320
    },
    {
      "epoch": 358.61,
      "learning_rate": 0.06415310036306453,
      "loss": 0.8276,
      "step": 222340
    },
    {
      "epoch": 358.65,
      "learning_rate": 0.06414987455983871,
      "loss": 0.8238,
      "step": 222360
    },
    {
      "epoch": 358.68,
      "learning_rate": 0.06414664875661291,
      "loss": 0.8348,
      "step": 222380
    },
    {
      "epoch": 358.71,
      "learning_rate": 0.0641434229533871,
      "loss": 0.852,
      "step": 222400
    },
    {
      "epoch": 358.74,
      "learning_rate": 0.0641401971501613,
      "loss": 0.8056,
      "step": 222420
    },
    {
      "epoch": 358.77,
      "learning_rate": 0.06413697134693548,
      "loss": 0.8235,
      "step": 222440
    },
    {
      "epoch": 358.81,
      "learning_rate": 0.06413374554370968,
      "loss": 0.8261,
      "step": 222460
    },
    {
      "epoch": 358.84,
      "learning_rate": 0.06413051974048387,
      "loss": 0.8323,
      "step": 222480
    },
    {
      "epoch": 358.87,
      "learning_rate": 0.06412729393725808,
      "loss": 0.831,
      "step": 222500
    },
    {
      "epoch": 358.9,
      "learning_rate": 0.06412406813403226,
      "loss": 0.8374,
      "step": 222520
    },
    {
      "epoch": 358.94,
      "learning_rate": 0.06412084233080646,
      "loss": 0.8083,
      "step": 222540
    },
    {
      "epoch": 358.97,
      "learning_rate": 0.06411761652758065,
      "loss": 0.852,
      "step": 222560
    },
    {
      "epoch": 359.0,
      "learning_rate": 0.06411439072435485,
      "loss": 0.8308,
      "step": 222580
    },
    {
      "epoch": 359.0,
      "eval_accuracy": {
        "accuracy": 0.7572398719850129
      },
      "eval_loss": 1.1807042360305786,
      "eval_runtime": 2.8991,
      "eval_samples_per_second": 4418.988,
      "eval_steps_per_second": 69.332,
      "step": 222580
    },
    {
      "epoch": 359.03,
      "learning_rate": 0.06411116492112903,
      "loss": 0.8505,
      "step": 222600
    },
    {
      "epoch": 359.06,
      "learning_rate": 0.06410793911790323,
      "loss": 0.8277,
      "step": 222620
    },
    {
      "epoch": 359.1,
      "learning_rate": 0.06410471331467743,
      "loss": 0.8132,
      "step": 222640
    },
    {
      "epoch": 359.13,
      "learning_rate": 0.06410148751145162,
      "loss": 0.8019,
      "step": 222660
    },
    {
      "epoch": 359.16,
      "learning_rate": 0.06409826170822581,
      "loss": 0.8115,
      "step": 222680
    },
    {
      "epoch": 359.19,
      "learning_rate": 0.064095035905,
      "loss": 0.8149,
      "step": 222700
    },
    {
      "epoch": 359.23,
      "learning_rate": 0.0640918101017742,
      "loss": 0.8272,
      "step": 222720
    },
    {
      "epoch": 359.26,
      "learning_rate": 0.06408858429854838,
      "loss": 0.8154,
      "step": 222740
    },
    {
      "epoch": 359.29,
      "learning_rate": 0.06408535849532258,
      "loss": 0.838,
      "step": 222760
    },
    {
      "epoch": 359.32,
      "learning_rate": 0.06408213269209677,
      "loss": 0.8156,
      "step": 222780
    },
    {
      "epoch": 359.35,
      "learning_rate": 0.06407890688887098,
      "loss": 0.8048,
      "step": 222800
    },
    {
      "epoch": 359.39,
      "learning_rate": 0.06407568108564517,
      "loss": 0.802,
      "step": 222820
    },
    {
      "epoch": 359.42,
      "learning_rate": 0.06407245528241937,
      "loss": 0.7994,
      "step": 222840
    },
    {
      "epoch": 359.45,
      "learning_rate": 0.06406922947919355,
      "loss": 0.8008,
      "step": 222860
    },
    {
      "epoch": 359.48,
      "learning_rate": 0.06406600367596775,
      "loss": 0.8133,
      "step": 222880
    },
    {
      "epoch": 359.52,
      "learning_rate": 0.06406277787274194,
      "loss": 0.8243,
      "step": 222900
    },
    {
      "epoch": 359.55,
      "learning_rate": 0.06405955206951613,
      "loss": 0.7977,
      "step": 222920
    },
    {
      "epoch": 359.58,
      "learning_rate": 0.06405632626629032,
      "loss": 0.7932,
      "step": 222940
    },
    {
      "epoch": 359.61,
      "learning_rate": 0.06405310046306452,
      "loss": 0.8226,
      "step": 222960
    },
    {
      "epoch": 359.65,
      "learning_rate": 0.06404987465983872,
      "loss": 0.8318,
      "step": 222980
    },
    {
      "epoch": 359.68,
      "learning_rate": 0.0640466488566129,
      "loss": 0.8072,
      "step": 223000
    },
    {
      "epoch": 359.71,
      "learning_rate": 0.0640434230533871,
      "loss": 0.8322,
      "step": 223020
    },
    {
      "epoch": 359.74,
      "learning_rate": 0.06404019725016129,
      "loss": 0.829,
      "step": 223040
    },
    {
      "epoch": 359.77,
      "learning_rate": 0.06403697144693549,
      "loss": 0.8304,
      "step": 223060
    },
    {
      "epoch": 359.81,
      "learning_rate": 0.06403374564370967,
      "loss": 0.8325,
      "step": 223080
    },
    {
      "epoch": 359.84,
      "learning_rate": 0.06403051984048388,
      "loss": 0.8126,
      "step": 223100
    },
    {
      "epoch": 359.87,
      "learning_rate": 0.06402729403725807,
      "loss": 0.8406,
      "step": 223120
    },
    {
      "epoch": 359.9,
      "learning_rate": 0.06402406823403227,
      "loss": 0.8503,
      "step": 223140
    },
    {
      "epoch": 359.94,
      "learning_rate": 0.06402084243080645,
      "loss": 0.8351,
      "step": 223160
    },
    {
      "epoch": 359.97,
      "learning_rate": 0.06401761662758065,
      "loss": 0.8153,
      "step": 223180
    },
    {
      "epoch": 360.0,
      "learning_rate": 0.06401439082435484,
      "loss": 0.8149,
      "step": 223200
    },
    {
      "epoch": 360.0,
      "eval_accuracy": {
        "accuracy": 0.7457653578955585
      },
      "eval_loss": 1.20725679397583,
      "eval_runtime": 2.9322,
      "eval_samples_per_second": 4369.132,
      "eval_steps_per_second": 68.55,
      "step": 223200
    },
    {
      "epoch": 360.03,
      "learning_rate": 0.06401116502112904,
      "loss": 0.8354,
      "step": 223220
    },
    {
      "epoch": 360.06,
      "learning_rate": 0.06400793921790322,
      "loss": 0.8225,
      "step": 223240
    },
    {
      "epoch": 360.1,
      "learning_rate": 0.06400471341467742,
      "loss": 0.8173,
      "step": 223260
    },
    {
      "epoch": 360.13,
      "learning_rate": 0.06400148761145162,
      "loss": 0.8071,
      "step": 223280
    },
    {
      "epoch": 360.16,
      "learning_rate": 0.0639982618082258,
      "loss": 0.8073,
      "step": 223300
    },
    {
      "epoch": 360.19,
      "learning_rate": 0.063995036005,
      "loss": 0.8181,
      "step": 223320
    },
    {
      "epoch": 360.23,
      "learning_rate": 0.0639918102017742,
      "loss": 0.8133,
      "step": 223340
    },
    {
      "epoch": 360.26,
      "learning_rate": 0.06398858439854839,
      "loss": 0.8122,
      "step": 223360
    },
    {
      "epoch": 360.29,
      "learning_rate": 0.06398535859532258,
      "loss": 0.803,
      "step": 223380
    },
    {
      "epoch": 360.32,
      "learning_rate": 0.06398213279209679,
      "loss": 0.7997,
      "step": 223400
    },
    {
      "epoch": 360.35,
      "learning_rate": 0.06397890698887097,
      "loss": 0.7974,
      "step": 223420
    },
    {
      "epoch": 360.39,
      "learning_rate": 0.06397568118564517,
      "loss": 0.8321,
      "step": 223440
    },
    {
      "epoch": 360.42,
      "learning_rate": 0.06397245538241936,
      "loss": 0.834,
      "step": 223460
    },
    {
      "epoch": 360.45,
      "learning_rate": 0.06396922957919356,
      "loss": 0.8239,
      "step": 223480
    },
    {
      "epoch": 360.48,
      "learning_rate": 0.06396600377596774,
      "loss": 0.8359,
      "step": 223500
    },
    {
      "epoch": 360.52,
      "learning_rate": 0.06396277797274194,
      "loss": 0.8272,
      "step": 223520
    },
    {
      "epoch": 360.55,
      "learning_rate": 0.06395955216951613,
      "loss": 0.8269,
      "step": 223540
    },
    {
      "epoch": 360.58,
      "learning_rate": 0.06395632636629033,
      "loss": 0.8137,
      "step": 223560
    },
    {
      "epoch": 360.61,
      "learning_rate": 0.06395310056306452,
      "loss": 0.8247,
      "step": 223580
    },
    {
      "epoch": 360.65,
      "learning_rate": 0.06394987475983871,
      "loss": 0.8005,
      "step": 223600
    },
    {
      "epoch": 360.68,
      "learning_rate": 0.06394664895661291,
      "loss": 0.8194,
      "step": 223620
    },
    {
      "epoch": 360.71,
      "learning_rate": 0.06394342315338711,
      "loss": 0.8228,
      "step": 223640
    },
    {
      "epoch": 360.74,
      "learning_rate": 0.06394019735016129,
      "loss": 0.8232,
      "step": 223660
    },
    {
      "epoch": 360.77,
      "learning_rate": 0.06393697154693548,
      "loss": 0.8198,
      "step": 223680
    },
    {
      "epoch": 360.81,
      "learning_rate": 0.06393374574370969,
      "loss": 0.8063,
      "step": 223700
    },
    {
      "epoch": 360.84,
      "learning_rate": 0.06393051994048388,
      "loss": 0.7953,
      "step": 223720
    },
    {
      "epoch": 360.87,
      "learning_rate": 0.06392729413725808,
      "loss": 0.8074,
      "step": 223740
    },
    {
      "epoch": 360.9,
      "learning_rate": 0.06392406833403226,
      "loss": 0.8088,
      "step": 223760
    },
    {
      "epoch": 360.94,
      "learning_rate": 0.06392084253080646,
      "loss": 0.824,
      "step": 223780
    },
    {
      "epoch": 360.97,
      "learning_rate": 0.06391761672758065,
      "loss": 0.8251,
      "step": 223800
    },
    {
      "epoch": 361.0,
      "learning_rate": 0.06391455221451613,
      "loss": 0.8213,
      "step": 223820
    },
    {
      "epoch": 361.0,
      "eval_accuracy": {
        "accuracy": 0.7533369760362189
      },
      "eval_loss": 1.2006913423538208,
      "eval_runtime": 2.9546,
      "eval_samples_per_second": 4335.982,
      "eval_steps_per_second": 68.03,
      "step": 223820
    },
    {
      "epoch": 361.03,
      "learning_rate": 0.06391132641129033,
      "loss": 0.7861,
      "step": 223840
    },
    {
      "epoch": 361.06,
      "learning_rate": 0.06390810060806451,
      "loss": 0.8107,
      "step": 223860
    },
    {
      "epoch": 361.1,
      "learning_rate": 0.06390487480483872,
      "loss": 0.8067,
      "step": 223880
    },
    {
      "epoch": 361.13,
      "learning_rate": 0.06390164900161291,
      "loss": 0.8141,
      "step": 223900
    },
    {
      "epoch": 361.16,
      "learning_rate": 0.06389842319838711,
      "loss": 0.8009,
      "step": 223920
    },
    {
      "epoch": 361.19,
      "learning_rate": 0.0638951973951613,
      "loss": 0.8074,
      "step": 223940
    },
    {
      "epoch": 361.23,
      "learning_rate": 0.06389197159193549,
      "loss": 0.8105,
      "step": 223960
    },
    {
      "epoch": 361.26,
      "learning_rate": 0.06388874578870968,
      "loss": 0.8051,
      "step": 223980
    },
    {
      "epoch": 361.29,
      "learning_rate": 0.06388551998548388,
      "loss": 0.8063,
      "step": 224000
    },
    {
      "epoch": 361.32,
      "learning_rate": 0.06388229418225806,
      "loss": 0.8165,
      "step": 224020
    },
    {
      "epoch": 361.35,
      "learning_rate": 0.06387906837903226,
      "loss": 0.8212,
      "step": 224040
    },
    {
      "epoch": 361.39,
      "learning_rate": 0.06387584257580646,
      "loss": 0.8154,
      "step": 224060
    },
    {
      "epoch": 361.42,
      "learning_rate": 0.06387261677258065,
      "loss": 0.8078,
      "step": 224080
    },
    {
      "epoch": 361.45,
      "learning_rate": 0.06386939096935484,
      "loss": 0.8011,
      "step": 224100
    },
    {
      "epoch": 361.48,
      "learning_rate": 0.06386616516612903,
      "loss": 0.8182,
      "step": 224120
    },
    {
      "epoch": 361.52,
      "learning_rate": 0.06386293936290323,
      "loss": 0.8359,
      "step": 224140
    },
    {
      "epoch": 361.55,
      "learning_rate": 0.06385971355967741,
      "loss": 0.8353,
      "step": 224160
    },
    {
      "epoch": 361.58,
      "learning_rate": 0.06385648775645163,
      "loss": 0.8102,
      "step": 224180
    },
    {
      "epoch": 361.61,
      "learning_rate": 0.06385326195322581,
      "loss": 0.8293,
      "step": 224200
    },
    {
      "epoch": 361.65,
      "learning_rate": 0.06385003615000001,
      "loss": 0.8317,
      "step": 224220
    },
    {
      "epoch": 361.68,
      "learning_rate": 0.0638468103467742,
      "loss": 0.8294,
      "step": 224240
    },
    {
      "epoch": 361.71,
      "learning_rate": 0.0638435845435484,
      "loss": 0.8138,
      "step": 224260
    },
    {
      "epoch": 361.74,
      "learning_rate": 0.06384035874032258,
      "loss": 0.7937,
      "step": 224280
    },
    {
      "epoch": 361.77,
      "learning_rate": 0.06383713293709678,
      "loss": 0.8376,
      "step": 224300
    },
    {
      "epoch": 361.81,
      "learning_rate": 0.06383390713387097,
      "loss": 0.8302,
      "step": 224320
    },
    {
      "epoch": 361.84,
      "learning_rate": 0.06383068133064516,
      "loss": 0.8382,
      "step": 224340
    },
    {
      "epoch": 361.87,
      "learning_rate": 0.06382745552741936,
      "loss": 0.8224,
      "step": 224360
    },
    {
      "epoch": 361.9,
      "learning_rate": 0.06382422972419355,
      "loss": 0.8179,
      "step": 224380
    },
    {
      "epoch": 361.94,
      "learning_rate": 0.06382100392096775,
      "loss": 0.8322,
      "step": 224400
    },
    {
      "epoch": 361.97,
      "learning_rate": 0.06381777811774193,
      "loss": 0.8211,
      "step": 224420
    },
    {
      "epoch": 362.0,
      "learning_rate": 0.06381455231451613,
      "loss": 0.8114,
      "step": 224440
    },
    {
      "epoch": 362.0,
      "eval_accuracy": {
        "accuracy": 0.7481851533838108
      },
      "eval_loss": 1.2104806900024414,
      "eval_runtime": 2.784,
      "eval_samples_per_second": 4601.629,
      "eval_steps_per_second": 72.198,
      "step": 224440
    },
    {
      "epoch": 362.03,
      "learning_rate": 0.06381132651129032,
      "loss": 0.8331,
      "step": 224460
    },
    {
      "epoch": 362.06,
      "learning_rate": 0.06380810070806453,
      "loss": 0.7928,
      "step": 224480
    },
    {
      "epoch": 362.1,
      "learning_rate": 0.06380487490483872,
      "loss": 0.8309,
      "step": 224500
    },
    {
      "epoch": 362.13,
      "learning_rate": 0.06380164910161291,
      "loss": 0.8175,
      "step": 224520
    },
    {
      "epoch": 362.16,
      "learning_rate": 0.0637984232983871,
      "loss": 0.7877,
      "step": 224540
    },
    {
      "epoch": 362.19,
      "learning_rate": 0.0637951974951613,
      "loss": 0.8059,
      "step": 224560
    },
    {
      "epoch": 362.23,
      "learning_rate": 0.06379197169193548,
      "loss": 0.8142,
      "step": 224580
    },
    {
      "epoch": 362.26,
      "learning_rate": 0.06378874588870968,
      "loss": 0.8095,
      "step": 224600
    },
    {
      "epoch": 362.29,
      "learning_rate": 0.06378552008548387,
      "loss": 0.8204,
      "step": 224620
    },
    {
      "epoch": 362.32,
      "learning_rate": 0.06378229428225807,
      "loss": 0.8166,
      "step": 224640
    },
    {
      "epoch": 362.35,
      "learning_rate": 0.06377906847903227,
      "loss": 0.8111,
      "step": 224660
    },
    {
      "epoch": 362.39,
      "learning_rate": 0.06377584267580645,
      "loss": 0.8179,
      "step": 224680
    },
    {
      "epoch": 362.42,
      "learning_rate": 0.06377261687258065,
      "loss": 0.812,
      "step": 224700
    },
    {
      "epoch": 362.45,
      "learning_rate": 0.06376939106935485,
      "loss": 0.8027,
      "step": 224720
    },
    {
      "epoch": 362.48,
      "learning_rate": 0.06376616526612904,
      "loss": 0.8101,
      "step": 224740
    },
    {
      "epoch": 362.52,
      "learning_rate": 0.06376293946290322,
      "loss": 0.7762,
      "step": 224760
    },
    {
      "epoch": 362.55,
      "learning_rate": 0.06375971365967743,
      "loss": 0.7966,
      "step": 224780
    },
    {
      "epoch": 362.58,
      "learning_rate": 0.06375648785645162,
      "loss": 0.8167,
      "step": 224800
    },
    {
      "epoch": 362.61,
      "learning_rate": 0.06375326205322582,
      "loss": 0.8131,
      "step": 224820
    },
    {
      "epoch": 362.65,
      "learning_rate": 0.06375003625,
      "loss": 0.8255,
      "step": 224840
    },
    {
      "epoch": 362.68,
      "learning_rate": 0.0637468104467742,
      "loss": 0.7986,
      "step": 224860
    },
    {
      "epoch": 362.71,
      "learning_rate": 0.06374358464354839,
      "loss": 0.7783,
      "step": 224880
    },
    {
      "epoch": 362.74,
      "learning_rate": 0.06374035884032259,
      "loss": 0.8167,
      "step": 224900
    },
    {
      "epoch": 362.77,
      "learning_rate": 0.06373713303709677,
      "loss": 0.8169,
      "step": 224920
    },
    {
      "epoch": 362.81,
      "learning_rate": 0.06373390723387097,
      "loss": 0.8208,
      "step": 224940
    },
    {
      "epoch": 362.84,
      "learning_rate": 0.06373068143064517,
      "loss": 0.8336,
      "step": 224960
    },
    {
      "epoch": 362.87,
      "learning_rate": 0.06372745562741935,
      "loss": 0.8277,
      "step": 224980
    },
    {
      "epoch": 362.9,
      "learning_rate": 0.06372422982419355,
      "loss": 0.8124,
      "step": 225000
    },
    {
      "epoch": 362.94,
      "learning_rate": 0.06372100402096775,
      "loss": 0.8214,
      "step": 225020
    },
    {
      "epoch": 362.97,
      "learning_rate": 0.06371777821774194,
      "loss": 0.8374,
      "step": 225040
    },
    {
      "epoch": 363.0,
      "learning_rate": 0.06371455241451612,
      "loss": 0.8626,
      "step": 225060
    },
    {
      "epoch": 363.0,
      "eval_accuracy": {
        "accuracy": 0.7431113886503786
      },
      "eval_loss": 1.2591265439987183,
      "eval_runtime": 3.0267,
      "eval_samples_per_second": 4232.68,
      "eval_steps_per_second": 66.409,
      "step": 225060
    },
    {
      "epoch": 363.03,
      "learning_rate": 0.06371132661129034,
      "loss": 0.8579,
      "step": 225080
    },
    {
      "epoch": 363.06,
      "learning_rate": 0.06370810080806451,
      "loss": 0.8208,
      "step": 225100
    },
    {
      "epoch": 363.1,
      "learning_rate": 0.06370487500483872,
      "loss": 0.8252,
      "step": 225120
    },
    {
      "epoch": 363.13,
      "learning_rate": 0.0637016492016129,
      "loss": 0.8285,
      "step": 225140
    },
    {
      "epoch": 363.16,
      "learning_rate": 0.0636984233983871,
      "loss": 0.8014,
      "step": 225160
    },
    {
      "epoch": 363.19,
      "learning_rate": 0.06369519759516129,
      "loss": 0.8014,
      "step": 225180
    },
    {
      "epoch": 363.23,
      "learning_rate": 0.06369197179193549,
      "loss": 0.7892,
      "step": 225200
    },
    {
      "epoch": 363.26,
      "learning_rate": 0.06368874598870967,
      "loss": 0.7885,
      "step": 225220
    },
    {
      "epoch": 363.29,
      "learning_rate": 0.06368552018548387,
      "loss": 0.8135,
      "step": 225240
    },
    {
      "epoch": 363.32,
      "learning_rate": 0.06368229438225807,
      "loss": 0.8044,
      "step": 225260
    },
    {
      "epoch": 363.35,
      "learning_rate": 0.06367906857903226,
      "loss": 0.8279,
      "step": 225280
    },
    {
      "epoch": 363.39,
      "learning_rate": 0.06367584277580646,
      "loss": 0.8043,
      "step": 225300
    },
    {
      "epoch": 363.42,
      "learning_rate": 0.06367261697258066,
      "loss": 0.8281,
      "step": 225320
    },
    {
      "epoch": 363.45,
      "learning_rate": 0.06366939116935484,
      "loss": 0.8281,
      "step": 225340
    },
    {
      "epoch": 363.48,
      "learning_rate": 0.06366616536612903,
      "loss": 0.8148,
      "step": 225360
    },
    {
      "epoch": 363.52,
      "learning_rate": 0.06366293956290324,
      "loss": 0.7938,
      "step": 225380
    },
    {
      "epoch": 363.55,
      "learning_rate": 0.06365971375967741,
      "loss": 0.8155,
      "step": 225400
    },
    {
      "epoch": 363.58,
      "learning_rate": 0.06365648795645162,
      "loss": 0.8148,
      "step": 225420
    },
    {
      "epoch": 363.61,
      "learning_rate": 0.06365326215322581,
      "loss": 0.8003,
      "step": 225440
    },
    {
      "epoch": 363.65,
      "learning_rate": 0.06365003635000001,
      "loss": 0.8398,
      "step": 225460
    },
    {
      "epoch": 363.68,
      "learning_rate": 0.0636468105467742,
      "loss": 0.8054,
      "step": 225480
    },
    {
      "epoch": 363.71,
      "learning_rate": 0.0636435847435484,
      "loss": 0.8151,
      "step": 225500
    },
    {
      "epoch": 363.74,
      "learning_rate": 0.06364035894032258,
      "loss": 0.8307,
      "step": 225520
    },
    {
      "epoch": 363.77,
      "learning_rate": 0.06363713313709678,
      "loss": 0.8222,
      "step": 225540
    },
    {
      "epoch": 363.81,
      "learning_rate": 0.06363390733387098,
      "loss": 0.8115,
      "step": 225560
    },
    {
      "epoch": 363.84,
      "learning_rate": 0.06363068153064516,
      "loss": 0.8284,
      "step": 225580
    },
    {
      "epoch": 363.87,
      "learning_rate": 0.06362745572741936,
      "loss": 0.8231,
      "step": 225600
    },
    {
      "epoch": 363.9,
      "learning_rate": 0.06362422992419356,
      "loss": 0.8261,
      "step": 225620
    },
    {
      "epoch": 363.94,
      "learning_rate": 0.06362100412096774,
      "loss": 0.8153,
      "step": 225640
    },
    {
      "epoch": 363.97,
      "learning_rate": 0.06361777831774194,
      "loss": 0.8373,
      "step": 225660
    },
    {
      "epoch": 364.0,
      "learning_rate": 0.06361455251451614,
      "loss": 0.8266,
      "step": 225680
    },
    {
      "epoch": 364.0,
      "eval_accuracy": {
        "accuracy": 0.7513855280618219
      },
      "eval_loss": 1.189410924911499,
      "eval_runtime": 3.4551,
      "eval_samples_per_second": 3707.857,
      "eval_steps_per_second": 58.175,
      "step": 225680
    },
    {
      "epoch": 364.03,
      "learning_rate": 0.06361132671129031,
      "loss": 0.8486,
      "step": 225700
    },
    {
      "epoch": 364.06,
      "learning_rate": 0.06360810090806453,
      "loss": 0.8068,
      "step": 225720
    },
    {
      "epoch": 364.1,
      "learning_rate": 0.06360487510483871,
      "loss": 0.8125,
      "step": 225740
    },
    {
      "epoch": 364.13,
      "learning_rate": 0.06360164930161291,
      "loss": 0.8141,
      "step": 225760
    },
    {
      "epoch": 364.16,
      "learning_rate": 0.0635984234983871,
      "loss": 0.8028,
      "step": 225780
    },
    {
      "epoch": 364.19,
      "learning_rate": 0.0635951976951613,
      "loss": 0.8104,
      "step": 225800
    },
    {
      "epoch": 364.23,
      "learning_rate": 0.06359197189193548,
      "loss": 0.8087,
      "step": 225820
    },
    {
      "epoch": 364.26,
      "learning_rate": 0.06358874608870968,
      "loss": 0.7944,
      "step": 225840
    },
    {
      "epoch": 364.29,
      "learning_rate": 0.06358552028548388,
      "loss": 0.8057,
      "step": 225860
    },
    {
      "epoch": 364.32,
      "learning_rate": 0.06358229448225806,
      "loss": 0.8043,
      "step": 225880
    },
    {
      "epoch": 364.35,
      "learning_rate": 0.06357906867903226,
      "loss": 0.8169,
      "step": 225900
    },
    {
      "epoch": 364.39,
      "learning_rate": 0.06357584287580646,
      "loss": 0.8058,
      "step": 225920
    },
    {
      "epoch": 364.42,
      "learning_rate": 0.06357261707258065,
      "loss": 0.8092,
      "step": 225940
    },
    {
      "epoch": 364.45,
      "learning_rate": 0.06356939126935485,
      "loss": 0.7957,
      "step": 225960
    },
    {
      "epoch": 364.48,
      "learning_rate": 0.06356616546612905,
      "loss": 0.8346,
      "step": 225980
    },
    {
      "epoch": 364.52,
      "learning_rate": 0.06356293966290322,
      "loss": 0.8445,
      "step": 226000
    },
    {
      "epoch": 364.55,
      "learning_rate": 0.06355971385967743,
      "loss": 0.8079,
      "step": 226020
    },
    {
      "epoch": 364.58,
      "learning_rate": 0.06355648805645162,
      "loss": 0.8279,
      "step": 226040
    },
    {
      "epoch": 364.61,
      "learning_rate": 0.06355326225322581,
      "loss": 0.8079,
      "step": 226060
    },
    {
      "epoch": 364.65,
      "learning_rate": 0.06355003645,
      "loss": 0.8163,
      "step": 226080
    },
    {
      "epoch": 364.68,
      "learning_rate": 0.0635468106467742,
      "loss": 0.8285,
      "step": 226100
    },
    {
      "epoch": 364.71,
      "learning_rate": 0.06354358484354838,
      "loss": 0.819,
      "step": 226120
    },
    {
      "epoch": 364.74,
      "learning_rate": 0.06354035904032258,
      "loss": 0.8125,
      "step": 226140
    },
    {
      "epoch": 364.77,
      "learning_rate": 0.06353713323709678,
      "loss": 0.8324,
      "step": 226160
    },
    {
      "epoch": 364.81,
      "learning_rate": 0.06353390743387097,
      "loss": 0.8127,
      "step": 226180
    },
    {
      "epoch": 364.84,
      "learning_rate": 0.06353068163064517,
      "loss": 0.8013,
      "step": 226200
    },
    {
      "epoch": 364.87,
      "learning_rate": 0.06352745582741937,
      "loss": 0.8475,
      "step": 226220
    },
    {
      "epoch": 364.9,
      "learning_rate": 0.06352423002419355,
      "loss": 0.8128,
      "step": 226240
    },
    {
      "epoch": 364.94,
      "learning_rate": 0.06352100422096775,
      "loss": 0.8518,
      "step": 226260
    },
    {
      "epoch": 364.97,
      "learning_rate": 0.06351777841774195,
      "loss": 0.8314,
      "step": 226280
    },
    {
      "epoch": 365.0,
      "learning_rate": 0.06351471390467742,
      "loss": 0.8186,
      "step": 226300
    },
    {
      "epoch": 365.0,
      "eval_accuracy": {
        "accuracy": 0.7547420185777847
      },
      "eval_loss": 1.1554815769195557,
      "eval_runtime": 2.7302,
      "eval_samples_per_second": 4692.313,
      "eval_steps_per_second": 73.621,
      "step": 226300
    },
    {
      "epoch": 365.03,
      "learning_rate": 0.06351148810145162,
      "loss": 0.7872,
      "step": 226320
    },
    {
      "epoch": 365.06,
      "learning_rate": 0.06350826229822581,
      "loss": 0.7868,
      "step": 226340
    },
    {
      "epoch": 365.1,
      "learning_rate": 0.063505036495,
      "loss": 0.8011,
      "step": 226360
    },
    {
      "epoch": 365.13,
      "learning_rate": 0.0635018106917742,
      "loss": 0.8146,
      "step": 226380
    },
    {
      "epoch": 365.16,
      "learning_rate": 0.0634985848885484,
      "loss": 0.7994,
      "step": 226400
    },
    {
      "epoch": 365.19,
      "learning_rate": 0.06349535908532258,
      "loss": 0.8294,
      "step": 226420
    },
    {
      "epoch": 365.23,
      "learning_rate": 0.06349213328209677,
      "loss": 0.7955,
      "step": 226440
    },
    {
      "epoch": 365.26,
      "learning_rate": 0.06348890747887098,
      "loss": 0.7894,
      "step": 226460
    },
    {
      "epoch": 365.29,
      "learning_rate": 0.06348568167564515,
      "loss": 0.8312,
      "step": 226480
    },
    {
      "epoch": 365.32,
      "learning_rate": 0.06348245587241937,
      "loss": 0.8363,
      "step": 226500
    },
    {
      "epoch": 365.35,
      "learning_rate": 0.06347923006919355,
      "loss": 0.8022,
      "step": 226520
    },
    {
      "epoch": 365.39,
      "learning_rate": 0.06347600426596775,
      "loss": 0.8147,
      "step": 226540
    },
    {
      "epoch": 365.42,
      "learning_rate": 0.06347277846274194,
      "loss": 0.7904,
      "step": 226560
    },
    {
      "epoch": 365.45,
      "learning_rate": 0.06346955265951615,
      "loss": 0.8315,
      "step": 226580
    },
    {
      "epoch": 365.48,
      "learning_rate": 0.06346632685629032,
      "loss": 0.8195,
      "step": 226600
    },
    {
      "epoch": 365.52,
      "learning_rate": 0.06346310105306452,
      "loss": 0.8172,
      "step": 226620
    },
    {
      "epoch": 365.55,
      "learning_rate": 0.06345987524983872,
      "loss": 0.8109,
      "step": 226640
    },
    {
      "epoch": 365.58,
      "learning_rate": 0.0634566494466129,
      "loss": 0.8285,
      "step": 226660
    },
    {
      "epoch": 365.61,
      "learning_rate": 0.0634534236433871,
      "loss": 0.8366,
      "step": 226680
    },
    {
      "epoch": 365.65,
      "learning_rate": 0.0634501978401613,
      "loss": 0.8054,
      "step": 226700
    },
    {
      "epoch": 365.68,
      "learning_rate": 0.06344697203693549,
      "loss": 0.8298,
      "step": 226720
    },
    {
      "epoch": 365.71,
      "learning_rate": 0.06344374623370967,
      "loss": 0.8103,
      "step": 226740
    },
    {
      "epoch": 365.74,
      "learning_rate": 0.06344052043048388,
      "loss": 0.81,
      "step": 226760
    },
    {
      "epoch": 365.77,
      "learning_rate": 0.06343729462725806,
      "loss": 0.8218,
      "step": 226780
    },
    {
      "epoch": 365.81,
      "learning_rate": 0.06343406882403227,
      "loss": 0.7902,
      "step": 226800
    },
    {
      "epoch": 365.84,
      "learning_rate": 0.06343084302080645,
      "loss": 0.8251,
      "step": 226820
    },
    {
      "epoch": 365.87,
      "learning_rate": 0.06342761721758065,
      "loss": 0.8165,
      "step": 226840
    },
    {
      "epoch": 365.9,
      "learning_rate": 0.06342439141435484,
      "loss": 0.8295,
      "step": 226860
    },
    {
      "epoch": 365.94,
      "learning_rate": 0.06342116561112904,
      "loss": 0.8291,
      "step": 226880
    },
    {
      "epoch": 365.97,
      "learning_rate": 0.06341793980790322,
      "loss": 0.8202,
      "step": 226900
    },
    {
      "epoch": 366.0,
      "learning_rate": 0.06341471400467742,
      "loss": 0.8017,
      "step": 226920
    },
    {
      "epoch": 366.0,
      "eval_accuracy": {
        "accuracy": 0.7533369760362189
      },
      "eval_loss": 1.1636102199554443,
      "eval_runtime": 2.6842,
      "eval_samples_per_second": 4772.814,
      "eval_steps_per_second": 74.884,
      "step": 226920
    },
    {
      "epoch": 366.03,
      "learning_rate": 0.06341148820145162,
      "loss": 0.8546,
      "step": 226940
    },
    {
      "epoch": 366.06,
      "learning_rate": 0.0634082623982258,
      "loss": 0.8223,
      "step": 226960
    },
    {
      "epoch": 366.1,
      "learning_rate": 0.063405036595,
      "loss": 0.8031,
      "step": 226980
    },
    {
      "epoch": 366.13,
      "learning_rate": 0.0634018107917742,
      "loss": 0.8012,
      "step": 227000
    },
    {
      "epoch": 366.16,
      "learning_rate": 0.06339858498854839,
      "loss": 0.8224,
      "step": 227020
    },
    {
      "epoch": 366.19,
      "learning_rate": 0.06339535918532259,
      "loss": 0.7942,
      "step": 227040
    },
    {
      "epoch": 366.23,
      "learning_rate": 0.06339213338209679,
      "loss": 0.8093,
      "step": 227060
    },
    {
      "epoch": 366.26,
      "learning_rate": 0.06338890757887096,
      "loss": 0.7941,
      "step": 227080
    },
    {
      "epoch": 366.29,
      "learning_rate": 0.06338568177564517,
      "loss": 0.817,
      "step": 227100
    },
    {
      "epoch": 366.32,
      "learning_rate": 0.06338245597241936,
      "loss": 0.7941,
      "step": 227120
    },
    {
      "epoch": 366.35,
      "learning_rate": 0.06337923016919356,
      "loss": 0.7968,
      "step": 227140
    },
    {
      "epoch": 366.39,
      "learning_rate": 0.06337600436596774,
      "loss": 0.7883,
      "step": 227160
    },
    {
      "epoch": 366.42,
      "learning_rate": 0.06337277856274194,
      "loss": 0.8212,
      "step": 227180
    },
    {
      "epoch": 366.45,
      "learning_rate": 0.06336955275951613,
      "loss": 0.8302,
      "step": 227200
    },
    {
      "epoch": 366.48,
      "learning_rate": 0.06336632695629033,
      "loss": 0.8137,
      "step": 227220
    },
    {
      "epoch": 366.52,
      "learning_rate": 0.06336310115306452,
      "loss": 0.8199,
      "step": 227240
    },
    {
      "epoch": 366.55,
      "learning_rate": 0.06335987534983871,
      "loss": 0.8271,
      "step": 227260
    },
    {
      "epoch": 366.58,
      "learning_rate": 0.06335664954661291,
      "loss": 0.8273,
      "step": 227280
    },
    {
      "epoch": 366.61,
      "learning_rate": 0.06335342374338711,
      "loss": 0.8392,
      "step": 227300
    },
    {
      "epoch": 366.65,
      "learning_rate": 0.06335019794016129,
      "loss": 0.8159,
      "step": 227320
    },
    {
      "epoch": 366.68,
      "learning_rate": 0.06334697213693549,
      "loss": 0.8189,
      "step": 227340
    },
    {
      "epoch": 366.71,
      "learning_rate": 0.06334374633370969,
      "loss": 0.8246,
      "step": 227360
    },
    {
      "epoch": 366.74,
      "learning_rate": 0.06334052053048386,
      "loss": 0.8118,
      "step": 227380
    },
    {
      "epoch": 366.77,
      "learning_rate": 0.06333729472725808,
      "loss": 0.8196,
      "step": 227400
    },
    {
      "epoch": 366.81,
      "learning_rate": 0.06333406892403226,
      "loss": 0.8139,
      "step": 227420
    },
    {
      "epoch": 366.84,
      "learning_rate": 0.06333084312080646,
      "loss": 0.8243,
      "step": 227440
    },
    {
      "epoch": 366.87,
      "learning_rate": 0.06332761731758065,
      "loss": 0.8053,
      "step": 227460
    },
    {
      "epoch": 366.9,
      "learning_rate": 0.06332439151435484,
      "loss": 0.8069,
      "step": 227480
    },
    {
      "epoch": 366.94,
      "learning_rate": 0.06332116571112903,
      "loss": 0.8162,
      "step": 227500
    },
    {
      "epoch": 366.97,
      "learning_rate": 0.06331793990790323,
      "loss": 0.8417,
      "step": 227520
    },
    {
      "epoch": 367.0,
      "learning_rate": 0.06331471410467743,
      "loss": 0.8394,
      "step": 227540
    },
    {
      "epoch": 367.0,
      "eval_accuracy": {
        "accuracy": 0.748653500897666
      },
      "eval_loss": 1.1991544961929321,
      "eval_runtime": 2.8676,
      "eval_samples_per_second": 4467.534,
      "eval_steps_per_second": 70.094,
      "step": 227540
    },
    {
      "epoch": 367.03,
      "learning_rate": 0.06331148830145161,
      "loss": 0.8524,
      "step": 227560
    },
    {
      "epoch": 367.06,
      "learning_rate": 0.06330826249822581,
      "loss": 0.8164,
      "step": 227580
    },
    {
      "epoch": 367.1,
      "learning_rate": 0.06330503669500001,
      "loss": 0.83,
      "step": 227600
    },
    {
      "epoch": 367.13,
      "learning_rate": 0.0633018108917742,
      "loss": 0.788,
      "step": 227620
    },
    {
      "epoch": 367.16,
      "learning_rate": 0.0632985850885484,
      "loss": 0.7973,
      "step": 227640
    },
    {
      "epoch": 367.19,
      "learning_rate": 0.0632953592853226,
      "loss": 0.7731,
      "step": 227660
    },
    {
      "epoch": 367.23,
      "learning_rate": 0.06329213348209677,
      "loss": 0.8035,
      "step": 227680
    },
    {
      "epoch": 367.26,
      "learning_rate": 0.06328890767887098,
      "loss": 0.79,
      "step": 227700
    },
    {
      "epoch": 367.29,
      "learning_rate": 0.06328568187564516,
      "loss": 0.787,
      "step": 227720
    },
    {
      "epoch": 367.32,
      "learning_rate": 0.06328245607241936,
      "loss": 0.7869,
      "step": 227740
    },
    {
      "epoch": 367.35,
      "learning_rate": 0.06327923026919355,
      "loss": 0.8122,
      "step": 227760
    },
    {
      "epoch": 367.39,
      "learning_rate": 0.06327600446596775,
      "loss": 0.824,
      "step": 227780
    },
    {
      "epoch": 367.42,
      "learning_rate": 0.06327277866274193,
      "loss": 0.8162,
      "step": 227800
    },
    {
      "epoch": 367.45,
      "learning_rate": 0.06326955285951615,
      "loss": 0.8156,
      "step": 227820
    },
    {
      "epoch": 367.48,
      "learning_rate": 0.06326632705629033,
      "loss": 0.8153,
      "step": 227840
    },
    {
      "epoch": 367.52,
      "learning_rate": 0.06326310125306452,
      "loss": 0.7908,
      "step": 227860
    },
    {
      "epoch": 367.55,
      "learning_rate": 0.06325987544983872,
      "loss": 0.7989,
      "step": 227880
    },
    {
      "epoch": 367.58,
      "learning_rate": 0.06325664964661291,
      "loss": 0.8173,
      "step": 227900
    },
    {
      "epoch": 367.61,
      "learning_rate": 0.0632534238433871,
      "loss": 0.8086,
      "step": 227920
    },
    {
      "epoch": 367.65,
      "learning_rate": 0.0632501980401613,
      "loss": 0.7995,
      "step": 227940
    },
    {
      "epoch": 367.68,
      "learning_rate": 0.06324697223693548,
      "loss": 0.806,
      "step": 227960
    },
    {
      "epoch": 367.71,
      "learning_rate": 0.06324374643370968,
      "loss": 0.8096,
      "step": 227980
    },
    {
      "epoch": 367.74,
      "learning_rate": 0.06324052063048388,
      "loss": 0.8163,
      "step": 228000
    },
    {
      "epoch": 367.77,
      "learning_rate": 0.06323729482725807,
      "loss": 0.7986,
      "step": 228020
    },
    {
      "epoch": 367.81,
      "learning_rate": 0.06323406902403227,
      "loss": 0.8405,
      "step": 228040
    },
    {
      "epoch": 367.84,
      "learning_rate": 0.06323084322080645,
      "loss": 0.7954,
      "step": 228060
    },
    {
      "epoch": 367.87,
      "learning_rate": 0.06322761741758065,
      "loss": 0.8159,
      "step": 228080
    },
    {
      "epoch": 367.9,
      "learning_rate": 0.06322439161435484,
      "loss": 0.8238,
      "step": 228100
    },
    {
      "epoch": 367.94,
      "learning_rate": 0.06322116581112905,
      "loss": 0.8178,
      "step": 228120
    },
    {
      "epoch": 367.97,
      "learning_rate": 0.06321794000790323,
      "loss": 0.8324,
      "step": 228140
    },
    {
      "epoch": 368.0,
      "learning_rate": 0.06321471420467742,
      "loss": 0.8396,
      "step": 228160
    },
    {
      "epoch": 368.0,
      "eval_accuracy": {
        "accuracy": 0.749980485520256
      },
      "eval_loss": 1.2092130184173584,
      "eval_runtime": 2.8354,
      "eval_samples_per_second": 4518.258,
      "eval_steps_per_second": 70.89,
      "step": 228160
    },
    {
      "epoch": 368.03,
      "learning_rate": 0.06321148840145162,
      "loss": 0.844,
      "step": 228180
    },
    {
      "epoch": 368.06,
      "learning_rate": 0.06320826259822582,
      "loss": 0.7994,
      "step": 228200
    },
    {
      "epoch": 368.1,
      "learning_rate": 0.063205036795,
      "loss": 0.8082,
      "step": 228220
    },
    {
      "epoch": 368.13,
      "learning_rate": 0.0632018109917742,
      "loss": 0.8101,
      "step": 228240
    },
    {
      "epoch": 368.16,
      "learning_rate": 0.06319858518854839,
      "loss": 0.7667,
      "step": 228260
    },
    {
      "epoch": 368.19,
      "learning_rate": 0.06319535938532259,
      "loss": 0.8001,
      "step": 228280
    },
    {
      "epoch": 368.23,
      "learning_rate": 0.06319213358209678,
      "loss": 0.7934,
      "step": 228300
    },
    {
      "epoch": 368.26,
      "learning_rate": 0.06318890777887097,
      "loss": 0.8165,
      "step": 228320
    },
    {
      "epoch": 368.29,
      "learning_rate": 0.06318568197564517,
      "loss": 0.8222,
      "step": 228340
    },
    {
      "epoch": 368.32,
      "learning_rate": 0.06318245617241935,
      "loss": 0.7959,
      "step": 228360
    },
    {
      "epoch": 368.35,
      "learning_rate": 0.06317923036919355,
      "loss": 0.8149,
      "step": 228380
    },
    {
      "epoch": 368.39,
      "learning_rate": 0.06317600456596774,
      "loss": 0.7845,
      "step": 228400
    },
    {
      "epoch": 368.42,
      "learning_rate": 0.06317277876274195,
      "loss": 0.8235,
      "step": 228420
    },
    {
      "epoch": 368.45,
      "learning_rate": 0.06316971424967743,
      "loss": 0.8038,
      "step": 228440
    },
    {
      "epoch": 368.48,
      "learning_rate": 0.0631664884464516,
      "loss": 0.8051,
      "step": 228460
    },
    {
      "epoch": 368.52,
      "learning_rate": 0.06316326264322582,
      "loss": 0.7994,
      "step": 228480
    },
    {
      "epoch": 368.55,
      "learning_rate": 0.06316003684,
      "loss": 0.8263,
      "step": 228500
    },
    {
      "epoch": 368.58,
      "learning_rate": 0.0631568110367742,
      "loss": 0.8413,
      "step": 228520
    },
    {
      "epoch": 368.61,
      "learning_rate": 0.06315358523354839,
      "loss": 0.8152,
      "step": 228540
    },
    {
      "epoch": 368.65,
      "learning_rate": 0.06315035943032259,
      "loss": 0.8204,
      "step": 228560
    },
    {
      "epoch": 368.68,
      "learning_rate": 0.06314713362709677,
      "loss": 0.8228,
      "step": 228580
    },
    {
      "epoch": 368.71,
      "learning_rate": 0.06314390782387097,
      "loss": 0.8129,
      "step": 228600
    },
    {
      "epoch": 368.74,
      "learning_rate": 0.06314068202064517,
      "loss": 0.8218,
      "step": 228620
    },
    {
      "epoch": 368.77,
      "learning_rate": 0.06313745621741935,
      "loss": 0.8507,
      "step": 228640
    },
    {
      "epoch": 368.81,
      "learning_rate": 0.06313423041419355,
      "loss": 0.8352,
      "step": 228660
    },
    {
      "epoch": 368.84,
      "learning_rate": 0.06313100461096775,
      "loss": 0.8449,
      "step": 228680
    },
    {
      "epoch": 368.87,
      "learning_rate": 0.06312777880774194,
      "loss": 0.8338,
      "step": 228700
    },
    {
      "epoch": 368.9,
      "learning_rate": 0.06312455300451614,
      "loss": 0.8315,
      "step": 228720
    },
    {
      "epoch": 368.94,
      "learning_rate": 0.06312132720129034,
      "loss": 0.8399,
      "step": 228740
    },
    {
      "epoch": 368.97,
      "learning_rate": 0.06311810139806451,
      "loss": 0.8366,
      "step": 228760
    },
    {
      "epoch": 369.0,
      "learning_rate": 0.06311487559483872,
      "loss": 0.8395,
      "step": 228780
    },
    {
      "epoch": 369.0,
      "eval_accuracy": {
        "accuracy": 0.7452189524627273
      },
      "eval_loss": 1.2492551803588867,
      "eval_runtime": 2.8423,
      "eval_samples_per_second": 4507.201,
      "eval_steps_per_second": 70.716,
      "step": 228780
    },
    {
      "epoch": 369.03,
      "learning_rate": 0.0631116497916129,
      "loss": 0.8365,
      "step": 228800
    },
    {
      "epoch": 369.06,
      "learning_rate": 0.0631084239883871,
      "loss": 0.8299,
      "step": 228820
    },
    {
      "epoch": 369.1,
      "learning_rate": 0.06310519818516129,
      "loss": 0.8218,
      "step": 228840
    },
    {
      "epoch": 369.13,
      "learning_rate": 0.06310197238193549,
      "loss": 0.7958,
      "step": 228860
    },
    {
      "epoch": 369.16,
      "learning_rate": 0.06309874657870967,
      "loss": 0.8063,
      "step": 228880
    },
    {
      "epoch": 369.19,
      "learning_rate": 0.06309552077548389,
      "loss": 0.7797,
      "step": 228900
    },
    {
      "epoch": 369.23,
      "learning_rate": 0.06309229497225807,
      "loss": 0.8159,
      "step": 228920
    },
    {
      "epoch": 369.26,
      "learning_rate": 0.06308906916903226,
      "loss": 0.7915,
      "step": 228940
    },
    {
      "epoch": 369.29,
      "learning_rate": 0.06308584336580646,
      "loss": 0.8396,
      "step": 228960
    },
    {
      "epoch": 369.32,
      "learning_rate": 0.06308261756258066,
      "loss": 0.8325,
      "step": 228980
    },
    {
      "epoch": 369.35,
      "learning_rate": 0.06307939175935484,
      "loss": 0.8027,
      "step": 229000
    },
    {
      "epoch": 369.39,
      "learning_rate": 0.06307616595612904,
      "loss": 0.8128,
      "step": 229020
    },
    {
      "epoch": 369.42,
      "learning_rate": 0.06307294015290323,
      "loss": 0.8205,
      "step": 229040
    },
    {
      "epoch": 369.45,
      "learning_rate": 0.06306971434967741,
      "loss": 0.822,
      "step": 229060
    },
    {
      "epoch": 369.48,
      "learning_rate": 0.06306648854645162,
      "loss": 0.8085,
      "step": 229080
    },
    {
      "epoch": 369.52,
      "learning_rate": 0.06306326274322581,
      "loss": 0.8029,
      "step": 229100
    },
    {
      "epoch": 369.55,
      "learning_rate": 0.06306003694000001,
      "loss": 0.7819,
      "step": 229120
    },
    {
      "epoch": 369.58,
      "learning_rate": 0.0630568111367742,
      "loss": 0.8007,
      "step": 229140
    },
    {
      "epoch": 369.61,
      "learning_rate": 0.06305358533354839,
      "loss": 0.7997,
      "step": 229160
    },
    {
      "epoch": 369.65,
      "learning_rate": 0.06305035953032258,
      "loss": 0.8033,
      "step": 229180
    },
    {
      "epoch": 369.68,
      "learning_rate": 0.06304713372709679,
      "loss": 0.8198,
      "step": 229200
    },
    {
      "epoch": 369.71,
      "learning_rate": 0.06304390792387098,
      "loss": 0.8336,
      "step": 229220
    },
    {
      "epoch": 369.74,
      "learning_rate": 0.06304068212064516,
      "loss": 0.7969,
      "step": 229240
    },
    {
      "epoch": 369.77,
      "learning_rate": 0.06303745631741936,
      "loss": 0.813,
      "step": 229260
    },
    {
      "epoch": 369.81,
      "learning_rate": 0.06303423051419356,
      "loss": 0.8073,
      "step": 229280
    },
    {
      "epoch": 369.84,
      "learning_rate": 0.06303100471096774,
      "loss": 0.7932,
      "step": 229300
    },
    {
      "epoch": 369.87,
      "learning_rate": 0.06302777890774194,
      "loss": 0.8021,
      "step": 229320
    },
    {
      "epoch": 369.9,
      "learning_rate": 0.06302455310451613,
      "loss": 0.8288,
      "step": 229340
    },
    {
      "epoch": 369.94,
      "learning_rate": 0.06302132730129033,
      "loss": 0.819,
      "step": 229360
    },
    {
      "epoch": 369.97,
      "learning_rate": 0.06301810149806453,
      "loss": 0.8169,
      "step": 229380
    },
    {
      "epoch": 370.0,
      "learning_rate": 0.06301487569483871,
      "loss": 0.8245,
      "step": 229400
    },
    {
      "epoch": 370.0,
      "eval_accuracy": {
        "accuracy": 0.7514635859807978
      },
      "eval_loss": 1.1810513734817505,
      "eval_runtime": 2.8528,
      "eval_samples_per_second": 4490.694,
      "eval_steps_per_second": 70.457,
      "step": 229400
    },
    {
      "epoch": 370.03,
      "learning_rate": 0.06301164989161291,
      "loss": 0.8449,
      "step": 229420
    },
    {
      "epoch": 370.06,
      "learning_rate": 0.0630084240883871,
      "loss": 0.777,
      "step": 229440
    },
    {
      "epoch": 370.1,
      "learning_rate": 0.0630051982851613,
      "loss": 0.7841,
      "step": 229460
    },
    {
      "epoch": 370.13,
      "learning_rate": 0.06300197248193548,
      "loss": 0.8036,
      "step": 229480
    },
    {
      "epoch": 370.16,
      "learning_rate": 0.0629987466787097,
      "loss": 0.8094,
      "step": 229500
    },
    {
      "epoch": 370.19,
      "learning_rate": 0.06299552087548388,
      "loss": 0.8076,
      "step": 229520
    },
    {
      "epoch": 370.23,
      "learning_rate": 0.06299229507225806,
      "loss": 0.8036,
      "step": 229540
    },
    {
      "epoch": 370.26,
      "learning_rate": 0.06298906926903226,
      "loss": 0.8378,
      "step": 229560
    },
    {
      "epoch": 370.29,
      "learning_rate": 0.06298584346580645,
      "loss": 0.8279,
      "step": 229580
    },
    {
      "epoch": 370.32,
      "learning_rate": 0.06298261766258065,
      "loss": 0.7818,
      "step": 229600
    },
    {
      "epoch": 370.35,
      "learning_rate": 0.06297939185935485,
      "loss": 0.8052,
      "step": 229620
    },
    {
      "epoch": 370.39,
      "learning_rate": 0.06297616605612903,
      "loss": 0.8069,
      "step": 229640
    },
    {
      "epoch": 370.42,
      "learning_rate": 0.06297294025290323,
      "loss": 0.8087,
      "step": 229660
    },
    {
      "epoch": 370.45,
      "learning_rate": 0.06296971444967743,
      "loss": 0.7765,
      "step": 229680
    },
    {
      "epoch": 370.48,
      "learning_rate": 0.06296648864645162,
      "loss": 0.8124,
      "step": 229700
    },
    {
      "epoch": 370.52,
      "learning_rate": 0.06296326284322581,
      "loss": 0.8165,
      "step": 229720
    },
    {
      "epoch": 370.55,
      "learning_rate": 0.06296003704,
      "loss": 0.8097,
      "step": 229740
    },
    {
      "epoch": 370.58,
      "learning_rate": 0.0629568112367742,
      "loss": 0.823,
      "step": 229760
    },
    {
      "epoch": 370.61,
      "learning_rate": 0.06295358543354838,
      "loss": 0.8214,
      "step": 229780
    },
    {
      "epoch": 370.65,
      "learning_rate": 0.0629503596303226,
      "loss": 0.8001,
      "step": 229800
    },
    {
      "epoch": 370.68,
      "learning_rate": 0.06294713382709678,
      "loss": 0.8012,
      "step": 229820
    },
    {
      "epoch": 370.71,
      "learning_rate": 0.06294390802387097,
      "loss": 0.7909,
      "step": 229840
    },
    {
      "epoch": 370.74,
      "learning_rate": 0.06294068222064517,
      "loss": 0.8081,
      "step": 229860
    },
    {
      "epoch": 370.77,
      "learning_rate": 0.06293745641741935,
      "loss": 0.801,
      "step": 229880
    },
    {
      "epoch": 370.81,
      "learning_rate": 0.06293423061419355,
      "loss": 0.8235,
      "step": 229900
    },
    {
      "epoch": 370.84,
      "learning_rate": 0.06293100481096775,
      "loss": 0.8199,
      "step": 229920
    },
    {
      "epoch": 370.87,
      "learning_rate": 0.06292777900774194,
      "loss": 0.8246,
      "step": 229940
    },
    {
      "epoch": 370.9,
      "learning_rate": 0.06292455320451613,
      "loss": 0.8305,
      "step": 229960
    },
    {
      "epoch": 370.94,
      "learning_rate": 0.06292132740129033,
      "loss": 0.827,
      "step": 229980
    },
    {
      "epoch": 370.97,
      "learning_rate": 0.06291810159806452,
      "loss": 0.82,
      "step": 230000
    },
    {
      "epoch": 371.0,
      "learning_rate": 0.06291487579483872,
      "loss": 0.8129,
      "step": 230020
    },
    {
      "epoch": 371.0,
      "eval_accuracy": {
        "accuracy": 0.7456092420576067
      },
      "eval_loss": 1.2163219451904297,
      "eval_runtime": 2.8027,
      "eval_samples_per_second": 4570.904,
      "eval_steps_per_second": 71.716,
      "step": 230020
    },
    {
      "epoch": 371.03,
      "learning_rate": 0.0629116499916129,
      "loss": 0.8159,
      "step": 230040
    },
    {
      "epoch": 371.06,
      "learning_rate": 0.0629084241883871,
      "loss": 0.81,
      "step": 230060
    },
    {
      "epoch": 371.1,
      "learning_rate": 0.06290519838516129,
      "loss": 0.7704,
      "step": 230080
    },
    {
      "epoch": 371.13,
      "learning_rate": 0.0629019725819355,
      "loss": 0.7902,
      "step": 230100
    },
    {
      "epoch": 371.16,
      "learning_rate": 0.06289874677870967,
      "loss": 0.8115,
      "step": 230120
    },
    {
      "epoch": 371.19,
      "learning_rate": 0.06289552097548388,
      "loss": 0.8165,
      "step": 230140
    },
    {
      "epoch": 371.23,
      "learning_rate": 0.06289229517225807,
      "loss": 0.8184,
      "step": 230160
    },
    {
      "epoch": 371.26,
      "learning_rate": 0.06288906936903225,
      "loss": 0.8077,
      "step": 230180
    },
    {
      "epoch": 371.29,
      "learning_rate": 0.06288584356580645,
      "loss": 0.812,
      "step": 230200
    },
    {
      "epoch": 371.32,
      "learning_rate": 0.06288261776258065,
      "loss": 0.7892,
      "step": 230220
    },
    {
      "epoch": 371.35,
      "learning_rate": 0.06287939195935484,
      "loss": 0.8072,
      "step": 230240
    },
    {
      "epoch": 371.39,
      "learning_rate": 0.06287616615612904,
      "loss": 0.807,
      "step": 230260
    },
    {
      "epoch": 371.42,
      "learning_rate": 0.06287294035290324,
      "loss": 0.7914,
      "step": 230280
    },
    {
      "epoch": 371.45,
      "learning_rate": 0.06286971454967742,
      "loss": 0.8287,
      "step": 230300
    },
    {
      "epoch": 371.48,
      "learning_rate": 0.06286648874645162,
      "loss": 0.8104,
      "step": 230320
    },
    {
      "epoch": 371.52,
      "learning_rate": 0.0628632629432258,
      "loss": 0.8218,
      "step": 230340
    },
    {
      "epoch": 371.55,
      "learning_rate": 0.06286003714,
      "loss": 0.8262,
      "step": 230360
    },
    {
      "epoch": 371.58,
      "learning_rate": 0.06285681133677419,
      "loss": 0.8133,
      "step": 230380
    },
    {
      "epoch": 371.61,
      "learning_rate": 0.0628535855335484,
      "loss": 0.8147,
      "step": 230400
    },
    {
      "epoch": 371.65,
      "learning_rate": 0.06285035973032257,
      "loss": 0.8018,
      "step": 230420
    },
    {
      "epoch": 371.68,
      "learning_rate": 0.06284713392709679,
      "loss": 0.7973,
      "step": 230440
    },
    {
      "epoch": 371.71,
      "learning_rate": 0.06284390812387097,
      "loss": 0.8176,
      "step": 230460
    },
    {
      "epoch": 371.74,
      "learning_rate": 0.06284068232064516,
      "loss": 0.8188,
      "step": 230480
    },
    {
      "epoch": 371.77,
      "learning_rate": 0.06283745651741936,
      "loss": 0.7947,
      "step": 230500
    },
    {
      "epoch": 371.81,
      "learning_rate": 0.06283423071419356,
      "loss": 0.8142,
      "step": 230520
    },
    {
      "epoch": 371.84,
      "learning_rate": 0.06283100491096774,
      "loss": 0.7948,
      "step": 230540
    },
    {
      "epoch": 371.87,
      "learning_rate": 0.06282777910774194,
      "loss": 0.8435,
      "step": 230560
    },
    {
      "epoch": 371.9,
      "learning_rate": 0.06282455330451614,
      "loss": 0.8049,
      "step": 230580
    },
    {
      "epoch": 371.94,
      "learning_rate": 0.06282132750129032,
      "loss": 0.7674,
      "step": 230600
    },
    {
      "epoch": 371.97,
      "learning_rate": 0.06281810169806452,
      "loss": 0.8038,
      "step": 230620
    },
    {
      "epoch": 372.0,
      "learning_rate": 0.062815037185,
      "loss": 0.8509,
      "step": 230640
    },
    {
      "epoch": 372.0,
      "eval_accuracy": {
        "accuracy": 0.7542736710639294
      },
      "eval_loss": 1.182504653930664,
      "eval_runtime": 2.8212,
      "eval_samples_per_second": 4541.036,
      "eval_steps_per_second": 71.247,
      "step": 230640
    },
    {
      "epoch": 372.03,
      "learning_rate": 0.06281181138177419,
      "loss": 0.8154,
      "step": 230660
    },
    {
      "epoch": 372.06,
      "learning_rate": 0.06280858557854839,
      "loss": 0.8058,
      "step": 230680
    },
    {
      "epoch": 372.1,
      "learning_rate": 0.06280535977532259,
      "loss": 0.7947,
      "step": 230700
    },
    {
      "epoch": 372.13,
      "learning_rate": 0.06280213397209677,
      "loss": 0.7964,
      "step": 230720
    },
    {
      "epoch": 372.16,
      "learning_rate": 0.06279890816887097,
      "loss": 0.8068,
      "step": 230740
    },
    {
      "epoch": 372.19,
      "learning_rate": 0.06279568236564517,
      "loss": 0.8026,
      "step": 230760
    },
    {
      "epoch": 372.23,
      "learning_rate": 0.06279245656241936,
      "loss": 0.8152,
      "step": 230780
    },
    {
      "epoch": 372.26,
      "learning_rate": 0.06278923075919356,
      "loss": 0.8115,
      "step": 230800
    },
    {
      "epoch": 372.29,
      "learning_rate": 0.06278600495596774,
      "loss": 0.8249,
      "step": 230820
    },
    {
      "epoch": 372.32,
      "learning_rate": 0.06278277915274194,
      "loss": 0.8137,
      "step": 230840
    },
    {
      "epoch": 372.35,
      "learning_rate": 0.06277955334951613,
      "loss": 0.8152,
      "step": 230860
    },
    {
      "epoch": 372.39,
      "learning_rate": 0.06277632754629034,
      "loss": 0.8112,
      "step": 230880
    },
    {
      "epoch": 372.42,
      "learning_rate": 0.06277310174306452,
      "loss": 0.8045,
      "step": 230900
    },
    {
      "epoch": 372.45,
      "learning_rate": 0.06276987593983871,
      "loss": 0.8029,
      "step": 230920
    },
    {
      "epoch": 372.48,
      "learning_rate": 0.06276665013661291,
      "loss": 0.8146,
      "step": 230940
    },
    {
      "epoch": 372.52,
      "learning_rate": 0.0627634243333871,
      "loss": 0.822,
      "step": 230960
    },
    {
      "epoch": 372.55,
      "learning_rate": 0.06276019853016129,
      "loss": 0.804,
      "step": 230980
    },
    {
      "epoch": 372.58,
      "learning_rate": 0.06275697272693549,
      "loss": 0.8152,
      "step": 231000
    },
    {
      "epoch": 372.61,
      "learning_rate": 0.06275374692370968,
      "loss": 0.8223,
      "step": 231020
    },
    {
      "epoch": 372.65,
      "learning_rate": 0.06275052112048388,
      "loss": 0.8292,
      "step": 231040
    },
    {
      "epoch": 372.68,
      "learning_rate": 0.06274729531725808,
      "loss": 0.8318,
      "step": 231060
    },
    {
      "epoch": 372.71,
      "learning_rate": 0.06274406951403226,
      "loss": 0.7997,
      "step": 231080
    },
    {
      "epoch": 372.74,
      "learning_rate": 0.06274084371080646,
      "loss": 0.7856,
      "step": 231100
    },
    {
      "epoch": 372.77,
      "learning_rate": 0.06273761790758065,
      "loss": 0.8236,
      "step": 231120
    },
    {
      "epoch": 372.81,
      "learning_rate": 0.06273439210435484,
      "loss": 0.8203,
      "step": 231140
    },
    {
      "epoch": 372.84,
      "learning_rate": 0.06273116630112903,
      "loss": 0.8009,
      "step": 231160
    },
    {
      "epoch": 372.87,
      "learning_rate": 0.06272794049790324,
      "loss": 0.7958,
      "step": 231180
    },
    {
      "epoch": 372.9,
      "learning_rate": 0.06272471469467741,
      "loss": 0.8329,
      "step": 231200
    },
    {
      "epoch": 372.94,
      "learning_rate": 0.06272148889145163,
      "loss": 0.8399,
      "step": 231220
    },
    {
      "epoch": 372.97,
      "learning_rate": 0.06271826308822581,
      "loss": 0.8332,
      "step": 231240
    },
    {
      "epoch": 373.0,
      "learning_rate": 0.062715037285,
      "loss": 0.8306,
      "step": 231260
    },
    {
      "epoch": 373.0,
      "eval_accuracy": {
        "accuracy": 0.744828662867848
      },
      "eval_loss": 1.229312777519226,
      "eval_runtime": 2.8194,
      "eval_samples_per_second": 4543.835,
      "eval_steps_per_second": 71.291,
      "step": 231260
    },
    {
      "epoch": 373.03,
      "learning_rate": 0.0627118114817742,
      "loss": 0.8322,
      "step": 231280
    },
    {
      "epoch": 373.06,
      "learning_rate": 0.0627085856785484,
      "loss": 0.8094,
      "step": 231300
    },
    {
      "epoch": 373.1,
      "learning_rate": 0.06270535987532258,
      "loss": 0.8193,
      "step": 231320
    },
    {
      "epoch": 373.13,
      "learning_rate": 0.06270213407209678,
      "loss": 0.8295,
      "step": 231340
    },
    {
      "epoch": 373.16,
      "learning_rate": 0.06269890826887098,
      "loss": 0.7991,
      "step": 231360
    },
    {
      "epoch": 373.19,
      "learning_rate": 0.06269568246564516,
      "loss": 0.7949,
      "step": 231380
    },
    {
      "epoch": 373.23,
      "learning_rate": 0.06269245666241936,
      "loss": 0.7933,
      "step": 231400
    },
    {
      "epoch": 373.26,
      "learning_rate": 0.06268923085919355,
      "loss": 0.7947,
      "step": 231420
    },
    {
      "epoch": 373.29,
      "learning_rate": 0.06268600505596775,
      "loss": 0.8099,
      "step": 231440
    },
    {
      "epoch": 373.32,
      "learning_rate": 0.06268277925274193,
      "loss": 0.8133,
      "step": 231460
    },
    {
      "epoch": 373.35,
      "learning_rate": 0.06267955344951615,
      "loss": 0.8077,
      "step": 231480
    },
    {
      "epoch": 373.39,
      "learning_rate": 0.06267632764629032,
      "loss": 0.8065,
      "step": 231500
    },
    {
      "epoch": 373.42,
      "learning_rate": 0.06267310184306453,
      "loss": 0.8414,
      "step": 231520
    },
    {
      "epoch": 373.45,
      "learning_rate": 0.06266987603983872,
      "loss": 0.778,
      "step": 231540
    },
    {
      "epoch": 373.48,
      "learning_rate": 0.0626666502366129,
      "loss": 0.788,
      "step": 231560
    },
    {
      "epoch": 373.52,
      "learning_rate": 0.0626634244333871,
      "loss": 0.7962,
      "step": 231580
    },
    {
      "epoch": 373.55,
      "learning_rate": 0.0626601986301613,
      "loss": 0.7799,
      "step": 231600
    },
    {
      "epoch": 373.58,
      "learning_rate": 0.06265697282693548,
      "loss": 0.8054,
      "step": 231620
    },
    {
      "epoch": 373.61,
      "learning_rate": 0.06265374702370968,
      "loss": 0.7969,
      "step": 231640
    },
    {
      "epoch": 373.65,
      "learning_rate": 0.06265052122048388,
      "loss": 0.7914,
      "step": 231660
    },
    {
      "epoch": 373.68,
      "learning_rate": 0.06264729541725807,
      "loss": 0.819,
      "step": 231680
    },
    {
      "epoch": 373.71,
      "learning_rate": 0.06264406961403227,
      "loss": 0.8014,
      "step": 231700
    },
    {
      "epoch": 373.74,
      "learning_rate": 0.06264084381080645,
      "loss": 0.8256,
      "step": 231720
    },
    {
      "epoch": 373.77,
      "learning_rate": 0.06263761800758065,
      "loss": 0.8251,
      "step": 231740
    },
    {
      "epoch": 373.81,
      "learning_rate": 0.06263439220435484,
      "loss": 0.8297,
      "step": 231760
    },
    {
      "epoch": 373.84,
      "learning_rate": 0.06263116640112905,
      "loss": 0.8346,
      "step": 231780
    },
    {
      "epoch": 373.87,
      "learning_rate": 0.06262794059790322,
      "loss": 0.8107,
      "step": 231800
    },
    {
      "epoch": 373.9,
      "learning_rate": 0.06262471479467743,
      "loss": 0.8218,
      "step": 231820
    },
    {
      "epoch": 373.94,
      "learning_rate": 0.06262148899145162,
      "loss": 0.827,
      "step": 231840
    },
    {
      "epoch": 373.97,
      "learning_rate": 0.0626182631882258,
      "loss": 0.8416,
      "step": 231860
    },
    {
      "epoch": 374.0,
      "learning_rate": 0.062615037385,
      "loss": 0.8188,
      "step": 231880
    },
    {
      "epoch": 374.0,
      "eval_accuracy": {
        "accuracy": 0.7484973850597143
      },
      "eval_loss": 1.2033737897872925,
      "eval_runtime": 2.7007,
      "eval_samples_per_second": 4743.609,
      "eval_steps_per_second": 74.426,
      "step": 231880
    },
    {
      "epoch": 374.03,
      "learning_rate": 0.0626118115817742,
      "loss": 0.8317,
      "step": 231900
    },
    {
      "epoch": 374.06,
      "learning_rate": 0.06260858577854839,
      "loss": 0.7974,
      "step": 231920
    },
    {
      "epoch": 374.1,
      "learning_rate": 0.06260535997532259,
      "loss": 0.7895,
      "step": 231940
    },
    {
      "epoch": 374.13,
      "learning_rate": 0.06260213417209678,
      "loss": 0.7789,
      "step": 231960
    },
    {
      "epoch": 374.16,
      "learning_rate": 0.06259890836887097,
      "loss": 0.7946,
      "step": 231980
    },
    {
      "epoch": 374.19,
      "learning_rate": 0.06259568256564517,
      "loss": 0.7878,
      "step": 232000
    },
    {
      "epoch": 374.23,
      "learning_rate": 0.06259245676241935,
      "loss": 0.8187,
      "step": 232020
    },
    {
      "epoch": 374.26,
      "learning_rate": 0.06258923095919355,
      "loss": 0.8175,
      "step": 232040
    },
    {
      "epoch": 374.29,
      "learning_rate": 0.06258600515596774,
      "loss": 0.8385,
      "step": 232060
    },
    {
      "epoch": 374.32,
      "learning_rate": 0.06258277935274195,
      "loss": 0.828,
      "step": 232080
    },
    {
      "epoch": 374.35,
      "learning_rate": 0.06257955354951612,
      "loss": 0.8195,
      "step": 232100
    },
    {
      "epoch": 374.39,
      "learning_rate": 0.06257632774629034,
      "loss": 0.815,
      "step": 232120
    },
    {
      "epoch": 374.42,
      "learning_rate": 0.06257310194306452,
      "loss": 0.8258,
      "step": 232140
    },
    {
      "epoch": 374.45,
      "learning_rate": 0.0625698761398387,
      "loss": 0.8228,
      "step": 232160
    },
    {
      "epoch": 374.48,
      "learning_rate": 0.0625666503366129,
      "loss": 0.8273,
      "step": 232180
    },
    {
      "epoch": 374.52,
      "learning_rate": 0.0625634245333871,
      "loss": 0.8218,
      "step": 232200
    },
    {
      "epoch": 374.55,
      "learning_rate": 0.06256019873016129,
      "loss": 0.8246,
      "step": 232220
    },
    {
      "epoch": 374.58,
      "learning_rate": 0.06255697292693549,
      "loss": 0.8374,
      "step": 232240
    },
    {
      "epoch": 374.61,
      "learning_rate": 0.06255374712370969,
      "loss": 0.8157,
      "step": 232260
    },
    {
      "epoch": 374.65,
      "learning_rate": 0.06255052132048387,
      "loss": 0.8114,
      "step": 232280
    },
    {
      "epoch": 374.68,
      "learning_rate": 0.06254729551725807,
      "loss": 0.8073,
      "step": 232300
    },
    {
      "epoch": 374.71,
      "learning_rate": 0.06254406971403226,
      "loss": 0.835,
      "step": 232320
    },
    {
      "epoch": 374.74,
      "learning_rate": 0.06254084391080646,
      "loss": 0.803,
      "step": 232340
    },
    {
      "epoch": 374.77,
      "learning_rate": 0.06253761810758064,
      "loss": 0.7876,
      "step": 232360
    },
    {
      "epoch": 374.81,
      "learning_rate": 0.06253439230435485,
      "loss": 0.8167,
      "step": 232380
    },
    {
      "epoch": 374.84,
      "learning_rate": 0.06253116650112903,
      "loss": 0.8439,
      "step": 232400
    },
    {
      "epoch": 374.87,
      "learning_rate": 0.06252794069790324,
      "loss": 0.8407,
      "step": 232420
    },
    {
      "epoch": 374.9,
      "learning_rate": 0.06252471489467742,
      "loss": 0.8313,
      "step": 232440
    },
    {
      "epoch": 374.94,
      "learning_rate": 0.06252148909145162,
      "loss": 0.8247,
      "step": 232460
    },
    {
      "epoch": 374.97,
      "learning_rate": 0.06251826328822581,
      "loss": 0.8093,
      "step": 232480
    },
    {
      "epoch": 375.0,
      "learning_rate": 0.06251503748500001,
      "loss": 0.8486,
      "step": 232500
    },
    {
      "epoch": 375.0,
      "eval_accuracy": {
        "accuracy": 0.7464678791663414
      },
      "eval_loss": 1.2067307233810425,
      "eval_runtime": 2.8377,
      "eval_samples_per_second": 4514.55,
      "eval_steps_per_second": 70.832,
      "step": 232500
    },
    {
      "epoch": 375.03,
      "learning_rate": 0.0625118116817742,
      "loss": 0.8613,
      "step": 232520
    },
    {
      "epoch": 375.06,
      "learning_rate": 0.06250858587854839,
      "loss": 0.7979,
      "step": 232540
    },
    {
      "epoch": 375.1,
      "learning_rate": 0.06250536007532259,
      "loss": 0.801,
      "step": 232560
    },
    {
      "epoch": 375.13,
      "learning_rate": 0.06250213427209678,
      "loss": 0.8119,
      "step": 232580
    },
    {
      "epoch": 375.16,
      "learning_rate": 0.062498908468870976,
      "loss": 0.799,
      "step": 232600
    },
    {
      "epoch": 375.19,
      "learning_rate": 0.062495682665645175,
      "loss": 0.7877,
      "step": 232620
    },
    {
      "epoch": 375.23,
      "learning_rate": 0.06249245686241936,
      "loss": 0.7987,
      "step": 232640
    },
    {
      "epoch": 375.26,
      "learning_rate": 0.062489231059193545,
      "loss": 0.8205,
      "step": 232660
    },
    {
      "epoch": 375.29,
      "learning_rate": 0.06248600525596775,
      "loss": 0.7998,
      "step": 232680
    },
    {
      "epoch": 375.32,
      "learning_rate": 0.062482779452741936,
      "loss": 0.7968,
      "step": 232700
    },
    {
      "epoch": 375.35,
      "learning_rate": 0.06247955364951614,
      "loss": 0.7775,
      "step": 232720
    },
    {
      "epoch": 375.39,
      "learning_rate": 0.062476327846290314,
      "loss": 0.7955,
      "step": 232740
    },
    {
      "epoch": 375.42,
      "learning_rate": 0.06247310204306453,
      "loss": 0.8055,
      "step": 232760
    },
    {
      "epoch": 375.45,
      "learning_rate": 0.06246987623983871,
      "loss": 0.8137,
      "step": 232780
    },
    {
      "epoch": 375.48,
      "learning_rate": 0.062466650436612904,
      "loss": 0.7829,
      "step": 232800
    },
    {
      "epoch": 375.52,
      "learning_rate": 0.0624634246333871,
      "loss": 0.8226,
      "step": 232820
    },
    {
      "epoch": 375.55,
      "learning_rate": 0.062460198830161295,
      "loss": 0.8333,
      "step": 232840
    },
    {
      "epoch": 375.58,
      "learning_rate": 0.06245697302693548,
      "loss": 0.8073,
      "step": 232860
    },
    {
      "epoch": 375.61,
      "learning_rate": 0.06245374722370968,
      "loss": 0.7944,
      "step": 232880
    },
    {
      "epoch": 375.65,
      "learning_rate": 0.06245052142048388,
      "loss": 0.8066,
      "step": 232900
    },
    {
      "epoch": 375.68,
      "learning_rate": 0.06244729561725807,
      "loss": 0.8031,
      "step": 232920
    },
    {
      "epoch": 375.71,
      "learning_rate": 0.062444069814032256,
      "loss": 0.8202,
      "step": 232940
    },
    {
      "epoch": 375.74,
      "learning_rate": 0.06244084401080644,
      "loss": 0.8208,
      "step": 232960
    },
    {
      "epoch": 375.77,
      "learning_rate": 0.06243761820758065,
      "loss": 0.8086,
      "step": 232980
    },
    {
      "epoch": 375.81,
      "learning_rate": 0.06243439240435483,
      "loss": 0.8353,
      "step": 233000
    },
    {
      "epoch": 375.84,
      "learning_rate": 0.062431166601129046,
      "loss": 0.7993,
      "step": 233020
    },
    {
      "epoch": 375.87,
      "learning_rate": 0.06242794079790323,
      "loss": 0.8179,
      "step": 233040
    },
    {
      "epoch": 375.9,
      "learning_rate": 0.06242471499467742,
      "loss": 0.8295,
      "step": 233060
    },
    {
      "epoch": 375.94,
      "learning_rate": 0.06242148919145161,
      "loss": 0.8029,
      "step": 233080
    },
    {
      "epoch": 375.97,
      "learning_rate": 0.06241826338822581,
      "loss": 0.8011,
      "step": 233100
    },
    {
      "epoch": 376.0,
      "learning_rate": 0.06241519887516131,
      "loss": 0.7914,
      "step": 233120
    },
    {
      "epoch": 376.0,
      "eval_accuracy": {
        "accuracy": 0.7536492077121224
      },
      "eval_loss": 1.1776736974716187,
      "eval_runtime": 3.1075,
      "eval_samples_per_second": 4122.584,
      "eval_steps_per_second": 64.682,
      "step": 233120
    },
    {
      "epoch": 376.03,
      "learning_rate": 0.06241197307193548,
      "loss": 0.8106,
      "step": 233140
    },
    {
      "epoch": 376.06,
      "learning_rate": 0.06240874726870969,
      "loss": 0.7973,
      "step": 233160
    },
    {
      "epoch": 376.1,
      "learning_rate": 0.06240552146548387,
      "loss": 0.7864,
      "step": 233180
    },
    {
      "epoch": 376.13,
      "learning_rate": 0.06240229566225808,
      "loss": 0.7939,
      "step": 233200
    },
    {
      "epoch": 376.16,
      "learning_rate": 0.062399069859032257,
      "loss": 0.7952,
      "step": 233220
    },
    {
      "epoch": 376.19,
      "learning_rate": 0.06239584405580645,
      "loss": 0.79,
      "step": 233240
    },
    {
      "epoch": 376.23,
      "learning_rate": 0.06239261825258065,
      "loss": 0.801,
      "step": 233260
    },
    {
      "epoch": 376.26,
      "learning_rate": 0.06238939244935485,
      "loss": 0.7971,
      "step": 233280
    },
    {
      "epoch": 376.29,
      "learning_rate": 0.06238616664612904,
      "loss": 0.8093,
      "step": 233300
    },
    {
      "epoch": 376.32,
      "learning_rate": 0.062382940842903224,
      "loss": 0.793,
      "step": 233320
    },
    {
      "epoch": 376.35,
      "learning_rate": 0.06237971503967742,
      "loss": 0.8058,
      "step": 233340
    },
    {
      "epoch": 376.39,
      "learning_rate": 0.062376489236451615,
      "loss": 0.8148,
      "step": 233360
    },
    {
      "epoch": 376.42,
      "learning_rate": 0.062373263433225815,
      "loss": 0.8025,
      "step": 233380
    },
    {
      "epoch": 376.45,
      "learning_rate": 0.06237003763,
      "loss": 0.7856,
      "step": 233400
    },
    {
      "epoch": 376.48,
      "learning_rate": 0.0623668118267742,
      "loss": 0.811,
      "step": 233420
    },
    {
      "epoch": 376.52,
      "learning_rate": 0.062363586023548384,
      "loss": 0.7913,
      "step": 233440
    },
    {
      "epoch": 376.55,
      "learning_rate": 0.06236036022032259,
      "loss": 0.7912,
      "step": 233460
    },
    {
      "epoch": 376.58,
      "learning_rate": 0.062357134417096775,
      "loss": 0.8062,
      "step": 233480
    },
    {
      "epoch": 376.61,
      "learning_rate": 0.06235390861387098,
      "loss": 0.7946,
      "step": 233500
    },
    {
      "epoch": 376.65,
      "learning_rate": 0.06235068281064515,
      "loss": 0.8098,
      "step": 233520
    },
    {
      "epoch": 376.68,
      "learning_rate": 0.062347457007419366,
      "loss": 0.8065,
      "step": 233540
    },
    {
      "epoch": 376.71,
      "learning_rate": 0.06234423120419355,
      "loss": 0.822,
      "step": 233560
    },
    {
      "epoch": 376.74,
      "learning_rate": 0.06234100540096774,
      "loss": 0.8065,
      "step": 233580
    },
    {
      "epoch": 376.77,
      "learning_rate": 0.06233777959774194,
      "loss": 0.8102,
      "step": 233600
    },
    {
      "epoch": 376.81,
      "learning_rate": 0.062334553794516134,
      "loss": 0.8007,
      "step": 233620
    },
    {
      "epoch": 376.84,
      "learning_rate": 0.06233132799129032,
      "loss": 0.8005,
      "step": 233640
    },
    {
      "epoch": 376.87,
      "learning_rate": 0.06232810218806452,
      "loss": 0.7961,
      "step": 233660
    },
    {
      "epoch": 376.9,
      "learning_rate": 0.06232487638483872,
      "loss": 0.8145,
      "step": 233680
    },
    {
      "epoch": 376.94,
      "learning_rate": 0.0623216505816129,
      "loss": 0.8141,
      "step": 233700
    },
    {
      "epoch": 376.97,
      "learning_rate": 0.062318424778387095,
      "loss": 0.8042,
      "step": 233720
    },
    {
      "epoch": 377.0,
      "learning_rate": 0.06231519897516128,
      "loss": 0.8283,
      "step": 233740
    },
    {
      "epoch": 377.0,
      "eval_accuracy": {
        "accuracy": 0.748653500897666
      },
      "eval_loss": 1.2003412246704102,
      "eval_runtime": 2.7911,
      "eval_samples_per_second": 4589.99,
      "eval_steps_per_second": 72.015,
      "step": 233740
    },
    {
      "epoch": 377.03,
      "learning_rate": 0.062311973171935486,
      "loss": 0.8263,
      "step": 233760
    },
    {
      "epoch": 377.06,
      "learning_rate": 0.06230874736870967,
      "loss": 0.8017,
      "step": 233780
    },
    {
      "epoch": 377.1,
      "learning_rate": 0.062305521565483885,
      "loss": 0.7982,
      "step": 233800
    },
    {
      "epoch": 377.13,
      "learning_rate": 0.06230229576225807,
      "loss": 0.7907,
      "step": 233820
    },
    {
      "epoch": 377.16,
      "learning_rate": 0.06229906995903226,
      "loss": 0.8131,
      "step": 233840
    },
    {
      "epoch": 377.19,
      "learning_rate": 0.06229584415580645,
      "loss": 0.8213,
      "step": 233860
    },
    {
      "epoch": 377.23,
      "learning_rate": 0.062292618352580646,
      "loss": 0.7809,
      "step": 233880
    },
    {
      "epoch": 377.26,
      "learning_rate": 0.06228939254935484,
      "loss": 0.7668,
      "step": 233900
    },
    {
      "epoch": 377.29,
      "learning_rate": 0.06228616674612904,
      "loss": 0.8083,
      "step": 233920
    },
    {
      "epoch": 377.32,
      "learning_rate": 0.06228294094290324,
      "loss": 0.8317,
      "step": 233940
    },
    {
      "epoch": 377.35,
      "learning_rate": 0.06227971513967742,
      "loss": 0.8148,
      "step": 233960
    },
    {
      "epoch": 377.39,
      "learning_rate": 0.062276489336451614,
      "loss": 0.7865,
      "step": 233980
    },
    {
      "epoch": 377.42,
      "learning_rate": 0.06227326353322581,
      "loss": 0.799,
      "step": 234000
    },
    {
      "epoch": 377.45,
      "learning_rate": 0.062270037730000005,
      "loss": 0.8116,
      "step": 234020
    },
    {
      "epoch": 377.48,
      "learning_rate": 0.06226681192677419,
      "loss": 0.8129,
      "step": 234040
    },
    {
      "epoch": 377.52,
      "learning_rate": 0.0622635861235484,
      "loss": 0.8101,
      "step": 234060
    },
    {
      "epoch": 377.55,
      "learning_rate": 0.06226036032032259,
      "loss": 0.8097,
      "step": 234080
    },
    {
      "epoch": 377.58,
      "learning_rate": 0.06225713451709678,
      "loss": 0.8207,
      "step": 234100
    },
    {
      "epoch": 377.61,
      "learning_rate": 0.062253908713870966,
      "loss": 0.8195,
      "step": 234120
    },
    {
      "epoch": 377.65,
      "learning_rate": 0.06225068291064517,
      "loss": 0.8072,
      "step": 234140
    },
    {
      "epoch": 377.68,
      "learning_rate": 0.06224745710741936,
      "loss": 0.8312,
      "step": 234160
    },
    {
      "epoch": 377.71,
      "learning_rate": 0.06224423130419354,
      "loss": 0.8124,
      "step": 234180
    },
    {
      "epoch": 377.74,
      "learning_rate": 0.06224100550096774,
      "loss": 0.8154,
      "step": 234200
    },
    {
      "epoch": 377.77,
      "learning_rate": 0.06223777969774194,
      "loss": 0.8135,
      "step": 234220
    },
    {
      "epoch": 377.81,
      "learning_rate": 0.06223455389451613,
      "loss": 0.8335,
      "step": 234240
    },
    {
      "epoch": 377.84,
      "learning_rate": 0.06223132809129032,
      "loss": 0.7943,
      "step": 234260
    },
    {
      "epoch": 377.87,
      "learning_rate": 0.062228102288064524,
      "loss": 0.7808,
      "step": 234280
    },
    {
      "epoch": 377.9,
      "learning_rate": 0.06222487648483871,
      "loss": 0.7849,
      "step": 234300
    },
    {
      "epoch": 377.94,
      "learning_rate": 0.06222165068161291,
      "loss": 0.7941,
      "step": 234320
    },
    {
      "epoch": 377.97,
      "learning_rate": 0.062218424878387094,
      "loss": 0.8341,
      "step": 234340
    },
    {
      "epoch": 378.0,
      "learning_rate": 0.0622151990751613,
      "loss": 0.8285,
      "step": 234360
    },
    {
      "epoch": 378.0,
      "eval_accuracy": {
        "accuracy": 0.7523222230895324
      },
      "eval_loss": 1.1885666847229004,
      "eval_runtime": 2.8175,
      "eval_samples_per_second": 4546.957,
      "eval_steps_per_second": 71.34,
      "step": 234360
    },
    {
      "epoch": 378.03,
      "learning_rate": 0.062211973271935485,
      "loss": 0.8407,
      "step": 234380
    },
    {
      "epoch": 378.06,
      "learning_rate": 0.06220874746870969,
      "loss": 0.8082,
      "step": 234400
    },
    {
      "epoch": 378.1,
      "learning_rate": 0.06220552166548387,
      "loss": 0.827,
      "step": 234420
    },
    {
      "epoch": 378.13,
      "learning_rate": 0.062202295862258075,
      "loss": 0.7942,
      "step": 234440
    },
    {
      "epoch": 378.16,
      "learning_rate": 0.06219907005903226,
      "loss": 0.7739,
      "step": 234460
    },
    {
      "epoch": 378.19,
      "learning_rate": 0.06219584425580646,
      "loss": 0.8106,
      "step": 234480
    },
    {
      "epoch": 378.23,
      "learning_rate": 0.062192618452580645,
      "loss": 0.7995,
      "step": 234500
    },
    {
      "epoch": 378.26,
      "learning_rate": 0.06218939264935484,
      "loss": 0.7883,
      "step": 234520
    },
    {
      "epoch": 378.29,
      "learning_rate": 0.062186166846129036,
      "loss": 0.7997,
      "step": 234540
    },
    {
      "epoch": 378.32,
      "learning_rate": 0.06218294104290323,
      "loss": 0.8054,
      "step": 234560
    },
    {
      "epoch": 378.35,
      "learning_rate": 0.06217971523967743,
      "loss": 0.7726,
      "step": 234580
    },
    {
      "epoch": 378.39,
      "learning_rate": 0.062176489436451626,
      "loss": 0.8086,
      "step": 234600
    },
    {
      "epoch": 378.42,
      "learning_rate": 0.06217326363322581,
      "loss": 0.8067,
      "step": 234620
    },
    {
      "epoch": 378.45,
      "learning_rate": 0.06217003783,
      "loss": 0.8044,
      "step": 234640
    },
    {
      "epoch": 378.48,
      "learning_rate": 0.0621668120267742,
      "loss": 0.8203,
      "step": 234660
    },
    {
      "epoch": 378.52,
      "learning_rate": 0.06216358622354839,
      "loss": 0.8052,
      "step": 234680
    },
    {
      "epoch": 378.55,
      "learning_rate": 0.06216036042032258,
      "loss": 0.8187,
      "step": 234700
    },
    {
      "epoch": 378.58,
      "learning_rate": 0.062157134617096765,
      "loss": 0.7959,
      "step": 234720
    },
    {
      "epoch": 378.61,
      "learning_rate": 0.06215390881387098,
      "loss": 0.8165,
      "step": 234740
    },
    {
      "epoch": 378.65,
      "learning_rate": 0.062150683010645164,
      "loss": 0.8312,
      "step": 234760
    },
    {
      "epoch": 378.68,
      "learning_rate": 0.06214745720741937,
      "loss": 0.8447,
      "step": 234780
    },
    {
      "epoch": 378.71,
      "learning_rate": 0.06214423140419354,
      "loss": 0.8101,
      "step": 234800
    },
    {
      "epoch": 378.74,
      "learning_rate": 0.06214100560096775,
      "loss": 0.8137,
      "step": 234820
    },
    {
      "epoch": 378.77,
      "learning_rate": 0.06213777979774193,
      "loss": 0.812,
      "step": 234840
    },
    {
      "epoch": 378.81,
      "learning_rate": 0.06213455399451613,
      "loss": 0.8143,
      "step": 234860
    },
    {
      "epoch": 378.84,
      "learning_rate": 0.06213132819129033,
      "loss": 0.809,
      "step": 234880
    },
    {
      "epoch": 378.87,
      "learning_rate": 0.06212810238806452,
      "loss": 0.8073,
      "step": 234900
    },
    {
      "epoch": 378.9,
      "learning_rate": 0.06212487658483871,
      "loss": 0.8257,
      "step": 234920
    },
    {
      "epoch": 378.94,
      "learning_rate": 0.062121650781612914,
      "loss": 0.833,
      "step": 234940
    },
    {
      "epoch": 378.97,
      "learning_rate": 0.0621184249783871,
      "loss": 0.824,
      "step": 234960
    },
    {
      "epoch": 379.0,
      "learning_rate": 0.062115199175161284,
      "loss": 0.8259,
      "step": 234980
    },
    {
      "epoch": 379.0,
      "eval_accuracy": {
        "accuracy": 0.7522441651705566
      },
      "eval_loss": 1.2043417692184448,
      "eval_runtime": 3.7442,
      "eval_samples_per_second": 3421.577,
      "eval_steps_per_second": 53.683,
      "step": 234980
    },
    {
      "epoch": 379.03,
      "learning_rate": 0.0621119733719355,
      "loss": 0.8299,
      "step": 235000
    },
    {
      "epoch": 379.06,
      "learning_rate": 0.06210874756870968,
      "loss": 0.813,
      "step": 235020
    },
    {
      "epoch": 379.1,
      "learning_rate": 0.062105521765483875,
      "loss": 0.7819,
      "step": 235040
    },
    {
      "epoch": 379.13,
      "learning_rate": 0.06210229596225806,
      "loss": 0.8016,
      "step": 235060
    },
    {
      "epoch": 379.16,
      "learning_rate": 0.062099070159032266,
      "loss": 0.8206,
      "step": 235080
    },
    {
      "epoch": 379.19,
      "learning_rate": 0.06209584435580645,
      "loss": 0.8079,
      "step": 235100
    },
    {
      "epoch": 379.23,
      "learning_rate": 0.06209261855258065,
      "loss": 0.7806,
      "step": 235120
    },
    {
      "epoch": 379.26,
      "learning_rate": 0.06208939274935485,
      "loss": 0.7869,
      "step": 235140
    },
    {
      "epoch": 379.29,
      "learning_rate": 0.062086166946129034,
      "loss": 0.7867,
      "step": 235160
    },
    {
      "epoch": 379.32,
      "learning_rate": 0.06208294114290323,
      "loss": 0.8028,
      "step": 235180
    },
    {
      "epoch": 379.35,
      "learning_rate": 0.062079715339677426,
      "loss": 0.7925,
      "step": 235200
    },
    {
      "epoch": 379.39,
      "learning_rate": 0.06207648953645162,
      "loss": 0.785,
      "step": 235220
    },
    {
      "epoch": 379.42,
      "learning_rate": 0.0620732637332258,
      "loss": 0.7909,
      "step": 235240
    },
    {
      "epoch": 379.45,
      "learning_rate": 0.062070037930000016,
      "loss": 0.7824,
      "step": 235260
    },
    {
      "epoch": 379.48,
      "learning_rate": 0.06206681212677419,
      "loss": 0.8161,
      "step": 235280
    },
    {
      "epoch": 379.52,
      "learning_rate": 0.06206358632354839,
      "loss": 0.783,
      "step": 235300
    },
    {
      "epoch": 379.55,
      "learning_rate": 0.06206036052032258,
      "loss": 0.7967,
      "step": 235320
    },
    {
      "epoch": 379.58,
      "learning_rate": 0.062057134717096785,
      "loss": 0.8121,
      "step": 235340
    },
    {
      "epoch": 379.61,
      "learning_rate": 0.06205390891387097,
      "loss": 0.794,
      "step": 235360
    },
    {
      "epoch": 379.65,
      "learning_rate": 0.06205068311064518,
      "loss": 0.8116,
      "step": 235380
    },
    {
      "epoch": 379.68,
      "learning_rate": 0.062047457307419354,
      "loss": 0.8232,
      "step": 235400
    },
    {
      "epoch": 379.71,
      "learning_rate": 0.06204423150419355,
      "loss": 0.8134,
      "step": 235420
    },
    {
      "epoch": 379.74,
      "learning_rate": 0.062041005700967745,
      "loss": 0.8062,
      "step": 235440
    },
    {
      "epoch": 379.77,
      "learning_rate": 0.06203777989774193,
      "loss": 0.8046,
      "step": 235460
    },
    {
      "epoch": 379.81,
      "learning_rate": 0.06203455409451614,
      "loss": 0.807,
      "step": 235480
    },
    {
      "epoch": 379.84,
      "learning_rate": 0.06203132829129032,
      "loss": 0.8195,
      "step": 235500
    },
    {
      "epoch": 379.87,
      "learning_rate": 0.06202810248806452,
      "loss": 0.7854,
      "step": 235520
    },
    {
      "epoch": 379.9,
      "learning_rate": 0.06202487668483872,
      "loss": 0.8229,
      "step": 235540
    },
    {
      "epoch": 379.94,
      "learning_rate": 0.06202165088161291,
      "loss": 0.8128,
      "step": 235560
    },
    {
      "epoch": 379.97,
      "learning_rate": 0.06201842507838709,
      "loss": 0.8369,
      "step": 235580
    },
    {
      "epoch": 380.0,
      "learning_rate": 0.062015360565322586,
      "loss": 0.819,
      "step": 235600
    },
    {
      "epoch": 380.0,
      "eval_accuracy": {
        "accuracy": 0.7518538755756772
      },
      "eval_loss": 1.1806021928787231,
      "eval_runtime": 2.8027,
      "eval_samples_per_second": 4570.893,
      "eval_steps_per_second": 71.716,
      "step": 235600
    },
    {
      "epoch": 380.03,
      "learning_rate": 0.06201213476209677,
      "loss": 0.8199,
      "step": 235620
    },
    {
      "epoch": 380.06,
      "learning_rate": 0.06200890895887097,
      "loss": 0.8062,
      "step": 235640
    },
    {
      "epoch": 380.1,
      "learning_rate": 0.06200568315564517,
      "loss": 0.7874,
      "step": 235660
    },
    {
      "epoch": 380.13,
      "learning_rate": 0.06200245735241936,
      "loss": 0.7961,
      "step": 235680
    },
    {
      "epoch": 380.16,
      "learning_rate": 0.06199923154919355,
      "loss": 0.7948,
      "step": 235700
    },
    {
      "epoch": 380.19,
      "learning_rate": 0.06199600574596773,
      "loss": 0.7992,
      "step": 235720
    },
    {
      "epoch": 380.23,
      "learning_rate": 0.06199277994274194,
      "loss": 0.7919,
      "step": 235740
    },
    {
      "epoch": 380.26,
      "learning_rate": 0.06198955413951612,
      "loss": 0.7888,
      "step": 235760
    },
    {
      "epoch": 380.29,
      "learning_rate": 0.061986328336290336,
      "loss": 0.7766,
      "step": 235780
    },
    {
      "epoch": 380.32,
      "learning_rate": 0.06198310253306452,
      "loss": 0.7944,
      "step": 235800
    },
    {
      "epoch": 380.35,
      "learning_rate": 0.061979876729838713,
      "loss": 0.8122,
      "step": 235820
    },
    {
      "epoch": 380.39,
      "learning_rate": 0.0619766509266129,
      "loss": 0.8142,
      "step": 235840
    },
    {
      "epoch": 380.42,
      "learning_rate": 0.061973425123387105,
      "loss": 0.8007,
      "step": 235860
    },
    {
      "epoch": 380.45,
      "learning_rate": 0.06197019932016129,
      "loss": 0.7966,
      "step": 235880
    },
    {
      "epoch": 380.48,
      "learning_rate": 0.06196697351693549,
      "loss": 0.8029,
      "step": 235900
    },
    {
      "epoch": 380.52,
      "learning_rate": 0.06196374771370969,
      "loss": 0.7875,
      "step": 235920
    },
    {
      "epoch": 380.55,
      "learning_rate": 0.06196052191048387,
      "loss": 0.7897,
      "step": 235940
    },
    {
      "epoch": 380.58,
      "learning_rate": 0.061957296107258066,
      "loss": 0.8006,
      "step": 235960
    },
    {
      "epoch": 380.61,
      "learning_rate": 0.061954070304032265,
      "loss": 0.7786,
      "step": 235980
    },
    {
      "epoch": 380.65,
      "learning_rate": 0.06195084450080646,
      "loss": 0.788,
      "step": 236000
    },
    {
      "epoch": 380.68,
      "learning_rate": 0.06194761869758064,
      "loss": 0.8067,
      "step": 236020
    },
    {
      "epoch": 380.71,
      "learning_rate": 0.061944392894354855,
      "loss": 0.8179,
      "step": 236040
    },
    {
      "epoch": 380.74,
      "learning_rate": 0.06194116709112904,
      "loss": 0.8068,
      "step": 236060
    },
    {
      "epoch": 380.77,
      "learning_rate": 0.06193794128790323,
      "loss": 0.8004,
      "step": 236080
    },
    {
      "epoch": 380.81,
      "learning_rate": 0.06193471548467742,
      "loss": 0.8235,
      "step": 236100
    },
    {
      "epoch": 380.84,
      "learning_rate": 0.061931489681451624,
      "loss": 0.8029,
      "step": 236120
    },
    {
      "epoch": 380.87,
      "learning_rate": 0.06192826387822581,
      "loss": 0.8125,
      "step": 236140
    },
    {
      "epoch": 380.9,
      "learning_rate": 0.06192503807500002,
      "loss": 0.8151,
      "step": 236160
    },
    {
      "epoch": 380.94,
      "learning_rate": 0.06192181227177419,
      "loss": 0.824,
      "step": 236180
    },
    {
      "epoch": 380.97,
      "learning_rate": 0.06191858646854839,
      "loss": 0.8227,
      "step": 236200
    },
    {
      "epoch": 381.0,
      "learning_rate": 0.061915360665322584,
      "loss": 0.7865,
      "step": 236220
    },
    {
      "epoch": 381.0,
      "eval_accuracy": {
        "accuracy": 0.7530247443603153
      },
      "eval_loss": 1.1690785884857178,
      "eval_runtime": 9.1758,
      "eval_samples_per_second": 1396.18,
      "eval_steps_per_second": 21.906,
      "step": 236220
    },
    {
      "epoch": 381.03,
      "learning_rate": 0.06191213486209677,
      "loss": 0.8154,
      "step": 236240
    },
    {
      "epoch": 381.06,
      "learning_rate": 0.061908909058870976,
      "loss": 0.7857,
      "step": 236260
    },
    {
      "epoch": 381.1,
      "learning_rate": 0.06190568325564516,
      "loss": 0.7742,
      "step": 236280
    },
    {
      "epoch": 381.13,
      "learning_rate": 0.06190245745241936,
      "loss": 0.783,
      "step": 236300
    },
    {
      "epoch": 381.16,
      "learning_rate": 0.06189923164919356,
      "loss": 0.7973,
      "step": 236320
    },
    {
      "epoch": 381.19,
      "learning_rate": 0.06189600584596775,
      "loss": 0.7908,
      "step": 236340
    },
    {
      "epoch": 381.23,
      "learning_rate": 0.06189278004274193,
      "loss": 0.8155,
      "step": 236360
    },
    {
      "epoch": 381.26,
      "learning_rate": 0.061889554239516135,
      "loss": 0.7854,
      "step": 236380
    },
    {
      "epoch": 381.29,
      "learning_rate": 0.06188632843629032,
      "loss": 0.8251,
      "step": 236400
    },
    {
      "epoch": 381.32,
      "learning_rate": 0.06188310263306453,
      "loss": 0.8221,
      "step": 236420
    },
    {
      "epoch": 381.35,
      "learning_rate": 0.06187987682983871,
      "loss": 0.7926,
      "step": 236440
    },
    {
      "epoch": 381.39,
      "learning_rate": 0.06187665102661292,
      "loss": 0.8058,
      "step": 236460
    },
    {
      "epoch": 381.42,
      "learning_rate": 0.061873425223387096,
      "loss": 0.8147,
      "step": 236480
    },
    {
      "epoch": 381.45,
      "learning_rate": 0.06187019942016129,
      "loss": 0.8111,
      "step": 236500
    },
    {
      "epoch": 381.48,
      "learning_rate": 0.06186697361693549,
      "loss": 0.8167,
      "step": 236520
    },
    {
      "epoch": 381.52,
      "learning_rate": 0.06186374781370968,
      "loss": 0.8274,
      "step": 236540
    },
    {
      "epoch": 381.55,
      "learning_rate": 0.06186052201048388,
      "loss": 0.7967,
      "step": 236560
    },
    {
      "epoch": 381.58,
      "learning_rate": 0.06185729620725808,
      "loss": 0.8246,
      "step": 236580
    },
    {
      "epoch": 381.61,
      "learning_rate": 0.06185407040403226,
      "loss": 0.8285,
      "step": 236600
    },
    {
      "epoch": 381.65,
      "learning_rate": 0.061850844600806455,
      "loss": 0.8041,
      "step": 236620
    },
    {
      "epoch": 381.68,
      "learning_rate": 0.061847618797580654,
      "loss": 0.7891,
      "step": 236640
    },
    {
      "epoch": 381.71,
      "learning_rate": 0.061844392994354826,
      "loss": 0.7906,
      "step": 236660
    },
    {
      "epoch": 381.74,
      "learning_rate": 0.06184116719112903,
      "loss": 0.8089,
      "step": 236680
    },
    {
      "epoch": 381.77,
      "learning_rate": 0.06183794138790322,
      "loss": 0.7904,
      "step": 236700
    },
    {
      "epoch": 381.81,
      "learning_rate": 0.06183471558467743,
      "loss": 0.805,
      "step": 236720
    },
    {
      "epoch": 381.84,
      "learning_rate": 0.061831489781451615,
      "loss": 0.8124,
      "step": 236740
    },
    {
      "epoch": 381.87,
      "learning_rate": 0.06182826397822582,
      "loss": 0.8072,
      "step": 236760
    },
    {
      "epoch": 381.9,
      "learning_rate": 0.06182503817499999,
      "loss": 0.7952,
      "step": 236780
    },
    {
      "epoch": 381.94,
      "learning_rate": 0.0618218123717742,
      "loss": 0.8001,
      "step": 236800
    },
    {
      "epoch": 381.97,
      "learning_rate": 0.061818586568548384,
      "loss": 0.7891,
      "step": 236820
    },
    {
      "epoch": 382.0,
      "learning_rate": 0.06181536076532258,
      "loss": 0.7942,
      "step": 236840
    },
    {
      "epoch": 382.0,
      "eval_accuracy": {
        "accuracy": 0.7543517289829054
      },
      "eval_loss": 1.1793121099472046,
      "eval_runtime": 3.0839,
      "eval_samples_per_second": 4154.148,
      "eval_steps_per_second": 65.177,
      "step": 236840
    },
    {
      "epoch": 382.03,
      "learning_rate": 0.06181213496209678,
      "loss": 0.8012,
      "step": 236860
    },
    {
      "epoch": 382.06,
      "learning_rate": 0.061808909158870974,
      "loss": 0.7764,
      "step": 236880
    },
    {
      "epoch": 382.1,
      "learning_rate": 0.06180568335564516,
      "loss": 0.8035,
      "step": 236900
    },
    {
      "epoch": 382.13,
      "learning_rate": 0.06180245755241936,
      "loss": 0.7865,
      "step": 236920
    },
    {
      "epoch": 382.16,
      "learning_rate": 0.06179923174919355,
      "loss": 0.7939,
      "step": 236940
    },
    {
      "epoch": 382.19,
      "learning_rate": 0.061796005945967736,
      "loss": 0.7927,
      "step": 236960
    },
    {
      "epoch": 382.23,
      "learning_rate": 0.06179278014274195,
      "loss": 0.8013,
      "step": 236980
    },
    {
      "epoch": 382.26,
      "learning_rate": 0.061789554339516134,
      "loss": 0.8084,
      "step": 237000
    },
    {
      "epoch": 382.29,
      "learning_rate": 0.061786328536290326,
      "loss": 0.8143,
      "step": 237020
    },
    {
      "epoch": 382.32,
      "learning_rate": 0.06178310273306451,
      "loss": 0.8285,
      "step": 237040
    },
    {
      "epoch": 382.35,
      "learning_rate": 0.06177987692983872,
      "loss": 0.8108,
      "step": 237060
    },
    {
      "epoch": 382.39,
      "learning_rate": 0.0617766511266129,
      "loss": 0.8003,
      "step": 237080
    },
    {
      "epoch": 382.42,
      "learning_rate": 0.061773425323387116,
      "loss": 0.8022,
      "step": 237100
    },
    {
      "epoch": 382.45,
      "learning_rate": 0.0617701995201613,
      "loss": 0.7865,
      "step": 237120
    },
    {
      "epoch": 382.48,
      "learning_rate": 0.061766973716935486,
      "loss": 0.8056,
      "step": 237140
    },
    {
      "epoch": 382.52,
      "learning_rate": 0.06176374791370968,
      "loss": 0.807,
      "step": 237160
    },
    {
      "epoch": 382.55,
      "learning_rate": 0.06176052211048388,
      "loss": 0.8082,
      "step": 237180
    },
    {
      "epoch": 382.58,
      "learning_rate": 0.06175729630725807,
      "loss": 0.8187,
      "step": 237200
    },
    {
      "epoch": 382.61,
      "learning_rate": 0.061754070504032255,
      "loss": 0.8269,
      "step": 237220
    },
    {
      "epoch": 382.65,
      "learning_rate": 0.06175084470080647,
      "loss": 0.8233,
      "step": 237240
    },
    {
      "epoch": 382.68,
      "learning_rate": 0.06174761889758065,
      "loss": 0.8086,
      "step": 237260
    },
    {
      "epoch": 382.71,
      "learning_rate": 0.061744393094354845,
      "loss": 0.7884,
      "step": 237280
    },
    {
      "epoch": 382.74,
      "learning_rate": 0.06174116729112903,
      "loss": 0.8107,
      "step": 237300
    },
    {
      "epoch": 382.77,
      "learning_rate": 0.061737941487903236,
      "loss": 0.793,
      "step": 237320
    },
    {
      "epoch": 382.81,
      "learning_rate": 0.06173471568467742,
      "loss": 0.7896,
      "step": 237340
    },
    {
      "epoch": 382.84,
      "learning_rate": 0.06173148988145162,
      "loss": 0.8063,
      "step": 237360
    },
    {
      "epoch": 382.87,
      "learning_rate": 0.061728264078225806,
      "loss": 0.8002,
      "step": 237380
    },
    {
      "epoch": 382.9,
      "learning_rate": 0.06172503827500001,
      "loss": 0.8234,
      "step": 237400
    },
    {
      "epoch": 382.94,
      "learning_rate": 0.0617218124717742,
      "loss": 0.7977,
      "step": 237420
    },
    {
      "epoch": 382.97,
      "learning_rate": 0.06171858666854838,
      "loss": 0.8052,
      "step": 237440
    },
    {
      "epoch": 383.0,
      "learning_rate": 0.06171536086532258,
      "loss": 0.8123,
      "step": 237460
    },
    {
      "epoch": 383.0,
      "eval_accuracy": {
        "accuracy": 0.7547420185777847
      },
      "eval_loss": 1.157151222229004,
      "eval_runtime": 2.763,
      "eval_samples_per_second": 4636.594,
      "eval_steps_per_second": 72.746,
      "step": 237460
    },
    {
      "epoch": 383.03,
      "learning_rate": 0.06171213506209677,
      "loss": 0.8326,
      "step": 237480
    },
    {
      "epoch": 383.06,
      "learning_rate": 0.06170890925887097,
      "loss": 0.7813,
      "step": 237500
    },
    {
      "epoch": 383.1,
      "learning_rate": 0.06170568345564517,
      "loss": 0.7738,
      "step": 237520
    },
    {
      "epoch": 383.13,
      "learning_rate": 0.061702457652419364,
      "loss": 0.7855,
      "step": 237540
    },
    {
      "epoch": 383.16,
      "learning_rate": 0.06169923184919355,
      "loss": 0.7968,
      "step": 237560
    },
    {
      "epoch": 383.19,
      "learning_rate": 0.06169600604596775,
      "loss": 0.7972,
      "step": 237580
    },
    {
      "epoch": 383.23,
      "learning_rate": 0.06169278024274193,
      "loss": 0.8052,
      "step": 237600
    },
    {
      "epoch": 383.26,
      "learning_rate": 0.06168955443951614,
      "loss": 0.8006,
      "step": 237620
    },
    {
      "epoch": 383.29,
      "learning_rate": 0.06168632863629031,
      "loss": 0.7883,
      "step": 237640
    },
    {
      "epoch": 383.32,
      "learning_rate": 0.061683102833064524,
      "loss": 0.7884,
      "step": 237660
    },
    {
      "epoch": 383.35,
      "learning_rate": 0.06167987702983871,
      "loss": 0.7972,
      "step": 237680
    },
    {
      "epoch": 383.39,
      "learning_rate": 0.061676651226612915,
      "loss": 0.8244,
      "step": 237700
    },
    {
      "epoch": 383.42,
      "learning_rate": 0.0616734254233871,
      "loss": 0.8151,
      "step": 237720
    },
    {
      "epoch": 383.45,
      "learning_rate": 0.06167019962016129,
      "loss": 0.7964,
      "step": 237740
    },
    {
      "epoch": 383.48,
      "learning_rate": 0.06166697381693548,
      "loss": 0.8174,
      "step": 237760
    },
    {
      "epoch": 383.52,
      "learning_rate": 0.06166374801370969,
      "loss": 0.7991,
      "step": 237780
    },
    {
      "epoch": 383.55,
      "learning_rate": 0.061660522210483876,
      "loss": 0.7953,
      "step": 237800
    },
    {
      "epoch": 383.58,
      "learning_rate": 0.06165729640725807,
      "loss": 0.8067,
      "step": 237820
    },
    {
      "epoch": 383.61,
      "learning_rate": 0.061654231894193556,
      "loss": 0.8074,
      "step": 237840
    },
    {
      "epoch": 383.65,
      "learning_rate": 0.06165100609096774,
      "loss": 0.8083,
      "step": 237860
    },
    {
      "epoch": 383.68,
      "learning_rate": 0.06164778028774194,
      "loss": 0.7953,
      "step": 237880
    },
    {
      "epoch": 383.71,
      "learning_rate": 0.06164455448451614,
      "loss": 0.8248,
      "step": 237900
    },
    {
      "epoch": 383.74,
      "learning_rate": 0.061641328681290325,
      "loss": 0.819,
      "step": 237920
    },
    {
      "epoch": 383.77,
      "learning_rate": 0.06163810287806452,
      "loss": 0.8,
      "step": 237940
    },
    {
      "epoch": 383.81,
      "learning_rate": 0.061634877074838716,
      "loss": 0.8098,
      "step": 237960
    },
    {
      "epoch": 383.84,
      "learning_rate": 0.06163165127161291,
      "loss": 0.8114,
      "step": 237980
    },
    {
      "epoch": 383.87,
      "learning_rate": 0.061628425468387094,
      "loss": 0.8165,
      "step": 238000
    },
    {
      "epoch": 383.9,
      "learning_rate": 0.06162519966516131,
      "loss": 0.7839,
      "step": 238020
    },
    {
      "epoch": 383.94,
      "learning_rate": 0.06162197386193548,
      "loss": 0.7983,
      "step": 238040
    },
    {
      "epoch": 383.97,
      "learning_rate": 0.061618748058709684,
      "loss": 0.8216,
      "step": 238060
    },
    {
      "epoch": 384.0,
      "learning_rate": 0.06161552225548387,
      "loss": 0.8437,
      "step": 238080
    },
    {
      "epoch": 384.0,
      "eval_accuracy": {
        "accuracy": 0.7442822574350167
      },
      "eval_loss": 1.2370121479034424,
      "eval_runtime": 2.795,
      "eval_samples_per_second": 4583.523,
      "eval_steps_per_second": 71.914,
      "step": 238080
    },
    {
      "epoch": 384.03,
      "learning_rate": 0.061612296452258075,
      "loss": 0.8294,
      "step": 238100
    },
    {
      "epoch": 384.06,
      "learning_rate": 0.06160907064903226,
      "loss": 0.8054,
      "step": 238120
    },
    {
      "epoch": 384.1,
      "learning_rate": 0.06160584484580646,
      "loss": 0.8164,
      "step": 238140
    },
    {
      "epoch": 384.13,
      "learning_rate": 0.061602619042580645,
      "loss": 0.8024,
      "step": 238160
    },
    {
      "epoch": 384.16,
      "learning_rate": 0.06159939323935485,
      "loss": 0.804,
      "step": 238180
    },
    {
      "epoch": 384.19,
      "learning_rate": 0.061596167436129036,
      "loss": 0.8063,
      "step": 238200
    },
    {
      "epoch": 384.23,
      "learning_rate": 0.06159294163290322,
      "loss": 0.8249,
      "step": 238220
    },
    {
      "epoch": 384.26,
      "learning_rate": 0.06158971582967742,
      "loss": 0.8,
      "step": 238240
    },
    {
      "epoch": 384.29,
      "learning_rate": 0.06158649002645161,
      "loss": 0.7685,
      "step": 238260
    },
    {
      "epoch": 384.32,
      "learning_rate": 0.06158326422322581,
      "loss": 0.7876,
      "step": 238280
    },
    {
      "epoch": 384.35,
      "learning_rate": 0.06158003842000001,
      "loss": 0.7951,
      "step": 238300
    },
    {
      "epoch": 384.39,
      "learning_rate": 0.0615768126167742,
      "loss": 0.8197,
      "step": 238320
    },
    {
      "epoch": 384.42,
      "learning_rate": 0.06157358681354838,
      "loss": 0.8294,
      "step": 238340
    },
    {
      "epoch": 384.45,
      "learning_rate": 0.06157036101032259,
      "loss": 0.7934,
      "step": 238360
    },
    {
      "epoch": 384.48,
      "learning_rate": 0.06156713520709677,
      "loss": 0.7884,
      "step": 238380
    },
    {
      "epoch": 384.52,
      "learning_rate": 0.06156390940387098,
      "loss": 0.8088,
      "step": 238400
    },
    {
      "epoch": 384.55,
      "learning_rate": 0.061560683600645164,
      "loss": 0.8065,
      "step": 238420
    },
    {
      "epoch": 384.58,
      "learning_rate": 0.06155745779741936,
      "loss": 0.7991,
      "step": 238440
    },
    {
      "epoch": 384.61,
      "learning_rate": 0.06155423199419355,
      "loss": 0.7737,
      "step": 238460
    },
    {
      "epoch": 384.65,
      "learning_rate": 0.061551006190967754,
      "loss": 0.7984,
      "step": 238480
    },
    {
      "epoch": 384.68,
      "learning_rate": 0.06154778038774194,
      "loss": 0.8065,
      "step": 238500
    },
    {
      "epoch": 384.71,
      "learning_rate": 0.06154455458451613,
      "loss": 0.808,
      "step": 238520
    },
    {
      "epoch": 384.74,
      "learning_rate": 0.061541328781290316,
      "loss": 0.801,
      "step": 238540
    },
    {
      "epoch": 384.77,
      "learning_rate": 0.06153810297806453,
      "loss": 0.791,
      "step": 238560
    },
    {
      "epoch": 384.81,
      "learning_rate": 0.061534877174838715,
      "loss": 0.7843,
      "step": 238580
    },
    {
      "epoch": 384.84,
      "learning_rate": 0.06153165137161291,
      "loss": 0.7937,
      "step": 238600
    },
    {
      "epoch": 384.87,
      "learning_rate": 0.061528425568387106,
      "loss": 0.82,
      "step": 238620
    },
    {
      "epoch": 384.9,
      "learning_rate": 0.0615251997651613,
      "loss": 0.7964,
      "step": 238640
    },
    {
      "epoch": 384.94,
      "learning_rate": 0.06152197396193548,
      "loss": 0.8037,
      "step": 238660
    },
    {
      "epoch": 384.97,
      "learning_rate": 0.06151874815870967,
      "loss": 0.8005,
      "step": 238680
    },
    {
      "epoch": 385.0,
      "learning_rate": 0.06151552235548388,
      "loss": 0.7924,
      "step": 238700
    },
    {
      "epoch": 385.0,
      "eval_accuracy": {
        "accuracy": 0.7523222230895324
      },
      "eval_loss": 1.1719942092895508,
      "eval_runtime": 2.7828,
      "eval_samples_per_second": 4603.677,
      "eval_steps_per_second": 72.23,
      "step": 238700
    },
    {
      "epoch": 385.03,
      "learning_rate": 0.06151229655225807,
      "loss": 0.8098,
      "step": 238720
    },
    {
      "epoch": 385.06,
      "learning_rate": 0.06150907074903226,
      "loss": 0.7839,
      "step": 238740
    },
    {
      "epoch": 385.1,
      "learning_rate": 0.061505844945806444,
      "loss": 0.7746,
      "step": 238760
    },
    {
      "epoch": 385.13,
      "learning_rate": 0.06150261914258065,
      "loss": 0.7765,
      "step": 238780
    },
    {
      "epoch": 385.16,
      "learning_rate": 0.061499393339354835,
      "loss": 0.8046,
      "step": 238800
    },
    {
      "epoch": 385.19,
      "learning_rate": 0.061496167536129034,
      "loss": 0.7725,
      "step": 238820
    },
    {
      "epoch": 385.23,
      "learning_rate": 0.061492941732903234,
      "loss": 0.8076,
      "step": 238840
    },
    {
      "epoch": 385.26,
      "learning_rate": 0.061489715929677426,
      "loss": 0.8038,
      "step": 238860
    },
    {
      "epoch": 385.29,
      "learning_rate": 0.06148649012645161,
      "loss": 0.7963,
      "step": 238880
    },
    {
      "epoch": 385.32,
      "learning_rate": 0.06148326432322581,
      "loss": 0.799,
      "step": 238900
    },
    {
      "epoch": 385.35,
      "learning_rate": 0.06148003852,
      "loss": 0.7906,
      "step": 238920
    },
    {
      "epoch": 385.39,
      "learning_rate": 0.0614768127167742,
      "loss": 0.7885,
      "step": 238940
    },
    {
      "epoch": 385.42,
      "learning_rate": 0.0614735869135484,
      "loss": 0.8049,
      "step": 238960
    },
    {
      "epoch": 385.45,
      "learning_rate": 0.061470361110322586,
      "loss": 0.81,
      "step": 238980
    },
    {
      "epoch": 385.48,
      "learning_rate": 0.06146713530709678,
      "loss": 0.8079,
      "step": 239000
    },
    {
      "epoch": 385.52,
      "learning_rate": 0.06146390950387096,
      "loss": 0.8165,
      "step": 239020
    },
    {
      "epoch": 385.55,
      "learning_rate": 0.06146068370064517,
      "loss": 0.8154,
      "step": 239040
    },
    {
      "epoch": 385.58,
      "learning_rate": 0.061457457897419354,
      "loss": 0.8096,
      "step": 239060
    },
    {
      "epoch": 385.61,
      "learning_rate": 0.06145423209419357,
      "loss": 0.8073,
      "step": 239080
    },
    {
      "epoch": 385.65,
      "learning_rate": 0.06145100629096775,
      "loss": 0.8097,
      "step": 239100
    },
    {
      "epoch": 385.68,
      "learning_rate": 0.06144778048774194,
      "loss": 0.7994,
      "step": 239120
    },
    {
      "epoch": 385.71,
      "learning_rate": 0.06144455468451613,
      "loss": 0.8005,
      "step": 239140
    },
    {
      "epoch": 385.74,
      "learning_rate": 0.06144132888129033,
      "loss": 0.8106,
      "step": 239160
    },
    {
      "epoch": 385.77,
      "learning_rate": 0.06143810307806452,
      "loss": 0.8216,
      "step": 239180
    },
    {
      "epoch": 385.81,
      "learning_rate": 0.061434877274838706,
      "loss": 0.8153,
      "step": 239200
    },
    {
      "epoch": 385.84,
      "learning_rate": 0.061431651471612905,
      "loss": 0.7965,
      "step": 239220
    },
    {
      "epoch": 385.87,
      "learning_rate": 0.061428425668387104,
      "loss": 0.8042,
      "step": 239240
    },
    {
      "epoch": 385.9,
      "learning_rate": 0.0614251998651613,
      "loss": 0.8167,
      "step": 239260
    },
    {
      "epoch": 385.94,
      "learning_rate": 0.06142197406193548,
      "loss": 0.8119,
      "step": 239280
    },
    {
      "epoch": 385.97,
      "learning_rate": 0.06141874825870969,
      "loss": 0.8006,
      "step": 239300
    },
    {
      "epoch": 386.0,
      "learning_rate": 0.061415522455483866,
      "loss": 0.8114,
      "step": 239320
    },
    {
      "epoch": 386.0,
      "eval_accuracy": {
        "accuracy": 0.7548981344157365
      },
      "eval_loss": 1.159969687461853,
      "eval_runtime": 3.6892,
      "eval_samples_per_second": 3472.564,
      "eval_steps_per_second": 54.483,
      "step": 239320
    },
    {
      "epoch": 386.03,
      "learning_rate": 0.06141229665225807,
      "loss": 0.8203,
      "step": 239340
    },
    {
      "epoch": 386.06,
      "learning_rate": 0.06140907084903226,
      "loss": 0.766,
      "step": 239360
    },
    {
      "epoch": 386.1,
      "learning_rate": 0.06140584504580646,
      "loss": 0.7538,
      "step": 239380
    },
    {
      "epoch": 386.13,
      "learning_rate": 0.06140261924258065,
      "loss": 0.7872,
      "step": 239400
    },
    {
      "epoch": 386.16,
      "learning_rate": 0.061399393439354855,
      "loss": 0.7815,
      "step": 239420
    },
    {
      "epoch": 386.19,
      "learning_rate": 0.06139616763612903,
      "loss": 0.8107,
      "step": 239440
    },
    {
      "epoch": 386.23,
      "learning_rate": 0.061392941832903225,
      "loss": 0.7976,
      "step": 239460
    },
    {
      "epoch": 386.26,
      "learning_rate": 0.061389716029677424,
      "loss": 0.7847,
      "step": 239480
    },
    {
      "epoch": 386.29,
      "learning_rate": 0.06138649022645162,
      "loss": 0.7848,
      "step": 239500
    },
    {
      "epoch": 386.32,
      "learning_rate": 0.06138326442322581,
      "loss": 0.8171,
      "step": 239520
    },
    {
      "epoch": 386.35,
      "learning_rate": 0.06138003862,
      "loss": 0.8077,
      "step": 239540
    },
    {
      "epoch": 386.39,
      "learning_rate": 0.0613768128167742,
      "loss": 0.7971,
      "step": 239560
    },
    {
      "epoch": 386.42,
      "learning_rate": 0.06137358701354839,
      "loss": 0.8099,
      "step": 239580
    },
    {
      "epoch": 386.45,
      "learning_rate": 0.06137036121032259,
      "loss": 0.8085,
      "step": 239600
    },
    {
      "epoch": 386.48,
      "learning_rate": 0.06136713540709676,
      "loss": 0.8021,
      "step": 239620
    },
    {
      "epoch": 386.52,
      "learning_rate": 0.061363909603870975,
      "loss": 0.7961,
      "step": 239640
    },
    {
      "epoch": 386.55,
      "learning_rate": 0.06136068380064516,
      "loss": 0.8113,
      "step": 239660
    },
    {
      "epoch": 386.58,
      "learning_rate": 0.061357457997419367,
      "loss": 0.817,
      "step": 239680
    },
    {
      "epoch": 386.61,
      "learning_rate": 0.06135423219419355,
      "loss": 0.8136,
      "step": 239700
    },
    {
      "epoch": 386.65,
      "learning_rate": 0.061351006390967744,
      "loss": 0.8144,
      "step": 239720
    },
    {
      "epoch": 386.68,
      "learning_rate": 0.06134778058774193,
      "loss": 0.7998,
      "step": 239740
    },
    {
      "epoch": 386.71,
      "learning_rate": 0.06134455478451613,
      "loss": 0.8082,
      "step": 239760
    },
    {
      "epoch": 386.74,
      "learning_rate": 0.06134132898129033,
      "loss": 0.8225,
      "step": 239780
    },
    {
      "epoch": 386.77,
      "learning_rate": 0.06133810317806452,
      "loss": 0.8154,
      "step": 239800
    },
    {
      "epoch": 386.81,
      "learning_rate": 0.061334877374838705,
      "loss": 0.7857,
      "step": 239820
    },
    {
      "epoch": 386.84,
      "learning_rate": 0.06133165157161291,
      "loss": 0.7997,
      "step": 239840
    },
    {
      "epoch": 386.87,
      "learning_rate": 0.061328425768387096,
      "loss": 0.8483,
      "step": 239860
    },
    {
      "epoch": 386.9,
      "learning_rate": 0.061325199965161295,
      "loss": 0.8359,
      "step": 239880
    },
    {
      "epoch": 386.94,
      "learning_rate": 0.061321974161935494,
      "loss": 0.8085,
      "step": 239900
    },
    {
      "epoch": 386.97,
      "learning_rate": 0.06131874835870968,
      "loss": 0.8086,
      "step": 239920
    },
    {
      "epoch": 387.0,
      "learning_rate": 0.06131568384564517,
      "loss": 0.8065,
      "step": 239940
    },
    {
      "epoch": 387.0,
      "eval_accuracy": {
        "accuracy": 0.7506830067910389
      },
      "eval_loss": 1.176003336906433,
      "eval_runtime": 2.8052,
      "eval_samples_per_second": 4566.869,
      "eval_steps_per_second": 71.653,
      "step": 239940
    },
    {
      "epoch": 387.03,
      "learning_rate": 0.06131245804241936,
      "loss": 0.7973,
      "step": 239960
    },
    {
      "epoch": 387.06,
      "learning_rate": 0.061309232239193545,
      "loss": 0.7816,
      "step": 239980
    },
    {
      "epoch": 387.1,
      "learning_rate": 0.06130600643596776,
      "loss": 0.7876,
      "step": 240000
    },
    {
      "epoch": 387.13,
      "learning_rate": 0.06130278063274194,
      "loss": 0.7855,
      "step": 240020
    },
    {
      "epoch": 387.16,
      "learning_rate": 0.061299554829516135,
      "loss": 0.7971,
      "step": 240040
    },
    {
      "epoch": 387.19,
      "learning_rate": 0.06129632902629032,
      "loss": 0.8004,
      "step": 240060
    },
    {
      "epoch": 387.23,
      "learning_rate": 0.06129310322306453,
      "loss": 0.7876,
      "step": 240080
    },
    {
      "epoch": 387.26,
      "learning_rate": 0.061289877419838705,
      "loss": 0.7889,
      "step": 240100
    },
    {
      "epoch": 387.29,
      "learning_rate": 0.06128665161661291,
      "loss": 0.8068,
      "step": 240120
    },
    {
      "epoch": 387.32,
      "learning_rate": 0.061283425813387096,
      "loss": 0.8097,
      "step": 240140
    },
    {
      "epoch": 387.35,
      "learning_rate": 0.0612802000101613,
      "loss": 0.8017,
      "step": 240160
    },
    {
      "epoch": 387.39,
      "learning_rate": 0.06127697420693549,
      "loss": 0.7846,
      "step": 240180
    },
    {
      "epoch": 387.42,
      "learning_rate": 0.06127374840370967,
      "loss": 0.8048,
      "step": 240200
    },
    {
      "epoch": 387.45,
      "learning_rate": 0.06127052260048387,
      "loss": 0.7934,
      "step": 240220
    },
    {
      "epoch": 387.48,
      "learning_rate": 0.061267296797258064,
      "loss": 0.7865,
      "step": 240240
    },
    {
      "epoch": 387.52,
      "learning_rate": 0.06126407099403226,
      "loss": 0.7921,
      "step": 240260
    },
    {
      "epoch": 387.55,
      "learning_rate": 0.06126084519080646,
      "loss": 0.7902,
      "step": 240280
    },
    {
      "epoch": 387.58,
      "learning_rate": 0.06125761938758065,
      "loss": 0.8158,
      "step": 240300
    },
    {
      "epoch": 387.61,
      "learning_rate": 0.06125439358435484,
      "loss": 0.8134,
      "step": 240320
    },
    {
      "epoch": 387.65,
      "learning_rate": 0.06125116778112904,
      "loss": 0.8164,
      "step": 240340
    },
    {
      "epoch": 387.68,
      "learning_rate": 0.061247941977903224,
      "loss": 0.8013,
      "step": 240360
    },
    {
      "epoch": 387.71,
      "learning_rate": 0.06124471617467743,
      "loss": 0.7773,
      "step": 240380
    },
    {
      "epoch": 387.74,
      "learning_rate": 0.0612414903714516,
      "loss": 0.8036,
      "step": 240400
    },
    {
      "epoch": 387.77,
      "learning_rate": 0.061238264568225814,
      "loss": 0.8163,
      "step": 240420
    },
    {
      "epoch": 387.81,
      "learning_rate": 0.061235038765,
      "loss": 0.8128,
      "step": 240440
    },
    {
      "epoch": 387.84,
      "learning_rate": 0.061231812961774205,
      "loss": 0.8191,
      "step": 240460
    },
    {
      "epoch": 387.87,
      "learning_rate": 0.06122858715854839,
      "loss": 0.8077,
      "step": 240480
    },
    {
      "epoch": 387.9,
      "learning_rate": 0.0612253613553226,
      "loss": 0.8149,
      "step": 240500
    },
    {
      "epoch": 387.94,
      "learning_rate": 0.06122213555209677,
      "loss": 0.8228,
      "step": 240520
    },
    {
      "epoch": 387.97,
      "learning_rate": 0.06121890974887098,
      "loss": 0.8157,
      "step": 240540
    },
    {
      "epoch": 388.0,
      "learning_rate": 0.061215683945645166,
      "loss": 0.815,
      "step": 240560
    },
    {
      "epoch": 388.0,
      "eval_accuracy": {
        "accuracy": 0.748653500897666
      },
      "eval_loss": 1.216936707496643,
      "eval_runtime": 2.8586,
      "eval_samples_per_second": 4481.492,
      "eval_steps_per_second": 70.313,
      "step": 240560
    },
    {
      "epoch": 388.03,
      "learning_rate": 0.06121245814241936,
      "loss": 0.8217,
      "step": 240580
    },
    {
      "epoch": 388.06,
      "learning_rate": 0.061209232339193544,
      "loss": 0.7971,
      "step": 240600
    },
    {
      "epoch": 388.1,
      "learning_rate": 0.06120600653596775,
      "loss": 0.803,
      "step": 240620
    },
    {
      "epoch": 388.13,
      "learning_rate": 0.061202780732741935,
      "loss": 0.7802,
      "step": 240640
    },
    {
      "epoch": 388.16,
      "learning_rate": 0.06119955492951612,
      "loss": 0.7887,
      "step": 240660
    },
    {
      "epoch": 388.19,
      "learning_rate": 0.06119632912629033,
      "loss": 0.7917,
      "step": 240680
    },
    {
      "epoch": 388.23,
      "learning_rate": 0.06119310332306452,
      "loss": 0.7745,
      "step": 240700
    },
    {
      "epoch": 388.26,
      "learning_rate": 0.06118987751983871,
      "loss": 0.7983,
      "step": 240720
    },
    {
      "epoch": 388.29,
      "learning_rate": 0.061186651716612896,
      "loss": 0.7862,
      "step": 240740
    },
    {
      "epoch": 388.32,
      "learning_rate": 0.0611834259133871,
      "loss": 0.7882,
      "step": 240760
    },
    {
      "epoch": 388.35,
      "learning_rate": 0.06118020011016129,
      "loss": 0.8059,
      "step": 240780
    },
    {
      "epoch": 388.39,
      "learning_rate": 0.0611769743069355,
      "loss": 0.7915,
      "step": 240800
    },
    {
      "epoch": 388.42,
      "learning_rate": 0.061173748503709685,
      "loss": 0.8009,
      "step": 240820
    },
    {
      "epoch": 388.45,
      "learning_rate": 0.06117052270048387,
      "loss": 0.7893,
      "step": 240840
    },
    {
      "epoch": 388.48,
      "learning_rate": 0.06116729689725806,
      "loss": 0.7795,
      "step": 240860
    },
    {
      "epoch": 388.52,
      "learning_rate": 0.06116407109403226,
      "loss": 0.7911,
      "step": 240880
    },
    {
      "epoch": 388.55,
      "learning_rate": 0.061160845290806454,
      "loss": 0.8173,
      "step": 240900
    },
    {
      "epoch": 388.58,
      "learning_rate": 0.06115761948758065,
      "loss": 0.7942,
      "step": 240920
    },
    {
      "epoch": 388.61,
      "learning_rate": 0.06115439368435485,
      "loss": 0.7961,
      "step": 240940
    },
    {
      "epoch": 388.65,
      "learning_rate": 0.06115116788112904,
      "loss": 0.8039,
      "step": 240960
    },
    {
      "epoch": 388.68,
      "learning_rate": 0.06114794207790323,
      "loss": 0.8054,
      "step": 240980
    },
    {
      "epoch": 388.71,
      "learning_rate": 0.061144716274677414,
      "loss": 0.8221,
      "step": 241000
    },
    {
      "epoch": 388.74,
      "learning_rate": 0.06114149047145162,
      "loss": 0.8076,
      "step": 241020
    },
    {
      "epoch": 388.77,
      "learning_rate": 0.061138264668225806,
      "loss": 0.8081,
      "step": 241040
    },
    {
      "epoch": 388.81,
      "learning_rate": 0.06113503886500002,
      "loss": 0.7889,
      "step": 241060
    },
    {
      "epoch": 388.84,
      "learning_rate": 0.061131813061774204,
      "loss": 0.785,
      "step": 241080
    },
    {
      "epoch": 388.87,
      "learning_rate": 0.061128587258548396,
      "loss": 0.799,
      "step": 241100
    },
    {
      "epoch": 388.9,
      "learning_rate": 0.06112536145532258,
      "loss": 0.8155,
      "step": 241120
    },
    {
      "epoch": 388.94,
      "learning_rate": 0.061122135652096767,
      "loss": 0.8142,
      "step": 241140
    },
    {
      "epoch": 388.97,
      "learning_rate": 0.06111890984887097,
      "loss": 0.8152,
      "step": 241160
    },
    {
      "epoch": 389.0,
      "learning_rate": 0.06111568404564516,
      "loss": 0.7783,
      "step": 241180
    },
    {
      "epoch": 389.0,
      "eval_accuracy": {
        "accuracy": 0.7516197018187495
      },
      "eval_loss": 1.206229329109192,
      "eval_runtime": 11.3633,
      "eval_samples_per_second": 1127.398,
      "eval_steps_per_second": 17.688,
      "step": 241180
    },
    {
      "epoch": 389.03,
      "learning_rate": 0.06111245824241936,
      "loss": 0.8193,
      "step": 241200
    },
    {
      "epoch": 389.06,
      "learning_rate": 0.061109232439193556,
      "loss": 0.7838,
      "step": 241220
    },
    {
      "epoch": 389.1,
      "learning_rate": 0.06110600663596775,
      "loss": 0.7617,
      "step": 241240
    },
    {
      "epoch": 389.13,
      "learning_rate": 0.06110278083274193,
      "loss": 0.7701,
      "step": 241260
    },
    {
      "epoch": 389.16,
      "learning_rate": 0.06109955502951614,
      "loss": 0.8069,
      "step": 241280
    },
    {
      "epoch": 389.19,
      "learning_rate": 0.06109632922629032,
      "loss": 0.7895,
      "step": 241300
    },
    {
      "epoch": 389.23,
      "learning_rate": 0.061093103423064524,
      "loss": 0.7844,
      "step": 241320
    },
    {
      "epoch": 389.26,
      "learning_rate": 0.06108987761983871,
      "loss": 0.8012,
      "step": 241340
    },
    {
      "epoch": 389.29,
      "learning_rate": 0.061086651816612915,
      "loss": 0.788,
      "step": 241360
    },
    {
      "epoch": 389.32,
      "learning_rate": 0.06108342601338709,
      "loss": 0.8069,
      "step": 241380
    },
    {
      "epoch": 389.35,
      "learning_rate": 0.0610802002101613,
      "loss": 0.794,
      "step": 241400
    },
    {
      "epoch": 389.39,
      "learning_rate": 0.061076974406935484,
      "loss": 0.7904,
      "step": 241420
    },
    {
      "epoch": 389.42,
      "learning_rate": 0.06107374860370968,
      "loss": 0.8046,
      "step": 241440
    },
    {
      "epoch": 389.45,
      "learning_rate": 0.061070522800483876,
      "loss": 0.8207,
      "step": 241460
    },
    {
      "epoch": 389.48,
      "learning_rate": 0.061067296997258075,
      "loss": 0.8243,
      "step": 241480
    },
    {
      "epoch": 389.52,
      "learning_rate": 0.06106407119403226,
      "loss": 0.7916,
      "step": 241500
    },
    {
      "epoch": 389.55,
      "learning_rate": 0.06106084539080645,
      "loss": 0.8072,
      "step": 241520
    },
    {
      "epoch": 389.58,
      "learning_rate": 0.06105761958758065,
      "loss": 0.787,
      "step": 241540
    },
    {
      "epoch": 389.61,
      "learning_rate": 0.06105439378435484,
      "loss": 0.8006,
      "step": 241560
    },
    {
      "epoch": 389.65,
      "learning_rate": 0.06105116798112904,
      "loss": 0.8069,
      "step": 241580
    },
    {
      "epoch": 389.68,
      "learning_rate": 0.061047942177903214,
      "loss": 0.8012,
      "step": 241600
    },
    {
      "epoch": 389.71,
      "learning_rate": 0.06104471637467743,
      "loss": 0.8058,
      "step": 241620
    },
    {
      "epoch": 389.74,
      "learning_rate": 0.06104149057145161,
      "loss": 0.8281,
      "step": 241640
    },
    {
      "epoch": 389.77,
      "learning_rate": 0.06103826476822582,
      "loss": 0.8411,
      "step": 241660
    },
    {
      "epoch": 389.81,
      "learning_rate": 0.06103503896499999,
      "loss": 0.8221,
      "step": 241680
    },
    {
      "epoch": 389.84,
      "learning_rate": 0.061031813161774195,
      "loss": 0.796,
      "step": 241700
    },
    {
      "epoch": 389.87,
      "learning_rate": 0.06102858735854838,
      "loss": 0.8288,
      "step": 241720
    },
    {
      "epoch": 389.9,
      "learning_rate": 0.061025361555322594,
      "loss": 0.7844,
      "step": 241740
    },
    {
      "epoch": 389.94,
      "learning_rate": 0.06102213575209678,
      "loss": 0.7797,
      "step": 241760
    },
    {
      "epoch": 389.97,
      "learning_rate": 0.06101890994887097,
      "loss": 0.7944,
      "step": 241780
    },
    {
      "epoch": 390.0,
      "learning_rate": 0.061015684145645156,
      "loss": 0.7945,
      "step": 241800
    },
    {
      "epoch": 390.0,
      "eval_accuracy": {
        "accuracy": 0.7505268909530872
      },
      "eval_loss": 1.2036572694778442,
      "eval_runtime": 3.1624,
      "eval_samples_per_second": 4051.056,
      "eval_steps_per_second": 63.56,
      "step": 241800
    },
    {
      "epoch": 390.03,
      "learning_rate": 0.06101245834241936,
      "loss": 0.8344,
      "step": 241820
    },
    {
      "epoch": 390.06,
      "learning_rate": 0.06100923253919355,
      "loss": 0.8006,
      "step": 241840
    },
    {
      "epoch": 390.1,
      "learning_rate": 0.06100600673596775,
      "loss": 0.7865,
      "step": 241860
    },
    {
      "epoch": 390.13,
      "learning_rate": 0.061002780932741946,
      "loss": 0.789,
      "step": 241880
    },
    {
      "epoch": 390.16,
      "learning_rate": 0.06099955512951614,
      "loss": 0.7836,
      "step": 241900
    },
    {
      "epoch": 390.19,
      "learning_rate": 0.06099632932629032,
      "loss": 0.7724,
      "step": 241920
    },
    {
      "epoch": 390.23,
      "learning_rate": 0.06099310352306451,
      "loss": 0.7919,
      "step": 241940
    },
    {
      "epoch": 390.26,
      "learning_rate": 0.060989877719838714,
      "loss": 0.7794,
      "step": 241960
    },
    {
      "epoch": 390.29,
      "learning_rate": 0.0609866519166129,
      "loss": 0.8008,
      "step": 241980
    },
    {
      "epoch": 390.32,
      "learning_rate": 0.06098342611338711,
      "loss": 0.8111,
      "step": 242000
    },
    {
      "epoch": 390.35,
      "learning_rate": 0.0609802003101613,
      "loss": 0.7903,
      "step": 242020
    },
    {
      "epoch": 390.39,
      "learning_rate": 0.06097697450693549,
      "loss": 0.7848,
      "step": 242040
    },
    {
      "epoch": 390.42,
      "learning_rate": 0.060973748703709675,
      "loss": 0.7592,
      "step": 242060
    },
    {
      "epoch": 390.45,
      "learning_rate": 0.060970522900483874,
      "loss": 0.7963,
      "step": 242080
    },
    {
      "epoch": 390.48,
      "learning_rate": 0.060967297097258066,
      "loss": 0.8035,
      "step": 242100
    },
    {
      "epoch": 390.52,
      "learning_rate": 0.060964071294032265,
      "loss": 0.7835,
      "step": 242120
    },
    {
      "epoch": 390.55,
      "learning_rate": 0.060960845490806465,
      "loss": 0.7808,
      "step": 242140
    },
    {
      "epoch": 390.58,
      "learning_rate": 0.06095761968758065,
      "loss": 0.7965,
      "step": 242160
    },
    {
      "epoch": 390.61,
      "learning_rate": 0.06095439388435484,
      "loss": 0.814,
      "step": 242180
    },
    {
      "epoch": 390.65,
      "learning_rate": 0.06095116808112904,
      "loss": 0.8002,
      "step": 242200
    },
    {
      "epoch": 390.68,
      "learning_rate": 0.06094794227790323,
      "loss": 0.8132,
      "step": 242220
    },
    {
      "epoch": 390.71,
      "learning_rate": 0.06094471647467742,
      "loss": 0.7875,
      "step": 242240
    },
    {
      "epoch": 390.74,
      "learning_rate": 0.06094149067145163,
      "loss": 0.8085,
      "step": 242260
    },
    {
      "epoch": 390.77,
      "learning_rate": 0.0609382648682258,
      "loss": 0.7964,
      "step": 242280
    },
    {
      "epoch": 390.81,
      "learning_rate": 0.06093503906500001,
      "loss": 0.7823,
      "step": 242300
    },
    {
      "epoch": 390.84,
      "learning_rate": 0.060931813261774194,
      "loss": 0.8197,
      "step": 242320
    },
    {
      "epoch": 390.87,
      "learning_rate": 0.0609285874585484,
      "loss": 0.7874,
      "step": 242340
    },
    {
      "epoch": 390.9,
      "learning_rate": 0.060925361655322585,
      "loss": 0.8064,
      "step": 242360
    },
    {
      "epoch": 390.94,
      "learning_rate": 0.06092213585209677,
      "loss": 0.8429,
      "step": 242380
    },
    {
      "epoch": 390.97,
      "learning_rate": 0.06091891004887097,
      "loss": 0.8047,
      "step": 242400
    },
    {
      "epoch": 391.0,
      "learning_rate": 0.06091584553580645,
      "loss": 0.8189,
      "step": 242420
    },
    {
      "epoch": 391.0,
      "eval_accuracy": {
        "accuracy": 0.757161814066037
      },
      "eval_loss": 1.1266344785690308,
      "eval_runtime": 2.9365,
      "eval_samples_per_second": 4362.659,
      "eval_steps_per_second": 68.449,
      "step": 242420
    },
    {
      "epoch": 391.03,
      "learning_rate": 0.06091261973258066,
      "loss": 0.786,
      "step": 242440
    },
    {
      "epoch": 391.06,
      "learning_rate": 0.06090939392935483,
      "loss": 0.7935,
      "step": 242460
    },
    {
      "epoch": 391.1,
      "learning_rate": 0.060906168126129034,
      "loss": 0.7977,
      "step": 242480
    },
    {
      "epoch": 391.13,
      "learning_rate": 0.06090294232290322,
      "loss": 0.7977,
      "step": 242500
    },
    {
      "epoch": 391.16,
      "learning_rate": 0.06089971651967742,
      "loss": 0.7894,
      "step": 242520
    },
    {
      "epoch": 391.19,
      "learning_rate": 0.06089649071645162,
      "loss": 0.7686,
      "step": 242540
    },
    {
      "epoch": 391.23,
      "learning_rate": 0.06089326491322581,
      "loss": 0.7829,
      "step": 242560
    },
    {
      "epoch": 391.26,
      "learning_rate": 0.060890039109999995,
      "loss": 0.7984,
      "step": 242580
    },
    {
      "epoch": 391.29,
      "learning_rate": 0.0608868133067742,
      "loss": 0.7981,
      "step": 242600
    },
    {
      "epoch": 391.32,
      "learning_rate": 0.060883587503548386,
      "loss": 0.7866,
      "step": 242620
    },
    {
      "epoch": 391.35,
      "learning_rate": 0.060880361700322586,
      "loss": 0.7767,
      "step": 242640
    },
    {
      "epoch": 391.39,
      "learning_rate": 0.060877135897096785,
      "loss": 0.7674,
      "step": 242660
    },
    {
      "epoch": 391.42,
      "learning_rate": 0.06087391009387097,
      "loss": 0.761,
      "step": 242680
    },
    {
      "epoch": 391.45,
      "learning_rate": 0.06087068429064516,
      "loss": 0.7746,
      "step": 242700
    },
    {
      "epoch": 391.48,
      "learning_rate": 0.06086745848741935,
      "loss": 0.8173,
      "step": 242720
    },
    {
      "epoch": 391.52,
      "learning_rate": 0.06086423268419355,
      "loss": 0.8168,
      "step": 242740
    },
    {
      "epoch": 391.55,
      "learning_rate": 0.06086100688096774,
      "loss": 0.7894,
      "step": 242760
    },
    {
      "epoch": 391.58,
      "learning_rate": 0.06085778107774195,
      "loss": 0.7921,
      "step": 242780
    },
    {
      "epoch": 391.61,
      "learning_rate": 0.06085455527451614,
      "loss": 0.7841,
      "step": 242800
    },
    {
      "epoch": 391.65,
      "learning_rate": 0.06085132947129033,
      "loss": 0.794,
      "step": 242820
    },
    {
      "epoch": 391.68,
      "learning_rate": 0.060848103668064514,
      "loss": 0.8049,
      "step": 242840
    },
    {
      "epoch": 391.71,
      "learning_rate": 0.06084487786483871,
      "loss": 0.7972,
      "step": 242860
    },
    {
      "epoch": 391.74,
      "learning_rate": 0.060841652061612905,
      "loss": 0.7946,
      "step": 242880
    },
    {
      "epoch": 391.77,
      "learning_rate": 0.060838426258387104,
      "loss": 0.789,
      "step": 242900
    },
    {
      "epoch": 391.81,
      "learning_rate": 0.060835200455161303,
      "loss": 0.8059,
      "step": 242920
    },
    {
      "epoch": 391.84,
      "learning_rate": 0.06083197465193549,
      "loss": 0.8108,
      "step": 242940
    },
    {
      "epoch": 391.87,
      "learning_rate": 0.06082874884870968,
      "loss": 0.8274,
      "step": 242960
    },
    {
      "epoch": 391.9,
      "learning_rate": 0.060825523045483866,
      "loss": 0.8224,
      "step": 242980
    },
    {
      "epoch": 391.94,
      "learning_rate": 0.06082229724225807,
      "loss": 0.8058,
      "step": 243000
    },
    {
      "epoch": 391.97,
      "learning_rate": 0.06081907143903226,
      "loss": 0.7931,
      "step": 243020
    },
    {
      "epoch": 392.0,
      "learning_rate": 0.06081584563580647,
      "loss": 0.7946,
      "step": 243040
    },
    {
      "epoch": 392.0,
      "eval_accuracy": {
        "accuracy": 0.7483412692217626
      },
      "eval_loss": 1.195777416229248,
      "eval_runtime": 3.7527,
      "eval_samples_per_second": 3413.823,
      "eval_steps_per_second": 53.562,
      "step": 243040
    },
    {
      "epoch": 392.03,
      "learning_rate": 0.06081261983258064,
      "loss": 0.8315,
      "step": 243060
    },
    {
      "epoch": 392.06,
      "learning_rate": 0.06080939402935485,
      "loss": 0.7812,
      "step": 243080
    },
    {
      "epoch": 392.1,
      "learning_rate": 0.06080616822612903,
      "loss": 0.7906,
      "step": 243100
    },
    {
      "epoch": 392.13,
      "learning_rate": 0.06080294242290324,
      "loss": 0.8104,
      "step": 243120
    },
    {
      "epoch": 392.16,
      "learning_rate": 0.060799716619677424,
      "loss": 0.7959,
      "step": 243140
    },
    {
      "epoch": 392.19,
      "learning_rate": 0.06079649081645161,
      "loss": 0.7993,
      "step": 243160
    },
    {
      "epoch": 392.23,
      "learning_rate": 0.06079326501322581,
      "loss": 0.7748,
      "step": 243180
    },
    {
      "epoch": 392.26,
      "learning_rate": 0.06079003921000001,
      "loss": 0.7792,
      "step": 243200
    },
    {
      "epoch": 392.29,
      "learning_rate": 0.0607868134067742,
      "loss": 0.7672,
      "step": 243220
    },
    {
      "epoch": 392.32,
      "learning_rate": 0.060783587603548385,
      "loss": 0.8009,
      "step": 243240
    },
    {
      "epoch": 392.35,
      "learning_rate": 0.060780361800322584,
      "loss": 0.7832,
      "step": 243260
    },
    {
      "epoch": 392.39,
      "learning_rate": 0.060777135997096776,
      "loss": 0.7921,
      "step": 243280
    },
    {
      "epoch": 392.42,
      "learning_rate": 0.060773910193870975,
      "loss": 0.798,
      "step": 243300
    },
    {
      "epoch": 392.45,
      "learning_rate": 0.06077068439064516,
      "loss": 0.7989,
      "step": 243320
    },
    {
      "epoch": 392.48,
      "learning_rate": 0.060767458587419367,
      "loss": 0.8128,
      "step": 243340
    },
    {
      "epoch": 392.52,
      "learning_rate": 0.060764232784193545,
      "loss": 0.7772,
      "step": 243360
    },
    {
      "epoch": 392.55,
      "learning_rate": 0.06076100698096775,
      "loss": 0.8214,
      "step": 243380
    },
    {
      "epoch": 392.58,
      "learning_rate": 0.060757781177741936,
      "loss": 0.8111,
      "step": 243400
    },
    {
      "epoch": 392.61,
      "learning_rate": 0.06075455537451614,
      "loss": 0.8132,
      "step": 243420
    },
    {
      "epoch": 392.65,
      "learning_rate": 0.06075132957129033,
      "loss": 0.79,
      "step": 243440
    },
    {
      "epoch": 392.68,
      "learning_rate": 0.060748103768064526,
      "loss": 0.7758,
      "step": 243460
    },
    {
      "epoch": 392.71,
      "learning_rate": 0.06074487796483871,
      "loss": 0.7946,
      "step": 243480
    },
    {
      "epoch": 392.74,
      "learning_rate": 0.060741652161612904,
      "loss": 0.7938,
      "step": 243500
    },
    {
      "epoch": 392.77,
      "learning_rate": 0.0607384263583871,
      "loss": 0.8184,
      "step": 243520
    },
    {
      "epoch": 392.81,
      "learning_rate": 0.060735200555161295,
      "loss": 0.8008,
      "step": 243540
    },
    {
      "epoch": 392.84,
      "learning_rate": 0.06073197475193548,
      "loss": 0.8186,
      "step": 243560
    },
    {
      "epoch": 392.87,
      "learning_rate": 0.06072874894870969,
      "loss": 0.8206,
      "step": 243580
    },
    {
      "epoch": 392.9,
      "learning_rate": 0.06072552314548388,
      "loss": 0.7917,
      "step": 243600
    },
    {
      "epoch": 392.94,
      "learning_rate": 0.060722297342258064,
      "loss": 0.8107,
      "step": 243620
    },
    {
      "epoch": 392.97,
      "learning_rate": 0.06071907153903227,
      "loss": 0.8018,
      "step": 243640
    },
    {
      "epoch": 393.0,
      "learning_rate": 0.06071584573580644,
      "loss": 0.8048,
      "step": 243660
    },
    {
      "epoch": 393.0,
      "eval_accuracy": {
        "accuracy": 0.7512294122238701
      },
      "eval_loss": 1.1901061534881592,
      "eval_runtime": 2.939,
      "eval_samples_per_second": 4358.969,
      "eval_steps_per_second": 68.391,
      "step": 243660
    },
    {
      "epoch": 393.03,
      "learning_rate": 0.06071261993258065,
      "loss": 0.8193,
      "step": 243680
    },
    {
      "epoch": 393.06,
      "learning_rate": 0.06070939412935483,
      "loss": 0.7851,
      "step": 243700
    },
    {
      "epoch": 393.1,
      "learning_rate": 0.060706168326129045,
      "loss": 0.7621,
      "step": 243720
    },
    {
      "epoch": 393.13,
      "learning_rate": 0.06070294252290323,
      "loss": 0.8021,
      "step": 243740
    },
    {
      "epoch": 393.16,
      "learning_rate": 0.06069971671967742,
      "loss": 0.7825,
      "step": 243760
    },
    {
      "epoch": 393.19,
      "learning_rate": 0.06069649091645161,
      "loss": 0.7704,
      "step": 243780
    },
    {
      "epoch": 393.23,
      "learning_rate": 0.06069326511322581,
      "loss": 0.774,
      "step": 243800
    },
    {
      "epoch": 393.26,
      "learning_rate": 0.06069003931,
      "loss": 0.7899,
      "step": 243820
    },
    {
      "epoch": 393.29,
      "learning_rate": 0.0606868135067742,
      "loss": 0.798,
      "step": 243840
    },
    {
      "epoch": 393.32,
      "learning_rate": 0.0606835877035484,
      "loss": 0.7764,
      "step": 243860
    },
    {
      "epoch": 393.35,
      "learning_rate": 0.06068036190032259,
      "loss": 0.7995,
      "step": 243880
    },
    {
      "epoch": 393.39,
      "learning_rate": 0.060677136097096775,
      "loss": 0.8195,
      "step": 243900
    },
    {
      "epoch": 393.42,
      "learning_rate": 0.06067391029387096,
      "loss": 0.781,
      "step": 243920
    },
    {
      "epoch": 393.45,
      "learning_rate": 0.060670684490645166,
      "loss": 0.7924,
      "step": 243940
    },
    {
      "epoch": 393.48,
      "learning_rate": 0.06066745868741935,
      "loss": 0.801,
      "step": 243960
    },
    {
      "epoch": 393.52,
      "learning_rate": 0.060664232884193564,
      "loss": 0.7861,
      "step": 243980
    },
    {
      "epoch": 393.55,
      "learning_rate": 0.06066100708096775,
      "loss": 0.7857,
      "step": 244000
    },
    {
      "epoch": 393.58,
      "learning_rate": 0.06065778127774194,
      "loss": 0.818,
      "step": 244020
    },
    {
      "epoch": 393.61,
      "learning_rate": 0.06065455547451613,
      "loss": 0.8078,
      "step": 244040
    },
    {
      "epoch": 393.65,
      "learning_rate": 0.06065132967129033,
      "loss": 0.8186,
      "step": 244060
    },
    {
      "epoch": 393.68,
      "learning_rate": 0.06064810386806452,
      "loss": 0.8076,
      "step": 244080
    },
    {
      "epoch": 393.71,
      "learning_rate": 0.0606448780648387,
      "loss": 0.8114,
      "step": 244100
    },
    {
      "epoch": 393.74,
      "learning_rate": 0.060641652261612916,
      "loss": 0.7979,
      "step": 244120
    },
    {
      "epoch": 393.77,
      "learning_rate": 0.0606384264583871,
      "loss": 0.7846,
      "step": 244140
    },
    {
      "epoch": 393.81,
      "learning_rate": 0.060635200655161293,
      "loss": 0.8291,
      "step": 244160
    },
    {
      "epoch": 393.84,
      "learning_rate": 0.06063197485193549,
      "loss": 0.814,
      "step": 244180
    },
    {
      "epoch": 393.87,
      "learning_rate": 0.060628749048709685,
      "loss": 0.7799,
      "step": 244200
    },
    {
      "epoch": 393.9,
      "learning_rate": 0.06062552324548387,
      "loss": 0.7705,
      "step": 244220
    },
    {
      "epoch": 393.94,
      "learning_rate": 0.06062229744225807,
      "loss": 0.7941,
      "step": 244240
    },
    {
      "epoch": 393.97,
      "learning_rate": 0.060619071639032254,
      "loss": 0.8116,
      "step": 244260
    },
    {
      "epoch": 394.0,
      "learning_rate": 0.06061584583580646,
      "loss": 0.8478,
      "step": 244280
    },
    {
      "epoch": 394.0,
      "eval_accuracy": {
        "accuracy": 0.7534930918741707
      },
      "eval_loss": 1.194217324256897,
      "eval_runtime": 2.7726,
      "eval_samples_per_second": 4620.554,
      "eval_steps_per_second": 72.495,
      "step": 244280
    },
    {
      "epoch": 394.03,
      "learning_rate": 0.060612620032580646,
      "loss": 0.8326,
      "step": 244300
    },
    {
      "epoch": 394.06,
      "learning_rate": 0.06060939422935485,
      "loss": 0.799,
      "step": 244320
    },
    {
      "epoch": 394.1,
      "learning_rate": 0.06060616842612903,
      "loss": 0.7917,
      "step": 244340
    },
    {
      "epoch": 394.13,
      "learning_rate": 0.060602942622903236,
      "loss": 0.7824,
      "step": 244360
    },
    {
      "epoch": 394.16,
      "learning_rate": 0.06059971681967742,
      "loss": 0.7934,
      "step": 244380
    },
    {
      "epoch": 394.19,
      "learning_rate": 0.06059649101645162,
      "loss": 0.8072,
      "step": 244400
    },
    {
      "epoch": 394.23,
      "learning_rate": 0.06059326521322581,
      "loss": 0.7904,
      "step": 244420
    },
    {
      "epoch": 394.26,
      "learning_rate": 0.06059003941,
      "loss": 0.809,
      "step": 244440
    },
    {
      "epoch": 394.29,
      "learning_rate": 0.0605868136067742,
      "loss": 0.802,
      "step": 244460
    },
    {
      "epoch": 394.32,
      "learning_rate": 0.06058358780354839,
      "loss": 0.7803,
      "step": 244480
    },
    {
      "epoch": 394.35,
      "learning_rate": 0.06058036200032259,
      "loss": 0.7793,
      "step": 244500
    },
    {
      "epoch": 394.39,
      "learning_rate": 0.06057713619709679,
      "loss": 0.8075,
      "step": 244520
    },
    {
      "epoch": 394.42,
      "learning_rate": 0.06057391039387097,
      "loss": 0.7824,
      "step": 244540
    },
    {
      "epoch": 394.45,
      "learning_rate": 0.06057068459064516,
      "loss": 0.7773,
      "step": 244560
    },
    {
      "epoch": 394.48,
      "learning_rate": 0.06056745878741936,
      "loss": 0.7801,
      "step": 244580
    },
    {
      "epoch": 394.52,
      "learning_rate": 0.06056423298419355,
      "loss": 0.8232,
      "step": 244600
    },
    {
      "epoch": 394.55,
      "learning_rate": 0.060561007180967755,
      "loss": 0.8152,
      "step": 244620
    },
    {
      "epoch": 394.58,
      "learning_rate": 0.060557781377741926,
      "loss": 0.7919,
      "step": 244640
    },
    {
      "epoch": 394.61,
      "learning_rate": 0.06055455557451614,
      "loss": 0.7795,
      "step": 244660
    },
    {
      "epoch": 394.65,
      "learning_rate": 0.060551329771290324,
      "loss": 0.7885,
      "step": 244680
    },
    {
      "epoch": 394.68,
      "learning_rate": 0.060548103968064516,
      "loss": 0.7961,
      "step": 244700
    },
    {
      "epoch": 394.71,
      "learning_rate": 0.060544878164838715,
      "loss": 0.7683,
      "step": 244720
    },
    {
      "epoch": 394.74,
      "learning_rate": 0.06054165236161291,
      "loss": 0.8018,
      "step": 244740
    },
    {
      "epoch": 394.77,
      "learning_rate": 0.06053842655838709,
      "loss": 0.7977,
      "step": 244760
    },
    {
      "epoch": 394.81,
      "learning_rate": 0.06053520075516129,
      "loss": 0.7858,
      "step": 244780
    },
    {
      "epoch": 394.84,
      "learning_rate": 0.06053197495193549,
      "loss": 0.8136,
      "step": 244800
    },
    {
      "epoch": 394.87,
      "learning_rate": 0.06052874914870968,
      "loss": 0.7979,
      "step": 244820
    },
    {
      "epoch": 394.9,
      "learning_rate": 0.06052552334548387,
      "loss": 0.7954,
      "step": 244840
    },
    {
      "epoch": 394.94,
      "learning_rate": 0.060522297542258054,
      "loss": 0.7926,
      "step": 244860
    },
    {
      "epoch": 394.97,
      "learning_rate": 0.06051907173903226,
      "loss": 0.8011,
      "step": 244880
    },
    {
      "epoch": 395.0,
      "learning_rate": 0.060516007225967755,
      "loss": 0.8034,
      "step": 244900
    },
    {
      "epoch": 395.0,
      "eval_accuracy": {
        "accuracy": 0.7620794629615174
      },
      "eval_loss": 1.1375759840011597,
      "eval_runtime": 2.946,
      "eval_samples_per_second": 4348.617,
      "eval_steps_per_second": 68.228,
      "step": 244900
    },
    {
      "epoch": 395.03,
      "learning_rate": 0.06051278142274194,
      "loss": 0.8044,
      "step": 244920
    },
    {
      "epoch": 395.06,
      "learning_rate": 0.06050955561951613,
      "loss": 0.788,
      "step": 244940
    },
    {
      "epoch": 395.1,
      "learning_rate": 0.06050632981629033,
      "loss": 0.7818,
      "step": 244960
    },
    {
      "epoch": 395.13,
      "learning_rate": 0.060503104013064524,
      "loss": 0.783,
      "step": 244980
    },
    {
      "epoch": 395.16,
      "learning_rate": 0.06049987820983871,
      "loss": 0.77,
      "step": 245000
    },
    {
      "epoch": 395.19,
      "learning_rate": 0.06049665240661292,
      "loss": 0.7843,
      "step": 245020
    },
    {
      "epoch": 395.23,
      "learning_rate": 0.06049342660338709,
      "loss": 0.7982,
      "step": 245040
    },
    {
      "epoch": 395.26,
      "learning_rate": 0.0604902008001613,
      "loss": 0.7978,
      "step": 245060
    },
    {
      "epoch": 395.29,
      "learning_rate": 0.060486974996935484,
      "loss": 0.7846,
      "step": 245080
    },
    {
      "epoch": 395.32,
      "learning_rate": 0.06048374919370969,
      "loss": 0.7846,
      "step": 245100
    },
    {
      "epoch": 395.35,
      "learning_rate": 0.06048052339048387,
      "loss": 0.8028,
      "step": 245120
    },
    {
      "epoch": 395.39,
      "learning_rate": 0.060477297587258075,
      "loss": 0.7961,
      "step": 245140
    },
    {
      "epoch": 395.42,
      "learning_rate": 0.06047407178403226,
      "loss": 0.7844,
      "step": 245160
    },
    {
      "epoch": 395.45,
      "learning_rate": 0.06047084598080646,
      "loss": 0.7645,
      "step": 245180
    },
    {
      "epoch": 395.48,
      "learning_rate": 0.06046762017758065,
      "loss": 0.8173,
      "step": 245200
    },
    {
      "epoch": 395.52,
      "learning_rate": 0.060464394374354836,
      "loss": 0.8125,
      "step": 245220
    },
    {
      "epoch": 395.55,
      "learning_rate": 0.060461168571129036,
      "loss": 0.7969,
      "step": 245240
    },
    {
      "epoch": 395.58,
      "learning_rate": 0.06045794276790323,
      "loss": 0.7867,
      "step": 245260
    },
    {
      "epoch": 395.61,
      "learning_rate": 0.06045471696467743,
      "loss": 0.7907,
      "step": 245280
    },
    {
      "epoch": 395.65,
      "learning_rate": 0.06045149116145161,
      "loss": 0.7789,
      "step": 245300
    },
    {
      "epoch": 395.68,
      "learning_rate": 0.06044826535822581,
      "loss": 0.7777,
      "step": 245320
    },
    {
      "epoch": 395.71,
      "learning_rate": 0.060445039554999996,
      "loss": 0.779,
      "step": 245340
    },
    {
      "epoch": 395.74,
      "learning_rate": 0.0604418137517742,
      "loss": 0.7917,
      "step": 245360
    },
    {
      "epoch": 395.77,
      "learning_rate": 0.06043858794854839,
      "loss": 0.8005,
      "step": 245380
    },
    {
      "epoch": 395.81,
      "learning_rate": 0.060435362145322594,
      "loss": 0.8071,
      "step": 245400
    },
    {
      "epoch": 395.84,
      "learning_rate": 0.060432136342096765,
      "loss": 0.807,
      "step": 245420
    },
    {
      "epoch": 395.87,
      "learning_rate": 0.06042891053887098,
      "loss": 0.783,
      "step": 245440
    },
    {
      "epoch": 395.9,
      "learning_rate": 0.06042568473564516,
      "loss": 0.8077,
      "step": 245460
    },
    {
      "epoch": 395.94,
      "learning_rate": 0.060422458932419355,
      "loss": 0.802,
      "step": 245480
    },
    {
      "epoch": 395.97,
      "learning_rate": 0.060419233129193554,
      "loss": 0.8145,
      "step": 245500
    },
    {
      "epoch": 396.0,
      "learning_rate": 0.06041600732596775,
      "loss": 0.8536,
      "step": 245520
    },
    {
      "epoch": 396.0,
      "eval_accuracy": {
        "accuracy": 0.7482632113027866
      },
      "eval_loss": 1.2286553382873535,
      "eval_runtime": 2.7861,
      "eval_samples_per_second": 4598.116,
      "eval_steps_per_second": 72.143,
      "step": 245520
    },
    {
      "epoch": 396.03,
      "learning_rate": 0.06041278152274193,
      "loss": 0.8355,
      "step": 245540
    },
    {
      "epoch": 396.06,
      "learning_rate": 0.060409555719516145,
      "loss": 0.7828,
      "step": 245560
    },
    {
      "epoch": 396.1,
      "learning_rate": 0.06040632991629033,
      "loss": 0.7743,
      "step": 245580
    },
    {
      "epoch": 396.13,
      "learning_rate": 0.06040310411306452,
      "loss": 0.7901,
      "step": 245600
    },
    {
      "epoch": 396.16,
      "learning_rate": 0.06039987830983871,
      "loss": 0.7859,
      "step": 245620
    },
    {
      "epoch": 396.19,
      "learning_rate": 0.06039665250661289,
      "loss": 0.7849,
      "step": 245640
    },
    {
      "epoch": 396.23,
      "learning_rate": 0.0603934267033871,
      "loss": 0.7924,
      "step": 245660
    },
    {
      "epoch": 396.26,
      "learning_rate": 0.060390200900161284,
      "loss": 0.7752,
      "step": 245680
    },
    {
      "epoch": 396.29,
      "learning_rate": 0.0603869750969355,
      "loss": 0.7813,
      "step": 245700
    },
    {
      "epoch": 396.32,
      "learning_rate": 0.06038374929370968,
      "loss": 0.7774,
      "step": 245720
    },
    {
      "epoch": 396.35,
      "learning_rate": 0.060380523490483874,
      "loss": 0.7827,
      "step": 245740
    },
    {
      "epoch": 396.39,
      "learning_rate": 0.06037729768725806,
      "loss": 0.7974,
      "step": 245760
    },
    {
      "epoch": 396.42,
      "learning_rate": 0.06037407188403226,
      "loss": 0.7944,
      "step": 245780
    },
    {
      "epoch": 396.45,
      "learning_rate": 0.06037084608080645,
      "loss": 0.798,
      "step": 245800
    },
    {
      "epoch": 396.48,
      "learning_rate": 0.06036762027758065,
      "loss": 0.8097,
      "step": 245820
    },
    {
      "epoch": 396.52,
      "learning_rate": 0.06036439447435485,
      "loss": 0.8007,
      "step": 245840
    },
    {
      "epoch": 396.55,
      "learning_rate": 0.060361168671129034,
      "loss": 0.8028,
      "step": 245860
    },
    {
      "epoch": 396.58,
      "learning_rate": 0.060357942867903226,
      "loss": 0.7968,
      "step": 245880
    },
    {
      "epoch": 396.61,
      "learning_rate": 0.060354717064677425,
      "loss": 0.8011,
      "step": 245900
    },
    {
      "epoch": 396.65,
      "learning_rate": 0.06035149126145162,
      "loss": 0.7839,
      "step": 245920
    },
    {
      "epoch": 396.68,
      "learning_rate": 0.0603482654582258,
      "loss": 0.802,
      "step": 245940
    },
    {
      "epoch": 396.71,
      "learning_rate": 0.060345039655000016,
      "loss": 0.8063,
      "step": 245960
    },
    {
      "epoch": 396.74,
      "learning_rate": 0.0603418138517742,
      "loss": 0.8264,
      "step": 245980
    },
    {
      "epoch": 396.77,
      "learning_rate": 0.06033858804854839,
      "loss": 0.8182,
      "step": 246000
    },
    {
      "epoch": 396.81,
      "learning_rate": 0.06033536224532258,
      "loss": 0.805,
      "step": 246020
    },
    {
      "epoch": 396.84,
      "learning_rate": 0.060332136442096784,
      "loss": 0.7934,
      "step": 246040
    },
    {
      "epoch": 396.87,
      "learning_rate": 0.06032891063887097,
      "loss": 0.8007,
      "step": 246060
    },
    {
      "epoch": 396.9,
      "learning_rate": 0.060325684835645155,
      "loss": 0.7873,
      "step": 246080
    },
    {
      "epoch": 396.94,
      "learning_rate": 0.06032245903241937,
      "loss": 0.7945,
      "step": 246100
    },
    {
      "epoch": 396.97,
      "learning_rate": 0.06031923322919355,
      "loss": 0.8081,
      "step": 246120
    },
    {
      "epoch": 397.0,
      "learning_rate": 0.060316007425967745,
      "loss": 0.787,
      "step": 246140
    },
    {
      "epoch": 397.0,
      "eval_accuracy": {
        "accuracy": 0.7581765670127234
      },
      "eval_loss": 1.1605762243270874,
      "eval_runtime": 2.8029,
      "eval_samples_per_second": 4570.701,
      "eval_steps_per_second": 71.713,
      "step": 246140
    },
    {
      "epoch": 397.03,
      "learning_rate": 0.06031278162274193,
      "loss": 0.7757,
      "step": 246160
    },
    {
      "epoch": 397.06,
      "learning_rate": 0.060309555819516136,
      "loss": 0.7684,
      "step": 246180
    },
    {
      "epoch": 397.1,
      "learning_rate": 0.06030633001629032,
      "loss": 0.7728,
      "step": 246200
    },
    {
      "epoch": 397.13,
      "learning_rate": 0.06030310421306452,
      "loss": 0.7642,
      "step": 246220
    },
    {
      "epoch": 397.16,
      "learning_rate": 0.060299878409838706,
      "loss": 0.7771,
      "step": 246240
    },
    {
      "epoch": 397.19,
      "learning_rate": 0.06029665260661291,
      "loss": 0.7854,
      "step": 246260
    },
    {
      "epoch": 397.23,
      "learning_rate": 0.0602934268033871,
      "loss": 0.7897,
      "step": 246280
    },
    {
      "epoch": 397.26,
      "learning_rate": 0.0602902010001613,
      "loss": 0.7776,
      "step": 246300
    },
    {
      "epoch": 397.29,
      "learning_rate": 0.06028697519693548,
      "loss": 0.7865,
      "step": 246320
    },
    {
      "epoch": 397.32,
      "learning_rate": 0.06028374939370969,
      "loss": 0.7928,
      "step": 246340
    },
    {
      "epoch": 397.35,
      "learning_rate": 0.06028052359048387,
      "loss": 0.8088,
      "step": 246360
    },
    {
      "epoch": 397.39,
      "learning_rate": 0.06027729778725808,
      "loss": 0.8175,
      "step": 246380
    },
    {
      "epoch": 397.42,
      "learning_rate": 0.06027407198403226,
      "loss": 0.8162,
      "step": 246400
    },
    {
      "epoch": 397.45,
      "learning_rate": 0.06027084618080645,
      "loss": 0.799,
      "step": 246420
    },
    {
      "epoch": 397.48,
      "learning_rate": 0.06026762037758065,
      "loss": 0.7954,
      "step": 246440
    },
    {
      "epoch": 397.52,
      "learning_rate": 0.06026439457435484,
      "loss": 0.777,
      "step": 246460
    },
    {
      "epoch": 397.55,
      "learning_rate": 0.06026116877112904,
      "loss": 0.797,
      "step": 246480
    },
    {
      "epoch": 397.58,
      "learning_rate": 0.06025794296790324,
      "loss": 0.7867,
      "step": 246500
    },
    {
      "epoch": 397.61,
      "learning_rate": 0.060254717164677424,
      "loss": 0.7686,
      "step": 246520
    },
    {
      "epoch": 397.65,
      "learning_rate": 0.060251491361451616,
      "loss": 0.7814,
      "step": 246540
    },
    {
      "epoch": 397.68,
      "learning_rate": 0.060248265558225815,
      "loss": 0.7861,
      "step": 246560
    },
    {
      "epoch": 397.71,
      "learning_rate": 0.060245039755,
      "loss": 0.8004,
      "step": 246580
    },
    {
      "epoch": 397.74,
      "learning_rate": 0.060241813951774206,
      "loss": 0.795,
      "step": 246600
    },
    {
      "epoch": 397.77,
      "learning_rate": 0.06023858814854838,
      "loss": 0.7927,
      "step": 246620
    },
    {
      "epoch": 397.81,
      "learning_rate": 0.06023536234532259,
      "loss": 0.7934,
      "step": 246640
    },
    {
      "epoch": 397.84,
      "learning_rate": 0.060232136542096776,
      "loss": 0.7663,
      "step": 246660
    },
    {
      "epoch": 397.87,
      "learning_rate": 0.06022891073887098,
      "loss": 0.7787,
      "step": 246680
    },
    {
      "epoch": 397.9,
      "learning_rate": 0.06022568493564515,
      "loss": 0.7962,
      "step": 246700
    },
    {
      "epoch": 397.94,
      "learning_rate": 0.06022245913241936,
      "loss": 0.7921,
      "step": 246720
    },
    {
      "epoch": 397.97,
      "learning_rate": 0.060219233329193544,
      "loss": 0.7874,
      "step": 246740
    },
    {
      "epoch": 398.0,
      "learning_rate": 0.060216007525967744,
      "loss": 0.803,
      "step": 246760
    },
    {
      "epoch": 398.0,
      "eval_accuracy": {
        "accuracy": 0.7542736710639294
      },
      "eval_loss": 1.1524351835250854,
      "eval_runtime": 2.8224,
      "eval_samples_per_second": 4539.108,
      "eval_steps_per_second": 71.217,
      "step": 246760
    },
    {
      "epoch": 398.03,
      "learning_rate": 0.06021278172274194,
      "loss": 0.8096,
      "step": 246780
    },
    {
      "epoch": 398.06,
      "learning_rate": 0.060209555919516135,
      "loss": 0.7817,
      "step": 246800
    },
    {
      "epoch": 398.1,
      "learning_rate": 0.06020633011629032,
      "loss": 0.7599,
      "step": 246820
    },
    {
      "epoch": 398.13,
      "learning_rate": 0.060203104313064526,
      "loss": 0.767,
      "step": 246840
    },
    {
      "epoch": 398.16,
      "learning_rate": 0.06019987850983871,
      "loss": 0.761,
      "step": 246860
    },
    {
      "epoch": 398.19,
      "learning_rate": 0.060196652706612896,
      "loss": 0.7788,
      "step": 246880
    },
    {
      "epoch": 398.23,
      "learning_rate": 0.06019342690338711,
      "loss": 0.7782,
      "step": 246900
    },
    {
      "epoch": 398.26,
      "learning_rate": 0.060190201100161295,
      "loss": 0.7853,
      "step": 246920
    },
    {
      "epoch": 398.29,
      "learning_rate": 0.06018697529693549,
      "loss": 0.7626,
      "step": 246940
    },
    {
      "epoch": 398.32,
      "learning_rate": 0.06018374949370967,
      "loss": 0.7525,
      "step": 246960
    },
    {
      "epoch": 398.35,
      "learning_rate": 0.06018052369048388,
      "loss": 0.799,
      "step": 246980
    },
    {
      "epoch": 398.39,
      "learning_rate": 0.06017729788725806,
      "loss": 0.797,
      "step": 247000
    },
    {
      "epoch": 398.42,
      "learning_rate": 0.06017407208403226,
      "loss": 0.8148,
      "step": 247020
    },
    {
      "epoch": 398.45,
      "learning_rate": 0.06017084628080646,
      "loss": 0.8038,
      "step": 247040
    },
    {
      "epoch": 398.48,
      "learning_rate": 0.06016762047758065,
      "loss": 0.8108,
      "step": 247060
    },
    {
      "epoch": 398.52,
      "learning_rate": 0.06016439467435484,
      "loss": 0.7958,
      "step": 247080
    },
    {
      "epoch": 398.55,
      "learning_rate": 0.06016116887112904,
      "loss": 0.8099,
      "step": 247100
    },
    {
      "epoch": 398.58,
      "learning_rate": 0.06015794306790323,
      "loss": 0.8051,
      "step": 247120
    },
    {
      "epoch": 398.61,
      "learning_rate": 0.060154717264677415,
      "loss": 0.7959,
      "step": 247140
    },
    {
      "epoch": 398.65,
      "learning_rate": 0.06015149146145163,
      "loss": 0.7714,
      "step": 247160
    },
    {
      "epoch": 398.68,
      "learning_rate": 0.060148265658225814,
      "loss": 0.7915,
      "step": 247180
    },
    {
      "epoch": 398.71,
      "learning_rate": 0.060145039855000006,
      "loss": 0.7918,
      "step": 247200
    },
    {
      "epoch": 398.74,
      "learning_rate": 0.06014181405177419,
      "loss": 0.7649,
      "step": 247220
    },
    {
      "epoch": 398.77,
      "learning_rate": 0.0601385882485484,
      "loss": 0.7876,
      "step": 247240
    },
    {
      "epoch": 398.81,
      "learning_rate": 0.06013536244532258,
      "loss": 0.8124,
      "step": 247260
    },
    {
      "epoch": 398.84,
      "learning_rate": 0.060132136642096795,
      "loss": 0.8162,
      "step": 247280
    },
    {
      "epoch": 398.87,
      "learning_rate": 0.060128910838870966,
      "loss": 0.8032,
      "step": 247300
    },
    {
      "epoch": 398.9,
      "learning_rate": 0.06012568503564517,
      "loss": 0.8173,
      "step": 247320
    },
    {
      "epoch": 398.94,
      "learning_rate": 0.06012245923241936,
      "loss": 0.7999,
      "step": 247340
    },
    {
      "epoch": 398.97,
      "learning_rate": 0.06011923342919354,
      "loss": 0.7859,
      "step": 247360
    },
    {
      "epoch": 399.0,
      "learning_rate": 0.060116168916129045,
      "loss": 0.8027,
      "step": 247380
    },
    {
      "epoch": 399.0,
      "eval_accuracy": {
        "accuracy": 0.75786433533682
      },
      "eval_loss": 1.1334415674209595,
      "eval_runtime": 2.8725,
      "eval_samples_per_second": 4459.839,
      "eval_steps_per_second": 69.973,
      "step": 247380
    },
    {
      "epoch": 399.03,
      "learning_rate": 0.06011294311290322,
      "loss": 0.7814,
      "step": 247400
    },
    {
      "epoch": 399.06,
      "learning_rate": 0.06010971730967743,
      "loss": 0.7821,
      "step": 247420
    },
    {
      "epoch": 399.1,
      "learning_rate": 0.060106491506451615,
      "loss": 0.7869,
      "step": 247440
    },
    {
      "epoch": 399.13,
      "learning_rate": 0.06010326570322582,
      "loss": 0.7814,
      "step": 247460
    },
    {
      "epoch": 399.16,
      "learning_rate": 0.06010003989999999,
      "loss": 0.7901,
      "step": 247480
    },
    {
      "epoch": 399.19,
      "learning_rate": 0.0600968140967742,
      "loss": 0.7783,
      "step": 247500
    },
    {
      "epoch": 399.23,
      "learning_rate": 0.06009358829354838,
      "loss": 0.792,
      "step": 247520
    },
    {
      "epoch": 399.26,
      "learning_rate": 0.06009036249032258,
      "loss": 0.7769,
      "step": 247540
    },
    {
      "epoch": 399.29,
      "learning_rate": 0.06008713668709678,
      "loss": 0.7883,
      "step": 247560
    },
    {
      "epoch": 399.32,
      "learning_rate": 0.060083910883870974,
      "loss": 0.7741,
      "step": 247580
    },
    {
      "epoch": 399.35,
      "learning_rate": 0.06008068508064516,
      "loss": 0.7703,
      "step": 247600
    },
    {
      "epoch": 399.39,
      "learning_rate": 0.060077459277419344,
      "loss": 0.7802,
      "step": 247620
    },
    {
      "epoch": 399.42,
      "learning_rate": 0.06007423347419355,
      "loss": 0.8086,
      "step": 247640
    },
    {
      "epoch": 399.45,
      "learning_rate": 0.060071007670967735,
      "loss": 0.7821,
      "step": 247660
    },
    {
      "epoch": 399.48,
      "learning_rate": 0.06006778186774195,
      "loss": 0.7775,
      "step": 247680
    },
    {
      "epoch": 399.52,
      "learning_rate": 0.060064556064516134,
      "loss": 0.7741,
      "step": 247700
    },
    {
      "epoch": 399.55,
      "learning_rate": 0.060061330261290326,
      "loss": 0.767,
      "step": 247720
    },
    {
      "epoch": 399.58,
      "learning_rate": 0.06005810445806451,
      "loss": 0.7784,
      "step": 247740
    },
    {
      "epoch": 399.61,
      "learning_rate": 0.06005487865483872,
      "loss": 0.8192,
      "step": 247760
    },
    {
      "epoch": 399.65,
      "learning_rate": 0.0600516528516129,
      "loss": 0.8047,
      "step": 247780
    },
    {
      "epoch": 399.68,
      "learning_rate": 0.0600484270483871,
      "loss": 0.7944,
      "step": 247800
    },
    {
      "epoch": 399.71,
      "learning_rate": 0.0600452012451613,
      "loss": 0.7725,
      "step": 247820
    },
    {
      "epoch": 399.74,
      "learning_rate": 0.060041975441935486,
      "loss": 0.8196,
      "step": 247840
    },
    {
      "epoch": 399.77,
      "learning_rate": 0.06003874963870968,
      "loss": 0.8025,
      "step": 247860
    },
    {
      "epoch": 399.81,
      "learning_rate": 0.06003552383548388,
      "loss": 0.8081,
      "step": 247880
    },
    {
      "epoch": 399.84,
      "learning_rate": 0.06003229803225807,
      "loss": 0.8045,
      "step": 247900
    },
    {
      "epoch": 399.87,
      "learning_rate": 0.06002907222903227,
      "loss": 0.8106,
      "step": 247920
    },
    {
      "epoch": 399.9,
      "learning_rate": 0.06002584642580647,
      "loss": 0.7917,
      "step": 247940
    },
    {
      "epoch": 399.94,
      "learning_rate": 0.06002262062258065,
      "loss": 0.7869,
      "step": 247960
    },
    {
      "epoch": 399.97,
      "learning_rate": 0.060019394819354845,
      "loss": 0.8058,
      "step": 247980
    },
    {
      "epoch": 400.0,
      "learning_rate": 0.06001616901612903,
      "loss": 0.807,
      "step": 248000
    },
    {
      "epoch": 400.0,
      "eval_accuracy": {
        "accuracy": 0.7502146592771837
      },
      "eval_loss": 1.2005943059921265,
      "eval_runtime": 2.9404,
      "eval_samples_per_second": 4356.839,
      "eval_steps_per_second": 68.357,
      "step": 248000
    },
    {
      "epoch": 400.03,
      "learning_rate": 0.060012943212903236,
      "loss": 0.8162,
      "step": 248020
    },
    {
      "epoch": 400.06,
      "learning_rate": 0.06000971740967742,
      "loss": 0.7991,
      "step": 248040
    },
    {
      "epoch": 400.1,
      "learning_rate": 0.060006491606451634,
      "loss": 0.7928,
      "step": 248060
    },
    {
      "epoch": 400.13,
      "learning_rate": 0.060003265803225805,
      "loss": 0.7961,
      "step": 248080
    },
    {
      "epoch": 400.16,
      "learning_rate": 0.060000040000000004,
      "loss": 0.8064,
      "step": 248100
    },
    {
      "epoch": 400.19,
      "learning_rate": 0.0599968141967742,
      "loss": 0.7846,
      "step": 248120
    },
    {
      "epoch": 400.23,
      "learning_rate": 0.05999358839354838,
      "loss": 0.7946,
      "step": 248140
    },
    {
      "epoch": 400.26,
      "learning_rate": 0.05999036259032259,
      "loss": 0.7572,
      "step": 248160
    },
    {
      "epoch": 400.29,
      "learning_rate": 0.05998713678709677,
      "loss": 0.7823,
      "step": 248180
    },
    {
      "epoch": 400.32,
      "learning_rate": 0.05998391098387097,
      "loss": 0.7951,
      "step": 248200
    },
    {
      "epoch": 400.35,
      "learning_rate": 0.05998068518064517,
      "loss": 0.7751,
      "step": 248220
    },
    {
      "epoch": 400.39,
      "learning_rate": 0.05997745937741936,
      "loss": 0.7942,
      "step": 248240
    },
    {
      "epoch": 400.42,
      "learning_rate": 0.05997423357419355,
      "loss": 0.7773,
      "step": 248260
    },
    {
      "epoch": 400.45,
      "learning_rate": 0.05997100777096775,
      "loss": 0.7664,
      "step": 248280
    },
    {
      "epoch": 400.48,
      "learning_rate": 0.05996778196774193,
      "loss": 0.7813,
      "step": 248300
    },
    {
      "epoch": 400.52,
      "learning_rate": 0.05996455616451614,
      "loss": 0.7842,
      "step": 248320
    },
    {
      "epoch": 400.55,
      "learning_rate": 0.059961330361290324,
      "loss": 0.8001,
      "step": 248340
    },
    {
      "epoch": 400.58,
      "learning_rate": 0.05995810455806453,
      "loss": 0.7943,
      "step": 248360
    },
    {
      "epoch": 400.61,
      "learning_rate": 0.05995487875483871,
      "loss": 0.7767,
      "step": 248380
    },
    {
      "epoch": 400.65,
      "learning_rate": 0.0599516529516129,
      "loss": 0.8004,
      "step": 248400
    },
    {
      "epoch": 400.68,
      "learning_rate": 0.0599484271483871,
      "loss": 0.8087,
      "step": 248420
    },
    {
      "epoch": 400.71,
      "learning_rate": 0.05994520134516129,
      "loss": 0.8384,
      "step": 248440
    },
    {
      "epoch": 400.74,
      "learning_rate": 0.05994197554193549,
      "loss": 0.7922,
      "step": 248460
    },
    {
      "epoch": 400.77,
      "learning_rate": 0.05993874973870969,
      "loss": 0.809,
      "step": 248480
    },
    {
      "epoch": 400.81,
      "learning_rate": 0.059935523935483875,
      "loss": 0.8007,
      "step": 248500
    },
    {
      "epoch": 400.84,
      "learning_rate": 0.05993229813225807,
      "loss": 0.8093,
      "step": 248520
    },
    {
      "epoch": 400.87,
      "learning_rate": 0.05992907232903227,
      "loss": 0.7907,
      "step": 248540
    },
    {
      "epoch": 400.9,
      "learning_rate": 0.05992584652580644,
      "loss": 0.7849,
      "step": 248560
    },
    {
      "epoch": 400.94,
      "learning_rate": 0.059922620722580644,
      "loss": 0.8381,
      "step": 248580
    },
    {
      "epoch": 400.97,
      "learning_rate": 0.05991939491935483,
      "loss": 0.8155,
      "step": 248600
    },
    {
      "epoch": 401.0,
      "learning_rate": 0.05991616911612904,
      "loss": 0.8093,
      "step": 248620
    },
    {
      "epoch": 401.0,
      "eval_accuracy": {
        "accuracy": 0.7530247443603153
      },
      "eval_loss": 1.1644879579544067,
      "eval_runtime": 2.8159,
      "eval_samples_per_second": 4549.551,
      "eval_steps_per_second": 71.381,
      "step": 248620
    },
    {
      "epoch": 401.03,
      "learning_rate": 0.05991294331290323,
      "loss": 0.8013,
      "step": 248640
    },
    {
      "epoch": 401.06,
      "learning_rate": 0.05990971750967743,
      "loss": 0.7796,
      "step": 248660
    },
    {
      "epoch": 401.1,
      "learning_rate": 0.059906491706451605,
      "loss": 0.7876,
      "step": 248680
    },
    {
      "epoch": 401.13,
      "learning_rate": 0.05990326590322581,
      "loss": 0.7773,
      "step": 248700
    },
    {
      "epoch": 401.16,
      "learning_rate": 0.059900040099999996,
      "loss": 0.7557,
      "step": 248720
    },
    {
      "epoch": 401.19,
      "learning_rate": 0.059896814296774195,
      "loss": 0.7717,
      "step": 248740
    },
    {
      "epoch": 401.23,
      "learning_rate": 0.059893588493548394,
      "loss": 0.7872,
      "step": 248760
    },
    {
      "epoch": 401.26,
      "learning_rate": 0.059890362690322586,
      "loss": 0.783,
      "step": 248780
    },
    {
      "epoch": 401.29,
      "learning_rate": 0.05988713688709677,
      "loss": 0.7731,
      "step": 248800
    },
    {
      "epoch": 401.32,
      "learning_rate": 0.05988391108387097,
      "loss": 0.7808,
      "step": 248820
    },
    {
      "epoch": 401.35,
      "learning_rate": 0.05988068528064516,
      "loss": 0.7901,
      "step": 248840
    },
    {
      "epoch": 401.39,
      "learning_rate": 0.05987745947741936,
      "loss": 0.7987,
      "step": 248860
    },
    {
      "epoch": 401.42,
      "learning_rate": 0.05987423367419356,
      "loss": 0.786,
      "step": 248880
    },
    {
      "epoch": 401.45,
      "learning_rate": 0.059871007870967746,
      "loss": 0.7907,
      "step": 248900
    },
    {
      "epoch": 401.48,
      "learning_rate": 0.05986778206774194,
      "loss": 0.7796,
      "step": 248920
    },
    {
      "epoch": 401.52,
      "learning_rate": 0.059864556264516124,
      "loss": 0.8154,
      "step": 248940
    },
    {
      "epoch": 401.55,
      "learning_rate": 0.05986133046129033,
      "loss": 0.7966,
      "step": 248960
    },
    {
      "epoch": 401.58,
      "learning_rate": 0.059858104658064515,
      "loss": 0.8142,
      "step": 248980
    },
    {
      "epoch": 401.61,
      "learning_rate": 0.05985487885483873,
      "loss": 0.7802,
      "step": 249000
    },
    {
      "epoch": 401.65,
      "learning_rate": 0.05985165305161291,
      "loss": 0.7922,
      "step": 249020
    },
    {
      "epoch": 401.68,
      "learning_rate": 0.0598484272483871,
      "loss": 0.7757,
      "step": 249040
    },
    {
      "epoch": 401.71,
      "learning_rate": 0.05984520144516129,
      "loss": 0.804,
      "step": 249060
    },
    {
      "epoch": 401.74,
      "learning_rate": 0.05984197564193549,
      "loss": 0.8034,
      "step": 249080
    },
    {
      "epoch": 401.77,
      "learning_rate": 0.05983874983870968,
      "loss": 0.7992,
      "step": 249100
    },
    {
      "epoch": 401.81,
      "learning_rate": 0.05983552403548387,
      "loss": 0.7967,
      "step": 249120
    },
    {
      "epoch": 401.84,
      "learning_rate": 0.05983229823225808,
      "loss": 0.8062,
      "step": 249140
    },
    {
      "epoch": 401.87,
      "learning_rate": 0.059829072429032265,
      "loss": 0.7962,
      "step": 249160
    },
    {
      "epoch": 401.9,
      "learning_rate": 0.05982584662580646,
      "loss": 0.7756,
      "step": 249180
    },
    {
      "epoch": 401.94,
      "learning_rate": 0.05982262082258064,
      "loss": 0.7734,
      "step": 249200
    },
    {
      "epoch": 401.97,
      "learning_rate": 0.05981939501935485,
      "loss": 0.7944,
      "step": 249220
    },
    {
      "epoch": 402.0,
      "learning_rate": 0.059816169216129034,
      "loss": 0.7736,
      "step": 249240
    },
    {
      "epoch": 402.0,
      "eval_accuracy": {
        "accuracy": 0.753961439388026
      },
      "eval_loss": 1.1441839933395386,
      "eval_runtime": 2.9444,
      "eval_samples_per_second": 4350.918,
      "eval_steps_per_second": 68.264,
      "step": 249240
    },
    {
      "epoch": 402.03,
      "learning_rate": 0.05981294341290323,
      "loss": 0.7836,
      "step": 249260
    },
    {
      "epoch": 402.06,
      "learning_rate": 0.05980971760967742,
      "loss": 0.799,
      "step": 249280
    },
    {
      "epoch": 402.1,
      "learning_rate": 0.059806491806451624,
      "loss": 0.7828,
      "step": 249300
    },
    {
      "epoch": 402.13,
      "learning_rate": 0.05980326600322581,
      "loss": 0.7762,
      "step": 249320
    },
    {
      "epoch": 402.16,
      "learning_rate": 0.059800040199999994,
      "loss": 0.7744,
      "step": 249340
    },
    {
      "epoch": 402.19,
      "learning_rate": 0.059796814396774194,
      "loss": 0.783,
      "step": 249360
    },
    {
      "epoch": 402.23,
      "learning_rate": 0.059793588593548386,
      "loss": 0.783,
      "step": 249380
    },
    {
      "epoch": 402.26,
      "learning_rate": 0.059790362790322585,
      "loss": 0.7643,
      "step": 249400
    },
    {
      "epoch": 402.29,
      "learning_rate": 0.059787136987096784,
      "loss": 0.7641,
      "step": 249420
    },
    {
      "epoch": 402.32,
      "learning_rate": 0.059783911183870976,
      "loss": 0.7676,
      "step": 249440
    },
    {
      "epoch": 402.35,
      "learning_rate": 0.05978068538064516,
      "loss": 0.7838,
      "step": 249460
    },
    {
      "epoch": 402.39,
      "learning_rate": 0.05977745957741936,
      "loss": 0.7898,
      "step": 249480
    },
    {
      "epoch": 402.42,
      "learning_rate": 0.059774233774193546,
      "loss": 0.8061,
      "step": 249500
    },
    {
      "epoch": 402.45,
      "learning_rate": 0.05977100797096775,
      "loss": 0.7987,
      "step": 249520
    },
    {
      "epoch": 402.48,
      "learning_rate": 0.05976778216774194,
      "loss": 0.781,
      "step": 249540
    },
    {
      "epoch": 402.52,
      "learning_rate": 0.059764556364516136,
      "loss": 0.8034,
      "step": 249560
    },
    {
      "epoch": 402.55,
      "learning_rate": 0.05976133056129032,
      "loss": 0.8154,
      "step": 249580
    },
    {
      "epoch": 402.58,
      "learning_rate": 0.05975810475806453,
      "loss": 0.8,
      "step": 249600
    },
    {
      "epoch": 402.61,
      "learning_rate": 0.05975487895483871,
      "loss": 0.7821,
      "step": 249620
    },
    {
      "epoch": 402.65,
      "learning_rate": 0.05975165315161292,
      "loss": 0.7831,
      "step": 249640
    },
    {
      "epoch": 402.68,
      "learning_rate": 0.05974842734838709,
      "loss": 0.7949,
      "step": 249660
    },
    {
      "epoch": 402.71,
      "learning_rate": 0.0597452015451613,
      "loss": 0.8118,
      "step": 249680
    },
    {
      "epoch": 402.74,
      "learning_rate": 0.05974197574193549,
      "loss": 0.8166,
      "step": 249700
    },
    {
      "epoch": 402.77,
      "learning_rate": 0.05973874993870968,
      "loss": 0.7906,
      "step": 249720
    },
    {
      "epoch": 402.81,
      "learning_rate": 0.05973552413548388,
      "loss": 0.8036,
      "step": 249740
    },
    {
      "epoch": 402.84,
      "learning_rate": 0.05973229833225807,
      "loss": 0.8101,
      "step": 249760
    },
    {
      "epoch": 402.87,
      "learning_rate": 0.05972907252903226,
      "loss": 0.778,
      "step": 249780
    },
    {
      "epoch": 402.9,
      "learning_rate": 0.05972584672580644,
      "loss": 0.7968,
      "step": 249800
    },
    {
      "epoch": 402.94,
      "learning_rate": 0.059722620922580655,
      "loss": 0.7654,
      "step": 249820
    },
    {
      "epoch": 402.97,
      "learning_rate": 0.05971939511935484,
      "loss": 0.7818,
      "step": 249840
    },
    {
      "epoch": 403.0,
      "learning_rate": 0.05971633060629033,
      "loss": 0.7836,
      "step": 249860
    },
    {
      "epoch": 403.0,
      "eval_accuracy": {
        "accuracy": 0.7563812348762782
      },
      "eval_loss": 1.1221323013305664,
      "eval_runtime": 3.7684,
      "eval_samples_per_second": 3399.618,
      "eval_steps_per_second": 53.339,
      "step": 249860
    },
    {
      "epoch": 403.03,
      "learning_rate": 0.05971310480306452,
      "loss": 0.7627,
      "step": 249880
    },
    {
      "epoch": 403.06,
      "learning_rate": 0.059709878999838706,
      "loss": 0.7704,
      "step": 249900
    },
    {
      "epoch": 403.1,
      "learning_rate": 0.05970665319661292,
      "loss": 0.7707,
      "step": 249920
    },
    {
      "epoch": 403.13,
      "learning_rate": 0.05970342739338709,
      "loss": 0.7521,
      "step": 249940
    },
    {
      "epoch": 403.16,
      "learning_rate": 0.059700201590161296,
      "loss": 0.765,
      "step": 249960
    },
    {
      "epoch": 403.19,
      "learning_rate": 0.05969697578693548,
      "loss": 0.777,
      "step": 249980
    },
    {
      "epoch": 403.23,
      "learning_rate": 0.05969374998370969,
      "loss": 0.756,
      "step": 250000
    },
    {
      "epoch": 403.26,
      "learning_rate": 0.05969052418048387,
      "loss": 0.7652,
      "step": 250020
    },
    {
      "epoch": 403.29,
      "learning_rate": 0.059687298377258086,
      "loss": 0.7936,
      "step": 250040
    },
    {
      "epoch": 403.32,
      "learning_rate": 0.05968407257403226,
      "loss": 0.7827,
      "step": 250060
    },
    {
      "epoch": 403.35,
      "learning_rate": 0.05968084677080646,
      "loss": 0.7812,
      "step": 250080
    },
    {
      "epoch": 403.39,
      "learning_rate": 0.05967762096758065,
      "loss": 0.779,
      "step": 250100
    },
    {
      "epoch": 403.42,
      "learning_rate": 0.05967439516435483,
      "loss": 0.778,
      "step": 250120
    },
    {
      "epoch": 403.45,
      "learning_rate": 0.05967116936112903,
      "loss": 0.7693,
      "step": 250140
    },
    {
      "epoch": 403.48,
      "learning_rate": 0.059667943557903225,
      "loss": 0.7799,
      "step": 250160
    },
    {
      "epoch": 403.52,
      "learning_rate": 0.059664717754677424,
      "loss": 0.7756,
      "step": 250180
    },
    {
      "epoch": 403.55,
      "learning_rate": 0.05966149195145162,
      "loss": 0.806,
      "step": 250200
    },
    {
      "epoch": 403.58,
      "learning_rate": 0.059658266148225815,
      "loss": 0.8031,
      "step": 250220
    },
    {
      "epoch": 403.61,
      "learning_rate": 0.059655040345,
      "loss": 0.7808,
      "step": 250240
    },
    {
      "epoch": 403.65,
      "learning_rate": 0.0596518145417742,
      "loss": 0.773,
      "step": 250260
    },
    {
      "epoch": 403.68,
      "learning_rate": 0.059648588738548385,
      "loss": 0.8033,
      "step": 250280
    },
    {
      "epoch": 403.71,
      "learning_rate": 0.05964536293532259,
      "loss": 0.782,
      "step": 250300
    },
    {
      "epoch": 403.74,
      "learning_rate": 0.059642137132096776,
      "loss": 0.7827,
      "step": 250320
    },
    {
      "epoch": 403.77,
      "learning_rate": 0.059638911328870975,
      "loss": 0.8166,
      "step": 250340
    },
    {
      "epoch": 403.81,
      "learning_rate": 0.05963568552564516,
      "loss": 0.7963,
      "step": 250360
    },
    {
      "epoch": 403.84,
      "learning_rate": 0.059632459722419366,
      "loss": 0.8229,
      "step": 250380
    },
    {
      "epoch": 403.87,
      "learning_rate": 0.05962923391919355,
      "loss": 0.8071,
      "step": 250400
    },
    {
      "epoch": 403.9,
      "learning_rate": 0.059626008115967744,
      "loss": 0.8319,
      "step": 250420
    },
    {
      "epoch": 403.94,
      "learning_rate": 0.05962278231274193,
      "loss": 0.8144,
      "step": 250440
    },
    {
      "epoch": 403.97,
      "learning_rate": 0.05961955650951614,
      "loss": 0.8212,
      "step": 250460
    },
    {
      "epoch": 404.0,
      "learning_rate": 0.05961633070629033,
      "loss": 0.787,
      "step": 250480
    },
    {
      "epoch": 404.0,
      "eval_accuracy": {
        "accuracy": 0.7528686285223636
      },
      "eval_loss": 1.1503506898880005,
      "eval_runtime": 2.7397,
      "eval_samples_per_second": 4676.056,
      "eval_steps_per_second": 73.366,
      "step": 250480
    },
    {
      "epoch": 404.03,
      "learning_rate": 0.05961310490306452,
      "loss": 0.8189,
      "step": 250500
    },
    {
      "epoch": 404.06,
      "learning_rate": 0.05960987909983872,
      "loss": 0.7753,
      "step": 250520
    },
    {
      "epoch": 404.1,
      "learning_rate": 0.05960665329661291,
      "loss": 0.782,
      "step": 250540
    },
    {
      "epoch": 404.13,
      "learning_rate": 0.059603427493387096,
      "loss": 0.8038,
      "step": 250560
    },
    {
      "epoch": 404.16,
      "learning_rate": 0.05960020169016128,
      "loss": 0.7887,
      "step": 250580
    },
    {
      "epoch": 404.19,
      "learning_rate": 0.059596975886935494,
      "loss": 0.7835,
      "step": 250600
    },
    {
      "epoch": 404.23,
      "learning_rate": 0.05959375008370968,
      "loss": 0.7751,
      "step": 250620
    },
    {
      "epoch": 404.26,
      "learning_rate": 0.05959052428048387,
      "loss": 0.792,
      "step": 250640
    },
    {
      "epoch": 404.29,
      "learning_rate": 0.059587298477258056,
      "loss": 0.7821,
      "step": 250660
    },
    {
      "epoch": 404.32,
      "learning_rate": 0.05958407267403226,
      "loss": 0.7702,
      "step": 250680
    },
    {
      "epoch": 404.35,
      "learning_rate": 0.05958084687080645,
      "loss": 0.7902,
      "step": 250700
    },
    {
      "epoch": 404.39,
      "learning_rate": 0.05957762106758065,
      "loss": 0.8019,
      "step": 250720
    },
    {
      "epoch": 404.42,
      "learning_rate": 0.059574395264354846,
      "loss": 0.7831,
      "step": 250740
    },
    {
      "epoch": 404.45,
      "learning_rate": 0.05957116946112904,
      "loss": 0.7611,
      "step": 250760
    },
    {
      "epoch": 404.48,
      "learning_rate": 0.05956794365790322,
      "loss": 0.7707,
      "step": 250780
    },
    {
      "epoch": 404.52,
      "learning_rate": 0.05956471785467742,
      "loss": 0.7901,
      "step": 250800
    },
    {
      "epoch": 404.55,
      "learning_rate": 0.059561492051451614,
      "loss": 0.7842,
      "step": 250820
    },
    {
      "epoch": 404.58,
      "learning_rate": 0.059558266248225813,
      "loss": 0.7927,
      "step": 250840
    },
    {
      "epoch": 404.61,
      "learning_rate": 0.05955504044500001,
      "loss": 0.7908,
      "step": 250860
    },
    {
      "epoch": 404.65,
      "learning_rate": 0.0595518146417742,
      "loss": 0.774,
      "step": 250880
    },
    {
      "epoch": 404.68,
      "learning_rate": 0.05954858883854839,
      "loss": 0.7914,
      "step": 250900
    },
    {
      "epoch": 404.71,
      "learning_rate": 0.059545363035322575,
      "loss": 0.7867,
      "step": 250920
    },
    {
      "epoch": 404.74,
      "learning_rate": 0.05954213723209678,
      "loss": 0.7984,
      "step": 250940
    },
    {
      "epoch": 404.77,
      "learning_rate": 0.059538911428870966,
      "loss": 0.7988,
      "step": 250960
    },
    {
      "epoch": 404.81,
      "learning_rate": 0.05953568562564518,
      "loss": 0.8079,
      "step": 250980
    },
    {
      "epoch": 404.84,
      "learning_rate": 0.059532459822419365,
      "loss": 0.802,
      "step": 251000
    },
    {
      "epoch": 404.87,
      "learning_rate": 0.05952923401919356,
      "loss": 0.792,
      "step": 251020
    },
    {
      "epoch": 404.9,
      "learning_rate": 0.05952600821596774,
      "loss": 0.7984,
      "step": 251040
    },
    {
      "epoch": 404.94,
      "learning_rate": 0.05952278241274194,
      "loss": 0.8037,
      "step": 251060
    },
    {
      "epoch": 404.97,
      "learning_rate": 0.05951955660951613,
      "loss": 0.8002,
      "step": 251080
    },
    {
      "epoch": 405.0,
      "learning_rate": 0.05951633080629032,
      "loss": 0.8045,
      "step": 251100
    },
    {
      "epoch": 405.0,
      "eval_accuracy": {
        "accuracy": 0.746077589571462
      },
      "eval_loss": 1.2045999765396118,
      "eval_runtime": 2.8038,
      "eval_samples_per_second": 4569.235,
      "eval_steps_per_second": 71.69,
      "step": 251100
    },
    {
      "epoch": 405.03,
      "learning_rate": 0.05951310500306453,
      "loss": 0.8078,
      "step": 251120
    },
    {
      "epoch": 405.06,
      "learning_rate": 0.05950987919983872,
      "loss": 0.7831,
      "step": 251140
    },
    {
      "epoch": 405.1,
      "learning_rate": 0.05950665339661291,
      "loss": 0.7789,
      "step": 251160
    },
    {
      "epoch": 405.13,
      "learning_rate": 0.059503427593387094,
      "loss": 0.7917,
      "step": 251180
    },
    {
      "epoch": 405.16,
      "learning_rate": 0.0595002017901613,
      "loss": 0.7847,
      "step": 251200
    },
    {
      "epoch": 405.19,
      "learning_rate": 0.05949697598693548,
      "loss": 0.7933,
      "step": 251220
    },
    {
      "epoch": 405.23,
      "learning_rate": 0.059493750183709684,
      "loss": 0.7945,
      "step": 251240
    },
    {
      "epoch": 405.26,
      "learning_rate": 0.05949052438048387,
      "loss": 0.7699,
      "step": 251260
    },
    {
      "epoch": 405.29,
      "learning_rate": 0.059487298577258076,
      "loss": 0.7764,
      "step": 251280
    },
    {
      "epoch": 405.32,
      "learning_rate": 0.05948407277403226,
      "loss": 0.7544,
      "step": 251300
    },
    {
      "epoch": 405.35,
      "learning_rate": 0.05948084697080647,
      "loss": 0.7527,
      "step": 251320
    },
    {
      "epoch": 405.39,
      "learning_rate": 0.059477621167580645,
      "loss": 0.7687,
      "step": 251340
    },
    {
      "epoch": 405.42,
      "learning_rate": 0.05947439536435484,
      "loss": 0.7836,
      "step": 251360
    },
    {
      "epoch": 405.45,
      "learning_rate": 0.059471169561129036,
      "loss": 0.7923,
      "step": 251380
    },
    {
      "epoch": 405.48,
      "learning_rate": 0.059467943757903236,
      "loss": 0.7844,
      "step": 251400
    },
    {
      "epoch": 405.52,
      "learning_rate": 0.05946471795467742,
      "loss": 0.8021,
      "step": 251420
    },
    {
      "epoch": 405.55,
      "learning_rate": 0.05946149215145161,
      "loss": 0.7983,
      "step": 251440
    },
    {
      "epoch": 405.58,
      "learning_rate": 0.05945826634822581,
      "loss": 0.7883,
      "step": 251460
    },
    {
      "epoch": 405.61,
      "learning_rate": 0.059455040545000004,
      "loss": 0.7971,
      "step": 251480
    },
    {
      "epoch": 405.65,
      "learning_rate": 0.0594518147417742,
      "loss": 0.7968,
      "step": 251500
    },
    {
      "epoch": 405.68,
      "learning_rate": 0.059448588938548375,
      "loss": 0.7637,
      "step": 251520
    },
    {
      "epoch": 405.71,
      "learning_rate": 0.05944536313532259,
      "loss": 0.78,
      "step": 251540
    },
    {
      "epoch": 405.74,
      "learning_rate": 0.05944213733209677,
      "loss": 0.7907,
      "step": 251560
    },
    {
      "epoch": 405.77,
      "learning_rate": 0.05943891152887098,
      "loss": 0.8004,
      "step": 251580
    },
    {
      "epoch": 405.81,
      "learning_rate": 0.059435685725645164,
      "loss": 0.8038,
      "step": 251600
    },
    {
      "epoch": 405.84,
      "learning_rate": 0.05943245992241937,
      "loss": 0.8,
      "step": 251620
    },
    {
      "epoch": 405.87,
      "learning_rate": 0.05942923411919354,
      "loss": 0.7745,
      "step": 251640
    },
    {
      "epoch": 405.9,
      "learning_rate": 0.059426008315967754,
      "loss": 0.7981,
      "step": 251660
    },
    {
      "epoch": 405.94,
      "learning_rate": 0.05942278251274194,
      "loss": 0.8088,
      "step": 251680
    },
    {
      "epoch": 405.97,
      "learning_rate": 0.05941955670951613,
      "loss": 0.7975,
      "step": 251700
    },
    {
      "epoch": 406.0,
      "learning_rate": 0.05941633090629032,
      "loss": 0.8023,
      "step": 251720
    },
    {
      "epoch": 406.0,
      "eval_accuracy": {
        "accuracy": 0.7482632113027866
      },
      "eval_loss": 1.1641336679458618,
      "eval_runtime": 4.218,
      "eval_samples_per_second": 3037.237,
      "eval_steps_per_second": 47.653,
      "step": 251720
    },
    {
      "epoch": 406.03,
      "learning_rate": 0.05941310510306452,
      "loss": 0.8115,
      "step": 251740
    },
    {
      "epoch": 406.06,
      "learning_rate": 0.05940987929983871,
      "loss": 0.7775,
      "step": 251760
    },
    {
      "epoch": 406.1,
      "learning_rate": 0.05940665349661291,
      "loss": 0.7596,
      "step": 251780
    },
    {
      "epoch": 406.13,
      "learning_rate": 0.059403427693387106,
      "loss": 0.7719,
      "step": 251800
    },
    {
      "epoch": 406.16,
      "learning_rate": 0.05940020189016129,
      "loss": 0.7859,
      "step": 251820
    },
    {
      "epoch": 406.19,
      "learning_rate": 0.059396976086935484,
      "loss": 0.7862,
      "step": 251840
    },
    {
      "epoch": 406.23,
      "learning_rate": 0.05939375028370967,
      "loss": 0.7628,
      "step": 251860
    },
    {
      "epoch": 406.26,
      "learning_rate": 0.059390524480483875,
      "loss": 0.7714,
      "step": 251880
    },
    {
      "epoch": 406.29,
      "learning_rate": 0.05938729867725806,
      "loss": 0.7802,
      "step": 251900
    },
    {
      "epoch": 406.32,
      "learning_rate": 0.05938407287403227,
      "loss": 0.7656,
      "step": 251920
    },
    {
      "epoch": 406.35,
      "learning_rate": 0.05938084707080646,
      "loss": 0.7783,
      "step": 251940
    },
    {
      "epoch": 406.39,
      "learning_rate": 0.05937762126758065,
      "loss": 0.8011,
      "step": 251960
    },
    {
      "epoch": 406.42,
      "learning_rate": 0.059374395464354836,
      "loss": 0.7701,
      "step": 251980
    },
    {
      "epoch": 406.45,
      "learning_rate": 0.059371169661129035,
      "loss": 0.7655,
      "step": 252000
    },
    {
      "epoch": 406.48,
      "learning_rate": 0.05936794385790323,
      "loss": 0.8125,
      "step": 252020
    },
    {
      "epoch": 406.52,
      "learning_rate": 0.059364718054677426,
      "loss": 0.8009,
      "step": 252040
    },
    {
      "epoch": 406.55,
      "learning_rate": 0.059361492251451625,
      "loss": 0.7812,
      "step": 252060
    },
    {
      "epoch": 406.58,
      "learning_rate": 0.05935826644822581,
      "loss": 0.7468,
      "step": 252080
    },
    {
      "epoch": 406.61,
      "learning_rate": 0.059355040645,
      "loss": 0.784,
      "step": 252100
    },
    {
      "epoch": 406.65,
      "learning_rate": 0.05935181484177419,
      "loss": 0.7753,
      "step": 252120
    },
    {
      "epoch": 406.68,
      "learning_rate": 0.059348589038548394,
      "loss": 0.7829,
      "step": 252140
    },
    {
      "epoch": 406.71,
      "learning_rate": 0.05934536323532258,
      "loss": 0.7794,
      "step": 252160
    },
    {
      "epoch": 406.74,
      "learning_rate": 0.05934213743209679,
      "loss": 0.7854,
      "step": 252180
    },
    {
      "epoch": 406.77,
      "learning_rate": 0.05933891162887098,
      "loss": 0.7636,
      "step": 252200
    },
    {
      "epoch": 406.81,
      "learning_rate": 0.05933568582564517,
      "loss": 0.7961,
      "step": 252220
    },
    {
      "epoch": 406.84,
      "learning_rate": 0.059332460022419355,
      "loss": 0.8132,
      "step": 252240
    },
    {
      "epoch": 406.87,
      "learning_rate": 0.05932923421919356,
      "loss": 0.8086,
      "step": 252260
    },
    {
      "epoch": 406.9,
      "learning_rate": 0.059326008415967746,
      "loss": 0.78,
      "step": 252280
    },
    {
      "epoch": 406.94,
      "learning_rate": 0.05932278261274193,
      "loss": 0.7926,
      "step": 252300
    },
    {
      "epoch": 406.97,
      "learning_rate": 0.05931955680951613,
      "loss": 0.7947,
      "step": 252320
    },
    {
      "epoch": 407.0,
      "learning_rate": 0.05931649229645161,
      "loss": 0.7807,
      "step": 252340
    },
    {
      "epoch": 407.0,
      "eval_accuracy": {
        "accuracy": 0.761064710014831
      },
      "eval_loss": 1.140821099281311,
      "eval_runtime": 2.7887,
      "eval_samples_per_second": 4593.817,
      "eval_steps_per_second": 72.075,
      "step": 252340
    },
    {
      "epoch": 407.03,
      "learning_rate": 0.05931326649322582,
      "loss": 0.7653,
      "step": 252360
    },
    {
      "epoch": 407.06,
      "learning_rate": 0.05931004069,
      "loss": 0.7684,
      "step": 252380
    },
    {
      "epoch": 407.1,
      "learning_rate": 0.05930681488677421,
      "loss": 0.758,
      "step": 252400
    },
    {
      "epoch": 407.13,
      "learning_rate": 0.05930358908354838,
      "loss": 0.769,
      "step": 252420
    },
    {
      "epoch": 407.16,
      "learning_rate": 0.05930036328032259,
      "loss": 0.776,
      "step": 252440
    },
    {
      "epoch": 407.19,
      "learning_rate": 0.05929713747709678,
      "loss": 0.7598,
      "step": 252460
    },
    {
      "epoch": 407.23,
      "learning_rate": 0.05929391167387097,
      "loss": 0.7852,
      "step": 252480
    },
    {
      "epoch": 407.26,
      "learning_rate": 0.059290685870645156,
      "loss": 0.7813,
      "step": 252500
    },
    {
      "epoch": 407.29,
      "learning_rate": 0.05928746006741936,
      "loss": 0.8005,
      "step": 252520
    },
    {
      "epoch": 407.32,
      "learning_rate": 0.05928423426419355,
      "loss": 0.765,
      "step": 252540
    },
    {
      "epoch": 407.35,
      "learning_rate": 0.059281008460967746,
      "loss": 0.7703,
      "step": 252560
    },
    {
      "epoch": 407.39,
      "learning_rate": 0.059277782657741945,
      "loss": 0.7932,
      "step": 252580
    },
    {
      "epoch": 407.42,
      "learning_rate": 0.05927455685451613,
      "loss": 0.7686,
      "step": 252600
    },
    {
      "epoch": 407.45,
      "learning_rate": 0.05927133105129032,
      "loss": 0.7819,
      "step": 252620
    },
    {
      "epoch": 407.48,
      "learning_rate": 0.05926810524806451,
      "loss": 0.7858,
      "step": 252640
    },
    {
      "epoch": 407.52,
      "learning_rate": 0.059264879444838714,
      "loss": 0.7756,
      "step": 252660
    },
    {
      "epoch": 407.55,
      "learning_rate": 0.0592616536416129,
      "loss": 0.8118,
      "step": 252680
    },
    {
      "epoch": 407.58,
      "learning_rate": 0.05925842783838711,
      "loss": 0.7838,
      "step": 252700
    },
    {
      "epoch": 407.61,
      "learning_rate": 0.0592552020351613,
      "loss": 0.794,
      "step": 252720
    },
    {
      "epoch": 407.65,
      "learning_rate": 0.05925197623193549,
      "loss": 0.7872,
      "step": 252740
    },
    {
      "epoch": 407.68,
      "learning_rate": 0.059248750428709675,
      "loss": 0.7762,
      "step": 252760
    },
    {
      "epoch": 407.71,
      "learning_rate": 0.059245524625483874,
      "loss": 0.7743,
      "step": 252780
    },
    {
      "epoch": 407.74,
      "learning_rate": 0.059242298822258066,
      "loss": 0.7788,
      "step": 252800
    },
    {
      "epoch": 407.77,
      "learning_rate": 0.059239073019032265,
      "loss": 0.7963,
      "step": 252820
    },
    {
      "epoch": 407.81,
      "learning_rate": 0.059235847215806464,
      "loss": 0.7937,
      "step": 252840
    },
    {
      "epoch": 407.84,
      "learning_rate": 0.05923262141258065,
      "loss": 0.795,
      "step": 252860
    },
    {
      "epoch": 407.87,
      "learning_rate": 0.05922939560935484,
      "loss": 0.7974,
      "step": 252880
    },
    {
      "epoch": 407.9,
      "learning_rate": 0.05922616980612903,
      "loss": 0.7878,
      "step": 252900
    },
    {
      "epoch": 407.94,
      "learning_rate": 0.05922294400290323,
      "loss": 0.8007,
      "step": 252920
    },
    {
      "epoch": 407.97,
      "learning_rate": 0.05921971819967742,
      "loss": 0.8072,
      "step": 252940
    },
    {
      "epoch": 408.0,
      "learning_rate": 0.05921649239645163,
      "loss": 0.7951,
      "step": 252960
    },
    {
      "epoch": 408.0,
      "eval_accuracy": {
        "accuracy": 0.7485754429786902
      },
      "eval_loss": 1.2183111906051636,
      "eval_runtime": 2.895,
      "eval_samples_per_second": 4425.255,
      "eval_steps_per_second": 69.431,
      "step": 252960
    },
    {
      "epoch": 408.03,
      "learning_rate": 0.059213266593225816,
      "loss": 0.8055,
      "step": 252980
    },
    {
      "epoch": 408.06,
      "learning_rate": 0.05921004079000001,
      "loss": 0.777,
      "step": 253000
    },
    {
      "epoch": 408.1,
      "learning_rate": 0.059206814986774194,
      "loss": 0.7846,
      "step": 253020
    },
    {
      "epoch": 408.13,
      "learning_rate": 0.05920358918354838,
      "loss": 0.7889,
      "step": 253040
    },
    {
      "epoch": 408.16,
      "learning_rate": 0.059200363380322585,
      "loss": 0.7801,
      "step": 253060
    },
    {
      "epoch": 408.19,
      "learning_rate": 0.05919713757709677,
      "loss": 0.8014,
      "step": 253080
    },
    {
      "epoch": 408.23,
      "learning_rate": 0.05919391177387097,
      "loss": 0.7752,
      "step": 253100
    },
    {
      "epoch": 408.26,
      "learning_rate": 0.05919068597064517,
      "loss": 0.7747,
      "step": 253120
    },
    {
      "epoch": 408.29,
      "learning_rate": 0.05918746016741936,
      "loss": 0.7891,
      "step": 253140
    },
    {
      "epoch": 408.32,
      "learning_rate": 0.059184234364193546,
      "loss": 0.7797,
      "step": 253160
    },
    {
      "epoch": 408.35,
      "learning_rate": 0.05918100856096775,
      "loss": 0.7666,
      "step": 253180
    },
    {
      "epoch": 408.39,
      "learning_rate": 0.05917778275774193,
      "loss": 0.7679,
      "step": 253200
    },
    {
      "epoch": 408.42,
      "learning_rate": 0.059174556954516136,
      "loss": 0.7797,
      "step": 253220
    },
    {
      "epoch": 408.45,
      "learning_rate": 0.05917133115129032,
      "loss": 0.7877,
      "step": 253240
    },
    {
      "epoch": 408.48,
      "learning_rate": 0.05916810534806453,
      "loss": 0.7779,
      "step": 253260
    },
    {
      "epoch": 408.52,
      "learning_rate": 0.05916487954483871,
      "loss": 0.779,
      "step": 253280
    },
    {
      "epoch": 408.55,
      "learning_rate": 0.05916165374161291,
      "loss": 0.7991,
      "step": 253300
    },
    {
      "epoch": 408.58,
      "learning_rate": 0.0591584279383871,
      "loss": 0.7941,
      "step": 253320
    },
    {
      "epoch": 408.61,
      "learning_rate": 0.0591552021351613,
      "loss": 0.7977,
      "step": 253340
    },
    {
      "epoch": 408.65,
      "learning_rate": 0.05915197633193549,
      "loss": 0.7818,
      "step": 253360
    },
    {
      "epoch": 408.68,
      "learning_rate": 0.05914875052870969,
      "loss": 0.774,
      "step": 253380
    },
    {
      "epoch": 408.71,
      "learning_rate": 0.05914552472548387,
      "loss": 0.7775,
      "step": 253400
    },
    {
      "epoch": 408.74,
      "learning_rate": 0.059142298922258064,
      "loss": 0.7792,
      "step": 253420
    },
    {
      "epoch": 408.77,
      "learning_rate": 0.059139073119032264,
      "loss": 0.7765,
      "step": 253440
    },
    {
      "epoch": 408.81,
      "learning_rate": 0.059135847315806456,
      "loss": 0.7747,
      "step": 253460
    },
    {
      "epoch": 408.84,
      "learning_rate": 0.059132621512580655,
      "loss": 0.7836,
      "step": 253480
    },
    {
      "epoch": 408.87,
      "learning_rate": 0.059129395709354854,
      "loss": 0.7844,
      "step": 253500
    },
    {
      "epoch": 408.9,
      "learning_rate": 0.05912616990612904,
      "loss": 0.7928,
      "step": 253520
    },
    {
      "epoch": 408.94,
      "learning_rate": 0.059122944102903224,
      "loss": 0.803,
      "step": 253540
    },
    {
      "epoch": 408.97,
      "learning_rate": 0.05911971829967743,
      "loss": 0.7968,
      "step": 253560
    },
    {
      "epoch": 409.0,
      "learning_rate": 0.0591164924964516,
      "loss": 0.778,
      "step": 253580
    },
    {
      "epoch": 409.0,
      "eval_accuracy": {
        "accuracy": 0.7580985090937475
      },
      "eval_loss": 1.128922462463379,
      "eval_runtime": 3.7953,
      "eval_samples_per_second": 3375.491,
      "eval_steps_per_second": 52.96,
      "step": 253580
    },
    {
      "epoch": 409.03,
      "learning_rate": 0.05911326669322581,
      "loss": 0.8093,
      "step": 253600
    },
    {
      "epoch": 409.06,
      "learning_rate": 0.05911004088999999,
      "loss": 0.8037,
      "step": 253620
    },
    {
      "epoch": 409.1,
      "learning_rate": 0.059106815086774206,
      "loss": 0.7915,
      "step": 253640
    },
    {
      "epoch": 409.13,
      "learning_rate": 0.05910358928354839,
      "loss": 0.765,
      "step": 253660
    },
    {
      "epoch": 409.16,
      "learning_rate": 0.05910036348032258,
      "loss": 0.7949,
      "step": 253680
    },
    {
      "epoch": 409.19,
      "learning_rate": 0.05909713767709677,
      "loss": 0.7838,
      "step": 253700
    },
    {
      "epoch": 409.23,
      "learning_rate": 0.059093911873870975,
      "loss": 0.7831,
      "step": 253720
    },
    {
      "epoch": 409.26,
      "learning_rate": 0.05909068607064516,
      "loss": 0.7878,
      "step": 253740
    },
    {
      "epoch": 409.29,
      "learning_rate": 0.05908746026741936,
      "loss": 0.7796,
      "step": 253760
    },
    {
      "epoch": 409.32,
      "learning_rate": 0.05908423446419356,
      "loss": 0.7792,
      "step": 253780
    },
    {
      "epoch": 409.35,
      "learning_rate": 0.05908100866096775,
      "loss": 0.7872,
      "step": 253800
    },
    {
      "epoch": 409.39,
      "learning_rate": 0.059077782857741935,
      "loss": 0.7837,
      "step": 253820
    },
    {
      "epoch": 409.42,
      "learning_rate": 0.05907455705451612,
      "loss": 0.7727,
      "step": 253840
    },
    {
      "epoch": 409.45,
      "learning_rate": 0.05907133125129033,
      "loss": 0.7736,
      "step": 253860
    },
    {
      "epoch": 409.48,
      "learning_rate": 0.05906810544806451,
      "loss": 0.7807,
      "step": 253880
    },
    {
      "epoch": 409.52,
      "learning_rate": 0.059064879644838725,
      "loss": 0.7864,
      "step": 253900
    },
    {
      "epoch": 409.55,
      "learning_rate": 0.05906165384161291,
      "loss": 0.7829,
      "step": 253920
    },
    {
      "epoch": 409.58,
      "learning_rate": 0.0590584280383871,
      "loss": 0.7858,
      "step": 253940
    },
    {
      "epoch": 409.61,
      "learning_rate": 0.05905520223516129,
      "loss": 0.774,
      "step": 253960
    },
    {
      "epoch": 409.65,
      "learning_rate": 0.059051976431935486,
      "loss": 0.7731,
      "step": 253980
    },
    {
      "epoch": 409.68,
      "learning_rate": 0.05904875062870968,
      "loss": 0.7771,
      "step": 254000
    },
    {
      "epoch": 409.71,
      "learning_rate": 0.05904552482548388,
      "loss": 0.7865,
      "step": 254020
    },
    {
      "epoch": 409.74,
      "learning_rate": 0.05904229902225808,
      "loss": 0.7956,
      "step": 254040
    },
    {
      "epoch": 409.77,
      "learning_rate": 0.05903907321903226,
      "loss": 0.7854,
      "step": 254060
    },
    {
      "epoch": 409.81,
      "learning_rate": 0.059035847415806454,
      "loss": 0.7746,
      "step": 254080
    },
    {
      "epoch": 409.84,
      "learning_rate": 0.05903262161258065,
      "loss": 0.7984,
      "step": 254100
    },
    {
      "epoch": 409.87,
      "learning_rate": 0.059029395809354845,
      "loss": 0.7999,
      "step": 254120
    },
    {
      "epoch": 409.9,
      "learning_rate": 0.05902617000612903,
      "loss": 0.8137,
      "step": 254140
    },
    {
      "epoch": 409.94,
      "learning_rate": 0.059022944202903244,
      "loss": 0.8042,
      "step": 254160
    },
    {
      "epoch": 409.97,
      "learning_rate": 0.059019718399677415,
      "loss": 0.8033,
      "step": 254180
    },
    {
      "epoch": 410.0,
      "learning_rate": 0.05901649259645162,
      "loss": 0.7985,
      "step": 254200
    },
    {
      "epoch": 410.0,
      "eval_accuracy": {
        "accuracy": 0.7531808601982671
      },
      "eval_loss": 1.1743961572647095,
      "eval_runtime": 2.7594,
      "eval_samples_per_second": 4642.711,
      "eval_steps_per_second": 72.842,
      "step": 254200
    },
    {
      "epoch": 410.03,
      "learning_rate": 0.059013266793225806,
      "loss": 0.8107,
      "step": 254220
    },
    {
      "epoch": 410.06,
      "learning_rate": 0.05901004099000001,
      "loss": 0.7547,
      "step": 254240
    },
    {
      "epoch": 410.1,
      "learning_rate": 0.0590068151867742,
      "loss": 0.7483,
      "step": 254260
    },
    {
      "epoch": 410.13,
      "learning_rate": 0.0590035893835484,
      "loss": 0.7648,
      "step": 254280
    },
    {
      "epoch": 410.16,
      "learning_rate": 0.05900036358032258,
      "loss": 0.7897,
      "step": 254300
    },
    {
      "epoch": 410.19,
      "learning_rate": 0.05899713777709678,
      "loss": 0.7705,
      "step": 254320
    },
    {
      "epoch": 410.23,
      "learning_rate": 0.05899391197387097,
      "loss": 0.7891,
      "step": 254340
    },
    {
      "epoch": 410.26,
      "learning_rate": 0.05899068617064516,
      "loss": 0.7991,
      "step": 254360
    },
    {
      "epoch": 410.29,
      "learning_rate": 0.05898746036741936,
      "loss": 0.7939,
      "step": 254380
    },
    {
      "epoch": 410.32,
      "learning_rate": 0.05898423456419355,
      "loss": 0.7813,
      "step": 254400
    },
    {
      "epoch": 410.35,
      "learning_rate": 0.05898100876096775,
      "loss": 0.7829,
      "step": 254420
    },
    {
      "epoch": 410.39,
      "learning_rate": 0.058977782957741934,
      "loss": 0.7962,
      "step": 254440
    },
    {
      "epoch": 410.42,
      "learning_rate": 0.05897455715451614,
      "loss": 0.8122,
      "step": 254460
    },
    {
      "epoch": 410.45,
      "learning_rate": 0.05897133135129032,
      "loss": 0.8122,
      "step": 254480
    },
    {
      "epoch": 410.48,
      "learning_rate": 0.058968105548064524,
      "loss": 0.8026,
      "step": 254500
    },
    {
      "epoch": 410.52,
      "learning_rate": 0.05896487974483871,
      "loss": 0.7789,
      "step": 254520
    },
    {
      "epoch": 410.55,
      "learning_rate": 0.058961653941612915,
      "loss": 0.7653,
      "step": 254540
    },
    {
      "epoch": 410.58,
      "learning_rate": 0.0589584281383871,
      "loss": 0.7772,
      "step": 254560
    },
    {
      "epoch": 410.61,
      "learning_rate": 0.0589552023351613,
      "loss": 0.761,
      "step": 254580
    },
    {
      "epoch": 410.65,
      "learning_rate": 0.058951976531935485,
      "loss": 0.7758,
      "step": 254600
    },
    {
      "epoch": 410.68,
      "learning_rate": 0.05894875072870968,
      "loss": 0.781,
      "step": 254620
    },
    {
      "epoch": 410.71,
      "learning_rate": 0.058945524925483876,
      "loss": 0.7869,
      "step": 254640
    },
    {
      "epoch": 410.74,
      "learning_rate": 0.05894229912225807,
      "loss": 0.791,
      "step": 254660
    },
    {
      "epoch": 410.77,
      "learning_rate": 0.058939073319032254,
      "loss": 0.7753,
      "step": 254680
    },
    {
      "epoch": 410.81,
      "learning_rate": 0.058935847515806467,
      "loss": 0.7871,
      "step": 254700
    },
    {
      "epoch": 410.84,
      "learning_rate": 0.05893262171258065,
      "loss": 0.7882,
      "step": 254720
    },
    {
      "epoch": 410.87,
      "learning_rate": 0.058929395909354844,
      "loss": 0.7898,
      "step": 254740
    },
    {
      "epoch": 410.9,
      "learning_rate": 0.05892617010612904,
      "loss": 0.7798,
      "step": 254760
    },
    {
      "epoch": 410.94,
      "learning_rate": 0.058922944302903214,
      "loss": 0.7722,
      "step": 254780
    },
    {
      "epoch": 410.97,
      "learning_rate": 0.05891971849967742,
      "loss": 0.7846,
      "step": 254800
    },
    {
      "epoch": 411.0,
      "learning_rate": 0.058916653986612916,
      "loss": 0.7939,
      "step": 254820
    },
    {
      "epoch": 411.0,
      "eval_accuracy": {
        "accuracy": 0.7554445398485676
      },
      "eval_loss": 1.1552989482879639,
      "eval_runtime": 2.8145,
      "eval_samples_per_second": 4551.806,
      "eval_steps_per_second": 71.416,
      "step": 254820
    },
    {
      "epoch": 411.03,
      "learning_rate": 0.0589134281833871,
      "loss": 0.7792,
      "step": 254840
    },
    {
      "epoch": 411.06,
      "learning_rate": 0.05891020238016129,
      "loss": 0.7727,
      "step": 254860
    },
    {
      "epoch": 411.1,
      "learning_rate": 0.05890697657693549,
      "loss": 0.7657,
      "step": 254880
    },
    {
      "epoch": 411.13,
      "learning_rate": 0.058903750773709684,
      "loss": 0.7476,
      "step": 254900
    },
    {
      "epoch": 411.16,
      "learning_rate": 0.05890052497048387,
      "loss": 0.7875,
      "step": 254920
    },
    {
      "epoch": 411.19,
      "learning_rate": 0.05889729916725808,
      "loss": 0.7711,
      "step": 254940
    },
    {
      "epoch": 411.23,
      "learning_rate": 0.058894073364032254,
      "loss": 0.7736,
      "step": 254960
    },
    {
      "epoch": 411.26,
      "learning_rate": 0.05889084756080646,
      "loss": 0.7793,
      "step": 254980
    },
    {
      "epoch": 411.29,
      "learning_rate": 0.058887621757580645,
      "loss": 0.7637,
      "step": 255000
    },
    {
      "epoch": 411.32,
      "learning_rate": 0.05888439595435485,
      "loss": 0.7765,
      "step": 255020
    },
    {
      "epoch": 411.35,
      "learning_rate": 0.058881170151129036,
      "loss": 0.7587,
      "step": 255040
    },
    {
      "epoch": 411.39,
      "learning_rate": 0.05887794434790322,
      "loss": 0.7827,
      "step": 255060
    },
    {
      "epoch": 411.42,
      "learning_rate": 0.05887471854467742,
      "loss": 0.7869,
      "step": 255080
    },
    {
      "epoch": 411.45,
      "learning_rate": 0.05887149274145162,
      "loss": 0.7809,
      "step": 255100
    },
    {
      "epoch": 411.48,
      "learning_rate": 0.05886826693822581,
      "loss": 0.7879,
      "step": 255120
    },
    {
      "epoch": 411.52,
      "learning_rate": 0.058865041135,
      "loss": 0.8034,
      "step": 255140
    },
    {
      "epoch": 411.55,
      "learning_rate": 0.058861815331774196,
      "loss": 0.8111,
      "step": 255160
    },
    {
      "epoch": 411.58,
      "learning_rate": 0.05885858952854839,
      "loss": 0.8147,
      "step": 255180
    },
    {
      "epoch": 411.61,
      "learning_rate": 0.05885536372532259,
      "loss": 0.8113,
      "step": 255200
    },
    {
      "epoch": 411.65,
      "learning_rate": 0.05885213792209677,
      "loss": 0.8049,
      "step": 255220
    },
    {
      "epoch": 411.68,
      "learning_rate": 0.05884891211887098,
      "loss": 0.7951,
      "step": 255240
    },
    {
      "epoch": 411.71,
      "learning_rate": 0.05884568631564516,
      "loss": 0.7895,
      "step": 255260
    },
    {
      "epoch": 411.74,
      "learning_rate": 0.05884246051241936,
      "loss": 0.7597,
      "step": 255280
    },
    {
      "epoch": 411.77,
      "learning_rate": 0.05883923470919355,
      "loss": 0.7817,
      "step": 255300
    },
    {
      "epoch": 411.81,
      "learning_rate": 0.058836008905967754,
      "loss": 0.7705,
      "step": 255320
    },
    {
      "epoch": 411.84,
      "learning_rate": 0.05883278310274194,
      "loss": 0.7898,
      "step": 255340
    },
    {
      "epoch": 411.87,
      "learning_rate": 0.05882955729951614,
      "loss": 0.7748,
      "step": 255360
    },
    {
      "epoch": 411.9,
      "learning_rate": 0.058826331496290324,
      "loss": 0.789,
      "step": 255380
    },
    {
      "epoch": 411.94,
      "learning_rate": 0.058823105693064516,
      "loss": 0.778,
      "step": 255400
    },
    {
      "epoch": 411.97,
      "learning_rate": 0.058819879889838715,
      "loss": 0.7753,
      "step": 255420
    },
    {
      "epoch": 412.0,
      "learning_rate": 0.05881665408661291,
      "loss": 0.7801,
      "step": 255440
    },
    {
      "epoch": 412.0,
      "eval_accuracy": {
        "accuracy": 0.7514635859807978
      },
      "eval_loss": 1.1875730752944946,
      "eval_runtime": 4.3599,
      "eval_samples_per_second": 2938.392,
      "eval_steps_per_second": 46.102,
      "step": 255440
    },
    {
      "epoch": 412.03,
      "learning_rate": 0.05881342828338709,
      "loss": 0.8067,
      "step": 255460
    },
    {
      "epoch": 412.06,
      "learning_rate": 0.058810202480161305,
      "loss": 0.8031,
      "step": 255480
    },
    {
      "epoch": 412.1,
      "learning_rate": 0.05880697667693549,
      "loss": 0.7958,
      "step": 255500
    },
    {
      "epoch": 412.13,
      "learning_rate": 0.058803750873709676,
      "loss": 0.7695,
      "step": 255520
    },
    {
      "epoch": 412.16,
      "learning_rate": 0.05880052507048388,
      "loss": 0.7561,
      "step": 255540
    },
    {
      "epoch": 412.19,
      "learning_rate": 0.05879729926725805,
      "loss": 0.773,
      "step": 255560
    },
    {
      "epoch": 412.23,
      "learning_rate": 0.05879407346403226,
      "loss": 0.7832,
      "step": 255580
    },
    {
      "epoch": 412.26,
      "learning_rate": 0.058790847660806445,
      "loss": 0.7679,
      "step": 255600
    },
    {
      "epoch": 412.29,
      "learning_rate": 0.05878762185758066,
      "loss": 0.7724,
      "step": 255620
    },
    {
      "epoch": 412.32,
      "learning_rate": 0.05878439605435484,
      "loss": 0.7768,
      "step": 255640
    },
    {
      "epoch": 412.35,
      "learning_rate": 0.058781170251129035,
      "loss": 0.7915,
      "step": 255660
    },
    {
      "epoch": 412.39,
      "learning_rate": 0.05877794444790322,
      "loss": 0.768,
      "step": 255680
    },
    {
      "epoch": 412.42,
      "learning_rate": 0.05877471864467742,
      "loss": 0.7625,
      "step": 255700
    },
    {
      "epoch": 412.45,
      "learning_rate": 0.05877149284145161,
      "loss": 0.7829,
      "step": 255720
    },
    {
      "epoch": 412.48,
      "learning_rate": 0.05876826703822581,
      "loss": 0.7763,
      "step": 255740
    },
    {
      "epoch": 412.52,
      "learning_rate": 0.05876504123500001,
      "loss": 0.7888,
      "step": 255760
    },
    {
      "epoch": 412.55,
      "learning_rate": 0.0587618154317742,
      "loss": 0.7926,
      "step": 255780
    },
    {
      "epoch": 412.58,
      "learning_rate": 0.05875858962854839,
      "loss": 0.7689,
      "step": 255800
    },
    {
      "epoch": 412.61,
      "learning_rate": 0.058755363825322586,
      "loss": 0.7697,
      "step": 255820
    },
    {
      "epoch": 412.65,
      "learning_rate": 0.05875213802209678,
      "loss": 0.7775,
      "step": 255840
    },
    {
      "epoch": 412.68,
      "learning_rate": 0.05874891221887096,
      "loss": 0.7857,
      "step": 255860
    },
    {
      "epoch": 412.71,
      "learning_rate": 0.058745686415645176,
      "loss": 0.7724,
      "step": 255880
    },
    {
      "epoch": 412.74,
      "learning_rate": 0.05874246061241936,
      "loss": 0.7812,
      "step": 255900
    },
    {
      "epoch": 412.77,
      "learning_rate": 0.058739234809193554,
      "loss": 0.772,
      "step": 255920
    },
    {
      "epoch": 412.81,
      "learning_rate": 0.05873600900596774,
      "loss": 0.7816,
      "step": 255940
    },
    {
      "epoch": 412.84,
      "learning_rate": 0.058732783202741945,
      "loss": 0.7908,
      "step": 255960
    },
    {
      "epoch": 412.87,
      "learning_rate": 0.05872955739951613,
      "loss": 0.7923,
      "step": 255980
    },
    {
      "epoch": 412.9,
      "learning_rate": 0.058726331596290315,
      "loss": 0.8096,
      "step": 256000
    },
    {
      "epoch": 412.94,
      "learning_rate": 0.05872310579306453,
      "loss": 0.7874,
      "step": 256020
    },
    {
      "epoch": 412.97,
      "learning_rate": 0.058719879989838714,
      "loss": 0.7845,
      "step": 256040
    },
    {
      "epoch": 413.0,
      "learning_rate": 0.058716654186612906,
      "loss": 0.788,
      "step": 256060
    },
    {
      "epoch": 413.0,
      "eval_accuracy": {
        "accuracy": 0.7553664819295918
      },
      "eval_loss": 1.1448333263397217,
      "eval_runtime": 2.755,
      "eval_samples_per_second": 4650.065,
      "eval_steps_per_second": 72.958,
      "step": 256060
    },
    {
      "epoch": 413.03,
      "learning_rate": 0.058713428383387105,
      "loss": 0.7952,
      "step": 256080
    },
    {
      "epoch": 413.06,
      "learning_rate": 0.0587102025801613,
      "loss": 0.7444,
      "step": 256100
    },
    {
      "epoch": 413.1,
      "learning_rate": 0.05870697677693548,
      "loss": 0.7618,
      "step": 256120
    },
    {
      "epoch": 413.13,
      "learning_rate": 0.058703750973709695,
      "loss": 0.7962,
      "step": 256140
    },
    {
      "epoch": 413.16,
      "learning_rate": 0.05870052517048387,
      "loss": 0.7687,
      "step": 256160
    },
    {
      "epoch": 413.19,
      "learning_rate": 0.05869729936725807,
      "loss": 0.79,
      "step": 256180
    },
    {
      "epoch": 413.23,
      "learning_rate": 0.05869407356403226,
      "loss": 0.7791,
      "step": 256200
    },
    {
      "epoch": 413.26,
      "learning_rate": 0.058690847760806464,
      "loss": 0.8138,
      "step": 256220
    },
    {
      "epoch": 413.29,
      "learning_rate": 0.05868762195758064,
      "loss": 0.7909,
      "step": 256240
    },
    {
      "epoch": 413.32,
      "learning_rate": 0.05868439615435485,
      "loss": 0.7643,
      "step": 256260
    },
    {
      "epoch": 413.35,
      "learning_rate": 0.05868117035112903,
      "loss": 0.7955,
      "step": 256280
    },
    {
      "epoch": 413.39,
      "learning_rate": 0.05867794454790323,
      "loss": 0.7684,
      "step": 256300
    },
    {
      "epoch": 413.42,
      "learning_rate": 0.058674718744677425,
      "loss": 0.7807,
      "step": 256320
    },
    {
      "epoch": 413.45,
      "learning_rate": 0.05867149294145161,
      "loss": 0.7837,
      "step": 256340
    },
    {
      "epoch": 413.48,
      "learning_rate": 0.05866826713822581,
      "loss": 0.7806,
      "step": 256360
    },
    {
      "epoch": 413.52,
      "learning_rate": 0.058665041335,
      "loss": 0.7797,
      "step": 256380
    },
    {
      "epoch": 413.55,
      "learning_rate": 0.0586618155317742,
      "loss": 0.8037,
      "step": 256400
    },
    {
      "epoch": 413.58,
      "learning_rate": 0.0586585897285484,
      "loss": 0.7945,
      "step": 256420
    },
    {
      "epoch": 413.61,
      "learning_rate": 0.058655363925322584,
      "loss": 0.8028,
      "step": 256440
    },
    {
      "epoch": 413.65,
      "learning_rate": 0.05865213812209677,
      "loss": 0.7515,
      "step": 256460
    },
    {
      "epoch": 413.68,
      "learning_rate": 0.058648912318870976,
      "loss": 0.7837,
      "step": 256480
    },
    {
      "epoch": 413.71,
      "learning_rate": 0.05864568651564516,
      "loss": 0.7878,
      "step": 256500
    },
    {
      "epoch": 413.74,
      "learning_rate": 0.05864246071241937,
      "loss": 0.7929,
      "step": 256520
    },
    {
      "epoch": 413.77,
      "learning_rate": 0.05863923490919354,
      "loss": 0.7561,
      "step": 256540
    },
    {
      "epoch": 413.81,
      "learning_rate": 0.05863600910596775,
      "loss": 0.7813,
      "step": 256560
    },
    {
      "epoch": 413.84,
      "learning_rate": 0.058632783302741937,
      "loss": 0.7739,
      "step": 256580
    },
    {
      "epoch": 413.87,
      "learning_rate": 0.05862955749951613,
      "loss": 0.7726,
      "step": 256600
    },
    {
      "epoch": 413.9,
      "learning_rate": 0.05862633169629033,
      "loss": 0.7587,
      "step": 256620
    },
    {
      "epoch": 413.94,
      "learning_rate": 0.05862310589306452,
      "loss": 0.7881,
      "step": 256640
    },
    {
      "epoch": 413.97,
      "learning_rate": 0.058619880089838705,
      "loss": 0.8015,
      "step": 256660
    },
    {
      "epoch": 414.0,
      "learning_rate": 0.05861665428661292,
      "loss": 0.7814,
      "step": 256680
    },
    {
      "epoch": 414.0,
      "eval_accuracy": {
        "accuracy": 0.7531808601982671
      },
      "eval_loss": 1.1315457820892334,
      "eval_runtime": 2.8377,
      "eval_samples_per_second": 4514.57,
      "eval_steps_per_second": 70.832,
      "step": 256680
    },
    {
      "epoch": 414.03,
      "learning_rate": 0.0586134284833871,
      "loss": 0.7942,
      "step": 256700
    },
    {
      "epoch": 414.06,
      "learning_rate": 0.058610202680161295,
      "loss": 0.7695,
      "step": 256720
    },
    {
      "epoch": 414.1,
      "learning_rate": 0.05860697687693548,
      "loss": 0.7638,
      "step": 256740
    },
    {
      "epoch": 414.13,
      "learning_rate": 0.058603751073709666,
      "loss": 0.7714,
      "step": 256760
    },
    {
      "epoch": 414.16,
      "learning_rate": 0.05860052527048387,
      "loss": 0.7539,
      "step": 256780
    },
    {
      "epoch": 414.19,
      "learning_rate": 0.05859729946725806,
      "loss": 0.766,
      "step": 256800
    },
    {
      "epoch": 414.23,
      "learning_rate": 0.05859407366403227,
      "loss": 0.7735,
      "step": 256820
    },
    {
      "epoch": 414.26,
      "learning_rate": 0.058590847860806455,
      "loss": 0.7807,
      "step": 256840
    },
    {
      "epoch": 414.29,
      "learning_rate": 0.05858762205758065,
      "loss": 0.779,
      "step": 256860
    },
    {
      "epoch": 414.32,
      "learning_rate": 0.05858439625435483,
      "loss": 0.7798,
      "step": 256880
    },
    {
      "epoch": 414.35,
      "learning_rate": 0.05858117045112904,
      "loss": 0.798,
      "step": 256900
    },
    {
      "epoch": 414.39,
      "learning_rate": 0.058577944647903224,
      "loss": 0.802,
      "step": 256920
    },
    {
      "epoch": 414.42,
      "learning_rate": 0.05857471884467742,
      "loss": 0.7829,
      "step": 256940
    },
    {
      "epoch": 414.45,
      "learning_rate": 0.05857149304145162,
      "loss": 0.7468,
      "step": 256960
    },
    {
      "epoch": 414.48,
      "learning_rate": 0.05856826723822581,
      "loss": 0.7697,
      "step": 256980
    },
    {
      "epoch": 414.52,
      "learning_rate": 0.058565041435,
      "loss": 0.7814,
      "step": 257000
    },
    {
      "epoch": 414.55,
      "learning_rate": 0.0585618156317742,
      "loss": 0.7815,
      "step": 257020
    },
    {
      "epoch": 414.58,
      "learning_rate": 0.05855858982854839,
      "loss": 0.777,
      "step": 257040
    },
    {
      "epoch": 414.61,
      "learning_rate": 0.05855536402532259,
      "loss": 0.7728,
      "step": 257060
    },
    {
      "epoch": 414.65,
      "learning_rate": 0.05855213822209679,
      "loss": 0.7796,
      "step": 257080
    },
    {
      "epoch": 414.68,
      "learning_rate": 0.058548912418870974,
      "loss": 0.7688,
      "step": 257100
    },
    {
      "epoch": 414.71,
      "learning_rate": 0.058545686615645166,
      "loss": 0.772,
      "step": 257120
    },
    {
      "epoch": 414.74,
      "learning_rate": 0.05854246081241935,
      "loss": 0.7548,
      "step": 257140
    },
    {
      "epoch": 414.77,
      "learning_rate": 0.05853923500919356,
      "loss": 0.781,
      "step": 257160
    },
    {
      "epoch": 414.81,
      "learning_rate": 0.05853600920596774,
      "loss": 0.7721,
      "step": 257180
    },
    {
      "epoch": 414.84,
      "learning_rate": 0.058532783402741956,
      "loss": 0.8057,
      "step": 257200
    },
    {
      "epoch": 414.87,
      "learning_rate": 0.05852955759951614,
      "loss": 0.792,
      "step": 257220
    },
    {
      "epoch": 414.9,
      "learning_rate": 0.058526331796290326,
      "loss": 0.7941,
      "step": 257240
    },
    {
      "epoch": 414.94,
      "learning_rate": 0.05852310599306452,
      "loss": 0.7798,
      "step": 257260
    },
    {
      "epoch": 414.97,
      "learning_rate": 0.058519880189838704,
      "loss": 0.7944,
      "step": 257280
    },
    {
      "epoch": 415.0,
      "learning_rate": 0.058516815676774206,
      "loss": 0.7739,
      "step": 257300
    },
    {
      "epoch": 415.0,
      "eval_accuracy": {
        "accuracy": 0.7575521036609164
      },
      "eval_loss": 1.134413242340088,
      "eval_runtime": 2.8757,
      "eval_samples_per_second": 4454.96,
      "eval_steps_per_second": 69.897,
      "step": 257300
    },
    {
      "epoch": 415.03,
      "learning_rate": 0.05851358987354838,
      "loss": 0.7521,
      "step": 257320
    },
    {
      "epoch": 415.06,
      "learning_rate": 0.05851036407032259,
      "loss": 0.7449,
      "step": 257340
    },
    {
      "epoch": 415.1,
      "learning_rate": 0.058507138267096775,
      "loss": 0.7477,
      "step": 257360
    },
    {
      "epoch": 415.13,
      "learning_rate": 0.05850391246387097,
      "loss": 0.7865,
      "step": 257380
    },
    {
      "epoch": 415.16,
      "learning_rate": 0.05850068666064517,
      "loss": 0.7941,
      "step": 257400
    },
    {
      "epoch": 415.19,
      "learning_rate": 0.05849746085741936,
      "loss": 0.7981,
      "step": 257420
    },
    {
      "epoch": 415.23,
      "learning_rate": 0.058494235054193544,
      "loss": 0.8043,
      "step": 257440
    },
    {
      "epoch": 415.26,
      "learning_rate": 0.05849100925096776,
      "loss": 0.772,
      "step": 257460
    },
    {
      "epoch": 415.29,
      "learning_rate": 0.05848778344774194,
      "loss": 0.7817,
      "step": 257480
    },
    {
      "epoch": 415.32,
      "learning_rate": 0.058484557644516134,
      "loss": 0.78,
      "step": 257500
    },
    {
      "epoch": 415.35,
      "learning_rate": 0.05848133184129032,
      "loss": 0.7994,
      "step": 257520
    },
    {
      "epoch": 415.39,
      "learning_rate": 0.058478106038064505,
      "loss": 0.7903,
      "step": 257540
    },
    {
      "epoch": 415.42,
      "learning_rate": 0.05847488023483871,
      "loss": 0.7824,
      "step": 257560
    },
    {
      "epoch": 415.45,
      "learning_rate": 0.058471654431612896,
      "loss": 0.7662,
      "step": 257580
    },
    {
      "epoch": 415.48,
      "learning_rate": 0.05846842862838711,
      "loss": 0.7678,
      "step": 257600
    },
    {
      "epoch": 415.52,
      "learning_rate": 0.058465202825161294,
      "loss": 0.7647,
      "step": 257620
    },
    {
      "epoch": 415.55,
      "learning_rate": 0.058461977021935486,
      "loss": 0.7657,
      "step": 257640
    },
    {
      "epoch": 415.58,
      "learning_rate": 0.05845875121870967,
      "loss": 0.8124,
      "step": 257660
    },
    {
      "epoch": 415.61,
      "learning_rate": 0.05845552541548387,
      "loss": 0.8091,
      "step": 257680
    },
    {
      "epoch": 415.65,
      "learning_rate": 0.05845229961225806,
      "loss": 0.7729,
      "step": 257700
    },
    {
      "epoch": 415.68,
      "learning_rate": 0.05844907380903226,
      "loss": 0.7704,
      "step": 257720
    },
    {
      "epoch": 415.71,
      "learning_rate": 0.05844584800580646,
      "loss": 0.7607,
      "step": 257740
    },
    {
      "epoch": 415.74,
      "learning_rate": 0.05844262220258065,
      "loss": 0.785,
      "step": 257760
    },
    {
      "epoch": 415.77,
      "learning_rate": 0.05843939639935484,
      "loss": 0.7818,
      "step": 257780
    },
    {
      "epoch": 415.81,
      "learning_rate": 0.05843617059612904,
      "loss": 0.7662,
      "step": 257800
    },
    {
      "epoch": 415.84,
      "learning_rate": 0.05843294479290323,
      "loss": 0.7609,
      "step": 257820
    },
    {
      "epoch": 415.87,
      "learning_rate": 0.058429718989677415,
      "loss": 0.7712,
      "step": 257840
    },
    {
      "epoch": 415.9,
      "learning_rate": 0.05842649318645163,
      "loss": 0.7585,
      "step": 257860
    },
    {
      "epoch": 415.94,
      "learning_rate": 0.05842326738322581,
      "loss": 0.7772,
      "step": 257880
    },
    {
      "epoch": 415.97,
      "learning_rate": 0.058420041580000005,
      "loss": 0.7819,
      "step": 257900
    },
    {
      "epoch": 416.0,
      "learning_rate": 0.05841681577677419,
      "loss": 0.7712,
      "step": 257920
    },
    {
      "epoch": 416.0,
      "eval_accuracy": {
        "accuracy": 0.7548200764967606
      },
      "eval_loss": 1.1406270265579224,
      "eval_runtime": 2.7491,
      "eval_samples_per_second": 4660.155,
      "eval_steps_per_second": 73.116,
      "step": 257920
    },
    {
      "epoch": 416.03,
      "learning_rate": 0.0584135899735484,
      "loss": 0.8048,
      "step": 257940
    },
    {
      "epoch": 416.06,
      "learning_rate": 0.05841036417032258,
      "loss": 0.7623,
      "step": 257960
    },
    {
      "epoch": 416.1,
      "learning_rate": 0.058407138367096795,
      "loss": 0.7767,
      "step": 257980
    },
    {
      "epoch": 416.13,
      "learning_rate": 0.05840391256387098,
      "loss": 0.7698,
      "step": 258000
    },
    {
      "epoch": 416.16,
      "learning_rate": 0.058400686760645165,
      "loss": 0.7844,
      "step": 258020
    },
    {
      "epoch": 416.19,
      "learning_rate": 0.05839746095741936,
      "loss": 0.797,
      "step": 258040
    },
    {
      "epoch": 416.23,
      "learning_rate": 0.05839423515419354,
      "loss": 0.7699,
      "step": 258060
    },
    {
      "epoch": 416.26,
      "learning_rate": 0.05839100935096775,
      "loss": 0.7735,
      "step": 258080
    },
    {
      "epoch": 416.29,
      "learning_rate": 0.058387783547741934,
      "loss": 0.7741,
      "step": 258100
    },
    {
      "epoch": 416.32,
      "learning_rate": 0.05838455774451613,
      "loss": 0.7999,
      "step": 258120
    },
    {
      "epoch": 416.35,
      "learning_rate": 0.05838133194129033,
      "loss": 0.7807,
      "step": 258140
    },
    {
      "epoch": 416.39,
      "learning_rate": 0.058378106138064524,
      "loss": 0.7879,
      "step": 258160
    },
    {
      "epoch": 416.42,
      "learning_rate": 0.05837488033483871,
      "loss": 0.7606,
      "step": 258180
    },
    {
      "epoch": 416.45,
      "learning_rate": 0.058371654531612915,
      "loss": 0.7702,
      "step": 258200
    },
    {
      "epoch": 416.48,
      "learning_rate": 0.058368428728387094,
      "loss": 0.7671,
      "step": 258220
    },
    {
      "epoch": 416.52,
      "learning_rate": 0.0583652029251613,
      "loss": 0.7647,
      "step": 258240
    },
    {
      "epoch": 416.55,
      "learning_rate": 0.058361977121935485,
      "loss": 0.7775,
      "step": 258260
    },
    {
      "epoch": 416.58,
      "learning_rate": 0.05835875131870969,
      "loss": 0.7869,
      "step": 258280
    },
    {
      "epoch": 416.61,
      "learning_rate": 0.058355525515483876,
      "loss": 0.7981,
      "step": 258300
    },
    {
      "epoch": 416.65,
      "learning_rate": 0.05835229971225806,
      "loss": 0.7748,
      "step": 258320
    },
    {
      "epoch": 416.68,
      "learning_rate": 0.05834907390903226,
      "loss": 0.7649,
      "step": 258340
    },
    {
      "epoch": 416.71,
      "learning_rate": 0.05834584810580645,
      "loss": 0.7711,
      "step": 258360
    },
    {
      "epoch": 416.74,
      "learning_rate": 0.05834262230258065,
      "loss": 0.8026,
      "step": 258380
    },
    {
      "epoch": 416.77,
      "learning_rate": 0.05833939649935485,
      "loss": 0.7899,
      "step": 258400
    },
    {
      "epoch": 416.81,
      "learning_rate": 0.058336170696129036,
      "loss": 0.7959,
      "step": 258420
    },
    {
      "epoch": 416.84,
      "learning_rate": 0.05833294489290323,
      "loss": 0.7697,
      "step": 258440
    },
    {
      "epoch": 416.87,
      "learning_rate": 0.05832971908967743,
      "loss": 0.7873,
      "step": 258460
    },
    {
      "epoch": 416.9,
      "learning_rate": 0.05832649328645161,
      "loss": 0.7586,
      "step": 258480
    },
    {
      "epoch": 416.94,
      "learning_rate": 0.05832326748322582,
      "loss": 0.7915,
      "step": 258500
    },
    {
      "epoch": 416.97,
      "learning_rate": 0.05832004167999999,
      "loss": 0.7945,
      "step": 258520
    },
    {
      "epoch": 417.0,
      "learning_rate": 0.0583168158767742,
      "loss": 0.791,
      "step": 258540
    },
    {
      "epoch": 417.0,
      "eval_accuracy": {
        "accuracy": 0.7559909452813988
      },
      "eval_loss": 1.149816632270813,
      "eval_runtime": 2.9016,
      "eval_samples_per_second": 4415.202,
      "eval_steps_per_second": 69.273,
      "step": 258540
    },
    {
      "epoch": 417.03,
      "learning_rate": 0.05831359007354839,
      "loss": 0.7919,
      "step": 258560
    },
    {
      "epoch": 417.06,
      "learning_rate": 0.058310364270322594,
      "loss": 0.7744,
      "step": 258580
    },
    {
      "epoch": 417.1,
      "learning_rate": 0.058307138467096765,
      "loss": 0.7804,
      "step": 258600
    },
    {
      "epoch": 417.13,
      "learning_rate": 0.05830391266387097,
      "loss": 0.7691,
      "step": 258620
    },
    {
      "epoch": 417.16,
      "learning_rate": 0.05830068686064516,
      "loss": 0.7609,
      "step": 258640
    },
    {
      "epoch": 417.19,
      "learning_rate": 0.058297461057419356,
      "loss": 0.7598,
      "step": 258660
    },
    {
      "epoch": 417.23,
      "learning_rate": 0.058294235254193555,
      "loss": 0.7677,
      "step": 258680
    },
    {
      "epoch": 417.26,
      "learning_rate": 0.05829100945096775,
      "loss": 0.7604,
      "step": 258700
    },
    {
      "epoch": 417.29,
      "learning_rate": 0.05828778364774193,
      "loss": 0.764,
      "step": 258720
    },
    {
      "epoch": 417.32,
      "learning_rate": 0.05828455784451614,
      "loss": 0.7878,
      "step": 258740
    },
    {
      "epoch": 417.35,
      "learning_rate": 0.058281332041290324,
      "loss": 0.7704,
      "step": 258760
    },
    {
      "epoch": 417.39,
      "learning_rate": 0.05827810623806451,
      "loss": 0.8001,
      "step": 258780
    },
    {
      "epoch": 417.42,
      "learning_rate": 0.05827488043483872,
      "loss": 0.7682,
      "step": 258800
    },
    {
      "epoch": 417.45,
      "learning_rate": 0.05827165463161291,
      "loss": 0.7359,
      "step": 258820
    },
    {
      "epoch": 417.48,
      "learning_rate": 0.0582684288283871,
      "loss": 0.7465,
      "step": 258840
    },
    {
      "epoch": 417.52,
      "learning_rate": 0.058265203025161284,
      "loss": 0.775,
      "step": 258860
    },
    {
      "epoch": 417.55,
      "learning_rate": 0.05826197722193549,
      "loss": 0.7818,
      "step": 258880
    },
    {
      "epoch": 417.58,
      "learning_rate": 0.058258751418709676,
      "loss": 0.774,
      "step": 258900
    },
    {
      "epoch": 417.61,
      "learning_rate": 0.058255525615483875,
      "loss": 0.7788,
      "step": 258920
    },
    {
      "epoch": 417.65,
      "learning_rate": 0.058252299812258074,
      "loss": 0.8145,
      "step": 258940
    },
    {
      "epoch": 417.68,
      "learning_rate": 0.05824907400903226,
      "loss": 0.7902,
      "step": 258960
    },
    {
      "epoch": 417.71,
      "learning_rate": 0.05824584820580645,
      "loss": 0.795,
      "step": 258980
    },
    {
      "epoch": 417.74,
      "learning_rate": 0.05824262240258065,
      "loss": 0.7829,
      "step": 259000
    },
    {
      "epoch": 417.77,
      "learning_rate": 0.05823939659935484,
      "loss": 0.8058,
      "step": 259020
    },
    {
      "epoch": 417.81,
      "learning_rate": 0.05823617079612904,
      "loss": 0.789,
      "step": 259040
    },
    {
      "epoch": 417.84,
      "learning_rate": 0.05823294499290324,
      "loss": 0.7924,
      "step": 259060
    },
    {
      "epoch": 417.87,
      "learning_rate": 0.058229719189677426,
      "loss": 0.7923,
      "step": 259080
    },
    {
      "epoch": 417.9,
      "learning_rate": 0.05822649338645162,
      "loss": 0.7946,
      "step": 259100
    },
    {
      "epoch": 417.94,
      "learning_rate": 0.0582232675832258,
      "loss": 0.7776,
      "step": 259120
    },
    {
      "epoch": 417.97,
      "learning_rate": 0.05822004178000001,
      "loss": 0.7872,
      "step": 259140
    },
    {
      "epoch": 418.0,
      "learning_rate": 0.058216815976774194,
      "loss": 0.7595,
      "step": 259160
    },
    {
      "epoch": 418.0,
      "eval_accuracy": {
        "accuracy": 0.75255639684646
      },
      "eval_loss": 1.1704705953598022,
      "eval_runtime": 3.1237,
      "eval_samples_per_second": 4101.2,
      "eval_steps_per_second": 64.346,
      "step": 259160
    },
    {
      "epoch": 418.03,
      "learning_rate": 0.05821359017354841,
      "loss": 0.7953,
      "step": 259180
    },
    {
      "epoch": 418.06,
      "learning_rate": 0.05821036437032258,
      "loss": 0.7493,
      "step": 259200
    },
    {
      "epoch": 418.1,
      "learning_rate": 0.058207138567096785,
      "loss": 0.7537,
      "step": 259220
    },
    {
      "epoch": 418.13,
      "learning_rate": 0.05820391276387097,
      "loss": 0.751,
      "step": 259240
    },
    {
      "epoch": 418.16,
      "learning_rate": 0.058200686960645155,
      "loss": 0.7688,
      "step": 259260
    },
    {
      "epoch": 418.19,
      "learning_rate": 0.05819746115741936,
      "loss": 0.7537,
      "step": 259280
    },
    {
      "epoch": 418.23,
      "learning_rate": 0.058194235354193546,
      "loss": 0.7659,
      "step": 259300
    },
    {
      "epoch": 418.26,
      "learning_rate": 0.058191009550967746,
      "loss": 0.7756,
      "step": 259320
    },
    {
      "epoch": 418.29,
      "learning_rate": 0.058187783747741945,
      "loss": 0.7553,
      "step": 259340
    },
    {
      "epoch": 418.32,
      "learning_rate": 0.05818455794451614,
      "loss": 0.7568,
      "step": 259360
    },
    {
      "epoch": 418.35,
      "learning_rate": 0.05818133214129032,
      "loss": 0.7727,
      "step": 259380
    },
    {
      "epoch": 418.39,
      "learning_rate": 0.05817810633806452,
      "loss": 0.7692,
      "step": 259400
    },
    {
      "epoch": 418.42,
      "learning_rate": 0.058174880534838706,
      "loss": 0.7968,
      "step": 259420
    },
    {
      "epoch": 418.45,
      "learning_rate": 0.05817165473161291,
      "loss": 0.7743,
      "step": 259440
    },
    {
      "epoch": 418.48,
      "learning_rate": 0.0581684289283871,
      "loss": 0.7874,
      "step": 259460
    },
    {
      "epoch": 418.52,
      "learning_rate": 0.058165203125161304,
      "loss": 0.7881,
      "step": 259480
    },
    {
      "epoch": 418.55,
      "learning_rate": 0.05816197732193548,
      "loss": 0.7646,
      "step": 259500
    },
    {
      "epoch": 418.58,
      "learning_rate": 0.05815875151870969,
      "loss": 0.793,
      "step": 259520
    },
    {
      "epoch": 418.61,
      "learning_rate": 0.05815552571548387,
      "loss": 0.7798,
      "step": 259540
    },
    {
      "epoch": 418.65,
      "learning_rate": 0.058152299912258065,
      "loss": 0.781,
      "step": 259560
    },
    {
      "epoch": 418.68,
      "learning_rate": 0.058149074109032264,
      "loss": 0.7862,
      "step": 259580
    },
    {
      "epoch": 418.71,
      "learning_rate": 0.05814584830580646,
      "loss": 0.7938,
      "step": 259600
    },
    {
      "epoch": 418.74,
      "learning_rate": 0.05814262250258065,
      "loss": 0.7866,
      "step": 259620
    },
    {
      "epoch": 418.77,
      "learning_rate": 0.05813939669935484,
      "loss": 0.771,
      "step": 259640
    },
    {
      "epoch": 418.81,
      "learning_rate": 0.05813617089612904,
      "loss": 0.7871,
      "step": 259660
    },
    {
      "epoch": 418.84,
      "learning_rate": 0.05813294509290323,
      "loss": 0.7849,
      "step": 259680
    },
    {
      "epoch": 418.87,
      "learning_rate": 0.05812971928967742,
      "loss": 0.7838,
      "step": 259700
    },
    {
      "epoch": 418.9,
      "learning_rate": 0.0581264934864516,
      "loss": 0.7879,
      "step": 259720
    },
    {
      "epoch": 418.94,
      "learning_rate": 0.058123267683225815,
      "loss": 0.797,
      "step": 259740
    },
    {
      "epoch": 418.97,
      "learning_rate": 0.05812004188,
      "loss": 0.8117,
      "step": 259760
    },
    {
      "epoch": 419.0,
      "learning_rate": 0.05811697736693549,
      "loss": 0.8019,
      "step": 259780
    },
    {
      "epoch": 419.0,
      "eval_accuracy": {
        "accuracy": 0.7549761923347124
      },
      "eval_loss": 1.1266026496887207,
      "eval_runtime": 2.7187,
      "eval_samples_per_second": 4712.114,
      "eval_steps_per_second": 73.931,
      "step": 259780
    },
    {
      "epoch": 419.03,
      "learning_rate": 0.05811375156370968,
      "loss": 0.7787,
      "step": 259800
    },
    {
      "epoch": 419.06,
      "learning_rate": 0.05811052576048388,
      "loss": 0.7712,
      "step": 259820
    },
    {
      "epoch": 419.1,
      "learning_rate": 0.05810729995725808,
      "loss": 0.757,
      "step": 259840
    },
    {
      "epoch": 419.13,
      "learning_rate": 0.058104074154032265,
      "loss": 0.7524,
      "step": 259860
    },
    {
      "epoch": 419.16,
      "learning_rate": 0.05810084835080646,
      "loss": 0.7713,
      "step": 259880
    },
    {
      "epoch": 419.19,
      "learning_rate": 0.05809762254758064,
      "loss": 0.7717,
      "step": 259900
    },
    {
      "epoch": 419.23,
      "learning_rate": 0.05809439674435485,
      "loss": 0.7475,
      "step": 259920
    },
    {
      "epoch": 419.26,
      "learning_rate": 0.05809117094112903,
      "loss": 0.7629,
      "step": 259940
    },
    {
      "epoch": 419.29,
      "learning_rate": 0.058087945137903246,
      "loss": 0.7658,
      "step": 259960
    },
    {
      "epoch": 419.32,
      "learning_rate": 0.05808471933467742,
      "loss": 0.7817,
      "step": 259980
    },
    {
      "epoch": 419.35,
      "learning_rate": 0.05808149353145162,
      "loss": 0.779,
      "step": 260000
    },
    {
      "epoch": 419.39,
      "learning_rate": 0.05807826772822581,
      "loss": 0.7905,
      "step": 260020
    },
    {
      "epoch": 419.42,
      "learning_rate": 0.058075041924999994,
      "loss": 0.7664,
      "step": 260040
    },
    {
      "epoch": 419.45,
      "learning_rate": 0.0580718161217742,
      "loss": 0.772,
      "step": 260060
    },
    {
      "epoch": 419.48,
      "learning_rate": 0.058068590318548385,
      "loss": 0.7985,
      "step": 260080
    },
    {
      "epoch": 419.52,
      "learning_rate": 0.058065364515322584,
      "loss": 0.7968,
      "step": 260100
    },
    {
      "epoch": 419.55,
      "learning_rate": 0.058062138712096784,
      "loss": 0.7989,
      "step": 260120
    },
    {
      "epoch": 419.58,
      "learning_rate": 0.058058912908870976,
      "loss": 0.7862,
      "step": 260140
    },
    {
      "epoch": 419.61,
      "learning_rate": 0.05805568710564516,
      "loss": 0.7997,
      "step": 260160
    },
    {
      "epoch": 419.65,
      "learning_rate": 0.05805246130241936,
      "loss": 0.7968,
      "step": 260180
    },
    {
      "epoch": 419.68,
      "learning_rate": 0.058049235499193545,
      "loss": 0.7986,
      "step": 260200
    },
    {
      "epoch": 419.71,
      "learning_rate": 0.05804600969596775,
      "loss": 0.7874,
      "step": 260220
    },
    {
      "epoch": 419.74,
      "learning_rate": 0.058042783892741937,
      "loss": 0.7869,
      "step": 260240
    },
    {
      "epoch": 419.77,
      "learning_rate": 0.05803955808951614,
      "loss": 0.7501,
      "step": 260260
    },
    {
      "epoch": 419.81,
      "learning_rate": 0.05803633228629032,
      "loss": 0.7738,
      "step": 260280
    },
    {
      "epoch": 419.84,
      "learning_rate": 0.05803310648306453,
      "loss": 0.7907,
      "step": 260300
    },
    {
      "epoch": 419.87,
      "learning_rate": 0.05802988067983871,
      "loss": 0.8081,
      "step": 260320
    },
    {
      "epoch": 419.9,
      "learning_rate": 0.058026654876612904,
      "loss": 0.8116,
      "step": 260340
    },
    {
      "epoch": 419.94,
      "learning_rate": 0.0580234290733871,
      "loss": 0.7931,
      "step": 260360
    },
    {
      "epoch": 419.97,
      "learning_rate": 0.0580202032701613,
      "loss": 0.7709,
      "step": 260380
    },
    {
      "epoch": 420.0,
      "learning_rate": 0.05801697746693549,
      "loss": 0.7922,
      "step": 260400
    },
    {
      "epoch": 420.0,
      "eval_accuracy": {
        "accuracy": 0.747404574194052
      },
      "eval_loss": 1.2012876272201538,
      "eval_runtime": 2.8744,
      "eval_samples_per_second": 4456.912,
      "eval_steps_per_second": 69.927,
      "step": 260400
    },
    {
      "epoch": 420.03,
      "learning_rate": 0.05801375166370968,
      "loss": 0.7945,
      "step": 260420
    },
    {
      "epoch": 420.06,
      "learning_rate": 0.05801052586048388,
      "loss": 0.7393,
      "step": 260440
    },
    {
      "epoch": 420.1,
      "learning_rate": 0.05800730005725807,
      "loss": 0.7737,
      "step": 260460
    },
    {
      "epoch": 420.13,
      "learning_rate": 0.058004074254032256,
      "loss": 0.772,
      "step": 260480
    },
    {
      "epoch": 420.16,
      "learning_rate": 0.05800084845080644,
      "loss": 0.7604,
      "step": 260500
    },
    {
      "epoch": 420.19,
      "learning_rate": 0.057997622647580654,
      "loss": 0.7463,
      "step": 260520
    },
    {
      "epoch": 420.23,
      "learning_rate": 0.05799439684435484,
      "loss": 0.765,
      "step": 260540
    },
    {
      "epoch": 420.26,
      "learning_rate": 0.057991171041129046,
      "loss": 0.7718,
      "step": 260560
    },
    {
      "epoch": 420.29,
      "learning_rate": 0.05798794523790322,
      "loss": 0.7673,
      "step": 260580
    },
    {
      "epoch": 420.32,
      "learning_rate": 0.05798471943467742,
      "loss": 0.7648,
      "step": 260600
    },
    {
      "epoch": 420.35,
      "learning_rate": 0.05798149363145161,
      "loss": 0.7769,
      "step": 260620
    },
    {
      "epoch": 420.39,
      "learning_rate": 0.05797826782822581,
      "loss": 0.7812,
      "step": 260640
    },
    {
      "epoch": 420.42,
      "learning_rate": 0.057975042025000006,
      "loss": 0.7618,
      "step": 260660
    },
    {
      "epoch": 420.45,
      "learning_rate": 0.0579718162217742,
      "loss": 0.7447,
      "step": 260680
    },
    {
      "epoch": 420.48,
      "learning_rate": 0.057968590418548384,
      "loss": 0.7894,
      "step": 260700
    },
    {
      "epoch": 420.52,
      "learning_rate": 0.05796536461532258,
      "loss": 0.7745,
      "step": 260720
    },
    {
      "epoch": 420.55,
      "learning_rate": 0.057962138812096775,
      "loss": 0.7789,
      "step": 260740
    },
    {
      "epoch": 420.58,
      "learning_rate": 0.057958913008870974,
      "loss": 0.7701,
      "step": 260760
    },
    {
      "epoch": 420.61,
      "learning_rate": 0.05795568720564517,
      "loss": 0.7631,
      "step": 260780
    },
    {
      "epoch": 420.65,
      "learning_rate": 0.05795246140241936,
      "loss": 0.7829,
      "step": 260800
    },
    {
      "epoch": 420.68,
      "learning_rate": 0.05794923559919355,
      "loss": 0.7766,
      "step": 260820
    },
    {
      "epoch": 420.71,
      "learning_rate": 0.057946009795967736,
      "loss": 0.8031,
      "step": 260840
    },
    {
      "epoch": 420.74,
      "learning_rate": 0.05794278399274194,
      "loss": 0.7734,
      "step": 260860
    },
    {
      "epoch": 420.77,
      "learning_rate": 0.05793955818951613,
      "loss": 0.7829,
      "step": 260880
    },
    {
      "epoch": 420.81,
      "learning_rate": 0.05793633238629034,
      "loss": 0.7673,
      "step": 260900
    },
    {
      "epoch": 420.84,
      "learning_rate": 0.057933106583064525,
      "loss": 0.7761,
      "step": 260920
    },
    {
      "epoch": 420.87,
      "learning_rate": 0.05792988077983871,
      "loss": 0.7731,
      "step": 260940
    },
    {
      "epoch": 420.9,
      "learning_rate": 0.0579266549766129,
      "loss": 0.783,
      "step": 260960
    },
    {
      "epoch": 420.94,
      "learning_rate": 0.0579234291733871,
      "loss": 0.7871,
      "step": 260980
    },
    {
      "epoch": 420.97,
      "learning_rate": 0.057920203370161294,
      "loss": 0.781,
      "step": 261000
    },
    {
      "epoch": 421.0,
      "learning_rate": 0.05791697756693548,
      "loss": 0.7619,
      "step": 261020
    },
    {
      "epoch": 421.0,
      "eval_accuracy": {
        "accuracy": 0.7523222230895324
      },
      "eval_loss": 1.173795461654663,
      "eval_runtime": 3.102,
      "eval_samples_per_second": 4129.893,
      "eval_steps_per_second": 64.797,
      "step": 261020
    },
    {
      "epoch": 421.03,
      "learning_rate": 0.05791375176370969,
      "loss": 0.7922,
      "step": 261040
    },
    {
      "epoch": 421.06,
      "learning_rate": 0.05791052596048388,
      "loss": 0.7815,
      "step": 261060
    },
    {
      "epoch": 421.1,
      "learning_rate": 0.05790730015725807,
      "loss": 0.7871,
      "step": 261080
    },
    {
      "epoch": 421.13,
      "learning_rate": 0.057904074354032255,
      "loss": 0.7869,
      "step": 261100
    },
    {
      "epoch": 421.16,
      "learning_rate": 0.05790084855080646,
      "loss": 0.7521,
      "step": 261120
    },
    {
      "epoch": 421.19,
      "learning_rate": 0.057897622747580646,
      "loss": 0.7691,
      "step": 261140
    },
    {
      "epoch": 421.23,
      "learning_rate": 0.05789439694435486,
      "loss": 0.7584,
      "step": 261160
    },
    {
      "epoch": 421.26,
      "learning_rate": 0.05789117114112903,
      "loss": 0.7752,
      "step": 261180
    },
    {
      "epoch": 421.29,
      "learning_rate": 0.057887945337903236,
      "loss": 0.7591,
      "step": 261200
    },
    {
      "epoch": 421.32,
      "learning_rate": 0.05788471953467742,
      "loss": 0.7694,
      "step": 261220
    },
    {
      "epoch": 421.35,
      "learning_rate": 0.05788149373145161,
      "loss": 0.7595,
      "step": 261240
    },
    {
      "epoch": 421.39,
      "learning_rate": 0.057878267928225806,
      "loss": 0.7943,
      "step": 261260
    },
    {
      "epoch": 421.42,
      "learning_rate": 0.057875042125,
      "loss": 0.7648,
      "step": 261280
    },
    {
      "epoch": 421.45,
      "learning_rate": 0.0578718163217742,
      "loss": 0.7801,
      "step": 261300
    },
    {
      "epoch": 421.48,
      "learning_rate": 0.057868590518548396,
      "loss": 0.7851,
      "step": 261320
    },
    {
      "epoch": 421.52,
      "learning_rate": 0.05786536471532259,
      "loss": 0.7679,
      "step": 261340
    },
    {
      "epoch": 421.55,
      "learning_rate": 0.057862138912096774,
      "loss": 0.7823,
      "step": 261360
    },
    {
      "epoch": 421.58,
      "learning_rate": 0.05785891310887097,
      "loss": 0.7723,
      "step": 261380
    },
    {
      "epoch": 421.61,
      "learning_rate": 0.05785568730564516,
      "loss": 0.7635,
      "step": 261400
    },
    {
      "epoch": 421.65,
      "learning_rate": 0.057852461502419364,
      "loss": 0.7823,
      "step": 261420
    },
    {
      "epoch": 421.68,
      "learning_rate": 0.05784923569919355,
      "loss": 0.7865,
      "step": 261440
    },
    {
      "epoch": 421.71,
      "learning_rate": 0.05784600989596775,
      "loss": 0.7748,
      "step": 261460
    },
    {
      "epoch": 421.74,
      "learning_rate": 0.05784278409274193,
      "loss": 0.7674,
      "step": 261480
    },
    {
      "epoch": 421.77,
      "learning_rate": 0.05783955828951614,
      "loss": 0.7875,
      "step": 261500
    },
    {
      "epoch": 421.81,
      "learning_rate": 0.057836332486290325,
      "loss": 0.7668,
      "step": 261520
    },
    {
      "epoch": 421.84,
      "learning_rate": 0.05783310668306453,
      "loss": 0.7831,
      "step": 261540
    },
    {
      "epoch": 421.87,
      "learning_rate": 0.0578298808798387,
      "loss": 0.7886,
      "step": 261560
    },
    {
      "epoch": 421.9,
      "learning_rate": 0.057826655076612915,
      "loss": 0.775,
      "step": 261580
    },
    {
      "epoch": 421.94,
      "learning_rate": 0.0578234292733871,
      "loss": 0.76,
      "step": 261600
    },
    {
      "epoch": 421.97,
      "learning_rate": 0.05782020347016129,
      "loss": 0.8034,
      "step": 261620
    },
    {
      "epoch": 422.0,
      "learning_rate": 0.05781697766693549,
      "loss": 0.773,
      "step": 261640
    },
    {
      "epoch": 422.0,
      "eval_accuracy": {
        "accuracy": 0.75255639684646
      },
      "eval_loss": 1.1415746212005615,
      "eval_runtime": 2.8526,
      "eval_samples_per_second": 4490.923,
      "eval_steps_per_second": 70.461,
      "step": 261640
    },
    {
      "epoch": 422.03,
      "learning_rate": 0.057813751863709684,
      "loss": 0.7936,
      "step": 261660
    },
    {
      "epoch": 422.06,
      "learning_rate": 0.05781052606048387,
      "loss": 0.7688,
      "step": 261680
    },
    {
      "epoch": 422.1,
      "learning_rate": 0.05780730025725808,
      "loss": 0.7556,
      "step": 261700
    },
    {
      "epoch": 422.13,
      "learning_rate": 0.05780407445403227,
      "loss": 0.766,
      "step": 261720
    },
    {
      "epoch": 422.16,
      "learning_rate": 0.05780084865080645,
      "loss": 0.7694,
      "step": 261740
    },
    {
      "epoch": 422.19,
      "learning_rate": 0.057797622847580644,
      "loss": 0.7701,
      "step": 261760
    },
    {
      "epoch": 422.23,
      "learning_rate": 0.05779439704435483,
      "loss": 0.7679,
      "step": 261780
    },
    {
      "epoch": 422.26,
      "learning_rate": 0.057791171241129036,
      "loss": 0.7489,
      "step": 261800
    },
    {
      "epoch": 422.29,
      "learning_rate": 0.05778794543790322,
      "loss": 0.764,
      "step": 261820
    },
    {
      "epoch": 422.32,
      "learning_rate": 0.057784719634677434,
      "loss": 0.7694,
      "step": 261840
    },
    {
      "epoch": 422.35,
      "learning_rate": 0.05778149383145162,
      "loss": 0.7737,
      "step": 261860
    },
    {
      "epoch": 422.39,
      "learning_rate": 0.05777826802822581,
      "loss": 0.7853,
      "step": 261880
    },
    {
      "epoch": 422.42,
      "learning_rate": 0.057775042224999996,
      "loss": 0.7813,
      "step": 261900
    },
    {
      "epoch": 422.45,
      "learning_rate": 0.057771816421774196,
      "loss": 0.7766,
      "step": 261920
    },
    {
      "epoch": 422.48,
      "learning_rate": 0.05776859061854839,
      "loss": 0.7949,
      "step": 261940
    },
    {
      "epoch": 422.52,
      "learning_rate": 0.05776536481532259,
      "loss": 0.7755,
      "step": 261960
    },
    {
      "epoch": 422.55,
      "learning_rate": 0.057762139012096786,
      "loss": 0.7964,
      "step": 261980
    },
    {
      "epoch": 422.58,
      "learning_rate": 0.05775891320887097,
      "loss": 0.7767,
      "step": 262000
    },
    {
      "epoch": 422.61,
      "learning_rate": 0.05775568740564516,
      "loss": 0.7857,
      "step": 262020
    },
    {
      "epoch": 422.65,
      "learning_rate": 0.05775246160241935,
      "loss": 0.7666,
      "step": 262040
    },
    {
      "epoch": 422.68,
      "learning_rate": 0.057749235799193555,
      "loss": 0.7724,
      "step": 262060
    },
    {
      "epoch": 422.71,
      "learning_rate": 0.05774600999596774,
      "loss": 0.7953,
      "step": 262080
    },
    {
      "epoch": 422.74,
      "learning_rate": 0.05774278419274195,
      "loss": 0.794,
      "step": 262100
    },
    {
      "epoch": 422.77,
      "learning_rate": 0.05773955838951614,
      "loss": 0.7729,
      "step": 262120
    },
    {
      "epoch": 422.81,
      "learning_rate": 0.05773633258629033,
      "loss": 0.7584,
      "step": 262140
    },
    {
      "epoch": 422.84,
      "learning_rate": 0.057733106783064515,
      "loss": 0.7829,
      "step": 262160
    },
    {
      "epoch": 422.87,
      "learning_rate": 0.057729880979838714,
      "loss": 0.7715,
      "step": 262180
    },
    {
      "epoch": 422.9,
      "learning_rate": 0.05772665517661291,
      "loss": 0.7585,
      "step": 262200
    },
    {
      "epoch": 422.94,
      "learning_rate": 0.05772342937338709,
      "loss": 0.7886,
      "step": 262220
    },
    {
      "epoch": 422.97,
      "learning_rate": 0.05772020357016129,
      "loss": 0.7796,
      "step": 262240
    },
    {
      "epoch": 423.0,
      "learning_rate": 0.05771713905709677,
      "loss": 0.7745,
      "step": 262260
    },
    {
      "epoch": 423.0,
      "eval_accuracy": {
        "accuracy": 0.7573179299039887
      },
      "eval_loss": 1.1604816913604736,
      "eval_runtime": 2.9469,
      "eval_samples_per_second": 4347.3,
      "eval_steps_per_second": 68.208,
      "step": 262260
    },
    {
      "epoch": 423.03,
      "learning_rate": 0.05771391325387098,
      "loss": 0.7692,
      "step": 262280
    },
    {
      "epoch": 423.06,
      "learning_rate": 0.057710687450645164,
      "loss": 0.7772,
      "step": 262300
    },
    {
      "epoch": 423.1,
      "learning_rate": 0.057707461647419356,
      "loss": 0.7756,
      "step": 262320
    },
    {
      "epoch": 423.13,
      "learning_rate": 0.05770423584419354,
      "loss": 0.7585,
      "step": 262340
    },
    {
      "epoch": 423.16,
      "learning_rate": 0.057701010040967754,
      "loss": 0.8046,
      "step": 262360
    },
    {
      "epoch": 423.19,
      "learning_rate": 0.05769778423774194,
      "loss": 0.7765,
      "step": 262380
    },
    {
      "epoch": 423.23,
      "learning_rate": 0.05769455843451613,
      "loss": 0.7726,
      "step": 262400
    },
    {
      "epoch": 423.26,
      "learning_rate": 0.05769133263129033,
      "loss": 0.7779,
      "step": 262420
    },
    {
      "epoch": 423.29,
      "learning_rate": 0.05768810682806452,
      "loss": 0.7663,
      "step": 262440
    },
    {
      "epoch": 423.32,
      "learning_rate": 0.05768488102483871,
      "loss": 0.7756,
      "step": 262460
    },
    {
      "epoch": 423.35,
      "learning_rate": 0.05768165522161289,
      "loss": 0.7635,
      "step": 262480
    },
    {
      "epoch": 423.39,
      "learning_rate": 0.057678429418387106,
      "loss": 0.7712,
      "step": 262500
    },
    {
      "epoch": 423.42,
      "learning_rate": 0.05767520361516129,
      "loss": 0.7698,
      "step": 262520
    },
    {
      "epoch": 423.45,
      "learning_rate": 0.05767197781193548,
      "loss": 0.7886,
      "step": 262540
    },
    {
      "epoch": 423.48,
      "learning_rate": 0.05766875200870967,
      "loss": 0.7948,
      "step": 262560
    },
    {
      "epoch": 423.52,
      "learning_rate": 0.057665526205483875,
      "loss": 0.7756,
      "step": 262580
    },
    {
      "epoch": 423.55,
      "learning_rate": 0.05766230040225806,
      "loss": 0.7776,
      "step": 262600
    },
    {
      "epoch": 423.58,
      "learning_rate": 0.05765907459903227,
      "loss": 0.7755,
      "step": 262620
    },
    {
      "epoch": 423.61,
      "learning_rate": 0.05765584879580646,
      "loss": 0.7767,
      "step": 262640
    },
    {
      "epoch": 423.65,
      "learning_rate": 0.05765262299258065,
      "loss": 0.7727,
      "step": 262660
    },
    {
      "epoch": 423.68,
      "learning_rate": 0.057649397189354835,
      "loss": 0.7589,
      "step": 262680
    },
    {
      "epoch": 423.71,
      "learning_rate": 0.057646171386129035,
      "loss": 0.7727,
      "step": 262700
    },
    {
      "epoch": 423.74,
      "learning_rate": 0.05764294558290323,
      "loss": 0.7826,
      "step": 262720
    },
    {
      "epoch": 423.77,
      "learning_rate": 0.057639719779677426,
      "loss": 0.7904,
      "step": 262740
    },
    {
      "epoch": 423.81,
      "learning_rate": 0.057636493976451625,
      "loss": 0.8068,
      "step": 262760
    },
    {
      "epoch": 423.84,
      "learning_rate": 0.05763326817322582,
      "loss": 0.7898,
      "step": 262780
    },
    {
      "epoch": 423.87,
      "learning_rate": 0.05763004237,
      "loss": 0.7662,
      "step": 262800
    },
    {
      "epoch": 423.9,
      "learning_rate": 0.05762681656677419,
      "loss": 0.7784,
      "step": 262820
    },
    {
      "epoch": 423.94,
      "learning_rate": 0.057623590763548393,
      "loss": 0.798,
      "step": 262840
    },
    {
      "epoch": 423.97,
      "learning_rate": 0.05762036496032258,
      "loss": 0.7596,
      "step": 262860
    },
    {
      "epoch": 424.0,
      "learning_rate": 0.05761713915709679,
      "loss": 0.7808,
      "step": 262880
    },
    {
      "epoch": 424.0,
      "eval_accuracy": {
        "accuracy": 0.7529466864413394
      },
      "eval_loss": 1.190150260925293,
      "eval_runtime": 3.2181,
      "eval_samples_per_second": 3980.98,
      "eval_steps_per_second": 62.46,
      "step": 262880
    },
    {
      "epoch": 424.03,
      "learning_rate": 0.05761391335387098,
      "loss": 0.8047,
      "step": 262900
    },
    {
      "epoch": 424.06,
      "learning_rate": 0.05761068755064517,
      "loss": 0.7747,
      "step": 262920
    },
    {
      "epoch": 424.1,
      "learning_rate": 0.057607461747419354,
      "loss": 0.7738,
      "step": 262940
    },
    {
      "epoch": 424.13,
      "learning_rate": 0.05760423594419355,
      "loss": 0.7727,
      "step": 262960
    },
    {
      "epoch": 424.16,
      "learning_rate": 0.057601010140967746,
      "loss": 0.7667,
      "step": 262980
    },
    {
      "epoch": 424.19,
      "learning_rate": 0.05759778433774193,
      "loss": 0.7694,
      "step": 263000
    },
    {
      "epoch": 424.23,
      "learning_rate": 0.057594558534516144,
      "loss": 0.7691,
      "step": 263020
    },
    {
      "epoch": 424.26,
      "learning_rate": 0.05759133273129033,
      "loss": 0.7614,
      "step": 263040
    },
    {
      "epoch": 424.29,
      "learning_rate": 0.05758810692806452,
      "loss": 0.7791,
      "step": 263060
    },
    {
      "epoch": 424.32,
      "learning_rate": 0.057584881124838706,
      "loss": 0.7696,
      "step": 263080
    },
    {
      "epoch": 424.35,
      "learning_rate": 0.05758165532161291,
      "loss": 0.7607,
      "step": 263100
    },
    {
      "epoch": 424.39,
      "learning_rate": 0.05757842951838709,
      "loss": 0.7782,
      "step": 263120
    },
    {
      "epoch": 424.42,
      "learning_rate": 0.0575752037151613,
      "loss": 0.7786,
      "step": 263140
    },
    {
      "epoch": 424.45,
      "learning_rate": 0.05757197791193548,
      "loss": 0.7843,
      "step": 263160
    },
    {
      "epoch": 424.48,
      "learning_rate": 0.05756875210870969,
      "loss": 0.7872,
      "step": 263180
    },
    {
      "epoch": 424.52,
      "learning_rate": 0.05756552630548387,
      "loss": 0.7707,
      "step": 263200
    },
    {
      "epoch": 424.55,
      "learning_rate": 0.05756230050225808,
      "loss": 0.7503,
      "step": 263220
    },
    {
      "epoch": 424.58,
      "learning_rate": 0.05755907469903226,
      "loss": 0.7628,
      "step": 263240
    },
    {
      "epoch": 424.61,
      "learning_rate": 0.05755584889580645,
      "loss": 0.7633,
      "step": 263260
    },
    {
      "epoch": 424.65,
      "learning_rate": 0.05755262309258065,
      "loss": 0.7752,
      "step": 263280
    },
    {
      "epoch": 424.68,
      "learning_rate": 0.05754939728935485,
      "loss": 0.7892,
      "step": 263300
    },
    {
      "epoch": 424.71,
      "learning_rate": 0.05754617148612904,
      "loss": 0.7764,
      "step": 263320
    },
    {
      "epoch": 424.74,
      "learning_rate": 0.057542945682903225,
      "loss": 0.7881,
      "step": 263340
    },
    {
      "epoch": 424.77,
      "learning_rate": 0.057539719879677424,
      "loss": 0.7781,
      "step": 263360
    },
    {
      "epoch": 424.81,
      "learning_rate": 0.057536494076451616,
      "loss": 0.7654,
      "step": 263380
    },
    {
      "epoch": 424.84,
      "learning_rate": 0.057533268273225815,
      "loss": 0.7673,
      "step": 263400
    },
    {
      "epoch": 424.87,
      "learning_rate": 0.05753004246999999,
      "loss": 0.7827,
      "step": 263420
    },
    {
      "epoch": 424.9,
      "learning_rate": 0.0575268166667742,
      "loss": 0.7774,
      "step": 263440
    },
    {
      "epoch": 424.94,
      "learning_rate": 0.057523590863548385,
      "loss": 0.7904,
      "step": 263460
    },
    {
      "epoch": 424.97,
      "learning_rate": 0.05752036506032259,
      "loss": 0.7993,
      "step": 263480
    },
    {
      "epoch": 425.0,
      "learning_rate": 0.057517139257096776,
      "loss": 0.7753,
      "step": 263500
    },
    {
      "epoch": 425.0,
      "eval_accuracy": {
        "accuracy": 0.755834829443447
      },
      "eval_loss": 1.128941297531128,
      "eval_runtime": 2.7678,
      "eval_samples_per_second": 4628.634,
      "eval_steps_per_second": 72.622,
      "step": 263500
    },
    {
      "epoch": 425.03,
      "learning_rate": 0.05751391345387098,
      "loss": 0.7906,
      "step": 263520
    },
    {
      "epoch": 425.06,
      "learning_rate": 0.057510687650645154,
      "loss": 0.7603,
      "step": 263540
    },
    {
      "epoch": 425.1,
      "learning_rate": 0.05750746184741937,
      "loss": 0.7599,
      "step": 263560
    },
    {
      "epoch": 425.13,
      "learning_rate": 0.05750423604419355,
      "loss": 0.757,
      "step": 263580
    },
    {
      "epoch": 425.16,
      "learning_rate": 0.057501010240967744,
      "loss": 0.7488,
      "step": 263600
    },
    {
      "epoch": 425.19,
      "learning_rate": 0.05749778443774193,
      "loss": 0.7494,
      "step": 263620
    },
    {
      "epoch": 425.23,
      "learning_rate": 0.057494558634516135,
      "loss": 0.7664,
      "step": 263640
    },
    {
      "epoch": 425.26,
      "learning_rate": 0.05749133283129032,
      "loss": 0.7645,
      "step": 263660
    },
    {
      "epoch": 425.29,
      "learning_rate": 0.05748810702806452,
      "loss": 0.7522,
      "step": 263680
    },
    {
      "epoch": 425.32,
      "learning_rate": 0.05748488122483872,
      "loss": 0.7703,
      "step": 263700
    },
    {
      "epoch": 425.35,
      "learning_rate": 0.057481655421612904,
      "loss": 0.7808,
      "step": 263720
    },
    {
      "epoch": 425.39,
      "learning_rate": 0.057478429618387096,
      "loss": 0.7663,
      "step": 263740
    },
    {
      "epoch": 425.42,
      "learning_rate": 0.05747520381516128,
      "loss": 0.7773,
      "step": 263760
    },
    {
      "epoch": 425.45,
      "learning_rate": 0.05747197801193549,
      "loss": 0.7795,
      "step": 263780
    },
    {
      "epoch": 425.48,
      "learning_rate": 0.05746875220870967,
      "loss": 0.76,
      "step": 263800
    },
    {
      "epoch": 425.52,
      "learning_rate": 0.057465526405483885,
      "loss": 0.749,
      "step": 263820
    },
    {
      "epoch": 425.55,
      "learning_rate": 0.05746230060225807,
      "loss": 0.7709,
      "step": 263840
    },
    {
      "epoch": 425.58,
      "learning_rate": 0.05745907479903226,
      "loss": 0.7713,
      "step": 263860
    },
    {
      "epoch": 425.61,
      "learning_rate": 0.05745584899580645,
      "loss": 0.7707,
      "step": 263880
    },
    {
      "epoch": 425.65,
      "learning_rate": 0.05745262319258065,
      "loss": 0.7914,
      "step": 263900
    },
    {
      "epoch": 425.68,
      "learning_rate": 0.05744939738935484,
      "loss": 0.7809,
      "step": 263920
    },
    {
      "epoch": 425.71,
      "learning_rate": 0.05744617158612904,
      "loss": 0.7893,
      "step": 263940
    },
    {
      "epoch": 425.74,
      "learning_rate": 0.05744294578290324,
      "loss": 0.7774,
      "step": 263960
    },
    {
      "epoch": 425.77,
      "learning_rate": 0.05743971997967742,
      "loss": 0.789,
      "step": 263980
    },
    {
      "epoch": 425.81,
      "learning_rate": 0.057436494176451615,
      "loss": 0.786,
      "step": 264000
    },
    {
      "epoch": 425.84,
      "learning_rate": 0.057433268373225814,
      "loss": 0.7845,
      "step": 264020
    },
    {
      "epoch": 425.87,
      "learning_rate": 0.057430042570000006,
      "loss": 0.7686,
      "step": 264040
    },
    {
      "epoch": 425.9,
      "learning_rate": 0.05742681676677419,
      "loss": 0.7892,
      "step": 264060
    },
    {
      "epoch": 425.94,
      "learning_rate": 0.057423590963548404,
      "loss": 0.7758,
      "step": 264080
    },
    {
      "epoch": 425.97,
      "learning_rate": 0.05742036516032259,
      "loss": 0.7754,
      "step": 264100
    },
    {
      "epoch": 426.0,
      "learning_rate": 0.05741713935709678,
      "loss": 0.7773,
      "step": 264120
    },
    {
      "epoch": 426.0,
      "eval_accuracy": {
        "accuracy": 0.7567715244711576
      },
      "eval_loss": 1.1586287021636963,
      "eval_runtime": 2.9654,
      "eval_samples_per_second": 4320.135,
      "eval_steps_per_second": 67.781,
      "step": 264120
    },
    {
      "epoch": 426.03,
      "learning_rate": 0.05741391355387097,
      "loss": 0.7785,
      "step": 264140
    },
    {
      "epoch": 426.06,
      "learning_rate": 0.05741068775064517,
      "loss": 0.7663,
      "step": 264160
    },
    {
      "epoch": 426.1,
      "learning_rate": 0.05740746194741936,
      "loss": 0.7593,
      "step": 264180
    },
    {
      "epoch": 426.13,
      "learning_rate": 0.05740423614419354,
      "loss": 0.7447,
      "step": 264200
    },
    {
      "epoch": 426.16,
      "learning_rate": 0.05740101034096774,
      "loss": 0.7551,
      "step": 264220
    },
    {
      "epoch": 426.19,
      "learning_rate": 0.05739778453774194,
      "loss": 0.7586,
      "step": 264240
    },
    {
      "epoch": 426.23,
      "learning_rate": 0.057394558734516134,
      "loss": 0.7365,
      "step": 264260
    },
    {
      "epoch": 426.26,
      "learning_rate": 0.05739133293129032,
      "loss": 0.7505,
      "step": 264280
    },
    {
      "epoch": 426.29,
      "learning_rate": 0.057388107128064525,
      "loss": 0.7645,
      "step": 264300
    },
    {
      "epoch": 426.32,
      "learning_rate": 0.05738488132483871,
      "loss": 0.7635,
      "step": 264320
    },
    {
      "epoch": 426.35,
      "learning_rate": 0.05738165552161291,
      "loss": 0.7814,
      "step": 264340
    },
    {
      "epoch": 426.39,
      "learning_rate": 0.057378429718387094,
      "loss": 0.7698,
      "step": 264360
    },
    {
      "epoch": 426.42,
      "learning_rate": 0.0573752039151613,
      "loss": 0.7641,
      "step": 264380
    },
    {
      "epoch": 426.45,
      "learning_rate": 0.05737197811193548,
      "loss": 0.7474,
      "step": 264400
    },
    {
      "epoch": 426.48,
      "learning_rate": 0.057368752308709685,
      "loss": 0.7955,
      "step": 264420
    },
    {
      "epoch": 426.52,
      "learning_rate": 0.05736552650548387,
      "loss": 0.7977,
      "step": 264440
    },
    {
      "epoch": 426.55,
      "learning_rate": 0.057362300702258076,
      "loss": 0.7761,
      "step": 264460
    },
    {
      "epoch": 426.58,
      "learning_rate": 0.05735907489903226,
      "loss": 0.7557,
      "step": 264480
    },
    {
      "epoch": 426.61,
      "learning_rate": 0.05735584909580646,
      "loss": 0.7477,
      "step": 264500
    },
    {
      "epoch": 426.65,
      "learning_rate": 0.057352623292580646,
      "loss": 0.7705,
      "step": 264520
    },
    {
      "epoch": 426.68,
      "learning_rate": 0.05734939748935484,
      "loss": 0.7471,
      "step": 264540
    },
    {
      "epoch": 426.71,
      "learning_rate": 0.05734617168612904,
      "loss": 0.7641,
      "step": 264560
    },
    {
      "epoch": 426.74,
      "learning_rate": 0.05734294588290323,
      "loss": 0.7888,
      "step": 264580
    },
    {
      "epoch": 426.77,
      "learning_rate": 0.05733972007967743,
      "loss": 0.7991,
      "step": 264600
    },
    {
      "epoch": 426.81,
      "learning_rate": 0.05733649427645163,
      "loss": 0.7953,
      "step": 264620
    },
    {
      "epoch": 426.84,
      "learning_rate": 0.05733326847322581,
      "loss": 0.7787,
      "step": 264640
    },
    {
      "epoch": 426.87,
      "learning_rate": 0.05733004267,
      "loss": 0.7903,
      "step": 264660
    },
    {
      "epoch": 426.9,
      "learning_rate": 0.057326816866774204,
      "loss": 0.7979,
      "step": 264680
    },
    {
      "epoch": 426.94,
      "learning_rate": 0.057323591063548375,
      "loss": 0.7745,
      "step": 264700
    },
    {
      "epoch": 426.97,
      "learning_rate": 0.05732036526032258,
      "loss": 0.7637,
      "step": 264720
    },
    {
      "epoch": 427.0,
      "learning_rate": 0.057317139457096766,
      "loss": 0.7915,
      "step": 264740
    },
    {
      "epoch": 427.0,
      "eval_accuracy": {
        "accuracy": 0.7458434158145344
      },
      "eval_loss": 1.188815712928772,
      "eval_runtime": 3.6665,
      "eval_samples_per_second": 3494.06,
      "eval_steps_per_second": 54.821,
      "step": 264740
    },
    {
      "epoch": 427.03,
      "learning_rate": 0.05731391365387098,
      "loss": 0.7774,
      "step": 264760
    },
    {
      "epoch": 427.06,
      "learning_rate": 0.057310687850645164,
      "loss": 0.7418,
      "step": 264780
    },
    {
      "epoch": 427.1,
      "learning_rate": 0.05730746204741937,
      "loss": 0.7288,
      "step": 264800
    },
    {
      "epoch": 427.13,
      "learning_rate": 0.05730423624419354,
      "loss": 0.7516,
      "step": 264820
    },
    {
      "epoch": 427.16,
      "learning_rate": 0.05730101044096775,
      "loss": 0.7505,
      "step": 264840
    },
    {
      "epoch": 427.19,
      "learning_rate": 0.05729778463774193,
      "loss": 0.788,
      "step": 264860
    },
    {
      "epoch": 427.23,
      "learning_rate": 0.05729455883451613,
      "loss": 0.7678,
      "step": 264880
    },
    {
      "epoch": 427.26,
      "learning_rate": 0.05729133303129033,
      "loss": 0.7565,
      "step": 264900
    },
    {
      "epoch": 427.29,
      "learning_rate": 0.05728810722806452,
      "loss": 0.7816,
      "step": 264920
    },
    {
      "epoch": 427.32,
      "learning_rate": 0.05728488142483871,
      "loss": 0.7768,
      "step": 264940
    },
    {
      "epoch": 427.35,
      "learning_rate": 0.057281655621612894,
      "loss": 0.7828,
      "step": 264960
    },
    {
      "epoch": 427.39,
      "learning_rate": 0.0572784298183871,
      "loss": 0.79,
      "step": 264980
    },
    {
      "epoch": 427.42,
      "learning_rate": 0.057275204015161285,
      "loss": 0.7856,
      "step": 265000
    },
    {
      "epoch": 427.45,
      "learning_rate": 0.0572719782119355,
      "loss": 0.7649,
      "step": 265020
    },
    {
      "epoch": 427.48,
      "learning_rate": 0.05726875240870968,
      "loss": 0.7561,
      "step": 265040
    },
    {
      "epoch": 427.52,
      "learning_rate": 0.057265526605483875,
      "loss": 0.7608,
      "step": 265060
    },
    {
      "epoch": 427.55,
      "learning_rate": 0.05726230080225806,
      "loss": 0.7866,
      "step": 265080
    },
    {
      "epoch": 427.58,
      "learning_rate": 0.05725907499903227,
      "loss": 0.7947,
      "step": 265100
    },
    {
      "epoch": 427.61,
      "learning_rate": 0.05725584919580645,
      "loss": 0.7782,
      "step": 265120
    },
    {
      "epoch": 427.65,
      "learning_rate": 0.05725262339258065,
      "loss": 0.7671,
      "step": 265140
    },
    {
      "epoch": 427.68,
      "learning_rate": 0.05724939758935485,
      "loss": 0.7832,
      "step": 265160
    },
    {
      "epoch": 427.71,
      "learning_rate": 0.057246171786129035,
      "loss": 0.7665,
      "step": 265180
    },
    {
      "epoch": 427.74,
      "learning_rate": 0.05724294598290323,
      "loss": 0.7754,
      "step": 265200
    },
    {
      "epoch": 427.77,
      "learning_rate": 0.05723972017967743,
      "loss": 0.7876,
      "step": 265220
    },
    {
      "epoch": 427.81,
      "learning_rate": 0.05723649437645162,
      "loss": 0.787,
      "step": 265240
    },
    {
      "epoch": 427.84,
      "learning_rate": 0.057233268573225804,
      "loss": 0.7732,
      "step": 265260
    },
    {
      "epoch": 427.87,
      "learning_rate": 0.05723004277000002,
      "loss": 0.781,
      "step": 265280
    },
    {
      "epoch": 427.9,
      "learning_rate": 0.05722681696677419,
      "loss": 0.7872,
      "step": 265300
    },
    {
      "epoch": 427.94,
      "learning_rate": 0.057223591163548394,
      "loss": 0.7664,
      "step": 265320
    },
    {
      "epoch": 427.97,
      "learning_rate": 0.05722036536032258,
      "loss": 0.7784,
      "step": 265340
    },
    {
      "epoch": 428.0,
      "learning_rate": 0.05721730084725807,
      "loss": 0.7693,
      "step": 265360
    },
    {
      "epoch": 428.0,
      "eval_accuracy": {
        "accuracy": 0.7542736710639294
      },
      "eval_loss": 1.1400408744812012,
      "eval_runtime": 2.842,
      "eval_samples_per_second": 4507.816,
      "eval_steps_per_second": 70.726,
      "step": 265360
    },
    {
      "epoch": 428.03,
      "learning_rate": 0.05721407504403227,
      "loss": 0.7649,
      "step": 265380
    },
    {
      "epoch": 428.06,
      "learning_rate": 0.057210849240806466,
      "loss": 0.7687,
      "step": 265400
    },
    {
      "epoch": 428.1,
      "learning_rate": 0.05720762343758065,
      "loss": 0.7435,
      "step": 265420
    },
    {
      "epoch": 428.13,
      "learning_rate": 0.05720439763435484,
      "loss": 0.7467,
      "step": 265440
    },
    {
      "epoch": 428.16,
      "learning_rate": 0.05720117183112904,
      "loss": 0.7654,
      "step": 265460
    },
    {
      "epoch": 428.19,
      "learning_rate": 0.057197946027903214,
      "loss": 0.7422,
      "step": 265480
    },
    {
      "epoch": 428.23,
      "learning_rate": 0.05719472022467742,
      "loss": 0.7567,
      "step": 265500
    },
    {
      "epoch": 428.26,
      "learning_rate": 0.057191494421451605,
      "loss": 0.7577,
      "step": 265520
    },
    {
      "epoch": 428.29,
      "learning_rate": 0.05718826861822582,
      "loss": 0.7643,
      "step": 265540
    },
    {
      "epoch": 428.32,
      "learning_rate": 0.057185042815,
      "loss": 0.7521,
      "step": 265560
    },
    {
      "epoch": 428.35,
      "learning_rate": 0.057181817011774196,
      "loss": 0.757,
      "step": 265580
    },
    {
      "epoch": 428.39,
      "learning_rate": 0.05717859120854838,
      "loss": 0.7508,
      "step": 265600
    },
    {
      "epoch": 428.42,
      "learning_rate": 0.05717536540532259,
      "loss": 0.7634,
      "step": 265620
    },
    {
      "epoch": 428.45,
      "learning_rate": 0.05717213960209677,
      "loss": 0.7398,
      "step": 265640
    },
    {
      "epoch": 428.48,
      "learning_rate": 0.05716891379887097,
      "loss": 0.7576,
      "step": 265660
    },
    {
      "epoch": 428.52,
      "learning_rate": 0.05716568799564517,
      "loss": 0.7539,
      "step": 265680
    },
    {
      "epoch": 428.55,
      "learning_rate": 0.05716246219241936,
      "loss": 0.7677,
      "step": 265700
    },
    {
      "epoch": 428.58,
      "learning_rate": 0.05715923638919355,
      "loss": 0.7806,
      "step": 265720
    },
    {
      "epoch": 428.61,
      "learning_rate": 0.05715601058596773,
      "loss": 0.7764,
      "step": 265740
    },
    {
      "epoch": 428.65,
      "learning_rate": 0.05715278478274194,
      "loss": 0.7565,
      "step": 265760
    },
    {
      "epoch": 428.68,
      "learning_rate": 0.057149558979516124,
      "loss": 0.767,
      "step": 265780
    },
    {
      "epoch": 428.71,
      "learning_rate": 0.05714633317629034,
      "loss": 0.7849,
      "step": 265800
    },
    {
      "epoch": 428.74,
      "learning_rate": 0.05714310737306452,
      "loss": 0.7536,
      "step": 265820
    },
    {
      "epoch": 428.77,
      "learning_rate": 0.057139881569838714,
      "loss": 0.7772,
      "step": 265840
    },
    {
      "epoch": 428.81,
      "learning_rate": 0.0571366557666129,
      "loss": 0.7681,
      "step": 265860
    },
    {
      "epoch": 428.84,
      "learning_rate": 0.0571334299633871,
      "loss": 0.7633,
      "step": 265880
    },
    {
      "epoch": 428.87,
      "learning_rate": 0.05713020416016129,
      "loss": 0.7952,
      "step": 265900
    },
    {
      "epoch": 428.9,
      "learning_rate": 0.05712697835693549,
      "loss": 0.7786,
      "step": 265920
    },
    {
      "epoch": 428.94,
      "learning_rate": 0.05712375255370969,
      "loss": 0.7945,
      "step": 265940
    },
    {
      "epoch": 428.97,
      "learning_rate": 0.057120526750483874,
      "loss": 0.773,
      "step": 265960
    },
    {
      "epoch": 429.0,
      "learning_rate": 0.057117300947258066,
      "loss": 0.7925,
      "step": 265980
    },
    {
      "epoch": 429.0,
      "eval_accuracy": {
        "accuracy": 0.7567715244711576
      },
      "eval_loss": 1.1418886184692383,
      "eval_runtime": 2.7736,
      "eval_samples_per_second": 4618.942,
      "eval_steps_per_second": 72.47,
      "step": 265980
    },
    {
      "epoch": 429.03,
      "learning_rate": 0.057114075144032266,
      "loss": 0.7862,
      "step": 266000
    },
    {
      "epoch": 429.06,
      "learning_rate": 0.05711084934080646,
      "loss": 0.7751,
      "step": 266020
    },
    {
      "epoch": 429.1,
      "learning_rate": 0.05710762353758064,
      "loss": 0.7632,
      "step": 266040
    },
    {
      "epoch": 429.13,
      "learning_rate": 0.057104397734354856,
      "loss": 0.7472,
      "step": 266060
    },
    {
      "epoch": 429.16,
      "learning_rate": 0.05710117193112903,
      "loss": 0.7592,
      "step": 266080
    },
    {
      "epoch": 429.19,
      "learning_rate": 0.05709794612790323,
      "loss": 0.7703,
      "step": 266100
    },
    {
      "epoch": 429.23,
      "learning_rate": 0.05709472032467742,
      "loss": 0.7815,
      "step": 266120
    },
    {
      "epoch": 429.26,
      "learning_rate": 0.057091494521451625,
      "loss": 0.7558,
      "step": 266140
    },
    {
      "epoch": 429.29,
      "learning_rate": 0.05708826871822581,
      "loss": 0.7717,
      "step": 266160
    },
    {
      "epoch": 429.32,
      "learning_rate": 0.05708504291500002,
      "loss": 0.7614,
      "step": 266180
    },
    {
      "epoch": 429.35,
      "learning_rate": 0.057081817111774194,
      "loss": 0.7667,
      "step": 266200
    },
    {
      "epoch": 429.39,
      "learning_rate": 0.05707859130854839,
      "loss": 0.7583,
      "step": 266220
    },
    {
      "epoch": 429.42,
      "learning_rate": 0.057075365505322585,
      "loss": 0.7757,
      "step": 266240
    },
    {
      "epoch": 429.45,
      "learning_rate": 0.05707213970209677,
      "loss": 0.7448,
      "step": 266260
    },
    {
      "epoch": 429.48,
      "learning_rate": 0.05706891389887097,
      "loss": 0.7774,
      "step": 266280
    },
    {
      "epoch": 429.52,
      "learning_rate": 0.05706568809564516,
      "loss": 0.7707,
      "step": 266300
    },
    {
      "epoch": 429.55,
      "learning_rate": 0.05706246229241936,
      "loss": 0.7562,
      "step": 266320
    },
    {
      "epoch": 429.58,
      "learning_rate": 0.05705923648919356,
      "loss": 0.7533,
      "step": 266340
    },
    {
      "epoch": 429.61,
      "learning_rate": 0.05705601068596775,
      "loss": 0.7868,
      "step": 266360
    },
    {
      "epoch": 429.65,
      "learning_rate": 0.05705278488274193,
      "loss": 0.7575,
      "step": 266380
    },
    {
      "epoch": 429.68,
      "learning_rate": 0.057049559079516136,
      "loss": 0.7783,
      "step": 266400
    },
    {
      "epoch": 429.71,
      "learning_rate": 0.05704633327629032,
      "loss": 0.7673,
      "step": 266420
    },
    {
      "epoch": 429.74,
      "learning_rate": 0.05704310747306453,
      "loss": 0.7735,
      "step": 266440
    },
    {
      "epoch": 429.77,
      "learning_rate": 0.05703988166983871,
      "loss": 0.7764,
      "step": 266460
    },
    {
      "epoch": 429.81,
      "learning_rate": 0.05703665586661291,
      "loss": 0.7646,
      "step": 266480
    },
    {
      "epoch": 429.84,
      "learning_rate": 0.0570334300633871,
      "loss": 0.7955,
      "step": 266500
    },
    {
      "epoch": 429.87,
      "learning_rate": 0.05703020426016129,
      "loss": 0.7882,
      "step": 266520
    },
    {
      "epoch": 429.9,
      "learning_rate": 0.05702697845693549,
      "loss": 0.8056,
      "step": 266540
    },
    {
      "epoch": 429.94,
      "learning_rate": 0.05702375265370968,
      "loss": 0.7713,
      "step": 266560
    },
    {
      "epoch": 429.97,
      "learning_rate": 0.057020526850483866,
      "loss": 0.7671,
      "step": 266580
    },
    {
      "epoch": 430.0,
      "learning_rate": 0.05701730104725808,
      "loss": 0.7877,
      "step": 266600
    },
    {
      "epoch": 430.0,
      "eval_accuracy": {
        "accuracy": 0.7491218484115213
      },
      "eval_loss": 1.1954160928726196,
      "eval_runtime": 2.7788,
      "eval_samples_per_second": 4610.238,
      "eval_steps_per_second": 72.333,
      "step": 266600
    },
    {
      "epoch": 430.03,
      "learning_rate": 0.057014075244032264,
      "loss": 0.7796,
      "step": 266620
    },
    {
      "epoch": 430.06,
      "learning_rate": 0.057010849440806456,
      "loss": 0.7731,
      "step": 266640
    },
    {
      "epoch": 430.1,
      "learning_rate": 0.057007623637580655,
      "loss": 0.758,
      "step": 266660
    },
    {
      "epoch": 430.13,
      "learning_rate": 0.05700439783435483,
      "loss": 0.7552,
      "step": 266680
    },
    {
      "epoch": 430.16,
      "learning_rate": 0.05700117203112903,
      "loss": 0.7571,
      "step": 266700
    },
    {
      "epoch": 430.19,
      "learning_rate": 0.05699794622790322,
      "loss": 0.7528,
      "step": 266720
    },
    {
      "epoch": 430.23,
      "learning_rate": 0.05699472042467743,
      "loss": 0.7549,
      "step": 266740
    },
    {
      "epoch": 430.26,
      "learning_rate": 0.056991494621451616,
      "loss": 0.7668,
      "step": 266760
    },
    {
      "epoch": 430.29,
      "learning_rate": 0.05698826881822581,
      "loss": 0.765,
      "step": 266780
    },
    {
      "epoch": 430.32,
      "learning_rate": 0.05698504301499999,
      "loss": 0.7579,
      "step": 266800
    },
    {
      "epoch": 430.35,
      "learning_rate": 0.05698181721177419,
      "loss": 0.7562,
      "step": 266820
    },
    {
      "epoch": 430.39,
      "learning_rate": 0.056978591408548385,
      "loss": 0.7903,
      "step": 266840
    },
    {
      "epoch": 430.42,
      "learning_rate": 0.056975365605322584,
      "loss": 0.7645,
      "step": 266860
    },
    {
      "epoch": 430.45,
      "learning_rate": 0.05697213980209678,
      "loss": 0.7916,
      "step": 266880
    },
    {
      "epoch": 430.48,
      "learning_rate": 0.056968913998870975,
      "loss": 0.7538,
      "step": 266900
    },
    {
      "epoch": 430.52,
      "learning_rate": 0.05696568819564516,
      "loss": 0.7699,
      "step": 266920
    },
    {
      "epoch": 430.55,
      "learning_rate": 0.05696246239241936,
      "loss": 0.7757,
      "step": 266940
    },
    {
      "epoch": 430.58,
      "learning_rate": 0.05695923658919355,
      "loss": 0.8002,
      "step": 266960
    },
    {
      "epoch": 430.61,
      "learning_rate": 0.05695601078596774,
      "loss": 0.7863,
      "step": 266980
    },
    {
      "epoch": 430.65,
      "learning_rate": 0.05695278498274195,
      "loss": 0.7611,
      "step": 267000
    },
    {
      "epoch": 430.68,
      "learning_rate": 0.056949559179516135,
      "loss": 0.7628,
      "step": 267020
    },
    {
      "epoch": 430.71,
      "learning_rate": 0.05694633337629033,
      "loss": 0.7787,
      "step": 267040
    },
    {
      "epoch": 430.74,
      "learning_rate": 0.05694310757306451,
      "loss": 0.7937,
      "step": 267060
    },
    {
      "epoch": 430.77,
      "learning_rate": 0.05693988176983872,
      "loss": 0.8041,
      "step": 267080
    },
    {
      "epoch": 430.81,
      "learning_rate": 0.056936655966612904,
      "loss": 0.7918,
      "step": 267100
    },
    {
      "epoch": 430.84,
      "learning_rate": 0.056933430163387116,
      "loss": 0.7502,
      "step": 267120
    },
    {
      "epoch": 430.87,
      "learning_rate": 0.0569302043601613,
      "loss": 0.7633,
      "step": 267140
    },
    {
      "epoch": 430.9,
      "learning_rate": 0.05692697855693549,
      "loss": 0.7466,
      "step": 267160
    },
    {
      "epoch": 430.94,
      "learning_rate": 0.05692375275370968,
      "loss": 0.7557,
      "step": 267180
    },
    {
      "epoch": 430.97,
      "learning_rate": 0.05692052695048388,
      "loss": 0.7684,
      "step": 267200
    },
    {
      "epoch": 431.0,
      "learning_rate": 0.05691730114725807,
      "loss": 0.7776,
      "step": 267220
    },
    {
      "epoch": 431.0,
      "eval_accuracy": {
        "accuracy": 0.7501366013582078
      },
      "eval_loss": 1.1904398202896118,
      "eval_runtime": 2.7637,
      "eval_samples_per_second": 4635.393,
      "eval_steps_per_second": 72.728,
      "step": 267220
    },
    {
      "epoch": 431.03,
      "learning_rate": 0.056914075344032256,
      "loss": 0.8162,
      "step": 267240
    },
    {
      "epoch": 431.06,
      "learning_rate": 0.056910849540806455,
      "loss": 0.7791,
      "step": 267260
    },
    {
      "epoch": 431.1,
      "learning_rate": 0.05690762373758064,
      "loss": 0.7654,
      "step": 267280
    },
    {
      "epoch": 431.13,
      "learning_rate": 0.056904397934354846,
      "loss": 0.7735,
      "step": 267300
    },
    {
      "epoch": 431.16,
      "learning_rate": 0.05690117213112903,
      "loss": 0.7625,
      "step": 267320
    },
    {
      "epoch": 431.19,
      "learning_rate": 0.05689794632790324,
      "loss": 0.7619,
      "step": 267340
    },
    {
      "epoch": 431.23,
      "learning_rate": 0.056894720524677415,
      "loss": 0.7736,
      "step": 267360
    },
    {
      "epoch": 431.26,
      "learning_rate": 0.05689149472145162,
      "loss": 0.7586,
      "step": 267380
    },
    {
      "epoch": 431.29,
      "learning_rate": 0.05688826891822581,
      "loss": 0.7512,
      "step": 267400
    },
    {
      "epoch": 431.32,
      "learning_rate": 0.05688504311500001,
      "loss": 0.7615,
      "step": 267420
    },
    {
      "epoch": 431.35,
      "learning_rate": 0.0568818173117742,
      "loss": 0.749,
      "step": 267440
    },
    {
      "epoch": 431.39,
      "learning_rate": 0.05687859150854838,
      "loss": 0.7726,
      "step": 267460
    },
    {
      "epoch": 431.42,
      "learning_rate": 0.05687536570532258,
      "loss": 0.7717,
      "step": 267480
    },
    {
      "epoch": 431.45,
      "learning_rate": 0.056872139902096774,
      "loss": 0.7735,
      "step": 267500
    },
    {
      "epoch": 431.48,
      "learning_rate": 0.056868914098870973,
      "loss": 0.7796,
      "step": 267520
    },
    {
      "epoch": 431.52,
      "learning_rate": 0.05686568829564517,
      "loss": 0.7849,
      "step": 267540
    },
    {
      "epoch": 431.55,
      "learning_rate": 0.05686246249241936,
      "loss": 0.761,
      "step": 267560
    },
    {
      "epoch": 431.58,
      "learning_rate": 0.05685923668919355,
      "loss": 0.7655,
      "step": 267580
    },
    {
      "epoch": 431.61,
      "learning_rate": 0.05685601088596775,
      "loss": 0.7666,
      "step": 267600
    },
    {
      "epoch": 431.65,
      "learning_rate": 0.056852785082741934,
      "loss": 0.7724,
      "step": 267620
    },
    {
      "epoch": 431.68,
      "learning_rate": 0.05684955927951614,
      "loss": 0.7822,
      "step": 267640
    },
    {
      "epoch": 431.71,
      "learning_rate": 0.05684633347629031,
      "loss": 0.8049,
      "step": 267660
    },
    {
      "epoch": 431.74,
      "learning_rate": 0.056843107673064525,
      "loss": 0.7666,
      "step": 267680
    },
    {
      "epoch": 431.77,
      "learning_rate": 0.05683988186983871,
      "loss": 0.7658,
      "step": 267700
    },
    {
      "epoch": 431.81,
      "learning_rate": 0.056836656066612916,
      "loss": 0.7741,
      "step": 267720
    },
    {
      "epoch": 431.84,
      "learning_rate": 0.0568334302633871,
      "loss": 0.7779,
      "step": 267740
    },
    {
      "epoch": 431.87,
      "learning_rate": 0.05683020446016129,
      "loss": 0.7851,
      "step": 267760
    },
    {
      "epoch": 431.9,
      "learning_rate": 0.05682697865693548,
      "loss": 0.7735,
      "step": 267780
    },
    {
      "epoch": 431.94,
      "learning_rate": 0.05682375285370968,
      "loss": 0.7774,
      "step": 267800
    },
    {
      "epoch": 431.97,
      "learning_rate": 0.05682052705048388,
      "loss": 0.7705,
      "step": 267820
    },
    {
      "epoch": 432.0,
      "learning_rate": 0.05681746253741935,
      "loss": 0.775,
      "step": 267840
    },
    {
      "epoch": 432.0,
      "eval_accuracy": {
        "accuracy": 0.761064710014831
      },
      "eval_loss": 1.1201094388961792,
      "eval_runtime": 3.1813,
      "eval_samples_per_second": 4026.95,
      "eval_steps_per_second": 63.181,
      "step": 267840
    },
    {
      "epoch": 432.03,
      "learning_rate": 0.05681423673419356,
      "loss": 0.7576,
      "step": 267860
    },
    {
      "epoch": 432.06,
      "learning_rate": 0.05681101093096774,
      "loss": 0.7608,
      "step": 267880
    },
    {
      "epoch": 432.1,
      "learning_rate": 0.05680778512774193,
      "loss": 0.7591,
      "step": 267900
    },
    {
      "epoch": 432.13,
      "learning_rate": 0.05680455932451614,
      "loss": 0.7468,
      "step": 267920
    },
    {
      "epoch": 432.16,
      "learning_rate": 0.056801333521290326,
      "loss": 0.7553,
      "step": 267940
    },
    {
      "epoch": 432.19,
      "learning_rate": 0.05679810771806452,
      "loss": 0.7697,
      "step": 267960
    },
    {
      "epoch": 432.23,
      "learning_rate": 0.05679488191483872,
      "loss": 0.7412,
      "step": 267980
    },
    {
      "epoch": 432.26,
      "learning_rate": 0.05679165611161291,
      "loss": 0.7804,
      "step": 268000
    },
    {
      "epoch": 432.29,
      "learning_rate": 0.056788430308387094,
      "loss": 0.761,
      "step": 268020
    },
    {
      "epoch": 432.32,
      "learning_rate": 0.05678520450516131,
      "loss": 0.7688,
      "step": 268040
    },
    {
      "epoch": 432.35,
      "learning_rate": 0.05678197870193548,
      "loss": 0.7607,
      "step": 268060
    },
    {
      "epoch": 432.39,
      "learning_rate": 0.056778752898709685,
      "loss": 0.7452,
      "step": 268080
    },
    {
      "epoch": 432.42,
      "learning_rate": 0.05677552709548387,
      "loss": 0.7762,
      "step": 268100
    },
    {
      "epoch": 432.45,
      "learning_rate": 0.056772301292258076,
      "loss": 0.7617,
      "step": 268120
    },
    {
      "epoch": 432.48,
      "learning_rate": 0.056769075489032254,
      "loss": 0.7668,
      "step": 268140
    },
    {
      "epoch": 432.52,
      "learning_rate": 0.05676584968580646,
      "loss": 0.7601,
      "step": 268160
    },
    {
      "epoch": 432.55,
      "learning_rate": 0.056762623882580646,
      "loss": 0.7517,
      "step": 268180
    },
    {
      "epoch": 432.58,
      "learning_rate": 0.056759398079354845,
      "loss": 0.7523,
      "step": 268200
    },
    {
      "epoch": 432.61,
      "learning_rate": 0.05675617227612904,
      "loss": 0.7503,
      "step": 268220
    },
    {
      "epoch": 432.65,
      "learning_rate": 0.05675294647290322,
      "loss": 0.753,
      "step": 268240
    },
    {
      "epoch": 432.68,
      "learning_rate": 0.05674972066967742,
      "loss": 0.762,
      "step": 268260
    },
    {
      "epoch": 432.71,
      "learning_rate": 0.05674649486645161,
      "loss": 0.7655,
      "step": 268280
    },
    {
      "epoch": 432.74,
      "learning_rate": 0.05674326906322581,
      "loss": 0.7973,
      "step": 268300
    },
    {
      "epoch": 432.77,
      "learning_rate": 0.05674004326000001,
      "loss": 0.7387,
      "step": 268320
    },
    {
      "epoch": 432.81,
      "learning_rate": 0.0567368174567742,
      "loss": 0.7618,
      "step": 268340
    },
    {
      "epoch": 432.84,
      "learning_rate": 0.05673359165354838,
      "loss": 0.765,
      "step": 268360
    },
    {
      "epoch": 432.87,
      "learning_rate": 0.05673036585032259,
      "loss": 0.7847,
      "step": 268380
    },
    {
      "epoch": 432.9,
      "learning_rate": 0.05672714004709677,
      "loss": 0.7772,
      "step": 268400
    },
    {
      "epoch": 432.94,
      "learning_rate": 0.05672391424387098,
      "loss": 0.7889,
      "step": 268420
    },
    {
      "epoch": 432.97,
      "learning_rate": 0.05672068844064515,
      "loss": 0.7603,
      "step": 268440
    },
    {
      "epoch": 433.0,
      "learning_rate": 0.056717462637419364,
      "loss": 0.7803,
      "step": 268460
    },
    {
      "epoch": 433.0,
      "eval_accuracy": {
        "accuracy": 0.7444383732729686
      },
      "eval_loss": 1.1997239589691162,
      "eval_runtime": 2.8609,
      "eval_samples_per_second": 4477.92,
      "eval_steps_per_second": 70.257,
      "step": 268460
    },
    {
      "epoch": 433.03,
      "learning_rate": 0.05671423683419355,
      "loss": 0.798,
      "step": 268480
    },
    {
      "epoch": 433.06,
      "learning_rate": 0.056711011030967755,
      "loss": 0.7814,
      "step": 268500
    },
    {
      "epoch": 433.1,
      "learning_rate": 0.05670778522774194,
      "loss": 0.7763,
      "step": 268520
    },
    {
      "epoch": 433.13,
      "learning_rate": 0.05670455942451613,
      "loss": 0.7732,
      "step": 268540
    },
    {
      "epoch": 433.16,
      "learning_rate": 0.05670133362129032,
      "loss": 0.7604,
      "step": 268560
    },
    {
      "epoch": 433.19,
      "learning_rate": 0.05669810781806453,
      "loss": 0.7703,
      "step": 268580
    },
    {
      "epoch": 433.23,
      "learning_rate": 0.056694882014838716,
      "loss": 0.7633,
      "step": 268600
    },
    {
      "epoch": 433.26,
      "learning_rate": 0.05669165621161291,
      "loss": 0.7594,
      "step": 268620
    },
    {
      "epoch": 433.29,
      "learning_rate": 0.05668843040838709,
      "loss": 0.7684,
      "step": 268640
    },
    {
      "epoch": 433.32,
      "learning_rate": 0.0566852046051613,
      "loss": 0.7718,
      "step": 268660
    },
    {
      "epoch": 433.35,
      "learning_rate": 0.056681978801935484,
      "loss": 0.7367,
      "step": 268680
    },
    {
      "epoch": 433.39,
      "learning_rate": 0.05667875299870967,
      "loss": 0.7463,
      "step": 268700
    },
    {
      "epoch": 433.42,
      "learning_rate": 0.05667552719548388,
      "loss": 0.7502,
      "step": 268720
    },
    {
      "epoch": 433.45,
      "learning_rate": 0.05667230139225807,
      "loss": 0.7696,
      "step": 268740
    },
    {
      "epoch": 433.48,
      "learning_rate": 0.05666907558903226,
      "loss": 0.7703,
      "step": 268760
    },
    {
      "epoch": 433.52,
      "learning_rate": 0.056665849785806445,
      "loss": 0.7662,
      "step": 268780
    },
    {
      "epoch": 433.55,
      "learning_rate": 0.05666262398258065,
      "loss": 0.7622,
      "step": 268800
    },
    {
      "epoch": 433.58,
      "learning_rate": 0.056659398179354836,
      "loss": 0.7625,
      "step": 268820
    },
    {
      "epoch": 433.61,
      "learning_rate": 0.056656172376129035,
      "loss": 0.7758,
      "step": 268840
    },
    {
      "epoch": 433.65,
      "learning_rate": 0.056652946572903234,
      "loss": 0.7896,
      "step": 268860
    },
    {
      "epoch": 433.68,
      "learning_rate": 0.05664972076967742,
      "loss": 0.7483,
      "step": 268880
    },
    {
      "epoch": 433.71,
      "learning_rate": 0.05664649496645161,
      "loss": 0.758,
      "step": 268900
    },
    {
      "epoch": 433.74,
      "learning_rate": 0.05664326916322581,
      "loss": 0.7847,
      "step": 268920
    },
    {
      "epoch": 433.77,
      "learning_rate": 0.05664004336,
      "loss": 0.7915,
      "step": 268940
    },
    {
      "epoch": 433.81,
      "learning_rate": 0.0566368175567742,
      "loss": 0.7772,
      "step": 268960
    },
    {
      "epoch": 433.84,
      "learning_rate": 0.0566335917535484,
      "loss": 0.7657,
      "step": 268980
    },
    {
      "epoch": 433.87,
      "learning_rate": 0.056630365950322586,
      "loss": 0.7486,
      "step": 269000
    },
    {
      "epoch": 433.9,
      "learning_rate": 0.05662714014709678,
      "loss": 0.7642,
      "step": 269020
    },
    {
      "epoch": 433.94,
      "learning_rate": 0.056623914343870964,
      "loss": 0.7883,
      "step": 269040
    },
    {
      "epoch": 433.97,
      "learning_rate": 0.05662068854064517,
      "loss": 0.762,
      "step": 269060
    },
    {
      "epoch": 434.0,
      "learning_rate": 0.056617462737419355,
      "loss": 0.7711,
      "step": 269080
    },
    {
      "epoch": 434.0,
      "eval_accuracy": {
        "accuracy": 0.7567715244711576
      },
      "eval_loss": 1.1444852352142334,
      "eval_runtime": 2.8411,
      "eval_samples_per_second": 4509.199,
      "eval_steps_per_second": 70.748,
      "step": 269080
    },
    {
      "epoch": 434.03,
      "learning_rate": 0.05661423693419357,
      "loss": 0.7854,
      "step": 269100
    },
    {
      "epoch": 434.06,
      "learning_rate": 0.05661101113096775,
      "loss": 0.7429,
      "step": 269120
    },
    {
      "epoch": 434.1,
      "learning_rate": 0.05660778532774194,
      "loss": 0.7444,
      "step": 269140
    },
    {
      "epoch": 434.13,
      "learning_rate": 0.05660455952451613,
      "loss": 0.7778,
      "step": 269160
    },
    {
      "epoch": 434.16,
      "learning_rate": 0.056601333721290316,
      "loss": 0.7745,
      "step": 269180
    },
    {
      "epoch": 434.19,
      "learning_rate": 0.05659810791806452,
      "loss": 0.7547,
      "step": 269200
    },
    {
      "epoch": 434.23,
      "learning_rate": 0.05659488211483871,
      "loss": 0.7643,
      "step": 269220
    },
    {
      "epoch": 434.26,
      "learning_rate": 0.056591656311612906,
      "loss": 0.7729,
      "step": 269240
    },
    {
      "epoch": 434.29,
      "learning_rate": 0.056588430508387105,
      "loss": 0.7571,
      "step": 269260
    },
    {
      "epoch": 434.32,
      "learning_rate": 0.0565852047051613,
      "loss": 0.7759,
      "step": 269280
    },
    {
      "epoch": 434.35,
      "learning_rate": 0.05658197890193548,
      "loss": 0.798,
      "step": 269300
    },
    {
      "epoch": 434.39,
      "learning_rate": 0.05657875309870969,
      "loss": 0.7701,
      "step": 269320
    },
    {
      "epoch": 434.42,
      "learning_rate": 0.05657552729548387,
      "loss": 0.792,
      "step": 269340
    },
    {
      "epoch": 434.45,
      "learning_rate": 0.05657230149225807,
      "loss": 0.7524,
      "step": 269360
    },
    {
      "epoch": 434.48,
      "learning_rate": 0.05656907568903226,
      "loss": 0.7623,
      "step": 269380
    },
    {
      "epoch": 434.52,
      "learning_rate": 0.056565849885806464,
      "loss": 0.775,
      "step": 269400
    },
    {
      "epoch": 434.55,
      "learning_rate": 0.05656262408258064,
      "loss": 0.7745,
      "step": 269420
    },
    {
      "epoch": 434.58,
      "learning_rate": 0.05655939827935485,
      "loss": 0.786,
      "step": 269440
    },
    {
      "epoch": 434.61,
      "learning_rate": 0.056556172476129034,
      "loss": 0.7691,
      "step": 269460
    },
    {
      "epoch": 434.65,
      "learning_rate": 0.056552946672903226,
      "loss": 0.7833,
      "step": 269480
    },
    {
      "epoch": 434.68,
      "learning_rate": 0.056549720869677425,
      "loss": 0.7731,
      "step": 269500
    },
    {
      "epoch": 434.71,
      "learning_rate": 0.056546495066451624,
      "loss": 0.7461,
      "step": 269520
    },
    {
      "epoch": 434.74,
      "learning_rate": 0.05654326926322581,
      "loss": 0.7342,
      "step": 269540
    },
    {
      "epoch": 434.77,
      "learning_rate": 0.05654004346,
      "loss": 0.7533,
      "step": 269560
    },
    {
      "epoch": 434.81,
      "learning_rate": 0.0565368176567742,
      "loss": 0.7737,
      "step": 269580
    },
    {
      "epoch": 434.84,
      "learning_rate": 0.056533591853548386,
      "loss": 0.779,
      "step": 269600
    },
    {
      "epoch": 434.87,
      "learning_rate": 0.05653036605032259,
      "loss": 0.7761,
      "step": 269620
    },
    {
      "epoch": 434.9,
      "learning_rate": 0.05652714024709676,
      "loss": 0.7824,
      "step": 269640
    },
    {
      "epoch": 434.94,
      "learning_rate": 0.056523914443870976,
      "loss": 0.7938,
      "step": 269660
    },
    {
      "epoch": 434.97,
      "learning_rate": 0.05652068864064516,
      "loss": 0.79,
      "step": 269680
    },
    {
      "epoch": 435.0,
      "learning_rate": 0.05651746283741937,
      "loss": 0.7665,
      "step": 269700
    },
    {
      "epoch": 435.0,
      "eval_accuracy": {
        "accuracy": 0.7600499570681446
      },
      "eval_loss": 1.0844639539718628,
      "eval_runtime": 3.701,
      "eval_samples_per_second": 3461.482,
      "eval_steps_per_second": 54.309,
      "step": 269700
    },
    {
      "epoch": 435.03,
      "learning_rate": 0.05651423703419354,
      "loss": 0.7827,
      "step": 269720
    },
    {
      "epoch": 435.06,
      "learning_rate": 0.056511011230967745,
      "loss": 0.7731,
      "step": 269740
    },
    {
      "epoch": 435.1,
      "learning_rate": 0.05650778542774193,
      "loss": 0.7607,
      "step": 269760
    },
    {
      "epoch": 435.13,
      "learning_rate": 0.05650455962451613,
      "loss": 0.7793,
      "step": 269780
    },
    {
      "epoch": 435.16,
      "learning_rate": 0.05650133382129033,
      "loss": 0.7712,
      "step": 269800
    },
    {
      "epoch": 435.19,
      "learning_rate": 0.05649810801806452,
      "loss": 0.772,
      "step": 269820
    },
    {
      "epoch": 435.23,
      "learning_rate": 0.056494882214838706,
      "loss": 0.7942,
      "step": 269840
    },
    {
      "epoch": 435.26,
      "learning_rate": 0.05649165641161291,
      "loss": 0.7508,
      "step": 269860
    },
    {
      "epoch": 435.29,
      "learning_rate": 0.0564884306083871,
      "loss": 0.745,
      "step": 269880
    },
    {
      "epoch": 435.32,
      "learning_rate": 0.056485204805161296,
      "loss": 0.7677,
      "step": 269900
    },
    {
      "epoch": 435.35,
      "learning_rate": 0.056481979001935495,
      "loss": 0.767,
      "step": 269920
    },
    {
      "epoch": 435.39,
      "learning_rate": 0.05647875319870968,
      "loss": 0.764,
      "step": 269940
    },
    {
      "epoch": 435.42,
      "learning_rate": 0.05647552739548387,
      "loss": 0.7574,
      "step": 269960
    },
    {
      "epoch": 435.45,
      "learning_rate": 0.05647230159225806,
      "loss": 0.7772,
      "step": 269980
    },
    {
      "epoch": 435.48,
      "learning_rate": 0.056469075789032264,
      "loss": 0.7571,
      "step": 270000
    },
    {
      "epoch": 435.52,
      "learning_rate": 0.05646584998580645,
      "loss": 0.7606,
      "step": 270020
    },
    {
      "epoch": 435.55,
      "learning_rate": 0.05646262418258066,
      "loss": 0.7691,
      "step": 270040
    },
    {
      "epoch": 435.58,
      "learning_rate": 0.05645939837935485,
      "loss": 0.7778,
      "step": 270060
    },
    {
      "epoch": 435.61,
      "learning_rate": 0.05645617257612903,
      "loss": 0.7937,
      "step": 270080
    },
    {
      "epoch": 435.65,
      "learning_rate": 0.056452946772903224,
      "loss": 0.7613,
      "step": 270100
    },
    {
      "epoch": 435.68,
      "learning_rate": 0.056449720969677424,
      "loss": 0.7728,
      "step": 270120
    },
    {
      "epoch": 435.71,
      "learning_rate": 0.056446495166451616,
      "loss": 0.7652,
      "step": 270140
    },
    {
      "epoch": 435.74,
      "learning_rate": 0.056443269363225815,
      "loss": 0.79,
      "step": 270160
    },
    {
      "epoch": 435.77,
      "learning_rate": 0.056440043560000014,
      "loss": 0.7798,
      "step": 270180
    },
    {
      "epoch": 435.81,
      "learning_rate": 0.0564368177567742,
      "loss": 0.7835,
      "step": 270200
    },
    {
      "epoch": 435.84,
      "learning_rate": 0.05643359195354839,
      "loss": 0.7748,
      "step": 270220
    },
    {
      "epoch": 435.87,
      "learning_rate": 0.056430366150322576,
      "loss": 0.7714,
      "step": 270240
    },
    {
      "epoch": 435.9,
      "learning_rate": 0.05642714034709678,
      "loss": 0.78,
      "step": 270260
    },
    {
      "epoch": 435.94,
      "learning_rate": 0.05642391454387097,
      "loss": 0.7599,
      "step": 270280
    },
    {
      "epoch": 435.97,
      "learning_rate": 0.05642068874064518,
      "loss": 0.7773,
      "step": 270300
    },
    {
      "epoch": 436.0,
      "learning_rate": 0.05641762422758065,
      "loss": 0.7721,
      "step": 270320
    },
    {
      "epoch": 436.0,
      "eval_accuracy": {
        "accuracy": 0.7598938412301928
      },
      "eval_loss": 1.1084847450256348,
      "eval_runtime": 2.7335,
      "eval_samples_per_second": 4686.625,
      "eval_steps_per_second": 73.531,
      "step": 270320
    },
    {
      "epoch": 436.03,
      "learning_rate": 0.05641439842435484,
      "loss": 0.7533,
      "step": 270340
    },
    {
      "epoch": 436.06,
      "learning_rate": 0.05641117262112904,
      "loss": 0.7373,
      "step": 270360
    },
    {
      "epoch": 436.1,
      "learning_rate": 0.056407946817903225,
      "loss": 0.7368,
      "step": 270380
    },
    {
      "epoch": 436.13,
      "learning_rate": 0.05640472101467743,
      "loss": 0.7496,
      "step": 270400
    },
    {
      "epoch": 436.16,
      "learning_rate": 0.0564014952114516,
      "loss": 0.759,
      "step": 270420
    },
    {
      "epoch": 436.19,
      "learning_rate": 0.056398269408225815,
      "loss": 0.77,
      "step": 270440
    },
    {
      "epoch": 436.23,
      "learning_rate": 0.056395043605,
      "loss": 0.7697,
      "step": 270460
    },
    {
      "epoch": 436.26,
      "learning_rate": 0.056391817801774206,
      "loss": 0.7633,
      "step": 270480
    },
    {
      "epoch": 436.29,
      "learning_rate": 0.05638859199854838,
      "loss": 0.7545,
      "step": 270500
    },
    {
      "epoch": 436.32,
      "learning_rate": 0.056385366195322584,
      "loss": 0.7406,
      "step": 270520
    },
    {
      "epoch": 436.35,
      "learning_rate": 0.05638214039209677,
      "loss": 0.7643,
      "step": 270540
    },
    {
      "epoch": 436.39,
      "learning_rate": 0.05637891458887097,
      "loss": 0.7603,
      "step": 270560
    },
    {
      "epoch": 436.42,
      "learning_rate": 0.05637568878564517,
      "loss": 0.7688,
      "step": 270580
    },
    {
      "epoch": 436.45,
      "learning_rate": 0.05637246298241936,
      "loss": 0.7874,
      "step": 270600
    },
    {
      "epoch": 436.48,
      "learning_rate": 0.056369237179193545,
      "loss": 0.7759,
      "step": 270620
    },
    {
      "epoch": 436.52,
      "learning_rate": 0.05636601137596775,
      "loss": 0.7642,
      "step": 270640
    },
    {
      "epoch": 436.55,
      "learning_rate": 0.056362785572741936,
      "loss": 0.7513,
      "step": 270660
    },
    {
      "epoch": 436.58,
      "learning_rate": 0.05635955976951612,
      "loss": 0.7515,
      "step": 270680
    },
    {
      "epoch": 436.61,
      "learning_rate": 0.056356333966290334,
      "loss": 0.7518,
      "step": 270700
    },
    {
      "epoch": 436.65,
      "learning_rate": 0.05635310816306452,
      "loss": 0.7728,
      "step": 270720
    },
    {
      "epoch": 436.68,
      "learning_rate": 0.05634988235983871,
      "loss": 0.7878,
      "step": 270740
    },
    {
      "epoch": 436.71,
      "learning_rate": 0.0563466565566129,
      "loss": 0.77,
      "step": 270760
    },
    {
      "epoch": 436.74,
      "learning_rate": 0.0563434307533871,
      "loss": 0.7766,
      "step": 270780
    },
    {
      "epoch": 436.77,
      "learning_rate": 0.05634020495016129,
      "loss": 0.7449,
      "step": 270800
    },
    {
      "epoch": 436.81,
      "learning_rate": 0.0563369791469355,
      "loss": 0.7689,
      "step": 270820
    },
    {
      "epoch": 436.84,
      "learning_rate": 0.056333753343709686,
      "loss": 0.7594,
      "step": 270840
    },
    {
      "epoch": 436.87,
      "learning_rate": 0.05633052754048387,
      "loss": 0.777,
      "step": 270860
    },
    {
      "epoch": 436.9,
      "learning_rate": 0.05632730173725806,
      "loss": 0.7734,
      "step": 270880
    },
    {
      "epoch": 436.94,
      "learning_rate": 0.05632407593403226,
      "loss": 0.7661,
      "step": 270900
    },
    {
      "epoch": 436.97,
      "learning_rate": 0.056320850130806455,
      "loss": 0.77,
      "step": 270920
    },
    {
      "epoch": 437.0,
      "learning_rate": 0.056317624327580654,
      "loss": 0.7689,
      "step": 270940
    },
    {
      "epoch": 437.0,
      "eval_accuracy": {
        "accuracy": 0.7496682538443525
      },
      "eval_loss": 1.1607104539871216,
      "eval_runtime": 2.7425,
      "eval_samples_per_second": 4671.225,
      "eval_steps_per_second": 73.29,
      "step": 270940
    },
    {
      "epoch": 437.03,
      "learning_rate": 0.05631439852435485,
      "loss": 0.766,
      "step": 270960
    },
    {
      "epoch": 437.06,
      "learning_rate": 0.05631117272112904,
      "loss": 0.7539,
      "step": 270980
    },
    {
      "epoch": 437.1,
      "learning_rate": 0.05630794691790323,
      "loss": 0.7605,
      "step": 271000
    },
    {
      "epoch": 437.13,
      "learning_rate": 0.056304721114677415,
      "loss": 0.7528,
      "step": 271020
    },
    {
      "epoch": 437.16,
      "learning_rate": 0.05630149531145162,
      "loss": 0.7547,
      "step": 271040
    },
    {
      "epoch": 437.19,
      "learning_rate": 0.05629826950822581,
      "loss": 0.7694,
      "step": 271060
    },
    {
      "epoch": 437.23,
      "learning_rate": 0.05629504370500002,
      "loss": 0.7801,
      "step": 271080
    },
    {
      "epoch": 437.26,
      "learning_rate": 0.05629181790177419,
      "loss": 0.791,
      "step": 271100
    },
    {
      "epoch": 437.29,
      "learning_rate": 0.0562885920985484,
      "loss": 0.7633,
      "step": 271120
    },
    {
      "epoch": 437.32,
      "learning_rate": 0.05628536629532258,
      "loss": 0.7655,
      "step": 271140
    },
    {
      "epoch": 437.35,
      "learning_rate": 0.05628214049209677,
      "loss": 0.7488,
      "step": 271160
    },
    {
      "epoch": 437.39,
      "learning_rate": 0.056278914688870973,
      "loss": 0.7625,
      "step": 271180
    },
    {
      "epoch": 437.42,
      "learning_rate": 0.05627568888564516,
      "loss": 0.7608,
      "step": 271200
    },
    {
      "epoch": 437.45,
      "learning_rate": 0.05627246308241936,
      "loss": 0.7737,
      "step": 271220
    },
    {
      "epoch": 437.48,
      "learning_rate": 0.05626923727919356,
      "loss": 0.7692,
      "step": 271240
    },
    {
      "epoch": 437.52,
      "learning_rate": 0.05626601147596775,
      "loss": 0.7578,
      "step": 271260
    },
    {
      "epoch": 437.55,
      "learning_rate": 0.056262785672741934,
      "loss": 0.7687,
      "step": 271280
    },
    {
      "epoch": 437.58,
      "learning_rate": 0.05625955986951613,
      "loss": 0.7544,
      "step": 271300
    },
    {
      "epoch": 437.61,
      "learning_rate": 0.05625633406629032,
      "loss": 0.7573,
      "step": 271320
    },
    {
      "epoch": 437.65,
      "learning_rate": 0.056253108263064525,
      "loss": 0.7555,
      "step": 271340
    },
    {
      "epoch": 437.68,
      "learning_rate": 0.05624988245983871,
      "loss": 0.7772,
      "step": 271360
    },
    {
      "epoch": 437.71,
      "learning_rate": 0.056246656656612916,
      "loss": 0.7793,
      "step": 271380
    },
    {
      "epoch": 437.74,
      "learning_rate": 0.056243430853387094,
      "loss": 0.7731,
      "step": 271400
    },
    {
      "epoch": 437.77,
      "learning_rate": 0.0562402050501613,
      "loss": 0.7642,
      "step": 271420
    },
    {
      "epoch": 437.81,
      "learning_rate": 0.056236979246935485,
      "loss": 0.7614,
      "step": 271440
    },
    {
      "epoch": 437.84,
      "learning_rate": 0.05623375344370968,
      "loss": 0.7569,
      "step": 271460
    },
    {
      "epoch": 437.87,
      "learning_rate": 0.05623052764048388,
      "loss": 0.771,
      "step": 271480
    },
    {
      "epoch": 437.9,
      "learning_rate": 0.056227301837258076,
      "loss": 0.7853,
      "step": 271500
    },
    {
      "epoch": 437.94,
      "learning_rate": 0.05622407603403226,
      "loss": 0.7757,
      "step": 271520
    },
    {
      "epoch": 437.97,
      "learning_rate": 0.05622085023080645,
      "loss": 0.7842,
      "step": 271540
    },
    {
      "epoch": 438.0,
      "learning_rate": 0.05621762442758065,
      "loss": 0.7798,
      "step": 271560
    },
    {
      "epoch": 438.0,
      "eval_accuracy": {
        "accuracy": 0.7637186792600109
      },
      "eval_loss": 1.1062668561935425,
      "eval_runtime": 3.3562,
      "eval_samples_per_second": 3817.086,
      "eval_steps_per_second": 59.889,
      "step": 271560
    },
    {
      "epoch": 438.03,
      "learning_rate": 0.056214398624354844,
      "loss": 0.7795,
      "step": 271580
    },
    {
      "epoch": 438.06,
      "learning_rate": 0.05621117282112903,
      "loss": 0.7486,
      "step": 271600
    },
    {
      "epoch": 438.1,
      "learning_rate": 0.056207947017903215,
      "loss": 0.7397,
      "step": 271620
    },
    {
      "epoch": 438.13,
      "learning_rate": 0.05620472121467743,
      "loss": 0.7487,
      "step": 271640
    },
    {
      "epoch": 438.16,
      "learning_rate": 0.05620149541145161,
      "loss": 0.7687,
      "step": 271660
    },
    {
      "epoch": 438.19,
      "learning_rate": 0.05619826960822582,
      "loss": 0.7383,
      "step": 271680
    },
    {
      "epoch": 438.23,
      "learning_rate": 0.05619504380499999,
      "loss": 0.7553,
      "step": 271700
    },
    {
      "epoch": 438.26,
      "learning_rate": 0.056191818001774196,
      "loss": 0.7447,
      "step": 271720
    },
    {
      "epoch": 438.29,
      "learning_rate": 0.05618859219854838,
      "loss": 0.7464,
      "step": 271740
    },
    {
      "epoch": 438.32,
      "learning_rate": 0.056185366395322595,
      "loss": 0.7462,
      "step": 271760
    },
    {
      "epoch": 438.35,
      "learning_rate": 0.05618214059209678,
      "loss": 0.7844,
      "step": 271780
    },
    {
      "epoch": 438.39,
      "learning_rate": 0.05617891478887097,
      "loss": 0.7679,
      "step": 271800
    },
    {
      "epoch": 438.42,
      "learning_rate": 0.05617568898564516,
      "loss": 0.7576,
      "step": 271820
    },
    {
      "epoch": 438.45,
      "learning_rate": 0.056172463182419356,
      "loss": 0.7624,
      "step": 271840
    },
    {
      "epoch": 438.48,
      "learning_rate": 0.05616923737919355,
      "loss": 0.7756,
      "step": 271860
    },
    {
      "epoch": 438.52,
      "learning_rate": 0.05616601157596775,
      "loss": 0.7719,
      "step": 271880
    },
    {
      "epoch": 438.55,
      "learning_rate": 0.05616278577274195,
      "loss": 0.7698,
      "step": 271900
    },
    {
      "epoch": 438.58,
      "learning_rate": 0.05615955996951613,
      "loss": 0.7808,
      "step": 271920
    },
    {
      "epoch": 438.61,
      "learning_rate": 0.056156334166290324,
      "loss": 0.7815,
      "step": 271940
    },
    {
      "epoch": 438.65,
      "learning_rate": 0.05615310836306451,
      "loss": 0.7711,
      "step": 271960
    },
    {
      "epoch": 438.68,
      "learning_rate": 0.056149882559838715,
      "loss": 0.7482,
      "step": 271980
    },
    {
      "epoch": 438.71,
      "learning_rate": 0.0561466567566129,
      "loss": 0.7927,
      "step": 272000
    },
    {
      "epoch": 438.74,
      "learning_rate": 0.05614343095338711,
      "loss": 0.7687,
      "step": 272020
    },
    {
      "epoch": 438.77,
      "learning_rate": 0.0561402051501613,
      "loss": 0.7626,
      "step": 272040
    },
    {
      "epoch": 438.81,
      "learning_rate": 0.05613697934693549,
      "loss": 0.7881,
      "step": 272060
    },
    {
      "epoch": 438.84,
      "learning_rate": 0.056133753543709676,
      "loss": 0.7661,
      "step": 272080
    },
    {
      "epoch": 438.87,
      "learning_rate": 0.056130527740483875,
      "loss": 0.7668,
      "step": 272100
    },
    {
      "epoch": 438.9,
      "learning_rate": 0.05612730193725807,
      "loss": 0.7633,
      "step": 272120
    },
    {
      "epoch": 438.94,
      "learning_rate": 0.05612407613403225,
      "loss": 0.748,
      "step": 272140
    },
    {
      "epoch": 438.97,
      "learning_rate": 0.056120850330806465,
      "loss": 0.7615,
      "step": 272160
    },
    {
      "epoch": 439.0,
      "learning_rate": 0.05611762452758065,
      "loss": 0.7731,
      "step": 272180
    },
    {
      "epoch": 439.0,
      "eval_accuracy": {
        "accuracy": 0.7546639606588088
      },
      "eval_loss": 1.140341877937317,
      "eval_runtime": 2.9595,
      "eval_samples_per_second": 4328.791,
      "eval_steps_per_second": 67.917,
      "step": 272180
    },
    {
      "epoch": 439.03,
      "learning_rate": 0.05611439872435484,
      "loss": 0.7783,
      "step": 272200
    },
    {
      "epoch": 439.06,
      "learning_rate": 0.05611117292112904,
      "loss": 0.7683,
      "step": 272220
    },
    {
      "epoch": 439.1,
      "learning_rate": 0.056107947117903234,
      "loss": 0.7761,
      "step": 272240
    },
    {
      "epoch": 439.13,
      "learning_rate": 0.05610472131467742,
      "loss": 0.7623,
      "step": 272260
    },
    {
      "epoch": 439.16,
      "learning_rate": 0.05610149551145162,
      "loss": 0.7818,
      "step": 272280
    },
    {
      "epoch": 439.19,
      "learning_rate": 0.056098269708225804,
      "loss": 0.7455,
      "step": 272300
    },
    {
      "epoch": 439.23,
      "learning_rate": 0.05609504390500001,
      "loss": 0.7546,
      "step": 272320
    },
    {
      "epoch": 439.26,
      "learning_rate": 0.056091818101774195,
      "loss": 0.741,
      "step": 272340
    },
    {
      "epoch": 439.29,
      "learning_rate": 0.0560885922985484,
      "loss": 0.7495,
      "step": 272360
    },
    {
      "epoch": 439.32,
      "learning_rate": 0.05608536649532258,
      "loss": 0.7691,
      "step": 272380
    },
    {
      "epoch": 439.35,
      "learning_rate": 0.05608214069209677,
      "loss": 0.7539,
      "step": 272400
    },
    {
      "epoch": 439.39,
      "learning_rate": 0.05607891488887097,
      "loss": 0.7426,
      "step": 272420
    },
    {
      "epoch": 439.42,
      "learning_rate": 0.05607568908564517,
      "loss": 0.7268,
      "step": 272440
    },
    {
      "epoch": 439.45,
      "learning_rate": 0.05607246328241936,
      "loss": 0.7535,
      "step": 272460
    },
    {
      "epoch": 439.48,
      "learning_rate": 0.05606923747919355,
      "loss": 0.7607,
      "step": 272480
    },
    {
      "epoch": 439.52,
      "learning_rate": 0.056066011675967746,
      "loss": 0.7691,
      "step": 272500
    },
    {
      "epoch": 439.55,
      "learning_rate": 0.05606278587274194,
      "loss": 0.7726,
      "step": 272520
    },
    {
      "epoch": 439.58,
      "learning_rate": 0.05605956006951614,
      "loss": 0.765,
      "step": 272540
    },
    {
      "epoch": 439.61,
      "learning_rate": 0.05605633426629032,
      "loss": 0.7616,
      "step": 272560
    },
    {
      "epoch": 439.65,
      "learning_rate": 0.05605310846306452,
      "loss": 0.7634,
      "step": 272580
    },
    {
      "epoch": 439.68,
      "learning_rate": 0.05604988265983871,
      "loss": 0.7693,
      "step": 272600
    },
    {
      "epoch": 439.71,
      "learning_rate": 0.05604665685661291,
      "loss": 0.7684,
      "step": 272620
    },
    {
      "epoch": 439.74,
      "learning_rate": 0.0560434310533871,
      "loss": 0.7718,
      "step": 272640
    },
    {
      "epoch": 439.77,
      "learning_rate": 0.056040205250161304,
      "loss": 0.7804,
      "step": 272660
    },
    {
      "epoch": 439.81,
      "learning_rate": 0.056036979446935475,
      "loss": 0.7768,
      "step": 272680
    },
    {
      "epoch": 439.84,
      "learning_rate": 0.05603375364370969,
      "loss": 0.7752,
      "step": 272700
    },
    {
      "epoch": 439.87,
      "learning_rate": 0.056030527840483874,
      "loss": 0.7859,
      "step": 272720
    },
    {
      "epoch": 439.9,
      "learning_rate": 0.056027302037258066,
      "loss": 0.7797,
      "step": 272740
    },
    {
      "epoch": 439.94,
      "learning_rate": 0.056024076234032265,
      "loss": 0.7687,
      "step": 272760
    },
    {
      "epoch": 439.97,
      "learning_rate": 0.05602085043080646,
      "loss": 0.753,
      "step": 272780
    },
    {
      "epoch": 440.0,
      "learning_rate": 0.05601762462758064,
      "loss": 0.7726,
      "step": 272800
    },
    {
      "epoch": 440.0,
      "eval_accuracy": {
        "accuracy": 0.7553664819295918
      },
      "eval_loss": 1.1479383707046509,
      "eval_runtime": 2.8933,
      "eval_samples_per_second": 4427.891,
      "eval_steps_per_second": 69.472,
      "step": 272800
    },
    {
      "epoch": 440.03,
      "learning_rate": 0.05601439882435484,
      "loss": 0.797,
      "step": 272820
    },
    {
      "epoch": 440.06,
      "learning_rate": 0.05601117302112904,
      "loss": 0.7769,
      "step": 272840
    },
    {
      "epoch": 440.1,
      "learning_rate": 0.056007947217903226,
      "loss": 0.7642,
      "step": 272860
    },
    {
      "epoch": 440.13,
      "learning_rate": 0.05600472141467742,
      "loss": 0.7333,
      "step": 272880
    },
    {
      "epoch": 440.16,
      "learning_rate": 0.0560014956114516,
      "loss": 0.742,
      "step": 272900
    },
    {
      "epoch": 440.19,
      "learning_rate": 0.05599826980822581,
      "loss": 0.7597,
      "step": 272920
    },
    {
      "epoch": 440.23,
      "learning_rate": 0.055995044004999994,
      "loss": 0.7564,
      "step": 272940
    },
    {
      "epoch": 440.26,
      "learning_rate": 0.05599181820177421,
      "loss": 0.7533,
      "step": 272960
    },
    {
      "epoch": 440.29,
      "learning_rate": 0.05598859239854839,
      "loss": 0.7611,
      "step": 272980
    },
    {
      "epoch": 440.32,
      "learning_rate": 0.055985366595322585,
      "loss": 0.7537,
      "step": 273000
    },
    {
      "epoch": 440.35,
      "learning_rate": 0.05598214079209677,
      "loss": 0.7532,
      "step": 273020
    },
    {
      "epoch": 440.39,
      "learning_rate": 0.05597891498887097,
      "loss": 0.7669,
      "step": 273040
    },
    {
      "epoch": 440.42,
      "learning_rate": 0.05597568918564516,
      "loss": 0.7448,
      "step": 273060
    },
    {
      "epoch": 440.45,
      "learning_rate": 0.05597246338241936,
      "loss": 0.7975,
      "step": 273080
    },
    {
      "epoch": 440.48,
      "learning_rate": 0.05596923757919356,
      "loss": 0.7859,
      "step": 273100
    },
    {
      "epoch": 440.52,
      "learning_rate": 0.055966011775967744,
      "loss": 0.7678,
      "step": 273120
    },
    {
      "epoch": 440.55,
      "learning_rate": 0.05596278597274194,
      "loss": 0.7711,
      "step": 273140
    },
    {
      "epoch": 440.58,
      "learning_rate": 0.055959560169516136,
      "loss": 0.7796,
      "step": 273160
    },
    {
      "epoch": 440.61,
      "learning_rate": 0.05595633436629033,
      "loss": 0.778,
      "step": 273180
    },
    {
      "epoch": 440.65,
      "learning_rate": 0.05595310856306451,
      "loss": 0.7632,
      "step": 273200
    },
    {
      "epoch": 440.68,
      "learning_rate": 0.055949882759838726,
      "loss": 0.7735,
      "step": 273220
    },
    {
      "epoch": 440.71,
      "learning_rate": 0.05594665695661291,
      "loss": 0.7749,
      "step": 273240
    },
    {
      "epoch": 440.74,
      "learning_rate": 0.0559434311533871,
      "loss": 0.7473,
      "step": 273260
    },
    {
      "epoch": 440.77,
      "learning_rate": 0.05594020535016129,
      "loss": 0.7881,
      "step": 273280
    },
    {
      "epoch": 440.81,
      "learning_rate": 0.055936979546935495,
      "loss": 0.7608,
      "step": 273300
    },
    {
      "epoch": 440.84,
      "learning_rate": 0.05593375374370968,
      "loss": 0.7848,
      "step": 273320
    },
    {
      "epoch": 440.87,
      "learning_rate": 0.055930527940483865,
      "loss": 0.7734,
      "step": 273340
    },
    {
      "epoch": 440.9,
      "learning_rate": 0.055927302137258064,
      "loss": 0.7745,
      "step": 273360
    },
    {
      "epoch": 440.94,
      "learning_rate": 0.05592407633403226,
      "loss": 0.7647,
      "step": 273380
    },
    {
      "epoch": 440.97,
      "learning_rate": 0.055920850530806455,
      "loss": 0.7631,
      "step": 273400
    },
    {
      "epoch": 441.0,
      "learning_rate": 0.05591778601774194,
      "loss": 0.771,
      "step": 273420
    },
    {
      "epoch": 441.0,
      "eval_accuracy": {
        "accuracy": 0.7607524783389275
      },
      "eval_loss": 1.112143874168396,
      "eval_runtime": 3.1713,
      "eval_samples_per_second": 4039.61,
      "eval_steps_per_second": 63.38,
      "step": 273420
    },
    {
      "epoch": 441.03,
      "learning_rate": 0.05591456021451614,
      "loss": 0.7523,
      "step": 273440
    },
    {
      "epoch": 441.06,
      "learning_rate": 0.055911334411290314,
      "loss": 0.7508,
      "step": 273460
    },
    {
      "epoch": 441.1,
      "learning_rate": 0.05590810860806453,
      "loss": 0.7464,
      "step": 273480
    },
    {
      "epoch": 441.13,
      "learning_rate": 0.05590488280483871,
      "loss": 0.7628,
      "step": 273500
    },
    {
      "epoch": 441.16,
      "learning_rate": 0.055901657001612905,
      "loss": 0.7666,
      "step": 273520
    },
    {
      "epoch": 441.19,
      "learning_rate": 0.055898431198387104,
      "loss": 0.7632,
      "step": 273540
    },
    {
      "epoch": 441.23,
      "learning_rate": 0.055895205395161296,
      "loss": 0.764,
      "step": 273560
    },
    {
      "epoch": 441.26,
      "learning_rate": 0.05589197959193548,
      "loss": 0.768,
      "step": 273580
    },
    {
      "epoch": 441.29,
      "learning_rate": 0.055888753788709694,
      "loss": 0.764,
      "step": 273600
    },
    {
      "epoch": 441.32,
      "learning_rate": 0.05588552798548388,
      "loss": 0.752,
      "step": 273620
    },
    {
      "epoch": 441.35,
      "learning_rate": 0.055882302182258065,
      "loss": 0.7665,
      "step": 273640
    },
    {
      "epoch": 441.39,
      "learning_rate": 0.05587907637903226,
      "loss": 0.7813,
      "step": 273660
    },
    {
      "epoch": 441.42,
      "learning_rate": 0.05587585057580644,
      "loss": 0.7709,
      "step": 273680
    },
    {
      "epoch": 441.45,
      "learning_rate": 0.05587262477258065,
      "loss": 0.7651,
      "step": 273700
    },
    {
      "epoch": 441.48,
      "learning_rate": 0.05586939896935483,
      "loss": 0.7769,
      "step": 273720
    },
    {
      "epoch": 441.52,
      "learning_rate": 0.055866173166129046,
      "loss": 0.7609,
      "step": 273740
    },
    {
      "epoch": 441.55,
      "learning_rate": 0.05586294736290323,
      "loss": 0.7651,
      "step": 273760
    },
    {
      "epoch": 441.58,
      "learning_rate": 0.055859721559677424,
      "loss": 0.7589,
      "step": 273780
    },
    {
      "epoch": 441.61,
      "learning_rate": 0.05585649575645161,
      "loss": 0.7695,
      "step": 273800
    },
    {
      "epoch": 441.65,
      "learning_rate": 0.05585326995322581,
      "loss": 0.7484,
      "step": 273820
    },
    {
      "epoch": 441.68,
      "learning_rate": 0.05585004415,
      "loss": 0.7564,
      "step": 273840
    },
    {
      "epoch": 441.71,
      "learning_rate": 0.0558468183467742,
      "loss": 0.772,
      "step": 273860
    },
    {
      "epoch": 441.74,
      "learning_rate": 0.0558435925435484,
      "loss": 0.7841,
      "step": 273880
    },
    {
      "epoch": 441.77,
      "learning_rate": 0.05584036674032258,
      "loss": 0.7844,
      "step": 273900
    },
    {
      "epoch": 441.81,
      "learning_rate": 0.055837140937096776,
      "loss": 0.7611,
      "step": 273920
    },
    {
      "epoch": 441.84,
      "learning_rate": 0.05583391513387096,
      "loss": 0.7645,
      "step": 273940
    },
    {
      "epoch": 441.87,
      "learning_rate": 0.05583068933064517,
      "loss": 0.7815,
      "step": 273960
    },
    {
      "epoch": 441.9,
      "learning_rate": 0.05582746352741935,
      "loss": 0.7656,
      "step": 273980
    },
    {
      "epoch": 441.94,
      "learning_rate": 0.055824237724193565,
      "loss": 0.7707,
      "step": 274000
    },
    {
      "epoch": 441.97,
      "learning_rate": 0.05582101192096775,
      "loss": 0.7813,
      "step": 274020
    },
    {
      "epoch": 442.0,
      "learning_rate": 0.05581778611774194,
      "loss": 0.8063,
      "step": 274040
    },
    {
      "epoch": 442.0,
      "eval_accuracy": {
        "accuracy": 0.7529466864413394
      },
      "eval_loss": 1.1561448574066162,
      "eval_runtime": 2.8614,
      "eval_samples_per_second": 4477.232,
      "eval_steps_per_second": 70.246,
      "step": 274040
    },
    {
      "epoch": 442.03,
      "learning_rate": 0.05581456031451613,
      "loss": 0.817,
      "step": 274060
    },
    {
      "epoch": 442.06,
      "learning_rate": 0.055811334511290334,
      "loss": 0.7674,
      "step": 274080
    },
    {
      "epoch": 442.1,
      "learning_rate": 0.05580810870806452,
      "loss": 0.7489,
      "step": 274100
    },
    {
      "epoch": 442.13,
      "learning_rate": 0.055804882904838704,
      "loss": 0.7529,
      "step": 274120
    },
    {
      "epoch": 442.16,
      "learning_rate": 0.05580165710161292,
      "loss": 0.7599,
      "step": 274140
    },
    {
      "epoch": 442.19,
      "learning_rate": 0.0557984312983871,
      "loss": 0.741,
      "step": 274160
    },
    {
      "epoch": 442.23,
      "learning_rate": 0.055795205495161294,
      "loss": 0.7521,
      "step": 274180
    },
    {
      "epoch": 442.26,
      "learning_rate": 0.05579197969193548,
      "loss": 0.7331,
      "step": 274200
    },
    {
      "epoch": 442.29,
      "learning_rate": 0.055788753888709686,
      "loss": 0.744,
      "step": 274220
    },
    {
      "epoch": 442.32,
      "learning_rate": 0.055785528085483864,
      "loss": 0.7379,
      "step": 274240
    },
    {
      "epoch": 442.35,
      "learning_rate": 0.05578230228225807,
      "loss": 0.721,
      "step": 274260
    },
    {
      "epoch": 442.39,
      "learning_rate": 0.055779076479032255,
      "loss": 0.7478,
      "step": 274280
    },
    {
      "epoch": 442.42,
      "learning_rate": 0.05577585067580646,
      "loss": 0.736,
      "step": 274300
    },
    {
      "epoch": 442.45,
      "learning_rate": 0.055772624872580646,
      "loss": 0.7755,
      "step": 274320
    },
    {
      "epoch": 442.48,
      "learning_rate": 0.05576939906935485,
      "loss": 0.7878,
      "step": 274340
    },
    {
      "epoch": 442.52,
      "learning_rate": 0.05576617326612903,
      "loss": 0.7667,
      "step": 274360
    },
    {
      "epoch": 442.55,
      "learning_rate": 0.05576294746290324,
      "loss": 0.7658,
      "step": 274380
    },
    {
      "epoch": 442.58,
      "learning_rate": 0.05575972165967742,
      "loss": 0.7654,
      "step": 274400
    },
    {
      "epoch": 442.61,
      "learning_rate": 0.05575649585645162,
      "loss": 0.7625,
      "step": 274420
    },
    {
      "epoch": 442.65,
      "learning_rate": 0.055753270053225806,
      "loss": 0.7639,
      "step": 274440
    },
    {
      "epoch": 442.68,
      "learning_rate": 0.05575004425,
      "loss": 0.7777,
      "step": 274460
    },
    {
      "epoch": 442.71,
      "learning_rate": 0.0557468184467742,
      "loss": 0.7624,
      "step": 274480
    },
    {
      "epoch": 442.74,
      "learning_rate": 0.05574359264354839,
      "loss": 0.7743,
      "step": 274500
    },
    {
      "epoch": 442.77,
      "learning_rate": 0.05574036684032259,
      "loss": 0.757,
      "step": 274520
    },
    {
      "epoch": 442.81,
      "learning_rate": 0.05573714103709679,
      "loss": 0.7731,
      "step": 274540
    },
    {
      "epoch": 442.84,
      "learning_rate": 0.05573391523387097,
      "loss": 0.7529,
      "step": 274560
    },
    {
      "epoch": 442.87,
      "learning_rate": 0.05573068943064516,
      "loss": 0.781,
      "step": 274580
    },
    {
      "epoch": 442.9,
      "learning_rate": 0.055727463627419364,
      "loss": 0.7829,
      "step": 274600
    },
    {
      "epoch": 442.94,
      "learning_rate": 0.05572423782419355,
      "loss": 0.7779,
      "step": 274620
    },
    {
      "epoch": 442.97,
      "learning_rate": 0.055721012020967756,
      "loss": 0.7742,
      "step": 274640
    },
    {
      "epoch": 443.0,
      "learning_rate": 0.05571778621774193,
      "loss": 0.7715,
      "step": 274660
    },
    {
      "epoch": 443.0,
      "eval_accuracy": {
        "accuracy": 0.7505268909530872
      },
      "eval_loss": 1.162031650543213,
      "eval_runtime": 2.9862,
      "eval_samples_per_second": 4290.048,
      "eval_steps_per_second": 67.309,
      "step": 274660
    },
    {
      "epoch": 443.03,
      "learning_rate": 0.05571456041451614,
      "loss": 0.7895,
      "step": 274680
    },
    {
      "epoch": 443.06,
      "learning_rate": 0.055711334611290325,
      "loss": 0.7358,
      "step": 274700
    },
    {
      "epoch": 443.1,
      "learning_rate": 0.05570810880806452,
      "loss": 0.7586,
      "step": 274720
    },
    {
      "epoch": 443.13,
      "learning_rate": 0.0557048830048387,
      "loss": 0.7581,
      "step": 274740
    },
    {
      "epoch": 443.16,
      "learning_rate": 0.05570165720161291,
      "loss": 0.7224,
      "step": 274760
    },
    {
      "epoch": 443.19,
      "learning_rate": 0.055698431398387094,
      "loss": 0.7427,
      "step": 274780
    },
    {
      "epoch": 443.23,
      "learning_rate": 0.05569520559516129,
      "loss": 0.7493,
      "step": 274800
    },
    {
      "epoch": 443.26,
      "learning_rate": 0.05569197979193549,
      "loss": 0.7526,
      "step": 274820
    },
    {
      "epoch": 443.29,
      "learning_rate": 0.055688753988709684,
      "loss": 0.7583,
      "step": 274840
    },
    {
      "epoch": 443.32,
      "learning_rate": 0.05568552818548387,
      "loss": 0.7529,
      "step": 274860
    },
    {
      "epoch": 443.35,
      "learning_rate": 0.055682302382258055,
      "loss": 0.77,
      "step": 274880
    },
    {
      "epoch": 443.39,
      "learning_rate": 0.05567907657903226,
      "loss": 0.7777,
      "step": 274900
    },
    {
      "epoch": 443.42,
      "learning_rate": 0.055675850775806446,
      "loss": 0.7596,
      "step": 274920
    },
    {
      "epoch": 443.45,
      "learning_rate": 0.05567262497258066,
      "loss": 0.7607,
      "step": 274940
    },
    {
      "epoch": 443.48,
      "learning_rate": 0.055669399169354844,
      "loss": 0.7489,
      "step": 274960
    },
    {
      "epoch": 443.52,
      "learning_rate": 0.055666173366129036,
      "loss": 0.7511,
      "step": 274980
    },
    {
      "epoch": 443.55,
      "learning_rate": 0.05566294756290322,
      "loss": 0.7739,
      "step": 275000
    },
    {
      "epoch": 443.58,
      "learning_rate": 0.05565972175967742,
      "loss": 0.7682,
      "step": 275020
    },
    {
      "epoch": 443.61,
      "learning_rate": 0.05565649595645161,
      "loss": 0.7355,
      "step": 275040
    },
    {
      "epoch": 443.65,
      "learning_rate": 0.05565327015322581,
      "loss": 0.7464,
      "step": 275060
    },
    {
      "epoch": 443.68,
      "learning_rate": 0.05565004435000001,
      "loss": 0.7295,
      "step": 275080
    },
    {
      "epoch": 443.71,
      "learning_rate": 0.055646818546774196,
      "loss": 0.7678,
      "step": 275100
    },
    {
      "epoch": 443.74,
      "learning_rate": 0.05564359274354839,
      "loss": 0.7672,
      "step": 275120
    },
    {
      "epoch": 443.77,
      "learning_rate": 0.05564036694032259,
      "loss": 0.7504,
      "step": 275140
    },
    {
      "epoch": 443.81,
      "learning_rate": 0.05563714113709678,
      "loss": 0.7656,
      "step": 275160
    },
    {
      "epoch": 443.84,
      "learning_rate": 0.055633915333870965,
      "loss": 0.7814,
      "step": 275180
    },
    {
      "epoch": 443.87,
      "learning_rate": 0.05563068953064518,
      "loss": 0.7559,
      "step": 275200
    },
    {
      "epoch": 443.9,
      "learning_rate": 0.05562746372741936,
      "loss": 0.7627,
      "step": 275220
    },
    {
      "epoch": 443.94,
      "learning_rate": 0.055624237924193555,
      "loss": 0.7581,
      "step": 275240
    },
    {
      "epoch": 443.97,
      "learning_rate": 0.05562101212096774,
      "loss": 0.7738,
      "step": 275260
    },
    {
      "epoch": 444.0,
      "learning_rate": 0.055617786317741946,
      "loss": 0.7925,
      "step": 275280
    },
    {
      "epoch": 444.0,
      "eval_accuracy": {
        "accuracy": 0.7566154086332059
      },
      "eval_loss": 1.1444504261016846,
      "eval_runtime": 2.7553,
      "eval_samples_per_second": 4649.606,
      "eval_steps_per_second": 72.951,
      "step": 275280
    },
    {
      "epoch": 444.03,
      "learning_rate": 0.05561456051451613,
      "loss": 0.7855,
      "step": 275300
    },
    {
      "epoch": 444.06,
      "learning_rate": 0.055611334711290344,
      "loss": 0.7666,
      "step": 275320
    },
    {
      "epoch": 444.1,
      "learning_rate": 0.055608108908064516,
      "loss": 0.7642,
      "step": 275340
    },
    {
      "epoch": 444.13,
      "learning_rate": 0.055604883104838715,
      "loss": 0.7331,
      "step": 275360
    },
    {
      "epoch": 444.16,
      "learning_rate": 0.05560165730161291,
      "loss": 0.7385,
      "step": 275380
    },
    {
      "epoch": 444.19,
      "learning_rate": 0.05559843149838709,
      "loss": 0.7606,
      "step": 275400
    },
    {
      "epoch": 444.23,
      "learning_rate": 0.0555952056951613,
      "loss": 0.7438,
      "step": 275420
    },
    {
      "epoch": 444.26,
      "learning_rate": 0.055591979891935484,
      "loss": 0.7634,
      "step": 275440
    },
    {
      "epoch": 444.29,
      "learning_rate": 0.05558875408870968,
      "loss": 0.7616,
      "step": 275460
    },
    {
      "epoch": 444.32,
      "learning_rate": 0.05558552828548388,
      "loss": 0.7595,
      "step": 275480
    },
    {
      "epoch": 444.35,
      "learning_rate": 0.055582302482258074,
      "loss": 0.7536,
      "step": 275500
    },
    {
      "epoch": 444.39,
      "learning_rate": 0.05557907667903225,
      "loss": 0.7709,
      "step": 275520
    },
    {
      "epoch": 444.42,
      "learning_rate": 0.05557585087580646,
      "loss": 0.7441,
      "step": 275540
    },
    {
      "epoch": 444.45,
      "learning_rate": 0.05557262507258064,
      "loss": 0.7573,
      "step": 275560
    },
    {
      "epoch": 444.48,
      "learning_rate": 0.05556939926935485,
      "loss": 0.7513,
      "step": 275580
    },
    {
      "epoch": 444.52,
      "learning_rate": 0.055566173466129035,
      "loss": 0.7517,
      "step": 275600
    },
    {
      "epoch": 444.55,
      "learning_rate": 0.05556294766290324,
      "loss": 0.7438,
      "step": 275620
    },
    {
      "epoch": 444.58,
      "learning_rate": 0.05555972185967742,
      "loss": 0.757,
      "step": 275640
    },
    {
      "epoch": 444.61,
      "learning_rate": 0.05555649605645161,
      "loss": 0.7652,
      "step": 275660
    },
    {
      "epoch": 444.65,
      "learning_rate": 0.05555327025322581,
      "loss": 0.7503,
      "step": 275680
    },
    {
      "epoch": 444.68,
      "learning_rate": 0.05555004445,
      "loss": 0.7724,
      "step": 275700
    },
    {
      "epoch": 444.71,
      "learning_rate": 0.0555468186467742,
      "loss": 0.7804,
      "step": 275720
    },
    {
      "epoch": 444.74,
      "learning_rate": 0.0555435928435484,
      "loss": 0.781,
      "step": 275740
    },
    {
      "epoch": 444.77,
      "learning_rate": 0.055540367040322586,
      "loss": 0.7724,
      "step": 275760
    },
    {
      "epoch": 444.81,
      "learning_rate": 0.05553714123709678,
      "loss": 0.7579,
      "step": 275780
    },
    {
      "epoch": 444.84,
      "learning_rate": 0.05553391543387098,
      "loss": 0.7731,
      "step": 275800
    },
    {
      "epoch": 444.87,
      "learning_rate": 0.05553068963064515,
      "loss": 0.7777,
      "step": 275820
    },
    {
      "epoch": 444.9,
      "learning_rate": 0.055527463827419354,
      "loss": 0.771,
      "step": 275840
    },
    {
      "epoch": 444.94,
      "learning_rate": 0.05552423802419354,
      "loss": 0.7682,
      "step": 275860
    },
    {
      "epoch": 444.97,
      "learning_rate": 0.05552101222096775,
      "loss": 0.7622,
      "step": 275880
    },
    {
      "epoch": 445.0,
      "learning_rate": 0.05551778641774194,
      "loss": 0.774,
      "step": 275900
    },
    {
      "epoch": 445.0,
      "eval_accuracy": {
        "accuracy": 0.7585668566076028
      },
      "eval_loss": 1.1232553720474243,
      "eval_runtime": 3.4122,
      "eval_samples_per_second": 3754.464,
      "eval_steps_per_second": 58.906,
      "step": 275900
    },
    {
      "epoch": 445.03,
      "learning_rate": 0.055514560614516144,
      "loss": 0.7621,
      "step": 275920
    },
    {
      "epoch": 445.06,
      "learning_rate": 0.055511334811290315,
      "loss": 0.7271,
      "step": 275940
    },
    {
      "epoch": 445.1,
      "learning_rate": 0.05550810900806452,
      "loss": 0.7503,
      "step": 275960
    },
    {
      "epoch": 445.13,
      "learning_rate": 0.055504883204838706,
      "loss": 0.7541,
      "step": 275980
    },
    {
      "epoch": 445.16,
      "learning_rate": 0.055501657401612906,
      "loss": 0.7465,
      "step": 276000
    },
    {
      "epoch": 445.19,
      "learning_rate": 0.055498431598387105,
      "loss": 0.7322,
      "step": 276020
    },
    {
      "epoch": 445.23,
      "learning_rate": 0.0554952057951613,
      "loss": 0.7476,
      "step": 276040
    },
    {
      "epoch": 445.26,
      "learning_rate": 0.05549197999193548,
      "loss": 0.7611,
      "step": 276060
    },
    {
      "epoch": 445.29,
      "learning_rate": 0.05548875418870968,
      "loss": 0.763,
      "step": 276080
    },
    {
      "epoch": 445.32,
      "learning_rate": 0.05548552838548387,
      "loss": 0.7312,
      "step": 276100
    },
    {
      "epoch": 445.35,
      "learning_rate": 0.05548230258225806,
      "loss": 0.7768,
      "step": 276120
    },
    {
      "epoch": 445.39,
      "learning_rate": 0.05547907677903227,
      "loss": 0.7575,
      "step": 276140
    },
    {
      "epoch": 445.42,
      "learning_rate": 0.05547585097580646,
      "loss": 0.7645,
      "step": 276160
    },
    {
      "epoch": 445.45,
      "learning_rate": 0.05547262517258065,
      "loss": 0.7603,
      "step": 276180
    },
    {
      "epoch": 445.48,
      "learning_rate": 0.055469399369354834,
      "loss": 0.7545,
      "step": 276200
    },
    {
      "epoch": 445.52,
      "learning_rate": 0.05546617356612904,
      "loss": 0.7471,
      "step": 276220
    },
    {
      "epoch": 445.55,
      "learning_rate": 0.055462947762903225,
      "loss": 0.7604,
      "step": 276240
    },
    {
      "epoch": 445.58,
      "learning_rate": 0.05545972195967744,
      "loss": 0.7638,
      "step": 276260
    },
    {
      "epoch": 445.61,
      "learning_rate": 0.05545649615645162,
      "loss": 0.7696,
      "step": 276280
    },
    {
      "epoch": 445.65,
      "learning_rate": 0.05545327035322581,
      "loss": 0.769,
      "step": 276300
    },
    {
      "epoch": 445.68,
      "learning_rate": 0.05545004455,
      "loss": 0.7924,
      "step": 276320
    },
    {
      "epoch": 445.71,
      "learning_rate": 0.0554468187467742,
      "loss": 0.7672,
      "step": 276340
    },
    {
      "epoch": 445.74,
      "learning_rate": 0.05544359294354839,
      "loss": 0.7472,
      "step": 276360
    },
    {
      "epoch": 445.77,
      "learning_rate": 0.05544036714032258,
      "loss": 0.7813,
      "step": 276380
    },
    {
      "epoch": 445.81,
      "learning_rate": 0.05543714133709679,
      "loss": 0.7854,
      "step": 276400
    },
    {
      "epoch": 445.84,
      "learning_rate": 0.05543391553387096,
      "loss": 0.7652,
      "step": 276420
    },
    {
      "epoch": 445.87,
      "learning_rate": 0.05543068973064517,
      "loss": 0.7565,
      "step": 276440
    },
    {
      "epoch": 445.9,
      "learning_rate": 0.05542746392741935,
      "loss": 0.7827,
      "step": 276460
    },
    {
      "epoch": 445.94,
      "learning_rate": 0.05542423812419356,
      "loss": 0.7649,
      "step": 276480
    },
    {
      "epoch": 445.97,
      "learning_rate": 0.055421012320967744,
      "loss": 0.7659,
      "step": 276500
    },
    {
      "epoch": 446.0,
      "learning_rate": 0.05541778651774194,
      "loss": 0.7798,
      "step": 276520
    },
    {
      "epoch": 446.0,
      "eval_accuracy": {
        "accuracy": 0.7547420185777847
      },
      "eval_loss": 1.1476199626922607,
      "eval_runtime": 3.0162,
      "eval_samples_per_second": 4247.413,
      "eval_steps_per_second": 66.64,
      "step": 276520
    },
    {
      "epoch": 446.03,
      "learning_rate": 0.05541456071451613,
      "loss": 0.7849,
      "step": 276540
    },
    {
      "epoch": 446.06,
      "learning_rate": 0.055411334911290334,
      "loss": 0.7404,
      "step": 276560
    },
    {
      "epoch": 446.1,
      "learning_rate": 0.05540810910806452,
      "loss": 0.731,
      "step": 276580
    },
    {
      "epoch": 446.13,
      "learning_rate": 0.055404883304838705,
      "loss": 0.7633,
      "step": 276600
    },
    {
      "epoch": 446.16,
      "learning_rate": 0.055401657501612904,
      "loss": 0.7567,
      "step": 276620
    },
    {
      "epoch": 446.19,
      "learning_rate": 0.055398431698387096,
      "loss": 0.7752,
      "step": 276640
    },
    {
      "epoch": 446.23,
      "learning_rate": 0.055395205895161295,
      "loss": 0.7442,
      "step": 276660
    },
    {
      "epoch": 446.26,
      "learning_rate": 0.055391980091935494,
      "loss": 0.7591,
      "step": 276680
    },
    {
      "epoch": 446.29,
      "learning_rate": 0.055388754288709686,
      "loss": 0.7596,
      "step": 276700
    },
    {
      "epoch": 446.32,
      "learning_rate": 0.05538552848548387,
      "loss": 0.7563,
      "step": 276720
    },
    {
      "epoch": 446.35,
      "learning_rate": 0.05538230268225807,
      "loss": 0.7507,
      "step": 276740
    },
    {
      "epoch": 446.39,
      "learning_rate": 0.055379076879032256,
      "loss": 0.7311,
      "step": 276760
    },
    {
      "epoch": 446.42,
      "learning_rate": 0.05537585107580646,
      "loss": 0.7489,
      "step": 276780
    },
    {
      "epoch": 446.45,
      "learning_rate": 0.05537262527258063,
      "loss": 0.7657,
      "step": 276800
    },
    {
      "epoch": 446.48,
      "learning_rate": 0.055369399469354846,
      "loss": 0.7624,
      "step": 276820
    },
    {
      "epoch": 446.52,
      "learning_rate": 0.05536617366612903,
      "loss": 0.742,
      "step": 276840
    },
    {
      "epoch": 446.55,
      "learning_rate": 0.05536294786290324,
      "loss": 0.754,
      "step": 276860
    },
    {
      "epoch": 446.58,
      "learning_rate": 0.05535972205967742,
      "loss": 0.743,
      "step": 276880
    },
    {
      "epoch": 446.61,
      "learning_rate": 0.055356496256451615,
      "loss": 0.7468,
      "step": 276900
    },
    {
      "epoch": 446.65,
      "learning_rate": 0.0553532704532258,
      "loss": 0.7595,
      "step": 276920
    },
    {
      "epoch": 446.68,
      "learning_rate": 0.05535004465000001,
      "loss": 0.7682,
      "step": 276940
    },
    {
      "epoch": 446.71,
      "learning_rate": 0.0553468188467742,
      "loss": 0.7625,
      "step": 276960
    },
    {
      "epoch": 446.74,
      "learning_rate": 0.05534359304354839,
      "loss": 0.7755,
      "step": 276980
    },
    {
      "epoch": 446.77,
      "learning_rate": 0.05534036724032259,
      "loss": 0.7719,
      "step": 277000
    },
    {
      "epoch": 446.81,
      "learning_rate": 0.05533714143709678,
      "loss": 0.7754,
      "step": 277020
    },
    {
      "epoch": 446.84,
      "learning_rate": 0.05533391563387097,
      "loss": 0.7586,
      "step": 277040
    },
    {
      "epoch": 446.87,
      "learning_rate": 0.05533068983064515,
      "loss": 0.77,
      "step": 277060
    },
    {
      "epoch": 446.9,
      "learning_rate": 0.055327464027419365,
      "loss": 0.777,
      "step": 277080
    },
    {
      "epoch": 446.94,
      "learning_rate": 0.05532423822419355,
      "loss": 0.7641,
      "step": 277100
    },
    {
      "epoch": 446.97,
      "learning_rate": 0.05532101242096774,
      "loss": 0.7591,
      "step": 277120
    },
    {
      "epoch": 447.0,
      "learning_rate": 0.05531794790790323,
      "loss": 0.7933,
      "step": 277140
    },
    {
      "epoch": 447.0,
      "eval_accuracy": {
        "accuracy": 0.7547420185777847
      },
      "eval_loss": 1.1435222625732422,
      "eval_runtime": 3.1051,
      "eval_samples_per_second": 4125.772,
      "eval_steps_per_second": 64.732,
      "step": 277140
    },
    {
      "epoch": 447.03,
      "learning_rate": 0.055314722104677416,
      "loss": 0.7735,
      "step": 277160
    },
    {
      "epoch": 447.06,
      "learning_rate": 0.05531149630145163,
      "loss": 0.7547,
      "step": 277180
    },
    {
      "epoch": 447.1,
      "learning_rate": 0.0553082704982258,
      "loss": 0.7595,
      "step": 277200
    },
    {
      "epoch": 447.13,
      "learning_rate": 0.05530504469500001,
      "loss": 0.7491,
      "step": 277220
    },
    {
      "epoch": 447.16,
      "learning_rate": 0.05530181889177419,
      "loss": 0.7504,
      "step": 277240
    },
    {
      "epoch": 447.19,
      "learning_rate": 0.0552985930885484,
      "loss": 0.7299,
      "step": 277260
    },
    {
      "epoch": 447.23,
      "learning_rate": 0.05529536728532258,
      "loss": 0.7343,
      "step": 277280
    },
    {
      "epoch": 447.26,
      "learning_rate": 0.05529214148209678,
      "loss": 0.7374,
      "step": 277300
    },
    {
      "epoch": 447.29,
      "learning_rate": 0.05528891567887097,
      "loss": 0.77,
      "step": 277320
    },
    {
      "epoch": 447.32,
      "learning_rate": 0.055285689875645166,
      "loss": 0.7711,
      "step": 277340
    },
    {
      "epoch": 447.35,
      "learning_rate": 0.05528246407241936,
      "loss": 0.7781,
      "step": 277360
    },
    {
      "epoch": 447.39,
      "learning_rate": 0.055279238269193544,
      "loss": 0.7396,
      "step": 277380
    },
    {
      "epoch": 447.42,
      "learning_rate": 0.05527601246596774,
      "loss": 0.7464,
      "step": 277400
    },
    {
      "epoch": 447.45,
      "learning_rate": 0.055272786662741935,
      "loss": 0.7472,
      "step": 277420
    },
    {
      "epoch": 447.48,
      "learning_rate": 0.055269560859516134,
      "loss": 0.7503,
      "step": 277440
    },
    {
      "epoch": 447.52,
      "learning_rate": 0.05526633505629033,
      "loss": 0.7451,
      "step": 277460
    },
    {
      "epoch": 447.55,
      "learning_rate": 0.055263109253064525,
      "loss": 0.7454,
      "step": 277480
    },
    {
      "epoch": 447.58,
      "learning_rate": 0.055259883449838704,
      "loss": 0.7708,
      "step": 277500
    },
    {
      "epoch": 447.61,
      "learning_rate": 0.05525665764661291,
      "loss": 0.7529,
      "step": 277520
    },
    {
      "epoch": 447.65,
      "learning_rate": 0.055253431843387095,
      "loss": 0.7458,
      "step": 277540
    },
    {
      "epoch": 447.68,
      "learning_rate": 0.0552502060401613,
      "loss": 0.7697,
      "step": 277560
    },
    {
      "epoch": 447.71,
      "learning_rate": 0.055246980236935486,
      "loss": 0.7437,
      "step": 277580
    },
    {
      "epoch": 447.74,
      "learning_rate": 0.055243754433709685,
      "loss": 0.7472,
      "step": 277600
    },
    {
      "epoch": 447.77,
      "learning_rate": 0.05524052863048387,
      "loss": 0.7805,
      "step": 277620
    },
    {
      "epoch": 447.81,
      "learning_rate": 0.05523730282725808,
      "loss": 0.7711,
      "step": 277640
    },
    {
      "epoch": 447.84,
      "learning_rate": 0.05523407702403226,
      "loss": 0.779,
      "step": 277660
    },
    {
      "epoch": 447.87,
      "learning_rate": 0.055230851220806454,
      "loss": 0.7768,
      "step": 277680
    },
    {
      "epoch": 447.9,
      "learning_rate": 0.05522762541758064,
      "loss": 0.7756,
      "step": 277700
    },
    {
      "epoch": 447.94,
      "learning_rate": 0.05522439961435485,
      "loss": 0.7631,
      "step": 277720
    },
    {
      "epoch": 447.97,
      "learning_rate": 0.05522117381112904,
      "loss": 0.7591,
      "step": 277740
    },
    {
      "epoch": 448.0,
      "learning_rate": 0.05521794800790323,
      "loss": 0.7539,
      "step": 277760
    },
    {
      "epoch": 448.0,
      "eval_accuracy": {
        "accuracy": 0.7668409960190461
      },
      "eval_loss": 1.1232750415802002,
      "eval_runtime": 2.8989,
      "eval_samples_per_second": 4419.245,
      "eval_steps_per_second": 69.336,
      "step": 277760
    },
    {
      "epoch": 448.03,
      "learning_rate": 0.05521472220467743,
      "loss": 0.7619,
      "step": 277780
    },
    {
      "epoch": 448.06,
      "learning_rate": 0.05521149640145162,
      "loss": 0.7311,
      "step": 277800
    },
    {
      "epoch": 448.1,
      "learning_rate": 0.055208270598225806,
      "loss": 0.7308,
      "step": 277820
    },
    {
      "epoch": 448.13,
      "learning_rate": 0.05520504479499999,
      "loss": 0.7136,
      "step": 277840
    },
    {
      "epoch": 448.16,
      "learning_rate": 0.055201818991774204,
      "loss": 0.7561,
      "step": 277860
    },
    {
      "epoch": 448.19,
      "learning_rate": 0.05519859318854839,
      "loss": 0.7566,
      "step": 277880
    },
    {
      "epoch": 448.23,
      "learning_rate": 0.05519536738532258,
      "loss": 0.757,
      "step": 277900
    },
    {
      "epoch": 448.26,
      "learning_rate": 0.05519214158209677,
      "loss": 0.7723,
      "step": 277920
    },
    {
      "epoch": 448.29,
      "learning_rate": 0.05518891577887097,
      "loss": 0.768,
      "step": 277940
    },
    {
      "epoch": 448.32,
      "learning_rate": 0.05518568997564516,
      "loss": 0.7418,
      "step": 277960
    },
    {
      "epoch": 448.35,
      "learning_rate": 0.05518246417241936,
      "loss": 0.7341,
      "step": 277980
    },
    {
      "epoch": 448.39,
      "learning_rate": 0.055179238369193556,
      "loss": 0.7349,
      "step": 278000
    },
    {
      "epoch": 448.42,
      "learning_rate": 0.05517601256596775,
      "loss": 0.7471,
      "step": 278020
    },
    {
      "epoch": 448.45,
      "learning_rate": 0.055172786762741934,
      "loss": 0.7835,
      "step": 278040
    },
    {
      "epoch": 448.48,
      "learning_rate": 0.05516956095951613,
      "loss": 0.7673,
      "step": 278060
    },
    {
      "epoch": 448.52,
      "learning_rate": 0.055166335156290325,
      "loss": 0.7523,
      "step": 278080
    },
    {
      "epoch": 448.55,
      "learning_rate": 0.055163109353064524,
      "loss": 0.7533,
      "step": 278100
    },
    {
      "epoch": 448.58,
      "learning_rate": 0.05515988354983872,
      "loss": 0.7365,
      "step": 278120
    },
    {
      "epoch": 448.61,
      "learning_rate": 0.05515665774661291,
      "loss": 0.7741,
      "step": 278140
    },
    {
      "epoch": 448.65,
      "learning_rate": 0.0551534319433871,
      "loss": 0.7791,
      "step": 278160
    },
    {
      "epoch": 448.68,
      "learning_rate": 0.055150206140161286,
      "loss": 0.7637,
      "step": 278180
    },
    {
      "epoch": 448.71,
      "learning_rate": 0.05514698033693549,
      "loss": 0.7636,
      "step": 278200
    },
    {
      "epoch": 448.74,
      "learning_rate": 0.05514375453370968,
      "loss": 0.7482,
      "step": 278220
    },
    {
      "epoch": 448.77,
      "learning_rate": 0.05514052873048389,
      "loss": 0.7826,
      "step": 278240
    },
    {
      "epoch": 448.81,
      "learning_rate": 0.055137302927258075,
      "loss": 0.7621,
      "step": 278260
    },
    {
      "epoch": 448.84,
      "learning_rate": 0.05513407712403226,
      "loss": 0.7609,
      "step": 278280
    },
    {
      "epoch": 448.87,
      "learning_rate": 0.05513085132080645,
      "loss": 0.7687,
      "step": 278300
    },
    {
      "epoch": 448.9,
      "learning_rate": 0.05512762551758065,
      "loss": 0.7919,
      "step": 278320
    },
    {
      "epoch": 448.94,
      "learning_rate": 0.055124399714354844,
      "loss": 0.7552,
      "step": 278340
    },
    {
      "epoch": 448.97,
      "learning_rate": 0.05512117391112903,
      "loss": 0.751,
      "step": 278360
    },
    {
      "epoch": 449.0,
      "learning_rate": 0.05511794810790323,
      "loss": 0.775,
      "step": 278380
    },
    {
      "epoch": 449.0,
      "eval_accuracy": {
        "accuracy": 0.7555225977675435
      },
      "eval_loss": 1.1484403610229492,
      "eval_runtime": 2.9122,
      "eval_samples_per_second": 4399.078,
      "eval_steps_per_second": 69.02,
      "step": 278380
    },
    {
      "epoch": 449.03,
      "learning_rate": 0.05511472230467743,
      "loss": 0.7678,
      "step": 278400
    },
    {
      "epoch": 449.06,
      "learning_rate": 0.05511149650145162,
      "loss": 0.7632,
      "step": 278420
    },
    {
      "epoch": 449.1,
      "learning_rate": 0.055108270698225804,
      "loss": 0.7487,
      "step": 278440
    },
    {
      "epoch": 449.13,
      "learning_rate": 0.05510504489500001,
      "loss": 0.7507,
      "step": 278460
    },
    {
      "epoch": 449.16,
      "learning_rate": 0.05510181909177419,
      "loss": 0.7471,
      "step": 278480
    },
    {
      "epoch": 449.19,
      "learning_rate": 0.055098593288548395,
      "loss": 0.7281,
      "step": 278500
    },
    {
      "epoch": 449.23,
      "learning_rate": 0.05509536748532258,
      "loss": 0.75,
      "step": 278520
    },
    {
      "epoch": 449.26,
      "learning_rate": 0.055092141682096786,
      "loss": 0.751,
      "step": 278540
    },
    {
      "epoch": 449.29,
      "learning_rate": 0.05508891587887097,
      "loss": 0.7543,
      "step": 278560
    },
    {
      "epoch": 449.32,
      "learning_rate": 0.05508569007564518,
      "loss": 0.759,
      "step": 278580
    },
    {
      "epoch": 449.35,
      "learning_rate": 0.055082464272419356,
      "loss": 0.7702,
      "step": 278600
    },
    {
      "epoch": 449.39,
      "learning_rate": 0.05507923846919355,
      "loss": 0.7477,
      "step": 278620
    },
    {
      "epoch": 449.42,
      "learning_rate": 0.05507601266596775,
      "loss": 0.7656,
      "step": 278640
    },
    {
      "epoch": 449.45,
      "learning_rate": 0.055072786862741946,
      "loss": 0.7711,
      "step": 278660
    },
    {
      "epoch": 449.48,
      "learning_rate": 0.05506956105951613,
      "loss": 0.7615,
      "step": 278680
    },
    {
      "epoch": 449.52,
      "learning_rate": 0.05506633525629032,
      "loss": 0.7473,
      "step": 278700
    },
    {
      "epoch": 449.55,
      "learning_rate": 0.05506310945306452,
      "loss": 0.7486,
      "step": 278720
    },
    {
      "epoch": 449.58,
      "learning_rate": 0.05505988364983871,
      "loss": 0.7802,
      "step": 278740
    },
    {
      "epoch": 449.61,
      "learning_rate": 0.055056657846612914,
      "loss": 0.7443,
      "step": 278760
    },
    {
      "epoch": 449.65,
      "learning_rate": 0.055053432043387085,
      "loss": 0.7575,
      "step": 278780
    },
    {
      "epoch": 449.68,
      "learning_rate": 0.0550502062401613,
      "loss": 0.7351,
      "step": 278800
    },
    {
      "epoch": 449.71,
      "learning_rate": 0.05504698043693548,
      "loss": 0.7674,
      "step": 278820
    },
    {
      "epoch": 449.74,
      "learning_rate": 0.05504375463370969,
      "loss": 0.7667,
      "step": 278840
    },
    {
      "epoch": 449.77,
      "learning_rate": 0.055040528830483874,
      "loss": 0.7669,
      "step": 278860
    },
    {
      "epoch": 449.81,
      "learning_rate": 0.05503730302725807,
      "loss": 0.7642,
      "step": 278880
    },
    {
      "epoch": 449.84,
      "learning_rate": 0.05503407722403225,
      "loss": 0.7588,
      "step": 278900
    },
    {
      "epoch": 449.87,
      "learning_rate": 0.05503085142080645,
      "loss": 0.751,
      "step": 278920
    },
    {
      "epoch": 449.9,
      "learning_rate": 0.05502762561758065,
      "loss": 0.7632,
      "step": 278940
    },
    {
      "epoch": 449.94,
      "learning_rate": 0.05502439981435484,
      "loss": 0.7587,
      "step": 278960
    },
    {
      "epoch": 449.97,
      "learning_rate": 0.05502117401112903,
      "loss": 0.77,
      "step": 278980
    },
    {
      "epoch": 450.0,
      "learning_rate": 0.05501794820790323,
      "loss": 0.7852,
      "step": 279000
    },
    {
      "epoch": 450.0,
      "eval_accuracy": {
        "accuracy": 0.7566154086332059
      },
      "eval_loss": 1.1187098026275635,
      "eval_runtime": 3.1433,
      "eval_samples_per_second": 4075.703,
      "eval_steps_per_second": 63.946,
      "step": 279000
    },
    {
      "epoch": 450.03,
      "learning_rate": 0.05501472240467742,
      "loss": 0.7846,
      "step": 279020
    },
    {
      "epoch": 450.06,
      "learning_rate": 0.05501149660145162,
      "loss": 0.7593,
      "step": 279040
    },
    {
      "epoch": 450.1,
      "learning_rate": 0.05500827079822582,
      "loss": 0.7299,
      "step": 279060
    },
    {
      "epoch": 450.13,
      "learning_rate": 0.055005044995,
      "loss": 0.7683,
      "step": 279080
    },
    {
      "epoch": 450.16,
      "learning_rate": 0.055001819191774194,
      "loss": 0.7449,
      "step": 279100
    },
    {
      "epoch": 450.19,
      "learning_rate": 0.05499859338854838,
      "loss": 0.7253,
      "step": 279120
    },
    {
      "epoch": 450.23,
      "learning_rate": 0.054995367585322585,
      "loss": 0.736,
      "step": 279140
    },
    {
      "epoch": 450.26,
      "learning_rate": 0.05499214178209677,
      "loss": 0.7335,
      "step": 279160
    },
    {
      "epoch": 450.29,
      "learning_rate": 0.054988915978870984,
      "loss": 0.7493,
      "step": 279180
    },
    {
      "epoch": 450.32,
      "learning_rate": 0.05498569017564517,
      "loss": 0.7328,
      "step": 279200
    },
    {
      "epoch": 450.35,
      "learning_rate": 0.054982464372419354,
      "loss": 0.7423,
      "step": 279220
    },
    {
      "epoch": 450.39,
      "learning_rate": 0.054979238569193546,
      "loss": 0.748,
      "step": 279240
    },
    {
      "epoch": 450.42,
      "learning_rate": 0.054976012765967745,
      "loss": 0.7267,
      "step": 279260
    },
    {
      "epoch": 450.45,
      "learning_rate": 0.05497278696274194,
      "loss": 0.7556,
      "step": 279280
    },
    {
      "epoch": 450.48,
      "learning_rate": 0.054969561159516137,
      "loss": 0.7525,
      "step": 279300
    },
    {
      "epoch": 450.52,
      "learning_rate": 0.054966335356290336,
      "loss": 0.7544,
      "step": 279320
    },
    {
      "epoch": 450.55,
      "learning_rate": 0.05496310955306452,
      "loss": 0.7613,
      "step": 279340
    },
    {
      "epoch": 450.58,
      "learning_rate": 0.05495988374983871,
      "loss": 0.7599,
      "step": 279360
    },
    {
      "epoch": 450.61,
      "learning_rate": 0.0549566579466129,
      "loss": 0.7656,
      "step": 279380
    },
    {
      "epoch": 450.65,
      "learning_rate": 0.054953432143387104,
      "loss": 0.7642,
      "step": 279400
    },
    {
      "epoch": 450.68,
      "learning_rate": 0.05495020634016129,
      "loss": 0.7596,
      "step": 279420
    },
    {
      "epoch": 450.71,
      "learning_rate": 0.0549469805369355,
      "loss": 0.7628,
      "step": 279440
    },
    {
      "epoch": 450.74,
      "learning_rate": 0.054943754733709674,
      "loss": 0.7577,
      "step": 279460
    },
    {
      "epoch": 450.77,
      "learning_rate": 0.05494052893048388,
      "loss": 0.7585,
      "step": 279480
    },
    {
      "epoch": 450.81,
      "learning_rate": 0.054937303127258065,
      "loss": 0.7605,
      "step": 279500
    },
    {
      "epoch": 450.84,
      "learning_rate": 0.05493407732403225,
      "loss": 0.7658,
      "step": 279520
    },
    {
      "epoch": 450.87,
      "learning_rate": 0.054930851520806456,
      "loss": 0.7556,
      "step": 279540
    },
    {
      "epoch": 450.9,
      "learning_rate": 0.05492762571758064,
      "loss": 0.7535,
      "step": 279560
    },
    {
      "epoch": 450.94,
      "learning_rate": 0.05492439991435484,
      "loss": 0.7747,
      "step": 279580
    },
    {
      "epoch": 450.97,
      "learning_rate": 0.05492117411112904,
      "loss": 0.7745,
      "step": 279600
    },
    {
      "epoch": 451.0,
      "learning_rate": 0.05491794830790323,
      "loss": 0.7795,
      "step": 279620
    },
    {
      "epoch": 451.0,
      "eval_accuracy": {
        "accuracy": 0.7563031769573023
      },
      "eval_loss": 1.1370149850845337,
      "eval_runtime": 3.3298,
      "eval_samples_per_second": 3847.425,
      "eval_steps_per_second": 60.365,
      "step": 279620
    },
    {
      "epoch": 451.03,
      "learning_rate": 0.05491472250467742,
      "loss": 0.7867,
      "step": 279640
    },
    {
      "epoch": 451.06,
      "learning_rate": 0.054911496701451616,
      "loss": 0.7555,
      "step": 279660
    },
    {
      "epoch": 451.1,
      "learning_rate": 0.0549082708982258,
      "loss": 0.7648,
      "step": 279680
    },
    {
      "epoch": 451.13,
      "learning_rate": 0.05490504509500001,
      "loss": 0.7426,
      "step": 279700
    },
    {
      "epoch": 451.16,
      "learning_rate": 0.05490181929177419,
      "loss": 0.7424,
      "step": 279720
    },
    {
      "epoch": 451.19,
      "learning_rate": 0.0548985934885484,
      "loss": 0.7503,
      "step": 279740
    },
    {
      "epoch": 451.23,
      "learning_rate": 0.05489536768532258,
      "loss": 0.7569,
      "step": 279760
    },
    {
      "epoch": 451.26,
      "learning_rate": 0.05489214188209678,
      "loss": 0.7445,
      "step": 279780
    },
    {
      "epoch": 451.29,
      "learning_rate": 0.05488891607887097,
      "loss": 0.7503,
      "step": 279800
    },
    {
      "epoch": 451.32,
      "learning_rate": 0.054885690275645174,
      "loss": 0.746,
      "step": 279820
    },
    {
      "epoch": 451.35,
      "learning_rate": 0.05488246447241936,
      "loss": 0.7459,
      "step": 279840
    },
    {
      "epoch": 451.39,
      "learning_rate": 0.05487923866919356,
      "loss": 0.752,
      "step": 279860
    },
    {
      "epoch": 451.42,
      "learning_rate": 0.054876012865967744,
      "loss": 0.7738,
      "step": 279880
    },
    {
      "epoch": 451.45,
      "learning_rate": 0.054872787062741936,
      "loss": 0.7729,
      "step": 279900
    },
    {
      "epoch": 451.48,
      "learning_rate": 0.054869722549677424,
      "loss": 0.7778,
      "step": 279920
    },
    {
      "epoch": 451.52,
      "learning_rate": 0.05486649674645161,
      "loss": 0.7597,
      "step": 279940
    },
    {
      "epoch": 451.55,
      "learning_rate": 0.05486327094322582,
      "loss": 0.7528,
      "step": 279960
    },
    {
      "epoch": 451.58,
      "learning_rate": 0.05486004514000001,
      "loss": 0.7644,
      "step": 279980
    },
    {
      "epoch": 451.61,
      "learning_rate": 0.05485681933677419,
      "loss": 0.7614,
      "step": 280000
    },
    {
      "epoch": 451.65,
      "learning_rate": 0.054853593533548385,
      "loss": 0.7594,
      "step": 280020
    },
    {
      "epoch": 451.68,
      "learning_rate": 0.054850367730322584,
      "loss": 0.7763,
      "step": 280040
    },
    {
      "epoch": 451.71,
      "learning_rate": 0.054847141927096776,
      "loss": 0.7542,
      "step": 280060
    },
    {
      "epoch": 451.74,
      "learning_rate": 0.054843916123870975,
      "loss": 0.7442,
      "step": 280080
    },
    {
      "epoch": 451.77,
      "learning_rate": 0.054840690320645175,
      "loss": 0.7492,
      "step": 280100
    },
    {
      "epoch": 451.81,
      "learning_rate": 0.05483746451741936,
      "loss": 0.764,
      "step": 280120
    },
    {
      "epoch": 451.84,
      "learning_rate": 0.05483423871419355,
      "loss": 0.7434,
      "step": 280140
    },
    {
      "epoch": 451.87,
      "learning_rate": 0.05483101291096774,
      "loss": 0.7685,
      "step": 280160
    },
    {
      "epoch": 451.9,
      "learning_rate": 0.05482778710774194,
      "loss": 0.7775,
      "step": 280180
    },
    {
      "epoch": 451.94,
      "learning_rate": 0.05482456130451613,
      "loss": 0.7521,
      "step": 280200
    },
    {
      "epoch": 451.97,
      "learning_rate": 0.05482133550129034,
      "loss": 0.78,
      "step": 280220
    },
    {
      "epoch": 452.0,
      "learning_rate": 0.05481810969806453,
      "loss": 0.7623,
      "step": 280240
    },
    {
      "epoch": 452.0,
      "eval_accuracy": {
        "accuracy": 0.7550542502536882
      },
      "eval_loss": 1.144635796546936,
      "eval_runtime": 2.8706,
      "eval_samples_per_second": 4462.879,
      "eval_steps_per_second": 70.021,
      "step": 280240
    },
    {
      "epoch": 452.03,
      "learning_rate": 0.05481488389483872,
      "loss": 0.7941,
      "step": 280260
    },
    {
      "epoch": 452.06,
      "learning_rate": 0.054811658091612904,
      "loss": 0.7535,
      "step": 280280
    },
    {
      "epoch": 452.1,
      "learning_rate": 0.05480843228838709,
      "loss": 0.7362,
      "step": 280300
    },
    {
      "epoch": 452.13,
      "learning_rate": 0.054805206485161295,
      "loss": 0.7588,
      "step": 280320
    },
    {
      "epoch": 452.16,
      "learning_rate": 0.05480198068193548,
      "loss": 0.7536,
      "step": 280340
    },
    {
      "epoch": 452.19,
      "learning_rate": 0.05479875487870968,
      "loss": 0.7428,
      "step": 280360
    },
    {
      "epoch": 452.23,
      "learning_rate": 0.05479552907548388,
      "loss": 0.7431,
      "step": 280380
    },
    {
      "epoch": 452.26,
      "learning_rate": 0.05479230327225807,
      "loss": 0.7451,
      "step": 280400
    },
    {
      "epoch": 452.29,
      "learning_rate": 0.054789077469032256,
      "loss": 0.7282,
      "step": 280420
    },
    {
      "epoch": 452.32,
      "learning_rate": 0.05478585166580646,
      "loss": 0.756,
      "step": 280440
    },
    {
      "epoch": 452.35,
      "learning_rate": 0.05478262586258064,
      "loss": 0.7555,
      "step": 280460
    },
    {
      "epoch": 452.39,
      "learning_rate": 0.054779400059354846,
      "loss": 0.7819,
      "step": 280480
    },
    {
      "epoch": 452.42,
      "learning_rate": 0.05477617425612903,
      "loss": 0.7493,
      "step": 280500
    },
    {
      "epoch": 452.45,
      "learning_rate": 0.05477294845290324,
      "loss": 0.7755,
      "step": 280520
    },
    {
      "epoch": 452.48,
      "learning_rate": 0.054769722649677416,
      "loss": 0.7798,
      "step": 280540
    },
    {
      "epoch": 452.52,
      "learning_rate": 0.05476649684645162,
      "loss": 0.7793,
      "step": 280560
    },
    {
      "epoch": 452.55,
      "learning_rate": 0.05476327104322581,
      "loss": 0.7749,
      "step": 280580
    },
    {
      "epoch": 452.58,
      "learning_rate": 0.05476004524,
      "loss": 0.7551,
      "step": 280600
    },
    {
      "epoch": 452.61,
      "learning_rate": 0.0547568194367742,
      "loss": 0.7586,
      "step": 280620
    },
    {
      "epoch": 452.65,
      "learning_rate": 0.0547535936335484,
      "loss": 0.7555,
      "step": 280640
    },
    {
      "epoch": 452.68,
      "learning_rate": 0.05475036783032258,
      "loss": 0.7532,
      "step": 280660
    },
    {
      "epoch": 452.71,
      "learning_rate": 0.054747142027096775,
      "loss": 0.7561,
      "step": 280680
    },
    {
      "epoch": 452.74,
      "learning_rate": 0.054743916223870974,
      "loss": 0.7631,
      "step": 280700
    },
    {
      "epoch": 452.77,
      "learning_rate": 0.054740690420645166,
      "loss": 0.7533,
      "step": 280720
    },
    {
      "epoch": 452.81,
      "learning_rate": 0.054737464617419365,
      "loss": 0.7527,
      "step": 280740
    },
    {
      "epoch": 452.84,
      "learning_rate": 0.05473423881419354,
      "loss": 0.735,
      "step": 280760
    },
    {
      "epoch": 452.87,
      "learning_rate": 0.05473101301096775,
      "loss": 0.7498,
      "step": 280780
    },
    {
      "epoch": 452.9,
      "learning_rate": 0.054727787207741935,
      "loss": 0.7563,
      "step": 280800
    },
    {
      "epoch": 452.94,
      "learning_rate": 0.05472456140451614,
      "loss": 0.7653,
      "step": 280820
    },
    {
      "epoch": 452.97,
      "learning_rate": 0.05472133560129031,
      "loss": 0.7481,
      "step": 280840
    },
    {
      "epoch": 453.0,
      "learning_rate": 0.05471810979806452,
      "loss": 0.7738,
      "step": 280860
    },
    {
      "epoch": 453.0,
      "eval_accuracy": {
        "accuracy": 0.75521036609164
      },
      "eval_loss": 1.1494958400726318,
      "eval_runtime": 3.8202,
      "eval_samples_per_second": 3353.479,
      "eval_steps_per_second": 52.615,
      "step": 280860
    },
    {
      "epoch": 453.03,
      "learning_rate": 0.0547148839948387,
      "loss": 0.7583,
      "step": 280880
    },
    {
      "epoch": 453.06,
      "learning_rate": 0.054711658191612916,
      "loss": 0.7263,
      "step": 280900
    },
    {
      "epoch": 453.1,
      "learning_rate": 0.0547084323883871,
      "loss": 0.7255,
      "step": 280920
    },
    {
      "epoch": 453.13,
      "learning_rate": 0.054705206585161294,
      "loss": 0.7424,
      "step": 280940
    },
    {
      "epoch": 453.16,
      "learning_rate": 0.05470198078193548,
      "loss": 0.7424,
      "step": 280960
    },
    {
      "epoch": 453.19,
      "learning_rate": 0.054698754978709685,
      "loss": 0.7473,
      "step": 280980
    },
    {
      "epoch": 453.23,
      "learning_rate": 0.05469552917548387,
      "loss": 0.7308,
      "step": 281000
    },
    {
      "epoch": 453.26,
      "learning_rate": 0.05469230337225807,
      "loss": 0.7496,
      "step": 281020
    },
    {
      "epoch": 453.29,
      "learning_rate": 0.05468907756903227,
      "loss": 0.7554,
      "step": 281040
    },
    {
      "epoch": 453.32,
      "learning_rate": 0.054685851765806454,
      "loss": 0.7446,
      "step": 281060
    },
    {
      "epoch": 453.35,
      "learning_rate": 0.054682625962580646,
      "loss": 0.7468,
      "step": 281080
    },
    {
      "epoch": 453.39,
      "learning_rate": 0.05467940015935483,
      "loss": 0.7478,
      "step": 281100
    },
    {
      "epoch": 453.42,
      "learning_rate": 0.05467617435612904,
      "loss": 0.7642,
      "step": 281120
    },
    {
      "epoch": 453.45,
      "learning_rate": 0.05467294855290322,
      "loss": 0.764,
      "step": 281140
    },
    {
      "epoch": 453.48,
      "learning_rate": 0.054669722749677435,
      "loss": 0.7456,
      "step": 281160
    },
    {
      "epoch": 453.52,
      "learning_rate": 0.05466649694645162,
      "loss": 0.7477,
      "step": 281180
    },
    {
      "epoch": 453.55,
      "learning_rate": 0.05466327114322581,
      "loss": 0.7446,
      "step": 281200
    },
    {
      "epoch": 453.58,
      "learning_rate": 0.05466004534,
      "loss": 0.7711,
      "step": 281220
    },
    {
      "epoch": 453.61,
      "learning_rate": 0.0546568195367742,
      "loss": 0.7553,
      "step": 281240
    },
    {
      "epoch": 453.65,
      "learning_rate": 0.05465359373354839,
      "loss": 0.7507,
      "step": 281260
    },
    {
      "epoch": 453.68,
      "learning_rate": 0.054650367930322574,
      "loss": 0.7642,
      "step": 281280
    },
    {
      "epoch": 453.71,
      "learning_rate": 0.05464714212709679,
      "loss": 0.7622,
      "step": 281300
    },
    {
      "epoch": 453.74,
      "learning_rate": 0.05464391632387097,
      "loss": 0.7565,
      "step": 281320
    },
    {
      "epoch": 453.77,
      "learning_rate": 0.054640690520645165,
      "loss": 0.7792,
      "step": 281340
    },
    {
      "epoch": 453.81,
      "learning_rate": 0.054637464717419364,
      "loss": 0.758,
      "step": 281360
    },
    {
      "epoch": 453.84,
      "learning_rate": 0.054634238914193556,
      "loss": 0.7359,
      "step": 281380
    },
    {
      "epoch": 453.87,
      "learning_rate": 0.05463101311096774,
      "loss": 0.7529,
      "step": 281400
    },
    {
      "epoch": 453.9,
      "learning_rate": 0.054627787307741954,
      "loss": 0.7576,
      "step": 281420
    },
    {
      "epoch": 453.94,
      "learning_rate": 0.054624561504516125,
      "loss": 0.7676,
      "step": 281440
    },
    {
      "epoch": 453.97,
      "learning_rate": 0.05462133570129033,
      "loss": 0.7675,
      "step": 281460
    },
    {
      "epoch": 454.0,
      "learning_rate": 0.05461810989806452,
      "loss": 0.7615,
      "step": 281480
    },
    {
      "epoch": 454.0,
      "eval_accuracy": {
        "accuracy": 0.7524783389274842
      },
      "eval_loss": 1.1447373628616333,
      "eval_runtime": 3.1705,
      "eval_samples_per_second": 4040.657,
      "eval_steps_per_second": 63.396,
      "step": 281480
    },
    {
      "epoch": 454.03,
      "learning_rate": 0.05461488409483872,
      "loss": 0.7792,
      "step": 281500
    },
    {
      "epoch": 454.06,
      "learning_rate": 0.05461165829161291,
      "loss": 0.7379,
      "step": 281520
    },
    {
      "epoch": 454.1,
      "learning_rate": 0.05460843248838709,
      "loss": 0.7639,
      "step": 281540
    },
    {
      "epoch": 454.13,
      "learning_rate": 0.05460520668516129,
      "loss": 0.7629,
      "step": 281560
    },
    {
      "epoch": 454.16,
      "learning_rate": 0.05460198088193549,
      "loss": 0.7634,
      "step": 281580
    },
    {
      "epoch": 454.19,
      "learning_rate": 0.05459875507870968,
      "loss": 0.7458,
      "step": 281600
    },
    {
      "epoch": 454.23,
      "learning_rate": 0.05459552927548387,
      "loss": 0.7318,
      "step": 281620
    },
    {
      "epoch": 454.26,
      "learning_rate": 0.05459230347225807,
      "loss": 0.7306,
      "step": 281640
    },
    {
      "epoch": 454.29,
      "learning_rate": 0.05458907766903226,
      "loss": 0.7249,
      "step": 281660
    },
    {
      "epoch": 454.32,
      "learning_rate": 0.05458585186580646,
      "loss": 0.7306,
      "step": 281680
    },
    {
      "epoch": 454.35,
      "learning_rate": 0.054582626062580644,
      "loss": 0.7468,
      "step": 281700
    },
    {
      "epoch": 454.39,
      "learning_rate": 0.05457940025935485,
      "loss": 0.7478,
      "step": 281720
    },
    {
      "epoch": 454.42,
      "learning_rate": 0.05457617445612903,
      "loss": 0.7656,
      "step": 281740
    },
    {
      "epoch": 454.45,
      "learning_rate": 0.054572948652903235,
      "loss": 0.7341,
      "step": 281760
    },
    {
      "epoch": 454.48,
      "learning_rate": 0.05456972284967742,
      "loss": 0.75,
      "step": 281780
    },
    {
      "epoch": 454.52,
      "learning_rate": 0.054566497046451626,
      "loss": 0.754,
      "step": 281800
    },
    {
      "epoch": 454.55,
      "learning_rate": 0.0545632712432258,
      "loss": 0.7514,
      "step": 281820
    },
    {
      "epoch": 454.58,
      "learning_rate": 0.05456004544000001,
      "loss": 0.7731,
      "step": 281840
    },
    {
      "epoch": 454.61,
      "learning_rate": 0.054556819636774195,
      "loss": 0.7581,
      "step": 281860
    },
    {
      "epoch": 454.65,
      "learning_rate": 0.05455359383354839,
      "loss": 0.7519,
      "step": 281880
    },
    {
      "epoch": 454.68,
      "learning_rate": 0.05455036803032259,
      "loss": 0.7419,
      "step": 281900
    },
    {
      "epoch": 454.71,
      "learning_rate": 0.05454714222709678,
      "loss": 0.7647,
      "step": 281920
    },
    {
      "epoch": 454.74,
      "learning_rate": 0.054543916423870964,
      "loss": 0.7526,
      "step": 281940
    },
    {
      "epoch": 454.77,
      "learning_rate": 0.05454069062064518,
      "loss": 0.7437,
      "step": 281960
    },
    {
      "epoch": 454.81,
      "learning_rate": 0.05453746481741936,
      "loss": 0.7516,
      "step": 281980
    },
    {
      "epoch": 454.84,
      "learning_rate": 0.05453423901419355,
      "loss": 0.763,
      "step": 282000
    },
    {
      "epoch": 454.87,
      "learning_rate": 0.05453101321096775,
      "loss": 0.76,
      "step": 282020
    },
    {
      "epoch": 454.9,
      "learning_rate": 0.054527787407741925,
      "loss": 0.7852,
      "step": 282040
    },
    {
      "epoch": 454.94,
      "learning_rate": 0.05452456160451613,
      "loss": 0.7736,
      "step": 282060
    },
    {
      "epoch": 454.97,
      "learning_rate": 0.054521335801290316,
      "loss": 0.7486,
      "step": 282080
    },
    {
      "epoch": 455.0,
      "learning_rate": 0.05451827128822581,
      "loss": 0.7566,
      "step": 282100
    },
    {
      "epoch": 455.0,
      "eval_accuracy": {
        "accuracy": 0.7579423932557958
      },
      "eval_loss": 1.1057988405227661,
      "eval_runtime": 2.8442,
      "eval_samples_per_second": 4504.194,
      "eval_steps_per_second": 70.669,
      "step": 282100
    },
    {
      "epoch": 455.03,
      "learning_rate": 0.054515045485000004,
      "loss": 0.7219,
      "step": 282120
    },
    {
      "epoch": 455.06,
      "learning_rate": 0.05451181968177419,
      "loss": 0.7117,
      "step": 282140
    },
    {
      "epoch": 455.1,
      "learning_rate": 0.054508593878548395,
      "loss": 0.7576,
      "step": 282160
    },
    {
      "epoch": 455.13,
      "learning_rate": 0.05450536807532258,
      "loss": 0.758,
      "step": 282180
    },
    {
      "epoch": 455.16,
      "learning_rate": 0.05450214227209679,
      "loss": 0.7306,
      "step": 282200
    },
    {
      "epoch": 455.19,
      "learning_rate": 0.054498916468870964,
      "loss": 0.7512,
      "step": 282220
    },
    {
      "epoch": 455.23,
      "learning_rate": 0.05449569066564517,
      "loss": 0.7648,
      "step": 282240
    },
    {
      "epoch": 455.26,
      "learning_rate": 0.054492464862419356,
      "loss": 0.7368,
      "step": 282260
    },
    {
      "epoch": 455.29,
      "learning_rate": 0.05448923905919356,
      "loss": 0.7453,
      "step": 282280
    },
    {
      "epoch": 455.32,
      "learning_rate": 0.05448601325596775,
      "loss": 0.7416,
      "step": 282300
    },
    {
      "epoch": 455.35,
      "learning_rate": 0.05448278745274193,
      "loss": 0.7512,
      "step": 282320
    },
    {
      "epoch": 455.39,
      "learning_rate": 0.05447956164951613,
      "loss": 0.7614,
      "step": 282340
    },
    {
      "epoch": 455.42,
      "learning_rate": 0.05447633584629033,
      "loss": 0.7529,
      "step": 282360
    },
    {
      "epoch": 455.45,
      "learning_rate": 0.05447311004306452,
      "loss": 0.7531,
      "step": 282380
    },
    {
      "epoch": 455.48,
      "learning_rate": 0.05446988423983871,
      "loss": 0.769,
      "step": 282400
    },
    {
      "epoch": 455.52,
      "learning_rate": 0.05446665843661291,
      "loss": 0.7622,
      "step": 282420
    },
    {
      "epoch": 455.55,
      "learning_rate": 0.0544634326333871,
      "loss": 0.7501,
      "step": 282440
    },
    {
      "epoch": 455.58,
      "learning_rate": 0.0544602068301613,
      "loss": 0.761,
      "step": 282460
    },
    {
      "epoch": 455.61,
      "learning_rate": 0.05445698102693548,
      "loss": 0.7644,
      "step": 282480
    },
    {
      "epoch": 455.65,
      "learning_rate": 0.05445375522370969,
      "loss": 0.7483,
      "step": 282500
    },
    {
      "epoch": 455.68,
      "learning_rate": 0.05445052942048387,
      "loss": 0.7324,
      "step": 282520
    },
    {
      "epoch": 455.71,
      "learning_rate": 0.054447303617258073,
      "loss": 0.7467,
      "step": 282540
    },
    {
      "epoch": 455.74,
      "learning_rate": 0.05444407781403226,
      "loss": 0.754,
      "step": 282560
    },
    {
      "epoch": 455.77,
      "learning_rate": 0.054440852010806465,
      "loss": 0.7507,
      "step": 282580
    },
    {
      "epoch": 455.81,
      "learning_rate": 0.05443762620758065,
      "loss": 0.7348,
      "step": 282600
    },
    {
      "epoch": 455.84,
      "learning_rate": 0.05443440040435485,
      "loss": 0.7224,
      "step": 282620
    },
    {
      "epoch": 455.87,
      "learning_rate": 0.054431174601129034,
      "loss": 0.7413,
      "step": 282640
    },
    {
      "epoch": 455.9,
      "learning_rate": 0.054427948797903226,
      "loss": 0.7624,
      "step": 282660
    },
    {
      "epoch": 455.94,
      "learning_rate": 0.054424722994677426,
      "loss": 0.7554,
      "step": 282680
    },
    {
      "epoch": 455.97,
      "learning_rate": 0.05442149719145162,
      "loss": 0.7539,
      "step": 282700
    },
    {
      "epoch": 456.0,
      "learning_rate": 0.0544182713882258,
      "loss": 0.7583,
      "step": 282720
    },
    {
      "epoch": 456.0,
      "eval_accuracy": {
        "accuracy": 0.7573179299039887
      },
      "eval_loss": 1.1001133918762207,
      "eval_runtime": 2.8856,
      "eval_samples_per_second": 4439.64,
      "eval_steps_per_second": 69.656,
      "step": 282720
    },
    {
      "epoch": 456.03,
      "learning_rate": 0.054415045585000016,
      "loss": 0.7825,
      "step": 282740
    },
    {
      "epoch": 456.06,
      "learning_rate": 0.0544118197817742,
      "loss": 0.7505,
      "step": 282760
    },
    {
      "epoch": 456.1,
      "learning_rate": 0.054408593978548386,
      "loss": 0.7504,
      "step": 282780
    },
    {
      "epoch": 456.13,
      "learning_rate": 0.05440536817532259,
      "loss": 0.7373,
      "step": 282800
    },
    {
      "epoch": 456.16,
      "learning_rate": 0.054402142372096764,
      "loss": 0.7336,
      "step": 282820
    },
    {
      "epoch": 456.19,
      "learning_rate": 0.05439891656887097,
      "loss": 0.74,
      "step": 282840
    },
    {
      "epoch": 456.23,
      "learning_rate": 0.054395690765645155,
      "loss": 0.7601,
      "step": 282860
    },
    {
      "epoch": 456.26,
      "learning_rate": 0.05439246496241937,
      "loss": 0.7481,
      "step": 282880
    },
    {
      "epoch": 456.29,
      "learning_rate": 0.05438923915919355,
      "loss": 0.7371,
      "step": 282900
    },
    {
      "epoch": 456.32,
      "learning_rate": 0.054386013355967745,
      "loss": 0.7295,
      "step": 282920
    },
    {
      "epoch": 456.35,
      "learning_rate": 0.05438278755274193,
      "loss": 0.7564,
      "step": 282940
    },
    {
      "epoch": 456.39,
      "learning_rate": 0.05437956174951613,
      "loss": 0.7592,
      "step": 282960
    },
    {
      "epoch": 456.42,
      "learning_rate": 0.05437633594629032,
      "loss": 0.7554,
      "step": 282980
    },
    {
      "epoch": 456.45,
      "learning_rate": 0.05437311014306452,
      "loss": 0.7551,
      "step": 283000
    },
    {
      "epoch": 456.48,
      "learning_rate": 0.05436988433983872,
      "loss": 0.7423,
      "step": 283020
    },
    {
      "epoch": 456.52,
      "learning_rate": 0.05436665853661291,
      "loss": 0.7348,
      "step": 283040
    },
    {
      "epoch": 456.55,
      "learning_rate": 0.0543634327333871,
      "loss": 0.7618,
      "step": 283060
    },
    {
      "epoch": 456.58,
      "learning_rate": 0.05436020693016128,
      "loss": 0.7544,
      "step": 283080
    },
    {
      "epoch": 456.61,
      "learning_rate": 0.05435698112693549,
      "loss": 0.7717,
      "step": 283100
    },
    {
      "epoch": 456.65,
      "learning_rate": 0.054353755323709674,
      "loss": 0.7795,
      "step": 283120
    },
    {
      "epoch": 456.68,
      "learning_rate": 0.05435052952048389,
      "loss": 0.7754,
      "step": 283140
    },
    {
      "epoch": 456.71,
      "learning_rate": 0.05434730371725807,
      "loss": 0.7708,
      "step": 283160
    },
    {
      "epoch": 456.74,
      "learning_rate": 0.054344077914032264,
      "loss": 0.758,
      "step": 283180
    },
    {
      "epoch": 456.77,
      "learning_rate": 0.05434085211080645,
      "loss": 0.7507,
      "step": 283200
    },
    {
      "epoch": 456.81,
      "learning_rate": 0.054337626307580655,
      "loss": 0.7541,
      "step": 283220
    },
    {
      "epoch": 456.84,
      "learning_rate": 0.05433440050435484,
      "loss": 0.7656,
      "step": 283240
    },
    {
      "epoch": 456.87,
      "learning_rate": 0.054331174701129026,
      "loss": 0.7321,
      "step": 283260
    },
    {
      "epoch": 456.9,
      "learning_rate": 0.05432794889790324,
      "loss": 0.7384,
      "step": 283280
    },
    {
      "epoch": 456.94,
      "learning_rate": 0.054324723094677424,
      "loss": 0.7603,
      "step": 283300
    },
    {
      "epoch": 456.97,
      "learning_rate": 0.054321497291451616,
      "loss": 0.7469,
      "step": 283320
    },
    {
      "epoch": 457.0,
      "learning_rate": 0.054318271488225815,
      "loss": 0.7253,
      "step": 283340
    },
    {
      "epoch": 457.0,
      "eval_accuracy": {
        "accuracy": 0.7595816095542893
      },
      "eval_loss": 1.1183927059173584,
      "eval_runtime": 3.2047,
      "eval_samples_per_second": 3997.608,
      "eval_steps_per_second": 62.721,
      "step": 283340
    },
    {
      "epoch": 457.03,
      "learning_rate": 0.05431504568500001,
      "loss": 0.7435,
      "step": 283360
    },
    {
      "epoch": 457.06,
      "learning_rate": 0.05431181988177419,
      "loss": 0.7365,
      "step": 283380
    },
    {
      "epoch": 457.1,
      "learning_rate": 0.05430859407854839,
      "loss": 0.7352,
      "step": 283400
    },
    {
      "epoch": 457.13,
      "learning_rate": 0.05430536827532258,
      "loss": 0.7454,
      "step": 283420
    },
    {
      "epoch": 457.16,
      "learning_rate": 0.05430214247209678,
      "loss": 0.7463,
      "step": 283440
    },
    {
      "epoch": 457.19,
      "learning_rate": 0.05429891666887097,
      "loss": 0.737,
      "step": 283460
    },
    {
      "epoch": 457.23,
      "learning_rate": 0.054295690865645174,
      "loss": 0.7501,
      "step": 283480
    },
    {
      "epoch": 457.26,
      "learning_rate": 0.05429246506241935,
      "loss": 0.7486,
      "step": 283500
    },
    {
      "epoch": 457.29,
      "learning_rate": 0.05428923925919356,
      "loss": 0.7433,
      "step": 283520
    },
    {
      "epoch": 457.32,
      "learning_rate": 0.054286013455967744,
      "loss": 0.7527,
      "step": 283540
    },
    {
      "epoch": 457.35,
      "learning_rate": 0.05428278765274194,
      "loss": 0.7679,
      "step": 283560
    },
    {
      "epoch": 457.39,
      "learning_rate": 0.054279561849516135,
      "loss": 0.7773,
      "step": 283580
    },
    {
      "epoch": 457.42,
      "learning_rate": 0.05427633604629032,
      "loss": 0.771,
      "step": 283600
    },
    {
      "epoch": 457.45,
      "learning_rate": 0.05427311024306452,
      "loss": 0.7403,
      "step": 283620
    },
    {
      "epoch": 457.48,
      "learning_rate": 0.05426988443983871,
      "loss": 0.7411,
      "step": 283640
    },
    {
      "epoch": 457.52,
      "learning_rate": 0.05426665863661291,
      "loss": 0.7552,
      "step": 283660
    },
    {
      "epoch": 457.55,
      "learning_rate": 0.05426343283338711,
      "loss": 0.7549,
      "step": 283680
    },
    {
      "epoch": 457.58,
      "learning_rate": 0.054260207030161295,
      "loss": 0.7551,
      "step": 283700
    },
    {
      "epoch": 457.61,
      "learning_rate": 0.05425698122693548,
      "loss": 0.7637,
      "step": 283720
    },
    {
      "epoch": 457.65,
      "learning_rate": 0.054253755423709686,
      "loss": 0.7832,
      "step": 283740
    },
    {
      "epoch": 457.68,
      "learning_rate": 0.05425052962048387,
      "loss": 0.784,
      "step": 283760
    },
    {
      "epoch": 457.71,
      "learning_rate": 0.05424730381725808,
      "loss": 0.7759,
      "step": 283780
    },
    {
      "epoch": 457.74,
      "learning_rate": 0.05424407801403225,
      "loss": 0.7507,
      "step": 283800
    },
    {
      "epoch": 457.77,
      "learning_rate": 0.05424085221080646,
      "loss": 0.7641,
      "step": 283820
    },
    {
      "epoch": 457.81,
      "learning_rate": 0.05423762640758065,
      "loss": 0.7593,
      "step": 283840
    },
    {
      "epoch": 457.84,
      "learning_rate": 0.05423440060435484,
      "loss": 0.756,
      "step": 283860
    },
    {
      "epoch": 457.87,
      "learning_rate": 0.05423117480112904,
      "loss": 0.7529,
      "step": 283880
    },
    {
      "epoch": 457.9,
      "learning_rate": 0.05422794899790323,
      "loss": 0.7555,
      "step": 283900
    },
    {
      "epoch": 457.94,
      "learning_rate": 0.054224723194677416,
      "loss": 0.7715,
      "step": 283920
    },
    {
      "epoch": 457.97,
      "learning_rate": 0.054221497391451615,
      "loss": 0.7722,
      "step": 283940
    },
    {
      "epoch": 458.0,
      "learning_rate": 0.054218271588225814,
      "loss": 0.7557,
      "step": 283960
    },
    {
      "epoch": 458.0,
      "eval_accuracy": {
        "accuracy": 0.7635625634220592
      },
      "eval_loss": 1.091626524925232,
      "eval_runtime": 4.0118,
      "eval_samples_per_second": 3193.336,
      "eval_steps_per_second": 50.102,
      "step": 283960
    },
    {
      "epoch": 458.03,
      "learning_rate": 0.054215045785000006,
      "loss": 0.772,
      "step": 283980
    },
    {
      "epoch": 458.06,
      "learning_rate": 0.05421181998177419,
      "loss": 0.7532,
      "step": 284000
    },
    {
      "epoch": 458.1,
      "learning_rate": 0.054208594178548376,
      "loss": 0.7234,
      "step": 284020
    },
    {
      "epoch": 458.13,
      "learning_rate": 0.05420536837532258,
      "loss": 0.7281,
      "step": 284040
    },
    {
      "epoch": 458.16,
      "learning_rate": 0.05420214257209677,
      "loss": 0.7326,
      "step": 284060
    },
    {
      "epoch": 458.19,
      "learning_rate": 0.05419891676887098,
      "loss": 0.7392,
      "step": 284080
    },
    {
      "epoch": 458.23,
      "learning_rate": 0.054195690965645166,
      "loss": 0.7359,
      "step": 284100
    },
    {
      "epoch": 458.26,
      "learning_rate": 0.05419246516241936,
      "loss": 0.7295,
      "step": 284120
    },
    {
      "epoch": 458.29,
      "learning_rate": 0.05418923935919354,
      "loss": 0.7373,
      "step": 284140
    },
    {
      "epoch": 458.32,
      "learning_rate": 0.05418601355596774,
      "loss": 0.7554,
      "step": 284160
    },
    {
      "epoch": 458.35,
      "learning_rate": 0.054182787752741934,
      "loss": 0.7179,
      "step": 284180
    },
    {
      "epoch": 458.39,
      "learning_rate": 0.05417956194951613,
      "loss": 0.742,
      "step": 284200
    },
    {
      "epoch": 458.42,
      "learning_rate": 0.05417633614629033,
      "loss": 0.7717,
      "step": 284220
    },
    {
      "epoch": 458.45,
      "learning_rate": 0.05417311034306452,
      "loss": 0.756,
      "step": 284240
    },
    {
      "epoch": 458.48,
      "learning_rate": 0.05416988453983871,
      "loss": 0.7619,
      "step": 284260
    },
    {
      "epoch": 458.52,
      "learning_rate": 0.05416665873661291,
      "loss": 0.7353,
      "step": 284280
    },
    {
      "epoch": 458.55,
      "learning_rate": 0.0541634329333871,
      "loss": 0.7442,
      "step": 284300
    },
    {
      "epoch": 458.58,
      "learning_rate": 0.054160207130161286,
      "loss": 0.7647,
      "step": 284320
    },
    {
      "epoch": 458.61,
      "learning_rate": 0.0541569813269355,
      "loss": 0.7306,
      "step": 284340
    },
    {
      "epoch": 458.65,
      "learning_rate": 0.054153755523709685,
      "loss": 0.7501,
      "step": 284360
    },
    {
      "epoch": 458.68,
      "learning_rate": 0.05415052972048388,
      "loss": 0.7432,
      "step": 284380
    },
    {
      "epoch": 458.71,
      "learning_rate": 0.05414730391725806,
      "loss": 0.7436,
      "step": 284400
    },
    {
      "epoch": 458.74,
      "learning_rate": 0.05414407811403227,
      "loss": 0.7706,
      "step": 284420
    },
    {
      "epoch": 458.77,
      "learning_rate": 0.05414085231080645,
      "loss": 0.7617,
      "step": 284440
    },
    {
      "epoch": 458.81,
      "learning_rate": 0.054137626507580666,
      "loss": 0.771,
      "step": 284460
    },
    {
      "epoch": 458.84,
      "learning_rate": 0.05413440070435484,
      "loss": 0.7484,
      "step": 284480
    },
    {
      "epoch": 458.87,
      "learning_rate": 0.05413117490112904,
      "loss": 0.7553,
      "step": 284500
    },
    {
      "epoch": 458.9,
      "learning_rate": 0.05412794909790323,
      "loss": 0.7703,
      "step": 284520
    },
    {
      "epoch": 458.94,
      "learning_rate": 0.054124723294677414,
      "loss": 0.7676,
      "step": 284540
    },
    {
      "epoch": 458.97,
      "learning_rate": 0.05412149749145162,
      "loss": 0.7472,
      "step": 284560
    },
    {
      "epoch": 459.0,
      "learning_rate": 0.05411843297838709,
      "loss": 0.7575,
      "step": 284580
    },
    {
      "epoch": 459.0,
      "eval_accuracy": {
        "accuracy": 0.7647334322066973
      },
      "eval_loss": 1.1157628297805786,
      "eval_runtime": 2.909,
      "eval_samples_per_second": 4403.948,
      "eval_steps_per_second": 69.096,
      "step": 284580
    },
    {
      "epoch": 459.03,
      "learning_rate": 0.0541152071751613,
      "loss": 0.7596,
      "step": 284600
    },
    {
      "epoch": 459.06,
      "learning_rate": 0.054111981371935486,
      "loss": 0.7383,
      "step": 284620
    },
    {
      "epoch": 459.1,
      "learning_rate": 0.05410875556870968,
      "loss": 0.7287,
      "step": 284640
    },
    {
      "epoch": 459.13,
      "learning_rate": 0.05410552976548388,
      "loss": 0.7689,
      "step": 284660
    },
    {
      "epoch": 459.16,
      "learning_rate": 0.05410230396225807,
      "loss": 0.7204,
      "step": 284680
    },
    {
      "epoch": 459.19,
      "learning_rate": 0.054099078159032254,
      "loss": 0.767,
      "step": 284700
    },
    {
      "epoch": 459.23,
      "learning_rate": 0.05409585235580647,
      "loss": 0.7317,
      "step": 284720
    },
    {
      "epoch": 459.26,
      "learning_rate": 0.05409262655258065,
      "loss": 0.7292,
      "step": 284740
    },
    {
      "epoch": 459.29,
      "learning_rate": 0.054089400749354845,
      "loss": 0.7491,
      "step": 284760
    },
    {
      "epoch": 459.32,
      "learning_rate": 0.05408617494612903,
      "loss": 0.7473,
      "step": 284780
    },
    {
      "epoch": 459.35,
      "learning_rate": 0.054082949142903215,
      "loss": 0.7687,
      "step": 284800
    },
    {
      "epoch": 459.39,
      "learning_rate": 0.05407972333967742,
      "loss": 0.7348,
      "step": 284820
    },
    {
      "epoch": 459.42,
      "learning_rate": 0.054076497536451607,
      "loss": 0.7392,
      "step": 284840
    },
    {
      "epoch": 459.45,
      "learning_rate": 0.05407327173322582,
      "loss": 0.7275,
      "step": 284860
    },
    {
      "epoch": 459.48,
      "learning_rate": 0.054070045930000005,
      "loss": 0.753,
      "step": 284880
    },
    {
      "epoch": 459.52,
      "learning_rate": 0.0540668201267742,
      "loss": 0.7559,
      "step": 284900
    },
    {
      "epoch": 459.55,
      "learning_rate": 0.05406359432354838,
      "loss": 0.7491,
      "step": 284920
    },
    {
      "epoch": 459.58,
      "learning_rate": 0.05406036852032258,
      "loss": 0.7542,
      "step": 284940
    },
    {
      "epoch": 459.61,
      "learning_rate": 0.05405714271709677,
      "loss": 0.7499,
      "step": 284960
    },
    {
      "epoch": 459.65,
      "learning_rate": 0.05405391691387097,
      "loss": 0.7487,
      "step": 284980
    },
    {
      "epoch": 459.68,
      "learning_rate": 0.05405069111064517,
      "loss": 0.7668,
      "step": 285000
    },
    {
      "epoch": 459.71,
      "learning_rate": 0.05404746530741936,
      "loss": 0.7639,
      "step": 285020
    },
    {
      "epoch": 459.74,
      "learning_rate": 0.05404423950419355,
      "loss": 0.7723,
      "step": 285040
    },
    {
      "epoch": 459.77,
      "learning_rate": 0.05404101370096775,
      "loss": 0.7798,
      "step": 285060
    },
    {
      "epoch": 459.81,
      "learning_rate": 0.05403778789774194,
      "loss": 0.7787,
      "step": 285080
    },
    {
      "epoch": 459.84,
      "learning_rate": 0.054034562094516125,
      "loss": 0.7635,
      "step": 285100
    },
    {
      "epoch": 459.87,
      "learning_rate": 0.05403133629129034,
      "loss": 0.7698,
      "step": 285120
    },
    {
      "epoch": 459.9,
      "learning_rate": 0.054028110488064524,
      "loss": 0.7545,
      "step": 285140
    },
    {
      "epoch": 459.94,
      "learning_rate": 0.054024884684838716,
      "loss": 0.7373,
      "step": 285160
    },
    {
      "epoch": 459.97,
      "learning_rate": 0.0540216588816129,
      "loss": 0.749,
      "step": 285180
    },
    {
      "epoch": 460.0,
      "learning_rate": 0.05401843307838711,
      "loss": 0.7648,
      "step": 285200
    },
    {
      "epoch": 460.0,
      "eval_accuracy": {
        "accuracy": 0.7521661072515806
      },
      "eval_loss": 1.133264422416687,
      "eval_runtime": 2.8223,
      "eval_samples_per_second": 4539.206,
      "eval_steps_per_second": 71.219,
      "step": 285200
    },
    {
      "epoch": 460.03,
      "learning_rate": 0.05401520727516129,
      "loss": 0.795,
      "step": 285220
    },
    {
      "epoch": 460.06,
      "learning_rate": 0.05401198147193548,
      "loss": 0.754,
      "step": 285240
    },
    {
      "epoch": 460.1,
      "learning_rate": 0.05400875566870969,
      "loss": 0.7306,
      "step": 285260
    },
    {
      "epoch": 460.13,
      "learning_rate": 0.054005529865483876,
      "loss": 0.7491,
      "step": 285280
    },
    {
      "epoch": 460.16,
      "learning_rate": 0.05400230406225807,
      "loss": 0.7274,
      "step": 285300
    },
    {
      "epoch": 460.19,
      "learning_rate": 0.05399907825903225,
      "loss": 0.7618,
      "step": 285320
    },
    {
      "epoch": 460.23,
      "learning_rate": 0.05399585245580646,
      "loss": 0.7538,
      "step": 285340
    },
    {
      "epoch": 460.26,
      "learning_rate": 0.053992626652580644,
      "loss": 0.7367,
      "step": 285360
    },
    {
      "epoch": 460.29,
      "learning_rate": 0.05398940084935484,
      "loss": 0.7392,
      "step": 285380
    },
    {
      "epoch": 460.32,
      "learning_rate": 0.05398617504612903,
      "loss": 0.7456,
      "step": 285400
    },
    {
      "epoch": 460.35,
      "learning_rate": 0.053982949242903235,
      "loss": 0.7513,
      "step": 285420
    },
    {
      "epoch": 460.39,
      "learning_rate": 0.05397972343967742,
      "loss": 0.7342,
      "step": 285440
    },
    {
      "epoch": 460.42,
      "learning_rate": 0.053976497636451626,
      "loss": 0.7426,
      "step": 285460
    },
    {
      "epoch": 460.45,
      "learning_rate": 0.053973271833225804,
      "loss": 0.7636,
      "step": 285480
    },
    {
      "epoch": 460.48,
      "learning_rate": 0.05397004603000001,
      "loss": 0.7593,
      "step": 285500
    },
    {
      "epoch": 460.52,
      "learning_rate": 0.053966820226774195,
      "loss": 0.7362,
      "step": 285520
    },
    {
      "epoch": 460.55,
      "learning_rate": 0.0539635944235484,
      "loss": 0.7446,
      "step": 285540
    },
    {
      "epoch": 460.58,
      "learning_rate": 0.05396036862032258,
      "loss": 0.7609,
      "step": 285560
    },
    {
      "epoch": 460.61,
      "learning_rate": 0.05395714281709677,
      "loss": 0.775,
      "step": 285580
    },
    {
      "epoch": 460.65,
      "learning_rate": 0.05395391701387097,
      "loss": 0.7439,
      "step": 285600
    },
    {
      "epoch": 460.68,
      "learning_rate": 0.05395069121064516,
      "loss": 0.7572,
      "step": 285620
    },
    {
      "epoch": 460.71,
      "learning_rate": 0.05394746540741936,
      "loss": 0.7162,
      "step": 285640
    },
    {
      "epoch": 460.74,
      "learning_rate": 0.05394423960419356,
      "loss": 0.7434,
      "step": 285660
    },
    {
      "epoch": 460.77,
      "learning_rate": 0.053941013800967746,
      "loss": 0.7522,
      "step": 285680
    },
    {
      "epoch": 460.81,
      "learning_rate": 0.05393778799774193,
      "loss": 0.7408,
      "step": 285700
    },
    {
      "epoch": 460.84,
      "learning_rate": 0.05393456219451614,
      "loss": 0.7567,
      "step": 285720
    },
    {
      "epoch": 460.87,
      "learning_rate": 0.05393133639129032,
      "loss": 0.7549,
      "step": 285740
    },
    {
      "epoch": 460.9,
      "learning_rate": 0.053928110588064515,
      "loss": 0.7772,
      "step": 285760
    },
    {
      "epoch": 460.94,
      "learning_rate": 0.0539248847848387,
      "loss": 0.7637,
      "step": 285780
    },
    {
      "epoch": 460.97,
      "learning_rate": 0.05392165898161291,
      "loss": 0.7608,
      "step": 285800
    },
    {
      "epoch": 461.0,
      "learning_rate": 0.0539184331783871,
      "loss": 0.7443,
      "step": 285820
    },
    {
      "epoch": 461.0,
      "eval_accuracy": {
        "accuracy": 0.745453126219655
      },
      "eval_loss": 1.1716896295547485,
      "eval_runtime": 2.7356,
      "eval_samples_per_second": 4682.99,
      "eval_steps_per_second": 73.474,
      "step": 285820
    },
    {
      "epoch": 461.03,
      "learning_rate": 0.053915207375161305,
      "loss": 0.7852,
      "step": 285840
    },
    {
      "epoch": 461.06,
      "learning_rate": 0.053911981571935476,
      "loss": 0.7377,
      "step": 285860
    },
    {
      "epoch": 461.1,
      "learning_rate": 0.05390875576870968,
      "loss": 0.7128,
      "step": 285880
    },
    {
      "epoch": 461.13,
      "learning_rate": 0.05390552996548387,
      "loss": 0.7547,
      "step": 285900
    },
    {
      "epoch": 461.16,
      "learning_rate": 0.053902304162258066,
      "loss": 0.745,
      "step": 285920
    },
    {
      "epoch": 461.19,
      "learning_rate": 0.053899078359032265,
      "loss": 0.7373,
      "step": 285940
    },
    {
      "epoch": 461.23,
      "learning_rate": 0.05389585255580646,
      "loss": 0.7325,
      "step": 285960
    },
    {
      "epoch": 461.26,
      "learning_rate": 0.05389262675258064,
      "loss": 0.7426,
      "step": 285980
    },
    {
      "epoch": 461.29,
      "learning_rate": 0.05388940094935485,
      "loss": 0.7332,
      "step": 286000
    },
    {
      "epoch": 461.32,
      "learning_rate": 0.053886175146129034,
      "loss": 0.7391,
      "step": 286020
    },
    {
      "epoch": 461.35,
      "learning_rate": 0.05388294934290322,
      "loss": 0.7493,
      "step": 286040
    },
    {
      "epoch": 461.39,
      "learning_rate": 0.05387972353967743,
      "loss": 0.7381,
      "step": 286060
    },
    {
      "epoch": 461.42,
      "learning_rate": 0.05387649773645162,
      "loss": 0.7413,
      "step": 286080
    },
    {
      "epoch": 461.45,
      "learning_rate": 0.05387327193322581,
      "loss": 0.7509,
      "step": 286100
    },
    {
      "epoch": 461.48,
      "learning_rate": 0.053870046129999995,
      "loss": 0.7293,
      "step": 286120
    },
    {
      "epoch": 461.52,
      "learning_rate": 0.0538668203267742,
      "loss": 0.7389,
      "step": 286140
    },
    {
      "epoch": 461.55,
      "learning_rate": 0.053863594523548386,
      "loss": 0.7581,
      "step": 286160
    },
    {
      "epoch": 461.58,
      "learning_rate": 0.053860368720322585,
      "loss": 0.7594,
      "step": 286180
    },
    {
      "epoch": 461.61,
      "learning_rate": 0.053857142917096784,
      "loss": 0.749,
      "step": 286200
    },
    {
      "epoch": 461.65,
      "learning_rate": 0.05385391711387097,
      "loss": 0.7525,
      "step": 286220
    },
    {
      "epoch": 461.68,
      "learning_rate": 0.05385069131064516,
      "loss": 0.7621,
      "step": 286240
    },
    {
      "epoch": 461.71,
      "learning_rate": 0.05384746550741936,
      "loss": 0.7658,
      "step": 286260
    },
    {
      "epoch": 461.74,
      "learning_rate": 0.05384423970419355,
      "loss": 0.7488,
      "step": 286280
    },
    {
      "epoch": 461.77,
      "learning_rate": 0.05384101390096774,
      "loss": 0.7438,
      "step": 286300
    },
    {
      "epoch": 461.81,
      "learning_rate": 0.05383778809774195,
      "loss": 0.7362,
      "step": 286320
    },
    {
      "epoch": 461.84,
      "learning_rate": 0.05383456229451612,
      "loss": 0.7598,
      "step": 286340
    },
    {
      "epoch": 461.87,
      "learning_rate": 0.05383133649129033,
      "loss": 0.7603,
      "step": 286360
    },
    {
      "epoch": 461.9,
      "learning_rate": 0.053828110688064514,
      "loss": 0.7701,
      "step": 286380
    },
    {
      "epoch": 461.94,
      "learning_rate": 0.05382488488483872,
      "loss": 0.7556,
      "step": 286400
    },
    {
      "epoch": 461.97,
      "learning_rate": 0.053821659081612905,
      "loss": 0.7696,
      "step": 286420
    },
    {
      "epoch": 462.0,
      "learning_rate": 0.05381843327838712,
      "loss": 0.7797,
      "step": 286440
    },
    {
      "epoch": 462.0,
      "eval_accuracy": {
        "accuracy": 0.7570056982280853
      },
      "eval_loss": 1.1364020109176636,
      "eval_runtime": 2.7834,
      "eval_samples_per_second": 4602.587,
      "eval_steps_per_second": 72.213,
      "step": 286440
    },
    {
      "epoch": 462.03,
      "learning_rate": 0.05381520747516129,
      "loss": 0.7763,
      "step": 286460
    },
    {
      "epoch": 462.06,
      "learning_rate": 0.05381198167193549,
      "loss": 0.7568,
      "step": 286480
    },
    {
      "epoch": 462.1,
      "learning_rate": 0.05380875586870968,
      "loss": 0.7335,
      "step": 286500
    },
    {
      "epoch": 462.13,
      "learning_rate": 0.053805530065483866,
      "loss": 0.7434,
      "step": 286520
    },
    {
      "epoch": 462.16,
      "learning_rate": 0.05380230426225807,
      "loss": 0.7384,
      "step": 286540
    },
    {
      "epoch": 462.19,
      "learning_rate": 0.05379907845903226,
      "loss": 0.7547,
      "step": 286560
    },
    {
      "epoch": 462.23,
      "learning_rate": 0.053795852655806456,
      "loss": 0.7359,
      "step": 286580
    },
    {
      "epoch": 462.26,
      "learning_rate": 0.053792626852580655,
      "loss": 0.7297,
      "step": 286600
    },
    {
      "epoch": 462.29,
      "learning_rate": 0.05378940104935485,
      "loss": 0.7372,
      "step": 286620
    },
    {
      "epoch": 462.32,
      "learning_rate": 0.053786175246129025,
      "loss": 0.722,
      "step": 286640
    },
    {
      "epoch": 462.35,
      "learning_rate": 0.05378294944290323,
      "loss": 0.746,
      "step": 286660
    },
    {
      "epoch": 462.39,
      "learning_rate": 0.05377972363967742,
      "loss": 0.7542,
      "step": 286680
    },
    {
      "epoch": 462.42,
      "learning_rate": 0.05377649783645162,
      "loss": 0.7244,
      "step": 286700
    },
    {
      "epoch": 462.45,
      "learning_rate": 0.05377327203322581,
      "loss": 0.7608,
      "step": 286720
    },
    {
      "epoch": 462.48,
      "learning_rate": 0.053770046230000014,
      "loss": 0.7506,
      "step": 286740
    },
    {
      "epoch": 462.52,
      "learning_rate": 0.05376682042677419,
      "loss": 0.7594,
      "step": 286760
    },
    {
      "epoch": 462.55,
      "learning_rate": 0.0537635946235484,
      "loss": 0.7788,
      "step": 286780
    },
    {
      "epoch": 462.58,
      "learning_rate": 0.053760368820322584,
      "loss": 0.7461,
      "step": 286800
    },
    {
      "epoch": 462.61,
      "learning_rate": 0.053757143017096776,
      "loss": 0.7331,
      "step": 286820
    },
    {
      "epoch": 462.65,
      "learning_rate": 0.05375391721387096,
      "loss": 0.7567,
      "step": 286840
    },
    {
      "epoch": 462.68,
      "learning_rate": 0.053750691410645174,
      "loss": 0.7421,
      "step": 286860
    },
    {
      "epoch": 462.71,
      "learning_rate": 0.05374746560741936,
      "loss": 0.7529,
      "step": 286880
    },
    {
      "epoch": 462.74,
      "learning_rate": 0.05374423980419355,
      "loss": 0.7522,
      "step": 286900
    },
    {
      "epoch": 462.77,
      "learning_rate": 0.05374101400096775,
      "loss": 0.7408,
      "step": 286920
    },
    {
      "epoch": 462.81,
      "learning_rate": 0.05373778819774194,
      "loss": 0.7436,
      "step": 286940
    },
    {
      "epoch": 462.84,
      "learning_rate": 0.05373456239451613,
      "loss": 0.7493,
      "step": 286960
    },
    {
      "epoch": 462.87,
      "learning_rate": 0.05373133659129031,
      "loss": 0.73,
      "step": 286980
    },
    {
      "epoch": 462.9,
      "learning_rate": 0.053728110788064526,
      "loss": 0.7397,
      "step": 287000
    },
    {
      "epoch": 462.94,
      "learning_rate": 0.05372488498483871,
      "loss": 0.746,
      "step": 287020
    },
    {
      "epoch": 462.97,
      "learning_rate": 0.05372165918161292,
      "loss": 0.7626,
      "step": 287040
    },
    {
      "epoch": 463.0,
      "learning_rate": 0.05371859466854839,
      "loss": 0.7672,
      "step": 287060
    },
    {
      "epoch": 463.0,
      "eval_accuracy": {
        "accuracy": 0.7557567715244712
      },
      "eval_loss": 1.1204204559326172,
      "eval_runtime": 4.3845,
      "eval_samples_per_second": 2921.886,
      "eval_steps_per_second": 45.843,
      "step": 287060
    },
    {
      "epoch": 463.03,
      "learning_rate": 0.05371536886532259,
      "loss": 0.7595,
      "step": 287080
    },
    {
      "epoch": 463.06,
      "learning_rate": 0.05371214306209679,
      "loss": 0.73,
      "step": 287100
    },
    {
      "epoch": 463.1,
      "learning_rate": 0.053708917258870975,
      "loss": 0.727,
      "step": 287120
    },
    {
      "epoch": 463.13,
      "learning_rate": 0.05370569145564517,
      "loss": 0.73,
      "step": 287140
    },
    {
      "epoch": 463.16,
      "learning_rate": 0.05370246565241935,
      "loss": 0.7201,
      "step": 287160
    },
    {
      "epoch": 463.19,
      "learning_rate": 0.05369923984919356,
      "loss": 0.7626,
      "step": 287180
    },
    {
      "epoch": 463.23,
      "learning_rate": 0.053696014045967744,
      "loss": 0.7486,
      "step": 287200
    },
    {
      "epoch": 463.26,
      "learning_rate": 0.05369278824274196,
      "loss": 0.7232,
      "step": 287220
    },
    {
      "epoch": 463.29,
      "learning_rate": 0.05368956243951613,
      "loss": 0.7276,
      "step": 287240
    },
    {
      "epoch": 463.32,
      "learning_rate": 0.05368633663629033,
      "loss": 0.7253,
      "step": 287260
    },
    {
      "epoch": 463.35,
      "learning_rate": 0.05368311083306452,
      "loss": 0.7328,
      "step": 287280
    },
    {
      "epoch": 463.39,
      "learning_rate": 0.053679885029838705,
      "loss": 0.7499,
      "step": 287300
    },
    {
      "epoch": 463.42,
      "learning_rate": 0.05367665922661291,
      "loss": 0.746,
      "step": 287320
    },
    {
      "epoch": 463.45,
      "learning_rate": 0.053673433423387096,
      "loss": 0.7586,
      "step": 287340
    },
    {
      "epoch": 463.48,
      "learning_rate": 0.053670207620161295,
      "loss": 0.7459,
      "step": 287360
    },
    {
      "epoch": 463.52,
      "learning_rate": 0.053666981816935494,
      "loss": 0.7498,
      "step": 287380
    },
    {
      "epoch": 463.55,
      "learning_rate": 0.053663756013709686,
      "loss": 0.7694,
      "step": 287400
    },
    {
      "epoch": 463.58,
      "learning_rate": 0.05366053021048387,
      "loss": 0.7528,
      "step": 287420
    },
    {
      "epoch": 463.61,
      "learning_rate": 0.05365730440725807,
      "loss": 0.7327,
      "step": 287440
    },
    {
      "epoch": 463.65,
      "learning_rate": 0.053654078604032256,
      "loss": 0.7433,
      "step": 287460
    },
    {
      "epoch": 463.68,
      "learning_rate": 0.05365085280080646,
      "loss": 0.7652,
      "step": 287480
    },
    {
      "epoch": 463.71,
      "learning_rate": 0.05364762699758065,
      "loss": 0.7712,
      "step": 287500
    },
    {
      "epoch": 463.74,
      "learning_rate": 0.05364440119435485,
      "loss": 0.7571,
      "step": 287520
    },
    {
      "epoch": 463.77,
      "learning_rate": 0.05364117539112903,
      "loss": 0.7425,
      "step": 287540
    },
    {
      "epoch": 463.81,
      "learning_rate": 0.05363794958790322,
      "loss": 0.7379,
      "step": 287560
    },
    {
      "epoch": 463.84,
      "learning_rate": 0.05363472378467742,
      "loss": 0.7461,
      "step": 287580
    },
    {
      "epoch": 463.87,
      "learning_rate": 0.053631497981451615,
      "loss": 0.7402,
      "step": 287600
    },
    {
      "epoch": 463.9,
      "learning_rate": 0.053628272178225814,
      "loss": 0.7477,
      "step": 287620
    },
    {
      "epoch": 463.94,
      "learning_rate": 0.05362504637500001,
      "loss": 0.7707,
      "step": 287640
    },
    {
      "epoch": 463.97,
      "learning_rate": 0.0536218205717742,
      "loss": 0.7569,
      "step": 287660
    },
    {
      "epoch": 464.0,
      "learning_rate": 0.05361859476854839,
      "loss": 0.785,
      "step": 287680
    },
    {
      "epoch": 464.0,
      "eval_accuracy": {
        "accuracy": 0.7581765670127234
      },
      "eval_loss": 1.1173880100250244,
      "eval_runtime": 2.7538,
      "eval_samples_per_second": 4652.147,
      "eval_steps_per_second": 72.991,
      "step": 287680
    },
    {
      "epoch": 464.03,
      "learning_rate": 0.05361536896532259,
      "loss": 0.7619,
      "step": 287700
    },
    {
      "epoch": 464.06,
      "learning_rate": 0.05361214316209676,
      "loss": 0.757,
      "step": 287720
    },
    {
      "epoch": 464.1,
      "learning_rate": 0.05360891735887097,
      "loss": 0.7445,
      "step": 287740
    },
    {
      "epoch": 464.13,
      "learning_rate": 0.05360569155564515,
      "loss": 0.7509,
      "step": 287760
    },
    {
      "epoch": 464.16,
      "learning_rate": 0.053602465752419365,
      "loss": 0.7437,
      "step": 287780
    },
    {
      "epoch": 464.19,
      "learning_rate": 0.05359923994919355,
      "loss": 0.7327,
      "step": 287800
    },
    {
      "epoch": 464.23,
      "learning_rate": 0.053596014145967756,
      "loss": 0.7266,
      "step": 287820
    },
    {
      "epoch": 464.26,
      "learning_rate": 0.05359278834274193,
      "loss": 0.7404,
      "step": 287840
    },
    {
      "epoch": 464.29,
      "learning_rate": 0.05358956253951613,
      "loss": 0.7275,
      "step": 287860
    },
    {
      "epoch": 464.32,
      "learning_rate": 0.05358633673629032,
      "loss": 0.7521,
      "step": 287880
    },
    {
      "epoch": 464.35,
      "learning_rate": 0.05358311093306452,
      "loss": 0.7691,
      "step": 287900
    },
    {
      "epoch": 464.39,
      "learning_rate": 0.05357988512983872,
      "loss": 0.7375,
      "step": 287920
    },
    {
      "epoch": 464.42,
      "learning_rate": 0.05357665932661291,
      "loss": 0.7607,
      "step": 287940
    },
    {
      "epoch": 464.45,
      "learning_rate": 0.053573433523387094,
      "loss": 0.7391,
      "step": 287960
    },
    {
      "epoch": 464.48,
      "learning_rate": 0.05357020772016129,
      "loss": 0.7641,
      "step": 287980
    },
    {
      "epoch": 464.52,
      "learning_rate": 0.053566981916935485,
      "loss": 0.758,
      "step": 288000
    },
    {
      "epoch": 464.55,
      "learning_rate": 0.05356375611370967,
      "loss": 0.7413,
      "step": 288020
    },
    {
      "epoch": 464.58,
      "learning_rate": 0.053560530310483884,
      "loss": 0.7358,
      "step": 288040
    },
    {
      "epoch": 464.61,
      "learning_rate": 0.05355730450725807,
      "loss": 0.743,
      "step": 288060
    },
    {
      "epoch": 464.65,
      "learning_rate": 0.05355407870403226,
      "loss": 0.7558,
      "step": 288080
    },
    {
      "epoch": 464.68,
      "learning_rate": 0.053550852900806446,
      "loss": 0.7235,
      "step": 288100
    },
    {
      "epoch": 464.71,
      "learning_rate": 0.05354762709758065,
      "loss": 0.7458,
      "step": 288120
    },
    {
      "epoch": 464.74,
      "learning_rate": 0.05354440129435484,
      "loss": 0.7479,
      "step": 288140
    },
    {
      "epoch": 464.77,
      "learning_rate": 0.05354117549112905,
      "loss": 0.747,
      "step": 288160
    },
    {
      "epoch": 464.81,
      "learning_rate": 0.053537949687903236,
      "loss": 0.7485,
      "step": 288180
    },
    {
      "epoch": 464.84,
      "learning_rate": 0.05353472388467742,
      "loss": 0.761,
      "step": 288200
    },
    {
      "epoch": 464.87,
      "learning_rate": 0.05353149808145161,
      "loss": 0.7437,
      "step": 288220
    },
    {
      "epoch": 464.9,
      "learning_rate": 0.05352827227822581,
      "loss": 0.7538,
      "step": 288240
    },
    {
      "epoch": 464.94,
      "learning_rate": 0.053525046475000004,
      "loss": 0.7687,
      "step": 288260
    },
    {
      "epoch": 464.97,
      "learning_rate": 0.05352182067177419,
      "loss": 0.7698,
      "step": 288280
    },
    {
      "epoch": 465.0,
      "learning_rate": 0.0535185948685484,
      "loss": 0.7823,
      "step": 288300
    },
    {
      "epoch": 465.0,
      "eval_accuracy": {
        "accuracy": 0.7538053235500741
      },
      "eval_loss": 1.1422739028930664,
      "eval_runtime": 2.8392,
      "eval_samples_per_second": 4512.128,
      "eval_steps_per_second": 70.794,
      "step": 288300
    },
    {
      "epoch": 465.03,
      "learning_rate": 0.05351536906532259,
      "loss": 0.7597,
      "step": 288320
    },
    {
      "epoch": 465.06,
      "learning_rate": 0.05351214326209678,
      "loss": 0.7516,
      "step": 288340
    },
    {
      "epoch": 465.1,
      "learning_rate": 0.053508917458870965,
      "loss": 0.7271,
      "step": 288360
    },
    {
      "epoch": 465.13,
      "learning_rate": 0.05350569165564517,
      "loss": 0.7142,
      "step": 288380
    },
    {
      "epoch": 465.16,
      "learning_rate": 0.053502465852419356,
      "loss": 0.7252,
      "step": 288400
    },
    {
      "epoch": 465.19,
      "learning_rate": 0.053499240049193555,
      "loss": 0.7418,
      "step": 288420
    },
    {
      "epoch": 465.23,
      "learning_rate": 0.05349601424596774,
      "loss": 0.7272,
      "step": 288440
    },
    {
      "epoch": 465.26,
      "learning_rate": 0.05349278844274195,
      "loss": 0.7324,
      "step": 288460
    },
    {
      "epoch": 465.29,
      "learning_rate": 0.05348956263951613,
      "loss": 0.7401,
      "step": 288480
    },
    {
      "epoch": 465.32,
      "learning_rate": 0.05348633683629032,
      "loss": 0.7285,
      "step": 288500
    },
    {
      "epoch": 465.35,
      "learning_rate": 0.053483111033064516,
      "loss": 0.7367,
      "step": 288520
    },
    {
      "epoch": 465.39,
      "learning_rate": 0.05347988522983871,
      "loss": 0.7436,
      "step": 288540
    },
    {
      "epoch": 465.42,
      "learning_rate": 0.05347665942661291,
      "loss": 0.7409,
      "step": 288560
    },
    {
      "epoch": 465.45,
      "learning_rate": 0.05347343362338711,
      "loss": 0.7387,
      "step": 288580
    },
    {
      "epoch": 465.48,
      "learning_rate": 0.0534702078201613,
      "loss": 0.7507,
      "step": 288600
    },
    {
      "epoch": 465.52,
      "learning_rate": 0.053466982016935484,
      "loss": 0.7517,
      "step": 288620
    },
    {
      "epoch": 465.55,
      "learning_rate": 0.05346375621370968,
      "loss": 0.7178,
      "step": 288640
    },
    {
      "epoch": 465.58,
      "learning_rate": 0.05346053041048387,
      "loss": 0.7312,
      "step": 288660
    },
    {
      "epoch": 465.61,
      "learning_rate": 0.053457304607258074,
      "loss": 0.722,
      "step": 288680
    },
    {
      "epoch": 465.65,
      "learning_rate": 0.05345407880403226,
      "loss": 0.7386,
      "step": 288700
    },
    {
      "epoch": 465.68,
      "learning_rate": 0.05345085300080646,
      "loss": 0.7441,
      "step": 288720
    },
    {
      "epoch": 465.71,
      "learning_rate": 0.053447627197580644,
      "loss": 0.7611,
      "step": 288740
    },
    {
      "epoch": 465.74,
      "learning_rate": 0.05344440139435485,
      "loss": 0.7826,
      "step": 288760
    },
    {
      "epoch": 465.77,
      "learning_rate": 0.053441175591129035,
      "loss": 0.7896,
      "step": 288780
    },
    {
      "epoch": 465.81,
      "learning_rate": 0.05343794978790323,
      "loss": 0.745,
      "step": 288800
    },
    {
      "epoch": 465.84,
      "learning_rate": 0.05343472398467741,
      "loss": 0.7609,
      "step": 288820
    },
    {
      "epoch": 465.87,
      "learning_rate": 0.053431498181451625,
      "loss": 0.7433,
      "step": 288840
    },
    {
      "epoch": 465.9,
      "learning_rate": 0.05342827237822581,
      "loss": 0.7683,
      "step": 288860
    },
    {
      "epoch": 465.94,
      "learning_rate": 0.053425046575,
      "loss": 0.7798,
      "step": 288880
    },
    {
      "epoch": 465.97,
      "learning_rate": 0.0534218207717742,
      "loss": 0.7705,
      "step": 288900
    },
    {
      "epoch": 466.0,
      "learning_rate": 0.053418594968548394,
      "loss": 0.7476,
      "step": 288920
    },
    {
      "epoch": 466.0,
      "eval_accuracy": {
        "accuracy": 0.7488876746545937
      },
      "eval_loss": 1.1768828630447388,
      "eval_runtime": 4.4603,
      "eval_samples_per_second": 2872.21,
      "eval_steps_per_second": 45.064,
      "step": 288920
    },
    {
      "epoch": 466.03,
      "learning_rate": 0.05341536916532258,
      "loss": 0.7766,
      "step": 288940
    },
    {
      "epoch": 466.06,
      "learning_rate": 0.053412143362096764,
      "loss": 0.7418,
      "step": 288960
    },
    {
      "epoch": 466.1,
      "learning_rate": 0.05340891755887098,
      "loss": 0.7333,
      "step": 288980
    },
    {
      "epoch": 466.13,
      "learning_rate": 0.05340569175564516,
      "loss": 0.7251,
      "step": 289000
    },
    {
      "epoch": 466.16,
      "learning_rate": 0.053402465952419355,
      "loss": 0.7388,
      "step": 289020
    },
    {
      "epoch": 466.19,
      "learning_rate": 0.05339924014919354,
      "loss": 0.7345,
      "step": 289040
    },
    {
      "epoch": 466.23,
      "learning_rate": 0.053396014345967746,
      "loss": 0.7494,
      "step": 289060
    },
    {
      "epoch": 466.26,
      "learning_rate": 0.05339278854274193,
      "loss": 0.7483,
      "step": 289080
    },
    {
      "epoch": 466.29,
      "learning_rate": 0.053389562739516144,
      "loss": 0.7366,
      "step": 289100
    },
    {
      "epoch": 466.32,
      "learning_rate": 0.05338633693629033,
      "loss": 0.7542,
      "step": 289120
    },
    {
      "epoch": 466.35,
      "learning_rate": 0.05338311113306452,
      "loss": 0.7543,
      "step": 289140
    },
    {
      "epoch": 466.39,
      "learning_rate": 0.05337988532983871,
      "loss": 0.7205,
      "step": 289160
    },
    {
      "epoch": 466.42,
      "learning_rate": 0.053376659526612906,
      "loss": 0.7395,
      "step": 289180
    },
    {
      "epoch": 466.45,
      "learning_rate": 0.0533734337233871,
      "loss": 0.7641,
      "step": 289200
    },
    {
      "epoch": 466.48,
      "learning_rate": 0.0533702079201613,
      "loss": 0.7383,
      "step": 289220
    },
    {
      "epoch": 466.52,
      "learning_rate": 0.053366982116935496,
      "loss": 0.7441,
      "step": 289240
    },
    {
      "epoch": 466.55,
      "learning_rate": 0.05336375631370968,
      "loss": 0.7562,
      "step": 289260
    },
    {
      "epoch": 466.58,
      "learning_rate": 0.053360530510483874,
      "loss": 0.7481,
      "step": 289280
    },
    {
      "epoch": 466.61,
      "learning_rate": 0.05335730470725806,
      "loss": 0.7358,
      "step": 289300
    },
    {
      "epoch": 466.65,
      "learning_rate": 0.053354078904032265,
      "loss": 0.7307,
      "step": 289320
    },
    {
      "epoch": 466.68,
      "learning_rate": 0.05335085310080645,
      "loss": 0.7572,
      "step": 289340
    },
    {
      "epoch": 466.71,
      "learning_rate": 0.05334762729758066,
      "loss": 0.7495,
      "step": 289360
    },
    {
      "epoch": 466.74,
      "learning_rate": 0.05334440149435485,
      "loss": 0.7547,
      "step": 289380
    },
    {
      "epoch": 466.77,
      "learning_rate": 0.05334117569112904,
      "loss": 0.7535,
      "step": 289400
    },
    {
      "epoch": 466.81,
      "learning_rate": 0.053337949887903226,
      "loss": 0.7382,
      "step": 289420
    },
    {
      "epoch": 466.84,
      "learning_rate": 0.053334724084677425,
      "loss": 0.7582,
      "step": 289440
    },
    {
      "epoch": 466.87,
      "learning_rate": 0.05333149828145162,
      "loss": 0.7442,
      "step": 289460
    },
    {
      "epoch": 466.9,
      "learning_rate": 0.0533282724782258,
      "loss": 0.7588,
      "step": 289480
    },
    {
      "epoch": 466.94,
      "learning_rate": 0.053325046675,
      "loss": 0.7628,
      "step": 289500
    },
    {
      "epoch": 466.97,
      "learning_rate": 0.0533218208717742,
      "loss": 0.7581,
      "step": 289520
    },
    {
      "epoch": 467.0,
      "learning_rate": 0.05331859506854839,
      "loss": 0.7419,
      "step": 289540
    },
    {
      "epoch": 467.0,
      "eval_accuracy": {
        "accuracy": 0.7612988837717587
      },
      "eval_loss": 1.0940043926239014,
      "eval_runtime": 2.8167,
      "eval_samples_per_second": 4548.291,
      "eval_steps_per_second": 71.361,
      "step": 289540
    },
    {
      "epoch": 467.03,
      "learning_rate": 0.05331536926532258,
      "loss": 0.7507,
      "step": 289560
    },
    {
      "epoch": 467.06,
      "learning_rate": 0.053312143462096784,
      "loss": 0.7403,
      "step": 289580
    },
    {
      "epoch": 467.1,
      "learning_rate": 0.05330891765887096,
      "loss": 0.7233,
      "step": 289600
    },
    {
      "epoch": 467.13,
      "learning_rate": 0.05330569185564517,
      "loss": 0.7403,
      "step": 289620
    },
    {
      "epoch": 467.16,
      "learning_rate": 0.05330246605241935,
      "loss": 0.7294,
      "step": 289640
    },
    {
      "epoch": 467.19,
      "learning_rate": 0.05329924024919356,
      "loss": 0.7308,
      "step": 289660
    },
    {
      "epoch": 467.23,
      "learning_rate": 0.053296014445967745,
      "loss": 0.7279,
      "step": 289680
    },
    {
      "epoch": 467.26,
      "learning_rate": 0.053292788642741944,
      "loss": 0.7402,
      "step": 289700
    },
    {
      "epoch": 467.29,
      "learning_rate": 0.05328956283951613,
      "loss": 0.762,
      "step": 289720
    },
    {
      "epoch": 467.32,
      "learning_rate": 0.05328633703629032,
      "loss": 0.7391,
      "step": 289740
    },
    {
      "epoch": 467.35,
      "learning_rate": 0.05328311123306452,
      "loss": 0.7466,
      "step": 289760
    },
    {
      "epoch": 467.39,
      "learning_rate": 0.05327988542983872,
      "loss": 0.7472,
      "step": 289780
    },
    {
      "epoch": 467.42,
      "learning_rate": 0.053276659626612904,
      "loss": 0.7402,
      "step": 289800
    },
    {
      "epoch": 467.45,
      "learning_rate": 0.0532734338233871,
      "loss": 0.7195,
      "step": 289820
    },
    {
      "epoch": 467.48,
      "learning_rate": 0.053270208020161296,
      "loss": 0.7476,
      "step": 289840
    },
    {
      "epoch": 467.52,
      "learning_rate": 0.05326698221693549,
      "loss": 0.7485,
      "step": 289860
    },
    {
      "epoch": 467.55,
      "learning_rate": 0.05326375641370969,
      "loss": 0.7516,
      "step": 289880
    },
    {
      "epoch": 467.58,
      "learning_rate": 0.05326053061048386,
      "loss": 0.75,
      "step": 289900
    },
    {
      "epoch": 467.61,
      "learning_rate": 0.05325730480725807,
      "loss": 0.7552,
      "step": 289920
    },
    {
      "epoch": 467.65,
      "learning_rate": 0.053254079004032256,
      "loss": 0.7422,
      "step": 289940
    },
    {
      "epoch": 467.68,
      "learning_rate": 0.05325085320080646,
      "loss": 0.7323,
      "step": 289960
    },
    {
      "epoch": 467.71,
      "learning_rate": 0.05324762739758065,
      "loss": 0.7477,
      "step": 289980
    },
    {
      "epoch": 467.74,
      "learning_rate": 0.05324440159435484,
      "loss": 0.7591,
      "step": 290000
    },
    {
      "epoch": 467.77,
      "learning_rate": 0.053241175791129025,
      "loss": 0.7565,
      "step": 290020
    },
    {
      "epoch": 467.81,
      "learning_rate": 0.053237949987903224,
      "loss": 0.7476,
      "step": 290040
    },
    {
      "epoch": 467.84,
      "learning_rate": 0.05323472418467742,
      "loss": 0.7433,
      "step": 290060
    },
    {
      "epoch": 467.87,
      "learning_rate": 0.053231498381451615,
      "loss": 0.7516,
      "step": 290080
    },
    {
      "epoch": 467.9,
      "learning_rate": 0.0532282725782258,
      "loss": 0.7685,
      "step": 290100
    },
    {
      "epoch": 467.94,
      "learning_rate": 0.05322504677500001,
      "loss": 0.7426,
      "step": 290120
    },
    {
      "epoch": 467.97,
      "learning_rate": 0.05322182097177419,
      "loss": 0.7743,
      "step": 290140
    },
    {
      "epoch": 468.0,
      "learning_rate": 0.05321875645870969,
      "loss": 0.7803,
      "step": 290160
    },
    {
      "epoch": 468.0,
      "eval_accuracy": {
        "accuracy": 0.7557567715244712
      },
      "eval_loss": 1.142993688583374,
      "eval_runtime": 2.898,
      "eval_samples_per_second": 4420.696,
      "eval_steps_per_second": 69.359,
      "step": 290160
    },
    {
      "epoch": 468.03,
      "learning_rate": 0.05321553065548388,
      "loss": 0.7308,
      "step": 290180
    },
    {
      "epoch": 468.06,
      "learning_rate": 0.053212304852258065,
      "loss": 0.7515,
      "step": 290200
    },
    {
      "epoch": 468.1,
      "learning_rate": 0.053209079049032264,
      "loss": 0.7531,
      "step": 290220
    },
    {
      "epoch": 468.13,
      "learning_rate": 0.053205853245806456,
      "loss": 0.7209,
      "step": 290240
    },
    {
      "epoch": 468.16,
      "learning_rate": 0.05320262744258064,
      "loss": 0.7343,
      "step": 290260
    },
    {
      "epoch": 468.19,
      "learning_rate": 0.053199401639354854,
      "loss": 0.7446,
      "step": 290280
    },
    {
      "epoch": 468.23,
      "learning_rate": 0.05319617583612904,
      "loss": 0.7454,
      "step": 290300
    },
    {
      "epoch": 468.26,
      "learning_rate": 0.05319295003290323,
      "loss": 0.7413,
      "step": 290320
    },
    {
      "epoch": 468.29,
      "learning_rate": 0.05318972422967742,
      "loss": 0.7308,
      "step": 290340
    },
    {
      "epoch": 468.32,
      "learning_rate": 0.05318649842645162,
      "loss": 0.7565,
      "step": 290360
    },
    {
      "epoch": 468.35,
      "learning_rate": 0.0531832726232258,
      "loss": 0.7298,
      "step": 290380
    },
    {
      "epoch": 468.39,
      "learning_rate": 0.05318004682000001,
      "loss": 0.7358,
      "step": 290400
    },
    {
      "epoch": 468.42,
      "learning_rate": 0.05317682101677419,
      "loss": 0.7328,
      "step": 290420
    },
    {
      "epoch": 468.45,
      "learning_rate": 0.0531735952135484,
      "loss": 0.7144,
      "step": 290440
    },
    {
      "epoch": 468.48,
      "learning_rate": 0.053170369410322584,
      "loss": 0.7316,
      "step": 290460
    },
    {
      "epoch": 468.52,
      "learning_rate": 0.05316714360709679,
      "loss": 0.7099,
      "step": 290480
    },
    {
      "epoch": 468.55,
      "learning_rate": 0.05316391780387097,
      "loss": 0.7382,
      "step": 290500
    },
    {
      "epoch": 468.58,
      "learning_rate": 0.05316069200064516,
      "loss": 0.7539,
      "step": 290520
    },
    {
      "epoch": 468.61,
      "learning_rate": 0.05315746619741936,
      "loss": 0.7566,
      "step": 290540
    },
    {
      "epoch": 468.65,
      "learning_rate": 0.05315424039419356,
      "loss": 0.7442,
      "step": 290560
    },
    {
      "epoch": 468.68,
      "learning_rate": 0.05315101459096774,
      "loss": 0.7544,
      "step": 290580
    },
    {
      "epoch": 468.71,
      "learning_rate": 0.053147788787741936,
      "loss": 0.7559,
      "step": 290600
    },
    {
      "epoch": 468.74,
      "learning_rate": 0.053144562984516135,
      "loss": 0.7375,
      "step": 290620
    },
    {
      "epoch": 468.77,
      "learning_rate": 0.05314133718129033,
      "loss": 0.7356,
      "step": 290640
    },
    {
      "epoch": 468.81,
      "learning_rate": 0.053138111378064526,
      "loss": 0.7646,
      "step": 290660
    },
    {
      "epoch": 468.84,
      "learning_rate": 0.0531348855748387,
      "loss": 0.7562,
      "step": 290680
    },
    {
      "epoch": 468.87,
      "learning_rate": 0.05313165977161291,
      "loss": 0.7641,
      "step": 290700
    },
    {
      "epoch": 468.9,
      "learning_rate": 0.053128433968387095,
      "loss": 0.7687,
      "step": 290720
    },
    {
      "epoch": 468.94,
      "learning_rate": 0.0531252081651613,
      "loss": 0.7488,
      "step": 290740
    },
    {
      "epoch": 468.97,
      "learning_rate": 0.05312198236193549,
      "loss": 0.7329,
      "step": 290760
    },
    {
      "epoch": 469.0,
      "learning_rate": 0.05311875655870968,
      "loss": 0.754,
      "step": 290780
    },
    {
      "epoch": 469.0,
      "eval_accuracy": {
        "accuracy": 0.7609085941768793
      },
      "eval_loss": 1.101211428642273,
      "eval_runtime": 4.5942,
      "eval_samples_per_second": 2788.539,
      "eval_steps_per_second": 43.751,
      "step": 290780
    },
    {
      "epoch": 469.03,
      "learning_rate": 0.053115530755483864,
      "loss": 0.7571,
      "step": 290800
    },
    {
      "epoch": 469.06,
      "learning_rate": 0.05311230495225808,
      "loss": 0.7523,
      "step": 290820
    },
    {
      "epoch": 469.1,
      "learning_rate": 0.05310907914903226,
      "loss": 0.7582,
      "step": 290840
    },
    {
      "epoch": 469.13,
      "learning_rate": 0.053105853345806454,
      "loss": 0.7339,
      "step": 290860
    },
    {
      "epoch": 469.16,
      "learning_rate": 0.05310262754258064,
      "loss": 0.7239,
      "step": 290880
    },
    {
      "epoch": 469.19,
      "learning_rate": 0.053099401739354846,
      "loss": 0.7443,
      "step": 290900
    },
    {
      "epoch": 469.23,
      "learning_rate": 0.05309617593612903,
      "loss": 0.7352,
      "step": 290920
    },
    {
      "epoch": 469.26,
      "learning_rate": 0.05309295013290323,
      "loss": 0.729,
      "step": 290940
    },
    {
      "epoch": 469.29,
      "learning_rate": 0.05308972432967743,
      "loss": 0.7314,
      "step": 290960
    },
    {
      "epoch": 469.32,
      "learning_rate": 0.053086498526451614,
      "loss": 0.7321,
      "step": 290980
    },
    {
      "epoch": 469.35,
      "learning_rate": 0.053083272723225806,
      "loss": 0.7284,
      "step": 291000
    },
    {
      "epoch": 469.39,
      "learning_rate": 0.05308004691999999,
      "loss": 0.7405,
      "step": 291020
    },
    {
      "epoch": 469.42,
      "learning_rate": 0.0530768211167742,
      "loss": 0.7268,
      "step": 291040
    },
    {
      "epoch": 469.45,
      "learning_rate": 0.05307359531354838,
      "loss": 0.7279,
      "step": 291060
    },
    {
      "epoch": 469.48,
      "learning_rate": 0.053070369510322596,
      "loss": 0.733,
      "step": 291080
    },
    {
      "epoch": 469.52,
      "learning_rate": 0.05306714370709678,
      "loss": 0.7406,
      "step": 291100
    },
    {
      "epoch": 469.55,
      "learning_rate": 0.053063917903870966,
      "loss": 0.7586,
      "step": 291120
    },
    {
      "epoch": 469.58,
      "learning_rate": 0.05306069210064516,
      "loss": 0.7543,
      "step": 291140
    },
    {
      "epoch": 469.61,
      "learning_rate": 0.05305746629741936,
      "loss": 0.7391,
      "step": 291160
    },
    {
      "epoch": 469.65,
      "learning_rate": 0.05305424049419355,
      "loss": 0.7327,
      "step": 291180
    },
    {
      "epoch": 469.68,
      "learning_rate": 0.05305101469096775,
      "loss": 0.7526,
      "step": 291200
    },
    {
      "epoch": 469.71,
      "learning_rate": 0.05304778888774195,
      "loss": 0.7717,
      "step": 291220
    },
    {
      "epoch": 469.74,
      "learning_rate": 0.05304456308451613,
      "loss": 0.7544,
      "step": 291240
    },
    {
      "epoch": 469.77,
      "learning_rate": 0.053041337281290325,
      "loss": 0.7502,
      "step": 291260
    },
    {
      "epoch": 469.81,
      "learning_rate": 0.05303811147806451,
      "loss": 0.7532,
      "step": 291280
    },
    {
      "epoch": 469.84,
      "learning_rate": 0.053034885674838717,
      "loss": 0.7456,
      "step": 291300
    },
    {
      "epoch": 469.87,
      "learning_rate": 0.0530316598716129,
      "loss": 0.7356,
      "step": 291320
    },
    {
      "epoch": 469.9,
      "learning_rate": 0.053028434068387115,
      "loss": 0.7187,
      "step": 291340
    },
    {
      "epoch": 469.94,
      "learning_rate": 0.053025208265161286,
      "loss": 0.7563,
      "step": 291360
    },
    {
      "epoch": 469.97,
      "learning_rate": 0.05302198246193549,
      "loss": 0.7582,
      "step": 291380
    },
    {
      "epoch": 470.0,
      "learning_rate": 0.05301875665870968,
      "loss": 0.7488,
      "step": 291400
    },
    {
      "epoch": 470.0,
      "eval_accuracy": {
        "accuracy": 0.754585902739833
      },
      "eval_loss": 1.120201587677002,
      "eval_runtime": 2.9835,
      "eval_samples_per_second": 4293.961,
      "eval_steps_per_second": 67.371,
      "step": 291400
    },
    {
      "epoch": 470.03,
      "learning_rate": 0.05301553085548388,
      "loss": 0.7742,
      "step": 291420
    },
    {
      "epoch": 470.06,
      "learning_rate": 0.05301230505225807,
      "loss": 0.7341,
      "step": 291440
    },
    {
      "epoch": 470.1,
      "learning_rate": 0.053009079249032254,
      "loss": 0.7366,
      "step": 291460
    },
    {
      "epoch": 470.13,
      "learning_rate": 0.05300585344580645,
      "loss": 0.7262,
      "step": 291480
    },
    {
      "epoch": 470.16,
      "learning_rate": 0.05300262764258065,
      "loss": 0.741,
      "step": 291500
    },
    {
      "epoch": 470.19,
      "learning_rate": 0.052999401839354844,
      "loss": 0.731,
      "step": 291520
    },
    {
      "epoch": 470.23,
      "learning_rate": 0.05299617603612903,
      "loss": 0.7373,
      "step": 291540
    },
    {
      "epoch": 470.26,
      "learning_rate": 0.052992950232903235,
      "loss": 0.7241,
      "step": 291560
    },
    {
      "epoch": 470.29,
      "learning_rate": 0.05298972442967742,
      "loss": 0.725,
      "step": 291580
    },
    {
      "epoch": 470.32,
      "learning_rate": 0.05298649862645162,
      "loss": 0.7342,
      "step": 291600
    },
    {
      "epoch": 470.35,
      "learning_rate": 0.052983272823225805,
      "loss": 0.7402,
      "step": 291620
    },
    {
      "epoch": 470.39,
      "learning_rate": 0.05298004702000001,
      "loss": 0.7336,
      "step": 291640
    },
    {
      "epoch": 470.42,
      "learning_rate": 0.05297682121677419,
      "loss": 0.7471,
      "step": 291660
    },
    {
      "epoch": 470.45,
      "learning_rate": 0.052973595413548395,
      "loss": 0.7468,
      "step": 291680
    },
    {
      "epoch": 470.48,
      "learning_rate": 0.05297036961032258,
      "loss": 0.7463,
      "step": 291700
    },
    {
      "epoch": 470.52,
      "learning_rate": 0.052967143807096786,
      "loss": 0.76,
      "step": 291720
    },
    {
      "epoch": 470.55,
      "learning_rate": 0.05296391800387097,
      "loss": 0.7376,
      "step": 291740
    },
    {
      "epoch": 470.58,
      "learning_rate": 0.05296069220064517,
      "loss": 0.7575,
      "step": 291760
    },
    {
      "epoch": 470.61,
      "learning_rate": 0.052957466397419356,
      "loss": 0.7633,
      "step": 291780
    },
    {
      "epoch": 470.65,
      "learning_rate": 0.05295424059419355,
      "loss": 0.7514,
      "step": 291800
    },
    {
      "epoch": 470.68,
      "learning_rate": 0.05295101479096775,
      "loss": 0.7215,
      "step": 291820
    },
    {
      "epoch": 470.71,
      "learning_rate": 0.05294778898774194,
      "loss": 0.7396,
      "step": 291840
    },
    {
      "epoch": 470.74,
      "learning_rate": 0.052944563184516125,
      "loss": 0.7416,
      "step": 291860
    },
    {
      "epoch": 470.77,
      "learning_rate": 0.05294133738129034,
      "loss": 0.7429,
      "step": 291880
    },
    {
      "epoch": 470.81,
      "learning_rate": 0.05293811157806452,
      "loss": 0.7371,
      "step": 291900
    },
    {
      "epoch": 470.84,
      "learning_rate": 0.05293488577483871,
      "loss": 0.7646,
      "step": 291920
    },
    {
      "epoch": 470.87,
      "learning_rate": 0.052931659971612914,
      "loss": 0.7279,
      "step": 291940
    },
    {
      "epoch": 470.9,
      "learning_rate": 0.052928434168387085,
      "loss": 0.7576,
      "step": 291960
    },
    {
      "epoch": 470.94,
      "learning_rate": 0.05292520836516129,
      "loss": 0.7478,
      "step": 291980
    },
    {
      "epoch": 470.97,
      "learning_rate": 0.05292198256193548,
      "loss": 0.7353,
      "step": 292000
    },
    {
      "epoch": 471.0,
      "learning_rate": 0.05291875675870969,
      "loss": 0.7398,
      "step": 292020
    },
    {
      "epoch": 471.0,
      "eval_accuracy": {
        "accuracy": 0.7620014050425415
      },
      "eval_loss": 1.1031125783920288,
      "eval_runtime": 2.8336,
      "eval_samples_per_second": 4521.037,
      "eval_steps_per_second": 70.933,
      "step": 292020
    },
    {
      "epoch": 471.03,
      "learning_rate": 0.052915530955483875,
      "loss": 0.7582,
      "step": 292040
    },
    {
      "epoch": 471.06,
      "learning_rate": 0.05291230515225807,
      "loss": 0.7341,
      "step": 292060
    },
    {
      "epoch": 471.1,
      "learning_rate": 0.05290907934903225,
      "loss": 0.7137,
      "step": 292080
    },
    {
      "epoch": 471.13,
      "learning_rate": 0.05290585354580646,
      "loss": 0.7223,
      "step": 292100
    },
    {
      "epoch": 471.16,
      "learning_rate": 0.052902627742580643,
      "loss": 0.7336,
      "step": 292120
    },
    {
      "epoch": 471.19,
      "learning_rate": 0.05289940193935484,
      "loss": 0.7162,
      "step": 292140
    },
    {
      "epoch": 471.23,
      "learning_rate": 0.05289617613612904,
      "loss": 0.7432,
      "step": 292160
    },
    {
      "epoch": 471.26,
      "learning_rate": 0.052892950332903234,
      "loss": 0.7447,
      "step": 292180
    },
    {
      "epoch": 471.29,
      "learning_rate": 0.05288972452967742,
      "loss": 0.7203,
      "step": 292200
    },
    {
      "epoch": 471.32,
      "learning_rate": 0.052886498726451604,
      "loss": 0.7387,
      "step": 292220
    },
    {
      "epoch": 471.35,
      "learning_rate": 0.05288327292322581,
      "loss": 0.7495,
      "step": 292240
    },
    {
      "epoch": 471.39,
      "learning_rate": 0.052880047119999996,
      "loss": 0.7519,
      "step": 292260
    },
    {
      "epoch": 471.42,
      "learning_rate": 0.05287682131677421,
      "loss": 0.7062,
      "step": 292280
    },
    {
      "epoch": 471.45,
      "learning_rate": 0.052873595513548394,
      "loss": 0.7419,
      "step": 292300
    },
    {
      "epoch": 471.48,
      "learning_rate": 0.052870369710322586,
      "loss": 0.7316,
      "step": 292320
    },
    {
      "epoch": 471.52,
      "learning_rate": 0.05286714390709677,
      "loss": 0.7627,
      "step": 292340
    },
    {
      "epoch": 471.55,
      "learning_rate": 0.05286391810387097,
      "loss": 0.7646,
      "step": 292360
    },
    {
      "epoch": 471.58,
      "learning_rate": 0.05286069230064516,
      "loss": 0.7555,
      "step": 292380
    },
    {
      "epoch": 471.61,
      "learning_rate": 0.05285746649741935,
      "loss": 0.7507,
      "step": 292400
    },
    {
      "epoch": 471.65,
      "learning_rate": 0.05285424069419356,
      "loss": 0.7492,
      "step": 292420
    },
    {
      "epoch": 471.68,
      "learning_rate": 0.052851014890967746,
      "loss": 0.756,
      "step": 292440
    },
    {
      "epoch": 471.71,
      "learning_rate": 0.05284778908774194,
      "loss": 0.7294,
      "step": 292460
    },
    {
      "epoch": 471.74,
      "learning_rate": 0.05284456328451614,
      "loss": 0.7522,
      "step": 292480
    },
    {
      "epoch": 471.77,
      "learning_rate": 0.05284133748129033,
      "loss": 0.7685,
      "step": 292500
    },
    {
      "epoch": 471.81,
      "learning_rate": 0.052838111678064514,
      "loss": 0.7553,
      "step": 292520
    },
    {
      "epoch": 471.84,
      "learning_rate": 0.05283488587483873,
      "loss": 0.741,
      "step": 292540
    },
    {
      "epoch": 471.87,
      "learning_rate": 0.0528316600716129,
      "loss": 0.7434,
      "step": 292560
    },
    {
      "epoch": 471.9,
      "learning_rate": 0.052828434268387105,
      "loss": 0.7491,
      "step": 292580
    },
    {
      "epoch": 471.94,
      "learning_rate": 0.05282520846516129,
      "loss": 0.7552,
      "step": 292600
    },
    {
      "epoch": 471.97,
      "learning_rate": 0.052821982661935496,
      "loss": 0.7581,
      "step": 292620
    },
    {
      "epoch": 472.0,
      "learning_rate": 0.05281891814887098,
      "loss": 0.7469,
      "step": 292640
    },
    {
      "epoch": 472.0,
      "eval_accuracy": {
        "accuracy": 0.762391694637421
      },
      "eval_loss": 1.0876073837280273,
      "eval_runtime": 4.7136,
      "eval_samples_per_second": 2717.861,
      "eval_steps_per_second": 42.642,
      "step": 292640
    },
    {
      "epoch": 472.03,
      "learning_rate": 0.05281569234564515,
      "loss": 0.7386,
      "step": 292660
    },
    {
      "epoch": 472.06,
      "learning_rate": 0.05281246654241936,
      "loss": 0.7212,
      "step": 292680
    },
    {
      "epoch": 472.1,
      "learning_rate": 0.05280924073919355,
      "loss": 0.7175,
      "step": 292700
    },
    {
      "epoch": 472.13,
      "learning_rate": 0.05280601493596775,
      "loss": 0.7382,
      "step": 292720
    },
    {
      "epoch": 472.16,
      "learning_rate": 0.052802789132741924,
      "loss": 0.7296,
      "step": 292740
    },
    {
      "epoch": 472.19,
      "learning_rate": 0.05279956332951613,
      "loss": 0.7269,
      "step": 292760
    },
    {
      "epoch": 472.23,
      "learning_rate": 0.052796337526290316,
      "loss": 0.708,
      "step": 292780
    },
    {
      "epoch": 472.26,
      "learning_rate": 0.05279311172306453,
      "loss": 0.7496,
      "step": 292800
    },
    {
      "epoch": 472.29,
      "learning_rate": 0.052789885919838714,
      "loss": 0.7372,
      "step": 292820
    },
    {
      "epoch": 472.32,
      "learning_rate": 0.052786660116612906,
      "loss": 0.7511,
      "step": 292840
    },
    {
      "epoch": 472.35,
      "learning_rate": 0.05278343431338709,
      "loss": 0.7521,
      "step": 292860
    },
    {
      "epoch": 472.39,
      "learning_rate": 0.0527802085101613,
      "loss": 0.7493,
      "step": 292880
    },
    {
      "epoch": 472.42,
      "learning_rate": 0.05277698270693548,
      "loss": 0.7395,
      "step": 292900
    },
    {
      "epoch": 472.45,
      "learning_rate": 0.05277375690370968,
      "loss": 0.7218,
      "step": 292920
    },
    {
      "epoch": 472.48,
      "learning_rate": 0.05277053110048388,
      "loss": 0.7503,
      "step": 292940
    },
    {
      "epoch": 472.52,
      "learning_rate": 0.05276730529725807,
      "loss": 0.7636,
      "step": 292960
    },
    {
      "epoch": 472.55,
      "learning_rate": 0.05276407949403226,
      "loss": 0.7412,
      "step": 292980
    },
    {
      "epoch": 472.58,
      "learning_rate": 0.05276085369080644,
      "loss": 0.7487,
      "step": 293000
    },
    {
      "epoch": 472.61,
      "learning_rate": 0.05275762788758065,
      "loss": 0.7451,
      "step": 293020
    },
    {
      "epoch": 472.65,
      "learning_rate": 0.052754402084354834,
      "loss": 0.7398,
      "step": 293040
    },
    {
      "epoch": 472.68,
      "learning_rate": 0.05275117628112905,
      "loss": 0.734,
      "step": 293060
    },
    {
      "epoch": 472.71,
      "learning_rate": 0.05274795047790323,
      "loss": 0.7431,
      "step": 293080
    },
    {
      "epoch": 472.74,
      "learning_rate": 0.052744724674677425,
      "loss": 0.7736,
      "step": 293100
    },
    {
      "epoch": 472.77,
      "learning_rate": 0.05274149887145161,
      "loss": 0.7568,
      "step": 293120
    },
    {
      "epoch": 472.81,
      "learning_rate": 0.05273827306822581,
      "loss": 0.7547,
      "step": 293140
    },
    {
      "epoch": 472.84,
      "learning_rate": 0.052735047265,
      "loss": 0.7573,
      "step": 293160
    },
    {
      "epoch": 472.87,
      "learning_rate": 0.0527318214617742,
      "loss": 0.7569,
      "step": 293180
    },
    {
      "epoch": 472.9,
      "learning_rate": 0.0527285956585484,
      "loss": 0.7265,
      "step": 293200
    },
    {
      "epoch": 472.94,
      "learning_rate": 0.052725369855322585,
      "loss": 0.7377,
      "step": 293220
    },
    {
      "epoch": 472.97,
      "learning_rate": 0.05272214405209678,
      "loss": 0.7458,
      "step": 293240
    },
    {
      "epoch": 473.0,
      "learning_rate": 0.052718918248870976,
      "loss": 0.7579,
      "step": 293260
    },
    {
      "epoch": 473.0,
      "eval_accuracy": {
        "accuracy": 0.7481070954648349
      },
      "eval_loss": 1.151334285736084,
      "eval_runtime": 2.8336,
      "eval_samples_per_second": 4521.118,
      "eval_steps_per_second": 70.935,
      "step": 293260
    },
    {
      "epoch": 473.03,
      "learning_rate": 0.05271569244564517,
      "loss": 0.7749,
      "step": 293280
    },
    {
      "epoch": 473.06,
      "learning_rate": 0.05271246664241935,
      "loss": 0.7501,
      "step": 293300
    },
    {
      "epoch": 473.1,
      "learning_rate": 0.052709240839193566,
      "loss": 0.7525,
      "step": 293320
    },
    {
      "epoch": 473.13,
      "learning_rate": 0.05270601503596774,
      "loss": 0.7228,
      "step": 293340
    },
    {
      "epoch": 473.16,
      "learning_rate": 0.052702789232741944,
      "loss": 0.7486,
      "step": 293360
    },
    {
      "epoch": 473.19,
      "learning_rate": 0.05269956342951613,
      "loss": 0.7356,
      "step": 293380
    },
    {
      "epoch": 473.23,
      "learning_rate": 0.052696337626290335,
      "loss": 0.7338,
      "step": 293400
    },
    {
      "epoch": 473.26,
      "learning_rate": 0.05269311182306452,
      "loss": 0.7354,
      "step": 293420
    },
    {
      "epoch": 473.29,
      "learning_rate": 0.052689886019838705,
      "loss": 0.7726,
      "step": 293440
    },
    {
      "epoch": 473.32,
      "learning_rate": 0.052686660216612904,
      "loss": 0.7302,
      "step": 293460
    },
    {
      "epoch": 473.35,
      "learning_rate": 0.052683434413387104,
      "loss": 0.742,
      "step": 293480
    },
    {
      "epoch": 473.39,
      "learning_rate": 0.052680208610161296,
      "loss": 0.7371,
      "step": 293500
    },
    {
      "epoch": 473.42,
      "learning_rate": 0.05267698280693548,
      "loss": 0.7364,
      "step": 293520
    },
    {
      "epoch": 473.45,
      "learning_rate": 0.05267375700370968,
      "loss": 0.7238,
      "step": 293540
    },
    {
      "epoch": 473.48,
      "learning_rate": 0.05267053120048387,
      "loss": 0.7289,
      "step": 293560
    },
    {
      "epoch": 473.52,
      "learning_rate": 0.05266730539725807,
      "loss": 0.7245,
      "step": 293580
    },
    {
      "epoch": 473.55,
      "learning_rate": 0.052664079594032256,
      "loss": 0.7385,
      "step": 293600
    },
    {
      "epoch": 473.58,
      "learning_rate": 0.05266085379080646,
      "loss": 0.7424,
      "step": 293620
    },
    {
      "epoch": 473.61,
      "learning_rate": 0.05265762798758064,
      "loss": 0.7434,
      "step": 293640
    },
    {
      "epoch": 473.65,
      "learning_rate": 0.05265440218435485,
      "loss": 0.737,
      "step": 293660
    },
    {
      "epoch": 473.68,
      "learning_rate": 0.05265117638112903,
      "loss": 0.7467,
      "step": 293680
    },
    {
      "epoch": 473.71,
      "learning_rate": 0.05264795057790324,
      "loss": 0.7536,
      "step": 293700
    },
    {
      "epoch": 473.74,
      "learning_rate": 0.05264472477467742,
      "loss": 0.7347,
      "step": 293720
    },
    {
      "epoch": 473.77,
      "learning_rate": 0.05264149897145162,
      "loss": 0.7382,
      "step": 293740
    },
    {
      "epoch": 473.81,
      "learning_rate": 0.05263827316822581,
      "loss": 0.7525,
      "step": 293760
    },
    {
      "epoch": 473.84,
      "learning_rate": 0.052635047365,
      "loss": 0.7446,
      "step": 293780
    },
    {
      "epoch": 473.87,
      "learning_rate": 0.0526318215617742,
      "loss": 0.7405,
      "step": 293800
    },
    {
      "epoch": 473.9,
      "learning_rate": 0.05262859575854839,
      "loss": 0.7485,
      "step": 293820
    },
    {
      "epoch": 473.94,
      "learning_rate": 0.052625369955322576,
      "loss": 0.7754,
      "step": 293840
    },
    {
      "epoch": 473.97,
      "learning_rate": 0.05262214415209679,
      "loss": 0.7505,
      "step": 293860
    },
    {
      "epoch": 474.0,
      "learning_rate": 0.052618918348870974,
      "loss": 0.7455,
      "step": 293880
    },
    {
      "epoch": 474.0,
      "eval_accuracy": {
        "accuracy": 0.7567715244711576
      },
      "eval_loss": 1.123344898223877,
      "eval_runtime": 3.0435,
      "eval_samples_per_second": 4209.238,
      "eval_steps_per_second": 66.041,
      "step": 293880
    },
    {
      "epoch": 474.03,
      "learning_rate": 0.05261569254564517,
      "loss": 0.7371,
      "step": 293900
    },
    {
      "epoch": 474.06,
      "learning_rate": 0.052612466742419366,
      "loss": 0.7293,
      "step": 293920
    },
    {
      "epoch": 474.1,
      "learning_rate": 0.05260924093919354,
      "loss": 0.7258,
      "step": 293940
    },
    {
      "epoch": 474.13,
      "learning_rate": 0.05260601513596774,
      "loss": 0.741,
      "step": 293960
    },
    {
      "epoch": 474.16,
      "learning_rate": 0.05260278933274193,
      "loss": 0.7145,
      "step": 293980
    },
    {
      "epoch": 474.19,
      "learning_rate": 0.05259956352951614,
      "loss": 0.7232,
      "step": 294000
    },
    {
      "epoch": 474.23,
      "learning_rate": 0.052596337726290326,
      "loss": 0.7212,
      "step": 294020
    },
    {
      "epoch": 474.26,
      "learning_rate": 0.05259311192306452,
      "loss": 0.728,
      "step": 294040
    },
    {
      "epoch": 474.29,
      "learning_rate": 0.052589886119838704,
      "loss": 0.7264,
      "step": 294060
    },
    {
      "epoch": 474.32,
      "learning_rate": 0.0525866603166129,
      "loss": 0.7354,
      "step": 294080
    },
    {
      "epoch": 474.35,
      "learning_rate": 0.052583434513387095,
      "loss": 0.7279,
      "step": 294100
    },
    {
      "epoch": 474.39,
      "learning_rate": 0.052580208710161294,
      "loss": 0.739,
      "step": 294120
    },
    {
      "epoch": 474.42,
      "learning_rate": 0.05257698290693549,
      "loss": 0.7364,
      "step": 294140
    },
    {
      "epoch": 474.45,
      "learning_rate": 0.052573757103709685,
      "loss": 0.7426,
      "step": 294160
    },
    {
      "epoch": 474.48,
      "learning_rate": 0.05257053130048387,
      "loss": 0.7426,
      "step": 294180
    },
    {
      "epoch": 474.52,
      "learning_rate": 0.05256730549725807,
      "loss": 0.7321,
      "step": 294200
    },
    {
      "epoch": 474.55,
      "learning_rate": 0.05256407969403226,
      "loss": 0.7368,
      "step": 294220
    },
    {
      "epoch": 474.58,
      "learning_rate": 0.05256085389080645,
      "loss": 0.7395,
      "step": 294240
    },
    {
      "epoch": 474.61,
      "learning_rate": 0.05255762808758066,
      "loss": 0.7523,
      "step": 294260
    },
    {
      "epoch": 474.65,
      "learning_rate": 0.052554402284354845,
      "loss": 0.7342,
      "step": 294280
    },
    {
      "epoch": 474.68,
      "learning_rate": 0.05255117648112904,
      "loss": 0.748,
      "step": 294300
    },
    {
      "epoch": 474.71,
      "learning_rate": 0.05254795067790322,
      "loss": 0.755,
      "step": 294320
    },
    {
      "epoch": 474.74,
      "learning_rate": 0.05254472487467743,
      "loss": 0.7392,
      "step": 294340
    },
    {
      "epoch": 474.77,
      "learning_rate": 0.052541499071451614,
      "loss": 0.7405,
      "step": 294360
    },
    {
      "epoch": 474.81,
      "learning_rate": 0.0525382732682258,
      "loss": 0.7631,
      "step": 294380
    },
    {
      "epoch": 474.84,
      "learning_rate": 0.05253504746500001,
      "loss": 0.7565,
      "step": 294400
    },
    {
      "epoch": 474.87,
      "learning_rate": 0.0525318216617742,
      "loss": 0.7551,
      "step": 294420
    },
    {
      "epoch": 474.9,
      "learning_rate": 0.05252859585854839,
      "loss": 0.7585,
      "step": 294440
    },
    {
      "epoch": 474.94,
      "learning_rate": 0.05252537005532259,
      "loss": 0.7678,
      "step": 294460
    },
    {
      "epoch": 474.97,
      "learning_rate": 0.05252214425209678,
      "loss": 0.7342,
      "step": 294480
    },
    {
      "epoch": 475.0,
      "learning_rate": 0.052518918448870966,
      "loss": 0.7535,
      "step": 294500
    },
    {
      "epoch": 475.0,
      "eval_accuracy": {
        "accuracy": 0.7570056982280853
      },
      "eval_loss": 1.1080437898635864,
      "eval_runtime": 3.0735,
      "eval_samples_per_second": 4168.176,
      "eval_steps_per_second": 65.397,
      "step": 294500
    },
    {
      "epoch": 475.03,
      "learning_rate": 0.052515692645645165,
      "loss": 0.7318,
      "step": 294520
    },
    {
      "epoch": 475.06,
      "learning_rate": 0.05251246684241935,
      "loss": 0.7203,
      "step": 294540
    },
    {
      "epoch": 475.1,
      "learning_rate": 0.052509241039193556,
      "loss": 0.7066,
      "step": 294560
    },
    {
      "epoch": 475.13,
      "learning_rate": 0.05250601523596774,
      "loss": 0.737,
      "step": 294580
    },
    {
      "epoch": 475.16,
      "learning_rate": 0.05250278943274195,
      "loss": 0.7393,
      "step": 294600
    },
    {
      "epoch": 475.19,
      "learning_rate": 0.052499563629516126,
      "loss": 0.7203,
      "step": 294620
    },
    {
      "epoch": 475.23,
      "learning_rate": 0.05249633782629033,
      "loss": 0.7167,
      "step": 294640
    },
    {
      "epoch": 475.26,
      "learning_rate": 0.05249311202306452,
      "loss": 0.7434,
      "step": 294660
    },
    {
      "epoch": 475.29,
      "learning_rate": 0.052489886219838716,
      "loss": 0.7532,
      "step": 294680
    },
    {
      "epoch": 475.32,
      "learning_rate": 0.05248666041661291,
      "loss": 0.7194,
      "step": 294700
    },
    {
      "epoch": 475.35,
      "learning_rate": 0.052483434613387094,
      "loss": 0.7413,
      "step": 294720
    },
    {
      "epoch": 475.39,
      "learning_rate": 0.05248020881016129,
      "loss": 0.7419,
      "step": 294740
    },
    {
      "epoch": 475.42,
      "learning_rate": 0.052476983006935485,
      "loss": 0.7219,
      "step": 294760
    },
    {
      "epoch": 475.45,
      "learning_rate": 0.052473757203709684,
      "loss": 0.7339,
      "step": 294780
    },
    {
      "epoch": 475.48,
      "learning_rate": 0.05247053140048388,
      "loss": 0.7443,
      "step": 294800
    },
    {
      "epoch": 475.52,
      "learning_rate": 0.05246730559725807,
      "loss": 0.7368,
      "step": 294820
    },
    {
      "epoch": 475.55,
      "learning_rate": 0.05246407979403225,
      "loss": 0.7491,
      "step": 294840
    },
    {
      "epoch": 475.58,
      "learning_rate": 0.05246085399080646,
      "loss": 0.7419,
      "step": 294860
    },
    {
      "epoch": 475.61,
      "learning_rate": 0.052457628187580645,
      "loss": 0.7317,
      "step": 294880
    },
    {
      "epoch": 475.65,
      "learning_rate": 0.05245440238435485,
      "loss": 0.7542,
      "step": 294900
    },
    {
      "epoch": 475.68,
      "learning_rate": 0.05245117658112902,
      "loss": 0.7599,
      "step": 294920
    },
    {
      "epoch": 475.71,
      "learning_rate": 0.052447950777903235,
      "loss": 0.7545,
      "step": 294940
    },
    {
      "epoch": 475.74,
      "learning_rate": 0.05244472497467742,
      "loss": 0.7492,
      "step": 294960
    },
    {
      "epoch": 475.77,
      "learning_rate": 0.052441499171451626,
      "loss": 0.7693,
      "step": 294980
    },
    {
      "epoch": 475.81,
      "learning_rate": 0.05243827336822581,
      "loss": 0.749,
      "step": 295000
    },
    {
      "epoch": 475.84,
      "learning_rate": 0.052435047565000004,
      "loss": 0.7437,
      "step": 295020
    },
    {
      "epoch": 475.87,
      "learning_rate": 0.05243182176177419,
      "loss": 0.7276,
      "step": 295040
    },
    {
      "epoch": 475.9,
      "learning_rate": 0.05242859595854839,
      "loss": 0.7506,
      "step": 295060
    },
    {
      "epoch": 475.94,
      "learning_rate": 0.05242537015532259,
      "loss": 0.7354,
      "step": 295080
    },
    {
      "epoch": 475.97,
      "learning_rate": 0.05242214435209678,
      "loss": 0.744,
      "step": 295100
    },
    {
      "epoch": 476.0,
      "learning_rate": 0.05241907983903227,
      "loss": 0.7521,
      "step": 295120
    },
    {
      "epoch": 476.0,
      "eval_accuracy": {
        "accuracy": 0.7575521036609164
      },
      "eval_loss": 1.1040679216384888,
      "eval_runtime": 2.8124,
      "eval_samples_per_second": 4555.156,
      "eval_steps_per_second": 71.469,
      "step": 295120
    },
    {
      "epoch": 476.03,
      "learning_rate": 0.05241585403580645,
      "loss": 0.7299,
      "step": 295140
    },
    {
      "epoch": 476.06,
      "learning_rate": 0.05241262823258064,
      "loss": 0.7168,
      "step": 295160
    },
    {
      "epoch": 476.1,
      "learning_rate": 0.05240940242935485,
      "loss": 0.7181,
      "step": 295180
    },
    {
      "epoch": 476.13,
      "learning_rate": 0.052406176626129036,
      "loss": 0.715,
      "step": 295200
    },
    {
      "epoch": 476.16,
      "learning_rate": 0.05240295082290323,
      "loss": 0.7291,
      "step": 295220
    },
    {
      "epoch": 476.19,
      "learning_rate": 0.05239972501967743,
      "loss": 0.7299,
      "step": 295240
    },
    {
      "epoch": 476.23,
      "learning_rate": 0.05239649921645162,
      "loss": 0.7463,
      "step": 295260
    },
    {
      "epoch": 476.26,
      "learning_rate": 0.052393273413225805,
      "loss": 0.735,
      "step": 295280
    },
    {
      "epoch": 476.29,
      "learning_rate": 0.05239004761000002,
      "loss": 0.7342,
      "step": 295300
    },
    {
      "epoch": 476.32,
      "learning_rate": 0.05238682180677419,
      "loss": 0.7186,
      "step": 295320
    },
    {
      "epoch": 476.35,
      "learning_rate": 0.052383596003548395,
      "loss": 0.7201,
      "step": 295340
    },
    {
      "epoch": 476.39,
      "learning_rate": 0.05238037020032258,
      "loss": 0.7319,
      "step": 295360
    },
    {
      "epoch": 476.42,
      "learning_rate": 0.052377144397096786,
      "loss": 0.7294,
      "step": 295380
    },
    {
      "epoch": 476.45,
      "learning_rate": 0.052373918593870965,
      "loss": 0.7394,
      "step": 295400
    },
    {
      "epoch": 476.48,
      "learning_rate": 0.05237069279064517,
      "loss": 0.7535,
      "step": 295420
    },
    {
      "epoch": 476.52,
      "learning_rate": 0.052367466987419356,
      "loss": 0.7301,
      "step": 295440
    },
    {
      "epoch": 476.55,
      "learning_rate": 0.052364241184193555,
      "loss": 0.733,
      "step": 295460
    },
    {
      "epoch": 476.58,
      "learning_rate": 0.05236101538096775,
      "loss": 0.713,
      "step": 295480
    },
    {
      "epoch": 476.61,
      "learning_rate": 0.05235778957774193,
      "loss": 0.7535,
      "step": 295500
    },
    {
      "epoch": 476.65,
      "learning_rate": 0.05235456377451613,
      "loss": 0.7547,
      "step": 295520
    },
    {
      "epoch": 476.68,
      "learning_rate": 0.052351337971290324,
      "loss": 0.7506,
      "step": 295540
    },
    {
      "epoch": 476.71,
      "learning_rate": 0.05234811216806452,
      "loss": 0.7511,
      "step": 295560
    },
    {
      "epoch": 476.74,
      "learning_rate": 0.05234488636483872,
      "loss": 0.7519,
      "step": 295580
    },
    {
      "epoch": 476.77,
      "learning_rate": 0.05234166056161291,
      "loss": 0.7407,
      "step": 295600
    },
    {
      "epoch": 476.81,
      "learning_rate": 0.05233843475838709,
      "loss": 0.7584,
      "step": 295620
    },
    {
      "epoch": 476.84,
      "learning_rate": 0.0523352089551613,
      "loss": 0.7544,
      "step": 295640
    },
    {
      "epoch": 476.87,
      "learning_rate": 0.052331983151935484,
      "loss": 0.7394,
      "step": 295660
    },
    {
      "epoch": 476.9,
      "learning_rate": 0.05232875734870969,
      "loss": 0.7391,
      "step": 295680
    },
    {
      "epoch": 476.94,
      "learning_rate": 0.05232553154548386,
      "loss": 0.7343,
      "step": 295700
    },
    {
      "epoch": 476.97,
      "learning_rate": 0.052322305742258074,
      "loss": 0.7324,
      "step": 295720
    },
    {
      "epoch": 477.0,
      "learning_rate": 0.05231907993903226,
      "loss": 0.7408,
      "step": 295740
    },
    {
      "epoch": 477.0,
      "eval_accuracy": {
        "accuracy": 0.7582546249316994
      },
      "eval_loss": 1.0915312767028809,
      "eval_runtime": 2.8688,
      "eval_samples_per_second": 4465.671,
      "eval_steps_per_second": 70.065,
      "step": 295740
    },
    {
      "epoch": 477.03,
      "learning_rate": 0.05231585413580645,
      "loss": 0.7493,
      "step": 295760
    },
    {
      "epoch": 477.06,
      "learning_rate": 0.05231262833258065,
      "loss": 0.7181,
      "step": 295780
    },
    {
      "epoch": 477.1,
      "learning_rate": 0.05230940252935484,
      "loss": 0.7162,
      "step": 295800
    },
    {
      "epoch": 477.13,
      "learning_rate": 0.05230617672612903,
      "loss": 0.7233,
      "step": 295820
    },
    {
      "epoch": 477.16,
      "learning_rate": 0.05230295092290324,
      "loss": 0.7121,
      "step": 295840
    },
    {
      "epoch": 477.19,
      "learning_rate": 0.052299725119677426,
      "loss": 0.7292,
      "step": 295860
    },
    {
      "epoch": 477.23,
      "learning_rate": 0.05229649931645162,
      "loss": 0.7291,
      "step": 295880
    },
    {
      "epoch": 477.26,
      "learning_rate": 0.0522932735132258,
      "loss": 0.7347,
      "step": 295900
    },
    {
      "epoch": 477.29,
      "learning_rate": 0.05229004770999999,
      "loss": 0.7256,
      "step": 295920
    },
    {
      "epoch": 477.32,
      "learning_rate": 0.052286821906774195,
      "loss": 0.7259,
      "step": 295940
    },
    {
      "epoch": 477.35,
      "learning_rate": 0.05228359610354838,
      "loss": 0.7273,
      "step": 295960
    },
    {
      "epoch": 477.39,
      "learning_rate": 0.05228037030032259,
      "loss": 0.739,
      "step": 295980
    },
    {
      "epoch": 477.42,
      "learning_rate": 0.05227714449709678,
      "loss": 0.7325,
      "step": 296000
    },
    {
      "epoch": 477.45,
      "learning_rate": 0.05227391869387097,
      "loss": 0.7437,
      "step": 296020
    },
    {
      "epoch": 477.48,
      "learning_rate": 0.052270692890645155,
      "loss": 0.7164,
      "step": 296040
    },
    {
      "epoch": 477.52,
      "learning_rate": 0.05226746708741936,
      "loss": 0.7457,
      "step": 296060
    },
    {
      "epoch": 477.55,
      "learning_rate": 0.05226424128419355,
      "loss": 0.7648,
      "step": 296080
    },
    {
      "epoch": 477.58,
      "learning_rate": 0.052261015480967746,
      "loss": 0.7782,
      "step": 296100
    },
    {
      "epoch": 477.61,
      "learning_rate": 0.052257789677741945,
      "loss": 0.7479,
      "step": 296120
    },
    {
      "epoch": 477.65,
      "learning_rate": 0.05225456387451613,
      "loss": 0.7383,
      "step": 296140
    },
    {
      "epoch": 477.68,
      "learning_rate": 0.05225133807129032,
      "loss": 0.7424,
      "step": 296160
    },
    {
      "epoch": 477.71,
      "learning_rate": 0.05224811226806452,
      "loss": 0.7596,
      "step": 296180
    },
    {
      "epoch": 477.74,
      "learning_rate": 0.05224488646483871,
      "loss": 0.7462,
      "step": 296200
    },
    {
      "epoch": 477.77,
      "learning_rate": 0.05224166066161291,
      "loss": 0.735,
      "step": 296220
    },
    {
      "epoch": 477.81,
      "learning_rate": 0.05223843485838711,
      "loss": 0.7458,
      "step": 296240
    },
    {
      "epoch": 477.84,
      "learning_rate": 0.0522352090551613,
      "loss": 0.7371,
      "step": 296260
    },
    {
      "epoch": 477.87,
      "learning_rate": 0.05223198325193549,
      "loss": 0.7459,
      "step": 296280
    },
    {
      "epoch": 477.9,
      "learning_rate": 0.052228757448709674,
      "loss": 0.7514,
      "step": 296300
    },
    {
      "epoch": 477.94,
      "learning_rate": 0.05222553164548388,
      "loss": 0.7356,
      "step": 296320
    },
    {
      "epoch": 477.97,
      "learning_rate": 0.052222305842258065,
      "loss": 0.7681,
      "step": 296340
    },
    {
      "epoch": 478.0,
      "learning_rate": 0.05221908003903228,
      "loss": 0.7324,
      "step": 296360
    },
    {
      "epoch": 478.0,
      "eval_accuracy": {
        "accuracy": 0.75255639684646
      },
      "eval_loss": 1.1371536254882812,
      "eval_runtime": 3.1119,
      "eval_samples_per_second": 4116.839,
      "eval_steps_per_second": 64.592,
      "step": 296360
    },
    {
      "epoch": 478.03,
      "learning_rate": 0.05221585423580645,
      "loss": 0.7431,
      "step": 296380
    },
    {
      "epoch": 478.06,
      "learning_rate": 0.05221262843258065,
      "loss": 0.7377,
      "step": 296400
    },
    {
      "epoch": 478.1,
      "learning_rate": 0.05220940262935484,
      "loss": 0.7492,
      "step": 296420
    },
    {
      "epoch": 478.13,
      "learning_rate": 0.052206176826129026,
      "loss": 0.7522,
      "step": 296440
    },
    {
      "epoch": 478.16,
      "learning_rate": 0.05220295102290323,
      "loss": 0.7475,
      "step": 296460
    },
    {
      "epoch": 478.19,
      "learning_rate": 0.05219972521967742,
      "loss": 0.7482,
      "step": 296480
    },
    {
      "epoch": 478.23,
      "learning_rate": 0.05219649941645162,
      "loss": 0.7311,
      "step": 296500
    },
    {
      "epoch": 478.26,
      "learning_rate": 0.052193273613225816,
      "loss": 0.7249,
      "step": 296520
    },
    {
      "epoch": 478.29,
      "learning_rate": 0.05219004781000001,
      "loss": 0.7308,
      "step": 296540
    },
    {
      "epoch": 478.32,
      "learning_rate": 0.05218682200677419,
      "loss": 0.7289,
      "step": 296560
    },
    {
      "epoch": 478.35,
      "learning_rate": 0.0521835962035484,
      "loss": 0.7423,
      "step": 296580
    },
    {
      "epoch": 478.39,
      "learning_rate": 0.05218037040032258,
      "loss": 0.7406,
      "step": 296600
    },
    {
      "epoch": 478.42,
      "learning_rate": 0.05217714459709678,
      "loss": 0.7422,
      "step": 296620
    },
    {
      "epoch": 478.45,
      "learning_rate": 0.05217391879387097,
      "loss": 0.7563,
      "step": 296640
    },
    {
      "epoch": 478.48,
      "learning_rate": 0.052170692990645175,
      "loss": 0.7484,
      "step": 296660
    },
    {
      "epoch": 478.52,
      "learning_rate": 0.05216746718741935,
      "loss": 0.751,
      "step": 296680
    },
    {
      "epoch": 478.55,
      "learning_rate": 0.052164241384193545,
      "loss": 0.7441,
      "step": 296700
    },
    {
      "epoch": 478.58,
      "learning_rate": 0.052161015580967744,
      "loss": 0.7618,
      "step": 296720
    },
    {
      "epoch": 478.61,
      "learning_rate": 0.052157789777741936,
      "loss": 0.7506,
      "step": 296740
    },
    {
      "epoch": 478.65,
      "learning_rate": 0.052154563974516135,
      "loss": 0.7354,
      "step": 296760
    },
    {
      "epoch": 478.68,
      "learning_rate": 0.052151338171290335,
      "loss": 0.7473,
      "step": 296780
    },
    {
      "epoch": 478.71,
      "learning_rate": 0.05214811236806452,
      "loss": 0.7394,
      "step": 296800
    },
    {
      "epoch": 478.74,
      "learning_rate": 0.05214488656483871,
      "loss": 0.7322,
      "step": 296820
    },
    {
      "epoch": 478.77,
      "learning_rate": 0.05214166076161291,
      "loss": 0.7338,
      "step": 296840
    },
    {
      "epoch": 478.81,
      "learning_rate": 0.052138434958387096,
      "loss": 0.7527,
      "step": 296860
    },
    {
      "epoch": 478.84,
      "learning_rate": 0.05213520915516129,
      "loss": 0.7308,
      "step": 296880
    },
    {
      "epoch": 478.87,
      "learning_rate": 0.052131983351935474,
      "loss": 0.7366,
      "step": 296900
    },
    {
      "epoch": 478.9,
      "learning_rate": 0.05212875754870969,
      "loss": 0.7503,
      "step": 296920
    },
    {
      "epoch": 478.94,
      "learning_rate": 0.05212553174548387,
      "loss": 0.7386,
      "step": 296940
    },
    {
      "epoch": 478.97,
      "learning_rate": 0.05212230594225808,
      "loss": 0.7338,
      "step": 296960
    },
    {
      "epoch": 479.0,
      "learning_rate": 0.05211908013903225,
      "loss": 0.7312,
      "step": 296980
    },
    {
      "epoch": 479.0,
      "eval_accuracy": {
        "accuracy": 0.7589571462024822
      },
      "eval_loss": 1.0945987701416016,
      "eval_runtime": 2.9346,
      "eval_samples_per_second": 4365.512,
      "eval_steps_per_second": 68.493,
      "step": 296980
    },
    {
      "epoch": 479.03,
      "learning_rate": 0.052115854335806455,
      "loss": 0.7568,
      "step": 297000
    },
    {
      "epoch": 479.06,
      "learning_rate": 0.05211262853258064,
      "loss": 0.7382,
      "step": 297020
    },
    {
      "epoch": 479.1,
      "learning_rate": 0.05210940272935484,
      "loss": 0.7244,
      "step": 297040
    },
    {
      "epoch": 479.13,
      "learning_rate": 0.05210617692612904,
      "loss": 0.7288,
      "step": 297060
    },
    {
      "epoch": 479.16,
      "learning_rate": 0.05210295112290323,
      "loss": 0.7285,
      "step": 297080
    },
    {
      "epoch": 479.19,
      "learning_rate": 0.052099725319677416,
      "loss": 0.7214,
      "step": 297100
    },
    {
      "epoch": 479.23,
      "learning_rate": 0.05209649951645162,
      "loss": 0.7364,
      "step": 297120
    },
    {
      "epoch": 479.26,
      "learning_rate": 0.05209327371322581,
      "loss": 0.7145,
      "step": 297140
    },
    {
      "epoch": 479.29,
      "learning_rate": 0.05209004790999999,
      "loss": 0.7438,
      "step": 297160
    },
    {
      "epoch": 479.32,
      "learning_rate": 0.052086822106774205,
      "loss": 0.7413,
      "step": 297180
    },
    {
      "epoch": 479.35,
      "learning_rate": 0.05208359630354839,
      "loss": 0.7195,
      "step": 297200
    },
    {
      "epoch": 479.39,
      "learning_rate": 0.05208037050032258,
      "loss": 0.7228,
      "step": 297220
    },
    {
      "epoch": 479.42,
      "learning_rate": 0.05207714469709677,
      "loss": 0.7392,
      "step": 297240
    },
    {
      "epoch": 479.45,
      "learning_rate": 0.052073918893870974,
      "loss": 0.7329,
      "step": 297260
    },
    {
      "epoch": 479.48,
      "learning_rate": 0.05207069309064516,
      "loss": 0.7413,
      "step": 297280
    },
    {
      "epoch": 479.52,
      "learning_rate": 0.05206746728741937,
      "loss": 0.7204,
      "step": 297300
    },
    {
      "epoch": 479.55,
      "learning_rate": 0.05206424148419356,
      "loss": 0.7241,
      "step": 297320
    },
    {
      "epoch": 479.58,
      "learning_rate": 0.05206101568096774,
      "loss": 0.7258,
      "step": 297340
    },
    {
      "epoch": 479.61,
      "learning_rate": 0.052057789877741935,
      "loss": 0.7412,
      "step": 297360
    },
    {
      "epoch": 479.65,
      "learning_rate": 0.052054564074516134,
      "loss": 0.7323,
      "step": 297380
    },
    {
      "epoch": 479.68,
      "learning_rate": 0.052051338271290326,
      "loss": 0.7403,
      "step": 297400
    },
    {
      "epoch": 479.71,
      "learning_rate": 0.05204811246806451,
      "loss": 0.7486,
      "step": 297420
    },
    {
      "epoch": 479.74,
      "learning_rate": 0.052044886664838724,
      "loss": 0.7195,
      "step": 297440
    },
    {
      "epoch": 479.77,
      "learning_rate": 0.05204166086161291,
      "loss": 0.7569,
      "step": 297460
    },
    {
      "epoch": 479.81,
      "learning_rate": 0.0520384350583871,
      "loss": 0.7407,
      "step": 297480
    },
    {
      "epoch": 479.84,
      "learning_rate": 0.05203520925516129,
      "loss": 0.7695,
      "step": 297500
    },
    {
      "epoch": 479.87,
      "learning_rate": 0.05203198345193549,
      "loss": 0.7504,
      "step": 297520
    },
    {
      "epoch": 479.9,
      "learning_rate": 0.05202875764870968,
      "loss": 0.7475,
      "step": 297540
    },
    {
      "epoch": 479.94,
      "learning_rate": 0.05202553184548389,
      "loss": 0.7423,
      "step": 297560
    },
    {
      "epoch": 479.97,
      "learning_rate": 0.05202230604225806,
      "loss": 0.7363,
      "step": 297580
    },
    {
      "epoch": 480.0,
      "learning_rate": 0.05201924152919355,
      "loss": 0.7487,
      "step": 297600
    },
    {
      "epoch": 480.0,
      "eval_accuracy": {
        "accuracy": 0.760362188744048
      },
      "eval_loss": 1.09819495677948,
      "eval_runtime": 2.8438,
      "eval_samples_per_second": 4504.821,
      "eval_steps_per_second": 70.679,
      "step": 297600
    },
    {
      "epoch": 480.03,
      "learning_rate": 0.05201601572596775,
      "loss": 0.7299,
      "step": 297620
    },
    {
      "epoch": 480.06,
      "learning_rate": 0.052012789922741935,
      "loss": 0.7481,
      "step": 297640
    },
    {
      "epoch": 480.1,
      "learning_rate": 0.05200956411951614,
      "loss": 0.7177,
      "step": 297660
    },
    {
      "epoch": 480.13,
      "learning_rate": 0.05200633831629031,
      "loss": 0.7196,
      "step": 297680
    },
    {
      "epoch": 480.16,
      "learning_rate": 0.052003112513064526,
      "loss": 0.7122,
      "step": 297700
    },
    {
      "epoch": 480.19,
      "learning_rate": 0.05199988670983871,
      "loss": 0.7418,
      "step": 297720
    },
    {
      "epoch": 480.23,
      "learning_rate": 0.05199666090661292,
      "loss": 0.7268,
      "step": 297740
    },
    {
      "epoch": 480.26,
      "learning_rate": 0.05199343510338709,
      "loss": 0.7197,
      "step": 297760
    },
    {
      "epoch": 480.29,
      "learning_rate": 0.051990209300161294,
      "loss": 0.7268,
      "step": 297780
    },
    {
      "epoch": 480.32,
      "learning_rate": 0.05198698349693548,
      "loss": 0.7298,
      "step": 297800
    },
    {
      "epoch": 480.35,
      "learning_rate": 0.05198375769370968,
      "loss": 0.7396,
      "step": 297820
    },
    {
      "epoch": 480.39,
      "learning_rate": 0.05198053189048388,
      "loss": 0.7317,
      "step": 297840
    },
    {
      "epoch": 480.42,
      "learning_rate": 0.05197730608725807,
      "loss": 0.7281,
      "step": 297860
    },
    {
      "epoch": 480.45,
      "learning_rate": 0.051974080284032255,
      "loss": 0.7393,
      "step": 297880
    },
    {
      "epoch": 480.48,
      "learning_rate": 0.05197085448080646,
      "loss": 0.7343,
      "step": 297900
    },
    {
      "epoch": 480.52,
      "learning_rate": 0.051967628677580646,
      "loss": 0.737,
      "step": 297920
    },
    {
      "epoch": 480.55,
      "learning_rate": 0.05196440287435483,
      "loss": 0.7604,
      "step": 297940
    },
    {
      "epoch": 480.58,
      "learning_rate": 0.051961177071129044,
      "loss": 0.76,
      "step": 297960
    },
    {
      "epoch": 480.61,
      "learning_rate": 0.05195795126790323,
      "loss": 0.7653,
      "step": 297980
    },
    {
      "epoch": 480.65,
      "learning_rate": 0.05195472546467742,
      "loss": 0.7343,
      "step": 298000
    },
    {
      "epoch": 480.68,
      "learning_rate": 0.05195149966145161,
      "loss": 0.7398,
      "step": 298020
    },
    {
      "epoch": 480.71,
      "learning_rate": 0.05194827385822581,
      "loss": 0.7434,
      "step": 298040
    },
    {
      "epoch": 480.74,
      "learning_rate": 0.051945048055,
      "loss": 0.7429,
      "step": 298060
    },
    {
      "epoch": 480.77,
      "learning_rate": 0.0519418222517742,
      "loss": 0.7587,
      "step": 298080
    },
    {
      "epoch": 480.81,
      "learning_rate": 0.051938596448548396,
      "loss": 0.7408,
      "step": 298100
    },
    {
      "epoch": 480.84,
      "learning_rate": 0.05193537064532258,
      "loss": 0.7428,
      "step": 298120
    },
    {
      "epoch": 480.87,
      "learning_rate": 0.051932144842096774,
      "loss": 0.7435,
      "step": 298140
    },
    {
      "epoch": 480.9,
      "learning_rate": 0.05192891903887097,
      "loss": 0.7558,
      "step": 298160
    },
    {
      "epoch": 480.94,
      "learning_rate": 0.051925693235645165,
      "loss": 0.7431,
      "step": 298180
    },
    {
      "epoch": 480.97,
      "learning_rate": 0.051922467432419364,
      "loss": 0.7547,
      "step": 298200
    },
    {
      "epoch": 481.0,
      "learning_rate": 0.05191924162919356,
      "loss": 0.7403,
      "step": 298220
    },
    {
      "epoch": 481.0,
      "eval_accuracy": {
        "accuracy": 0.7608305362579033
      },
      "eval_loss": 1.1114875078201294,
      "eval_runtime": 3.8429,
      "eval_samples_per_second": 3333.691,
      "eval_steps_per_second": 52.304,
      "step": 298220
    },
    {
      "epoch": 481.03,
      "learning_rate": 0.05191601582596775,
      "loss": 0.7618,
      "step": 298240
    },
    {
      "epoch": 481.06,
      "learning_rate": 0.05191279002274194,
      "loss": 0.74,
      "step": 298260
    },
    {
      "epoch": 481.1,
      "learning_rate": 0.051909564219516126,
      "loss": 0.7287,
      "step": 298280
    },
    {
      "epoch": 481.13,
      "learning_rate": 0.05190633841629033,
      "loss": 0.7401,
      "step": 298300
    },
    {
      "epoch": 481.16,
      "learning_rate": 0.05190311261306452,
      "loss": 0.7272,
      "step": 298320
    },
    {
      "epoch": 481.19,
      "learning_rate": 0.05189988680983873,
      "loss": 0.7457,
      "step": 298340
    },
    {
      "epoch": 481.23,
      "learning_rate": 0.0518966610066129,
      "loss": 0.7424,
      "step": 298360
    },
    {
      "epoch": 481.26,
      "learning_rate": 0.05189343520338711,
      "loss": 0.7227,
      "step": 298380
    },
    {
      "epoch": 481.29,
      "learning_rate": 0.05189020940016129,
      "loss": 0.7328,
      "step": 298400
    },
    {
      "epoch": 481.32,
      "learning_rate": 0.05188698359693548,
      "loss": 0.7328,
      "step": 298420
    },
    {
      "epoch": 481.35,
      "learning_rate": 0.051883757793709684,
      "loss": 0.7183,
      "step": 298440
    },
    {
      "epoch": 481.39,
      "learning_rate": 0.05188053199048387,
      "loss": 0.7183,
      "step": 298460
    },
    {
      "epoch": 481.42,
      "learning_rate": 0.05187730618725807,
      "loss": 0.7362,
      "step": 298480
    },
    {
      "epoch": 481.45,
      "learning_rate": 0.05187408038403227,
      "loss": 0.7493,
      "step": 298500
    },
    {
      "epoch": 481.48,
      "learning_rate": 0.05187085458080646,
      "loss": 0.7303,
      "step": 298520
    },
    {
      "epoch": 481.52,
      "learning_rate": 0.051867628777580645,
      "loss": 0.7352,
      "step": 298540
    },
    {
      "epoch": 481.55,
      "learning_rate": 0.051864402974354844,
      "loss": 0.7501,
      "step": 298560
    },
    {
      "epoch": 481.58,
      "learning_rate": 0.05186117717112903,
      "loss": 0.7445,
      "step": 298580
    },
    {
      "epoch": 481.61,
      "learning_rate": 0.051857951367903235,
      "loss": 0.7438,
      "step": 298600
    },
    {
      "epoch": 481.65,
      "learning_rate": 0.05185472556467742,
      "loss": 0.7479,
      "step": 298620
    },
    {
      "epoch": 481.68,
      "learning_rate": 0.051851499761451626,
      "loss": 0.7554,
      "step": 298640
    },
    {
      "epoch": 481.71,
      "learning_rate": 0.051848273958225805,
      "loss": 0.7526,
      "step": 298660
    },
    {
      "epoch": 481.74,
      "learning_rate": 0.05184504815500001,
      "loss": 0.7581,
      "step": 298680
    },
    {
      "epoch": 481.77,
      "learning_rate": 0.051841822351774196,
      "loss": 0.7393,
      "step": 298700
    },
    {
      "epoch": 481.81,
      "learning_rate": 0.05183859654854839,
      "loss": 0.7458,
      "step": 298720
    },
    {
      "epoch": 481.84,
      "learning_rate": 0.05183537074532259,
      "loss": 0.7263,
      "step": 298740
    },
    {
      "epoch": 481.87,
      "learning_rate": 0.051832144942096786,
      "loss": 0.7389,
      "step": 298760
    },
    {
      "epoch": 481.9,
      "learning_rate": 0.05182891913887097,
      "loss": 0.7297,
      "step": 298780
    },
    {
      "epoch": 481.94,
      "learning_rate": 0.051825693335645164,
      "loss": 0.7369,
      "step": 298800
    },
    {
      "epoch": 481.97,
      "learning_rate": 0.05182246753241936,
      "loss": 0.7321,
      "step": 298820
    },
    {
      "epoch": 482.0,
      "learning_rate": 0.051819241729193555,
      "loss": 0.7707,
      "step": 298840
    },
    {
      "epoch": 482.0,
      "eval_accuracy": {
        "accuracy": 0.7523222230895324
      },
      "eval_loss": 1.1139286756515503,
      "eval_runtime": 2.899,
      "eval_samples_per_second": 4419.061,
      "eval_steps_per_second": 69.333,
      "step": 298840
    },
    {
      "epoch": 482.03,
      "learning_rate": 0.05181601592596774,
      "loss": 0.7639,
      "step": 298860
    },
    {
      "epoch": 482.06,
      "learning_rate": 0.051812790122741925,
      "loss": 0.7264,
      "step": 298880
    },
    {
      "epoch": 482.1,
      "learning_rate": 0.05180956431951614,
      "loss": 0.7251,
      "step": 298900
    },
    {
      "epoch": 482.13,
      "learning_rate": 0.05180633851629032,
      "loss": 0.742,
      "step": 298920
    },
    {
      "epoch": 482.16,
      "learning_rate": 0.05180311271306453,
      "loss": 0.7372,
      "step": 298940
    },
    {
      "epoch": 482.19,
      "learning_rate": 0.0517998869098387,
      "loss": 0.7253,
      "step": 298960
    },
    {
      "epoch": 482.23,
      "learning_rate": 0.05179666110661291,
      "loss": 0.7204,
      "step": 298980
    },
    {
      "epoch": 482.26,
      "learning_rate": 0.05179343530338709,
      "loss": 0.7287,
      "step": 299000
    },
    {
      "epoch": 482.29,
      "learning_rate": 0.05179020950016129,
      "loss": 0.7388,
      "step": 299020
    },
    {
      "epoch": 482.32,
      "learning_rate": 0.05178698369693549,
      "loss": 0.7393,
      "step": 299040
    },
    {
      "epoch": 482.35,
      "learning_rate": 0.05178375789370968,
      "loss": 0.7248,
      "step": 299060
    },
    {
      "epoch": 482.39,
      "learning_rate": 0.05178053209048387,
      "loss": 0.7173,
      "step": 299080
    },
    {
      "epoch": 482.42,
      "learning_rate": 0.05177730628725807,
      "loss": 0.7506,
      "step": 299100
    },
    {
      "epoch": 482.45,
      "learning_rate": 0.05177408048403226,
      "loss": 0.7376,
      "step": 299120
    },
    {
      "epoch": 482.48,
      "learning_rate": 0.05177085468080646,
      "loss": 0.7127,
      "step": 299140
    },
    {
      "epoch": 482.52,
      "learning_rate": 0.05176762887758066,
      "loss": 0.7093,
      "step": 299160
    },
    {
      "epoch": 482.55,
      "learning_rate": 0.05176440307435484,
      "loss": 0.7361,
      "step": 299180
    },
    {
      "epoch": 482.58,
      "learning_rate": 0.051761177271129034,
      "loss": 0.7436,
      "step": 299200
    },
    {
      "epoch": 482.61,
      "learning_rate": 0.05175795146790322,
      "loss": 0.7241,
      "step": 299220
    },
    {
      "epoch": 482.65,
      "learning_rate": 0.051754725664677426,
      "loss": 0.7338,
      "step": 299240
    },
    {
      "epoch": 482.68,
      "learning_rate": 0.05175149986145161,
      "loss": 0.7455,
      "step": 299260
    },
    {
      "epoch": 482.71,
      "learning_rate": 0.051748274058225824,
      "loss": 0.7454,
      "step": 299280
    },
    {
      "epoch": 482.74,
      "learning_rate": 0.05174504825500001,
      "loss": 0.745,
      "step": 299300
    },
    {
      "epoch": 482.77,
      "learning_rate": 0.051741822451774194,
      "loss": 0.7301,
      "step": 299320
    },
    {
      "epoch": 482.81,
      "learning_rate": 0.051738596648548386,
      "loss": 0.7121,
      "step": 299340
    },
    {
      "epoch": 482.84,
      "learning_rate": 0.051735370845322586,
      "loss": 0.7085,
      "step": 299360
    },
    {
      "epoch": 482.87,
      "learning_rate": 0.05173214504209678,
      "loss": 0.7308,
      "step": 299380
    },
    {
      "epoch": 482.9,
      "learning_rate": 0.05172891923887096,
      "loss": 0.7358,
      "step": 299400
    },
    {
      "epoch": 482.94,
      "learning_rate": 0.051725693435645176,
      "loss": 0.7476,
      "step": 299420
    },
    {
      "epoch": 482.97,
      "learning_rate": 0.05172246763241936,
      "loss": 0.7504,
      "step": 299440
    },
    {
      "epoch": 483.0,
      "learning_rate": 0.05171924182919355,
      "loss": 0.7709,
      "step": 299460
    },
    {
      "epoch": 483.0,
      "eval_accuracy": {
        "accuracy": 0.7548981344157365
      },
      "eval_loss": 1.141514539718628,
      "eval_runtime": 2.946,
      "eval_samples_per_second": 4348.598,
      "eval_steps_per_second": 68.228,
      "step": 299460
    },
    {
      "epoch": 483.03,
      "learning_rate": 0.05171601602596774,
      "loss": 0.7749,
      "step": 299480
    },
    {
      "epoch": 483.06,
      "learning_rate": 0.051712790222741944,
      "loss": 0.7365,
      "step": 299500
    },
    {
      "epoch": 483.1,
      "learning_rate": 0.05170956441951613,
      "loss": 0.7231,
      "step": 299520
    },
    {
      "epoch": 483.13,
      "learning_rate": 0.05170633861629033,
      "loss": 0.7226,
      "step": 299540
    },
    {
      "epoch": 483.16,
      "learning_rate": 0.051703112813064514,
      "loss": 0.7448,
      "step": 299560
    },
    {
      "epoch": 483.19,
      "learning_rate": 0.05169988700983872,
      "loss": 0.7394,
      "step": 299580
    },
    {
      "epoch": 483.23,
      "learning_rate": 0.051696661206612905,
      "loss": 0.7365,
      "step": 299600
    },
    {
      "epoch": 483.26,
      "learning_rate": 0.05169343540338711,
      "loss": 0.7134,
      "step": 299620
    },
    {
      "epoch": 483.29,
      "learning_rate": 0.05169020960016129,
      "loss": 0.7143,
      "step": 299640
    },
    {
      "epoch": 483.32,
      "learning_rate": 0.05168698379693548,
      "loss": 0.7365,
      "step": 299660
    },
    {
      "epoch": 483.35,
      "learning_rate": 0.05168375799370968,
      "loss": 0.7452,
      "step": 299680
    },
    {
      "epoch": 483.39,
      "learning_rate": 0.05168053219048388,
      "loss": 0.754,
      "step": 299700
    },
    {
      "epoch": 483.42,
      "learning_rate": 0.05167730638725807,
      "loss": 0.7372,
      "step": 299720
    },
    {
      "epoch": 483.45,
      "learning_rate": 0.05167408058403226,
      "loss": 0.7375,
      "step": 299740
    },
    {
      "epoch": 483.48,
      "learning_rate": 0.051670854780806456,
      "loss": 0.733,
      "step": 299760
    },
    {
      "epoch": 483.52,
      "learning_rate": 0.05166762897758065,
      "loss": 0.7246,
      "step": 299780
    },
    {
      "epoch": 483.55,
      "learning_rate": 0.05166440317435485,
      "loss": 0.7213,
      "step": 299800
    },
    {
      "epoch": 483.58,
      "learning_rate": 0.05166117737112903,
      "loss": 0.7477,
      "step": 299820
    },
    {
      "epoch": 483.61,
      "learning_rate": 0.05165795156790323,
      "loss": 0.7302,
      "step": 299840
    },
    {
      "epoch": 483.65,
      "learning_rate": 0.05165472576467742,
      "loss": 0.716,
      "step": 299860
    },
    {
      "epoch": 483.68,
      "learning_rate": 0.05165149996145162,
      "loss": 0.7485,
      "step": 299880
    },
    {
      "epoch": 483.71,
      "learning_rate": 0.05164827415822581,
      "loss": 0.7124,
      "step": 299900
    },
    {
      "epoch": 483.74,
      "learning_rate": 0.051645048355000014,
      "loss": 0.7115,
      "step": 299920
    },
    {
      "epoch": 483.77,
      "learning_rate": 0.051641822551774186,
      "loss": 0.7228,
      "step": 299940
    },
    {
      "epoch": 483.81,
      "learning_rate": 0.0516385967485484,
      "loss": 0.7178,
      "step": 299960
    },
    {
      "epoch": 483.84,
      "learning_rate": 0.051635370945322584,
      "loss": 0.7541,
      "step": 299980
    },
    {
      "epoch": 483.87,
      "learning_rate": 0.051632145142096776,
      "loss": 0.7536,
      "step": 300000
    },
    {
      "epoch": 483.9,
      "learning_rate": 0.051628919338870975,
      "loss": 0.7472,
      "step": 300020
    },
    {
      "epoch": 483.94,
      "learning_rate": 0.05162569353564517,
      "loss": 0.7425,
      "step": 300040
    },
    {
      "epoch": 483.97,
      "learning_rate": 0.05162246773241935,
      "loss": 0.7374,
      "step": 300060
    },
    {
      "epoch": 484.0,
      "learning_rate": 0.05161940321935485,
      "loss": 0.7618,
      "step": 300080
    },
    {
      "epoch": 484.0,
      "eval_accuracy": {
        "accuracy": 0.7506830067910389
      },
      "eval_loss": 1.1444685459136963,
      "eval_runtime": 2.7719,
      "eval_samples_per_second": 4621.693,
      "eval_steps_per_second": 72.513,
      "step": 300080
    },
    {
      "epoch": 484.03,
      "learning_rate": 0.05161617741612903,
      "loss": 0.7186,
      "step": 300100
    },
    {
      "epoch": 484.06,
      "learning_rate": 0.051612951612903225,
      "loss": 0.7203,
      "step": 300120
    },
    {
      "epoch": 484.1,
      "learning_rate": 0.051609725809677424,
      "loss": 0.738,
      "step": 300140
    },
    {
      "epoch": 484.13,
      "learning_rate": 0.05160650000645162,
      "loss": 0.7299,
      "step": 300160
    },
    {
      "epoch": 484.16,
      "learning_rate": 0.0516032742032258,
      "loss": 0.7059,
      "step": 300180
    },
    {
      "epoch": 484.19,
      "learning_rate": 0.051600048400000015,
      "loss": 0.7095,
      "step": 300200
    },
    {
      "epoch": 484.23,
      "learning_rate": 0.0515968225967742,
      "loss": 0.7034,
      "step": 300220
    },
    {
      "epoch": 484.26,
      "learning_rate": 0.05159359679354839,
      "loss": 0.7031,
      "step": 300240
    },
    {
      "epoch": 484.29,
      "learning_rate": 0.05159037099032258,
      "loss": 0.7178,
      "step": 300260
    },
    {
      "epoch": 484.32,
      "learning_rate": 0.05158714518709678,
      "loss": 0.7259,
      "step": 300280
    },
    {
      "epoch": 484.35,
      "learning_rate": 0.05158391938387097,
      "loss": 0.73,
      "step": 300300
    },
    {
      "epoch": 484.39,
      "learning_rate": 0.05158069358064518,
      "loss": 0.7506,
      "step": 300320
    },
    {
      "epoch": 484.42,
      "learning_rate": 0.05157746777741935,
      "loss": 0.7214,
      "step": 300340
    },
    {
      "epoch": 484.45,
      "learning_rate": 0.05157424197419356,
      "loss": 0.7234,
      "step": 300360
    },
    {
      "epoch": 484.48,
      "learning_rate": 0.051571016170967744,
      "loss": 0.7346,
      "step": 300380
    },
    {
      "epoch": 484.52,
      "learning_rate": 0.05156779036774193,
      "loss": 0.7337,
      "step": 300400
    },
    {
      "epoch": 484.55,
      "learning_rate": 0.05156456456451613,
      "loss": 0.7537,
      "step": 300420
    },
    {
      "epoch": 484.58,
      "learning_rate": 0.05156133876129032,
      "loss": 0.7554,
      "step": 300440
    },
    {
      "epoch": 484.61,
      "learning_rate": 0.05155811295806452,
      "loss": 0.7389,
      "step": 300460
    },
    {
      "epoch": 484.65,
      "learning_rate": 0.05155488715483872,
      "loss": 0.7327,
      "step": 300480
    },
    {
      "epoch": 484.68,
      "learning_rate": 0.05155166135161291,
      "loss": 0.7345,
      "step": 300500
    },
    {
      "epoch": 484.71,
      "learning_rate": 0.051548435548387096,
      "loss": 0.748,
      "step": 300520
    },
    {
      "epoch": 484.74,
      "learning_rate": 0.051545209745161295,
      "loss": 0.7172,
      "step": 300540
    },
    {
      "epoch": 484.77,
      "learning_rate": 0.05154198394193548,
      "loss": 0.7269,
      "step": 300560
    },
    {
      "epoch": 484.81,
      "learning_rate": 0.05153875813870969,
      "loss": 0.7301,
      "step": 300580
    },
    {
      "epoch": 484.84,
      "learning_rate": 0.05153553233548387,
      "loss": 0.7249,
      "step": 300600
    },
    {
      "epoch": 484.87,
      "learning_rate": 0.05153230653225807,
      "loss": 0.7354,
      "step": 300620
    },
    {
      "epoch": 484.9,
      "learning_rate": 0.051529080729032256,
      "loss": 0.7495,
      "step": 300640
    },
    {
      "epoch": 484.94,
      "learning_rate": 0.05152585492580646,
      "loss": 0.7367,
      "step": 300660
    },
    {
      "epoch": 484.97,
      "learning_rate": 0.05152262912258065,
      "loss": 0.7371,
      "step": 300680
    },
    {
      "epoch": 485.0,
      "learning_rate": 0.05151940331935485,
      "loss": 0.7277,
      "step": 300700
    },
    {
      "epoch": 485.0,
      "eval_accuracy": {
        "accuracy": 0.7595816095542893
      },
      "eval_loss": 1.1043058633804321,
      "eval_runtime": 3.861,
      "eval_samples_per_second": 3318.025,
      "eval_steps_per_second": 52.059,
      "step": 300700
    },
    {
      "epoch": 485.03,
      "learning_rate": 0.051516177516129025,
      "loss": 0.7583,
      "step": 300720
    },
    {
      "epoch": 485.06,
      "learning_rate": 0.05151295171290324,
      "loss": 0.7208,
      "step": 300740
    },
    {
      "epoch": 485.1,
      "learning_rate": 0.05150972590967742,
      "loss": 0.7072,
      "step": 300760
    },
    {
      "epoch": 485.13,
      "learning_rate": 0.051506500106451615,
      "loss": 0.7213,
      "step": 300780
    },
    {
      "epoch": 485.16,
      "learning_rate": 0.051503274303225814,
      "loss": 0.7105,
      "step": 300800
    },
    {
      "epoch": 485.19,
      "learning_rate": 0.051500048500000006,
      "loss": 0.7103,
      "step": 300820
    },
    {
      "epoch": 485.23,
      "learning_rate": 0.05149682269677419,
      "loss": 0.7415,
      "step": 300840
    },
    {
      "epoch": 485.26,
      "learning_rate": 0.05149359689354839,
      "loss": 0.7288,
      "step": 300860
    },
    {
      "epoch": 485.29,
      "learning_rate": 0.05149037109032259,
      "loss": 0.7333,
      "step": 300880
    },
    {
      "epoch": 485.32,
      "learning_rate": 0.051487145287096775,
      "loss": 0.7298,
      "step": 300900
    },
    {
      "epoch": 485.35,
      "learning_rate": 0.05148391948387097,
      "loss": 0.742,
      "step": 300920
    },
    {
      "epoch": 485.39,
      "learning_rate": 0.05148069368064515,
      "loss": 0.7215,
      "step": 300940
    },
    {
      "epoch": 485.42,
      "learning_rate": 0.05147746787741936,
      "loss": 0.7472,
      "step": 300960
    },
    {
      "epoch": 485.45,
      "learning_rate": 0.051474242074193544,
      "loss": 0.7421,
      "step": 300980
    },
    {
      "epoch": 485.48,
      "learning_rate": 0.05147101627096776,
      "loss": 0.7165,
      "step": 301000
    },
    {
      "epoch": 485.52,
      "learning_rate": 0.05146779046774194,
      "loss": 0.7339,
      "step": 301020
    },
    {
      "epoch": 485.55,
      "learning_rate": 0.051464564664516134,
      "loss": 0.7209,
      "step": 301040
    },
    {
      "epoch": 485.58,
      "learning_rate": 0.05146133886129032,
      "loss": 0.7228,
      "step": 301060
    },
    {
      "epoch": 485.61,
      "learning_rate": 0.05145811305806452,
      "loss": 0.7113,
      "step": 301080
    },
    {
      "epoch": 485.65,
      "learning_rate": 0.05145488725483871,
      "loss": 0.7279,
      "step": 301100
    },
    {
      "epoch": 485.68,
      "learning_rate": 0.05145166145161291,
      "loss": 0.7249,
      "step": 301120
    },
    {
      "epoch": 485.71,
      "learning_rate": 0.05144843564838711,
      "loss": 0.7293,
      "step": 301140
    },
    {
      "epoch": 485.74,
      "learning_rate": 0.051445209845161294,
      "loss": 0.7385,
      "step": 301160
    },
    {
      "epoch": 485.77,
      "learning_rate": 0.051441984041935486,
      "loss": 0.7517,
      "step": 301180
    },
    {
      "epoch": 485.81,
      "learning_rate": 0.05143875823870967,
      "loss": 0.7423,
      "step": 301200
    },
    {
      "epoch": 485.84,
      "learning_rate": 0.05143553243548388,
      "loss": 0.7346,
      "step": 301220
    },
    {
      "epoch": 485.87,
      "learning_rate": 0.05143230663225806,
      "loss": 0.7326,
      "step": 301240
    },
    {
      "epoch": 485.9,
      "learning_rate": 0.051429080829032275,
      "loss": 0.7236,
      "step": 301260
    },
    {
      "epoch": 485.94,
      "learning_rate": 0.05142585502580646,
      "loss": 0.7169,
      "step": 301280
    },
    {
      "epoch": 485.97,
      "learning_rate": 0.05142262922258065,
      "loss": 0.7561,
      "step": 301300
    },
    {
      "epoch": 486.0,
      "learning_rate": 0.05141940341935484,
      "loss": 0.7617,
      "step": 301320
    },
    {
      "epoch": 486.0,
      "eval_accuracy": {
        "accuracy": 0.7580204511747717
      },
      "eval_loss": 1.110137701034546,
      "eval_runtime": 2.7997,
      "eval_samples_per_second": 4575.869,
      "eval_steps_per_second": 71.794,
      "step": 301320
    },
    {
      "epoch": 486.03,
      "learning_rate": 0.05141617761612904,
      "loss": 0.7387,
      "step": 301340
    },
    {
      "epoch": 486.06,
      "learning_rate": 0.05141295181290323,
      "loss": 0.7278,
      "step": 301360
    },
    {
      "epoch": 486.1,
      "learning_rate": 0.051409726009677414,
      "loss": 0.7298,
      "step": 301380
    },
    {
      "epoch": 486.13,
      "learning_rate": 0.051406500206451614,
      "loss": 0.7261,
      "step": 301400
    },
    {
      "epoch": 486.16,
      "learning_rate": 0.05140327440322581,
      "loss": 0.7276,
      "step": 301420
    },
    {
      "epoch": 486.19,
      "learning_rate": 0.051400048600000005,
      "loss": 0.7311,
      "step": 301440
    },
    {
      "epoch": 486.23,
      "learning_rate": 0.05139682279677419,
      "loss": 0.7001,
      "step": 301460
    },
    {
      "epoch": 486.26,
      "learning_rate": 0.051393596993548396,
      "loss": 0.7381,
      "step": 301480
    },
    {
      "epoch": 486.29,
      "learning_rate": 0.051390371190322574,
      "loss": 0.7228,
      "step": 301500
    },
    {
      "epoch": 486.32,
      "learning_rate": 0.05138714538709678,
      "loss": 0.729,
      "step": 301520
    },
    {
      "epoch": 486.35,
      "learning_rate": 0.051383919583870966,
      "loss": 0.7178,
      "step": 301540
    },
    {
      "epoch": 486.39,
      "learning_rate": 0.05138069378064517,
      "loss": 0.7117,
      "step": 301560
    },
    {
      "epoch": 486.42,
      "learning_rate": 0.05137746797741936,
      "loss": 0.7144,
      "step": 301580
    },
    {
      "epoch": 486.45,
      "learning_rate": 0.05137424217419356,
      "loss": 0.7395,
      "step": 301600
    },
    {
      "epoch": 486.48,
      "learning_rate": 0.05137101637096774,
      "loss": 0.7511,
      "step": 301620
    },
    {
      "epoch": 486.52,
      "learning_rate": 0.05136779056774193,
      "loss": 0.7628,
      "step": 301640
    },
    {
      "epoch": 486.55,
      "learning_rate": 0.05136456476451613,
      "loss": 0.7346,
      "step": 301660
    },
    {
      "epoch": 486.58,
      "learning_rate": 0.05136133896129033,
      "loss": 0.7566,
      "step": 301680
    },
    {
      "epoch": 486.61,
      "learning_rate": 0.05135811315806452,
      "loss": 0.728,
      "step": 301700
    },
    {
      "epoch": 486.65,
      "learning_rate": 0.05135488735483871,
      "loss": 0.729,
      "step": 301720
    },
    {
      "epoch": 486.68,
      "learning_rate": 0.05135166155161291,
      "loss": 0.7392,
      "step": 301740
    },
    {
      "epoch": 486.71,
      "learning_rate": 0.0513484357483871,
      "loss": 0.7227,
      "step": 301760
    },
    {
      "epoch": 486.74,
      "learning_rate": 0.0513452099451613,
      "loss": 0.7628,
      "step": 301780
    },
    {
      "epoch": 486.77,
      "learning_rate": 0.05134198414193547,
      "loss": 0.7379,
      "step": 301800
    },
    {
      "epoch": 486.81,
      "learning_rate": 0.051338758338709684,
      "loss": 0.732,
      "step": 301820
    },
    {
      "epoch": 486.84,
      "learning_rate": 0.05133553253548387,
      "loss": 0.7312,
      "step": 301840
    },
    {
      "epoch": 486.87,
      "learning_rate": 0.051332306732258075,
      "loss": 0.7397,
      "step": 301860
    },
    {
      "epoch": 486.9,
      "learning_rate": 0.05132908092903226,
      "loss": 0.7478,
      "step": 301880
    },
    {
      "epoch": 486.94,
      "learning_rate": 0.05132585512580645,
      "loss": 0.7522,
      "step": 301900
    },
    {
      "epoch": 486.97,
      "learning_rate": 0.05132262932258064,
      "loss": 0.74,
      "step": 301920
    },
    {
      "epoch": 487.0,
      "learning_rate": 0.05131940351935485,
      "loss": 0.7458,
      "step": 301940
    },
    {
      "epoch": 487.0,
      "eval_accuracy": {
        "accuracy": 0.7585668566076028
      },
      "eval_loss": 1.1133732795715332,
      "eval_runtime": 2.8736,
      "eval_samples_per_second": 4458.216,
      "eval_steps_per_second": 69.948,
      "step": 301940
    },
    {
      "epoch": 487.03,
      "learning_rate": 0.051316177716129036,
      "loss": 0.7682,
      "step": 301960
    },
    {
      "epoch": 487.06,
      "learning_rate": 0.05131295191290323,
      "loss": 0.7402,
      "step": 301980
    },
    {
      "epoch": 487.1,
      "learning_rate": 0.05130972610967741,
      "loss": 0.7287,
      "step": 302000
    },
    {
      "epoch": 487.13,
      "learning_rate": 0.05130650030645162,
      "loss": 0.7304,
      "step": 302020
    },
    {
      "epoch": 487.16,
      "learning_rate": 0.051303274503225804,
      "loss": 0.7273,
      "step": 302040
    },
    {
      "epoch": 487.19,
      "learning_rate": 0.0513000487,
      "loss": 0.7073,
      "step": 302060
    },
    {
      "epoch": 487.23,
      "learning_rate": 0.0512968228967742,
      "loss": 0.7241,
      "step": 302080
    },
    {
      "epoch": 487.26,
      "learning_rate": 0.051293597093548395,
      "loss": 0.7469,
      "step": 302100
    },
    {
      "epoch": 487.29,
      "learning_rate": 0.05129037129032258,
      "loss": 0.7418,
      "step": 302120
    },
    {
      "epoch": 487.32,
      "learning_rate": 0.051287145487096765,
      "loss": 0.7211,
      "step": 302140
    },
    {
      "epoch": 487.35,
      "learning_rate": 0.05128391968387097,
      "loss": 0.7182,
      "step": 302160
    },
    {
      "epoch": 487.39,
      "learning_rate": 0.051280693880645156,
      "loss": 0.7369,
      "step": 302180
    },
    {
      "epoch": 487.42,
      "learning_rate": 0.05127746807741937,
      "loss": 0.741,
      "step": 302200
    },
    {
      "epoch": 487.45,
      "learning_rate": 0.051274242274193554,
      "loss": 0.7256,
      "step": 302220
    },
    {
      "epoch": 487.48,
      "learning_rate": 0.05127101647096775,
      "loss": 0.732,
      "step": 302240
    },
    {
      "epoch": 487.52,
      "learning_rate": 0.05126779066774193,
      "loss": 0.7425,
      "step": 302260
    },
    {
      "epoch": 487.55,
      "learning_rate": 0.05126456486451613,
      "loss": 0.7268,
      "step": 302280
    },
    {
      "epoch": 487.58,
      "learning_rate": 0.05126133906129032,
      "loss": 0.7321,
      "step": 302300
    },
    {
      "epoch": 487.61,
      "learning_rate": 0.05125811325806452,
      "loss": 0.7182,
      "step": 302320
    },
    {
      "epoch": 487.65,
      "learning_rate": 0.05125488745483872,
      "loss": 0.7291,
      "step": 302340
    },
    {
      "epoch": 487.68,
      "learning_rate": 0.051251661651612906,
      "loss": 0.7336,
      "step": 302360
    },
    {
      "epoch": 487.71,
      "learning_rate": 0.0512484358483871,
      "loss": 0.7411,
      "step": 302380
    },
    {
      "epoch": 487.74,
      "learning_rate": 0.0512452100451613,
      "loss": 0.741,
      "step": 302400
    },
    {
      "epoch": 487.77,
      "learning_rate": 0.05124198424193549,
      "loss": 0.7108,
      "step": 302420
    },
    {
      "epoch": 487.81,
      "learning_rate": 0.051238758438709675,
      "loss": 0.7146,
      "step": 302440
    },
    {
      "epoch": 487.84,
      "learning_rate": 0.05123553263548389,
      "loss": 0.7353,
      "step": 302460
    },
    {
      "epoch": 487.87,
      "learning_rate": 0.05123230683225806,
      "loss": 0.7387,
      "step": 302480
    },
    {
      "epoch": 487.9,
      "learning_rate": 0.051229081029032265,
      "loss": 0.7411,
      "step": 302500
    },
    {
      "epoch": 487.94,
      "learning_rate": 0.05122585522580645,
      "loss": 0.7358,
      "step": 302520
    },
    {
      "epoch": 487.97,
      "learning_rate": 0.05122262942258066,
      "loss": 0.7441,
      "step": 302540
    },
    {
      "epoch": 488.0,
      "learning_rate": 0.05121940361935484,
      "loss": 0.7345,
      "step": 302560
    },
    {
      "epoch": 488.0,
      "eval_accuracy": {
        "accuracy": 0.7555225977675435
      },
      "eval_loss": 1.123203158378601,
      "eval_runtime": 3.1226,
      "eval_samples_per_second": 4102.67,
      "eval_steps_per_second": 64.369,
      "step": 302560
    },
    {
      "epoch": 488.03,
      "learning_rate": 0.05121617781612903,
      "loss": 0.7504,
      "step": 302580
    },
    {
      "epoch": 488.06,
      "learning_rate": 0.051212952012903226,
      "loss": 0.7271,
      "step": 302600
    },
    {
      "epoch": 488.1,
      "learning_rate": 0.051209726209677425,
      "loss": 0.7044,
      "step": 302620
    },
    {
      "epoch": 488.13,
      "learning_rate": 0.05120650040645162,
      "loss": 0.7028,
      "step": 302640
    },
    {
      "epoch": 488.16,
      "learning_rate": 0.0512032746032258,
      "loss": 0.7215,
      "step": 302660
    },
    {
      "epoch": 488.19,
      "learning_rate": 0.05120004880000001,
      "loss": 0.7367,
      "step": 302680
    },
    {
      "epoch": 488.23,
      "learning_rate": 0.051196822996774194,
      "loss": 0.7362,
      "step": 302700
    },
    {
      "epoch": 488.26,
      "learning_rate": 0.05119359719354839,
      "loss": 0.7384,
      "step": 302720
    },
    {
      "epoch": 488.29,
      "learning_rate": 0.05119037139032258,
      "loss": 0.7225,
      "step": 302740
    },
    {
      "epoch": 488.32,
      "learning_rate": 0.051187145587096784,
      "loss": 0.7193,
      "step": 302760
    },
    {
      "epoch": 488.35,
      "learning_rate": 0.05118391978387096,
      "loss": 0.7198,
      "step": 302780
    },
    {
      "epoch": 488.39,
      "learning_rate": 0.05118069398064517,
      "loss": 0.7329,
      "step": 302800
    },
    {
      "epoch": 488.42,
      "learning_rate": 0.051177468177419354,
      "loss": 0.7531,
      "step": 302820
    },
    {
      "epoch": 488.45,
      "learning_rate": 0.05117424237419356,
      "loss": 0.718,
      "step": 302840
    },
    {
      "epoch": 488.48,
      "learning_rate": 0.051171016570967745,
      "loss": 0.7323,
      "step": 302860
    },
    {
      "epoch": 488.52,
      "learning_rate": 0.05116779076774195,
      "loss": 0.7282,
      "step": 302880
    },
    {
      "epoch": 488.55,
      "learning_rate": 0.05116456496451613,
      "loss": 0.7504,
      "step": 302900
    },
    {
      "epoch": 488.58,
      "learning_rate": 0.05116133916129032,
      "loss": 0.7373,
      "step": 302920
    },
    {
      "epoch": 488.61,
      "learning_rate": 0.05115811335806452,
      "loss": 0.7347,
      "step": 302940
    },
    {
      "epoch": 488.65,
      "learning_rate": 0.05115488755483871,
      "loss": 0.732,
      "step": 302960
    },
    {
      "epoch": 488.68,
      "learning_rate": 0.0511516617516129,
      "loss": 0.7339,
      "step": 302980
    },
    {
      "epoch": 488.71,
      "learning_rate": 0.05114843594838711,
      "loss": 0.7364,
      "step": 303000
    },
    {
      "epoch": 488.74,
      "learning_rate": 0.051145210145161296,
      "loss": 0.7337,
      "step": 303020
    },
    {
      "epoch": 488.77,
      "learning_rate": 0.05114198434193548,
      "loss": 0.7088,
      "step": 303040
    },
    {
      "epoch": 488.81,
      "learning_rate": 0.05113875853870969,
      "loss": 0.7161,
      "step": 303060
    },
    {
      "epoch": 488.84,
      "learning_rate": 0.05113553273548386,
      "loss": 0.7474,
      "step": 303080
    },
    {
      "epoch": 488.87,
      "learning_rate": 0.051132306932258065,
      "loss": 0.7305,
      "step": 303100
    },
    {
      "epoch": 488.9,
      "learning_rate": 0.05112908112903225,
      "loss": 0.7326,
      "step": 303120
    },
    {
      "epoch": 488.94,
      "learning_rate": 0.05112585532580646,
      "loss": 0.715,
      "step": 303140
    },
    {
      "epoch": 488.97,
      "learning_rate": 0.05112262952258065,
      "loss": 0.7364,
      "step": 303160
    },
    {
      "epoch": 489.0,
      "learning_rate": 0.05111956500951614,
      "loss": 0.7447,
      "step": 303180
    },
    {
      "epoch": 489.0,
      "eval_accuracy": {
        "accuracy": 0.7629381000702521
      },
      "eval_loss": 1.0925133228302002,
      "eval_runtime": 2.7601,
      "eval_samples_per_second": 4641.489,
      "eval_steps_per_second": 72.823,
      "step": 303180
    },
    {
      "epoch": 489.03,
      "learning_rate": 0.05111633920629033,
      "loss": 0.7215,
      "step": 303200
    },
    {
      "epoch": 489.06,
      "learning_rate": 0.051113113403064514,
      "loss": 0.7072,
      "step": 303220
    },
    {
      "epoch": 489.1,
      "learning_rate": 0.05110988759983873,
      "loss": 0.7114,
      "step": 303240
    },
    {
      "epoch": 489.13,
      "learning_rate": 0.05110666179661291,
      "loss": 0.7263,
      "step": 303260
    },
    {
      "epoch": 489.16,
      "learning_rate": 0.051103435993387104,
      "loss": 0.7234,
      "step": 303280
    },
    {
      "epoch": 489.19,
      "learning_rate": 0.05110021019016129,
      "loss": 0.7206,
      "step": 303300
    },
    {
      "epoch": 489.23,
      "learning_rate": 0.051096984386935496,
      "loss": 0.7439,
      "step": 303320
    },
    {
      "epoch": 489.26,
      "learning_rate": 0.05109375858370968,
      "loss": 0.7224,
      "step": 303340
    },
    {
      "epoch": 489.29,
      "learning_rate": 0.051090532780483866,
      "loss": 0.7295,
      "step": 303360
    },
    {
      "epoch": 489.32,
      "learning_rate": 0.051087306977258065,
      "loss": 0.7254,
      "step": 303380
    },
    {
      "epoch": 489.35,
      "learning_rate": 0.051084081174032264,
      "loss": 0.7203,
      "step": 303400
    },
    {
      "epoch": 489.39,
      "learning_rate": 0.051080855370806456,
      "loss": 0.7275,
      "step": 303420
    },
    {
      "epoch": 489.42,
      "learning_rate": 0.05107762956758064,
      "loss": 0.7273,
      "step": 303440
    },
    {
      "epoch": 489.45,
      "learning_rate": 0.05107440376435485,
      "loss": 0.7339,
      "step": 303460
    },
    {
      "epoch": 489.48,
      "learning_rate": 0.05107117796112903,
      "loss": 0.7286,
      "step": 303480
    },
    {
      "epoch": 489.52,
      "learning_rate": 0.05106795215790323,
      "loss": 0.7292,
      "step": 303500
    },
    {
      "epoch": 489.55,
      "learning_rate": 0.05106472635467742,
      "loss": 0.7383,
      "step": 303520
    },
    {
      "epoch": 489.58,
      "learning_rate": 0.05106150055145162,
      "loss": 0.7465,
      "step": 303540
    },
    {
      "epoch": 489.61,
      "learning_rate": 0.0510582747482258,
      "loss": 0.7458,
      "step": 303560
    },
    {
      "epoch": 489.65,
      "learning_rate": 0.05105504894500001,
      "loss": 0.743,
      "step": 303580
    },
    {
      "epoch": 489.68,
      "learning_rate": 0.05105182314177419,
      "loss": 0.7248,
      "step": 303600
    },
    {
      "epoch": 489.71,
      "learning_rate": 0.0510485973385484,
      "loss": 0.7441,
      "step": 303620
    },
    {
      "epoch": 489.74,
      "learning_rate": 0.051045371535322584,
      "loss": 0.7367,
      "step": 303640
    },
    {
      "epoch": 489.77,
      "learning_rate": 0.05104214573209678,
      "loss": 0.7353,
      "step": 303660
    },
    {
      "epoch": 489.81,
      "learning_rate": 0.05103891992887097,
      "loss": 0.743,
      "step": 303680
    },
    {
      "epoch": 489.84,
      "learning_rate": 0.05103569412564516,
      "loss": 0.7336,
      "step": 303700
    },
    {
      "epoch": 489.87,
      "learning_rate": 0.05103246832241936,
      "loss": 0.7545,
      "step": 303720
    },
    {
      "epoch": 489.9,
      "learning_rate": 0.05102924251919355,
      "loss": 0.7346,
      "step": 303740
    },
    {
      "epoch": 489.94,
      "learning_rate": 0.05102601671596775,
      "loss": 0.7526,
      "step": 303760
    },
    {
      "epoch": 489.97,
      "learning_rate": 0.05102279091274195,
      "loss": 0.7432,
      "step": 303780
    },
    {
      "epoch": 490.0,
      "learning_rate": 0.051019565109516135,
      "loss": 0.7571,
      "step": 303800
    },
    {
      "epoch": 490.0,
      "eval_accuracy": {
        "accuracy": 0.7637967371789868
      },
      "eval_loss": 1.0929287672042847,
      "eval_runtime": 3.6242,
      "eval_samples_per_second": 3534.836,
      "eval_steps_per_second": 55.46,
      "step": 303800
    },
    {
      "epoch": 490.03,
      "learning_rate": 0.05101633930629032,
      "loss": 0.7406,
      "step": 303820
    },
    {
      "epoch": 490.06,
      "learning_rate": 0.051013113503064526,
      "loss": 0.7426,
      "step": 303840
    },
    {
      "epoch": 490.1,
      "learning_rate": 0.0510098876998387,
      "loss": 0.716,
      "step": 303860
    },
    {
      "epoch": 490.13,
      "learning_rate": 0.051006661896612904,
      "loss": 0.7055,
      "step": 303880
    },
    {
      "epoch": 490.16,
      "learning_rate": 0.05100343609338709,
      "loss": 0.709,
      "step": 303900
    },
    {
      "epoch": 490.19,
      "learning_rate": 0.0510002102901613,
      "loss": 0.7182,
      "step": 303920
    },
    {
      "epoch": 490.23,
      "learning_rate": 0.05099698448693549,
      "loss": 0.7162,
      "step": 303940
    },
    {
      "epoch": 490.26,
      "learning_rate": 0.05099375868370968,
      "loss": 0.7293,
      "step": 303960
    },
    {
      "epoch": 490.29,
      "learning_rate": 0.050990532880483865,
      "loss": 0.7283,
      "step": 303980
    },
    {
      "epoch": 490.32,
      "learning_rate": 0.05098730707725807,
      "loss": 0.732,
      "step": 304000
    },
    {
      "epoch": 490.35,
      "learning_rate": 0.050984081274032256,
      "loss": 0.7126,
      "step": 304020
    },
    {
      "epoch": 490.39,
      "learning_rate": 0.050980855470806455,
      "loss": 0.7265,
      "step": 304040
    },
    {
      "epoch": 490.42,
      "learning_rate": 0.050977629667580654,
      "loss": 0.7347,
      "step": 304060
    },
    {
      "epoch": 490.45,
      "learning_rate": 0.050974403864354846,
      "loss": 0.7396,
      "step": 304080
    },
    {
      "epoch": 490.48,
      "learning_rate": 0.05097117806112903,
      "loss": 0.7272,
      "step": 304100
    },
    {
      "epoch": 490.52,
      "learning_rate": 0.05096795225790322,
      "loss": 0.7226,
      "step": 304120
    },
    {
      "epoch": 490.55,
      "learning_rate": 0.05096472645467742,
      "loss": 0.7214,
      "step": 304140
    },
    {
      "epoch": 490.58,
      "learning_rate": 0.05096150065145161,
      "loss": 0.7441,
      "step": 304160
    },
    {
      "epoch": 490.61,
      "learning_rate": 0.05095827484822582,
      "loss": 0.7328,
      "step": 304180
    },
    {
      "epoch": 490.65,
      "learning_rate": 0.050955049045000006,
      "loss": 0.7303,
      "step": 304200
    },
    {
      "epoch": 490.68,
      "learning_rate": 0.0509518232417742,
      "loss": 0.7134,
      "step": 304220
    },
    {
      "epoch": 490.71,
      "learning_rate": 0.05094859743854838,
      "loss": 0.7197,
      "step": 304240
    },
    {
      "epoch": 490.74,
      "learning_rate": 0.05094537163532259,
      "loss": 0.7302,
      "step": 304260
    },
    {
      "epoch": 490.77,
      "learning_rate": 0.050942145832096775,
      "loss": 0.727,
      "step": 304280
    },
    {
      "epoch": 490.81,
      "learning_rate": 0.050938920028870974,
      "loss": 0.7332,
      "step": 304300
    },
    {
      "epoch": 490.84,
      "learning_rate": 0.05093569422564517,
      "loss": 0.7389,
      "step": 304320
    },
    {
      "epoch": 490.87,
      "learning_rate": 0.05093246842241936,
      "loss": 0.7273,
      "step": 304340
    },
    {
      "epoch": 490.9,
      "learning_rate": 0.05092924261919355,
      "loss": 0.7294,
      "step": 304360
    },
    {
      "epoch": 490.94,
      "learning_rate": 0.05092601681596775,
      "loss": 0.7552,
      "step": 304380
    },
    {
      "epoch": 490.97,
      "learning_rate": 0.05092279101274194,
      "loss": 0.7492,
      "step": 304400
    },
    {
      "epoch": 491.0,
      "learning_rate": 0.05091956520951613,
      "loss": 0.7327,
      "step": 304420
    },
    {
      "epoch": 491.0,
      "eval_accuracy": {
        "accuracy": 0.754585902739833
      },
      "eval_loss": 1.1491634845733643,
      "eval_runtime": 3.8605,
      "eval_samples_per_second": 3318.485,
      "eval_steps_per_second": 52.066,
      "step": 304420
    },
    {
      "epoch": 491.03,
      "learning_rate": 0.05091633940629034,
      "loss": 0.741,
      "step": 304440
    },
    {
      "epoch": 491.06,
      "learning_rate": 0.05091311360306451,
      "loss": 0.7345,
      "step": 304460
    },
    {
      "epoch": 491.1,
      "learning_rate": 0.05090988779983872,
      "loss": 0.735,
      "step": 304480
    },
    {
      "epoch": 491.13,
      "learning_rate": 0.0509066619966129,
      "loss": 0.7479,
      "step": 304500
    },
    {
      "epoch": 491.16,
      "learning_rate": 0.05090343619338711,
      "loss": 0.7247,
      "step": 304520
    },
    {
      "epoch": 491.19,
      "learning_rate": 0.05090021039016129,
      "loss": 0.7227,
      "step": 304540
    },
    {
      "epoch": 491.23,
      "learning_rate": 0.05089698458693549,
      "loss": 0.7296,
      "step": 304560
    },
    {
      "epoch": 491.26,
      "learning_rate": 0.05089375878370968,
      "loss": 0.7167,
      "step": 304580
    },
    {
      "epoch": 491.29,
      "learning_rate": 0.05089053298048388,
      "loss": 0.7465,
      "step": 304600
    },
    {
      "epoch": 491.32,
      "learning_rate": 0.05088730717725807,
      "loss": 0.7344,
      "step": 304620
    },
    {
      "epoch": 491.35,
      "learning_rate": 0.050884081374032254,
      "loss": 0.7253,
      "step": 304640
    },
    {
      "epoch": 491.39,
      "learning_rate": 0.05088085557080645,
      "loss": 0.7052,
      "step": 304660
    },
    {
      "epoch": 491.42,
      "learning_rate": 0.050877629767580645,
      "loss": 0.7289,
      "step": 304680
    },
    {
      "epoch": 491.45,
      "learning_rate": 0.050874403964354845,
      "loss": 0.7313,
      "step": 304700
    },
    {
      "epoch": 491.48,
      "learning_rate": 0.050871178161129044,
      "loss": 0.7273,
      "step": 304720
    },
    {
      "epoch": 491.52,
      "learning_rate": 0.050867952357903236,
      "loss": 0.7485,
      "step": 304740
    },
    {
      "epoch": 491.55,
      "learning_rate": 0.050864726554677414,
      "loss": 0.74,
      "step": 304760
    },
    {
      "epoch": 491.58,
      "learning_rate": 0.05086150075145162,
      "loss": 0.7212,
      "step": 304780
    },
    {
      "epoch": 491.61,
      "learning_rate": 0.050858274948225805,
      "loss": 0.73,
      "step": 304800
    },
    {
      "epoch": 491.65,
      "learning_rate": 0.05085504914500001,
      "loss": 0.7178,
      "step": 304820
    },
    {
      "epoch": 491.68,
      "learning_rate": 0.0508518233417742,
      "loss": 0.7127,
      "step": 304840
    },
    {
      "epoch": 491.71,
      "learning_rate": 0.050848597538548396,
      "loss": 0.7229,
      "step": 304860
    },
    {
      "epoch": 491.74,
      "learning_rate": 0.05084537173532258,
      "loss": 0.7395,
      "step": 304880
    },
    {
      "epoch": 491.77,
      "learning_rate": 0.05084214593209677,
      "loss": 0.7319,
      "step": 304900
    },
    {
      "epoch": 491.81,
      "learning_rate": 0.05083892012887097,
      "loss": 0.7305,
      "step": 304920
    },
    {
      "epoch": 491.84,
      "learning_rate": 0.050835694325645164,
      "loss": 0.7332,
      "step": 304940
    },
    {
      "epoch": 491.87,
      "learning_rate": 0.05083246852241935,
      "loss": 0.745,
      "step": 304960
    },
    {
      "epoch": 491.9,
      "learning_rate": 0.05082924271919356,
      "loss": 0.745,
      "step": 304980
    },
    {
      "epoch": 491.94,
      "learning_rate": 0.05082601691596775,
      "loss": 0.7364,
      "step": 305000
    },
    {
      "epoch": 491.97,
      "learning_rate": 0.05082279111274194,
      "loss": 0.7267,
      "step": 305020
    },
    {
      "epoch": 492.0,
      "learning_rate": 0.05081956530951614,
      "loss": 0.747,
      "step": 305040
    },
    {
      "epoch": 492.0,
      "eval_accuracy": {
        "accuracy": 0.7562251190383265
      },
      "eval_loss": 1.1261075735092163,
      "eval_runtime": 2.8797,
      "eval_samples_per_second": 4448.797,
      "eval_steps_per_second": 69.8,
      "step": 305040
    },
    {
      "epoch": 492.03,
      "learning_rate": 0.05081633950629031,
      "loss": 0.7442,
      "step": 305060
    },
    {
      "epoch": 492.06,
      "learning_rate": 0.050813113703064516,
      "loss": 0.7211,
      "step": 305080
    },
    {
      "epoch": 492.1,
      "learning_rate": 0.0508098878998387,
      "loss": 0.6996,
      "step": 305100
    },
    {
      "epoch": 492.13,
      "learning_rate": 0.050806662096612915,
      "loss": 0.6959,
      "step": 305120
    },
    {
      "epoch": 492.16,
      "learning_rate": 0.0508034362933871,
      "loss": 0.7129,
      "step": 305140
    },
    {
      "epoch": 492.19,
      "learning_rate": 0.05080021049016129,
      "loss": 0.7172,
      "step": 305160
    },
    {
      "epoch": 492.23,
      "learning_rate": 0.05079698468693548,
      "loss": 0.7313,
      "step": 305180
    },
    {
      "epoch": 492.26,
      "learning_rate": 0.05079375888370968,
      "loss": 0.7198,
      "step": 305200
    },
    {
      "epoch": 492.29,
      "learning_rate": 0.05079053308048387,
      "loss": 0.7312,
      "step": 305220
    },
    {
      "epoch": 492.32,
      "learning_rate": 0.05078730727725807,
      "loss": 0.7406,
      "step": 305240
    },
    {
      "epoch": 492.35,
      "learning_rate": 0.05078408147403227,
      "loss": 0.7204,
      "step": 305260
    },
    {
      "epoch": 492.39,
      "learning_rate": 0.05078085567080646,
      "loss": 0.7148,
      "step": 305280
    },
    {
      "epoch": 492.42,
      "learning_rate": 0.050777629867580644,
      "loss": 0.7197,
      "step": 305300
    },
    {
      "epoch": 492.45,
      "learning_rate": 0.05077440406435484,
      "loss": 0.6963,
      "step": 305320
    },
    {
      "epoch": 492.48,
      "learning_rate": 0.050771178261129035,
      "loss": 0.7271,
      "step": 305340
    },
    {
      "epoch": 492.52,
      "learning_rate": 0.05076795245790322,
      "loss": 0.7445,
      "step": 305360
    },
    {
      "epoch": 492.55,
      "learning_rate": 0.05076472665467743,
      "loss": 0.7283,
      "step": 305380
    },
    {
      "epoch": 492.58,
      "learning_rate": 0.05076150085145162,
      "loss": 0.7324,
      "step": 305400
    },
    {
      "epoch": 492.61,
      "learning_rate": 0.05075827504822581,
      "loss": 0.7025,
      "step": 305420
    },
    {
      "epoch": 492.65,
      "learning_rate": 0.050755049244999996,
      "loss": 0.7304,
      "step": 305440
    },
    {
      "epoch": 492.68,
      "learning_rate": 0.0507518234417742,
      "loss": 0.7237,
      "step": 305460
    },
    {
      "epoch": 492.71,
      "learning_rate": 0.05074859763854839,
      "loss": 0.7295,
      "step": 305480
    },
    {
      "epoch": 492.74,
      "learning_rate": 0.0507453718353226,
      "loss": 0.746,
      "step": 305500
    },
    {
      "epoch": 492.77,
      "learning_rate": 0.050742146032096785,
      "loss": 0.721,
      "step": 305520
    },
    {
      "epoch": 492.81,
      "learning_rate": 0.05073892022887097,
      "loss": 0.738,
      "step": 305540
    },
    {
      "epoch": 492.84,
      "learning_rate": 0.05073569442564516,
      "loss": 0.7424,
      "step": 305560
    },
    {
      "epoch": 492.87,
      "learning_rate": 0.05073246862241936,
      "loss": 0.7266,
      "step": 305580
    },
    {
      "epoch": 492.9,
      "learning_rate": 0.050729242819193554,
      "loss": 0.7338,
      "step": 305600
    },
    {
      "epoch": 492.94,
      "learning_rate": 0.05072601701596774,
      "loss": 0.7435,
      "step": 305620
    },
    {
      "epoch": 492.97,
      "learning_rate": 0.05072279121274194,
      "loss": 0.7327,
      "step": 305640
    },
    {
      "epoch": 493.0,
      "learning_rate": 0.05071972669967742,
      "loss": 0.7351,
      "step": 305660
    },
    {
      "epoch": 493.0,
      "eval_accuracy": {
        "accuracy": 0.7563031769573023
      },
      "eval_loss": 1.1167140007019043,
      "eval_runtime": 2.7931,
      "eval_samples_per_second": 4586.698,
      "eval_steps_per_second": 71.964,
      "step": 305660
    },
    {
      "epoch": 493.03,
      "learning_rate": 0.05071650089645161,
      "loss": 0.7414,
      "step": 305680
    },
    {
      "epoch": 493.06,
      "learning_rate": 0.05071327509322581,
      "loss": 0.7442,
      "step": 305700
    },
    {
      "epoch": 493.1,
      "learning_rate": 0.05071004929,
      "loss": 0.7213,
      "step": 305720
    },
    {
      "epoch": 493.13,
      "learning_rate": 0.05070682348677419,
      "loss": 0.7075,
      "step": 305740
    },
    {
      "epoch": 493.16,
      "learning_rate": 0.0507035976835484,
      "loss": 0.7122,
      "step": 305760
    },
    {
      "epoch": 493.19,
      "learning_rate": 0.05070037188032259,
      "loss": 0.7291,
      "step": 305780
    },
    {
      "epoch": 493.23,
      "learning_rate": 0.05069714607709678,
      "loss": 0.7222,
      "step": 305800
    },
    {
      "epoch": 493.26,
      "learning_rate": 0.05069392027387098,
      "loss": 0.7387,
      "step": 305820
    },
    {
      "epoch": 493.29,
      "learning_rate": 0.05069069447064515,
      "loss": 0.7348,
      "step": 305840
    },
    {
      "epoch": 493.32,
      "learning_rate": 0.050687468667419355,
      "loss": 0.7395,
      "step": 305860
    },
    {
      "epoch": 493.35,
      "learning_rate": 0.05068424286419354,
      "loss": 0.7213,
      "step": 305880
    },
    {
      "epoch": 493.39,
      "learning_rate": 0.050681017060967753,
      "loss": 0.7372,
      "step": 305900
    },
    {
      "epoch": 493.42,
      "learning_rate": 0.05067779125774194,
      "loss": 0.7295,
      "step": 305920
    },
    {
      "epoch": 493.45,
      "learning_rate": 0.05067456545451613,
      "loss": 0.7289,
      "step": 305940
    },
    {
      "epoch": 493.48,
      "learning_rate": 0.050671339651290316,
      "loss": 0.7141,
      "step": 305960
    },
    {
      "epoch": 493.52,
      "learning_rate": 0.050668113848064515,
      "loss": 0.7283,
      "step": 305980
    },
    {
      "epoch": 493.55,
      "learning_rate": 0.05066488804483871,
      "loss": 0.7104,
      "step": 306000
    },
    {
      "epoch": 493.58,
      "learning_rate": 0.050661662241612906,
      "loss": 0.7187,
      "step": 306020
    },
    {
      "epoch": 493.61,
      "learning_rate": 0.050658436438387106,
      "loss": 0.7463,
      "step": 306040
    },
    {
      "epoch": 493.65,
      "learning_rate": 0.0506552106351613,
      "loss": 0.7249,
      "step": 306060
    },
    {
      "epoch": 493.68,
      "learning_rate": 0.05065198483193548,
      "loss": 0.7265,
      "step": 306080
    },
    {
      "epoch": 493.71,
      "learning_rate": 0.05064875902870968,
      "loss": 0.7472,
      "step": 306100
    },
    {
      "epoch": 493.74,
      "learning_rate": 0.050645533225483874,
      "loss": 0.7275,
      "step": 306120
    },
    {
      "epoch": 493.77,
      "learning_rate": 0.05064230742225806,
      "loss": 0.7326,
      "step": 306140
    },
    {
      "epoch": 493.81,
      "learning_rate": 0.05063908161903227,
      "loss": 0.7468,
      "step": 306160
    },
    {
      "epoch": 493.84,
      "learning_rate": 0.05063585581580646,
      "loss": 0.7451,
      "step": 306180
    },
    {
      "epoch": 493.87,
      "learning_rate": 0.05063263001258065,
      "loss": 0.7337,
      "step": 306200
    },
    {
      "epoch": 493.9,
      "learning_rate": 0.050629404209354835,
      "loss": 0.7295,
      "step": 306220
    },
    {
      "epoch": 493.94,
      "learning_rate": 0.05062617840612904,
      "loss": 0.7281,
      "step": 306240
    },
    {
      "epoch": 493.97,
      "learning_rate": 0.050622952602903226,
      "loss": 0.7185,
      "step": 306260
    },
    {
      "epoch": 494.0,
      "learning_rate": 0.05061972679967741,
      "loss": 0.7347,
      "step": 306280
    },
    {
      "epoch": 494.0,
      "eval_accuracy": {
        "accuracy": 0.7598938412301928
      },
      "eval_loss": 1.0942381620407104,
      "eval_runtime": 3.2147,
      "eval_samples_per_second": 3985.076,
      "eval_steps_per_second": 62.524,
      "step": 306280
    },
    {
      "epoch": 494.03,
      "learning_rate": 0.050616500996451624,
      "loss": 0.7297,
      "step": 306300
    },
    {
      "epoch": 494.06,
      "learning_rate": 0.05061327519322581,
      "loss": 0.7353,
      "step": 306320
    },
    {
      "epoch": 494.1,
      "learning_rate": 0.05061004939,
      "loss": 0.7072,
      "step": 306340
    },
    {
      "epoch": 494.13,
      "learning_rate": 0.0506068235867742,
      "loss": 0.6996,
      "step": 306360
    },
    {
      "epoch": 494.16,
      "learning_rate": 0.05060359778354839,
      "loss": 0.7202,
      "step": 306380
    },
    {
      "epoch": 494.19,
      "learning_rate": 0.05060037198032258,
      "loss": 0.7261,
      "step": 306400
    },
    {
      "epoch": 494.23,
      "learning_rate": 0.05059714617709678,
      "loss": 0.7217,
      "step": 306420
    },
    {
      "epoch": 494.26,
      "learning_rate": 0.05059392037387096,
      "loss": 0.6965,
      "step": 306440
    },
    {
      "epoch": 494.29,
      "learning_rate": 0.05059069457064517,
      "loss": 0.7065,
      "step": 306460
    },
    {
      "epoch": 494.32,
      "learning_rate": 0.050587468767419354,
      "loss": 0.7085,
      "step": 306480
    },
    {
      "epoch": 494.35,
      "learning_rate": 0.05058424296419356,
      "loss": 0.7159,
      "step": 306500
    },
    {
      "epoch": 494.39,
      "learning_rate": 0.05058101716096774,
      "loss": 0.738,
      "step": 306520
    },
    {
      "epoch": 494.42,
      "learning_rate": 0.050577791357741944,
      "loss": 0.7007,
      "step": 306540
    },
    {
      "epoch": 494.45,
      "learning_rate": 0.05057456555451613,
      "loss": 0.7205,
      "step": 306560
    },
    {
      "epoch": 494.48,
      "learning_rate": 0.050571339751290335,
      "loss": 0.7403,
      "step": 306580
    },
    {
      "epoch": 494.52,
      "learning_rate": 0.05056811394806452,
      "loss": 0.7158,
      "step": 306600
    },
    {
      "epoch": 494.55,
      "learning_rate": 0.050564888144838706,
      "loss": 0.7203,
      "step": 306620
    },
    {
      "epoch": 494.58,
      "learning_rate": 0.050561662341612905,
      "loss": 0.7359,
      "step": 306640
    },
    {
      "epoch": 494.61,
      "learning_rate": 0.0505584365383871,
      "loss": 0.7395,
      "step": 306660
    },
    {
      "epoch": 494.65,
      "learning_rate": 0.050555210735161296,
      "loss": 0.7489,
      "step": 306680
    },
    {
      "epoch": 494.68,
      "learning_rate": 0.050551984931935495,
      "loss": 0.7271,
      "step": 306700
    },
    {
      "epoch": 494.71,
      "learning_rate": 0.05054875912870968,
      "loss": 0.7377,
      "step": 306720
    },
    {
      "epoch": 494.74,
      "learning_rate": 0.05054553332548387,
      "loss": 0.7383,
      "step": 306740
    },
    {
      "epoch": 494.77,
      "learning_rate": 0.05054230752225807,
      "loss": 0.7555,
      "step": 306760
    },
    {
      "epoch": 494.81,
      "learning_rate": 0.05053908171903226,
      "loss": 0.7496,
      "step": 306780
    },
    {
      "epoch": 494.84,
      "learning_rate": 0.05053585591580646,
      "loss": 0.7245,
      "step": 306800
    },
    {
      "epoch": 494.87,
      "learning_rate": 0.050532630112580634,
      "loss": 0.753,
      "step": 306820
    },
    {
      "epoch": 494.9,
      "learning_rate": 0.05052940430935485,
      "loss": 0.7383,
      "step": 306840
    },
    {
      "epoch": 494.94,
      "learning_rate": 0.05052617850612903,
      "loss": 0.7229,
      "step": 306860
    },
    {
      "epoch": 494.97,
      "learning_rate": 0.05052295270290324,
      "loss": 0.7415,
      "step": 306880
    },
    {
      "epoch": 495.0,
      "learning_rate": 0.050519726899677424,
      "loss": 0.7397,
      "step": 306900
    },
    {
      "epoch": 495.0,
      "eval_accuracy": {
        "accuracy": 0.7624697525563968
      },
      "eval_loss": 1.0988876819610596,
      "eval_runtime": 3.3493,
      "eval_samples_per_second": 3825.005,
      "eval_steps_per_second": 60.013,
      "step": 306900
    },
    {
      "epoch": 495.03,
      "learning_rate": 0.050516501096451616,
      "loss": 0.7478,
      "step": 306920
    },
    {
      "epoch": 495.06,
      "learning_rate": 0.0505132752932258,
      "loss": 0.7247,
      "step": 306940
    },
    {
      "epoch": 495.1,
      "learning_rate": 0.05051004949,
      "loss": 0.7057,
      "step": 306960
    },
    {
      "epoch": 495.13,
      "learning_rate": 0.0505068236867742,
      "loss": 0.712,
      "step": 306980
    },
    {
      "epoch": 495.16,
      "learning_rate": 0.05050359788354839,
      "loss": 0.7058,
      "step": 307000
    },
    {
      "epoch": 495.19,
      "learning_rate": 0.05050037208032258,
      "loss": 0.7238,
      "step": 307020
    },
    {
      "epoch": 495.23,
      "learning_rate": 0.05049714627709678,
      "loss": 0.7018,
      "step": 307040
    },
    {
      "epoch": 495.26,
      "learning_rate": 0.05049392047387097,
      "loss": 0.7237,
      "step": 307060
    },
    {
      "epoch": 495.29,
      "learning_rate": 0.05049069467064515,
      "loss": 0.7233,
      "step": 307080
    },
    {
      "epoch": 495.32,
      "learning_rate": 0.050487468867419366,
      "loss": 0.7359,
      "step": 307100
    },
    {
      "epoch": 495.35,
      "learning_rate": 0.05048424306419355,
      "loss": 0.7302,
      "step": 307120
    },
    {
      "epoch": 495.39,
      "learning_rate": 0.050481017260967743,
      "loss": 0.7188,
      "step": 307140
    },
    {
      "epoch": 495.42,
      "learning_rate": 0.05047779145774193,
      "loss": 0.7119,
      "step": 307160
    },
    {
      "epoch": 495.45,
      "learning_rate": 0.050474565654516135,
      "loss": 0.7251,
      "step": 307180
    },
    {
      "epoch": 495.48,
      "learning_rate": 0.05047133985129032,
      "loss": 0.7218,
      "step": 307200
    },
    {
      "epoch": 495.52,
      "learning_rate": 0.05046811404806452,
      "loss": 0.7435,
      "step": 307220
    },
    {
      "epoch": 495.55,
      "learning_rate": 0.05046488824483872,
      "loss": 0.7194,
      "step": 307240
    },
    {
      "epoch": 495.58,
      "learning_rate": 0.0504616624416129,
      "loss": 0.7034,
      "step": 307260
    },
    {
      "epoch": 495.61,
      "learning_rate": 0.050458436638387096,
      "loss": 0.7437,
      "step": 307280
    },
    {
      "epoch": 495.65,
      "learning_rate": 0.050455210835161295,
      "loss": 0.7465,
      "step": 307300
    },
    {
      "epoch": 495.68,
      "learning_rate": 0.05045198503193549,
      "loss": 0.7269,
      "step": 307320
    },
    {
      "epoch": 495.71,
      "learning_rate": 0.050448759228709686,
      "loss": 0.7267,
      "step": 307340
    },
    {
      "epoch": 495.74,
      "learning_rate": 0.050445533425483885,
      "loss": 0.7251,
      "step": 307360
    },
    {
      "epoch": 495.77,
      "learning_rate": 0.05044230762225807,
      "loss": 0.7405,
      "step": 307380
    },
    {
      "epoch": 495.81,
      "learning_rate": 0.05043908181903226,
      "loss": 0.7391,
      "step": 307400
    },
    {
      "epoch": 495.84,
      "learning_rate": 0.05043585601580645,
      "loss": 0.7489,
      "step": 307420
    },
    {
      "epoch": 495.87,
      "learning_rate": 0.050432630212580654,
      "loss": 0.7134,
      "step": 307440
    },
    {
      "epoch": 495.9,
      "learning_rate": 0.05042940440935484,
      "loss": 0.7279,
      "step": 307460
    },
    {
      "epoch": 495.94,
      "learning_rate": 0.05042617860612905,
      "loss": 0.7239,
      "step": 307480
    },
    {
      "epoch": 495.97,
      "learning_rate": 0.05042295280290322,
      "loss": 0.7365,
      "step": 307500
    },
    {
      "epoch": 496.0,
      "learning_rate": 0.05041972699967743,
      "loss": 0.7501,
      "step": 307520
    },
    {
      "epoch": 496.0,
      "eval_accuracy": {
        "accuracy": 0.7591132620404341
      },
      "eval_loss": 1.0966756343841553,
      "eval_runtime": 2.9034,
      "eval_samples_per_second": 4412.376,
      "eval_steps_per_second": 69.229,
      "step": 307520
    },
    {
      "epoch": 496.03,
      "learning_rate": 0.050416501196451614,
      "loss": 0.7386,
      "step": 307540
    },
    {
      "epoch": 496.06,
      "learning_rate": 0.0504132753932258,
      "loss": 0.7123,
      "step": 307560
    },
    {
      "epoch": 496.1,
      "learning_rate": 0.050410049590000006,
      "loss": 0.7079,
      "step": 307580
    },
    {
      "epoch": 496.13,
      "learning_rate": 0.05040682378677419,
      "loss": 0.7254,
      "step": 307600
    },
    {
      "epoch": 496.16,
      "learning_rate": 0.05040359798354839,
      "loss": 0.7211,
      "step": 307620
    },
    {
      "epoch": 496.19,
      "learning_rate": 0.05040037218032259,
      "loss": 0.7266,
      "step": 307640
    },
    {
      "epoch": 496.23,
      "learning_rate": 0.05039714637709678,
      "loss": 0.7187,
      "step": 307660
    },
    {
      "epoch": 496.26,
      "learning_rate": 0.050393920573870966,
      "loss": 0.708,
      "step": 307680
    },
    {
      "epoch": 496.29,
      "learning_rate": 0.05039069477064517,
      "loss": 0.7314,
      "step": 307700
    },
    {
      "epoch": 496.32,
      "learning_rate": 0.05038746896741935,
      "loss": 0.7456,
      "step": 307720
    },
    {
      "epoch": 496.35,
      "learning_rate": 0.05038424316419356,
      "loss": 0.7397,
      "step": 307740
    },
    {
      "epoch": 496.39,
      "learning_rate": 0.05038101736096774,
      "loss": 0.744,
      "step": 307760
    },
    {
      "epoch": 496.42,
      "learning_rate": 0.05037779155774195,
      "loss": 0.7415,
      "step": 307780
    },
    {
      "epoch": 496.45,
      "learning_rate": 0.050374565754516126,
      "loss": 0.7305,
      "step": 307800
    },
    {
      "epoch": 496.48,
      "learning_rate": 0.05037133995129033,
      "loss": 0.7357,
      "step": 307820
    },
    {
      "epoch": 496.52,
      "learning_rate": 0.05036811414806452,
      "loss": 0.7388,
      "step": 307840
    },
    {
      "epoch": 496.55,
      "learning_rate": 0.05036488834483871,
      "loss": 0.7216,
      "step": 307860
    },
    {
      "epoch": 496.58,
      "learning_rate": 0.05036166254161291,
      "loss": 0.7258,
      "step": 307880
    },
    {
      "epoch": 496.61,
      "learning_rate": 0.05035843673838711,
      "loss": 0.7131,
      "step": 307900
    },
    {
      "epoch": 496.65,
      "learning_rate": 0.05035521093516129,
      "loss": 0.7341,
      "step": 307920
    },
    {
      "epoch": 496.68,
      "learning_rate": 0.050351985131935485,
      "loss": 0.724,
      "step": 307940
    },
    {
      "epoch": 496.71,
      "learning_rate": 0.050348759328709684,
      "loss": 0.7252,
      "step": 307960
    },
    {
      "epoch": 496.74,
      "learning_rate": 0.050345533525483877,
      "loss": 0.7314,
      "step": 307980
    },
    {
      "epoch": 496.77,
      "learning_rate": 0.05034230772225806,
      "loss": 0.7216,
      "step": 308000
    },
    {
      "epoch": 496.81,
      "learning_rate": 0.05033908191903225,
      "loss": 0.6977,
      "step": 308020
    },
    {
      "epoch": 496.84,
      "learning_rate": 0.05033585611580646,
      "loss": 0.7047,
      "step": 308040
    },
    {
      "epoch": 496.87,
      "learning_rate": 0.050332630312580645,
      "loss": 0.7425,
      "step": 308060
    },
    {
      "epoch": 496.9,
      "learning_rate": 0.05032940450935485,
      "loss": 0.7518,
      "step": 308080
    },
    {
      "epoch": 496.94,
      "learning_rate": 0.05032617870612902,
      "loss": 0.7356,
      "step": 308100
    },
    {
      "epoch": 496.97,
      "learning_rate": 0.05032295290290323,
      "loss": 0.7378,
      "step": 308120
    },
    {
      "epoch": 497.0,
      "learning_rate": 0.050319888389838724,
      "loss": 0.7408,
      "step": 308140
    },
    {
      "epoch": 497.0,
      "eval_accuracy": {
        "accuracy": 0.7707438919678401
      },
      "eval_loss": 1.0489200353622437,
      "eval_runtime": 2.7759,
      "eval_samples_per_second": 4615.163,
      "eval_steps_per_second": 72.41,
      "step": 308140
    },
    {
      "epoch": 497.03,
      "learning_rate": 0.05031666258661291,
      "loss": 0.7068,
      "step": 308160
    },
    {
      "epoch": 497.06,
      "learning_rate": 0.0503134367833871,
      "loss": 0.6969,
      "step": 308180
    },
    {
      "epoch": 497.1,
      "learning_rate": 0.050310210980161287,
      "loss": 0.7187,
      "step": 308200
    },
    {
      "epoch": 497.13,
      "learning_rate": 0.05030698517693549,
      "loss": 0.7233,
      "step": 308220
    },
    {
      "epoch": 497.16,
      "learning_rate": 0.05030375937370968,
      "loss": 0.7203,
      "step": 308240
    },
    {
      "epoch": 497.19,
      "learning_rate": 0.05030053357048389,
      "loss": 0.7074,
      "step": 308260
    },
    {
      "epoch": 497.23,
      "learning_rate": 0.050297307767258076,
      "loss": 0.7238,
      "step": 308280
    },
    {
      "epoch": 497.26,
      "learning_rate": 0.05029408196403226,
      "loss": 0.7247,
      "step": 308300
    },
    {
      "epoch": 497.29,
      "learning_rate": 0.05029085616080645,
      "loss": 0.7393,
      "step": 308320
    },
    {
      "epoch": 497.32,
      "learning_rate": 0.05028763035758064,
      "loss": 0.712,
      "step": 308340
    },
    {
      "epoch": 497.35,
      "learning_rate": 0.050284404554354845,
      "loss": 0.7166,
      "step": 308360
    },
    {
      "epoch": 497.39,
      "learning_rate": 0.05028117875112903,
      "loss": 0.7482,
      "step": 308380
    },
    {
      "epoch": 497.42,
      "learning_rate": 0.05027795294790323,
      "loss": 0.7184,
      "step": 308400
    },
    {
      "epoch": 497.45,
      "learning_rate": 0.05027472714467743,
      "loss": 0.7255,
      "step": 308420
    },
    {
      "epoch": 497.48,
      "learning_rate": 0.05027150134145162,
      "loss": 0.714,
      "step": 308440
    },
    {
      "epoch": 497.52,
      "learning_rate": 0.050268275538225805,
      "loss": 0.7169,
      "step": 308460
    },
    {
      "epoch": 497.55,
      "learning_rate": 0.05026504973500001,
      "loss": 0.717,
      "step": 308480
    },
    {
      "epoch": 497.58,
      "learning_rate": 0.05026182393177419,
      "loss": 0.7197,
      "step": 308500
    },
    {
      "epoch": 497.61,
      "learning_rate": 0.050258598128548396,
      "loss": 0.7329,
      "step": 308520
    },
    {
      "epoch": 497.65,
      "learning_rate": 0.05025537232532258,
      "loss": 0.74,
      "step": 308540
    },
    {
      "epoch": 497.68,
      "learning_rate": 0.05025214652209679,
      "loss": 0.7249,
      "step": 308560
    },
    {
      "epoch": 497.71,
      "learning_rate": 0.050248920718870965,
      "loss": 0.722,
      "step": 308580
    },
    {
      "epoch": 497.74,
      "learning_rate": 0.05024569491564516,
      "loss": 0.7361,
      "step": 308600
    },
    {
      "epoch": 497.77,
      "learning_rate": 0.050242469112419356,
      "loss": 0.7252,
      "step": 308620
    },
    {
      "epoch": 497.81,
      "learning_rate": 0.05023924330919355,
      "loss": 0.739,
      "step": 308640
    },
    {
      "epoch": 497.84,
      "learning_rate": 0.05023601750596775,
      "loss": 0.7278,
      "step": 308660
    },
    {
      "epoch": 497.87,
      "learning_rate": 0.05023279170274195,
      "loss": 0.7283,
      "step": 308680
    },
    {
      "epoch": 497.9,
      "learning_rate": 0.05022956589951613,
      "loss": 0.7302,
      "step": 308700
    },
    {
      "epoch": 497.94,
      "learning_rate": 0.050226340096290324,
      "loss": 0.7196,
      "step": 308720
    },
    {
      "epoch": 497.97,
      "learning_rate": 0.05022311429306452,
      "loss": 0.7132,
      "step": 308740
    },
    {
      "epoch": 498.0,
      "learning_rate": 0.05021988848983871,
      "loss": 0.7358,
      "step": 308760
    },
    {
      "epoch": 498.0,
      "eval_accuracy": {
        "accuracy": 0.7559128873624229
      },
      "eval_loss": 1.1148704290390015,
      "eval_runtime": 3.0773,
      "eval_samples_per_second": 4163.097,
      "eval_steps_per_second": 65.317,
      "step": 308760
    },
    {
      "epoch": 498.03,
      "learning_rate": 0.050216662686612915,
      "loss": 0.7217,
      "step": 308780
    },
    {
      "epoch": 498.06,
      "learning_rate": 0.050213436883387086,
      "loss": 0.7294,
      "step": 308800
    },
    {
      "epoch": 498.1,
      "learning_rate": 0.0502102110801613,
      "loss": 0.7295,
      "step": 308820
    },
    {
      "epoch": 498.13,
      "learning_rate": 0.050206985276935484,
      "loss": 0.7061,
      "step": 308840
    },
    {
      "epoch": 498.16,
      "learning_rate": 0.05020375947370969,
      "loss": 0.7179,
      "step": 308860
    },
    {
      "epoch": 498.19,
      "learning_rate": 0.05020053367048386,
      "loss": 0.7243,
      "step": 308880
    },
    {
      "epoch": 498.23,
      "learning_rate": 0.05019730786725807,
      "loss": 0.7279,
      "step": 308900
    },
    {
      "epoch": 498.26,
      "learning_rate": 0.05019408206403225,
      "loss": 0.7214,
      "step": 308920
    },
    {
      "epoch": 498.29,
      "learning_rate": 0.05019085626080645,
      "loss": 0.7272,
      "step": 308940
    },
    {
      "epoch": 498.32,
      "learning_rate": 0.05018763045758065,
      "loss": 0.7302,
      "step": 308960
    },
    {
      "epoch": 498.35,
      "learning_rate": 0.05018440465435484,
      "loss": 0.7253,
      "step": 308980
    },
    {
      "epoch": 498.39,
      "learning_rate": 0.05018117885112903,
      "loss": 0.7279,
      "step": 309000
    },
    {
      "epoch": 498.42,
      "learning_rate": 0.050177953047903234,
      "loss": 0.7324,
      "step": 309020
    },
    {
      "epoch": 498.45,
      "learning_rate": 0.05017472724467742,
      "loss": 0.7364,
      "step": 309040
    },
    {
      "epoch": 498.48,
      "learning_rate": 0.05017150144145162,
      "loss": 0.7229,
      "step": 309060
    },
    {
      "epoch": 498.52,
      "learning_rate": 0.05016827563822582,
      "loss": 0.7238,
      "step": 309080
    },
    {
      "epoch": 498.55,
      "learning_rate": 0.050165049835,
      "loss": 0.7268,
      "step": 309100
    },
    {
      "epoch": 498.58,
      "learning_rate": 0.050161824031774195,
      "loss": 0.7362,
      "step": 309120
    },
    {
      "epoch": 498.61,
      "learning_rate": 0.05015859822854838,
      "loss": 0.7318,
      "step": 309140
    },
    {
      "epoch": 498.65,
      "learning_rate": 0.050155372425322586,
      "loss": 0.7126,
      "step": 309160
    },
    {
      "epoch": 498.68,
      "learning_rate": 0.05015214662209677,
      "loss": 0.7389,
      "step": 309180
    },
    {
      "epoch": 498.71,
      "learning_rate": 0.050148920818870985,
      "loss": 0.7374,
      "step": 309200
    },
    {
      "epoch": 498.74,
      "learning_rate": 0.05014569501564517,
      "loss": 0.7365,
      "step": 309220
    },
    {
      "epoch": 498.77,
      "learning_rate": 0.050142469212419355,
      "loss": 0.7338,
      "step": 309240
    },
    {
      "epoch": 498.81,
      "learning_rate": 0.05013924340919355,
      "loss": 0.713,
      "step": 309260
    },
    {
      "epoch": 498.84,
      "learning_rate": 0.050136017605967746,
      "loss": 0.7218,
      "step": 309280
    },
    {
      "epoch": 498.87,
      "learning_rate": 0.05013279180274194,
      "loss": 0.741,
      "step": 309300
    },
    {
      "epoch": 498.9,
      "learning_rate": 0.05012956599951614,
      "loss": 0.744,
      "step": 309320
    },
    {
      "epoch": 498.94,
      "learning_rate": 0.05012634019629034,
      "loss": 0.7122,
      "step": 309340
    },
    {
      "epoch": 498.97,
      "learning_rate": 0.05012311439306452,
      "loss": 0.7302,
      "step": 309360
    },
    {
      "epoch": 499.0,
      "learning_rate": 0.050119888589838714,
      "loss": 0.7278,
      "step": 309380
    },
    {
      "epoch": 499.0,
      "eval_accuracy": {
        "accuracy": 0.7531028022792913
      },
      "eval_loss": 1.117445945739746,
      "eval_runtime": 2.8851,
      "eval_samples_per_second": 4440.397,
      "eval_steps_per_second": 69.668,
      "step": 309380
    },
    {
      "epoch": 499.03,
      "learning_rate": 0.0501166627866129,
      "loss": 0.7503,
      "step": 309400
    },
    {
      "epoch": 499.06,
      "learning_rate": 0.050113436983387105,
      "loss": 0.7044,
      "step": 309420
    },
    {
      "epoch": 499.1,
      "learning_rate": 0.05011021118016129,
      "loss": 0.6923,
      "step": 309440
    },
    {
      "epoch": 499.13,
      "learning_rate": 0.0501069853769355,
      "loss": 0.7166,
      "step": 309460
    },
    {
      "epoch": 499.16,
      "learning_rate": 0.050103759573709675,
      "loss": 0.7285,
      "step": 309480
    },
    {
      "epoch": 499.19,
      "learning_rate": 0.05010053377048388,
      "loss": 0.7256,
      "step": 309500
    },
    {
      "epoch": 499.23,
      "learning_rate": 0.050097307967258066,
      "loss": 0.7069,
      "step": 309520
    },
    {
      "epoch": 499.26,
      "learning_rate": 0.05009408216403225,
      "loss": 0.7134,
      "step": 309540
    },
    {
      "epoch": 499.29,
      "learning_rate": 0.05009085636080646,
      "loss": 0.7231,
      "step": 309560
    },
    {
      "epoch": 499.32,
      "learning_rate": 0.05008763055758064,
      "loss": 0.7053,
      "step": 309580
    },
    {
      "epoch": 499.35,
      "learning_rate": 0.05008440475435484,
      "loss": 0.7139,
      "step": 309600
    },
    {
      "epoch": 499.39,
      "learning_rate": 0.05008117895112904,
      "loss": 0.718,
      "step": 309620
    },
    {
      "epoch": 499.42,
      "learning_rate": 0.05007795314790323,
      "loss": 0.6994,
      "step": 309640
    },
    {
      "epoch": 499.45,
      "learning_rate": 0.05007472734467742,
      "loss": 0.706,
      "step": 309660
    },
    {
      "epoch": 499.48,
      "learning_rate": 0.05007150154145162,
      "loss": 0.7064,
      "step": 309680
    },
    {
      "epoch": 499.52,
      "learning_rate": 0.0500682757382258,
      "loss": 0.726,
      "step": 309700
    },
    {
      "epoch": 499.55,
      "learning_rate": 0.05006504993500001,
      "loss": 0.709,
      "step": 309720
    },
    {
      "epoch": 499.58,
      "learning_rate": 0.050061824131774194,
      "loss": 0.7639,
      "step": 309740
    },
    {
      "epoch": 499.61,
      "learning_rate": 0.0500585983285484,
      "loss": 0.7253,
      "step": 309760
    },
    {
      "epoch": 499.65,
      "learning_rate": 0.05005537252532258,
      "loss": 0.7241,
      "step": 309780
    },
    {
      "epoch": 499.68,
      "learning_rate": 0.050052146722096784,
      "loss": 0.7363,
      "step": 309800
    },
    {
      "epoch": 499.71,
      "learning_rate": 0.05004892091887097,
      "loss": 0.7441,
      "step": 309820
    },
    {
      "epoch": 499.74,
      "learning_rate": 0.050045695115645175,
      "loss": 0.7299,
      "step": 309840
    },
    {
      "epoch": 499.77,
      "learning_rate": 0.050042469312419346,
      "loss": 0.7333,
      "step": 309860
    },
    {
      "epoch": 499.81,
      "learning_rate": 0.05003924350919356,
      "loss": 0.7271,
      "step": 309880
    },
    {
      "epoch": 499.84,
      "learning_rate": 0.050036017705967745,
      "loss": 0.7311,
      "step": 309900
    },
    {
      "epoch": 499.87,
      "learning_rate": 0.05003279190274194,
      "loss": 0.7348,
      "step": 309920
    },
    {
      "epoch": 499.9,
      "learning_rate": 0.050029566099516136,
      "loss": 0.7359,
      "step": 309940
    },
    {
      "epoch": 499.94,
      "learning_rate": 0.05002634029629033,
      "loss": 0.7365,
      "step": 309960
    },
    {
      "epoch": 499.97,
      "learning_rate": 0.05002311449306451,
      "loss": 0.7183,
      "step": 309980
    },
    {
      "epoch": 500.0,
      "learning_rate": 0.0500198886898387,
      "loss": 0.7399,
      "step": 310000
    },
    {
      "epoch": 500.0,
      "eval_accuracy": {
        "accuracy": 0.7555225977675435
      },
      "eval_loss": 1.1133136749267578,
      "eval_runtime": 2.7734,
      "eval_samples_per_second": 4619.235,
      "eval_steps_per_second": 72.474,
      "step": 310000
    },
    {
      "epoch": 500.03,
      "learning_rate": 0.05001666288661291,
      "loss": 0.7582,
      "step": 310020
    },
    {
      "epoch": 500.06,
      "learning_rate": 0.0500134370833871,
      "loss": 0.7279,
      "step": 310040
    },
    {
      "epoch": 500.1,
      "learning_rate": 0.0500102112801613,
      "loss": 0.7231,
      "step": 310060
    },
    {
      "epoch": 500.13,
      "learning_rate": 0.050006985476935474,
      "loss": 0.7336,
      "step": 310080
    },
    {
      "epoch": 500.16,
      "learning_rate": 0.05000375967370968,
      "loss": 0.7106,
      "step": 310100
    },
    {
      "epoch": 500.19,
      "learning_rate": 0.050000533870483865,
      "loss": 0.7043,
      "step": 310120
    },
    {
      "epoch": 500.23,
      "learning_rate": 0.049997308067258064,
      "loss": 0.7197,
      "step": 310140
    },
    {
      "epoch": 500.26,
      "learning_rate": 0.04999408226403226,
      "loss": 0.7189,
      "step": 310160
    },
    {
      "epoch": 500.29,
      "learning_rate": 0.049990856460806456,
      "loss": 0.7211,
      "step": 310180
    },
    {
      "epoch": 500.32,
      "learning_rate": 0.04998763065758065,
      "loss": 0.7157,
      "step": 310200
    },
    {
      "epoch": 500.35,
      "learning_rate": 0.04998440485435484,
      "loss": 0.7056,
      "step": 310220
    },
    {
      "epoch": 500.39,
      "learning_rate": 0.04998117905112904,
      "loss": 0.7076,
      "step": 310240
    },
    {
      "epoch": 500.42,
      "learning_rate": 0.04997795324790323,
      "loss": 0.7382,
      "step": 310260
    },
    {
      "epoch": 500.45,
      "learning_rate": 0.04997472744467742,
      "loss": 0.7449,
      "step": 310280
    },
    {
      "epoch": 500.48,
      "learning_rate": 0.04997150164145162,
      "loss": 0.7141,
      "step": 310300
    },
    {
      "epoch": 500.52,
      "learning_rate": 0.049968275838225815,
      "loss": 0.7126,
      "step": 310320
    },
    {
      "epoch": 500.55,
      "learning_rate": 0.04996505003500001,
      "loss": 0.7055,
      "step": 310340
    },
    {
      "epoch": 500.58,
      "learning_rate": 0.0499618242317742,
      "loss": 0.7091,
      "step": 310360
    },
    {
      "epoch": 500.61,
      "learning_rate": 0.0499585984285484,
      "loss": 0.7129,
      "step": 310380
    },
    {
      "epoch": 500.65,
      "learning_rate": 0.049955372625322576,
      "loss": 0.7449,
      "step": 310400
    },
    {
      "epoch": 500.68,
      "learning_rate": 0.049952146822096775,
      "loss": 0.7363,
      "step": 310420
    },
    {
      "epoch": 500.71,
      "learning_rate": 0.04994892101887097,
      "loss": 0.7171,
      "step": 310440
    },
    {
      "epoch": 500.74,
      "learning_rate": 0.04994569521564516,
      "loss": 0.7087,
      "step": 310460
    },
    {
      "epoch": 500.77,
      "learning_rate": 0.04994246941241936,
      "loss": 0.7345,
      "step": 310480
    },
    {
      "epoch": 500.81,
      "learning_rate": 0.04993924360919355,
      "loss": 0.7207,
      "step": 310500
    },
    {
      "epoch": 500.84,
      "learning_rate": 0.04993601780596774,
      "loss": 0.7438,
      "step": 310520
    },
    {
      "epoch": 500.87,
      "learning_rate": 0.04993279200274194,
      "loss": 0.7302,
      "step": 310540
    },
    {
      "epoch": 500.9,
      "learning_rate": 0.049929566199516134,
      "loss": 0.7353,
      "step": 310560
    },
    {
      "epoch": 500.94,
      "learning_rate": 0.04992634039629033,
      "loss": 0.7346,
      "step": 310580
    },
    {
      "epoch": 500.97,
      "learning_rate": 0.049923114593064526,
      "loss": 0.7389,
      "step": 310600
    },
    {
      "epoch": 501.0,
      "learning_rate": 0.04992005008,
      "loss": 0.7425,
      "step": 310620
    },
    {
      "epoch": 501.0,
      "eval_accuracy": {
        "accuracy": 0.764343142611818
      },
      "eval_loss": 1.0640069246292114,
      "eval_runtime": 2.8013,
      "eval_samples_per_second": 4573.157,
      "eval_steps_per_second": 71.751,
      "step": 310620
    },
    {
      "epoch": 501.03,
      "learning_rate": 0.0499168242767742,
      "loss": 0.6902,
      "step": 310640
    },
    {
      "epoch": 501.06,
      "learning_rate": 0.04991359847354839,
      "loss": 0.7233,
      "step": 310660
    },
    {
      "epoch": 501.1,
      "learning_rate": 0.049910372670322584,
      "loss": 0.7238,
      "step": 310680
    },
    {
      "epoch": 501.13,
      "learning_rate": 0.049907146867096776,
      "loss": 0.7188,
      "step": 310700
    },
    {
      "epoch": 501.16,
      "learning_rate": 0.049903921063870975,
      "loss": 0.7018,
      "step": 310720
    },
    {
      "epoch": 501.19,
      "learning_rate": 0.04990069526064517,
      "loss": 0.7355,
      "step": 310740
    },
    {
      "epoch": 501.23,
      "learning_rate": 0.04989746945741936,
      "loss": 0.7093,
      "step": 310760
    },
    {
      "epoch": 501.26,
      "learning_rate": 0.04989424365419356,
      "loss": 0.7122,
      "step": 310780
    },
    {
      "epoch": 501.29,
      "learning_rate": 0.04989101785096775,
      "loss": 0.7384,
      "step": 310800
    },
    {
      "epoch": 501.32,
      "learning_rate": 0.04988779204774194,
      "loss": 0.7178,
      "step": 310820
    },
    {
      "epoch": 501.35,
      "learning_rate": 0.04988456624451613,
      "loss": 0.7315,
      "step": 310840
    },
    {
      "epoch": 501.39,
      "learning_rate": 0.04988134044129032,
      "loss": 0.7194,
      "step": 310860
    },
    {
      "epoch": 501.42,
      "learning_rate": 0.04987811463806452,
      "loss": 0.7187,
      "step": 310880
    },
    {
      "epoch": 501.45,
      "learning_rate": 0.04987488883483871,
      "loss": 0.7226,
      "step": 310900
    },
    {
      "epoch": 501.48,
      "learning_rate": 0.0498716630316129,
      "loss": 0.7291,
      "step": 310920
    },
    {
      "epoch": 501.52,
      "learning_rate": 0.0498684372283871,
      "loss": 0.7271,
      "step": 310940
    },
    {
      "epoch": 501.55,
      "learning_rate": 0.049865211425161295,
      "loss": 0.7382,
      "step": 310960
    },
    {
      "epoch": 501.58,
      "learning_rate": 0.04986198562193549,
      "loss": 0.7069,
      "step": 310980
    },
    {
      "epoch": 501.61,
      "learning_rate": 0.04985875981870968,
      "loss": 0.7176,
      "step": 311000
    },
    {
      "epoch": 501.65,
      "learning_rate": 0.04985553401548388,
      "loss": 0.7186,
      "step": 311020
    },
    {
      "epoch": 501.68,
      "learning_rate": 0.04985230821225807,
      "loss": 0.7204,
      "step": 311040
    },
    {
      "epoch": 501.71,
      "learning_rate": 0.04984908240903226,
      "loss": 0.7163,
      "step": 311060
    },
    {
      "epoch": 501.74,
      "learning_rate": 0.04984585660580646,
      "loss": 0.722,
      "step": 311080
    },
    {
      "epoch": 501.77,
      "learning_rate": 0.049842630802580654,
      "loss": 0.7441,
      "step": 311100
    },
    {
      "epoch": 501.81,
      "learning_rate": 0.049839404999354846,
      "loss": 0.7267,
      "step": 311120
    },
    {
      "epoch": 501.84,
      "learning_rate": 0.049836179196129045,
      "loss": 0.7198,
      "step": 311140
    },
    {
      "epoch": 501.87,
      "learning_rate": 0.04983295339290322,
      "loss": 0.7414,
      "step": 311160
    },
    {
      "epoch": 501.9,
      "learning_rate": 0.04982972758967742,
      "loss": 0.7296,
      "step": 311180
    },
    {
      "epoch": 501.94,
      "learning_rate": 0.049826501786451614,
      "loss": 0.7512,
      "step": 311200
    },
    {
      "epoch": 501.97,
      "learning_rate": 0.049823275983225807,
      "loss": 0.7164,
      "step": 311220
    },
    {
      "epoch": 502.0,
      "learning_rate": 0.04982005018,
      "loss": 0.7202,
      "step": 311240
    },
    {
      "epoch": 502.0,
      "eval_accuracy": {
        "accuracy": 0.7618452892045898
      },
      "eval_loss": 1.0955305099487305,
      "eval_runtime": 4.171,
      "eval_samples_per_second": 3071.426,
      "eval_steps_per_second": 48.19,
      "step": 311240
    },
    {
      "epoch": 502.03,
      "learning_rate": 0.0498168243767742,
      "loss": 0.7479,
      "step": 311260
    },
    {
      "epoch": 502.06,
      "learning_rate": 0.04981359857354839,
      "loss": 0.7168,
      "step": 311280
    },
    {
      "epoch": 502.1,
      "learning_rate": 0.04981037277032258,
      "loss": 0.7195,
      "step": 311300
    },
    {
      "epoch": 502.13,
      "learning_rate": 0.04980714696709678,
      "loss": 0.701,
      "step": 311320
    },
    {
      "epoch": 502.16,
      "learning_rate": 0.04980392116387097,
      "loss": 0.7139,
      "step": 311340
    },
    {
      "epoch": 502.19,
      "learning_rate": 0.049800695360645165,
      "loss": 0.696,
      "step": 311360
    },
    {
      "epoch": 502.23,
      "learning_rate": 0.049797469557419365,
      "loss": 0.7247,
      "step": 311380
    },
    {
      "epoch": 502.26,
      "learning_rate": 0.04979424375419356,
      "loss": 0.7246,
      "step": 311400
    },
    {
      "epoch": 502.29,
      "learning_rate": 0.04979101795096775,
      "loss": 0.6996,
      "step": 311420
    },
    {
      "epoch": 502.32,
      "learning_rate": 0.04978779214774194,
      "loss": 0.6868,
      "step": 311440
    },
    {
      "epoch": 502.35,
      "learning_rate": 0.04978456634451614,
      "loss": 0.7196,
      "step": 311460
    },
    {
      "epoch": 502.39,
      "learning_rate": 0.04978134054129032,
      "loss": 0.7049,
      "step": 311480
    },
    {
      "epoch": 502.42,
      "learning_rate": 0.04977811473806452,
      "loss": 0.7081,
      "step": 311500
    },
    {
      "epoch": 502.45,
      "learning_rate": 0.04977488893483871,
      "loss": 0.7143,
      "step": 311520
    },
    {
      "epoch": 502.48,
      "learning_rate": 0.0497716631316129,
      "loss": 0.7331,
      "step": 311540
    },
    {
      "epoch": 502.52,
      "learning_rate": 0.0497684373283871,
      "loss": 0.7024,
      "step": 311560
    },
    {
      "epoch": 502.55,
      "learning_rate": 0.04976521152516129,
      "loss": 0.7258,
      "step": 311580
    },
    {
      "epoch": 502.58,
      "learning_rate": 0.049761985721935485,
      "loss": 0.724,
      "step": 311600
    },
    {
      "epoch": 502.61,
      "learning_rate": 0.049758759918709684,
      "loss": 0.7039,
      "step": 311620
    },
    {
      "epoch": 502.65,
      "learning_rate": 0.049755534115483877,
      "loss": 0.7232,
      "step": 311640
    },
    {
      "epoch": 502.68,
      "learning_rate": 0.04975230831225807,
      "loss": 0.712,
      "step": 311660
    },
    {
      "epoch": 502.71,
      "learning_rate": 0.04974908250903227,
      "loss": 0.7352,
      "step": 311680
    },
    {
      "epoch": 502.74,
      "learning_rate": 0.04974585670580646,
      "loss": 0.7366,
      "step": 311700
    },
    {
      "epoch": 502.77,
      "learning_rate": 0.04974263090258065,
      "loss": 0.7463,
      "step": 311720
    },
    {
      "epoch": 502.81,
      "learning_rate": 0.049739405099354844,
      "loss": 0.7288,
      "step": 311740
    },
    {
      "epoch": 502.84,
      "learning_rate": 0.04973617929612904,
      "loss": 0.7203,
      "step": 311760
    },
    {
      "epoch": 502.87,
      "learning_rate": 0.04973295349290322,
      "loss": 0.7437,
      "step": 311780
    },
    {
      "epoch": 502.9,
      "learning_rate": 0.04972972768967742,
      "loss": 0.7363,
      "step": 311800
    },
    {
      "epoch": 502.94,
      "learning_rate": 0.04972650188645161,
      "loss": 0.7327,
      "step": 311820
    },
    {
      "epoch": 502.97,
      "learning_rate": 0.049723276083225805,
      "loss": 0.7262,
      "step": 311840
    },
    {
      "epoch": 503.0,
      "learning_rate": 0.049720050280000004,
      "loss": 0.7372,
      "step": 311860
    },
    {
      "epoch": 503.0,
      "eval_accuracy": {
        "accuracy": 0.7531028022792913
      },
      "eval_loss": 1.132391095161438,
      "eval_runtime": 2.8632,
      "eval_samples_per_second": 4474.347,
      "eval_steps_per_second": 70.201,
      "step": 311860
    },
    {
      "epoch": 503.03,
      "learning_rate": 0.049716824476774196,
      "loss": 0.741,
      "step": 311880
    },
    {
      "epoch": 503.06,
      "learning_rate": 0.04971359867354839,
      "loss": 0.7123,
      "step": 311900
    },
    {
      "epoch": 503.1,
      "learning_rate": 0.04971037287032259,
      "loss": 0.7135,
      "step": 311920
    },
    {
      "epoch": 503.13,
      "learning_rate": 0.04970714706709678,
      "loss": 0.7019,
      "step": 311940
    },
    {
      "epoch": 503.16,
      "learning_rate": 0.04970392126387097,
      "loss": 0.7173,
      "step": 311960
    },
    {
      "epoch": 503.19,
      "learning_rate": 0.049700695460645164,
      "loss": 0.7373,
      "step": 311980
    },
    {
      "epoch": 503.23,
      "learning_rate": 0.04969746965741936,
      "loss": 0.7043,
      "step": 312000
    },
    {
      "epoch": 503.26,
      "learning_rate": 0.049694243854193555,
      "loss": 0.7066,
      "step": 312020
    },
    {
      "epoch": 503.29,
      "learning_rate": 0.04969101805096775,
      "loss": 0.7015,
      "step": 312040
    },
    {
      "epoch": 503.32,
      "learning_rate": 0.049687792247741946,
      "loss": 0.7113,
      "step": 312060
    },
    {
      "epoch": 503.35,
      "learning_rate": 0.04968456644451614,
      "loss": 0.712,
      "step": 312080
    },
    {
      "epoch": 503.39,
      "learning_rate": 0.049681340641290324,
      "loss": 0.7183,
      "step": 312100
    },
    {
      "epoch": 503.42,
      "learning_rate": 0.049678114838064516,
      "loss": 0.7033,
      "step": 312120
    },
    {
      "epoch": 503.45,
      "learning_rate": 0.04967488903483871,
      "loss": 0.7073,
      "step": 312140
    },
    {
      "epoch": 503.48,
      "learning_rate": 0.04967166323161291,
      "loss": 0.7257,
      "step": 312160
    },
    {
      "epoch": 503.52,
      "learning_rate": 0.0496684374283871,
      "loss": 0.7144,
      "step": 312180
    },
    {
      "epoch": 503.55,
      "learning_rate": 0.04966521162516129,
      "loss": 0.7185,
      "step": 312200
    },
    {
      "epoch": 503.58,
      "learning_rate": 0.04966198582193549,
      "loss": 0.7147,
      "step": 312220
    },
    {
      "epoch": 503.61,
      "learning_rate": 0.04965876001870968,
      "loss": 0.7141,
      "step": 312240
    },
    {
      "epoch": 503.65,
      "learning_rate": 0.049655534215483875,
      "loss": 0.7181,
      "step": 312260
    },
    {
      "epoch": 503.68,
      "learning_rate": 0.04965230841225807,
      "loss": 0.746,
      "step": 312280
    },
    {
      "epoch": 503.71,
      "learning_rate": 0.049649082609032266,
      "loss": 0.7079,
      "step": 312300
    },
    {
      "epoch": 503.74,
      "learning_rate": 0.04964585680580646,
      "loss": 0.723,
      "step": 312320
    },
    {
      "epoch": 503.77,
      "learning_rate": 0.04964263100258065,
      "loss": 0.7341,
      "step": 312340
    },
    {
      "epoch": 503.81,
      "learning_rate": 0.04963940519935485,
      "loss": 0.7285,
      "step": 312360
    },
    {
      "epoch": 503.84,
      "learning_rate": 0.04963617939612904,
      "loss": 0.7136,
      "step": 312380
    },
    {
      "epoch": 503.87,
      "learning_rate": 0.04963295359290323,
      "loss": 0.7338,
      "step": 312400
    },
    {
      "epoch": 503.9,
      "learning_rate": 0.04962972778967742,
      "loss": 0.7147,
      "step": 312420
    },
    {
      "epoch": 503.94,
      "learning_rate": 0.04962650198645161,
      "loss": 0.7038,
      "step": 312440
    },
    {
      "epoch": 503.97,
      "learning_rate": 0.04962327618322581,
      "loss": 0.7073,
      "step": 312460
    },
    {
      "epoch": 504.0,
      "learning_rate": 0.04962005038,
      "loss": 0.7223,
      "step": 312480
    },
    {
      "epoch": 504.0,
      "eval_accuracy": {
        "accuracy": 0.7542736710639294
      },
      "eval_loss": 1.112186074256897,
      "eval_runtime": 2.8645,
      "eval_samples_per_second": 4472.308,
      "eval_steps_per_second": 70.169,
      "step": 312480
    },
    {
      "epoch": 504.03,
      "learning_rate": 0.049616824576774195,
      "loss": 0.7172,
      "step": 312500
    },
    {
      "epoch": 504.06,
      "learning_rate": 0.04961359877354839,
      "loss": 0.7132,
      "step": 312520
    },
    {
      "epoch": 504.1,
      "learning_rate": 0.049610372970322586,
      "loss": 0.7195,
      "step": 312540
    },
    {
      "epoch": 504.13,
      "learning_rate": 0.04960714716709678,
      "loss": 0.7071,
      "step": 312560
    },
    {
      "epoch": 504.16,
      "learning_rate": 0.04960392136387097,
      "loss": 0.74,
      "step": 312580
    },
    {
      "epoch": 504.19,
      "learning_rate": 0.04960069556064517,
      "loss": 0.7153,
      "step": 312600
    },
    {
      "epoch": 504.23,
      "learning_rate": 0.04959746975741936,
      "loss": 0.7134,
      "step": 312620
    },
    {
      "epoch": 504.26,
      "learning_rate": 0.049594243954193554,
      "loss": 0.7137,
      "step": 312640
    },
    {
      "epoch": 504.29,
      "learning_rate": 0.04959101815096775,
      "loss": 0.7255,
      "step": 312660
    },
    {
      "epoch": 504.32,
      "learning_rate": 0.049587792347741945,
      "loss": 0.7206,
      "step": 312680
    },
    {
      "epoch": 504.35,
      "learning_rate": 0.04958456654451614,
      "loss": 0.7311,
      "step": 312700
    },
    {
      "epoch": 504.39,
      "learning_rate": 0.04958134074129032,
      "loss": 0.7104,
      "step": 312720
    },
    {
      "epoch": 504.42,
      "learning_rate": 0.049578114938064514,
      "loss": 0.7053,
      "step": 312740
    },
    {
      "epoch": 504.45,
      "learning_rate": 0.049574889134838714,
      "loss": 0.714,
      "step": 312760
    },
    {
      "epoch": 504.48,
      "learning_rate": 0.049571663331612906,
      "loss": 0.7146,
      "step": 312780
    },
    {
      "epoch": 504.52,
      "learning_rate": 0.0495684375283871,
      "loss": 0.723,
      "step": 312800
    },
    {
      "epoch": 504.55,
      "learning_rate": 0.04956521172516129,
      "loss": 0.7327,
      "step": 312820
    },
    {
      "epoch": 504.58,
      "learning_rate": 0.04956198592193549,
      "loss": 0.7159,
      "step": 312840
    },
    {
      "epoch": 504.61,
      "learning_rate": 0.04955876011870968,
      "loss": 0.7126,
      "step": 312860
    },
    {
      "epoch": 504.65,
      "learning_rate": 0.04955553431548387,
      "loss": 0.7031,
      "step": 312880
    },
    {
      "epoch": 504.68,
      "learning_rate": 0.04955230851225807,
      "loss": 0.6977,
      "step": 312900
    },
    {
      "epoch": 504.71,
      "learning_rate": 0.049549082709032265,
      "loss": 0.7002,
      "step": 312920
    },
    {
      "epoch": 504.74,
      "learning_rate": 0.04954585690580646,
      "loss": 0.7166,
      "step": 312940
    },
    {
      "epoch": 504.77,
      "learning_rate": 0.049542631102580656,
      "loss": 0.7196,
      "step": 312960
    },
    {
      "epoch": 504.81,
      "learning_rate": 0.04953940529935485,
      "loss": 0.7305,
      "step": 312980
    },
    {
      "epoch": 504.84,
      "learning_rate": 0.04953617949612904,
      "loss": 0.7486,
      "step": 313000
    },
    {
      "epoch": 504.87,
      "learning_rate": 0.049532953692903225,
      "loss": 0.7456,
      "step": 313020
    },
    {
      "epoch": 504.9,
      "learning_rate": 0.04952972788967742,
      "loss": 0.723,
      "step": 313040
    },
    {
      "epoch": 504.94,
      "learning_rate": 0.04952650208645161,
      "loss": 0.7336,
      "step": 313060
    },
    {
      "epoch": 504.97,
      "learning_rate": 0.04952327628322581,
      "loss": 0.739,
      "step": 313080
    },
    {
      "epoch": 505.0,
      "learning_rate": 0.0495202117701613,
      "loss": 0.7323,
      "step": 313100
    },
    {
      "epoch": 505.0,
      "eval_accuracy": {
        "accuracy": 0.7623136367184451
      },
      "eval_loss": 1.0850660800933838,
      "eval_runtime": 3.341,
      "eval_samples_per_second": 3834.471,
      "eval_steps_per_second": 60.161,
      "step": 313100
    },
    {
      "epoch": 505.03,
      "learning_rate": 0.04951698596693549,
      "loss": 0.7033,
      "step": 313120
    },
    {
      "epoch": 505.06,
      "learning_rate": 0.04951376016370969,
      "loss": 0.7089,
      "step": 313140
    },
    {
      "epoch": 505.1,
      "learning_rate": 0.04951053436048387,
      "loss": 0.7079,
      "step": 313160
    },
    {
      "epoch": 505.13,
      "learning_rate": 0.049507308557258066,
      "loss": 0.7267,
      "step": 313180
    },
    {
      "epoch": 505.16,
      "learning_rate": 0.04950408275403226,
      "loss": 0.7117,
      "step": 313200
    },
    {
      "epoch": 505.19,
      "learning_rate": 0.04950085695080645,
      "loss": 0.6982,
      "step": 313220
    },
    {
      "epoch": 505.23,
      "learning_rate": 0.04949763114758065,
      "loss": 0.7168,
      "step": 313240
    },
    {
      "epoch": 505.26,
      "learning_rate": 0.04949440534435484,
      "loss": 0.7172,
      "step": 313260
    },
    {
      "epoch": 505.29,
      "learning_rate": 0.049491179541129034,
      "loss": 0.7069,
      "step": 313280
    },
    {
      "epoch": 505.32,
      "learning_rate": 0.04948795373790323,
      "loss": 0.6993,
      "step": 313300
    },
    {
      "epoch": 505.35,
      "learning_rate": 0.049484727934677425,
      "loss": 0.7159,
      "step": 313320
    },
    {
      "epoch": 505.39,
      "learning_rate": 0.04948150213145162,
      "loss": 0.7217,
      "step": 313340
    },
    {
      "epoch": 505.42,
      "learning_rate": 0.04947827632822581,
      "loss": 0.72,
      "step": 313360
    },
    {
      "epoch": 505.45,
      "learning_rate": 0.04947505052500001,
      "loss": 0.7137,
      "step": 313380
    },
    {
      "epoch": 505.48,
      "learning_rate": 0.0494718247217742,
      "loss": 0.7036,
      "step": 313400
    },
    {
      "epoch": 505.52,
      "learning_rate": 0.04946859891854839,
      "loss": 0.721,
      "step": 313420
    },
    {
      "epoch": 505.55,
      "learning_rate": 0.04946537311532259,
      "loss": 0.7128,
      "step": 313440
    },
    {
      "epoch": 505.58,
      "learning_rate": 0.049462147312096784,
      "loss": 0.7118,
      "step": 313460
    },
    {
      "epoch": 505.61,
      "learning_rate": 0.04945892150887097,
      "loss": 0.7181,
      "step": 313480
    },
    {
      "epoch": 505.65,
      "learning_rate": 0.04945569570564516,
      "loss": 0.7417,
      "step": 313500
    },
    {
      "epoch": 505.68,
      "learning_rate": 0.04945246990241935,
      "loss": 0.7082,
      "step": 313520
    },
    {
      "epoch": 505.71,
      "learning_rate": 0.04944924409919355,
      "loss": 0.71,
      "step": 313540
    },
    {
      "epoch": 505.74,
      "learning_rate": 0.049446018295967745,
      "loss": 0.7233,
      "step": 313560
    },
    {
      "epoch": 505.77,
      "learning_rate": 0.04944279249274194,
      "loss": 0.7427,
      "step": 313580
    },
    {
      "epoch": 505.81,
      "learning_rate": 0.04943956668951613,
      "loss": 0.7393,
      "step": 313600
    },
    {
      "epoch": 505.84,
      "learning_rate": 0.04943634088629033,
      "loss": 0.7338,
      "step": 313620
    },
    {
      "epoch": 505.87,
      "learning_rate": 0.04943311508306452,
      "loss": 0.7293,
      "step": 313640
    },
    {
      "epoch": 505.9,
      "learning_rate": 0.04942988927983871,
      "loss": 0.7272,
      "step": 313660
    },
    {
      "epoch": 505.94,
      "learning_rate": 0.04942666347661291,
      "loss": 0.7171,
      "step": 313680
    },
    {
      "epoch": 505.97,
      "learning_rate": 0.049423437673387104,
      "loss": 0.7355,
      "step": 313700
    },
    {
      "epoch": 506.0,
      "learning_rate": 0.049420211870161296,
      "loss": 0.73,
      "step": 313720
    },
    {
      "epoch": 506.0,
      "eval_accuracy": {
        "accuracy": 0.7545078448208571
      },
      "eval_loss": 1.1279162168502808,
      "eval_runtime": 2.7841,
      "eval_samples_per_second": 4601.497,
      "eval_steps_per_second": 72.196,
      "step": 313720
    },
    {
      "epoch": 506.03,
      "learning_rate": 0.049416986066935495,
      "loss": 0.7466,
      "step": 313740
    },
    {
      "epoch": 506.06,
      "learning_rate": 0.04941376026370969,
      "loss": 0.7029,
      "step": 313760
    },
    {
      "epoch": 506.1,
      "learning_rate": 0.04941053446048388,
      "loss": 0.7223,
      "step": 313780
    },
    {
      "epoch": 506.13,
      "learning_rate": 0.049407308657258064,
      "loss": 0.7227,
      "step": 313800
    },
    {
      "epoch": 506.16,
      "learning_rate": 0.04940408285403226,
      "loss": 0.7042,
      "step": 313820
    },
    {
      "epoch": 506.19,
      "learning_rate": 0.049400857050806456,
      "loss": 0.7089,
      "step": 313840
    },
    {
      "epoch": 506.23,
      "learning_rate": 0.04939763124758065,
      "loss": 0.7363,
      "step": 313860
    },
    {
      "epoch": 506.26,
      "learning_rate": 0.04939440544435484,
      "loss": 0.7075,
      "step": 313880
    },
    {
      "epoch": 506.29,
      "learning_rate": 0.04939117964112903,
      "loss": 0.7051,
      "step": 313900
    },
    {
      "epoch": 506.32,
      "learning_rate": 0.04938795383790323,
      "loss": 0.7253,
      "step": 313920
    },
    {
      "epoch": 506.35,
      "learning_rate": 0.04938472803467742,
      "loss": 0.7222,
      "step": 313940
    },
    {
      "epoch": 506.39,
      "learning_rate": 0.049381502231451616,
      "loss": 0.7391,
      "step": 313960
    },
    {
      "epoch": 506.42,
      "learning_rate": 0.049378276428225815,
      "loss": 0.727,
      "step": 313980
    },
    {
      "epoch": 506.45,
      "learning_rate": 0.04937505062500001,
      "loss": 0.7226,
      "step": 314000
    },
    {
      "epoch": 506.48,
      "learning_rate": 0.0493718248217742,
      "loss": 0.7237,
      "step": 314020
    },
    {
      "epoch": 506.52,
      "learning_rate": 0.0493685990185484,
      "loss": 0.7188,
      "step": 314040
    },
    {
      "epoch": 506.55,
      "learning_rate": 0.04936537321532259,
      "loss": 0.7264,
      "step": 314060
    },
    {
      "epoch": 506.58,
      "learning_rate": 0.04936214741209678,
      "loss": 0.74,
      "step": 314080
    },
    {
      "epoch": 506.61,
      "learning_rate": 0.04935892160887097,
      "loss": 0.7261,
      "step": 314100
    },
    {
      "epoch": 506.65,
      "learning_rate": 0.04935569580564516,
      "loss": 0.7392,
      "step": 314120
    },
    {
      "epoch": 506.68,
      "learning_rate": 0.04935247000241935,
      "loss": 0.7384,
      "step": 314140
    },
    {
      "epoch": 506.71,
      "learning_rate": 0.04934924419919355,
      "loss": 0.7306,
      "step": 314160
    },
    {
      "epoch": 506.74,
      "learning_rate": 0.04934601839596774,
      "loss": 0.7093,
      "step": 314180
    },
    {
      "epoch": 506.77,
      "learning_rate": 0.049342792592741935,
      "loss": 0.7058,
      "step": 314200
    },
    {
      "epoch": 506.81,
      "learning_rate": 0.049339566789516134,
      "loss": 0.7144,
      "step": 314220
    },
    {
      "epoch": 506.84,
      "learning_rate": 0.04933634098629033,
      "loss": 0.7088,
      "step": 314240
    },
    {
      "epoch": 506.87,
      "learning_rate": 0.04933311518306452,
      "loss": 0.7332,
      "step": 314260
    },
    {
      "epoch": 506.9,
      "learning_rate": 0.04932988937983872,
      "loss": 0.7273,
      "step": 314280
    },
    {
      "epoch": 506.94,
      "learning_rate": 0.04932666357661291,
      "loss": 0.7316,
      "step": 314300
    },
    {
      "epoch": 506.97,
      "learning_rate": 0.0493234377733871,
      "loss": 0.7298,
      "step": 314320
    },
    {
      "epoch": 507.0,
      "learning_rate": 0.0493202119701613,
      "loss": 0.7298,
      "step": 314340
    },
    {
      "epoch": 507.0,
      "eval_accuracy": {
        "accuracy": 0.761064710014831
      },
      "eval_loss": 1.1089463233947754,
      "eval_runtime": 2.8855,
      "eval_samples_per_second": 4439.822,
      "eval_steps_per_second": 69.659,
      "step": 314340
    },
    {
      "epoch": 507.03,
      "learning_rate": 0.04931698616693549,
      "loss": 0.7425,
      "step": 314360
    },
    {
      "epoch": 507.06,
      "learning_rate": 0.049313760363709686,
      "loss": 0.6928,
      "step": 314380
    },
    {
      "epoch": 507.1,
      "learning_rate": 0.04931053456048388,
      "loss": 0.7058,
      "step": 314400
    },
    {
      "epoch": 507.13,
      "learning_rate": 0.04930730875725806,
      "loss": 0.6968,
      "step": 314420
    },
    {
      "epoch": 507.16,
      "learning_rate": 0.049304082954032255,
      "loss": 0.7083,
      "step": 314440
    },
    {
      "epoch": 507.19,
      "learning_rate": 0.049300857150806454,
      "loss": 0.6963,
      "step": 314460
    },
    {
      "epoch": 507.23,
      "learning_rate": 0.049297631347580646,
      "loss": 0.698,
      "step": 314480
    },
    {
      "epoch": 507.26,
      "learning_rate": 0.04929440554435484,
      "loss": 0.7035,
      "step": 314500
    },
    {
      "epoch": 507.29,
      "learning_rate": 0.04929117974112904,
      "loss": 0.7247,
      "step": 314520
    },
    {
      "epoch": 507.32,
      "learning_rate": 0.04928795393790323,
      "loss": 0.7106,
      "step": 314540
    },
    {
      "epoch": 507.35,
      "learning_rate": 0.04928472813467742,
      "loss": 0.6983,
      "step": 314560
    },
    {
      "epoch": 507.39,
      "learning_rate": 0.04928150233145162,
      "loss": 0.6941,
      "step": 314580
    },
    {
      "epoch": 507.42,
      "learning_rate": 0.04927827652822581,
      "loss": 0.7263,
      "step": 314600
    },
    {
      "epoch": 507.45,
      "learning_rate": 0.049275050725000005,
      "loss": 0.7189,
      "step": 314620
    },
    {
      "epoch": 507.48,
      "learning_rate": 0.0492718249217742,
      "loss": 0.7414,
      "step": 314640
    },
    {
      "epoch": 507.52,
      "learning_rate": 0.049268599118548397,
      "loss": 0.7449,
      "step": 314660
    },
    {
      "epoch": 507.55,
      "learning_rate": 0.04926537331532259,
      "loss": 0.7293,
      "step": 314680
    },
    {
      "epoch": 507.58,
      "learning_rate": 0.04926214751209678,
      "loss": 0.7236,
      "step": 314700
    },
    {
      "epoch": 507.61,
      "learning_rate": 0.049258921708870966,
      "loss": 0.7256,
      "step": 314720
    },
    {
      "epoch": 507.65,
      "learning_rate": 0.04925569590564516,
      "loss": 0.73,
      "step": 314740
    },
    {
      "epoch": 507.68,
      "learning_rate": 0.04925247010241936,
      "loss": 0.7372,
      "step": 314760
    },
    {
      "epoch": 507.71,
      "learning_rate": 0.04924924429919355,
      "loss": 0.7061,
      "step": 314780
    },
    {
      "epoch": 507.74,
      "learning_rate": 0.04924601849596774,
      "loss": 0.7192,
      "step": 314800
    },
    {
      "epoch": 507.77,
      "learning_rate": 0.04924279269274194,
      "loss": 0.7115,
      "step": 314820
    },
    {
      "epoch": 507.81,
      "learning_rate": 0.04923956688951613,
      "loss": 0.7104,
      "step": 314840
    },
    {
      "epoch": 507.84,
      "learning_rate": 0.049236341086290325,
      "loss": 0.7331,
      "step": 314860
    },
    {
      "epoch": 507.87,
      "learning_rate": 0.04923311528306452,
      "loss": 0.7077,
      "step": 314880
    },
    {
      "epoch": 507.9,
      "learning_rate": 0.049229889479838716,
      "loss": 0.7268,
      "step": 314900
    },
    {
      "epoch": 507.94,
      "learning_rate": 0.04922666367661291,
      "loss": 0.7235,
      "step": 314920
    },
    {
      "epoch": 507.97,
      "learning_rate": 0.0492234378733871,
      "loss": 0.7071,
      "step": 314940
    },
    {
      "epoch": 508.0,
      "learning_rate": 0.0492202120701613,
      "loss": 0.7201,
      "step": 314960
    },
    {
      "epoch": 508.0,
      "eval_accuracy": {
        "accuracy": 0.7562251190383265
      },
      "eval_loss": 1.0985692739486694,
      "eval_runtime": 5.9208,
      "eval_samples_per_second": 2163.716,
      "eval_steps_per_second": 33.948,
      "step": 314960
    },
    {
      "epoch": 508.03,
      "learning_rate": 0.04921698626693549,
      "loss": 0.7243,
      "step": 314980
    },
    {
      "epoch": 508.06,
      "learning_rate": 0.049213760463709684,
      "loss": 0.7225,
      "step": 315000
    },
    {
      "epoch": 508.1,
      "learning_rate": 0.04921053466048388,
      "loss": 0.7264,
      "step": 315020
    },
    {
      "epoch": 508.13,
      "learning_rate": 0.04920730885725806,
      "loss": 0.6875,
      "step": 315040
    },
    {
      "epoch": 508.16,
      "learning_rate": 0.04920408305403226,
      "loss": 0.7096,
      "step": 315060
    },
    {
      "epoch": 508.19,
      "learning_rate": 0.04920085725080645,
      "loss": 0.7184,
      "step": 315080
    },
    {
      "epoch": 508.23,
      "learning_rate": 0.049197631447580645,
      "loss": 0.7072,
      "step": 315100
    },
    {
      "epoch": 508.26,
      "learning_rate": 0.049194405644354844,
      "loss": 0.7289,
      "step": 315120
    },
    {
      "epoch": 508.29,
      "learning_rate": 0.049191179841129036,
      "loss": 0.7236,
      "step": 315140
    },
    {
      "epoch": 508.32,
      "learning_rate": 0.04918795403790323,
      "loss": 0.7165,
      "step": 315160
    },
    {
      "epoch": 508.35,
      "learning_rate": 0.04918472823467742,
      "loss": 0.7147,
      "step": 315180
    },
    {
      "epoch": 508.39,
      "learning_rate": 0.04918150243145162,
      "loss": 0.7295,
      "step": 315200
    },
    {
      "epoch": 508.42,
      "learning_rate": 0.04917827662822581,
      "loss": 0.7044,
      "step": 315220
    },
    {
      "epoch": 508.45,
      "learning_rate": 0.049175050825000004,
      "loss": 0.7006,
      "step": 315240
    },
    {
      "epoch": 508.48,
      "learning_rate": 0.0491718250217742,
      "loss": 0.7374,
      "step": 315260
    },
    {
      "epoch": 508.52,
      "learning_rate": 0.049168599218548395,
      "loss": 0.7183,
      "step": 315280
    },
    {
      "epoch": 508.55,
      "learning_rate": 0.04916537341532259,
      "loss": 0.7143,
      "step": 315300
    },
    {
      "epoch": 508.58,
      "learning_rate": 0.049162147612096786,
      "loss": 0.7228,
      "step": 315320
    },
    {
      "epoch": 508.61,
      "learning_rate": 0.049158921808870965,
      "loss": 0.7155,
      "step": 315340
    },
    {
      "epoch": 508.65,
      "learning_rate": 0.049155696005645164,
      "loss": 0.7276,
      "step": 315360
    },
    {
      "epoch": 508.68,
      "learning_rate": 0.049152470202419356,
      "loss": 0.7427,
      "step": 315380
    },
    {
      "epoch": 508.71,
      "learning_rate": 0.04914924439919355,
      "loss": 0.7024,
      "step": 315400
    },
    {
      "epoch": 508.74,
      "learning_rate": 0.04914601859596774,
      "loss": 0.7226,
      "step": 315420
    },
    {
      "epoch": 508.77,
      "learning_rate": 0.04914279279274194,
      "loss": 0.7188,
      "step": 315440
    },
    {
      "epoch": 508.81,
      "learning_rate": 0.04913956698951613,
      "loss": 0.7114,
      "step": 315460
    },
    {
      "epoch": 508.84,
      "learning_rate": 0.049136341186290323,
      "loss": 0.7093,
      "step": 315480
    },
    {
      "epoch": 508.87,
      "learning_rate": 0.04913311538306452,
      "loss": 0.7089,
      "step": 315500
    },
    {
      "epoch": 508.9,
      "learning_rate": 0.049129889579838715,
      "loss": 0.7138,
      "step": 315520
    },
    {
      "epoch": 508.94,
      "learning_rate": 0.04912666377661291,
      "loss": 0.7226,
      "step": 315540
    },
    {
      "epoch": 508.97,
      "learning_rate": 0.049123437973387106,
      "loss": 0.7193,
      "step": 315560
    },
    {
      "epoch": 509.0,
      "learning_rate": 0.0491202121701613,
      "loss": 0.6958,
      "step": 315580
    },
    {
      "epoch": 509.0,
      "eval_accuracy": {
        "accuracy": 0.7625478104753727
      },
      "eval_loss": 1.080223560333252,
      "eval_runtime": 3.0114,
      "eval_samples_per_second": 4254.147,
      "eval_steps_per_second": 66.746,
      "step": 315580
    },
    {
      "epoch": 509.03,
      "learning_rate": 0.04911698636693549,
      "loss": 0.7288,
      "step": 315600
    },
    {
      "epoch": 509.06,
      "learning_rate": 0.04911376056370969,
      "loss": 0.6969,
      "step": 315620
    },
    {
      "epoch": 509.1,
      "learning_rate": 0.04911053476048388,
      "loss": 0.7092,
      "step": 315640
    },
    {
      "epoch": 509.13,
      "learning_rate": 0.04910730895725807,
      "loss": 0.7022,
      "step": 315660
    },
    {
      "epoch": 509.16,
      "learning_rate": 0.04910408315403226,
      "loss": 0.6969,
      "step": 315680
    },
    {
      "epoch": 509.19,
      "learning_rate": 0.04910085735080645,
      "loss": 0.693,
      "step": 315700
    },
    {
      "epoch": 509.23,
      "learning_rate": 0.04909763154758064,
      "loss": 0.6981,
      "step": 315720
    },
    {
      "epoch": 509.26,
      "learning_rate": 0.04909440574435484,
      "loss": 0.7158,
      "step": 315740
    },
    {
      "epoch": 509.29,
      "learning_rate": 0.049091179941129034,
      "loss": 0.7042,
      "step": 315760
    },
    {
      "epoch": 509.32,
      "learning_rate": 0.04908795413790323,
      "loss": 0.7214,
      "step": 315780
    },
    {
      "epoch": 509.35,
      "learning_rate": 0.049084728334677426,
      "loss": 0.716,
      "step": 315800
    },
    {
      "epoch": 509.39,
      "learning_rate": 0.04908150253145162,
      "loss": 0.7145,
      "step": 315820
    },
    {
      "epoch": 509.42,
      "learning_rate": 0.04907827672822581,
      "loss": 0.7193,
      "step": 315840
    },
    {
      "epoch": 509.45,
      "learning_rate": 0.04907505092500001,
      "loss": 0.7179,
      "step": 315860
    },
    {
      "epoch": 509.48,
      "learning_rate": 0.0490718251217742,
      "loss": 0.7213,
      "step": 315880
    },
    {
      "epoch": 509.52,
      "learning_rate": 0.04906859931854839,
      "loss": 0.7178,
      "step": 315900
    },
    {
      "epoch": 509.55,
      "learning_rate": 0.049065373515322586,
      "loss": 0.7268,
      "step": 315920
    },
    {
      "epoch": 509.58,
      "learning_rate": 0.049062147712096785,
      "loss": 0.7205,
      "step": 315940
    },
    {
      "epoch": 509.61,
      "learning_rate": 0.04905892190887098,
      "loss": 0.7188,
      "step": 315960
    },
    {
      "epoch": 509.65,
      "learning_rate": 0.04905569610564516,
      "loss": 0.7148,
      "step": 315980
    },
    {
      "epoch": 509.68,
      "learning_rate": 0.049052470302419354,
      "loss": 0.7264,
      "step": 316000
    },
    {
      "epoch": 509.71,
      "learning_rate": 0.049049244499193546,
      "loss": 0.7334,
      "step": 316020
    },
    {
      "epoch": 509.74,
      "learning_rate": 0.049046018695967745,
      "loss": 0.7311,
      "step": 316040
    },
    {
      "epoch": 509.77,
      "learning_rate": 0.04904279289274194,
      "loss": 0.7354,
      "step": 316060
    },
    {
      "epoch": 509.81,
      "learning_rate": 0.04903956708951613,
      "loss": 0.7247,
      "step": 316080
    },
    {
      "epoch": 509.84,
      "learning_rate": 0.04903634128629033,
      "loss": 0.7171,
      "step": 316100
    },
    {
      "epoch": 509.87,
      "learning_rate": 0.04903311548306452,
      "loss": 0.7071,
      "step": 316120
    },
    {
      "epoch": 509.9,
      "learning_rate": 0.04902988967983871,
      "loss": 0.736,
      "step": 316140
    },
    {
      "epoch": 509.94,
      "learning_rate": 0.04902666387661291,
      "loss": 0.7427,
      "step": 316160
    },
    {
      "epoch": 509.97,
      "learning_rate": 0.049023438073387104,
      "loss": 0.7311,
      "step": 316180
    },
    {
      "epoch": 510.0,
      "learning_rate": 0.049020373560322586,
      "loss": 0.7367,
      "step": 316200
    },
    {
      "epoch": 510.0,
      "eval_accuracy": {
        "accuracy": 0.7684021543985637
      },
      "eval_loss": 1.0689753293991089,
      "eval_runtime": 2.9396,
      "eval_samples_per_second": 4358.146,
      "eval_steps_per_second": 68.378,
      "step": 316200
    },
    {
      "epoch": 510.03,
      "learning_rate": 0.04901714775709678,
      "loss": 0.7065,
      "step": 316220
    },
    {
      "epoch": 510.06,
      "learning_rate": 0.04901392195387097,
      "loss": 0.7077,
      "step": 316240
    },
    {
      "epoch": 510.1,
      "learning_rate": 0.04901069615064516,
      "loss": 0.7088,
      "step": 316260
    },
    {
      "epoch": 510.13,
      "learning_rate": 0.04900747034741936,
      "loss": 0.6882,
      "step": 316280
    },
    {
      "epoch": 510.16,
      "learning_rate": 0.049004244544193554,
      "loss": 0.6772,
      "step": 316300
    },
    {
      "epoch": 510.19,
      "learning_rate": 0.049001018740967746,
      "loss": 0.7085,
      "step": 316320
    },
    {
      "epoch": 510.23,
      "learning_rate": 0.048997792937741945,
      "loss": 0.7049,
      "step": 316340
    },
    {
      "epoch": 510.26,
      "learning_rate": 0.04899456713451614,
      "loss": 0.7015,
      "step": 316360
    },
    {
      "epoch": 510.29,
      "learning_rate": 0.04899134133129033,
      "loss": 0.7082,
      "step": 316380
    },
    {
      "epoch": 510.32,
      "learning_rate": 0.04898811552806453,
      "loss": 0.7191,
      "step": 316400
    },
    {
      "epoch": 510.35,
      "learning_rate": 0.04898488972483871,
      "loss": 0.7202,
      "step": 316420
    },
    {
      "epoch": 510.39,
      "learning_rate": 0.048981663921612906,
      "loss": 0.7148,
      "step": 316440
    },
    {
      "epoch": 510.42,
      "learning_rate": 0.0489784381183871,
      "loss": 0.7191,
      "step": 316460
    },
    {
      "epoch": 510.45,
      "learning_rate": 0.04897521231516129,
      "loss": 0.7441,
      "step": 316480
    },
    {
      "epoch": 510.48,
      "learning_rate": 0.04897198651193548,
      "loss": 0.7134,
      "step": 316500
    },
    {
      "epoch": 510.52,
      "learning_rate": 0.04896876070870968,
      "loss": 0.7035,
      "step": 316520
    },
    {
      "epoch": 510.55,
      "learning_rate": 0.04896553490548387,
      "loss": 0.7195,
      "step": 316540
    },
    {
      "epoch": 510.58,
      "learning_rate": 0.048962309102258066,
      "loss": 0.7005,
      "step": 316560
    },
    {
      "epoch": 510.61,
      "learning_rate": 0.048959083299032265,
      "loss": 0.7199,
      "step": 316580
    },
    {
      "epoch": 510.65,
      "learning_rate": 0.04895585749580646,
      "loss": 0.7281,
      "step": 316600
    },
    {
      "epoch": 510.68,
      "learning_rate": 0.04895263169258065,
      "loss": 0.7288,
      "step": 316620
    },
    {
      "epoch": 510.71,
      "learning_rate": 0.04894940588935485,
      "loss": 0.7201,
      "step": 316640
    },
    {
      "epoch": 510.74,
      "learning_rate": 0.04894618008612904,
      "loss": 0.7126,
      "step": 316660
    },
    {
      "epoch": 510.77,
      "learning_rate": 0.04894295428290323,
      "loss": 0.7459,
      "step": 316680
    },
    {
      "epoch": 510.81,
      "learning_rate": 0.04893972847967743,
      "loss": 0.7316,
      "step": 316700
    },
    {
      "epoch": 510.84,
      "learning_rate": 0.048936502676451624,
      "loss": 0.7319,
      "step": 316720
    },
    {
      "epoch": 510.87,
      "learning_rate": 0.04893327687322581,
      "loss": 0.7287,
      "step": 316740
    },
    {
      "epoch": 510.9,
      "learning_rate": 0.04893005107,
      "loss": 0.735,
      "step": 316760
    },
    {
      "epoch": 510.94,
      "learning_rate": 0.04892682526677419,
      "loss": 0.7396,
      "step": 316780
    },
    {
      "epoch": 510.97,
      "learning_rate": 0.048923599463548385,
      "loss": 0.7451,
      "step": 316800
    },
    {
      "epoch": 511.0,
      "learning_rate": 0.048920373660322584,
      "loss": 0.7415,
      "step": 316820
    },
    {
      "epoch": 511.0,
      "eval_accuracy": {
        "accuracy": 0.7547420185777847
      },
      "eval_loss": 1.1275094747543335,
      "eval_runtime": 2.9203,
      "eval_samples_per_second": 4386.898,
      "eval_steps_per_second": 68.829,
      "step": 316820
    },
    {
      "epoch": 511.03,
      "learning_rate": 0.04891714785709678,
      "loss": 0.7435,
      "step": 316840
    },
    {
      "epoch": 511.06,
      "learning_rate": 0.04891392205387097,
      "loss": 0.6944,
      "step": 316860
    },
    {
      "epoch": 511.1,
      "learning_rate": 0.04891069625064517,
      "loss": 0.7007,
      "step": 316880
    },
    {
      "epoch": 511.13,
      "learning_rate": 0.04890747044741936,
      "loss": 0.6988,
      "step": 316900
    },
    {
      "epoch": 511.16,
      "learning_rate": 0.04890424464419355,
      "loss": 0.693,
      "step": 316920
    },
    {
      "epoch": 511.19,
      "learning_rate": 0.04890101884096775,
      "loss": 0.7052,
      "step": 316940
    },
    {
      "epoch": 511.23,
      "learning_rate": 0.04889779303774194,
      "loss": 0.7289,
      "step": 316960
    },
    {
      "epoch": 511.26,
      "learning_rate": 0.048894567234516136,
      "loss": 0.7173,
      "step": 316980
    },
    {
      "epoch": 511.29,
      "learning_rate": 0.04889134143129033,
      "loss": 0.7207,
      "step": 317000
    },
    {
      "epoch": 511.32,
      "learning_rate": 0.04888811562806453,
      "loss": 0.7089,
      "step": 317020
    },
    {
      "epoch": 511.35,
      "learning_rate": 0.048884889824838705,
      "loss": 0.7104,
      "step": 317040
    },
    {
      "epoch": 511.39,
      "learning_rate": 0.048881664021612904,
      "loss": 0.7099,
      "step": 317060
    },
    {
      "epoch": 511.42,
      "learning_rate": 0.048878438218387096,
      "loss": 0.7006,
      "step": 317080
    },
    {
      "epoch": 511.45,
      "learning_rate": 0.04887521241516129,
      "loss": 0.7036,
      "step": 317100
    },
    {
      "epoch": 511.48,
      "learning_rate": 0.04887198661193549,
      "loss": 0.7125,
      "step": 317120
    },
    {
      "epoch": 511.52,
      "learning_rate": 0.04886876080870968,
      "loss": 0.7079,
      "step": 317140
    },
    {
      "epoch": 511.55,
      "learning_rate": 0.04886553500548387,
      "loss": 0.7202,
      "step": 317160
    },
    {
      "epoch": 511.58,
      "learning_rate": 0.04886230920225807,
      "loss": 0.7305,
      "step": 317180
    },
    {
      "epoch": 511.61,
      "learning_rate": 0.04885908339903226,
      "loss": 0.733,
      "step": 317200
    },
    {
      "epoch": 511.65,
      "learning_rate": 0.048855857595806455,
      "loss": 0.7196,
      "step": 317220
    },
    {
      "epoch": 511.68,
      "learning_rate": 0.048852631792580654,
      "loss": 0.7153,
      "step": 317240
    },
    {
      "epoch": 511.71,
      "learning_rate": 0.04884940598935485,
      "loss": 0.728,
      "step": 317260
    },
    {
      "epoch": 511.74,
      "learning_rate": 0.04884618018612904,
      "loss": 0.7348,
      "step": 317280
    },
    {
      "epoch": 511.77,
      "learning_rate": 0.04884295438290323,
      "loss": 0.7226,
      "step": 317300
    },
    {
      "epoch": 511.81,
      "learning_rate": 0.04883972857967743,
      "loss": 0.7034,
      "step": 317320
    },
    {
      "epoch": 511.84,
      "learning_rate": 0.04883650277645162,
      "loss": 0.7135,
      "step": 317340
    },
    {
      "epoch": 511.87,
      "learning_rate": 0.04883327697322581,
      "loss": 0.7272,
      "step": 317360
    },
    {
      "epoch": 511.9,
      "learning_rate": 0.04883005117,
      "loss": 0.7395,
      "step": 317380
    },
    {
      "epoch": 511.94,
      "learning_rate": 0.04882682536677419,
      "loss": 0.7237,
      "step": 317400
    },
    {
      "epoch": 511.97,
      "learning_rate": 0.04882359956354839,
      "loss": 0.7346,
      "step": 317420
    },
    {
      "epoch": 512.0,
      "learning_rate": 0.04882037376032258,
      "loss": 0.7269,
      "step": 317440
    },
    {
      "epoch": 512.0,
      "eval_accuracy": {
        "accuracy": 0.7572398719850129
      },
      "eval_loss": 1.086724877357483,
      "eval_runtime": 2.9701,
      "eval_samples_per_second": 4313.308,
      "eval_steps_per_second": 67.674,
      "step": 317440
    },
    {
      "epoch": 512.03,
      "learning_rate": 0.048817147957096775,
      "loss": 0.7281,
      "step": 317460
    },
    {
      "epoch": 512.06,
      "learning_rate": 0.048813922153870974,
      "loss": 0.7198,
      "step": 317480
    },
    {
      "epoch": 512.1,
      "learning_rate": 0.048810696350645166,
      "loss": 0.7132,
      "step": 317500
    },
    {
      "epoch": 512.13,
      "learning_rate": 0.04880747054741936,
      "loss": 0.7131,
      "step": 317520
    },
    {
      "epoch": 512.16,
      "learning_rate": 0.04880424474419355,
      "loss": 0.7141,
      "step": 317540
    },
    {
      "epoch": 512.19,
      "learning_rate": 0.04880101894096775,
      "loss": 0.7111,
      "step": 317560
    },
    {
      "epoch": 512.23,
      "learning_rate": 0.04879779313774194,
      "loss": 0.7007,
      "step": 317580
    },
    {
      "epoch": 512.26,
      "learning_rate": 0.048794567334516134,
      "loss": 0.7009,
      "step": 317600
    },
    {
      "epoch": 512.29,
      "learning_rate": 0.04879134153129033,
      "loss": 0.7198,
      "step": 317620
    },
    {
      "epoch": 512.32,
      "learning_rate": 0.048788115728064525,
      "loss": 0.7133,
      "step": 317640
    },
    {
      "epoch": 512.35,
      "learning_rate": 0.04878488992483871,
      "loss": 0.7152,
      "step": 317660
    },
    {
      "epoch": 512.39,
      "learning_rate": 0.0487816641216129,
      "loss": 0.728,
      "step": 317680
    },
    {
      "epoch": 512.42,
      "learning_rate": 0.048778438318387095,
      "loss": 0.7203,
      "step": 317700
    },
    {
      "epoch": 512.45,
      "learning_rate": 0.048775212515161294,
      "loss": 0.7209,
      "step": 317720
    },
    {
      "epoch": 512.48,
      "learning_rate": 0.048771986711935486,
      "loss": 0.7251,
      "step": 317740
    },
    {
      "epoch": 512.52,
      "learning_rate": 0.04876876090870968,
      "loss": 0.7118,
      "step": 317760
    },
    {
      "epoch": 512.55,
      "learning_rate": 0.04876553510548388,
      "loss": 0.7006,
      "step": 317780
    },
    {
      "epoch": 512.58,
      "learning_rate": 0.04876230930225807,
      "loss": 0.7176,
      "step": 317800
    },
    {
      "epoch": 512.61,
      "learning_rate": 0.04875908349903226,
      "loss": 0.7057,
      "step": 317820
    },
    {
      "epoch": 512.65,
      "learning_rate": 0.048755857695806454,
      "loss": 0.7127,
      "step": 317840
    },
    {
      "epoch": 512.68,
      "learning_rate": 0.04875263189258065,
      "loss": 0.7179,
      "step": 317860
    },
    {
      "epoch": 512.71,
      "learning_rate": 0.048749406089354845,
      "loss": 0.7114,
      "step": 317880
    },
    {
      "epoch": 512.74,
      "learning_rate": 0.04874618028612904,
      "loss": 0.7234,
      "step": 317900
    },
    {
      "epoch": 512.77,
      "learning_rate": 0.048742954482903236,
      "loss": 0.7242,
      "step": 317920
    },
    {
      "epoch": 512.81,
      "learning_rate": 0.04873972867967743,
      "loss": 0.7153,
      "step": 317940
    },
    {
      "epoch": 512.84,
      "learning_rate": 0.04873650287645162,
      "loss": 0.7141,
      "step": 317960
    },
    {
      "epoch": 512.87,
      "learning_rate": 0.048733277073225806,
      "loss": 0.7176,
      "step": 317980
    },
    {
      "epoch": 512.9,
      "learning_rate": 0.04873005127,
      "loss": 0.7219,
      "step": 318000
    },
    {
      "epoch": 512.94,
      "learning_rate": 0.0487268254667742,
      "loss": 0.7443,
      "step": 318020
    },
    {
      "epoch": 512.97,
      "learning_rate": 0.04872359966354839,
      "loss": 0.7091,
      "step": 318040
    },
    {
      "epoch": 513.0,
      "learning_rate": 0.04872037386032258,
      "loss": 0.7198,
      "step": 318060
    },
    {
      "epoch": 513.0,
      "eval_accuracy": {
        "accuracy": 0.7622355787994692
      },
      "eval_loss": 1.0769566297531128,
      "eval_runtime": 3.1207,
      "eval_samples_per_second": 4105.163,
      "eval_steps_per_second": 64.409,
      "step": 318060
    },
    {
      "epoch": 513.03,
      "learning_rate": 0.048717148057096774,
      "loss": 0.7354,
      "step": 318080
    },
    {
      "epoch": 513.06,
      "learning_rate": 0.04871392225387097,
      "loss": 0.7121,
      "step": 318100
    },
    {
      "epoch": 513.1,
      "learning_rate": 0.048710696450645165,
      "loss": 0.6954,
      "step": 318120
    },
    {
      "epoch": 513.13,
      "learning_rate": 0.04870747064741936,
      "loss": 0.683,
      "step": 318140
    },
    {
      "epoch": 513.16,
      "learning_rate": 0.048704244844193556,
      "loss": 0.6789,
      "step": 318160
    },
    {
      "epoch": 513.19,
      "learning_rate": 0.04870101904096775,
      "loss": 0.697,
      "step": 318180
    },
    {
      "epoch": 513.23,
      "learning_rate": 0.04869779323774194,
      "loss": 0.7034,
      "step": 318200
    },
    {
      "epoch": 513.26,
      "learning_rate": 0.04869456743451614,
      "loss": 0.7113,
      "step": 318220
    },
    {
      "epoch": 513.29,
      "learning_rate": 0.04869134163129033,
      "loss": 0.7063,
      "step": 318240
    },
    {
      "epoch": 513.32,
      "learning_rate": 0.048688115828064524,
      "loss": 0.695,
      "step": 318260
    },
    {
      "epoch": 513.35,
      "learning_rate": 0.048684890024838716,
      "loss": 0.7085,
      "step": 318280
    },
    {
      "epoch": 513.39,
      "learning_rate": 0.0486816642216129,
      "loss": 0.7035,
      "step": 318300
    },
    {
      "epoch": 513.42,
      "learning_rate": 0.0486784384183871,
      "loss": 0.7139,
      "step": 318320
    },
    {
      "epoch": 513.45,
      "learning_rate": 0.04867521261516129,
      "loss": 0.7205,
      "step": 318340
    },
    {
      "epoch": 513.48,
      "learning_rate": 0.048671986811935485,
      "loss": 0.7145,
      "step": 318360
    },
    {
      "epoch": 513.52,
      "learning_rate": 0.04866876100870968,
      "loss": 0.7193,
      "step": 318380
    },
    {
      "epoch": 513.55,
      "learning_rate": 0.048665535205483876,
      "loss": 0.7131,
      "step": 318400
    },
    {
      "epoch": 513.58,
      "learning_rate": 0.04866230940225807,
      "loss": 0.7016,
      "step": 318420
    },
    {
      "epoch": 513.61,
      "learning_rate": 0.04865908359903226,
      "loss": 0.7082,
      "step": 318440
    },
    {
      "epoch": 513.65,
      "learning_rate": 0.04865585779580646,
      "loss": 0.6976,
      "step": 318460
    },
    {
      "epoch": 513.68,
      "learning_rate": 0.04865263199258065,
      "loss": 0.6997,
      "step": 318480
    },
    {
      "epoch": 513.71,
      "learning_rate": 0.048649406189354844,
      "loss": 0.6955,
      "step": 318500
    },
    {
      "epoch": 513.74,
      "learning_rate": 0.04864618038612904,
      "loss": 0.6994,
      "step": 318520
    },
    {
      "epoch": 513.77,
      "learning_rate": 0.048642954582903235,
      "loss": 0.7224,
      "step": 318540
    },
    {
      "epoch": 513.81,
      "learning_rate": 0.04863972877967743,
      "loss": 0.72,
      "step": 318560
    },
    {
      "epoch": 513.84,
      "learning_rate": 0.04863650297645162,
      "loss": 0.7079,
      "step": 318580
    },
    {
      "epoch": 513.87,
      "learning_rate": 0.048633277173225804,
      "loss": 0.725,
      "step": 318600
    },
    {
      "epoch": 513.9,
      "learning_rate": 0.048630051369999996,
      "loss": 0.7388,
      "step": 318620
    },
    {
      "epoch": 513.94,
      "learning_rate": 0.048626825566774196,
      "loss": 0.7099,
      "step": 318640
    },
    {
      "epoch": 513.97,
      "learning_rate": 0.04862359976354839,
      "loss": 0.7012,
      "step": 318660
    },
    {
      "epoch": 514.0,
      "learning_rate": 0.048620535250483876,
      "loss": 0.7177,
      "step": 318680
    },
    {
      "epoch": 514.0,
      "eval_accuracy": {
        "accuracy": 0.7591132620404341
      },
      "eval_loss": 1.0682238340377808,
      "eval_runtime": 2.8149,
      "eval_samples_per_second": 4551.211,
      "eval_steps_per_second": 71.407,
      "step": 318680
    },
    {
      "epoch": 514.03,
      "learning_rate": 0.048617309447258075,
      "loss": 0.7161,
      "step": 318700
    },
    {
      "epoch": 514.06,
      "learning_rate": 0.04861408364403227,
      "loss": 0.71,
      "step": 318720
    },
    {
      "epoch": 514.1,
      "learning_rate": 0.04861085784080645,
      "loss": 0.7059,
      "step": 318740
    },
    {
      "epoch": 514.13,
      "learning_rate": 0.048607632037580645,
      "loss": 0.701,
      "step": 318760
    },
    {
      "epoch": 514.16,
      "learning_rate": 0.04860440623435484,
      "loss": 0.722,
      "step": 318780
    },
    {
      "epoch": 514.19,
      "learning_rate": 0.048601180431129036,
      "loss": 0.7023,
      "step": 318800
    },
    {
      "epoch": 514.23,
      "learning_rate": 0.04859795462790323,
      "loss": 0.71,
      "step": 318820
    },
    {
      "epoch": 514.26,
      "learning_rate": 0.04859472882467742,
      "loss": 0.7041,
      "step": 318840
    },
    {
      "epoch": 514.29,
      "learning_rate": 0.04859150302145162,
      "loss": 0.696,
      "step": 318860
    },
    {
      "epoch": 514.32,
      "learning_rate": 0.04858827721822581,
      "loss": 0.7194,
      "step": 318880
    },
    {
      "epoch": 514.35,
      "learning_rate": 0.048585051415000004,
      "loss": 0.7095,
      "step": 318900
    },
    {
      "epoch": 514.39,
      "learning_rate": 0.048581825611774196,
      "loss": 0.7056,
      "step": 318920
    },
    {
      "epoch": 514.42,
      "learning_rate": 0.048578599808548395,
      "loss": 0.7285,
      "step": 318940
    },
    {
      "epoch": 514.45,
      "learning_rate": 0.04857537400532259,
      "loss": 0.7125,
      "step": 318960
    },
    {
      "epoch": 514.48,
      "learning_rate": 0.04857214820209678,
      "loss": 0.7075,
      "step": 318980
    },
    {
      "epoch": 514.52,
      "learning_rate": 0.04856892239887098,
      "loss": 0.7314,
      "step": 319000
    },
    {
      "epoch": 514.55,
      "learning_rate": 0.04856569659564517,
      "loss": 0.7085,
      "step": 319020
    },
    {
      "epoch": 514.58,
      "learning_rate": 0.04856247079241936,
      "loss": 0.7317,
      "step": 319040
    },
    {
      "epoch": 514.61,
      "learning_rate": 0.04855924498919355,
      "loss": 0.7273,
      "step": 319060
    },
    {
      "epoch": 514.65,
      "learning_rate": 0.04855601918596774,
      "loss": 0.7224,
      "step": 319080
    },
    {
      "epoch": 514.68,
      "learning_rate": 0.04855279338274194,
      "loss": 0.7036,
      "step": 319100
    },
    {
      "epoch": 514.71,
      "learning_rate": 0.04854956757951613,
      "loss": 0.7191,
      "step": 319120
    },
    {
      "epoch": 514.74,
      "learning_rate": 0.048546341776290323,
      "loss": 0.7344,
      "step": 319140
    },
    {
      "epoch": 514.77,
      "learning_rate": 0.048543115973064516,
      "loss": 0.6937,
      "step": 319160
    },
    {
      "epoch": 514.81,
      "learning_rate": 0.048539890169838715,
      "loss": 0.7114,
      "step": 319180
    },
    {
      "epoch": 514.84,
      "learning_rate": 0.04853666436661291,
      "loss": 0.7293,
      "step": 319200
    },
    {
      "epoch": 514.87,
      "learning_rate": 0.0485334385633871,
      "loss": 0.7052,
      "step": 319220
    },
    {
      "epoch": 514.9,
      "learning_rate": 0.0485302127601613,
      "loss": 0.715,
      "step": 319240
    },
    {
      "epoch": 514.94,
      "learning_rate": 0.04852698695693549,
      "loss": 0.73,
      "step": 319260
    },
    {
      "epoch": 514.97,
      "learning_rate": 0.04852376115370968,
      "loss": 0.7159,
      "step": 319280
    },
    {
      "epoch": 515.0,
      "learning_rate": 0.04852053535048388,
      "loss": 0.7151,
      "step": 319300
    },
    {
      "epoch": 515.0,
      "eval_accuracy": {
        "accuracy": 0.7612208258527827
      },
      "eval_loss": 1.0641647577285767,
      "eval_runtime": 2.9525,
      "eval_samples_per_second": 4338.975,
      "eval_steps_per_second": 68.077,
      "step": 319300
    },
    {
      "epoch": 515.03,
      "learning_rate": 0.048517309547258074,
      "loss": 0.726,
      "step": 319320
    },
    {
      "epoch": 515.06,
      "learning_rate": 0.048514083744032266,
      "loss": 0.7289,
      "step": 319340
    },
    {
      "epoch": 515.1,
      "learning_rate": 0.04851085794080645,
      "loss": 0.7183,
      "step": 319360
    },
    {
      "epoch": 515.13,
      "learning_rate": 0.04850763213758064,
      "loss": 0.6904,
      "step": 319380
    },
    {
      "epoch": 515.16,
      "learning_rate": 0.04850440633435484,
      "loss": 0.7057,
      "step": 319400
    },
    {
      "epoch": 515.19,
      "learning_rate": 0.048501180531129034,
      "loss": 0.6977,
      "step": 319420
    },
    {
      "epoch": 515.23,
      "learning_rate": 0.04849795472790323,
      "loss": 0.6868,
      "step": 319440
    },
    {
      "epoch": 515.26,
      "learning_rate": 0.04849472892467742,
      "loss": 0.6909,
      "step": 319460
    },
    {
      "epoch": 515.29,
      "learning_rate": 0.04849150312145162,
      "loss": 0.7042,
      "step": 319480
    },
    {
      "epoch": 515.32,
      "learning_rate": 0.04848827731822581,
      "loss": 0.7231,
      "step": 319500
    },
    {
      "epoch": 515.35,
      "learning_rate": 0.048485051515,
      "loss": 0.7199,
      "step": 319520
    },
    {
      "epoch": 515.39,
      "learning_rate": 0.0484818257117742,
      "loss": 0.7053,
      "step": 319540
    },
    {
      "epoch": 515.42,
      "learning_rate": 0.04847859990854839,
      "loss": 0.6974,
      "step": 319560
    },
    {
      "epoch": 515.45,
      "learning_rate": 0.048475374105322586,
      "loss": 0.7163,
      "step": 319580
    },
    {
      "epoch": 515.48,
      "learning_rate": 0.048472148302096785,
      "loss": 0.7139,
      "step": 319600
    },
    {
      "epoch": 515.52,
      "learning_rate": 0.04846892249887098,
      "loss": 0.7023,
      "step": 319620
    },
    {
      "epoch": 515.55,
      "learning_rate": 0.04846569669564517,
      "loss": 0.7085,
      "step": 319640
    },
    {
      "epoch": 515.58,
      "learning_rate": 0.04846247089241936,
      "loss": 0.7146,
      "step": 319660
    },
    {
      "epoch": 515.61,
      "learning_rate": 0.048459245089193546,
      "loss": 0.6947,
      "step": 319680
    },
    {
      "epoch": 515.65,
      "learning_rate": 0.04845601928596774,
      "loss": 0.7071,
      "step": 319700
    },
    {
      "epoch": 515.68,
      "learning_rate": 0.04845279348274194,
      "loss": 0.7209,
      "step": 319720
    },
    {
      "epoch": 515.71,
      "learning_rate": 0.04844956767951613,
      "loss": 0.7161,
      "step": 319740
    },
    {
      "epoch": 515.74,
      "learning_rate": 0.04844634187629032,
      "loss": 0.719,
      "step": 319760
    },
    {
      "epoch": 515.77,
      "learning_rate": 0.04844311607306452,
      "loss": 0.7141,
      "step": 319780
    },
    {
      "epoch": 515.81,
      "learning_rate": 0.04843989026983871,
      "loss": 0.7443,
      "step": 319800
    },
    {
      "epoch": 515.84,
      "learning_rate": 0.048436664466612905,
      "loss": 0.7384,
      "step": 319820
    },
    {
      "epoch": 515.87,
      "learning_rate": 0.048433438663387104,
      "loss": 0.7333,
      "step": 319840
    },
    {
      "epoch": 515.9,
      "learning_rate": 0.0484302128601613,
      "loss": 0.7162,
      "step": 319860
    },
    {
      "epoch": 515.94,
      "learning_rate": 0.04842698705693549,
      "loss": 0.7158,
      "step": 319880
    },
    {
      "epoch": 515.97,
      "learning_rate": 0.04842376125370968,
      "loss": 0.7123,
      "step": 319900
    },
    {
      "epoch": 516.0,
      "learning_rate": 0.04842053545048388,
      "loss": 0.7332,
      "step": 319920
    },
    {
      "epoch": 516.0,
      "eval_accuracy": {
        "accuracy": 0.7594254937163375
      },
      "eval_loss": 1.0941917896270752,
      "eval_runtime": 5.2693,
      "eval_samples_per_second": 2431.274,
      "eval_steps_per_second": 38.146,
      "step": 319920
    },
    {
      "epoch": 516.03,
      "learning_rate": 0.04841730964725807,
      "loss": 0.729,
      "step": 319940
    },
    {
      "epoch": 516.06,
      "learning_rate": 0.048414083844032264,
      "loss": 0.7052,
      "step": 319960
    },
    {
      "epoch": 516.1,
      "learning_rate": 0.04841085804080645,
      "loss": 0.7089,
      "step": 319980
    },
    {
      "epoch": 516.13,
      "learning_rate": 0.04840763223758064,
      "loss": 0.7011,
      "step": 320000
    },
    {
      "epoch": 516.16,
      "learning_rate": 0.04840440643435484,
      "loss": 0.6826,
      "step": 320020
    },
    {
      "epoch": 516.19,
      "learning_rate": 0.04840118063112903,
      "loss": 0.6885,
      "step": 320040
    },
    {
      "epoch": 516.23,
      "learning_rate": 0.048397954827903225,
      "loss": 0.7008,
      "step": 320060
    },
    {
      "epoch": 516.26,
      "learning_rate": 0.048394729024677424,
      "loss": 0.7147,
      "step": 320080
    },
    {
      "epoch": 516.29,
      "learning_rate": 0.048391503221451616,
      "loss": 0.7107,
      "step": 320100
    },
    {
      "epoch": 516.32,
      "learning_rate": 0.04838827741822581,
      "loss": 0.7017,
      "step": 320120
    },
    {
      "epoch": 516.35,
      "learning_rate": 0.04838505161500001,
      "loss": 0.7231,
      "step": 320140
    },
    {
      "epoch": 516.39,
      "learning_rate": 0.0483818258117742,
      "loss": 0.7148,
      "step": 320160
    },
    {
      "epoch": 516.42,
      "learning_rate": 0.04837860000854839,
      "loss": 0.7151,
      "step": 320180
    },
    {
      "epoch": 516.45,
      "learning_rate": 0.048375374205322584,
      "loss": 0.7288,
      "step": 320200
    },
    {
      "epoch": 516.48,
      "learning_rate": 0.04837214840209678,
      "loss": 0.7283,
      "step": 320220
    },
    {
      "epoch": 516.52,
      "learning_rate": 0.048368922598870975,
      "loss": 0.7043,
      "step": 320240
    },
    {
      "epoch": 516.55,
      "learning_rate": 0.04836569679564517,
      "loss": 0.721,
      "step": 320260
    },
    {
      "epoch": 516.58,
      "learning_rate": 0.04836247099241937,
      "loss": 0.7174,
      "step": 320280
    },
    {
      "epoch": 516.61,
      "learning_rate": 0.048359245189193545,
      "loss": 0.6962,
      "step": 320300
    },
    {
      "epoch": 516.65,
      "learning_rate": 0.048356019385967744,
      "loss": 0.724,
      "step": 320320
    },
    {
      "epoch": 516.68,
      "learning_rate": 0.048352793582741936,
      "loss": 0.7358,
      "step": 320340
    },
    {
      "epoch": 516.71,
      "learning_rate": 0.04834956777951613,
      "loss": 0.7207,
      "step": 320360
    },
    {
      "epoch": 516.74,
      "learning_rate": 0.04834634197629033,
      "loss": 0.7012,
      "step": 320380
    },
    {
      "epoch": 516.77,
      "learning_rate": 0.04834311617306452,
      "loss": 0.6957,
      "step": 320400
    },
    {
      "epoch": 516.81,
      "learning_rate": 0.04833989036983871,
      "loss": 0.7072,
      "step": 320420
    },
    {
      "epoch": 516.84,
      "learning_rate": 0.048336664566612904,
      "loss": 0.7168,
      "step": 320440
    },
    {
      "epoch": 516.87,
      "learning_rate": 0.0483334387633871,
      "loss": 0.7111,
      "step": 320460
    },
    {
      "epoch": 516.9,
      "learning_rate": 0.048330212960161295,
      "loss": 0.7272,
      "step": 320480
    },
    {
      "epoch": 516.94,
      "learning_rate": 0.04832698715693549,
      "loss": 0.746,
      "step": 320500
    },
    {
      "epoch": 516.97,
      "learning_rate": 0.048323761353709686,
      "loss": 0.7223,
      "step": 320520
    },
    {
      "epoch": 517.0,
      "learning_rate": 0.04832053555048388,
      "loss": 0.7008,
      "step": 320540
    },
    {
      "epoch": 517.0,
      "eval_accuracy": {
        "accuracy": 0.7580204511747717
      },
      "eval_loss": 1.1134954690933228,
      "eval_runtime": 3.3269,
      "eval_samples_per_second": 3850.775,
      "eval_steps_per_second": 60.417,
      "step": 320540
    },
    {
      "epoch": 517.03,
      "learning_rate": 0.04831730974725807,
      "loss": 0.7072,
      "step": 320560
    },
    {
      "epoch": 517.06,
      "learning_rate": 0.04831408394403227,
      "loss": 0.7243,
      "step": 320580
    },
    {
      "epoch": 517.1,
      "learning_rate": 0.04831085814080646,
      "loss": 0.7097,
      "step": 320600
    },
    {
      "epoch": 517.13,
      "learning_rate": 0.04830763233758065,
      "loss": 0.6832,
      "step": 320620
    },
    {
      "epoch": 517.16,
      "learning_rate": 0.04830440653435484,
      "loss": 0.704,
      "step": 320640
    },
    {
      "epoch": 517.19,
      "learning_rate": 0.04830118073112903,
      "loss": 0.6989,
      "step": 320660
    },
    {
      "epoch": 517.23,
      "learning_rate": 0.04829795492790323,
      "loss": 0.7047,
      "step": 320680
    },
    {
      "epoch": 517.26,
      "learning_rate": 0.04829472912467742,
      "loss": 0.709,
      "step": 320700
    },
    {
      "epoch": 517.29,
      "learning_rate": 0.048291503321451615,
      "loss": 0.7049,
      "step": 320720
    },
    {
      "epoch": 517.32,
      "learning_rate": 0.04828827751822581,
      "loss": 0.7113,
      "step": 320740
    },
    {
      "epoch": 517.35,
      "learning_rate": 0.048285051715000006,
      "loss": 0.6963,
      "step": 320760
    },
    {
      "epoch": 517.39,
      "learning_rate": 0.0482818259117742,
      "loss": 0.7148,
      "step": 320780
    },
    {
      "epoch": 517.42,
      "learning_rate": 0.04827860010854839,
      "loss": 0.7199,
      "step": 320800
    },
    {
      "epoch": 517.45,
      "learning_rate": 0.04827537430532259,
      "loss": 0.7304,
      "step": 320820
    },
    {
      "epoch": 517.48,
      "learning_rate": 0.04827214850209678,
      "loss": 0.7119,
      "step": 320840
    },
    {
      "epoch": 517.52,
      "learning_rate": 0.048268922698870974,
      "loss": 0.7071,
      "step": 320860
    },
    {
      "epoch": 517.55,
      "learning_rate": 0.04826569689564517,
      "loss": 0.7202,
      "step": 320880
    },
    {
      "epoch": 517.58,
      "learning_rate": 0.048262471092419365,
      "loss": 0.7271,
      "step": 320900
    },
    {
      "epoch": 517.61,
      "learning_rate": 0.04825924528919355,
      "loss": 0.7022,
      "step": 320920
    },
    {
      "epoch": 517.65,
      "learning_rate": 0.04825601948596774,
      "loss": 0.713,
      "step": 320940
    },
    {
      "epoch": 517.68,
      "learning_rate": 0.048252793682741935,
      "loss": 0.7094,
      "step": 320960
    },
    {
      "epoch": 517.71,
      "learning_rate": 0.04824956787951613,
      "loss": 0.7034,
      "step": 320980
    },
    {
      "epoch": 517.74,
      "learning_rate": 0.048246342076290326,
      "loss": 0.7074,
      "step": 321000
    },
    {
      "epoch": 517.77,
      "learning_rate": 0.04824311627306452,
      "loss": 0.7228,
      "step": 321020
    },
    {
      "epoch": 517.81,
      "learning_rate": 0.04823989046983871,
      "loss": 0.7091,
      "step": 321040
    },
    {
      "epoch": 517.84,
      "learning_rate": 0.04823666466661291,
      "loss": 0.7192,
      "step": 321060
    },
    {
      "epoch": 517.87,
      "learning_rate": 0.0482334388633871,
      "loss": 0.724,
      "step": 321080
    },
    {
      "epoch": 517.9,
      "learning_rate": 0.048230213060161294,
      "loss": 0.7153,
      "step": 321100
    },
    {
      "epoch": 517.94,
      "learning_rate": 0.04822698725693549,
      "loss": 0.7069,
      "step": 321120
    },
    {
      "epoch": 517.97,
      "learning_rate": 0.048223761453709685,
      "loss": 0.7047,
      "step": 321140
    },
    {
      "epoch": 518.0,
      "learning_rate": 0.048220696940645166,
      "loss": 0.7361,
      "step": 321160
    },
    {
      "epoch": 518.0,
      "eval_accuracy": {
        "accuracy": 0.7665287643431427
      },
      "eval_loss": 1.0602740049362183,
      "eval_runtime": 2.8006,
      "eval_samples_per_second": 4574.321,
      "eval_steps_per_second": 71.769,
      "step": 321160
    },
    {
      "epoch": 518.03,
      "learning_rate": 0.04821747113741936,
      "loss": 0.6929,
      "step": 321180
    },
    {
      "epoch": 518.06,
      "learning_rate": 0.04821424533419355,
      "loss": 0.7078,
      "step": 321200
    },
    {
      "epoch": 518.1,
      "learning_rate": 0.04821101953096775,
      "loss": 0.7036,
      "step": 321220
    },
    {
      "epoch": 518.13,
      "learning_rate": 0.04820779372774194,
      "loss": 0.7271,
      "step": 321240
    },
    {
      "epoch": 518.16,
      "learning_rate": 0.048204567924516134,
      "loss": 0.7143,
      "step": 321260
    },
    {
      "epoch": 518.19,
      "learning_rate": 0.048201342121290326,
      "loss": 0.7046,
      "step": 321280
    },
    {
      "epoch": 518.23,
      "learning_rate": 0.048198116318064525,
      "loss": 0.7242,
      "step": 321300
    },
    {
      "epoch": 518.26,
      "learning_rate": 0.04819489051483872,
      "loss": 0.7043,
      "step": 321320
    },
    {
      "epoch": 518.29,
      "learning_rate": 0.04819166471161291,
      "loss": 0.7191,
      "step": 321340
    },
    {
      "epoch": 518.32,
      "learning_rate": 0.04818843890838711,
      "loss": 0.727,
      "step": 321360
    },
    {
      "epoch": 518.35,
      "learning_rate": 0.04818521310516129,
      "loss": 0.7193,
      "step": 321380
    },
    {
      "epoch": 518.39,
      "learning_rate": 0.048181987301935486,
      "loss": 0.7263,
      "step": 321400
    },
    {
      "epoch": 518.42,
      "learning_rate": 0.04817876149870968,
      "loss": 0.7171,
      "step": 321420
    },
    {
      "epoch": 518.45,
      "learning_rate": 0.04817553569548387,
      "loss": 0.7205,
      "step": 321440
    },
    {
      "epoch": 518.48,
      "learning_rate": 0.04817230989225807,
      "loss": 0.6964,
      "step": 321460
    },
    {
      "epoch": 518.52,
      "learning_rate": 0.04816908408903226,
      "loss": 0.7184,
      "step": 321480
    },
    {
      "epoch": 518.55,
      "learning_rate": 0.048165858285806454,
      "loss": 0.7074,
      "step": 321500
    },
    {
      "epoch": 518.58,
      "learning_rate": 0.048162632482580646,
      "loss": 0.7092,
      "step": 321520
    },
    {
      "epoch": 518.61,
      "learning_rate": 0.048159406679354845,
      "loss": 0.7124,
      "step": 321540
    },
    {
      "epoch": 518.65,
      "learning_rate": 0.04815618087612904,
      "loss": 0.7055,
      "step": 321560
    },
    {
      "epoch": 518.68,
      "learning_rate": 0.04815295507290323,
      "loss": 0.7126,
      "step": 321580
    },
    {
      "epoch": 518.71,
      "learning_rate": 0.04814972926967743,
      "loss": 0.7054,
      "step": 321600
    },
    {
      "epoch": 518.74,
      "learning_rate": 0.04814650346645162,
      "loss": 0.7179,
      "step": 321620
    },
    {
      "epoch": 518.77,
      "learning_rate": 0.04814327766322581,
      "loss": 0.7118,
      "step": 321640
    },
    {
      "epoch": 518.81,
      "learning_rate": 0.04814005186000001,
      "loss": 0.7222,
      "step": 321660
    },
    {
      "epoch": 518.84,
      "learning_rate": 0.04813682605677419,
      "loss": 0.7256,
      "step": 321680
    },
    {
      "epoch": 518.87,
      "learning_rate": 0.04813360025354839,
      "loss": 0.7305,
      "step": 321700
    },
    {
      "epoch": 518.9,
      "learning_rate": 0.04813037445032258,
      "loss": 0.7188,
      "step": 321720
    },
    {
      "epoch": 518.94,
      "learning_rate": 0.048127148647096774,
      "loss": 0.7086,
      "step": 321740
    },
    {
      "epoch": 518.97,
      "learning_rate": 0.04812392284387097,
      "loss": 0.7275,
      "step": 321760
    },
    {
      "epoch": 519.0,
      "learning_rate": 0.048120697040645165,
      "loss": 0.7327,
      "step": 321780
    },
    {
      "epoch": 519.0,
      "eval_accuracy": {
        "accuracy": 0.7583326828506752
      },
      "eval_loss": 1.095522165298462,
      "eval_runtime": 2.811,
      "eval_samples_per_second": 4557.401,
      "eval_steps_per_second": 71.504,
      "step": 321780
    },
    {
      "epoch": 519.03,
      "learning_rate": 0.04811747123741936,
      "loss": 0.734,
      "step": 321800
    },
    {
      "epoch": 519.06,
      "learning_rate": 0.04811424543419355,
      "loss": 0.7122,
      "step": 321820
    },
    {
      "epoch": 519.1,
      "learning_rate": 0.04811101963096775,
      "loss": 0.6953,
      "step": 321840
    },
    {
      "epoch": 519.13,
      "learning_rate": 0.04810779382774194,
      "loss": 0.6989,
      "step": 321860
    },
    {
      "epoch": 519.16,
      "learning_rate": 0.04810456802451613,
      "loss": 0.6952,
      "step": 321880
    },
    {
      "epoch": 519.19,
      "learning_rate": 0.04810134222129033,
      "loss": 0.7053,
      "step": 321900
    },
    {
      "epoch": 519.23,
      "learning_rate": 0.048098116418064524,
      "loss": 0.6895,
      "step": 321920
    },
    {
      "epoch": 519.26,
      "learning_rate": 0.048094890614838716,
      "loss": 0.7091,
      "step": 321940
    },
    {
      "epoch": 519.29,
      "learning_rate": 0.048091664811612915,
      "loss": 0.7038,
      "step": 321960
    },
    {
      "epoch": 519.32,
      "learning_rate": 0.04808843900838711,
      "loss": 0.7034,
      "step": 321980
    },
    {
      "epoch": 519.35,
      "learning_rate": 0.04808521320516129,
      "loss": 0.7012,
      "step": 322000
    },
    {
      "epoch": 519.39,
      "learning_rate": 0.048081987401935485,
      "loss": 0.697,
      "step": 322020
    },
    {
      "epoch": 519.42,
      "learning_rate": 0.04807876159870968,
      "loss": 0.7116,
      "step": 322040
    },
    {
      "epoch": 519.45,
      "learning_rate": 0.04807553579548387,
      "loss": 0.7135,
      "step": 322060
    },
    {
      "epoch": 519.48,
      "learning_rate": 0.04807230999225807,
      "loss": 0.7126,
      "step": 322080
    },
    {
      "epoch": 519.52,
      "learning_rate": 0.04806908418903226,
      "loss": 0.6977,
      "step": 322100
    },
    {
      "epoch": 519.55,
      "learning_rate": 0.04806585838580645,
      "loss": 0.716,
      "step": 322120
    },
    {
      "epoch": 519.58,
      "learning_rate": 0.04806263258258065,
      "loss": 0.6941,
      "step": 322140
    },
    {
      "epoch": 519.61,
      "learning_rate": 0.048059406779354844,
      "loss": 0.7177,
      "step": 322160
    },
    {
      "epoch": 519.65,
      "learning_rate": 0.048056180976129036,
      "loss": 0.7098,
      "step": 322180
    },
    {
      "epoch": 519.68,
      "learning_rate": 0.048052955172903235,
      "loss": 0.7124,
      "step": 322200
    },
    {
      "epoch": 519.71,
      "learning_rate": 0.04804972936967743,
      "loss": 0.7164,
      "step": 322220
    },
    {
      "epoch": 519.74,
      "learning_rate": 0.04804650356645162,
      "loss": 0.7025,
      "step": 322240
    },
    {
      "epoch": 519.77,
      "learning_rate": 0.04804327776322582,
      "loss": 0.7125,
      "step": 322260
    },
    {
      "epoch": 519.81,
      "learning_rate": 0.04804005196000001,
      "loss": 0.708,
      "step": 322280
    },
    {
      "epoch": 519.84,
      "learning_rate": 0.048036826156774196,
      "loss": 0.7132,
      "step": 322300
    },
    {
      "epoch": 519.87,
      "learning_rate": 0.04803360035354839,
      "loss": 0.7341,
      "step": 322320
    },
    {
      "epoch": 519.9,
      "learning_rate": 0.04803037455032258,
      "loss": 0.7188,
      "step": 322340
    },
    {
      "epoch": 519.94,
      "learning_rate": 0.04802714874709677,
      "loss": 0.7177,
      "step": 322360
    },
    {
      "epoch": 519.97,
      "learning_rate": 0.04802392294387097,
      "loss": 0.7198,
      "step": 322380
    },
    {
      "epoch": 520.0,
      "learning_rate": 0.04802069714064516,
      "loss": 0.71,
      "step": 322400
    },
    {
      "epoch": 520.0,
      "eval_accuracy": {
        "accuracy": 0.7647334322066973
      },
      "eval_loss": 1.0699703693389893,
      "eval_runtime": 2.9511,
      "eval_samples_per_second": 4341.048,
      "eval_steps_per_second": 68.109,
      "step": 322400
    },
    {
      "epoch": 520.03,
      "learning_rate": 0.048017471337419355,
      "loss": 0.7005,
      "step": 322420
    },
    {
      "epoch": 520.06,
      "learning_rate": 0.048014245534193555,
      "loss": 0.7195,
      "step": 322440
    },
    {
      "epoch": 520.1,
      "learning_rate": 0.04801101973096775,
      "loss": 0.6911,
      "step": 322460
    },
    {
      "epoch": 520.13,
      "learning_rate": 0.04800779392774194,
      "loss": 0.6902,
      "step": 322480
    },
    {
      "epoch": 520.16,
      "learning_rate": 0.04800456812451614,
      "loss": 0.7064,
      "step": 322500
    },
    {
      "epoch": 520.19,
      "learning_rate": 0.04800134232129033,
      "loss": 0.7052,
      "step": 322520
    },
    {
      "epoch": 520.23,
      "learning_rate": 0.04799811651806452,
      "loss": 0.6963,
      "step": 322540
    },
    {
      "epoch": 520.26,
      "learning_rate": 0.047994890714838714,
      "loss": 0.7063,
      "step": 322560
    },
    {
      "epoch": 520.29,
      "learning_rate": 0.047991664911612913,
      "loss": 0.7008,
      "step": 322580
    },
    {
      "epoch": 520.32,
      "learning_rate": 0.047988439108387106,
      "loss": 0.704,
      "step": 322600
    },
    {
      "epoch": 520.35,
      "learning_rate": 0.04798521330516129,
      "loss": 0.7252,
      "step": 322620
    },
    {
      "epoch": 520.39,
      "learning_rate": 0.04798198750193548,
      "loss": 0.7148,
      "step": 322640
    },
    {
      "epoch": 520.42,
      "learning_rate": 0.047978761698709675,
      "loss": 0.7247,
      "step": 322660
    },
    {
      "epoch": 520.45,
      "learning_rate": 0.047975535895483874,
      "loss": 0.7213,
      "step": 322680
    },
    {
      "epoch": 520.48,
      "learning_rate": 0.047972310092258066,
      "loss": 0.7161,
      "step": 322700
    },
    {
      "epoch": 520.52,
      "learning_rate": 0.04796908428903226,
      "loss": 0.7001,
      "step": 322720
    },
    {
      "epoch": 520.55,
      "learning_rate": 0.04796585848580646,
      "loss": 0.7097,
      "step": 322740
    },
    {
      "epoch": 520.58,
      "learning_rate": 0.04796263268258065,
      "loss": 0.7134,
      "step": 322760
    },
    {
      "epoch": 520.61,
      "learning_rate": 0.04795940687935484,
      "loss": 0.7164,
      "step": 322780
    },
    {
      "epoch": 520.65,
      "learning_rate": 0.04795618107612904,
      "loss": 0.7232,
      "step": 322800
    },
    {
      "epoch": 520.68,
      "learning_rate": 0.04795295527290323,
      "loss": 0.7104,
      "step": 322820
    },
    {
      "epoch": 520.71,
      "learning_rate": 0.047949729469677425,
      "loss": 0.7333,
      "step": 322840
    },
    {
      "epoch": 520.74,
      "learning_rate": 0.04794650366645162,
      "loss": 0.7055,
      "step": 322860
    },
    {
      "epoch": 520.77,
      "learning_rate": 0.04794327786322582,
      "loss": 0.7232,
      "step": 322880
    },
    {
      "epoch": 520.81,
      "learning_rate": 0.04794005206000001,
      "loss": 0.7227,
      "step": 322900
    },
    {
      "epoch": 520.84,
      "learning_rate": 0.0479368262567742,
      "loss": 0.7257,
      "step": 322920
    },
    {
      "epoch": 520.87,
      "learning_rate": 0.047933600453548386,
      "loss": 0.7343,
      "step": 322940
    },
    {
      "epoch": 520.9,
      "learning_rate": 0.04793037465032258,
      "loss": 0.7206,
      "step": 322960
    },
    {
      "epoch": 520.94,
      "learning_rate": 0.04792714884709678,
      "loss": 0.7186,
      "step": 322980
    },
    {
      "epoch": 520.97,
      "learning_rate": 0.04792392304387097,
      "loss": 0.7314,
      "step": 323000
    },
    {
      "epoch": 521.0,
      "learning_rate": 0.04792069724064516,
      "loss": 0.7126,
      "step": 323020
    },
    {
      "epoch": 521.0,
      "eval_accuracy": {
        "accuracy": 0.7527125126844119
      },
      "eval_loss": 1.0949009656906128,
      "eval_runtime": 2.9089,
      "eval_samples_per_second": 4404.106,
      "eval_steps_per_second": 69.099,
      "step": 323020
    },
    {
      "epoch": 521.03,
      "learning_rate": 0.04791747143741936,
      "loss": 0.7279,
      "step": 323040
    },
    {
      "epoch": 521.06,
      "learning_rate": 0.04791424563419355,
      "loss": 0.6966,
      "step": 323060
    },
    {
      "epoch": 521.1,
      "learning_rate": 0.047911019830967745,
      "loss": 0.6965,
      "step": 323080
    },
    {
      "epoch": 521.13,
      "learning_rate": 0.04790779402774194,
      "loss": 0.7036,
      "step": 323100
    },
    {
      "epoch": 521.16,
      "learning_rate": 0.047904568224516136,
      "loss": 0.7093,
      "step": 323120
    },
    {
      "epoch": 521.19,
      "learning_rate": 0.04790134242129033,
      "loss": 0.6943,
      "step": 323140
    },
    {
      "epoch": 521.23,
      "learning_rate": 0.04789811661806452,
      "loss": 0.6993,
      "step": 323160
    },
    {
      "epoch": 521.26,
      "learning_rate": 0.04789489081483872,
      "loss": 0.6812,
      "step": 323180
    },
    {
      "epoch": 521.29,
      "learning_rate": 0.04789166501161291,
      "loss": 0.729,
      "step": 323200
    },
    {
      "epoch": 521.32,
      "learning_rate": 0.047888439208387104,
      "loss": 0.7047,
      "step": 323220
    },
    {
      "epoch": 521.35,
      "learning_rate": 0.04788521340516129,
      "loss": 0.7425,
      "step": 323240
    },
    {
      "epoch": 521.39,
      "learning_rate": 0.04788198760193548,
      "loss": 0.6947,
      "step": 323260
    },
    {
      "epoch": 521.42,
      "learning_rate": 0.04787876179870968,
      "loss": 0.7111,
      "step": 323280
    },
    {
      "epoch": 521.45,
      "learning_rate": 0.04787553599548387,
      "loss": 0.7237,
      "step": 323300
    },
    {
      "epoch": 521.48,
      "learning_rate": 0.047872310192258065,
      "loss": 0.7167,
      "step": 323320
    },
    {
      "epoch": 521.52,
      "learning_rate": 0.047869084389032264,
      "loss": 0.717,
      "step": 323340
    },
    {
      "epoch": 521.55,
      "learning_rate": 0.047865858585806456,
      "loss": 0.7007,
      "step": 323360
    },
    {
      "epoch": 521.58,
      "learning_rate": 0.04786263278258065,
      "loss": 0.7182,
      "step": 323380
    },
    {
      "epoch": 521.61,
      "learning_rate": 0.04785940697935484,
      "loss": 0.7081,
      "step": 323400
    },
    {
      "epoch": 521.65,
      "learning_rate": 0.04785618117612904,
      "loss": 0.7243,
      "step": 323420
    },
    {
      "epoch": 521.68,
      "learning_rate": 0.04785295537290323,
      "loss": 0.7018,
      "step": 323440
    },
    {
      "epoch": 521.71,
      "learning_rate": 0.047849729569677424,
      "loss": 0.7168,
      "step": 323460
    },
    {
      "epoch": 521.74,
      "learning_rate": 0.04784650376645162,
      "loss": 0.7097,
      "step": 323480
    },
    {
      "epoch": 521.77,
      "learning_rate": 0.047843277963225815,
      "loss": 0.718,
      "step": 323500
    },
    {
      "epoch": 521.81,
      "learning_rate": 0.04784005216000001,
      "loss": 0.7308,
      "step": 323520
    },
    {
      "epoch": 521.84,
      "learning_rate": 0.047836826356774206,
      "loss": 0.7193,
      "step": 323540
    },
    {
      "epoch": 521.87,
      "learning_rate": 0.047833600553548385,
      "loss": 0.72,
      "step": 323560
    },
    {
      "epoch": 521.9,
      "learning_rate": 0.047830374750322584,
      "loss": 0.7054,
      "step": 323580
    },
    {
      "epoch": 521.94,
      "learning_rate": 0.047827148947096776,
      "loss": 0.7179,
      "step": 323600
    },
    {
      "epoch": 521.97,
      "learning_rate": 0.04782392314387097,
      "loss": 0.7153,
      "step": 323620
    },
    {
      "epoch": 522.0,
      "learning_rate": 0.047820858630806456,
      "loss": 0.7363,
      "step": 323640
    },
    {
      "epoch": 522.0,
      "eval_accuracy": {
        "accuracy": 0.7651237218015767
      },
      "eval_loss": 1.0805902481079102,
      "eval_runtime": 3.6166,
      "eval_samples_per_second": 3542.291,
      "eval_steps_per_second": 55.577,
      "step": 323640
    },
    {
      "epoch": 522.03,
      "learning_rate": 0.047817632827580656,
      "loss": 0.6899,
      "step": 323660
    },
    {
      "epoch": 522.06,
      "learning_rate": 0.04781440702435485,
      "loss": 0.7044,
      "step": 323680
    },
    {
      "epoch": 522.1,
      "learning_rate": 0.04781118122112903,
      "loss": 0.7019,
      "step": 323700
    },
    {
      "epoch": 522.13,
      "learning_rate": 0.047807955417903225,
      "loss": 0.6994,
      "step": 323720
    },
    {
      "epoch": 522.16,
      "learning_rate": 0.04780472961467742,
      "loss": 0.6936,
      "step": 323740
    },
    {
      "epoch": 522.19,
      "learning_rate": 0.047801503811451616,
      "loss": 0.7015,
      "step": 323760
    },
    {
      "epoch": 522.23,
      "learning_rate": 0.04779827800822581,
      "loss": 0.7352,
      "step": 323780
    },
    {
      "epoch": 522.26,
      "learning_rate": 0.047795052205,
      "loss": 0.7078,
      "step": 323800
    },
    {
      "epoch": 522.29,
      "learning_rate": 0.0477918264017742,
      "loss": 0.7107,
      "step": 323820
    },
    {
      "epoch": 522.32,
      "learning_rate": 0.04778860059854839,
      "loss": 0.7055,
      "step": 323840
    },
    {
      "epoch": 522.35,
      "learning_rate": 0.047785374795322584,
      "loss": 0.694,
      "step": 323860
    },
    {
      "epoch": 522.39,
      "learning_rate": 0.04778214899209678,
      "loss": 0.6937,
      "step": 323880
    },
    {
      "epoch": 522.42,
      "learning_rate": 0.047778923188870975,
      "loss": 0.7037,
      "step": 323900
    },
    {
      "epoch": 522.45,
      "learning_rate": 0.04777569738564517,
      "loss": 0.721,
      "step": 323920
    },
    {
      "epoch": 522.48,
      "learning_rate": 0.04777247158241936,
      "loss": 0.7218,
      "step": 323940
    },
    {
      "epoch": 522.52,
      "learning_rate": 0.04776924577919356,
      "loss": 0.7058,
      "step": 323960
    },
    {
      "epoch": 522.55,
      "learning_rate": 0.04776601997596775,
      "loss": 0.723,
      "step": 323980
    },
    {
      "epoch": 522.58,
      "learning_rate": 0.047762794172741936,
      "loss": 0.7027,
      "step": 324000
    },
    {
      "epoch": 522.61,
      "learning_rate": 0.04775956836951613,
      "loss": 0.7011,
      "step": 324020
    },
    {
      "epoch": 522.65,
      "learning_rate": 0.04775634256629032,
      "loss": 0.6838,
      "step": 324040
    },
    {
      "epoch": 522.68,
      "learning_rate": 0.04775311676306452,
      "loss": 0.7036,
      "step": 324060
    },
    {
      "epoch": 522.71,
      "learning_rate": 0.04774989095983871,
      "loss": 0.7163,
      "step": 324080
    },
    {
      "epoch": 522.74,
      "learning_rate": 0.047746665156612904,
      "loss": 0.7317,
      "step": 324100
    },
    {
      "epoch": 522.77,
      "learning_rate": 0.0477434393533871,
      "loss": 0.7337,
      "step": 324120
    },
    {
      "epoch": 522.81,
      "learning_rate": 0.047740213550161295,
      "loss": 0.71,
      "step": 324140
    },
    {
      "epoch": 522.84,
      "learning_rate": 0.04773698774693549,
      "loss": 0.6989,
      "step": 324160
    },
    {
      "epoch": 522.87,
      "learning_rate": 0.04773376194370968,
      "loss": 0.7071,
      "step": 324180
    },
    {
      "epoch": 522.9,
      "learning_rate": 0.04773053614048388,
      "loss": 0.7022,
      "step": 324200
    },
    {
      "epoch": 522.94,
      "learning_rate": 0.04772731033725807,
      "loss": 0.7049,
      "step": 324220
    },
    {
      "epoch": 522.97,
      "learning_rate": 0.04772408453403226,
      "loss": 0.7176,
      "step": 324240
    },
    {
      "epoch": 523.0,
      "learning_rate": 0.04772085873080646,
      "loss": 0.7047,
      "step": 324260
    },
    {
      "epoch": 523.0,
      "eval_accuracy": {
        "accuracy": 0.7592693778783858
      },
      "eval_loss": 1.097898006439209,
      "eval_runtime": 2.9392,
      "eval_samples_per_second": 4358.742,
      "eval_steps_per_second": 68.387,
      "step": 324260
    },
    {
      "epoch": 523.03,
      "learning_rate": 0.047717632927580654,
      "loss": 0.7213,
      "step": 324280
    },
    {
      "epoch": 523.06,
      "learning_rate": 0.047714407124354846,
      "loss": 0.6921,
      "step": 324300
    },
    {
      "epoch": 523.1,
      "learning_rate": 0.04771118132112903,
      "loss": 0.6893,
      "step": 324320
    },
    {
      "epoch": 523.13,
      "learning_rate": 0.047707955517903224,
      "loss": 0.7042,
      "step": 324340
    },
    {
      "epoch": 523.16,
      "learning_rate": 0.04770472971467742,
      "loss": 0.6857,
      "step": 324360
    },
    {
      "epoch": 523.19,
      "learning_rate": 0.047701503911451615,
      "loss": 0.7087,
      "step": 324380
    },
    {
      "epoch": 523.23,
      "learning_rate": 0.04769827810822581,
      "loss": 0.705,
      "step": 324400
    },
    {
      "epoch": 523.26,
      "learning_rate": 0.047695052305000006,
      "loss": 0.7224,
      "step": 324420
    },
    {
      "epoch": 523.29,
      "learning_rate": 0.0476918265017742,
      "loss": 0.7182,
      "step": 324440
    },
    {
      "epoch": 523.32,
      "learning_rate": 0.04768860069854839,
      "loss": 0.7064,
      "step": 324460
    },
    {
      "epoch": 523.35,
      "learning_rate": 0.04768537489532258,
      "loss": 0.7072,
      "step": 324480
    },
    {
      "epoch": 523.39,
      "learning_rate": 0.04768214909209678,
      "loss": 0.7177,
      "step": 324500
    },
    {
      "epoch": 523.42,
      "learning_rate": 0.047678923288870974,
      "loss": 0.7188,
      "step": 324520
    },
    {
      "epoch": 523.45,
      "learning_rate": 0.047675697485645166,
      "loss": 0.6857,
      "step": 324540
    },
    {
      "epoch": 523.48,
      "learning_rate": 0.047672471682419365,
      "loss": 0.7094,
      "step": 324560
    },
    {
      "epoch": 523.52,
      "learning_rate": 0.04766924587919356,
      "loss": 0.7032,
      "step": 324580
    },
    {
      "epoch": 523.55,
      "learning_rate": 0.04766602007596775,
      "loss": 0.7191,
      "step": 324600
    },
    {
      "epoch": 523.58,
      "learning_rate": 0.047662794272741935,
      "loss": 0.7081,
      "step": 324620
    },
    {
      "epoch": 523.61,
      "learning_rate": 0.04765956846951613,
      "loss": 0.6961,
      "step": 324640
    },
    {
      "epoch": 523.65,
      "learning_rate": 0.047656342666290326,
      "loss": 0.6975,
      "step": 324660
    },
    {
      "epoch": 523.68,
      "learning_rate": 0.04765311686306452,
      "loss": 0.706,
      "step": 324680
    },
    {
      "epoch": 523.71,
      "learning_rate": 0.04764989105983871,
      "loss": 0.7067,
      "step": 324700
    },
    {
      "epoch": 523.74,
      "learning_rate": 0.0476466652566129,
      "loss": 0.6938,
      "step": 324720
    },
    {
      "epoch": 523.77,
      "learning_rate": 0.0476434394533871,
      "loss": 0.7146,
      "step": 324740
    },
    {
      "epoch": 523.81,
      "learning_rate": 0.047640213650161294,
      "loss": 0.7073,
      "step": 324760
    },
    {
      "epoch": 523.84,
      "learning_rate": 0.047636987846935486,
      "loss": 0.6957,
      "step": 324780
    },
    {
      "epoch": 523.87,
      "learning_rate": 0.047633762043709685,
      "loss": 0.7106,
      "step": 324800
    },
    {
      "epoch": 523.9,
      "learning_rate": 0.04763053624048388,
      "loss": 0.7119,
      "step": 324820
    },
    {
      "epoch": 523.94,
      "learning_rate": 0.04762731043725807,
      "loss": 0.7094,
      "step": 324840
    },
    {
      "epoch": 523.97,
      "learning_rate": 0.04762408463403227,
      "loss": 0.7256,
      "step": 324860
    },
    {
      "epoch": 524.0,
      "learning_rate": 0.04762085883080646,
      "loss": 0.7304,
      "step": 324880
    },
    {
      "epoch": 524.0,
      "eval_accuracy": {
        "accuracy": 0.7609866520958551
      },
      "eval_loss": 1.0908669233322144,
      "eval_runtime": 2.8501,
      "eval_samples_per_second": 4494.977,
      "eval_steps_per_second": 70.525,
      "step": 324880
    },
    {
      "epoch": 524.03,
      "learning_rate": 0.04761763302758065,
      "loss": 0.7266,
      "step": 324900
    },
    {
      "epoch": 524.06,
      "learning_rate": 0.047614407224354845,
      "loss": 0.6968,
      "step": 324920
    },
    {
      "epoch": 524.1,
      "learning_rate": 0.04761118142112903,
      "loss": 0.6941,
      "step": 324940
    },
    {
      "epoch": 524.13,
      "learning_rate": 0.04760795561790322,
      "loss": 0.7146,
      "step": 324960
    },
    {
      "epoch": 524.16,
      "learning_rate": 0.04760472981467742,
      "loss": 0.7055,
      "step": 324980
    },
    {
      "epoch": 524.19,
      "learning_rate": 0.04760150401145161,
      "loss": 0.7112,
      "step": 325000
    },
    {
      "epoch": 524.23,
      "learning_rate": 0.047598278208225805,
      "loss": 0.6821,
      "step": 325020
    },
    {
      "epoch": 524.26,
      "learning_rate": 0.047595052405000005,
      "loss": 0.7154,
      "step": 325040
    },
    {
      "epoch": 524.29,
      "learning_rate": 0.0475918266017742,
      "loss": 0.7054,
      "step": 325060
    },
    {
      "epoch": 524.32,
      "learning_rate": 0.04758860079854839,
      "loss": 0.6982,
      "step": 325080
    },
    {
      "epoch": 524.35,
      "learning_rate": 0.04758537499532259,
      "loss": 0.6814,
      "step": 325100
    },
    {
      "epoch": 524.39,
      "learning_rate": 0.04758214919209678,
      "loss": 0.6936,
      "step": 325120
    },
    {
      "epoch": 524.42,
      "learning_rate": 0.04757892338887097,
      "loss": 0.7012,
      "step": 325140
    },
    {
      "epoch": 524.45,
      "learning_rate": 0.04757569758564517,
      "loss": 0.7079,
      "step": 325160
    },
    {
      "epoch": 524.48,
      "learning_rate": 0.047572471782419364,
      "loss": 0.6993,
      "step": 325180
    },
    {
      "epoch": 524.52,
      "learning_rate": 0.047569245979193556,
      "loss": 0.709,
      "step": 325200
    },
    {
      "epoch": 524.55,
      "learning_rate": 0.04756602017596775,
      "loss": 0.7129,
      "step": 325220
    },
    {
      "epoch": 524.58,
      "learning_rate": 0.04756279437274193,
      "loss": 0.7343,
      "step": 325240
    },
    {
      "epoch": 524.61,
      "learning_rate": 0.047559568569516125,
      "loss": 0.7151,
      "step": 325260
    },
    {
      "epoch": 524.65,
      "learning_rate": 0.047556342766290324,
      "loss": 0.7036,
      "step": 325280
    },
    {
      "epoch": 524.68,
      "learning_rate": 0.047553116963064516,
      "loss": 0.7073,
      "step": 325300
    },
    {
      "epoch": 524.71,
      "learning_rate": 0.04754989115983871,
      "loss": 0.732,
      "step": 325320
    },
    {
      "epoch": 524.74,
      "learning_rate": 0.04754666535661291,
      "loss": 0.7117,
      "step": 325340
    },
    {
      "epoch": 524.77,
      "learning_rate": 0.0475434395533871,
      "loss": 0.7177,
      "step": 325360
    },
    {
      "epoch": 524.81,
      "learning_rate": 0.04754021375016129,
      "loss": 0.7139,
      "step": 325380
    },
    {
      "epoch": 524.84,
      "learning_rate": 0.04753698794693549,
      "loss": 0.7066,
      "step": 325400
    },
    {
      "epoch": 524.87,
      "learning_rate": 0.04753376214370968,
      "loss": 0.721,
      "step": 325420
    },
    {
      "epoch": 524.9,
      "learning_rate": 0.047530536340483875,
      "loss": 0.7234,
      "step": 325440
    },
    {
      "epoch": 524.94,
      "learning_rate": 0.04752731053725807,
      "loss": 0.71,
      "step": 325460
    },
    {
      "epoch": 524.97,
      "learning_rate": 0.04752408473403227,
      "loss": 0.7231,
      "step": 325480
    },
    {
      "epoch": 525.0,
      "learning_rate": 0.04752085893080646,
      "loss": 0.722,
      "step": 325500
    },
    {
      "epoch": 525.0,
      "eval_accuracy": {
        "accuracy": 0.7620794629615174
      },
      "eval_loss": 1.0851200819015503,
      "eval_runtime": 2.9637,
      "eval_samples_per_second": 4322.699,
      "eval_steps_per_second": 67.822,
      "step": 325500
    },
    {
      "epoch": 525.03,
      "learning_rate": 0.04751763312758065,
      "loss": 0.7452,
      "step": 325520
    },
    {
      "epoch": 525.06,
      "learning_rate": 0.04751440732435485,
      "loss": 0.6905,
      "step": 325540
    },
    {
      "epoch": 525.1,
      "learning_rate": 0.04751118152112903,
      "loss": 0.6991,
      "step": 325560
    },
    {
      "epoch": 525.13,
      "learning_rate": 0.04750795571790323,
      "loss": 0.6841,
      "step": 325580
    },
    {
      "epoch": 525.16,
      "learning_rate": 0.04750472991467742,
      "loss": 0.6735,
      "step": 325600
    },
    {
      "epoch": 525.19,
      "learning_rate": 0.04750150411145161,
      "loss": 0.7134,
      "step": 325620
    },
    {
      "epoch": 525.23,
      "learning_rate": 0.04749827830822581,
      "loss": 0.7193,
      "step": 325640
    },
    {
      "epoch": 525.26,
      "learning_rate": 0.047495052505,
      "loss": 0.7151,
      "step": 325660
    },
    {
      "epoch": 525.29,
      "learning_rate": 0.047491826701774195,
      "loss": 0.6872,
      "step": 325680
    },
    {
      "epoch": 525.32,
      "learning_rate": 0.047488600898548394,
      "loss": 0.7088,
      "step": 325700
    },
    {
      "epoch": 525.35,
      "learning_rate": 0.047485375095322586,
      "loss": 0.6949,
      "step": 325720
    },
    {
      "epoch": 525.39,
      "learning_rate": 0.04748214929209678,
      "loss": 0.6925,
      "step": 325740
    },
    {
      "epoch": 525.42,
      "learning_rate": 0.04747892348887097,
      "loss": 0.709,
      "step": 325760
    },
    {
      "epoch": 525.45,
      "learning_rate": 0.04747569768564517,
      "loss": 0.7079,
      "step": 325780
    },
    {
      "epoch": 525.48,
      "learning_rate": 0.04747247188241936,
      "loss": 0.7155,
      "step": 325800
    },
    {
      "epoch": 525.52,
      "learning_rate": 0.047469246079193554,
      "loss": 0.7223,
      "step": 325820
    },
    {
      "epoch": 525.55,
      "learning_rate": 0.04746602027596775,
      "loss": 0.7068,
      "step": 325840
    },
    {
      "epoch": 525.58,
      "learning_rate": 0.047462794472741945,
      "loss": 0.7017,
      "step": 325860
    },
    {
      "epoch": 525.61,
      "learning_rate": 0.04745956866951613,
      "loss": 0.7072,
      "step": 325880
    },
    {
      "epoch": 525.65,
      "learning_rate": 0.04745634286629032,
      "loss": 0.7169,
      "step": 325900
    },
    {
      "epoch": 525.68,
      "learning_rate": 0.047453117063064515,
      "loss": 0.7128,
      "step": 325920
    },
    {
      "epoch": 525.71,
      "learning_rate": 0.047449891259838714,
      "loss": 0.7282,
      "step": 325940
    },
    {
      "epoch": 525.74,
      "learning_rate": 0.047446665456612906,
      "loss": 0.7129,
      "step": 325960
    },
    {
      "epoch": 525.77,
      "learning_rate": 0.0474434396533871,
      "loss": 0.7127,
      "step": 325980
    },
    {
      "epoch": 525.81,
      "learning_rate": 0.04744021385016129,
      "loss": 0.7289,
      "step": 326000
    },
    {
      "epoch": 525.84,
      "learning_rate": 0.04743698804693549,
      "loss": 0.7243,
      "step": 326020
    },
    {
      "epoch": 525.87,
      "learning_rate": 0.04743376224370968,
      "loss": 0.707,
      "step": 326040
    },
    {
      "epoch": 525.9,
      "learning_rate": 0.047430536440483874,
      "loss": 0.7095,
      "step": 326060
    },
    {
      "epoch": 525.94,
      "learning_rate": 0.04742731063725807,
      "loss": 0.7098,
      "step": 326080
    },
    {
      "epoch": 525.97,
      "learning_rate": 0.047424084834032265,
      "loss": 0.7131,
      "step": 326100
    },
    {
      "epoch": 526.0,
      "learning_rate": 0.04742102032096775,
      "loss": 0.7009,
      "step": 326120
    },
    {
      "epoch": 526.0,
      "eval_accuracy": {
        "accuracy": 0.7645773163687456
      },
      "eval_loss": 1.056198239326477,
      "eval_runtime": 3.9336,
      "eval_samples_per_second": 3256.832,
      "eval_steps_per_second": 51.099,
      "step": 326120
    },
    {
      "epoch": 526.03,
      "learning_rate": 0.04741779451774194,
      "loss": 0.68,
      "step": 326140
    },
    {
      "epoch": 526.06,
      "learning_rate": 0.04741456871451613,
      "loss": 0.6797,
      "step": 326160
    },
    {
      "epoch": 526.1,
      "learning_rate": 0.04741134291129033,
      "loss": 0.6828,
      "step": 326180
    },
    {
      "epoch": 526.13,
      "learning_rate": 0.04740811710806452,
      "loss": 0.6901,
      "step": 326200
    },
    {
      "epoch": 526.16,
      "learning_rate": 0.047404891304838714,
      "loss": 0.7021,
      "step": 326220
    },
    {
      "epoch": 526.19,
      "learning_rate": 0.047401665501612913,
      "loss": 0.6977,
      "step": 326240
    },
    {
      "epoch": 526.23,
      "learning_rate": 0.047398439698387106,
      "loss": 0.7113,
      "step": 326260
    },
    {
      "epoch": 526.26,
      "learning_rate": 0.0473952138951613,
      "loss": 0.6942,
      "step": 326280
    },
    {
      "epoch": 526.29,
      "learning_rate": 0.04739198809193549,
      "loss": 0.6926,
      "step": 326300
    },
    {
      "epoch": 526.32,
      "learning_rate": 0.047388762288709675,
      "loss": 0.6922,
      "step": 326320
    },
    {
      "epoch": 526.35,
      "learning_rate": 0.04738553648548387,
      "loss": 0.7033,
      "step": 326340
    },
    {
      "epoch": 526.39,
      "learning_rate": 0.047382310682258066,
      "loss": 0.6906,
      "step": 326360
    },
    {
      "epoch": 526.42,
      "learning_rate": 0.04737908487903226,
      "loss": 0.69,
      "step": 326380
    },
    {
      "epoch": 526.45,
      "learning_rate": 0.04737585907580645,
      "loss": 0.7238,
      "step": 326400
    },
    {
      "epoch": 526.48,
      "learning_rate": 0.04737263327258065,
      "loss": 0.7176,
      "step": 326420
    },
    {
      "epoch": 526.52,
      "learning_rate": 0.04736940746935484,
      "loss": 0.7368,
      "step": 326440
    },
    {
      "epoch": 526.55,
      "learning_rate": 0.047366181666129034,
      "loss": 0.7153,
      "step": 326460
    },
    {
      "epoch": 526.58,
      "learning_rate": 0.04736295586290323,
      "loss": 0.7234,
      "step": 326480
    },
    {
      "epoch": 526.61,
      "learning_rate": 0.047359730059677425,
      "loss": 0.6982,
      "step": 326500
    },
    {
      "epoch": 526.65,
      "learning_rate": 0.04735650425645162,
      "loss": 0.7131,
      "step": 326520
    },
    {
      "epoch": 526.68,
      "learning_rate": 0.04735327845322581,
      "loss": 0.7103,
      "step": 326540
    },
    {
      "epoch": 526.71,
      "learning_rate": 0.04735005265000001,
      "loss": 0.6923,
      "step": 326560
    },
    {
      "epoch": 526.74,
      "learning_rate": 0.0473468268467742,
      "loss": 0.7036,
      "step": 326580
    },
    {
      "epoch": 526.77,
      "learning_rate": 0.04734360104354839,
      "loss": 0.6957,
      "step": 326600
    },
    {
      "epoch": 526.81,
      "learning_rate": 0.04734037524032259,
      "loss": 0.7087,
      "step": 326620
    },
    {
      "epoch": 526.84,
      "learning_rate": 0.04733714943709677,
      "loss": 0.7085,
      "step": 326640
    },
    {
      "epoch": 526.87,
      "learning_rate": 0.04733392363387097,
      "loss": 0.7028,
      "step": 326660
    },
    {
      "epoch": 526.9,
      "learning_rate": 0.04733069783064516,
      "loss": 0.7184,
      "step": 326680
    },
    {
      "epoch": 526.94,
      "learning_rate": 0.047327472027419354,
      "loss": 0.7062,
      "step": 326700
    },
    {
      "epoch": 526.97,
      "learning_rate": 0.04732424622419355,
      "loss": 0.736,
      "step": 326720
    },
    {
      "epoch": 527.0,
      "learning_rate": 0.047321020420967745,
      "loss": 0.7214,
      "step": 326740
    },
    {
      "epoch": 527.0,
      "eval_accuracy": {
        "accuracy": 0.7631722738271798
      },
      "eval_loss": 1.0774569511413574,
      "eval_runtime": 2.913,
      "eval_samples_per_second": 4397.916,
      "eval_steps_per_second": 69.002,
      "step": 326740
    },
    {
      "epoch": 527.03,
      "learning_rate": 0.04731779461774194,
      "loss": 0.7365,
      "step": 326760
    },
    {
      "epoch": 527.06,
      "learning_rate": 0.047314568814516136,
      "loss": 0.6835,
      "step": 326780
    },
    {
      "epoch": 527.1,
      "learning_rate": 0.04731134301129033,
      "loss": 0.6879,
      "step": 326800
    },
    {
      "epoch": 527.13,
      "learning_rate": 0.04730811720806452,
      "loss": 0.6995,
      "step": 326820
    },
    {
      "epoch": 527.16,
      "learning_rate": 0.04730489140483871,
      "loss": 0.6895,
      "step": 326840
    },
    {
      "epoch": 527.19,
      "learning_rate": 0.04730166560161291,
      "loss": 0.7023,
      "step": 326860
    },
    {
      "epoch": 527.23,
      "learning_rate": 0.047298439798387104,
      "loss": 0.6994,
      "step": 326880
    },
    {
      "epoch": 527.26,
      "learning_rate": 0.047295213995161296,
      "loss": 0.6899,
      "step": 326900
    },
    {
      "epoch": 527.29,
      "learning_rate": 0.047291988191935495,
      "loss": 0.7045,
      "step": 326920
    },
    {
      "epoch": 527.32,
      "learning_rate": 0.047288762388709674,
      "loss": 0.7034,
      "step": 326940
    },
    {
      "epoch": 527.35,
      "learning_rate": 0.04728553658548387,
      "loss": 0.6983,
      "step": 326960
    },
    {
      "epoch": 527.39,
      "learning_rate": 0.047282310782258065,
      "loss": 0.7067,
      "step": 326980
    },
    {
      "epoch": 527.42,
      "learning_rate": 0.04727908497903226,
      "loss": 0.7036,
      "step": 327000
    },
    {
      "epoch": 527.45,
      "learning_rate": 0.047275859175806456,
      "loss": 0.7027,
      "step": 327020
    },
    {
      "epoch": 527.48,
      "learning_rate": 0.04727263337258065,
      "loss": 0.7063,
      "step": 327040
    },
    {
      "epoch": 527.52,
      "learning_rate": 0.04726940756935484,
      "loss": 0.6979,
      "step": 327060
    },
    {
      "epoch": 527.55,
      "learning_rate": 0.04726618176612903,
      "loss": 0.7027,
      "step": 327080
    },
    {
      "epoch": 527.58,
      "learning_rate": 0.04726295596290323,
      "loss": 0.7163,
      "step": 327100
    },
    {
      "epoch": 527.61,
      "learning_rate": 0.047259730159677424,
      "loss": 0.7081,
      "step": 327120
    },
    {
      "epoch": 527.65,
      "learning_rate": 0.047256504356451616,
      "loss": 0.7049,
      "step": 327140
    },
    {
      "epoch": 527.68,
      "learning_rate": 0.047253278553225815,
      "loss": 0.7214,
      "step": 327160
    },
    {
      "epoch": 527.71,
      "learning_rate": 0.04725005275000001,
      "loss": 0.7072,
      "step": 327180
    },
    {
      "epoch": 527.74,
      "learning_rate": 0.0472468269467742,
      "loss": 0.7317,
      "step": 327200
    },
    {
      "epoch": 527.77,
      "learning_rate": 0.0472436011435484,
      "loss": 0.7161,
      "step": 327220
    },
    {
      "epoch": 527.81,
      "learning_rate": 0.04724037534032259,
      "loss": 0.717,
      "step": 327240
    },
    {
      "epoch": 527.84,
      "learning_rate": 0.047237149537096776,
      "loss": 0.7086,
      "step": 327260
    },
    {
      "epoch": 527.87,
      "learning_rate": 0.04723392373387097,
      "loss": 0.7082,
      "step": 327280
    },
    {
      "epoch": 527.9,
      "learning_rate": 0.04723069793064516,
      "loss": 0.7171,
      "step": 327300
    },
    {
      "epoch": 527.94,
      "learning_rate": 0.04722747212741936,
      "loss": 0.7149,
      "step": 327320
    },
    {
      "epoch": 527.97,
      "learning_rate": 0.04722424632419355,
      "loss": 0.702,
      "step": 327340
    },
    {
      "epoch": 528.0,
      "learning_rate": 0.047221020520967744,
      "loss": 0.7118,
      "step": 327360
    },
    {
      "epoch": 528.0,
      "eval_accuracy": {
        "accuracy": 0.7618452892045898
      },
      "eval_loss": 1.0985075235366821,
      "eval_runtime": 2.7716,
      "eval_samples_per_second": 4622.257,
      "eval_steps_per_second": 72.522,
      "step": 327360
    },
    {
      "epoch": 528.03,
      "learning_rate": 0.047217794717741936,
      "loss": 0.7425,
      "step": 327380
    },
    {
      "epoch": 528.06,
      "learning_rate": 0.047214568914516135,
      "loss": 0.7239,
      "step": 327400
    },
    {
      "epoch": 528.1,
      "learning_rate": 0.04721134311129033,
      "loss": 0.7114,
      "step": 327420
    },
    {
      "epoch": 528.13,
      "learning_rate": 0.04720811730806452,
      "loss": 0.7066,
      "step": 327440
    },
    {
      "epoch": 528.16,
      "learning_rate": 0.04720489150483872,
      "loss": 0.7034,
      "step": 327460
    },
    {
      "epoch": 528.19,
      "learning_rate": 0.04720166570161291,
      "loss": 0.6932,
      "step": 327480
    },
    {
      "epoch": 528.23,
      "learning_rate": 0.0471984398983871,
      "loss": 0.6996,
      "step": 327500
    },
    {
      "epoch": 528.26,
      "learning_rate": 0.0471952140951613,
      "loss": 0.6968,
      "step": 327520
    },
    {
      "epoch": 528.29,
      "learning_rate": 0.047191988291935494,
      "loss": 0.7029,
      "step": 327540
    },
    {
      "epoch": 528.32,
      "learning_rate": 0.04718876248870968,
      "loss": 0.693,
      "step": 327560
    },
    {
      "epoch": 528.35,
      "learning_rate": 0.04718553668548387,
      "loss": 0.7037,
      "step": 327580
    },
    {
      "epoch": 528.39,
      "learning_rate": 0.04718231088225806,
      "loss": 0.702,
      "step": 327600
    },
    {
      "epoch": 528.42,
      "learning_rate": 0.047179085079032256,
      "loss": 0.7004,
      "step": 327620
    },
    {
      "epoch": 528.45,
      "learning_rate": 0.047175859275806455,
      "loss": 0.7048,
      "step": 327640
    },
    {
      "epoch": 528.48,
      "learning_rate": 0.04717263347258065,
      "loss": 0.6983,
      "step": 327660
    },
    {
      "epoch": 528.52,
      "learning_rate": 0.04716940766935484,
      "loss": 0.7001,
      "step": 327680
    },
    {
      "epoch": 528.55,
      "learning_rate": 0.04716618186612904,
      "loss": 0.6937,
      "step": 327700
    },
    {
      "epoch": 528.58,
      "learning_rate": 0.04716295606290323,
      "loss": 0.7079,
      "step": 327720
    },
    {
      "epoch": 528.61,
      "learning_rate": 0.04715973025967742,
      "loss": 0.6883,
      "step": 327740
    },
    {
      "epoch": 528.65,
      "learning_rate": 0.04715650445645162,
      "loss": 0.7213,
      "step": 327760
    },
    {
      "epoch": 528.68,
      "learning_rate": 0.047153278653225814,
      "loss": 0.7076,
      "step": 327780
    },
    {
      "epoch": 528.71,
      "learning_rate": 0.047150052850000006,
      "loss": 0.7063,
      "step": 327800
    },
    {
      "epoch": 528.74,
      "learning_rate": 0.047146827046774205,
      "loss": 0.7012,
      "step": 327820
    },
    {
      "epoch": 528.77,
      "learning_rate": 0.0471436012435484,
      "loss": 0.7102,
      "step": 327840
    },
    {
      "epoch": 528.81,
      "learning_rate": 0.04714037544032259,
      "loss": 0.7133,
      "step": 327860
    },
    {
      "epoch": 528.84,
      "learning_rate": 0.047137149637096774,
      "loss": 0.7279,
      "step": 327880
    },
    {
      "epoch": 528.87,
      "learning_rate": 0.047133923833870967,
      "loss": 0.7298,
      "step": 327900
    },
    {
      "epoch": 528.9,
      "learning_rate": 0.04713069803064516,
      "loss": 0.7085,
      "step": 327920
    },
    {
      "epoch": 528.94,
      "learning_rate": 0.04712747222741936,
      "loss": 0.7246,
      "step": 327940
    },
    {
      "epoch": 528.97,
      "learning_rate": 0.04712424642419355,
      "loss": 0.711,
      "step": 327960
    },
    {
      "epoch": 529.0,
      "learning_rate": 0.04712102062096774,
      "loss": 0.6964,
      "step": 327980
    },
    {
      "epoch": 529.0,
      "eval_accuracy": {
        "accuracy": 0.7624697525563968
      },
      "eval_loss": 1.076414704322815,
      "eval_runtime": 2.8003,
      "eval_samples_per_second": 4574.792,
      "eval_steps_per_second": 71.777,
      "step": 327980
    },
    {
      "epoch": 529.03,
      "learning_rate": 0.04711779481774194,
      "loss": 0.7279,
      "step": 328000
    },
    {
      "epoch": 529.06,
      "learning_rate": 0.04711456901451613,
      "loss": 0.7018,
      "step": 328020
    },
    {
      "epoch": 529.1,
      "learning_rate": 0.047111343211290325,
      "loss": 0.6985,
      "step": 328040
    },
    {
      "epoch": 529.13,
      "learning_rate": 0.047108117408064525,
      "loss": 0.7009,
      "step": 328060
    },
    {
      "epoch": 529.16,
      "learning_rate": 0.04710489160483872,
      "loss": 0.6973,
      "step": 328080
    },
    {
      "epoch": 529.19,
      "learning_rate": 0.04710166580161291,
      "loss": 0.6705,
      "step": 328100
    },
    {
      "epoch": 529.23,
      "learning_rate": 0.0470984399983871,
      "loss": 0.6986,
      "step": 328120
    },
    {
      "epoch": 529.26,
      "learning_rate": 0.0470952141951613,
      "loss": 0.7034,
      "step": 328140
    },
    {
      "epoch": 529.29,
      "learning_rate": 0.04709198839193549,
      "loss": 0.7021,
      "step": 328160
    },
    {
      "epoch": 529.32,
      "learning_rate": 0.047088762588709684,
      "loss": 0.7049,
      "step": 328180
    },
    {
      "epoch": 529.35,
      "learning_rate": 0.04708553678548387,
      "loss": 0.6883,
      "step": 328200
    },
    {
      "epoch": 529.39,
      "learning_rate": 0.04708231098225806,
      "loss": 0.7097,
      "step": 328220
    },
    {
      "epoch": 529.42,
      "learning_rate": 0.04707908517903226,
      "loss": 0.6994,
      "step": 328240
    },
    {
      "epoch": 529.45,
      "learning_rate": 0.04707585937580645,
      "loss": 0.6791,
      "step": 328260
    },
    {
      "epoch": 529.48,
      "learning_rate": 0.047072633572580645,
      "loss": 0.6929,
      "step": 328280
    },
    {
      "epoch": 529.52,
      "learning_rate": 0.047069407769354844,
      "loss": 0.6929,
      "step": 328300
    },
    {
      "epoch": 529.55,
      "learning_rate": 0.047066181966129036,
      "loss": 0.6812,
      "step": 328320
    },
    {
      "epoch": 529.58,
      "learning_rate": 0.04706295616290323,
      "loss": 0.7075,
      "step": 328340
    },
    {
      "epoch": 529.61,
      "learning_rate": 0.04705973035967743,
      "loss": 0.7146,
      "step": 328360
    },
    {
      "epoch": 529.65,
      "learning_rate": 0.04705650455645162,
      "loss": 0.698,
      "step": 328380
    },
    {
      "epoch": 529.68,
      "learning_rate": 0.04705327875322581,
      "loss": 0.7122,
      "step": 328400
    },
    {
      "epoch": 529.71,
      "learning_rate": 0.047050052950000004,
      "loss": 0.7096,
      "step": 328420
    },
    {
      "epoch": 529.74,
      "learning_rate": 0.0470468271467742,
      "loss": 0.6976,
      "step": 328440
    },
    {
      "epoch": 529.77,
      "learning_rate": 0.047043601343548395,
      "loss": 0.7147,
      "step": 328460
    },
    {
      "epoch": 529.81,
      "learning_rate": 0.04704037554032259,
      "loss": 0.7107,
      "step": 328480
    },
    {
      "epoch": 529.84,
      "learning_rate": 0.04703714973709677,
      "loss": 0.7037,
      "step": 328500
    },
    {
      "epoch": 529.87,
      "learning_rate": 0.047033923933870965,
      "loss": 0.7133,
      "step": 328520
    },
    {
      "epoch": 529.9,
      "learning_rate": 0.047030698130645164,
      "loss": 0.701,
      "step": 328540
    },
    {
      "epoch": 529.94,
      "learning_rate": 0.047027472327419356,
      "loss": 0.727,
      "step": 328560
    },
    {
      "epoch": 529.97,
      "learning_rate": 0.04702424652419355,
      "loss": 0.7074,
      "step": 328580
    },
    {
      "epoch": 530.0,
      "learning_rate": 0.047021182011129044,
      "loss": 0.6932,
      "step": 328600
    },
    {
      "epoch": 530.0,
      "eval_accuracy": {
        "accuracy": 0.7595816095542893
      },
      "eval_loss": 1.084415316581726,
      "eval_runtime": 3.0524,
      "eval_samples_per_second": 4197.089,
      "eval_steps_per_second": 65.851,
      "step": 328600
    },
    {
      "epoch": 530.03,
      "learning_rate": 0.047017956207903236,
      "loss": 0.6744,
      "step": 328620
    },
    {
      "epoch": 530.06,
      "learning_rate": 0.04701473040467742,
      "loss": 0.6777,
      "step": 328640
    },
    {
      "epoch": 530.1,
      "learning_rate": 0.04701150460145161,
      "loss": 0.6947,
      "step": 328660
    },
    {
      "epoch": 530.13,
      "learning_rate": 0.047008278798225805,
      "loss": 0.6968,
      "step": 328680
    },
    {
      "epoch": 530.16,
      "learning_rate": 0.047005052995,
      "loss": 0.6783,
      "step": 328700
    },
    {
      "epoch": 530.19,
      "learning_rate": 0.0470018271917742,
      "loss": 0.6889,
      "step": 328720
    },
    {
      "epoch": 530.23,
      "learning_rate": 0.04699860138854839,
      "loss": 0.6785,
      "step": 328740
    },
    {
      "epoch": 530.26,
      "learning_rate": 0.04699537558532258,
      "loss": 0.6962,
      "step": 328760
    },
    {
      "epoch": 530.29,
      "learning_rate": 0.04699214978209678,
      "loss": 0.697,
      "step": 328780
    },
    {
      "epoch": 530.32,
      "learning_rate": 0.04698892397887097,
      "loss": 0.6916,
      "step": 328800
    },
    {
      "epoch": 530.35,
      "learning_rate": 0.046985698175645164,
      "loss": 0.7002,
      "step": 328820
    },
    {
      "epoch": 530.39,
      "learning_rate": 0.046982472372419364,
      "loss": 0.7046,
      "step": 328840
    },
    {
      "epoch": 530.42,
      "learning_rate": 0.046979246569193556,
      "loss": 0.6954,
      "step": 328860
    },
    {
      "epoch": 530.45,
      "learning_rate": 0.04697602076596775,
      "loss": 0.7065,
      "step": 328880
    },
    {
      "epoch": 530.48,
      "learning_rate": 0.04697279496274195,
      "loss": 0.7017,
      "step": 328900
    },
    {
      "epoch": 530.52,
      "learning_rate": 0.04696956915951614,
      "loss": 0.7108,
      "step": 328920
    },
    {
      "epoch": 530.55,
      "learning_rate": 0.04696634335629033,
      "loss": 0.6977,
      "step": 328940
    },
    {
      "epoch": 530.58,
      "learning_rate": 0.046963117553064516,
      "loss": 0.6957,
      "step": 328960
    },
    {
      "epoch": 530.61,
      "learning_rate": 0.04695989174983871,
      "loss": 0.7247,
      "step": 328980
    },
    {
      "epoch": 530.65,
      "learning_rate": 0.0469566659466129,
      "loss": 0.7214,
      "step": 329000
    },
    {
      "epoch": 530.68,
      "learning_rate": 0.0469534401433871,
      "loss": 0.6911,
      "step": 329020
    },
    {
      "epoch": 530.71,
      "learning_rate": 0.04695021434016129,
      "loss": 0.7008,
      "step": 329040
    },
    {
      "epoch": 530.74,
      "learning_rate": 0.046946988536935484,
      "loss": 0.7249,
      "step": 329060
    },
    {
      "epoch": 530.77,
      "learning_rate": 0.04694376273370968,
      "loss": 0.7152,
      "step": 329080
    },
    {
      "epoch": 530.81,
      "learning_rate": 0.046940536930483875,
      "loss": 0.6863,
      "step": 329100
    },
    {
      "epoch": 530.84,
      "learning_rate": 0.04693731112725807,
      "loss": 0.7107,
      "step": 329120
    },
    {
      "epoch": 530.87,
      "learning_rate": 0.04693408532403227,
      "loss": 0.7028,
      "step": 329140
    },
    {
      "epoch": 530.9,
      "learning_rate": 0.04693085952080646,
      "loss": 0.7146,
      "step": 329160
    },
    {
      "epoch": 530.94,
      "learning_rate": 0.04692763371758065,
      "loss": 0.7135,
      "step": 329180
    },
    {
      "epoch": 530.97,
      "learning_rate": 0.04692440791435484,
      "loss": 0.7045,
      "step": 329200
    },
    {
      "epoch": 531.0,
      "learning_rate": 0.04692118211112904,
      "loss": 0.723,
      "step": 329220
    },
    {
      "epoch": 531.0,
      "eval_accuracy": {
        "accuracy": 0.7616111154476621
      },
      "eval_loss": 1.0815905332565308,
      "eval_runtime": 2.8354,
      "eval_samples_per_second": 4518.296,
      "eval_steps_per_second": 70.89,
      "step": 329220
    },
    {
      "epoch": 531.03,
      "learning_rate": 0.046917956307903234,
      "loss": 0.7378,
      "step": 329240
    },
    {
      "epoch": 531.06,
      "learning_rate": 0.04691473050467742,
      "loss": 0.7062,
      "step": 329260
    },
    {
      "epoch": 531.1,
      "learning_rate": 0.04691150470145161,
      "loss": 0.6945,
      "step": 329280
    },
    {
      "epoch": 531.13,
      "learning_rate": 0.046908278898225804,
      "loss": 0.7109,
      "step": 329300
    },
    {
      "epoch": 531.16,
      "learning_rate": 0.046905053095,
      "loss": 0.717,
      "step": 329320
    },
    {
      "epoch": 531.19,
      "learning_rate": 0.046901827291774195,
      "loss": 0.6896,
      "step": 329340
    },
    {
      "epoch": 531.23,
      "learning_rate": 0.04689860148854839,
      "loss": 0.7083,
      "step": 329360
    },
    {
      "epoch": 531.26,
      "learning_rate": 0.046895375685322586,
      "loss": 0.6854,
      "step": 329380
    },
    {
      "epoch": 531.29,
      "learning_rate": 0.04689214988209678,
      "loss": 0.6827,
      "step": 329400
    },
    {
      "epoch": 531.32,
      "learning_rate": 0.04688892407887097,
      "loss": 0.7161,
      "step": 329420
    },
    {
      "epoch": 531.35,
      "learning_rate": 0.04688569827564517,
      "loss": 0.7086,
      "step": 329440
    },
    {
      "epoch": 531.39,
      "learning_rate": 0.04688247247241936,
      "loss": 0.7113,
      "step": 329460
    },
    {
      "epoch": 531.42,
      "learning_rate": 0.046879246669193554,
      "loss": 0.7177,
      "step": 329480
    },
    {
      "epoch": 531.45,
      "learning_rate": 0.046876020865967746,
      "loss": 0.7257,
      "step": 329500
    },
    {
      "epoch": 531.48,
      "learning_rate": 0.046872795062741945,
      "loss": 0.6904,
      "step": 329520
    },
    {
      "epoch": 531.52,
      "learning_rate": 0.04686956925951614,
      "loss": 0.6883,
      "step": 329540
    },
    {
      "epoch": 531.55,
      "learning_rate": 0.04686634345629033,
      "loss": 0.7128,
      "step": 329560
    },
    {
      "epoch": 531.58,
      "learning_rate": 0.046863117653064515,
      "loss": 0.7044,
      "step": 329580
    },
    {
      "epoch": 531.61,
      "learning_rate": 0.04685989184983871,
      "loss": 0.6997,
      "step": 329600
    },
    {
      "epoch": 531.65,
      "learning_rate": 0.046856666046612906,
      "loss": 0.7094,
      "step": 329620
    },
    {
      "epoch": 531.68,
      "learning_rate": 0.0468534402433871,
      "loss": 0.701,
      "step": 329640
    },
    {
      "epoch": 531.71,
      "learning_rate": 0.04685021444016129,
      "loss": 0.7125,
      "step": 329660
    },
    {
      "epoch": 531.74,
      "learning_rate": 0.04684698863693549,
      "loss": 0.7197,
      "step": 329680
    },
    {
      "epoch": 531.77,
      "learning_rate": 0.04684376283370968,
      "loss": 0.7048,
      "step": 329700
    },
    {
      "epoch": 531.81,
      "learning_rate": 0.046840537030483874,
      "loss": 0.7071,
      "step": 329720
    },
    {
      "epoch": 531.84,
      "learning_rate": 0.046837311227258066,
      "loss": 0.7028,
      "step": 329740
    },
    {
      "epoch": 531.87,
      "learning_rate": 0.046834085424032265,
      "loss": 0.7243,
      "step": 329760
    },
    {
      "epoch": 531.9,
      "learning_rate": 0.04683085962080646,
      "loss": 0.7056,
      "step": 329780
    },
    {
      "epoch": 531.94,
      "learning_rate": 0.04682763381758065,
      "loss": 0.6917,
      "step": 329800
    },
    {
      "epoch": 531.97,
      "learning_rate": 0.04682440801435485,
      "loss": 0.7025,
      "step": 329820
    },
    {
      "epoch": 532.0,
      "learning_rate": 0.04682118221112904,
      "loss": 0.7282,
      "step": 329840
    },
    {
      "epoch": 532.0,
      "eval_accuracy": {
        "accuracy": 0.7588790882835064
      },
      "eval_loss": 1.0969680547714233,
      "eval_runtime": 3.002,
      "eval_samples_per_second": 4267.483,
      "eval_steps_per_second": 66.955,
      "step": 329840
    },
    {
      "epoch": 532.03,
      "learning_rate": 0.04681795640790323,
      "loss": 0.7217,
      "step": 329860
    },
    {
      "epoch": 532.06,
      "learning_rate": 0.04681473060467742,
      "loss": 0.6892,
      "step": 329880
    },
    {
      "epoch": 532.1,
      "learning_rate": 0.04681150480145161,
      "loss": 0.7154,
      "step": 329900
    },
    {
      "epoch": 532.13,
      "learning_rate": 0.04680827899822581,
      "loss": 0.6901,
      "step": 329920
    },
    {
      "epoch": 532.16,
      "learning_rate": 0.046805053195,
      "loss": 0.6889,
      "step": 329940
    },
    {
      "epoch": 532.19,
      "learning_rate": 0.046801827391774194,
      "loss": 0.6775,
      "step": 329960
    },
    {
      "epoch": 532.23,
      "learning_rate": 0.046798601588548386,
      "loss": 0.7051,
      "step": 329980
    },
    {
      "epoch": 532.26,
      "learning_rate": 0.046795375785322585,
      "loss": 0.7087,
      "step": 330000
    },
    {
      "epoch": 532.29,
      "learning_rate": 0.04679214998209678,
      "loss": 0.6889,
      "step": 330020
    },
    {
      "epoch": 532.32,
      "learning_rate": 0.04678892417887097,
      "loss": 0.6969,
      "step": 330040
    },
    {
      "epoch": 532.35,
      "learning_rate": 0.04678569837564517,
      "loss": 0.702,
      "step": 330060
    },
    {
      "epoch": 532.39,
      "learning_rate": 0.04678247257241936,
      "loss": 0.7133,
      "step": 330080
    },
    {
      "epoch": 532.42,
      "learning_rate": 0.04677924676919355,
      "loss": 0.7104,
      "step": 330100
    },
    {
      "epoch": 532.45,
      "learning_rate": 0.04677602096596775,
      "loss": 0.6886,
      "step": 330120
    },
    {
      "epoch": 532.48,
      "learning_rate": 0.046772795162741944,
      "loss": 0.6872,
      "step": 330140
    },
    {
      "epoch": 532.52,
      "learning_rate": 0.046769569359516136,
      "loss": 0.6992,
      "step": 330160
    },
    {
      "epoch": 532.55,
      "learning_rate": 0.046766343556290335,
      "loss": 0.7179,
      "step": 330180
    },
    {
      "epoch": 532.58,
      "learning_rate": 0.04676311775306451,
      "loss": 0.6941,
      "step": 330200
    },
    {
      "epoch": 532.61,
      "learning_rate": 0.04675989194983871,
      "loss": 0.6946,
      "step": 330220
    },
    {
      "epoch": 532.65,
      "learning_rate": 0.046756666146612905,
      "loss": 0.6965,
      "step": 330240
    },
    {
      "epoch": 532.68,
      "learning_rate": 0.0467534403433871,
      "loss": 0.7028,
      "step": 330260
    },
    {
      "epoch": 532.71,
      "learning_rate": 0.04675021454016129,
      "loss": 0.7135,
      "step": 330280
    },
    {
      "epoch": 532.74,
      "learning_rate": 0.04674698873693549,
      "loss": 0.7019,
      "step": 330300
    },
    {
      "epoch": 532.77,
      "learning_rate": 0.04674376293370968,
      "loss": 0.6987,
      "step": 330320
    },
    {
      "epoch": 532.81,
      "learning_rate": 0.04674053713048387,
      "loss": 0.7205,
      "step": 330340
    },
    {
      "epoch": 532.84,
      "learning_rate": 0.04673731132725807,
      "loss": 0.7075,
      "step": 330360
    },
    {
      "epoch": 532.87,
      "learning_rate": 0.046734085524032264,
      "loss": 0.7053,
      "step": 330380
    },
    {
      "epoch": 532.9,
      "learning_rate": 0.046730859720806456,
      "loss": 0.707,
      "step": 330400
    },
    {
      "epoch": 532.94,
      "learning_rate": 0.046727633917580655,
      "loss": 0.704,
      "step": 330420
    },
    {
      "epoch": 532.97,
      "learning_rate": 0.04672440811435485,
      "loss": 0.7087,
      "step": 330440
    },
    {
      "epoch": 533.0,
      "learning_rate": 0.04672118231112904,
      "loss": 0.7094,
      "step": 330460
    },
    {
      "epoch": 533.0,
      "eval_accuracy": {
        "accuracy": 0.7634845055030833
      },
      "eval_loss": 1.055088996887207,
      "eval_runtime": 3.1283,
      "eval_samples_per_second": 4095.153,
      "eval_steps_per_second": 64.251,
      "step": 330460
    },
    {
      "epoch": 533.03,
      "learning_rate": 0.04671795650790323,
      "loss": 0.7333,
      "step": 330480
    },
    {
      "epoch": 533.06,
      "learning_rate": 0.04671473070467743,
      "loss": 0.7078,
      "step": 330500
    },
    {
      "epoch": 533.1,
      "learning_rate": 0.04671150490145161,
      "loss": 0.7024,
      "step": 330520
    },
    {
      "epoch": 533.13,
      "learning_rate": 0.04670827909822581,
      "loss": 0.676,
      "step": 330540
    },
    {
      "epoch": 533.16,
      "learning_rate": 0.046705053295,
      "loss": 0.6945,
      "step": 330560
    },
    {
      "epoch": 533.19,
      "learning_rate": 0.04670182749177419,
      "loss": 0.6763,
      "step": 330580
    },
    {
      "epoch": 533.23,
      "learning_rate": 0.04669860168854839,
      "loss": 0.6854,
      "step": 330600
    },
    {
      "epoch": 533.26,
      "learning_rate": 0.04669537588532258,
      "loss": 0.6803,
      "step": 330620
    },
    {
      "epoch": 533.29,
      "learning_rate": 0.046692150082096776,
      "loss": 0.6922,
      "step": 330640
    },
    {
      "epoch": 533.32,
      "learning_rate": 0.046688924278870975,
      "loss": 0.6933,
      "step": 330660
    },
    {
      "epoch": 533.35,
      "learning_rate": 0.04668569847564517,
      "loss": 0.7052,
      "step": 330680
    },
    {
      "epoch": 533.39,
      "learning_rate": 0.04668247267241936,
      "loss": 0.6956,
      "step": 330700
    },
    {
      "epoch": 533.42,
      "learning_rate": 0.04667924686919356,
      "loss": 0.7011,
      "step": 330720
    },
    {
      "epoch": 533.45,
      "learning_rate": 0.04667602106596775,
      "loss": 0.7003,
      "step": 330740
    },
    {
      "epoch": 533.48,
      "learning_rate": 0.04667279526274194,
      "loss": 0.7117,
      "step": 330760
    },
    {
      "epoch": 533.52,
      "learning_rate": 0.046669569459516135,
      "loss": 0.7037,
      "step": 330780
    },
    {
      "epoch": 533.55,
      "learning_rate": 0.046666343656290334,
      "loss": 0.7118,
      "step": 330800
    },
    {
      "epoch": 533.58,
      "learning_rate": 0.04666311785306451,
      "loss": 0.6777,
      "step": 330820
    },
    {
      "epoch": 533.61,
      "learning_rate": 0.04665989204983871,
      "loss": 0.6793,
      "step": 330840
    },
    {
      "epoch": 533.65,
      "learning_rate": 0.0466566662466129,
      "loss": 0.6976,
      "step": 330860
    },
    {
      "epoch": 533.68,
      "learning_rate": 0.046653440443387095,
      "loss": 0.7125,
      "step": 330880
    },
    {
      "epoch": 533.71,
      "learning_rate": 0.046650214640161294,
      "loss": 0.7046,
      "step": 330900
    },
    {
      "epoch": 533.74,
      "learning_rate": 0.04664698883693549,
      "loss": 0.7101,
      "step": 330920
    },
    {
      "epoch": 533.77,
      "learning_rate": 0.04664376303370968,
      "loss": 0.6897,
      "step": 330940
    },
    {
      "epoch": 533.81,
      "learning_rate": 0.04664053723048388,
      "loss": 0.7222,
      "step": 330960
    },
    {
      "epoch": 533.84,
      "learning_rate": 0.04663731142725807,
      "loss": 0.7077,
      "step": 330980
    },
    {
      "epoch": 533.87,
      "learning_rate": 0.04663408562403226,
      "loss": 0.7024,
      "step": 331000
    },
    {
      "epoch": 533.9,
      "learning_rate": 0.046630859820806454,
      "loss": 0.709,
      "step": 331020
    },
    {
      "epoch": 533.94,
      "learning_rate": 0.04662763401758065,
      "loss": 0.7062,
      "step": 331040
    },
    {
      "epoch": 533.97,
      "learning_rate": 0.046624408214354846,
      "loss": 0.6891,
      "step": 331060
    },
    {
      "epoch": 534.0,
      "learning_rate": 0.04662134370129033,
      "loss": 0.6958,
      "step": 331080
    },
    {
      "epoch": 534.0,
      "eval_accuracy": {
        "accuracy": 0.7659823589103114
      },
      "eval_loss": 1.0405254364013672,
      "eval_runtime": 2.9043,
      "eval_samples_per_second": 4410.979,
      "eval_steps_per_second": 69.207,
      "step": 331080
    },
    {
      "epoch": 534.03,
      "learning_rate": 0.04661811789806452,
      "loss": 0.6761,
      "step": 331100
    },
    {
      "epoch": 534.06,
      "learning_rate": 0.04661489209483871,
      "loss": 0.6772,
      "step": 331120
    },
    {
      "epoch": 534.1,
      "learning_rate": 0.04661166629161291,
      "loss": 0.6872,
      "step": 331140
    },
    {
      "epoch": 534.13,
      "learning_rate": 0.0466084404883871,
      "loss": 0.6841,
      "step": 331160
    },
    {
      "epoch": 534.16,
      "learning_rate": 0.046605214685161295,
      "loss": 0.702,
      "step": 331180
    },
    {
      "epoch": 534.19,
      "learning_rate": 0.046601988881935494,
      "loss": 0.6859,
      "step": 331200
    },
    {
      "epoch": 534.23,
      "learning_rate": 0.046598763078709686,
      "loss": 0.6881,
      "step": 331220
    },
    {
      "epoch": 534.26,
      "learning_rate": 0.04659553727548388,
      "loss": 0.6871,
      "step": 331240
    },
    {
      "epoch": 534.29,
      "learning_rate": 0.04659231147225808,
      "loss": 0.7161,
      "step": 331260
    },
    {
      "epoch": 534.32,
      "learning_rate": 0.046589085669032256,
      "loss": 0.727,
      "step": 331280
    },
    {
      "epoch": 534.35,
      "learning_rate": 0.046585859865806455,
      "loss": 0.7127,
      "step": 331300
    },
    {
      "epoch": 534.39,
      "learning_rate": 0.04658263406258065,
      "loss": 0.7178,
      "step": 331320
    },
    {
      "epoch": 534.42,
      "learning_rate": 0.04657940825935484,
      "loss": 0.7243,
      "step": 331340
    },
    {
      "epoch": 534.45,
      "learning_rate": 0.04657618245612903,
      "loss": 0.7028,
      "step": 331360
    },
    {
      "epoch": 534.48,
      "learning_rate": 0.04657295665290323,
      "loss": 0.6975,
      "step": 331380
    },
    {
      "epoch": 534.52,
      "learning_rate": 0.04656973084967742,
      "loss": 0.6904,
      "step": 331400
    },
    {
      "epoch": 534.55,
      "learning_rate": 0.046566505046451614,
      "loss": 0.7028,
      "step": 331420
    },
    {
      "epoch": 534.58,
      "learning_rate": 0.046563279243225814,
      "loss": 0.7204,
      "step": 331440
    },
    {
      "epoch": 534.61,
      "learning_rate": 0.046560053440000006,
      "loss": 0.7195,
      "step": 331460
    },
    {
      "epoch": 534.65,
      "learning_rate": 0.0465568276367742,
      "loss": 0.7204,
      "step": 331480
    },
    {
      "epoch": 534.68,
      "learning_rate": 0.0465536018335484,
      "loss": 0.7177,
      "step": 331500
    },
    {
      "epoch": 534.71,
      "learning_rate": 0.04655037603032259,
      "loss": 0.7194,
      "step": 331520
    },
    {
      "epoch": 534.74,
      "learning_rate": 0.04654715022709678,
      "loss": 0.7084,
      "step": 331540
    },
    {
      "epoch": 534.77,
      "learning_rate": 0.04654392442387097,
      "loss": 0.6939,
      "step": 331560
    },
    {
      "epoch": 534.81,
      "learning_rate": 0.04654069862064516,
      "loss": 0.6889,
      "step": 331580
    },
    {
      "epoch": 534.84,
      "learning_rate": 0.04653747281741935,
      "loss": 0.7143,
      "step": 331600
    },
    {
      "epoch": 534.87,
      "learning_rate": 0.04653424701419355,
      "loss": 0.7034,
      "step": 331620
    },
    {
      "epoch": 534.9,
      "learning_rate": 0.04653102121096774,
      "loss": 0.7032,
      "step": 331640
    },
    {
      "epoch": 534.94,
      "learning_rate": 0.046527795407741934,
      "loss": 0.6925,
      "step": 331660
    },
    {
      "epoch": 534.97,
      "learning_rate": 0.04652456960451613,
      "loss": 0.703,
      "step": 331680
    },
    {
      "epoch": 535.0,
      "learning_rate": 0.046521343801290325,
      "loss": 0.7156,
      "step": 331700
    },
    {
      "epoch": 535.0,
      "eval_accuracy": {
        "accuracy": 0.7503707751151354
      },
      "eval_loss": 1.1103484630584717,
      "eval_runtime": 2.9252,
      "eval_samples_per_second": 4379.572,
      "eval_steps_per_second": 68.714,
      "step": 331700
    },
    {
      "epoch": 535.03,
      "learning_rate": 0.04651811799806452,
      "loss": 0.724,
      "step": 331720
    },
    {
      "epoch": 535.06,
      "learning_rate": 0.04651489219483872,
      "loss": 0.6974,
      "step": 331740
    },
    {
      "epoch": 535.1,
      "learning_rate": 0.04651166639161291,
      "loss": 0.6826,
      "step": 331760
    },
    {
      "epoch": 535.13,
      "learning_rate": 0.0465084405883871,
      "loss": 0.6994,
      "step": 331780
    },
    {
      "epoch": 535.16,
      "learning_rate": 0.0465052147851613,
      "loss": 0.6875,
      "step": 331800
    },
    {
      "epoch": 535.19,
      "learning_rate": 0.04650198898193549,
      "loss": 0.686,
      "step": 331820
    },
    {
      "epoch": 535.23,
      "learning_rate": 0.046498763178709684,
      "loss": 0.7177,
      "step": 331840
    },
    {
      "epoch": 535.26,
      "learning_rate": 0.04649553737548388,
      "loss": 0.6977,
      "step": 331860
    },
    {
      "epoch": 535.29,
      "learning_rate": 0.046492311572258076,
      "loss": 0.6899,
      "step": 331880
    },
    {
      "epoch": 535.32,
      "learning_rate": 0.046489085769032254,
      "loss": 0.6806,
      "step": 331900
    },
    {
      "epoch": 535.35,
      "learning_rate": 0.04648585996580645,
      "loss": 0.6851,
      "step": 331920
    },
    {
      "epoch": 535.39,
      "learning_rate": 0.046482634162580645,
      "loss": 0.7073,
      "step": 331940
    },
    {
      "epoch": 535.42,
      "learning_rate": 0.04647940835935484,
      "loss": 0.7033,
      "step": 331960
    },
    {
      "epoch": 535.45,
      "learning_rate": 0.046476182556129036,
      "loss": 0.7132,
      "step": 331980
    },
    {
      "epoch": 535.48,
      "learning_rate": 0.04647295675290323,
      "loss": 0.6844,
      "step": 332000
    },
    {
      "epoch": 535.52,
      "learning_rate": 0.04646973094967742,
      "loss": 0.6905,
      "step": 332020
    },
    {
      "epoch": 535.55,
      "learning_rate": 0.04646650514645162,
      "loss": 0.687,
      "step": 332040
    },
    {
      "epoch": 535.58,
      "learning_rate": 0.04646327934322581,
      "loss": 0.6907,
      "step": 332060
    },
    {
      "epoch": 535.61,
      "learning_rate": 0.046460053540000004,
      "loss": 0.6844,
      "step": 332080
    },
    {
      "epoch": 535.65,
      "learning_rate": 0.046456827736774196,
      "loss": 0.7145,
      "step": 332100
    },
    {
      "epoch": 535.68,
      "learning_rate": 0.046453601933548395,
      "loss": 0.7109,
      "step": 332120
    },
    {
      "epoch": 535.71,
      "learning_rate": 0.04645037613032259,
      "loss": 0.6876,
      "step": 332140
    },
    {
      "epoch": 535.74,
      "learning_rate": 0.04644715032709678,
      "loss": 0.719,
      "step": 332160
    },
    {
      "epoch": 535.77,
      "learning_rate": 0.04644392452387098,
      "loss": 0.7352,
      "step": 332180
    },
    {
      "epoch": 535.81,
      "learning_rate": 0.04644069872064516,
      "loss": 0.7005,
      "step": 332200
    },
    {
      "epoch": 535.84,
      "learning_rate": 0.046437472917419356,
      "loss": 0.7134,
      "step": 332220
    },
    {
      "epoch": 535.87,
      "learning_rate": 0.04643424711419355,
      "loss": 0.7162,
      "step": 332240
    },
    {
      "epoch": 535.9,
      "learning_rate": 0.04643102131096774,
      "loss": 0.7016,
      "step": 332260
    },
    {
      "epoch": 535.94,
      "learning_rate": 0.04642779550774194,
      "loss": 0.6913,
      "step": 332280
    },
    {
      "epoch": 535.97,
      "learning_rate": 0.04642456970451613,
      "loss": 0.7243,
      "step": 332300
    },
    {
      "epoch": 536.0,
      "learning_rate": 0.046421343901290324,
      "loss": 0.7308,
      "step": 332320
    },
    {
      "epoch": 536.0,
      "eval_accuracy": {
        "accuracy": 0.7563812348762782
      },
      "eval_loss": 1.0914206504821777,
      "eval_runtime": 2.8047,
      "eval_samples_per_second": 4567.682,
      "eval_steps_per_second": 71.665,
      "step": 332320
    },
    {
      "epoch": 536.03,
      "learning_rate": 0.04641811809806452,
      "loss": 0.7235,
      "step": 332340
    },
    {
      "epoch": 536.06,
      "learning_rate": 0.046414892294838715,
      "loss": 0.6724,
      "step": 332360
    },
    {
      "epoch": 536.1,
      "learning_rate": 0.04641166649161291,
      "loss": 0.6801,
      "step": 332380
    },
    {
      "epoch": 536.13,
      "learning_rate": 0.0464084406883871,
      "loss": 0.7013,
      "step": 332400
    },
    {
      "epoch": 536.16,
      "learning_rate": 0.0464052148851613,
      "loss": 0.6942,
      "step": 332420
    },
    {
      "epoch": 536.19,
      "learning_rate": 0.04640198908193549,
      "loss": 0.7018,
      "step": 332440
    },
    {
      "epoch": 536.23,
      "learning_rate": 0.04639876327870968,
      "loss": 0.6962,
      "step": 332460
    },
    {
      "epoch": 536.26,
      "learning_rate": 0.04639553747548388,
      "loss": 0.7011,
      "step": 332480
    },
    {
      "epoch": 536.29,
      "learning_rate": 0.046392311672258074,
      "loss": 0.6933,
      "step": 332500
    },
    {
      "epoch": 536.32,
      "learning_rate": 0.04638908586903226,
      "loss": 0.698,
      "step": 332520
    },
    {
      "epoch": 536.35,
      "learning_rate": 0.04638586006580645,
      "loss": 0.697,
      "step": 332540
    },
    {
      "epoch": 536.39,
      "learning_rate": 0.046382634262580644,
      "loss": 0.7227,
      "step": 332560
    },
    {
      "epoch": 536.42,
      "learning_rate": 0.04637940845935484,
      "loss": 0.7019,
      "step": 332580
    },
    {
      "epoch": 536.45,
      "learning_rate": 0.046376182656129035,
      "loss": 0.6871,
      "step": 332600
    },
    {
      "epoch": 536.48,
      "learning_rate": 0.04637295685290323,
      "loss": 0.6986,
      "step": 332620
    },
    {
      "epoch": 536.52,
      "learning_rate": 0.04636973104967742,
      "loss": 0.6925,
      "step": 332640
    },
    {
      "epoch": 536.55,
      "learning_rate": 0.04636650524645162,
      "loss": 0.6933,
      "step": 332660
    },
    {
      "epoch": 536.58,
      "learning_rate": 0.04636327944322581,
      "loss": 0.6844,
      "step": 332680
    },
    {
      "epoch": 536.61,
      "learning_rate": 0.04636005364,
      "loss": 0.7005,
      "step": 332700
    },
    {
      "epoch": 536.65,
      "learning_rate": 0.0463568278367742,
      "loss": 0.7133,
      "step": 332720
    },
    {
      "epoch": 536.68,
      "learning_rate": 0.046353602033548394,
      "loss": 0.7181,
      "step": 332740
    },
    {
      "epoch": 536.71,
      "learning_rate": 0.046350376230322586,
      "loss": 0.6962,
      "step": 332760
    },
    {
      "epoch": 536.74,
      "learning_rate": 0.046347150427096785,
      "loss": 0.7047,
      "step": 332780
    },
    {
      "epoch": 536.77,
      "learning_rate": 0.04634392462387098,
      "loss": 0.6763,
      "step": 332800
    },
    {
      "epoch": 536.81,
      "learning_rate": 0.04634069882064517,
      "loss": 0.7013,
      "step": 332820
    },
    {
      "epoch": 536.84,
      "learning_rate": 0.046337473017419355,
      "loss": 0.7044,
      "step": 332840
    },
    {
      "epoch": 536.87,
      "learning_rate": 0.04633424721419355,
      "loss": 0.7023,
      "step": 332860
    },
    {
      "epoch": 536.9,
      "learning_rate": 0.046331021410967746,
      "loss": 0.7011,
      "step": 332880
    },
    {
      "epoch": 536.94,
      "learning_rate": 0.04632779560774194,
      "loss": 0.7066,
      "step": 332900
    },
    {
      "epoch": 536.97,
      "learning_rate": 0.04632456980451613,
      "loss": 0.6918,
      "step": 332920
    },
    {
      "epoch": 537.0,
      "learning_rate": 0.04632134400129032,
      "loss": 0.7005,
      "step": 332940
    },
    {
      "epoch": 537.0,
      "eval_accuracy": {
        "accuracy": 0.7652017797205527
      },
      "eval_loss": 1.0669015645980835,
      "eval_runtime": 4.0022,
      "eval_samples_per_second": 3200.988,
      "eval_steps_per_second": 50.222,
      "step": 332940
    },
    {
      "epoch": 537.03,
      "learning_rate": 0.04631811819806452,
      "loss": 0.7061,
      "step": 332960
    },
    {
      "epoch": 537.06,
      "learning_rate": 0.046314892394838714,
      "loss": 0.6975,
      "step": 332980
    },
    {
      "epoch": 537.1,
      "learning_rate": 0.046311666591612906,
      "loss": 0.7041,
      "step": 333000
    },
    {
      "epoch": 537.13,
      "learning_rate": 0.046308440788387105,
      "loss": 0.6966,
      "step": 333020
    },
    {
      "epoch": 537.16,
      "learning_rate": 0.0463052149851613,
      "loss": 0.6848,
      "step": 333040
    },
    {
      "epoch": 537.19,
      "learning_rate": 0.04630198918193549,
      "loss": 0.6784,
      "step": 333060
    },
    {
      "epoch": 537.23,
      "learning_rate": 0.04629876337870969,
      "loss": 0.7093,
      "step": 333080
    },
    {
      "epoch": 537.26,
      "learning_rate": 0.04629553757548388,
      "loss": 0.7072,
      "step": 333100
    },
    {
      "epoch": 537.29,
      "learning_rate": 0.04629231177225807,
      "loss": 0.6978,
      "step": 333120
    },
    {
      "epoch": 537.32,
      "learning_rate": 0.04628908596903226,
      "loss": 0.7063,
      "step": 333140
    },
    {
      "epoch": 537.35,
      "learning_rate": 0.04628586016580645,
      "loss": 0.7076,
      "step": 333160
    },
    {
      "epoch": 537.39,
      "learning_rate": 0.04628263436258064,
      "loss": 0.6916,
      "step": 333180
    },
    {
      "epoch": 537.42,
      "learning_rate": 0.04627940855935484,
      "loss": 0.6978,
      "step": 333200
    },
    {
      "epoch": 537.45,
      "learning_rate": 0.04627618275612903,
      "loss": 0.6866,
      "step": 333220
    },
    {
      "epoch": 537.48,
      "learning_rate": 0.046272956952903226,
      "loss": 0.7085,
      "step": 333240
    },
    {
      "epoch": 537.52,
      "learning_rate": 0.046269731149677425,
      "loss": 0.7049,
      "step": 333260
    },
    {
      "epoch": 537.55,
      "learning_rate": 0.04626650534645162,
      "loss": 0.709,
      "step": 333280
    },
    {
      "epoch": 537.58,
      "learning_rate": 0.04626327954322581,
      "loss": 0.6948,
      "step": 333300
    },
    {
      "epoch": 537.61,
      "learning_rate": 0.04626005374000001,
      "loss": 0.699,
      "step": 333320
    },
    {
      "epoch": 537.65,
      "learning_rate": 0.0462568279367742,
      "loss": 0.6984,
      "step": 333340
    },
    {
      "epoch": 537.68,
      "learning_rate": 0.04625360213354839,
      "loss": 0.7023,
      "step": 333360
    },
    {
      "epoch": 537.71,
      "learning_rate": 0.046250376330322585,
      "loss": 0.7192,
      "step": 333380
    },
    {
      "epoch": 537.74,
      "learning_rate": 0.046247150527096784,
      "loss": 0.7178,
      "step": 333400
    },
    {
      "epoch": 537.77,
      "learning_rate": 0.046243924723870976,
      "loss": 0.7037,
      "step": 333420
    },
    {
      "epoch": 537.81,
      "learning_rate": 0.04624069892064517,
      "loss": 0.701,
      "step": 333440
    },
    {
      "epoch": 537.84,
      "learning_rate": 0.04623747311741935,
      "loss": 0.7033,
      "step": 333460
    },
    {
      "epoch": 537.87,
      "learning_rate": 0.046234247314193545,
      "loss": 0.7044,
      "step": 333480
    },
    {
      "epoch": 537.9,
      "learning_rate": 0.046231021510967744,
      "loss": 0.7149,
      "step": 333500
    },
    {
      "epoch": 537.94,
      "learning_rate": 0.04622779570774194,
      "loss": 0.7027,
      "step": 333520
    },
    {
      "epoch": 537.97,
      "learning_rate": 0.04622456990451613,
      "loss": 0.7127,
      "step": 333540
    },
    {
      "epoch": 538.0,
      "learning_rate": 0.046221505391451624,
      "loss": 0.7124,
      "step": 333560
    },
    {
      "epoch": 538.0,
      "eval_accuracy": {
        "accuracy": 0.7593474357973616
      },
      "eval_loss": 1.1018656492233276,
      "eval_runtime": 2.8773,
      "eval_samples_per_second": 4452.424,
      "eval_steps_per_second": 69.857,
      "step": 333560
    },
    {
      "epoch": 538.03,
      "learning_rate": 0.046218279588225816,
      "loss": 0.6807,
      "step": 333580
    },
    {
      "epoch": 538.06,
      "learning_rate": 0.046215053785,
      "loss": 0.6875,
      "step": 333600
    },
    {
      "epoch": 538.1,
      "learning_rate": 0.046211827981774194,
      "loss": 0.7075,
      "step": 333620
    },
    {
      "epoch": 538.13,
      "learning_rate": 0.046208602178548386,
      "loss": 0.6752,
      "step": 333640
    },
    {
      "epoch": 538.16,
      "learning_rate": 0.046205376375322585,
      "loss": 0.6756,
      "step": 333660
    },
    {
      "epoch": 538.19,
      "learning_rate": 0.04620215057209678,
      "loss": 0.7017,
      "step": 333680
    },
    {
      "epoch": 538.23,
      "learning_rate": 0.04619892476887097,
      "loss": 0.7089,
      "step": 333700
    },
    {
      "epoch": 538.26,
      "learning_rate": 0.04619569896564516,
      "loss": 0.7025,
      "step": 333720
    },
    {
      "epoch": 538.29,
      "learning_rate": 0.04619247316241936,
      "loss": 0.7048,
      "step": 333740
    },
    {
      "epoch": 538.32,
      "learning_rate": 0.04618924735919355,
      "loss": 0.7035,
      "step": 333760
    },
    {
      "epoch": 538.35,
      "learning_rate": 0.046186021555967745,
      "loss": 0.7117,
      "step": 333780
    },
    {
      "epoch": 538.39,
      "learning_rate": 0.046182795752741944,
      "loss": 0.7026,
      "step": 333800
    },
    {
      "epoch": 538.42,
      "learning_rate": 0.046179569949516136,
      "loss": 0.6927,
      "step": 333820
    },
    {
      "epoch": 538.45,
      "learning_rate": 0.04617634414629033,
      "loss": 0.7048,
      "step": 333840
    },
    {
      "epoch": 538.48,
      "learning_rate": 0.04617311834306453,
      "loss": 0.6968,
      "step": 333860
    },
    {
      "epoch": 538.52,
      "learning_rate": 0.04616989253983872,
      "loss": 0.6902,
      "step": 333880
    },
    {
      "epoch": 538.55,
      "learning_rate": 0.046166666736612905,
      "loss": 0.6776,
      "step": 333900
    },
    {
      "epoch": 538.58,
      "learning_rate": 0.0461634409333871,
      "loss": 0.6818,
      "step": 333920
    },
    {
      "epoch": 538.61,
      "learning_rate": 0.04616021513016129,
      "loss": 0.6859,
      "step": 333940
    },
    {
      "epoch": 538.65,
      "learning_rate": 0.04615698932693549,
      "loss": 0.7013,
      "step": 333960
    },
    {
      "epoch": 538.68,
      "learning_rate": 0.04615376352370968,
      "loss": 0.7014,
      "step": 333980
    },
    {
      "epoch": 538.71,
      "learning_rate": 0.04615053772048387,
      "loss": 0.706,
      "step": 334000
    },
    {
      "epoch": 538.74,
      "learning_rate": 0.046147311917258065,
      "loss": 0.7126,
      "step": 334020
    },
    {
      "epoch": 538.77,
      "learning_rate": 0.046144086114032264,
      "loss": 0.722,
      "step": 334040
    },
    {
      "epoch": 538.81,
      "learning_rate": 0.046140860310806456,
      "loss": 0.7279,
      "step": 334060
    },
    {
      "epoch": 538.84,
      "learning_rate": 0.04613763450758065,
      "loss": 0.7002,
      "step": 334080
    },
    {
      "epoch": 538.87,
      "learning_rate": 0.04613440870435485,
      "loss": 0.7175,
      "step": 334100
    },
    {
      "epoch": 538.9,
      "learning_rate": 0.04613118290112904,
      "loss": 0.6827,
      "step": 334120
    },
    {
      "epoch": 538.94,
      "learning_rate": 0.04612795709790323,
      "loss": 0.7199,
      "step": 334140
    },
    {
      "epoch": 538.97,
      "learning_rate": 0.04612473129467743,
      "loss": 0.7138,
      "step": 334160
    },
    {
      "epoch": 539.0,
      "learning_rate": 0.04612150549145162,
      "loss": 0.7143,
      "step": 334180
    },
    {
      "epoch": 539.0,
      "eval_accuracy": {
        "accuracy": 0.7613769416907346
      },
      "eval_loss": 1.0666534900665283,
      "eval_runtime": 2.8288,
      "eval_samples_per_second": 4528.796,
      "eval_steps_per_second": 71.055,
      "step": 334180
    },
    {
      "epoch": 539.03,
      "learning_rate": 0.046118279688225815,
      "loss": 0.7036,
      "step": 334200
    },
    {
      "epoch": 539.06,
      "learning_rate": 0.046115053885,
      "loss": 0.6884,
      "step": 334220
    },
    {
      "epoch": 539.1,
      "learning_rate": 0.04611182808177419,
      "loss": 0.6883,
      "step": 334240
    },
    {
      "epoch": 539.13,
      "learning_rate": 0.046108602278548384,
      "loss": 0.7062,
      "step": 334260
    },
    {
      "epoch": 539.16,
      "learning_rate": 0.04610537647532258,
      "loss": 0.6916,
      "step": 334280
    },
    {
      "epoch": 539.19,
      "learning_rate": 0.046102150672096776,
      "loss": 0.6898,
      "step": 334300
    },
    {
      "epoch": 539.23,
      "learning_rate": 0.04609892486887097,
      "loss": 0.6976,
      "step": 334320
    },
    {
      "epoch": 539.26,
      "learning_rate": 0.04609569906564517,
      "loss": 0.676,
      "step": 334340
    },
    {
      "epoch": 539.29,
      "learning_rate": 0.04609247326241936,
      "loss": 0.6672,
      "step": 334360
    },
    {
      "epoch": 539.32,
      "learning_rate": 0.04608924745919355,
      "loss": 0.6837,
      "step": 334380
    },
    {
      "epoch": 539.35,
      "learning_rate": 0.04608602165596775,
      "loss": 0.6773,
      "step": 334400
    },
    {
      "epoch": 539.39,
      "learning_rate": 0.04608279585274194,
      "loss": 0.7116,
      "step": 334420
    },
    {
      "epoch": 539.42,
      "learning_rate": 0.046079570049516135,
      "loss": 0.714,
      "step": 334440
    },
    {
      "epoch": 539.45,
      "learning_rate": 0.046076344246290334,
      "loss": 0.6993,
      "step": 334460
    },
    {
      "epoch": 539.48,
      "learning_rate": 0.046073118443064526,
      "loss": 0.7179,
      "step": 334480
    },
    {
      "epoch": 539.52,
      "learning_rate": 0.04606989263983872,
      "loss": 0.681,
      "step": 334500
    },
    {
      "epoch": 539.55,
      "learning_rate": 0.0460666668366129,
      "loss": 0.6946,
      "step": 334520
    },
    {
      "epoch": 539.58,
      "learning_rate": 0.046063441033387095,
      "loss": 0.694,
      "step": 334540
    },
    {
      "epoch": 539.61,
      "learning_rate": 0.04606021523016129,
      "loss": 0.7083,
      "step": 334560
    },
    {
      "epoch": 539.65,
      "learning_rate": 0.04605698942693549,
      "loss": 0.7013,
      "step": 334580
    },
    {
      "epoch": 539.68,
      "learning_rate": 0.04605376362370968,
      "loss": 0.6773,
      "step": 334600
    },
    {
      "epoch": 539.71,
      "learning_rate": 0.04605053782048387,
      "loss": 0.7021,
      "step": 334620
    },
    {
      "epoch": 539.74,
      "learning_rate": 0.04604731201725807,
      "loss": 0.7007,
      "step": 334640
    },
    {
      "epoch": 539.77,
      "learning_rate": 0.04604408621403226,
      "loss": 0.7065,
      "step": 334660
    },
    {
      "epoch": 539.81,
      "learning_rate": 0.046040860410806454,
      "loss": 0.7009,
      "step": 334680
    },
    {
      "epoch": 539.84,
      "learning_rate": 0.04603763460758065,
      "loss": 0.6995,
      "step": 334700
    },
    {
      "epoch": 539.87,
      "learning_rate": 0.046034408804354846,
      "loss": 0.6816,
      "step": 334720
    },
    {
      "epoch": 539.9,
      "learning_rate": 0.04603118300112904,
      "loss": 0.6983,
      "step": 334740
    },
    {
      "epoch": 539.94,
      "learning_rate": 0.04602795719790323,
      "loss": 0.6931,
      "step": 334760
    },
    {
      "epoch": 539.97,
      "learning_rate": 0.04602473139467743,
      "loss": 0.6841,
      "step": 334780
    },
    {
      "epoch": 540.0,
      "learning_rate": 0.04602150559145162,
      "loss": 0.6966,
      "step": 334800
    },
    {
      "epoch": 540.0,
      "eval_accuracy": {
        "accuracy": 0.7648114901256733
      },
      "eval_loss": 1.0451395511627197,
      "eval_runtime": 2.9331,
      "eval_samples_per_second": 4367.73,
      "eval_steps_per_second": 68.528,
      "step": 334800
    },
    {
      "epoch": 540.03,
      "learning_rate": 0.04601827978822581,
      "loss": 0.7015,
      "step": 334820
    },
    {
      "epoch": 540.06,
      "learning_rate": 0.046015053985,
      "loss": 0.6803,
      "step": 334840
    },
    {
      "epoch": 540.1,
      "learning_rate": 0.04601182818177419,
      "loss": 0.6832,
      "step": 334860
    },
    {
      "epoch": 540.13,
      "learning_rate": 0.04600860237854839,
      "loss": 0.6734,
      "step": 334880
    },
    {
      "epoch": 540.16,
      "learning_rate": 0.04600537657532258,
      "loss": 0.673,
      "step": 334900
    },
    {
      "epoch": 540.19,
      "learning_rate": 0.046002150772096774,
      "loss": 0.6898,
      "step": 334920
    },
    {
      "epoch": 540.23,
      "learning_rate": 0.04599892496887097,
      "loss": 0.7065,
      "step": 334940
    },
    {
      "epoch": 540.26,
      "learning_rate": 0.045995699165645165,
      "loss": 0.7061,
      "step": 334960
    },
    {
      "epoch": 540.29,
      "learning_rate": 0.04599247336241936,
      "loss": 0.7137,
      "step": 334980
    },
    {
      "epoch": 540.32,
      "learning_rate": 0.04598924755919355,
      "loss": 0.711,
      "step": 335000
    },
    {
      "epoch": 540.35,
      "learning_rate": 0.04598602175596775,
      "loss": 0.696,
      "step": 335020
    },
    {
      "epoch": 540.39,
      "learning_rate": 0.04598279595274194,
      "loss": 0.7015,
      "step": 335040
    },
    {
      "epoch": 540.42,
      "learning_rate": 0.04597957014951613,
      "loss": 0.7153,
      "step": 335060
    },
    {
      "epoch": 540.45,
      "learning_rate": 0.04597634434629033,
      "loss": 0.6929,
      "step": 335080
    },
    {
      "epoch": 540.48,
      "learning_rate": 0.045973118543064524,
      "loss": 0.697,
      "step": 335100
    },
    {
      "epoch": 540.52,
      "learning_rate": 0.045969892739838716,
      "loss": 0.682,
      "step": 335120
    },
    {
      "epoch": 540.55,
      "learning_rate": 0.045966666936612915,
      "loss": 0.6897,
      "step": 335140
    },
    {
      "epoch": 540.58,
      "learning_rate": 0.045963441133387094,
      "loss": 0.6977,
      "step": 335160
    },
    {
      "epoch": 540.61,
      "learning_rate": 0.04596021533016129,
      "loss": 0.6939,
      "step": 335180
    },
    {
      "epoch": 540.65,
      "learning_rate": 0.045956989526935485,
      "loss": 0.701,
      "step": 335200
    },
    {
      "epoch": 540.68,
      "learning_rate": 0.04595376372370968,
      "loss": 0.6943,
      "step": 335220
    },
    {
      "epoch": 540.71,
      "learning_rate": 0.045950537920483876,
      "loss": 0.6984,
      "step": 335240
    },
    {
      "epoch": 540.74,
      "learning_rate": 0.04594731211725807,
      "loss": 0.7135,
      "step": 335260
    },
    {
      "epoch": 540.77,
      "learning_rate": 0.04594408631403226,
      "loss": 0.689,
      "step": 335280
    },
    {
      "epoch": 540.81,
      "learning_rate": 0.04594086051080645,
      "loss": 0.701,
      "step": 335300
    },
    {
      "epoch": 540.84,
      "learning_rate": 0.04593763470758065,
      "loss": 0.7087,
      "step": 335320
    },
    {
      "epoch": 540.87,
      "learning_rate": 0.045934408904354844,
      "loss": 0.6995,
      "step": 335340
    },
    {
      "epoch": 540.9,
      "learning_rate": 0.045931183101129036,
      "loss": 0.7049,
      "step": 335360
    },
    {
      "epoch": 540.94,
      "learning_rate": 0.045927957297903235,
      "loss": 0.6941,
      "step": 335380
    },
    {
      "epoch": 540.97,
      "learning_rate": 0.04592473149467743,
      "loss": 0.7207,
      "step": 335400
    },
    {
      "epoch": 541.0,
      "learning_rate": 0.04592150569145162,
      "loss": 0.7256,
      "step": 335420
    },
    {
      "epoch": 541.0,
      "eval_accuracy": {
        "accuracy": 0.7621575208804934
      },
      "eval_loss": 1.0627137422561646,
      "eval_runtime": 2.9795,
      "eval_samples_per_second": 4299.724,
      "eval_steps_per_second": 67.461,
      "step": 335420
    },
    {
      "epoch": 541.03,
      "learning_rate": 0.04591827988822582,
      "loss": 0.7361,
      "step": 335440
    },
    {
      "epoch": 541.06,
      "learning_rate": 0.045915054085,
      "loss": 0.7042,
      "step": 335460
    },
    {
      "epoch": 541.1,
      "learning_rate": 0.045911828281774196,
      "loss": 0.6887,
      "step": 335480
    },
    {
      "epoch": 541.13,
      "learning_rate": 0.04590860247854839,
      "loss": 0.7001,
      "step": 335500
    },
    {
      "epoch": 541.16,
      "learning_rate": 0.04590537667532258,
      "loss": 0.7072,
      "step": 335520
    },
    {
      "epoch": 541.19,
      "learning_rate": 0.04590215087209677,
      "loss": 0.6888,
      "step": 335540
    },
    {
      "epoch": 541.23,
      "learning_rate": 0.04589892506887097,
      "loss": 0.6733,
      "step": 335560
    },
    {
      "epoch": 541.26,
      "learning_rate": 0.045895699265645164,
      "loss": 0.6999,
      "step": 335580
    },
    {
      "epoch": 541.29,
      "learning_rate": 0.045892473462419356,
      "loss": 0.7018,
      "step": 335600
    },
    {
      "epoch": 541.32,
      "learning_rate": 0.045889247659193555,
      "loss": 0.7006,
      "step": 335620
    },
    {
      "epoch": 541.35,
      "learning_rate": 0.04588602185596775,
      "loss": 0.6915,
      "step": 335640
    },
    {
      "epoch": 541.39,
      "learning_rate": 0.04588279605274194,
      "loss": 0.6942,
      "step": 335660
    },
    {
      "epoch": 541.42,
      "learning_rate": 0.04587957024951614,
      "loss": 0.6947,
      "step": 335680
    },
    {
      "epoch": 541.45,
      "learning_rate": 0.04587634444629033,
      "loss": 0.6834,
      "step": 335700
    },
    {
      "epoch": 541.48,
      "learning_rate": 0.04587311864306452,
      "loss": 0.685,
      "step": 335720
    },
    {
      "epoch": 541.52,
      "learning_rate": 0.04586989283983872,
      "loss": 0.678,
      "step": 335740
    },
    {
      "epoch": 541.55,
      "learning_rate": 0.045866667036612914,
      "loss": 0.6784,
      "step": 335760
    },
    {
      "epoch": 541.58,
      "learning_rate": 0.0458634412333871,
      "loss": 0.7048,
      "step": 335780
    },
    {
      "epoch": 541.61,
      "learning_rate": 0.04586021543016129,
      "loss": 0.7096,
      "step": 335800
    },
    {
      "epoch": 541.65,
      "learning_rate": 0.045856989626935483,
      "loss": 0.6757,
      "step": 335820
    },
    {
      "epoch": 541.68,
      "learning_rate": 0.045853763823709676,
      "loss": 0.701,
      "step": 335840
    },
    {
      "epoch": 541.71,
      "learning_rate": 0.045850538020483875,
      "loss": 0.7015,
      "step": 335860
    },
    {
      "epoch": 541.74,
      "learning_rate": 0.04584731221725807,
      "loss": 0.709,
      "step": 335880
    },
    {
      "epoch": 541.77,
      "learning_rate": 0.04584408641403226,
      "loss": 0.6959,
      "step": 335900
    },
    {
      "epoch": 541.81,
      "learning_rate": 0.04584086061080646,
      "loss": 0.7036,
      "step": 335920
    },
    {
      "epoch": 541.84,
      "learning_rate": 0.04583763480758065,
      "loss": 0.6989,
      "step": 335940
    },
    {
      "epoch": 541.87,
      "learning_rate": 0.04583440900435484,
      "loss": 0.7023,
      "step": 335960
    },
    {
      "epoch": 541.9,
      "learning_rate": 0.04583118320112904,
      "loss": 0.7174,
      "step": 335980
    },
    {
      "epoch": 541.94,
      "learning_rate": 0.045827957397903234,
      "loss": 0.7249,
      "step": 336000
    },
    {
      "epoch": 541.97,
      "learning_rate": 0.045824731594677426,
      "loss": 0.6927,
      "step": 336020
    },
    {
      "epoch": 542.0,
      "learning_rate": 0.04582166708161291,
      "loss": 0.7101,
      "step": 336040
    },
    {
      "epoch": 542.0,
      "eval_accuracy": {
        "accuracy": 0.760440246663024
      },
      "eval_loss": 1.0697914361953735,
      "eval_runtime": 4.4355,
      "eval_samples_per_second": 2888.261,
      "eval_steps_per_second": 45.316,
      "step": 336040
    },
    {
      "epoch": 542.03,
      "learning_rate": 0.0458184412783871,
      "loss": 0.6651,
      "step": 336060
    },
    {
      "epoch": 542.06,
      "learning_rate": 0.04581521547516129,
      "loss": 0.679,
      "step": 336080
    },
    {
      "epoch": 542.1,
      "learning_rate": 0.04581198967193549,
      "loss": 0.6922,
      "step": 336100
    },
    {
      "epoch": 542.13,
      "learning_rate": 0.04580876386870968,
      "loss": 0.6916,
      "step": 336120
    },
    {
      "epoch": 542.16,
      "learning_rate": 0.045805538065483875,
      "loss": 0.6895,
      "step": 336140
    },
    {
      "epoch": 542.19,
      "learning_rate": 0.045802312262258074,
      "loss": 0.6915,
      "step": 336160
    },
    {
      "epoch": 542.23,
      "learning_rate": 0.045799086459032266,
      "loss": 0.6966,
      "step": 336180
    },
    {
      "epoch": 542.26,
      "learning_rate": 0.04579586065580646,
      "loss": 0.7147,
      "step": 336200
    },
    {
      "epoch": 542.29,
      "learning_rate": 0.045792634852580644,
      "loss": 0.6945,
      "step": 336220
    },
    {
      "epoch": 542.32,
      "learning_rate": 0.045789409049354836,
      "loss": 0.6909,
      "step": 336240
    },
    {
      "epoch": 542.35,
      "learning_rate": 0.045786183246129035,
      "loss": 0.6956,
      "step": 336260
    },
    {
      "epoch": 542.39,
      "learning_rate": 0.04578295744290323,
      "loss": 0.6697,
      "step": 336280
    },
    {
      "epoch": 542.42,
      "learning_rate": 0.04577973163967742,
      "loss": 0.692,
      "step": 336300
    },
    {
      "epoch": 542.45,
      "learning_rate": 0.04577650583645162,
      "loss": 0.7149,
      "step": 336320
    },
    {
      "epoch": 542.48,
      "learning_rate": 0.04577328003322581,
      "loss": 0.6919,
      "step": 336340
    },
    {
      "epoch": 542.52,
      "learning_rate": 0.04577005423,
      "loss": 0.7025,
      "step": 336360
    },
    {
      "epoch": 542.55,
      "learning_rate": 0.045766828426774195,
      "loss": 0.6901,
      "step": 336380
    },
    {
      "epoch": 542.58,
      "learning_rate": 0.045763602623548394,
      "loss": 0.6881,
      "step": 336400
    },
    {
      "epoch": 542.61,
      "learning_rate": 0.045760376820322586,
      "loss": 0.7074,
      "step": 336420
    },
    {
      "epoch": 542.65,
      "learning_rate": 0.04575715101709678,
      "loss": 0.6921,
      "step": 336440
    },
    {
      "epoch": 542.68,
      "learning_rate": 0.04575392521387098,
      "loss": 0.691,
      "step": 336460
    },
    {
      "epoch": 542.71,
      "learning_rate": 0.04575069941064517,
      "loss": 0.6895,
      "step": 336480
    },
    {
      "epoch": 542.74,
      "learning_rate": 0.04574747360741936,
      "loss": 0.691,
      "step": 336500
    },
    {
      "epoch": 542.77,
      "learning_rate": 0.04574424780419356,
      "loss": 0.7029,
      "step": 336520
    },
    {
      "epoch": 542.81,
      "learning_rate": 0.04574102200096774,
      "loss": 0.712,
      "step": 336540
    },
    {
      "epoch": 542.84,
      "learning_rate": 0.04573779619774194,
      "loss": 0.7008,
      "step": 336560
    },
    {
      "epoch": 542.87,
      "learning_rate": 0.04573457039451613,
      "loss": 0.6769,
      "step": 336580
    },
    {
      "epoch": 542.9,
      "learning_rate": 0.04573134459129032,
      "loss": 0.6871,
      "step": 336600
    },
    {
      "epoch": 542.94,
      "learning_rate": 0.045728118788064515,
      "loss": 0.7002,
      "step": 336620
    },
    {
      "epoch": 542.97,
      "learning_rate": 0.045724892984838714,
      "loss": 0.7155,
      "step": 336640
    },
    {
      "epoch": 543.0,
      "learning_rate": 0.045721667181612906,
      "loss": 0.7009,
      "step": 336660
    },
    {
      "epoch": 543.0,
      "eval_accuracy": {
        "accuracy": 0.7627819842323004
      },
      "eval_loss": 1.0631486177444458,
      "eval_runtime": 2.9612,
      "eval_samples_per_second": 4326.294,
      "eval_steps_per_second": 67.878,
      "step": 336660
    },
    {
      "epoch": 543.03,
      "learning_rate": 0.0457184413783871,
      "loss": 0.7088,
      "step": 336680
    },
    {
      "epoch": 543.06,
      "learning_rate": 0.0457152155751613,
      "loss": 0.6952,
      "step": 336700
    },
    {
      "epoch": 543.1,
      "learning_rate": 0.04571198977193549,
      "loss": 0.6654,
      "step": 336720
    },
    {
      "epoch": 543.13,
      "learning_rate": 0.04570876396870968,
      "loss": 0.6993,
      "step": 336740
    },
    {
      "epoch": 543.16,
      "learning_rate": 0.04570553816548388,
      "loss": 0.6901,
      "step": 336760
    },
    {
      "epoch": 543.19,
      "learning_rate": 0.04570231236225807,
      "loss": 0.6887,
      "step": 336780
    },
    {
      "epoch": 543.23,
      "learning_rate": 0.045699086559032265,
      "loss": 0.6972,
      "step": 336800
    },
    {
      "epoch": 543.26,
      "learning_rate": 0.045695860755806464,
      "loss": 0.6928,
      "step": 336820
    },
    {
      "epoch": 543.29,
      "learning_rate": 0.04569263495258064,
      "loss": 0.6996,
      "step": 336840
    },
    {
      "epoch": 543.32,
      "learning_rate": 0.04568940914935484,
      "loss": 0.7163,
      "step": 336860
    },
    {
      "epoch": 543.35,
      "learning_rate": 0.04568618334612903,
      "loss": 0.6797,
      "step": 336880
    },
    {
      "epoch": 543.39,
      "learning_rate": 0.045682957542903226,
      "loss": 0.6892,
      "step": 336900
    },
    {
      "epoch": 543.42,
      "learning_rate": 0.04567973173967742,
      "loss": 0.7043,
      "step": 336920
    },
    {
      "epoch": 543.45,
      "learning_rate": 0.04567650593645162,
      "loss": 0.6848,
      "step": 336940
    },
    {
      "epoch": 543.48,
      "learning_rate": 0.04567328013322581,
      "loss": 0.6861,
      "step": 336960
    },
    {
      "epoch": 543.52,
      "learning_rate": 0.04567005433,
      "loss": 0.7049,
      "step": 336980
    },
    {
      "epoch": 543.55,
      "learning_rate": 0.0456668285267742,
      "loss": 0.706,
      "step": 337000
    },
    {
      "epoch": 543.58,
      "learning_rate": 0.04566360272354839,
      "loss": 0.6974,
      "step": 337020
    },
    {
      "epoch": 543.61,
      "learning_rate": 0.045660376920322585,
      "loss": 0.6865,
      "step": 337040
    },
    {
      "epoch": 543.65,
      "learning_rate": 0.045657151117096784,
      "loss": 0.7096,
      "step": 337060
    },
    {
      "epoch": 543.68,
      "learning_rate": 0.045653925313870976,
      "loss": 0.7163,
      "step": 337080
    },
    {
      "epoch": 543.71,
      "learning_rate": 0.04565069951064517,
      "loss": 0.685,
      "step": 337100
    },
    {
      "epoch": 543.74,
      "learning_rate": 0.04564747370741936,
      "loss": 0.7062,
      "step": 337120
    },
    {
      "epoch": 543.77,
      "learning_rate": 0.04564424790419356,
      "loss": 0.7019,
      "step": 337140
    },
    {
      "epoch": 543.81,
      "learning_rate": 0.04564102210096774,
      "loss": 0.7099,
      "step": 337160
    },
    {
      "epoch": 543.84,
      "learning_rate": 0.04563779629774194,
      "loss": 0.6986,
      "step": 337180
    },
    {
      "epoch": 543.87,
      "learning_rate": 0.04563457049451613,
      "loss": 0.713,
      "step": 337200
    },
    {
      "epoch": 543.9,
      "learning_rate": 0.04563134469129032,
      "loss": 0.6964,
      "step": 337220
    },
    {
      "epoch": 543.94,
      "learning_rate": 0.04562811888806452,
      "loss": 0.7216,
      "step": 337240
    },
    {
      "epoch": 543.97,
      "learning_rate": 0.04562489308483871,
      "loss": 0.706,
      "step": 337260
    },
    {
      "epoch": 544.0,
      "learning_rate": 0.045621667281612904,
      "loss": 0.7256,
      "step": 337280
    },
    {
      "epoch": 544.0,
      "eval_accuracy": {
        "accuracy": 0.7634064475841074
      },
      "eval_loss": 1.0660862922668457,
      "eval_runtime": 2.9155,
      "eval_samples_per_second": 4394.052,
      "eval_steps_per_second": 68.941,
      "step": 337280
    },
    {
      "epoch": 544.03,
      "learning_rate": 0.0456184414783871,
      "loss": 0.7232,
      "step": 337300
    },
    {
      "epoch": 544.06,
      "learning_rate": 0.045615215675161296,
      "loss": 0.6919,
      "step": 337320
    },
    {
      "epoch": 544.1,
      "learning_rate": 0.04561198987193549,
      "loss": 0.6751,
      "step": 337340
    },
    {
      "epoch": 544.13,
      "learning_rate": 0.04560876406870969,
      "loss": 0.6946,
      "step": 337360
    },
    {
      "epoch": 544.16,
      "learning_rate": 0.04560553826548388,
      "loss": 0.6904,
      "step": 337380
    },
    {
      "epoch": 544.19,
      "learning_rate": 0.04560231246225807,
      "loss": 0.6977,
      "step": 337400
    },
    {
      "epoch": 544.23,
      "learning_rate": 0.04559908665903226,
      "loss": 0.686,
      "step": 337420
    },
    {
      "epoch": 544.26,
      "learning_rate": 0.04559586085580646,
      "loss": 0.6894,
      "step": 337440
    },
    {
      "epoch": 544.29,
      "learning_rate": 0.045592635052580655,
      "loss": 0.6842,
      "step": 337460
    },
    {
      "epoch": 544.32,
      "learning_rate": 0.04558940924935484,
      "loss": 0.6671,
      "step": 337480
    },
    {
      "epoch": 544.35,
      "learning_rate": 0.04558618344612903,
      "loss": 0.6947,
      "step": 337500
    },
    {
      "epoch": 544.39,
      "learning_rate": 0.045582957642903224,
      "loss": 0.6952,
      "step": 337520
    },
    {
      "epoch": 544.42,
      "learning_rate": 0.04557973183967742,
      "loss": 0.672,
      "step": 337540
    },
    {
      "epoch": 544.45,
      "learning_rate": 0.045576506036451615,
      "loss": 0.6875,
      "step": 337560
    },
    {
      "epoch": 544.48,
      "learning_rate": 0.04557328023322581,
      "loss": 0.7126,
      "step": 337580
    },
    {
      "epoch": 544.52,
      "learning_rate": 0.04557005443000001,
      "loss": 0.7087,
      "step": 337600
    },
    {
      "epoch": 544.55,
      "learning_rate": 0.0455668286267742,
      "loss": 0.7006,
      "step": 337620
    },
    {
      "epoch": 544.58,
      "learning_rate": 0.04556360282354839,
      "loss": 0.694,
      "step": 337640
    },
    {
      "epoch": 544.61,
      "learning_rate": 0.04556037702032258,
      "loss": 0.7012,
      "step": 337660
    },
    {
      "epoch": 544.65,
      "learning_rate": 0.04555715121709678,
      "loss": 0.6924,
      "step": 337680
    },
    {
      "epoch": 544.68,
      "learning_rate": 0.045553925413870974,
      "loss": 0.7105,
      "step": 337700
    },
    {
      "epoch": 544.71,
      "learning_rate": 0.045550699610645166,
      "loss": 0.6946,
      "step": 337720
    },
    {
      "epoch": 544.74,
      "learning_rate": 0.045547473807419366,
      "loss": 0.6993,
      "step": 337740
    },
    {
      "epoch": 544.77,
      "learning_rate": 0.04554424800419356,
      "loss": 0.6986,
      "step": 337760
    },
    {
      "epoch": 544.81,
      "learning_rate": 0.04554102220096774,
      "loss": 0.6978,
      "step": 337780
    },
    {
      "epoch": 544.84,
      "learning_rate": 0.045537796397741935,
      "loss": 0.6952,
      "step": 337800
    },
    {
      "epoch": 544.87,
      "learning_rate": 0.04553457059451613,
      "loss": 0.7255,
      "step": 337820
    },
    {
      "epoch": 544.9,
      "learning_rate": 0.045531344791290326,
      "loss": 0.6922,
      "step": 337840
    },
    {
      "epoch": 544.94,
      "learning_rate": 0.04552811898806452,
      "loss": 0.707,
      "step": 337860
    },
    {
      "epoch": 544.97,
      "learning_rate": 0.04552489318483871,
      "loss": 0.6834,
      "step": 337880
    },
    {
      "epoch": 545.0,
      "learning_rate": 0.04552166738161291,
      "loss": 0.6769,
      "step": 337900
    },
    {
      "epoch": 545.0,
      "eval_accuracy": {
        "accuracy": 0.7673874014518773
      },
      "eval_loss": 1.0506621599197388,
      "eval_runtime": 3.9066,
      "eval_samples_per_second": 3279.315,
      "eval_steps_per_second": 51.451,
      "step": 337900
    },
    {
      "epoch": 545.03,
      "learning_rate": 0.0455184415783871,
      "loss": 0.7024,
      "step": 337920
    },
    {
      "epoch": 545.06,
      "learning_rate": 0.045515215775161294,
      "loss": 0.6779,
      "step": 337940
    },
    {
      "epoch": 545.1,
      "learning_rate": 0.045511989971935486,
      "loss": 0.6768,
      "step": 337960
    },
    {
      "epoch": 545.13,
      "learning_rate": 0.045508764168709685,
      "loss": 0.6654,
      "step": 337980
    },
    {
      "epoch": 545.16,
      "learning_rate": 0.04550553836548388,
      "loss": 0.6808,
      "step": 338000
    },
    {
      "epoch": 545.19,
      "learning_rate": 0.04550231256225807,
      "loss": 0.6956,
      "step": 338020
    },
    {
      "epoch": 545.23,
      "learning_rate": 0.04549908675903227,
      "loss": 0.6761,
      "step": 338040
    },
    {
      "epoch": 545.26,
      "learning_rate": 0.04549586095580646,
      "loss": 0.6677,
      "step": 338060
    },
    {
      "epoch": 545.29,
      "learning_rate": 0.04549263515258065,
      "loss": 0.7028,
      "step": 338080
    },
    {
      "epoch": 545.32,
      "learning_rate": 0.04548940934935484,
      "loss": 0.6943,
      "step": 338100
    },
    {
      "epoch": 545.35,
      "learning_rate": 0.04548618354612903,
      "loss": 0.6998,
      "step": 338120
    },
    {
      "epoch": 545.39,
      "learning_rate": 0.04548295774290323,
      "loss": 0.6842,
      "step": 338140
    },
    {
      "epoch": 545.42,
      "learning_rate": 0.04547973193967742,
      "loss": 0.7021,
      "step": 338160
    },
    {
      "epoch": 545.45,
      "learning_rate": 0.045476506136451614,
      "loss": 0.6861,
      "step": 338180
    },
    {
      "epoch": 545.48,
      "learning_rate": 0.045473280333225806,
      "loss": 0.6907,
      "step": 338200
    },
    {
      "epoch": 545.52,
      "learning_rate": 0.045470054530000005,
      "loss": 0.698,
      "step": 338220
    },
    {
      "epoch": 545.55,
      "learning_rate": 0.0454668287267742,
      "loss": 0.6903,
      "step": 338240
    },
    {
      "epoch": 545.58,
      "learning_rate": 0.04546360292354839,
      "loss": 0.6888,
      "step": 338260
    },
    {
      "epoch": 545.61,
      "learning_rate": 0.04546037712032259,
      "loss": 0.6814,
      "step": 338280
    },
    {
      "epoch": 545.65,
      "learning_rate": 0.04545715131709678,
      "loss": 0.6907,
      "step": 338300
    },
    {
      "epoch": 545.68,
      "learning_rate": 0.04545392551387097,
      "loss": 0.6985,
      "step": 338320
    },
    {
      "epoch": 545.71,
      "learning_rate": 0.04545069971064517,
      "loss": 0.6873,
      "step": 338340
    },
    {
      "epoch": 545.74,
      "learning_rate": 0.045447473907419364,
      "loss": 0.7006,
      "step": 338360
    },
    {
      "epoch": 545.77,
      "learning_rate": 0.045444248104193556,
      "loss": 0.703,
      "step": 338380
    },
    {
      "epoch": 545.81,
      "learning_rate": 0.04544102230096774,
      "loss": 0.6823,
      "step": 338400
    },
    {
      "epoch": 545.84,
      "learning_rate": 0.045437796497741934,
      "loss": 0.6882,
      "step": 338420
    },
    {
      "epoch": 545.87,
      "learning_rate": 0.04543457069451613,
      "loss": 0.682,
      "step": 338440
    },
    {
      "epoch": 545.9,
      "learning_rate": 0.045431344891290325,
      "loss": 0.7065,
      "step": 338460
    },
    {
      "epoch": 545.94,
      "learning_rate": 0.04542811908806452,
      "loss": 0.7037,
      "step": 338480
    },
    {
      "epoch": 545.97,
      "learning_rate": 0.04542489328483871,
      "loss": 0.7029,
      "step": 338500
    },
    {
      "epoch": 546.0,
      "learning_rate": 0.045421828771774204,
      "loss": 0.705,
      "step": 338520
    },
    {
      "epoch": 546.0,
      "eval_accuracy": {
        "accuracy": 0.7664507064241667
      },
      "eval_loss": 1.0532029867172241,
      "eval_runtime": 2.9496,
      "eval_samples_per_second": 4343.268,
      "eval_steps_per_second": 68.144,
      "step": 338520
    },
    {
      "epoch": 546.03,
      "learning_rate": 0.04541860296854838,
      "loss": 0.7004,
      "step": 338540
    },
    {
      "epoch": 546.06,
      "learning_rate": 0.04541537716532258,
      "loss": 0.6699,
      "step": 338560
    },
    {
      "epoch": 546.1,
      "learning_rate": 0.045412151362096774,
      "loss": 0.6896,
      "step": 338580
    },
    {
      "epoch": 546.13,
      "learning_rate": 0.045408925558870966,
      "loss": 0.6722,
      "step": 338600
    },
    {
      "epoch": 546.16,
      "learning_rate": 0.045405699755645165,
      "loss": 0.678,
      "step": 338620
    },
    {
      "epoch": 546.19,
      "learning_rate": 0.04540247395241936,
      "loss": 0.6833,
      "step": 338640
    },
    {
      "epoch": 546.23,
      "learning_rate": 0.04539924814919355,
      "loss": 0.6862,
      "step": 338660
    },
    {
      "epoch": 546.26,
      "learning_rate": 0.04539602234596775,
      "loss": 0.69,
      "step": 338680
    },
    {
      "epoch": 546.29,
      "learning_rate": 0.04539279654274194,
      "loss": 0.6944,
      "step": 338700
    },
    {
      "epoch": 546.32,
      "learning_rate": 0.04538957073951613,
      "loss": 0.6979,
      "step": 338720
    },
    {
      "epoch": 546.35,
      "learning_rate": 0.045386344936290325,
      "loss": 0.698,
      "step": 338740
    },
    {
      "epoch": 546.39,
      "learning_rate": 0.045383119133064524,
      "loss": 0.7093,
      "step": 338760
    },
    {
      "epoch": 546.42,
      "learning_rate": 0.045379893329838716,
      "loss": 0.69,
      "step": 338780
    },
    {
      "epoch": 546.45,
      "learning_rate": 0.04537666752661291,
      "loss": 0.7044,
      "step": 338800
    },
    {
      "epoch": 546.48,
      "learning_rate": 0.04537344172338711,
      "loss": 0.7029,
      "step": 338820
    },
    {
      "epoch": 546.52,
      "learning_rate": 0.0453702159201613,
      "loss": 0.6991,
      "step": 338840
    },
    {
      "epoch": 546.55,
      "learning_rate": 0.045366990116935485,
      "loss": 0.7005,
      "step": 338860
    },
    {
      "epoch": 546.58,
      "learning_rate": 0.04536376431370968,
      "loss": 0.6858,
      "step": 338880
    },
    {
      "epoch": 546.61,
      "learning_rate": 0.04536053851048387,
      "loss": 0.6829,
      "step": 338900
    },
    {
      "epoch": 546.65,
      "learning_rate": 0.04535731270725807,
      "loss": 0.6926,
      "step": 338920
    },
    {
      "epoch": 546.68,
      "learning_rate": 0.04535408690403226,
      "loss": 0.6982,
      "step": 338940
    },
    {
      "epoch": 546.71,
      "learning_rate": 0.04535086110080645,
      "loss": 0.6849,
      "step": 338960
    },
    {
      "epoch": 546.74,
      "learning_rate": 0.04534763529758065,
      "loss": 0.6893,
      "step": 338980
    },
    {
      "epoch": 546.77,
      "learning_rate": 0.045344409494354844,
      "loss": 0.6985,
      "step": 339000
    },
    {
      "epoch": 546.81,
      "learning_rate": 0.045341183691129036,
      "loss": 0.7108,
      "step": 339020
    },
    {
      "epoch": 546.84,
      "learning_rate": 0.04533795788790323,
      "loss": 0.7018,
      "step": 339040
    },
    {
      "epoch": 546.87,
      "learning_rate": 0.04533473208467743,
      "loss": 0.6889,
      "step": 339060
    },
    {
      "epoch": 546.9,
      "learning_rate": 0.04533150628145162,
      "loss": 0.7003,
      "step": 339080
    },
    {
      "epoch": 546.94,
      "learning_rate": 0.04532828047822581,
      "loss": 0.6953,
      "step": 339100
    },
    {
      "epoch": 546.97,
      "learning_rate": 0.04532505467500001,
      "loss": 0.7035,
      "step": 339120
    },
    {
      "epoch": 547.0,
      "learning_rate": 0.0453218288717742,
      "loss": 0.7035,
      "step": 339140
    },
    {
      "epoch": 547.0,
      "eval_accuracy": {
        "accuracy": 0.7637186792600109
      },
      "eval_loss": 1.0615569353103638,
      "eval_runtime": 2.8459,
      "eval_samples_per_second": 4501.49,
      "eval_steps_per_second": 70.627,
      "step": 339140
    },
    {
      "epoch": 547.03,
      "learning_rate": 0.04531860306854839,
      "loss": 0.7102,
      "step": 339160
    },
    {
      "epoch": 547.06,
      "learning_rate": 0.04531537726532258,
      "loss": 0.7034,
      "step": 339180
    },
    {
      "epoch": 547.1,
      "learning_rate": 0.04531215146209677,
      "loss": 0.6863,
      "step": 339200
    },
    {
      "epoch": 547.13,
      "learning_rate": 0.04530892565887097,
      "loss": 0.7005,
      "step": 339220
    },
    {
      "epoch": 547.16,
      "learning_rate": 0.045305699855645164,
      "loss": 0.6831,
      "step": 339240
    },
    {
      "epoch": 547.19,
      "learning_rate": 0.045302474052419356,
      "loss": 0.6702,
      "step": 339260
    },
    {
      "epoch": 547.23,
      "learning_rate": 0.04529924824919355,
      "loss": 0.6836,
      "step": 339280
    },
    {
      "epoch": 547.26,
      "learning_rate": 0.04529602244596775,
      "loss": 0.6832,
      "step": 339300
    },
    {
      "epoch": 547.29,
      "learning_rate": 0.04529279664274194,
      "loss": 0.6882,
      "step": 339320
    },
    {
      "epoch": 547.32,
      "learning_rate": 0.04528957083951613,
      "loss": 0.7045,
      "step": 339340
    },
    {
      "epoch": 547.35,
      "learning_rate": 0.04528634503629033,
      "loss": 0.6853,
      "step": 339360
    },
    {
      "epoch": 547.39,
      "learning_rate": 0.04528311923306452,
      "loss": 0.692,
      "step": 339380
    },
    {
      "epoch": 547.42,
      "learning_rate": 0.045279893429838715,
      "loss": 0.6798,
      "step": 339400
    },
    {
      "epoch": 547.45,
      "learning_rate": 0.045276667626612914,
      "loss": 0.6957,
      "step": 339420
    },
    {
      "epoch": 547.48,
      "learning_rate": 0.045273441823387106,
      "loss": 0.6926,
      "step": 339440
    },
    {
      "epoch": 547.52,
      "learning_rate": 0.0452702160201613,
      "loss": 0.6856,
      "step": 339460
    },
    {
      "epoch": 547.55,
      "learning_rate": 0.045266990216935483,
      "loss": 0.6901,
      "step": 339480
    },
    {
      "epoch": 547.58,
      "learning_rate": 0.045263764413709676,
      "loss": 0.6927,
      "step": 339500
    },
    {
      "epoch": 547.61,
      "learning_rate": 0.045260538610483875,
      "loss": 0.6814,
      "step": 339520
    },
    {
      "epoch": 547.65,
      "learning_rate": 0.04525731280725807,
      "loss": 0.7077,
      "step": 339540
    },
    {
      "epoch": 547.68,
      "learning_rate": 0.04525408700403226,
      "loss": 0.6904,
      "step": 339560
    },
    {
      "epoch": 547.71,
      "learning_rate": 0.04525086120080645,
      "loss": 0.664,
      "step": 339580
    },
    {
      "epoch": 547.74,
      "learning_rate": 0.04524763539758065,
      "loss": 0.6972,
      "step": 339600
    },
    {
      "epoch": 547.77,
      "learning_rate": 0.04524440959435484,
      "loss": 0.6976,
      "step": 339620
    },
    {
      "epoch": 547.81,
      "learning_rate": 0.045241183791129035,
      "loss": 0.6979,
      "step": 339640
    },
    {
      "epoch": 547.84,
      "learning_rate": 0.045237957987903234,
      "loss": 0.6949,
      "step": 339660
    },
    {
      "epoch": 547.87,
      "learning_rate": 0.045234732184677426,
      "loss": 0.6883,
      "step": 339680
    },
    {
      "epoch": 547.9,
      "learning_rate": 0.04523150638145162,
      "loss": 0.694,
      "step": 339700
    },
    {
      "epoch": 547.94,
      "learning_rate": 0.04522828057822582,
      "loss": 0.7145,
      "step": 339720
    },
    {
      "epoch": 547.97,
      "learning_rate": 0.04522505477500001,
      "loss": 0.7186,
      "step": 339740
    },
    {
      "epoch": 548.0,
      "learning_rate": 0.0452218289717742,
      "loss": 0.7007,
      "step": 339760
    },
    {
      "epoch": 548.0,
      "eval_accuracy": {
        "accuracy": 0.7606744204199516
      },
      "eval_loss": 1.0831432342529297,
      "eval_runtime": 3.4425,
      "eval_samples_per_second": 3721.456,
      "eval_steps_per_second": 58.388,
      "step": 339760
    },
    {
      "epoch": 548.03,
      "learning_rate": 0.045218603168548394,
      "loss": 0.7032,
      "step": 339780
    },
    {
      "epoch": 548.06,
      "learning_rate": 0.04521537736532258,
      "loss": 0.6585,
      "step": 339800
    },
    {
      "epoch": 548.1,
      "learning_rate": 0.04521215156209677,
      "loss": 0.6767,
      "step": 339820
    },
    {
      "epoch": 548.13,
      "learning_rate": 0.04520892575887097,
      "loss": 0.6783,
      "step": 339840
    },
    {
      "epoch": 548.16,
      "learning_rate": 0.04520569995564516,
      "loss": 0.6777,
      "step": 339860
    },
    {
      "epoch": 548.19,
      "learning_rate": 0.045202474152419354,
      "loss": 0.6843,
      "step": 339880
    },
    {
      "epoch": 548.23,
      "learning_rate": 0.04519924834919355,
      "loss": 0.6795,
      "step": 339900
    },
    {
      "epoch": 548.26,
      "learning_rate": 0.045196022545967746,
      "loss": 0.6764,
      "step": 339920
    },
    {
      "epoch": 548.29,
      "learning_rate": 0.04519279674274194,
      "loss": 0.6788,
      "step": 339940
    },
    {
      "epoch": 548.32,
      "learning_rate": 0.04518957093951614,
      "loss": 0.6858,
      "step": 339960
    },
    {
      "epoch": 548.35,
      "learning_rate": 0.04518634513629033,
      "loss": 0.6967,
      "step": 339980
    },
    {
      "epoch": 548.39,
      "learning_rate": 0.04518311933306452,
      "loss": 0.684,
      "step": 340000
    },
    {
      "epoch": 548.42,
      "learning_rate": 0.04517989352983871,
      "loss": 0.6915,
      "step": 340020
    },
    {
      "epoch": 548.45,
      "learning_rate": 0.04517666772661291,
      "loss": 0.6732,
      "step": 340040
    },
    {
      "epoch": 548.48,
      "learning_rate": 0.045173441923387105,
      "loss": 0.696,
      "step": 340060
    },
    {
      "epoch": 548.52,
      "learning_rate": 0.0451702161201613,
      "loss": 0.6946,
      "step": 340080
    },
    {
      "epoch": 548.55,
      "learning_rate": 0.04516699031693548,
      "loss": 0.6872,
      "step": 340100
    },
    {
      "epoch": 548.58,
      "learning_rate": 0.045163764513709674,
      "loss": 0.7025,
      "step": 340120
    },
    {
      "epoch": 548.61,
      "learning_rate": 0.04516053871048387,
      "loss": 0.7036,
      "step": 340140
    },
    {
      "epoch": 548.65,
      "learning_rate": 0.045157312907258065,
      "loss": 0.718,
      "step": 340160
    },
    {
      "epoch": 548.68,
      "learning_rate": 0.04515408710403226,
      "loss": 0.705,
      "step": 340180
    },
    {
      "epoch": 548.71,
      "learning_rate": 0.04515086130080646,
      "loss": 0.6793,
      "step": 340200
    },
    {
      "epoch": 548.74,
      "learning_rate": 0.04514763549758065,
      "loss": 0.7085,
      "step": 340220
    },
    {
      "epoch": 548.77,
      "learning_rate": 0.04514440969435484,
      "loss": 0.7106,
      "step": 340240
    },
    {
      "epoch": 548.81,
      "learning_rate": 0.04514118389112904,
      "loss": 0.6886,
      "step": 340260
    },
    {
      "epoch": 548.84,
      "learning_rate": 0.04513795808790323,
      "loss": 0.6953,
      "step": 340280
    },
    {
      "epoch": 548.87,
      "learning_rate": 0.045134732284677424,
      "loss": 0.7003,
      "step": 340300
    },
    {
      "epoch": 548.9,
      "learning_rate": 0.045131506481451616,
      "loss": 0.6979,
      "step": 340320
    },
    {
      "epoch": 548.94,
      "learning_rate": 0.045128280678225816,
      "loss": 0.715,
      "step": 340340
    },
    {
      "epoch": 548.97,
      "learning_rate": 0.04512505487500001,
      "loss": 0.7023,
      "step": 340360
    },
    {
      "epoch": 549.0,
      "learning_rate": 0.0451218290717742,
      "loss": 0.6901,
      "step": 340380
    },
    {
      "epoch": 549.0,
      "eval_accuracy": {
        "accuracy": 0.7654359534774803
      },
      "eval_loss": 1.0565085411071777,
      "eval_runtime": 2.9203,
      "eval_samples_per_second": 4386.875,
      "eval_steps_per_second": 68.828,
      "step": 340380
    },
    {
      "epoch": 549.03,
      "learning_rate": 0.0451186032685484,
      "loss": 0.6853,
      "step": 340400
    },
    {
      "epoch": 549.06,
      "learning_rate": 0.04511537746532258,
      "loss": 0.669,
      "step": 340420
    },
    {
      "epoch": 549.1,
      "learning_rate": 0.045112151662096776,
      "loss": 0.6826,
      "step": 340440
    },
    {
      "epoch": 549.13,
      "learning_rate": 0.04510892585887097,
      "loss": 0.6821,
      "step": 340460
    },
    {
      "epoch": 549.16,
      "learning_rate": 0.04510570005564516,
      "loss": 0.6838,
      "step": 340480
    },
    {
      "epoch": 549.19,
      "learning_rate": 0.04510247425241936,
      "loss": 0.6863,
      "step": 340500
    },
    {
      "epoch": 549.23,
      "learning_rate": 0.04509924844919355,
      "loss": 0.6861,
      "step": 340520
    },
    {
      "epoch": 549.26,
      "learning_rate": 0.045096022645967744,
      "loss": 0.6817,
      "step": 340540
    },
    {
      "epoch": 549.29,
      "learning_rate": 0.045092796842741936,
      "loss": 0.6912,
      "step": 340560
    },
    {
      "epoch": 549.32,
      "learning_rate": 0.045089571039516135,
      "loss": 0.7077,
      "step": 340580
    },
    {
      "epoch": 549.35,
      "learning_rate": 0.04508634523629033,
      "loss": 0.6872,
      "step": 340600
    },
    {
      "epoch": 549.39,
      "learning_rate": 0.04508311943306452,
      "loss": 0.6817,
      "step": 340620
    },
    {
      "epoch": 549.42,
      "learning_rate": 0.04507989362983872,
      "loss": 0.6889,
      "step": 340640
    },
    {
      "epoch": 549.45,
      "learning_rate": 0.04507666782661291,
      "loss": 0.6959,
      "step": 340660
    },
    {
      "epoch": 549.48,
      "learning_rate": 0.0450734420233871,
      "loss": 0.6829,
      "step": 340680
    },
    {
      "epoch": 549.52,
      "learning_rate": 0.0450702162201613,
      "loss": 0.6807,
      "step": 340700
    },
    {
      "epoch": 549.55,
      "learning_rate": 0.04506699041693548,
      "loss": 0.6808,
      "step": 340720
    },
    {
      "epoch": 549.58,
      "learning_rate": 0.04506376461370968,
      "loss": 0.7081,
      "step": 340740
    },
    {
      "epoch": 549.61,
      "learning_rate": 0.04506053881048387,
      "loss": 0.7016,
      "step": 340760
    },
    {
      "epoch": 549.65,
      "learning_rate": 0.045057313007258064,
      "loss": 0.698,
      "step": 340780
    },
    {
      "epoch": 549.68,
      "learning_rate": 0.04505408720403226,
      "loss": 0.6924,
      "step": 340800
    },
    {
      "epoch": 549.71,
      "learning_rate": 0.045050861400806455,
      "loss": 0.7068,
      "step": 340820
    },
    {
      "epoch": 549.74,
      "learning_rate": 0.04504763559758065,
      "loss": 0.6999,
      "step": 340840
    },
    {
      "epoch": 549.77,
      "learning_rate": 0.04504440979435484,
      "loss": 0.6829,
      "step": 340860
    },
    {
      "epoch": 549.81,
      "learning_rate": 0.04504118399112904,
      "loss": 0.6893,
      "step": 340880
    },
    {
      "epoch": 549.84,
      "learning_rate": 0.04503795818790323,
      "loss": 0.6868,
      "step": 340900
    },
    {
      "epoch": 549.87,
      "learning_rate": 0.04503473238467742,
      "loss": 0.6972,
      "step": 340920
    },
    {
      "epoch": 549.9,
      "learning_rate": 0.04503150658145162,
      "loss": 0.6964,
      "step": 340940
    },
    {
      "epoch": 549.94,
      "learning_rate": 0.045028280778225814,
      "loss": 0.6889,
      "step": 340960
    },
    {
      "epoch": 549.97,
      "learning_rate": 0.045025054975000006,
      "loss": 0.6977,
      "step": 340980
    },
    {
      "epoch": 550.0,
      "learning_rate": 0.04502199046193549,
      "loss": 0.692,
      "step": 341000
    },
    {
      "epoch": 550.0,
      "eval_accuracy": {
        "accuracy": 0.7638747950979626
      },
      "eval_loss": 1.0515730381011963,
      "eval_runtime": 2.9087,
      "eval_samples_per_second": 4404.345,
      "eval_steps_per_second": 69.103,
      "step": 341000
    },
    {
      "epoch": 550.03,
      "learning_rate": 0.04501876465870968,
      "loss": 0.6924,
      "step": 341020
    },
    {
      "epoch": 550.06,
      "learning_rate": 0.04501553885548388,
      "loss": 0.6871,
      "step": 341040
    },
    {
      "epoch": 550.1,
      "learning_rate": 0.04501231305225807,
      "loss": 0.6931,
      "step": 341060
    },
    {
      "epoch": 550.13,
      "learning_rate": 0.04500908724903226,
      "loss": 0.6965,
      "step": 341080
    },
    {
      "epoch": 550.16,
      "learning_rate": 0.045005861445806455,
      "loss": 0.681,
      "step": 341100
    },
    {
      "epoch": 550.19,
      "learning_rate": 0.045002635642580655,
      "loss": 0.6849,
      "step": 341120
    },
    {
      "epoch": 550.23,
      "learning_rate": 0.04499940983935485,
      "loss": 0.6871,
      "step": 341140
    },
    {
      "epoch": 550.26,
      "learning_rate": 0.04499618403612904,
      "loss": 0.6925,
      "step": 341160
    },
    {
      "epoch": 550.29,
      "learning_rate": 0.044992958232903224,
      "loss": 0.6926,
      "step": 341180
    },
    {
      "epoch": 550.32,
      "learning_rate": 0.044989732429677416,
      "loss": 0.6821,
      "step": 341200
    },
    {
      "epoch": 550.35,
      "learning_rate": 0.044986506626451615,
      "loss": 0.671,
      "step": 341220
    },
    {
      "epoch": 550.39,
      "learning_rate": 0.04498328082322581,
      "loss": 0.6905,
      "step": 341240
    },
    {
      "epoch": 550.42,
      "learning_rate": 0.04498005502,
      "loss": 0.6932,
      "step": 341260
    },
    {
      "epoch": 550.45,
      "learning_rate": 0.0449768292167742,
      "loss": 0.703,
      "step": 341280
    },
    {
      "epoch": 550.48,
      "learning_rate": 0.04497360341354839,
      "loss": 0.7017,
      "step": 341300
    },
    {
      "epoch": 550.52,
      "learning_rate": 0.04497037761032258,
      "loss": 0.7125,
      "step": 341320
    },
    {
      "epoch": 550.55,
      "learning_rate": 0.04496715180709678,
      "loss": 0.678,
      "step": 341340
    },
    {
      "epoch": 550.58,
      "learning_rate": 0.044963926003870974,
      "loss": 0.6796,
      "step": 341360
    },
    {
      "epoch": 550.61,
      "learning_rate": 0.044960700200645166,
      "loss": 0.6886,
      "step": 341380
    },
    {
      "epoch": 550.65,
      "learning_rate": 0.04495747439741936,
      "loss": 0.6871,
      "step": 341400
    },
    {
      "epoch": 550.68,
      "learning_rate": 0.04495424859419356,
      "loss": 0.7009,
      "step": 341420
    },
    {
      "epoch": 550.71,
      "learning_rate": 0.04495102279096775,
      "loss": 0.6922,
      "step": 341440
    },
    {
      "epoch": 550.74,
      "learning_rate": 0.04494779698774194,
      "loss": 0.7054,
      "step": 341460
    },
    {
      "epoch": 550.77,
      "learning_rate": 0.04494457118451613,
      "loss": 0.6965,
      "step": 341480
    },
    {
      "epoch": 550.81,
      "learning_rate": 0.04494134538129032,
      "loss": 0.7114,
      "step": 341500
    },
    {
      "epoch": 550.84,
      "learning_rate": 0.04493811957806452,
      "loss": 0.707,
      "step": 341520
    },
    {
      "epoch": 550.87,
      "learning_rate": 0.04493489377483871,
      "loss": 0.7182,
      "step": 341540
    },
    {
      "epoch": 550.9,
      "learning_rate": 0.0449316679716129,
      "loss": 0.6927,
      "step": 341560
    },
    {
      "epoch": 550.94,
      "learning_rate": 0.0449284421683871,
      "loss": 0.6836,
      "step": 341580
    },
    {
      "epoch": 550.97,
      "learning_rate": 0.044925216365161294,
      "loss": 0.6882,
      "step": 341600
    },
    {
      "epoch": 551.0,
      "learning_rate": 0.044921990561935486,
      "loss": 0.6963,
      "step": 341620
    },
    {
      "epoch": 551.0,
      "eval_accuracy": {
        "accuracy": 0.7673093435329014
      },
      "eval_loss": 1.0417966842651367,
      "eval_runtime": 3.5852,
      "eval_samples_per_second": 3573.283,
      "eval_steps_per_second": 56.064,
      "step": 341620
    },
    {
      "epoch": 551.03,
      "learning_rate": 0.04491876475870968,
      "loss": 0.6885,
      "step": 341640
    },
    {
      "epoch": 551.06,
      "learning_rate": 0.04491553895548388,
      "loss": 0.6709,
      "step": 341660
    },
    {
      "epoch": 551.1,
      "learning_rate": 0.04491231315225807,
      "loss": 0.6879,
      "step": 341680
    },
    {
      "epoch": 551.13,
      "learning_rate": 0.04490908734903226,
      "loss": 0.6678,
      "step": 341700
    },
    {
      "epoch": 551.16,
      "learning_rate": 0.04490586154580646,
      "loss": 0.6815,
      "step": 341720
    },
    {
      "epoch": 551.19,
      "learning_rate": 0.04490263574258065,
      "loss": 0.6878,
      "step": 341740
    },
    {
      "epoch": 551.23,
      "learning_rate": 0.044899409939354845,
      "loss": 0.6959,
      "step": 341760
    },
    {
      "epoch": 551.26,
      "learning_rate": 0.044896184136129044,
      "loss": 0.6878,
      "step": 341780
    },
    {
      "epoch": 551.29,
      "learning_rate": 0.04489295833290322,
      "loss": 0.6916,
      "step": 341800
    },
    {
      "epoch": 551.32,
      "learning_rate": 0.04488973252967742,
      "loss": 0.686,
      "step": 341820
    },
    {
      "epoch": 551.35,
      "learning_rate": 0.044886506726451614,
      "loss": 0.688,
      "step": 341840
    },
    {
      "epoch": 551.39,
      "learning_rate": 0.044883280923225806,
      "loss": 0.6842,
      "step": 341860
    },
    {
      "epoch": 551.42,
      "learning_rate": 0.044880055120000005,
      "loss": 0.7065,
      "step": 341880
    },
    {
      "epoch": 551.45,
      "learning_rate": 0.0448768293167742,
      "loss": 0.6849,
      "step": 341900
    },
    {
      "epoch": 551.48,
      "learning_rate": 0.04487360351354839,
      "loss": 0.6874,
      "step": 341920
    },
    {
      "epoch": 551.52,
      "learning_rate": 0.04487037771032258,
      "loss": 0.6847,
      "step": 341940
    },
    {
      "epoch": 551.55,
      "learning_rate": 0.04486715190709678,
      "loss": 0.6779,
      "step": 341960
    },
    {
      "epoch": 551.58,
      "learning_rate": 0.04486392610387097,
      "loss": 0.6707,
      "step": 341980
    },
    {
      "epoch": 551.61,
      "learning_rate": 0.044860700300645165,
      "loss": 0.7011,
      "step": 342000
    },
    {
      "epoch": 551.65,
      "learning_rate": 0.044857474497419364,
      "loss": 0.7125,
      "step": 342020
    },
    {
      "epoch": 551.68,
      "learning_rate": 0.044854248694193556,
      "loss": 0.7015,
      "step": 342040
    },
    {
      "epoch": 551.71,
      "learning_rate": 0.04485102289096775,
      "loss": 0.6976,
      "step": 342060
    },
    {
      "epoch": 551.74,
      "learning_rate": 0.04484779708774195,
      "loss": 0.7183,
      "step": 342080
    },
    {
      "epoch": 551.77,
      "learning_rate": 0.04484457128451614,
      "loss": 0.6958,
      "step": 342100
    },
    {
      "epoch": 551.81,
      "learning_rate": 0.044841345481290325,
      "loss": 0.6934,
      "step": 342120
    },
    {
      "epoch": 551.84,
      "learning_rate": 0.04483811967806452,
      "loss": 0.6821,
      "step": 342140
    },
    {
      "epoch": 551.87,
      "learning_rate": 0.04483489387483871,
      "loss": 0.6886,
      "step": 342160
    },
    {
      "epoch": 551.9,
      "learning_rate": 0.0448316680716129,
      "loss": 0.6797,
      "step": 342180
    },
    {
      "epoch": 551.94,
      "learning_rate": 0.0448284422683871,
      "loss": 0.6948,
      "step": 342200
    },
    {
      "epoch": 551.97,
      "learning_rate": 0.04482521646516129,
      "loss": 0.6746,
      "step": 342220
    },
    {
      "epoch": 552.0,
      "learning_rate": 0.044821990661935485,
      "loss": 0.7015,
      "step": 342240
    },
    {
      "epoch": 552.0,
      "eval_accuracy": {
        "accuracy": 0.7580204511747717
      },
      "eval_loss": 1.0872986316680908,
      "eval_runtime": 2.8338,
      "eval_samples_per_second": 4520.783,
      "eval_steps_per_second": 70.929,
      "step": 342240
    },
    {
      "epoch": 552.03,
      "learning_rate": 0.044818764858709684,
      "loss": 0.7252,
      "step": 342260
    },
    {
      "epoch": 552.06,
      "learning_rate": 0.044815539055483876,
      "loss": 0.6836,
      "step": 342280
    },
    {
      "epoch": 552.1,
      "learning_rate": 0.04481231325225807,
      "loss": 0.6792,
      "step": 342300
    },
    {
      "epoch": 552.13,
      "learning_rate": 0.04480908744903227,
      "loss": 0.6967,
      "step": 342320
    },
    {
      "epoch": 552.16,
      "learning_rate": 0.04480586164580646,
      "loss": 0.6753,
      "step": 342340
    },
    {
      "epoch": 552.19,
      "learning_rate": 0.04480263584258065,
      "loss": 0.6951,
      "step": 342360
    },
    {
      "epoch": 552.23,
      "learning_rate": 0.04479941003935485,
      "loss": 0.6988,
      "step": 342380
    },
    {
      "epoch": 552.26,
      "learning_rate": 0.04479618423612904,
      "loss": 0.7219,
      "step": 342400
    },
    {
      "epoch": 552.29,
      "learning_rate": 0.04479295843290323,
      "loss": 0.6879,
      "step": 342420
    },
    {
      "epoch": 552.32,
      "learning_rate": 0.04478973262967742,
      "loss": 0.6831,
      "step": 342440
    },
    {
      "epoch": 552.35,
      "learning_rate": 0.04478650682645161,
      "loss": 0.6642,
      "step": 342460
    },
    {
      "epoch": 552.39,
      "learning_rate": 0.044783281023225804,
      "loss": 0.6935,
      "step": 342480
    },
    {
      "epoch": 552.42,
      "learning_rate": 0.044780055220000003,
      "loss": 0.685,
      "step": 342500
    },
    {
      "epoch": 552.45,
      "learning_rate": 0.044776829416774196,
      "loss": 0.6703,
      "step": 342520
    },
    {
      "epoch": 552.48,
      "learning_rate": 0.04477360361354839,
      "loss": 0.6905,
      "step": 342540
    },
    {
      "epoch": 552.52,
      "learning_rate": 0.04477037781032259,
      "loss": 0.689,
      "step": 342560
    },
    {
      "epoch": 552.55,
      "learning_rate": 0.04476715200709678,
      "loss": 0.6872,
      "step": 342580
    },
    {
      "epoch": 552.58,
      "learning_rate": 0.04476392620387097,
      "loss": 0.6738,
      "step": 342600
    },
    {
      "epoch": 552.61,
      "learning_rate": 0.04476070040064517,
      "loss": 0.7071,
      "step": 342620
    },
    {
      "epoch": 552.65,
      "learning_rate": 0.04475747459741936,
      "loss": 0.6865,
      "step": 342640
    },
    {
      "epoch": 552.68,
      "learning_rate": 0.044754248794193555,
      "loss": 0.6873,
      "step": 342660
    },
    {
      "epoch": 552.71,
      "learning_rate": 0.04475102299096775,
      "loss": 0.6897,
      "step": 342680
    },
    {
      "epoch": 552.74,
      "learning_rate": 0.044747797187741946,
      "loss": 0.6875,
      "step": 342700
    },
    {
      "epoch": 552.77,
      "learning_rate": 0.04474457138451614,
      "loss": 0.69,
      "step": 342720
    },
    {
      "epoch": 552.81,
      "learning_rate": 0.04474134558129032,
      "loss": 0.6749,
      "step": 342740
    },
    {
      "epoch": 552.84,
      "learning_rate": 0.044738119778064515,
      "loss": 0.6909,
      "step": 342760
    },
    {
      "epoch": 552.87,
      "learning_rate": 0.04473489397483871,
      "loss": 0.7075,
      "step": 342780
    },
    {
      "epoch": 552.9,
      "learning_rate": 0.04473166817161291,
      "loss": 0.6744,
      "step": 342800
    },
    {
      "epoch": 552.94,
      "learning_rate": 0.0447284423683871,
      "loss": 0.6801,
      "step": 342820
    },
    {
      "epoch": 552.97,
      "learning_rate": 0.04472521656516129,
      "loss": 0.694,
      "step": 342840
    },
    {
      "epoch": 553.0,
      "learning_rate": 0.04472199076193549,
      "loss": 0.6992,
      "step": 342860
    },
    {
      "epoch": 553.0,
      "eval_accuracy": {
        "accuracy": 0.7566154086332059
      },
      "eval_loss": 1.0865999460220337,
      "eval_runtime": 3.0296,
      "eval_samples_per_second": 4228.543,
      "eval_steps_per_second": 66.344,
      "step": 342860
    },
    {
      "epoch": 553.03,
      "learning_rate": 0.04471876495870968,
      "loss": 0.6986,
      "step": 342880
    },
    {
      "epoch": 553.06,
      "learning_rate": 0.044715539155483874,
      "loss": 0.6747,
      "step": 342900
    },
    {
      "epoch": 553.1,
      "learning_rate": 0.04471231335225807,
      "loss": 0.682,
      "step": 342920
    },
    {
      "epoch": 553.13,
      "learning_rate": 0.044709087549032266,
      "loss": 0.6659,
      "step": 342940
    },
    {
      "epoch": 553.16,
      "learning_rate": 0.04470586174580646,
      "loss": 0.6874,
      "step": 342960
    },
    {
      "epoch": 553.19,
      "learning_rate": 0.04470263594258065,
      "loss": 0.6731,
      "step": 342980
    },
    {
      "epoch": 553.23,
      "learning_rate": 0.04469941013935485,
      "loss": 0.6867,
      "step": 343000
    },
    {
      "epoch": 553.26,
      "learning_rate": 0.04469618433612904,
      "loss": 0.6976,
      "step": 343020
    },
    {
      "epoch": 553.29,
      "learning_rate": 0.044692958532903226,
      "loss": 0.6971,
      "step": 343040
    },
    {
      "epoch": 553.32,
      "learning_rate": 0.04468973272967742,
      "loss": 0.6872,
      "step": 343060
    },
    {
      "epoch": 553.35,
      "learning_rate": 0.04468650692645161,
      "loss": 0.6907,
      "step": 343080
    },
    {
      "epoch": 553.39,
      "learning_rate": 0.04468328112322581,
      "loss": 0.6856,
      "step": 343100
    },
    {
      "epoch": 553.42,
      "learning_rate": 0.04468005532,
      "loss": 0.6757,
      "step": 343120
    },
    {
      "epoch": 553.45,
      "learning_rate": 0.044676829516774194,
      "loss": 0.6661,
      "step": 343140
    },
    {
      "epoch": 553.48,
      "learning_rate": 0.04467360371354839,
      "loss": 0.6857,
      "step": 343160
    },
    {
      "epoch": 553.52,
      "learning_rate": 0.044670377910322585,
      "loss": 0.6861,
      "step": 343180
    },
    {
      "epoch": 553.55,
      "learning_rate": 0.04466715210709678,
      "loss": 0.6708,
      "step": 343200
    },
    {
      "epoch": 553.58,
      "learning_rate": 0.04466392630387097,
      "loss": 0.6789,
      "step": 343220
    },
    {
      "epoch": 553.61,
      "learning_rate": 0.04466070050064517,
      "loss": 0.6675,
      "step": 343240
    },
    {
      "epoch": 553.65,
      "learning_rate": 0.04465747469741936,
      "loss": 0.6859,
      "step": 343260
    },
    {
      "epoch": 553.68,
      "learning_rate": 0.04465424889419355,
      "loss": 0.6981,
      "step": 343280
    },
    {
      "epoch": 553.71,
      "learning_rate": 0.04465102309096775,
      "loss": 0.6874,
      "step": 343300
    },
    {
      "epoch": 553.74,
      "learning_rate": 0.044647797287741944,
      "loss": 0.6907,
      "step": 343320
    },
    {
      "epoch": 553.77,
      "learning_rate": 0.044644571484516136,
      "loss": 0.6849,
      "step": 343340
    },
    {
      "epoch": 553.81,
      "learning_rate": 0.04464134568129032,
      "loss": 0.6965,
      "step": 343360
    },
    {
      "epoch": 553.84,
      "learning_rate": 0.044638119878064514,
      "loss": 0.7032,
      "step": 343380
    },
    {
      "epoch": 553.87,
      "learning_rate": 0.04463489407483871,
      "loss": 0.6949,
      "step": 343400
    },
    {
      "epoch": 553.9,
      "learning_rate": 0.044631668271612905,
      "loss": 0.6944,
      "step": 343420
    },
    {
      "epoch": 553.94,
      "learning_rate": 0.0446284424683871,
      "loss": 0.7025,
      "step": 343440
    },
    {
      "epoch": 553.97,
      "learning_rate": 0.044625216665161296,
      "loss": 0.7074,
      "step": 343460
    },
    {
      "epoch": 554.0,
      "learning_rate": 0.044622152152096785,
      "loss": 0.7065,
      "step": 343480
    },
    {
      "epoch": 554.0,
      "eval_accuracy": {
        "accuracy": 0.7600499570681446
      },
      "eval_loss": 1.0669004917144775,
      "eval_runtime": 3.0322,
      "eval_samples_per_second": 4224.98,
      "eval_steps_per_second": 66.288,
      "step": 343480
    },
    {
      "epoch": 554.03,
      "learning_rate": 0.04461892634887097,
      "loss": 0.6778,
      "step": 343500
    },
    {
      "epoch": 554.06,
      "learning_rate": 0.04461570054564516,
      "loss": 0.6949,
      "step": 343520
    },
    {
      "epoch": 554.1,
      "learning_rate": 0.044612474742419354,
      "loss": 0.6945,
      "step": 343540
    },
    {
      "epoch": 554.13,
      "learning_rate": 0.044609248939193547,
      "loss": 0.6836,
      "step": 343560
    },
    {
      "epoch": 554.16,
      "learning_rate": 0.044606023135967746,
      "loss": 0.6797,
      "step": 343580
    },
    {
      "epoch": 554.19,
      "learning_rate": 0.04460279733274194,
      "loss": 0.6739,
      "step": 343600
    },
    {
      "epoch": 554.23,
      "learning_rate": 0.04459957152951613,
      "loss": 0.6892,
      "step": 343620
    },
    {
      "epoch": 554.26,
      "learning_rate": 0.04459634572629033,
      "loss": 0.6824,
      "step": 343640
    },
    {
      "epoch": 554.29,
      "learning_rate": 0.04459311992306452,
      "loss": 0.7052,
      "step": 343660
    },
    {
      "epoch": 554.32,
      "learning_rate": 0.04458989411983871,
      "loss": 0.6726,
      "step": 343680
    },
    {
      "epoch": 554.35,
      "learning_rate": 0.04458666831661291,
      "loss": 0.6658,
      "step": 343700
    },
    {
      "epoch": 554.39,
      "learning_rate": 0.044583442513387105,
      "loss": 0.6744,
      "step": 343720
    },
    {
      "epoch": 554.42,
      "learning_rate": 0.0445802167101613,
      "loss": 0.691,
      "step": 343740
    },
    {
      "epoch": 554.45,
      "learning_rate": 0.04457699090693549,
      "loss": 0.6684,
      "step": 343760
    },
    {
      "epoch": 554.48,
      "learning_rate": 0.04457376510370969,
      "loss": 0.694,
      "step": 343780
    },
    {
      "epoch": 554.52,
      "learning_rate": 0.044570539300483866,
      "loss": 0.7029,
      "step": 343800
    },
    {
      "epoch": 554.55,
      "learning_rate": 0.044567313497258065,
      "loss": 0.6971,
      "step": 343820
    },
    {
      "epoch": 554.58,
      "learning_rate": 0.04456408769403226,
      "loss": 0.6971,
      "step": 343840
    },
    {
      "epoch": 554.61,
      "learning_rate": 0.04456086189080645,
      "loss": 0.6971,
      "step": 343860
    },
    {
      "epoch": 554.65,
      "learning_rate": 0.04455763608758065,
      "loss": 0.6795,
      "step": 343880
    },
    {
      "epoch": 554.68,
      "learning_rate": 0.04455441028435484,
      "loss": 0.7053,
      "step": 343900
    },
    {
      "epoch": 554.71,
      "learning_rate": 0.04455118448112903,
      "loss": 0.709,
      "step": 343920
    },
    {
      "epoch": 554.74,
      "learning_rate": 0.04454795867790323,
      "loss": 0.6928,
      "step": 343940
    },
    {
      "epoch": 554.77,
      "learning_rate": 0.044544732874677424,
      "loss": 0.695,
      "step": 343960
    },
    {
      "epoch": 554.81,
      "learning_rate": 0.044541507071451616,
      "loss": 0.6758,
      "step": 343980
    },
    {
      "epoch": 554.84,
      "learning_rate": 0.044538281268225816,
      "loss": 0.7098,
      "step": 344000
    },
    {
      "epoch": 554.87,
      "learning_rate": 0.04453505546500001,
      "loss": 0.7023,
      "step": 344020
    },
    {
      "epoch": 554.9,
      "learning_rate": 0.0445318296617742,
      "loss": 0.7101,
      "step": 344040
    },
    {
      "epoch": 554.94,
      "learning_rate": 0.04452860385854839,
      "loss": 0.6987,
      "step": 344060
    },
    {
      "epoch": 554.97,
      "learning_rate": 0.04452537805532259,
      "loss": 0.6745,
      "step": 344080
    },
    {
      "epoch": 555.0,
      "learning_rate": 0.04452215225209678,
      "loss": 0.6868,
      "step": 344100
    },
    {
      "epoch": 555.0,
      "eval_accuracy": {
        "accuracy": 0.7663726485051908
      },
      "eval_loss": 1.0358779430389404,
      "eval_runtime": 2.9618,
      "eval_samples_per_second": 4325.397,
      "eval_steps_per_second": 67.864,
      "step": 344100
    },
    {
      "epoch": 555.03,
      "learning_rate": 0.04451892644887097,
      "loss": 0.6858,
      "step": 344120
    },
    {
      "epoch": 555.06,
      "learning_rate": 0.04451570064564516,
      "loss": 0.6791,
      "step": 344140
    },
    {
      "epoch": 555.1,
      "learning_rate": 0.04451247484241935,
      "loss": 0.6701,
      "step": 344160
    },
    {
      "epoch": 555.13,
      "learning_rate": 0.04450924903919355,
      "loss": 0.6718,
      "step": 344180
    },
    {
      "epoch": 555.16,
      "learning_rate": 0.044506023235967744,
      "loss": 0.6822,
      "step": 344200
    },
    {
      "epoch": 555.19,
      "learning_rate": 0.044502797432741936,
      "loss": 0.6704,
      "step": 344220
    },
    {
      "epoch": 555.23,
      "learning_rate": 0.044499571629516135,
      "loss": 0.6857,
      "step": 344240
    },
    {
      "epoch": 555.26,
      "learning_rate": 0.04449634582629033,
      "loss": 0.6959,
      "step": 344260
    },
    {
      "epoch": 555.29,
      "learning_rate": 0.04449312002306452,
      "loss": 0.6886,
      "step": 344280
    },
    {
      "epoch": 555.32,
      "learning_rate": 0.04448989421983871,
      "loss": 0.6934,
      "step": 344300
    },
    {
      "epoch": 555.35,
      "learning_rate": 0.04448666841661291,
      "loss": 0.6829,
      "step": 344320
    },
    {
      "epoch": 555.39,
      "learning_rate": 0.0444834426133871,
      "loss": 0.6779,
      "step": 344340
    },
    {
      "epoch": 555.42,
      "learning_rate": 0.044480216810161295,
      "loss": 0.6804,
      "step": 344360
    },
    {
      "epoch": 555.45,
      "learning_rate": 0.044476991006935494,
      "loss": 0.7003,
      "step": 344380
    },
    {
      "epoch": 555.48,
      "learning_rate": 0.044473765203709686,
      "loss": 0.6921,
      "step": 344400
    },
    {
      "epoch": 555.52,
      "learning_rate": 0.04447053940048388,
      "loss": 0.6945,
      "step": 344420
    },
    {
      "epoch": 555.55,
      "learning_rate": 0.044467313597258064,
      "loss": 0.6914,
      "step": 344440
    },
    {
      "epoch": 555.58,
      "learning_rate": 0.044464087794032256,
      "loss": 0.7028,
      "step": 344460
    },
    {
      "epoch": 555.61,
      "learning_rate": 0.044460861990806455,
      "loss": 0.7039,
      "step": 344480
    },
    {
      "epoch": 555.65,
      "learning_rate": 0.04445763618758065,
      "loss": 0.6938,
      "step": 344500
    },
    {
      "epoch": 555.68,
      "learning_rate": 0.04445441038435484,
      "loss": 0.706,
      "step": 344520
    },
    {
      "epoch": 555.71,
      "learning_rate": 0.04445118458112904,
      "loss": 0.6996,
      "step": 344540
    },
    {
      "epoch": 555.74,
      "learning_rate": 0.04444795877790323,
      "loss": 0.6815,
      "step": 344560
    },
    {
      "epoch": 555.77,
      "learning_rate": 0.04444473297467742,
      "loss": 0.7038,
      "step": 344580
    },
    {
      "epoch": 555.81,
      "learning_rate": 0.044441507171451615,
      "loss": 0.6881,
      "step": 344600
    },
    {
      "epoch": 555.84,
      "learning_rate": 0.044438281368225814,
      "loss": 0.6965,
      "step": 344620
    },
    {
      "epoch": 555.87,
      "learning_rate": 0.044435055565000006,
      "loss": 0.6924,
      "step": 344640
    },
    {
      "epoch": 555.9,
      "learning_rate": 0.0444318297617742,
      "loss": 0.694,
      "step": 344660
    },
    {
      "epoch": 555.94,
      "learning_rate": 0.0444286039585484,
      "loss": 0.7075,
      "step": 344680
    },
    {
      "epoch": 555.97,
      "learning_rate": 0.04442537815532259,
      "loss": 0.6855,
      "step": 344700
    },
    {
      "epoch": 556.0,
      "learning_rate": 0.04442215235209678,
      "loss": 0.702,
      "step": 344720
    },
    {
      "epoch": 556.0,
      "eval_accuracy": {
        "accuracy": 0.7644212005307939
      },
      "eval_loss": 1.0548784732818604,
      "eval_runtime": 3.5315,
      "eval_samples_per_second": 3627.61,
      "eval_steps_per_second": 56.916,
      "step": 344720
    },
    {
      "epoch": 556.03,
      "learning_rate": 0.04441892654887097,
      "loss": 0.6786,
      "step": 344740
    },
    {
      "epoch": 556.06,
      "learning_rate": 0.04441570074564516,
      "loss": 0.6751,
      "step": 344760
    },
    {
      "epoch": 556.1,
      "learning_rate": 0.04441247494241936,
      "loss": 0.6727,
      "step": 344780
    },
    {
      "epoch": 556.13,
      "learning_rate": 0.04440924913919355,
      "loss": 0.6751,
      "step": 344800
    },
    {
      "epoch": 556.16,
      "learning_rate": 0.04440602333596774,
      "loss": 0.6858,
      "step": 344820
    },
    {
      "epoch": 556.19,
      "learning_rate": 0.044402797532741935,
      "loss": 0.6859,
      "step": 344840
    },
    {
      "epoch": 556.23,
      "learning_rate": 0.044399571729516134,
      "loss": 0.7104,
      "step": 344860
    },
    {
      "epoch": 556.26,
      "learning_rate": 0.044396345926290326,
      "loss": 0.681,
      "step": 344880
    },
    {
      "epoch": 556.29,
      "learning_rate": 0.04439312012306452,
      "loss": 0.6908,
      "step": 344900
    },
    {
      "epoch": 556.32,
      "learning_rate": 0.04438989431983872,
      "loss": 0.6879,
      "step": 344920
    },
    {
      "epoch": 556.35,
      "learning_rate": 0.04438666851661291,
      "loss": 0.6808,
      "step": 344940
    },
    {
      "epoch": 556.39,
      "learning_rate": 0.0443834427133871,
      "loss": 0.6804,
      "step": 344960
    },
    {
      "epoch": 556.42,
      "learning_rate": 0.0443802169101613,
      "loss": 0.6854,
      "step": 344980
    },
    {
      "epoch": 556.45,
      "learning_rate": 0.04437699110693549,
      "loss": 0.6799,
      "step": 345000
    },
    {
      "epoch": 556.48,
      "learning_rate": 0.044373765303709685,
      "loss": 0.6827,
      "step": 345020
    },
    {
      "epoch": 556.52,
      "learning_rate": 0.04437053950048388,
      "loss": 0.661,
      "step": 345040
    },
    {
      "epoch": 556.55,
      "learning_rate": 0.04436731369725806,
      "loss": 0.6984,
      "step": 345060
    },
    {
      "epoch": 556.58,
      "learning_rate": 0.044364087894032254,
      "loss": 0.7055,
      "step": 345080
    },
    {
      "epoch": 556.61,
      "learning_rate": 0.044360862090806454,
      "loss": 0.6782,
      "step": 345100
    },
    {
      "epoch": 556.65,
      "learning_rate": 0.044357636287580646,
      "loss": 0.6913,
      "step": 345120
    },
    {
      "epoch": 556.68,
      "learning_rate": 0.04435441048435484,
      "loss": 0.6887,
      "step": 345140
    },
    {
      "epoch": 556.71,
      "learning_rate": 0.04435118468112904,
      "loss": 0.6818,
      "step": 345160
    },
    {
      "epoch": 556.74,
      "learning_rate": 0.04434795887790323,
      "loss": 0.7047,
      "step": 345180
    },
    {
      "epoch": 556.77,
      "learning_rate": 0.04434473307467742,
      "loss": 0.6957,
      "step": 345200
    },
    {
      "epoch": 556.81,
      "learning_rate": 0.04434150727145162,
      "loss": 0.6712,
      "step": 345220
    },
    {
      "epoch": 556.84,
      "learning_rate": 0.04433828146822581,
      "loss": 0.686,
      "step": 345240
    },
    {
      "epoch": 556.87,
      "learning_rate": 0.044335055665000005,
      "loss": 0.6847,
      "step": 345260
    },
    {
      "epoch": 556.9,
      "learning_rate": 0.044331829861774204,
      "loss": 0.7109,
      "step": 345280
    },
    {
      "epoch": 556.94,
      "learning_rate": 0.044328604058548396,
      "loss": 0.6939,
      "step": 345300
    },
    {
      "epoch": 556.97,
      "learning_rate": 0.04432537825532259,
      "loss": 0.6959,
      "step": 345320
    },
    {
      "epoch": 557.0,
      "learning_rate": 0.04432215245209678,
      "loss": 0.6891,
      "step": 345340
    },
    {
      "epoch": 557.0,
      "eval_accuracy": {
        "accuracy": 0.7622355787994692
      },
      "eval_loss": 1.0479940176010132,
      "eval_runtime": 3.0194,
      "eval_samples_per_second": 4242.846,
      "eval_steps_per_second": 66.569,
      "step": 345340
    },
    {
      "epoch": 557.03,
      "learning_rate": 0.044318926648870965,
      "loss": 0.7029,
      "step": 345360
    },
    {
      "epoch": 557.06,
      "learning_rate": 0.04431570084564516,
      "loss": 0.6889,
      "step": 345380
    },
    {
      "epoch": 557.1,
      "learning_rate": 0.04431247504241936,
      "loss": 0.6782,
      "step": 345400
    },
    {
      "epoch": 557.13,
      "learning_rate": 0.04430924923919355,
      "loss": 0.6798,
      "step": 345420
    },
    {
      "epoch": 557.16,
      "learning_rate": 0.04430602343596774,
      "loss": 0.6889,
      "step": 345440
    },
    {
      "epoch": 557.19,
      "learning_rate": 0.04430279763274194,
      "loss": 0.6982,
      "step": 345460
    },
    {
      "epoch": 557.23,
      "learning_rate": 0.04429957182951613,
      "loss": 0.6622,
      "step": 345480
    },
    {
      "epoch": 557.26,
      "learning_rate": 0.044296346026290324,
      "loss": 0.671,
      "step": 345500
    },
    {
      "epoch": 557.29,
      "learning_rate": 0.044293120223064524,
      "loss": 0.6916,
      "step": 345520
    },
    {
      "epoch": 557.32,
      "learning_rate": 0.044289894419838716,
      "loss": 0.6761,
      "step": 345540
    },
    {
      "epoch": 557.35,
      "learning_rate": 0.04428666861661291,
      "loss": 0.6882,
      "step": 345560
    },
    {
      "epoch": 557.39,
      "learning_rate": 0.0442834428133871,
      "loss": 0.685,
      "step": 345580
    },
    {
      "epoch": 557.42,
      "learning_rate": 0.0442802170101613,
      "loss": 0.6874,
      "step": 345600
    },
    {
      "epoch": 557.45,
      "learning_rate": 0.04427699120693549,
      "loss": 0.6657,
      "step": 345620
    },
    {
      "epoch": 557.48,
      "learning_rate": 0.04427376540370968,
      "loss": 0.6837,
      "step": 345640
    },
    {
      "epoch": 557.52,
      "learning_rate": 0.04427053960048388,
      "loss": 0.6935,
      "step": 345660
    },
    {
      "epoch": 557.55,
      "learning_rate": 0.04426731379725806,
      "loss": 0.6833,
      "step": 345680
    },
    {
      "epoch": 557.58,
      "learning_rate": 0.04426408799403226,
      "loss": 0.6814,
      "step": 345700
    },
    {
      "epoch": 557.61,
      "learning_rate": 0.04426086219080645,
      "loss": 0.6804,
      "step": 345720
    },
    {
      "epoch": 557.65,
      "learning_rate": 0.044257636387580644,
      "loss": 0.689,
      "step": 345740
    },
    {
      "epoch": 557.68,
      "learning_rate": 0.04425441058435484,
      "loss": 0.6904,
      "step": 345760
    },
    {
      "epoch": 557.71,
      "learning_rate": 0.044251184781129035,
      "loss": 0.6793,
      "step": 345780
    },
    {
      "epoch": 557.74,
      "learning_rate": 0.04424795897790323,
      "loss": 0.6871,
      "step": 345800
    },
    {
      "epoch": 557.77,
      "learning_rate": 0.04424473317467743,
      "loss": 0.6817,
      "step": 345820
    },
    {
      "epoch": 557.81,
      "learning_rate": 0.04424150737145162,
      "loss": 0.6873,
      "step": 345840
    },
    {
      "epoch": 557.84,
      "learning_rate": 0.04423828156822581,
      "loss": 0.7132,
      "step": 345860
    },
    {
      "epoch": 557.87,
      "learning_rate": 0.044235055765,
      "loss": 0.6935,
      "step": 345880
    },
    {
      "epoch": 557.9,
      "learning_rate": 0.0442318299617742,
      "loss": 0.696,
      "step": 345900
    },
    {
      "epoch": 557.94,
      "learning_rate": 0.044228604158548394,
      "loss": 0.686,
      "step": 345920
    },
    {
      "epoch": 557.97,
      "learning_rate": 0.04422537835532259,
      "loss": 0.6784,
      "step": 345940
    },
    {
      "epoch": 558.0,
      "learning_rate": 0.04422231384225807,
      "loss": 0.7092,
      "step": 345960
    },
    {
      "epoch": 558.0,
      "eval_accuracy": {
        "accuracy": 0.7639528530169386
      },
      "eval_loss": 1.0508781671524048,
      "eval_runtime": 3.1401,
      "eval_samples_per_second": 4079.826,
      "eval_steps_per_second": 64.011,
      "step": 345960
    },
    {
      "epoch": 558.03,
      "learning_rate": 0.04421908803903226,
      "loss": 0.6924,
      "step": 345980
    },
    {
      "epoch": 558.06,
      "learning_rate": 0.04421586223580646,
      "loss": 0.6985,
      "step": 346000
    },
    {
      "epoch": 558.1,
      "learning_rate": 0.04421263643258065,
      "loss": 0.6727,
      "step": 346020
    },
    {
      "epoch": 558.13,
      "learning_rate": 0.044209410629354844,
      "loss": 0.6649,
      "step": 346040
    },
    {
      "epoch": 558.16,
      "learning_rate": 0.04420618482612904,
      "loss": 0.6712,
      "step": 346060
    },
    {
      "epoch": 558.19,
      "learning_rate": 0.044202959022903235,
      "loss": 0.6733,
      "step": 346080
    },
    {
      "epoch": 558.23,
      "learning_rate": 0.04419973321967743,
      "loss": 0.6926,
      "step": 346100
    },
    {
      "epoch": 558.26,
      "learning_rate": 0.04419650741645161,
      "loss": 0.6843,
      "step": 346120
    },
    {
      "epoch": 558.29,
      "learning_rate": 0.044193281613225804,
      "loss": 0.6664,
      "step": 346140
    },
    {
      "epoch": 558.32,
      "learning_rate": 0.04419005581,
      "loss": 0.6731,
      "step": 346160
    },
    {
      "epoch": 558.35,
      "learning_rate": 0.044186830006774196,
      "loss": 0.6633,
      "step": 346180
    },
    {
      "epoch": 558.39,
      "learning_rate": 0.04418360420354839,
      "loss": 0.674,
      "step": 346200
    },
    {
      "epoch": 558.42,
      "learning_rate": 0.04418037840032258,
      "loss": 0.6927,
      "step": 346220
    },
    {
      "epoch": 558.45,
      "learning_rate": 0.04417715259709678,
      "loss": 0.6958,
      "step": 346240
    },
    {
      "epoch": 558.48,
      "learning_rate": 0.04417392679387097,
      "loss": 0.6942,
      "step": 346260
    },
    {
      "epoch": 558.52,
      "learning_rate": 0.04417070099064516,
      "loss": 0.6824,
      "step": 346280
    },
    {
      "epoch": 558.55,
      "learning_rate": 0.04416747518741936,
      "loss": 0.686,
      "step": 346300
    },
    {
      "epoch": 558.58,
      "learning_rate": 0.044164249384193555,
      "loss": 0.6923,
      "step": 346320
    },
    {
      "epoch": 558.61,
      "learning_rate": 0.04416102358096775,
      "loss": 0.693,
      "step": 346340
    },
    {
      "epoch": 558.65,
      "learning_rate": 0.044157797777741946,
      "loss": 0.7229,
      "step": 346360
    },
    {
      "epoch": 558.68,
      "learning_rate": 0.04415457197451614,
      "loss": 0.7023,
      "step": 346380
    },
    {
      "epoch": 558.71,
      "learning_rate": 0.04415134617129033,
      "loss": 0.6894,
      "step": 346400
    },
    {
      "epoch": 558.74,
      "learning_rate": 0.04414812036806452,
      "loss": 0.6916,
      "step": 346420
    },
    {
      "epoch": 558.77,
      "learning_rate": 0.04414489456483871,
      "loss": 0.6912,
      "step": 346440
    },
    {
      "epoch": 558.81,
      "learning_rate": 0.0441416687616129,
      "loss": 0.689,
      "step": 346460
    },
    {
      "epoch": 558.84,
      "learning_rate": 0.0441384429583871,
      "loss": 0.6759,
      "step": 346480
    },
    {
      "epoch": 558.87,
      "learning_rate": 0.04413521715516129,
      "loss": 0.6802,
      "step": 346500
    },
    {
      "epoch": 558.9,
      "learning_rate": 0.04413199135193548,
      "loss": 0.6862,
      "step": 346520
    },
    {
      "epoch": 558.94,
      "learning_rate": 0.04412876554870968,
      "loss": 0.6931,
      "step": 346540
    },
    {
      "epoch": 558.97,
      "learning_rate": 0.044125539745483874,
      "loss": 0.6921,
      "step": 346560
    },
    {
      "epoch": 559.0,
      "learning_rate": 0.044122313942258067,
      "loss": 0.6982,
      "step": 346580
    },
    {
      "epoch": 559.0,
      "eval_accuracy": {
        "accuracy": 0.7608305362579033
      },
      "eval_loss": 1.0626989603042603,
      "eval_runtime": 2.953,
      "eval_samples_per_second": 4338.346,
      "eval_steps_per_second": 68.067,
      "step": 346580
    },
    {
      "epoch": 559.03,
      "learning_rate": 0.044119088139032266,
      "loss": 0.6944,
      "step": 346600
    },
    {
      "epoch": 559.06,
      "learning_rate": 0.04411586233580646,
      "loss": 0.664,
      "step": 346620
    },
    {
      "epoch": 559.1,
      "learning_rate": 0.04411263653258065,
      "loss": 0.6699,
      "step": 346640
    },
    {
      "epoch": 559.13,
      "learning_rate": 0.04410941072935484,
      "loss": 0.678,
      "step": 346660
    },
    {
      "epoch": 559.16,
      "learning_rate": 0.04410618492612904,
      "loss": 0.6776,
      "step": 346680
    },
    {
      "epoch": 559.19,
      "learning_rate": 0.04410295912290323,
      "loss": 0.6726,
      "step": 346700
    },
    {
      "epoch": 559.23,
      "learning_rate": 0.044099733319677425,
      "loss": 0.6805,
      "step": 346720
    },
    {
      "epoch": 559.26,
      "learning_rate": 0.044096507516451625,
      "loss": 0.6739,
      "step": 346740
    },
    {
      "epoch": 559.29,
      "learning_rate": 0.0440932817132258,
      "loss": 0.6837,
      "step": 346760
    },
    {
      "epoch": 559.32,
      "learning_rate": 0.04409005591,
      "loss": 0.6902,
      "step": 346780
    },
    {
      "epoch": 559.35,
      "learning_rate": 0.044086830106774194,
      "loss": 0.6758,
      "step": 346800
    },
    {
      "epoch": 559.39,
      "learning_rate": 0.044083604303548386,
      "loss": 0.664,
      "step": 346820
    },
    {
      "epoch": 559.42,
      "learning_rate": 0.044080378500322585,
      "loss": 0.6748,
      "step": 346840
    },
    {
      "epoch": 559.45,
      "learning_rate": 0.04407715269709678,
      "loss": 0.6745,
      "step": 346860
    },
    {
      "epoch": 559.48,
      "learning_rate": 0.04407392689387097,
      "loss": 0.6813,
      "step": 346880
    },
    {
      "epoch": 559.52,
      "learning_rate": 0.04407070109064517,
      "loss": 0.6782,
      "step": 346900
    },
    {
      "epoch": 559.55,
      "learning_rate": 0.04406747528741936,
      "loss": 0.6844,
      "step": 346920
    },
    {
      "epoch": 559.58,
      "learning_rate": 0.04406424948419355,
      "loss": 0.6829,
      "step": 346940
    },
    {
      "epoch": 559.61,
      "learning_rate": 0.044061023680967745,
      "loss": 0.6899,
      "step": 346960
    },
    {
      "epoch": 559.65,
      "learning_rate": 0.044057797877741944,
      "loss": 0.6517,
      "step": 346980
    },
    {
      "epoch": 559.68,
      "learning_rate": 0.044054572074516136,
      "loss": 0.6991,
      "step": 347000
    },
    {
      "epoch": 559.71,
      "learning_rate": 0.04405134627129033,
      "loss": 0.6772,
      "step": 347020
    },
    {
      "epoch": 559.74,
      "learning_rate": 0.04404812046806453,
      "loss": 0.6851,
      "step": 347040
    },
    {
      "epoch": 559.77,
      "learning_rate": 0.044044894664838706,
      "loss": 0.6797,
      "step": 347060
    },
    {
      "epoch": 559.81,
      "learning_rate": 0.044041668861612905,
      "loss": 0.6874,
      "step": 347080
    },
    {
      "epoch": 559.84,
      "learning_rate": 0.0440384430583871,
      "loss": 0.6831,
      "step": 347100
    },
    {
      "epoch": 559.87,
      "learning_rate": 0.04403521725516129,
      "loss": 0.69,
      "step": 347120
    },
    {
      "epoch": 559.9,
      "learning_rate": 0.04403199145193549,
      "loss": 0.6985,
      "step": 347140
    },
    {
      "epoch": 559.94,
      "learning_rate": 0.04402876564870968,
      "loss": 0.6924,
      "step": 347160
    },
    {
      "epoch": 559.97,
      "learning_rate": 0.04402553984548387,
      "loss": 0.7109,
      "step": 347180
    },
    {
      "epoch": 560.0,
      "learning_rate": 0.044022314042258065,
      "loss": 0.7117,
      "step": 347200
    },
    {
      "epoch": 560.0,
      "eval_accuracy": {
        "accuracy": 0.7614549996097104
      },
      "eval_loss": 1.0605207681655884,
      "eval_runtime": 3.0667,
      "eval_samples_per_second": 4177.474,
      "eval_steps_per_second": 65.543,
      "step": 347200
    },
    {
      "epoch": 560.03,
      "learning_rate": 0.044019088239032264,
      "loss": 0.6917,
      "step": 347220
    },
    {
      "epoch": 560.06,
      "learning_rate": 0.044015862435806456,
      "loss": 0.6938,
      "step": 347240
    },
    {
      "epoch": 560.1,
      "learning_rate": 0.04401263663258065,
      "loss": 0.6625,
      "step": 347260
    },
    {
      "epoch": 560.13,
      "learning_rate": 0.04400941082935485,
      "loss": 0.6764,
      "step": 347280
    },
    {
      "epoch": 560.16,
      "learning_rate": 0.04400618502612904,
      "loss": 0.6953,
      "step": 347300
    },
    {
      "epoch": 560.19,
      "learning_rate": 0.04400295922290323,
      "loss": 0.6656,
      "step": 347320
    },
    {
      "epoch": 560.23,
      "learning_rate": 0.04399973341967743,
      "loss": 0.677,
      "step": 347340
    },
    {
      "epoch": 560.26,
      "learning_rate": 0.04399650761645162,
      "loss": 0.6816,
      "step": 347360
    },
    {
      "epoch": 560.29,
      "learning_rate": 0.04399328181322581,
      "loss": 0.6762,
      "step": 347380
    },
    {
      "epoch": 560.32,
      "learning_rate": 0.04399005601,
      "loss": 0.6652,
      "step": 347400
    },
    {
      "epoch": 560.35,
      "learning_rate": 0.04398683020677419,
      "loss": 0.6703,
      "step": 347420
    },
    {
      "epoch": 560.39,
      "learning_rate": 0.04398360440354839,
      "loss": 0.6896,
      "step": 347440
    },
    {
      "epoch": 560.42,
      "learning_rate": 0.043980378600322584,
      "loss": 0.6882,
      "step": 347460
    },
    {
      "epoch": 560.45,
      "learning_rate": 0.043977152797096776,
      "loss": 0.6824,
      "step": 347480
    },
    {
      "epoch": 560.48,
      "learning_rate": 0.04397392699387097,
      "loss": 0.6932,
      "step": 347500
    },
    {
      "epoch": 560.52,
      "learning_rate": 0.04397070119064517,
      "loss": 0.6889,
      "step": 347520
    },
    {
      "epoch": 560.55,
      "learning_rate": 0.04396747538741936,
      "loss": 0.6875,
      "step": 347540
    },
    {
      "epoch": 560.58,
      "learning_rate": 0.04396424958419355,
      "loss": 0.6713,
      "step": 347560
    },
    {
      "epoch": 560.61,
      "learning_rate": 0.04396102378096775,
      "loss": 0.6813,
      "step": 347580
    },
    {
      "epoch": 560.65,
      "learning_rate": 0.04395779797774194,
      "loss": 0.6998,
      "step": 347600
    },
    {
      "epoch": 560.68,
      "learning_rate": 0.043954572174516135,
      "loss": 0.6846,
      "step": 347620
    },
    {
      "epoch": 560.71,
      "learning_rate": 0.043951346371290334,
      "loss": 0.6782,
      "step": 347640
    },
    {
      "epoch": 560.74,
      "learning_rate": 0.043948120568064526,
      "loss": 0.6894,
      "step": 347660
    },
    {
      "epoch": 560.77,
      "learning_rate": 0.04394489476483871,
      "loss": 0.687,
      "step": 347680
    },
    {
      "epoch": 560.81,
      "learning_rate": 0.043941668961612904,
      "loss": 0.6816,
      "step": 347700
    },
    {
      "epoch": 560.84,
      "learning_rate": 0.043938443158387096,
      "loss": 0.6964,
      "step": 347720
    },
    {
      "epoch": 560.87,
      "learning_rate": 0.04393521735516129,
      "loss": 0.7094,
      "step": 347740
    },
    {
      "epoch": 560.9,
      "learning_rate": 0.04393199155193549,
      "loss": 0.6889,
      "step": 347760
    },
    {
      "epoch": 560.94,
      "learning_rate": 0.04392876574870968,
      "loss": 0.6906,
      "step": 347780
    },
    {
      "epoch": 560.97,
      "learning_rate": 0.04392553994548387,
      "loss": 0.7065,
      "step": 347800
    },
    {
      "epoch": 561.0,
      "learning_rate": 0.04392231414225807,
      "loss": 0.6892,
      "step": 347820
    },
    {
      "epoch": 561.0,
      "eval_accuracy": {
        "accuracy": 0.7623136367184451
      },
      "eval_loss": 1.0553275346755981,
      "eval_runtime": 3.0914,
      "eval_samples_per_second": 4144.109,
      "eval_steps_per_second": 65.02,
      "step": 347820
    },
    {
      "epoch": 561.03,
      "learning_rate": 0.04391908833903226,
      "loss": 0.6973,
      "step": 347840
    },
    {
      "epoch": 561.06,
      "learning_rate": 0.043915862535806455,
      "loss": 0.6837,
      "step": 347860
    },
    {
      "epoch": 561.1,
      "learning_rate": 0.043912636732580654,
      "loss": 0.6785,
      "step": 347880
    },
    {
      "epoch": 561.13,
      "learning_rate": 0.043909410929354846,
      "loss": 0.6678,
      "step": 347900
    },
    {
      "epoch": 561.16,
      "learning_rate": 0.04390618512612904,
      "loss": 0.6734,
      "step": 347920
    },
    {
      "epoch": 561.19,
      "learning_rate": 0.04390295932290324,
      "loss": 0.6849,
      "step": 347940
    },
    {
      "epoch": 561.23,
      "learning_rate": 0.04389973351967743,
      "loss": 0.6878,
      "step": 347960
    },
    {
      "epoch": 561.26,
      "learning_rate": 0.04389650771645162,
      "loss": 0.6747,
      "step": 347980
    },
    {
      "epoch": 561.29,
      "learning_rate": 0.04389328191322581,
      "loss": 0.6815,
      "step": 348000
    },
    {
      "epoch": 561.32,
      "learning_rate": 0.04389005611,
      "loss": 0.6846,
      "step": 348020
    },
    {
      "epoch": 561.35,
      "learning_rate": 0.04388683030677419,
      "loss": 0.6883,
      "step": 348040
    },
    {
      "epoch": 561.39,
      "learning_rate": 0.04388360450354839,
      "loss": 0.6859,
      "step": 348060
    },
    {
      "epoch": 561.42,
      "learning_rate": 0.04388037870032258,
      "loss": 0.6813,
      "step": 348080
    },
    {
      "epoch": 561.45,
      "learning_rate": 0.043877152897096774,
      "loss": 0.6871,
      "step": 348100
    },
    {
      "epoch": 561.48,
      "learning_rate": 0.043873927093870974,
      "loss": 0.706,
      "step": 348120
    },
    {
      "epoch": 561.52,
      "learning_rate": 0.043870701290645166,
      "loss": 0.7097,
      "step": 348140
    },
    {
      "epoch": 561.55,
      "learning_rate": 0.04386747548741936,
      "loss": 0.688,
      "step": 348160
    },
    {
      "epoch": 561.58,
      "learning_rate": 0.04386424968419356,
      "loss": 0.6774,
      "step": 348180
    },
    {
      "epoch": 561.61,
      "learning_rate": 0.04386102388096775,
      "loss": 0.6927,
      "step": 348200
    },
    {
      "epoch": 561.65,
      "learning_rate": 0.04385779807774194,
      "loss": 0.6862,
      "step": 348220
    },
    {
      "epoch": 561.68,
      "learning_rate": 0.04385457227451613,
      "loss": 0.6925,
      "step": 348240
    },
    {
      "epoch": 561.71,
      "learning_rate": 0.04385134647129033,
      "loss": 0.6949,
      "step": 348260
    },
    {
      "epoch": 561.74,
      "learning_rate": 0.043848120668064525,
      "loss": 0.7155,
      "step": 348280
    },
    {
      "epoch": 561.77,
      "learning_rate": 0.04384489486483871,
      "loss": 0.6967,
      "step": 348300
    },
    {
      "epoch": 561.81,
      "learning_rate": 0.0438416690616129,
      "loss": 0.6773,
      "step": 348320
    },
    {
      "epoch": 561.84,
      "learning_rate": 0.043838443258387094,
      "loss": 0.6746,
      "step": 348340
    },
    {
      "epoch": 561.87,
      "learning_rate": 0.04383521745516129,
      "loss": 0.7094,
      "step": 348360
    },
    {
      "epoch": 561.9,
      "learning_rate": 0.043831991651935485,
      "loss": 0.6837,
      "step": 348380
    },
    {
      "epoch": 561.94,
      "learning_rate": 0.04382876584870968,
      "loss": 0.6979,
      "step": 348400
    },
    {
      "epoch": 561.97,
      "learning_rate": 0.04382554004548388,
      "loss": 0.6811,
      "step": 348420
    },
    {
      "epoch": 562.0,
      "learning_rate": 0.04382247553241935,
      "loss": 0.6935,
      "step": 348440
    },
    {
      "epoch": 562.0,
      "eval_accuracy": {
        "accuracy": 0.7675435172898291
      },
      "eval_loss": 1.030409336090088,
      "eval_runtime": 2.8938,
      "eval_samples_per_second": 4427.101,
      "eval_steps_per_second": 69.46,
      "step": 348440
    },
    {
      "epoch": 562.03,
      "learning_rate": 0.04381924972919355,
      "loss": 0.6739,
      "step": 348460
    },
    {
      "epoch": 562.06,
      "learning_rate": 0.04381602392596774,
      "loss": 0.6732,
      "step": 348480
    },
    {
      "epoch": 562.1,
      "learning_rate": 0.043812798122741935,
      "loss": 0.6576,
      "step": 348500
    },
    {
      "epoch": 562.13,
      "learning_rate": 0.043809572319516134,
      "loss": 0.6778,
      "step": 348520
    },
    {
      "epoch": 562.16,
      "learning_rate": 0.043806346516290326,
      "loss": 0.6809,
      "step": 348540
    },
    {
      "epoch": 562.19,
      "learning_rate": 0.04380312071306452,
      "loss": 0.667,
      "step": 348560
    },
    {
      "epoch": 562.23,
      "learning_rate": 0.04379989490983871,
      "loss": 0.6699,
      "step": 348580
    },
    {
      "epoch": 562.26,
      "learning_rate": 0.04379666910661291,
      "loss": 0.689,
      "step": 348600
    },
    {
      "epoch": 562.29,
      "learning_rate": 0.0437934433033871,
      "loss": 0.6815,
      "step": 348620
    },
    {
      "epoch": 562.32,
      "learning_rate": 0.043790217500161294,
      "loss": 0.6602,
      "step": 348640
    },
    {
      "epoch": 562.35,
      "learning_rate": 0.04378699169693549,
      "loss": 0.6652,
      "step": 348660
    },
    {
      "epoch": 562.39,
      "learning_rate": 0.043783765893709685,
      "loss": 0.6548,
      "step": 348680
    },
    {
      "epoch": 562.42,
      "learning_rate": 0.04378054009048388,
      "loss": 0.6596,
      "step": 348700
    },
    {
      "epoch": 562.45,
      "learning_rate": 0.043777314287258076,
      "loss": 0.6495,
      "step": 348720
    },
    {
      "epoch": 562.48,
      "learning_rate": 0.04377408848403227,
      "loss": 0.7033,
      "step": 348740
    },
    {
      "epoch": 562.52,
      "learning_rate": 0.043770862680806454,
      "loss": 0.6845,
      "step": 348760
    },
    {
      "epoch": 562.55,
      "learning_rate": 0.043767636877580646,
      "loss": 0.6777,
      "step": 348780
    },
    {
      "epoch": 562.58,
      "learning_rate": 0.04376441107435484,
      "loss": 0.6757,
      "step": 348800
    },
    {
      "epoch": 562.61,
      "learning_rate": 0.04376118527112903,
      "loss": 0.6812,
      "step": 348820
    },
    {
      "epoch": 562.65,
      "learning_rate": 0.04375795946790323,
      "loss": 0.6758,
      "step": 348840
    },
    {
      "epoch": 562.68,
      "learning_rate": 0.04375473366467742,
      "loss": 0.6986,
      "step": 348860
    },
    {
      "epoch": 562.71,
      "learning_rate": 0.04375150786145161,
      "loss": 0.6941,
      "step": 348880
    },
    {
      "epoch": 562.74,
      "learning_rate": 0.04374828205822581,
      "loss": 0.6728,
      "step": 348900
    },
    {
      "epoch": 562.77,
      "learning_rate": 0.043745056255000005,
      "loss": 0.6989,
      "step": 348920
    },
    {
      "epoch": 562.81,
      "learning_rate": 0.0437418304517742,
      "loss": 0.7062,
      "step": 348940
    },
    {
      "epoch": 562.84,
      "learning_rate": 0.043738604648548396,
      "loss": 0.6958,
      "step": 348960
    },
    {
      "epoch": 562.87,
      "learning_rate": 0.04373537884532259,
      "loss": 0.6929,
      "step": 348980
    },
    {
      "epoch": 562.9,
      "learning_rate": 0.04373215304209678,
      "loss": 0.7016,
      "step": 349000
    },
    {
      "epoch": 562.94,
      "learning_rate": 0.04372892723887098,
      "loss": 0.6917,
      "step": 349020
    },
    {
      "epoch": 562.97,
      "learning_rate": 0.04372570143564517,
      "loss": 0.7067,
      "step": 349040
    },
    {
      "epoch": 563.0,
      "learning_rate": 0.043722475632419364,
      "loss": 0.6931,
      "step": 349060
    },
    {
      "epoch": 563.0,
      "eval_accuracy": {
        "accuracy": 0.7638747950979626
      },
      "eval_loss": 1.0596885681152344,
      "eval_runtime": 3.013,
      "eval_samples_per_second": 4251.934,
      "eval_steps_per_second": 66.711,
      "step": 349060
    },
    {
      "epoch": 563.03,
      "learning_rate": 0.04371924982919355,
      "loss": 0.6955,
      "step": 349080
    },
    {
      "epoch": 563.06,
      "learning_rate": 0.04371602402596774,
      "loss": 0.6942,
      "step": 349100
    },
    {
      "epoch": 563.1,
      "learning_rate": 0.04371279822274193,
      "loss": 0.6688,
      "step": 349120
    },
    {
      "epoch": 563.13,
      "learning_rate": 0.04370957241951613,
      "loss": 0.6659,
      "step": 349140
    },
    {
      "epoch": 563.16,
      "learning_rate": 0.043706346616290324,
      "loss": 0.6845,
      "step": 349160
    },
    {
      "epoch": 563.19,
      "learning_rate": 0.04370312081306452,
      "loss": 0.6799,
      "step": 349180
    },
    {
      "epoch": 563.23,
      "learning_rate": 0.043699895009838716,
      "loss": 0.6752,
      "step": 349200
    },
    {
      "epoch": 563.26,
      "learning_rate": 0.04369666920661291,
      "loss": 0.7009,
      "step": 349220
    },
    {
      "epoch": 563.29,
      "learning_rate": 0.0436934434033871,
      "loss": 0.6776,
      "step": 349240
    },
    {
      "epoch": 563.32,
      "learning_rate": 0.0436902176001613,
      "loss": 0.6724,
      "step": 349260
    },
    {
      "epoch": 563.35,
      "learning_rate": 0.04368699179693549,
      "loss": 0.6796,
      "step": 349280
    },
    {
      "epoch": 563.39,
      "learning_rate": 0.04368376599370968,
      "loss": 0.6701,
      "step": 349300
    },
    {
      "epoch": 563.42,
      "learning_rate": 0.043680540190483876,
      "loss": 0.6955,
      "step": 349320
    },
    {
      "epoch": 563.45,
      "learning_rate": 0.043677314387258075,
      "loss": 0.6926,
      "step": 349340
    },
    {
      "epoch": 563.48,
      "learning_rate": 0.04367408858403227,
      "loss": 0.6743,
      "step": 349360
    },
    {
      "epoch": 563.52,
      "learning_rate": 0.04367086278080645,
      "loss": 0.6866,
      "step": 349380
    },
    {
      "epoch": 563.55,
      "learning_rate": 0.043667636977580644,
      "loss": 0.6863,
      "step": 349400
    },
    {
      "epoch": 563.58,
      "learning_rate": 0.043664411174354836,
      "loss": 0.6785,
      "step": 349420
    },
    {
      "epoch": 563.61,
      "learning_rate": 0.043661185371129035,
      "loss": 0.6868,
      "step": 349440
    },
    {
      "epoch": 563.65,
      "learning_rate": 0.04365795956790323,
      "loss": 0.6911,
      "step": 349460
    },
    {
      "epoch": 563.68,
      "learning_rate": 0.04365473376467742,
      "loss": 0.6893,
      "step": 349480
    },
    {
      "epoch": 563.71,
      "learning_rate": 0.04365150796145162,
      "loss": 0.6799,
      "step": 349500
    },
    {
      "epoch": 563.74,
      "learning_rate": 0.04364828215822581,
      "loss": 0.6667,
      "step": 349520
    },
    {
      "epoch": 563.77,
      "learning_rate": 0.043645056355,
      "loss": 0.6656,
      "step": 349540
    },
    {
      "epoch": 563.81,
      "learning_rate": 0.0436418305517742,
      "loss": 0.6852,
      "step": 349560
    },
    {
      "epoch": 563.84,
      "learning_rate": 0.043638604748548394,
      "loss": 0.6704,
      "step": 349580
    },
    {
      "epoch": 563.87,
      "learning_rate": 0.04363537894532259,
      "loss": 0.6819,
      "step": 349600
    },
    {
      "epoch": 563.9,
      "learning_rate": 0.04363215314209678,
      "loss": 0.6882,
      "step": 349620
    },
    {
      "epoch": 563.94,
      "learning_rate": 0.04362892733887098,
      "loss": 0.6903,
      "step": 349640
    },
    {
      "epoch": 563.97,
      "learning_rate": 0.04362570153564517,
      "loss": 0.6889,
      "step": 349660
    },
    {
      "epoch": 564.0,
      "learning_rate": 0.04362247573241936,
      "loss": 0.6988,
      "step": 349680
    },
    {
      "epoch": 564.0,
      "eval_accuracy": {
        "accuracy": 0.7580204511747717
      },
      "eval_loss": 1.0592623949050903,
      "eval_runtime": 2.8408,
      "eval_samples_per_second": 4509.602,
      "eval_steps_per_second": 70.754,
      "step": 349680
    },
    {
      "epoch": 564.03,
      "learning_rate": 0.04361924992919355,
      "loss": 0.6986,
      "step": 349700
    },
    {
      "epoch": 564.06,
      "learning_rate": 0.04361602412596774,
      "loss": 0.6809,
      "step": 349720
    },
    {
      "epoch": 564.1,
      "learning_rate": 0.04361279832274194,
      "loss": 0.6724,
      "step": 349740
    },
    {
      "epoch": 564.13,
      "learning_rate": 0.04360957251951613,
      "loss": 0.6843,
      "step": 349760
    },
    {
      "epoch": 564.16,
      "learning_rate": 0.04360634671629032,
      "loss": 0.6831,
      "step": 349780
    },
    {
      "epoch": 564.19,
      "learning_rate": 0.04360312091306452,
      "loss": 0.6763,
      "step": 349800
    },
    {
      "epoch": 564.23,
      "learning_rate": 0.043599895109838714,
      "loss": 0.6727,
      "step": 349820
    },
    {
      "epoch": 564.26,
      "learning_rate": 0.043596669306612906,
      "loss": 0.6672,
      "step": 349840
    },
    {
      "epoch": 564.29,
      "learning_rate": 0.0435934435033871,
      "loss": 0.6749,
      "step": 349860
    },
    {
      "epoch": 564.32,
      "learning_rate": 0.0435902177001613,
      "loss": 0.6879,
      "step": 349880
    },
    {
      "epoch": 564.35,
      "learning_rate": 0.04358699189693549,
      "loss": 0.6839,
      "step": 349900
    },
    {
      "epoch": 564.39,
      "learning_rate": 0.04358376609370968,
      "loss": 0.6777,
      "step": 349920
    },
    {
      "epoch": 564.42,
      "learning_rate": 0.04358054029048388,
      "loss": 0.6913,
      "step": 349940
    },
    {
      "epoch": 564.45,
      "learning_rate": 0.04357731448725807,
      "loss": 0.6681,
      "step": 349960
    },
    {
      "epoch": 564.48,
      "learning_rate": 0.043574088684032265,
      "loss": 0.6828,
      "step": 349980
    },
    {
      "epoch": 564.52,
      "learning_rate": 0.04357086288080645,
      "loss": 0.6803,
      "step": 350000
    },
    {
      "epoch": 564.55,
      "learning_rate": 0.04356763707758064,
      "loss": 0.6989,
      "step": 350020
    },
    {
      "epoch": 564.58,
      "learning_rate": 0.04356441127435484,
      "loss": 0.6807,
      "step": 350040
    },
    {
      "epoch": 564.61,
      "learning_rate": 0.043561185471129034,
      "loss": 0.6748,
      "step": 350060
    },
    {
      "epoch": 564.65,
      "learning_rate": 0.043557959667903226,
      "loss": 0.6778,
      "step": 350080
    },
    {
      "epoch": 564.68,
      "learning_rate": 0.04355473386467742,
      "loss": 0.6749,
      "step": 350100
    },
    {
      "epoch": 564.71,
      "learning_rate": 0.04355150806145162,
      "loss": 0.6804,
      "step": 350120
    },
    {
      "epoch": 564.74,
      "learning_rate": 0.04354828225822581,
      "loss": 0.7006,
      "step": 350140
    },
    {
      "epoch": 564.77,
      "learning_rate": 0.043545056455,
      "loss": 0.6975,
      "step": 350160
    },
    {
      "epoch": 564.81,
      "learning_rate": 0.0435418306517742,
      "loss": 0.6884,
      "step": 350180
    },
    {
      "epoch": 564.84,
      "learning_rate": 0.04353860484854839,
      "loss": 0.6764,
      "step": 350200
    },
    {
      "epoch": 564.87,
      "learning_rate": 0.043535379045322585,
      "loss": 0.7101,
      "step": 350220
    },
    {
      "epoch": 564.9,
      "learning_rate": 0.043532153242096784,
      "loss": 0.698,
      "step": 350240
    },
    {
      "epoch": 564.94,
      "learning_rate": 0.043528927438870976,
      "loss": 0.6683,
      "step": 350260
    },
    {
      "epoch": 564.97,
      "learning_rate": 0.04352570163564517,
      "loss": 0.6936,
      "step": 350280
    },
    {
      "epoch": 565.0,
      "learning_rate": 0.04352247583241937,
      "loss": 0.6742,
      "step": 350300
    },
    {
      "epoch": 565.0,
      "eval_accuracy": {
        "accuracy": 0.768167980641636
      },
      "eval_loss": 1.0252782106399536,
      "eval_runtime": 2.903,
      "eval_samples_per_second": 4413.033,
      "eval_steps_per_second": 69.239,
      "step": 350300
    },
    {
      "epoch": 565.03,
      "learning_rate": 0.043519250029193546,
      "loss": 0.6966,
      "step": 350320
    },
    {
      "epoch": 565.06,
      "learning_rate": 0.043516024225967745,
      "loss": 0.6818,
      "step": 350340
    },
    {
      "epoch": 565.1,
      "learning_rate": 0.04351279842274194,
      "loss": 0.6888,
      "step": 350360
    },
    {
      "epoch": 565.13,
      "learning_rate": 0.04350957261951613,
      "loss": 0.6684,
      "step": 350380
    },
    {
      "epoch": 565.16,
      "learning_rate": 0.04350634681629032,
      "loss": 0.6774,
      "step": 350400
    },
    {
      "epoch": 565.19,
      "learning_rate": 0.04350312101306452,
      "loss": 0.672,
      "step": 350420
    },
    {
      "epoch": 565.23,
      "learning_rate": 0.04349989520983871,
      "loss": 0.6601,
      "step": 350440
    },
    {
      "epoch": 565.26,
      "learning_rate": 0.043496669406612905,
      "loss": 0.6847,
      "step": 350460
    },
    {
      "epoch": 565.29,
      "learning_rate": 0.043493443603387104,
      "loss": 0.6959,
      "step": 350480
    },
    {
      "epoch": 565.32,
      "learning_rate": 0.043490217800161296,
      "loss": 0.6961,
      "step": 350500
    },
    {
      "epoch": 565.35,
      "learning_rate": 0.04348699199693549,
      "loss": 0.6629,
      "step": 350520
    },
    {
      "epoch": 565.39,
      "learning_rate": 0.04348376619370969,
      "loss": 0.6795,
      "step": 350540
    },
    {
      "epoch": 565.42,
      "learning_rate": 0.04348054039048388,
      "loss": 0.6712,
      "step": 350560
    },
    {
      "epoch": 565.45,
      "learning_rate": 0.04347731458725807,
      "loss": 0.6819,
      "step": 350580
    },
    {
      "epoch": 565.48,
      "learning_rate": 0.043474088784032264,
      "loss": 0.6877,
      "step": 350600
    },
    {
      "epoch": 565.52,
      "learning_rate": 0.04347086298080645,
      "loss": 0.6697,
      "step": 350620
    },
    {
      "epoch": 565.55,
      "learning_rate": 0.04346763717758064,
      "loss": 0.6788,
      "step": 350640
    },
    {
      "epoch": 565.58,
      "learning_rate": 0.04346441137435484,
      "loss": 0.6926,
      "step": 350660
    },
    {
      "epoch": 565.61,
      "learning_rate": 0.04346118557112903,
      "loss": 0.6841,
      "step": 350680
    },
    {
      "epoch": 565.65,
      "learning_rate": 0.043457959767903225,
      "loss": 0.6784,
      "step": 350700
    },
    {
      "epoch": 565.68,
      "learning_rate": 0.043454733964677424,
      "loss": 0.6577,
      "step": 350720
    },
    {
      "epoch": 565.71,
      "learning_rate": 0.043451508161451616,
      "loss": 0.6982,
      "step": 350740
    },
    {
      "epoch": 565.74,
      "learning_rate": 0.04344828235822581,
      "loss": 0.6852,
      "step": 350760
    },
    {
      "epoch": 565.77,
      "learning_rate": 0.04344505655500001,
      "loss": 0.6712,
      "step": 350780
    },
    {
      "epoch": 565.81,
      "learning_rate": 0.0434418307517742,
      "loss": 0.6873,
      "step": 350800
    },
    {
      "epoch": 565.84,
      "learning_rate": 0.04343860494854839,
      "loss": 0.7024,
      "step": 350820
    },
    {
      "epoch": 565.87,
      "learning_rate": 0.04343537914532259,
      "loss": 0.6822,
      "step": 350840
    },
    {
      "epoch": 565.9,
      "learning_rate": 0.04343215334209678,
      "loss": 0.6941,
      "step": 350860
    },
    {
      "epoch": 565.94,
      "learning_rate": 0.043428927538870975,
      "loss": 0.6892,
      "step": 350880
    },
    {
      "epoch": 565.97,
      "learning_rate": 0.04342570173564517,
      "loss": 0.6842,
      "step": 350900
    },
    {
      "epoch": 566.0,
      "learning_rate": 0.04342263722258065,
      "loss": 0.6826,
      "step": 350920
    },
    {
      "epoch": 566.0,
      "eval_accuracy": {
        "accuracy": 0.7679338068847085
      },
      "eval_loss": 1.0282565355300903,
      "eval_runtime": 2.8783,
      "eval_samples_per_second": 4450.948,
      "eval_steps_per_second": 69.834,
      "step": 350920
    },
    {
      "epoch": 566.03,
      "learning_rate": 0.04341941141935484,
      "loss": 0.6689,
      "step": 350940
    },
    {
      "epoch": 566.06,
      "learning_rate": 0.04341618561612904,
      "loss": 0.6754,
      "step": 350960
    },
    {
      "epoch": 566.1,
      "learning_rate": 0.04341295981290323,
      "loss": 0.6585,
      "step": 350980
    },
    {
      "epoch": 566.13,
      "learning_rate": 0.043409734009677424,
      "loss": 0.685,
      "step": 351000
    },
    {
      "epoch": 566.16,
      "learning_rate": 0.04340650820645162,
      "loss": 0.6766,
      "step": 351020
    },
    {
      "epoch": 566.19,
      "learning_rate": 0.043403282403225815,
      "loss": 0.6684,
      "step": 351040
    },
    {
      "epoch": 566.23,
      "learning_rate": 0.04340005660000001,
      "loss": 0.6805,
      "step": 351060
    },
    {
      "epoch": 566.26,
      "learning_rate": 0.04339683079677419,
      "loss": 0.6893,
      "step": 351080
    },
    {
      "epoch": 566.29,
      "learning_rate": 0.043393604993548385,
      "loss": 0.6881,
      "step": 351100
    },
    {
      "epoch": 566.32,
      "learning_rate": 0.043390379190322584,
      "loss": 0.6739,
      "step": 351120
    },
    {
      "epoch": 566.35,
      "learning_rate": 0.043387153387096776,
      "loss": 0.6664,
      "step": 351140
    },
    {
      "epoch": 566.39,
      "learning_rate": 0.04338392758387097,
      "loss": 0.6762,
      "step": 351160
    },
    {
      "epoch": 566.42,
      "learning_rate": 0.04338070178064516,
      "loss": 0.6858,
      "step": 351180
    },
    {
      "epoch": 566.45,
      "learning_rate": 0.04337747597741936,
      "loss": 0.6658,
      "step": 351200
    },
    {
      "epoch": 566.48,
      "learning_rate": 0.04337425017419355,
      "loss": 0.6743,
      "step": 351220
    },
    {
      "epoch": 566.52,
      "learning_rate": 0.043371024370967744,
      "loss": 0.6831,
      "step": 351240
    },
    {
      "epoch": 566.55,
      "learning_rate": 0.04336779856774194,
      "loss": 0.684,
      "step": 351260
    },
    {
      "epoch": 566.58,
      "learning_rate": 0.043364572764516135,
      "loss": 0.7051,
      "step": 351280
    },
    {
      "epoch": 566.61,
      "learning_rate": 0.04336134696129033,
      "loss": 0.7022,
      "step": 351300
    },
    {
      "epoch": 566.65,
      "learning_rate": 0.043358121158064526,
      "loss": 0.6918,
      "step": 351320
    },
    {
      "epoch": 566.68,
      "learning_rate": 0.04335489535483872,
      "loss": 0.6907,
      "step": 351340
    },
    {
      "epoch": 566.71,
      "learning_rate": 0.04335166955161291,
      "loss": 0.6629,
      "step": 351360
    },
    {
      "epoch": 566.74,
      "learning_rate": 0.043348443748387096,
      "loss": 0.6738,
      "step": 351380
    },
    {
      "epoch": 566.77,
      "learning_rate": 0.04334521794516129,
      "loss": 0.653,
      "step": 351400
    },
    {
      "epoch": 566.81,
      "learning_rate": 0.04334199214193549,
      "loss": 0.6714,
      "step": 351420
    },
    {
      "epoch": 566.84,
      "learning_rate": 0.04333876633870968,
      "loss": 0.6793,
      "step": 351440
    },
    {
      "epoch": 566.87,
      "learning_rate": 0.04333554053548387,
      "loss": 0.7026,
      "step": 351460
    },
    {
      "epoch": 566.9,
      "learning_rate": 0.04333231473225806,
      "loss": 0.7,
      "step": 351480
    },
    {
      "epoch": 566.94,
      "learning_rate": 0.04332908892903226,
      "loss": 0.6791,
      "step": 351500
    },
    {
      "epoch": 566.97,
      "learning_rate": 0.043325863125806455,
      "loss": 0.6993,
      "step": 351520
    },
    {
      "epoch": 567.0,
      "learning_rate": 0.04332263732258065,
      "loss": 0.6786,
      "step": 351540
    },
    {
      "epoch": 567.0,
      "eval_accuracy": {
        "accuracy": 0.7648895480446491
      },
      "eval_loss": 1.0332496166229248,
      "eval_runtime": 2.861,
      "eval_samples_per_second": 4477.74,
      "eval_steps_per_second": 70.254,
      "step": 351540
    },
    {
      "epoch": 567.03,
      "learning_rate": 0.043319411519354846,
      "loss": 0.6826,
      "step": 351560
    },
    {
      "epoch": 567.06,
      "learning_rate": 0.04331618571612904,
      "loss": 0.6716,
      "step": 351580
    },
    {
      "epoch": 567.1,
      "learning_rate": 0.04331295991290323,
      "loss": 0.6706,
      "step": 351600
    },
    {
      "epoch": 567.13,
      "learning_rate": 0.04330973410967743,
      "loss": 0.6787,
      "step": 351620
    },
    {
      "epoch": 567.16,
      "learning_rate": 0.04330650830645162,
      "loss": 0.6607,
      "step": 351640
    },
    {
      "epoch": 567.19,
      "learning_rate": 0.043303282503225814,
      "loss": 0.6638,
      "step": 351660
    },
    {
      "epoch": 567.23,
      "learning_rate": 0.043300056700000006,
      "loss": 0.6569,
      "step": 351680
    },
    {
      "epoch": 567.26,
      "learning_rate": 0.04329683089677419,
      "loss": 0.6681,
      "step": 351700
    },
    {
      "epoch": 567.29,
      "learning_rate": 0.04329360509354838,
      "loss": 0.6776,
      "step": 351720
    },
    {
      "epoch": 567.32,
      "learning_rate": 0.04329037929032258,
      "loss": 0.6988,
      "step": 351740
    },
    {
      "epoch": 567.35,
      "learning_rate": 0.043287153487096774,
      "loss": 0.6781,
      "step": 351760
    },
    {
      "epoch": 567.39,
      "learning_rate": 0.04328392768387097,
      "loss": 0.678,
      "step": 351780
    },
    {
      "epoch": 567.42,
      "learning_rate": 0.043280701880645166,
      "loss": 0.6756,
      "step": 351800
    },
    {
      "epoch": 567.45,
      "learning_rate": 0.04327747607741936,
      "loss": 0.7026,
      "step": 351820
    },
    {
      "epoch": 567.48,
      "learning_rate": 0.04327425027419355,
      "loss": 0.6722,
      "step": 351840
    },
    {
      "epoch": 567.52,
      "learning_rate": 0.04327102447096775,
      "loss": 0.6552,
      "step": 351860
    },
    {
      "epoch": 567.55,
      "learning_rate": 0.04326779866774194,
      "loss": 0.6542,
      "step": 351880
    },
    {
      "epoch": 567.58,
      "learning_rate": 0.04326457286451613,
      "loss": 0.6799,
      "step": 351900
    },
    {
      "epoch": 567.61,
      "learning_rate": 0.04326134706129033,
      "loss": 0.6796,
      "step": 351920
    },
    {
      "epoch": 567.65,
      "learning_rate": 0.043258121258064525,
      "loss": 0.6866,
      "step": 351940
    },
    {
      "epoch": 567.68,
      "learning_rate": 0.04325489545483872,
      "loss": 0.6991,
      "step": 351960
    },
    {
      "epoch": 567.71,
      "learning_rate": 0.04325166965161291,
      "loss": 0.6964,
      "step": 351980
    },
    {
      "epoch": 567.74,
      "learning_rate": 0.04324844384838711,
      "loss": 0.6962,
      "step": 352000
    },
    {
      "epoch": 567.77,
      "learning_rate": 0.043245218045161286,
      "loss": 0.6896,
      "step": 352020
    },
    {
      "epoch": 567.81,
      "learning_rate": 0.043241992241935485,
      "loss": 0.6914,
      "step": 352040
    },
    {
      "epoch": 567.84,
      "learning_rate": 0.04323876643870968,
      "loss": 0.6831,
      "step": 352060
    },
    {
      "epoch": 567.87,
      "learning_rate": 0.04323554063548387,
      "loss": 0.6876,
      "step": 352080
    },
    {
      "epoch": 567.9,
      "learning_rate": 0.04323231483225807,
      "loss": 0.6835,
      "step": 352100
    },
    {
      "epoch": 567.94,
      "learning_rate": 0.04322908902903226,
      "loss": 0.6914,
      "step": 352120
    },
    {
      "epoch": 567.97,
      "learning_rate": 0.04322586322580645,
      "loss": 0.691,
      "step": 352140
    },
    {
      "epoch": 568.0,
      "learning_rate": 0.04322263742258065,
      "loss": 0.6867,
      "step": 352160
    },
    {
      "epoch": 568.0,
      "eval_accuracy": {
        "accuracy": 0.7652798376395286
      },
      "eval_loss": 1.0525962114334106,
      "eval_runtime": 2.8115,
      "eval_samples_per_second": 4556.63,
      "eval_steps_per_second": 71.492,
      "step": 352160
    },
    {
      "epoch": 568.03,
      "learning_rate": 0.043219411619354844,
      "loss": 0.6839,
      "step": 352180
    },
    {
      "epoch": 568.06,
      "learning_rate": 0.04321618581612904,
      "loss": 0.6898,
      "step": 352200
    },
    {
      "epoch": 568.1,
      "learning_rate": 0.04321296001290323,
      "loss": 0.6744,
      "step": 352220
    },
    {
      "epoch": 568.13,
      "learning_rate": 0.04320973420967743,
      "loss": 0.6603,
      "step": 352240
    },
    {
      "epoch": 568.16,
      "learning_rate": 0.04320650840645162,
      "loss": 0.6763,
      "step": 352260
    },
    {
      "epoch": 568.19,
      "learning_rate": 0.04320328260322581,
      "loss": 0.674,
      "step": 352280
    },
    {
      "epoch": 568.23,
      "learning_rate": 0.04320005680000001,
      "loss": 0.6626,
      "step": 352300
    },
    {
      "epoch": 568.26,
      "learning_rate": 0.04319683099677419,
      "loss": 0.6829,
      "step": 352320
    },
    {
      "epoch": 568.29,
      "learning_rate": 0.04319360519354839,
      "loss": 0.6746,
      "step": 352340
    },
    {
      "epoch": 568.32,
      "learning_rate": 0.04319037939032258,
      "loss": 0.6791,
      "step": 352360
    },
    {
      "epoch": 568.35,
      "learning_rate": 0.04318715358709677,
      "loss": 0.674,
      "step": 352380
    },
    {
      "epoch": 568.39,
      "learning_rate": 0.04318392778387097,
      "loss": 0.6898,
      "step": 352400
    },
    {
      "epoch": 568.42,
      "learning_rate": 0.043180701980645164,
      "loss": 0.6718,
      "step": 352420
    },
    {
      "epoch": 568.45,
      "learning_rate": 0.043177476177419356,
      "loss": 0.6933,
      "step": 352440
    },
    {
      "epoch": 568.48,
      "learning_rate": 0.043174250374193555,
      "loss": 0.6822,
      "step": 352460
    },
    {
      "epoch": 568.52,
      "learning_rate": 0.04317102457096775,
      "loss": 0.6756,
      "step": 352480
    },
    {
      "epoch": 568.55,
      "learning_rate": 0.04316779876774194,
      "loss": 0.6794,
      "step": 352500
    },
    {
      "epoch": 568.58,
      "learning_rate": 0.04316457296451613,
      "loss": 0.6786,
      "step": 352520
    },
    {
      "epoch": 568.61,
      "learning_rate": 0.04316134716129033,
      "loss": 0.6861,
      "step": 352540
    },
    {
      "epoch": 568.65,
      "learning_rate": 0.04315812135806452,
      "loss": 0.683,
      "step": 352560
    },
    {
      "epoch": 568.68,
      "learning_rate": 0.043154895554838715,
      "loss": 0.6885,
      "step": 352580
    },
    {
      "epoch": 568.71,
      "learning_rate": 0.043151669751612914,
      "loss": 0.6664,
      "step": 352600
    },
    {
      "epoch": 568.74,
      "learning_rate": 0.04314844394838711,
      "loss": 0.6715,
      "step": 352620
    },
    {
      "epoch": 568.77,
      "learning_rate": 0.04314521814516129,
      "loss": 0.6703,
      "step": 352640
    },
    {
      "epoch": 568.81,
      "learning_rate": 0.043141992341935484,
      "loss": 0.674,
      "step": 352660
    },
    {
      "epoch": 568.84,
      "learning_rate": 0.043138766538709676,
      "loss": 0.6712,
      "step": 352680
    },
    {
      "epoch": 568.87,
      "learning_rate": 0.043135540735483875,
      "loss": 0.6626,
      "step": 352700
    },
    {
      "epoch": 568.9,
      "learning_rate": 0.04313231493225807,
      "loss": 0.6848,
      "step": 352720
    },
    {
      "epoch": 568.94,
      "learning_rate": 0.04312908912903226,
      "loss": 0.7043,
      "step": 352740
    },
    {
      "epoch": 568.97,
      "learning_rate": 0.04312586332580645,
      "loss": 0.6924,
      "step": 352760
    },
    {
      "epoch": 569.0,
      "learning_rate": 0.04312263752258065,
      "loss": 0.6944,
      "step": 352780
    },
    {
      "epoch": 569.0,
      "eval_accuracy": {
        "accuracy": 0.760440246663024
      },
      "eval_loss": 1.0708119869232178,
      "eval_runtime": 2.8023,
      "eval_samples_per_second": 4571.604,
      "eval_steps_per_second": 71.727,
      "step": 352780
    },
    {
      "epoch": 569.03,
      "learning_rate": 0.04311941171935484,
      "loss": 0.7236,
      "step": 352800
    },
    {
      "epoch": 569.06,
      "learning_rate": 0.043116185916129035,
      "loss": 0.671,
      "step": 352820
    },
    {
      "epoch": 569.1,
      "learning_rate": 0.043112960112903234,
      "loss": 0.6659,
      "step": 352840
    },
    {
      "epoch": 569.13,
      "learning_rate": 0.043109734309677426,
      "loss": 0.661,
      "step": 352860
    },
    {
      "epoch": 569.16,
      "learning_rate": 0.04310650850645162,
      "loss": 0.6664,
      "step": 352880
    },
    {
      "epoch": 569.19,
      "learning_rate": 0.04310328270322582,
      "loss": 0.6748,
      "step": 352900
    },
    {
      "epoch": 569.23,
      "learning_rate": 0.04310005690000001,
      "loss": 0.668,
      "step": 352920
    },
    {
      "epoch": 569.26,
      "learning_rate": 0.043096831096774195,
      "loss": 0.6755,
      "step": 352940
    },
    {
      "epoch": 569.29,
      "learning_rate": 0.04309360529354839,
      "loss": 0.6646,
      "step": 352960
    },
    {
      "epoch": 569.32,
      "learning_rate": 0.04309037949032258,
      "loss": 0.6847,
      "step": 352980
    },
    {
      "epoch": 569.35,
      "learning_rate": 0.04308715368709678,
      "loss": 0.6847,
      "step": 353000
    },
    {
      "epoch": 569.39,
      "learning_rate": 0.04308392788387097,
      "loss": 0.67,
      "step": 353020
    },
    {
      "epoch": 569.42,
      "learning_rate": 0.04308070208064516,
      "loss": 0.6898,
      "step": 353040
    },
    {
      "epoch": 569.45,
      "learning_rate": 0.043077476277419355,
      "loss": 0.6754,
      "step": 353060
    },
    {
      "epoch": 569.48,
      "learning_rate": 0.043074250474193554,
      "loss": 0.6746,
      "step": 353080
    },
    {
      "epoch": 569.52,
      "learning_rate": 0.043071024670967746,
      "loss": 0.6632,
      "step": 353100
    },
    {
      "epoch": 569.55,
      "learning_rate": 0.04306779886774194,
      "loss": 0.6743,
      "step": 353120
    },
    {
      "epoch": 569.58,
      "learning_rate": 0.04306457306451614,
      "loss": 0.688,
      "step": 353140
    },
    {
      "epoch": 569.61,
      "learning_rate": 0.04306134726129033,
      "loss": 0.6735,
      "step": 353160
    },
    {
      "epoch": 569.65,
      "learning_rate": 0.04305812145806452,
      "loss": 0.6896,
      "step": 353180
    },
    {
      "epoch": 569.68,
      "learning_rate": 0.04305489565483872,
      "loss": 0.6915,
      "step": 353200
    },
    {
      "epoch": 569.71,
      "learning_rate": 0.04305166985161291,
      "loss": 0.7013,
      "step": 353220
    },
    {
      "epoch": 569.74,
      "learning_rate": 0.043048444048387105,
      "loss": 0.6778,
      "step": 353240
    },
    {
      "epoch": 569.77,
      "learning_rate": 0.04304521824516129,
      "loss": 0.7116,
      "step": 353260
    },
    {
      "epoch": 569.81,
      "learning_rate": 0.04304199244193548,
      "loss": 0.7016,
      "step": 353280
    },
    {
      "epoch": 569.84,
      "learning_rate": 0.043038766638709675,
      "loss": 0.6917,
      "step": 353300
    },
    {
      "epoch": 569.87,
      "learning_rate": 0.043035540835483874,
      "loss": 0.6831,
      "step": 353320
    },
    {
      "epoch": 569.9,
      "learning_rate": 0.043032315032258066,
      "loss": 0.6823,
      "step": 353340
    },
    {
      "epoch": 569.94,
      "learning_rate": 0.04302908922903226,
      "loss": 0.6744,
      "step": 353360
    },
    {
      "epoch": 569.97,
      "learning_rate": 0.04302586342580646,
      "loss": 0.6795,
      "step": 353380
    },
    {
      "epoch": 570.0,
      "learning_rate": 0.04302279891274193,
      "loss": 0.6876,
      "step": 353400
    },
    {
      "epoch": 570.0,
      "eval_accuracy": {
        "accuracy": 0.7691827335883226
      },
      "eval_loss": 1.0302352905273438,
      "eval_runtime": 3.1973,
      "eval_samples_per_second": 4006.88,
      "eval_steps_per_second": 62.867,
      "step": 353400
    },
    {
      "epoch": 570.03,
      "learning_rate": 0.04301957310951613,
      "loss": 0.6715,
      "step": 353420
    },
    {
      "epoch": 570.06,
      "learning_rate": 0.04301634730629032,
      "loss": 0.6731,
      "step": 353440
    },
    {
      "epoch": 570.1,
      "learning_rate": 0.043013121503064515,
      "loss": 0.6745,
      "step": 353460
    },
    {
      "epoch": 570.13,
      "learning_rate": 0.043009895699838714,
      "loss": 0.6579,
      "step": 353480
    },
    {
      "epoch": 570.16,
      "learning_rate": 0.043006669896612906,
      "loss": 0.6654,
      "step": 353500
    },
    {
      "epoch": 570.19,
      "learning_rate": 0.0430034440933871,
      "loss": 0.6701,
      "step": 353520
    },
    {
      "epoch": 570.23,
      "learning_rate": 0.0430002182901613,
      "loss": 0.6866,
      "step": 353540
    },
    {
      "epoch": 570.26,
      "learning_rate": 0.04299699248693549,
      "loss": 0.6707,
      "step": 353560
    },
    {
      "epoch": 570.29,
      "learning_rate": 0.04299376668370968,
      "loss": 0.6665,
      "step": 353580
    },
    {
      "epoch": 570.32,
      "learning_rate": 0.042990540880483874,
      "loss": 0.6848,
      "step": 353600
    },
    {
      "epoch": 570.35,
      "learning_rate": 0.04298731507725807,
      "loss": 0.6623,
      "step": 353620
    },
    {
      "epoch": 570.39,
      "learning_rate": 0.042984089274032265,
      "loss": 0.6753,
      "step": 353640
    },
    {
      "epoch": 570.42,
      "learning_rate": 0.04298086347080646,
      "loss": 0.6546,
      "step": 353660
    },
    {
      "epoch": 570.45,
      "learning_rate": 0.042977637667580657,
      "loss": 0.6726,
      "step": 353680
    },
    {
      "epoch": 570.48,
      "learning_rate": 0.042974411864354835,
      "loss": 0.6689,
      "step": 353700
    },
    {
      "epoch": 570.52,
      "learning_rate": 0.042971186061129034,
      "loss": 0.6701,
      "step": 353720
    },
    {
      "epoch": 570.55,
      "learning_rate": 0.042967960257903226,
      "loss": 0.6801,
      "step": 353740
    },
    {
      "epoch": 570.58,
      "learning_rate": 0.04296473445467742,
      "loss": 0.6869,
      "step": 353760
    },
    {
      "epoch": 570.61,
      "learning_rate": 0.04296150865145162,
      "loss": 0.6657,
      "step": 353780
    },
    {
      "epoch": 570.65,
      "learning_rate": 0.04295828284822581,
      "loss": 0.6758,
      "step": 353800
    },
    {
      "epoch": 570.68,
      "learning_rate": 0.042955057045,
      "loss": 0.6769,
      "step": 353820
    },
    {
      "epoch": 570.71,
      "learning_rate": 0.042951831241774194,
      "loss": 0.6722,
      "step": 353840
    },
    {
      "epoch": 570.74,
      "learning_rate": 0.04294860543854839,
      "loss": 0.681,
      "step": 353860
    },
    {
      "epoch": 570.77,
      "learning_rate": 0.042945379635322585,
      "loss": 0.6855,
      "step": 353880
    },
    {
      "epoch": 570.81,
      "learning_rate": 0.04294215383209678,
      "loss": 0.6934,
      "step": 353900
    },
    {
      "epoch": 570.84,
      "learning_rate": 0.042938928028870976,
      "loss": 0.6813,
      "step": 353920
    },
    {
      "epoch": 570.87,
      "learning_rate": 0.04293570222564517,
      "loss": 0.6779,
      "step": 353940
    },
    {
      "epoch": 570.9,
      "learning_rate": 0.04293247642241936,
      "loss": 0.6805,
      "step": 353960
    },
    {
      "epoch": 570.94,
      "learning_rate": 0.04292925061919356,
      "loss": 0.676,
      "step": 353980
    },
    {
      "epoch": 570.97,
      "learning_rate": 0.04292602481596775,
      "loss": 0.6824,
      "step": 354000
    },
    {
      "epoch": 571.0,
      "learning_rate": 0.04292279901274194,
      "loss": 0.6769,
      "step": 354020
    },
    {
      "epoch": 571.0,
      "eval_accuracy": {
        "accuracy": 0.763640621341035
      },
      "eval_loss": 1.0520188808441162,
      "eval_runtime": 3.3068,
      "eval_samples_per_second": 3874.113,
      "eval_steps_per_second": 60.783,
      "step": 354020
    },
    {
      "epoch": 571.03,
      "learning_rate": 0.04291957320951613,
      "loss": 0.685,
      "step": 354040
    },
    {
      "epoch": 571.06,
      "learning_rate": 0.04291634740629032,
      "loss": 0.6732,
      "step": 354060
    },
    {
      "epoch": 571.1,
      "learning_rate": 0.04291312160306452,
      "loss": 0.6638,
      "step": 354080
    },
    {
      "epoch": 571.13,
      "learning_rate": 0.04290989579983871,
      "loss": 0.669,
      "step": 354100
    },
    {
      "epoch": 571.16,
      "learning_rate": 0.042906669996612905,
      "loss": 0.6535,
      "step": 354120
    },
    {
      "epoch": 571.19,
      "learning_rate": 0.0429034441933871,
      "loss": 0.6634,
      "step": 354140
    },
    {
      "epoch": 571.23,
      "learning_rate": 0.042900218390161296,
      "loss": 0.6646,
      "step": 354160
    },
    {
      "epoch": 571.26,
      "learning_rate": 0.04289699258693549,
      "loss": 0.6682,
      "step": 354180
    },
    {
      "epoch": 571.29,
      "learning_rate": 0.04289376678370968,
      "loss": 0.6733,
      "step": 354200
    },
    {
      "epoch": 571.32,
      "learning_rate": 0.04289054098048388,
      "loss": 0.6734,
      "step": 354220
    },
    {
      "epoch": 571.35,
      "learning_rate": 0.04288731517725807,
      "loss": 0.6822,
      "step": 354240
    },
    {
      "epoch": 571.39,
      "learning_rate": 0.042884089374032264,
      "loss": 0.6852,
      "step": 354260
    },
    {
      "epoch": 571.42,
      "learning_rate": 0.04288086357080646,
      "loss": 0.6774,
      "step": 354280
    },
    {
      "epoch": 571.45,
      "learning_rate": 0.042877637767580655,
      "loss": 0.6682,
      "step": 354300
    },
    {
      "epoch": 571.48,
      "learning_rate": 0.04287441196435485,
      "loss": 0.6699,
      "step": 354320
    },
    {
      "epoch": 571.52,
      "learning_rate": 0.04287118616112903,
      "loss": 0.6867,
      "step": 354340
    },
    {
      "epoch": 571.55,
      "learning_rate": 0.042867960357903225,
      "loss": 0.6896,
      "step": 354360
    },
    {
      "epoch": 571.58,
      "learning_rate": 0.04286473455467742,
      "loss": 0.6789,
      "step": 354380
    },
    {
      "epoch": 571.61,
      "learning_rate": 0.042861508751451616,
      "loss": 0.6824,
      "step": 354400
    },
    {
      "epoch": 571.65,
      "learning_rate": 0.04285828294822581,
      "loss": 0.6792,
      "step": 354420
    },
    {
      "epoch": 571.68,
      "learning_rate": 0.042855057145,
      "loss": 0.6879,
      "step": 354440
    },
    {
      "epoch": 571.71,
      "learning_rate": 0.0428518313417742,
      "loss": 0.6827,
      "step": 354460
    },
    {
      "epoch": 571.74,
      "learning_rate": 0.04284860553854839,
      "loss": 0.677,
      "step": 354480
    },
    {
      "epoch": 571.77,
      "learning_rate": 0.042845379735322583,
      "loss": 0.6847,
      "step": 354500
    },
    {
      "epoch": 571.81,
      "learning_rate": 0.04284215393209678,
      "loss": 0.6982,
      "step": 354520
    },
    {
      "epoch": 571.84,
      "learning_rate": 0.042838928128870975,
      "loss": 0.656,
      "step": 354540
    },
    {
      "epoch": 571.87,
      "learning_rate": 0.04283570232564517,
      "loss": 0.6709,
      "step": 354560
    },
    {
      "epoch": 571.9,
      "learning_rate": 0.04283247652241936,
      "loss": 0.6712,
      "step": 354580
    },
    {
      "epoch": 571.94,
      "learning_rate": 0.04282925071919356,
      "loss": 0.6746,
      "step": 354600
    },
    {
      "epoch": 571.97,
      "learning_rate": 0.04282602491596775,
      "loss": 0.6765,
      "step": 354620
    },
    {
      "epoch": 572.0,
      "learning_rate": 0.042822799112741936,
      "loss": 0.6972,
      "step": 354640
    },
    {
      "epoch": 572.0,
      "eval_accuracy": {
        "accuracy": 0.7633283896651315
      },
      "eval_loss": 1.0588780641555786,
      "eval_runtime": 3.2262,
      "eval_samples_per_second": 3970.871,
      "eval_steps_per_second": 62.302,
      "step": 354640
    },
    {
      "epoch": 572.03,
      "learning_rate": 0.04281957330951613,
      "loss": 0.6927,
      "step": 354660
    },
    {
      "epoch": 572.06,
      "learning_rate": 0.04281634750629032,
      "loss": 0.6717,
      "step": 354680
    },
    {
      "epoch": 572.1,
      "learning_rate": 0.04281312170306452,
      "loss": 0.6627,
      "step": 354700
    },
    {
      "epoch": 572.13,
      "learning_rate": 0.04280989589983871,
      "loss": 0.665,
      "step": 354720
    },
    {
      "epoch": 572.16,
      "learning_rate": 0.0428066700966129,
      "loss": 0.6639,
      "step": 354740
    },
    {
      "epoch": 572.19,
      "learning_rate": 0.0428034442933871,
      "loss": 0.6797,
      "step": 354760
    },
    {
      "epoch": 572.23,
      "learning_rate": 0.042800218490161294,
      "loss": 0.6743,
      "step": 354780
    },
    {
      "epoch": 572.26,
      "learning_rate": 0.04279699268693549,
      "loss": 0.674,
      "step": 354800
    },
    {
      "epoch": 572.29,
      "learning_rate": 0.042793766883709686,
      "loss": 0.6866,
      "step": 354820
    },
    {
      "epoch": 572.32,
      "learning_rate": 0.04279054108048388,
      "loss": 0.6669,
      "step": 354840
    },
    {
      "epoch": 572.35,
      "learning_rate": 0.04278731527725807,
      "loss": 0.6771,
      "step": 354860
    },
    {
      "epoch": 572.39,
      "learning_rate": 0.04278408947403226,
      "loss": 0.6625,
      "step": 354880
    },
    {
      "epoch": 572.42,
      "learning_rate": 0.04278086367080646,
      "loss": 0.6982,
      "step": 354900
    },
    {
      "epoch": 572.45,
      "learning_rate": 0.04277763786758065,
      "loss": 0.6804,
      "step": 354920
    },
    {
      "epoch": 572.48,
      "learning_rate": 0.042774412064354846,
      "loss": 0.6757,
      "step": 354940
    },
    {
      "epoch": 572.52,
      "learning_rate": 0.04277118626112903,
      "loss": 0.6791,
      "step": 354960
    },
    {
      "epoch": 572.55,
      "learning_rate": 0.04276796045790322,
      "loss": 0.6875,
      "step": 354980
    },
    {
      "epoch": 572.58,
      "learning_rate": 0.04276473465467742,
      "loss": 0.6743,
      "step": 355000
    },
    {
      "epoch": 572.61,
      "learning_rate": 0.042761508851451614,
      "loss": 0.6657,
      "step": 355020
    },
    {
      "epoch": 572.65,
      "learning_rate": 0.042758283048225806,
      "loss": 0.6865,
      "step": 355040
    },
    {
      "epoch": 572.68,
      "learning_rate": 0.042755057245000005,
      "loss": 0.6855,
      "step": 355060
    },
    {
      "epoch": 572.71,
      "learning_rate": 0.0427518314417742,
      "loss": 0.6757,
      "step": 355080
    },
    {
      "epoch": 572.74,
      "learning_rate": 0.04274860563854839,
      "loss": 0.6701,
      "step": 355100
    },
    {
      "epoch": 572.77,
      "learning_rate": 0.04274537983532258,
      "loss": 0.6742,
      "step": 355120
    },
    {
      "epoch": 572.81,
      "learning_rate": 0.04274215403209678,
      "loss": 0.6692,
      "step": 355140
    },
    {
      "epoch": 572.84,
      "learning_rate": 0.04273892822887097,
      "loss": 0.6874,
      "step": 355160
    },
    {
      "epoch": 572.87,
      "learning_rate": 0.042735702425645165,
      "loss": 0.6742,
      "step": 355180
    },
    {
      "epoch": 572.9,
      "learning_rate": 0.042732476622419364,
      "loss": 0.6829,
      "step": 355200
    },
    {
      "epoch": 572.94,
      "learning_rate": 0.04272925081919356,
      "loss": 0.6942,
      "step": 355220
    },
    {
      "epoch": 572.97,
      "learning_rate": 0.04272602501596775,
      "loss": 0.6924,
      "step": 355240
    },
    {
      "epoch": 573.0,
      "learning_rate": 0.042722799212741934,
      "loss": 0.6876,
      "step": 355260
    },
    {
      "epoch": 573.0,
      "eval_accuracy": {
        "accuracy": 0.7602841308250722
      },
      "eval_loss": 1.0668365955352783,
      "eval_runtime": 2.9023,
      "eval_samples_per_second": 4414.06,
      "eval_steps_per_second": 69.255,
      "step": 355260
    },
    {
      "epoch": 573.03,
      "learning_rate": 0.042719573409516126,
      "loss": 0.6894,
      "step": 355280
    },
    {
      "epoch": 573.06,
      "learning_rate": 0.042716347606290325,
      "loss": 0.6696,
      "step": 355300
    },
    {
      "epoch": 573.1,
      "learning_rate": 0.04271312180306452,
      "loss": 0.6584,
      "step": 355320
    },
    {
      "epoch": 573.13,
      "learning_rate": 0.04270989599983871,
      "loss": 0.6628,
      "step": 355340
    },
    {
      "epoch": 573.16,
      "learning_rate": 0.04270667019661291,
      "loss": 0.669,
      "step": 355360
    },
    {
      "epoch": 573.19,
      "learning_rate": 0.0427034443933871,
      "loss": 0.6646,
      "step": 355380
    },
    {
      "epoch": 573.23,
      "learning_rate": 0.04270021859016129,
      "loss": 0.664,
      "step": 355400
    },
    {
      "epoch": 573.26,
      "learning_rate": 0.042696992786935485,
      "loss": 0.6623,
      "step": 355420
    },
    {
      "epoch": 573.29,
      "learning_rate": 0.042693766983709684,
      "loss": 0.6667,
      "step": 355440
    },
    {
      "epoch": 573.32,
      "learning_rate": 0.042690541180483876,
      "loss": 0.6823,
      "step": 355460
    },
    {
      "epoch": 573.35,
      "learning_rate": 0.04268731537725807,
      "loss": 0.6844,
      "step": 355480
    },
    {
      "epoch": 573.39,
      "learning_rate": 0.04268408957403227,
      "loss": 0.6894,
      "step": 355500
    },
    {
      "epoch": 573.42,
      "learning_rate": 0.04268086377080646,
      "loss": 0.6757,
      "step": 355520
    },
    {
      "epoch": 573.45,
      "learning_rate": 0.04267763796758065,
      "loss": 0.673,
      "step": 355540
    },
    {
      "epoch": 573.48,
      "learning_rate": 0.04267441216435485,
      "loss": 0.694,
      "step": 355560
    },
    {
      "epoch": 573.52,
      "learning_rate": 0.04267118636112903,
      "loss": 0.6833,
      "step": 355580
    },
    {
      "epoch": 573.55,
      "learning_rate": 0.04266796055790323,
      "loss": 0.6724,
      "step": 355600
    },
    {
      "epoch": 573.58,
      "learning_rate": 0.04266473475467742,
      "loss": 0.6881,
      "step": 355620
    },
    {
      "epoch": 573.61,
      "learning_rate": 0.04266150895145161,
      "loss": 0.6628,
      "step": 355640
    },
    {
      "epoch": 573.65,
      "learning_rate": 0.042658283148225805,
      "loss": 0.6892,
      "step": 355660
    },
    {
      "epoch": 573.68,
      "learning_rate": 0.042655057345000004,
      "loss": 0.6801,
      "step": 355680
    },
    {
      "epoch": 573.71,
      "learning_rate": 0.042651831541774196,
      "loss": 0.6825,
      "step": 355700
    },
    {
      "epoch": 573.74,
      "learning_rate": 0.04264860573854839,
      "loss": 0.6894,
      "step": 355720
    },
    {
      "epoch": 573.77,
      "learning_rate": 0.04264537993532259,
      "loss": 0.6886,
      "step": 355740
    },
    {
      "epoch": 573.81,
      "learning_rate": 0.04264215413209678,
      "loss": 0.688,
      "step": 355760
    },
    {
      "epoch": 573.84,
      "learning_rate": 0.04263892832887097,
      "loss": 0.6705,
      "step": 355780
    },
    {
      "epoch": 573.87,
      "learning_rate": 0.04263570252564517,
      "loss": 0.6742,
      "step": 355800
    },
    {
      "epoch": 573.9,
      "learning_rate": 0.04263247672241936,
      "loss": 0.6693,
      "step": 355820
    },
    {
      "epoch": 573.94,
      "learning_rate": 0.042629250919193555,
      "loss": 0.6851,
      "step": 355840
    },
    {
      "epoch": 573.97,
      "learning_rate": 0.042626025115967754,
      "loss": 0.6699,
      "step": 355860
    },
    {
      "epoch": 574.0,
      "learning_rate": 0.04262296060290323,
      "loss": 0.6854,
      "step": 355880
    },
    {
      "epoch": 574.0,
      "eval_accuracy": {
        "accuracy": 0.7598938412301928
      },
      "eval_loss": 1.0468695163726807,
      "eval_runtime": 4.0092,
      "eval_samples_per_second": 3195.414,
      "eval_steps_per_second": 50.135,
      "step": 355880
    },
    {
      "epoch": 574.03,
      "learning_rate": 0.04261973479967743,
      "loss": 0.6506,
      "step": 355900
    },
    {
      "epoch": 574.06,
      "learning_rate": 0.04261650899645162,
      "loss": 0.6482,
      "step": 355920
    },
    {
      "epoch": 574.1,
      "learning_rate": 0.04261328319322581,
      "loss": 0.6693,
      "step": 355940
    },
    {
      "epoch": 574.13,
      "learning_rate": 0.042610057390000004,
      "loss": 0.6582,
      "step": 355960
    },
    {
      "epoch": 574.16,
      "learning_rate": 0.0426068315867742,
      "loss": 0.6911,
      "step": 355980
    },
    {
      "epoch": 574.19,
      "learning_rate": 0.042603605783548396,
      "loss": 0.6769,
      "step": 356000
    },
    {
      "epoch": 574.23,
      "learning_rate": 0.04260037998032258,
      "loss": 0.6877,
      "step": 356020
    },
    {
      "epoch": 574.26,
      "learning_rate": 0.04259715417709677,
      "loss": 0.6878,
      "step": 356040
    },
    {
      "epoch": 574.29,
      "learning_rate": 0.042593928373870965,
      "loss": 0.6719,
      "step": 356060
    },
    {
      "epoch": 574.32,
      "learning_rate": 0.042590702570645164,
      "loss": 0.6685,
      "step": 356080
    },
    {
      "epoch": 574.35,
      "learning_rate": 0.042587476767419356,
      "loss": 0.664,
      "step": 356100
    },
    {
      "epoch": 574.39,
      "learning_rate": 0.04258425096419355,
      "loss": 0.6696,
      "step": 356120
    },
    {
      "epoch": 574.42,
      "learning_rate": 0.04258102516096775,
      "loss": 0.6788,
      "step": 356140
    },
    {
      "epoch": 574.45,
      "learning_rate": 0.04257779935774194,
      "loss": 0.671,
      "step": 356160
    },
    {
      "epoch": 574.48,
      "learning_rate": 0.04257457355451613,
      "loss": 0.6557,
      "step": 356180
    },
    {
      "epoch": 574.52,
      "learning_rate": 0.042571347751290324,
      "loss": 0.6775,
      "step": 356200
    },
    {
      "epoch": 574.55,
      "learning_rate": 0.04256812194806452,
      "loss": 0.6856,
      "step": 356220
    },
    {
      "epoch": 574.58,
      "learning_rate": 0.042564896144838715,
      "loss": 0.6662,
      "step": 356240
    },
    {
      "epoch": 574.61,
      "learning_rate": 0.04256167034161291,
      "loss": 0.6799,
      "step": 356260
    },
    {
      "epoch": 574.65,
      "learning_rate": 0.04255844453838711,
      "loss": 0.6673,
      "step": 356280
    },
    {
      "epoch": 574.68,
      "learning_rate": 0.0425552187351613,
      "loss": 0.6908,
      "step": 356300
    },
    {
      "epoch": 574.71,
      "learning_rate": 0.04255199293193549,
      "loss": 0.6769,
      "step": 356320
    },
    {
      "epoch": 574.74,
      "learning_rate": 0.042548767128709676,
      "loss": 0.6755,
      "step": 356340
    },
    {
      "epoch": 574.77,
      "learning_rate": 0.04254554132548387,
      "loss": 0.6896,
      "step": 356360
    },
    {
      "epoch": 574.81,
      "learning_rate": 0.04254231552225807,
      "loss": 0.6784,
      "step": 356380
    },
    {
      "epoch": 574.84,
      "learning_rate": 0.04253908971903226,
      "loss": 0.6673,
      "step": 356400
    },
    {
      "epoch": 574.87,
      "learning_rate": 0.04253586391580645,
      "loss": 0.6759,
      "step": 356420
    },
    {
      "epoch": 574.9,
      "learning_rate": 0.04253263811258065,
      "loss": 0.6947,
      "step": 356440
    },
    {
      "epoch": 574.94,
      "learning_rate": 0.04252941230935484,
      "loss": 0.6813,
      "step": 356460
    },
    {
      "epoch": 574.97,
      "learning_rate": 0.042526186506129035,
      "loss": 0.6947,
      "step": 356480
    },
    {
      "epoch": 575.0,
      "learning_rate": 0.04252296070290323,
      "loss": 0.696,
      "step": 356500
    },
    {
      "epoch": 575.0,
      "eval_accuracy": {
        "accuracy": 0.7648895480446491
      },
      "eval_loss": 1.058518409729004,
      "eval_runtime": 3.3379,
      "eval_samples_per_second": 3838.019,
      "eval_steps_per_second": 60.217,
      "step": 356500
    },
    {
      "epoch": 575.03,
      "learning_rate": 0.042519734899677426,
      "loss": 0.7041,
      "step": 356520
    },
    {
      "epoch": 575.06,
      "learning_rate": 0.04251650909645162,
      "loss": 0.6754,
      "step": 356540
    },
    {
      "epoch": 575.1,
      "learning_rate": 0.04251328329322581,
      "loss": 0.655,
      "step": 356560
    },
    {
      "epoch": 575.13,
      "learning_rate": 0.04251005749000001,
      "loss": 0.6648,
      "step": 356580
    },
    {
      "epoch": 575.16,
      "learning_rate": 0.0425068316867742,
      "loss": 0.6641,
      "step": 356600
    },
    {
      "epoch": 575.19,
      "learning_rate": 0.042503605883548394,
      "loss": 0.6709,
      "step": 356620
    },
    {
      "epoch": 575.23,
      "learning_rate": 0.04250038008032259,
      "loss": 0.6635,
      "step": 356640
    },
    {
      "epoch": 575.26,
      "learning_rate": 0.04249715427709677,
      "loss": 0.6955,
      "step": 356660
    },
    {
      "epoch": 575.29,
      "learning_rate": 0.04249392847387097,
      "loss": 0.6771,
      "step": 356680
    },
    {
      "epoch": 575.32,
      "learning_rate": 0.04249070267064516,
      "loss": 0.6691,
      "step": 356700
    },
    {
      "epoch": 575.35,
      "learning_rate": 0.042487476867419355,
      "loss": 0.6758,
      "step": 356720
    },
    {
      "epoch": 575.39,
      "learning_rate": 0.04248425106419355,
      "loss": 0.6783,
      "step": 356740
    },
    {
      "epoch": 575.42,
      "learning_rate": 0.042481025260967746,
      "loss": 0.6662,
      "step": 356760
    },
    {
      "epoch": 575.45,
      "learning_rate": 0.04247779945774194,
      "loss": 0.6618,
      "step": 356780
    },
    {
      "epoch": 575.48,
      "learning_rate": 0.04247457365451613,
      "loss": 0.6763,
      "step": 356800
    },
    {
      "epoch": 575.52,
      "learning_rate": 0.04247134785129033,
      "loss": 0.6722,
      "step": 356820
    },
    {
      "epoch": 575.55,
      "learning_rate": 0.04246812204806452,
      "loss": 0.6848,
      "step": 356840
    },
    {
      "epoch": 575.58,
      "learning_rate": 0.042464896244838714,
      "loss": 0.6854,
      "step": 356860
    },
    {
      "epoch": 575.61,
      "learning_rate": 0.04246167044161291,
      "loss": 0.6885,
      "step": 356880
    },
    {
      "epoch": 575.65,
      "learning_rate": 0.042458444638387105,
      "loss": 0.6517,
      "step": 356900
    },
    {
      "epoch": 575.68,
      "learning_rate": 0.0424552188351613,
      "loss": 0.6723,
      "step": 356920
    },
    {
      "epoch": 575.71,
      "learning_rate": 0.042451993031935496,
      "loss": 0.6759,
      "step": 356940
    },
    {
      "epoch": 575.74,
      "learning_rate": 0.042448767228709675,
      "loss": 0.6821,
      "step": 356960
    },
    {
      "epoch": 575.77,
      "learning_rate": 0.042445541425483874,
      "loss": 0.6784,
      "step": 356980
    },
    {
      "epoch": 575.81,
      "learning_rate": 0.042442315622258066,
      "loss": 0.6752,
      "step": 357000
    },
    {
      "epoch": 575.84,
      "learning_rate": 0.04243908981903226,
      "loss": 0.6827,
      "step": 357020
    },
    {
      "epoch": 575.87,
      "learning_rate": 0.04243586401580645,
      "loss": 0.697,
      "step": 357040
    },
    {
      "epoch": 575.9,
      "learning_rate": 0.04243263821258065,
      "loss": 0.6922,
      "step": 357060
    },
    {
      "epoch": 575.94,
      "learning_rate": 0.04242941240935484,
      "loss": 0.6831,
      "step": 357080
    },
    {
      "epoch": 575.97,
      "learning_rate": 0.042426186606129034,
      "loss": 0.6638,
      "step": 357100
    },
    {
      "epoch": 576.0,
      "learning_rate": 0.04242296080290323,
      "loss": 0.6839,
      "step": 357120
    },
    {
      "epoch": 576.0,
      "eval_accuracy": {
        "accuracy": 0.7671532276949496
      },
      "eval_loss": 1.0333937406539917,
      "eval_runtime": 2.943,
      "eval_samples_per_second": 4353.109,
      "eval_steps_per_second": 68.299,
      "step": 357120
    },
    {
      "epoch": 576.03,
      "learning_rate": 0.042419734999677425,
      "loss": 0.6798,
      "step": 357140
    },
    {
      "epoch": 576.06,
      "learning_rate": 0.04241650919645162,
      "loss": 0.6643,
      "step": 357160
    },
    {
      "epoch": 576.1,
      "learning_rate": 0.042413283393225816,
      "loss": 0.6661,
      "step": 357180
    },
    {
      "epoch": 576.13,
      "learning_rate": 0.04241005759000001,
      "loss": 0.6618,
      "step": 357200
    },
    {
      "epoch": 576.16,
      "learning_rate": 0.0424068317867742,
      "loss": 0.6702,
      "step": 357220
    },
    {
      "epoch": 576.19,
      "learning_rate": 0.04240360598354839,
      "loss": 0.681,
      "step": 357240
    },
    {
      "epoch": 576.23,
      "learning_rate": 0.04240038018032259,
      "loss": 0.6734,
      "step": 357260
    },
    {
      "epoch": 576.26,
      "learning_rate": 0.04239715437709677,
      "loss": 0.6772,
      "step": 357280
    },
    {
      "epoch": 576.29,
      "learning_rate": 0.04239392857387097,
      "loss": 0.6839,
      "step": 357300
    },
    {
      "epoch": 576.32,
      "learning_rate": 0.04239070277064516,
      "loss": 0.6546,
      "step": 357320
    },
    {
      "epoch": 576.35,
      "learning_rate": 0.04238747696741935,
      "loss": 0.6684,
      "step": 357340
    },
    {
      "epoch": 576.39,
      "learning_rate": 0.04238425116419355,
      "loss": 0.6789,
      "step": 357360
    },
    {
      "epoch": 576.42,
      "learning_rate": 0.042381025360967745,
      "loss": 0.6679,
      "step": 357380
    },
    {
      "epoch": 576.45,
      "learning_rate": 0.04237779955774194,
      "loss": 0.664,
      "step": 357400
    },
    {
      "epoch": 576.48,
      "learning_rate": 0.042374573754516136,
      "loss": 0.6774,
      "step": 357420
    },
    {
      "epoch": 576.52,
      "learning_rate": 0.04237134795129033,
      "loss": 0.6642,
      "step": 357440
    },
    {
      "epoch": 576.55,
      "learning_rate": 0.04236812214806452,
      "loss": 0.6642,
      "step": 357460
    },
    {
      "epoch": 576.58,
      "learning_rate": 0.04236489634483872,
      "loss": 0.6885,
      "step": 357480
    },
    {
      "epoch": 576.61,
      "learning_rate": 0.04236167054161291,
      "loss": 0.7018,
      "step": 357500
    },
    {
      "epoch": 576.65,
      "learning_rate": 0.042358444738387104,
      "loss": 0.6777,
      "step": 357520
    },
    {
      "epoch": 576.68,
      "learning_rate": 0.042355218935161296,
      "loss": 0.6785,
      "step": 357540
    },
    {
      "epoch": 576.71,
      "learning_rate": 0.042351993131935495,
      "loss": 0.7078,
      "step": 357560
    },
    {
      "epoch": 576.74,
      "learning_rate": 0.04234876732870967,
      "loss": 0.6838,
      "step": 357580
    },
    {
      "epoch": 576.77,
      "learning_rate": 0.04234554152548387,
      "loss": 0.6693,
      "step": 357600
    },
    {
      "epoch": 576.81,
      "learning_rate": 0.042342315722258064,
      "loss": 0.6763,
      "step": 357620
    },
    {
      "epoch": 576.84,
      "learning_rate": 0.042339089919032256,
      "loss": 0.6866,
      "step": 357640
    },
    {
      "epoch": 576.87,
      "learning_rate": 0.042335864115806456,
      "loss": 0.6956,
      "step": 357660
    },
    {
      "epoch": 576.9,
      "learning_rate": 0.04233263831258065,
      "loss": 0.6838,
      "step": 357680
    },
    {
      "epoch": 576.94,
      "learning_rate": 0.04232941250935484,
      "loss": 0.6758,
      "step": 357700
    },
    {
      "epoch": 576.97,
      "learning_rate": 0.04232618670612904,
      "loss": 0.6584,
      "step": 357720
    },
    {
      "epoch": 577.0,
      "learning_rate": 0.04232296090290323,
      "loss": 0.6704,
      "step": 357740
    },
    {
      "epoch": 577.0,
      "eval_accuracy": {
        "accuracy": 0.770197486535009
      },
      "eval_loss": 1.046690821647644,
      "eval_runtime": 2.9023,
      "eval_samples_per_second": 4414.029,
      "eval_steps_per_second": 69.255,
      "step": 357740
    },
    {
      "epoch": 577.03,
      "learning_rate": 0.04231973509967742,
      "loss": 0.6933,
      "step": 357760
    },
    {
      "epoch": 577.06,
      "learning_rate": 0.042316509296451615,
      "loss": 0.6623,
      "step": 357780
    },
    {
      "epoch": 577.1,
      "learning_rate": 0.042313283493225815,
      "loss": 0.6666,
      "step": 357800
    },
    {
      "epoch": 577.13,
      "learning_rate": 0.04231005769000001,
      "loss": 0.6569,
      "step": 357820
    },
    {
      "epoch": 577.16,
      "learning_rate": 0.0423068318867742,
      "loss": 0.6629,
      "step": 357840
    },
    {
      "epoch": 577.19,
      "learning_rate": 0.0423036060835484,
      "loss": 0.6633,
      "step": 357860
    },
    {
      "epoch": 577.23,
      "learning_rate": 0.04230038028032259,
      "loss": 0.6521,
      "step": 357880
    },
    {
      "epoch": 577.26,
      "learning_rate": 0.042297154477096775,
      "loss": 0.6618,
      "step": 357900
    },
    {
      "epoch": 577.29,
      "learning_rate": 0.04229392867387097,
      "loss": 0.6578,
      "step": 357920
    },
    {
      "epoch": 577.32,
      "learning_rate": 0.04229070287064516,
      "loss": 0.6851,
      "step": 357940
    },
    {
      "epoch": 577.35,
      "learning_rate": 0.04228747706741936,
      "loss": 0.6731,
      "step": 357960
    },
    {
      "epoch": 577.39,
      "learning_rate": 0.04228425126419355,
      "loss": 0.6699,
      "step": 357980
    },
    {
      "epoch": 577.42,
      "learning_rate": 0.04228102546096774,
      "loss": 0.6657,
      "step": 358000
    },
    {
      "epoch": 577.45,
      "learning_rate": 0.04227779965774194,
      "loss": 0.6762,
      "step": 358020
    },
    {
      "epoch": 577.48,
      "learning_rate": 0.042274573854516134,
      "loss": 0.6879,
      "step": 358040
    },
    {
      "epoch": 577.52,
      "learning_rate": 0.042271348051290326,
      "loss": 0.6731,
      "step": 358060
    },
    {
      "epoch": 577.55,
      "learning_rate": 0.04226812224806452,
      "loss": 0.697,
      "step": 358080
    },
    {
      "epoch": 577.58,
      "learning_rate": 0.04226489644483872,
      "loss": 0.6814,
      "step": 358100
    },
    {
      "epoch": 577.61,
      "learning_rate": 0.04226167064161291,
      "loss": 0.6797,
      "step": 358120
    },
    {
      "epoch": 577.65,
      "learning_rate": 0.0422584448383871,
      "loss": 0.6685,
      "step": 358140
    },
    {
      "epoch": 577.68,
      "learning_rate": 0.0422552190351613,
      "loss": 0.6655,
      "step": 358160
    },
    {
      "epoch": 577.71,
      "learning_rate": 0.04225199323193549,
      "loss": 0.6659,
      "step": 358180
    },
    {
      "epoch": 577.74,
      "learning_rate": 0.04224876742870968,
      "loss": 0.6775,
      "step": 358200
    },
    {
      "epoch": 577.77,
      "learning_rate": 0.04224554162548387,
      "loss": 0.7007,
      "step": 358220
    },
    {
      "epoch": 577.81,
      "learning_rate": 0.04224231582225806,
      "loss": 0.6859,
      "step": 358240
    },
    {
      "epoch": 577.84,
      "learning_rate": 0.04223909001903226,
      "loss": 0.6885,
      "step": 358260
    },
    {
      "epoch": 577.87,
      "learning_rate": 0.042235864215806454,
      "loss": 0.6704,
      "step": 358280
    },
    {
      "epoch": 577.9,
      "learning_rate": 0.042232638412580646,
      "loss": 0.6767,
      "step": 358300
    },
    {
      "epoch": 577.94,
      "learning_rate": 0.04222941260935484,
      "loss": 0.6765,
      "step": 358320
    },
    {
      "epoch": 577.97,
      "learning_rate": 0.04222618680612904,
      "loss": 0.6593,
      "step": 358340
    },
    {
      "epoch": 578.0,
      "learning_rate": 0.04222312229306451,
      "loss": 0.6811,
      "step": 358360
    },
    {
      "epoch": 578.0,
      "eval_accuracy": {
        "accuracy": 0.7680899227226602
      },
      "eval_loss": 1.0379458665847778,
      "eval_runtime": 3.201,
      "eval_samples_per_second": 4002.24,
      "eval_steps_per_second": 62.794,
      "step": 358360
    },
    {
      "epoch": 578.03,
      "learning_rate": 0.04221989648983871,
      "loss": 0.6764,
      "step": 358380
    },
    {
      "epoch": 578.06,
      "learning_rate": 0.0422166706866129,
      "loss": 0.6667,
      "step": 358400
    },
    {
      "epoch": 578.1,
      "learning_rate": 0.042213444883387095,
      "loss": 0.6679,
      "step": 358420
    },
    {
      "epoch": 578.13,
      "learning_rate": 0.042210219080161294,
      "loss": 0.6439,
      "step": 358440
    },
    {
      "epoch": 578.16,
      "learning_rate": 0.04220699327693549,
      "loss": 0.6729,
      "step": 358460
    },
    {
      "epoch": 578.19,
      "learning_rate": 0.04220376747370968,
      "loss": 0.6753,
      "step": 358480
    },
    {
      "epoch": 578.23,
      "learning_rate": 0.04220054167048388,
      "loss": 0.6524,
      "step": 358500
    },
    {
      "epoch": 578.26,
      "learning_rate": 0.04219731586725807,
      "loss": 0.6751,
      "step": 358520
    },
    {
      "epoch": 578.29,
      "learning_rate": 0.04219409006403226,
      "loss": 0.6607,
      "step": 358540
    },
    {
      "epoch": 578.32,
      "learning_rate": 0.04219086426080646,
      "loss": 0.675,
      "step": 358560
    },
    {
      "epoch": 578.35,
      "learning_rate": 0.04218763845758065,
      "loss": 0.6771,
      "step": 358580
    },
    {
      "epoch": 578.39,
      "learning_rate": 0.042184412654354846,
      "loss": 0.6683,
      "step": 358600
    },
    {
      "epoch": 578.42,
      "learning_rate": 0.04218118685112904,
      "loss": 0.6873,
      "step": 358620
    },
    {
      "epoch": 578.45,
      "learning_rate": 0.04217796104790324,
      "loss": 0.669,
      "step": 358640
    },
    {
      "epoch": 578.48,
      "learning_rate": 0.042174735244677415,
      "loss": 0.674,
      "step": 358660
    },
    {
      "epoch": 578.52,
      "learning_rate": 0.042171509441451614,
      "loss": 0.6596,
      "step": 358680
    },
    {
      "epoch": 578.55,
      "learning_rate": 0.042168283638225806,
      "loss": 0.6748,
      "step": 358700
    },
    {
      "epoch": 578.58,
      "learning_rate": 0.042165057835,
      "loss": 0.6678,
      "step": 358720
    },
    {
      "epoch": 578.61,
      "learning_rate": 0.0421618320317742,
      "loss": 0.6867,
      "step": 358740
    },
    {
      "epoch": 578.65,
      "learning_rate": 0.04215860622854839,
      "loss": 0.6653,
      "step": 358760
    },
    {
      "epoch": 578.68,
      "learning_rate": 0.04215538042532258,
      "loss": 0.6701,
      "step": 358780
    },
    {
      "epoch": 578.71,
      "learning_rate": 0.04215215462209678,
      "loss": 0.6674,
      "step": 358800
    },
    {
      "epoch": 578.74,
      "learning_rate": 0.04214892881887097,
      "loss": 0.6612,
      "step": 358820
    },
    {
      "epoch": 578.77,
      "learning_rate": 0.042145703015645165,
      "loss": 0.6817,
      "step": 358840
    },
    {
      "epoch": 578.81,
      "learning_rate": 0.04214247721241936,
      "loss": 0.6794,
      "step": 358860
    },
    {
      "epoch": 578.84,
      "learning_rate": 0.04213925140919356,
      "loss": 0.6722,
      "step": 358880
    },
    {
      "epoch": 578.87,
      "learning_rate": 0.04213602560596775,
      "loss": 0.6836,
      "step": 358900
    },
    {
      "epoch": 578.9,
      "learning_rate": 0.04213279980274194,
      "loss": 0.6931,
      "step": 358920
    },
    {
      "epoch": 578.94,
      "learning_rate": 0.04212957399951614,
      "loss": 0.6867,
      "step": 358940
    },
    {
      "epoch": 578.97,
      "learning_rate": 0.04212634819629033,
      "loss": 0.6755,
      "step": 358960
    },
    {
      "epoch": 579.0,
      "learning_rate": 0.04212312239306452,
      "loss": 0.683,
      "step": 358980
    },
    {
      "epoch": 579.0,
      "eval_accuracy": {
        "accuracy": 0.764967605963625
      },
      "eval_loss": 1.0451633930206299,
      "eval_runtime": 2.8047,
      "eval_samples_per_second": 4567.715,
      "eval_steps_per_second": 71.666,
      "step": 358980
    },
    {
      "epoch": 579.03,
      "learning_rate": 0.04211989658983871,
      "loss": 0.6947,
      "step": 359000
    },
    {
      "epoch": 579.06,
      "learning_rate": 0.0421166707866129,
      "loss": 0.6743,
      "step": 359020
    },
    {
      "epoch": 579.1,
      "learning_rate": 0.0421134449833871,
      "loss": 0.6603,
      "step": 359040
    },
    {
      "epoch": 579.13,
      "learning_rate": 0.04211021918016129,
      "loss": 0.6758,
      "step": 359060
    },
    {
      "epoch": 579.16,
      "learning_rate": 0.042106993376935485,
      "loss": 0.6819,
      "step": 359080
    },
    {
      "epoch": 579.19,
      "learning_rate": 0.042103767573709684,
      "loss": 0.6642,
      "step": 359100
    },
    {
      "epoch": 579.23,
      "learning_rate": 0.042100541770483876,
      "loss": 0.6748,
      "step": 359120
    },
    {
      "epoch": 579.26,
      "learning_rate": 0.04209731596725807,
      "loss": 0.6731,
      "step": 359140
    },
    {
      "epoch": 579.29,
      "learning_rate": 0.04209409016403226,
      "loss": 0.6762,
      "step": 359160
    },
    {
      "epoch": 579.32,
      "learning_rate": 0.04209086436080646,
      "loss": 0.68,
      "step": 359180
    },
    {
      "epoch": 579.35,
      "learning_rate": 0.04208763855758065,
      "loss": 0.6726,
      "step": 359200
    },
    {
      "epoch": 579.39,
      "learning_rate": 0.042084412754354844,
      "loss": 0.6818,
      "step": 359220
    },
    {
      "epoch": 579.42,
      "learning_rate": 0.04208118695112904,
      "loss": 0.6821,
      "step": 359240
    },
    {
      "epoch": 579.45,
      "learning_rate": 0.042077961147903235,
      "loss": 0.6684,
      "step": 359260
    },
    {
      "epoch": 579.48,
      "learning_rate": 0.04207473534467742,
      "loss": 0.6755,
      "step": 359280
    },
    {
      "epoch": 579.52,
      "learning_rate": 0.04207150954145161,
      "loss": 0.6838,
      "step": 359300
    },
    {
      "epoch": 579.55,
      "learning_rate": 0.042068283738225805,
      "loss": 0.683,
      "step": 359320
    },
    {
      "epoch": 579.58,
      "learning_rate": 0.042065057935000004,
      "loss": 0.6668,
      "step": 359340
    },
    {
      "epoch": 579.61,
      "learning_rate": 0.042061832131774196,
      "loss": 0.673,
      "step": 359360
    },
    {
      "epoch": 579.65,
      "learning_rate": 0.04205860632854839,
      "loss": 0.6756,
      "step": 359380
    },
    {
      "epoch": 579.68,
      "learning_rate": 0.04205538052532258,
      "loss": 0.6807,
      "step": 359400
    },
    {
      "epoch": 579.71,
      "learning_rate": 0.04205215472209678,
      "loss": 0.6679,
      "step": 359420
    },
    {
      "epoch": 579.74,
      "learning_rate": 0.04204892891887097,
      "loss": 0.6632,
      "step": 359440
    },
    {
      "epoch": 579.77,
      "learning_rate": 0.042045703115645164,
      "loss": 0.6645,
      "step": 359460
    },
    {
      "epoch": 579.81,
      "learning_rate": 0.04204247731241936,
      "loss": 0.6868,
      "step": 359480
    },
    {
      "epoch": 579.84,
      "learning_rate": 0.042039251509193555,
      "loss": 0.6606,
      "step": 359500
    },
    {
      "epoch": 579.87,
      "learning_rate": 0.04203602570596775,
      "loss": 0.6764,
      "step": 359520
    },
    {
      "epoch": 579.9,
      "learning_rate": 0.042032799902741946,
      "loss": 0.6839,
      "step": 359540
    },
    {
      "epoch": 579.94,
      "learning_rate": 0.04202957409951614,
      "loss": 0.6762,
      "step": 359560
    },
    {
      "epoch": 579.97,
      "learning_rate": 0.04202634829629033,
      "loss": 0.6867,
      "step": 359580
    },
    {
      "epoch": 580.0,
      "learning_rate": 0.042023122493064516,
      "loss": 0.6775,
      "step": 359600
    },
    {
      "epoch": 580.0,
      "eval_accuracy": {
        "accuracy": 0.7671532276949496
      },
      "eval_loss": 1.0296173095703125,
      "eval_runtime": 2.926,
      "eval_samples_per_second": 4378.337,
      "eval_steps_per_second": 68.695,
      "step": 359600
    },
    {
      "epoch": 580.03,
      "learning_rate": 0.04201989668983871,
      "loss": 0.6785,
      "step": 359620
    },
    {
      "epoch": 580.06,
      "learning_rate": 0.04201667088661291,
      "loss": 0.668,
      "step": 359640
    },
    {
      "epoch": 580.1,
      "learning_rate": 0.0420134450833871,
      "loss": 0.6552,
      "step": 359660
    },
    {
      "epoch": 580.13,
      "learning_rate": 0.04201021928016129,
      "loss": 0.6628,
      "step": 359680
    },
    {
      "epoch": 580.16,
      "learning_rate": 0.042006993476935484,
      "loss": 0.6668,
      "step": 359700
    },
    {
      "epoch": 580.19,
      "learning_rate": 0.04200376767370968,
      "loss": 0.6708,
      "step": 359720
    },
    {
      "epoch": 580.23,
      "learning_rate": 0.042000541870483875,
      "loss": 0.664,
      "step": 359740
    },
    {
      "epoch": 580.26,
      "learning_rate": 0.04199731606725807,
      "loss": 0.6678,
      "step": 359760
    },
    {
      "epoch": 580.29,
      "learning_rate": 0.041994090264032266,
      "loss": 0.6693,
      "step": 359780
    },
    {
      "epoch": 580.32,
      "learning_rate": 0.04199086446080646,
      "loss": 0.6646,
      "step": 359800
    },
    {
      "epoch": 580.35,
      "learning_rate": 0.04198763865758065,
      "loss": 0.6904,
      "step": 359820
    },
    {
      "epoch": 580.39,
      "learning_rate": 0.04198441285435485,
      "loss": 0.6677,
      "step": 359840
    },
    {
      "epoch": 580.42,
      "learning_rate": 0.04198118705112904,
      "loss": 0.6839,
      "step": 359860
    },
    {
      "epoch": 580.45,
      "learning_rate": 0.041977961247903234,
      "loss": 0.688,
      "step": 359880
    },
    {
      "epoch": 580.48,
      "learning_rate": 0.04197473544467742,
      "loss": 0.6786,
      "step": 359900
    },
    {
      "epoch": 580.52,
      "learning_rate": 0.04197150964145161,
      "loss": 0.68,
      "step": 359920
    },
    {
      "epoch": 580.55,
      "learning_rate": 0.0419682838382258,
      "loss": 0.6695,
      "step": 359940
    },
    {
      "epoch": 580.58,
      "learning_rate": 0.041965058035,
      "loss": 0.6628,
      "step": 359960
    },
    {
      "epoch": 580.61,
      "learning_rate": 0.041961832231774195,
      "loss": 0.6795,
      "step": 359980
    },
    {
      "epoch": 580.65,
      "learning_rate": 0.04195860642854839,
      "loss": 0.6727,
      "step": 360000
    },
    {
      "epoch": 580.68,
      "learning_rate": 0.041955380625322586,
      "loss": 0.6745,
      "step": 360020
    },
    {
      "epoch": 580.71,
      "learning_rate": 0.04195215482209678,
      "loss": 0.6641,
      "step": 360040
    },
    {
      "epoch": 580.74,
      "learning_rate": 0.04194892901887097,
      "loss": 0.6666,
      "step": 360060
    },
    {
      "epoch": 580.77,
      "learning_rate": 0.04194570321564517,
      "loss": 0.6712,
      "step": 360080
    },
    {
      "epoch": 580.81,
      "learning_rate": 0.04194247741241936,
      "loss": 0.6757,
      "step": 360100
    },
    {
      "epoch": 580.84,
      "learning_rate": 0.041939251609193554,
      "loss": 0.6676,
      "step": 360120
    },
    {
      "epoch": 580.87,
      "learning_rate": 0.041936025805967746,
      "loss": 0.6836,
      "step": 360140
    },
    {
      "epoch": 580.9,
      "learning_rate": 0.041932800002741945,
      "loss": 0.6537,
      "step": 360160
    },
    {
      "epoch": 580.94,
      "learning_rate": 0.04192957419951614,
      "loss": 0.6643,
      "step": 360180
    },
    {
      "epoch": 580.97,
      "learning_rate": 0.04192634839629033,
      "loss": 0.6731,
      "step": 360200
    },
    {
      "epoch": 581.0,
      "learning_rate": 0.041923122593064514,
      "loss": 0.6781,
      "step": 360220
    },
    {
      "epoch": 581.0,
      "eval_accuracy": {
        "accuracy": 0.7630161579892281
      },
      "eval_loss": 1.044417142868042,
      "eval_runtime": 3.3653,
      "eval_samples_per_second": 3806.775,
      "eval_steps_per_second": 59.727,
      "step": 360220
    },
    {
      "epoch": 581.03,
      "learning_rate": 0.041919896789838706,
      "loss": 0.6975,
      "step": 360240
    },
    {
      "epoch": 581.06,
      "learning_rate": 0.041916670986612906,
      "loss": 0.6878,
      "step": 360260
    },
    {
      "epoch": 581.1,
      "learning_rate": 0.0419134451833871,
      "loss": 0.6704,
      "step": 360280
    },
    {
      "epoch": 581.13,
      "learning_rate": 0.04191021938016129,
      "loss": 0.6645,
      "step": 360300
    },
    {
      "epoch": 581.16,
      "learning_rate": 0.04190699357693549,
      "loss": 0.6663,
      "step": 360320
    },
    {
      "epoch": 581.19,
      "learning_rate": 0.04190376777370968,
      "loss": 0.669,
      "step": 360340
    },
    {
      "epoch": 581.23,
      "learning_rate": 0.04190054197048387,
      "loss": 0.6562,
      "step": 360360
    },
    {
      "epoch": 581.26,
      "learning_rate": 0.04189731616725807,
      "loss": 0.6684,
      "step": 360380
    },
    {
      "epoch": 581.29,
      "learning_rate": 0.041894090364032265,
      "loss": 0.6637,
      "step": 360400
    },
    {
      "epoch": 581.32,
      "learning_rate": 0.04189086456080646,
      "loss": 0.6708,
      "step": 360420
    },
    {
      "epoch": 581.35,
      "learning_rate": 0.04188763875758065,
      "loss": 0.6653,
      "step": 360440
    },
    {
      "epoch": 581.39,
      "learning_rate": 0.04188441295435485,
      "loss": 0.6791,
      "step": 360460
    },
    {
      "epoch": 581.42,
      "learning_rate": 0.04188118715112904,
      "loss": 0.6642,
      "step": 360480
    },
    {
      "epoch": 581.45,
      "learning_rate": 0.04187796134790323,
      "loss": 0.668,
      "step": 360500
    },
    {
      "epoch": 581.48,
      "learning_rate": 0.04187473554467742,
      "loss": 0.6717,
      "step": 360520
    },
    {
      "epoch": 581.52,
      "learning_rate": 0.04187150974145161,
      "loss": 0.66,
      "step": 360540
    },
    {
      "epoch": 581.55,
      "learning_rate": 0.04186828393822581,
      "loss": 0.6702,
      "step": 360560
    },
    {
      "epoch": 581.58,
      "learning_rate": 0.041865058135,
      "loss": 0.6815,
      "step": 360580
    },
    {
      "epoch": 581.61,
      "learning_rate": 0.04186183233177419,
      "loss": 0.6683,
      "step": 360600
    },
    {
      "epoch": 581.65,
      "learning_rate": 0.04185860652854839,
      "loss": 0.6598,
      "step": 360620
    },
    {
      "epoch": 581.68,
      "learning_rate": 0.041855380725322584,
      "loss": 0.6714,
      "step": 360640
    },
    {
      "epoch": 581.71,
      "learning_rate": 0.041852154922096776,
      "loss": 0.6739,
      "step": 360660
    },
    {
      "epoch": 581.74,
      "learning_rate": 0.04184892911887097,
      "loss": 0.6737,
      "step": 360680
    },
    {
      "epoch": 581.77,
      "learning_rate": 0.04184570331564517,
      "loss": 0.6843,
      "step": 360700
    },
    {
      "epoch": 581.81,
      "learning_rate": 0.04184247751241936,
      "loss": 0.6827,
      "step": 360720
    },
    {
      "epoch": 581.84,
      "learning_rate": 0.04183925170919355,
      "loss": 0.6767,
      "step": 360740
    },
    {
      "epoch": 581.87,
      "learning_rate": 0.04183602590596775,
      "loss": 0.6835,
      "step": 360760
    },
    {
      "epoch": 581.9,
      "learning_rate": 0.04183280010274194,
      "loss": 0.6736,
      "step": 360780
    },
    {
      "epoch": 581.94,
      "learning_rate": 0.041829574299516135,
      "loss": 0.6738,
      "step": 360800
    },
    {
      "epoch": 581.97,
      "learning_rate": 0.041826348496290335,
      "loss": 0.6737,
      "step": 360820
    },
    {
      "epoch": 582.0,
      "learning_rate": 0.04182312269306451,
      "loss": 0.6965,
      "step": 360840
    },
    {
      "epoch": 582.0,
      "eval_accuracy": {
        "accuracy": 0.7626258683943486
      },
      "eval_loss": 1.0511001348495483,
      "eval_runtime": 3.3764,
      "eval_samples_per_second": 3794.278,
      "eval_steps_per_second": 59.531,
      "step": 360840
    },
    {
      "epoch": 582.03,
      "learning_rate": 0.04181989688983871,
      "loss": 0.6823,
      "step": 360860
    },
    {
      "epoch": 582.06,
      "learning_rate": 0.041816671086612904,
      "loss": 0.6644,
      "step": 360880
    },
    {
      "epoch": 582.1,
      "learning_rate": 0.041813445283387096,
      "loss": 0.6549,
      "step": 360900
    },
    {
      "epoch": 582.13,
      "learning_rate": 0.041810219480161295,
      "loss": 0.6594,
      "step": 360920
    },
    {
      "epoch": 582.16,
      "learning_rate": 0.04180699367693549,
      "loss": 0.6526,
      "step": 360940
    },
    {
      "epoch": 582.19,
      "learning_rate": 0.04180376787370968,
      "loss": 0.6821,
      "step": 360960
    },
    {
      "epoch": 582.23,
      "learning_rate": 0.04180054207048387,
      "loss": 0.6604,
      "step": 360980
    },
    {
      "epoch": 582.26,
      "learning_rate": 0.04179731626725807,
      "loss": 0.658,
      "step": 361000
    },
    {
      "epoch": 582.29,
      "learning_rate": 0.04179409046403226,
      "loss": 0.657,
      "step": 361020
    },
    {
      "epoch": 582.32,
      "learning_rate": 0.041790864660806455,
      "loss": 0.6817,
      "step": 361040
    },
    {
      "epoch": 582.35,
      "learning_rate": 0.041787638857580654,
      "loss": 0.6709,
      "step": 361060
    },
    {
      "epoch": 582.39,
      "learning_rate": 0.041784413054354846,
      "loss": 0.6616,
      "step": 361080
    },
    {
      "epoch": 582.42,
      "learning_rate": 0.04178118725112904,
      "loss": 0.6645,
      "step": 361100
    },
    {
      "epoch": 582.45,
      "learning_rate": 0.04177796144790324,
      "loss": 0.6835,
      "step": 361120
    },
    {
      "epoch": 582.48,
      "learning_rate": 0.04177473564467743,
      "loss": 0.6495,
      "step": 361140
    },
    {
      "epoch": 582.52,
      "learning_rate": 0.041771509841451615,
      "loss": 0.6598,
      "step": 361160
    },
    {
      "epoch": 582.55,
      "learning_rate": 0.04176828403822581,
      "loss": 0.6581,
      "step": 361180
    },
    {
      "epoch": 582.58,
      "learning_rate": 0.041765058235,
      "loss": 0.6706,
      "step": 361200
    },
    {
      "epoch": 582.61,
      "learning_rate": 0.04176183243177419,
      "loss": 0.6767,
      "step": 361220
    },
    {
      "epoch": 582.65,
      "learning_rate": 0.04175860662854839,
      "loss": 0.6613,
      "step": 361240
    },
    {
      "epoch": 582.68,
      "learning_rate": 0.04175538082532258,
      "loss": 0.6846,
      "step": 361260
    },
    {
      "epoch": 582.71,
      "learning_rate": 0.041752155022096775,
      "loss": 0.6809,
      "step": 361280
    },
    {
      "epoch": 582.74,
      "learning_rate": 0.041748929218870974,
      "loss": 0.6791,
      "step": 361300
    },
    {
      "epoch": 582.77,
      "learning_rate": 0.041745703415645166,
      "loss": 0.6794,
      "step": 361320
    },
    {
      "epoch": 582.81,
      "learning_rate": 0.04174247761241936,
      "loss": 0.6586,
      "step": 361340
    },
    {
      "epoch": 582.84,
      "learning_rate": 0.04173925180919356,
      "loss": 0.6983,
      "step": 361360
    },
    {
      "epoch": 582.87,
      "learning_rate": 0.04173602600596775,
      "loss": 0.705,
      "step": 361380
    },
    {
      "epoch": 582.9,
      "learning_rate": 0.04173280020274194,
      "loss": 0.7068,
      "step": 361400
    },
    {
      "epoch": 582.94,
      "learning_rate": 0.04172957439951614,
      "loss": 0.6854,
      "step": 361420
    },
    {
      "epoch": 582.97,
      "learning_rate": 0.04172634859629033,
      "loss": 0.6794,
      "step": 361440
    },
    {
      "epoch": 583.0,
      "learning_rate": 0.041723284083225815,
      "loss": 0.6877,
      "step": 361460
    },
    {
      "epoch": 583.0,
      "eval_accuracy": {
        "accuracy": 0.7632503317461556
      },
      "eval_loss": 1.0482417345046997,
      "eval_runtime": 2.8692,
      "eval_samples_per_second": 4465.043,
      "eval_steps_per_second": 70.055,
      "step": 361460
    },
    {
      "epoch": 583.03,
      "learning_rate": 0.04172005828000001,
      "loss": 0.67,
      "step": 361480
    },
    {
      "epoch": 583.06,
      "learning_rate": 0.0417168324767742,
      "loss": 0.6524,
      "step": 361500
    },
    {
      "epoch": 583.1,
      "learning_rate": 0.04171360667354839,
      "loss": 0.654,
      "step": 361520
    },
    {
      "epoch": 583.13,
      "learning_rate": 0.04171038087032259,
      "loss": 0.6833,
      "step": 361540
    },
    {
      "epoch": 583.16,
      "learning_rate": 0.04170715506709678,
      "loss": 0.6607,
      "step": 361560
    },
    {
      "epoch": 583.19,
      "learning_rate": 0.041703929263870974,
      "loss": 0.6744,
      "step": 361580
    },
    {
      "epoch": 583.23,
      "learning_rate": 0.04170070346064516,
      "loss": 0.6582,
      "step": 361600
    },
    {
      "epoch": 583.26,
      "learning_rate": 0.04169747765741935,
      "loss": 0.6706,
      "step": 361620
    },
    {
      "epoch": 583.29,
      "learning_rate": 0.04169425185419355,
      "loss": 0.6653,
      "step": 361640
    },
    {
      "epoch": 583.32,
      "learning_rate": 0.04169102605096774,
      "loss": 0.6813,
      "step": 361660
    },
    {
      "epoch": 583.35,
      "learning_rate": 0.041687800247741935,
      "loss": 0.6808,
      "step": 361680
    },
    {
      "epoch": 583.39,
      "learning_rate": 0.041684574444516134,
      "loss": 0.6644,
      "step": 361700
    },
    {
      "epoch": 583.42,
      "learning_rate": 0.041681348641290326,
      "loss": 0.6694,
      "step": 361720
    },
    {
      "epoch": 583.45,
      "learning_rate": 0.04167812283806452,
      "loss": 0.6611,
      "step": 361740
    },
    {
      "epoch": 583.48,
      "learning_rate": 0.04167489703483871,
      "loss": 0.6748,
      "step": 361760
    },
    {
      "epoch": 583.52,
      "learning_rate": 0.04167167123161291,
      "loss": 0.6723,
      "step": 361780
    },
    {
      "epoch": 583.55,
      "learning_rate": 0.0416684454283871,
      "loss": 0.6649,
      "step": 361800
    },
    {
      "epoch": 583.58,
      "learning_rate": 0.041665219625161294,
      "loss": 0.6649,
      "step": 361820
    },
    {
      "epoch": 583.61,
      "learning_rate": 0.04166199382193549,
      "loss": 0.6661,
      "step": 361840
    },
    {
      "epoch": 583.65,
      "learning_rate": 0.041658768018709685,
      "loss": 0.6762,
      "step": 361860
    },
    {
      "epoch": 583.68,
      "learning_rate": 0.04165554221548388,
      "loss": 0.6652,
      "step": 361880
    },
    {
      "epoch": 583.71,
      "learning_rate": 0.04165231641225808,
      "loss": 0.6565,
      "step": 361900
    },
    {
      "epoch": 583.74,
      "learning_rate": 0.041649090609032255,
      "loss": 0.6655,
      "step": 361920
    },
    {
      "epoch": 583.77,
      "learning_rate": 0.041645864805806454,
      "loss": 0.6687,
      "step": 361940
    },
    {
      "epoch": 583.81,
      "learning_rate": 0.041642639002580646,
      "loss": 0.6895,
      "step": 361960
    },
    {
      "epoch": 583.84,
      "learning_rate": 0.04163941319935484,
      "loss": 0.6645,
      "step": 361980
    },
    {
      "epoch": 583.87,
      "learning_rate": 0.04163618739612904,
      "loss": 0.6667,
      "step": 362000
    },
    {
      "epoch": 583.9,
      "learning_rate": 0.04163296159290323,
      "loss": 0.6745,
      "step": 362020
    },
    {
      "epoch": 583.94,
      "learning_rate": 0.04162973578967742,
      "loss": 0.6689,
      "step": 362040
    },
    {
      "epoch": 583.97,
      "learning_rate": 0.041626509986451614,
      "loss": 0.6852,
      "step": 362060
    },
    {
      "epoch": 584.0,
      "learning_rate": 0.04162328418322581,
      "loss": 0.6951,
      "step": 362080
    },
    {
      "epoch": 584.0,
      "eval_accuracy": {
        "accuracy": 0.7658262430723597
      },
      "eval_loss": 1.0371294021606445,
      "eval_runtime": 4.1062,
      "eval_samples_per_second": 3119.906,
      "eval_steps_per_second": 48.95,
      "step": 362080
    },
    {
      "epoch": 584.03,
      "learning_rate": 0.041620058380000005,
      "loss": 0.672,
      "step": 362100
    },
    {
      "epoch": 584.06,
      "learning_rate": 0.0416168325767742,
      "loss": 0.6508,
      "step": 362120
    },
    {
      "epoch": 584.1,
      "learning_rate": 0.041613606773548396,
      "loss": 0.6524,
      "step": 362140
    },
    {
      "epoch": 584.13,
      "learning_rate": 0.04161038097032259,
      "loss": 0.6552,
      "step": 362160
    },
    {
      "epoch": 584.16,
      "learning_rate": 0.04160715516709678,
      "loss": 0.6699,
      "step": 362180
    },
    {
      "epoch": 584.19,
      "learning_rate": 0.04160392936387098,
      "loss": 0.671,
      "step": 362200
    },
    {
      "epoch": 584.23,
      "learning_rate": 0.04160070356064516,
      "loss": 0.6757,
      "step": 362220
    },
    {
      "epoch": 584.26,
      "learning_rate": 0.04159747775741936,
      "loss": 0.6547,
      "step": 362240
    },
    {
      "epoch": 584.29,
      "learning_rate": 0.04159425195419355,
      "loss": 0.657,
      "step": 362260
    },
    {
      "epoch": 584.32,
      "learning_rate": 0.04159102615096774,
      "loss": 0.6497,
      "step": 362280
    },
    {
      "epoch": 584.35,
      "learning_rate": 0.041587800347741934,
      "loss": 0.6574,
      "step": 362300
    },
    {
      "epoch": 584.39,
      "learning_rate": 0.04158457454451613,
      "loss": 0.6812,
      "step": 362320
    },
    {
      "epoch": 584.42,
      "learning_rate": 0.041581348741290325,
      "loss": 0.6614,
      "step": 362340
    },
    {
      "epoch": 584.45,
      "learning_rate": 0.04157812293806452,
      "loss": 0.6556,
      "step": 362360
    },
    {
      "epoch": 584.48,
      "learning_rate": 0.041574897134838716,
      "loss": 0.6577,
      "step": 362380
    },
    {
      "epoch": 584.52,
      "learning_rate": 0.04157167133161291,
      "loss": 0.676,
      "step": 362400
    },
    {
      "epoch": 584.55,
      "learning_rate": 0.0415684455283871,
      "loss": 0.6633,
      "step": 362420
    },
    {
      "epoch": 584.58,
      "learning_rate": 0.0415652197251613,
      "loss": 0.6755,
      "step": 362440
    },
    {
      "epoch": 584.61,
      "learning_rate": 0.04156199392193549,
      "loss": 0.6746,
      "step": 362460
    },
    {
      "epoch": 584.65,
      "learning_rate": 0.041558768118709684,
      "loss": 0.6777,
      "step": 362480
    },
    {
      "epoch": 584.68,
      "learning_rate": 0.04155554231548388,
      "loss": 0.6741,
      "step": 362500
    },
    {
      "epoch": 584.71,
      "learning_rate": 0.041552316512258075,
      "loss": 0.6791,
      "step": 362520
    },
    {
      "epoch": 584.74,
      "learning_rate": 0.04154909070903226,
      "loss": 0.6592,
      "step": 362540
    },
    {
      "epoch": 584.77,
      "learning_rate": 0.04154586490580645,
      "loss": 0.681,
      "step": 362560
    },
    {
      "epoch": 584.81,
      "learning_rate": 0.041542639102580645,
      "loss": 0.6805,
      "step": 362580
    },
    {
      "epoch": 584.84,
      "learning_rate": 0.04153941329935484,
      "loss": 0.6673,
      "step": 362600
    },
    {
      "epoch": 584.87,
      "learning_rate": 0.041536187496129036,
      "loss": 0.6802,
      "step": 362620
    },
    {
      "epoch": 584.9,
      "learning_rate": 0.04153296169290323,
      "loss": 0.6598,
      "step": 362640
    },
    {
      "epoch": 584.94,
      "learning_rate": 0.04152973588967742,
      "loss": 0.6599,
      "step": 362660
    },
    {
      "epoch": 584.97,
      "learning_rate": 0.04152651008645162,
      "loss": 0.6715,
      "step": 362680
    },
    {
      "epoch": 585.0,
      "learning_rate": 0.04152328428322581,
      "loss": 0.6798,
      "step": 362700
    },
    {
      "epoch": 585.0,
      "eval_accuracy": {
        "accuracy": 0.7630161579892281
      },
      "eval_loss": 1.065047264099121,
      "eval_runtime": 3.0992,
      "eval_samples_per_second": 4133.667,
      "eval_steps_per_second": 64.856,
      "step": 362700
    },
    {
      "epoch": 585.03,
      "learning_rate": 0.041520058480000004,
      "loss": 0.6914,
      "step": 362720
    },
    {
      "epoch": 585.06,
      "learning_rate": 0.0415168326767742,
      "loss": 0.6728,
      "step": 362740
    },
    {
      "epoch": 585.1,
      "learning_rate": 0.041513606873548395,
      "loss": 0.6645,
      "step": 362760
    },
    {
      "epoch": 585.13,
      "learning_rate": 0.04151038107032259,
      "loss": 0.674,
      "step": 362780
    },
    {
      "epoch": 585.16,
      "learning_rate": 0.04150715526709678,
      "loss": 0.6614,
      "step": 362800
    },
    {
      "epoch": 585.19,
      "learning_rate": 0.04150392946387098,
      "loss": 0.6762,
      "step": 362820
    },
    {
      "epoch": 585.23,
      "learning_rate": 0.04150070366064516,
      "loss": 0.6682,
      "step": 362840
    },
    {
      "epoch": 585.26,
      "learning_rate": 0.041497477857419356,
      "loss": 0.6579,
      "step": 362860
    },
    {
      "epoch": 585.29,
      "learning_rate": 0.04149425205419355,
      "loss": 0.6589,
      "step": 362880
    },
    {
      "epoch": 585.32,
      "learning_rate": 0.04149102625096774,
      "loss": 0.652,
      "step": 362900
    },
    {
      "epoch": 585.35,
      "learning_rate": 0.04148780044774194,
      "loss": 0.6569,
      "step": 362920
    },
    {
      "epoch": 585.39,
      "learning_rate": 0.04148457464451613,
      "loss": 0.6639,
      "step": 362940
    },
    {
      "epoch": 585.42,
      "learning_rate": 0.04148134884129032,
      "loss": 0.656,
      "step": 362960
    },
    {
      "epoch": 585.45,
      "learning_rate": 0.04147812303806452,
      "loss": 0.6718,
      "step": 362980
    },
    {
      "epoch": 585.48,
      "learning_rate": 0.041474897234838715,
      "loss": 0.6704,
      "step": 363000
    },
    {
      "epoch": 585.52,
      "learning_rate": 0.04147167143161291,
      "loss": 0.6671,
      "step": 363020
    },
    {
      "epoch": 585.55,
      "learning_rate": 0.041468445628387106,
      "loss": 0.6748,
      "step": 363040
    },
    {
      "epoch": 585.58,
      "learning_rate": 0.0414652198251613,
      "loss": 0.6529,
      "step": 363060
    },
    {
      "epoch": 585.61,
      "learning_rate": 0.04146199402193549,
      "loss": 0.6779,
      "step": 363080
    },
    {
      "epoch": 585.65,
      "learning_rate": 0.04145876821870968,
      "loss": 0.6691,
      "step": 363100
    },
    {
      "epoch": 585.68,
      "learning_rate": 0.04145554241548388,
      "loss": 0.6601,
      "step": 363120
    },
    {
      "epoch": 585.71,
      "learning_rate": 0.041452316612258074,
      "loss": 0.6765,
      "step": 363140
    },
    {
      "epoch": 585.74,
      "learning_rate": 0.04144909080903226,
      "loss": 0.6604,
      "step": 363160
    },
    {
      "epoch": 585.77,
      "learning_rate": 0.04144586500580645,
      "loss": 0.692,
      "step": 363180
    },
    {
      "epoch": 585.81,
      "learning_rate": 0.04144263920258064,
      "loss": 0.666,
      "step": 363200
    },
    {
      "epoch": 585.84,
      "learning_rate": 0.04143941339935484,
      "loss": 0.6816,
      "step": 363220
    },
    {
      "epoch": 585.87,
      "learning_rate": 0.041436187596129034,
      "loss": 0.6756,
      "step": 363240
    },
    {
      "epoch": 585.9,
      "learning_rate": 0.041432961792903227,
      "loss": 0.6814,
      "step": 363260
    },
    {
      "epoch": 585.94,
      "learning_rate": 0.041429735989677426,
      "loss": 0.6832,
      "step": 363280
    },
    {
      "epoch": 585.97,
      "learning_rate": 0.04142651018645162,
      "loss": 0.6777,
      "step": 363300
    },
    {
      "epoch": 586.0,
      "learning_rate": 0.04142328438322581,
      "loss": 0.6737,
      "step": 363320
    },
    {
      "epoch": 586.0,
      "eval_accuracy": {
        "accuracy": 0.761767231285614
      },
      "eval_loss": 1.062877893447876,
      "eval_runtime": 2.9962,
      "eval_samples_per_second": 4275.718,
      "eval_steps_per_second": 67.084,
      "step": 363320
    },
    {
      "epoch": 586.03,
      "learning_rate": 0.04142005858,
      "loss": 0.6917,
      "step": 363340
    },
    {
      "epoch": 586.06,
      "learning_rate": 0.0414168327767742,
      "loss": 0.6656,
      "step": 363360
    },
    {
      "epoch": 586.1,
      "learning_rate": 0.04141360697354839,
      "loss": 0.6587,
      "step": 363380
    },
    {
      "epoch": 586.13,
      "learning_rate": 0.041410381170322585,
      "loss": 0.6616,
      "step": 363400
    },
    {
      "epoch": 586.16,
      "learning_rate": 0.041407155367096785,
      "loss": 0.6568,
      "step": 363420
    },
    {
      "epoch": 586.19,
      "learning_rate": 0.04140392956387098,
      "loss": 0.666,
      "step": 363440
    },
    {
      "epoch": 586.23,
      "learning_rate": 0.04140070376064517,
      "loss": 0.6502,
      "step": 363460
    },
    {
      "epoch": 586.26,
      "learning_rate": 0.041397477957419354,
      "loss": 0.6461,
      "step": 363480
    },
    {
      "epoch": 586.29,
      "learning_rate": 0.041394252154193546,
      "loss": 0.6586,
      "step": 363500
    },
    {
      "epoch": 586.32,
      "learning_rate": 0.041391026350967745,
      "loss": 0.661,
      "step": 363520
    },
    {
      "epoch": 586.35,
      "learning_rate": 0.04138780054774194,
      "loss": 0.6554,
      "step": 363540
    },
    {
      "epoch": 586.39,
      "learning_rate": 0.04138457474451613,
      "loss": 0.6614,
      "step": 363560
    },
    {
      "epoch": 586.42,
      "learning_rate": 0.04138134894129032,
      "loss": 0.6668,
      "step": 363580
    },
    {
      "epoch": 586.45,
      "learning_rate": 0.04137812313806452,
      "loss": 0.6718,
      "step": 363600
    },
    {
      "epoch": 586.48,
      "learning_rate": 0.04137489733483871,
      "loss": 0.6728,
      "step": 363620
    },
    {
      "epoch": 586.52,
      "learning_rate": 0.041371671531612905,
      "loss": 0.6642,
      "step": 363640
    },
    {
      "epoch": 586.55,
      "learning_rate": 0.041368445728387104,
      "loss": 0.6791,
      "step": 363660
    },
    {
      "epoch": 586.58,
      "learning_rate": 0.041365219925161296,
      "loss": 0.6651,
      "step": 363680
    },
    {
      "epoch": 586.61,
      "learning_rate": 0.04136199412193549,
      "loss": 0.6632,
      "step": 363700
    },
    {
      "epoch": 586.65,
      "learning_rate": 0.04135876831870969,
      "loss": 0.6786,
      "step": 363720
    },
    {
      "epoch": 586.68,
      "learning_rate": 0.04135554251548388,
      "loss": 0.6768,
      "step": 363740
    },
    {
      "epoch": 586.71,
      "learning_rate": 0.04135231671225807,
      "loss": 0.6614,
      "step": 363760
    },
    {
      "epoch": 586.74,
      "learning_rate": 0.04134909090903226,
      "loss": 0.6528,
      "step": 363780
    },
    {
      "epoch": 586.77,
      "learning_rate": 0.04134586510580645,
      "loss": 0.6564,
      "step": 363800
    },
    {
      "epoch": 586.81,
      "learning_rate": 0.04134263930258065,
      "loss": 0.6788,
      "step": 363820
    },
    {
      "epoch": 586.84,
      "learning_rate": 0.04133941349935484,
      "loss": 0.6658,
      "step": 363840
    },
    {
      "epoch": 586.87,
      "learning_rate": 0.04133618769612903,
      "loss": 0.6657,
      "step": 363860
    },
    {
      "epoch": 586.9,
      "learning_rate": 0.041332961892903225,
      "loss": 0.6634,
      "step": 363880
    },
    {
      "epoch": 586.94,
      "learning_rate": 0.041329736089677424,
      "loss": 0.6703,
      "step": 363900
    },
    {
      "epoch": 586.97,
      "learning_rate": 0.041326510286451616,
      "loss": 0.69,
      "step": 363920
    },
    {
      "epoch": 587.0,
      "learning_rate": 0.0413234457733871,
      "loss": 0.6759,
      "step": 363940
    },
    {
      "epoch": 587.0,
      "eval_accuracy": {
        "accuracy": 0.7589571462024822
      },
      "eval_loss": 1.0481760501861572,
      "eval_runtime": 4.2538,
      "eval_samples_per_second": 3011.67,
      "eval_steps_per_second": 47.252,
      "step": 363940
    },
    {
      "epoch": 587.03,
      "learning_rate": 0.04132021997016129,
      "loss": 0.6576,
      "step": 363960
    },
    {
      "epoch": 587.06,
      "learning_rate": 0.04131699416693548,
      "loss": 0.6737,
      "step": 363980
    },
    {
      "epoch": 587.1,
      "learning_rate": 0.04131376836370968,
      "loss": 0.6664,
      "step": 364000
    },
    {
      "epoch": 587.13,
      "learning_rate": 0.04131054256048387,
      "loss": 0.6509,
      "step": 364020
    },
    {
      "epoch": 587.16,
      "learning_rate": 0.041307316757258065,
      "loss": 0.6473,
      "step": 364040
    },
    {
      "epoch": 587.19,
      "learning_rate": 0.041304090954032265,
      "loss": 0.6578,
      "step": 364060
    },
    {
      "epoch": 587.23,
      "learning_rate": 0.04130086515080646,
      "loss": 0.667,
      "step": 364080
    },
    {
      "epoch": 587.26,
      "learning_rate": 0.04129763934758065,
      "loss": 0.6407,
      "step": 364100
    },
    {
      "epoch": 587.29,
      "learning_rate": 0.04129441354435485,
      "loss": 0.6577,
      "step": 364120
    },
    {
      "epoch": 587.32,
      "learning_rate": 0.04129118774112904,
      "loss": 0.6596,
      "step": 364140
    },
    {
      "epoch": 587.35,
      "learning_rate": 0.04128796193790323,
      "loss": 0.666,
      "step": 364160
    },
    {
      "epoch": 587.39,
      "learning_rate": 0.041284736134677424,
      "loss": 0.6712,
      "step": 364180
    },
    {
      "epoch": 587.42,
      "learning_rate": 0.041281510331451624,
      "loss": 0.6709,
      "step": 364200
    },
    {
      "epoch": 587.45,
      "learning_rate": 0.041278284528225816,
      "loss": 0.6701,
      "step": 364220
    },
    {
      "epoch": 587.48,
      "learning_rate": 0.041275058725,
      "loss": 0.6766,
      "step": 364240
    },
    {
      "epoch": 587.52,
      "learning_rate": 0.04127183292177419,
      "loss": 0.6703,
      "step": 364260
    },
    {
      "epoch": 587.55,
      "learning_rate": 0.041268607118548385,
      "loss": 0.6685,
      "step": 364280
    },
    {
      "epoch": 587.58,
      "learning_rate": 0.041265381315322584,
      "loss": 0.6739,
      "step": 364300
    },
    {
      "epoch": 587.61,
      "learning_rate": 0.041262155512096776,
      "loss": 0.6725,
      "step": 364320
    },
    {
      "epoch": 587.65,
      "learning_rate": 0.04125892970887097,
      "loss": 0.6496,
      "step": 364340
    },
    {
      "epoch": 587.68,
      "learning_rate": 0.04125570390564517,
      "loss": 0.6745,
      "step": 364360
    },
    {
      "epoch": 587.71,
      "learning_rate": 0.04125247810241936,
      "loss": 0.6807,
      "step": 364380
    },
    {
      "epoch": 587.74,
      "learning_rate": 0.04124925229919355,
      "loss": 0.6793,
      "step": 364400
    },
    {
      "epoch": 587.77,
      "learning_rate": 0.041246026495967744,
      "loss": 0.6953,
      "step": 364420
    },
    {
      "epoch": 587.81,
      "learning_rate": 0.04124280069274194,
      "loss": 0.6765,
      "step": 364440
    },
    {
      "epoch": 587.84,
      "learning_rate": 0.041239574889516135,
      "loss": 0.6791,
      "step": 364460
    },
    {
      "epoch": 587.87,
      "learning_rate": 0.04123634908629033,
      "loss": 0.668,
      "step": 364480
    },
    {
      "epoch": 587.9,
      "learning_rate": 0.04123312328306453,
      "loss": 0.6793,
      "step": 364500
    },
    {
      "epoch": 587.94,
      "learning_rate": 0.04122989747983872,
      "loss": 0.6755,
      "step": 364520
    },
    {
      "epoch": 587.97,
      "learning_rate": 0.041226671676612904,
      "loss": 0.6813,
      "step": 364540
    },
    {
      "epoch": 588.0,
      "learning_rate": 0.041223445873387096,
      "loss": 0.6718,
      "step": 364560
    },
    {
      "epoch": 588.0,
      "eval_accuracy": {
        "accuracy": 0.7687924439934432
      },
      "eval_loss": 1.0144288539886475,
      "eval_runtime": 3.2479,
      "eval_samples_per_second": 3944.426,
      "eval_steps_per_second": 61.887,
      "step": 364560
    },
    {
      "epoch": 588.03,
      "learning_rate": 0.04122022007016129,
      "loss": 0.6743,
      "step": 364580
    },
    {
      "epoch": 588.06,
      "learning_rate": 0.04121699426693549,
      "loss": 0.6659,
      "step": 364600
    },
    {
      "epoch": 588.1,
      "learning_rate": 0.04121376846370968,
      "loss": 0.6523,
      "step": 364620
    },
    {
      "epoch": 588.13,
      "learning_rate": 0.04121054266048387,
      "loss": 0.6656,
      "step": 364640
    },
    {
      "epoch": 588.16,
      "learning_rate": 0.04120731685725807,
      "loss": 0.6615,
      "step": 364660
    },
    {
      "epoch": 588.19,
      "learning_rate": 0.04120409105403226,
      "loss": 0.6695,
      "step": 364680
    },
    {
      "epoch": 588.23,
      "learning_rate": 0.041200865250806455,
      "loss": 0.6622,
      "step": 364700
    },
    {
      "epoch": 588.26,
      "learning_rate": 0.04119763944758065,
      "loss": 0.6578,
      "step": 364720
    },
    {
      "epoch": 588.29,
      "learning_rate": 0.041194413644354846,
      "loss": 0.6673,
      "step": 364740
    },
    {
      "epoch": 588.32,
      "learning_rate": 0.04119118784112904,
      "loss": 0.6714,
      "step": 364760
    },
    {
      "epoch": 588.35,
      "learning_rate": 0.04118796203790323,
      "loss": 0.6669,
      "step": 364780
    },
    {
      "epoch": 588.39,
      "learning_rate": 0.04118473623467743,
      "loss": 0.6562,
      "step": 364800
    },
    {
      "epoch": 588.42,
      "learning_rate": 0.04118151043145162,
      "loss": 0.6671,
      "step": 364820
    },
    {
      "epoch": 588.45,
      "learning_rate": 0.041178284628225814,
      "loss": 0.6569,
      "step": 364840
    },
    {
      "epoch": 588.48,
      "learning_rate": 0.041175058825,
      "loss": 0.6595,
      "step": 364860
    },
    {
      "epoch": 588.52,
      "learning_rate": 0.04117183302177419,
      "loss": 0.6555,
      "step": 364880
    },
    {
      "epoch": 588.55,
      "learning_rate": 0.04116860721854839,
      "loss": 0.6676,
      "step": 364900
    },
    {
      "epoch": 588.58,
      "learning_rate": 0.04116538141532258,
      "loss": 0.6639,
      "step": 364920
    },
    {
      "epoch": 588.61,
      "learning_rate": 0.041162155612096775,
      "loss": 0.671,
      "step": 364940
    },
    {
      "epoch": 588.65,
      "learning_rate": 0.04115892980887097,
      "loss": 0.6672,
      "step": 364960
    },
    {
      "epoch": 588.68,
      "learning_rate": 0.041155704005645166,
      "loss": 0.6809,
      "step": 364980
    },
    {
      "epoch": 588.71,
      "learning_rate": 0.04115247820241936,
      "loss": 0.6823,
      "step": 365000
    },
    {
      "epoch": 588.74,
      "learning_rate": 0.04114925239919355,
      "loss": 0.6764,
      "step": 365020
    },
    {
      "epoch": 588.77,
      "learning_rate": 0.04114602659596775,
      "loss": 0.6782,
      "step": 365040
    },
    {
      "epoch": 588.81,
      "learning_rate": 0.04114280079274194,
      "loss": 0.6644,
      "step": 365060
    },
    {
      "epoch": 588.84,
      "learning_rate": 0.041139574989516134,
      "loss": 0.6717,
      "step": 365080
    },
    {
      "epoch": 588.87,
      "learning_rate": 0.04113634918629033,
      "loss": 0.6694,
      "step": 365100
    },
    {
      "epoch": 588.9,
      "learning_rate": 0.041133123383064525,
      "loss": 0.683,
      "step": 365120
    },
    {
      "epoch": 588.94,
      "learning_rate": 0.04112989757983872,
      "loss": 0.6784,
      "step": 365140
    },
    {
      "epoch": 588.97,
      "learning_rate": 0.0411266717766129,
      "loss": 0.6677,
      "step": 365160
    },
    {
      "epoch": 589.0,
      "learning_rate": 0.041123445973387095,
      "loss": 0.6658,
      "step": 365180
    },
    {
      "epoch": 589.0,
      "eval_accuracy": {
        "accuracy": 0.7658262430723597
      },
      "eval_loss": 1.0476062297821045,
      "eval_runtime": 2.9393,
      "eval_samples_per_second": 4358.54,
      "eval_steps_per_second": 68.384,
      "step": 365180
    },
    {
      "epoch": 589.03,
      "learning_rate": 0.04112022017016129,
      "loss": 0.6856,
      "step": 365200
    },
    {
      "epoch": 589.06,
      "learning_rate": 0.041116994366935486,
      "loss": 0.672,
      "step": 365220
    },
    {
      "epoch": 589.1,
      "learning_rate": 0.04111376856370968,
      "loss": 0.6686,
      "step": 365240
    },
    {
      "epoch": 589.13,
      "learning_rate": 0.04111054276048387,
      "loss": 0.6454,
      "step": 365260
    },
    {
      "epoch": 589.16,
      "learning_rate": 0.04110731695725807,
      "loss": 0.6597,
      "step": 365280
    },
    {
      "epoch": 589.19,
      "learning_rate": 0.04110409115403226,
      "loss": 0.6653,
      "step": 365300
    },
    {
      "epoch": 589.23,
      "learning_rate": 0.041100865350806454,
      "loss": 0.6589,
      "step": 365320
    },
    {
      "epoch": 589.26,
      "learning_rate": 0.04109763954758065,
      "loss": 0.6723,
      "step": 365340
    },
    {
      "epoch": 589.29,
      "learning_rate": 0.041094413744354845,
      "loss": 0.6584,
      "step": 365360
    },
    {
      "epoch": 589.32,
      "learning_rate": 0.04109118794112904,
      "loss": 0.6494,
      "step": 365380
    },
    {
      "epoch": 589.35,
      "learning_rate": 0.041087962137903236,
      "loss": 0.6687,
      "step": 365400
    },
    {
      "epoch": 589.39,
      "learning_rate": 0.04108473633467743,
      "loss": 0.6712,
      "step": 365420
    },
    {
      "epoch": 589.42,
      "learning_rate": 0.04108151053145162,
      "loss": 0.6797,
      "step": 365440
    },
    {
      "epoch": 589.45,
      "learning_rate": 0.04107828472822581,
      "loss": 0.6597,
      "step": 365460
    },
    {
      "epoch": 589.48,
      "learning_rate": 0.041075058925,
      "loss": 0.6632,
      "step": 365480
    },
    {
      "epoch": 589.52,
      "learning_rate": 0.04107183312177419,
      "loss": 0.6621,
      "step": 365500
    },
    {
      "epoch": 589.55,
      "learning_rate": 0.04106860731854839,
      "loss": 0.6623,
      "step": 365520
    },
    {
      "epoch": 589.58,
      "learning_rate": 0.04106538151532258,
      "loss": 0.6889,
      "step": 365540
    },
    {
      "epoch": 589.61,
      "learning_rate": 0.04106215571209677,
      "loss": 0.6602,
      "step": 365560
    },
    {
      "epoch": 589.65,
      "learning_rate": 0.04105892990887097,
      "loss": 0.6638,
      "step": 365580
    },
    {
      "epoch": 589.68,
      "learning_rate": 0.041055704105645165,
      "loss": 0.6681,
      "step": 365600
    },
    {
      "epoch": 589.71,
      "learning_rate": 0.04105247830241936,
      "loss": 0.6808,
      "step": 365620
    },
    {
      "epoch": 589.74,
      "learning_rate": 0.041049252499193556,
      "loss": 0.6566,
      "step": 365640
    },
    {
      "epoch": 589.77,
      "learning_rate": 0.04104602669596775,
      "loss": 0.6789,
      "step": 365660
    },
    {
      "epoch": 589.81,
      "learning_rate": 0.04104280089274194,
      "loss": 0.6713,
      "step": 365680
    },
    {
      "epoch": 589.84,
      "learning_rate": 0.04103957508951613,
      "loss": 0.66,
      "step": 365700
    },
    {
      "epoch": 589.87,
      "learning_rate": 0.04103634928629033,
      "loss": 0.684,
      "step": 365720
    },
    {
      "epoch": 589.9,
      "learning_rate": 0.041033123483064524,
      "loss": 0.6676,
      "step": 365740
    },
    {
      "epoch": 589.94,
      "learning_rate": 0.041029897679838716,
      "loss": 0.6676,
      "step": 365760
    },
    {
      "epoch": 589.97,
      "learning_rate": 0.041026671876612915,
      "loss": 0.6737,
      "step": 365780
    },
    {
      "epoch": 590.0,
      "learning_rate": 0.04102344607338709,
      "loss": 0.6523,
      "step": 365800
    },
    {
      "epoch": 590.0,
      "eval_accuracy": {
        "accuracy": 0.7691827335883226
      },
      "eval_loss": 1.0284790992736816,
      "eval_runtime": 2.8219,
      "eval_samples_per_second": 4539.769,
      "eval_steps_per_second": 71.227,
      "step": 365800
    },
    {
      "epoch": 590.03,
      "learning_rate": 0.04102022027016129,
      "loss": 0.6625,
      "step": 365820
    },
    {
      "epoch": 590.06,
      "learning_rate": 0.041016994466935484,
      "loss": 0.6594,
      "step": 365840
    },
    {
      "epoch": 590.1,
      "learning_rate": 0.04101376866370968,
      "loss": 0.6517,
      "step": 365860
    },
    {
      "epoch": 590.13,
      "learning_rate": 0.041010542860483876,
      "loss": 0.6572,
      "step": 365880
    },
    {
      "epoch": 590.16,
      "learning_rate": 0.04100731705725807,
      "loss": 0.6459,
      "step": 365900
    },
    {
      "epoch": 590.19,
      "learning_rate": 0.04100409125403226,
      "loss": 0.6595,
      "step": 365920
    },
    {
      "epoch": 590.23,
      "learning_rate": 0.04100086545080646,
      "loss": 0.6683,
      "step": 365940
    },
    {
      "epoch": 590.26,
      "learning_rate": 0.04099763964758065,
      "loss": 0.6694,
      "step": 365960
    },
    {
      "epoch": 590.29,
      "learning_rate": 0.04099441384435484,
      "loss": 0.6566,
      "step": 365980
    },
    {
      "epoch": 590.32,
      "learning_rate": 0.040991188041129036,
      "loss": 0.6805,
      "step": 366000
    },
    {
      "epoch": 590.35,
      "learning_rate": 0.040987962237903235,
      "loss": 0.6711,
      "step": 366020
    },
    {
      "epoch": 590.39,
      "learning_rate": 0.04098473643467743,
      "loss": 0.6596,
      "step": 366040
    },
    {
      "epoch": 590.42,
      "learning_rate": 0.04098151063145162,
      "loss": 0.683,
      "step": 366060
    },
    {
      "epoch": 590.45,
      "learning_rate": 0.04097828482822582,
      "loss": 0.6693,
      "step": 366080
    },
    {
      "epoch": 590.48,
      "learning_rate": 0.040975059024999996,
      "loss": 0.6555,
      "step": 366100
    },
    {
      "epoch": 590.52,
      "learning_rate": 0.040971833221774195,
      "loss": 0.6549,
      "step": 366120
    },
    {
      "epoch": 590.55,
      "learning_rate": 0.04096860741854839,
      "loss": 0.6707,
      "step": 366140
    },
    {
      "epoch": 590.58,
      "learning_rate": 0.04096538161532258,
      "loss": 0.6625,
      "step": 366160
    },
    {
      "epoch": 590.61,
      "learning_rate": 0.04096215581209678,
      "loss": 0.6672,
      "step": 366180
    },
    {
      "epoch": 590.65,
      "learning_rate": 0.04095893000887097,
      "loss": 0.6738,
      "step": 366200
    },
    {
      "epoch": 590.68,
      "learning_rate": 0.04095570420564516,
      "loss": 0.672,
      "step": 366220
    },
    {
      "epoch": 590.71,
      "learning_rate": 0.040952478402419355,
      "loss": 0.6725,
      "step": 366240
    },
    {
      "epoch": 590.74,
      "learning_rate": 0.040949252599193554,
      "loss": 0.658,
      "step": 366260
    },
    {
      "epoch": 590.77,
      "learning_rate": 0.040946026795967747,
      "loss": 0.6656,
      "step": 366280
    },
    {
      "epoch": 590.81,
      "learning_rate": 0.04094280099274194,
      "loss": 0.6691,
      "step": 366300
    },
    {
      "epoch": 590.84,
      "learning_rate": 0.04093957518951614,
      "loss": 0.6668,
      "step": 366320
    },
    {
      "epoch": 590.87,
      "learning_rate": 0.04093634938629033,
      "loss": 0.6708,
      "step": 366340
    },
    {
      "epoch": 590.9,
      "learning_rate": 0.04093312358306452,
      "loss": 0.6775,
      "step": 366360
    },
    {
      "epoch": 590.94,
      "learning_rate": 0.04092989777983872,
      "loss": 0.6792,
      "step": 366380
    },
    {
      "epoch": 590.97,
      "learning_rate": 0.04092667197661291,
      "loss": 0.6806,
      "step": 366400
    },
    {
      "epoch": 591.0,
      "learning_rate": 0.040923607463548395,
      "loss": 0.6809,
      "step": 366420
    },
    {
      "epoch": 591.0,
      "eval_accuracy": {
        "accuracy": 0.7620794629615174
      },
      "eval_loss": 1.044456124305725,
      "eval_runtime": 3.8813,
      "eval_samples_per_second": 3300.71,
      "eval_steps_per_second": 51.787,
      "step": 366420
    },
    {
      "epoch": 591.03,
      "learning_rate": 0.04092038166032259,
      "loss": 0.6714,
      "step": 366440
    },
    {
      "epoch": 591.06,
      "learning_rate": 0.04091715585709678,
      "loss": 0.6505,
      "step": 366460
    },
    {
      "epoch": 591.1,
      "learning_rate": 0.04091393005387098,
      "loss": 0.6708,
      "step": 366480
    },
    {
      "epoch": 591.13,
      "learning_rate": 0.04091070425064517,
      "loss": 0.661,
      "step": 366500
    },
    {
      "epoch": 591.16,
      "learning_rate": 0.04090747844741936,
      "loss": 0.6414,
      "step": 366520
    },
    {
      "epoch": 591.19,
      "learning_rate": 0.040904252644193555,
      "loss": 0.6547,
      "step": 366540
    },
    {
      "epoch": 591.23,
      "learning_rate": 0.04090102684096774,
      "loss": 0.6563,
      "step": 366560
    },
    {
      "epoch": 591.26,
      "learning_rate": 0.04089780103774193,
      "loss": 0.6609,
      "step": 366580
    },
    {
      "epoch": 591.29,
      "learning_rate": 0.04089457523451613,
      "loss": 0.6521,
      "step": 366600
    },
    {
      "epoch": 591.32,
      "learning_rate": 0.04089134943129032,
      "loss": 0.6615,
      "step": 366620
    },
    {
      "epoch": 591.35,
      "learning_rate": 0.040888123628064516,
      "loss": 0.6754,
      "step": 366640
    },
    {
      "epoch": 591.39,
      "learning_rate": 0.040884897824838715,
      "loss": 0.6661,
      "step": 366660
    },
    {
      "epoch": 591.42,
      "learning_rate": 0.04088167202161291,
      "loss": 0.6661,
      "step": 366680
    },
    {
      "epoch": 591.45,
      "learning_rate": 0.0408784462183871,
      "loss": 0.6906,
      "step": 366700
    },
    {
      "epoch": 591.48,
      "learning_rate": 0.0408752204151613,
      "loss": 0.6698,
      "step": 366720
    },
    {
      "epoch": 591.52,
      "learning_rate": 0.04087199461193549,
      "loss": 0.6717,
      "step": 366740
    },
    {
      "epoch": 591.55,
      "learning_rate": 0.04086876880870968,
      "loss": 0.6602,
      "step": 366760
    },
    {
      "epoch": 591.58,
      "learning_rate": 0.040865543005483874,
      "loss": 0.6641,
      "step": 366780
    },
    {
      "epoch": 591.61,
      "learning_rate": 0.040862317202258074,
      "loss": 0.6577,
      "step": 366800
    },
    {
      "epoch": 591.65,
      "learning_rate": 0.040859091399032266,
      "loss": 0.668,
      "step": 366820
    },
    {
      "epoch": 591.68,
      "learning_rate": 0.04085586559580646,
      "loss": 0.6673,
      "step": 366840
    },
    {
      "epoch": 591.71,
      "learning_rate": 0.04085263979258064,
      "loss": 0.6753,
      "step": 366860
    },
    {
      "epoch": 591.74,
      "learning_rate": 0.040849413989354835,
      "loss": 0.6771,
      "step": 366880
    },
    {
      "epoch": 591.77,
      "learning_rate": 0.040846188186129034,
      "loss": 0.6666,
      "step": 366900
    },
    {
      "epoch": 591.81,
      "learning_rate": 0.040842962382903227,
      "loss": 0.6655,
      "step": 366920
    },
    {
      "epoch": 591.84,
      "learning_rate": 0.04083973657967742,
      "loss": 0.6812,
      "step": 366940
    },
    {
      "epoch": 591.87,
      "learning_rate": 0.04083651077645162,
      "loss": 0.673,
      "step": 366960
    },
    {
      "epoch": 591.9,
      "learning_rate": 0.04083328497322581,
      "loss": 0.6689,
      "step": 366980
    },
    {
      "epoch": 591.94,
      "learning_rate": 0.04083005917,
      "loss": 0.6805,
      "step": 367000
    },
    {
      "epoch": 591.97,
      "learning_rate": 0.0408268333667742,
      "loss": 0.6735,
      "step": 367020
    },
    {
      "epoch": 592.0,
      "learning_rate": 0.04082360756354839,
      "loss": 0.6812,
      "step": 367040
    },
    {
      "epoch": 592.0,
      "eval_accuracy": {
        "accuracy": 0.7616111154476621
      },
      "eval_loss": 1.0419296026229858,
      "eval_runtime": 2.8692,
      "eval_samples_per_second": 4465.051,
      "eval_steps_per_second": 70.055,
      "step": 367040
    },
    {
      "epoch": 592.03,
      "learning_rate": 0.040820381760322585,
      "loss": 0.6789,
      "step": 367060
    },
    {
      "epoch": 592.06,
      "learning_rate": 0.04081715595709678,
      "loss": 0.6476,
      "step": 367080
    },
    {
      "epoch": 592.1,
      "learning_rate": 0.04081393015387098,
      "loss": 0.6753,
      "step": 367100
    },
    {
      "epoch": 592.13,
      "learning_rate": 0.04081070435064517,
      "loss": 0.6561,
      "step": 367120
    },
    {
      "epoch": 592.16,
      "learning_rate": 0.04080747854741936,
      "loss": 0.6522,
      "step": 367140
    },
    {
      "epoch": 592.19,
      "learning_rate": 0.04080425274419356,
      "loss": 0.6638,
      "step": 367160
    },
    {
      "epoch": 592.23,
      "learning_rate": 0.04080102694096774,
      "loss": 0.6647,
      "step": 367180
    },
    {
      "epoch": 592.26,
      "learning_rate": 0.04079780113774194,
      "loss": 0.6519,
      "step": 367200
    },
    {
      "epoch": 592.29,
      "learning_rate": 0.04079457533451613,
      "loss": 0.6606,
      "step": 367220
    },
    {
      "epoch": 592.32,
      "learning_rate": 0.04079134953129032,
      "loss": 0.6627,
      "step": 367240
    },
    {
      "epoch": 592.35,
      "learning_rate": 0.04078812372806452,
      "loss": 0.6693,
      "step": 367260
    },
    {
      "epoch": 592.39,
      "learning_rate": 0.04078489792483871,
      "loss": 0.6695,
      "step": 367280
    },
    {
      "epoch": 592.42,
      "learning_rate": 0.040781672121612905,
      "loss": 0.6584,
      "step": 367300
    },
    {
      "epoch": 592.45,
      "learning_rate": 0.0407784463183871,
      "loss": 0.6618,
      "step": 367320
    },
    {
      "epoch": 592.48,
      "learning_rate": 0.040775220515161296,
      "loss": 0.6567,
      "step": 367340
    },
    {
      "epoch": 592.52,
      "learning_rate": 0.04077199471193549,
      "loss": 0.6527,
      "step": 367360
    },
    {
      "epoch": 592.55,
      "learning_rate": 0.04076876890870968,
      "loss": 0.6596,
      "step": 367380
    },
    {
      "epoch": 592.58,
      "learning_rate": 0.04076554310548388,
      "loss": 0.6677,
      "step": 367400
    },
    {
      "epoch": 592.61,
      "learning_rate": 0.04076231730225807,
      "loss": 0.6525,
      "step": 367420
    },
    {
      "epoch": 592.65,
      "learning_rate": 0.040759091499032264,
      "loss": 0.6834,
      "step": 367440
    },
    {
      "epoch": 592.68,
      "learning_rate": 0.04075586569580646,
      "loss": 0.6716,
      "step": 367460
    },
    {
      "epoch": 592.71,
      "learning_rate": 0.04075263989258064,
      "loss": 0.6866,
      "step": 367480
    },
    {
      "epoch": 592.74,
      "learning_rate": 0.04074941408935484,
      "loss": 0.65,
      "step": 367500
    },
    {
      "epoch": 592.77,
      "learning_rate": 0.04074618828612903,
      "loss": 0.6572,
      "step": 367520
    },
    {
      "epoch": 592.81,
      "learning_rate": 0.040742962482903225,
      "loss": 0.6646,
      "step": 367540
    },
    {
      "epoch": 592.84,
      "learning_rate": 0.040739736679677424,
      "loss": 0.6748,
      "step": 367560
    },
    {
      "epoch": 592.87,
      "learning_rate": 0.040736510876451616,
      "loss": 0.6819,
      "step": 367580
    },
    {
      "epoch": 592.9,
      "learning_rate": 0.04073328507322581,
      "loss": 0.674,
      "step": 367600
    },
    {
      "epoch": 592.94,
      "learning_rate": 0.04073005927,
      "loss": 0.6614,
      "step": 367620
    },
    {
      "epoch": 592.97,
      "learning_rate": 0.0407268334667742,
      "loss": 0.6721,
      "step": 367640
    },
    {
      "epoch": 593.0,
      "learning_rate": 0.04072360766354839,
      "loss": 0.6773,
      "step": 367660
    },
    {
      "epoch": 593.0,
      "eval_accuracy": {
        "accuracy": 0.7680118648036843
      },
      "eval_loss": 1.0289711952209473,
      "eval_runtime": 3.0724,
      "eval_samples_per_second": 4169.725,
      "eval_steps_per_second": 65.421,
      "step": 367660
    },
    {
      "epoch": 593.03,
      "learning_rate": 0.040720381860322584,
      "loss": 0.6796,
      "step": 367680
    },
    {
      "epoch": 593.06,
      "learning_rate": 0.04071715605709678,
      "loss": 0.663,
      "step": 367700
    },
    {
      "epoch": 593.1,
      "learning_rate": 0.040713930253870975,
      "loss": 0.6544,
      "step": 367720
    },
    {
      "epoch": 593.13,
      "learning_rate": 0.04071070445064517,
      "loss": 0.6533,
      "step": 367740
    },
    {
      "epoch": 593.16,
      "learning_rate": 0.040707478647419366,
      "loss": 0.6401,
      "step": 367760
    },
    {
      "epoch": 593.19,
      "learning_rate": 0.04070425284419356,
      "loss": 0.6493,
      "step": 367780
    },
    {
      "epoch": 593.23,
      "learning_rate": 0.040701027040967744,
      "loss": 0.6447,
      "step": 367800
    },
    {
      "epoch": 593.26,
      "learning_rate": 0.040697801237741936,
      "loss": 0.6445,
      "step": 367820
    },
    {
      "epoch": 593.29,
      "learning_rate": 0.04069457543451613,
      "loss": 0.6611,
      "step": 367840
    },
    {
      "epoch": 593.32,
      "learning_rate": 0.04069134963129032,
      "loss": 0.6569,
      "step": 367860
    },
    {
      "epoch": 593.35,
      "learning_rate": 0.04068812382806452,
      "loss": 0.641,
      "step": 367880
    },
    {
      "epoch": 593.39,
      "learning_rate": 0.04068489802483871,
      "loss": 0.6752,
      "step": 367900
    },
    {
      "epoch": 593.42,
      "learning_rate": 0.040681672221612904,
      "loss": 0.6616,
      "step": 367920
    },
    {
      "epoch": 593.45,
      "learning_rate": 0.0406784464183871,
      "loss": 0.6651,
      "step": 367940
    },
    {
      "epoch": 593.48,
      "learning_rate": 0.040675220615161295,
      "loss": 0.6668,
      "step": 367960
    },
    {
      "epoch": 593.52,
      "learning_rate": 0.04067199481193549,
      "loss": 0.6955,
      "step": 367980
    },
    {
      "epoch": 593.55,
      "learning_rate": 0.040668769008709686,
      "loss": 0.6713,
      "step": 368000
    },
    {
      "epoch": 593.58,
      "learning_rate": 0.04066554320548388,
      "loss": 0.6857,
      "step": 368020
    },
    {
      "epoch": 593.61,
      "learning_rate": 0.04066231740225807,
      "loss": 0.6634,
      "step": 368040
    },
    {
      "epoch": 593.65,
      "learning_rate": 0.04065909159903227,
      "loss": 0.6784,
      "step": 368060
    },
    {
      "epoch": 593.68,
      "learning_rate": 0.04065586579580646,
      "loss": 0.6808,
      "step": 368080
    },
    {
      "epoch": 593.71,
      "learning_rate": 0.04065263999258065,
      "loss": 0.665,
      "step": 368100
    },
    {
      "epoch": 593.74,
      "learning_rate": 0.04064941418935484,
      "loss": 0.6555,
      "step": 368120
    },
    {
      "epoch": 593.77,
      "learning_rate": 0.04064618838612903,
      "loss": 0.6695,
      "step": 368140
    },
    {
      "epoch": 593.81,
      "learning_rate": 0.04064296258290322,
      "loss": 0.6653,
      "step": 368160
    },
    {
      "epoch": 593.84,
      "learning_rate": 0.04063973677967742,
      "loss": 0.6703,
      "step": 368180
    },
    {
      "epoch": 593.87,
      "learning_rate": 0.040636510976451615,
      "loss": 0.6654,
      "step": 368200
    },
    {
      "epoch": 593.9,
      "learning_rate": 0.04063328517322581,
      "loss": 0.6771,
      "step": 368220
    },
    {
      "epoch": 593.94,
      "learning_rate": 0.040630059370000006,
      "loss": 0.6796,
      "step": 368240
    },
    {
      "epoch": 593.97,
      "learning_rate": 0.0406268335667742,
      "loss": 0.6713,
      "step": 368260
    },
    {
      "epoch": 594.0,
      "learning_rate": 0.04062360776354839,
      "loss": 0.6659,
      "step": 368280
    },
    {
      "epoch": 594.0,
      "eval_accuracy": {
        "accuracy": 0.7710561236437437
      },
      "eval_loss": 1.0141364336013794,
      "eval_runtime": 4.5327,
      "eval_samples_per_second": 2826.362,
      "eval_steps_per_second": 44.345,
      "step": 368280
    },
    {
      "epoch": 594.03,
      "learning_rate": 0.04062038196032259,
      "loss": 0.6824,
      "step": 368300
    },
    {
      "epoch": 594.06,
      "learning_rate": 0.04061715615709678,
      "loss": 0.6651,
      "step": 368320
    },
    {
      "epoch": 594.1,
      "learning_rate": 0.040613930353870974,
      "loss": 0.6641,
      "step": 368340
    },
    {
      "epoch": 594.13,
      "learning_rate": 0.040610704550645166,
      "loss": 0.6581,
      "step": 368360
    },
    {
      "epoch": 594.16,
      "learning_rate": 0.040607478747419365,
      "loss": 0.6509,
      "step": 368380
    },
    {
      "epoch": 594.19,
      "learning_rate": 0.04060425294419356,
      "loss": 0.6621,
      "step": 368400
    },
    {
      "epoch": 594.23,
      "learning_rate": 0.04060102714096774,
      "loss": 0.6394,
      "step": 368420
    },
    {
      "epoch": 594.26,
      "learning_rate": 0.040597801337741934,
      "loss": 0.6767,
      "step": 368440
    },
    {
      "epoch": 594.29,
      "learning_rate": 0.04059457553451613,
      "loss": 0.655,
      "step": 368460
    },
    {
      "epoch": 594.32,
      "learning_rate": 0.040591349731290326,
      "loss": 0.6426,
      "step": 368480
    },
    {
      "epoch": 594.35,
      "learning_rate": 0.04058812392806452,
      "loss": 0.6601,
      "step": 368500
    },
    {
      "epoch": 594.39,
      "learning_rate": 0.04058489812483871,
      "loss": 0.6787,
      "step": 368520
    },
    {
      "epoch": 594.42,
      "learning_rate": 0.04058167232161291,
      "loss": 0.6766,
      "step": 368540
    },
    {
      "epoch": 594.45,
      "learning_rate": 0.0405784465183871,
      "loss": 0.6556,
      "step": 368560
    },
    {
      "epoch": 594.48,
      "learning_rate": 0.04057522071516129,
      "loss": 0.648,
      "step": 368580
    },
    {
      "epoch": 594.52,
      "learning_rate": 0.040571994911935486,
      "loss": 0.6594,
      "step": 368600
    },
    {
      "epoch": 594.55,
      "learning_rate": 0.040568769108709685,
      "loss": 0.6657,
      "step": 368620
    },
    {
      "epoch": 594.58,
      "learning_rate": 0.04056554330548388,
      "loss": 0.6667,
      "step": 368640
    },
    {
      "epoch": 594.61,
      "learning_rate": 0.04056231750225807,
      "loss": 0.6651,
      "step": 368660
    },
    {
      "epoch": 594.65,
      "learning_rate": 0.04055909169903227,
      "loss": 0.6649,
      "step": 368680
    },
    {
      "epoch": 594.68,
      "learning_rate": 0.04055586589580646,
      "loss": 0.6548,
      "step": 368700
    },
    {
      "epoch": 594.71,
      "learning_rate": 0.04055264009258065,
      "loss": 0.6598,
      "step": 368720
    },
    {
      "epoch": 594.74,
      "learning_rate": 0.04054941428935484,
      "loss": 0.6626,
      "step": 368740
    },
    {
      "epoch": 594.77,
      "learning_rate": 0.04054618848612903,
      "loss": 0.6519,
      "step": 368760
    },
    {
      "epoch": 594.81,
      "learning_rate": 0.04054296268290323,
      "loss": 0.6811,
      "step": 368780
    },
    {
      "epoch": 594.84,
      "learning_rate": 0.04053973687967742,
      "loss": 0.6634,
      "step": 368800
    },
    {
      "epoch": 594.87,
      "learning_rate": 0.04053651107645161,
      "loss": 0.666,
      "step": 368820
    },
    {
      "epoch": 594.9,
      "learning_rate": 0.04053328527322581,
      "loss": 0.6637,
      "step": 368840
    },
    {
      "epoch": 594.94,
      "learning_rate": 0.040530059470000004,
      "loss": 0.6702,
      "step": 368860
    },
    {
      "epoch": 594.97,
      "learning_rate": 0.0405268336667742,
      "loss": 0.6592,
      "step": 368880
    },
    {
      "epoch": 595.0,
      "learning_rate": 0.04052360786354839,
      "loss": 0.6928,
      "step": 368900
    },
    {
      "epoch": 595.0,
      "eval_accuracy": {
        "accuracy": 0.7599718991491686
      },
      "eval_loss": 1.0672920942306519,
      "eval_runtime": 3.1818,
      "eval_samples_per_second": 4026.356,
      "eval_steps_per_second": 63.172,
      "step": 368900
    },
    {
      "epoch": 595.03,
      "learning_rate": 0.04052038206032259,
      "loss": 0.6909,
      "step": 368920
    },
    {
      "epoch": 595.06,
      "learning_rate": 0.04051715625709678,
      "loss": 0.6743,
      "step": 368940
    },
    {
      "epoch": 595.1,
      "learning_rate": 0.04051393045387097,
      "loss": 0.6685,
      "step": 368960
    },
    {
      "epoch": 595.13,
      "learning_rate": 0.04051070465064517,
      "loss": 0.6525,
      "step": 368980
    },
    {
      "epoch": 595.16,
      "learning_rate": 0.04050747884741936,
      "loss": 0.6419,
      "step": 369000
    },
    {
      "epoch": 595.19,
      "learning_rate": 0.040504253044193556,
      "loss": 0.6577,
      "step": 369020
    },
    {
      "epoch": 595.23,
      "learning_rate": 0.04050102724096774,
      "loss": 0.6435,
      "step": 369040
    },
    {
      "epoch": 595.26,
      "learning_rate": 0.04049780143774193,
      "loss": 0.6622,
      "step": 369060
    },
    {
      "epoch": 595.29,
      "learning_rate": 0.04049457563451613,
      "loss": 0.6533,
      "step": 369080
    },
    {
      "epoch": 595.32,
      "learning_rate": 0.040491349831290324,
      "loss": 0.6732,
      "step": 369100
    },
    {
      "epoch": 595.35,
      "learning_rate": 0.040488124028064516,
      "loss": 0.665,
      "step": 369120
    },
    {
      "epoch": 595.39,
      "learning_rate": 0.04048489822483871,
      "loss": 0.655,
      "step": 369140
    },
    {
      "epoch": 595.42,
      "learning_rate": 0.04048167242161291,
      "loss": 0.6454,
      "step": 369160
    },
    {
      "epoch": 595.45,
      "learning_rate": 0.0404784466183871,
      "loss": 0.6514,
      "step": 369180
    },
    {
      "epoch": 595.48,
      "learning_rate": 0.04047522081516129,
      "loss": 0.6483,
      "step": 369200
    },
    {
      "epoch": 595.52,
      "learning_rate": 0.04047199501193549,
      "loss": 0.6437,
      "step": 369220
    },
    {
      "epoch": 595.55,
      "learning_rate": 0.04046876920870968,
      "loss": 0.6492,
      "step": 369240
    },
    {
      "epoch": 595.58,
      "learning_rate": 0.040465543405483875,
      "loss": 0.6709,
      "step": 369260
    },
    {
      "epoch": 595.61,
      "learning_rate": 0.040462317602258074,
      "loss": 0.6738,
      "step": 369280
    },
    {
      "epoch": 595.65,
      "learning_rate": 0.04045909179903227,
      "loss": 0.682,
      "step": 369300
    },
    {
      "epoch": 595.68,
      "learning_rate": 0.04045586599580646,
      "loss": 0.6799,
      "step": 369320
    },
    {
      "epoch": 595.71,
      "learning_rate": 0.04045264019258066,
      "loss": 0.6551,
      "step": 369340
    },
    {
      "epoch": 595.74,
      "learning_rate": 0.040449414389354836,
      "loss": 0.6671,
      "step": 369360
    },
    {
      "epoch": 595.77,
      "learning_rate": 0.040446188586129035,
      "loss": 0.6678,
      "step": 369380
    },
    {
      "epoch": 595.81,
      "learning_rate": 0.04044296278290323,
      "loss": 0.6531,
      "step": 369400
    },
    {
      "epoch": 595.84,
      "learning_rate": 0.04043973697967742,
      "loss": 0.6622,
      "step": 369420
    },
    {
      "epoch": 595.87,
      "learning_rate": 0.04043651117645161,
      "loss": 0.6631,
      "step": 369440
    },
    {
      "epoch": 595.9,
      "learning_rate": 0.04043328537322581,
      "loss": 0.6611,
      "step": 369460
    },
    {
      "epoch": 595.94,
      "learning_rate": 0.04043005957,
      "loss": 0.6694,
      "step": 369480
    },
    {
      "epoch": 595.97,
      "learning_rate": 0.040426833766774195,
      "loss": 0.6727,
      "step": 369500
    },
    {
      "epoch": 596.0,
      "learning_rate": 0.04042376925370968,
      "loss": 0.6758,
      "step": 369520
    },
    {
      "epoch": 596.0,
      "eval_accuracy": {
        "accuracy": 0.7764421200530793
      },
      "eval_loss": 0.9990087151527405,
      "eval_runtime": 2.9457,
      "eval_samples_per_second": 4349.015,
      "eval_steps_per_second": 68.234,
      "step": 369520
    },
    {
      "epoch": 596.03,
      "learning_rate": 0.04042054345048387,
      "loss": 0.6481,
      "step": 369540
    },
    {
      "epoch": 596.06,
      "learning_rate": 0.04041731764725807,
      "loss": 0.6545,
      "step": 369560
    },
    {
      "epoch": 596.1,
      "learning_rate": 0.04041409184403226,
      "loss": 0.6552,
      "step": 369580
    },
    {
      "epoch": 596.13,
      "learning_rate": 0.04041086604080645,
      "loss": 0.6484,
      "step": 369600
    },
    {
      "epoch": 596.16,
      "learning_rate": 0.04040764023758065,
      "loss": 0.6499,
      "step": 369620
    },
    {
      "epoch": 596.19,
      "learning_rate": 0.04040441443435484,
      "loss": 0.6589,
      "step": 369640
    },
    {
      "epoch": 596.23,
      "learning_rate": 0.040401188631129036,
      "loss": 0.6708,
      "step": 369660
    },
    {
      "epoch": 596.26,
      "learning_rate": 0.04039796282790323,
      "loss": 0.6604,
      "step": 369680
    },
    {
      "epoch": 596.29,
      "learning_rate": 0.04039473702467743,
      "loss": 0.6466,
      "step": 369700
    },
    {
      "epoch": 596.32,
      "learning_rate": 0.04039151122145162,
      "loss": 0.6501,
      "step": 369720
    },
    {
      "epoch": 596.35,
      "learning_rate": 0.04038828541822581,
      "loss": 0.6802,
      "step": 369740
    },
    {
      "epoch": 596.39,
      "learning_rate": 0.04038505961500001,
      "loss": 0.6614,
      "step": 369760
    },
    {
      "epoch": 596.42,
      "learning_rate": 0.0403818338117742,
      "loss": 0.6423,
      "step": 369780
    },
    {
      "epoch": 596.45,
      "learning_rate": 0.04037860800854839,
      "loss": 0.6671,
      "step": 369800
    },
    {
      "epoch": 596.48,
      "learning_rate": 0.04037538220532258,
      "loss": 0.651,
      "step": 369820
    },
    {
      "epoch": 596.52,
      "learning_rate": 0.04037215640209677,
      "loss": 0.663,
      "step": 369840
    },
    {
      "epoch": 596.55,
      "learning_rate": 0.04036893059887097,
      "loss": 0.6748,
      "step": 369860
    },
    {
      "epoch": 596.58,
      "learning_rate": 0.04036570479564516,
      "loss": 0.6566,
      "step": 369880
    },
    {
      "epoch": 596.61,
      "learning_rate": 0.040362478992419355,
      "loss": 0.672,
      "step": 369900
    },
    {
      "epoch": 596.65,
      "learning_rate": 0.040359253189193554,
      "loss": 0.6685,
      "step": 369920
    },
    {
      "epoch": 596.68,
      "learning_rate": 0.040356027385967747,
      "loss": 0.6604,
      "step": 369940
    },
    {
      "epoch": 596.71,
      "learning_rate": 0.04035280158274194,
      "loss": 0.6566,
      "step": 369960
    },
    {
      "epoch": 596.74,
      "learning_rate": 0.04034957577951613,
      "loss": 0.6655,
      "step": 369980
    },
    {
      "epoch": 596.77,
      "learning_rate": 0.04034634997629033,
      "loss": 0.6648,
      "step": 370000
    },
    {
      "epoch": 596.81,
      "learning_rate": 0.04034312417306452,
      "loss": 0.6629,
      "step": 370020
    },
    {
      "epoch": 596.84,
      "learning_rate": 0.040339898369838714,
      "loss": 0.6683,
      "step": 370040
    },
    {
      "epoch": 596.87,
      "learning_rate": 0.04033667256661291,
      "loss": 0.6715,
      "step": 370060
    },
    {
      "epoch": 596.9,
      "learning_rate": 0.040333446763387105,
      "loss": 0.6772,
      "step": 370080
    },
    {
      "epoch": 596.94,
      "learning_rate": 0.0403302209601613,
      "loss": 0.6591,
      "step": 370100
    },
    {
      "epoch": 596.97,
      "learning_rate": 0.04032699515693548,
      "loss": 0.6635,
      "step": 370120
    },
    {
      "epoch": 597.0,
      "learning_rate": 0.040323769353709675,
      "loss": 0.6652,
      "step": 370140
    },
    {
      "epoch": 597.0,
      "eval_accuracy": {
        "accuracy": 0.7652017797205527
      },
      "eval_loss": 1.020137906074524,
      "eval_runtime": 3.515,
      "eval_samples_per_second": 3644.659,
      "eval_steps_per_second": 57.183,
      "step": 370140
    },
    {
      "epoch": 597.03,
      "learning_rate": 0.040320543550483874,
      "loss": 0.663,
      "step": 370160
    },
    {
      "epoch": 597.06,
      "learning_rate": 0.040317317747258066,
      "loss": 0.6407,
      "step": 370180
    },
    {
      "epoch": 597.1,
      "learning_rate": 0.04031409194403226,
      "loss": 0.6341,
      "step": 370200
    },
    {
      "epoch": 597.13,
      "learning_rate": 0.04031086614080645,
      "loss": 0.6523,
      "step": 370220
    },
    {
      "epoch": 597.16,
      "learning_rate": 0.04030764033758065,
      "loss": 0.6633,
      "step": 370240
    },
    {
      "epoch": 597.19,
      "learning_rate": 0.04030441453435484,
      "loss": 0.6504,
      "step": 370260
    },
    {
      "epoch": 597.23,
      "learning_rate": 0.040301188731129034,
      "loss": 0.6573,
      "step": 370280
    },
    {
      "epoch": 597.26,
      "learning_rate": 0.04029796292790323,
      "loss": 0.6448,
      "step": 370300
    },
    {
      "epoch": 597.29,
      "learning_rate": 0.040294737124677425,
      "loss": 0.6566,
      "step": 370320
    },
    {
      "epoch": 597.32,
      "learning_rate": 0.04029151132145162,
      "loss": 0.6635,
      "step": 370340
    },
    {
      "epoch": 597.35,
      "learning_rate": 0.040288285518225816,
      "loss": 0.6608,
      "step": 370360
    },
    {
      "epoch": 597.39,
      "learning_rate": 0.04028505971500001,
      "loss": 0.6709,
      "step": 370380
    },
    {
      "epoch": 597.42,
      "learning_rate": 0.0402818339117742,
      "loss": 0.6465,
      "step": 370400
    },
    {
      "epoch": 597.45,
      "learning_rate": 0.040278608108548386,
      "loss": 0.6616,
      "step": 370420
    },
    {
      "epoch": 597.48,
      "learning_rate": 0.04027538230532258,
      "loss": 0.6744,
      "step": 370440
    },
    {
      "epoch": 597.52,
      "learning_rate": 0.04027215650209678,
      "loss": 0.6615,
      "step": 370460
    },
    {
      "epoch": 597.55,
      "learning_rate": 0.04026893069887097,
      "loss": 0.6711,
      "step": 370480
    },
    {
      "epoch": 597.58,
      "learning_rate": 0.04026570489564516,
      "loss": 0.6609,
      "step": 370500
    },
    {
      "epoch": 597.61,
      "learning_rate": 0.040262479092419354,
      "loss": 0.6741,
      "step": 370520
    },
    {
      "epoch": 597.65,
      "learning_rate": 0.04025925328919355,
      "loss": 0.6618,
      "step": 370540
    },
    {
      "epoch": 597.68,
      "learning_rate": 0.040256027485967745,
      "loss": 0.6636,
      "step": 370560
    },
    {
      "epoch": 597.71,
      "learning_rate": 0.04025280168274194,
      "loss": 0.6682,
      "step": 370580
    },
    {
      "epoch": 597.74,
      "learning_rate": 0.040249575879516136,
      "loss": 0.6466,
      "step": 370600
    },
    {
      "epoch": 597.77,
      "learning_rate": 0.04024635007629033,
      "loss": 0.6723,
      "step": 370620
    },
    {
      "epoch": 597.81,
      "learning_rate": 0.04024312427306452,
      "loss": 0.6545,
      "step": 370640
    },
    {
      "epoch": 597.84,
      "learning_rate": 0.04023989846983872,
      "loss": 0.6678,
      "step": 370660
    },
    {
      "epoch": 597.87,
      "learning_rate": 0.04023667266661291,
      "loss": 0.6757,
      "step": 370680
    },
    {
      "epoch": 597.9,
      "learning_rate": 0.040233446863387104,
      "loss": 0.6657,
      "step": 370700
    },
    {
      "epoch": 597.94,
      "learning_rate": 0.040230221060161296,
      "loss": 0.6679,
      "step": 370720
    },
    {
      "epoch": 597.97,
      "learning_rate": 0.04022699525693548,
      "loss": 0.6871,
      "step": 370740
    },
    {
      "epoch": 598.0,
      "learning_rate": 0.040223769453709673,
      "loss": 0.6865,
      "step": 370760
    },
    {
      "epoch": 598.0,
      "eval_accuracy": {
        "accuracy": 0.7627039263133245
      },
      "eval_loss": 1.052143931388855,
      "eval_runtime": 2.908,
      "eval_samples_per_second": 4405.492,
      "eval_steps_per_second": 69.121,
      "step": 370760
    },
    {
      "epoch": 598.03,
      "learning_rate": 0.04022054365048387,
      "loss": 0.6947,
      "step": 370780
    },
    {
      "epoch": 598.06,
      "learning_rate": 0.040217317847258065,
      "loss": 0.6756,
      "step": 370800
    },
    {
      "epoch": 598.1,
      "learning_rate": 0.04021409204403226,
      "loss": 0.6392,
      "step": 370820
    },
    {
      "epoch": 598.13,
      "learning_rate": 0.040210866240806456,
      "loss": 0.6596,
      "step": 370840
    },
    {
      "epoch": 598.16,
      "learning_rate": 0.04020764043758065,
      "loss": 0.6588,
      "step": 370860
    },
    {
      "epoch": 598.19,
      "learning_rate": 0.04020441463435484,
      "loss": 0.6637,
      "step": 370880
    },
    {
      "epoch": 598.23,
      "learning_rate": 0.04020118883112904,
      "loss": 0.6577,
      "step": 370900
    },
    {
      "epoch": 598.26,
      "learning_rate": 0.04019796302790323,
      "loss": 0.6444,
      "step": 370920
    },
    {
      "epoch": 598.29,
      "learning_rate": 0.040194737224677424,
      "loss": 0.6753,
      "step": 370940
    },
    {
      "epoch": 598.32,
      "learning_rate": 0.04019151142145162,
      "loss": 0.663,
      "step": 370960
    },
    {
      "epoch": 598.35,
      "learning_rate": 0.040188285618225815,
      "loss": 0.672,
      "step": 370980
    },
    {
      "epoch": 598.39,
      "learning_rate": 0.04018505981500001,
      "loss": 0.6563,
      "step": 371000
    },
    {
      "epoch": 598.42,
      "learning_rate": 0.0401818340117742,
      "loss": 0.6603,
      "step": 371020
    },
    {
      "epoch": 598.45,
      "learning_rate": 0.0401786082085484,
      "loss": 0.6637,
      "step": 371040
    },
    {
      "epoch": 598.48,
      "learning_rate": 0.04017538240532258,
      "loss": 0.6613,
      "step": 371060
    },
    {
      "epoch": 598.52,
      "learning_rate": 0.040172156602096776,
      "loss": 0.6684,
      "step": 371080
    },
    {
      "epoch": 598.55,
      "learning_rate": 0.04016893079887097,
      "loss": 0.6644,
      "step": 371100
    },
    {
      "epoch": 598.58,
      "learning_rate": 0.04016570499564516,
      "loss": 0.6478,
      "step": 371120
    },
    {
      "epoch": 598.61,
      "learning_rate": 0.04016247919241936,
      "loss": 0.6651,
      "step": 371140
    },
    {
      "epoch": 598.65,
      "learning_rate": 0.04015925338919355,
      "loss": 0.6508,
      "step": 371160
    },
    {
      "epoch": 598.68,
      "learning_rate": 0.04015602758596774,
      "loss": 0.6566,
      "step": 371180
    },
    {
      "epoch": 598.71,
      "learning_rate": 0.04015280178274194,
      "loss": 0.6657,
      "step": 371200
    },
    {
      "epoch": 598.74,
      "learning_rate": 0.040149575979516135,
      "loss": 0.6532,
      "step": 371220
    },
    {
      "epoch": 598.77,
      "learning_rate": 0.04014635017629033,
      "loss": 0.6603,
      "step": 371240
    },
    {
      "epoch": 598.81,
      "learning_rate": 0.04014312437306452,
      "loss": 0.6596,
      "step": 371260
    },
    {
      "epoch": 598.84,
      "learning_rate": 0.04013989856983872,
      "loss": 0.661,
      "step": 371280
    },
    {
      "epoch": 598.87,
      "learning_rate": 0.04013667276661291,
      "loss": 0.6687,
      "step": 371300
    },
    {
      "epoch": 598.9,
      "learning_rate": 0.0401334469633871,
      "loss": 0.6733,
      "step": 371320
    },
    {
      "epoch": 598.94,
      "learning_rate": 0.0401302211601613,
      "loss": 0.6675,
      "step": 371340
    },
    {
      "epoch": 598.97,
      "learning_rate": 0.04012699535693548,
      "loss": 0.6619,
      "step": 371360
    },
    {
      "epoch": 599.0,
      "learning_rate": 0.04012376955370968,
      "loss": 0.6571,
      "step": 371380
    },
    {
      "epoch": 599.0,
      "eval_accuracy": {
        "accuracy": 0.7678557489657326
      },
      "eval_loss": 1.0312068462371826,
      "eval_runtime": 2.8939,
      "eval_samples_per_second": 4426.889,
      "eval_steps_per_second": 69.456,
      "step": 371380
    },
    {
      "epoch": 599.03,
      "learning_rate": 0.04012054375048387,
      "loss": 0.6881,
      "step": 371400
    },
    {
      "epoch": 599.06,
      "learning_rate": 0.04011731794725806,
      "loss": 0.657,
      "step": 371420
    },
    {
      "epoch": 599.1,
      "learning_rate": 0.04011409214403226,
      "loss": 0.6513,
      "step": 371440
    },
    {
      "epoch": 599.13,
      "learning_rate": 0.040110866340806454,
      "loss": 0.6515,
      "step": 371460
    },
    {
      "epoch": 599.16,
      "learning_rate": 0.04010764053758065,
      "loss": 0.6458,
      "step": 371480
    },
    {
      "epoch": 599.19,
      "learning_rate": 0.040104414734354846,
      "loss": 0.6487,
      "step": 371500
    },
    {
      "epoch": 599.23,
      "learning_rate": 0.04010118893112904,
      "loss": 0.6473,
      "step": 371520
    },
    {
      "epoch": 599.26,
      "learning_rate": 0.04009796312790323,
      "loss": 0.6537,
      "step": 371540
    },
    {
      "epoch": 599.29,
      "learning_rate": 0.04009473732467742,
      "loss": 0.655,
      "step": 371560
    },
    {
      "epoch": 599.32,
      "learning_rate": 0.04009151152145162,
      "loss": 0.6686,
      "step": 371580
    },
    {
      "epoch": 599.35,
      "learning_rate": 0.04008828571822581,
      "loss": 0.6467,
      "step": 371600
    },
    {
      "epoch": 599.39,
      "learning_rate": 0.040085059915000006,
      "loss": 0.6598,
      "step": 371620
    },
    {
      "epoch": 599.42,
      "learning_rate": 0.040081834111774205,
      "loss": 0.6502,
      "step": 371640
    },
    {
      "epoch": 599.45,
      "learning_rate": 0.0400786083085484,
      "loss": 0.6655,
      "step": 371660
    },
    {
      "epoch": 599.48,
      "learning_rate": 0.04007538250532258,
      "loss": 0.6728,
      "step": 371680
    },
    {
      "epoch": 599.52,
      "learning_rate": 0.040072156702096774,
      "loss": 0.6653,
      "step": 371700
    },
    {
      "epoch": 599.55,
      "learning_rate": 0.040068930898870966,
      "loss": 0.6569,
      "step": 371720
    },
    {
      "epoch": 599.58,
      "learning_rate": 0.040065705095645165,
      "loss": 0.6584,
      "step": 371740
    },
    {
      "epoch": 599.61,
      "learning_rate": 0.04006247929241936,
      "loss": 0.6687,
      "step": 371760
    },
    {
      "epoch": 599.65,
      "learning_rate": 0.04005925348919355,
      "loss": 0.6505,
      "step": 371780
    },
    {
      "epoch": 599.68,
      "learning_rate": 0.04005602768596774,
      "loss": 0.6586,
      "step": 371800
    },
    {
      "epoch": 599.71,
      "learning_rate": 0.04005280188274194,
      "loss": 0.6622,
      "step": 371820
    },
    {
      "epoch": 599.74,
      "learning_rate": 0.04004957607951613,
      "loss": 0.6518,
      "step": 371840
    },
    {
      "epoch": 599.77,
      "learning_rate": 0.040046350276290325,
      "loss": 0.658,
      "step": 371860
    },
    {
      "epoch": 599.81,
      "learning_rate": 0.040043124473064524,
      "loss": 0.6738,
      "step": 371880
    },
    {
      "epoch": 599.84,
      "learning_rate": 0.04003989866983872,
      "loss": 0.6727,
      "step": 371900
    },
    {
      "epoch": 599.87,
      "learning_rate": 0.04003667286661291,
      "loss": 0.6632,
      "step": 371920
    },
    {
      "epoch": 599.9,
      "learning_rate": 0.04003344706338711,
      "loss": 0.6729,
      "step": 371940
    },
    {
      "epoch": 599.94,
      "learning_rate": 0.0400302212601613,
      "loss": 0.6587,
      "step": 371960
    },
    {
      "epoch": 599.97,
      "learning_rate": 0.040026995456935485,
      "loss": 0.6553,
      "step": 371980
    },
    {
      "epoch": 600.0,
      "learning_rate": 0.04002376965370968,
      "loss": 0.6525,
      "step": 372000
    },
    {
      "epoch": 600.0,
      "eval_accuracy": {
        "accuracy": 0.769494965264226
      },
      "eval_loss": 1.0221145153045654,
      "eval_runtime": 3.8139,
      "eval_samples_per_second": 3359.013,
      "eval_steps_per_second": 52.702,
      "step": 372000
    },
    {
      "epoch": 600.03,
      "learning_rate": 0.04002054385048387,
      "loss": 0.6778,
      "step": 372020
    },
    {
      "epoch": 600.06,
      "learning_rate": 0.04001731804725807,
      "loss": 0.6704,
      "step": 372040
    },
    {
      "epoch": 600.1,
      "learning_rate": 0.04001409224403226,
      "loss": 0.6469,
      "step": 372060
    },
    {
      "epoch": 600.13,
      "learning_rate": 0.04001086644080645,
      "loss": 0.663,
      "step": 372080
    },
    {
      "epoch": 600.16,
      "learning_rate": 0.040007640637580645,
      "loss": 0.6602,
      "step": 372100
    },
    {
      "epoch": 600.19,
      "learning_rate": 0.040004414834354844,
      "loss": 0.6598,
      "step": 372120
    },
    {
      "epoch": 600.23,
      "learning_rate": 0.040001189031129036,
      "loss": 0.6683,
      "step": 372140
    },
    {
      "epoch": 600.26,
      "learning_rate": 0.03999796322790323,
      "loss": 0.6637,
      "step": 372160
    },
    {
      "epoch": 600.29,
      "learning_rate": 0.03999473742467743,
      "loss": 0.6459,
      "step": 372180
    },
    {
      "epoch": 600.32,
      "learning_rate": 0.03999151162145162,
      "loss": 0.6561,
      "step": 372200
    },
    {
      "epoch": 600.35,
      "learning_rate": 0.03998828581822581,
      "loss": 0.6589,
      "step": 372220
    },
    {
      "epoch": 600.39,
      "learning_rate": 0.03998506001500001,
      "loss": 0.648,
      "step": 372240
    },
    {
      "epoch": 600.42,
      "learning_rate": 0.0399818342117742,
      "loss": 0.6593,
      "step": 372260
    },
    {
      "epoch": 600.45,
      "learning_rate": 0.039978608408548395,
      "loss": 0.6501,
      "step": 372280
    },
    {
      "epoch": 600.48,
      "learning_rate": 0.03997538260532258,
      "loss": 0.6537,
      "step": 372300
    },
    {
      "epoch": 600.52,
      "learning_rate": 0.03997215680209677,
      "loss": 0.6517,
      "step": 372320
    },
    {
      "epoch": 600.55,
      "learning_rate": 0.039968930998870965,
      "loss": 0.6577,
      "step": 372340
    },
    {
      "epoch": 600.58,
      "learning_rate": 0.039965705195645164,
      "loss": 0.6619,
      "step": 372360
    },
    {
      "epoch": 600.61,
      "learning_rate": 0.039962479392419356,
      "loss": 0.6598,
      "step": 372380
    },
    {
      "epoch": 600.65,
      "learning_rate": 0.03995925358919355,
      "loss": 0.6538,
      "step": 372400
    },
    {
      "epoch": 600.68,
      "learning_rate": 0.03995602778596775,
      "loss": 0.6678,
      "step": 372420
    },
    {
      "epoch": 600.71,
      "learning_rate": 0.03995280198274194,
      "loss": 0.6791,
      "step": 372440
    },
    {
      "epoch": 600.74,
      "learning_rate": 0.03994957617951613,
      "loss": 0.66,
      "step": 372460
    },
    {
      "epoch": 600.77,
      "learning_rate": 0.03994635037629033,
      "loss": 0.6678,
      "step": 372480
    },
    {
      "epoch": 600.81,
      "learning_rate": 0.03994312457306452,
      "loss": 0.6692,
      "step": 372500
    },
    {
      "epoch": 600.84,
      "learning_rate": 0.039939898769838715,
      "loss": 0.6768,
      "step": 372520
    },
    {
      "epoch": 600.87,
      "learning_rate": 0.03993667296661291,
      "loss": 0.6772,
      "step": 372540
    },
    {
      "epoch": 600.9,
      "learning_rate": 0.039933447163387106,
      "loss": 0.6759,
      "step": 372560
    },
    {
      "epoch": 600.94,
      "learning_rate": 0.0399302213601613,
      "loss": 0.666,
      "step": 372580
    },
    {
      "epoch": 600.97,
      "learning_rate": 0.039926995556935484,
      "loss": 0.6729,
      "step": 372600
    },
    {
      "epoch": 601.0,
      "learning_rate": 0.03992393104387097,
      "loss": 0.6548,
      "step": 372620
    },
    {
      "epoch": 601.0,
      "eval_accuracy": {
        "accuracy": 0.7742564983217547
      },
      "eval_loss": 0.9985499978065491,
      "eval_runtime": 2.9529,
      "eval_samples_per_second": 4338.395,
      "eval_steps_per_second": 68.068,
      "step": 372620
    },
    {
      "epoch": 601.03,
      "learning_rate": 0.039920705240645164,
      "loss": 0.6531,
      "step": 372640
    },
    {
      "epoch": 601.06,
      "learning_rate": 0.03991747943741936,
      "loss": 0.6405,
      "step": 372660
    },
    {
      "epoch": 601.1,
      "learning_rate": 0.039914253634193556,
      "loss": 0.6414,
      "step": 372680
    },
    {
      "epoch": 601.13,
      "learning_rate": 0.03991102783096775,
      "loss": 0.6352,
      "step": 372700
    },
    {
      "epoch": 601.16,
      "learning_rate": 0.03990780202774195,
      "loss": 0.6468,
      "step": 372720
    },
    {
      "epoch": 601.19,
      "learning_rate": 0.039904576224516125,
      "loss": 0.6408,
      "step": 372740
    },
    {
      "epoch": 601.23,
      "learning_rate": 0.039901350421290324,
      "loss": 0.6513,
      "step": 372760
    },
    {
      "epoch": 601.26,
      "learning_rate": 0.039898124618064516,
      "loss": 0.6566,
      "step": 372780
    },
    {
      "epoch": 601.29,
      "learning_rate": 0.03989489881483871,
      "loss": 0.6602,
      "step": 372800
    },
    {
      "epoch": 601.32,
      "learning_rate": 0.03989167301161291,
      "loss": 0.6622,
      "step": 372820
    },
    {
      "epoch": 601.35,
      "learning_rate": 0.0398884472083871,
      "loss": 0.6466,
      "step": 372840
    },
    {
      "epoch": 601.39,
      "learning_rate": 0.03988522140516129,
      "loss": 0.6622,
      "step": 372860
    },
    {
      "epoch": 601.42,
      "learning_rate": 0.039881995601935484,
      "loss": 0.6491,
      "step": 372880
    },
    {
      "epoch": 601.45,
      "learning_rate": 0.03987876979870968,
      "loss": 0.653,
      "step": 372900
    },
    {
      "epoch": 601.48,
      "learning_rate": 0.039875543995483875,
      "loss": 0.6535,
      "step": 372920
    },
    {
      "epoch": 601.52,
      "learning_rate": 0.03987231819225807,
      "loss": 0.6589,
      "step": 372940
    },
    {
      "epoch": 601.55,
      "learning_rate": 0.03986909238903227,
      "loss": 0.65,
      "step": 372960
    },
    {
      "epoch": 601.58,
      "learning_rate": 0.03986586658580646,
      "loss": 0.6621,
      "step": 372980
    },
    {
      "epoch": 601.61,
      "learning_rate": 0.03986264078258065,
      "loss": 0.6847,
      "step": 373000
    },
    {
      "epoch": 601.65,
      "learning_rate": 0.03985941497935485,
      "loss": 0.6767,
      "step": 373020
    },
    {
      "epoch": 601.68,
      "learning_rate": 0.03985618917612904,
      "loss": 0.6708,
      "step": 373040
    },
    {
      "epoch": 601.71,
      "learning_rate": 0.03985296337290323,
      "loss": 0.685,
      "step": 373060
    },
    {
      "epoch": 601.74,
      "learning_rate": 0.03984973756967742,
      "loss": 0.6863,
      "step": 373080
    },
    {
      "epoch": 601.77,
      "learning_rate": 0.03984651176645161,
      "loss": 0.6692,
      "step": 373100
    },
    {
      "epoch": 601.81,
      "learning_rate": 0.03984328596322581,
      "loss": 0.6712,
      "step": 373120
    },
    {
      "epoch": 601.84,
      "learning_rate": 0.03984006016,
      "loss": 0.678,
      "step": 373140
    },
    {
      "epoch": 601.87,
      "learning_rate": 0.039836834356774195,
      "loss": 0.6448,
      "step": 373160
    },
    {
      "epoch": 601.9,
      "learning_rate": 0.03983360855354839,
      "loss": 0.6555,
      "step": 373180
    },
    {
      "epoch": 601.94,
      "learning_rate": 0.039830382750322586,
      "loss": 0.6571,
      "step": 373200
    },
    {
      "epoch": 601.97,
      "learning_rate": 0.03982715694709678,
      "loss": 0.6663,
      "step": 373220
    },
    {
      "epoch": 602.0,
      "learning_rate": 0.03982393114387097,
      "loss": 0.666,
      "step": 373240
    },
    {
      "epoch": 602.0,
      "eval_accuracy": {
        "accuracy": 0.7698852548591054
      },
      "eval_loss": 1.0007539987564087,
      "eval_runtime": 3.093,
      "eval_samples_per_second": 4141.961,
      "eval_steps_per_second": 64.986,
      "step": 373240
    },
    {
      "epoch": 602.03,
      "learning_rate": 0.03982070534064517,
      "loss": 0.648,
      "step": 373260
    },
    {
      "epoch": 602.06,
      "learning_rate": 0.03981747953741936,
      "loss": 0.6552,
      "step": 373280
    },
    {
      "epoch": 602.1,
      "learning_rate": 0.039814253734193554,
      "loss": 0.6391,
      "step": 373300
    },
    {
      "epoch": 602.13,
      "learning_rate": 0.03981102793096775,
      "loss": 0.6528,
      "step": 373320
    },
    {
      "epoch": 602.16,
      "learning_rate": 0.039807802127741945,
      "loss": 0.639,
      "step": 373340
    },
    {
      "epoch": 602.19,
      "learning_rate": 0.03980457632451614,
      "loss": 0.6501,
      "step": 373360
    },
    {
      "epoch": 602.23,
      "learning_rate": 0.03980135052129032,
      "loss": 0.6706,
      "step": 373380
    },
    {
      "epoch": 602.26,
      "learning_rate": 0.039798124718064515,
      "loss": 0.6646,
      "step": 373400
    },
    {
      "epoch": 602.29,
      "learning_rate": 0.03979489891483871,
      "loss": 0.6655,
      "step": 373420
    },
    {
      "epoch": 602.32,
      "learning_rate": 0.039791673111612906,
      "loss": 0.6624,
      "step": 373440
    },
    {
      "epoch": 602.35,
      "learning_rate": 0.0397884473083871,
      "loss": 0.6542,
      "step": 373460
    },
    {
      "epoch": 602.39,
      "learning_rate": 0.03978522150516129,
      "loss": 0.6466,
      "step": 373480
    },
    {
      "epoch": 602.42,
      "learning_rate": 0.03978199570193549,
      "loss": 0.6467,
      "step": 373500
    },
    {
      "epoch": 602.45,
      "learning_rate": 0.03977876989870968,
      "loss": 0.6457,
      "step": 373520
    },
    {
      "epoch": 602.48,
      "learning_rate": 0.039775544095483874,
      "loss": 0.6566,
      "step": 373540
    },
    {
      "epoch": 602.52,
      "learning_rate": 0.03977231829225807,
      "loss": 0.6624,
      "step": 373560
    },
    {
      "epoch": 602.55,
      "learning_rate": 0.039769092489032265,
      "loss": 0.6556,
      "step": 373580
    },
    {
      "epoch": 602.58,
      "learning_rate": 0.03976586668580646,
      "loss": 0.6839,
      "step": 373600
    },
    {
      "epoch": 602.61,
      "learning_rate": 0.03976264088258065,
      "loss": 0.6688,
      "step": 373620
    },
    {
      "epoch": 602.65,
      "learning_rate": 0.03975941507935485,
      "loss": 0.6687,
      "step": 373640
    },
    {
      "epoch": 602.68,
      "learning_rate": 0.03975618927612904,
      "loss": 0.6482,
      "step": 373660
    },
    {
      "epoch": 602.71,
      "learning_rate": 0.039752963472903226,
      "loss": 0.6861,
      "step": 373680
    },
    {
      "epoch": 602.74,
      "learning_rate": 0.03974973766967742,
      "loss": 0.6653,
      "step": 373700
    },
    {
      "epoch": 602.77,
      "learning_rate": 0.03974651186645161,
      "loss": 0.6631,
      "step": 373720
    },
    {
      "epoch": 602.81,
      "learning_rate": 0.03974328606322581,
      "loss": 0.6442,
      "step": 373740
    },
    {
      "epoch": 602.84,
      "learning_rate": 0.03974006026,
      "loss": 0.659,
      "step": 373760
    },
    {
      "epoch": 602.87,
      "learning_rate": 0.039736834456774194,
      "loss": 0.6598,
      "step": 373780
    },
    {
      "epoch": 602.9,
      "learning_rate": 0.03973360865354839,
      "loss": 0.6621,
      "step": 373800
    },
    {
      "epoch": 602.94,
      "learning_rate": 0.039730382850322585,
      "loss": 0.6585,
      "step": 373820
    },
    {
      "epoch": 602.97,
      "learning_rate": 0.03972715704709678,
      "loss": 0.6664,
      "step": 373840
    },
    {
      "epoch": 603.0,
      "learning_rate": 0.039723931243870976,
      "loss": 0.6806,
      "step": 373860
    },
    {
      "epoch": 603.0,
      "eval_accuracy": {
        "accuracy": 0.7658262430723597
      },
      "eval_loss": 1.0250409841537476,
      "eval_runtime": 3.9912,
      "eval_samples_per_second": 3209.849,
      "eval_steps_per_second": 50.361,
      "step": 373860
    },
    {
      "epoch": 603.03,
      "learning_rate": 0.03972070544064517,
      "loss": 0.6607,
      "step": 373880
    },
    {
      "epoch": 603.06,
      "learning_rate": 0.03971747963741936,
      "loss": 0.6516,
      "step": 373900
    },
    {
      "epoch": 603.1,
      "learning_rate": 0.03971425383419355,
      "loss": 0.6487,
      "step": 373920
    },
    {
      "epoch": 603.13,
      "learning_rate": 0.03971102803096775,
      "loss": 0.6602,
      "step": 373940
    },
    {
      "epoch": 603.16,
      "learning_rate": 0.039707802227741944,
      "loss": 0.655,
      "step": 373960
    },
    {
      "epoch": 603.19,
      "learning_rate": 0.039704576424516136,
      "loss": 0.655,
      "step": 373980
    },
    {
      "epoch": 603.23,
      "learning_rate": 0.03970135062129032,
      "loss": 0.6512,
      "step": 374000
    },
    {
      "epoch": 603.26,
      "learning_rate": 0.03969812481806451,
      "loss": 0.6499,
      "step": 374020
    },
    {
      "epoch": 603.29,
      "learning_rate": 0.03969489901483871,
      "loss": 0.6729,
      "step": 374040
    },
    {
      "epoch": 603.32,
      "learning_rate": 0.039691673211612905,
      "loss": 0.6542,
      "step": 374060
    },
    {
      "epoch": 603.35,
      "learning_rate": 0.0396884474083871,
      "loss": 0.655,
      "step": 374080
    },
    {
      "epoch": 603.39,
      "learning_rate": 0.039685221605161296,
      "loss": 0.653,
      "step": 374100
    },
    {
      "epoch": 603.42,
      "learning_rate": 0.03968199580193549,
      "loss": 0.6439,
      "step": 374120
    },
    {
      "epoch": 603.45,
      "learning_rate": 0.03967876999870968,
      "loss": 0.653,
      "step": 374140
    },
    {
      "epoch": 603.48,
      "learning_rate": 0.03967554419548387,
      "loss": 0.6544,
      "step": 374160
    },
    {
      "epoch": 603.52,
      "learning_rate": 0.03967231839225807,
      "loss": 0.6676,
      "step": 374180
    },
    {
      "epoch": 603.55,
      "learning_rate": 0.039669092589032263,
      "loss": 0.6806,
      "step": 374200
    },
    {
      "epoch": 603.58,
      "learning_rate": 0.039665866785806456,
      "loss": 0.6664,
      "step": 374220
    },
    {
      "epoch": 603.61,
      "learning_rate": 0.039662640982580655,
      "loss": 0.6404,
      "step": 374240
    },
    {
      "epoch": 603.65,
      "learning_rate": 0.03965941517935485,
      "loss": 0.6448,
      "step": 374260
    },
    {
      "epoch": 603.68,
      "learning_rate": 0.03965618937612904,
      "loss": 0.6528,
      "step": 374280
    },
    {
      "epoch": 603.71,
      "learning_rate": 0.039652963572903224,
      "loss": 0.6635,
      "step": 374300
    },
    {
      "epoch": 603.74,
      "learning_rate": 0.039649737769677416,
      "loss": 0.6593,
      "step": 374320
    },
    {
      "epoch": 603.77,
      "learning_rate": 0.039646511966451616,
      "loss": 0.6743,
      "step": 374340
    },
    {
      "epoch": 603.81,
      "learning_rate": 0.03964328616322581,
      "loss": 0.6791,
      "step": 374360
    },
    {
      "epoch": 603.84,
      "learning_rate": 0.03964006036,
      "loss": 0.6676,
      "step": 374380
    },
    {
      "epoch": 603.87,
      "learning_rate": 0.0396368345567742,
      "loss": 0.6499,
      "step": 374400
    },
    {
      "epoch": 603.9,
      "learning_rate": 0.03963360875354839,
      "loss": 0.6698,
      "step": 374420
    },
    {
      "epoch": 603.94,
      "learning_rate": 0.03963038295032258,
      "loss": 0.6635,
      "step": 374440
    },
    {
      "epoch": 603.97,
      "learning_rate": 0.039627157147096775,
      "loss": 0.6787,
      "step": 374460
    },
    {
      "epoch": 604.0,
      "learning_rate": 0.039623931343870974,
      "loss": 0.6604,
      "step": 374480
    },
    {
      "epoch": 604.0,
      "eval_accuracy": {
        "accuracy": 0.768870501912419
      },
      "eval_loss": 1.0267871618270874,
      "eval_runtime": 3.1618,
      "eval_samples_per_second": 4051.786,
      "eval_steps_per_second": 63.571,
      "step": 374480
    },
    {
      "epoch": 604.03,
      "learning_rate": 0.03962070554064517,
      "loss": 0.6698,
      "step": 374500
    },
    {
      "epoch": 604.06,
      "learning_rate": 0.03961747973741936,
      "loss": 0.6425,
      "step": 374520
    },
    {
      "epoch": 604.1,
      "learning_rate": 0.03961425393419356,
      "loss": 0.6711,
      "step": 374540
    },
    {
      "epoch": 604.13,
      "learning_rate": 0.03961102813096775,
      "loss": 0.6579,
      "step": 374560
    },
    {
      "epoch": 604.16,
      "learning_rate": 0.03960780232774194,
      "loss": 0.664,
      "step": 374580
    },
    {
      "epoch": 604.19,
      "learning_rate": 0.03960457652451614,
      "loss": 0.635,
      "step": 374600
    },
    {
      "epoch": 604.23,
      "learning_rate": 0.03960135072129032,
      "loss": 0.6509,
      "step": 374620
    },
    {
      "epoch": 604.26,
      "learning_rate": 0.03959812491806452,
      "loss": 0.6515,
      "step": 374640
    },
    {
      "epoch": 604.29,
      "learning_rate": 0.03959489911483871,
      "loss": 0.6567,
      "step": 374660
    },
    {
      "epoch": 604.32,
      "learning_rate": 0.0395916733116129,
      "loss": 0.6589,
      "step": 374680
    },
    {
      "epoch": 604.35,
      "learning_rate": 0.039588447508387095,
      "loss": 0.6682,
      "step": 374700
    },
    {
      "epoch": 604.39,
      "learning_rate": 0.039585221705161294,
      "loss": 0.6556,
      "step": 374720
    },
    {
      "epoch": 604.42,
      "learning_rate": 0.039581995901935486,
      "loss": 0.6337,
      "step": 374740
    },
    {
      "epoch": 604.45,
      "learning_rate": 0.03957877009870968,
      "loss": 0.6559,
      "step": 374760
    },
    {
      "epoch": 604.48,
      "learning_rate": 0.03957554429548388,
      "loss": 0.652,
      "step": 374780
    },
    {
      "epoch": 604.52,
      "learning_rate": 0.03957231849225807,
      "loss": 0.6526,
      "step": 374800
    },
    {
      "epoch": 604.55,
      "learning_rate": 0.03956909268903226,
      "loss": 0.6518,
      "step": 374820
    },
    {
      "epoch": 604.58,
      "learning_rate": 0.03956586688580646,
      "loss": 0.66,
      "step": 374840
    },
    {
      "epoch": 604.61,
      "learning_rate": 0.03956264108258065,
      "loss": 0.6654,
      "step": 374860
    },
    {
      "epoch": 604.65,
      "learning_rate": 0.039559415279354845,
      "loss": 0.6668,
      "step": 374880
    },
    {
      "epoch": 604.68,
      "learning_rate": 0.039556189476129044,
      "loss": 0.6658,
      "step": 374900
    },
    {
      "epoch": 604.71,
      "learning_rate": 0.03955296367290322,
      "loss": 0.6544,
      "step": 374920
    },
    {
      "epoch": 604.74,
      "learning_rate": 0.03954973786967742,
      "loss": 0.6584,
      "step": 374940
    },
    {
      "epoch": 604.77,
      "learning_rate": 0.039546512066451614,
      "loss": 0.6612,
      "step": 374960
    },
    {
      "epoch": 604.81,
      "learning_rate": 0.039543286263225806,
      "loss": 0.6455,
      "step": 374980
    },
    {
      "epoch": 604.84,
      "learning_rate": 0.03954006046,
      "loss": 0.6729,
      "step": 375000
    },
    {
      "epoch": 604.87,
      "learning_rate": 0.0395368346567742,
      "loss": 0.6695,
      "step": 375020
    },
    {
      "epoch": 604.9,
      "learning_rate": 0.03953360885354839,
      "loss": 0.6635,
      "step": 375040
    },
    {
      "epoch": 604.94,
      "learning_rate": 0.03953038305032258,
      "loss": 0.6753,
      "step": 375060
    },
    {
      "epoch": 604.97,
      "learning_rate": 0.03952715724709678,
      "loss": 0.6613,
      "step": 375080
    },
    {
      "epoch": 605.0,
      "learning_rate": 0.039524092734032255,
      "loss": 0.6578,
      "step": 375100
    },
    {
      "epoch": 605.0,
      "eval_accuracy": {
        "accuracy": 0.7704316602919367
      },
      "eval_loss": 1.012219786643982,
      "eval_runtime": 2.9701,
      "eval_samples_per_second": 4313.315,
      "eval_steps_per_second": 67.674,
      "step": 375100
    },
    {
      "epoch": 605.03,
      "learning_rate": 0.039520866930806454,
      "loss": 0.6415,
      "step": 375120
    },
    {
      "epoch": 605.06,
      "learning_rate": 0.03951764112758065,
      "loss": 0.6416,
      "step": 375140
    },
    {
      "epoch": 605.1,
      "learning_rate": 0.03951441532435484,
      "loss": 0.6411,
      "step": 375160
    },
    {
      "epoch": 605.13,
      "learning_rate": 0.03951118952112904,
      "loss": 0.6496,
      "step": 375180
    },
    {
      "epoch": 605.16,
      "learning_rate": 0.03950796371790323,
      "loss": 0.6586,
      "step": 375200
    },
    {
      "epoch": 605.19,
      "learning_rate": 0.03950473791467742,
      "loss": 0.6355,
      "step": 375220
    },
    {
      "epoch": 605.23,
      "learning_rate": 0.039501512111451614,
      "loss": 0.6507,
      "step": 375240
    },
    {
      "epoch": 605.26,
      "learning_rate": 0.03949828630822581,
      "loss": 0.6441,
      "step": 375260
    },
    {
      "epoch": 605.29,
      "learning_rate": 0.039495060505000006,
      "loss": 0.66,
      "step": 375280
    },
    {
      "epoch": 605.32,
      "learning_rate": 0.0394918347017742,
      "loss": 0.6443,
      "step": 375300
    },
    {
      "epoch": 605.35,
      "learning_rate": 0.0394886088985484,
      "loss": 0.6545,
      "step": 375320
    },
    {
      "epoch": 605.39,
      "learning_rate": 0.03948538309532259,
      "loss": 0.6568,
      "step": 375340
    },
    {
      "epoch": 605.42,
      "learning_rate": 0.03948215729209678,
      "loss": 0.6691,
      "step": 375360
    },
    {
      "epoch": 605.45,
      "learning_rate": 0.039478931488870966,
      "loss": 0.6493,
      "step": 375380
    },
    {
      "epoch": 605.48,
      "learning_rate": 0.03947570568564516,
      "loss": 0.6476,
      "step": 375400
    },
    {
      "epoch": 605.52,
      "learning_rate": 0.03947247988241936,
      "loss": 0.6533,
      "step": 375420
    },
    {
      "epoch": 605.55,
      "learning_rate": 0.03946925407919355,
      "loss": 0.6659,
      "step": 375440
    },
    {
      "epoch": 605.58,
      "learning_rate": 0.03946602827596774,
      "loss": 0.6638,
      "step": 375460
    },
    {
      "epoch": 605.61,
      "learning_rate": 0.03946280247274194,
      "loss": 0.6557,
      "step": 375480
    },
    {
      "epoch": 605.65,
      "learning_rate": 0.03945957666951613,
      "loss": 0.656,
      "step": 375500
    },
    {
      "epoch": 605.68,
      "learning_rate": 0.039456350866290325,
      "loss": 0.6667,
      "step": 375520
    },
    {
      "epoch": 605.71,
      "learning_rate": 0.03945312506306452,
      "loss": 0.6583,
      "step": 375540
    },
    {
      "epoch": 605.74,
      "learning_rate": 0.03944989925983872,
      "loss": 0.6705,
      "step": 375560
    },
    {
      "epoch": 605.77,
      "learning_rate": 0.03944667345661291,
      "loss": 0.6577,
      "step": 375580
    },
    {
      "epoch": 605.81,
      "learning_rate": 0.0394434476533871,
      "loss": 0.6791,
      "step": 375600
    },
    {
      "epoch": 605.84,
      "learning_rate": 0.0394402218501613,
      "loss": 0.669,
      "step": 375620
    },
    {
      "epoch": 605.87,
      "learning_rate": 0.03943699604693549,
      "loss": 0.6766,
      "step": 375640
    },
    {
      "epoch": 605.9,
      "learning_rate": 0.039433770243709684,
      "loss": 0.6674,
      "step": 375660
    },
    {
      "epoch": 605.94,
      "learning_rate": 0.03943054444048388,
      "loss": 0.6584,
      "step": 375680
    },
    {
      "epoch": 605.97,
      "learning_rate": 0.03942731863725806,
      "loss": 0.6848,
      "step": 375700
    },
    {
      "epoch": 606.0,
      "learning_rate": 0.03942409283403226,
      "loss": 0.6648,
      "step": 375720
    },
    {
      "epoch": 606.0,
      "eval_accuracy": {
        "accuracy": 0.7666848801810944
      },
      "eval_loss": 1.0227712392807007,
      "eval_runtime": 2.8985,
      "eval_samples_per_second": 4419.938,
      "eval_steps_per_second": 69.347,
      "step": 375720
    },
    {
      "epoch": 606.03,
      "learning_rate": 0.03942086703080645,
      "loss": 0.6729,
      "step": 375740
    },
    {
      "epoch": 606.06,
      "learning_rate": 0.039417641227580645,
      "loss": 0.6324,
      "step": 375760
    },
    {
      "epoch": 606.1,
      "learning_rate": 0.03941441542435484,
      "loss": 0.6471,
      "step": 375780
    },
    {
      "epoch": 606.13,
      "learning_rate": 0.039411189621129036,
      "loss": 0.6665,
      "step": 375800
    },
    {
      "epoch": 606.16,
      "learning_rate": 0.03940796381790323,
      "loss": 0.6394,
      "step": 375820
    },
    {
      "epoch": 606.19,
      "learning_rate": 0.03940473801467742,
      "loss": 0.6381,
      "step": 375840
    },
    {
      "epoch": 606.23,
      "learning_rate": 0.03940151221145162,
      "loss": 0.6402,
      "step": 375860
    },
    {
      "epoch": 606.26,
      "learning_rate": 0.03939828640822581,
      "loss": 0.636,
      "step": 375880
    },
    {
      "epoch": 606.29,
      "learning_rate": 0.039395060605000004,
      "loss": 0.6461,
      "step": 375900
    },
    {
      "epoch": 606.32,
      "learning_rate": 0.0393918348017742,
      "loss": 0.6438,
      "step": 375920
    },
    {
      "epoch": 606.35,
      "learning_rate": 0.039388608998548395,
      "loss": 0.654,
      "step": 375940
    },
    {
      "epoch": 606.39,
      "learning_rate": 0.03938538319532259,
      "loss": 0.6453,
      "step": 375960
    },
    {
      "epoch": 606.42,
      "learning_rate": 0.03938215739209679,
      "loss": 0.6654,
      "step": 375980
    },
    {
      "epoch": 606.45,
      "learning_rate": 0.039378931588870965,
      "loss": 0.6784,
      "step": 376000
    },
    {
      "epoch": 606.48,
      "learning_rate": 0.039375705785645164,
      "loss": 0.6508,
      "step": 376020
    },
    {
      "epoch": 606.52,
      "learning_rate": 0.039372479982419356,
      "loss": 0.6581,
      "step": 376040
    },
    {
      "epoch": 606.55,
      "learning_rate": 0.03936925417919355,
      "loss": 0.6653,
      "step": 376060
    },
    {
      "epoch": 606.58,
      "learning_rate": 0.03936602837596774,
      "loss": 0.6668,
      "step": 376080
    },
    {
      "epoch": 606.61,
      "learning_rate": 0.03936280257274194,
      "loss": 0.6682,
      "step": 376100
    },
    {
      "epoch": 606.65,
      "learning_rate": 0.03935957676951613,
      "loss": 0.6431,
      "step": 376120
    },
    {
      "epoch": 606.68,
      "learning_rate": 0.039356350966290324,
      "loss": 0.655,
      "step": 376140
    },
    {
      "epoch": 606.71,
      "learning_rate": 0.03935312516306452,
      "loss": 0.6558,
      "step": 376160
    },
    {
      "epoch": 606.74,
      "learning_rate": 0.039349899359838715,
      "loss": 0.6442,
      "step": 376180
    },
    {
      "epoch": 606.77,
      "learning_rate": 0.03934667355661291,
      "loss": 0.6461,
      "step": 376200
    },
    {
      "epoch": 606.81,
      "learning_rate": 0.039343447753387106,
      "loss": 0.6675,
      "step": 376220
    },
    {
      "epoch": 606.84,
      "learning_rate": 0.0393402219501613,
      "loss": 0.6756,
      "step": 376240
    },
    {
      "epoch": 606.87,
      "learning_rate": 0.03933699614693549,
      "loss": 0.6541,
      "step": 376260
    },
    {
      "epoch": 606.9,
      "learning_rate": 0.03933377034370968,
      "loss": 0.6623,
      "step": 376280
    },
    {
      "epoch": 606.94,
      "learning_rate": 0.03933054454048388,
      "loss": 0.6509,
      "step": 376300
    },
    {
      "epoch": 606.97,
      "learning_rate": 0.03932731873725806,
      "loss": 0.6729,
      "step": 376320
    },
    {
      "epoch": 607.0,
      "learning_rate": 0.03932409293403226,
      "loss": 0.6597,
      "step": 376340
    },
    {
      "epoch": 607.0,
      "eval_accuracy": {
        "accuracy": 0.768870501912419
      },
      "eval_loss": 1.0181224346160889,
      "eval_runtime": 2.9465,
      "eval_samples_per_second": 4347.89,
      "eval_steps_per_second": 68.217,
      "step": 376340
    },
    {
      "epoch": 607.03,
      "learning_rate": 0.03932086713080645,
      "loss": 0.6734,
      "step": 376360
    },
    {
      "epoch": 607.06,
      "learning_rate": 0.039317641327580644,
      "loss": 0.6547,
      "step": 376380
    },
    {
      "epoch": 607.1,
      "learning_rate": 0.03931441552435484,
      "loss": 0.6319,
      "step": 376400
    },
    {
      "epoch": 607.13,
      "learning_rate": 0.039311189721129035,
      "loss": 0.668,
      "step": 376420
    },
    {
      "epoch": 607.16,
      "learning_rate": 0.03930796391790323,
      "loss": 0.6529,
      "step": 376440
    },
    {
      "epoch": 607.19,
      "learning_rate": 0.039304738114677426,
      "loss": 0.6403,
      "step": 376460
    },
    {
      "epoch": 607.23,
      "learning_rate": 0.03930151231145162,
      "loss": 0.6477,
      "step": 376480
    },
    {
      "epoch": 607.26,
      "learning_rate": 0.03929828650822581,
      "loss": 0.6444,
      "step": 376500
    },
    {
      "epoch": 607.29,
      "learning_rate": 0.03929506070500001,
      "loss": 0.6462,
      "step": 376520
    },
    {
      "epoch": 607.32,
      "learning_rate": 0.0392918349017742,
      "loss": 0.6477,
      "step": 376540
    },
    {
      "epoch": 607.35,
      "learning_rate": 0.039288609098548394,
      "loss": 0.6548,
      "step": 376560
    },
    {
      "epoch": 607.39,
      "learning_rate": 0.039285383295322586,
      "loss": 0.6564,
      "step": 376580
    },
    {
      "epoch": 607.42,
      "learning_rate": 0.039282157492096785,
      "loss": 0.6627,
      "step": 376600
    },
    {
      "epoch": 607.45,
      "learning_rate": 0.03927893168887096,
      "loss": 0.6531,
      "step": 376620
    },
    {
      "epoch": 607.48,
      "learning_rate": 0.03927570588564516,
      "loss": 0.6533,
      "step": 376640
    },
    {
      "epoch": 607.52,
      "learning_rate": 0.039272480082419355,
      "loss": 0.6527,
      "step": 376660
    },
    {
      "epoch": 607.55,
      "learning_rate": 0.03926925427919355,
      "loss": 0.6448,
      "step": 376680
    },
    {
      "epoch": 607.58,
      "learning_rate": 0.039266028475967746,
      "loss": 0.6529,
      "step": 376700
    },
    {
      "epoch": 607.61,
      "learning_rate": 0.03926280267274194,
      "loss": 0.6792,
      "step": 376720
    },
    {
      "epoch": 607.65,
      "learning_rate": 0.03925957686951613,
      "loss": 0.6526,
      "step": 376740
    },
    {
      "epoch": 607.68,
      "learning_rate": 0.03925635106629033,
      "loss": 0.6535,
      "step": 376760
    },
    {
      "epoch": 607.71,
      "learning_rate": 0.03925312526306452,
      "loss": 0.6425,
      "step": 376780
    },
    {
      "epoch": 607.74,
      "learning_rate": 0.039249899459838714,
      "loss": 0.6606,
      "step": 376800
    },
    {
      "epoch": 607.77,
      "learning_rate": 0.039246673656612906,
      "loss": 0.691,
      "step": 376820
    },
    {
      "epoch": 607.81,
      "learning_rate": 0.039243447853387105,
      "loss": 0.6815,
      "step": 376840
    },
    {
      "epoch": 607.84,
      "learning_rate": 0.0392402220501613,
      "loss": 0.6389,
      "step": 376860
    },
    {
      "epoch": 607.87,
      "learning_rate": 0.03923699624693549,
      "loss": 0.6556,
      "step": 376880
    },
    {
      "epoch": 607.9,
      "learning_rate": 0.03923377044370969,
      "loss": 0.6645,
      "step": 376900
    },
    {
      "epoch": 607.94,
      "learning_rate": 0.03923054464048388,
      "loss": 0.6693,
      "step": 376920
    },
    {
      "epoch": 607.97,
      "learning_rate": 0.039227318837258066,
      "loss": 0.6578,
      "step": 376940
    },
    {
      "epoch": 608.0,
      "learning_rate": 0.03922409303403226,
      "loss": 0.649,
      "step": 376960
    },
    {
      "epoch": 608.0,
      "eval_accuracy": {
        "accuracy": 0.7646553742877215
      },
      "eval_loss": 1.0325604677200317,
      "eval_runtime": 3.7449,
      "eval_samples_per_second": 3420.941,
      "eval_steps_per_second": 53.673,
      "step": 376960
    },
    {
      "epoch": 608.03,
      "learning_rate": 0.03922086723080645,
      "loss": 0.6713,
      "step": 376980
    },
    {
      "epoch": 608.06,
      "learning_rate": 0.03921764142758065,
      "loss": 0.6493,
      "step": 377000
    },
    {
      "epoch": 608.1,
      "learning_rate": 0.03921441562435484,
      "loss": 0.6473,
      "step": 377020
    },
    {
      "epoch": 608.13,
      "learning_rate": 0.03921118982112903,
      "loss": 0.6473,
      "step": 377040
    },
    {
      "epoch": 608.16,
      "learning_rate": 0.03920796401790323,
      "loss": 0.6466,
      "step": 377060
    },
    {
      "epoch": 608.19,
      "learning_rate": 0.039204738214677425,
      "loss": 0.6443,
      "step": 377080
    },
    {
      "epoch": 608.23,
      "learning_rate": 0.03920151241145162,
      "loss": 0.6336,
      "step": 377100
    },
    {
      "epoch": 608.26,
      "learning_rate": 0.03919828660822581,
      "loss": 0.6417,
      "step": 377120
    },
    {
      "epoch": 608.29,
      "learning_rate": 0.03919506080500001,
      "loss": 0.6501,
      "step": 377140
    },
    {
      "epoch": 608.32,
      "learning_rate": 0.0391918350017742,
      "loss": 0.6581,
      "step": 377160
    },
    {
      "epoch": 608.35,
      "learning_rate": 0.03918860919854839,
      "loss": 0.639,
      "step": 377180
    },
    {
      "epoch": 608.39,
      "learning_rate": 0.03918538339532259,
      "loss": 0.641,
      "step": 377200
    },
    {
      "epoch": 608.42,
      "learning_rate": 0.039182157592096784,
      "loss": 0.6608,
      "step": 377220
    },
    {
      "epoch": 608.45,
      "learning_rate": 0.03917893178887097,
      "loss": 0.6573,
      "step": 377240
    },
    {
      "epoch": 608.48,
      "learning_rate": 0.03917570598564516,
      "loss": 0.6638,
      "step": 377260
    },
    {
      "epoch": 608.52,
      "learning_rate": 0.03917248018241935,
      "loss": 0.6638,
      "step": 377280
    },
    {
      "epoch": 608.55,
      "learning_rate": 0.03916925437919355,
      "loss": 0.6419,
      "step": 377300
    },
    {
      "epoch": 608.58,
      "learning_rate": 0.039166028575967744,
      "loss": 0.6523,
      "step": 377320
    },
    {
      "epoch": 608.61,
      "learning_rate": 0.039162802772741936,
      "loss": 0.6442,
      "step": 377340
    },
    {
      "epoch": 608.65,
      "learning_rate": 0.03915957696951613,
      "loss": 0.6466,
      "step": 377360
    },
    {
      "epoch": 608.68,
      "learning_rate": 0.03915635116629033,
      "loss": 0.6508,
      "step": 377380
    },
    {
      "epoch": 608.71,
      "learning_rate": 0.03915312536306452,
      "loss": 0.6597,
      "step": 377400
    },
    {
      "epoch": 608.74,
      "learning_rate": 0.03914989955983871,
      "loss": 0.6685,
      "step": 377420
    },
    {
      "epoch": 608.77,
      "learning_rate": 0.03914667375661291,
      "loss": 0.6634,
      "step": 377440
    },
    {
      "epoch": 608.81,
      "learning_rate": 0.0391434479533871,
      "loss": 0.6406,
      "step": 377460
    },
    {
      "epoch": 608.84,
      "learning_rate": 0.039140222150161295,
      "loss": 0.6571,
      "step": 377480
    },
    {
      "epoch": 608.87,
      "learning_rate": 0.039136996346935495,
      "loss": 0.6642,
      "step": 377500
    },
    {
      "epoch": 608.9,
      "learning_rate": 0.03913377054370969,
      "loss": 0.6545,
      "step": 377520
    },
    {
      "epoch": 608.94,
      "learning_rate": 0.03913054474048388,
      "loss": 0.6552,
      "step": 377540
    },
    {
      "epoch": 608.97,
      "learning_rate": 0.039127318937258064,
      "loss": 0.6624,
      "step": 377560
    },
    {
      "epoch": 609.0,
      "learning_rate": 0.03912425442419355,
      "loss": 0.6702,
      "step": 377580
    },
    {
      "epoch": 609.0,
      "eval_accuracy": {
        "accuracy": 0.770197486535009
      },
      "eval_loss": 1.008636713027954,
      "eval_runtime": 3.0118,
      "eval_samples_per_second": 4253.595,
      "eval_steps_per_second": 66.737,
      "step": 377580
    },
    {
      "epoch": 609.03,
      "learning_rate": 0.03912102862096775,
      "loss": 0.6555,
      "step": 377600
    },
    {
      "epoch": 609.06,
      "learning_rate": 0.039117802817741944,
      "loss": 0.6443,
      "step": 377620
    },
    {
      "epoch": 609.1,
      "learning_rate": 0.039114577014516136,
      "loss": 0.6376,
      "step": 377640
    },
    {
      "epoch": 609.13,
      "learning_rate": 0.03911135121129033,
      "loss": 0.6382,
      "step": 377660
    },
    {
      "epoch": 609.16,
      "learning_rate": 0.03910812540806453,
      "loss": 0.667,
      "step": 377680
    },
    {
      "epoch": 609.19,
      "learning_rate": 0.039104899604838705,
      "loss": 0.6529,
      "step": 377700
    },
    {
      "epoch": 609.23,
      "learning_rate": 0.039101673801612905,
      "loss": 0.6784,
      "step": 377720
    },
    {
      "epoch": 609.26,
      "learning_rate": 0.0390984479983871,
      "loss": 0.6485,
      "step": 377740
    },
    {
      "epoch": 609.29,
      "learning_rate": 0.03909522219516129,
      "loss": 0.6537,
      "step": 377760
    },
    {
      "epoch": 609.32,
      "learning_rate": 0.03909199639193549,
      "loss": 0.6719,
      "step": 377780
    },
    {
      "epoch": 609.35,
      "learning_rate": 0.03908877058870968,
      "loss": 0.6489,
      "step": 377800
    },
    {
      "epoch": 609.39,
      "learning_rate": 0.03908554478548387,
      "loss": 0.6512,
      "step": 377820
    },
    {
      "epoch": 609.42,
      "learning_rate": 0.03908231898225807,
      "loss": 0.6533,
      "step": 377840
    },
    {
      "epoch": 609.45,
      "learning_rate": 0.039079093179032263,
      "loss": 0.6487,
      "step": 377860
    },
    {
      "epoch": 609.48,
      "learning_rate": 0.039075867375806456,
      "loss": 0.6542,
      "step": 377880
    },
    {
      "epoch": 609.52,
      "learning_rate": 0.03907264157258065,
      "loss": 0.6606,
      "step": 377900
    },
    {
      "epoch": 609.55,
      "learning_rate": 0.03906941576935485,
      "loss": 0.6386,
      "step": 377920
    },
    {
      "epoch": 609.58,
      "learning_rate": 0.03906618996612904,
      "loss": 0.6774,
      "step": 377940
    },
    {
      "epoch": 609.61,
      "learning_rate": 0.03906296416290323,
      "loss": 0.6495,
      "step": 377960
    },
    {
      "epoch": 609.65,
      "learning_rate": 0.03905973835967743,
      "loss": 0.6664,
      "step": 377980
    },
    {
      "epoch": 609.68,
      "learning_rate": 0.03905651255645162,
      "loss": 0.6558,
      "step": 378000
    },
    {
      "epoch": 609.71,
      "learning_rate": 0.03905328675322581,
      "loss": 0.6605,
      "step": 378020
    },
    {
      "epoch": 609.74,
      "learning_rate": 0.03905006095,
      "loss": 0.648,
      "step": 378040
    },
    {
      "epoch": 609.77,
      "learning_rate": 0.03904683514677419,
      "loss": 0.6431,
      "step": 378060
    },
    {
      "epoch": 609.81,
      "learning_rate": 0.03904360934354839,
      "loss": 0.6502,
      "step": 378080
    },
    {
      "epoch": 609.84,
      "learning_rate": 0.03904038354032258,
      "loss": 0.6467,
      "step": 378100
    },
    {
      "epoch": 609.87,
      "learning_rate": 0.039037157737096775,
      "loss": 0.6545,
      "step": 378120
    },
    {
      "epoch": 609.9,
      "learning_rate": 0.039033931933870974,
      "loss": 0.6708,
      "step": 378140
    },
    {
      "epoch": 609.94,
      "learning_rate": 0.03903070613064517,
      "loss": 0.669,
      "step": 378160
    },
    {
      "epoch": 609.97,
      "learning_rate": 0.03902748032741936,
      "loss": 0.6638,
      "step": 378180
    },
    {
      "epoch": 610.0,
      "learning_rate": 0.03902425452419355,
      "loss": 0.661,
      "step": 378200
    },
    {
      "epoch": 610.0,
      "eval_accuracy": {
        "accuracy": 0.7652798376395286
      },
      "eval_loss": 1.0209470987319946,
      "eval_runtime": 2.8382,
      "eval_samples_per_second": 4513.788,
      "eval_steps_per_second": 70.82,
      "step": 378200
    },
    {
      "epoch": 610.03,
      "learning_rate": 0.03902102872096775,
      "loss": 0.6669,
      "step": 378220
    },
    {
      "epoch": 610.06,
      "learning_rate": 0.03901780291774194,
      "loss": 0.6559,
      "step": 378240
    },
    {
      "epoch": 610.1,
      "learning_rate": 0.039014577114516134,
      "loss": 0.6409,
      "step": 378260
    },
    {
      "epoch": 610.13,
      "learning_rate": 0.03901135131129033,
      "loss": 0.6465,
      "step": 378280
    },
    {
      "epoch": 610.16,
      "learning_rate": 0.039008125508064526,
      "loss": 0.6417,
      "step": 378300
    },
    {
      "epoch": 610.19,
      "learning_rate": 0.03900489970483871,
      "loss": 0.6313,
      "step": 378320
    },
    {
      "epoch": 610.23,
      "learning_rate": 0.0390016739016129,
      "loss": 0.6605,
      "step": 378340
    },
    {
      "epoch": 610.26,
      "learning_rate": 0.038998448098387095,
      "loss": 0.6526,
      "step": 378360
    },
    {
      "epoch": 610.29,
      "learning_rate": 0.038995222295161294,
      "loss": 0.651,
      "step": 378380
    },
    {
      "epoch": 610.32,
      "learning_rate": 0.038991996491935486,
      "loss": 0.6547,
      "step": 378400
    },
    {
      "epoch": 610.35,
      "learning_rate": 0.03898877068870968,
      "loss": 0.6624,
      "step": 378420
    },
    {
      "epoch": 610.39,
      "learning_rate": 0.03898554488548387,
      "loss": 0.6491,
      "step": 378440
    },
    {
      "epoch": 610.42,
      "learning_rate": 0.03898231908225807,
      "loss": 0.6574,
      "step": 378460
    },
    {
      "epoch": 610.45,
      "learning_rate": 0.03897909327903226,
      "loss": 0.6492,
      "step": 378480
    },
    {
      "epoch": 610.48,
      "learning_rate": 0.038975867475806454,
      "loss": 0.6379,
      "step": 378500
    },
    {
      "epoch": 610.52,
      "learning_rate": 0.03897264167258065,
      "loss": 0.6291,
      "step": 378520
    },
    {
      "epoch": 610.55,
      "learning_rate": 0.038969415869354845,
      "loss": 0.6553,
      "step": 378540
    },
    {
      "epoch": 610.58,
      "learning_rate": 0.03896619006612904,
      "loss": 0.657,
      "step": 378560
    },
    {
      "epoch": 610.61,
      "learning_rate": 0.03896296426290324,
      "loss": 0.6523,
      "step": 378580
    },
    {
      "epoch": 610.65,
      "learning_rate": 0.03895973845967743,
      "loss": 0.6502,
      "step": 378600
    },
    {
      "epoch": 610.68,
      "learning_rate": 0.03895651265645162,
      "loss": 0.6501,
      "step": 378620
    },
    {
      "epoch": 610.71,
      "learning_rate": 0.038953286853225806,
      "loss": 0.653,
      "step": 378640
    },
    {
      "epoch": 610.74,
      "learning_rate": 0.03895006105,
      "loss": 0.6599,
      "step": 378660
    },
    {
      "epoch": 610.77,
      "learning_rate": 0.03894683524677419,
      "loss": 0.6494,
      "step": 378680
    },
    {
      "epoch": 610.81,
      "learning_rate": 0.03894360944354839,
      "loss": 0.6674,
      "step": 378700
    },
    {
      "epoch": 610.84,
      "learning_rate": 0.03894038364032258,
      "loss": 0.6768,
      "step": 378720
    },
    {
      "epoch": 610.87,
      "learning_rate": 0.038937157837096774,
      "loss": 0.6544,
      "step": 378740
    },
    {
      "epoch": 610.9,
      "learning_rate": 0.03893393203387097,
      "loss": 0.6625,
      "step": 378760
    },
    {
      "epoch": 610.94,
      "learning_rate": 0.038930706230645165,
      "loss": 0.6666,
      "step": 378780
    },
    {
      "epoch": 610.97,
      "learning_rate": 0.03892748042741936,
      "loss": 0.663,
      "step": 378800
    },
    {
      "epoch": 611.0,
      "learning_rate": 0.038924254624193556,
      "loss": 0.6735,
      "step": 378820
    },
    {
      "epoch": 611.0,
      "eval_accuracy": {
        "accuracy": 0.769494965264226
      },
      "eval_loss": 1.0185346603393555,
      "eval_runtime": 3.2305,
      "eval_samples_per_second": 3965.627,
      "eval_steps_per_second": 62.219,
      "step": 378820
    },
    {
      "epoch": 611.03,
      "learning_rate": 0.03892102882096775,
      "loss": 0.6485,
      "step": 378840
    },
    {
      "epoch": 611.06,
      "learning_rate": 0.03891780301774194,
      "loss": 0.6457,
      "step": 378860
    },
    {
      "epoch": 611.1,
      "learning_rate": 0.03891457721451614,
      "loss": 0.6425,
      "step": 378880
    },
    {
      "epoch": 611.13,
      "learning_rate": 0.03891135141129033,
      "loss": 0.6646,
      "step": 378900
    },
    {
      "epoch": 611.16,
      "learning_rate": 0.038908125608064524,
      "loss": 0.6464,
      "step": 378920
    },
    {
      "epoch": 611.19,
      "learning_rate": 0.03890489980483871,
      "loss": 0.6402,
      "step": 378940
    },
    {
      "epoch": 611.23,
      "learning_rate": 0.0389016740016129,
      "loss": 0.6479,
      "step": 378960
    },
    {
      "epoch": 611.26,
      "learning_rate": 0.038898448198387094,
      "loss": 0.6599,
      "step": 378980
    },
    {
      "epoch": 611.29,
      "learning_rate": 0.03889522239516129,
      "loss": 0.6426,
      "step": 379000
    },
    {
      "epoch": 611.32,
      "learning_rate": 0.038891996591935485,
      "loss": 0.6472,
      "step": 379020
    },
    {
      "epoch": 611.35,
      "learning_rate": 0.03888877078870968,
      "loss": 0.6578,
      "step": 379040
    },
    {
      "epoch": 611.39,
      "learning_rate": 0.038885544985483876,
      "loss": 0.641,
      "step": 379060
    },
    {
      "epoch": 611.42,
      "learning_rate": 0.03888231918225807,
      "loss": 0.6614,
      "step": 379080
    },
    {
      "epoch": 611.45,
      "learning_rate": 0.03887909337903226,
      "loss": 0.6515,
      "step": 379100
    },
    {
      "epoch": 611.48,
      "learning_rate": 0.03887586757580646,
      "loss": 0.653,
      "step": 379120
    },
    {
      "epoch": 611.52,
      "learning_rate": 0.03887264177258065,
      "loss": 0.6663,
      "step": 379140
    },
    {
      "epoch": 611.55,
      "learning_rate": 0.038869415969354844,
      "loss": 0.6354,
      "step": 379160
    },
    {
      "epoch": 611.58,
      "learning_rate": 0.038866190166129036,
      "loss": 0.6632,
      "step": 379180
    },
    {
      "epoch": 611.61,
      "learning_rate": 0.038862964362903235,
      "loss": 0.6638,
      "step": 379200
    },
    {
      "epoch": 611.65,
      "learning_rate": 0.03885973855967743,
      "loss": 0.6491,
      "step": 379220
    },
    {
      "epoch": 611.68,
      "learning_rate": 0.03885651275645162,
      "loss": 0.6551,
      "step": 379240
    },
    {
      "epoch": 611.71,
      "learning_rate": 0.038853286953225805,
      "loss": 0.6535,
      "step": 379260
    },
    {
      "epoch": 611.74,
      "learning_rate": 0.03885006115,
      "loss": 0.6662,
      "step": 379280
    },
    {
      "epoch": 611.77,
      "learning_rate": 0.038846835346774196,
      "loss": 0.6676,
      "step": 379300
    },
    {
      "epoch": 611.81,
      "learning_rate": 0.03884360954354839,
      "loss": 0.6453,
      "step": 379320
    },
    {
      "epoch": 611.84,
      "learning_rate": 0.03884038374032258,
      "loss": 0.6421,
      "step": 379340
    },
    {
      "epoch": 611.87,
      "learning_rate": 0.03883715793709678,
      "loss": 0.6519,
      "step": 379360
    },
    {
      "epoch": 611.9,
      "learning_rate": 0.03883393213387097,
      "loss": 0.6623,
      "step": 379380
    },
    {
      "epoch": 611.94,
      "learning_rate": 0.038830706330645164,
      "loss": 0.6598,
      "step": 379400
    },
    {
      "epoch": 611.97,
      "learning_rate": 0.03882748052741936,
      "loss": 0.6564,
      "step": 379420
    },
    {
      "epoch": 612.0,
      "learning_rate": 0.038824254724193555,
      "loss": 0.6548,
      "step": 379440
    },
    {
      "epoch": 612.0,
      "eval_accuracy": {
        "accuracy": 0.761767231285614
      },
      "eval_loss": 1.0345677137374878,
      "eval_runtime": 2.8596,
      "eval_samples_per_second": 4480.072,
      "eval_steps_per_second": 70.291,
      "step": 379440
    },
    {
      "epoch": 612.03,
      "learning_rate": 0.03882102892096775,
      "loss": 0.6582,
      "step": 379460
    },
    {
      "epoch": 612.06,
      "learning_rate": 0.03881780311774194,
      "loss": 0.6348,
      "step": 379480
    },
    {
      "epoch": 612.1,
      "learning_rate": 0.03881457731451614,
      "loss": 0.6373,
      "step": 379500
    },
    {
      "epoch": 612.13,
      "learning_rate": 0.03881135151129033,
      "loss": 0.6563,
      "step": 379520
    },
    {
      "epoch": 612.16,
      "learning_rate": 0.03880812570806452,
      "loss": 0.6501,
      "step": 379540
    },
    {
      "epoch": 612.19,
      "learning_rate": 0.03880489990483871,
      "loss": 0.6549,
      "step": 379560
    },
    {
      "epoch": 612.23,
      "learning_rate": 0.0388016741016129,
      "loss": 0.6464,
      "step": 379580
    },
    {
      "epoch": 612.26,
      "learning_rate": 0.0387984482983871,
      "loss": 0.664,
      "step": 379600
    },
    {
      "epoch": 612.29,
      "learning_rate": 0.03879522249516129,
      "loss": 0.6456,
      "step": 379620
    },
    {
      "epoch": 612.32,
      "learning_rate": 0.03879199669193548,
      "loss": 0.655,
      "step": 379640
    },
    {
      "epoch": 612.35,
      "learning_rate": 0.03878877088870968,
      "loss": 0.6538,
      "step": 379660
    },
    {
      "epoch": 612.39,
      "learning_rate": 0.038785545085483875,
      "loss": 0.6343,
      "step": 379680
    },
    {
      "epoch": 612.42,
      "learning_rate": 0.03878231928225807,
      "loss": 0.6534,
      "step": 379700
    },
    {
      "epoch": 612.45,
      "learning_rate": 0.03877909347903226,
      "loss": 0.6564,
      "step": 379720
    },
    {
      "epoch": 612.48,
      "learning_rate": 0.03877586767580646,
      "loss": 0.6683,
      "step": 379740
    },
    {
      "epoch": 612.52,
      "learning_rate": 0.03877264187258065,
      "loss": 0.6537,
      "step": 379760
    },
    {
      "epoch": 612.55,
      "learning_rate": 0.03876941606935484,
      "loss": 0.6533,
      "step": 379780
    },
    {
      "epoch": 612.58,
      "learning_rate": 0.03876619026612904,
      "loss": 0.667,
      "step": 379800
    },
    {
      "epoch": 612.61,
      "learning_rate": 0.038762964462903234,
      "loss": 0.649,
      "step": 379820
    },
    {
      "epoch": 612.65,
      "learning_rate": 0.038759738659677426,
      "loss": 0.6499,
      "step": 379840
    },
    {
      "epoch": 612.68,
      "learning_rate": 0.038756512856451625,
      "loss": 0.6642,
      "step": 379860
    },
    {
      "epoch": 612.71,
      "learning_rate": 0.0387532870532258,
      "loss": 0.6787,
      "step": 379880
    },
    {
      "epoch": 612.74,
      "learning_rate": 0.03875006125,
      "loss": 0.6682,
      "step": 379900
    },
    {
      "epoch": 612.77,
      "learning_rate": 0.038746835446774194,
      "loss": 0.6451,
      "step": 379920
    },
    {
      "epoch": 612.81,
      "learning_rate": 0.038743609643548386,
      "loss": 0.6768,
      "step": 379940
    },
    {
      "epoch": 612.84,
      "learning_rate": 0.038740383840322586,
      "loss": 0.6785,
      "step": 379960
    },
    {
      "epoch": 612.87,
      "learning_rate": 0.03873715803709678,
      "loss": 0.659,
      "step": 379980
    },
    {
      "epoch": 612.9,
      "learning_rate": 0.03873393223387097,
      "loss": 0.6604,
      "step": 380000
    },
    {
      "epoch": 612.94,
      "learning_rate": 0.03873070643064516,
      "loss": 0.6504,
      "step": 380020
    },
    {
      "epoch": 612.97,
      "learning_rate": 0.03872748062741936,
      "loss": 0.6552,
      "step": 380040
    },
    {
      "epoch": 613.0,
      "learning_rate": 0.038724416114354836,
      "loss": 0.6618,
      "step": 380060
    },
    {
      "epoch": 613.0,
      "eval_accuracy": {
        "accuracy": 0.7678557489657326
      },
      "eval_loss": 1.0184906721115112,
      "eval_runtime": 2.8787,
      "eval_samples_per_second": 4450.252,
      "eval_steps_per_second": 69.823,
      "step": 380060
    },
    {
      "epoch": 613.03,
      "learning_rate": 0.038721190311129035,
      "loss": 0.6542,
      "step": 380080
    },
    {
      "epoch": 613.06,
      "learning_rate": 0.03871796450790323,
      "loss": 0.6617,
      "step": 380100
    },
    {
      "epoch": 613.1,
      "learning_rate": 0.03871473870467742,
      "loss": 0.6504,
      "step": 380120
    },
    {
      "epoch": 613.13,
      "learning_rate": 0.03871151290145162,
      "loss": 0.6562,
      "step": 380140
    },
    {
      "epoch": 613.16,
      "learning_rate": 0.03870828709822581,
      "loss": 0.6477,
      "step": 380160
    },
    {
      "epoch": 613.19,
      "learning_rate": 0.038705061295,
      "loss": 0.6379,
      "step": 380180
    },
    {
      "epoch": 613.23,
      "learning_rate": 0.0387018354917742,
      "loss": 0.6514,
      "step": 380200
    },
    {
      "epoch": 613.26,
      "learning_rate": 0.038698609688548394,
      "loss": 0.6447,
      "step": 380220
    },
    {
      "epoch": 613.29,
      "learning_rate": 0.038695383885322586,
      "loss": 0.6361,
      "step": 380240
    },
    {
      "epoch": 613.32,
      "learning_rate": 0.03869215808209678,
      "loss": 0.648,
      "step": 380260
    },
    {
      "epoch": 613.35,
      "learning_rate": 0.03868893227887098,
      "loss": 0.6472,
      "step": 380280
    },
    {
      "epoch": 613.39,
      "learning_rate": 0.03868570647564517,
      "loss": 0.654,
      "step": 380300
    },
    {
      "epoch": 613.42,
      "learning_rate": 0.03868248067241936,
      "loss": 0.6711,
      "step": 380320
    },
    {
      "epoch": 613.45,
      "learning_rate": 0.03867925486919355,
      "loss": 0.6556,
      "step": 380340
    },
    {
      "epoch": 613.48,
      "learning_rate": 0.03867602906596774,
      "loss": 0.643,
      "step": 380360
    },
    {
      "epoch": 613.52,
      "learning_rate": 0.03867280326274194,
      "loss": 0.6464,
      "step": 380380
    },
    {
      "epoch": 613.55,
      "learning_rate": 0.03866957745951613,
      "loss": 0.6629,
      "step": 380400
    },
    {
      "epoch": 613.58,
      "learning_rate": 0.03866635165629032,
      "loss": 0.6454,
      "step": 380420
    },
    {
      "epoch": 613.61,
      "learning_rate": 0.03866312585306452,
      "loss": 0.6419,
      "step": 380440
    },
    {
      "epoch": 613.65,
      "learning_rate": 0.038659900049838714,
      "loss": 0.6472,
      "step": 380460
    },
    {
      "epoch": 613.68,
      "learning_rate": 0.038656674246612906,
      "loss": 0.6557,
      "step": 380480
    },
    {
      "epoch": 613.71,
      "learning_rate": 0.038653448443387105,
      "loss": 0.677,
      "step": 380500
    },
    {
      "epoch": 613.74,
      "learning_rate": 0.0386502226401613,
      "loss": 0.6721,
      "step": 380520
    },
    {
      "epoch": 613.77,
      "learning_rate": 0.03864699683693549,
      "loss": 0.653,
      "step": 380540
    },
    {
      "epoch": 613.81,
      "learning_rate": 0.03864377103370968,
      "loss": 0.6513,
      "step": 380560
    },
    {
      "epoch": 613.84,
      "learning_rate": 0.03864054523048388,
      "loss": 0.6472,
      "step": 380580
    },
    {
      "epoch": 613.87,
      "learning_rate": 0.03863731942725807,
      "loss": 0.6554,
      "step": 380600
    },
    {
      "epoch": 613.9,
      "learning_rate": 0.038634093624032265,
      "loss": 0.6461,
      "step": 380620
    },
    {
      "epoch": 613.94,
      "learning_rate": 0.03863086782080645,
      "loss": 0.6616,
      "step": 380640
    },
    {
      "epoch": 613.97,
      "learning_rate": 0.03862764201758064,
      "loss": 0.6476,
      "step": 380660
    },
    {
      "epoch": 614.0,
      "learning_rate": 0.03862441621435484,
      "loss": 0.6669,
      "step": 380680
    },
    {
      "epoch": 614.0,
      "eval_accuracy": {
        "accuracy": 0.7672312856139255
      },
      "eval_loss": 1.0165057182312012,
      "eval_runtime": 3.0117,
      "eval_samples_per_second": 4253.786,
      "eval_steps_per_second": 66.74,
      "step": 380680
    },
    {
      "epoch": 614.03,
      "learning_rate": 0.03862119041112903,
      "loss": 0.674,
      "step": 380700
    },
    {
      "epoch": 614.06,
      "learning_rate": 0.038617964607903225,
      "loss": 0.6551,
      "step": 380720
    },
    {
      "epoch": 614.1,
      "learning_rate": 0.038614738804677425,
      "loss": 0.6341,
      "step": 380740
    },
    {
      "epoch": 614.13,
      "learning_rate": 0.03861151300145162,
      "loss": 0.6373,
      "step": 380760
    },
    {
      "epoch": 614.16,
      "learning_rate": 0.03860828719822581,
      "loss": 0.6587,
      "step": 380780
    },
    {
      "epoch": 614.19,
      "learning_rate": 0.038605061395,
      "loss": 0.6665,
      "step": 380800
    },
    {
      "epoch": 614.23,
      "learning_rate": 0.0386018355917742,
      "loss": 0.669,
      "step": 380820
    },
    {
      "epoch": 614.26,
      "learning_rate": 0.03859860978854839,
      "loss": 0.6548,
      "step": 380840
    },
    {
      "epoch": 614.29,
      "learning_rate": 0.038595383985322584,
      "loss": 0.6545,
      "step": 380860
    },
    {
      "epoch": 614.32,
      "learning_rate": 0.038592158182096784,
      "loss": 0.6499,
      "step": 380880
    },
    {
      "epoch": 614.35,
      "learning_rate": 0.038588932378870976,
      "loss": 0.6623,
      "step": 380900
    },
    {
      "epoch": 614.39,
      "learning_rate": 0.03858570657564517,
      "loss": 0.6358,
      "step": 380920
    },
    {
      "epoch": 614.42,
      "learning_rate": 0.03858248077241937,
      "loss": 0.6248,
      "step": 380940
    },
    {
      "epoch": 614.45,
      "learning_rate": 0.038579254969193545,
      "loss": 0.6555,
      "step": 380960
    },
    {
      "epoch": 614.48,
      "learning_rate": 0.038576029165967744,
      "loss": 0.636,
      "step": 380980
    },
    {
      "epoch": 614.52,
      "learning_rate": 0.038572803362741936,
      "loss": 0.6606,
      "step": 381000
    },
    {
      "epoch": 614.55,
      "learning_rate": 0.03856957755951613,
      "loss": 0.6591,
      "step": 381020
    },
    {
      "epoch": 614.58,
      "learning_rate": 0.03856635175629033,
      "loss": 0.6542,
      "step": 381040
    },
    {
      "epoch": 614.61,
      "learning_rate": 0.03856312595306452,
      "loss": 0.6547,
      "step": 381060
    },
    {
      "epoch": 614.65,
      "learning_rate": 0.03855990014983871,
      "loss": 0.6531,
      "step": 381080
    },
    {
      "epoch": 614.68,
      "learning_rate": 0.038556674346612904,
      "loss": 0.6387,
      "step": 381100
    },
    {
      "epoch": 614.71,
      "learning_rate": 0.0385534485433871,
      "loss": 0.6361,
      "step": 381120
    },
    {
      "epoch": 614.74,
      "learning_rate": 0.038550222740161295,
      "loss": 0.6446,
      "step": 381140
    },
    {
      "epoch": 614.77,
      "learning_rate": 0.03854699693693549,
      "loss": 0.6484,
      "step": 381160
    },
    {
      "epoch": 614.81,
      "learning_rate": 0.03854377113370969,
      "loss": 0.6612,
      "step": 381180
    },
    {
      "epoch": 614.84,
      "learning_rate": 0.03854054533048388,
      "loss": 0.6492,
      "step": 381200
    },
    {
      "epoch": 614.87,
      "learning_rate": 0.03853731952725807,
      "loss": 0.6677,
      "step": 381220
    },
    {
      "epoch": 614.9,
      "learning_rate": 0.03853409372403227,
      "loss": 0.6487,
      "step": 381240
    },
    {
      "epoch": 614.94,
      "learning_rate": 0.03853086792080645,
      "loss": 0.6555,
      "step": 381260
    },
    {
      "epoch": 614.97,
      "learning_rate": 0.03852764211758065,
      "loss": 0.662,
      "step": 381280
    },
    {
      "epoch": 615.0,
      "learning_rate": 0.03852441631435484,
      "loss": 0.6486,
      "step": 381300
    },
    {
      "epoch": 615.0,
      "eval_accuracy": {
        "accuracy": 0.773475919131996
      },
      "eval_loss": 1.0083997249603271,
      "eval_runtime": 2.845,
      "eval_samples_per_second": 4502.96,
      "eval_steps_per_second": 70.65,
      "step": 381300
    },
    {
      "epoch": 615.03,
      "learning_rate": 0.03852119051112903,
      "loss": 0.6589,
      "step": 381320
    },
    {
      "epoch": 615.06,
      "learning_rate": 0.038517964707903224,
      "loss": 0.663,
      "step": 381340
    },
    {
      "epoch": 615.1,
      "learning_rate": 0.03851473890467742,
      "loss": 0.645,
      "step": 381360
    },
    {
      "epoch": 615.13,
      "learning_rate": 0.038511513101451615,
      "loss": 0.6502,
      "step": 381380
    },
    {
      "epoch": 615.16,
      "learning_rate": 0.03850828729822581,
      "loss": 0.6527,
      "step": 381400
    },
    {
      "epoch": 615.19,
      "learning_rate": 0.038505061495000006,
      "loss": 0.659,
      "step": 381420
    },
    {
      "epoch": 615.23,
      "learning_rate": 0.0385018356917742,
      "loss": 0.638,
      "step": 381440
    },
    {
      "epoch": 615.26,
      "learning_rate": 0.03849860988854839,
      "loss": 0.6456,
      "step": 381460
    },
    {
      "epoch": 615.29,
      "learning_rate": 0.03849538408532259,
      "loss": 0.6504,
      "step": 381480
    },
    {
      "epoch": 615.32,
      "learning_rate": 0.03849215828209678,
      "loss": 0.6607,
      "step": 381500
    },
    {
      "epoch": 615.35,
      "learning_rate": 0.038488932478870974,
      "loss": 0.667,
      "step": 381520
    },
    {
      "epoch": 615.39,
      "learning_rate": 0.03848570667564517,
      "loss": 0.6515,
      "step": 381540
    },
    {
      "epoch": 615.42,
      "learning_rate": 0.038482480872419365,
      "loss": 0.6515,
      "step": 381560
    },
    {
      "epoch": 615.45,
      "learning_rate": 0.03847925506919355,
      "loss": 0.6412,
      "step": 381580
    },
    {
      "epoch": 615.48,
      "learning_rate": 0.03847602926596774,
      "loss": 0.6439,
      "step": 381600
    },
    {
      "epoch": 615.52,
      "learning_rate": 0.038472803462741935,
      "loss": 0.64,
      "step": 381620
    },
    {
      "epoch": 615.55,
      "learning_rate": 0.03846957765951613,
      "loss": 0.6465,
      "step": 381640
    },
    {
      "epoch": 615.58,
      "learning_rate": 0.038466351856290326,
      "loss": 0.662,
      "step": 381660
    },
    {
      "epoch": 615.61,
      "learning_rate": 0.03846312605306452,
      "loss": 0.6461,
      "step": 381680
    },
    {
      "epoch": 615.65,
      "learning_rate": 0.03845990024983871,
      "loss": 0.6433,
      "step": 381700
    },
    {
      "epoch": 615.68,
      "learning_rate": 0.03845667444661291,
      "loss": 0.6682,
      "step": 381720
    },
    {
      "epoch": 615.71,
      "learning_rate": 0.0384534486433871,
      "loss": 0.6706,
      "step": 381740
    },
    {
      "epoch": 615.74,
      "learning_rate": 0.038450222840161294,
      "loss": 0.6365,
      "step": 381760
    },
    {
      "epoch": 615.77,
      "learning_rate": 0.03844699703693549,
      "loss": 0.6411,
      "step": 381780
    },
    {
      "epoch": 615.81,
      "learning_rate": 0.038443771233709685,
      "loss": 0.6601,
      "step": 381800
    },
    {
      "epoch": 615.84,
      "learning_rate": 0.03844054543048388,
      "loss": 0.6615,
      "step": 381820
    },
    {
      "epoch": 615.87,
      "learning_rate": 0.03843731962725807,
      "loss": 0.6495,
      "step": 381840
    },
    {
      "epoch": 615.9,
      "learning_rate": 0.03843409382403227,
      "loss": 0.6657,
      "step": 381860
    },
    {
      "epoch": 615.94,
      "learning_rate": 0.03843086802080645,
      "loss": 0.6527,
      "step": 381880
    },
    {
      "epoch": 615.97,
      "learning_rate": 0.038427642217580646,
      "loss": 0.6673,
      "step": 381900
    },
    {
      "epoch": 616.0,
      "learning_rate": 0.03842441641435484,
      "loss": 0.6513,
      "step": 381920
    },
    {
      "epoch": 616.0,
      "eval_accuracy": {
        "accuracy": 0.7657481851533838
      },
      "eval_loss": 1.0290255546569824,
      "eval_runtime": 3.8468,
      "eval_samples_per_second": 3330.269,
      "eval_steps_per_second": 52.251,
      "step": 381920
    },
    {
      "epoch": 616.03,
      "learning_rate": 0.03842119061112903,
      "loss": 0.6626,
      "step": 381940
    },
    {
      "epoch": 616.06,
      "learning_rate": 0.03841796480790323,
      "loss": 0.6407,
      "step": 381960
    },
    {
      "epoch": 616.1,
      "learning_rate": 0.03841473900467742,
      "loss": 0.6465,
      "step": 381980
    },
    {
      "epoch": 616.13,
      "learning_rate": 0.038411513201451614,
      "loss": 0.6311,
      "step": 382000
    },
    {
      "epoch": 616.16,
      "learning_rate": 0.03840828739822581,
      "loss": 0.6444,
      "step": 382020
    },
    {
      "epoch": 616.19,
      "learning_rate": 0.038405061595000005,
      "loss": 0.6631,
      "step": 382040
    },
    {
      "epoch": 616.23,
      "learning_rate": 0.0384018357917742,
      "loss": 0.6519,
      "step": 382060
    },
    {
      "epoch": 616.26,
      "learning_rate": 0.038398609988548396,
      "loss": 0.641,
      "step": 382080
    },
    {
      "epoch": 616.29,
      "learning_rate": 0.03839538418532259,
      "loss": 0.6524,
      "step": 382100
    },
    {
      "epoch": 616.32,
      "learning_rate": 0.03839215838209678,
      "loss": 0.6493,
      "step": 382120
    },
    {
      "epoch": 616.35,
      "learning_rate": 0.03838893257887097,
      "loss": 0.638,
      "step": 382140
    },
    {
      "epoch": 616.39,
      "learning_rate": 0.03838570677564517,
      "loss": 0.6465,
      "step": 382160
    },
    {
      "epoch": 616.42,
      "learning_rate": 0.038382480972419364,
      "loss": 0.6468,
      "step": 382180
    },
    {
      "epoch": 616.45,
      "learning_rate": 0.03837925516919355,
      "loss": 0.6517,
      "step": 382200
    },
    {
      "epoch": 616.48,
      "learning_rate": 0.03837602936596774,
      "loss": 0.6565,
      "step": 382220
    },
    {
      "epoch": 616.52,
      "learning_rate": 0.03837280356274193,
      "loss": 0.6541,
      "step": 382240
    },
    {
      "epoch": 616.55,
      "learning_rate": 0.03836957775951613,
      "loss": 0.6602,
      "step": 382260
    },
    {
      "epoch": 616.58,
      "learning_rate": 0.038366351956290325,
      "loss": 0.6408,
      "step": 382280
    },
    {
      "epoch": 616.61,
      "learning_rate": 0.03836312615306452,
      "loss": 0.6376,
      "step": 382300
    },
    {
      "epoch": 616.65,
      "learning_rate": 0.038359900349838716,
      "loss": 0.6507,
      "step": 382320
    },
    {
      "epoch": 616.68,
      "learning_rate": 0.03835667454661291,
      "loss": 0.6449,
      "step": 382340
    },
    {
      "epoch": 616.71,
      "learning_rate": 0.0383534487433871,
      "loss": 0.657,
      "step": 382360
    },
    {
      "epoch": 616.74,
      "learning_rate": 0.03835022294016129,
      "loss": 0.6551,
      "step": 382380
    },
    {
      "epoch": 616.77,
      "learning_rate": 0.03834699713693549,
      "loss": 0.6545,
      "step": 382400
    },
    {
      "epoch": 616.81,
      "learning_rate": 0.038343771333709684,
      "loss": 0.6484,
      "step": 382420
    },
    {
      "epoch": 616.84,
      "learning_rate": 0.038340545530483876,
      "loss": 0.652,
      "step": 382440
    },
    {
      "epoch": 616.87,
      "learning_rate": 0.038337319727258075,
      "loss": 0.6616,
      "step": 382460
    },
    {
      "epoch": 616.9,
      "learning_rate": 0.03833409392403227,
      "loss": 0.6619,
      "step": 382480
    },
    {
      "epoch": 616.94,
      "learning_rate": 0.03833086812080645,
      "loss": 0.6673,
      "step": 382500
    },
    {
      "epoch": 616.97,
      "learning_rate": 0.038327642317580644,
      "loss": 0.6583,
      "step": 382520
    },
    {
      "epoch": 617.0,
      "learning_rate": 0.03832457780451613,
      "loss": 0.653,
      "step": 382540
    },
    {
      "epoch": 617.0,
      "eval_accuracy": {
        "accuracy": 0.7731636874560924
      },
      "eval_loss": 1.0068705081939697,
      "eval_runtime": 2.8571,
      "eval_samples_per_second": 4483.864,
      "eval_steps_per_second": 70.35,
      "step": 382540
    },
    {
      "epoch": 617.03,
      "learning_rate": 0.03832135200129033,
      "loss": 0.6341,
      "step": 382560
    },
    {
      "epoch": 617.06,
      "learning_rate": 0.038318126198064524,
      "loss": 0.6376,
      "step": 382580
    },
    {
      "epoch": 617.1,
      "learning_rate": 0.038314900394838716,
      "loss": 0.6389,
      "step": 382600
    },
    {
      "epoch": 617.13,
      "learning_rate": 0.038311674591612915,
      "loss": 0.6269,
      "step": 382620
    },
    {
      "epoch": 617.16,
      "learning_rate": 0.03830844878838711,
      "loss": 0.6521,
      "step": 382640
    },
    {
      "epoch": 617.19,
      "learning_rate": 0.03830522298516129,
      "loss": 0.6525,
      "step": 382660
    },
    {
      "epoch": 617.23,
      "learning_rate": 0.038301997181935485,
      "loss": 0.6447,
      "step": 382680
    },
    {
      "epoch": 617.26,
      "learning_rate": 0.03829877137870968,
      "loss": 0.6359,
      "step": 382700
    },
    {
      "epoch": 617.29,
      "learning_rate": 0.03829554557548387,
      "loss": 0.6428,
      "step": 382720
    },
    {
      "epoch": 617.32,
      "learning_rate": 0.03829231977225807,
      "loss": 0.641,
      "step": 382740
    },
    {
      "epoch": 617.35,
      "learning_rate": 0.03828909396903226,
      "loss": 0.6353,
      "step": 382760
    },
    {
      "epoch": 617.39,
      "learning_rate": 0.03828586816580645,
      "loss": 0.6317,
      "step": 382780
    },
    {
      "epoch": 617.42,
      "learning_rate": 0.03828264236258065,
      "loss": 0.6451,
      "step": 382800
    },
    {
      "epoch": 617.45,
      "learning_rate": 0.038279416559354844,
      "loss": 0.6464,
      "step": 382820
    },
    {
      "epoch": 617.48,
      "learning_rate": 0.038276190756129036,
      "loss": 0.6408,
      "step": 382840
    },
    {
      "epoch": 617.52,
      "learning_rate": 0.038272964952903235,
      "loss": 0.6445,
      "step": 382860
    },
    {
      "epoch": 617.55,
      "learning_rate": 0.03826973914967743,
      "loss": 0.6632,
      "step": 382880
    },
    {
      "epoch": 617.58,
      "learning_rate": 0.03826651334645162,
      "loss": 0.6635,
      "step": 382900
    },
    {
      "epoch": 617.61,
      "learning_rate": 0.03826328754322581,
      "loss": 0.6744,
      "step": 382920
    },
    {
      "epoch": 617.65,
      "learning_rate": 0.03826006174000001,
      "loss": 0.6547,
      "step": 382940
    },
    {
      "epoch": 617.68,
      "learning_rate": 0.03825683593677419,
      "loss": 0.6656,
      "step": 382960
    },
    {
      "epoch": 617.71,
      "learning_rate": 0.03825361013354839,
      "loss": 0.665,
      "step": 382980
    },
    {
      "epoch": 617.74,
      "learning_rate": 0.03825038433032258,
      "loss": 0.6486,
      "step": 383000
    },
    {
      "epoch": 617.77,
      "learning_rate": 0.03824715852709677,
      "loss": 0.6587,
      "step": 383020
    },
    {
      "epoch": 617.81,
      "learning_rate": 0.03824393272387097,
      "loss": 0.6398,
      "step": 383040
    },
    {
      "epoch": 617.84,
      "learning_rate": 0.038240706920645164,
      "loss": 0.6485,
      "step": 383060
    },
    {
      "epoch": 617.87,
      "learning_rate": 0.038237481117419356,
      "loss": 0.6508,
      "step": 383080
    },
    {
      "epoch": 617.9,
      "learning_rate": 0.038234255314193555,
      "loss": 0.659,
      "step": 383100
    },
    {
      "epoch": 617.94,
      "learning_rate": 0.03823102951096775,
      "loss": 0.6444,
      "step": 383120
    },
    {
      "epoch": 617.97,
      "learning_rate": 0.03822780370774194,
      "loss": 0.6582,
      "step": 383140
    },
    {
      "epoch": 618.0,
      "learning_rate": 0.03822457790451614,
      "loss": 0.6688,
      "step": 383160
    },
    {
      "epoch": 618.0,
      "eval_accuracy": {
        "accuracy": 0.7715244711575989
      },
      "eval_loss": 1.0090000629425049,
      "eval_runtime": 2.8532,
      "eval_samples_per_second": 4490.041,
      "eval_steps_per_second": 70.447,
      "step": 383160
    },
    {
      "epoch": 618.03,
      "learning_rate": 0.03822135210129033,
      "loss": 0.6535,
      "step": 383180
    },
    {
      "epoch": 618.06,
      "learning_rate": 0.03821812629806452,
      "loss": 0.6409,
      "step": 383200
    },
    {
      "epoch": 618.1,
      "learning_rate": 0.038214900494838715,
      "loss": 0.6329,
      "step": 383220
    },
    {
      "epoch": 618.13,
      "learning_rate": 0.038211674691612914,
      "loss": 0.6385,
      "step": 383240
    },
    {
      "epoch": 618.16,
      "learning_rate": 0.038208448888387106,
      "loss": 0.6369,
      "step": 383260
    },
    {
      "epoch": 618.19,
      "learning_rate": 0.03820522308516129,
      "loss": 0.6406,
      "step": 383280
    },
    {
      "epoch": 618.23,
      "learning_rate": 0.03820199728193548,
      "loss": 0.6365,
      "step": 383300
    },
    {
      "epoch": 618.26,
      "learning_rate": 0.038198771478709675,
      "loss": 0.6304,
      "step": 383320
    },
    {
      "epoch": 618.29,
      "learning_rate": 0.038195545675483875,
      "loss": 0.6412,
      "step": 383340
    },
    {
      "epoch": 618.32,
      "learning_rate": 0.03819231987225807,
      "loss": 0.6646,
      "step": 383360
    },
    {
      "epoch": 618.35,
      "learning_rate": 0.03818909406903226,
      "loss": 0.6468,
      "step": 383380
    },
    {
      "epoch": 618.39,
      "learning_rate": 0.03818586826580646,
      "loss": 0.6565,
      "step": 383400
    },
    {
      "epoch": 618.42,
      "learning_rate": 0.03818264246258065,
      "loss": 0.6449,
      "step": 383420
    },
    {
      "epoch": 618.45,
      "learning_rate": 0.03817941665935484,
      "loss": 0.6398,
      "step": 383440
    },
    {
      "epoch": 618.48,
      "learning_rate": 0.038176190856129034,
      "loss": 0.637,
      "step": 383460
    },
    {
      "epoch": 618.52,
      "learning_rate": 0.038172965052903234,
      "loss": 0.6565,
      "step": 383480
    },
    {
      "epoch": 618.55,
      "learning_rate": 0.038169739249677426,
      "loss": 0.6518,
      "step": 383500
    },
    {
      "epoch": 618.58,
      "learning_rate": 0.03816651344645162,
      "loss": 0.6516,
      "step": 383520
    },
    {
      "epoch": 618.61,
      "learning_rate": 0.03816328764322582,
      "loss": 0.659,
      "step": 383540
    },
    {
      "epoch": 618.65,
      "learning_rate": 0.03816006184000001,
      "loss": 0.6469,
      "step": 383560
    },
    {
      "epoch": 618.68,
      "learning_rate": 0.038156836036774194,
      "loss": 0.6498,
      "step": 383580
    },
    {
      "epoch": 618.71,
      "learning_rate": 0.038153610233548386,
      "loss": 0.6591,
      "step": 383600
    },
    {
      "epoch": 618.74,
      "learning_rate": 0.03815038443032258,
      "loss": 0.6592,
      "step": 383620
    },
    {
      "epoch": 618.77,
      "learning_rate": 0.03814715862709678,
      "loss": 0.6649,
      "step": 383640
    },
    {
      "epoch": 618.81,
      "learning_rate": 0.03814393282387097,
      "loss": 0.6528,
      "step": 383660
    },
    {
      "epoch": 618.84,
      "learning_rate": 0.03814070702064516,
      "loss": 0.6529,
      "step": 383680
    },
    {
      "epoch": 618.87,
      "learning_rate": 0.038137481217419354,
      "loss": 0.6571,
      "step": 383700
    },
    {
      "epoch": 618.9,
      "learning_rate": 0.03813425541419355,
      "loss": 0.6645,
      "step": 383720
    },
    {
      "epoch": 618.94,
      "learning_rate": 0.038131029610967745,
      "loss": 0.6596,
      "step": 383740
    },
    {
      "epoch": 618.97,
      "learning_rate": 0.03812780380774194,
      "loss": 0.6544,
      "step": 383760
    },
    {
      "epoch": 619.0,
      "learning_rate": 0.03812457800451614,
      "loss": 0.6498,
      "step": 383780
    },
    {
      "epoch": 619.0,
      "eval_accuracy": {
        "accuracy": 0.7624697525563968
      },
      "eval_loss": 1.0217760801315308,
      "eval_runtime": 2.9052,
      "eval_samples_per_second": 4409.632,
      "eval_steps_per_second": 69.186,
      "step": 383780
    },
    {
      "epoch": 619.03,
      "learning_rate": 0.03812135220129033,
      "loss": 0.6562,
      "step": 383800
    },
    {
      "epoch": 619.06,
      "learning_rate": 0.03811812639806452,
      "loss": 0.6545,
      "step": 383820
    },
    {
      "epoch": 619.1,
      "learning_rate": 0.03811490059483872,
      "loss": 0.6385,
      "step": 383840
    },
    {
      "epoch": 619.13,
      "learning_rate": 0.03811167479161291,
      "loss": 0.6374,
      "step": 383860
    },
    {
      "epoch": 619.16,
      "learning_rate": 0.038108448988387104,
      "loss": 0.6351,
      "step": 383880
    },
    {
      "epoch": 619.19,
      "learning_rate": 0.03810522318516129,
      "loss": 0.6406,
      "step": 383900
    },
    {
      "epoch": 619.23,
      "learning_rate": 0.03810199738193548,
      "loss": 0.6458,
      "step": 383920
    },
    {
      "epoch": 619.26,
      "learning_rate": 0.03809877157870968,
      "loss": 0.6524,
      "step": 383940
    },
    {
      "epoch": 619.29,
      "learning_rate": 0.03809554577548387,
      "loss": 0.6532,
      "step": 383960
    },
    {
      "epoch": 619.32,
      "learning_rate": 0.038092319972258065,
      "loss": 0.6555,
      "step": 383980
    },
    {
      "epoch": 619.35,
      "learning_rate": 0.03808909416903226,
      "loss": 0.6534,
      "step": 384000
    },
    {
      "epoch": 619.39,
      "learning_rate": 0.038085868365806456,
      "loss": 0.6571,
      "step": 384020
    },
    {
      "epoch": 619.42,
      "learning_rate": 0.03808264256258065,
      "loss": 0.6484,
      "step": 384040
    },
    {
      "epoch": 619.45,
      "learning_rate": 0.03807941675935484,
      "loss": 0.6458,
      "step": 384060
    },
    {
      "epoch": 619.48,
      "learning_rate": 0.03807619095612904,
      "loss": 0.652,
      "step": 384080
    },
    {
      "epoch": 619.52,
      "learning_rate": 0.03807296515290323,
      "loss": 0.6433,
      "step": 384100
    },
    {
      "epoch": 619.55,
      "learning_rate": 0.038069739349677424,
      "loss": 0.6472,
      "step": 384120
    },
    {
      "epoch": 619.58,
      "learning_rate": 0.03806651354645162,
      "loss": 0.6555,
      "step": 384140
    },
    {
      "epoch": 619.61,
      "learning_rate": 0.038063287743225815,
      "loss": 0.6344,
      "step": 384160
    },
    {
      "epoch": 619.65,
      "learning_rate": 0.03806006194000001,
      "loss": 0.6503,
      "step": 384180
    },
    {
      "epoch": 619.68,
      "learning_rate": 0.03805683613677419,
      "loss": 0.6454,
      "step": 384200
    },
    {
      "epoch": 619.71,
      "learning_rate": 0.038053610333548385,
      "loss": 0.6629,
      "step": 384220
    },
    {
      "epoch": 619.74,
      "learning_rate": 0.03805038453032258,
      "loss": 0.6471,
      "step": 384240
    },
    {
      "epoch": 619.77,
      "learning_rate": 0.038047158727096776,
      "loss": 0.6596,
      "step": 384260
    },
    {
      "epoch": 619.81,
      "learning_rate": 0.03804393292387097,
      "loss": 0.6502,
      "step": 384280
    },
    {
      "epoch": 619.84,
      "learning_rate": 0.03804070712064516,
      "loss": 0.6383,
      "step": 384300
    },
    {
      "epoch": 619.87,
      "learning_rate": 0.03803748131741936,
      "loss": 0.647,
      "step": 384320
    },
    {
      "epoch": 619.9,
      "learning_rate": 0.03803425551419355,
      "loss": 0.6549,
      "step": 384340
    },
    {
      "epoch": 619.94,
      "learning_rate": 0.038031029710967744,
      "loss": 0.6581,
      "step": 384360
    },
    {
      "epoch": 619.97,
      "learning_rate": 0.03802780390774194,
      "loss": 0.6417,
      "step": 384380
    },
    {
      "epoch": 620.0,
      "learning_rate": 0.038024578104516135,
      "loss": 0.6454,
      "step": 384400
    },
    {
      "epoch": 620.0,
      "eval_accuracy": {
        "accuracy": 0.768246038560612
      },
      "eval_loss": 1.0081872940063477,
      "eval_runtime": 4.3665,
      "eval_samples_per_second": 2933.928,
      "eval_steps_per_second": 46.032,
      "step": 384400
    },
    {
      "epoch": 620.03,
      "learning_rate": 0.03802135230129033,
      "loss": 0.6631,
      "step": 384420
    },
    {
      "epoch": 620.06,
      "learning_rate": 0.038018126498064526,
      "loss": 0.6431,
      "step": 384440
    },
    {
      "epoch": 620.1,
      "learning_rate": 0.03801490069483872,
      "loss": 0.635,
      "step": 384460
    },
    {
      "epoch": 620.13,
      "learning_rate": 0.03801167489161291,
      "loss": 0.6564,
      "step": 384480
    },
    {
      "epoch": 620.16,
      "learning_rate": 0.0380084490883871,
      "loss": 0.6435,
      "step": 384500
    },
    {
      "epoch": 620.19,
      "learning_rate": 0.03800522328516129,
      "loss": 0.645,
      "step": 384520
    },
    {
      "epoch": 620.23,
      "learning_rate": 0.03800199748193548,
      "loss": 0.6424,
      "step": 384540
    },
    {
      "epoch": 620.26,
      "learning_rate": 0.03799877167870968,
      "loss": 0.6355,
      "step": 384560
    },
    {
      "epoch": 620.29,
      "learning_rate": 0.03799554587548387,
      "loss": 0.6377,
      "step": 384580
    },
    {
      "epoch": 620.32,
      "learning_rate": 0.037992320072258064,
      "loss": 0.6539,
      "step": 384600
    },
    {
      "epoch": 620.35,
      "learning_rate": 0.03798909426903226,
      "loss": 0.6322,
      "step": 384620
    },
    {
      "epoch": 620.39,
      "learning_rate": 0.037985868465806455,
      "loss": 0.6334,
      "step": 384640
    },
    {
      "epoch": 620.42,
      "learning_rate": 0.03798264266258065,
      "loss": 0.6305,
      "step": 384660
    },
    {
      "epoch": 620.45,
      "learning_rate": 0.037979416859354846,
      "loss": 0.6451,
      "step": 384680
    },
    {
      "epoch": 620.48,
      "learning_rate": 0.03797619105612904,
      "loss": 0.6452,
      "step": 384700
    },
    {
      "epoch": 620.52,
      "learning_rate": 0.03797296525290323,
      "loss": 0.6389,
      "step": 384720
    },
    {
      "epoch": 620.55,
      "learning_rate": 0.03796973944967742,
      "loss": 0.6586,
      "step": 384740
    },
    {
      "epoch": 620.58,
      "learning_rate": 0.03796651364645162,
      "loss": 0.6391,
      "step": 384760
    },
    {
      "epoch": 620.61,
      "learning_rate": 0.037963287843225814,
      "loss": 0.6343,
      "step": 384780
    },
    {
      "epoch": 620.65,
      "learning_rate": 0.037960062040000006,
      "loss": 0.6459,
      "step": 384800
    },
    {
      "epoch": 620.68,
      "learning_rate": 0.03795683623677419,
      "loss": 0.6576,
      "step": 384820
    },
    {
      "epoch": 620.71,
      "learning_rate": 0.03795361043354838,
      "loss": 0.6607,
      "step": 384840
    },
    {
      "epoch": 620.74,
      "learning_rate": 0.03795038463032258,
      "loss": 0.6461,
      "step": 384860
    },
    {
      "epoch": 620.77,
      "learning_rate": 0.037947158827096775,
      "loss": 0.6734,
      "step": 384880
    },
    {
      "epoch": 620.81,
      "learning_rate": 0.03794393302387097,
      "loss": 0.6721,
      "step": 384900
    },
    {
      "epoch": 620.84,
      "learning_rate": 0.037940707220645166,
      "loss": 0.6542,
      "step": 384920
    },
    {
      "epoch": 620.87,
      "learning_rate": 0.03793748141741936,
      "loss": 0.6577,
      "step": 384940
    },
    {
      "epoch": 620.9,
      "learning_rate": 0.03793425561419355,
      "loss": 0.6568,
      "step": 384960
    },
    {
      "epoch": 620.94,
      "learning_rate": 0.03793102981096775,
      "loss": 0.658,
      "step": 384980
    },
    {
      "epoch": 620.97,
      "learning_rate": 0.03792780400774194,
      "loss": 0.6599,
      "step": 385000
    },
    {
      "epoch": 621.0,
      "learning_rate": 0.037924578204516134,
      "loss": 0.6617,
      "step": 385020
    },
    {
      "epoch": 621.0,
      "eval_accuracy": {
        "accuracy": 0.7738662087268754
      },
      "eval_loss": 0.9892111420631409,
      "eval_runtime": 3.7421,
      "eval_samples_per_second": 3423.478,
      "eval_steps_per_second": 53.713,
      "step": 385020
    },
    {
      "epoch": 621.03,
      "learning_rate": 0.037921352401290326,
      "loss": 0.6495,
      "step": 385040
    },
    {
      "epoch": 621.06,
      "learning_rate": 0.037918126598064525,
      "loss": 0.6376,
      "step": 385060
    },
    {
      "epoch": 621.1,
      "learning_rate": 0.03791490079483872,
      "loss": 0.6336,
      "step": 385080
    },
    {
      "epoch": 621.13,
      "learning_rate": 0.03791167499161291,
      "loss": 0.6564,
      "step": 385100
    },
    {
      "epoch": 621.16,
      "learning_rate": 0.03790844918838711,
      "loss": 0.6542,
      "step": 385120
    },
    {
      "epoch": 621.19,
      "learning_rate": 0.03790522338516129,
      "loss": 0.6532,
      "step": 385140
    },
    {
      "epoch": 621.23,
      "learning_rate": 0.037901997581935486,
      "loss": 0.6546,
      "step": 385160
    },
    {
      "epoch": 621.26,
      "learning_rate": 0.03789877177870968,
      "loss": 0.6535,
      "step": 385180
    },
    {
      "epoch": 621.29,
      "learning_rate": 0.03789554597548387,
      "loss": 0.655,
      "step": 385200
    },
    {
      "epoch": 621.32,
      "learning_rate": 0.03789232017225807,
      "loss": 0.6405,
      "step": 385220
    },
    {
      "epoch": 621.35,
      "learning_rate": 0.03788909436903226,
      "loss": 0.6301,
      "step": 385240
    },
    {
      "epoch": 621.39,
      "learning_rate": 0.03788586856580645,
      "loss": 0.6436,
      "step": 385260
    },
    {
      "epoch": 621.42,
      "learning_rate": 0.037882642762580646,
      "loss": 0.6445,
      "step": 385280
    },
    {
      "epoch": 621.45,
      "learning_rate": 0.037879416959354845,
      "loss": 0.6463,
      "step": 385300
    },
    {
      "epoch": 621.48,
      "learning_rate": 0.03787619115612904,
      "loss": 0.6338,
      "step": 385320
    },
    {
      "epoch": 621.52,
      "learning_rate": 0.03787296535290323,
      "loss": 0.6553,
      "step": 385340
    },
    {
      "epoch": 621.55,
      "learning_rate": 0.03786973954967743,
      "loss": 0.6467,
      "step": 385360
    },
    {
      "epoch": 621.58,
      "learning_rate": 0.03786651374645162,
      "loss": 0.6523,
      "step": 385380
    },
    {
      "epoch": 621.61,
      "learning_rate": 0.03786328794322581,
      "loss": 0.6387,
      "step": 385400
    },
    {
      "epoch": 621.65,
      "learning_rate": 0.03786006214000001,
      "loss": 0.6479,
      "step": 385420
    },
    {
      "epoch": 621.68,
      "learning_rate": 0.037856836336774204,
      "loss": 0.6551,
      "step": 385440
    },
    {
      "epoch": 621.71,
      "learning_rate": 0.03785361053354839,
      "loss": 0.6485,
      "step": 385460
    },
    {
      "epoch": 621.74,
      "learning_rate": 0.03785038473032258,
      "loss": 0.6525,
      "step": 385480
    },
    {
      "epoch": 621.77,
      "learning_rate": 0.03784715892709677,
      "loss": 0.6392,
      "step": 385500
    },
    {
      "epoch": 621.81,
      "learning_rate": 0.03784393312387097,
      "loss": 0.6483,
      "step": 385520
    },
    {
      "epoch": 621.84,
      "learning_rate": 0.037840707320645164,
      "loss": 0.6545,
      "step": 385540
    },
    {
      "epoch": 621.87,
      "learning_rate": 0.03783748151741936,
      "loss": 0.6422,
      "step": 385560
    },
    {
      "epoch": 621.9,
      "learning_rate": 0.03783425571419355,
      "loss": 0.6492,
      "step": 385580
    },
    {
      "epoch": 621.94,
      "learning_rate": 0.03783102991096775,
      "loss": 0.6419,
      "step": 385600
    },
    {
      "epoch": 621.97,
      "learning_rate": 0.03782780410774194,
      "loss": 0.6376,
      "step": 385620
    },
    {
      "epoch": 622.0,
      "learning_rate": 0.03782473959467742,
      "loss": 0.6451,
      "step": 385640
    },
    {
      "epoch": 622.0,
      "eval_accuracy": {
        "accuracy": 0.7717586449145266
      },
      "eval_loss": 1.0015321969985962,
      "eval_runtime": 2.9258,
      "eval_samples_per_second": 4378.603,
      "eval_steps_per_second": 68.699,
      "step": 385640
    },
    {
      "epoch": 622.03,
      "learning_rate": 0.037821513791451614,
      "loss": 0.6294,
      "step": 385660
    },
    {
      "epoch": 622.06,
      "learning_rate": 0.037818287988225806,
      "loss": 0.6347,
      "step": 385680
    },
    {
      "epoch": 622.1,
      "learning_rate": 0.037815062185000005,
      "loss": 0.6345,
      "step": 385700
    },
    {
      "epoch": 622.13,
      "learning_rate": 0.0378118363817742,
      "loss": 0.6358,
      "step": 385720
    },
    {
      "epoch": 622.16,
      "learning_rate": 0.03780861057854839,
      "loss": 0.6495,
      "step": 385740
    },
    {
      "epoch": 622.19,
      "learning_rate": 0.03780538477532259,
      "loss": 0.6444,
      "step": 385760
    },
    {
      "epoch": 622.23,
      "learning_rate": 0.03780215897209678,
      "loss": 0.6565,
      "step": 385780
    },
    {
      "epoch": 622.26,
      "learning_rate": 0.03779893316887097,
      "loss": 0.6434,
      "step": 385800
    },
    {
      "epoch": 622.29,
      "learning_rate": 0.037795707365645165,
      "loss": 0.6396,
      "step": 385820
    },
    {
      "epoch": 622.32,
      "learning_rate": 0.037792481562419364,
      "loss": 0.6355,
      "step": 385840
    },
    {
      "epoch": 622.35,
      "learning_rate": 0.037789255759193556,
      "loss": 0.639,
      "step": 385860
    },
    {
      "epoch": 622.39,
      "learning_rate": 0.03778602995596775,
      "loss": 0.6325,
      "step": 385880
    },
    {
      "epoch": 622.42,
      "learning_rate": 0.03778280415274193,
      "loss": 0.6513,
      "step": 385900
    },
    {
      "epoch": 622.45,
      "learning_rate": 0.037779578349516126,
      "loss": 0.6624,
      "step": 385920
    },
    {
      "epoch": 622.48,
      "learning_rate": 0.037776352546290325,
      "loss": 0.6527,
      "step": 385940
    },
    {
      "epoch": 622.52,
      "learning_rate": 0.03777312674306452,
      "loss": 0.6503,
      "step": 385960
    },
    {
      "epoch": 622.55,
      "learning_rate": 0.03776990093983871,
      "loss": 0.6414,
      "step": 385980
    },
    {
      "epoch": 622.58,
      "learning_rate": 0.03776667513661291,
      "loss": 0.6542,
      "step": 386000
    },
    {
      "epoch": 622.61,
      "learning_rate": 0.0377634493333871,
      "loss": 0.6387,
      "step": 386020
    },
    {
      "epoch": 622.65,
      "learning_rate": 0.03776022353016129,
      "loss": 0.6534,
      "step": 386040
    },
    {
      "epoch": 622.68,
      "learning_rate": 0.03775699772693549,
      "loss": 0.6344,
      "step": 386060
    },
    {
      "epoch": 622.71,
      "learning_rate": 0.037753771923709684,
      "loss": 0.6415,
      "step": 386080
    },
    {
      "epoch": 622.74,
      "learning_rate": 0.037750546120483876,
      "loss": 0.6495,
      "step": 386100
    },
    {
      "epoch": 622.77,
      "learning_rate": 0.03774732031725807,
      "loss": 0.6362,
      "step": 386120
    },
    {
      "epoch": 622.81,
      "learning_rate": 0.03774409451403227,
      "loss": 0.6753,
      "step": 386140
    },
    {
      "epoch": 622.84,
      "learning_rate": 0.03774086871080646,
      "loss": 0.6476,
      "step": 386160
    },
    {
      "epoch": 622.87,
      "learning_rate": 0.03773764290758065,
      "loss": 0.6618,
      "step": 386180
    },
    {
      "epoch": 622.9,
      "learning_rate": 0.03773441710435485,
      "loss": 0.6591,
      "step": 386200
    },
    {
      "epoch": 622.94,
      "learning_rate": 0.03773119130112903,
      "loss": 0.6475,
      "step": 386220
    },
    {
      "epoch": 622.97,
      "learning_rate": 0.03772796549790323,
      "loss": 0.6401,
      "step": 386240
    },
    {
      "epoch": 623.0,
      "learning_rate": 0.03772473969467742,
      "loss": 0.6561,
      "step": 386260
    },
    {
      "epoch": 623.0,
      "eval_accuracy": {
        "accuracy": 0.7686363281554913
      },
      "eval_loss": 1.0190353393554688,
      "eval_runtime": 4.0877,
      "eval_samples_per_second": 3134.035,
      "eval_steps_per_second": 49.172,
      "step": 386260
    },
    {
      "epoch": 623.03,
      "learning_rate": 0.03772151389145161,
      "loss": 0.6596,
      "step": 386280
    },
    {
      "epoch": 623.06,
      "learning_rate": 0.03771828808822581,
      "loss": 0.661,
      "step": 386300
    },
    {
      "epoch": 623.1,
      "learning_rate": 0.037715062285,
      "loss": 0.6334,
      "step": 386320
    },
    {
      "epoch": 623.13,
      "learning_rate": 0.037711836481774196,
      "loss": 0.6283,
      "step": 386340
    },
    {
      "epoch": 623.16,
      "learning_rate": 0.03770861067854839,
      "loss": 0.6378,
      "step": 386360
    },
    {
      "epoch": 623.19,
      "learning_rate": 0.03770538487532259,
      "loss": 0.6529,
      "step": 386380
    },
    {
      "epoch": 623.23,
      "learning_rate": 0.03770215907209678,
      "loss": 0.658,
      "step": 386400
    },
    {
      "epoch": 623.26,
      "learning_rate": 0.03769893326887097,
      "loss": 0.6385,
      "step": 386420
    },
    {
      "epoch": 623.29,
      "learning_rate": 0.03769570746564517,
      "loss": 0.6471,
      "step": 386440
    },
    {
      "epoch": 623.32,
      "learning_rate": 0.03769248166241936,
      "loss": 0.6394,
      "step": 386460
    },
    {
      "epoch": 623.35,
      "learning_rate": 0.037689255859193554,
      "loss": 0.6469,
      "step": 386480
    },
    {
      "epoch": 623.39,
      "learning_rate": 0.037686030055967754,
      "loss": 0.6476,
      "step": 386500
    },
    {
      "epoch": 623.42,
      "learning_rate": 0.03768280425274193,
      "loss": 0.6553,
      "step": 386520
    },
    {
      "epoch": 623.45,
      "learning_rate": 0.03767957844951613,
      "loss": 0.6521,
      "step": 386540
    },
    {
      "epoch": 623.48,
      "learning_rate": 0.03767635264629032,
      "loss": 0.6336,
      "step": 386560
    },
    {
      "epoch": 623.52,
      "learning_rate": 0.037673126843064515,
      "loss": 0.6306,
      "step": 386580
    },
    {
      "epoch": 623.55,
      "learning_rate": 0.037669901039838714,
      "loss": 0.6573,
      "step": 386600
    },
    {
      "epoch": 623.58,
      "learning_rate": 0.037666675236612907,
      "loss": 0.6464,
      "step": 386620
    },
    {
      "epoch": 623.61,
      "learning_rate": 0.0376634494333871,
      "loss": 0.6555,
      "step": 386640
    },
    {
      "epoch": 623.65,
      "learning_rate": 0.03766022363016129,
      "loss": 0.6478,
      "step": 386660
    },
    {
      "epoch": 623.68,
      "learning_rate": 0.03765699782693549,
      "loss": 0.6476,
      "step": 386680
    },
    {
      "epoch": 623.71,
      "learning_rate": 0.03765377202370968,
      "loss": 0.6554,
      "step": 386700
    },
    {
      "epoch": 623.74,
      "learning_rate": 0.037650546220483874,
      "loss": 0.6608,
      "step": 386720
    },
    {
      "epoch": 623.77,
      "learning_rate": 0.03764732041725807,
      "loss": 0.6509,
      "step": 386740
    },
    {
      "epoch": 623.81,
      "learning_rate": 0.037644094614032265,
      "loss": 0.6516,
      "step": 386760
    },
    {
      "epoch": 623.84,
      "learning_rate": 0.03764086881080646,
      "loss": 0.6511,
      "step": 386780
    },
    {
      "epoch": 623.87,
      "learning_rate": 0.03763764300758066,
      "loss": 0.6429,
      "step": 386800
    },
    {
      "epoch": 623.9,
      "learning_rate": 0.03763441720435485,
      "loss": 0.6584,
      "step": 386820
    },
    {
      "epoch": 623.94,
      "learning_rate": 0.037631191401129034,
      "loss": 0.6696,
      "step": 386840
    },
    {
      "epoch": 623.97,
      "learning_rate": 0.037627965597903226,
      "loss": 0.6508,
      "step": 386860
    },
    {
      "epoch": 624.0,
      "learning_rate": 0.03762473979467742,
      "loss": 0.6516,
      "step": 386880
    },
    {
      "epoch": 624.0,
      "eval_accuracy": {
        "accuracy": 0.7687143860744673
      },
      "eval_loss": 1.026253342628479,
      "eval_runtime": 2.916,
      "eval_samples_per_second": 4393.335,
      "eval_steps_per_second": 68.93,
      "step": 386880
    },
    {
      "epoch": 624.03,
      "learning_rate": 0.03762151399145161,
      "loss": 0.6661,
      "step": 386900
    },
    {
      "epoch": 624.06,
      "learning_rate": 0.03761828818822581,
      "loss": 0.642,
      "step": 386920
    },
    {
      "epoch": 624.1,
      "learning_rate": 0.037615062385,
      "loss": 0.6409,
      "step": 386940
    },
    {
      "epoch": 624.13,
      "learning_rate": 0.037611836581774194,
      "loss": 0.6202,
      "step": 386960
    },
    {
      "epoch": 624.16,
      "learning_rate": 0.03760861077854839,
      "loss": 0.6333,
      "step": 386980
    },
    {
      "epoch": 624.19,
      "learning_rate": 0.037605384975322585,
      "loss": 0.6312,
      "step": 387000
    },
    {
      "epoch": 624.23,
      "learning_rate": 0.03760215917209678,
      "loss": 0.6295,
      "step": 387020
    },
    {
      "epoch": 624.26,
      "learning_rate": 0.037598933368870976,
      "loss": 0.6489,
      "step": 387040
    },
    {
      "epoch": 624.29,
      "learning_rate": 0.03759570756564517,
      "loss": 0.6466,
      "step": 387060
    },
    {
      "epoch": 624.32,
      "learning_rate": 0.03759248176241936,
      "loss": 0.6377,
      "step": 387080
    },
    {
      "epoch": 624.35,
      "learning_rate": 0.03758925595919355,
      "loss": 0.63,
      "step": 387100
    },
    {
      "epoch": 624.39,
      "learning_rate": 0.03758603015596775,
      "loss": 0.6396,
      "step": 387120
    },
    {
      "epoch": 624.42,
      "learning_rate": 0.03758280435274194,
      "loss": 0.6379,
      "step": 387140
    },
    {
      "epoch": 624.45,
      "learning_rate": 0.03757957854951613,
      "loss": 0.6518,
      "step": 387160
    },
    {
      "epoch": 624.48,
      "learning_rate": 0.03757635274629032,
      "loss": 0.6419,
      "step": 387180
    },
    {
      "epoch": 624.52,
      "learning_rate": 0.037573126943064514,
      "loss": 0.6453,
      "step": 387200
    },
    {
      "epoch": 624.55,
      "learning_rate": 0.03756990113983871,
      "loss": 0.6439,
      "step": 387220
    },
    {
      "epoch": 624.58,
      "learning_rate": 0.037566675336612905,
      "loss": 0.6402,
      "step": 387240
    },
    {
      "epoch": 624.61,
      "learning_rate": 0.0375634495333871,
      "loss": 0.6446,
      "step": 387260
    },
    {
      "epoch": 624.65,
      "learning_rate": 0.037560223730161296,
      "loss": 0.6385,
      "step": 387280
    },
    {
      "epoch": 624.68,
      "learning_rate": 0.03755699792693549,
      "loss": 0.6288,
      "step": 387300
    },
    {
      "epoch": 624.71,
      "learning_rate": 0.03755377212370968,
      "loss": 0.6497,
      "step": 387320
    },
    {
      "epoch": 624.74,
      "learning_rate": 0.03755054632048388,
      "loss": 0.6462,
      "step": 387340
    },
    {
      "epoch": 624.77,
      "learning_rate": 0.03754732051725807,
      "loss": 0.6496,
      "step": 387360
    },
    {
      "epoch": 624.81,
      "learning_rate": 0.037544094714032264,
      "loss": 0.6409,
      "step": 387380
    },
    {
      "epoch": 624.84,
      "learning_rate": 0.037540868910806456,
      "loss": 0.6545,
      "step": 387400
    },
    {
      "epoch": 624.87,
      "learning_rate": 0.037537643107580655,
      "loss": 0.6628,
      "step": 387420
    },
    {
      "epoch": 624.9,
      "learning_rate": 0.03753441730435485,
      "loss": 0.6507,
      "step": 387440
    },
    {
      "epoch": 624.94,
      "learning_rate": 0.03753119150112903,
      "loss": 0.6349,
      "step": 387460
    },
    {
      "epoch": 624.97,
      "learning_rate": 0.037527965697903225,
      "loss": 0.6595,
      "step": 387480
    },
    {
      "epoch": 625.0,
      "learning_rate": 0.03752473989467742,
      "loss": 0.643,
      "step": 387500
    },
    {
      "epoch": 625.0,
      "eval_accuracy": {
        "accuracy": 0.7625478104753727
      },
      "eval_loss": 1.0293926000595093,
      "eval_runtime": 2.9451,
      "eval_samples_per_second": 4349.923,
      "eval_steps_per_second": 68.249,
      "step": 387500
    },
    {
      "epoch": 625.03,
      "learning_rate": 0.037521514091451616,
      "loss": 0.6733,
      "step": 387520
    },
    {
      "epoch": 625.06,
      "learning_rate": 0.03751828828822581,
      "loss": 0.6418,
      "step": 387540
    },
    {
      "epoch": 625.1,
      "learning_rate": 0.037515062485,
      "loss": 0.6472,
      "step": 387560
    },
    {
      "epoch": 625.13,
      "learning_rate": 0.0375118366817742,
      "loss": 0.6391,
      "step": 387580
    },
    {
      "epoch": 625.16,
      "learning_rate": 0.03750861087854839,
      "loss": 0.6305,
      "step": 387600
    },
    {
      "epoch": 625.19,
      "learning_rate": 0.037505385075322584,
      "loss": 0.6314,
      "step": 387620
    },
    {
      "epoch": 625.23,
      "learning_rate": 0.037502159272096776,
      "loss": 0.6294,
      "step": 387640
    },
    {
      "epoch": 625.26,
      "learning_rate": 0.037498933468870975,
      "loss": 0.6467,
      "step": 387660
    },
    {
      "epoch": 625.29,
      "learning_rate": 0.03749570766564517,
      "loss": 0.6368,
      "step": 387680
    },
    {
      "epoch": 625.32,
      "learning_rate": 0.03749248186241936,
      "loss": 0.6353,
      "step": 387700
    },
    {
      "epoch": 625.35,
      "learning_rate": 0.03748925605919356,
      "loss": 0.634,
      "step": 387720
    },
    {
      "epoch": 625.39,
      "learning_rate": 0.03748603025596775,
      "loss": 0.6453,
      "step": 387740
    },
    {
      "epoch": 625.42,
      "learning_rate": 0.03748280445274194,
      "loss": 0.6431,
      "step": 387760
    },
    {
      "epoch": 625.45,
      "learning_rate": 0.03747957864951613,
      "loss": 0.6689,
      "step": 387780
    },
    {
      "epoch": 625.48,
      "learning_rate": 0.03747635284629032,
      "loss": 0.6682,
      "step": 387800
    },
    {
      "epoch": 625.52,
      "learning_rate": 0.03747312704306452,
      "loss": 0.6359,
      "step": 387820
    },
    {
      "epoch": 625.55,
      "learning_rate": 0.03746990123983871,
      "loss": 0.6503,
      "step": 387840
    },
    {
      "epoch": 625.58,
      "learning_rate": 0.0374666754366129,
      "loss": 0.6613,
      "step": 387860
    },
    {
      "epoch": 625.61,
      "learning_rate": 0.0374634496333871,
      "loss": 0.6584,
      "step": 387880
    },
    {
      "epoch": 625.65,
      "learning_rate": 0.037460223830161295,
      "loss": 0.6341,
      "step": 387900
    },
    {
      "epoch": 625.68,
      "learning_rate": 0.03745699802693549,
      "loss": 0.6448,
      "step": 387920
    },
    {
      "epoch": 625.71,
      "learning_rate": 0.03745377222370968,
      "loss": 0.6455,
      "step": 387940
    },
    {
      "epoch": 625.74,
      "learning_rate": 0.03745054642048388,
      "loss": 0.65,
      "step": 387960
    },
    {
      "epoch": 625.77,
      "learning_rate": 0.03744732061725807,
      "loss": 0.6399,
      "step": 387980
    },
    {
      "epoch": 625.81,
      "learning_rate": 0.03744409481403226,
      "loss": 0.6514,
      "step": 388000
    },
    {
      "epoch": 625.84,
      "learning_rate": 0.03744086901080646,
      "loss": 0.6389,
      "step": 388020
    },
    {
      "epoch": 625.87,
      "learning_rate": 0.037437643207580654,
      "loss": 0.6394,
      "step": 388040
    },
    {
      "epoch": 625.9,
      "learning_rate": 0.037434417404354846,
      "loss": 0.6564,
      "step": 388060
    },
    {
      "epoch": 625.94,
      "learning_rate": 0.03743119160112903,
      "loss": 0.6643,
      "step": 388080
    },
    {
      "epoch": 625.97,
      "learning_rate": 0.03742796579790322,
      "loss": 0.6578,
      "step": 388100
    },
    {
      "epoch": 626.0,
      "learning_rate": 0.03742473999467742,
      "loss": 0.6435,
      "step": 388120
    },
    {
      "epoch": 626.0,
      "eval_accuracy": {
        "accuracy": 0.7626258683943486
      },
      "eval_loss": 1.0260051488876343,
      "eval_runtime": 2.9287,
      "eval_samples_per_second": 4374.305,
      "eval_steps_per_second": 68.631,
      "step": 388120
    },
    {
      "epoch": 626.03,
      "learning_rate": 0.037421514191451614,
      "loss": 0.658,
      "step": 388140
    },
    {
      "epoch": 626.06,
      "learning_rate": 0.03741828838822581,
      "loss": 0.6524,
      "step": 388160
    },
    {
      "epoch": 626.1,
      "learning_rate": 0.037415062585,
      "loss": 0.6353,
      "step": 388180
    },
    {
      "epoch": 626.13,
      "learning_rate": 0.0374118367817742,
      "loss": 0.6441,
      "step": 388200
    },
    {
      "epoch": 626.16,
      "learning_rate": 0.03740861097854839,
      "loss": 0.6317,
      "step": 388220
    },
    {
      "epoch": 626.19,
      "learning_rate": 0.03740538517532258,
      "loss": 0.6429,
      "step": 388240
    },
    {
      "epoch": 626.23,
      "learning_rate": 0.03740215937209678,
      "loss": 0.6368,
      "step": 388260
    },
    {
      "epoch": 626.26,
      "learning_rate": 0.03739893356887097,
      "loss": 0.6267,
      "step": 388280
    },
    {
      "epoch": 626.29,
      "learning_rate": 0.037395707765645166,
      "loss": 0.6367,
      "step": 388300
    },
    {
      "epoch": 626.32,
      "learning_rate": 0.037392481962419365,
      "loss": 0.6422,
      "step": 388320
    },
    {
      "epoch": 626.35,
      "learning_rate": 0.03738925615919356,
      "loss": 0.6502,
      "step": 388340
    },
    {
      "epoch": 626.39,
      "learning_rate": 0.03738603035596775,
      "loss": 0.6418,
      "step": 388360
    },
    {
      "epoch": 626.42,
      "learning_rate": 0.03738280455274195,
      "loss": 0.655,
      "step": 388380
    },
    {
      "epoch": 626.45,
      "learning_rate": 0.037379578749516126,
      "loss": 0.6499,
      "step": 388400
    },
    {
      "epoch": 626.48,
      "learning_rate": 0.037376352946290325,
      "loss": 0.6365,
      "step": 388420
    },
    {
      "epoch": 626.52,
      "learning_rate": 0.03737312714306452,
      "loss": 0.6471,
      "step": 388440
    },
    {
      "epoch": 626.55,
      "learning_rate": 0.03736990133983871,
      "loss": 0.6487,
      "step": 388460
    },
    {
      "epoch": 626.58,
      "learning_rate": 0.0373666755366129,
      "loss": 0.639,
      "step": 388480
    },
    {
      "epoch": 626.61,
      "learning_rate": 0.0373634497333871,
      "loss": 0.6443,
      "step": 388500
    },
    {
      "epoch": 626.65,
      "learning_rate": 0.03736022393016129,
      "loss": 0.6419,
      "step": 388520
    },
    {
      "epoch": 626.68,
      "learning_rate": 0.037356998126935485,
      "loss": 0.6346,
      "step": 388540
    },
    {
      "epoch": 626.71,
      "learning_rate": 0.037353772323709684,
      "loss": 0.6489,
      "step": 388560
    },
    {
      "epoch": 626.74,
      "learning_rate": 0.03735054652048388,
      "loss": 0.6482,
      "step": 388580
    },
    {
      "epoch": 626.77,
      "learning_rate": 0.03734732071725807,
      "loss": 0.6405,
      "step": 388600
    },
    {
      "epoch": 626.81,
      "learning_rate": 0.03734409491403227,
      "loss": 0.6401,
      "step": 388620
    },
    {
      "epoch": 626.84,
      "learning_rate": 0.03734086911080646,
      "loss": 0.6508,
      "step": 388640
    },
    {
      "epoch": 626.87,
      "learning_rate": 0.03733764330758065,
      "loss": 0.639,
      "step": 388660
    },
    {
      "epoch": 626.9,
      "learning_rate": 0.037334417504354844,
      "loss": 0.6447,
      "step": 388680
    },
    {
      "epoch": 626.94,
      "learning_rate": 0.03733119170112903,
      "loss": 0.645,
      "step": 388700
    },
    {
      "epoch": 626.97,
      "learning_rate": 0.03732796589790322,
      "loss": 0.6448,
      "step": 388720
    },
    {
      "epoch": 627.0,
      "learning_rate": 0.03732490138483872,
      "loss": 0.6439,
      "step": 388740
    },
    {
      "epoch": 627.0,
      "eval_accuracy": {
        "accuracy": 0.7684802123175396
      },
      "eval_loss": 1.0054118633270264,
      "eval_runtime": 3.4752,
      "eval_samples_per_second": 3686.413,
      "eval_steps_per_second": 57.838,
      "step": 388740
    },
    {
      "epoch": 627.03,
      "learning_rate": 0.03732167558161291,
      "loss": 0.6352,
      "step": 388760
    },
    {
      "epoch": 627.06,
      "learning_rate": 0.0373184497783871,
      "loss": 0.6216,
      "step": 388780
    },
    {
      "epoch": 627.1,
      "learning_rate": 0.0373152239751613,
      "loss": 0.6325,
      "step": 388800
    },
    {
      "epoch": 627.13,
      "learning_rate": 0.03731199817193549,
      "loss": 0.6373,
      "step": 388820
    },
    {
      "epoch": 627.16,
      "learning_rate": 0.03730877236870968,
      "loss": 0.642,
      "step": 388840
    },
    {
      "epoch": 627.19,
      "learning_rate": 0.03730554656548387,
      "loss": 0.6436,
      "step": 388860
    },
    {
      "epoch": 627.23,
      "learning_rate": 0.03730232076225806,
      "loss": 0.6241,
      "step": 388880
    },
    {
      "epoch": 627.26,
      "learning_rate": 0.03729909495903226,
      "loss": 0.6348,
      "step": 388900
    },
    {
      "epoch": 627.29,
      "learning_rate": 0.03729586915580645,
      "loss": 0.6409,
      "step": 388920
    },
    {
      "epoch": 627.32,
      "learning_rate": 0.037292643352580646,
      "loss": 0.6458,
      "step": 388940
    },
    {
      "epoch": 627.35,
      "learning_rate": 0.037289417549354845,
      "loss": 0.6391,
      "step": 388960
    },
    {
      "epoch": 627.39,
      "learning_rate": 0.03728619174612904,
      "loss": 0.634,
      "step": 388980
    },
    {
      "epoch": 627.42,
      "learning_rate": 0.03728296594290323,
      "loss": 0.6343,
      "step": 389000
    },
    {
      "epoch": 627.45,
      "learning_rate": 0.03727974013967742,
      "loss": 0.6378,
      "step": 389020
    },
    {
      "epoch": 627.48,
      "learning_rate": 0.03727651433645162,
      "loss": 0.6385,
      "step": 389040
    },
    {
      "epoch": 627.52,
      "learning_rate": 0.03727328853322581,
      "loss": 0.6513,
      "step": 389060
    },
    {
      "epoch": 627.55,
      "learning_rate": 0.037270062730000005,
      "loss": 0.6554,
      "step": 389080
    },
    {
      "epoch": 627.58,
      "learning_rate": 0.037266836926774204,
      "loss": 0.6411,
      "step": 389100
    },
    {
      "epoch": 627.61,
      "learning_rate": 0.037263611123548396,
      "loss": 0.6473,
      "step": 389120
    },
    {
      "epoch": 627.65,
      "learning_rate": 0.03726038532032259,
      "loss": 0.6526,
      "step": 389140
    },
    {
      "epoch": 627.68,
      "learning_rate": 0.03725715951709677,
      "loss": 0.6523,
      "step": 389160
    },
    {
      "epoch": 627.71,
      "learning_rate": 0.037253933713870965,
      "loss": 0.651,
      "step": 389180
    },
    {
      "epoch": 627.74,
      "learning_rate": 0.037250707910645164,
      "loss": 0.6597,
      "step": 389200
    },
    {
      "epoch": 627.77,
      "learning_rate": 0.03724748210741936,
      "loss": 0.6501,
      "step": 389220
    },
    {
      "epoch": 627.81,
      "learning_rate": 0.03724425630419355,
      "loss": 0.6454,
      "step": 389240
    },
    {
      "epoch": 627.84,
      "learning_rate": 0.03724103050096774,
      "loss": 0.6533,
      "step": 389260
    },
    {
      "epoch": 627.87,
      "learning_rate": 0.03723780469774194,
      "loss": 0.6445,
      "step": 389280
    },
    {
      "epoch": 627.9,
      "learning_rate": 0.03723457889451613,
      "loss": 0.6374,
      "step": 389300
    },
    {
      "epoch": 627.94,
      "learning_rate": 0.037231353091290324,
      "loss": 0.647,
      "step": 389320
    },
    {
      "epoch": 627.97,
      "learning_rate": 0.03722812728806452,
      "loss": 0.6753,
      "step": 389340
    },
    {
      "epoch": 628.0,
      "learning_rate": 0.037224901484838716,
      "loss": 0.6515,
      "step": 389360
    },
    {
      "epoch": 628.0,
      "eval_accuracy": {
        "accuracy": 0.7704316602919367
      },
      "eval_loss": 1.014351725578308,
      "eval_runtime": 2.9501,
      "eval_samples_per_second": 4342.566,
      "eval_steps_per_second": 68.133,
      "step": 389360
    },
    {
      "epoch": 628.03,
      "learning_rate": 0.03722167568161291,
      "loss": 0.6587,
      "step": 389380
    },
    {
      "epoch": 628.06,
      "learning_rate": 0.03721844987838711,
      "loss": 0.6404,
      "step": 389400
    },
    {
      "epoch": 628.1,
      "learning_rate": 0.0372152240751613,
      "loss": 0.6349,
      "step": 389420
    },
    {
      "epoch": 628.13,
      "learning_rate": 0.03721199827193549,
      "loss": 0.6281,
      "step": 389440
    },
    {
      "epoch": 628.16,
      "learning_rate": 0.037208772468709676,
      "loss": 0.6353,
      "step": 389460
    },
    {
      "epoch": 628.19,
      "learning_rate": 0.03720554666548387,
      "loss": 0.6337,
      "step": 389480
    },
    {
      "epoch": 628.23,
      "learning_rate": 0.03720232086225807,
      "loss": 0.6376,
      "step": 389500
    },
    {
      "epoch": 628.26,
      "learning_rate": 0.03719909505903226,
      "loss": 0.6383,
      "step": 389520
    },
    {
      "epoch": 628.29,
      "learning_rate": 0.03719586925580645,
      "loss": 0.639,
      "step": 389540
    },
    {
      "epoch": 628.32,
      "learning_rate": 0.037192643452580644,
      "loss": 0.6306,
      "step": 389560
    },
    {
      "epoch": 628.35,
      "learning_rate": 0.03718941764935484,
      "loss": 0.6226,
      "step": 389580
    },
    {
      "epoch": 628.39,
      "learning_rate": 0.037186191846129035,
      "loss": 0.6541,
      "step": 389600
    },
    {
      "epoch": 628.42,
      "learning_rate": 0.03718296604290323,
      "loss": 0.651,
      "step": 389620
    },
    {
      "epoch": 628.45,
      "learning_rate": 0.037179740239677427,
      "loss": 0.6341,
      "step": 389640
    },
    {
      "epoch": 628.48,
      "learning_rate": 0.03717651443645162,
      "loss": 0.6423,
      "step": 389660
    },
    {
      "epoch": 628.52,
      "learning_rate": 0.03717328863322581,
      "loss": 0.6496,
      "step": 389680
    },
    {
      "epoch": 628.55,
      "learning_rate": 0.03717006283000001,
      "loss": 0.6494,
      "step": 389700
    },
    {
      "epoch": 628.58,
      "learning_rate": 0.0371668370267742,
      "loss": 0.6494,
      "step": 389720
    },
    {
      "epoch": 628.61,
      "learning_rate": 0.037163611223548394,
      "loss": 0.6371,
      "step": 389740
    },
    {
      "epoch": 628.65,
      "learning_rate": 0.037160385420322586,
      "loss": 0.6379,
      "step": 389760
    },
    {
      "epoch": 628.68,
      "learning_rate": 0.03715715961709677,
      "loss": 0.6438,
      "step": 389780
    },
    {
      "epoch": 628.71,
      "learning_rate": 0.037153933813870964,
      "loss": 0.6401,
      "step": 389800
    },
    {
      "epoch": 628.74,
      "learning_rate": 0.03715070801064516,
      "loss": 0.6511,
      "step": 389820
    },
    {
      "epoch": 628.77,
      "learning_rate": 0.037147482207419355,
      "loss": 0.6463,
      "step": 389840
    },
    {
      "epoch": 628.81,
      "learning_rate": 0.03714425640419355,
      "loss": 0.6432,
      "step": 389860
    },
    {
      "epoch": 628.84,
      "learning_rate": 0.037141030600967746,
      "loss": 0.6376,
      "step": 389880
    },
    {
      "epoch": 628.87,
      "learning_rate": 0.03713780479774194,
      "loss": 0.6588,
      "step": 389900
    },
    {
      "epoch": 628.9,
      "learning_rate": 0.03713457899451613,
      "loss": 0.6474,
      "step": 389920
    },
    {
      "epoch": 628.94,
      "learning_rate": 0.03713135319129033,
      "loss": 0.6428,
      "step": 389940
    },
    {
      "epoch": 628.97,
      "learning_rate": 0.03712812738806452,
      "loss": 0.6427,
      "step": 389960
    },
    {
      "epoch": 629.0,
      "learning_rate": 0.037124901584838714,
      "loss": 0.6541,
      "step": 389980
    },
    {
      "epoch": 629.0,
      "eval_accuracy": {
        "accuracy": 0.7712902974006713
      },
      "eval_loss": 1.0101240873336792,
      "eval_runtime": 2.9595,
      "eval_samples_per_second": 4328.771,
      "eval_steps_per_second": 67.917,
      "step": 389980
    },
    {
      "epoch": 629.03,
      "learning_rate": 0.03712167578161291,
      "loss": 0.6423,
      "step": 390000
    },
    {
      "epoch": 629.06,
      "learning_rate": 0.037118449978387105,
      "loss": 0.645,
      "step": 390020
    },
    {
      "epoch": 629.1,
      "learning_rate": 0.0371152241751613,
      "loss": 0.6537,
      "step": 390040
    },
    {
      "epoch": 629.13,
      "learning_rate": 0.03711199837193549,
      "loss": 0.6317,
      "step": 390060
    },
    {
      "epoch": 629.16,
      "learning_rate": 0.03710877256870969,
      "loss": 0.6516,
      "step": 390080
    },
    {
      "epoch": 629.19,
      "learning_rate": 0.03710554676548387,
      "loss": 0.638,
      "step": 390100
    },
    {
      "epoch": 629.23,
      "learning_rate": 0.037102320962258066,
      "loss": 0.6369,
      "step": 390120
    },
    {
      "epoch": 629.26,
      "learning_rate": 0.03709909515903226,
      "loss": 0.639,
      "step": 390140
    },
    {
      "epoch": 629.29,
      "learning_rate": 0.03709586935580645,
      "loss": 0.6454,
      "step": 390160
    },
    {
      "epoch": 629.32,
      "learning_rate": 0.03709264355258065,
      "loss": 0.6374,
      "step": 390180
    },
    {
      "epoch": 629.35,
      "learning_rate": 0.03708941774935484,
      "loss": 0.654,
      "step": 390200
    },
    {
      "epoch": 629.39,
      "learning_rate": 0.037086191946129034,
      "loss": 0.6323,
      "step": 390220
    },
    {
      "epoch": 629.42,
      "learning_rate": 0.03708296614290323,
      "loss": 0.6452,
      "step": 390240
    },
    {
      "epoch": 629.45,
      "learning_rate": 0.037079740339677425,
      "loss": 0.6246,
      "step": 390260
    },
    {
      "epoch": 629.48,
      "learning_rate": 0.03707651453645162,
      "loss": 0.6458,
      "step": 390280
    },
    {
      "epoch": 629.52,
      "learning_rate": 0.03707328873322581,
      "loss": 0.639,
      "step": 390300
    },
    {
      "epoch": 629.55,
      "learning_rate": 0.03707006293000001,
      "loss": 0.6239,
      "step": 390320
    },
    {
      "epoch": 629.58,
      "learning_rate": 0.0370668371267742,
      "loss": 0.6383,
      "step": 390340
    },
    {
      "epoch": 629.61,
      "learning_rate": 0.03706361132354839,
      "loss": 0.6447,
      "step": 390360
    },
    {
      "epoch": 629.65,
      "learning_rate": 0.03706038552032259,
      "loss": 0.6225,
      "step": 390380
    },
    {
      "epoch": 629.68,
      "learning_rate": 0.03705715971709677,
      "loss": 0.6377,
      "step": 390400
    },
    {
      "epoch": 629.71,
      "learning_rate": 0.03705393391387097,
      "loss": 0.6617,
      "step": 390420
    },
    {
      "epoch": 629.74,
      "learning_rate": 0.03705070811064516,
      "loss": 0.6418,
      "step": 390440
    },
    {
      "epoch": 629.77,
      "learning_rate": 0.037047482307419353,
      "loss": 0.6565,
      "step": 390460
    },
    {
      "epoch": 629.81,
      "learning_rate": 0.03704425650419355,
      "loss": 0.6357,
      "step": 390480
    },
    {
      "epoch": 629.84,
      "learning_rate": 0.037041030700967745,
      "loss": 0.6372,
      "step": 390500
    },
    {
      "epoch": 629.87,
      "learning_rate": 0.03703780489774194,
      "loss": 0.6472,
      "step": 390520
    },
    {
      "epoch": 629.9,
      "learning_rate": 0.037034579094516136,
      "loss": 0.6411,
      "step": 390540
    },
    {
      "epoch": 629.94,
      "learning_rate": 0.03703135329129033,
      "loss": 0.6588,
      "step": 390560
    },
    {
      "epoch": 629.97,
      "learning_rate": 0.03702812748806452,
      "loss": 0.6555,
      "step": 390580
    },
    {
      "epoch": 630.0,
      "learning_rate": 0.03702490168483871,
      "loss": 0.6605,
      "step": 390600
    },
    {
      "epoch": 630.0,
      "eval_accuracy": {
        "accuracy": 0.7647334322066973
      },
      "eval_loss": 1.029402732849121,
      "eval_runtime": 3.0127,
      "eval_samples_per_second": 4252.366,
      "eval_steps_per_second": 66.718,
      "step": 390600
    },
    {
      "epoch": 630.03,
      "learning_rate": 0.03702167588161291,
      "loss": 0.6449,
      "step": 390620
    },
    {
      "epoch": 630.06,
      "learning_rate": 0.037018450078387104,
      "loss": 0.6313,
      "step": 390640
    },
    {
      "epoch": 630.1,
      "learning_rate": 0.037015224275161296,
      "loss": 0.6284,
      "step": 390660
    },
    {
      "epoch": 630.13,
      "learning_rate": 0.037011998471935495,
      "loss": 0.6569,
      "step": 390680
    },
    {
      "epoch": 630.16,
      "learning_rate": 0.03700877266870969,
      "loss": 0.6261,
      "step": 390700
    },
    {
      "epoch": 630.19,
      "learning_rate": 0.03700554686548387,
      "loss": 0.6392,
      "step": 390720
    },
    {
      "epoch": 630.23,
      "learning_rate": 0.037002321062258064,
      "loss": 0.6404,
      "step": 390740
    },
    {
      "epoch": 630.26,
      "learning_rate": 0.03699909525903226,
      "loss": 0.6398,
      "step": 390760
    },
    {
      "epoch": 630.29,
      "learning_rate": 0.036995869455806456,
      "loss": 0.65,
      "step": 390780
    },
    {
      "epoch": 630.32,
      "learning_rate": 0.03699264365258065,
      "loss": 0.6502,
      "step": 390800
    },
    {
      "epoch": 630.35,
      "learning_rate": 0.03698941784935484,
      "loss": 0.6414,
      "step": 390820
    },
    {
      "epoch": 630.39,
      "learning_rate": 0.03698619204612903,
      "loss": 0.6489,
      "step": 390840
    },
    {
      "epoch": 630.42,
      "learning_rate": 0.03698296624290323,
      "loss": 0.6486,
      "step": 390860
    },
    {
      "epoch": 630.45,
      "learning_rate": 0.03697974043967742,
      "loss": 0.6456,
      "step": 390880
    },
    {
      "epoch": 630.48,
      "learning_rate": 0.036976514636451616,
      "loss": 0.6576,
      "step": 390900
    },
    {
      "epoch": 630.52,
      "learning_rate": 0.036973288833225815,
      "loss": 0.6468,
      "step": 390920
    },
    {
      "epoch": 630.55,
      "learning_rate": 0.03697006303000001,
      "loss": 0.632,
      "step": 390940
    },
    {
      "epoch": 630.58,
      "learning_rate": 0.0369668372267742,
      "loss": 0.6434,
      "step": 390960
    },
    {
      "epoch": 630.61,
      "learning_rate": 0.0369636114235484,
      "loss": 0.6195,
      "step": 390980
    },
    {
      "epoch": 630.65,
      "learning_rate": 0.03696038562032259,
      "loss": 0.6257,
      "step": 391000
    },
    {
      "epoch": 630.68,
      "learning_rate": 0.036957159817096776,
      "loss": 0.6426,
      "step": 391020
    },
    {
      "epoch": 630.71,
      "learning_rate": 0.03695393401387097,
      "loss": 0.6476,
      "step": 391040
    },
    {
      "epoch": 630.74,
      "learning_rate": 0.03695070821064516,
      "loss": 0.6576,
      "step": 391060
    },
    {
      "epoch": 630.77,
      "learning_rate": 0.03694748240741936,
      "loss": 0.6339,
      "step": 391080
    },
    {
      "epoch": 630.81,
      "learning_rate": 0.03694425660419355,
      "loss": 0.6494,
      "step": 391100
    },
    {
      "epoch": 630.84,
      "learning_rate": 0.03694103080096774,
      "loss": 0.6611,
      "step": 391120
    },
    {
      "epoch": 630.87,
      "learning_rate": 0.036937804997741935,
      "loss": 0.6462,
      "step": 391140
    },
    {
      "epoch": 630.9,
      "learning_rate": 0.036934579194516134,
      "loss": 0.6628,
      "step": 391160
    },
    {
      "epoch": 630.94,
      "learning_rate": 0.03693135339129033,
      "loss": 0.6353,
      "step": 391180
    },
    {
      "epoch": 630.97,
      "learning_rate": 0.03692812758806452,
      "loss": 0.6449,
      "step": 391200
    },
    {
      "epoch": 631.0,
      "learning_rate": 0.036925063075,
      "loss": 0.6512,
      "step": 391220
    },
    {
      "epoch": 631.0,
      "eval_accuracy": {
        "accuracy": 0.7753493091874171
      },
      "eval_loss": 0.9831874966621399,
      "eval_runtime": 2.8982,
      "eval_samples_per_second": 4420.327,
      "eval_steps_per_second": 69.353,
      "step": 391220
    },
    {
      "epoch": 631.03,
      "learning_rate": 0.03692183727177419,
      "loss": 0.6336,
      "step": 391240
    },
    {
      "epoch": 631.06,
      "learning_rate": 0.03691861146854839,
      "loss": 0.6366,
      "step": 391260
    },
    {
      "epoch": 631.1,
      "learning_rate": 0.036915385665322584,
      "loss": 0.6372,
      "step": 391280
    },
    {
      "epoch": 631.13,
      "learning_rate": 0.036912159862096776,
      "loss": 0.6503,
      "step": 391300
    },
    {
      "epoch": 631.16,
      "learning_rate": 0.036908934058870975,
      "loss": 0.6391,
      "step": 391320
    },
    {
      "epoch": 631.19,
      "learning_rate": 0.03690570825564517,
      "loss": 0.6422,
      "step": 391340
    },
    {
      "epoch": 631.23,
      "learning_rate": 0.03690248245241936,
      "loss": 0.6528,
      "step": 391360
    },
    {
      "epoch": 631.26,
      "learning_rate": 0.03689925664919355,
      "loss": 0.6378,
      "step": 391380
    },
    {
      "epoch": 631.29,
      "learning_rate": 0.03689603084596775,
      "loss": 0.6173,
      "step": 391400
    },
    {
      "epoch": 631.32,
      "learning_rate": 0.03689280504274194,
      "loss": 0.6267,
      "step": 391420
    },
    {
      "epoch": 631.35,
      "learning_rate": 0.036889579239516135,
      "loss": 0.624,
      "step": 391440
    },
    {
      "epoch": 631.39,
      "learning_rate": 0.036886353436290334,
      "loss": 0.6412,
      "step": 391460
    },
    {
      "epoch": 631.42,
      "learning_rate": 0.03688312763306451,
      "loss": 0.657,
      "step": 391480
    },
    {
      "epoch": 631.45,
      "learning_rate": 0.03687990182983871,
      "loss": 0.6543,
      "step": 391500
    },
    {
      "epoch": 631.48,
      "learning_rate": 0.0368766760266129,
      "loss": 0.647,
      "step": 391520
    },
    {
      "epoch": 631.52,
      "learning_rate": 0.036873450223387096,
      "loss": 0.6265,
      "step": 391540
    },
    {
      "epoch": 631.55,
      "learning_rate": 0.036870224420161295,
      "loss": 0.6259,
      "step": 391560
    },
    {
      "epoch": 631.58,
      "learning_rate": 0.03686699861693549,
      "loss": 0.6443,
      "step": 391580
    },
    {
      "epoch": 631.61,
      "learning_rate": 0.03686377281370968,
      "loss": 0.6596,
      "step": 391600
    },
    {
      "epoch": 631.65,
      "learning_rate": 0.03686054701048388,
      "loss": 0.6345,
      "step": 391620
    },
    {
      "epoch": 631.68,
      "learning_rate": 0.03685732120725807,
      "loss": 0.6574,
      "step": 391640
    },
    {
      "epoch": 631.71,
      "learning_rate": 0.03685409540403226,
      "loss": 0.6505,
      "step": 391660
    },
    {
      "epoch": 631.74,
      "learning_rate": 0.036850869600806455,
      "loss": 0.6455,
      "step": 391680
    },
    {
      "epoch": 631.77,
      "learning_rate": 0.036847643797580654,
      "loss": 0.6631,
      "step": 391700
    },
    {
      "epoch": 631.81,
      "learning_rate": 0.036844417994354846,
      "loss": 0.6464,
      "step": 391720
    },
    {
      "epoch": 631.84,
      "learning_rate": 0.03684119219112904,
      "loss": 0.6541,
      "step": 391740
    },
    {
      "epoch": 631.87,
      "learning_rate": 0.03683796638790324,
      "loss": 0.6417,
      "step": 391760
    },
    {
      "epoch": 631.9,
      "learning_rate": 0.036834740584677415,
      "loss": 0.6395,
      "step": 391780
    },
    {
      "epoch": 631.94,
      "learning_rate": 0.036831514781451614,
      "loss": 0.6419,
      "step": 391800
    },
    {
      "epoch": 631.97,
      "learning_rate": 0.03682828897822581,
      "loss": 0.6373,
      "step": 391820
    },
    {
      "epoch": 632.0,
      "learning_rate": 0.036825063175,
      "loss": 0.6409,
      "step": 391840
    },
    {
      "epoch": 632.0,
      "eval_accuracy": {
        "accuracy": 0.7716805869955506
      },
      "eval_loss": 1.0015544891357422,
      "eval_runtime": 3.0427,
      "eval_samples_per_second": 4210.438,
      "eval_steps_per_second": 66.06,
      "step": 391840
    },
    {
      "epoch": 632.03,
      "learning_rate": 0.0368218373717742,
      "loss": 0.6475,
      "step": 391860
    },
    {
      "epoch": 632.06,
      "learning_rate": 0.03681861156854839,
      "loss": 0.6333,
      "step": 391880
    },
    {
      "epoch": 632.1,
      "learning_rate": 0.03681538576532258,
      "loss": 0.6409,
      "step": 391900
    },
    {
      "epoch": 632.13,
      "learning_rate": 0.036812159962096774,
      "loss": 0.6272,
      "step": 391920
    },
    {
      "epoch": 632.16,
      "learning_rate": 0.03680893415887097,
      "loss": 0.6349,
      "step": 391940
    },
    {
      "epoch": 632.19,
      "learning_rate": 0.036805708355645166,
      "loss": 0.6319,
      "step": 391960
    },
    {
      "epoch": 632.23,
      "learning_rate": 0.03680248255241936,
      "loss": 0.6229,
      "step": 391980
    },
    {
      "epoch": 632.26,
      "learning_rate": 0.03679925674919356,
      "loss": 0.633,
      "step": 392000
    },
    {
      "epoch": 632.29,
      "learning_rate": 0.03679603094596775,
      "loss": 0.6262,
      "step": 392020
    },
    {
      "epoch": 632.32,
      "learning_rate": 0.03679280514274194,
      "loss": 0.6338,
      "step": 392040
    },
    {
      "epoch": 632.35,
      "learning_rate": 0.03678957933951614,
      "loss": 0.6334,
      "step": 392060
    },
    {
      "epoch": 632.39,
      "learning_rate": 0.03678635353629033,
      "loss": 0.6376,
      "step": 392080
    },
    {
      "epoch": 632.42,
      "learning_rate": 0.03678312773306452,
      "loss": 0.6345,
      "step": 392100
    },
    {
      "epoch": 632.45,
      "learning_rate": 0.03677990192983871,
      "loss": 0.6393,
      "step": 392120
    },
    {
      "epoch": 632.48,
      "learning_rate": 0.0367766761266129,
      "loss": 0.6413,
      "step": 392140
    },
    {
      "epoch": 632.52,
      "learning_rate": 0.0367734503233871,
      "loss": 0.6292,
      "step": 392160
    },
    {
      "epoch": 632.55,
      "learning_rate": 0.03677022452016129,
      "loss": 0.6476,
      "step": 392180
    },
    {
      "epoch": 632.58,
      "learning_rate": 0.036766998716935485,
      "loss": 0.6421,
      "step": 392200
    },
    {
      "epoch": 632.61,
      "learning_rate": 0.03676377291370968,
      "loss": 0.6414,
      "step": 392220
    },
    {
      "epoch": 632.65,
      "learning_rate": 0.03676054711048388,
      "loss": 0.6395,
      "step": 392240
    },
    {
      "epoch": 632.68,
      "learning_rate": 0.03675732130725807,
      "loss": 0.6423,
      "step": 392260
    },
    {
      "epoch": 632.71,
      "learning_rate": 0.03675409550403226,
      "loss": 0.6517,
      "step": 392280
    },
    {
      "epoch": 632.74,
      "learning_rate": 0.03675086970080646,
      "loss": 0.6381,
      "step": 392300
    },
    {
      "epoch": 632.77,
      "learning_rate": 0.03674764389758065,
      "loss": 0.6578,
      "step": 392320
    },
    {
      "epoch": 632.81,
      "learning_rate": 0.036744418094354844,
      "loss": 0.6427,
      "step": 392340
    },
    {
      "epoch": 632.84,
      "learning_rate": 0.03674119229112904,
      "loss": 0.6431,
      "step": 392360
    },
    {
      "epoch": 632.87,
      "learning_rate": 0.036737966487903236,
      "loss": 0.642,
      "step": 392380
    },
    {
      "epoch": 632.9,
      "learning_rate": 0.03673474068467743,
      "loss": 0.6498,
      "step": 392400
    },
    {
      "epoch": 632.94,
      "learning_rate": 0.03673151488145161,
      "loss": 0.6386,
      "step": 392420
    },
    {
      "epoch": 632.97,
      "learning_rate": 0.036728289078225805,
      "loss": 0.6674,
      "step": 392440
    },
    {
      "epoch": 633.0,
      "learning_rate": 0.036725063275,
      "loss": 0.6423,
      "step": 392460
    },
    {
      "epoch": 633.0,
      "eval_accuracy": {
        "accuracy": 0.768870501912419
      },
      "eval_loss": 1.0119216442108154,
      "eval_runtime": 2.9274,
      "eval_samples_per_second": 4376.289,
      "eval_steps_per_second": 68.662,
      "step": 392460
    },
    {
      "epoch": 633.03,
      "learning_rate": 0.036721837471774196,
      "loss": 0.6559,
      "step": 392480
    },
    {
      "epoch": 633.06,
      "learning_rate": 0.03671861166854839,
      "loss": 0.6527,
      "step": 392500
    },
    {
      "epoch": 633.1,
      "learning_rate": 0.03671538586532258,
      "loss": 0.6522,
      "step": 392520
    },
    {
      "epoch": 633.13,
      "learning_rate": 0.03671216006209678,
      "loss": 0.6476,
      "step": 392540
    },
    {
      "epoch": 633.16,
      "learning_rate": 0.03670893425887097,
      "loss": 0.6421,
      "step": 392560
    },
    {
      "epoch": 633.19,
      "learning_rate": 0.036705708455645164,
      "loss": 0.6328,
      "step": 392580
    },
    {
      "epoch": 633.23,
      "learning_rate": 0.03670248265241936,
      "loss": 0.6319,
      "step": 392600
    },
    {
      "epoch": 633.26,
      "learning_rate": 0.036699256849193555,
      "loss": 0.6365,
      "step": 392620
    },
    {
      "epoch": 633.29,
      "learning_rate": 0.03669603104596775,
      "loss": 0.6249,
      "step": 392640
    },
    {
      "epoch": 633.32,
      "learning_rate": 0.03669280524274194,
      "loss": 0.6459,
      "step": 392660
    },
    {
      "epoch": 633.35,
      "learning_rate": 0.03668957943951614,
      "loss": 0.6395,
      "step": 392680
    },
    {
      "epoch": 633.39,
      "learning_rate": 0.03668635363629033,
      "loss": 0.6528,
      "step": 392700
    },
    {
      "epoch": 633.42,
      "learning_rate": 0.036683127833064516,
      "loss": 0.6445,
      "step": 392720
    },
    {
      "epoch": 633.45,
      "learning_rate": 0.03667990202983871,
      "loss": 0.6494,
      "step": 392740
    },
    {
      "epoch": 633.48,
      "learning_rate": 0.0366766762266129,
      "loss": 0.6426,
      "step": 392760
    },
    {
      "epoch": 633.52,
      "learning_rate": 0.0366734504233871,
      "loss": 0.6455,
      "step": 392780
    },
    {
      "epoch": 633.55,
      "learning_rate": 0.03667022462016129,
      "loss": 0.6477,
      "step": 392800
    },
    {
      "epoch": 633.58,
      "learning_rate": 0.036666998816935484,
      "loss": 0.6449,
      "step": 392820
    },
    {
      "epoch": 633.61,
      "learning_rate": 0.03666377301370968,
      "loss": 0.6388,
      "step": 392840
    },
    {
      "epoch": 633.65,
      "learning_rate": 0.036660547210483875,
      "loss": 0.6313,
      "step": 392860
    },
    {
      "epoch": 633.68,
      "learning_rate": 0.03665732140725807,
      "loss": 0.6338,
      "step": 392880
    },
    {
      "epoch": 633.71,
      "learning_rate": 0.036654095604032266,
      "loss": 0.6391,
      "step": 392900
    },
    {
      "epoch": 633.74,
      "learning_rate": 0.03665086980080646,
      "loss": 0.6349,
      "step": 392920
    },
    {
      "epoch": 633.77,
      "learning_rate": 0.03664764399758065,
      "loss": 0.6421,
      "step": 392940
    },
    {
      "epoch": 633.81,
      "learning_rate": 0.03664441819435484,
      "loss": 0.6407,
      "step": 392960
    },
    {
      "epoch": 633.84,
      "learning_rate": 0.03664119239112904,
      "loss": 0.6307,
      "step": 392980
    },
    {
      "epoch": 633.87,
      "learning_rate": 0.036637966587903234,
      "loss": 0.6521,
      "step": 393000
    },
    {
      "epoch": 633.9,
      "learning_rate": 0.036634740784677426,
      "loss": 0.6395,
      "step": 393020
    },
    {
      "epoch": 633.94,
      "learning_rate": 0.03663151498145161,
      "loss": 0.644,
      "step": 393040
    },
    {
      "epoch": 633.97,
      "learning_rate": 0.036628289178225804,
      "loss": 0.6379,
      "step": 393060
    },
    {
      "epoch": 634.0,
      "learning_rate": 0.036625063375,
      "loss": 0.6524,
      "step": 393080
    },
    {
      "epoch": 634.0,
      "eval_accuracy": {
        "accuracy": 0.7676996331277808
      },
      "eval_loss": 1.0151278972625732,
      "eval_runtime": 3.0942,
      "eval_samples_per_second": 4140.389,
      "eval_steps_per_second": 64.961,
      "step": 393080
    },
    {
      "epoch": 634.03,
      "learning_rate": 0.036621837571774195,
      "loss": 0.6382,
      "step": 393100
    },
    {
      "epoch": 634.06,
      "learning_rate": 0.03661861176854839,
      "loss": 0.6249,
      "step": 393120
    },
    {
      "epoch": 634.1,
      "learning_rate": 0.036615385965322586,
      "loss": 0.6345,
      "step": 393140
    },
    {
      "epoch": 634.13,
      "learning_rate": 0.03661216016209678,
      "loss": 0.6401,
      "step": 393160
    },
    {
      "epoch": 634.16,
      "learning_rate": 0.03660893435887097,
      "loss": 0.6311,
      "step": 393180
    },
    {
      "epoch": 634.19,
      "learning_rate": 0.03660570855564516,
      "loss": 0.6233,
      "step": 393200
    },
    {
      "epoch": 634.23,
      "learning_rate": 0.03660248275241936,
      "loss": 0.6232,
      "step": 393220
    },
    {
      "epoch": 634.26,
      "learning_rate": 0.036599256949193554,
      "loss": 0.64,
      "step": 393240
    },
    {
      "epoch": 634.29,
      "learning_rate": 0.036596031145967746,
      "loss": 0.6246,
      "step": 393260
    },
    {
      "epoch": 634.32,
      "learning_rate": 0.036592805342741945,
      "loss": 0.6307,
      "step": 393280
    },
    {
      "epoch": 634.35,
      "learning_rate": 0.03658957953951614,
      "loss": 0.6274,
      "step": 393300
    },
    {
      "epoch": 634.39,
      "learning_rate": 0.03658635373629033,
      "loss": 0.6409,
      "step": 393320
    },
    {
      "epoch": 634.42,
      "learning_rate": 0.036583127933064515,
      "loss": 0.6474,
      "step": 393340
    },
    {
      "epoch": 634.45,
      "learning_rate": 0.03657990212983871,
      "loss": 0.6338,
      "step": 393360
    },
    {
      "epoch": 634.48,
      "learning_rate": 0.036576676326612906,
      "loss": 0.6291,
      "step": 393380
    },
    {
      "epoch": 634.52,
      "learning_rate": 0.0365734505233871,
      "loss": 0.6439,
      "step": 393400
    },
    {
      "epoch": 634.55,
      "learning_rate": 0.03657022472016129,
      "loss": 0.649,
      "step": 393420
    },
    {
      "epoch": 634.58,
      "learning_rate": 0.03656699891693549,
      "loss": 0.6518,
      "step": 393440
    },
    {
      "epoch": 634.61,
      "learning_rate": 0.03656377311370968,
      "loss": 0.6359,
      "step": 393460
    },
    {
      "epoch": 634.65,
      "learning_rate": 0.036560547310483874,
      "loss": 0.6562,
      "step": 393480
    },
    {
      "epoch": 634.68,
      "learning_rate": 0.036557321507258066,
      "loss": 0.6467,
      "step": 393500
    },
    {
      "epoch": 634.71,
      "learning_rate": 0.036554095704032265,
      "loss": 0.6483,
      "step": 393520
    },
    {
      "epoch": 634.74,
      "learning_rate": 0.03655086990080646,
      "loss": 0.6301,
      "step": 393540
    },
    {
      "epoch": 634.77,
      "learning_rate": 0.03654764409758065,
      "loss": 0.6372,
      "step": 393560
    },
    {
      "epoch": 634.81,
      "learning_rate": 0.03654441829435485,
      "loss": 0.6407,
      "step": 393580
    },
    {
      "epoch": 634.84,
      "learning_rate": 0.03654119249112904,
      "loss": 0.6335,
      "step": 393600
    },
    {
      "epoch": 634.87,
      "learning_rate": 0.03653796668790323,
      "loss": 0.6472,
      "step": 393620
    },
    {
      "epoch": 634.9,
      "learning_rate": 0.03653474088467743,
      "loss": 0.6479,
      "step": 393640
    },
    {
      "epoch": 634.94,
      "learning_rate": 0.03653151508145161,
      "loss": 0.6571,
      "step": 393660
    },
    {
      "epoch": 634.97,
      "learning_rate": 0.03652828927822581,
      "loss": 0.6295,
      "step": 393680
    },
    {
      "epoch": 635.0,
      "learning_rate": 0.0365252247651613,
      "loss": 0.6412,
      "step": 393700
    },
    {
      "epoch": 635.0,
      "eval_accuracy": {
        "accuracy": 0.7730075716181407
      },
      "eval_loss": 0.9917665719985962,
      "eval_runtime": 2.9417,
      "eval_samples_per_second": 4354.916,
      "eval_steps_per_second": 68.327,
      "step": 393700
    },
    {
      "epoch": 635.03,
      "learning_rate": 0.03652199896193549,
      "loss": 0.6276,
      "step": 393720
    },
    {
      "epoch": 635.06,
      "learning_rate": 0.03651877315870968,
      "loss": 0.629,
      "step": 393740
    },
    {
      "epoch": 635.1,
      "learning_rate": 0.03651554735548388,
      "loss": 0.6288,
      "step": 393760
    },
    {
      "epoch": 635.13,
      "learning_rate": 0.03651232155225807,
      "loss": 0.6294,
      "step": 393780
    },
    {
      "epoch": 635.16,
      "learning_rate": 0.03650909574903226,
      "loss": 0.6398,
      "step": 393800
    },
    {
      "epoch": 635.19,
      "learning_rate": 0.03650586994580645,
      "loss": 0.6206,
      "step": 393820
    },
    {
      "epoch": 635.23,
      "learning_rate": 0.03650264414258064,
      "loss": 0.6173,
      "step": 393840
    },
    {
      "epoch": 635.26,
      "learning_rate": 0.03649941833935484,
      "loss": 0.628,
      "step": 393860
    },
    {
      "epoch": 635.29,
      "learning_rate": 0.036496192536129034,
      "loss": 0.6482,
      "step": 393880
    },
    {
      "epoch": 635.32,
      "learning_rate": 0.036492966732903226,
      "loss": 0.6446,
      "step": 393900
    },
    {
      "epoch": 635.35,
      "learning_rate": 0.036489740929677425,
      "loss": 0.6307,
      "step": 393920
    },
    {
      "epoch": 635.39,
      "learning_rate": 0.03648651512645162,
      "loss": 0.632,
      "step": 393940
    },
    {
      "epoch": 635.42,
      "learning_rate": 0.03648328932322581,
      "loss": 0.6238,
      "step": 393960
    },
    {
      "epoch": 635.45,
      "learning_rate": 0.03648006352000001,
      "loss": 0.6432,
      "step": 393980
    },
    {
      "epoch": 635.48,
      "learning_rate": 0.0364768377167742,
      "loss": 0.6427,
      "step": 394000
    },
    {
      "epoch": 635.52,
      "learning_rate": 0.03647361191354839,
      "loss": 0.6287,
      "step": 394020
    },
    {
      "epoch": 635.55,
      "learning_rate": 0.036470386110322585,
      "loss": 0.6458,
      "step": 394040
    },
    {
      "epoch": 635.58,
      "learning_rate": 0.036467160307096784,
      "loss": 0.6556,
      "step": 394060
    },
    {
      "epoch": 635.61,
      "learning_rate": 0.036463934503870976,
      "loss": 0.6564,
      "step": 394080
    },
    {
      "epoch": 635.65,
      "learning_rate": 0.03646070870064516,
      "loss": 0.6537,
      "step": 394100
    },
    {
      "epoch": 635.68,
      "learning_rate": 0.036457482897419353,
      "loss": 0.6396,
      "step": 394120
    },
    {
      "epoch": 635.71,
      "learning_rate": 0.036454257094193546,
      "loss": 0.6273,
      "step": 394140
    },
    {
      "epoch": 635.74,
      "learning_rate": 0.036451031290967745,
      "loss": 0.6351,
      "step": 394160
    },
    {
      "epoch": 635.77,
      "learning_rate": 0.03644780548774194,
      "loss": 0.6447,
      "step": 394180
    },
    {
      "epoch": 635.81,
      "learning_rate": 0.03644457968451613,
      "loss": 0.6528,
      "step": 394200
    },
    {
      "epoch": 635.84,
      "learning_rate": 0.03644135388129033,
      "loss": 0.6503,
      "step": 394220
    },
    {
      "epoch": 635.87,
      "learning_rate": 0.03643812807806452,
      "loss": 0.6634,
      "step": 394240
    },
    {
      "epoch": 635.9,
      "learning_rate": 0.03643490227483871,
      "loss": 0.6525,
      "step": 394260
    },
    {
      "epoch": 635.94,
      "learning_rate": 0.036431676471612905,
      "loss": 0.6475,
      "step": 394280
    },
    {
      "epoch": 635.97,
      "learning_rate": 0.036428450668387104,
      "loss": 0.644,
      "step": 394300
    },
    {
      "epoch": 636.0,
      "learning_rate": 0.036425224865161296,
      "loss": 0.6643,
      "step": 394320
    },
    {
      "epoch": 636.0,
      "eval_accuracy": {
        "accuracy": 0.7650456638826009
      },
      "eval_loss": 1.0205000638961792,
      "eval_runtime": 2.966,
      "eval_samples_per_second": 4319.285,
      "eval_steps_per_second": 67.768,
      "step": 394320
    },
    {
      "epoch": 636.03,
      "learning_rate": 0.03642199906193549,
      "loss": 0.6543,
      "step": 394340
    },
    {
      "epoch": 636.06,
      "learning_rate": 0.03641877325870969,
      "loss": 0.6364,
      "step": 394360
    },
    {
      "epoch": 636.1,
      "learning_rate": 0.03641554745548388,
      "loss": 0.645,
      "step": 394380
    },
    {
      "epoch": 636.13,
      "learning_rate": 0.03641232165225807,
      "loss": 0.6366,
      "step": 394400
    },
    {
      "epoch": 636.16,
      "learning_rate": 0.03640909584903226,
      "loss": 0.6445,
      "step": 394420
    },
    {
      "epoch": 636.19,
      "learning_rate": 0.03640587004580645,
      "loss": 0.6396,
      "step": 394440
    },
    {
      "epoch": 636.23,
      "learning_rate": 0.03640264424258065,
      "loss": 0.6279,
      "step": 394460
    },
    {
      "epoch": 636.26,
      "learning_rate": 0.03639941843935484,
      "loss": 0.6307,
      "step": 394480
    },
    {
      "epoch": 636.29,
      "learning_rate": 0.03639619263612903,
      "loss": 0.6289,
      "step": 394500
    },
    {
      "epoch": 636.32,
      "learning_rate": 0.03639296683290323,
      "loss": 0.6379,
      "step": 394520
    },
    {
      "epoch": 636.35,
      "learning_rate": 0.03638974102967742,
      "loss": 0.6527,
      "step": 394540
    },
    {
      "epoch": 636.39,
      "learning_rate": 0.036386515226451616,
      "loss": 0.632,
      "step": 394560
    },
    {
      "epoch": 636.42,
      "learning_rate": 0.03638328942322581,
      "loss": 0.6301,
      "step": 394580
    },
    {
      "epoch": 636.45,
      "learning_rate": 0.03638006362000001,
      "loss": 0.6218,
      "step": 394600
    },
    {
      "epoch": 636.48,
      "learning_rate": 0.0363768378167742,
      "loss": 0.6395,
      "step": 394620
    },
    {
      "epoch": 636.52,
      "learning_rate": 0.03637361201354839,
      "loss": 0.6353,
      "step": 394640
    },
    {
      "epoch": 636.55,
      "learning_rate": 0.03637038621032259,
      "loss": 0.6343,
      "step": 394660
    },
    {
      "epoch": 636.58,
      "learning_rate": 0.03636716040709678,
      "loss": 0.6468,
      "step": 394680
    },
    {
      "epoch": 636.61,
      "learning_rate": 0.036363934603870975,
      "loss": 0.659,
      "step": 394700
    },
    {
      "epoch": 636.65,
      "learning_rate": 0.036360708800645174,
      "loss": 0.6369,
      "step": 394720
    },
    {
      "epoch": 636.68,
      "learning_rate": 0.03635748299741935,
      "loss": 0.6228,
      "step": 394740
    },
    {
      "epoch": 636.71,
      "learning_rate": 0.03635425719419355,
      "loss": 0.6414,
      "step": 394760
    },
    {
      "epoch": 636.74,
      "learning_rate": 0.03635103139096774,
      "loss": 0.6262,
      "step": 394780
    },
    {
      "epoch": 636.77,
      "learning_rate": 0.036347805587741935,
      "loss": 0.6447,
      "step": 394800
    },
    {
      "epoch": 636.81,
      "learning_rate": 0.03634457978451613,
      "loss": 0.6553,
      "step": 394820
    },
    {
      "epoch": 636.84,
      "learning_rate": 0.03634135398129033,
      "loss": 0.6414,
      "step": 394840
    },
    {
      "epoch": 636.87,
      "learning_rate": 0.03633812817806452,
      "loss": 0.6492,
      "step": 394860
    },
    {
      "epoch": 636.9,
      "learning_rate": 0.03633490237483871,
      "loss": 0.6349,
      "step": 394880
    },
    {
      "epoch": 636.94,
      "learning_rate": 0.03633167657161291,
      "loss": 0.6496,
      "step": 394900
    },
    {
      "epoch": 636.97,
      "learning_rate": 0.0363284507683871,
      "loss": 0.6466,
      "step": 394920
    },
    {
      "epoch": 637.0,
      "learning_rate": 0.036325224965161294,
      "loss": 0.6416,
      "step": 394940
    },
    {
      "epoch": 637.0,
      "eval_accuracy": {
        "accuracy": 0.7663726485051908
      },
      "eval_loss": 1.029887318611145,
      "eval_runtime": 2.8432,
      "eval_samples_per_second": 4505.78,
      "eval_steps_per_second": 70.694,
      "step": 394940
    },
    {
      "epoch": 637.03,
      "learning_rate": 0.03632199916193549,
      "loss": 0.6464,
      "step": 394960
    },
    {
      "epoch": 637.06,
      "learning_rate": 0.036318773358709686,
      "loss": 0.6209,
      "step": 394980
    },
    {
      "epoch": 637.1,
      "learning_rate": 0.03631554755548388,
      "loss": 0.6269,
      "step": 395000
    },
    {
      "epoch": 637.13,
      "learning_rate": 0.03631232175225808,
      "loss": 0.616,
      "step": 395020
    },
    {
      "epoch": 637.16,
      "learning_rate": 0.036309095949032255,
      "loss": 0.6371,
      "step": 395040
    },
    {
      "epoch": 637.19,
      "learning_rate": 0.036305870145806454,
      "loss": 0.6215,
      "step": 395060
    },
    {
      "epoch": 637.23,
      "learning_rate": 0.036302644342580646,
      "loss": 0.6317,
      "step": 395080
    },
    {
      "epoch": 637.26,
      "learning_rate": 0.03629941853935484,
      "loss": 0.6402,
      "step": 395100
    },
    {
      "epoch": 637.29,
      "learning_rate": 0.03629619273612903,
      "loss": 0.6307,
      "step": 395120
    },
    {
      "epoch": 637.32,
      "learning_rate": 0.03629296693290323,
      "loss": 0.6313,
      "step": 395140
    },
    {
      "epoch": 637.35,
      "learning_rate": 0.03628974112967742,
      "loss": 0.6302,
      "step": 395160
    },
    {
      "epoch": 637.39,
      "learning_rate": 0.036286515326451614,
      "loss": 0.646,
      "step": 395180
    },
    {
      "epoch": 637.42,
      "learning_rate": 0.03628328952322581,
      "loss": 0.6395,
      "step": 395200
    },
    {
      "epoch": 637.45,
      "learning_rate": 0.036280063720000005,
      "loss": 0.645,
      "step": 395220
    },
    {
      "epoch": 637.48,
      "learning_rate": 0.0362768379167742,
      "loss": 0.6535,
      "step": 395240
    },
    {
      "epoch": 637.52,
      "learning_rate": 0.0362736121135484,
      "loss": 0.6488,
      "step": 395260
    },
    {
      "epoch": 637.55,
      "learning_rate": 0.03627038631032259,
      "loss": 0.6423,
      "step": 395280
    },
    {
      "epoch": 637.58,
      "learning_rate": 0.03626716050709678,
      "loss": 0.6454,
      "step": 395300
    },
    {
      "epoch": 637.61,
      "learning_rate": 0.03626393470387097,
      "loss": 0.645,
      "step": 395320
    },
    {
      "epoch": 637.65,
      "learning_rate": 0.03626070890064517,
      "loss": 0.6265,
      "step": 395340
    },
    {
      "epoch": 637.68,
      "learning_rate": 0.03625748309741935,
      "loss": 0.6456,
      "step": 395360
    },
    {
      "epoch": 637.71,
      "learning_rate": 0.03625425729419355,
      "loss": 0.6535,
      "step": 395380
    },
    {
      "epoch": 637.74,
      "learning_rate": 0.03625103149096774,
      "loss": 0.6542,
      "step": 395400
    },
    {
      "epoch": 637.77,
      "learning_rate": 0.036247805687741934,
      "loss": 0.6475,
      "step": 395420
    },
    {
      "epoch": 637.81,
      "learning_rate": 0.03624457988451613,
      "loss": 0.6407,
      "step": 395440
    },
    {
      "epoch": 637.84,
      "learning_rate": 0.036241354081290325,
      "loss": 0.6288,
      "step": 395460
    },
    {
      "epoch": 637.87,
      "learning_rate": 0.03623812827806452,
      "loss": 0.644,
      "step": 395480
    },
    {
      "epoch": 637.9,
      "learning_rate": 0.036234902474838716,
      "loss": 0.6243,
      "step": 395500
    },
    {
      "epoch": 637.94,
      "learning_rate": 0.03623167667161291,
      "loss": 0.645,
      "step": 395520
    },
    {
      "epoch": 637.97,
      "learning_rate": 0.0362284508683871,
      "loss": 0.6363,
      "step": 395540
    },
    {
      "epoch": 638.0,
      "learning_rate": 0.0362252250651613,
      "loss": 0.6452,
      "step": 395560
    },
    {
      "epoch": 638.0,
      "eval_accuracy": {
        "accuracy": 0.7709780657247678
      },
      "eval_loss": 0.9906232953071594,
      "eval_runtime": 3.0923,
      "eval_samples_per_second": 4142.909,
      "eval_steps_per_second": 65.001,
      "step": 395560
    },
    {
      "epoch": 638.03,
      "learning_rate": 0.03622199926193549,
      "loss": 0.6447,
      "step": 395580
    },
    {
      "epoch": 638.06,
      "learning_rate": 0.036218773458709684,
      "loss": 0.6378,
      "step": 395600
    },
    {
      "epoch": 638.1,
      "learning_rate": 0.036215547655483876,
      "loss": 0.6155,
      "step": 395620
    },
    {
      "epoch": 638.13,
      "learning_rate": 0.036212321852258075,
      "loss": 0.636,
      "step": 395640
    },
    {
      "epoch": 638.16,
      "learning_rate": 0.036209096049032254,
      "loss": 0.6257,
      "step": 395660
    },
    {
      "epoch": 638.19,
      "learning_rate": 0.03620587024580645,
      "loss": 0.6356,
      "step": 395680
    },
    {
      "epoch": 638.23,
      "learning_rate": 0.036202644442580645,
      "loss": 0.6378,
      "step": 395700
    },
    {
      "epoch": 638.26,
      "learning_rate": 0.03619941863935484,
      "loss": 0.637,
      "step": 395720
    },
    {
      "epoch": 638.29,
      "learning_rate": 0.036196192836129036,
      "loss": 0.6376,
      "step": 395740
    },
    {
      "epoch": 638.32,
      "learning_rate": 0.03619296703290323,
      "loss": 0.6317,
      "step": 395760
    },
    {
      "epoch": 638.35,
      "learning_rate": 0.03618974122967742,
      "loss": 0.6279,
      "step": 395780
    },
    {
      "epoch": 638.39,
      "learning_rate": 0.03618651542645162,
      "loss": 0.6337,
      "step": 395800
    },
    {
      "epoch": 638.42,
      "learning_rate": 0.03618328962322581,
      "loss": 0.6548,
      "step": 395820
    },
    {
      "epoch": 638.45,
      "learning_rate": 0.036180063820000004,
      "loss": 0.6376,
      "step": 395840
    },
    {
      "epoch": 638.48,
      "learning_rate": 0.036176838016774196,
      "loss": 0.6514,
      "step": 395860
    },
    {
      "epoch": 638.52,
      "learning_rate": 0.036173612213548395,
      "loss": 0.6415,
      "step": 395880
    },
    {
      "epoch": 638.55,
      "learning_rate": 0.03617038641032259,
      "loss": 0.6401,
      "step": 395900
    },
    {
      "epoch": 638.58,
      "learning_rate": 0.03616716060709678,
      "loss": 0.6255,
      "step": 395920
    },
    {
      "epoch": 638.61,
      "learning_rate": 0.03616393480387098,
      "loss": 0.6348,
      "step": 395940
    },
    {
      "epoch": 638.65,
      "learning_rate": 0.03616070900064517,
      "loss": 0.6335,
      "step": 395960
    },
    {
      "epoch": 638.68,
      "learning_rate": 0.036157483197419356,
      "loss": 0.6498,
      "step": 395980
    },
    {
      "epoch": 638.71,
      "learning_rate": 0.03615425739419355,
      "loss": 0.6561,
      "step": 396000
    },
    {
      "epoch": 638.74,
      "learning_rate": 0.03615103159096774,
      "loss": 0.6563,
      "step": 396020
    },
    {
      "epoch": 638.77,
      "learning_rate": 0.03614780578774194,
      "loss": 0.6463,
      "step": 396040
    },
    {
      "epoch": 638.81,
      "learning_rate": 0.03614457998451613,
      "loss": 0.6341,
      "step": 396060
    },
    {
      "epoch": 638.84,
      "learning_rate": 0.036141354181290324,
      "loss": 0.6291,
      "step": 396080
    },
    {
      "epoch": 638.87,
      "learning_rate": 0.036138128378064516,
      "loss": 0.6572,
      "step": 396100
    },
    {
      "epoch": 638.9,
      "learning_rate": 0.036134902574838715,
      "loss": 0.6403,
      "step": 396120
    },
    {
      "epoch": 638.94,
      "learning_rate": 0.03613167677161291,
      "loss": 0.6402,
      "step": 396140
    },
    {
      "epoch": 638.97,
      "learning_rate": 0.0361284509683871,
      "loss": 0.643,
      "step": 396160
    },
    {
      "epoch": 639.0,
      "learning_rate": 0.03612538645532258,
      "loss": 0.6437,
      "step": 396180
    },
    {
      "epoch": 639.0,
      "eval_accuracy": {
        "accuracy": 0.7662165326672391
      },
      "eval_loss": 1.0099493265151978,
      "eval_runtime": 3.1099,
      "eval_samples_per_second": 4119.457,
      "eval_steps_per_second": 64.633,
      "step": 396180
    },
    {
      "epoch": 639.03,
      "learning_rate": 0.03612216065209677,
      "loss": 0.6287,
      "step": 396200
    },
    {
      "epoch": 639.06,
      "learning_rate": 0.03611893484887097,
      "loss": 0.6367,
      "step": 396220
    },
    {
      "epoch": 639.1,
      "learning_rate": 0.036115709045645164,
      "loss": 0.6126,
      "step": 396240
    },
    {
      "epoch": 639.13,
      "learning_rate": 0.036112483242419356,
      "loss": 0.6318,
      "step": 396260
    },
    {
      "epoch": 639.16,
      "learning_rate": 0.036109257439193555,
      "loss": 0.6353,
      "step": 396280
    },
    {
      "epoch": 639.19,
      "learning_rate": 0.03610603163596775,
      "loss": 0.6326,
      "step": 396300
    },
    {
      "epoch": 639.23,
      "learning_rate": 0.03610280583274194,
      "loss": 0.6329,
      "step": 396320
    },
    {
      "epoch": 639.26,
      "learning_rate": 0.03609958002951614,
      "loss": 0.6157,
      "step": 396340
    },
    {
      "epoch": 639.29,
      "learning_rate": 0.03609635422629033,
      "loss": 0.6434,
      "step": 396360
    },
    {
      "epoch": 639.32,
      "learning_rate": 0.03609312842306452,
      "loss": 0.6524,
      "step": 396380
    },
    {
      "epoch": 639.35,
      "learning_rate": 0.036089902619838715,
      "loss": 0.6242,
      "step": 396400
    },
    {
      "epoch": 639.39,
      "learning_rate": 0.0360866768166129,
      "loss": 0.6199,
      "step": 396420
    },
    {
      "epoch": 639.42,
      "learning_rate": 0.03608345101338709,
      "loss": 0.64,
      "step": 396440
    },
    {
      "epoch": 639.45,
      "learning_rate": 0.03608022521016129,
      "loss": 0.6306,
      "step": 396460
    },
    {
      "epoch": 639.48,
      "learning_rate": 0.036076999406935484,
      "loss": 0.6255,
      "step": 396480
    },
    {
      "epoch": 639.52,
      "learning_rate": 0.036073773603709676,
      "loss": 0.6462,
      "step": 396500
    },
    {
      "epoch": 639.55,
      "learning_rate": 0.036070547800483875,
      "loss": 0.6513,
      "step": 396520
    },
    {
      "epoch": 639.58,
      "learning_rate": 0.03606732199725807,
      "loss": 0.6403,
      "step": 396540
    },
    {
      "epoch": 639.61,
      "learning_rate": 0.03606409619403226,
      "loss": 0.6306,
      "step": 396560
    },
    {
      "epoch": 639.65,
      "learning_rate": 0.03606087039080646,
      "loss": 0.6372,
      "step": 396580
    },
    {
      "epoch": 639.68,
      "learning_rate": 0.03605764458758065,
      "loss": 0.641,
      "step": 396600
    },
    {
      "epoch": 639.71,
      "learning_rate": 0.03605441878435484,
      "loss": 0.6436,
      "step": 396620
    },
    {
      "epoch": 639.74,
      "learning_rate": 0.03605119298112904,
      "loss": 0.6382,
      "step": 396640
    },
    {
      "epoch": 639.77,
      "learning_rate": 0.036047967177903234,
      "loss": 0.645,
      "step": 396660
    },
    {
      "epoch": 639.81,
      "learning_rate": 0.036044741374677426,
      "loss": 0.6428,
      "step": 396680
    },
    {
      "epoch": 639.84,
      "learning_rate": 0.03604151557145162,
      "loss": 0.6327,
      "step": 396700
    },
    {
      "epoch": 639.87,
      "learning_rate": 0.03603828976822582,
      "loss": 0.6418,
      "step": 396720
    },
    {
      "epoch": 639.9,
      "learning_rate": 0.036035063964999996,
      "loss": 0.6588,
      "step": 396740
    },
    {
      "epoch": 639.94,
      "learning_rate": 0.036031838161774195,
      "loss": 0.6483,
      "step": 396760
    },
    {
      "epoch": 639.97,
      "learning_rate": 0.03602861235854839,
      "loss": 0.6537,
      "step": 396780
    },
    {
      "epoch": 640.0,
      "learning_rate": 0.03602538655532258,
      "loss": 0.6403,
      "step": 396800
    },
    {
      "epoch": 640.0,
      "eval_accuracy": {
        "accuracy": 0.7719928186714542
      },
      "eval_loss": 0.9940341114997864,
      "eval_runtime": 2.8677,
      "eval_samples_per_second": 4467.385,
      "eval_steps_per_second": 70.092,
      "step": 396800
    },
    {
      "epoch": 640.03,
      "learning_rate": 0.03602216075209678,
      "loss": 0.6327,
      "step": 396820
    },
    {
      "epoch": 640.06,
      "learning_rate": 0.03601893494887097,
      "loss": 0.6428,
      "step": 396840
    },
    {
      "epoch": 640.1,
      "learning_rate": 0.03601570914564516,
      "loss": 0.6348,
      "step": 396860
    },
    {
      "epoch": 640.13,
      "learning_rate": 0.03601248334241936,
      "loss": 0.6338,
      "step": 396880
    },
    {
      "epoch": 640.16,
      "learning_rate": 0.036009257539193554,
      "loss": 0.6261,
      "step": 396900
    },
    {
      "epoch": 640.19,
      "learning_rate": 0.036006031735967746,
      "loss": 0.6351,
      "step": 396920
    },
    {
      "epoch": 640.23,
      "learning_rate": 0.03600280593274194,
      "loss": 0.6277,
      "step": 396940
    },
    {
      "epoch": 640.26,
      "learning_rate": 0.03599958012951614,
      "loss": 0.6284,
      "step": 396960
    },
    {
      "epoch": 640.29,
      "learning_rate": 0.03599635432629033,
      "loss": 0.6112,
      "step": 396980
    },
    {
      "epoch": 640.32,
      "learning_rate": 0.03599312852306452,
      "loss": 0.6259,
      "step": 397000
    },
    {
      "epoch": 640.35,
      "learning_rate": 0.03598990271983872,
      "loss": 0.6316,
      "step": 397020
    },
    {
      "epoch": 640.39,
      "learning_rate": 0.03598667691661291,
      "loss": 0.6353,
      "step": 397040
    },
    {
      "epoch": 640.42,
      "learning_rate": 0.0359834511133871,
      "loss": 0.6369,
      "step": 397060
    },
    {
      "epoch": 640.45,
      "learning_rate": 0.03598022531016129,
      "loss": 0.6305,
      "step": 397080
    },
    {
      "epoch": 640.48,
      "learning_rate": 0.03597699950693548,
      "loss": 0.638,
      "step": 397100
    },
    {
      "epoch": 640.52,
      "learning_rate": 0.03597377370370968,
      "loss": 0.6477,
      "step": 397120
    },
    {
      "epoch": 640.55,
      "learning_rate": 0.035970547900483874,
      "loss": 0.6423,
      "step": 397140
    },
    {
      "epoch": 640.58,
      "learning_rate": 0.035967322097258066,
      "loss": 0.6331,
      "step": 397160
    },
    {
      "epoch": 640.61,
      "learning_rate": 0.035964096294032265,
      "loss": 0.64,
      "step": 397180
    },
    {
      "epoch": 640.65,
      "learning_rate": 0.03596087049080646,
      "loss": 0.6545,
      "step": 397200
    },
    {
      "epoch": 640.68,
      "learning_rate": 0.03595764468758065,
      "loss": 0.6524,
      "step": 397220
    },
    {
      "epoch": 640.71,
      "learning_rate": 0.03595441888435484,
      "loss": 0.6455,
      "step": 397240
    },
    {
      "epoch": 640.74,
      "learning_rate": 0.03595119308112904,
      "loss": 0.6432,
      "step": 397260
    },
    {
      "epoch": 640.77,
      "learning_rate": 0.03594796727790323,
      "loss": 0.6405,
      "step": 397280
    },
    {
      "epoch": 640.81,
      "learning_rate": 0.035944741474677425,
      "loss": 0.6377,
      "step": 397300
    },
    {
      "epoch": 640.84,
      "learning_rate": 0.035941515671451624,
      "loss": 0.6308,
      "step": 397320
    },
    {
      "epoch": 640.87,
      "learning_rate": 0.035938289868225816,
      "loss": 0.641,
      "step": 397340
    },
    {
      "epoch": 640.9,
      "learning_rate": 0.035935064065,
      "loss": 0.6379,
      "step": 397360
    },
    {
      "epoch": 640.94,
      "learning_rate": 0.03593183826177419,
      "loss": 0.6471,
      "step": 397380
    },
    {
      "epoch": 640.97,
      "learning_rate": 0.035928612458548385,
      "loss": 0.6251,
      "step": 397400
    },
    {
      "epoch": 641.0,
      "learning_rate": 0.035925386655322585,
      "loss": 0.6368,
      "step": 397420
    },
    {
      "epoch": 641.0,
      "eval_accuracy": {
        "accuracy": 0.7655140113964561
      },
      "eval_loss": 1.0007922649383545,
      "eval_runtime": 2.8799,
      "eval_samples_per_second": 4448.419,
      "eval_steps_per_second": 69.794,
      "step": 397420
    },
    {
      "epoch": 641.03,
      "learning_rate": 0.03592216085209678,
      "loss": 0.6464,
      "step": 397440
    },
    {
      "epoch": 641.06,
      "learning_rate": 0.03591893504887097,
      "loss": 0.6394,
      "step": 397460
    },
    {
      "epoch": 641.1,
      "learning_rate": 0.03591570924564516,
      "loss": 0.6306,
      "step": 397480
    },
    {
      "epoch": 641.13,
      "learning_rate": 0.03591248344241936,
      "loss": 0.6245,
      "step": 397500
    },
    {
      "epoch": 641.16,
      "learning_rate": 0.03590925763919355,
      "loss": 0.6328,
      "step": 397520
    },
    {
      "epoch": 641.19,
      "learning_rate": 0.035906031835967744,
      "loss": 0.637,
      "step": 397540
    },
    {
      "epoch": 641.23,
      "learning_rate": 0.035902806032741943,
      "loss": 0.631,
      "step": 397560
    },
    {
      "epoch": 641.26,
      "learning_rate": 0.035899580229516136,
      "loss": 0.6331,
      "step": 397580
    },
    {
      "epoch": 641.29,
      "learning_rate": 0.03589635442629033,
      "loss": 0.6375,
      "step": 397600
    },
    {
      "epoch": 641.32,
      "learning_rate": 0.03589312862306453,
      "loss": 0.631,
      "step": 397620
    },
    {
      "epoch": 641.35,
      "learning_rate": 0.03588990281983872,
      "loss": 0.6315,
      "step": 397640
    },
    {
      "epoch": 641.39,
      "learning_rate": 0.03588667701661291,
      "loss": 0.631,
      "step": 397660
    },
    {
      "epoch": 641.42,
      "learning_rate": 0.035883451213387096,
      "loss": 0.6332,
      "step": 397680
    },
    {
      "epoch": 641.45,
      "learning_rate": 0.03588022541016129,
      "loss": 0.6347,
      "step": 397700
    },
    {
      "epoch": 641.48,
      "learning_rate": 0.03587699960693548,
      "loss": 0.6328,
      "step": 397720
    },
    {
      "epoch": 641.52,
      "learning_rate": 0.03587377380370968,
      "loss": 0.6404,
      "step": 397740
    },
    {
      "epoch": 641.55,
      "learning_rate": 0.03587054800048387,
      "loss": 0.6441,
      "step": 397760
    },
    {
      "epoch": 641.58,
      "learning_rate": 0.035867322197258064,
      "loss": 0.6424,
      "step": 397780
    },
    {
      "epoch": 641.61,
      "learning_rate": 0.03586409639403226,
      "loss": 0.6411,
      "step": 397800
    },
    {
      "epoch": 641.65,
      "learning_rate": 0.035860870590806455,
      "loss": 0.6455,
      "step": 397820
    },
    {
      "epoch": 641.68,
      "learning_rate": 0.03585764478758065,
      "loss": 0.6124,
      "step": 397840
    },
    {
      "epoch": 641.71,
      "learning_rate": 0.03585441898435485,
      "loss": 0.6324,
      "step": 397860
    },
    {
      "epoch": 641.74,
      "learning_rate": 0.03585119318112904,
      "loss": 0.6406,
      "step": 397880
    },
    {
      "epoch": 641.77,
      "learning_rate": 0.03584796737790323,
      "loss": 0.6386,
      "step": 397900
    },
    {
      "epoch": 641.81,
      "learning_rate": 0.03584474157467743,
      "loss": 0.6388,
      "step": 397920
    },
    {
      "epoch": 641.84,
      "learning_rate": 0.03584151577145162,
      "loss": 0.628,
      "step": 397940
    },
    {
      "epoch": 641.87,
      "learning_rate": 0.035838289968225814,
      "loss": 0.634,
      "step": 397960
    },
    {
      "epoch": 641.9,
      "learning_rate": 0.035835064165,
      "loss": 0.6357,
      "step": 397980
    },
    {
      "epoch": 641.94,
      "learning_rate": 0.03583183836177419,
      "loss": 0.6604,
      "step": 398000
    },
    {
      "epoch": 641.97,
      "learning_rate": 0.035828612558548384,
      "loss": 0.637,
      "step": 398020
    },
    {
      "epoch": 642.0,
      "learning_rate": 0.03582538675532258,
      "loss": 0.6514,
      "step": 398040
    },
    {
      "epoch": 642.0,
      "eval_accuracy": {
        "accuracy": 0.7691046756693467
      },
      "eval_loss": 0.9942218065261841,
      "eval_runtime": 3.0479,
      "eval_samples_per_second": 4203.247,
      "eval_steps_per_second": 65.947,
      "step": 398040
    },
    {
      "epoch": 642.03,
      "learning_rate": 0.035822160952096775,
      "loss": 0.6532,
      "step": 398060
    },
    {
      "epoch": 642.06,
      "learning_rate": 0.03581893514887097,
      "loss": 0.6355,
      "step": 398080
    },
    {
      "epoch": 642.1,
      "learning_rate": 0.035815709345645166,
      "loss": 0.6359,
      "step": 398100
    },
    {
      "epoch": 642.13,
      "learning_rate": 0.03581248354241936,
      "loss": 0.6248,
      "step": 398120
    },
    {
      "epoch": 642.16,
      "learning_rate": 0.03580925773919355,
      "loss": 0.6306,
      "step": 398140
    },
    {
      "epoch": 642.19,
      "learning_rate": 0.03580603193596775,
      "loss": 0.6413,
      "step": 398160
    },
    {
      "epoch": 642.23,
      "learning_rate": 0.03580280613274194,
      "loss": 0.6221,
      "step": 398180
    },
    {
      "epoch": 642.26,
      "learning_rate": 0.035799580329516134,
      "loss": 0.6144,
      "step": 398200
    },
    {
      "epoch": 642.29,
      "learning_rate": 0.035796354526290326,
      "loss": 0.6459,
      "step": 398220
    },
    {
      "epoch": 642.32,
      "learning_rate": 0.035793128723064525,
      "loss": 0.6385,
      "step": 398240
    },
    {
      "epoch": 642.35,
      "learning_rate": 0.03578990291983872,
      "loss": 0.6365,
      "step": 398260
    },
    {
      "epoch": 642.39,
      "learning_rate": 0.03578667711661291,
      "loss": 0.6253,
      "step": 398280
    },
    {
      "epoch": 642.42,
      "learning_rate": 0.035783451313387095,
      "loss": 0.6318,
      "step": 398300
    },
    {
      "epoch": 642.45,
      "learning_rate": 0.03578022551016129,
      "loss": 0.6309,
      "step": 398320
    },
    {
      "epoch": 642.48,
      "learning_rate": 0.035776999706935486,
      "loss": 0.632,
      "step": 398340
    },
    {
      "epoch": 642.52,
      "learning_rate": 0.03577377390370968,
      "loss": 0.6472,
      "step": 398360
    },
    {
      "epoch": 642.55,
      "learning_rate": 0.03577054810048387,
      "loss": 0.6421,
      "step": 398380
    },
    {
      "epoch": 642.58,
      "learning_rate": 0.03576732229725807,
      "loss": 0.636,
      "step": 398400
    },
    {
      "epoch": 642.61,
      "learning_rate": 0.03576409649403226,
      "loss": 0.6451,
      "step": 398420
    },
    {
      "epoch": 642.65,
      "learning_rate": 0.035760870690806454,
      "loss": 0.6348,
      "step": 398440
    },
    {
      "epoch": 642.68,
      "learning_rate": 0.03575764488758065,
      "loss": 0.6406,
      "step": 398460
    },
    {
      "epoch": 642.71,
      "learning_rate": 0.035754419084354845,
      "loss": 0.6389,
      "step": 398480
    },
    {
      "epoch": 642.74,
      "learning_rate": 0.03575119328112904,
      "loss": 0.6442,
      "step": 398500
    },
    {
      "epoch": 642.77,
      "learning_rate": 0.03574796747790323,
      "loss": 0.6421,
      "step": 398520
    },
    {
      "epoch": 642.81,
      "learning_rate": 0.03574474167467743,
      "loss": 0.6398,
      "step": 398540
    },
    {
      "epoch": 642.84,
      "learning_rate": 0.03574151587145162,
      "loss": 0.6291,
      "step": 398560
    },
    {
      "epoch": 642.87,
      "learning_rate": 0.03573829006822581,
      "loss": 0.6226,
      "step": 398580
    },
    {
      "epoch": 642.9,
      "learning_rate": 0.035735064265,
      "loss": 0.6351,
      "step": 398600
    },
    {
      "epoch": 642.94,
      "learning_rate": 0.03573183846177419,
      "loss": 0.6488,
      "step": 398620
    },
    {
      "epoch": 642.97,
      "learning_rate": 0.03572861265854839,
      "loss": 0.6523,
      "step": 398640
    },
    {
      "epoch": 643.0,
      "learning_rate": 0.03572554814548388,
      "loss": 0.6405,
      "step": 398660
    },
    {
      "epoch": 643.0,
      "eval_accuracy": {
        "accuracy": 0.768167980641636
      },
      "eval_loss": 1.0089466571807861,
      "eval_runtime": 3.064,
      "eval_samples_per_second": 4181.129,
      "eval_steps_per_second": 65.6,
      "step": 398660
    },
    {
      "epoch": 643.03,
      "learning_rate": 0.03572232234225807,
      "loss": 0.623,
      "step": 398680
    },
    {
      "epoch": 643.06,
      "learning_rate": 0.03571909653903227,
      "loss": 0.6219,
      "step": 398700
    },
    {
      "epoch": 643.1,
      "learning_rate": 0.03571587073580646,
      "loss": 0.6291,
      "step": 398720
    },
    {
      "epoch": 643.13,
      "learning_rate": 0.035712644932580646,
      "loss": 0.6286,
      "step": 398740
    },
    {
      "epoch": 643.16,
      "learning_rate": 0.03570941912935484,
      "loss": 0.6427,
      "step": 398760
    },
    {
      "epoch": 643.19,
      "learning_rate": 0.03570619332612903,
      "loss": 0.6162,
      "step": 398780
    },
    {
      "epoch": 643.23,
      "learning_rate": 0.03570296752290322,
      "loss": 0.6254,
      "step": 398800
    },
    {
      "epoch": 643.26,
      "learning_rate": 0.03569974171967742,
      "loss": 0.6263,
      "step": 398820
    },
    {
      "epoch": 643.29,
      "learning_rate": 0.035696515916451614,
      "loss": 0.6239,
      "step": 398840
    },
    {
      "epoch": 643.32,
      "learning_rate": 0.035693290113225806,
      "loss": 0.6403,
      "step": 398860
    },
    {
      "epoch": 643.35,
      "learning_rate": 0.035690064310000005,
      "loss": 0.6475,
      "step": 398880
    },
    {
      "epoch": 643.39,
      "learning_rate": 0.0356868385067742,
      "loss": 0.6335,
      "step": 398900
    },
    {
      "epoch": 643.42,
      "learning_rate": 0.03568361270354839,
      "loss": 0.6254,
      "step": 398920
    },
    {
      "epoch": 643.45,
      "learning_rate": 0.03568038690032259,
      "loss": 0.6281,
      "step": 398940
    },
    {
      "epoch": 643.48,
      "learning_rate": 0.03567716109709678,
      "loss": 0.6415,
      "step": 398960
    },
    {
      "epoch": 643.52,
      "learning_rate": 0.03567393529387097,
      "loss": 0.6341,
      "step": 398980
    },
    {
      "epoch": 643.55,
      "learning_rate": 0.03567070949064517,
      "loss": 0.6282,
      "step": 399000
    },
    {
      "epoch": 643.58,
      "learning_rate": 0.035667483687419364,
      "loss": 0.6344,
      "step": 399020
    },
    {
      "epoch": 643.61,
      "learning_rate": 0.035664257884193556,
      "loss": 0.6409,
      "step": 399040
    },
    {
      "epoch": 643.65,
      "learning_rate": 0.03566103208096774,
      "loss": 0.6456,
      "step": 399060
    },
    {
      "epoch": 643.68,
      "learning_rate": 0.035657806277741934,
      "loss": 0.6507,
      "step": 399080
    },
    {
      "epoch": 643.71,
      "learning_rate": 0.035654580474516126,
      "loss": 0.6379,
      "step": 399100
    },
    {
      "epoch": 643.74,
      "learning_rate": 0.035651354671290325,
      "loss": 0.6375,
      "step": 399120
    },
    {
      "epoch": 643.77,
      "learning_rate": 0.03564812886806452,
      "loss": 0.6418,
      "step": 399140
    },
    {
      "epoch": 643.81,
      "learning_rate": 0.03564490306483871,
      "loss": 0.6414,
      "step": 399160
    },
    {
      "epoch": 643.84,
      "learning_rate": 0.03564167726161291,
      "loss": 0.6442,
      "step": 399180
    },
    {
      "epoch": 643.87,
      "learning_rate": 0.0356384514583871,
      "loss": 0.6445,
      "step": 399200
    },
    {
      "epoch": 643.9,
      "learning_rate": 0.03563522565516129,
      "loss": 0.6304,
      "step": 399220
    },
    {
      "epoch": 643.94,
      "learning_rate": 0.03563199985193549,
      "loss": 0.6405,
      "step": 399240
    },
    {
      "epoch": 643.97,
      "learning_rate": 0.035628774048709684,
      "loss": 0.6366,
      "step": 399260
    },
    {
      "epoch": 644.0,
      "learning_rate": 0.035625548245483876,
      "loss": 0.629,
      "step": 399280
    },
    {
      "epoch": 644.0,
      "eval_accuracy": {
        "accuracy": 0.7699633127780814
      },
      "eval_loss": 1.0040521621704102,
      "eval_runtime": 2.8868,
      "eval_samples_per_second": 4437.808,
      "eval_steps_per_second": 69.628,
      "step": 399280
    },
    {
      "epoch": 644.03,
      "learning_rate": 0.03562232244225807,
      "loss": 0.6514,
      "step": 399300
    },
    {
      "epoch": 644.06,
      "learning_rate": 0.03561909663903227,
      "loss": 0.6307,
      "step": 399320
    },
    {
      "epoch": 644.1,
      "learning_rate": 0.03561587083580646,
      "loss": 0.6407,
      "step": 399340
    },
    {
      "epoch": 644.13,
      "learning_rate": 0.03561264503258065,
      "loss": 0.6209,
      "step": 399360
    },
    {
      "epoch": 644.16,
      "learning_rate": 0.03560941922935484,
      "loss": 0.6309,
      "step": 399380
    },
    {
      "epoch": 644.19,
      "learning_rate": 0.03560619342612903,
      "loss": 0.6143,
      "step": 399400
    },
    {
      "epoch": 644.23,
      "learning_rate": 0.03560296762290323,
      "loss": 0.6256,
      "step": 399420
    },
    {
      "epoch": 644.26,
      "learning_rate": 0.03559974181967742,
      "loss": 0.6229,
      "step": 399440
    },
    {
      "epoch": 644.29,
      "learning_rate": 0.03559651601645161,
      "loss": 0.6195,
      "step": 399460
    },
    {
      "epoch": 644.32,
      "learning_rate": 0.03559329021322581,
      "loss": 0.6286,
      "step": 399480
    },
    {
      "epoch": 644.35,
      "learning_rate": 0.035590064410000004,
      "loss": 0.6397,
      "step": 399500
    },
    {
      "epoch": 644.39,
      "learning_rate": 0.035586838606774196,
      "loss": 0.6275,
      "step": 399520
    },
    {
      "epoch": 644.42,
      "learning_rate": 0.035583612803548395,
      "loss": 0.6442,
      "step": 399540
    },
    {
      "epoch": 644.45,
      "learning_rate": 0.03558038700032259,
      "loss": 0.6284,
      "step": 399560
    },
    {
      "epoch": 644.48,
      "learning_rate": 0.03557716119709678,
      "loss": 0.6258,
      "step": 399580
    },
    {
      "epoch": 644.52,
      "learning_rate": 0.03557393539387097,
      "loss": 0.6398,
      "step": 399600
    },
    {
      "epoch": 644.55,
      "learning_rate": 0.03557070959064517,
      "loss": 0.6359,
      "step": 399620
    },
    {
      "epoch": 644.58,
      "learning_rate": 0.03556748378741936,
      "loss": 0.6331,
      "step": 399640
    },
    {
      "epoch": 644.61,
      "learning_rate": 0.035564257984193555,
      "loss": 0.6289,
      "step": 399660
    },
    {
      "epoch": 644.65,
      "learning_rate": 0.03556103218096774,
      "loss": 0.628,
      "step": 399680
    },
    {
      "epoch": 644.68,
      "learning_rate": 0.03555780637774193,
      "loss": 0.6379,
      "step": 399700
    },
    {
      "epoch": 644.71,
      "learning_rate": 0.03555458057451613,
      "loss": 0.6409,
      "step": 399720
    },
    {
      "epoch": 644.74,
      "learning_rate": 0.035551354771290324,
      "loss": 0.625,
      "step": 399740
    },
    {
      "epoch": 644.77,
      "learning_rate": 0.035548128968064516,
      "loss": 0.6273,
      "step": 399760
    },
    {
      "epoch": 644.81,
      "learning_rate": 0.035544903164838715,
      "loss": 0.6356,
      "step": 399780
    },
    {
      "epoch": 644.84,
      "learning_rate": 0.03554167736161291,
      "loss": 0.6455,
      "step": 399800
    },
    {
      "epoch": 644.87,
      "learning_rate": 0.0355384515583871,
      "loss": 0.6322,
      "step": 399820
    },
    {
      "epoch": 644.9,
      "learning_rate": 0.03553522575516129,
      "loss": 0.6599,
      "step": 399840
    },
    {
      "epoch": 644.94,
      "learning_rate": 0.03553199995193549,
      "loss": 0.6402,
      "step": 399860
    },
    {
      "epoch": 644.97,
      "learning_rate": 0.03552877414870968,
      "loss": 0.6388,
      "step": 399880
    },
    {
      "epoch": 645.0,
      "learning_rate": 0.035525548345483875,
      "loss": 0.6446,
      "step": 399900
    },
    {
      "epoch": 645.0,
      "eval_accuracy": {
        "accuracy": 0.7703536023729607
      },
      "eval_loss": 1.0019810199737549,
      "eval_runtime": 2.9921,
      "eval_samples_per_second": 4281.613,
      "eval_steps_per_second": 67.177,
      "step": 399900
    },
    {
      "epoch": 645.03,
      "learning_rate": 0.035522322542258074,
      "loss": 0.6509,
      "step": 399920
    },
    {
      "epoch": 645.06,
      "learning_rate": 0.035519096739032266,
      "loss": 0.6296,
      "step": 399940
    },
    {
      "epoch": 645.1,
      "learning_rate": 0.03551587093580646,
      "loss": 0.6331,
      "step": 399960
    },
    {
      "epoch": 645.13,
      "learning_rate": 0.03551264513258066,
      "loss": 0.6325,
      "step": 399980
    },
    {
      "epoch": 645.16,
      "learning_rate": 0.035509419329354835,
      "loss": 0.6437,
      "step": 400000
    },
    {
      "epoch": 645.19,
      "learning_rate": 0.035506193526129035,
      "loss": 0.6256,
      "step": 400020
    },
    {
      "epoch": 645.23,
      "learning_rate": 0.03550296772290323,
      "loss": 0.6427,
      "step": 400040
    },
    {
      "epoch": 645.26,
      "learning_rate": 0.03549974191967742,
      "loss": 0.629,
      "step": 400060
    },
    {
      "epoch": 645.29,
      "learning_rate": 0.03549651611645162,
      "loss": 0.6317,
      "step": 400080
    },
    {
      "epoch": 645.32,
      "learning_rate": 0.03549329031322581,
      "loss": 0.6398,
      "step": 400100
    },
    {
      "epoch": 645.35,
      "learning_rate": 0.03549006451,
      "loss": 0.6351,
      "step": 400120
    },
    {
      "epoch": 645.39,
      "learning_rate": 0.035486838706774194,
      "loss": 0.6316,
      "step": 400140
    },
    {
      "epoch": 645.42,
      "learning_rate": 0.035483612903548394,
      "loss": 0.6112,
      "step": 400160
    },
    {
      "epoch": 645.45,
      "learning_rate": 0.035480387100322586,
      "loss": 0.6239,
      "step": 400180
    },
    {
      "epoch": 645.48,
      "learning_rate": 0.03547716129709678,
      "loss": 0.6168,
      "step": 400200
    },
    {
      "epoch": 645.52,
      "learning_rate": 0.03547393549387098,
      "loss": 0.6355,
      "step": 400220
    },
    {
      "epoch": 645.55,
      "learning_rate": 0.03547070969064517,
      "loss": 0.6402,
      "step": 400240
    },
    {
      "epoch": 645.58,
      "learning_rate": 0.03546748388741936,
      "loss": 0.6374,
      "step": 400260
    },
    {
      "epoch": 645.61,
      "learning_rate": 0.03546425808419356,
      "loss": 0.634,
      "step": 400280
    },
    {
      "epoch": 645.65,
      "learning_rate": 0.03546103228096774,
      "loss": 0.6347,
      "step": 400300
    },
    {
      "epoch": 645.68,
      "learning_rate": 0.03545780647774194,
      "loss": 0.6372,
      "step": 400320
    },
    {
      "epoch": 645.71,
      "learning_rate": 0.03545458067451613,
      "loss": 0.6338,
      "step": 400340
    },
    {
      "epoch": 645.74,
      "learning_rate": 0.03545135487129032,
      "loss": 0.6391,
      "step": 400360
    },
    {
      "epoch": 645.77,
      "learning_rate": 0.035448129068064514,
      "loss": 0.6457,
      "step": 400380
    },
    {
      "epoch": 645.81,
      "learning_rate": 0.03544490326483871,
      "loss": 0.6478,
      "step": 400400
    },
    {
      "epoch": 645.84,
      "learning_rate": 0.035441677461612905,
      "loss": 0.6323,
      "step": 400420
    },
    {
      "epoch": 645.87,
      "learning_rate": 0.0354384516583871,
      "loss": 0.6404,
      "step": 400440
    },
    {
      "epoch": 645.9,
      "learning_rate": 0.0354352258551613,
      "loss": 0.6467,
      "step": 400460
    },
    {
      "epoch": 645.94,
      "learning_rate": 0.03543200005193549,
      "loss": 0.6481,
      "step": 400480
    },
    {
      "epoch": 645.97,
      "learning_rate": 0.03542877424870968,
      "loss": 0.6212,
      "step": 400500
    },
    {
      "epoch": 646.0,
      "learning_rate": 0.03542554844548388,
      "loss": 0.6555,
      "step": 400520
    },
    {
      "epoch": 646.0,
      "eval_accuracy": {
        "accuracy": 0.7639528530169386
      },
      "eval_loss": 1.0134416818618774,
      "eval_runtime": 2.9744,
      "eval_samples_per_second": 4307.082,
      "eval_steps_per_second": 67.577,
      "step": 400520
    },
    {
      "epoch": 646.03,
      "learning_rate": 0.03542232264225807,
      "loss": 0.6426,
      "step": 400540
    },
    {
      "epoch": 646.06,
      "learning_rate": 0.035419096839032264,
      "loss": 0.6325,
      "step": 400560
    },
    {
      "epoch": 646.1,
      "learning_rate": 0.035415871035806464,
      "loss": 0.6242,
      "step": 400580
    },
    {
      "epoch": 646.13,
      "learning_rate": 0.035412645232580656,
      "loss": 0.6163,
      "step": 400600
    },
    {
      "epoch": 646.16,
      "learning_rate": 0.03540941942935484,
      "loss": 0.6119,
      "step": 400620
    },
    {
      "epoch": 646.19,
      "learning_rate": 0.03540619362612903,
      "loss": 0.6413,
      "step": 400640
    },
    {
      "epoch": 646.23,
      "learning_rate": 0.035402967822903225,
      "loss": 0.6174,
      "step": 400660
    },
    {
      "epoch": 646.26,
      "learning_rate": 0.03539974201967742,
      "loss": 0.6391,
      "step": 400680
    },
    {
      "epoch": 646.29,
      "learning_rate": 0.035396516216451616,
      "loss": 0.6239,
      "step": 400700
    },
    {
      "epoch": 646.32,
      "learning_rate": 0.03539329041322581,
      "loss": 0.6296,
      "step": 400720
    },
    {
      "epoch": 646.35,
      "learning_rate": 0.03539006461,
      "loss": 0.6338,
      "step": 400740
    },
    {
      "epoch": 646.39,
      "learning_rate": 0.0353868388067742,
      "loss": 0.6394,
      "step": 400760
    },
    {
      "epoch": 646.42,
      "learning_rate": 0.03538361300354839,
      "loss": 0.6343,
      "step": 400780
    },
    {
      "epoch": 646.45,
      "learning_rate": 0.035380387200322584,
      "loss": 0.6271,
      "step": 400800
    },
    {
      "epoch": 646.48,
      "learning_rate": 0.03537716139709678,
      "loss": 0.6328,
      "step": 400820
    },
    {
      "epoch": 646.52,
      "learning_rate": 0.035373935593870975,
      "loss": 0.6284,
      "step": 400840
    },
    {
      "epoch": 646.55,
      "learning_rate": 0.03537070979064517,
      "loss": 0.6397,
      "step": 400860
    },
    {
      "epoch": 646.58,
      "learning_rate": 0.03536748398741936,
      "loss": 0.6423,
      "step": 400880
    },
    {
      "epoch": 646.61,
      "learning_rate": 0.03536425818419356,
      "loss": 0.646,
      "step": 400900
    },
    {
      "epoch": 646.65,
      "learning_rate": 0.03536103238096774,
      "loss": 0.6533,
      "step": 400920
    },
    {
      "epoch": 646.68,
      "learning_rate": 0.035357806577741936,
      "loss": 0.6378,
      "step": 400940
    },
    {
      "epoch": 646.71,
      "learning_rate": 0.03535458077451613,
      "loss": 0.6353,
      "step": 400960
    },
    {
      "epoch": 646.74,
      "learning_rate": 0.03535135497129032,
      "loss": 0.6401,
      "step": 400980
    },
    {
      "epoch": 646.77,
      "learning_rate": 0.03534812916806452,
      "loss": 0.6501,
      "step": 401000
    },
    {
      "epoch": 646.81,
      "learning_rate": 0.03534490336483871,
      "loss": 0.6378,
      "step": 401020
    },
    {
      "epoch": 646.84,
      "learning_rate": 0.035341677561612904,
      "loss": 0.6494,
      "step": 401040
    },
    {
      "epoch": 646.87,
      "learning_rate": 0.0353384517583871,
      "loss": 0.6297,
      "step": 401060
    },
    {
      "epoch": 646.9,
      "learning_rate": 0.035335225955161295,
      "loss": 0.6451,
      "step": 401080
    },
    {
      "epoch": 646.94,
      "learning_rate": 0.03533200015193549,
      "loss": 0.6348,
      "step": 401100
    },
    {
      "epoch": 646.97,
      "learning_rate": 0.03532877434870968,
      "loss": 0.6285,
      "step": 401120
    },
    {
      "epoch": 647.0,
      "learning_rate": 0.03532570983564516,
      "loss": 0.6222,
      "step": 401140
    },
    {
      "epoch": 647.0,
      "eval_accuracy": {
        "accuracy": 0.7733198032940442
      },
      "eval_loss": 0.9912844896316528,
      "eval_runtime": 3.2672,
      "eval_samples_per_second": 3921.089,
      "eval_steps_per_second": 61.52,
      "step": 401140
    },
    {
      "epoch": 647.03,
      "learning_rate": 0.03532248403241936,
      "loss": 0.6313,
      "step": 401160
    },
    {
      "epoch": 647.06,
      "learning_rate": 0.03531925822919355,
      "loss": 0.6193,
      "step": 401180
    },
    {
      "epoch": 647.1,
      "learning_rate": 0.035316032425967744,
      "loss": 0.6193,
      "step": 401200
    },
    {
      "epoch": 647.13,
      "learning_rate": 0.03531280662274194,
      "loss": 0.6118,
      "step": 401220
    },
    {
      "epoch": 647.16,
      "learning_rate": 0.035309580819516136,
      "loss": 0.6242,
      "step": 401240
    },
    {
      "epoch": 647.19,
      "learning_rate": 0.03530635501629033,
      "loss": 0.622,
      "step": 401260
    },
    {
      "epoch": 647.23,
      "learning_rate": 0.03530312921306452,
      "loss": 0.6279,
      "step": 401280
    },
    {
      "epoch": 647.26,
      "learning_rate": 0.03529990340983872,
      "loss": 0.6278,
      "step": 401300
    },
    {
      "epoch": 647.29,
      "learning_rate": 0.03529667760661291,
      "loss": 0.6329,
      "step": 401320
    },
    {
      "epoch": 647.32,
      "learning_rate": 0.0352934518033871,
      "loss": 0.6266,
      "step": 401340
    },
    {
      "epoch": 647.35,
      "learning_rate": 0.0352902260001613,
      "loss": 0.6344,
      "step": 401360
    },
    {
      "epoch": 647.39,
      "learning_rate": 0.03528700019693548,
      "loss": 0.636,
      "step": 401380
    },
    {
      "epoch": 647.42,
      "learning_rate": 0.03528377439370968,
      "loss": 0.6082,
      "step": 401400
    },
    {
      "epoch": 647.45,
      "learning_rate": 0.03528054859048387,
      "loss": 0.6211,
      "step": 401420
    },
    {
      "epoch": 647.48,
      "learning_rate": 0.035277322787258064,
      "loss": 0.621,
      "step": 401440
    },
    {
      "epoch": 647.52,
      "learning_rate": 0.035274096984032256,
      "loss": 0.6339,
      "step": 401460
    },
    {
      "epoch": 647.55,
      "learning_rate": 0.035270871180806455,
      "loss": 0.6278,
      "step": 401480
    },
    {
      "epoch": 647.58,
      "learning_rate": 0.03526764537758065,
      "loss": 0.651,
      "step": 401500
    },
    {
      "epoch": 647.61,
      "learning_rate": 0.03526441957435484,
      "loss": 0.6262,
      "step": 401520
    },
    {
      "epoch": 647.65,
      "learning_rate": 0.03526119377112904,
      "loss": 0.6329,
      "step": 401540
    },
    {
      "epoch": 647.68,
      "learning_rate": 0.03525796796790323,
      "loss": 0.6257,
      "step": 401560
    },
    {
      "epoch": 647.71,
      "learning_rate": 0.03525474216467742,
      "loss": 0.6258,
      "step": 401580
    },
    {
      "epoch": 647.74,
      "learning_rate": 0.03525151636145162,
      "loss": 0.6283,
      "step": 401600
    },
    {
      "epoch": 647.77,
      "learning_rate": 0.035248290558225814,
      "loss": 0.6394,
      "step": 401620
    },
    {
      "epoch": 647.81,
      "learning_rate": 0.035245064755000007,
      "loss": 0.6394,
      "step": 401640
    },
    {
      "epoch": 647.84,
      "learning_rate": 0.035241838951774206,
      "loss": 0.6418,
      "step": 401660
    },
    {
      "epoch": 647.87,
      "learning_rate": 0.0352386131485484,
      "loss": 0.6501,
      "step": 401680
    },
    {
      "epoch": 647.9,
      "learning_rate": 0.03523538734532258,
      "loss": 0.623,
      "step": 401700
    },
    {
      "epoch": 647.94,
      "learning_rate": 0.035232161542096775,
      "loss": 0.6411,
      "step": 401720
    },
    {
      "epoch": 647.97,
      "learning_rate": 0.03522893573887097,
      "loss": 0.6313,
      "step": 401740
    },
    {
      "epoch": 648.0,
      "learning_rate": 0.03522570993564516,
      "loss": 0.6231,
      "step": 401760
    },
    {
      "epoch": 648.0,
      "eval_accuracy": {
        "accuracy": 0.7737881508078994
      },
      "eval_loss": 0.9822038412094116,
      "eval_runtime": 3.118,
      "eval_samples_per_second": 4108.741,
      "eval_steps_per_second": 64.465,
      "step": 401760
    },
    {
      "epoch": 648.03,
      "learning_rate": 0.03522248413241936,
      "loss": 0.6275,
      "step": 401780
    },
    {
      "epoch": 648.06,
      "learning_rate": 0.03521925832919355,
      "loss": 0.6386,
      "step": 401800
    },
    {
      "epoch": 648.1,
      "learning_rate": 0.03521603252596774,
      "loss": 0.6336,
      "step": 401820
    },
    {
      "epoch": 648.13,
      "learning_rate": 0.03521280672274194,
      "loss": 0.6508,
      "step": 401840
    },
    {
      "epoch": 648.16,
      "learning_rate": 0.035209580919516134,
      "loss": 0.6262,
      "step": 401860
    },
    {
      "epoch": 648.19,
      "learning_rate": 0.035206355116290326,
      "loss": 0.6047,
      "step": 401880
    },
    {
      "epoch": 648.23,
      "learning_rate": 0.035203129313064525,
      "loss": 0.6313,
      "step": 401900
    },
    {
      "epoch": 648.26,
      "learning_rate": 0.03519990350983872,
      "loss": 0.6255,
      "step": 401920
    },
    {
      "epoch": 648.29,
      "learning_rate": 0.03519667770661291,
      "loss": 0.6227,
      "step": 401940
    },
    {
      "epoch": 648.32,
      "learning_rate": 0.0351934519033871,
      "loss": 0.6344,
      "step": 401960
    },
    {
      "epoch": 648.35,
      "learning_rate": 0.0351902261001613,
      "loss": 0.6285,
      "step": 401980
    },
    {
      "epoch": 648.39,
      "learning_rate": 0.03518700029693548,
      "loss": 0.6262,
      "step": 402000
    },
    {
      "epoch": 648.42,
      "learning_rate": 0.03518377449370968,
      "loss": 0.6373,
      "step": 402020
    },
    {
      "epoch": 648.45,
      "learning_rate": 0.03518054869048387,
      "loss": 0.627,
      "step": 402040
    },
    {
      "epoch": 648.48,
      "learning_rate": 0.03517732288725806,
      "loss": 0.6346,
      "step": 402060
    },
    {
      "epoch": 648.52,
      "learning_rate": 0.03517409708403226,
      "loss": 0.6312,
      "step": 402080
    },
    {
      "epoch": 648.55,
      "learning_rate": 0.035170871280806454,
      "loss": 0.6431,
      "step": 402100
    },
    {
      "epoch": 648.58,
      "learning_rate": 0.035167645477580646,
      "loss": 0.6259,
      "step": 402120
    },
    {
      "epoch": 648.61,
      "learning_rate": 0.035164419674354845,
      "loss": 0.6513,
      "step": 402140
    },
    {
      "epoch": 648.65,
      "learning_rate": 0.03516119387112904,
      "loss": 0.6356,
      "step": 402160
    },
    {
      "epoch": 648.68,
      "learning_rate": 0.03515796806790323,
      "loss": 0.63,
      "step": 402180
    },
    {
      "epoch": 648.71,
      "learning_rate": 0.03515474226467742,
      "loss": 0.6243,
      "step": 402200
    },
    {
      "epoch": 648.74,
      "learning_rate": 0.03515151646145162,
      "loss": 0.6272,
      "step": 402220
    },
    {
      "epoch": 648.77,
      "learning_rate": 0.03514829065822581,
      "loss": 0.623,
      "step": 402240
    },
    {
      "epoch": 648.81,
      "learning_rate": 0.035145064855000005,
      "loss": 0.6357,
      "step": 402260
    },
    {
      "epoch": 648.84,
      "learning_rate": 0.035141839051774204,
      "loss": 0.6435,
      "step": 402280
    },
    {
      "epoch": 648.87,
      "learning_rate": 0.035138613248548396,
      "loss": 0.6361,
      "step": 402300
    },
    {
      "epoch": 648.9,
      "learning_rate": 0.03513538744532258,
      "loss": 0.6378,
      "step": 402320
    },
    {
      "epoch": 648.94,
      "learning_rate": 0.035132161642096774,
      "loss": 0.647,
      "step": 402340
    },
    {
      "epoch": 648.97,
      "learning_rate": 0.035128935838870966,
      "loss": 0.6478,
      "step": 402360
    },
    {
      "epoch": 649.0,
      "learning_rate": 0.035125710035645165,
      "loss": 0.6353,
      "step": 402380
    },
    {
      "epoch": 649.0,
      "eval_accuracy": {
        "accuracy": 0.7680118648036843
      },
      "eval_loss": 1.0114439725875854,
      "eval_runtime": 4.3408,
      "eval_samples_per_second": 2951.313,
      "eval_steps_per_second": 46.305,
      "step": 402380
    },
    {
      "epoch": 649.03,
      "learning_rate": 0.03512248423241936,
      "loss": 0.6365,
      "step": 402400
    },
    {
      "epoch": 649.06,
      "learning_rate": 0.03511925842919355,
      "loss": 0.6178,
      "step": 402420
    },
    {
      "epoch": 649.1,
      "learning_rate": 0.03511603262596775,
      "loss": 0.6262,
      "step": 402440
    },
    {
      "epoch": 649.13,
      "learning_rate": 0.03511280682274194,
      "loss": 0.6341,
      "step": 402460
    },
    {
      "epoch": 649.16,
      "learning_rate": 0.03510958101951613,
      "loss": 0.617,
      "step": 402480
    },
    {
      "epoch": 649.19,
      "learning_rate": 0.035106355216290325,
      "loss": 0.6045,
      "step": 402500
    },
    {
      "epoch": 649.23,
      "learning_rate": 0.035103129413064524,
      "loss": 0.6112,
      "step": 402520
    },
    {
      "epoch": 649.26,
      "learning_rate": 0.035099903609838716,
      "loss": 0.6306,
      "step": 402540
    },
    {
      "epoch": 649.29,
      "learning_rate": 0.03509667780661291,
      "loss": 0.6224,
      "step": 402560
    },
    {
      "epoch": 649.32,
      "learning_rate": 0.03509345200338711,
      "loss": 0.6335,
      "step": 402580
    },
    {
      "epoch": 649.35,
      "learning_rate": 0.0350902262001613,
      "loss": 0.6322,
      "step": 402600
    },
    {
      "epoch": 649.39,
      "learning_rate": 0.035087000396935485,
      "loss": 0.6457,
      "step": 402620
    },
    {
      "epoch": 649.42,
      "learning_rate": 0.03508377459370968,
      "loss": 0.6335,
      "step": 402640
    },
    {
      "epoch": 649.45,
      "learning_rate": 0.03508054879048387,
      "loss": 0.6418,
      "step": 402660
    },
    {
      "epoch": 649.48,
      "learning_rate": 0.03507732298725807,
      "loss": 0.6315,
      "step": 402680
    },
    {
      "epoch": 649.52,
      "learning_rate": 0.03507409718403226,
      "loss": 0.6327,
      "step": 402700
    },
    {
      "epoch": 649.55,
      "learning_rate": 0.03507087138080645,
      "loss": 0.624,
      "step": 402720
    },
    {
      "epoch": 649.58,
      "learning_rate": 0.035067645577580644,
      "loss": 0.6457,
      "step": 402740
    },
    {
      "epoch": 649.61,
      "learning_rate": 0.035064419774354844,
      "loss": 0.6221,
      "step": 402760
    },
    {
      "epoch": 649.65,
      "learning_rate": 0.035061193971129036,
      "loss": 0.6377,
      "step": 402780
    },
    {
      "epoch": 649.68,
      "learning_rate": 0.03505796816790323,
      "loss": 0.6442,
      "step": 402800
    },
    {
      "epoch": 649.71,
      "learning_rate": 0.03505474236467743,
      "loss": 0.6332,
      "step": 402820
    },
    {
      "epoch": 649.74,
      "learning_rate": 0.03505151656145162,
      "loss": 0.6287,
      "step": 402840
    },
    {
      "epoch": 649.77,
      "learning_rate": 0.03504829075822581,
      "loss": 0.6364,
      "step": 402860
    },
    {
      "epoch": 649.81,
      "learning_rate": 0.03504506495500001,
      "loss": 0.6212,
      "step": 402880
    },
    {
      "epoch": 649.84,
      "learning_rate": 0.0350418391517742,
      "loss": 0.631,
      "step": 402900
    },
    {
      "epoch": 649.87,
      "learning_rate": 0.035038613348548395,
      "loss": 0.64,
      "step": 402920
    },
    {
      "epoch": 649.9,
      "learning_rate": 0.03503538754532258,
      "loss": 0.6362,
      "step": 402940
    },
    {
      "epoch": 649.94,
      "learning_rate": 0.03503216174209677,
      "loss": 0.6252,
      "step": 402960
    },
    {
      "epoch": 649.97,
      "learning_rate": 0.03502893593887097,
      "loss": 0.6231,
      "step": 402980
    },
    {
      "epoch": 650.0,
      "learning_rate": 0.03502571013564516,
      "loss": 0.6167,
      "step": 403000
    },
    {
      "epoch": 650.0,
      "eval_accuracy": {
        "accuracy": 0.7672312856139255
      },
      "eval_loss": 1.0006905794143677,
      "eval_runtime": 3.0011,
      "eval_samples_per_second": 4268.713,
      "eval_steps_per_second": 66.975,
      "step": 403000
    },
    {
      "epoch": 650.03,
      "learning_rate": 0.035022484332419355,
      "loss": 0.6318,
      "step": 403020
    },
    {
      "epoch": 650.06,
      "learning_rate": 0.03501925852919355,
      "loss": 0.6198,
      "step": 403040
    },
    {
      "epoch": 650.1,
      "learning_rate": 0.03501603272596775,
      "loss": 0.6431,
      "step": 403060
    },
    {
      "epoch": 650.13,
      "learning_rate": 0.03501280692274194,
      "loss": 0.6422,
      "step": 403080
    },
    {
      "epoch": 650.16,
      "learning_rate": 0.03500958111951613,
      "loss": 0.6288,
      "step": 403100
    },
    {
      "epoch": 650.19,
      "learning_rate": 0.03500635531629033,
      "loss": 0.6338,
      "step": 403120
    },
    {
      "epoch": 650.23,
      "learning_rate": 0.03500312951306452,
      "loss": 0.627,
      "step": 403140
    },
    {
      "epoch": 650.26,
      "learning_rate": 0.034999903709838714,
      "loss": 0.6306,
      "step": 403160
    },
    {
      "epoch": 650.29,
      "learning_rate": 0.034996677906612914,
      "loss": 0.6309,
      "step": 403180
    },
    {
      "epoch": 650.32,
      "learning_rate": 0.034993452103387106,
      "loss": 0.6281,
      "step": 403200
    },
    {
      "epoch": 650.35,
      "learning_rate": 0.0349902263001613,
      "loss": 0.6224,
      "step": 403220
    },
    {
      "epoch": 650.39,
      "learning_rate": 0.03498700049693548,
      "loss": 0.6283,
      "step": 403240
    },
    {
      "epoch": 650.42,
      "learning_rate": 0.034983774693709675,
      "loss": 0.6304,
      "step": 403260
    },
    {
      "epoch": 650.45,
      "learning_rate": 0.03498054889048387,
      "loss": 0.615,
      "step": 403280
    },
    {
      "epoch": 650.48,
      "learning_rate": 0.034977323087258066,
      "loss": 0.6176,
      "step": 403300
    },
    {
      "epoch": 650.52,
      "learning_rate": 0.03497409728403226,
      "loss": 0.6158,
      "step": 403320
    },
    {
      "epoch": 650.55,
      "learning_rate": 0.03497087148080645,
      "loss": 0.6126,
      "step": 403340
    },
    {
      "epoch": 650.58,
      "learning_rate": 0.03496764567758065,
      "loss": 0.6402,
      "step": 403360
    },
    {
      "epoch": 650.61,
      "learning_rate": 0.03496441987435484,
      "loss": 0.6452,
      "step": 403380
    },
    {
      "epoch": 650.65,
      "learning_rate": 0.034961194071129034,
      "loss": 0.6164,
      "step": 403400
    },
    {
      "epoch": 650.68,
      "learning_rate": 0.03495796826790323,
      "loss": 0.6144,
      "step": 403420
    },
    {
      "epoch": 650.71,
      "learning_rate": 0.034954742464677425,
      "loss": 0.6237,
      "step": 403440
    },
    {
      "epoch": 650.74,
      "learning_rate": 0.03495151666145162,
      "loss": 0.6413,
      "step": 403460
    },
    {
      "epoch": 650.77,
      "learning_rate": 0.03494829085822582,
      "loss": 0.6488,
      "step": 403480
    },
    {
      "epoch": 650.81,
      "learning_rate": 0.03494506505500001,
      "loss": 0.6197,
      "step": 403500
    },
    {
      "epoch": 650.84,
      "learning_rate": 0.0349418392517742,
      "loss": 0.6288,
      "step": 403520
    },
    {
      "epoch": 650.87,
      "learning_rate": 0.03493861344854839,
      "loss": 0.6336,
      "step": 403540
    },
    {
      "epoch": 650.9,
      "learning_rate": 0.03493538764532258,
      "loss": 0.6369,
      "step": 403560
    },
    {
      "epoch": 650.94,
      "learning_rate": 0.03493216184209677,
      "loss": 0.6333,
      "step": 403580
    },
    {
      "epoch": 650.97,
      "learning_rate": 0.03492893603887097,
      "loss": 0.648,
      "step": 403600
    },
    {
      "epoch": 651.0,
      "learning_rate": 0.03492587152580646,
      "loss": 0.6343,
      "step": 403620
    },
    {
      "epoch": 651.0,
      "eval_accuracy": {
        "accuracy": 0.7719928186714542
      },
      "eval_loss": 1.003024697303772,
      "eval_runtime": 2.8674,
      "eval_samples_per_second": 4467.802,
      "eval_steps_per_second": 70.098,
      "step": 403620
    },
    {
      "epoch": 651.03,
      "learning_rate": 0.03492264572258065,
      "loss": 0.6395,
      "step": 403640
    },
    {
      "epoch": 651.06,
      "learning_rate": 0.03491941991935485,
      "loss": 0.6055,
      "step": 403660
    },
    {
      "epoch": 651.1,
      "learning_rate": 0.03491619411612904,
      "loss": 0.6164,
      "step": 403680
    },
    {
      "epoch": 651.13,
      "learning_rate": 0.03491296831290323,
      "loss": 0.6325,
      "step": 403700
    },
    {
      "epoch": 651.16,
      "learning_rate": 0.03490974250967742,
      "loss": 0.6134,
      "step": 403720
    },
    {
      "epoch": 651.19,
      "learning_rate": 0.03490651670645161,
      "loss": 0.6189,
      "step": 403740
    },
    {
      "epoch": 651.23,
      "learning_rate": 0.03490329090322581,
      "loss": 0.6104,
      "step": 403760
    },
    {
      "epoch": 651.26,
      "learning_rate": 0.0349000651,
      "loss": 0.6345,
      "step": 403780
    },
    {
      "epoch": 651.29,
      "learning_rate": 0.034896839296774194,
      "loss": 0.6261,
      "step": 403800
    },
    {
      "epoch": 651.32,
      "learning_rate": 0.03489361349354839,
      "loss": 0.6192,
      "step": 403820
    },
    {
      "epoch": 651.35,
      "learning_rate": 0.034890387690322586,
      "loss": 0.6322,
      "step": 403840
    },
    {
      "epoch": 651.39,
      "learning_rate": 0.03488716188709678,
      "loss": 0.6369,
      "step": 403860
    },
    {
      "epoch": 651.42,
      "learning_rate": 0.03488393608387097,
      "loss": 0.6293,
      "step": 403880
    },
    {
      "epoch": 651.45,
      "learning_rate": 0.03488071028064517,
      "loss": 0.6197,
      "step": 403900
    },
    {
      "epoch": 651.48,
      "learning_rate": 0.03487748447741936,
      "loss": 0.635,
      "step": 403920
    },
    {
      "epoch": 651.52,
      "learning_rate": 0.03487425867419355,
      "loss": 0.6361,
      "step": 403940
    },
    {
      "epoch": 651.55,
      "learning_rate": 0.03487103287096775,
      "loss": 0.6182,
      "step": 403960
    },
    {
      "epoch": 651.58,
      "learning_rate": 0.034867807067741945,
      "loss": 0.628,
      "step": 403980
    },
    {
      "epoch": 651.61,
      "learning_rate": 0.03486458126451614,
      "loss": 0.6331,
      "step": 404000
    },
    {
      "epoch": 651.65,
      "learning_rate": 0.03486135546129032,
      "loss": 0.6309,
      "step": 404020
    },
    {
      "epoch": 651.68,
      "learning_rate": 0.034858129658064514,
      "loss": 0.638,
      "step": 404040
    },
    {
      "epoch": 651.71,
      "learning_rate": 0.03485490385483871,
      "loss": 0.6265,
      "step": 404060
    },
    {
      "epoch": 651.74,
      "learning_rate": 0.034851678051612905,
      "loss": 0.6385,
      "step": 404080
    },
    {
      "epoch": 651.77,
      "learning_rate": 0.0348484522483871,
      "loss": 0.641,
      "step": 404100
    },
    {
      "epoch": 651.81,
      "learning_rate": 0.03484522644516129,
      "loss": 0.635,
      "step": 404120
    },
    {
      "epoch": 651.84,
      "learning_rate": 0.03484200064193549,
      "loss": 0.6371,
      "step": 404140
    },
    {
      "epoch": 651.87,
      "learning_rate": 0.03483877483870968,
      "loss": 0.6482,
      "step": 404160
    },
    {
      "epoch": 651.9,
      "learning_rate": 0.03483554903548387,
      "loss": 0.632,
      "step": 404180
    },
    {
      "epoch": 651.94,
      "learning_rate": 0.03483232323225807,
      "loss": 0.6331,
      "step": 404200
    },
    {
      "epoch": 651.97,
      "learning_rate": 0.034829097429032264,
      "loss": 0.617,
      "step": 404220
    },
    {
      "epoch": 652.0,
      "learning_rate": 0.03482587162580646,
      "loss": 0.6382,
      "step": 404240
    },
    {
      "epoch": 652.0,
      "eval_accuracy": {
        "accuracy": 0.7710561236437437
      },
      "eval_loss": 0.994211733341217,
      "eval_runtime": 3.1779,
      "eval_samples_per_second": 4031.267,
      "eval_steps_per_second": 63.249,
      "step": 404240
    },
    {
      "epoch": 652.03,
      "learning_rate": 0.034822645822580656,
      "loss": 0.629,
      "step": 404260
    },
    {
      "epoch": 652.06,
      "learning_rate": 0.03481942001935485,
      "loss": 0.6244,
      "step": 404280
    },
    {
      "epoch": 652.1,
      "learning_rate": 0.03481619421612904,
      "loss": 0.6201,
      "step": 404300
    },
    {
      "epoch": 652.13,
      "learning_rate": 0.034812968412903225,
      "loss": 0.6185,
      "step": 404320
    },
    {
      "epoch": 652.16,
      "learning_rate": 0.03480974260967742,
      "loss": 0.6284,
      "step": 404340
    },
    {
      "epoch": 652.19,
      "learning_rate": 0.03480651680645161,
      "loss": 0.6241,
      "step": 404360
    },
    {
      "epoch": 652.23,
      "learning_rate": 0.03480329100322581,
      "loss": 0.6408,
      "step": 404380
    },
    {
      "epoch": 652.26,
      "learning_rate": 0.0348000652,
      "loss": 0.6395,
      "step": 404400
    },
    {
      "epoch": 652.29,
      "learning_rate": 0.03479683939677419,
      "loss": 0.6291,
      "step": 404420
    },
    {
      "epoch": 652.32,
      "learning_rate": 0.03479361359354839,
      "loss": 0.6306,
      "step": 404440
    },
    {
      "epoch": 652.35,
      "learning_rate": 0.034790387790322584,
      "loss": 0.6213,
      "step": 404460
    },
    {
      "epoch": 652.39,
      "learning_rate": 0.034787161987096776,
      "loss": 0.6252,
      "step": 404480
    },
    {
      "epoch": 652.42,
      "learning_rate": 0.034783936183870975,
      "loss": 0.6145,
      "step": 404500
    },
    {
      "epoch": 652.45,
      "learning_rate": 0.03478071038064517,
      "loss": 0.6211,
      "step": 404520
    },
    {
      "epoch": 652.48,
      "learning_rate": 0.03477748457741936,
      "loss": 0.6111,
      "step": 404540
    },
    {
      "epoch": 652.52,
      "learning_rate": 0.03477425877419356,
      "loss": 0.6278,
      "step": 404560
    },
    {
      "epoch": 652.55,
      "learning_rate": 0.03477103297096775,
      "loss": 0.6316,
      "step": 404580
    },
    {
      "epoch": 652.58,
      "learning_rate": 0.03476780716774194,
      "loss": 0.6268,
      "step": 404600
    },
    {
      "epoch": 652.61,
      "learning_rate": 0.034764581364516135,
      "loss": 0.6308,
      "step": 404620
    },
    {
      "epoch": 652.65,
      "learning_rate": 0.03476135556129032,
      "loss": 0.6365,
      "step": 404640
    },
    {
      "epoch": 652.68,
      "learning_rate": 0.03475812975806451,
      "loss": 0.6377,
      "step": 404660
    },
    {
      "epoch": 652.71,
      "learning_rate": 0.03475490395483871,
      "loss": 0.6363,
      "step": 404680
    },
    {
      "epoch": 652.74,
      "learning_rate": 0.034751678151612904,
      "loss": 0.6132,
      "step": 404700
    },
    {
      "epoch": 652.77,
      "learning_rate": 0.034748452348387096,
      "loss": 0.6445,
      "step": 404720
    },
    {
      "epoch": 652.81,
      "learning_rate": 0.034745226545161295,
      "loss": 0.6299,
      "step": 404740
    },
    {
      "epoch": 652.84,
      "learning_rate": 0.03474200074193549,
      "loss": 0.6243,
      "step": 404760
    },
    {
      "epoch": 652.87,
      "learning_rate": 0.03473877493870968,
      "loss": 0.645,
      "step": 404780
    },
    {
      "epoch": 652.9,
      "learning_rate": 0.03473554913548388,
      "loss": 0.6481,
      "step": 404800
    },
    {
      "epoch": 652.94,
      "learning_rate": 0.03473232333225807,
      "loss": 0.6362,
      "step": 404820
    },
    {
      "epoch": 652.97,
      "learning_rate": 0.03472909752903226,
      "loss": 0.6435,
      "step": 404840
    },
    {
      "epoch": 653.0,
      "learning_rate": 0.034725871725806455,
      "loss": 0.6259,
      "step": 404860
    },
    {
      "epoch": 653.0,
      "eval_accuracy": {
        "accuracy": 0.7751931933494653
      },
      "eval_loss": 0.9778238534927368,
      "eval_runtime": 3.0597,
      "eval_samples_per_second": 4187.061,
      "eval_steps_per_second": 65.693,
      "step": 404860
    },
    {
      "epoch": 653.03,
      "learning_rate": 0.034722645922580654,
      "loss": 0.6415,
      "step": 404880
    },
    {
      "epoch": 653.06,
      "learning_rate": 0.034719420119354846,
      "loss": 0.6267,
      "step": 404900
    },
    {
      "epoch": 653.1,
      "learning_rate": 0.03471619431612904,
      "loss": 0.5952,
      "step": 404920
    },
    {
      "epoch": 653.13,
      "learning_rate": 0.034712968512903224,
      "loss": 0.6234,
      "step": 404940
    },
    {
      "epoch": 653.16,
      "learning_rate": 0.034709742709677416,
      "loss": 0.6166,
      "step": 404960
    },
    {
      "epoch": 653.19,
      "learning_rate": 0.034706516906451615,
      "loss": 0.6281,
      "step": 404980
    },
    {
      "epoch": 653.23,
      "learning_rate": 0.03470329110322581,
      "loss": 0.6361,
      "step": 405000
    },
    {
      "epoch": 653.26,
      "learning_rate": 0.0347000653,
      "loss": 0.6342,
      "step": 405020
    },
    {
      "epoch": 653.29,
      "learning_rate": 0.0346968394967742,
      "loss": 0.6224,
      "step": 405040
    },
    {
      "epoch": 653.32,
      "learning_rate": 0.03469361369354839,
      "loss": 0.6266,
      "step": 405060
    },
    {
      "epoch": 653.35,
      "learning_rate": 0.03469038789032258,
      "loss": 0.6326,
      "step": 405080
    },
    {
      "epoch": 653.39,
      "learning_rate": 0.03468716208709678,
      "loss": 0.6288,
      "step": 405100
    },
    {
      "epoch": 653.42,
      "learning_rate": 0.034683936283870974,
      "loss": 0.6303,
      "step": 405120
    },
    {
      "epoch": 653.45,
      "learning_rate": 0.034680710480645166,
      "loss": 0.6283,
      "step": 405140
    },
    {
      "epoch": 653.48,
      "learning_rate": 0.03467748467741936,
      "loss": 0.6327,
      "step": 405160
    },
    {
      "epoch": 653.52,
      "learning_rate": 0.03467425887419356,
      "loss": 0.6286,
      "step": 405180
    },
    {
      "epoch": 653.55,
      "learning_rate": 0.03467103307096775,
      "loss": 0.6456,
      "step": 405200
    },
    {
      "epoch": 653.58,
      "learning_rate": 0.03466780726774194,
      "loss": 0.6239,
      "step": 405220
    },
    {
      "epoch": 653.61,
      "learning_rate": 0.03466458146451614,
      "loss": 0.6395,
      "step": 405240
    },
    {
      "epoch": 653.65,
      "learning_rate": 0.03466135566129032,
      "loss": 0.6218,
      "step": 405260
    },
    {
      "epoch": 653.68,
      "learning_rate": 0.03465812985806452,
      "loss": 0.6288,
      "step": 405280
    },
    {
      "epoch": 653.71,
      "learning_rate": 0.03465490405483871,
      "loss": 0.639,
      "step": 405300
    },
    {
      "epoch": 653.74,
      "learning_rate": 0.0346516782516129,
      "loss": 0.641,
      "step": 405320
    },
    {
      "epoch": 653.77,
      "learning_rate": 0.0346484524483871,
      "loss": 0.6262,
      "step": 405340
    },
    {
      "epoch": 653.81,
      "learning_rate": 0.034645226645161294,
      "loss": 0.6138,
      "step": 405360
    },
    {
      "epoch": 653.84,
      "learning_rate": 0.034642000841935486,
      "loss": 0.6214,
      "step": 405380
    },
    {
      "epoch": 653.87,
      "learning_rate": 0.03463877503870968,
      "loss": 0.6287,
      "step": 405400
    },
    {
      "epoch": 653.9,
      "learning_rate": 0.03463554923548388,
      "loss": 0.6135,
      "step": 405420
    },
    {
      "epoch": 653.94,
      "learning_rate": 0.03463232343225807,
      "loss": 0.6328,
      "step": 405440
    },
    {
      "epoch": 653.97,
      "learning_rate": 0.03462909762903226,
      "loss": 0.6408,
      "step": 405460
    },
    {
      "epoch": 654.0,
      "learning_rate": 0.03462587182580646,
      "loss": 0.6335,
      "step": 405480
    },
    {
      "epoch": 654.0,
      "eval_accuracy": {
        "accuracy": 0.7710561236437437
      },
      "eval_loss": 1.0050814151763916,
      "eval_runtime": 2.8895,
      "eval_samples_per_second": 4433.607,
      "eval_steps_per_second": 69.562,
      "step": 405480
    },
    {
      "epoch": 654.03,
      "learning_rate": 0.03462264602258065,
      "loss": 0.6478,
      "step": 405500
    },
    {
      "epoch": 654.06,
      "learning_rate": 0.034619420219354845,
      "loss": 0.6119,
      "step": 405520
    },
    {
      "epoch": 654.1,
      "learning_rate": 0.034616194416129044,
      "loss": 0.6122,
      "step": 405540
    },
    {
      "epoch": 654.13,
      "learning_rate": 0.03461296861290322,
      "loss": 0.6223,
      "step": 405560
    },
    {
      "epoch": 654.16,
      "learning_rate": 0.03460974280967742,
      "loss": 0.6231,
      "step": 405580
    },
    {
      "epoch": 654.19,
      "learning_rate": 0.03460651700645161,
      "loss": 0.6241,
      "step": 405600
    },
    {
      "epoch": 654.23,
      "learning_rate": 0.034603291203225806,
      "loss": 0.6376,
      "step": 405620
    },
    {
      "epoch": 654.26,
      "learning_rate": 0.034600065400000005,
      "loss": 0.6323,
      "step": 405640
    },
    {
      "epoch": 654.29,
      "learning_rate": 0.0345968395967742,
      "loss": 0.6245,
      "step": 405660
    },
    {
      "epoch": 654.32,
      "learning_rate": 0.03459361379354839,
      "loss": 0.6173,
      "step": 405680
    },
    {
      "epoch": 654.35,
      "learning_rate": 0.03459038799032258,
      "loss": 0.6273,
      "step": 405700
    },
    {
      "epoch": 654.39,
      "learning_rate": 0.03458716218709678,
      "loss": 0.6296,
      "step": 405720
    },
    {
      "epoch": 654.42,
      "learning_rate": 0.03458393638387097,
      "loss": 0.6376,
      "step": 405740
    },
    {
      "epoch": 654.45,
      "learning_rate": 0.034580710580645165,
      "loss": 0.6314,
      "step": 405760
    },
    {
      "epoch": 654.48,
      "learning_rate": 0.034577484777419364,
      "loss": 0.6251,
      "step": 405780
    },
    {
      "epoch": 654.52,
      "learning_rate": 0.034574258974193556,
      "loss": 0.6236,
      "step": 405800
    },
    {
      "epoch": 654.55,
      "learning_rate": 0.03457103317096775,
      "loss": 0.628,
      "step": 405820
    },
    {
      "epoch": 654.58,
      "learning_rate": 0.03456780736774195,
      "loss": 0.6213,
      "step": 405840
    },
    {
      "epoch": 654.61,
      "learning_rate": 0.03456458156451614,
      "loss": 0.6365,
      "step": 405860
    },
    {
      "epoch": 654.65,
      "learning_rate": 0.034561355761290324,
      "loss": 0.6223,
      "step": 405880
    },
    {
      "epoch": 654.68,
      "learning_rate": 0.03455812995806452,
      "loss": 0.626,
      "step": 405900
    },
    {
      "epoch": 654.71,
      "learning_rate": 0.03455490415483871,
      "loss": 0.6227,
      "step": 405920
    },
    {
      "epoch": 654.74,
      "learning_rate": 0.0345516783516129,
      "loss": 0.6344,
      "step": 405940
    },
    {
      "epoch": 654.77,
      "learning_rate": 0.0345484525483871,
      "loss": 0.6333,
      "step": 405960
    },
    {
      "epoch": 654.81,
      "learning_rate": 0.03454522674516129,
      "loss": 0.6339,
      "step": 405980
    },
    {
      "epoch": 654.84,
      "learning_rate": 0.034542000941935484,
      "loss": 0.6164,
      "step": 406000
    },
    {
      "epoch": 654.87,
      "learning_rate": 0.03453877513870968,
      "loss": 0.6281,
      "step": 406020
    },
    {
      "epoch": 654.9,
      "learning_rate": 0.034535549335483876,
      "loss": 0.6135,
      "step": 406040
    },
    {
      "epoch": 654.94,
      "learning_rate": 0.03453232353225807,
      "loss": 0.6245,
      "step": 406060
    },
    {
      "epoch": 654.97,
      "learning_rate": 0.03452909772903227,
      "loss": 0.6324,
      "step": 406080
    },
    {
      "epoch": 655.0,
      "learning_rate": 0.03452587192580646,
      "loss": 0.6277,
      "step": 406100
    },
    {
      "epoch": 655.0,
      "eval_accuracy": {
        "accuracy": 0.7748809616735618
      },
      "eval_loss": 0.9824797511100769,
      "eval_runtime": 3.1564,
      "eval_samples_per_second": 4058.785,
      "eval_steps_per_second": 63.681,
      "step": 406100
    },
    {
      "epoch": 655.03,
      "learning_rate": 0.03452264612258065,
      "loss": 0.6395,
      "step": 406120
    },
    {
      "epoch": 655.06,
      "learning_rate": 0.03451942031935484,
      "loss": 0.6215,
      "step": 406140
    },
    {
      "epoch": 655.1,
      "learning_rate": 0.03451619451612904,
      "loss": 0.6223,
      "step": 406160
    },
    {
      "epoch": 655.13,
      "learning_rate": 0.03451296871290323,
      "loss": 0.6293,
      "step": 406180
    },
    {
      "epoch": 655.16,
      "learning_rate": 0.03450974290967742,
      "loss": 0.6189,
      "step": 406200
    },
    {
      "epoch": 655.19,
      "learning_rate": 0.03450651710645161,
      "loss": 0.6224,
      "step": 406220
    },
    {
      "epoch": 655.23,
      "learning_rate": 0.034503291303225804,
      "loss": 0.6131,
      "step": 406240
    },
    {
      "epoch": 655.26,
      "learning_rate": 0.0345000655,
      "loss": 0.6363,
      "step": 406260
    },
    {
      "epoch": 655.29,
      "learning_rate": 0.034496839696774195,
      "loss": 0.6252,
      "step": 406280
    },
    {
      "epoch": 655.32,
      "learning_rate": 0.03449361389354839,
      "loss": 0.6339,
      "step": 406300
    },
    {
      "epoch": 655.35,
      "learning_rate": 0.034490388090322587,
      "loss": 0.6143,
      "step": 406320
    },
    {
      "epoch": 655.39,
      "learning_rate": 0.03448716228709678,
      "loss": 0.6051,
      "step": 406340
    },
    {
      "epoch": 655.42,
      "learning_rate": 0.03448393648387097,
      "loss": 0.6169,
      "step": 406360
    },
    {
      "epoch": 655.45,
      "learning_rate": 0.03448071068064517,
      "loss": 0.6217,
      "step": 406380
    },
    {
      "epoch": 655.48,
      "learning_rate": 0.03447748487741936,
      "loss": 0.6296,
      "step": 406400
    },
    {
      "epoch": 655.52,
      "learning_rate": 0.034474259074193554,
      "loss": 0.6144,
      "step": 406420
    },
    {
      "epoch": 655.55,
      "learning_rate": 0.034471033270967746,
      "loss": 0.6233,
      "step": 406440
    },
    {
      "epoch": 655.58,
      "learning_rate": 0.034467807467741945,
      "loss": 0.6209,
      "step": 406460
    },
    {
      "epoch": 655.61,
      "learning_rate": 0.03446458166451614,
      "loss": 0.6316,
      "step": 406480
    },
    {
      "epoch": 655.65,
      "learning_rate": 0.03446135586129032,
      "loss": 0.6205,
      "step": 406500
    },
    {
      "epoch": 655.68,
      "learning_rate": 0.034458130058064515,
      "loss": 0.623,
      "step": 406520
    },
    {
      "epoch": 655.71,
      "learning_rate": 0.03445490425483871,
      "loss": 0.6292,
      "step": 406540
    },
    {
      "epoch": 655.74,
      "learning_rate": 0.034451678451612906,
      "loss": 0.6269,
      "step": 406560
    },
    {
      "epoch": 655.77,
      "learning_rate": 0.0344484526483871,
      "loss": 0.6438,
      "step": 406580
    },
    {
      "epoch": 655.81,
      "learning_rate": 0.03444522684516129,
      "loss": 0.6386,
      "step": 406600
    },
    {
      "epoch": 655.84,
      "learning_rate": 0.03444200104193549,
      "loss": 0.6305,
      "step": 406620
    },
    {
      "epoch": 655.87,
      "learning_rate": 0.03443877523870968,
      "loss": 0.6372,
      "step": 406640
    },
    {
      "epoch": 655.9,
      "learning_rate": 0.034435549435483874,
      "loss": 0.6456,
      "step": 406660
    },
    {
      "epoch": 655.94,
      "learning_rate": 0.034432323632258066,
      "loss": 0.6176,
      "step": 406680
    },
    {
      "epoch": 655.97,
      "learning_rate": 0.034429097829032265,
      "loss": 0.643,
      "step": 406700
    },
    {
      "epoch": 656.0,
      "learning_rate": 0.03442603331596775,
      "loss": 0.632,
      "step": 406720
    },
    {
      "epoch": 656.0,
      "eval_accuracy": {
        "accuracy": 0.77339786121302
      },
      "eval_loss": 0.9870051741600037,
      "eval_runtime": 3.1025,
      "eval_samples_per_second": 4129.276,
      "eval_steps_per_second": 64.787,
      "step": 406720
    },
    {
      "epoch": 656.03,
      "learning_rate": 0.03442280751274194,
      "loss": 0.6176,
      "step": 406740
    },
    {
      "epoch": 656.06,
      "learning_rate": 0.03441958170951613,
      "loss": 0.6158,
      "step": 406760
    },
    {
      "epoch": 656.1,
      "learning_rate": 0.03441635590629032,
      "loss": 0.6131,
      "step": 406780
    },
    {
      "epoch": 656.13,
      "learning_rate": 0.03441313010306452,
      "loss": 0.6045,
      "step": 406800
    },
    {
      "epoch": 656.16,
      "learning_rate": 0.034409904299838714,
      "loss": 0.6295,
      "step": 406820
    },
    {
      "epoch": 656.19,
      "learning_rate": 0.03440667849661291,
      "loss": 0.6229,
      "step": 406840
    },
    {
      "epoch": 656.23,
      "learning_rate": 0.034403452693387106,
      "loss": 0.629,
      "step": 406860
    },
    {
      "epoch": 656.26,
      "learning_rate": 0.0344002268901613,
      "loss": 0.622,
      "step": 406880
    },
    {
      "epoch": 656.29,
      "learning_rate": 0.03439700108693549,
      "loss": 0.6366,
      "step": 406900
    },
    {
      "epoch": 656.32,
      "learning_rate": 0.03439377528370969,
      "loss": 0.6266,
      "step": 406920
    },
    {
      "epoch": 656.35,
      "learning_rate": 0.03439054948048388,
      "loss": 0.6253,
      "step": 406940
    },
    {
      "epoch": 656.39,
      "learning_rate": 0.034387323677258066,
      "loss": 0.633,
      "step": 406960
    },
    {
      "epoch": 656.42,
      "learning_rate": 0.03438409787403226,
      "loss": 0.6176,
      "step": 406980
    },
    {
      "epoch": 656.45,
      "learning_rate": 0.03438087207080645,
      "loss": 0.6299,
      "step": 407000
    },
    {
      "epoch": 656.48,
      "learning_rate": 0.03437764626758064,
      "loss": 0.6092,
      "step": 407020
    },
    {
      "epoch": 656.52,
      "learning_rate": 0.03437442046435484,
      "loss": 0.6188,
      "step": 407040
    },
    {
      "epoch": 656.55,
      "learning_rate": 0.034371194661129034,
      "loss": 0.6207,
      "step": 407060
    },
    {
      "epoch": 656.58,
      "learning_rate": 0.034367968857903226,
      "loss": 0.6367,
      "step": 407080
    },
    {
      "epoch": 656.61,
      "learning_rate": 0.034364743054677425,
      "loss": 0.6276,
      "step": 407100
    },
    {
      "epoch": 656.65,
      "learning_rate": 0.03436151725145162,
      "loss": 0.6423,
      "step": 407120
    },
    {
      "epoch": 656.68,
      "learning_rate": 0.03435829144822581,
      "loss": 0.6265,
      "step": 407140
    },
    {
      "epoch": 656.71,
      "learning_rate": 0.03435506564500001,
      "loss": 0.6163,
      "step": 407160
    },
    {
      "epoch": 656.74,
      "learning_rate": 0.0343518398417742,
      "loss": 0.6418,
      "step": 407180
    },
    {
      "epoch": 656.77,
      "learning_rate": 0.03434861403854839,
      "loss": 0.6226,
      "step": 407200
    },
    {
      "epoch": 656.81,
      "learning_rate": 0.034345388235322585,
      "loss": 0.6405,
      "step": 407220
    },
    {
      "epoch": 656.84,
      "learning_rate": 0.034342162432096784,
      "loss": 0.6335,
      "step": 407240
    },
    {
      "epoch": 656.87,
      "learning_rate": 0.03433893662887097,
      "loss": 0.6426,
      "step": 407260
    },
    {
      "epoch": 656.9,
      "learning_rate": 0.03433571082564516,
      "loss": 0.6475,
      "step": 407280
    },
    {
      "epoch": 656.94,
      "learning_rate": 0.034332485022419354,
      "loss": 0.6294,
      "step": 407300
    },
    {
      "epoch": 656.97,
      "learning_rate": 0.034329259219193546,
      "loss": 0.6269,
      "step": 407320
    },
    {
      "epoch": 657.0,
      "learning_rate": 0.034326033415967745,
      "loss": 0.6336,
      "step": 407340
    },
    {
      "epoch": 657.0,
      "eval_accuracy": {
        "accuracy": 0.7717586449145266
      },
      "eval_loss": 0.9829668998718262,
      "eval_runtime": 3.9395,
      "eval_samples_per_second": 3251.921,
      "eval_steps_per_second": 51.021,
      "step": 407340
    },
    {
      "epoch": 657.03,
      "learning_rate": 0.03432280761274194,
      "loss": 0.6424,
      "step": 407360
    },
    {
      "epoch": 657.06,
      "learning_rate": 0.03431958180951613,
      "loss": 0.6432,
      "step": 407380
    },
    {
      "epoch": 657.1,
      "learning_rate": 0.03431635600629033,
      "loss": 0.6207,
      "step": 407400
    },
    {
      "epoch": 657.13,
      "learning_rate": 0.03431313020306452,
      "loss": 0.6049,
      "step": 407420
    },
    {
      "epoch": 657.16,
      "learning_rate": 0.03430990439983871,
      "loss": 0.6107,
      "step": 407440
    },
    {
      "epoch": 657.19,
      "learning_rate": 0.03430667859661291,
      "loss": 0.6414,
      "step": 407460
    },
    {
      "epoch": 657.23,
      "learning_rate": 0.034303452793387104,
      "loss": 0.6128,
      "step": 407480
    },
    {
      "epoch": 657.26,
      "learning_rate": 0.034300226990161296,
      "loss": 0.6296,
      "step": 407500
    },
    {
      "epoch": 657.29,
      "learning_rate": 0.03429700118693549,
      "loss": 0.6135,
      "step": 407520
    },
    {
      "epoch": 657.32,
      "learning_rate": 0.03429377538370969,
      "loss": 0.6047,
      "step": 407540
    },
    {
      "epoch": 657.35,
      "learning_rate": 0.03429054958048388,
      "loss": 0.6165,
      "step": 407560
    },
    {
      "epoch": 657.39,
      "learning_rate": 0.034287323777258065,
      "loss": 0.6254,
      "step": 407580
    },
    {
      "epoch": 657.42,
      "learning_rate": 0.03428409797403226,
      "loss": 0.6398,
      "step": 407600
    },
    {
      "epoch": 657.45,
      "learning_rate": 0.03428087217080645,
      "loss": 0.63,
      "step": 407620
    },
    {
      "epoch": 657.48,
      "learning_rate": 0.03427764636758065,
      "loss": 0.6211,
      "step": 407640
    },
    {
      "epoch": 657.52,
      "learning_rate": 0.03427442056435484,
      "loss": 0.6196,
      "step": 407660
    },
    {
      "epoch": 657.55,
      "learning_rate": 0.03427119476112903,
      "loss": 0.6111,
      "step": 407680
    },
    {
      "epoch": 657.58,
      "learning_rate": 0.03426796895790323,
      "loss": 0.6285,
      "step": 407700
    },
    {
      "epoch": 657.61,
      "learning_rate": 0.034264743154677424,
      "loss": 0.6306,
      "step": 407720
    },
    {
      "epoch": 657.65,
      "learning_rate": 0.034261517351451616,
      "loss": 0.6312,
      "step": 407740
    },
    {
      "epoch": 657.68,
      "learning_rate": 0.03425829154822581,
      "loss": 0.6255,
      "step": 407760
    },
    {
      "epoch": 657.71,
      "learning_rate": 0.03425506574500001,
      "loss": 0.6308,
      "step": 407780
    },
    {
      "epoch": 657.74,
      "learning_rate": 0.0342518399417742,
      "loss": 0.6406,
      "step": 407800
    },
    {
      "epoch": 657.77,
      "learning_rate": 0.03424861413854839,
      "loss": 0.6368,
      "step": 407820
    },
    {
      "epoch": 657.81,
      "learning_rate": 0.03424538833532259,
      "loss": 0.6294,
      "step": 407840
    },
    {
      "epoch": 657.84,
      "learning_rate": 0.03424216253209678,
      "loss": 0.6501,
      "step": 407860
    },
    {
      "epoch": 657.87,
      "learning_rate": 0.03423893672887097,
      "loss": 0.6273,
      "step": 407880
    },
    {
      "epoch": 657.9,
      "learning_rate": 0.03423571092564516,
      "loss": 0.6325,
      "step": 407900
    },
    {
      "epoch": 657.94,
      "learning_rate": 0.03423248512241935,
      "loss": 0.6238,
      "step": 407920
    },
    {
      "epoch": 657.97,
      "learning_rate": 0.03422925931919355,
      "loss": 0.6281,
      "step": 407940
    },
    {
      "epoch": 658.0,
      "learning_rate": 0.034226033515967744,
      "loss": 0.6221,
      "step": 407960
    },
    {
      "epoch": 658.0,
      "eval_accuracy": {
        "accuracy": 0.7722269924283819
      },
      "eval_loss": 0.9993337392807007,
      "eval_runtime": 2.9274,
      "eval_samples_per_second": 4376.188,
      "eval_steps_per_second": 68.661,
      "step": 407960
    },
    {
      "epoch": 658.03,
      "learning_rate": 0.034222807712741936,
      "loss": 0.638,
      "step": 407980
    },
    {
      "epoch": 658.06,
      "learning_rate": 0.034219581909516135,
      "loss": 0.6219,
      "step": 408000
    },
    {
      "epoch": 658.1,
      "learning_rate": 0.03421635610629033,
      "loss": 0.6318,
      "step": 408020
    },
    {
      "epoch": 658.13,
      "learning_rate": 0.03421313030306452,
      "loss": 0.6301,
      "step": 408040
    },
    {
      "epoch": 658.16,
      "learning_rate": 0.03420990449983871,
      "loss": 0.6176,
      "step": 408060
    },
    {
      "epoch": 658.19,
      "learning_rate": 0.03420667869661291,
      "loss": 0.6226,
      "step": 408080
    },
    {
      "epoch": 658.23,
      "learning_rate": 0.0342034528933871,
      "loss": 0.6155,
      "step": 408100
    },
    {
      "epoch": 658.26,
      "learning_rate": 0.034200227090161295,
      "loss": 0.6309,
      "step": 408120
    },
    {
      "epoch": 658.29,
      "learning_rate": 0.034197001286935494,
      "loss": 0.6234,
      "step": 408140
    },
    {
      "epoch": 658.32,
      "learning_rate": 0.034193775483709686,
      "loss": 0.6252,
      "step": 408160
    },
    {
      "epoch": 658.35,
      "learning_rate": 0.03419054968048388,
      "loss": 0.6332,
      "step": 408180
    },
    {
      "epoch": 658.39,
      "learning_rate": 0.03418732387725806,
      "loss": 0.625,
      "step": 408200
    },
    {
      "epoch": 658.42,
      "learning_rate": 0.034184098074032256,
      "loss": 0.6297,
      "step": 408220
    },
    {
      "epoch": 658.45,
      "learning_rate": 0.034180872270806455,
      "loss": 0.6297,
      "step": 408240
    },
    {
      "epoch": 658.48,
      "learning_rate": 0.03417764646758065,
      "loss": 0.618,
      "step": 408260
    },
    {
      "epoch": 658.52,
      "learning_rate": 0.03417442066435484,
      "loss": 0.6229,
      "step": 408280
    },
    {
      "epoch": 658.55,
      "learning_rate": 0.03417119486112903,
      "loss": 0.6353,
      "step": 408300
    },
    {
      "epoch": 658.58,
      "learning_rate": 0.03416796905790323,
      "loss": 0.6333,
      "step": 408320
    },
    {
      "epoch": 658.61,
      "learning_rate": 0.03416474325467742,
      "loss": 0.6295,
      "step": 408340
    },
    {
      "epoch": 658.65,
      "learning_rate": 0.034161517451451615,
      "loss": 0.6274,
      "step": 408360
    },
    {
      "epoch": 658.68,
      "learning_rate": 0.034158291648225814,
      "loss": 0.6224,
      "step": 408380
    },
    {
      "epoch": 658.71,
      "learning_rate": 0.034155065845000006,
      "loss": 0.6239,
      "step": 408400
    },
    {
      "epoch": 658.74,
      "learning_rate": 0.0341518400417742,
      "loss": 0.6261,
      "step": 408420
    },
    {
      "epoch": 658.77,
      "learning_rate": 0.0341486142385484,
      "loss": 0.6226,
      "step": 408440
    },
    {
      "epoch": 658.81,
      "learning_rate": 0.03414538843532259,
      "loss": 0.6256,
      "step": 408460
    },
    {
      "epoch": 658.84,
      "learning_rate": 0.03414216263209678,
      "loss": 0.6316,
      "step": 408480
    },
    {
      "epoch": 658.87,
      "learning_rate": 0.03413893682887097,
      "loss": 0.6202,
      "step": 408500
    },
    {
      "epoch": 658.9,
      "learning_rate": 0.03413571102564516,
      "loss": 0.6293,
      "step": 408520
    },
    {
      "epoch": 658.94,
      "learning_rate": 0.03413248522241936,
      "loss": 0.6303,
      "step": 408540
    },
    {
      "epoch": 658.97,
      "learning_rate": 0.03412925941919355,
      "loss": 0.6319,
      "step": 408560
    },
    {
      "epoch": 659.0,
      "learning_rate": 0.03412603361596774,
      "loss": 0.6396,
      "step": 408580
    },
    {
      "epoch": 659.0,
      "eval_accuracy": {
        "accuracy": 0.7706658340488642
      },
      "eval_loss": 1.004980444908142,
      "eval_runtime": 2.9232,
      "eval_samples_per_second": 4382.583,
      "eval_steps_per_second": 68.761,
      "step": 408580
    },
    {
      "epoch": 659.03,
      "learning_rate": 0.034122807812741934,
      "loss": 0.6452,
      "step": 408600
    },
    {
      "epoch": 659.06,
      "learning_rate": 0.03411958200951613,
      "loss": 0.626,
      "step": 408620
    },
    {
      "epoch": 659.1,
      "learning_rate": 0.034116356206290326,
      "loss": 0.5967,
      "step": 408640
    },
    {
      "epoch": 659.13,
      "learning_rate": 0.03411313040306452,
      "loss": 0.6242,
      "step": 408660
    },
    {
      "epoch": 659.16,
      "learning_rate": 0.03410990459983872,
      "loss": 0.6158,
      "step": 408680
    },
    {
      "epoch": 659.19,
      "learning_rate": 0.03410667879661291,
      "loss": 0.618,
      "step": 408700
    },
    {
      "epoch": 659.23,
      "learning_rate": 0.0341034529933871,
      "loss": 0.6226,
      "step": 408720
    },
    {
      "epoch": 659.26,
      "learning_rate": 0.0341002271901613,
      "loss": 0.6202,
      "step": 408740
    },
    {
      "epoch": 659.29,
      "learning_rate": 0.03409700138693549,
      "loss": 0.6238,
      "step": 408760
    },
    {
      "epoch": 659.32,
      "learning_rate": 0.034093775583709685,
      "loss": 0.6366,
      "step": 408780
    },
    {
      "epoch": 659.35,
      "learning_rate": 0.03409054978048388,
      "loss": 0.6239,
      "step": 408800
    },
    {
      "epoch": 659.39,
      "learning_rate": 0.03408732397725806,
      "loss": 0.6196,
      "step": 408820
    },
    {
      "epoch": 659.42,
      "learning_rate": 0.034084098174032254,
      "loss": 0.6355,
      "step": 408840
    },
    {
      "epoch": 659.45,
      "learning_rate": 0.03408087237080645,
      "loss": 0.6267,
      "step": 408860
    },
    {
      "epoch": 659.48,
      "learning_rate": 0.034077646567580645,
      "loss": 0.6346,
      "step": 408880
    },
    {
      "epoch": 659.52,
      "learning_rate": 0.03407442076435484,
      "loss": 0.6165,
      "step": 408900
    },
    {
      "epoch": 659.55,
      "learning_rate": 0.03407119496112904,
      "loss": 0.6362,
      "step": 408920
    },
    {
      "epoch": 659.58,
      "learning_rate": 0.03406796915790323,
      "loss": 0.6286,
      "step": 408940
    },
    {
      "epoch": 659.61,
      "learning_rate": 0.03406474335467742,
      "loss": 0.6408,
      "step": 408960
    },
    {
      "epoch": 659.65,
      "learning_rate": 0.03406151755145162,
      "loss": 0.6164,
      "step": 408980
    },
    {
      "epoch": 659.68,
      "learning_rate": 0.03405829174822581,
      "loss": 0.6409,
      "step": 409000
    },
    {
      "epoch": 659.71,
      "learning_rate": 0.034055065945000004,
      "loss": 0.6403,
      "step": 409020
    },
    {
      "epoch": 659.74,
      "learning_rate": 0.0340518401417742,
      "loss": 0.6317,
      "step": 409040
    },
    {
      "epoch": 659.77,
      "learning_rate": 0.034048614338548396,
      "loss": 0.6234,
      "step": 409060
    },
    {
      "epoch": 659.81,
      "learning_rate": 0.03404538853532259,
      "loss": 0.6185,
      "step": 409080
    },
    {
      "epoch": 659.84,
      "learning_rate": 0.03404216273209678,
      "loss": 0.6306,
      "step": 409100
    },
    {
      "epoch": 659.87,
      "learning_rate": 0.03403893692887098,
      "loss": 0.6267,
      "step": 409120
    },
    {
      "epoch": 659.9,
      "learning_rate": 0.03403571112564516,
      "loss": 0.6202,
      "step": 409140
    },
    {
      "epoch": 659.94,
      "learning_rate": 0.034032485322419356,
      "loss": 0.6373,
      "step": 409160
    },
    {
      "epoch": 659.97,
      "learning_rate": 0.03402925951919355,
      "loss": 0.6345,
      "step": 409180
    },
    {
      "epoch": 660.0,
      "learning_rate": 0.03402619500612904,
      "loss": 0.6395,
      "step": 409200
    },
    {
      "epoch": 660.0,
      "eval_accuracy": {
        "accuracy": 0.7738662087268754
      },
      "eval_loss": 0.9740999937057495,
      "eval_runtime": 4.4605,
      "eval_samples_per_second": 2872.089,
      "eval_steps_per_second": 45.062,
      "step": 409200
    },
    {
      "epoch": 660.03,
      "learning_rate": 0.034022969202903236,
      "loss": 0.6137,
      "step": 409220
    },
    {
      "epoch": 660.06,
      "learning_rate": 0.03401974339967743,
      "loss": 0.601,
      "step": 409240
    },
    {
      "epoch": 660.1,
      "learning_rate": 0.03401651759645162,
      "loss": 0.6215,
      "step": 409260
    },
    {
      "epoch": 660.13,
      "learning_rate": 0.034013291793225806,
      "loss": 0.6288,
      "step": 409280
    },
    {
      "epoch": 660.16,
      "learning_rate": 0.03401006599,
      "loss": 0.6356,
      "step": 409300
    },
    {
      "epoch": 660.19,
      "learning_rate": 0.0340068401867742,
      "loss": 0.6119,
      "step": 409320
    },
    {
      "epoch": 660.23,
      "learning_rate": 0.03400361438354839,
      "loss": 0.6187,
      "step": 409340
    },
    {
      "epoch": 660.26,
      "learning_rate": 0.03400038858032258,
      "loss": 0.6197,
      "step": 409360
    },
    {
      "epoch": 660.29,
      "learning_rate": 0.03399716277709677,
      "loss": 0.62,
      "step": 409380
    },
    {
      "epoch": 660.32,
      "learning_rate": 0.03399393697387097,
      "loss": 0.6173,
      "step": 409400
    },
    {
      "epoch": 660.35,
      "learning_rate": 0.033990711170645165,
      "loss": 0.6225,
      "step": 409420
    },
    {
      "epoch": 660.39,
      "learning_rate": 0.03398748536741936,
      "loss": 0.626,
      "step": 409440
    },
    {
      "epoch": 660.42,
      "learning_rate": 0.033984259564193556,
      "loss": 0.6184,
      "step": 409460
    },
    {
      "epoch": 660.45,
      "learning_rate": 0.03398103376096775,
      "loss": 0.6301,
      "step": 409480
    },
    {
      "epoch": 660.48,
      "learning_rate": 0.03397780795774194,
      "loss": 0.6214,
      "step": 409500
    },
    {
      "epoch": 660.52,
      "learning_rate": 0.03397458215451614,
      "loss": 0.6162,
      "step": 409520
    },
    {
      "epoch": 660.55,
      "learning_rate": 0.03397135635129033,
      "loss": 0.6267,
      "step": 409540
    },
    {
      "epoch": 660.58,
      "learning_rate": 0.033968130548064523,
      "loss": 0.6197,
      "step": 409560
    },
    {
      "epoch": 660.61,
      "learning_rate": 0.03396490474483871,
      "loss": 0.6229,
      "step": 409580
    },
    {
      "epoch": 660.65,
      "learning_rate": 0.0339616789416129,
      "loss": 0.6373,
      "step": 409600
    },
    {
      "epoch": 660.68,
      "learning_rate": 0.0339584531383871,
      "loss": 0.6292,
      "step": 409620
    },
    {
      "epoch": 660.71,
      "learning_rate": 0.03395522733516129,
      "loss": 0.6301,
      "step": 409640
    },
    {
      "epoch": 660.74,
      "learning_rate": 0.033952001531935484,
      "loss": 0.627,
      "step": 409660
    },
    {
      "epoch": 660.77,
      "learning_rate": 0.033948775728709676,
      "loss": 0.6246,
      "step": 409680
    },
    {
      "epoch": 660.81,
      "learning_rate": 0.033945549925483876,
      "loss": 0.6266,
      "step": 409700
    },
    {
      "epoch": 660.84,
      "learning_rate": 0.03394232412225807,
      "loss": 0.6168,
      "step": 409720
    },
    {
      "epoch": 660.87,
      "learning_rate": 0.03393909831903226,
      "loss": 0.6179,
      "step": 409740
    },
    {
      "epoch": 660.9,
      "learning_rate": 0.03393587251580646,
      "loss": 0.6255,
      "step": 409760
    },
    {
      "epoch": 660.94,
      "learning_rate": 0.03393264671258065,
      "loss": 0.6353,
      "step": 409780
    },
    {
      "epoch": 660.97,
      "learning_rate": 0.03392942090935484,
      "loss": 0.6293,
      "step": 409800
    },
    {
      "epoch": 661.0,
      "learning_rate": 0.03392619510612904,
      "loss": 0.629,
      "step": 409820
    },
    {
      "epoch": 661.0,
      "eval_accuracy": {
        "accuracy": 0.7704316602919367
      },
      "eval_loss": 0.9803723692893982,
      "eval_runtime": 3.0488,
      "eval_samples_per_second": 4201.95,
      "eval_steps_per_second": 65.927,
      "step": 409820
    },
    {
      "epoch": 661.03,
      "learning_rate": 0.033922969302903234,
      "loss": 0.6362,
      "step": 409840
    },
    {
      "epoch": 661.06,
      "learning_rate": 0.03391974349967743,
      "loss": 0.6176,
      "step": 409860
    },
    {
      "epoch": 661.1,
      "learning_rate": 0.03391651769645162,
      "loss": 0.6182,
      "step": 409880
    },
    {
      "epoch": 661.13,
      "learning_rate": 0.033913291893225804,
      "loss": 0.6225,
      "step": 409900
    },
    {
      "epoch": 661.16,
      "learning_rate": 0.033910066089999996,
      "loss": 0.6159,
      "step": 409920
    },
    {
      "epoch": 661.19,
      "learning_rate": 0.033906840286774195,
      "loss": 0.5992,
      "step": 409940
    },
    {
      "epoch": 661.23,
      "learning_rate": 0.03390361448354839,
      "loss": 0.6121,
      "step": 409960
    },
    {
      "epoch": 661.26,
      "learning_rate": 0.03390038868032258,
      "loss": 0.634,
      "step": 409980
    },
    {
      "epoch": 661.29,
      "learning_rate": 0.03389716287709678,
      "loss": 0.6125,
      "step": 410000
    },
    {
      "epoch": 661.32,
      "learning_rate": 0.03389393707387097,
      "loss": 0.6152,
      "step": 410020
    },
    {
      "epoch": 661.35,
      "learning_rate": 0.03389071127064516,
      "loss": 0.6173,
      "step": 410040
    },
    {
      "epoch": 661.39,
      "learning_rate": 0.03388748546741936,
      "loss": 0.6191,
      "step": 410060
    },
    {
      "epoch": 661.42,
      "learning_rate": 0.033884259664193554,
      "loss": 0.6173,
      "step": 410080
    },
    {
      "epoch": 661.45,
      "learning_rate": 0.033881033860967746,
      "loss": 0.6196,
      "step": 410100
    },
    {
      "epoch": 661.48,
      "learning_rate": 0.033877808057741945,
      "loss": 0.6308,
      "step": 410120
    },
    {
      "epoch": 661.52,
      "learning_rate": 0.03387458225451614,
      "loss": 0.6319,
      "step": 410140
    },
    {
      "epoch": 661.55,
      "learning_rate": 0.03387135645129033,
      "loss": 0.6257,
      "step": 410160
    },
    {
      "epoch": 661.58,
      "learning_rate": 0.03386813064806452,
      "loss": 0.6289,
      "step": 410180
    },
    {
      "epoch": 661.61,
      "learning_rate": 0.03386490484483871,
      "loss": 0.6466,
      "step": 410200
    },
    {
      "epoch": 661.65,
      "learning_rate": 0.0338616790416129,
      "loss": 0.6239,
      "step": 410220
    },
    {
      "epoch": 661.68,
      "learning_rate": 0.0338584532383871,
      "loss": 0.6228,
      "step": 410240
    },
    {
      "epoch": 661.71,
      "learning_rate": 0.03385522743516129,
      "loss": 0.6142,
      "step": 410260
    },
    {
      "epoch": 661.74,
      "learning_rate": 0.03385200163193548,
      "loss": 0.6153,
      "step": 410280
    },
    {
      "epoch": 661.77,
      "learning_rate": 0.03384877582870968,
      "loss": 0.6172,
      "step": 410300
    },
    {
      "epoch": 661.81,
      "learning_rate": 0.033845550025483874,
      "loss": 0.6248,
      "step": 410320
    },
    {
      "epoch": 661.84,
      "learning_rate": 0.033842324222258066,
      "loss": 0.6359,
      "step": 410340
    },
    {
      "epoch": 661.87,
      "learning_rate": 0.033839098419032265,
      "loss": 0.6367,
      "step": 410360
    },
    {
      "epoch": 661.9,
      "learning_rate": 0.03383587261580646,
      "loss": 0.6355,
      "step": 410380
    },
    {
      "epoch": 661.94,
      "learning_rate": 0.03383264681258065,
      "loss": 0.6312,
      "step": 410400
    },
    {
      "epoch": 661.97,
      "learning_rate": 0.03382942100935484,
      "loss": 0.6271,
      "step": 410420
    },
    {
      "epoch": 662.0,
      "learning_rate": 0.03382619520612904,
      "loss": 0.6228,
      "step": 410440
    },
    {
      "epoch": 662.0,
      "eval_accuracy": {
        "accuracy": 0.7709780657247678
      },
      "eval_loss": 0.9725715517997742,
      "eval_runtime": 2.8519,
      "eval_samples_per_second": 4492.163,
      "eval_steps_per_second": 70.48,
      "step": 410440
    },
    {
      "epoch": 662.03,
      "learning_rate": 0.03382296940290323,
      "loss": 0.6273,
      "step": 410460
    },
    {
      "epoch": 662.06,
      "learning_rate": 0.033819743599677425,
      "loss": 0.6194,
      "step": 410480
    },
    {
      "epoch": 662.1,
      "learning_rate": 0.033816517796451624,
      "loss": 0.6056,
      "step": 410500
    },
    {
      "epoch": 662.13,
      "learning_rate": 0.0338132919932258,
      "loss": 0.6174,
      "step": 410520
    },
    {
      "epoch": 662.16,
      "learning_rate": 0.03381006619,
      "loss": 0.6153,
      "step": 410540
    },
    {
      "epoch": 662.19,
      "learning_rate": 0.033806840386774194,
      "loss": 0.609,
      "step": 410560
    },
    {
      "epoch": 662.23,
      "learning_rate": 0.033803614583548386,
      "loss": 0.6261,
      "step": 410580
    },
    {
      "epoch": 662.26,
      "learning_rate": 0.033800388780322585,
      "loss": 0.6213,
      "step": 410600
    },
    {
      "epoch": 662.29,
      "learning_rate": 0.03379716297709678,
      "loss": 0.6165,
      "step": 410620
    },
    {
      "epoch": 662.32,
      "learning_rate": 0.03379393717387097,
      "loss": 0.6169,
      "step": 410640
    },
    {
      "epoch": 662.35,
      "learning_rate": 0.03379071137064517,
      "loss": 0.6274,
      "step": 410660
    },
    {
      "epoch": 662.39,
      "learning_rate": 0.03378748556741936,
      "loss": 0.621,
      "step": 410680
    },
    {
      "epoch": 662.42,
      "learning_rate": 0.03378425976419355,
      "loss": 0.6289,
      "step": 410700
    },
    {
      "epoch": 662.45,
      "learning_rate": 0.033781033960967745,
      "loss": 0.6276,
      "step": 410720
    },
    {
      "epoch": 662.48,
      "learning_rate": 0.033777808157741944,
      "loss": 0.63,
      "step": 410740
    },
    {
      "epoch": 662.52,
      "learning_rate": 0.033774582354516136,
      "loss": 0.6183,
      "step": 410760
    },
    {
      "epoch": 662.55,
      "learning_rate": 0.03377135655129033,
      "loss": 0.6271,
      "step": 410780
    },
    {
      "epoch": 662.58,
      "learning_rate": 0.03376813074806453,
      "loss": 0.6164,
      "step": 410800
    },
    {
      "epoch": 662.61,
      "learning_rate": 0.033764904944838706,
      "loss": 0.6318,
      "step": 410820
    },
    {
      "epoch": 662.65,
      "learning_rate": 0.033761679141612905,
      "loss": 0.6262,
      "step": 410840
    },
    {
      "epoch": 662.68,
      "learning_rate": 0.0337584533383871,
      "loss": 0.6224,
      "step": 410860
    },
    {
      "epoch": 662.71,
      "learning_rate": 0.03375522753516129,
      "loss": 0.6411,
      "step": 410880
    },
    {
      "epoch": 662.74,
      "learning_rate": 0.03375200173193549,
      "loss": 0.6096,
      "step": 410900
    },
    {
      "epoch": 662.77,
      "learning_rate": 0.03374877592870968,
      "loss": 0.6279,
      "step": 410920
    },
    {
      "epoch": 662.81,
      "learning_rate": 0.03374555012548387,
      "loss": 0.6248,
      "step": 410940
    },
    {
      "epoch": 662.84,
      "learning_rate": 0.033742324322258065,
      "loss": 0.623,
      "step": 410960
    },
    {
      "epoch": 662.87,
      "learning_rate": 0.033739098519032264,
      "loss": 0.6301,
      "step": 410980
    },
    {
      "epoch": 662.9,
      "learning_rate": 0.033735872715806456,
      "loss": 0.6279,
      "step": 411000
    },
    {
      "epoch": 662.94,
      "learning_rate": 0.03373264691258065,
      "loss": 0.6263,
      "step": 411020
    },
    {
      "epoch": 662.97,
      "learning_rate": 0.03372942110935485,
      "loss": 0.6259,
      "step": 411040
    },
    {
      "epoch": 663.0,
      "learning_rate": 0.03372619530612904,
      "loss": 0.625,
      "step": 411060
    },
    {
      "epoch": 663.0,
      "eval_accuracy": {
        "accuracy": 0.7659823589103114
      },
      "eval_loss": 1.0004950761795044,
      "eval_runtime": 2.8768,
      "eval_samples_per_second": 4453.213,
      "eval_steps_per_second": 69.869,
      "step": 411060
    },
    {
      "epoch": 663.03,
      "learning_rate": 0.03372296950290323,
      "loss": 0.6213,
      "step": 411080
    },
    {
      "epoch": 663.06,
      "learning_rate": 0.03371974369967743,
      "loss": 0.6199,
      "step": 411100
    },
    {
      "epoch": 663.1,
      "learning_rate": 0.03371651789645162,
      "loss": 0.6198,
      "step": 411120
    },
    {
      "epoch": 663.13,
      "learning_rate": 0.03371329209322581,
      "loss": 0.6274,
      "step": 411140
    },
    {
      "epoch": 663.16,
      "learning_rate": 0.03371006629,
      "loss": 0.6216,
      "step": 411160
    },
    {
      "epoch": 663.19,
      "learning_rate": 0.03370684048677419,
      "loss": 0.6114,
      "step": 411180
    },
    {
      "epoch": 663.23,
      "learning_rate": 0.033703614683548384,
      "loss": 0.6228,
      "step": 411200
    },
    {
      "epoch": 663.26,
      "learning_rate": 0.03370038888032258,
      "loss": 0.6086,
      "step": 411220
    },
    {
      "epoch": 663.29,
      "learning_rate": 0.033697163077096776,
      "loss": 0.6257,
      "step": 411240
    },
    {
      "epoch": 663.32,
      "learning_rate": 0.03369393727387097,
      "loss": 0.6182,
      "step": 411260
    },
    {
      "epoch": 663.35,
      "learning_rate": 0.03369071147064517,
      "loss": 0.6104,
      "step": 411280
    },
    {
      "epoch": 663.39,
      "learning_rate": 0.03368748566741936,
      "loss": 0.6113,
      "step": 411300
    },
    {
      "epoch": 663.42,
      "learning_rate": 0.03368425986419355,
      "loss": 0.6284,
      "step": 411320
    },
    {
      "epoch": 663.45,
      "learning_rate": 0.03368103406096775,
      "loss": 0.6083,
      "step": 411340
    },
    {
      "epoch": 663.48,
      "learning_rate": 0.03367780825774194,
      "loss": 0.6227,
      "step": 411360
    },
    {
      "epoch": 663.52,
      "learning_rate": 0.033674582454516135,
      "loss": 0.6308,
      "step": 411380
    },
    {
      "epoch": 663.55,
      "learning_rate": 0.033671356651290334,
      "loss": 0.6264,
      "step": 411400
    },
    {
      "epoch": 663.58,
      "learning_rate": 0.033668130848064526,
      "loss": 0.6263,
      "step": 411420
    },
    {
      "epoch": 663.61,
      "learning_rate": 0.03366490504483872,
      "loss": 0.6397,
      "step": 411440
    },
    {
      "epoch": 663.65,
      "learning_rate": 0.0336616792416129,
      "loss": 0.6289,
      "step": 411460
    },
    {
      "epoch": 663.68,
      "learning_rate": 0.033658453438387095,
      "loss": 0.6247,
      "step": 411480
    },
    {
      "epoch": 663.71,
      "learning_rate": 0.03365522763516129,
      "loss": 0.6125,
      "step": 411500
    },
    {
      "epoch": 663.74,
      "learning_rate": 0.03365200183193549,
      "loss": 0.6213,
      "step": 411520
    },
    {
      "epoch": 663.77,
      "learning_rate": 0.03364877602870968,
      "loss": 0.6216,
      "step": 411540
    },
    {
      "epoch": 663.81,
      "learning_rate": 0.03364555022548387,
      "loss": 0.6293,
      "step": 411560
    },
    {
      "epoch": 663.84,
      "learning_rate": 0.03364232442225807,
      "loss": 0.6221,
      "step": 411580
    },
    {
      "epoch": 663.87,
      "learning_rate": 0.03363909861903226,
      "loss": 0.6359,
      "step": 411600
    },
    {
      "epoch": 663.9,
      "learning_rate": 0.033635872815806454,
      "loss": 0.6254,
      "step": 411620
    },
    {
      "epoch": 663.94,
      "learning_rate": 0.03363264701258065,
      "loss": 0.6262,
      "step": 411640
    },
    {
      "epoch": 663.97,
      "learning_rate": 0.033629421209354846,
      "loss": 0.6234,
      "step": 411660
    },
    {
      "epoch": 664.0,
      "learning_rate": 0.03362619540612904,
      "loss": 0.6357,
      "step": 411680
    },
    {
      "epoch": 664.0,
      "eval_accuracy": {
        "accuracy": 0.7772226992428382
      },
      "eval_loss": 0.9678456783294678,
      "eval_runtime": 3.1665,
      "eval_samples_per_second": 4045.764,
      "eval_steps_per_second": 63.477,
      "step": 411680
    },
    {
      "epoch": 664.03,
      "learning_rate": 0.03362296960290323,
      "loss": 0.6226,
      "step": 411700
    },
    {
      "epoch": 664.06,
      "learning_rate": 0.03361974379967743,
      "loss": 0.6286,
      "step": 411720
    },
    {
      "epoch": 664.1,
      "learning_rate": 0.03361651799645162,
      "loss": 0.6119,
      "step": 411740
    },
    {
      "epoch": 664.13,
      "learning_rate": 0.033613292193225806,
      "loss": 0.6066,
      "step": 411760
    },
    {
      "epoch": 664.16,
      "learning_rate": 0.03361006639,
      "loss": 0.6034,
      "step": 411780
    },
    {
      "epoch": 664.19,
      "learning_rate": 0.03360684058677419,
      "loss": 0.6169,
      "step": 411800
    },
    {
      "epoch": 664.23,
      "learning_rate": 0.03360361478354839,
      "loss": 0.6347,
      "step": 411820
    },
    {
      "epoch": 664.26,
      "learning_rate": 0.03360038898032258,
      "loss": 0.6172,
      "step": 411840
    },
    {
      "epoch": 664.29,
      "learning_rate": 0.033597163177096774,
      "loss": 0.617,
      "step": 411860
    },
    {
      "epoch": 664.32,
      "learning_rate": 0.03359393737387097,
      "loss": 0.6254,
      "step": 411880
    },
    {
      "epoch": 664.35,
      "learning_rate": 0.033590711570645165,
      "loss": 0.6201,
      "step": 411900
    },
    {
      "epoch": 664.39,
      "learning_rate": 0.03358748576741936,
      "loss": 0.6337,
      "step": 411920
    },
    {
      "epoch": 664.42,
      "learning_rate": 0.03358425996419356,
      "loss": 0.6357,
      "step": 411940
    },
    {
      "epoch": 664.45,
      "learning_rate": 0.03358103416096775,
      "loss": 0.6282,
      "step": 411960
    },
    {
      "epoch": 664.48,
      "learning_rate": 0.03357780835774194,
      "loss": 0.6182,
      "step": 411980
    },
    {
      "epoch": 664.52,
      "learning_rate": 0.03357458255451613,
      "loss": 0.6174,
      "step": 412000
    },
    {
      "epoch": 664.55,
      "learning_rate": 0.03357135675129033,
      "loss": 0.6346,
      "step": 412020
    },
    {
      "epoch": 664.58,
      "learning_rate": 0.033568130948064524,
      "loss": 0.6251,
      "step": 412040
    },
    {
      "epoch": 664.61,
      "learning_rate": 0.033564905144838716,
      "loss": 0.6219,
      "step": 412060
    },
    {
      "epoch": 664.65,
      "learning_rate": 0.0335616793416129,
      "loss": 0.6323,
      "step": 412080
    },
    {
      "epoch": 664.68,
      "learning_rate": 0.033558453538387094,
      "loss": 0.6204,
      "step": 412100
    },
    {
      "epoch": 664.71,
      "learning_rate": 0.03355522773516129,
      "loss": 0.6157,
      "step": 412120
    },
    {
      "epoch": 664.74,
      "learning_rate": 0.033552001931935485,
      "loss": 0.6111,
      "step": 412140
    },
    {
      "epoch": 664.77,
      "learning_rate": 0.03354877612870968,
      "loss": 0.6269,
      "step": 412160
    },
    {
      "epoch": 664.81,
      "learning_rate": 0.033545550325483876,
      "loss": 0.6135,
      "step": 412180
    },
    {
      "epoch": 664.84,
      "learning_rate": 0.03354232452225807,
      "loss": 0.6176,
      "step": 412200
    },
    {
      "epoch": 664.87,
      "learning_rate": 0.03353909871903226,
      "loss": 0.6253,
      "step": 412220
    },
    {
      "epoch": 664.9,
      "learning_rate": 0.03353587291580645,
      "loss": 0.6402,
      "step": 412240
    },
    {
      "epoch": 664.94,
      "learning_rate": 0.03353264711258065,
      "loss": 0.6228,
      "step": 412260
    },
    {
      "epoch": 664.97,
      "learning_rate": 0.033529421309354844,
      "loss": 0.6089,
      "step": 412280
    },
    {
      "epoch": 665.0,
      "learning_rate": 0.033526195506129036,
      "loss": 0.6268,
      "step": 412300
    },
    {
      "epoch": 665.0,
      "eval_accuracy": {
        "accuracy": 0.7736320349699477
      },
      "eval_loss": 0.9821732044219971,
      "eval_runtime": 3.0024,
      "eval_samples_per_second": 4266.885,
      "eval_steps_per_second": 66.946,
      "step": 412300
    },
    {
      "epoch": 665.03,
      "learning_rate": 0.033522969702903235,
      "loss": 0.6351,
      "step": 412320
    },
    {
      "epoch": 665.06,
      "learning_rate": 0.03351974389967743,
      "loss": 0.6295,
      "step": 412340
    },
    {
      "epoch": 665.1,
      "learning_rate": 0.03351651809645162,
      "loss": 0.6208,
      "step": 412360
    },
    {
      "epoch": 665.13,
      "learning_rate": 0.033513292293225805,
      "loss": 0.6102,
      "step": 412380
    },
    {
      "epoch": 665.16,
      "learning_rate": 0.03351006649,
      "loss": 0.6092,
      "step": 412400
    },
    {
      "epoch": 665.19,
      "learning_rate": 0.033506840686774196,
      "loss": 0.6252,
      "step": 412420
    },
    {
      "epoch": 665.23,
      "learning_rate": 0.03350361488354839,
      "loss": 0.6136,
      "step": 412440
    },
    {
      "epoch": 665.26,
      "learning_rate": 0.03350038908032258,
      "loss": 0.6167,
      "step": 412460
    },
    {
      "epoch": 665.29,
      "learning_rate": 0.033497324567258076,
      "loss": 0.6168,
      "step": 412480
    },
    {
      "epoch": 665.32,
      "learning_rate": 0.03349409876403227,
      "loss": 0.6229,
      "step": 412500
    },
    {
      "epoch": 665.35,
      "learning_rate": 0.03349087296080645,
      "loss": 0.6141,
      "step": 412520
    },
    {
      "epoch": 665.39,
      "learning_rate": 0.033487647157580645,
      "loss": 0.6016,
      "step": 412540
    },
    {
      "epoch": 665.42,
      "learning_rate": 0.03348442135435484,
      "loss": 0.6264,
      "step": 412560
    },
    {
      "epoch": 665.45,
      "learning_rate": 0.03348119555112903,
      "loss": 0.6284,
      "step": 412580
    },
    {
      "epoch": 665.48,
      "learning_rate": 0.03347796974790323,
      "loss": 0.6163,
      "step": 412600
    },
    {
      "epoch": 665.52,
      "learning_rate": 0.03347474394467742,
      "loss": 0.6047,
      "step": 412620
    },
    {
      "epoch": 665.55,
      "learning_rate": 0.03347151814145161,
      "loss": 0.6181,
      "step": 412640
    },
    {
      "epoch": 665.58,
      "learning_rate": 0.03346829233822581,
      "loss": 0.623,
      "step": 412660
    },
    {
      "epoch": 665.61,
      "learning_rate": 0.033465066535000004,
      "loss": 0.6226,
      "step": 412680
    },
    {
      "epoch": 665.65,
      "learning_rate": 0.033461840731774196,
      "loss": 0.6198,
      "step": 412700
    },
    {
      "epoch": 665.68,
      "learning_rate": 0.033458614928548396,
      "loss": 0.6256,
      "step": 412720
    },
    {
      "epoch": 665.71,
      "learning_rate": 0.03345538912532259,
      "loss": 0.6282,
      "step": 412740
    },
    {
      "epoch": 665.74,
      "learning_rate": 0.03345216332209678,
      "loss": 0.632,
      "step": 412760
    },
    {
      "epoch": 665.77,
      "learning_rate": 0.03344893751887097,
      "loss": 0.6295,
      "step": 412780
    },
    {
      "epoch": 665.81,
      "learning_rate": 0.03344571171564517,
      "loss": 0.6317,
      "step": 412800
    },
    {
      "epoch": 665.84,
      "learning_rate": 0.03344248591241936,
      "loss": 0.6228,
      "step": 412820
    },
    {
      "epoch": 665.87,
      "learning_rate": 0.03343926010919355,
      "loss": 0.618,
      "step": 412840
    },
    {
      "epoch": 665.9,
      "learning_rate": 0.03343603430596774,
      "loss": 0.6088,
      "step": 412860
    },
    {
      "epoch": 665.94,
      "learning_rate": 0.03343280850274193,
      "loss": 0.6272,
      "step": 412880
    },
    {
      "epoch": 665.97,
      "learning_rate": 0.03342958269951613,
      "loss": 0.6262,
      "step": 412900
    },
    {
      "epoch": 666.0,
      "learning_rate": 0.033426356896290324,
      "loss": 0.6274,
      "step": 412920
    },
    {
      "epoch": 666.0,
      "eval_accuracy": {
        "accuracy": 0.7754273671063929
      },
      "eval_loss": 0.9931874871253967,
      "eval_runtime": 2.9981,
      "eval_samples_per_second": 4272.991,
      "eval_steps_per_second": 67.042,
      "step": 412920
    },
    {
      "epoch": 666.03,
      "learning_rate": 0.033423131093064516,
      "loss": 0.6275,
      "step": 412940
    },
    {
      "epoch": 666.06,
      "learning_rate": 0.033419905289838715,
      "loss": 0.6298,
      "step": 412960
    },
    {
      "epoch": 666.1,
      "learning_rate": 0.03341667948661291,
      "loss": 0.6246,
      "step": 412980
    },
    {
      "epoch": 666.13,
      "learning_rate": 0.0334134536833871,
      "loss": 0.6215,
      "step": 413000
    },
    {
      "epoch": 666.16,
      "learning_rate": 0.0334102278801613,
      "loss": 0.6274,
      "step": 413020
    },
    {
      "epoch": 666.19,
      "learning_rate": 0.03340700207693549,
      "loss": 0.6144,
      "step": 413040
    },
    {
      "epoch": 666.23,
      "learning_rate": 0.03340377627370968,
      "loss": 0.627,
      "step": 413060
    },
    {
      "epoch": 666.26,
      "learning_rate": 0.033400550470483875,
      "loss": 0.6063,
      "step": 413080
    },
    {
      "epoch": 666.29,
      "learning_rate": 0.033397324667258074,
      "loss": 0.6074,
      "step": 413100
    },
    {
      "epoch": 666.32,
      "learning_rate": 0.033394098864032266,
      "loss": 0.6072,
      "step": 413120
    },
    {
      "epoch": 666.35,
      "learning_rate": 0.03339087306080645,
      "loss": 0.6168,
      "step": 413140
    },
    {
      "epoch": 666.39,
      "learning_rate": 0.033387647257580644,
      "loss": 0.6166,
      "step": 413160
    },
    {
      "epoch": 666.42,
      "learning_rate": 0.033384421454354836,
      "loss": 0.6188,
      "step": 413180
    },
    {
      "epoch": 666.45,
      "learning_rate": 0.033381195651129035,
      "loss": 0.6139,
      "step": 413200
    },
    {
      "epoch": 666.48,
      "learning_rate": 0.03337796984790323,
      "loss": 0.6175,
      "step": 413220
    },
    {
      "epoch": 666.52,
      "learning_rate": 0.03337474404467742,
      "loss": 0.6108,
      "step": 413240
    },
    {
      "epoch": 666.55,
      "learning_rate": 0.03337151824145162,
      "loss": 0.631,
      "step": 413260
    },
    {
      "epoch": 666.58,
      "learning_rate": 0.03336829243822581,
      "loss": 0.6098,
      "step": 413280
    },
    {
      "epoch": 666.61,
      "learning_rate": 0.033365066635,
      "loss": 0.6146,
      "step": 413300
    },
    {
      "epoch": 666.65,
      "learning_rate": 0.033361840831774195,
      "loss": 0.6241,
      "step": 413320
    },
    {
      "epoch": 666.68,
      "learning_rate": 0.033358615028548394,
      "loss": 0.6169,
      "step": 413340
    },
    {
      "epoch": 666.71,
      "learning_rate": 0.033355389225322586,
      "loss": 0.6234,
      "step": 413360
    },
    {
      "epoch": 666.74,
      "learning_rate": 0.03335216342209678,
      "loss": 0.6107,
      "step": 413380
    },
    {
      "epoch": 666.77,
      "learning_rate": 0.03334893761887098,
      "loss": 0.6124,
      "step": 413400
    },
    {
      "epoch": 666.81,
      "learning_rate": 0.03334571181564517,
      "loss": 0.6255,
      "step": 413420
    },
    {
      "epoch": 666.84,
      "learning_rate": 0.03334248601241936,
      "loss": 0.6303,
      "step": 413440
    },
    {
      "epoch": 666.87,
      "learning_rate": 0.03333926020919355,
      "loss": 0.6239,
      "step": 413460
    },
    {
      "epoch": 666.9,
      "learning_rate": 0.03333603440596774,
      "loss": 0.6244,
      "step": 413480
    },
    {
      "epoch": 666.94,
      "learning_rate": 0.03333280860274194,
      "loss": 0.6293,
      "step": 413500
    },
    {
      "epoch": 666.97,
      "learning_rate": 0.03332958279951613,
      "loss": 0.6483,
      "step": 413520
    },
    {
      "epoch": 667.0,
      "learning_rate": 0.03332635699629032,
      "loss": 0.638,
      "step": 413540
    },
    {
      "epoch": 667.0,
      "eval_accuracy": {
        "accuracy": 0.7684802123175396
      },
      "eval_loss": 0.9933460354804993,
      "eval_runtime": 3.1853,
      "eval_samples_per_second": 4021.949,
      "eval_steps_per_second": 63.103,
      "step": 413540
    },
    {
      "epoch": 667.03,
      "learning_rate": 0.03332313119306452,
      "loss": 0.6379,
      "step": 413560
    },
    {
      "epoch": 667.06,
      "learning_rate": 0.033319905389838714,
      "loss": 0.6151,
      "step": 413580
    },
    {
      "epoch": 667.1,
      "learning_rate": 0.033316679586612906,
      "loss": 0.6092,
      "step": 413600
    },
    {
      "epoch": 667.13,
      "learning_rate": 0.0333134537833871,
      "loss": 0.5957,
      "step": 413620
    },
    {
      "epoch": 667.16,
      "learning_rate": 0.0333102279801613,
      "loss": 0.6053,
      "step": 413640
    },
    {
      "epoch": 667.19,
      "learning_rate": 0.03330700217693549,
      "loss": 0.6186,
      "step": 413660
    },
    {
      "epoch": 667.23,
      "learning_rate": 0.03330377637370968,
      "loss": 0.6051,
      "step": 413680
    },
    {
      "epoch": 667.26,
      "learning_rate": 0.03330055057048388,
      "loss": 0.6012,
      "step": 413700
    },
    {
      "epoch": 667.29,
      "learning_rate": 0.03329732476725807,
      "loss": 0.6196,
      "step": 413720
    },
    {
      "epoch": 667.32,
      "learning_rate": 0.033294098964032265,
      "loss": 0.6098,
      "step": 413740
    },
    {
      "epoch": 667.35,
      "learning_rate": 0.033290873160806464,
      "loss": 0.6327,
      "step": 413760
    },
    {
      "epoch": 667.39,
      "learning_rate": 0.03328764735758064,
      "loss": 0.6214,
      "step": 413780
    },
    {
      "epoch": 667.42,
      "learning_rate": 0.03328442155435484,
      "loss": 0.6108,
      "step": 413800
    },
    {
      "epoch": 667.45,
      "learning_rate": 0.033281195751129033,
      "loss": 0.6178,
      "step": 413820
    },
    {
      "epoch": 667.48,
      "learning_rate": 0.033277969947903226,
      "loss": 0.6228,
      "step": 413840
    },
    {
      "epoch": 667.52,
      "learning_rate": 0.03327474414467742,
      "loss": 0.6199,
      "step": 413860
    },
    {
      "epoch": 667.55,
      "learning_rate": 0.03327151834145162,
      "loss": 0.6236,
      "step": 413880
    },
    {
      "epoch": 667.58,
      "learning_rate": 0.03326829253822581,
      "loss": 0.6265,
      "step": 413900
    },
    {
      "epoch": 667.61,
      "learning_rate": 0.033265066735,
      "loss": 0.6203,
      "step": 413920
    },
    {
      "epoch": 667.65,
      "learning_rate": 0.0332618409317742,
      "loss": 0.6287,
      "step": 413940
    },
    {
      "epoch": 667.68,
      "learning_rate": 0.03325861512854839,
      "loss": 0.607,
      "step": 413960
    },
    {
      "epoch": 667.71,
      "learning_rate": 0.033255389325322585,
      "loss": 0.6244,
      "step": 413980
    },
    {
      "epoch": 667.74,
      "learning_rate": 0.033252163522096784,
      "loss": 0.6201,
      "step": 414000
    },
    {
      "epoch": 667.77,
      "learning_rate": 0.033248937718870976,
      "loss": 0.6178,
      "step": 414020
    },
    {
      "epoch": 667.81,
      "learning_rate": 0.03324571191564517,
      "loss": 0.6266,
      "step": 414040
    },
    {
      "epoch": 667.84,
      "learning_rate": 0.03324248611241937,
      "loss": 0.6204,
      "step": 414060
    },
    {
      "epoch": 667.87,
      "learning_rate": 0.033239260309193545,
      "loss": 0.626,
      "step": 414080
    },
    {
      "epoch": 667.9,
      "learning_rate": 0.033236034505967745,
      "loss": 0.6312,
      "step": 414100
    },
    {
      "epoch": 667.94,
      "learning_rate": 0.03323280870274194,
      "loss": 0.6209,
      "step": 414120
    },
    {
      "epoch": 667.97,
      "learning_rate": 0.03322958289951613,
      "loss": 0.6205,
      "step": 414140
    },
    {
      "epoch": 668.0,
      "learning_rate": 0.03322635709629032,
      "loss": 0.6338,
      "step": 414160
    },
    {
      "epoch": 668.0,
      "eval_accuracy": {
        "accuracy": 0.7697291390211537
      },
      "eval_loss": 0.9918642640113831,
      "eval_runtime": 3.2736,
      "eval_samples_per_second": 3913.42,
      "eval_steps_per_second": 61.4,
      "step": 414160
    },
    {
      "epoch": 668.03,
      "learning_rate": 0.03322313129306452,
      "loss": 0.6385,
      "step": 414180
    },
    {
      "epoch": 668.06,
      "learning_rate": 0.03321990548983871,
      "loss": 0.5914,
      "step": 414200
    },
    {
      "epoch": 668.1,
      "learning_rate": 0.033216679686612904,
      "loss": 0.5929,
      "step": 414220
    },
    {
      "epoch": 668.13,
      "learning_rate": 0.033213453883387103,
      "loss": 0.6074,
      "step": 414240
    },
    {
      "epoch": 668.16,
      "learning_rate": 0.033210228080161296,
      "loss": 0.6176,
      "step": 414260
    },
    {
      "epoch": 668.19,
      "learning_rate": 0.03320700227693549,
      "loss": 0.6118,
      "step": 414280
    },
    {
      "epoch": 668.23,
      "learning_rate": 0.03320377647370969,
      "loss": 0.6059,
      "step": 414300
    },
    {
      "epoch": 668.26,
      "learning_rate": 0.03320055067048388,
      "loss": 0.6094,
      "step": 414320
    },
    {
      "epoch": 668.29,
      "learning_rate": 0.03319732486725807,
      "loss": 0.6102,
      "step": 414340
    },
    {
      "epoch": 668.32,
      "learning_rate": 0.03319409906403226,
      "loss": 0.6204,
      "step": 414360
    },
    {
      "epoch": 668.35,
      "learning_rate": 0.03319087326080646,
      "loss": 0.6182,
      "step": 414380
    },
    {
      "epoch": 668.39,
      "learning_rate": 0.03318764745758064,
      "loss": 0.6212,
      "step": 414400
    },
    {
      "epoch": 668.42,
      "learning_rate": 0.03318442165435484,
      "loss": 0.6319,
      "step": 414420
    },
    {
      "epoch": 668.45,
      "learning_rate": 0.03318119585112903,
      "loss": 0.6239,
      "step": 414440
    },
    {
      "epoch": 668.48,
      "learning_rate": 0.033177970047903224,
      "loss": 0.6245,
      "step": 414460
    },
    {
      "epoch": 668.52,
      "learning_rate": 0.03317474424467742,
      "loss": 0.6216,
      "step": 414480
    },
    {
      "epoch": 668.55,
      "learning_rate": 0.033171518441451615,
      "loss": 0.6145,
      "step": 414500
    },
    {
      "epoch": 668.58,
      "learning_rate": 0.03316829263822581,
      "loss": 0.6188,
      "step": 414520
    },
    {
      "epoch": 668.61,
      "learning_rate": 0.03316506683500001,
      "loss": 0.6194,
      "step": 414540
    },
    {
      "epoch": 668.65,
      "learning_rate": 0.0331618410317742,
      "loss": 0.6224,
      "step": 414560
    },
    {
      "epoch": 668.68,
      "learning_rate": 0.03315861522854839,
      "loss": 0.6369,
      "step": 414580
    },
    {
      "epoch": 668.71,
      "learning_rate": 0.03315538942532259,
      "loss": 0.6224,
      "step": 414600
    },
    {
      "epoch": 668.74,
      "learning_rate": 0.03315216362209678,
      "loss": 0.6237,
      "step": 414620
    },
    {
      "epoch": 668.77,
      "learning_rate": 0.033148937818870974,
      "loss": 0.6317,
      "step": 414640
    },
    {
      "epoch": 668.81,
      "learning_rate": 0.033145712015645167,
      "loss": 0.624,
      "step": 414660
    },
    {
      "epoch": 668.84,
      "learning_rate": 0.033142486212419366,
      "loss": 0.6068,
      "step": 414680
    },
    {
      "epoch": 668.87,
      "learning_rate": 0.033139260409193544,
      "loss": 0.6156,
      "step": 414700
    },
    {
      "epoch": 668.9,
      "learning_rate": 0.03313603460596774,
      "loss": 0.616,
      "step": 414720
    },
    {
      "epoch": 668.94,
      "learning_rate": 0.033132808802741935,
      "loss": 0.6157,
      "step": 414740
    },
    {
      "epoch": 668.97,
      "learning_rate": 0.03312958299951613,
      "loss": 0.6198,
      "step": 414760
    },
    {
      "epoch": 669.0,
      "learning_rate": 0.03312651848645162,
      "loss": 0.622,
      "step": 414780
    },
    {
      "epoch": 669.0,
      "eval_accuracy": {
        "accuracy": 0.7717586449145266
      },
      "eval_loss": 0.9872047305107117,
      "eval_runtime": 3.0936,
      "eval_samples_per_second": 4141.101,
      "eval_steps_per_second": 64.972,
      "step": 414780
    },
    {
      "epoch": 669.03,
      "learning_rate": 0.033123292683225815,
      "loss": 0.5943,
      "step": 414800
    },
    {
      "epoch": 669.06,
      "learning_rate": 0.03312006688000001,
      "loss": 0.5996,
      "step": 414820
    },
    {
      "epoch": 669.1,
      "learning_rate": 0.03311684107677419,
      "loss": 0.6046,
      "step": 414840
    },
    {
      "epoch": 669.13,
      "learning_rate": 0.033113615273548384,
      "loss": 0.6164,
      "step": 414860
    },
    {
      "epoch": 669.16,
      "learning_rate": 0.03311038947032258,
      "loss": 0.6132,
      "step": 414880
    },
    {
      "epoch": 669.19,
      "learning_rate": 0.033107163667096776,
      "loss": 0.6181,
      "step": 414900
    },
    {
      "epoch": 669.23,
      "learning_rate": 0.03310393786387097,
      "loss": 0.6351,
      "step": 414920
    },
    {
      "epoch": 669.26,
      "learning_rate": 0.03310071206064516,
      "loss": 0.607,
      "step": 414940
    },
    {
      "epoch": 669.29,
      "learning_rate": 0.03309748625741936,
      "loss": 0.6045,
      "step": 414960
    },
    {
      "epoch": 669.32,
      "learning_rate": 0.03309426045419355,
      "loss": 0.6117,
      "step": 414980
    },
    {
      "epoch": 669.35,
      "learning_rate": 0.03309103465096774,
      "loss": 0.6148,
      "step": 415000
    },
    {
      "epoch": 669.39,
      "learning_rate": 0.03308780884774194,
      "loss": 0.6099,
      "step": 415020
    },
    {
      "epoch": 669.42,
      "learning_rate": 0.033084583044516135,
      "loss": 0.6034,
      "step": 415040
    },
    {
      "epoch": 669.45,
      "learning_rate": 0.03308135724129033,
      "loss": 0.6134,
      "step": 415060
    },
    {
      "epoch": 669.48,
      "learning_rate": 0.033078131438064526,
      "loss": 0.6129,
      "step": 415080
    },
    {
      "epoch": 669.52,
      "learning_rate": 0.03307490563483872,
      "loss": 0.622,
      "step": 415100
    },
    {
      "epoch": 669.55,
      "learning_rate": 0.03307167983161291,
      "loss": 0.6171,
      "step": 415120
    },
    {
      "epoch": 669.58,
      "learning_rate": 0.03306845402838711,
      "loss": 0.62,
      "step": 415140
    },
    {
      "epoch": 669.61,
      "learning_rate": 0.03306522822516129,
      "loss": 0.6332,
      "step": 415160
    },
    {
      "epoch": 669.65,
      "learning_rate": 0.03306200242193549,
      "loss": 0.6292,
      "step": 415180
    },
    {
      "epoch": 669.68,
      "learning_rate": 0.03305877661870968,
      "loss": 0.6253,
      "step": 415200
    },
    {
      "epoch": 669.71,
      "learning_rate": 0.03305555081548387,
      "loss": 0.6275,
      "step": 415220
    },
    {
      "epoch": 669.74,
      "learning_rate": 0.03305232501225806,
      "loss": 0.6231,
      "step": 415240
    },
    {
      "epoch": 669.77,
      "learning_rate": 0.03304909920903226,
      "loss": 0.6284,
      "step": 415260
    },
    {
      "epoch": 669.81,
      "learning_rate": 0.033045873405806454,
      "loss": 0.6227,
      "step": 415280
    },
    {
      "epoch": 669.84,
      "learning_rate": 0.033042647602580646,
      "loss": 0.6314,
      "step": 415300
    },
    {
      "epoch": 669.87,
      "learning_rate": 0.033039421799354846,
      "loss": 0.6268,
      "step": 415320
    },
    {
      "epoch": 669.9,
      "learning_rate": 0.03303619599612904,
      "loss": 0.6123,
      "step": 415340
    },
    {
      "epoch": 669.94,
      "learning_rate": 0.03303297019290323,
      "loss": 0.6232,
      "step": 415360
    },
    {
      "epoch": 669.97,
      "learning_rate": 0.03302974438967743,
      "loss": 0.628,
      "step": 415380
    },
    {
      "epoch": 670.0,
      "learning_rate": 0.03302651858645162,
      "loss": 0.6334,
      "step": 415400
    },
    {
      "epoch": 670.0,
      "eval_accuracy": {
        "accuracy": 0.7709000078057919
      },
      "eval_loss": 0.9948096871376038,
      "eval_runtime": 3.1191,
      "eval_samples_per_second": 4107.22,
      "eval_steps_per_second": 64.441,
      "step": 415400
    },
    {
      "epoch": 670.03,
      "learning_rate": 0.03302329278322581,
      "loss": 0.6285,
      "step": 415420
    },
    {
      "epoch": 670.06,
      "learning_rate": 0.033020066980000005,
      "loss": 0.617,
      "step": 415440
    },
    {
      "epoch": 670.1,
      "learning_rate": 0.03301684117677419,
      "loss": 0.6163,
      "step": 415460
    },
    {
      "epoch": 670.13,
      "learning_rate": 0.03301361537354838,
      "loss": 0.6086,
      "step": 415480
    },
    {
      "epoch": 670.16,
      "learning_rate": 0.03301038957032258,
      "loss": 0.6221,
      "step": 415500
    },
    {
      "epoch": 670.19,
      "learning_rate": 0.033007163767096774,
      "loss": 0.6119,
      "step": 415520
    },
    {
      "epoch": 670.23,
      "learning_rate": 0.033003937963870966,
      "loss": 0.614,
      "step": 415540
    },
    {
      "epoch": 670.26,
      "learning_rate": 0.033000712160645165,
      "loss": 0.6179,
      "step": 415560
    },
    {
      "epoch": 670.29,
      "learning_rate": 0.03299748635741936,
      "loss": 0.6112,
      "step": 415580
    },
    {
      "epoch": 670.32,
      "learning_rate": 0.03299426055419355,
      "loss": 0.6147,
      "step": 415600
    },
    {
      "epoch": 670.35,
      "learning_rate": 0.03299103475096775,
      "loss": 0.6142,
      "step": 415620
    },
    {
      "epoch": 670.39,
      "learning_rate": 0.03298780894774194,
      "loss": 0.6233,
      "step": 415640
    },
    {
      "epoch": 670.42,
      "learning_rate": 0.03298458314451613,
      "loss": 0.6214,
      "step": 415660
    },
    {
      "epoch": 670.45,
      "learning_rate": 0.03298135734129033,
      "loss": 0.6191,
      "step": 415680
    },
    {
      "epoch": 670.48,
      "learning_rate": 0.032978131538064524,
      "loss": 0.6081,
      "step": 415700
    },
    {
      "epoch": 670.52,
      "learning_rate": 0.032974905734838716,
      "loss": 0.6125,
      "step": 415720
    },
    {
      "epoch": 670.55,
      "learning_rate": 0.03297167993161291,
      "loss": 0.6111,
      "step": 415740
    },
    {
      "epoch": 670.58,
      "learning_rate": 0.03296845412838711,
      "loss": 0.6169,
      "step": 415760
    },
    {
      "epoch": 670.61,
      "learning_rate": 0.032965228325161286,
      "loss": 0.6063,
      "step": 415780
    },
    {
      "epoch": 670.65,
      "learning_rate": 0.032962002521935485,
      "loss": 0.6229,
      "step": 415800
    },
    {
      "epoch": 670.68,
      "learning_rate": 0.03295877671870968,
      "loss": 0.617,
      "step": 415820
    },
    {
      "epoch": 670.71,
      "learning_rate": 0.03295555091548387,
      "loss": 0.6353,
      "step": 415840
    },
    {
      "epoch": 670.74,
      "learning_rate": 0.03295232511225807,
      "loss": 0.6065,
      "step": 415860
    },
    {
      "epoch": 670.77,
      "learning_rate": 0.03294909930903226,
      "loss": 0.6167,
      "step": 415880
    },
    {
      "epoch": 670.81,
      "learning_rate": 0.03294587350580645,
      "loss": 0.6308,
      "step": 415900
    },
    {
      "epoch": 670.84,
      "learning_rate": 0.03294264770258065,
      "loss": 0.6406,
      "step": 415920
    },
    {
      "epoch": 670.87,
      "learning_rate": 0.032939421899354844,
      "loss": 0.6247,
      "step": 415940
    },
    {
      "epoch": 670.9,
      "learning_rate": 0.032936196096129036,
      "loss": 0.6162,
      "step": 415960
    },
    {
      "epoch": 670.94,
      "learning_rate": 0.03293297029290323,
      "loss": 0.6257,
      "step": 415980
    },
    {
      "epoch": 670.97,
      "learning_rate": 0.03292974448967743,
      "loss": 0.6347,
      "step": 416000
    },
    {
      "epoch": 671.0,
      "learning_rate": 0.03292651868645162,
      "loss": 0.6206,
      "step": 416020
    },
    {
      "epoch": 671.0,
      "eval_accuracy": {
        "accuracy": 0.7719928186714542
      },
      "eval_loss": 0.9936229586601257,
      "eval_runtime": 2.9822,
      "eval_samples_per_second": 4295.85,
      "eval_steps_per_second": 67.4,
      "step": 416020
    },
    {
      "epoch": 671.03,
      "learning_rate": 0.03292329288322581,
      "loss": 0.619,
      "step": 416040
    },
    {
      "epoch": 671.06,
      "learning_rate": 0.03292006708000001,
      "loss": 0.6118,
      "step": 416060
    },
    {
      "epoch": 671.1,
      "learning_rate": 0.0329168412767742,
      "loss": 0.6137,
      "step": 416080
    },
    {
      "epoch": 671.13,
      "learning_rate": 0.03291361547354839,
      "loss": 0.6063,
      "step": 416100
    },
    {
      "epoch": 671.16,
      "learning_rate": 0.03291038967032258,
      "loss": 0.6111,
      "step": 416120
    },
    {
      "epoch": 671.19,
      "learning_rate": 0.03290716386709677,
      "loss": 0.6206,
      "step": 416140
    },
    {
      "epoch": 671.23,
      "learning_rate": 0.03290393806387097,
      "loss": 0.6086,
      "step": 416160
    },
    {
      "epoch": 671.26,
      "learning_rate": 0.032900712260645164,
      "loss": 0.6198,
      "step": 416180
    },
    {
      "epoch": 671.29,
      "learning_rate": 0.032897486457419356,
      "loss": 0.6136,
      "step": 416200
    },
    {
      "epoch": 671.32,
      "learning_rate": 0.03289426065419355,
      "loss": 0.6211,
      "step": 416220
    },
    {
      "epoch": 671.35,
      "learning_rate": 0.03289103485096775,
      "loss": 0.6184,
      "step": 416240
    },
    {
      "epoch": 671.39,
      "learning_rate": 0.03288780904774194,
      "loss": 0.6234,
      "step": 416260
    },
    {
      "epoch": 671.42,
      "learning_rate": 0.03288458324451613,
      "loss": 0.6061,
      "step": 416280
    },
    {
      "epoch": 671.45,
      "learning_rate": 0.03288135744129033,
      "loss": 0.6261,
      "step": 416300
    },
    {
      "epoch": 671.48,
      "learning_rate": 0.03287813163806452,
      "loss": 0.6206,
      "step": 416320
    },
    {
      "epoch": 671.52,
      "learning_rate": 0.032874905834838715,
      "loss": 0.6086,
      "step": 416340
    },
    {
      "epoch": 671.55,
      "learning_rate": 0.032871680031612914,
      "loss": 0.6197,
      "step": 416360
    },
    {
      "epoch": 671.58,
      "learning_rate": 0.032868454228387106,
      "loss": 0.6154,
      "step": 416380
    },
    {
      "epoch": 671.61,
      "learning_rate": 0.03286522842516129,
      "loss": 0.615,
      "step": 416400
    },
    {
      "epoch": 671.65,
      "learning_rate": 0.032862002621935484,
      "loss": 0.62,
      "step": 416420
    },
    {
      "epoch": 671.68,
      "learning_rate": 0.032858776818709676,
      "loss": 0.6208,
      "step": 416440
    },
    {
      "epoch": 671.71,
      "learning_rate": 0.032855551015483875,
      "loss": 0.6179,
      "step": 416460
    },
    {
      "epoch": 671.74,
      "learning_rate": 0.03285232521225807,
      "loss": 0.6196,
      "step": 416480
    },
    {
      "epoch": 671.77,
      "learning_rate": 0.03284909940903226,
      "loss": 0.634,
      "step": 416500
    },
    {
      "epoch": 671.81,
      "learning_rate": 0.03284587360580645,
      "loss": 0.6221,
      "step": 416520
    },
    {
      "epoch": 671.84,
      "learning_rate": 0.03284264780258065,
      "loss": 0.629,
      "step": 416540
    },
    {
      "epoch": 671.87,
      "learning_rate": 0.03283942199935484,
      "loss": 0.6284,
      "step": 416560
    },
    {
      "epoch": 671.9,
      "learning_rate": 0.032836196196129035,
      "loss": 0.6233,
      "step": 416580
    },
    {
      "epoch": 671.94,
      "learning_rate": 0.032832970392903234,
      "loss": 0.6255,
      "step": 416600
    },
    {
      "epoch": 671.97,
      "learning_rate": 0.032829744589677426,
      "loss": 0.6195,
      "step": 416620
    },
    {
      "epoch": 672.0,
      "learning_rate": 0.03282651878645162,
      "loss": 0.6264,
      "step": 416640
    },
    {
      "epoch": 672.0,
      "eval_accuracy": {
        "accuracy": 0.7738662087268754
      },
      "eval_loss": 0.9605116844177246,
      "eval_runtime": 3.4863,
      "eval_samples_per_second": 3674.666,
      "eval_steps_per_second": 57.654,
      "step": 416640
    },
    {
      "epoch": 672.03,
      "learning_rate": 0.03282329298322582,
      "loss": 0.6257,
      "step": 416660
    },
    {
      "epoch": 672.06,
      "learning_rate": 0.03282006718000001,
      "loss": 0.6064,
      "step": 416680
    },
    {
      "epoch": 672.1,
      "learning_rate": 0.0328168413767742,
      "loss": 0.6008,
      "step": 416700
    },
    {
      "epoch": 672.13,
      "learning_rate": 0.03281361557354839,
      "loss": 0.6043,
      "step": 416720
    },
    {
      "epoch": 672.16,
      "learning_rate": 0.03281038977032258,
      "loss": 0.608,
      "step": 416740
    },
    {
      "epoch": 672.19,
      "learning_rate": 0.03280716396709677,
      "loss": 0.6072,
      "step": 416760
    },
    {
      "epoch": 672.23,
      "learning_rate": 0.03280393816387097,
      "loss": 0.6065,
      "step": 416780
    },
    {
      "epoch": 672.26,
      "learning_rate": 0.03280071236064516,
      "loss": 0.6136,
      "step": 416800
    },
    {
      "epoch": 672.29,
      "learning_rate": 0.032797486557419354,
      "loss": 0.6231,
      "step": 416820
    },
    {
      "epoch": 672.32,
      "learning_rate": 0.032794260754193554,
      "loss": 0.61,
      "step": 416840
    },
    {
      "epoch": 672.35,
      "learning_rate": 0.032791034950967746,
      "loss": 0.6043,
      "step": 416860
    },
    {
      "epoch": 672.39,
      "learning_rate": 0.03278780914774194,
      "loss": 0.6083,
      "step": 416880
    },
    {
      "epoch": 672.42,
      "learning_rate": 0.03278458334451614,
      "loss": 0.6095,
      "step": 416900
    },
    {
      "epoch": 672.45,
      "learning_rate": 0.03278135754129033,
      "loss": 0.6032,
      "step": 416920
    },
    {
      "epoch": 672.48,
      "learning_rate": 0.03277813173806452,
      "loss": 0.5985,
      "step": 416940
    },
    {
      "epoch": 672.52,
      "learning_rate": 0.03277490593483872,
      "loss": 0.6148,
      "step": 416960
    },
    {
      "epoch": 672.55,
      "learning_rate": 0.03277168013161291,
      "loss": 0.6167,
      "step": 416980
    },
    {
      "epoch": 672.58,
      "learning_rate": 0.032768454328387105,
      "loss": 0.6151,
      "step": 417000
    },
    {
      "epoch": 672.61,
      "learning_rate": 0.03276522852516129,
      "loss": 0.614,
      "step": 417020
    },
    {
      "epoch": 672.65,
      "learning_rate": 0.03276200272193548,
      "loss": 0.6125,
      "step": 417040
    },
    {
      "epoch": 672.68,
      "learning_rate": 0.032758776918709674,
      "loss": 0.6224,
      "step": 417060
    },
    {
      "epoch": 672.71,
      "learning_rate": 0.03275555111548387,
      "loss": 0.6094,
      "step": 417080
    },
    {
      "epoch": 672.74,
      "learning_rate": 0.032752325312258065,
      "loss": 0.6294,
      "step": 417100
    },
    {
      "epoch": 672.77,
      "learning_rate": 0.03274909950903226,
      "loss": 0.6217,
      "step": 417120
    },
    {
      "epoch": 672.81,
      "learning_rate": 0.03274587370580646,
      "loss": 0.6375,
      "step": 417140
    },
    {
      "epoch": 672.84,
      "learning_rate": 0.03274264790258065,
      "loss": 0.6261,
      "step": 417160
    },
    {
      "epoch": 672.87,
      "learning_rate": 0.03273942209935484,
      "loss": 0.6394,
      "step": 417180
    },
    {
      "epoch": 672.9,
      "learning_rate": 0.03273619629612904,
      "loss": 0.6235,
      "step": 417200
    },
    {
      "epoch": 672.94,
      "learning_rate": 0.03273297049290323,
      "loss": 0.6307,
      "step": 417220
    },
    {
      "epoch": 672.97,
      "learning_rate": 0.032729744689677424,
      "loss": 0.6317,
      "step": 417240
    },
    {
      "epoch": 673.0,
      "learning_rate": 0.03272651888645162,
      "loss": 0.6403,
      "step": 417260
    },
    {
      "epoch": 673.0,
      "eval_accuracy": {
        "accuracy": 0.7729295136991647
      },
      "eval_loss": 0.9810314774513245,
      "eval_runtime": 3.0517,
      "eval_samples_per_second": 4197.991,
      "eval_steps_per_second": 65.865,
      "step": 417260
    },
    {
      "epoch": 673.03,
      "learning_rate": 0.032723293083225816,
      "loss": 0.6204,
      "step": 417280
    },
    {
      "epoch": 673.06,
      "learning_rate": 0.03272006728000001,
      "loss": 0.604,
      "step": 417300
    },
    {
      "epoch": 673.1,
      "learning_rate": 0.0327168414767742,
      "loss": 0.6,
      "step": 417320
    },
    {
      "epoch": 673.13,
      "learning_rate": 0.032713615673548385,
      "loss": 0.6008,
      "step": 417340
    },
    {
      "epoch": 673.16,
      "learning_rate": 0.03271038987032258,
      "loss": 0.5995,
      "step": 417360
    },
    {
      "epoch": 673.19,
      "learning_rate": 0.032707164067096776,
      "loss": 0.623,
      "step": 417380
    },
    {
      "epoch": 673.23,
      "learning_rate": 0.03270393826387097,
      "loss": 0.5978,
      "step": 417400
    },
    {
      "epoch": 673.26,
      "learning_rate": 0.03270071246064516,
      "loss": 0.6065,
      "step": 417420
    },
    {
      "epoch": 673.29,
      "learning_rate": 0.03269748665741936,
      "loss": 0.6211,
      "step": 417440
    },
    {
      "epoch": 673.32,
      "learning_rate": 0.03269426085419355,
      "loss": 0.6191,
      "step": 417460
    },
    {
      "epoch": 673.35,
      "learning_rate": 0.032691035050967744,
      "loss": 0.63,
      "step": 417480
    },
    {
      "epoch": 673.39,
      "learning_rate": 0.03268780924774194,
      "loss": 0.6174,
      "step": 417500
    },
    {
      "epoch": 673.42,
      "learning_rate": 0.032684583444516135,
      "loss": 0.6027,
      "step": 417520
    },
    {
      "epoch": 673.45,
      "learning_rate": 0.03268135764129033,
      "loss": 0.6035,
      "step": 417540
    },
    {
      "epoch": 673.48,
      "learning_rate": 0.03267813183806452,
      "loss": 0.6165,
      "step": 417560
    },
    {
      "epoch": 673.52,
      "learning_rate": 0.03267490603483872,
      "loss": 0.608,
      "step": 417580
    },
    {
      "epoch": 673.55,
      "learning_rate": 0.03267168023161291,
      "loss": 0.6167,
      "step": 417600
    },
    {
      "epoch": 673.58,
      "learning_rate": 0.0326684544283871,
      "loss": 0.6151,
      "step": 417620
    },
    {
      "epoch": 673.61,
      "learning_rate": 0.03266522862516129,
      "loss": 0.6253,
      "step": 417640
    },
    {
      "epoch": 673.65,
      "learning_rate": 0.03266200282193548,
      "loss": 0.6271,
      "step": 417660
    },
    {
      "epoch": 673.68,
      "learning_rate": 0.03265877701870968,
      "loss": 0.6276,
      "step": 417680
    },
    {
      "epoch": 673.71,
      "learning_rate": 0.03265555121548387,
      "loss": 0.6267,
      "step": 417700
    },
    {
      "epoch": 673.74,
      "learning_rate": 0.032652325412258064,
      "loss": 0.6351,
      "step": 417720
    },
    {
      "epoch": 673.77,
      "learning_rate": 0.03264909960903226,
      "loss": 0.6305,
      "step": 417740
    },
    {
      "epoch": 673.81,
      "learning_rate": 0.032645873805806455,
      "loss": 0.6109,
      "step": 417760
    },
    {
      "epoch": 673.84,
      "learning_rate": 0.03264264800258065,
      "loss": 0.621,
      "step": 417780
    },
    {
      "epoch": 673.87,
      "learning_rate": 0.03263942219935484,
      "loss": 0.6241,
      "step": 417800
    },
    {
      "epoch": 673.9,
      "learning_rate": 0.03263619639612904,
      "loss": 0.6229,
      "step": 417820
    },
    {
      "epoch": 673.94,
      "learning_rate": 0.03263297059290323,
      "loss": 0.6066,
      "step": 417840
    },
    {
      "epoch": 673.97,
      "learning_rate": 0.03262974478967742,
      "loss": 0.6062,
      "step": 417860
    },
    {
      "epoch": 674.0,
      "learning_rate": 0.03262651898645162,
      "loss": 0.6234,
      "step": 417880
    },
    {
      "epoch": 674.0,
      "eval_accuracy": {
        "accuracy": 0.7733198032940442
      },
      "eval_loss": 0.9872509241104126,
      "eval_runtime": 2.9648,
      "eval_samples_per_second": 4321.078,
      "eval_steps_per_second": 67.796,
      "step": 417880
    },
    {
      "epoch": 674.03,
      "learning_rate": 0.032623293183225814,
      "loss": 0.6221,
      "step": 417900
    },
    {
      "epoch": 674.06,
      "learning_rate": 0.032620067380000006,
      "loss": 0.6184,
      "step": 417920
    },
    {
      "epoch": 674.1,
      "learning_rate": 0.032616841576774205,
      "loss": 0.5959,
      "step": 417940
    },
    {
      "epoch": 674.13,
      "learning_rate": 0.032613615773548384,
      "loss": 0.5969,
      "step": 417960
    },
    {
      "epoch": 674.16,
      "learning_rate": 0.03261038997032258,
      "loss": 0.6187,
      "step": 417980
    },
    {
      "epoch": 674.19,
      "learning_rate": 0.032607164167096775,
      "loss": 0.6137,
      "step": 418000
    },
    {
      "epoch": 674.23,
      "learning_rate": 0.03260393836387097,
      "loss": 0.6111,
      "step": 418020
    },
    {
      "epoch": 674.26,
      "learning_rate": 0.032600712560645166,
      "loss": 0.6156,
      "step": 418040
    },
    {
      "epoch": 674.29,
      "learning_rate": 0.03259748675741936,
      "loss": 0.6118,
      "step": 418060
    },
    {
      "epoch": 674.32,
      "learning_rate": 0.03259426095419355,
      "loss": 0.6152,
      "step": 418080
    },
    {
      "epoch": 674.35,
      "learning_rate": 0.03259103515096774,
      "loss": 0.6318,
      "step": 418100
    },
    {
      "epoch": 674.39,
      "learning_rate": 0.03258780934774194,
      "loss": 0.6068,
      "step": 418120
    },
    {
      "epoch": 674.42,
      "learning_rate": 0.032584583544516134,
      "loss": 0.6187,
      "step": 418140
    },
    {
      "epoch": 674.45,
      "learning_rate": 0.032581357741290326,
      "loss": 0.606,
      "step": 418160
    },
    {
      "epoch": 674.48,
      "learning_rate": 0.032578131938064525,
      "loss": 0.6258,
      "step": 418180
    },
    {
      "epoch": 674.52,
      "learning_rate": 0.03257490613483872,
      "loss": 0.6281,
      "step": 418200
    },
    {
      "epoch": 674.55,
      "learning_rate": 0.03257168033161291,
      "loss": 0.6222,
      "step": 418220
    },
    {
      "epoch": 674.58,
      "learning_rate": 0.03256845452838711,
      "loss": 0.6097,
      "step": 418240
    },
    {
      "epoch": 674.61,
      "learning_rate": 0.03256522872516129,
      "loss": 0.6092,
      "step": 418260
    },
    {
      "epoch": 674.65,
      "learning_rate": 0.032562002921935486,
      "loss": 0.6084,
      "step": 418280
    },
    {
      "epoch": 674.68,
      "learning_rate": 0.03255877711870968,
      "loss": 0.6199,
      "step": 418300
    },
    {
      "epoch": 674.71,
      "learning_rate": 0.03255555131548387,
      "loss": 0.6179,
      "step": 418320
    },
    {
      "epoch": 674.74,
      "learning_rate": 0.03255232551225806,
      "loss": 0.6145,
      "step": 418340
    },
    {
      "epoch": 674.77,
      "learning_rate": 0.03254909970903226,
      "loss": 0.6191,
      "step": 418360
    },
    {
      "epoch": 674.81,
      "learning_rate": 0.032545873905806454,
      "loss": 0.6072,
      "step": 418380
    },
    {
      "epoch": 674.84,
      "learning_rate": 0.032542648102580646,
      "loss": 0.6095,
      "step": 418400
    },
    {
      "epoch": 674.87,
      "learning_rate": 0.032539422299354845,
      "loss": 0.6163,
      "step": 418420
    },
    {
      "epoch": 674.9,
      "learning_rate": 0.03253619649612904,
      "loss": 0.6111,
      "step": 418440
    },
    {
      "epoch": 674.94,
      "learning_rate": 0.03253297069290323,
      "loss": 0.6295,
      "step": 418460
    },
    {
      "epoch": 674.97,
      "learning_rate": 0.03252974488967743,
      "loss": 0.6133,
      "step": 418480
    },
    {
      "epoch": 675.0,
      "learning_rate": 0.03252651908645162,
      "loss": 0.62,
      "step": 418500
    },
    {
      "epoch": 675.0,
      "eval_accuracy": {
        "accuracy": 0.7634845055030833
      },
      "eval_loss": 1.0192503929138184,
      "eval_runtime": 3.1377,
      "eval_samples_per_second": 4082.923,
      "eval_steps_per_second": 64.06,
      "step": 418500
    },
    {
      "epoch": 675.03,
      "learning_rate": 0.03252329328322581,
      "loss": 0.6284,
      "step": 418520
    },
    {
      "epoch": 675.06,
      "learning_rate": 0.032520067480000005,
      "loss": 0.6211,
      "step": 418540
    },
    {
      "epoch": 675.1,
      "learning_rate": 0.032516841676774204,
      "loss": 0.6096,
      "step": 418560
    },
    {
      "epoch": 675.13,
      "learning_rate": 0.03251361587354839,
      "loss": 0.5977,
      "step": 418580
    },
    {
      "epoch": 675.16,
      "learning_rate": 0.03251039007032258,
      "loss": 0.6158,
      "step": 418600
    },
    {
      "epoch": 675.19,
      "learning_rate": 0.03250716426709677,
      "loss": 0.6053,
      "step": 418620
    },
    {
      "epoch": 675.23,
      "learning_rate": 0.032503938463870966,
      "loss": 0.6046,
      "step": 418640
    },
    {
      "epoch": 675.26,
      "learning_rate": 0.032500712660645165,
      "loss": 0.6174,
      "step": 418660
    },
    {
      "epoch": 675.29,
      "learning_rate": 0.03249748685741936,
      "loss": 0.6038,
      "step": 418680
    },
    {
      "epoch": 675.32,
      "learning_rate": 0.03249426105419355,
      "loss": 0.6159,
      "step": 418700
    },
    {
      "epoch": 675.35,
      "learning_rate": 0.03249103525096775,
      "loss": 0.5995,
      "step": 418720
    },
    {
      "epoch": 675.39,
      "learning_rate": 0.03248780944774194,
      "loss": 0.6158,
      "step": 418740
    },
    {
      "epoch": 675.42,
      "learning_rate": 0.03248458364451613,
      "loss": 0.623,
      "step": 418760
    },
    {
      "epoch": 675.45,
      "learning_rate": 0.03248135784129033,
      "loss": 0.6042,
      "step": 418780
    },
    {
      "epoch": 675.48,
      "learning_rate": 0.032478293328225806,
      "loss": 0.6347,
      "step": 418800
    },
    {
      "epoch": 675.52,
      "learning_rate": 0.032475067525000005,
      "loss": 0.6247,
      "step": 418820
    },
    {
      "epoch": 675.55,
      "learning_rate": 0.0324718417217742,
      "loss": 0.6345,
      "step": 418840
    },
    {
      "epoch": 675.58,
      "learning_rate": 0.03246861591854839,
      "loss": 0.6305,
      "step": 418860
    },
    {
      "epoch": 675.61,
      "learning_rate": 0.03246539011532258,
      "loss": 0.6226,
      "step": 418880
    },
    {
      "epoch": 675.65,
      "learning_rate": 0.03246216431209678,
      "loss": 0.6098,
      "step": 418900
    },
    {
      "epoch": 675.68,
      "learning_rate": 0.03245893850887097,
      "loss": 0.6066,
      "step": 418920
    },
    {
      "epoch": 675.71,
      "learning_rate": 0.032455712705645165,
      "loss": 0.624,
      "step": 418940
    },
    {
      "epoch": 675.74,
      "learning_rate": 0.032452486902419364,
      "loss": 0.621,
      "step": 418960
    },
    {
      "epoch": 675.77,
      "learning_rate": 0.032449261099193556,
      "loss": 0.6286,
      "step": 418980
    },
    {
      "epoch": 675.81,
      "learning_rate": 0.03244603529596775,
      "loss": 0.6078,
      "step": 419000
    },
    {
      "epoch": 675.84,
      "learning_rate": 0.03244280949274195,
      "loss": 0.631,
      "step": 419020
    },
    {
      "epoch": 675.87,
      "learning_rate": 0.032439583689516126,
      "loss": 0.6309,
      "step": 419040
    },
    {
      "epoch": 675.9,
      "learning_rate": 0.032436357886290325,
      "loss": 0.6236,
      "step": 419060
    },
    {
      "epoch": 675.94,
      "learning_rate": 0.03243313208306452,
      "loss": 0.6298,
      "step": 419080
    },
    {
      "epoch": 675.97,
      "learning_rate": 0.03242990627983871,
      "loss": 0.6193,
      "step": 419100
    },
    {
      "epoch": 676.0,
      "learning_rate": 0.032426841766774205,
      "loss": 0.6287,
      "step": 419120
    },
    {
      "epoch": 676.0,
      "eval_accuracy": {
        "accuracy": 0.7746467879166341
      },
      "eval_loss": 0.9723544716835022,
      "eval_runtime": 2.9363,
      "eval_samples_per_second": 4362.971,
      "eval_steps_per_second": 68.453,
      "step": 419120
    },
    {
      "epoch": 676.03,
      "learning_rate": 0.0324236159635484,
      "loss": 0.6087,
      "step": 419140
    },
    {
      "epoch": 676.06,
      "learning_rate": 0.03242039016032259,
      "loss": 0.6053,
      "step": 419160
    },
    {
      "epoch": 676.1,
      "learning_rate": 0.032417164357096774,
      "loss": 0.6017,
      "step": 419180
    },
    {
      "epoch": 676.13,
      "learning_rate": 0.032413938553870966,
      "loss": 0.6004,
      "step": 419200
    },
    {
      "epoch": 676.16,
      "learning_rate": 0.03241071275064516,
      "loss": 0.6021,
      "step": 419220
    },
    {
      "epoch": 676.19,
      "learning_rate": 0.03240748694741936,
      "loss": 0.6105,
      "step": 419240
    },
    {
      "epoch": 676.23,
      "learning_rate": 0.03240426114419355,
      "loss": 0.6163,
      "step": 419260
    },
    {
      "epoch": 676.26,
      "learning_rate": 0.03240103534096774,
      "loss": 0.6154,
      "step": 419280
    },
    {
      "epoch": 676.29,
      "learning_rate": 0.03239780953774194,
      "loss": 0.6031,
      "step": 419300
    },
    {
      "epoch": 676.32,
      "learning_rate": 0.03239458373451613,
      "loss": 0.6187,
      "step": 419320
    },
    {
      "epoch": 676.35,
      "learning_rate": 0.032391357931290325,
      "loss": 0.6269,
      "step": 419340
    },
    {
      "epoch": 676.39,
      "learning_rate": 0.032388132128064524,
      "loss": 0.614,
      "step": 419360
    },
    {
      "epoch": 676.42,
      "learning_rate": 0.032384906324838716,
      "loss": 0.6141,
      "step": 419380
    },
    {
      "epoch": 676.45,
      "learning_rate": 0.03238168052161291,
      "loss": 0.6032,
      "step": 419400
    },
    {
      "epoch": 676.48,
      "learning_rate": 0.0323784547183871,
      "loss": 0.6212,
      "step": 419420
    },
    {
      "epoch": 676.52,
      "learning_rate": 0.0323752289151613,
      "loss": 0.6102,
      "step": 419440
    },
    {
      "epoch": 676.55,
      "learning_rate": 0.03237200311193549,
      "loss": 0.6102,
      "step": 419460
    },
    {
      "epoch": 676.58,
      "learning_rate": 0.03236877730870968,
      "loss": 0.6205,
      "step": 419480
    },
    {
      "epoch": 676.61,
      "learning_rate": 0.03236555150548387,
      "loss": 0.609,
      "step": 419500
    },
    {
      "epoch": 676.65,
      "learning_rate": 0.03236232570225806,
      "loss": 0.6144,
      "step": 419520
    },
    {
      "epoch": 676.68,
      "learning_rate": 0.03235909989903226,
      "loss": 0.6253,
      "step": 419540
    },
    {
      "epoch": 676.71,
      "learning_rate": 0.03235587409580645,
      "loss": 0.6263,
      "step": 419560
    },
    {
      "epoch": 676.74,
      "learning_rate": 0.032352648292580645,
      "loss": 0.6082,
      "step": 419580
    },
    {
      "epoch": 676.77,
      "learning_rate": 0.032349422489354844,
      "loss": 0.622,
      "step": 419600
    },
    {
      "epoch": 676.81,
      "learning_rate": 0.032346196686129036,
      "loss": 0.6144,
      "step": 419620
    },
    {
      "epoch": 676.84,
      "learning_rate": 0.03234297088290323,
      "loss": 0.6272,
      "step": 419640
    },
    {
      "epoch": 676.87,
      "learning_rate": 0.03233974507967743,
      "loss": 0.6256,
      "step": 419660
    },
    {
      "epoch": 676.9,
      "learning_rate": 0.03233651927645162,
      "loss": 0.6172,
      "step": 419680
    },
    {
      "epoch": 676.94,
      "learning_rate": 0.03233329347322581,
      "loss": 0.6252,
      "step": 419700
    },
    {
      "epoch": 676.97,
      "learning_rate": 0.032330067670000004,
      "loss": 0.632,
      "step": 419720
    },
    {
      "epoch": 677.0,
      "learning_rate": 0.0323268418667742,
      "loss": 0.63,
      "step": 419740
    },
    {
      "epoch": 677.0,
      "eval_accuracy": {
        "accuracy": 0.7699633127780814
      },
      "eval_loss": 0.9823743104934692,
      "eval_runtime": 3.1072,
      "eval_samples_per_second": 4123.021,
      "eval_steps_per_second": 64.689,
      "step": 419740
    },
    {
      "epoch": 677.03,
      "learning_rate": 0.032323616063548395,
      "loss": 0.6329,
      "step": 419760
    },
    {
      "epoch": 677.06,
      "learning_rate": 0.03232039026032259,
      "loss": 0.6254,
      "step": 419780
    },
    {
      "epoch": 677.1,
      "learning_rate": 0.03231716445709677,
      "loss": 0.6155,
      "step": 419800
    },
    {
      "epoch": 677.13,
      "learning_rate": 0.032313938653870965,
      "loss": 0.6023,
      "step": 419820
    },
    {
      "epoch": 677.16,
      "learning_rate": 0.032310712850645164,
      "loss": 0.6062,
      "step": 419840
    },
    {
      "epoch": 677.19,
      "learning_rate": 0.032307487047419356,
      "loss": 0.6165,
      "step": 419860
    },
    {
      "epoch": 677.23,
      "learning_rate": 0.03230426124419355,
      "loss": 0.6071,
      "step": 419880
    },
    {
      "epoch": 677.26,
      "learning_rate": 0.03230103544096775,
      "loss": 0.6112,
      "step": 419900
    },
    {
      "epoch": 677.29,
      "learning_rate": 0.03229780963774194,
      "loss": 0.5903,
      "step": 419920
    },
    {
      "epoch": 677.32,
      "learning_rate": 0.03229458383451613,
      "loss": 0.6109,
      "step": 419940
    },
    {
      "epoch": 677.35,
      "learning_rate": 0.032291358031290324,
      "loss": 0.6131,
      "step": 419960
    },
    {
      "epoch": 677.39,
      "learning_rate": 0.03228813222806452,
      "loss": 0.6141,
      "step": 419980
    },
    {
      "epoch": 677.42,
      "learning_rate": 0.032284906424838715,
      "loss": 0.6248,
      "step": 420000
    },
    {
      "epoch": 677.45,
      "learning_rate": 0.03228168062161291,
      "loss": 0.6225,
      "step": 420020
    },
    {
      "epoch": 677.48,
      "learning_rate": 0.032278454818387106,
      "loss": 0.6048,
      "step": 420040
    },
    {
      "epoch": 677.52,
      "learning_rate": 0.0322752290151613,
      "loss": 0.6082,
      "step": 420060
    },
    {
      "epoch": 677.55,
      "learning_rate": 0.03227200321193549,
      "loss": 0.628,
      "step": 420080
    },
    {
      "epoch": 677.58,
      "learning_rate": 0.032268777408709676,
      "loss": 0.6159,
      "step": 420100
    },
    {
      "epoch": 677.61,
      "learning_rate": 0.03226555160548387,
      "loss": 0.6107,
      "step": 420120
    },
    {
      "epoch": 677.65,
      "learning_rate": 0.03226232580225807,
      "loss": 0.6166,
      "step": 420140
    },
    {
      "epoch": 677.68,
      "learning_rate": 0.03225909999903226,
      "loss": 0.6142,
      "step": 420160
    },
    {
      "epoch": 677.71,
      "learning_rate": 0.03225587419580645,
      "loss": 0.621,
      "step": 420180
    },
    {
      "epoch": 677.74,
      "learning_rate": 0.03225264839258065,
      "loss": 0.619,
      "step": 420200
    },
    {
      "epoch": 677.77,
      "learning_rate": 0.03224942258935484,
      "loss": 0.617,
      "step": 420220
    },
    {
      "epoch": 677.81,
      "learning_rate": 0.032246196786129035,
      "loss": 0.6119,
      "step": 420240
    },
    {
      "epoch": 677.84,
      "learning_rate": 0.03224297098290323,
      "loss": 0.6275,
      "step": 420260
    },
    {
      "epoch": 677.87,
      "learning_rate": 0.032239745179677426,
      "loss": 0.6146,
      "step": 420280
    },
    {
      "epoch": 677.9,
      "learning_rate": 0.03223651937645162,
      "loss": 0.6015,
      "step": 420300
    },
    {
      "epoch": 677.94,
      "learning_rate": 0.03223329357322581,
      "loss": 0.611,
      "step": 420320
    },
    {
      "epoch": 677.97,
      "learning_rate": 0.03223006777000001,
      "loss": 0.6271,
      "step": 420340
    },
    {
      "epoch": 678.0,
      "learning_rate": 0.0322268419667742,
      "loss": 0.6295,
      "step": 420360
    },
    {
      "epoch": 678.0,
      "eval_accuracy": {
        "accuracy": 0.7716025290765748
      },
      "eval_loss": 0.9788290858268738,
      "eval_runtime": 3.0244,
      "eval_samples_per_second": 4235.836,
      "eval_steps_per_second": 66.459,
      "step": 420360
    },
    {
      "epoch": 678.03,
      "learning_rate": 0.032223616163548394,
      "loss": 0.6346,
      "step": 420380
    },
    {
      "epoch": 678.06,
      "learning_rate": 0.03222039036032259,
      "loss": 0.6073,
      "step": 420400
    },
    {
      "epoch": 678.1,
      "learning_rate": 0.03221716455709677,
      "loss": 0.6083,
      "step": 420420
    },
    {
      "epoch": 678.13,
      "learning_rate": 0.03221393875387097,
      "loss": 0.6012,
      "step": 420440
    },
    {
      "epoch": 678.16,
      "learning_rate": 0.03221071295064516,
      "loss": 0.6066,
      "step": 420460
    },
    {
      "epoch": 678.19,
      "learning_rate": 0.032207487147419354,
      "loss": 0.6112,
      "step": 420480
    },
    {
      "epoch": 678.23,
      "learning_rate": 0.03220426134419355,
      "loss": 0.5838,
      "step": 420500
    },
    {
      "epoch": 678.26,
      "learning_rate": 0.032201035540967746,
      "loss": 0.5894,
      "step": 420520
    },
    {
      "epoch": 678.29,
      "learning_rate": 0.03219780973774194,
      "loss": 0.6121,
      "step": 420540
    },
    {
      "epoch": 678.32,
      "learning_rate": 0.03219458393451613,
      "loss": 0.6136,
      "step": 420560
    },
    {
      "epoch": 678.35,
      "learning_rate": 0.03219135813129033,
      "loss": 0.618,
      "step": 420580
    },
    {
      "epoch": 678.39,
      "learning_rate": 0.03218813232806452,
      "loss": 0.6184,
      "step": 420600
    },
    {
      "epoch": 678.42,
      "learning_rate": 0.03218490652483871,
      "loss": 0.619,
      "step": 420620
    },
    {
      "epoch": 678.45,
      "learning_rate": 0.03218168072161291,
      "loss": 0.6176,
      "step": 420640
    },
    {
      "epoch": 678.48,
      "learning_rate": 0.032178454918387105,
      "loss": 0.6177,
      "step": 420660
    },
    {
      "epoch": 678.52,
      "learning_rate": 0.0321752291151613,
      "loss": 0.6225,
      "step": 420680
    },
    {
      "epoch": 678.55,
      "learning_rate": 0.032172003311935496,
      "loss": 0.6195,
      "step": 420700
    },
    {
      "epoch": 678.58,
      "learning_rate": 0.03216877750870969,
      "loss": 0.6366,
      "step": 420720
    },
    {
      "epoch": 678.61,
      "learning_rate": 0.03216555170548387,
      "loss": 0.6163,
      "step": 420740
    },
    {
      "epoch": 678.65,
      "learning_rate": 0.032162325902258065,
      "loss": 0.6131,
      "step": 420760
    },
    {
      "epoch": 678.68,
      "learning_rate": 0.03215910009903226,
      "loss": 0.6002,
      "step": 420780
    },
    {
      "epoch": 678.71,
      "learning_rate": 0.03215587429580645,
      "loss": 0.6124,
      "step": 420800
    },
    {
      "epoch": 678.74,
      "learning_rate": 0.03215264849258065,
      "loss": 0.6055,
      "step": 420820
    },
    {
      "epoch": 678.77,
      "learning_rate": 0.03214942268935484,
      "loss": 0.6283,
      "step": 420840
    },
    {
      "epoch": 678.81,
      "learning_rate": 0.03214619688612903,
      "loss": 0.6217,
      "step": 420860
    },
    {
      "epoch": 678.84,
      "learning_rate": 0.03214297108290323,
      "loss": 0.6157,
      "step": 420880
    },
    {
      "epoch": 678.87,
      "learning_rate": 0.032139745279677424,
      "loss": 0.6054,
      "step": 420900
    },
    {
      "epoch": 678.9,
      "learning_rate": 0.03213651947645162,
      "loss": 0.61,
      "step": 420920
    },
    {
      "epoch": 678.94,
      "learning_rate": 0.032133293673225816,
      "loss": 0.623,
      "step": 420940
    },
    {
      "epoch": 678.97,
      "learning_rate": 0.03213006787000001,
      "loss": 0.6113,
      "step": 420960
    },
    {
      "epoch": 679.0,
      "learning_rate": 0.0321268420667742,
      "loss": 0.6222,
      "step": 420980
    },
    {
      "epoch": 679.0,
      "eval_accuracy": {
        "accuracy": 0.7752712512684412
      },
      "eval_loss": 0.9859462380409241,
      "eval_runtime": 3.12,
      "eval_samples_per_second": 4106.129,
      "eval_steps_per_second": 64.424,
      "step": 420980
    },
    {
      "epoch": 679.03,
      "learning_rate": 0.03212361626354839,
      "loss": 0.6157,
      "step": 421000
    },
    {
      "epoch": 679.06,
      "learning_rate": 0.03212039046032259,
      "loss": 0.6065,
      "step": 421020
    },
    {
      "epoch": 679.1,
      "learning_rate": 0.03211716465709677,
      "loss": 0.6049,
      "step": 421040
    },
    {
      "epoch": 679.13,
      "learning_rate": 0.03211393885387097,
      "loss": 0.6012,
      "step": 421060
    },
    {
      "epoch": 679.16,
      "learning_rate": 0.03211071305064516,
      "loss": 0.5919,
      "step": 421080
    },
    {
      "epoch": 679.19,
      "learning_rate": 0.03210748724741935,
      "loss": 0.6044,
      "step": 421100
    },
    {
      "epoch": 679.23,
      "learning_rate": 0.03210426144419355,
      "loss": 0.6117,
      "step": 421120
    },
    {
      "epoch": 679.26,
      "learning_rate": 0.032101035640967744,
      "loss": 0.6111,
      "step": 421140
    },
    {
      "epoch": 679.29,
      "learning_rate": 0.032097809837741936,
      "loss": 0.6107,
      "step": 421160
    },
    {
      "epoch": 679.32,
      "learning_rate": 0.032094584034516135,
      "loss": 0.6042,
      "step": 421180
    },
    {
      "epoch": 679.35,
      "learning_rate": 0.03209135823129033,
      "loss": 0.6082,
      "step": 421200
    },
    {
      "epoch": 679.39,
      "learning_rate": 0.03208813242806452,
      "loss": 0.6086,
      "step": 421220
    },
    {
      "epoch": 679.42,
      "learning_rate": 0.03208490662483871,
      "loss": 0.6052,
      "step": 421240
    },
    {
      "epoch": 679.45,
      "learning_rate": 0.03208168082161291,
      "loss": 0.6101,
      "step": 421260
    },
    {
      "epoch": 679.48,
      "learning_rate": 0.0320784550183871,
      "loss": 0.626,
      "step": 421280
    },
    {
      "epoch": 679.52,
      "learning_rate": 0.032075229215161295,
      "loss": 0.6227,
      "step": 421300
    },
    {
      "epoch": 679.55,
      "learning_rate": 0.032072003411935494,
      "loss": 0.6072,
      "step": 421320
    },
    {
      "epoch": 679.58,
      "learning_rate": 0.032068777608709687,
      "loss": 0.6084,
      "step": 421340
    },
    {
      "epoch": 679.61,
      "learning_rate": 0.03206555180548387,
      "loss": 0.6173,
      "step": 421360
    },
    {
      "epoch": 679.65,
      "learning_rate": 0.032062326002258064,
      "loss": 0.6144,
      "step": 421380
    },
    {
      "epoch": 679.68,
      "learning_rate": 0.032059100199032256,
      "loss": 0.6283,
      "step": 421400
    },
    {
      "epoch": 679.71,
      "learning_rate": 0.032055874395806455,
      "loss": 0.6306,
      "step": 421420
    },
    {
      "epoch": 679.74,
      "learning_rate": 0.03205264859258065,
      "loss": 0.6186,
      "step": 421440
    },
    {
      "epoch": 679.77,
      "learning_rate": 0.03204942278935484,
      "loss": 0.6176,
      "step": 421460
    },
    {
      "epoch": 679.81,
      "learning_rate": 0.03204619698612904,
      "loss": 0.622,
      "step": 421480
    },
    {
      "epoch": 679.84,
      "learning_rate": 0.03204297118290323,
      "loss": 0.6125,
      "step": 421500
    },
    {
      "epoch": 679.87,
      "learning_rate": 0.03203974537967742,
      "loss": 0.6323,
      "step": 421520
    },
    {
      "epoch": 679.9,
      "learning_rate": 0.032036519576451615,
      "loss": 0.63,
      "step": 421540
    },
    {
      "epoch": 679.94,
      "learning_rate": 0.032033293773225814,
      "loss": 0.6211,
      "step": 421560
    },
    {
      "epoch": 679.97,
      "learning_rate": 0.032030067970000006,
      "loss": 0.6169,
      "step": 421580
    },
    {
      "epoch": 680.0,
      "learning_rate": 0.0320268421667742,
      "loss": 0.6143,
      "step": 421600
    },
    {
      "epoch": 680.0,
      "eval_accuracy": {
        "accuracy": 0.7706658340488642
      },
      "eval_loss": 0.9716174602508545,
      "eval_runtime": 2.9515,
      "eval_samples_per_second": 4340.542,
      "eval_steps_per_second": 68.102,
      "step": 421600
    },
    {
      "epoch": 680.03,
      "learning_rate": 0.0320236163635484,
      "loss": 0.6314,
      "step": 421620
    },
    {
      "epoch": 680.06,
      "learning_rate": 0.03202039056032259,
      "loss": 0.6043,
      "step": 421640
    },
    {
      "epoch": 680.1,
      "learning_rate": 0.032017164757096775,
      "loss": 0.6064,
      "step": 421660
    },
    {
      "epoch": 680.13,
      "learning_rate": 0.03201393895387097,
      "loss": 0.6075,
      "step": 421680
    },
    {
      "epoch": 680.16,
      "learning_rate": 0.03201071315064516,
      "loss": 0.6008,
      "step": 421700
    },
    {
      "epoch": 680.19,
      "learning_rate": 0.03200748734741936,
      "loss": 0.602,
      "step": 421720
    },
    {
      "epoch": 680.23,
      "learning_rate": 0.03200426154419355,
      "loss": 0.5919,
      "step": 421740
    },
    {
      "epoch": 680.26,
      "learning_rate": 0.03200103574096774,
      "loss": 0.6113,
      "step": 421760
    },
    {
      "epoch": 680.29,
      "learning_rate": 0.031997809937741935,
      "loss": 0.5995,
      "step": 421780
    },
    {
      "epoch": 680.32,
      "learning_rate": 0.031994584134516134,
      "loss": 0.6219,
      "step": 421800
    },
    {
      "epoch": 680.35,
      "learning_rate": 0.031991358331290326,
      "loss": 0.6179,
      "step": 421820
    },
    {
      "epoch": 680.39,
      "learning_rate": 0.03198813252806452,
      "loss": 0.6253,
      "step": 421840
    },
    {
      "epoch": 680.42,
      "learning_rate": 0.03198490672483872,
      "loss": 0.602,
      "step": 421860
    },
    {
      "epoch": 680.45,
      "learning_rate": 0.03198168092161291,
      "loss": 0.6148,
      "step": 421880
    },
    {
      "epoch": 680.48,
      "learning_rate": 0.0319784551183871,
      "loss": 0.5927,
      "step": 421900
    },
    {
      "epoch": 680.52,
      "learning_rate": 0.0319752293151613,
      "loss": 0.6036,
      "step": 421920
    },
    {
      "epoch": 680.55,
      "learning_rate": 0.03197200351193549,
      "loss": 0.6081,
      "step": 421940
    },
    {
      "epoch": 680.58,
      "learning_rate": 0.031968777708709685,
      "loss": 0.6091,
      "step": 421960
    },
    {
      "epoch": 680.61,
      "learning_rate": 0.03196555190548387,
      "loss": 0.5979,
      "step": 421980
    },
    {
      "epoch": 680.65,
      "learning_rate": 0.03196232610225806,
      "loss": 0.6109,
      "step": 422000
    },
    {
      "epoch": 680.68,
      "learning_rate": 0.03195910029903226,
      "loss": 0.5991,
      "step": 422020
    },
    {
      "epoch": 680.71,
      "learning_rate": 0.031955874495806454,
      "loss": 0.6137,
      "step": 422040
    },
    {
      "epoch": 680.74,
      "learning_rate": 0.031952648692580646,
      "loss": 0.6232,
      "step": 422060
    },
    {
      "epoch": 680.77,
      "learning_rate": 0.03194942288935484,
      "loss": 0.618,
      "step": 422080
    },
    {
      "epoch": 680.81,
      "learning_rate": 0.03194619708612904,
      "loss": 0.5928,
      "step": 422100
    },
    {
      "epoch": 680.84,
      "learning_rate": 0.03194297128290323,
      "loss": 0.6095,
      "step": 422120
    },
    {
      "epoch": 680.87,
      "learning_rate": 0.03193974547967742,
      "loss": 0.6136,
      "step": 422140
    },
    {
      "epoch": 680.9,
      "learning_rate": 0.03193651967645162,
      "loss": 0.6167,
      "step": 422160
    },
    {
      "epoch": 680.94,
      "learning_rate": 0.03193329387322581,
      "loss": 0.6312,
      "step": 422180
    },
    {
      "epoch": 680.97,
      "learning_rate": 0.031930068070000005,
      "loss": 0.6243,
      "step": 422200
    },
    {
      "epoch": 681.0,
      "learning_rate": 0.031927003556935486,
      "loss": 0.6342,
      "step": 422220
    },
    {
      "epoch": 681.0,
      "eval_accuracy": {
        "accuracy": 0.772148934509406
      },
      "eval_loss": 0.9803102016448975,
      "eval_runtime": 3.1331,
      "eval_samples_per_second": 4088.867,
      "eval_steps_per_second": 64.153,
      "step": 422220
    },
    {
      "epoch": 681.03,
      "learning_rate": 0.03192377775370968,
      "loss": 0.6113,
      "step": 422240
    },
    {
      "epoch": 681.06,
      "learning_rate": 0.03192055195048388,
      "loss": 0.6127,
      "step": 422260
    },
    {
      "epoch": 681.1,
      "learning_rate": 0.03191732614725807,
      "loss": 0.6067,
      "step": 422280
    },
    {
      "epoch": 681.13,
      "learning_rate": 0.03191410034403226,
      "loss": 0.5893,
      "step": 422300
    },
    {
      "epoch": 681.16,
      "learning_rate": 0.031910874540806454,
      "loss": 0.5992,
      "step": 422320
    },
    {
      "epoch": 681.19,
      "learning_rate": 0.03190764873758065,
      "loss": 0.607,
      "step": 422340
    },
    {
      "epoch": 681.23,
      "learning_rate": 0.031904422934354845,
      "loss": 0.6151,
      "step": 422360
    },
    {
      "epoch": 681.26,
      "learning_rate": 0.03190119713112904,
      "loss": 0.608,
      "step": 422380
    },
    {
      "epoch": 681.29,
      "learning_rate": 0.031897971327903236,
      "loss": 0.6119,
      "step": 422400
    },
    {
      "epoch": 681.32,
      "learning_rate": 0.031894745524677415,
      "loss": 0.609,
      "step": 422420
    },
    {
      "epoch": 681.35,
      "learning_rate": 0.031891519721451614,
      "loss": 0.612,
      "step": 422440
    },
    {
      "epoch": 681.39,
      "learning_rate": 0.031888293918225806,
      "loss": 0.6071,
      "step": 422460
    },
    {
      "epoch": 681.42,
      "learning_rate": 0.031885068115,
      "loss": 0.6307,
      "step": 422480
    },
    {
      "epoch": 681.45,
      "learning_rate": 0.0318818423117742,
      "loss": 0.6159,
      "step": 422500
    },
    {
      "epoch": 681.48,
      "learning_rate": 0.03187861650854839,
      "loss": 0.612,
      "step": 422520
    },
    {
      "epoch": 681.52,
      "learning_rate": 0.03187539070532258,
      "loss": 0.6106,
      "step": 422540
    },
    {
      "epoch": 681.55,
      "learning_rate": 0.03187216490209678,
      "loss": 0.617,
      "step": 422560
    },
    {
      "epoch": 681.58,
      "learning_rate": 0.03186893909887097,
      "loss": 0.6228,
      "step": 422580
    },
    {
      "epoch": 681.61,
      "learning_rate": 0.031865713295645165,
      "loss": 0.6164,
      "step": 422600
    },
    {
      "epoch": 681.65,
      "learning_rate": 0.03186248749241936,
      "loss": 0.608,
      "step": 422620
    },
    {
      "epoch": 681.68,
      "learning_rate": 0.031859261689193556,
      "loss": 0.6025,
      "step": 422640
    },
    {
      "epoch": 681.71,
      "learning_rate": 0.03185603588596775,
      "loss": 0.6046,
      "step": 422660
    },
    {
      "epoch": 681.74,
      "learning_rate": 0.03185281008274194,
      "loss": 0.6111,
      "step": 422680
    },
    {
      "epoch": 681.77,
      "learning_rate": 0.03184958427951614,
      "loss": 0.6021,
      "step": 422700
    },
    {
      "epoch": 681.81,
      "learning_rate": 0.03184635847629033,
      "loss": 0.6191,
      "step": 422720
    },
    {
      "epoch": 681.84,
      "learning_rate": 0.03184313267306452,
      "loss": 0.6212,
      "step": 422740
    },
    {
      "epoch": 681.87,
      "learning_rate": 0.03183990686983871,
      "loss": 0.6061,
      "step": 422760
    },
    {
      "epoch": 681.9,
      "learning_rate": 0.0318366810666129,
      "loss": 0.6285,
      "step": 422780
    },
    {
      "epoch": 681.94,
      "learning_rate": 0.0318334552633871,
      "loss": 0.6237,
      "step": 422800
    },
    {
      "epoch": 681.97,
      "learning_rate": 0.03183022946016129,
      "loss": 0.6185,
      "step": 422820
    },
    {
      "epoch": 682.0,
      "learning_rate": 0.031827003656935485,
      "loss": 0.6202,
      "step": 422840
    },
    {
      "epoch": 682.0,
      "eval_accuracy": {
        "accuracy": 0.7700413706970572
      },
      "eval_loss": 0.9877859354019165,
      "eval_runtime": 3.4728,
      "eval_samples_per_second": 3688.948,
      "eval_steps_per_second": 57.878,
      "step": 422840
    },
    {
      "epoch": 682.03,
      "learning_rate": 0.03182377785370968,
      "loss": 0.6213,
      "step": 422860
    },
    {
      "epoch": 682.06,
      "learning_rate": 0.031820552050483876,
      "loss": 0.6142,
      "step": 422880
    },
    {
      "epoch": 682.1,
      "learning_rate": 0.03181732624725807,
      "loss": 0.6137,
      "step": 422900
    },
    {
      "epoch": 682.13,
      "learning_rate": 0.03181410044403226,
      "loss": 0.606,
      "step": 422920
    },
    {
      "epoch": 682.16,
      "learning_rate": 0.03181087464080646,
      "loss": 0.6233,
      "step": 422940
    },
    {
      "epoch": 682.19,
      "learning_rate": 0.03180764883758065,
      "loss": 0.6122,
      "step": 422960
    },
    {
      "epoch": 682.23,
      "learning_rate": 0.031804423034354844,
      "loss": 0.6204,
      "step": 422980
    },
    {
      "epoch": 682.26,
      "learning_rate": 0.03180119723112904,
      "loss": 0.6027,
      "step": 423000
    },
    {
      "epoch": 682.29,
      "learning_rate": 0.031797971427903235,
      "loss": 0.6052,
      "step": 423020
    },
    {
      "epoch": 682.32,
      "learning_rate": 0.03179474562467742,
      "loss": 0.5963,
      "step": 423040
    },
    {
      "epoch": 682.35,
      "learning_rate": 0.03179151982145161,
      "loss": 0.6203,
      "step": 423060
    },
    {
      "epoch": 682.39,
      "learning_rate": 0.031788294018225804,
      "loss": 0.6102,
      "step": 423080
    },
    {
      "epoch": 682.42,
      "learning_rate": 0.031785068215000004,
      "loss": 0.6171,
      "step": 423100
    },
    {
      "epoch": 682.45,
      "learning_rate": 0.031781842411774196,
      "loss": 0.5999,
      "step": 423120
    },
    {
      "epoch": 682.48,
      "learning_rate": 0.03177861660854839,
      "loss": 0.6055,
      "step": 423140
    },
    {
      "epoch": 682.52,
      "learning_rate": 0.03177539080532258,
      "loss": 0.6004,
      "step": 423160
    },
    {
      "epoch": 682.55,
      "learning_rate": 0.03177216500209678,
      "loss": 0.6182,
      "step": 423180
    },
    {
      "epoch": 682.58,
      "learning_rate": 0.03176893919887097,
      "loss": 0.6274,
      "step": 423200
    },
    {
      "epoch": 682.61,
      "learning_rate": 0.03176571339564516,
      "loss": 0.6336,
      "step": 423220
    },
    {
      "epoch": 682.65,
      "learning_rate": 0.03176248759241936,
      "loss": 0.618,
      "step": 423240
    },
    {
      "epoch": 682.68,
      "learning_rate": 0.031759261789193555,
      "loss": 0.6087,
      "step": 423260
    },
    {
      "epoch": 682.71,
      "learning_rate": 0.03175603598596775,
      "loss": 0.6121,
      "step": 423280
    },
    {
      "epoch": 682.74,
      "learning_rate": 0.031752810182741946,
      "loss": 0.6147,
      "step": 423300
    },
    {
      "epoch": 682.77,
      "learning_rate": 0.03174958437951614,
      "loss": 0.615,
      "step": 423320
    },
    {
      "epoch": 682.81,
      "learning_rate": 0.03174635857629033,
      "loss": 0.6201,
      "step": 423340
    },
    {
      "epoch": 682.84,
      "learning_rate": 0.031743132773064515,
      "loss": 0.6264,
      "step": 423360
    },
    {
      "epoch": 682.87,
      "learning_rate": 0.03173990696983871,
      "loss": 0.6247,
      "step": 423380
    },
    {
      "epoch": 682.9,
      "learning_rate": 0.0317366811666129,
      "loss": 0.6181,
      "step": 423400
    },
    {
      "epoch": 682.94,
      "learning_rate": 0.0317334553633871,
      "loss": 0.5903,
      "step": 423420
    },
    {
      "epoch": 682.97,
      "learning_rate": 0.03173022956016129,
      "loss": 0.6051,
      "step": 423440
    },
    {
      "epoch": 683.0,
      "learning_rate": 0.03172700375693548,
      "loss": 0.6151,
      "step": 423460
    },
    {
      "epoch": 683.0,
      "eval_accuracy": {
        "accuracy": 0.7747248458356101
      },
      "eval_loss": 0.9705337285995483,
      "eval_runtime": 3.0391,
      "eval_samples_per_second": 4215.324,
      "eval_steps_per_second": 66.137,
      "step": 423460
    },
    {
      "epoch": 683.03,
      "learning_rate": 0.03172377795370968,
      "loss": 0.6096,
      "step": 423480
    },
    {
      "epoch": 683.06,
      "learning_rate": 0.031720552150483874,
      "loss": 0.6137,
      "step": 423500
    },
    {
      "epoch": 683.1,
      "learning_rate": 0.03171732634725807,
      "loss": 0.5975,
      "step": 423520
    },
    {
      "epoch": 683.13,
      "learning_rate": 0.031714100544032266,
      "loss": 0.6044,
      "step": 423540
    },
    {
      "epoch": 683.16,
      "learning_rate": 0.03171087474080646,
      "loss": 0.605,
      "step": 423560
    },
    {
      "epoch": 683.19,
      "learning_rate": 0.03170764893758065,
      "loss": 0.6065,
      "step": 423580
    },
    {
      "epoch": 683.23,
      "learning_rate": 0.03170442313435485,
      "loss": 0.5999,
      "step": 423600
    },
    {
      "epoch": 683.26,
      "learning_rate": 0.03170119733112904,
      "loss": 0.6043,
      "step": 423620
    },
    {
      "epoch": 683.29,
      "learning_rate": 0.03169797152790323,
      "loss": 0.6006,
      "step": 423640
    },
    {
      "epoch": 683.32,
      "learning_rate": 0.031694745724677426,
      "loss": 0.6039,
      "step": 423660
    },
    {
      "epoch": 683.35,
      "learning_rate": 0.03169151992145161,
      "loss": 0.6191,
      "step": 423680
    },
    {
      "epoch": 683.39,
      "learning_rate": 0.0316882941182258,
      "loss": 0.5995,
      "step": 423700
    },
    {
      "epoch": 683.42,
      "learning_rate": 0.031685068315,
      "loss": 0.6135,
      "step": 423720
    },
    {
      "epoch": 683.45,
      "learning_rate": 0.031681842511774194,
      "loss": 0.6085,
      "step": 423740
    },
    {
      "epoch": 683.48,
      "learning_rate": 0.031678616708548386,
      "loss": 0.6121,
      "step": 423760
    },
    {
      "epoch": 683.52,
      "learning_rate": 0.031675390905322585,
      "loss": 0.6107,
      "step": 423780
    },
    {
      "epoch": 683.55,
      "learning_rate": 0.03167216510209678,
      "loss": 0.5969,
      "step": 423800
    },
    {
      "epoch": 683.58,
      "learning_rate": 0.03166893929887097,
      "loss": 0.5985,
      "step": 423820
    },
    {
      "epoch": 683.61,
      "learning_rate": 0.03166571349564517,
      "loss": 0.5957,
      "step": 423840
    },
    {
      "epoch": 683.65,
      "learning_rate": 0.03166248769241936,
      "loss": 0.6181,
      "step": 423860
    },
    {
      "epoch": 683.68,
      "learning_rate": 0.03165926188919355,
      "loss": 0.6155,
      "step": 423880
    },
    {
      "epoch": 683.71,
      "learning_rate": 0.031656036085967745,
      "loss": 0.626,
      "step": 423900
    },
    {
      "epoch": 683.74,
      "learning_rate": 0.031652810282741944,
      "loss": 0.6096,
      "step": 423920
    },
    {
      "epoch": 683.77,
      "learning_rate": 0.03164958447951614,
      "loss": 0.6108,
      "step": 423940
    },
    {
      "epoch": 683.81,
      "learning_rate": 0.03164635867629033,
      "loss": 0.6128,
      "step": 423960
    },
    {
      "epoch": 683.84,
      "learning_rate": 0.031643132873064514,
      "loss": 0.6137,
      "step": 423980
    },
    {
      "epoch": 683.87,
      "learning_rate": 0.031639907069838706,
      "loss": 0.6198,
      "step": 424000
    },
    {
      "epoch": 683.9,
      "learning_rate": 0.031636681266612905,
      "loss": 0.6178,
      "step": 424020
    },
    {
      "epoch": 683.94,
      "learning_rate": 0.0316334554633871,
      "loss": 0.6203,
      "step": 424040
    },
    {
      "epoch": 683.97,
      "learning_rate": 0.03163022966016129,
      "loss": 0.6094,
      "step": 424060
    },
    {
      "epoch": 684.0,
      "learning_rate": 0.03162700385693549,
      "loss": 0.6107,
      "step": 424080
    },
    {
      "epoch": 684.0,
      "eval_accuracy": {
        "accuracy": 0.7705097182109125
      },
      "eval_loss": 0.9893715977668762,
      "eval_runtime": 2.9885,
      "eval_samples_per_second": 4286.736,
      "eval_steps_per_second": 67.257,
      "step": 424080
    },
    {
      "epoch": 684.03,
      "learning_rate": 0.03162377805370968,
      "loss": 0.6072,
      "step": 424100
    },
    {
      "epoch": 684.06,
      "learning_rate": 0.03162055225048387,
      "loss": 0.6173,
      "step": 424120
    },
    {
      "epoch": 684.1,
      "learning_rate": 0.03161732644725807,
      "loss": 0.6032,
      "step": 424140
    },
    {
      "epoch": 684.13,
      "learning_rate": 0.031614100644032264,
      "loss": 0.5991,
      "step": 424160
    },
    {
      "epoch": 684.16,
      "learning_rate": 0.031610874840806456,
      "loss": 0.6161,
      "step": 424180
    },
    {
      "epoch": 684.19,
      "learning_rate": 0.03160764903758065,
      "loss": 0.608,
      "step": 424200
    },
    {
      "epoch": 684.23,
      "learning_rate": 0.03160442323435485,
      "loss": 0.6059,
      "step": 424220
    },
    {
      "epoch": 684.26,
      "learning_rate": 0.03160119743112904,
      "loss": 0.6008,
      "step": 424240
    },
    {
      "epoch": 684.29,
      "learning_rate": 0.03159797162790323,
      "loss": 0.5854,
      "step": 424260
    },
    {
      "epoch": 684.32,
      "learning_rate": 0.03159474582467743,
      "loss": 0.6035,
      "step": 424280
    },
    {
      "epoch": 684.35,
      "learning_rate": 0.03159152002145161,
      "loss": 0.5984,
      "step": 424300
    },
    {
      "epoch": 684.39,
      "learning_rate": 0.03158829421822581,
      "loss": 0.6127,
      "step": 424320
    },
    {
      "epoch": 684.42,
      "learning_rate": 0.031585068415,
      "loss": 0.6022,
      "step": 424340
    },
    {
      "epoch": 684.45,
      "learning_rate": 0.03158184261177419,
      "loss": 0.6025,
      "step": 424360
    },
    {
      "epoch": 684.48,
      "learning_rate": 0.03157861680854839,
      "loss": 0.609,
      "step": 424380
    },
    {
      "epoch": 684.52,
      "learning_rate": 0.031575391005322584,
      "loss": 0.6182,
      "step": 424400
    },
    {
      "epoch": 684.55,
      "learning_rate": 0.031572165202096776,
      "loss": 0.6111,
      "step": 424420
    },
    {
      "epoch": 684.58,
      "learning_rate": 0.03156893939887097,
      "loss": 0.6104,
      "step": 424440
    },
    {
      "epoch": 684.61,
      "learning_rate": 0.03156571359564517,
      "loss": 0.6075,
      "step": 424460
    },
    {
      "epoch": 684.65,
      "learning_rate": 0.03156248779241936,
      "loss": 0.6103,
      "step": 424480
    },
    {
      "epoch": 684.68,
      "learning_rate": 0.03155926198919355,
      "loss": 0.6097,
      "step": 424500
    },
    {
      "epoch": 684.71,
      "learning_rate": 0.03155603618596775,
      "loss": 0.6049,
      "step": 424520
    },
    {
      "epoch": 684.74,
      "learning_rate": 0.03155281038274194,
      "loss": 0.6209,
      "step": 424540
    },
    {
      "epoch": 684.77,
      "learning_rate": 0.031549584579516135,
      "loss": 0.6204,
      "step": 424560
    },
    {
      "epoch": 684.81,
      "learning_rate": 0.031546358776290334,
      "loss": 0.6129,
      "step": 424580
    },
    {
      "epoch": 684.84,
      "learning_rate": 0.03154313297306451,
      "loss": 0.6202,
      "step": 424600
    },
    {
      "epoch": 684.87,
      "learning_rate": 0.03153990716983871,
      "loss": 0.6083,
      "step": 424620
    },
    {
      "epoch": 684.9,
      "learning_rate": 0.031536681366612904,
      "loss": 0.6032,
      "step": 424640
    },
    {
      "epoch": 684.94,
      "learning_rate": 0.031533455563387096,
      "loss": 0.6007,
      "step": 424660
    },
    {
      "epoch": 684.97,
      "learning_rate": 0.031530229760161295,
      "loss": 0.6168,
      "step": 424680
    },
    {
      "epoch": 685.0,
      "learning_rate": 0.03152716524709678,
      "loss": 0.6218,
      "step": 424700
    },
    {
      "epoch": 685.0,
      "eval_accuracy": {
        "accuracy": 0.7765201779720553
      },
      "eval_loss": 0.966643750667572,
      "eval_runtime": 3.0288,
      "eval_samples_per_second": 4229.727,
      "eval_steps_per_second": 66.363,
      "step": 424700
    },
    {
      "epoch": 685.03,
      "learning_rate": 0.031523939443870976,
      "loss": 0.6142,
      "step": 424720
    },
    {
      "epoch": 685.06,
      "learning_rate": 0.03152071364064516,
      "loss": 0.6093,
      "step": 424740
    },
    {
      "epoch": 685.1,
      "learning_rate": 0.03151748783741935,
      "loss": 0.5946,
      "step": 424760
    },
    {
      "epoch": 685.13,
      "learning_rate": 0.031514262034193545,
      "loss": 0.5908,
      "step": 424780
    },
    {
      "epoch": 685.16,
      "learning_rate": 0.031511036230967744,
      "loss": 0.5967,
      "step": 424800
    },
    {
      "epoch": 685.19,
      "learning_rate": 0.031507810427741936,
      "loss": 0.6003,
      "step": 424820
    },
    {
      "epoch": 685.23,
      "learning_rate": 0.03150458462451613,
      "loss": 0.6085,
      "step": 424840
    },
    {
      "epoch": 685.26,
      "learning_rate": 0.03150135882129033,
      "loss": 0.6117,
      "step": 424860
    },
    {
      "epoch": 685.29,
      "learning_rate": 0.03149813301806452,
      "loss": 0.61,
      "step": 424880
    },
    {
      "epoch": 685.32,
      "learning_rate": 0.03149490721483871,
      "loss": 0.619,
      "step": 424900
    },
    {
      "epoch": 685.35,
      "learning_rate": 0.03149168141161291,
      "loss": 0.6101,
      "step": 424920
    },
    {
      "epoch": 685.39,
      "learning_rate": 0.0314884556083871,
      "loss": 0.6107,
      "step": 424940
    },
    {
      "epoch": 685.42,
      "learning_rate": 0.031485229805161295,
      "loss": 0.6047,
      "step": 424960
    },
    {
      "epoch": 685.45,
      "learning_rate": 0.03148200400193549,
      "loss": 0.6257,
      "step": 424980
    },
    {
      "epoch": 685.48,
      "learning_rate": 0.031478778198709687,
      "loss": 0.6116,
      "step": 425000
    },
    {
      "epoch": 685.52,
      "learning_rate": 0.03147555239548388,
      "loss": 0.6111,
      "step": 425020
    },
    {
      "epoch": 685.55,
      "learning_rate": 0.03147232659225807,
      "loss": 0.6239,
      "step": 425040
    },
    {
      "epoch": 685.58,
      "learning_rate": 0.031469100789032256,
      "loss": 0.6128,
      "step": 425060
    },
    {
      "epoch": 685.61,
      "learning_rate": 0.03146587498580645,
      "loss": 0.5942,
      "step": 425080
    },
    {
      "epoch": 685.65,
      "learning_rate": 0.03146264918258065,
      "loss": 0.609,
      "step": 425100
    },
    {
      "epoch": 685.68,
      "learning_rate": 0.03145942337935484,
      "loss": 0.6115,
      "step": 425120
    },
    {
      "epoch": 685.71,
      "learning_rate": 0.03145619757612903,
      "loss": 0.612,
      "step": 425140
    },
    {
      "epoch": 685.74,
      "learning_rate": 0.03145297177290323,
      "loss": 0.614,
      "step": 425160
    },
    {
      "epoch": 685.77,
      "learning_rate": 0.03144974596967742,
      "loss": 0.6238,
      "step": 425180
    },
    {
      "epoch": 685.81,
      "learning_rate": 0.031446520166451615,
      "loss": 0.6139,
      "step": 425200
    },
    {
      "epoch": 685.84,
      "learning_rate": 0.031443294363225814,
      "loss": 0.6133,
      "step": 425220
    },
    {
      "epoch": 685.87,
      "learning_rate": 0.031440068560000006,
      "loss": 0.5933,
      "step": 425240
    },
    {
      "epoch": 685.9,
      "learning_rate": 0.0314368427567742,
      "loss": 0.5984,
      "step": 425260
    },
    {
      "epoch": 685.94,
      "learning_rate": 0.03143361695354839,
      "loss": 0.6045,
      "step": 425280
    },
    {
      "epoch": 685.97,
      "learning_rate": 0.03143039115032259,
      "loss": 0.6097,
      "step": 425300
    },
    {
      "epoch": 686.0,
      "learning_rate": 0.03142716534709678,
      "loss": 0.6119,
      "step": 425320
    },
    {
      "epoch": 686.0,
      "eval_accuracy": {
        "accuracy": 0.7724611661853095
      },
      "eval_loss": 0.9833836555480957,
      "eval_runtime": 5.3683,
      "eval_samples_per_second": 2386.429,
      "eval_steps_per_second": 37.442,
      "step": 425320
    },
    {
      "epoch": 686.03,
      "learning_rate": 0.031423939543870974,
      "loss": 0.6069,
      "step": 425340
    },
    {
      "epoch": 686.06,
      "learning_rate": 0.03142071374064516,
      "loss": 0.6046,
      "step": 425360
    },
    {
      "epoch": 686.1,
      "learning_rate": 0.03141748793741935,
      "loss": 0.6128,
      "step": 425380
    },
    {
      "epoch": 686.13,
      "learning_rate": 0.03141426213419355,
      "loss": 0.6124,
      "step": 425400
    },
    {
      "epoch": 686.16,
      "learning_rate": 0.03141103633096774,
      "loss": 0.6156,
      "step": 425420
    },
    {
      "epoch": 686.19,
      "learning_rate": 0.031407810527741935,
      "loss": 0.6157,
      "step": 425440
    },
    {
      "epoch": 686.23,
      "learning_rate": 0.031404584724516134,
      "loss": 0.6023,
      "step": 425460
    },
    {
      "epoch": 686.26,
      "learning_rate": 0.031401358921290326,
      "loss": 0.6007,
      "step": 425480
    },
    {
      "epoch": 686.29,
      "learning_rate": 0.03139813311806452,
      "loss": 0.6009,
      "step": 425500
    },
    {
      "epoch": 686.32,
      "learning_rate": 0.03139490731483871,
      "loss": 0.6143,
      "step": 425520
    },
    {
      "epoch": 686.35,
      "learning_rate": 0.03139168151161291,
      "loss": 0.6154,
      "step": 425540
    },
    {
      "epoch": 686.39,
      "learning_rate": 0.0313884557083871,
      "loss": 0.6161,
      "step": 425560
    },
    {
      "epoch": 686.42,
      "learning_rate": 0.031385229905161294,
      "loss": 0.5941,
      "step": 425580
    },
    {
      "epoch": 686.45,
      "learning_rate": 0.03138200410193549,
      "loss": 0.6105,
      "step": 425600
    },
    {
      "epoch": 686.48,
      "learning_rate": 0.031378778298709685,
      "loss": 0.6053,
      "step": 425620
    },
    {
      "epoch": 686.52,
      "learning_rate": 0.03137555249548388,
      "loss": 0.6206,
      "step": 425640
    },
    {
      "epoch": 686.55,
      "learning_rate": 0.031372326692258076,
      "loss": 0.6105,
      "step": 425660
    },
    {
      "epoch": 686.58,
      "learning_rate": 0.031369100889032255,
      "loss": 0.6045,
      "step": 425680
    },
    {
      "epoch": 686.61,
      "learning_rate": 0.031365875085806454,
      "loss": 0.5923,
      "step": 425700
    },
    {
      "epoch": 686.65,
      "learning_rate": 0.031362649282580646,
      "loss": 0.6247,
      "step": 425720
    },
    {
      "epoch": 686.68,
      "learning_rate": 0.03135942347935484,
      "loss": 0.6064,
      "step": 425740
    },
    {
      "epoch": 686.71,
      "learning_rate": 0.03135619767612904,
      "loss": 0.623,
      "step": 425760
    },
    {
      "epoch": 686.74,
      "learning_rate": 0.03135297187290323,
      "loss": 0.602,
      "step": 425780
    },
    {
      "epoch": 686.77,
      "learning_rate": 0.03134974606967742,
      "loss": 0.6209,
      "step": 425800
    },
    {
      "epoch": 686.81,
      "learning_rate": 0.031346520266451613,
      "loss": 0.6161,
      "step": 425820
    },
    {
      "epoch": 686.84,
      "learning_rate": 0.03134329446322581,
      "loss": 0.596,
      "step": 425840
    },
    {
      "epoch": 686.87,
      "learning_rate": 0.031340068660000005,
      "loss": 0.6042,
      "step": 425860
    },
    {
      "epoch": 686.9,
      "learning_rate": 0.0313368428567742,
      "loss": 0.6122,
      "step": 425880
    },
    {
      "epoch": 686.94,
      "learning_rate": 0.031333617053548396,
      "loss": 0.6092,
      "step": 425900
    },
    {
      "epoch": 686.97,
      "learning_rate": 0.03133039125032259,
      "loss": 0.6191,
      "step": 425920
    },
    {
      "epoch": 687.0,
      "learning_rate": 0.03132716544709678,
      "loss": 0.6245,
      "step": 425940
    },
    {
      "epoch": 687.0,
      "eval_accuracy": {
        "accuracy": 0.7740223245648271
      },
      "eval_loss": 0.9792904853820801,
      "eval_runtime": 2.9463,
      "eval_samples_per_second": 4348.162,
      "eval_steps_per_second": 68.221,
      "step": 425940
    },
    {
      "epoch": 687.03,
      "learning_rate": 0.03132393964387098,
      "loss": 0.6282,
      "step": 425960
    },
    {
      "epoch": 687.06,
      "learning_rate": 0.03132071384064517,
      "loss": 0.603,
      "step": 425980
    },
    {
      "epoch": 687.1,
      "learning_rate": 0.03131748803741936,
      "loss": 0.5907,
      "step": 426000
    },
    {
      "epoch": 687.13,
      "learning_rate": 0.03131426223419355,
      "loss": 0.6013,
      "step": 426020
    },
    {
      "epoch": 687.16,
      "learning_rate": 0.03131103643096774,
      "loss": 0.5936,
      "step": 426040
    },
    {
      "epoch": 687.19,
      "learning_rate": 0.03130781062774193,
      "loss": 0.6026,
      "step": 426060
    },
    {
      "epoch": 687.23,
      "learning_rate": 0.03130458482451613,
      "loss": 0.6068,
      "step": 426080
    },
    {
      "epoch": 687.26,
      "learning_rate": 0.031301359021290324,
      "loss": 0.6075,
      "step": 426100
    },
    {
      "epoch": 687.29,
      "learning_rate": 0.03129813321806452,
      "loss": 0.6104,
      "step": 426120
    },
    {
      "epoch": 687.32,
      "learning_rate": 0.031294907414838716,
      "loss": 0.597,
      "step": 426140
    },
    {
      "epoch": 687.35,
      "learning_rate": 0.03129168161161291,
      "loss": 0.6088,
      "step": 426160
    },
    {
      "epoch": 687.39,
      "learning_rate": 0.0312884558083871,
      "loss": 0.6112,
      "step": 426180
    },
    {
      "epoch": 687.42,
      "learning_rate": 0.0312852300051613,
      "loss": 0.6187,
      "step": 426200
    },
    {
      "epoch": 687.45,
      "learning_rate": 0.03128200420193549,
      "loss": 0.6119,
      "step": 426220
    },
    {
      "epoch": 687.48,
      "learning_rate": 0.03127877839870968,
      "loss": 0.6146,
      "step": 426240
    },
    {
      "epoch": 687.52,
      "learning_rate": 0.031275552595483876,
      "loss": 0.6175,
      "step": 426260
    },
    {
      "epoch": 687.55,
      "learning_rate": 0.031272326792258075,
      "loss": 0.6176,
      "step": 426280
    },
    {
      "epoch": 687.58,
      "learning_rate": 0.03126910098903225,
      "loss": 0.5945,
      "step": 426300
    },
    {
      "epoch": 687.61,
      "learning_rate": 0.03126587518580645,
      "loss": 0.6103,
      "step": 426320
    },
    {
      "epoch": 687.65,
      "learning_rate": 0.031262649382580644,
      "loss": 0.6172,
      "step": 426340
    },
    {
      "epoch": 687.68,
      "learning_rate": 0.031259423579354836,
      "loss": 0.6084,
      "step": 426360
    },
    {
      "epoch": 687.71,
      "learning_rate": 0.031256197776129035,
      "loss": 0.6091,
      "step": 426380
    },
    {
      "epoch": 687.74,
      "learning_rate": 0.03125297197290323,
      "loss": 0.6145,
      "step": 426400
    },
    {
      "epoch": 687.77,
      "learning_rate": 0.03124974616967742,
      "loss": 0.6241,
      "step": 426420
    },
    {
      "epoch": 687.81,
      "learning_rate": 0.03124652036645161,
      "loss": 0.622,
      "step": 426440
    },
    {
      "epoch": 687.84,
      "learning_rate": 0.031243294563225804,
      "loss": 0.6,
      "step": 426460
    },
    {
      "epoch": 687.87,
      "learning_rate": 0.031240068760000003,
      "loss": 0.6156,
      "step": 426480
    },
    {
      "epoch": 687.9,
      "learning_rate": 0.031236842956774192,
      "loss": 0.6222,
      "step": 426500
    },
    {
      "epoch": 687.94,
      "learning_rate": 0.031233617153548388,
      "loss": 0.6024,
      "step": 426520
    },
    {
      "epoch": 687.97,
      "learning_rate": 0.031230391350322587,
      "loss": 0.614,
      "step": 426540
    },
    {
      "epoch": 688.0,
      "learning_rate": 0.031227165547096775,
      "loss": 0.6052,
      "step": 426560
    },
    {
      "epoch": 688.0,
      "eval_accuracy": {
        "accuracy": 0.7733198032940442
      },
      "eval_loss": 0.9809011816978455,
      "eval_runtime": 2.9472,
      "eval_samples_per_second": 4346.833,
      "eval_steps_per_second": 68.2,
      "step": 426560
    },
    {
      "epoch": 688.03,
      "learning_rate": 0.03122393974387097,
      "loss": 0.6124,
      "step": 426580
    },
    {
      "epoch": 688.06,
      "learning_rate": 0.03122071394064517,
      "loss": 0.5988,
      "step": 426600
    },
    {
      "epoch": 688.1,
      "learning_rate": 0.031217488137419355,
      "loss": 0.6033,
      "step": 426620
    },
    {
      "epoch": 688.13,
      "learning_rate": 0.031214262334193544,
      "loss": 0.6253,
      "step": 426640
    },
    {
      "epoch": 688.16,
      "learning_rate": 0.03121103653096774,
      "loss": 0.6017,
      "step": 426660
    },
    {
      "epoch": 688.19,
      "learning_rate": 0.03120781072774193,
      "loss": 0.6052,
      "step": 426680
    },
    {
      "epoch": 688.23,
      "learning_rate": 0.031204584924516127,
      "loss": 0.5876,
      "step": 426700
    },
    {
      "epoch": 688.26,
      "learning_rate": 0.031201359121290323,
      "loss": 0.603,
      "step": 426720
    },
    {
      "epoch": 688.29,
      "learning_rate": 0.031198133318064515,
      "loss": 0.603,
      "step": 426740
    },
    {
      "epoch": 688.32,
      "learning_rate": 0.03119490751483871,
      "loss": 0.6197,
      "step": 426760
    },
    {
      "epoch": 688.35,
      "learning_rate": 0.031191681711612903,
      "loss": 0.611,
      "step": 426780
    },
    {
      "epoch": 688.39,
      "learning_rate": 0.0311884559083871,
      "loss": 0.6145,
      "step": 426800
    },
    {
      "epoch": 688.42,
      "learning_rate": 0.031185230105161294,
      "loss": 0.59,
      "step": 426820
    },
    {
      "epoch": 688.45,
      "learning_rate": 0.031182004301935486,
      "loss": 0.605,
      "step": 426840
    },
    {
      "epoch": 688.48,
      "learning_rate": 0.031178778498709682,
      "loss": 0.6204,
      "step": 426860
    },
    {
      "epoch": 688.52,
      "learning_rate": 0.031175552695483874,
      "loss": 0.6052,
      "step": 426880
    },
    {
      "epoch": 688.55,
      "learning_rate": 0.03117232689225807,
      "loss": 0.5978,
      "step": 426900
    },
    {
      "epoch": 688.58,
      "learning_rate": 0.031169101089032248,
      "loss": 0.5945,
      "step": 426920
    },
    {
      "epoch": 688.61,
      "learning_rate": 0.031165875285806444,
      "loss": 0.6074,
      "step": 426940
    },
    {
      "epoch": 688.65,
      "learning_rate": 0.031162649482580643,
      "loss": 0.6079,
      "step": 426960
    },
    {
      "epoch": 688.68,
      "learning_rate": 0.03115942367935483,
      "loss": 0.5938,
      "step": 426980
    },
    {
      "epoch": 688.71,
      "learning_rate": 0.031156197876129027,
      "loss": 0.5992,
      "step": 427000
    },
    {
      "epoch": 688.74,
      "learning_rate": 0.031152972072903226,
      "loss": 0.6176,
      "step": 427020
    },
    {
      "epoch": 688.77,
      "learning_rate": 0.031149746269677415,
      "loss": 0.6199,
      "step": 427040
    },
    {
      "epoch": 688.81,
      "learning_rate": 0.03114652046645161,
      "loss": 0.6127,
      "step": 427060
    },
    {
      "epoch": 688.84,
      "learning_rate": 0.03114329466322581,
      "loss": 0.6155,
      "step": 427080
    },
    {
      "epoch": 688.87,
      "learning_rate": 0.031140068859999998,
      "loss": 0.6032,
      "step": 427100
    },
    {
      "epoch": 688.9,
      "learning_rate": 0.031136843056774194,
      "loss": 0.5967,
      "step": 427120
    },
    {
      "epoch": 688.94,
      "learning_rate": 0.031133617253548393,
      "loss": 0.5946,
      "step": 427140
    },
    {
      "epoch": 688.97,
      "learning_rate": 0.03113039145032258,
      "loss": 0.622,
      "step": 427160
    },
    {
      "epoch": 689.0,
      "learning_rate": 0.03112732693725806,
      "loss": 0.6291,
      "step": 427180
    },
    {
      "epoch": 689.0,
      "eval_accuracy": {
        "accuracy": 0.7762860042151276
      },
      "eval_loss": 0.9568522572517395,
      "eval_runtime": 3.2693,
      "eval_samples_per_second": 3918.53,
      "eval_steps_per_second": 61.48,
      "step": 427180
    },
    {
      "epoch": 689.03,
      "learning_rate": 0.03112410113403226,
      "loss": 0.5947,
      "step": 427200
    },
    {
      "epoch": 689.06,
      "learning_rate": 0.031120875330806447,
      "loss": 0.6056,
      "step": 427220
    },
    {
      "epoch": 689.1,
      "learning_rate": 0.031117649527580643,
      "loss": 0.6181,
      "step": 427240
    },
    {
      "epoch": 689.13,
      "learning_rate": 0.031114423724354842,
      "loss": 0.5952,
      "step": 427260
    },
    {
      "epoch": 689.16,
      "learning_rate": 0.03111119792112903,
      "loss": 0.5858,
      "step": 427280
    },
    {
      "epoch": 689.19,
      "learning_rate": 0.031107972117903226,
      "loss": 0.6045,
      "step": 427300
    },
    {
      "epoch": 689.23,
      "learning_rate": 0.031104746314677426,
      "loss": 0.5914,
      "step": 427320
    },
    {
      "epoch": 689.26,
      "learning_rate": 0.031101520511451614,
      "loss": 0.5961,
      "step": 427340
    },
    {
      "epoch": 689.29,
      "learning_rate": 0.03109829470822581,
      "loss": 0.6024,
      "step": 427360
    },
    {
      "epoch": 689.32,
      "learning_rate": 0.031095068904999995,
      "loss": 0.5995,
      "step": 427380
    },
    {
      "epoch": 689.35,
      "learning_rate": 0.031091843101774194,
      "loss": 0.6177,
      "step": 427400
    },
    {
      "epoch": 689.39,
      "learning_rate": 0.031088617298548383,
      "loss": 0.6181,
      "step": 427420
    },
    {
      "epoch": 689.42,
      "learning_rate": 0.03108539149532258,
      "loss": 0.6085,
      "step": 427440
    },
    {
      "epoch": 689.45,
      "learning_rate": 0.03108216569209677,
      "loss": 0.598,
      "step": 427460
    },
    {
      "epoch": 689.48,
      "learning_rate": 0.031078939888870966,
      "loss": 0.5936,
      "step": 427480
    },
    {
      "epoch": 689.52,
      "learning_rate": 0.031075714085645162,
      "loss": 0.6163,
      "step": 427500
    },
    {
      "epoch": 689.55,
      "learning_rate": 0.031072488282419354,
      "loss": 0.6096,
      "step": 427520
    },
    {
      "epoch": 689.58,
      "learning_rate": 0.03106926247919355,
      "loss": 0.6215,
      "step": 427540
    },
    {
      "epoch": 689.61,
      "learning_rate": 0.031066036675967742,
      "loss": 0.6033,
      "step": 427560
    },
    {
      "epoch": 689.65,
      "learning_rate": 0.031062810872741937,
      "loss": 0.6071,
      "step": 427580
    },
    {
      "epoch": 689.68,
      "learning_rate": 0.031059585069516133,
      "loss": 0.6079,
      "step": 427600
    },
    {
      "epoch": 689.71,
      "learning_rate": 0.031056359266290325,
      "loss": 0.6206,
      "step": 427620
    },
    {
      "epoch": 689.74,
      "learning_rate": 0.03105313346306452,
      "loss": 0.6173,
      "step": 427640
    },
    {
      "epoch": 689.77,
      "learning_rate": 0.031049907659838713,
      "loss": 0.5916,
      "step": 427660
    },
    {
      "epoch": 689.81,
      "learning_rate": 0.031046681856612898,
      "loss": 0.6068,
      "step": 427680
    },
    {
      "epoch": 689.84,
      "learning_rate": 0.031043456053387094,
      "loss": 0.6176,
      "step": 427700
    },
    {
      "epoch": 689.87,
      "learning_rate": 0.031040230250161283,
      "loss": 0.6188,
      "step": 427720
    },
    {
      "epoch": 689.9,
      "learning_rate": 0.03103700444693548,
      "loss": 0.6037,
      "step": 427740
    },
    {
      "epoch": 689.94,
      "learning_rate": 0.03103377864370967,
      "loss": 0.6228,
      "step": 427760
    },
    {
      "epoch": 689.97,
      "learning_rate": 0.031030552840483866,
      "loss": 0.6203,
      "step": 427780
    },
    {
      "epoch": 690.0,
      "learning_rate": 0.031027327037258065,
      "loss": 0.6333,
      "step": 427800
    },
    {
      "epoch": 690.0,
      "eval_accuracy": {
        "accuracy": 0.769573023183202
      },
      "eval_loss": 0.9804603457450867,
      "eval_runtime": 2.9223,
      "eval_samples_per_second": 4383.878,
      "eval_steps_per_second": 68.781,
      "step": 427800
    },
    {
      "epoch": 690.03,
      "learning_rate": 0.031024101234032254,
      "loss": 0.6153,
      "step": 427820
    },
    {
      "epoch": 690.06,
      "learning_rate": 0.03102087543080645,
      "loss": 0.5867,
      "step": 427840
    },
    {
      "epoch": 690.1,
      "learning_rate": 0.03101764962758065,
      "loss": 0.5969,
      "step": 427860
    },
    {
      "epoch": 690.13,
      "learning_rate": 0.031014423824354837,
      "loss": 0.5998,
      "step": 427880
    },
    {
      "epoch": 690.16,
      "learning_rate": 0.031011198021129033,
      "loss": 0.6139,
      "step": 427900
    },
    {
      "epoch": 690.19,
      "learning_rate": 0.031007972217903232,
      "loss": 0.598,
      "step": 427920
    },
    {
      "epoch": 690.23,
      "learning_rate": 0.03100474641467742,
      "loss": 0.6028,
      "step": 427940
    },
    {
      "epoch": 690.26,
      "learning_rate": 0.031001520611451616,
      "loss": 0.5912,
      "step": 427960
    },
    {
      "epoch": 690.29,
      "learning_rate": 0.030998294808225815,
      "loss": 0.5965,
      "step": 427980
    },
    {
      "epoch": 690.32,
      "learning_rate": 0.030995069004999994,
      "loss": 0.6135,
      "step": 428000
    },
    {
      "epoch": 690.35,
      "learning_rate": 0.03099184320177419,
      "loss": 0.5908,
      "step": 428020
    },
    {
      "epoch": 690.39,
      "learning_rate": 0.030988617398548385,
      "loss": 0.6095,
      "step": 428040
    },
    {
      "epoch": 690.42,
      "learning_rate": 0.030985391595322577,
      "loss": 0.5966,
      "step": 428060
    },
    {
      "epoch": 690.45,
      "learning_rate": 0.030982165792096773,
      "loss": 0.6095,
      "step": 428080
    },
    {
      "epoch": 690.48,
      "learning_rate": 0.030978939988870965,
      "loss": 0.6287,
      "step": 428100
    },
    {
      "epoch": 690.52,
      "learning_rate": 0.03097571418564516,
      "loss": 0.6111,
      "step": 428120
    },
    {
      "epoch": 690.55,
      "learning_rate": 0.030972488382419356,
      "loss": 0.6102,
      "step": 428140
    },
    {
      "epoch": 690.58,
      "learning_rate": 0.030969262579193548,
      "loss": 0.6072,
      "step": 428160
    },
    {
      "epoch": 690.61,
      "learning_rate": 0.030966036775967744,
      "loss": 0.6105,
      "step": 428180
    },
    {
      "epoch": 690.65,
      "learning_rate": 0.030962810972741936,
      "loss": 0.6067,
      "step": 428200
    },
    {
      "epoch": 690.68,
      "learning_rate": 0.03095958516951613,
      "loss": 0.6101,
      "step": 428220
    },
    {
      "epoch": 690.71,
      "learning_rate": 0.030956359366290327,
      "loss": 0.6157,
      "step": 428240
    },
    {
      "epoch": 690.74,
      "learning_rate": 0.03095313356306452,
      "loss": 0.6245,
      "step": 428260
    },
    {
      "epoch": 690.77,
      "learning_rate": 0.030949907759838715,
      "loss": 0.6032,
      "step": 428280
    },
    {
      "epoch": 690.81,
      "learning_rate": 0.03094668195661291,
      "loss": 0.6122,
      "step": 428300
    },
    {
      "epoch": 690.84,
      "learning_rate": 0.03094345615338709,
      "loss": 0.6207,
      "step": 428320
    },
    {
      "epoch": 690.87,
      "learning_rate": 0.030940230350161288,
      "loss": 0.6033,
      "step": 428340
    },
    {
      "epoch": 690.9,
      "learning_rate": 0.030937004546935477,
      "loss": 0.6181,
      "step": 428360
    },
    {
      "epoch": 690.94,
      "learning_rate": 0.030933778743709672,
      "loss": 0.6231,
      "step": 428380
    },
    {
      "epoch": 690.97,
      "learning_rate": 0.03093055294048387,
      "loss": 0.6202,
      "step": 428400
    },
    {
      "epoch": 691.0,
      "learning_rate": 0.03092732713725806,
      "loss": 0.6143,
      "step": 428420
    },
    {
      "epoch": 691.0,
      "eval_accuracy": {
        "accuracy": 0.7717586449145266
      },
      "eval_loss": 0.9654093384742737,
      "eval_runtime": 3.1274,
      "eval_samples_per_second": 4096.342,
      "eval_steps_per_second": 64.27,
      "step": 428420
    },
    {
      "epoch": 691.03,
      "learning_rate": 0.030924101334032256,
      "loss": 0.6028,
      "step": 428440
    },
    {
      "epoch": 691.06,
      "learning_rate": 0.030920875530806455,
      "loss": 0.6117,
      "step": 428460
    },
    {
      "epoch": 691.1,
      "learning_rate": 0.030917649727580643,
      "loss": 0.6094,
      "step": 428480
    },
    {
      "epoch": 691.13,
      "learning_rate": 0.03091442392435484,
      "loss": 0.6172,
      "step": 428500
    },
    {
      "epoch": 691.16,
      "learning_rate": 0.030911198121129038,
      "loss": 0.605,
      "step": 428520
    },
    {
      "epoch": 691.19,
      "learning_rate": 0.030907972317903227,
      "loss": 0.6174,
      "step": 428540
    },
    {
      "epoch": 691.23,
      "learning_rate": 0.030904746514677423,
      "loss": 0.5991,
      "step": 428560
    },
    {
      "epoch": 691.26,
      "learning_rate": 0.03090152071145162,
      "loss": 0.6038,
      "step": 428580
    },
    {
      "epoch": 691.29,
      "learning_rate": 0.03089829490822581,
      "loss": 0.6069,
      "step": 428600
    },
    {
      "epoch": 691.32,
      "learning_rate": 0.030895069104999996,
      "loss": 0.6017,
      "step": 428620
    },
    {
      "epoch": 691.35,
      "learning_rate": 0.030891843301774188,
      "loss": 0.6153,
      "step": 428640
    },
    {
      "epoch": 691.39,
      "learning_rate": 0.030888617498548383,
      "loss": 0.605,
      "step": 428660
    },
    {
      "epoch": 691.42,
      "learning_rate": 0.03088539169532258,
      "loss": 0.6233,
      "step": 428680
    },
    {
      "epoch": 691.45,
      "learning_rate": 0.03088216589209677,
      "loss": 0.6091,
      "step": 428700
    },
    {
      "epoch": 691.48,
      "learning_rate": 0.030878940088870967,
      "loss": 0.5958,
      "step": 428720
    },
    {
      "epoch": 691.52,
      "learning_rate": 0.03087571428564516,
      "loss": 0.5996,
      "step": 428740
    },
    {
      "epoch": 691.55,
      "learning_rate": 0.030872488482419354,
      "loss": 0.6004,
      "step": 428760
    },
    {
      "epoch": 691.58,
      "learning_rate": 0.03086926267919355,
      "loss": 0.6146,
      "step": 428780
    },
    {
      "epoch": 691.61,
      "learning_rate": 0.030866036875967742,
      "loss": 0.628,
      "step": 428800
    },
    {
      "epoch": 691.65,
      "learning_rate": 0.030862811072741938,
      "loss": 0.6189,
      "step": 428820
    },
    {
      "epoch": 691.68,
      "learning_rate": 0.030859585269516134,
      "loss": 0.603,
      "step": 428840
    },
    {
      "epoch": 691.71,
      "learning_rate": 0.030856359466290326,
      "loss": 0.6095,
      "step": 428860
    },
    {
      "epoch": 691.74,
      "learning_rate": 0.03085313366306452,
      "loss": 0.6067,
      "step": 428880
    },
    {
      "epoch": 691.77,
      "learning_rate": 0.03084990785983871,
      "loss": 0.5999,
      "step": 428900
    },
    {
      "epoch": 691.81,
      "learning_rate": 0.03084668205661291,
      "loss": 0.607,
      "step": 428920
    },
    {
      "epoch": 691.84,
      "learning_rate": 0.030843456253387094,
      "loss": 0.624,
      "step": 428940
    },
    {
      "epoch": 691.87,
      "learning_rate": 0.030840230450161283,
      "loss": 0.6139,
      "step": 428960
    },
    {
      "epoch": 691.9,
      "learning_rate": 0.03083700464693548,
      "loss": 0.6079,
      "step": 428980
    },
    {
      "epoch": 691.94,
      "learning_rate": 0.030833778843709678,
      "loss": 0.6119,
      "step": 429000
    },
    {
      "epoch": 691.97,
      "learning_rate": 0.030830553040483866,
      "loss": 0.6133,
      "step": 429020
    },
    {
      "epoch": 692.0,
      "learning_rate": 0.030827327237258062,
      "loss": 0.6245,
      "step": 429040
    },
    {
      "epoch": 692.0,
      "eval_accuracy": {
        "accuracy": 0.7662165326672391
      },
      "eval_loss": 1.0084422826766968,
      "eval_runtime": 4.4978,
      "eval_samples_per_second": 2848.263,
      "eval_steps_per_second": 44.688,
      "step": 429040
    },
    {
      "epoch": 692.03,
      "learning_rate": 0.03082410143403226,
      "loss": 0.6217,
      "step": 429060
    },
    {
      "epoch": 692.06,
      "learning_rate": 0.03082087563080645,
      "loss": 0.5986,
      "step": 429080
    },
    {
      "epoch": 692.1,
      "learning_rate": 0.030817649827580645,
      "loss": 0.5963,
      "step": 429100
    },
    {
      "epoch": 692.13,
      "learning_rate": 0.030814424024354845,
      "loss": 0.5956,
      "step": 429120
    },
    {
      "epoch": 692.16,
      "learning_rate": 0.030811198221129033,
      "loss": 0.5979,
      "step": 429140
    },
    {
      "epoch": 692.19,
      "learning_rate": 0.03080797241790323,
      "loss": 0.5964,
      "step": 429160
    },
    {
      "epoch": 692.23,
      "learning_rate": 0.030804746614677428,
      "loss": 0.609,
      "step": 429180
    },
    {
      "epoch": 692.26,
      "learning_rate": 0.030801520811451617,
      "loss": 0.5946,
      "step": 429200
    },
    {
      "epoch": 692.29,
      "learning_rate": 0.030798295008225812,
      "loss": 0.5972,
      "step": 429220
    },
    {
      "epoch": 692.32,
      "learning_rate": 0.030795069204999994,
      "loss": 0.6128,
      "step": 429240
    },
    {
      "epoch": 692.35,
      "learning_rate": 0.03079184340177419,
      "loss": 0.6002,
      "step": 429260
    },
    {
      "epoch": 692.39,
      "learning_rate": 0.030788617598548382,
      "loss": 0.6036,
      "step": 429280
    },
    {
      "epoch": 692.42,
      "learning_rate": 0.030785391795322577,
      "loss": 0.6069,
      "step": 429300
    },
    {
      "epoch": 692.45,
      "learning_rate": 0.030782165992096773,
      "loss": 0.5995,
      "step": 429320
    },
    {
      "epoch": 692.48,
      "learning_rate": 0.030778940188870965,
      "loss": 0.5938,
      "step": 429340
    },
    {
      "epoch": 692.52,
      "learning_rate": 0.03077571438564516,
      "loss": 0.6097,
      "step": 429360
    },
    {
      "epoch": 692.55,
      "learning_rate": 0.03077248858241935,
      "loss": 0.6109,
      "step": 429380
    },
    {
      "epoch": 692.58,
      "learning_rate": 0.03076926277919355,
      "loss": 0.6105,
      "step": 429400
    },
    {
      "epoch": 692.61,
      "learning_rate": 0.030766036975967744,
      "loss": 0.6068,
      "step": 429420
    },
    {
      "epoch": 692.65,
      "learning_rate": 0.030762811172741933,
      "loss": 0.5993,
      "step": 429440
    },
    {
      "epoch": 692.68,
      "learning_rate": 0.030759585369516132,
      "loss": 0.596,
      "step": 429460
    },
    {
      "epoch": 692.71,
      "learning_rate": 0.030756359566290328,
      "loss": 0.6042,
      "step": 429480
    },
    {
      "epoch": 692.74,
      "learning_rate": 0.030753133763064516,
      "loss": 0.6115,
      "step": 429500
    },
    {
      "epoch": 692.77,
      "learning_rate": 0.030749907959838715,
      "loss": 0.6081,
      "step": 429520
    },
    {
      "epoch": 692.81,
      "learning_rate": 0.030746682156612904,
      "loss": 0.6218,
      "step": 429540
    },
    {
      "epoch": 692.84,
      "learning_rate": 0.03074345635338709,
      "loss": 0.6133,
      "step": 429560
    },
    {
      "epoch": 692.87,
      "learning_rate": 0.030740230550161285,
      "loss": 0.613,
      "step": 429580
    },
    {
      "epoch": 692.9,
      "learning_rate": 0.030737004746935484,
      "loss": 0.604,
      "step": 429600
    },
    {
      "epoch": 692.94,
      "learning_rate": 0.030733778943709673,
      "loss": 0.6019,
      "step": 429620
    },
    {
      "epoch": 692.97,
      "learning_rate": 0.03073055314048387,
      "loss": 0.5906,
      "step": 429640
    },
    {
      "epoch": 693.0,
      "learning_rate": 0.030727327337258067,
      "loss": 0.6145,
      "step": 429660
    },
    {
      "epoch": 693.0,
      "eval_accuracy": {
        "accuracy": 0.7678557489657326
      },
      "eval_loss": 0.9822804927825928,
      "eval_runtime": 2.929,
      "eval_samples_per_second": 4373.916,
      "eval_steps_per_second": 68.625,
      "step": 429660
    },
    {
      "epoch": 693.03,
      "learning_rate": 0.030724101534032256,
      "loss": 0.615,
      "step": 429680
    },
    {
      "epoch": 693.06,
      "learning_rate": 0.03072087573080645,
      "loss": 0.5908,
      "step": 429700
    },
    {
      "epoch": 693.1,
      "learning_rate": 0.03071764992758065,
      "loss": 0.6004,
      "step": 429720
    },
    {
      "epoch": 693.13,
      "learning_rate": 0.03071442412435484,
      "loss": 0.6137,
      "step": 429740
    },
    {
      "epoch": 693.16,
      "learning_rate": 0.030711198321129035,
      "loss": 0.6027,
      "step": 429760
    },
    {
      "epoch": 693.19,
      "learning_rate": 0.030707972517903227,
      "loss": 0.5952,
      "step": 429780
    },
    {
      "epoch": 693.23,
      "learning_rate": 0.030704746714677423,
      "loss": 0.5943,
      "step": 429800
    },
    {
      "epoch": 693.26,
      "learning_rate": 0.03070152091145162,
      "loss": 0.5999,
      "step": 429820
    },
    {
      "epoch": 693.29,
      "learning_rate": 0.03069829510822581,
      "loss": 0.5908,
      "step": 429840
    },
    {
      "epoch": 693.32,
      "learning_rate": 0.030695069304999996,
      "loss": 0.603,
      "step": 429860
    },
    {
      "epoch": 693.35,
      "learning_rate": 0.030691843501774188,
      "loss": 0.6008,
      "step": 429880
    },
    {
      "epoch": 693.39,
      "learning_rate": 0.030688617698548384,
      "loss": 0.6022,
      "step": 429900
    },
    {
      "epoch": 693.42,
      "learning_rate": 0.030685391895322572,
      "loss": 0.6105,
      "step": 429920
    },
    {
      "epoch": 693.45,
      "learning_rate": 0.03068216609209677,
      "loss": 0.6082,
      "step": 429940
    },
    {
      "epoch": 693.48,
      "learning_rate": 0.030678940288870967,
      "loss": 0.6103,
      "step": 429960
    },
    {
      "epoch": 693.52,
      "learning_rate": 0.030675714485645156,
      "loss": 0.6072,
      "step": 429980
    },
    {
      "epoch": 693.55,
      "learning_rate": 0.030672488682419355,
      "loss": 0.5968,
      "step": 430000
    },
    {
      "epoch": 693.58,
      "learning_rate": 0.03066926287919355,
      "loss": 0.6042,
      "step": 430020
    },
    {
      "epoch": 693.61,
      "learning_rate": 0.03066603707596774,
      "loss": 0.5929,
      "step": 430040
    },
    {
      "epoch": 693.65,
      "learning_rate": 0.03066281127274194,
      "loss": 0.6049,
      "step": 430060
    },
    {
      "epoch": 693.68,
      "learning_rate": 0.030659585469516127,
      "loss": 0.6092,
      "step": 430080
    },
    {
      "epoch": 693.71,
      "learning_rate": 0.030656359666290323,
      "loss": 0.6151,
      "step": 430100
    },
    {
      "epoch": 693.74,
      "learning_rate": 0.03065313386306452,
      "loss": 0.6081,
      "step": 430120
    },
    {
      "epoch": 693.77,
      "learning_rate": 0.03064990805983871,
      "loss": 0.6045,
      "step": 430140
    },
    {
      "epoch": 693.81,
      "learning_rate": 0.030646682256612906,
      "loss": 0.607,
      "step": 430160
    },
    {
      "epoch": 693.84,
      "learning_rate": 0.03064345645338709,
      "loss": 0.6114,
      "step": 430180
    },
    {
      "epoch": 693.87,
      "learning_rate": 0.03064023065016129,
      "loss": 0.6091,
      "step": 430200
    },
    {
      "epoch": 693.9,
      "learning_rate": 0.03063700484693548,
      "loss": 0.6288,
      "step": 430220
    },
    {
      "epoch": 693.94,
      "learning_rate": 0.030633779043709675,
      "loss": 0.6167,
      "step": 430240
    },
    {
      "epoch": 693.97,
      "learning_rate": 0.030630553240483874,
      "loss": 0.6203,
      "step": 430260
    },
    {
      "epoch": 694.0,
      "learning_rate": 0.030627488727419355,
      "loss": 0.6139,
      "step": 430280
    },
    {
      "epoch": 694.0,
      "eval_accuracy": {
        "accuracy": 0.7761298883771759
      },
      "eval_loss": 0.9736637473106384,
      "eval_runtime": 2.8465,
      "eval_samples_per_second": 4500.555,
      "eval_steps_per_second": 70.612,
      "step": 430280
    },
    {
      "epoch": 694.03,
      "learning_rate": 0.030624262924193554,
      "loss": 0.6049,
      "step": 430300
    },
    {
      "epoch": 694.06,
      "learning_rate": 0.03062103712096774,
      "loss": 0.5957,
      "step": 430320
    },
    {
      "epoch": 694.1,
      "learning_rate": 0.030617811317741928,
      "loss": 0.6052,
      "step": 430340
    },
    {
      "epoch": 694.13,
      "learning_rate": 0.030614585514516124,
      "loss": 0.5962,
      "step": 430360
    },
    {
      "epoch": 694.16,
      "learning_rate": 0.030611359711290323,
      "loss": 0.5992,
      "step": 430380
    },
    {
      "epoch": 694.19,
      "learning_rate": 0.03060813390806451,
      "loss": 0.5936,
      "step": 430400
    },
    {
      "epoch": 694.23,
      "learning_rate": 0.030604908104838707,
      "loss": 0.5919,
      "step": 430420
    },
    {
      "epoch": 694.26,
      "learning_rate": 0.030601682301612906,
      "loss": 0.6078,
      "step": 430440
    },
    {
      "epoch": 694.29,
      "learning_rate": 0.030598456498387095,
      "loss": 0.5874,
      "step": 430460
    },
    {
      "epoch": 694.32,
      "learning_rate": 0.03059523069516129,
      "loss": 0.6055,
      "step": 430480
    },
    {
      "epoch": 694.35,
      "learning_rate": 0.03059200489193549,
      "loss": 0.6033,
      "step": 430500
    },
    {
      "epoch": 694.39,
      "learning_rate": 0.03058877908870968,
      "loss": 0.6077,
      "step": 430520
    },
    {
      "epoch": 694.42,
      "learning_rate": 0.030585553285483874,
      "loss": 0.6092,
      "step": 430540
    },
    {
      "epoch": 694.45,
      "learning_rate": 0.030582327482258073,
      "loss": 0.6068,
      "step": 430560
    },
    {
      "epoch": 694.48,
      "learning_rate": 0.030579101679032262,
      "loss": 0.5993,
      "step": 430580
    },
    {
      "epoch": 694.52,
      "learning_rate": 0.030575875875806457,
      "loss": 0.5968,
      "step": 430600
    },
    {
      "epoch": 694.55,
      "learning_rate": 0.03057265007258065,
      "loss": 0.5998,
      "step": 430620
    },
    {
      "epoch": 694.58,
      "learning_rate": 0.030569424269354835,
      "loss": 0.5901,
      "step": 430640
    },
    {
      "epoch": 694.61,
      "learning_rate": 0.030566198466129027,
      "loss": 0.6197,
      "step": 430660
    },
    {
      "epoch": 694.65,
      "learning_rate": 0.030562972662903223,
      "loss": 0.6014,
      "step": 430680
    },
    {
      "epoch": 694.68,
      "learning_rate": 0.03055974685967742,
      "loss": 0.6031,
      "step": 430700
    },
    {
      "epoch": 694.71,
      "learning_rate": 0.03055652105645161,
      "loss": 0.6004,
      "step": 430720
    },
    {
      "epoch": 694.74,
      "learning_rate": 0.030553295253225806,
      "loss": 0.6106,
      "step": 430740
    },
    {
      "epoch": 694.77,
      "learning_rate": 0.030550069449999995,
      "loss": 0.621,
      "step": 430760
    },
    {
      "epoch": 694.81,
      "learning_rate": 0.030546843646774194,
      "loss": 0.6131,
      "step": 430780
    },
    {
      "epoch": 694.84,
      "learning_rate": 0.03054361784354839,
      "loss": 0.6269,
      "step": 430800
    },
    {
      "epoch": 694.87,
      "learning_rate": 0.030540392040322578,
      "loss": 0.6043,
      "step": 430820
    },
    {
      "epoch": 694.9,
      "learning_rate": 0.030537166237096777,
      "loss": 0.6073,
      "step": 430840
    },
    {
      "epoch": 694.94,
      "learning_rate": 0.030533940433870966,
      "loss": 0.6184,
      "step": 430860
    },
    {
      "epoch": 694.97,
      "learning_rate": 0.03053071463064516,
      "loss": 0.6116,
      "step": 430880
    },
    {
      "epoch": 695.0,
      "learning_rate": 0.03052748882741936,
      "loss": 0.628,
      "step": 430900
    },
    {
      "epoch": 695.0,
      "eval_accuracy": {
        "accuracy": 0.769494965264226
      },
      "eval_loss": 0.9842965006828308,
      "eval_runtime": 3.7487,
      "eval_samples_per_second": 3417.442,
      "eval_steps_per_second": 53.618,
      "step": 430900
    },
    {
      "epoch": 695.03,
      "learning_rate": 0.03052426302419355,
      "loss": 0.6175,
      "step": 430920
    },
    {
      "epoch": 695.06,
      "learning_rate": 0.030521037220967735,
      "loss": 0.5953,
      "step": 430940
    },
    {
      "epoch": 695.1,
      "learning_rate": 0.03051781141774193,
      "loss": 0.5931,
      "step": 430960
    },
    {
      "epoch": 695.13,
      "learning_rate": 0.03051458561451613,
      "loss": 0.5955,
      "step": 430980
    },
    {
      "epoch": 695.16,
      "learning_rate": 0.030511359811290318,
      "loss": 0.5996,
      "step": 431000
    },
    {
      "epoch": 695.19,
      "learning_rate": 0.030508134008064514,
      "loss": 0.591,
      "step": 431020
    },
    {
      "epoch": 695.23,
      "learning_rate": 0.030504908204838713,
      "loss": 0.5884,
      "step": 431040
    },
    {
      "epoch": 695.26,
      "learning_rate": 0.0305016824016129,
      "loss": 0.6001,
      "step": 431060
    },
    {
      "epoch": 695.29,
      "learning_rate": 0.030498456598387097,
      "loss": 0.6026,
      "step": 431080
    },
    {
      "epoch": 695.32,
      "learning_rate": 0.030495230795161296,
      "loss": 0.6057,
      "step": 431100
    },
    {
      "epoch": 695.35,
      "learning_rate": 0.030492004991935485,
      "loss": 0.6085,
      "step": 431120
    },
    {
      "epoch": 695.39,
      "learning_rate": 0.03048877918870968,
      "loss": 0.6055,
      "step": 431140
    },
    {
      "epoch": 695.42,
      "learning_rate": 0.030485553385483873,
      "loss": 0.6054,
      "step": 431160
    },
    {
      "epoch": 695.45,
      "learning_rate": 0.030482327582258068,
      "loss": 0.6104,
      "step": 431180
    },
    {
      "epoch": 695.48,
      "learning_rate": 0.030479101779032264,
      "loss": 0.6113,
      "step": 431200
    },
    {
      "epoch": 695.52,
      "learning_rate": 0.030475875975806456,
      "loss": 0.6093,
      "step": 431220
    },
    {
      "epoch": 695.55,
      "learning_rate": 0.03047265017258065,
      "loss": 0.5878,
      "step": 431240
    },
    {
      "epoch": 695.58,
      "learning_rate": 0.030469424369354833,
      "loss": 0.5996,
      "step": 431260
    },
    {
      "epoch": 695.61,
      "learning_rate": 0.03046619856612903,
      "loss": 0.5898,
      "step": 431280
    },
    {
      "epoch": 695.65,
      "learning_rate": 0.030462972762903218,
      "loss": 0.5943,
      "step": 431300
    },
    {
      "epoch": 695.68,
      "learning_rate": 0.030459746959677417,
      "loss": 0.6075,
      "step": 431320
    },
    {
      "epoch": 695.71,
      "learning_rate": 0.030456521156451612,
      "loss": 0.6134,
      "step": 431340
    },
    {
      "epoch": 695.74,
      "learning_rate": 0.0304532953532258,
      "loss": 0.6079,
      "step": 431360
    },
    {
      "epoch": 695.77,
      "learning_rate": 0.03045006955,
      "loss": 0.6151,
      "step": 431380
    },
    {
      "epoch": 695.81,
      "learning_rate": 0.03044684374677419,
      "loss": 0.6125,
      "step": 431400
    },
    {
      "epoch": 695.84,
      "learning_rate": 0.030443617943548384,
      "loss": 0.6056,
      "step": 431420
    },
    {
      "epoch": 695.87,
      "learning_rate": 0.030440392140322584,
      "loss": 0.6155,
      "step": 431440
    },
    {
      "epoch": 695.9,
      "learning_rate": 0.030437166337096772,
      "loss": 0.6227,
      "step": 431460
    },
    {
      "epoch": 695.94,
      "learning_rate": 0.030433940533870968,
      "loss": 0.6072,
      "step": 431480
    },
    {
      "epoch": 695.97,
      "learning_rate": 0.030430714730645167,
      "loss": 0.5997,
      "step": 431500
    },
    {
      "epoch": 696.0,
      "learning_rate": 0.030427488927419356,
      "loss": 0.6055,
      "step": 431520
    },
    {
      "epoch": 696.0,
      "eval_accuracy": {
        "accuracy": 0.7819842323003668
      },
      "eval_loss": 0.9487180709838867,
      "eval_runtime": 2.8921,
      "eval_samples_per_second": 4429.636,
      "eval_steps_per_second": 69.499,
      "step": 431520
    },
    {
      "epoch": 696.03,
      "learning_rate": 0.03042426312419355,
      "loss": 0.606,
      "step": 431540
    },
    {
      "epoch": 696.06,
      "learning_rate": 0.030421037320967736,
      "loss": 0.6029,
      "step": 431560
    },
    {
      "epoch": 696.1,
      "learning_rate": 0.030417811517741936,
      "loss": 0.5982,
      "step": 431580
    },
    {
      "epoch": 696.13,
      "learning_rate": 0.030414585714516124,
      "loss": 0.5937,
      "step": 431600
    },
    {
      "epoch": 696.16,
      "learning_rate": 0.03041135991129032,
      "loss": 0.6016,
      "step": 431620
    },
    {
      "epoch": 696.19,
      "learning_rate": 0.03040813410806452,
      "loss": 0.598,
      "step": 431640
    },
    {
      "epoch": 696.23,
      "learning_rate": 0.030404908304838708,
      "loss": 0.6078,
      "step": 431660
    },
    {
      "epoch": 696.26,
      "learning_rate": 0.030401682501612903,
      "loss": 0.6102,
      "step": 431680
    },
    {
      "epoch": 696.29,
      "learning_rate": 0.030398456698387095,
      "loss": 0.6033,
      "step": 431700
    },
    {
      "epoch": 696.32,
      "learning_rate": 0.03039523089516129,
      "loss": 0.5972,
      "step": 431720
    },
    {
      "epoch": 696.35,
      "learning_rate": 0.030392005091935487,
      "loss": 0.5968,
      "step": 431740
    },
    {
      "epoch": 696.39,
      "learning_rate": 0.03038877928870968,
      "loss": 0.613,
      "step": 431760
    },
    {
      "epoch": 696.42,
      "learning_rate": 0.030385553485483874,
      "loss": 0.6042,
      "step": 431780
    },
    {
      "epoch": 696.45,
      "learning_rate": 0.030382327682258067,
      "loss": 0.6028,
      "step": 431800
    },
    {
      "epoch": 696.48,
      "learning_rate": 0.030379101879032262,
      "loss": 0.6226,
      "step": 431820
    },
    {
      "epoch": 696.52,
      "learning_rate": 0.030375876075806458,
      "loss": 0.6236,
      "step": 431840
    },
    {
      "epoch": 696.55,
      "learning_rate": 0.03037265027258065,
      "loss": 0.5952,
      "step": 431860
    },
    {
      "epoch": 696.58,
      "learning_rate": 0.030369424469354835,
      "loss": 0.6012,
      "step": 431880
    },
    {
      "epoch": 696.61,
      "learning_rate": 0.030366198666129024,
      "loss": 0.586,
      "step": 431900
    },
    {
      "epoch": 696.65,
      "learning_rate": 0.030362972862903223,
      "loss": 0.5979,
      "step": 431920
    },
    {
      "epoch": 696.68,
      "learning_rate": 0.030359747059677412,
      "loss": 0.5859,
      "step": 431940
    },
    {
      "epoch": 696.71,
      "learning_rate": 0.030356521256451607,
      "loss": 0.5951,
      "step": 431960
    },
    {
      "epoch": 696.74,
      "learning_rate": 0.030353295453225806,
      "loss": 0.5938,
      "step": 431980
    },
    {
      "epoch": 696.77,
      "learning_rate": 0.030350069649999995,
      "loss": 0.6023,
      "step": 432000
    },
    {
      "epoch": 696.81,
      "learning_rate": 0.03034684384677419,
      "loss": 0.6043,
      "step": 432020
    },
    {
      "epoch": 696.84,
      "learning_rate": 0.03034361804354839,
      "loss": 0.6101,
      "step": 432040
    },
    {
      "epoch": 696.87,
      "learning_rate": 0.03034039224032258,
      "loss": 0.6098,
      "step": 432060
    },
    {
      "epoch": 696.9,
      "learning_rate": 0.030337166437096774,
      "loss": 0.6085,
      "step": 432080
    },
    {
      "epoch": 696.94,
      "learning_rate": 0.030333940633870973,
      "loss": 0.6183,
      "step": 432100
    },
    {
      "epoch": 696.97,
      "learning_rate": 0.030330714830645162,
      "loss": 0.6169,
      "step": 432120
    },
    {
      "epoch": 697.0,
      "learning_rate": 0.030327489027419358,
      "loss": 0.6022,
      "step": 432140
    },
    {
      "epoch": 697.0,
      "eval_accuracy": {
        "accuracy": 0.774100382483803
      },
      "eval_loss": 0.9725626707077026,
      "eval_runtime": 3.281,
      "eval_samples_per_second": 3904.652,
      "eval_steps_per_second": 61.263,
      "step": 432140
    },
    {
      "epoch": 697.03,
      "learning_rate": 0.030324263224193557,
      "loss": 0.6272,
      "step": 432160
    },
    {
      "epoch": 697.06,
      "learning_rate": 0.030321037420967735,
      "loss": 0.6128,
      "step": 432180
    },
    {
      "epoch": 697.1,
      "learning_rate": 0.03031781161774193,
      "loss": 0.5972,
      "step": 432200
    },
    {
      "epoch": 697.13,
      "learning_rate": 0.030314585814516126,
      "loss": 0.5869,
      "step": 432220
    },
    {
      "epoch": 697.16,
      "learning_rate": 0.03031136001129032,
      "loss": 0.591,
      "step": 432240
    },
    {
      "epoch": 697.19,
      "learning_rate": 0.030308134208064514,
      "loss": 0.5968,
      "step": 432260
    },
    {
      "epoch": 697.23,
      "learning_rate": 0.03030490840483871,
      "loss": 0.5863,
      "step": 432280
    },
    {
      "epoch": 697.26,
      "learning_rate": 0.030301682601612902,
      "loss": 0.599,
      "step": 432300
    },
    {
      "epoch": 697.29,
      "learning_rate": 0.030298456798387097,
      "loss": 0.602,
      "step": 432320
    },
    {
      "epoch": 697.32,
      "learning_rate": 0.03029523099516129,
      "loss": 0.5841,
      "step": 432340
    },
    {
      "epoch": 697.35,
      "learning_rate": 0.030292005191935485,
      "loss": 0.5839,
      "step": 432360
    },
    {
      "epoch": 697.39,
      "learning_rate": 0.03028877938870968,
      "loss": 0.5892,
      "step": 432380
    },
    {
      "epoch": 697.42,
      "learning_rate": 0.030285553585483873,
      "loss": 0.5995,
      "step": 432400
    },
    {
      "epoch": 697.45,
      "learning_rate": 0.03028232778225807,
      "loss": 0.6058,
      "step": 432420
    },
    {
      "epoch": 697.48,
      "learning_rate": 0.03027910197903226,
      "loss": 0.6041,
      "step": 432440
    },
    {
      "epoch": 697.52,
      "learning_rate": 0.030275876175806456,
      "loss": 0.6056,
      "step": 432460
    },
    {
      "epoch": 697.55,
      "learning_rate": 0.030272650372580652,
      "loss": 0.6098,
      "step": 432480
    },
    {
      "epoch": 697.58,
      "learning_rate": 0.03026942456935483,
      "loss": 0.6051,
      "step": 432500
    },
    {
      "epoch": 697.61,
      "learning_rate": 0.03026619876612903,
      "loss": 0.5993,
      "step": 432520
    },
    {
      "epoch": 697.65,
      "learning_rate": 0.030262972962903218,
      "loss": 0.6002,
      "step": 432540
    },
    {
      "epoch": 697.68,
      "learning_rate": 0.030259747159677414,
      "loss": 0.603,
      "step": 432560
    },
    {
      "epoch": 697.71,
      "learning_rate": 0.030256521356451613,
      "loss": 0.5999,
      "step": 432580
    },
    {
      "epoch": 697.74,
      "learning_rate": 0.0302532955532258,
      "loss": 0.6031,
      "step": 432600
    },
    {
      "epoch": 697.77,
      "learning_rate": 0.030250069749999997,
      "loss": 0.6108,
      "step": 432620
    },
    {
      "epoch": 697.81,
      "learning_rate": 0.030246843946774196,
      "loss": 0.6082,
      "step": 432640
    },
    {
      "epoch": 697.84,
      "learning_rate": 0.030243618143548385,
      "loss": 0.6061,
      "step": 432660
    },
    {
      "epoch": 697.87,
      "learning_rate": 0.03024039234032258,
      "loss": 0.6021,
      "step": 432680
    },
    {
      "epoch": 697.9,
      "learning_rate": 0.03023716653709678,
      "loss": 0.6135,
      "step": 432700
    },
    {
      "epoch": 697.94,
      "learning_rate": 0.03023394073387097,
      "loss": 0.6102,
      "step": 432720
    },
    {
      "epoch": 697.97,
      "learning_rate": 0.030230714930645164,
      "loss": 0.5964,
      "step": 432740
    },
    {
      "epoch": 698.0,
      "learning_rate": 0.030227650417580645,
      "loss": 0.6068,
      "step": 432760
    },
    {
      "epoch": 698.0,
      "eval_accuracy": {
        "accuracy": 0.7757395987822965
      },
      "eval_loss": 0.9572778344154358,
      "eval_runtime": 2.9456,
      "eval_samples_per_second": 4349.156,
      "eval_steps_per_second": 68.237,
      "step": 432760
    },
    {
      "epoch": 698.03,
      "learning_rate": 0.030224424614354834,
      "loss": 0.5948,
      "step": 432780
    },
    {
      "epoch": 698.06,
      "learning_rate": 0.03022119881112903,
      "loss": 0.5817,
      "step": 432800
    },
    {
      "epoch": 698.1,
      "learning_rate": 0.03021797300790323,
      "loss": 0.5943,
      "step": 432820
    },
    {
      "epoch": 698.13,
      "learning_rate": 0.030214747204677418,
      "loss": 0.5829,
      "step": 432840
    },
    {
      "epoch": 698.16,
      "learning_rate": 0.030211521401451613,
      "loss": 0.5908,
      "step": 432860
    },
    {
      "epoch": 698.19,
      "learning_rate": 0.030208295598225812,
      "loss": 0.5916,
      "step": 432880
    },
    {
      "epoch": 698.23,
      "learning_rate": 0.030205069795,
      "loss": 0.5898,
      "step": 432900
    },
    {
      "epoch": 698.26,
      "learning_rate": 0.030201843991774197,
      "loss": 0.5976,
      "step": 432920
    },
    {
      "epoch": 698.29,
      "learning_rate": 0.030198618188548396,
      "loss": 0.6064,
      "step": 432940
    },
    {
      "epoch": 698.32,
      "learning_rate": 0.03019539238532258,
      "loss": 0.6081,
      "step": 432960
    },
    {
      "epoch": 698.35,
      "learning_rate": 0.03019216658209677,
      "loss": 0.6164,
      "step": 432980
    },
    {
      "epoch": 698.39,
      "learning_rate": 0.030188940778870965,
      "loss": 0.5856,
      "step": 433000
    },
    {
      "epoch": 698.42,
      "learning_rate": 0.030185714975645157,
      "loss": 0.6083,
      "step": 433020
    },
    {
      "epoch": 698.45,
      "learning_rate": 0.030182489172419353,
      "loss": 0.6134,
      "step": 433040
    },
    {
      "epoch": 698.48,
      "learning_rate": 0.03017926336919355,
      "loss": 0.5972,
      "step": 433060
    },
    {
      "epoch": 698.52,
      "learning_rate": 0.03017603756596774,
      "loss": 0.5772,
      "step": 433080
    },
    {
      "epoch": 698.55,
      "learning_rate": 0.030172811762741936,
      "loss": 0.6043,
      "step": 433100
    },
    {
      "epoch": 698.58,
      "learning_rate": 0.03016958595951613,
      "loss": 0.6018,
      "step": 433120
    },
    {
      "epoch": 698.61,
      "learning_rate": 0.030166360156290324,
      "loss": 0.5966,
      "step": 433140
    },
    {
      "epoch": 698.65,
      "learning_rate": 0.03016313435306452,
      "loss": 0.5905,
      "step": 433160
    },
    {
      "epoch": 698.68,
      "learning_rate": 0.030159908549838712,
      "loss": 0.6128,
      "step": 433180
    },
    {
      "epoch": 698.71,
      "learning_rate": 0.030156682746612908,
      "loss": 0.6005,
      "step": 433200
    },
    {
      "epoch": 698.74,
      "learning_rate": 0.0301534569433871,
      "loss": 0.5955,
      "step": 433220
    },
    {
      "epoch": 698.77,
      "learning_rate": 0.030150231140161295,
      "loss": 0.614,
      "step": 433240
    },
    {
      "epoch": 698.81,
      "learning_rate": 0.030147005336935474,
      "loss": 0.6226,
      "step": 433260
    },
    {
      "epoch": 698.84,
      "learning_rate": 0.03014377953370967,
      "loss": 0.5942,
      "step": 433280
    },
    {
      "epoch": 698.87,
      "learning_rate": 0.03014055373048387,
      "loss": 0.6078,
      "step": 433300
    },
    {
      "epoch": 698.9,
      "learning_rate": 0.030137327927258057,
      "loss": 0.6235,
      "step": 433320
    },
    {
      "epoch": 698.94,
      "learning_rate": 0.030134102124032253,
      "loss": 0.6011,
      "step": 433340
    },
    {
      "epoch": 698.97,
      "learning_rate": 0.03013087632080645,
      "loss": 0.6021,
      "step": 433360
    },
    {
      "epoch": 699.0,
      "learning_rate": 0.03012765051758064,
      "loss": 0.6082,
      "step": 433380
    },
    {
      "epoch": 699.0,
      "eval_accuracy": {
        "accuracy": 0.7749590195925377
      },
      "eval_loss": 0.968136191368103,
      "eval_runtime": 5.5644,
      "eval_samples_per_second": 2302.3,
      "eval_steps_per_second": 36.122,
      "step": 433380
    },
    {
      "epoch": 699.03,
      "learning_rate": 0.030124424714354836,
      "loss": 0.6157,
      "step": 433400
    },
    {
      "epoch": 699.06,
      "learning_rate": 0.030121198911129035,
      "loss": 0.5912,
      "step": 433420
    },
    {
      "epoch": 699.1,
      "learning_rate": 0.030117973107903224,
      "loss": 0.6012,
      "step": 433440
    },
    {
      "epoch": 699.13,
      "learning_rate": 0.03011474730467742,
      "loss": 0.5897,
      "step": 433460
    },
    {
      "epoch": 699.16,
      "learning_rate": 0.03011152150145162,
      "loss": 0.5954,
      "step": 433480
    },
    {
      "epoch": 699.19,
      "learning_rate": 0.030108295698225807,
      "loss": 0.5922,
      "step": 433500
    },
    {
      "epoch": 699.23,
      "learning_rate": 0.030105069895000003,
      "loss": 0.5873,
      "step": 433520
    },
    {
      "epoch": 699.26,
      "learning_rate": 0.030101844091774202,
      "loss": 0.6095,
      "step": 433540
    },
    {
      "epoch": 699.29,
      "learning_rate": 0.03009861828854839,
      "loss": 0.6105,
      "step": 433560
    },
    {
      "epoch": 699.32,
      "learning_rate": 0.030095392485322576,
      "loss": 0.6063,
      "step": 433580
    },
    {
      "epoch": 699.35,
      "learning_rate": 0.03009216668209677,
      "loss": 0.5975,
      "step": 433600
    },
    {
      "epoch": 699.39,
      "learning_rate": 0.030088940878870964,
      "loss": 0.6043,
      "step": 433620
    },
    {
      "epoch": 699.42,
      "learning_rate": 0.03008571507564516,
      "loss": 0.6024,
      "step": 433640
    },
    {
      "epoch": 699.45,
      "learning_rate": 0.03008248927241935,
      "loss": 0.6102,
      "step": 433660
    },
    {
      "epoch": 699.48,
      "learning_rate": 0.030079263469193547,
      "loss": 0.5907,
      "step": 433680
    },
    {
      "epoch": 699.52,
      "learning_rate": 0.030076037665967743,
      "loss": 0.6154,
      "step": 433700
    },
    {
      "epoch": 699.55,
      "learning_rate": 0.030072811862741935,
      "loss": 0.6034,
      "step": 433720
    },
    {
      "epoch": 699.58,
      "learning_rate": 0.03006958605951613,
      "loss": 0.5889,
      "step": 433740
    },
    {
      "epoch": 699.61,
      "learning_rate": 0.030066360256290323,
      "loss": 0.6111,
      "step": 433760
    },
    {
      "epoch": 699.65,
      "learning_rate": 0.030063134453064518,
      "loss": 0.6129,
      "step": 433780
    },
    {
      "epoch": 699.68,
      "learning_rate": 0.030059908649838714,
      "loss": 0.6023,
      "step": 433800
    },
    {
      "epoch": 699.71,
      "learning_rate": 0.030056682846612906,
      "loss": 0.6178,
      "step": 433820
    },
    {
      "epoch": 699.74,
      "learning_rate": 0.0300534570433871,
      "loss": 0.6268,
      "step": 433840
    },
    {
      "epoch": 699.77,
      "learning_rate": 0.030050231240161297,
      "loss": 0.604,
      "step": 433860
    },
    {
      "epoch": 699.81,
      "learning_rate": 0.030047005436935476,
      "loss": 0.6057,
      "step": 433880
    },
    {
      "epoch": 699.84,
      "learning_rate": 0.030043779633709675,
      "loss": 0.6037,
      "step": 433900
    },
    {
      "epoch": 699.87,
      "learning_rate": 0.030040553830483863,
      "loss": 0.6043,
      "step": 433920
    },
    {
      "epoch": 699.9,
      "learning_rate": 0.03003732802725806,
      "loss": 0.6063,
      "step": 433940
    },
    {
      "epoch": 699.94,
      "learning_rate": 0.030034102224032258,
      "loss": 0.6052,
      "step": 433960
    },
    {
      "epoch": 699.97,
      "learning_rate": 0.030030876420806447,
      "loss": 0.6127,
      "step": 433980
    },
    {
      "epoch": 700.0,
      "learning_rate": 0.030027650617580642,
      "loss": 0.6238,
      "step": 434000
    },
    {
      "epoch": 700.0,
      "eval_accuracy": {
        "accuracy": 0.7735539770509718
      },
      "eval_loss": 0.9740896224975586,
      "eval_runtime": 3.1843,
      "eval_samples_per_second": 4023.164,
      "eval_steps_per_second": 63.122,
      "step": 434000
    },
    {
      "epoch": 700.03,
      "learning_rate": 0.03002442481435484,
      "loss": 0.6008,
      "step": 434020
    },
    {
      "epoch": 700.06,
      "learning_rate": 0.03002119901112903,
      "loss": 0.6016,
      "step": 434040
    },
    {
      "epoch": 700.1,
      "learning_rate": 0.030017973207903226,
      "loss": 0.5926,
      "step": 434060
    },
    {
      "epoch": 700.13,
      "learning_rate": 0.030014747404677425,
      "loss": 0.5981,
      "step": 434080
    },
    {
      "epoch": 700.16,
      "learning_rate": 0.030011521601451614,
      "loss": 0.5975,
      "step": 434100
    },
    {
      "epoch": 700.19,
      "learning_rate": 0.03000829579822581,
      "loss": 0.5945,
      "step": 434120
    },
    {
      "epoch": 700.23,
      "learning_rate": 0.030005069995000008,
      "loss": 0.5842,
      "step": 434140
    },
    {
      "epoch": 700.26,
      "learning_rate": 0.030001844191774197,
      "loss": 0.6056,
      "step": 434160
    },
    {
      "epoch": 700.29,
      "learning_rate": 0.029998618388548393,
      "loss": 0.5987,
      "step": 434180
    },
    {
      "epoch": 700.32,
      "learning_rate": 0.029995392585322574,
      "loss": 0.6032,
      "step": 434200
    },
    {
      "epoch": 700.35,
      "learning_rate": 0.02999216678209677,
      "loss": 0.6044,
      "step": 434220
    },
    {
      "epoch": 700.39,
      "learning_rate": 0.029988940978870966,
      "loss": 0.5956,
      "step": 434240
    },
    {
      "epoch": 700.42,
      "learning_rate": 0.029985715175645158,
      "loss": 0.6037,
      "step": 434260
    },
    {
      "epoch": 700.45,
      "learning_rate": 0.029982489372419353,
      "loss": 0.5977,
      "step": 434280
    },
    {
      "epoch": 700.48,
      "learning_rate": 0.029979263569193546,
      "loss": 0.6161,
      "step": 434300
    },
    {
      "epoch": 700.52,
      "learning_rate": 0.02997603776596774,
      "loss": 0.6172,
      "step": 434320
    },
    {
      "epoch": 700.55,
      "learning_rate": 0.029972811962741937,
      "loss": 0.6136,
      "step": 434340
    },
    {
      "epoch": 700.58,
      "learning_rate": 0.02996958615951613,
      "loss": 0.5891,
      "step": 434360
    },
    {
      "epoch": 700.61,
      "learning_rate": 0.029966360356290325,
      "loss": 0.6031,
      "step": 434380
    },
    {
      "epoch": 700.65,
      "learning_rate": 0.029963134553064513,
      "loss": 0.6032,
      "step": 434400
    },
    {
      "epoch": 700.68,
      "learning_rate": 0.029959908749838712,
      "loss": 0.6004,
      "step": 434420
    },
    {
      "epoch": 700.71,
      "learning_rate": 0.029956682946612908,
      "loss": 0.6089,
      "step": 434440
    },
    {
      "epoch": 700.74,
      "learning_rate": 0.029953457143387097,
      "loss": 0.6072,
      "step": 434460
    },
    {
      "epoch": 700.77,
      "learning_rate": 0.029950231340161296,
      "loss": 0.6052,
      "step": 434480
    },
    {
      "epoch": 700.81,
      "learning_rate": 0.02994700553693548,
      "loss": 0.6034,
      "step": 434500
    },
    {
      "epoch": 700.84,
      "learning_rate": 0.02994377973370967,
      "loss": 0.6106,
      "step": 434520
    },
    {
      "epoch": 700.87,
      "learning_rate": 0.029940553930483865,
      "loss": 0.6119,
      "step": 434540
    },
    {
      "epoch": 700.9,
      "learning_rate": 0.029937328127258064,
      "loss": 0.6005,
      "step": 434560
    },
    {
      "epoch": 700.94,
      "learning_rate": 0.029934102324032253,
      "loss": 0.5924,
      "step": 434580
    },
    {
      "epoch": 700.97,
      "learning_rate": 0.02993087652080645,
      "loss": 0.5887,
      "step": 434600
    },
    {
      "epoch": 701.0,
      "learning_rate": 0.029927650717580648,
      "loss": 0.6228,
      "step": 434620
    },
    {
      "epoch": 701.0,
      "eval_accuracy": {
        "accuracy": 0.7719928186714542
      },
      "eval_loss": 0.9842779636383057,
      "eval_runtime": 3.122,
      "eval_samples_per_second": 4103.441,
      "eval_steps_per_second": 64.382,
      "step": 434620
    },
    {
      "epoch": 701.03,
      "learning_rate": 0.029924424914354836,
      "loss": 0.5945,
      "step": 434640
    },
    {
      "epoch": 701.06,
      "learning_rate": 0.029921199111129032,
      "loss": 0.6031,
      "step": 434660
    },
    {
      "epoch": 701.1,
      "learning_rate": 0.02991797330790323,
      "loss": 0.5985,
      "step": 434680
    },
    {
      "epoch": 701.13,
      "learning_rate": 0.02991474750467742,
      "loss": 0.5945,
      "step": 434700
    },
    {
      "epoch": 701.16,
      "learning_rate": 0.029911521701451615,
      "loss": 0.585,
      "step": 434720
    },
    {
      "epoch": 701.19,
      "learning_rate": 0.029908295898225815,
      "loss": 0.5904,
      "step": 434740
    },
    {
      "epoch": 701.23,
      "learning_rate": 0.029905070095000003,
      "loss": 0.5988,
      "step": 434760
    },
    {
      "epoch": 701.26,
      "learning_rate": 0.0299018442917742,
      "loss": 0.5951,
      "step": 434780
    },
    {
      "epoch": 701.29,
      "learning_rate": 0.02989861848854839,
      "loss": 0.5804,
      "step": 434800
    },
    {
      "epoch": 701.32,
      "learning_rate": 0.029895392685322576,
      "loss": 0.5885,
      "step": 434820
    },
    {
      "epoch": 701.35,
      "learning_rate": 0.02989216688209677,
      "loss": 0.6043,
      "step": 434840
    },
    {
      "epoch": 701.39,
      "learning_rate": 0.029888941078870964,
      "loss": 0.6008,
      "step": 434860
    },
    {
      "epoch": 701.42,
      "learning_rate": 0.02988571527564516,
      "loss": 0.6136,
      "step": 434880
    },
    {
      "epoch": 701.45,
      "learning_rate": 0.029882489472419352,
      "loss": 0.61,
      "step": 434900
    },
    {
      "epoch": 701.48,
      "learning_rate": 0.029879263669193547,
      "loss": 0.5996,
      "step": 434920
    },
    {
      "epoch": 701.52,
      "learning_rate": 0.029876037865967736,
      "loss": 0.6037,
      "step": 434940
    },
    {
      "epoch": 701.55,
      "learning_rate": 0.029872812062741935,
      "loss": 0.6082,
      "step": 434960
    },
    {
      "epoch": 701.58,
      "learning_rate": 0.02986958625951613,
      "loss": 0.6017,
      "step": 434980
    },
    {
      "epoch": 701.61,
      "learning_rate": 0.02986636045629032,
      "loss": 0.6111,
      "step": 435000
    },
    {
      "epoch": 701.65,
      "learning_rate": 0.02986313465306452,
      "loss": 0.602,
      "step": 435020
    },
    {
      "epoch": 701.68,
      "learning_rate": 0.029859908849838714,
      "loss": 0.6013,
      "step": 435040
    },
    {
      "epoch": 701.71,
      "learning_rate": 0.029856683046612903,
      "loss": 0.5891,
      "step": 435060
    },
    {
      "epoch": 701.74,
      "learning_rate": 0.029853457243387102,
      "loss": 0.6003,
      "step": 435080
    },
    {
      "epoch": 701.77,
      "learning_rate": 0.02985023144016129,
      "loss": 0.5997,
      "step": 435100
    },
    {
      "epoch": 701.81,
      "learning_rate": 0.029847005636935486,
      "loss": 0.5963,
      "step": 435120
    },
    {
      "epoch": 701.84,
      "learning_rate": 0.02984377983370967,
      "loss": 0.5996,
      "step": 435140
    },
    {
      "epoch": 701.87,
      "learning_rate": 0.02984055403048387,
      "loss": 0.6028,
      "step": 435160
    },
    {
      "epoch": 701.9,
      "learning_rate": 0.02983732822725806,
      "loss": 0.6021,
      "step": 435180
    },
    {
      "epoch": 701.94,
      "learning_rate": 0.029834102424032255,
      "loss": 0.5912,
      "step": 435200
    },
    {
      "epoch": 701.97,
      "learning_rate": 0.029830876620806454,
      "loss": 0.599,
      "step": 435220
    },
    {
      "epoch": 702.0,
      "learning_rate": 0.029827812107741936,
      "loss": 0.6099,
      "step": 435240
    },
    {
      "epoch": 702.0,
      "eval_accuracy": {
        "accuracy": 0.7708219498868161
      },
      "eval_loss": 0.9606828689575195,
      "eval_runtime": 4.6066,
      "eval_samples_per_second": 2781.0,
      "eval_steps_per_second": 43.633,
      "step": 435240
    },
    {
      "epoch": 702.03,
      "learning_rate": 0.029824586304516135,
      "loss": 0.5925,
      "step": 435260
    },
    {
      "epoch": 702.06,
      "learning_rate": 0.02982136050129032,
      "loss": 0.5784,
      "step": 435280
    },
    {
      "epoch": 702.1,
      "learning_rate": 0.02981813469806451,
      "loss": 0.599,
      "step": 435300
    },
    {
      "epoch": 702.13,
      "learning_rate": 0.029814908894838704,
      "loss": 0.594,
      "step": 435320
    },
    {
      "epoch": 702.16,
      "learning_rate": 0.029811683091612903,
      "loss": 0.602,
      "step": 435340
    },
    {
      "epoch": 702.19,
      "learning_rate": 0.029808457288387092,
      "loss": 0.5749,
      "step": 435360
    },
    {
      "epoch": 702.23,
      "learning_rate": 0.029805231485161288,
      "loss": 0.5931,
      "step": 435380
    },
    {
      "epoch": 702.26,
      "learning_rate": 0.029802005681935487,
      "loss": 0.6011,
      "step": 435400
    },
    {
      "epoch": 702.29,
      "learning_rate": 0.029798779878709675,
      "loss": 0.6049,
      "step": 435420
    },
    {
      "epoch": 702.32,
      "learning_rate": 0.02979555407548387,
      "loss": 0.6082,
      "step": 435440
    },
    {
      "epoch": 702.35,
      "learning_rate": 0.02979232827225807,
      "loss": 0.608,
      "step": 435460
    },
    {
      "epoch": 702.39,
      "learning_rate": 0.02978910246903226,
      "loss": 0.5955,
      "step": 435480
    },
    {
      "epoch": 702.42,
      "learning_rate": 0.029785876665806454,
      "loss": 0.5904,
      "step": 435500
    },
    {
      "epoch": 702.45,
      "learning_rate": 0.029782650862580654,
      "loss": 0.6019,
      "step": 435520
    },
    {
      "epoch": 702.48,
      "learning_rate": 0.029779425059354842,
      "loss": 0.5959,
      "step": 435540
    },
    {
      "epoch": 702.52,
      "learning_rate": 0.029776199256129038,
      "loss": 0.5991,
      "step": 435560
    },
    {
      "epoch": 702.55,
      "learning_rate": 0.02977297345290322,
      "loss": 0.6028,
      "step": 435580
    },
    {
      "epoch": 702.58,
      "learning_rate": 0.029769747649677415,
      "loss": 0.6021,
      "step": 435600
    },
    {
      "epoch": 702.61,
      "learning_rate": 0.02976652184645161,
      "loss": 0.5929,
      "step": 435620
    },
    {
      "epoch": 702.65,
      "learning_rate": 0.029763296043225803,
      "loss": 0.6009,
      "step": 435640
    },
    {
      "epoch": 702.68,
      "learning_rate": 0.02976007024,
      "loss": 0.6005,
      "step": 435660
    },
    {
      "epoch": 702.71,
      "learning_rate": 0.02975684443677419,
      "loss": 0.5957,
      "step": 435680
    },
    {
      "epoch": 702.74,
      "learning_rate": 0.029753618633548386,
      "loss": 0.609,
      "step": 435700
    },
    {
      "epoch": 702.77,
      "learning_rate": 0.029750392830322582,
      "loss": 0.6139,
      "step": 435720
    },
    {
      "epoch": 702.81,
      "learning_rate": 0.029747167027096774,
      "loss": 0.6188,
      "step": 435740
    },
    {
      "epoch": 702.84,
      "learning_rate": 0.02974394122387097,
      "loss": 0.5955,
      "step": 435760
    },
    {
      "epoch": 702.87,
      "learning_rate": 0.02974071542064516,
      "loss": 0.616,
      "step": 435780
    },
    {
      "epoch": 702.9,
      "learning_rate": 0.029737489617419358,
      "loss": 0.61,
      "step": 435800
    },
    {
      "epoch": 702.94,
      "learning_rate": 0.029734263814193553,
      "loss": 0.5942,
      "step": 435820
    },
    {
      "epoch": 702.97,
      "learning_rate": 0.029731038010967742,
      "loss": 0.6095,
      "step": 435840
    },
    {
      "epoch": 703.0,
      "learning_rate": 0.02972781220774194,
      "loss": 0.5897,
      "step": 435860
    },
    {
      "epoch": 703.0,
      "eval_accuracy": {
        "accuracy": 0.7744126141597065
      },
      "eval_loss": 0.9870136976242065,
      "eval_runtime": 2.9894,
      "eval_samples_per_second": 4285.467,
      "eval_steps_per_second": 67.237,
      "step": 435860
    },
    {
      "epoch": 703.03,
      "learning_rate": 0.02972458640451613,
      "loss": 0.6259,
      "step": 435880
    },
    {
      "epoch": 703.06,
      "learning_rate": 0.029721360601290315,
      "loss": 0.5825,
      "step": 435900
    },
    {
      "epoch": 703.1,
      "learning_rate": 0.02971813479806451,
      "loss": 0.5804,
      "step": 435920
    },
    {
      "epoch": 703.13,
      "learning_rate": 0.02971490899483871,
      "loss": 0.6055,
      "step": 435940
    },
    {
      "epoch": 703.16,
      "learning_rate": 0.0297116831916129,
      "loss": 0.5816,
      "step": 435960
    },
    {
      "epoch": 703.19,
      "learning_rate": 0.029708457388387094,
      "loss": 0.595,
      "step": 435980
    },
    {
      "epoch": 703.23,
      "learning_rate": 0.029705231585161293,
      "loss": 0.5854,
      "step": 436000
    },
    {
      "epoch": 703.26,
      "learning_rate": 0.02970200578193548,
      "loss": 0.5904,
      "step": 436020
    },
    {
      "epoch": 703.29,
      "learning_rate": 0.029698779978709677,
      "loss": 0.6016,
      "step": 436040
    },
    {
      "epoch": 703.32,
      "learning_rate": 0.029695554175483876,
      "loss": 0.5872,
      "step": 436060
    },
    {
      "epoch": 703.35,
      "learning_rate": 0.029692328372258065,
      "loss": 0.6148,
      "step": 436080
    },
    {
      "epoch": 703.39,
      "learning_rate": 0.02968910256903226,
      "loss": 0.5931,
      "step": 436100
    },
    {
      "epoch": 703.42,
      "learning_rate": 0.02968587676580646,
      "loss": 0.5855,
      "step": 436120
    },
    {
      "epoch": 703.45,
      "learning_rate": 0.02968265096258065,
      "loss": 0.5965,
      "step": 436140
    },
    {
      "epoch": 703.48,
      "learning_rate": 0.029679425159354844,
      "loss": 0.5948,
      "step": 436160
    },
    {
      "epoch": 703.52,
      "learning_rate": 0.029676199356129036,
      "loss": 0.5897,
      "step": 436180
    },
    {
      "epoch": 703.55,
      "learning_rate": 0.02967297355290322,
      "loss": 0.6046,
      "step": 436200
    },
    {
      "epoch": 703.58,
      "learning_rate": 0.029669747749677414,
      "loss": 0.5953,
      "step": 436220
    },
    {
      "epoch": 703.61,
      "learning_rate": 0.02966652194645161,
      "loss": 0.5927,
      "step": 436240
    },
    {
      "epoch": 703.65,
      "learning_rate": 0.029663296143225805,
      "loss": 0.598,
      "step": 436260
    },
    {
      "epoch": 703.68,
      "learning_rate": 0.029660070339999997,
      "loss": 0.5884,
      "step": 436280
    },
    {
      "epoch": 703.71,
      "learning_rate": 0.029656844536774193,
      "loss": 0.6119,
      "step": 436300
    },
    {
      "epoch": 703.74,
      "learning_rate": 0.02965361873354838,
      "loss": 0.6061,
      "step": 436320
    },
    {
      "epoch": 703.77,
      "learning_rate": 0.02965039293032258,
      "loss": 0.6046,
      "step": 436340
    },
    {
      "epoch": 703.81,
      "learning_rate": 0.029647167127096776,
      "loss": 0.6139,
      "step": 436360
    },
    {
      "epoch": 703.84,
      "learning_rate": 0.029643941323870965,
      "loss": 0.6134,
      "step": 436380
    },
    {
      "epoch": 703.87,
      "learning_rate": 0.029640715520645164,
      "loss": 0.618,
      "step": 436400
    },
    {
      "epoch": 703.9,
      "learning_rate": 0.029637489717419353,
      "loss": 0.6126,
      "step": 436420
    },
    {
      "epoch": 703.94,
      "learning_rate": 0.029634263914193548,
      "loss": 0.6036,
      "step": 436440
    },
    {
      "epoch": 703.97,
      "learning_rate": 0.029631038110967747,
      "loss": 0.5939,
      "step": 436460
    },
    {
      "epoch": 704.0,
      "learning_rate": 0.029627812307741936,
      "loss": 0.6178,
      "step": 436480
    },
    {
      "epoch": 704.0,
      "eval_accuracy": {
        "accuracy": 0.7653578955585044
      },
      "eval_loss": 1.0013642311096191,
      "eval_runtime": 3.1214,
      "eval_samples_per_second": 4104.206,
      "eval_steps_per_second": 64.394,
      "step": 436480
    },
    {
      "epoch": 704.03,
      "learning_rate": 0.02962458650451613,
      "loss": 0.627,
      "step": 436500
    },
    {
      "epoch": 704.06,
      "learning_rate": 0.029621360701290317,
      "loss": 0.5928,
      "step": 436520
    },
    {
      "epoch": 704.1,
      "learning_rate": 0.029618134898064516,
      "loss": 0.5942,
      "step": 436540
    },
    {
      "epoch": 704.13,
      "learning_rate": 0.029614909094838705,
      "loss": 0.5961,
      "step": 436560
    },
    {
      "epoch": 704.16,
      "learning_rate": 0.0296116832916129,
      "loss": 0.5851,
      "step": 436580
    },
    {
      "epoch": 704.19,
      "learning_rate": 0.0296084574883871,
      "loss": 0.5984,
      "step": 436600
    },
    {
      "epoch": 704.23,
      "learning_rate": 0.029605231685161288,
      "loss": 0.5943,
      "step": 436620
    },
    {
      "epoch": 704.26,
      "learning_rate": 0.029602005881935484,
      "loss": 0.5865,
      "step": 436640
    },
    {
      "epoch": 704.29,
      "learning_rate": 0.029598780078709683,
      "loss": 0.6059,
      "step": 436660
    },
    {
      "epoch": 704.32,
      "learning_rate": 0.02959555427548387,
      "loss": 0.5948,
      "step": 436680
    },
    {
      "epoch": 704.35,
      "learning_rate": 0.029592328472258067,
      "loss": 0.5776,
      "step": 436700
    },
    {
      "epoch": 704.39,
      "learning_rate": 0.02958910266903226,
      "loss": 0.5881,
      "step": 436720
    },
    {
      "epoch": 704.42,
      "learning_rate": 0.029585876865806455,
      "loss": 0.5948,
      "step": 436740
    },
    {
      "epoch": 704.45,
      "learning_rate": 0.02958265106258065,
      "loss": 0.5849,
      "step": 436760
    },
    {
      "epoch": 704.48,
      "learning_rate": 0.029579425259354843,
      "loss": 0.5881,
      "step": 436780
    },
    {
      "epoch": 704.52,
      "learning_rate": 0.029576199456129038,
      "loss": 0.5939,
      "step": 436800
    },
    {
      "epoch": 704.55,
      "learning_rate": 0.02957297365290322,
      "loss": 0.6046,
      "step": 436820
    },
    {
      "epoch": 704.58,
      "learning_rate": 0.029569747849677416,
      "loss": 0.5965,
      "step": 436840
    },
    {
      "epoch": 704.61,
      "learning_rate": 0.029566522046451604,
      "loss": 0.5943,
      "step": 436860
    },
    {
      "epoch": 704.65,
      "learning_rate": 0.029563296243225803,
      "loss": 0.6037,
      "step": 436880
    },
    {
      "epoch": 704.68,
      "learning_rate": 0.02956007044,
      "loss": 0.6118,
      "step": 436900
    },
    {
      "epoch": 704.71,
      "learning_rate": 0.029556844636774188,
      "loss": 0.591,
      "step": 436920
    },
    {
      "epoch": 704.74,
      "learning_rate": 0.029553618833548387,
      "loss": 0.5927,
      "step": 436940
    },
    {
      "epoch": 704.77,
      "learning_rate": 0.029550393030322575,
      "loss": 0.6126,
      "step": 436960
    },
    {
      "epoch": 704.81,
      "learning_rate": 0.02954716722709677,
      "loss": 0.5939,
      "step": 436980
    },
    {
      "epoch": 704.84,
      "learning_rate": 0.02954394142387097,
      "loss": 0.6014,
      "step": 437000
    },
    {
      "epoch": 704.87,
      "learning_rate": 0.02954071562064516,
      "loss": 0.5879,
      "step": 437020
    },
    {
      "epoch": 704.9,
      "learning_rate": 0.029537489817419355,
      "loss": 0.588,
      "step": 437040
    },
    {
      "epoch": 704.94,
      "learning_rate": 0.029534264014193554,
      "loss": 0.6068,
      "step": 437060
    },
    {
      "epoch": 704.97,
      "learning_rate": 0.029531038210967742,
      "loss": 0.5974,
      "step": 437080
    },
    {
      "epoch": 705.0,
      "learning_rate": 0.029527812407741938,
      "loss": 0.6114,
      "step": 437100
    },
    {
      "epoch": 705.0,
      "eval_accuracy": {
        "accuracy": 0.7716025290765748
      },
      "eval_loss": 0.9637638926506042,
      "eval_runtime": 2.9748,
      "eval_samples_per_second": 4306.525,
      "eval_steps_per_second": 67.568,
      "step": 437100
    },
    {
      "epoch": 705.03,
      "learning_rate": 0.029524586604516137,
      "loss": 0.6011,
      "step": 437120
    },
    {
      "epoch": 705.06,
      "learning_rate": 0.029521360801290322,
      "loss": 0.6032,
      "step": 437140
    },
    {
      "epoch": 705.1,
      "learning_rate": 0.02951813499806451,
      "loss": 0.6112,
      "step": 437160
    },
    {
      "epoch": 705.13,
      "learning_rate": 0.029514909194838707,
      "loss": 0.585,
      "step": 437180
    },
    {
      "epoch": 705.16,
      "learning_rate": 0.0295116833916129,
      "loss": 0.5749,
      "step": 437200
    },
    {
      "epoch": 705.19,
      "learning_rate": 0.029508457588387094,
      "loss": 0.5908,
      "step": 437220
    },
    {
      "epoch": 705.23,
      "learning_rate": 0.02950523178516129,
      "loss": 0.5874,
      "step": 437240
    },
    {
      "epoch": 705.26,
      "learning_rate": 0.029502005981935482,
      "loss": 0.5989,
      "step": 437260
    },
    {
      "epoch": 705.29,
      "learning_rate": 0.029498780178709678,
      "loss": 0.5941,
      "step": 437280
    },
    {
      "epoch": 705.32,
      "learning_rate": 0.029495554375483873,
      "loss": 0.5978,
      "step": 437300
    },
    {
      "epoch": 705.35,
      "learning_rate": 0.029492328572258066,
      "loss": 0.5982,
      "step": 437320
    },
    {
      "epoch": 705.39,
      "learning_rate": 0.02948910276903226,
      "loss": 0.5933,
      "step": 437340
    },
    {
      "epoch": 705.42,
      "learning_rate": 0.029485876965806453,
      "loss": 0.5947,
      "step": 437360
    },
    {
      "epoch": 705.45,
      "learning_rate": 0.02948265116258065,
      "loss": 0.5979,
      "step": 437380
    },
    {
      "epoch": 705.48,
      "learning_rate": 0.029479425359354845,
      "loss": 0.5937,
      "step": 437400
    },
    {
      "epoch": 705.52,
      "learning_rate": 0.029476199556129037,
      "loss": 0.5933,
      "step": 437420
    },
    {
      "epoch": 705.55,
      "learning_rate": 0.029472973752903232,
      "loss": 0.6041,
      "step": 437440
    },
    {
      "epoch": 705.58,
      "learning_rate": 0.02946974794967741,
      "loss": 0.5888,
      "step": 437460
    },
    {
      "epoch": 705.61,
      "learning_rate": 0.02946652214645161,
      "loss": 0.5818,
      "step": 437480
    },
    {
      "epoch": 705.65,
      "learning_rate": 0.0294632963432258,
      "loss": 0.5974,
      "step": 437500
    },
    {
      "epoch": 705.68,
      "learning_rate": 0.029460070539999994,
      "loss": 0.6248,
      "step": 437520
    },
    {
      "epoch": 705.71,
      "learning_rate": 0.029456844736774193,
      "loss": 0.6105,
      "step": 437540
    },
    {
      "epoch": 705.74,
      "learning_rate": 0.029453618933548382,
      "loss": 0.6182,
      "step": 437560
    },
    {
      "epoch": 705.77,
      "learning_rate": 0.029450393130322577,
      "loss": 0.6064,
      "step": 437580
    },
    {
      "epoch": 705.81,
      "learning_rate": 0.029447167327096777,
      "loss": 0.5995,
      "step": 437600
    },
    {
      "epoch": 705.84,
      "learning_rate": 0.029443941523870965,
      "loss": 0.5938,
      "step": 437620
    },
    {
      "epoch": 705.87,
      "learning_rate": 0.02944071572064516,
      "loss": 0.6153,
      "step": 437640
    },
    {
      "epoch": 705.9,
      "learning_rate": 0.02943748991741936,
      "loss": 0.6073,
      "step": 437660
    },
    {
      "epoch": 705.94,
      "learning_rate": 0.02943426411419355,
      "loss": 0.6036,
      "step": 437680
    },
    {
      "epoch": 705.97,
      "learning_rate": 0.029431038310967744,
      "loss": 0.6184,
      "step": 437700
    },
    {
      "epoch": 706.0,
      "learning_rate": 0.029427812507741943,
      "loss": 0.6079,
      "step": 437720
    },
    {
      "epoch": 706.0,
      "eval_accuracy": {
        "accuracy": 0.7747248458356101
      },
      "eval_loss": 0.9614955186843872,
      "eval_runtime": 3.7811,
      "eval_samples_per_second": 3388.131,
      "eval_steps_per_second": 53.159,
      "step": 437720
    },
    {
      "epoch": 706.03,
      "learning_rate": 0.029424586704516132,
      "loss": 0.6017,
      "step": 437740
    },
    {
      "epoch": 706.06,
      "learning_rate": 0.029421360901290317,
      "loss": 0.6066,
      "step": 437760
    },
    {
      "epoch": 706.1,
      "learning_rate": 0.029418135098064513,
      "loss": 0.599,
      "step": 437780
    },
    {
      "epoch": 706.13,
      "learning_rate": 0.029414909294838705,
      "loss": 0.5946,
      "step": 437800
    },
    {
      "epoch": 706.16,
      "learning_rate": 0.0294116834916129,
      "loss": 0.5992,
      "step": 437820
    },
    {
      "epoch": 706.19,
      "learning_rate": 0.029408457688387096,
      "loss": 0.6047,
      "step": 437840
    },
    {
      "epoch": 706.23,
      "learning_rate": 0.02940523188516129,
      "loss": 0.5949,
      "step": 437860
    },
    {
      "epoch": 706.26,
      "learning_rate": 0.029402006081935484,
      "loss": 0.5849,
      "step": 437880
    },
    {
      "epoch": 706.29,
      "learning_rate": 0.029398780278709676,
      "loss": 0.5868,
      "step": 437900
    },
    {
      "epoch": 706.32,
      "learning_rate": 0.029395554475483872,
      "loss": 0.5913,
      "step": 437920
    },
    {
      "epoch": 706.35,
      "learning_rate": 0.029392328672258067,
      "loss": 0.5934,
      "step": 437940
    },
    {
      "epoch": 706.39,
      "learning_rate": 0.02938910286903226,
      "loss": 0.6101,
      "step": 437960
    },
    {
      "epoch": 706.42,
      "learning_rate": 0.029385877065806455,
      "loss": 0.5864,
      "step": 437980
    },
    {
      "epoch": 706.45,
      "learning_rate": 0.029382651262580647,
      "loss": 0.5923,
      "step": 438000
    },
    {
      "epoch": 706.48,
      "learning_rate": 0.029379425459354843,
      "loss": 0.5927,
      "step": 438020
    },
    {
      "epoch": 706.52,
      "learning_rate": 0.02937619965612904,
      "loss": 0.5989,
      "step": 438040
    },
    {
      "epoch": 706.55,
      "learning_rate": 0.02937297385290323,
      "loss": 0.6021,
      "step": 438060
    },
    {
      "epoch": 706.58,
      "learning_rate": 0.029369748049677416,
      "loss": 0.6066,
      "step": 438080
    },
    {
      "epoch": 706.61,
      "learning_rate": 0.029366522246451605,
      "loss": 0.61,
      "step": 438100
    },
    {
      "epoch": 706.65,
      "learning_rate": 0.0293632964432258,
      "loss": 0.5886,
      "step": 438120
    },
    {
      "epoch": 706.68,
      "learning_rate": 0.02936007064,
      "loss": 0.601,
      "step": 438140
    },
    {
      "epoch": 706.71,
      "learning_rate": 0.029356844836774188,
      "loss": 0.6068,
      "step": 438160
    },
    {
      "epoch": 706.74,
      "learning_rate": 0.029353619033548384,
      "loss": 0.5979,
      "step": 438180
    },
    {
      "epoch": 706.77,
      "learning_rate": 0.029350393230322583,
      "loss": 0.6078,
      "step": 438200
    },
    {
      "epoch": 706.81,
      "learning_rate": 0.02934716742709677,
      "loss": 0.5945,
      "step": 438220
    },
    {
      "epoch": 706.84,
      "learning_rate": 0.029343941623870967,
      "loss": 0.5959,
      "step": 438240
    },
    {
      "epoch": 706.87,
      "learning_rate": 0.029340715820645166,
      "loss": 0.5904,
      "step": 438260
    },
    {
      "epoch": 706.9,
      "learning_rate": 0.029337490017419355,
      "loss": 0.5838,
      "step": 438280
    },
    {
      "epoch": 706.94,
      "learning_rate": 0.02933426421419355,
      "loss": 0.603,
      "step": 438300
    },
    {
      "epoch": 706.97,
      "learning_rate": 0.02933103841096775,
      "loss": 0.6022,
      "step": 438320
    },
    {
      "epoch": 707.0,
      "learning_rate": 0.02932781260774194,
      "loss": 0.6034,
      "step": 438340
    },
    {
      "epoch": 707.0,
      "eval_accuracy": {
        "accuracy": 0.7765982358910312
      },
      "eval_loss": 0.957459032535553,
      "eval_runtime": 3.0664,
      "eval_samples_per_second": 4177.878,
      "eval_steps_per_second": 65.549,
      "step": 438340
    },
    {
      "epoch": 707.03,
      "learning_rate": 0.029324586804516134,
      "loss": 0.6033,
      "step": 438360
    },
    {
      "epoch": 707.06,
      "learning_rate": 0.029321361001290316,
      "loss": 0.5826,
      "step": 438380
    },
    {
      "epoch": 707.1,
      "learning_rate": 0.02931813519806451,
      "loss": 0.5915,
      "step": 438400
    },
    {
      "epoch": 707.13,
      "learning_rate": 0.029314909394838707,
      "loss": 0.5937,
      "step": 438420
    },
    {
      "epoch": 707.16,
      "learning_rate": 0.0293116835916129,
      "loss": 0.5987,
      "step": 438440
    },
    {
      "epoch": 707.19,
      "learning_rate": 0.029308457788387095,
      "loss": 0.5906,
      "step": 438460
    },
    {
      "epoch": 707.23,
      "learning_rate": 0.02930523198516129,
      "loss": 0.5983,
      "step": 438480
    },
    {
      "epoch": 707.26,
      "learning_rate": 0.029302006181935483,
      "loss": 0.5933,
      "step": 438500
    },
    {
      "epoch": 707.29,
      "learning_rate": 0.029298780378709678,
      "loss": 0.5878,
      "step": 438520
    },
    {
      "epoch": 707.32,
      "learning_rate": 0.02929555457548387,
      "loss": 0.5892,
      "step": 438540
    },
    {
      "epoch": 707.35,
      "learning_rate": 0.029292328772258066,
      "loss": 0.6015,
      "step": 438560
    },
    {
      "epoch": 707.39,
      "learning_rate": 0.02928910296903226,
      "loss": 0.6021,
      "step": 438580
    },
    {
      "epoch": 707.42,
      "learning_rate": 0.029285877165806454,
      "loss": 0.6076,
      "step": 438600
    },
    {
      "epoch": 707.45,
      "learning_rate": 0.02928265136258065,
      "loss": 0.5889,
      "step": 438620
    },
    {
      "epoch": 707.48,
      "learning_rate": 0.029279425559354838,
      "loss": 0.5897,
      "step": 438640
    },
    {
      "epoch": 707.52,
      "learning_rate": 0.029276199756129037,
      "loss": 0.5892,
      "step": 438660
    },
    {
      "epoch": 707.55,
      "learning_rate": 0.029272973952903233,
      "loss": 0.5887,
      "step": 438680
    },
    {
      "epoch": 707.58,
      "learning_rate": 0.02926974814967741,
      "loss": 0.6046,
      "step": 438700
    },
    {
      "epoch": 707.61,
      "learning_rate": 0.029266522346451607,
      "loss": 0.6091,
      "step": 438720
    },
    {
      "epoch": 707.65,
      "learning_rate": 0.029263296543225806,
      "loss": 0.5971,
      "step": 438740
    },
    {
      "epoch": 707.68,
      "learning_rate": 0.029260070739999994,
      "loss": 0.608,
      "step": 438760
    },
    {
      "epoch": 707.71,
      "learning_rate": 0.02925684493677419,
      "loss": 0.6046,
      "step": 438780
    },
    {
      "epoch": 707.74,
      "learning_rate": 0.02925361913354839,
      "loss": 0.5975,
      "step": 438800
    },
    {
      "epoch": 707.77,
      "learning_rate": 0.029250393330322578,
      "loss": 0.5914,
      "step": 438820
    },
    {
      "epoch": 707.81,
      "learning_rate": 0.029247167527096773,
      "loss": 0.5917,
      "step": 438840
    },
    {
      "epoch": 707.84,
      "learning_rate": 0.029243941723870973,
      "loss": 0.6019,
      "step": 438860
    },
    {
      "epoch": 707.87,
      "learning_rate": 0.02924071592064516,
      "loss": 0.6052,
      "step": 438880
    },
    {
      "epoch": 707.9,
      "learning_rate": 0.029237490117419357,
      "loss": 0.5986,
      "step": 438900
    },
    {
      "epoch": 707.94,
      "learning_rate": 0.029234264314193556,
      "loss": 0.6109,
      "step": 438920
    },
    {
      "epoch": 707.97,
      "learning_rate": 0.029231038510967745,
      "loss": 0.5991,
      "step": 438940
    },
    {
      "epoch": 708.0,
      "learning_rate": 0.029227973997903223,
      "loss": 0.6017,
      "step": 438960
    },
    {
      "epoch": 708.0,
      "eval_accuracy": {
        "accuracy": 0.7796424947310905
      },
      "eval_loss": 0.9428736567497253,
      "eval_runtime": 2.9101,
      "eval_samples_per_second": 4402.242,
      "eval_steps_per_second": 69.07,
      "step": 438960
    },
    {
      "epoch": 708.03,
      "learning_rate": 0.029224748194677422,
      "loss": 0.5928,
      "step": 438980
    },
    {
      "epoch": 708.06,
      "learning_rate": 0.02922152239145161,
      "loss": 0.5934,
      "step": 439000
    },
    {
      "epoch": 708.1,
      "learning_rate": 0.029218296588225806,
      "loss": 0.5923,
      "step": 439020
    },
    {
      "epoch": 708.13,
      "learning_rate": 0.029215070785000005,
      "loss": 0.6018,
      "step": 439040
    },
    {
      "epoch": 708.16,
      "learning_rate": 0.029211844981774194,
      "loss": 0.5892,
      "step": 439060
    },
    {
      "epoch": 708.19,
      "learning_rate": 0.02920861917854839,
      "loss": 0.5796,
      "step": 439080
    },
    {
      "epoch": 708.23,
      "learning_rate": 0.02920539337532259,
      "loss": 0.5853,
      "step": 439100
    },
    {
      "epoch": 708.26,
      "learning_rate": 0.029202167572096777,
      "loss": 0.6049,
      "step": 439120
    },
    {
      "epoch": 708.29,
      "learning_rate": 0.029198941768870963,
      "loss": 0.5942,
      "step": 439140
    },
    {
      "epoch": 708.32,
      "learning_rate": 0.029195715965645158,
      "loss": 0.578,
      "step": 439160
    },
    {
      "epoch": 708.35,
      "learning_rate": 0.02919249016241935,
      "loss": 0.5986,
      "step": 439180
    },
    {
      "epoch": 708.39,
      "learning_rate": 0.029189264359193546,
      "loss": 0.5923,
      "step": 439200
    },
    {
      "epoch": 708.42,
      "learning_rate": 0.029186038555967738,
      "loss": 0.5881,
      "step": 439220
    },
    {
      "epoch": 708.45,
      "learning_rate": 0.029182812752741934,
      "loss": 0.596,
      "step": 439240
    },
    {
      "epoch": 708.48,
      "learning_rate": 0.02917958694951613,
      "loss": 0.5887,
      "step": 439260
    },
    {
      "epoch": 708.52,
      "learning_rate": 0.02917636114629032,
      "loss": 0.5933,
      "step": 439280
    },
    {
      "epoch": 708.55,
      "learning_rate": 0.029173135343064517,
      "loss": 0.6095,
      "step": 439300
    },
    {
      "epoch": 708.58,
      "learning_rate": 0.02916990953983871,
      "loss": 0.6031,
      "step": 439320
    },
    {
      "epoch": 708.61,
      "learning_rate": 0.029166683736612905,
      "loss": 0.5993,
      "step": 439340
    },
    {
      "epoch": 708.65,
      "learning_rate": 0.0291634579333871,
      "loss": 0.6026,
      "step": 439360
    },
    {
      "epoch": 708.68,
      "learning_rate": 0.029160232130161293,
      "loss": 0.5979,
      "step": 439380
    },
    {
      "epoch": 708.71,
      "learning_rate": 0.02915700632693549,
      "loss": 0.591,
      "step": 439400
    },
    {
      "epoch": 708.74,
      "learning_rate": 0.029153780523709677,
      "loss": 0.5987,
      "step": 439420
    },
    {
      "epoch": 708.77,
      "learning_rate": 0.029150554720483876,
      "loss": 0.61,
      "step": 439440
    },
    {
      "epoch": 708.81,
      "learning_rate": 0.02914732891725806,
      "loss": 0.5997,
      "step": 439460
    },
    {
      "epoch": 708.84,
      "learning_rate": 0.02914410311403225,
      "loss": 0.5971,
      "step": 439480
    },
    {
      "epoch": 708.87,
      "learning_rate": 0.029140877310806446,
      "loss": 0.5948,
      "step": 439500
    },
    {
      "epoch": 708.9,
      "learning_rate": 0.029137651507580645,
      "loss": 0.6116,
      "step": 439520
    },
    {
      "epoch": 708.94,
      "learning_rate": 0.029134425704354833,
      "loss": 0.5831,
      "step": 439540
    },
    {
      "epoch": 708.97,
      "learning_rate": 0.02913119990112903,
      "loss": 0.5924,
      "step": 439560
    },
    {
      "epoch": 709.0,
      "learning_rate": 0.029127974097903228,
      "loss": 0.6125,
      "step": 439580
    },
    {
      "epoch": 709.0,
      "eval_accuracy": {
        "accuracy": 0.7730075716181407
      },
      "eval_loss": 0.9904548525810242,
      "eval_runtime": 3.0517,
      "eval_samples_per_second": 4197.925,
      "eval_steps_per_second": 65.864,
      "step": 439580
    },
    {
      "epoch": 709.03,
      "learning_rate": 0.029124748294677417,
      "loss": 0.6233,
      "step": 439600
    },
    {
      "epoch": 709.06,
      "learning_rate": 0.029121522491451612,
      "loss": 0.5885,
      "step": 439620
    },
    {
      "epoch": 709.1,
      "learning_rate": 0.02911829668822581,
      "loss": 0.5763,
      "step": 439640
    },
    {
      "epoch": 709.13,
      "learning_rate": 0.029115070885,
      "loss": 0.5821,
      "step": 439660
    },
    {
      "epoch": 709.16,
      "learning_rate": 0.029111845081774196,
      "loss": 0.5884,
      "step": 439680
    },
    {
      "epoch": 709.19,
      "learning_rate": 0.029108619278548395,
      "loss": 0.5923,
      "step": 439700
    },
    {
      "epoch": 709.23,
      "learning_rate": 0.029105393475322584,
      "loss": 0.5995,
      "step": 439720
    },
    {
      "epoch": 709.26,
      "learning_rate": 0.02910216767209678,
      "loss": 0.5927,
      "step": 439740
    },
    {
      "epoch": 709.29,
      "learning_rate": 0.02909894186887096,
      "loss": 0.5885,
      "step": 439760
    },
    {
      "epoch": 709.32,
      "learning_rate": 0.029095716065645157,
      "loss": 0.6,
      "step": 439780
    },
    {
      "epoch": 709.35,
      "learning_rate": 0.029092490262419352,
      "loss": 0.5946,
      "step": 439800
    },
    {
      "epoch": 709.39,
      "learning_rate": 0.029089264459193544,
      "loss": 0.6004,
      "step": 439820
    },
    {
      "epoch": 709.42,
      "learning_rate": 0.02908603865596774,
      "loss": 0.5891,
      "step": 439840
    },
    {
      "epoch": 709.45,
      "learning_rate": 0.029082812852741932,
      "loss": 0.5829,
      "step": 439860
    },
    {
      "epoch": 709.48,
      "learning_rate": 0.029079587049516128,
      "loss": 0.6088,
      "step": 439880
    },
    {
      "epoch": 709.52,
      "learning_rate": 0.029076361246290323,
      "loss": 0.6066,
      "step": 439900
    },
    {
      "epoch": 709.55,
      "learning_rate": 0.029073135443064516,
      "loss": 0.6004,
      "step": 439920
    },
    {
      "epoch": 709.58,
      "learning_rate": 0.02906990963983871,
      "loss": 0.5939,
      "step": 439940
    },
    {
      "epoch": 709.61,
      "learning_rate": 0.0290666838366129,
      "loss": 0.5936,
      "step": 439960
    },
    {
      "epoch": 709.65,
      "learning_rate": 0.0290634580333871,
      "loss": 0.5909,
      "step": 439980
    },
    {
      "epoch": 709.68,
      "learning_rate": 0.029060232230161295,
      "loss": 0.5906,
      "step": 440000
    },
    {
      "epoch": 709.71,
      "learning_rate": 0.029057006426935483,
      "loss": 0.5797,
      "step": 440020
    },
    {
      "epoch": 709.74,
      "learning_rate": 0.029053780623709682,
      "loss": 0.61,
      "step": 440040
    },
    {
      "epoch": 709.77,
      "learning_rate": 0.029050554820483878,
      "loss": 0.589,
      "step": 440060
    },
    {
      "epoch": 709.81,
      "learning_rate": 0.029047329017258056,
      "loss": 0.5935,
      "step": 440080
    },
    {
      "epoch": 709.84,
      "learning_rate": 0.029044103214032252,
      "loss": 0.6117,
      "step": 440100
    },
    {
      "epoch": 709.87,
      "learning_rate": 0.02904087741080645,
      "loss": 0.6026,
      "step": 440120
    },
    {
      "epoch": 709.9,
      "learning_rate": 0.02903765160758064,
      "loss": 0.596,
      "step": 440140
    },
    {
      "epoch": 709.94,
      "learning_rate": 0.029034425804354835,
      "loss": 0.5982,
      "step": 440160
    },
    {
      "epoch": 709.97,
      "learning_rate": 0.029031200001129034,
      "loss": 0.6123,
      "step": 440180
    },
    {
      "epoch": 710.0,
      "learning_rate": 0.029027974197903223,
      "loss": 0.6039,
      "step": 440200
    },
    {
      "epoch": 710.0,
      "eval_accuracy": {
        "accuracy": 0.776676293810007
      },
      "eval_loss": 0.9603962898254395,
      "eval_runtime": 2.8979,
      "eval_samples_per_second": 4420.833,
      "eval_steps_per_second": 69.361,
      "step": 440200
    },
    {
      "epoch": 710.03,
      "learning_rate": 0.02902474839467742,
      "loss": 0.5946,
      "step": 440220
    },
    {
      "epoch": 710.06,
      "learning_rate": 0.029021522591451618,
      "loss": 0.5961,
      "step": 440240
    },
    {
      "epoch": 710.1,
      "learning_rate": 0.029018296788225807,
      "loss": 0.5971,
      "step": 440260
    },
    {
      "epoch": 710.13,
      "learning_rate": 0.029015070985000002,
      "loss": 0.5795,
      "step": 440280
    },
    {
      "epoch": 710.16,
      "learning_rate": 0.0290118451817742,
      "loss": 0.5938,
      "step": 440300
    },
    {
      "epoch": 710.19,
      "learning_rate": 0.02900861937854839,
      "loss": 0.6044,
      "step": 440320
    },
    {
      "epoch": 710.23,
      "learning_rate": 0.029005393575322586,
      "loss": 0.5818,
      "step": 440340
    },
    {
      "epoch": 710.26,
      "learning_rate": 0.029002167772096778,
      "loss": 0.5813,
      "step": 440360
    },
    {
      "epoch": 710.29,
      "learning_rate": 0.028998941968870973,
      "loss": 0.6008,
      "step": 440380
    },
    {
      "epoch": 710.32,
      "learning_rate": 0.028995716165645155,
      "loss": 0.602,
      "step": 440400
    },
    {
      "epoch": 710.35,
      "learning_rate": 0.02899249036241935,
      "loss": 0.5895,
      "step": 440420
    },
    {
      "epoch": 710.39,
      "learning_rate": 0.028989264559193546,
      "loss": 0.6092,
      "step": 440440
    },
    {
      "epoch": 710.42,
      "learning_rate": 0.02898603875596774,
      "loss": 0.5945,
      "step": 440460
    },
    {
      "epoch": 710.45,
      "learning_rate": 0.028982812952741934,
      "loss": 0.5909,
      "step": 440480
    },
    {
      "epoch": 710.48,
      "learning_rate": 0.028979587149516123,
      "loss": 0.6014,
      "step": 440500
    },
    {
      "epoch": 710.52,
      "learning_rate": 0.028976361346290322,
      "loss": 0.6003,
      "step": 440520
    },
    {
      "epoch": 710.55,
      "learning_rate": 0.028973135543064518,
      "loss": 0.6012,
      "step": 440540
    },
    {
      "epoch": 710.58,
      "learning_rate": 0.028969909739838706,
      "loss": 0.5975,
      "step": 440560
    },
    {
      "epoch": 710.61,
      "learning_rate": 0.028966683936612905,
      "loss": 0.5979,
      "step": 440580
    },
    {
      "epoch": 710.65,
      "learning_rate": 0.028963458133387094,
      "loss": 0.5913,
      "step": 440600
    },
    {
      "epoch": 710.68,
      "learning_rate": 0.02896023233016129,
      "loss": 0.5982,
      "step": 440620
    },
    {
      "epoch": 710.71,
      "learning_rate": 0.02895700652693549,
      "loss": 0.6133,
      "step": 440640
    },
    {
      "epoch": 710.74,
      "learning_rate": 0.028953780723709677,
      "loss": 0.6092,
      "step": 440660
    },
    {
      "epoch": 710.77,
      "learning_rate": 0.028950554920483873,
      "loss": 0.5867,
      "step": 440680
    },
    {
      "epoch": 710.81,
      "learning_rate": 0.028947329117258058,
      "loss": 0.611,
      "step": 440700
    },
    {
      "epoch": 710.84,
      "learning_rate": 0.028944103314032257,
      "loss": 0.6098,
      "step": 440720
    },
    {
      "epoch": 710.87,
      "learning_rate": 0.028940877510806446,
      "loss": 0.6085,
      "step": 440740
    },
    {
      "epoch": 710.9,
      "learning_rate": 0.02893765170758064,
      "loss": 0.5865,
      "step": 440760
    },
    {
      "epoch": 710.94,
      "learning_rate": 0.02893442590435484,
      "loss": 0.5863,
      "step": 440780
    },
    {
      "epoch": 710.97,
      "learning_rate": 0.02893120010112903,
      "loss": 0.5854,
      "step": 440800
    },
    {
      "epoch": 711.0,
      "learning_rate": 0.028927974297903225,
      "loss": 0.5878,
      "step": 440820
    },
    {
      "epoch": 711.0,
      "eval_accuracy": {
        "accuracy": 0.7754273671063929
      },
      "eval_loss": 0.9756277203559875,
      "eval_runtime": 4.6218,
      "eval_samples_per_second": 2771.843,
      "eval_steps_per_second": 43.489,
      "step": 440820
    },
    {
      "epoch": 711.03,
      "learning_rate": 0.028924748494677424,
      "loss": 0.5932,
      "step": 440840
    },
    {
      "epoch": 711.06,
      "learning_rate": 0.028921522691451613,
      "loss": 0.5914,
      "step": 440860
    },
    {
      "epoch": 711.1,
      "learning_rate": 0.02891829688822581,
      "loss": 0.5939,
      "step": 440880
    },
    {
      "epoch": 711.13,
      "learning_rate": 0.028915071085,
      "loss": 0.5944,
      "step": 440900
    },
    {
      "epoch": 711.16,
      "learning_rate": 0.028911845281774196,
      "loss": 0.6,
      "step": 440920
    },
    {
      "epoch": 711.19,
      "learning_rate": 0.028908619478548392,
      "loss": 0.5983,
      "step": 440940
    },
    {
      "epoch": 711.23,
      "learning_rate": 0.028905393675322584,
      "loss": 0.5843,
      "step": 440960
    },
    {
      "epoch": 711.26,
      "learning_rate": 0.02890216787209678,
      "loss": 0.5899,
      "step": 440980
    },
    {
      "epoch": 711.29,
      "learning_rate": 0.028898942068870972,
      "loss": 0.6006,
      "step": 441000
    },
    {
      "epoch": 711.32,
      "learning_rate": 0.028895716265645157,
      "loss": 0.5968,
      "step": 441020
    },
    {
      "epoch": 711.35,
      "learning_rate": 0.028892490462419346,
      "loss": 0.5871,
      "step": 441040
    },
    {
      "epoch": 711.39,
      "learning_rate": 0.028889264659193545,
      "loss": 0.5991,
      "step": 441060
    },
    {
      "epoch": 711.42,
      "learning_rate": 0.02888603885596774,
      "loss": 0.5921,
      "step": 441080
    },
    {
      "epoch": 711.45,
      "learning_rate": 0.02888281305274193,
      "loss": 0.5982,
      "step": 441100
    },
    {
      "epoch": 711.48,
      "learning_rate": 0.028879587249516128,
      "loss": 0.5937,
      "step": 441120
    },
    {
      "epoch": 711.52,
      "learning_rate": 0.028876361446290317,
      "loss": 0.5914,
      "step": 441140
    },
    {
      "epoch": 711.55,
      "learning_rate": 0.028873135643064513,
      "loss": 0.5942,
      "step": 441160
    },
    {
      "epoch": 711.58,
      "learning_rate": 0.02886990983983871,
      "loss": 0.588,
      "step": 441180
    },
    {
      "epoch": 711.61,
      "learning_rate": 0.0288666840366129,
      "loss": 0.6013,
      "step": 441200
    },
    {
      "epoch": 711.65,
      "learning_rate": 0.028863458233387096,
      "loss": 0.5912,
      "step": 441220
    },
    {
      "epoch": 711.68,
      "learning_rate": 0.028860232430161295,
      "loss": 0.6048,
      "step": 441240
    },
    {
      "epoch": 711.71,
      "learning_rate": 0.028857006626935484,
      "loss": 0.5898,
      "step": 441260
    },
    {
      "epoch": 711.74,
      "learning_rate": 0.02885378082370968,
      "loss": 0.5887,
      "step": 441280
    },
    {
      "epoch": 711.77,
      "learning_rate": 0.02885055502048388,
      "loss": 0.5893,
      "step": 441300
    },
    {
      "epoch": 711.81,
      "learning_rate": 0.028847329217258064,
      "loss": 0.5976,
      "step": 441320
    },
    {
      "epoch": 711.84,
      "learning_rate": 0.028844103414032252,
      "loss": 0.6154,
      "step": 441340
    },
    {
      "epoch": 711.87,
      "learning_rate": 0.028840877610806448,
      "loss": 0.6038,
      "step": 441360
    },
    {
      "epoch": 711.9,
      "learning_rate": 0.028837651807580647,
      "loss": 0.5944,
      "step": 441380
    },
    {
      "epoch": 711.94,
      "learning_rate": 0.028834426004354836,
      "loss": 0.5989,
      "step": 441400
    },
    {
      "epoch": 711.97,
      "learning_rate": 0.02883120020112903,
      "loss": 0.5914,
      "step": 441420
    },
    {
      "epoch": 712.0,
      "learning_rate": 0.028828135688064516,
      "loss": 0.6047,
      "step": 441440
    },
    {
      "epoch": 712.0,
      "eval_accuracy": {
        "accuracy": 0.7748809616735618
      },
      "eval_loss": 0.9550535678863525,
      "eval_runtime": 2.9463,
      "eval_samples_per_second": 4348.125,
      "eval_steps_per_second": 68.221,
      "step": 441440
    },
    {
      "epoch": 712.03,
      "learning_rate": 0.0288249098848387,
      "loss": 0.5966,
      "step": 441460
    },
    {
      "epoch": 712.06,
      "learning_rate": 0.028821684081612897,
      "loss": 0.5837,
      "step": 441480
    },
    {
      "epoch": 712.1,
      "learning_rate": 0.028818458278387096,
      "loss": 0.5907,
      "step": 441500
    },
    {
      "epoch": 712.13,
      "learning_rate": 0.028815232475161285,
      "loss": 0.5794,
      "step": 441520
    },
    {
      "epoch": 712.16,
      "learning_rate": 0.02881200667193548,
      "loss": 0.5956,
      "step": 441540
    },
    {
      "epoch": 712.19,
      "learning_rate": 0.02880878086870968,
      "loss": 0.5906,
      "step": 441560
    },
    {
      "epoch": 712.23,
      "learning_rate": 0.02880555506548387,
      "loss": 0.5808,
      "step": 441580
    },
    {
      "epoch": 712.26,
      "learning_rate": 0.028802329262258064,
      "loss": 0.5807,
      "step": 441600
    },
    {
      "epoch": 712.29,
      "learning_rate": 0.028799103459032263,
      "loss": 0.5941,
      "step": 441620
    },
    {
      "epoch": 712.32,
      "learning_rate": 0.028795877655806452,
      "loss": 0.5898,
      "step": 441640
    },
    {
      "epoch": 712.35,
      "learning_rate": 0.028792651852580647,
      "loss": 0.595,
      "step": 441660
    },
    {
      "epoch": 712.39,
      "learning_rate": 0.02878942604935484,
      "loss": 0.6006,
      "step": 441680
    },
    {
      "epoch": 712.42,
      "learning_rate": 0.028786200246129035,
      "loss": 0.5947,
      "step": 441700
    },
    {
      "epoch": 712.45,
      "learning_rate": 0.02878297444290323,
      "loss": 0.5924,
      "step": 441720
    },
    {
      "epoch": 712.48,
      "learning_rate": 0.028779748639677423,
      "loss": 0.5962,
      "step": 441740
    },
    {
      "epoch": 712.52,
      "learning_rate": 0.02877652283645162,
      "loss": 0.5932,
      "step": 441760
    },
    {
      "epoch": 712.55,
      "learning_rate": 0.0287732970332258,
      "loss": 0.6011,
      "step": 441780
    },
    {
      "epoch": 712.58,
      "learning_rate": 0.028770071229999996,
      "loss": 0.5938,
      "step": 441800
    },
    {
      "epoch": 712.61,
      "learning_rate": 0.02876684542677419,
      "loss": 0.5799,
      "step": 441820
    },
    {
      "epoch": 712.65,
      "learning_rate": 0.028763619623548384,
      "loss": 0.5905,
      "step": 441840
    },
    {
      "epoch": 712.68,
      "learning_rate": 0.02876039382032258,
      "loss": 0.5869,
      "step": 441860
    },
    {
      "epoch": 712.71,
      "learning_rate": 0.028757168017096768,
      "loss": 0.5885,
      "step": 441880
    },
    {
      "epoch": 712.74,
      "learning_rate": 0.028753942213870967,
      "loss": 0.5983,
      "step": 441900
    },
    {
      "epoch": 712.77,
      "learning_rate": 0.028750716410645163,
      "loss": 0.5875,
      "step": 441920
    },
    {
      "epoch": 712.81,
      "learning_rate": 0.02874749060741935,
      "loss": 0.5962,
      "step": 441940
    },
    {
      "epoch": 712.84,
      "learning_rate": 0.02874426480419355,
      "loss": 0.5948,
      "step": 441960
    },
    {
      "epoch": 712.87,
      "learning_rate": 0.02874103900096774,
      "loss": 0.6005,
      "step": 441980
    },
    {
      "epoch": 712.9,
      "learning_rate": 0.028737813197741935,
      "loss": 0.6025,
      "step": 442000
    },
    {
      "epoch": 712.94,
      "learning_rate": 0.028734587394516134,
      "loss": 0.603,
      "step": 442020
    },
    {
      "epoch": 712.97,
      "learning_rate": 0.028731361591290323,
      "loss": 0.6094,
      "step": 442040
    },
    {
      "epoch": 713.0,
      "learning_rate": 0.02872813578806452,
      "loss": 0.6059,
      "step": 442060
    },
    {
      "epoch": 713.0,
      "eval_accuracy": {
        "accuracy": 0.7732417453750683
      },
      "eval_loss": 0.9638814330101013,
      "eval_runtime": 2.9632,
      "eval_samples_per_second": 4323.394,
      "eval_steps_per_second": 67.833,
      "step": 442060
    },
    {
      "epoch": 713.03,
      "learning_rate": 0.028724909984838704,
      "loss": 0.6078,
      "step": 442080
    },
    {
      "epoch": 713.06,
      "learning_rate": 0.028721684181612903,
      "loss": 0.5811,
      "step": 442100
    },
    {
      "epoch": 713.1,
      "learning_rate": 0.02871845837838709,
      "loss": 0.5901,
      "step": 442120
    },
    {
      "epoch": 713.13,
      "learning_rate": 0.028715232575161287,
      "loss": 0.5989,
      "step": 442140
    },
    {
      "epoch": 713.16,
      "learning_rate": 0.028712006771935486,
      "loss": 0.594,
      "step": 442160
    },
    {
      "epoch": 713.19,
      "learning_rate": 0.028708780968709675,
      "loss": 0.5862,
      "step": 442180
    },
    {
      "epoch": 713.23,
      "learning_rate": 0.02870555516548387,
      "loss": 0.5908,
      "step": 442200
    },
    {
      "epoch": 713.26,
      "learning_rate": 0.028702329362258062,
      "loss": 0.5895,
      "step": 442220
    },
    {
      "epoch": 713.29,
      "learning_rate": 0.028699103559032258,
      "loss": 0.6098,
      "step": 442240
    },
    {
      "epoch": 713.32,
      "learning_rate": 0.028695877755806454,
      "loss": 0.6039,
      "step": 442260
    },
    {
      "epoch": 713.35,
      "learning_rate": 0.028692651952580646,
      "loss": 0.6027,
      "step": 442280
    },
    {
      "epoch": 713.39,
      "learning_rate": 0.02868942614935484,
      "loss": 0.5977,
      "step": 442300
    },
    {
      "epoch": 713.42,
      "learning_rate": 0.028686200346129037,
      "loss": 0.605,
      "step": 442320
    },
    {
      "epoch": 713.45,
      "learning_rate": 0.02868297454290323,
      "loss": 0.591,
      "step": 442340
    },
    {
      "epoch": 713.48,
      "learning_rate": 0.028679748739677425,
      "loss": 0.5869,
      "step": 442360
    },
    {
      "epoch": 713.52,
      "learning_rate": 0.028676522936451617,
      "loss": 0.5989,
      "step": 442380
    },
    {
      "epoch": 713.55,
      "learning_rate": 0.028673297133225802,
      "loss": 0.5913,
      "step": 442400
    },
    {
      "epoch": 713.58,
      "learning_rate": 0.02867007132999999,
      "loss": 0.5815,
      "step": 442420
    },
    {
      "epoch": 713.61,
      "learning_rate": 0.02866684552677419,
      "loss": 0.6039,
      "step": 442440
    },
    {
      "epoch": 713.65,
      "learning_rate": 0.028663619723548386,
      "loss": 0.5967,
      "step": 442460
    },
    {
      "epoch": 713.68,
      "learning_rate": 0.028660393920322574,
      "loss": 0.5912,
      "step": 442480
    },
    {
      "epoch": 713.71,
      "learning_rate": 0.028657168117096773,
      "loss": 0.5911,
      "step": 442500
    },
    {
      "epoch": 713.74,
      "learning_rate": 0.028653942313870962,
      "loss": 0.584,
      "step": 442520
    },
    {
      "epoch": 713.77,
      "learning_rate": 0.028650716510645158,
      "loss": 0.58,
      "step": 442540
    },
    {
      "epoch": 713.81,
      "learning_rate": 0.028647490707419357,
      "loss": 0.5942,
      "step": 442560
    },
    {
      "epoch": 713.84,
      "learning_rate": 0.028644264904193546,
      "loss": 0.6092,
      "step": 442580
    },
    {
      "epoch": 713.87,
      "learning_rate": 0.02864103910096774,
      "loss": 0.6042,
      "step": 442600
    },
    {
      "epoch": 713.9,
      "learning_rate": 0.02863781329774194,
      "loss": 0.6059,
      "step": 442620
    },
    {
      "epoch": 713.94,
      "learning_rate": 0.02863458749451613,
      "loss": 0.5949,
      "step": 442640
    },
    {
      "epoch": 713.97,
      "learning_rate": 0.028631361691290325,
      "loss": 0.6004,
      "step": 442660
    },
    {
      "epoch": 714.0,
      "learning_rate": 0.028628135888064524,
      "loss": 0.593,
      "step": 442680
    },
    {
      "epoch": 714.0,
      "eval_accuracy": {
        "accuracy": 0.7709000078057919
      },
      "eval_loss": 0.9663829803466797,
      "eval_runtime": 3.1296,
      "eval_samples_per_second": 4093.439,
      "eval_steps_per_second": 64.225,
      "step": 442680
    },
    {
      "epoch": 714.03,
      "learning_rate": 0.028624910084838712,
      "loss": 0.5959,
      "step": 442700
    },
    {
      "epoch": 714.06,
      "learning_rate": 0.028621684281612898,
      "loss": 0.5868,
      "step": 442720
    },
    {
      "epoch": 714.1,
      "learning_rate": 0.028618458478387093,
      "loss": 0.5933,
      "step": 442740
    },
    {
      "epoch": 714.13,
      "learning_rate": 0.028615232675161285,
      "loss": 0.5906,
      "step": 442760
    },
    {
      "epoch": 714.16,
      "learning_rate": 0.02861200687193548,
      "loss": 0.5919,
      "step": 442780
    },
    {
      "epoch": 714.19,
      "learning_rate": 0.028608781068709677,
      "loss": 0.593,
      "step": 442800
    },
    {
      "epoch": 714.23,
      "learning_rate": 0.02860555526548387,
      "loss": 0.5706,
      "step": 442820
    },
    {
      "epoch": 714.26,
      "learning_rate": 0.028602329462258064,
      "loss": 0.5924,
      "step": 442840
    },
    {
      "epoch": 714.29,
      "learning_rate": 0.02859910365903226,
      "loss": 0.5896,
      "step": 442860
    },
    {
      "epoch": 714.32,
      "learning_rate": 0.028595877855806452,
      "loss": 0.5857,
      "step": 442880
    },
    {
      "epoch": 714.35,
      "learning_rate": 0.028592652052580648,
      "loss": 0.5992,
      "step": 442900
    },
    {
      "epoch": 714.39,
      "learning_rate": 0.02858942624935484,
      "loss": 0.5945,
      "step": 442920
    },
    {
      "epoch": 714.42,
      "learning_rate": 0.028586200446129036,
      "loss": 0.5902,
      "step": 442940
    },
    {
      "epoch": 714.45,
      "learning_rate": 0.02858297464290323,
      "loss": 0.5939,
      "step": 442960
    },
    {
      "epoch": 714.48,
      "learning_rate": 0.028579748839677423,
      "loss": 0.6018,
      "step": 442980
    },
    {
      "epoch": 714.52,
      "learning_rate": 0.02857652303645162,
      "loss": 0.591,
      "step": 443000
    },
    {
      "epoch": 714.55,
      "learning_rate": 0.028573297233225797,
      "loss": 0.5922,
      "step": 443020
    },
    {
      "epoch": 714.58,
      "learning_rate": 0.028570071429999996,
      "loss": 0.5896,
      "step": 443040
    },
    {
      "epoch": 714.61,
      "learning_rate": 0.028566845626774185,
      "loss": 0.5846,
      "step": 443060
    },
    {
      "epoch": 714.65,
      "learning_rate": 0.02856361982354838,
      "loss": 0.5952,
      "step": 443080
    },
    {
      "epoch": 714.68,
      "learning_rate": 0.02856039402032258,
      "loss": 0.5976,
      "step": 443100
    },
    {
      "epoch": 714.71,
      "learning_rate": 0.02855716821709677,
      "loss": 0.5995,
      "step": 443120
    },
    {
      "epoch": 714.74,
      "learning_rate": 0.028553942413870964,
      "loss": 0.5886,
      "step": 443140
    },
    {
      "epoch": 714.77,
      "learning_rate": 0.028550716610645163,
      "loss": 0.5971,
      "step": 443160
    },
    {
      "epoch": 714.81,
      "learning_rate": 0.028547490807419352,
      "loss": 0.5778,
      "step": 443180
    },
    {
      "epoch": 714.84,
      "learning_rate": 0.028544265004193548,
      "loss": 0.5897,
      "step": 443200
    },
    {
      "epoch": 714.87,
      "learning_rate": 0.028541039200967747,
      "loss": 0.5774,
      "step": 443220
    },
    {
      "epoch": 714.9,
      "learning_rate": 0.028537813397741935,
      "loss": 0.5921,
      "step": 443240
    },
    {
      "epoch": 714.94,
      "learning_rate": 0.02853458759451613,
      "loss": 0.6,
      "step": 443260
    },
    {
      "epoch": 714.97,
      "learning_rate": 0.02853136179129033,
      "loss": 0.5931,
      "step": 443280
    },
    {
      "epoch": 715.0,
      "learning_rate": 0.02852813598806452,
      "loss": 0.5952,
      "step": 443300
    },
    {
      "epoch": 715.0,
      "eval_accuracy": {
        "accuracy": 0.7763640621341035
      },
      "eval_loss": 0.9555649161338806,
      "eval_runtime": 3.3502,
      "eval_samples_per_second": 3823.919,
      "eval_steps_per_second": 59.996,
      "step": 443300
    },
    {
      "epoch": 715.03,
      "learning_rate": 0.028524910184838714,
      "loss": 0.6055,
      "step": 443320
    },
    {
      "epoch": 715.06,
      "learning_rate": 0.0285216843816129,
      "loss": 0.5815,
      "step": 443340
    },
    {
      "epoch": 715.1,
      "learning_rate": 0.02851845857838709,
      "loss": 0.5833,
      "step": 443360
    },
    {
      "epoch": 715.13,
      "learning_rate": 0.028515232775161287,
      "loss": 0.5811,
      "step": 443380
    },
    {
      "epoch": 715.16,
      "learning_rate": 0.02851200697193548,
      "loss": 0.5835,
      "step": 443400
    },
    {
      "epoch": 715.19,
      "learning_rate": 0.028508781168709675,
      "loss": 0.5822,
      "step": 443420
    },
    {
      "epoch": 715.23,
      "learning_rate": 0.02850555536548387,
      "loss": 0.5932,
      "step": 443440
    },
    {
      "epoch": 715.26,
      "learning_rate": 0.028502329562258063,
      "loss": 0.5863,
      "step": 443460
    },
    {
      "epoch": 715.29,
      "learning_rate": 0.02849910375903226,
      "loss": 0.6042,
      "step": 443480
    },
    {
      "epoch": 715.32,
      "learning_rate": 0.028495877955806454,
      "loss": 0.5977,
      "step": 443500
    },
    {
      "epoch": 715.35,
      "learning_rate": 0.028492652152580646,
      "loss": 0.5985,
      "step": 443520
    },
    {
      "epoch": 715.39,
      "learning_rate": 0.028489426349354842,
      "loss": 0.592,
      "step": 443540
    },
    {
      "epoch": 715.42,
      "learning_rate": 0.028486200546129034,
      "loss": 0.5949,
      "step": 443560
    },
    {
      "epoch": 715.45,
      "learning_rate": 0.02848297474290323,
      "loss": 0.5888,
      "step": 443580
    },
    {
      "epoch": 715.48,
      "learning_rate": 0.028479748939677425,
      "loss": 0.5906,
      "step": 443600
    },
    {
      "epoch": 715.52,
      "learning_rate": 0.028476523136451617,
      "loss": 0.5929,
      "step": 443620
    },
    {
      "epoch": 715.55,
      "learning_rate": 0.028473297333225803,
      "loss": 0.5944,
      "step": 443640
    },
    {
      "epoch": 715.58,
      "learning_rate": 0.02847007152999999,
      "loss": 0.6046,
      "step": 443660
    },
    {
      "epoch": 715.61,
      "learning_rate": 0.028466845726774187,
      "loss": 0.6041,
      "step": 443680
    },
    {
      "epoch": 715.65,
      "learning_rate": 0.028463619923548386,
      "loss": 0.6069,
      "step": 443700
    },
    {
      "epoch": 715.68,
      "learning_rate": 0.028460394120322575,
      "loss": 0.5877,
      "step": 443720
    },
    {
      "epoch": 715.71,
      "learning_rate": 0.02845716831709677,
      "loss": 0.5979,
      "step": 443740
    },
    {
      "epoch": 715.74,
      "learning_rate": 0.02845394251387097,
      "loss": 0.5986,
      "step": 443760
    },
    {
      "epoch": 715.77,
      "learning_rate": 0.028450716710645158,
      "loss": 0.606,
      "step": 443780
    },
    {
      "epoch": 715.81,
      "learning_rate": 0.028447490907419354,
      "loss": 0.5979,
      "step": 443800
    },
    {
      "epoch": 715.84,
      "learning_rate": 0.028444265104193553,
      "loss": 0.5912,
      "step": 443820
    },
    {
      "epoch": 715.87,
      "learning_rate": 0.02844103930096774,
      "loss": 0.5966,
      "step": 443840
    },
    {
      "epoch": 715.9,
      "learning_rate": 0.028437813497741937,
      "loss": 0.5828,
      "step": 443860
    },
    {
      "epoch": 715.94,
      "learning_rate": 0.028434587694516136,
      "loss": 0.5937,
      "step": 443880
    },
    {
      "epoch": 715.97,
      "learning_rate": 0.028431361891290325,
      "loss": 0.595,
      "step": 443900
    },
    {
      "epoch": 716.0,
      "learning_rate": 0.028428297378225803,
      "loss": 0.5829,
      "step": 443920
    },
    {
      "epoch": 716.0,
      "eval_accuracy": {
        "accuracy": 0.7758176567012723
      },
      "eval_loss": 0.9345999360084534,
      "eval_runtime": 2.9658,
      "eval_samples_per_second": 4319.542,
      "eval_steps_per_second": 67.772,
      "step": 443920
    },
    {
      "epoch": 716.03,
      "learning_rate": 0.028425071575000002,
      "loss": 0.5737,
      "step": 443940
    },
    {
      "epoch": 716.06,
      "learning_rate": 0.02842184577177419,
      "loss": 0.5767,
      "step": 443960
    },
    {
      "epoch": 716.1,
      "learning_rate": 0.028418619968548386,
      "loss": 0.5885,
      "step": 443980
    },
    {
      "epoch": 716.13,
      "learning_rate": 0.028415394165322586,
      "loss": 0.5957,
      "step": 444000
    },
    {
      "epoch": 716.16,
      "learning_rate": 0.028412168362096774,
      "loss": 0.5878,
      "step": 444020
    },
    {
      "epoch": 716.19,
      "learning_rate": 0.02840894255887097,
      "loss": 0.5857,
      "step": 444040
    },
    {
      "epoch": 716.23,
      "learning_rate": 0.02840571675564517,
      "loss": 0.5843,
      "step": 444060
    },
    {
      "epoch": 716.26,
      "learning_rate": 0.028402490952419358,
      "loss": 0.5912,
      "step": 444080
    },
    {
      "epoch": 716.29,
      "learning_rate": 0.028399265149193543,
      "loss": 0.5888,
      "step": 444100
    },
    {
      "epoch": 716.32,
      "learning_rate": 0.02839603934596774,
      "loss": 0.5804,
      "step": 444120
    },
    {
      "epoch": 716.35,
      "learning_rate": 0.02839281354274193,
      "loss": 0.5916,
      "step": 444140
    },
    {
      "epoch": 716.39,
      "learning_rate": 0.028389587739516126,
      "loss": 0.5878,
      "step": 444160
    },
    {
      "epoch": 716.42,
      "learning_rate": 0.028386361936290322,
      "loss": 0.5953,
      "step": 444180
    },
    {
      "epoch": 716.45,
      "learning_rate": 0.028383136133064514,
      "loss": 0.5975,
      "step": 444200
    },
    {
      "epoch": 716.48,
      "learning_rate": 0.02837991032983871,
      "loss": 0.6002,
      "step": 444220
    },
    {
      "epoch": 716.52,
      "learning_rate": 0.028376684526612902,
      "loss": 0.5997,
      "step": 444240
    },
    {
      "epoch": 716.55,
      "learning_rate": 0.028373458723387097,
      "loss": 0.5789,
      "step": 444260
    },
    {
      "epoch": 716.58,
      "learning_rate": 0.028370232920161293,
      "loss": 0.5918,
      "step": 444280
    },
    {
      "epoch": 716.61,
      "learning_rate": 0.028367007116935485,
      "loss": 0.5877,
      "step": 444300
    },
    {
      "epoch": 716.65,
      "learning_rate": 0.02836378131370968,
      "loss": 0.5971,
      "step": 444320
    },
    {
      "epoch": 716.68,
      "learning_rate": 0.028360555510483873,
      "loss": 0.6078,
      "step": 444340
    },
    {
      "epoch": 716.71,
      "learning_rate": 0.02835732970725807,
      "loss": 0.5958,
      "step": 444360
    },
    {
      "epoch": 716.74,
      "learning_rate": 0.028354103904032264,
      "loss": 0.6034,
      "step": 444380
    },
    {
      "epoch": 716.77,
      "learning_rate": 0.028350878100806443,
      "loss": 0.5926,
      "step": 444400
    },
    {
      "epoch": 716.81,
      "learning_rate": 0.02834765229758064,
      "loss": 0.594,
      "step": 444420
    },
    {
      "epoch": 716.84,
      "learning_rate": 0.02834442649435483,
      "loss": 0.5921,
      "step": 444440
    },
    {
      "epoch": 716.87,
      "learning_rate": 0.028341200691129026,
      "loss": 0.6062,
      "step": 444460
    },
    {
      "epoch": 716.9,
      "learning_rate": 0.028337974887903225,
      "loss": 0.5906,
      "step": 444480
    },
    {
      "epoch": 716.94,
      "learning_rate": 0.028334749084677414,
      "loss": 0.5923,
      "step": 444500
    },
    {
      "epoch": 716.97,
      "learning_rate": 0.02833152328145161,
      "loss": 0.5931,
      "step": 444520
    },
    {
      "epoch": 717.0,
      "learning_rate": 0.02832829747822581,
      "loss": 0.6066,
      "step": 444540
    },
    {
      "epoch": 717.0,
      "eval_accuracy": {
        "accuracy": 0.7759737725392241
      },
      "eval_loss": 0.9587881565093994,
      "eval_runtime": 3.0191,
      "eval_samples_per_second": 4243.255,
      "eval_steps_per_second": 66.575,
      "step": 444540
    },
    {
      "epoch": 717.03,
      "learning_rate": 0.028325071674999997,
      "loss": 0.6032,
      "step": 444560
    },
    {
      "epoch": 717.06,
      "learning_rate": 0.028321845871774193,
      "loss": 0.5835,
      "step": 444580
    },
    {
      "epoch": 717.1,
      "learning_rate": 0.028318620068548392,
      "loss": 0.5808,
      "step": 444600
    },
    {
      "epoch": 717.13,
      "learning_rate": 0.02831539426532258,
      "loss": 0.5782,
      "step": 444620
    },
    {
      "epoch": 717.16,
      "learning_rate": 0.028312168462096776,
      "loss": 0.5823,
      "step": 444640
    },
    {
      "epoch": 717.19,
      "learning_rate": 0.028308942658870975,
      "loss": 0.5772,
      "step": 444660
    },
    {
      "epoch": 717.23,
      "learning_rate": 0.028305716855645164,
      "loss": 0.5793,
      "step": 444680
    },
    {
      "epoch": 717.26,
      "learning_rate": 0.02830249105241936,
      "loss": 0.5766,
      "step": 444700
    },
    {
      "epoch": 717.29,
      "learning_rate": 0.028299265249193545,
      "loss": 0.5822,
      "step": 444720
    },
    {
      "epoch": 717.32,
      "learning_rate": 0.028296039445967737,
      "loss": 0.5875,
      "step": 444740
    },
    {
      "epoch": 717.35,
      "learning_rate": 0.028292813642741933,
      "loss": 0.5939,
      "step": 444760
    },
    {
      "epoch": 717.39,
      "learning_rate": 0.028289587839516125,
      "loss": 0.5954,
      "step": 444780
    },
    {
      "epoch": 717.42,
      "learning_rate": 0.02828636203629032,
      "loss": 0.5872,
      "step": 444800
    },
    {
      "epoch": 717.45,
      "learning_rate": 0.028283136233064516,
      "loss": 0.5904,
      "step": 444820
    },
    {
      "epoch": 717.48,
      "learning_rate": 0.028279910429838708,
      "loss": 0.5957,
      "step": 444840
    },
    {
      "epoch": 717.52,
      "learning_rate": 0.028276684626612904,
      "loss": 0.5943,
      "step": 444860
    },
    {
      "epoch": 717.55,
      "learning_rate": 0.028273458823387096,
      "loss": 0.5885,
      "step": 444880
    },
    {
      "epoch": 717.58,
      "learning_rate": 0.02827023302016129,
      "loss": 0.5974,
      "step": 444900
    },
    {
      "epoch": 717.61,
      "learning_rate": 0.028267007216935487,
      "loss": 0.5749,
      "step": 444920
    },
    {
      "epoch": 717.65,
      "learning_rate": 0.02826378141370968,
      "loss": 0.5912,
      "step": 444940
    },
    {
      "epoch": 717.68,
      "learning_rate": 0.028260555610483875,
      "loss": 0.5865,
      "step": 444960
    },
    {
      "epoch": 717.71,
      "learning_rate": 0.028257329807258064,
      "loss": 0.5973,
      "step": 444980
    },
    {
      "epoch": 717.74,
      "learning_rate": 0.028254104004032263,
      "loss": 0.587,
      "step": 445000
    },
    {
      "epoch": 717.77,
      "learning_rate": 0.02825087820080646,
      "loss": 0.5939,
      "step": 445020
    },
    {
      "epoch": 717.81,
      "learning_rate": 0.028247652397580637,
      "loss": 0.594,
      "step": 445040
    },
    {
      "epoch": 717.84,
      "learning_rate": 0.028244426594354832,
      "loss": 0.6078,
      "step": 445060
    },
    {
      "epoch": 717.87,
      "learning_rate": 0.02824120079112903,
      "loss": 0.598,
      "step": 445080
    },
    {
      "epoch": 717.9,
      "learning_rate": 0.02823797498790322,
      "loss": 0.6108,
      "step": 445100
    },
    {
      "epoch": 717.94,
      "learning_rate": 0.028234749184677416,
      "loss": 0.6028,
      "step": 445120
    },
    {
      "epoch": 717.97,
      "learning_rate": 0.028231523381451615,
      "loss": 0.5904,
      "step": 445140
    },
    {
      "epoch": 718.0,
      "learning_rate": 0.028228297578225803,
      "loss": 0.5998,
      "step": 445160
    },
    {
      "epoch": 718.0,
      "eval_accuracy": {
        "accuracy": 0.7764421200530793
      },
      "eval_loss": 0.9541125297546387,
      "eval_runtime": 3.5055,
      "eval_samples_per_second": 3654.522,
      "eval_steps_per_second": 57.338,
      "step": 445160
    },
    {
      "epoch": 718.03,
      "learning_rate": 0.028225071775,
      "loss": 0.6072,
      "step": 445180
    },
    {
      "epoch": 718.06,
      "learning_rate": 0.028221845971774198,
      "loss": 0.5955,
      "step": 445200
    },
    {
      "epoch": 718.1,
      "learning_rate": 0.028218620168548387,
      "loss": 0.5804,
      "step": 445220
    },
    {
      "epoch": 718.13,
      "learning_rate": 0.028215394365322582,
      "loss": 0.5872,
      "step": 445240
    },
    {
      "epoch": 718.16,
      "learning_rate": 0.02821216856209678,
      "loss": 0.5968,
      "step": 445260
    },
    {
      "epoch": 718.19,
      "learning_rate": 0.02820894275887097,
      "loss": 0.5841,
      "step": 445280
    },
    {
      "epoch": 718.23,
      "learning_rate": 0.028205716955645166,
      "loss": 0.5964,
      "step": 445300
    },
    {
      "epoch": 718.26,
      "learning_rate": 0.028202491152419365,
      "loss": 0.5859,
      "step": 445320
    },
    {
      "epoch": 718.29,
      "learning_rate": 0.028199265349193543,
      "loss": 0.5808,
      "step": 445340
    },
    {
      "epoch": 718.32,
      "learning_rate": 0.02819603954596774,
      "loss": 0.5849,
      "step": 445360
    },
    {
      "epoch": 718.35,
      "learning_rate": 0.02819281374274193,
      "loss": 0.583,
      "step": 445380
    },
    {
      "epoch": 718.39,
      "learning_rate": 0.028189587939516127,
      "loss": 0.5765,
      "step": 445400
    },
    {
      "epoch": 718.42,
      "learning_rate": 0.02818636213629032,
      "loss": 0.582,
      "step": 445420
    },
    {
      "epoch": 718.45,
      "learning_rate": 0.028183136333064514,
      "loss": 0.5831,
      "step": 445440
    },
    {
      "epoch": 718.48,
      "learning_rate": 0.02817991052983871,
      "loss": 0.5845,
      "step": 445460
    },
    {
      "epoch": 718.52,
      "learning_rate": 0.028176684726612902,
      "loss": 0.5887,
      "step": 445480
    },
    {
      "epoch": 718.55,
      "learning_rate": 0.028173458923387098,
      "loss": 0.5923,
      "step": 445500
    },
    {
      "epoch": 718.58,
      "learning_rate": 0.028170233120161287,
      "loss": 0.59,
      "step": 445520
    },
    {
      "epoch": 718.61,
      "learning_rate": 0.028167007316935486,
      "loss": 0.5812,
      "step": 445540
    },
    {
      "epoch": 718.65,
      "learning_rate": 0.02816378151370968,
      "loss": 0.5861,
      "step": 445560
    },
    {
      "epoch": 718.68,
      "learning_rate": 0.02816055571048387,
      "loss": 0.6048,
      "step": 445580
    },
    {
      "epoch": 718.71,
      "learning_rate": 0.02815732990725807,
      "loss": 0.601,
      "step": 445600
    },
    {
      "epoch": 718.74,
      "learning_rate": 0.028154104104032258,
      "loss": 0.5827,
      "step": 445620
    },
    {
      "epoch": 718.77,
      "learning_rate": 0.028150878300806453,
      "loss": 0.6004,
      "step": 445640
    },
    {
      "epoch": 718.81,
      "learning_rate": 0.02814765249758064,
      "loss": 0.5984,
      "step": 445660
    },
    {
      "epoch": 718.84,
      "learning_rate": 0.028144426694354838,
      "loss": 0.5956,
      "step": 445680
    },
    {
      "epoch": 718.87,
      "learning_rate": 0.028141200891129026,
      "loss": 0.6104,
      "step": 445700
    },
    {
      "epoch": 718.9,
      "learning_rate": 0.028137975087903222,
      "loss": 0.6076,
      "step": 445720
    },
    {
      "epoch": 718.94,
      "learning_rate": 0.02813474928467742,
      "loss": 0.6142,
      "step": 445740
    },
    {
      "epoch": 718.97,
      "learning_rate": 0.02813152348145161,
      "loss": 0.5844,
      "step": 445760
    },
    {
      "epoch": 719.0,
      "learning_rate": 0.028128297678225805,
      "loss": 0.6051,
      "step": 445780
    },
    {
      "epoch": 719.0,
      "eval_accuracy": {
        "accuracy": 0.7769885254859106
      },
      "eval_loss": 0.9547249674797058,
      "eval_runtime": 3.0444,
      "eval_samples_per_second": 4208.063,
      "eval_steps_per_second": 66.023,
      "step": 445780
    },
    {
      "epoch": 719.03,
      "learning_rate": 0.028125071875000004,
      "loss": 0.5966,
      "step": 445800
    },
    {
      "epoch": 719.06,
      "learning_rate": 0.028121846071774193,
      "loss": 0.5914,
      "step": 445820
    },
    {
      "epoch": 719.1,
      "learning_rate": 0.02811862026854839,
      "loss": 0.5841,
      "step": 445840
    },
    {
      "epoch": 719.13,
      "learning_rate": 0.028115394465322588,
      "loss": 0.5801,
      "step": 445860
    },
    {
      "epoch": 719.16,
      "learning_rate": 0.028112168662096777,
      "loss": 0.5854,
      "step": 445880
    },
    {
      "epoch": 719.19,
      "learning_rate": 0.028108942858870972,
      "loss": 0.6057,
      "step": 445900
    },
    {
      "epoch": 719.23,
      "learning_rate": 0.028105717055645164,
      "loss": 0.5955,
      "step": 445920
    },
    {
      "epoch": 719.26,
      "learning_rate": 0.02810249125241936,
      "loss": 0.5882,
      "step": 445940
    },
    {
      "epoch": 719.29,
      "learning_rate": 0.028099265449193542,
      "loss": 0.5728,
      "step": 445960
    },
    {
      "epoch": 719.32,
      "learning_rate": 0.028096039645967737,
      "loss": 0.589,
      "step": 445980
    },
    {
      "epoch": 719.35,
      "learning_rate": 0.028092813842741933,
      "loss": 0.5743,
      "step": 446000
    },
    {
      "epoch": 719.39,
      "learning_rate": 0.028089588039516125,
      "loss": 0.5924,
      "step": 446020
    },
    {
      "epoch": 719.42,
      "learning_rate": 0.02808636223629032,
      "loss": 0.5937,
      "step": 446040
    },
    {
      "epoch": 719.45,
      "learning_rate": 0.02808313643306451,
      "loss": 0.5879,
      "step": 446060
    },
    {
      "epoch": 719.48,
      "learning_rate": 0.02807991062983871,
      "loss": 0.5929,
      "step": 446080
    },
    {
      "epoch": 719.52,
      "learning_rate": 0.028076684826612904,
      "loss": 0.5829,
      "step": 446100
    },
    {
      "epoch": 719.55,
      "learning_rate": 0.028073459023387093,
      "loss": 0.5975,
      "step": 446120
    },
    {
      "epoch": 719.58,
      "learning_rate": 0.028070233220161292,
      "loss": 0.5868,
      "step": 446140
    },
    {
      "epoch": 719.61,
      "learning_rate": 0.02806700741693548,
      "loss": 0.5818,
      "step": 446160
    },
    {
      "epoch": 719.65,
      "learning_rate": 0.028063781613709676,
      "loss": 0.5886,
      "step": 446180
    },
    {
      "epoch": 719.68,
      "learning_rate": 0.028060555810483875,
      "loss": 0.5942,
      "step": 446200
    },
    {
      "epoch": 719.71,
      "learning_rate": 0.028057330007258064,
      "loss": 0.5933,
      "step": 446220
    },
    {
      "epoch": 719.74,
      "learning_rate": 0.02805410420403226,
      "loss": 0.5932,
      "step": 446240
    },
    {
      "epoch": 719.77,
      "learning_rate": 0.02805087840080646,
      "loss": 0.6016,
      "step": 446260
    },
    {
      "epoch": 719.81,
      "learning_rate": 0.028047652597580644,
      "loss": 0.5867,
      "step": 446280
    },
    {
      "epoch": 719.84,
      "learning_rate": 0.028044426794354833,
      "loss": 0.591,
      "step": 446300
    },
    {
      "epoch": 719.87,
      "learning_rate": 0.02804120099112903,
      "loss": 0.6061,
      "step": 446320
    },
    {
      "epoch": 719.9,
      "learning_rate": 0.028037975187903227,
      "loss": 0.5911,
      "step": 446340
    },
    {
      "epoch": 719.94,
      "learning_rate": 0.028034749384677416,
      "loss": 0.5854,
      "step": 446360
    },
    {
      "epoch": 719.97,
      "learning_rate": 0.02803152358145161,
      "loss": 0.5922,
      "step": 446380
    },
    {
      "epoch": 720.0,
      "learning_rate": 0.028028459068387104,
      "loss": 0.5902,
      "step": 446400
    },
    {
      "epoch": 720.0,
      "eval_accuracy": {
        "accuracy": 0.7783155101085005
      },
      "eval_loss": 0.9393874406814575,
      "eval_runtime": 3.0522,
      "eval_samples_per_second": 4197.27,
      "eval_steps_per_second": 65.854,
      "step": 446400
    },
    {
      "epoch": 720.03,
      "learning_rate": 0.028025233265161282,
      "loss": 0.5735,
      "step": 446420
    },
    {
      "epoch": 720.06,
      "learning_rate": 0.028022007461935478,
      "loss": 0.5872,
      "step": 446440
    },
    {
      "epoch": 720.1,
      "learning_rate": 0.028018781658709677,
      "loss": 0.577,
      "step": 446460
    },
    {
      "epoch": 720.13,
      "learning_rate": 0.028015555855483865,
      "loss": 0.5836,
      "step": 446480
    },
    {
      "epoch": 720.16,
      "learning_rate": 0.02801233005225806,
      "loss": 0.5962,
      "step": 446500
    },
    {
      "epoch": 720.19,
      "learning_rate": 0.02800910424903226,
      "loss": 0.5948,
      "step": 446520
    },
    {
      "epoch": 720.23,
      "learning_rate": 0.02800587844580645,
      "loss": 0.5895,
      "step": 446540
    },
    {
      "epoch": 720.26,
      "learning_rate": 0.028002652642580644,
      "loss": 0.5946,
      "step": 446560
    },
    {
      "epoch": 720.29,
      "learning_rate": 0.027999426839354843,
      "loss": 0.5847,
      "step": 446580
    },
    {
      "epoch": 720.32,
      "learning_rate": 0.027996201036129032,
      "loss": 0.6002,
      "step": 446600
    },
    {
      "epoch": 720.35,
      "learning_rate": 0.027992975232903228,
      "loss": 0.5833,
      "step": 446620
    },
    {
      "epoch": 720.39,
      "learning_rate": 0.027989749429677427,
      "loss": 0.6024,
      "step": 446640
    },
    {
      "epoch": 720.42,
      "learning_rate": 0.027986523626451616,
      "loss": 0.5894,
      "step": 446660
    },
    {
      "epoch": 720.45,
      "learning_rate": 0.02798329782322581,
      "loss": 0.5897,
      "step": 446680
    },
    {
      "epoch": 720.48,
      "learning_rate": 0.027980072020000003,
      "loss": 0.5933,
      "step": 446700
    },
    {
      "epoch": 720.52,
      "learning_rate": 0.02797684621677419,
      "loss": 0.5882,
      "step": 446720
    },
    {
      "epoch": 720.55,
      "learning_rate": 0.027973620413548384,
      "loss": 0.5779,
      "step": 446740
    },
    {
      "epoch": 720.58,
      "learning_rate": 0.027970394610322576,
      "loss": 0.5949,
      "step": 446760
    },
    {
      "epoch": 720.61,
      "learning_rate": 0.027967168807096772,
      "loss": 0.5735,
      "step": 446780
    },
    {
      "epoch": 720.65,
      "learning_rate": 0.027963943003870964,
      "loss": 0.5803,
      "step": 446800
    },
    {
      "epoch": 720.68,
      "learning_rate": 0.02796071720064516,
      "loss": 0.5969,
      "step": 446820
    },
    {
      "epoch": 720.71,
      "learning_rate": 0.027957491397419355,
      "loss": 0.575,
      "step": 446840
    },
    {
      "epoch": 720.74,
      "learning_rate": 0.027954265594193548,
      "loss": 0.5807,
      "step": 446860
    },
    {
      "epoch": 720.77,
      "learning_rate": 0.027951039790967743,
      "loss": 0.6041,
      "step": 446880
    },
    {
      "epoch": 720.81,
      "learning_rate": 0.027947813987741932,
      "loss": 0.5874,
      "step": 446900
    },
    {
      "epoch": 720.84,
      "learning_rate": 0.02794458818451613,
      "loss": 0.5997,
      "step": 446920
    },
    {
      "epoch": 720.87,
      "learning_rate": 0.027941362381290327,
      "loss": 0.5878,
      "step": 446940
    },
    {
      "epoch": 720.9,
      "learning_rate": 0.027938136578064515,
      "loss": 0.5927,
      "step": 446960
    },
    {
      "epoch": 720.94,
      "learning_rate": 0.027934910774838714,
      "loss": 0.5999,
      "step": 446980
    },
    {
      "epoch": 720.97,
      "learning_rate": 0.027931684971612903,
      "loss": 0.5822,
      "step": 447000
    },
    {
      "epoch": 721.0,
      "learning_rate": 0.0279284591683871,
      "loss": 0.5948,
      "step": 447020
    },
    {
      "epoch": 721.0,
      "eval_accuracy": {
        "accuracy": 0.777300757161814
      },
      "eval_loss": 0.9470992088317871,
      "eval_runtime": 3.4437,
      "eval_samples_per_second": 3720.094,
      "eval_steps_per_second": 58.367,
      "step": 447020
    },
    {
      "epoch": 721.03,
      "learning_rate": 0.027925233365161284,
      "loss": 0.5974,
      "step": 447040
    },
    {
      "epoch": 721.06,
      "learning_rate": 0.027922007561935483,
      "loss": 0.5861,
      "step": 447060
    },
    {
      "epoch": 721.1,
      "learning_rate": 0.02791878175870967,
      "loss": 0.5786,
      "step": 447080
    },
    {
      "epoch": 721.13,
      "learning_rate": 0.027915555955483867,
      "loss": 0.5871,
      "step": 447100
    },
    {
      "epoch": 721.16,
      "learning_rate": 0.027912330152258066,
      "loss": 0.5705,
      "step": 447120
    },
    {
      "epoch": 721.19,
      "learning_rate": 0.027909104349032255,
      "loss": 0.5839,
      "step": 447140
    },
    {
      "epoch": 721.23,
      "learning_rate": 0.02790587854580645,
      "loss": 0.5922,
      "step": 447160
    },
    {
      "epoch": 721.26,
      "learning_rate": 0.02790265274258065,
      "loss": 0.5791,
      "step": 447180
    },
    {
      "epoch": 721.29,
      "learning_rate": 0.02789942693935484,
      "loss": 0.5962,
      "step": 447200
    },
    {
      "epoch": 721.32,
      "learning_rate": 0.027896201136129034,
      "loss": 0.603,
      "step": 447220
    },
    {
      "epoch": 721.35,
      "learning_rate": 0.027892975332903226,
      "loss": 0.5939,
      "step": 447240
    },
    {
      "epoch": 721.39,
      "learning_rate": 0.027889749529677422,
      "loss": 0.5852,
      "step": 447260
    },
    {
      "epoch": 721.42,
      "learning_rate": 0.027886523726451617,
      "loss": 0.59,
      "step": 447280
    },
    {
      "epoch": 721.45,
      "learning_rate": 0.02788329792322581,
      "loss": 0.5851,
      "step": 447300
    },
    {
      "epoch": 721.48,
      "learning_rate": 0.027880072120000005,
      "loss": 0.5862,
      "step": 447320
    },
    {
      "epoch": 721.52,
      "learning_rate": 0.0278768463167742,
      "loss": 0.5872,
      "step": 447340
    },
    {
      "epoch": 721.55,
      "learning_rate": 0.027873620513548383,
      "loss": 0.5856,
      "step": 447360
    },
    {
      "epoch": 721.58,
      "learning_rate": 0.027870394710322578,
      "loss": 0.5804,
      "step": 447380
    },
    {
      "epoch": 721.61,
      "learning_rate": 0.02786716890709677,
      "loss": 0.5883,
      "step": 447400
    },
    {
      "epoch": 721.65,
      "learning_rate": 0.027863943103870966,
      "loss": 0.6037,
      "step": 447420
    },
    {
      "epoch": 721.68,
      "learning_rate": 0.027860717300645155,
      "loss": 0.5852,
      "step": 447440
    },
    {
      "epoch": 721.71,
      "learning_rate": 0.027857491497419354,
      "loss": 0.5912,
      "step": 447460
    },
    {
      "epoch": 721.74,
      "learning_rate": 0.02785426569419355,
      "loss": 0.5922,
      "step": 447480
    },
    {
      "epoch": 721.77,
      "learning_rate": 0.027851039890967738,
      "loss": 0.5902,
      "step": 447500
    },
    {
      "epoch": 721.81,
      "learning_rate": 0.027847814087741937,
      "loss": 0.6,
      "step": 447520
    },
    {
      "epoch": 721.84,
      "learning_rate": 0.027844588284516126,
      "loss": 0.597,
      "step": 447540
    },
    {
      "epoch": 721.87,
      "learning_rate": 0.02784136248129032,
      "loss": 0.5861,
      "step": 447560
    },
    {
      "epoch": 721.9,
      "learning_rate": 0.02783813667806452,
      "loss": 0.5994,
      "step": 447580
    },
    {
      "epoch": 721.94,
      "learning_rate": 0.02783491087483871,
      "loss": 0.5878,
      "step": 447600
    },
    {
      "epoch": 721.97,
      "learning_rate": 0.027831685071612905,
      "loss": 0.5936,
      "step": 447620
    },
    {
      "epoch": 722.0,
      "learning_rate": 0.027828459268387104,
      "loss": 0.59,
      "step": 447640
    },
    {
      "epoch": 722.0,
      "eval_accuracy": {
        "accuracy": 0.772773397861213
      },
      "eval_loss": 0.9624615907669067,
      "eval_runtime": 3.4149,
      "eval_samples_per_second": 3751.456,
      "eval_steps_per_second": 58.859,
      "step": 447640
    },
    {
      "epoch": 722.03,
      "learning_rate": 0.02782523346516129,
      "loss": 0.5938,
      "step": 447660
    },
    {
      "epoch": 722.06,
      "learning_rate": 0.027822007661935478,
      "loss": 0.5845,
      "step": 447680
    },
    {
      "epoch": 722.1,
      "learning_rate": 0.027818781858709674,
      "loss": 0.583,
      "step": 447700
    },
    {
      "epoch": 722.13,
      "learning_rate": 0.027815556055483873,
      "loss": 0.5999,
      "step": 447720
    },
    {
      "epoch": 722.16,
      "learning_rate": 0.02781233025225806,
      "loss": 0.5909,
      "step": 447740
    },
    {
      "epoch": 722.19,
      "learning_rate": 0.027809104449032257,
      "loss": 0.5875,
      "step": 447760
    },
    {
      "epoch": 722.23,
      "learning_rate": 0.02780587864580645,
      "loss": 0.5726,
      "step": 447780
    },
    {
      "epoch": 722.26,
      "learning_rate": 0.027802652842580645,
      "loss": 0.5796,
      "step": 447800
    },
    {
      "epoch": 722.29,
      "learning_rate": 0.02779942703935484,
      "loss": 0.5828,
      "step": 447820
    },
    {
      "epoch": 722.32,
      "learning_rate": 0.027796201236129033,
      "loss": 0.592,
      "step": 447840
    },
    {
      "epoch": 722.35,
      "learning_rate": 0.027792975432903228,
      "loss": 0.5852,
      "step": 447860
    },
    {
      "epoch": 722.39,
      "learning_rate": 0.02778974962967742,
      "loss": 0.5916,
      "step": 447880
    },
    {
      "epoch": 722.42,
      "learning_rate": 0.027786523826451616,
      "loss": 0.5779,
      "step": 447900
    },
    {
      "epoch": 722.45,
      "learning_rate": 0.02778329802322581,
      "loss": 0.5789,
      "step": 447920
    },
    {
      "epoch": 722.48,
      "learning_rate": 0.027780072220000004,
      "loss": 0.5838,
      "step": 447940
    },
    {
      "epoch": 722.52,
      "learning_rate": 0.0277768464167742,
      "loss": 0.5795,
      "step": 447960
    },
    {
      "epoch": 722.55,
      "learning_rate": 0.027773620613548378,
      "loss": 0.5943,
      "step": 447980
    },
    {
      "epoch": 722.58,
      "learning_rate": 0.027770394810322577,
      "loss": 0.5872,
      "step": 448000
    },
    {
      "epoch": 722.61,
      "learning_rate": 0.027767169007096772,
      "loss": 0.5918,
      "step": 448020
    },
    {
      "epoch": 722.65,
      "learning_rate": 0.02776394320387096,
      "loss": 0.6003,
      "step": 448040
    },
    {
      "epoch": 722.68,
      "learning_rate": 0.02776071740064516,
      "loss": 0.6043,
      "step": 448060
    },
    {
      "epoch": 722.71,
      "learning_rate": 0.02775749159741935,
      "loss": 0.5969,
      "step": 448080
    },
    {
      "epoch": 722.74,
      "learning_rate": 0.027754265794193544,
      "loss": 0.5954,
      "step": 448100
    },
    {
      "epoch": 722.77,
      "learning_rate": 0.027751039990967744,
      "loss": 0.6055,
      "step": 448120
    },
    {
      "epoch": 722.81,
      "learning_rate": 0.027747814187741932,
      "loss": 0.5867,
      "step": 448140
    },
    {
      "epoch": 722.84,
      "learning_rate": 0.027744588384516128,
      "loss": 0.5838,
      "step": 448160
    },
    {
      "epoch": 722.87,
      "learning_rate": 0.027741362581290327,
      "loss": 0.5908,
      "step": 448180
    },
    {
      "epoch": 722.9,
      "learning_rate": 0.027738136778064516,
      "loss": 0.5916,
      "step": 448200
    },
    {
      "epoch": 722.94,
      "learning_rate": 0.02773491097483871,
      "loss": 0.5807,
      "step": 448220
    },
    {
      "epoch": 722.97,
      "learning_rate": 0.02773168517161291,
      "loss": 0.5845,
      "step": 448240
    },
    {
      "epoch": 723.0,
      "learning_rate": 0.0277284593683871,
      "loss": 0.5845,
      "step": 448260
    },
    {
      "epoch": 723.0,
      "eval_accuracy": {
        "accuracy": 0.7762079462961518
      },
      "eval_loss": 0.9594765305519104,
      "eval_runtime": 3.035,
      "eval_samples_per_second": 4221.11,
      "eval_steps_per_second": 66.228,
      "step": 448260
    },
    {
      "epoch": 723.03,
      "learning_rate": 0.027725233565161284,
      "loss": 0.597,
      "step": 448280
    },
    {
      "epoch": 723.06,
      "learning_rate": 0.02772200776193548,
      "loss": 0.5911,
      "step": 448300
    },
    {
      "epoch": 723.1,
      "learning_rate": 0.027718781958709672,
      "loss": 0.5888,
      "step": 448320
    },
    {
      "epoch": 723.13,
      "learning_rate": 0.027715556155483868,
      "loss": 0.5795,
      "step": 448340
    },
    {
      "epoch": 723.16,
      "learning_rate": 0.027712330352258063,
      "loss": 0.5808,
      "step": 448360
    },
    {
      "epoch": 723.19,
      "learning_rate": 0.027709104549032255,
      "loss": 0.5777,
      "step": 448380
    },
    {
      "epoch": 723.23,
      "learning_rate": 0.02770587874580645,
      "loss": 0.5871,
      "step": 448400
    },
    {
      "epoch": 723.26,
      "learning_rate": 0.027702652942580643,
      "loss": 0.5847,
      "step": 448420
    },
    {
      "epoch": 723.29,
      "learning_rate": 0.02769942713935484,
      "loss": 0.5894,
      "step": 448440
    },
    {
      "epoch": 723.32,
      "learning_rate": 0.027696201336129034,
      "loss": 0.5803,
      "step": 448460
    },
    {
      "epoch": 723.35,
      "learning_rate": 0.027692975532903227,
      "loss": 0.6024,
      "step": 448480
    },
    {
      "epoch": 723.39,
      "learning_rate": 0.027689749729677422,
      "loss": 0.5769,
      "step": 448500
    },
    {
      "epoch": 723.42,
      "learning_rate": 0.027686523926451618,
      "loss": 0.589,
      "step": 448520
    },
    {
      "epoch": 723.45,
      "learning_rate": 0.02768329812322581,
      "loss": 0.5798,
      "step": 448540
    },
    {
      "epoch": 723.48,
      "learning_rate": 0.027680072320000006,
      "loss": 0.5775,
      "step": 448560
    },
    {
      "epoch": 723.52,
      "learning_rate": 0.027676846516774198,
      "loss": 0.5854,
      "step": 448580
    },
    {
      "epoch": 723.55,
      "learning_rate": 0.027673620713548383,
      "loss": 0.5937,
      "step": 448600
    },
    {
      "epoch": 723.58,
      "learning_rate": 0.02767039491032257,
      "loss": 0.5771,
      "step": 448620
    },
    {
      "epoch": 723.61,
      "learning_rate": 0.027667169107096767,
      "loss": 0.5825,
      "step": 448640
    },
    {
      "epoch": 723.65,
      "learning_rate": 0.027663943303870966,
      "loss": 0.6034,
      "step": 448660
    },
    {
      "epoch": 723.68,
      "learning_rate": 0.027660717500645155,
      "loss": 0.5875,
      "step": 448680
    },
    {
      "epoch": 723.71,
      "learning_rate": 0.02765749169741935,
      "loss": 0.5878,
      "step": 448700
    },
    {
      "epoch": 723.74,
      "learning_rate": 0.02765426589419355,
      "loss": 0.5861,
      "step": 448720
    },
    {
      "epoch": 723.77,
      "learning_rate": 0.02765104009096774,
      "loss": 0.5841,
      "step": 448740
    },
    {
      "epoch": 723.81,
      "learning_rate": 0.027647814287741934,
      "loss": 0.5866,
      "step": 448760
    },
    {
      "epoch": 723.84,
      "learning_rate": 0.027644588484516133,
      "loss": 0.5911,
      "step": 448780
    },
    {
      "epoch": 723.87,
      "learning_rate": 0.027641362681290322,
      "loss": 0.6022,
      "step": 448800
    },
    {
      "epoch": 723.9,
      "learning_rate": 0.027638136878064518,
      "loss": 0.5919,
      "step": 448820
    },
    {
      "epoch": 723.94,
      "learning_rate": 0.027634911074838717,
      "loss": 0.6082,
      "step": 448840
    },
    {
      "epoch": 723.97,
      "learning_rate": 0.027631685271612905,
      "loss": 0.5846,
      "step": 448860
    },
    {
      "epoch": 724.0,
      "learning_rate": 0.0276284594683871,
      "loss": 0.5869,
      "step": 448880
    },
    {
      "epoch": 724.0,
      "eval_accuracy": {
        "accuracy": 0.7821403481383187
      },
      "eval_loss": 0.9199932217597961,
      "eval_runtime": 3.3444,
      "eval_samples_per_second": 3830.565,
      "eval_steps_per_second": 60.1,
      "step": 448880
    },
    {
      "epoch": 724.03,
      "learning_rate": 0.027625233665161286,
      "loss": 0.5837,
      "step": 448900
    },
    {
      "epoch": 724.06,
      "learning_rate": 0.02762200786193548,
      "loss": 0.5832,
      "step": 448920
    },
    {
      "epoch": 724.1,
      "learning_rate": 0.027618782058709674,
      "loss": 0.5737,
      "step": 448940
    },
    {
      "epoch": 724.13,
      "learning_rate": 0.027615556255483866,
      "loss": 0.5733,
      "step": 448960
    },
    {
      "epoch": 724.16,
      "learning_rate": 0.027612330452258062,
      "loss": 0.578,
      "step": 448980
    },
    {
      "epoch": 724.19,
      "learning_rate": 0.027609104649032257,
      "loss": 0.5921,
      "step": 449000
    },
    {
      "epoch": 724.23,
      "learning_rate": 0.02760587884580645,
      "loss": 0.584,
      "step": 449020
    },
    {
      "epoch": 724.26,
      "learning_rate": 0.027602653042580645,
      "loss": 0.5764,
      "step": 449040
    },
    {
      "epoch": 724.29,
      "learning_rate": 0.02759942723935484,
      "loss": 0.5886,
      "step": 449060
    },
    {
      "epoch": 724.32,
      "learning_rate": 0.027596201436129033,
      "loss": 0.5917,
      "step": 449080
    },
    {
      "epoch": 724.35,
      "learning_rate": 0.02759297563290323,
      "loss": 0.5875,
      "step": 449100
    },
    {
      "epoch": 724.39,
      "learning_rate": 0.02758974982967742,
      "loss": 0.5995,
      "step": 449120
    },
    {
      "epoch": 724.42,
      "learning_rate": 0.027586524026451616,
      "loss": 0.5915,
      "step": 449140
    },
    {
      "epoch": 724.45,
      "learning_rate": 0.027583298223225812,
      "loss": 0.59,
      "step": 449160
    },
    {
      "epoch": 724.48,
      "learning_rate": 0.027580072420000004,
      "loss": 0.5896,
      "step": 449180
    },
    {
      "epoch": 724.52,
      "learning_rate": 0.0275768466167742,
      "loss": 0.5921,
      "step": 449200
    },
    {
      "epoch": 724.55,
      "learning_rate": 0.027573620813548378,
      "loss": 0.5819,
      "step": 449220
    },
    {
      "epoch": 724.58,
      "learning_rate": 0.027570395010322574,
      "loss": 0.5903,
      "step": 449240
    },
    {
      "epoch": 724.61,
      "learning_rate": 0.027567169207096773,
      "loss": 0.5768,
      "step": 449260
    },
    {
      "epoch": 724.65,
      "learning_rate": 0.02756394340387096,
      "loss": 0.5829,
      "step": 449280
    },
    {
      "epoch": 724.68,
      "learning_rate": 0.027560717600645157,
      "loss": 0.5838,
      "step": 449300
    },
    {
      "epoch": 724.71,
      "learning_rate": 0.027557491797419356,
      "loss": 0.5903,
      "step": 449320
    },
    {
      "epoch": 724.74,
      "learning_rate": 0.027554265994193545,
      "loss": 0.5954,
      "step": 449340
    },
    {
      "epoch": 724.77,
      "learning_rate": 0.02755104019096774,
      "loss": 0.5945,
      "step": 449360
    },
    {
      "epoch": 724.81,
      "learning_rate": 0.02754781438774194,
      "loss": 0.5842,
      "step": 449380
    },
    {
      "epoch": 724.84,
      "learning_rate": 0.02754458858451613,
      "loss": 0.5904,
      "step": 449400
    },
    {
      "epoch": 724.87,
      "learning_rate": 0.027541362781290324,
      "loss": 0.589,
      "step": 449420
    },
    {
      "epoch": 724.9,
      "learning_rate": 0.027538136978064523,
      "loss": 0.5906,
      "step": 449440
    },
    {
      "epoch": 724.94,
      "learning_rate": 0.02753491117483871,
      "loss": 0.6061,
      "step": 449460
    },
    {
      "epoch": 724.97,
      "learning_rate": 0.027531685371612907,
      "loss": 0.5917,
      "step": 449480
    },
    {
      "epoch": 725.0,
      "learning_rate": 0.02752862085854839,
      "loss": 0.5699,
      "step": 449500
    },
    {
      "epoch": 725.0,
      "eval_accuracy": {
        "accuracy": 0.7785496838654281
      },
      "eval_loss": 0.9475897550582886,
      "eval_runtime": 4.469,
      "eval_samples_per_second": 2866.634,
      "eval_steps_per_second": 44.976,
      "step": 449500
    },
    {
      "epoch": 725.03,
      "learning_rate": 0.027525395055322577,
      "loss": 0.5823,
      "step": 449520
    },
    {
      "epoch": 725.06,
      "learning_rate": 0.027522169252096773,
      "loss": 0.5933,
      "step": 449540
    },
    {
      "epoch": 725.1,
      "learning_rate": 0.027518943448870972,
      "loss": 0.597,
      "step": 449560
    },
    {
      "epoch": 725.13,
      "learning_rate": 0.02751571764564516,
      "loss": 0.5807,
      "step": 449580
    },
    {
      "epoch": 725.16,
      "learning_rate": 0.027512491842419357,
      "loss": 0.5795,
      "step": 449600
    },
    {
      "epoch": 725.19,
      "learning_rate": 0.027509266039193556,
      "loss": 0.5793,
      "step": 449620
    },
    {
      "epoch": 725.23,
      "learning_rate": 0.027506040235967744,
      "loss": 0.5866,
      "step": 449640
    },
    {
      "epoch": 725.26,
      "learning_rate": 0.02750281443274194,
      "loss": 0.5873,
      "step": 449660
    },
    {
      "epoch": 725.29,
      "learning_rate": 0.027499588629516125,
      "loss": 0.5902,
      "step": 449680
    },
    {
      "epoch": 725.32,
      "learning_rate": 0.027496362826290317,
      "loss": 0.5832,
      "step": 449700
    },
    {
      "epoch": 725.35,
      "learning_rate": 0.027493137023064513,
      "loss": 0.5694,
      "step": 449720
    },
    {
      "epoch": 725.39,
      "learning_rate": 0.02748991121983871,
      "loss": 0.5707,
      "step": 449740
    },
    {
      "epoch": 725.42,
      "learning_rate": 0.0274866854166129,
      "loss": 0.5921,
      "step": 449760
    },
    {
      "epoch": 725.45,
      "learning_rate": 0.027483459613387096,
      "loss": 0.5956,
      "step": 449780
    },
    {
      "epoch": 725.48,
      "learning_rate": 0.02748023381016129,
      "loss": 0.5921,
      "step": 449800
    },
    {
      "epoch": 725.52,
      "learning_rate": 0.027477008006935484,
      "loss": 0.5933,
      "step": 449820
    },
    {
      "epoch": 725.55,
      "learning_rate": 0.02747378220370968,
      "loss": 0.5926,
      "step": 449840
    },
    {
      "epoch": 725.58,
      "learning_rate": 0.027470556400483872,
      "loss": 0.6025,
      "step": 449860
    },
    {
      "epoch": 725.61,
      "learning_rate": 0.027467330597258068,
      "loss": 0.5896,
      "step": 449880
    },
    {
      "epoch": 725.65,
      "learning_rate": 0.02746410479403226,
      "loss": 0.5932,
      "step": 449900
    },
    {
      "epoch": 725.68,
      "learning_rate": 0.027460878990806455,
      "loss": 0.5786,
      "step": 449920
    },
    {
      "epoch": 725.71,
      "learning_rate": 0.02745765318758065,
      "loss": 0.5889,
      "step": 449940
    },
    {
      "epoch": 725.74,
      "learning_rate": 0.027454427384354843,
      "loss": 0.6029,
      "step": 449960
    },
    {
      "epoch": 725.77,
      "learning_rate": 0.02745120158112903,
      "loss": 0.5954,
      "step": 449980
    },
    {
      "epoch": 725.81,
      "learning_rate": 0.027447975777903217,
      "loss": 0.5898,
      "step": 450000
    },
    {
      "epoch": 725.84,
      "learning_rate": 0.027444749974677413,
      "loss": 0.5873,
      "step": 450020
    },
    {
      "epoch": 725.87,
      "learning_rate": 0.02744152417145161,
      "loss": 0.5917,
      "step": 450040
    },
    {
      "epoch": 725.9,
      "learning_rate": 0.0274382983682258,
      "loss": 0.586,
      "step": 450060
    },
    {
      "epoch": 725.94,
      "learning_rate": 0.027435072564999996,
      "loss": 0.5737,
      "step": 450080
    },
    {
      "epoch": 725.97,
      "learning_rate": 0.027431846761774195,
      "loss": 0.578,
      "step": 450100
    },
    {
      "epoch": 726.0,
      "learning_rate": 0.027428620958548384,
      "loss": 0.5995,
      "step": 450120
    },
    {
      "epoch": 726.0,
      "eval_accuracy": {
        "accuracy": 0.7738662087268754
      },
      "eval_loss": 0.9585361480712891,
      "eval_runtime": 2.9536,
      "eval_samples_per_second": 4337.415,
      "eval_steps_per_second": 68.052,
      "step": 450120
    },
    {
      "epoch": 726.03,
      "learning_rate": 0.02742539515532258,
      "loss": 0.5973,
      "step": 450140
    },
    {
      "epoch": 726.06,
      "learning_rate": 0.02742216935209678,
      "loss": 0.5627,
      "step": 450160
    },
    {
      "epoch": 726.1,
      "learning_rate": 0.027418943548870967,
      "loss": 0.5853,
      "step": 450180
    },
    {
      "epoch": 726.13,
      "learning_rate": 0.027415717745645163,
      "loss": 0.5794,
      "step": 450200
    },
    {
      "epoch": 726.16,
      "learning_rate": 0.027412491942419362,
      "loss": 0.573,
      "step": 450220
    },
    {
      "epoch": 726.19,
      "learning_rate": 0.02740926613919355,
      "loss": 0.5936,
      "step": 450240
    },
    {
      "epoch": 726.23,
      "learning_rate": 0.027406040335967746,
      "loss": 0.5835,
      "step": 450260
    },
    {
      "epoch": 726.26,
      "learning_rate": 0.027402814532741945,
      "loss": 0.5837,
      "step": 450280
    },
    {
      "epoch": 726.29,
      "learning_rate": 0.027399588729516124,
      "loss": 0.5851,
      "step": 450300
    },
    {
      "epoch": 726.32,
      "learning_rate": 0.02739636292629032,
      "loss": 0.5887,
      "step": 450320
    },
    {
      "epoch": 726.35,
      "learning_rate": 0.02739313712306451,
      "loss": 0.6028,
      "step": 450340
    },
    {
      "epoch": 726.39,
      "learning_rate": 0.027389911319838707,
      "loss": 0.5827,
      "step": 450360
    },
    {
      "epoch": 726.42,
      "learning_rate": 0.027386685516612903,
      "loss": 0.5914,
      "step": 450380
    },
    {
      "epoch": 726.45,
      "learning_rate": 0.027383459713387095,
      "loss": 0.5934,
      "step": 450400
    },
    {
      "epoch": 726.48,
      "learning_rate": 0.02738023391016129,
      "loss": 0.5983,
      "step": 450420
    },
    {
      "epoch": 726.52,
      "learning_rate": 0.027377008106935483,
      "loss": 0.5998,
      "step": 450440
    },
    {
      "epoch": 726.55,
      "learning_rate": 0.027373782303709678,
      "loss": 0.5952,
      "step": 450460
    },
    {
      "epoch": 726.58,
      "learning_rate": 0.027370556500483874,
      "loss": 0.5883,
      "step": 450480
    },
    {
      "epoch": 726.61,
      "learning_rate": 0.027367330697258066,
      "loss": 0.5988,
      "step": 450500
    },
    {
      "epoch": 726.65,
      "learning_rate": 0.02736410489403226,
      "loss": 0.5821,
      "step": 450520
    },
    {
      "epoch": 726.68,
      "learning_rate": 0.02736087909080645,
      "loss": 0.585,
      "step": 450540
    },
    {
      "epoch": 726.71,
      "learning_rate": 0.02735765328758065,
      "loss": 0.5863,
      "step": 450560
    },
    {
      "epoch": 726.74,
      "learning_rate": 0.027354427484354845,
      "loss": 0.5772,
      "step": 450580
    },
    {
      "epoch": 726.77,
      "learning_rate": 0.027351201681129023,
      "loss": 0.5837,
      "step": 450600
    },
    {
      "epoch": 726.81,
      "learning_rate": 0.02734797587790322,
      "loss": 0.5908,
      "step": 450620
    },
    {
      "epoch": 726.84,
      "learning_rate": 0.027344750074677418,
      "loss": 0.5869,
      "step": 450640
    },
    {
      "epoch": 726.87,
      "learning_rate": 0.027341524271451607,
      "loss": 0.5861,
      "step": 450660
    },
    {
      "epoch": 726.9,
      "learning_rate": 0.027338298468225802,
      "loss": 0.5925,
      "step": 450680
    },
    {
      "epoch": 726.94,
      "learning_rate": 0.027335072665,
      "loss": 0.5772,
      "step": 450700
    },
    {
      "epoch": 726.97,
      "learning_rate": 0.02733184686177419,
      "loss": 0.6018,
      "step": 450720
    },
    {
      "epoch": 727.0,
      "learning_rate": 0.027328621058548386,
      "loss": 0.5898,
      "step": 450740
    },
    {
      "epoch": 727.0,
      "eval_accuracy": {
        "accuracy": 0.7769885254859106
      },
      "eval_loss": 0.9448568224906921,
      "eval_runtime": 4.1982,
      "eval_samples_per_second": 3051.52,
      "eval_steps_per_second": 47.877,
      "step": 450740
    },
    {
      "epoch": 727.03,
      "learning_rate": 0.027325395255322585,
      "loss": 0.5768,
      "step": 450760
    },
    {
      "epoch": 727.06,
      "learning_rate": 0.027322169452096774,
      "loss": 0.5663,
      "step": 450780
    },
    {
      "epoch": 727.1,
      "learning_rate": 0.02731894364887097,
      "loss": 0.573,
      "step": 450800
    },
    {
      "epoch": 727.13,
      "learning_rate": 0.027315717845645168,
      "loss": 0.5867,
      "step": 450820
    },
    {
      "epoch": 727.16,
      "learning_rate": 0.027312492042419357,
      "loss": 0.5892,
      "step": 450840
    },
    {
      "epoch": 727.19,
      "learning_rate": 0.027309266239193553,
      "loss": 0.5937,
      "step": 450860
    },
    {
      "epoch": 727.23,
      "learning_rate": 0.02730604043596775,
      "loss": 0.5684,
      "step": 450880
    },
    {
      "epoch": 727.26,
      "learning_rate": 0.02730281463274194,
      "loss": 0.5896,
      "step": 450900
    },
    {
      "epoch": 727.29,
      "learning_rate": 0.027299588829516126,
      "loss": 0.5898,
      "step": 450920
    },
    {
      "epoch": 727.32,
      "learning_rate": 0.027296363026290318,
      "loss": 0.5803,
      "step": 450940
    },
    {
      "epoch": 727.35,
      "learning_rate": 0.027293137223064513,
      "loss": 0.586,
      "step": 450960
    },
    {
      "epoch": 727.39,
      "learning_rate": 0.027289911419838705,
      "loss": 0.5833,
      "step": 450980
    },
    {
      "epoch": 727.42,
      "learning_rate": 0.0272866856166129,
      "loss": 0.5828,
      "step": 451000
    },
    {
      "epoch": 727.45,
      "learning_rate": 0.027283459813387097,
      "loss": 0.5724,
      "step": 451020
    },
    {
      "epoch": 727.48,
      "learning_rate": 0.02728023401016129,
      "loss": 0.5863,
      "step": 451040
    },
    {
      "epoch": 727.52,
      "learning_rate": 0.027277008206935485,
      "loss": 0.5852,
      "step": 451060
    },
    {
      "epoch": 727.55,
      "learning_rate": 0.027273782403709673,
      "loss": 0.5849,
      "step": 451080
    },
    {
      "epoch": 727.58,
      "learning_rate": 0.027270556600483872,
      "loss": 0.5762,
      "step": 451100
    },
    {
      "epoch": 727.61,
      "learning_rate": 0.027267330797258068,
      "loss": 0.5784,
      "step": 451120
    },
    {
      "epoch": 727.65,
      "learning_rate": 0.027264104994032257,
      "loss": 0.5837,
      "step": 451140
    },
    {
      "epoch": 727.68,
      "learning_rate": 0.027260879190806456,
      "loss": 0.5885,
      "step": 451160
    },
    {
      "epoch": 727.71,
      "learning_rate": 0.027257653387580644,
      "loss": 0.5849,
      "step": 451180
    },
    {
      "epoch": 727.74,
      "learning_rate": 0.02725442758435484,
      "loss": 0.5761,
      "step": 451200
    },
    {
      "epoch": 727.77,
      "learning_rate": 0.027251201781129025,
      "loss": 0.5817,
      "step": 451220
    },
    {
      "epoch": 727.81,
      "learning_rate": 0.027247975977903224,
      "loss": 0.578,
      "step": 451240
    },
    {
      "epoch": 727.84,
      "learning_rate": 0.027244750174677413,
      "loss": 0.5912,
      "step": 451260
    },
    {
      "epoch": 727.87,
      "learning_rate": 0.02724152437145161,
      "loss": 0.5939,
      "step": 451280
    },
    {
      "epoch": 727.9,
      "learning_rate": 0.027238298568225808,
      "loss": 0.6037,
      "step": 451300
    },
    {
      "epoch": 727.94,
      "learning_rate": 0.027235072764999996,
      "loss": 0.5935,
      "step": 451320
    },
    {
      "epoch": 727.97,
      "learning_rate": 0.027231846961774192,
      "loss": 0.5999,
      "step": 451340
    },
    {
      "epoch": 728.0,
      "learning_rate": 0.02722862115854839,
      "loss": 0.604,
      "step": 451360
    },
    {
      "epoch": 728.0,
      "eval_accuracy": {
        "accuracy": 0.7781593942705487
      },
      "eval_loss": 0.9499736428260803,
      "eval_runtime": 3.033,
      "eval_samples_per_second": 4223.858,
      "eval_steps_per_second": 66.271,
      "step": 451360
    },
    {
      "epoch": 728.03,
      "learning_rate": 0.02722539535532258,
      "loss": 0.5961,
      "step": 451380
    },
    {
      "epoch": 728.06,
      "learning_rate": 0.027222169552096775,
      "loss": 0.5816,
      "step": 451400
    },
    {
      "epoch": 728.1,
      "learning_rate": 0.027218943748870975,
      "loss": 0.5722,
      "step": 451420
    },
    {
      "epoch": 728.13,
      "learning_rate": 0.027215717945645163,
      "loss": 0.5845,
      "step": 451440
    },
    {
      "epoch": 728.16,
      "learning_rate": 0.02721249214241936,
      "loss": 0.5881,
      "step": 451460
    },
    {
      "epoch": 728.19,
      "learning_rate": 0.02720926633919355,
      "loss": 0.5789,
      "step": 451480
    },
    {
      "epoch": 728.23,
      "learning_rate": 0.027206040535967747,
      "loss": 0.5712,
      "step": 451500
    },
    {
      "epoch": 728.26,
      "learning_rate": 0.027202814732741942,
      "loss": 0.5941,
      "step": 451520
    },
    {
      "epoch": 728.29,
      "learning_rate": 0.027199588929516124,
      "loss": 0.5921,
      "step": 451540
    },
    {
      "epoch": 728.32,
      "learning_rate": 0.02719636312629032,
      "loss": 0.5888,
      "step": 451560
    },
    {
      "epoch": 728.35,
      "learning_rate": 0.027193137323064512,
      "loss": 0.5855,
      "step": 451580
    },
    {
      "epoch": 728.39,
      "learning_rate": 0.027189911519838707,
      "loss": 0.5849,
      "step": 451600
    },
    {
      "epoch": 728.42,
      "learning_rate": 0.027186685716612896,
      "loss": 0.5888,
      "step": 451620
    },
    {
      "epoch": 728.45,
      "learning_rate": 0.027183459913387095,
      "loss": 0.5766,
      "step": 451640
    },
    {
      "epoch": 728.48,
      "learning_rate": 0.02718023411016129,
      "loss": 0.5816,
      "step": 451660
    },
    {
      "epoch": 728.52,
      "learning_rate": 0.02717700830693548,
      "loss": 0.5775,
      "step": 451680
    },
    {
      "epoch": 728.55,
      "learning_rate": 0.02717378250370968,
      "loss": 0.5867,
      "step": 451700
    },
    {
      "epoch": 728.58,
      "learning_rate": 0.027170556700483867,
      "loss": 0.589,
      "step": 451720
    },
    {
      "epoch": 728.61,
      "learning_rate": 0.027167330897258063,
      "loss": 0.5914,
      "step": 451740
    },
    {
      "epoch": 728.65,
      "learning_rate": 0.027164105094032262,
      "loss": 0.5796,
      "step": 451760
    },
    {
      "epoch": 728.68,
      "learning_rate": 0.02716087929080645,
      "loss": 0.586,
      "step": 451780
    },
    {
      "epoch": 728.71,
      "learning_rate": 0.027157653487580646,
      "loss": 0.5918,
      "step": 451800
    },
    {
      "epoch": 728.74,
      "learning_rate": 0.027154427684354845,
      "loss": 0.5874,
      "step": 451820
    },
    {
      "epoch": 728.77,
      "learning_rate": 0.027151201881129034,
      "loss": 0.5862,
      "step": 451840
    },
    {
      "epoch": 728.81,
      "learning_rate": 0.02714797607790322,
      "loss": 0.5914,
      "step": 451860
    },
    {
      "epoch": 728.84,
      "learning_rate": 0.027144750274677415,
      "loss": 0.5855,
      "step": 451880
    },
    {
      "epoch": 728.87,
      "learning_rate": 0.027141524471451614,
      "loss": 0.5806,
      "step": 451900
    },
    {
      "epoch": 728.9,
      "learning_rate": 0.027138298668225803,
      "loss": 0.5768,
      "step": 451920
    },
    {
      "epoch": 728.94,
      "learning_rate": 0.027135072865,
      "loss": 0.5955,
      "step": 451940
    },
    {
      "epoch": 728.97,
      "learning_rate": 0.027131847061774197,
      "loss": 0.582,
      "step": 451960
    },
    {
      "epoch": 729.0,
      "learning_rate": 0.02712878254870968,
      "loss": 0.5861,
      "step": 451980
    },
    {
      "epoch": 729.0,
      "eval_accuracy": {
        "accuracy": 0.7809694793536804
      },
      "eval_loss": 0.9462484121322632,
      "eval_runtime": 3.081,
      "eval_samples_per_second": 4158.049,
      "eval_steps_per_second": 65.238,
      "step": 451980
    },
    {
      "epoch": 729.03,
      "learning_rate": 0.027125556745483864,
      "loss": 0.5722,
      "step": 452000
    },
    {
      "epoch": 729.06,
      "learning_rate": 0.027122330942258063,
      "loss": 0.5915,
      "step": 452020
    },
    {
      "epoch": 729.1,
      "learning_rate": 0.027119105139032252,
      "loss": 0.5788,
      "step": 452040
    },
    {
      "epoch": 729.13,
      "learning_rate": 0.027115879335806448,
      "loss": 0.5839,
      "step": 452060
    },
    {
      "epoch": 729.16,
      "learning_rate": 0.027112653532580647,
      "loss": 0.578,
      "step": 452080
    },
    {
      "epoch": 729.19,
      "learning_rate": 0.027109427729354835,
      "loss": 0.5778,
      "step": 452100
    },
    {
      "epoch": 729.23,
      "learning_rate": 0.02710620192612903,
      "loss": 0.583,
      "step": 452120
    },
    {
      "epoch": 729.26,
      "learning_rate": 0.02710297612290323,
      "loss": 0.5858,
      "step": 452140
    },
    {
      "epoch": 729.29,
      "learning_rate": 0.02709975031967742,
      "loss": 0.5778,
      "step": 452160
    },
    {
      "epoch": 729.32,
      "learning_rate": 0.027096524516451614,
      "loss": 0.582,
      "step": 452180
    },
    {
      "epoch": 729.35,
      "learning_rate": 0.027093298713225814,
      "loss": 0.5852,
      "step": 452200
    },
    {
      "epoch": 729.39,
      "learning_rate": 0.027090072910000002,
      "loss": 0.5806,
      "step": 452220
    },
    {
      "epoch": 729.42,
      "learning_rate": 0.027086847106774198,
      "loss": 0.5765,
      "step": 452240
    },
    {
      "epoch": 729.45,
      "learning_rate": 0.02708362130354839,
      "loss": 0.5852,
      "step": 452260
    },
    {
      "epoch": 729.48,
      "learning_rate": 0.027080395500322586,
      "loss": 0.5818,
      "step": 452280
    },
    {
      "epoch": 729.52,
      "learning_rate": 0.027077169697096767,
      "loss": 0.5779,
      "step": 452300
    },
    {
      "epoch": 729.55,
      "learning_rate": 0.027073943893870963,
      "loss": 0.5887,
      "step": 452320
    },
    {
      "epoch": 729.58,
      "learning_rate": 0.02707071809064516,
      "loss": 0.5845,
      "step": 452340
    },
    {
      "epoch": 729.61,
      "learning_rate": 0.02706749228741935,
      "loss": 0.5814,
      "step": 452360
    },
    {
      "epoch": 729.65,
      "learning_rate": 0.027064266484193546,
      "loss": 0.5876,
      "step": 452380
    },
    {
      "epoch": 729.68,
      "learning_rate": 0.027061040680967742,
      "loss": 0.5825,
      "step": 452400
    },
    {
      "epoch": 729.71,
      "learning_rate": 0.027057814877741934,
      "loss": 0.5944,
      "step": 452420
    },
    {
      "epoch": 729.74,
      "learning_rate": 0.02705458907451613,
      "loss": 0.5776,
      "step": 452440
    },
    {
      "epoch": 729.77,
      "learning_rate": 0.02705136327129032,
      "loss": 0.5967,
      "step": 452460
    },
    {
      "epoch": 729.81,
      "learning_rate": 0.027048137468064518,
      "loss": 0.5962,
      "step": 452480
    },
    {
      "epoch": 729.84,
      "learning_rate": 0.027044911664838713,
      "loss": 0.5893,
      "step": 452500
    },
    {
      "epoch": 729.87,
      "learning_rate": 0.027041685861612902,
      "loss": 0.5838,
      "step": 452520
    },
    {
      "epoch": 729.9,
      "learning_rate": 0.0270384600583871,
      "loss": 0.5905,
      "step": 452540
    },
    {
      "epoch": 729.94,
      "learning_rate": 0.02703523425516129,
      "loss": 0.587,
      "step": 452560
    },
    {
      "epoch": 729.97,
      "learning_rate": 0.027032008451935485,
      "loss": 0.5872,
      "step": 452580
    },
    {
      "epoch": 730.0,
      "learning_rate": 0.027028782648709684,
      "loss": 0.5866,
      "step": 452600
    },
    {
      "epoch": 730.0,
      "eval_accuracy": {
        "accuracy": 0.7779252205136211
      },
      "eval_loss": 0.9546709656715393,
      "eval_runtime": 3.1718,
      "eval_samples_per_second": 4039.002,
      "eval_steps_per_second": 63.37,
      "step": 452600
    },
    {
      "epoch": 730.03,
      "learning_rate": 0.02702555684548387,
      "loss": 0.6022,
      "step": 452620
    },
    {
      "epoch": 730.06,
      "learning_rate": 0.02702233104225806,
      "loss": 0.5708,
      "step": 452640
    },
    {
      "epoch": 730.1,
      "learning_rate": 0.027019105239032254,
      "loss": 0.5823,
      "step": 452660
    },
    {
      "epoch": 730.13,
      "learning_rate": 0.027015879435806453,
      "loss": 0.5625,
      "step": 452680
    },
    {
      "epoch": 730.16,
      "learning_rate": 0.02701265363258064,
      "loss": 0.5694,
      "step": 452700
    },
    {
      "epoch": 730.19,
      "learning_rate": 0.027009427829354837,
      "loss": 0.5635,
      "step": 452720
    },
    {
      "epoch": 730.23,
      "learning_rate": 0.027006202026129036,
      "loss": 0.5815,
      "step": 452740
    },
    {
      "epoch": 730.26,
      "learning_rate": 0.027002976222903225,
      "loss": 0.5869,
      "step": 452760
    },
    {
      "epoch": 730.29,
      "learning_rate": 0.02699975041967742,
      "loss": 0.5875,
      "step": 452780
    },
    {
      "epoch": 730.32,
      "learning_rate": 0.026996524616451613,
      "loss": 0.5852,
      "step": 452800
    },
    {
      "epoch": 730.35,
      "learning_rate": 0.02699329881322581,
      "loss": 0.5782,
      "step": 452820
    },
    {
      "epoch": 730.39,
      "learning_rate": 0.026990073010000004,
      "loss": 0.5815,
      "step": 452840
    },
    {
      "epoch": 730.42,
      "learning_rate": 0.026986847206774196,
      "loss": 0.5783,
      "step": 452860
    },
    {
      "epoch": 730.45,
      "learning_rate": 0.026983621403548392,
      "loss": 0.5798,
      "step": 452880
    },
    {
      "epoch": 730.48,
      "learning_rate": 0.026980395600322584,
      "loss": 0.5727,
      "step": 452900
    },
    {
      "epoch": 730.52,
      "learning_rate": 0.02697716979709677,
      "loss": 0.5935,
      "step": 452920
    },
    {
      "epoch": 730.55,
      "learning_rate": 0.026973943993870965,
      "loss": 0.5871,
      "step": 452940
    },
    {
      "epoch": 730.58,
      "learning_rate": 0.026970718190645157,
      "loss": 0.5751,
      "step": 452960
    },
    {
      "epoch": 730.61,
      "learning_rate": 0.026967492387419353,
      "loss": 0.5878,
      "step": 452980
    },
    {
      "epoch": 730.65,
      "learning_rate": 0.02696426658419354,
      "loss": 0.5799,
      "step": 453000
    },
    {
      "epoch": 730.68,
      "learning_rate": 0.02696104078096774,
      "loss": 0.5777,
      "step": 453020
    },
    {
      "epoch": 730.71,
      "learning_rate": 0.026957814977741936,
      "loss": 0.5855,
      "step": 453040
    },
    {
      "epoch": 730.74,
      "learning_rate": 0.026954589174516125,
      "loss": 0.5916,
      "step": 453060
    },
    {
      "epoch": 730.77,
      "learning_rate": 0.026951363371290324,
      "loss": 0.5843,
      "step": 453080
    },
    {
      "epoch": 730.81,
      "learning_rate": 0.026948137568064513,
      "loss": 0.5876,
      "step": 453100
    },
    {
      "epoch": 730.84,
      "learning_rate": 0.026944911764838708,
      "loss": 0.5829,
      "step": 453120
    },
    {
      "epoch": 730.87,
      "learning_rate": 0.026941685961612907,
      "loss": 0.5913,
      "step": 453140
    },
    {
      "epoch": 730.9,
      "learning_rate": 0.026938460158387096,
      "loss": 0.5859,
      "step": 453160
    },
    {
      "epoch": 730.94,
      "learning_rate": 0.02693523435516129,
      "loss": 0.5967,
      "step": 453180
    },
    {
      "epoch": 730.97,
      "learning_rate": 0.02693200855193549,
      "loss": 0.5981,
      "step": 453200
    },
    {
      "epoch": 731.0,
      "learning_rate": 0.02692878274870968,
      "loss": 0.589,
      "step": 453220
    },
    {
      "epoch": 731.0,
      "eval_accuracy": {
        "accuracy": 0.7742564983217547
      },
      "eval_loss": 0.9606647491455078,
      "eval_runtime": 2.9692,
      "eval_samples_per_second": 4314.6,
      "eval_steps_per_second": 67.695,
      "step": 453220
    },
    {
      "epoch": 731.03,
      "learning_rate": 0.026925556945483865,
      "loss": 0.5879,
      "step": 453240
    },
    {
      "epoch": 731.06,
      "learning_rate": 0.02692233114225806,
      "loss": 0.5758,
      "step": 453260
    },
    {
      "epoch": 731.1,
      "learning_rate": 0.02691910533903226,
      "loss": 0.5819,
      "step": 453280
    },
    {
      "epoch": 731.13,
      "learning_rate": 0.026915879535806448,
      "loss": 0.5877,
      "step": 453300
    },
    {
      "epoch": 731.16,
      "learning_rate": 0.026912653732580644,
      "loss": 0.589,
      "step": 453320
    },
    {
      "epoch": 731.19,
      "learning_rate": 0.026909427929354836,
      "loss": 0.5778,
      "step": 453340
    },
    {
      "epoch": 731.23,
      "learning_rate": 0.02690620212612903,
      "loss": 0.5763,
      "step": 453360
    },
    {
      "epoch": 731.26,
      "learning_rate": 0.026902976322903227,
      "loss": 0.5858,
      "step": 453380
    },
    {
      "epoch": 731.29,
      "learning_rate": 0.02689975051967742,
      "loss": 0.5773,
      "step": 453400
    },
    {
      "epoch": 731.32,
      "learning_rate": 0.026896524716451615,
      "loss": 0.5859,
      "step": 453420
    },
    {
      "epoch": 731.35,
      "learning_rate": 0.026893298913225807,
      "loss": 0.5801,
      "step": 453440
    },
    {
      "epoch": 731.39,
      "learning_rate": 0.026890073110000003,
      "loss": 0.5882,
      "step": 453460
    },
    {
      "epoch": 731.42,
      "learning_rate": 0.026886847306774198,
      "loss": 0.5752,
      "step": 453480
    },
    {
      "epoch": 731.45,
      "learning_rate": 0.02688362150354839,
      "loss": 0.5848,
      "step": 453500
    },
    {
      "epoch": 731.48,
      "learning_rate": 0.026880395700322586,
      "loss": 0.5994,
      "step": 453520
    },
    {
      "epoch": 731.52,
      "learning_rate": 0.026877169897096764,
      "loss": 0.5729,
      "step": 453540
    },
    {
      "epoch": 731.55,
      "learning_rate": 0.026873944093870963,
      "loss": 0.5936,
      "step": 453560
    },
    {
      "epoch": 731.58,
      "learning_rate": 0.02687071829064516,
      "loss": 0.591,
      "step": 453580
    },
    {
      "epoch": 731.61,
      "learning_rate": 0.026867492487419348,
      "loss": 0.5756,
      "step": 453600
    },
    {
      "epoch": 731.65,
      "learning_rate": 0.026864266684193547,
      "loss": 0.5993,
      "step": 453620
    },
    {
      "epoch": 731.68,
      "learning_rate": 0.026861040880967735,
      "loss": 0.5986,
      "step": 453640
    },
    {
      "epoch": 731.71,
      "learning_rate": 0.02685781507774193,
      "loss": 0.5843,
      "step": 453660
    },
    {
      "epoch": 731.74,
      "learning_rate": 0.02685458927451613,
      "loss": 0.5866,
      "step": 453680
    },
    {
      "epoch": 731.77,
      "learning_rate": 0.02685136347129032,
      "loss": 0.5819,
      "step": 453700
    },
    {
      "epoch": 731.81,
      "learning_rate": 0.026848137668064515,
      "loss": 0.5755,
      "step": 453720
    },
    {
      "epoch": 731.84,
      "learning_rate": 0.026844911864838714,
      "loss": 0.5805,
      "step": 453740
    },
    {
      "epoch": 731.87,
      "learning_rate": 0.026841686061612902,
      "loss": 0.5765,
      "step": 453760
    },
    {
      "epoch": 731.9,
      "learning_rate": 0.026838460258387098,
      "loss": 0.5988,
      "step": 453780
    },
    {
      "epoch": 731.94,
      "learning_rate": 0.026835234455161297,
      "loss": 0.5898,
      "step": 453800
    },
    {
      "epoch": 731.97,
      "learning_rate": 0.026832008651935486,
      "loss": 0.5816,
      "step": 453820
    },
    {
      "epoch": 732.0,
      "learning_rate": 0.02682878284870968,
      "loss": 0.5764,
      "step": 453840
    },
    {
      "epoch": 732.0,
      "eval_accuracy": {
        "accuracy": 0.7714464132386231
      },
      "eval_loss": 0.9643179178237915,
      "eval_runtime": 3.3375,
      "eval_samples_per_second": 3838.47,
      "eval_steps_per_second": 60.224,
      "step": 453840
    },
    {
      "epoch": 732.03,
      "learning_rate": 0.026825557045483867,
      "loss": 0.5877,
      "step": 453860
    },
    {
      "epoch": 732.06,
      "learning_rate": 0.02682233124225806,
      "loss": 0.5815,
      "step": 453880
    },
    {
      "epoch": 732.1,
      "learning_rate": 0.026819105439032254,
      "loss": 0.5818,
      "step": 453900
    },
    {
      "epoch": 732.13,
      "learning_rate": 0.02681587963580645,
      "loss": 0.5796,
      "step": 453920
    },
    {
      "epoch": 732.16,
      "learning_rate": 0.026812653832580642,
      "loss": 0.5917,
      "step": 453940
    },
    {
      "epoch": 732.19,
      "learning_rate": 0.026809428029354838,
      "loss": 0.5772,
      "step": 453960
    },
    {
      "epoch": 732.23,
      "learning_rate": 0.02680620222612903,
      "loss": 0.5757,
      "step": 453980
    },
    {
      "epoch": 732.26,
      "learning_rate": 0.026802976422903226,
      "loss": 0.5806,
      "step": 454000
    },
    {
      "epoch": 732.29,
      "learning_rate": 0.02679975061967742,
      "loss": 0.5795,
      "step": 454020
    },
    {
      "epoch": 732.32,
      "learning_rate": 0.026796524816451613,
      "loss": 0.5728,
      "step": 454040
    },
    {
      "epoch": 732.35,
      "learning_rate": 0.02679329901322581,
      "loss": 0.5845,
      "step": 454060
    },
    {
      "epoch": 732.39,
      "learning_rate": 0.026790073210000005,
      "loss": 0.5756,
      "step": 454080
    },
    {
      "epoch": 732.42,
      "learning_rate": 0.026786847406774197,
      "loss": 0.5739,
      "step": 454100
    },
    {
      "epoch": 732.45,
      "learning_rate": 0.026783621603548392,
      "loss": 0.5876,
      "step": 454120
    },
    {
      "epoch": 732.48,
      "learning_rate": 0.026780395800322584,
      "loss": 0.5908,
      "step": 454140
    },
    {
      "epoch": 732.52,
      "learning_rate": 0.02677716999709677,
      "loss": 0.5811,
      "step": 454160
    },
    {
      "epoch": 732.55,
      "learning_rate": 0.02677394419387096,
      "loss": 0.5833,
      "step": 454180
    },
    {
      "epoch": 732.58,
      "learning_rate": 0.026770718390645154,
      "loss": 0.583,
      "step": 454200
    },
    {
      "epoch": 732.61,
      "learning_rate": 0.026767492587419353,
      "loss": 0.5692,
      "step": 454220
    },
    {
      "epoch": 732.65,
      "learning_rate": 0.026764266784193542,
      "loss": 0.5768,
      "step": 454240
    },
    {
      "epoch": 732.68,
      "learning_rate": 0.026761040980967737,
      "loss": 0.5911,
      "step": 454260
    },
    {
      "epoch": 732.71,
      "learning_rate": 0.026757815177741937,
      "loss": 0.588,
      "step": 454280
    },
    {
      "epoch": 732.74,
      "learning_rate": 0.026754589374516125,
      "loss": 0.5848,
      "step": 454300
    },
    {
      "epoch": 732.77,
      "learning_rate": 0.02675136357129032,
      "loss": 0.5866,
      "step": 454320
    },
    {
      "epoch": 732.81,
      "learning_rate": 0.02674813776806452,
      "loss": 0.585,
      "step": 454340
    },
    {
      "epoch": 732.84,
      "learning_rate": 0.02674491196483871,
      "loss": 0.5729,
      "step": 454360
    },
    {
      "epoch": 732.87,
      "learning_rate": 0.026741686161612904,
      "loss": 0.5749,
      "step": 454380
    },
    {
      "epoch": 732.9,
      "learning_rate": 0.026738460358387103,
      "loss": 0.5768,
      "step": 454400
    },
    {
      "epoch": 732.94,
      "learning_rate": 0.026735234555161292,
      "loss": 0.6,
      "step": 454420
    },
    {
      "epoch": 732.97,
      "learning_rate": 0.026732008751935488,
      "loss": 0.5952,
      "step": 454440
    },
    {
      "epoch": 733.0,
      "learning_rate": 0.026728782948709687,
      "loss": 0.5993,
      "step": 454460
    },
    {
      "epoch": 733.0,
      "eval_accuracy": {
        "accuracy": 0.7750370775115135
      },
      "eval_loss": 0.9478812217712402,
      "eval_runtime": 3.0259,
      "eval_samples_per_second": 4233.721,
      "eval_steps_per_second": 66.426,
      "step": 454460
    },
    {
      "epoch": 733.03,
      "learning_rate": 0.026725557145483865,
      "loss": 0.5967,
      "step": 454480
    },
    {
      "epoch": 733.06,
      "learning_rate": 0.02672233134225806,
      "loss": 0.5613,
      "step": 454500
    },
    {
      "epoch": 733.1,
      "learning_rate": 0.026719105539032253,
      "loss": 0.5698,
      "step": 454520
    },
    {
      "epoch": 733.13,
      "learning_rate": 0.02671587973580645,
      "loss": 0.5713,
      "step": 454540
    },
    {
      "epoch": 733.16,
      "learning_rate": 0.026712653932580644,
      "loss": 0.5843,
      "step": 454560
    },
    {
      "epoch": 733.19,
      "learning_rate": 0.026709428129354836,
      "loss": 0.5755,
      "step": 454580
    },
    {
      "epoch": 733.23,
      "learning_rate": 0.026706202326129032,
      "loss": 0.5741,
      "step": 454600
    },
    {
      "epoch": 733.26,
      "learning_rate": 0.026702976522903224,
      "loss": 0.591,
      "step": 454620
    },
    {
      "epoch": 733.29,
      "learning_rate": 0.02669975071967742,
      "loss": 0.5819,
      "step": 454640
    },
    {
      "epoch": 733.32,
      "learning_rate": 0.026696524916451615,
      "loss": 0.5879,
      "step": 454660
    },
    {
      "epoch": 733.35,
      "learning_rate": 0.026693299113225807,
      "loss": 0.5915,
      "step": 454680
    },
    {
      "epoch": 733.39,
      "learning_rate": 0.026690073310000003,
      "loss": 0.5884,
      "step": 454700
    },
    {
      "epoch": 733.42,
      "learning_rate": 0.0266868475067742,
      "loss": 0.5794,
      "step": 454720
    },
    {
      "epoch": 733.45,
      "learning_rate": 0.02668362170354839,
      "loss": 0.5801,
      "step": 454740
    },
    {
      "epoch": 733.48,
      "learning_rate": 0.026680395900322586,
      "loss": 0.5827,
      "step": 454760
    },
    {
      "epoch": 733.52,
      "learning_rate": 0.026677170097096775,
      "loss": 0.586,
      "step": 454780
    },
    {
      "epoch": 733.55,
      "learning_rate": 0.02667394429387096,
      "loss": 0.6004,
      "step": 454800
    },
    {
      "epoch": 733.58,
      "learning_rate": 0.02667071849064516,
      "loss": 0.5856,
      "step": 454820
    },
    {
      "epoch": 733.61,
      "learning_rate": 0.026667492687419348,
      "loss": 0.5776,
      "step": 454840
    },
    {
      "epoch": 733.65,
      "learning_rate": 0.026664266884193544,
      "loss": 0.589,
      "step": 454860
    },
    {
      "epoch": 733.68,
      "learning_rate": 0.026661041080967743,
      "loss": 0.5833,
      "step": 454880
    },
    {
      "epoch": 733.71,
      "learning_rate": 0.02665781527774193,
      "loss": 0.5898,
      "step": 454900
    },
    {
      "epoch": 733.74,
      "learning_rate": 0.026654589474516127,
      "loss": 0.5739,
      "step": 454920
    },
    {
      "epoch": 733.77,
      "learning_rate": 0.026651363671290326,
      "loss": 0.5775,
      "step": 454940
    },
    {
      "epoch": 733.81,
      "learning_rate": 0.026648137868064515,
      "loss": 0.5932,
      "step": 454960
    },
    {
      "epoch": 733.84,
      "learning_rate": 0.02664491206483871,
      "loss": 0.5944,
      "step": 454980
    },
    {
      "epoch": 733.87,
      "learning_rate": 0.02664168626161291,
      "loss": 0.5819,
      "step": 455000
    },
    {
      "epoch": 733.9,
      "learning_rate": 0.0266384604583871,
      "loss": 0.5853,
      "step": 455020
    },
    {
      "epoch": 733.94,
      "learning_rate": 0.026635234655161294,
      "loss": 0.5806,
      "step": 455040
    },
    {
      "epoch": 733.97,
      "learning_rate": 0.026632008851935493,
      "loss": 0.5753,
      "step": 455060
    },
    {
      "epoch": 734.0,
      "learning_rate": 0.026628944338870964,
      "loss": 0.5826,
      "step": 455080
    },
    {
      "epoch": 734.0,
      "eval_accuracy": {
        "accuracy": 0.7749590195925377
      },
      "eval_loss": 0.9547057747840881,
      "eval_runtime": 3.0921,
      "eval_samples_per_second": 4143.194,
      "eval_steps_per_second": 65.005,
      "step": 455080
    },
    {
      "epoch": 734.03,
      "learning_rate": 0.02662571853564516,
      "loss": 0.5796,
      "step": 455100
    },
    {
      "epoch": 734.06,
      "learning_rate": 0.02662249273241936,
      "loss": 0.5727,
      "step": 455120
    },
    {
      "epoch": 734.1,
      "learning_rate": 0.026619266929193548,
      "loss": 0.5705,
      "step": 455140
    },
    {
      "epoch": 734.13,
      "learning_rate": 0.026616041125967743,
      "loss": 0.5774,
      "step": 455160
    },
    {
      "epoch": 734.16,
      "learning_rate": 0.026612815322741942,
      "loss": 0.5839,
      "step": 455180
    },
    {
      "epoch": 734.19,
      "learning_rate": 0.02660958951951613,
      "loss": 0.5891,
      "step": 455200
    },
    {
      "epoch": 734.23,
      "learning_rate": 0.026606363716290327,
      "loss": 0.5821,
      "step": 455220
    },
    {
      "epoch": 734.26,
      "learning_rate": 0.026603137913064512,
      "loss": 0.5894,
      "step": 455240
    },
    {
      "epoch": 734.29,
      "learning_rate": 0.026599912109838704,
      "loss": 0.5761,
      "step": 455260
    },
    {
      "epoch": 734.32,
      "learning_rate": 0.0265966863066129,
      "loss": 0.5746,
      "step": 455280
    },
    {
      "epoch": 734.35,
      "learning_rate": 0.026593460503387095,
      "loss": 0.5713,
      "step": 455300
    },
    {
      "epoch": 734.39,
      "learning_rate": 0.026590234700161287,
      "loss": 0.5785,
      "step": 455320
    },
    {
      "epoch": 734.42,
      "learning_rate": 0.026587008896935483,
      "loss": 0.5758,
      "step": 455340
    },
    {
      "epoch": 734.45,
      "learning_rate": 0.026583783093709675,
      "loss": 0.5849,
      "step": 455360
    },
    {
      "epoch": 734.48,
      "learning_rate": 0.02658055729048387,
      "loss": 0.573,
      "step": 455380
    },
    {
      "epoch": 734.52,
      "learning_rate": 0.026577331487258066,
      "loss": 0.5877,
      "step": 455400
    },
    {
      "epoch": 734.55,
      "learning_rate": 0.02657410568403226,
      "loss": 0.5918,
      "step": 455420
    },
    {
      "epoch": 734.58,
      "learning_rate": 0.026570879880806454,
      "loss": 0.5772,
      "step": 455440
    },
    {
      "epoch": 734.61,
      "learning_rate": 0.026567654077580646,
      "loss": 0.5782,
      "step": 455460
    },
    {
      "epoch": 734.65,
      "learning_rate": 0.026564428274354842,
      "loss": 0.5787,
      "step": 455480
    },
    {
      "epoch": 734.68,
      "learning_rate": 0.026561202471129038,
      "loss": 0.5706,
      "step": 455500
    },
    {
      "epoch": 734.71,
      "learning_rate": 0.02655797666790323,
      "loss": 0.5875,
      "step": 455520
    },
    {
      "epoch": 734.74,
      "learning_rate": 0.026554750864677425,
      "loss": 0.5802,
      "step": 455540
    },
    {
      "epoch": 734.77,
      "learning_rate": 0.026551525061451604,
      "loss": 0.5827,
      "step": 455560
    },
    {
      "epoch": 734.81,
      "learning_rate": 0.0265482992582258,
      "loss": 0.5911,
      "step": 455580
    },
    {
      "epoch": 734.84,
      "learning_rate": 0.026545073455,
      "loss": 0.5737,
      "step": 455600
    },
    {
      "epoch": 734.87,
      "learning_rate": 0.026541847651774187,
      "loss": 0.5818,
      "step": 455620
    },
    {
      "epoch": 734.9,
      "learning_rate": 0.026538621848548383,
      "loss": 0.5744,
      "step": 455640
    },
    {
      "epoch": 734.94,
      "learning_rate": 0.026535396045322582,
      "loss": 0.5911,
      "step": 455660
    },
    {
      "epoch": 734.97,
      "learning_rate": 0.02653217024209677,
      "loss": 0.5834,
      "step": 455680
    },
    {
      "epoch": 735.0,
      "learning_rate": 0.026528944438870966,
      "loss": 0.5737,
      "step": 455700
    },
    {
      "epoch": 735.0,
      "eval_accuracy": {
        "accuracy": 0.7768324096479587
      },
      "eval_loss": 0.9409583806991577,
      "eval_runtime": 3.0522,
      "eval_samples_per_second": 4197.328,
      "eval_steps_per_second": 65.855,
      "step": 455700
    },
    {
      "epoch": 735.03,
      "learning_rate": 0.026525718635645165,
      "loss": 0.5846,
      "step": 455720
    },
    {
      "epoch": 735.06,
      "learning_rate": 0.026522492832419354,
      "loss": 0.5904,
      "step": 455740
    },
    {
      "epoch": 735.1,
      "learning_rate": 0.02651926702919355,
      "loss": 0.5751,
      "step": 455760
    },
    {
      "epoch": 735.13,
      "learning_rate": 0.02651604122596775,
      "loss": 0.5626,
      "step": 455780
    },
    {
      "epoch": 735.16,
      "learning_rate": 0.026512815422741937,
      "loss": 0.5742,
      "step": 455800
    },
    {
      "epoch": 735.19,
      "learning_rate": 0.026509589619516133,
      "loss": 0.5708,
      "step": 455820
    },
    {
      "epoch": 735.23,
      "learning_rate": 0.026506363816290332,
      "loss": 0.578,
      "step": 455840
    },
    {
      "epoch": 735.26,
      "learning_rate": 0.02650313801306451,
      "loss": 0.5793,
      "step": 455860
    },
    {
      "epoch": 735.29,
      "learning_rate": 0.026499912209838706,
      "loss": 0.5869,
      "step": 455880
    },
    {
      "epoch": 735.32,
      "learning_rate": 0.026496686406612898,
      "loss": 0.5706,
      "step": 455900
    },
    {
      "epoch": 735.35,
      "learning_rate": 0.026493460603387094,
      "loss": 0.5688,
      "step": 455920
    },
    {
      "epoch": 735.39,
      "learning_rate": 0.02649023480016129,
      "loss": 0.59,
      "step": 455940
    },
    {
      "epoch": 735.42,
      "learning_rate": 0.02648700899693548,
      "loss": 0.5742,
      "step": 455960
    },
    {
      "epoch": 735.45,
      "learning_rate": 0.026483783193709677,
      "loss": 0.587,
      "step": 455980
    },
    {
      "epoch": 735.48,
      "learning_rate": 0.02648055739048387,
      "loss": 0.5824,
      "step": 456000
    },
    {
      "epoch": 735.52,
      "learning_rate": 0.026477331587258065,
      "loss": 0.6019,
      "step": 456020
    },
    {
      "epoch": 735.55,
      "learning_rate": 0.02647410578403226,
      "loss": 0.5849,
      "step": 456040
    },
    {
      "epoch": 735.58,
      "learning_rate": 0.026470879980806453,
      "loss": 0.5906,
      "step": 456060
    },
    {
      "epoch": 735.61,
      "learning_rate": 0.02646765417758065,
      "loss": 0.5941,
      "step": 456080
    },
    {
      "epoch": 735.65,
      "learning_rate": 0.026464428374354837,
      "loss": 0.5734,
      "step": 456100
    },
    {
      "epoch": 735.68,
      "learning_rate": 0.026461202571129036,
      "loss": 0.588,
      "step": 456120
    },
    {
      "epoch": 735.71,
      "learning_rate": 0.02645797676790323,
      "loss": 0.5903,
      "step": 456140
    },
    {
      "epoch": 735.74,
      "learning_rate": 0.02645475096467742,
      "loss": 0.5886,
      "step": 456160
    },
    {
      "epoch": 735.77,
      "learning_rate": 0.026451525161451606,
      "loss": 0.5648,
      "step": 456180
    },
    {
      "epoch": 735.81,
      "learning_rate": 0.026448299358225805,
      "loss": 0.571,
      "step": 456200
    },
    {
      "epoch": 735.84,
      "learning_rate": 0.026445073554999993,
      "loss": 0.5876,
      "step": 456220
    },
    {
      "epoch": 735.87,
      "learning_rate": 0.02644184775177419,
      "loss": 0.5833,
      "step": 456240
    },
    {
      "epoch": 735.9,
      "learning_rate": 0.026438621948548388,
      "loss": 0.5823,
      "step": 456260
    },
    {
      "epoch": 735.94,
      "learning_rate": 0.026435396145322577,
      "loss": 0.5982,
      "step": 456280
    },
    {
      "epoch": 735.97,
      "learning_rate": 0.026432170342096772,
      "loss": 0.5759,
      "step": 456300
    },
    {
      "epoch": 736.0,
      "learning_rate": 0.02642894453887097,
      "loss": 0.5895,
      "step": 456320
    },
    {
      "epoch": 736.0,
      "eval_accuracy": {
        "accuracy": 0.7765201779720553
      },
      "eval_loss": 0.9482572078704834,
      "eval_runtime": 2.9442,
      "eval_samples_per_second": 4351.215,
      "eval_steps_per_second": 68.269,
      "step": 456320
    },
    {
      "epoch": 736.03,
      "learning_rate": 0.02642571873564516,
      "loss": 0.5906,
      "step": 456340
    },
    {
      "epoch": 736.06,
      "learning_rate": 0.026422492932419356,
      "loss": 0.5831,
      "step": 456360
    },
    {
      "epoch": 736.1,
      "learning_rate": 0.026419267129193555,
      "loss": 0.5837,
      "step": 456380
    },
    {
      "epoch": 736.13,
      "learning_rate": 0.026416041325967744,
      "loss": 0.5691,
      "step": 456400
    },
    {
      "epoch": 736.16,
      "learning_rate": 0.02641281552274194,
      "loss": 0.5726,
      "step": 456420
    },
    {
      "epoch": 736.19,
      "learning_rate": 0.02640958971951614,
      "loss": 0.5759,
      "step": 456440
    },
    {
      "epoch": 736.23,
      "learning_rate": 0.026406363916290327,
      "loss": 0.5816,
      "step": 456460
    },
    {
      "epoch": 736.26,
      "learning_rate": 0.026403138113064512,
      "loss": 0.5832,
      "step": 456480
    },
    {
      "epoch": 736.29,
      "learning_rate": 0.026399912309838704,
      "loss": 0.5712,
      "step": 456500
    },
    {
      "epoch": 736.32,
      "learning_rate": 0.0263966865066129,
      "loss": 0.573,
      "step": 456520
    },
    {
      "epoch": 736.35,
      "learning_rate": 0.026393460703387092,
      "loss": 0.5671,
      "step": 456540
    },
    {
      "epoch": 736.39,
      "learning_rate": 0.026390234900161288,
      "loss": 0.5747,
      "step": 456560
    },
    {
      "epoch": 736.42,
      "learning_rate": 0.026387009096935483,
      "loss": 0.5792,
      "step": 456580
    },
    {
      "epoch": 736.45,
      "learning_rate": 0.026383783293709676,
      "loss": 0.5761,
      "step": 456600
    },
    {
      "epoch": 736.48,
      "learning_rate": 0.02638055749048387,
      "loss": 0.5676,
      "step": 456620
    },
    {
      "epoch": 736.52,
      "learning_rate": 0.02637733168725806,
      "loss": 0.5694,
      "step": 456640
    },
    {
      "epoch": 736.55,
      "learning_rate": 0.02637410588403226,
      "loss": 0.5723,
      "step": 456660
    },
    {
      "epoch": 736.58,
      "learning_rate": 0.026370880080806455,
      "loss": 0.5854,
      "step": 456680
    },
    {
      "epoch": 736.61,
      "learning_rate": 0.026367654277580643,
      "loss": 0.5801,
      "step": 456700
    },
    {
      "epoch": 736.65,
      "learning_rate": 0.026364428474354842,
      "loss": 0.5893,
      "step": 456720
    },
    {
      "epoch": 736.68,
      "learning_rate": 0.02636120267112903,
      "loss": 0.5967,
      "step": 456740
    },
    {
      "epoch": 736.71,
      "learning_rate": 0.026357976867903227,
      "loss": 0.5952,
      "step": 456760
    },
    {
      "epoch": 736.74,
      "learning_rate": 0.026354751064677426,
      "loss": 0.5875,
      "step": 456780
    },
    {
      "epoch": 736.77,
      "learning_rate": 0.02635152526145161,
      "loss": 0.6034,
      "step": 456800
    },
    {
      "epoch": 736.81,
      "learning_rate": 0.0263482994582258,
      "loss": 0.5889,
      "step": 456820
    },
    {
      "epoch": 736.84,
      "learning_rate": 0.026345073654999995,
      "loss": 0.5825,
      "step": 456840
    },
    {
      "epoch": 736.87,
      "learning_rate": 0.026341847851774194,
      "loss": 0.5871,
      "step": 456860
    },
    {
      "epoch": 736.9,
      "learning_rate": 0.026338622048548383,
      "loss": 0.5772,
      "step": 456880
    },
    {
      "epoch": 736.94,
      "learning_rate": 0.02633539624532258,
      "loss": 0.5982,
      "step": 456900
    },
    {
      "epoch": 736.97,
      "learning_rate": 0.026332170442096778,
      "loss": 0.5888,
      "step": 456920
    },
    {
      "epoch": 737.0,
      "learning_rate": 0.026328944638870967,
      "loss": 0.5875,
      "step": 456940
    },
    {
      "epoch": 737.0,
      "eval_accuracy": {
        "accuracy": 0.7752712512684412
      },
      "eval_loss": 0.9452702403068542,
      "eval_runtime": 3.0131,
      "eval_samples_per_second": 4251.733,
      "eval_steps_per_second": 66.708,
      "step": 456940
    },
    {
      "epoch": 737.03,
      "learning_rate": 0.026325718835645162,
      "loss": 0.5869,
      "step": 456960
    },
    {
      "epoch": 737.06,
      "learning_rate": 0.02632249303241936,
      "loss": 0.5756,
      "step": 456980
    },
    {
      "epoch": 737.1,
      "learning_rate": 0.02631926722919355,
      "loss": 0.5712,
      "step": 457000
    },
    {
      "epoch": 737.13,
      "learning_rate": 0.026316041425967746,
      "loss": 0.5815,
      "step": 457020
    },
    {
      "epoch": 737.16,
      "learning_rate": 0.026312815622741938,
      "loss": 0.5723,
      "step": 457040
    },
    {
      "epoch": 737.19,
      "learning_rate": 0.026309589819516133,
      "loss": 0.562,
      "step": 457060
    },
    {
      "epoch": 737.23,
      "learning_rate": 0.02630636401629033,
      "loss": 0.565,
      "step": 457080
    },
    {
      "epoch": 737.26,
      "learning_rate": 0.02630313821306452,
      "loss": 0.5628,
      "step": 457100
    },
    {
      "epoch": 737.29,
      "learning_rate": 0.026299912409838706,
      "loss": 0.5804,
      "step": 457120
    },
    {
      "epoch": 737.32,
      "learning_rate": 0.0262966866066129,
      "loss": 0.5769,
      "step": 457140
    },
    {
      "epoch": 737.35,
      "learning_rate": 0.026293460803387094,
      "loss": 0.5876,
      "step": 457160
    },
    {
      "epoch": 737.39,
      "learning_rate": 0.026290235000161283,
      "loss": 0.5843,
      "step": 457180
    },
    {
      "epoch": 737.42,
      "learning_rate": 0.026287009196935482,
      "loss": 0.5914,
      "step": 457200
    },
    {
      "epoch": 737.45,
      "learning_rate": 0.026283783393709678,
      "loss": 0.5842,
      "step": 457220
    },
    {
      "epoch": 737.48,
      "learning_rate": 0.026280557590483866,
      "loss": 0.5849,
      "step": 457240
    },
    {
      "epoch": 737.52,
      "learning_rate": 0.026277331787258065,
      "loss": 0.5941,
      "step": 457260
    },
    {
      "epoch": 737.55,
      "learning_rate": 0.026274105984032254,
      "loss": 0.5782,
      "step": 457280
    },
    {
      "epoch": 737.58,
      "learning_rate": 0.02627088018080645,
      "loss": 0.5847,
      "step": 457300
    },
    {
      "epoch": 737.61,
      "learning_rate": 0.02626765437758065,
      "loss": 0.5863,
      "step": 457320
    },
    {
      "epoch": 737.65,
      "learning_rate": 0.026264428574354837,
      "loss": 0.5881,
      "step": 457340
    },
    {
      "epoch": 737.68,
      "learning_rate": 0.026261202771129033,
      "loss": 0.5751,
      "step": 457360
    },
    {
      "epoch": 737.71,
      "learning_rate": 0.026257976967903232,
      "loss": 0.5754,
      "step": 457380
    },
    {
      "epoch": 737.74,
      "learning_rate": 0.02625475116467742,
      "loss": 0.5763,
      "step": 457400
    },
    {
      "epoch": 737.77,
      "learning_rate": 0.026251525361451606,
      "loss": 0.5768,
      "step": 457420
    },
    {
      "epoch": 737.81,
      "learning_rate": 0.0262482995582258,
      "loss": 0.5906,
      "step": 457440
    },
    {
      "epoch": 737.84,
      "learning_rate": 0.026245073755,
      "loss": 0.5923,
      "step": 457460
    },
    {
      "epoch": 737.87,
      "learning_rate": 0.02624184795177419,
      "loss": 0.5837,
      "step": 457480
    },
    {
      "epoch": 737.9,
      "learning_rate": 0.026238622148548385,
      "loss": 0.5827,
      "step": 457500
    },
    {
      "epoch": 737.94,
      "learning_rate": 0.026235396345322584,
      "loss": 0.5839,
      "step": 457520
    },
    {
      "epoch": 737.97,
      "learning_rate": 0.026232170542096773,
      "loss": 0.5881,
      "step": 457540
    },
    {
      "epoch": 738.0,
      "learning_rate": 0.02622894473887097,
      "loss": 0.5777,
      "step": 457560
    },
    {
      "epoch": 738.0,
      "eval_accuracy": {
        "accuracy": 0.7747248458356101
      },
      "eval_loss": 0.9468895196914673,
      "eval_runtime": 2.9474,
      "eval_samples_per_second": 4346.566,
      "eval_steps_per_second": 68.196,
      "step": 457560
    },
    {
      "epoch": 738.03,
      "learning_rate": 0.02622571893564516,
      "loss": 0.5799,
      "step": 457580
    },
    {
      "epoch": 738.06,
      "learning_rate": 0.026222493132419356,
      "loss": 0.5659,
      "step": 457600
    },
    {
      "epoch": 738.1,
      "learning_rate": 0.026219267329193552,
      "loss": 0.5778,
      "step": 457620
    },
    {
      "epoch": 738.13,
      "learning_rate": 0.026216041525967744,
      "loss": 0.5662,
      "step": 457640
    },
    {
      "epoch": 738.16,
      "learning_rate": 0.02621281572274194,
      "loss": 0.5818,
      "step": 457660
    },
    {
      "epoch": 738.19,
      "learning_rate": 0.026209589919516132,
      "loss": 0.5691,
      "step": 457680
    },
    {
      "epoch": 738.23,
      "learning_rate": 0.026206364116290327,
      "loss": 0.5611,
      "step": 457700
    },
    {
      "epoch": 738.26,
      "learning_rate": 0.026203138313064523,
      "loss": 0.5711,
      "step": 457720
    },
    {
      "epoch": 738.29,
      "learning_rate": 0.026199912509838705,
      "loss": 0.5741,
      "step": 457740
    },
    {
      "epoch": 738.32,
      "learning_rate": 0.0261966867066129,
      "loss": 0.5738,
      "step": 457760
    },
    {
      "epoch": 738.35,
      "learning_rate": 0.02619346090338709,
      "loss": 0.5691,
      "step": 457780
    },
    {
      "epoch": 738.39,
      "learning_rate": 0.026190235100161288,
      "loss": 0.5755,
      "step": 457800
    },
    {
      "epoch": 738.42,
      "learning_rate": 0.026187009296935477,
      "loss": 0.5884,
      "step": 457820
    },
    {
      "epoch": 738.45,
      "learning_rate": 0.026183783493709673,
      "loss": 0.5927,
      "step": 457840
    },
    {
      "epoch": 738.48,
      "learning_rate": 0.02618055769048387,
      "loss": 0.5931,
      "step": 457860
    },
    {
      "epoch": 738.52,
      "learning_rate": 0.02617733188725806,
      "loss": 0.5685,
      "step": 457880
    },
    {
      "epoch": 738.55,
      "learning_rate": 0.026174106084032256,
      "loss": 0.575,
      "step": 457900
    },
    {
      "epoch": 738.58,
      "learning_rate": 0.026170880280806455,
      "loss": 0.6,
      "step": 457920
    },
    {
      "epoch": 738.61,
      "learning_rate": 0.026167654477580644,
      "loss": 0.5854,
      "step": 457940
    },
    {
      "epoch": 738.65,
      "learning_rate": 0.02616442867435484,
      "loss": 0.577,
      "step": 457960
    },
    {
      "epoch": 738.68,
      "learning_rate": 0.02616120287112904,
      "loss": 0.5747,
      "step": 457980
    },
    {
      "epoch": 738.71,
      "learning_rate": 0.026157977067903227,
      "loss": 0.5801,
      "step": 458000
    },
    {
      "epoch": 738.74,
      "learning_rate": 0.026154751264677423,
      "loss": 0.5751,
      "step": 458020
    },
    {
      "epoch": 738.77,
      "learning_rate": 0.026151525461451608,
      "loss": 0.5782,
      "step": 458040
    },
    {
      "epoch": 738.81,
      "learning_rate": 0.026148299658225807,
      "loss": 0.5773,
      "step": 458060
    },
    {
      "epoch": 738.84,
      "learning_rate": 0.026145073854999996,
      "loss": 0.5861,
      "step": 458080
    },
    {
      "epoch": 738.87,
      "learning_rate": 0.02614184805177419,
      "loss": 0.5836,
      "step": 458100
    },
    {
      "epoch": 738.9,
      "learning_rate": 0.026138622248548384,
      "loss": 0.5843,
      "step": 458120
    },
    {
      "epoch": 738.94,
      "learning_rate": 0.02613539644532258,
      "loss": 0.5935,
      "step": 458140
    },
    {
      "epoch": 738.97,
      "learning_rate": 0.026132170642096775,
      "loss": 0.5771,
      "step": 458160
    },
    {
      "epoch": 739.0,
      "learning_rate": 0.026128944838870967,
      "loss": 0.5802,
      "step": 458180
    },
    {
      "epoch": 739.0,
      "eval_accuracy": {
        "accuracy": 0.7764421200530793
      },
      "eval_loss": 0.9376463294029236,
      "eval_runtime": 2.9613,
      "eval_samples_per_second": 4326.07,
      "eval_steps_per_second": 67.874,
      "step": 458180
    },
    {
      "epoch": 739.03,
      "learning_rate": 0.026125719035645163,
      "loss": 0.5868,
      "step": 458200
    },
    {
      "epoch": 739.06,
      "learning_rate": 0.026122493232419355,
      "loss": 0.5527,
      "step": 458220
    },
    {
      "epoch": 739.1,
      "learning_rate": 0.02611926742919355,
      "loss": 0.5773,
      "step": 458240
    },
    {
      "epoch": 739.13,
      "learning_rate": 0.026116041625967746,
      "loss": 0.5737,
      "step": 458260
    },
    {
      "epoch": 739.16,
      "learning_rate": 0.026112815822741938,
      "loss": 0.5806,
      "step": 458280
    },
    {
      "epoch": 739.19,
      "learning_rate": 0.026109590019516134,
      "loss": 0.5744,
      "step": 458300
    },
    {
      "epoch": 739.23,
      "learning_rate": 0.026106364216290326,
      "loss": 0.5721,
      "step": 458320
    },
    {
      "epoch": 739.26,
      "learning_rate": 0.02610313841306452,
      "loss": 0.5853,
      "step": 458340
    },
    {
      "epoch": 739.29,
      "learning_rate": 0.0260999126098387,
      "loss": 0.5703,
      "step": 458360
    },
    {
      "epoch": 739.32,
      "learning_rate": 0.026096686806612895,
      "loss": 0.5859,
      "step": 458380
    },
    {
      "epoch": 739.35,
      "learning_rate": 0.026093461003387095,
      "loss": 0.5661,
      "step": 458400
    },
    {
      "epoch": 739.39,
      "learning_rate": 0.026090235200161283,
      "loss": 0.5809,
      "step": 458420
    },
    {
      "epoch": 739.42,
      "learning_rate": 0.02608700939693548,
      "loss": 0.5741,
      "step": 458440
    },
    {
      "epoch": 739.45,
      "learning_rate": 0.026083783593709678,
      "loss": 0.5761,
      "step": 458460
    },
    {
      "epoch": 739.48,
      "learning_rate": 0.026080557790483867,
      "loss": 0.5714,
      "step": 458480
    },
    {
      "epoch": 739.52,
      "learning_rate": 0.026077331987258062,
      "loss": 0.5793,
      "step": 458500
    },
    {
      "epoch": 739.55,
      "learning_rate": 0.02607410618403226,
      "loss": 0.5738,
      "step": 458520
    },
    {
      "epoch": 739.58,
      "learning_rate": 0.02607088038080645,
      "loss": 0.5833,
      "step": 458540
    },
    {
      "epoch": 739.61,
      "learning_rate": 0.026067654577580646,
      "loss": 0.5762,
      "step": 458560
    },
    {
      "epoch": 739.65,
      "learning_rate": 0.026064428774354845,
      "loss": 0.5753,
      "step": 458580
    },
    {
      "epoch": 739.68,
      "learning_rate": 0.026061202971129033,
      "loss": 0.5878,
      "step": 458600
    },
    {
      "epoch": 739.71,
      "learning_rate": 0.02605797716790323,
      "loss": 0.5794,
      "step": 458620
    },
    {
      "epoch": 739.74,
      "learning_rate": 0.026054751364677428,
      "loss": 0.5922,
      "step": 458640
    },
    {
      "epoch": 739.77,
      "learning_rate": 0.026051525561451606,
      "loss": 0.5881,
      "step": 458660
    },
    {
      "epoch": 739.81,
      "learning_rate": 0.026048299758225802,
      "loss": 0.5832,
      "step": 458680
    },
    {
      "epoch": 739.84,
      "learning_rate": 0.026045073954999998,
      "loss": 0.5868,
      "step": 458700
    },
    {
      "epoch": 739.87,
      "learning_rate": 0.02604184815177419,
      "loss": 0.5632,
      "step": 458720
    },
    {
      "epoch": 739.9,
      "learning_rate": 0.026038622348548385,
      "loss": 0.5831,
      "step": 458740
    },
    {
      "epoch": 739.94,
      "learning_rate": 0.026035396545322578,
      "loss": 0.5911,
      "step": 458760
    },
    {
      "epoch": 739.97,
      "learning_rate": 0.026032170742096773,
      "loss": 0.5695,
      "step": 458780
    },
    {
      "epoch": 740.0,
      "learning_rate": 0.02602894493887097,
      "loss": 0.577,
      "step": 458800
    },
    {
      "epoch": 740.0,
      "eval_accuracy": {
        "accuracy": 0.7751151354304894
      },
      "eval_loss": 0.9528746008872986,
      "eval_runtime": 4.0967,
      "eval_samples_per_second": 3127.124,
      "eval_steps_per_second": 49.063,
      "step": 458800
    },
    {
      "epoch": 740.03,
      "learning_rate": 0.02602571913564516,
      "loss": 0.5768,
      "step": 458820
    },
    {
      "epoch": 740.06,
      "learning_rate": 0.026022493332419357,
      "loss": 0.5627,
      "step": 458840
    },
    {
      "epoch": 740.1,
      "learning_rate": 0.02601926752919355,
      "loss": 0.5788,
      "step": 458860
    },
    {
      "epoch": 740.13,
      "learning_rate": 0.026016041725967744,
      "loss": 0.575,
      "step": 458880
    },
    {
      "epoch": 740.16,
      "learning_rate": 0.02601281592274194,
      "loss": 0.5677,
      "step": 458900
    },
    {
      "epoch": 740.19,
      "learning_rate": 0.026009590119516132,
      "loss": 0.5775,
      "step": 458920
    },
    {
      "epoch": 740.23,
      "learning_rate": 0.026006364316290328,
      "loss": 0.5731,
      "step": 458940
    },
    {
      "epoch": 740.26,
      "learning_rate": 0.026003138513064517,
      "loss": 0.5852,
      "step": 458960
    },
    {
      "epoch": 740.29,
      "learning_rate": 0.0259999127098387,
      "loss": 0.5742,
      "step": 458980
    },
    {
      "epoch": 740.32,
      "learning_rate": 0.0259966869066129,
      "loss": 0.5609,
      "step": 459000
    },
    {
      "epoch": 740.35,
      "learning_rate": 0.02599346110338709,
      "loss": 0.5619,
      "step": 459020
    },
    {
      "epoch": 740.39,
      "learning_rate": 0.025990235300161285,
      "loss": 0.5795,
      "step": 459040
    },
    {
      "epoch": 740.42,
      "learning_rate": 0.025987009496935484,
      "loss": 0.5858,
      "step": 459060
    },
    {
      "epoch": 740.45,
      "learning_rate": 0.025983783693709673,
      "loss": 0.5762,
      "step": 459080
    },
    {
      "epoch": 740.48,
      "learning_rate": 0.025980719180645165,
      "loss": 0.5712,
      "step": 459100
    },
    {
      "epoch": 740.52,
      "learning_rate": 0.02597749337741935,
      "loss": 0.5862,
      "step": 459120
    },
    {
      "epoch": 740.55,
      "learning_rate": 0.025974267574193546,
      "loss": 0.5725,
      "step": 459140
    },
    {
      "epoch": 740.58,
      "learning_rate": 0.025971041770967734,
      "loss": 0.5975,
      "step": 459160
    },
    {
      "epoch": 740.61,
      "learning_rate": 0.025967815967741933,
      "loss": 0.5744,
      "step": 459180
    },
    {
      "epoch": 740.65,
      "learning_rate": 0.025964590164516122,
      "loss": 0.5792,
      "step": 459200
    },
    {
      "epoch": 740.68,
      "learning_rate": 0.025961525651451618,
      "loss": 0.5973,
      "step": 459220
    },
    {
      "epoch": 740.71,
      "learning_rate": 0.025958299848225813,
      "loss": 0.565,
      "step": 459240
    },
    {
      "epoch": 740.74,
      "learning_rate": 0.025955074044999995,
      "loss": 0.5701,
      "step": 459260
    },
    {
      "epoch": 740.77,
      "learning_rate": 0.02595184824177419,
      "loss": 0.5775,
      "step": 459280
    },
    {
      "epoch": 740.81,
      "learning_rate": 0.025948622438548383,
      "loss": 0.5846,
      "step": 459300
    },
    {
      "epoch": 740.84,
      "learning_rate": 0.02594539663532258,
      "loss": 0.5945,
      "step": 459320
    },
    {
      "epoch": 740.87,
      "learning_rate": 0.025942170832096767,
      "loss": 0.5906,
      "step": 459340
    },
    {
      "epoch": 740.9,
      "learning_rate": 0.025938945028870966,
      "loss": 0.5903,
      "step": 459360
    },
    {
      "epoch": 740.94,
      "learning_rate": 0.02593571922564516,
      "loss": 0.5788,
      "step": 459380
    },
    {
      "epoch": 740.97,
      "learning_rate": 0.02593249342241935,
      "loss": 0.5796,
      "step": 459400
    },
    {
      "epoch": 741.0,
      "learning_rate": 0.02592926761919355,
      "loss": 0.5809,
      "step": 459420
    },
    {
      "epoch": 741.0,
      "eval_accuracy": {
        "accuracy": 0.7776129888377176
      },
      "eval_loss": 0.9468321204185486,
      "eval_runtime": 3.0296,
      "eval_samples_per_second": 4228.579,
      "eval_steps_per_second": 66.345,
      "step": 459420
    },
    {
      "epoch": 741.03,
      "learning_rate": 0.025926041815967738,
      "loss": 0.5852,
      "step": 459440
    },
    {
      "epoch": 741.06,
      "learning_rate": 0.025922816012741934,
      "loss": 0.5698,
      "step": 459460
    },
    {
      "epoch": 741.1,
      "learning_rate": 0.025919590209516133,
      "loss": 0.5664,
      "step": 459480
    },
    {
      "epoch": 741.13,
      "learning_rate": 0.02591636440629032,
      "loss": 0.58,
      "step": 459500
    },
    {
      "epoch": 741.16,
      "learning_rate": 0.025913138603064517,
      "loss": 0.5722,
      "step": 459520
    },
    {
      "epoch": 741.19,
      "learning_rate": 0.025909912799838716,
      "loss": 0.5851,
      "step": 459540
    },
    {
      "epoch": 741.23,
      "learning_rate": 0.025906686996612905,
      "loss": 0.5656,
      "step": 459560
    },
    {
      "epoch": 741.26,
      "learning_rate": 0.02590346119338709,
      "loss": 0.5775,
      "step": 459580
    },
    {
      "epoch": 741.29,
      "learning_rate": 0.025900235390161286,
      "loss": 0.5778,
      "step": 459600
    },
    {
      "epoch": 741.32,
      "learning_rate": 0.025897009586935485,
      "loss": 0.5763,
      "step": 459620
    },
    {
      "epoch": 741.35,
      "learning_rate": 0.025893783783709674,
      "loss": 0.5929,
      "step": 459640
    },
    {
      "epoch": 741.39,
      "learning_rate": 0.02589055798048387,
      "loss": 0.5615,
      "step": 459660
    },
    {
      "epoch": 741.42,
      "learning_rate": 0.02588733217725807,
      "loss": 0.5647,
      "step": 459680
    },
    {
      "epoch": 741.45,
      "learning_rate": 0.025884106374032257,
      "loss": 0.5859,
      "step": 459700
    },
    {
      "epoch": 741.48,
      "learning_rate": 0.025880880570806453,
      "loss": 0.5856,
      "step": 459720
    },
    {
      "epoch": 741.52,
      "learning_rate": 0.025877654767580645,
      "loss": 0.5842,
      "step": 459740
    },
    {
      "epoch": 741.55,
      "learning_rate": 0.02587442896435484,
      "loss": 0.5886,
      "step": 459760
    },
    {
      "epoch": 741.58,
      "learning_rate": 0.025871203161129036,
      "loss": 0.5916,
      "step": 459780
    },
    {
      "epoch": 741.61,
      "learning_rate": 0.025867977357903228,
      "loss": 0.5753,
      "step": 459800
    },
    {
      "epoch": 741.65,
      "learning_rate": 0.025864751554677424,
      "loss": 0.5825,
      "step": 459820
    },
    {
      "epoch": 741.68,
      "learning_rate": 0.025861525751451616,
      "loss": 0.5735,
      "step": 459840
    },
    {
      "epoch": 741.71,
      "learning_rate": 0.02585829994822581,
      "loss": 0.5767,
      "step": 459860
    },
    {
      "epoch": 741.74,
      "learning_rate": 0.02585507414499999,
      "loss": 0.57,
      "step": 459880
    },
    {
      "epoch": 741.77,
      "learning_rate": 0.02585184834177419,
      "loss": 0.5803,
      "step": 459900
    },
    {
      "epoch": 741.81,
      "learning_rate": 0.025848622538548385,
      "loss": 0.5851,
      "step": 459920
    },
    {
      "epoch": 741.84,
      "learning_rate": 0.025845396735322573,
      "loss": 0.5915,
      "step": 459940
    },
    {
      "epoch": 741.87,
      "learning_rate": 0.025842170932096772,
      "loss": 0.5772,
      "step": 459960
    },
    {
      "epoch": 741.9,
      "learning_rate": 0.02583894512887096,
      "loss": 0.575,
      "step": 459980
    },
    {
      "epoch": 741.94,
      "learning_rate": 0.025835719325645157,
      "loss": 0.586,
      "step": 460000
    },
    {
      "epoch": 741.97,
      "learning_rate": 0.025832493522419356,
      "loss": 0.5783,
      "step": 460020
    },
    {
      "epoch": 742.0,
      "learning_rate": 0.025829267719193545,
      "loss": 0.5923,
      "step": 460040
    },
    {
      "epoch": 742.0,
      "eval_accuracy": {
        "accuracy": 0.7748029037545859
      },
      "eval_loss": 0.9437455534934998,
      "eval_runtime": 3.8473,
      "eval_samples_per_second": 3329.886,
      "eval_steps_per_second": 52.245,
      "step": 460040
    },
    {
      "epoch": 742.03,
      "learning_rate": 0.02582604191596774,
      "loss": 0.5908,
      "step": 460060
    },
    {
      "epoch": 742.06,
      "learning_rate": 0.02582281611274194,
      "loss": 0.5713,
      "step": 460080
    },
    {
      "epoch": 742.1,
      "learning_rate": 0.025819590309516128,
      "loss": 0.5617,
      "step": 460100
    },
    {
      "epoch": 742.13,
      "learning_rate": 0.025816364506290324,
      "loss": 0.5579,
      "step": 460120
    },
    {
      "epoch": 742.16,
      "learning_rate": 0.025813138703064523,
      "loss": 0.5738,
      "step": 460140
    },
    {
      "epoch": 742.19,
      "learning_rate": 0.02580991289983871,
      "loss": 0.578,
      "step": 460160
    },
    {
      "epoch": 742.23,
      "learning_rate": 0.025806687096612907,
      "loss": 0.578,
      "step": 460180
    },
    {
      "epoch": 742.26,
      "learning_rate": 0.025803461293387092,
      "loss": 0.5769,
      "step": 460200
    },
    {
      "epoch": 742.29,
      "learning_rate": 0.02580023549016129,
      "loss": 0.5624,
      "step": 460220
    },
    {
      "epoch": 742.32,
      "learning_rate": 0.02579700968693548,
      "loss": 0.571,
      "step": 460240
    },
    {
      "epoch": 742.35,
      "learning_rate": 0.025793783883709676,
      "loss": 0.571,
      "step": 460260
    },
    {
      "epoch": 742.39,
      "learning_rate": 0.025790558080483868,
      "loss": 0.5828,
      "step": 460280
    },
    {
      "epoch": 742.42,
      "learning_rate": 0.025787332277258063,
      "loss": 0.5663,
      "step": 460300
    },
    {
      "epoch": 742.45,
      "learning_rate": 0.02578410647403226,
      "loss": 0.5801,
      "step": 460320
    },
    {
      "epoch": 742.48,
      "learning_rate": 0.02578088067080645,
      "loss": 0.5799,
      "step": 460340
    },
    {
      "epoch": 742.52,
      "learning_rate": 0.025777654867580647,
      "loss": 0.5766,
      "step": 460360
    },
    {
      "epoch": 742.55,
      "learning_rate": 0.02577442906435484,
      "loss": 0.5685,
      "step": 460380
    },
    {
      "epoch": 742.58,
      "learning_rate": 0.025771203261129035,
      "loss": 0.5774,
      "step": 460400
    },
    {
      "epoch": 742.61,
      "learning_rate": 0.02576797745790323,
      "loss": 0.586,
      "step": 460420
    },
    {
      "epoch": 742.65,
      "learning_rate": 0.025764751654677422,
      "loss": 0.5788,
      "step": 460440
    },
    {
      "epoch": 742.68,
      "learning_rate": 0.025761525851451618,
      "loss": 0.5859,
      "step": 460460
    },
    {
      "epoch": 742.71,
      "learning_rate": 0.02575830004822581,
      "loss": 0.5657,
      "step": 460480
    },
    {
      "epoch": 742.74,
      "learning_rate": 0.025755074244999995,
      "loss": 0.5777,
      "step": 460500
    },
    {
      "epoch": 742.77,
      "learning_rate": 0.025751848441774184,
      "loss": 0.5913,
      "step": 460520
    },
    {
      "epoch": 742.81,
      "learning_rate": 0.02574862263854838,
      "loss": 0.5818,
      "step": 460540
    },
    {
      "epoch": 742.84,
      "learning_rate": 0.02574539683532258,
      "loss": 0.5738,
      "step": 460560
    },
    {
      "epoch": 742.87,
      "learning_rate": 0.025742171032096767,
      "loss": 0.5763,
      "step": 460580
    },
    {
      "epoch": 742.9,
      "learning_rate": 0.025738945228870963,
      "loss": 0.5759,
      "step": 460600
    },
    {
      "epoch": 742.94,
      "learning_rate": 0.025735719425645162,
      "loss": 0.59,
      "step": 460620
    },
    {
      "epoch": 742.97,
      "learning_rate": 0.02573249362241935,
      "loss": 0.6019,
      "step": 460640
    },
    {
      "epoch": 743.0,
      "learning_rate": 0.025729267819193546,
      "loss": 0.5822,
      "step": 460660
    },
    {
      "epoch": 743.0,
      "eval_accuracy": {
        "accuracy": 0.7746467879166341
      },
      "eval_loss": 0.9524627923965454,
      "eval_runtime": 3.1488,
      "eval_samples_per_second": 4068.475,
      "eval_steps_per_second": 63.833,
      "step": 460660
    },
    {
      "epoch": 743.03,
      "learning_rate": 0.025726042015967746,
      "loss": 0.586,
      "step": 460680
    },
    {
      "epoch": 743.06,
      "learning_rate": 0.025722816212741934,
      "loss": 0.584,
      "step": 460700
    },
    {
      "epoch": 743.1,
      "learning_rate": 0.02571959040951613,
      "loss": 0.5754,
      "step": 460720
    },
    {
      "epoch": 743.13,
      "learning_rate": 0.02571636460629033,
      "loss": 0.5857,
      "step": 460740
    },
    {
      "epoch": 743.16,
      "learning_rate": 0.025713138803064518,
      "loss": 0.5738,
      "step": 460760
    },
    {
      "epoch": 743.19,
      "learning_rate": 0.025709912999838713,
      "loss": 0.5814,
      "step": 460780
    },
    {
      "epoch": 743.23,
      "learning_rate": 0.025706687196612912,
      "loss": 0.5671,
      "step": 460800
    },
    {
      "epoch": 743.26,
      "learning_rate": 0.02570346139338709,
      "loss": 0.5607,
      "step": 460820
    },
    {
      "epoch": 743.29,
      "learning_rate": 0.025700235590161286,
      "loss": 0.5722,
      "step": 460840
    },
    {
      "epoch": 743.32,
      "learning_rate": 0.025697009786935482,
      "loss": 0.568,
      "step": 460860
    },
    {
      "epoch": 743.35,
      "learning_rate": 0.025693783983709674,
      "loss": 0.5606,
      "step": 460880
    },
    {
      "epoch": 743.39,
      "learning_rate": 0.02569055818048387,
      "loss": 0.5781,
      "step": 460900
    },
    {
      "epoch": 743.42,
      "learning_rate": 0.025687332377258062,
      "loss": 0.5734,
      "step": 460920
    },
    {
      "epoch": 743.45,
      "learning_rate": 0.025684106574032257,
      "loss": 0.5554,
      "step": 460940
    },
    {
      "epoch": 743.48,
      "learning_rate": 0.025680880770806453,
      "loss": 0.5775,
      "step": 460960
    },
    {
      "epoch": 743.52,
      "learning_rate": 0.025677654967580645,
      "loss": 0.5895,
      "step": 460980
    },
    {
      "epoch": 743.55,
      "learning_rate": 0.02567442916435484,
      "loss": 0.5784,
      "step": 461000
    },
    {
      "epoch": 743.58,
      "learning_rate": 0.025671203361129033,
      "loss": 0.5859,
      "step": 461020
    },
    {
      "epoch": 743.61,
      "learning_rate": 0.02566797755790323,
      "loss": 0.5775,
      "step": 461040
    },
    {
      "epoch": 743.65,
      "learning_rate": 0.025664751754677424,
      "loss": 0.575,
      "step": 461060
    },
    {
      "epoch": 743.68,
      "learning_rate": 0.025661525951451616,
      "loss": 0.586,
      "step": 461080
    },
    {
      "epoch": 743.71,
      "learning_rate": 0.025658300148225812,
      "loss": 0.581,
      "step": 461100
    },
    {
      "epoch": 743.74,
      "learning_rate": 0.02565507434499999,
      "loss": 0.569,
      "step": 461120
    },
    {
      "epoch": 743.77,
      "learning_rate": 0.025651848541774186,
      "loss": 0.5917,
      "step": 461140
    },
    {
      "epoch": 743.81,
      "learning_rate": 0.025648622738548385,
      "loss": 0.5754,
      "step": 461160
    },
    {
      "epoch": 743.84,
      "learning_rate": 0.025645396935322574,
      "loss": 0.585,
      "step": 461180
    },
    {
      "epoch": 743.87,
      "learning_rate": 0.02564217113209677,
      "loss": 0.5755,
      "step": 461200
    },
    {
      "epoch": 743.9,
      "learning_rate": 0.02563894532887097,
      "loss": 0.5887,
      "step": 461220
    },
    {
      "epoch": 743.94,
      "learning_rate": 0.025635719525645157,
      "loss": 0.5794,
      "step": 461240
    },
    {
      "epoch": 743.97,
      "learning_rate": 0.025632493722419353,
      "loss": 0.5717,
      "step": 461260
    },
    {
      "epoch": 744.0,
      "learning_rate": 0.025629267919193552,
      "loss": 0.5787,
      "step": 461280
    },
    {
      "epoch": 744.0,
      "eval_accuracy": {
        "accuracy": 0.7730856295371166
      },
      "eval_loss": 0.961159884929657,
      "eval_runtime": 3.234,
      "eval_samples_per_second": 3961.349,
      "eval_steps_per_second": 62.152,
      "step": 461280
    },
    {
      "epoch": 744.03,
      "learning_rate": 0.02562604211596774,
      "loss": 0.5878,
      "step": 461300
    },
    {
      "epoch": 744.06,
      "learning_rate": 0.025622816312741936,
      "loss": 0.5676,
      "step": 461320
    },
    {
      "epoch": 744.1,
      "learning_rate": 0.025619590509516135,
      "loss": 0.5568,
      "step": 461340
    },
    {
      "epoch": 744.13,
      "learning_rate": 0.025616364706290324,
      "loss": 0.5665,
      "step": 461360
    },
    {
      "epoch": 744.16,
      "learning_rate": 0.02561313890306452,
      "loss": 0.5891,
      "step": 461380
    },
    {
      "epoch": 744.19,
      "learning_rate": 0.02560991309983872,
      "loss": 0.5834,
      "step": 461400
    },
    {
      "epoch": 744.23,
      "learning_rate": 0.025606687296612907,
      "loss": 0.5856,
      "step": 461420
    },
    {
      "epoch": 744.26,
      "learning_rate": 0.025603461493387093,
      "loss": 0.5838,
      "step": 461440
    },
    {
      "epoch": 744.29,
      "learning_rate": 0.025600235690161285,
      "loss": 0.5814,
      "step": 461460
    },
    {
      "epoch": 744.32,
      "learning_rate": 0.02559700988693548,
      "loss": 0.5824,
      "step": 461480
    },
    {
      "epoch": 744.35,
      "learning_rate": 0.025593784083709676,
      "loss": 0.5732,
      "step": 461500
    },
    {
      "epoch": 744.39,
      "learning_rate": 0.025590558280483868,
      "loss": 0.5722,
      "step": 461520
    },
    {
      "epoch": 744.42,
      "learning_rate": 0.025587332477258064,
      "loss": 0.5831,
      "step": 461540
    },
    {
      "epoch": 744.45,
      "learning_rate": 0.025584106674032256,
      "loss": 0.5693,
      "step": 461560
    },
    {
      "epoch": 744.48,
      "learning_rate": 0.02558088087080645,
      "loss": 0.5775,
      "step": 461580
    },
    {
      "epoch": 744.52,
      "learning_rate": 0.025577655067580647,
      "loss": 0.5777,
      "step": 461600
    },
    {
      "epoch": 744.55,
      "learning_rate": 0.02557442926435484,
      "loss": 0.5912,
      "step": 461620
    },
    {
      "epoch": 744.58,
      "learning_rate": 0.025571203461129035,
      "loss": 0.576,
      "step": 461640
    },
    {
      "epoch": 744.61,
      "learning_rate": 0.025567977657903224,
      "loss": 0.5697,
      "step": 461660
    },
    {
      "epoch": 744.65,
      "learning_rate": 0.025564751854677423,
      "loss": 0.5726,
      "step": 461680
    },
    {
      "epoch": 744.68,
      "learning_rate": 0.02556152605145162,
      "loss": 0.5762,
      "step": 461700
    },
    {
      "epoch": 744.71,
      "learning_rate": 0.025558300248225807,
      "loss": 0.5737,
      "step": 461720
    },
    {
      "epoch": 744.74,
      "learning_rate": 0.025555074445000006,
      "loss": 0.5809,
      "step": 461740
    },
    {
      "epoch": 744.77,
      "learning_rate": 0.02555184864177419,
      "loss": 0.5734,
      "step": 461760
    },
    {
      "epoch": 744.81,
      "learning_rate": 0.02554862283854838,
      "loss": 0.5846,
      "step": 461780
    },
    {
      "epoch": 744.84,
      "learning_rate": 0.025545397035322576,
      "loss": 0.5788,
      "step": 461800
    },
    {
      "epoch": 744.87,
      "learning_rate": 0.025542171232096775,
      "loss": 0.578,
      "step": 461820
    },
    {
      "epoch": 744.9,
      "learning_rate": 0.025538945428870963,
      "loss": 0.581,
      "step": 461840
    },
    {
      "epoch": 744.94,
      "learning_rate": 0.02553571962564516,
      "loss": 0.5913,
      "step": 461860
    },
    {
      "epoch": 744.97,
      "learning_rate": 0.025532493822419358,
      "loss": 0.5836,
      "step": 461880
    },
    {
      "epoch": 745.0,
      "learning_rate": 0.02552942930935483,
      "loss": 0.5706,
      "step": 461900
    },
    {
      "epoch": 745.0,
      "eval_accuracy": {
        "accuracy": 0.7758176567012723
      },
      "eval_loss": 0.9319273829460144,
      "eval_runtime": 3.0639,
      "eval_samples_per_second": 4181.22,
      "eval_steps_per_second": 65.602,
      "step": 461900
    },
    {
      "epoch": 745.03,
      "learning_rate": 0.025526203506129025,
      "loss": 0.5755,
      "step": 461920
    },
    {
      "epoch": 745.06,
      "learning_rate": 0.025522977702903224,
      "loss": 0.5573,
      "step": 461940
    },
    {
      "epoch": 745.1,
      "learning_rate": 0.025519751899677413,
      "loss": 0.5593,
      "step": 461960
    },
    {
      "epoch": 745.13,
      "learning_rate": 0.02551652609645161,
      "loss": 0.5663,
      "step": 461980
    },
    {
      "epoch": 745.16,
      "learning_rate": 0.025513300293225807,
      "loss": 0.5658,
      "step": 462000
    },
    {
      "epoch": 745.19,
      "learning_rate": 0.025510074489999996,
      "loss": 0.573,
      "step": 462020
    },
    {
      "epoch": 745.23,
      "learning_rate": 0.02550684868677419,
      "loss": 0.5755,
      "step": 462040
    },
    {
      "epoch": 745.26,
      "learning_rate": 0.02550362288354839,
      "loss": 0.5767,
      "step": 462060
    },
    {
      "epoch": 745.29,
      "learning_rate": 0.02550039708032258,
      "loss": 0.5689,
      "step": 462080
    },
    {
      "epoch": 745.32,
      "learning_rate": 0.025497171277096775,
      "loss": 0.5693,
      "step": 462100
    },
    {
      "epoch": 745.35,
      "learning_rate": 0.025493945473870974,
      "loss": 0.573,
      "step": 462120
    },
    {
      "epoch": 745.39,
      "learning_rate": 0.025490719670645163,
      "loss": 0.5721,
      "step": 462140
    },
    {
      "epoch": 745.42,
      "learning_rate": 0.02548749386741936,
      "loss": 0.5816,
      "step": 462160
    },
    {
      "epoch": 745.45,
      "learning_rate": 0.025484268064193558,
      "loss": 0.5788,
      "step": 462180
    },
    {
      "epoch": 745.48,
      "learning_rate": 0.025481042260967736,
      "loss": 0.5682,
      "step": 462200
    },
    {
      "epoch": 745.52,
      "learning_rate": 0.02547781645774193,
      "loss": 0.5638,
      "step": 462220
    },
    {
      "epoch": 745.55,
      "learning_rate": 0.025474590654516124,
      "loss": 0.569,
      "step": 462240
    },
    {
      "epoch": 745.58,
      "learning_rate": 0.02547136485129032,
      "loss": 0.5754,
      "step": 462260
    },
    {
      "epoch": 745.61,
      "learning_rate": 0.025468139048064515,
      "loss": 0.5836,
      "step": 462280
    },
    {
      "epoch": 745.65,
      "learning_rate": 0.025464913244838707,
      "loss": 0.5832,
      "step": 462300
    },
    {
      "epoch": 745.68,
      "learning_rate": 0.025461687441612903,
      "loss": 0.5841,
      "step": 462320
    },
    {
      "epoch": 745.71,
      "learning_rate": 0.025458461638387095,
      "loss": 0.579,
      "step": 462340
    },
    {
      "epoch": 745.74,
      "learning_rate": 0.02545523583516129,
      "loss": 0.5799,
      "step": 462360
    },
    {
      "epoch": 745.77,
      "learning_rate": 0.025452010031935486,
      "loss": 0.5692,
      "step": 462380
    },
    {
      "epoch": 745.81,
      "learning_rate": 0.02544878422870968,
      "loss": 0.5821,
      "step": 462400
    },
    {
      "epoch": 745.84,
      "learning_rate": 0.025445558425483874,
      "loss": 0.5793,
      "step": 462420
    },
    {
      "epoch": 745.87,
      "learning_rate": 0.02544233262225807,
      "loss": 0.583,
      "step": 462440
    },
    {
      "epoch": 745.9,
      "learning_rate": 0.02543910681903226,
      "loss": 0.5827,
      "step": 462460
    },
    {
      "epoch": 745.94,
      "learning_rate": 0.025435881015806457,
      "loss": 0.5828,
      "step": 462480
    },
    {
      "epoch": 745.97,
      "learning_rate": 0.025432655212580646,
      "loss": 0.5849,
      "step": 462500
    },
    {
      "epoch": 746.0,
      "learning_rate": 0.02542942940935483,
      "loss": 0.5819,
      "step": 462520
    },
    {
      "epoch": 746.0,
      "eval_accuracy": {
        "accuracy": 0.7798766684880181
      },
      "eval_loss": 0.9356868267059326,
      "eval_runtime": 3.1754,
      "eval_samples_per_second": 4034.499,
      "eval_steps_per_second": 63.3,
      "step": 462520
    },
    {
      "epoch": 746.03,
      "learning_rate": 0.02542620360612903,
      "loss": 0.5882,
      "step": 462540
    },
    {
      "epoch": 746.06,
      "learning_rate": 0.02542297780290322,
      "loss": 0.5812,
      "step": 462560
    },
    {
      "epoch": 746.1,
      "learning_rate": 0.025419751999677415,
      "loss": 0.5762,
      "step": 462580
    },
    {
      "epoch": 746.13,
      "learning_rate": 0.025416526196451614,
      "loss": 0.587,
      "step": 462600
    },
    {
      "epoch": 746.16,
      "learning_rate": 0.025413300393225802,
      "loss": 0.5685,
      "step": 462620
    },
    {
      "epoch": 746.19,
      "learning_rate": 0.025410074589999998,
      "loss": 0.5739,
      "step": 462640
    },
    {
      "epoch": 746.23,
      "learning_rate": 0.025406848786774197,
      "loss": 0.5827,
      "step": 462660
    },
    {
      "epoch": 746.26,
      "learning_rate": 0.025403622983548386,
      "loss": 0.566,
      "step": 462680
    },
    {
      "epoch": 746.29,
      "learning_rate": 0.02540039718032258,
      "loss": 0.5748,
      "step": 462700
    },
    {
      "epoch": 746.32,
      "learning_rate": 0.02539717137709678,
      "loss": 0.563,
      "step": 462720
    },
    {
      "epoch": 746.35,
      "learning_rate": 0.02539394557387097,
      "loss": 0.58,
      "step": 462740
    },
    {
      "epoch": 746.39,
      "learning_rate": 0.025390719770645165,
      "loss": 0.5721,
      "step": 462760
    },
    {
      "epoch": 746.42,
      "learning_rate": 0.025387493967419364,
      "loss": 0.5746,
      "step": 462780
    },
    {
      "epoch": 746.45,
      "learning_rate": 0.025384268164193553,
      "loss": 0.5696,
      "step": 462800
    },
    {
      "epoch": 746.48,
      "learning_rate": 0.025381042360967738,
      "loss": 0.576,
      "step": 462820
    },
    {
      "epoch": 746.52,
      "learning_rate": 0.02537781655774193,
      "loss": 0.5672,
      "step": 462840
    },
    {
      "epoch": 746.55,
      "learning_rate": 0.025374590754516126,
      "loss": 0.5701,
      "step": 462860
    },
    {
      "epoch": 746.58,
      "learning_rate": 0.025371364951290318,
      "loss": 0.5666,
      "step": 462880
    },
    {
      "epoch": 746.61,
      "learning_rate": 0.025368139148064513,
      "loss": 0.5855,
      "step": 462900
    },
    {
      "epoch": 746.65,
      "learning_rate": 0.02536491334483871,
      "loss": 0.5778,
      "step": 462920
    },
    {
      "epoch": 746.68,
      "learning_rate": 0.0253616875416129,
      "loss": 0.5691,
      "step": 462940
    },
    {
      "epoch": 746.71,
      "learning_rate": 0.025358461738387097,
      "loss": 0.5659,
      "step": 462960
    },
    {
      "epoch": 746.74,
      "learning_rate": 0.025355235935161285,
      "loss": 0.5803,
      "step": 462980
    },
    {
      "epoch": 746.77,
      "learning_rate": 0.025352010131935485,
      "loss": 0.5719,
      "step": 463000
    },
    {
      "epoch": 746.81,
      "learning_rate": 0.02534878432870968,
      "loss": 0.5715,
      "step": 463020
    },
    {
      "epoch": 746.84,
      "learning_rate": 0.02534555852548387,
      "loss": 0.5869,
      "step": 463040
    },
    {
      "epoch": 746.87,
      "learning_rate": 0.025342332722258068,
      "loss": 0.5808,
      "step": 463060
    },
    {
      "epoch": 746.9,
      "learning_rate": 0.025339106919032264,
      "loss": 0.5735,
      "step": 463080
    },
    {
      "epoch": 746.94,
      "learning_rate": 0.025335881115806452,
      "loss": 0.5811,
      "step": 463100
    },
    {
      "epoch": 746.97,
      "learning_rate": 0.02533265531258065,
      "loss": 0.6016,
      "step": 463120
    },
    {
      "epoch": 747.0,
      "learning_rate": 0.025329429509354837,
      "loss": 0.5914,
      "step": 463140
    },
    {
      "epoch": 747.0,
      "eval_accuracy": {
        "accuracy": 0.7745687299976582
      },
      "eval_loss": 0.937332272529602,
      "eval_runtime": 3.9078,
      "eval_samples_per_second": 3278.305,
      "eval_steps_per_second": 51.435,
      "step": 463140
    },
    {
      "epoch": 747.03,
      "learning_rate": 0.025326203706129025,
      "loss": 0.5931,
      "step": 463160
    },
    {
      "epoch": 747.06,
      "learning_rate": 0.02532297790290322,
      "loss": 0.5709,
      "step": 463180
    },
    {
      "epoch": 747.1,
      "learning_rate": 0.02531975209967742,
      "loss": 0.5741,
      "step": 463200
    },
    {
      "epoch": 747.13,
      "learning_rate": 0.02531652629645161,
      "loss": 0.5709,
      "step": 463220
    },
    {
      "epoch": 747.16,
      "learning_rate": 0.025313300493225804,
      "loss": 0.5697,
      "step": 463240
    },
    {
      "epoch": 747.19,
      "learning_rate": 0.025310074690000003,
      "loss": 0.5699,
      "step": 463260
    },
    {
      "epoch": 747.23,
      "learning_rate": 0.025306848886774192,
      "loss": 0.5763,
      "step": 463280
    },
    {
      "epoch": 747.26,
      "learning_rate": 0.025303623083548388,
      "loss": 0.5506,
      "step": 463300
    },
    {
      "epoch": 747.29,
      "learning_rate": 0.025300397280322587,
      "loss": 0.5721,
      "step": 463320
    },
    {
      "epoch": 747.32,
      "learning_rate": 0.025297171477096776,
      "loss": 0.5741,
      "step": 463340
    },
    {
      "epoch": 747.35,
      "learning_rate": 0.02529394567387097,
      "loss": 0.5844,
      "step": 463360
    },
    {
      "epoch": 747.39,
      "learning_rate": 0.025290719870645163,
      "loss": 0.5682,
      "step": 463380
    },
    {
      "epoch": 747.42,
      "learning_rate": 0.02528749406741936,
      "loss": 0.5761,
      "step": 463400
    },
    {
      "epoch": 747.45,
      "learning_rate": 0.025284268264193555,
      "loss": 0.5706,
      "step": 463420
    },
    {
      "epoch": 747.48,
      "learning_rate": 0.025281042460967736,
      "loss": 0.5722,
      "step": 463440
    },
    {
      "epoch": 747.52,
      "learning_rate": 0.025277816657741932,
      "loss": 0.5733,
      "step": 463460
    },
    {
      "epoch": 747.55,
      "learning_rate": 0.025274590854516124,
      "loss": 0.5862,
      "step": 463480
    },
    {
      "epoch": 747.58,
      "learning_rate": 0.02527136505129032,
      "loss": 0.5727,
      "step": 463500
    },
    {
      "epoch": 747.61,
      "learning_rate": 0.02526813924806451,
      "loss": 0.5785,
      "step": 463520
    },
    {
      "epoch": 747.65,
      "learning_rate": 0.025264913444838707,
      "loss": 0.5723,
      "step": 463540
    },
    {
      "epoch": 747.68,
      "learning_rate": 0.025261687641612903,
      "loss": 0.5749,
      "step": 463560
    },
    {
      "epoch": 747.71,
      "learning_rate": 0.025258461838387092,
      "loss": 0.571,
      "step": 463580
    },
    {
      "epoch": 747.74,
      "learning_rate": 0.02525523603516129,
      "loss": 0.5798,
      "step": 463600
    },
    {
      "epoch": 747.77,
      "learning_rate": 0.025252010231935487,
      "loss": 0.5638,
      "step": 463620
    },
    {
      "epoch": 747.81,
      "learning_rate": 0.025248784428709675,
      "loss": 0.5861,
      "step": 463640
    },
    {
      "epoch": 747.84,
      "learning_rate": 0.025245558625483874,
      "loss": 0.5743,
      "step": 463660
    },
    {
      "epoch": 747.87,
      "learning_rate": 0.025242332822258063,
      "loss": 0.5635,
      "step": 463680
    },
    {
      "epoch": 747.9,
      "learning_rate": 0.02523910701903226,
      "loss": 0.5822,
      "step": 463700
    },
    {
      "epoch": 747.94,
      "learning_rate": 0.025235881215806458,
      "loss": 0.5741,
      "step": 463720
    },
    {
      "epoch": 747.97,
      "learning_rate": 0.025232655412580646,
      "loss": 0.5728,
      "step": 463740
    },
    {
      "epoch": 748.0,
      "learning_rate": 0.02522942960935483,
      "loss": 0.5877,
      "step": 463760
    },
    {
      "epoch": 748.0,
      "eval_accuracy": {
        "accuracy": 0.7822964639762704
      },
      "eval_loss": 0.930811882019043,
      "eval_runtime": 3.0908,
      "eval_samples_per_second": 4144.839,
      "eval_steps_per_second": 65.031,
      "step": 463760
    },
    {
      "epoch": 748.03,
      "learning_rate": 0.025226203806129027,
      "loss": 0.5832,
      "step": 463780
    },
    {
      "epoch": 748.06,
      "learning_rate": 0.025222978002903226,
      "loss": 0.558,
      "step": 463800
    },
    {
      "epoch": 748.1,
      "learning_rate": 0.025219752199677415,
      "loss": 0.5651,
      "step": 463820
    },
    {
      "epoch": 748.13,
      "learning_rate": 0.02521652639645161,
      "loss": 0.5587,
      "step": 463840
    },
    {
      "epoch": 748.16,
      "learning_rate": 0.02521330059322581,
      "loss": 0.5728,
      "step": 463860
    },
    {
      "epoch": 748.19,
      "learning_rate": 0.02521007479,
      "loss": 0.5632,
      "step": 463880
    },
    {
      "epoch": 748.23,
      "learning_rate": 0.025206848986774194,
      "loss": 0.5714,
      "step": 463900
    },
    {
      "epoch": 748.26,
      "learning_rate": 0.025203623183548386,
      "loss": 0.572,
      "step": 463920
    },
    {
      "epoch": 748.29,
      "learning_rate": 0.025200397380322582,
      "loss": 0.568,
      "step": 463940
    },
    {
      "epoch": 748.32,
      "learning_rate": 0.025197171577096777,
      "loss": 0.5869,
      "step": 463960
    },
    {
      "epoch": 748.35,
      "learning_rate": 0.02519394577387097,
      "loss": 0.5566,
      "step": 463980
    },
    {
      "epoch": 748.39,
      "learning_rate": 0.025190719970645165,
      "loss": 0.5647,
      "step": 464000
    },
    {
      "epoch": 748.42,
      "learning_rate": 0.025187494167419357,
      "loss": 0.5772,
      "step": 464020
    },
    {
      "epoch": 748.45,
      "learning_rate": 0.025184268364193553,
      "loss": 0.5623,
      "step": 464040
    },
    {
      "epoch": 748.48,
      "learning_rate": 0.02518104256096775,
      "loss": 0.5774,
      "step": 464060
    },
    {
      "epoch": 748.52,
      "learning_rate": 0.02517781675774193,
      "loss": 0.5872,
      "step": 464080
    },
    {
      "epoch": 748.55,
      "learning_rate": 0.025174590954516126,
      "loss": 0.5793,
      "step": 464100
    },
    {
      "epoch": 748.58,
      "learning_rate": 0.025171365151290315,
      "loss": 0.5713,
      "step": 464120
    },
    {
      "epoch": 748.61,
      "learning_rate": 0.025168139348064514,
      "loss": 0.5671,
      "step": 464140
    },
    {
      "epoch": 748.65,
      "learning_rate": 0.02516491354483871,
      "loss": 0.5659,
      "step": 464160
    },
    {
      "epoch": 748.68,
      "learning_rate": 0.025161687741612898,
      "loss": 0.5645,
      "step": 464180
    },
    {
      "epoch": 748.71,
      "learning_rate": 0.025158461938387097,
      "loss": 0.5732,
      "step": 464200
    },
    {
      "epoch": 748.74,
      "learning_rate": 0.025155236135161286,
      "loss": 0.567,
      "step": 464220
    },
    {
      "epoch": 748.77,
      "learning_rate": 0.02515201033193548,
      "loss": 0.5893,
      "step": 464240
    },
    {
      "epoch": 748.81,
      "learning_rate": 0.02514878452870968,
      "loss": 0.5663,
      "step": 464260
    },
    {
      "epoch": 748.84,
      "learning_rate": 0.02514555872548387,
      "loss": 0.5664,
      "step": 464280
    },
    {
      "epoch": 748.87,
      "learning_rate": 0.025142332922258065,
      "loss": 0.5835,
      "step": 464300
    },
    {
      "epoch": 748.9,
      "learning_rate": 0.025139107119032264,
      "loss": 0.5827,
      "step": 464320
    },
    {
      "epoch": 748.94,
      "learning_rate": 0.025135881315806453,
      "loss": 0.5839,
      "step": 464340
    },
    {
      "epoch": 748.97,
      "learning_rate": 0.02513265551258065,
      "loss": 0.5823,
      "step": 464360
    },
    {
      "epoch": 749.0,
      "learning_rate": 0.025129429709354834,
      "loss": 0.5918,
      "step": 464380
    },
    {
      "epoch": 749.0,
      "eval_accuracy": {
        "accuracy": 0.7783935680274764
      },
      "eval_loss": 0.9395619630813599,
      "eval_runtime": 2.9142,
      "eval_samples_per_second": 4396.132,
      "eval_steps_per_second": 68.974,
      "step": 464380
    },
    {
      "epoch": 749.03,
      "learning_rate": 0.025126203906129033,
      "loss": 0.5847,
      "step": 464400
    },
    {
      "epoch": 749.06,
      "learning_rate": 0.02512297810290322,
      "loss": 0.5622,
      "step": 464420
    },
    {
      "epoch": 749.1,
      "learning_rate": 0.025119752299677417,
      "loss": 0.5641,
      "step": 464440
    },
    {
      "epoch": 749.13,
      "learning_rate": 0.02511652649645161,
      "loss": 0.5769,
      "step": 464460
    },
    {
      "epoch": 749.16,
      "learning_rate": 0.025113300693225805,
      "loss": 0.5667,
      "step": 464480
    },
    {
      "epoch": 749.19,
      "learning_rate": 0.02511007489,
      "loss": 0.5698,
      "step": 464500
    },
    {
      "epoch": 749.23,
      "learning_rate": 0.025106849086774193,
      "loss": 0.5724,
      "step": 464520
    },
    {
      "epoch": 749.26,
      "learning_rate": 0.025103623283548388,
      "loss": 0.5883,
      "step": 464540
    },
    {
      "epoch": 749.29,
      "learning_rate": 0.02510039748032258,
      "loss": 0.5658,
      "step": 464560
    },
    {
      "epoch": 749.32,
      "learning_rate": 0.025097171677096776,
      "loss": 0.5784,
      "step": 464580
    },
    {
      "epoch": 749.35,
      "learning_rate": 0.02509394587387097,
      "loss": 0.5761,
      "step": 464600
    },
    {
      "epoch": 749.39,
      "learning_rate": 0.025090720070645164,
      "loss": 0.5767,
      "step": 464620
    },
    {
      "epoch": 749.42,
      "learning_rate": 0.02508749426741936,
      "loss": 0.5674,
      "step": 464640
    },
    {
      "epoch": 749.45,
      "learning_rate": 0.02508426846419355,
      "loss": 0.5627,
      "step": 464660
    },
    {
      "epoch": 749.48,
      "learning_rate": 0.025081042660967747,
      "loss": 0.5646,
      "step": 464680
    },
    {
      "epoch": 749.52,
      "learning_rate": 0.025077816857741925,
      "loss": 0.5838,
      "step": 464700
    },
    {
      "epoch": 749.55,
      "learning_rate": 0.02507459105451612,
      "loss": 0.574,
      "step": 464720
    },
    {
      "epoch": 749.58,
      "learning_rate": 0.02507136525129032,
      "loss": 0.5659,
      "step": 464740
    },
    {
      "epoch": 749.61,
      "learning_rate": 0.02506813944806451,
      "loss": 0.5729,
      "step": 464760
    },
    {
      "epoch": 749.65,
      "learning_rate": 0.025064913644838704,
      "loss": 0.5751,
      "step": 464780
    },
    {
      "epoch": 749.68,
      "learning_rate": 0.025061687841612904,
      "loss": 0.5582,
      "step": 464800
    },
    {
      "epoch": 749.71,
      "learning_rate": 0.025058462038387092,
      "loss": 0.5675,
      "step": 464820
    },
    {
      "epoch": 749.74,
      "learning_rate": 0.025055236235161288,
      "loss": 0.5765,
      "step": 464840
    },
    {
      "epoch": 749.77,
      "learning_rate": 0.025052010431935487,
      "loss": 0.5829,
      "step": 464860
    },
    {
      "epoch": 749.81,
      "learning_rate": 0.025048784628709676,
      "loss": 0.5688,
      "step": 464880
    },
    {
      "epoch": 749.84,
      "learning_rate": 0.02504555882548387,
      "loss": 0.5735,
      "step": 464900
    },
    {
      "epoch": 749.87,
      "learning_rate": 0.02504233302225807,
      "loss": 0.5703,
      "step": 464920
    },
    {
      "epoch": 749.9,
      "learning_rate": 0.02503910721903226,
      "loss": 0.5852,
      "step": 464940
    },
    {
      "epoch": 749.94,
      "learning_rate": 0.025035881415806455,
      "loss": 0.5841,
      "step": 464960
    },
    {
      "epoch": 749.97,
      "learning_rate": 0.025032655612580654,
      "loss": 0.5801,
      "step": 464980
    },
    {
      "epoch": 750.0,
      "learning_rate": 0.025029429809354832,
      "loss": 0.5853,
      "step": 465000
    },
    {
      "epoch": 750.0,
      "eval_accuracy": {
        "accuracy": 0.776676293810007
      },
      "eval_loss": 0.9429951310157776,
      "eval_runtime": 3.8359,
      "eval_samples_per_second": 3339.734,
      "eval_steps_per_second": 52.399,
      "step": 465000
    },
    {
      "epoch": 750.03,
      "learning_rate": 0.025026204006129028,
      "loss": 0.5886,
      "step": 465020
    },
    {
      "epoch": 750.06,
      "learning_rate": 0.025022978202903223,
      "loss": 0.5737,
      "step": 465040
    },
    {
      "epoch": 750.1,
      "learning_rate": 0.025019752399677415,
      "loss": 0.5729,
      "step": 465060
    },
    {
      "epoch": 750.13,
      "learning_rate": 0.02501652659645161,
      "loss": 0.5689,
      "step": 465080
    },
    {
      "epoch": 750.16,
      "learning_rate": 0.025013300793225803,
      "loss": 0.5761,
      "step": 465100
    },
    {
      "epoch": 750.19,
      "learning_rate": 0.02501007499,
      "loss": 0.5683,
      "step": 465120
    },
    {
      "epoch": 750.23,
      "learning_rate": 0.025006849186774194,
      "loss": 0.5729,
      "step": 465140
    },
    {
      "epoch": 750.26,
      "learning_rate": 0.025003623383548387,
      "loss": 0.5601,
      "step": 465160
    },
    {
      "epoch": 750.29,
      "learning_rate": 0.025000397580322582,
      "loss": 0.5588,
      "step": 465180
    },
    {
      "epoch": 750.32,
      "learning_rate": 0.024997171777096774,
      "loss": 0.5678,
      "step": 465200
    },
    {
      "epoch": 750.35,
      "learning_rate": 0.02499394597387097,
      "loss": 0.5708,
      "step": 465220
    },
    {
      "epoch": 750.39,
      "learning_rate": 0.024990720170645166,
      "loss": 0.5672,
      "step": 465240
    },
    {
      "epoch": 750.42,
      "learning_rate": 0.024987494367419358,
      "loss": 0.5762,
      "step": 465260
    },
    {
      "epoch": 750.45,
      "learning_rate": 0.024984268564193553,
      "loss": 0.5743,
      "step": 465280
    },
    {
      "epoch": 750.48,
      "learning_rate": 0.02498104276096775,
      "loss": 0.5693,
      "step": 465300
    },
    {
      "epoch": 750.52,
      "learning_rate": 0.02497781695774193,
      "loss": 0.578,
      "step": 465320
    },
    {
      "epoch": 750.55,
      "learning_rate": 0.024974591154516126,
      "loss": 0.5786,
      "step": 465340
    },
    {
      "epoch": 750.58,
      "learning_rate": 0.02497136535129032,
      "loss": 0.5724,
      "step": 465360
    },
    {
      "epoch": 750.61,
      "learning_rate": 0.024968139548064514,
      "loss": 0.5666,
      "step": 465380
    },
    {
      "epoch": 750.65,
      "learning_rate": 0.024964913744838706,
      "loss": 0.5724,
      "step": 465400
    },
    {
      "epoch": 750.68,
      "learning_rate": 0.024961687941612902,
      "loss": 0.5782,
      "step": 465420
    },
    {
      "epoch": 750.71,
      "learning_rate": 0.024958462138387098,
      "loss": 0.5671,
      "step": 465440
    },
    {
      "epoch": 750.74,
      "learning_rate": 0.02495523633516129,
      "loss": 0.5673,
      "step": 465460
    },
    {
      "epoch": 750.77,
      "learning_rate": 0.024952010531935485,
      "loss": 0.577,
      "step": 465480
    },
    {
      "epoch": 750.81,
      "learning_rate": 0.024948784728709678,
      "loss": 0.5685,
      "step": 465500
    },
    {
      "epoch": 750.84,
      "learning_rate": 0.024945558925483873,
      "loss": 0.572,
      "step": 465520
    },
    {
      "epoch": 750.87,
      "learning_rate": 0.02494233312225807,
      "loss": 0.5761,
      "step": 465540
    },
    {
      "epoch": 750.9,
      "learning_rate": 0.02493910731903226,
      "loss": 0.5823,
      "step": 465560
    },
    {
      "epoch": 750.94,
      "learning_rate": 0.024935881515806457,
      "loss": 0.5827,
      "step": 465580
    },
    {
      "epoch": 750.97,
      "learning_rate": 0.02493265571258065,
      "loss": 0.5803,
      "step": 465600
    },
    {
      "epoch": 751.0,
      "learning_rate": 0.024929429909354834,
      "loss": 0.5838,
      "step": 465620
    },
    {
      "epoch": 751.0,
      "eval_accuracy": {
        "accuracy": 0.7755054250253688
      },
      "eval_loss": 0.9364791512489319,
      "eval_runtime": 3.1239,
      "eval_samples_per_second": 4101.012,
      "eval_steps_per_second": 64.343,
      "step": 465620
    },
    {
      "epoch": 751.03,
      "learning_rate": 0.024926204106129026,
      "loss": 0.5744,
      "step": 465640
    },
    {
      "epoch": 751.06,
      "learning_rate": 0.024922978302903222,
      "loss": 0.566,
      "step": 465660
    },
    {
      "epoch": 751.1,
      "learning_rate": 0.024919752499677417,
      "loss": 0.5679,
      "step": 465680
    },
    {
      "epoch": 751.13,
      "learning_rate": 0.02491652669645161,
      "loss": 0.5805,
      "step": 465700
    },
    {
      "epoch": 751.16,
      "learning_rate": 0.024913300893225805,
      "loss": 0.5725,
      "step": 465720
    },
    {
      "epoch": 751.19,
      "learning_rate": 0.024910075089999997,
      "loss": 0.5518,
      "step": 465740
    },
    {
      "epoch": 751.23,
      "learning_rate": 0.024906849286774193,
      "loss": 0.5622,
      "step": 465760
    },
    {
      "epoch": 751.26,
      "learning_rate": 0.02490362348354839,
      "loss": 0.5685,
      "step": 465780
    },
    {
      "epoch": 751.29,
      "learning_rate": 0.02490039768032258,
      "loss": 0.5702,
      "step": 465800
    },
    {
      "epoch": 751.32,
      "learning_rate": 0.024897171877096776,
      "loss": 0.5653,
      "step": 465820
    },
    {
      "epoch": 751.35,
      "learning_rate": 0.02489394607387097,
      "loss": 0.5685,
      "step": 465840
    },
    {
      "epoch": 751.39,
      "learning_rate": 0.024890720270645164,
      "loss": 0.5683,
      "step": 465860
    },
    {
      "epoch": 751.42,
      "learning_rate": 0.02488749446741936,
      "loss": 0.5665,
      "step": 465880
    },
    {
      "epoch": 751.45,
      "learning_rate": 0.024884268664193552,
      "loss": 0.5661,
      "step": 465900
    },
    {
      "epoch": 751.48,
      "learning_rate": 0.024881204151129033,
      "loss": 0.5876,
      "step": 465920
    },
    {
      "epoch": 751.52,
      "learning_rate": 0.024877978347903226,
      "loss": 0.5801,
      "step": 465940
    },
    {
      "epoch": 751.55,
      "learning_rate": 0.02487475254467742,
      "loss": 0.5699,
      "step": 465960
    },
    {
      "epoch": 751.58,
      "learning_rate": 0.024871526741451617,
      "loss": 0.5929,
      "step": 465980
    },
    {
      "epoch": 751.61,
      "learning_rate": 0.02486830093822581,
      "loss": 0.5685,
      "step": 466000
    },
    {
      "epoch": 751.65,
      "learning_rate": 0.024865075135000005,
      "loss": 0.574,
      "step": 466020
    },
    {
      "epoch": 751.68,
      "learning_rate": 0.024861849331774197,
      "loss": 0.592,
      "step": 466040
    },
    {
      "epoch": 751.71,
      "learning_rate": 0.024858623528548392,
      "loss": 0.5819,
      "step": 466060
    },
    {
      "epoch": 751.74,
      "learning_rate": 0.024855397725322574,
      "loss": 0.5703,
      "step": 466080
    },
    {
      "epoch": 751.77,
      "learning_rate": 0.02485217192209677,
      "loss": 0.5752,
      "step": 466100
    },
    {
      "epoch": 751.81,
      "learning_rate": 0.024848946118870965,
      "loss": 0.5697,
      "step": 466120
    },
    {
      "epoch": 751.84,
      "learning_rate": 0.024845720315645158,
      "loss": 0.5823,
      "step": 466140
    },
    {
      "epoch": 751.87,
      "learning_rate": 0.024842494512419353,
      "loss": 0.5901,
      "step": 466160
    },
    {
      "epoch": 751.9,
      "learning_rate": 0.024839268709193545,
      "loss": 0.5707,
      "step": 466180
    },
    {
      "epoch": 751.94,
      "learning_rate": 0.02483604290596774,
      "loss": 0.5616,
      "step": 466200
    },
    {
      "epoch": 751.97,
      "learning_rate": 0.024832817102741937,
      "loss": 0.5744,
      "step": 466220
    },
    {
      "epoch": 752.0,
      "learning_rate": 0.02482959129951613,
      "loss": 0.5597,
      "step": 466240
    },
    {
      "epoch": 752.0,
      "eval_accuracy": {
        "accuracy": 0.7820622902193427
      },
      "eval_loss": 0.9220115542411804,
      "eval_runtime": 3.0525,
      "eval_samples_per_second": 4196.913,
      "eval_steps_per_second": 65.848,
      "step": 466240
    },
    {
      "epoch": 752.03,
      "learning_rate": 0.024826365496290324,
      "loss": 0.5757,
      "step": 466260
    },
    {
      "epoch": 752.06,
      "learning_rate": 0.024823139693064517,
      "loss": 0.5667,
      "step": 466280
    },
    {
      "epoch": 752.1,
      "learning_rate": 0.024819913889838712,
      "loss": 0.5665,
      "step": 466300
    },
    {
      "epoch": 752.13,
      "learning_rate": 0.024816688086612908,
      "loss": 0.5578,
      "step": 466320
    },
    {
      "epoch": 752.16,
      "learning_rate": 0.0248134622833871,
      "loss": 0.5703,
      "step": 466340
    },
    {
      "epoch": 752.19,
      "learning_rate": 0.024810236480161296,
      "loss": 0.5612,
      "step": 466360
    },
    {
      "epoch": 752.23,
      "learning_rate": 0.02480701067693549,
      "loss": 0.5561,
      "step": 466380
    },
    {
      "epoch": 752.26,
      "learning_rate": 0.024803784873709673,
      "loss": 0.5653,
      "step": 466400
    },
    {
      "epoch": 752.29,
      "learning_rate": 0.02480055907048387,
      "loss": 0.5669,
      "step": 466420
    },
    {
      "epoch": 752.32,
      "learning_rate": 0.02479733326725806,
      "loss": 0.5662,
      "step": 466440
    },
    {
      "epoch": 752.35,
      "learning_rate": 0.024794107464032256,
      "loss": 0.566,
      "step": 466460
    },
    {
      "epoch": 752.39,
      "learning_rate": 0.02479088166080645,
      "loss": 0.5771,
      "step": 466480
    },
    {
      "epoch": 752.42,
      "learning_rate": 0.024787655857580644,
      "loss": 0.5912,
      "step": 466500
    },
    {
      "epoch": 752.45,
      "learning_rate": 0.02478443005435484,
      "loss": 0.5832,
      "step": 466520
    },
    {
      "epoch": 752.48,
      "learning_rate": 0.024781204251129032,
      "loss": 0.5689,
      "step": 466540
    },
    {
      "epoch": 752.52,
      "learning_rate": 0.024777978447903228,
      "loss": 0.578,
      "step": 466560
    },
    {
      "epoch": 752.55,
      "learning_rate": 0.02477475264467742,
      "loss": 0.5539,
      "step": 466580
    },
    {
      "epoch": 752.58,
      "learning_rate": 0.024771526841451615,
      "loss": 0.5837,
      "step": 466600
    },
    {
      "epoch": 752.61,
      "learning_rate": 0.02476830103822581,
      "loss": 0.5831,
      "step": 466620
    },
    {
      "epoch": 752.65,
      "learning_rate": 0.024765075235000003,
      "loss": 0.5736,
      "step": 466640
    },
    {
      "epoch": 752.68,
      "learning_rate": 0.0247618494317742,
      "loss": 0.5673,
      "step": 466660
    },
    {
      "epoch": 752.71,
      "learning_rate": 0.02475862362854839,
      "loss": 0.5724,
      "step": 466680
    },
    {
      "epoch": 752.74,
      "learning_rate": 0.024755397825322576,
      "loss": 0.5752,
      "step": 466700
    },
    {
      "epoch": 752.77,
      "learning_rate": 0.024752172022096768,
      "loss": 0.5827,
      "step": 466720
    },
    {
      "epoch": 752.81,
      "learning_rate": 0.024748946218870964,
      "loss": 0.5814,
      "step": 466740
    },
    {
      "epoch": 752.84,
      "learning_rate": 0.02474572041564516,
      "loss": 0.5736,
      "step": 466760
    },
    {
      "epoch": 752.87,
      "learning_rate": 0.02474249461241935,
      "loss": 0.5768,
      "step": 466780
    },
    {
      "epoch": 752.9,
      "learning_rate": 0.024739268809193547,
      "loss": 0.5788,
      "step": 466800
    },
    {
      "epoch": 752.94,
      "learning_rate": 0.02473604300596774,
      "loss": 0.5802,
      "step": 466820
    },
    {
      "epoch": 752.97,
      "learning_rate": 0.024732817202741935,
      "loss": 0.5766,
      "step": 466840
    },
    {
      "epoch": 753.0,
      "learning_rate": 0.024729752689677413,
      "loss": 0.5903,
      "step": 466860
    },
    {
      "epoch": 753.0,
      "eval_accuracy": {
        "accuracy": 0.7795644368121146
      },
      "eval_loss": 0.9343748092651367,
      "eval_runtime": 3.2742,
      "eval_samples_per_second": 3912.731,
      "eval_steps_per_second": 61.389,
      "step": 466860
    },
    {
      "epoch": 753.03,
      "learning_rate": 0.02472652688645161,
      "loss": 0.5668,
      "step": 466880
    },
    {
      "epoch": 753.06,
      "learning_rate": 0.024723301083225804,
      "loss": 0.5539,
      "step": 466900
    },
    {
      "epoch": 753.1,
      "learning_rate": 0.024720075279999996,
      "loss": 0.552,
      "step": 466920
    },
    {
      "epoch": 753.13,
      "learning_rate": 0.024716849476774192,
      "loss": 0.5726,
      "step": 466940
    },
    {
      "epoch": 753.16,
      "learning_rate": 0.024713623673548388,
      "loss": 0.5623,
      "step": 466960
    },
    {
      "epoch": 753.19,
      "learning_rate": 0.02471039787032258,
      "loss": 0.5554,
      "step": 466980
    },
    {
      "epoch": 753.23,
      "learning_rate": 0.024707172067096776,
      "loss": 0.5668,
      "step": 467000
    },
    {
      "epoch": 753.26,
      "learning_rate": 0.024703946263870968,
      "loss": 0.5559,
      "step": 467020
    },
    {
      "epoch": 753.29,
      "learning_rate": 0.024700720460645163,
      "loss": 0.5625,
      "step": 467040
    },
    {
      "epoch": 753.32,
      "learning_rate": 0.02469749465741936,
      "loss": 0.565,
      "step": 467060
    },
    {
      "epoch": 753.35,
      "learning_rate": 0.02469426885419355,
      "loss": 0.5645,
      "step": 467080
    },
    {
      "epoch": 753.39,
      "learning_rate": 0.024691043050967747,
      "loss": 0.5642,
      "step": 467100
    },
    {
      "epoch": 753.42,
      "learning_rate": 0.02468781724774194,
      "loss": 0.574,
      "step": 467120
    },
    {
      "epoch": 753.45,
      "learning_rate": 0.024684591444516134,
      "loss": 0.5702,
      "step": 467140
    },
    {
      "epoch": 753.48,
      "learning_rate": 0.024681365641290316,
      "loss": 0.5652,
      "step": 467160
    },
    {
      "epoch": 753.52,
      "learning_rate": 0.024678139838064512,
      "loss": 0.5715,
      "step": 467180
    },
    {
      "epoch": 753.55,
      "learning_rate": 0.024674914034838707,
      "loss": 0.554,
      "step": 467200
    },
    {
      "epoch": 753.58,
      "learning_rate": 0.0246716882316129,
      "loss": 0.5612,
      "step": 467220
    },
    {
      "epoch": 753.61,
      "learning_rate": 0.024668462428387095,
      "loss": 0.581,
      "step": 467240
    },
    {
      "epoch": 753.65,
      "learning_rate": 0.024665236625161287,
      "loss": 0.5907,
      "step": 467260
    },
    {
      "epoch": 753.68,
      "learning_rate": 0.024662010821935483,
      "loss": 0.586,
      "step": 467280
    },
    {
      "epoch": 753.71,
      "learning_rate": 0.02465878501870968,
      "loss": 0.5966,
      "step": 467300
    },
    {
      "epoch": 753.74,
      "learning_rate": 0.02465555921548387,
      "loss": 0.5621,
      "step": 467320
    },
    {
      "epoch": 753.77,
      "learning_rate": 0.024652333412258066,
      "loss": 0.5822,
      "step": 467340
    },
    {
      "epoch": 753.81,
      "learning_rate": 0.02464910760903226,
      "loss": 0.5842,
      "step": 467360
    },
    {
      "epoch": 753.84,
      "learning_rate": 0.024645881805806454,
      "loss": 0.5814,
      "step": 467380
    },
    {
      "epoch": 753.87,
      "learning_rate": 0.02464265600258065,
      "loss": 0.5636,
      "step": 467400
    },
    {
      "epoch": 753.9,
      "learning_rate": 0.024639430199354842,
      "loss": 0.5777,
      "step": 467420
    },
    {
      "epoch": 753.94,
      "learning_rate": 0.024636204396129038,
      "loss": 0.5745,
      "step": 467440
    },
    {
      "epoch": 753.97,
      "learning_rate": 0.02463297859290322,
      "loss": 0.5716,
      "step": 467460
    },
    {
      "epoch": 754.0,
      "learning_rate": 0.024629752789677415,
      "loss": 0.578,
      "step": 467480
    },
    {
      "epoch": 754.0,
      "eval_accuracy": {
        "accuracy": 0.7724611661853095
      },
      "eval_loss": 0.9518113732337952,
      "eval_runtime": 2.9843,
      "eval_samples_per_second": 4292.857,
      "eval_steps_per_second": 67.353,
      "step": 467480
    },
    {
      "epoch": 754.03,
      "learning_rate": 0.02462652698645161,
      "loss": 0.5894,
      "step": 467500
    },
    {
      "epoch": 754.06,
      "learning_rate": 0.024623301183225803,
      "loss": 0.5779,
      "step": 467520
    },
    {
      "epoch": 754.1,
      "learning_rate": 0.02462007538,
      "loss": 0.5674,
      "step": 467540
    },
    {
      "epoch": 754.13,
      "learning_rate": 0.02461684957677419,
      "loss": 0.5697,
      "step": 467560
    },
    {
      "epoch": 754.16,
      "learning_rate": 0.024613623773548386,
      "loss": 0.5559,
      "step": 467580
    },
    {
      "epoch": 754.19,
      "learning_rate": 0.024610397970322582,
      "loss": 0.5608,
      "step": 467600
    },
    {
      "epoch": 754.23,
      "learning_rate": 0.024607172167096774,
      "loss": 0.5636,
      "step": 467620
    },
    {
      "epoch": 754.26,
      "learning_rate": 0.02460394636387097,
      "loss": 0.571,
      "step": 467640
    },
    {
      "epoch": 754.29,
      "learning_rate": 0.024600720560645162,
      "loss": 0.5657,
      "step": 467660
    },
    {
      "epoch": 754.32,
      "learning_rate": 0.024597494757419357,
      "loss": 0.562,
      "step": 467680
    },
    {
      "epoch": 754.35,
      "learning_rate": 0.024594268954193553,
      "loss": 0.5744,
      "step": 467700
    },
    {
      "epoch": 754.39,
      "learning_rate": 0.024591043150967745,
      "loss": 0.5719,
      "step": 467720
    },
    {
      "epoch": 754.42,
      "learning_rate": 0.02458781734774194,
      "loss": 0.5762,
      "step": 467740
    },
    {
      "epoch": 754.45,
      "learning_rate": 0.024584591544516133,
      "loss": 0.5752,
      "step": 467760
    },
    {
      "epoch": 754.48,
      "learning_rate": 0.024581365741290318,
      "loss": 0.5729,
      "step": 467780
    },
    {
      "epoch": 754.52,
      "learning_rate": 0.02457813993806451,
      "loss": 0.574,
      "step": 467800
    },
    {
      "epoch": 754.55,
      "learning_rate": 0.024574914134838706,
      "loss": 0.564,
      "step": 467820
    },
    {
      "epoch": 754.58,
      "learning_rate": 0.0245716883316129,
      "loss": 0.5802,
      "step": 467840
    },
    {
      "epoch": 754.61,
      "learning_rate": 0.024568462528387094,
      "loss": 0.5905,
      "step": 467860
    },
    {
      "epoch": 754.65,
      "learning_rate": 0.02456523672516129,
      "loss": 0.5704,
      "step": 467880
    },
    {
      "epoch": 754.68,
      "learning_rate": 0.02456201092193548,
      "loss": 0.5855,
      "step": 467900
    },
    {
      "epoch": 754.71,
      "learning_rate": 0.024558785118709677,
      "loss": 0.5617,
      "step": 467920
    },
    {
      "epoch": 754.74,
      "learning_rate": 0.024555559315483873,
      "loss": 0.5674,
      "step": 467940
    },
    {
      "epoch": 754.77,
      "learning_rate": 0.024552333512258065,
      "loss": 0.5631,
      "step": 467960
    },
    {
      "epoch": 754.81,
      "learning_rate": 0.02454910770903226,
      "loss": 0.5717,
      "step": 467980
    },
    {
      "epoch": 754.84,
      "learning_rate": 0.024545881905806453,
      "loss": 0.5606,
      "step": 468000
    },
    {
      "epoch": 754.87,
      "learning_rate": 0.02454265610258065,
      "loss": 0.5705,
      "step": 468020
    },
    {
      "epoch": 754.9,
      "learning_rate": 0.024539430299354844,
      "loss": 0.5712,
      "step": 468040
    },
    {
      "epoch": 754.94,
      "learning_rate": 0.024536204496129036,
      "loss": 0.5802,
      "step": 468060
    },
    {
      "epoch": 754.97,
      "learning_rate": 0.02453297869290322,
      "loss": 0.5743,
      "step": 468080
    },
    {
      "epoch": 755.0,
      "learning_rate": 0.024529752889677413,
      "loss": 0.5801,
      "step": 468100
    },
    {
      "epoch": 755.0,
      "eval_accuracy": {
        "accuracy": 0.7740223245648271
      },
      "eval_loss": 0.9301639199256897,
      "eval_runtime": 4.5854,
      "eval_samples_per_second": 2793.871,
      "eval_steps_per_second": 43.835,
      "step": 468100
    },
    {
      "epoch": 755.03,
      "learning_rate": 0.02452652708645161,
      "loss": 0.5765,
      "step": 468120
    },
    {
      "epoch": 755.06,
      "learning_rate": 0.024523301283225805,
      "loss": 0.5523,
      "step": 468140
    },
    {
      "epoch": 755.1,
      "learning_rate": 0.024520075479999997,
      "loss": 0.5548,
      "step": 468160
    },
    {
      "epoch": 755.13,
      "learning_rate": 0.024516849676774193,
      "loss": 0.5648,
      "step": 468180
    },
    {
      "epoch": 755.16,
      "learning_rate": 0.024513623873548385,
      "loss": 0.5616,
      "step": 468200
    },
    {
      "epoch": 755.19,
      "learning_rate": 0.02451039807032258,
      "loss": 0.5694,
      "step": 468220
    },
    {
      "epoch": 755.23,
      "learning_rate": 0.024507172267096776,
      "loss": 0.574,
      "step": 468240
    },
    {
      "epoch": 755.26,
      "learning_rate": 0.024503946463870968,
      "loss": 0.5563,
      "step": 468260
    },
    {
      "epoch": 755.29,
      "learning_rate": 0.024500720660645164,
      "loss": 0.5667,
      "step": 468280
    },
    {
      "epoch": 755.32,
      "learning_rate": 0.024497494857419356,
      "loss": 0.5628,
      "step": 468300
    },
    {
      "epoch": 755.35,
      "learning_rate": 0.02449426905419355,
      "loss": 0.5697,
      "step": 468320
    },
    {
      "epoch": 755.39,
      "learning_rate": 0.024491043250967747,
      "loss": 0.564,
      "step": 468340
    },
    {
      "epoch": 755.42,
      "learning_rate": 0.02448781744774194,
      "loss": 0.5628,
      "step": 468360
    },
    {
      "epoch": 755.45,
      "learning_rate": 0.024484591644516135,
      "loss": 0.5642,
      "step": 468380
    },
    {
      "epoch": 755.48,
      "learning_rate": 0.024481365841290317,
      "loss": 0.5645,
      "step": 468400
    },
    {
      "epoch": 755.52,
      "learning_rate": 0.024478140038064512,
      "loss": 0.5689,
      "step": 468420
    },
    {
      "epoch": 755.55,
      "learning_rate": 0.024474914234838704,
      "loss": 0.5637,
      "step": 468440
    },
    {
      "epoch": 755.58,
      "learning_rate": 0.0244716884316129,
      "loss": 0.5812,
      "step": 468460
    },
    {
      "epoch": 755.61,
      "learning_rate": 0.024468462628387096,
      "loss": 0.5598,
      "step": 468480
    },
    {
      "epoch": 755.65,
      "learning_rate": 0.024465236825161288,
      "loss": 0.581,
      "step": 468500
    },
    {
      "epoch": 755.68,
      "learning_rate": 0.024462011021935483,
      "loss": 0.5904,
      "step": 468520
    },
    {
      "epoch": 755.71,
      "learning_rate": 0.024458785218709676,
      "loss": 0.5847,
      "step": 468540
    },
    {
      "epoch": 755.74,
      "learning_rate": 0.02445555941548387,
      "loss": 0.5576,
      "step": 468560
    },
    {
      "epoch": 755.77,
      "learning_rate": 0.024452333612258067,
      "loss": 0.5743,
      "step": 468580
    },
    {
      "epoch": 755.81,
      "learning_rate": 0.02444910780903226,
      "loss": 0.5681,
      "step": 468600
    },
    {
      "epoch": 755.84,
      "learning_rate": 0.024445882005806455,
      "loss": 0.5797,
      "step": 468620
    },
    {
      "epoch": 755.87,
      "learning_rate": 0.02444265620258065,
      "loss": 0.5636,
      "step": 468640
    },
    {
      "epoch": 755.9,
      "learning_rate": 0.024439430399354842,
      "loss": 0.5718,
      "step": 468660
    },
    {
      "epoch": 755.94,
      "learning_rate": 0.024436204596129038,
      "loss": 0.5742,
      "step": 468680
    },
    {
      "epoch": 755.97,
      "learning_rate": 0.02443297879290323,
      "loss": 0.572,
      "step": 468700
    },
    {
      "epoch": 756.0,
      "learning_rate": 0.024429752989677415,
      "loss": 0.5715,
      "step": 468720
    },
    {
      "epoch": 756.0,
      "eval_accuracy": {
        "accuracy": 0.7800327843259699
      },
      "eval_loss": 0.9312188029289246,
      "eval_runtime": 3.017,
      "eval_samples_per_second": 4246.326,
      "eval_steps_per_second": 66.623,
      "step": 468720
    },
    {
      "epoch": 756.03,
      "learning_rate": 0.024426527186451608,
      "loss": 0.5719,
      "step": 468740
    },
    {
      "epoch": 756.06,
      "learning_rate": 0.024423301383225803,
      "loss": 0.5686,
      "step": 468760
    },
    {
      "epoch": 756.1,
      "learning_rate": 0.02442007558,
      "loss": 0.5814,
      "step": 468780
    },
    {
      "epoch": 756.13,
      "learning_rate": 0.02441684977677419,
      "loss": 0.5583,
      "step": 468800
    },
    {
      "epoch": 756.16,
      "learning_rate": 0.024413623973548387,
      "loss": 0.5661,
      "step": 468820
    },
    {
      "epoch": 756.19,
      "learning_rate": 0.02441039817032258,
      "loss": 0.5742,
      "step": 468840
    },
    {
      "epoch": 756.23,
      "learning_rate": 0.024407172367096774,
      "loss": 0.5736,
      "step": 468860
    },
    {
      "epoch": 756.26,
      "learning_rate": 0.02440394656387097,
      "loss": 0.5689,
      "step": 468880
    },
    {
      "epoch": 756.29,
      "learning_rate": 0.024400720760645162,
      "loss": 0.5784,
      "step": 468900
    },
    {
      "epoch": 756.32,
      "learning_rate": 0.024397494957419358,
      "loss": 0.5638,
      "step": 468920
    },
    {
      "epoch": 756.35,
      "learning_rate": 0.02439426915419355,
      "loss": 0.5713,
      "step": 468940
    },
    {
      "epoch": 756.39,
      "learning_rate": 0.024391043350967746,
      "loss": 0.5819,
      "step": 468960
    },
    {
      "epoch": 756.42,
      "learning_rate": 0.02438781754774194,
      "loss": 0.5755,
      "step": 468980
    },
    {
      "epoch": 756.45,
      "learning_rate": 0.024384591744516133,
      "loss": 0.5672,
      "step": 469000
    },
    {
      "epoch": 756.48,
      "learning_rate": 0.02438136594129032,
      "loss": 0.5664,
      "step": 469020
    },
    {
      "epoch": 756.52,
      "learning_rate": 0.02437814013806451,
      "loss": 0.5709,
      "step": 469040
    },
    {
      "epoch": 756.55,
      "learning_rate": 0.024374914334838706,
      "loss": 0.5711,
      "step": 469060
    },
    {
      "epoch": 756.58,
      "learning_rate": 0.0243716885316129,
      "loss": 0.5703,
      "step": 469080
    },
    {
      "epoch": 756.61,
      "learning_rate": 0.024368462728387094,
      "loss": 0.5706,
      "step": 469100
    },
    {
      "epoch": 756.65,
      "learning_rate": 0.02436523692516129,
      "loss": 0.5746,
      "step": 469120
    },
    {
      "epoch": 756.68,
      "learning_rate": 0.024362011121935482,
      "loss": 0.5621,
      "step": 469140
    },
    {
      "epoch": 756.71,
      "learning_rate": 0.024358785318709678,
      "loss": 0.5832,
      "step": 469160
    },
    {
      "epoch": 756.74,
      "learning_rate": 0.024355559515483873,
      "loss": 0.5582,
      "step": 469180
    },
    {
      "epoch": 756.77,
      "learning_rate": 0.024352333712258065,
      "loss": 0.5598,
      "step": 469200
    },
    {
      "epoch": 756.81,
      "learning_rate": 0.02434910790903226,
      "loss": 0.5736,
      "step": 469220
    },
    {
      "epoch": 756.84,
      "learning_rate": 0.024345882105806453,
      "loss": 0.5671,
      "step": 469240
    },
    {
      "epoch": 756.87,
      "learning_rate": 0.02434265630258065,
      "loss": 0.5575,
      "step": 469260
    },
    {
      "epoch": 756.9,
      "learning_rate": 0.024339430499354844,
      "loss": 0.5555,
      "step": 469280
    },
    {
      "epoch": 756.94,
      "learning_rate": 0.024336204696129037,
      "loss": 0.5797,
      "step": 469300
    },
    {
      "epoch": 756.97,
      "learning_rate": 0.024332978892903232,
      "loss": 0.5796,
      "step": 469320
    },
    {
      "epoch": 757.0,
      "learning_rate": 0.024329753089677414,
      "loss": 0.5717,
      "step": 469340
    },
    {
      "epoch": 757.0,
      "eval_accuracy": {
        "accuracy": 0.7781593942705487
      },
      "eval_loss": 0.9185121059417725,
      "eval_runtime": 3.1907,
      "eval_samples_per_second": 4015.136,
      "eval_steps_per_second": 62.996,
      "step": 469340
    },
    {
      "epoch": 757.03,
      "learning_rate": 0.02432652728645161,
      "loss": 0.5849,
      "step": 469360
    },
    {
      "epoch": 757.06,
      "learning_rate": 0.0243233014832258,
      "loss": 0.56,
      "step": 469380
    },
    {
      "epoch": 757.1,
      "learning_rate": 0.024320075679999997,
      "loss": 0.5662,
      "step": 469400
    },
    {
      "epoch": 757.13,
      "learning_rate": 0.024316849876774193,
      "loss": 0.56,
      "step": 469420
    },
    {
      "epoch": 757.16,
      "learning_rate": 0.024313624073548385,
      "loss": 0.5639,
      "step": 469440
    },
    {
      "epoch": 757.19,
      "learning_rate": 0.02431039827032258,
      "loss": 0.5652,
      "step": 469460
    },
    {
      "epoch": 757.23,
      "learning_rate": 0.024307172467096773,
      "loss": 0.5622,
      "step": 469480
    },
    {
      "epoch": 757.26,
      "learning_rate": 0.02430394666387097,
      "loss": 0.5637,
      "step": 469500
    },
    {
      "epoch": 757.29,
      "learning_rate": 0.024300720860645164,
      "loss": 0.5725,
      "step": 469520
    },
    {
      "epoch": 757.32,
      "learning_rate": 0.024297495057419356,
      "loss": 0.5616,
      "step": 469540
    },
    {
      "epoch": 757.35,
      "learning_rate": 0.024294269254193552,
      "loss": 0.5761,
      "step": 469560
    },
    {
      "epoch": 757.39,
      "learning_rate": 0.024291043450967744,
      "loss": 0.569,
      "step": 469580
    },
    {
      "epoch": 757.42,
      "learning_rate": 0.02428781764774194,
      "loss": 0.5688,
      "step": 469600
    },
    {
      "epoch": 757.45,
      "learning_rate": 0.024284591844516135,
      "loss": 0.5762,
      "step": 469620
    },
    {
      "epoch": 757.48,
      "learning_rate": 0.024281366041290317,
      "loss": 0.5684,
      "step": 469640
    },
    {
      "epoch": 757.52,
      "learning_rate": 0.024278140238064513,
      "loss": 0.5745,
      "step": 469660
    },
    {
      "epoch": 757.55,
      "learning_rate": 0.024274914434838705,
      "loss": 0.5683,
      "step": 469680
    },
    {
      "epoch": 757.58,
      "learning_rate": 0.0242716886316129,
      "loss": 0.5617,
      "step": 469700
    },
    {
      "epoch": 757.61,
      "learning_rate": 0.024268462828387093,
      "loss": 0.5609,
      "step": 469720
    },
    {
      "epoch": 757.65,
      "learning_rate": 0.024265237025161288,
      "loss": 0.5572,
      "step": 469740
    },
    {
      "epoch": 757.68,
      "learning_rate": 0.024262011221935484,
      "loss": 0.5679,
      "step": 469760
    },
    {
      "epoch": 757.71,
      "learning_rate": 0.024258785418709676,
      "loss": 0.5639,
      "step": 469780
    },
    {
      "epoch": 757.74,
      "learning_rate": 0.02425555961548387,
      "loss": 0.5714,
      "step": 469800
    },
    {
      "epoch": 757.77,
      "learning_rate": 0.024252333812258067,
      "loss": 0.5747,
      "step": 469820
    },
    {
      "epoch": 757.81,
      "learning_rate": 0.02424910800903226,
      "loss": 0.5731,
      "step": 469840
    },
    {
      "epoch": 757.84,
      "learning_rate": 0.024245882205806455,
      "loss": 0.5855,
      "step": 469860
    },
    {
      "epoch": 757.87,
      "learning_rate": 0.024242656402580647,
      "loss": 0.5658,
      "step": 469880
    },
    {
      "epoch": 757.9,
      "learning_rate": 0.024239430599354843,
      "loss": 0.5686,
      "step": 469900
    },
    {
      "epoch": 757.94,
      "learning_rate": 0.02423620479612904,
      "loss": 0.5756,
      "step": 469920
    },
    {
      "epoch": 757.97,
      "learning_rate": 0.02423297899290323,
      "loss": 0.573,
      "step": 469940
    },
    {
      "epoch": 758.0,
      "learning_rate": 0.024229753189677416,
      "loss": 0.5862,
      "step": 469960
    },
    {
      "epoch": 758.0,
      "eval_accuracy": {
        "accuracy": 0.7834673327609086
      },
      "eval_loss": 0.9255019426345825,
      "eval_runtime": 4.4988,
      "eval_samples_per_second": 2847.636,
      "eval_steps_per_second": 44.678,
      "step": 469960
    },
    {
      "epoch": 758.03,
      "learning_rate": 0.024226527386451608,
      "loss": 0.5748,
      "step": 469980
    },
    {
      "epoch": 758.06,
      "learning_rate": 0.024223301583225804,
      "loss": 0.5611,
      "step": 470000
    },
    {
      "epoch": 758.1,
      "learning_rate": 0.024220075779999996,
      "loss": 0.5705,
      "step": 470020
    },
    {
      "epoch": 758.13,
      "learning_rate": 0.02421684997677419,
      "loss": 0.5598,
      "step": 470040
    },
    {
      "epoch": 758.16,
      "learning_rate": 0.024213624173548387,
      "loss": 0.562,
      "step": 470060
    },
    {
      "epoch": 758.19,
      "learning_rate": 0.02421039837032258,
      "loss": 0.5633,
      "step": 470080
    },
    {
      "epoch": 758.23,
      "learning_rate": 0.024207172567096775,
      "loss": 0.5528,
      "step": 470100
    },
    {
      "epoch": 758.26,
      "learning_rate": 0.024203946763870967,
      "loss": 0.5735,
      "step": 470120
    },
    {
      "epoch": 758.29,
      "learning_rate": 0.024200720960645163,
      "loss": 0.5658,
      "step": 470140
    },
    {
      "epoch": 758.32,
      "learning_rate": 0.024197495157419358,
      "loss": 0.5524,
      "step": 470160
    },
    {
      "epoch": 758.35,
      "learning_rate": 0.02419426935419355,
      "loss": 0.5649,
      "step": 470180
    },
    {
      "epoch": 758.39,
      "learning_rate": 0.024191043550967746,
      "loss": 0.56,
      "step": 470200
    },
    {
      "epoch": 758.42,
      "learning_rate": 0.024187817747741938,
      "loss": 0.5641,
      "step": 470220
    },
    {
      "epoch": 758.45,
      "learning_rate": 0.024184591944516134,
      "loss": 0.5743,
      "step": 470240
    },
    {
      "epoch": 758.48,
      "learning_rate": 0.024181366141290316,
      "loss": 0.5664,
      "step": 470260
    },
    {
      "epoch": 758.52,
      "learning_rate": 0.02417814033806451,
      "loss": 0.577,
      "step": 470280
    },
    {
      "epoch": 758.55,
      "learning_rate": 0.024174914534838707,
      "loss": 0.5541,
      "step": 470300
    },
    {
      "epoch": 758.58,
      "learning_rate": 0.0241716887316129,
      "loss": 0.5611,
      "step": 470320
    },
    {
      "epoch": 758.61,
      "learning_rate": 0.024168462928387095,
      "loss": 0.5546,
      "step": 470340
    },
    {
      "epoch": 758.65,
      "learning_rate": 0.02416523712516129,
      "loss": 0.5656,
      "step": 470360
    },
    {
      "epoch": 758.68,
      "learning_rate": 0.024162011321935482,
      "loss": 0.5696,
      "step": 470380
    },
    {
      "epoch": 758.71,
      "learning_rate": 0.024158785518709678,
      "loss": 0.5735,
      "step": 470400
    },
    {
      "epoch": 758.74,
      "learning_rate": 0.02415555971548387,
      "loss": 0.5752,
      "step": 470420
    },
    {
      "epoch": 758.77,
      "learning_rate": 0.024152333912258066,
      "loss": 0.5628,
      "step": 470440
    },
    {
      "epoch": 758.81,
      "learning_rate": 0.02414910810903226,
      "loss": 0.58,
      "step": 470460
    },
    {
      "epoch": 758.84,
      "learning_rate": 0.024145882305806454,
      "loss": 0.571,
      "step": 470480
    },
    {
      "epoch": 758.87,
      "learning_rate": 0.02414265650258065,
      "loss": 0.5746,
      "step": 470500
    },
    {
      "epoch": 758.9,
      "learning_rate": 0.02413943069935484,
      "loss": 0.565,
      "step": 470520
    },
    {
      "epoch": 758.94,
      "learning_rate": 0.024136204896129037,
      "loss": 0.5642,
      "step": 470540
    },
    {
      "epoch": 758.97,
      "learning_rate": 0.024132979092903233,
      "loss": 0.5717,
      "step": 470560
    },
    {
      "epoch": 759.0,
      "learning_rate": 0.02412991457983871,
      "loss": 0.5699,
      "step": 470580
    },
    {
      "epoch": 759.0,
      "eval_accuracy": {
        "accuracy": 0.7815939427054874
      },
      "eval_loss": 0.9229989647865295,
      "eval_runtime": 3.0938,
      "eval_samples_per_second": 4140.868,
      "eval_steps_per_second": 64.969,
      "step": 470580
    },
    {
      "epoch": 759.03,
      "learning_rate": 0.024126688776612906,
      "loss": 0.5581,
      "step": 470600
    },
    {
      "epoch": 759.06,
      "learning_rate": 0.0241234629733871,
      "loss": 0.5635,
      "step": 470620
    },
    {
      "epoch": 759.1,
      "learning_rate": 0.024120237170161294,
      "loss": 0.5547,
      "step": 470640
    },
    {
      "epoch": 759.13,
      "learning_rate": 0.024117011366935486,
      "loss": 0.564,
      "step": 470660
    },
    {
      "epoch": 759.16,
      "learning_rate": 0.024113785563709682,
      "loss": 0.5683,
      "step": 470680
    },
    {
      "epoch": 759.19,
      "learning_rate": 0.024110559760483877,
      "loss": 0.5528,
      "step": 470700
    },
    {
      "epoch": 759.23,
      "learning_rate": 0.02410733395725806,
      "loss": 0.5638,
      "step": 470720
    },
    {
      "epoch": 759.26,
      "learning_rate": 0.024104108154032255,
      "loss": 0.5633,
      "step": 470740
    },
    {
      "epoch": 759.29,
      "learning_rate": 0.024100882350806447,
      "loss": 0.5698,
      "step": 470760
    },
    {
      "epoch": 759.32,
      "learning_rate": 0.024097656547580643,
      "loss": 0.5736,
      "step": 470780
    },
    {
      "epoch": 759.35,
      "learning_rate": 0.024094430744354835,
      "loss": 0.5655,
      "step": 470800
    },
    {
      "epoch": 759.39,
      "learning_rate": 0.02409120494112903,
      "loss": 0.5667,
      "step": 470820
    },
    {
      "epoch": 759.42,
      "learning_rate": 0.024087979137903226,
      "loss": 0.5663,
      "step": 470840
    },
    {
      "epoch": 759.45,
      "learning_rate": 0.024084753334677418,
      "loss": 0.5641,
      "step": 470860
    },
    {
      "epoch": 759.48,
      "learning_rate": 0.024081527531451614,
      "loss": 0.5691,
      "step": 470880
    },
    {
      "epoch": 759.52,
      "learning_rate": 0.02407830172822581,
      "loss": 0.5685,
      "step": 470900
    },
    {
      "epoch": 759.55,
      "learning_rate": 0.024075075925,
      "loss": 0.5702,
      "step": 470920
    },
    {
      "epoch": 759.58,
      "learning_rate": 0.024071850121774197,
      "loss": 0.5648,
      "step": 470940
    },
    {
      "epoch": 759.61,
      "learning_rate": 0.02406862431854839,
      "loss": 0.5739,
      "step": 470960
    },
    {
      "epoch": 759.65,
      "learning_rate": 0.024065398515322585,
      "loss": 0.5663,
      "step": 470980
    },
    {
      "epoch": 759.68,
      "learning_rate": 0.02406217271209678,
      "loss": 0.5629,
      "step": 471000
    },
    {
      "epoch": 759.71,
      "learning_rate": 0.024058946908870973,
      "loss": 0.5651,
      "step": 471020
    },
    {
      "epoch": 759.74,
      "learning_rate": 0.024055721105645158,
      "loss": 0.588,
      "step": 471040
    },
    {
      "epoch": 759.77,
      "learning_rate": 0.02405249530241935,
      "loss": 0.5659,
      "step": 471060
    },
    {
      "epoch": 759.81,
      "learning_rate": 0.024049269499193546,
      "loss": 0.5652,
      "step": 471080
    },
    {
      "epoch": 759.84,
      "learning_rate": 0.024046043695967738,
      "loss": 0.5686,
      "step": 471100
    },
    {
      "epoch": 759.87,
      "learning_rate": 0.024042817892741934,
      "loss": 0.5725,
      "step": 471120
    },
    {
      "epoch": 759.9,
      "learning_rate": 0.02403959208951613,
      "loss": 0.5719,
      "step": 471140
    },
    {
      "epoch": 759.94,
      "learning_rate": 0.02403636628629032,
      "loss": 0.5754,
      "step": 471160
    },
    {
      "epoch": 759.97,
      "learning_rate": 0.024033140483064517,
      "loss": 0.5676,
      "step": 471180
    },
    {
      "epoch": 760.0,
      "learning_rate": 0.02402991467983871,
      "loss": 0.5832,
      "step": 471200
    },
    {
      "epoch": 760.0,
      "eval_accuracy": {
        "accuracy": 0.7800327843259699
      },
      "eval_loss": 0.930922269821167,
      "eval_runtime": 3.1137,
      "eval_samples_per_second": 4114.375,
      "eval_steps_per_second": 64.553,
      "step": 471200
    },
    {
      "epoch": 760.03,
      "learning_rate": 0.024026688876612905,
      "loss": 0.5662,
      "step": 471220
    },
    {
      "epoch": 760.06,
      "learning_rate": 0.0240234630733871,
      "loss": 0.57,
      "step": 471240
    },
    {
      "epoch": 760.1,
      "learning_rate": 0.024020237270161292,
      "loss": 0.5534,
      "step": 471260
    },
    {
      "epoch": 760.13,
      "learning_rate": 0.024017011466935488,
      "loss": 0.5677,
      "step": 471280
    },
    {
      "epoch": 760.16,
      "learning_rate": 0.02401378566370968,
      "loss": 0.5595,
      "step": 471300
    },
    {
      "epoch": 760.19,
      "learning_rate": 0.024010559860483876,
      "loss": 0.565,
      "step": 471320
    },
    {
      "epoch": 760.23,
      "learning_rate": 0.024007334057258058,
      "loss": 0.5706,
      "step": 471340
    },
    {
      "epoch": 760.26,
      "learning_rate": 0.024004108254032253,
      "loss": 0.5541,
      "step": 471360
    },
    {
      "epoch": 760.29,
      "learning_rate": 0.02400088245080645,
      "loss": 0.5709,
      "step": 471380
    },
    {
      "epoch": 760.32,
      "learning_rate": 0.02399765664758064,
      "loss": 0.5771,
      "step": 471400
    },
    {
      "epoch": 760.35,
      "learning_rate": 0.023994430844354837,
      "loss": 0.5667,
      "step": 471420
    },
    {
      "epoch": 760.39,
      "learning_rate": 0.023991205041129032,
      "loss": 0.575,
      "step": 471440
    },
    {
      "epoch": 760.42,
      "learning_rate": 0.023987979237903224,
      "loss": 0.5757,
      "step": 471460
    },
    {
      "epoch": 760.45,
      "learning_rate": 0.02398475343467742,
      "loss": 0.5631,
      "step": 471480
    },
    {
      "epoch": 760.48,
      "learning_rate": 0.023981527631451612,
      "loss": 0.5581,
      "step": 471500
    },
    {
      "epoch": 760.52,
      "learning_rate": 0.023978301828225808,
      "loss": 0.568,
      "step": 471520
    },
    {
      "epoch": 760.55,
      "learning_rate": 0.023975076025000003,
      "loss": 0.5562,
      "step": 471540
    },
    {
      "epoch": 760.58,
      "learning_rate": 0.023971850221774196,
      "loss": 0.5643,
      "step": 471560
    },
    {
      "epoch": 760.61,
      "learning_rate": 0.02396862441854839,
      "loss": 0.5644,
      "step": 471580
    },
    {
      "epoch": 760.65,
      "learning_rate": 0.023965398615322583,
      "loss": 0.5731,
      "step": 471600
    },
    {
      "epoch": 760.68,
      "learning_rate": 0.02396217281209678,
      "loss": 0.5601,
      "step": 471620
    },
    {
      "epoch": 760.71,
      "learning_rate": 0.023958947008870975,
      "loss": 0.5833,
      "step": 471640
    },
    {
      "epoch": 760.74,
      "learning_rate": 0.023955721205645156,
      "loss": 0.5634,
      "step": 471660
    },
    {
      "epoch": 760.77,
      "learning_rate": 0.023952495402419352,
      "loss": 0.5746,
      "step": 471680
    },
    {
      "epoch": 760.81,
      "learning_rate": 0.023949269599193544,
      "loss": 0.5623,
      "step": 471700
    },
    {
      "epoch": 760.84,
      "learning_rate": 0.02394604379596774,
      "loss": 0.5678,
      "step": 471720
    },
    {
      "epoch": 760.87,
      "learning_rate": 0.023942817992741932,
      "loss": 0.5693,
      "step": 471740
    },
    {
      "epoch": 760.9,
      "learning_rate": 0.023939592189516128,
      "loss": 0.5664,
      "step": 471760
    },
    {
      "epoch": 760.94,
      "learning_rate": 0.023936366386290323,
      "loss": 0.5695,
      "step": 471780
    },
    {
      "epoch": 760.97,
      "learning_rate": 0.023933140583064515,
      "loss": 0.5667,
      "step": 471800
    },
    {
      "epoch": 761.0,
      "learning_rate": 0.02392991477983871,
      "loss": 0.5622,
      "step": 471820
    },
    {
      "epoch": 761.0,
      "eval_accuracy": {
        "accuracy": 0.7822964639762704
      },
      "eval_loss": 0.928307294845581,
      "eval_runtime": 3.0969,
      "eval_samples_per_second": 4136.651,
      "eval_steps_per_second": 64.903,
      "step": 471820
    },
    {
      "epoch": 761.03,
      "learning_rate": 0.023926688976612903,
      "loss": 0.5854,
      "step": 471840
    },
    {
      "epoch": 761.06,
      "learning_rate": 0.0239234631733871,
      "loss": 0.5592,
      "step": 471860
    },
    {
      "epoch": 761.1,
      "learning_rate": 0.023920237370161294,
      "loss": 0.5645,
      "step": 471880
    },
    {
      "epoch": 761.13,
      "learning_rate": 0.023917011566935487,
      "loss": 0.5531,
      "step": 471900
    },
    {
      "epoch": 761.16,
      "learning_rate": 0.023913785763709682,
      "loss": 0.5519,
      "step": 471920
    },
    {
      "epoch": 761.19,
      "learning_rate": 0.023910559960483874,
      "loss": 0.5563,
      "step": 471940
    },
    {
      "epoch": 761.23,
      "learning_rate": 0.02390733415725806,
      "loss": 0.5624,
      "step": 471960
    },
    {
      "epoch": 761.26,
      "learning_rate": 0.02390410835403225,
      "loss": 0.5636,
      "step": 471980
    },
    {
      "epoch": 761.29,
      "learning_rate": 0.023900882550806447,
      "loss": 0.5583,
      "step": 472000
    },
    {
      "epoch": 761.32,
      "learning_rate": 0.023897656747580643,
      "loss": 0.5673,
      "step": 472020
    },
    {
      "epoch": 761.35,
      "learning_rate": 0.023894430944354835,
      "loss": 0.5486,
      "step": 472040
    },
    {
      "epoch": 761.39,
      "learning_rate": 0.02389120514112903,
      "loss": 0.5688,
      "step": 472060
    },
    {
      "epoch": 761.42,
      "learning_rate": 0.023887979337903226,
      "loss": 0.5666,
      "step": 472080
    },
    {
      "epoch": 761.45,
      "learning_rate": 0.02388475353467742,
      "loss": 0.5701,
      "step": 472100
    },
    {
      "epoch": 761.48,
      "learning_rate": 0.023881527731451614,
      "loss": 0.5695,
      "step": 472120
    },
    {
      "epoch": 761.52,
      "learning_rate": 0.023878301928225806,
      "loss": 0.5648,
      "step": 472140
    },
    {
      "epoch": 761.55,
      "learning_rate": 0.023875076125000002,
      "loss": 0.5654,
      "step": 472160
    },
    {
      "epoch": 761.58,
      "learning_rate": 0.023871850321774198,
      "loss": 0.5741,
      "step": 472180
    },
    {
      "epoch": 761.61,
      "learning_rate": 0.02386862451854839,
      "loss": 0.567,
      "step": 472200
    },
    {
      "epoch": 761.65,
      "learning_rate": 0.023865398715322585,
      "loss": 0.572,
      "step": 472220
    },
    {
      "epoch": 761.68,
      "learning_rate": 0.023862172912096778,
      "loss": 0.5623,
      "step": 472240
    },
    {
      "epoch": 761.71,
      "learning_rate": 0.023858947108870973,
      "loss": 0.5784,
      "step": 472260
    },
    {
      "epoch": 761.74,
      "learning_rate": 0.023855721305645155,
      "loss": 0.5681,
      "step": 472280
    },
    {
      "epoch": 761.77,
      "learning_rate": 0.02385249550241935,
      "loss": 0.5549,
      "step": 472300
    },
    {
      "epoch": 761.81,
      "learning_rate": 0.023849269699193546,
      "loss": 0.5709,
      "step": 472320
    },
    {
      "epoch": 761.84,
      "learning_rate": 0.02384604389596774,
      "loss": 0.5749,
      "step": 472340
    },
    {
      "epoch": 761.87,
      "learning_rate": 0.023842818092741934,
      "loss": 0.5733,
      "step": 472360
    },
    {
      "epoch": 761.9,
      "learning_rate": 0.023839592289516126,
      "loss": 0.5687,
      "step": 472380
    },
    {
      "epoch": 761.94,
      "learning_rate": 0.02383636648629032,
      "loss": 0.5671,
      "step": 472400
    },
    {
      "epoch": 761.97,
      "learning_rate": 0.023833140683064517,
      "loss": 0.5727,
      "step": 472420
    },
    {
      "epoch": 762.0,
      "learning_rate": 0.02382991487983871,
      "loss": 0.5657,
      "step": 472440
    },
    {
      "epoch": 762.0,
      "eval_accuracy": {
        "accuracy": 0.7835453906798845
      },
      "eval_loss": 0.9160340428352356,
      "eval_runtime": 3.5147,
      "eval_samples_per_second": 3644.977,
      "eval_steps_per_second": 57.188,
      "step": 472440
    },
    {
      "epoch": 762.03,
      "learning_rate": 0.023826689076612905,
      "loss": 0.5704,
      "step": 472460
    },
    {
      "epoch": 762.06,
      "learning_rate": 0.023823463273387097,
      "loss": 0.5618,
      "step": 472480
    },
    {
      "epoch": 762.1,
      "learning_rate": 0.023820237470161293,
      "loss": 0.5446,
      "step": 472500
    },
    {
      "epoch": 762.13,
      "learning_rate": 0.02381701166693549,
      "loss": 0.5621,
      "step": 472520
    },
    {
      "epoch": 762.16,
      "learning_rate": 0.02381378586370968,
      "loss": 0.581,
      "step": 472540
    },
    {
      "epoch": 762.19,
      "learning_rate": 0.023810560060483876,
      "loss": 0.5704,
      "step": 472560
    },
    {
      "epoch": 762.23,
      "learning_rate": 0.023807334257258058,
      "loss": 0.5446,
      "step": 472580
    },
    {
      "epoch": 762.26,
      "learning_rate": 0.023804108454032254,
      "loss": 0.5544,
      "step": 472600
    },
    {
      "epoch": 762.29,
      "learning_rate": 0.02380088265080645,
      "loss": 0.5704,
      "step": 472620
    },
    {
      "epoch": 762.32,
      "learning_rate": 0.02379765684758064,
      "loss": 0.5665,
      "step": 472640
    },
    {
      "epoch": 762.35,
      "learning_rate": 0.023794431044354837,
      "loss": 0.5695,
      "step": 472660
    },
    {
      "epoch": 762.39,
      "learning_rate": 0.02379120524112903,
      "loss": 0.5661,
      "step": 472680
    },
    {
      "epoch": 762.42,
      "learning_rate": 0.023787979437903225,
      "loss": 0.5733,
      "step": 472700
    },
    {
      "epoch": 762.45,
      "learning_rate": 0.02378475363467742,
      "loss": 0.5611,
      "step": 472720
    },
    {
      "epoch": 762.48,
      "learning_rate": 0.023781527831451613,
      "loss": 0.5705,
      "step": 472740
    },
    {
      "epoch": 762.52,
      "learning_rate": 0.02377830202822581,
      "loss": 0.5544,
      "step": 472760
    },
    {
      "epoch": 762.55,
      "learning_rate": 0.023775076225,
      "loss": 0.57,
      "step": 472780
    },
    {
      "epoch": 762.58,
      "learning_rate": 0.023771850421774196,
      "loss": 0.5614,
      "step": 472800
    },
    {
      "epoch": 762.61,
      "learning_rate": 0.02376862461854839,
      "loss": 0.5734,
      "step": 472820
    },
    {
      "epoch": 762.65,
      "learning_rate": 0.023765398815322584,
      "loss": 0.5631,
      "step": 472840
    },
    {
      "epoch": 762.68,
      "learning_rate": 0.02376217301209678,
      "loss": 0.5645,
      "step": 472860
    },
    {
      "epoch": 762.71,
      "learning_rate": 0.02375894720887097,
      "loss": 0.5705,
      "step": 472880
    },
    {
      "epoch": 762.74,
      "learning_rate": 0.023755721405645157,
      "loss": 0.5659,
      "step": 472900
    },
    {
      "epoch": 762.77,
      "learning_rate": 0.02375249560241935,
      "loss": 0.5717,
      "step": 472920
    },
    {
      "epoch": 762.81,
      "learning_rate": 0.023749269799193545,
      "loss": 0.5799,
      "step": 472940
    },
    {
      "epoch": 762.84,
      "learning_rate": 0.02374604399596774,
      "loss": 0.5757,
      "step": 472960
    },
    {
      "epoch": 762.87,
      "learning_rate": 0.023742818192741932,
      "loss": 0.57,
      "step": 472980
    },
    {
      "epoch": 762.9,
      "learning_rate": 0.023739592389516128,
      "loss": 0.5604,
      "step": 473000
    },
    {
      "epoch": 762.94,
      "learning_rate": 0.02373636658629032,
      "loss": 0.568,
      "step": 473020
    },
    {
      "epoch": 762.97,
      "learning_rate": 0.023733140783064516,
      "loss": 0.5606,
      "step": 473040
    },
    {
      "epoch": 763.0,
      "learning_rate": 0.02372991497983871,
      "loss": 0.5692,
      "step": 473060
    },
    {
      "epoch": 763.0,
      "eval_accuracy": {
        "accuracy": 0.7753493091874171
      },
      "eval_loss": 0.9211206436157227,
      "eval_runtime": 3.1828,
      "eval_samples_per_second": 4025.036,
      "eval_steps_per_second": 63.151,
      "step": 473060
    },
    {
      "epoch": 763.03,
      "learning_rate": 0.023726689176612904,
      "loss": 0.5732,
      "step": 473080
    },
    {
      "epoch": 763.06,
      "learning_rate": 0.0237234633733871,
      "loss": 0.5594,
      "step": 473100
    },
    {
      "epoch": 763.1,
      "learning_rate": 0.02372023757016129,
      "loss": 0.5524,
      "step": 473120
    },
    {
      "epoch": 763.13,
      "learning_rate": 0.023717011766935487,
      "loss": 0.5693,
      "step": 473140
    },
    {
      "epoch": 763.16,
      "learning_rate": 0.023713785963709683,
      "loss": 0.568,
      "step": 473160
    },
    {
      "epoch": 763.19,
      "learning_rate": 0.023710560160483875,
      "loss": 0.5639,
      "step": 473180
    },
    {
      "epoch": 763.23,
      "learning_rate": 0.02370733435725806,
      "loss": 0.5578,
      "step": 473200
    },
    {
      "epoch": 763.26,
      "learning_rate": 0.023704108554032252,
      "loss": 0.5546,
      "step": 473220
    },
    {
      "epoch": 763.29,
      "learning_rate": 0.023700882750806448,
      "loss": 0.5686,
      "step": 473240
    },
    {
      "epoch": 763.32,
      "learning_rate": 0.023697656947580643,
      "loss": 0.5685,
      "step": 473260
    },
    {
      "epoch": 763.35,
      "learning_rate": 0.023694431144354836,
      "loss": 0.5555,
      "step": 473280
    },
    {
      "epoch": 763.39,
      "learning_rate": 0.02369120534112903,
      "loss": 0.5645,
      "step": 473300
    },
    {
      "epoch": 763.42,
      "learning_rate": 0.023687979537903223,
      "loss": 0.5521,
      "step": 473320
    },
    {
      "epoch": 763.45,
      "learning_rate": 0.02368475373467742,
      "loss": 0.566,
      "step": 473340
    },
    {
      "epoch": 763.48,
      "learning_rate": 0.023681527931451615,
      "loss": 0.5627,
      "step": 473360
    },
    {
      "epoch": 763.52,
      "learning_rate": 0.023678302128225807,
      "loss": 0.5746,
      "step": 473380
    },
    {
      "epoch": 763.55,
      "learning_rate": 0.023675076325000002,
      "loss": 0.5663,
      "step": 473400
    },
    {
      "epoch": 763.58,
      "learning_rate": 0.023671850521774195,
      "loss": 0.5631,
      "step": 473420
    },
    {
      "epoch": 763.61,
      "learning_rate": 0.02366862471854839,
      "loss": 0.5731,
      "step": 473440
    },
    {
      "epoch": 763.65,
      "learning_rate": 0.023665398915322586,
      "loss": 0.5681,
      "step": 473460
    },
    {
      "epoch": 763.68,
      "learning_rate": 0.023662173112096778,
      "loss": 0.5709,
      "step": 473480
    },
    {
      "epoch": 763.71,
      "learning_rate": 0.023658947308870974,
      "loss": 0.5604,
      "step": 473500
    },
    {
      "epoch": 763.74,
      "learning_rate": 0.023655721505645155,
      "loss": 0.5689,
      "step": 473520
    },
    {
      "epoch": 763.77,
      "learning_rate": 0.02365249570241935,
      "loss": 0.5604,
      "step": 473540
    },
    {
      "epoch": 763.81,
      "learning_rate": 0.023649269899193543,
      "loss": 0.5681,
      "step": 473560
    },
    {
      "epoch": 763.84,
      "learning_rate": 0.02364604409596774,
      "loss": 0.5725,
      "step": 473580
    },
    {
      "epoch": 763.87,
      "learning_rate": 0.023642818292741934,
      "loss": 0.5769,
      "step": 473600
    },
    {
      "epoch": 763.9,
      "learning_rate": 0.023639592489516126,
      "loss": 0.571,
      "step": 473620
    },
    {
      "epoch": 763.94,
      "learning_rate": 0.023636366686290322,
      "loss": 0.5719,
      "step": 473640
    },
    {
      "epoch": 763.97,
      "learning_rate": 0.023633140883064514,
      "loss": 0.5695,
      "step": 473660
    },
    {
      "epoch": 764.0,
      "learning_rate": 0.02362991507983871,
      "loss": 0.5729,
      "step": 473680
    },
    {
      "epoch": 764.0,
      "eval_accuracy": {
        "accuracy": 0.7825306377331981
      },
      "eval_loss": 0.9232112765312195,
      "eval_runtime": 3.182,
      "eval_samples_per_second": 4026.081,
      "eval_steps_per_second": 63.168,
      "step": 473680
    },
    {
      "epoch": 764.03,
      "learning_rate": 0.023626689276612906,
      "loss": 0.5791,
      "step": 473700
    },
    {
      "epoch": 764.06,
      "learning_rate": 0.023623463473387098,
      "loss": 0.5613,
      "step": 473720
    },
    {
      "epoch": 764.1,
      "learning_rate": 0.023620237670161293,
      "loss": 0.5644,
      "step": 473740
    },
    {
      "epoch": 764.13,
      "learning_rate": 0.02361701186693549,
      "loss": 0.5576,
      "step": 473760
    },
    {
      "epoch": 764.16,
      "learning_rate": 0.02361378606370968,
      "loss": 0.5662,
      "step": 473780
    },
    {
      "epoch": 764.19,
      "learning_rate": 0.023610560260483877,
      "loss": 0.5694,
      "step": 473800
    },
    {
      "epoch": 764.23,
      "learning_rate": 0.02360733445725807,
      "loss": 0.5578,
      "step": 473820
    },
    {
      "epoch": 764.26,
      "learning_rate": 0.023604108654032254,
      "loss": 0.5622,
      "step": 473840
    },
    {
      "epoch": 764.29,
      "learning_rate": 0.023600882850806446,
      "loss": 0.5639,
      "step": 473860
    },
    {
      "epoch": 764.32,
      "learning_rate": 0.023597657047580642,
      "loss": 0.5457,
      "step": 473880
    },
    {
      "epoch": 764.35,
      "learning_rate": 0.023594431244354837,
      "loss": 0.5558,
      "step": 473900
    },
    {
      "epoch": 764.39,
      "learning_rate": 0.02359120544112903,
      "loss": 0.5598,
      "step": 473920
    },
    {
      "epoch": 764.42,
      "learning_rate": 0.023587979637903225,
      "loss": 0.5691,
      "step": 473940
    },
    {
      "epoch": 764.45,
      "learning_rate": 0.023584753834677417,
      "loss": 0.5698,
      "step": 473960
    },
    {
      "epoch": 764.48,
      "learning_rate": 0.023581528031451613,
      "loss": 0.5713,
      "step": 473980
    },
    {
      "epoch": 764.52,
      "learning_rate": 0.02357830222822581,
      "loss": 0.5484,
      "step": 474000
    },
    {
      "epoch": 764.55,
      "learning_rate": 0.023575076425,
      "loss": 0.5553,
      "step": 474020
    },
    {
      "epoch": 764.58,
      "learning_rate": 0.023571850621774196,
      "loss": 0.5727,
      "step": 474040
    },
    {
      "epoch": 764.61,
      "learning_rate": 0.02356862481854839,
      "loss": 0.5584,
      "step": 474060
    },
    {
      "epoch": 764.65,
      "learning_rate": 0.023565399015322584,
      "loss": 0.5636,
      "step": 474080
    },
    {
      "epoch": 764.68,
      "learning_rate": 0.02356217321209678,
      "loss": 0.5737,
      "step": 474100
    },
    {
      "epoch": 764.71,
      "learning_rate": 0.023558947408870972,
      "loss": 0.5622,
      "step": 474120
    },
    {
      "epoch": 764.74,
      "learning_rate": 0.023555721605645157,
      "loss": 0.5583,
      "step": 474140
    },
    {
      "epoch": 764.77,
      "learning_rate": 0.02355249580241935,
      "loss": 0.5691,
      "step": 474160
    },
    {
      "epoch": 764.81,
      "learning_rate": 0.023549269999193545,
      "loss": 0.5849,
      "step": 474180
    },
    {
      "epoch": 764.84,
      "learning_rate": 0.023546044195967737,
      "loss": 0.5737,
      "step": 474200
    },
    {
      "epoch": 764.87,
      "learning_rate": 0.023542818392741933,
      "loss": 0.5798,
      "step": 474220
    },
    {
      "epoch": 764.9,
      "learning_rate": 0.02353959258951613,
      "loss": 0.5695,
      "step": 474240
    },
    {
      "epoch": 764.94,
      "learning_rate": 0.02353636678629032,
      "loss": 0.5674,
      "step": 474260
    },
    {
      "epoch": 764.97,
      "learning_rate": 0.023533140983064516,
      "loss": 0.5697,
      "step": 474280
    },
    {
      "epoch": 765.0,
      "learning_rate": 0.023530076469999994,
      "loss": 0.5668,
      "step": 474300
    },
    {
      "epoch": 765.0,
      "eval_accuracy": {
        "accuracy": 0.7824525798142221
      },
      "eval_loss": 0.9135074019432068,
      "eval_runtime": 3.3804,
      "eval_samples_per_second": 3789.77,
      "eval_steps_per_second": 59.46,
      "step": 474300
    },
    {
      "epoch": 765.03,
      "learning_rate": 0.02352685066677419,
      "loss": 0.5445,
      "step": 474320
    },
    {
      "epoch": 765.06,
      "learning_rate": 0.023523624863548385,
      "loss": 0.5565,
      "step": 474340
    },
    {
      "epoch": 765.1,
      "learning_rate": 0.023520399060322578,
      "loss": 0.5579,
      "step": 474360
    },
    {
      "epoch": 765.13,
      "learning_rate": 0.023517173257096773,
      "loss": 0.544,
      "step": 474380
    },
    {
      "epoch": 765.16,
      "learning_rate": 0.023513947453870965,
      "loss": 0.5706,
      "step": 474400
    },
    {
      "epoch": 765.19,
      "learning_rate": 0.02351072165064516,
      "loss": 0.562,
      "step": 474420
    },
    {
      "epoch": 765.23,
      "learning_rate": 0.023507495847419357,
      "loss": 0.5663,
      "step": 474440
    },
    {
      "epoch": 765.26,
      "learning_rate": 0.02350427004419355,
      "loss": 0.5495,
      "step": 474460
    },
    {
      "epoch": 765.29,
      "learning_rate": 0.023501044240967744,
      "loss": 0.5622,
      "step": 474480
    },
    {
      "epoch": 765.32,
      "learning_rate": 0.023497818437741937,
      "loss": 0.5612,
      "step": 474500
    },
    {
      "epoch": 765.35,
      "learning_rate": 0.023494592634516132,
      "loss": 0.5676,
      "step": 474520
    },
    {
      "epoch": 765.39,
      "learning_rate": 0.023491366831290328,
      "loss": 0.5586,
      "step": 474540
    },
    {
      "epoch": 765.42,
      "learning_rate": 0.02348814102806452,
      "loss": 0.5537,
      "step": 474560
    },
    {
      "epoch": 765.45,
      "learning_rate": 0.023484915224838716,
      "loss": 0.5684,
      "step": 474580
    },
    {
      "epoch": 765.48,
      "learning_rate": 0.023481689421612897,
      "loss": 0.5566,
      "step": 474600
    },
    {
      "epoch": 765.52,
      "learning_rate": 0.023478463618387093,
      "loss": 0.5764,
      "step": 474620
    },
    {
      "epoch": 765.55,
      "learning_rate": 0.023475237815161285,
      "loss": 0.5581,
      "step": 474640
    },
    {
      "epoch": 765.58,
      "learning_rate": 0.02347201201193548,
      "loss": 0.562,
      "step": 474660
    },
    {
      "epoch": 765.61,
      "learning_rate": 0.023468786208709676,
      "loss": 0.5718,
      "step": 474680
    },
    {
      "epoch": 765.65,
      "learning_rate": 0.02346556040548387,
      "loss": 0.5694,
      "step": 474700
    },
    {
      "epoch": 765.68,
      "learning_rate": 0.023462334602258064,
      "loss": 0.5613,
      "step": 474720
    },
    {
      "epoch": 765.71,
      "learning_rate": 0.023459108799032256,
      "loss": 0.5738,
      "step": 474740
    },
    {
      "epoch": 765.74,
      "learning_rate": 0.023455882995806452,
      "loss": 0.5783,
      "step": 474760
    },
    {
      "epoch": 765.77,
      "learning_rate": 0.023452657192580648,
      "loss": 0.5675,
      "step": 474780
    },
    {
      "epoch": 765.81,
      "learning_rate": 0.02344943138935484,
      "loss": 0.5712,
      "step": 474800
    },
    {
      "epoch": 765.84,
      "learning_rate": 0.023446205586129035,
      "loss": 0.5669,
      "step": 474820
    },
    {
      "epoch": 765.87,
      "learning_rate": 0.02344297978290323,
      "loss": 0.5733,
      "step": 474840
    },
    {
      "epoch": 765.9,
      "learning_rate": 0.023439753979677423,
      "loss": 0.5514,
      "step": 474860
    },
    {
      "epoch": 765.94,
      "learning_rate": 0.02343652817645162,
      "loss": 0.5642,
      "step": 474880
    },
    {
      "epoch": 765.97,
      "learning_rate": 0.0234333023732258,
      "loss": 0.577,
      "step": 474900
    },
    {
      "epoch": 766.0,
      "learning_rate": 0.023430076569999996,
      "loss": 0.5729,
      "step": 474920
    },
    {
      "epoch": 766.0,
      "eval_accuracy": {
        "accuracy": 0.7768324096479587
      },
      "eval_loss": 0.937964916229248,
      "eval_runtime": 3.0492,
      "eval_samples_per_second": 4201.398,
      "eval_steps_per_second": 65.918,
      "step": 474920
    },
    {
      "epoch": 766.03,
      "learning_rate": 0.02342685076677419,
      "loss": 0.5778,
      "step": 474940
    },
    {
      "epoch": 766.06,
      "learning_rate": 0.023423624963548384,
      "loss": 0.552,
      "step": 474960
    },
    {
      "epoch": 766.1,
      "learning_rate": 0.02342039916032258,
      "loss": 0.5528,
      "step": 474980
    },
    {
      "epoch": 766.13,
      "learning_rate": 0.023417173357096772,
      "loss": 0.5536,
      "step": 475000
    },
    {
      "epoch": 766.16,
      "learning_rate": 0.023413947553870967,
      "loss": 0.5625,
      "step": 475020
    },
    {
      "epoch": 766.19,
      "learning_rate": 0.02341072175064516,
      "loss": 0.5645,
      "step": 475040
    },
    {
      "epoch": 766.23,
      "learning_rate": 0.023407495947419355,
      "loss": 0.5609,
      "step": 475060
    },
    {
      "epoch": 766.26,
      "learning_rate": 0.02340427014419355,
      "loss": 0.555,
      "step": 475080
    },
    {
      "epoch": 766.29,
      "learning_rate": 0.023401044340967743,
      "loss": 0.5662,
      "step": 475100
    },
    {
      "epoch": 766.32,
      "learning_rate": 0.02339781853774194,
      "loss": 0.5539,
      "step": 475120
    },
    {
      "epoch": 766.35,
      "learning_rate": 0.02339459273451613,
      "loss": 0.5635,
      "step": 475140
    },
    {
      "epoch": 766.39,
      "learning_rate": 0.023391366931290326,
      "loss": 0.5653,
      "step": 475160
    },
    {
      "epoch": 766.42,
      "learning_rate": 0.023388141128064522,
      "loss": 0.557,
      "step": 475180
    },
    {
      "epoch": 766.45,
      "learning_rate": 0.023384915324838714,
      "loss": 0.5734,
      "step": 475200
    },
    {
      "epoch": 766.48,
      "learning_rate": 0.0233816895216129,
      "loss": 0.5622,
      "step": 475220
    },
    {
      "epoch": 766.52,
      "learning_rate": 0.02337846371838709,
      "loss": 0.5589,
      "step": 475240
    },
    {
      "epoch": 766.55,
      "learning_rate": 0.023375237915161287,
      "loss": 0.5652,
      "step": 475260
    },
    {
      "epoch": 766.58,
      "learning_rate": 0.02337201211193548,
      "loss": 0.5612,
      "step": 475280
    },
    {
      "epoch": 766.61,
      "learning_rate": 0.023368786308709675,
      "loss": 0.5502,
      "step": 475300
    },
    {
      "epoch": 766.65,
      "learning_rate": 0.02336556050548387,
      "loss": 0.5651,
      "step": 475320
    },
    {
      "epoch": 766.68,
      "learning_rate": 0.023362334702258063,
      "loss": 0.5804,
      "step": 475340
    },
    {
      "epoch": 766.71,
      "learning_rate": 0.02335910889903226,
      "loss": 0.5668,
      "step": 475360
    },
    {
      "epoch": 766.74,
      "learning_rate": 0.023355883095806454,
      "loss": 0.5728,
      "step": 475380
    },
    {
      "epoch": 766.77,
      "learning_rate": 0.023352657292580646,
      "loss": 0.5748,
      "step": 475400
    },
    {
      "epoch": 766.81,
      "learning_rate": 0.02334943148935484,
      "loss": 0.5667,
      "step": 475420
    },
    {
      "epoch": 766.84,
      "learning_rate": 0.023346205686129034,
      "loss": 0.5665,
      "step": 475440
    },
    {
      "epoch": 766.87,
      "learning_rate": 0.02334297988290323,
      "loss": 0.5594,
      "step": 475460
    },
    {
      "epoch": 766.9,
      "learning_rate": 0.023339754079677425,
      "loss": 0.5682,
      "step": 475480
    },
    {
      "epoch": 766.94,
      "learning_rate": 0.023336528276451617,
      "loss": 0.5655,
      "step": 475500
    },
    {
      "epoch": 766.97,
      "learning_rate": 0.023333302473225803,
      "loss": 0.5708,
      "step": 475520
    },
    {
      "epoch": 767.0,
      "learning_rate": 0.023330076669999995,
      "loss": 0.5772,
      "step": 475540
    },
    {
      "epoch": 767.0,
      "eval_accuracy": {
        "accuracy": 0.7825306377331981
      },
      "eval_loss": 0.9196987748146057,
      "eval_runtime": 2.9626,
      "eval_samples_per_second": 4324.258,
      "eval_steps_per_second": 67.846,
      "step": 475540
    },
    {
      "epoch": 767.03,
      "learning_rate": 0.02332685086677419,
      "loss": 0.5707,
      "step": 475560
    },
    {
      "epoch": 767.06,
      "learning_rate": 0.023323625063548382,
      "loss": 0.5622,
      "step": 475580
    },
    {
      "epoch": 767.1,
      "learning_rate": 0.023320399260322578,
      "loss": 0.5617,
      "step": 475600
    },
    {
      "epoch": 767.13,
      "learning_rate": 0.023317173457096774,
      "loss": 0.5509,
      "step": 475620
    },
    {
      "epoch": 767.16,
      "learning_rate": 0.023313947653870966,
      "loss": 0.5622,
      "step": 475640
    },
    {
      "epoch": 767.19,
      "learning_rate": 0.02331072185064516,
      "loss": 0.5759,
      "step": 475660
    },
    {
      "epoch": 767.23,
      "learning_rate": 0.023307496047419354,
      "loss": 0.5542,
      "step": 475680
    },
    {
      "epoch": 767.26,
      "learning_rate": 0.02330427024419355,
      "loss": 0.5498,
      "step": 475700
    },
    {
      "epoch": 767.29,
      "learning_rate": 0.023301044440967745,
      "loss": 0.5564,
      "step": 475720
    },
    {
      "epoch": 767.32,
      "learning_rate": 0.023297818637741937,
      "loss": 0.5609,
      "step": 475740
    },
    {
      "epoch": 767.35,
      "learning_rate": 0.023294592834516133,
      "loss": 0.5736,
      "step": 475760
    },
    {
      "epoch": 767.39,
      "learning_rate": 0.023291367031290325,
      "loss": 0.5564,
      "step": 475780
    },
    {
      "epoch": 767.42,
      "learning_rate": 0.02328814122806452,
      "loss": 0.5592,
      "step": 475800
    },
    {
      "epoch": 767.45,
      "learning_rate": 0.023284915424838716,
      "loss": 0.5554,
      "step": 475820
    },
    {
      "epoch": 767.48,
      "learning_rate": 0.023281689621612898,
      "loss": 0.571,
      "step": 475840
    },
    {
      "epoch": 767.52,
      "learning_rate": 0.023278463818387093,
      "loss": 0.5778,
      "step": 475860
    },
    {
      "epoch": 767.55,
      "learning_rate": 0.023275238015161286,
      "loss": 0.5555,
      "step": 475880
    },
    {
      "epoch": 767.58,
      "learning_rate": 0.02327201221193548,
      "loss": 0.5671,
      "step": 475900
    },
    {
      "epoch": 767.61,
      "learning_rate": 0.023268786408709673,
      "loss": 0.5675,
      "step": 475920
    },
    {
      "epoch": 767.65,
      "learning_rate": 0.02326556060548387,
      "loss": 0.5668,
      "step": 475940
    },
    {
      "epoch": 767.68,
      "learning_rate": 0.023262334802258065,
      "loss": 0.57,
      "step": 475960
    },
    {
      "epoch": 767.71,
      "learning_rate": 0.023259108999032257,
      "loss": 0.5608,
      "step": 475980
    },
    {
      "epoch": 767.74,
      "learning_rate": 0.023255883195806452,
      "loss": 0.5702,
      "step": 476000
    },
    {
      "epoch": 767.77,
      "learning_rate": 0.023252657392580648,
      "loss": 0.5501,
      "step": 476020
    },
    {
      "epoch": 767.81,
      "learning_rate": 0.02324943158935484,
      "loss": 0.5693,
      "step": 476040
    },
    {
      "epoch": 767.84,
      "learning_rate": 0.023246205786129036,
      "loss": 0.5683,
      "step": 476060
    },
    {
      "epoch": 767.87,
      "learning_rate": 0.023242979982903228,
      "loss": 0.572,
      "step": 476080
    },
    {
      "epoch": 767.9,
      "learning_rate": 0.023239754179677424,
      "loss": 0.5657,
      "step": 476100
    },
    {
      "epoch": 767.94,
      "learning_rate": 0.02323652837645162,
      "loss": 0.5759,
      "step": 476120
    },
    {
      "epoch": 767.97,
      "learning_rate": 0.02323330257322581,
      "loss": 0.5714,
      "step": 476140
    },
    {
      "epoch": 768.0,
      "learning_rate": 0.023230076769999997,
      "loss": 0.5521,
      "step": 476160
    },
    {
      "epoch": 768.0,
      "eval_accuracy": {
        "accuracy": 0.7817500585434393
      },
      "eval_loss": 0.9154525995254517,
      "eval_runtime": 3.4744,
      "eval_samples_per_second": 3687.253,
      "eval_steps_per_second": 57.852,
      "step": 476160
    },
    {
      "epoch": 768.03,
      "learning_rate": 0.02322685096677419,
      "loss": 0.5742,
      "step": 476180
    },
    {
      "epoch": 768.06,
      "learning_rate": 0.023223625163548384,
      "loss": 0.558,
      "step": 476200
    },
    {
      "epoch": 768.1,
      "learning_rate": 0.023220399360322577,
      "loss": 0.5484,
      "step": 476220
    },
    {
      "epoch": 768.13,
      "learning_rate": 0.023217173557096772,
      "loss": 0.5469,
      "step": 476240
    },
    {
      "epoch": 768.16,
      "learning_rate": 0.023213947753870968,
      "loss": 0.5557,
      "step": 476260
    },
    {
      "epoch": 768.19,
      "learning_rate": 0.02321072195064516,
      "loss": 0.5602,
      "step": 476280
    },
    {
      "epoch": 768.23,
      "learning_rate": 0.023207496147419356,
      "loss": 0.5636,
      "step": 476300
    },
    {
      "epoch": 768.26,
      "learning_rate": 0.023204270344193548,
      "loss": 0.5661,
      "step": 476320
    },
    {
      "epoch": 768.29,
      "learning_rate": 0.023201044540967743,
      "loss": 0.5675,
      "step": 476340
    },
    {
      "epoch": 768.32,
      "learning_rate": 0.02319781873774194,
      "loss": 0.5535,
      "step": 476360
    },
    {
      "epoch": 768.35,
      "learning_rate": 0.02319459293451613,
      "loss": 0.5629,
      "step": 476380
    },
    {
      "epoch": 768.39,
      "learning_rate": 0.023191367131290327,
      "loss": 0.5525,
      "step": 476400
    },
    {
      "epoch": 768.42,
      "learning_rate": 0.02318814132806452,
      "loss": 0.5492,
      "step": 476420
    },
    {
      "epoch": 768.45,
      "learning_rate": 0.023184915524838715,
      "loss": 0.5634,
      "step": 476440
    },
    {
      "epoch": 768.48,
      "learning_rate": 0.023181689721612896,
      "loss": 0.5596,
      "step": 476460
    },
    {
      "epoch": 768.52,
      "learning_rate": 0.023178463918387092,
      "loss": 0.5605,
      "step": 476480
    },
    {
      "epoch": 768.55,
      "learning_rate": 0.023175238115161288,
      "loss": 0.5645,
      "step": 476500
    },
    {
      "epoch": 768.58,
      "learning_rate": 0.02317201231193548,
      "loss": 0.5711,
      "step": 476520
    },
    {
      "epoch": 768.61,
      "learning_rate": 0.023168786508709675,
      "loss": 0.567,
      "step": 476540
    },
    {
      "epoch": 768.65,
      "learning_rate": 0.02316556070548387,
      "loss": 0.5664,
      "step": 476560
    },
    {
      "epoch": 768.68,
      "learning_rate": 0.023162334902258063,
      "loss": 0.5484,
      "step": 476580
    },
    {
      "epoch": 768.71,
      "learning_rate": 0.02315910909903226,
      "loss": 0.5567,
      "step": 476600
    },
    {
      "epoch": 768.74,
      "learning_rate": 0.02315588329580645,
      "loss": 0.5592,
      "step": 476620
    },
    {
      "epoch": 768.77,
      "learning_rate": 0.023152657492580647,
      "loss": 0.5636,
      "step": 476640
    },
    {
      "epoch": 768.81,
      "learning_rate": 0.023149431689354842,
      "loss": 0.5647,
      "step": 476660
    },
    {
      "epoch": 768.84,
      "learning_rate": 0.023146205886129034,
      "loss": 0.5693,
      "step": 476680
    },
    {
      "epoch": 768.87,
      "learning_rate": 0.02314298008290323,
      "loss": 0.5523,
      "step": 476700
    },
    {
      "epoch": 768.9,
      "learning_rate": 0.023139754279677422,
      "loss": 0.5653,
      "step": 476720
    },
    {
      "epoch": 768.94,
      "learning_rate": 0.023136528476451618,
      "loss": 0.5769,
      "step": 476740
    },
    {
      "epoch": 768.97,
      "learning_rate": 0.023133302673225813,
      "loss": 0.5649,
      "step": 476760
    },
    {
      "epoch": 769.0,
      "learning_rate": 0.02313023816016129,
      "loss": 0.5727,
      "step": 476780
    },
    {
      "epoch": 769.0,
      "eval_accuracy": {
        "accuracy": 0.7803450160018733
      },
      "eval_loss": 0.9284219741821289,
      "eval_runtime": 3.037,
      "eval_samples_per_second": 4218.309,
      "eval_steps_per_second": 66.184,
      "step": 476780
    },
    {
      "epoch": 769.03,
      "learning_rate": 0.023127012356935487,
      "loss": 0.559,
      "step": 476800
    },
    {
      "epoch": 769.06,
      "learning_rate": 0.02312378655370968,
      "loss": 0.5538,
      "step": 476820
    },
    {
      "epoch": 769.1,
      "learning_rate": 0.023120560750483875,
      "loss": 0.5597,
      "step": 476840
    },
    {
      "epoch": 769.13,
      "learning_rate": 0.023117334947258067,
      "loss": 0.5549,
      "step": 476860
    },
    {
      "epoch": 769.16,
      "learning_rate": 0.023114109144032263,
      "loss": 0.5653,
      "step": 476880
    },
    {
      "epoch": 769.19,
      "learning_rate": 0.023110883340806458,
      "loss": 0.5569,
      "step": 476900
    },
    {
      "epoch": 769.23,
      "learning_rate": 0.02310765753758064,
      "loss": 0.5542,
      "step": 476920
    },
    {
      "epoch": 769.26,
      "learning_rate": 0.023104431734354836,
      "loss": 0.5662,
      "step": 476940
    },
    {
      "epoch": 769.29,
      "learning_rate": 0.023101205931129028,
      "loss": 0.5668,
      "step": 476960
    },
    {
      "epoch": 769.32,
      "learning_rate": 0.023097980127903223,
      "loss": 0.5518,
      "step": 476980
    },
    {
      "epoch": 769.35,
      "learning_rate": 0.023094754324677415,
      "loss": 0.5695,
      "step": 477000
    },
    {
      "epoch": 769.39,
      "learning_rate": 0.02309152852145161,
      "loss": 0.5601,
      "step": 477020
    },
    {
      "epoch": 769.42,
      "learning_rate": 0.023088302718225807,
      "loss": 0.5611,
      "step": 477040
    },
    {
      "epoch": 769.45,
      "learning_rate": 0.023085076915,
      "loss": 0.5636,
      "step": 477060
    },
    {
      "epoch": 769.48,
      "learning_rate": 0.023081851111774195,
      "loss": 0.5641,
      "step": 477080
    },
    {
      "epoch": 769.52,
      "learning_rate": 0.02307862530854839,
      "loss": 0.5539,
      "step": 477100
    },
    {
      "epoch": 769.55,
      "learning_rate": 0.023075399505322582,
      "loss": 0.5752,
      "step": 477120
    },
    {
      "epoch": 769.58,
      "learning_rate": 0.023072173702096778,
      "loss": 0.5553,
      "step": 477140
    },
    {
      "epoch": 769.61,
      "learning_rate": 0.02306894789887097,
      "loss": 0.5553,
      "step": 477160
    },
    {
      "epoch": 769.65,
      "learning_rate": 0.023065722095645166,
      "loss": 0.556,
      "step": 477180
    },
    {
      "epoch": 769.68,
      "learning_rate": 0.02306249629241936,
      "loss": 0.5647,
      "step": 477200
    },
    {
      "epoch": 769.71,
      "learning_rate": 0.023059270489193543,
      "loss": 0.5693,
      "step": 477220
    },
    {
      "epoch": 769.74,
      "learning_rate": 0.02305604468596774,
      "loss": 0.5646,
      "step": 477240
    },
    {
      "epoch": 769.77,
      "learning_rate": 0.02305281888274193,
      "loss": 0.5615,
      "step": 477260
    },
    {
      "epoch": 769.81,
      "learning_rate": 0.023049593079516126,
      "loss": 0.5562,
      "step": 477280
    },
    {
      "epoch": 769.84,
      "learning_rate": 0.02304636727629032,
      "loss": 0.5584,
      "step": 477300
    },
    {
      "epoch": 769.87,
      "learning_rate": 0.023043141473064514,
      "loss": 0.5676,
      "step": 477320
    },
    {
      "epoch": 769.9,
      "learning_rate": 0.02303991566983871,
      "loss": 0.5593,
      "step": 477340
    },
    {
      "epoch": 769.94,
      "learning_rate": 0.023036689866612902,
      "loss": 0.5677,
      "step": 477360
    },
    {
      "epoch": 769.97,
      "learning_rate": 0.023033464063387098,
      "loss": 0.5529,
      "step": 477380
    },
    {
      "epoch": 770.0,
      "learning_rate": 0.02303023826016129,
      "loss": 0.5633,
      "step": 477400
    },
    {
      "epoch": 770.0,
      "eval_accuracy": {
        "accuracy": 0.7788619155413317
      },
      "eval_loss": 0.9246589541435242,
      "eval_runtime": 3.2001,
      "eval_samples_per_second": 4003.322,
      "eval_steps_per_second": 62.811,
      "step": 477400
    },
    {
      "epoch": 770.03,
      "learning_rate": 0.023027012456935485,
      "loss": 0.5719,
      "step": 477420
    },
    {
      "epoch": 770.06,
      "learning_rate": 0.02302378665370968,
      "loss": 0.5664,
      "step": 477440
    },
    {
      "epoch": 770.1,
      "learning_rate": 0.023020560850483873,
      "loss": 0.5641,
      "step": 477460
    },
    {
      "epoch": 770.13,
      "learning_rate": 0.02301733504725807,
      "loss": 0.5541,
      "step": 477480
    },
    {
      "epoch": 770.16,
      "learning_rate": 0.02301410924403226,
      "loss": 0.5537,
      "step": 477500
    },
    {
      "epoch": 770.19,
      "learning_rate": 0.023010883440806457,
      "loss": 0.5468,
      "step": 477520
    },
    {
      "epoch": 770.23,
      "learning_rate": 0.02300765763758064,
      "loss": 0.5777,
      "step": 477540
    },
    {
      "epoch": 770.26,
      "learning_rate": 0.023004431834354834,
      "loss": 0.5506,
      "step": 477560
    },
    {
      "epoch": 770.29,
      "learning_rate": 0.02300120603112903,
      "loss": 0.5563,
      "step": 477580
    },
    {
      "epoch": 770.32,
      "learning_rate": 0.022997980227903222,
      "loss": 0.5599,
      "step": 477600
    },
    {
      "epoch": 770.35,
      "learning_rate": 0.022994754424677417,
      "loss": 0.5592,
      "step": 477620
    },
    {
      "epoch": 770.39,
      "learning_rate": 0.022991528621451613,
      "loss": 0.5657,
      "step": 477640
    },
    {
      "epoch": 770.42,
      "learning_rate": 0.022988302818225805,
      "loss": 0.5614,
      "step": 477660
    },
    {
      "epoch": 770.45,
      "learning_rate": 0.022985077015,
      "loss": 0.5558,
      "step": 477680
    },
    {
      "epoch": 770.48,
      "learning_rate": 0.022981851211774193,
      "loss": 0.5564,
      "step": 477700
    },
    {
      "epoch": 770.52,
      "learning_rate": 0.02297862540854839,
      "loss": 0.5676,
      "step": 477720
    },
    {
      "epoch": 770.55,
      "learning_rate": 0.022975399605322584,
      "loss": 0.5608,
      "step": 477740
    },
    {
      "epoch": 770.58,
      "learning_rate": 0.022972173802096776,
      "loss": 0.5574,
      "step": 477760
    },
    {
      "epoch": 770.61,
      "learning_rate": 0.022968947998870972,
      "loss": 0.5713,
      "step": 477780
    },
    {
      "epoch": 770.65,
      "learning_rate": 0.022965722195645164,
      "loss": 0.5705,
      "step": 477800
    },
    {
      "epoch": 770.68,
      "learning_rate": 0.02296249639241936,
      "loss": 0.56,
      "step": 477820
    },
    {
      "epoch": 770.71,
      "learning_rate": 0.02295927058919354,
      "loss": 0.5695,
      "step": 477840
    },
    {
      "epoch": 770.74,
      "learning_rate": 0.022956044785967737,
      "loss": 0.5757,
      "step": 477860
    },
    {
      "epoch": 770.77,
      "learning_rate": 0.022952818982741933,
      "loss": 0.5647,
      "step": 477880
    },
    {
      "epoch": 770.81,
      "learning_rate": 0.022949593179516125,
      "loss": 0.5601,
      "step": 477900
    },
    {
      "epoch": 770.84,
      "learning_rate": 0.02294636737629032,
      "loss": 0.5597,
      "step": 477920
    },
    {
      "epoch": 770.87,
      "learning_rate": 0.022943141573064513,
      "loss": 0.565,
      "step": 477940
    },
    {
      "epoch": 770.9,
      "learning_rate": 0.02293991576983871,
      "loss": 0.5803,
      "step": 477960
    },
    {
      "epoch": 770.94,
      "learning_rate": 0.022936689966612904,
      "loss": 0.5669,
      "step": 477980
    },
    {
      "epoch": 770.97,
      "learning_rate": 0.022933464163387096,
      "loss": 0.5553,
      "step": 478000
    },
    {
      "epoch": 771.0,
      "learning_rate": 0.022930238360161292,
      "loss": 0.5655,
      "step": 478020
    },
    {
      "epoch": 771.0,
      "eval_accuracy": {
        "accuracy": 0.7787057997033799
      },
      "eval_loss": 0.9263002872467041,
      "eval_runtime": 4.6224,
      "eval_samples_per_second": 2771.483,
      "eval_steps_per_second": 43.484,
      "step": 478020
    },
    {
      "epoch": 771.03,
      "learning_rate": 0.022927012556935484,
      "loss": 0.5617,
      "step": 478040
    },
    {
      "epoch": 771.06,
      "learning_rate": 0.02292378675370968,
      "loss": 0.5675,
      "step": 478060
    },
    {
      "epoch": 771.1,
      "learning_rate": 0.022920560950483875,
      "loss": 0.5533,
      "step": 478080
    },
    {
      "epoch": 771.13,
      "learning_rate": 0.022917335147258067,
      "loss": 0.56,
      "step": 478100
    },
    {
      "epoch": 771.16,
      "learning_rate": 0.022914109344032263,
      "loss": 0.5574,
      "step": 478120
    },
    {
      "epoch": 771.19,
      "learning_rate": 0.022910883540806455,
      "loss": 0.5467,
      "step": 478140
    },
    {
      "epoch": 771.23,
      "learning_rate": 0.02290765773758064,
      "loss": 0.5575,
      "step": 478160
    },
    {
      "epoch": 771.26,
      "learning_rate": 0.022904431934354836,
      "loss": 0.5559,
      "step": 478180
    },
    {
      "epoch": 771.29,
      "learning_rate": 0.022901206131129028,
      "loss": 0.5449,
      "step": 478200
    },
    {
      "epoch": 771.32,
      "learning_rate": 0.022897980327903224,
      "loss": 0.5583,
      "step": 478220
    },
    {
      "epoch": 771.35,
      "learning_rate": 0.022894754524677416,
      "loss": 0.5761,
      "step": 478240
    },
    {
      "epoch": 771.39,
      "learning_rate": 0.02289152872145161,
      "loss": 0.5647,
      "step": 478260
    },
    {
      "epoch": 771.42,
      "learning_rate": 0.022888302918225807,
      "loss": 0.5564,
      "step": 478280
    },
    {
      "epoch": 771.45,
      "learning_rate": 0.022885077115,
      "loss": 0.5699,
      "step": 478300
    },
    {
      "epoch": 771.48,
      "learning_rate": 0.022881851311774195,
      "loss": 0.5616,
      "step": 478320
    },
    {
      "epoch": 771.52,
      "learning_rate": 0.022878625508548387,
      "loss": 0.5485,
      "step": 478340
    },
    {
      "epoch": 771.55,
      "learning_rate": 0.022875399705322583,
      "loss": 0.5595,
      "step": 478360
    },
    {
      "epoch": 771.58,
      "learning_rate": 0.02287217390209678,
      "loss": 0.5625,
      "step": 478380
    },
    {
      "epoch": 771.61,
      "learning_rate": 0.02286894809887097,
      "loss": 0.5527,
      "step": 478400
    },
    {
      "epoch": 771.65,
      "learning_rate": 0.022865722295645166,
      "loss": 0.5739,
      "step": 478420
    },
    {
      "epoch": 771.68,
      "learning_rate": 0.02286249649241936,
      "loss": 0.5579,
      "step": 478440
    },
    {
      "epoch": 771.71,
      "learning_rate": 0.022859270689193554,
      "loss": 0.567,
      "step": 478460
    },
    {
      "epoch": 771.74,
      "learning_rate": 0.022856044885967736,
      "loss": 0.5663,
      "step": 478480
    },
    {
      "epoch": 771.77,
      "learning_rate": 0.02285281908274193,
      "loss": 0.5701,
      "step": 478500
    },
    {
      "epoch": 771.81,
      "learning_rate": 0.022849593279516127,
      "loss": 0.5463,
      "step": 478520
    },
    {
      "epoch": 771.84,
      "learning_rate": 0.02284636747629032,
      "loss": 0.5573,
      "step": 478540
    },
    {
      "epoch": 771.87,
      "learning_rate": 0.022843141673064515,
      "loss": 0.568,
      "step": 478560
    },
    {
      "epoch": 771.9,
      "learning_rate": 0.022839915869838707,
      "loss": 0.5681,
      "step": 478580
    },
    {
      "epoch": 771.94,
      "learning_rate": 0.022836690066612902,
      "loss": 0.5713,
      "step": 478600
    },
    {
      "epoch": 771.97,
      "learning_rate": 0.022833464263387098,
      "loss": 0.5548,
      "step": 478620
    },
    {
      "epoch": 772.0,
      "learning_rate": 0.02283023846016129,
      "loss": 0.557,
      "step": 478640
    },
    {
      "epoch": 772.0,
      "eval_accuracy": {
        "accuracy": 0.7781593942705487
      },
      "eval_loss": 0.9305768013000488,
      "eval_runtime": 3.0644,
      "eval_samples_per_second": 4180.532,
      "eval_steps_per_second": 65.591,
      "step": 478640
    },
    {
      "epoch": 772.03,
      "learning_rate": 0.022827012656935486,
      "loss": 0.5649,
      "step": 478660
    },
    {
      "epoch": 772.06,
      "learning_rate": 0.022823786853709678,
      "loss": 0.5621,
      "step": 478680
    },
    {
      "epoch": 772.1,
      "learning_rate": 0.022820561050483874,
      "loss": 0.5643,
      "step": 478700
    },
    {
      "epoch": 772.13,
      "learning_rate": 0.02281733524725807,
      "loss": 0.5645,
      "step": 478720
    },
    {
      "epoch": 772.16,
      "learning_rate": 0.02281410944403226,
      "loss": 0.5566,
      "step": 478740
    },
    {
      "epoch": 772.19,
      "learning_rate": 0.022810883640806457,
      "loss": 0.5492,
      "step": 478760
    },
    {
      "epoch": 772.23,
      "learning_rate": 0.02280765783758064,
      "loss": 0.5558,
      "step": 478780
    },
    {
      "epoch": 772.26,
      "learning_rate": 0.022804432034354834,
      "loss": 0.5514,
      "step": 478800
    },
    {
      "epoch": 772.29,
      "learning_rate": 0.02280120623112903,
      "loss": 0.5535,
      "step": 478820
    },
    {
      "epoch": 772.32,
      "learning_rate": 0.022797980427903222,
      "loss": 0.5596,
      "step": 478840
    },
    {
      "epoch": 772.35,
      "learning_rate": 0.022794754624677418,
      "loss": 0.555,
      "step": 478860
    },
    {
      "epoch": 772.39,
      "learning_rate": 0.02279152882145161,
      "loss": 0.554,
      "step": 478880
    },
    {
      "epoch": 772.42,
      "learning_rate": 0.022788303018225806,
      "loss": 0.5575,
      "step": 478900
    },
    {
      "epoch": 772.45,
      "learning_rate": 0.022785077215,
      "loss": 0.5675,
      "step": 478920
    },
    {
      "epoch": 772.48,
      "learning_rate": 0.022781851411774193,
      "loss": 0.5617,
      "step": 478940
    },
    {
      "epoch": 772.52,
      "learning_rate": 0.02277862560854839,
      "loss": 0.5619,
      "step": 478960
    },
    {
      "epoch": 772.55,
      "learning_rate": 0.02277539980532258,
      "loss": 0.5602,
      "step": 478980
    },
    {
      "epoch": 772.58,
      "learning_rate": 0.022772174002096777,
      "loss": 0.5696,
      "step": 479000
    },
    {
      "epoch": 772.61,
      "learning_rate": 0.022768948198870972,
      "loss": 0.5607,
      "step": 479020
    },
    {
      "epoch": 772.65,
      "learning_rate": 0.022765722395645165,
      "loss": 0.563,
      "step": 479040
    },
    {
      "epoch": 772.68,
      "learning_rate": 0.02276249659241936,
      "loss": 0.5675,
      "step": 479060
    },
    {
      "epoch": 772.71,
      "learning_rate": 0.022759270789193552,
      "loss": 0.5588,
      "step": 479080
    },
    {
      "epoch": 772.74,
      "learning_rate": 0.022756044985967738,
      "loss": 0.5656,
      "step": 479100
    },
    {
      "epoch": 772.77,
      "learning_rate": 0.02275281918274193,
      "loss": 0.5709,
      "step": 479120
    },
    {
      "epoch": 772.81,
      "learning_rate": 0.022749593379516125,
      "loss": 0.563,
      "step": 479140
    },
    {
      "epoch": 772.84,
      "learning_rate": 0.02274636757629032,
      "loss": 0.562,
      "step": 479160
    },
    {
      "epoch": 772.87,
      "learning_rate": 0.022743141773064513,
      "loss": 0.552,
      "step": 479180
    },
    {
      "epoch": 772.9,
      "learning_rate": 0.02273991596983871,
      "loss": 0.5541,
      "step": 479200
    },
    {
      "epoch": 772.94,
      "learning_rate": 0.0227366901666129,
      "loss": 0.5765,
      "step": 479220
    },
    {
      "epoch": 772.97,
      "learning_rate": 0.022733464363387097,
      "loss": 0.5623,
      "step": 479240
    },
    {
      "epoch": 773.0,
      "learning_rate": 0.022730238560161292,
      "loss": 0.5683,
      "step": 479260
    },
    {
      "epoch": 773.0,
      "eval_accuracy": {
        "accuracy": 0.7770665834048864
      },
      "eval_loss": 0.9333507418632507,
      "eval_runtime": 3.0336,
      "eval_samples_per_second": 4222.968,
      "eval_steps_per_second": 66.257,
      "step": 479260
    },
    {
      "epoch": 773.03,
      "learning_rate": 0.022727012756935484,
      "loss": 0.5685,
      "step": 479280
    },
    {
      "epoch": 773.06,
      "learning_rate": 0.02272378695370968,
      "loss": 0.5476,
      "step": 479300
    },
    {
      "epoch": 773.1,
      "learning_rate": 0.022720561150483872,
      "loss": 0.5446,
      "step": 479320
    },
    {
      "epoch": 773.13,
      "learning_rate": 0.022717335347258068,
      "loss": 0.5555,
      "step": 479340
    },
    {
      "epoch": 773.16,
      "learning_rate": 0.022714109544032263,
      "loss": 0.5508,
      "step": 479360
    },
    {
      "epoch": 773.19,
      "learning_rate": 0.022710883740806456,
      "loss": 0.5585,
      "step": 479380
    },
    {
      "epoch": 773.23,
      "learning_rate": 0.02270765793758064,
      "loss": 0.5558,
      "step": 479400
    },
    {
      "epoch": 773.26,
      "learning_rate": 0.022704432134354833,
      "loss": 0.5678,
      "step": 479420
    },
    {
      "epoch": 773.29,
      "learning_rate": 0.02270120633112903,
      "loss": 0.5616,
      "step": 479440
    },
    {
      "epoch": 773.32,
      "learning_rate": 0.022697980527903224,
      "loss": 0.5542,
      "step": 479460
    },
    {
      "epoch": 773.35,
      "learning_rate": 0.022694754724677416,
      "loss": 0.5595,
      "step": 479480
    },
    {
      "epoch": 773.39,
      "learning_rate": 0.022691528921451612,
      "loss": 0.5663,
      "step": 479500
    },
    {
      "epoch": 773.42,
      "learning_rate": 0.022688303118225804,
      "loss": 0.5529,
      "step": 479520
    },
    {
      "epoch": 773.45,
      "learning_rate": 0.022685077315,
      "loss": 0.5588,
      "step": 479540
    },
    {
      "epoch": 773.48,
      "learning_rate": 0.022681851511774195,
      "loss": 0.5582,
      "step": 479560
    },
    {
      "epoch": 773.52,
      "learning_rate": 0.022678625708548387,
      "loss": 0.5615,
      "step": 479580
    },
    {
      "epoch": 773.55,
      "learning_rate": 0.022675399905322583,
      "loss": 0.5646,
      "step": 479600
    },
    {
      "epoch": 773.58,
      "learning_rate": 0.022672174102096775,
      "loss": 0.5628,
      "step": 479620
    },
    {
      "epoch": 773.61,
      "learning_rate": 0.02266894829887097,
      "loss": 0.5619,
      "step": 479640
    },
    {
      "epoch": 773.65,
      "learning_rate": 0.022665722495645167,
      "loss": 0.544,
      "step": 479660
    },
    {
      "epoch": 773.68,
      "learning_rate": 0.02266249669241936,
      "loss": 0.556,
      "step": 479680
    },
    {
      "epoch": 773.71,
      "learning_rate": 0.022659270889193554,
      "loss": 0.5736,
      "step": 479700
    },
    {
      "epoch": 773.74,
      "learning_rate": 0.022656045085967736,
      "loss": 0.569,
      "step": 479720
    },
    {
      "epoch": 773.77,
      "learning_rate": 0.02265281928274193,
      "loss": 0.561,
      "step": 479740
    },
    {
      "epoch": 773.81,
      "learning_rate": 0.022649593479516124,
      "loss": 0.5635,
      "step": 479760
    },
    {
      "epoch": 773.84,
      "learning_rate": 0.02264636767629032,
      "loss": 0.5656,
      "step": 479780
    },
    {
      "epoch": 773.87,
      "learning_rate": 0.022643141873064515,
      "loss": 0.5633,
      "step": 479800
    },
    {
      "epoch": 773.9,
      "learning_rate": 0.022639916069838707,
      "loss": 0.5704,
      "step": 479820
    },
    {
      "epoch": 773.94,
      "learning_rate": 0.022636690266612903,
      "loss": 0.5664,
      "step": 479840
    },
    {
      "epoch": 773.97,
      "learning_rate": 0.022633464463387095,
      "loss": 0.5687,
      "step": 479860
    },
    {
      "epoch": 774.0,
      "learning_rate": 0.022630399950322577,
      "loss": 0.5577,
      "step": 479880
    },
    {
      "epoch": 774.0,
      "eval_accuracy": {
        "accuracy": 0.7822964639762704
      },
      "eval_loss": 0.9233191609382629,
      "eval_runtime": 2.9395,
      "eval_samples_per_second": 4358.22,
      "eval_steps_per_second": 68.379,
      "step": 479880
    },
    {
      "epoch": 774.03,
      "learning_rate": 0.022627174147096772,
      "loss": 0.5555,
      "step": 479900
    },
    {
      "epoch": 774.06,
      "learning_rate": 0.022623948343870964,
      "loss": 0.5476,
      "step": 479920
    },
    {
      "epoch": 774.1,
      "learning_rate": 0.02262072254064516,
      "loss": 0.5609,
      "step": 479940
    },
    {
      "epoch": 774.13,
      "learning_rate": 0.022617496737419352,
      "loss": 0.5581,
      "step": 479960
    },
    {
      "epoch": 774.16,
      "learning_rate": 0.022614270934193548,
      "loss": 0.5591,
      "step": 479980
    },
    {
      "epoch": 774.19,
      "learning_rate": 0.022611045130967743,
      "loss": 0.5523,
      "step": 480000
    },
    {
      "epoch": 774.23,
      "learning_rate": 0.022607819327741936,
      "loss": 0.5518,
      "step": 480020
    },
    {
      "epoch": 774.26,
      "learning_rate": 0.02260459352451613,
      "loss": 0.5573,
      "step": 480040
    },
    {
      "epoch": 774.29,
      "learning_rate": 0.022601367721290323,
      "loss": 0.5564,
      "step": 480060
    },
    {
      "epoch": 774.32,
      "learning_rate": 0.02259814191806452,
      "loss": 0.5654,
      "step": 480080
    },
    {
      "epoch": 774.35,
      "learning_rate": 0.022594916114838715,
      "loss": 0.5459,
      "step": 480100
    },
    {
      "epoch": 774.39,
      "learning_rate": 0.022591690311612907,
      "loss": 0.5659,
      "step": 480120
    },
    {
      "epoch": 774.42,
      "learning_rate": 0.022588464508387102,
      "loss": 0.5535,
      "step": 480140
    },
    {
      "epoch": 774.45,
      "learning_rate": 0.022585238705161284,
      "loss": 0.5438,
      "step": 480160
    },
    {
      "epoch": 774.48,
      "learning_rate": 0.02258201290193548,
      "loss": 0.5551,
      "step": 480180
    },
    {
      "epoch": 774.52,
      "learning_rate": 0.022578787098709672,
      "loss": 0.5555,
      "step": 480200
    },
    {
      "epoch": 774.55,
      "learning_rate": 0.022575561295483867,
      "loss": 0.5784,
      "step": 480220
    },
    {
      "epoch": 774.58,
      "learning_rate": 0.022572335492258063,
      "loss": 0.5526,
      "step": 480240
    },
    {
      "epoch": 774.61,
      "learning_rate": 0.022569109689032255,
      "loss": 0.5737,
      "step": 480260
    },
    {
      "epoch": 774.65,
      "learning_rate": 0.02256588388580645,
      "loss": 0.5536,
      "step": 480280
    },
    {
      "epoch": 774.68,
      "learning_rate": 0.022562658082580643,
      "loss": 0.5649,
      "step": 480300
    },
    {
      "epoch": 774.71,
      "learning_rate": 0.02255943227935484,
      "loss": 0.5645,
      "step": 480320
    },
    {
      "epoch": 774.74,
      "learning_rate": 0.022556206476129034,
      "loss": 0.568,
      "step": 480340
    },
    {
      "epoch": 774.77,
      "learning_rate": 0.022552980672903226,
      "loss": 0.5585,
      "step": 480360
    },
    {
      "epoch": 774.81,
      "learning_rate": 0.022549754869677422,
      "loss": 0.5673,
      "step": 480380
    },
    {
      "epoch": 774.84,
      "learning_rate": 0.022546529066451618,
      "loss": 0.5651,
      "step": 480400
    },
    {
      "epoch": 774.87,
      "learning_rate": 0.02254330326322581,
      "loss": 0.5697,
      "step": 480420
    },
    {
      "epoch": 774.9,
      "learning_rate": 0.022540077460000005,
      "loss": 0.5602,
      "step": 480440
    },
    {
      "epoch": 774.94,
      "learning_rate": 0.022536851656774198,
      "loss": 0.5704,
      "step": 480460
    },
    {
      "epoch": 774.97,
      "learning_rate": 0.022533625853548383,
      "loss": 0.5547,
      "step": 480480
    },
    {
      "epoch": 775.0,
      "learning_rate": 0.022530400050322575,
      "loss": 0.5657,
      "step": 480500
    },
    {
      "epoch": 775.0,
      "eval_accuracy": {
        "accuracy": 0.7813597689485599
      },
      "eval_loss": 0.9158855676651001,
      "eval_runtime": 2.9101,
      "eval_samples_per_second": 4402.312,
      "eval_steps_per_second": 69.071,
      "step": 480500
    },
    {
      "epoch": 775.03,
      "learning_rate": 0.02252717424709677,
      "loss": 0.5673,
      "step": 480520
    },
    {
      "epoch": 775.06,
      "learning_rate": 0.022523948443870966,
      "loss": 0.5398,
      "step": 480540
    },
    {
      "epoch": 775.1,
      "learning_rate": 0.02252072264064516,
      "loss": 0.5525,
      "step": 480560
    },
    {
      "epoch": 775.13,
      "learning_rate": 0.022517496837419354,
      "loss": 0.553,
      "step": 480580
    },
    {
      "epoch": 775.16,
      "learning_rate": 0.022514271034193546,
      "loss": 0.5646,
      "step": 480600
    },
    {
      "epoch": 775.19,
      "learning_rate": 0.022511045230967742,
      "loss": 0.5455,
      "step": 480620
    },
    {
      "epoch": 775.23,
      "learning_rate": 0.022507819427741937,
      "loss": 0.5526,
      "step": 480640
    },
    {
      "epoch": 775.26,
      "learning_rate": 0.02250459362451613,
      "loss": 0.5456,
      "step": 480660
    },
    {
      "epoch": 775.29,
      "learning_rate": 0.022501367821290325,
      "loss": 0.5433,
      "step": 480680
    },
    {
      "epoch": 775.32,
      "learning_rate": 0.022498142018064517,
      "loss": 0.5584,
      "step": 480700
    },
    {
      "epoch": 775.35,
      "learning_rate": 0.022494916214838713,
      "loss": 0.5758,
      "step": 480720
    },
    {
      "epoch": 775.39,
      "learning_rate": 0.02249169041161291,
      "loss": 0.566,
      "step": 480740
    },
    {
      "epoch": 775.42,
      "learning_rate": 0.0224884646083871,
      "loss": 0.5573,
      "step": 480760
    },
    {
      "epoch": 775.45,
      "learning_rate": 0.022485238805161296,
      "loss": 0.5617,
      "step": 480780
    },
    {
      "epoch": 775.48,
      "learning_rate": 0.022482013001935478,
      "loss": 0.5561,
      "step": 480800
    },
    {
      "epoch": 775.52,
      "learning_rate": 0.022478787198709674,
      "loss": 0.5565,
      "step": 480820
    },
    {
      "epoch": 775.55,
      "learning_rate": 0.022475561395483866,
      "loss": 0.5639,
      "step": 480840
    },
    {
      "epoch": 775.58,
      "learning_rate": 0.02247233559225806,
      "loss": 0.5522,
      "step": 480860
    },
    {
      "epoch": 775.61,
      "learning_rate": 0.022469109789032257,
      "loss": 0.5717,
      "step": 480880
    },
    {
      "epoch": 775.65,
      "learning_rate": 0.02246588398580645,
      "loss": 0.5609,
      "step": 480900
    },
    {
      "epoch": 775.68,
      "learning_rate": 0.022462658182580645,
      "loss": 0.5674,
      "step": 480920
    },
    {
      "epoch": 775.71,
      "learning_rate": 0.022459432379354837,
      "loss": 0.5608,
      "step": 480940
    },
    {
      "epoch": 775.74,
      "learning_rate": 0.022456206576129033,
      "loss": 0.554,
      "step": 480960
    },
    {
      "epoch": 775.77,
      "learning_rate": 0.02245298077290323,
      "loss": 0.549,
      "step": 480980
    },
    {
      "epoch": 775.81,
      "learning_rate": 0.02244975496967742,
      "loss": 0.5493,
      "step": 481000
    },
    {
      "epoch": 775.84,
      "learning_rate": 0.022446529166451616,
      "loss": 0.558,
      "step": 481020
    },
    {
      "epoch": 775.87,
      "learning_rate": 0.022443303363225812,
      "loss": 0.5569,
      "step": 481040
    },
    {
      "epoch": 775.9,
      "learning_rate": 0.022440077560000004,
      "loss": 0.5661,
      "step": 481060
    },
    {
      "epoch": 775.94,
      "learning_rate": 0.0224368517567742,
      "loss": 0.5692,
      "step": 481080
    },
    {
      "epoch": 775.97,
      "learning_rate": 0.02243362595354838,
      "loss": 0.5688,
      "step": 481100
    },
    {
      "epoch": 776.0,
      "learning_rate": 0.022430400150322577,
      "loss": 0.5574,
      "step": 481120
    },
    {
      "epoch": 776.0,
      "eval_accuracy": {
        "accuracy": 0.7834673327609086
      },
      "eval_loss": 0.9162589311599731,
      "eval_runtime": 3.1189,
      "eval_samples_per_second": 4107.493,
      "eval_steps_per_second": 64.445,
      "step": 481120
    },
    {
      "epoch": 776.03,
      "learning_rate": 0.02242717434709677,
      "loss": 0.5685,
      "step": 481140
    },
    {
      "epoch": 776.06,
      "learning_rate": 0.022423948543870965,
      "loss": 0.5545,
      "step": 481160
    },
    {
      "epoch": 776.1,
      "learning_rate": 0.02242072274064516,
      "loss": 0.5435,
      "step": 481180
    },
    {
      "epoch": 776.13,
      "learning_rate": 0.022417496937419353,
      "loss": 0.5478,
      "step": 481200
    },
    {
      "epoch": 776.16,
      "learning_rate": 0.022414271134193548,
      "loss": 0.5449,
      "step": 481220
    },
    {
      "epoch": 776.19,
      "learning_rate": 0.02241104533096774,
      "loss": 0.5458,
      "step": 481240
    },
    {
      "epoch": 776.23,
      "learning_rate": 0.022407819527741936,
      "loss": 0.563,
      "step": 481260
    },
    {
      "epoch": 776.26,
      "learning_rate": 0.02240459372451613,
      "loss": 0.5493,
      "step": 481280
    },
    {
      "epoch": 776.29,
      "learning_rate": 0.022401367921290324,
      "loss": 0.5663,
      "step": 481300
    },
    {
      "epoch": 776.32,
      "learning_rate": 0.02239814211806452,
      "loss": 0.5542,
      "step": 481320
    },
    {
      "epoch": 776.35,
      "learning_rate": 0.02239491631483871,
      "loss": 0.5584,
      "step": 481340
    },
    {
      "epoch": 776.39,
      "learning_rate": 0.022391690511612907,
      "loss": 0.5654,
      "step": 481360
    },
    {
      "epoch": 776.42,
      "learning_rate": 0.022388464708387103,
      "loss": 0.5573,
      "step": 481380
    },
    {
      "epoch": 776.45,
      "learning_rate": 0.022385238905161295,
      "loss": 0.5663,
      "step": 481400
    },
    {
      "epoch": 776.48,
      "learning_rate": 0.02238201310193548,
      "loss": 0.5612,
      "step": 481420
    },
    {
      "epoch": 776.52,
      "learning_rate": 0.022378787298709672,
      "loss": 0.5594,
      "step": 481440
    },
    {
      "epoch": 776.55,
      "learning_rate": 0.022375561495483868,
      "loss": 0.5749,
      "step": 481460
    },
    {
      "epoch": 776.58,
      "learning_rate": 0.02237233569225806,
      "loss": 0.5512,
      "step": 481480
    },
    {
      "epoch": 776.61,
      "learning_rate": 0.022369109889032256,
      "loss": 0.5713,
      "step": 481500
    },
    {
      "epoch": 776.65,
      "learning_rate": 0.02236588408580645,
      "loss": 0.5581,
      "step": 481520
    },
    {
      "epoch": 776.68,
      "learning_rate": 0.022362658282580643,
      "loss": 0.5603,
      "step": 481540
    },
    {
      "epoch": 776.71,
      "learning_rate": 0.02235943247935484,
      "loss": 0.5606,
      "step": 481560
    },
    {
      "epoch": 776.74,
      "learning_rate": 0.022356206676129035,
      "loss": 0.5526,
      "step": 481580
    },
    {
      "epoch": 776.77,
      "learning_rate": 0.022352980872903227,
      "loss": 0.56,
      "step": 481600
    },
    {
      "epoch": 776.81,
      "learning_rate": 0.022349755069677422,
      "loss": 0.564,
      "step": 481620
    },
    {
      "epoch": 776.84,
      "learning_rate": 0.022346529266451615,
      "loss": 0.5633,
      "step": 481640
    },
    {
      "epoch": 776.87,
      "learning_rate": 0.02234330346322581,
      "loss": 0.5575,
      "step": 481660
    },
    {
      "epoch": 776.9,
      "learning_rate": 0.022340077660000006,
      "loss": 0.552,
      "step": 481680
    },
    {
      "epoch": 776.94,
      "learning_rate": 0.022336851856774198,
      "loss": 0.5577,
      "step": 481700
    },
    {
      "epoch": 776.97,
      "learning_rate": 0.022333626053548383,
      "loss": 0.5546,
      "step": 481720
    },
    {
      "epoch": 777.0,
      "learning_rate": 0.022330400250322575,
      "loss": 0.5626,
      "step": 481740
    },
    {
      "epoch": 777.0,
      "eval_accuracy": {
        "accuracy": 0.780579189758801
      },
      "eval_loss": 0.9175016283988953,
      "eval_runtime": 3.3751,
      "eval_samples_per_second": 3795.772,
      "eval_steps_per_second": 59.554,
      "step": 481740
    },
    {
      "epoch": 777.03,
      "learning_rate": 0.02232717444709677,
      "loss": 0.5623,
      "step": 481760
    },
    {
      "epoch": 777.06,
      "learning_rate": 0.022323948643870963,
      "loss": 0.5559,
      "step": 481780
    },
    {
      "epoch": 777.1,
      "learning_rate": 0.02232072284064516,
      "loss": 0.5452,
      "step": 481800
    },
    {
      "epoch": 777.13,
      "learning_rate": 0.022317497037419354,
      "loss": 0.565,
      "step": 481820
    },
    {
      "epoch": 777.16,
      "learning_rate": 0.022314271234193547,
      "loss": 0.5668,
      "step": 481840
    },
    {
      "epoch": 777.19,
      "learning_rate": 0.022311045430967742,
      "loss": 0.5568,
      "step": 481860
    },
    {
      "epoch": 777.23,
      "learning_rate": 0.022307819627741934,
      "loss": 0.5526,
      "step": 481880
    },
    {
      "epoch": 777.26,
      "learning_rate": 0.02230459382451613,
      "loss": 0.5437,
      "step": 481900
    },
    {
      "epoch": 777.29,
      "learning_rate": 0.022301368021290326,
      "loss": 0.5546,
      "step": 481920
    },
    {
      "epoch": 777.32,
      "learning_rate": 0.022298142218064518,
      "loss": 0.5562,
      "step": 481940
    },
    {
      "epoch": 777.35,
      "learning_rate": 0.022294916414838713,
      "loss": 0.5682,
      "step": 481960
    },
    {
      "epoch": 777.39,
      "learning_rate": 0.022291690611612906,
      "loss": 0.5525,
      "step": 481980
    },
    {
      "epoch": 777.42,
      "learning_rate": 0.0222884648083871,
      "loss": 0.5569,
      "step": 482000
    },
    {
      "epoch": 777.45,
      "learning_rate": 0.022285239005161297,
      "loss": 0.5515,
      "step": 482020
    },
    {
      "epoch": 777.48,
      "learning_rate": 0.02228201320193548,
      "loss": 0.5566,
      "step": 482040
    },
    {
      "epoch": 777.52,
      "learning_rate": 0.022278787398709674,
      "loss": 0.5612,
      "step": 482060
    },
    {
      "epoch": 777.55,
      "learning_rate": 0.022275561595483866,
      "loss": 0.5635,
      "step": 482080
    },
    {
      "epoch": 777.58,
      "learning_rate": 0.022272335792258062,
      "loss": 0.551,
      "step": 482100
    },
    {
      "epoch": 777.61,
      "learning_rate": 0.022269109989032254,
      "loss": 0.5449,
      "step": 482120
    },
    {
      "epoch": 777.65,
      "learning_rate": 0.02226588418580645,
      "loss": 0.5562,
      "step": 482140
    },
    {
      "epoch": 777.68,
      "learning_rate": 0.022262658382580645,
      "loss": 0.556,
      "step": 482160
    },
    {
      "epoch": 777.71,
      "learning_rate": 0.022259432579354838,
      "loss": 0.5625,
      "step": 482180
    },
    {
      "epoch": 777.74,
      "learning_rate": 0.022256206776129033,
      "loss": 0.5558,
      "step": 482200
    },
    {
      "epoch": 777.77,
      "learning_rate": 0.02225298097290323,
      "loss": 0.5434,
      "step": 482220
    },
    {
      "epoch": 777.81,
      "learning_rate": 0.02224975516967742,
      "loss": 0.5581,
      "step": 482240
    },
    {
      "epoch": 777.84,
      "learning_rate": 0.022246529366451617,
      "loss": 0.5649,
      "step": 482260
    },
    {
      "epoch": 777.87,
      "learning_rate": 0.02224330356322581,
      "loss": 0.5669,
      "step": 482280
    },
    {
      "epoch": 777.9,
      "learning_rate": 0.022240077760000004,
      "loss": 0.5706,
      "step": 482300
    },
    {
      "epoch": 777.94,
      "learning_rate": 0.0222368519567742,
      "loss": 0.5688,
      "step": 482320
    },
    {
      "epoch": 777.97,
      "learning_rate": 0.02223362615354838,
      "loss": 0.5683,
      "step": 482340
    },
    {
      "epoch": 778.0,
      "learning_rate": 0.022230561640483874,
      "loss": 0.5729,
      "step": 482360
    },
    {
      "epoch": 778.0,
      "eval_accuracy": {
        "accuracy": 0.7802669580828975
      },
      "eval_loss": 0.9251681566238403,
      "eval_runtime": 4.0179,
      "eval_samples_per_second": 3188.468,
      "eval_steps_per_second": 50.026,
      "step": 482360
    },
    {
      "epoch": 778.03,
      "learning_rate": 0.022227335837258066,
      "loss": 0.5593,
      "step": 482380
    },
    {
      "epoch": 778.06,
      "learning_rate": 0.02222411003403226,
      "loss": 0.5509,
      "step": 482400
    },
    {
      "epoch": 778.1,
      "learning_rate": 0.022220884230806454,
      "loss": 0.5438,
      "step": 482420
    },
    {
      "epoch": 778.13,
      "learning_rate": 0.02221765842758065,
      "loss": 0.5554,
      "step": 482440
    },
    {
      "epoch": 778.16,
      "learning_rate": 0.022214432624354845,
      "loss": 0.5532,
      "step": 482460
    },
    {
      "epoch": 778.19,
      "learning_rate": 0.022211206821129027,
      "loss": 0.5424,
      "step": 482480
    },
    {
      "epoch": 778.23,
      "learning_rate": 0.022207981017903222,
      "loss": 0.5529,
      "step": 482500
    },
    {
      "epoch": 778.26,
      "learning_rate": 0.022204755214677414,
      "loss": 0.5691,
      "step": 482520
    },
    {
      "epoch": 778.29,
      "learning_rate": 0.02220152941145161,
      "loss": 0.5606,
      "step": 482540
    },
    {
      "epoch": 778.32,
      "learning_rate": 0.022198303608225802,
      "loss": 0.5504,
      "step": 482560
    },
    {
      "epoch": 778.35,
      "learning_rate": 0.022195077804999998,
      "loss": 0.5477,
      "step": 482580
    },
    {
      "epoch": 778.39,
      "learning_rate": 0.022191852001774193,
      "loss": 0.5583,
      "step": 482600
    },
    {
      "epoch": 778.42,
      "learning_rate": 0.022188626198548386,
      "loss": 0.5729,
      "step": 482620
    },
    {
      "epoch": 778.45,
      "learning_rate": 0.02218540039532258,
      "loss": 0.5649,
      "step": 482640
    },
    {
      "epoch": 778.48,
      "learning_rate": 0.022182174592096777,
      "loss": 0.5458,
      "step": 482660
    },
    {
      "epoch": 778.52,
      "learning_rate": 0.02217894878887097,
      "loss": 0.5684,
      "step": 482680
    },
    {
      "epoch": 778.55,
      "learning_rate": 0.022175722985645165,
      "loss": 0.5556,
      "step": 482700
    },
    {
      "epoch": 778.58,
      "learning_rate": 0.022172497182419357,
      "loss": 0.558,
      "step": 482720
    },
    {
      "epoch": 778.61,
      "learning_rate": 0.022169271379193552,
      "loss": 0.5532,
      "step": 482740
    },
    {
      "epoch": 778.65,
      "learning_rate": 0.022166045575967748,
      "loss": 0.5559,
      "step": 482760
    },
    {
      "epoch": 778.68,
      "learning_rate": 0.02216281977274194,
      "loss": 0.5419,
      "step": 482780
    },
    {
      "epoch": 778.71,
      "learning_rate": 0.022159593969516125,
      "loss": 0.5507,
      "step": 482800
    },
    {
      "epoch": 778.74,
      "learning_rate": 0.022156368166290318,
      "loss": 0.5476,
      "step": 482820
    },
    {
      "epoch": 778.77,
      "learning_rate": 0.022153142363064513,
      "loss": 0.5616,
      "step": 482840
    },
    {
      "epoch": 778.81,
      "learning_rate": 0.022149916559838705,
      "loss": 0.5639,
      "step": 482860
    },
    {
      "epoch": 778.84,
      "learning_rate": 0.0221466907566129,
      "loss": 0.5758,
      "step": 482880
    },
    {
      "epoch": 778.87,
      "learning_rate": 0.022143464953387097,
      "loss": 0.5778,
      "step": 482900
    },
    {
      "epoch": 778.9,
      "learning_rate": 0.02214023915016129,
      "loss": 0.5587,
      "step": 482920
    },
    {
      "epoch": 778.94,
      "learning_rate": 0.022137013346935484,
      "loss": 0.5674,
      "step": 482940
    },
    {
      "epoch": 778.97,
      "learning_rate": 0.022133787543709676,
      "loss": 0.5527,
      "step": 482960
    },
    {
      "epoch": 779.0,
      "learning_rate": 0.022130561740483872,
      "loss": 0.5561,
      "step": 482980
    },
    {
      "epoch": 779.0,
      "eval_accuracy": {
        "accuracy": 0.7780813363515728
      },
      "eval_loss": 0.9289143681526184,
      "eval_runtime": 3.1885,
      "eval_samples_per_second": 4017.899,
      "eval_steps_per_second": 63.039,
      "step": 482980
    },
    {
      "epoch": 779.03,
      "learning_rate": 0.022127335937258068,
      "loss": 0.562,
      "step": 483000
    },
    {
      "epoch": 779.06,
      "learning_rate": 0.02212411013403226,
      "loss": 0.5567,
      "step": 483020
    },
    {
      "epoch": 779.1,
      "learning_rate": 0.022120884330806456,
      "loss": 0.5472,
      "step": 483040
    },
    {
      "epoch": 779.13,
      "learning_rate": 0.022117658527580648,
      "loss": 0.5462,
      "step": 483060
    },
    {
      "epoch": 779.16,
      "learning_rate": 0.022114432724354843,
      "loss": 0.5495,
      "step": 483080
    },
    {
      "epoch": 779.19,
      "learning_rate": 0.02211120692112904,
      "loss": 0.5461,
      "step": 483100
    },
    {
      "epoch": 779.23,
      "learning_rate": 0.02210798111790322,
      "loss": 0.5593,
      "step": 483120
    },
    {
      "epoch": 779.26,
      "learning_rate": 0.022104755314677416,
      "loss": 0.5451,
      "step": 483140
    },
    {
      "epoch": 779.29,
      "learning_rate": 0.02210152951145161,
      "loss": 0.5493,
      "step": 483160
    },
    {
      "epoch": 779.32,
      "learning_rate": 0.022098303708225804,
      "loss": 0.5536,
      "step": 483180
    },
    {
      "epoch": 779.35,
      "learning_rate": 0.022095077904999996,
      "loss": 0.553,
      "step": 483200
    },
    {
      "epoch": 779.39,
      "learning_rate": 0.022091852101774192,
      "loss": 0.554,
      "step": 483220
    },
    {
      "epoch": 779.42,
      "learning_rate": 0.022088626298548387,
      "loss": 0.5523,
      "step": 483240
    },
    {
      "epoch": 779.45,
      "learning_rate": 0.02208540049532258,
      "loss": 0.5497,
      "step": 483260
    },
    {
      "epoch": 779.48,
      "learning_rate": 0.022082174692096775,
      "loss": 0.5493,
      "step": 483280
    },
    {
      "epoch": 779.52,
      "learning_rate": 0.02207894888887097,
      "loss": 0.5743,
      "step": 483300
    },
    {
      "epoch": 779.55,
      "learning_rate": 0.022075723085645163,
      "loss": 0.5572,
      "step": 483320
    },
    {
      "epoch": 779.58,
      "learning_rate": 0.02207249728241936,
      "loss": 0.5668,
      "step": 483340
    },
    {
      "epoch": 779.61,
      "learning_rate": 0.02206927147919355,
      "loss": 0.5547,
      "step": 483360
    },
    {
      "epoch": 779.65,
      "learning_rate": 0.022066045675967746,
      "loss": 0.5558,
      "step": 483380
    },
    {
      "epoch": 779.68,
      "learning_rate": 0.022062819872741942,
      "loss": 0.5528,
      "step": 483400
    },
    {
      "epoch": 779.71,
      "learning_rate": 0.022059594069516124,
      "loss": 0.5598,
      "step": 483420
    },
    {
      "epoch": 779.74,
      "learning_rate": 0.02205636826629032,
      "loss": 0.5587,
      "step": 483440
    },
    {
      "epoch": 779.77,
      "learning_rate": 0.02205314246306451,
      "loss": 0.5662,
      "step": 483460
    },
    {
      "epoch": 779.81,
      "learning_rate": 0.022049916659838707,
      "loss": 0.5601,
      "step": 483480
    },
    {
      "epoch": 779.84,
      "learning_rate": 0.0220466908566129,
      "loss": 0.557,
      "step": 483500
    },
    {
      "epoch": 779.87,
      "learning_rate": 0.022043465053387095,
      "loss": 0.5631,
      "step": 483520
    },
    {
      "epoch": 779.9,
      "learning_rate": 0.02204023925016129,
      "loss": 0.5603,
      "step": 483540
    },
    {
      "epoch": 779.94,
      "learning_rate": 0.022037013446935483,
      "loss": 0.566,
      "step": 483560
    },
    {
      "epoch": 779.97,
      "learning_rate": 0.02203378764370968,
      "loss": 0.5654,
      "step": 483580
    },
    {
      "epoch": 780.0,
      "learning_rate": 0.02203056184048387,
      "loss": 0.5671,
      "step": 483600
    },
    {
      "epoch": 780.0,
      "eval_accuracy": {
        "accuracy": 0.7801889001639216
      },
      "eval_loss": 0.9163423180580139,
      "eval_runtime": 3.3254,
      "eval_samples_per_second": 3852.484,
      "eval_steps_per_second": 60.444,
      "step": 483600
    },
    {
      "epoch": 780.03,
      "learning_rate": 0.022027336037258066,
      "loss": 0.5637,
      "step": 483620
    },
    {
      "epoch": 780.06,
      "learning_rate": 0.022024110234032262,
      "loss": 0.5496,
      "step": 483640
    },
    {
      "epoch": 780.1,
      "learning_rate": 0.022020884430806454,
      "loss": 0.5425,
      "step": 483660
    },
    {
      "epoch": 780.13,
      "learning_rate": 0.02201765862758065,
      "loss": 0.5413,
      "step": 483680
    },
    {
      "epoch": 780.16,
      "learning_rate": 0.022014432824354842,
      "loss": 0.5496,
      "step": 483700
    },
    {
      "epoch": 780.19,
      "learning_rate": 0.022011207021129037,
      "loss": 0.5491,
      "step": 483720
    },
    {
      "epoch": 780.23,
      "learning_rate": 0.02200798121790322,
      "loss": 0.564,
      "step": 483740
    },
    {
      "epoch": 780.26,
      "learning_rate": 0.022004755414677415,
      "loss": 0.5494,
      "step": 483760
    },
    {
      "epoch": 780.29,
      "learning_rate": 0.02200152961145161,
      "loss": 0.5529,
      "step": 483780
    },
    {
      "epoch": 780.32,
      "learning_rate": 0.021998303808225803,
      "loss": 0.5737,
      "step": 483800
    },
    {
      "epoch": 780.35,
      "learning_rate": 0.021995078004999998,
      "loss": 0.5568,
      "step": 483820
    },
    {
      "epoch": 780.39,
      "learning_rate": 0.021991852201774194,
      "loss": 0.5613,
      "step": 483840
    },
    {
      "epoch": 780.42,
      "learning_rate": 0.021988626398548386,
      "loss": 0.5653,
      "step": 483860
    },
    {
      "epoch": 780.45,
      "learning_rate": 0.02198540059532258,
      "loss": 0.5619,
      "step": 483880
    },
    {
      "epoch": 780.48,
      "learning_rate": 0.021982174792096774,
      "loss": 0.5577,
      "step": 483900
    },
    {
      "epoch": 780.52,
      "learning_rate": 0.02197894898887097,
      "loss": 0.5592,
      "step": 483920
    },
    {
      "epoch": 780.55,
      "learning_rate": 0.021975723185645165,
      "loss": 0.5628,
      "step": 483940
    },
    {
      "epoch": 780.58,
      "learning_rate": 0.021972497382419357,
      "loss": 0.5581,
      "step": 483960
    },
    {
      "epoch": 780.61,
      "learning_rate": 0.021969271579193553,
      "loss": 0.5527,
      "step": 483980
    },
    {
      "epoch": 780.65,
      "learning_rate": 0.021966045775967745,
      "loss": 0.5551,
      "step": 484000
    },
    {
      "epoch": 780.68,
      "learning_rate": 0.02196281997274194,
      "loss": 0.5612,
      "step": 484020
    },
    {
      "epoch": 780.71,
      "learning_rate": 0.021959594169516122,
      "loss": 0.563,
      "step": 484040
    },
    {
      "epoch": 780.74,
      "learning_rate": 0.021956368366290318,
      "loss": 0.5572,
      "step": 484060
    },
    {
      "epoch": 780.77,
      "learning_rate": 0.021953142563064514,
      "loss": 0.5563,
      "step": 484080
    },
    {
      "epoch": 780.81,
      "learning_rate": 0.021949916759838706,
      "loss": 0.5623,
      "step": 484100
    },
    {
      "epoch": 780.84,
      "learning_rate": 0.0219466909566129,
      "loss": 0.5577,
      "step": 484120
    },
    {
      "epoch": 780.87,
      "learning_rate": 0.021943465153387093,
      "loss": 0.5566,
      "step": 484140
    },
    {
      "epoch": 780.9,
      "learning_rate": 0.02194023935016129,
      "loss": 0.5559,
      "step": 484160
    },
    {
      "epoch": 780.94,
      "learning_rate": 0.021937013546935485,
      "loss": 0.5523,
      "step": 484180
    },
    {
      "epoch": 780.97,
      "learning_rate": 0.021933787743709677,
      "loss": 0.5497,
      "step": 484200
    },
    {
      "epoch": 781.0,
      "learning_rate": 0.021930561940483873,
      "loss": 0.5658,
      "step": 484220
    },
    {
      "epoch": 781.0,
      "eval_accuracy": {
        "accuracy": 0.7836234485988604
      },
      "eval_loss": 0.9181020855903625,
      "eval_runtime": 2.9978,
      "eval_samples_per_second": 4273.499,
      "eval_steps_per_second": 67.05,
      "step": 484220
    },
    {
      "epoch": 781.03,
      "learning_rate": 0.021927336137258065,
      "loss": 0.5655,
      "step": 484240
    },
    {
      "epoch": 781.06,
      "learning_rate": 0.02192411033403226,
      "loss": 0.5408,
      "step": 484260
    },
    {
      "epoch": 781.1,
      "learning_rate": 0.021920884530806456,
      "loss": 0.5393,
      "step": 484280
    },
    {
      "epoch": 781.13,
      "learning_rate": 0.021917658727580648,
      "loss": 0.5428,
      "step": 484300
    },
    {
      "epoch": 781.16,
      "learning_rate": 0.021914432924354844,
      "loss": 0.5639,
      "step": 484320
    },
    {
      "epoch": 781.19,
      "learning_rate": 0.021911207121129036,
      "loss": 0.5579,
      "step": 484340
    },
    {
      "epoch": 781.23,
      "learning_rate": 0.02190798131790322,
      "loss": 0.5547,
      "step": 484360
    },
    {
      "epoch": 781.26,
      "learning_rate": 0.021904755514677417,
      "loss": 0.5556,
      "step": 484380
    },
    {
      "epoch": 781.29,
      "learning_rate": 0.02190152971145161,
      "loss": 0.5439,
      "step": 484400
    },
    {
      "epoch": 781.32,
      "learning_rate": 0.021898303908225804,
      "loss": 0.5489,
      "step": 484420
    },
    {
      "epoch": 781.35,
      "learning_rate": 0.021895078104999997,
      "loss": 0.5464,
      "step": 484440
    },
    {
      "epoch": 781.39,
      "learning_rate": 0.021891852301774192,
      "loss": 0.5473,
      "step": 484460
    },
    {
      "epoch": 781.42,
      "learning_rate": 0.021888626498548388,
      "loss": 0.5551,
      "step": 484480
    },
    {
      "epoch": 781.45,
      "learning_rate": 0.02188540069532258,
      "loss": 0.5705,
      "step": 484500
    },
    {
      "epoch": 781.48,
      "learning_rate": 0.021882174892096776,
      "loss": 0.5586,
      "step": 484520
    },
    {
      "epoch": 781.52,
      "learning_rate": 0.021878949088870968,
      "loss": 0.5679,
      "step": 484540
    },
    {
      "epoch": 781.55,
      "learning_rate": 0.021875723285645163,
      "loss": 0.5511,
      "step": 484560
    },
    {
      "epoch": 781.58,
      "learning_rate": 0.02187249748241936,
      "loss": 0.5543,
      "step": 484580
    },
    {
      "epoch": 781.61,
      "learning_rate": 0.02186927167919355,
      "loss": 0.5643,
      "step": 484600
    },
    {
      "epoch": 781.65,
      "learning_rate": 0.021866045875967747,
      "loss": 0.5669,
      "step": 484620
    },
    {
      "epoch": 781.68,
      "learning_rate": 0.02186282007274194,
      "loss": 0.559,
      "step": 484640
    },
    {
      "epoch": 781.71,
      "learning_rate": 0.021859594269516124,
      "loss": 0.5555,
      "step": 484660
    },
    {
      "epoch": 781.74,
      "learning_rate": 0.021856368466290316,
      "loss": 0.5549,
      "step": 484680
    },
    {
      "epoch": 781.77,
      "learning_rate": 0.021853142663064512,
      "loss": 0.5495,
      "step": 484700
    },
    {
      "epoch": 781.81,
      "learning_rate": 0.021849916859838708,
      "loss": 0.5569,
      "step": 484720
    },
    {
      "epoch": 781.84,
      "learning_rate": 0.0218466910566129,
      "loss": 0.5624,
      "step": 484740
    },
    {
      "epoch": 781.87,
      "learning_rate": 0.021843465253387095,
      "loss": 0.5677,
      "step": 484760
    },
    {
      "epoch": 781.9,
      "learning_rate": 0.021840239450161288,
      "loss": 0.5619,
      "step": 484780
    },
    {
      "epoch": 781.94,
      "learning_rate": 0.021837013646935483,
      "loss": 0.5513,
      "step": 484800
    },
    {
      "epoch": 781.97,
      "learning_rate": 0.02183378784370968,
      "loss": 0.5568,
      "step": 484820
    },
    {
      "epoch": 782.0,
      "learning_rate": 0.021830723330645157,
      "loss": 0.5633,
      "step": 484840
    },
    {
      "epoch": 782.0,
      "eval_accuracy": {
        "accuracy": 0.7793302630551869
      },
      "eval_loss": 0.9270660281181335,
      "eval_runtime": 3.2269,
      "eval_samples_per_second": 3970.055,
      "eval_steps_per_second": 62.289,
      "step": 484840
    },
    {
      "epoch": 782.03,
      "learning_rate": 0.021827497527419353,
      "loss": 0.547,
      "step": 484860
    },
    {
      "epoch": 782.06,
      "learning_rate": 0.021824271724193545,
      "loss": 0.5411,
      "step": 484880
    },
    {
      "epoch": 782.1,
      "learning_rate": 0.02182104592096774,
      "loss": 0.5491,
      "step": 484900
    },
    {
      "epoch": 782.13,
      "learning_rate": 0.021817820117741936,
      "loss": 0.55,
      "step": 484920
    },
    {
      "epoch": 782.16,
      "learning_rate": 0.021814594314516128,
      "loss": 0.5522,
      "step": 484940
    },
    {
      "epoch": 782.19,
      "learning_rate": 0.021811368511290324,
      "loss": 0.5618,
      "step": 484960
    },
    {
      "epoch": 782.23,
      "learning_rate": 0.021808142708064516,
      "loss": 0.5474,
      "step": 484980
    },
    {
      "epoch": 782.26,
      "learning_rate": 0.02180491690483871,
      "loss": 0.5477,
      "step": 485000
    },
    {
      "epoch": 782.29,
      "learning_rate": 0.021801691101612907,
      "loss": 0.5619,
      "step": 485020
    },
    {
      "epoch": 782.32,
      "learning_rate": 0.0217984652983871,
      "loss": 0.5578,
      "step": 485040
    },
    {
      "epoch": 782.35,
      "learning_rate": 0.021795239495161295,
      "loss": 0.5525,
      "step": 485060
    },
    {
      "epoch": 782.39,
      "learning_rate": 0.021792013691935487,
      "loss": 0.5358,
      "step": 485080
    },
    {
      "epoch": 782.42,
      "learning_rate": 0.021788787888709683,
      "loss": 0.5519,
      "step": 485100
    },
    {
      "epoch": 782.45,
      "learning_rate": 0.021785562085483864,
      "loss": 0.5534,
      "step": 485120
    },
    {
      "epoch": 782.48,
      "learning_rate": 0.02178233628225806,
      "loss": 0.547,
      "step": 485140
    },
    {
      "epoch": 782.52,
      "learning_rate": 0.021779110479032256,
      "loss": 0.5553,
      "step": 485160
    },
    {
      "epoch": 782.55,
      "learning_rate": 0.021775884675806448,
      "loss": 0.543,
      "step": 485180
    },
    {
      "epoch": 782.58,
      "learning_rate": 0.021772658872580643,
      "loss": 0.5511,
      "step": 485200
    },
    {
      "epoch": 782.61,
      "learning_rate": 0.021769433069354836,
      "loss": 0.564,
      "step": 485220
    },
    {
      "epoch": 782.65,
      "learning_rate": 0.02176620726612903,
      "loss": 0.5566,
      "step": 485240
    },
    {
      "epoch": 782.68,
      "learning_rate": 0.021762981462903227,
      "loss": 0.5444,
      "step": 485260
    },
    {
      "epoch": 782.71,
      "learning_rate": 0.02175975565967742,
      "loss": 0.5572,
      "step": 485280
    },
    {
      "epoch": 782.74,
      "learning_rate": 0.021756529856451615,
      "loss": 0.5543,
      "step": 485300
    },
    {
      "epoch": 782.77,
      "learning_rate": 0.021753304053225807,
      "loss": 0.5685,
      "step": 485320
    },
    {
      "epoch": 782.81,
      "learning_rate": 0.021750078250000002,
      "loss": 0.567,
      "step": 485340
    },
    {
      "epoch": 782.84,
      "learning_rate": 0.021746852446774198,
      "loss": 0.5571,
      "step": 485360
    },
    {
      "epoch": 782.87,
      "learning_rate": 0.02174362664354839,
      "loss": 0.5532,
      "step": 485380
    },
    {
      "epoch": 782.9,
      "learning_rate": 0.021740400840322586,
      "loss": 0.5687,
      "step": 485400
    },
    {
      "epoch": 782.94,
      "learning_rate": 0.021737175037096778,
      "loss": 0.5559,
      "step": 485420
    },
    {
      "epoch": 782.97,
      "learning_rate": 0.021733949233870963,
      "loss": 0.56,
      "step": 485440
    },
    {
      "epoch": 783.0,
      "learning_rate": 0.02173072343064516,
      "loss": 0.5668,
      "step": 485460
    },
    {
      "epoch": 783.0,
      "eval_accuracy": {
        "accuracy": 0.7834673327609086
      },
      "eval_loss": 0.9143385887145996,
      "eval_runtime": 3.3434,
      "eval_samples_per_second": 3831.734,
      "eval_steps_per_second": 60.119,
      "step": 485460
    },
    {
      "epoch": 783.03,
      "learning_rate": 0.02172749762741935,
      "loss": 0.5682,
      "step": 485480
    },
    {
      "epoch": 783.06,
      "learning_rate": 0.021724271824193547,
      "loss": 0.557,
      "step": 485500
    },
    {
      "epoch": 783.1,
      "learning_rate": 0.02172104602096774,
      "loss": 0.5548,
      "step": 485520
    },
    {
      "epoch": 783.13,
      "learning_rate": 0.021717820217741934,
      "loss": 0.5457,
      "step": 485540
    },
    {
      "epoch": 783.16,
      "learning_rate": 0.02171459441451613,
      "loss": 0.5575,
      "step": 485560
    },
    {
      "epoch": 783.19,
      "learning_rate": 0.021711368611290322,
      "loss": 0.5526,
      "step": 485580
    },
    {
      "epoch": 783.23,
      "learning_rate": 0.021708142808064518,
      "loss": 0.5524,
      "step": 485600
    },
    {
      "epoch": 783.26,
      "learning_rate": 0.02170491700483871,
      "loss": 0.542,
      "step": 485620
    },
    {
      "epoch": 783.29,
      "learning_rate": 0.021701691201612906,
      "loss": 0.5633,
      "step": 485640
    },
    {
      "epoch": 783.32,
      "learning_rate": 0.0216984653983871,
      "loss": 0.5614,
      "step": 485660
    },
    {
      "epoch": 783.35,
      "learning_rate": 0.021695239595161293,
      "loss": 0.5561,
      "step": 485680
    },
    {
      "epoch": 783.39,
      "learning_rate": 0.02169201379193549,
      "loss": 0.5474,
      "step": 485700
    },
    {
      "epoch": 783.42,
      "learning_rate": 0.02168878798870968,
      "loss": 0.5477,
      "step": 485720
    },
    {
      "epoch": 783.45,
      "learning_rate": 0.021685562185483866,
      "loss": 0.5623,
      "step": 485740
    },
    {
      "epoch": 783.48,
      "learning_rate": 0.02168233638225806,
      "loss": 0.5459,
      "step": 485760
    },
    {
      "epoch": 783.52,
      "learning_rate": 0.021679110579032254,
      "loss": 0.5609,
      "step": 485780
    },
    {
      "epoch": 783.55,
      "learning_rate": 0.02167588477580645,
      "loss": 0.5642,
      "step": 485800
    },
    {
      "epoch": 783.58,
      "learning_rate": 0.021672658972580642,
      "loss": 0.5553,
      "step": 485820
    },
    {
      "epoch": 783.61,
      "learning_rate": 0.021669433169354838,
      "loss": 0.5547,
      "step": 485840
    },
    {
      "epoch": 783.65,
      "learning_rate": 0.02166620736612903,
      "loss": 0.5447,
      "step": 485860
    },
    {
      "epoch": 783.68,
      "learning_rate": 0.021662981562903225,
      "loss": 0.5615,
      "step": 485880
    },
    {
      "epoch": 783.71,
      "learning_rate": 0.02165975575967742,
      "loss": 0.5522,
      "step": 485900
    },
    {
      "epoch": 783.74,
      "learning_rate": 0.021656529956451613,
      "loss": 0.5441,
      "step": 485920
    },
    {
      "epoch": 783.77,
      "learning_rate": 0.02165330415322581,
      "loss": 0.5561,
      "step": 485940
    },
    {
      "epoch": 783.81,
      "learning_rate": 0.02165007835,
      "loss": 0.5565,
      "step": 485960
    },
    {
      "epoch": 783.84,
      "learning_rate": 0.021646852546774197,
      "loss": 0.555,
      "step": 485980
    },
    {
      "epoch": 783.87,
      "learning_rate": 0.021643626743548392,
      "loss": 0.567,
      "step": 486000
    },
    {
      "epoch": 783.9,
      "learning_rate": 0.021640400940322584,
      "loss": 0.556,
      "step": 486020
    },
    {
      "epoch": 783.94,
      "learning_rate": 0.02163717513709678,
      "loss": 0.5545,
      "step": 486040
    },
    {
      "epoch": 783.97,
      "learning_rate": 0.02163394933387096,
      "loss": 0.5618,
      "step": 486060
    },
    {
      "epoch": 784.0,
      "learning_rate": 0.021630723530645157,
      "loss": 0.5507,
      "step": 486080
    },
    {
      "epoch": 784.0,
      "eval_accuracy": {
        "accuracy": 0.7794083209741628
      },
      "eval_loss": 0.9260365962982178,
      "eval_runtime": 3.0355,
      "eval_samples_per_second": 4220.357,
      "eval_steps_per_second": 66.216,
      "step": 486080
    },
    {
      "epoch": 784.03,
      "learning_rate": 0.021627497727419353,
      "loss": 0.553,
      "step": 486100
    },
    {
      "epoch": 784.06,
      "learning_rate": 0.021624271924193545,
      "loss": 0.5489,
      "step": 486120
    },
    {
      "epoch": 784.1,
      "learning_rate": 0.02162104612096774,
      "loss": 0.5441,
      "step": 486140
    },
    {
      "epoch": 784.13,
      "learning_rate": 0.021617820317741933,
      "loss": 0.5423,
      "step": 486160
    },
    {
      "epoch": 784.16,
      "learning_rate": 0.02161459451451613,
      "loss": 0.5611,
      "step": 486180
    },
    {
      "epoch": 784.19,
      "learning_rate": 0.021611368711290324,
      "loss": 0.5444,
      "step": 486200
    },
    {
      "epoch": 784.23,
      "learning_rate": 0.021608142908064516,
      "loss": 0.5585,
      "step": 486220
    },
    {
      "epoch": 784.26,
      "learning_rate": 0.021604917104838712,
      "loss": 0.5535,
      "step": 486240
    },
    {
      "epoch": 784.29,
      "learning_rate": 0.021601691301612904,
      "loss": 0.5522,
      "step": 486260
    },
    {
      "epoch": 784.32,
      "learning_rate": 0.0215984654983871,
      "loss": 0.5478,
      "step": 486280
    },
    {
      "epoch": 784.35,
      "learning_rate": 0.021595239695161295,
      "loss": 0.5558,
      "step": 486300
    },
    {
      "epoch": 784.39,
      "learning_rate": 0.021592013891935487,
      "loss": 0.5531,
      "step": 486320
    },
    {
      "epoch": 784.42,
      "learning_rate": 0.021588788088709683,
      "loss": 0.5569,
      "step": 486340
    },
    {
      "epoch": 784.45,
      "learning_rate": 0.021585562285483865,
      "loss": 0.5544,
      "step": 486360
    },
    {
      "epoch": 784.48,
      "learning_rate": 0.02158233648225806,
      "loss": 0.5457,
      "step": 486380
    },
    {
      "epoch": 784.52,
      "learning_rate": 0.021579110679032253,
      "loss": 0.5517,
      "step": 486400
    },
    {
      "epoch": 784.55,
      "learning_rate": 0.021575884875806448,
      "loss": 0.542,
      "step": 486420
    },
    {
      "epoch": 784.58,
      "learning_rate": 0.021572659072580644,
      "loss": 0.5543,
      "step": 486440
    },
    {
      "epoch": 784.61,
      "learning_rate": 0.021569433269354836,
      "loss": 0.5571,
      "step": 486460
    },
    {
      "epoch": 784.65,
      "learning_rate": 0.02156620746612903,
      "loss": 0.547,
      "step": 486480
    },
    {
      "epoch": 784.68,
      "learning_rate": 0.021562981662903224,
      "loss": 0.5439,
      "step": 486500
    },
    {
      "epoch": 784.71,
      "learning_rate": 0.02155975585967742,
      "loss": 0.5495,
      "step": 486520
    },
    {
      "epoch": 784.74,
      "learning_rate": 0.021556530056451615,
      "loss": 0.5631,
      "step": 486540
    },
    {
      "epoch": 784.77,
      "learning_rate": 0.021553304253225807,
      "loss": 0.561,
      "step": 486560
    },
    {
      "epoch": 784.81,
      "learning_rate": 0.021550078450000003,
      "loss": 0.5574,
      "step": 486580
    },
    {
      "epoch": 784.84,
      "learning_rate": 0.0215468526467742,
      "loss": 0.5632,
      "step": 486600
    },
    {
      "epoch": 784.87,
      "learning_rate": 0.02154362684354839,
      "loss": 0.5496,
      "step": 486620
    },
    {
      "epoch": 784.9,
      "learning_rate": 0.021540401040322586,
      "loss": 0.5464,
      "step": 486640
    },
    {
      "epoch": 784.94,
      "learning_rate": 0.02153717523709678,
      "loss": 0.5602,
      "step": 486660
    },
    {
      "epoch": 784.97,
      "learning_rate": 0.021533949433870964,
      "loss": 0.5678,
      "step": 486680
    },
    {
      "epoch": 785.0,
      "learning_rate": 0.021530723630645156,
      "loss": 0.5611,
      "step": 486700
    },
    {
      "epoch": 785.0,
      "eval_accuracy": {
        "accuracy": 0.7815158847865116
      },
      "eval_loss": 0.9097476005554199,
      "eval_runtime": 3.1452,
      "eval_samples_per_second": 4073.127,
      "eval_steps_per_second": 63.906,
      "step": 486700
    },
    {
      "epoch": 785.03,
      "learning_rate": 0.02152749782741935,
      "loss": 0.557,
      "step": 486720
    },
    {
      "epoch": 785.06,
      "learning_rate": 0.021524272024193547,
      "loss": 0.5582,
      "step": 486740
    },
    {
      "epoch": 785.1,
      "learning_rate": 0.02152104622096774,
      "loss": 0.5412,
      "step": 486760
    },
    {
      "epoch": 785.13,
      "learning_rate": 0.021517820417741935,
      "loss": 0.5471,
      "step": 486780
    },
    {
      "epoch": 785.16,
      "learning_rate": 0.021514594614516127,
      "loss": 0.5488,
      "step": 486800
    },
    {
      "epoch": 785.19,
      "learning_rate": 0.021511368811290323,
      "loss": 0.5453,
      "step": 486820
    },
    {
      "epoch": 785.23,
      "learning_rate": 0.021508143008064518,
      "loss": 0.5413,
      "step": 486840
    },
    {
      "epoch": 785.26,
      "learning_rate": 0.02150491720483871,
      "loss": 0.5522,
      "step": 486860
    },
    {
      "epoch": 785.29,
      "learning_rate": 0.021501691401612906,
      "loss": 0.5397,
      "step": 486880
    },
    {
      "epoch": 785.32,
      "learning_rate": 0.021498465598387098,
      "loss": 0.5496,
      "step": 486900
    },
    {
      "epoch": 785.35,
      "learning_rate": 0.021495239795161294,
      "loss": 0.5664,
      "step": 486920
    },
    {
      "epoch": 785.39,
      "learning_rate": 0.02149201399193549,
      "loss": 0.5477,
      "step": 486940
    },
    {
      "epoch": 785.42,
      "learning_rate": 0.02148878818870968,
      "loss": 0.5517,
      "step": 486960
    },
    {
      "epoch": 785.45,
      "learning_rate": 0.021485562385483867,
      "loss": 0.5697,
      "step": 486980
    },
    {
      "epoch": 785.48,
      "learning_rate": 0.02148233658225806,
      "loss": 0.5473,
      "step": 487000
    },
    {
      "epoch": 785.52,
      "learning_rate": 0.021479110779032255,
      "loss": 0.5535,
      "step": 487020
    },
    {
      "epoch": 785.55,
      "learning_rate": 0.021475884975806447,
      "loss": 0.5473,
      "step": 487040
    },
    {
      "epoch": 785.58,
      "learning_rate": 0.021472659172580642,
      "loss": 0.5466,
      "step": 487060
    },
    {
      "epoch": 785.61,
      "learning_rate": 0.021469433369354838,
      "loss": 0.552,
      "step": 487080
    },
    {
      "epoch": 785.65,
      "learning_rate": 0.02146620756612903,
      "loss": 0.5487,
      "step": 487100
    },
    {
      "epoch": 785.68,
      "learning_rate": 0.021462981762903226,
      "loss": 0.5602,
      "step": 487120
    },
    {
      "epoch": 785.71,
      "learning_rate": 0.021459755959677418,
      "loss": 0.5562,
      "step": 487140
    },
    {
      "epoch": 785.74,
      "learning_rate": 0.021456530156451614,
      "loss": 0.5662,
      "step": 487160
    },
    {
      "epoch": 785.77,
      "learning_rate": 0.02145330435322581,
      "loss": 0.5571,
      "step": 487180
    },
    {
      "epoch": 785.81,
      "learning_rate": 0.02145007855,
      "loss": 0.5713,
      "step": 487200
    },
    {
      "epoch": 785.84,
      "learning_rate": 0.021446852746774197,
      "loss": 0.5404,
      "step": 487220
    },
    {
      "epoch": 785.87,
      "learning_rate": 0.021443626943548393,
      "loss": 0.5467,
      "step": 487240
    },
    {
      "epoch": 785.9,
      "learning_rate": 0.021440401140322585,
      "loss": 0.5618,
      "step": 487260
    },
    {
      "epoch": 785.94,
      "learning_rate": 0.02143717533709678,
      "loss": 0.5556,
      "step": 487280
    },
    {
      "epoch": 785.97,
      "learning_rate": 0.021433949533870962,
      "loss": 0.5536,
      "step": 487300
    },
    {
      "epoch": 786.0,
      "learning_rate": 0.021430723730645158,
      "loss": 0.5691,
      "step": 487320
    },
    {
      "epoch": 786.0,
      "eval_accuracy": {
        "accuracy": 0.7820622902193427
      },
      "eval_loss": 0.9108297228813171,
      "eval_runtime": 2.9168,
      "eval_samples_per_second": 4392.096,
      "eval_steps_per_second": 68.91,
      "step": 487320
    },
    {
      "epoch": 786.03,
      "learning_rate": 0.02142749792741935,
      "loss": 0.5625,
      "step": 487340
    },
    {
      "epoch": 786.06,
      "learning_rate": 0.021424272124193545,
      "loss": 0.5533,
      "step": 487360
    },
    {
      "epoch": 786.1,
      "learning_rate": 0.02142104632096774,
      "loss": 0.5495,
      "step": 487380
    },
    {
      "epoch": 786.13,
      "learning_rate": 0.021417820517741933,
      "loss": 0.5507,
      "step": 487400
    },
    {
      "epoch": 786.16,
      "learning_rate": 0.02141459471451613,
      "loss": 0.5347,
      "step": 487420
    },
    {
      "epoch": 786.19,
      "learning_rate": 0.02141136891129032,
      "loss": 0.5524,
      "step": 487440
    },
    {
      "epoch": 786.23,
      "learning_rate": 0.021408143108064517,
      "loss": 0.5519,
      "step": 487460
    },
    {
      "epoch": 786.26,
      "learning_rate": 0.021404917304838712,
      "loss": 0.5434,
      "step": 487480
    },
    {
      "epoch": 786.29,
      "learning_rate": 0.021401691501612904,
      "loss": 0.5546,
      "step": 487500
    },
    {
      "epoch": 786.32,
      "learning_rate": 0.0213984656983871,
      "loss": 0.5423,
      "step": 487520
    },
    {
      "epoch": 786.35,
      "learning_rate": 0.021395239895161292,
      "loss": 0.5503,
      "step": 487540
    },
    {
      "epoch": 786.39,
      "learning_rate": 0.021392014091935488,
      "loss": 0.5428,
      "step": 487560
    },
    {
      "epoch": 786.42,
      "learning_rate": 0.021388788288709683,
      "loss": 0.5511,
      "step": 487580
    },
    {
      "epoch": 786.45,
      "learning_rate": 0.021385562485483865,
      "loss": 0.561,
      "step": 487600
    },
    {
      "epoch": 786.48,
      "learning_rate": 0.02138233668225806,
      "loss": 0.555,
      "step": 487620
    },
    {
      "epoch": 786.52,
      "learning_rate": 0.021379110879032253,
      "loss": 0.5601,
      "step": 487640
    },
    {
      "epoch": 786.55,
      "learning_rate": 0.02137588507580645,
      "loss": 0.5505,
      "step": 487660
    },
    {
      "epoch": 786.58,
      "learning_rate": 0.02137265927258064,
      "loss": 0.5617,
      "step": 487680
    },
    {
      "epoch": 786.61,
      "learning_rate": 0.021369433469354836,
      "loss": 0.5544,
      "step": 487700
    },
    {
      "epoch": 786.65,
      "learning_rate": 0.021366207666129032,
      "loss": 0.5499,
      "step": 487720
    },
    {
      "epoch": 786.68,
      "learning_rate": 0.021362981862903224,
      "loss": 0.5529,
      "step": 487740
    },
    {
      "epoch": 786.71,
      "learning_rate": 0.02135975605967742,
      "loss": 0.5404,
      "step": 487760
    },
    {
      "epoch": 786.74,
      "learning_rate": 0.021356530256451615,
      "loss": 0.5371,
      "step": 487780
    },
    {
      "epoch": 786.77,
      "learning_rate": 0.021353304453225808,
      "loss": 0.5627,
      "step": 487800
    },
    {
      "epoch": 786.81,
      "learning_rate": 0.021350078650000003,
      "loss": 0.5536,
      "step": 487820
    },
    {
      "epoch": 786.84,
      "learning_rate": 0.021346852846774195,
      "loss": 0.5452,
      "step": 487840
    },
    {
      "epoch": 786.87,
      "learning_rate": 0.02134362704354839,
      "loss": 0.5654,
      "step": 487860
    },
    {
      "epoch": 786.9,
      "learning_rate": 0.021340401240322587,
      "loss": 0.5573,
      "step": 487880
    },
    {
      "epoch": 786.94,
      "learning_rate": 0.02133717543709678,
      "loss": 0.5503,
      "step": 487900
    },
    {
      "epoch": 786.97,
      "learning_rate": 0.021333949633870964,
      "loss": 0.5653,
      "step": 487920
    },
    {
      "epoch": 787.0,
      "learning_rate": 0.021330723830645156,
      "loss": 0.5471,
      "step": 487940
    },
    {
      "epoch": 787.0,
      "eval_accuracy": {
        "accuracy": 0.7796424947310905
      },
      "eval_loss": 0.9211159348487854,
      "eval_runtime": 3.1409,
      "eval_samples_per_second": 4078.773,
      "eval_steps_per_second": 63.994,
      "step": 487940
    },
    {
      "epoch": 787.03,
      "learning_rate": 0.021327498027419352,
      "loss": 0.5523,
      "step": 487960
    },
    {
      "epoch": 787.06,
      "learning_rate": 0.021324272224193544,
      "loss": 0.5455,
      "step": 487980
    },
    {
      "epoch": 787.1,
      "learning_rate": 0.02132104642096774,
      "loss": 0.5563,
      "step": 488000
    },
    {
      "epoch": 787.13,
      "learning_rate": 0.021317820617741935,
      "loss": 0.5461,
      "step": 488020
    },
    {
      "epoch": 787.16,
      "learning_rate": 0.021314594814516127,
      "loss": 0.5391,
      "step": 488040
    },
    {
      "epoch": 787.19,
      "learning_rate": 0.021311369011290323,
      "loss": 0.5432,
      "step": 488060
    },
    {
      "epoch": 787.23,
      "learning_rate": 0.021308143208064515,
      "loss": 0.5502,
      "step": 488080
    },
    {
      "epoch": 787.26,
      "learning_rate": 0.02130491740483871,
      "loss": 0.5494,
      "step": 488100
    },
    {
      "epoch": 787.29,
      "learning_rate": 0.021301691601612906,
      "loss": 0.5493,
      "step": 488120
    },
    {
      "epoch": 787.32,
      "learning_rate": 0.0212984657983871,
      "loss": 0.5485,
      "step": 488140
    },
    {
      "epoch": 787.35,
      "learning_rate": 0.021295239995161294,
      "loss": 0.5598,
      "step": 488160
    },
    {
      "epoch": 787.39,
      "learning_rate": 0.021292014191935486,
      "loss": 0.5501,
      "step": 488180
    },
    {
      "epoch": 787.42,
      "learning_rate": 0.021288788388709682,
      "loss": 0.5485,
      "step": 488200
    },
    {
      "epoch": 787.45,
      "learning_rate": 0.021285562585483878,
      "loss": 0.5542,
      "step": 488220
    },
    {
      "epoch": 787.48,
      "learning_rate": 0.02128233678225806,
      "loss": 0.5591,
      "step": 488240
    },
    {
      "epoch": 787.52,
      "learning_rate": 0.021279110979032255,
      "loss": 0.5576,
      "step": 488260
    },
    {
      "epoch": 787.55,
      "learning_rate": 0.021275885175806447,
      "loss": 0.5462,
      "step": 488280
    },
    {
      "epoch": 787.58,
      "learning_rate": 0.021272659372580643,
      "loss": 0.5667,
      "step": 488300
    },
    {
      "epoch": 787.61,
      "learning_rate": 0.021269433569354835,
      "loss": 0.5602,
      "step": 488320
    },
    {
      "epoch": 787.65,
      "learning_rate": 0.02126620776612903,
      "loss": 0.5511,
      "step": 488340
    },
    {
      "epoch": 787.68,
      "learning_rate": 0.021262981962903226,
      "loss": 0.5633,
      "step": 488360
    },
    {
      "epoch": 787.71,
      "learning_rate": 0.02125975615967742,
      "loss": 0.5558,
      "step": 488380
    },
    {
      "epoch": 787.74,
      "learning_rate": 0.021256530356451614,
      "loss": 0.5489,
      "step": 488400
    },
    {
      "epoch": 787.77,
      "learning_rate": 0.02125330455322581,
      "loss": 0.5418,
      "step": 488420
    },
    {
      "epoch": 787.81,
      "learning_rate": 0.02125007875,
      "loss": 0.554,
      "step": 488440
    },
    {
      "epoch": 787.84,
      "learning_rate": 0.021246852946774197,
      "loss": 0.5413,
      "step": 488460
    },
    {
      "epoch": 787.87,
      "learning_rate": 0.02124362714354839,
      "loss": 0.5473,
      "step": 488480
    },
    {
      "epoch": 787.9,
      "learning_rate": 0.021240401340322585,
      "loss": 0.5447,
      "step": 488500
    },
    {
      "epoch": 787.94,
      "learning_rate": 0.02123717553709678,
      "loss": 0.5615,
      "step": 488520
    },
    {
      "epoch": 787.97,
      "learning_rate": 0.021233949733870962,
      "loss": 0.5589,
      "step": 488540
    },
    {
      "epoch": 788.0,
      "learning_rate": 0.021230723930645158,
      "loss": 0.5635,
      "step": 488560
    },
    {
      "epoch": 788.0,
      "eval_accuracy": {
        "accuracy": 0.7774568729997658
      },
      "eval_loss": 0.9159719944000244,
      "eval_runtime": 2.9697,
      "eval_samples_per_second": 4313.934,
      "eval_steps_per_second": 67.684,
      "step": 488560
    },
    {
      "epoch": 788.03,
      "learning_rate": 0.02122749812741935,
      "loss": 0.5499,
      "step": 488580
    },
    {
      "epoch": 788.06,
      "learning_rate": 0.021224272324193546,
      "loss": 0.5293,
      "step": 488600
    },
    {
      "epoch": 788.1,
      "learning_rate": 0.021221046520967738,
      "loss": 0.551,
      "step": 488620
    },
    {
      "epoch": 788.13,
      "learning_rate": 0.021217820717741934,
      "loss": 0.5471,
      "step": 488640
    },
    {
      "epoch": 788.16,
      "learning_rate": 0.02121459491451613,
      "loss": 0.5488,
      "step": 488660
    },
    {
      "epoch": 788.19,
      "learning_rate": 0.02121136911129032,
      "loss": 0.552,
      "step": 488680
    },
    {
      "epoch": 788.23,
      "learning_rate": 0.021208143308064517,
      "loss": 0.5503,
      "step": 488700
    },
    {
      "epoch": 788.26,
      "learning_rate": 0.02120491750483871,
      "loss": 0.5425,
      "step": 488720
    },
    {
      "epoch": 788.29,
      "learning_rate": 0.021201691701612905,
      "loss": 0.5464,
      "step": 488740
    },
    {
      "epoch": 788.32,
      "learning_rate": 0.0211984658983871,
      "loss": 0.5533,
      "step": 488760
    },
    {
      "epoch": 788.35,
      "learning_rate": 0.021195240095161293,
      "loss": 0.5543,
      "step": 488780
    },
    {
      "epoch": 788.39,
      "learning_rate": 0.02119201429193549,
      "loss": 0.5618,
      "step": 488800
    },
    {
      "epoch": 788.42,
      "learning_rate": 0.02118878848870968,
      "loss": 0.5535,
      "step": 488820
    },
    {
      "epoch": 788.45,
      "learning_rate": 0.021185562685483876,
      "loss": 0.5345,
      "step": 488840
    },
    {
      "epoch": 788.48,
      "learning_rate": 0.021182498172419358,
      "loss": 0.5456,
      "step": 488860
    },
    {
      "epoch": 788.52,
      "learning_rate": 0.02117927236919355,
      "loss": 0.5555,
      "step": 488880
    },
    {
      "epoch": 788.55,
      "learning_rate": 0.021176046565967745,
      "loss": 0.5471,
      "step": 488900
    },
    {
      "epoch": 788.58,
      "learning_rate": 0.021172820762741938,
      "loss": 0.5511,
      "step": 488920
    },
    {
      "epoch": 788.61,
      "learning_rate": 0.021169594959516133,
      "loss": 0.5542,
      "step": 488940
    },
    {
      "epoch": 788.65,
      "learning_rate": 0.02116636915629033,
      "loss": 0.5457,
      "step": 488960
    },
    {
      "epoch": 788.68,
      "learning_rate": 0.02116314335306452,
      "loss": 0.5555,
      "step": 488980
    },
    {
      "epoch": 788.71,
      "learning_rate": 0.021159917549838706,
      "loss": 0.5518,
      "step": 489000
    },
    {
      "epoch": 788.74,
      "learning_rate": 0.0211566917466129,
      "loss": 0.547,
      "step": 489020
    },
    {
      "epoch": 788.77,
      "learning_rate": 0.021153465943387094,
      "loss": 0.5603,
      "step": 489040
    },
    {
      "epoch": 788.81,
      "learning_rate": 0.021150240140161286,
      "loss": 0.5531,
      "step": 489060
    },
    {
      "epoch": 788.84,
      "learning_rate": 0.02114701433693548,
      "loss": 0.5431,
      "step": 489080
    },
    {
      "epoch": 788.87,
      "learning_rate": 0.021143788533709677,
      "loss": 0.5397,
      "step": 489100
    },
    {
      "epoch": 788.9,
      "learning_rate": 0.02114056273048387,
      "loss": 0.5552,
      "step": 489120
    },
    {
      "epoch": 788.94,
      "learning_rate": 0.021137336927258065,
      "loss": 0.5645,
      "step": 489140
    },
    {
      "epoch": 788.97,
      "learning_rate": 0.021134111124032257,
      "loss": 0.5767,
      "step": 489160
    },
    {
      "epoch": 789.0,
      "learning_rate": 0.021130885320806453,
      "loss": 0.562,
      "step": 489180
    },
    {
      "epoch": 789.0,
      "eval_accuracy": {
        "accuracy": 0.7820622902193427
      },
      "eval_loss": 0.9095253944396973,
      "eval_runtime": 2.9584,
      "eval_samples_per_second": 4330.335,
      "eval_steps_per_second": 67.941,
      "step": 489180
    },
    {
      "epoch": 789.03,
      "learning_rate": 0.02112765951758065,
      "loss": 0.5623,
      "step": 489200
    },
    {
      "epoch": 789.06,
      "learning_rate": 0.02112443371435484,
      "loss": 0.5523,
      "step": 489220
    },
    {
      "epoch": 789.1,
      "learning_rate": 0.021121207911129036,
      "loss": 0.5465,
      "step": 489240
    },
    {
      "epoch": 789.13,
      "learning_rate": 0.02111798210790323,
      "loss": 0.5445,
      "step": 489260
    },
    {
      "epoch": 789.16,
      "learning_rate": 0.021114756304677424,
      "loss": 0.5439,
      "step": 489280
    },
    {
      "epoch": 789.19,
      "learning_rate": 0.021111530501451606,
      "loss": 0.5497,
      "step": 489300
    },
    {
      "epoch": 789.23,
      "learning_rate": 0.0211083046982258,
      "loss": 0.552,
      "step": 489320
    },
    {
      "epoch": 789.26,
      "learning_rate": 0.021105078894999997,
      "loss": 0.5586,
      "step": 489340
    },
    {
      "epoch": 789.29,
      "learning_rate": 0.02110185309177419,
      "loss": 0.5532,
      "step": 489360
    },
    {
      "epoch": 789.32,
      "learning_rate": 0.021098627288548385,
      "loss": 0.5504,
      "step": 489380
    },
    {
      "epoch": 789.35,
      "learning_rate": 0.02109540148532258,
      "loss": 0.5458,
      "step": 489400
    },
    {
      "epoch": 789.39,
      "learning_rate": 0.021092175682096773,
      "loss": 0.5418,
      "step": 489420
    },
    {
      "epoch": 789.42,
      "learning_rate": 0.021088949878870968,
      "loss": 0.5597,
      "step": 489440
    },
    {
      "epoch": 789.45,
      "learning_rate": 0.02108572407564516,
      "loss": 0.5459,
      "step": 489460
    },
    {
      "epoch": 789.48,
      "learning_rate": 0.021082498272419356,
      "loss": 0.5487,
      "step": 489480
    },
    {
      "epoch": 789.52,
      "learning_rate": 0.02107927246919355,
      "loss": 0.5542,
      "step": 489500
    },
    {
      "epoch": 789.55,
      "learning_rate": 0.021076046665967744,
      "loss": 0.5516,
      "step": 489520
    },
    {
      "epoch": 789.58,
      "learning_rate": 0.02107282086274194,
      "loss": 0.5441,
      "step": 489540
    },
    {
      "epoch": 789.61,
      "learning_rate": 0.02106959505951613,
      "loss": 0.5503,
      "step": 489560
    },
    {
      "epoch": 789.65,
      "learning_rate": 0.021066369256290327,
      "loss": 0.5472,
      "step": 489580
    },
    {
      "epoch": 789.68,
      "learning_rate": 0.021063143453064523,
      "loss": 0.5591,
      "step": 489600
    },
    {
      "epoch": 789.71,
      "learning_rate": 0.021059917649838705,
      "loss": 0.5541,
      "step": 489620
    },
    {
      "epoch": 789.74,
      "learning_rate": 0.0210566918466129,
      "loss": 0.5556,
      "step": 489640
    },
    {
      "epoch": 789.77,
      "learning_rate": 0.021053466043387092,
      "loss": 0.5545,
      "step": 489660
    },
    {
      "epoch": 789.81,
      "learning_rate": 0.021050240240161288,
      "loss": 0.5498,
      "step": 489680
    },
    {
      "epoch": 789.84,
      "learning_rate": 0.02104701443693548,
      "loss": 0.5438,
      "step": 489700
    },
    {
      "epoch": 789.87,
      "learning_rate": 0.021043788633709676,
      "loss": 0.5544,
      "step": 489720
    },
    {
      "epoch": 789.9,
      "learning_rate": 0.02104056283048387,
      "loss": 0.5479,
      "step": 489740
    },
    {
      "epoch": 789.94,
      "learning_rate": 0.021037337027258064,
      "loss": 0.5505,
      "step": 489760
    },
    {
      "epoch": 789.97,
      "learning_rate": 0.02103411122403226,
      "loss": 0.5578,
      "step": 489780
    },
    {
      "epoch": 790.0,
      "learning_rate": 0.021031046710967737,
      "loss": 0.5673,
      "step": 489800
    },
    {
      "epoch": 790.0,
      "eval_accuracy": {
        "accuracy": 0.7794863788931387
      },
      "eval_loss": 0.9202733039855957,
      "eval_runtime": 3.1018,
      "eval_samples_per_second": 4130.215,
      "eval_steps_per_second": 64.802,
      "step": 489800
    },
    {
      "epoch": 790.03,
      "learning_rate": 0.021027820907741933,
      "loss": 0.5437,
      "step": 489820
    },
    {
      "epoch": 790.06,
      "learning_rate": 0.021024595104516125,
      "loss": 0.5539,
      "step": 489840
    },
    {
      "epoch": 790.1,
      "learning_rate": 0.02102136930129032,
      "loss": 0.5407,
      "step": 489860
    },
    {
      "epoch": 790.13,
      "learning_rate": 0.021018143498064516,
      "loss": 0.5392,
      "step": 489880
    },
    {
      "epoch": 790.16,
      "learning_rate": 0.02101491769483871,
      "loss": 0.5501,
      "step": 489900
    },
    {
      "epoch": 790.19,
      "learning_rate": 0.021011691891612904,
      "loss": 0.5478,
      "step": 489920
    },
    {
      "epoch": 790.23,
      "learning_rate": 0.0210084660883871,
      "loss": 0.552,
      "step": 489940
    },
    {
      "epoch": 790.26,
      "learning_rate": 0.021005240285161292,
      "loss": 0.5418,
      "step": 489960
    },
    {
      "epoch": 790.29,
      "learning_rate": 0.021002014481935487,
      "loss": 0.5547,
      "step": 489980
    },
    {
      "epoch": 790.32,
      "learning_rate": 0.02099878867870968,
      "loss": 0.5468,
      "step": 490000
    },
    {
      "epoch": 790.35,
      "learning_rate": 0.020995562875483875,
      "loss": 0.5469,
      "step": 490020
    },
    {
      "epoch": 790.39,
      "learning_rate": 0.02099233707225807,
      "loss": 0.562,
      "step": 490040
    },
    {
      "epoch": 790.42,
      "learning_rate": 0.020989111269032263,
      "loss": 0.5615,
      "step": 490060
    },
    {
      "epoch": 790.45,
      "learning_rate": 0.020985885465806448,
      "loss": 0.5462,
      "step": 490080
    },
    {
      "epoch": 790.48,
      "learning_rate": 0.02098265966258064,
      "loss": 0.5571,
      "step": 490100
    },
    {
      "epoch": 790.52,
      "learning_rate": 0.020979433859354836,
      "loss": 0.5515,
      "step": 490120
    },
    {
      "epoch": 790.55,
      "learning_rate": 0.020976208056129028,
      "loss": 0.55,
      "step": 490140
    },
    {
      "epoch": 790.58,
      "learning_rate": 0.020972982252903224,
      "loss": 0.5483,
      "step": 490160
    },
    {
      "epoch": 790.61,
      "learning_rate": 0.02096975644967742,
      "loss": 0.5515,
      "step": 490180
    },
    {
      "epoch": 790.65,
      "learning_rate": 0.02096653064645161,
      "loss": 0.5471,
      "step": 490200
    },
    {
      "epoch": 790.68,
      "learning_rate": 0.020963304843225807,
      "loss": 0.5463,
      "step": 490220
    },
    {
      "epoch": 790.71,
      "learning_rate": 0.02096007904,
      "loss": 0.5458,
      "step": 490240
    },
    {
      "epoch": 790.74,
      "learning_rate": 0.020956853236774195,
      "loss": 0.5412,
      "step": 490260
    },
    {
      "epoch": 790.77,
      "learning_rate": 0.02095362743354839,
      "loss": 0.553,
      "step": 490280
    },
    {
      "epoch": 790.81,
      "learning_rate": 0.020950401630322583,
      "loss": 0.5532,
      "step": 490300
    },
    {
      "epoch": 790.84,
      "learning_rate": 0.02094717582709678,
      "loss": 0.5512,
      "step": 490320
    },
    {
      "epoch": 790.87,
      "learning_rate": 0.02094395002387097,
      "loss": 0.5576,
      "step": 490340
    },
    {
      "epoch": 790.9,
      "learning_rate": 0.020940724220645166,
      "loss": 0.5493,
      "step": 490360
    },
    {
      "epoch": 790.94,
      "learning_rate": 0.020937498417419348,
      "loss": 0.545,
      "step": 490380
    },
    {
      "epoch": 790.97,
      "learning_rate": 0.020934272614193544,
      "loss": 0.5575,
      "step": 490400
    },
    {
      "epoch": 791.0,
      "learning_rate": 0.02093104681096774,
      "loss": 0.5668,
      "step": 490420
    },
    {
      "epoch": 791.0,
      "eval_accuracy": {
        "accuracy": 0.7808914214347046
      },
      "eval_loss": 0.9206850528717041,
      "eval_runtime": 2.9459,
      "eval_samples_per_second": 4348.783,
      "eval_steps_per_second": 68.231,
      "step": 490420
    },
    {
      "epoch": 791.03,
      "learning_rate": 0.02092782100774193,
      "loss": 0.5496,
      "step": 490440
    },
    {
      "epoch": 791.06,
      "learning_rate": 0.020924595204516127,
      "loss": 0.5526,
      "step": 490460
    },
    {
      "epoch": 791.1,
      "learning_rate": 0.020921369401290323,
      "loss": 0.5474,
      "step": 490480
    },
    {
      "epoch": 791.13,
      "learning_rate": 0.020918143598064515,
      "loss": 0.5396,
      "step": 490500
    },
    {
      "epoch": 791.16,
      "learning_rate": 0.02091491779483871,
      "loss": 0.5407,
      "step": 490520
    },
    {
      "epoch": 791.19,
      "learning_rate": 0.020911691991612903,
      "loss": 0.5429,
      "step": 490540
    },
    {
      "epoch": 791.23,
      "learning_rate": 0.020908466188387098,
      "loss": 0.5458,
      "step": 490560
    },
    {
      "epoch": 791.26,
      "learning_rate": 0.020905240385161294,
      "loss": 0.5534,
      "step": 490580
    },
    {
      "epoch": 791.29,
      "learning_rate": 0.020902014581935486,
      "loss": 0.546,
      "step": 490600
    },
    {
      "epoch": 791.32,
      "learning_rate": 0.02089878877870968,
      "loss": 0.5472,
      "step": 490620
    },
    {
      "epoch": 791.35,
      "learning_rate": 0.020895562975483874,
      "loss": 0.551,
      "step": 490640
    },
    {
      "epoch": 791.39,
      "learning_rate": 0.02089233717225807,
      "loss": 0.5526,
      "step": 490660
    },
    {
      "epoch": 791.42,
      "learning_rate": 0.020889111369032265,
      "loss": 0.5363,
      "step": 490680
    },
    {
      "epoch": 791.45,
      "learning_rate": 0.020885885565806447,
      "loss": 0.5555,
      "step": 490700
    },
    {
      "epoch": 791.48,
      "learning_rate": 0.020882659762580642,
      "loss": 0.5495,
      "step": 490720
    },
    {
      "epoch": 791.52,
      "learning_rate": 0.020879433959354834,
      "loss": 0.5509,
      "step": 490740
    },
    {
      "epoch": 791.55,
      "learning_rate": 0.02087620815612903,
      "loss": 0.5448,
      "step": 490760
    },
    {
      "epoch": 791.58,
      "learning_rate": 0.020872982352903222,
      "loss": 0.5572,
      "step": 490780
    },
    {
      "epoch": 791.61,
      "learning_rate": 0.020869756549677418,
      "loss": 0.5515,
      "step": 490800
    },
    {
      "epoch": 791.65,
      "learning_rate": 0.020866530746451614,
      "loss": 0.5543,
      "step": 490820
    },
    {
      "epoch": 791.68,
      "learning_rate": 0.020863304943225806,
      "loss": 0.558,
      "step": 490840
    },
    {
      "epoch": 791.71,
      "learning_rate": 0.02086007914,
      "loss": 0.543,
      "step": 490860
    },
    {
      "epoch": 791.74,
      "learning_rate": 0.020856853336774193,
      "loss": 0.5543,
      "step": 490880
    },
    {
      "epoch": 791.77,
      "learning_rate": 0.02085362753354839,
      "loss": 0.5534,
      "step": 490900
    },
    {
      "epoch": 791.81,
      "learning_rate": 0.020850401730322585,
      "loss": 0.554,
      "step": 490920
    },
    {
      "epoch": 791.84,
      "learning_rate": 0.020847175927096777,
      "loss": 0.5552,
      "step": 490940
    },
    {
      "epoch": 791.87,
      "learning_rate": 0.020843950123870972,
      "loss": 0.5582,
      "step": 490960
    },
    {
      "epoch": 791.9,
      "learning_rate": 0.020840724320645165,
      "loss": 0.5545,
      "step": 490980
    },
    {
      "epoch": 791.94,
      "learning_rate": 0.02083749851741935,
      "loss": 0.5429,
      "step": 491000
    },
    {
      "epoch": 791.97,
      "learning_rate": 0.020834272714193542,
      "loss": 0.5664,
      "step": 491020
    },
    {
      "epoch": 792.0,
      "learning_rate": 0.020831046910967738,
      "loss": 0.5585,
      "step": 491040
    },
    {
      "epoch": 792.0,
      "eval_accuracy": {
        "accuracy": 0.7790180313792834
      },
      "eval_loss": 0.9232337474822998,
      "eval_runtime": 3.1421,
      "eval_samples_per_second": 4077.178,
      "eval_steps_per_second": 63.969,
      "step": 491040
    },
    {
      "epoch": 792.03,
      "learning_rate": 0.020827821107741933,
      "loss": 0.5499,
      "step": 491060
    },
    {
      "epoch": 792.06,
      "learning_rate": 0.020824595304516125,
      "loss": 0.54,
      "step": 491080
    },
    {
      "epoch": 792.1,
      "learning_rate": 0.02082136950129032,
      "loss": 0.5386,
      "step": 491100
    },
    {
      "epoch": 792.13,
      "learning_rate": 0.020818143698064517,
      "loss": 0.5514,
      "step": 491120
    },
    {
      "epoch": 792.16,
      "learning_rate": 0.02081491789483871,
      "loss": 0.5527,
      "step": 491140
    },
    {
      "epoch": 792.19,
      "learning_rate": 0.020811692091612904,
      "loss": 0.5426,
      "step": 491160
    },
    {
      "epoch": 792.23,
      "learning_rate": 0.020808466288387097,
      "loss": 0.5426,
      "step": 491180
    },
    {
      "epoch": 792.26,
      "learning_rate": 0.020805240485161292,
      "loss": 0.5456,
      "step": 491200
    },
    {
      "epoch": 792.29,
      "learning_rate": 0.020802014681935488,
      "loss": 0.5411,
      "step": 491220
    },
    {
      "epoch": 792.32,
      "learning_rate": 0.02079878887870968,
      "loss": 0.5551,
      "step": 491240
    },
    {
      "epoch": 792.35,
      "learning_rate": 0.020795563075483876,
      "loss": 0.562,
      "step": 491260
    },
    {
      "epoch": 792.39,
      "learning_rate": 0.020792337272258068,
      "loss": 0.5657,
      "step": 491280
    },
    {
      "epoch": 792.42,
      "learning_rate": 0.020789111469032263,
      "loss": 0.5579,
      "step": 491300
    },
    {
      "epoch": 792.45,
      "learning_rate": 0.020785885665806445,
      "loss": 0.552,
      "step": 491320
    },
    {
      "epoch": 792.48,
      "learning_rate": 0.02078265986258064,
      "loss": 0.5521,
      "step": 491340
    },
    {
      "epoch": 792.52,
      "learning_rate": 0.020779434059354836,
      "loss": 0.5404,
      "step": 491360
    },
    {
      "epoch": 792.55,
      "learning_rate": 0.02077620825612903,
      "loss": 0.5447,
      "step": 491380
    },
    {
      "epoch": 792.58,
      "learning_rate": 0.020772982452903224,
      "loss": 0.5505,
      "step": 491400
    },
    {
      "epoch": 792.61,
      "learning_rate": 0.020769756649677416,
      "loss": 0.5506,
      "step": 491420
    },
    {
      "epoch": 792.65,
      "learning_rate": 0.020766530846451612,
      "loss": 0.5396,
      "step": 491440
    },
    {
      "epoch": 792.68,
      "learning_rate": 0.020763305043225808,
      "loss": 0.5531,
      "step": 491460
    },
    {
      "epoch": 792.71,
      "learning_rate": 0.02076007924,
      "loss": 0.5688,
      "step": 491480
    },
    {
      "epoch": 792.74,
      "learning_rate": 0.020756853436774195,
      "loss": 0.5518,
      "step": 491500
    },
    {
      "epoch": 792.77,
      "learning_rate": 0.020753627633548388,
      "loss": 0.5482,
      "step": 491520
    },
    {
      "epoch": 792.81,
      "learning_rate": 0.020750401830322583,
      "loss": 0.5457,
      "step": 491540
    },
    {
      "epoch": 792.84,
      "learning_rate": 0.02074717602709678,
      "loss": 0.554,
      "step": 491560
    },
    {
      "epoch": 792.87,
      "learning_rate": 0.02074395022387097,
      "loss": 0.5494,
      "step": 491580
    },
    {
      "epoch": 792.9,
      "learning_rate": 0.020740724420645167,
      "loss": 0.5525,
      "step": 491600
    },
    {
      "epoch": 792.94,
      "learning_rate": 0.02073749861741935,
      "loss": 0.5477,
      "step": 491620
    },
    {
      "epoch": 792.97,
      "learning_rate": 0.020734272814193544,
      "loss": 0.5478,
      "step": 491640
    },
    {
      "epoch": 793.0,
      "learning_rate": 0.02073104701096774,
      "loss": 0.5541,
      "step": 491660
    },
    {
      "epoch": 793.0,
      "eval_accuracy": {
        "accuracy": 0.7840917961127156
      },
      "eval_loss": 0.9098708629608154,
      "eval_runtime": 2.9502,
      "eval_samples_per_second": 4342.363,
      "eval_steps_per_second": 68.13,
      "step": 491660
    },
    {
      "epoch": 793.03,
      "learning_rate": 0.020727821207741932,
      "loss": 0.5492,
      "step": 491680
    },
    {
      "epoch": 793.06,
      "learning_rate": 0.020724595404516127,
      "loss": 0.543,
      "step": 491700
    },
    {
      "epoch": 793.1,
      "learning_rate": 0.02072136960129032,
      "loss": 0.5426,
      "step": 491720
    },
    {
      "epoch": 793.13,
      "learning_rate": 0.020718143798064515,
      "loss": 0.5295,
      "step": 491740
    },
    {
      "epoch": 793.16,
      "learning_rate": 0.02071491799483871,
      "loss": 0.5498,
      "step": 491760
    },
    {
      "epoch": 793.19,
      "learning_rate": 0.020711692191612903,
      "loss": 0.5427,
      "step": 491780
    },
    {
      "epoch": 793.23,
      "learning_rate": 0.0207084663883871,
      "loss": 0.5404,
      "step": 491800
    },
    {
      "epoch": 793.26,
      "learning_rate": 0.02070524058516129,
      "loss": 0.5475,
      "step": 491820
    },
    {
      "epoch": 793.29,
      "learning_rate": 0.020702014781935486,
      "loss": 0.5505,
      "step": 491840
    },
    {
      "epoch": 793.32,
      "learning_rate": 0.020698788978709682,
      "loss": 0.5479,
      "step": 491860
    },
    {
      "epoch": 793.35,
      "learning_rate": 0.020695563175483874,
      "loss": 0.5429,
      "step": 491880
    },
    {
      "epoch": 793.39,
      "learning_rate": 0.02069233737225807,
      "loss": 0.5473,
      "step": 491900
    },
    {
      "epoch": 793.42,
      "learning_rate": 0.020689111569032262,
      "loss": 0.5484,
      "step": 491920
    },
    {
      "epoch": 793.45,
      "learning_rate": 0.020685885765806447,
      "loss": 0.5483,
      "step": 491940
    },
    {
      "epoch": 793.48,
      "learning_rate": 0.02068265996258064,
      "loss": 0.5484,
      "step": 491960
    },
    {
      "epoch": 793.52,
      "learning_rate": 0.020679434159354835,
      "loss": 0.5553,
      "step": 491980
    },
    {
      "epoch": 793.55,
      "learning_rate": 0.02067620835612903,
      "loss": 0.5522,
      "step": 492000
    },
    {
      "epoch": 793.58,
      "learning_rate": 0.020672982552903223,
      "loss": 0.5534,
      "step": 492020
    },
    {
      "epoch": 793.61,
      "learning_rate": 0.02066975674967742,
      "loss": 0.5435,
      "step": 492040
    },
    {
      "epoch": 793.65,
      "learning_rate": 0.02066653094645161,
      "loss": 0.5561,
      "step": 492060
    },
    {
      "epoch": 793.68,
      "learning_rate": 0.020663305143225806,
      "loss": 0.5467,
      "step": 492080
    },
    {
      "epoch": 793.71,
      "learning_rate": 0.02066007934,
      "loss": 0.5509,
      "step": 492100
    },
    {
      "epoch": 793.74,
      "learning_rate": 0.020656853536774194,
      "loss": 0.5492,
      "step": 492120
    },
    {
      "epoch": 793.77,
      "learning_rate": 0.02065362773354839,
      "loss": 0.5564,
      "step": 492140
    },
    {
      "epoch": 793.81,
      "learning_rate": 0.02065040193032258,
      "loss": 0.5451,
      "step": 492160
    },
    {
      "epoch": 793.84,
      "learning_rate": 0.020647176127096777,
      "loss": 0.5495,
      "step": 492180
    },
    {
      "epoch": 793.87,
      "learning_rate": 0.020643950323870973,
      "loss": 0.5447,
      "step": 492200
    },
    {
      "epoch": 793.9,
      "learning_rate": 0.020640724520645165,
      "loss": 0.5414,
      "step": 492220
    },
    {
      "epoch": 793.94,
      "learning_rate": 0.02063749871741935,
      "loss": 0.556,
      "step": 492240
    },
    {
      "epoch": 793.97,
      "learning_rate": 0.020634272914193542,
      "loss": 0.5585,
      "step": 492260
    },
    {
      "epoch": 794.0,
      "learning_rate": 0.020631208401129034,
      "loss": 0.5676,
      "step": 492280
    },
    {
      "epoch": 794.0,
      "eval_accuracy": {
        "accuracy": 0.7829209273280774
      },
      "eval_loss": 0.8989245295524597,
      "eval_runtime": 2.9478,
      "eval_samples_per_second": 4345.965,
      "eval_steps_per_second": 68.187,
      "step": 492280
    },
    {
      "epoch": 794.03,
      "learning_rate": 0.02062798259790323,
      "loss": 0.5556,
      "step": 492300
    },
    {
      "epoch": 794.06,
      "learning_rate": 0.020624756794677422,
      "loss": 0.5404,
      "step": 492320
    },
    {
      "epoch": 794.1,
      "learning_rate": 0.020621530991451618,
      "loss": 0.5376,
      "step": 492340
    },
    {
      "epoch": 794.13,
      "learning_rate": 0.02061830518822581,
      "loss": 0.5373,
      "step": 492360
    },
    {
      "epoch": 794.16,
      "learning_rate": 0.020615079385000006,
      "loss": 0.5337,
      "step": 492380
    },
    {
      "epoch": 794.19,
      "learning_rate": 0.020611853581774187,
      "loss": 0.5303,
      "step": 492400
    },
    {
      "epoch": 794.23,
      "learning_rate": 0.020608627778548383,
      "loss": 0.5345,
      "step": 492420
    },
    {
      "epoch": 794.26,
      "learning_rate": 0.02060540197532258,
      "loss": 0.5476,
      "step": 492440
    },
    {
      "epoch": 794.29,
      "learning_rate": 0.02060217617209677,
      "loss": 0.5462,
      "step": 492460
    },
    {
      "epoch": 794.32,
      "learning_rate": 0.020598950368870966,
      "loss": 0.5521,
      "step": 492480
    },
    {
      "epoch": 794.35,
      "learning_rate": 0.02059572456564516,
      "loss": 0.5584,
      "step": 492500
    },
    {
      "epoch": 794.39,
      "learning_rate": 0.020592498762419354,
      "loss": 0.5479,
      "step": 492520
    },
    {
      "epoch": 794.42,
      "learning_rate": 0.02058927295919355,
      "loss": 0.5373,
      "step": 492540
    },
    {
      "epoch": 794.45,
      "learning_rate": 0.020586047155967742,
      "loss": 0.5597,
      "step": 492560
    },
    {
      "epoch": 794.48,
      "learning_rate": 0.020582821352741937,
      "loss": 0.5522,
      "step": 492580
    },
    {
      "epoch": 794.52,
      "learning_rate": 0.02057959554951613,
      "loss": 0.5502,
      "step": 492600
    },
    {
      "epoch": 794.55,
      "learning_rate": 0.020576369746290325,
      "loss": 0.5496,
      "step": 492620
    },
    {
      "epoch": 794.58,
      "learning_rate": 0.02057314394306452,
      "loss": 0.5525,
      "step": 492640
    },
    {
      "epoch": 794.61,
      "learning_rate": 0.020569918139838713,
      "loss": 0.5525,
      "step": 492660
    },
    {
      "epoch": 794.65,
      "learning_rate": 0.02056669233661291,
      "loss": 0.552,
      "step": 492680
    },
    {
      "epoch": 794.68,
      "learning_rate": 0.02056346653338709,
      "loss": 0.5495,
      "step": 492700
    },
    {
      "epoch": 794.71,
      "learning_rate": 0.020560240730161286,
      "loss": 0.5682,
      "step": 492720
    },
    {
      "epoch": 794.74,
      "learning_rate": 0.02055701492693548,
      "loss": 0.5531,
      "step": 492740
    },
    {
      "epoch": 794.77,
      "learning_rate": 0.020553789123709674,
      "loss": 0.5528,
      "step": 492760
    },
    {
      "epoch": 794.81,
      "learning_rate": 0.02055056332048387,
      "loss": 0.5543,
      "step": 492780
    },
    {
      "epoch": 794.84,
      "learning_rate": 0.02054733751725806,
      "loss": 0.5504,
      "step": 492800
    },
    {
      "epoch": 794.87,
      "learning_rate": 0.020544111714032257,
      "loss": 0.5595,
      "step": 492820
    },
    {
      "epoch": 794.9,
      "learning_rate": 0.020540885910806453,
      "loss": 0.558,
      "step": 492840
    },
    {
      "epoch": 794.94,
      "learning_rate": 0.020537660107580645,
      "loss": 0.5563,
      "step": 492860
    },
    {
      "epoch": 794.97,
      "learning_rate": 0.02053443430435484,
      "loss": 0.5567,
      "step": 492880
    },
    {
      "epoch": 795.0,
      "learning_rate": 0.020531208501129033,
      "loss": 0.5463,
      "step": 492900
    },
    {
      "epoch": 795.0,
      "eval_accuracy": {
        "accuracy": 0.7830770431660292
      },
      "eval_loss": 0.9118415117263794,
      "eval_runtime": 3.0904,
      "eval_samples_per_second": 4145.385,
      "eval_steps_per_second": 65.04,
      "step": 492900
    },
    {
      "epoch": 795.03,
      "learning_rate": 0.02052798269790323,
      "loss": 0.5556,
      "step": 492920
    },
    {
      "epoch": 795.06,
      "learning_rate": 0.020524756894677424,
      "loss": 0.5419,
      "step": 492940
    },
    {
      "epoch": 795.1,
      "learning_rate": 0.020521531091451616,
      "loss": 0.534,
      "step": 492960
    },
    {
      "epoch": 795.13,
      "learning_rate": 0.020518305288225812,
      "loss": 0.5438,
      "step": 492980
    },
    {
      "epoch": 795.16,
      "learning_rate": 0.020515079485000004,
      "loss": 0.547,
      "step": 493000
    },
    {
      "epoch": 795.19,
      "learning_rate": 0.02051185368177419,
      "loss": 0.5494,
      "step": 493020
    },
    {
      "epoch": 795.23,
      "learning_rate": 0.02050862787854838,
      "loss": 0.5347,
      "step": 493040
    },
    {
      "epoch": 795.26,
      "learning_rate": 0.020505402075322577,
      "loss": 0.5365,
      "step": 493060
    },
    {
      "epoch": 795.29,
      "learning_rate": 0.020502176272096773,
      "loss": 0.5433,
      "step": 493080
    },
    {
      "epoch": 795.32,
      "learning_rate": 0.020498950468870965,
      "loss": 0.5533,
      "step": 493100
    },
    {
      "epoch": 795.35,
      "learning_rate": 0.02049572466564516,
      "loss": 0.5477,
      "step": 493120
    },
    {
      "epoch": 795.39,
      "learning_rate": 0.020492498862419353,
      "loss": 0.5478,
      "step": 493140
    },
    {
      "epoch": 795.42,
      "learning_rate": 0.020489273059193548,
      "loss": 0.5391,
      "step": 493160
    },
    {
      "epoch": 795.45,
      "learning_rate": 0.020486047255967744,
      "loss": 0.5494,
      "step": 493180
    },
    {
      "epoch": 795.48,
      "learning_rate": 0.020482821452741936,
      "loss": 0.5447,
      "step": 493200
    },
    {
      "epoch": 795.52,
      "learning_rate": 0.02047959564951613,
      "loss": 0.5348,
      "step": 493220
    },
    {
      "epoch": 795.55,
      "learning_rate": 0.020476369846290324,
      "loss": 0.5465,
      "step": 493240
    },
    {
      "epoch": 795.58,
      "learning_rate": 0.02047314404306452,
      "loss": 0.5657,
      "step": 493260
    },
    {
      "epoch": 795.61,
      "learning_rate": 0.020469918239838715,
      "loss": 0.5542,
      "step": 493280
    },
    {
      "epoch": 795.65,
      "learning_rate": 0.020466692436612907,
      "loss": 0.558,
      "step": 493300
    },
    {
      "epoch": 795.68,
      "learning_rate": 0.020463466633387092,
      "loss": 0.5439,
      "step": 493320
    },
    {
      "epoch": 795.71,
      "learning_rate": 0.020460240830161285,
      "loss": 0.554,
      "step": 493340
    },
    {
      "epoch": 795.74,
      "learning_rate": 0.02045701502693548,
      "loss": 0.5563,
      "step": 493360
    },
    {
      "epoch": 795.77,
      "learning_rate": 0.020453789223709676,
      "loss": 0.5604,
      "step": 493380
    },
    {
      "epoch": 795.81,
      "learning_rate": 0.020450563420483868,
      "loss": 0.5384,
      "step": 493400
    },
    {
      "epoch": 795.84,
      "learning_rate": 0.020447337617258064,
      "loss": 0.5547,
      "step": 493420
    },
    {
      "epoch": 795.87,
      "learning_rate": 0.020444111814032256,
      "loss": 0.5516,
      "step": 493440
    },
    {
      "epoch": 795.9,
      "learning_rate": 0.02044088601080645,
      "loss": 0.5471,
      "step": 493460
    },
    {
      "epoch": 795.94,
      "learning_rate": 0.020437660207580647,
      "loss": 0.5573,
      "step": 493480
    },
    {
      "epoch": 795.97,
      "learning_rate": 0.02043443440435484,
      "loss": 0.5413,
      "step": 493500
    },
    {
      "epoch": 796.0,
      "learning_rate": 0.020431208601129035,
      "loss": 0.5531,
      "step": 493520
    },
    {
      "epoch": 796.0,
      "eval_accuracy": {
        "accuracy": 0.7861213020060885
      },
      "eval_loss": 0.9069930911064148,
      "eval_runtime": 3.2173,
      "eval_samples_per_second": 3981.924,
      "eval_steps_per_second": 62.475,
      "step": 493520
    },
    {
      "epoch": 796.03,
      "learning_rate": 0.020427982797903227,
      "loss": 0.5315,
      "step": 493540
    },
    {
      "epoch": 796.06,
      "learning_rate": 0.020424756994677423,
      "loss": 0.5447,
      "step": 493560
    },
    {
      "epoch": 796.1,
      "learning_rate": 0.020421531191451618,
      "loss": 0.5475,
      "step": 493580
    },
    {
      "epoch": 796.13,
      "learning_rate": 0.02041830538822581,
      "loss": 0.5383,
      "step": 493600
    },
    {
      "epoch": 796.16,
      "learning_rate": 0.020415079585000006,
      "loss": 0.5377,
      "step": 493620
    },
    {
      "epoch": 796.19,
      "learning_rate": 0.020411853781774188,
      "loss": 0.5441,
      "step": 493640
    },
    {
      "epoch": 796.23,
      "learning_rate": 0.020408627978548383,
      "loss": 0.5463,
      "step": 493660
    },
    {
      "epoch": 796.26,
      "learning_rate": 0.020405402175322575,
      "loss": 0.5466,
      "step": 493680
    },
    {
      "epoch": 796.29,
      "learning_rate": 0.02040217637209677,
      "loss": 0.544,
      "step": 493700
    },
    {
      "epoch": 796.32,
      "learning_rate": 0.020398950568870967,
      "loss": 0.5436,
      "step": 493720
    },
    {
      "epoch": 796.35,
      "learning_rate": 0.02039572476564516,
      "loss": 0.5455,
      "step": 493740
    },
    {
      "epoch": 796.39,
      "learning_rate": 0.020392498962419355,
      "loss": 0.545,
      "step": 493760
    },
    {
      "epoch": 796.42,
      "learning_rate": 0.020389273159193547,
      "loss": 0.556,
      "step": 493780
    },
    {
      "epoch": 796.45,
      "learning_rate": 0.020386047355967742,
      "loss": 0.5492,
      "step": 493800
    },
    {
      "epoch": 796.48,
      "learning_rate": 0.020382821552741938,
      "loss": 0.5496,
      "step": 493820
    },
    {
      "epoch": 796.52,
      "learning_rate": 0.02037959574951613,
      "loss": 0.5501,
      "step": 493840
    },
    {
      "epoch": 796.55,
      "learning_rate": 0.020376369946290326,
      "loss": 0.5492,
      "step": 493860
    },
    {
      "epoch": 796.58,
      "learning_rate": 0.02037314414306452,
      "loss": 0.5548,
      "step": 493880
    },
    {
      "epoch": 796.61,
      "learning_rate": 0.020369918339838713,
      "loss": 0.5497,
      "step": 493900
    },
    {
      "epoch": 796.65,
      "learning_rate": 0.02036669253661291,
      "loss": 0.5474,
      "step": 493920
    },
    {
      "epoch": 796.68,
      "learning_rate": 0.02036346673338709,
      "loss": 0.5439,
      "step": 493940
    },
    {
      "epoch": 796.71,
      "learning_rate": 0.020360240930161286,
      "loss": 0.5433,
      "step": 493960
    },
    {
      "epoch": 796.74,
      "learning_rate": 0.02035701512693548,
      "loss": 0.5364,
      "step": 493980
    },
    {
      "epoch": 796.77,
      "learning_rate": 0.020353789323709674,
      "loss": 0.5421,
      "step": 494000
    },
    {
      "epoch": 796.81,
      "learning_rate": 0.02035056352048387,
      "loss": 0.5441,
      "step": 494020
    },
    {
      "epoch": 796.84,
      "learning_rate": 0.020347337717258062,
      "loss": 0.5604,
      "step": 494040
    },
    {
      "epoch": 796.87,
      "learning_rate": 0.020344111914032258,
      "loss": 0.5571,
      "step": 494060
    },
    {
      "epoch": 796.9,
      "learning_rate": 0.02034088611080645,
      "loss": 0.5422,
      "step": 494080
    },
    {
      "epoch": 796.94,
      "learning_rate": 0.020337660307580645,
      "loss": 0.5502,
      "step": 494100
    },
    {
      "epoch": 796.97,
      "learning_rate": 0.02033443450435484,
      "loss": 0.5621,
      "step": 494120
    },
    {
      "epoch": 797.0,
      "learning_rate": 0.020331208701129033,
      "loss": 0.5463,
      "step": 494140
    },
    {
      "epoch": 797.0,
      "eval_accuracy": {
        "accuracy": 0.7847943173834986
      },
      "eval_loss": 0.9074889421463013,
      "eval_runtime": 3.0761,
      "eval_samples_per_second": 4164.751,
      "eval_steps_per_second": 65.343,
      "step": 494140
    },
    {
      "epoch": 797.03,
      "learning_rate": 0.02032798289790323,
      "loss": 0.5509,
      "step": 494160
    },
    {
      "epoch": 797.06,
      "learning_rate": 0.02032475709467742,
      "loss": 0.5503,
      "step": 494180
    },
    {
      "epoch": 797.1,
      "learning_rate": 0.020321531291451617,
      "loss": 0.5397,
      "step": 494200
    },
    {
      "epoch": 797.13,
      "learning_rate": 0.020318305488225812,
      "loss": 0.5303,
      "step": 494220
    },
    {
      "epoch": 797.16,
      "learning_rate": 0.020315079685000004,
      "loss": 0.5398,
      "step": 494240
    },
    {
      "epoch": 797.19,
      "learning_rate": 0.02031185388177419,
      "loss": 0.5483,
      "step": 494260
    },
    {
      "epoch": 797.23,
      "learning_rate": 0.020308628078548382,
      "loss": 0.5449,
      "step": 494280
    },
    {
      "epoch": 797.26,
      "learning_rate": 0.020305402275322577,
      "loss": 0.5448,
      "step": 494300
    },
    {
      "epoch": 797.29,
      "learning_rate": 0.02030217647209677,
      "loss": 0.5481,
      "step": 494320
    },
    {
      "epoch": 797.32,
      "learning_rate": 0.020298950668870965,
      "loss": 0.5498,
      "step": 494340
    },
    {
      "epoch": 797.35,
      "learning_rate": 0.02029572486564516,
      "loss": 0.547,
      "step": 494360
    },
    {
      "epoch": 797.39,
      "learning_rate": 0.020292499062419353,
      "loss": 0.5413,
      "step": 494380
    },
    {
      "epoch": 797.42,
      "learning_rate": 0.02028927325919355,
      "loss": 0.5486,
      "step": 494400
    },
    {
      "epoch": 797.45,
      "learning_rate": 0.02028604745596774,
      "loss": 0.5351,
      "step": 494420
    },
    {
      "epoch": 797.48,
      "learning_rate": 0.020282821652741936,
      "loss": 0.5386,
      "step": 494440
    },
    {
      "epoch": 797.52,
      "learning_rate": 0.020279595849516132,
      "loss": 0.5446,
      "step": 494460
    },
    {
      "epoch": 797.55,
      "learning_rate": 0.020276370046290324,
      "loss": 0.5321,
      "step": 494480
    },
    {
      "epoch": 797.58,
      "learning_rate": 0.02027314424306452,
      "loss": 0.5434,
      "step": 494500
    },
    {
      "epoch": 797.61,
      "learning_rate": 0.020269918439838715,
      "loss": 0.5627,
      "step": 494520
    },
    {
      "epoch": 797.65,
      "learning_rate": 0.020266692636612908,
      "loss": 0.5412,
      "step": 494540
    },
    {
      "epoch": 797.68,
      "learning_rate": 0.020263466833387093,
      "loss": 0.5556,
      "step": 494560
    },
    {
      "epoch": 797.71,
      "learning_rate": 0.020260241030161285,
      "loss": 0.5621,
      "step": 494580
    },
    {
      "epoch": 797.74,
      "learning_rate": 0.02025701522693548,
      "loss": 0.5561,
      "step": 494600
    },
    {
      "epoch": 797.77,
      "learning_rate": 0.020253789423709673,
      "loss": 0.5546,
      "step": 494620
    },
    {
      "epoch": 797.81,
      "learning_rate": 0.02025056362048387,
      "loss": 0.5479,
      "step": 494640
    },
    {
      "epoch": 797.84,
      "learning_rate": 0.020247337817258064,
      "loss": 0.5494,
      "step": 494660
    },
    {
      "epoch": 797.87,
      "learning_rate": 0.020244112014032256,
      "loss": 0.5384,
      "step": 494680
    },
    {
      "epoch": 797.9,
      "learning_rate": 0.020240886210806452,
      "loss": 0.5443,
      "step": 494700
    },
    {
      "epoch": 797.94,
      "learning_rate": 0.020237660407580644,
      "loss": 0.5376,
      "step": 494720
    },
    {
      "epoch": 797.97,
      "learning_rate": 0.02023443460435484,
      "loss": 0.5531,
      "step": 494740
    },
    {
      "epoch": 798.0,
      "learning_rate": 0.020231370091290318,
      "loss": 0.5507,
      "step": 494760
    },
    {
      "epoch": 798.0,
      "eval_accuracy": {
        "accuracy": 0.7780813363515728
      },
      "eval_loss": 0.912996232509613,
      "eval_runtime": 3.3909,
      "eval_samples_per_second": 3778.039,
      "eval_steps_per_second": 59.276,
      "step": 494760
    },
    {
      "epoch": 798.03,
      "learning_rate": 0.020228144288064513,
      "loss": 0.5412,
      "step": 494780
    },
    {
      "epoch": 798.06,
      "learning_rate": 0.02022491848483871,
      "loss": 0.5352,
      "step": 494800
    },
    {
      "epoch": 798.1,
      "learning_rate": 0.0202216926816129,
      "loss": 0.543,
      "step": 494820
    },
    {
      "epoch": 798.13,
      "learning_rate": 0.020218466878387097,
      "loss": 0.5499,
      "step": 494840
    },
    {
      "epoch": 798.16,
      "learning_rate": 0.02021524107516129,
      "loss": 0.5369,
      "step": 494860
    },
    {
      "epoch": 798.19,
      "learning_rate": 0.020212015271935484,
      "loss": 0.5415,
      "step": 494880
    },
    {
      "epoch": 798.23,
      "learning_rate": 0.02020878946870968,
      "loss": 0.5396,
      "step": 494900
    },
    {
      "epoch": 798.26,
      "learning_rate": 0.020205563665483872,
      "loss": 0.5383,
      "step": 494920
    },
    {
      "epoch": 798.29,
      "learning_rate": 0.020202337862258068,
      "loss": 0.5383,
      "step": 494940
    },
    {
      "epoch": 798.32,
      "learning_rate": 0.020199112059032263,
      "loss": 0.5495,
      "step": 494960
    },
    {
      "epoch": 798.35,
      "learning_rate": 0.020195886255806456,
      "loss": 0.538,
      "step": 494980
    },
    {
      "epoch": 798.39,
      "learning_rate": 0.02019266045258065,
      "loss": 0.5422,
      "step": 495000
    },
    {
      "epoch": 798.42,
      "learning_rate": 0.020189434649354833,
      "loss": 0.5405,
      "step": 495020
    },
    {
      "epoch": 798.45,
      "learning_rate": 0.02018620884612903,
      "loss": 0.5567,
      "step": 495040
    },
    {
      "epoch": 798.48,
      "learning_rate": 0.02018298304290322,
      "loss": 0.5497,
      "step": 495060
    },
    {
      "epoch": 798.52,
      "learning_rate": 0.020179757239677416,
      "loss": 0.5518,
      "step": 495080
    },
    {
      "epoch": 798.55,
      "learning_rate": 0.020176531436451612,
      "loss": 0.5532,
      "step": 495100
    },
    {
      "epoch": 798.58,
      "learning_rate": 0.020173305633225804,
      "loss": 0.5503,
      "step": 495120
    },
    {
      "epoch": 798.61,
      "learning_rate": 0.02017007983,
      "loss": 0.5569,
      "step": 495140
    },
    {
      "epoch": 798.65,
      "learning_rate": 0.020166854026774192,
      "loss": 0.5447,
      "step": 495160
    },
    {
      "epoch": 798.68,
      "learning_rate": 0.020163628223548388,
      "loss": 0.5512,
      "step": 495180
    },
    {
      "epoch": 798.71,
      "learning_rate": 0.020160402420322583,
      "loss": 0.551,
      "step": 495200
    },
    {
      "epoch": 798.74,
      "learning_rate": 0.020157176617096775,
      "loss": 0.5351,
      "step": 495220
    },
    {
      "epoch": 798.77,
      "learning_rate": 0.02015395081387097,
      "loss": 0.544,
      "step": 495240
    },
    {
      "epoch": 798.81,
      "learning_rate": 0.020150725010645163,
      "loss": 0.5541,
      "step": 495260
    },
    {
      "epoch": 798.84,
      "learning_rate": 0.02014749920741936,
      "loss": 0.5546,
      "step": 495280
    },
    {
      "epoch": 798.87,
      "learning_rate": 0.020144273404193554,
      "loss": 0.5374,
      "step": 495300
    },
    {
      "epoch": 798.9,
      "learning_rate": 0.020141047600967747,
      "loss": 0.5507,
      "step": 495320
    },
    {
      "epoch": 798.94,
      "learning_rate": 0.02013782179774193,
      "loss": 0.5501,
      "step": 495340
    },
    {
      "epoch": 798.97,
      "learning_rate": 0.020134595994516124,
      "loss": 0.5454,
      "step": 495360
    },
    {
      "epoch": 799.0,
      "learning_rate": 0.02013137019129032,
      "loss": 0.5454,
      "step": 495380
    },
    {
      "epoch": 799.0,
      "eval_accuracy": {
        "accuracy": 0.7808914214347046
      },
      "eval_loss": 0.9138368368148804,
      "eval_runtime": 2.9305,
      "eval_samples_per_second": 4371.639,
      "eval_steps_per_second": 68.589,
      "step": 495380
    },
    {
      "epoch": 799.03,
      "learning_rate": 0.02012814438806451,
      "loss": 0.5606,
      "step": 495400
    },
    {
      "epoch": 799.06,
      "learning_rate": 0.020124918584838707,
      "loss": 0.55,
      "step": 495420
    },
    {
      "epoch": 799.1,
      "learning_rate": 0.020121692781612903,
      "loss": 0.5372,
      "step": 495440
    },
    {
      "epoch": 799.13,
      "learning_rate": 0.020118466978387095,
      "loss": 0.5409,
      "step": 495460
    },
    {
      "epoch": 799.16,
      "learning_rate": 0.02011524117516129,
      "loss": 0.5418,
      "step": 495480
    },
    {
      "epoch": 799.19,
      "learning_rate": 0.020112015371935486,
      "loss": 0.5416,
      "step": 495500
    },
    {
      "epoch": 799.23,
      "learning_rate": 0.02010878956870968,
      "loss": 0.5362,
      "step": 495520
    },
    {
      "epoch": 799.26,
      "learning_rate": 0.020105563765483874,
      "loss": 0.5485,
      "step": 495540
    },
    {
      "epoch": 799.29,
      "learning_rate": 0.020102337962258066,
      "loss": 0.5416,
      "step": 495560
    },
    {
      "epoch": 799.32,
      "learning_rate": 0.020099112159032262,
      "loss": 0.5546,
      "step": 495580
    },
    {
      "epoch": 799.35,
      "learning_rate": 0.020095886355806458,
      "loss": 0.5496,
      "step": 495600
    },
    {
      "epoch": 799.39,
      "learning_rate": 0.02009266055258065,
      "loss": 0.5491,
      "step": 495620
    },
    {
      "epoch": 799.42,
      "learning_rate": 0.020089434749354835,
      "loss": 0.5509,
      "step": 495640
    },
    {
      "epoch": 799.45,
      "learning_rate": 0.020086208946129027,
      "loss": 0.5383,
      "step": 495660
    },
    {
      "epoch": 799.48,
      "learning_rate": 0.020082983142903223,
      "loss": 0.552,
      "step": 495680
    },
    {
      "epoch": 799.52,
      "learning_rate": 0.020079757339677415,
      "loss": 0.5356,
      "step": 495700
    },
    {
      "epoch": 799.55,
      "learning_rate": 0.02007653153645161,
      "loss": 0.5558,
      "step": 495720
    },
    {
      "epoch": 799.58,
      "learning_rate": 0.020073305733225806,
      "loss": 0.5561,
      "step": 495740
    },
    {
      "epoch": 799.61,
      "learning_rate": 0.020070079929999998,
      "loss": 0.5412,
      "step": 495760
    },
    {
      "epoch": 799.65,
      "learning_rate": 0.020066854126774194,
      "loss": 0.5493,
      "step": 495780
    },
    {
      "epoch": 799.68,
      "learning_rate": 0.020063628323548386,
      "loss": 0.5418,
      "step": 495800
    },
    {
      "epoch": 799.71,
      "learning_rate": 0.02006040252032258,
      "loss": 0.5478,
      "step": 495820
    },
    {
      "epoch": 799.74,
      "learning_rate": 0.020057176717096777,
      "loss": 0.5471,
      "step": 495840
    },
    {
      "epoch": 799.77,
      "learning_rate": 0.02005395091387097,
      "loss": 0.5466,
      "step": 495860
    },
    {
      "epoch": 799.81,
      "learning_rate": 0.020050725110645165,
      "loss": 0.5403,
      "step": 495880
    },
    {
      "epoch": 799.84,
      "learning_rate": 0.020047499307419357,
      "loss": 0.5479,
      "step": 495900
    },
    {
      "epoch": 799.87,
      "learning_rate": 0.020044273504193553,
      "loss": 0.5363,
      "step": 495920
    },
    {
      "epoch": 799.9,
      "learning_rate": 0.02004104770096775,
      "loss": 0.5378,
      "step": 495940
    },
    {
      "epoch": 799.94,
      "learning_rate": 0.02003782189774193,
      "loss": 0.5425,
      "step": 495960
    },
    {
      "epoch": 799.97,
      "learning_rate": 0.020034596094516126,
      "loss": 0.5417,
      "step": 495980
    },
    {
      "epoch": 800.0,
      "learning_rate": 0.020031370291290318,
      "loss": 0.5549,
      "step": 496000
    },
    {
      "epoch": 800.0,
      "eval_accuracy": {
        "accuracy": 0.7820622902193427
      },
      "eval_loss": 0.9110062122344971,
      "eval_runtime": 3.1324,
      "eval_samples_per_second": 4089.788,
      "eval_steps_per_second": 64.167,
      "step": 496000
    },
    {
      "epoch": 800.03,
      "learning_rate": 0.020028144488064514,
      "loss": 0.5465,
      "step": 496020
    },
    {
      "epoch": 800.06,
      "learning_rate": 0.020024918684838706,
      "loss": 0.5323,
      "step": 496040
    },
    {
      "epoch": 800.1,
      "learning_rate": 0.0200216928816129,
      "loss": 0.5455,
      "step": 496060
    },
    {
      "epoch": 800.13,
      "learning_rate": 0.020018467078387097,
      "loss": 0.5434,
      "step": 496080
    },
    {
      "epoch": 800.16,
      "learning_rate": 0.02001524127516129,
      "loss": 0.5345,
      "step": 496100
    },
    {
      "epoch": 800.19,
      "learning_rate": 0.020012015471935485,
      "loss": 0.5347,
      "step": 496120
    },
    {
      "epoch": 800.23,
      "learning_rate": 0.02000878966870968,
      "loss": 0.5388,
      "step": 496140
    },
    {
      "epoch": 800.26,
      "learning_rate": 0.020005563865483873,
      "loss": 0.5221,
      "step": 496160
    },
    {
      "epoch": 800.29,
      "learning_rate": 0.020002338062258068,
      "loss": 0.5452,
      "step": 496180
    },
    {
      "epoch": 800.32,
      "learning_rate": 0.01999911225903226,
      "loss": 0.539,
      "step": 496200
    },
    {
      "epoch": 800.35,
      "learning_rate": 0.019995886455806456,
      "loss": 0.5361,
      "step": 496220
    },
    {
      "epoch": 800.39,
      "learning_rate": 0.01999266065258065,
      "loss": 0.5432,
      "step": 496240
    },
    {
      "epoch": 800.42,
      "learning_rate": 0.019989434849354833,
      "loss": 0.5429,
      "step": 496260
    },
    {
      "epoch": 800.45,
      "learning_rate": 0.01998620904612903,
      "loss": 0.5308,
      "step": 496280
    },
    {
      "epoch": 800.48,
      "learning_rate": 0.01998298324290322,
      "loss": 0.5499,
      "step": 496300
    },
    {
      "epoch": 800.52,
      "learning_rate": 0.019979757439677417,
      "loss": 0.5554,
      "step": 496320
    },
    {
      "epoch": 800.55,
      "learning_rate": 0.01997653163645161,
      "loss": 0.5318,
      "step": 496340
    },
    {
      "epoch": 800.58,
      "learning_rate": 0.019973305833225805,
      "loss": 0.5514,
      "step": 496360
    },
    {
      "epoch": 800.61,
      "learning_rate": 0.01997008003,
      "loss": 0.5518,
      "step": 496380
    },
    {
      "epoch": 800.65,
      "learning_rate": 0.019966854226774192,
      "loss": 0.5518,
      "step": 496400
    },
    {
      "epoch": 800.68,
      "learning_rate": 0.019963628423548388,
      "loss": 0.548,
      "step": 496420
    },
    {
      "epoch": 800.71,
      "learning_rate": 0.01996040262032258,
      "loss": 0.5571,
      "step": 496440
    },
    {
      "epoch": 800.74,
      "learning_rate": 0.019957176817096776,
      "loss": 0.5514,
      "step": 496460
    },
    {
      "epoch": 800.77,
      "learning_rate": 0.01995395101387097,
      "loss": 0.5625,
      "step": 496480
    },
    {
      "epoch": 800.81,
      "learning_rate": 0.019950725210645164,
      "loss": 0.5577,
      "step": 496500
    },
    {
      "epoch": 800.84,
      "learning_rate": 0.01994749940741936,
      "loss": 0.5482,
      "step": 496520
    },
    {
      "epoch": 800.87,
      "learning_rate": 0.01994427360419355,
      "loss": 0.5432,
      "step": 496540
    },
    {
      "epoch": 800.9,
      "learning_rate": 0.019941047800967747,
      "loss": 0.5515,
      "step": 496560
    },
    {
      "epoch": 800.94,
      "learning_rate": 0.01993782199774193,
      "loss": 0.5436,
      "step": 496580
    },
    {
      "epoch": 800.97,
      "learning_rate": 0.019934596194516124,
      "loss": 0.5474,
      "step": 496600
    },
    {
      "epoch": 801.0,
      "learning_rate": 0.01993137039129032,
      "loss": 0.5489,
      "step": 496620
    },
    {
      "epoch": 801.0,
      "eval_accuracy": {
        "accuracy": 0.7819842323003668
      },
      "eval_loss": 0.9094647169113159,
      "eval_runtime": 3.0917,
      "eval_samples_per_second": 4143.615,
      "eval_steps_per_second": 65.012,
      "step": 496620
    },
    {
      "epoch": 801.03,
      "learning_rate": 0.019928144588064512,
      "loss": 0.536,
      "step": 496640
    },
    {
      "epoch": 801.06,
      "learning_rate": 0.019924918784838708,
      "loss": 0.5472,
      "step": 496660
    },
    {
      "epoch": 801.1,
      "learning_rate": 0.019921692981612903,
      "loss": 0.5436,
      "step": 496680
    },
    {
      "epoch": 801.13,
      "learning_rate": 0.019918467178387095,
      "loss": 0.5468,
      "step": 496700
    },
    {
      "epoch": 801.16,
      "learning_rate": 0.01991524137516129,
      "loss": 0.5539,
      "step": 496720
    },
    {
      "epoch": 801.19,
      "learning_rate": 0.019912015571935483,
      "loss": 0.5444,
      "step": 496740
    },
    {
      "epoch": 801.23,
      "learning_rate": 0.01990878976870968,
      "loss": 0.5396,
      "step": 496760
    },
    {
      "epoch": 801.26,
      "learning_rate": 0.019905563965483875,
      "loss": 0.5315,
      "step": 496780
    },
    {
      "epoch": 801.29,
      "learning_rate": 0.019902338162258067,
      "loss": 0.5262,
      "step": 496800
    },
    {
      "epoch": 801.32,
      "learning_rate": 0.019899112359032262,
      "loss": 0.5433,
      "step": 496820
    },
    {
      "epoch": 801.35,
      "learning_rate": 0.019895886555806454,
      "loss": 0.5388,
      "step": 496840
    },
    {
      "epoch": 801.39,
      "learning_rate": 0.01989266075258065,
      "loss": 0.532,
      "step": 496860
    },
    {
      "epoch": 801.42,
      "learning_rate": 0.019889434949354832,
      "loss": 0.5408,
      "step": 496880
    },
    {
      "epoch": 801.45,
      "learning_rate": 0.019886209146129027,
      "loss": 0.5499,
      "step": 496900
    },
    {
      "epoch": 801.48,
      "learning_rate": 0.019882983342903223,
      "loss": 0.5422,
      "step": 496920
    },
    {
      "epoch": 801.52,
      "learning_rate": 0.019879757539677415,
      "loss": 0.5424,
      "step": 496940
    },
    {
      "epoch": 801.55,
      "learning_rate": 0.01987653173645161,
      "loss": 0.5481,
      "step": 496960
    },
    {
      "epoch": 801.58,
      "learning_rate": 0.019873305933225803,
      "loss": 0.5385,
      "step": 496980
    },
    {
      "epoch": 801.61,
      "learning_rate": 0.01987008013,
      "loss": 0.5518,
      "step": 497000
    },
    {
      "epoch": 801.65,
      "learning_rate": 0.019866854326774194,
      "loss": 0.5517,
      "step": 497020
    },
    {
      "epoch": 801.68,
      "learning_rate": 0.019863628523548386,
      "loss": 0.5516,
      "step": 497040
    },
    {
      "epoch": 801.71,
      "learning_rate": 0.019860402720322582,
      "loss": 0.5493,
      "step": 497060
    },
    {
      "epoch": 801.74,
      "learning_rate": 0.019857176917096774,
      "loss": 0.5515,
      "step": 497080
    },
    {
      "epoch": 801.77,
      "learning_rate": 0.01985395111387097,
      "loss": 0.5443,
      "step": 497100
    },
    {
      "epoch": 801.81,
      "learning_rate": 0.019850725310645165,
      "loss": 0.5448,
      "step": 497120
    },
    {
      "epoch": 801.84,
      "learning_rate": 0.019847499507419358,
      "loss": 0.5428,
      "step": 497140
    },
    {
      "epoch": 801.87,
      "learning_rate": 0.019844273704193553,
      "loss": 0.5547,
      "step": 497160
    },
    {
      "epoch": 801.9,
      "learning_rate": 0.019841047900967745,
      "loss": 0.5506,
      "step": 497180
    },
    {
      "epoch": 801.94,
      "learning_rate": 0.01983782209774193,
      "loss": 0.554,
      "step": 497200
    },
    {
      "epoch": 801.97,
      "learning_rate": 0.019834596294516123,
      "loss": 0.5419,
      "step": 497220
    },
    {
      "epoch": 802.0,
      "learning_rate": 0.019831531781451615,
      "loss": 0.5621,
      "step": 497240
    },
    {
      "epoch": 802.0,
      "eval_accuracy": {
        "accuracy": 0.7843259698696433
      },
      "eval_loss": 0.90671706199646,
      "eval_runtime": 3.0108,
      "eval_samples_per_second": 4255.06,
      "eval_steps_per_second": 66.76,
      "step": 497240
    },
    {
      "epoch": 802.03,
      "learning_rate": 0.01982830597822581,
      "loss": 0.5406,
      "step": 497260
    },
    {
      "epoch": 802.06,
      "learning_rate": 0.019825080175000002,
      "loss": 0.5326,
      "step": 497280
    },
    {
      "epoch": 802.1,
      "learning_rate": 0.019821854371774198,
      "loss": 0.5465,
      "step": 497300
    },
    {
      "epoch": 802.13,
      "learning_rate": 0.019818628568548394,
      "loss": 0.5358,
      "step": 497320
    },
    {
      "epoch": 802.16,
      "learning_rate": 0.019815402765322575,
      "loss": 0.5467,
      "step": 497340
    },
    {
      "epoch": 802.19,
      "learning_rate": 0.01981217696209677,
      "loss": 0.5434,
      "step": 497360
    },
    {
      "epoch": 802.23,
      "learning_rate": 0.019808951158870963,
      "loss": 0.5468,
      "step": 497380
    },
    {
      "epoch": 802.26,
      "learning_rate": 0.01980572535564516,
      "loss": 0.5473,
      "step": 497400
    },
    {
      "epoch": 802.29,
      "learning_rate": 0.01980249955241935,
      "loss": 0.5462,
      "step": 497420
    },
    {
      "epoch": 802.32,
      "learning_rate": 0.019799273749193547,
      "loss": 0.5456,
      "step": 497440
    },
    {
      "epoch": 802.35,
      "learning_rate": 0.019796047945967742,
      "loss": 0.5462,
      "step": 497460
    },
    {
      "epoch": 802.39,
      "learning_rate": 0.019792822142741934,
      "loss": 0.5465,
      "step": 497480
    },
    {
      "epoch": 802.42,
      "learning_rate": 0.01978959633951613,
      "loss": 0.5474,
      "step": 497500
    },
    {
      "epoch": 802.45,
      "learning_rate": 0.019786370536290322,
      "loss": 0.5394,
      "step": 497520
    },
    {
      "epoch": 802.48,
      "learning_rate": 0.019783144733064518,
      "loss": 0.5445,
      "step": 497540
    },
    {
      "epoch": 802.52,
      "learning_rate": 0.019779918929838713,
      "loss": 0.5362,
      "step": 497560
    },
    {
      "epoch": 802.55,
      "learning_rate": 0.019776693126612906,
      "loss": 0.5421,
      "step": 497580
    },
    {
      "epoch": 802.58,
      "learning_rate": 0.0197734673233871,
      "loss": 0.5442,
      "step": 497600
    },
    {
      "epoch": 802.61,
      "learning_rate": 0.019770241520161293,
      "loss": 0.5412,
      "step": 497620
    },
    {
      "epoch": 802.65,
      "learning_rate": 0.01976701571693549,
      "loss": 0.5357,
      "step": 497640
    },
    {
      "epoch": 802.68,
      "learning_rate": 0.01976378991370967,
      "loss": 0.5488,
      "step": 497660
    },
    {
      "epoch": 802.71,
      "learning_rate": 0.019760564110483866,
      "loss": 0.5373,
      "step": 497680
    },
    {
      "epoch": 802.74,
      "learning_rate": 0.019757338307258062,
      "loss": 0.5497,
      "step": 497700
    },
    {
      "epoch": 802.77,
      "learning_rate": 0.019754112504032254,
      "loss": 0.5486,
      "step": 497720
    },
    {
      "epoch": 802.81,
      "learning_rate": 0.01975088670080645,
      "loss": 0.5448,
      "step": 497740
    },
    {
      "epoch": 802.84,
      "learning_rate": 0.019747660897580645,
      "loss": 0.5488,
      "step": 497760
    },
    {
      "epoch": 802.87,
      "learning_rate": 0.019744435094354838,
      "loss": 0.553,
      "step": 497780
    },
    {
      "epoch": 802.9,
      "learning_rate": 0.019741209291129033,
      "loss": 0.5472,
      "step": 497800
    },
    {
      "epoch": 802.94,
      "learning_rate": 0.019737983487903225,
      "loss": 0.5448,
      "step": 497820
    },
    {
      "epoch": 802.97,
      "learning_rate": 0.01973475768467742,
      "loss": 0.5449,
      "step": 497840
    },
    {
      "epoch": 803.0,
      "learning_rate": 0.019731531881451617,
      "loss": 0.552,
      "step": 497860
    },
    {
      "epoch": 803.0,
      "eval_accuracy": {
        "accuracy": 0.7839356802747639
      },
      "eval_loss": 0.9117410182952881,
      "eval_runtime": 4.2733,
      "eval_samples_per_second": 2997.936,
      "eval_steps_per_second": 47.037,
      "step": 497860
    },
    {
      "epoch": 803.03,
      "learning_rate": 0.01972830607822581,
      "loss": 0.5478,
      "step": 497880
    },
    {
      "epoch": 803.06,
      "learning_rate": 0.019725080275000004,
      "loss": 0.54,
      "step": 497900
    },
    {
      "epoch": 803.1,
      "learning_rate": 0.019721854471774197,
      "loss": 0.5363,
      "step": 497920
    },
    {
      "epoch": 803.13,
      "learning_rate": 0.019718628668548392,
      "loss": 0.5535,
      "step": 497940
    },
    {
      "epoch": 803.16,
      "learning_rate": 0.019715402865322574,
      "loss": 0.5396,
      "step": 497960
    },
    {
      "epoch": 803.19,
      "learning_rate": 0.01971217706209677,
      "loss": 0.5538,
      "step": 497980
    },
    {
      "epoch": 803.23,
      "learning_rate": 0.019708951258870965,
      "loss": 0.539,
      "step": 498000
    },
    {
      "epoch": 803.26,
      "learning_rate": 0.019705725455645157,
      "loss": 0.5447,
      "step": 498020
    },
    {
      "epoch": 803.29,
      "learning_rate": 0.019702499652419353,
      "loss": 0.5458,
      "step": 498040
    },
    {
      "epoch": 803.32,
      "learning_rate": 0.019699273849193545,
      "loss": 0.528,
      "step": 498060
    },
    {
      "epoch": 803.35,
      "learning_rate": 0.01969604804596774,
      "loss": 0.5398,
      "step": 498080
    },
    {
      "epoch": 803.39,
      "learning_rate": 0.019692822242741936,
      "loss": 0.5369,
      "step": 498100
    },
    {
      "epoch": 803.42,
      "learning_rate": 0.01968959643951613,
      "loss": 0.5366,
      "step": 498120
    },
    {
      "epoch": 803.45,
      "learning_rate": 0.019686370636290324,
      "loss": 0.5388,
      "step": 498140
    },
    {
      "epoch": 803.48,
      "learning_rate": 0.019683144833064516,
      "loss": 0.5417,
      "step": 498160
    },
    {
      "epoch": 803.52,
      "learning_rate": 0.019679919029838712,
      "loss": 0.5446,
      "step": 498180
    },
    {
      "epoch": 803.55,
      "learning_rate": 0.019676693226612908,
      "loss": 0.5501,
      "step": 498200
    },
    {
      "epoch": 803.58,
      "learning_rate": 0.0196734674233871,
      "loss": 0.5397,
      "step": 498220
    },
    {
      "epoch": 803.61,
      "learning_rate": 0.019670241620161295,
      "loss": 0.5523,
      "step": 498240
    },
    {
      "epoch": 803.65,
      "learning_rate": 0.019667015816935488,
      "loss": 0.5467,
      "step": 498260
    },
    {
      "epoch": 803.68,
      "learning_rate": 0.019663790013709673,
      "loss": 0.5396,
      "step": 498280
    },
    {
      "epoch": 803.71,
      "learning_rate": 0.019660564210483865,
      "loss": 0.5467,
      "step": 498300
    },
    {
      "epoch": 803.74,
      "learning_rate": 0.01965733840725806,
      "loss": 0.5317,
      "step": 498320
    },
    {
      "epoch": 803.77,
      "learning_rate": 0.019654112604032256,
      "loss": 0.5571,
      "step": 498340
    },
    {
      "epoch": 803.81,
      "learning_rate": 0.01965088680080645,
      "loss": 0.552,
      "step": 498360
    },
    {
      "epoch": 803.84,
      "learning_rate": 0.019647660997580644,
      "loss": 0.5566,
      "step": 498380
    },
    {
      "epoch": 803.87,
      "learning_rate": 0.01964443519435484,
      "loss": 0.5575,
      "step": 498400
    },
    {
      "epoch": 803.9,
      "learning_rate": 0.01964120939112903,
      "loss": 0.5546,
      "step": 498420
    },
    {
      "epoch": 803.94,
      "learning_rate": 0.019637983587903227,
      "loss": 0.5501,
      "step": 498440
    },
    {
      "epoch": 803.97,
      "learning_rate": 0.01963475778467742,
      "loss": 0.5366,
      "step": 498460
    },
    {
      "epoch": 804.0,
      "learning_rate": 0.019631531981451615,
      "loss": 0.548,
      "step": 498480
    },
    {
      "epoch": 804.0,
      "eval_accuracy": {
        "accuracy": 0.783857622355788
      },
      "eval_loss": 0.9069665670394897,
      "eval_runtime": 3.3194,
      "eval_samples_per_second": 3859.489,
      "eval_steps_per_second": 60.554,
      "step": 498480
    },
    {
      "epoch": 804.03,
      "learning_rate": 0.01962830617822581,
      "loss": 0.5354,
      "step": 498500
    },
    {
      "epoch": 804.06,
      "learning_rate": 0.019625080375000003,
      "loss": 0.5407,
      "step": 498520
    },
    {
      "epoch": 804.1,
      "learning_rate": 0.0196218545717742,
      "loss": 0.5378,
      "step": 498540
    },
    {
      "epoch": 804.13,
      "learning_rate": 0.01961862876854839,
      "loss": 0.5417,
      "step": 498560
    },
    {
      "epoch": 804.16,
      "learning_rate": 0.019615402965322576,
      "loss": 0.5219,
      "step": 498580
    },
    {
      "epoch": 804.19,
      "learning_rate": 0.019612177162096768,
      "loss": 0.5374,
      "step": 498600
    },
    {
      "epoch": 804.23,
      "learning_rate": 0.019608951358870964,
      "loss": 0.5414,
      "step": 498620
    },
    {
      "epoch": 804.26,
      "learning_rate": 0.01960572555564516,
      "loss": 0.5357,
      "step": 498640
    },
    {
      "epoch": 804.29,
      "learning_rate": 0.01960249975241935,
      "loss": 0.552,
      "step": 498660
    },
    {
      "epoch": 804.32,
      "learning_rate": 0.019599273949193547,
      "loss": 0.5513,
      "step": 498680
    },
    {
      "epoch": 804.35,
      "learning_rate": 0.01959604814596774,
      "loss": 0.5523,
      "step": 498700
    },
    {
      "epoch": 804.39,
      "learning_rate": 0.019592822342741935,
      "loss": 0.5499,
      "step": 498720
    },
    {
      "epoch": 804.42,
      "learning_rate": 0.01958959653951613,
      "loss": 0.5364,
      "step": 498740
    },
    {
      "epoch": 804.45,
      "learning_rate": 0.019586370736290323,
      "loss": 0.5417,
      "step": 498760
    },
    {
      "epoch": 804.48,
      "learning_rate": 0.019583144933064518,
      "loss": 0.5426,
      "step": 498780
    },
    {
      "epoch": 804.52,
      "learning_rate": 0.01957991912983871,
      "loss": 0.5514,
      "step": 498800
    },
    {
      "epoch": 804.55,
      "learning_rate": 0.019576693326612906,
      "loss": 0.5486,
      "step": 498820
    },
    {
      "epoch": 804.58,
      "learning_rate": 0.0195734675233871,
      "loss": 0.551,
      "step": 498840
    },
    {
      "epoch": 804.61,
      "learning_rate": 0.019570241720161294,
      "loss": 0.5356,
      "step": 498860
    },
    {
      "epoch": 804.65,
      "learning_rate": 0.01956701591693549,
      "loss": 0.5325,
      "step": 498880
    },
    {
      "epoch": 804.68,
      "learning_rate": 0.01956379011370967,
      "loss": 0.5387,
      "step": 498900
    },
    {
      "epoch": 804.71,
      "learning_rate": 0.019560564310483867,
      "loss": 0.5462,
      "step": 498920
    },
    {
      "epoch": 804.74,
      "learning_rate": 0.019557338507258062,
      "loss": 0.5405,
      "step": 498940
    },
    {
      "epoch": 804.77,
      "learning_rate": 0.019554112704032255,
      "loss": 0.5452,
      "step": 498960
    },
    {
      "epoch": 804.81,
      "learning_rate": 0.01955088690080645,
      "loss": 0.5396,
      "step": 498980
    },
    {
      "epoch": 804.84,
      "learning_rate": 0.019547661097580642,
      "loss": 0.5419,
      "step": 499000
    },
    {
      "epoch": 804.87,
      "learning_rate": 0.019544435294354838,
      "loss": 0.5494,
      "step": 499020
    },
    {
      "epoch": 804.9,
      "learning_rate": 0.019541209491129034,
      "loss": 0.5472,
      "step": 499040
    },
    {
      "epoch": 804.94,
      "learning_rate": 0.019537983687903226,
      "loss": 0.5379,
      "step": 499060
    },
    {
      "epoch": 804.97,
      "learning_rate": 0.01953475788467742,
      "loss": 0.5434,
      "step": 499080
    },
    {
      "epoch": 805.0,
      "learning_rate": 0.019531532081451614,
      "loss": 0.5457,
      "step": 499100
    },
    {
      "epoch": 805.0,
      "eval_accuracy": {
        "accuracy": 0.7842479119506673
      },
      "eval_loss": 0.9036972522735596,
      "eval_runtime": 3.0839,
      "eval_samples_per_second": 4154.167,
      "eval_steps_per_second": 65.177,
      "step": 499100
    },
    {
      "epoch": 805.03,
      "learning_rate": 0.01952830627822581,
      "loss": 0.5526,
      "step": 499120
    },
    {
      "epoch": 805.06,
      "learning_rate": 0.019525080475000005,
      "loss": 0.5416,
      "step": 499140
    },
    {
      "epoch": 805.1,
      "learning_rate": 0.019521854671774197,
      "loss": 0.532,
      "step": 499160
    },
    {
      "epoch": 805.13,
      "learning_rate": 0.019518628868548393,
      "loss": 0.5326,
      "step": 499180
    },
    {
      "epoch": 805.16,
      "learning_rate": 0.019515403065322574,
      "loss": 0.5378,
      "step": 499200
    },
    {
      "epoch": 805.19,
      "learning_rate": 0.01951217726209677,
      "loss": 0.5421,
      "step": 499220
    },
    {
      "epoch": 805.23,
      "learning_rate": 0.019508951458870962,
      "loss": 0.5528,
      "step": 499240
    },
    {
      "epoch": 805.26,
      "learning_rate": 0.019505725655645158,
      "loss": 0.5416,
      "step": 499260
    },
    {
      "epoch": 805.29,
      "learning_rate": 0.019502499852419353,
      "loss": 0.5296,
      "step": 499280
    },
    {
      "epoch": 805.32,
      "learning_rate": 0.019499274049193546,
      "loss": 0.5461,
      "step": 499300
    },
    {
      "epoch": 805.35,
      "learning_rate": 0.01949604824596774,
      "loss": 0.5338,
      "step": 499320
    },
    {
      "epoch": 805.39,
      "learning_rate": 0.019492822442741933,
      "loss": 0.5282,
      "step": 499340
    },
    {
      "epoch": 805.42,
      "learning_rate": 0.01948959663951613,
      "loss": 0.5393,
      "step": 499360
    },
    {
      "epoch": 805.45,
      "learning_rate": 0.019486370836290325,
      "loss": 0.5496,
      "step": 499380
    },
    {
      "epoch": 805.48,
      "learning_rate": 0.019483145033064517,
      "loss": 0.5435,
      "step": 499400
    },
    {
      "epoch": 805.52,
      "learning_rate": 0.019479919229838712,
      "loss": 0.5554,
      "step": 499420
    },
    {
      "epoch": 805.55,
      "learning_rate": 0.019476693426612905,
      "loss": 0.5408,
      "step": 499440
    },
    {
      "epoch": 805.58,
      "learning_rate": 0.0194734676233871,
      "loss": 0.5363,
      "step": 499460
    },
    {
      "epoch": 805.61,
      "learning_rate": 0.019470241820161296,
      "loss": 0.5391,
      "step": 499480
    },
    {
      "epoch": 805.65,
      "learning_rate": 0.019467016016935488,
      "loss": 0.5355,
      "step": 499500
    },
    {
      "epoch": 805.68,
      "learning_rate": 0.019463790213709673,
      "loss": 0.5391,
      "step": 499520
    },
    {
      "epoch": 805.71,
      "learning_rate": 0.019460564410483865,
      "loss": 0.5484,
      "step": 499540
    },
    {
      "epoch": 805.74,
      "learning_rate": 0.01945733860725806,
      "loss": 0.5424,
      "step": 499560
    },
    {
      "epoch": 805.77,
      "learning_rate": 0.019454112804032257,
      "loss": 0.5446,
      "step": 499580
    },
    {
      "epoch": 805.81,
      "learning_rate": 0.01945088700080645,
      "loss": 0.5482,
      "step": 499600
    },
    {
      "epoch": 805.84,
      "learning_rate": 0.019447661197580644,
      "loss": 0.5435,
      "step": 499620
    },
    {
      "epoch": 805.87,
      "learning_rate": 0.019444435394354836,
      "loss": 0.5439,
      "step": 499640
    },
    {
      "epoch": 805.9,
      "learning_rate": 0.019441209591129032,
      "loss": 0.5431,
      "step": 499660
    },
    {
      "epoch": 805.94,
      "learning_rate": 0.019437983787903228,
      "loss": 0.5382,
      "step": 499680
    },
    {
      "epoch": 805.97,
      "learning_rate": 0.01943475798467742,
      "loss": 0.5473,
      "step": 499700
    },
    {
      "epoch": 806.0,
      "learning_rate": 0.0194316934716129,
      "loss": 0.5439,
      "step": 499720
    },
    {
      "epoch": 806.0,
      "eval_accuracy": {
        "accuracy": 0.7808133635157287
      },
      "eval_loss": 0.896253228187561,
      "eval_runtime": 2.9255,
      "eval_samples_per_second": 4379.125,
      "eval_steps_per_second": 68.707,
      "step": 499720
    },
    {
      "epoch": 806.03,
      "learning_rate": 0.019428467668387094,
      "loss": 0.5166,
      "step": 499740
    },
    {
      "epoch": 806.06,
      "learning_rate": 0.01942524186516129,
      "loss": 0.5314,
      "step": 499760
    },
    {
      "epoch": 806.1,
      "learning_rate": 0.01942201606193548,
      "loss": 0.5356,
      "step": 499780
    },
    {
      "epoch": 806.13,
      "learning_rate": 0.019418790258709677,
      "loss": 0.5317,
      "step": 499800
    },
    {
      "epoch": 806.16,
      "learning_rate": 0.019415564455483873,
      "loss": 0.5407,
      "step": 499820
    },
    {
      "epoch": 806.19,
      "learning_rate": 0.019412338652258065,
      "loss": 0.5306,
      "step": 499840
    },
    {
      "epoch": 806.23,
      "learning_rate": 0.01940911284903226,
      "loss": 0.5408,
      "step": 499860
    },
    {
      "epoch": 806.26,
      "learning_rate": 0.019405887045806453,
      "loss": 0.5381,
      "step": 499880
    },
    {
      "epoch": 806.29,
      "learning_rate": 0.019402661242580648,
      "loss": 0.5533,
      "step": 499900
    },
    {
      "epoch": 806.32,
      "learning_rate": 0.019399435439354844,
      "loss": 0.536,
      "step": 499920
    },
    {
      "epoch": 806.35,
      "learning_rate": 0.019396209636129036,
      "loss": 0.5335,
      "step": 499940
    },
    {
      "epoch": 806.39,
      "learning_rate": 0.01939298383290323,
      "loss": 0.5422,
      "step": 499960
    },
    {
      "epoch": 806.42,
      "learning_rate": 0.019389758029677413,
      "loss": 0.5513,
      "step": 499980
    },
    {
      "epoch": 806.45,
      "learning_rate": 0.01938653222645161,
      "loss": 0.5299,
      "step": 500000
    },
    {
      "epoch": 806.48,
      "learning_rate": 0.019383306423225805,
      "loss": 0.5407,
      "step": 500020
    },
    {
      "epoch": 806.52,
      "learning_rate": 0.019380080619999997,
      "loss": 0.5316,
      "step": 500040
    },
    {
      "epoch": 806.55,
      "learning_rate": 0.019376854816774192,
      "loss": 0.5449,
      "step": 500060
    },
    {
      "epoch": 806.58,
      "learning_rate": 0.019373629013548384,
      "loss": 0.537,
      "step": 500080
    },
    {
      "epoch": 806.61,
      "learning_rate": 0.01937040321032258,
      "loss": 0.5536,
      "step": 500100
    },
    {
      "epoch": 806.65,
      "learning_rate": 0.019367177407096776,
      "loss": 0.5455,
      "step": 500120
    },
    {
      "epoch": 806.68,
      "learning_rate": 0.019363951603870968,
      "loss": 0.5571,
      "step": 500140
    },
    {
      "epoch": 806.71,
      "learning_rate": 0.019360725800645164,
      "loss": 0.5432,
      "step": 500160
    },
    {
      "epoch": 806.74,
      "learning_rate": 0.019357499997419356,
      "loss": 0.5502,
      "step": 500180
    },
    {
      "epoch": 806.77,
      "learning_rate": 0.01935427419419355,
      "loss": 0.5493,
      "step": 500200
    },
    {
      "epoch": 806.81,
      "learning_rate": 0.019351048390967747,
      "loss": 0.5344,
      "step": 500220
    },
    {
      "epoch": 806.84,
      "learning_rate": 0.01934782258774194,
      "loss": 0.5487,
      "step": 500240
    },
    {
      "epoch": 806.87,
      "learning_rate": 0.019344596784516135,
      "loss": 0.5434,
      "step": 500260
    },
    {
      "epoch": 806.9,
      "learning_rate": 0.019341370981290316,
      "loss": 0.5427,
      "step": 500280
    },
    {
      "epoch": 806.94,
      "learning_rate": 0.019338145178064512,
      "loss": 0.5451,
      "step": 500300
    },
    {
      "epoch": 806.97,
      "learning_rate": 0.019334919374838704,
      "loss": 0.5522,
      "step": 500320
    },
    {
      "epoch": 807.0,
      "learning_rate": 0.0193316935716129,
      "loss": 0.5354,
      "step": 500340
    },
    {
      "epoch": 807.0,
      "eval_accuracy": {
        "accuracy": 0.7833112169229568
      },
      "eval_loss": 0.9041736125946045,
      "eval_runtime": 3.0692,
      "eval_samples_per_second": 4174.114,
      "eval_steps_per_second": 65.49,
      "step": 500340
    },
    {
      "epoch": 807.03,
      "learning_rate": 0.019328467768387095,
      "loss": 0.5392,
      "step": 500360
    },
    {
      "epoch": 807.06,
      "learning_rate": 0.019325241965161288,
      "loss": 0.5412,
      "step": 500380
    },
    {
      "epoch": 807.1,
      "learning_rate": 0.019322016161935483,
      "loss": 0.55,
      "step": 500400
    },
    {
      "epoch": 807.13,
      "learning_rate": 0.019318790358709675,
      "loss": 0.5333,
      "step": 500420
    },
    {
      "epoch": 807.16,
      "learning_rate": 0.01931556455548387,
      "loss": 0.5271,
      "step": 500440
    },
    {
      "epoch": 807.19,
      "learning_rate": 0.019312338752258067,
      "loss": 0.5319,
      "step": 500460
    },
    {
      "epoch": 807.23,
      "learning_rate": 0.01930911294903226,
      "loss": 0.5452,
      "step": 500480
    },
    {
      "epoch": 807.26,
      "learning_rate": 0.019305887145806454,
      "loss": 0.5334,
      "step": 500500
    },
    {
      "epoch": 807.29,
      "learning_rate": 0.019302661342580647,
      "loss": 0.5411,
      "step": 500520
    },
    {
      "epoch": 807.32,
      "learning_rate": 0.019299435539354842,
      "loss": 0.5385,
      "step": 500540
    },
    {
      "epoch": 807.35,
      "learning_rate": 0.019296209736129038,
      "loss": 0.5389,
      "step": 500560
    },
    {
      "epoch": 807.39,
      "learning_rate": 0.01929298393290323,
      "loss": 0.543,
      "step": 500580
    },
    {
      "epoch": 807.42,
      "learning_rate": 0.019289758129677415,
      "loss": 0.5491,
      "step": 500600
    },
    {
      "epoch": 807.45,
      "learning_rate": 0.019286532326451607,
      "loss": 0.5313,
      "step": 500620
    },
    {
      "epoch": 807.48,
      "learning_rate": 0.019283306523225803,
      "loss": 0.5365,
      "step": 500640
    },
    {
      "epoch": 807.52,
      "learning_rate": 0.01928008072,
      "loss": 0.5283,
      "step": 500660
    },
    {
      "epoch": 807.55,
      "learning_rate": 0.01927685491677419,
      "loss": 0.535,
      "step": 500680
    },
    {
      "epoch": 807.58,
      "learning_rate": 0.019273629113548386,
      "loss": 0.544,
      "step": 500700
    },
    {
      "epoch": 807.61,
      "learning_rate": 0.01927040331032258,
      "loss": 0.548,
      "step": 500720
    },
    {
      "epoch": 807.65,
      "learning_rate": 0.019267177507096774,
      "loss": 0.5445,
      "step": 500740
    },
    {
      "epoch": 807.68,
      "learning_rate": 0.01926395170387097,
      "loss": 0.5418,
      "step": 500760
    },
    {
      "epoch": 807.71,
      "learning_rate": 0.019260725900645162,
      "loss": 0.5465,
      "step": 500780
    },
    {
      "epoch": 807.74,
      "learning_rate": 0.019257500097419358,
      "loss": 0.5527,
      "step": 500800
    },
    {
      "epoch": 807.77,
      "learning_rate": 0.01925427429419355,
      "loss": 0.5537,
      "step": 500820
    },
    {
      "epoch": 807.81,
      "learning_rate": 0.019251048490967745,
      "loss": 0.5429,
      "step": 500840
    },
    {
      "epoch": 807.84,
      "learning_rate": 0.01924782268774194,
      "loss": 0.5527,
      "step": 500860
    },
    {
      "epoch": 807.87,
      "learning_rate": 0.019244596884516133,
      "loss": 0.549,
      "step": 500880
    },
    {
      "epoch": 807.9,
      "learning_rate": 0.01924137108129032,
      "loss": 0.5495,
      "step": 500900
    },
    {
      "epoch": 807.94,
      "learning_rate": 0.01923814527806451,
      "loss": 0.5494,
      "step": 500920
    },
    {
      "epoch": 807.97,
      "learning_rate": 0.019234919474838706,
      "loss": 0.539,
      "step": 500940
    },
    {
      "epoch": 808.0,
      "learning_rate": 0.0192316936716129,
      "loss": 0.5478,
      "step": 500960
    },
    {
      "epoch": 808.0,
      "eval_accuracy": {
        "accuracy": 0.7829989852470534
      },
      "eval_loss": 0.9033219218254089,
      "eval_runtime": 3.1168,
      "eval_samples_per_second": 4110.283,
      "eval_steps_per_second": 64.489,
      "step": 500960
    },
    {
      "epoch": 808.03,
      "learning_rate": 0.019228467868387094,
      "loss": 0.5436,
      "step": 500980
    },
    {
      "epoch": 808.06,
      "learning_rate": 0.01922524206516129,
      "loss": 0.5189,
      "step": 501000
    },
    {
      "epoch": 808.1,
      "learning_rate": 0.019222016261935482,
      "loss": 0.5261,
      "step": 501020
    },
    {
      "epoch": 808.13,
      "learning_rate": 0.019218790458709677,
      "loss": 0.5348,
      "step": 501040
    },
    {
      "epoch": 808.16,
      "learning_rate": 0.01921556465548387,
      "loss": 0.5355,
      "step": 501060
    },
    {
      "epoch": 808.19,
      "learning_rate": 0.019212338852258065,
      "loss": 0.5337,
      "step": 501080
    },
    {
      "epoch": 808.23,
      "learning_rate": 0.01920911304903226,
      "loss": 0.5382,
      "step": 501100
    },
    {
      "epoch": 808.26,
      "learning_rate": 0.019205887245806453,
      "loss": 0.5446,
      "step": 501120
    },
    {
      "epoch": 808.29,
      "learning_rate": 0.01920266144258065,
      "loss": 0.5504,
      "step": 501140
    },
    {
      "epoch": 808.32,
      "learning_rate": 0.019199435639354844,
      "loss": 0.5443,
      "step": 501160
    },
    {
      "epoch": 808.35,
      "learning_rate": 0.019196209836129036,
      "loss": 0.5461,
      "step": 501180
    },
    {
      "epoch": 808.39,
      "learning_rate": 0.019192984032903232,
      "loss": 0.534,
      "step": 501200
    },
    {
      "epoch": 808.42,
      "learning_rate": 0.019189758229677414,
      "loss": 0.5419,
      "step": 501220
    },
    {
      "epoch": 808.45,
      "learning_rate": 0.01918653242645161,
      "loss": 0.545,
      "step": 501240
    },
    {
      "epoch": 808.48,
      "learning_rate": 0.0191833066232258,
      "loss": 0.5417,
      "step": 501260
    },
    {
      "epoch": 808.52,
      "learning_rate": 0.019180080819999997,
      "loss": 0.5482,
      "step": 501280
    },
    {
      "epoch": 808.55,
      "learning_rate": 0.019176855016774193,
      "loss": 0.5526,
      "step": 501300
    },
    {
      "epoch": 808.58,
      "learning_rate": 0.019173629213548385,
      "loss": 0.5319,
      "step": 501320
    },
    {
      "epoch": 808.61,
      "learning_rate": 0.01917040341032258,
      "loss": 0.5512,
      "step": 501340
    },
    {
      "epoch": 808.65,
      "learning_rate": 0.019167177607096773,
      "loss": 0.5254,
      "step": 501360
    },
    {
      "epoch": 808.68,
      "learning_rate": 0.01916395180387097,
      "loss": 0.5397,
      "step": 501380
    },
    {
      "epoch": 808.71,
      "learning_rate": 0.019160726000645164,
      "loss": 0.5354,
      "step": 501400
    },
    {
      "epoch": 808.74,
      "learning_rate": 0.019157500197419356,
      "loss": 0.539,
      "step": 501420
    },
    {
      "epoch": 808.77,
      "learning_rate": 0.01915427439419355,
      "loss": 0.5409,
      "step": 501440
    },
    {
      "epoch": 808.81,
      "learning_rate": 0.019151048590967744,
      "loss": 0.5464,
      "step": 501460
    },
    {
      "epoch": 808.84,
      "learning_rate": 0.01914782278774194,
      "loss": 0.5462,
      "step": 501480
    },
    {
      "epoch": 808.87,
      "learning_rate": 0.019144596984516135,
      "loss": 0.5386,
      "step": 501500
    },
    {
      "epoch": 808.9,
      "learning_rate": 0.019141371181290317,
      "loss": 0.5357,
      "step": 501520
    },
    {
      "epoch": 808.94,
      "learning_rate": 0.019138145378064512,
      "loss": 0.5397,
      "step": 501540
    },
    {
      "epoch": 808.97,
      "learning_rate": 0.019134919574838705,
      "loss": 0.5392,
      "step": 501560
    },
    {
      "epoch": 809.0,
      "learning_rate": 0.0191316937716129,
      "loss": 0.5446,
      "step": 501580
    },
    {
      "epoch": 809.0,
      "eval_accuracy": {
        "accuracy": 0.7828428694091015
      },
      "eval_loss": 0.8987141847610474,
      "eval_runtime": 3.2263,
      "eval_samples_per_second": 3970.859,
      "eval_steps_per_second": 62.301,
      "step": 501580
    },
    {
      "epoch": 809.03,
      "learning_rate": 0.019128467968387092,
      "loss": 0.5365,
      "step": 501600
    },
    {
      "epoch": 809.06,
      "learning_rate": 0.019125242165161288,
      "loss": 0.5401,
      "step": 501620
    },
    {
      "epoch": 809.1,
      "learning_rate": 0.019122016361935484,
      "loss": 0.5438,
      "step": 501640
    },
    {
      "epoch": 809.13,
      "learning_rate": 0.019118790558709676,
      "loss": 0.5259,
      "step": 501660
    },
    {
      "epoch": 809.16,
      "learning_rate": 0.01911556475548387,
      "loss": 0.533,
      "step": 501680
    },
    {
      "epoch": 809.19,
      "learning_rate": 0.019112338952258067,
      "loss": 0.5425,
      "step": 501700
    },
    {
      "epoch": 809.23,
      "learning_rate": 0.01910911314903226,
      "loss": 0.5343,
      "step": 501720
    },
    {
      "epoch": 809.26,
      "learning_rate": 0.019105887345806455,
      "loss": 0.5254,
      "step": 501740
    },
    {
      "epoch": 809.29,
      "learning_rate": 0.019102661542580647,
      "loss": 0.542,
      "step": 501760
    },
    {
      "epoch": 809.32,
      "learning_rate": 0.019099435739354843,
      "loss": 0.5418,
      "step": 501780
    },
    {
      "epoch": 809.35,
      "learning_rate": 0.01909620993612904,
      "loss": 0.534,
      "step": 501800
    },
    {
      "epoch": 809.39,
      "learning_rate": 0.01909298413290323,
      "loss": 0.5314,
      "step": 501820
    },
    {
      "epoch": 809.42,
      "learning_rate": 0.019089758329677416,
      "loss": 0.5408,
      "step": 501840
    },
    {
      "epoch": 809.45,
      "learning_rate": 0.019086532526451608,
      "loss": 0.5344,
      "step": 501860
    },
    {
      "epoch": 809.48,
      "learning_rate": 0.019083306723225803,
      "loss": 0.5543,
      "step": 501880
    },
    {
      "epoch": 809.52,
      "learning_rate": 0.019080080919999996,
      "loss": 0.5476,
      "step": 501900
    },
    {
      "epoch": 809.55,
      "learning_rate": 0.01907685511677419,
      "loss": 0.5407,
      "step": 501920
    },
    {
      "epoch": 809.58,
      "learning_rate": 0.019073629313548387,
      "loss": 0.5489,
      "step": 501940
    },
    {
      "epoch": 809.61,
      "learning_rate": 0.01907040351032258,
      "loss": 0.5373,
      "step": 501960
    },
    {
      "epoch": 809.65,
      "learning_rate": 0.019067177707096775,
      "loss": 0.5382,
      "step": 501980
    },
    {
      "epoch": 809.68,
      "learning_rate": 0.019063951903870967,
      "loss": 0.5502,
      "step": 502000
    },
    {
      "epoch": 809.71,
      "learning_rate": 0.019060726100645162,
      "loss": 0.5446,
      "step": 502020
    },
    {
      "epoch": 809.74,
      "learning_rate": 0.019057500297419358,
      "loss": 0.552,
      "step": 502040
    },
    {
      "epoch": 809.77,
      "learning_rate": 0.01905427449419355,
      "loss": 0.536,
      "step": 502060
    },
    {
      "epoch": 809.81,
      "learning_rate": 0.019051048690967746,
      "loss": 0.5419,
      "step": 502080
    },
    {
      "epoch": 809.84,
      "learning_rate": 0.019047822887741938,
      "loss": 0.5393,
      "step": 502100
    },
    {
      "epoch": 809.87,
      "learning_rate": 0.019044597084516134,
      "loss": 0.5425,
      "step": 502120
    },
    {
      "epoch": 809.9,
      "learning_rate": 0.01904137128129033,
      "loss": 0.5413,
      "step": 502140
    },
    {
      "epoch": 809.94,
      "learning_rate": 0.01903814547806451,
      "loss": 0.5356,
      "step": 502160
    },
    {
      "epoch": 809.97,
      "learning_rate": 0.019034919674838707,
      "loss": 0.5514,
      "step": 502180
    },
    {
      "epoch": 810.0,
      "learning_rate": 0.019031855161774195,
      "loss": 0.5463,
      "step": 502200
    },
    {
      "epoch": 810.0,
      "eval_accuracy": {
        "accuracy": 0.7829209273280774
      },
      "eval_loss": 0.9007822871208191,
      "eval_runtime": 2.9556,
      "eval_samples_per_second": 4334.539,
      "eval_steps_per_second": 68.007,
      "step": 502200
    },
    {
      "epoch": 810.03,
      "learning_rate": 0.01902862935854839,
      "loss": 0.5291,
      "step": 502220
    },
    {
      "epoch": 810.06,
      "learning_rate": 0.019025403555322586,
      "loss": 0.5437,
      "step": 502240
    },
    {
      "epoch": 810.1,
      "learning_rate": 0.01902217775209678,
      "loss": 0.5352,
      "step": 502260
    },
    {
      "epoch": 810.13,
      "learning_rate": 0.019018951948870974,
      "loss": 0.5361,
      "step": 502280
    },
    {
      "epoch": 810.16,
      "learning_rate": 0.019015726145645156,
      "loss": 0.5402,
      "step": 502300
    },
    {
      "epoch": 810.19,
      "learning_rate": 0.01901250034241935,
      "loss": 0.5464,
      "step": 502320
    },
    {
      "epoch": 810.23,
      "learning_rate": 0.019009274539193544,
      "loss": 0.5289,
      "step": 502340
    },
    {
      "epoch": 810.26,
      "learning_rate": 0.01900604873596774,
      "loss": 0.5342,
      "step": 502360
    },
    {
      "epoch": 810.29,
      "learning_rate": 0.019002822932741935,
      "loss": 0.5438,
      "step": 502380
    },
    {
      "epoch": 810.32,
      "learning_rate": 0.018999597129516127,
      "loss": 0.5526,
      "step": 502400
    },
    {
      "epoch": 810.35,
      "learning_rate": 0.018996371326290323,
      "loss": 0.5445,
      "step": 502420
    },
    {
      "epoch": 810.39,
      "learning_rate": 0.018993145523064515,
      "loss": 0.536,
      "step": 502440
    },
    {
      "epoch": 810.42,
      "learning_rate": 0.01898991971983871,
      "loss": 0.5531,
      "step": 502460
    },
    {
      "epoch": 810.45,
      "learning_rate": 0.018986693916612906,
      "loss": 0.5438,
      "step": 502480
    },
    {
      "epoch": 810.48,
      "learning_rate": 0.018983468113387098,
      "loss": 0.5492,
      "step": 502500
    },
    {
      "epoch": 810.52,
      "learning_rate": 0.018980242310161294,
      "loss": 0.5582,
      "step": 502520
    },
    {
      "epoch": 810.55,
      "learning_rate": 0.018977016506935486,
      "loss": 0.5341,
      "step": 502540
    },
    {
      "epoch": 810.58,
      "learning_rate": 0.01897379070370968,
      "loss": 0.5387,
      "step": 502560
    },
    {
      "epoch": 810.61,
      "learning_rate": 0.018970564900483877,
      "loss": 0.5265,
      "step": 502580
    },
    {
      "epoch": 810.65,
      "learning_rate": 0.01896733909725806,
      "loss": 0.5542,
      "step": 502600
    },
    {
      "epoch": 810.68,
      "learning_rate": 0.018964113294032255,
      "loss": 0.5248,
      "step": 502620
    },
    {
      "epoch": 810.71,
      "learning_rate": 0.018960887490806447,
      "loss": 0.5316,
      "step": 502640
    },
    {
      "epoch": 810.74,
      "learning_rate": 0.018957661687580642,
      "loss": 0.5481,
      "step": 502660
    },
    {
      "epoch": 810.77,
      "learning_rate": 0.018954435884354835,
      "loss": 0.5329,
      "step": 502680
    },
    {
      "epoch": 810.81,
      "learning_rate": 0.01895121008112903,
      "loss": 0.5268,
      "step": 502700
    },
    {
      "epoch": 810.84,
      "learning_rate": 0.018947984277903226,
      "loss": 0.5322,
      "step": 502720
    },
    {
      "epoch": 810.87,
      "learning_rate": 0.018944758474677418,
      "loss": 0.5517,
      "step": 502740
    },
    {
      "epoch": 810.9,
      "learning_rate": 0.018941532671451614,
      "loss": 0.5378,
      "step": 502760
    },
    {
      "epoch": 810.94,
      "learning_rate": 0.01893830686822581,
      "loss": 0.5429,
      "step": 502780
    },
    {
      "epoch": 810.97,
      "learning_rate": 0.018935081065,
      "loss": 0.5468,
      "step": 502800
    },
    {
      "epoch": 811.0,
      "learning_rate": 0.018931855261774197,
      "loss": 0.539,
      "step": 502820
    },
    {
      "epoch": 811.0,
      "eval_accuracy": {
        "accuracy": 0.7823745218952463
      },
      "eval_loss": 0.9069150686264038,
      "eval_runtime": 2.9701,
      "eval_samples_per_second": 4313.344,
      "eval_steps_per_second": 67.675,
      "step": 502820
    },
    {
      "epoch": 811.03,
      "learning_rate": 0.01892862945854839,
      "loss": 0.5455,
      "step": 502840
    },
    {
      "epoch": 811.06,
      "learning_rate": 0.018925403655322585,
      "loss": 0.5347,
      "step": 502860
    },
    {
      "epoch": 811.1,
      "learning_rate": 0.01892217785209678,
      "loss": 0.5342,
      "step": 502880
    },
    {
      "epoch": 811.13,
      "learning_rate": 0.018918952048870973,
      "loss": 0.5399,
      "step": 502900
    },
    {
      "epoch": 811.16,
      "learning_rate": 0.018915726245645158,
      "loss": 0.5407,
      "step": 502920
    },
    {
      "epoch": 811.19,
      "learning_rate": 0.01891250044241935,
      "loss": 0.5344,
      "step": 502940
    },
    {
      "epoch": 811.23,
      "learning_rate": 0.018909274639193546,
      "loss": 0.5271,
      "step": 502960
    },
    {
      "epoch": 811.26,
      "learning_rate": 0.018906048835967738,
      "loss": 0.5413,
      "step": 502980
    },
    {
      "epoch": 811.29,
      "learning_rate": 0.018902823032741933,
      "loss": 0.5432,
      "step": 503000
    },
    {
      "epoch": 811.32,
      "learning_rate": 0.01889959722951613,
      "loss": 0.5403,
      "step": 503020
    },
    {
      "epoch": 811.35,
      "learning_rate": 0.01889637142629032,
      "loss": 0.5313,
      "step": 503040
    },
    {
      "epoch": 811.39,
      "learning_rate": 0.018893145623064517,
      "loss": 0.5396,
      "step": 503060
    },
    {
      "epoch": 811.42,
      "learning_rate": 0.01888991981983871,
      "loss": 0.5443,
      "step": 503080
    },
    {
      "epoch": 811.45,
      "learning_rate": 0.018886694016612905,
      "loss": 0.5429,
      "step": 503100
    },
    {
      "epoch": 811.48,
      "learning_rate": 0.0188834682133871,
      "loss": 0.5294,
      "step": 503120
    },
    {
      "epoch": 811.52,
      "learning_rate": 0.018880242410161292,
      "loss": 0.5437,
      "step": 503140
    },
    {
      "epoch": 811.55,
      "learning_rate": 0.018877016606935488,
      "loss": 0.5438,
      "step": 503160
    },
    {
      "epoch": 811.58,
      "learning_rate": 0.01887379080370968,
      "loss": 0.5339,
      "step": 503180
    },
    {
      "epoch": 811.61,
      "learning_rate": 0.018870565000483876,
      "loss": 0.5474,
      "step": 503200
    },
    {
      "epoch": 811.65,
      "learning_rate": 0.018867339197258057,
      "loss": 0.5345,
      "step": 503220
    },
    {
      "epoch": 811.68,
      "learning_rate": 0.018864113394032253,
      "loss": 0.5444,
      "step": 503240
    },
    {
      "epoch": 811.71,
      "learning_rate": 0.01886088759080645,
      "loss": 0.5446,
      "step": 503260
    },
    {
      "epoch": 811.74,
      "learning_rate": 0.01885766178758064,
      "loss": 0.5249,
      "step": 503280
    },
    {
      "epoch": 811.77,
      "learning_rate": 0.018854435984354836,
      "loss": 0.5522,
      "step": 503300
    },
    {
      "epoch": 811.81,
      "learning_rate": 0.01885121018112903,
      "loss": 0.5486,
      "step": 503320
    },
    {
      "epoch": 811.84,
      "learning_rate": 0.018847984377903224,
      "loss": 0.5386,
      "step": 503340
    },
    {
      "epoch": 811.87,
      "learning_rate": 0.01884475857467742,
      "loss": 0.5514,
      "step": 503360
    },
    {
      "epoch": 811.9,
      "learning_rate": 0.018841532771451612,
      "loss": 0.5375,
      "step": 503380
    },
    {
      "epoch": 811.94,
      "learning_rate": 0.018838306968225808,
      "loss": 0.5443,
      "step": 503400
    },
    {
      "epoch": 811.97,
      "learning_rate": 0.018835081165000003,
      "loss": 0.534,
      "step": 503420
    },
    {
      "epoch": 812.0,
      "learning_rate": 0.018831855361774195,
      "loss": 0.5496,
      "step": 503440
    },
    {
      "epoch": 812.0,
      "eval_accuracy": {
        "accuracy": 0.7783935680274764
      },
      "eval_loss": 0.9183781743049622,
      "eval_runtime": 3.1977,
      "eval_samples_per_second": 4006.342,
      "eval_steps_per_second": 62.858,
      "step": 503440
    },
    {
      "epoch": 812.03,
      "learning_rate": 0.01882862955854839,
      "loss": 0.5448,
      "step": 503460
    },
    {
      "epoch": 812.06,
      "learning_rate": 0.018825403755322583,
      "loss": 0.5377,
      "step": 503480
    },
    {
      "epoch": 812.1,
      "learning_rate": 0.01882217795209678,
      "loss": 0.5354,
      "step": 503500
    },
    {
      "epoch": 812.13,
      "learning_rate": 0.018818952148870974,
      "loss": 0.5359,
      "step": 503520
    },
    {
      "epoch": 812.16,
      "learning_rate": 0.018815726345645156,
      "loss": 0.5368,
      "step": 503540
    },
    {
      "epoch": 812.19,
      "learning_rate": 0.018812500542419352,
      "loss": 0.5382,
      "step": 503560
    },
    {
      "epoch": 812.23,
      "learning_rate": 0.018809274739193544,
      "loss": 0.5315,
      "step": 503580
    },
    {
      "epoch": 812.26,
      "learning_rate": 0.01880604893596774,
      "loss": 0.5435,
      "step": 503600
    },
    {
      "epoch": 812.29,
      "learning_rate": 0.018802823132741932,
      "loss": 0.5386,
      "step": 503620
    },
    {
      "epoch": 812.32,
      "learning_rate": 0.018799597329516127,
      "loss": 0.543,
      "step": 503640
    },
    {
      "epoch": 812.35,
      "learning_rate": 0.018796371526290323,
      "loss": 0.5333,
      "step": 503660
    },
    {
      "epoch": 812.39,
      "learning_rate": 0.018793145723064515,
      "loss": 0.5305,
      "step": 503680
    },
    {
      "epoch": 812.42,
      "learning_rate": 0.01878991991983871,
      "loss": 0.5435,
      "step": 503700
    },
    {
      "epoch": 812.45,
      "learning_rate": 0.018786694116612903,
      "loss": 0.5335,
      "step": 503720
    },
    {
      "epoch": 812.48,
      "learning_rate": 0.0187834683133871,
      "loss": 0.5261,
      "step": 503740
    },
    {
      "epoch": 812.52,
      "learning_rate": 0.018780242510161294,
      "loss": 0.5356,
      "step": 503760
    },
    {
      "epoch": 812.55,
      "learning_rate": 0.018777016706935486,
      "loss": 0.5431,
      "step": 503780
    },
    {
      "epoch": 812.58,
      "learning_rate": 0.018773790903709682,
      "loss": 0.5296,
      "step": 503800
    },
    {
      "epoch": 812.61,
      "learning_rate": 0.018770565100483874,
      "loss": 0.5292,
      "step": 503820
    },
    {
      "epoch": 812.65,
      "learning_rate": 0.01876733929725806,
      "loss": 0.5396,
      "step": 503840
    },
    {
      "epoch": 812.68,
      "learning_rate": 0.01876411349403225,
      "loss": 0.5547,
      "step": 503860
    },
    {
      "epoch": 812.71,
      "learning_rate": 0.018760887690806447,
      "loss": 0.5378,
      "step": 503880
    },
    {
      "epoch": 812.74,
      "learning_rate": 0.018757661887580643,
      "loss": 0.5418,
      "step": 503900
    },
    {
      "epoch": 812.77,
      "learning_rate": 0.018754436084354835,
      "loss": 0.5446,
      "step": 503920
    },
    {
      "epoch": 812.81,
      "learning_rate": 0.01875121028112903,
      "loss": 0.5475,
      "step": 503940
    },
    {
      "epoch": 812.84,
      "learning_rate": 0.018747984477903226,
      "loss": 0.5399,
      "step": 503960
    },
    {
      "epoch": 812.87,
      "learning_rate": 0.01874475867467742,
      "loss": 0.537,
      "step": 503980
    },
    {
      "epoch": 812.9,
      "learning_rate": 0.018741532871451614,
      "loss": 0.552,
      "step": 504000
    },
    {
      "epoch": 812.94,
      "learning_rate": 0.018738307068225806,
      "loss": 0.5467,
      "step": 504020
    },
    {
      "epoch": 812.97,
      "learning_rate": 0.018735081265000002,
      "loss": 0.5483,
      "step": 504040
    },
    {
      "epoch": 813.0,
      "learning_rate": 0.018731855461774197,
      "loss": 0.5502,
      "step": 504060
    },
    {
      "epoch": 813.0,
      "eval_accuracy": {
        "accuracy": 0.7819842323003668
      },
      "eval_loss": 0.9071680903434753,
      "eval_runtime": 3.1929,
      "eval_samples_per_second": 4012.294,
      "eval_steps_per_second": 62.951,
      "step": 504060
    },
    {
      "epoch": 813.03,
      "learning_rate": 0.01872862965854839,
      "loss": 0.5369,
      "step": 504080
    },
    {
      "epoch": 813.06,
      "learning_rate": 0.018725403855322585,
      "loss": 0.5382,
      "step": 504100
    },
    {
      "epoch": 813.1,
      "learning_rate": 0.018722178052096777,
      "loss": 0.5393,
      "step": 504120
    },
    {
      "epoch": 813.13,
      "learning_rate": 0.018718952248870973,
      "loss": 0.5337,
      "step": 504140
    },
    {
      "epoch": 813.16,
      "learning_rate": 0.018715726445645155,
      "loss": 0.5276,
      "step": 504160
    },
    {
      "epoch": 813.19,
      "learning_rate": 0.01871250064241935,
      "loss": 0.5393,
      "step": 504180
    },
    {
      "epoch": 813.23,
      "learning_rate": 0.018709274839193546,
      "loss": 0.5306,
      "step": 504200
    },
    {
      "epoch": 813.26,
      "learning_rate": 0.018706049035967738,
      "loss": 0.5281,
      "step": 504220
    },
    {
      "epoch": 813.29,
      "learning_rate": 0.018702823232741934,
      "loss": 0.5401,
      "step": 504240
    },
    {
      "epoch": 813.32,
      "learning_rate": 0.018699597429516126,
      "loss": 0.5361,
      "step": 504260
    },
    {
      "epoch": 813.35,
      "learning_rate": 0.01869637162629032,
      "loss": 0.5454,
      "step": 504280
    },
    {
      "epoch": 813.39,
      "learning_rate": 0.018693145823064517,
      "loss": 0.535,
      "step": 504300
    },
    {
      "epoch": 813.42,
      "learning_rate": 0.01868992001983871,
      "loss": 0.545,
      "step": 504320
    },
    {
      "epoch": 813.45,
      "learning_rate": 0.018686694216612905,
      "loss": 0.5448,
      "step": 504340
    },
    {
      "epoch": 813.48,
      "learning_rate": 0.018683468413387097,
      "loss": 0.5429,
      "step": 504360
    },
    {
      "epoch": 813.52,
      "learning_rate": 0.018680242610161293,
      "loss": 0.5375,
      "step": 504380
    },
    {
      "epoch": 813.55,
      "learning_rate": 0.01867701680693549,
      "loss": 0.5156,
      "step": 504400
    },
    {
      "epoch": 813.58,
      "learning_rate": 0.01867379100370968,
      "loss": 0.5351,
      "step": 504420
    },
    {
      "epoch": 813.61,
      "learning_rate": 0.018670565200483876,
      "loss": 0.5408,
      "step": 504440
    },
    {
      "epoch": 813.65,
      "learning_rate": 0.018667339397258068,
      "loss": 0.5459,
      "step": 504460
    },
    {
      "epoch": 813.68,
      "learning_rate": 0.018664113594032253,
      "loss": 0.5424,
      "step": 504480
    },
    {
      "epoch": 813.71,
      "learning_rate": 0.01866088779080645,
      "loss": 0.5328,
      "step": 504500
    },
    {
      "epoch": 813.74,
      "learning_rate": 0.01865766198758064,
      "loss": 0.5422,
      "step": 504520
    },
    {
      "epoch": 813.77,
      "learning_rate": 0.018654436184354837,
      "loss": 0.5399,
      "step": 504540
    },
    {
      "epoch": 813.81,
      "learning_rate": 0.01865121038112903,
      "loss": 0.5367,
      "step": 504560
    },
    {
      "epoch": 813.84,
      "learning_rate": 0.018647984577903225,
      "loss": 0.5434,
      "step": 504580
    },
    {
      "epoch": 813.87,
      "learning_rate": 0.01864475877467742,
      "loss": 0.5498,
      "step": 504600
    },
    {
      "epoch": 813.9,
      "learning_rate": 0.018641532971451612,
      "loss": 0.5475,
      "step": 504620
    },
    {
      "epoch": 813.94,
      "learning_rate": 0.018638307168225808,
      "loss": 0.5383,
      "step": 504640
    },
    {
      "epoch": 813.97,
      "learning_rate": 0.018635081365,
      "loss": 0.5364,
      "step": 504660
    },
    {
      "epoch": 814.0,
      "learning_rate": 0.018631855561774196,
      "loss": 0.5345,
      "step": 504680
    },
    {
      "epoch": 814.0,
      "eval_accuracy": {
        "accuracy": 0.7878385762235579
      },
      "eval_loss": 0.8952442407608032,
      "eval_runtime": 3.2084,
      "eval_samples_per_second": 3992.897,
      "eval_steps_per_second": 62.647,
      "step": 504680
    },
    {
      "epoch": 814.03,
      "learning_rate": 0.01862862975854839,
      "loss": 0.5378,
      "step": 504700
    },
    {
      "epoch": 814.06,
      "learning_rate": 0.018625403955322584,
      "loss": 0.5334,
      "step": 504720
    },
    {
      "epoch": 814.1,
      "learning_rate": 0.01862217815209678,
      "loss": 0.5442,
      "step": 504740
    },
    {
      "epoch": 814.13,
      "learning_rate": 0.01861895234887097,
      "loss": 0.5293,
      "step": 504760
    },
    {
      "epoch": 814.16,
      "learning_rate": 0.018615726545645157,
      "loss": 0.5231,
      "step": 504780
    },
    {
      "epoch": 814.19,
      "learning_rate": 0.01861250074241935,
      "loss": 0.5323,
      "step": 504800
    },
    {
      "epoch": 814.23,
      "learning_rate": 0.018609274939193544,
      "loss": 0.5396,
      "step": 504820
    },
    {
      "epoch": 814.26,
      "learning_rate": 0.01860604913596774,
      "loss": 0.5317,
      "step": 504840
    },
    {
      "epoch": 814.29,
      "learning_rate": 0.018602823332741932,
      "loss": 0.5389,
      "step": 504860
    },
    {
      "epoch": 814.32,
      "learning_rate": 0.018599597529516128,
      "loss": 0.532,
      "step": 504880
    },
    {
      "epoch": 814.35,
      "learning_rate": 0.01859637172629032,
      "loss": 0.5447,
      "step": 504900
    },
    {
      "epoch": 814.39,
      "learning_rate": 0.018593145923064516,
      "loss": 0.5372,
      "step": 504920
    },
    {
      "epoch": 814.42,
      "learning_rate": 0.01858992011983871,
      "loss": 0.5298,
      "step": 504940
    },
    {
      "epoch": 814.45,
      "learning_rate": 0.018586694316612903,
      "loss": 0.5379,
      "step": 504960
    },
    {
      "epoch": 814.48,
      "learning_rate": 0.0185834685133871,
      "loss": 0.5352,
      "step": 504980
    },
    {
      "epoch": 814.52,
      "learning_rate": 0.01858024271016129,
      "loss": 0.5436,
      "step": 505000
    },
    {
      "epoch": 814.55,
      "learning_rate": 0.018577016906935487,
      "loss": 0.5359,
      "step": 505020
    },
    {
      "epoch": 814.58,
      "learning_rate": 0.018573791103709682,
      "loss": 0.5372,
      "step": 505040
    },
    {
      "epoch": 814.61,
      "learning_rate": 0.018570565300483875,
      "loss": 0.5319,
      "step": 505060
    },
    {
      "epoch": 814.65,
      "learning_rate": 0.01856733949725807,
      "loss": 0.5378,
      "step": 505080
    },
    {
      "epoch": 814.68,
      "learning_rate": 0.018564113694032252,
      "loss": 0.5397,
      "step": 505100
    },
    {
      "epoch": 814.71,
      "learning_rate": 0.018560887890806448,
      "loss": 0.5443,
      "step": 505120
    },
    {
      "epoch": 814.74,
      "learning_rate": 0.018557662087580643,
      "loss": 0.5371,
      "step": 505140
    },
    {
      "epoch": 814.77,
      "learning_rate": 0.018554436284354835,
      "loss": 0.546,
      "step": 505160
    },
    {
      "epoch": 814.81,
      "learning_rate": 0.01855121048112903,
      "loss": 0.5374,
      "step": 505180
    },
    {
      "epoch": 814.84,
      "learning_rate": 0.018547984677903223,
      "loss": 0.5291,
      "step": 505200
    },
    {
      "epoch": 814.87,
      "learning_rate": 0.01854475887467742,
      "loss": 0.5467,
      "step": 505220
    },
    {
      "epoch": 814.9,
      "learning_rate": 0.018541533071451614,
      "loss": 0.5415,
      "step": 505240
    },
    {
      "epoch": 814.94,
      "learning_rate": 0.018538307268225807,
      "loss": 0.5422,
      "step": 505260
    },
    {
      "epoch": 814.97,
      "learning_rate": 0.018535081465000002,
      "loss": 0.536,
      "step": 505280
    },
    {
      "epoch": 815.0,
      "learning_rate": 0.018531855661774194,
      "loss": 0.542,
      "step": 505300
    },
    {
      "epoch": 815.0,
      "eval_accuracy": {
        "accuracy": 0.785184606978378
      },
      "eval_loss": 0.8983293175697327,
      "eval_runtime": 3.4997,
      "eval_samples_per_second": 3660.549,
      "eval_steps_per_second": 57.433,
      "step": 505300
    },
    {
      "epoch": 815.03,
      "learning_rate": 0.01852862985854839,
      "loss": 0.5475,
      "step": 505320
    },
    {
      "epoch": 815.06,
      "learning_rate": 0.018525404055322586,
      "loss": 0.5318,
      "step": 505340
    },
    {
      "epoch": 815.1,
      "learning_rate": 0.018522178252096778,
      "loss": 0.5366,
      "step": 505360
    },
    {
      "epoch": 815.13,
      "learning_rate": 0.018518952448870973,
      "loss": 0.527,
      "step": 505380
    },
    {
      "epoch": 815.16,
      "learning_rate": 0.018515726645645155,
      "loss": 0.5382,
      "step": 505400
    },
    {
      "epoch": 815.19,
      "learning_rate": 0.01851250084241935,
      "loss": 0.5282,
      "step": 505420
    },
    {
      "epoch": 815.23,
      "learning_rate": 0.018509275039193543,
      "loss": 0.5339,
      "step": 505440
    },
    {
      "epoch": 815.26,
      "learning_rate": 0.01850604923596774,
      "loss": 0.5301,
      "step": 505460
    },
    {
      "epoch": 815.29,
      "learning_rate": 0.018502823432741934,
      "loss": 0.5373,
      "step": 505480
    },
    {
      "epoch": 815.32,
      "learning_rate": 0.018499597629516126,
      "loss": 0.5231,
      "step": 505500
    },
    {
      "epoch": 815.35,
      "learning_rate": 0.018496371826290322,
      "loss": 0.5469,
      "step": 505520
    },
    {
      "epoch": 815.39,
      "learning_rate": 0.018493146023064514,
      "loss": 0.5324,
      "step": 505540
    },
    {
      "epoch": 815.42,
      "learning_rate": 0.01848992021983871,
      "loss": 0.5331,
      "step": 505560
    },
    {
      "epoch": 815.45,
      "learning_rate": 0.018486694416612905,
      "loss": 0.5481,
      "step": 505580
    },
    {
      "epoch": 815.48,
      "learning_rate": 0.018483468613387097,
      "loss": 0.5433,
      "step": 505600
    },
    {
      "epoch": 815.52,
      "learning_rate": 0.018480242810161293,
      "loss": 0.526,
      "step": 505620
    },
    {
      "epoch": 815.55,
      "learning_rate": 0.018477017006935485,
      "loss": 0.532,
      "step": 505640
    },
    {
      "epoch": 815.58,
      "learning_rate": 0.01847379120370968,
      "loss": 0.5368,
      "step": 505660
    },
    {
      "epoch": 815.61,
      "learning_rate": 0.018470565400483877,
      "loss": 0.5371,
      "step": 505680
    },
    {
      "epoch": 815.65,
      "learning_rate": 0.01846733959725807,
      "loss": 0.5479,
      "step": 505700
    },
    {
      "epoch": 815.68,
      "learning_rate": 0.018464113794032254,
      "loss": 0.5302,
      "step": 505720
    },
    {
      "epoch": 815.71,
      "learning_rate": 0.018460887990806446,
      "loss": 0.5346,
      "step": 505740
    },
    {
      "epoch": 815.74,
      "learning_rate": 0.01845766218758064,
      "loss": 0.54,
      "step": 505760
    },
    {
      "epoch": 815.77,
      "learning_rate": 0.018454436384354837,
      "loss": 0.542,
      "step": 505780
    },
    {
      "epoch": 815.81,
      "learning_rate": 0.01845121058112903,
      "loss": 0.5435,
      "step": 505800
    },
    {
      "epoch": 815.84,
      "learning_rate": 0.018447984777903225,
      "loss": 0.5344,
      "step": 505820
    },
    {
      "epoch": 815.87,
      "learning_rate": 0.018444758974677417,
      "loss": 0.5402,
      "step": 505840
    },
    {
      "epoch": 815.9,
      "learning_rate": 0.018441533171451613,
      "loss": 0.5475,
      "step": 505860
    },
    {
      "epoch": 815.94,
      "learning_rate": 0.01843830736822581,
      "loss": 0.5386,
      "step": 505880
    },
    {
      "epoch": 815.97,
      "learning_rate": 0.018435081565,
      "loss": 0.5472,
      "step": 505900
    },
    {
      "epoch": 816.0,
      "learning_rate": 0.018431855761774196,
      "loss": 0.5618,
      "step": 505920
    },
    {
      "epoch": 816.0,
      "eval_accuracy": {
        "accuracy": 0.7815939427054874
      },
      "eval_loss": 0.8943333625793457,
      "eval_runtime": 3.7008,
      "eval_samples_per_second": 3461.684,
      "eval_steps_per_second": 54.313,
      "step": 505920
    },
    {
      "epoch": 816.03,
      "learning_rate": 0.01842862995854839,
      "loss": 0.5383,
      "step": 505940
    },
    {
      "epoch": 816.06,
      "learning_rate": 0.018425404155322584,
      "loss": 0.5374,
      "step": 505960
    },
    {
      "epoch": 816.1,
      "learning_rate": 0.01842217835209678,
      "loss": 0.5421,
      "step": 505980
    },
    {
      "epoch": 816.13,
      "learning_rate": 0.018418952548870972,
      "loss": 0.5363,
      "step": 506000
    },
    {
      "epoch": 816.16,
      "learning_rate": 0.018415726745645157,
      "loss": 0.5333,
      "step": 506020
    },
    {
      "epoch": 816.19,
      "learning_rate": 0.01841250094241935,
      "loss": 0.5346,
      "step": 506040
    },
    {
      "epoch": 816.23,
      "learning_rate": 0.018409275139193545,
      "loss": 0.536,
      "step": 506060
    },
    {
      "epoch": 816.26,
      "learning_rate": 0.018406049335967737,
      "loss": 0.5291,
      "step": 506080
    },
    {
      "epoch": 816.29,
      "learning_rate": 0.018402823532741933,
      "loss": 0.5327,
      "step": 506100
    },
    {
      "epoch": 816.32,
      "learning_rate": 0.018399597729516128,
      "loss": 0.5416,
      "step": 506120
    },
    {
      "epoch": 816.35,
      "learning_rate": 0.01839637192629032,
      "loss": 0.5274,
      "step": 506140
    },
    {
      "epoch": 816.39,
      "learning_rate": 0.018393146123064516,
      "loss": 0.5347,
      "step": 506160
    },
    {
      "epoch": 816.42,
      "learning_rate": 0.018389920319838708,
      "loss": 0.5504,
      "step": 506180
    },
    {
      "epoch": 816.45,
      "learning_rate": 0.018386694516612904,
      "loss": 0.5418,
      "step": 506200
    },
    {
      "epoch": 816.48,
      "learning_rate": 0.018383630003548385,
      "loss": 0.5296,
      "step": 506220
    },
    {
      "epoch": 816.52,
      "learning_rate": 0.018380404200322577,
      "loss": 0.5337,
      "step": 506240
    },
    {
      "epoch": 816.55,
      "learning_rate": 0.018377178397096773,
      "loss": 0.547,
      "step": 506260
    },
    {
      "epoch": 816.58,
      "learning_rate": 0.018373952593870965,
      "loss": 0.5383,
      "step": 506280
    },
    {
      "epoch": 816.61,
      "learning_rate": 0.01837072679064516,
      "loss": 0.537,
      "step": 506300
    },
    {
      "epoch": 816.65,
      "learning_rate": 0.018367500987419356,
      "loss": 0.5478,
      "step": 506320
    },
    {
      "epoch": 816.68,
      "learning_rate": 0.01836427518419355,
      "loss": 0.5479,
      "step": 506340
    },
    {
      "epoch": 816.71,
      "learning_rate": 0.018361049380967744,
      "loss": 0.5316,
      "step": 506360
    },
    {
      "epoch": 816.74,
      "learning_rate": 0.018357823577741936,
      "loss": 0.5308,
      "step": 506380
    },
    {
      "epoch": 816.77,
      "learning_rate": 0.018354597774516132,
      "loss": 0.549,
      "step": 506400
    },
    {
      "epoch": 816.81,
      "learning_rate": 0.018351371971290328,
      "loss": 0.5365,
      "step": 506420
    },
    {
      "epoch": 816.84,
      "learning_rate": 0.01834814616806452,
      "loss": 0.5345,
      "step": 506440
    },
    {
      "epoch": 816.87,
      "learning_rate": 0.018344920364838715,
      "loss": 0.5328,
      "step": 506460
    },
    {
      "epoch": 816.9,
      "learning_rate": 0.018341694561612897,
      "loss": 0.5305,
      "step": 506480
    },
    {
      "epoch": 816.94,
      "learning_rate": 0.018338468758387093,
      "loss": 0.5344,
      "step": 506500
    },
    {
      "epoch": 816.97,
      "learning_rate": 0.018335242955161285,
      "loss": 0.5308,
      "step": 506520
    },
    {
      "epoch": 817.0,
      "learning_rate": 0.01833201715193548,
      "loss": 0.53,
      "step": 506540
    },
    {
      "epoch": 817.0,
      "eval_accuracy": {
        "accuracy": 0.7842479119506673
      },
      "eval_loss": 0.9047765135765076,
      "eval_runtime": 3.0882,
      "eval_samples_per_second": 4148.309,
      "eval_steps_per_second": 65.085,
      "step": 506540
    },
    {
      "epoch": 817.03,
      "learning_rate": 0.018328791348709676,
      "loss": 0.5378,
      "step": 506560
    },
    {
      "epoch": 817.06,
      "learning_rate": 0.01832556554548387,
      "loss": 0.5365,
      "step": 506580
    },
    {
      "epoch": 817.1,
      "learning_rate": 0.018322339742258064,
      "loss": 0.5313,
      "step": 506600
    },
    {
      "epoch": 817.13,
      "learning_rate": 0.018319113939032256,
      "loss": 0.5221,
      "step": 506620
    },
    {
      "epoch": 817.16,
      "learning_rate": 0.018315888135806452,
      "loss": 0.5371,
      "step": 506640
    },
    {
      "epoch": 817.19,
      "learning_rate": 0.018312662332580647,
      "loss": 0.5368,
      "step": 506660
    },
    {
      "epoch": 817.23,
      "learning_rate": 0.01830943652935484,
      "loss": 0.5369,
      "step": 506680
    },
    {
      "epoch": 817.26,
      "learning_rate": 0.018306210726129035,
      "loss": 0.5304,
      "step": 506700
    },
    {
      "epoch": 817.29,
      "learning_rate": 0.018302984922903227,
      "loss": 0.5514,
      "step": 506720
    },
    {
      "epoch": 817.32,
      "learning_rate": 0.018299759119677423,
      "loss": 0.531,
      "step": 506740
    },
    {
      "epoch": 817.35,
      "learning_rate": 0.01829653331645162,
      "loss": 0.5387,
      "step": 506760
    },
    {
      "epoch": 817.39,
      "learning_rate": 0.01829330751322581,
      "loss": 0.533,
      "step": 506780
    },
    {
      "epoch": 817.42,
      "learning_rate": 0.018290081709999996,
      "loss": 0.536,
      "step": 506800
    },
    {
      "epoch": 817.45,
      "learning_rate": 0.018286855906774188,
      "loss": 0.5386,
      "step": 506820
    },
    {
      "epoch": 817.48,
      "learning_rate": 0.018283630103548384,
      "loss": 0.5369,
      "step": 506840
    },
    {
      "epoch": 817.52,
      "learning_rate": 0.01828040430032258,
      "loss": 0.5264,
      "step": 506860
    },
    {
      "epoch": 817.55,
      "learning_rate": 0.01827717849709677,
      "loss": 0.5349,
      "step": 506880
    },
    {
      "epoch": 817.58,
      "learning_rate": 0.018273952693870967,
      "loss": 0.5346,
      "step": 506900
    },
    {
      "epoch": 817.61,
      "learning_rate": 0.01827072689064516,
      "loss": 0.5466,
      "step": 506920
    },
    {
      "epoch": 817.65,
      "learning_rate": 0.018267501087419355,
      "loss": 0.5342,
      "step": 506940
    },
    {
      "epoch": 817.68,
      "learning_rate": 0.01826427528419355,
      "loss": 0.5378,
      "step": 506960
    },
    {
      "epoch": 817.71,
      "learning_rate": 0.018261049480967743,
      "loss": 0.529,
      "step": 506980
    },
    {
      "epoch": 817.74,
      "learning_rate": 0.01825782367774194,
      "loss": 0.5206,
      "step": 507000
    },
    {
      "epoch": 817.77,
      "learning_rate": 0.01825459787451613,
      "loss": 0.5433,
      "step": 507020
    },
    {
      "epoch": 817.81,
      "learning_rate": 0.018251372071290326,
      "loss": 0.5368,
      "step": 507040
    },
    {
      "epoch": 817.84,
      "learning_rate": 0.018248146268064522,
      "loss": 0.5261,
      "step": 507060
    },
    {
      "epoch": 817.87,
      "learning_rate": 0.018244920464838714,
      "loss": 0.5341,
      "step": 507080
    },
    {
      "epoch": 817.9,
      "learning_rate": 0.0182416946616129,
      "loss": 0.5255,
      "step": 507100
    },
    {
      "epoch": 817.94,
      "learning_rate": 0.01823846885838709,
      "loss": 0.541,
      "step": 507120
    },
    {
      "epoch": 817.97,
      "learning_rate": 0.018235243055161287,
      "loss": 0.5422,
      "step": 507140
    },
    {
      "epoch": 818.0,
      "learning_rate": 0.01823201725193548,
      "loss": 0.5354,
      "step": 507160
    },
    {
      "epoch": 818.0,
      "eval_accuracy": {
        "accuracy": 0.785809070330185
      },
      "eval_loss": 0.899999737739563,
      "eval_runtime": 3.3128,
      "eval_samples_per_second": 3867.152,
      "eval_steps_per_second": 60.674,
      "step": 507160
    },
    {
      "epoch": 818.03,
      "learning_rate": 0.018228791448709675,
      "loss": 0.537,
      "step": 507180
    },
    {
      "epoch": 818.06,
      "learning_rate": 0.01822556564548387,
      "loss": 0.5239,
      "step": 507200
    },
    {
      "epoch": 818.1,
      "learning_rate": 0.018222339842258062,
      "loss": 0.5289,
      "step": 507220
    },
    {
      "epoch": 818.13,
      "learning_rate": 0.018219114039032258,
      "loss": 0.5392,
      "step": 507240
    },
    {
      "epoch": 818.16,
      "learning_rate": 0.01821588823580645,
      "loss": 0.5387,
      "step": 507260
    },
    {
      "epoch": 818.19,
      "learning_rate": 0.018212662432580646,
      "loss": 0.5426,
      "step": 507280
    },
    {
      "epoch": 818.23,
      "learning_rate": 0.01820943662935484,
      "loss": 0.5267,
      "step": 507300
    },
    {
      "epoch": 818.26,
      "learning_rate": 0.018206210826129034,
      "loss": 0.5329,
      "step": 507320
    },
    {
      "epoch": 818.29,
      "learning_rate": 0.01820298502290323,
      "loss": 0.5387,
      "step": 507340
    },
    {
      "epoch": 818.32,
      "learning_rate": 0.018199759219677425,
      "loss": 0.5357,
      "step": 507360
    },
    {
      "epoch": 818.35,
      "learning_rate": 0.018196533416451617,
      "loss": 0.5338,
      "step": 507380
    },
    {
      "epoch": 818.39,
      "learning_rate": 0.018193307613225813,
      "loss": 0.5298,
      "step": 507400
    },
    {
      "epoch": 818.42,
      "learning_rate": 0.018190081809999994,
      "loss": 0.5279,
      "step": 507420
    },
    {
      "epoch": 818.45,
      "learning_rate": 0.01818685600677419,
      "loss": 0.5389,
      "step": 507440
    },
    {
      "epoch": 818.48,
      "learning_rate": 0.018183630203548382,
      "loss": 0.5291,
      "step": 507460
    },
    {
      "epoch": 818.52,
      "learning_rate": 0.018180404400322578,
      "loss": 0.5404,
      "step": 507480
    },
    {
      "epoch": 818.55,
      "learning_rate": 0.018177178597096773,
      "loss": 0.5458,
      "step": 507500
    },
    {
      "epoch": 818.58,
      "learning_rate": 0.018173952793870966,
      "loss": 0.527,
      "step": 507520
    },
    {
      "epoch": 818.61,
      "learning_rate": 0.01817072699064516,
      "loss": 0.5285,
      "step": 507540
    },
    {
      "epoch": 818.65,
      "learning_rate": 0.018167501187419353,
      "loss": 0.547,
      "step": 507560
    },
    {
      "epoch": 818.68,
      "learning_rate": 0.01816427538419355,
      "loss": 0.5471,
      "step": 507580
    },
    {
      "epoch": 818.71,
      "learning_rate": 0.018161049580967745,
      "loss": 0.5376,
      "step": 507600
    },
    {
      "epoch": 818.74,
      "learning_rate": 0.018157823777741937,
      "loss": 0.5447,
      "step": 507620
    },
    {
      "epoch": 818.77,
      "learning_rate": 0.018154597974516132,
      "loss": 0.5483,
      "step": 507640
    },
    {
      "epoch": 818.81,
      "learning_rate": 0.018151372171290325,
      "loss": 0.5202,
      "step": 507660
    },
    {
      "epoch": 818.84,
      "learning_rate": 0.01814814636806452,
      "loss": 0.5316,
      "step": 507680
    },
    {
      "epoch": 818.87,
      "learning_rate": 0.018144920564838716,
      "loss": 0.5322,
      "step": 507700
    },
    {
      "epoch": 818.9,
      "learning_rate": 0.018141694761612898,
      "loss": 0.5301,
      "step": 507720
    },
    {
      "epoch": 818.94,
      "learning_rate": 0.018138468958387093,
      "loss": 0.5313,
      "step": 507740
    },
    {
      "epoch": 818.97,
      "learning_rate": 0.018135243155161285,
      "loss": 0.5427,
      "step": 507760
    },
    {
      "epoch": 819.0,
      "learning_rate": 0.01813201735193548,
      "loss": 0.5445,
      "step": 507780
    },
    {
      "epoch": 819.0,
      "eval_accuracy": {
        "accuracy": 0.7841698540316915
      },
      "eval_loss": 0.8931499719619751,
      "eval_runtime": 3.5711,
      "eval_samples_per_second": 3587.413,
      "eval_steps_per_second": 56.285,
      "step": 507780
    },
    {
      "epoch": 819.03,
      "learning_rate": 0.018128791548709673,
      "loss": 0.5429,
      "step": 507800
    },
    {
      "epoch": 819.06,
      "learning_rate": 0.01812556574548387,
      "loss": 0.5346,
      "step": 507820
    },
    {
      "epoch": 819.1,
      "learning_rate": 0.018122339942258064,
      "loss": 0.523,
      "step": 507840
    },
    {
      "epoch": 819.13,
      "learning_rate": 0.018119114139032257,
      "loss": 0.5295,
      "step": 507860
    },
    {
      "epoch": 819.16,
      "learning_rate": 0.018115888335806452,
      "loss": 0.5362,
      "step": 507880
    },
    {
      "epoch": 819.19,
      "learning_rate": 0.018112662532580648,
      "loss": 0.5355,
      "step": 507900
    },
    {
      "epoch": 819.23,
      "learning_rate": 0.01810943672935484,
      "loss": 0.5259,
      "step": 507920
    },
    {
      "epoch": 819.26,
      "learning_rate": 0.018106210926129036,
      "loss": 0.5221,
      "step": 507940
    },
    {
      "epoch": 819.29,
      "learning_rate": 0.018102985122903228,
      "loss": 0.5338,
      "step": 507960
    },
    {
      "epoch": 819.32,
      "learning_rate": 0.018099759319677423,
      "loss": 0.516,
      "step": 507980
    },
    {
      "epoch": 819.35,
      "learning_rate": 0.01809653351645162,
      "loss": 0.5353,
      "step": 508000
    },
    {
      "epoch": 819.39,
      "learning_rate": 0.01809330771322581,
      "loss": 0.5348,
      "step": 508020
    },
    {
      "epoch": 819.42,
      "learning_rate": 0.018090081909999996,
      "loss": 0.5284,
      "step": 508040
    },
    {
      "epoch": 819.45,
      "learning_rate": 0.01808685610677419,
      "loss": 0.5356,
      "step": 508060
    },
    {
      "epoch": 819.48,
      "learning_rate": 0.018083630303548384,
      "loss": 0.5331,
      "step": 508080
    },
    {
      "epoch": 819.52,
      "learning_rate": 0.018080404500322576,
      "loss": 0.5277,
      "step": 508100
    },
    {
      "epoch": 819.55,
      "learning_rate": 0.018077178697096772,
      "loss": 0.5414,
      "step": 508120
    },
    {
      "epoch": 819.58,
      "learning_rate": 0.018073952893870968,
      "loss": 0.5442,
      "step": 508140
    },
    {
      "epoch": 819.61,
      "learning_rate": 0.01807072709064516,
      "loss": 0.5255,
      "step": 508160
    },
    {
      "epoch": 819.65,
      "learning_rate": 0.018067501287419355,
      "loss": 0.5336,
      "step": 508180
    },
    {
      "epoch": 819.68,
      "learning_rate": 0.018064275484193548,
      "loss": 0.5383,
      "step": 508200
    },
    {
      "epoch": 819.71,
      "learning_rate": 0.01806121097112903,
      "loss": 0.5393,
      "step": 508220
    },
    {
      "epoch": 819.74,
      "learning_rate": 0.01805798516790322,
      "loss": 0.5372,
      "step": 508240
    },
    {
      "epoch": 819.77,
      "learning_rate": 0.018054759364677417,
      "loss": 0.537,
      "step": 508260
    },
    {
      "epoch": 819.81,
      "learning_rate": 0.018051533561451612,
      "loss": 0.5381,
      "step": 508280
    },
    {
      "epoch": 819.84,
      "learning_rate": 0.018048307758225805,
      "loss": 0.5405,
      "step": 508300
    },
    {
      "epoch": 819.87,
      "learning_rate": 0.018045081955,
      "loss": 0.5464,
      "step": 508320
    },
    {
      "epoch": 819.9,
      "learning_rate": 0.018041856151774192,
      "loss": 0.5348,
      "step": 508340
    },
    {
      "epoch": 819.94,
      "learning_rate": 0.018038630348548388,
      "loss": 0.5366,
      "step": 508360
    },
    {
      "epoch": 819.97,
      "learning_rate": 0.018035404545322584,
      "loss": 0.5416,
      "step": 508380
    },
    {
      "epoch": 820.0,
      "learning_rate": 0.01803234003225806,
      "loss": 0.5389,
      "step": 508400
    },
    {
      "epoch": 820.0,
      "eval_accuracy": {
        "accuracy": 0.7807353055967527
      },
      "eval_loss": 0.8970950245857239,
      "eval_runtime": 2.9653,
      "eval_samples_per_second": 4320.246,
      "eval_steps_per_second": 67.783,
      "step": 508400
    },
    {
      "epoch": 820.03,
      "learning_rate": 0.018029114229032257,
      "loss": 0.5292,
      "step": 508420
    },
    {
      "epoch": 820.06,
      "learning_rate": 0.01802588842580645,
      "loss": 0.5366,
      "step": 508440
    },
    {
      "epoch": 820.1,
      "learning_rate": 0.018022662622580645,
      "loss": 0.5296,
      "step": 508460
    },
    {
      "epoch": 820.13,
      "learning_rate": 0.01801943681935484,
      "loss": 0.5232,
      "step": 508480
    },
    {
      "epoch": 820.16,
      "learning_rate": 0.018016211016129033,
      "loss": 0.5245,
      "step": 508500
    },
    {
      "epoch": 820.19,
      "learning_rate": 0.01801298521290323,
      "loss": 0.5263,
      "step": 508520
    },
    {
      "epoch": 820.23,
      "learning_rate": 0.01800975940967742,
      "loss": 0.5237,
      "step": 508540
    },
    {
      "epoch": 820.26,
      "learning_rate": 0.018006533606451616,
      "loss": 0.531,
      "step": 508560
    },
    {
      "epoch": 820.29,
      "learning_rate": 0.018003307803225812,
      "loss": 0.5345,
      "step": 508580
    },
    {
      "epoch": 820.32,
      "learning_rate": 0.018000082000000004,
      "loss": 0.5479,
      "step": 508600
    },
    {
      "epoch": 820.35,
      "learning_rate": 0.01799685619677419,
      "loss": 0.5399,
      "step": 508620
    },
    {
      "epoch": 820.39,
      "learning_rate": 0.01799363039354838,
      "loss": 0.5309,
      "step": 508640
    },
    {
      "epoch": 820.42,
      "learning_rate": 0.017990404590322577,
      "loss": 0.5386,
      "step": 508660
    },
    {
      "epoch": 820.45,
      "learning_rate": 0.01798717878709677,
      "loss": 0.5296,
      "step": 508680
    },
    {
      "epoch": 820.48,
      "learning_rate": 0.017983952983870965,
      "loss": 0.5368,
      "step": 508700
    },
    {
      "epoch": 820.52,
      "learning_rate": 0.01798072718064516,
      "loss": 0.5306,
      "step": 508720
    },
    {
      "epoch": 820.55,
      "learning_rate": 0.017977501377419353,
      "loss": 0.5177,
      "step": 508740
    },
    {
      "epoch": 820.58,
      "learning_rate": 0.017974275574193548,
      "loss": 0.5386,
      "step": 508760
    },
    {
      "epoch": 820.61,
      "learning_rate": 0.01797104977096774,
      "loss": 0.5368,
      "step": 508780
    },
    {
      "epoch": 820.65,
      "learning_rate": 0.017967823967741936,
      "loss": 0.5429,
      "step": 508800
    },
    {
      "epoch": 820.68,
      "learning_rate": 0.01796459816451613,
      "loss": 0.5404,
      "step": 508820
    },
    {
      "epoch": 820.71,
      "learning_rate": 0.017961372361290324,
      "loss": 0.5416,
      "step": 508840
    },
    {
      "epoch": 820.74,
      "learning_rate": 0.01795814655806452,
      "loss": 0.5429,
      "step": 508860
    },
    {
      "epoch": 820.77,
      "learning_rate": 0.017954920754838715,
      "loss": 0.5321,
      "step": 508880
    },
    {
      "epoch": 820.81,
      "learning_rate": 0.017951694951612907,
      "loss": 0.5364,
      "step": 508900
    },
    {
      "epoch": 820.84,
      "learning_rate": 0.017948469148387103,
      "loss": 0.5351,
      "step": 508920
    },
    {
      "epoch": 820.87,
      "learning_rate": 0.017945243345161285,
      "loss": 0.5232,
      "step": 508940
    },
    {
      "epoch": 820.9,
      "learning_rate": 0.01794201754193548,
      "loss": 0.5196,
      "step": 508960
    },
    {
      "epoch": 820.94,
      "learning_rate": 0.017938791738709672,
      "loss": 0.5442,
      "step": 508980
    },
    {
      "epoch": 820.97,
      "learning_rate": 0.017935565935483868,
      "loss": 0.5323,
      "step": 509000
    },
    {
      "epoch": 821.0,
      "learning_rate": 0.017932340132258064,
      "loss": 0.5343,
      "step": 509020
    },
    {
      "epoch": 821.0,
      "eval_accuracy": {
        "accuracy": 0.7868238232768714
      },
      "eval_loss": 0.8824292421340942,
      "eval_runtime": 4.0918,
      "eval_samples_per_second": 3130.91,
      "eval_steps_per_second": 49.123,
      "step": 509020
    },
    {
      "epoch": 821.03,
      "learning_rate": 0.017929114329032256,
      "loss": 0.5441,
      "step": 509040
    },
    {
      "epoch": 821.06,
      "learning_rate": 0.01792588852580645,
      "loss": 0.5373,
      "step": 509060
    },
    {
      "epoch": 821.1,
      "learning_rate": 0.017922662722580644,
      "loss": 0.5254,
      "step": 509080
    },
    {
      "epoch": 821.13,
      "learning_rate": 0.01791943691935484,
      "loss": 0.5234,
      "step": 509100
    },
    {
      "epoch": 821.16,
      "learning_rate": 0.017916211116129035,
      "loss": 0.5292,
      "step": 509120
    },
    {
      "epoch": 821.19,
      "learning_rate": 0.017912985312903227,
      "loss": 0.5347,
      "step": 509140
    },
    {
      "epoch": 821.23,
      "learning_rate": 0.017909759509677423,
      "loss": 0.5327,
      "step": 509160
    },
    {
      "epoch": 821.26,
      "learning_rate": 0.017906533706451615,
      "loss": 0.5435,
      "step": 509180
    },
    {
      "epoch": 821.29,
      "learning_rate": 0.01790330790322581,
      "loss": 0.5421,
      "step": 509200
    },
    {
      "epoch": 821.32,
      "learning_rate": 0.017900082100000006,
      "loss": 0.5254,
      "step": 509220
    },
    {
      "epoch": 821.35,
      "learning_rate": 0.017896856296774198,
      "loss": 0.5221,
      "step": 509240
    },
    {
      "epoch": 821.39,
      "learning_rate": 0.017893630493548383,
      "loss": 0.5281,
      "step": 509260
    },
    {
      "epoch": 821.42,
      "learning_rate": 0.017890404690322576,
      "loss": 0.5412,
      "step": 509280
    },
    {
      "epoch": 821.45,
      "learning_rate": 0.01788717888709677,
      "loss": 0.5272,
      "step": 509300
    },
    {
      "epoch": 821.48,
      "learning_rate": 0.017883953083870963,
      "loss": 0.5304,
      "step": 509320
    },
    {
      "epoch": 821.52,
      "learning_rate": 0.01788072728064516,
      "loss": 0.5471,
      "step": 509340
    },
    {
      "epoch": 821.55,
      "learning_rate": 0.017877501477419355,
      "loss": 0.5231,
      "step": 509360
    },
    {
      "epoch": 821.58,
      "learning_rate": 0.017874275674193547,
      "loss": 0.5401,
      "step": 509380
    },
    {
      "epoch": 821.61,
      "learning_rate": 0.017871049870967742,
      "loss": 0.5365,
      "step": 509400
    },
    {
      "epoch": 821.65,
      "learning_rate": 0.017867824067741934,
      "loss": 0.5298,
      "step": 509420
    },
    {
      "epoch": 821.68,
      "learning_rate": 0.01786459826451613,
      "loss": 0.537,
      "step": 509440
    },
    {
      "epoch": 821.71,
      "learning_rate": 0.017861372461290326,
      "loss": 0.5246,
      "step": 509460
    },
    {
      "epoch": 821.74,
      "learning_rate": 0.017858146658064518,
      "loss": 0.5348,
      "step": 509480
    },
    {
      "epoch": 821.77,
      "learning_rate": 0.017854920854838714,
      "loss": 0.5316,
      "step": 509500
    },
    {
      "epoch": 821.81,
      "learning_rate": 0.01785169505161291,
      "loss": 0.5433,
      "step": 509520
    },
    {
      "epoch": 821.84,
      "learning_rate": 0.0178484692483871,
      "loss": 0.5397,
      "step": 509540
    },
    {
      "epoch": 821.87,
      "learning_rate": 0.017845243445161287,
      "loss": 0.5319,
      "step": 509560
    },
    {
      "epoch": 821.9,
      "learning_rate": 0.01784201764193548,
      "loss": 0.5397,
      "step": 509580
    },
    {
      "epoch": 821.94,
      "learning_rate": 0.017838791838709674,
      "loss": 0.5427,
      "step": 509600
    },
    {
      "epoch": 821.97,
      "learning_rate": 0.017835566035483866,
      "loss": 0.5306,
      "step": 509620
    },
    {
      "epoch": 822.0,
      "learning_rate": 0.017832340232258062,
      "loss": 0.5382,
      "step": 509640
    },
    {
      "epoch": 822.0,
      "eval_accuracy": {
        "accuracy": 0.781281711029584
      },
      "eval_loss": 0.9040096998214722,
      "eval_runtime": 3.2493,
      "eval_samples_per_second": 3942.712,
      "eval_steps_per_second": 61.86,
      "step": 509640
    },
    {
      "epoch": 822.03,
      "learning_rate": 0.017829114429032258,
      "loss": 0.5319,
      "step": 509660
    },
    {
      "epoch": 822.06,
      "learning_rate": 0.01782588862580645,
      "loss": 0.5251,
      "step": 509680
    },
    {
      "epoch": 822.1,
      "learning_rate": 0.017822662822580645,
      "loss": 0.5256,
      "step": 509700
    },
    {
      "epoch": 822.13,
      "learning_rate": 0.017819437019354838,
      "loss": 0.5296,
      "step": 509720
    },
    {
      "epoch": 822.16,
      "learning_rate": 0.017816211216129033,
      "loss": 0.5222,
      "step": 509740
    },
    {
      "epoch": 822.19,
      "learning_rate": 0.01781298541290323,
      "loss": 0.5176,
      "step": 509760
    },
    {
      "epoch": 822.23,
      "learning_rate": 0.01780975960967742,
      "loss": 0.5373,
      "step": 509780
    },
    {
      "epoch": 822.26,
      "learning_rate": 0.017806533806451617,
      "loss": 0.5228,
      "step": 509800
    },
    {
      "epoch": 822.29,
      "learning_rate": 0.01780330800322581,
      "loss": 0.5327,
      "step": 509820
    },
    {
      "epoch": 822.32,
      "learning_rate": 0.017800082200000004,
      "loss": 0.5327,
      "step": 509840
    },
    {
      "epoch": 822.35,
      "learning_rate": 0.0177968563967742,
      "loss": 0.5366,
      "step": 509860
    },
    {
      "epoch": 822.39,
      "learning_rate": 0.017793630593548382,
      "loss": 0.5308,
      "step": 509880
    },
    {
      "epoch": 822.42,
      "learning_rate": 0.017790404790322577,
      "loss": 0.5362,
      "step": 509900
    },
    {
      "epoch": 822.45,
      "learning_rate": 0.01778717898709677,
      "loss": 0.5448,
      "step": 509920
    },
    {
      "epoch": 822.48,
      "learning_rate": 0.017783953183870965,
      "loss": 0.5318,
      "step": 509940
    },
    {
      "epoch": 822.52,
      "learning_rate": 0.017780727380645157,
      "loss": 0.535,
      "step": 509960
    },
    {
      "epoch": 822.55,
      "learning_rate": 0.017777501577419353,
      "loss": 0.5455,
      "step": 509980
    },
    {
      "epoch": 822.58,
      "learning_rate": 0.01777427577419355,
      "loss": 0.5264,
      "step": 510000
    },
    {
      "epoch": 822.61,
      "learning_rate": 0.01777104997096774,
      "loss": 0.5342,
      "step": 510020
    },
    {
      "epoch": 822.65,
      "learning_rate": 0.017767824167741936,
      "loss": 0.5312,
      "step": 510040
    },
    {
      "epoch": 822.68,
      "learning_rate": 0.017764598364516132,
      "loss": 0.5411,
      "step": 510060
    },
    {
      "epoch": 822.71,
      "learning_rate": 0.017761372561290324,
      "loss": 0.5259,
      "step": 510080
    },
    {
      "epoch": 822.74,
      "learning_rate": 0.01775814675806452,
      "loss": 0.5278,
      "step": 510100
    },
    {
      "epoch": 822.77,
      "learning_rate": 0.017754920954838712,
      "loss": 0.5243,
      "step": 510120
    },
    {
      "epoch": 822.81,
      "learning_rate": 0.017751695151612908,
      "loss": 0.5396,
      "step": 510140
    },
    {
      "epoch": 822.84,
      "learning_rate": 0.017748469348387103,
      "loss": 0.5408,
      "step": 510160
    },
    {
      "epoch": 822.87,
      "learning_rate": 0.017745243545161285,
      "loss": 0.5348,
      "step": 510180
    },
    {
      "epoch": 822.9,
      "learning_rate": 0.01774201774193548,
      "loss": 0.5362,
      "step": 510200
    },
    {
      "epoch": 822.94,
      "learning_rate": 0.017738791938709673,
      "loss": 0.5345,
      "step": 510220
    },
    {
      "epoch": 822.97,
      "learning_rate": 0.01773556613548387,
      "loss": 0.5324,
      "step": 510240
    },
    {
      "epoch": 823.0,
      "learning_rate": 0.01773234033225806,
      "loss": 0.5412,
      "step": 510260
    },
    {
      "epoch": 823.0,
      "eval_accuracy": {
        "accuracy": 0.786511591600968
      },
      "eval_loss": 0.9003509879112244,
      "eval_runtime": 3.2147,
      "eval_samples_per_second": 3985.147,
      "eval_steps_per_second": 62.526,
      "step": 510260
    },
    {
      "epoch": 823.03,
      "learning_rate": 0.017729114529032256,
      "loss": 0.5458,
      "step": 510280
    },
    {
      "epoch": 823.06,
      "learning_rate": 0.017725888725806452,
      "loss": 0.5424,
      "step": 510300
    },
    {
      "epoch": 823.1,
      "learning_rate": 0.017722662922580644,
      "loss": 0.5284,
      "step": 510320
    },
    {
      "epoch": 823.13,
      "learning_rate": 0.01771943711935484,
      "loss": 0.5277,
      "step": 510340
    },
    {
      "epoch": 823.16,
      "learning_rate": 0.017716211316129032,
      "loss": 0.5209,
      "step": 510360
    },
    {
      "epoch": 823.19,
      "learning_rate": 0.017712985512903227,
      "loss": 0.523,
      "step": 510380
    },
    {
      "epoch": 823.23,
      "learning_rate": 0.017709759709677423,
      "loss": 0.5219,
      "step": 510400
    },
    {
      "epoch": 823.26,
      "learning_rate": 0.017706533906451615,
      "loss": 0.5329,
      "step": 510420
    },
    {
      "epoch": 823.29,
      "learning_rate": 0.01770330810322581,
      "loss": 0.5386,
      "step": 510440
    },
    {
      "epoch": 823.32,
      "learning_rate": 0.017700082300000003,
      "loss": 0.5423,
      "step": 510460
    },
    {
      "epoch": 823.35,
      "learning_rate": 0.0176968564967742,
      "loss": 0.536,
      "step": 510480
    },
    {
      "epoch": 823.39,
      "learning_rate": 0.01769363069354838,
      "loss": 0.5458,
      "step": 510500
    },
    {
      "epoch": 823.42,
      "learning_rate": 0.017690404890322576,
      "loss": 0.5362,
      "step": 510520
    },
    {
      "epoch": 823.45,
      "learning_rate": 0.01768717908709677,
      "loss": 0.5272,
      "step": 510540
    },
    {
      "epoch": 823.48,
      "learning_rate": 0.017683953283870964,
      "loss": 0.5387,
      "step": 510560
    },
    {
      "epoch": 823.52,
      "learning_rate": 0.01768072748064516,
      "loss": 0.527,
      "step": 510580
    },
    {
      "epoch": 823.55,
      "learning_rate": 0.01767750167741935,
      "loss": 0.5285,
      "step": 510600
    },
    {
      "epoch": 823.58,
      "learning_rate": 0.017674275874193547,
      "loss": 0.5299,
      "step": 510620
    },
    {
      "epoch": 823.61,
      "learning_rate": 0.017671050070967743,
      "loss": 0.5409,
      "step": 510640
    },
    {
      "epoch": 823.65,
      "learning_rate": 0.017667824267741935,
      "loss": 0.545,
      "step": 510660
    },
    {
      "epoch": 823.68,
      "learning_rate": 0.01766459846451613,
      "loss": 0.5282,
      "step": 510680
    },
    {
      "epoch": 823.71,
      "learning_rate": 0.017661372661290326,
      "loss": 0.5286,
      "step": 510700
    },
    {
      "epoch": 823.74,
      "learning_rate": 0.01765814685806452,
      "loss": 0.53,
      "step": 510720
    },
    {
      "epoch": 823.77,
      "learning_rate": 0.017654921054838714,
      "loss": 0.5399,
      "step": 510740
    },
    {
      "epoch": 823.81,
      "learning_rate": 0.017651695251612906,
      "loss": 0.529,
      "step": 510760
    },
    {
      "epoch": 823.84,
      "learning_rate": 0.0176484694483871,
      "loss": 0.5324,
      "step": 510780
    },
    {
      "epoch": 823.87,
      "learning_rate": 0.017645243645161283,
      "loss": 0.534,
      "step": 510800
    },
    {
      "epoch": 823.9,
      "learning_rate": 0.01764201784193548,
      "loss": 0.5386,
      "step": 510820
    },
    {
      "epoch": 823.94,
      "learning_rate": 0.017638792038709675,
      "loss": 0.5286,
      "step": 510840
    },
    {
      "epoch": 823.97,
      "learning_rate": 0.017635566235483867,
      "loss": 0.5332,
      "step": 510860
    },
    {
      "epoch": 824.0,
      "learning_rate": 0.017632340432258062,
      "loss": 0.5241,
      "step": 510880
    },
    {
      "epoch": 824.0,
      "eval_accuracy": {
        "accuracy": 0.7833892748419327
      },
      "eval_loss": 0.9000536203384399,
      "eval_runtime": 3.083,
      "eval_samples_per_second": 4155.419,
      "eval_steps_per_second": 65.197,
      "step": 510880
    },
    {
      "epoch": 824.03,
      "learning_rate": 0.017629114629032255,
      "loss": 0.5312,
      "step": 510900
    },
    {
      "epoch": 824.06,
      "learning_rate": 0.01762588882580645,
      "loss": 0.5231,
      "step": 510920
    },
    {
      "epoch": 824.1,
      "learning_rate": 0.017622663022580646,
      "loss": 0.5253,
      "step": 510940
    },
    {
      "epoch": 824.13,
      "learning_rate": 0.017619437219354838,
      "loss": 0.5418,
      "step": 510960
    },
    {
      "epoch": 824.16,
      "learning_rate": 0.017616211416129034,
      "loss": 0.5229,
      "step": 510980
    },
    {
      "epoch": 824.19,
      "learning_rate": 0.017612985612903226,
      "loss": 0.5237,
      "step": 511000
    },
    {
      "epoch": 824.23,
      "learning_rate": 0.01760975980967742,
      "loss": 0.5269,
      "step": 511020
    },
    {
      "epoch": 824.26,
      "learning_rate": 0.017606534006451617,
      "loss": 0.5327,
      "step": 511040
    },
    {
      "epoch": 824.29,
      "learning_rate": 0.01760330820322581,
      "loss": 0.5267,
      "step": 511060
    },
    {
      "epoch": 824.32,
      "learning_rate": 0.017600082400000005,
      "loss": 0.5233,
      "step": 511080
    },
    {
      "epoch": 824.35,
      "learning_rate": 0.017596856596774197,
      "loss": 0.5339,
      "step": 511100
    },
    {
      "epoch": 824.39,
      "learning_rate": 0.017593630793548382,
      "loss": 0.5342,
      "step": 511120
    },
    {
      "epoch": 824.42,
      "learning_rate": 0.017590404990322574,
      "loss": 0.5329,
      "step": 511140
    },
    {
      "epoch": 824.45,
      "learning_rate": 0.01758717918709677,
      "loss": 0.541,
      "step": 511160
    },
    {
      "epoch": 824.48,
      "learning_rate": 0.017583953383870966,
      "loss": 0.5296,
      "step": 511180
    },
    {
      "epoch": 824.52,
      "learning_rate": 0.017580727580645158,
      "loss": 0.526,
      "step": 511200
    },
    {
      "epoch": 824.55,
      "learning_rate": 0.017577501777419353,
      "loss": 0.5306,
      "step": 511220
    },
    {
      "epoch": 824.58,
      "learning_rate": 0.01757427597419355,
      "loss": 0.524,
      "step": 511240
    },
    {
      "epoch": 824.61,
      "learning_rate": 0.01757105017096774,
      "loss": 0.5253,
      "step": 511260
    },
    {
      "epoch": 824.65,
      "learning_rate": 0.017567824367741937,
      "loss": 0.5374,
      "step": 511280
    },
    {
      "epoch": 824.68,
      "learning_rate": 0.01756459856451613,
      "loss": 0.5303,
      "step": 511300
    },
    {
      "epoch": 824.71,
      "learning_rate": 0.017561372761290325,
      "loss": 0.5248,
      "step": 511320
    },
    {
      "epoch": 824.74,
      "learning_rate": 0.01755814695806452,
      "loss": 0.5281,
      "step": 511340
    },
    {
      "epoch": 824.77,
      "learning_rate": 0.017554921154838712,
      "loss": 0.5241,
      "step": 511360
    },
    {
      "epoch": 824.81,
      "learning_rate": 0.017551695351612908,
      "loss": 0.5365,
      "step": 511380
    },
    {
      "epoch": 824.84,
      "learning_rate": 0.0175484695483871,
      "loss": 0.5348,
      "step": 511400
    },
    {
      "epoch": 824.87,
      "learning_rate": 0.017545243745161285,
      "loss": 0.5405,
      "step": 511420
    },
    {
      "epoch": 824.9,
      "learning_rate": 0.017542017941935478,
      "loss": 0.5314,
      "step": 511440
    },
    {
      "epoch": 824.94,
      "learning_rate": 0.017538792138709673,
      "loss": 0.5462,
      "step": 511460
    },
    {
      "epoch": 824.97,
      "learning_rate": 0.01753556633548387,
      "loss": 0.5416,
      "step": 511480
    },
    {
      "epoch": 825.0,
      "learning_rate": 0.01753234053225806,
      "loss": 0.535,
      "step": 511500
    },
    {
      "epoch": 825.0,
      "eval_accuracy": {
        "accuracy": 0.7833112169229568
      },
      "eval_loss": 0.8989518880844116,
      "eval_runtime": 3.1355,
      "eval_samples_per_second": 4085.761,
      "eval_steps_per_second": 64.104,
      "step": 511500
    },
    {
      "epoch": 825.03,
      "learning_rate": 0.017529114729032257,
      "loss": 0.5464,
      "step": 511520
    },
    {
      "epoch": 825.06,
      "learning_rate": 0.01752588892580645,
      "loss": 0.5257,
      "step": 511540
    },
    {
      "epoch": 825.1,
      "learning_rate": 0.017522663122580644,
      "loss": 0.5241,
      "step": 511560
    },
    {
      "epoch": 825.13,
      "learning_rate": 0.01751943731935484,
      "loss": 0.5342,
      "step": 511580
    },
    {
      "epoch": 825.16,
      "learning_rate": 0.017516211516129032,
      "loss": 0.5308,
      "step": 511600
    },
    {
      "epoch": 825.19,
      "learning_rate": 0.017512985712903228,
      "loss": 0.521,
      "step": 511620
    },
    {
      "epoch": 825.23,
      "learning_rate": 0.01750975990967742,
      "loss": 0.5332,
      "step": 511640
    },
    {
      "epoch": 825.26,
      "learning_rate": 0.017506534106451616,
      "loss": 0.5313,
      "step": 511660
    },
    {
      "epoch": 825.29,
      "learning_rate": 0.01750330830322581,
      "loss": 0.5361,
      "step": 511680
    },
    {
      "epoch": 825.32,
      "learning_rate": 0.017500082500000003,
      "loss": 0.5375,
      "step": 511700
    },
    {
      "epoch": 825.35,
      "learning_rate": 0.0174968566967742,
      "loss": 0.5397,
      "step": 511720
    },
    {
      "epoch": 825.39,
      "learning_rate": 0.01749363089354838,
      "loss": 0.5271,
      "step": 511740
    },
    {
      "epoch": 825.42,
      "learning_rate": 0.017490405090322576,
      "loss": 0.5207,
      "step": 511760
    },
    {
      "epoch": 825.45,
      "learning_rate": 0.017487179287096772,
      "loss": 0.5202,
      "step": 511780
    },
    {
      "epoch": 825.48,
      "learning_rate": 0.017483953483870964,
      "loss": 0.5318,
      "step": 511800
    },
    {
      "epoch": 825.52,
      "learning_rate": 0.01748072768064516,
      "loss": 0.5271,
      "step": 511820
    },
    {
      "epoch": 825.55,
      "learning_rate": 0.017477501877419352,
      "loss": 0.5274,
      "step": 511840
    },
    {
      "epoch": 825.58,
      "learning_rate": 0.017474276074193548,
      "loss": 0.534,
      "step": 511860
    },
    {
      "epoch": 825.61,
      "learning_rate": 0.017471050270967743,
      "loss": 0.529,
      "step": 511880
    },
    {
      "epoch": 825.65,
      "learning_rate": 0.017467824467741935,
      "loss": 0.5443,
      "step": 511900
    },
    {
      "epoch": 825.68,
      "learning_rate": 0.01746459866451613,
      "loss": 0.5309,
      "step": 511920
    },
    {
      "epoch": 825.71,
      "learning_rate": 0.017461372861290323,
      "loss": 0.551,
      "step": 511940
    },
    {
      "epoch": 825.74,
      "learning_rate": 0.01745814705806452,
      "loss": 0.5381,
      "step": 511960
    },
    {
      "epoch": 825.77,
      "learning_rate": 0.017454921254838714,
      "loss": 0.522,
      "step": 511980
    },
    {
      "epoch": 825.81,
      "learning_rate": 0.017451695451612907,
      "loss": 0.5232,
      "step": 512000
    },
    {
      "epoch": 825.84,
      "learning_rate": 0.017448469648387102,
      "loss": 0.5353,
      "step": 512020
    },
    {
      "epoch": 825.87,
      "learning_rate": 0.017445243845161294,
      "loss": 0.5195,
      "step": 512040
    },
    {
      "epoch": 825.9,
      "learning_rate": 0.01744201804193548,
      "loss": 0.5473,
      "step": 512060
    },
    {
      "epoch": 825.94,
      "learning_rate": 0.01743879223870967,
      "loss": 0.5298,
      "step": 512080
    },
    {
      "epoch": 825.97,
      "learning_rate": 0.017435566435483867,
      "loss": 0.544,
      "step": 512100
    },
    {
      "epoch": 826.0,
      "learning_rate": 0.017432340632258063,
      "loss": 0.5372,
      "step": 512120
    },
    {
      "epoch": 826.0,
      "eval_accuracy": {
        "accuracy": 0.7858871282491608
      },
      "eval_loss": 0.8944194316864014,
      "eval_runtime": 4.2386,
      "eval_samples_per_second": 3022.466,
      "eval_steps_per_second": 47.421,
      "step": 512120
    },
    {
      "epoch": 826.03,
      "learning_rate": 0.017429114829032255,
      "loss": 0.533,
      "step": 512140
    },
    {
      "epoch": 826.06,
      "learning_rate": 0.01742588902580645,
      "loss": 0.5197,
      "step": 512160
    },
    {
      "epoch": 826.1,
      "learning_rate": 0.017422663222580643,
      "loss": 0.5306,
      "step": 512180
    },
    {
      "epoch": 826.13,
      "learning_rate": 0.01741943741935484,
      "loss": 0.5214,
      "step": 512200
    },
    {
      "epoch": 826.16,
      "learning_rate": 0.017416211616129034,
      "loss": 0.5249,
      "step": 512220
    },
    {
      "epoch": 826.19,
      "learning_rate": 0.017412985812903226,
      "loss": 0.5341,
      "step": 512240
    },
    {
      "epoch": 826.23,
      "learning_rate": 0.017409760009677422,
      "loss": 0.5338,
      "step": 512260
    },
    {
      "epoch": 826.26,
      "learning_rate": 0.017406534206451614,
      "loss": 0.5368,
      "step": 512280
    },
    {
      "epoch": 826.29,
      "learning_rate": 0.01740330840322581,
      "loss": 0.5338,
      "step": 512300
    },
    {
      "epoch": 826.32,
      "learning_rate": 0.017400082600000005,
      "loss": 0.5333,
      "step": 512320
    },
    {
      "epoch": 826.35,
      "learning_rate": 0.017396856796774197,
      "loss": 0.5224,
      "step": 512340
    },
    {
      "epoch": 826.39,
      "learning_rate": 0.017393630993548383,
      "loss": 0.5463,
      "step": 512360
    },
    {
      "epoch": 826.42,
      "learning_rate": 0.017390405190322575,
      "loss": 0.5312,
      "step": 512380
    },
    {
      "epoch": 826.45,
      "learning_rate": 0.01738717938709677,
      "loss": 0.5228,
      "step": 512400
    },
    {
      "epoch": 826.48,
      "learning_rate": 0.017384114874032262,
      "loss": 0.5187,
      "step": 512420
    },
    {
      "epoch": 826.52,
      "learning_rate": 0.017380889070806455,
      "loss": 0.5341,
      "step": 512440
    },
    {
      "epoch": 826.55,
      "learning_rate": 0.01737766326758065,
      "loss": 0.535,
      "step": 512460
    },
    {
      "epoch": 826.58,
      "learning_rate": 0.017374437464354842,
      "loss": 0.5338,
      "step": 512480
    },
    {
      "epoch": 826.61,
      "learning_rate": 0.017371211661129028,
      "loss": 0.5329,
      "step": 512500
    },
    {
      "epoch": 826.65,
      "learning_rate": 0.01736798585790322,
      "loss": 0.5364,
      "step": 512520
    },
    {
      "epoch": 826.68,
      "learning_rate": 0.017364760054677415,
      "loss": 0.5243,
      "step": 512540
    },
    {
      "epoch": 826.71,
      "learning_rate": 0.01736153425145161,
      "loss": 0.5438,
      "step": 512560
    },
    {
      "epoch": 826.74,
      "learning_rate": 0.017358308448225803,
      "loss": 0.5377,
      "step": 512580
    },
    {
      "epoch": 826.77,
      "learning_rate": 0.017355082645,
      "loss": 0.5265,
      "step": 512600
    },
    {
      "epoch": 826.81,
      "learning_rate": 0.01735185684177419,
      "loss": 0.5312,
      "step": 512620
    },
    {
      "epoch": 826.84,
      "learning_rate": 0.017348631038548386,
      "loss": 0.5271,
      "step": 512640
    },
    {
      "epoch": 826.87,
      "learning_rate": 0.017345405235322582,
      "loss": 0.532,
      "step": 512660
    },
    {
      "epoch": 826.9,
      "learning_rate": 0.017342179432096774,
      "loss": 0.5383,
      "step": 512680
    },
    {
      "epoch": 826.94,
      "learning_rate": 0.01733895362887097,
      "loss": 0.5286,
      "step": 512700
    },
    {
      "epoch": 826.97,
      "learning_rate": 0.017335727825645162,
      "loss": 0.5299,
      "step": 512720
    },
    {
      "epoch": 827.0,
      "learning_rate": 0.017332502022419358,
      "loss": 0.5179,
      "step": 512740
    },
    {
      "epoch": 827.0,
      "eval_accuracy": {
        "accuracy": 0.781906174381391
      },
      "eval_loss": 0.8969176411628723,
      "eval_runtime": 3.0028,
      "eval_samples_per_second": 4266.422,
      "eval_steps_per_second": 66.939,
      "step": 512740
    },
    {
      "epoch": 827.03,
      "learning_rate": 0.017329276219193553,
      "loss": 0.5288,
      "step": 512760
    },
    {
      "epoch": 827.06,
      "learning_rate": 0.017326050415967745,
      "loss": 0.5218,
      "step": 512780
    },
    {
      "epoch": 827.1,
      "learning_rate": 0.01732282461274194,
      "loss": 0.5263,
      "step": 512800
    },
    {
      "epoch": 827.13,
      "learning_rate": 0.017319598809516123,
      "loss": 0.5297,
      "step": 512820
    },
    {
      "epoch": 827.16,
      "learning_rate": 0.01731637300629032,
      "loss": 0.5282,
      "step": 512840
    },
    {
      "epoch": 827.19,
      "learning_rate": 0.017313147203064514,
      "loss": 0.5389,
      "step": 512860
    },
    {
      "epoch": 827.23,
      "learning_rate": 0.017309921399838706,
      "loss": 0.5373,
      "step": 512880
    },
    {
      "epoch": 827.26,
      "learning_rate": 0.017306695596612902,
      "loss": 0.5349,
      "step": 512900
    },
    {
      "epoch": 827.29,
      "learning_rate": 0.017303469793387094,
      "loss": 0.5325,
      "step": 512920
    },
    {
      "epoch": 827.32,
      "learning_rate": 0.01730024399016129,
      "loss": 0.5256,
      "step": 512940
    },
    {
      "epoch": 827.35,
      "learning_rate": 0.017297018186935485,
      "loss": 0.5308,
      "step": 512960
    },
    {
      "epoch": 827.39,
      "learning_rate": 0.017293792383709677,
      "loss": 0.514,
      "step": 512980
    },
    {
      "epoch": 827.42,
      "learning_rate": 0.017290566580483873,
      "loss": 0.5265,
      "step": 513000
    },
    {
      "epoch": 827.45,
      "learning_rate": 0.017287340777258065,
      "loss": 0.5307,
      "step": 513020
    },
    {
      "epoch": 827.48,
      "learning_rate": 0.01728411497403226,
      "loss": 0.5366,
      "step": 513040
    },
    {
      "epoch": 827.52,
      "learning_rate": 0.017280889170806456,
      "loss": 0.5325,
      "step": 513060
    },
    {
      "epoch": 827.55,
      "learning_rate": 0.01727766336758065,
      "loss": 0.5311,
      "step": 513080
    },
    {
      "epoch": 827.58,
      "learning_rate": 0.017274437564354844,
      "loss": 0.5208,
      "step": 513100
    },
    {
      "epoch": 827.61,
      "learning_rate": 0.017271211761129026,
      "loss": 0.5158,
      "step": 513120
    },
    {
      "epoch": 827.65,
      "learning_rate": 0.01726798595790322,
      "loss": 0.5267,
      "step": 513140
    },
    {
      "epoch": 827.68,
      "learning_rate": 0.017264760154677414,
      "loss": 0.5299,
      "step": 513160
    },
    {
      "epoch": 827.71,
      "learning_rate": 0.01726153435145161,
      "loss": 0.533,
      "step": 513180
    },
    {
      "epoch": 827.74,
      "learning_rate": 0.017258308548225805,
      "loss": 0.5264,
      "step": 513200
    },
    {
      "epoch": 827.77,
      "learning_rate": 0.017255082744999997,
      "loss": 0.5351,
      "step": 513220
    },
    {
      "epoch": 827.81,
      "learning_rate": 0.017251856941774193,
      "loss": 0.5409,
      "step": 513240
    },
    {
      "epoch": 827.84,
      "learning_rate": 0.017248631138548385,
      "loss": 0.5301,
      "step": 513260
    },
    {
      "epoch": 827.87,
      "learning_rate": 0.01724540533532258,
      "loss": 0.5389,
      "step": 513280
    },
    {
      "epoch": 827.9,
      "learning_rate": 0.017242179532096776,
      "loss": 0.5314,
      "step": 513300
    },
    {
      "epoch": 827.94,
      "learning_rate": 0.01723895372887097,
      "loss": 0.5287,
      "step": 513320
    },
    {
      "epoch": 827.97,
      "learning_rate": 0.017235727925645164,
      "loss": 0.5408,
      "step": 513340
    },
    {
      "epoch": 828.0,
      "learning_rate": 0.017232663412580642,
      "loss": 0.534,
      "step": 513360
    },
    {
      "epoch": 828.0,
      "eval_accuracy": {
        "accuracy": 0.7872921707907267
      },
      "eval_loss": 0.8861496448516846,
      "eval_runtime": 3.2761,
      "eval_samples_per_second": 3910.485,
      "eval_steps_per_second": 61.354,
      "step": 513360
    },
    {
      "epoch": 828.03,
      "learning_rate": 0.017229437609354838,
      "loss": 0.5202,
      "step": 513380
    },
    {
      "epoch": 828.06,
      "learning_rate": 0.017226211806129033,
      "loss": 0.5314,
      "step": 513400
    },
    {
      "epoch": 828.1,
      "learning_rate": 0.017222986002903225,
      "loss": 0.5267,
      "step": 513420
    },
    {
      "epoch": 828.13,
      "learning_rate": 0.01721976019967742,
      "loss": 0.5275,
      "step": 513440
    },
    {
      "epoch": 828.16,
      "learning_rate": 0.017216534396451613,
      "loss": 0.5106,
      "step": 513460
    },
    {
      "epoch": 828.19,
      "learning_rate": 0.01721330859322581,
      "loss": 0.5331,
      "step": 513480
    },
    {
      "epoch": 828.23,
      "learning_rate": 0.017210082790000004,
      "loss": 0.5281,
      "step": 513500
    },
    {
      "epoch": 828.26,
      "learning_rate": 0.017206856986774197,
      "loss": 0.5278,
      "step": 513520
    },
    {
      "epoch": 828.29,
      "learning_rate": 0.017203631183548392,
      "loss": 0.5256,
      "step": 513540
    },
    {
      "epoch": 828.32,
      "learning_rate": 0.017200405380322584,
      "loss": 0.5241,
      "step": 513560
    },
    {
      "epoch": 828.35,
      "learning_rate": 0.01719717957709677,
      "loss": 0.5324,
      "step": 513580
    },
    {
      "epoch": 828.39,
      "learning_rate": 0.017193953773870962,
      "loss": 0.5271,
      "step": 513600
    },
    {
      "epoch": 828.42,
      "learning_rate": 0.017190727970645157,
      "loss": 0.5176,
      "step": 513620
    },
    {
      "epoch": 828.45,
      "learning_rate": 0.017187502167419353,
      "loss": 0.5385,
      "step": 513640
    },
    {
      "epoch": 828.48,
      "learning_rate": 0.017184276364193545,
      "loss": 0.5231,
      "step": 513660
    },
    {
      "epoch": 828.52,
      "learning_rate": 0.01718105056096774,
      "loss": 0.5418,
      "step": 513680
    },
    {
      "epoch": 828.55,
      "learning_rate": 0.017177824757741933,
      "loss": 0.5275,
      "step": 513700
    },
    {
      "epoch": 828.58,
      "learning_rate": 0.01717459895451613,
      "loss": 0.538,
      "step": 513720
    },
    {
      "epoch": 828.61,
      "learning_rate": 0.017171373151290324,
      "loss": 0.5359,
      "step": 513740
    },
    {
      "epoch": 828.65,
      "learning_rate": 0.017168147348064516,
      "loss": 0.5255,
      "step": 513760
    },
    {
      "epoch": 828.68,
      "learning_rate": 0.017164921544838712,
      "loss": 0.5326,
      "step": 513780
    },
    {
      "epoch": 828.71,
      "learning_rate": 0.017161695741612904,
      "loss": 0.5344,
      "step": 513800
    },
    {
      "epoch": 828.74,
      "learning_rate": 0.0171584699383871,
      "loss": 0.5391,
      "step": 513820
    },
    {
      "epoch": 828.77,
      "learning_rate": 0.017155244135161295,
      "loss": 0.5345,
      "step": 513840
    },
    {
      "epoch": 828.81,
      "learning_rate": 0.017152018331935488,
      "loss": 0.5333,
      "step": 513860
    },
    {
      "epoch": 828.84,
      "learning_rate": 0.017148792528709683,
      "loss": 0.5319,
      "step": 513880
    },
    {
      "epoch": 828.87,
      "learning_rate": 0.017145566725483865,
      "loss": 0.5332,
      "step": 513900
    },
    {
      "epoch": 828.9,
      "learning_rate": 0.01714234092225806,
      "loss": 0.524,
      "step": 513920
    },
    {
      "epoch": 828.94,
      "learning_rate": 0.017139115119032256,
      "loss": 0.5419,
      "step": 513940
    },
    {
      "epoch": 828.97,
      "learning_rate": 0.01713588931580645,
      "loss": 0.5471,
      "step": 513960
    },
    {
      "epoch": 829.0,
      "learning_rate": 0.017132663512580644,
      "loss": 0.5339,
      "step": 513980
    },
    {
      "epoch": 829.0,
      "eval_accuracy": {
        "accuracy": 0.7816720006244634
      },
      "eval_loss": 0.9044102430343628,
      "eval_runtime": 3.2957,
      "eval_samples_per_second": 3887.188,
      "eval_steps_per_second": 60.989,
      "step": 513980
    },
    {
      "epoch": 829.03,
      "learning_rate": 0.017129437709354836,
      "loss": 0.5406,
      "step": 514000
    },
    {
      "epoch": 829.06,
      "learning_rate": 0.017126211906129032,
      "loss": 0.5225,
      "step": 514020
    },
    {
      "epoch": 829.1,
      "learning_rate": 0.017122986102903227,
      "loss": 0.5271,
      "step": 514040
    },
    {
      "epoch": 829.13,
      "learning_rate": 0.01711976029967742,
      "loss": 0.5308,
      "step": 514060
    },
    {
      "epoch": 829.16,
      "learning_rate": 0.017116534496451615,
      "loss": 0.5224,
      "step": 514080
    },
    {
      "epoch": 829.19,
      "learning_rate": 0.017113308693225807,
      "loss": 0.5287,
      "step": 514100
    },
    {
      "epoch": 829.23,
      "learning_rate": 0.017110082890000003,
      "loss": 0.5213,
      "step": 514120
    },
    {
      "epoch": 829.26,
      "learning_rate": 0.0171068570867742,
      "loss": 0.5325,
      "step": 514140
    },
    {
      "epoch": 829.29,
      "learning_rate": 0.01710363128354839,
      "loss": 0.525,
      "step": 514160
    },
    {
      "epoch": 829.32,
      "learning_rate": 0.017100405480322586,
      "loss": 0.5279,
      "step": 514180
    },
    {
      "epoch": 829.35,
      "learning_rate": 0.017097179677096768,
      "loss": 0.5297,
      "step": 514200
    },
    {
      "epoch": 829.39,
      "learning_rate": 0.017093953873870964,
      "loss": 0.5221,
      "step": 514220
    },
    {
      "epoch": 829.42,
      "learning_rate": 0.017090728070645156,
      "loss": 0.521,
      "step": 514240
    },
    {
      "epoch": 829.45,
      "learning_rate": 0.01708750226741935,
      "loss": 0.5181,
      "step": 514260
    },
    {
      "epoch": 829.48,
      "learning_rate": 0.017084276464193547,
      "loss": 0.535,
      "step": 514280
    },
    {
      "epoch": 829.52,
      "learning_rate": 0.01708105066096774,
      "loss": 0.5324,
      "step": 514300
    },
    {
      "epoch": 829.55,
      "learning_rate": 0.017077824857741935,
      "loss": 0.5322,
      "step": 514320
    },
    {
      "epoch": 829.58,
      "learning_rate": 0.017074599054516127,
      "loss": 0.5236,
      "step": 514340
    },
    {
      "epoch": 829.61,
      "learning_rate": 0.017071373251290323,
      "loss": 0.5258,
      "step": 514360
    },
    {
      "epoch": 829.65,
      "learning_rate": 0.01706814744806452,
      "loss": 0.5278,
      "step": 514380
    },
    {
      "epoch": 829.68,
      "learning_rate": 0.01706492164483871,
      "loss": 0.5372,
      "step": 514400
    },
    {
      "epoch": 829.71,
      "learning_rate": 0.017061695841612906,
      "loss": 0.5225,
      "step": 514420
    },
    {
      "epoch": 829.74,
      "learning_rate": 0.017058470038387098,
      "loss": 0.5244,
      "step": 514440
    },
    {
      "epoch": 829.77,
      "learning_rate": 0.017055244235161294,
      "loss": 0.5301,
      "step": 514460
    },
    {
      "epoch": 829.81,
      "learning_rate": 0.01705201843193549,
      "loss": 0.5191,
      "step": 514480
    },
    {
      "epoch": 829.84,
      "learning_rate": 0.01704879262870968,
      "loss": 0.5201,
      "step": 514500
    },
    {
      "epoch": 829.87,
      "learning_rate": 0.017045566825483867,
      "loss": 0.5343,
      "step": 514520
    },
    {
      "epoch": 829.9,
      "learning_rate": 0.01704234102225806,
      "loss": 0.5378,
      "step": 514540
    },
    {
      "epoch": 829.94,
      "learning_rate": 0.017039115219032255,
      "loss": 0.5323,
      "step": 514560
    },
    {
      "epoch": 829.97,
      "learning_rate": 0.01703588941580645,
      "loss": 0.5349,
      "step": 514580
    },
    {
      "epoch": 830.0,
      "learning_rate": 0.017032663612580642,
      "loss": 0.5419,
      "step": 514600
    },
    {
      "epoch": 830.0,
      "eval_accuracy": {
        "accuracy": 0.7888533291702443
      },
      "eval_loss": 0.8872954845428467,
      "eval_runtime": 3.0159,
      "eval_samples_per_second": 4247.83,
      "eval_steps_per_second": 66.647,
      "step": 514600
    },
    {
      "epoch": 830.03,
      "learning_rate": 0.017029437809354838,
      "loss": 0.5411,
      "step": 514620
    },
    {
      "epoch": 830.06,
      "learning_rate": 0.01702621200612903,
      "loss": 0.5322,
      "step": 514640
    },
    {
      "epoch": 830.1,
      "learning_rate": 0.017022986202903226,
      "loss": 0.5286,
      "step": 514660
    },
    {
      "epoch": 830.13,
      "learning_rate": 0.01701976039967742,
      "loss": 0.5204,
      "step": 514680
    },
    {
      "epoch": 830.16,
      "learning_rate": 0.017016534596451614,
      "loss": 0.5229,
      "step": 514700
    },
    {
      "epoch": 830.19,
      "learning_rate": 0.01701330879322581,
      "loss": 0.539,
      "step": 514720
    },
    {
      "epoch": 830.23,
      "learning_rate": 0.01701008299,
      "loss": 0.5362,
      "step": 514740
    },
    {
      "epoch": 830.26,
      "learning_rate": 0.017006857186774197,
      "loss": 0.5209,
      "step": 514760
    },
    {
      "epoch": 830.29,
      "learning_rate": 0.017003631383548393,
      "loss": 0.5202,
      "step": 514780
    },
    {
      "epoch": 830.32,
      "learning_rate": 0.017000405580322585,
      "loss": 0.5297,
      "step": 514800
    },
    {
      "epoch": 830.35,
      "learning_rate": 0.01699717977709677,
      "loss": 0.5425,
      "step": 514820
    },
    {
      "epoch": 830.39,
      "learning_rate": 0.016993953973870962,
      "loss": 0.5152,
      "step": 514840
    },
    {
      "epoch": 830.42,
      "learning_rate": 0.016990728170645158,
      "loss": 0.5394,
      "step": 514860
    },
    {
      "epoch": 830.45,
      "learning_rate": 0.01698750236741935,
      "loss": 0.5144,
      "step": 514880
    },
    {
      "epoch": 830.48,
      "learning_rate": 0.016984276564193546,
      "loss": 0.5354,
      "step": 514900
    },
    {
      "epoch": 830.52,
      "learning_rate": 0.01698105076096774,
      "loss": 0.5293,
      "step": 514920
    },
    {
      "epoch": 830.55,
      "learning_rate": 0.016977824957741933,
      "loss": 0.5355,
      "step": 514940
    },
    {
      "epoch": 830.58,
      "learning_rate": 0.01697459915451613,
      "loss": 0.5363,
      "step": 514960
    },
    {
      "epoch": 830.61,
      "learning_rate": 0.01697137335129032,
      "loss": 0.5222,
      "step": 514980
    },
    {
      "epoch": 830.65,
      "learning_rate": 0.016968147548064517,
      "loss": 0.5314,
      "step": 515000
    },
    {
      "epoch": 830.68,
      "learning_rate": 0.016964921744838712,
      "loss": 0.5371,
      "step": 515020
    },
    {
      "epoch": 830.71,
      "learning_rate": 0.016961695941612905,
      "loss": 0.5303,
      "step": 515040
    },
    {
      "epoch": 830.74,
      "learning_rate": 0.0169584701383871,
      "loss": 0.5304,
      "step": 515060
    },
    {
      "epoch": 830.77,
      "learning_rate": 0.016955244335161296,
      "loss": 0.5281,
      "step": 515080
    },
    {
      "epoch": 830.81,
      "learning_rate": 0.016952018531935488,
      "loss": 0.5261,
      "step": 515100
    },
    {
      "epoch": 830.84,
      "learning_rate": 0.016948792728709684,
      "loss": 0.5282,
      "step": 515120
    },
    {
      "epoch": 830.87,
      "learning_rate": 0.016945566925483865,
      "loss": 0.5193,
      "step": 515140
    },
    {
      "epoch": 830.9,
      "learning_rate": 0.01694234112225806,
      "loss": 0.5272,
      "step": 515160
    },
    {
      "epoch": 830.94,
      "learning_rate": 0.016939115319032253,
      "loss": 0.5437,
      "step": 515180
    },
    {
      "epoch": 830.97,
      "learning_rate": 0.01693588951580645,
      "loss": 0.5288,
      "step": 515200
    },
    {
      "epoch": 831.0,
      "learning_rate": 0.016932663712580644,
      "loss": 0.533,
      "step": 515220
    },
    {
      "epoch": 831.0,
      "eval_accuracy": {
        "accuracy": 0.7848723753024744
      },
      "eval_loss": 0.8897261023521423,
      "eval_runtime": 3.2556,
      "eval_samples_per_second": 3935.121,
      "eval_steps_per_second": 61.741,
      "step": 515220
    },
    {
      "epoch": 831.03,
      "learning_rate": 0.016929437909354837,
      "loss": 0.5295,
      "step": 515240
    },
    {
      "epoch": 831.06,
      "learning_rate": 0.016926212106129032,
      "loss": 0.5281,
      "step": 515260
    },
    {
      "epoch": 831.1,
      "learning_rate": 0.016922986302903224,
      "loss": 0.5245,
      "step": 515280
    },
    {
      "epoch": 831.13,
      "learning_rate": 0.01691976049967742,
      "loss": 0.523,
      "step": 515300
    },
    {
      "epoch": 831.16,
      "learning_rate": 0.016916534696451616,
      "loss": 0.5332,
      "step": 515320
    },
    {
      "epoch": 831.19,
      "learning_rate": 0.016913308893225808,
      "loss": 0.5313,
      "step": 515340
    },
    {
      "epoch": 831.23,
      "learning_rate": 0.016910083090000003,
      "loss": 0.5243,
      "step": 515360
    },
    {
      "epoch": 831.26,
      "learning_rate": 0.016906857286774195,
      "loss": 0.5125,
      "step": 515380
    },
    {
      "epoch": 831.29,
      "learning_rate": 0.01690363148354839,
      "loss": 0.5158,
      "step": 515400
    },
    {
      "epoch": 831.32,
      "learning_rate": 0.016900405680322587,
      "loss": 0.527,
      "step": 515420
    },
    {
      "epoch": 831.35,
      "learning_rate": 0.01689717987709677,
      "loss": 0.5322,
      "step": 515440
    },
    {
      "epoch": 831.39,
      "learning_rate": 0.016893954073870964,
      "loss": 0.5304,
      "step": 515460
    },
    {
      "epoch": 831.42,
      "learning_rate": 0.016890728270645156,
      "loss": 0.5385,
      "step": 515480
    },
    {
      "epoch": 831.45,
      "learning_rate": 0.016887502467419352,
      "loss": 0.5251,
      "step": 515500
    },
    {
      "epoch": 831.48,
      "learning_rate": 0.016884276664193544,
      "loss": 0.5299,
      "step": 515520
    },
    {
      "epoch": 831.52,
      "learning_rate": 0.01688105086096774,
      "loss": 0.5328,
      "step": 515540
    },
    {
      "epoch": 831.55,
      "learning_rate": 0.016877825057741935,
      "loss": 0.5289,
      "step": 515560
    },
    {
      "epoch": 831.58,
      "learning_rate": 0.016874599254516127,
      "loss": 0.5275,
      "step": 515580
    },
    {
      "epoch": 831.61,
      "learning_rate": 0.016871373451290323,
      "loss": 0.5217,
      "step": 515600
    },
    {
      "epoch": 831.65,
      "learning_rate": 0.016868147648064515,
      "loss": 0.5269,
      "step": 515620
    },
    {
      "epoch": 831.68,
      "learning_rate": 0.01686492184483871,
      "loss": 0.5284,
      "step": 515640
    },
    {
      "epoch": 831.71,
      "learning_rate": 0.016861696041612906,
      "loss": 0.5195,
      "step": 515660
    },
    {
      "epoch": 831.74,
      "learning_rate": 0.0168584702383871,
      "loss": 0.541,
      "step": 515680
    },
    {
      "epoch": 831.77,
      "learning_rate": 0.016855244435161294,
      "loss": 0.5323,
      "step": 515700
    },
    {
      "epoch": 831.81,
      "learning_rate": 0.01685201863193549,
      "loss": 0.5293,
      "step": 515720
    },
    {
      "epoch": 831.84,
      "learning_rate": 0.016848792828709682,
      "loss": 0.5341,
      "step": 515740
    },
    {
      "epoch": 831.87,
      "learning_rate": 0.016845567025483867,
      "loss": 0.523,
      "step": 515760
    },
    {
      "epoch": 831.9,
      "learning_rate": 0.01684234122225806,
      "loss": 0.5359,
      "step": 515780
    },
    {
      "epoch": 831.94,
      "learning_rate": 0.016839115419032255,
      "loss": 0.5237,
      "step": 515800
    },
    {
      "epoch": 831.97,
      "learning_rate": 0.016835889615806447,
      "loss": 0.5375,
      "step": 515820
    },
    {
      "epoch": 832.0,
      "learning_rate": 0.01683282510274194,
      "loss": 0.5259,
      "step": 515840
    },
    {
      "epoch": 832.0,
      "eval_accuracy": {
        "accuracy": 0.7863554757630161
      },
      "eval_loss": 0.887820303440094,
      "eval_runtime": 3.2552,
      "eval_samples_per_second": 3935.593,
      "eval_steps_per_second": 61.748,
      "step": 515840
    },
    {
      "epoch": 832.03,
      "learning_rate": 0.016829599299516135,
      "loss": 0.5263,
      "step": 515860
    },
    {
      "epoch": 832.06,
      "learning_rate": 0.016826373496290327,
      "loss": 0.533,
      "step": 515880
    },
    {
      "epoch": 832.1,
      "learning_rate": 0.016823147693064512,
      "loss": 0.526,
      "step": 515900
    },
    {
      "epoch": 832.13,
      "learning_rate": 0.016819921889838704,
      "loss": 0.5371,
      "step": 515920
    },
    {
      "epoch": 832.16,
      "learning_rate": 0.0168166960866129,
      "loss": 0.5211,
      "step": 515940
    },
    {
      "epoch": 832.19,
      "learning_rate": 0.016813470283387092,
      "loss": 0.525,
      "step": 515960
    },
    {
      "epoch": 832.23,
      "learning_rate": 0.016810244480161288,
      "loss": 0.5303,
      "step": 515980
    },
    {
      "epoch": 832.26,
      "learning_rate": 0.016807018676935483,
      "loss": 0.5233,
      "step": 516000
    },
    {
      "epoch": 832.29,
      "learning_rate": 0.016803792873709675,
      "loss": 0.52,
      "step": 516020
    },
    {
      "epoch": 832.32,
      "learning_rate": 0.01680056707048387,
      "loss": 0.5239,
      "step": 516040
    },
    {
      "epoch": 832.35,
      "learning_rate": 0.016797341267258063,
      "loss": 0.5247,
      "step": 516060
    },
    {
      "epoch": 832.39,
      "learning_rate": 0.01679411546403226,
      "loss": 0.5376,
      "step": 516080
    },
    {
      "epoch": 832.42,
      "learning_rate": 0.016790889660806455,
      "loss": 0.5333,
      "step": 516100
    },
    {
      "epoch": 832.45,
      "learning_rate": 0.016787663857580647,
      "loss": 0.5312,
      "step": 516120
    },
    {
      "epoch": 832.48,
      "learning_rate": 0.016784438054354842,
      "loss": 0.5261,
      "step": 516140
    },
    {
      "epoch": 832.52,
      "learning_rate": 0.016781212251129038,
      "loss": 0.5239,
      "step": 516160
    },
    {
      "epoch": 832.55,
      "learning_rate": 0.01677798644790323,
      "loss": 0.5099,
      "step": 516180
    },
    {
      "epoch": 832.58,
      "learning_rate": 0.016774760644677426,
      "loss": 0.5325,
      "step": 516200
    },
    {
      "epoch": 832.61,
      "learning_rate": 0.016771534841451607,
      "loss": 0.5296,
      "step": 516220
    },
    {
      "epoch": 832.65,
      "learning_rate": 0.016768309038225803,
      "loss": 0.5285,
      "step": 516240
    },
    {
      "epoch": 832.68,
      "learning_rate": 0.016765083234999995,
      "loss": 0.5412,
      "step": 516260
    },
    {
      "epoch": 832.71,
      "learning_rate": 0.01676185743177419,
      "loss": 0.5264,
      "step": 516280
    },
    {
      "epoch": 832.74,
      "learning_rate": 0.016758631628548386,
      "loss": 0.5342,
      "step": 516300
    },
    {
      "epoch": 832.77,
      "learning_rate": 0.01675540582532258,
      "loss": 0.5419,
      "step": 516320
    },
    {
      "epoch": 832.81,
      "learning_rate": 0.016752180022096774,
      "loss": 0.5282,
      "step": 516340
    },
    {
      "epoch": 832.84,
      "learning_rate": 0.016748954218870966,
      "loss": 0.5224,
      "step": 516360
    },
    {
      "epoch": 832.87,
      "learning_rate": 0.016745728415645162,
      "loss": 0.5128,
      "step": 516380
    },
    {
      "epoch": 832.9,
      "learning_rate": 0.016742502612419358,
      "loss": 0.526,
      "step": 516400
    },
    {
      "epoch": 832.94,
      "learning_rate": 0.01673927680919355,
      "loss": 0.5334,
      "step": 516420
    },
    {
      "epoch": 832.97,
      "learning_rate": 0.016736051005967745,
      "loss": 0.5225,
      "step": 516440
    },
    {
      "epoch": 833.0,
      "learning_rate": 0.016732825202741938,
      "loss": 0.5213,
      "step": 516460
    },
    {
      "epoch": 833.0,
      "eval_accuracy": {
        "accuracy": 0.7837795644368121
      },
      "eval_loss": 0.8856587409973145,
      "eval_runtime": 3.0656,
      "eval_samples_per_second": 4178.951,
      "eval_steps_per_second": 65.566,
      "step": 516460
    },
    {
      "epoch": 833.03,
      "learning_rate": 0.016729599399516133,
      "loss": 0.5327,
      "step": 516480
    },
    {
      "epoch": 833.06,
      "learning_rate": 0.01672637359629033,
      "loss": 0.5213,
      "step": 516500
    },
    {
      "epoch": 833.1,
      "learning_rate": 0.01672314779306451,
      "loss": 0.5271,
      "step": 516520
    },
    {
      "epoch": 833.13,
      "learning_rate": 0.016719921989838706,
      "loss": 0.5252,
      "step": 516540
    },
    {
      "epoch": 833.16,
      "learning_rate": 0.0167166961866129,
      "loss": 0.5276,
      "step": 516560
    },
    {
      "epoch": 833.19,
      "learning_rate": 0.016713470383387094,
      "loss": 0.5264,
      "step": 516580
    },
    {
      "epoch": 833.23,
      "learning_rate": 0.016710244580161286,
      "loss": 0.5195,
      "step": 516600
    },
    {
      "epoch": 833.26,
      "learning_rate": 0.016707018776935482,
      "loss": 0.5278,
      "step": 516620
    },
    {
      "epoch": 833.29,
      "learning_rate": 0.016703792973709677,
      "loss": 0.5207,
      "step": 516640
    },
    {
      "epoch": 833.32,
      "learning_rate": 0.01670056717048387,
      "loss": 0.5199,
      "step": 516660
    },
    {
      "epoch": 833.35,
      "learning_rate": 0.016697341367258065,
      "loss": 0.5142,
      "step": 516680
    },
    {
      "epoch": 833.39,
      "learning_rate": 0.016694115564032257,
      "loss": 0.5247,
      "step": 516700
    },
    {
      "epoch": 833.42,
      "learning_rate": 0.016690889760806453,
      "loss": 0.5288,
      "step": 516720
    },
    {
      "epoch": 833.45,
      "learning_rate": 0.01668766395758065,
      "loss": 0.5313,
      "step": 516740
    },
    {
      "epoch": 833.48,
      "learning_rate": 0.01668443815435484,
      "loss": 0.532,
      "step": 516760
    },
    {
      "epoch": 833.52,
      "learning_rate": 0.016681212351129036,
      "loss": 0.5228,
      "step": 516780
    },
    {
      "epoch": 833.55,
      "learning_rate": 0.016677986547903232,
      "loss": 0.5186,
      "step": 516800
    },
    {
      "epoch": 833.58,
      "learning_rate": 0.016674760744677424,
      "loss": 0.524,
      "step": 516820
    },
    {
      "epoch": 833.61,
      "learning_rate": 0.01667153494145161,
      "loss": 0.5327,
      "step": 516840
    },
    {
      "epoch": 833.65,
      "learning_rate": 0.0166683091382258,
      "loss": 0.5358,
      "step": 516860
    },
    {
      "epoch": 833.68,
      "learning_rate": 0.016665083334999997,
      "loss": 0.5223,
      "step": 516880
    },
    {
      "epoch": 833.71,
      "learning_rate": 0.01666185753177419,
      "loss": 0.5349,
      "step": 516900
    },
    {
      "epoch": 833.74,
      "learning_rate": 0.016658631728548385,
      "loss": 0.5301,
      "step": 516920
    },
    {
      "epoch": 833.77,
      "learning_rate": 0.01665540592532258,
      "loss": 0.5307,
      "step": 516940
    },
    {
      "epoch": 833.81,
      "learning_rate": 0.016652180122096773,
      "loss": 0.5367,
      "step": 516960
    },
    {
      "epoch": 833.84,
      "learning_rate": 0.01664895431887097,
      "loss": 0.5312,
      "step": 516980
    },
    {
      "epoch": 833.87,
      "learning_rate": 0.01664572851564516,
      "loss": 0.5344,
      "step": 517000
    },
    {
      "epoch": 833.9,
      "learning_rate": 0.016642502712419356,
      "loss": 0.5328,
      "step": 517020
    },
    {
      "epoch": 833.94,
      "learning_rate": 0.016639276909193552,
      "loss": 0.5324,
      "step": 517040
    },
    {
      "epoch": 833.97,
      "learning_rate": 0.016636051105967744,
      "loss": 0.5283,
      "step": 517060
    },
    {
      "epoch": 834.0,
      "learning_rate": 0.01663282530274194,
      "loss": 0.5299,
      "step": 517080
    },
    {
      "epoch": 834.0,
      "eval_accuracy": {
        "accuracy": 0.7817500585434393
      },
      "eval_loss": 0.9030371904373169,
      "eval_runtime": 3.1329,
      "eval_samples_per_second": 4089.152,
      "eval_steps_per_second": 64.157,
      "step": 517080
    },
    {
      "epoch": 834.03,
      "learning_rate": 0.01662959949951613,
      "loss": 0.5367,
      "step": 517100
    },
    {
      "epoch": 834.06,
      "learning_rate": 0.016626373696290327,
      "loss": 0.5155,
      "step": 517120
    },
    {
      "epoch": 834.1,
      "learning_rate": 0.01662314789306451,
      "loss": 0.5156,
      "step": 517140
    },
    {
      "epoch": 834.13,
      "learning_rate": 0.016619922089838705,
      "loss": 0.5272,
      "step": 517160
    },
    {
      "epoch": 834.16,
      "learning_rate": 0.0166166962866129,
      "loss": 0.5256,
      "step": 517180
    },
    {
      "epoch": 834.19,
      "learning_rate": 0.016613470483387092,
      "loss": 0.5174,
      "step": 517200
    },
    {
      "epoch": 834.23,
      "learning_rate": 0.016610244680161288,
      "loss": 0.5345,
      "step": 517220
    },
    {
      "epoch": 834.26,
      "learning_rate": 0.01660701887693548,
      "loss": 0.5288,
      "step": 517240
    },
    {
      "epoch": 834.29,
      "learning_rate": 0.016603793073709676,
      "loss": 0.53,
      "step": 517260
    },
    {
      "epoch": 834.32,
      "learning_rate": 0.01660056727048387,
      "loss": 0.5198,
      "step": 517280
    },
    {
      "epoch": 834.35,
      "learning_rate": 0.016597341467258064,
      "loss": 0.5228,
      "step": 517300
    },
    {
      "epoch": 834.39,
      "learning_rate": 0.01659411566403226,
      "loss": 0.5302,
      "step": 517320
    },
    {
      "epoch": 834.42,
      "learning_rate": 0.016590889860806455,
      "loss": 0.5116,
      "step": 517340
    },
    {
      "epoch": 834.45,
      "learning_rate": 0.016587664057580647,
      "loss": 0.5286,
      "step": 517360
    },
    {
      "epoch": 834.48,
      "learning_rate": 0.016584438254354843,
      "loss": 0.5339,
      "step": 517380
    },
    {
      "epoch": 834.52,
      "learning_rate": 0.016581212451129035,
      "loss": 0.5267,
      "step": 517400
    },
    {
      "epoch": 834.55,
      "learning_rate": 0.01657798664790323,
      "loss": 0.5244,
      "step": 517420
    },
    {
      "epoch": 834.58,
      "learning_rate": 0.016574760844677426,
      "loss": 0.5329,
      "step": 517440
    },
    {
      "epoch": 834.61,
      "learning_rate": 0.016571535041451608,
      "loss": 0.5301,
      "step": 517460
    },
    {
      "epoch": 834.65,
      "learning_rate": 0.016568309238225803,
      "loss": 0.5263,
      "step": 517480
    },
    {
      "epoch": 834.68,
      "learning_rate": 0.016565083434999996,
      "loss": 0.5385,
      "step": 517500
    },
    {
      "epoch": 834.71,
      "learning_rate": 0.01656185763177419,
      "loss": 0.5335,
      "step": 517520
    },
    {
      "epoch": 834.74,
      "learning_rate": 0.016558631828548383,
      "loss": 0.5367,
      "step": 517540
    },
    {
      "epoch": 834.77,
      "learning_rate": 0.01655540602532258,
      "loss": 0.533,
      "step": 517560
    },
    {
      "epoch": 834.81,
      "learning_rate": 0.016552180222096775,
      "loss": 0.5188,
      "step": 517580
    },
    {
      "epoch": 834.84,
      "learning_rate": 0.016548954418870967,
      "loss": 0.5199,
      "step": 517600
    },
    {
      "epoch": 834.87,
      "learning_rate": 0.016545728615645162,
      "loss": 0.5224,
      "step": 517620
    },
    {
      "epoch": 834.9,
      "learning_rate": 0.016542502812419355,
      "loss": 0.5216,
      "step": 517640
    },
    {
      "epoch": 834.94,
      "learning_rate": 0.01653927700919355,
      "loss": 0.5218,
      "step": 517660
    },
    {
      "epoch": 834.97,
      "learning_rate": 0.016536051205967746,
      "loss": 0.5313,
      "step": 517680
    },
    {
      "epoch": 835.0,
      "learning_rate": 0.016532825402741938,
      "loss": 0.5261,
      "step": 517700
    },
    {
      "epoch": 835.0,
      "eval_accuracy": {
        "accuracy": 0.7847162594645227
      },
      "eval_loss": 0.8897637128829956,
      "eval_runtime": 4.6975,
      "eval_samples_per_second": 2727.203,
      "eval_steps_per_second": 42.789,
      "step": 517700
    },
    {
      "epoch": 835.03,
      "learning_rate": 0.016529599599516134,
      "loss": 0.5298,
      "step": 517720
    },
    {
      "epoch": 835.06,
      "learning_rate": 0.016526373796290326,
      "loss": 0.5172,
      "step": 517740
    },
    {
      "epoch": 835.1,
      "learning_rate": 0.01652314799306451,
      "loss": 0.516,
      "step": 517760
    },
    {
      "epoch": 835.13,
      "learning_rate": 0.016519922189838703,
      "loss": 0.5241,
      "step": 517780
    },
    {
      "epoch": 835.16,
      "learning_rate": 0.0165166963866129,
      "loss": 0.5257,
      "step": 517800
    },
    {
      "epoch": 835.19,
      "learning_rate": 0.016513470583387094,
      "loss": 0.527,
      "step": 517820
    },
    {
      "epoch": 835.23,
      "learning_rate": 0.016510244780161287,
      "loss": 0.5156,
      "step": 517840
    },
    {
      "epoch": 835.26,
      "learning_rate": 0.016507018976935482,
      "loss": 0.5228,
      "step": 517860
    },
    {
      "epoch": 835.29,
      "learning_rate": 0.016503793173709678,
      "loss": 0.5139,
      "step": 517880
    },
    {
      "epoch": 835.32,
      "learning_rate": 0.01650056737048387,
      "loss": 0.5233,
      "step": 517900
    },
    {
      "epoch": 835.35,
      "learning_rate": 0.016497341567258066,
      "loss": 0.5159,
      "step": 517920
    },
    {
      "epoch": 835.39,
      "learning_rate": 0.016494115764032258,
      "loss": 0.533,
      "step": 517940
    },
    {
      "epoch": 835.42,
      "learning_rate": 0.016490889960806453,
      "loss": 0.5167,
      "step": 517960
    },
    {
      "epoch": 835.45,
      "learning_rate": 0.01648766415758065,
      "loss": 0.5267,
      "step": 517980
    },
    {
      "epoch": 835.48,
      "learning_rate": 0.01648443835435484,
      "loss": 0.5205,
      "step": 518000
    },
    {
      "epoch": 835.52,
      "learning_rate": 0.016481212551129037,
      "loss": 0.5236,
      "step": 518020
    },
    {
      "epoch": 835.55,
      "learning_rate": 0.01647798674790323,
      "loss": 0.5301,
      "step": 518040
    },
    {
      "epoch": 835.58,
      "learning_rate": 0.016474760944677425,
      "loss": 0.5305,
      "step": 518060
    },
    {
      "epoch": 835.61,
      "learning_rate": 0.016471535141451606,
      "loss": 0.537,
      "step": 518080
    },
    {
      "epoch": 835.65,
      "learning_rate": 0.016468309338225802,
      "loss": 0.5221,
      "step": 518100
    },
    {
      "epoch": 835.68,
      "learning_rate": 0.016465083534999998,
      "loss": 0.5304,
      "step": 518120
    },
    {
      "epoch": 835.71,
      "learning_rate": 0.01646185773177419,
      "loss": 0.5218,
      "step": 518140
    },
    {
      "epoch": 835.74,
      "learning_rate": 0.016458631928548385,
      "loss": 0.535,
      "step": 518160
    },
    {
      "epoch": 835.77,
      "learning_rate": 0.016455406125322578,
      "loss": 0.528,
      "step": 518180
    },
    {
      "epoch": 835.81,
      "learning_rate": 0.016452180322096773,
      "loss": 0.5303,
      "step": 518200
    },
    {
      "epoch": 835.84,
      "learning_rate": 0.01644895451887097,
      "loss": 0.5322,
      "step": 518220
    },
    {
      "epoch": 835.87,
      "learning_rate": 0.01644572871564516,
      "loss": 0.5308,
      "step": 518240
    },
    {
      "epoch": 835.9,
      "learning_rate": 0.016442502912419357,
      "loss": 0.5388,
      "step": 518260
    },
    {
      "epoch": 835.94,
      "learning_rate": 0.01643927710919355,
      "loss": 0.5346,
      "step": 518280
    },
    {
      "epoch": 835.97,
      "learning_rate": 0.016436051305967744,
      "loss": 0.5188,
      "step": 518300
    },
    {
      "epoch": 836.0,
      "learning_rate": 0.016432986792903222,
      "loss": 0.5327,
      "step": 518320
    },
    {
      "epoch": 836.0,
      "eval_accuracy": {
        "accuracy": 0.7869799391148232
      },
      "eval_loss": 0.8772270083427429,
      "eval_runtime": 3.0697,
      "eval_samples_per_second": 4173.424,
      "eval_steps_per_second": 65.48,
      "step": 518320
    },
    {
      "epoch": 836.03,
      "learning_rate": 0.016429760989677418,
      "loss": 0.51,
      "step": 518340
    },
    {
      "epoch": 836.06,
      "learning_rate": 0.016426535186451614,
      "loss": 0.5291,
      "step": 518360
    },
    {
      "epoch": 836.1,
      "learning_rate": 0.016423309383225806,
      "loss": 0.5223,
      "step": 518380
    },
    {
      "epoch": 836.13,
      "learning_rate": 0.01642008358,
      "loss": 0.5309,
      "step": 518400
    },
    {
      "epoch": 836.16,
      "learning_rate": 0.016416857776774197,
      "loss": 0.529,
      "step": 518420
    },
    {
      "epoch": 836.19,
      "learning_rate": 0.01641363197354839,
      "loss": 0.5234,
      "step": 518440
    },
    {
      "epoch": 836.23,
      "learning_rate": 0.016410406170322585,
      "loss": 0.5242,
      "step": 518460
    },
    {
      "epoch": 836.26,
      "learning_rate": 0.016407180367096777,
      "loss": 0.5178,
      "step": 518480
    },
    {
      "epoch": 836.29,
      "learning_rate": 0.016403954563870973,
      "loss": 0.5168,
      "step": 518500
    },
    {
      "epoch": 836.32,
      "learning_rate": 0.016400728760645168,
      "loss": 0.5228,
      "step": 518520
    },
    {
      "epoch": 836.35,
      "learning_rate": 0.01639750295741935,
      "loss": 0.5269,
      "step": 518540
    },
    {
      "epoch": 836.39,
      "learning_rate": 0.016394277154193546,
      "loss": 0.5233,
      "step": 518560
    },
    {
      "epoch": 836.42,
      "learning_rate": 0.016391051350967738,
      "loss": 0.5331,
      "step": 518580
    },
    {
      "epoch": 836.45,
      "learning_rate": 0.016387825547741933,
      "loss": 0.5166,
      "step": 518600
    },
    {
      "epoch": 836.48,
      "learning_rate": 0.016384599744516126,
      "loss": 0.5296,
      "step": 518620
    },
    {
      "epoch": 836.52,
      "learning_rate": 0.01638137394129032,
      "loss": 0.5237,
      "step": 518640
    },
    {
      "epoch": 836.55,
      "learning_rate": 0.016378148138064517,
      "loss": 0.5313,
      "step": 518660
    },
    {
      "epoch": 836.58,
      "learning_rate": 0.01637492233483871,
      "loss": 0.5286,
      "step": 518680
    },
    {
      "epoch": 836.61,
      "learning_rate": 0.016371696531612905,
      "loss": 0.5168,
      "step": 518700
    },
    {
      "epoch": 836.65,
      "learning_rate": 0.016368470728387097,
      "loss": 0.5218,
      "step": 518720
    },
    {
      "epoch": 836.68,
      "learning_rate": 0.016365244925161292,
      "loss": 0.5326,
      "step": 518740
    },
    {
      "epoch": 836.71,
      "learning_rate": 0.016362019121935488,
      "loss": 0.5266,
      "step": 518760
    },
    {
      "epoch": 836.74,
      "learning_rate": 0.01635879331870968,
      "loss": 0.5305,
      "step": 518780
    },
    {
      "epoch": 836.77,
      "learning_rate": 0.016355567515483876,
      "loss": 0.5319,
      "step": 518800
    },
    {
      "epoch": 836.81,
      "learning_rate": 0.016352341712258068,
      "loss": 0.5202,
      "step": 518820
    },
    {
      "epoch": 836.84,
      "learning_rate": 0.016349115909032253,
      "loss": 0.5317,
      "step": 518840
    },
    {
      "epoch": 836.87,
      "learning_rate": 0.016345890105806445,
      "loss": 0.525,
      "step": 518860
    },
    {
      "epoch": 836.9,
      "learning_rate": 0.01634266430258064,
      "loss": 0.5325,
      "step": 518880
    },
    {
      "epoch": 836.94,
      "learning_rate": 0.016339438499354837,
      "loss": 0.5343,
      "step": 518900
    },
    {
      "epoch": 836.97,
      "learning_rate": 0.01633621269612903,
      "loss": 0.5357,
      "step": 518920
    },
    {
      "epoch": 837.0,
      "learning_rate": 0.016332986892903224,
      "loss": 0.521,
      "step": 518940
    },
    {
      "epoch": 837.0,
      "eval_accuracy": {
        "accuracy": 0.7875263445476544
      },
      "eval_loss": 0.8912319540977478,
      "eval_runtime": 3.0369,
      "eval_samples_per_second": 4218.42,
      "eval_steps_per_second": 66.186,
      "step": 518940
    },
    {
      "epoch": 837.03,
      "learning_rate": 0.01632976108967742,
      "loss": 0.5239,
      "step": 518960
    },
    {
      "epoch": 837.06,
      "learning_rate": 0.016326535286451612,
      "loss": 0.5188,
      "step": 518980
    },
    {
      "epoch": 837.1,
      "learning_rate": 0.016323309483225808,
      "loss": 0.5239,
      "step": 519000
    },
    {
      "epoch": 837.13,
      "learning_rate": 0.01632008368,
      "loss": 0.5233,
      "step": 519020
    },
    {
      "epoch": 837.16,
      "learning_rate": 0.016316857876774195,
      "loss": 0.5225,
      "step": 519040
    },
    {
      "epoch": 837.19,
      "learning_rate": 0.01631363207354839,
      "loss": 0.5278,
      "step": 519060
    },
    {
      "epoch": 837.23,
      "learning_rate": 0.016310406270322583,
      "loss": 0.5205,
      "step": 519080
    },
    {
      "epoch": 837.26,
      "learning_rate": 0.01630718046709678,
      "loss": 0.5175,
      "step": 519100
    },
    {
      "epoch": 837.29,
      "learning_rate": 0.01630395466387097,
      "loss": 0.528,
      "step": 519120
    },
    {
      "epoch": 837.32,
      "learning_rate": 0.016300728860645167,
      "loss": 0.5303,
      "step": 519140
    },
    {
      "epoch": 837.35,
      "learning_rate": 0.01629750305741935,
      "loss": 0.5214,
      "step": 519160
    },
    {
      "epoch": 837.39,
      "learning_rate": 0.016294277254193544,
      "loss": 0.5237,
      "step": 519180
    },
    {
      "epoch": 837.42,
      "learning_rate": 0.01629105145096774,
      "loss": 0.523,
      "step": 519200
    },
    {
      "epoch": 837.45,
      "learning_rate": 0.016287825647741932,
      "loss": 0.516,
      "step": 519220
    },
    {
      "epoch": 837.48,
      "learning_rate": 0.016284599844516127,
      "loss": 0.5339,
      "step": 519240
    },
    {
      "epoch": 837.52,
      "learning_rate": 0.01628137404129032,
      "loss": 0.5216,
      "step": 519260
    },
    {
      "epoch": 837.55,
      "learning_rate": 0.016278148238064515,
      "loss": 0.5287,
      "step": 519280
    },
    {
      "epoch": 837.58,
      "learning_rate": 0.01627492243483871,
      "loss": 0.5201,
      "step": 519300
    },
    {
      "epoch": 837.61,
      "learning_rate": 0.016271696631612903,
      "loss": 0.529,
      "step": 519320
    },
    {
      "epoch": 837.65,
      "learning_rate": 0.0162684708283871,
      "loss": 0.5219,
      "step": 519340
    },
    {
      "epoch": 837.68,
      "learning_rate": 0.01626524502516129,
      "loss": 0.5234,
      "step": 519360
    },
    {
      "epoch": 837.71,
      "learning_rate": 0.016262019221935486,
      "loss": 0.5398,
      "step": 519380
    },
    {
      "epoch": 837.74,
      "learning_rate": 0.016258793418709682,
      "loss": 0.5377,
      "step": 519400
    },
    {
      "epoch": 837.77,
      "learning_rate": 0.016255567615483874,
      "loss": 0.5222,
      "step": 519420
    },
    {
      "epoch": 837.81,
      "learning_rate": 0.01625234181225807,
      "loss": 0.5261,
      "step": 519440
    },
    {
      "epoch": 837.84,
      "learning_rate": 0.01624911600903225,
      "loss": 0.5337,
      "step": 519460
    },
    {
      "epoch": 837.87,
      "learning_rate": 0.016245890205806447,
      "loss": 0.5389,
      "step": 519480
    },
    {
      "epoch": 837.9,
      "learning_rate": 0.01624266440258064,
      "loss": 0.5257,
      "step": 519500
    },
    {
      "epoch": 837.94,
      "learning_rate": 0.016239438599354835,
      "loss": 0.5288,
      "step": 519520
    },
    {
      "epoch": 837.97,
      "learning_rate": 0.01623621279612903,
      "loss": 0.5182,
      "step": 519540
    },
    {
      "epoch": 838.0,
      "learning_rate": 0.016232986992903223,
      "loss": 0.5238,
      "step": 519560
    },
    {
      "epoch": 838.0,
      "eval_accuracy": {
        "accuracy": 0.7878385762235579
      },
      "eval_loss": 0.8862206935882568,
      "eval_runtime": 3.0785,
      "eval_samples_per_second": 4161.404,
      "eval_steps_per_second": 65.291,
      "step": 519560
    },
    {
      "epoch": 838.03,
      "learning_rate": 0.01622976118967742,
      "loss": 0.5395,
      "step": 519580
    },
    {
      "epoch": 838.06,
      "learning_rate": 0.016226535386451614,
      "loss": 0.5286,
      "step": 519600
    },
    {
      "epoch": 838.1,
      "learning_rate": 0.016223309583225806,
      "loss": 0.5124,
      "step": 519620
    },
    {
      "epoch": 838.13,
      "learning_rate": 0.016220083780000002,
      "loss": 0.5158,
      "step": 519640
    },
    {
      "epoch": 838.16,
      "learning_rate": 0.016216857976774194,
      "loss": 0.5154,
      "step": 519660
    },
    {
      "epoch": 838.19,
      "learning_rate": 0.01621363217354839,
      "loss": 0.5227,
      "step": 519680
    },
    {
      "epoch": 838.23,
      "learning_rate": 0.016210406370322585,
      "loss": 0.5251,
      "step": 519700
    },
    {
      "epoch": 838.26,
      "learning_rate": 0.016207180567096777,
      "loss": 0.5083,
      "step": 519720
    },
    {
      "epoch": 838.29,
      "learning_rate": 0.016203954763870973,
      "loss": 0.5245,
      "step": 519740
    },
    {
      "epoch": 838.32,
      "learning_rate": 0.016200728960645165,
      "loss": 0.5174,
      "step": 519760
    },
    {
      "epoch": 838.35,
      "learning_rate": 0.01619750315741935,
      "loss": 0.5224,
      "step": 519780
    },
    {
      "epoch": 838.39,
      "learning_rate": 0.016194277354193543,
      "loss": 0.5204,
      "step": 519800
    },
    {
      "epoch": 838.42,
      "learning_rate": 0.016191051550967738,
      "loss": 0.5246,
      "step": 519820
    },
    {
      "epoch": 838.45,
      "learning_rate": 0.016187825747741934,
      "loss": 0.5065,
      "step": 519840
    },
    {
      "epoch": 838.48,
      "learning_rate": 0.016184599944516126,
      "loss": 0.5326,
      "step": 519860
    },
    {
      "epoch": 838.52,
      "learning_rate": 0.01618137414129032,
      "loss": 0.5292,
      "step": 519880
    },
    {
      "epoch": 838.55,
      "learning_rate": 0.016178148338064514,
      "loss": 0.5319,
      "step": 519900
    },
    {
      "epoch": 838.58,
      "learning_rate": 0.01617492253483871,
      "loss": 0.5292,
      "step": 519920
    },
    {
      "epoch": 838.61,
      "learning_rate": 0.016171696731612905,
      "loss": 0.5301,
      "step": 519940
    },
    {
      "epoch": 838.65,
      "learning_rate": 0.016168470928387097,
      "loss": 0.5301,
      "step": 519960
    },
    {
      "epoch": 838.68,
      "learning_rate": 0.016165245125161293,
      "loss": 0.5292,
      "step": 519980
    },
    {
      "epoch": 838.71,
      "learning_rate": 0.016162019321935485,
      "loss": 0.5218,
      "step": 520000
    },
    {
      "epoch": 838.74,
      "learning_rate": 0.01615879351870968,
      "loss": 0.522,
      "step": 520020
    },
    {
      "epoch": 838.77,
      "learning_rate": 0.016155567715483876,
      "loss": 0.5259,
      "step": 520040
    },
    {
      "epoch": 838.81,
      "learning_rate": 0.01615234191225807,
      "loss": 0.522,
      "step": 520060
    },
    {
      "epoch": 838.84,
      "learning_rate": 0.016149116109032254,
      "loss": 0.5354,
      "step": 520080
    },
    {
      "epoch": 838.87,
      "learning_rate": 0.016145890305806446,
      "loss": 0.5394,
      "step": 520100
    },
    {
      "epoch": 838.9,
      "learning_rate": 0.01614266450258064,
      "loss": 0.5263,
      "step": 520120
    },
    {
      "epoch": 838.94,
      "learning_rate": 0.016139438699354837,
      "loss": 0.5251,
      "step": 520140
    },
    {
      "epoch": 838.97,
      "learning_rate": 0.01613621289612903,
      "loss": 0.5412,
      "step": 520160
    },
    {
      "epoch": 839.0,
      "learning_rate": 0.016132987092903225,
      "loss": 0.5168,
      "step": 520180
    },
    {
      "epoch": 839.0,
      "eval_accuracy": {
        "accuracy": 0.7845601436265709
      },
      "eval_loss": 0.892897367477417,
      "eval_runtime": 3.9954,
      "eval_samples_per_second": 3206.415,
      "eval_steps_per_second": 50.308,
      "step": 520180
    },
    {
      "epoch": 839.03,
      "learning_rate": 0.016129761289677417,
      "loss": 0.5326,
      "step": 520200
    },
    {
      "epoch": 839.06,
      "learning_rate": 0.016126535486451612,
      "loss": 0.5153,
      "step": 520220
    },
    {
      "epoch": 839.1,
      "learning_rate": 0.016123309683225808,
      "loss": 0.5245,
      "step": 520240
    },
    {
      "epoch": 839.13,
      "learning_rate": 0.01612008388,
      "loss": 0.5266,
      "step": 520260
    },
    {
      "epoch": 839.16,
      "learning_rate": 0.016116858076774196,
      "loss": 0.5192,
      "step": 520280
    },
    {
      "epoch": 839.19,
      "learning_rate": 0.016113632273548388,
      "loss": 0.5197,
      "step": 520300
    },
    {
      "epoch": 839.23,
      "learning_rate": 0.016110406470322584,
      "loss": 0.5171,
      "step": 520320
    },
    {
      "epoch": 839.26,
      "learning_rate": 0.01610718066709678,
      "loss": 0.5122,
      "step": 520340
    },
    {
      "epoch": 839.29,
      "learning_rate": 0.01610395486387097,
      "loss": 0.5309,
      "step": 520360
    },
    {
      "epoch": 839.32,
      "learning_rate": 0.016100729060645167,
      "loss": 0.5229,
      "step": 520380
    },
    {
      "epoch": 839.35,
      "learning_rate": 0.01609750325741935,
      "loss": 0.5155,
      "step": 520400
    },
    {
      "epoch": 839.39,
      "learning_rate": 0.016094277454193544,
      "loss": 0.5238,
      "step": 520420
    },
    {
      "epoch": 839.42,
      "learning_rate": 0.016091051650967737,
      "loss": 0.5168,
      "step": 520440
    },
    {
      "epoch": 839.45,
      "learning_rate": 0.016087825847741932,
      "loss": 0.5201,
      "step": 520460
    },
    {
      "epoch": 839.48,
      "learning_rate": 0.016084600044516128,
      "loss": 0.532,
      "step": 520480
    },
    {
      "epoch": 839.52,
      "learning_rate": 0.01608137424129032,
      "loss": 0.5235,
      "step": 520500
    },
    {
      "epoch": 839.55,
      "learning_rate": 0.016078148438064516,
      "loss": 0.5111,
      "step": 520520
    },
    {
      "epoch": 839.58,
      "learning_rate": 0.016074922634838708,
      "loss": 0.5344,
      "step": 520540
    },
    {
      "epoch": 839.61,
      "learning_rate": 0.016071696831612903,
      "loss": 0.5334,
      "step": 520560
    },
    {
      "epoch": 839.65,
      "learning_rate": 0.0160684710283871,
      "loss": 0.5267,
      "step": 520580
    },
    {
      "epoch": 839.68,
      "learning_rate": 0.01606524522516129,
      "loss": 0.5174,
      "step": 520600
    },
    {
      "epoch": 839.71,
      "learning_rate": 0.016062019421935487,
      "loss": 0.5192,
      "step": 520620
    },
    {
      "epoch": 839.74,
      "learning_rate": 0.01605879361870968,
      "loss": 0.5187,
      "step": 520640
    },
    {
      "epoch": 839.77,
      "learning_rate": 0.016055567815483875,
      "loss": 0.5352,
      "step": 520660
    },
    {
      "epoch": 839.81,
      "learning_rate": 0.01605234201225807,
      "loss": 0.5296,
      "step": 520680
    },
    {
      "epoch": 839.84,
      "learning_rate": 0.016049116209032252,
      "loss": 0.522,
      "step": 520700
    },
    {
      "epoch": 839.87,
      "learning_rate": 0.016045890405806448,
      "loss": 0.5281,
      "step": 520720
    },
    {
      "epoch": 839.9,
      "learning_rate": 0.01604266460258064,
      "loss": 0.5284,
      "step": 520740
    },
    {
      "epoch": 839.94,
      "learning_rate": 0.016039438799354835,
      "loss": 0.517,
      "step": 520760
    },
    {
      "epoch": 839.97,
      "learning_rate": 0.01603621299612903,
      "loss": 0.5248,
      "step": 520780
    },
    {
      "epoch": 840.0,
      "learning_rate": 0.016032987192903223,
      "loss": 0.5384,
      "step": 520800
    },
    {
      "epoch": 840.0,
      "eval_accuracy": {
        "accuracy": 0.7869018811958474
      },
      "eval_loss": 0.8863615989685059,
      "eval_runtime": 3.2162,
      "eval_samples_per_second": 3983.219,
      "eval_steps_per_second": 62.495,
      "step": 520800
    },
    {
      "epoch": 840.03,
      "learning_rate": 0.01602976138967742,
      "loss": 0.5285,
      "step": 520820
    },
    {
      "epoch": 840.06,
      "learning_rate": 0.01602653558645161,
      "loss": 0.5155,
      "step": 520840
    },
    {
      "epoch": 840.1,
      "learning_rate": 0.016023309783225807,
      "loss": 0.5204,
      "step": 520860
    },
    {
      "epoch": 840.13,
      "learning_rate": 0.016020083980000002,
      "loss": 0.5206,
      "step": 520880
    },
    {
      "epoch": 840.16,
      "learning_rate": 0.016016858176774194,
      "loss": 0.5166,
      "step": 520900
    },
    {
      "epoch": 840.19,
      "learning_rate": 0.01601363237354839,
      "loss": 0.5209,
      "step": 520920
    },
    {
      "epoch": 840.23,
      "learning_rate": 0.016010406570322582,
      "loss": 0.5126,
      "step": 520940
    },
    {
      "epoch": 840.26,
      "learning_rate": 0.016007180767096778,
      "loss": 0.5247,
      "step": 520960
    },
    {
      "epoch": 840.29,
      "learning_rate": 0.016003954963870973,
      "loss": 0.52,
      "step": 520980
    },
    {
      "epoch": 840.32,
      "learning_rate": 0.016000729160645166,
      "loss": 0.5247,
      "step": 521000
    },
    {
      "epoch": 840.35,
      "learning_rate": 0.01599750335741935,
      "loss": 0.5283,
      "step": 521020
    },
    {
      "epoch": 840.39,
      "learning_rate": 0.015994277554193543,
      "loss": 0.5257,
      "step": 521040
    },
    {
      "epoch": 840.42,
      "learning_rate": 0.01599105175096774,
      "loss": 0.5199,
      "step": 521060
    },
    {
      "epoch": 840.45,
      "learning_rate": 0.01598782594774193,
      "loss": 0.5272,
      "step": 521080
    },
    {
      "epoch": 840.48,
      "learning_rate": 0.015984600144516126,
      "loss": 0.5235,
      "step": 521100
    },
    {
      "epoch": 840.52,
      "learning_rate": 0.015981374341290322,
      "loss": 0.5214,
      "step": 521120
    },
    {
      "epoch": 840.55,
      "learning_rate": 0.015978148538064514,
      "loss": 0.5164,
      "step": 521140
    },
    {
      "epoch": 840.58,
      "learning_rate": 0.01597492273483871,
      "loss": 0.5281,
      "step": 521160
    },
    {
      "epoch": 840.61,
      "learning_rate": 0.015971696931612902,
      "loss": 0.5212,
      "step": 521180
    },
    {
      "epoch": 840.65,
      "learning_rate": 0.015968471128387098,
      "loss": 0.526,
      "step": 521200
    },
    {
      "epoch": 840.68,
      "learning_rate": 0.015965245325161293,
      "loss": 0.5273,
      "step": 521220
    },
    {
      "epoch": 840.71,
      "learning_rate": 0.015962019521935485,
      "loss": 0.5289,
      "step": 521240
    },
    {
      "epoch": 840.74,
      "learning_rate": 0.01595879371870968,
      "loss": 0.529,
      "step": 521260
    },
    {
      "epoch": 840.77,
      "learning_rate": 0.015955567915483877,
      "loss": 0.5213,
      "step": 521280
    },
    {
      "epoch": 840.81,
      "learning_rate": 0.01595234211225807,
      "loss": 0.5257,
      "step": 521300
    },
    {
      "epoch": 840.84,
      "learning_rate": 0.015949116309032264,
      "loss": 0.5266,
      "step": 521320
    },
    {
      "epoch": 840.87,
      "learning_rate": 0.015945890505806446,
      "loss": 0.5325,
      "step": 521340
    },
    {
      "epoch": 840.9,
      "learning_rate": 0.01594266470258064,
      "loss": 0.5286,
      "step": 521360
    },
    {
      "epoch": 840.94,
      "learning_rate": 0.015939438899354834,
      "loss": 0.5224,
      "step": 521380
    },
    {
      "epoch": 840.97,
      "learning_rate": 0.01593621309612903,
      "loss": 0.5279,
      "step": 521400
    },
    {
      "epoch": 841.0,
      "learning_rate": 0.01593314858306452,
      "loss": 0.5223,
      "step": 521420
    },
    {
      "epoch": 841.0,
      "eval_accuracy": {
        "accuracy": 0.7849504332214503
      },
      "eval_loss": 0.8921514749526978,
      "eval_runtime": 3.0139,
      "eval_samples_per_second": 4250.675,
      "eval_steps_per_second": 66.692,
      "step": 521420
    },
    {
      "epoch": 841.03,
      "learning_rate": 0.015929922779838714,
      "loss": 0.5201,
      "step": 521440
    },
    {
      "epoch": 841.06,
      "learning_rate": 0.01592669697661291,
      "loss": 0.5239,
      "step": 521460
    },
    {
      "epoch": 841.1,
      "learning_rate": 0.01592347117338709,
      "loss": 0.5181,
      "step": 521480
    },
    {
      "epoch": 841.13,
      "learning_rate": 0.015920245370161287,
      "loss": 0.5159,
      "step": 521500
    },
    {
      "epoch": 841.16,
      "learning_rate": 0.01591701956693548,
      "loss": 0.5186,
      "step": 521520
    },
    {
      "epoch": 841.19,
      "learning_rate": 0.015913793763709674,
      "loss": 0.5278,
      "step": 521540
    },
    {
      "epoch": 841.23,
      "learning_rate": 0.01591056796048387,
      "loss": 0.5196,
      "step": 521560
    },
    {
      "epoch": 841.26,
      "learning_rate": 0.015907342157258062,
      "loss": 0.5154,
      "step": 521580
    },
    {
      "epoch": 841.29,
      "learning_rate": 0.015904116354032258,
      "loss": 0.5165,
      "step": 521600
    },
    {
      "epoch": 841.32,
      "learning_rate": 0.01590089055080645,
      "loss": 0.5234,
      "step": 521620
    },
    {
      "epoch": 841.35,
      "learning_rate": 0.015897664747580646,
      "loss": 0.5139,
      "step": 521640
    },
    {
      "epoch": 841.39,
      "learning_rate": 0.01589443894435484,
      "loss": 0.5295,
      "step": 521660
    },
    {
      "epoch": 841.42,
      "learning_rate": 0.015891213141129033,
      "loss": 0.521,
      "step": 521680
    },
    {
      "epoch": 841.45,
      "learning_rate": 0.01588798733790323,
      "loss": 0.5254,
      "step": 521700
    },
    {
      "epoch": 841.48,
      "learning_rate": 0.01588476153467742,
      "loss": 0.522,
      "step": 521720
    },
    {
      "epoch": 841.52,
      "learning_rate": 0.015881535731451617,
      "loss": 0.5219,
      "step": 521740
    },
    {
      "epoch": 841.55,
      "learning_rate": 0.015878309928225812,
      "loss": 0.5184,
      "step": 521760
    },
    {
      "epoch": 841.58,
      "learning_rate": 0.015875084124999994,
      "loss": 0.5237,
      "step": 521780
    },
    {
      "epoch": 841.61,
      "learning_rate": 0.01587185832177419,
      "loss": 0.5344,
      "step": 521800
    },
    {
      "epoch": 841.65,
      "learning_rate": 0.015868632518548382,
      "loss": 0.5174,
      "step": 521820
    },
    {
      "epoch": 841.68,
      "learning_rate": 0.015865406715322578,
      "loss": 0.521,
      "step": 521840
    },
    {
      "epoch": 841.71,
      "learning_rate": 0.015862180912096773,
      "loss": 0.5133,
      "step": 521860
    },
    {
      "epoch": 841.74,
      "learning_rate": 0.015858955108870965,
      "loss": 0.5206,
      "step": 521880
    },
    {
      "epoch": 841.77,
      "learning_rate": 0.01585572930564516,
      "loss": 0.5289,
      "step": 521900
    },
    {
      "epoch": 841.81,
      "learning_rate": 0.015852503502419353,
      "loss": 0.5233,
      "step": 521920
    },
    {
      "epoch": 841.84,
      "learning_rate": 0.01584927769919355,
      "loss": 0.5121,
      "step": 521940
    },
    {
      "epoch": 841.87,
      "learning_rate": 0.015846051895967744,
      "loss": 0.5248,
      "step": 521960
    },
    {
      "epoch": 841.9,
      "learning_rate": 0.015842826092741936,
      "loss": 0.5312,
      "step": 521980
    },
    {
      "epoch": 841.94,
      "learning_rate": 0.015839600289516132,
      "loss": 0.5298,
      "step": 522000
    },
    {
      "epoch": 841.97,
      "learning_rate": 0.015836374486290324,
      "loss": 0.5241,
      "step": 522020
    },
    {
      "epoch": 842.0,
      "learning_rate": 0.01583314868306452,
      "loss": 0.5141,
      "step": 522040
    },
    {
      "epoch": 842.0,
      "eval_accuracy": {
        "accuracy": 0.7897900241979549
      },
      "eval_loss": 0.8826013207435608,
      "eval_runtime": 4.4123,
      "eval_samples_per_second": 2903.474,
      "eval_steps_per_second": 45.554,
      "step": 522040
    },
    {
      "epoch": 842.03,
      "learning_rate": 0.015829922879838716,
      "loss": 0.5281,
      "step": 522060
    },
    {
      "epoch": 842.06,
      "learning_rate": 0.015826697076612908,
      "loss": 0.5151,
      "step": 522080
    },
    {
      "epoch": 842.1,
      "learning_rate": 0.015823471273387093,
      "loss": 0.5229,
      "step": 522100
    },
    {
      "epoch": 842.13,
      "learning_rate": 0.015820245470161285,
      "loss": 0.5155,
      "step": 522120
    },
    {
      "epoch": 842.16,
      "learning_rate": 0.01581701966693548,
      "loss": 0.5247,
      "step": 522140
    },
    {
      "epoch": 842.19,
      "learning_rate": 0.015813793863709673,
      "loss": 0.5267,
      "step": 522160
    },
    {
      "epoch": 842.23,
      "learning_rate": 0.01581056806048387,
      "loss": 0.5114,
      "step": 522180
    },
    {
      "epoch": 842.26,
      "learning_rate": 0.015807342257258064,
      "loss": 0.5267,
      "step": 522200
    },
    {
      "epoch": 842.29,
      "learning_rate": 0.015804116454032256,
      "loss": 0.5143,
      "step": 522220
    },
    {
      "epoch": 842.32,
      "learning_rate": 0.015800890650806452,
      "loss": 0.52,
      "step": 522240
    },
    {
      "epoch": 842.35,
      "learning_rate": 0.015797664847580644,
      "loss": 0.5088,
      "step": 522260
    },
    {
      "epoch": 842.39,
      "learning_rate": 0.01579443904435484,
      "loss": 0.5213,
      "step": 522280
    },
    {
      "epoch": 842.42,
      "learning_rate": 0.015791213241129035,
      "loss": 0.5176,
      "step": 522300
    },
    {
      "epoch": 842.45,
      "learning_rate": 0.015787987437903227,
      "loss": 0.5162,
      "step": 522320
    },
    {
      "epoch": 842.48,
      "learning_rate": 0.015784761634677423,
      "loss": 0.5116,
      "step": 522340
    },
    {
      "epoch": 842.52,
      "learning_rate": 0.01578153583145162,
      "loss": 0.5124,
      "step": 522360
    },
    {
      "epoch": 842.55,
      "learning_rate": 0.01577831002822581,
      "loss": 0.5246,
      "step": 522380
    },
    {
      "epoch": 842.58,
      "learning_rate": 0.015775084224999996,
      "loss": 0.5346,
      "step": 522400
    },
    {
      "epoch": 842.61,
      "learning_rate": 0.015771858421774188,
      "loss": 0.5293,
      "step": 522420
    },
    {
      "epoch": 842.65,
      "learning_rate": 0.015768632618548384,
      "loss": 0.534,
      "step": 522440
    },
    {
      "epoch": 842.68,
      "learning_rate": 0.015765406815322576,
      "loss": 0.5298,
      "step": 522460
    },
    {
      "epoch": 842.71,
      "learning_rate": 0.01576218101209677,
      "loss": 0.5028,
      "step": 522480
    },
    {
      "epoch": 842.74,
      "learning_rate": 0.015758955208870967,
      "loss": 0.5236,
      "step": 522500
    },
    {
      "epoch": 842.77,
      "learning_rate": 0.01575572940564516,
      "loss": 0.5344,
      "step": 522520
    },
    {
      "epoch": 842.81,
      "learning_rate": 0.015752503602419355,
      "loss": 0.5283,
      "step": 522540
    },
    {
      "epoch": 842.84,
      "learning_rate": 0.015749277799193547,
      "loss": 0.5245,
      "step": 522560
    },
    {
      "epoch": 842.87,
      "learning_rate": 0.015746051995967743,
      "loss": 0.5303,
      "step": 522580
    },
    {
      "epoch": 842.9,
      "learning_rate": 0.01574282619274194,
      "loss": 0.5338,
      "step": 522600
    },
    {
      "epoch": 842.94,
      "learning_rate": 0.01573960038951613,
      "loss": 0.5296,
      "step": 522620
    },
    {
      "epoch": 842.97,
      "learning_rate": 0.015736374586290326,
      "loss": 0.536,
      "step": 522640
    },
    {
      "epoch": 843.0,
      "learning_rate": 0.01573314878306452,
      "loss": 0.5306,
      "step": 522660
    },
    {
      "epoch": 843.0,
      "eval_accuracy": {
        "accuracy": 0.7848723753024744
      },
      "eval_loss": 0.886865496635437,
      "eval_runtime": 3.1148,
      "eval_samples_per_second": 4112.93,
      "eval_steps_per_second": 64.53,
      "step": 522660
    },
    {
      "epoch": 843.03,
      "learning_rate": 0.015729922979838714,
      "loss": 0.5247,
      "step": 522680
    },
    {
      "epoch": 843.06,
      "learning_rate": 0.01572669717661291,
      "loss": 0.5133,
      "step": 522700
    },
    {
      "epoch": 843.1,
      "learning_rate": 0.01572347137338709,
      "loss": 0.5222,
      "step": 522720
    },
    {
      "epoch": 843.13,
      "learning_rate": 0.015720245570161287,
      "loss": 0.5213,
      "step": 522740
    },
    {
      "epoch": 843.16,
      "learning_rate": 0.01571701976693548,
      "loss": 0.5226,
      "step": 522760
    },
    {
      "epoch": 843.19,
      "learning_rate": 0.015713793963709675,
      "loss": 0.5169,
      "step": 522780
    },
    {
      "epoch": 843.23,
      "learning_rate": 0.015710568160483867,
      "loss": 0.5187,
      "step": 522800
    },
    {
      "epoch": 843.26,
      "learning_rate": 0.015707342357258063,
      "loss": 0.5228,
      "step": 522820
    },
    {
      "epoch": 843.29,
      "learning_rate": 0.015704116554032258,
      "loss": 0.5284,
      "step": 522840
    },
    {
      "epoch": 843.32,
      "learning_rate": 0.01570089075080645,
      "loss": 0.5259,
      "step": 522860
    },
    {
      "epoch": 843.35,
      "learning_rate": 0.015697664947580646,
      "loss": 0.5373,
      "step": 522880
    },
    {
      "epoch": 843.39,
      "learning_rate": 0.01569443914435484,
      "loss": 0.5175,
      "step": 522900
    },
    {
      "epoch": 843.42,
      "learning_rate": 0.015691213341129034,
      "loss": 0.542,
      "step": 522920
    },
    {
      "epoch": 843.45,
      "learning_rate": 0.01568798753790323,
      "loss": 0.5153,
      "step": 522940
    },
    {
      "epoch": 843.48,
      "learning_rate": 0.01568476173467742,
      "loss": 0.5227,
      "step": 522960
    },
    {
      "epoch": 843.52,
      "learning_rate": 0.015681535931451617,
      "loss": 0.5249,
      "step": 522980
    },
    {
      "epoch": 843.55,
      "learning_rate": 0.015678310128225813,
      "loss": 0.5193,
      "step": 523000
    },
    {
      "epoch": 843.58,
      "learning_rate": 0.015675084324999995,
      "loss": 0.5231,
      "step": 523020
    },
    {
      "epoch": 843.61,
      "learning_rate": 0.01567185852177419,
      "loss": 0.5218,
      "step": 523040
    },
    {
      "epoch": 843.65,
      "learning_rate": 0.015668632718548382,
      "loss": 0.5243,
      "step": 523060
    },
    {
      "epoch": 843.68,
      "learning_rate": 0.015665406915322578,
      "loss": 0.5214,
      "step": 523080
    },
    {
      "epoch": 843.71,
      "learning_rate": 0.01566218111209677,
      "loss": 0.5205,
      "step": 523100
    },
    {
      "epoch": 843.74,
      "learning_rate": 0.015658955308870966,
      "loss": 0.5076,
      "step": 523120
    },
    {
      "epoch": 843.77,
      "learning_rate": 0.01565572950564516,
      "loss": 0.5162,
      "step": 523140
    },
    {
      "epoch": 843.81,
      "learning_rate": 0.015652503702419353,
      "loss": 0.511,
      "step": 523160
    },
    {
      "epoch": 843.84,
      "learning_rate": 0.01564927789919355,
      "loss": 0.5177,
      "step": 523180
    },
    {
      "epoch": 843.87,
      "learning_rate": 0.01564605209596774,
      "loss": 0.5189,
      "step": 523200
    },
    {
      "epoch": 843.9,
      "learning_rate": 0.015642826292741937,
      "loss": 0.5217,
      "step": 523220
    },
    {
      "epoch": 843.94,
      "learning_rate": 0.015639600489516133,
      "loss": 0.5272,
      "step": 523240
    },
    {
      "epoch": 843.97,
      "learning_rate": 0.015636374686290325,
      "loss": 0.5202,
      "step": 523260
    },
    {
      "epoch": 844.0,
      "learning_rate": 0.01563314888306452,
      "loss": 0.5316,
      "step": 523280
    },
    {
      "epoch": 844.0,
      "eval_accuracy": {
        "accuracy": 0.7872921707907267
      },
      "eval_loss": 0.8763934373855591,
      "eval_runtime": 3.3111,
      "eval_samples_per_second": 3869.053,
      "eval_steps_per_second": 60.704,
      "step": 523280
    },
    {
      "epoch": 844.03,
      "learning_rate": 0.015629923079838712,
      "loss": 0.5155,
      "step": 523300
    },
    {
      "epoch": 844.06,
      "learning_rate": 0.015626697276612908,
      "loss": 0.5185,
      "step": 523320
    },
    {
      "epoch": 844.1,
      "learning_rate": 0.015623471473387092,
      "loss": 0.519,
      "step": 523340
    },
    {
      "epoch": 844.13,
      "learning_rate": 0.015620245670161285,
      "loss": 0.5134,
      "step": 523360
    },
    {
      "epoch": 844.16,
      "learning_rate": 0.015617019866935478,
      "loss": 0.5108,
      "step": 523380
    },
    {
      "epoch": 844.19,
      "learning_rate": 0.015613794063709675,
      "loss": 0.5141,
      "step": 523400
    },
    {
      "epoch": 844.23,
      "learning_rate": 0.015610568260483869,
      "loss": 0.5083,
      "step": 523420
    },
    {
      "epoch": 844.26,
      "learning_rate": 0.015607342457258061,
      "loss": 0.5165,
      "step": 523440
    },
    {
      "epoch": 844.29,
      "learning_rate": 0.015604116654032255,
      "loss": 0.5178,
      "step": 523460
    },
    {
      "epoch": 844.32,
      "learning_rate": 0.015600890850806452,
      "loss": 0.5206,
      "step": 523480
    },
    {
      "epoch": 844.35,
      "learning_rate": 0.015597665047580644,
      "loss": 0.5062,
      "step": 523500
    },
    {
      "epoch": 844.39,
      "learning_rate": 0.015594439244354838,
      "loss": 0.5213,
      "step": 523520
    },
    {
      "epoch": 844.42,
      "learning_rate": 0.015591213441129036,
      "loss": 0.5201,
      "step": 523540
    },
    {
      "epoch": 844.45,
      "learning_rate": 0.015587987637903228,
      "loss": 0.5243,
      "step": 523560
    },
    {
      "epoch": 844.48,
      "learning_rate": 0.015584761834677422,
      "loss": 0.5153,
      "step": 523580
    },
    {
      "epoch": 844.52,
      "learning_rate": 0.015581536031451619,
      "loss": 0.5147,
      "step": 523600
    },
    {
      "epoch": 844.55,
      "learning_rate": 0.015578310228225811,
      "loss": 0.5246,
      "step": 523620
    },
    {
      "epoch": 844.58,
      "learning_rate": 0.015575084425000005,
      "loss": 0.5138,
      "step": 523640
    },
    {
      "epoch": 844.61,
      "learning_rate": 0.015571858621774189,
      "loss": 0.525,
      "step": 523660
    },
    {
      "epoch": 844.65,
      "learning_rate": 0.01556863281854838,
      "loss": 0.519,
      "step": 523680
    },
    {
      "epoch": 844.68,
      "learning_rate": 0.015565407015322575,
      "loss": 0.5224,
      "step": 523700
    },
    {
      "epoch": 844.71,
      "learning_rate": 0.015562181212096772,
      "loss": 0.524,
      "step": 523720
    },
    {
      "epoch": 844.74,
      "learning_rate": 0.015558955408870964,
      "loss": 0.5408,
      "step": 523740
    },
    {
      "epoch": 844.77,
      "learning_rate": 0.015555729605645158,
      "loss": 0.5293,
      "step": 523760
    },
    {
      "epoch": 844.81,
      "learning_rate": 0.015552503802419355,
      "loss": 0.5319,
      "step": 523780
    },
    {
      "epoch": 844.84,
      "learning_rate": 0.015549277999193548,
      "loss": 0.5296,
      "step": 523800
    },
    {
      "epoch": 844.87,
      "learning_rate": 0.015546052195967741,
      "loss": 0.515,
      "step": 523820
    },
    {
      "epoch": 844.9,
      "learning_rate": 0.015542826392741939,
      "loss": 0.5296,
      "step": 523840
    },
    {
      "epoch": 844.94,
      "learning_rate": 0.015539600589516131,
      "loss": 0.5316,
      "step": 523860
    },
    {
      "epoch": 844.97,
      "learning_rate": 0.015536374786290325,
      "loss": 0.5267,
      "step": 523880
    },
    {
      "epoch": 845.0,
      "learning_rate": 0.015533148983064519,
      "loss": 0.5077,
      "step": 523900
    },
    {
      "epoch": 845.0,
      "eval_accuracy": {
        "accuracy": 0.789087502927172
      },
      "eval_loss": 0.8754405379295349,
      "eval_runtime": 4.074,
      "eval_samples_per_second": 3144.564,
      "eval_steps_per_second": 49.337,
      "step": 523900
    },
    {
      "epoch": 845.03,
      "learning_rate": 0.015529923179838714,
      "loss": 0.5141,
      "step": 523920
    },
    {
      "epoch": 845.06,
      "learning_rate": 0.015526697376612908,
      "loss": 0.515,
      "step": 523940
    },
    {
      "epoch": 845.1,
      "learning_rate": 0.015523471573387092,
      "loss": 0.5192,
      "step": 523960
    },
    {
      "epoch": 845.13,
      "learning_rate": 0.015520245770161284,
      "loss": 0.5107,
      "step": 523980
    },
    {
      "epoch": 845.16,
      "learning_rate": 0.015517019966935478,
      "loss": 0.5117,
      "step": 524000
    },
    {
      "epoch": 845.19,
      "learning_rate": 0.015513794163709675,
      "loss": 0.5168,
      "step": 524020
    },
    {
      "epoch": 845.23,
      "learning_rate": 0.015510568360483867,
      "loss": 0.5056,
      "step": 524040
    },
    {
      "epoch": 845.26,
      "learning_rate": 0.015507342557258061,
      "loss": 0.5118,
      "step": 524060
    },
    {
      "epoch": 845.29,
      "learning_rate": 0.015504116754032259,
      "loss": 0.5157,
      "step": 524080
    },
    {
      "epoch": 845.32,
      "learning_rate": 0.01550089095080645,
      "loss": 0.5145,
      "step": 524100
    },
    {
      "epoch": 845.35,
      "learning_rate": 0.015497665147580645,
      "loss": 0.5201,
      "step": 524120
    },
    {
      "epoch": 845.39,
      "learning_rate": 0.015494439344354842,
      "loss": 0.5194,
      "step": 524140
    },
    {
      "epoch": 845.42,
      "learning_rate": 0.015491213541129034,
      "loss": 0.5084,
      "step": 524160
    },
    {
      "epoch": 845.45,
      "learning_rate": 0.015487987737903228,
      "loss": 0.5283,
      "step": 524180
    },
    {
      "epoch": 845.48,
      "learning_rate": 0.015484761934677422,
      "loss": 0.5267,
      "step": 524200
    },
    {
      "epoch": 845.52,
      "learning_rate": 0.015481536131451618,
      "loss": 0.521,
      "step": 524220
    },
    {
      "epoch": 845.55,
      "learning_rate": 0.015478310328225811,
      "loss": 0.5085,
      "step": 524240
    },
    {
      "epoch": 845.58,
      "learning_rate": 0.015475084525000005,
      "loss": 0.5314,
      "step": 524260
    },
    {
      "epoch": 845.61,
      "learning_rate": 0.015471858721774187,
      "loss": 0.5249,
      "step": 524280
    },
    {
      "epoch": 845.65,
      "learning_rate": 0.015468632918548381,
      "loss": 0.5268,
      "step": 524300
    },
    {
      "epoch": 845.68,
      "learning_rate": 0.015465407115322578,
      "loss": 0.5204,
      "step": 524320
    },
    {
      "epoch": 845.71,
      "learning_rate": 0.01546218131209677,
      "loss": 0.5282,
      "step": 524340
    },
    {
      "epoch": 845.74,
      "learning_rate": 0.015458955508870964,
      "loss": 0.523,
      "step": 524360
    },
    {
      "epoch": 845.77,
      "learning_rate": 0.015455729705645162,
      "loss": 0.5174,
      "step": 524380
    },
    {
      "epoch": 845.81,
      "learning_rate": 0.015452503902419354,
      "loss": 0.5188,
      "step": 524400
    },
    {
      "epoch": 845.84,
      "learning_rate": 0.015449278099193548,
      "loss": 0.528,
      "step": 524420
    },
    {
      "epoch": 845.87,
      "learning_rate": 0.015446052295967742,
      "loss": 0.531,
      "step": 524440
    },
    {
      "epoch": 845.9,
      "learning_rate": 0.015442826492741937,
      "loss": 0.5284,
      "step": 524460
    },
    {
      "epoch": 845.94,
      "learning_rate": 0.015439600689516131,
      "loss": 0.5261,
      "step": 524480
    },
    {
      "epoch": 845.97,
      "learning_rate": 0.015436374886290325,
      "loss": 0.5325,
      "step": 524500
    },
    {
      "epoch": 846.0,
      "learning_rate": 0.015433149083064519,
      "loss": 0.522,
      "step": 524520
    },
    {
      "epoch": 846.0,
      "eval_accuracy": {
        "accuracy": 0.7861213020060885
      },
      "eval_loss": 0.8775618672370911,
      "eval_runtime": 3.1055,
      "eval_samples_per_second": 4125.212,
      "eval_steps_per_second": 64.723,
      "step": 524520
    },
    {
      "epoch": 846.03,
      "learning_rate": 0.015429923279838715,
      "loss": 0.5184,
      "step": 524540
    },
    {
      "epoch": 846.06,
      "learning_rate": 0.015426697476612908,
      "loss": 0.5158,
      "step": 524560
    },
    {
      "epoch": 846.1,
      "learning_rate": 0.01542347167338709,
      "loss": 0.5118,
      "step": 524580
    },
    {
      "epoch": 846.13,
      "learning_rate": 0.015420245870161284,
      "loss": 0.5199,
      "step": 524600
    },
    {
      "epoch": 846.16,
      "learning_rate": 0.015417020066935481,
      "loss": 0.533,
      "step": 524620
    },
    {
      "epoch": 846.19,
      "learning_rate": 0.015413794263709674,
      "loss": 0.5154,
      "step": 524640
    },
    {
      "epoch": 846.23,
      "learning_rate": 0.015410568460483868,
      "loss": 0.5251,
      "step": 524660
    },
    {
      "epoch": 846.26,
      "learning_rate": 0.015407342657258065,
      "loss": 0.5114,
      "step": 524680
    },
    {
      "epoch": 846.29,
      "learning_rate": 0.015404116854032257,
      "loss": 0.5161,
      "step": 524700
    },
    {
      "epoch": 846.32,
      "learning_rate": 0.015400891050806451,
      "loss": 0.5205,
      "step": 524720
    },
    {
      "epoch": 846.35,
      "learning_rate": 0.015397665247580645,
      "loss": 0.517,
      "step": 524740
    },
    {
      "epoch": 846.39,
      "learning_rate": 0.015394439444354839,
      "loss": 0.5166,
      "step": 524760
    },
    {
      "epoch": 846.42,
      "learning_rate": 0.015391213641129034,
      "loss": 0.5152,
      "step": 524780
    },
    {
      "epoch": 846.45,
      "learning_rate": 0.015387987837903228,
      "loss": 0.5172,
      "step": 524800
    },
    {
      "epoch": 846.48,
      "learning_rate": 0.015384762034677422,
      "loss": 0.5156,
      "step": 524820
    },
    {
      "epoch": 846.52,
      "learning_rate": 0.015381536231451616,
      "loss": 0.5189,
      "step": 524840
    },
    {
      "epoch": 846.55,
      "learning_rate": 0.015378310428225812,
      "loss": 0.5234,
      "step": 524860
    },
    {
      "epoch": 846.58,
      "learning_rate": 0.015375084625000006,
      "loss": 0.5203,
      "step": 524880
    },
    {
      "epoch": 846.61,
      "learning_rate": 0.015371858821774187,
      "loss": 0.5229,
      "step": 524900
    },
    {
      "epoch": 846.65,
      "learning_rate": 0.015368633018548385,
      "loss": 0.5267,
      "step": 524920
    },
    {
      "epoch": 846.68,
      "learning_rate": 0.015365407215322577,
      "loss": 0.5203,
      "step": 524940
    },
    {
      "epoch": 846.71,
      "learning_rate": 0.01536218141209677,
      "loss": 0.5158,
      "step": 524960
    },
    {
      "epoch": 846.74,
      "learning_rate": 0.015358955608870965,
      "loss": 0.5237,
      "step": 524980
    },
    {
      "epoch": 846.77,
      "learning_rate": 0.01535572980564516,
      "loss": 0.521,
      "step": 525000
    },
    {
      "epoch": 846.81,
      "learning_rate": 0.015352504002419354,
      "loss": 0.5251,
      "step": 525020
    },
    {
      "epoch": 846.84,
      "learning_rate": 0.015349278199193548,
      "loss": 0.53,
      "step": 525040
    },
    {
      "epoch": 846.87,
      "learning_rate": 0.015346052395967742,
      "loss": 0.5203,
      "step": 525060
    },
    {
      "epoch": 846.9,
      "learning_rate": 0.015342826592741938,
      "loss": 0.5225,
      "step": 525080
    },
    {
      "epoch": 846.94,
      "learning_rate": 0.015339600789516131,
      "loss": 0.5206,
      "step": 525100
    },
    {
      "epoch": 846.97,
      "learning_rate": 0.015336374986290325,
      "loss": 0.5317,
      "step": 525120
    },
    {
      "epoch": 847.0,
      "learning_rate": 0.01533314918306452,
      "loss": 0.5275,
      "step": 525140
    },
    {
      "epoch": 847.0,
      "eval_accuracy": {
        "accuracy": 0.7840137381937398
      },
      "eval_loss": 0.8817930221557617,
      "eval_runtime": 3.2556,
      "eval_samples_per_second": 3935.064,
      "eval_steps_per_second": 61.74,
      "step": 525140
    },
    {
      "epoch": 847.03,
      "learning_rate": 0.015329923379838711,
      "loss": 0.524,
      "step": 525160
    },
    {
      "epoch": 847.06,
      "learning_rate": 0.015326697576612909,
      "loss": 0.5163,
      "step": 525180
    },
    {
      "epoch": 847.1,
      "learning_rate": 0.01532347177338709,
      "loss": 0.506,
      "step": 525200
    },
    {
      "epoch": 847.13,
      "learning_rate": 0.015320245970161288,
      "loss": 0.5022,
      "step": 525220
    },
    {
      "epoch": 847.16,
      "learning_rate": 0.01531702016693548,
      "loss": 0.5115,
      "step": 525240
    },
    {
      "epoch": 847.19,
      "learning_rate": 0.015313794363709674,
      "loss": 0.5165,
      "step": 525260
    },
    {
      "epoch": 847.23,
      "learning_rate": 0.015310568560483868,
      "loss": 0.5079,
      "step": 525280
    },
    {
      "epoch": 847.26,
      "learning_rate": 0.015307342757258062,
      "loss": 0.5161,
      "step": 525300
    },
    {
      "epoch": 847.29,
      "learning_rate": 0.015304116954032257,
      "loss": 0.512,
      "step": 525320
    },
    {
      "epoch": 847.32,
      "learning_rate": 0.015300891150806451,
      "loss": 0.5224,
      "step": 525340
    },
    {
      "epoch": 847.35,
      "learning_rate": 0.015297665347580645,
      "loss": 0.5247,
      "step": 525360
    },
    {
      "epoch": 847.39,
      "learning_rate": 0.015294439544354839,
      "loss": 0.5303,
      "step": 525380
    },
    {
      "epoch": 847.42,
      "learning_rate": 0.015291213741129035,
      "loss": 0.5258,
      "step": 525400
    },
    {
      "epoch": 847.45,
      "learning_rate": 0.015287987937903228,
      "loss": 0.5151,
      "step": 525420
    },
    {
      "epoch": 847.48,
      "learning_rate": 0.015284923424838706,
      "loss": 0.5187,
      "step": 525440
    },
    {
      "epoch": 847.52,
      "learning_rate": 0.015281697621612904,
      "loss": 0.5205,
      "step": 525460
    },
    {
      "epoch": 847.55,
      "learning_rate": 0.015278471818387096,
      "loss": 0.5226,
      "step": 525480
    },
    {
      "epoch": 847.58,
      "learning_rate": 0.01527524601516129,
      "loss": 0.514,
      "step": 525500
    },
    {
      "epoch": 847.61,
      "learning_rate": 0.015272020211935484,
      "loss": 0.5195,
      "step": 525520
    },
    {
      "epoch": 847.65,
      "learning_rate": 0.01526879440870968,
      "loss": 0.5129,
      "step": 525540
    },
    {
      "epoch": 847.68,
      "learning_rate": 0.015265568605483873,
      "loss": 0.5138,
      "step": 525560
    },
    {
      "epoch": 847.71,
      "learning_rate": 0.015262342802258067,
      "loss": 0.523,
      "step": 525580
    },
    {
      "epoch": 847.74,
      "learning_rate": 0.015259116999032261,
      "loss": 0.5192,
      "step": 525600
    },
    {
      "epoch": 847.77,
      "learning_rate": 0.015255891195806457,
      "loss": 0.5248,
      "step": 525620
    },
    {
      "epoch": 847.81,
      "learning_rate": 0.01525266539258065,
      "loss": 0.5305,
      "step": 525640
    },
    {
      "epoch": 847.84,
      "learning_rate": 0.015249439589354832,
      "loss": 0.5266,
      "step": 525660
    },
    {
      "epoch": 847.87,
      "learning_rate": 0.015246213786129026,
      "loss": 0.516,
      "step": 525680
    },
    {
      "epoch": 847.9,
      "learning_rate": 0.015242987982903224,
      "loss": 0.5267,
      "step": 525700
    },
    {
      "epoch": 847.94,
      "learning_rate": 0.015239762179677416,
      "loss": 0.527,
      "step": 525720
    },
    {
      "epoch": 847.97,
      "learning_rate": 0.01523653637645161,
      "loss": 0.5256,
      "step": 525740
    },
    {
      "epoch": 848.0,
      "learning_rate": 0.015233310573225807,
      "loss": 0.5263,
      "step": 525760
    },
    {
      "epoch": 848.0,
      "eval_accuracy": {
        "accuracy": 0.7870579970337991
      },
      "eval_loss": 0.8709101676940918,
      "eval_runtime": 3.3717,
      "eval_samples_per_second": 3799.586,
      "eval_steps_per_second": 59.614,
      "step": 525760
    },
    {
      "epoch": 848.03,
      "learning_rate": 0.01523008477,
      "loss": 0.5146,
      "step": 525780
    },
    {
      "epoch": 848.06,
      "learning_rate": 0.015226858966774193,
      "loss": 0.5191,
      "step": 525800
    },
    {
      "epoch": 848.1,
      "learning_rate": 0.015223633163548387,
      "loss": 0.5133,
      "step": 525820
    },
    {
      "epoch": 848.13,
      "learning_rate": 0.01522040736032258,
      "loss": 0.5082,
      "step": 525840
    },
    {
      "epoch": 848.16,
      "learning_rate": 0.015217181557096776,
      "loss": 0.5103,
      "step": 525860
    },
    {
      "epoch": 848.19,
      "learning_rate": 0.01521395575387097,
      "loss": 0.5129,
      "step": 525880
    },
    {
      "epoch": 848.23,
      "learning_rate": 0.015210729950645164,
      "loss": 0.5187,
      "step": 525900
    },
    {
      "epoch": 848.26,
      "learning_rate": 0.015207504147419358,
      "loss": 0.531,
      "step": 525920
    },
    {
      "epoch": 848.29,
      "learning_rate": 0.015204278344193554,
      "loss": 0.5295,
      "step": 525940
    },
    {
      "epoch": 848.32,
      "learning_rate": 0.015201052540967748,
      "loss": 0.5107,
      "step": 525960
    },
    {
      "epoch": 848.35,
      "learning_rate": 0.01519782673774193,
      "loss": 0.5174,
      "step": 525980
    },
    {
      "epoch": 848.39,
      "learning_rate": 0.015194600934516127,
      "loss": 0.527,
      "step": 526000
    },
    {
      "epoch": 848.42,
      "learning_rate": 0.015191375131290319,
      "loss": 0.5163,
      "step": 526020
    },
    {
      "epoch": 848.45,
      "learning_rate": 0.015188149328064513,
      "loss": 0.5256,
      "step": 526040
    },
    {
      "epoch": 848.48,
      "learning_rate": 0.015184923524838707,
      "loss": 0.5208,
      "step": 526060
    },
    {
      "epoch": 848.52,
      "learning_rate": 0.015181697721612902,
      "loss": 0.5192,
      "step": 526080
    },
    {
      "epoch": 848.55,
      "learning_rate": 0.015178471918387096,
      "loss": 0.5144,
      "step": 526100
    },
    {
      "epoch": 848.58,
      "learning_rate": 0.01517524611516129,
      "loss": 0.5185,
      "step": 526120
    },
    {
      "epoch": 848.61,
      "learning_rate": 0.015172020311935484,
      "loss": 0.5261,
      "step": 526140
    },
    {
      "epoch": 848.65,
      "learning_rate": 0.01516879450870968,
      "loss": 0.5142,
      "step": 526160
    },
    {
      "epoch": 848.68,
      "learning_rate": 0.015165568705483874,
      "loss": 0.5201,
      "step": 526180
    },
    {
      "epoch": 848.71,
      "learning_rate": 0.015162342902258067,
      "loss": 0.5282,
      "step": 526200
    },
    {
      "epoch": 848.74,
      "learning_rate": 0.015159117099032261,
      "loss": 0.5262,
      "step": 526220
    },
    {
      "epoch": 848.77,
      "learning_rate": 0.015155891295806453,
      "loss": 0.5167,
      "step": 526240
    },
    {
      "epoch": 848.81,
      "learning_rate": 0.01515266549258065,
      "loss": 0.5153,
      "step": 526260
    },
    {
      "epoch": 848.84,
      "learning_rate": 0.015149439689354833,
      "loss": 0.5137,
      "step": 526280
    },
    {
      "epoch": 848.87,
      "learning_rate": 0.01514621388612903,
      "loss": 0.5171,
      "step": 526300
    },
    {
      "epoch": 848.9,
      "learning_rate": 0.015142988082903222,
      "loss": 0.5232,
      "step": 526320
    },
    {
      "epoch": 848.94,
      "learning_rate": 0.015139762279677416,
      "loss": 0.5222,
      "step": 526340
    },
    {
      "epoch": 848.97,
      "learning_rate": 0.01513653647645161,
      "loss": 0.5195,
      "step": 526360
    },
    {
      "epoch": 849.0,
      "learning_rate": 0.015133310673225804,
      "loss": 0.5276,
      "step": 526380
    },
    {
      "epoch": 849.0,
      "eval_accuracy": {
        "accuracy": 0.7919756459292795
      },
      "eval_loss": 0.8740010261535645,
      "eval_runtime": 3.881,
      "eval_samples_per_second": 3300.942,
      "eval_steps_per_second": 51.791,
      "step": 526380
    },
    {
      "epoch": 849.03,
      "learning_rate": 0.01513008487,
      "loss": 0.5246,
      "step": 526400
    },
    {
      "epoch": 849.06,
      "learning_rate": 0.015126859066774193,
      "loss": 0.5138,
      "step": 526420
    },
    {
      "epoch": 849.1,
      "learning_rate": 0.015123633263548387,
      "loss": 0.524,
      "step": 526440
    },
    {
      "epoch": 849.13,
      "learning_rate": 0.015120407460322581,
      "loss": 0.502,
      "step": 526460
    },
    {
      "epoch": 849.16,
      "learning_rate": 0.015117181657096777,
      "loss": 0.5286,
      "step": 526480
    },
    {
      "epoch": 849.19,
      "learning_rate": 0.01511395585387097,
      "loss": 0.5115,
      "step": 526500
    },
    {
      "epoch": 849.23,
      "learning_rate": 0.015110730050645164,
      "loss": 0.5024,
      "step": 526520
    },
    {
      "epoch": 849.26,
      "learning_rate": 0.015107504247419357,
      "loss": 0.5072,
      "step": 526540
    },
    {
      "epoch": 849.29,
      "learning_rate": 0.01510427844419355,
      "loss": 0.5219,
      "step": 526560
    },
    {
      "epoch": 849.32,
      "learning_rate": 0.015101052640967748,
      "loss": 0.5207,
      "step": 526580
    },
    {
      "epoch": 849.35,
      "learning_rate": 0.01509782683774193,
      "loss": 0.5158,
      "step": 526600
    },
    {
      "epoch": 849.39,
      "learning_rate": 0.015094601034516125,
      "loss": 0.5278,
      "step": 526620
    },
    {
      "epoch": 849.42,
      "learning_rate": 0.015091375231290319,
      "loss": 0.5179,
      "step": 526640
    },
    {
      "epoch": 849.45,
      "learning_rate": 0.015088149428064513,
      "loss": 0.5129,
      "step": 526660
    },
    {
      "epoch": 849.48,
      "learning_rate": 0.015084923624838707,
      "loss": 0.513,
      "step": 526680
    },
    {
      "epoch": 849.52,
      "learning_rate": 0.0150816978216129,
      "loss": 0.5354,
      "step": 526700
    },
    {
      "epoch": 849.55,
      "learning_rate": 0.015078472018387096,
      "loss": 0.5234,
      "step": 526720
    },
    {
      "epoch": 849.58,
      "learning_rate": 0.01507524621516129,
      "loss": 0.5237,
      "step": 526740
    },
    {
      "epoch": 849.61,
      "learning_rate": 0.015072020411935484,
      "loss": 0.5309,
      "step": 526760
    },
    {
      "epoch": 849.65,
      "learning_rate": 0.015068794608709676,
      "loss": 0.5131,
      "step": 526780
    },
    {
      "epoch": 849.68,
      "learning_rate": 0.015065568805483874,
      "loss": 0.5122,
      "step": 526800
    },
    {
      "epoch": 849.71,
      "learning_rate": 0.015062343002258068,
      "loss": 0.5265,
      "step": 526820
    },
    {
      "epoch": 849.74,
      "learning_rate": 0.01505911719903226,
      "loss": 0.5206,
      "step": 526840
    },
    {
      "epoch": 849.77,
      "learning_rate": 0.015055891395806454,
      "loss": 0.5137,
      "step": 526860
    },
    {
      "epoch": 849.81,
      "learning_rate": 0.015052665592580651,
      "loss": 0.5208,
      "step": 526880
    },
    {
      "epoch": 849.84,
      "learning_rate": 0.015049439789354833,
      "loss": 0.5168,
      "step": 526900
    },
    {
      "epoch": 849.87,
      "learning_rate": 0.015046213986129027,
      "loss": 0.5139,
      "step": 526920
    },
    {
      "epoch": 849.9,
      "learning_rate": 0.015042988182903222,
      "loss": 0.5199,
      "step": 526940
    },
    {
      "epoch": 849.94,
      "learning_rate": 0.015039762379677416,
      "loss": 0.5269,
      "step": 526960
    },
    {
      "epoch": 849.97,
      "learning_rate": 0.01503653657645161,
      "loss": 0.5143,
      "step": 526980
    },
    {
      "epoch": 850.0,
      "learning_rate": 0.015033310773225804,
      "loss": 0.5171,
      "step": 527000
    },
    {
      "epoch": 850.0,
      "eval_accuracy": {
        "accuracy": 0.7849504332214503
      },
      "eval_loss": 0.8848488926887512,
      "eval_runtime": 3.073,
      "eval_samples_per_second": 4168.941,
      "eval_steps_per_second": 65.409,
      "step": 527000
    },
    {
      "epoch": 850.03,
      "learning_rate": 0.01503008497,
      "loss": 0.5268,
      "step": 527020
    },
    {
      "epoch": 850.06,
      "learning_rate": 0.015026859166774193,
      "loss": 0.5086,
      "step": 527040
    },
    {
      "epoch": 850.1,
      "learning_rate": 0.015023633363548387,
      "loss": 0.5159,
      "step": 527060
    },
    {
      "epoch": 850.13,
      "learning_rate": 0.01502040756032258,
      "loss": 0.5151,
      "step": 527080
    },
    {
      "epoch": 850.16,
      "learning_rate": 0.015017181757096773,
      "loss": 0.502,
      "step": 527100
    },
    {
      "epoch": 850.19,
      "learning_rate": 0.01501395595387097,
      "loss": 0.5175,
      "step": 527120
    },
    {
      "epoch": 850.23,
      "learning_rate": 0.015010730150645163,
      "loss": 0.5128,
      "step": 527140
    },
    {
      "epoch": 850.26,
      "learning_rate": 0.015007504347419357,
      "loss": 0.5232,
      "step": 527160
    },
    {
      "epoch": 850.29,
      "learning_rate": 0.015004278544193554,
      "loss": 0.5125,
      "step": 527180
    },
    {
      "epoch": 850.32,
      "learning_rate": 0.015001052740967746,
      "loss": 0.5301,
      "step": 527200
    },
    {
      "epoch": 850.35,
      "learning_rate": 0.01499782693774193,
      "loss": 0.5207,
      "step": 527220
    },
    {
      "epoch": 850.39,
      "learning_rate": 0.014994601134516124,
      "loss": 0.5127,
      "step": 527240
    },
    {
      "epoch": 850.42,
      "learning_rate": 0.01499137533129032,
      "loss": 0.5307,
      "step": 527260
    },
    {
      "epoch": 850.45,
      "learning_rate": 0.014988149528064513,
      "loss": 0.5112,
      "step": 527280
    },
    {
      "epoch": 850.48,
      "learning_rate": 0.014984923724838707,
      "loss": 0.5161,
      "step": 527300
    },
    {
      "epoch": 850.52,
      "learning_rate": 0.0149816979216129,
      "loss": 0.5194,
      "step": 527320
    },
    {
      "epoch": 850.55,
      "learning_rate": 0.014978472118387097,
      "loss": 0.5174,
      "step": 527340
    },
    {
      "epoch": 850.58,
      "learning_rate": 0.01497524631516129,
      "loss": 0.5173,
      "step": 527360
    },
    {
      "epoch": 850.61,
      "learning_rate": 0.014972020511935483,
      "loss": 0.5307,
      "step": 527380
    },
    {
      "epoch": 850.65,
      "learning_rate": 0.014968794708709677,
      "loss": 0.5183,
      "step": 527400
    },
    {
      "epoch": 850.68,
      "learning_rate": 0.014965568905483874,
      "loss": 0.5279,
      "step": 527420
    },
    {
      "epoch": 850.71,
      "learning_rate": 0.014962504392419352,
      "loss": 0.5191,
      "step": 527440
    },
    {
      "epoch": 850.74,
      "learning_rate": 0.014959278589193546,
      "loss": 0.5142,
      "step": 527460
    },
    {
      "epoch": 850.77,
      "learning_rate": 0.014956052785967741,
      "loss": 0.5163,
      "step": 527480
    },
    {
      "epoch": 850.81,
      "learning_rate": 0.014952826982741935,
      "loss": 0.5189,
      "step": 527500
    },
    {
      "epoch": 850.84,
      "learning_rate": 0.01494960117951613,
      "loss": 0.5122,
      "step": 527520
    },
    {
      "epoch": 850.87,
      "learning_rate": 0.014946375376290323,
      "loss": 0.5214,
      "step": 527540
    },
    {
      "epoch": 850.9,
      "learning_rate": 0.014943149573064519,
      "loss": 0.5211,
      "step": 527560
    },
    {
      "epoch": 850.94,
      "learning_rate": 0.014939923769838713,
      "loss": 0.5266,
      "step": 527580
    },
    {
      "epoch": 850.97,
      "learning_rate": 0.014936697966612907,
      "loss": 0.5177,
      "step": 527600
    },
    {
      "epoch": 851.0,
      "learning_rate": 0.014933472163387099,
      "loss": 0.5149,
      "step": 527620
    },
    {
      "epoch": 851.0,
      "eval_accuracy": {
        "accuracy": 0.7858871282491608
      },
      "eval_loss": 0.8811833262443542,
      "eval_runtime": 3.9702,
      "eval_samples_per_second": 3226.786,
      "eval_steps_per_second": 50.627,
      "step": 527620
    },
    {
      "epoch": 851.03,
      "learning_rate": 0.014930246360161293,
      "loss": 0.5197,
      "step": 527640
    },
    {
      "epoch": 851.06,
      "learning_rate": 0.014927020556935478,
      "loss": 0.5098,
      "step": 527660
    },
    {
      "epoch": 851.1,
      "learning_rate": 0.014923794753709672,
      "loss": 0.5171,
      "step": 527680
    },
    {
      "epoch": 851.13,
      "learning_rate": 0.014920568950483867,
      "loss": 0.52,
      "step": 527700
    },
    {
      "epoch": 851.16,
      "learning_rate": 0.014917343147258061,
      "loss": 0.5176,
      "step": 527720
    },
    {
      "epoch": 851.19,
      "learning_rate": 0.014914117344032255,
      "loss": 0.5149,
      "step": 527740
    },
    {
      "epoch": 851.23,
      "learning_rate": 0.014910891540806449,
      "loss": 0.5155,
      "step": 527760
    },
    {
      "epoch": 851.26,
      "learning_rate": 0.014907665737580643,
      "loss": 0.5074,
      "step": 527780
    },
    {
      "epoch": 851.29,
      "learning_rate": 0.014904439934354839,
      "loss": 0.505,
      "step": 527800
    },
    {
      "epoch": 851.32,
      "learning_rate": 0.014901214131129032,
      "loss": 0.5275,
      "step": 527820
    },
    {
      "epoch": 851.35,
      "learning_rate": 0.014897988327903226,
      "loss": 0.5111,
      "step": 527840
    },
    {
      "epoch": 851.39,
      "learning_rate": 0.014894762524677418,
      "loss": 0.5007,
      "step": 527860
    },
    {
      "epoch": 851.42,
      "learning_rate": 0.014891536721451616,
      "loss": 0.5146,
      "step": 527880
    },
    {
      "epoch": 851.45,
      "learning_rate": 0.01488831091822581,
      "loss": 0.5135,
      "step": 527900
    },
    {
      "epoch": 851.48,
      "learning_rate": 0.014885085115000002,
      "loss": 0.5158,
      "step": 527920
    },
    {
      "epoch": 851.52,
      "learning_rate": 0.014881859311774196,
      "loss": 0.5149,
      "step": 527940
    },
    {
      "epoch": 851.55,
      "learning_rate": 0.014878633508548393,
      "loss": 0.5266,
      "step": 527960
    },
    {
      "epoch": 851.58,
      "learning_rate": 0.014875407705322575,
      "loss": 0.517,
      "step": 527980
    },
    {
      "epoch": 851.61,
      "learning_rate": 0.014872181902096769,
      "loss": 0.5246,
      "step": 528000
    },
    {
      "epoch": 851.65,
      "learning_rate": 0.014868956098870964,
      "loss": 0.525,
      "step": 528020
    },
    {
      "epoch": 851.68,
      "learning_rate": 0.014865730295645158,
      "loss": 0.526,
      "step": 528040
    },
    {
      "epoch": 851.71,
      "learning_rate": 0.014862504492419352,
      "loss": 0.5342,
      "step": 528060
    },
    {
      "epoch": 851.74,
      "learning_rate": 0.014859278689193546,
      "loss": 0.5192,
      "step": 528080
    },
    {
      "epoch": 851.77,
      "learning_rate": 0.014856052885967742,
      "loss": 0.5144,
      "step": 528100
    },
    {
      "epoch": 851.81,
      "learning_rate": 0.014852827082741936,
      "loss": 0.5248,
      "step": 528120
    },
    {
      "epoch": 851.84,
      "learning_rate": 0.01484960127951613,
      "loss": 0.5231,
      "step": 528140
    },
    {
      "epoch": 851.87,
      "learning_rate": 0.014846375476290322,
      "loss": 0.5224,
      "step": 528160
    },
    {
      "epoch": 851.9,
      "learning_rate": 0.014843149673064516,
      "loss": 0.5133,
      "step": 528180
    },
    {
      "epoch": 851.94,
      "learning_rate": 0.014839923869838713,
      "loss": 0.5132,
      "step": 528200
    },
    {
      "epoch": 851.97,
      "learning_rate": 0.014836698066612905,
      "loss": 0.5098,
      "step": 528220
    },
    {
      "epoch": 852.0,
      "learning_rate": 0.014833633553548387,
      "loss": 0.5229,
      "step": 528240
    },
    {
      "epoch": 852.0,
      "eval_accuracy": {
        "accuracy": 0.7902583717118101
      },
      "eval_loss": 0.8643128275871277,
      "eval_runtime": 3.0259,
      "eval_samples_per_second": 4233.785,
      "eval_steps_per_second": 66.427,
      "step": 528240
    },
    {
      "epoch": 852.03,
      "learning_rate": 0.01483040775032258,
      "loss": 0.5077,
      "step": 528260
    },
    {
      "epoch": 852.06,
      "learning_rate": 0.014827181947096774,
      "loss": 0.5191,
      "step": 528280
    },
    {
      "epoch": 852.1,
      "learning_rate": 0.014823956143870968,
      "loss": 0.5116,
      "step": 528300
    },
    {
      "epoch": 852.13,
      "learning_rate": 0.014820730340645164,
      "loss": 0.5145,
      "step": 528320
    },
    {
      "epoch": 852.16,
      "learning_rate": 0.014817504537419358,
      "loss": 0.5241,
      "step": 528340
    },
    {
      "epoch": 852.19,
      "learning_rate": 0.014814278734193552,
      "loss": 0.5191,
      "step": 528360
    },
    {
      "epoch": 852.23,
      "learning_rate": 0.014811052930967746,
      "loss": 0.5258,
      "step": 528380
    },
    {
      "epoch": 852.26,
      "learning_rate": 0.014807827127741938,
      "loss": 0.514,
      "step": 528400
    },
    {
      "epoch": 852.29,
      "learning_rate": 0.014804601324516135,
      "loss": 0.5072,
      "step": 528420
    },
    {
      "epoch": 852.32,
      "learning_rate": 0.014801375521290317,
      "loss": 0.5078,
      "step": 528440
    },
    {
      "epoch": 852.35,
      "learning_rate": 0.014798149718064514,
      "loss": 0.5161,
      "step": 528460
    },
    {
      "epoch": 852.39,
      "learning_rate": 0.014794923914838706,
      "loss": 0.5146,
      "step": 528480
    },
    {
      "epoch": 852.42,
      "learning_rate": 0.0147916981116129,
      "loss": 0.5214,
      "step": 528500
    },
    {
      "epoch": 852.45,
      "learning_rate": 0.014788472308387094,
      "loss": 0.5153,
      "step": 528520
    },
    {
      "epoch": 852.48,
      "learning_rate": 0.014785246505161288,
      "loss": 0.5213,
      "step": 528540
    },
    {
      "epoch": 852.52,
      "learning_rate": 0.014782020701935484,
      "loss": 0.5016,
      "step": 528560
    },
    {
      "epoch": 852.55,
      "learning_rate": 0.014778794898709677,
      "loss": 0.5159,
      "step": 528580
    },
    {
      "epoch": 852.58,
      "learning_rate": 0.014775569095483871,
      "loss": 0.5255,
      "step": 528600
    },
    {
      "epoch": 852.61,
      "learning_rate": 0.014772343292258065,
      "loss": 0.519,
      "step": 528620
    },
    {
      "epoch": 852.65,
      "learning_rate": 0.014769117489032261,
      "loss": 0.5155,
      "step": 528640
    },
    {
      "epoch": 852.68,
      "learning_rate": 0.014765891685806455,
      "loss": 0.5032,
      "step": 528660
    },
    {
      "epoch": 852.71,
      "learning_rate": 0.014762665882580649,
      "loss": 0.5225,
      "step": 528680
    },
    {
      "epoch": 852.74,
      "learning_rate": 0.01475944007935484,
      "loss": 0.5179,
      "step": 528700
    },
    {
      "epoch": 852.77,
      "learning_rate": 0.014756214276129035,
      "loss": 0.5235,
      "step": 528720
    },
    {
      "epoch": 852.81,
      "learning_rate": 0.01475298847290322,
      "loss": 0.5274,
      "step": 528740
    },
    {
      "epoch": 852.84,
      "learning_rate": 0.014749762669677414,
      "loss": 0.5181,
      "step": 528760
    },
    {
      "epoch": 852.87,
      "learning_rate": 0.01474653686645161,
      "loss": 0.5207,
      "step": 528780
    },
    {
      "epoch": 852.9,
      "learning_rate": 0.014743311063225803,
      "loss": 0.5202,
      "step": 528800
    },
    {
      "epoch": 852.94,
      "learning_rate": 0.014740085259999997,
      "loss": 0.5183,
      "step": 528820
    },
    {
      "epoch": 852.97,
      "learning_rate": 0.014736859456774191,
      "loss": 0.5033,
      "step": 528840
    },
    {
      "epoch": 853.0,
      "learning_rate": 0.014733633653548387,
      "loss": 0.5241,
      "step": 528860
    },
    {
      "epoch": 853.0,
      "eval_accuracy": {
        "accuracy": 0.7880727499804855
      },
      "eval_loss": 0.8761700391769409,
      "eval_runtime": 4.0594,
      "eval_samples_per_second": 3155.854,
      "eval_steps_per_second": 49.514,
      "step": 528860
    },
    {
      "epoch": 853.03,
      "learning_rate": 0.01473040785032258,
      "loss": 0.5194,
      "step": 528880
    },
    {
      "epoch": 853.06,
      "learning_rate": 0.014727182047096775,
      "loss": 0.5157,
      "step": 528900
    },
    {
      "epoch": 853.1,
      "learning_rate": 0.014723956243870968,
      "loss": 0.5126,
      "step": 528920
    },
    {
      "epoch": 853.13,
      "learning_rate": 0.01472073044064516,
      "loss": 0.5077,
      "step": 528940
    },
    {
      "epoch": 853.16,
      "learning_rate": 0.014717504637419358,
      "loss": 0.5129,
      "step": 528960
    },
    {
      "epoch": 853.19,
      "learning_rate": 0.014714278834193552,
      "loss": 0.5098,
      "step": 528980
    },
    {
      "epoch": 853.23,
      "learning_rate": 0.014711053030967744,
      "loss": 0.5197,
      "step": 529000
    },
    {
      "epoch": 853.26,
      "learning_rate": 0.014707827227741938,
      "loss": 0.5242,
      "step": 529020
    },
    {
      "epoch": 853.29,
      "learning_rate": 0.014704601424516135,
      "loss": 0.5307,
      "step": 529040
    },
    {
      "epoch": 853.32,
      "learning_rate": 0.014701375621290317,
      "loss": 0.5138,
      "step": 529060
    },
    {
      "epoch": 853.35,
      "learning_rate": 0.01469814981806451,
      "loss": 0.51,
      "step": 529080
    },
    {
      "epoch": 853.39,
      "learning_rate": 0.014694924014838706,
      "loss": 0.5143,
      "step": 529100
    },
    {
      "epoch": 853.42,
      "learning_rate": 0.0146916982116129,
      "loss": 0.519,
      "step": 529120
    },
    {
      "epoch": 853.45,
      "learning_rate": 0.014688472408387094,
      "loss": 0.5108,
      "step": 529140
    },
    {
      "epoch": 853.48,
      "learning_rate": 0.014685246605161288,
      "loss": 0.5234,
      "step": 529160
    },
    {
      "epoch": 853.52,
      "learning_rate": 0.014682020801935484,
      "loss": 0.5021,
      "step": 529180
    },
    {
      "epoch": 853.55,
      "learning_rate": 0.014678794998709678,
      "loss": 0.517,
      "step": 529200
    },
    {
      "epoch": 853.58,
      "learning_rate": 0.014675569195483872,
      "loss": 0.5125,
      "step": 529220
    },
    {
      "epoch": 853.61,
      "learning_rate": 0.014672343392258064,
      "loss": 0.5114,
      "step": 529240
    },
    {
      "epoch": 853.65,
      "learning_rate": 0.014669117589032258,
      "loss": 0.532,
      "step": 529260
    },
    {
      "epoch": 853.68,
      "learning_rate": 0.014665891785806455,
      "loss": 0.5211,
      "step": 529280
    },
    {
      "epoch": 853.71,
      "learning_rate": 0.014662665982580647,
      "loss": 0.5218,
      "step": 529300
    },
    {
      "epoch": 853.74,
      "learning_rate": 0.014659440179354841,
      "loss": 0.5236,
      "step": 529320
    },
    {
      "epoch": 853.77,
      "learning_rate": 0.014656214376129038,
      "loss": 0.5077,
      "step": 529340
    },
    {
      "epoch": 853.81,
      "learning_rate": 0.01465298857290322,
      "loss": 0.5149,
      "step": 529360
    },
    {
      "epoch": 853.84,
      "learning_rate": 0.014649762769677414,
      "loss": 0.5256,
      "step": 529380
    },
    {
      "epoch": 853.87,
      "learning_rate": 0.014646536966451608,
      "loss": 0.5172,
      "step": 529400
    },
    {
      "epoch": 853.9,
      "learning_rate": 0.014643311163225804,
      "loss": 0.5241,
      "step": 529420
    },
    {
      "epoch": 853.94,
      "learning_rate": 0.014640085359999997,
      "loss": 0.5104,
      "step": 529440
    },
    {
      "epoch": 853.97,
      "learning_rate": 0.014636859556774191,
      "loss": 0.5211,
      "step": 529460
    },
    {
      "epoch": 854.0,
      "learning_rate": 0.014633633753548383,
      "loss": 0.5164,
      "step": 529480
    },
    {
      "epoch": 854.0,
      "eval_accuracy": {
        "accuracy": 0.7885410974943408
      },
      "eval_loss": 0.8719342350959778,
      "eval_runtime": 3.4,
      "eval_samples_per_second": 3767.964,
      "eval_steps_per_second": 59.118,
      "step": 529480
    },
    {
      "epoch": 854.03,
      "learning_rate": 0.01463040795032258,
      "loss": 0.5273,
      "step": 529500
    },
    {
      "epoch": 854.06,
      "learning_rate": 0.014627182147096775,
      "loss": 0.5218,
      "step": 529520
    },
    {
      "epoch": 854.1,
      "learning_rate": 0.014623956343870967,
      "loss": 0.5061,
      "step": 529540
    },
    {
      "epoch": 854.13,
      "learning_rate": 0.01462073054064516,
      "loss": 0.5133,
      "step": 529560
    },
    {
      "epoch": 854.16,
      "learning_rate": 0.014617504737419358,
      "loss": 0.5221,
      "step": 529580
    },
    {
      "epoch": 854.19,
      "learning_rate": 0.01461427893419355,
      "loss": 0.5121,
      "step": 529600
    },
    {
      "epoch": 854.23,
      "learning_rate": 0.014611053130967744,
      "loss": 0.5187,
      "step": 529620
    },
    {
      "epoch": 854.26,
      "learning_rate": 0.014607827327741942,
      "loss": 0.5145,
      "step": 529640
    },
    {
      "epoch": 854.29,
      "learning_rate": 0.014604601524516134,
      "loss": 0.5215,
      "step": 529660
    },
    {
      "epoch": 854.32,
      "learning_rate": 0.014601375721290317,
      "loss": 0.505,
      "step": 529680
    },
    {
      "epoch": 854.35,
      "learning_rate": 0.014598149918064511,
      "loss": 0.5129,
      "step": 529700
    },
    {
      "epoch": 854.39,
      "learning_rate": 0.014594924114838703,
      "loss": 0.5082,
      "step": 529720
    },
    {
      "epoch": 854.42,
      "learning_rate": 0.0145916983116129,
      "loss": 0.5193,
      "step": 529740
    },
    {
      "epoch": 854.45,
      "learning_rate": 0.014588472508387094,
      "loss": 0.5107,
      "step": 529760
    },
    {
      "epoch": 854.48,
      "learning_rate": 0.014585246705161287,
      "loss": 0.5256,
      "step": 529780
    },
    {
      "epoch": 854.52,
      "learning_rate": 0.01458202090193548,
      "loss": 0.5049,
      "step": 529800
    },
    {
      "epoch": 854.55,
      "learning_rate": 0.014578795098709678,
      "loss": 0.5183,
      "step": 529820
    },
    {
      "epoch": 854.58,
      "learning_rate": 0.01457556929548387,
      "loss": 0.5208,
      "step": 529840
    },
    {
      "epoch": 854.61,
      "learning_rate": 0.014572343492258064,
      "loss": 0.5195,
      "step": 529860
    },
    {
      "epoch": 854.65,
      "learning_rate": 0.014569117689032261,
      "loss": 0.5179,
      "step": 529880
    },
    {
      "epoch": 854.68,
      "learning_rate": 0.014565891885806453,
      "loss": 0.5199,
      "step": 529900
    },
    {
      "epoch": 854.71,
      "learning_rate": 0.014562666082580647,
      "loss": 0.513,
      "step": 529920
    },
    {
      "epoch": 854.74,
      "learning_rate": 0.014559440279354845,
      "loss": 0.5248,
      "step": 529940
    },
    {
      "epoch": 854.77,
      "learning_rate": 0.014556214476129037,
      "loss": 0.5186,
      "step": 529960
    },
    {
      "epoch": 854.81,
      "learning_rate": 0.01455298867290322,
      "loss": 0.5071,
      "step": 529980
    },
    {
      "epoch": 854.84,
      "learning_rate": 0.014549762869677414,
      "loss": 0.5091,
      "step": 530000
    },
    {
      "epoch": 854.87,
      "learning_rate": 0.014546537066451606,
      "loss": 0.5255,
      "step": 530020
    },
    {
      "epoch": 854.9,
      "learning_rate": 0.014543311263225804,
      "loss": 0.5224,
      "step": 530040
    },
    {
      "epoch": 854.94,
      "learning_rate": 0.014540085459999998,
      "loss": 0.5184,
      "step": 530060
    },
    {
      "epoch": 854.97,
      "learning_rate": 0.01453685965677419,
      "loss": 0.5247,
      "step": 530080
    },
    {
      "epoch": 855.0,
      "learning_rate": 0.014533633853548384,
      "loss": 0.5188,
      "step": 530100
    },
    {
      "epoch": 855.0,
      "eval_accuracy": {
        "accuracy": 0.785106549059402
      },
      "eval_loss": 0.8782464265823364,
      "eval_runtime": 3.1792,
      "eval_samples_per_second": 4029.675,
      "eval_steps_per_second": 63.224,
      "step": 530100
    },
    {
      "epoch": 855.03,
      "learning_rate": 0.014530408050322581,
      "loss": 0.5169,
      "step": 530120
    },
    {
      "epoch": 855.06,
      "learning_rate": 0.014527182247096773,
      "loss": 0.5197,
      "step": 530140
    },
    {
      "epoch": 855.1,
      "learning_rate": 0.014523956443870967,
      "loss": 0.5098,
      "step": 530160
    },
    {
      "epoch": 855.13,
      "learning_rate": 0.014520730640645164,
      "loss": 0.5125,
      "step": 530180
    },
    {
      "epoch": 855.16,
      "learning_rate": 0.014517504837419357,
      "loss": 0.5049,
      "step": 530200
    },
    {
      "epoch": 855.19,
      "learning_rate": 0.01451427903419355,
      "loss": 0.5189,
      "step": 530220
    },
    {
      "epoch": 855.23,
      "learning_rate": 0.014511053230967748,
      "loss": 0.5139,
      "step": 530240
    },
    {
      "epoch": 855.26,
      "learning_rate": 0.01450782742774194,
      "loss": 0.5048,
      "step": 530260
    },
    {
      "epoch": 855.29,
      "learning_rate": 0.014504601624516134,
      "loss": 0.5137,
      "step": 530280
    },
    {
      "epoch": 855.32,
      "learning_rate": 0.014501375821290317,
      "loss": 0.5274,
      "step": 530300
    },
    {
      "epoch": 855.35,
      "learning_rate": 0.01449815001806451,
      "loss": 0.5084,
      "step": 530320
    },
    {
      "epoch": 855.39,
      "learning_rate": 0.014494924214838703,
      "loss": 0.5084,
      "step": 530340
    },
    {
      "epoch": 855.42,
      "learning_rate": 0.0144916984116129,
      "loss": 0.5078,
      "step": 530360
    },
    {
      "epoch": 855.45,
      "learning_rate": 0.014488472608387093,
      "loss": 0.5233,
      "step": 530380
    },
    {
      "epoch": 855.48,
      "learning_rate": 0.014485246805161287,
      "loss": 0.5101,
      "step": 530400
    },
    {
      "epoch": 855.52,
      "learning_rate": 0.014482021001935484,
      "loss": 0.509,
      "step": 530420
    },
    {
      "epoch": 855.55,
      "learning_rate": 0.014478795198709676,
      "loss": 0.508,
      "step": 530440
    },
    {
      "epoch": 855.58,
      "learning_rate": 0.01447556939548387,
      "loss": 0.5099,
      "step": 530460
    },
    {
      "epoch": 855.61,
      "learning_rate": 0.014472343592258068,
      "loss": 0.5203,
      "step": 530480
    },
    {
      "epoch": 855.65,
      "learning_rate": 0.01446911778903226,
      "loss": 0.5071,
      "step": 530500
    },
    {
      "epoch": 855.68,
      "learning_rate": 0.014465891985806454,
      "loss": 0.5339,
      "step": 530520
    },
    {
      "epoch": 855.71,
      "learning_rate": 0.014462666182580648,
      "loss": 0.5226,
      "step": 530540
    },
    {
      "epoch": 855.74,
      "learning_rate": 0.014459440379354843,
      "loss": 0.5191,
      "step": 530560
    },
    {
      "epoch": 855.77,
      "learning_rate": 0.014456214576129037,
      "loss": 0.5148,
      "step": 530580
    },
    {
      "epoch": 855.81,
      "learning_rate": 0.014452988772903231,
      "loss": 0.5167,
      "step": 530600
    },
    {
      "epoch": 855.84,
      "learning_rate": 0.014449762969677413,
      "loss": 0.5182,
      "step": 530620
    },
    {
      "epoch": 855.87,
      "learning_rate": 0.014446537166451607,
      "loss": 0.5168,
      "step": 530640
    },
    {
      "epoch": 855.9,
      "learning_rate": 0.014443311363225804,
      "loss": 0.5181,
      "step": 530660
    },
    {
      "epoch": 855.94,
      "learning_rate": 0.014440085559999996,
      "loss": 0.5243,
      "step": 530680
    },
    {
      "epoch": 855.97,
      "learning_rate": 0.01443685975677419,
      "loss": 0.5204,
      "step": 530700
    },
    {
      "epoch": 856.0,
      "learning_rate": 0.014433795243709684,
      "loss": 0.5251,
      "step": 530720
    },
    {
      "epoch": 856.0,
      "eval_accuracy": {
        "accuracy": 0.7827648114901257
      },
      "eval_loss": 0.882626473903656,
      "eval_runtime": 3.121,
      "eval_samples_per_second": 4104.788,
      "eval_steps_per_second": 64.403,
      "step": 530720
    },
    {
      "epoch": 856.03,
      "learning_rate": 0.014430569440483876,
      "loss": 0.5105,
      "step": 530740
    },
    {
      "epoch": 856.06,
      "learning_rate": 0.01442734363725806,
      "loss": 0.5124,
      "step": 530760
    },
    {
      "epoch": 856.1,
      "learning_rate": 0.014424117834032253,
      "loss": 0.5138,
      "step": 530780
    },
    {
      "epoch": 856.13,
      "learning_rate": 0.014420892030806449,
      "loss": 0.5074,
      "step": 530800
    },
    {
      "epoch": 856.16,
      "learning_rate": 0.014417666227580643,
      "loss": 0.5156,
      "step": 530820
    },
    {
      "epoch": 856.19,
      "learning_rate": 0.014414440424354837,
      "loss": 0.5223,
      "step": 530840
    },
    {
      "epoch": 856.23,
      "learning_rate": 0.014411214621129029,
      "loss": 0.5143,
      "step": 530860
    },
    {
      "epoch": 856.26,
      "learning_rate": 0.014407988817903223,
      "loss": 0.5167,
      "step": 530880
    },
    {
      "epoch": 856.29,
      "learning_rate": 0.01440476301467742,
      "loss": 0.5146,
      "step": 530900
    },
    {
      "epoch": 856.32,
      "learning_rate": 0.014401537211451612,
      "loss": 0.4993,
      "step": 530920
    },
    {
      "epoch": 856.35,
      "learning_rate": 0.014398311408225806,
      "loss": 0.5085,
      "step": 530940
    },
    {
      "epoch": 856.39,
      "learning_rate": 0.014395085605000003,
      "loss": 0.5158,
      "step": 530960
    },
    {
      "epoch": 856.42,
      "learning_rate": 0.014391859801774196,
      "loss": 0.5223,
      "step": 530980
    },
    {
      "epoch": 856.45,
      "learning_rate": 0.01438863399854839,
      "loss": 0.5106,
      "step": 531000
    },
    {
      "epoch": 856.48,
      "learning_rate": 0.014385408195322587,
      "loss": 0.5199,
      "step": 531020
    },
    {
      "epoch": 856.52,
      "learning_rate": 0.014382182392096779,
      "loss": 0.5058,
      "step": 531040
    },
    {
      "epoch": 856.55,
      "learning_rate": 0.014378956588870962,
      "loss": 0.5131,
      "step": 531060
    },
    {
      "epoch": 856.58,
      "learning_rate": 0.014375730785645156,
      "loss": 0.51,
      "step": 531080
    },
    {
      "epoch": 856.61,
      "learning_rate": 0.014372504982419348,
      "loss": 0.5058,
      "step": 531100
    },
    {
      "epoch": 856.65,
      "learning_rate": 0.014369279179193546,
      "loss": 0.5134,
      "step": 531120
    },
    {
      "epoch": 856.68,
      "learning_rate": 0.01436605337596774,
      "loss": 0.5089,
      "step": 531140
    },
    {
      "epoch": 856.71,
      "learning_rate": 0.014362827572741932,
      "loss": 0.5052,
      "step": 531160
    },
    {
      "epoch": 856.74,
      "learning_rate": 0.014359601769516126,
      "loss": 0.5141,
      "step": 531180
    },
    {
      "epoch": 856.77,
      "learning_rate": 0.014356375966290323,
      "loss": 0.5183,
      "step": 531200
    },
    {
      "epoch": 856.81,
      "learning_rate": 0.014353150163064515,
      "loss": 0.5154,
      "step": 531220
    },
    {
      "epoch": 856.84,
      "learning_rate": 0.01434992435983871,
      "loss": 0.5242,
      "step": 531240
    },
    {
      "epoch": 856.87,
      "learning_rate": 0.014346698556612907,
      "loss": 0.5152,
      "step": 531260
    },
    {
      "epoch": 856.9,
      "learning_rate": 0.014343472753387099,
      "loss": 0.5205,
      "step": 531280
    },
    {
      "epoch": 856.94,
      "learning_rate": 0.014340246950161293,
      "loss": 0.5248,
      "step": 531300
    },
    {
      "epoch": 856.97,
      "learning_rate": 0.01433702114693549,
      "loss": 0.5219,
      "step": 531320
    },
    {
      "epoch": 857.0,
      "learning_rate": 0.014333795343709682,
      "loss": 0.5217,
      "step": 531340
    },
    {
      "epoch": 857.0,
      "eval_accuracy": {
        "accuracy": 0.7840137381937398
      },
      "eval_loss": 0.8758281469345093,
      "eval_runtime": 3.2599,
      "eval_samples_per_second": 3929.833,
      "eval_steps_per_second": 61.658,
      "step": 531340
    },
    {
      "epoch": 857.03,
      "learning_rate": 0.014330569540483876,
      "loss": 0.5163,
      "step": 531360
    },
    {
      "epoch": 857.06,
      "learning_rate": 0.01432734373725806,
      "loss": 0.5094,
      "step": 531380
    },
    {
      "epoch": 857.1,
      "learning_rate": 0.014324117934032252,
      "loss": 0.5198,
      "step": 531400
    },
    {
      "epoch": 857.13,
      "learning_rate": 0.014320892130806446,
      "loss": 0.5086,
      "step": 531420
    },
    {
      "epoch": 857.16,
      "learning_rate": 0.014317666327580643,
      "loss": 0.5177,
      "step": 531440
    },
    {
      "epoch": 857.19,
      "learning_rate": 0.014314440524354835,
      "loss": 0.5111,
      "step": 531460
    },
    {
      "epoch": 857.23,
      "learning_rate": 0.014311214721129029,
      "loss": 0.5028,
      "step": 531480
    },
    {
      "epoch": 857.26,
      "learning_rate": 0.014307988917903226,
      "loss": 0.5122,
      "step": 531500
    },
    {
      "epoch": 857.29,
      "learning_rate": 0.014304763114677418,
      "loss": 0.5148,
      "step": 531520
    },
    {
      "epoch": 857.32,
      "learning_rate": 0.014301537311451612,
      "loss": 0.5177,
      "step": 531540
    },
    {
      "epoch": 857.35,
      "learning_rate": 0.01429831150822581,
      "loss": 0.5157,
      "step": 531560
    },
    {
      "epoch": 857.39,
      "learning_rate": 0.014295085705000002,
      "loss": 0.5143,
      "step": 531580
    },
    {
      "epoch": 857.42,
      "learning_rate": 0.014291859901774196,
      "loss": 0.513,
      "step": 531600
    },
    {
      "epoch": 857.45,
      "learning_rate": 0.01428863409854839,
      "loss": 0.5213,
      "step": 531620
    },
    {
      "epoch": 857.48,
      "learning_rate": 0.014285408295322585,
      "loss": 0.5138,
      "step": 531640
    },
    {
      "epoch": 857.52,
      "learning_rate": 0.01428218249209678,
      "loss": 0.5079,
      "step": 531660
    },
    {
      "epoch": 857.55,
      "learning_rate": 0.014278956688870963,
      "loss": 0.5206,
      "step": 531680
    },
    {
      "epoch": 857.58,
      "learning_rate": 0.014275730885645155,
      "loss": 0.5194,
      "step": 531700
    },
    {
      "epoch": 857.61,
      "learning_rate": 0.014272505082419349,
      "loss": 0.5047,
      "step": 531720
    },
    {
      "epoch": 857.65,
      "learning_rate": 0.014269279279193546,
      "loss": 0.5155,
      "step": 531740
    },
    {
      "epoch": 857.68,
      "learning_rate": 0.014266053475967738,
      "loss": 0.5179,
      "step": 531760
    },
    {
      "epoch": 857.71,
      "learning_rate": 0.014262827672741932,
      "loss": 0.5128,
      "step": 531780
    },
    {
      "epoch": 857.74,
      "learning_rate": 0.01425960186951613,
      "loss": 0.5116,
      "step": 531800
    },
    {
      "epoch": 857.77,
      "learning_rate": 0.014256376066290322,
      "loss": 0.5147,
      "step": 531820
    },
    {
      "epoch": 857.81,
      "learning_rate": 0.014253150263064516,
      "loss": 0.5177,
      "step": 531840
    },
    {
      "epoch": 857.84,
      "learning_rate": 0.014249924459838713,
      "loss": 0.5144,
      "step": 531860
    },
    {
      "epoch": 857.87,
      "learning_rate": 0.014246698656612905,
      "loss": 0.5218,
      "step": 531880
    },
    {
      "epoch": 857.9,
      "learning_rate": 0.014243472853387099,
      "loss": 0.5221,
      "step": 531900
    },
    {
      "epoch": 857.94,
      "learning_rate": 0.014240247050161293,
      "loss": 0.5156,
      "step": 531920
    },
    {
      "epoch": 857.97,
      "learning_rate": 0.014237021246935487,
      "loss": 0.518,
      "step": 531940
    },
    {
      "epoch": 858.0,
      "learning_rate": 0.014233795443709682,
      "loss": 0.5181,
      "step": 531960
    },
    {
      "epoch": 858.0,
      "eval_accuracy": {
        "accuracy": 0.7874482866286785
      },
      "eval_loss": 0.8811703324317932,
      "eval_runtime": 3.0237,
      "eval_samples_per_second": 4236.884,
      "eval_steps_per_second": 66.475,
      "step": 531960
    },
    {
      "epoch": 858.03,
      "learning_rate": 0.014230569640483876,
      "loss": 0.5269,
      "step": 531980
    },
    {
      "epoch": 858.06,
      "learning_rate": 0.014227343837258058,
      "loss": 0.5165,
      "step": 532000
    },
    {
      "epoch": 858.1,
      "learning_rate": 0.014224118034032252,
      "loss": 0.5238,
      "step": 532020
    },
    {
      "epoch": 858.13,
      "learning_rate": 0.01422089223080645,
      "loss": 0.5013,
      "step": 532040
    },
    {
      "epoch": 858.16,
      "learning_rate": 0.014217666427580641,
      "loss": 0.5111,
      "step": 532060
    },
    {
      "epoch": 858.19,
      "learning_rate": 0.014214440624354835,
      "loss": 0.5162,
      "step": 532080
    },
    {
      "epoch": 858.23,
      "learning_rate": 0.014211214821129033,
      "loss": 0.5141,
      "step": 532100
    },
    {
      "epoch": 858.26,
      "learning_rate": 0.014207989017903225,
      "loss": 0.5154,
      "step": 532120
    },
    {
      "epoch": 858.29,
      "learning_rate": 0.014204763214677419,
      "loss": 0.5109,
      "step": 532140
    },
    {
      "epoch": 858.32,
      "learning_rate": 0.014201537411451613,
      "loss": 0.503,
      "step": 532160
    },
    {
      "epoch": 858.35,
      "learning_rate": 0.014198311608225808,
      "loss": 0.5072,
      "step": 532180
    },
    {
      "epoch": 858.39,
      "learning_rate": 0.014195085805000002,
      "loss": 0.5104,
      "step": 532200
    },
    {
      "epoch": 858.42,
      "learning_rate": 0.014191860001774196,
      "loss": 0.5089,
      "step": 532220
    },
    {
      "epoch": 858.45,
      "learning_rate": 0.01418863419854839,
      "loss": 0.5146,
      "step": 532240
    },
    {
      "epoch": 858.48,
      "learning_rate": 0.014185408395322585,
      "loss": 0.5086,
      "step": 532260
    },
    {
      "epoch": 858.52,
      "learning_rate": 0.01418218259209678,
      "loss": 0.5074,
      "step": 532280
    },
    {
      "epoch": 858.55,
      "learning_rate": 0.014178956788870961,
      "loss": 0.5187,
      "step": 532300
    },
    {
      "epoch": 858.58,
      "learning_rate": 0.014175730985645155,
      "loss": 0.5052,
      "step": 532320
    },
    {
      "epoch": 858.61,
      "learning_rate": 0.014172505182419352,
      "loss": 0.5099,
      "step": 532340
    },
    {
      "epoch": 858.65,
      "learning_rate": 0.014169279379193545,
      "loss": 0.5237,
      "step": 532360
    },
    {
      "epoch": 858.68,
      "learning_rate": 0.014166053575967738,
      "loss": 0.5191,
      "step": 532380
    },
    {
      "epoch": 858.71,
      "learning_rate": 0.014162827772741936,
      "loss": 0.5096,
      "step": 532400
    },
    {
      "epoch": 858.74,
      "learning_rate": 0.014159601969516128,
      "loss": 0.5213,
      "step": 532420
    },
    {
      "epoch": 858.77,
      "learning_rate": 0.014156376166290322,
      "loss": 0.5144,
      "step": 532440
    },
    {
      "epoch": 858.81,
      "learning_rate": 0.014153150363064516,
      "loss": 0.5243,
      "step": 532460
    },
    {
      "epoch": 858.84,
      "learning_rate": 0.01414992455983871,
      "loss": 0.5144,
      "step": 532480
    },
    {
      "epoch": 858.87,
      "learning_rate": 0.014146698756612905,
      "loss": 0.5153,
      "step": 532500
    },
    {
      "epoch": 858.9,
      "learning_rate": 0.014143472953387099,
      "loss": 0.517,
      "step": 532520
    },
    {
      "epoch": 858.94,
      "learning_rate": 0.014140247150161293,
      "loss": 0.5178,
      "step": 532540
    },
    {
      "epoch": 858.97,
      "learning_rate": 0.014137021346935487,
      "loss": 0.5195,
      "step": 532560
    },
    {
      "epoch": 859.0,
      "learning_rate": 0.014133795543709683,
      "loss": 0.5183,
      "step": 532580
    },
    {
      "epoch": 859.0,
      "eval_accuracy": {
        "accuracy": 0.7865896495199438
      },
      "eval_loss": 0.876202404499054,
      "eval_runtime": 3.2225,
      "eval_samples_per_second": 3975.449,
      "eval_steps_per_second": 62.373,
      "step": 532580
    },
    {
      "epoch": 859.03,
      "learning_rate": 0.014130569740483876,
      "loss": 0.523,
      "step": 532600
    },
    {
      "epoch": 859.06,
      "learning_rate": 0.014127343937258058,
      "loss": 0.5035,
      "step": 532620
    },
    {
      "epoch": 859.1,
      "learning_rate": 0.014124118134032256,
      "loss": 0.5094,
      "step": 532640
    },
    {
      "epoch": 859.13,
      "learning_rate": 0.014120892330806448,
      "loss": 0.5034,
      "step": 532660
    },
    {
      "epoch": 859.16,
      "learning_rate": 0.014117666527580642,
      "loss": 0.5047,
      "step": 532680
    },
    {
      "epoch": 859.19,
      "learning_rate": 0.014114440724354835,
      "loss": 0.5262,
      "step": 532700
    },
    {
      "epoch": 859.23,
      "learning_rate": 0.014111214921129031,
      "loss": 0.5141,
      "step": 532720
    },
    {
      "epoch": 859.26,
      "learning_rate": 0.014107989117903225,
      "loss": 0.4999,
      "step": 532740
    },
    {
      "epoch": 859.29,
      "learning_rate": 0.014104763314677419,
      "loss": 0.5176,
      "step": 532760
    },
    {
      "epoch": 859.32,
      "learning_rate": 0.014101537511451613,
      "loss": 0.5131,
      "step": 532780
    },
    {
      "epoch": 859.35,
      "learning_rate": 0.014098311708225807,
      "loss": 0.5039,
      "step": 532800
    },
    {
      "epoch": 859.39,
      "learning_rate": 0.014095085905000002,
      "loss": 0.5237,
      "step": 532820
    },
    {
      "epoch": 859.42,
      "learning_rate": 0.014091860101774196,
      "loss": 0.5176,
      "step": 532840
    },
    {
      "epoch": 859.45,
      "learning_rate": 0.01408863429854839,
      "loss": 0.5025,
      "step": 532860
    },
    {
      "epoch": 859.48,
      "learning_rate": 0.014085408495322582,
      "loss": 0.5212,
      "step": 532880
    },
    {
      "epoch": 859.52,
      "learning_rate": 0.01408218269209678,
      "loss": 0.5056,
      "step": 532900
    },
    {
      "epoch": 859.55,
      "learning_rate": 0.014078956888870973,
      "loss": 0.5211,
      "step": 532920
    },
    {
      "epoch": 859.58,
      "learning_rate": 0.014075731085645159,
      "loss": 0.509,
      "step": 532940
    },
    {
      "epoch": 859.61,
      "learning_rate": 0.01407250528241935,
      "loss": 0.5128,
      "step": 532960
    },
    {
      "epoch": 859.65,
      "learning_rate": 0.014069279479193545,
      "loss": 0.5131,
      "step": 532980
    },
    {
      "epoch": 859.68,
      "learning_rate": 0.014066053675967739,
      "loss": 0.5175,
      "step": 533000
    },
    {
      "epoch": 859.71,
      "learning_rate": 0.014062827872741933,
      "loss": 0.5125,
      "step": 533020
    },
    {
      "epoch": 859.74,
      "learning_rate": 0.014059602069516128,
      "loss": 0.5099,
      "step": 533040
    },
    {
      "epoch": 859.77,
      "learning_rate": 0.014056376266290322,
      "loss": 0.5137,
      "step": 533060
    },
    {
      "epoch": 859.81,
      "learning_rate": 0.014053150463064516,
      "loss": 0.5219,
      "step": 533080
    },
    {
      "epoch": 859.84,
      "learning_rate": 0.01404992465983871,
      "loss": 0.5217,
      "step": 533100
    },
    {
      "epoch": 859.87,
      "learning_rate": 0.014046698856612905,
      "loss": 0.5184,
      "step": 533120
    },
    {
      "epoch": 859.9,
      "learning_rate": 0.0140434730533871,
      "loss": 0.5168,
      "step": 533140
    },
    {
      "epoch": 859.94,
      "learning_rate": 0.014040247250161293,
      "loss": 0.5191,
      "step": 533160
    },
    {
      "epoch": 859.97,
      "learning_rate": 0.014037021446935485,
      "loss": 0.5094,
      "step": 533180
    },
    {
      "epoch": 860.0,
      "learning_rate": 0.01403379564370968,
      "loss": 0.5175,
      "step": 533200
    },
    {
      "epoch": 860.0,
      "eval_accuracy": {
        "accuracy": 0.7872141128717508
      },
      "eval_loss": 0.879398763179779,
      "eval_runtime": 3.1426,
      "eval_samples_per_second": 4076.613,
      "eval_steps_per_second": 63.961,
      "step": 533200
    },
    {
      "epoch": 860.03,
      "learning_rate": 0.014030569840483877,
      "loss": 0.52,
      "step": 533220
    },
    {
      "epoch": 860.06,
      "learning_rate": 0.014027344037258058,
      "loss": 0.5177,
      "step": 533240
    },
    {
      "epoch": 860.1,
      "learning_rate": 0.014024118234032254,
      "loss": 0.5072,
      "step": 533260
    },
    {
      "epoch": 860.13,
      "learning_rate": 0.014020892430806448,
      "loss": 0.5139,
      "step": 533280
    },
    {
      "epoch": 860.16,
      "learning_rate": 0.014017666627580642,
      "loss": 0.5198,
      "step": 533300
    },
    {
      "epoch": 860.19,
      "learning_rate": 0.014014440824354836,
      "loss": 0.5132,
      "step": 533320
    },
    {
      "epoch": 860.23,
      "learning_rate": 0.01401121502112903,
      "loss": 0.505,
      "step": 533340
    },
    {
      "epoch": 860.26,
      "learning_rate": 0.014007989217903225,
      "loss": 0.516,
      "step": 533360
    },
    {
      "epoch": 860.29,
      "learning_rate": 0.014004763414677419,
      "loss": 0.5167,
      "step": 533380
    },
    {
      "epoch": 860.32,
      "learning_rate": 0.014001537611451613,
      "loss": 0.5011,
      "step": 533400
    },
    {
      "epoch": 860.35,
      "learning_rate": 0.013998311808225805,
      "loss": 0.5148,
      "step": 533420
    },
    {
      "epoch": 860.39,
      "learning_rate": 0.013995086005000002,
      "loss": 0.5046,
      "step": 533440
    },
    {
      "epoch": 860.42,
      "learning_rate": 0.013991860201774196,
      "loss": 0.5068,
      "step": 533460
    },
    {
      "epoch": 860.45,
      "learning_rate": 0.013988634398548389,
      "loss": 0.5127,
      "step": 533480
    },
    {
      "epoch": 860.48,
      "learning_rate": 0.013985408595322582,
      "loss": 0.5167,
      "step": 533500
    },
    {
      "epoch": 860.52,
      "learning_rate": 0.01398218279209678,
      "loss": 0.5072,
      "step": 533520
    },
    {
      "epoch": 860.55,
      "learning_rate": 0.013978956988870972,
      "loss": 0.4904,
      "step": 533540
    },
    {
      "epoch": 860.58,
      "learning_rate": 0.013975731185645155,
      "loss": 0.519,
      "step": 533560
    },
    {
      "epoch": 860.61,
      "learning_rate": 0.013972505382419351,
      "loss": 0.5137,
      "step": 533580
    },
    {
      "epoch": 860.65,
      "learning_rate": 0.013969279579193545,
      "loss": 0.5232,
      "step": 533600
    },
    {
      "epoch": 860.68,
      "learning_rate": 0.013966053775967739,
      "loss": 0.5167,
      "step": 533620
    },
    {
      "epoch": 860.71,
      "learning_rate": 0.013962827972741933,
      "loss": 0.5165,
      "step": 533640
    },
    {
      "epoch": 860.74,
      "learning_rate": 0.013959602169516125,
      "loss": 0.5184,
      "step": 533660
    },
    {
      "epoch": 860.77,
      "learning_rate": 0.013956376366290322,
      "loss": 0.5194,
      "step": 533680
    },
    {
      "epoch": 860.81,
      "learning_rate": 0.013953150563064516,
      "loss": 0.5076,
      "step": 533700
    },
    {
      "epoch": 860.84,
      "learning_rate": 0.013949924759838708,
      "loss": 0.5122,
      "step": 533720
    },
    {
      "epoch": 860.87,
      "learning_rate": 0.013946698956612902,
      "loss": 0.5112,
      "step": 533740
    },
    {
      "epoch": 860.9,
      "learning_rate": 0.0139434731533871,
      "loss": 0.5184,
      "step": 533760
    },
    {
      "epoch": 860.94,
      "learning_rate": 0.013940247350161292,
      "loss": 0.5303,
      "step": 533780
    },
    {
      "epoch": 860.97,
      "learning_rate": 0.013937021546935486,
      "loss": 0.513,
      "step": 533800
    },
    {
      "epoch": 861.0,
      "learning_rate": 0.013933795743709683,
      "loss": 0.5172,
      "step": 533820
    },
    {
      "epoch": 861.0,
      "eval_accuracy": {
        "accuracy": 0.7879946920615096
      },
      "eval_loss": 0.8810324668884277,
      "eval_runtime": 3.0945,
      "eval_samples_per_second": 4139.878,
      "eval_steps_per_second": 64.953,
      "step": 533820
    },
    {
      "epoch": 861.03,
      "learning_rate": 0.013930569940483875,
      "loss": 0.5094,
      "step": 533840
    },
    {
      "epoch": 861.06,
      "learning_rate": 0.013927344137258059,
      "loss": 0.5108,
      "step": 533860
    },
    {
      "epoch": 861.1,
      "learning_rate": 0.013924118334032252,
      "loss": 0.5137,
      "step": 533880
    },
    {
      "epoch": 861.13,
      "learning_rate": 0.013920892530806448,
      "loss": 0.5081,
      "step": 533900
    },
    {
      "epoch": 861.16,
      "learning_rate": 0.013917666727580642,
      "loss": 0.5126,
      "step": 533920
    },
    {
      "epoch": 861.19,
      "learning_rate": 0.013914440924354836,
      "loss": 0.5122,
      "step": 533940
    },
    {
      "epoch": 861.23,
      "learning_rate": 0.013911215121129028,
      "loss": 0.5152,
      "step": 533960
    },
    {
      "epoch": 861.26,
      "learning_rate": 0.013907989317903225,
      "loss": 0.5049,
      "step": 533980
    },
    {
      "epoch": 861.29,
      "learning_rate": 0.01390476351467742,
      "loss": 0.519,
      "step": 534000
    },
    {
      "epoch": 861.32,
      "learning_rate": 0.013901537711451611,
      "loss": 0.4974,
      "step": 534020
    },
    {
      "epoch": 861.35,
      "learning_rate": 0.013898311908225805,
      "loss": 0.5103,
      "step": 534040
    },
    {
      "epoch": 861.39,
      "learning_rate": 0.013895086105000003,
      "loss": 0.5019,
      "step": 534060
    },
    {
      "epoch": 861.42,
      "learning_rate": 0.013891860301774195,
      "loss": 0.5068,
      "step": 534080
    },
    {
      "epoch": 861.45,
      "learning_rate": 0.013888634498548389,
      "loss": 0.5138,
      "step": 534100
    },
    {
      "epoch": 861.48,
      "learning_rate": 0.013885408695322586,
      "loss": 0.5148,
      "step": 534120
    },
    {
      "epoch": 861.52,
      "learning_rate": 0.013882182892096778,
      "loss": 0.5024,
      "step": 534140
    },
    {
      "epoch": 861.55,
      "learning_rate": 0.013878957088870972,
      "loss": 0.5133,
      "step": 534160
    },
    {
      "epoch": 861.58,
      "learning_rate": 0.013875731285645156,
      "loss": 0.5172,
      "step": 534180
    },
    {
      "epoch": 861.61,
      "learning_rate": 0.013872505482419348,
      "loss": 0.5088,
      "step": 534200
    },
    {
      "epoch": 861.65,
      "learning_rate": 0.013869279679193545,
      "loss": 0.5084,
      "step": 534220
    },
    {
      "epoch": 861.68,
      "learning_rate": 0.013866053875967739,
      "loss": 0.5096,
      "step": 534240
    },
    {
      "epoch": 861.71,
      "learning_rate": 0.013862828072741931,
      "loss": 0.5115,
      "step": 534260
    },
    {
      "epoch": 861.74,
      "learning_rate": 0.013859602269516125,
      "loss": 0.5184,
      "step": 534280
    },
    {
      "epoch": 861.77,
      "learning_rate": 0.013856376466290322,
      "loss": 0.5091,
      "step": 534300
    },
    {
      "epoch": 861.81,
      "learning_rate": 0.013853150663064515,
      "loss": 0.5234,
      "step": 534320
    },
    {
      "epoch": 861.84,
      "learning_rate": 0.013849924859838708,
      "loss": 0.5136,
      "step": 534340
    },
    {
      "epoch": 861.87,
      "learning_rate": 0.013846699056612906,
      "loss": 0.5173,
      "step": 534360
    },
    {
      "epoch": 861.9,
      "learning_rate": 0.013843473253387098,
      "loss": 0.5129,
      "step": 534380
    },
    {
      "epoch": 861.94,
      "learning_rate": 0.013840247450161292,
      "loss": 0.5174,
      "step": 534400
    },
    {
      "epoch": 861.97,
      "learning_rate": 0.01383702164693549,
      "loss": 0.5106,
      "step": 534420
    },
    {
      "epoch": 862.0,
      "learning_rate": 0.013833957133870967,
      "loss": 0.5112,
      "step": 534440
    },
    {
      "epoch": 862.0,
      "eval_accuracy": {
        "accuracy": 0.7894777925220514
      },
      "eval_loss": 0.8668261170387268,
      "eval_runtime": 3.9078,
      "eval_samples_per_second": 3278.336,
      "eval_steps_per_second": 51.436,
      "step": 534440
    },
    {
      "epoch": 862.03,
      "learning_rate": 0.013830731330645161,
      "loss": 0.5146,
      "step": 534460
    },
    {
      "epoch": 862.06,
      "learning_rate": 0.013827505527419355,
      "loss": 0.5022,
      "step": 534480
    },
    {
      "epoch": 862.1,
      "learning_rate": 0.013824279724193547,
      "loss": 0.5179,
      "step": 534500
    },
    {
      "epoch": 862.13,
      "learning_rate": 0.013821053920967745,
      "loss": 0.515,
      "step": 534520
    },
    {
      "epoch": 862.16,
      "learning_rate": 0.013817828117741938,
      "loss": 0.5122,
      "step": 534540
    },
    {
      "epoch": 862.19,
      "learning_rate": 0.01381460231451613,
      "loss": 0.5154,
      "step": 534560
    },
    {
      "epoch": 862.23,
      "learning_rate": 0.013811376511290325,
      "loss": 0.4994,
      "step": 534580
    },
    {
      "epoch": 862.26,
      "learning_rate": 0.013808150708064522,
      "loss": 0.5216,
      "step": 534600
    },
    {
      "epoch": 862.29,
      "learning_rate": 0.013804924904838704,
      "loss": 0.5126,
      "step": 534620
    },
    {
      "epoch": 862.32,
      "learning_rate": 0.013801699101612898,
      "loss": 0.5154,
      "step": 534640
    },
    {
      "epoch": 862.35,
      "learning_rate": 0.013798473298387093,
      "loss": 0.5107,
      "step": 534660
    },
    {
      "epoch": 862.39,
      "learning_rate": 0.013795247495161287,
      "loss": 0.5139,
      "step": 534680
    },
    {
      "epoch": 862.42,
      "learning_rate": 0.013792021691935481,
      "loss": 0.5056,
      "step": 534700
    },
    {
      "epoch": 862.45,
      "learning_rate": 0.013788795888709675,
      "loss": 0.5129,
      "step": 534720
    },
    {
      "epoch": 862.48,
      "learning_rate": 0.013785570085483867,
      "loss": 0.5043,
      "step": 534740
    },
    {
      "epoch": 862.52,
      "learning_rate": 0.013782344282258064,
      "loss": 0.5218,
      "step": 534760
    },
    {
      "epoch": 862.55,
      "learning_rate": 0.013779118479032258,
      "loss": 0.5138,
      "step": 534780
    },
    {
      "epoch": 862.58,
      "learning_rate": 0.01377589267580645,
      "loss": 0.5116,
      "step": 534800
    },
    {
      "epoch": 862.61,
      "learning_rate": 0.013772666872580644,
      "loss": 0.5235,
      "step": 534820
    },
    {
      "epoch": 862.65,
      "learning_rate": 0.013769441069354842,
      "loss": 0.5105,
      "step": 534840
    },
    {
      "epoch": 862.68,
      "learning_rate": 0.013766215266129034,
      "loss": 0.5123,
      "step": 534860
    },
    {
      "epoch": 862.71,
      "learning_rate": 0.013762989462903228,
      "loss": 0.4988,
      "step": 534880
    },
    {
      "epoch": 862.74,
      "learning_rate": 0.013759763659677425,
      "loss": 0.5145,
      "step": 534900
    },
    {
      "epoch": 862.77,
      "learning_rate": 0.013756537856451617,
      "loss": 0.5037,
      "step": 534920
    },
    {
      "epoch": 862.81,
      "learning_rate": 0.0137533120532258,
      "loss": 0.5219,
      "step": 534940
    },
    {
      "epoch": 862.84,
      "learning_rate": 0.013750086249999995,
      "loss": 0.5064,
      "step": 534960
    },
    {
      "epoch": 862.87,
      "learning_rate": 0.01374686044677419,
      "loss": 0.5143,
      "step": 534980
    },
    {
      "epoch": 862.9,
      "learning_rate": 0.013743634643548384,
      "loss": 0.5127,
      "step": 535000
    },
    {
      "epoch": 862.94,
      "learning_rate": 0.013740408840322578,
      "loss": 0.5121,
      "step": 535020
    },
    {
      "epoch": 862.97,
      "learning_rate": 0.01373718303709677,
      "loss": 0.5216,
      "step": 535040
    },
    {
      "epoch": 863.0,
      "learning_rate": 0.013733957233870967,
      "loss": 0.5112,
      "step": 535060
    },
    {
      "epoch": 863.0,
      "eval_accuracy": {
        "accuracy": 0.7920537038482554
      },
      "eval_loss": 0.8628132343292236,
      "eval_runtime": 3.3756,
      "eval_samples_per_second": 3795.197,
      "eval_steps_per_second": 59.545,
      "step": 535060
    },
    {
      "epoch": 863.03,
      "learning_rate": 0.013730731430645161,
      "loss": 0.5133,
      "step": 535080
    },
    {
      "epoch": 863.06,
      "learning_rate": 0.013727505627419354,
      "loss": 0.5063,
      "step": 535100
    },
    {
      "epoch": 863.1,
      "learning_rate": 0.013724279824193547,
      "loss": 0.5139,
      "step": 535120
    },
    {
      "epoch": 863.13,
      "learning_rate": 0.013721054020967745,
      "loss": 0.5069,
      "step": 535140
    },
    {
      "epoch": 863.16,
      "learning_rate": 0.013717828217741937,
      "loss": 0.5073,
      "step": 535160
    },
    {
      "epoch": 863.19,
      "learning_rate": 0.01371460241451613,
      "loss": 0.5118,
      "step": 535180
    },
    {
      "epoch": 863.23,
      "learning_rate": 0.013711376611290328,
      "loss": 0.5071,
      "step": 535200
    },
    {
      "epoch": 863.26,
      "learning_rate": 0.01370815080806452,
      "loss": 0.5096,
      "step": 535220
    },
    {
      "epoch": 863.29,
      "learning_rate": 0.013704925004838714,
      "loss": 0.5146,
      "step": 535240
    },
    {
      "epoch": 863.32,
      "learning_rate": 0.013701699201612898,
      "loss": 0.5047,
      "step": 535260
    },
    {
      "epoch": 863.35,
      "learning_rate": 0.01369847339838709,
      "loss": 0.5258,
      "step": 535280
    },
    {
      "epoch": 863.39,
      "learning_rate": 0.013695247595161287,
      "loss": 0.5084,
      "step": 535300
    },
    {
      "epoch": 863.42,
      "learning_rate": 0.013692021791935481,
      "loss": 0.5169,
      "step": 535320
    },
    {
      "epoch": 863.45,
      "learning_rate": 0.013688795988709673,
      "loss": 0.5138,
      "step": 535340
    },
    {
      "epoch": 863.48,
      "learning_rate": 0.013685570185483867,
      "loss": 0.4988,
      "step": 535360
    },
    {
      "epoch": 863.52,
      "learning_rate": 0.013682344382258065,
      "loss": 0.5047,
      "step": 535380
    },
    {
      "epoch": 863.55,
      "learning_rate": 0.013679118579032257,
      "loss": 0.5059,
      "step": 535400
    },
    {
      "epoch": 863.58,
      "learning_rate": 0.01367589277580645,
      "loss": 0.4996,
      "step": 535420
    },
    {
      "epoch": 863.61,
      "learning_rate": 0.013672666972580648,
      "loss": 0.5203,
      "step": 535440
    },
    {
      "epoch": 863.65,
      "learning_rate": 0.01366944116935484,
      "loss": 0.4982,
      "step": 535460
    },
    {
      "epoch": 863.68,
      "learning_rate": 0.013666215366129034,
      "loss": 0.5066,
      "step": 535480
    },
    {
      "epoch": 863.71,
      "learning_rate": 0.013662989562903231,
      "loss": 0.4989,
      "step": 535500
    },
    {
      "epoch": 863.74,
      "learning_rate": 0.013659763759677424,
      "loss": 0.5112,
      "step": 535520
    },
    {
      "epoch": 863.77,
      "learning_rate": 0.013656537956451617,
      "loss": 0.5128,
      "step": 535540
    },
    {
      "epoch": 863.81,
      "learning_rate": 0.013653312153225801,
      "loss": 0.5149,
      "step": 535560
    },
    {
      "epoch": 863.84,
      "learning_rate": 0.013650086349999993,
      "loss": 0.5148,
      "step": 535580
    },
    {
      "epoch": 863.87,
      "learning_rate": 0.013646860546774187,
      "loss": 0.529,
      "step": 535600
    },
    {
      "epoch": 863.9,
      "learning_rate": 0.013643634743548384,
      "loss": 0.5153,
      "step": 535620
    },
    {
      "epoch": 863.94,
      "learning_rate": 0.013640408940322576,
      "loss": 0.511,
      "step": 535640
    },
    {
      "epoch": 863.97,
      "learning_rate": 0.01363718313709677,
      "loss": 0.5187,
      "step": 535660
    },
    {
      "epoch": 864.0,
      "learning_rate": 0.013633957333870968,
      "loss": 0.5212,
      "step": 535680
    },
    {
      "epoch": 864.0,
      "eval_accuracy": {
        "accuracy": 0.7866677074389197
      },
      "eval_loss": 0.8739303350448608,
      "eval_runtime": 3.1282,
      "eval_samples_per_second": 4095.354,
      "eval_steps_per_second": 64.255,
      "step": 535680
    },
    {
      "epoch": 864.03,
      "learning_rate": 0.01363073153064516,
      "loss": 0.5067,
      "step": 535700
    },
    {
      "epoch": 864.06,
      "learning_rate": 0.013627505727419354,
      "loss": 0.5084,
      "step": 535720
    },
    {
      "epoch": 864.1,
      "learning_rate": 0.013624279924193551,
      "loss": 0.5045,
      "step": 535740
    },
    {
      "epoch": 864.13,
      "learning_rate": 0.013621054120967743,
      "loss": 0.5031,
      "step": 535760
    },
    {
      "epoch": 864.16,
      "learning_rate": 0.013617828317741937,
      "loss": 0.5113,
      "step": 535780
    },
    {
      "epoch": 864.19,
      "learning_rate": 0.013614602514516135,
      "loss": 0.5104,
      "step": 535800
    },
    {
      "epoch": 864.23,
      "learning_rate": 0.013611376711290327,
      "loss": 0.5087,
      "step": 535820
    },
    {
      "epoch": 864.26,
      "learning_rate": 0.01360815090806452,
      "loss": 0.5056,
      "step": 535840
    },
    {
      "epoch": 864.29,
      "learning_rate": 0.013604925104838714,
      "loss": 0.5085,
      "step": 535860
    },
    {
      "epoch": 864.32,
      "learning_rate": 0.013601699301612896,
      "loss": 0.5051,
      "step": 535880
    },
    {
      "epoch": 864.35,
      "learning_rate": 0.01359847349838709,
      "loss": 0.5141,
      "step": 535900
    },
    {
      "epoch": 864.39,
      "learning_rate": 0.013595247695161287,
      "loss": 0.5163,
      "step": 535920
    },
    {
      "epoch": 864.42,
      "learning_rate": 0.01359202189193548,
      "loss": 0.5052,
      "step": 535940
    },
    {
      "epoch": 864.45,
      "learning_rate": 0.013588796088709673,
      "loss": 0.5162,
      "step": 535960
    },
    {
      "epoch": 864.48,
      "learning_rate": 0.01358557028548387,
      "loss": 0.5106,
      "step": 535980
    },
    {
      "epoch": 864.52,
      "learning_rate": 0.013582344482258063,
      "loss": 0.5205,
      "step": 536000
    },
    {
      "epoch": 864.55,
      "learning_rate": 0.013579118679032257,
      "loss": 0.5096,
      "step": 536020
    },
    {
      "epoch": 864.58,
      "learning_rate": 0.013575892875806454,
      "loss": 0.5091,
      "step": 536040
    },
    {
      "epoch": 864.61,
      "learning_rate": 0.013572667072580646,
      "loss": 0.5055,
      "step": 536060
    },
    {
      "epoch": 864.65,
      "learning_rate": 0.01356944126935484,
      "loss": 0.5019,
      "step": 536080
    },
    {
      "epoch": 864.68,
      "learning_rate": 0.013566215466129034,
      "loss": 0.5106,
      "step": 536100
    },
    {
      "epoch": 864.71,
      "learning_rate": 0.01356298966290323,
      "loss": 0.5255,
      "step": 536120
    },
    {
      "epoch": 864.74,
      "learning_rate": 0.013559763859677424,
      "loss": 0.5169,
      "step": 536140
    },
    {
      "epoch": 864.77,
      "learning_rate": 0.013556538056451618,
      "loss": 0.5084,
      "step": 536160
    },
    {
      "epoch": 864.81,
      "learning_rate": 0.0135533122532258,
      "loss": 0.5008,
      "step": 536180
    },
    {
      "epoch": 864.84,
      "learning_rate": 0.013550086449999993,
      "loss": 0.5231,
      "step": 536200
    },
    {
      "epoch": 864.87,
      "learning_rate": 0.01354686064677419,
      "loss": 0.5197,
      "step": 536220
    },
    {
      "epoch": 864.9,
      "learning_rate": 0.013543634843548383,
      "loss": 0.517,
      "step": 536240
    },
    {
      "epoch": 864.94,
      "learning_rate": 0.013540409040322577,
      "loss": 0.5107,
      "step": 536260
    },
    {
      "epoch": 864.97,
      "learning_rate": 0.013537183237096774,
      "loss": 0.5119,
      "step": 536280
    },
    {
      "epoch": 865.0,
      "learning_rate": 0.013533957433870966,
      "loss": 0.5157,
      "step": 536300
    },
    {
      "epoch": 865.0,
      "eval_accuracy": {
        "accuracy": 0.7909608929825931
      },
      "eval_loss": 0.8665356040000916,
      "eval_runtime": 3.2527,
      "eval_samples_per_second": 3938.628,
      "eval_steps_per_second": 61.796,
      "step": 536300
    },
    {
      "epoch": 865.03,
      "learning_rate": 0.01353073163064516,
      "loss": 0.5077,
      "step": 536320
    },
    {
      "epoch": 865.06,
      "learning_rate": 0.013527505827419357,
      "loss": 0.4931,
      "step": 536340
    },
    {
      "epoch": 865.1,
      "learning_rate": 0.01352428002419355,
      "loss": 0.5107,
      "step": 536360
    },
    {
      "epoch": 865.13,
      "learning_rate": 0.013521054220967743,
      "loss": 0.5001,
      "step": 536380
    },
    {
      "epoch": 865.16,
      "learning_rate": 0.013517828417741937,
      "loss": 0.5115,
      "step": 536400
    },
    {
      "epoch": 865.19,
      "learning_rate": 0.013514602614516131,
      "loss": 0.507,
      "step": 536420
    },
    {
      "epoch": 865.23,
      "learning_rate": 0.013511376811290327,
      "loss": 0.5115,
      "step": 536440
    },
    {
      "epoch": 865.26,
      "learning_rate": 0.01350815100806452,
      "loss": 0.5064,
      "step": 536460
    },
    {
      "epoch": 865.29,
      "learning_rate": 0.013504925204838715,
      "loss": 0.5093,
      "step": 536480
    },
    {
      "epoch": 865.32,
      "learning_rate": 0.013501699401612896,
      "loss": 0.5107,
      "step": 536500
    },
    {
      "epoch": 865.35,
      "learning_rate": 0.013498473598387094,
      "loss": 0.5015,
      "step": 536520
    },
    {
      "epoch": 865.39,
      "learning_rate": 0.013495247795161286,
      "loss": 0.5066,
      "step": 536540
    },
    {
      "epoch": 865.42,
      "learning_rate": 0.01349202199193548,
      "loss": 0.5122,
      "step": 536560
    },
    {
      "epoch": 865.45,
      "learning_rate": 0.013488796188709677,
      "loss": 0.5075,
      "step": 536580
    },
    {
      "epoch": 865.48,
      "learning_rate": 0.01348557038548387,
      "loss": 0.513,
      "step": 536600
    },
    {
      "epoch": 865.52,
      "learning_rate": 0.013482344582258063,
      "loss": 0.5104,
      "step": 536620
    },
    {
      "epoch": 865.55,
      "learning_rate": 0.013479118779032257,
      "loss": 0.5101,
      "step": 536640
    },
    {
      "epoch": 865.58,
      "learning_rate": 0.013475892975806453,
      "loss": 0.5132,
      "step": 536660
    },
    {
      "epoch": 865.61,
      "learning_rate": 0.013472667172580647,
      "loss": 0.5142,
      "step": 536680
    },
    {
      "epoch": 865.65,
      "learning_rate": 0.01346944136935484,
      "loss": 0.5192,
      "step": 536700
    },
    {
      "epoch": 865.68,
      "learning_rate": 0.013466215566129034,
      "loss": 0.5082,
      "step": 536720
    },
    {
      "epoch": 865.71,
      "learning_rate": 0.013462989762903228,
      "loss": 0.5033,
      "step": 536740
    },
    {
      "epoch": 865.74,
      "learning_rate": 0.013459763959677424,
      "loss": 0.5132,
      "step": 536760
    },
    {
      "epoch": 865.77,
      "learning_rate": 0.013456538156451618,
      "loss": 0.5087,
      "step": 536780
    },
    {
      "epoch": 865.81,
      "learning_rate": 0.0134533123532258,
      "loss": 0.5125,
      "step": 536800
    },
    {
      "epoch": 865.84,
      "learning_rate": 0.013450086549999997,
      "loss": 0.5117,
      "step": 536820
    },
    {
      "epoch": 865.87,
      "learning_rate": 0.013446860746774189,
      "loss": 0.516,
      "step": 536840
    },
    {
      "epoch": 865.9,
      "learning_rate": 0.013443634943548383,
      "loss": 0.5155,
      "step": 536860
    },
    {
      "epoch": 865.94,
      "learning_rate": 0.01344040914032258,
      "loss": 0.5057,
      "step": 536880
    },
    {
      "epoch": 865.97,
      "learning_rate": 0.013437183337096772,
      "loss": 0.5139,
      "step": 536900
    },
    {
      "epoch": 866.0,
      "learning_rate": 0.013433957533870966,
      "loss": 0.5154,
      "step": 536920
    },
    {
      "epoch": 866.0,
      "eval_accuracy": {
        "accuracy": 0.7880727499804855
      },
      "eval_loss": 0.8748475313186646,
      "eval_runtime": 3.2761,
      "eval_samples_per_second": 3910.434,
      "eval_steps_per_second": 61.353,
      "step": 536920
    },
    {
      "epoch": 866.03,
      "learning_rate": 0.01343073173064516,
      "loss": 0.5116,
      "step": 536940
    },
    {
      "epoch": 866.06,
      "learning_rate": 0.013427505927419354,
      "loss": 0.5101,
      "step": 536960
    },
    {
      "epoch": 866.1,
      "learning_rate": 0.01342428012419355,
      "loss": 0.5236,
      "step": 536980
    },
    {
      "epoch": 866.13,
      "learning_rate": 0.013421054320967744,
      "loss": 0.4945,
      "step": 537000
    },
    {
      "epoch": 866.16,
      "learning_rate": 0.013417828517741938,
      "loss": 0.4995,
      "step": 537020
    },
    {
      "epoch": 866.19,
      "learning_rate": 0.013414602714516131,
      "loss": 0.5028,
      "step": 537040
    },
    {
      "epoch": 866.23,
      "learning_rate": 0.013411376911290324,
      "loss": 0.5083,
      "step": 537060
    },
    {
      "epoch": 866.26,
      "learning_rate": 0.013408151108064521,
      "loss": 0.5072,
      "step": 537080
    },
    {
      "epoch": 866.29,
      "learning_rate": 0.013404925304838715,
      "loss": 0.5106,
      "step": 537100
    },
    {
      "epoch": 866.32,
      "learning_rate": 0.0134016995016129,
      "loss": 0.5134,
      "step": 537120
    },
    {
      "epoch": 866.35,
      "learning_rate": 0.013398473698387092,
      "loss": 0.517,
      "step": 537140
    },
    {
      "epoch": 866.39,
      "learning_rate": 0.013395247895161286,
      "loss": 0.5154,
      "step": 537160
    },
    {
      "epoch": 866.42,
      "learning_rate": 0.01339202209193548,
      "loss": 0.5045,
      "step": 537180
    },
    {
      "epoch": 866.45,
      "learning_rate": 0.013388796288709676,
      "loss": 0.5065,
      "step": 537200
    },
    {
      "epoch": 866.48,
      "learning_rate": 0.01338557048548387,
      "loss": 0.5122,
      "step": 537220
    },
    {
      "epoch": 866.52,
      "learning_rate": 0.013382344682258063,
      "loss": 0.5203,
      "step": 537240
    },
    {
      "epoch": 866.55,
      "learning_rate": 0.013379118879032257,
      "loss": 0.501,
      "step": 537260
    },
    {
      "epoch": 866.58,
      "learning_rate": 0.013375893075806451,
      "loss": 0.5021,
      "step": 537280
    },
    {
      "epoch": 866.61,
      "learning_rate": 0.013372667272580647,
      "loss": 0.5084,
      "step": 537300
    },
    {
      "epoch": 866.65,
      "learning_rate": 0.01336944146935484,
      "loss": 0.5072,
      "step": 537320
    },
    {
      "epoch": 866.68,
      "learning_rate": 0.013366215666129035,
      "loss": 0.519,
      "step": 537340
    },
    {
      "epoch": 866.71,
      "learning_rate": 0.013362989862903227,
      "loss": 0.5132,
      "step": 537360
    },
    {
      "epoch": 866.74,
      "learning_rate": 0.013359764059677424,
      "loss": 0.5073,
      "step": 537380
    },
    {
      "epoch": 866.77,
      "learning_rate": 0.013356538256451618,
      "loss": 0.5058,
      "step": 537400
    },
    {
      "epoch": 866.81,
      "learning_rate": 0.013353312453225803,
      "loss": 0.5152,
      "step": 537420
    },
    {
      "epoch": 866.84,
      "learning_rate": 0.013350086649999995,
      "loss": 0.5138,
      "step": 537440
    },
    {
      "epoch": 866.87,
      "learning_rate": 0.01334686084677419,
      "loss": 0.5087,
      "step": 537460
    },
    {
      "epoch": 866.9,
      "learning_rate": 0.013343635043548383,
      "loss": 0.5092,
      "step": 537480
    },
    {
      "epoch": 866.94,
      "learning_rate": 0.013340409240322577,
      "loss": 0.5136,
      "step": 537500
    },
    {
      "epoch": 866.97,
      "learning_rate": 0.013337183437096773,
      "loss": 0.5126,
      "step": 537520
    },
    {
      "epoch": 867.0,
      "learning_rate": 0.013334118924032263,
      "loss": 0.5121,
      "step": 537540
    },
    {
      "epoch": 867.0,
      "eval_accuracy": {
        "accuracy": 0.7881508078994613
      },
      "eval_loss": 0.8724055886268616,
      "eval_runtime": 3.0732,
      "eval_samples_per_second": 4168.591,
      "eval_steps_per_second": 65.404,
      "step": 537540
    },
    {
      "epoch": 867.03,
      "learning_rate": 0.013330893120806445,
      "loss": 0.5077,
      "step": 537560
    },
    {
      "epoch": 867.06,
      "learning_rate": 0.013327667317580639,
      "loss": 0.4993,
      "step": 537580
    },
    {
      "epoch": 867.1,
      "learning_rate": 0.013324441514354836,
      "loss": 0.5058,
      "step": 537600
    },
    {
      "epoch": 867.13,
      "learning_rate": 0.013321215711129028,
      "loss": 0.5088,
      "step": 537620
    },
    {
      "epoch": 867.16,
      "learning_rate": 0.013317989907903222,
      "loss": 0.5108,
      "step": 537640
    },
    {
      "epoch": 867.19,
      "learning_rate": 0.01331476410467742,
      "loss": 0.5029,
      "step": 537660
    },
    {
      "epoch": 867.23,
      "learning_rate": 0.013311538301451611,
      "loss": 0.5152,
      "step": 537680
    },
    {
      "epoch": 867.26,
      "learning_rate": 0.013308312498225805,
      "loss": 0.5089,
      "step": 537700
    },
    {
      "epoch": 867.29,
      "learning_rate": 0.013305086695,
      "loss": 0.5101,
      "step": 537720
    },
    {
      "epoch": 867.32,
      "learning_rate": 0.013301860891774195,
      "loss": 0.5098,
      "step": 537740
    },
    {
      "epoch": 867.35,
      "learning_rate": 0.013298635088548389,
      "loss": 0.5057,
      "step": 537760
    },
    {
      "epoch": 867.39,
      "learning_rate": 0.013295409285322583,
      "loss": 0.5095,
      "step": 537780
    },
    {
      "epoch": 867.42,
      "learning_rate": 0.013292183482096777,
      "loss": 0.5165,
      "step": 537800
    },
    {
      "epoch": 867.45,
      "learning_rate": 0.01328895767887097,
      "loss": 0.5089,
      "step": 537820
    },
    {
      "epoch": 867.48,
      "learning_rate": 0.013285731875645166,
      "loss": 0.5123,
      "step": 537840
    },
    {
      "epoch": 867.52,
      "learning_rate": 0.01328250607241936,
      "loss": 0.5141,
      "step": 537860
    },
    {
      "epoch": 867.55,
      "learning_rate": 0.013279280269193542,
      "loss": 0.5098,
      "step": 537880
    },
    {
      "epoch": 867.58,
      "learning_rate": 0.013276054465967739,
      "loss": 0.5002,
      "step": 537900
    },
    {
      "epoch": 867.61,
      "learning_rate": 0.013272828662741931,
      "loss": 0.4992,
      "step": 537920
    },
    {
      "epoch": 867.65,
      "learning_rate": 0.013269602859516125,
      "loss": 0.5056,
      "step": 537940
    },
    {
      "epoch": 867.68,
      "learning_rate": 0.013266377056290322,
      "loss": 0.5143,
      "step": 537960
    },
    {
      "epoch": 867.71,
      "learning_rate": 0.013263151253064515,
      "loss": 0.5021,
      "step": 537980
    },
    {
      "epoch": 867.74,
      "learning_rate": 0.013259925449838708,
      "loss": 0.5068,
      "step": 538000
    },
    {
      "epoch": 867.77,
      "learning_rate": 0.013256699646612902,
      "loss": 0.5062,
      "step": 538020
    },
    {
      "epoch": 867.81,
      "learning_rate": 0.013253473843387096,
      "loss": 0.5108,
      "step": 538040
    },
    {
      "epoch": 867.84,
      "learning_rate": 0.013250248040161292,
      "loss": 0.5091,
      "step": 538060
    },
    {
      "epoch": 867.87,
      "learning_rate": 0.013247022236935486,
      "loss": 0.5149,
      "step": 538080
    },
    {
      "epoch": 867.9,
      "learning_rate": 0.01324379643370968,
      "loss": 0.5149,
      "step": 538100
    },
    {
      "epoch": 867.94,
      "learning_rate": 0.013240570630483874,
      "loss": 0.5118,
      "step": 538120
    },
    {
      "epoch": 867.97,
      "learning_rate": 0.013237344827258066,
      "loss": 0.5158,
      "step": 538140
    },
    {
      "epoch": 868.0,
      "learning_rate": 0.013234119024032263,
      "loss": 0.5201,
      "step": 538160
    },
    {
      "epoch": 868.0,
      "eval_accuracy": {
        "accuracy": 0.7870579970337991
      },
      "eval_loss": 0.8701024055480957,
      "eval_runtime": 3.2368,
      "eval_samples_per_second": 3957.961,
      "eval_steps_per_second": 62.099,
      "step": 538160
    },
    {
      "epoch": 868.03,
      "learning_rate": 0.013230893220806457,
      "loss": 0.5038,
      "step": 538180
    },
    {
      "epoch": 868.06,
      "learning_rate": 0.013227667417580642,
      "loss": 0.4984,
      "step": 538200
    },
    {
      "epoch": 868.1,
      "learning_rate": 0.013224441614354834,
      "loss": 0.4964,
      "step": 538220
    },
    {
      "epoch": 868.13,
      "learning_rate": 0.013221215811129028,
      "loss": 0.5041,
      "step": 538240
    },
    {
      "epoch": 868.16,
      "learning_rate": 0.013217990007903222,
      "loss": 0.508,
      "step": 538260
    },
    {
      "epoch": 868.19,
      "learning_rate": 0.013214764204677418,
      "loss": 0.5019,
      "step": 538280
    },
    {
      "epoch": 868.23,
      "learning_rate": 0.013211538401451612,
      "loss": 0.5066,
      "step": 538300
    },
    {
      "epoch": 868.26,
      "learning_rate": 0.013208312598225806,
      "loss": 0.5055,
      "step": 538320
    },
    {
      "epoch": 868.29,
      "learning_rate": 0.013205086795,
      "loss": 0.5009,
      "step": 538340
    },
    {
      "epoch": 868.32,
      "learning_rate": 0.013201860991774193,
      "loss": 0.5134,
      "step": 538360
    },
    {
      "epoch": 868.35,
      "learning_rate": 0.013198635188548389,
      "loss": 0.5109,
      "step": 538380
    },
    {
      "epoch": 868.39,
      "learning_rate": 0.013195409385322583,
      "loss": 0.5059,
      "step": 538400
    },
    {
      "epoch": 868.42,
      "learning_rate": 0.013192183582096777,
      "loss": 0.5112,
      "step": 538420
    },
    {
      "epoch": 868.45,
      "learning_rate": 0.013188957778870969,
      "loss": 0.5087,
      "step": 538440
    },
    {
      "epoch": 868.48,
      "learning_rate": 0.013185731975645166,
      "loss": 0.5053,
      "step": 538460
    },
    {
      "epoch": 868.52,
      "learning_rate": 0.01318250617241936,
      "loss": 0.5031,
      "step": 538480
    },
    {
      "epoch": 868.55,
      "learning_rate": 0.013179280369193545,
      "loss": 0.5125,
      "step": 538500
    },
    {
      "epoch": 868.58,
      "learning_rate": 0.013176054565967737,
      "loss": 0.5133,
      "step": 538520
    },
    {
      "epoch": 868.61,
      "learning_rate": 0.013172828762741931,
      "loss": 0.5141,
      "step": 538540
    },
    {
      "epoch": 868.65,
      "learning_rate": 0.013169602959516125,
      "loss": 0.5051,
      "step": 538560
    },
    {
      "epoch": 868.68,
      "learning_rate": 0.01316637715629032,
      "loss": 0.5155,
      "step": 538580
    },
    {
      "epoch": 868.71,
      "learning_rate": 0.013163151353064515,
      "loss": 0.5101,
      "step": 538600
    },
    {
      "epoch": 868.74,
      "learning_rate": 0.013159925549838709,
      "loss": 0.5138,
      "step": 538620
    },
    {
      "epoch": 868.77,
      "learning_rate": 0.013156699746612903,
      "loss": 0.5149,
      "step": 538640
    },
    {
      "epoch": 868.81,
      "learning_rate": 0.013153473943387096,
      "loss": 0.5122,
      "step": 538660
    },
    {
      "epoch": 868.84,
      "learning_rate": 0.013150248140161289,
      "loss": 0.5081,
      "step": 538680
    },
    {
      "epoch": 868.87,
      "learning_rate": 0.013147022336935486,
      "loss": 0.5146,
      "step": 538700
    },
    {
      "epoch": 868.9,
      "learning_rate": 0.01314379653370968,
      "loss": 0.5114,
      "step": 538720
    },
    {
      "epoch": 868.94,
      "learning_rate": 0.013140570730483872,
      "loss": 0.5132,
      "step": 538740
    },
    {
      "epoch": 868.97,
      "learning_rate": 0.013137344927258066,
      "loss": 0.5153,
      "step": 538760
    },
    {
      "epoch": 869.0,
      "learning_rate": 0.013134119124032263,
      "loss": 0.5113,
      "step": 538780
    },
    {
      "epoch": 869.0,
      "eval_accuracy": {
        "accuracy": 0.7901803137928343
      },
      "eval_loss": 0.8604116439819336,
      "eval_runtime": 3.4723,
      "eval_samples_per_second": 3689.452,
      "eval_steps_per_second": 57.886,
      "step": 538780
    },
    {
      "epoch": 869.03,
      "learning_rate": 0.013130893320806455,
      "loss": 0.494,
      "step": 538800
    },
    {
      "epoch": 869.06,
      "learning_rate": 0.01312766751758064,
      "loss": 0.5113,
      "step": 538820
    },
    {
      "epoch": 869.1,
      "learning_rate": 0.013124441714354835,
      "loss": 0.5128,
      "step": 538840
    },
    {
      "epoch": 869.13,
      "learning_rate": 0.013121215911129028,
      "loss": 0.507,
      "step": 538860
    },
    {
      "epoch": 869.16,
      "learning_rate": 0.013117990107903222,
      "loss": 0.5081,
      "step": 538880
    },
    {
      "epoch": 869.19,
      "learning_rate": 0.013114764304677416,
      "loss": 0.5065,
      "step": 538900
    },
    {
      "epoch": 869.23,
      "learning_rate": 0.013111538501451612,
      "loss": 0.5028,
      "step": 538920
    },
    {
      "epoch": 869.26,
      "learning_rate": 0.013108312698225806,
      "loss": 0.5167,
      "step": 538940
    },
    {
      "epoch": 869.29,
      "learning_rate": 0.013105086895,
      "loss": 0.5081,
      "step": 538960
    },
    {
      "epoch": 869.32,
      "learning_rate": 0.013101861091774192,
      "loss": 0.5224,
      "step": 538980
    },
    {
      "epoch": 869.35,
      "learning_rate": 0.013098635288548386,
      "loss": 0.511,
      "step": 539000
    },
    {
      "epoch": 869.39,
      "learning_rate": 0.013095409485322583,
      "loss": 0.4965,
      "step": 539020
    },
    {
      "epoch": 869.42,
      "learning_rate": 0.013092183682096775,
      "loss": 0.5021,
      "step": 539040
    },
    {
      "epoch": 869.45,
      "learning_rate": 0.013088957878870969,
      "loss": 0.5046,
      "step": 539060
    },
    {
      "epoch": 869.48,
      "learning_rate": 0.013085732075645166,
      "loss": 0.5015,
      "step": 539080
    },
    {
      "epoch": 869.52,
      "learning_rate": 0.013082506272419359,
      "loss": 0.5046,
      "step": 539100
    },
    {
      "epoch": 869.55,
      "learning_rate": 0.013079280469193542,
      "loss": 0.5037,
      "step": 539120
    },
    {
      "epoch": 869.58,
      "learning_rate": 0.013076054665967738,
      "loss": 0.5112,
      "step": 539140
    },
    {
      "epoch": 869.61,
      "learning_rate": 0.013072828862741932,
      "loss": 0.5054,
      "step": 539160
    },
    {
      "epoch": 869.65,
      "learning_rate": 0.013069603059516125,
      "loss": 0.5032,
      "step": 539180
    },
    {
      "epoch": 869.68,
      "learning_rate": 0.01306637725629032,
      "loss": 0.52,
      "step": 539200
    },
    {
      "epoch": 869.71,
      "learning_rate": 0.013063151453064512,
      "loss": 0.5088,
      "step": 539220
    },
    {
      "epoch": 869.74,
      "learning_rate": 0.013059925649838709,
      "loss": 0.5152,
      "step": 539240
    },
    {
      "epoch": 869.77,
      "learning_rate": 0.013056699846612903,
      "loss": 0.5046,
      "step": 539260
    },
    {
      "epoch": 869.81,
      "learning_rate": 0.013053474043387095,
      "loss": 0.5104,
      "step": 539280
    },
    {
      "epoch": 869.84,
      "learning_rate": 0.013050248240161289,
      "loss": 0.5196,
      "step": 539300
    },
    {
      "epoch": 869.87,
      "learning_rate": 0.013047022436935486,
      "loss": 0.51,
      "step": 539320
    },
    {
      "epoch": 869.9,
      "learning_rate": 0.013043796633709678,
      "loss": 0.5025,
      "step": 539340
    },
    {
      "epoch": 869.94,
      "learning_rate": 0.013040570830483872,
      "loss": 0.5192,
      "step": 539360
    },
    {
      "epoch": 869.97,
      "learning_rate": 0.01303734502725807,
      "loss": 0.506,
      "step": 539380
    },
    {
      "epoch": 870.0,
      "learning_rate": 0.013034119224032262,
      "loss": 0.5139,
      "step": 539400
    },
    {
      "epoch": 870.0,
      "eval_accuracy": {
        "accuracy": 0.7879946920615096
      },
      "eval_loss": 0.87858647108078,
      "eval_runtime": 4.0474,
      "eval_samples_per_second": 3165.278,
      "eval_steps_per_second": 49.662,
      "step": 539400
    },
    {
      "epoch": 870.03,
      "learning_rate": 0.013030893420806456,
      "loss": 0.5103,
      "step": 539420
    },
    {
      "epoch": 870.06,
      "learning_rate": 0.013027667617580639,
      "loss": 0.5158,
      "step": 539440
    },
    {
      "epoch": 870.1,
      "learning_rate": 0.013024441814354835,
      "loss": 0.512,
      "step": 539460
    },
    {
      "epoch": 870.13,
      "learning_rate": 0.013021216011129029,
      "loss": 0.4971,
      "step": 539480
    },
    {
      "epoch": 870.16,
      "learning_rate": 0.013017990207903223,
      "loss": 0.4992,
      "step": 539500
    },
    {
      "epoch": 870.19,
      "learning_rate": 0.013014764404677415,
      "loss": 0.4994,
      "step": 539520
    },
    {
      "epoch": 870.23,
      "learning_rate": 0.013011538601451609,
      "loss": 0.4991,
      "step": 539540
    },
    {
      "epoch": 870.26,
      "learning_rate": 0.013008312798225806,
      "loss": 0.5101,
      "step": 539560
    },
    {
      "epoch": 870.29,
      "learning_rate": 0.013005086994999998,
      "loss": 0.4976,
      "step": 539580
    },
    {
      "epoch": 870.32,
      "learning_rate": 0.013001861191774192,
      "loss": 0.5034,
      "step": 539600
    },
    {
      "epoch": 870.35,
      "learning_rate": 0.01299863538854839,
      "loss": 0.4985,
      "step": 539620
    },
    {
      "epoch": 870.39,
      "learning_rate": 0.012995409585322582,
      "loss": 0.5091,
      "step": 539640
    },
    {
      "epoch": 870.42,
      "learning_rate": 0.012992183782096775,
      "loss": 0.5057,
      "step": 539660
    },
    {
      "epoch": 870.45,
      "learning_rate": 0.012988957978870973,
      "loss": 0.5069,
      "step": 539680
    },
    {
      "epoch": 870.48,
      "learning_rate": 0.012985732175645165,
      "loss": 0.505,
      "step": 539700
    },
    {
      "epoch": 870.52,
      "learning_rate": 0.012982506372419359,
      "loss": 0.5117,
      "step": 539720
    },
    {
      "epoch": 870.55,
      "learning_rate": 0.012979280569193542,
      "loss": 0.5056,
      "step": 539740
    },
    {
      "epoch": 870.58,
      "learning_rate": 0.012976054765967734,
      "loss": 0.5102,
      "step": 539760
    },
    {
      "epoch": 870.61,
      "learning_rate": 0.012972828962741932,
      "loss": 0.5026,
      "step": 539780
    },
    {
      "epoch": 870.65,
      "learning_rate": 0.012969603159516126,
      "loss": 0.5043,
      "step": 539800
    },
    {
      "epoch": 870.68,
      "learning_rate": 0.012966377356290318,
      "loss": 0.5164,
      "step": 539820
    },
    {
      "epoch": 870.71,
      "learning_rate": 0.012963151553064512,
      "loss": 0.5013,
      "step": 539840
    },
    {
      "epoch": 870.74,
      "learning_rate": 0.012959925749838709,
      "loss": 0.5118,
      "step": 539860
    },
    {
      "epoch": 870.77,
      "learning_rate": 0.012956699946612901,
      "loss": 0.5073,
      "step": 539880
    },
    {
      "epoch": 870.81,
      "learning_rate": 0.012953474143387095,
      "loss": 0.5094,
      "step": 539900
    },
    {
      "epoch": 870.84,
      "learning_rate": 0.012950248340161293,
      "loss": 0.5179,
      "step": 539920
    },
    {
      "epoch": 870.87,
      "learning_rate": 0.012947022536935485,
      "loss": 0.515,
      "step": 539940
    },
    {
      "epoch": 870.9,
      "learning_rate": 0.012943796733709679,
      "loss": 0.5188,
      "step": 539960
    },
    {
      "epoch": 870.94,
      "learning_rate": 0.012940570930483876,
      "loss": 0.5104,
      "step": 539980
    },
    {
      "epoch": 870.97,
      "learning_rate": 0.012937345127258068,
      "loss": 0.5131,
      "step": 540000
    },
    {
      "epoch": 871.0,
      "learning_rate": 0.012934119324032262,
      "loss": 0.5146,
      "step": 540020
    },
    {
      "epoch": 871.0,
      "eval_accuracy": {
        "accuracy": 0.7908828350636172
      },
      "eval_loss": 0.8653348684310913,
      "eval_runtime": 2.9776,
      "eval_samples_per_second": 4302.501,
      "eval_steps_per_second": 67.505,
      "step": 540020
    },
    {
      "epoch": 871.03,
      "learning_rate": 0.012930893520806456,
      "loss": 0.5081,
      "step": 540040
    },
    {
      "epoch": 871.06,
      "learning_rate": 0.012927667717580638,
      "loss": 0.5029,
      "step": 540060
    },
    {
      "epoch": 871.1,
      "learning_rate": 0.012924441914354831,
      "loss": 0.4995,
      "step": 540080
    },
    {
      "epoch": 871.13,
      "learning_rate": 0.012921216111129029,
      "loss": 0.5023,
      "step": 540100
    },
    {
      "epoch": 871.16,
      "learning_rate": 0.012917990307903221,
      "loss": 0.5075,
      "step": 540120
    },
    {
      "epoch": 871.19,
      "learning_rate": 0.012914764504677415,
      "loss": 0.5087,
      "step": 540140
    },
    {
      "epoch": 871.23,
      "learning_rate": 0.012911538701451612,
      "loss": 0.5041,
      "step": 540160
    },
    {
      "epoch": 871.26,
      "learning_rate": 0.012908312898225804,
      "loss": 0.5038,
      "step": 540180
    },
    {
      "epoch": 871.29,
      "learning_rate": 0.012905087094999998,
      "loss": 0.4969,
      "step": 540200
    },
    {
      "epoch": 871.32,
      "learning_rate": 0.012901861291774196,
      "loss": 0.5074,
      "step": 540220
    },
    {
      "epoch": 871.35,
      "learning_rate": 0.012898635488548388,
      "loss": 0.5074,
      "step": 540240
    },
    {
      "epoch": 871.39,
      "learning_rate": 0.012895409685322582,
      "loss": 0.5045,
      "step": 540260
    },
    {
      "epoch": 871.42,
      "learning_rate": 0.012892183882096779,
      "loss": 0.5048,
      "step": 540280
    },
    {
      "epoch": 871.45,
      "learning_rate": 0.012888958078870971,
      "loss": 0.5075,
      "step": 540300
    },
    {
      "epoch": 871.48,
      "learning_rate": 0.012885732275645165,
      "loss": 0.5018,
      "step": 540320
    },
    {
      "epoch": 871.52,
      "learning_rate": 0.012882506472419359,
      "loss": 0.5074,
      "step": 540340
    },
    {
      "epoch": 871.55,
      "learning_rate": 0.012879280669193553,
      "loss": 0.4946,
      "step": 540360
    },
    {
      "epoch": 871.58,
      "learning_rate": 0.012876054865967735,
      "loss": 0.4997,
      "step": 540380
    },
    {
      "epoch": 871.61,
      "learning_rate": 0.012872829062741932,
      "loss": 0.5097,
      "step": 540400
    },
    {
      "epoch": 871.65,
      "learning_rate": 0.012869603259516124,
      "loss": 0.512,
      "step": 540420
    },
    {
      "epoch": 871.68,
      "learning_rate": 0.012866377456290318,
      "loss": 0.5096,
      "step": 540440
    },
    {
      "epoch": 871.71,
      "learning_rate": 0.012863151653064515,
      "loss": 0.5124,
      "step": 540460
    },
    {
      "epoch": 871.74,
      "learning_rate": 0.012859925849838708,
      "loss": 0.5026,
      "step": 540480
    },
    {
      "epoch": 871.77,
      "learning_rate": 0.012856700046612901,
      "loss": 0.5128,
      "step": 540500
    },
    {
      "epoch": 871.81,
      "learning_rate": 0.012853474243387099,
      "loss": 0.5144,
      "step": 540520
    },
    {
      "epoch": 871.84,
      "learning_rate": 0.012850248440161291,
      "loss": 0.509,
      "step": 540540
    },
    {
      "epoch": 871.87,
      "learning_rate": 0.012847022636935485,
      "loss": 0.523,
      "step": 540560
    },
    {
      "epoch": 871.9,
      "learning_rate": 0.012843796833709679,
      "loss": 0.5116,
      "step": 540580
    },
    {
      "epoch": 871.94,
      "learning_rate": 0.012840571030483874,
      "loss": 0.507,
      "step": 540600
    },
    {
      "epoch": 871.97,
      "learning_rate": 0.012837345227258068,
      "loss": 0.5026,
      "step": 540620
    },
    {
      "epoch": 872.0,
      "learning_rate": 0.012834119424032262,
      "loss": 0.5195,
      "step": 540640
    },
    {
      "epoch": 872.0,
      "eval_accuracy": {
        "accuracy": 0.7936929201467489
      },
      "eval_loss": 0.8617925047874451,
      "eval_runtime": 3.1867,
      "eval_samples_per_second": 4020.19,
      "eval_steps_per_second": 63.075,
      "step": 540640
    },
    {
      "epoch": 872.03,
      "learning_rate": 0.012830893620806456,
      "loss": 0.5054,
      "step": 540660
    },
    {
      "epoch": 872.06,
      "learning_rate": 0.012827667817580638,
      "loss": 0.4929,
      "step": 540680
    },
    {
      "epoch": 872.1,
      "learning_rate": 0.012824442014354835,
      "loss": 0.5134,
      "step": 540700
    },
    {
      "epoch": 872.13,
      "learning_rate": 0.012821216211129027,
      "loss": 0.5013,
      "step": 540720
    },
    {
      "epoch": 872.16,
      "learning_rate": 0.012817990407903221,
      "loss": 0.5091,
      "step": 540740
    },
    {
      "epoch": 872.19,
      "learning_rate": 0.012814764604677419,
      "loss": 0.5046,
      "step": 540760
    },
    {
      "epoch": 872.23,
      "learning_rate": 0.01281153880145161,
      "loss": 0.4968,
      "step": 540780
    },
    {
      "epoch": 872.26,
      "learning_rate": 0.012808312998225805,
      "loss": 0.5009,
      "step": 540800
    },
    {
      "epoch": 872.29,
      "learning_rate": 0.012805087195000002,
      "loss": 0.5096,
      "step": 540820
    },
    {
      "epoch": 872.32,
      "learning_rate": 0.012801861391774194,
      "loss": 0.5008,
      "step": 540840
    },
    {
      "epoch": 872.35,
      "learning_rate": 0.012798635588548388,
      "loss": 0.502,
      "step": 540860
    },
    {
      "epoch": 872.39,
      "learning_rate": 0.012795409785322582,
      "loss": 0.5086,
      "step": 540880
    },
    {
      "epoch": 872.42,
      "learning_rate": 0.012792183982096776,
      "loss": 0.5036,
      "step": 540900
    },
    {
      "epoch": 872.45,
      "learning_rate": 0.012788958178870971,
      "loss": 0.5031,
      "step": 540920
    },
    {
      "epoch": 872.48,
      "learning_rate": 0.012785732375645165,
      "loss": 0.4955,
      "step": 540940
    },
    {
      "epoch": 872.52,
      "learning_rate": 0.01278250657241936,
      "loss": 0.4976,
      "step": 540960
    },
    {
      "epoch": 872.55,
      "learning_rate": 0.012779280769193553,
      "loss": 0.5026,
      "step": 540980
    },
    {
      "epoch": 872.58,
      "learning_rate": 0.012776054965967738,
      "loss": 0.5093,
      "step": 541000
    },
    {
      "epoch": 872.61,
      "learning_rate": 0.01277282916274193,
      "loss": 0.5094,
      "step": 541020
    },
    {
      "epoch": 872.65,
      "learning_rate": 0.012769603359516124,
      "loss": 0.507,
      "step": 541040
    },
    {
      "epoch": 872.68,
      "learning_rate": 0.012766377556290322,
      "loss": 0.5107,
      "step": 541060
    },
    {
      "epoch": 872.71,
      "learning_rate": 0.012763151753064514,
      "loss": 0.5181,
      "step": 541080
    },
    {
      "epoch": 872.74,
      "learning_rate": 0.012759925949838708,
      "loss": 0.4969,
      "step": 541100
    },
    {
      "epoch": 872.77,
      "learning_rate": 0.012756700146612902,
      "loss": 0.5038,
      "step": 541120
    },
    {
      "epoch": 872.81,
      "learning_rate": 0.012753474343387097,
      "loss": 0.518,
      "step": 541140
    },
    {
      "epoch": 872.84,
      "learning_rate": 0.012750248540161291,
      "loss": 0.4961,
      "step": 541160
    },
    {
      "epoch": 872.87,
      "learning_rate": 0.012747022736935485,
      "loss": 0.5141,
      "step": 541180
    },
    {
      "epoch": 872.9,
      "learning_rate": 0.012743796933709679,
      "loss": 0.511,
      "step": 541200
    },
    {
      "epoch": 872.94,
      "learning_rate": 0.012740571130483873,
      "loss": 0.5146,
      "step": 541220
    },
    {
      "epoch": 872.97,
      "learning_rate": 0.012737345327258068,
      "loss": 0.5167,
      "step": 541240
    },
    {
      "epoch": 873.0,
      "learning_rate": 0.012734280814193547,
      "loss": 0.5285,
      "step": 541260
    },
    {
      "epoch": 873.0,
      "eval_accuracy": {
        "accuracy": 0.789087502927172
      },
      "eval_loss": 0.8616484999656677,
      "eval_runtime": 3.0628,
      "eval_samples_per_second": 4182.77,
      "eval_steps_per_second": 65.626,
      "step": 541260
    },
    {
      "epoch": 873.03,
      "learning_rate": 0.01273105501096774,
      "loss": 0.4933,
      "step": 541280
    },
    {
      "epoch": 873.06,
      "learning_rate": 0.012727829207741938,
      "loss": 0.4978,
      "step": 541300
    },
    {
      "epoch": 873.1,
      "learning_rate": 0.01272460340451613,
      "loss": 0.516,
      "step": 541320
    },
    {
      "epoch": 873.13,
      "learning_rate": 0.012721377601290324,
      "loss": 0.5015,
      "step": 541340
    },
    {
      "epoch": 873.16,
      "learning_rate": 0.012718151798064521,
      "loss": 0.4996,
      "step": 541360
    },
    {
      "epoch": 873.19,
      "learning_rate": 0.012714925994838713,
      "loss": 0.5016,
      "step": 541380
    },
    {
      "epoch": 873.23,
      "learning_rate": 0.012711700191612907,
      "loss": 0.5038,
      "step": 541400
    },
    {
      "epoch": 873.26,
      "learning_rate": 0.012708474388387101,
      "loss": 0.5032,
      "step": 541420
    },
    {
      "epoch": 873.29,
      "learning_rate": 0.012705248585161283,
      "loss": 0.5152,
      "step": 541440
    },
    {
      "epoch": 873.32,
      "learning_rate": 0.012702022781935477,
      "loss": 0.5034,
      "step": 541460
    },
    {
      "epoch": 873.35,
      "learning_rate": 0.012698796978709674,
      "loss": 0.5009,
      "step": 541480
    },
    {
      "epoch": 873.39,
      "learning_rate": 0.012695571175483866,
      "loss": 0.5003,
      "step": 541500
    },
    {
      "epoch": 873.42,
      "learning_rate": 0.01269234537225806,
      "loss": 0.497,
      "step": 541520
    },
    {
      "epoch": 873.45,
      "learning_rate": 0.012689119569032258,
      "loss": 0.5146,
      "step": 541540
    },
    {
      "epoch": 873.48,
      "learning_rate": 0.01268589376580645,
      "loss": 0.5049,
      "step": 541560
    },
    {
      "epoch": 873.52,
      "learning_rate": 0.012682667962580644,
      "loss": 0.4975,
      "step": 541580
    },
    {
      "epoch": 873.55,
      "learning_rate": 0.012679442159354841,
      "loss": 0.5051,
      "step": 541600
    },
    {
      "epoch": 873.58,
      "learning_rate": 0.012676216356129033,
      "loss": 0.5073,
      "step": 541620
    },
    {
      "epoch": 873.61,
      "learning_rate": 0.012672990552903227,
      "loss": 0.5022,
      "step": 541640
    },
    {
      "epoch": 873.65,
      "learning_rate": 0.01266976474967742,
      "loss": 0.5098,
      "step": 541660
    },
    {
      "epoch": 873.68,
      "learning_rate": 0.012666538946451616,
      "loss": 0.5108,
      "step": 541680
    },
    {
      "epoch": 873.71,
      "learning_rate": 0.01266331314322581,
      "loss": 0.5222,
      "step": 541700
    },
    {
      "epoch": 873.74,
      "learning_rate": 0.012660087340000004,
      "loss": 0.5048,
      "step": 541720
    },
    {
      "epoch": 873.77,
      "learning_rate": 0.012656861536774198,
      "loss": 0.5019,
      "step": 541740
    },
    {
      "epoch": 873.81,
      "learning_rate": 0.01265363573354838,
      "loss": 0.5105,
      "step": 541760
    },
    {
      "epoch": 873.84,
      "learning_rate": 0.012650409930322577,
      "loss": 0.5082,
      "step": 541780
    },
    {
      "epoch": 873.87,
      "learning_rate": 0.01264718412709677,
      "loss": 0.5169,
      "step": 541800
    },
    {
      "epoch": 873.9,
      "learning_rate": 0.012643958323870963,
      "loss": 0.5199,
      "step": 541820
    },
    {
      "epoch": 873.94,
      "learning_rate": 0.01264073252064516,
      "loss": 0.4982,
      "step": 541840
    },
    {
      "epoch": 873.97,
      "learning_rate": 0.012637506717419353,
      "loss": 0.5022,
      "step": 541860
    },
    {
      "epoch": 874.0,
      "learning_rate": 0.012634280914193547,
      "loss": 0.5061,
      "step": 541880
    },
    {
      "epoch": 874.0,
      "eval_accuracy": {
        "accuracy": 0.7885410974943408
      },
      "eval_loss": 0.8664067387580872,
      "eval_runtime": 3.0968,
      "eval_samples_per_second": 4136.824,
      "eval_steps_per_second": 64.905,
      "step": 541880
    },
    {
      "epoch": 874.03,
      "learning_rate": 0.012631055110967744,
      "loss": 0.505,
      "step": 541900
    },
    {
      "epoch": 874.06,
      "learning_rate": 0.012627829307741936,
      "loss": 0.4912,
      "step": 541920
    },
    {
      "epoch": 874.1,
      "learning_rate": 0.01262460350451613,
      "loss": 0.5047,
      "step": 541940
    },
    {
      "epoch": 874.13,
      "learning_rate": 0.012621377701290324,
      "loss": 0.4947,
      "step": 541960
    },
    {
      "epoch": 874.16,
      "learning_rate": 0.012618151898064518,
      "loss": 0.504,
      "step": 541980
    },
    {
      "epoch": 874.19,
      "learning_rate": 0.012614926094838714,
      "loss": 0.5109,
      "step": 542000
    },
    {
      "epoch": 874.23,
      "learning_rate": 0.012611700291612907,
      "loss": 0.508,
      "step": 542020
    },
    {
      "epoch": 874.26,
      "learning_rate": 0.012608474488387101,
      "loss": 0.5056,
      "step": 542040
    },
    {
      "epoch": 874.29,
      "learning_rate": 0.012605248685161283,
      "loss": 0.5105,
      "step": 542060
    },
    {
      "epoch": 874.32,
      "learning_rate": 0.01260202288193548,
      "loss": 0.5174,
      "step": 542080
    },
    {
      "epoch": 874.35,
      "learning_rate": 0.012598797078709673,
      "loss": 0.5053,
      "step": 542100
    },
    {
      "epoch": 874.39,
      "learning_rate": 0.012595571275483866,
      "loss": 0.5083,
      "step": 542120
    },
    {
      "epoch": 874.42,
      "learning_rate": 0.012592345472258064,
      "loss": 0.5065,
      "step": 542140
    },
    {
      "epoch": 874.45,
      "learning_rate": 0.012589119669032256,
      "loss": 0.497,
      "step": 542160
    },
    {
      "epoch": 874.48,
      "learning_rate": 0.01258589386580645,
      "loss": 0.5004,
      "step": 542180
    },
    {
      "epoch": 874.52,
      "learning_rate": 0.012582668062580644,
      "loss": 0.5056,
      "step": 542200
    },
    {
      "epoch": 874.55,
      "learning_rate": 0.01257944225935484,
      "loss": 0.5041,
      "step": 542220
    },
    {
      "epoch": 874.58,
      "learning_rate": 0.012576216456129033,
      "loss": 0.5072,
      "step": 542240
    },
    {
      "epoch": 874.61,
      "learning_rate": 0.012572990652903227,
      "loss": 0.5091,
      "step": 542260
    },
    {
      "epoch": 874.65,
      "learning_rate": 0.012569764849677421,
      "loss": 0.5084,
      "step": 542280
    },
    {
      "epoch": 874.68,
      "learning_rate": 0.012566539046451615,
      "loss": 0.5081,
      "step": 542300
    },
    {
      "epoch": 874.71,
      "learning_rate": 0.01256331324322581,
      "loss": 0.517,
      "step": 542320
    },
    {
      "epoch": 874.74,
      "learning_rate": 0.012560087440000004,
      "loss": 0.5072,
      "step": 542340
    },
    {
      "epoch": 874.77,
      "learning_rate": 0.012556861636774198,
      "loss": 0.4921,
      "step": 542360
    },
    {
      "epoch": 874.81,
      "learning_rate": 0.012553635833548384,
      "loss": 0.5015,
      "step": 542380
    },
    {
      "epoch": 874.84,
      "learning_rate": 0.012550410030322576,
      "loss": 0.497,
      "step": 542400
    },
    {
      "epoch": 874.87,
      "learning_rate": 0.01254718422709677,
      "loss": 0.4982,
      "step": 542420
    },
    {
      "epoch": 874.9,
      "learning_rate": 0.012543958423870967,
      "loss": 0.5067,
      "step": 542440
    },
    {
      "epoch": 874.94,
      "learning_rate": 0.01254073262064516,
      "loss": 0.5122,
      "step": 542460
    },
    {
      "epoch": 874.97,
      "learning_rate": 0.012537506817419353,
      "loss": 0.5117,
      "step": 542480
    },
    {
      "epoch": 875.0,
      "learning_rate": 0.012534281014193547,
      "loss": 0.5032,
      "step": 542500
    },
    {
      "epoch": 875.0,
      "eval_accuracy": {
        "accuracy": 0.791663414253376
      },
      "eval_loss": 0.857903003692627,
      "eval_runtime": 3.5604,
      "eval_samples_per_second": 3598.147,
      "eval_steps_per_second": 56.454,
      "step": 542500
    },
    {
      "epoch": 875.03,
      "learning_rate": 0.01253105521096774,
      "loss": 0.5169,
      "step": 542520
    },
    {
      "epoch": 875.06,
      "learning_rate": 0.012527829407741936,
      "loss": 0.5036,
      "step": 542540
    },
    {
      "epoch": 875.1,
      "learning_rate": 0.01252460360451613,
      "loss": 0.494,
      "step": 542560
    },
    {
      "epoch": 875.13,
      "learning_rate": 0.012521377801290324,
      "loss": 0.4967,
      "step": 542580
    },
    {
      "epoch": 875.16,
      "learning_rate": 0.012518151998064518,
      "loss": 0.5056,
      "step": 542600
    },
    {
      "epoch": 875.19,
      "learning_rate": 0.01251492619483871,
      "loss": 0.5025,
      "step": 542620
    },
    {
      "epoch": 875.23,
      "learning_rate": 0.012511700391612908,
      "loss": 0.4992,
      "step": 542640
    },
    {
      "epoch": 875.26,
      "learning_rate": 0.012508474588387102,
      "loss": 0.4988,
      "step": 542660
    },
    {
      "epoch": 875.29,
      "learning_rate": 0.012505248785161294,
      "loss": 0.5,
      "step": 542680
    },
    {
      "epoch": 875.32,
      "learning_rate": 0.012502022981935479,
      "loss": 0.5082,
      "step": 542700
    },
    {
      "epoch": 875.35,
      "learning_rate": 0.012498797178709673,
      "loss": 0.5001,
      "step": 542720
    },
    {
      "epoch": 875.39,
      "learning_rate": 0.012495571375483867,
      "loss": 0.5,
      "step": 542740
    },
    {
      "epoch": 875.42,
      "learning_rate": 0.012492345572258062,
      "loss": 0.5054,
      "step": 542760
    },
    {
      "epoch": 875.45,
      "learning_rate": 0.012489119769032256,
      "loss": 0.5,
      "step": 542780
    },
    {
      "epoch": 875.48,
      "learning_rate": 0.01248589396580645,
      "loss": 0.5055,
      "step": 542800
    },
    {
      "epoch": 875.52,
      "learning_rate": 0.012482668162580644,
      "loss": 0.5038,
      "step": 542820
    },
    {
      "epoch": 875.55,
      "learning_rate": 0.012479442359354838,
      "loss": 0.4922,
      "step": 542840
    },
    {
      "epoch": 875.58,
      "learning_rate": 0.012476216556129033,
      "loss": 0.5056,
      "step": 542860
    },
    {
      "epoch": 875.61,
      "learning_rate": 0.012472990752903227,
      "loss": 0.5076,
      "step": 542880
    },
    {
      "epoch": 875.65,
      "learning_rate": 0.012469764949677421,
      "loss": 0.5075,
      "step": 542900
    },
    {
      "epoch": 875.68,
      "learning_rate": 0.012466539146451615,
      "loss": 0.4992,
      "step": 542920
    },
    {
      "epoch": 875.71,
      "learning_rate": 0.012463313343225809,
      "loss": 0.5121,
      "step": 542940
    },
    {
      "epoch": 875.74,
      "learning_rate": 0.012460087540000005,
      "loss": 0.5141,
      "step": 542960
    },
    {
      "epoch": 875.77,
      "learning_rate": 0.012456861736774199,
      "loss": 0.5167,
      "step": 542980
    },
    {
      "epoch": 875.81,
      "learning_rate": 0.012453635933548382,
      "loss": 0.5105,
      "step": 543000
    },
    {
      "epoch": 875.84,
      "learning_rate": 0.012450410130322576,
      "loss": 0.5167,
      "step": 543020
    },
    {
      "epoch": 875.87,
      "learning_rate": 0.01244718432709677,
      "loss": 0.5084,
      "step": 543040
    },
    {
      "epoch": 875.9,
      "learning_rate": 0.012443958523870964,
      "loss": 0.5036,
      "step": 543060
    },
    {
      "epoch": 875.94,
      "learning_rate": 0.01244073272064516,
      "loss": 0.5063,
      "step": 543080
    },
    {
      "epoch": 875.97,
      "learning_rate": 0.012437506917419353,
      "loss": 0.502,
      "step": 543100
    },
    {
      "epoch": 876.0,
      "learning_rate": 0.012434281114193547,
      "loss": 0.5054,
      "step": 543120
    },
    {
      "epoch": 876.0,
      "eval_accuracy": {
        "accuracy": 0.7912731246584966
      },
      "eval_loss": 0.8659146428108215,
      "eval_runtime": 2.9689,
      "eval_samples_per_second": 4315.059,
      "eval_steps_per_second": 67.702,
      "step": 543120
    },
    {
      "epoch": 876.03,
      "learning_rate": 0.012431055310967741,
      "loss": 0.5013,
      "step": 543140
    },
    {
      "epoch": 876.06,
      "learning_rate": 0.012427829507741935,
      "loss": 0.5035,
      "step": 543160
    },
    {
      "epoch": 876.1,
      "learning_rate": 0.01242460370451613,
      "loss": 0.5026,
      "step": 543180
    },
    {
      "epoch": 876.13,
      "learning_rate": 0.012421377901290324,
      "loss": 0.505,
      "step": 543200
    },
    {
      "epoch": 876.16,
      "learning_rate": 0.012418152098064518,
      "loss": 0.4952,
      "step": 543220
    },
    {
      "epoch": 876.19,
      "learning_rate": 0.012414926294838712,
      "loss": 0.5092,
      "step": 543240
    },
    {
      "epoch": 876.23,
      "learning_rate": 0.012411700491612906,
      "loss": 0.5005,
      "step": 543260
    },
    {
      "epoch": 876.26,
      "learning_rate": 0.012408474688387102,
      "loss": 0.501,
      "step": 543280
    },
    {
      "epoch": 876.29,
      "learning_rate": 0.012405248885161296,
      "loss": 0.5127,
      "step": 543300
    },
    {
      "epoch": 876.32,
      "learning_rate": 0.012402023081935479,
      "loss": 0.5102,
      "step": 543320
    },
    {
      "epoch": 876.35,
      "learning_rate": 0.012398797278709673,
      "loss": 0.5104,
      "step": 543340
    },
    {
      "epoch": 876.39,
      "learning_rate": 0.012395571475483867,
      "loss": 0.505,
      "step": 543360
    },
    {
      "epoch": 876.42,
      "learning_rate": 0.01239234567225806,
      "loss": 0.4974,
      "step": 543380
    },
    {
      "epoch": 876.45,
      "learning_rate": 0.012389119869032256,
      "loss": 0.4921,
      "step": 543400
    },
    {
      "epoch": 876.48,
      "learning_rate": 0.01238589406580645,
      "loss": 0.5118,
      "step": 543420
    },
    {
      "epoch": 876.52,
      "learning_rate": 0.012382668262580644,
      "loss": 0.5002,
      "step": 543440
    },
    {
      "epoch": 876.55,
      "learning_rate": 0.012379442459354838,
      "loss": 0.5169,
      "step": 543460
    },
    {
      "epoch": 876.58,
      "learning_rate": 0.012376216656129032,
      "loss": 0.5016,
      "step": 543480
    },
    {
      "epoch": 876.61,
      "learning_rate": 0.012372990852903228,
      "loss": 0.4922,
      "step": 543500
    },
    {
      "epoch": 876.65,
      "learning_rate": 0.012369765049677421,
      "loss": 0.5011,
      "step": 543520
    },
    {
      "epoch": 876.68,
      "learning_rate": 0.012366539246451615,
      "loss": 0.5093,
      "step": 543540
    },
    {
      "epoch": 876.71,
      "learning_rate": 0.01236331344322581,
      "loss": 0.5123,
      "step": 543560
    },
    {
      "epoch": 876.74,
      "learning_rate": 0.012360087640000005,
      "loss": 0.5015,
      "step": 543580
    },
    {
      "epoch": 876.77,
      "learning_rate": 0.012356861836774199,
      "loss": 0.5035,
      "step": 543600
    },
    {
      "epoch": 876.81,
      "learning_rate": 0.012353636033548382,
      "loss": 0.4968,
      "step": 543620
    },
    {
      "epoch": 876.84,
      "learning_rate": 0.012350410230322576,
      "loss": 0.5054,
      "step": 543640
    },
    {
      "epoch": 876.87,
      "learning_rate": 0.01234718442709677,
      "loss": 0.5117,
      "step": 543660
    },
    {
      "epoch": 876.9,
      "learning_rate": 0.012343958623870964,
      "loss": 0.5062,
      "step": 543680
    },
    {
      "epoch": 876.94,
      "learning_rate": 0.012340732820645158,
      "loss": 0.4994,
      "step": 543700
    },
    {
      "epoch": 876.97,
      "learning_rate": 0.012337507017419353,
      "loss": 0.5052,
      "step": 543720
    },
    {
      "epoch": 877.0,
      "learning_rate": 0.012334281214193547,
      "loss": 0.5001,
      "step": 543740
    },
    {
      "epoch": 877.0,
      "eval_accuracy": {
        "accuracy": 0.7876044024666302
      },
      "eval_loss": 0.8628986477851868,
      "eval_runtime": 3.6918,
      "eval_samples_per_second": 3470.084,
      "eval_steps_per_second": 54.444,
      "step": 543740
    },
    {
      "epoch": 877.03,
      "learning_rate": 0.012331055410967741,
      "loss": 0.515,
      "step": 543760
    },
    {
      "epoch": 877.06,
      "learning_rate": 0.012327829607741935,
      "loss": 0.5039,
      "step": 543780
    },
    {
      "epoch": 877.1,
      "learning_rate": 0.012324603804516129,
      "loss": 0.5058,
      "step": 543800
    },
    {
      "epoch": 877.13,
      "learning_rate": 0.012321378001290325,
      "loss": 0.5103,
      "step": 543820
    },
    {
      "epoch": 877.16,
      "learning_rate": 0.012318152198064519,
      "loss": 0.4948,
      "step": 543840
    },
    {
      "epoch": 877.19,
      "learning_rate": 0.012314926394838712,
      "loss": 0.5034,
      "step": 543860
    },
    {
      "epoch": 877.23,
      "learning_rate": 0.012311700591612906,
      "loss": 0.4851,
      "step": 543880
    },
    {
      "epoch": 877.26,
      "learning_rate": 0.012308474788387102,
      "loss": 0.5002,
      "step": 543900
    },
    {
      "epoch": 877.29,
      "learning_rate": 0.012305248985161296,
      "loss": 0.5042,
      "step": 543920
    },
    {
      "epoch": 877.32,
      "learning_rate": 0.01230202318193548,
      "loss": 0.5084,
      "step": 543940
    },
    {
      "epoch": 877.35,
      "learning_rate": 0.012298797378709673,
      "loss": 0.4952,
      "step": 543960
    },
    {
      "epoch": 877.39,
      "learning_rate": 0.012295571575483867,
      "loss": 0.5095,
      "step": 543980
    },
    {
      "epoch": 877.42,
      "learning_rate": 0.012292345772258061,
      "loss": 0.5048,
      "step": 544000
    },
    {
      "epoch": 877.45,
      "learning_rate": 0.012289119969032255,
      "loss": 0.4917,
      "step": 544020
    },
    {
      "epoch": 877.48,
      "learning_rate": 0.01228589416580645,
      "loss": 0.5106,
      "step": 544040
    },
    {
      "epoch": 877.52,
      "learning_rate": 0.012282668362580644,
      "loss": 0.4976,
      "step": 544060
    },
    {
      "epoch": 877.55,
      "learning_rate": 0.012279442559354838,
      "loss": 0.5043,
      "step": 544080
    },
    {
      "epoch": 877.58,
      "learning_rate": 0.012276216756129032,
      "loss": 0.5119,
      "step": 544100
    },
    {
      "epoch": 877.61,
      "learning_rate": 0.012272990952903226,
      "loss": 0.5066,
      "step": 544120
    },
    {
      "epoch": 877.65,
      "learning_rate": 0.012269765149677422,
      "loss": 0.4947,
      "step": 544140
    },
    {
      "epoch": 877.68,
      "learning_rate": 0.012266539346451616,
      "loss": 0.5112,
      "step": 544160
    },
    {
      "epoch": 877.71,
      "learning_rate": 0.01226331354322581,
      "loss": 0.5117,
      "step": 544180
    },
    {
      "epoch": 877.74,
      "learning_rate": 0.012260087740000003,
      "loss": 0.5038,
      "step": 544200
    },
    {
      "epoch": 877.77,
      "learning_rate": 0.012256861936774199,
      "loss": 0.5102,
      "step": 544220
    },
    {
      "epoch": 877.81,
      "learning_rate": 0.01225363613354838,
      "loss": 0.4999,
      "step": 544240
    },
    {
      "epoch": 877.84,
      "learning_rate": 0.012250410330322576,
      "loss": 0.4955,
      "step": 544260
    },
    {
      "epoch": 877.87,
      "learning_rate": 0.01224718452709677,
      "loss": 0.5024,
      "step": 544280
    },
    {
      "epoch": 877.9,
      "learning_rate": 0.012243958723870964,
      "loss": 0.5168,
      "step": 544300
    },
    {
      "epoch": 877.94,
      "learning_rate": 0.012240732920645158,
      "loss": 0.5051,
      "step": 544320
    },
    {
      "epoch": 877.97,
      "learning_rate": 0.012237507117419352,
      "loss": 0.503,
      "step": 544340
    },
    {
      "epoch": 878.0,
      "learning_rate": 0.012234442604354844,
      "loss": 0.5184,
      "step": 544360
    },
    {
      "epoch": 878.0,
      "eval_accuracy": {
        "accuracy": 0.7879946920615096
      },
      "eval_loss": 0.868895947933197,
      "eval_runtime": 3.1702,
      "eval_samples_per_second": 4041.08,
      "eval_steps_per_second": 63.403,
      "step": 544360
    },
    {
      "epoch": 878.03,
      "learning_rate": 0.012231216801129027,
      "loss": 0.5077,
      "step": 544380
    },
    {
      "epoch": 878.06,
      "learning_rate": 0.012227990997903221,
      "loss": 0.5021,
      "step": 544400
    },
    {
      "epoch": 878.1,
      "learning_rate": 0.012224765194677415,
      "loss": 0.4957,
      "step": 544420
    },
    {
      "epoch": 878.13,
      "learning_rate": 0.012221539391451609,
      "loss": 0.4948,
      "step": 544440
    },
    {
      "epoch": 878.16,
      "learning_rate": 0.012218313588225803,
      "loss": 0.4944,
      "step": 544460
    },
    {
      "epoch": 878.19,
      "learning_rate": 0.012215087784999999,
      "loss": 0.5074,
      "step": 544480
    },
    {
      "epoch": 878.23,
      "learning_rate": 0.012211861981774192,
      "loss": 0.5055,
      "step": 544500
    },
    {
      "epoch": 878.26,
      "learning_rate": 0.012208636178548386,
      "loss": 0.5056,
      "step": 544520
    },
    {
      "epoch": 878.29,
      "learning_rate": 0.01220541037532258,
      "loss": 0.5131,
      "step": 544540
    },
    {
      "epoch": 878.32,
      "learning_rate": 0.012202184572096774,
      "loss": 0.5036,
      "step": 544560
    },
    {
      "epoch": 878.35,
      "learning_rate": 0.01219895876887097,
      "loss": 0.5043,
      "step": 544580
    },
    {
      "epoch": 878.39,
      "learning_rate": 0.012195732965645164,
      "loss": 0.5021,
      "step": 544600
    },
    {
      "epoch": 878.42,
      "learning_rate": 0.012192507162419357,
      "loss": 0.5,
      "step": 544620
    },
    {
      "epoch": 878.45,
      "learning_rate": 0.012189281359193551,
      "loss": 0.5032,
      "step": 544640
    },
    {
      "epoch": 878.48,
      "learning_rate": 0.012186055555967747,
      "loss": 0.4971,
      "step": 544660
    },
    {
      "epoch": 878.52,
      "learning_rate": 0.012182829752741941,
      "loss": 0.5017,
      "step": 544680
    },
    {
      "epoch": 878.55,
      "learning_rate": 0.012179603949516124,
      "loss": 0.5039,
      "step": 544700
    },
    {
      "epoch": 878.58,
      "learning_rate": 0.012176378146290318,
      "loss": 0.5057,
      "step": 544720
    },
    {
      "epoch": 878.61,
      "learning_rate": 0.012173152343064512,
      "loss": 0.5113,
      "step": 544740
    },
    {
      "epoch": 878.65,
      "learning_rate": 0.012169926539838706,
      "loss": 0.5048,
      "step": 544760
    },
    {
      "epoch": 878.68,
      "learning_rate": 0.0121667007366129,
      "loss": 0.5054,
      "step": 544780
    },
    {
      "epoch": 878.71,
      "learning_rate": 0.012163474933387096,
      "loss": 0.5058,
      "step": 544800
    },
    {
      "epoch": 878.74,
      "learning_rate": 0.01216024913016129,
      "loss": 0.5024,
      "step": 544820
    },
    {
      "epoch": 878.77,
      "learning_rate": 0.012157023326935483,
      "loss": 0.5104,
      "step": 544840
    },
    {
      "epoch": 878.81,
      "learning_rate": 0.012153797523709677,
      "loss": 0.5041,
      "step": 544860
    },
    {
      "epoch": 878.84,
      "learning_rate": 0.012150571720483871,
      "loss": 0.5119,
      "step": 544880
    },
    {
      "epoch": 878.87,
      "learning_rate": 0.012147345917258067,
      "loss": 0.5042,
      "step": 544900
    },
    {
      "epoch": 878.9,
      "learning_rate": 0.01214412011403226,
      "loss": 0.4986,
      "step": 544920
    },
    {
      "epoch": 878.94,
      "learning_rate": 0.012140894310806455,
      "loss": 0.5017,
      "step": 544940
    },
    {
      "epoch": 878.97,
      "learning_rate": 0.012137668507580648,
      "loss": 0.5041,
      "step": 544960
    },
    {
      "epoch": 879.0,
      "learning_rate": 0.012134442704354844,
      "loss": 0.5021,
      "step": 544980
    },
    {
      "epoch": 879.0,
      "eval_accuracy": {
        "accuracy": 0.7903364296307861
      },
      "eval_loss": 0.862315833568573,
      "eval_runtime": 3.3004,
      "eval_samples_per_second": 3881.601,
      "eval_steps_per_second": 60.901,
      "step": 544980
    },
    {
      "epoch": 879.03,
      "learning_rate": 0.012131216901129038,
      "loss": 0.5047,
      "step": 545000
    },
    {
      "epoch": 879.06,
      "learning_rate": 0.012127991097903221,
      "loss": 0.5009,
      "step": 545020
    },
    {
      "epoch": 879.1,
      "learning_rate": 0.012124765294677415,
      "loss": 0.5079,
      "step": 545040
    },
    {
      "epoch": 879.13,
      "learning_rate": 0.01212153949145161,
      "loss": 0.5047,
      "step": 545060
    },
    {
      "epoch": 879.16,
      "learning_rate": 0.012118313688225803,
      "loss": 0.4998,
      "step": 545080
    },
    {
      "epoch": 879.19,
      "learning_rate": 0.012115087884999997,
      "loss": 0.5033,
      "step": 545100
    },
    {
      "epoch": 879.23,
      "learning_rate": 0.012111862081774193,
      "loss": 0.5005,
      "step": 545120
    },
    {
      "epoch": 879.26,
      "learning_rate": 0.012108636278548386,
      "loss": 0.4982,
      "step": 545140
    },
    {
      "epoch": 879.29,
      "learning_rate": 0.01210541047532258,
      "loss": 0.4844,
      "step": 545160
    },
    {
      "epoch": 879.32,
      "learning_rate": 0.012102184672096774,
      "loss": 0.5042,
      "step": 545180
    },
    {
      "epoch": 879.35,
      "learning_rate": 0.01209895886887097,
      "loss": 0.5052,
      "step": 545200
    },
    {
      "epoch": 879.39,
      "learning_rate": 0.012095733065645164,
      "loss": 0.4926,
      "step": 545220
    },
    {
      "epoch": 879.42,
      "learning_rate": 0.012092507262419358,
      "loss": 0.5003,
      "step": 545240
    },
    {
      "epoch": 879.45,
      "learning_rate": 0.012089281459193552,
      "loss": 0.5015,
      "step": 545260
    },
    {
      "epoch": 879.48,
      "learning_rate": 0.012086055655967745,
      "loss": 0.4995,
      "step": 545280
    },
    {
      "epoch": 879.52,
      "learning_rate": 0.012082829852741941,
      "loss": 0.5049,
      "step": 545300
    },
    {
      "epoch": 879.55,
      "learning_rate": 0.012079604049516123,
      "loss": 0.506,
      "step": 545320
    },
    {
      "epoch": 879.58,
      "learning_rate": 0.012076378246290318,
      "loss": 0.5011,
      "step": 545340
    },
    {
      "epoch": 879.61,
      "learning_rate": 0.012073152443064512,
      "loss": 0.5074,
      "step": 545360
    },
    {
      "epoch": 879.65,
      "learning_rate": 0.012069926639838706,
      "loss": 0.5006,
      "step": 545380
    },
    {
      "epoch": 879.68,
      "learning_rate": 0.0120667008366129,
      "loss": 0.4974,
      "step": 545400
    },
    {
      "epoch": 879.71,
      "learning_rate": 0.012063475033387094,
      "loss": 0.4997,
      "step": 545420
    },
    {
      "epoch": 879.74,
      "learning_rate": 0.01206024923016129,
      "loss": 0.5105,
      "step": 545440
    },
    {
      "epoch": 879.77,
      "learning_rate": 0.012057023426935484,
      "loss": 0.5125,
      "step": 545460
    },
    {
      "epoch": 879.81,
      "learning_rate": 0.012053797623709677,
      "loss": 0.5016,
      "step": 545480
    },
    {
      "epoch": 879.84,
      "learning_rate": 0.012050571820483871,
      "loss": 0.5082,
      "step": 545500
    },
    {
      "epoch": 879.87,
      "learning_rate": 0.012047346017258067,
      "loss": 0.5022,
      "step": 545520
    },
    {
      "epoch": 879.9,
      "learning_rate": 0.01204412021403226,
      "loss": 0.5066,
      "step": 545540
    },
    {
      "epoch": 879.94,
      "learning_rate": 0.012040894410806455,
      "loss": 0.5067,
      "step": 545560
    },
    {
      "epoch": 879.97,
      "learning_rate": 0.012037668607580649,
      "loss": 0.5063,
      "step": 545580
    },
    {
      "epoch": 880.0,
      "learning_rate": 0.012034442804354843,
      "loss": 0.5079,
      "step": 545600
    },
    {
      "epoch": 880.0,
      "eval_accuracy": {
        "accuracy": 0.7903364296307861
      },
      "eval_loss": 0.8612651824951172,
      "eval_runtime": 3.2522,
      "eval_samples_per_second": 3939.232,
      "eval_steps_per_second": 61.805,
      "step": 545600
    },
    {
      "epoch": 880.03,
      "learning_rate": 0.012031217001129038,
      "loss": 0.5005,
      "step": 545620
    },
    {
      "epoch": 880.06,
      "learning_rate": 0.01202799119790322,
      "loss": 0.506,
      "step": 545640
    },
    {
      "epoch": 880.1,
      "learning_rate": 0.012024765394677416,
      "loss": 0.5108,
      "step": 545660
    },
    {
      "epoch": 880.13,
      "learning_rate": 0.01202153959145161,
      "loss": 0.5057,
      "step": 545680
    },
    {
      "epoch": 880.16,
      "learning_rate": 0.012018313788225803,
      "loss": 0.4983,
      "step": 545700
    },
    {
      "epoch": 880.19,
      "learning_rate": 0.012015087984999997,
      "loss": 0.4994,
      "step": 545720
    },
    {
      "epoch": 880.23,
      "learning_rate": 0.012011862181774191,
      "loss": 0.512,
      "step": 545740
    },
    {
      "epoch": 880.26,
      "learning_rate": 0.012008636378548387,
      "loss": 0.4976,
      "step": 545760
    },
    {
      "epoch": 880.29,
      "learning_rate": 0.01200541057532258,
      "loss": 0.5066,
      "step": 545780
    },
    {
      "epoch": 880.32,
      "learning_rate": 0.012002184772096774,
      "loss": 0.4857,
      "step": 545800
    },
    {
      "epoch": 880.35,
      "learning_rate": 0.011998958968870968,
      "loss": 0.4986,
      "step": 545820
    },
    {
      "epoch": 880.39,
      "learning_rate": 0.011995733165645164,
      "loss": 0.497,
      "step": 545840
    },
    {
      "epoch": 880.42,
      "learning_rate": 0.011992507362419358,
      "loss": 0.4943,
      "step": 545860
    },
    {
      "epoch": 880.45,
      "learning_rate": 0.011989281559193552,
      "loss": 0.5121,
      "step": 545880
    },
    {
      "epoch": 880.48,
      "learning_rate": 0.011986055755967746,
      "loss": 0.5101,
      "step": 545900
    },
    {
      "epoch": 880.52,
      "learning_rate": 0.01198282995274194,
      "loss": 0.501,
      "step": 545920
    },
    {
      "epoch": 880.55,
      "learning_rate": 0.011979604149516123,
      "loss": 0.5046,
      "step": 545940
    },
    {
      "epoch": 880.58,
      "learning_rate": 0.011976378346290317,
      "loss": 0.5068,
      "step": 545960
    },
    {
      "epoch": 880.61,
      "learning_rate": 0.011973152543064513,
      "loss": 0.4928,
      "step": 545980
    },
    {
      "epoch": 880.65,
      "learning_rate": 0.011969926739838706,
      "loss": 0.5053,
      "step": 546000
    },
    {
      "epoch": 880.68,
      "learning_rate": 0.0119667009366129,
      "loss": 0.5096,
      "step": 546020
    },
    {
      "epoch": 880.71,
      "learning_rate": 0.011963475133387094,
      "loss": 0.5132,
      "step": 546040
    },
    {
      "epoch": 880.74,
      "learning_rate": 0.011960249330161288,
      "loss": 0.5001,
      "step": 546060
    },
    {
      "epoch": 880.77,
      "learning_rate": 0.011957023526935484,
      "loss": 0.4974,
      "step": 546080
    },
    {
      "epoch": 880.81,
      "learning_rate": 0.011953797723709678,
      "loss": 0.514,
      "step": 546100
    },
    {
      "epoch": 880.84,
      "learning_rate": 0.011950571920483872,
      "loss": 0.5038,
      "step": 546120
    },
    {
      "epoch": 880.87,
      "learning_rate": 0.011947346117258065,
      "loss": 0.5027,
      "step": 546140
    },
    {
      "epoch": 880.9,
      "learning_rate": 0.011944120314032261,
      "loss": 0.4961,
      "step": 546160
    },
    {
      "epoch": 880.94,
      "learning_rate": 0.011940894510806455,
      "loss": 0.4953,
      "step": 546180
    },
    {
      "epoch": 880.97,
      "learning_rate": 0.011937668707580649,
      "loss": 0.4991,
      "step": 546200
    },
    {
      "epoch": 881.0,
      "learning_rate": 0.011934442904354843,
      "loss": 0.5108,
      "step": 546220
    },
    {
      "epoch": 881.0,
      "eval_accuracy": {
        "accuracy": 0.7909608929825931
      },
      "eval_loss": 0.8574057221412659,
      "eval_runtime": 3.2554,
      "eval_samples_per_second": 3935.282,
      "eval_steps_per_second": 61.743,
      "step": 546220
    },
    {
      "epoch": 881.03,
      "learning_rate": 0.011931217101129037,
      "loss": 0.5133,
      "step": 546240
    },
    {
      "epoch": 881.06,
      "learning_rate": 0.01192799129790322,
      "loss": 0.504,
      "step": 546260
    },
    {
      "epoch": 881.1,
      "learning_rate": 0.011924765494677414,
      "loss": 0.4977,
      "step": 546280
    },
    {
      "epoch": 881.13,
      "learning_rate": 0.01192153969145161,
      "loss": 0.4956,
      "step": 546300
    },
    {
      "epoch": 881.16,
      "learning_rate": 0.011918313888225803,
      "loss": 0.4992,
      "step": 546320
    },
    {
      "epoch": 881.19,
      "learning_rate": 0.011915088084999997,
      "loss": 0.4963,
      "step": 546340
    },
    {
      "epoch": 881.23,
      "learning_rate": 0.011911862281774191,
      "loss": 0.4979,
      "step": 546360
    },
    {
      "epoch": 881.26,
      "learning_rate": 0.011908636478548387,
      "loss": 0.4984,
      "step": 546380
    },
    {
      "epoch": 881.29,
      "learning_rate": 0.01190541067532258,
      "loss": 0.5105,
      "step": 546400
    },
    {
      "epoch": 881.32,
      "learning_rate": 0.011902184872096775,
      "loss": 0.5065,
      "step": 546420
    },
    {
      "epoch": 881.35,
      "learning_rate": 0.011898959068870969,
      "loss": 0.5001,
      "step": 546440
    },
    {
      "epoch": 881.39,
      "learning_rate": 0.011895733265645162,
      "loss": 0.4881,
      "step": 546460
    },
    {
      "epoch": 881.42,
      "learning_rate": 0.011892507462419358,
      "loss": 0.5027,
      "step": 546480
    },
    {
      "epoch": 881.45,
      "learning_rate": 0.011889281659193552,
      "loss": 0.4883,
      "step": 546500
    },
    {
      "epoch": 881.48,
      "learning_rate": 0.011886055855967746,
      "loss": 0.5105,
      "step": 546520
    },
    {
      "epoch": 881.52,
      "learning_rate": 0.01188283005274194,
      "loss": 0.5048,
      "step": 546540
    },
    {
      "epoch": 881.55,
      "learning_rate": 0.011879604249516123,
      "loss": 0.503,
      "step": 546560
    },
    {
      "epoch": 881.58,
      "learning_rate": 0.011876378446290317,
      "loss": 0.5101,
      "step": 546580
    },
    {
      "epoch": 881.61,
      "learning_rate": 0.011873152643064511,
      "loss": 0.5016,
      "step": 546600
    },
    {
      "epoch": 881.65,
      "learning_rate": 0.011869926839838707,
      "loss": 0.5066,
      "step": 546620
    },
    {
      "epoch": 881.68,
      "learning_rate": 0.0118667010366129,
      "loss": 0.4966,
      "step": 546640
    },
    {
      "epoch": 881.71,
      "learning_rate": 0.011863475233387094,
      "loss": 0.4952,
      "step": 546660
    },
    {
      "epoch": 881.74,
      "learning_rate": 0.011860249430161288,
      "loss": 0.5118,
      "step": 546680
    },
    {
      "epoch": 881.77,
      "learning_rate": 0.011857023626935484,
      "loss": 0.5033,
      "step": 546700
    },
    {
      "epoch": 881.81,
      "learning_rate": 0.011853797823709678,
      "loss": 0.5003,
      "step": 546720
    },
    {
      "epoch": 881.84,
      "learning_rate": 0.011850572020483872,
      "loss": 0.5065,
      "step": 546740
    },
    {
      "epoch": 881.87,
      "learning_rate": 0.011847346217258066,
      "loss": 0.4995,
      "step": 546760
    },
    {
      "epoch": 881.9,
      "learning_rate": 0.01184412041403226,
      "loss": 0.4895,
      "step": 546780
    },
    {
      "epoch": 881.94,
      "learning_rate": 0.011840894610806455,
      "loss": 0.5041,
      "step": 546800
    },
    {
      "epoch": 881.97,
      "learning_rate": 0.011837668807580649,
      "loss": 0.5053,
      "step": 546820
    },
    {
      "epoch": 882.0,
      "learning_rate": 0.011834443004354843,
      "loss": 0.5094,
      "step": 546840
    },
    {
      "epoch": 882.0,
      "eval_accuracy": {
        "accuracy": 0.7896339083600031
      },
      "eval_loss": 0.8628057837486267,
      "eval_runtime": 3.8807,
      "eval_samples_per_second": 3301.193,
      "eval_steps_per_second": 51.795,
      "step": 546840
    },
    {
      "epoch": 882.03,
      "learning_rate": 0.011831217201129037,
      "loss": 0.496,
      "step": 546860
    },
    {
      "epoch": 882.06,
      "learning_rate": 0.01182799139790322,
      "loss": 0.5055,
      "step": 546880
    },
    {
      "epoch": 882.1,
      "learning_rate": 0.011824765594677414,
      "loss": 0.4896,
      "step": 546900
    },
    {
      "epoch": 882.13,
      "learning_rate": 0.011821539791451608,
      "loss": 0.4874,
      "step": 546920
    },
    {
      "epoch": 882.16,
      "learning_rate": 0.011818313988225804,
      "loss": 0.4996,
      "step": 546940
    },
    {
      "epoch": 882.19,
      "learning_rate": 0.011815088184999998,
      "loss": 0.4921,
      "step": 546960
    },
    {
      "epoch": 882.23,
      "learning_rate": 0.011811862381774191,
      "loss": 0.5073,
      "step": 546980
    },
    {
      "epoch": 882.26,
      "learning_rate": 0.011808636578548385,
      "loss": 0.4988,
      "step": 547000
    },
    {
      "epoch": 882.29,
      "learning_rate": 0.011805410775322581,
      "loss": 0.4938,
      "step": 547020
    },
    {
      "epoch": 882.32,
      "learning_rate": 0.011802184972096775,
      "loss": 0.494,
      "step": 547040
    },
    {
      "epoch": 882.35,
      "learning_rate": 0.011798959168870969,
      "loss": 0.5056,
      "step": 547060
    },
    {
      "epoch": 882.39,
      "learning_rate": 0.011795733365645163,
      "loss": 0.4978,
      "step": 547080
    },
    {
      "epoch": 882.42,
      "learning_rate": 0.011792507562419357,
      "loss": 0.4985,
      "step": 547100
    },
    {
      "epoch": 882.45,
      "learning_rate": 0.011789281759193552,
      "loss": 0.4943,
      "step": 547120
    },
    {
      "epoch": 882.48,
      "learning_rate": 0.011786055955967746,
      "loss": 0.504,
      "step": 547140
    },
    {
      "epoch": 882.52,
      "learning_rate": 0.01178283015274194,
      "loss": 0.5042,
      "step": 547160
    },
    {
      "epoch": 882.55,
      "learning_rate": 0.011779604349516123,
      "loss": 0.5015,
      "step": 547180
    },
    {
      "epoch": 882.58,
      "learning_rate": 0.011776378546290317,
      "loss": 0.5083,
      "step": 547200
    },
    {
      "epoch": 882.61,
      "learning_rate": 0.011773152743064511,
      "loss": 0.5026,
      "step": 547220
    },
    {
      "epoch": 882.65,
      "learning_rate": 0.011769926939838707,
      "loss": 0.5104,
      "step": 547240
    },
    {
      "epoch": 882.68,
      "learning_rate": 0.0117667011366129,
      "loss": 0.5067,
      "step": 547260
    },
    {
      "epoch": 882.71,
      "learning_rate": 0.011763475333387095,
      "loss": 0.5081,
      "step": 547280
    },
    {
      "epoch": 882.74,
      "learning_rate": 0.011760249530161289,
      "loss": 0.5026,
      "step": 547300
    },
    {
      "epoch": 882.77,
      "learning_rate": 0.011757023726935482,
      "loss": 0.4913,
      "step": 547320
    },
    {
      "epoch": 882.81,
      "learning_rate": 0.011753797923709678,
      "loss": 0.5014,
      "step": 547340
    },
    {
      "epoch": 882.84,
      "learning_rate": 0.011750572120483872,
      "loss": 0.5051,
      "step": 547360
    },
    {
      "epoch": 882.87,
      "learning_rate": 0.011747346317258066,
      "loss": 0.5049,
      "step": 547380
    },
    {
      "epoch": 882.9,
      "learning_rate": 0.01174412051403226,
      "loss": 0.5053,
      "step": 547400
    },
    {
      "epoch": 882.94,
      "learning_rate": 0.011740894710806454,
      "loss": 0.5015,
      "step": 547420
    },
    {
      "epoch": 882.97,
      "learning_rate": 0.01173766890758065,
      "loss": 0.5188,
      "step": 547440
    },
    {
      "epoch": 883.0,
      "learning_rate": 0.011734443104354843,
      "loss": 0.5046,
      "step": 547460
    },
    {
      "epoch": 883.0,
      "eval_accuracy": {
        "accuracy": 0.7893216766840996
      },
      "eval_loss": 0.8591656684875488,
      "eval_runtime": 3.0904,
      "eval_samples_per_second": 4145.37,
      "eval_steps_per_second": 65.039,
      "step": 547460
    },
    {
      "epoch": 883.03,
      "learning_rate": 0.011731217301129037,
      "loss": 0.5093,
      "step": 547480
    },
    {
      "epoch": 883.06,
      "learning_rate": 0.01172799149790322,
      "loss": 0.4996,
      "step": 547500
    },
    {
      "epoch": 883.1,
      "learning_rate": 0.011724765694677414,
      "loss": 0.4956,
      "step": 547520
    },
    {
      "epoch": 883.13,
      "learning_rate": 0.011721539891451608,
      "loss": 0.5033,
      "step": 547540
    },
    {
      "epoch": 883.16,
      "learning_rate": 0.011718314088225804,
      "loss": 0.4987,
      "step": 547560
    },
    {
      "epoch": 883.19,
      "learning_rate": 0.011715088284999998,
      "loss": 0.4911,
      "step": 547580
    },
    {
      "epoch": 883.23,
      "learning_rate": 0.011711862481774192,
      "loss": 0.4909,
      "step": 547600
    },
    {
      "epoch": 883.26,
      "learning_rate": 0.011708636678548386,
      "loss": 0.4988,
      "step": 547620
    },
    {
      "epoch": 883.29,
      "learning_rate": 0.01170541087532258,
      "loss": 0.5019,
      "step": 547640
    },
    {
      "epoch": 883.32,
      "learning_rate": 0.011702185072096775,
      "loss": 0.4972,
      "step": 547660
    },
    {
      "epoch": 883.35,
      "learning_rate": 0.011698959268870969,
      "loss": 0.497,
      "step": 547680
    },
    {
      "epoch": 883.39,
      "learning_rate": 0.011695733465645163,
      "loss": 0.5003,
      "step": 547700
    },
    {
      "epoch": 883.42,
      "learning_rate": 0.011692507662419357,
      "loss": 0.4953,
      "step": 547720
    },
    {
      "epoch": 883.45,
      "learning_rate": 0.01168928185919355,
      "loss": 0.4955,
      "step": 547740
    },
    {
      "epoch": 883.48,
      "learning_rate": 0.011686056055967746,
      "loss": 0.4985,
      "step": 547760
    },
    {
      "epoch": 883.52,
      "learning_rate": 0.01168283025274194,
      "loss": 0.5025,
      "step": 547780
    },
    {
      "epoch": 883.55,
      "learning_rate": 0.011679604449516134,
      "loss": 0.4881,
      "step": 547800
    },
    {
      "epoch": 883.58,
      "learning_rate": 0.011676378646290318,
      "loss": 0.5006,
      "step": 547820
    },
    {
      "epoch": 883.61,
      "learning_rate": 0.011673152843064511,
      "loss": 0.4961,
      "step": 547840
    },
    {
      "epoch": 883.65,
      "learning_rate": 0.011669927039838705,
      "loss": 0.5097,
      "step": 547860
    },
    {
      "epoch": 883.68,
      "learning_rate": 0.011666701236612901,
      "loss": 0.5001,
      "step": 547880
    },
    {
      "epoch": 883.71,
      "learning_rate": 0.011663475433387095,
      "loss": 0.507,
      "step": 547900
    },
    {
      "epoch": 883.74,
      "learning_rate": 0.011660249630161289,
      "loss": 0.495,
      "step": 547920
    },
    {
      "epoch": 883.77,
      "learning_rate": 0.011657023826935483,
      "loss": 0.5004,
      "step": 547940
    },
    {
      "epoch": 883.81,
      "learning_rate": 0.011653798023709677,
      "loss": 0.5092,
      "step": 547960
    },
    {
      "epoch": 883.84,
      "learning_rate": 0.011650572220483872,
      "loss": 0.4988,
      "step": 547980
    },
    {
      "epoch": 883.87,
      "learning_rate": 0.011647346417258066,
      "loss": 0.5019,
      "step": 548000
    },
    {
      "epoch": 883.9,
      "learning_rate": 0.01164412061403226,
      "loss": 0.5082,
      "step": 548020
    },
    {
      "epoch": 883.94,
      "learning_rate": 0.011640894810806454,
      "loss": 0.5094,
      "step": 548040
    },
    {
      "epoch": 883.97,
      "learning_rate": 0.011637669007580648,
      "loss": 0.503,
      "step": 548060
    },
    {
      "epoch": 884.0,
      "learning_rate": 0.011634443204354843,
      "loss": 0.4979,
      "step": 548080
    },
    {
      "epoch": 884.0,
      "eval_accuracy": {
        "accuracy": 0.7901022558738584
      },
      "eval_loss": 0.8616243600845337,
      "eval_runtime": 3.3427,
      "eval_samples_per_second": 3832.488,
      "eval_steps_per_second": 60.13,
      "step": 548080
    },
    {
      "epoch": 884.03,
      "learning_rate": 0.011631217401129037,
      "loss": 0.5098,
      "step": 548100
    },
    {
      "epoch": 884.06,
      "learning_rate": 0.01162799159790322,
      "loss": 0.5013,
      "step": 548120
    },
    {
      "epoch": 884.1,
      "learning_rate": 0.011624765794677415,
      "loss": 0.4846,
      "step": 548140
    },
    {
      "epoch": 884.13,
      "learning_rate": 0.011621539991451608,
      "loss": 0.4978,
      "step": 548160
    },
    {
      "epoch": 884.16,
      "learning_rate": 0.011618314188225802,
      "loss": 0.4989,
      "step": 548180
    },
    {
      "epoch": 884.19,
      "learning_rate": 0.011615088384999998,
      "loss": 0.5099,
      "step": 548200
    },
    {
      "epoch": 884.23,
      "learning_rate": 0.011611862581774192,
      "loss": 0.5026,
      "step": 548220
    },
    {
      "epoch": 884.26,
      "learning_rate": 0.011608636778548386,
      "loss": 0.4993,
      "step": 548240
    },
    {
      "epoch": 884.29,
      "learning_rate": 0.01160541097532258,
      "loss": 0.5082,
      "step": 548260
    },
    {
      "epoch": 884.32,
      "learning_rate": 0.011602185172096774,
      "loss": 0.4897,
      "step": 548280
    },
    {
      "epoch": 884.35,
      "learning_rate": 0.01159895936887097,
      "loss": 0.4932,
      "step": 548300
    },
    {
      "epoch": 884.39,
      "learning_rate": 0.011595733565645163,
      "loss": 0.4949,
      "step": 548320
    },
    {
      "epoch": 884.42,
      "learning_rate": 0.011592507762419357,
      "loss": 0.498,
      "step": 548340
    },
    {
      "epoch": 884.45,
      "learning_rate": 0.01158928195919355,
      "loss": 0.4907,
      "step": 548360
    },
    {
      "epoch": 884.48,
      "learning_rate": 0.01158621744612903,
      "loss": 0.4938,
      "step": 548380
    },
    {
      "epoch": 884.52,
      "learning_rate": 0.011582991642903225,
      "loss": 0.4976,
      "step": 548400
    },
    {
      "epoch": 884.55,
      "learning_rate": 0.01157976583967742,
      "loss": 0.4955,
      "step": 548420
    },
    {
      "epoch": 884.58,
      "learning_rate": 0.011576540036451614,
      "loss": 0.4934,
      "step": 548440
    },
    {
      "epoch": 884.61,
      "learning_rate": 0.011573314233225808,
      "loss": 0.5076,
      "step": 548460
    },
    {
      "epoch": 884.65,
      "learning_rate": 0.011570088430000002,
      "loss": 0.5093,
      "step": 548480
    },
    {
      "epoch": 884.68,
      "learning_rate": 0.011566862626774196,
      "loss": 0.5071,
      "step": 548500
    },
    {
      "epoch": 884.71,
      "learning_rate": 0.011563636823548391,
      "loss": 0.5022,
      "step": 548520
    },
    {
      "epoch": 884.74,
      "learning_rate": 0.011560411020322585,
      "loss": 0.4982,
      "step": 548540
    },
    {
      "epoch": 884.77,
      "learning_rate": 0.011557185217096779,
      "loss": 0.5017,
      "step": 548560
    },
    {
      "epoch": 884.81,
      "learning_rate": 0.011553959413870963,
      "loss": 0.5017,
      "step": 548580
    },
    {
      "epoch": 884.84,
      "learning_rate": 0.011550733610645156,
      "loss": 0.4968,
      "step": 548600
    },
    {
      "epoch": 884.87,
      "learning_rate": 0.01154750780741935,
      "loss": 0.5099,
      "step": 548620
    },
    {
      "epoch": 884.9,
      "learning_rate": 0.011544282004193546,
      "loss": 0.5067,
      "step": 548640
    },
    {
      "epoch": 884.94,
      "learning_rate": 0.01154105620096774,
      "loss": 0.5073,
      "step": 548660
    },
    {
      "epoch": 884.97,
      "learning_rate": 0.011537830397741934,
      "loss": 0.5082,
      "step": 548680
    },
    {
      "epoch": 885.0,
      "learning_rate": 0.011534604594516128,
      "loss": 0.504,
      "step": 548700
    },
    {
      "epoch": 885.0,
      "eval_accuracy": {
        "accuracy": 0.7921317617672313
      },
      "eval_loss": 0.8590609431266785,
      "eval_runtime": 4.829,
      "eval_samples_per_second": 2652.946,
      "eval_steps_per_second": 41.624,
      "step": 548700
    },
    {
      "epoch": 885.03,
      "learning_rate": 0.011531378791290322,
      "loss": 0.4997,
      "step": 548720
    },
    {
      "epoch": 885.06,
      "learning_rate": 0.011528152988064517,
      "loss": 0.496,
      "step": 548740
    },
    {
      "epoch": 885.1,
      "learning_rate": 0.011524927184838711,
      "loss": 0.508,
      "step": 548760
    },
    {
      "epoch": 885.13,
      "learning_rate": 0.011521701381612905,
      "loss": 0.491,
      "step": 548780
    },
    {
      "epoch": 885.16,
      "learning_rate": 0.011518475578387099,
      "loss": 0.4925,
      "step": 548800
    },
    {
      "epoch": 885.19,
      "learning_rate": 0.011515249775161293,
      "loss": 0.5032,
      "step": 548820
    },
    {
      "epoch": 885.23,
      "learning_rate": 0.011512023971935488,
      "loss": 0.5001,
      "step": 548840
    },
    {
      "epoch": 885.26,
      "learning_rate": 0.011508798168709682,
      "loss": 0.5045,
      "step": 548860
    },
    {
      "epoch": 885.29,
      "learning_rate": 0.011505572365483866,
      "loss": 0.4926,
      "step": 548880
    },
    {
      "epoch": 885.32,
      "learning_rate": 0.01150234656225806,
      "loss": 0.5046,
      "step": 548900
    },
    {
      "epoch": 885.35,
      "learning_rate": 0.011499120759032254,
      "loss": 0.4995,
      "step": 548920
    },
    {
      "epoch": 885.39,
      "learning_rate": 0.011495894955806447,
      "loss": 0.5035,
      "step": 548940
    },
    {
      "epoch": 885.42,
      "learning_rate": 0.011492669152580643,
      "loss": 0.499,
      "step": 548960
    },
    {
      "epoch": 885.45,
      "learning_rate": 0.011489443349354837,
      "loss": 0.5015,
      "step": 548980
    },
    {
      "epoch": 885.48,
      "learning_rate": 0.01148621754612903,
      "loss": 0.5049,
      "step": 549000
    },
    {
      "epoch": 885.52,
      "learning_rate": 0.011482991742903225,
      "loss": 0.5004,
      "step": 549020
    },
    {
      "epoch": 885.55,
      "learning_rate": 0.011479765939677419,
      "loss": 0.4907,
      "step": 549040
    },
    {
      "epoch": 885.58,
      "learning_rate": 0.011476540136451614,
      "loss": 0.5149,
      "step": 549060
    },
    {
      "epoch": 885.61,
      "learning_rate": 0.011473314333225808,
      "loss": 0.4983,
      "step": 549080
    },
    {
      "epoch": 885.65,
      "learning_rate": 0.011470088530000002,
      "loss": 0.4928,
      "step": 549100
    },
    {
      "epoch": 885.68,
      "learning_rate": 0.011466862726774196,
      "loss": 0.5041,
      "step": 549120
    },
    {
      "epoch": 885.71,
      "learning_rate": 0.01146363692354839,
      "loss": 0.5052,
      "step": 549140
    },
    {
      "epoch": 885.74,
      "learning_rate": 0.011460411120322585,
      "loss": 0.505,
      "step": 549160
    },
    {
      "epoch": 885.77,
      "learning_rate": 0.01145718531709678,
      "loss": 0.5047,
      "step": 549180
    },
    {
      "epoch": 885.81,
      "learning_rate": 0.011453959513870963,
      "loss": 0.5026,
      "step": 549200
    },
    {
      "epoch": 885.84,
      "learning_rate": 0.011450733710645157,
      "loss": 0.5,
      "step": 549220
    },
    {
      "epoch": 885.87,
      "learning_rate": 0.01144750790741935,
      "loss": 0.5012,
      "step": 549240
    },
    {
      "epoch": 885.9,
      "learning_rate": 0.011444282104193544,
      "loss": 0.5106,
      "step": 549260
    },
    {
      "epoch": 885.94,
      "learning_rate": 0.01144105630096774,
      "loss": 0.5123,
      "step": 549280
    },
    {
      "epoch": 885.97,
      "learning_rate": 0.011437830497741934,
      "loss": 0.4976,
      "step": 549300
    },
    {
      "epoch": 886.0,
      "learning_rate": 0.011434765984677424,
      "loss": 0.4877,
      "step": 549320
    },
    {
      "epoch": 886.0,
      "eval_accuracy": {
        "accuracy": 0.7947076730934354
      },
      "eval_loss": 0.8529086709022522,
      "eval_runtime": 3.4935,
      "eval_samples_per_second": 3667.072,
      "eval_steps_per_second": 57.535,
      "step": 549320
    },
    {
      "epoch": 886.03,
      "learning_rate": 0.011431540181451608,
      "loss": 0.4946,
      "step": 549340
    },
    {
      "epoch": 886.06,
      "learning_rate": 0.011428314378225802,
      "loss": 0.5049,
      "step": 549360
    },
    {
      "epoch": 886.1,
      "learning_rate": 0.011425088574999995,
      "loss": 0.4945,
      "step": 549380
    },
    {
      "epoch": 886.13,
      "learning_rate": 0.011421862771774191,
      "loss": 0.5022,
      "step": 549400
    },
    {
      "epoch": 886.16,
      "learning_rate": 0.011418636968548385,
      "loss": 0.4896,
      "step": 549420
    },
    {
      "epoch": 886.19,
      "learning_rate": 0.011415411165322579,
      "loss": 0.4929,
      "step": 549440
    },
    {
      "epoch": 886.23,
      "learning_rate": 0.011412185362096773,
      "loss": 0.5024,
      "step": 549460
    },
    {
      "epoch": 886.26,
      "learning_rate": 0.011408959558870967,
      "loss": 0.5003,
      "step": 549480
    },
    {
      "epoch": 886.29,
      "learning_rate": 0.011405733755645162,
      "loss": 0.4959,
      "step": 549500
    },
    {
      "epoch": 886.32,
      "learning_rate": 0.011402507952419356,
      "loss": 0.4963,
      "step": 549520
    },
    {
      "epoch": 886.35,
      "learning_rate": 0.01139928214919355,
      "loss": 0.4848,
      "step": 549540
    },
    {
      "epoch": 886.39,
      "learning_rate": 0.011396056345967744,
      "loss": 0.5005,
      "step": 549560
    },
    {
      "epoch": 886.42,
      "learning_rate": 0.011392830542741938,
      "loss": 0.4889,
      "step": 549580
    },
    {
      "epoch": 886.45,
      "learning_rate": 0.011389604739516133,
      "loss": 0.5024,
      "step": 549600
    },
    {
      "epoch": 886.48,
      "learning_rate": 0.011386378936290327,
      "loss": 0.5105,
      "step": 549620
    },
    {
      "epoch": 886.52,
      "learning_rate": 0.011383153133064521,
      "loss": 0.5086,
      "step": 549640
    },
    {
      "epoch": 886.55,
      "learning_rate": 0.011379927329838705,
      "loss": 0.502,
      "step": 549660
    },
    {
      "epoch": 886.58,
      "learning_rate": 0.011376701526612899,
      "loss": 0.4918,
      "step": 549680
    },
    {
      "epoch": 886.61,
      "learning_rate": 0.011373475723387092,
      "loss": 0.505,
      "step": 549700
    },
    {
      "epoch": 886.65,
      "learning_rate": 0.011370249920161288,
      "loss": 0.5003,
      "step": 549720
    },
    {
      "epoch": 886.68,
      "learning_rate": 0.011367024116935482,
      "loss": 0.5083,
      "step": 549740
    },
    {
      "epoch": 886.71,
      "learning_rate": 0.011363798313709676,
      "loss": 0.5062,
      "step": 549760
    },
    {
      "epoch": 886.74,
      "learning_rate": 0.01136057251048387,
      "loss": 0.4934,
      "step": 549780
    },
    {
      "epoch": 886.77,
      "learning_rate": 0.011357346707258064,
      "loss": 0.4964,
      "step": 549800
    },
    {
      "epoch": 886.81,
      "learning_rate": 0.01135412090403226,
      "loss": 0.5038,
      "step": 549820
    },
    {
      "epoch": 886.84,
      "learning_rate": 0.011350895100806453,
      "loss": 0.4894,
      "step": 549840
    },
    {
      "epoch": 886.87,
      "learning_rate": 0.011347669297580647,
      "loss": 0.5,
      "step": 549860
    },
    {
      "epoch": 886.9,
      "learning_rate": 0.011344443494354841,
      "loss": 0.4939,
      "step": 549880
    },
    {
      "epoch": 886.94,
      "learning_rate": 0.011341217691129035,
      "loss": 0.5028,
      "step": 549900
    },
    {
      "epoch": 886.97,
      "learning_rate": 0.01133799188790323,
      "loss": 0.5056,
      "step": 549920
    },
    {
      "epoch": 887.0,
      "learning_rate": 0.011334766084677424,
      "loss": 0.5049,
      "step": 549940
    },
    {
      "epoch": 887.0,
      "eval_accuracy": {
        "accuracy": 0.7888533291702443
      },
      "eval_loss": 0.8599005937576294,
      "eval_runtime": 3.1736,
      "eval_samples_per_second": 4036.713,
      "eval_steps_per_second": 63.335,
      "step": 549940
    },
    {
      "epoch": 887.03,
      "learning_rate": 0.011331540281451608,
      "loss": 0.499,
      "step": 549960
    },
    {
      "epoch": 887.06,
      "learning_rate": 0.011328314478225802,
      "loss": 0.4974,
      "step": 549980
    },
    {
      "epoch": 887.1,
      "learning_rate": 0.011325088674999996,
      "loss": 0.4881,
      "step": 550000
    },
    {
      "epoch": 887.13,
      "learning_rate": 0.01132186287177419,
      "loss": 0.501,
      "step": 550020
    },
    {
      "epoch": 887.16,
      "learning_rate": 0.011318637068548385,
      "loss": 0.4969,
      "step": 550040
    },
    {
      "epoch": 887.19,
      "learning_rate": 0.011315411265322579,
      "loss": 0.4934,
      "step": 550060
    },
    {
      "epoch": 887.23,
      "learning_rate": 0.011312185462096773,
      "loss": 0.5,
      "step": 550080
    },
    {
      "epoch": 887.26,
      "learning_rate": 0.011308959658870967,
      "loss": 0.4998,
      "step": 550100
    },
    {
      "epoch": 887.29,
      "learning_rate": 0.01130573385564516,
      "loss": 0.5005,
      "step": 550120
    },
    {
      "epoch": 887.32,
      "learning_rate": 0.011302508052419356,
      "loss": 0.5036,
      "step": 550140
    },
    {
      "epoch": 887.35,
      "learning_rate": 0.01129928224919355,
      "loss": 0.4959,
      "step": 550160
    },
    {
      "epoch": 887.39,
      "learning_rate": 0.011296056445967744,
      "loss": 0.4901,
      "step": 550180
    },
    {
      "epoch": 887.42,
      "learning_rate": 0.011292830642741938,
      "loss": 0.5043,
      "step": 550200
    },
    {
      "epoch": 887.45,
      "learning_rate": 0.011289604839516132,
      "loss": 0.4964,
      "step": 550220
    },
    {
      "epoch": 887.48,
      "learning_rate": 0.011286379036290328,
      "loss": 0.5029,
      "step": 550240
    },
    {
      "epoch": 887.52,
      "learning_rate": 0.011283153233064521,
      "loss": 0.4981,
      "step": 550260
    },
    {
      "epoch": 887.55,
      "learning_rate": 0.011279927429838705,
      "loss": 0.5081,
      "step": 550280
    },
    {
      "epoch": 887.58,
      "learning_rate": 0.011276701626612899,
      "loss": 0.5043,
      "step": 550300
    },
    {
      "epoch": 887.61,
      "learning_rate": 0.011273475823387093,
      "loss": 0.5014,
      "step": 550320
    },
    {
      "epoch": 887.65,
      "learning_rate": 0.011270250020161287,
      "loss": 0.4998,
      "step": 550340
    },
    {
      "epoch": 887.68,
      "learning_rate": 0.011267024216935482,
      "loss": 0.4908,
      "step": 550360
    },
    {
      "epoch": 887.71,
      "learning_rate": 0.011263798413709676,
      "loss": 0.4941,
      "step": 550380
    },
    {
      "epoch": 887.74,
      "learning_rate": 0.01126057261048387,
      "loss": 0.4886,
      "step": 550400
    },
    {
      "epoch": 887.77,
      "learning_rate": 0.011257346807258064,
      "loss": 0.4936,
      "step": 550420
    },
    {
      "epoch": 887.81,
      "learning_rate": 0.011254121004032258,
      "loss": 0.5025,
      "step": 550440
    },
    {
      "epoch": 887.84,
      "learning_rate": 0.011250895200806453,
      "loss": 0.5049,
      "step": 550460
    },
    {
      "epoch": 887.87,
      "learning_rate": 0.011247669397580647,
      "loss": 0.5016,
      "step": 550480
    },
    {
      "epoch": 887.9,
      "learning_rate": 0.011244443594354841,
      "loss": 0.4931,
      "step": 550500
    },
    {
      "epoch": 887.94,
      "learning_rate": 0.011241217791129035,
      "loss": 0.4997,
      "step": 550520
    },
    {
      "epoch": 887.97,
      "learning_rate": 0.01123799198790323,
      "loss": 0.5017,
      "step": 550540
    },
    {
      "epoch": 888.0,
      "learning_rate": 0.011234766184677425,
      "loss": 0.5054,
      "step": 550560
    },
    {
      "epoch": 888.0,
      "eval_accuracy": {
        "accuracy": 0.7897900241979549
      },
      "eval_loss": 0.8572788238525391,
      "eval_runtime": 3.2009,
      "eval_samples_per_second": 4002.321,
      "eval_steps_per_second": 62.795,
      "step": 550560
    },
    {
      "epoch": 888.03,
      "learning_rate": 0.011231540381451608,
      "loss": 0.518,
      "step": 550580
    },
    {
      "epoch": 888.06,
      "learning_rate": 0.011228314578225802,
      "loss": 0.499,
      "step": 550600
    },
    {
      "epoch": 888.1,
      "learning_rate": 0.011225088774999996,
      "loss": 0.4986,
      "step": 550620
    },
    {
      "epoch": 888.13,
      "learning_rate": 0.01122186297177419,
      "loss": 0.4987,
      "step": 550640
    },
    {
      "epoch": 888.16,
      "learning_rate": 0.011218637168548384,
      "loss": 0.4928,
      "step": 550660
    },
    {
      "epoch": 888.19,
      "learning_rate": 0.01121541136532258,
      "loss": 0.4976,
      "step": 550680
    },
    {
      "epoch": 888.23,
      "learning_rate": 0.011212185562096773,
      "loss": 0.4992,
      "step": 550700
    },
    {
      "epoch": 888.26,
      "learning_rate": 0.011208959758870967,
      "loss": 0.4993,
      "step": 550720
    },
    {
      "epoch": 888.29,
      "learning_rate": 0.011205733955645161,
      "loss": 0.4987,
      "step": 550740
    },
    {
      "epoch": 888.32,
      "learning_rate": 0.011202508152419355,
      "loss": 0.499,
      "step": 550760
    },
    {
      "epoch": 888.35,
      "learning_rate": 0.01119928234919355,
      "loss": 0.4965,
      "step": 550780
    },
    {
      "epoch": 888.39,
      "learning_rate": 0.011196056545967744,
      "loss": 0.4932,
      "step": 550800
    },
    {
      "epoch": 888.42,
      "learning_rate": 0.011192830742741938,
      "loss": 0.4936,
      "step": 550820
    },
    {
      "epoch": 888.45,
      "learning_rate": 0.011189604939516132,
      "loss": 0.5,
      "step": 550840
    },
    {
      "epoch": 888.48,
      "learning_rate": 0.011186379136290328,
      "loss": 0.4921,
      "step": 550860
    },
    {
      "epoch": 888.52,
      "learning_rate": 0.011183153333064522,
      "loss": 0.4873,
      "step": 550880
    },
    {
      "epoch": 888.55,
      "learning_rate": 0.011179927529838705,
      "loss": 0.4963,
      "step": 550900
    },
    {
      "epoch": 888.58,
      "learning_rate": 0.011176701726612899,
      "loss": 0.5002,
      "step": 550920
    },
    {
      "epoch": 888.61,
      "learning_rate": 0.011173475923387093,
      "loss": 0.5034,
      "step": 550940
    },
    {
      "epoch": 888.65,
      "learning_rate": 0.011170250120161287,
      "loss": 0.5009,
      "step": 550960
    },
    {
      "epoch": 888.68,
      "learning_rate": 0.01116702431693548,
      "loss": 0.5028,
      "step": 550980
    },
    {
      "epoch": 888.71,
      "learning_rate": 0.011163798513709676,
      "loss": 0.5003,
      "step": 551000
    },
    {
      "epoch": 888.74,
      "learning_rate": 0.01116057271048387,
      "loss": 0.4901,
      "step": 551020
    },
    {
      "epoch": 888.77,
      "learning_rate": 0.011157346907258064,
      "loss": 0.5037,
      "step": 551040
    },
    {
      "epoch": 888.81,
      "learning_rate": 0.011154121104032258,
      "loss": 0.4977,
      "step": 551060
    },
    {
      "epoch": 888.84,
      "learning_rate": 0.011150895300806452,
      "loss": 0.4895,
      "step": 551080
    },
    {
      "epoch": 888.87,
      "learning_rate": 0.011147669497580647,
      "loss": 0.5002,
      "step": 551100
    },
    {
      "epoch": 888.9,
      "learning_rate": 0.011144443694354841,
      "loss": 0.5073,
      "step": 551120
    },
    {
      "epoch": 888.94,
      "learning_rate": 0.011141217891129035,
      "loss": 0.4963,
      "step": 551140
    },
    {
      "epoch": 888.97,
      "learning_rate": 0.01113799208790323,
      "loss": 0.4982,
      "step": 551160
    },
    {
      "epoch": 889.0,
      "learning_rate": 0.011134766284677425,
      "loss": 0.4974,
      "step": 551180
    },
    {
      "epoch": 889.0,
      "eval_accuracy": {
        "accuracy": 0.7902583717118101
      },
      "eval_loss": 0.8622117042541504,
      "eval_runtime": 4.0851,
      "eval_samples_per_second": 3136.033,
      "eval_steps_per_second": 49.203,
      "step": 551180
    },
    {
      "epoch": 889.03,
      "learning_rate": 0.011131540481451607,
      "loss": 0.5036,
      "step": 551200
    },
    {
      "epoch": 889.06,
      "learning_rate": 0.011128314678225802,
      "loss": 0.4935,
      "step": 551220
    },
    {
      "epoch": 889.1,
      "learning_rate": 0.011125088874999996,
      "loss": 0.4912,
      "step": 551240
    },
    {
      "epoch": 889.13,
      "learning_rate": 0.01112186307177419,
      "loss": 0.4934,
      "step": 551260
    },
    {
      "epoch": 889.16,
      "learning_rate": 0.011118637268548384,
      "loss": 0.5034,
      "step": 551280
    },
    {
      "epoch": 889.19,
      "learning_rate": 0.011115411465322578,
      "loss": 0.4911,
      "step": 551300
    },
    {
      "epoch": 889.23,
      "learning_rate": 0.011112185662096773,
      "loss": 0.4948,
      "step": 551320
    },
    {
      "epoch": 889.26,
      "learning_rate": 0.011108959858870967,
      "loss": 0.4945,
      "step": 551340
    },
    {
      "epoch": 889.29,
      "learning_rate": 0.011105734055645161,
      "loss": 0.5015,
      "step": 551360
    },
    {
      "epoch": 889.32,
      "learning_rate": 0.011102508252419355,
      "loss": 0.5049,
      "step": 551380
    },
    {
      "epoch": 889.35,
      "learning_rate": 0.01109928244919355,
      "loss": 0.4981,
      "step": 551400
    },
    {
      "epoch": 889.39,
      "learning_rate": 0.011096056645967745,
      "loss": 0.4949,
      "step": 551420
    },
    {
      "epoch": 889.42,
      "learning_rate": 0.011092830842741938,
      "loss": 0.5098,
      "step": 551440
    },
    {
      "epoch": 889.45,
      "learning_rate": 0.011089605039516132,
      "loss": 0.5008,
      "step": 551460
    },
    {
      "epoch": 889.48,
      "learning_rate": 0.011086379236290326,
      "loss": 0.4952,
      "step": 551480
    },
    {
      "epoch": 889.52,
      "learning_rate": 0.011083153433064522,
      "loss": 0.4919,
      "step": 551500
    },
    {
      "epoch": 889.55,
      "learning_rate": 0.011079927629838704,
      "loss": 0.4996,
      "step": 551520
    },
    {
      "epoch": 889.58,
      "learning_rate": 0.0110767018266129,
      "loss": 0.5018,
      "step": 551540
    },
    {
      "epoch": 889.61,
      "learning_rate": 0.011073476023387093,
      "loss": 0.501,
      "step": 551560
    },
    {
      "epoch": 889.65,
      "learning_rate": 0.011070250220161287,
      "loss": 0.5003,
      "step": 551580
    },
    {
      "epoch": 889.68,
      "learning_rate": 0.011067024416935481,
      "loss": 0.4872,
      "step": 551600
    },
    {
      "epoch": 889.71,
      "learning_rate": 0.011063798613709675,
      "loss": 0.4945,
      "step": 551620
    },
    {
      "epoch": 889.74,
      "learning_rate": 0.01106057281048387,
      "loss": 0.4975,
      "step": 551640
    },
    {
      "epoch": 889.77,
      "learning_rate": 0.011057347007258064,
      "loss": 0.4964,
      "step": 551660
    },
    {
      "epoch": 889.81,
      "learning_rate": 0.011054121204032258,
      "loss": 0.4966,
      "step": 551680
    },
    {
      "epoch": 889.84,
      "learning_rate": 0.011050895400806452,
      "loss": 0.4918,
      "step": 551700
    },
    {
      "epoch": 889.87,
      "learning_rate": 0.011047669597580648,
      "loss": 0.4945,
      "step": 551720
    },
    {
      "epoch": 889.9,
      "learning_rate": 0.011044443794354842,
      "loss": 0.504,
      "step": 551740
    },
    {
      "epoch": 889.94,
      "learning_rate": 0.011041217991129035,
      "loss": 0.5114,
      "step": 551760
    },
    {
      "epoch": 889.97,
      "learning_rate": 0.01103799218790323,
      "loss": 0.502,
      "step": 551780
    },
    {
      "epoch": 890.0,
      "learning_rate": 0.01103492767483871,
      "loss": 0.5001,
      "step": 551800
    },
    {
      "epoch": 890.0,
      "eval_accuracy": {
        "accuracy": 0.7908828350636172
      },
      "eval_loss": 0.853132963180542,
      "eval_runtime": 3.1538,
      "eval_samples_per_second": 4062.037,
      "eval_steps_per_second": 63.732,
      "step": 551800
    },
    {
      "epoch": 890.03,
      "learning_rate": 0.011031701871612903,
      "loss": 0.4948,
      "step": 551820
    },
    {
      "epoch": 890.06,
      "learning_rate": 0.011028476068387097,
      "loss": 0.4944,
      "step": 551840
    },
    {
      "epoch": 890.1,
      "learning_rate": 0.011025250265161293,
      "loss": 0.5081,
      "step": 551860
    },
    {
      "epoch": 890.13,
      "learning_rate": 0.011022024461935486,
      "loss": 0.4829,
      "step": 551880
    },
    {
      "epoch": 890.16,
      "learning_rate": 0.01101879865870968,
      "loss": 0.4971,
      "step": 551900
    },
    {
      "epoch": 890.19,
      "learning_rate": 0.011015572855483874,
      "loss": 0.4998,
      "step": 551920
    },
    {
      "epoch": 890.23,
      "learning_rate": 0.01101234705225807,
      "loss": 0.4934,
      "step": 551940
    },
    {
      "epoch": 890.26,
      "learning_rate": 0.011009121249032252,
      "loss": 0.5052,
      "step": 551960
    },
    {
      "epoch": 890.29,
      "learning_rate": 0.011005895445806447,
      "loss": 0.4924,
      "step": 551980
    },
    {
      "epoch": 890.32,
      "learning_rate": 0.011002669642580641,
      "loss": 0.4931,
      "step": 552000
    },
    {
      "epoch": 890.35,
      "learning_rate": 0.010999443839354835,
      "loss": 0.492,
      "step": 552020
    },
    {
      "epoch": 890.39,
      "learning_rate": 0.010996218036129029,
      "loss": 0.4984,
      "step": 552040
    },
    {
      "epoch": 890.42,
      "learning_rate": 0.010992992232903223,
      "loss": 0.4858,
      "step": 552060
    },
    {
      "epoch": 890.45,
      "learning_rate": 0.010989766429677418,
      "loss": 0.5014,
      "step": 552080
    },
    {
      "epoch": 890.48,
      "learning_rate": 0.010986540626451612,
      "loss": 0.4984,
      "step": 552100
    },
    {
      "epoch": 890.52,
      "learning_rate": 0.010983314823225806,
      "loss": 0.4928,
      "step": 552120
    },
    {
      "epoch": 890.55,
      "learning_rate": 0.01098008902,
      "loss": 0.5005,
      "step": 552140
    },
    {
      "epoch": 890.58,
      "learning_rate": 0.010976863216774194,
      "loss": 0.5039,
      "step": 552160
    },
    {
      "epoch": 890.61,
      "learning_rate": 0.01097363741354839,
      "loss": 0.4874,
      "step": 552180
    },
    {
      "epoch": 890.65,
      "learning_rate": 0.010970411610322583,
      "loss": 0.5059,
      "step": 552200
    },
    {
      "epoch": 890.68,
      "learning_rate": 0.010967185807096777,
      "loss": 0.4993,
      "step": 552220
    },
    {
      "epoch": 890.71,
      "learning_rate": 0.010963960003870971,
      "loss": 0.5024,
      "step": 552240
    },
    {
      "epoch": 890.74,
      "learning_rate": 0.010960734200645167,
      "loss": 0.4964,
      "step": 552260
    },
    {
      "epoch": 890.77,
      "learning_rate": 0.010957508397419349,
      "loss": 0.4962,
      "step": 552280
    },
    {
      "epoch": 890.81,
      "learning_rate": 0.010954282594193544,
      "loss": 0.4962,
      "step": 552300
    },
    {
      "epoch": 890.84,
      "learning_rate": 0.010951056790967738,
      "loss": 0.4959,
      "step": 552320
    },
    {
      "epoch": 890.87,
      "learning_rate": 0.010947830987741932,
      "loss": 0.4957,
      "step": 552340
    },
    {
      "epoch": 890.9,
      "learning_rate": 0.010944605184516126,
      "loss": 0.511,
      "step": 552360
    },
    {
      "epoch": 890.94,
      "learning_rate": 0.01094137938129032,
      "loss": 0.501,
      "step": 552380
    },
    {
      "epoch": 890.97,
      "learning_rate": 0.010938153578064515,
      "loss": 0.4963,
      "step": 552400
    },
    {
      "epoch": 891.0,
      "learning_rate": 0.01093492777483871,
      "loss": 0.496,
      "step": 552420
    },
    {
      "epoch": 891.0,
      "eval_accuracy": {
        "accuracy": 0.7901803137928343
      },
      "eval_loss": 0.859629213809967,
      "eval_runtime": 4.0098,
      "eval_samples_per_second": 3194.945,
      "eval_steps_per_second": 50.128,
      "step": 552420
    },
    {
      "epoch": 891.03,
      "learning_rate": 0.010931701971612903,
      "loss": 0.4971,
      "step": 552440
    },
    {
      "epoch": 891.06,
      "learning_rate": 0.010928476168387097,
      "loss": 0.4944,
      "step": 552460
    },
    {
      "epoch": 891.1,
      "learning_rate": 0.010925250365161293,
      "loss": 0.4923,
      "step": 552480
    },
    {
      "epoch": 891.13,
      "learning_rate": 0.010922024561935487,
      "loss": 0.4907,
      "step": 552500
    },
    {
      "epoch": 891.16,
      "learning_rate": 0.01091879875870968,
      "loss": 0.4995,
      "step": 552520
    },
    {
      "epoch": 891.19,
      "learning_rate": 0.010915572955483874,
      "loss": 0.4952,
      "step": 552540
    },
    {
      "epoch": 891.23,
      "learning_rate": 0.010912347152258068,
      "loss": 0.5037,
      "step": 552560
    },
    {
      "epoch": 891.26,
      "learning_rate": 0.010909121349032264,
      "loss": 0.502,
      "step": 552580
    },
    {
      "epoch": 891.29,
      "learning_rate": 0.010905895545806446,
      "loss": 0.5022,
      "step": 552600
    },
    {
      "epoch": 891.32,
      "learning_rate": 0.010902669742580641,
      "loss": 0.4929,
      "step": 552620
    },
    {
      "epoch": 891.35,
      "learning_rate": 0.010899443939354835,
      "loss": 0.496,
      "step": 552640
    },
    {
      "epoch": 891.39,
      "learning_rate": 0.010896218136129029,
      "loss": 0.4956,
      "step": 552660
    },
    {
      "epoch": 891.42,
      "learning_rate": 0.010892992332903223,
      "loss": 0.5001,
      "step": 552680
    },
    {
      "epoch": 891.45,
      "learning_rate": 0.010889766529677417,
      "loss": 0.5062,
      "step": 552700
    },
    {
      "epoch": 891.48,
      "learning_rate": 0.010886540726451613,
      "loss": 0.4903,
      "step": 552720
    },
    {
      "epoch": 891.52,
      "learning_rate": 0.010883314923225806,
      "loss": 0.4943,
      "step": 552740
    },
    {
      "epoch": 891.55,
      "learning_rate": 0.01088008912,
      "loss": 0.5053,
      "step": 552760
    },
    {
      "epoch": 891.58,
      "learning_rate": 0.010876863316774194,
      "loss": 0.4859,
      "step": 552780
    },
    {
      "epoch": 891.61,
      "learning_rate": 0.01087363751354839,
      "loss": 0.492,
      "step": 552800
    },
    {
      "epoch": 891.65,
      "learning_rate": 0.010870411710322584,
      "loss": 0.4912,
      "step": 552820
    },
    {
      "epoch": 891.68,
      "learning_rate": 0.010867185907096778,
      "loss": 0.501,
      "step": 552840
    },
    {
      "epoch": 891.71,
      "learning_rate": 0.010863960103870971,
      "loss": 0.4953,
      "step": 552860
    },
    {
      "epoch": 891.74,
      "learning_rate": 0.010860734300645165,
      "loss": 0.4995,
      "step": 552880
    },
    {
      "epoch": 891.77,
      "learning_rate": 0.010857508497419349,
      "loss": 0.4948,
      "step": 552900
    },
    {
      "epoch": 891.81,
      "learning_rate": 0.010854282694193543,
      "loss": 0.5022,
      "step": 552920
    },
    {
      "epoch": 891.84,
      "learning_rate": 0.010851056890967738,
      "loss": 0.5015,
      "step": 552940
    },
    {
      "epoch": 891.87,
      "learning_rate": 0.010847831087741932,
      "loss": 0.4905,
      "step": 552960
    },
    {
      "epoch": 891.9,
      "learning_rate": 0.010844605284516126,
      "loss": 0.497,
      "step": 552980
    },
    {
      "epoch": 891.94,
      "learning_rate": 0.01084137948129032,
      "loss": 0.5024,
      "step": 553000
    },
    {
      "epoch": 891.97,
      "learning_rate": 0.010838153678064514,
      "loss": 0.4984,
      "step": 553020
    },
    {
      "epoch": 892.0,
      "learning_rate": 0.01083492787483871,
      "loss": 0.5048,
      "step": 553040
    },
    {
      "epoch": 892.0,
      "eval_accuracy": {
        "accuracy": 0.789009445008196
      },
      "eval_loss": 0.8645638823509216,
      "eval_runtime": 3.9802,
      "eval_samples_per_second": 3218.661,
      "eval_steps_per_second": 50.5,
      "step": 553040
    },
    {
      "epoch": 892.03,
      "learning_rate": 0.010831702071612903,
      "loss": 0.5066,
      "step": 553060
    },
    {
      "epoch": 892.06,
      "learning_rate": 0.010828476268387097,
      "loss": 0.5027,
      "step": 553080
    },
    {
      "epoch": 892.1,
      "learning_rate": 0.010825250465161291,
      "loss": 0.4942,
      "step": 553100
    },
    {
      "epoch": 892.13,
      "learning_rate": 0.010822024661935487,
      "loss": 0.4871,
      "step": 553120
    },
    {
      "epoch": 892.16,
      "learning_rate": 0.01081879885870968,
      "loss": 0.4938,
      "step": 553140
    },
    {
      "epoch": 892.19,
      "learning_rate": 0.010815573055483875,
      "loss": 0.4954,
      "step": 553160
    },
    {
      "epoch": 892.23,
      "learning_rate": 0.010812347252258069,
      "loss": 0.4874,
      "step": 553180
    },
    {
      "epoch": 892.26,
      "learning_rate": 0.010809121449032262,
      "loss": 0.4895,
      "step": 553200
    },
    {
      "epoch": 892.29,
      "learning_rate": 0.010805895645806446,
      "loss": 0.4922,
      "step": 553220
    },
    {
      "epoch": 892.32,
      "learning_rate": 0.01080266984258064,
      "loss": 0.4964,
      "step": 553240
    },
    {
      "epoch": 892.35,
      "learning_rate": 0.010799444039354835,
      "loss": 0.4943,
      "step": 553260
    },
    {
      "epoch": 892.39,
      "learning_rate": 0.01079621823612903,
      "loss": 0.4923,
      "step": 553280
    },
    {
      "epoch": 892.42,
      "learning_rate": 0.010792992432903223,
      "loss": 0.5037,
      "step": 553300
    },
    {
      "epoch": 892.45,
      "learning_rate": 0.010789766629677417,
      "loss": 0.5004,
      "step": 553320
    },
    {
      "epoch": 892.48,
      "learning_rate": 0.010786540826451613,
      "loss": 0.4865,
      "step": 553340
    },
    {
      "epoch": 892.52,
      "learning_rate": 0.010783315023225807,
      "loss": 0.5031,
      "step": 553360
    },
    {
      "epoch": 892.55,
      "learning_rate": 0.01078008922,
      "loss": 0.4852,
      "step": 553380
    },
    {
      "epoch": 892.58,
      "learning_rate": 0.010776863416774194,
      "loss": 0.4947,
      "step": 553400
    },
    {
      "epoch": 892.61,
      "learning_rate": 0.010773637613548388,
      "loss": 0.498,
      "step": 553420
    },
    {
      "epoch": 892.65,
      "learning_rate": 0.010770411810322584,
      "loss": 0.4964,
      "step": 553440
    },
    {
      "epoch": 892.68,
      "learning_rate": 0.010767186007096778,
      "loss": 0.5041,
      "step": 553460
    },
    {
      "epoch": 892.71,
      "learning_rate": 0.010763960203870972,
      "loss": 0.499,
      "step": 553480
    },
    {
      "epoch": 892.74,
      "learning_rate": 0.010760734400645166,
      "loss": 0.5028,
      "step": 553500
    },
    {
      "epoch": 892.77,
      "learning_rate": 0.010757508597419349,
      "loss": 0.4863,
      "step": 553520
    },
    {
      "epoch": 892.81,
      "learning_rate": 0.010754282794193543,
      "loss": 0.5057,
      "step": 553540
    },
    {
      "epoch": 892.84,
      "learning_rate": 0.010751056990967737,
      "loss": 0.5036,
      "step": 553560
    },
    {
      "epoch": 892.87,
      "learning_rate": 0.010747831187741932,
      "loss": 0.5007,
      "step": 553580
    },
    {
      "epoch": 892.9,
      "learning_rate": 0.010744605384516126,
      "loss": 0.4932,
      "step": 553600
    },
    {
      "epoch": 892.94,
      "learning_rate": 0.01074137958129032,
      "loss": 0.5021,
      "step": 553620
    },
    {
      "epoch": 892.97,
      "learning_rate": 0.010738153778064514,
      "loss": 0.5067,
      "step": 553640
    },
    {
      "epoch": 893.0,
      "learning_rate": 0.01073492797483871,
      "loss": 0.4864,
      "step": 553660
    },
    {
      "epoch": 893.0,
      "eval_accuracy": {
        "accuracy": 0.7917414721723519
      },
      "eval_loss": 0.8571196794509888,
      "eval_runtime": 3.0407,
      "eval_samples_per_second": 4213.193,
      "eval_steps_per_second": 66.103,
      "step": 553660
    },
    {
      "epoch": 893.03,
      "learning_rate": 0.010731702171612904,
      "loss": 0.4948,
      "step": 553680
    },
    {
      "epoch": 893.06,
      "learning_rate": 0.010728476368387098,
      "loss": 0.4885,
      "step": 553700
    },
    {
      "epoch": 893.1,
      "learning_rate": 0.010725250565161291,
      "loss": 0.5043,
      "step": 553720
    },
    {
      "epoch": 893.13,
      "learning_rate": 0.010722024761935485,
      "loss": 0.4956,
      "step": 553740
    },
    {
      "epoch": 893.16,
      "learning_rate": 0.010718798958709681,
      "loss": 0.4953,
      "step": 553760
    },
    {
      "epoch": 893.19,
      "learning_rate": 0.010715573155483875,
      "loss": 0.4931,
      "step": 553780
    },
    {
      "epoch": 893.23,
      "learning_rate": 0.010712347352258069,
      "loss": 0.4946,
      "step": 553800
    },
    {
      "epoch": 893.26,
      "learning_rate": 0.010709121549032263,
      "loss": 0.4952,
      "step": 553820
    },
    {
      "epoch": 893.29,
      "learning_rate": 0.010705895745806446,
      "loss": 0.4815,
      "step": 553840
    },
    {
      "epoch": 893.32,
      "learning_rate": 0.01070266994258064,
      "loss": 0.4959,
      "step": 553860
    },
    {
      "epoch": 893.35,
      "learning_rate": 0.010699444139354834,
      "loss": 0.4978,
      "step": 553880
    },
    {
      "epoch": 893.39,
      "learning_rate": 0.01069621833612903,
      "loss": 0.4914,
      "step": 553900
    },
    {
      "epoch": 893.42,
      "learning_rate": 0.010692992532903223,
      "loss": 0.4921,
      "step": 553920
    },
    {
      "epoch": 893.45,
      "learning_rate": 0.010689766729677417,
      "loss": 0.4942,
      "step": 553940
    },
    {
      "epoch": 893.48,
      "learning_rate": 0.010686540926451611,
      "loss": 0.5027,
      "step": 553960
    },
    {
      "epoch": 893.52,
      "learning_rate": 0.010683315123225807,
      "loss": 0.4946,
      "step": 553980
    },
    {
      "epoch": 893.55,
      "learning_rate": 0.01068008932,
      "loss": 0.5072,
      "step": 554000
    },
    {
      "epoch": 893.58,
      "learning_rate": 0.010676863516774195,
      "loss": 0.5,
      "step": 554020
    },
    {
      "epoch": 893.61,
      "learning_rate": 0.010673637713548388,
      "loss": 0.502,
      "step": 554040
    },
    {
      "epoch": 893.65,
      "learning_rate": 0.010670411910322582,
      "loss": 0.4926,
      "step": 554060
    },
    {
      "epoch": 893.68,
      "learning_rate": 0.010667186107096778,
      "loss": 0.4952,
      "step": 554080
    },
    {
      "epoch": 893.71,
      "learning_rate": 0.010663960303870972,
      "loss": 0.4976,
      "step": 554100
    },
    {
      "epoch": 893.74,
      "learning_rate": 0.010660734500645166,
      "loss": 0.4984,
      "step": 554120
    },
    {
      "epoch": 893.77,
      "learning_rate": 0.01065750869741935,
      "loss": 0.5031,
      "step": 554140
    },
    {
      "epoch": 893.81,
      "learning_rate": 0.010654282894193543,
      "loss": 0.4909,
      "step": 554160
    },
    {
      "epoch": 893.84,
      "learning_rate": 0.010651057090967737,
      "loss": 0.4913,
      "step": 554180
    },
    {
      "epoch": 893.87,
      "learning_rate": 0.010647831287741933,
      "loss": 0.4965,
      "step": 554200
    },
    {
      "epoch": 893.9,
      "learning_rate": 0.010644605484516127,
      "loss": 0.5008,
      "step": 554220
    },
    {
      "epoch": 893.94,
      "learning_rate": 0.01064137968129032,
      "loss": 0.4967,
      "step": 554240
    },
    {
      "epoch": 893.97,
      "learning_rate": 0.010638153878064514,
      "loss": 0.4937,
      "step": 554260
    },
    {
      "epoch": 894.0,
      "learning_rate": 0.010634928074838708,
      "loss": 0.4979,
      "step": 554280
    },
    {
      "epoch": 894.0,
      "eval_accuracy": {
        "accuracy": 0.7901022558738584
      },
      "eval_loss": 0.861255943775177,
      "eval_runtime": 3.1719,
      "eval_samples_per_second": 4038.912,
      "eval_steps_per_second": 63.369,
      "step": 554280
    },
    {
      "epoch": 894.03,
      "learning_rate": 0.010631702271612904,
      "loss": 0.5046,
      "step": 554300
    },
    {
      "epoch": 894.06,
      "learning_rate": 0.010628476468387098,
      "loss": 0.4934,
      "step": 554320
    },
    {
      "epoch": 894.1,
      "learning_rate": 0.010625250665161292,
      "loss": 0.5015,
      "step": 554340
    },
    {
      "epoch": 894.13,
      "learning_rate": 0.010622024861935486,
      "loss": 0.4954,
      "step": 554360
    },
    {
      "epoch": 894.16,
      "learning_rate": 0.01061879905870968,
      "loss": 0.4977,
      "step": 554380
    },
    {
      "epoch": 894.19,
      "learning_rate": 0.010615573255483875,
      "loss": 0.4906,
      "step": 554400
    },
    {
      "epoch": 894.23,
      "learning_rate": 0.010612347452258069,
      "loss": 0.4812,
      "step": 554420
    },
    {
      "epoch": 894.26,
      "learning_rate": 0.010609121649032263,
      "loss": 0.4938,
      "step": 554440
    },
    {
      "epoch": 894.29,
      "learning_rate": 0.010605895845806446,
      "loss": 0.4923,
      "step": 554460
    },
    {
      "epoch": 894.32,
      "learning_rate": 0.01060267004258064,
      "loss": 0.4931,
      "step": 554480
    },
    {
      "epoch": 894.35,
      "learning_rate": 0.010599444239354834,
      "loss": 0.4904,
      "step": 554500
    },
    {
      "epoch": 894.39,
      "learning_rate": 0.01059621843612903,
      "loss": 0.5081,
      "step": 554520
    },
    {
      "epoch": 894.42,
      "learning_rate": 0.010592992632903224,
      "loss": 0.4999,
      "step": 554540
    },
    {
      "epoch": 894.45,
      "learning_rate": 0.010589766829677418,
      "loss": 0.4908,
      "step": 554560
    },
    {
      "epoch": 894.48,
      "learning_rate": 0.010586541026451611,
      "loss": 0.4911,
      "step": 554580
    },
    {
      "epoch": 894.52,
      "learning_rate": 0.010583315223225805,
      "loss": 0.4874,
      "step": 554600
    },
    {
      "epoch": 894.55,
      "learning_rate": 0.010580089420000001,
      "loss": 0.4972,
      "step": 554620
    },
    {
      "epoch": 894.58,
      "learning_rate": 0.010576863616774195,
      "loss": 0.4979,
      "step": 554640
    },
    {
      "epoch": 894.61,
      "learning_rate": 0.010573637813548389,
      "loss": 0.4877,
      "step": 554660
    },
    {
      "epoch": 894.65,
      "learning_rate": 0.010570412010322583,
      "loss": 0.4982,
      "step": 554680
    },
    {
      "epoch": 894.68,
      "learning_rate": 0.010567186207096776,
      "loss": 0.4925,
      "step": 554700
    },
    {
      "epoch": 894.71,
      "learning_rate": 0.010563960403870972,
      "loss": 0.4992,
      "step": 554720
    },
    {
      "epoch": 894.74,
      "learning_rate": 0.010560734600645166,
      "loss": 0.4952,
      "step": 554740
    },
    {
      "epoch": 894.77,
      "learning_rate": 0.01055750879741936,
      "loss": 0.4958,
      "step": 554760
    },
    {
      "epoch": 894.81,
      "learning_rate": 0.010554282994193543,
      "loss": 0.5014,
      "step": 554780
    },
    {
      "epoch": 894.84,
      "learning_rate": 0.010551057190967737,
      "loss": 0.4935,
      "step": 554800
    },
    {
      "epoch": 894.87,
      "learning_rate": 0.010547831387741931,
      "loss": 0.493,
      "step": 554820
    },
    {
      "epoch": 894.9,
      "learning_rate": 0.010544605584516127,
      "loss": 0.4885,
      "step": 554840
    },
    {
      "epoch": 894.94,
      "learning_rate": 0.01054137978129032,
      "loss": 0.4976,
      "step": 554860
    },
    {
      "epoch": 894.97,
      "learning_rate": 0.010538153978064515,
      "loss": 0.4998,
      "step": 554880
    },
    {
      "epoch": 895.0,
      "learning_rate": 0.010535089465000005,
      "loss": 0.5039,
      "step": 554900
    },
    {
      "epoch": 895.0,
      "eval_accuracy": {
        "accuracy": 0.791038950901569
      },
      "eval_loss": 0.8552645444869995,
      "eval_runtime": 4.1384,
      "eval_samples_per_second": 3095.639,
      "eval_steps_per_second": 48.569,
      "step": 554900
    },
    {
      "epoch": 895.03,
      "learning_rate": 0.010531863661774188,
      "loss": 0.5019,
      "step": 554920
    },
    {
      "epoch": 895.06,
      "learning_rate": 0.010528637858548382,
      "loss": 0.4964,
      "step": 554940
    },
    {
      "epoch": 895.1,
      "learning_rate": 0.010525412055322576,
      "loss": 0.4942,
      "step": 554960
    },
    {
      "epoch": 895.13,
      "learning_rate": 0.010522186252096772,
      "loss": 0.5049,
      "step": 554980
    },
    {
      "epoch": 895.16,
      "learning_rate": 0.010518960448870966,
      "loss": 0.4852,
      "step": 555000
    },
    {
      "epoch": 895.19,
      "learning_rate": 0.01051573464564516,
      "loss": 0.4939,
      "step": 555020
    },
    {
      "epoch": 895.23,
      "learning_rate": 0.010512508842419353,
      "loss": 0.4922,
      "step": 555040
    },
    {
      "epoch": 895.26,
      "learning_rate": 0.010509283039193549,
      "loss": 0.4939,
      "step": 555060
    },
    {
      "epoch": 895.29,
      "learning_rate": 0.010506057235967743,
      "loss": 0.4889,
      "step": 555080
    },
    {
      "epoch": 895.32,
      "learning_rate": 0.010502831432741937,
      "loss": 0.5013,
      "step": 555100
    },
    {
      "epoch": 895.35,
      "learning_rate": 0.01049960562951613,
      "loss": 0.4892,
      "step": 555120
    },
    {
      "epoch": 895.39,
      "learning_rate": 0.010496379826290324,
      "loss": 0.4806,
      "step": 555140
    },
    {
      "epoch": 895.42,
      "learning_rate": 0.01049315402306452,
      "loss": 0.4973,
      "step": 555160
    },
    {
      "epoch": 895.45,
      "learning_rate": 0.010489928219838714,
      "loss": 0.5002,
      "step": 555180
    },
    {
      "epoch": 895.48,
      "learning_rate": 0.010486702416612908,
      "loss": 0.4843,
      "step": 555200
    },
    {
      "epoch": 895.52,
      "learning_rate": 0.010483476613387091,
      "loss": 0.5021,
      "step": 555220
    },
    {
      "epoch": 895.55,
      "learning_rate": 0.010480250810161285,
      "loss": 0.4888,
      "step": 555240
    },
    {
      "epoch": 895.58,
      "learning_rate": 0.01047702500693548,
      "loss": 0.5004,
      "step": 555260
    },
    {
      "epoch": 895.61,
      "learning_rate": 0.010473799203709675,
      "loss": 0.4949,
      "step": 555280
    },
    {
      "epoch": 895.65,
      "learning_rate": 0.010470573400483869,
      "loss": 0.5054,
      "step": 555300
    },
    {
      "epoch": 895.68,
      "learning_rate": 0.010467347597258063,
      "loss": 0.4965,
      "step": 555320
    },
    {
      "epoch": 895.71,
      "learning_rate": 0.010464121794032256,
      "loss": 0.4977,
      "step": 555340
    },
    {
      "epoch": 895.74,
      "learning_rate": 0.01046089599080645,
      "loss": 0.4928,
      "step": 555360
    },
    {
      "epoch": 895.77,
      "learning_rate": 0.010457670187580646,
      "loss": 0.4908,
      "step": 555380
    },
    {
      "epoch": 895.81,
      "learning_rate": 0.01045444438435484,
      "loss": 0.4969,
      "step": 555400
    },
    {
      "epoch": 895.84,
      "learning_rate": 0.010451218581129034,
      "loss": 0.4925,
      "step": 555420
    },
    {
      "epoch": 895.87,
      "learning_rate": 0.010447992777903228,
      "loss": 0.4913,
      "step": 555440
    },
    {
      "epoch": 895.9,
      "learning_rate": 0.010444766974677422,
      "loss": 0.4856,
      "step": 555460
    },
    {
      "epoch": 895.94,
      "learning_rate": 0.010441541171451617,
      "loss": 0.5027,
      "step": 555480
    },
    {
      "epoch": 895.97,
      "learning_rate": 0.010438315368225811,
      "loss": 0.4844,
      "step": 555500
    },
    {
      "epoch": 896.0,
      "learning_rate": 0.010435089565000005,
      "loss": 0.4963,
      "step": 555520
    },
    {
      "epoch": 896.0,
      "eval_accuracy": {
        "accuracy": 0.7901803137928343
      },
      "eval_loss": 0.8617806434631348,
      "eval_runtime": 3.0399,
      "eval_samples_per_second": 4214.338,
      "eval_steps_per_second": 66.121,
      "step": 555520
    },
    {
      "epoch": 896.03,
      "learning_rate": 0.010431863761774188,
      "loss": 0.4866,
      "step": 555540
    },
    {
      "epoch": 896.06,
      "learning_rate": 0.010428637958548382,
      "loss": 0.495,
      "step": 555560
    },
    {
      "epoch": 896.1,
      "learning_rate": 0.010425412155322576,
      "loss": 0.4899,
      "step": 555580
    },
    {
      "epoch": 896.13,
      "learning_rate": 0.010422186352096772,
      "loss": 0.4909,
      "step": 555600
    },
    {
      "epoch": 896.16,
      "learning_rate": 0.010418960548870966,
      "loss": 0.4845,
      "step": 555620
    },
    {
      "epoch": 896.19,
      "learning_rate": 0.01041573474564516,
      "loss": 0.4998,
      "step": 555640
    },
    {
      "epoch": 896.23,
      "learning_rate": 0.010412508942419353,
      "loss": 0.4903,
      "step": 555660
    },
    {
      "epoch": 896.26,
      "learning_rate": 0.010409283139193547,
      "loss": 0.4994,
      "step": 555680
    },
    {
      "epoch": 896.29,
      "learning_rate": 0.010406057335967743,
      "loss": 0.4849,
      "step": 555700
    },
    {
      "epoch": 896.32,
      "learning_rate": 0.010402831532741937,
      "loss": 0.4911,
      "step": 555720
    },
    {
      "epoch": 896.35,
      "learning_rate": 0.01039960572951613,
      "loss": 0.4921,
      "step": 555740
    },
    {
      "epoch": 896.39,
      "learning_rate": 0.010396379926290325,
      "loss": 0.4932,
      "step": 555760
    },
    {
      "epoch": 896.42,
      "learning_rate": 0.010393154123064519,
      "loss": 0.497,
      "step": 555780
    },
    {
      "epoch": 896.45,
      "learning_rate": 0.010389928319838714,
      "loss": 0.4973,
      "step": 555800
    },
    {
      "epoch": 896.48,
      "learning_rate": 0.010386702516612908,
      "loss": 0.4955,
      "step": 555820
    },
    {
      "epoch": 896.52,
      "learning_rate": 0.010383476713387092,
      "loss": 0.489,
      "step": 555840
    },
    {
      "epoch": 896.55,
      "learning_rate": 0.010380250910161285,
      "loss": 0.4864,
      "step": 555860
    },
    {
      "epoch": 896.58,
      "learning_rate": 0.01037702510693548,
      "loss": 0.4959,
      "step": 555880
    },
    {
      "epoch": 896.61,
      "learning_rate": 0.010373799303709673,
      "loss": 0.4988,
      "step": 555900
    },
    {
      "epoch": 896.65,
      "learning_rate": 0.010370573500483869,
      "loss": 0.4881,
      "step": 555920
    },
    {
      "epoch": 896.68,
      "learning_rate": 0.010367347697258063,
      "loss": 0.4953,
      "step": 555940
    },
    {
      "epoch": 896.71,
      "learning_rate": 0.010364121894032257,
      "loss": 0.4997,
      "step": 555960
    },
    {
      "epoch": 896.74,
      "learning_rate": 0.01036089609080645,
      "loss": 0.5085,
      "step": 555980
    },
    {
      "epoch": 896.77,
      "learning_rate": 0.010357670287580644,
      "loss": 0.4965,
      "step": 556000
    },
    {
      "epoch": 896.81,
      "learning_rate": 0.01035444448435484,
      "loss": 0.4902,
      "step": 556020
    },
    {
      "epoch": 896.84,
      "learning_rate": 0.010351218681129034,
      "loss": 0.4924,
      "step": 556040
    },
    {
      "epoch": 896.87,
      "learning_rate": 0.010347992877903228,
      "loss": 0.4967,
      "step": 556060
    },
    {
      "epoch": 896.9,
      "learning_rate": 0.010344767074677422,
      "loss": 0.4959,
      "step": 556080
    },
    {
      "epoch": 896.94,
      "learning_rate": 0.010341541271451616,
      "loss": 0.4987,
      "step": 556100
    },
    {
      "epoch": 896.97,
      "learning_rate": 0.010338315468225811,
      "loss": 0.5044,
      "step": 556120
    },
    {
      "epoch": 897.0,
      "learning_rate": 0.010335089665000005,
      "loss": 0.4986,
      "step": 556140
    },
    {
      "epoch": 897.0,
      "eval_accuracy": {
        "accuracy": 0.7876824603856061
      },
      "eval_loss": 0.8548177480697632,
      "eval_runtime": 3.0486,
      "eval_samples_per_second": 4202.233,
      "eval_steps_per_second": 65.932,
      "step": 556140
    },
    {
      "epoch": 897.03,
      "learning_rate": 0.010331863861774189,
      "loss": 0.4856,
      "step": 556160
    },
    {
      "epoch": 897.06,
      "learning_rate": 0.010328638058548383,
      "loss": 0.4773,
      "step": 556180
    },
    {
      "epoch": 897.1,
      "learning_rate": 0.010325412255322576,
      "loss": 0.4882,
      "step": 556200
    },
    {
      "epoch": 897.13,
      "learning_rate": 0.01032218645209677,
      "loss": 0.4936,
      "step": 556220
    },
    {
      "epoch": 897.16,
      "learning_rate": 0.010318960648870966,
      "loss": 0.4939,
      "step": 556240
    },
    {
      "epoch": 897.19,
      "learning_rate": 0.01031573484564516,
      "loss": 0.4945,
      "step": 556260
    },
    {
      "epoch": 897.23,
      "learning_rate": 0.010312509042419354,
      "loss": 0.4885,
      "step": 556280
    },
    {
      "epoch": 897.26,
      "learning_rate": 0.010309283239193548,
      "loss": 0.4976,
      "step": 556300
    },
    {
      "epoch": 897.29,
      "learning_rate": 0.010306057435967741,
      "loss": 0.4932,
      "step": 556320
    },
    {
      "epoch": 897.32,
      "learning_rate": 0.010302831632741937,
      "loss": 0.5025,
      "step": 556340
    },
    {
      "epoch": 897.35,
      "learning_rate": 0.010299605829516131,
      "loss": 0.4856,
      "step": 556360
    },
    {
      "epoch": 897.39,
      "learning_rate": 0.010296380026290325,
      "loss": 0.5017,
      "step": 556380
    },
    {
      "epoch": 897.42,
      "learning_rate": 0.010293154223064519,
      "loss": 0.4935,
      "step": 556400
    },
    {
      "epoch": 897.45,
      "learning_rate": 0.010289928419838713,
      "loss": 0.4903,
      "step": 556420
    },
    {
      "epoch": 897.48,
      "learning_rate": 0.010286702616612908,
      "loss": 0.5006,
      "step": 556440
    },
    {
      "epoch": 897.52,
      "learning_rate": 0.010283476813387092,
      "loss": 0.4924,
      "step": 556460
    },
    {
      "epoch": 897.55,
      "learning_rate": 0.010280251010161286,
      "loss": 0.4964,
      "step": 556480
    },
    {
      "epoch": 897.58,
      "learning_rate": 0.01027702520693548,
      "loss": 0.4908,
      "step": 556500
    },
    {
      "epoch": 897.61,
      "learning_rate": 0.010273799403709673,
      "loss": 0.4989,
      "step": 556520
    },
    {
      "epoch": 897.65,
      "learning_rate": 0.010270573600483867,
      "loss": 0.5023,
      "step": 556540
    },
    {
      "epoch": 897.68,
      "learning_rate": 0.010267347797258063,
      "loss": 0.4929,
      "step": 556560
    },
    {
      "epoch": 897.71,
      "learning_rate": 0.010264121994032257,
      "loss": 0.4889,
      "step": 556580
    },
    {
      "epoch": 897.74,
      "learning_rate": 0.01026089619080645,
      "loss": 0.4971,
      "step": 556600
    },
    {
      "epoch": 897.77,
      "learning_rate": 0.010257670387580645,
      "loss": 0.487,
      "step": 556620
    },
    {
      "epoch": 897.81,
      "learning_rate": 0.010254444584354839,
      "loss": 0.4946,
      "step": 556640
    },
    {
      "epoch": 897.84,
      "learning_rate": 0.010251218781129034,
      "loss": 0.4962,
      "step": 556660
    },
    {
      "epoch": 897.87,
      "learning_rate": 0.010247992977903228,
      "loss": 0.4952,
      "step": 556680
    },
    {
      "epoch": 897.9,
      "learning_rate": 0.010244767174677422,
      "loss": 0.485,
      "step": 556700
    },
    {
      "epoch": 897.94,
      "learning_rate": 0.010241541371451616,
      "loss": 0.497,
      "step": 556720
    },
    {
      "epoch": 897.97,
      "learning_rate": 0.010238315568225811,
      "loss": 0.4994,
      "step": 556740
    },
    {
      "epoch": 898.0,
      "learning_rate": 0.010235089765000005,
      "loss": 0.4924,
      "step": 556760
    },
    {
      "epoch": 898.0,
      "eval_accuracy": {
        "accuracy": 0.7889313870892202
      },
      "eval_loss": 0.8530696630477905,
      "eval_runtime": 4.0111,
      "eval_samples_per_second": 3193.872,
      "eval_steps_per_second": 50.111,
      "step": 556760
    },
    {
      "epoch": 898.03,
      "learning_rate": 0.010231863961774189,
      "loss": 0.5021,
      "step": 556780
    },
    {
      "epoch": 898.06,
      "learning_rate": 0.010228638158548383,
      "loss": 0.4883,
      "step": 556800
    },
    {
      "epoch": 898.1,
      "learning_rate": 0.010225412355322577,
      "loss": 0.4884,
      "step": 556820
    },
    {
      "epoch": 898.13,
      "learning_rate": 0.01022218655209677,
      "loss": 0.4967,
      "step": 556840
    },
    {
      "epoch": 898.16,
      "learning_rate": 0.010218960748870964,
      "loss": 0.4878,
      "step": 556860
    },
    {
      "epoch": 898.19,
      "learning_rate": 0.01021573494564516,
      "loss": 0.4814,
      "step": 556880
    },
    {
      "epoch": 898.23,
      "learning_rate": 0.010212509142419354,
      "loss": 0.502,
      "step": 556900
    },
    {
      "epoch": 898.26,
      "learning_rate": 0.010209283339193548,
      "loss": 0.479,
      "step": 556920
    },
    {
      "epoch": 898.29,
      "learning_rate": 0.010206057535967742,
      "loss": 0.4849,
      "step": 556940
    },
    {
      "epoch": 898.32,
      "learning_rate": 0.010202831732741936,
      "loss": 0.4995,
      "step": 556960
    },
    {
      "epoch": 898.35,
      "learning_rate": 0.010199605929516131,
      "loss": 0.5015,
      "step": 556980
    },
    {
      "epoch": 898.39,
      "learning_rate": 0.010196380126290325,
      "loss": 0.4894,
      "step": 557000
    },
    {
      "epoch": 898.42,
      "learning_rate": 0.010193154323064519,
      "loss": 0.4909,
      "step": 557020
    },
    {
      "epoch": 898.45,
      "learning_rate": 0.010189928519838713,
      "loss": 0.4833,
      "step": 557040
    },
    {
      "epoch": 898.48,
      "learning_rate": 0.010186702716612909,
      "loss": 0.492,
      "step": 557060
    },
    {
      "epoch": 898.52,
      "learning_rate": 0.010183476913387102,
      "loss": 0.4908,
      "step": 557080
    },
    {
      "epoch": 898.55,
      "learning_rate": 0.010180251110161286,
      "loss": 0.5078,
      "step": 557100
    },
    {
      "epoch": 898.58,
      "learning_rate": 0.01017702530693548,
      "loss": 0.4938,
      "step": 557120
    },
    {
      "epoch": 898.61,
      "learning_rate": 0.010173799503709674,
      "loss": 0.4941,
      "step": 557140
    },
    {
      "epoch": 898.65,
      "learning_rate": 0.010170573700483868,
      "loss": 0.4896,
      "step": 557160
    },
    {
      "epoch": 898.68,
      "learning_rate": 0.010167347897258061,
      "loss": 0.4895,
      "step": 557180
    },
    {
      "epoch": 898.71,
      "learning_rate": 0.010164122094032257,
      "loss": 0.4855,
      "step": 557200
    },
    {
      "epoch": 898.74,
      "learning_rate": 0.010160896290806451,
      "loss": 0.487,
      "step": 557220
    },
    {
      "epoch": 898.77,
      "learning_rate": 0.010157670487580645,
      "loss": 0.5028,
      "step": 557240
    },
    {
      "epoch": 898.81,
      "learning_rate": 0.010154444684354839,
      "loss": 0.4992,
      "step": 557260
    },
    {
      "epoch": 898.84,
      "learning_rate": 0.010151218881129033,
      "loss": 0.4924,
      "step": 557280
    },
    {
      "epoch": 898.87,
      "learning_rate": 0.010147993077903228,
      "loss": 0.4926,
      "step": 557300
    },
    {
      "epoch": 898.9,
      "learning_rate": 0.010144767274677422,
      "loss": 0.5055,
      "step": 557320
    },
    {
      "epoch": 898.94,
      "learning_rate": 0.010141541471451616,
      "loss": 0.5005,
      "step": 557340
    },
    {
      "epoch": 898.97,
      "learning_rate": 0.01013831566822581,
      "loss": 0.501,
      "step": 557360
    },
    {
      "epoch": 899.0,
      "learning_rate": 0.01013525115516129,
      "loss": 0.4904,
      "step": 557380
    },
    {
      "epoch": 899.0,
      "eval_accuracy": {
        "accuracy": 0.7912731246584966
      },
      "eval_loss": 0.8540578484535217,
      "eval_runtime": 3.0403,
      "eval_samples_per_second": 4213.683,
      "eval_steps_per_second": 66.111,
      "step": 557380
    },
    {
      "epoch": 899.03,
      "learning_rate": 0.010132025351935484,
      "loss": 0.4904,
      "step": 557400
    },
    {
      "epoch": 899.06,
      "learning_rate": 0.01012879954870968,
      "loss": 0.4873,
      "step": 557420
    },
    {
      "epoch": 899.1,
      "learning_rate": 0.010125573745483873,
      "loss": 0.4896,
      "step": 557440
    },
    {
      "epoch": 899.13,
      "learning_rate": 0.010122347942258067,
      "loss": 0.4944,
      "step": 557460
    },
    {
      "epoch": 899.16,
      "learning_rate": 0.010119122139032261,
      "loss": 0.4959,
      "step": 557480
    },
    {
      "epoch": 899.19,
      "learning_rate": 0.010115896335806457,
      "loss": 0.4958,
      "step": 557500
    },
    {
      "epoch": 899.23,
      "learning_rate": 0.01011267053258065,
      "loss": 0.4963,
      "step": 557520
    },
    {
      "epoch": 899.26,
      "learning_rate": 0.010109444729354834,
      "loss": 0.4926,
      "step": 557540
    },
    {
      "epoch": 899.29,
      "learning_rate": 0.010106218926129028,
      "loss": 0.4958,
      "step": 557560
    },
    {
      "epoch": 899.32,
      "learning_rate": 0.010102993122903222,
      "loss": 0.4915,
      "step": 557580
    },
    {
      "epoch": 899.35,
      "learning_rate": 0.010099767319677416,
      "loss": 0.4881,
      "step": 557600
    },
    {
      "epoch": 899.39,
      "learning_rate": 0.01009654151645161,
      "loss": 0.5035,
      "step": 557620
    },
    {
      "epoch": 899.42,
      "learning_rate": 0.010093315713225805,
      "loss": 0.4848,
      "step": 557640
    },
    {
      "epoch": 899.45,
      "learning_rate": 0.010090089909999999,
      "loss": 0.488,
      "step": 557660
    },
    {
      "epoch": 899.48,
      "learning_rate": 0.010086864106774193,
      "loss": 0.4929,
      "step": 557680
    },
    {
      "epoch": 899.52,
      "learning_rate": 0.010083638303548387,
      "loss": 0.4916,
      "step": 557700
    },
    {
      "epoch": 899.55,
      "learning_rate": 0.01008041250032258,
      "loss": 0.495,
      "step": 557720
    },
    {
      "epoch": 899.58,
      "learning_rate": 0.010077186697096776,
      "loss": 0.4878,
      "step": 557740
    },
    {
      "epoch": 899.61,
      "learning_rate": 0.01007396089387097,
      "loss": 0.4884,
      "step": 557760
    },
    {
      "epoch": 899.65,
      "learning_rate": 0.010070735090645164,
      "loss": 0.4858,
      "step": 557780
    },
    {
      "epoch": 899.68,
      "learning_rate": 0.010067509287419358,
      "loss": 0.4874,
      "step": 557800
    },
    {
      "epoch": 899.71,
      "learning_rate": 0.010064283484193554,
      "loss": 0.4958,
      "step": 557820
    },
    {
      "epoch": 899.74,
      "learning_rate": 0.010061057680967747,
      "loss": 0.4844,
      "step": 557840
    },
    {
      "epoch": 899.77,
      "learning_rate": 0.010057831877741931,
      "loss": 0.4956,
      "step": 557860
    },
    {
      "epoch": 899.81,
      "learning_rate": 0.010054606074516125,
      "loss": 0.4809,
      "step": 557880
    },
    {
      "epoch": 899.84,
      "learning_rate": 0.010051380271290319,
      "loss": 0.5011,
      "step": 557900
    },
    {
      "epoch": 899.87,
      "learning_rate": 0.010048154468064513,
      "loss": 0.4936,
      "step": 557920
    },
    {
      "epoch": 899.9,
      "learning_rate": 0.010044928664838707,
      "loss": 0.494,
      "step": 557940
    },
    {
      "epoch": 899.94,
      "learning_rate": 0.010041702861612902,
      "loss": 0.4974,
      "step": 557960
    },
    {
      "epoch": 899.97,
      "learning_rate": 0.010038477058387096,
      "loss": 0.4947,
      "step": 557980
    },
    {
      "epoch": 900.0,
      "learning_rate": 0.01003525125516129,
      "loss": 0.4997,
      "step": 558000
    },
    {
      "epoch": 900.0,
      "eval_accuracy": {
        "accuracy": 0.7881508078994613
      },
      "eval_loss": 0.8570348024368286,
      "eval_runtime": 3.0376,
      "eval_samples_per_second": 4217.486,
      "eval_steps_per_second": 66.171,
      "step": 558000
    },
    {
      "epoch": 900.03,
      "learning_rate": 0.010032025451935484,
      "loss": 0.5018,
      "step": 558020
    },
    {
      "epoch": 900.06,
      "learning_rate": 0.010028799648709678,
      "loss": 0.4899,
      "step": 558040
    },
    {
      "epoch": 900.1,
      "learning_rate": 0.010025573845483873,
      "loss": 0.4882,
      "step": 558060
    },
    {
      "epoch": 900.13,
      "learning_rate": 0.010022348042258067,
      "loss": 0.4927,
      "step": 558080
    },
    {
      "epoch": 900.16,
      "learning_rate": 0.010019122239032261,
      "loss": 0.485,
      "step": 558100
    },
    {
      "epoch": 900.19,
      "learning_rate": 0.010015896435806455,
      "loss": 0.4987,
      "step": 558120
    },
    {
      "epoch": 900.23,
      "learning_rate": 0.01001267063258065,
      "loss": 0.4839,
      "step": 558140
    },
    {
      "epoch": 900.26,
      "learning_rate": 0.010009444829354832,
      "loss": 0.4903,
      "step": 558160
    },
    {
      "epoch": 900.29,
      "learning_rate": 0.010006219026129028,
      "loss": 0.4864,
      "step": 558180
    },
    {
      "epoch": 900.32,
      "learning_rate": 0.010002993222903222,
      "loss": 0.4899,
      "step": 558200
    },
    {
      "epoch": 900.35,
      "learning_rate": 0.009999767419677416,
      "loss": 0.49,
      "step": 558220
    },
    {
      "epoch": 900.39,
      "learning_rate": 0.00999654161645161,
      "loss": 0.4945,
      "step": 558240
    },
    {
      "epoch": 900.42,
      "learning_rate": 0.009993315813225804,
      "loss": 0.5001,
      "step": 558260
    },
    {
      "epoch": 900.45,
      "learning_rate": 0.00999009001,
      "loss": 0.4756,
      "step": 558280
    },
    {
      "epoch": 900.48,
      "learning_rate": 0.009986864206774193,
      "loss": 0.4882,
      "step": 558300
    },
    {
      "epoch": 900.52,
      "learning_rate": 0.009983638403548387,
      "loss": 0.5006,
      "step": 558320
    },
    {
      "epoch": 900.55,
      "learning_rate": 0.00998041260032258,
      "loss": 0.5016,
      "step": 558340
    },
    {
      "epoch": 900.58,
      "learning_rate": 0.009977186797096775,
      "loss": 0.49,
      "step": 558360
    },
    {
      "epoch": 900.61,
      "learning_rate": 0.00997396099387097,
      "loss": 0.4954,
      "step": 558380
    },
    {
      "epoch": 900.65,
      "learning_rate": 0.009970735190645164,
      "loss": 0.4974,
      "step": 558400
    },
    {
      "epoch": 900.68,
      "learning_rate": 0.009967509387419358,
      "loss": 0.4919,
      "step": 558420
    },
    {
      "epoch": 900.71,
      "learning_rate": 0.009964283584193552,
      "loss": 0.4889,
      "step": 558440
    },
    {
      "epoch": 900.74,
      "learning_rate": 0.009961057780967748,
      "loss": 0.4885,
      "step": 558460
    },
    {
      "epoch": 900.77,
      "learning_rate": 0.00995783197774193,
      "loss": 0.4962,
      "step": 558480
    },
    {
      "epoch": 900.81,
      "learning_rate": 0.009954606174516125,
      "loss": 0.4856,
      "step": 558500
    },
    {
      "epoch": 900.84,
      "learning_rate": 0.009951380371290319,
      "loss": 0.502,
      "step": 558520
    },
    {
      "epoch": 900.87,
      "learning_rate": 0.009948154568064513,
      "loss": 0.4952,
      "step": 558540
    },
    {
      "epoch": 900.9,
      "learning_rate": 0.009944928764838707,
      "loss": 0.4927,
      "step": 558560
    },
    {
      "epoch": 900.94,
      "learning_rate": 0.0099417029616129,
      "loss": 0.4856,
      "step": 558580
    },
    {
      "epoch": 900.97,
      "learning_rate": 0.009938477158387096,
      "loss": 0.4978,
      "step": 558600
    },
    {
      "epoch": 901.0,
      "learning_rate": 0.00993525135516129,
      "loss": 0.4973,
      "step": 558620
    },
    {
      "epoch": 901.0,
      "eval_accuracy": {
        "accuracy": 0.7905706033877137
      },
      "eval_loss": 0.852941632270813,
      "eval_runtime": 3.8079,
      "eval_samples_per_second": 3364.327,
      "eval_steps_per_second": 52.785,
      "step": 558620
    },
    {
      "epoch": 901.03,
      "learning_rate": 0.009932025551935484,
      "loss": 0.4939,
      "step": 558640
    },
    {
      "epoch": 901.06,
      "learning_rate": 0.009928799748709678,
      "loss": 0.4849,
      "step": 558660
    },
    {
      "epoch": 901.1,
      "learning_rate": 0.009925573945483874,
      "loss": 0.4883,
      "step": 558680
    },
    {
      "epoch": 901.13,
      "learning_rate": 0.009922348142258067,
      "loss": 0.4928,
      "step": 558700
    },
    {
      "epoch": 901.16,
      "learning_rate": 0.009919122339032261,
      "loss": 0.4976,
      "step": 558720
    },
    {
      "epoch": 901.19,
      "learning_rate": 0.009915896535806455,
      "loss": 0.4987,
      "step": 558740
    },
    {
      "epoch": 901.23,
      "learning_rate": 0.009912670732580649,
      "loss": 0.4915,
      "step": 558760
    },
    {
      "epoch": 901.26,
      "learning_rate": 0.009909444929354833,
      "loss": 0.5003,
      "step": 558780
    },
    {
      "epoch": 901.29,
      "learning_rate": 0.009906219126129026,
      "loss": 0.4839,
      "step": 558800
    },
    {
      "epoch": 901.32,
      "learning_rate": 0.009902993322903222,
      "loss": 0.4868,
      "step": 558820
    },
    {
      "epoch": 901.35,
      "learning_rate": 0.009899767519677416,
      "loss": 0.486,
      "step": 558840
    },
    {
      "epoch": 901.39,
      "learning_rate": 0.00989654171645161,
      "loss": 0.4856,
      "step": 558860
    },
    {
      "epoch": 901.42,
      "learning_rate": 0.009893315913225804,
      "loss": 0.4954,
      "step": 558880
    },
    {
      "epoch": 901.45,
      "learning_rate": 0.009890090109999998,
      "loss": 0.492,
      "step": 558900
    },
    {
      "epoch": 901.48,
      "learning_rate": 0.009886864306774193,
      "loss": 0.5067,
      "step": 558920
    },
    {
      "epoch": 901.52,
      "learning_rate": 0.009883638503548387,
      "loss": 0.4937,
      "step": 558940
    },
    {
      "epoch": 901.55,
      "learning_rate": 0.009880412700322581,
      "loss": 0.4936,
      "step": 558960
    },
    {
      "epoch": 901.58,
      "learning_rate": 0.009877186897096775,
      "loss": 0.4939,
      "step": 558980
    },
    {
      "epoch": 901.61,
      "learning_rate": 0.00987396109387097,
      "loss": 0.4902,
      "step": 559000
    },
    {
      "epoch": 901.65,
      "learning_rate": 0.009870735290645164,
      "loss": 0.4866,
      "step": 559020
    },
    {
      "epoch": 901.68,
      "learning_rate": 0.009867509487419358,
      "loss": 0.4993,
      "step": 559040
    },
    {
      "epoch": 901.71,
      "learning_rate": 0.009864283684193552,
      "loss": 0.4953,
      "step": 559060
    },
    {
      "epoch": 901.74,
      "learning_rate": 0.009861057880967746,
      "loss": 0.4962,
      "step": 559080
    },
    {
      "epoch": 901.77,
      "learning_rate": 0.00985783207774193,
      "loss": 0.4825,
      "step": 559100
    },
    {
      "epoch": 901.81,
      "learning_rate": 0.009854606274516124,
      "loss": 0.497,
      "step": 559120
    },
    {
      "epoch": 901.84,
      "learning_rate": 0.009851380471290319,
      "loss": 0.4899,
      "step": 559140
    },
    {
      "epoch": 901.87,
      "learning_rate": 0.009848154668064513,
      "loss": 0.4811,
      "step": 559160
    },
    {
      "epoch": 901.9,
      "learning_rate": 0.009844928864838707,
      "loss": 0.4837,
      "step": 559180
    },
    {
      "epoch": 901.94,
      "learning_rate": 0.0098417030616129,
      "loss": 0.4909,
      "step": 559200
    },
    {
      "epoch": 901.97,
      "learning_rate": 0.009838477258387095,
      "loss": 0.4834,
      "step": 559220
    },
    {
      "epoch": 902.0,
      "learning_rate": 0.00983525145516129,
      "loss": 0.4936,
      "step": 559240
    },
    {
      "epoch": 902.0,
      "eval_accuracy": {
        "accuracy": 0.7911170088205448
      },
      "eval_loss": 0.8485169410705566,
      "eval_runtime": 3.1141,
      "eval_samples_per_second": 4113.813,
      "eval_steps_per_second": 64.544,
      "step": 559240
    },
    {
      "epoch": 902.03,
      "learning_rate": 0.009832025651935484,
      "loss": 0.5065,
      "step": 559260
    },
    {
      "epoch": 902.06,
      "learning_rate": 0.009828799848709678,
      "loss": 0.4858,
      "step": 559280
    },
    {
      "epoch": 902.1,
      "learning_rate": 0.009825574045483872,
      "loss": 0.4916,
      "step": 559300
    },
    {
      "epoch": 902.13,
      "learning_rate": 0.009822348242258068,
      "loss": 0.496,
      "step": 559320
    },
    {
      "epoch": 902.16,
      "learning_rate": 0.009819122439032262,
      "loss": 0.4854,
      "step": 559340
    },
    {
      "epoch": 902.19,
      "learning_rate": 0.009815896635806455,
      "loss": 0.483,
      "step": 559360
    },
    {
      "epoch": 902.23,
      "learning_rate": 0.00981267083258065,
      "loss": 0.4849,
      "step": 559380
    },
    {
      "epoch": 902.26,
      "learning_rate": 0.009809445029354843,
      "loss": 0.4864,
      "step": 559400
    },
    {
      "epoch": 902.29,
      "learning_rate": 0.009806219226129027,
      "loss": 0.4898,
      "step": 559420
    },
    {
      "epoch": 902.32,
      "learning_rate": 0.00980299342290322,
      "loss": 0.4888,
      "step": 559440
    },
    {
      "epoch": 902.35,
      "learning_rate": 0.009799767619677416,
      "loss": 0.4954,
      "step": 559460
    },
    {
      "epoch": 902.39,
      "learning_rate": 0.00979654181645161,
      "loss": 0.4973,
      "step": 559480
    },
    {
      "epoch": 902.42,
      "learning_rate": 0.009793316013225804,
      "loss": 0.4906,
      "step": 559500
    },
    {
      "epoch": 902.45,
      "learning_rate": 0.009790090209999998,
      "loss": 0.4953,
      "step": 559520
    },
    {
      "epoch": 902.48,
      "learning_rate": 0.009786864406774193,
      "loss": 0.5028,
      "step": 559540
    },
    {
      "epoch": 902.52,
      "learning_rate": 0.009783638603548387,
      "loss": 0.4687,
      "step": 559560
    },
    {
      "epoch": 902.55,
      "learning_rate": 0.009780412800322581,
      "loss": 0.4887,
      "step": 559580
    },
    {
      "epoch": 902.58,
      "learning_rate": 0.009777186997096775,
      "loss": 0.4944,
      "step": 559600
    },
    {
      "epoch": 902.61,
      "learning_rate": 0.009773961193870969,
      "loss": 0.4921,
      "step": 559620
    },
    {
      "epoch": 902.65,
      "learning_rate": 0.009770735390645165,
      "loss": 0.4876,
      "step": 559640
    },
    {
      "epoch": 902.68,
      "learning_rate": 0.009767509587419359,
      "loss": 0.4884,
      "step": 559660
    },
    {
      "epoch": 902.71,
      "learning_rate": 0.009764283784193552,
      "loss": 0.4943,
      "step": 559680
    },
    {
      "epoch": 902.74,
      "learning_rate": 0.009761057980967746,
      "loss": 0.4993,
      "step": 559700
    },
    {
      "epoch": 902.77,
      "learning_rate": 0.00975783217774193,
      "loss": 0.4945,
      "step": 559720
    },
    {
      "epoch": 902.81,
      "learning_rate": 0.009754606374516124,
      "loss": 0.4811,
      "step": 559740
    },
    {
      "epoch": 902.84,
      "learning_rate": 0.009751380571290318,
      "loss": 0.4804,
      "step": 559760
    },
    {
      "epoch": 902.87,
      "learning_rate": 0.009748154768064513,
      "loss": 0.4904,
      "step": 559780
    },
    {
      "epoch": 902.9,
      "learning_rate": 0.009744928964838707,
      "loss": 0.4884,
      "step": 559800
    },
    {
      "epoch": 902.94,
      "learning_rate": 0.009741703161612901,
      "loss": 0.4955,
      "step": 559820
    },
    {
      "epoch": 902.97,
      "learning_rate": 0.009738477358387095,
      "loss": 0.5002,
      "step": 559840
    },
    {
      "epoch": 903.0,
      "learning_rate": 0.00973525155516129,
      "loss": 0.492,
      "step": 559860
    },
    {
      "epoch": 903.0,
      "eval_accuracy": {
        "accuracy": 0.7940051518226524
      },
      "eval_loss": 0.8480960726737976,
      "eval_runtime": 3.1295,
      "eval_samples_per_second": 4093.638,
      "eval_steps_per_second": 64.228,
      "step": 559860
    },
    {
      "epoch": 903.03,
      "learning_rate": 0.009732025751935484,
      "loss": 0.483,
      "step": 559880
    },
    {
      "epoch": 903.06,
      "learning_rate": 0.009728799948709678,
      "loss": 0.4907,
      "step": 559900
    },
    {
      "epoch": 903.1,
      "learning_rate": 0.009725574145483872,
      "loss": 0.4896,
      "step": 559920
    },
    {
      "epoch": 903.13,
      "learning_rate": 0.009722348342258066,
      "loss": 0.485,
      "step": 559940
    },
    {
      "epoch": 903.16,
      "learning_rate": 0.009719122539032262,
      "loss": 0.489,
      "step": 559960
    },
    {
      "epoch": 903.19,
      "learning_rate": 0.009715896735806456,
      "loss": 0.4916,
      "step": 559980
    },
    {
      "epoch": 903.23,
      "learning_rate": 0.00971267093258065,
      "loss": 0.4951,
      "step": 560000
    },
    {
      "epoch": 903.26,
      "learning_rate": 0.009709445129354843,
      "loss": 0.4827,
      "step": 560020
    },
    {
      "epoch": 903.29,
      "learning_rate": 0.009706219326129027,
      "loss": 0.487,
      "step": 560040
    },
    {
      "epoch": 903.32,
      "learning_rate": 0.00970299352290322,
      "loss": 0.4796,
      "step": 560060
    },
    {
      "epoch": 903.35,
      "learning_rate": 0.009699767719677415,
      "loss": 0.4882,
      "step": 560080
    },
    {
      "epoch": 903.39,
      "learning_rate": 0.00969654191645161,
      "loss": 0.4875,
      "step": 560100
    },
    {
      "epoch": 903.42,
      "learning_rate": 0.009693316113225804,
      "loss": 0.4952,
      "step": 560120
    },
    {
      "epoch": 903.45,
      "learning_rate": 0.009690090309999998,
      "loss": 0.4831,
      "step": 560140
    },
    {
      "epoch": 903.48,
      "learning_rate": 0.009686864506774192,
      "loss": 0.489,
      "step": 560160
    },
    {
      "epoch": 903.52,
      "learning_rate": 0.009683638703548388,
      "loss": 0.4927,
      "step": 560180
    },
    {
      "epoch": 903.55,
      "learning_rate": 0.009680412900322581,
      "loss": 0.4923,
      "step": 560200
    },
    {
      "epoch": 903.58,
      "learning_rate": 0.009677187097096775,
      "loss": 0.4829,
      "step": 560220
    },
    {
      "epoch": 903.61,
      "learning_rate": 0.00967396129387097,
      "loss": 0.496,
      "step": 560240
    },
    {
      "epoch": 903.65,
      "learning_rate": 0.009670735490645163,
      "loss": 0.4925,
      "step": 560260
    },
    {
      "epoch": 903.68,
      "learning_rate": 0.009667509687419359,
      "loss": 0.4975,
      "step": 560280
    },
    {
      "epoch": 903.71,
      "learning_rate": 0.009664283884193553,
      "loss": 0.4854,
      "step": 560300
    },
    {
      "epoch": 903.74,
      "learning_rate": 0.009661058080967747,
      "loss": 0.4949,
      "step": 560320
    },
    {
      "epoch": 903.77,
      "learning_rate": 0.00965783227774193,
      "loss": 0.4974,
      "step": 560340
    },
    {
      "epoch": 903.81,
      "learning_rate": 0.009654606474516124,
      "loss": 0.4863,
      "step": 560360
    },
    {
      "epoch": 903.84,
      "learning_rate": 0.009651380671290318,
      "loss": 0.4819,
      "step": 560380
    },
    {
      "epoch": 903.87,
      "learning_rate": 0.009648154868064513,
      "loss": 0.4919,
      "step": 560400
    },
    {
      "epoch": 903.9,
      "learning_rate": 0.009644929064838707,
      "loss": 0.4857,
      "step": 560420
    },
    {
      "epoch": 903.94,
      "learning_rate": 0.009641703261612901,
      "loss": 0.4965,
      "step": 560440
    },
    {
      "epoch": 903.97,
      "learning_rate": 0.009638477458387095,
      "loss": 0.5035,
      "step": 560460
    },
    {
      "epoch": 904.0,
      "learning_rate": 0.009635251655161289,
      "loss": 0.4923,
      "step": 560480
    },
    {
      "epoch": 904.0,
      "eval_accuracy": {
        "accuracy": 0.7940832097416283
      },
      "eval_loss": 0.8484585285186768,
      "eval_runtime": 3.1942,
      "eval_samples_per_second": 4010.666,
      "eval_steps_per_second": 62.926,
      "step": 560480
    },
    {
      "epoch": 904.03,
      "learning_rate": 0.009632025851935485,
      "loss": 0.4889,
      "step": 560500
    },
    {
      "epoch": 904.06,
      "learning_rate": 0.009628800048709679,
      "loss": 0.4842,
      "step": 560520
    },
    {
      "epoch": 904.1,
      "learning_rate": 0.009625574245483872,
      "loss": 0.4825,
      "step": 560540
    },
    {
      "epoch": 904.13,
      "learning_rate": 0.009622348442258066,
      "loss": 0.4827,
      "step": 560560
    },
    {
      "epoch": 904.16,
      "learning_rate": 0.00961912263903226,
      "loss": 0.4905,
      "step": 560580
    },
    {
      "epoch": 904.19,
      "learning_rate": 0.009615896835806456,
      "loss": 0.4811,
      "step": 560600
    },
    {
      "epoch": 904.23,
      "learning_rate": 0.00961267103258065,
      "loss": 0.4957,
      "step": 560620
    },
    {
      "epoch": 904.26,
      "learning_rate": 0.009609445229354844,
      "loss": 0.4833,
      "step": 560640
    },
    {
      "epoch": 904.29,
      "learning_rate": 0.009606219426129027,
      "loss": 0.4933,
      "step": 560660
    },
    {
      "epoch": 904.32,
      "learning_rate": 0.009602993622903221,
      "loss": 0.4886,
      "step": 560680
    },
    {
      "epoch": 904.35,
      "learning_rate": 0.009599767819677415,
      "loss": 0.4944,
      "step": 560700
    },
    {
      "epoch": 904.39,
      "learning_rate": 0.00959654201645161,
      "loss": 0.4895,
      "step": 560720
    },
    {
      "epoch": 904.42,
      "learning_rate": 0.009593316213225804,
      "loss": 0.4846,
      "step": 560740
    },
    {
      "epoch": 904.45,
      "learning_rate": 0.009590090409999998,
      "loss": 0.4818,
      "step": 560760
    },
    {
      "epoch": 904.48,
      "learning_rate": 0.009586864606774192,
      "loss": 0.4862,
      "step": 560780
    },
    {
      "epoch": 904.52,
      "learning_rate": 0.009583638803548386,
      "loss": 0.4825,
      "step": 560800
    },
    {
      "epoch": 904.55,
      "learning_rate": 0.009580413000322582,
      "loss": 0.4824,
      "step": 560820
    },
    {
      "epoch": 904.58,
      "learning_rate": 0.009577187197096776,
      "loss": 0.496,
      "step": 560840
    },
    {
      "epoch": 904.61,
      "learning_rate": 0.00957396139387097,
      "loss": 0.4891,
      "step": 560860
    },
    {
      "epoch": 904.65,
      "learning_rate": 0.009570735590645163,
      "loss": 0.4973,
      "step": 560880
    },
    {
      "epoch": 904.68,
      "learning_rate": 0.009567509787419357,
      "loss": 0.4944,
      "step": 560900
    },
    {
      "epoch": 904.71,
      "learning_rate": 0.009564283984193553,
      "loss": 0.4946,
      "step": 560920
    },
    {
      "epoch": 904.74,
      "learning_rate": 0.009561058180967747,
      "loss": 0.5018,
      "step": 560940
    },
    {
      "epoch": 904.77,
      "learning_rate": 0.00955783237774193,
      "loss": 0.4958,
      "step": 560960
    },
    {
      "epoch": 904.81,
      "learning_rate": 0.009554606574516124,
      "loss": 0.4903,
      "step": 560980
    },
    {
      "epoch": 904.84,
      "learning_rate": 0.009551380771290318,
      "loss": 0.4939,
      "step": 561000
    },
    {
      "epoch": 904.87,
      "learning_rate": 0.009548154968064512,
      "loss": 0.4866,
      "step": 561020
    },
    {
      "epoch": 904.9,
      "learning_rate": 0.009544929164838708,
      "loss": 0.4999,
      "step": 561040
    },
    {
      "epoch": 904.94,
      "learning_rate": 0.009541703361612901,
      "loss": 0.5015,
      "step": 561060
    },
    {
      "epoch": 904.97,
      "learning_rate": 0.009538477558387095,
      "loss": 0.4907,
      "step": 561080
    },
    {
      "epoch": 905.0,
      "learning_rate": 0.00953525175516129,
      "loss": 0.4906,
      "step": 561100
    },
    {
      "epoch": 905.0,
      "eval_accuracy": {
        "accuracy": 0.7918195300913278
      },
      "eval_loss": 0.8498409390449524,
      "eval_runtime": 3.6067,
      "eval_samples_per_second": 3551.983,
      "eval_steps_per_second": 55.729,
      "step": 561100
    },
    {
      "epoch": 905.03,
      "learning_rate": 0.009532025951935483,
      "loss": 0.4919,
      "step": 561120
    },
    {
      "epoch": 905.06,
      "learning_rate": 0.009528800148709679,
      "loss": 0.4875,
      "step": 561140
    },
    {
      "epoch": 905.1,
      "learning_rate": 0.009525574345483873,
      "loss": 0.4819,
      "step": 561160
    },
    {
      "epoch": 905.13,
      "learning_rate": 0.009522348542258066,
      "loss": 0.4898,
      "step": 561180
    },
    {
      "epoch": 905.16,
      "learning_rate": 0.00951912273903226,
      "loss": 0.4869,
      "step": 561200
    },
    {
      "epoch": 905.19,
      "learning_rate": 0.009515896935806454,
      "loss": 0.4867,
      "step": 561220
    },
    {
      "epoch": 905.23,
      "learning_rate": 0.00951267113258065,
      "loss": 0.4811,
      "step": 561240
    },
    {
      "epoch": 905.26,
      "learning_rate": 0.009509445329354844,
      "loss": 0.4833,
      "step": 561260
    },
    {
      "epoch": 905.29,
      "learning_rate": 0.009506219526129027,
      "loss": 0.4937,
      "step": 561280
    },
    {
      "epoch": 905.32,
      "learning_rate": 0.009502993722903221,
      "loss": 0.4831,
      "step": 561300
    },
    {
      "epoch": 905.35,
      "learning_rate": 0.009499767919677415,
      "loss": 0.483,
      "step": 561320
    },
    {
      "epoch": 905.39,
      "learning_rate": 0.009496542116451609,
      "loss": 0.4863,
      "step": 561340
    },
    {
      "epoch": 905.42,
      "learning_rate": 0.009493316313225805,
      "loss": 0.4916,
      "step": 561360
    },
    {
      "epoch": 905.45,
      "learning_rate": 0.009490090509999998,
      "loss": 0.4883,
      "step": 561380
    },
    {
      "epoch": 905.48,
      "learning_rate": 0.009487025996935489,
      "loss": 0.4924,
      "step": 561400
    },
    {
      "epoch": 905.52,
      "learning_rate": 0.009483800193709672,
      "loss": 0.4889,
      "step": 561420
    },
    {
      "epoch": 905.55,
      "learning_rate": 0.009480574390483866,
      "loss": 0.4901,
      "step": 561440
    },
    {
      "epoch": 905.58,
      "learning_rate": 0.00947734858725806,
      "loss": 0.4908,
      "step": 561460
    },
    {
      "epoch": 905.61,
      "learning_rate": 0.009474122784032256,
      "loss": 0.4931,
      "step": 561480
    },
    {
      "epoch": 905.65,
      "learning_rate": 0.00947089698080645,
      "loss": 0.4875,
      "step": 561500
    },
    {
      "epoch": 905.68,
      "learning_rate": 0.009467671177580643,
      "loss": 0.4997,
      "step": 561520
    },
    {
      "epoch": 905.71,
      "learning_rate": 0.009464445374354837,
      "loss": 0.4899,
      "step": 561540
    },
    {
      "epoch": 905.74,
      "learning_rate": 0.009461219571129031,
      "loss": 0.4821,
      "step": 561560
    },
    {
      "epoch": 905.77,
      "learning_rate": 0.009457993767903227,
      "loss": 0.4955,
      "step": 561580
    },
    {
      "epoch": 905.81,
      "learning_rate": 0.00945476796467742,
      "loss": 0.4928,
      "step": 561600
    },
    {
      "epoch": 905.84,
      "learning_rate": 0.009451542161451615,
      "loss": 0.4919,
      "step": 561620
    },
    {
      "epoch": 905.87,
      "learning_rate": 0.009448316358225808,
      "loss": 0.4923,
      "step": 561640
    },
    {
      "epoch": 905.9,
      "learning_rate": 0.009445090555000002,
      "loss": 0.4923,
      "step": 561660
    },
    {
      "epoch": 905.94,
      "learning_rate": 0.009441864751774198,
      "loss": 0.4868,
      "step": 561680
    },
    {
      "epoch": 905.97,
      "learning_rate": 0.009438638948548392,
      "loss": 0.4955,
      "step": 561700
    },
    {
      "epoch": 906.0,
      "learning_rate": 0.009435574435483872,
      "loss": 0.491,
      "step": 561720
    },
    {
      "epoch": 906.0,
      "eval_accuracy": {
        "accuracy": 0.7908828350636172
      },
      "eval_loss": 0.845143735408783,
      "eval_runtime": 3.432,
      "eval_samples_per_second": 3732.809,
      "eval_steps_per_second": 58.566,
      "step": 561720
    },
    {
      "epoch": 906.03,
      "learning_rate": 0.009432348632258065,
      "loss": 0.4907,
      "step": 561740
    },
    {
      "epoch": 906.06,
      "learning_rate": 0.00942912282903226,
      "loss": 0.4981,
      "step": 561760
    },
    {
      "epoch": 906.1,
      "learning_rate": 0.009425897025806453,
      "loss": 0.4743,
      "step": 561780
    },
    {
      "epoch": 906.13,
      "learning_rate": 0.009422671222580649,
      "loss": 0.4829,
      "step": 561800
    },
    {
      "epoch": 906.16,
      "learning_rate": 0.009419445419354843,
      "loss": 0.4881,
      "step": 561820
    },
    {
      "epoch": 906.19,
      "learning_rate": 0.009416219616129037,
      "loss": 0.4842,
      "step": 561840
    },
    {
      "epoch": 906.23,
      "learning_rate": 0.00941299381290323,
      "loss": 0.5001,
      "step": 561860
    },
    {
      "epoch": 906.26,
      "learning_rate": 0.009409768009677414,
      "loss": 0.4918,
      "step": 561880
    },
    {
      "epoch": 906.29,
      "learning_rate": 0.009406542206451608,
      "loss": 0.4892,
      "step": 561900
    },
    {
      "epoch": 906.32,
      "learning_rate": 0.009403316403225802,
      "loss": 0.4823,
      "step": 561920
    },
    {
      "epoch": 906.35,
      "learning_rate": 0.009400090599999997,
      "loss": 0.4884,
      "step": 561940
    },
    {
      "epoch": 906.39,
      "learning_rate": 0.009396864796774191,
      "loss": 0.4841,
      "step": 561960
    },
    {
      "epoch": 906.42,
      "learning_rate": 0.009393638993548385,
      "loss": 0.4924,
      "step": 561980
    },
    {
      "epoch": 906.45,
      "learning_rate": 0.009390413190322579,
      "loss": 0.4856,
      "step": 562000
    },
    {
      "epoch": 906.48,
      "learning_rate": 0.009387187387096775,
      "loss": 0.4952,
      "step": 562020
    },
    {
      "epoch": 906.52,
      "learning_rate": 0.009383961583870969,
      "loss": 0.4878,
      "step": 562040
    },
    {
      "epoch": 906.55,
      "learning_rate": 0.009380735780645163,
      "loss": 0.4936,
      "step": 562060
    },
    {
      "epoch": 906.58,
      "learning_rate": 0.009377509977419356,
      "loss": 0.4779,
      "step": 562080
    },
    {
      "epoch": 906.61,
      "learning_rate": 0.00937428417419355,
      "loss": 0.4912,
      "step": 562100
    },
    {
      "epoch": 906.65,
      "learning_rate": 0.009371058370967746,
      "loss": 0.4872,
      "step": 562120
    },
    {
      "epoch": 906.68,
      "learning_rate": 0.00936783256774194,
      "loss": 0.4891,
      "step": 562140
    },
    {
      "epoch": 906.71,
      "learning_rate": 0.009364606764516134,
      "loss": 0.4843,
      "step": 562160
    },
    {
      "epoch": 906.74,
      "learning_rate": 0.009361380961290317,
      "loss": 0.4952,
      "step": 562180
    },
    {
      "epoch": 906.77,
      "learning_rate": 0.009358155158064511,
      "loss": 0.4841,
      "step": 562200
    },
    {
      "epoch": 906.81,
      "learning_rate": 0.009354929354838705,
      "loss": 0.4843,
      "step": 562220
    },
    {
      "epoch": 906.84,
      "learning_rate": 0.0093517035516129,
      "loss": 0.4833,
      "step": 562240
    },
    {
      "epoch": 906.87,
      "learning_rate": 0.009348477748387094,
      "loss": 0.4905,
      "step": 562260
    },
    {
      "epoch": 906.9,
      "learning_rate": 0.009345251945161288,
      "loss": 0.4987,
      "step": 562280
    },
    {
      "epoch": 906.94,
      "learning_rate": 0.009342026141935482,
      "loss": 0.496,
      "step": 562300
    },
    {
      "epoch": 906.97,
      "learning_rate": 0.009338800338709676,
      "loss": 0.5042,
      "step": 562320
    },
    {
      "epoch": 907.0,
      "learning_rate": 0.009335574535483872,
      "loss": 0.491,
      "step": 562340
    },
    {
      "epoch": 907.0,
      "eval_accuracy": {
        "accuracy": 0.792287877605183
      },
      "eval_loss": 0.8490321636199951,
      "eval_runtime": 3.0766,
      "eval_samples_per_second": 4164.077,
      "eval_steps_per_second": 65.333,
      "step": 562340
    },
    {
      "epoch": 907.03,
      "learning_rate": 0.009332348732258066,
      "loss": 0.489,
      "step": 562360
    },
    {
      "epoch": 907.06,
      "learning_rate": 0.00932912292903226,
      "loss": 0.4852,
      "step": 562380
    },
    {
      "epoch": 907.1,
      "learning_rate": 0.009325897125806453,
      "loss": 0.4872,
      "step": 562400
    },
    {
      "epoch": 907.13,
      "learning_rate": 0.009322671322580647,
      "loss": 0.4838,
      "step": 562420
    },
    {
      "epoch": 907.16,
      "learning_rate": 0.009319445519354843,
      "loss": 0.4863,
      "step": 562440
    },
    {
      "epoch": 907.19,
      "learning_rate": 0.009316219716129037,
      "loss": 0.4757,
      "step": 562460
    },
    {
      "epoch": 907.23,
      "learning_rate": 0.00931299391290323,
      "loss": 0.4862,
      "step": 562480
    },
    {
      "epoch": 907.26,
      "learning_rate": 0.009309768109677414,
      "loss": 0.4858,
      "step": 562500
    },
    {
      "epoch": 907.29,
      "learning_rate": 0.009306542306451608,
      "loss": 0.4965,
      "step": 562520
    },
    {
      "epoch": 907.32,
      "learning_rate": 0.009303316503225802,
      "loss": 0.4853,
      "step": 562540
    },
    {
      "epoch": 907.35,
      "learning_rate": 0.009300090699999998,
      "loss": 0.4849,
      "step": 562560
    },
    {
      "epoch": 907.39,
      "learning_rate": 0.009296864896774192,
      "loss": 0.4906,
      "step": 562580
    },
    {
      "epoch": 907.42,
      "learning_rate": 0.009293639093548385,
      "loss": 0.4902,
      "step": 562600
    },
    {
      "epoch": 907.45,
      "learning_rate": 0.00929041329032258,
      "loss": 0.4833,
      "step": 562620
    },
    {
      "epoch": 907.48,
      "learning_rate": 0.009287187487096773,
      "loss": 0.4834,
      "step": 562640
    },
    {
      "epoch": 907.52,
      "learning_rate": 0.009283961683870969,
      "loss": 0.4935,
      "step": 562660
    },
    {
      "epoch": 907.55,
      "learning_rate": 0.009280735880645163,
      "loss": 0.4958,
      "step": 562680
    },
    {
      "epoch": 907.58,
      "learning_rate": 0.009277510077419357,
      "loss": 0.4904,
      "step": 562700
    },
    {
      "epoch": 907.61,
      "learning_rate": 0.00927428427419355,
      "loss": 0.4837,
      "step": 562720
    },
    {
      "epoch": 907.65,
      "learning_rate": 0.009271058470967744,
      "loss": 0.4946,
      "step": 562740
    },
    {
      "epoch": 907.68,
      "learning_rate": 0.00926783266774194,
      "loss": 0.4823,
      "step": 562760
    },
    {
      "epoch": 907.71,
      "learning_rate": 0.009264606864516134,
      "loss": 0.4985,
      "step": 562780
    },
    {
      "epoch": 907.74,
      "learning_rate": 0.009261381061290317,
      "loss": 0.4895,
      "step": 562800
    },
    {
      "epoch": 907.77,
      "learning_rate": 0.009258155258064511,
      "loss": 0.4904,
      "step": 562820
    },
    {
      "epoch": 907.81,
      "learning_rate": 0.009254929454838705,
      "loss": 0.4939,
      "step": 562840
    },
    {
      "epoch": 907.84,
      "learning_rate": 0.009251703651612899,
      "loss": 0.4929,
      "step": 562860
    },
    {
      "epoch": 907.87,
      "learning_rate": 0.009248477848387095,
      "loss": 0.489,
      "step": 562880
    },
    {
      "epoch": 907.9,
      "learning_rate": 0.009245252045161289,
      "loss": 0.4885,
      "step": 562900
    },
    {
      "epoch": 907.94,
      "learning_rate": 0.009242026241935482,
      "loss": 0.4926,
      "step": 562920
    },
    {
      "epoch": 907.97,
      "learning_rate": 0.009238800438709676,
      "loss": 0.4812,
      "step": 562940
    },
    {
      "epoch": 908.0,
      "learning_rate": 0.00923557463548387,
      "loss": 0.4784,
      "step": 562960
    },
    {
      "epoch": 908.0,
      "eval_accuracy": {
        "accuracy": 0.7948637889313871
      },
      "eval_loss": 0.8448145985603333,
      "eval_runtime": 3.1489,
      "eval_samples_per_second": 4068.341,
      "eval_steps_per_second": 63.831,
      "step": 562960
    },
    {
      "epoch": 908.03,
      "learning_rate": 0.009232348832258066,
      "loss": 0.4915,
      "step": 562980
    },
    {
      "epoch": 908.06,
      "learning_rate": 0.00922912302903226,
      "loss": 0.4921,
      "step": 563000
    },
    {
      "epoch": 908.1,
      "learning_rate": 0.009225897225806454,
      "loss": 0.4858,
      "step": 563020
    },
    {
      "epoch": 908.13,
      "learning_rate": 0.009222671422580648,
      "loss": 0.4711,
      "step": 563040
    },
    {
      "epoch": 908.16,
      "learning_rate": 0.009219445619354841,
      "loss": 0.4899,
      "step": 563060
    },
    {
      "epoch": 908.19,
      "learning_rate": 0.009216219816129037,
      "loss": 0.4953,
      "step": 563080
    },
    {
      "epoch": 908.23,
      "learning_rate": 0.009212994012903231,
      "loss": 0.4949,
      "step": 563100
    },
    {
      "epoch": 908.26,
      "learning_rate": 0.009209768209677414,
      "loss": 0.4856,
      "step": 563120
    },
    {
      "epoch": 908.29,
      "learning_rate": 0.009206542406451608,
      "loss": 0.4821,
      "step": 563140
    },
    {
      "epoch": 908.32,
      "learning_rate": 0.009203316603225802,
      "loss": 0.4866,
      "step": 563160
    },
    {
      "epoch": 908.35,
      "learning_rate": 0.009200090799999996,
      "loss": 0.4904,
      "step": 563180
    },
    {
      "epoch": 908.39,
      "learning_rate": 0.009196864996774192,
      "loss": 0.491,
      "step": 563200
    },
    {
      "epoch": 908.42,
      "learning_rate": 0.009193639193548386,
      "loss": 0.4902,
      "step": 563220
    },
    {
      "epoch": 908.45,
      "learning_rate": 0.00919041339032258,
      "loss": 0.493,
      "step": 563240
    },
    {
      "epoch": 908.48,
      "learning_rate": 0.009187187587096773,
      "loss": 0.5031,
      "step": 563260
    },
    {
      "epoch": 908.52,
      "learning_rate": 0.009183961783870967,
      "loss": 0.4811,
      "step": 563280
    },
    {
      "epoch": 908.55,
      "learning_rate": 0.009180735980645163,
      "loss": 0.4926,
      "step": 563300
    },
    {
      "epoch": 908.58,
      "learning_rate": 0.009177510177419357,
      "loss": 0.4861,
      "step": 563320
    },
    {
      "epoch": 908.61,
      "learning_rate": 0.00917428437419355,
      "loss": 0.4858,
      "step": 563340
    },
    {
      "epoch": 908.65,
      "learning_rate": 0.009171058570967745,
      "loss": 0.4738,
      "step": 563360
    },
    {
      "epoch": 908.68,
      "learning_rate": 0.009167832767741938,
      "loss": 0.4868,
      "step": 563380
    },
    {
      "epoch": 908.71,
      "learning_rate": 0.009164606964516134,
      "loss": 0.4812,
      "step": 563400
    },
    {
      "epoch": 908.74,
      "learning_rate": 0.009161381161290318,
      "loss": 0.4888,
      "step": 563420
    },
    {
      "epoch": 908.77,
      "learning_rate": 0.009158155358064511,
      "loss": 0.4813,
      "step": 563440
    },
    {
      "epoch": 908.81,
      "learning_rate": 0.009154929554838705,
      "loss": 0.4887,
      "step": 563460
    },
    {
      "epoch": 908.84,
      "learning_rate": 0.0091517037516129,
      "loss": 0.4846,
      "step": 563480
    },
    {
      "epoch": 908.87,
      "learning_rate": 0.009148477948387093,
      "loss": 0.4886,
      "step": 563500
    },
    {
      "epoch": 908.9,
      "learning_rate": 0.009145252145161289,
      "loss": 0.4886,
      "step": 563520
    },
    {
      "epoch": 908.94,
      "learning_rate": 0.009142026341935483,
      "loss": 0.4948,
      "step": 563540
    },
    {
      "epoch": 908.97,
      "learning_rate": 0.009138800538709677,
      "loss": 0.4837,
      "step": 563560
    },
    {
      "epoch": 909.0,
      "learning_rate": 0.00913557473548387,
      "loss": 0.4925,
      "step": 563580
    },
    {
      "epoch": 909.0,
      "eval_accuracy": {
        "accuracy": 0.7920537038482554
      },
      "eval_loss": 0.8447454571723938,
      "eval_runtime": 3.1215,
      "eval_samples_per_second": 4104.143,
      "eval_steps_per_second": 64.393,
      "step": 563580
    },
    {
      "epoch": 909.03,
      "learning_rate": 0.009132348932258064,
      "loss": 0.4928,
      "step": 563600
    },
    {
      "epoch": 909.06,
      "learning_rate": 0.00912912312903226,
      "loss": 0.484,
      "step": 563620
    },
    {
      "epoch": 909.1,
      "learning_rate": 0.009125897325806454,
      "loss": 0.4855,
      "step": 563640
    },
    {
      "epoch": 909.13,
      "learning_rate": 0.009122671522580648,
      "loss": 0.4802,
      "step": 563660
    },
    {
      "epoch": 909.16,
      "learning_rate": 0.009119445719354842,
      "loss": 0.4795,
      "step": 563680
    },
    {
      "epoch": 909.19,
      "learning_rate": 0.009116219916129037,
      "loss": 0.4848,
      "step": 563700
    },
    {
      "epoch": 909.23,
      "learning_rate": 0.009112994112903231,
      "loss": 0.4844,
      "step": 563720
    },
    {
      "epoch": 909.26,
      "learning_rate": 0.009109768309677415,
      "loss": 0.491,
      "step": 563740
    },
    {
      "epoch": 909.29,
      "learning_rate": 0.009106542506451609,
      "loss": 0.4874,
      "step": 563760
    },
    {
      "epoch": 909.32,
      "learning_rate": 0.009103316703225802,
      "loss": 0.4875,
      "step": 563780
    },
    {
      "epoch": 909.35,
      "learning_rate": 0.009100090899999996,
      "loss": 0.4812,
      "step": 563800
    },
    {
      "epoch": 909.39,
      "learning_rate": 0.00909686509677419,
      "loss": 0.4907,
      "step": 563820
    },
    {
      "epoch": 909.42,
      "learning_rate": 0.009093639293548386,
      "loss": 0.478,
      "step": 563840
    },
    {
      "epoch": 909.45,
      "learning_rate": 0.00909041349032258,
      "loss": 0.4924,
      "step": 563860
    },
    {
      "epoch": 909.48,
      "learning_rate": 0.009087187687096774,
      "loss": 0.4925,
      "step": 563880
    },
    {
      "epoch": 909.52,
      "learning_rate": 0.009083961883870968,
      "loss": 0.4878,
      "step": 563900
    },
    {
      "epoch": 909.55,
      "learning_rate": 0.009080736080645161,
      "loss": 0.492,
      "step": 563920
    },
    {
      "epoch": 909.58,
      "learning_rate": 0.009077510277419357,
      "loss": 0.4911,
      "step": 563940
    },
    {
      "epoch": 909.61,
      "learning_rate": 0.009074284474193551,
      "loss": 0.4864,
      "step": 563960
    },
    {
      "epoch": 909.65,
      "learning_rate": 0.009071058670967745,
      "loss": 0.4787,
      "step": 563980
    },
    {
      "epoch": 909.68,
      "learning_rate": 0.009067832867741939,
      "loss": 0.4737,
      "step": 564000
    },
    {
      "epoch": 909.71,
      "learning_rate": 0.009064607064516134,
      "loss": 0.4844,
      "step": 564020
    },
    {
      "epoch": 909.74,
      "learning_rate": 0.009061381261290328,
      "loss": 0.485,
      "step": 564040
    },
    {
      "epoch": 909.77,
      "learning_rate": 0.009058155458064512,
      "loss": 0.49,
      "step": 564060
    },
    {
      "epoch": 909.81,
      "learning_rate": 0.009054929654838706,
      "loss": 0.4986,
      "step": 564080
    },
    {
      "epoch": 909.84,
      "learning_rate": 0.0090517038516129,
      "loss": 0.4935,
      "step": 564100
    },
    {
      "epoch": 909.87,
      "learning_rate": 0.009048478048387093,
      "loss": 0.4926,
      "step": 564120
    },
    {
      "epoch": 909.9,
      "learning_rate": 0.009045252245161287,
      "loss": 0.4879,
      "step": 564140
    },
    {
      "epoch": 909.94,
      "learning_rate": 0.009042026441935483,
      "loss": 0.4907,
      "step": 564160
    },
    {
      "epoch": 909.97,
      "learning_rate": 0.009038800638709677,
      "loss": 0.4937,
      "step": 564180
    },
    {
      "epoch": 910.0,
      "learning_rate": 0.009035736125645157,
      "loss": 0.496,
      "step": 564200
    },
    {
      "epoch": 910.0,
      "eval_accuracy": {
        "accuracy": 0.7926781672000625
      },
      "eval_loss": 0.8447610139846802,
      "eval_runtime": 3.2997,
      "eval_samples_per_second": 3882.45,
      "eval_steps_per_second": 60.914,
      "step": 564200
    },
    {
      "epoch": 910.03,
      "learning_rate": 0.00903251032241935,
      "loss": 0.4824,
      "step": 564220
    },
    {
      "epoch": 910.06,
      "learning_rate": 0.009029284519193544,
      "loss": 0.4826,
      "step": 564240
    },
    {
      "epoch": 910.1,
      "learning_rate": 0.009026058715967738,
      "loss": 0.4873,
      "step": 564260
    },
    {
      "epoch": 910.13,
      "learning_rate": 0.009022832912741934,
      "loss": 0.4934,
      "step": 564280
    },
    {
      "epoch": 910.16,
      "learning_rate": 0.009019607109516128,
      "loss": 0.4854,
      "step": 564300
    },
    {
      "epoch": 910.19,
      "learning_rate": 0.009016381306290322,
      "loss": 0.488,
      "step": 564320
    },
    {
      "epoch": 910.23,
      "learning_rate": 0.009013155503064516,
      "loss": 0.4831,
      "step": 564340
    },
    {
      "epoch": 910.26,
      "learning_rate": 0.00900992969983871,
      "loss": 0.4858,
      "step": 564360
    },
    {
      "epoch": 910.29,
      "learning_rate": 0.009006703896612905,
      "loss": 0.4921,
      "step": 564380
    },
    {
      "epoch": 910.32,
      "learning_rate": 0.009003478093387099,
      "loss": 0.482,
      "step": 564400
    },
    {
      "epoch": 910.35,
      "learning_rate": 0.009000252290161293,
      "loss": 0.482,
      "step": 564420
    },
    {
      "epoch": 910.39,
      "learning_rate": 0.008997026486935487,
      "loss": 0.4827,
      "step": 564440
    },
    {
      "epoch": 910.42,
      "learning_rate": 0.00899380068370968,
      "loss": 0.4867,
      "step": 564460
    },
    {
      "epoch": 910.45,
      "learning_rate": 0.008990574880483876,
      "loss": 0.4901,
      "step": 564480
    },
    {
      "epoch": 910.48,
      "learning_rate": 0.00898734907725806,
      "loss": 0.4857,
      "step": 564500
    },
    {
      "epoch": 910.52,
      "learning_rate": 0.008984123274032254,
      "loss": 0.4939,
      "step": 564520
    },
    {
      "epoch": 910.55,
      "learning_rate": 0.008980897470806447,
      "loss": 0.4888,
      "step": 564540
    },
    {
      "epoch": 910.58,
      "learning_rate": 0.008977671667580641,
      "loss": 0.4902,
      "step": 564560
    },
    {
      "epoch": 910.61,
      "learning_rate": 0.008974445864354835,
      "loss": 0.4837,
      "step": 564580
    },
    {
      "epoch": 910.65,
      "learning_rate": 0.008971220061129031,
      "loss": 0.4791,
      "step": 564600
    },
    {
      "epoch": 910.68,
      "learning_rate": 0.008967994257903225,
      "loss": 0.4991,
      "step": 564620
    },
    {
      "epoch": 910.71,
      "learning_rate": 0.008964768454677419,
      "loss": 0.4815,
      "step": 564640
    },
    {
      "epoch": 910.74,
      "learning_rate": 0.008961542651451613,
      "loss": 0.4897,
      "step": 564660
    },
    {
      "epoch": 910.77,
      "learning_rate": 0.008958316848225806,
      "loss": 0.4825,
      "step": 564680
    },
    {
      "epoch": 910.81,
      "learning_rate": 0.008955091045000002,
      "loss": 0.4902,
      "step": 564700
    },
    {
      "epoch": 910.84,
      "learning_rate": 0.008951865241774196,
      "loss": 0.4849,
      "step": 564720
    },
    {
      "epoch": 910.87,
      "learning_rate": 0.00894863943854839,
      "loss": 0.4872,
      "step": 564740
    },
    {
      "epoch": 910.9,
      "learning_rate": 0.008945413635322584,
      "loss": 0.4847,
      "step": 564760
    },
    {
      "epoch": 910.94,
      "learning_rate": 0.00894218783209678,
      "loss": 0.492,
      "step": 564780
    },
    {
      "epoch": 910.97,
      "learning_rate": 0.008938962028870973,
      "loss": 0.4934,
      "step": 564800
    },
    {
      "epoch": 911.0,
      "learning_rate": 0.008935736225645157,
      "loss": 0.4795,
      "step": 564820
    },
    {
      "epoch": 911.0,
      "eval_accuracy": {
        "accuracy": 0.7940832097416283
      },
      "eval_loss": 0.846224844455719,
      "eval_runtime": 3.2769,
      "eval_samples_per_second": 3909.531,
      "eval_steps_per_second": 61.339,
      "step": 564820
    },
    {
      "epoch": 911.03,
      "learning_rate": 0.00893251042241935,
      "loss": 0.4843,
      "step": 564840
    },
    {
      "epoch": 911.06,
      "learning_rate": 0.008929284619193545,
      "loss": 0.4839,
      "step": 564860
    },
    {
      "epoch": 911.1,
      "learning_rate": 0.008926058815967738,
      "loss": 0.4808,
      "step": 564880
    },
    {
      "epoch": 911.13,
      "learning_rate": 0.008922833012741932,
      "loss": 0.4836,
      "step": 564900
    },
    {
      "epoch": 911.16,
      "learning_rate": 0.008919607209516128,
      "loss": 0.4818,
      "step": 564920
    },
    {
      "epoch": 911.19,
      "learning_rate": 0.008916381406290322,
      "loss": 0.4832,
      "step": 564940
    },
    {
      "epoch": 911.23,
      "learning_rate": 0.008913155603064516,
      "loss": 0.4885,
      "step": 564960
    },
    {
      "epoch": 911.26,
      "learning_rate": 0.00890992979983871,
      "loss": 0.4847,
      "step": 564980
    },
    {
      "epoch": 911.29,
      "learning_rate": 0.008906703996612904,
      "loss": 0.479,
      "step": 565000
    },
    {
      "epoch": 911.32,
      "learning_rate": 0.008903478193387099,
      "loss": 0.4801,
      "step": 565020
    },
    {
      "epoch": 911.35,
      "learning_rate": 0.008900252390161293,
      "loss": 0.4865,
      "step": 565040
    },
    {
      "epoch": 911.39,
      "learning_rate": 0.008897026586935487,
      "loss": 0.4921,
      "step": 565060
    },
    {
      "epoch": 911.42,
      "learning_rate": 0.00889380078370968,
      "loss": 0.4868,
      "step": 565080
    },
    {
      "epoch": 911.45,
      "learning_rate": 0.008890574980483876,
      "loss": 0.4828,
      "step": 565100
    },
    {
      "epoch": 911.48,
      "learning_rate": 0.008887349177258058,
      "loss": 0.4806,
      "step": 565120
    },
    {
      "epoch": 911.52,
      "learning_rate": 0.008884123374032254,
      "loss": 0.4884,
      "step": 565140
    },
    {
      "epoch": 911.55,
      "learning_rate": 0.008880897570806448,
      "loss": 0.4908,
      "step": 565160
    },
    {
      "epoch": 911.58,
      "learning_rate": 0.008877671767580642,
      "loss": 0.4887,
      "step": 565180
    },
    {
      "epoch": 911.61,
      "learning_rate": 0.008874445964354835,
      "loss": 0.4842,
      "step": 565200
    },
    {
      "epoch": 911.65,
      "learning_rate": 0.00887122016112903,
      "loss": 0.4898,
      "step": 565220
    },
    {
      "epoch": 911.68,
      "learning_rate": 0.008867994357903225,
      "loss": 0.484,
      "step": 565240
    },
    {
      "epoch": 911.71,
      "learning_rate": 0.008864768554677419,
      "loss": 0.4844,
      "step": 565260
    },
    {
      "epoch": 911.74,
      "learning_rate": 0.008861542751451613,
      "loss": 0.4882,
      "step": 565280
    },
    {
      "epoch": 911.77,
      "learning_rate": 0.008858316948225807,
      "loss": 0.4997,
      "step": 565300
    },
    {
      "epoch": 911.81,
      "learning_rate": 0.008855091145,
      "loss": 0.4856,
      "step": 565320
    },
    {
      "epoch": 911.84,
      "learning_rate": 0.008851865341774196,
      "loss": 0.4836,
      "step": 565340
    },
    {
      "epoch": 911.87,
      "learning_rate": 0.00884863953854839,
      "loss": 0.4841,
      "step": 565360
    },
    {
      "epoch": 911.9,
      "learning_rate": 0.008845413735322584,
      "loss": 0.4862,
      "step": 565380
    },
    {
      "epoch": 911.94,
      "learning_rate": 0.008842187932096778,
      "loss": 0.4963,
      "step": 565400
    },
    {
      "epoch": 911.97,
      "learning_rate": 0.008838962128870973,
      "loss": 0.493,
      "step": 565420
    },
    {
      "epoch": 912.0,
      "learning_rate": 0.008835736325645155,
      "loss": 0.4869,
      "step": 565440
    },
    {
      "epoch": 912.0,
      "eval_accuracy": {
        "accuracy": 0.7918195300913278
      },
      "eval_loss": 0.849344789981842,
      "eval_runtime": 3.0703,
      "eval_samples_per_second": 4172.493,
      "eval_steps_per_second": 65.465,
      "step": 565440
    },
    {
      "epoch": 912.03,
      "learning_rate": 0.00883251052241935,
      "loss": 0.4871,
      "step": 565460
    },
    {
      "epoch": 912.06,
      "learning_rate": 0.008829284719193545,
      "loss": 0.4794,
      "step": 565480
    },
    {
      "epoch": 912.1,
      "learning_rate": 0.008826058915967739,
      "loss": 0.4777,
      "step": 565500
    },
    {
      "epoch": 912.13,
      "learning_rate": 0.008822833112741933,
      "loss": 0.4738,
      "step": 565520
    },
    {
      "epoch": 912.16,
      "learning_rate": 0.008819607309516126,
      "loss": 0.4842,
      "step": 565540
    },
    {
      "epoch": 912.19,
      "learning_rate": 0.008816381506290322,
      "loss": 0.4782,
      "step": 565560
    },
    {
      "epoch": 912.23,
      "learning_rate": 0.008813155703064516,
      "loss": 0.4856,
      "step": 565580
    },
    {
      "epoch": 912.26,
      "learning_rate": 0.00880992989983871,
      "loss": 0.4901,
      "step": 565600
    },
    {
      "epoch": 912.29,
      "learning_rate": 0.008806704096612904,
      "loss": 0.4775,
      "step": 565620
    },
    {
      "epoch": 912.32,
      "learning_rate": 0.0088034782933871,
      "loss": 0.4865,
      "step": 565640
    },
    {
      "epoch": 912.35,
      "learning_rate": 0.008800252490161293,
      "loss": 0.4918,
      "step": 565660
    },
    {
      "epoch": 912.39,
      "learning_rate": 0.008797026686935487,
      "loss": 0.4982,
      "step": 565680
    },
    {
      "epoch": 912.42,
      "learning_rate": 0.008793800883709681,
      "loss": 0.4884,
      "step": 565700
    },
    {
      "epoch": 912.45,
      "learning_rate": 0.008790575080483875,
      "loss": 0.4881,
      "step": 565720
    },
    {
      "epoch": 912.48,
      "learning_rate": 0.008787349277258058,
      "loss": 0.4821,
      "step": 565740
    },
    {
      "epoch": 912.52,
      "learning_rate": 0.008784123474032252,
      "loss": 0.4845,
      "step": 565760
    },
    {
      "epoch": 912.55,
      "learning_rate": 0.008780897670806448,
      "loss": 0.4891,
      "step": 565780
    },
    {
      "epoch": 912.58,
      "learning_rate": 0.008777671867580642,
      "loss": 0.4838,
      "step": 565800
    },
    {
      "epoch": 912.61,
      "learning_rate": 0.008774446064354836,
      "loss": 0.4926,
      "step": 565820
    },
    {
      "epoch": 912.65,
      "learning_rate": 0.00877122026112903,
      "loss": 0.4901,
      "step": 565840
    },
    {
      "epoch": 912.68,
      "learning_rate": 0.008767994457903223,
      "loss": 0.4881,
      "step": 565860
    },
    {
      "epoch": 912.71,
      "learning_rate": 0.008764768654677419,
      "loss": 0.4835,
      "step": 565880
    },
    {
      "epoch": 912.74,
      "learning_rate": 0.008761542851451613,
      "loss": 0.4833,
      "step": 565900
    },
    {
      "epoch": 912.77,
      "learning_rate": 0.008758317048225807,
      "loss": 0.4872,
      "step": 565920
    },
    {
      "epoch": 912.81,
      "learning_rate": 0.008755091245,
      "loss": 0.49,
      "step": 565940
    },
    {
      "epoch": 912.84,
      "learning_rate": 0.008751865441774196,
      "loss": 0.4972,
      "step": 565960
    },
    {
      "epoch": 912.87,
      "learning_rate": 0.00874863963854839,
      "loss": 0.4776,
      "step": 565980
    },
    {
      "epoch": 912.9,
      "learning_rate": 0.008745413835322584,
      "loss": 0.489,
      "step": 566000
    },
    {
      "epoch": 912.94,
      "learning_rate": 0.008742188032096778,
      "loss": 0.4855,
      "step": 566020
    },
    {
      "epoch": 912.97,
      "learning_rate": 0.008738962228870972,
      "loss": 0.4992,
      "step": 566040
    },
    {
      "epoch": 913.0,
      "learning_rate": 0.008735736425645155,
      "loss": 0.4937,
      "step": 566060
    },
    {
      "epoch": 913.0,
      "eval_accuracy": {
        "accuracy": 0.7879166341425338
      },
      "eval_loss": 0.857853353023529,
      "eval_runtime": 3.1289,
      "eval_samples_per_second": 4094.418,
      "eval_steps_per_second": 64.24,
      "step": 566060
    },
    {
      "epoch": 913.03,
      "learning_rate": 0.00873251062241935,
      "loss": 0.483,
      "step": 566080
    },
    {
      "epoch": 913.06,
      "learning_rate": 0.008729284819193545,
      "loss": 0.494,
      "step": 566100
    },
    {
      "epoch": 913.1,
      "learning_rate": 0.008726059015967739,
      "loss": 0.4776,
      "step": 566120
    },
    {
      "epoch": 913.13,
      "learning_rate": 0.008722833212741933,
      "loss": 0.482,
      "step": 566140
    },
    {
      "epoch": 913.16,
      "learning_rate": 0.008719607409516127,
      "loss": 0.48,
      "step": 566160
    },
    {
      "epoch": 913.19,
      "learning_rate": 0.00871638160629032,
      "loss": 0.4837,
      "step": 566180
    },
    {
      "epoch": 913.23,
      "learning_rate": 0.008713155803064516,
      "loss": 0.482,
      "step": 566200
    },
    {
      "epoch": 913.26,
      "learning_rate": 0.00870992999983871,
      "loss": 0.4947,
      "step": 566220
    },
    {
      "epoch": 913.29,
      "learning_rate": 0.008706704196612904,
      "loss": 0.4739,
      "step": 566240
    },
    {
      "epoch": 913.32,
      "learning_rate": 0.008703478393387098,
      "loss": 0.4805,
      "step": 566260
    },
    {
      "epoch": 913.35,
      "learning_rate": 0.008700252590161293,
      "loss": 0.4925,
      "step": 566280
    },
    {
      "epoch": 913.39,
      "learning_rate": 0.008697026786935487,
      "loss": 0.4878,
      "step": 566300
    },
    {
      "epoch": 913.42,
      "learning_rate": 0.008693800983709681,
      "loss": 0.4873,
      "step": 566320
    },
    {
      "epoch": 913.45,
      "learning_rate": 0.008690575180483875,
      "loss": 0.4809,
      "step": 566340
    },
    {
      "epoch": 913.48,
      "learning_rate": 0.008687349377258069,
      "loss": 0.4827,
      "step": 566360
    },
    {
      "epoch": 913.52,
      "learning_rate": 0.008684123574032252,
      "loss": 0.4855,
      "step": 566380
    },
    {
      "epoch": 913.55,
      "learning_rate": 0.008680897770806446,
      "loss": 0.4883,
      "step": 566400
    },
    {
      "epoch": 913.58,
      "learning_rate": 0.008677671967580642,
      "loss": 0.4811,
      "step": 566420
    },
    {
      "epoch": 913.61,
      "learning_rate": 0.008674446164354836,
      "loss": 0.4964,
      "step": 566440
    },
    {
      "epoch": 913.65,
      "learning_rate": 0.00867122036112903,
      "loss": 0.4918,
      "step": 566460
    },
    {
      "epoch": 913.68,
      "learning_rate": 0.008667994557903224,
      "loss": 0.4868,
      "step": 566480
    },
    {
      "epoch": 913.71,
      "learning_rate": 0.00866476875467742,
      "loss": 0.482,
      "step": 566500
    },
    {
      "epoch": 913.74,
      "learning_rate": 0.008661542951451613,
      "loss": 0.4748,
      "step": 566520
    },
    {
      "epoch": 913.77,
      "learning_rate": 0.008658317148225807,
      "loss": 0.491,
      "step": 566540
    },
    {
      "epoch": 913.81,
      "learning_rate": 0.008655091345000001,
      "loss": 0.4814,
      "step": 566560
    },
    {
      "epoch": 913.84,
      "learning_rate": 0.008651865541774195,
      "loss": 0.4879,
      "step": 566580
    },
    {
      "epoch": 913.87,
      "learning_rate": 0.00864863973854839,
      "loss": 0.4904,
      "step": 566600
    },
    {
      "epoch": 913.9,
      "learning_rate": 0.008645413935322584,
      "loss": 0.4744,
      "step": 566620
    },
    {
      "epoch": 913.94,
      "learning_rate": 0.008642188132096778,
      "loss": 0.4927,
      "step": 566640
    },
    {
      "epoch": 913.97,
      "learning_rate": 0.008638962328870972,
      "loss": 0.4888,
      "step": 566660
    },
    {
      "epoch": 914.0,
      "learning_rate": 0.008635736525645156,
      "loss": 0.4865,
      "step": 566680
    },
    {
      "epoch": 914.0,
      "eval_accuracy": {
        "accuracy": 0.7928342830380142
      },
      "eval_loss": 0.8471723794937134,
      "eval_runtime": 3.1359,
      "eval_samples_per_second": 4085.274,
      "eval_steps_per_second": 64.096,
      "step": 566680
    },
    {
      "epoch": 914.03,
      "learning_rate": 0.00863251072241935,
      "loss": 0.4832,
      "step": 566700
    },
    {
      "epoch": 914.06,
      "learning_rate": 0.008629284919193543,
      "loss": 0.4798,
      "step": 566720
    },
    {
      "epoch": 914.1,
      "learning_rate": 0.008626059115967739,
      "loss": 0.4858,
      "step": 566740
    },
    {
      "epoch": 914.13,
      "learning_rate": 0.008622833312741933,
      "loss": 0.472,
      "step": 566760
    },
    {
      "epoch": 914.16,
      "learning_rate": 0.008619607509516127,
      "loss": 0.4815,
      "step": 566780
    },
    {
      "epoch": 914.19,
      "learning_rate": 0.00861638170629032,
      "loss": 0.4886,
      "step": 566800
    },
    {
      "epoch": 914.23,
      "learning_rate": 0.008613155903064516,
      "loss": 0.4903,
      "step": 566820
    },
    {
      "epoch": 914.26,
      "learning_rate": 0.00860993009983871,
      "loss": 0.4815,
      "step": 566840
    },
    {
      "epoch": 914.29,
      "learning_rate": 0.008606704296612904,
      "loss": 0.481,
      "step": 566860
    },
    {
      "epoch": 914.32,
      "learning_rate": 0.008603478493387098,
      "loss": 0.493,
      "step": 566880
    },
    {
      "epoch": 914.35,
      "learning_rate": 0.008600252690161292,
      "loss": 0.4935,
      "step": 566900
    },
    {
      "epoch": 914.39,
      "learning_rate": 0.008597026886935488,
      "loss": 0.4871,
      "step": 566920
    },
    {
      "epoch": 914.42,
      "learning_rate": 0.008593801083709681,
      "loss": 0.4888,
      "step": 566940
    },
    {
      "epoch": 914.45,
      "learning_rate": 0.008590575280483875,
      "loss": 0.4775,
      "step": 566960
    },
    {
      "epoch": 914.48,
      "learning_rate": 0.00858734947725807,
      "loss": 0.4803,
      "step": 566980
    },
    {
      "epoch": 914.52,
      "learning_rate": 0.008584123674032253,
      "loss": 0.4869,
      "step": 567000
    },
    {
      "epoch": 914.55,
      "learning_rate": 0.008580897870806447,
      "loss": 0.4803,
      "step": 567020
    },
    {
      "epoch": 914.58,
      "learning_rate": 0.00857767206758064,
      "loss": 0.4844,
      "step": 567040
    },
    {
      "epoch": 914.61,
      "learning_rate": 0.008574446264354836,
      "loss": 0.4832,
      "step": 567060
    },
    {
      "epoch": 914.65,
      "learning_rate": 0.00857122046112903,
      "loss": 0.4857,
      "step": 567080
    },
    {
      "epoch": 914.68,
      "learning_rate": 0.008567994657903224,
      "loss": 0.4941,
      "step": 567100
    },
    {
      "epoch": 914.71,
      "learning_rate": 0.008564768854677418,
      "loss": 0.4846,
      "step": 567120
    },
    {
      "epoch": 914.74,
      "learning_rate": 0.008561543051451613,
      "loss": 0.479,
      "step": 567140
    },
    {
      "epoch": 914.77,
      "learning_rate": 0.008558317248225807,
      "loss": 0.4875,
      "step": 567160
    },
    {
      "epoch": 914.81,
      "learning_rate": 0.008555091445000001,
      "loss": 0.4863,
      "step": 567180
    },
    {
      "epoch": 914.84,
      "learning_rate": 0.008551865641774195,
      "loss": 0.4787,
      "step": 567200
    },
    {
      "epoch": 914.87,
      "learning_rate": 0.008548639838548389,
      "loss": 0.4862,
      "step": 567220
    },
    {
      "epoch": 914.9,
      "learning_rate": 0.008545414035322585,
      "loss": 0.4871,
      "step": 567240
    },
    {
      "epoch": 914.94,
      "learning_rate": 0.008542188232096778,
      "loss": 0.4865,
      "step": 567260
    },
    {
      "epoch": 914.97,
      "learning_rate": 0.008538962428870972,
      "loss": 0.4897,
      "step": 567280
    },
    {
      "epoch": 915.0,
      "learning_rate": 0.008535897915806452,
      "loss": 0.482,
      "step": 567300
    },
    {
      "epoch": 915.0,
      "eval_accuracy": {
        "accuracy": 0.7938490359847007
      },
      "eval_loss": 0.8475374579429626,
      "eval_runtime": 3.1936,
      "eval_samples_per_second": 4011.408,
      "eval_steps_per_second": 62.938,
      "step": 567300
    },
    {
      "epoch": 915.03,
      "learning_rate": 0.008532672112580646,
      "loss": 0.4776,
      "step": 567320
    },
    {
      "epoch": 915.06,
      "learning_rate": 0.00852944630935484,
      "loss": 0.4855,
      "step": 567340
    },
    {
      "epoch": 915.1,
      "learning_rate": 0.008526220506129036,
      "loss": 0.4732,
      "step": 567360
    },
    {
      "epoch": 915.13,
      "learning_rate": 0.00852299470290323,
      "loss": 0.4787,
      "step": 567380
    },
    {
      "epoch": 915.16,
      "learning_rate": 0.008519768899677423,
      "loss": 0.4861,
      "step": 567400
    },
    {
      "epoch": 915.19,
      "learning_rate": 0.008516543096451617,
      "loss": 0.4839,
      "step": 567420
    },
    {
      "epoch": 915.23,
      "learning_rate": 0.0085133172932258,
      "loss": 0.485,
      "step": 567440
    },
    {
      "epoch": 915.26,
      "learning_rate": 0.008510091489999995,
      "loss": 0.481,
      "step": 567460
    },
    {
      "epoch": 915.29,
      "learning_rate": 0.008506865686774188,
      "loss": 0.4774,
      "step": 567480
    },
    {
      "epoch": 915.32,
      "learning_rate": 0.008503639883548384,
      "loss": 0.4741,
      "step": 567500
    },
    {
      "epoch": 915.35,
      "learning_rate": 0.008500414080322578,
      "loss": 0.4871,
      "step": 567520
    },
    {
      "epoch": 915.39,
      "learning_rate": 0.008497188277096772,
      "loss": 0.4842,
      "step": 567540
    },
    {
      "epoch": 915.42,
      "learning_rate": 0.008493962473870966,
      "loss": 0.4851,
      "step": 567560
    },
    {
      "epoch": 915.45,
      "learning_rate": 0.008490736670645161,
      "loss": 0.4859,
      "step": 567580
    },
    {
      "epoch": 915.48,
      "learning_rate": 0.008487510867419355,
      "loss": 0.4878,
      "step": 567600
    },
    {
      "epoch": 915.52,
      "learning_rate": 0.00848428506419355,
      "loss": 0.4815,
      "step": 567620
    },
    {
      "epoch": 915.55,
      "learning_rate": 0.008481059260967743,
      "loss": 0.4727,
      "step": 567640
    },
    {
      "epoch": 915.58,
      "learning_rate": 0.008477833457741937,
      "loss": 0.4938,
      "step": 567660
    },
    {
      "epoch": 915.61,
      "learning_rate": 0.008474607654516133,
      "loss": 0.4793,
      "step": 567680
    },
    {
      "epoch": 915.65,
      "learning_rate": 0.008471381851290326,
      "loss": 0.475,
      "step": 567700
    },
    {
      "epoch": 915.68,
      "learning_rate": 0.00846815604806452,
      "loss": 0.4881,
      "step": 567720
    },
    {
      "epoch": 915.71,
      "learning_rate": 0.008464930244838714,
      "loss": 0.4766,
      "step": 567740
    },
    {
      "epoch": 915.74,
      "learning_rate": 0.008461704441612898,
      "loss": 0.4797,
      "step": 567760
    },
    {
      "epoch": 915.77,
      "learning_rate": 0.008458478638387092,
      "loss": 0.4976,
      "step": 567780
    },
    {
      "epoch": 915.81,
      "learning_rate": 0.008455252835161286,
      "loss": 0.4889,
      "step": 567800
    },
    {
      "epoch": 915.84,
      "learning_rate": 0.008452027031935481,
      "loss": 0.4875,
      "step": 567820
    },
    {
      "epoch": 915.87,
      "learning_rate": 0.008448801228709675,
      "loss": 0.4871,
      "step": 567840
    },
    {
      "epoch": 915.9,
      "learning_rate": 0.008445575425483869,
      "loss": 0.4891,
      "step": 567860
    },
    {
      "epoch": 915.94,
      "learning_rate": 0.008442349622258063,
      "loss": 0.4949,
      "step": 567880
    },
    {
      "epoch": 915.97,
      "learning_rate": 0.008439123819032258,
      "loss": 0.4863,
      "step": 567900
    },
    {
      "epoch": 916.0,
      "learning_rate": 0.008435898015806452,
      "loss": 0.4867,
      "step": 567920
    },
    {
      "epoch": 916.0,
      "eval_accuracy": {
        "accuracy": 0.7944734993365077
      },
      "eval_loss": 0.8479186296463013,
      "eval_runtime": 3.1468,
      "eval_samples_per_second": 4071.075,
      "eval_steps_per_second": 63.874,
      "step": 567920
    },
    {
      "epoch": 916.03,
      "learning_rate": 0.008432672212580646,
      "loss": 0.4862,
      "step": 567940
    },
    {
      "epoch": 916.06,
      "learning_rate": 0.00842944640935484,
      "loss": 0.4913,
      "step": 567960
    },
    {
      "epoch": 916.1,
      "learning_rate": 0.008426220606129034,
      "loss": 0.4885,
      "step": 567980
    },
    {
      "epoch": 916.13,
      "learning_rate": 0.00842299480290323,
      "loss": 0.4787,
      "step": 568000
    },
    {
      "epoch": 916.16,
      "learning_rate": 0.008419768999677424,
      "loss": 0.4879,
      "step": 568020
    },
    {
      "epoch": 916.19,
      "learning_rate": 0.008416543196451617,
      "loss": 0.4805,
      "step": 568040
    },
    {
      "epoch": 916.23,
      "learning_rate": 0.008413317393225801,
      "loss": 0.4887,
      "step": 568060
    },
    {
      "epoch": 916.26,
      "learning_rate": 0.008410091589999995,
      "loss": 0.4834,
      "step": 568080
    },
    {
      "epoch": 916.29,
      "learning_rate": 0.008406865786774189,
      "loss": 0.4955,
      "step": 568100
    },
    {
      "epoch": 916.32,
      "learning_rate": 0.008403639983548383,
      "loss": 0.4809,
      "step": 568120
    },
    {
      "epoch": 916.35,
      "learning_rate": 0.008400414180322578,
      "loss": 0.4867,
      "step": 568140
    },
    {
      "epoch": 916.39,
      "learning_rate": 0.008397188377096772,
      "loss": 0.4821,
      "step": 568160
    },
    {
      "epoch": 916.42,
      "learning_rate": 0.008393962573870966,
      "loss": 0.4724,
      "step": 568180
    },
    {
      "epoch": 916.45,
      "learning_rate": 0.00839073677064516,
      "loss": 0.4883,
      "step": 568200
    },
    {
      "epoch": 916.48,
      "learning_rate": 0.008387510967419355,
      "loss": 0.4827,
      "step": 568220
    },
    {
      "epoch": 916.52,
      "learning_rate": 0.00838428516419355,
      "loss": 0.487,
      "step": 568240
    },
    {
      "epoch": 916.55,
      "learning_rate": 0.008381059360967743,
      "loss": 0.4836,
      "step": 568260
    },
    {
      "epoch": 916.58,
      "learning_rate": 0.008377833557741937,
      "loss": 0.4739,
      "step": 568280
    },
    {
      "epoch": 916.61,
      "learning_rate": 0.008374607754516131,
      "loss": 0.4953,
      "step": 568300
    },
    {
      "epoch": 916.65,
      "learning_rate": 0.008371381951290327,
      "loss": 0.4771,
      "step": 568320
    },
    {
      "epoch": 916.68,
      "learning_rate": 0.00836815614806452,
      "loss": 0.4848,
      "step": 568340
    },
    {
      "epoch": 916.71,
      "learning_rate": 0.008364930344838714,
      "loss": 0.4873,
      "step": 568360
    },
    {
      "epoch": 916.74,
      "learning_rate": 0.008361704541612898,
      "loss": 0.4807,
      "step": 568380
    },
    {
      "epoch": 916.77,
      "learning_rate": 0.008358478738387092,
      "loss": 0.4826,
      "step": 568400
    },
    {
      "epoch": 916.81,
      "learning_rate": 0.008355252935161286,
      "loss": 0.4868,
      "step": 568420
    },
    {
      "epoch": 916.84,
      "learning_rate": 0.008352027131935481,
      "loss": 0.482,
      "step": 568440
    },
    {
      "epoch": 916.87,
      "learning_rate": 0.008348801328709675,
      "loss": 0.4776,
      "step": 568460
    },
    {
      "epoch": 916.9,
      "learning_rate": 0.00834557552548387,
      "loss": 0.4854,
      "step": 568480
    },
    {
      "epoch": 916.94,
      "learning_rate": 0.008342349722258063,
      "loss": 0.484,
      "step": 568500
    },
    {
      "epoch": 916.97,
      "learning_rate": 0.008339123919032257,
      "loss": 0.4869,
      "step": 568520
    },
    {
      "epoch": 917.0,
      "learning_rate": 0.008335898115806453,
      "loss": 0.4768,
      "step": 568540
    },
    {
      "epoch": 917.0,
      "eval_accuracy": {
        "accuracy": 0.7945515572554835
      },
      "eval_loss": 0.8449935913085938,
      "eval_runtime": 3.306,
      "eval_samples_per_second": 3875.099,
      "eval_steps_per_second": 60.799,
      "step": 568540
    },
    {
      "epoch": 917.03,
      "learning_rate": 0.008332672312580646,
      "loss": 0.4956,
      "step": 568560
    },
    {
      "epoch": 917.06,
      "learning_rate": 0.00832944650935484,
      "loss": 0.4807,
      "step": 568580
    },
    {
      "epoch": 917.1,
      "learning_rate": 0.008326220706129034,
      "loss": 0.4888,
      "step": 568600
    },
    {
      "epoch": 917.13,
      "learning_rate": 0.008322994902903228,
      "loss": 0.4752,
      "step": 568620
    },
    {
      "epoch": 917.16,
      "learning_rate": 0.008319769099677424,
      "loss": 0.4824,
      "step": 568640
    },
    {
      "epoch": 917.19,
      "learning_rate": 0.008316543296451618,
      "loss": 0.4782,
      "step": 568660
    },
    {
      "epoch": 917.23,
      "learning_rate": 0.008313317493225801,
      "loss": 0.4814,
      "step": 568680
    },
    {
      "epoch": 917.26,
      "learning_rate": 0.008310091689999995,
      "loss": 0.49,
      "step": 568700
    },
    {
      "epoch": 917.29,
      "learning_rate": 0.008306865886774189,
      "loss": 0.4864,
      "step": 568720
    },
    {
      "epoch": 917.32,
      "learning_rate": 0.008303640083548383,
      "loss": 0.483,
      "step": 568740
    },
    {
      "epoch": 917.35,
      "learning_rate": 0.008300414280322578,
      "loss": 0.4901,
      "step": 568760
    },
    {
      "epoch": 917.39,
      "learning_rate": 0.008297188477096772,
      "loss": 0.4766,
      "step": 568780
    },
    {
      "epoch": 917.42,
      "learning_rate": 0.008293962673870966,
      "loss": 0.4866,
      "step": 568800
    },
    {
      "epoch": 917.45,
      "learning_rate": 0.00829073687064516,
      "loss": 0.4859,
      "step": 568820
    },
    {
      "epoch": 917.48,
      "learning_rate": 0.008287511067419354,
      "loss": 0.4788,
      "step": 568840
    },
    {
      "epoch": 917.52,
      "learning_rate": 0.00828428526419355,
      "loss": 0.4877,
      "step": 568860
    },
    {
      "epoch": 917.55,
      "learning_rate": 0.008281059460967743,
      "loss": 0.4879,
      "step": 568880
    },
    {
      "epoch": 917.58,
      "learning_rate": 0.008277833657741937,
      "loss": 0.4881,
      "step": 568900
    },
    {
      "epoch": 917.61,
      "learning_rate": 0.008274607854516131,
      "loss": 0.4854,
      "step": 568920
    },
    {
      "epoch": 917.65,
      "learning_rate": 0.008271382051290325,
      "loss": 0.4755,
      "step": 568940
    },
    {
      "epoch": 917.68,
      "learning_rate": 0.00826815624806452,
      "loss": 0.486,
      "step": 568960
    },
    {
      "epoch": 917.71,
      "learning_rate": 0.008264930444838715,
      "loss": 0.4839,
      "step": 568980
    },
    {
      "epoch": 917.74,
      "learning_rate": 0.008261704641612898,
      "loss": 0.4796,
      "step": 569000
    },
    {
      "epoch": 917.77,
      "learning_rate": 0.008258478838387092,
      "loss": 0.4769,
      "step": 569020
    },
    {
      "epoch": 917.81,
      "learning_rate": 0.008255253035161286,
      "loss": 0.4791,
      "step": 569040
    },
    {
      "epoch": 917.84,
      "learning_rate": 0.00825202723193548,
      "loss": 0.4797,
      "step": 569060
    },
    {
      "epoch": 917.87,
      "learning_rate": 0.008248801428709675,
      "loss": 0.4714,
      "step": 569080
    },
    {
      "epoch": 917.9,
      "learning_rate": 0.00824557562548387,
      "loss": 0.4794,
      "step": 569100
    },
    {
      "epoch": 917.94,
      "learning_rate": 0.008242349822258063,
      "loss": 0.4857,
      "step": 569120
    },
    {
      "epoch": 917.97,
      "learning_rate": 0.008239124019032257,
      "loss": 0.4848,
      "step": 569140
    },
    {
      "epoch": 918.0,
      "learning_rate": 0.008235898215806451,
      "loss": 0.4844,
      "step": 569160
    },
    {
      "epoch": 918.0,
      "eval_accuracy": {
        "accuracy": 0.7936929201467489
      },
      "eval_loss": 0.84186851978302,
      "eval_runtime": 3.823,
      "eval_samples_per_second": 3351.014,
      "eval_steps_per_second": 52.576,
      "step": 569160
    },
    {
      "epoch": 918.03,
      "learning_rate": 0.008232672412580647,
      "loss": 0.4806,
      "step": 569180
    },
    {
      "epoch": 918.06,
      "learning_rate": 0.00822944660935484,
      "loss": 0.4816,
      "step": 569200
    },
    {
      "epoch": 918.1,
      "learning_rate": 0.008226220806129034,
      "loss": 0.4747,
      "step": 569220
    },
    {
      "epoch": 918.13,
      "learning_rate": 0.008222995002903228,
      "loss": 0.4809,
      "step": 569240
    },
    {
      "epoch": 918.16,
      "learning_rate": 0.008219769199677422,
      "loss": 0.4816,
      "step": 569260
    },
    {
      "epoch": 918.19,
      "learning_rate": 0.008216543396451618,
      "loss": 0.4906,
      "step": 569280
    },
    {
      "epoch": 918.23,
      "learning_rate": 0.008213317593225812,
      "loss": 0.482,
      "step": 569300
    },
    {
      "epoch": 918.26,
      "learning_rate": 0.008210091789999995,
      "loss": 0.4854,
      "step": 569320
    },
    {
      "epoch": 918.29,
      "learning_rate": 0.008206865986774189,
      "loss": 0.4867,
      "step": 569340
    },
    {
      "epoch": 918.32,
      "learning_rate": 0.008203640183548383,
      "loss": 0.4793,
      "step": 569360
    },
    {
      "epoch": 918.35,
      "learning_rate": 0.008200414380322577,
      "loss": 0.4947,
      "step": 569380
    },
    {
      "epoch": 918.39,
      "learning_rate": 0.008197188577096772,
      "loss": 0.4748,
      "step": 569400
    },
    {
      "epoch": 918.42,
      "learning_rate": 0.008193962773870966,
      "loss": 0.4857,
      "step": 569420
    },
    {
      "epoch": 918.45,
      "learning_rate": 0.00819073697064516,
      "loss": 0.4794,
      "step": 569440
    },
    {
      "epoch": 918.48,
      "learning_rate": 0.008187511167419354,
      "loss": 0.4761,
      "step": 569460
    },
    {
      "epoch": 918.52,
      "learning_rate": 0.008184285364193548,
      "loss": 0.4736,
      "step": 569480
    },
    {
      "epoch": 918.55,
      "learning_rate": 0.008181059560967744,
      "loss": 0.4749,
      "step": 569500
    },
    {
      "epoch": 918.58,
      "learning_rate": 0.008177833757741938,
      "loss": 0.4861,
      "step": 569520
    },
    {
      "epoch": 918.61,
      "learning_rate": 0.008174607954516131,
      "loss": 0.4825,
      "step": 569540
    },
    {
      "epoch": 918.65,
      "learning_rate": 0.008171382151290325,
      "loss": 0.4881,
      "step": 569560
    },
    {
      "epoch": 918.68,
      "learning_rate": 0.00816815634806452,
      "loss": 0.484,
      "step": 569580
    },
    {
      "epoch": 918.71,
      "learning_rate": 0.008164930544838715,
      "loss": 0.4808,
      "step": 569600
    },
    {
      "epoch": 918.74,
      "learning_rate": 0.008161704741612898,
      "loss": 0.4809,
      "step": 569620
    },
    {
      "epoch": 918.77,
      "learning_rate": 0.008158478938387092,
      "loss": 0.4979,
      "step": 569640
    },
    {
      "epoch": 918.81,
      "learning_rate": 0.008155253135161286,
      "loss": 0.4789,
      "step": 569660
    },
    {
      "epoch": 918.84,
      "learning_rate": 0.00815202733193548,
      "loss": 0.489,
      "step": 569680
    },
    {
      "epoch": 918.87,
      "learning_rate": 0.008148801528709674,
      "loss": 0.4895,
      "step": 569700
    },
    {
      "epoch": 918.9,
      "learning_rate": 0.00814557572548387,
      "loss": 0.483,
      "step": 569720
    },
    {
      "epoch": 918.94,
      "learning_rate": 0.008142349922258063,
      "loss": 0.4793,
      "step": 569740
    },
    {
      "epoch": 918.97,
      "learning_rate": 0.008139124119032257,
      "loss": 0.4827,
      "step": 569760
    },
    {
      "epoch": 919.0,
      "learning_rate": 0.008136059605967737,
      "loss": 0.482,
      "step": 569780
    },
    {
      "epoch": 919.0,
      "eval_accuracy": {
        "accuracy": 0.7934587463898213
      },
      "eval_loss": 0.8433597683906555,
      "eval_runtime": 3.5623,
      "eval_samples_per_second": 3596.225,
      "eval_steps_per_second": 56.423,
      "step": 569780
    },
    {
      "epoch": 919.03,
      "learning_rate": 0.008132833802741931,
      "loss": 0.4688,
      "step": 569800
    },
    {
      "epoch": 919.06,
      "learning_rate": 0.008129607999516125,
      "loss": 0.4792,
      "step": 569820
    },
    {
      "epoch": 919.1,
      "learning_rate": 0.00812638219629032,
      "loss": 0.48,
      "step": 569840
    },
    {
      "epoch": 919.13,
      "learning_rate": 0.008123156393064514,
      "loss": 0.4742,
      "step": 569860
    },
    {
      "epoch": 919.16,
      "learning_rate": 0.008119930589838708,
      "loss": 0.4789,
      "step": 569880
    },
    {
      "epoch": 919.19,
      "learning_rate": 0.008116704786612902,
      "loss": 0.4886,
      "step": 569900
    },
    {
      "epoch": 919.23,
      "learning_rate": 0.008113478983387096,
      "loss": 0.4806,
      "step": 569920
    },
    {
      "epoch": 919.26,
      "learning_rate": 0.008110253180161292,
      "loss": 0.4856,
      "step": 569940
    },
    {
      "epoch": 919.29,
      "learning_rate": 0.008107027376935486,
      "loss": 0.4751,
      "step": 569960
    },
    {
      "epoch": 919.32,
      "learning_rate": 0.00810380157370968,
      "loss": 0.4863,
      "step": 569980
    },
    {
      "epoch": 919.35,
      "learning_rate": 0.008100575770483873,
      "loss": 0.4904,
      "step": 570000
    },
    {
      "epoch": 919.39,
      "learning_rate": 0.008097349967258067,
      "loss": 0.4744,
      "step": 570020
    },
    {
      "epoch": 919.42,
      "learning_rate": 0.008094124164032263,
      "loss": 0.4784,
      "step": 570040
    },
    {
      "epoch": 919.45,
      "learning_rate": 0.008090898360806457,
      "loss": 0.4858,
      "step": 570060
    },
    {
      "epoch": 919.48,
      "learning_rate": 0.00808767255758064,
      "loss": 0.4835,
      "step": 570080
    },
    {
      "epoch": 919.52,
      "learning_rate": 0.008084446754354834,
      "loss": 0.4846,
      "step": 570100
    },
    {
      "epoch": 919.55,
      "learning_rate": 0.008081220951129028,
      "loss": 0.4824,
      "step": 570120
    },
    {
      "epoch": 919.58,
      "learning_rate": 0.008077995147903222,
      "loss": 0.4813,
      "step": 570140
    },
    {
      "epoch": 919.61,
      "learning_rate": 0.008074769344677418,
      "loss": 0.4768,
      "step": 570160
    },
    {
      "epoch": 919.65,
      "learning_rate": 0.008071543541451611,
      "loss": 0.4827,
      "step": 570180
    },
    {
      "epoch": 919.68,
      "learning_rate": 0.008068317738225805,
      "loss": 0.4805,
      "step": 570200
    },
    {
      "epoch": 919.71,
      "learning_rate": 0.008065091935,
      "loss": 0.492,
      "step": 570220
    },
    {
      "epoch": 919.74,
      "learning_rate": 0.008061866131774193,
      "loss": 0.4854,
      "step": 570240
    },
    {
      "epoch": 919.77,
      "learning_rate": 0.008058640328548389,
      "loss": 0.4827,
      "step": 570260
    },
    {
      "epoch": 919.81,
      "learning_rate": 0.008055414525322583,
      "loss": 0.4802,
      "step": 570280
    },
    {
      "epoch": 919.84,
      "learning_rate": 0.008052188722096777,
      "loss": 0.4759,
      "step": 570300
    },
    {
      "epoch": 919.87,
      "learning_rate": 0.00804896291887097,
      "loss": 0.4828,
      "step": 570320
    },
    {
      "epoch": 919.9,
      "learning_rate": 0.008045737115645164,
      "loss": 0.4793,
      "step": 570340
    },
    {
      "epoch": 919.94,
      "learning_rate": 0.00804251131241936,
      "loss": 0.4863,
      "step": 570360
    },
    {
      "epoch": 919.97,
      "learning_rate": 0.008039285509193543,
      "loss": 0.4849,
      "step": 570380
    },
    {
      "epoch": 920.0,
      "learning_rate": 0.008036059705967737,
      "loss": 0.4927,
      "step": 570400
    },
    {
      "epoch": 920.0,
      "eval_accuracy": {
        "accuracy": 0.7904925454687378
      },
      "eval_loss": 0.8418769836425781,
      "eval_runtime": 3.0117,
      "eval_samples_per_second": 4253.788,
      "eval_steps_per_second": 66.74,
      "step": 570400
    },
    {
      "epoch": 920.03,
      "learning_rate": 0.008032833902741931,
      "loss": 0.4858,
      "step": 570420
    },
    {
      "epoch": 920.06,
      "learning_rate": 0.008029608099516125,
      "loss": 0.4862,
      "step": 570440
    },
    {
      "epoch": 920.1,
      "learning_rate": 0.008026382296290319,
      "loss": 0.4749,
      "step": 570460
    },
    {
      "epoch": 920.13,
      "learning_rate": 0.008023156493064515,
      "loss": 0.4776,
      "step": 570480
    },
    {
      "epoch": 920.16,
      "learning_rate": 0.008019930689838708,
      "loss": 0.4722,
      "step": 570500
    },
    {
      "epoch": 920.19,
      "learning_rate": 0.008016704886612902,
      "loss": 0.4782,
      "step": 570520
    },
    {
      "epoch": 920.23,
      "learning_rate": 0.008013479083387096,
      "loss": 0.4847,
      "step": 570540
    },
    {
      "epoch": 920.26,
      "learning_rate": 0.00801025328016129,
      "loss": 0.4891,
      "step": 570560
    },
    {
      "epoch": 920.29,
      "learning_rate": 0.008007027476935486,
      "loss": 0.4775,
      "step": 570580
    },
    {
      "epoch": 920.32,
      "learning_rate": 0.00800380167370968,
      "loss": 0.4851,
      "step": 570600
    },
    {
      "epoch": 920.35,
      "learning_rate": 0.008000575870483874,
      "loss": 0.4721,
      "step": 570620
    },
    {
      "epoch": 920.39,
      "learning_rate": 0.007997350067258067,
      "loss": 0.4783,
      "step": 570640
    },
    {
      "epoch": 920.42,
      "learning_rate": 0.007994124264032263,
      "loss": 0.4848,
      "step": 570660
    },
    {
      "epoch": 920.45,
      "learning_rate": 0.007990898460806457,
      "loss": 0.4791,
      "step": 570680
    },
    {
      "epoch": 920.48,
      "learning_rate": 0.00798767265758064,
      "loss": 0.4849,
      "step": 570700
    },
    {
      "epoch": 920.52,
      "learning_rate": 0.007984446854354834,
      "loss": 0.482,
      "step": 570720
    },
    {
      "epoch": 920.55,
      "learning_rate": 0.007981221051129028,
      "loss": 0.4774,
      "step": 570740
    },
    {
      "epoch": 920.58,
      "learning_rate": 0.007977995247903222,
      "loss": 0.485,
      "step": 570760
    },
    {
      "epoch": 920.61,
      "learning_rate": 0.007974769444677416,
      "loss": 0.4834,
      "step": 570780
    },
    {
      "epoch": 920.65,
      "learning_rate": 0.007971543641451612,
      "loss": 0.4857,
      "step": 570800
    },
    {
      "epoch": 920.68,
      "learning_rate": 0.007968317838225806,
      "loss": 0.4777,
      "step": 570820
    },
    {
      "epoch": 920.71,
      "learning_rate": 0.007965092035,
      "loss": 0.4653,
      "step": 570840
    },
    {
      "epoch": 920.74,
      "learning_rate": 0.007961866231774193,
      "loss": 0.4779,
      "step": 570860
    },
    {
      "epoch": 920.77,
      "learning_rate": 0.007958640428548387,
      "loss": 0.4878,
      "step": 570880
    },
    {
      "epoch": 920.81,
      "learning_rate": 0.007955414625322583,
      "loss": 0.4823,
      "step": 570900
    },
    {
      "epoch": 920.84,
      "learning_rate": 0.007952188822096777,
      "loss": 0.4891,
      "step": 570920
    },
    {
      "epoch": 920.87,
      "learning_rate": 0.00794896301887097,
      "loss": 0.4806,
      "step": 570940
    },
    {
      "epoch": 920.9,
      "learning_rate": 0.007945737215645165,
      "loss": 0.4823,
      "step": 570960
    },
    {
      "epoch": 920.94,
      "learning_rate": 0.00794251141241936,
      "loss": 0.4845,
      "step": 570980
    },
    {
      "epoch": 920.97,
      "learning_rate": 0.007939285609193542,
      "loss": 0.4908,
      "step": 571000
    },
    {
      "epoch": 921.0,
      "learning_rate": 0.007936059805967738,
      "loss": 0.4916,
      "step": 571020
    },
    {
      "epoch": 921.0,
      "eval_accuracy": {
        "accuracy": 0.7921317617672313
      },
      "eval_loss": 0.8440088033676147,
      "eval_runtime": 3.523,
      "eval_samples_per_second": 3636.388,
      "eval_steps_per_second": 57.054,
      "step": 571020
    },
    {
      "epoch": 921.03,
      "learning_rate": 0.007932834002741931,
      "loss": 0.4885,
      "step": 571040
    },
    {
      "epoch": 921.06,
      "learning_rate": 0.007929608199516125,
      "loss": 0.4726,
      "step": 571060
    },
    {
      "epoch": 921.1,
      "learning_rate": 0.00792638239629032,
      "loss": 0.4824,
      "step": 571080
    },
    {
      "epoch": 921.13,
      "learning_rate": 0.007923156593064513,
      "loss": 0.4754,
      "step": 571100
    },
    {
      "epoch": 921.16,
      "learning_rate": 0.007919930789838709,
      "loss": 0.4833,
      "step": 571120
    },
    {
      "epoch": 921.19,
      "learning_rate": 0.007916704986612903,
      "loss": 0.4931,
      "step": 571140
    },
    {
      "epoch": 921.23,
      "learning_rate": 0.007913479183387096,
      "loss": 0.4695,
      "step": 571160
    },
    {
      "epoch": 921.26,
      "learning_rate": 0.00791025338016129,
      "loss": 0.4819,
      "step": 571180
    },
    {
      "epoch": 921.29,
      "learning_rate": 0.007907027576935484,
      "loss": 0.4808,
      "step": 571200
    },
    {
      "epoch": 921.32,
      "learning_rate": 0.00790380177370968,
      "loss": 0.4797,
      "step": 571220
    },
    {
      "epoch": 921.35,
      "learning_rate": 0.007900575970483874,
      "loss": 0.4739,
      "step": 571240
    },
    {
      "epoch": 921.39,
      "learning_rate": 0.007897350167258068,
      "loss": 0.4759,
      "step": 571260
    },
    {
      "epoch": 921.42,
      "learning_rate": 0.007894124364032262,
      "loss": 0.4764,
      "step": 571280
    },
    {
      "epoch": 921.45,
      "learning_rate": 0.007890898560806457,
      "loss": 0.4852,
      "step": 571300
    },
    {
      "epoch": 921.48,
      "learning_rate": 0.007887672757580639,
      "loss": 0.4782,
      "step": 571320
    },
    {
      "epoch": 921.52,
      "learning_rate": 0.007884446954354835,
      "loss": 0.48,
      "step": 571340
    },
    {
      "epoch": 921.55,
      "learning_rate": 0.007881221151129028,
      "loss": 0.4909,
      "step": 571360
    },
    {
      "epoch": 921.58,
      "learning_rate": 0.007877995347903222,
      "loss": 0.4838,
      "step": 571380
    },
    {
      "epoch": 921.61,
      "learning_rate": 0.007874769544677416,
      "loss": 0.4895,
      "step": 571400
    },
    {
      "epoch": 921.65,
      "learning_rate": 0.00787154374145161,
      "loss": 0.4853,
      "step": 571420
    },
    {
      "epoch": 921.68,
      "learning_rate": 0.007868317938225806,
      "loss": 0.4843,
      "step": 571440
    },
    {
      "epoch": 921.71,
      "learning_rate": 0.007865092135,
      "loss": 0.481,
      "step": 571460
    },
    {
      "epoch": 921.74,
      "learning_rate": 0.007861866331774194,
      "loss": 0.4826,
      "step": 571480
    },
    {
      "epoch": 921.77,
      "learning_rate": 0.007858640528548387,
      "loss": 0.4772,
      "step": 571500
    },
    {
      "epoch": 921.81,
      "learning_rate": 0.007855414725322581,
      "loss": 0.4866,
      "step": 571520
    },
    {
      "epoch": 921.84,
      "learning_rate": 0.007852188922096777,
      "loss": 0.4781,
      "step": 571540
    },
    {
      "epoch": 921.87,
      "learning_rate": 0.00784896311887097,
      "loss": 0.4791,
      "step": 571560
    },
    {
      "epoch": 921.9,
      "learning_rate": 0.007845737315645165,
      "loss": 0.4832,
      "step": 571580
    },
    {
      "epoch": 921.94,
      "learning_rate": 0.007842511512419359,
      "loss": 0.4807,
      "step": 571600
    },
    {
      "epoch": 921.97,
      "learning_rate": 0.007839285709193554,
      "loss": 0.4827,
      "step": 571620
    },
    {
      "epoch": 922.0,
      "learning_rate": 0.007836059905967736,
      "loss": 0.4767,
      "step": 571640
    },
    {
      "epoch": 922.0,
      "eval_accuracy": {
        "accuracy": 0.7970494106627117
      },
      "eval_loss": 0.839816153049469,
      "eval_runtime": 3.2214,
      "eval_samples_per_second": 3976.882,
      "eval_steps_per_second": 62.396,
      "step": 571640
    },
    {
      "epoch": 922.03,
      "learning_rate": 0.007832834102741932,
      "loss": 0.4784,
      "step": 571660
    },
    {
      "epoch": 922.06,
      "learning_rate": 0.007829608299516125,
      "loss": 0.471,
      "step": 571680
    },
    {
      "epoch": 922.1,
      "learning_rate": 0.00782638249629032,
      "loss": 0.4765,
      "step": 571700
    },
    {
      "epoch": 922.13,
      "learning_rate": 0.007823156693064513,
      "loss": 0.4877,
      "step": 571720
    },
    {
      "epoch": 922.16,
      "learning_rate": 0.007819930889838707,
      "loss": 0.485,
      "step": 571740
    },
    {
      "epoch": 922.19,
      "learning_rate": 0.007816705086612903,
      "loss": 0.4836,
      "step": 571760
    },
    {
      "epoch": 922.23,
      "learning_rate": 0.007813479283387097,
      "loss": 0.4766,
      "step": 571780
    },
    {
      "epoch": 922.26,
      "learning_rate": 0.007810253480161292,
      "loss": 0.47,
      "step": 571800
    },
    {
      "epoch": 922.29,
      "learning_rate": 0.007807027676935485,
      "loss": 0.4895,
      "step": 571820
    },
    {
      "epoch": 922.32,
      "learning_rate": 0.00780380187370968,
      "loss": 0.4886,
      "step": 571840
    },
    {
      "epoch": 922.35,
      "learning_rate": 0.007800576070483874,
      "loss": 0.4886,
      "step": 571860
    },
    {
      "epoch": 922.39,
      "learning_rate": 0.007797350267258069,
      "loss": 0.4791,
      "step": 571880
    },
    {
      "epoch": 922.42,
      "learning_rate": 0.007794124464032263,
      "loss": 0.4827,
      "step": 571900
    },
    {
      "epoch": 922.45,
      "learning_rate": 0.007790898660806457,
      "loss": 0.4805,
      "step": 571920
    },
    {
      "epoch": 922.48,
      "learning_rate": 0.00778767285758064,
      "loss": 0.4726,
      "step": 571940
    },
    {
      "epoch": 922.52,
      "learning_rate": 0.007784447054354835,
      "loss": 0.4831,
      "step": 571960
    },
    {
      "epoch": 922.55,
      "learning_rate": 0.007781221251129029,
      "loss": 0.4848,
      "step": 571980
    },
    {
      "epoch": 922.58,
      "learning_rate": 0.007777995447903223,
      "loss": 0.4807,
      "step": 572000
    },
    {
      "epoch": 922.61,
      "learning_rate": 0.0077747696446774164,
      "loss": 0.4788,
      "step": 572020
    },
    {
      "epoch": 922.65,
      "learning_rate": 0.007771543841451612,
      "loss": 0.4763,
      "step": 572040
    },
    {
      "epoch": 922.68,
      "learning_rate": 0.007768318038225805,
      "loss": 0.4709,
      "step": 572060
    },
    {
      "epoch": 922.71,
      "learning_rate": 0.007765092235,
      "loss": 0.4754,
      "step": 572080
    },
    {
      "epoch": 922.74,
      "learning_rate": 0.0077618664317741955,
      "loss": 0.4944,
      "step": 572100
    },
    {
      "epoch": 922.77,
      "learning_rate": 0.0077586406285483885,
      "loss": 0.4838,
      "step": 572120
    },
    {
      "epoch": 922.81,
      "learning_rate": 0.007755414825322583,
      "loss": 0.4812,
      "step": 572140
    },
    {
      "epoch": 922.84,
      "learning_rate": 0.007752189022096777,
      "loss": 0.4798,
      "step": 572160
    },
    {
      "epoch": 922.87,
      "learning_rate": 0.007748963218870972,
      "loss": 0.4792,
      "step": 572180
    },
    {
      "epoch": 922.9,
      "learning_rate": 0.007745737415645166,
      "loss": 0.4844,
      "step": 572200
    },
    {
      "epoch": 922.94,
      "learning_rate": 0.007742511612419359,
      "loss": 0.4843,
      "step": 572220
    },
    {
      "epoch": 922.97,
      "learning_rate": 0.0077392858091935544,
      "loss": 0.4826,
      "step": 572240
    },
    {
      "epoch": 923.0,
      "learning_rate": 0.007736060005967736,
      "loss": 0.4734,
      "step": 572260
    },
    {
      "epoch": 923.0,
      "eval_accuracy": {
        "accuracy": 0.7922098196862072
      },
      "eval_loss": 0.8405641317367554,
      "eval_runtime": 3.2344,
      "eval_samples_per_second": 3960.85,
      "eval_steps_per_second": 62.144,
      "step": 572260
    },
    {
      "epoch": 923.03,
      "learning_rate": 0.007732834202741932,
      "loss": 0.4824,
      "step": 572280
    },
    {
      "epoch": 923.06,
      "learning_rate": 0.007729608399516125,
      "loss": 0.4833,
      "step": 572300
    },
    {
      "epoch": 923.1,
      "learning_rate": 0.00772638259629032,
      "loss": 0.4743,
      "step": 572320
    },
    {
      "epoch": 923.13,
      "learning_rate": 0.007723156793064515,
      "loss": 0.4763,
      "step": 572340
    },
    {
      "epoch": 923.16,
      "learning_rate": 0.007719930989838708,
      "loss": 0.483,
      "step": 572360
    },
    {
      "epoch": 923.19,
      "learning_rate": 0.007716705186612903,
      "loss": 0.477,
      "step": 572380
    },
    {
      "epoch": 923.23,
      "learning_rate": 0.007713479383387097,
      "loss": 0.484,
      "step": 572400
    },
    {
      "epoch": 923.26,
      "learning_rate": 0.007710253580161292,
      "loss": 0.4827,
      "step": 572420
    },
    {
      "epoch": 923.29,
      "learning_rate": 0.0077070277769354855,
      "loss": 0.4781,
      "step": 572440
    },
    {
      "epoch": 923.32,
      "learning_rate": 0.00770380197370968,
      "loss": 0.4792,
      "step": 572460
    },
    {
      "epoch": 923.35,
      "learning_rate": 0.007700576170483874,
      "loss": 0.4839,
      "step": 572480
    },
    {
      "epoch": 923.39,
      "learning_rate": 0.007697350367258069,
      "loss": 0.4811,
      "step": 572500
    },
    {
      "epoch": 923.42,
      "learning_rate": 0.007694124564032262,
      "loss": 0.4924,
      "step": 572520
    },
    {
      "epoch": 923.45,
      "learning_rate": 0.007690898760806458,
      "loss": 0.4836,
      "step": 572540
    },
    {
      "epoch": 923.48,
      "learning_rate": 0.007687672957580639,
      "loss": 0.4817,
      "step": 572560
    },
    {
      "epoch": 923.52,
      "learning_rate": 0.007684447154354835,
      "loss": 0.4801,
      "step": 572580
    },
    {
      "epoch": 923.55,
      "learning_rate": 0.007681221351129028,
      "loss": 0.4858,
      "step": 572600
    },
    {
      "epoch": 923.58,
      "learning_rate": 0.007677995547903223,
      "loss": 0.4824,
      "step": 572620
    },
    {
      "epoch": 923.61,
      "learning_rate": 0.007674769744677418,
      "loss": 0.4737,
      "step": 572640
    },
    {
      "epoch": 923.65,
      "learning_rate": 0.007671543941451611,
      "loss": 0.4786,
      "step": 572660
    },
    {
      "epoch": 923.68,
      "learning_rate": 0.007668318138225806,
      "loss": 0.481,
      "step": 572680
    },
    {
      "epoch": 923.71,
      "learning_rate": 0.007665092335,
      "loss": 0.4725,
      "step": 572700
    },
    {
      "epoch": 923.74,
      "learning_rate": 0.007661866531774194,
      "loss": 0.4753,
      "step": 572720
    },
    {
      "epoch": 923.77,
      "learning_rate": 0.007658640728548389,
      "loss": 0.4728,
      "step": 572740
    },
    {
      "epoch": 923.81,
      "learning_rate": 0.007655414925322582,
      "loss": 0.4782,
      "step": 572760
    },
    {
      "epoch": 923.84,
      "learning_rate": 0.007652189122096777,
      "loss": 0.4772,
      "step": 572780
    },
    {
      "epoch": 923.87,
      "learning_rate": 0.00764896331887097,
      "loss": 0.4785,
      "step": 572800
    },
    {
      "epoch": 923.9,
      "learning_rate": 0.007645737515645165,
      "loss": 0.4872,
      "step": 572820
    },
    {
      "epoch": 923.94,
      "learning_rate": 0.007642511712419361,
      "loss": 0.481,
      "step": 572840
    },
    {
      "epoch": 923.97,
      "learning_rate": 0.007639285909193554,
      "loss": 0.4789,
      "step": 572860
    },
    {
      "epoch": 924.0,
      "learning_rate": 0.007636060105967738,
      "loss": 0.497,
      "step": 572880
    },
    {
      "epoch": 924.0,
      "eval_accuracy": {
        "accuracy": 0.7946296151744594
      },
      "eval_loss": 0.8356094360351562,
      "eval_runtime": 4.1943,
      "eval_samples_per_second": 3054.368,
      "eval_steps_per_second": 47.922,
      "step": 572880
    },
    {
      "epoch": 924.03,
      "learning_rate": 0.007632834302741931,
      "loss": 0.4785,
      "step": 572900
    },
    {
      "epoch": 924.06,
      "learning_rate": 0.007629608499516126,
      "loss": 0.4786,
      "step": 572920
    },
    {
      "epoch": 924.1,
      "learning_rate": 0.00762638269629032,
      "loss": 0.4769,
      "step": 572940
    },
    {
      "epoch": 924.13,
      "learning_rate": 0.0076231568930645146,
      "loss": 0.4832,
      "step": 572960
    },
    {
      "epoch": 924.16,
      "learning_rate": 0.0076199310898387084,
      "loss": 0.4774,
      "step": 572980
    },
    {
      "epoch": 924.19,
      "learning_rate": 0.007616705286612903,
      "loss": 0.4752,
      "step": 573000
    },
    {
      "epoch": 924.23,
      "learning_rate": 0.007613479483387097,
      "loss": 0.4783,
      "step": 573020
    },
    {
      "epoch": 924.26,
      "learning_rate": 0.00761025368016129,
      "loss": 0.4766,
      "step": 573040
    },
    {
      "epoch": 924.29,
      "learning_rate": 0.007607027876935485,
      "loss": 0.4864,
      "step": 573060
    },
    {
      "epoch": 924.32,
      "learning_rate": 0.0076038020737096805,
      "loss": 0.484,
      "step": 573080
    },
    {
      "epoch": 924.35,
      "learning_rate": 0.0076005762704838735,
      "loss": 0.4801,
      "step": 573100
    },
    {
      "epoch": 924.39,
      "learning_rate": 0.007597350467258068,
      "loss": 0.4899,
      "step": 573120
    },
    {
      "epoch": 924.42,
      "learning_rate": 0.007594124664032264,
      "loss": 0.4806,
      "step": 573140
    },
    {
      "epoch": 924.45,
      "learning_rate": 0.007590898860806457,
      "loss": 0.4822,
      "step": 573160
    },
    {
      "epoch": 924.48,
      "learning_rate": 0.007587673057580641,
      "loss": 0.4733,
      "step": 573180
    },
    {
      "epoch": 924.52,
      "learning_rate": 0.007584447254354834,
      "loss": 0.48,
      "step": 573200
    },
    {
      "epoch": 924.55,
      "learning_rate": 0.007581221451129029,
      "loss": 0.4821,
      "step": 573220
    },
    {
      "epoch": 924.58,
      "learning_rate": 0.007577995647903223,
      "loss": 0.4785,
      "step": 573240
    },
    {
      "epoch": 924.61,
      "learning_rate": 0.007574769844677417,
      "loss": 0.4797,
      "step": 573260
    },
    {
      "epoch": 924.65,
      "learning_rate": 0.007571544041451612,
      "loss": 0.4821,
      "step": 573280
    },
    {
      "epoch": 924.68,
      "learning_rate": 0.007568318238225805,
      "loss": 0.4726,
      "step": 573300
    },
    {
      "epoch": 924.71,
      "learning_rate": 0.007565092435,
      "loss": 0.479,
      "step": 573320
    },
    {
      "epoch": 924.74,
      "learning_rate": 0.007561866631774193,
      "loss": 0.4736,
      "step": 573340
    },
    {
      "epoch": 924.77,
      "learning_rate": 0.007558640828548388,
      "loss": 0.4766,
      "step": 573360
    },
    {
      "epoch": 924.81,
      "learning_rate": 0.007555415025322584,
      "loss": 0.4834,
      "step": 573380
    },
    {
      "epoch": 924.84,
      "learning_rate": 0.007552189222096777,
      "loss": 0.4715,
      "step": 573400
    },
    {
      "epoch": 924.87,
      "learning_rate": 0.0075489634188709714,
      "loss": 0.4829,
      "step": 573420
    },
    {
      "epoch": 924.9,
      "learning_rate": 0.007545737615645165,
      "loss": 0.4777,
      "step": 573440
    },
    {
      "epoch": 924.94,
      "learning_rate": 0.00754251181241936,
      "loss": 0.4847,
      "step": 573460
    },
    {
      "epoch": 924.97,
      "learning_rate": 0.007539286009193554,
      "loss": 0.4807,
      "step": 573480
    },
    {
      "epoch": 925.0,
      "learning_rate": 0.0075360602059677375,
      "loss": 0.4766,
      "step": 573500
    },
    {
      "epoch": 925.0,
      "eval_accuracy": {
        "accuracy": 0.7926781672000625
      },
      "eval_loss": 0.8421483039855957,
      "eval_runtime": 3.2105,
      "eval_samples_per_second": 3990.3,
      "eval_steps_per_second": 62.606,
      "step": 573500
    },
    {
      "epoch": 925.03,
      "learning_rate": 0.007532834402741931,
      "loss": 0.4747,
      "step": 573520
    },
    {
      "epoch": 925.06,
      "learning_rate": 0.007529608599516126,
      "loss": 0.4701,
      "step": 573540
    },
    {
      "epoch": 925.1,
      "learning_rate": 0.00752638279629032,
      "loss": 0.4724,
      "step": 573560
    },
    {
      "epoch": 925.13,
      "learning_rate": 0.007523156993064513,
      "loss": 0.4823,
      "step": 573580
    },
    {
      "epoch": 925.16,
      "learning_rate": 0.007519931189838708,
      "loss": 0.4817,
      "step": 573600
    },
    {
      "epoch": 925.19,
      "learning_rate": 0.007516705386612903,
      "loss": 0.4778,
      "step": 573620
    },
    {
      "epoch": 925.23,
      "learning_rate": 0.0075134795833870964,
      "loss": 0.4864,
      "step": 573640
    },
    {
      "epoch": 925.26,
      "learning_rate": 0.007510253780161291,
      "loss": 0.4823,
      "step": 573660
    },
    {
      "epoch": 925.29,
      "learning_rate": 0.007507027976935487,
      "loss": 0.482,
      "step": 573680
    },
    {
      "epoch": 925.32,
      "learning_rate": 0.00750380217370968,
      "loss": 0.478,
      "step": 573700
    },
    {
      "epoch": 925.35,
      "learning_rate": 0.007500576370483874,
      "loss": 0.4863,
      "step": 573720
    },
    {
      "epoch": 925.39,
      "learning_rate": 0.0074973505672580685,
      "loss": 0.4829,
      "step": 573740
    },
    {
      "epoch": 925.42,
      "learning_rate": 0.007494124764032262,
      "loss": 0.4778,
      "step": 573760
    },
    {
      "epoch": 925.45,
      "learning_rate": 0.007490898960806457,
      "loss": 0.4808,
      "step": 573780
    },
    {
      "epoch": 925.48,
      "learning_rate": 0.00748767315758065,
      "loss": 0.4767,
      "step": 573800
    },
    {
      "epoch": 925.52,
      "learning_rate": 0.0074844473543548345,
      "loss": 0.4856,
      "step": 573820
    },
    {
      "epoch": 925.55,
      "learning_rate": 0.0074812215511290275,
      "loss": 0.4799,
      "step": 573840
    },
    {
      "epoch": 925.58,
      "learning_rate": 0.0074781570380645195,
      "loss": 0.4765,
      "step": 573860
    },
    {
      "epoch": 925.61,
      "learning_rate": 0.0074749312348387125,
      "loss": 0.4755,
      "step": 573880
    },
    {
      "epoch": 925.65,
      "learning_rate": 0.007471705431612907,
      "loss": 0.4916,
      "step": 573900
    },
    {
      "epoch": 925.68,
      "learning_rate": 0.007468479628387103,
      "loss": 0.4736,
      "step": 573920
    },
    {
      "epoch": 925.71,
      "learning_rate": 0.007465253825161296,
      "loss": 0.4703,
      "step": 573940
    },
    {
      "epoch": 925.74,
      "learning_rate": 0.00746202802193548,
      "loss": 0.474,
      "step": 573960
    },
    {
      "epoch": 925.77,
      "learning_rate": 0.007458802218709673,
      "loss": 0.4874,
      "step": 573980
    },
    {
      "epoch": 925.81,
      "learning_rate": 0.007455576415483868,
      "loss": 0.4725,
      "step": 574000
    },
    {
      "epoch": 925.84,
      "learning_rate": 0.007452350612258062,
      "loss": 0.4699,
      "step": 574020
    },
    {
      "epoch": 925.87,
      "learning_rate": 0.007449124809032257,
      "loss": 0.4747,
      "step": 574040
    },
    {
      "epoch": 925.9,
      "learning_rate": 0.0074458990058064506,
      "loss": 0.4769,
      "step": 574060
    },
    {
      "epoch": 925.94,
      "learning_rate": 0.007442673202580645,
      "loss": 0.4853,
      "step": 574080
    },
    {
      "epoch": 925.97,
      "learning_rate": 0.007439447399354839,
      "loss": 0.4743,
      "step": 574100
    },
    {
      "epoch": 926.0,
      "learning_rate": 0.007436221596129034,
      "loss": 0.4803,
      "step": 574120
    },
    {
      "epoch": 926.0,
      "eval_accuracy": {
        "accuracy": 0.7958785418780735
      },
      "eval_loss": 0.8391673564910889,
      "eval_runtime": 3.3225,
      "eval_samples_per_second": 3855.846,
      "eval_steps_per_second": 60.497,
      "step": 574120
    },
    {
      "epoch": 926.03,
      "learning_rate": 0.007432995792903227,
      "loss": 0.4868,
      "step": 574140
    },
    {
      "epoch": 926.06,
      "learning_rate": 0.007429769989677423,
      "loss": 0.4777,
      "step": 574160
    },
    {
      "epoch": 926.1,
      "learning_rate": 0.007426544186451616,
      "loss": 0.4763,
      "step": 574180
    },
    {
      "epoch": 926.13,
      "learning_rate": 0.00742331838322581,
      "loss": 0.4782,
      "step": 574200
    },
    {
      "epoch": 926.16,
      "learning_rate": 0.007420092580000006,
      "loss": 0.4827,
      "step": 574220
    },
    {
      "epoch": 926.19,
      "learning_rate": 0.007416866776774199,
      "loss": 0.4857,
      "step": 574240
    },
    {
      "epoch": 926.23,
      "learning_rate": 0.007413640973548383,
      "loss": 0.4832,
      "step": 574260
    },
    {
      "epoch": 926.26,
      "learning_rate": 0.007410415170322576,
      "loss": 0.4764,
      "step": 574280
    },
    {
      "epoch": 926.29,
      "learning_rate": 0.007407189367096771,
      "loss": 0.478,
      "step": 574300
    },
    {
      "epoch": 926.32,
      "learning_rate": 0.007403963563870965,
      "loss": 0.4719,
      "step": 574320
    },
    {
      "epoch": 926.35,
      "learning_rate": 0.007400737760645159,
      "loss": 0.4731,
      "step": 574340
    },
    {
      "epoch": 926.39,
      "learning_rate": 0.007397511957419354,
      "loss": 0.4869,
      "step": 574360
    },
    {
      "epoch": 926.42,
      "learning_rate": 0.007394286154193547,
      "loss": 0.4766,
      "step": 574380
    },
    {
      "epoch": 926.45,
      "learning_rate": 0.007391060350967742,
      "loss": 0.4752,
      "step": 574400
    },
    {
      "epoch": 926.48,
      "learning_rate": 0.007387834547741935,
      "loss": 0.4735,
      "step": 574420
    },
    {
      "epoch": 926.52,
      "learning_rate": 0.00738460874451613,
      "loss": 0.4807,
      "step": 574440
    },
    {
      "epoch": 926.55,
      "learning_rate": 0.007381382941290326,
      "loss": 0.4751,
      "step": 574460
    },
    {
      "epoch": 926.58,
      "learning_rate": 0.007378157138064519,
      "loss": 0.4765,
      "step": 574480
    },
    {
      "epoch": 926.61,
      "learning_rate": 0.0073749313348387135,
      "loss": 0.4868,
      "step": 574500
    },
    {
      "epoch": 926.65,
      "learning_rate": 0.0073717055316129074,
      "loss": 0.4851,
      "step": 574520
    },
    {
      "epoch": 926.68,
      "learning_rate": 0.007368479728387102,
      "loss": 0.4648,
      "step": 574540
    },
    {
      "epoch": 926.71,
      "learning_rate": 0.007365253925161296,
      "loss": 0.4786,
      "step": 574560
    },
    {
      "epoch": 926.74,
      "learning_rate": 0.00736202812193548,
      "loss": 0.4755,
      "step": 574580
    },
    {
      "epoch": 926.77,
      "learning_rate": 0.0073588023187096735,
      "loss": 0.4799,
      "step": 574600
    },
    {
      "epoch": 926.81,
      "learning_rate": 0.007355576515483868,
      "loss": 0.4859,
      "step": 574620
    },
    {
      "epoch": 926.84,
      "learning_rate": 0.007352350712258062,
      "loss": 0.4813,
      "step": 574640
    },
    {
      "epoch": 926.87,
      "learning_rate": 0.007349124909032255,
      "loss": 0.4815,
      "step": 574660
    },
    {
      "epoch": 926.9,
      "learning_rate": 0.00734589910580645,
      "loss": 0.4769,
      "step": 574680
    },
    {
      "epoch": 926.94,
      "learning_rate": 0.0073426733025806455,
      "loss": 0.4832,
      "step": 574700
    },
    {
      "epoch": 926.97,
      "learning_rate": 0.0073394474993548385,
      "loss": 0.4794,
      "step": 574720
    },
    {
      "epoch": 927.0,
      "learning_rate": 0.007336221696129033,
      "loss": 0.4735,
      "step": 574740
    },
    {
      "epoch": 927.0,
      "eval_accuracy": {
        "accuracy": 0.7934587463898213
      },
      "eval_loss": 0.8382526636123657,
      "eval_runtime": 3.484,
      "eval_samples_per_second": 3677.066,
      "eval_steps_per_second": 57.692,
      "step": 574740
    },
    {
      "epoch": 927.03,
      "learning_rate": 0.007332995892903229,
      "loss": 0.4818,
      "step": 574760
    },
    {
      "epoch": 927.06,
      "learning_rate": 0.007329770089677422,
      "loss": 0.4728,
      "step": 574780
    },
    {
      "epoch": 927.1,
      "learning_rate": 0.007326544286451616,
      "loss": 0.4821,
      "step": 574800
    },
    {
      "epoch": 927.13,
      "learning_rate": 0.007323318483225811,
      "loss": 0.4869,
      "step": 574820
    },
    {
      "epoch": 927.16,
      "learning_rate": 0.0073200926800000045,
      "loss": 0.4747,
      "step": 574840
    },
    {
      "epoch": 927.19,
      "learning_rate": 0.007316866876774199,
      "loss": 0.4763,
      "step": 574860
    },
    {
      "epoch": 927.23,
      "learning_rate": 0.007313641073548382,
      "loss": 0.4826,
      "step": 574880
    },
    {
      "epoch": 927.26,
      "learning_rate": 0.007310415270322577,
      "loss": 0.476,
      "step": 574900
    },
    {
      "epoch": 927.29,
      "learning_rate": 0.00730718946709677,
      "loss": 0.4775,
      "step": 574920
    },
    {
      "epoch": 927.32,
      "learning_rate": 0.007303963663870965,
      "loss": 0.4841,
      "step": 574940
    },
    {
      "epoch": 927.35,
      "learning_rate": 0.007300737860645158,
      "loss": 0.4776,
      "step": 574960
    },
    {
      "epoch": 927.39,
      "learning_rate": 0.007297512057419353,
      "loss": 0.4811,
      "step": 574980
    },
    {
      "epoch": 927.42,
      "learning_rate": 0.007294286254193549,
      "loss": 0.4794,
      "step": 575000
    },
    {
      "epoch": 927.45,
      "learning_rate": 0.007291060450967742,
      "loss": 0.4675,
      "step": 575020
    },
    {
      "epoch": 927.48,
      "learning_rate": 0.0072878346477419365,
      "loss": 0.4791,
      "step": 575040
    },
    {
      "epoch": 927.52,
      "learning_rate": 0.00728460884451613,
      "loss": 0.4734,
      "step": 575060
    },
    {
      "epoch": 927.55,
      "learning_rate": 0.007281383041290325,
      "loss": 0.4665,
      "step": 575080
    },
    {
      "epoch": 927.58,
      "learning_rate": 0.007278157238064519,
      "loss": 0.4868,
      "step": 575100
    },
    {
      "epoch": 927.61,
      "learning_rate": 0.007274931434838712,
      "loss": 0.4897,
      "step": 575120
    },
    {
      "epoch": 927.65,
      "learning_rate": 0.007271705631612908,
      "loss": 0.4701,
      "step": 575140
    },
    {
      "epoch": 927.68,
      "learning_rate": 0.007268479828387101,
      "loss": 0.4799,
      "step": 575160
    },
    {
      "epoch": 927.71,
      "learning_rate": 0.007265254025161295,
      "loss": 0.4699,
      "step": 575180
    },
    {
      "epoch": 927.74,
      "learning_rate": 0.007262028221935478,
      "loss": 0.471,
      "step": 575200
    },
    {
      "epoch": 927.77,
      "learning_rate": 0.007258802418709673,
      "loss": 0.476,
      "step": 575220
    },
    {
      "epoch": 927.81,
      "learning_rate": 0.007255576615483868,
      "loss": 0.4791,
      "step": 575240
    },
    {
      "epoch": 927.84,
      "learning_rate": 0.0072523508122580614,
      "loss": 0.4848,
      "step": 575260
    },
    {
      "epoch": 927.87,
      "learning_rate": 0.007249125009032256,
      "loss": 0.4774,
      "step": 575280
    },
    {
      "epoch": 927.9,
      "learning_rate": 0.007245899205806452,
      "loss": 0.4677,
      "step": 575300
    },
    {
      "epoch": 927.94,
      "learning_rate": 0.007242673402580645,
      "loss": 0.4891,
      "step": 575320
    },
    {
      "epoch": 927.97,
      "learning_rate": 0.007239447599354839,
      "loss": 0.4822,
      "step": 575340
    },
    {
      "epoch": 928.0,
      "learning_rate": 0.0072362217961290335,
      "loss": 0.4766,
      "step": 575360
    },
    {
      "epoch": 928.0,
      "eval_accuracy": {
        "accuracy": 0.7943954414175318
      },
      "eval_loss": 0.8361145853996277,
      "eval_runtime": 3.2068,
      "eval_samples_per_second": 3994.965,
      "eval_steps_per_second": 62.68,
      "step": 575360
    },
    {
      "epoch": 928.03,
      "learning_rate": 0.007232995992903227,
      "loss": 0.4787,
      "step": 575380
    },
    {
      "epoch": 928.06,
      "learning_rate": 0.007229770189677422,
      "loss": 0.4711,
      "step": 575400
    },
    {
      "epoch": 928.1,
      "learning_rate": 0.007226544386451615,
      "loss": 0.4826,
      "step": 575420
    },
    {
      "epoch": 928.13,
      "learning_rate": 0.007223318583225811,
      "loss": 0.4792,
      "step": 575440
    },
    {
      "epoch": 928.16,
      "learning_rate": 0.007220092780000004,
      "loss": 0.48,
      "step": 575460
    },
    {
      "epoch": 928.19,
      "learning_rate": 0.007216866976774199,
      "loss": 0.4869,
      "step": 575480
    },
    {
      "epoch": 928.23,
      "learning_rate": 0.007213641173548381,
      "loss": 0.4761,
      "step": 575500
    },
    {
      "epoch": 928.26,
      "learning_rate": 0.007210415370322576,
      "loss": 0.4712,
      "step": 575520
    },
    {
      "epoch": 928.29,
      "learning_rate": 0.007207189567096772,
      "loss": 0.4782,
      "step": 575540
    },
    {
      "epoch": 928.32,
      "learning_rate": 0.007203963763870965,
      "loss": 0.478,
      "step": 575560
    },
    {
      "epoch": 928.35,
      "learning_rate": 0.007200737960645159,
      "loss": 0.4798,
      "step": 575580
    },
    {
      "epoch": 928.39,
      "learning_rate": 0.007197512157419353,
      "loss": 0.4698,
      "step": 575600
    },
    {
      "epoch": 928.42,
      "learning_rate": 0.007194286354193548,
      "loss": 0.4772,
      "step": 575620
    },
    {
      "epoch": 928.45,
      "learning_rate": 0.007191060550967742,
      "loss": 0.4712,
      "step": 575640
    },
    {
      "epoch": 928.48,
      "learning_rate": 0.007187834747741935,
      "loss": 0.4767,
      "step": 575660
    },
    {
      "epoch": 928.52,
      "learning_rate": 0.0071846089445161306,
      "loss": 0.4764,
      "step": 575680
    },
    {
      "epoch": 928.55,
      "learning_rate": 0.007181383141290324,
      "loss": 0.481,
      "step": 575700
    },
    {
      "epoch": 928.58,
      "learning_rate": 0.007178157338064518,
      "loss": 0.4775,
      "step": 575720
    },
    {
      "epoch": 928.61,
      "learning_rate": 0.007174931534838714,
      "loss": 0.4805,
      "step": 575740
    },
    {
      "epoch": 928.65,
      "learning_rate": 0.007171705731612907,
      "loss": 0.4793,
      "step": 575760
    },
    {
      "epoch": 928.68,
      "learning_rate": 0.007168479928387102,
      "loss": 0.4734,
      "step": 575780
    },
    {
      "epoch": 928.71,
      "learning_rate": 0.007165254125161296,
      "loss": 0.4799,
      "step": 575800
    },
    {
      "epoch": 928.74,
      "learning_rate": 0.007162028321935479,
      "loss": 0.4676,
      "step": 575820
    },
    {
      "epoch": 928.77,
      "learning_rate": 0.007158802518709673,
      "loss": 0.4741,
      "step": 575840
    },
    {
      "epoch": 928.81,
      "learning_rate": 0.007155738005645164,
      "loss": 0.4716,
      "step": 575860
    },
    {
      "epoch": 928.84,
      "learning_rate": 0.007152512202419358,
      "loss": 0.4753,
      "step": 575880
    },
    {
      "epoch": 928.87,
      "learning_rate": 0.007149286399193553,
      "loss": 0.477,
      "step": 575900
    },
    {
      "epoch": 928.9,
      "learning_rate": 0.007146060595967747,
      "loss": 0.4854,
      "step": 575920
    },
    {
      "epoch": 928.94,
      "learning_rate": 0.007142834792741941,
      "loss": 0.4725,
      "step": 575940
    },
    {
      "epoch": 928.97,
      "learning_rate": 0.007139608989516124,
      "loss": 0.4816,
      "step": 575960
    },
    {
      "epoch": 929.0,
      "learning_rate": 0.007136383186290319,
      "loss": 0.4803,
      "step": 575980
    },
    {
      "epoch": 929.0,
      "eval_accuracy": {
        "accuracy": 0.792990398875966
      },
      "eval_loss": 0.8395374417304993,
      "eval_runtime": 3.4646,
      "eval_samples_per_second": 3697.646,
      "eval_steps_per_second": 58.015,
      "step": 575980
    },
    {
      "epoch": 929.03,
      "learning_rate": 0.007133157383064512,
      "loss": 0.4762,
      "step": 576000
    },
    {
      "epoch": 929.06,
      "learning_rate": 0.007129931579838707,
      "loss": 0.4746,
      "step": 576020
    },
    {
      "epoch": 929.1,
      "learning_rate": 0.0071267057766129,
      "loss": 0.4809,
      "step": 576040
    },
    {
      "epoch": 929.13,
      "learning_rate": 0.007123479973387095,
      "loss": 0.4711,
      "step": 576060
    },
    {
      "epoch": 929.16,
      "learning_rate": 0.007120254170161291,
      "loss": 0.4713,
      "step": 576080
    },
    {
      "epoch": 929.19,
      "learning_rate": 0.007117028366935484,
      "loss": 0.4832,
      "step": 576100
    },
    {
      "epoch": 929.23,
      "learning_rate": 0.0071138025637096786,
      "loss": 0.4704,
      "step": 576120
    },
    {
      "epoch": 929.26,
      "learning_rate": 0.0071105767604838725,
      "loss": 0.4724,
      "step": 576140
    },
    {
      "epoch": 929.29,
      "learning_rate": 0.007107350957258067,
      "loss": 0.4858,
      "step": 576160
    },
    {
      "epoch": 929.32,
      "learning_rate": 0.007104125154032261,
      "loss": 0.4671,
      "step": 576180
    },
    {
      "epoch": 929.35,
      "learning_rate": 0.007100899350806456,
      "loss": 0.4672,
      "step": 576200
    },
    {
      "epoch": 929.39,
      "learning_rate": 0.00709767354758065,
      "loss": 0.4719,
      "step": 576220
    },
    {
      "epoch": 929.42,
      "learning_rate": 0.007094447744354843,
      "loss": 0.4732,
      "step": 576240
    },
    {
      "epoch": 929.45,
      "learning_rate": 0.0070912219411290375,
      "loss": 0.4762,
      "step": 576260
    },
    {
      "epoch": 929.48,
      "learning_rate": 0.00708799613790322,
      "loss": 0.4823,
      "step": 576280
    },
    {
      "epoch": 929.52,
      "learning_rate": 0.007084770334677415,
      "loss": 0.4845,
      "step": 576300
    },
    {
      "epoch": 929.55,
      "learning_rate": 0.0070815445314516105,
      "loss": 0.4758,
      "step": 576320
    },
    {
      "epoch": 929.58,
      "learning_rate": 0.0070783187282258036,
      "loss": 0.479,
      "step": 576340
    },
    {
      "epoch": 929.61,
      "learning_rate": 0.007075092924999998,
      "loss": 0.4777,
      "step": 576360
    },
    {
      "epoch": 929.65,
      "learning_rate": 0.007071867121774194,
      "loss": 0.4726,
      "step": 576380
    },
    {
      "epoch": 929.68,
      "learning_rate": 0.007068641318548387,
      "loss": 0.4848,
      "step": 576400
    },
    {
      "epoch": 929.71,
      "learning_rate": 0.007065415515322581,
      "loss": 0.4863,
      "step": 576420
    },
    {
      "epoch": 929.74,
      "learning_rate": 0.007062189712096776,
      "loss": 0.4686,
      "step": 576440
    },
    {
      "epoch": 929.77,
      "learning_rate": 0.0070589639088709695,
      "loss": 0.4756,
      "step": 576460
    },
    {
      "epoch": 929.81,
      "learning_rate": 0.007055738105645164,
      "loss": 0.4735,
      "step": 576480
    },
    {
      "epoch": 929.84,
      "learning_rate": 0.007052512302419357,
      "loss": 0.4723,
      "step": 576500
    },
    {
      "epoch": 929.87,
      "learning_rate": 0.007049286499193553,
      "loss": 0.4748,
      "step": 576520
    },
    {
      "epoch": 929.9,
      "learning_rate": 0.007046060695967746,
      "loss": 0.4869,
      "step": 576540
    },
    {
      "epoch": 929.94,
      "learning_rate": 0.007042834892741941,
      "loss": 0.4793,
      "step": 576560
    },
    {
      "epoch": 929.97,
      "learning_rate": 0.007039609089516123,
      "loss": 0.4868,
      "step": 576580
    },
    {
      "epoch": 930.0,
      "learning_rate": 0.007036544576451614,
      "loss": 0.489,
      "step": 576600
    },
    {
      "epoch": 930.0,
      "eval_accuracy": {
        "accuracy": 0.7978299898524706
      },
      "eval_loss": 0.8350182771682739,
      "eval_runtime": 3.9872,
      "eval_samples_per_second": 3213.005,
      "eval_steps_per_second": 50.411,
      "step": 576600
    },
    {
      "epoch": 930.03,
      "learning_rate": 0.00703331877322581,
      "loss": 0.4748,
      "step": 576620
    },
    {
      "epoch": 930.06,
      "learning_rate": 0.007030092970000003,
      "loss": 0.4612,
      "step": 576640
    },
    {
      "epoch": 930.1,
      "learning_rate": 0.007026867166774198,
      "loss": 0.4735,
      "step": 576660
    },
    {
      "epoch": 930.13,
      "learning_rate": 0.007023641363548392,
      "loss": 0.4796,
      "step": 576680
    },
    {
      "epoch": 930.16,
      "learning_rate": 0.007020415560322586,
      "loss": 0.4822,
      "step": 576700
    },
    {
      "epoch": 930.19,
      "learning_rate": 0.007017189757096769,
      "loss": 0.4702,
      "step": 576720
    },
    {
      "epoch": 930.23,
      "learning_rate": 0.007013963953870964,
      "loss": 0.4769,
      "step": 576740
    },
    {
      "epoch": 930.26,
      "learning_rate": 0.007010738150645158,
      "loss": 0.4775,
      "step": 576760
    },
    {
      "epoch": 930.29,
      "learning_rate": 0.007007512347419352,
      "loss": 0.4779,
      "step": 576780
    },
    {
      "epoch": 930.32,
      "learning_rate": 0.007004286544193546,
      "loss": 0.47,
      "step": 576800
    },
    {
      "epoch": 930.35,
      "learning_rate": 0.007001060740967739,
      "loss": 0.4811,
      "step": 576820
    },
    {
      "epoch": 930.39,
      "learning_rate": 0.006997834937741934,
      "loss": 0.461,
      "step": 576840
    },
    {
      "epoch": 930.42,
      "learning_rate": 0.00699460913451613,
      "loss": 0.4764,
      "step": 576860
    },
    {
      "epoch": 930.45,
      "learning_rate": 0.006991383331290323,
      "loss": 0.4664,
      "step": 576880
    },
    {
      "epoch": 930.48,
      "learning_rate": 0.0069881575280645175,
      "loss": 0.483,
      "step": 576900
    },
    {
      "epoch": 930.52,
      "learning_rate": 0.006984931724838713,
      "loss": 0.4744,
      "step": 576920
    },
    {
      "epoch": 930.55,
      "learning_rate": 0.006981705921612906,
      "loss": 0.4808,
      "step": 576940
    },
    {
      "epoch": 930.58,
      "learning_rate": 0.0069784801183871,
      "loss": 0.4805,
      "step": 576960
    },
    {
      "epoch": 930.61,
      "learning_rate": 0.006975254315161295,
      "loss": 0.4855,
      "step": 576980
    },
    {
      "epoch": 930.65,
      "learning_rate": 0.006972028511935489,
      "loss": 0.475,
      "step": 577000
    },
    {
      "epoch": 930.68,
      "learning_rate": 0.0069688027087096835,
      "loss": 0.4714,
      "step": 577020
    },
    {
      "epoch": 930.71,
      "learning_rate": 0.006965576905483866,
      "loss": 0.4712,
      "step": 577040
    },
    {
      "epoch": 930.74,
      "learning_rate": 0.006962351102258061,
      "loss": 0.4711,
      "step": 577060
    },
    {
      "epoch": 930.77,
      "learning_rate": 0.006959125299032254,
      "loss": 0.4757,
      "step": 577080
    },
    {
      "epoch": 930.81,
      "learning_rate": 0.0069558994958064495,
      "loss": 0.4814,
      "step": 577100
    },
    {
      "epoch": 930.84,
      "learning_rate": 0.0069526736925806425,
      "loss": 0.4848,
      "step": 577120
    },
    {
      "epoch": 930.87,
      "learning_rate": 0.006949447889354837,
      "loss": 0.4821,
      "step": 577140
    },
    {
      "epoch": 930.9,
      "learning_rate": 0.006946222086129033,
      "loss": 0.4803,
      "step": 577160
    },
    {
      "epoch": 930.94,
      "learning_rate": 0.006942996282903226,
      "loss": 0.4726,
      "step": 577180
    },
    {
      "epoch": 930.97,
      "learning_rate": 0.006939770479677421,
      "loss": 0.4849,
      "step": 577200
    },
    {
      "epoch": 931.0,
      "learning_rate": 0.0069365446764516146,
      "loss": 0.4865,
      "step": 577220
    },
    {
      "epoch": 931.0,
      "eval_accuracy": {
        "accuracy": 0.7940832097416283
      },
      "eval_loss": 0.839290201663971,
      "eval_runtime": 3.1237,
      "eval_samples_per_second": 4101.207,
      "eval_steps_per_second": 64.346,
      "step": 577220
    },
    {
      "epoch": 931.03,
      "learning_rate": 0.006933318873225809,
      "loss": 0.4749,
      "step": 577240
    },
    {
      "epoch": 931.06,
      "learning_rate": 0.006930093070000003,
      "loss": 0.4861,
      "step": 577260
    },
    {
      "epoch": 931.1,
      "learning_rate": 0.006926867266774198,
      "loss": 0.4792,
      "step": 577280
    },
    {
      "epoch": 931.13,
      "learning_rate": 0.006923641463548392,
      "loss": 0.4749,
      "step": 577300
    },
    {
      "epoch": 931.16,
      "learning_rate": 0.006920415660322585,
      "loss": 0.4729,
      "step": 577320
    },
    {
      "epoch": 931.19,
      "learning_rate": 0.006917189857096769,
      "loss": 0.4752,
      "step": 577340
    },
    {
      "epoch": 931.23,
      "learning_rate": 0.006913964053870962,
      "loss": 0.478,
      "step": 577360
    },
    {
      "epoch": 931.26,
      "learning_rate": 0.006910738250645157,
      "loss": 0.4708,
      "step": 577380
    },
    {
      "epoch": 931.29,
      "learning_rate": 0.006907512447419353,
      "loss": 0.4665,
      "step": 577400
    },
    {
      "epoch": 931.32,
      "learning_rate": 0.006904286644193546,
      "loss": 0.4755,
      "step": 577420
    },
    {
      "epoch": 931.35,
      "learning_rate": 0.00690106084096774,
      "loss": 0.4756,
      "step": 577440
    },
    {
      "epoch": 931.39,
      "learning_rate": 0.006897835037741936,
      "loss": 0.4837,
      "step": 577460
    },
    {
      "epoch": 931.42,
      "learning_rate": 0.006894609234516129,
      "loss": 0.472,
      "step": 577480
    },
    {
      "epoch": 931.45,
      "learning_rate": 0.006891383431290323,
      "loss": 0.4691,
      "step": 577500
    },
    {
      "epoch": 931.48,
      "learning_rate": 0.006888157628064518,
      "loss": 0.4815,
      "step": 577520
    },
    {
      "epoch": 931.52,
      "learning_rate": 0.006884931824838712,
      "loss": 0.4762,
      "step": 577540
    },
    {
      "epoch": 931.55,
      "learning_rate": 0.006881706021612906,
      "loss": 0.4811,
      "step": 577560
    },
    {
      "epoch": 931.58,
      "learning_rate": 0.006878480218387099,
      "loss": 0.4807,
      "step": 577580
    },
    {
      "epoch": 931.61,
      "learning_rate": 0.006875254415161295,
      "loss": 0.4732,
      "step": 577600
    },
    {
      "epoch": 931.65,
      "learning_rate": 0.006872028611935488,
      "loss": 0.4712,
      "step": 577620
    },
    {
      "epoch": 931.68,
      "learning_rate": 0.006868802808709683,
      "loss": 0.4709,
      "step": 577640
    },
    {
      "epoch": 931.71,
      "learning_rate": 0.006865577005483865,
      "loss": 0.4717,
      "step": 577660
    },
    {
      "epoch": 931.74,
      "learning_rate": 0.00686235120225806,
      "loss": 0.4594,
      "step": 577680
    },
    {
      "epoch": 931.77,
      "learning_rate": 0.006859125399032256,
      "loss": 0.4723,
      "step": 577700
    },
    {
      "epoch": 931.81,
      "learning_rate": 0.006855899595806449,
      "loss": 0.4838,
      "step": 577720
    },
    {
      "epoch": 931.84,
      "learning_rate": 0.006852673792580644,
      "loss": 0.473,
      "step": 577740
    },
    {
      "epoch": 931.87,
      "learning_rate": 0.0068494479893548375,
      "loss": 0.4787,
      "step": 577760
    },
    {
      "epoch": 931.9,
      "learning_rate": 0.006846222186129032,
      "loss": 0.4859,
      "step": 577780
    },
    {
      "epoch": 931.94,
      "learning_rate": 0.006842996382903226,
      "loss": 0.4727,
      "step": 577800
    },
    {
      "epoch": 931.97,
      "learning_rate": 0.006839770579677419,
      "loss": 0.4833,
      "step": 577820
    },
    {
      "epoch": 932.0,
      "learning_rate": 0.006836544776451615,
      "loss": 0.4849,
      "step": 577840
    },
    {
      "epoch": 932.0,
      "eval_accuracy": {
        "accuracy": 0.7952540785262665
      },
      "eval_loss": 0.8336096405982971,
      "eval_runtime": 3.4081,
      "eval_samples_per_second": 3758.936,
      "eval_steps_per_second": 58.976,
      "step": 577840
    },
    {
      "epoch": 932.03,
      "learning_rate": 0.006833318973225808,
      "loss": 0.4729,
      "step": 577860
    },
    {
      "epoch": 932.06,
      "learning_rate": 0.0068300931700000025,
      "loss": 0.4742,
      "step": 577880
    },
    {
      "epoch": 932.1,
      "learning_rate": 0.006826867366774198,
      "loss": 0.4769,
      "step": 577900
    },
    {
      "epoch": 932.13,
      "learning_rate": 0.006823641563548391,
      "loss": 0.4792,
      "step": 577920
    },
    {
      "epoch": 932.16,
      "learning_rate": 0.006820415760322586,
      "loss": 0.4771,
      "step": 577940
    },
    {
      "epoch": 932.19,
      "learning_rate": 0.006817189957096769,
      "loss": 0.4674,
      "step": 577960
    },
    {
      "epoch": 932.23,
      "learning_rate": 0.006813964153870963,
      "loss": 0.4709,
      "step": 577980
    },
    {
      "epoch": 932.26,
      "learning_rate": 0.006810738350645159,
      "loss": 0.4774,
      "step": 578000
    },
    {
      "epoch": 932.29,
      "learning_rate": 0.006807512547419352,
      "loss": 0.4731,
      "step": 578020
    },
    {
      "epoch": 932.32,
      "learning_rate": 0.006804286744193546,
      "loss": 0.4787,
      "step": 578040
    },
    {
      "epoch": 932.35,
      "learning_rate": 0.006801060940967741,
      "loss": 0.4665,
      "step": 578060
    },
    {
      "epoch": 932.39,
      "learning_rate": 0.0067978351377419345,
      "loss": 0.4677,
      "step": 578080
    },
    {
      "epoch": 932.42,
      "learning_rate": 0.006794609334516129,
      "loss": 0.4782,
      "step": 578100
    },
    {
      "epoch": 932.45,
      "learning_rate": 0.006791383531290322,
      "loss": 0.469,
      "step": 578120
    },
    {
      "epoch": 932.48,
      "learning_rate": 0.006788157728064518,
      "loss": 0.475,
      "step": 578140
    },
    {
      "epoch": 932.52,
      "learning_rate": 0.006784931924838711,
      "loss": 0.4827,
      "step": 578160
    },
    {
      "epoch": 932.55,
      "learning_rate": 0.006781706121612906,
      "loss": 0.4733,
      "step": 578180
    },
    {
      "epoch": 932.58,
      "learning_rate": 0.006778480318387101,
      "loss": 0.4675,
      "step": 578200
    },
    {
      "epoch": 932.61,
      "learning_rate": 0.006775254515161294,
      "loss": 0.4805,
      "step": 578220
    },
    {
      "epoch": 932.65,
      "learning_rate": 0.006772028711935489,
      "loss": 0.4807,
      "step": 578240
    },
    {
      "epoch": 932.68,
      "learning_rate": 0.006768802908709683,
      "loss": 0.4853,
      "step": 578260
    },
    {
      "epoch": 932.71,
      "learning_rate": 0.0067655771054838665,
      "loss": 0.4823,
      "step": 578280
    },
    {
      "epoch": 932.74,
      "learning_rate": 0.00676235130225806,
      "loss": 0.4746,
      "step": 578300
    },
    {
      "epoch": 932.77,
      "learning_rate": 0.006759125499032255,
      "loss": 0.4732,
      "step": 578320
    },
    {
      "epoch": 932.81,
      "learning_rate": 0.006755899695806449,
      "loss": 0.479,
      "step": 578340
    },
    {
      "epoch": 932.84,
      "learning_rate": 0.006752673892580642,
      "loss": 0.4745,
      "step": 578360
    },
    {
      "epoch": 932.87,
      "learning_rate": 0.006749448089354838,
      "loss": 0.4825,
      "step": 578380
    },
    {
      "epoch": 932.9,
      "learning_rate": 0.006746222286129031,
      "loss": 0.4719,
      "step": 578400
    },
    {
      "epoch": 932.94,
      "learning_rate": 0.0067429964829032255,
      "loss": 0.4714,
      "step": 578420
    },
    {
      "epoch": 932.97,
      "learning_rate": 0.006739770679677421,
      "loss": 0.4807,
      "step": 578440
    },
    {
      "epoch": 933.0,
      "learning_rate": 0.006736544876451614,
      "loss": 0.4742,
      "step": 578460
    },
    {
      "epoch": 933.0,
      "eval_accuracy": {
        "accuracy": 0.7941612676606041
      },
      "eval_loss": 0.8333062529563904,
      "eval_runtime": 3.1245,
      "eval_samples_per_second": 4100.129,
      "eval_steps_per_second": 64.33,
      "step": 578460
    },
    {
      "epoch": 933.03,
      "learning_rate": 0.006733319073225809,
      "loss": 0.4726,
      "step": 578480
    },
    {
      "epoch": 933.06,
      "learning_rate": 0.006730093270000003,
      "loss": 0.4741,
      "step": 578500
    },
    {
      "epoch": 933.1,
      "learning_rate": 0.0067268674667741975,
      "loss": 0.4786,
      "step": 578520
    },
    {
      "epoch": 933.13,
      "learning_rate": 0.006723641663548391,
      "loss": 0.4636,
      "step": 578540
    },
    {
      "epoch": 933.16,
      "learning_rate": 0.006720415860322586,
      "loss": 0.4612,
      "step": 578560
    },
    {
      "epoch": 933.19,
      "learning_rate": 0.00671719005709678,
      "loss": 0.4702,
      "step": 578580
    },
    {
      "epoch": 933.23,
      "learning_rate": 0.0067139642538709635,
      "loss": 0.4808,
      "step": 578600
    },
    {
      "epoch": 933.26,
      "learning_rate": 0.006710738450645157,
      "loss": 0.4814,
      "step": 578620
    },
    {
      "epoch": 933.29,
      "learning_rate": 0.006707512647419352,
      "loss": 0.4696,
      "step": 578640
    },
    {
      "epoch": 933.32,
      "learning_rate": 0.006704286844193545,
      "loss": 0.4732,
      "step": 578660
    },
    {
      "epoch": 933.35,
      "learning_rate": 0.006701061040967741,
      "loss": 0.469,
      "step": 578680
    },
    {
      "epoch": 933.39,
      "learning_rate": 0.006697835237741934,
      "loss": 0.4689,
      "step": 578700
    },
    {
      "epoch": 933.42,
      "learning_rate": 0.006694609434516129,
      "loss": 0.4772,
      "step": 578720
    },
    {
      "epoch": 933.45,
      "learning_rate": 0.006691383631290324,
      "loss": 0.4694,
      "step": 578740
    },
    {
      "epoch": 933.48,
      "learning_rate": 0.006688157828064517,
      "loss": 0.4602,
      "step": 578760
    },
    {
      "epoch": 933.52,
      "learning_rate": 0.006684932024838712,
      "loss": 0.4804,
      "step": 578780
    },
    {
      "epoch": 933.55,
      "learning_rate": 0.006681706221612906,
      "loss": 0.4798,
      "step": 578800
    },
    {
      "epoch": 933.58,
      "learning_rate": 0.0066784804183871,
      "loss": 0.4631,
      "step": 578820
    },
    {
      "epoch": 933.61,
      "learning_rate": 0.0066752546151612946,
      "loss": 0.4792,
      "step": 578840
    },
    {
      "epoch": 933.65,
      "learning_rate": 0.006672028811935488,
      "loss": 0.4799,
      "step": 578860
    },
    {
      "epoch": 933.68,
      "learning_rate": 0.006668803008709683,
      "loss": 0.4717,
      "step": 578880
    },
    {
      "epoch": 933.71,
      "learning_rate": 0.006665577205483865,
      "loss": 0.4821,
      "step": 578900
    },
    {
      "epoch": 933.74,
      "learning_rate": 0.006662351402258061,
      "loss": 0.4741,
      "step": 578920
    },
    {
      "epoch": 933.77,
      "learning_rate": 0.006659125599032254,
      "loss": 0.4726,
      "step": 578940
    },
    {
      "epoch": 933.81,
      "learning_rate": 0.006655899795806448,
      "loss": 0.4864,
      "step": 578960
    },
    {
      "epoch": 933.84,
      "learning_rate": 0.006652673992580644,
      "loss": 0.4861,
      "step": 578980
    },
    {
      "epoch": 933.87,
      "learning_rate": 0.006649448189354837,
      "loss": 0.4791,
      "step": 579000
    },
    {
      "epoch": 933.9,
      "learning_rate": 0.006646222386129032,
      "loss": 0.4749,
      "step": 579020
    },
    {
      "epoch": 933.94,
      "learning_rate": 0.006642996582903226,
      "loss": 0.4732,
      "step": 579040
    },
    {
      "epoch": 933.97,
      "learning_rate": 0.00663977077967742,
      "loss": 0.4776,
      "step": 579060
    },
    {
      "epoch": 934.0,
      "learning_rate": 0.006636544976451614,
      "loss": 0.4861,
      "step": 579080
    },
    {
      "epoch": 934.0,
      "eval_accuracy": {
        "accuracy": 0.7971274685816876
      },
      "eval_loss": 0.8345534801483154,
      "eval_runtime": 3.2641,
      "eval_samples_per_second": 3924.806,
      "eval_steps_per_second": 61.579,
      "step": 579080
    },
    {
      "epoch": 934.03,
      "learning_rate": 0.006633319173225809,
      "loss": 0.4779,
      "step": 579100
    },
    {
      "epoch": 934.06,
      "learning_rate": 0.006630093370000003,
      "loss": 0.4754,
      "step": 579120
    },
    {
      "epoch": 934.1,
      "learning_rate": 0.006626867566774196,
      "loss": 0.4763,
      "step": 579140
    },
    {
      "epoch": 934.13,
      "learning_rate": 0.006623641763548391,
      "loss": 0.4703,
      "step": 579160
    },
    {
      "epoch": 934.16,
      "learning_rate": 0.006620415960322586,
      "loss": 0.4741,
      "step": 579180
    },
    {
      "epoch": 934.19,
      "learning_rate": 0.006617190157096779,
      "loss": 0.4683,
      "step": 579200
    },
    {
      "epoch": 934.23,
      "learning_rate": 0.006613964353870964,
      "loss": 0.4645,
      "step": 579220
    },
    {
      "epoch": 934.26,
      "learning_rate": 0.006610738550645157,
      "loss": 0.474,
      "step": 579240
    },
    {
      "epoch": 934.29,
      "learning_rate": 0.0066075127474193515,
      "loss": 0.4701,
      "step": 579260
    },
    {
      "epoch": 934.32,
      "learning_rate": 0.006604286944193547,
      "loss": 0.4713,
      "step": 579280
    },
    {
      "epoch": 934.35,
      "learning_rate": 0.00660106114096774,
      "loss": 0.479,
      "step": 579300
    },
    {
      "epoch": 934.39,
      "learning_rate": 0.006597835337741935,
      "loss": 0.4789,
      "step": 579320
    },
    {
      "epoch": 934.42,
      "learning_rate": 0.006594609534516129,
      "loss": 0.4693,
      "step": 579340
    },
    {
      "epoch": 934.45,
      "learning_rate": 0.006591383731290323,
      "loss": 0.4735,
      "step": 579360
    },
    {
      "epoch": 934.48,
      "learning_rate": 0.0065881579280645175,
      "loss": 0.479,
      "step": 579380
    },
    {
      "epoch": 934.52,
      "learning_rate": 0.0065849321248387105,
      "loss": 0.4806,
      "step": 579400
    },
    {
      "epoch": 934.55,
      "learning_rate": 0.006581706321612906,
      "loss": 0.467,
      "step": 579420
    },
    {
      "epoch": 934.58,
      "learning_rate": 0.006578480518387099,
      "loss": 0.4673,
      "step": 579440
    },
    {
      "epoch": 934.61,
      "learning_rate": 0.006575254715161294,
      "loss": 0.4756,
      "step": 579460
    },
    {
      "epoch": 934.65,
      "learning_rate": 0.0065720289119354895,
      "loss": 0.4711,
      "step": 579480
    },
    {
      "epoch": 934.68,
      "learning_rate": 0.0065688031087096825,
      "loss": 0.4786,
      "step": 579500
    },
    {
      "epoch": 934.71,
      "learning_rate": 0.006565577305483867,
      "loss": 0.479,
      "step": 579520
    },
    {
      "epoch": 934.74,
      "learning_rate": 0.00656235150225806,
      "loss": 0.4778,
      "step": 579540
    },
    {
      "epoch": 934.77,
      "learning_rate": 0.006559125699032255,
      "loss": 0.4816,
      "step": 579560
    },
    {
      "epoch": 934.81,
      "learning_rate": 0.0065558998958064486,
      "loss": 0.4811,
      "step": 579580
    },
    {
      "epoch": 934.84,
      "learning_rate": 0.006552674092580643,
      "loss": 0.4638,
      "step": 579600
    },
    {
      "epoch": 934.87,
      "learning_rate": 0.006549448289354837,
      "loss": 0.4776,
      "step": 579620
    },
    {
      "epoch": 934.9,
      "learning_rate": 0.006546222486129032,
      "loss": 0.4793,
      "step": 579640
    },
    {
      "epoch": 934.94,
      "learning_rate": 0.006542996682903226,
      "loss": 0.4792,
      "step": 579660
    },
    {
      "epoch": 934.97,
      "learning_rate": 0.006539770879677419,
      "loss": 0.4825,
      "step": 579680
    },
    {
      "epoch": 935.0,
      "learning_rate": 0.006536545076451614,
      "loss": 0.4662,
      "step": 579700
    },
    {
      "epoch": 935.0,
      "eval_accuracy": {
        "accuracy": 0.7962688314729529
      },
      "eval_loss": 0.8322469592094421,
      "eval_runtime": 3.1691,
      "eval_samples_per_second": 4042.508,
      "eval_steps_per_second": 63.425,
      "step": 579700
    },
    {
      "epoch": 935.03,
      "learning_rate": 0.006533319273225809,
      "loss": 0.4694,
      "step": 579720
    },
    {
      "epoch": 935.06,
      "learning_rate": 0.006530093470000002,
      "loss": 0.4734,
      "step": 579740
    },
    {
      "epoch": 935.1,
      "learning_rate": 0.006526867666774197,
      "loss": 0.4698,
      "step": 579760
    },
    {
      "epoch": 935.13,
      "learning_rate": 0.006523641863548393,
      "loss": 0.4742,
      "step": 579780
    },
    {
      "epoch": 935.16,
      "learning_rate": 0.006520416060322586,
      "loss": 0.478,
      "step": 579800
    },
    {
      "epoch": 935.19,
      "learning_rate": 0.00651719025709678,
      "loss": 0.4702,
      "step": 579820
    },
    {
      "epoch": 935.23,
      "learning_rate": 0.006513964453870963,
      "loss": 0.472,
      "step": 579840
    },
    {
      "epoch": 935.26,
      "learning_rate": 0.006510738650645157,
      "loss": 0.4756,
      "step": 579860
    },
    {
      "epoch": 935.29,
      "learning_rate": 0.006507512847419352,
      "loss": 0.4695,
      "step": 579880
    },
    {
      "epoch": 935.32,
      "learning_rate": 0.006504287044193546,
      "loss": 0.4779,
      "step": 579900
    },
    {
      "epoch": 935.35,
      "learning_rate": 0.00650106124096774,
      "loss": 0.4671,
      "step": 579920
    },
    {
      "epoch": 935.39,
      "learning_rate": 0.006497835437741933,
      "loss": 0.4719,
      "step": 579940
    },
    {
      "epoch": 935.42,
      "learning_rate": 0.006494609634516129,
      "loss": 0.4804,
      "step": 579960
    },
    {
      "epoch": 935.45,
      "learning_rate": 0.006491383831290322,
      "loss": 0.4717,
      "step": 579980
    },
    {
      "epoch": 935.48,
      "learning_rate": 0.006488158028064517,
      "loss": 0.4711,
      "step": 580000
    },
    {
      "epoch": 935.52,
      "learning_rate": 0.006484932224838712,
      "loss": 0.4792,
      "step": 580020
    },
    {
      "epoch": 935.55,
      "learning_rate": 0.0064817064216129055,
      "loss": 0.4658,
      "step": 580040
    },
    {
      "epoch": 935.58,
      "learning_rate": 0.0064784806183871,
      "loss": 0.4726,
      "step": 580060
    },
    {
      "epoch": 935.61,
      "learning_rate": 0.006475254815161294,
      "loss": 0.4698,
      "step": 580080
    },
    {
      "epoch": 935.65,
      "learning_rate": 0.006472029011935489,
      "loss": 0.4663,
      "step": 580100
    },
    {
      "epoch": 935.68,
      "learning_rate": 0.006468803208709683,
      "loss": 0.4738,
      "step": 580120
    },
    {
      "epoch": 935.71,
      "learning_rate": 0.006465577405483866,
      "loss": 0.4765,
      "step": 580140
    },
    {
      "epoch": 935.74,
      "learning_rate": 0.00646235160225806,
      "loss": 0.4743,
      "step": 580160
    },
    {
      "epoch": 935.77,
      "learning_rate": 0.006459125799032255,
      "loss": 0.4759,
      "step": 580180
    },
    {
      "epoch": 935.81,
      "learning_rate": 0.006455899995806449,
      "loss": 0.4809,
      "step": 580200
    },
    {
      "epoch": 935.84,
      "learning_rate": 0.006452674192580642,
      "loss": 0.472,
      "step": 580220
    },
    {
      "epoch": 935.87,
      "learning_rate": 0.0064494483893548366,
      "loss": 0.4805,
      "step": 580240
    },
    {
      "epoch": 935.9,
      "learning_rate": 0.006446222586129032,
      "loss": 0.4856,
      "step": 580260
    },
    {
      "epoch": 935.94,
      "learning_rate": 0.006442996782903225,
      "loss": 0.4764,
      "step": 580280
    },
    {
      "epoch": 935.97,
      "learning_rate": 0.00643977097967742,
      "loss": 0.475,
      "step": 580300
    },
    {
      "epoch": 936.0,
      "learning_rate": 0.006436706466612899,
      "loss": 0.4767,
      "step": 580320
    },
    {
      "epoch": 936.0,
      "eval_accuracy": {
        "accuracy": 0.7964249473109047
      },
      "eval_loss": 0.8353100419044495,
      "eval_runtime": 3.4182,
      "eval_samples_per_second": 3747.859,
      "eval_steps_per_second": 58.803,
      "step": 580320
    },
    {
      "epoch": 936.03,
      "learning_rate": 0.006433480663387094,
      "loss": 0.4767,
      "step": 580340
    },
    {
      "epoch": 936.06,
      "learning_rate": 0.006430254860161289,
      "loss": 0.48,
      "step": 580360
    },
    {
      "epoch": 936.1,
      "learning_rate": 0.006427029056935482,
      "loss": 0.475,
      "step": 580380
    },
    {
      "epoch": 936.13,
      "learning_rate": 0.006423803253709677,
      "loss": 0.467,
      "step": 580400
    },
    {
      "epoch": 936.16,
      "learning_rate": 0.006420577450483871,
      "loss": 0.4771,
      "step": 580420
    },
    {
      "epoch": 936.19,
      "learning_rate": 0.006417351647258065,
      "loss": 0.4695,
      "step": 580440
    },
    {
      "epoch": 936.23,
      "learning_rate": 0.00641412584403226,
      "loss": 0.4757,
      "step": 580460
    },
    {
      "epoch": 936.26,
      "learning_rate": 0.006410900040806453,
      "loss": 0.4706,
      "step": 580480
    },
    {
      "epoch": 936.29,
      "learning_rate": 0.006407674237580648,
      "loss": 0.4737,
      "step": 580500
    },
    {
      "epoch": 936.32,
      "learning_rate": 0.006404448434354841,
      "loss": 0.4696,
      "step": 580520
    },
    {
      "epoch": 936.35,
      "learning_rate": 0.006401222631129036,
      "loss": 0.4778,
      "step": 580540
    },
    {
      "epoch": 936.39,
      "learning_rate": 0.006397996827903232,
      "loss": 0.4807,
      "step": 580560
    },
    {
      "epoch": 936.42,
      "learning_rate": 0.006394771024677425,
      "loss": 0.468,
      "step": 580580
    },
    {
      "epoch": 936.45,
      "learning_rate": 0.006391545221451609,
      "loss": 0.4731,
      "step": 580600
    },
    {
      "epoch": 936.48,
      "learning_rate": 0.006388319418225802,
      "loss": 0.4648,
      "step": 580620
    },
    {
      "epoch": 936.52,
      "learning_rate": 0.006385093614999997,
      "loss": 0.4626,
      "step": 580640
    },
    {
      "epoch": 936.55,
      "learning_rate": 0.006381867811774191,
      "loss": 0.4755,
      "step": 580660
    },
    {
      "epoch": 936.58,
      "learning_rate": 0.006378642008548385,
      "loss": 0.48,
      "step": 580680
    },
    {
      "epoch": 936.61,
      "learning_rate": 0.006375416205322579,
      "loss": 0.4565,
      "step": 580700
    },
    {
      "epoch": 936.65,
      "learning_rate": 0.006372190402096774,
      "loss": 0.4674,
      "step": 580720
    },
    {
      "epoch": 936.68,
      "learning_rate": 0.006368964598870968,
      "loss": 0.477,
      "step": 580740
    },
    {
      "epoch": 936.71,
      "learning_rate": 0.006365738795645161,
      "loss": 0.4752,
      "step": 580760
    },
    {
      "epoch": 936.74,
      "learning_rate": 0.006362512992419356,
      "loss": 0.471,
      "step": 580780
    },
    {
      "epoch": 936.77,
      "learning_rate": 0.006359287189193551,
      "loss": 0.4806,
      "step": 580800
    },
    {
      "epoch": 936.81,
      "learning_rate": 0.006356061385967744,
      "loss": 0.4756,
      "step": 580820
    },
    {
      "epoch": 936.84,
      "learning_rate": 0.006352835582741939,
      "loss": 0.4747,
      "step": 580840
    },
    {
      "epoch": 936.87,
      "learning_rate": 0.006349609779516135,
      "loss": 0.4742,
      "step": 580860
    },
    {
      "epoch": 936.9,
      "learning_rate": 0.006346383976290328,
      "loss": 0.4778,
      "step": 580880
    },
    {
      "epoch": 936.94,
      "learning_rate": 0.006343158173064522,
      "loss": 0.4692,
      "step": 580900
    },
    {
      "epoch": 936.97,
      "learning_rate": 0.006339932369838705,
      "loss": 0.4712,
      "step": 580920
    },
    {
      "epoch": 937.0,
      "learning_rate": 0.006336706566612899,
      "loss": 0.4873,
      "step": 580940
    },
    {
      "epoch": 937.0,
      "eval_accuracy": {
        "accuracy": 0.7950199047693388
      },
      "eval_loss": 0.8326330184936523,
      "eval_runtime": 3.3548,
      "eval_samples_per_second": 3818.687,
      "eval_steps_per_second": 59.914,
      "step": 580940
    },
    {
      "epoch": 937.03,
      "learning_rate": 0.006333480763387094,
      "loss": 0.4763,
      "step": 580960
    },
    {
      "epoch": 937.06,
      "learning_rate": 0.006330254960161288,
      "loss": 0.4638,
      "step": 580980
    },
    {
      "epoch": 937.1,
      "learning_rate": 0.0063270291569354825,
      "loss": 0.4741,
      "step": 581000
    },
    {
      "epoch": 937.13,
      "learning_rate": 0.0063238033537096755,
      "loss": 0.468,
      "step": 581020
    },
    {
      "epoch": 937.16,
      "learning_rate": 0.006320577550483871,
      "loss": 0.4703,
      "step": 581040
    },
    {
      "epoch": 937.19,
      "learning_rate": 0.006317351747258064,
      "loss": 0.4691,
      "step": 581060
    },
    {
      "epoch": 937.23,
      "learning_rate": 0.006314125944032259,
      "loss": 0.4703,
      "step": 581080
    },
    {
      "epoch": 937.26,
      "learning_rate": 0.0063109001408064545,
      "loss": 0.4712,
      "step": 581100
    },
    {
      "epoch": 937.29,
      "learning_rate": 0.0063076743375806476,
      "loss": 0.4769,
      "step": 581120
    },
    {
      "epoch": 937.32,
      "learning_rate": 0.006304448534354842,
      "loss": 0.4727,
      "step": 581140
    },
    {
      "epoch": 937.35,
      "learning_rate": 0.006301222731129036,
      "loss": 0.4729,
      "step": 581160
    },
    {
      "epoch": 937.39,
      "learning_rate": 0.006297996927903231,
      "loss": 0.4678,
      "step": 581180
    },
    {
      "epoch": 937.42,
      "learning_rate": 0.006294771124677425,
      "loss": 0.4776,
      "step": 581200
    },
    {
      "epoch": 937.45,
      "learning_rate": 0.006291545321451608,
      "loss": 0.4757,
      "step": 581220
    },
    {
      "epoch": 937.48,
      "learning_rate": 0.006288319518225802,
      "loss": 0.4742,
      "step": 581240
    },
    {
      "epoch": 937.52,
      "learning_rate": 0.006285093714999997,
      "loss": 0.4825,
      "step": 581260
    },
    {
      "epoch": 937.55,
      "learning_rate": 0.006281867911774191,
      "loss": 0.4736,
      "step": 581280
    },
    {
      "epoch": 937.58,
      "learning_rate": 0.006278642108548384,
      "loss": 0.462,
      "step": 581300
    },
    {
      "epoch": 937.61,
      "learning_rate": 0.006275416305322579,
      "loss": 0.4722,
      "step": 581320
    },
    {
      "epoch": 937.65,
      "learning_rate": 0.006272190502096774,
      "loss": 0.4733,
      "step": 581340
    },
    {
      "epoch": 937.68,
      "learning_rate": 0.006268964698870967,
      "loss": 0.4663,
      "step": 581360
    },
    {
      "epoch": 937.71,
      "learning_rate": 0.006265738895645162,
      "loss": 0.4819,
      "step": 581380
    },
    {
      "epoch": 937.74,
      "learning_rate": 0.006262513092419358,
      "loss": 0.4667,
      "step": 581400
    },
    {
      "epoch": 937.77,
      "learning_rate": 0.006259287289193551,
      "loss": 0.4747,
      "step": 581420
    },
    {
      "epoch": 937.81,
      "learning_rate": 0.006256061485967745,
      "loss": 0.4846,
      "step": 581440
    },
    {
      "epoch": 937.84,
      "learning_rate": 0.006252835682741939,
      "loss": 0.4704,
      "step": 581460
    },
    {
      "epoch": 937.87,
      "learning_rate": 0.006249609879516133,
      "loss": 0.475,
      "step": 581480
    },
    {
      "epoch": 937.9,
      "learning_rate": 0.006246384076290328,
      "loss": 0.4676,
      "step": 581500
    },
    {
      "epoch": 937.94,
      "learning_rate": 0.006243158273064522,
      "loss": 0.483,
      "step": 581520
    },
    {
      "epoch": 937.97,
      "learning_rate": 0.006239932469838705,
      "loss": 0.4702,
      "step": 581540
    },
    {
      "epoch": 938.0,
      "learning_rate": 0.006236706666612899,
      "loss": 0.4757,
      "step": 581560
    },
    {
      "epoch": 938.0,
      "eval_accuracy": {
        "accuracy": 0.7964249473109047
      },
      "eval_loss": 0.8349403738975525,
      "eval_runtime": 3.2119,
      "eval_samples_per_second": 3988.582,
      "eval_steps_per_second": 62.579,
      "step": 581560
    },
    {
      "epoch": 938.03,
      "learning_rate": 0.006233480863387094,
      "loss": 0.4726,
      "step": 581580
    },
    {
      "epoch": 938.06,
      "learning_rate": 0.006230255060161288,
      "loss": 0.4666,
      "step": 581600
    },
    {
      "epoch": 938.1,
      "learning_rate": 0.006227029256935482,
      "loss": 0.4759,
      "step": 581620
    },
    {
      "epoch": 938.13,
      "learning_rate": 0.006223803453709677,
      "loss": 0.4685,
      "step": 581640
    },
    {
      "epoch": 938.16,
      "learning_rate": 0.0062205776504838705,
      "loss": 0.4694,
      "step": 581660
    },
    {
      "epoch": 938.19,
      "learning_rate": 0.006217351847258065,
      "loss": 0.4686,
      "step": 581680
    },
    {
      "epoch": 938.23,
      "learning_rate": 0.006214126044032259,
      "loss": 0.484,
      "step": 581700
    },
    {
      "epoch": 938.26,
      "learning_rate": 0.006210900240806454,
      "loss": 0.4747,
      "step": 581720
    },
    {
      "epoch": 938.29,
      "learning_rate": 0.006207674437580648,
      "loss": 0.4723,
      "step": 581740
    },
    {
      "epoch": 938.32,
      "learning_rate": 0.006204448634354842,
      "loss": 0.4672,
      "step": 581760
    },
    {
      "epoch": 938.35,
      "learning_rate": 0.006201222831129036,
      "loss": 0.4577,
      "step": 581780
    },
    {
      "epoch": 938.39,
      "learning_rate": 0.00619799702790323,
      "loss": 0.4643,
      "step": 581800
    },
    {
      "epoch": 938.42,
      "learning_rate": 0.006194771224677425,
      "loss": 0.4689,
      "step": 581820
    },
    {
      "epoch": 938.45,
      "learning_rate": 0.006191545421451608,
      "loss": 0.4743,
      "step": 581840
    },
    {
      "epoch": 938.48,
      "learning_rate": 0.006188319618225802,
      "loss": 0.4806,
      "step": 581860
    },
    {
      "epoch": 938.52,
      "learning_rate": 0.006185093814999996,
      "loss": 0.4795,
      "step": 581880
    },
    {
      "epoch": 938.55,
      "learning_rate": 0.006181868011774191,
      "loss": 0.4759,
      "step": 581900
    },
    {
      "epoch": 938.58,
      "learning_rate": 0.006178642208548385,
      "loss": 0.4768,
      "step": 581920
    },
    {
      "epoch": 938.61,
      "learning_rate": 0.006175416405322579,
      "loss": 0.4759,
      "step": 581940
    },
    {
      "epoch": 938.65,
      "learning_rate": 0.006172190602096774,
      "loss": 0.4635,
      "step": 581960
    },
    {
      "epoch": 938.68,
      "learning_rate": 0.0061689647988709675,
      "loss": 0.4626,
      "step": 581980
    },
    {
      "epoch": 938.71,
      "learning_rate": 0.006165738995645162,
      "loss": 0.4738,
      "step": 582000
    },
    {
      "epoch": 938.74,
      "learning_rate": 0.006162513192419356,
      "loss": 0.4655,
      "step": 582020
    },
    {
      "epoch": 938.77,
      "learning_rate": 0.006159287389193551,
      "loss": 0.4711,
      "step": 582040
    },
    {
      "epoch": 938.81,
      "learning_rate": 0.006156061585967745,
      "loss": 0.4781,
      "step": 582060
    },
    {
      "epoch": 938.84,
      "learning_rate": 0.006152835782741939,
      "loss": 0.4747,
      "step": 582080
    },
    {
      "epoch": 938.87,
      "learning_rate": 0.0061496099795161335,
      "loss": 0.4741,
      "step": 582100
    },
    {
      "epoch": 938.9,
      "learning_rate": 0.006146384176290327,
      "loss": 0.4696,
      "step": 582120
    },
    {
      "epoch": 938.94,
      "learning_rate": 0.006143158373064522,
      "loss": 0.4803,
      "step": 582140
    },
    {
      "epoch": 938.97,
      "learning_rate": 0.006139932569838705,
      "loss": 0.4704,
      "step": 582160
    },
    {
      "epoch": 939.0,
      "learning_rate": 0.0061367067666128995,
      "loss": 0.4715,
      "step": 582180
    },
    {
      "epoch": 939.0,
      "eval_accuracy": {
        "accuracy": 0.7981422215283741
      },
      "eval_loss": 0.8284100890159607,
      "eval_runtime": 3.1007,
      "eval_samples_per_second": 4131.654,
      "eval_steps_per_second": 64.824,
      "step": 582180
    },
    {
      "epoch": 939.03,
      "learning_rate": 0.006133480963387093,
      "loss": 0.4712,
      "step": 582200
    },
    {
      "epoch": 939.06,
      "learning_rate": 0.006130255160161288,
      "loss": 0.4665,
      "step": 582220
    },
    {
      "epoch": 939.1,
      "learning_rate": 0.006127029356935482,
      "loss": 0.4808,
      "step": 582240
    },
    {
      "epoch": 939.13,
      "learning_rate": 0.006123803553709677,
      "loss": 0.4757,
      "step": 582260
    },
    {
      "epoch": 939.16,
      "learning_rate": 0.006120577750483871,
      "loss": 0.4705,
      "step": 582280
    },
    {
      "epoch": 939.19,
      "learning_rate": 0.0061173519472580646,
      "loss": 0.4661,
      "step": 582300
    },
    {
      "epoch": 939.23,
      "learning_rate": 0.006114126144032259,
      "loss": 0.4697,
      "step": 582320
    },
    {
      "epoch": 939.26,
      "learning_rate": 0.006110900340806453,
      "loss": 0.4692,
      "step": 582340
    },
    {
      "epoch": 939.29,
      "learning_rate": 0.006107674537580648,
      "loss": 0.4748,
      "step": 582360
    },
    {
      "epoch": 939.32,
      "learning_rate": 0.006104448734354842,
      "loss": 0.4713,
      "step": 582380
    },
    {
      "epoch": 939.35,
      "learning_rate": 0.006101222931129037,
      "loss": 0.4689,
      "step": 582400
    },
    {
      "epoch": 939.39,
      "learning_rate": 0.0060979971279032305,
      "loss": 0.4738,
      "step": 582420
    },
    {
      "epoch": 939.42,
      "learning_rate": 0.006094771324677424,
      "loss": 0.469,
      "step": 582440
    },
    {
      "epoch": 939.45,
      "learning_rate": 0.006091545521451608,
      "loss": 0.4642,
      "step": 582460
    },
    {
      "epoch": 939.48,
      "learning_rate": 0.006088319718225802,
      "loss": 0.4622,
      "step": 582480
    },
    {
      "epoch": 939.52,
      "learning_rate": 0.0060850939149999965,
      "loss": 0.4711,
      "step": 582500
    },
    {
      "epoch": 939.55,
      "learning_rate": 0.00608186811177419,
      "loss": 0.473,
      "step": 582520
    },
    {
      "epoch": 939.58,
      "learning_rate": 0.006078642308548385,
      "loss": 0.4855,
      "step": 582540
    },
    {
      "epoch": 939.61,
      "learning_rate": 0.006075416505322579,
      "loss": 0.4766,
      "step": 582560
    },
    {
      "epoch": 939.65,
      "learning_rate": 0.006072190702096774,
      "loss": 0.4732,
      "step": 582580
    },
    {
      "epoch": 939.68,
      "learning_rate": 0.006068964898870968,
      "loss": 0.4716,
      "step": 582600
    },
    {
      "epoch": 939.71,
      "learning_rate": 0.006065739095645162,
      "loss": 0.469,
      "step": 582620
    },
    {
      "epoch": 939.74,
      "learning_rate": 0.006062513292419356,
      "loss": 0.4711,
      "step": 582640
    },
    {
      "epoch": 939.77,
      "learning_rate": 0.00605928748919355,
      "loss": 0.4771,
      "step": 582660
    },
    {
      "epoch": 939.81,
      "learning_rate": 0.006056061685967745,
      "loss": 0.4688,
      "step": 582680
    },
    {
      "epoch": 939.84,
      "learning_rate": 0.006052835882741939,
      "loss": 0.4663,
      "step": 582700
    },
    {
      "epoch": 939.87,
      "learning_rate": 0.006049610079516134,
      "loss": 0.4682,
      "step": 582720
    },
    {
      "epoch": 939.9,
      "learning_rate": 0.0060463842762903276,
      "loss": 0.4733,
      "step": 582740
    },
    {
      "epoch": 939.94,
      "learning_rate": 0.0060431584730645214,
      "loss": 0.477,
      "step": 582760
    },
    {
      "epoch": 939.97,
      "learning_rate": 0.006039932669838705,
      "loss": 0.4807,
      "step": 582780
    },
    {
      "epoch": 940.0,
      "learning_rate": 0.006036706866612899,
      "loss": 0.4728,
      "step": 582800
    },
    {
      "epoch": 940.0,
      "eval_accuracy": {
        "accuracy": 0.7930684567949419
      },
      "eval_loss": 0.8325120806694031,
      "eval_runtime": 3.2874,
      "eval_samples_per_second": 3896.973,
      "eval_steps_per_second": 61.142,
      "step": 582800
    },
    {
      "epoch": 940.03,
      "learning_rate": 0.006033481063387094,
      "loss": 0.4773,
      "step": 582820
    },
    {
      "epoch": 940.06,
      "learning_rate": 0.0060302552601612875,
      "loss": 0.4729,
      "step": 582840
    },
    {
      "epoch": 940.1,
      "learning_rate": 0.006027029456935482,
      "loss": 0.4684,
      "step": 582860
    },
    {
      "epoch": 940.13,
      "learning_rate": 0.006023803653709676,
      "loss": 0.4797,
      "step": 582880
    },
    {
      "epoch": 940.16,
      "learning_rate": 0.006020577850483871,
      "loss": 0.4539,
      "step": 582900
    },
    {
      "epoch": 940.19,
      "learning_rate": 0.006017352047258065,
      "loss": 0.4772,
      "step": 582920
    },
    {
      "epoch": 940.23,
      "learning_rate": 0.006014126244032259,
      "loss": 0.4721,
      "step": 582940
    },
    {
      "epoch": 940.26,
      "learning_rate": 0.006010900440806453,
      "loss": 0.4671,
      "step": 582960
    },
    {
      "epoch": 940.29,
      "learning_rate": 0.006007674637580647,
      "loss": 0.4789,
      "step": 582980
    },
    {
      "epoch": 940.32,
      "learning_rate": 0.006004448834354842,
      "loss": 0.4711,
      "step": 583000
    },
    {
      "epoch": 940.35,
      "learning_rate": 0.006001223031129036,
      "loss": 0.4655,
      "step": 583020
    },
    {
      "epoch": 940.39,
      "learning_rate": 0.005997997227903231,
      "loss": 0.4761,
      "step": 583040
    },
    {
      "epoch": 940.42,
      "learning_rate": 0.005994771424677425,
      "loss": 0.4688,
      "step": 583060
    },
    {
      "epoch": 940.45,
      "learning_rate": 0.005991545621451608,
      "loss": 0.4677,
      "step": 583080
    },
    {
      "epoch": 940.48,
      "learning_rate": 0.005988319818225802,
      "loss": 0.4662,
      "step": 583100
    },
    {
      "epoch": 940.52,
      "learning_rate": 0.005985094014999997,
      "loss": 0.4801,
      "step": 583120
    },
    {
      "epoch": 940.55,
      "learning_rate": 0.005981868211774191,
      "loss": 0.4735,
      "step": 583140
    },
    {
      "epoch": 940.58,
      "learning_rate": 0.0059786424085483845,
      "loss": 0.4721,
      "step": 583160
    },
    {
      "epoch": 940.61,
      "learning_rate": 0.005975416605322579,
      "loss": 0.4728,
      "step": 583180
    },
    {
      "epoch": 940.65,
      "learning_rate": 0.005972190802096773,
      "loss": 0.4709,
      "step": 583200
    },
    {
      "epoch": 940.68,
      "learning_rate": 0.005968964998870968,
      "loss": 0.4793,
      "step": 583220
    },
    {
      "epoch": 940.71,
      "learning_rate": 0.005965739195645162,
      "loss": 0.4693,
      "step": 583240
    },
    {
      "epoch": 940.74,
      "learning_rate": 0.005962513392419357,
      "loss": 0.4578,
      "step": 583260
    },
    {
      "epoch": 940.77,
      "learning_rate": 0.0059592875891935505,
      "loss": 0.4673,
      "step": 583280
    },
    {
      "epoch": 940.81,
      "learning_rate": 0.005956061785967744,
      "loss": 0.4717,
      "step": 583300
    },
    {
      "epoch": 940.84,
      "learning_rate": 0.005952835982741939,
      "loss": 0.4739,
      "step": 583320
    },
    {
      "epoch": 940.87,
      "learning_rate": 0.005949610179516133,
      "loss": 0.465,
      "step": 583340
    },
    {
      "epoch": 940.9,
      "learning_rate": 0.005946384376290328,
      "loss": 0.4647,
      "step": 583360
    },
    {
      "epoch": 940.94,
      "learning_rate": 0.005943158573064522,
      "loss": 0.4706,
      "step": 583380
    },
    {
      "epoch": 940.97,
      "learning_rate": 0.005939932769838705,
      "loss": 0.475,
      "step": 583400
    },
    {
      "epoch": 941.0,
      "learning_rate": 0.005936868256774195,
      "loss": 0.4736,
      "step": 583420
    },
    {
      "epoch": 941.0,
      "eval_accuracy": {
        "accuracy": 0.7972835844196394
      },
      "eval_loss": 0.827973484992981,
      "eval_runtime": 3.3357,
      "eval_samples_per_second": 3840.554,
      "eval_steps_per_second": 60.257,
      "step": 583420
    },
    {
      "epoch": 941.03,
      "learning_rate": 0.00593364245354839,
      "loss": 0.467,
      "step": 583440
    },
    {
      "epoch": 941.06,
      "learning_rate": 0.005930416650322584,
      "loss": 0.4675,
      "step": 583460
    },
    {
      "epoch": 941.1,
      "learning_rate": 0.005927190847096779,
      "loss": 0.4697,
      "step": 583480
    },
    {
      "epoch": 941.13,
      "learning_rate": 0.005923965043870973,
      "loss": 0.4709,
      "step": 583500
    },
    {
      "epoch": 941.16,
      "learning_rate": 0.0059207392406451665,
      "loss": 0.4687,
      "step": 583520
    },
    {
      "epoch": 941.19,
      "learning_rate": 0.00591751343741935,
      "loss": 0.4668,
      "step": 583540
    },
    {
      "epoch": 941.23,
      "learning_rate": 0.005914287634193544,
      "loss": 0.4752,
      "step": 583560
    },
    {
      "epoch": 941.26,
      "learning_rate": 0.005911061830967739,
      "loss": 0.4711,
      "step": 583580
    },
    {
      "epoch": 941.29,
      "learning_rate": 0.0059078360277419325,
      "loss": 0.471,
      "step": 583600
    },
    {
      "epoch": 941.32,
      "learning_rate": 0.005904610224516127,
      "loss": 0.4755,
      "step": 583620
    },
    {
      "epoch": 941.35,
      "learning_rate": 0.005901384421290321,
      "loss": 0.4757,
      "step": 583640
    },
    {
      "epoch": 941.39,
      "learning_rate": 0.005898158618064516,
      "loss": 0.4733,
      "step": 583660
    },
    {
      "epoch": 941.42,
      "learning_rate": 0.00589493281483871,
      "loss": 0.4732,
      "step": 583680
    },
    {
      "epoch": 941.45,
      "learning_rate": 0.005891707011612904,
      "loss": 0.4739,
      "step": 583700
    },
    {
      "epoch": 941.48,
      "learning_rate": 0.0058884812083870985,
      "loss": 0.463,
      "step": 583720
    },
    {
      "epoch": 941.52,
      "learning_rate": 0.005885255405161292,
      "loss": 0.4669,
      "step": 583740
    },
    {
      "epoch": 941.55,
      "learning_rate": 0.005882029601935487,
      "loss": 0.4675,
      "step": 583760
    },
    {
      "epoch": 941.58,
      "learning_rate": 0.005878803798709681,
      "loss": 0.4807,
      "step": 583780
    },
    {
      "epoch": 941.61,
      "learning_rate": 0.005875577995483876,
      "loss": 0.4606,
      "step": 583800
    },
    {
      "epoch": 941.65,
      "learning_rate": 0.00587235219225807,
      "loss": 0.4669,
      "step": 583820
    },
    {
      "epoch": 941.68,
      "learning_rate": 0.0058691263890322636,
      "loss": 0.4687,
      "step": 583840
    },
    {
      "epoch": 941.71,
      "learning_rate": 0.005865900585806447,
      "loss": 0.4609,
      "step": 583860
    },
    {
      "epoch": 941.74,
      "learning_rate": 0.005862674782580641,
      "loss": 0.462,
      "step": 583880
    },
    {
      "epoch": 941.77,
      "learning_rate": 0.005859448979354836,
      "loss": 0.4813,
      "step": 583900
    },
    {
      "epoch": 941.81,
      "learning_rate": 0.00585622317612903,
      "loss": 0.4667,
      "step": 583920
    },
    {
      "epoch": 941.84,
      "learning_rate": 0.005852997372903224,
      "loss": 0.4733,
      "step": 583940
    },
    {
      "epoch": 941.87,
      "learning_rate": 0.005849771569677418,
      "loss": 0.4652,
      "step": 583960
    },
    {
      "epoch": 941.9,
      "learning_rate": 0.005846545766451613,
      "loss": 0.4732,
      "step": 583980
    },
    {
      "epoch": 941.94,
      "learning_rate": 0.005843319963225807,
      "loss": 0.4782,
      "step": 584000
    },
    {
      "epoch": 941.97,
      "learning_rate": 0.005840094160000001,
      "loss": 0.4744,
      "step": 584020
    },
    {
      "epoch": 942.0,
      "learning_rate": 0.0058368683567741955,
      "loss": 0.478,
      "step": 584040
    },
    {
      "epoch": 942.0,
      "eval_accuracy": {
        "accuracy": 0.7957224260401218
      },
      "eval_loss": 0.8316308856010437,
      "eval_runtime": 4.2203,
      "eval_samples_per_second": 3035.563,
      "eval_steps_per_second": 47.627,
      "step": 584040
    },
    {
      "epoch": 942.03,
      "learning_rate": 0.005833642553548389,
      "loss": 0.4789,
      "step": 584060
    },
    {
      "epoch": 942.06,
      "learning_rate": 0.005830416750322584,
      "loss": 0.4637,
      "step": 584080
    },
    {
      "epoch": 942.1,
      "learning_rate": 0.005827190947096778,
      "loss": 0.4692,
      "step": 584100
    },
    {
      "epoch": 942.13,
      "learning_rate": 0.005823965143870973,
      "loss": 0.4686,
      "step": 584120
    },
    {
      "epoch": 942.16,
      "learning_rate": 0.005820739340645167,
      "loss": 0.4694,
      "step": 584140
    },
    {
      "epoch": 942.19,
      "learning_rate": 0.00581751353741935,
      "loss": 0.4636,
      "step": 584160
    },
    {
      "epoch": 942.23,
      "learning_rate": 0.005814287734193544,
      "loss": 0.4723,
      "step": 584180
    },
    {
      "epoch": 942.26,
      "learning_rate": 0.005811061930967739,
      "loss": 0.4785,
      "step": 584200
    },
    {
      "epoch": 942.29,
      "learning_rate": 0.005807836127741933,
      "loss": 0.4726,
      "step": 584220
    },
    {
      "epoch": 942.32,
      "learning_rate": 0.005804610324516127,
      "loss": 0.4664,
      "step": 584240
    },
    {
      "epoch": 942.35,
      "learning_rate": 0.005801384521290321,
      "loss": 0.4762,
      "step": 584260
    },
    {
      "epoch": 942.39,
      "learning_rate": 0.005798158718064515,
      "loss": 0.4725,
      "step": 584280
    },
    {
      "epoch": 942.42,
      "learning_rate": 0.00579493291483871,
      "loss": 0.4712,
      "step": 584300
    },
    {
      "epoch": 942.45,
      "learning_rate": 0.005791707111612904,
      "loss": 0.4709,
      "step": 584320
    },
    {
      "epoch": 942.48,
      "learning_rate": 0.005788481308387099,
      "loss": 0.4732,
      "step": 584340
    },
    {
      "epoch": 942.52,
      "learning_rate": 0.005785255505161293,
      "loss": 0.4721,
      "step": 584360
    },
    {
      "epoch": 942.55,
      "learning_rate": 0.0057820297019354865,
      "loss": 0.4718,
      "step": 584380
    },
    {
      "epoch": 942.58,
      "learning_rate": 0.005778803898709681,
      "loss": 0.4696,
      "step": 584400
    },
    {
      "epoch": 942.61,
      "learning_rate": 0.005775578095483875,
      "loss": 0.4752,
      "step": 584420
    },
    {
      "epoch": 942.65,
      "learning_rate": 0.00577235229225807,
      "loss": 0.4665,
      "step": 584440
    },
    {
      "epoch": 942.68,
      "learning_rate": 0.005769126489032264,
      "loss": 0.4771,
      "step": 584460
    },
    {
      "epoch": 942.71,
      "learning_rate": 0.005765900685806447,
      "loss": 0.4641,
      "step": 584480
    },
    {
      "epoch": 942.74,
      "learning_rate": 0.005762674882580641,
      "loss": 0.4585,
      "step": 584500
    },
    {
      "epoch": 942.77,
      "learning_rate": 0.005759449079354836,
      "loss": 0.4641,
      "step": 584520
    },
    {
      "epoch": 942.81,
      "learning_rate": 0.00575622327612903,
      "loss": 0.4705,
      "step": 584540
    },
    {
      "epoch": 942.84,
      "learning_rate": 0.005752997472903224,
      "loss": 0.4663,
      "step": 584560
    },
    {
      "epoch": 942.87,
      "learning_rate": 0.005749771669677418,
      "loss": 0.4611,
      "step": 584580
    },
    {
      "epoch": 942.9,
      "learning_rate": 0.005746545866451612,
      "loss": 0.4826,
      "step": 584600
    },
    {
      "epoch": 942.94,
      "learning_rate": 0.005743320063225807,
      "loss": 0.4682,
      "step": 584620
    },
    {
      "epoch": 942.97,
      "learning_rate": 0.005740094260000001,
      "loss": 0.4693,
      "step": 584640
    },
    {
      "epoch": 943.0,
      "learning_rate": 0.005736868456774196,
      "loss": 0.4789,
      "step": 584660
    },
    {
      "epoch": 943.0,
      "eval_accuracy": {
        "accuracy": 0.7976738740145187
      },
      "eval_loss": 0.8310372233390808,
      "eval_runtime": 3.3432,
      "eval_samples_per_second": 3831.974,
      "eval_steps_per_second": 60.122,
      "step": 584660
    },
    {
      "epoch": 943.03,
      "learning_rate": 0.00573364265354839,
      "loss": 0.4669,
      "step": 584680
    },
    {
      "epoch": 943.06,
      "learning_rate": 0.0057304168503225835,
      "loss": 0.4728,
      "step": 584700
    },
    {
      "epoch": 943.1,
      "learning_rate": 0.005727191047096778,
      "loss": 0.4744,
      "step": 584720
    },
    {
      "epoch": 943.13,
      "learning_rate": 0.005723965243870972,
      "loss": 0.468,
      "step": 584740
    },
    {
      "epoch": 943.16,
      "learning_rate": 0.005720739440645167,
      "loss": 0.4752,
      "step": 584760
    },
    {
      "epoch": 943.19,
      "learning_rate": 0.0057175136374193495,
      "loss": 0.4713,
      "step": 584780
    },
    {
      "epoch": 943.23,
      "learning_rate": 0.005714287834193544,
      "loss": 0.4734,
      "step": 584800
    },
    {
      "epoch": 943.26,
      "learning_rate": 0.005711062030967738,
      "loss": 0.4687,
      "step": 584820
    },
    {
      "epoch": 943.29,
      "learning_rate": 0.005707836227741933,
      "loss": 0.4681,
      "step": 584840
    },
    {
      "epoch": 943.32,
      "learning_rate": 0.005704610424516127,
      "loss": 0.4753,
      "step": 584860
    },
    {
      "epoch": 943.35,
      "learning_rate": 0.005701384621290321,
      "loss": 0.4695,
      "step": 584880
    },
    {
      "epoch": 943.39,
      "learning_rate": 0.0056981588180645155,
      "loss": 0.473,
      "step": 584900
    },
    {
      "epoch": 943.42,
      "learning_rate": 0.005694933014838709,
      "loss": 0.4749,
      "step": 584920
    },
    {
      "epoch": 943.45,
      "learning_rate": 0.005691707211612904,
      "loss": 0.4727,
      "step": 584940
    },
    {
      "epoch": 943.48,
      "learning_rate": 0.005688481408387098,
      "loss": 0.4739,
      "step": 584960
    },
    {
      "epoch": 943.52,
      "learning_rate": 0.005685255605161293,
      "loss": 0.461,
      "step": 584980
    },
    {
      "epoch": 943.55,
      "learning_rate": 0.005682029801935487,
      "loss": 0.4631,
      "step": 585000
    },
    {
      "epoch": 943.58,
      "learning_rate": 0.0056788039987096806,
      "loss": 0.4717,
      "step": 585020
    },
    {
      "epoch": 943.61,
      "learning_rate": 0.005675578195483875,
      "loss": 0.4757,
      "step": 585040
    },
    {
      "epoch": 943.65,
      "learning_rate": 0.005672352392258069,
      "loss": 0.4674,
      "step": 585060
    },
    {
      "epoch": 943.68,
      "learning_rate": 0.005669126589032264,
      "loss": 0.4549,
      "step": 585080
    },
    {
      "epoch": 943.71,
      "learning_rate": 0.005665900785806447,
      "loss": 0.4736,
      "step": 585100
    },
    {
      "epoch": 943.74,
      "learning_rate": 0.005662674982580641,
      "loss": 0.4666,
      "step": 585120
    },
    {
      "epoch": 943.77,
      "learning_rate": 0.005659449179354835,
      "loss": 0.4764,
      "step": 585140
    },
    {
      "epoch": 943.81,
      "learning_rate": 0.00565622337612903,
      "loss": 0.4746,
      "step": 585160
    },
    {
      "epoch": 943.84,
      "learning_rate": 0.005652997572903224,
      "loss": 0.4635,
      "step": 585180
    },
    {
      "epoch": 943.87,
      "learning_rate": 0.005649771769677419,
      "loss": 0.4638,
      "step": 585200
    },
    {
      "epoch": 943.9,
      "learning_rate": 0.0056465459664516125,
      "loss": 0.4658,
      "step": 585220
    },
    {
      "epoch": 943.94,
      "learning_rate": 0.005643320163225806,
      "loss": 0.4638,
      "step": 585240
    },
    {
      "epoch": 943.97,
      "learning_rate": 0.005640094360000001,
      "loss": 0.4656,
      "step": 585260
    },
    {
      "epoch": 944.0,
      "learning_rate": 0.005636868556774195,
      "loss": 0.4733,
      "step": 585280
    },
    {
      "epoch": 944.0,
      "eval_accuracy": {
        "accuracy": 0.7947076730934354
      },
      "eval_loss": 0.8347618579864502,
      "eval_runtime": 3.2987,
      "eval_samples_per_second": 3883.628,
      "eval_steps_per_second": 60.933,
      "step": 585280
    },
    {
      "epoch": 944.03,
      "learning_rate": 0.00563364275354839,
      "loss": 0.4768,
      "step": 585300
    },
    {
      "epoch": 944.06,
      "learning_rate": 0.005630416950322584,
      "loss": 0.4657,
      "step": 585320
    },
    {
      "epoch": 944.1,
      "learning_rate": 0.0056271911470967785,
      "loss": 0.4633,
      "step": 585340
    },
    {
      "epoch": 944.13,
      "learning_rate": 0.005623965343870972,
      "loss": 0.4699,
      "step": 585360
    },
    {
      "epoch": 944.16,
      "learning_rate": 0.005620739540645166,
      "loss": 0.4711,
      "step": 585380
    },
    {
      "epoch": 944.19,
      "learning_rate": 0.00561751373741935,
      "loss": 0.4712,
      "step": 585400
    },
    {
      "epoch": 944.23,
      "learning_rate": 0.005614287934193544,
      "loss": 0.4608,
      "step": 585420
    },
    {
      "epoch": 944.26,
      "learning_rate": 0.005611062130967738,
      "loss": 0.4709,
      "step": 585440
    },
    {
      "epoch": 944.29,
      "learning_rate": 0.005607836327741932,
      "loss": 0.4711,
      "step": 585460
    },
    {
      "epoch": 944.32,
      "learning_rate": 0.005604610524516127,
      "loss": 0.4743,
      "step": 585480
    },
    {
      "epoch": 944.35,
      "learning_rate": 0.005601384721290321,
      "loss": 0.4686,
      "step": 585500
    },
    {
      "epoch": 944.39,
      "learning_rate": 0.005598158918064516,
      "loss": 0.4736,
      "step": 585520
    },
    {
      "epoch": 944.42,
      "learning_rate": 0.00559493311483871,
      "loss": 0.4642,
      "step": 585540
    },
    {
      "epoch": 944.45,
      "learning_rate": 0.0055917073116129035,
      "loss": 0.4715,
      "step": 585560
    },
    {
      "epoch": 944.48,
      "learning_rate": 0.005588481508387098,
      "loss": 0.4725,
      "step": 585580
    },
    {
      "epoch": 944.52,
      "learning_rate": 0.005585255705161292,
      "loss": 0.4635,
      "step": 585600
    },
    {
      "epoch": 944.55,
      "learning_rate": 0.005582029901935487,
      "loss": 0.4724,
      "step": 585620
    },
    {
      "epoch": 944.58,
      "learning_rate": 0.005578804098709681,
      "loss": 0.463,
      "step": 585640
    },
    {
      "epoch": 944.61,
      "learning_rate": 0.0055755782954838755,
      "loss": 0.4629,
      "step": 585660
    },
    {
      "epoch": 944.65,
      "learning_rate": 0.005572352492258069,
      "loss": 0.4767,
      "step": 585680
    },
    {
      "epoch": 944.68,
      "learning_rate": 0.005569126689032263,
      "loss": 0.4601,
      "step": 585700
    },
    {
      "epoch": 944.71,
      "learning_rate": 0.005565900885806447,
      "loss": 0.4677,
      "step": 585720
    },
    {
      "epoch": 944.74,
      "learning_rate": 0.005562675082580641,
      "loss": 0.4581,
      "step": 585740
    },
    {
      "epoch": 944.77,
      "learning_rate": 0.005559449279354835,
      "loss": 0.464,
      "step": 585760
    },
    {
      "epoch": 944.81,
      "learning_rate": 0.005556223476129029,
      "loss": 0.4774,
      "step": 585780
    },
    {
      "epoch": 944.84,
      "learning_rate": 0.005552997672903224,
      "loss": 0.4679,
      "step": 585800
    },
    {
      "epoch": 944.87,
      "learning_rate": 0.005549771869677418,
      "loss": 0.468,
      "step": 585820
    },
    {
      "epoch": 944.9,
      "learning_rate": 0.005546546066451613,
      "loss": 0.469,
      "step": 585840
    },
    {
      "epoch": 944.94,
      "learning_rate": 0.005543320263225807,
      "loss": 0.4743,
      "step": 585860
    },
    {
      "epoch": 944.97,
      "learning_rate": 0.0055400944600000005,
      "loss": 0.4715,
      "step": 585880
    },
    {
      "epoch": 945.0,
      "learning_rate": 0.005536868656774195,
      "loss": 0.478,
      "step": 585900
    },
    {
      "epoch": 945.0,
      "eval_accuracy": {
        "accuracy": 0.7952540785262665
      },
      "eval_loss": 0.830540657043457,
      "eval_runtime": 3.1652,
      "eval_samples_per_second": 4047.419,
      "eval_steps_per_second": 63.503,
      "step": 585900
    },
    {
      "epoch": 945.03,
      "learning_rate": 0.005533642853548389,
      "loss": 0.4703,
      "step": 585920
    },
    {
      "epoch": 945.06,
      "learning_rate": 0.005530417050322584,
      "loss": 0.4677,
      "step": 585940
    },
    {
      "epoch": 945.1,
      "learning_rate": 0.005527191247096778,
      "loss": 0.4646,
      "step": 585960
    },
    {
      "epoch": 945.13,
      "learning_rate": 0.005523965443870973,
      "loss": 0.4615,
      "step": 585980
    },
    {
      "epoch": 945.16,
      "learning_rate": 0.0055207396406451665,
      "loss": 0.4639,
      "step": 586000
    },
    {
      "epoch": 945.19,
      "learning_rate": 0.00551751383741936,
      "loss": 0.4707,
      "step": 586020
    },
    {
      "epoch": 945.23,
      "learning_rate": 0.005514288034193544,
      "loss": 0.4623,
      "step": 586040
    },
    {
      "epoch": 945.26,
      "learning_rate": 0.005511062230967738,
      "loss": 0.4724,
      "step": 586060
    },
    {
      "epoch": 945.29,
      "learning_rate": 0.0055078364277419325,
      "loss": 0.4637,
      "step": 586080
    },
    {
      "epoch": 945.32,
      "learning_rate": 0.005504610624516126,
      "loss": 0.4651,
      "step": 586100
    },
    {
      "epoch": 945.35,
      "learning_rate": 0.005501384821290321,
      "loss": 0.4724,
      "step": 586120
    },
    {
      "epoch": 945.39,
      "learning_rate": 0.005498159018064515,
      "loss": 0.4703,
      "step": 586140
    },
    {
      "epoch": 945.42,
      "learning_rate": 0.00549493321483871,
      "loss": 0.4679,
      "step": 586160
    },
    {
      "epoch": 945.45,
      "learning_rate": 0.005491707411612904,
      "loss": 0.4662,
      "step": 586180
    },
    {
      "epoch": 945.48,
      "learning_rate": 0.0054884816083870976,
      "loss": 0.4609,
      "step": 586200
    },
    {
      "epoch": 945.52,
      "learning_rate": 0.005485255805161292,
      "loss": 0.4729,
      "step": 586220
    },
    {
      "epoch": 945.55,
      "learning_rate": 0.005482030001935486,
      "loss": 0.4705,
      "step": 586240
    },
    {
      "epoch": 945.58,
      "learning_rate": 0.005478804198709681,
      "loss": 0.4671,
      "step": 586260
    },
    {
      "epoch": 945.61,
      "learning_rate": 0.005475578395483875,
      "loss": 0.4707,
      "step": 586280
    },
    {
      "epoch": 945.65,
      "learning_rate": 0.00547235259225807,
      "loss": 0.4694,
      "step": 586300
    },
    {
      "epoch": 945.68,
      "learning_rate": 0.0054691267890322635,
      "loss": 0.4681,
      "step": 586320
    },
    {
      "epoch": 945.71,
      "learning_rate": 0.005465900985806447,
      "loss": 0.4733,
      "step": 586340
    },
    {
      "epoch": 945.74,
      "learning_rate": 0.005462675182580641,
      "loss": 0.4666,
      "step": 586360
    },
    {
      "epoch": 945.77,
      "learning_rate": 0.005459449379354836,
      "loss": 0.4722,
      "step": 586380
    },
    {
      "epoch": 945.81,
      "learning_rate": 0.0054562235761290295,
      "loss": 0.4763,
      "step": 586400
    },
    {
      "epoch": 945.84,
      "learning_rate": 0.005452997772903223,
      "loss": 0.4678,
      "step": 586420
    },
    {
      "epoch": 945.87,
      "learning_rate": 0.005449771969677418,
      "loss": 0.4714,
      "step": 586440
    },
    {
      "epoch": 945.9,
      "learning_rate": 0.005446546166451612,
      "loss": 0.4698,
      "step": 586460
    },
    {
      "epoch": 945.94,
      "learning_rate": 0.005443320363225807,
      "loss": 0.4693,
      "step": 586480
    },
    {
      "epoch": 945.97,
      "learning_rate": 0.005440094560000001,
      "loss": 0.4637,
      "step": 586500
    },
    {
      "epoch": 946.0,
      "learning_rate": 0.0054370300469354805,
      "loss": 0.4807,
      "step": 586520
    },
    {
      "epoch": 946.0,
      "eval_accuracy": {
        "accuracy": 0.7981422215283741
      },
      "eval_loss": 0.8291429281234741,
      "eval_runtime": 3.2422,
      "eval_samples_per_second": 3951.385,
      "eval_steps_per_second": 61.996,
      "step": 586520
    },
    {
      "epoch": 946.03,
      "learning_rate": 0.005433804243709674,
      "loss": 0.4674,
      "step": 586540
    },
    {
      "epoch": 946.06,
      "learning_rate": 0.005430578440483869,
      "loss": 0.4697,
      "step": 586560
    },
    {
      "epoch": 946.1,
      "learning_rate": 0.005427352637258063,
      "loss": 0.4735,
      "step": 586580
    },
    {
      "epoch": 946.13,
      "learning_rate": 0.005424126834032258,
      "loss": 0.4563,
      "step": 586600
    },
    {
      "epoch": 946.16,
      "learning_rate": 0.005420901030806452,
      "loss": 0.4791,
      "step": 586620
    },
    {
      "epoch": 946.19,
      "learning_rate": 0.005417675227580646,
      "loss": 0.4808,
      "step": 586640
    },
    {
      "epoch": 946.23,
      "learning_rate": 0.00541444942435484,
      "loss": 0.468,
      "step": 586660
    },
    {
      "epoch": 946.26,
      "learning_rate": 0.005411223621129034,
      "loss": 0.4677,
      "step": 586680
    },
    {
      "epoch": 946.29,
      "learning_rate": 0.005407997817903229,
      "loss": 0.476,
      "step": 586700
    },
    {
      "epoch": 946.32,
      "learning_rate": 0.005404772014677423,
      "loss": 0.4707,
      "step": 586720
    },
    {
      "epoch": 946.35,
      "learning_rate": 0.005401546211451618,
      "loss": 0.4669,
      "step": 586740
    },
    {
      "epoch": 946.39,
      "learning_rate": 0.0053983204082258115,
      "loss": 0.4636,
      "step": 586760
    },
    {
      "epoch": 946.42,
      "learning_rate": 0.005395094605000005,
      "loss": 0.4633,
      "step": 586780
    },
    {
      "epoch": 946.45,
      "learning_rate": 0.005391868801774189,
      "loss": 0.4645,
      "step": 586800
    },
    {
      "epoch": 946.48,
      "learning_rate": 0.005388642998548383,
      "loss": 0.4735,
      "step": 586820
    },
    {
      "epoch": 946.52,
      "learning_rate": 0.0053854171953225775,
      "loss": 0.4603,
      "step": 586840
    },
    {
      "epoch": 946.55,
      "learning_rate": 0.005382191392096771,
      "loss": 0.4688,
      "step": 586860
    },
    {
      "epoch": 946.58,
      "learning_rate": 0.005378965588870966,
      "loss": 0.4644,
      "step": 586880
    },
    {
      "epoch": 946.61,
      "learning_rate": 0.00537573978564516,
      "loss": 0.4686,
      "step": 586900
    },
    {
      "epoch": 946.65,
      "learning_rate": 0.005372513982419355,
      "loss": 0.4668,
      "step": 586920
    },
    {
      "epoch": 946.68,
      "learning_rate": 0.005369288179193549,
      "loss": 0.4616,
      "step": 586940
    },
    {
      "epoch": 946.71,
      "learning_rate": 0.005366062375967743,
      "loss": 0.4697,
      "step": 586960
    },
    {
      "epoch": 946.74,
      "learning_rate": 0.005362836572741937,
      "loss": 0.4631,
      "step": 586980
    },
    {
      "epoch": 946.77,
      "learning_rate": 0.005359610769516131,
      "loss": 0.4662,
      "step": 587000
    },
    {
      "epoch": 946.81,
      "learning_rate": 0.005356384966290326,
      "loss": 0.4717,
      "step": 587020
    },
    {
      "epoch": 946.84,
      "learning_rate": 0.00535315916306452,
      "loss": 0.4643,
      "step": 587040
    },
    {
      "epoch": 946.87,
      "learning_rate": 0.005349933359838715,
      "loss": 0.4763,
      "step": 587060
    },
    {
      "epoch": 946.9,
      "learning_rate": 0.0053467075566129086,
      "loss": 0.4692,
      "step": 587080
    },
    {
      "epoch": 946.94,
      "learning_rate": 0.005343481753387092,
      "loss": 0.4669,
      "step": 587100
    },
    {
      "epoch": 946.97,
      "learning_rate": 0.005340255950161286,
      "loss": 0.4685,
      "step": 587120
    },
    {
      "epoch": 947.0,
      "learning_rate": 0.005337030146935481,
      "loss": 0.4617,
      "step": 587140
    },
    {
      "epoch": 947.0,
      "eval_accuracy": {
        "accuracy": 0.7958785418780735
      },
      "eval_loss": 0.8278839588165283,
      "eval_runtime": 3.2853,
      "eval_samples_per_second": 3899.483,
      "eval_steps_per_second": 61.181,
      "step": 587140
    },
    {
      "epoch": 947.03,
      "learning_rate": 0.005333804343709675,
      "loss": 0.4727,
      "step": 587160
    },
    {
      "epoch": 947.06,
      "learning_rate": 0.0053305785404838685,
      "loss": 0.4685,
      "step": 587180
    },
    {
      "epoch": 947.1,
      "learning_rate": 0.005327352737258063,
      "loss": 0.4681,
      "step": 587200
    },
    {
      "epoch": 947.13,
      "learning_rate": 0.005324126934032257,
      "loss": 0.4729,
      "step": 587220
    },
    {
      "epoch": 947.16,
      "learning_rate": 0.005320901130806452,
      "loss": 0.467,
      "step": 587240
    },
    {
      "epoch": 947.19,
      "learning_rate": 0.005317675327580646,
      "loss": 0.465,
      "step": 587260
    },
    {
      "epoch": 947.23,
      "learning_rate": 0.0053144495243548405,
      "loss": 0.4688,
      "step": 587280
    },
    {
      "epoch": 947.26,
      "learning_rate": 0.005311223721129034,
      "loss": 0.4669,
      "step": 587300
    },
    {
      "epoch": 947.29,
      "learning_rate": 0.005307997917903228,
      "loss": 0.4737,
      "step": 587320
    },
    {
      "epoch": 947.32,
      "learning_rate": 0.005304772114677423,
      "loss": 0.4653,
      "step": 587340
    },
    {
      "epoch": 947.35,
      "learning_rate": 0.005301546311451617,
      "loss": 0.4651,
      "step": 587360
    },
    {
      "epoch": 947.39,
      "learning_rate": 0.005298320508225812,
      "loss": 0.47,
      "step": 587380
    },
    {
      "epoch": 947.42,
      "learning_rate": 0.005295094705000006,
      "loss": 0.4631,
      "step": 587400
    },
    {
      "epoch": 947.45,
      "learning_rate": 0.005291868901774189,
      "loss": 0.467,
      "step": 587420
    },
    {
      "epoch": 947.48,
      "learning_rate": 0.005288643098548383,
      "loss": 0.4632,
      "step": 587440
    },
    {
      "epoch": 947.52,
      "learning_rate": 0.005285417295322578,
      "loss": 0.4722,
      "step": 587460
    },
    {
      "epoch": 947.55,
      "learning_rate": 0.005282191492096772,
      "loss": 0.4663,
      "step": 587480
    },
    {
      "epoch": 947.58,
      "learning_rate": 0.0052789656888709655,
      "loss": 0.4642,
      "step": 587500
    },
    {
      "epoch": 947.61,
      "learning_rate": 0.00527573988564516,
      "loss": 0.4667,
      "step": 587520
    },
    {
      "epoch": 947.65,
      "learning_rate": 0.005272514082419354,
      "loss": 0.4819,
      "step": 587540
    },
    {
      "epoch": 947.68,
      "learning_rate": 0.005269288279193549,
      "loss": 0.4742,
      "step": 587560
    },
    {
      "epoch": 947.71,
      "learning_rate": 0.005266062475967743,
      "loss": 0.4666,
      "step": 587580
    },
    {
      "epoch": 947.74,
      "learning_rate": 0.005262836672741938,
      "loss": 0.466,
      "step": 587600
    },
    {
      "epoch": 947.77,
      "learning_rate": 0.0052596108695161315,
      "loss": 0.4619,
      "step": 587620
    },
    {
      "epoch": 947.81,
      "learning_rate": 0.005256385066290325,
      "loss": 0.4684,
      "step": 587640
    },
    {
      "epoch": 947.84,
      "learning_rate": 0.00525315926306452,
      "loss": 0.4708,
      "step": 587660
    },
    {
      "epoch": 947.87,
      "learning_rate": 0.005249933459838714,
      "loss": 0.4666,
      "step": 587680
    },
    {
      "epoch": 947.9,
      "learning_rate": 0.005246707656612909,
      "loss": 0.4618,
      "step": 587700
    },
    {
      "epoch": 947.94,
      "learning_rate": 0.005243481853387091,
      "loss": 0.4642,
      "step": 587720
    },
    {
      "epoch": 947.97,
      "learning_rate": 0.005240256050161286,
      "loss": 0.4601,
      "step": 587740
    },
    {
      "epoch": 948.0,
      "learning_rate": 0.00523703024693548,
      "loss": 0.474,
      "step": 587760
    },
    {
      "epoch": 948.0,
      "eval_accuracy": {
        "accuracy": 0.7972055265006635
      },
      "eval_loss": 0.8271092772483826,
      "eval_runtime": 3.348,
      "eval_samples_per_second": 3826.511,
      "eval_steps_per_second": 60.037,
      "step": 587760
    },
    {
      "epoch": 948.03,
      "learning_rate": 0.005233804443709675,
      "loss": 0.4747,
      "step": 587780
    },
    {
      "epoch": 948.06,
      "learning_rate": 0.005230578640483869,
      "loss": 0.4606,
      "step": 587800
    },
    {
      "epoch": 948.1,
      "learning_rate": 0.005227352837258063,
      "loss": 0.4679,
      "step": 587820
    },
    {
      "epoch": 948.13,
      "learning_rate": 0.005224127034032257,
      "loss": 0.4606,
      "step": 587840
    },
    {
      "epoch": 948.16,
      "learning_rate": 0.005220901230806451,
      "loss": 0.4636,
      "step": 587860
    },
    {
      "epoch": 948.19,
      "learning_rate": 0.005217675427580646,
      "loss": 0.4699,
      "step": 587880
    },
    {
      "epoch": 948.23,
      "learning_rate": 0.00521444962435484,
      "loss": 0.462,
      "step": 587900
    },
    {
      "epoch": 948.26,
      "learning_rate": 0.005211223821129035,
      "loss": 0.4684,
      "step": 587920
    },
    {
      "epoch": 948.29,
      "learning_rate": 0.0052079980179032285,
      "loss": 0.4719,
      "step": 587940
    },
    {
      "epoch": 948.32,
      "learning_rate": 0.005204772214677422,
      "loss": 0.4659,
      "step": 587960
    },
    {
      "epoch": 948.35,
      "learning_rate": 0.005201546411451617,
      "loss": 0.4637,
      "step": 587980
    },
    {
      "epoch": 948.39,
      "learning_rate": 0.005198320608225811,
      "loss": 0.4673,
      "step": 588000
    },
    {
      "epoch": 948.42,
      "learning_rate": 0.005195094805000006,
      "loss": 0.4707,
      "step": 588020
    },
    {
      "epoch": 948.45,
      "learning_rate": 0.005191869001774188,
      "loss": 0.4678,
      "step": 588040
    },
    {
      "epoch": 948.48,
      "learning_rate": 0.005188643198548383,
      "loss": 0.4683,
      "step": 588060
    },
    {
      "epoch": 948.52,
      "learning_rate": 0.005185417395322577,
      "loss": 0.4685,
      "step": 588080
    },
    {
      "epoch": 948.55,
      "learning_rate": 0.005182191592096772,
      "loss": 0.462,
      "step": 588100
    },
    {
      "epoch": 948.58,
      "learning_rate": 0.005178965788870966,
      "loss": 0.4722,
      "step": 588120
    },
    {
      "epoch": 948.61,
      "learning_rate": 0.00517573998564516,
      "loss": 0.4647,
      "step": 588140
    },
    {
      "epoch": 948.65,
      "learning_rate": 0.005172514182419354,
      "loss": 0.4618,
      "step": 588160
    },
    {
      "epoch": 948.68,
      "learning_rate": 0.005169288379193548,
      "loss": 0.4633,
      "step": 588180
    },
    {
      "epoch": 948.71,
      "learning_rate": 0.005166062575967743,
      "loss": 0.4746,
      "step": 588200
    },
    {
      "epoch": 948.74,
      "learning_rate": 0.005162836772741937,
      "loss": 0.4746,
      "step": 588220
    },
    {
      "epoch": 948.77,
      "learning_rate": 0.005159610969516132,
      "loss": 0.4706,
      "step": 588240
    },
    {
      "epoch": 948.81,
      "learning_rate": 0.005156385166290326,
      "loss": 0.4685,
      "step": 588260
    },
    {
      "epoch": 948.84,
      "learning_rate": 0.0051531593630645195,
      "loss": 0.47,
      "step": 588280
    },
    {
      "epoch": 948.87,
      "learning_rate": 0.005149933559838714,
      "loss": 0.4681,
      "step": 588300
    },
    {
      "epoch": 948.9,
      "learning_rate": 0.005146707756612908,
      "loss": 0.4569,
      "step": 588320
    },
    {
      "epoch": 948.94,
      "learning_rate": 0.005143481953387103,
      "loss": 0.466,
      "step": 588340
    },
    {
      "epoch": 948.97,
      "learning_rate": 0.0051402561501612855,
      "loss": 0.4587,
      "step": 588360
    },
    {
      "epoch": 949.0,
      "learning_rate": 0.00513703034693548,
      "loss": 0.4671,
      "step": 588380
    },
    {
      "epoch": 949.0,
      "eval_accuracy": {
        "accuracy": 0.7990789165560847
      },
      "eval_loss": 0.8266398310661316,
      "eval_runtime": 3.2863,
      "eval_samples_per_second": 3898.247,
      "eval_steps_per_second": 61.162,
      "step": 588380
    },
    {
      "epoch": 949.03,
      "learning_rate": 0.005133804543709674,
      "loss": 0.4717,
      "step": 588400
    },
    {
      "epoch": 949.06,
      "learning_rate": 0.005130578740483869,
      "loss": 0.4646,
      "step": 588420
    },
    {
      "epoch": 949.1,
      "learning_rate": 0.005127352937258063,
      "loss": 0.4761,
      "step": 588440
    },
    {
      "epoch": 949.13,
      "learning_rate": 0.0051241271340322575,
      "loss": 0.4733,
      "step": 588460
    },
    {
      "epoch": 949.16,
      "learning_rate": 0.005120901330806451,
      "loss": 0.4622,
      "step": 588480
    },
    {
      "epoch": 949.19,
      "learning_rate": 0.005117675527580645,
      "loss": 0.4632,
      "step": 588500
    },
    {
      "epoch": 949.23,
      "learning_rate": 0.00511444972435484,
      "loss": 0.4592,
      "step": 588520
    },
    {
      "epoch": 949.26,
      "learning_rate": 0.005111223921129034,
      "loss": 0.4549,
      "step": 588540
    },
    {
      "epoch": 949.29,
      "learning_rate": 0.005107998117903229,
      "loss": 0.4648,
      "step": 588560
    },
    {
      "epoch": 949.32,
      "learning_rate": 0.005104772314677423,
      "loss": 0.4645,
      "step": 588580
    },
    {
      "epoch": 949.35,
      "learning_rate": 0.005101546511451617,
      "loss": 0.468,
      "step": 588600
    },
    {
      "epoch": 949.39,
      "learning_rate": 0.005098320708225811,
      "loss": 0.4555,
      "step": 588620
    },
    {
      "epoch": 949.42,
      "learning_rate": 0.005095094905000005,
      "loss": 0.4775,
      "step": 588640
    },
    {
      "epoch": 949.45,
      "learning_rate": 0.005091869101774189,
      "loss": 0.4705,
      "step": 588660
    },
    {
      "epoch": 949.48,
      "learning_rate": 0.0050886432985483825,
      "loss": 0.4653,
      "step": 588680
    },
    {
      "epoch": 949.52,
      "learning_rate": 0.005085417495322577,
      "loss": 0.4552,
      "step": 588700
    },
    {
      "epoch": 949.55,
      "learning_rate": 0.005082191692096771,
      "loss": 0.4641,
      "step": 588720
    },
    {
      "epoch": 949.58,
      "learning_rate": 0.005078965888870966,
      "loss": 0.4691,
      "step": 588740
    },
    {
      "epoch": 949.61,
      "learning_rate": 0.00507574008564516,
      "loss": 0.469,
      "step": 588760
    },
    {
      "epoch": 949.65,
      "learning_rate": 0.005072514282419355,
      "loss": 0.474,
      "step": 588780
    },
    {
      "epoch": 949.68,
      "learning_rate": 0.0050692884791935485,
      "loss": 0.4702,
      "step": 588800
    },
    {
      "epoch": 949.71,
      "learning_rate": 0.005066062675967742,
      "loss": 0.4645,
      "step": 588820
    },
    {
      "epoch": 949.74,
      "learning_rate": 0.005062836872741937,
      "loss": 0.4707,
      "step": 588840
    },
    {
      "epoch": 949.77,
      "learning_rate": 0.005059611069516131,
      "loss": 0.4632,
      "step": 588860
    },
    {
      "epoch": 949.81,
      "learning_rate": 0.005056385266290326,
      "loss": 0.4632,
      "step": 588880
    },
    {
      "epoch": 949.84,
      "learning_rate": 0.00505315946306452,
      "loss": 0.4586,
      "step": 588900
    },
    {
      "epoch": 949.87,
      "learning_rate": 0.005049933659838714,
      "loss": 0.4694,
      "step": 588920
    },
    {
      "epoch": 949.9,
      "learning_rate": 0.005046707856612908,
      "loss": 0.4718,
      "step": 588940
    },
    {
      "epoch": 949.94,
      "learning_rate": 0.005043482053387102,
      "loss": 0.4659,
      "step": 588960
    },
    {
      "epoch": 949.97,
      "learning_rate": 0.005040256250161286,
      "loss": 0.4718,
      "step": 588980
    },
    {
      "epoch": 950.0,
      "learning_rate": 0.00503703044693548,
      "loss": 0.475,
      "step": 589000
    },
    {
      "epoch": 950.0,
      "eval_accuracy": {
        "accuracy": 0.7947857310124112
      },
      "eval_loss": 0.8330573439598083,
      "eval_runtime": 4.5038,
      "eval_samples_per_second": 2844.478,
      "eval_steps_per_second": 44.629,
      "step": 589000
    },
    {
      "epoch": 950.03,
      "learning_rate": 0.005033804643709674,
      "loss": 0.4637,
      "step": 589020
    },
    {
      "epoch": 950.06,
      "learning_rate": 0.005030578840483868,
      "loss": 0.4733,
      "step": 589040
    },
    {
      "epoch": 950.1,
      "learning_rate": 0.005027353037258063,
      "loss": 0.4665,
      "step": 589060
    },
    {
      "epoch": 950.13,
      "learning_rate": 0.005024127234032257,
      "loss": 0.4643,
      "step": 589080
    },
    {
      "epoch": 950.16,
      "learning_rate": 0.005020901430806452,
      "loss": 0.4621,
      "step": 589100
    },
    {
      "epoch": 950.19,
      "learning_rate": 0.0050176756275806455,
      "loss": 0.4715,
      "step": 589120
    },
    {
      "epoch": 950.23,
      "learning_rate": 0.005014449824354839,
      "loss": 0.4592,
      "step": 589140
    },
    {
      "epoch": 950.26,
      "learning_rate": 0.005011224021129034,
      "loss": 0.4671,
      "step": 589160
    },
    {
      "epoch": 950.29,
      "learning_rate": 0.005007998217903228,
      "loss": 0.4617,
      "step": 589180
    },
    {
      "epoch": 950.32,
      "learning_rate": 0.005004772414677423,
      "loss": 0.4755,
      "step": 589200
    },
    {
      "epoch": 950.35,
      "learning_rate": 0.005001546611451617,
      "loss": 0.4653,
      "step": 589220
    },
    {
      "epoch": 950.39,
      "learning_rate": 0.0049983208082258115,
      "loss": 0.4632,
      "step": 589240
    },
    {
      "epoch": 950.42,
      "learning_rate": 0.004995095005000005,
      "loss": 0.4692,
      "step": 589260
    },
    {
      "epoch": 950.45,
      "learning_rate": 0.004991869201774189,
      "loss": 0.4609,
      "step": 589280
    },
    {
      "epoch": 950.48,
      "learning_rate": 0.004988643398548383,
      "loss": 0.4654,
      "step": 589300
    },
    {
      "epoch": 950.52,
      "learning_rate": 0.0049854175953225775,
      "loss": 0.4678,
      "step": 589320
    },
    {
      "epoch": 950.55,
      "learning_rate": 0.004982191792096771,
      "loss": 0.4726,
      "step": 589340
    },
    {
      "epoch": 950.58,
      "learning_rate": 0.004978965988870965,
      "loss": 0.4637,
      "step": 589360
    },
    {
      "epoch": 950.61,
      "learning_rate": 0.00497574018564516,
      "loss": 0.4562,
      "step": 589380
    },
    {
      "epoch": 950.65,
      "learning_rate": 0.004972514382419354,
      "loss": 0.4617,
      "step": 589400
    },
    {
      "epoch": 950.68,
      "learning_rate": 0.004969288579193549,
      "loss": 0.4665,
      "step": 589420
    },
    {
      "epoch": 950.71,
      "learning_rate": 0.004966062775967743,
      "loss": 0.4584,
      "step": 589440
    },
    {
      "epoch": 950.74,
      "learning_rate": 0.004962836972741937,
      "loss": 0.4671,
      "step": 589460
    },
    {
      "epoch": 950.77,
      "learning_rate": 0.004959611169516131,
      "loss": 0.4673,
      "step": 589480
    },
    {
      "epoch": 950.81,
      "learning_rate": 0.004956385366290325,
      "loss": 0.4656,
      "step": 589500
    },
    {
      "epoch": 950.84,
      "learning_rate": 0.00495315956306452,
      "loss": 0.467,
      "step": 589520
    },
    {
      "epoch": 950.87,
      "learning_rate": 0.004949933759838714,
      "loss": 0.4732,
      "step": 589540
    },
    {
      "epoch": 950.9,
      "learning_rate": 0.0049467079566129085,
      "loss": 0.4668,
      "step": 589560
    },
    {
      "epoch": 950.94,
      "learning_rate": 0.004943482153387102,
      "loss": 0.4697,
      "step": 589580
    },
    {
      "epoch": 950.97,
      "learning_rate": 0.004940256350161286,
      "loss": 0.4689,
      "step": 589600
    },
    {
      "epoch": 951.0,
      "learning_rate": 0.004937191837096776,
      "loss": 0.4779,
      "step": 589620
    },
    {
      "epoch": 951.0,
      "eval_accuracy": {
        "accuracy": 0.7965810631488565
      },
      "eval_loss": 0.8261306881904602,
      "eval_runtime": 3.2116,
      "eval_samples_per_second": 3988.971,
      "eval_steps_per_second": 62.586,
      "step": 589620
    },
    {
      "epoch": 951.03,
      "learning_rate": 0.004933966033870971,
      "loss": 0.4619,
      "step": 589640
    },
    {
      "epoch": 951.06,
      "learning_rate": 0.004930740230645165,
      "loss": 0.464,
      "step": 589660
    },
    {
      "epoch": 951.1,
      "learning_rate": 0.0049275144274193595,
      "loss": 0.4646,
      "step": 589680
    },
    {
      "epoch": 951.13,
      "learning_rate": 0.004924288624193553,
      "loss": 0.4643,
      "step": 589700
    },
    {
      "epoch": 951.16,
      "learning_rate": 0.004921062820967747,
      "loss": 0.4656,
      "step": 589720
    },
    {
      "epoch": 951.19,
      "learning_rate": 0.004917837017741931,
      "loss": 0.4664,
      "step": 589740
    },
    {
      "epoch": 951.23,
      "learning_rate": 0.004914611214516125,
      "loss": 0.4618,
      "step": 589760
    },
    {
      "epoch": 951.26,
      "learning_rate": 0.004911385411290319,
      "loss": 0.4629,
      "step": 589780
    },
    {
      "epoch": 951.29,
      "learning_rate": 0.004908159608064513,
      "loss": 0.4672,
      "step": 589800
    },
    {
      "epoch": 951.32,
      "learning_rate": 0.004904933804838708,
      "loss": 0.4633,
      "step": 589820
    },
    {
      "epoch": 951.35,
      "learning_rate": 0.004901708001612902,
      "loss": 0.4639,
      "step": 589840
    },
    {
      "epoch": 951.39,
      "learning_rate": 0.004898482198387097,
      "loss": 0.4623,
      "step": 589860
    },
    {
      "epoch": 951.42,
      "learning_rate": 0.004895256395161291,
      "loss": 0.4678,
      "step": 589880
    },
    {
      "epoch": 951.45,
      "learning_rate": 0.0048920305919354845,
      "loss": 0.4594,
      "step": 589900
    },
    {
      "epoch": 951.48,
      "learning_rate": 0.004888804788709679,
      "loss": 0.4651,
      "step": 589920
    },
    {
      "epoch": 951.52,
      "learning_rate": 0.004885578985483873,
      "loss": 0.4762,
      "step": 589940
    },
    {
      "epoch": 951.55,
      "learning_rate": 0.004882353182258068,
      "loss": 0.473,
      "step": 589960
    },
    {
      "epoch": 951.58,
      "learning_rate": 0.004879127379032262,
      "loss": 0.4745,
      "step": 589980
    },
    {
      "epoch": 951.61,
      "learning_rate": 0.0048759015758064565,
      "loss": 0.4729,
      "step": 590000
    },
    {
      "epoch": 951.65,
      "learning_rate": 0.00487267577258065,
      "loss": 0.4651,
      "step": 590020
    },
    {
      "epoch": 951.68,
      "learning_rate": 0.004869449969354834,
      "loss": 0.4586,
      "step": 590040
    },
    {
      "epoch": 951.71,
      "learning_rate": 0.004866224166129028,
      "loss": 0.4769,
      "step": 590060
    },
    {
      "epoch": 951.74,
      "learning_rate": 0.004862998362903222,
      "loss": 0.4652,
      "step": 590080
    },
    {
      "epoch": 951.77,
      "learning_rate": 0.0048597725596774164,
      "loss": 0.4589,
      "step": 590100
    },
    {
      "epoch": 951.81,
      "learning_rate": 0.00485654675645161,
      "loss": 0.4669,
      "step": 590120
    },
    {
      "epoch": 951.84,
      "learning_rate": 0.004853320953225805,
      "loss": 0.4549,
      "step": 590140
    },
    {
      "epoch": 951.87,
      "learning_rate": 0.004850095149999999,
      "loss": 0.4681,
      "step": 590160
    },
    {
      "epoch": 951.9,
      "learning_rate": 0.004846869346774194,
      "loss": 0.4791,
      "step": 590180
    },
    {
      "epoch": 951.94,
      "learning_rate": 0.004843643543548388,
      "loss": 0.4607,
      "step": 590200
    },
    {
      "epoch": 951.97,
      "learning_rate": 0.0048404177403225815,
      "loss": 0.4616,
      "step": 590220
    },
    {
      "epoch": 952.0,
      "learning_rate": 0.004837191937096776,
      "loss": 0.459,
      "step": 590240
    },
    {
      "epoch": 952.0,
      "eval_accuracy": {
        "accuracy": 0.796815236905784
      },
      "eval_loss": 0.8257982134819031,
      "eval_runtime": 3.1859,
      "eval_samples_per_second": 4021.144,
      "eval_steps_per_second": 63.09,
      "step": 590240
    },
    {
      "epoch": 952.03,
      "learning_rate": 0.00483396613387097,
      "loss": 0.4617,
      "step": 590260
    },
    {
      "epoch": 952.06,
      "learning_rate": 0.004830740330645165,
      "loss": 0.4741,
      "step": 590280
    },
    {
      "epoch": 952.1,
      "learning_rate": 0.004827514527419359,
      "loss": 0.4619,
      "step": 590300
    },
    {
      "epoch": 952.13,
      "learning_rate": 0.004824288724193554,
      "loss": 0.4702,
      "step": 590320
    },
    {
      "epoch": 952.16,
      "learning_rate": 0.0048210629209677475,
      "loss": 0.4692,
      "step": 590340
    },
    {
      "epoch": 952.19,
      "learning_rate": 0.004817837117741931,
      "loss": 0.4685,
      "step": 590360
    },
    {
      "epoch": 952.23,
      "learning_rate": 0.004814611314516125,
      "loss": 0.4618,
      "step": 590380
    },
    {
      "epoch": 952.26,
      "learning_rate": 0.00481138551129032,
      "loss": 0.4693,
      "step": 590400
    },
    {
      "epoch": 952.29,
      "learning_rate": 0.0048081597080645135,
      "loss": 0.4659,
      "step": 590420
    },
    {
      "epoch": 952.32,
      "learning_rate": 0.004804933904838707,
      "loss": 0.4573,
      "step": 590440
    },
    {
      "epoch": 952.35,
      "learning_rate": 0.004801708101612902,
      "loss": 0.4698,
      "step": 590460
    },
    {
      "epoch": 952.39,
      "learning_rate": 0.004798482298387096,
      "loss": 0.4606,
      "step": 590480
    },
    {
      "epoch": 952.42,
      "learning_rate": 0.004795256495161291,
      "loss": 0.463,
      "step": 590500
    },
    {
      "epoch": 952.45,
      "learning_rate": 0.004792030691935485,
      "loss": 0.4682,
      "step": 590520
    },
    {
      "epoch": 952.48,
      "learning_rate": 0.0047888048887096794,
      "loss": 0.4602,
      "step": 590540
    },
    {
      "epoch": 952.52,
      "learning_rate": 0.004785579085483873,
      "loss": 0.4653,
      "step": 590560
    },
    {
      "epoch": 952.55,
      "learning_rate": 0.004782353282258067,
      "loss": 0.466,
      "step": 590580
    },
    {
      "epoch": 952.58,
      "learning_rate": 0.004779127479032262,
      "loss": 0.4613,
      "step": 590600
    },
    {
      "epoch": 952.61,
      "learning_rate": 0.004775901675806456,
      "loss": 0.4596,
      "step": 590620
    },
    {
      "epoch": 952.65,
      "learning_rate": 0.004772675872580651,
      "loss": 0.4581,
      "step": 590640
    },
    {
      "epoch": 952.68,
      "learning_rate": 0.0047694500693548445,
      "loss": 0.4694,
      "step": 590660
    },
    {
      "epoch": 952.71,
      "learning_rate": 0.004766224266129028,
      "loss": 0.4646,
      "step": 590680
    },
    {
      "epoch": 952.74,
      "learning_rate": 0.004762998462903222,
      "loss": 0.4666,
      "step": 590700
    },
    {
      "epoch": 952.77,
      "learning_rate": 0.004759772659677417,
      "loss": 0.4616,
      "step": 590720
    },
    {
      "epoch": 952.81,
      "learning_rate": 0.0047565468564516105,
      "loss": 0.4684,
      "step": 590740
    },
    {
      "epoch": 952.84,
      "learning_rate": 0.004753321053225804,
      "loss": 0.4676,
      "step": 590760
    },
    {
      "epoch": 952.87,
      "learning_rate": 0.004750095249999999,
      "loss": 0.4699,
      "step": 590780
    },
    {
      "epoch": 952.9,
      "learning_rate": 0.004746869446774193,
      "loss": 0.4672,
      "step": 590800
    },
    {
      "epoch": 952.94,
      "learning_rate": 0.004743643643548388,
      "loss": 0.4631,
      "step": 590820
    },
    {
      "epoch": 952.97,
      "learning_rate": 0.004740417840322582,
      "loss": 0.4645,
      "step": 590840
    },
    {
      "epoch": 953.0,
      "learning_rate": 0.0047371920370967765,
      "loss": 0.4614,
      "step": 590860
    },
    {
      "epoch": 953.0,
      "eval_accuracy": {
        "accuracy": 0.7976738740145187
      },
      "eval_loss": 0.8256687521934509,
      "eval_runtime": 3.1225,
      "eval_samples_per_second": 4102.841,
      "eval_steps_per_second": 64.372,
      "step": 590860
    },
    {
      "epoch": 953.03,
      "learning_rate": 0.00473396623387097,
      "loss": 0.4618,
      "step": 590880
    },
    {
      "epoch": 953.06,
      "learning_rate": 0.004730740430645164,
      "loss": 0.4617,
      "step": 590900
    },
    {
      "epoch": 953.1,
      "learning_rate": 0.004727514627419359,
      "loss": 0.4591,
      "step": 590920
    },
    {
      "epoch": 953.13,
      "learning_rate": 0.004724288824193553,
      "loss": 0.4701,
      "step": 590940
    },
    {
      "epoch": 953.16,
      "learning_rate": 0.004721063020967748,
      "loss": 0.4614,
      "step": 590960
    },
    {
      "epoch": 953.19,
      "learning_rate": 0.00471783721774193,
      "loss": 0.4745,
      "step": 590980
    },
    {
      "epoch": 953.23,
      "learning_rate": 0.004714611414516125,
      "loss": 0.4688,
      "step": 591000
    },
    {
      "epoch": 953.26,
      "learning_rate": 0.004711385611290319,
      "loss": 0.4619,
      "step": 591020
    },
    {
      "epoch": 953.29,
      "learning_rate": 0.004708159808064514,
      "loss": 0.459,
      "step": 591040
    },
    {
      "epoch": 953.32,
      "learning_rate": 0.004704934004838708,
      "loss": 0.4645,
      "step": 591060
    },
    {
      "epoch": 953.35,
      "learning_rate": 0.0047017082016129015,
      "loss": 0.4745,
      "step": 591080
    },
    {
      "epoch": 953.39,
      "learning_rate": 0.004698482398387096,
      "loss": 0.4702,
      "step": 591100
    },
    {
      "epoch": 953.42,
      "learning_rate": 0.00469525659516129,
      "loss": 0.4564,
      "step": 591120
    },
    {
      "epoch": 953.45,
      "learning_rate": 0.004692030791935485,
      "loss": 0.4678,
      "step": 591140
    },
    {
      "epoch": 953.48,
      "learning_rate": 0.004688804988709679,
      "loss": 0.4596,
      "step": 591160
    },
    {
      "epoch": 953.52,
      "learning_rate": 0.0046855791854838735,
      "loss": 0.4624,
      "step": 591180
    },
    {
      "epoch": 953.55,
      "learning_rate": 0.004682353382258067,
      "loss": 0.4674,
      "step": 591200
    },
    {
      "epoch": 953.58,
      "learning_rate": 0.004679127579032261,
      "loss": 0.4725,
      "step": 591220
    },
    {
      "epoch": 953.61,
      "learning_rate": 0.004675901775806456,
      "loss": 0.4623,
      "step": 591240
    },
    {
      "epoch": 953.65,
      "learning_rate": 0.00467267597258065,
      "loss": 0.4646,
      "step": 591260
    },
    {
      "epoch": 953.68,
      "learning_rate": 0.004669450169354845,
      "loss": 0.4639,
      "step": 591280
    },
    {
      "epoch": 953.71,
      "learning_rate": 0.004666224366129027,
      "loss": 0.4664,
      "step": 591300
    },
    {
      "epoch": 953.74,
      "learning_rate": 0.004662998562903222,
      "loss": 0.469,
      "step": 591320
    },
    {
      "epoch": 953.77,
      "learning_rate": 0.004659772759677416,
      "loss": 0.459,
      "step": 591340
    },
    {
      "epoch": 953.81,
      "learning_rate": 0.004656546956451611,
      "loss": 0.4624,
      "step": 591360
    },
    {
      "epoch": 953.84,
      "learning_rate": 0.004653321153225805,
      "loss": 0.4599,
      "step": 591380
    },
    {
      "epoch": 953.87,
      "learning_rate": 0.004650095349999999,
      "loss": 0.46,
      "step": 591400
    },
    {
      "epoch": 953.9,
      "learning_rate": 0.004646869546774193,
      "loss": 0.4668,
      "step": 591420
    },
    {
      "epoch": 953.94,
      "learning_rate": 0.004643643743548387,
      "loss": 0.4597,
      "step": 591440
    },
    {
      "epoch": 953.97,
      "learning_rate": 0.004640417940322582,
      "loss": 0.4671,
      "step": 591460
    },
    {
      "epoch": 954.0,
      "learning_rate": 0.004637192137096776,
      "loss": 0.47,
      "step": 591480
    },
    {
      "epoch": 954.0,
      "eval_accuracy": {
        "accuracy": 0.7973616423386153
      },
      "eval_loss": 0.82498699426651,
      "eval_runtime": 3.3586,
      "eval_samples_per_second": 3814.426,
      "eval_steps_per_second": 59.847,
      "step": 591480
    },
    {
      "epoch": 954.03,
      "learning_rate": 0.004633966333870971,
      "loss": 0.4691,
      "step": 591500
    },
    {
      "epoch": 954.06,
      "learning_rate": 0.0046307405306451645,
      "loss": 0.4603,
      "step": 591520
    },
    {
      "epoch": 954.1,
      "learning_rate": 0.004627514727419359,
      "loss": 0.4589,
      "step": 591540
    },
    {
      "epoch": 954.13,
      "learning_rate": 0.004624288924193553,
      "loss": 0.4625,
      "step": 591560
    },
    {
      "epoch": 954.16,
      "learning_rate": 0.004621063120967747,
      "loss": 0.4658,
      "step": 591580
    },
    {
      "epoch": 954.19,
      "learning_rate": 0.0046178373177419305,
      "loss": 0.4546,
      "step": 591600
    },
    {
      "epoch": 954.23,
      "learning_rate": 0.004614611514516124,
      "loss": 0.4614,
      "step": 591620
    },
    {
      "epoch": 954.26,
      "learning_rate": 0.004611385711290319,
      "loss": 0.4593,
      "step": 591640
    },
    {
      "epoch": 954.29,
      "learning_rate": 0.004608159908064513,
      "loss": 0.4703,
      "step": 591660
    },
    {
      "epoch": 954.32,
      "learning_rate": 0.004604934104838708,
      "loss": 0.4684,
      "step": 591680
    },
    {
      "epoch": 954.35,
      "learning_rate": 0.004601708301612902,
      "loss": 0.4669,
      "step": 591700
    },
    {
      "epoch": 954.39,
      "learning_rate": 0.0045984824983870964,
      "loss": 0.4626,
      "step": 591720
    },
    {
      "epoch": 954.42,
      "learning_rate": 0.00459525669516129,
      "loss": 0.4566,
      "step": 591740
    },
    {
      "epoch": 954.45,
      "learning_rate": 0.004592030891935484,
      "loss": 0.466,
      "step": 591760
    },
    {
      "epoch": 954.48,
      "learning_rate": 0.004588805088709679,
      "loss": 0.4595,
      "step": 591780
    },
    {
      "epoch": 954.52,
      "learning_rate": 0.004585579285483873,
      "loss": 0.4501,
      "step": 591800
    },
    {
      "epoch": 954.55,
      "learning_rate": 0.004582353482258068,
      "loss": 0.4589,
      "step": 591820
    },
    {
      "epoch": 954.58,
      "learning_rate": 0.0045791276790322615,
      "loss": 0.4628,
      "step": 591840
    },
    {
      "epoch": 954.61,
      "learning_rate": 0.004575901875806456,
      "loss": 0.4672,
      "step": 591860
    },
    {
      "epoch": 954.65,
      "learning_rate": 0.00457267607258065,
      "loss": 0.4673,
      "step": 591880
    },
    {
      "epoch": 954.68,
      "learning_rate": 0.004569450269354844,
      "loss": 0.4683,
      "step": 591900
    },
    {
      "epoch": 954.71,
      "learning_rate": 0.0045662244661290275,
      "loss": 0.4741,
      "step": 591920
    },
    {
      "epoch": 954.74,
      "learning_rate": 0.004562998662903221,
      "loss": 0.4707,
      "step": 591940
    },
    {
      "epoch": 954.77,
      "learning_rate": 0.004559772859677416,
      "loss": 0.4595,
      "step": 591960
    },
    {
      "epoch": 954.81,
      "learning_rate": 0.00455654705645161,
      "loss": 0.4619,
      "step": 591980
    },
    {
      "epoch": 954.84,
      "learning_rate": 0.004553321253225805,
      "loss": 0.4591,
      "step": 592000
    },
    {
      "epoch": 954.87,
      "learning_rate": 0.004550095449999999,
      "loss": 0.4617,
      "step": 592020
    },
    {
      "epoch": 954.9,
      "learning_rate": 0.0045468696467741935,
      "loss": 0.4628,
      "step": 592040
    },
    {
      "epoch": 954.94,
      "learning_rate": 0.004543643843548387,
      "loss": 0.4791,
      "step": 592060
    },
    {
      "epoch": 954.97,
      "learning_rate": 0.004540418040322581,
      "loss": 0.4664,
      "step": 592080
    },
    {
      "epoch": 955.0,
      "learning_rate": 0.004537192237096776,
      "loss": 0.4772,
      "step": 592100
    },
    {
      "epoch": 955.0,
      "eval_accuracy": {
        "accuracy": 0.7992350323940364
      },
      "eval_loss": 0.8228031992912292,
      "eval_runtime": 4.0307,
      "eval_samples_per_second": 3178.351,
      "eval_steps_per_second": 49.867,
      "step": 592100
    },
    {
      "epoch": 955.03,
      "learning_rate": 0.00453396643387097,
      "loss": 0.4652,
      "step": 592120
    },
    {
      "epoch": 955.06,
      "learning_rate": 0.004530740630645165,
      "loss": 0.4778,
      "step": 592140
    },
    {
      "epoch": 955.1,
      "learning_rate": 0.004527514827419359,
      "loss": 0.4572,
      "step": 592160
    },
    {
      "epoch": 955.13,
      "learning_rate": 0.004524289024193553,
      "loss": 0.4685,
      "step": 592180
    },
    {
      "epoch": 955.16,
      "learning_rate": 0.004521063220967747,
      "loss": 0.4597,
      "step": 592200
    },
    {
      "epoch": 955.19,
      "learning_rate": 0.004517837417741931,
      "loss": 0.4692,
      "step": 592220
    },
    {
      "epoch": 955.23,
      "learning_rate": 0.004514611614516125,
      "loss": 0.4626,
      "step": 592240
    },
    {
      "epoch": 955.26,
      "learning_rate": 0.004511385811290319,
      "loss": 0.4669,
      "step": 592260
    },
    {
      "epoch": 955.29,
      "learning_rate": 0.004508160008064513,
      "loss": 0.4636,
      "step": 592280
    },
    {
      "epoch": 955.32,
      "learning_rate": 0.004504934204838707,
      "loss": 0.4697,
      "step": 592300
    },
    {
      "epoch": 955.35,
      "learning_rate": 0.004501708401612902,
      "loss": 0.4554,
      "step": 592320
    },
    {
      "epoch": 955.39,
      "learning_rate": 0.004498482598387096,
      "loss": 0.4599,
      "step": 592340
    },
    {
      "epoch": 955.42,
      "learning_rate": 0.0044952567951612905,
      "loss": 0.4561,
      "step": 592360
    },
    {
      "epoch": 955.45,
      "learning_rate": 0.004492030991935484,
      "loss": 0.4598,
      "step": 592380
    },
    {
      "epoch": 955.48,
      "learning_rate": 0.004488805188709679,
      "loss": 0.4662,
      "step": 592400
    },
    {
      "epoch": 955.52,
      "learning_rate": 0.004485579385483873,
      "loss": 0.4586,
      "step": 592420
    },
    {
      "epoch": 955.55,
      "learning_rate": 0.004482353582258067,
      "loss": 0.4611,
      "step": 592440
    },
    {
      "epoch": 955.58,
      "learning_rate": 0.004479127779032262,
      "loss": 0.4589,
      "step": 592460
    },
    {
      "epoch": 955.61,
      "learning_rate": 0.004475901975806456,
      "loss": 0.4712,
      "step": 592480
    },
    {
      "epoch": 955.65,
      "learning_rate": 0.00447267617258065,
      "loss": 0.4768,
      "step": 592500
    },
    {
      "epoch": 955.68,
      "learning_rate": 0.004469450369354844,
      "loss": 0.4708,
      "step": 592520
    },
    {
      "epoch": 955.71,
      "learning_rate": 0.004466224566129028,
      "loss": 0.4546,
      "step": 592540
    },
    {
      "epoch": 955.74,
      "learning_rate": 0.004462998762903222,
      "loss": 0.464,
      "step": 592560
    },
    {
      "epoch": 955.77,
      "learning_rate": 0.004459772959677416,
      "loss": 0.472,
      "step": 592580
    },
    {
      "epoch": 955.81,
      "learning_rate": 0.00445654715645161,
      "loss": 0.4661,
      "step": 592600
    },
    {
      "epoch": 955.84,
      "learning_rate": 0.004453321353225804,
      "loss": 0.4554,
      "step": 592620
    },
    {
      "epoch": 955.87,
      "learning_rate": 0.004450095549999999,
      "loss": 0.4633,
      "step": 592640
    },
    {
      "epoch": 955.9,
      "learning_rate": 0.004446869746774193,
      "loss": 0.4558,
      "step": 592660
    },
    {
      "epoch": 955.94,
      "learning_rate": 0.004443643943548388,
      "loss": 0.4578,
      "step": 592680
    },
    {
      "epoch": 955.97,
      "learning_rate": 0.0044404181403225815,
      "loss": 0.463,
      "step": 592700
    },
    {
      "epoch": 956.0,
      "learning_rate": 0.004437192337096776,
      "loss": 0.4662,
      "step": 592720
    },
    {
      "epoch": 956.0,
      "eval_accuracy": {
        "accuracy": 0.796815236905784
      },
      "eval_loss": 0.8207333087921143,
      "eval_runtime": 3.7324,
      "eval_samples_per_second": 3432.386,
      "eval_steps_per_second": 53.853,
      "step": 592720
    },
    {
      "epoch": 956.03,
      "learning_rate": 0.00443396653387097,
      "loss": 0.4593,
      "step": 592740
    },
    {
      "epoch": 956.06,
      "learning_rate": 0.004430740730645164,
      "loss": 0.4679,
      "step": 592760
    },
    {
      "epoch": 956.1,
      "learning_rate": 0.004427514927419359,
      "loss": 0.4621,
      "step": 592780
    },
    {
      "epoch": 956.13,
      "learning_rate": 0.004424289124193553,
      "loss": 0.458,
      "step": 592800
    },
    {
      "epoch": 956.16,
      "learning_rate": 0.004421063320967747,
      "loss": 0.4561,
      "step": 592820
    },
    {
      "epoch": 956.19,
      "learning_rate": 0.004417837517741941,
      "loss": 0.4627,
      "step": 592840
    },
    {
      "epoch": 956.23,
      "learning_rate": 0.004414611714516125,
      "loss": 0.4638,
      "step": 592860
    },
    {
      "epoch": 956.26,
      "learning_rate": 0.004411385911290319,
      "loss": 0.466,
      "step": 592880
    },
    {
      "epoch": 956.29,
      "learning_rate": 0.0044081601080645134,
      "loss": 0.4643,
      "step": 592900
    },
    {
      "epoch": 956.32,
      "learning_rate": 0.004404934304838707,
      "loss": 0.4644,
      "step": 592920
    },
    {
      "epoch": 956.35,
      "learning_rate": 0.004401708501612901,
      "loss": 0.4609,
      "step": 592940
    },
    {
      "epoch": 956.39,
      "learning_rate": 0.004398482698387096,
      "loss": 0.4655,
      "step": 592960
    },
    {
      "epoch": 956.42,
      "learning_rate": 0.00439525689516129,
      "loss": 0.4614,
      "step": 592980
    },
    {
      "epoch": 956.45,
      "learning_rate": 0.004392031091935485,
      "loss": 0.4629,
      "step": 593000
    },
    {
      "epoch": 956.48,
      "learning_rate": 0.0043888052887096785,
      "loss": 0.4557,
      "step": 593020
    },
    {
      "epoch": 956.52,
      "learning_rate": 0.004385579485483873,
      "loss": 0.4549,
      "step": 593040
    },
    {
      "epoch": 956.55,
      "learning_rate": 0.004382353682258067,
      "loss": 0.4731,
      "step": 593060
    },
    {
      "epoch": 956.58,
      "learning_rate": 0.004379127879032261,
      "loss": 0.4669,
      "step": 593080
    },
    {
      "epoch": 956.61,
      "learning_rate": 0.004375902075806456,
      "loss": 0.467,
      "step": 593100
    },
    {
      "epoch": 956.65,
      "learning_rate": 0.00437267627258065,
      "loss": 0.4683,
      "step": 593120
    },
    {
      "epoch": 956.68,
      "learning_rate": 0.0043694504693548445,
      "loss": 0.4609,
      "step": 593140
    },
    {
      "epoch": 956.71,
      "learning_rate": 0.004366224666129027,
      "loss": 0.458,
      "step": 593160
    },
    {
      "epoch": 956.74,
      "learning_rate": 0.004362998862903222,
      "loss": 0.4571,
      "step": 593180
    },
    {
      "epoch": 956.77,
      "learning_rate": 0.004359773059677416,
      "loss": 0.4636,
      "step": 593200
    },
    {
      "epoch": 956.81,
      "learning_rate": 0.0043565472564516105,
      "loss": 0.4639,
      "step": 593220
    },
    {
      "epoch": 956.84,
      "learning_rate": 0.004353321453225804,
      "loss": 0.4644,
      "step": 593240
    },
    {
      "epoch": 956.87,
      "learning_rate": 0.004350095649999998,
      "loss": 0.4727,
      "step": 593260
    },
    {
      "epoch": 956.9,
      "learning_rate": 0.004346869846774193,
      "loss": 0.4645,
      "step": 593280
    },
    {
      "epoch": 956.94,
      "learning_rate": 0.004343644043548387,
      "loss": 0.4524,
      "step": 593300
    },
    {
      "epoch": 956.97,
      "learning_rate": 0.004340418240322582,
      "loss": 0.4612,
      "step": 593320
    },
    {
      "epoch": 957.0,
      "learning_rate": 0.0043373537272580615,
      "loss": 0.4683,
      "step": 593340
    },
    {
      "epoch": 957.0,
      "eval_accuracy": {
        "accuracy": 0.7974397002575911
      },
      "eval_loss": 0.8221474885940552,
      "eval_runtime": 3.0643,
      "eval_samples_per_second": 4180.734,
      "eval_steps_per_second": 65.594,
      "step": 593340
    },
    {
      "epoch": 957.03,
      "learning_rate": 0.004334127924032255,
      "loss": 0.461,
      "step": 593360
    },
    {
      "epoch": 957.06,
      "learning_rate": 0.004330902120806449,
      "loss": 0.4699,
      "step": 593380
    },
    {
      "epoch": 957.1,
      "learning_rate": 0.004327676317580644,
      "loss": 0.4549,
      "step": 593400
    },
    {
      "epoch": 957.13,
      "learning_rate": 0.004324450514354838,
      "loss": 0.4635,
      "step": 593420
    },
    {
      "epoch": 957.16,
      "learning_rate": 0.004321224711129033,
      "loss": 0.4768,
      "step": 593440
    },
    {
      "epoch": 957.19,
      "learning_rate": 0.0043179989079032265,
      "loss": 0.4564,
      "step": 593460
    },
    {
      "epoch": 957.23,
      "learning_rate": 0.004314773104677421,
      "loss": 0.4645,
      "step": 593480
    },
    {
      "epoch": 957.26,
      "learning_rate": 0.004311547301451615,
      "loss": 0.4636,
      "step": 593500
    },
    {
      "epoch": 957.29,
      "learning_rate": 0.004308321498225809,
      "loss": 0.462,
      "step": 593520
    },
    {
      "epoch": 957.32,
      "learning_rate": 0.004305095695000004,
      "loss": 0.4663,
      "step": 593540
    },
    {
      "epoch": 957.35,
      "learning_rate": 0.004301869891774198,
      "loss": 0.4713,
      "step": 593560
    },
    {
      "epoch": 957.39,
      "learning_rate": 0.0042986440885483925,
      "loss": 0.4654,
      "step": 593580
    },
    {
      "epoch": 957.42,
      "learning_rate": 0.004295418285322586,
      "loss": 0.4605,
      "step": 593600
    },
    {
      "epoch": 957.45,
      "learning_rate": 0.00429219248209677,
      "loss": 0.4693,
      "step": 593620
    },
    {
      "epoch": 957.48,
      "learning_rate": 0.004288966678870964,
      "loss": 0.4703,
      "step": 593640
    },
    {
      "epoch": 957.52,
      "learning_rate": 0.0042857408756451585,
      "loss": 0.4543,
      "step": 593660
    },
    {
      "epoch": 957.55,
      "learning_rate": 0.004282515072419352,
      "loss": 0.4543,
      "step": 593680
    },
    {
      "epoch": 957.58,
      "learning_rate": 0.004279289269193546,
      "loss": 0.4673,
      "step": 593700
    },
    {
      "epoch": 957.61,
      "learning_rate": 0.004276063465967741,
      "loss": 0.4511,
      "step": 593720
    },
    {
      "epoch": 957.65,
      "learning_rate": 0.004272837662741935,
      "loss": 0.4583,
      "step": 593740
    },
    {
      "epoch": 957.68,
      "learning_rate": 0.00426961185951613,
      "loss": 0.4593,
      "step": 593760
    },
    {
      "epoch": 957.71,
      "learning_rate": 0.004266386056290324,
      "loss": 0.4564,
      "step": 593780
    },
    {
      "epoch": 957.74,
      "learning_rate": 0.004263160253064518,
      "loss": 0.4644,
      "step": 593800
    },
    {
      "epoch": 957.77,
      "learning_rate": 0.004259934449838712,
      "loss": 0.4619,
      "step": 593820
    },
    {
      "epoch": 957.81,
      "learning_rate": 0.004256708646612906,
      "loss": 0.4575,
      "step": 593840
    },
    {
      "epoch": 957.84,
      "learning_rate": 0.004253482843387101,
      "loss": 0.4689,
      "step": 593860
    },
    {
      "epoch": 957.87,
      "learning_rate": 0.004250257040161295,
      "loss": 0.4617,
      "step": 593880
    },
    {
      "epoch": 957.9,
      "learning_rate": 0.0042470312369354895,
      "loss": 0.464,
      "step": 593900
    },
    {
      "epoch": 957.94,
      "learning_rate": 0.004243805433709672,
      "loss": 0.4675,
      "step": 593920
    },
    {
      "epoch": 957.97,
      "learning_rate": 0.004240579630483867,
      "loss": 0.4623,
      "step": 593940
    },
    {
      "epoch": 958.0,
      "learning_rate": 0.004237353827258061,
      "loss": 0.4591,
      "step": 593960
    },
    {
      "epoch": 958.0,
      "eval_accuracy": {
        "accuracy": 0.7986105690422294
      },
      "eval_loss": 0.825223445892334,
      "eval_runtime": 4.0164,
      "eval_samples_per_second": 3189.633,
      "eval_steps_per_second": 50.044,
      "step": 593960
    },
    {
      "epoch": 958.03,
      "learning_rate": 0.0042341280240322555,
      "loss": 0.4632,
      "step": 593980
    },
    {
      "epoch": 958.06,
      "learning_rate": 0.0042309022208064494,
      "loss": 0.4618,
      "step": 594000
    },
    {
      "epoch": 958.1,
      "learning_rate": 0.004227676417580643,
      "loss": 0.4719,
      "step": 594020
    },
    {
      "epoch": 958.13,
      "learning_rate": 0.004224450614354838,
      "loss": 0.4493,
      "step": 594040
    },
    {
      "epoch": 958.16,
      "learning_rate": 0.004221224811129032,
      "loss": 0.4627,
      "step": 594060
    },
    {
      "epoch": 958.19,
      "learning_rate": 0.004217999007903227,
      "loss": 0.4564,
      "step": 594080
    },
    {
      "epoch": 958.23,
      "learning_rate": 0.004214773204677421,
      "loss": 0.4504,
      "step": 594100
    },
    {
      "epoch": 958.26,
      "learning_rate": 0.004211547401451615,
      "loss": 0.4614,
      "step": 594120
    },
    {
      "epoch": 958.29,
      "learning_rate": 0.004208321598225809,
      "loss": 0.4579,
      "step": 594140
    },
    {
      "epoch": 958.32,
      "learning_rate": 0.004205095795000003,
      "loss": 0.4617,
      "step": 594160
    },
    {
      "epoch": 958.35,
      "learning_rate": 0.004201869991774198,
      "loss": 0.4588,
      "step": 594180
    },
    {
      "epoch": 958.39,
      "learning_rate": 0.004198644188548392,
      "loss": 0.4655,
      "step": 594200
    },
    {
      "epoch": 958.42,
      "learning_rate": 0.004195418385322587,
      "loss": 0.461,
      "step": 594220
    },
    {
      "epoch": 958.45,
      "learning_rate": 0.004192192582096769,
      "loss": 0.4741,
      "step": 594240
    },
    {
      "epoch": 958.48,
      "learning_rate": 0.004188966778870964,
      "loss": 0.471,
      "step": 594260
    },
    {
      "epoch": 958.52,
      "learning_rate": 0.004185740975645158,
      "loss": 0.4675,
      "step": 594280
    },
    {
      "epoch": 958.55,
      "learning_rate": 0.004182515172419353,
      "loss": 0.4698,
      "step": 594300
    },
    {
      "epoch": 958.58,
      "learning_rate": 0.0041792893691935465,
      "loss": 0.4556,
      "step": 594320
    },
    {
      "epoch": 958.61,
      "learning_rate": 0.004176063565967741,
      "loss": 0.4642,
      "step": 594340
    },
    {
      "epoch": 958.65,
      "learning_rate": 0.004172837762741935,
      "loss": 0.4477,
      "step": 594360
    },
    {
      "epoch": 958.68,
      "learning_rate": 0.004169611959516129,
      "loss": 0.4612,
      "step": 594380
    },
    {
      "epoch": 958.71,
      "learning_rate": 0.004166386156290324,
      "loss": 0.4565,
      "step": 594400
    },
    {
      "epoch": 958.74,
      "learning_rate": 0.004163160353064518,
      "loss": 0.4617,
      "step": 594420
    },
    {
      "epoch": 958.77,
      "learning_rate": 0.0041599345498387124,
      "loss": 0.453,
      "step": 594440
    },
    {
      "epoch": 958.81,
      "learning_rate": 0.004156708746612906,
      "loss": 0.4758,
      "step": 594460
    },
    {
      "epoch": 958.84,
      "learning_rate": 0.004153482943387101,
      "loss": 0.4593,
      "step": 594480
    },
    {
      "epoch": 958.87,
      "learning_rate": 0.004150257140161295,
      "loss": 0.4671,
      "step": 594500
    },
    {
      "epoch": 958.9,
      "learning_rate": 0.004147031336935489,
      "loss": 0.4642,
      "step": 594520
    },
    {
      "epoch": 958.94,
      "learning_rate": 0.004143805533709672,
      "loss": 0.4604,
      "step": 594540
    },
    {
      "epoch": 958.97,
      "learning_rate": 0.004140579730483866,
      "loss": 0.4747,
      "step": 594560
    },
    {
      "epoch": 959.0,
      "learning_rate": 0.004137353927258061,
      "loss": 0.4573,
      "step": 594580
    },
    {
      "epoch": 959.0,
      "eval_accuracy": {
        "accuracy": 0.7975958160955429
      },
      "eval_loss": 0.821651816368103,
      "eval_runtime": 3.1698,
      "eval_samples_per_second": 4041.586,
      "eval_steps_per_second": 63.411,
      "step": 594580
    },
    {
      "epoch": 959.03,
      "learning_rate": 0.004134128124032255,
      "loss": 0.4679,
      "step": 594600
    },
    {
      "epoch": 959.06,
      "learning_rate": 0.00413090232080645,
      "loss": 0.4516,
      "step": 594620
    },
    {
      "epoch": 959.1,
      "learning_rate": 0.0041276765175806435,
      "loss": 0.4641,
      "step": 594640
    },
    {
      "epoch": 959.13,
      "learning_rate": 0.004124450714354838,
      "loss": 0.4567,
      "step": 594660
    },
    {
      "epoch": 959.16,
      "learning_rate": 0.004121224911129032,
      "loss": 0.4606,
      "step": 594680
    },
    {
      "epoch": 959.19,
      "learning_rate": 0.004117999107903226,
      "loss": 0.4684,
      "step": 594700
    },
    {
      "epoch": 959.23,
      "learning_rate": 0.004114773304677421,
      "loss": 0.4571,
      "step": 594720
    },
    {
      "epoch": 959.26,
      "learning_rate": 0.004111547501451615,
      "loss": 0.4663,
      "step": 594740
    },
    {
      "epoch": 959.29,
      "learning_rate": 0.0041083216982258095,
      "loss": 0.4724,
      "step": 594760
    },
    {
      "epoch": 959.32,
      "learning_rate": 0.004105095895000003,
      "loss": 0.4558,
      "step": 594780
    },
    {
      "epoch": 959.35,
      "learning_rate": 0.004101870091774198,
      "loss": 0.465,
      "step": 594800
    },
    {
      "epoch": 959.39,
      "learning_rate": 0.004098644288548392,
      "loss": 0.4652,
      "step": 594820
    },
    {
      "epoch": 959.42,
      "learning_rate": 0.004095418485322586,
      "loss": 0.4545,
      "step": 594840
    },
    {
      "epoch": 959.45,
      "learning_rate": 0.004092192682096769,
      "loss": 0.4612,
      "step": 594860
    },
    {
      "epoch": 959.48,
      "learning_rate": 0.004088966878870963,
      "loss": 0.4568,
      "step": 594880
    },
    {
      "epoch": 959.52,
      "learning_rate": 0.004085741075645158,
      "loss": 0.4618,
      "step": 594900
    },
    {
      "epoch": 959.55,
      "learning_rate": 0.004082515272419352,
      "loss": 0.4662,
      "step": 594920
    },
    {
      "epoch": 959.58,
      "learning_rate": 0.004079289469193547,
      "loss": 0.4669,
      "step": 594940
    },
    {
      "epoch": 959.61,
      "learning_rate": 0.004076063665967741,
      "loss": 0.4682,
      "step": 594960
    },
    {
      "epoch": 959.65,
      "learning_rate": 0.004072837862741935,
      "loss": 0.4678,
      "step": 594980
    },
    {
      "epoch": 959.68,
      "learning_rate": 0.004069612059516129,
      "loss": 0.455,
      "step": 595000
    },
    {
      "epoch": 959.71,
      "learning_rate": 0.004066386256290323,
      "loss": 0.4602,
      "step": 595020
    },
    {
      "epoch": 959.74,
      "learning_rate": 0.004063160453064518,
      "loss": 0.4689,
      "step": 595040
    },
    {
      "epoch": 959.77,
      "learning_rate": 0.004059934649838712,
      "loss": 0.4539,
      "step": 595060
    },
    {
      "epoch": 959.81,
      "learning_rate": 0.0040567088466129065,
      "loss": 0.4599,
      "step": 595080
    },
    {
      "epoch": 959.84,
      "learning_rate": 0.0040534830433871,
      "loss": 0.4547,
      "step": 595100
    },
    {
      "epoch": 959.87,
      "learning_rate": 0.004050257240161295,
      "loss": 0.4526,
      "step": 595120
    },
    {
      "epoch": 959.9,
      "learning_rate": 0.004047031436935489,
      "loss": 0.4611,
      "step": 595140
    },
    {
      "epoch": 959.94,
      "learning_rate": 0.004043805633709683,
      "loss": 0.4666,
      "step": 595160
    },
    {
      "epoch": 959.97,
      "learning_rate": 0.0040405798304838664,
      "loss": 0.4552,
      "step": 595180
    },
    {
      "epoch": 960.0,
      "learning_rate": 0.00403735402725806,
      "loss": 0.469,
      "step": 595200
    },
    {
      "epoch": 960.0,
      "eval_accuracy": {
        "accuracy": 0.7942393255795801
      },
      "eval_loss": 0.8254983425140381,
      "eval_runtime": 3.2165,
      "eval_samples_per_second": 3982.934,
      "eval_steps_per_second": 62.491,
      "step": 595200
    },
    {
      "epoch": 960.03,
      "learning_rate": 0.004034128224032255,
      "loss": 0.4703,
      "step": 595220
    },
    {
      "epoch": 960.06,
      "learning_rate": 0.004030902420806449,
      "loss": 0.4586,
      "step": 595240
    },
    {
      "epoch": 960.1,
      "learning_rate": 0.004027676617580644,
      "loss": 0.4697,
      "step": 595260
    },
    {
      "epoch": 960.13,
      "learning_rate": 0.004024450814354838,
      "loss": 0.4613,
      "step": 595280
    },
    {
      "epoch": 960.16,
      "learning_rate": 0.004021225011129032,
      "loss": 0.4554,
      "step": 595300
    },
    {
      "epoch": 960.19,
      "learning_rate": 0.004017999207903226,
      "loss": 0.464,
      "step": 595320
    },
    {
      "epoch": 960.23,
      "learning_rate": 0.00401477340467742,
      "loss": 0.4599,
      "step": 595340
    },
    {
      "epoch": 960.26,
      "learning_rate": 0.004011547601451615,
      "loss": 0.4616,
      "step": 595360
    },
    {
      "epoch": 960.29,
      "learning_rate": 0.004008321798225809,
      "loss": 0.473,
      "step": 595380
    },
    {
      "epoch": 960.32,
      "learning_rate": 0.004005095995000004,
      "loss": 0.4555,
      "step": 595400
    },
    {
      "epoch": 960.35,
      "learning_rate": 0.0040018701917741975,
      "loss": 0.4569,
      "step": 595420
    },
    {
      "epoch": 960.39,
      "learning_rate": 0.003998644388548392,
      "loss": 0.456,
      "step": 595440
    },
    {
      "epoch": 960.42,
      "learning_rate": 0.003995418585322586,
      "loss": 0.4533,
      "step": 595460
    },
    {
      "epoch": 960.45,
      "learning_rate": 0.00399219278209677,
      "loss": 0.4577,
      "step": 595480
    },
    {
      "epoch": 960.48,
      "learning_rate": 0.0039889669788709635,
      "loss": 0.4623,
      "step": 595500
    },
    {
      "epoch": 960.52,
      "learning_rate": 0.003985741175645158,
      "loss": 0.4589,
      "step": 595520
    },
    {
      "epoch": 960.55,
      "learning_rate": 0.003982515372419352,
      "loss": 0.4552,
      "step": 595540
    },
    {
      "epoch": 960.58,
      "learning_rate": 0.003979289569193546,
      "loss": 0.463,
      "step": 595560
    },
    {
      "epoch": 960.61,
      "learning_rate": 0.003976063765967741,
      "loss": 0.4609,
      "step": 595580
    },
    {
      "epoch": 960.65,
      "learning_rate": 0.003972837962741935,
      "loss": 0.4492,
      "step": 595600
    },
    {
      "epoch": 960.68,
      "learning_rate": 0.0039696121595161294,
      "loss": 0.4629,
      "step": 595620
    },
    {
      "epoch": 960.71,
      "learning_rate": 0.003966386356290323,
      "loss": 0.4588,
      "step": 595640
    },
    {
      "epoch": 960.74,
      "learning_rate": 0.003963160553064518,
      "loss": 0.4554,
      "step": 595660
    },
    {
      "epoch": 960.77,
      "learning_rate": 0.003959934749838712,
      "loss": 0.4694,
      "step": 595680
    },
    {
      "epoch": 960.81,
      "learning_rate": 0.003956708946612906,
      "loss": 0.4651,
      "step": 595700
    },
    {
      "epoch": 960.84,
      "learning_rate": 0.003953483143387101,
      "loss": 0.4684,
      "step": 595720
    },
    {
      "epoch": 960.87,
      "learning_rate": 0.0039502573401612945,
      "loss": 0.4561,
      "step": 595740
    },
    {
      "epoch": 960.9,
      "learning_rate": 0.003947031536935489,
      "loss": 0.4662,
      "step": 595760
    },
    {
      "epoch": 960.94,
      "learning_rate": 0.003943805733709683,
      "loss": 0.4685,
      "step": 595780
    },
    {
      "epoch": 960.97,
      "learning_rate": 0.003940579930483867,
      "loss": 0.4588,
      "step": 595800
    },
    {
      "epoch": 961.0,
      "learning_rate": 0.0039373541272580605,
      "loss": 0.4665,
      "step": 595820
    },
    {
      "epoch": 961.0,
      "eval_accuracy": {
        "accuracy": 0.800093669502771
      },
      "eval_loss": 0.8180473446846008,
      "eval_runtime": 3.3862,
      "eval_samples_per_second": 3783.256,
      "eval_steps_per_second": 59.358,
      "step": 595820
    },
    {
      "epoch": 961.03,
      "learning_rate": 0.003934128324032255,
      "loss": 0.4579,
      "step": 595840
    },
    {
      "epoch": 961.06,
      "learning_rate": 0.003930902520806449,
      "loss": 0.4531,
      "step": 595860
    },
    {
      "epoch": 961.1,
      "learning_rate": 0.003927676717580643,
      "loss": 0.4632,
      "step": 595880
    },
    {
      "epoch": 961.13,
      "learning_rate": 0.003924450914354838,
      "loss": 0.4553,
      "step": 595900
    },
    {
      "epoch": 961.16,
      "learning_rate": 0.003921225111129032,
      "loss": 0.4572,
      "step": 595920
    },
    {
      "epoch": 961.19,
      "learning_rate": 0.0039179993079032265,
      "loss": 0.4584,
      "step": 595940
    },
    {
      "epoch": 961.23,
      "learning_rate": 0.00391477350467742,
      "loss": 0.462,
      "step": 595960
    },
    {
      "epoch": 961.26,
      "learning_rate": 0.003911547701451615,
      "loss": 0.4631,
      "step": 595980
    },
    {
      "epoch": 961.29,
      "learning_rate": 0.003908321898225809,
      "loss": 0.4547,
      "step": 596000
    },
    {
      "epoch": 961.32,
      "learning_rate": 0.003905096095000003,
      "loss": 0.4631,
      "step": 596020
    },
    {
      "epoch": 961.35,
      "learning_rate": 0.003901870291774197,
      "loss": 0.4685,
      "step": 596040
    },
    {
      "epoch": 961.39,
      "learning_rate": 0.003898644488548391,
      "loss": 0.4577,
      "step": 596060
    },
    {
      "epoch": 961.42,
      "learning_rate": 0.0038954186853225855,
      "loss": 0.4619,
      "step": 596080
    },
    {
      "epoch": 961.45,
      "learning_rate": 0.0038921928820967685,
      "loss": 0.4573,
      "step": 596100
    },
    {
      "epoch": 961.48,
      "learning_rate": 0.0038889670788709637,
      "loss": 0.4601,
      "step": 596120
    },
    {
      "epoch": 961.52,
      "learning_rate": 0.003885741275645157,
      "loss": 0.4614,
      "step": 596140
    },
    {
      "epoch": 961.55,
      "learning_rate": 0.0038825154724193515,
      "loss": 0.4599,
      "step": 596160
    },
    {
      "epoch": 961.58,
      "learning_rate": 0.0038792896691935454,
      "loss": 0.4514,
      "step": 596180
    },
    {
      "epoch": 961.61,
      "learning_rate": 0.0038760638659677397,
      "loss": 0.4565,
      "step": 596200
    },
    {
      "epoch": 961.65,
      "learning_rate": 0.003872838062741935,
      "loss": 0.4673,
      "step": 596220
    },
    {
      "epoch": 961.68,
      "learning_rate": 0.0038696122595161288,
      "loss": 0.4611,
      "step": 596240
    },
    {
      "epoch": 961.71,
      "learning_rate": 0.003866386456290323,
      "loss": 0.4639,
      "step": 596260
    },
    {
      "epoch": 961.74,
      "learning_rate": 0.0038631606530645166,
      "loss": 0.4668,
      "step": 596280
    },
    {
      "epoch": 961.77,
      "learning_rate": 0.003859934849838711,
      "loss": 0.4571,
      "step": 596300
    },
    {
      "epoch": 961.81,
      "learning_rate": 0.003856709046612906,
      "loss": 0.4608,
      "step": 596320
    },
    {
      "epoch": 961.84,
      "learning_rate": 0.0038534832433871,
      "loss": 0.465,
      "step": 596340
    },
    {
      "epoch": 961.87,
      "learning_rate": 0.0038502574401612943,
      "loss": 0.4644,
      "step": 596360
    },
    {
      "epoch": 961.9,
      "learning_rate": 0.0038470316369354886,
      "loss": 0.4715,
      "step": 596380
    },
    {
      "epoch": 961.94,
      "learning_rate": 0.003843805833709683,
      "loss": 0.4595,
      "step": 596400
    },
    {
      "epoch": 961.97,
      "learning_rate": 0.003840580030483866,
      "loss": 0.4611,
      "step": 596420
    },
    {
      "epoch": 962.0,
      "learning_rate": 0.0038373542272580603,
      "loss": 0.4522,
      "step": 596440
    },
    {
      "epoch": 962.0,
      "eval_accuracy": {
        "accuracy": 0.7985325111232534
      },
      "eval_loss": 0.8193086981773376,
      "eval_runtime": 3.3124,
      "eval_samples_per_second": 3867.63,
      "eval_steps_per_second": 60.682,
      "step": 596440
    },
    {
      "epoch": 962.03,
      "learning_rate": 0.0038341284240322546,
      "loss": 0.4593,
      "step": 596460
    },
    {
      "epoch": 962.06,
      "learning_rate": 0.0038309026208064485,
      "loss": 0.4602,
      "step": 596480
    },
    {
      "epoch": 962.1,
      "learning_rate": 0.003827676817580643,
      "loss": 0.4587,
      "step": 596500
    },
    {
      "epoch": 962.13,
      "learning_rate": 0.003824451014354837,
      "loss": 0.4565,
      "step": 596520
    },
    {
      "epoch": 962.16,
      "learning_rate": 0.0038212252111290315,
      "loss": 0.4531,
      "step": 596540
    },
    {
      "epoch": 962.19,
      "learning_rate": 0.003817999407903226,
      "loss": 0.4704,
      "step": 596560
    },
    {
      "epoch": 962.23,
      "learning_rate": 0.0038147736046774197,
      "loss": 0.4668,
      "step": 596580
    },
    {
      "epoch": 962.26,
      "learning_rate": 0.003811547801451614,
      "loss": 0.4526,
      "step": 596600
    },
    {
      "epoch": 962.29,
      "learning_rate": 0.0038083219982258084,
      "loss": 0.4583,
      "step": 596620
    },
    {
      "epoch": 962.32,
      "learning_rate": 0.0038050961950000027,
      "loss": 0.4538,
      "step": 596640
    },
    {
      "epoch": 962.35,
      "learning_rate": 0.003801870391774197,
      "loss": 0.4595,
      "step": 596660
    },
    {
      "epoch": 962.39,
      "learning_rate": 0.003798644588548391,
      "loss": 0.4599,
      "step": 596680
    },
    {
      "epoch": 962.42,
      "learning_rate": 0.0037954187853225852,
      "loss": 0.459,
      "step": 596700
    },
    {
      "epoch": 962.45,
      "learning_rate": 0.0037921929820967683,
      "loss": 0.4583,
      "step": 596720
    },
    {
      "epoch": 962.48,
      "learning_rate": 0.0037889671788709626,
      "loss": 0.4615,
      "step": 596740
    },
    {
      "epoch": 962.52,
      "learning_rate": 0.003785741375645158,
      "loss": 0.4631,
      "step": 596760
    },
    {
      "epoch": 962.55,
      "learning_rate": 0.0037825155724193517,
      "loss": 0.4617,
      "step": 596780
    },
    {
      "epoch": 962.58,
      "learning_rate": 0.0037792897691935456,
      "loss": 0.4503,
      "step": 596800
    },
    {
      "epoch": 962.61,
      "learning_rate": 0.0037760639659677395,
      "loss": 0.4478,
      "step": 596820
    },
    {
      "epoch": 962.65,
      "learning_rate": 0.003772838162741934,
      "loss": 0.4594,
      "step": 596840
    },
    {
      "epoch": 962.68,
      "learning_rate": 0.003769612359516129,
      "loss": 0.4614,
      "step": 596860
    },
    {
      "epoch": 962.71,
      "learning_rate": 0.003766386556290323,
      "loss": 0.4588,
      "step": 596880
    },
    {
      "epoch": 962.74,
      "learning_rate": 0.003763160753064517,
      "loss": 0.4614,
      "step": 596900
    },
    {
      "epoch": 962.77,
      "learning_rate": 0.0037599349498387115,
      "loss": 0.458,
      "step": 596920
    },
    {
      "epoch": 962.81,
      "learning_rate": 0.003756709146612905,
      "loss": 0.4604,
      "step": 596940
    },
    {
      "epoch": 962.84,
      "learning_rate": 0.0037534833433871,
      "loss": 0.4612,
      "step": 596960
    },
    {
      "epoch": 962.87,
      "learning_rate": 0.003750257540161294,
      "loss": 0.4523,
      "step": 596980
    },
    {
      "epoch": 962.9,
      "learning_rate": 0.0037470317369354884,
      "loss": 0.464,
      "step": 597000
    },
    {
      "epoch": 962.94,
      "learning_rate": 0.0037438059337096827,
      "loss": 0.4747,
      "step": 597020
    },
    {
      "epoch": 962.97,
      "learning_rate": 0.0037405801304838658,
      "loss": 0.471,
      "step": 597040
    },
    {
      "epoch": 963.0,
      "learning_rate": 0.00373735432725806,
      "loss": 0.4622,
      "step": 597060
    },
    {
      "epoch": 963.0,
      "eval_accuracy": {
        "accuracy": 0.7972055265006635
      },
      "eval_loss": 0.820460855960846,
      "eval_runtime": 3.2977,
      "eval_samples_per_second": 3884.808,
      "eval_steps_per_second": 60.951,
      "step": 597060
    },
    {
      "epoch": 963.03,
      "learning_rate": 0.0037341285240322544,
      "loss": 0.4633,
      "step": 597080
    },
    {
      "epoch": 963.06,
      "learning_rate": 0.0037309027208064487,
      "loss": 0.4717,
      "step": 597100
    },
    {
      "epoch": 963.1,
      "learning_rate": 0.0037276769175806426,
      "loss": 0.4594,
      "step": 597120
    },
    {
      "epoch": 963.13,
      "learning_rate": 0.003724451114354837,
      "loss": 0.4562,
      "step": 597140
    },
    {
      "epoch": 963.16,
      "learning_rate": 0.0037212253111290313,
      "loss": 0.4646,
      "step": 597160
    },
    {
      "epoch": 963.19,
      "learning_rate": 0.0037179995079032256,
      "loss": 0.4545,
      "step": 597180
    },
    {
      "epoch": 963.23,
      "learning_rate": 0.00371477370467742,
      "loss": 0.4582,
      "step": 597200
    },
    {
      "epoch": 963.26,
      "learning_rate": 0.003711547901451614,
      "loss": 0.4552,
      "step": 597220
    },
    {
      "epoch": 963.29,
      "learning_rate": 0.003708322098225808,
      "loss": 0.4645,
      "step": 597240
    },
    {
      "epoch": 963.32,
      "learning_rate": 0.0037050962950000025,
      "loss": 0.4523,
      "step": 597260
    },
    {
      "epoch": 963.35,
      "learning_rate": 0.003701870491774197,
      "loss": 0.463,
      "step": 597280
    },
    {
      "epoch": 963.39,
      "learning_rate": 0.003698644688548391,
      "loss": 0.4526,
      "step": 597300
    },
    {
      "epoch": 963.42,
      "learning_rate": 0.003695418885322585,
      "loss": 0.4592,
      "step": 597320
    },
    {
      "epoch": 963.45,
      "learning_rate": 0.0036921930820967685,
      "loss": 0.4729,
      "step": 597340
    },
    {
      "epoch": 963.48,
      "learning_rate": 0.0036891285690322587,
      "loss": 0.4626,
      "step": 597360
    },
    {
      "epoch": 963.52,
      "learning_rate": 0.003685902765806453,
      "loss": 0.4599,
      "step": 597380
    },
    {
      "epoch": 963.55,
      "learning_rate": 0.003682676962580648,
      "loss": 0.4554,
      "step": 597400
    },
    {
      "epoch": 963.58,
      "learning_rate": 0.003679451159354842,
      "loss": 0.4507,
      "step": 597420
    },
    {
      "epoch": 963.61,
      "learning_rate": 0.0036762253561290364,
      "loss": 0.4617,
      "step": 597440
    },
    {
      "epoch": 963.65,
      "learning_rate": 0.0036729995529032307,
      "loss": 0.459,
      "step": 597460
    },
    {
      "epoch": 963.68,
      "learning_rate": 0.0036697737496774138,
      "loss": 0.4616,
      "step": 597480
    },
    {
      "epoch": 963.71,
      "learning_rate": 0.003666547946451608,
      "loss": 0.4559,
      "step": 597500
    },
    {
      "epoch": 963.74,
      "learning_rate": 0.0036633221432258024,
      "loss": 0.4583,
      "step": 597520
    },
    {
      "epoch": 963.77,
      "learning_rate": 0.0036600963399999967,
      "loss": 0.4626,
      "step": 597540
    },
    {
      "epoch": 963.81,
      "learning_rate": 0.0036568705367741906,
      "loss": 0.4654,
      "step": 597560
    },
    {
      "epoch": 963.84,
      "learning_rate": 0.003653644733548385,
      "loss": 0.4674,
      "step": 597580
    },
    {
      "epoch": 963.87,
      "learning_rate": 0.0036504189303225793,
      "loss": 0.4501,
      "step": 597600
    },
    {
      "epoch": 963.9,
      "learning_rate": 0.0036471931270967736,
      "loss": 0.4615,
      "step": 597620
    },
    {
      "epoch": 963.94,
      "learning_rate": 0.003643967323870968,
      "loss": 0.4533,
      "step": 597640
    },
    {
      "epoch": 963.97,
      "learning_rate": 0.003640741520645162,
      "loss": 0.46,
      "step": 597660
    },
    {
      "epoch": 964.0,
      "learning_rate": 0.003637515717419356,
      "loss": 0.4533,
      "step": 597680
    },
    {
      "epoch": 964.0,
      "eval_accuracy": {
        "accuracy": 0.7973616423386153
      },
      "eval_loss": 0.8190205693244934,
      "eval_runtime": 3.2654,
      "eval_samples_per_second": 3923.252,
      "eval_steps_per_second": 61.554,
      "step": 597680
    },
    {
      "epoch": 964.03,
      "learning_rate": 0.0036342899141935505,
      "loss": 0.4615,
      "step": 597700
    },
    {
      "epoch": 964.06,
      "learning_rate": 0.003631064110967745,
      "loss": 0.4652,
      "step": 597720
    },
    {
      "epoch": 964.1,
      "learning_rate": 0.003627838307741939,
      "loss": 0.4459,
      "step": 597740
    },
    {
      "epoch": 964.13,
      "learning_rate": 0.003624612504516133,
      "loss": 0.4662,
      "step": 597760
    },
    {
      "epoch": 964.16,
      "learning_rate": 0.0036213867012903273,
      "loss": 0.4533,
      "step": 597780
    },
    {
      "epoch": 964.19,
      "learning_rate": 0.0036181608980645104,
      "loss": 0.4631,
      "step": 597800
    },
    {
      "epoch": 964.23,
      "learning_rate": 0.0036149350948387047,
      "loss": 0.4604,
      "step": 597820
    },
    {
      "epoch": 964.26,
      "learning_rate": 0.0036117092916129,
      "loss": 0.4572,
      "step": 597840
    },
    {
      "epoch": 964.29,
      "learning_rate": 0.003608483488387094,
      "loss": 0.4611,
      "step": 597860
    },
    {
      "epoch": 964.32,
      "learning_rate": 0.0036052576851612877,
      "loss": 0.4612,
      "step": 597880
    },
    {
      "epoch": 964.35,
      "learning_rate": 0.0036020318819354816,
      "loss": 0.4529,
      "step": 597900
    },
    {
      "epoch": 964.39,
      "learning_rate": 0.003598806078709676,
      "loss": 0.449,
      "step": 597920
    },
    {
      "epoch": 964.42,
      "learning_rate": 0.003595580275483871,
      "loss": 0.4496,
      "step": 597940
    },
    {
      "epoch": 964.45,
      "learning_rate": 0.003592354472258065,
      "loss": 0.4544,
      "step": 597960
    },
    {
      "epoch": 964.48,
      "learning_rate": 0.0035891286690322593,
      "loss": 0.4678,
      "step": 597980
    },
    {
      "epoch": 964.52,
      "learning_rate": 0.0035859028658064536,
      "loss": 0.4635,
      "step": 598000
    },
    {
      "epoch": 964.55,
      "learning_rate": 0.003582677062580647,
      "loss": 0.4529,
      "step": 598020
    },
    {
      "epoch": 964.58,
      "learning_rate": 0.0035794512593548423,
      "loss": 0.468,
      "step": 598040
    },
    {
      "epoch": 964.61,
      "learning_rate": 0.003576225456129036,
      "loss": 0.453,
      "step": 598060
    },
    {
      "epoch": 964.65,
      "learning_rate": 0.0035729996529032305,
      "loss": 0.4607,
      "step": 598080
    },
    {
      "epoch": 964.68,
      "learning_rate": 0.003569773849677425,
      "loss": 0.4617,
      "step": 598100
    },
    {
      "epoch": 964.71,
      "learning_rate": 0.003566548046451608,
      "loss": 0.4557,
      "step": 598120
    },
    {
      "epoch": 964.74,
      "learning_rate": 0.003563322243225802,
      "loss": 0.463,
      "step": 598140
    },
    {
      "epoch": 964.77,
      "learning_rate": 0.0035600964399999965,
      "loss": 0.4557,
      "step": 598160
    },
    {
      "epoch": 964.81,
      "learning_rate": 0.003556870636774191,
      "loss": 0.4659,
      "step": 598180
    },
    {
      "epoch": 964.84,
      "learning_rate": 0.0035536448335483847,
      "loss": 0.4733,
      "step": 598200
    },
    {
      "epoch": 964.87,
      "learning_rate": 0.003550419030322579,
      "loss": 0.4532,
      "step": 598220
    },
    {
      "epoch": 964.9,
      "learning_rate": 0.0035471932270967734,
      "loss": 0.4626,
      "step": 598240
    },
    {
      "epoch": 964.94,
      "learning_rate": 0.0035439674238709677,
      "loss": 0.4555,
      "step": 598260
    },
    {
      "epoch": 964.97,
      "learning_rate": 0.003540741620645162,
      "loss": 0.4539,
      "step": 598280
    },
    {
      "epoch": 965.0,
      "learning_rate": 0.003537515817419356,
      "loss": 0.4557,
      "step": 598300
    },
    {
      "epoch": 965.0,
      "eval_accuracy": {
        "accuracy": 0.7991569744750605
      },
      "eval_loss": 0.8183808922767639,
      "eval_runtime": 3.2962,
      "eval_samples_per_second": 3886.588,
      "eval_steps_per_second": 60.979,
      "step": 598300
    },
    {
      "epoch": 965.03,
      "learning_rate": 0.0035342900141935502,
      "loss": 0.4617,
      "step": 598320
    },
    {
      "epoch": 965.06,
      "learning_rate": 0.0035310642109677454,
      "loss": 0.461,
      "step": 598340
    },
    {
      "epoch": 965.1,
      "learning_rate": 0.003527838407741939,
      "loss": 0.4629,
      "step": 598360
    },
    {
      "epoch": 965.13,
      "learning_rate": 0.003524612604516133,
      "loss": 0.4503,
      "step": 598380
    },
    {
      "epoch": 965.16,
      "learning_rate": 0.003521386801290327,
      "loss": 0.4587,
      "step": 598400
    },
    {
      "epoch": 965.19,
      "learning_rate": 0.0035181609980645106,
      "loss": 0.4664,
      "step": 598420
    },
    {
      "epoch": 965.23,
      "learning_rate": 0.0035149351948387045,
      "loss": 0.4604,
      "step": 598440
    },
    {
      "epoch": 965.26,
      "learning_rate": 0.003511709391612899,
      "loss": 0.4527,
      "step": 598460
    },
    {
      "epoch": 965.29,
      "learning_rate": 0.003508483588387094,
      "loss": 0.4604,
      "step": 598480
    },
    {
      "epoch": 965.32,
      "learning_rate": 0.003505257785161288,
      "loss": 0.4587,
      "step": 598500
    },
    {
      "epoch": 965.35,
      "learning_rate": 0.003502031981935482,
      "loss": 0.4567,
      "step": 598520
    },
    {
      "epoch": 965.39,
      "learning_rate": 0.0034988061787096757,
      "loss": 0.4708,
      "step": 598540
    },
    {
      "epoch": 965.42,
      "learning_rate": 0.00349558037548387,
      "loss": 0.4561,
      "step": 598560
    },
    {
      "epoch": 965.45,
      "learning_rate": 0.003492354572258065,
      "loss": 0.4556,
      "step": 598580
    },
    {
      "epoch": 965.48,
      "learning_rate": 0.003489128769032259,
      "loss": 0.4634,
      "step": 598600
    },
    {
      "epoch": 965.52,
      "learning_rate": 0.0034859029658064534,
      "loss": 0.4635,
      "step": 598620
    },
    {
      "epoch": 965.55,
      "learning_rate": 0.0034826771625806477,
      "loss": 0.4569,
      "step": 598640
    },
    {
      "epoch": 965.58,
      "learning_rate": 0.003479451359354842,
      "loss": 0.4519,
      "step": 598660
    },
    {
      "epoch": 965.61,
      "learning_rate": 0.0034762255561290364,
      "loss": 0.4535,
      "step": 598680
    },
    {
      "epoch": 965.65,
      "learning_rate": 0.0034729997529032303,
      "loss": 0.4649,
      "step": 598700
    },
    {
      "epoch": 965.68,
      "learning_rate": 0.0034697739496774246,
      "loss": 0.4561,
      "step": 598720
    },
    {
      "epoch": 965.71,
      "learning_rate": 0.0034665481464516076,
      "loss": 0.4462,
      "step": 598740
    },
    {
      "epoch": 965.74,
      "learning_rate": 0.003463322343225802,
      "loss": 0.461,
      "step": 598760
    },
    {
      "epoch": 965.77,
      "learning_rate": 0.0034600965399999963,
      "loss": 0.4505,
      "step": 598780
    },
    {
      "epoch": 965.81,
      "learning_rate": 0.0034568707367741906,
      "loss": 0.4524,
      "step": 598800
    },
    {
      "epoch": 965.84,
      "learning_rate": 0.003453644933548385,
      "loss": 0.4533,
      "step": 598820
    },
    {
      "epoch": 965.87,
      "learning_rate": 0.003450419130322579,
      "loss": 0.457,
      "step": 598840
    },
    {
      "epoch": 965.9,
      "learning_rate": 0.003447193327096773,
      "loss": 0.4696,
      "step": 598860
    },
    {
      "epoch": 965.94,
      "learning_rate": 0.0034439675238709675,
      "loss": 0.456,
      "step": 598880
    },
    {
      "epoch": 965.97,
      "learning_rate": 0.003440741720645162,
      "loss": 0.4648,
      "step": 598900
    },
    {
      "epoch": 966.0,
      "learning_rate": 0.003437515917419356,
      "loss": 0.4548,
      "step": 598920
    },
    {
      "epoch": 966.0,
      "eval_accuracy": {
        "accuracy": 0.797517758176567
      },
      "eval_loss": 0.818485677242279,
      "eval_runtime": 3.1614,
      "eval_samples_per_second": 4052.307,
      "eval_steps_per_second": 63.579,
      "step": 598920
    },
    {
      "epoch": 966.03,
      "learning_rate": 0.00343429011419355,
      "loss": 0.4516,
      "step": 598940
    },
    {
      "epoch": 966.06,
      "learning_rate": 0.0034310643109677443,
      "loss": 0.4608,
      "step": 598960
    },
    {
      "epoch": 966.1,
      "learning_rate": 0.0034278385077419395,
      "loss": 0.4578,
      "step": 598980
    },
    {
      "epoch": 966.13,
      "learning_rate": 0.0034246127045161334,
      "loss": 0.4556,
      "step": 599000
    },
    {
      "epoch": 966.16,
      "learning_rate": 0.0034213869012903273,
      "loss": 0.4512,
      "step": 599020
    },
    {
      "epoch": 966.19,
      "learning_rate": 0.003418161098064511,
      "loss": 0.4536,
      "step": 599040
    },
    {
      "epoch": 966.23,
      "learning_rate": 0.003414935294838705,
      "loss": 0.4647,
      "step": 599060
    },
    {
      "epoch": 966.26,
      "learning_rate": 0.0034117094916128986,
      "loss": 0.4514,
      "step": 599080
    },
    {
      "epoch": 966.29,
      "learning_rate": 0.003408483688387093,
      "loss": 0.453,
      "step": 599100
    },
    {
      "epoch": 966.32,
      "learning_rate": 0.003405257885161288,
      "loss": 0.4626,
      "step": 599120
    },
    {
      "epoch": 966.35,
      "learning_rate": 0.003402032081935482,
      "loss": 0.4549,
      "step": 599140
    },
    {
      "epoch": 966.39,
      "learning_rate": 0.0033988062787096763,
      "loss": 0.4614,
      "step": 599160
    },
    {
      "epoch": 966.42,
      "learning_rate": 0.0033955804754838706,
      "loss": 0.4675,
      "step": 599180
    },
    {
      "epoch": 966.45,
      "learning_rate": 0.003392354672258064,
      "loss": 0.465,
      "step": 599200
    },
    {
      "epoch": 966.48,
      "learning_rate": 0.0033891288690322593,
      "loss": 0.4595,
      "step": 599220
    },
    {
      "epoch": 966.52,
      "learning_rate": 0.003385903065806453,
      "loss": 0.4626,
      "step": 599240
    },
    {
      "epoch": 966.55,
      "learning_rate": 0.0033826772625806475,
      "loss": 0.4653,
      "step": 599260
    },
    {
      "epoch": 966.58,
      "learning_rate": 0.003379451459354842,
      "loss": 0.4517,
      "step": 599280
    },
    {
      "epoch": 966.61,
      "learning_rate": 0.003376225656129036,
      "loss": 0.4585,
      "step": 599300
    },
    {
      "epoch": 966.65,
      "learning_rate": 0.0033729998529032305,
      "loss": 0.4536,
      "step": 599320
    },
    {
      "epoch": 966.68,
      "learning_rate": 0.0033697740496774244,
      "loss": 0.4553,
      "step": 599340
    },
    {
      "epoch": 966.71,
      "learning_rate": 0.003366709536612904,
      "loss": 0.4614,
      "step": 599360
    },
    {
      "epoch": 966.74,
      "learning_rate": 0.003363483733387098,
      "loss": 0.4588,
      "step": 599380
    },
    {
      "epoch": 966.77,
      "learning_rate": 0.0033602579301612923,
      "loss": 0.4549,
      "step": 599400
    },
    {
      "epoch": 966.81,
      "learning_rate": 0.0033570321269354875,
      "loss": 0.4551,
      "step": 599420
    },
    {
      "epoch": 966.84,
      "learning_rate": 0.003353806323709681,
      "loss": 0.4539,
      "step": 599440
    },
    {
      "epoch": 966.87,
      "learning_rate": 0.0033505805204838753,
      "loss": 0.4545,
      "step": 599460
    },
    {
      "epoch": 966.9,
      "learning_rate": 0.003347354717258069,
      "loss": 0.4654,
      "step": 599480
    },
    {
      "epoch": 966.94,
      "learning_rate": 0.0033441289140322527,
      "loss": 0.4602,
      "step": 599500
    },
    {
      "epoch": 966.97,
      "learning_rate": 0.0033409031108064466,
      "loss": 0.4576,
      "step": 599520
    },
    {
      "epoch": 967.0,
      "learning_rate": 0.003337838597741937,
      "loss": 0.4613,
      "step": 599540
    },
    {
      "epoch": 967.0,
      "eval_accuracy": {
        "accuracy": 0.7980641636093981
      },
      "eval_loss": 0.8191190958023071,
      "eval_runtime": 3.1782,
      "eval_samples_per_second": 4030.881,
      "eval_steps_per_second": 63.243,
      "step": 599540
    },
    {
      "epoch": 967.03,
      "learning_rate": 0.0033346127945161324,
      "loss": 0.4596,
      "step": 599560
    },
    {
      "epoch": 967.06,
      "learning_rate": 0.0033313869912903263,
      "loss": 0.4632,
      "step": 599580
    },
    {
      "epoch": 967.1,
      "learning_rate": 0.0033281611880645206,
      "loss": 0.457,
      "step": 599600
    },
    {
      "epoch": 967.13,
      "learning_rate": 0.003324935384838715,
      "loss": 0.4505,
      "step": 599620
    },
    {
      "epoch": 967.16,
      "learning_rate": 0.003321709581612898,
      "loss": 0.4506,
      "step": 599640
    },
    {
      "epoch": 967.19,
      "learning_rate": 0.0033184837783870923,
      "loss": 0.4504,
      "step": 599660
    },
    {
      "epoch": 967.23,
      "learning_rate": 0.0033152579751612866,
      "loss": 0.4517,
      "step": 599680
    },
    {
      "epoch": 967.26,
      "learning_rate": 0.003312032171935481,
      "loss": 0.4611,
      "step": 599700
    },
    {
      "epoch": 967.29,
      "learning_rate": 0.003308806368709675,
      "loss": 0.4508,
      "step": 599720
    },
    {
      "epoch": 967.32,
      "learning_rate": 0.003305580565483869,
      "loss": 0.4636,
      "step": 599740
    },
    {
      "epoch": 967.35,
      "learning_rate": 0.0033023547622580635,
      "loss": 0.4559,
      "step": 599760
    },
    {
      "epoch": 967.39,
      "learning_rate": 0.003299128959032258,
      "loss": 0.46,
      "step": 599780
    },
    {
      "epoch": 967.42,
      "learning_rate": 0.003295903155806452,
      "loss": 0.4544,
      "step": 599800
    },
    {
      "epoch": 967.45,
      "learning_rate": 0.003292677352580646,
      "loss": 0.4663,
      "step": 599820
    },
    {
      "epoch": 967.48,
      "learning_rate": 0.0032894515493548404,
      "loss": 0.4609,
      "step": 599840
    },
    {
      "epoch": 967.52,
      "learning_rate": 0.0032862257461290347,
      "loss": 0.4589,
      "step": 599860
    },
    {
      "epoch": 967.55,
      "learning_rate": 0.003282999942903229,
      "loss": 0.4529,
      "step": 599880
    },
    {
      "epoch": 967.58,
      "learning_rate": 0.0032797741396774233,
      "loss": 0.4525,
      "step": 599900
    },
    {
      "epoch": 967.61,
      "learning_rate": 0.0032765483364516172,
      "loss": 0.46,
      "step": 599920
    },
    {
      "epoch": 967.65,
      "learning_rate": 0.0032733225332258115,
      "loss": 0.4626,
      "step": 599940
    },
    {
      "epoch": 967.68,
      "learning_rate": 0.0032700967299999946,
      "loss": 0.476,
      "step": 599960
    },
    {
      "epoch": 967.71,
      "learning_rate": 0.003266870926774189,
      "loss": 0.4658,
      "step": 599980
    },
    {
      "epoch": 967.74,
      "learning_rate": 0.003263645123548384,
      "loss": 0.4505,
      "step": 600000
    },
    {
      "epoch": 967.77,
      "learning_rate": 0.003260419320322578,
      "loss": 0.4554,
      "step": 600020
    },
    {
      "epoch": 967.81,
      "learning_rate": 0.003257193517096772,
      "loss": 0.4497,
      "step": 600040
    },
    {
      "epoch": 967.84,
      "learning_rate": 0.003253967713870966,
      "loss": 0.4505,
      "step": 600060
    },
    {
      "epoch": 967.87,
      "learning_rate": 0.00325074191064516,
      "loss": 0.4633,
      "step": 600080
    },
    {
      "epoch": 967.9,
      "learning_rate": 0.0032475161074193553,
      "loss": 0.4585,
      "step": 600100
    },
    {
      "epoch": 967.94,
      "learning_rate": 0.003244290304193549,
      "loss": 0.4515,
      "step": 600120
    },
    {
      "epoch": 967.97,
      "learning_rate": 0.0032410645009677435,
      "loss": 0.4556,
      "step": 600140
    },
    {
      "epoch": 968.0,
      "learning_rate": 0.003237838697741938,
      "loss": 0.4613,
      "step": 600160
    },
    {
      "epoch": 968.0,
      "eval_accuracy": {
        "accuracy": 0.7997033799078916
      },
      "eval_loss": 0.8193674087524414,
      "eval_runtime": 4.5006,
      "eval_samples_per_second": 2846.491,
      "eval_steps_per_second": 44.66,
      "step": 600160
    },
    {
      "epoch": 968.03,
      "learning_rate": 0.0032346128945161313,
      "loss": 0.4657,
      "step": 600180
    },
    {
      "epoch": 968.06,
      "learning_rate": 0.0032313870912903265,
      "loss": 0.4573,
      "step": 600200
    },
    {
      "epoch": 968.1,
      "learning_rate": 0.0032281612880645204,
      "loss": 0.4548,
      "step": 600220
    },
    {
      "epoch": 968.13,
      "learning_rate": 0.0032249354848387147,
      "loss": 0.4632,
      "step": 600240
    },
    {
      "epoch": 968.16,
      "learning_rate": 0.0032217096816128978,
      "loss": 0.4624,
      "step": 600260
    },
    {
      "epoch": 968.19,
      "learning_rate": 0.003218483878387092,
      "loss": 0.4567,
      "step": 600280
    },
    {
      "epoch": 968.23,
      "learning_rate": 0.0032152580751612864,
      "loss": 0.4596,
      "step": 600300
    },
    {
      "epoch": 968.26,
      "learning_rate": 0.0032120322719354807,
      "loss": 0.4512,
      "step": 600320
    },
    {
      "epoch": 968.29,
      "learning_rate": 0.003208806468709675,
      "loss": 0.4563,
      "step": 600340
    },
    {
      "epoch": 968.32,
      "learning_rate": 0.003205580665483869,
      "loss": 0.4538,
      "step": 600360
    },
    {
      "epoch": 968.35,
      "learning_rate": 0.0032023548622580633,
      "loss": 0.4615,
      "step": 600380
    },
    {
      "epoch": 968.39,
      "learning_rate": 0.0031991290590322576,
      "loss": 0.4512,
      "step": 600400
    },
    {
      "epoch": 968.42,
      "learning_rate": 0.003195903255806452,
      "loss": 0.462,
      "step": 600420
    },
    {
      "epoch": 968.45,
      "learning_rate": 0.0031926774525806462,
      "loss": 0.4465,
      "step": 600440
    },
    {
      "epoch": 968.48,
      "learning_rate": 0.00318945164935484,
      "loss": 0.4519,
      "step": 600460
    },
    {
      "epoch": 968.52,
      "learning_rate": 0.0031862258461290345,
      "loss": 0.4557,
      "step": 600480
    },
    {
      "epoch": 968.55,
      "learning_rate": 0.0031830000429032296,
      "loss": 0.4475,
      "step": 600500
    },
    {
      "epoch": 968.58,
      "learning_rate": 0.003179774239677423,
      "loss": 0.4618,
      "step": 600520
    },
    {
      "epoch": 968.61,
      "learning_rate": 0.0031765484364516174,
      "loss": 0.4571,
      "step": 600540
    },
    {
      "epoch": 968.65,
      "learning_rate": 0.0031733226332258113,
      "loss": 0.4603,
      "step": 600560
    },
    {
      "epoch": 968.68,
      "learning_rate": 0.003170096829999995,
      "loss": 0.4575,
      "step": 600580
    },
    {
      "epoch": 968.71,
      "learning_rate": 0.0031668710267741887,
      "loss": 0.457,
      "step": 600600
    },
    {
      "epoch": 968.74,
      "learning_rate": 0.003163645223548383,
      "loss": 0.4559,
      "step": 600620
    },
    {
      "epoch": 968.77,
      "learning_rate": 0.003160419420322578,
      "loss": 0.463,
      "step": 600640
    },
    {
      "epoch": 968.81,
      "learning_rate": 0.003157193617096772,
      "loss": 0.4553,
      "step": 600660
    },
    {
      "epoch": 968.84,
      "learning_rate": 0.0031539678138709664,
      "loss": 0.4497,
      "step": 600680
    },
    {
      "epoch": 968.87,
      "learning_rate": 0.0031507420106451607,
      "loss": 0.463,
      "step": 600700
    },
    {
      "epoch": 968.9,
      "learning_rate": 0.003147516207419354,
      "loss": 0.4489,
      "step": 600720
    },
    {
      "epoch": 968.94,
      "learning_rate": 0.0031442904041935494,
      "loss": 0.4637,
      "step": 600740
    },
    {
      "epoch": 968.97,
      "learning_rate": 0.0031410646009677433,
      "loss": 0.4507,
      "step": 600760
    },
    {
      "epoch": 969.0,
      "learning_rate": 0.0031378387977419376,
      "loss": 0.4585,
      "step": 600780
    },
    {
      "epoch": 969.0,
      "eval_accuracy": {
        "accuracy": 0.7990008586371087
      },
      "eval_loss": 0.8133324384689331,
      "eval_runtime": 3.1257,
      "eval_samples_per_second": 4098.589,
      "eval_steps_per_second": 64.305,
      "step": 600780
    },
    {
      "epoch": 969.03,
      "learning_rate": 0.003134612994516132,
      "loss": 0.4607,
      "step": 600800
    },
    {
      "epoch": 969.06,
      "learning_rate": 0.0031313871912903263,
      "loss": 0.4678,
      "step": 600820
    },
    {
      "epoch": 969.1,
      "learning_rate": 0.0031281613880645206,
      "loss": 0.4555,
      "step": 600840
    },
    {
      "epoch": 969.13,
      "learning_rate": 0.0031249355848387145,
      "loss": 0.4495,
      "step": 600860
    },
    {
      "epoch": 969.16,
      "learning_rate": 0.003121709781612898,
      "loss": 0.4641,
      "step": 600880
    },
    {
      "epoch": 969.19,
      "learning_rate": 0.003118483978387092,
      "loss": 0.4597,
      "step": 600900
    },
    {
      "epoch": 969.23,
      "learning_rate": 0.003115258175161286,
      "loss": 0.4555,
      "step": 600920
    },
    {
      "epoch": 969.26,
      "learning_rate": 0.0031120323719354805,
      "loss": 0.4607,
      "step": 600940
    },
    {
      "epoch": 969.29,
      "learning_rate": 0.003108806568709675,
      "loss": 0.4534,
      "step": 600960
    },
    {
      "epoch": 969.32,
      "learning_rate": 0.003105580765483869,
      "loss": 0.462,
      "step": 600980
    },
    {
      "epoch": 969.35,
      "learning_rate": 0.0031023549622580635,
      "loss": 0.4536,
      "step": 601000
    },
    {
      "epoch": 969.39,
      "learning_rate": 0.003099129159032258,
      "loss": 0.4477,
      "step": 601020
    },
    {
      "epoch": 969.42,
      "learning_rate": 0.0030959033558064517,
      "loss": 0.4543,
      "step": 601040
    },
    {
      "epoch": 969.45,
      "learning_rate": 0.003092677552580646,
      "loss": 0.4588,
      "step": 601060
    },
    {
      "epoch": 969.48,
      "learning_rate": 0.0030894517493548403,
      "loss": 0.4564,
      "step": 601080
    },
    {
      "epoch": 969.52,
      "learning_rate": 0.0030862259461290347,
      "loss": 0.4519,
      "step": 601100
    },
    {
      "epoch": 969.55,
      "learning_rate": 0.003083000142903229,
      "loss": 0.4648,
      "step": 601120
    },
    {
      "epoch": 969.58,
      "learning_rate": 0.0030797743396774233,
      "loss": 0.4565,
      "step": 601140
    },
    {
      "epoch": 969.61,
      "learning_rate": 0.0030765485364516176,
      "loss": 0.453,
      "step": 601160
    },
    {
      "epoch": 969.65,
      "learning_rate": 0.0030733227332258115,
      "loss": 0.4561,
      "step": 601180
    },
    {
      "epoch": 969.68,
      "learning_rate": 0.003070096929999995,
      "loss": 0.4587,
      "step": 601200
    },
    {
      "epoch": 969.71,
      "learning_rate": 0.0030668711267741893,
      "loss": 0.461,
      "step": 601220
    },
    {
      "epoch": 969.74,
      "learning_rate": 0.0030636453235483832,
      "loss": 0.451,
      "step": 601240
    },
    {
      "epoch": 969.77,
      "learning_rate": 0.0030604195203225775,
      "loss": 0.4572,
      "step": 601260
    },
    {
      "epoch": 969.81,
      "learning_rate": 0.003057193717096772,
      "loss": 0.4483,
      "step": 601280
    },
    {
      "epoch": 969.84,
      "learning_rate": 0.003053967913870966,
      "loss": 0.4511,
      "step": 601300
    },
    {
      "epoch": 969.87,
      "learning_rate": 0.0030507421106451605,
      "loss": 0.4575,
      "step": 601320
    },
    {
      "epoch": 969.9,
      "learning_rate": 0.003047516307419355,
      "loss": 0.4563,
      "step": 601340
    },
    {
      "epoch": 969.94,
      "learning_rate": 0.003044290504193549,
      "loss": 0.4548,
      "step": 601360
    },
    {
      "epoch": 969.97,
      "learning_rate": 0.003041064700967743,
      "loss": 0.4506,
      "step": 601380
    },
    {
      "epoch": 970.0,
      "learning_rate": 0.0030378388977419374,
      "loss": 0.4575,
      "step": 601400
    },
    {
      "epoch": 970.0,
      "eval_accuracy": {
        "accuracy": 0.7989228007181328
      },
      "eval_loss": 0.8166562914848328,
      "eval_runtime": 3.4018,
      "eval_samples_per_second": 3765.903,
      "eval_steps_per_second": 59.086,
      "step": 601400
    },
    {
      "epoch": 970.03,
      "learning_rate": 0.0030346130945161317,
      "loss": 0.4518,
      "step": 601420
    },
    {
      "epoch": 970.06,
      "learning_rate": 0.003031387291290326,
      "loss": 0.4653,
      "step": 601440
    },
    {
      "epoch": 970.1,
      "learning_rate": 0.0030281614880645204,
      "loss": 0.4557,
      "step": 601460
    },
    {
      "epoch": 970.13,
      "learning_rate": 0.0030249356848387147,
      "loss": 0.4597,
      "step": 601480
    },
    {
      "epoch": 970.16,
      "learning_rate": 0.0030217098816128977,
      "loss": 0.4551,
      "step": 601500
    },
    {
      "epoch": 970.19,
      "learning_rate": 0.003018484078387092,
      "loss": 0.4511,
      "step": 601520
    },
    {
      "epoch": 970.23,
      "learning_rate": 0.0030152582751612864,
      "loss": 0.4489,
      "step": 601540
    },
    {
      "epoch": 970.26,
      "learning_rate": 0.0030120324719354803,
      "loss": 0.4587,
      "step": 601560
    },
    {
      "epoch": 970.29,
      "learning_rate": 0.0030088066687096746,
      "loss": 0.4531,
      "step": 601580
    },
    {
      "epoch": 970.32,
      "learning_rate": 0.003005580865483869,
      "loss": 0.4628,
      "step": 601600
    },
    {
      "epoch": 970.35,
      "learning_rate": 0.0030023550622580632,
      "loss": 0.4509,
      "step": 601620
    },
    {
      "epoch": 970.39,
      "learning_rate": 0.0029991292590322576,
      "loss": 0.4492,
      "step": 601640
    },
    {
      "epoch": 970.42,
      "learning_rate": 0.002995903455806452,
      "loss": 0.4657,
      "step": 601660
    },
    {
      "epoch": 970.45,
      "learning_rate": 0.002992677652580646,
      "loss": 0.4567,
      "step": 601680
    },
    {
      "epoch": 970.48,
      "learning_rate": 0.00298945184935484,
      "loss": 0.457,
      "step": 601700
    },
    {
      "epoch": 970.52,
      "learning_rate": 0.0029862260461290344,
      "loss": 0.4618,
      "step": 601720
    },
    {
      "epoch": 970.55,
      "learning_rate": 0.0029830002429032288,
      "loss": 0.4505,
      "step": 601740
    },
    {
      "epoch": 970.58,
      "learning_rate": 0.002979774439677423,
      "loss": 0.4445,
      "step": 601760
    },
    {
      "epoch": 970.61,
      "learning_rate": 0.0029765486364516174,
      "loss": 0.4561,
      "step": 601780
    },
    {
      "epoch": 970.65,
      "learning_rate": 0.0029733228332258117,
      "loss": 0.4574,
      "step": 601800
    },
    {
      "epoch": 970.68,
      "learning_rate": 0.0029700970299999948,
      "loss": 0.4618,
      "step": 601820
    },
    {
      "epoch": 970.71,
      "learning_rate": 0.002966871226774189,
      "loss": 0.457,
      "step": 601840
    },
    {
      "epoch": 970.74,
      "learning_rate": 0.0029636454235483834,
      "loss": 0.4461,
      "step": 601860
    },
    {
      "epoch": 970.77,
      "learning_rate": 0.0029604196203225778,
      "loss": 0.4566,
      "step": 601880
    },
    {
      "epoch": 970.81,
      "learning_rate": 0.0029571938170967716,
      "loss": 0.4503,
      "step": 601900
    },
    {
      "epoch": 970.84,
      "learning_rate": 0.002953968013870966,
      "loss": 0.4629,
      "step": 601920
    },
    {
      "epoch": 970.87,
      "learning_rate": 0.0029507422106451603,
      "loss": 0.4593,
      "step": 601940
    },
    {
      "epoch": 970.9,
      "learning_rate": 0.0029475164074193546,
      "loss": 0.4589,
      "step": 601960
    },
    {
      "epoch": 970.94,
      "learning_rate": 0.002944290604193549,
      "loss": 0.4561,
      "step": 601980
    },
    {
      "epoch": 970.97,
      "learning_rate": 0.0029410648009677433,
      "loss": 0.4605,
      "step": 602000
    },
    {
      "epoch": 971.0,
      "learning_rate": 0.0029378389977419376,
      "loss": 0.457,
      "step": 602020
    },
    {
      "epoch": 971.0,
      "eval_accuracy": {
        "accuracy": 0.7994692061509641
      },
      "eval_loss": 0.8159370422363281,
      "eval_runtime": 3.2985,
      "eval_samples_per_second": 3883.879,
      "eval_steps_per_second": 60.937,
      "step": 602020
    },
    {
      "epoch": 971.03,
      "learning_rate": 0.0029346131945161315,
      "loss": 0.4587,
      "step": 602040
    },
    {
      "epoch": 971.06,
      "learning_rate": 0.002931387391290326,
      "loss": 0.4547,
      "step": 602060
    },
    {
      "epoch": 971.1,
      "learning_rate": 0.00292816158806452,
      "loss": 0.4494,
      "step": 602080
    },
    {
      "epoch": 971.13,
      "learning_rate": 0.0029249357848387145,
      "loss": 0.4578,
      "step": 602100
    },
    {
      "epoch": 971.16,
      "learning_rate": 0.0029217099816128975,
      "loss": 0.4478,
      "step": 602120
    },
    {
      "epoch": 971.19,
      "learning_rate": 0.002918484178387092,
      "loss": 0.4514,
      "step": 602140
    },
    {
      "epoch": 971.23,
      "learning_rate": 0.002915258375161286,
      "loss": 0.4608,
      "step": 602160
    },
    {
      "epoch": 971.26,
      "learning_rate": 0.0029120325719354805,
      "loss": 0.4525,
      "step": 602180
    },
    {
      "epoch": 971.29,
      "learning_rate": 0.002908806768709675,
      "loss": 0.448,
      "step": 602200
    },
    {
      "epoch": 971.32,
      "learning_rate": 0.002905580965483869,
      "loss": 0.4597,
      "step": 602220
    },
    {
      "epoch": 971.35,
      "learning_rate": 0.002902355162258063,
      "loss": 0.4517,
      "step": 602240
    },
    {
      "epoch": 971.39,
      "learning_rate": 0.0028991293590322573,
      "loss": 0.4581,
      "step": 602260
    },
    {
      "epoch": 971.42,
      "learning_rate": 0.0028959035558064517,
      "loss": 0.4506,
      "step": 602280
    },
    {
      "epoch": 971.45,
      "learning_rate": 0.002892677752580646,
      "loss": 0.4458,
      "step": 602300
    },
    {
      "epoch": 971.48,
      "learning_rate": 0.0028894519493548403,
      "loss": 0.4623,
      "step": 602320
    },
    {
      "epoch": 971.52,
      "learning_rate": 0.0028862261461290346,
      "loss": 0.4574,
      "step": 602340
    },
    {
      "epoch": 971.55,
      "learning_rate": 0.002883000342903229,
      "loss": 0.4635,
      "step": 602360
    },
    {
      "epoch": 971.58,
      "learning_rate": 0.002879774539677423,
      "loss": 0.4541,
      "step": 602380
    },
    {
      "epoch": 971.61,
      "learning_rate": 0.002876548736451617,
      "loss": 0.4604,
      "step": 602400
    },
    {
      "epoch": 971.65,
      "learning_rate": 0.0028733229332258115,
      "loss": 0.4577,
      "step": 602420
    },
    {
      "epoch": 971.68,
      "learning_rate": 0.0028700971299999945,
      "loss": 0.4573,
      "step": 602440
    },
    {
      "epoch": 971.71,
      "learning_rate": 0.002866871326774189,
      "loss": 0.4508,
      "step": 602460
    },
    {
      "epoch": 971.74,
      "learning_rate": 0.002863645523548383,
      "loss": 0.4505,
      "step": 602480
    },
    {
      "epoch": 971.77,
      "learning_rate": 0.0028604197203225775,
      "loss": 0.4589,
      "step": 602500
    },
    {
      "epoch": 971.81,
      "learning_rate": 0.002857193917096772,
      "loss": 0.4569,
      "step": 602520
    },
    {
      "epoch": 971.84,
      "learning_rate": 0.002853968113870966,
      "loss": 0.459,
      "step": 602540
    },
    {
      "epoch": 971.87,
      "learning_rate": 0.00285074231064516,
      "loss": 0.4604,
      "step": 602560
    },
    {
      "epoch": 971.9,
      "learning_rate": 0.0028475165074193544,
      "loss": 0.4455,
      "step": 602580
    },
    {
      "epoch": 971.94,
      "learning_rate": 0.0028442907041935487,
      "loss": 0.4681,
      "step": 602600
    },
    {
      "epoch": 971.97,
      "learning_rate": 0.002841064900967743,
      "loss": 0.4515,
      "step": 602620
    },
    {
      "epoch": 972.0,
      "learning_rate": 0.0028378390977419374,
      "loss": 0.4564,
      "step": 602640
    },
    {
      "epoch": 972.0,
      "eval_accuracy": {
        "accuracy": 0.7979080477714464
      },
      "eval_loss": 0.8161758780479431,
      "eval_runtime": 4.1738,
      "eval_samples_per_second": 3069.387,
      "eval_steps_per_second": 48.158,
      "step": 602640
    },
    {
      "epoch": 972.03,
      "learning_rate": 0.0028346132945161317,
      "loss": 0.4543,
      "step": 602660
    },
    {
      "epoch": 972.06,
      "learning_rate": 0.002831387491290326,
      "loss": 0.4514,
      "step": 602680
    },
    {
      "epoch": 972.1,
      "learning_rate": 0.00282816168806452,
      "loss": 0.4573,
      "step": 602700
    },
    {
      "epoch": 972.13,
      "learning_rate": 0.0028249358848387142,
      "loss": 0.4512,
      "step": 602720
    },
    {
      "epoch": 972.16,
      "learning_rate": 0.0028217100816129085,
      "loss": 0.4535,
      "step": 602740
    },
    {
      "epoch": 972.19,
      "learning_rate": 0.0028184842783870916,
      "loss": 0.452,
      "step": 602760
    },
    {
      "epoch": 972.23,
      "learning_rate": 0.002815258475161286,
      "loss": 0.4614,
      "step": 602780
    },
    {
      "epoch": 972.26,
      "learning_rate": 0.0028120326719354802,
      "loss": 0.4473,
      "step": 602800
    },
    {
      "epoch": 972.29,
      "learning_rate": 0.0028088068687096746,
      "loss": 0.4548,
      "step": 602820
    },
    {
      "epoch": 972.32,
      "learning_rate": 0.002805581065483869,
      "loss": 0.4456,
      "step": 602840
    },
    {
      "epoch": 972.35,
      "learning_rate": 0.0028023552622580632,
      "loss": 0.4528,
      "step": 602860
    },
    {
      "epoch": 972.39,
      "learning_rate": 0.0027991294590322575,
      "loss": 0.453,
      "step": 602880
    },
    {
      "epoch": 972.42,
      "learning_rate": 0.0027959036558064514,
      "loss": 0.4683,
      "step": 602900
    },
    {
      "epoch": 972.45,
      "learning_rate": 0.0027926778525806458,
      "loss": 0.4659,
      "step": 602920
    },
    {
      "epoch": 972.48,
      "learning_rate": 0.00278945204935484,
      "loss": 0.4572,
      "step": 602940
    },
    {
      "epoch": 972.52,
      "learning_rate": 0.0027862262461290344,
      "loss": 0.4588,
      "step": 602960
    },
    {
      "epoch": 972.55,
      "learning_rate": 0.0027830004429032287,
      "loss": 0.4468,
      "step": 602980
    },
    {
      "epoch": 972.58,
      "learning_rate": 0.002779774639677423,
      "loss": 0.4608,
      "step": 603000
    },
    {
      "epoch": 972.61,
      "learning_rate": 0.0027765488364516174,
      "loss": 0.461,
      "step": 603020
    },
    {
      "epoch": 972.65,
      "learning_rate": 0.0027733230332258113,
      "loss": 0.4457,
      "step": 603040
    },
    {
      "epoch": 972.68,
      "learning_rate": 0.0027700972299999948,
      "loss": 0.4662,
      "step": 603060
    },
    {
      "epoch": 972.71,
      "learning_rate": 0.002766871426774189,
      "loss": 0.4495,
      "step": 603080
    },
    {
      "epoch": 972.74,
      "learning_rate": 0.002763645623548383,
      "loss": 0.4529,
      "step": 603100
    },
    {
      "epoch": 972.77,
      "learning_rate": 0.0027604198203225773,
      "loss": 0.4504,
      "step": 603120
    },
    {
      "epoch": 972.81,
      "learning_rate": 0.0027571940170967716,
      "loss": 0.4598,
      "step": 603140
    },
    {
      "epoch": 972.84,
      "learning_rate": 0.002753968213870966,
      "loss": 0.4536,
      "step": 603160
    },
    {
      "epoch": 972.87,
      "learning_rate": 0.0027507424106451603,
      "loss": 0.4536,
      "step": 603180
    },
    {
      "epoch": 972.9,
      "learning_rate": 0.0027475166074193546,
      "loss": 0.4507,
      "step": 603200
    },
    {
      "epoch": 972.94,
      "learning_rate": 0.0027442908041935485,
      "loss": 0.46,
      "step": 603220
    },
    {
      "epoch": 972.97,
      "learning_rate": 0.002741065000967743,
      "loss": 0.4544,
      "step": 603240
    },
    {
      "epoch": 973.0,
      "learning_rate": 0.002737839197741937,
      "loss": 0.4506,
      "step": 603260
    },
    {
      "epoch": 973.0,
      "eval_accuracy": {
        "accuracy": 0.800093669502771
      },
      "eval_loss": 0.8168635368347168,
      "eval_runtime": 3.387,
      "eval_samples_per_second": 3782.453,
      "eval_steps_per_second": 59.345,
      "step": 603260
    },
    {
      "epoch": 973.03,
      "learning_rate": 0.0027346133945161315,
      "loss": 0.4525,
      "step": 603280
    },
    {
      "epoch": 973.06,
      "learning_rate": 0.0027313875912903258,
      "loss": 0.4505,
      "step": 603300
    },
    {
      "epoch": 973.1,
      "learning_rate": 0.00272816178806452,
      "loss": 0.45,
      "step": 603320
    },
    {
      "epoch": 973.13,
      "learning_rate": 0.0027249359848387144,
      "loss": 0.4549,
      "step": 603340
    },
    {
      "epoch": 973.16,
      "learning_rate": 0.0027217101816129083,
      "loss": 0.4488,
      "step": 603360
    },
    {
      "epoch": 973.19,
      "learning_rate": 0.002718484378387092,
      "loss": 0.4449,
      "step": 603380
    },
    {
      "epoch": 973.23,
      "learning_rate": 0.002715258575161286,
      "loss": 0.4559,
      "step": 603400
    },
    {
      "epoch": 973.26,
      "learning_rate": 0.00271203277193548,
      "loss": 0.4568,
      "step": 603420
    },
    {
      "epoch": 973.29,
      "learning_rate": 0.0027088069687096743,
      "loss": 0.4526,
      "step": 603440
    },
    {
      "epoch": 973.32,
      "learning_rate": 0.0027055811654838687,
      "loss": 0.4611,
      "step": 603460
    },
    {
      "epoch": 973.35,
      "learning_rate": 0.002702355362258063,
      "loss": 0.4548,
      "step": 603480
    },
    {
      "epoch": 973.39,
      "learning_rate": 0.0026991295590322573,
      "loss": 0.4567,
      "step": 603500
    },
    {
      "epoch": 973.42,
      "learning_rate": 0.0026959037558064516,
      "loss": 0.4454,
      "step": 603520
    },
    {
      "epoch": 973.45,
      "learning_rate": 0.002692677952580646,
      "loss": 0.456,
      "step": 603540
    },
    {
      "epoch": 973.48,
      "learning_rate": 0.00268945214935484,
      "loss": 0.4494,
      "step": 603560
    },
    {
      "epoch": 973.52,
      "learning_rate": 0.0026863876362903196,
      "loss": 0.4501,
      "step": 603580
    },
    {
      "epoch": 973.55,
      "learning_rate": 0.002683161833064514,
      "loss": 0.4552,
      "step": 603600
    },
    {
      "epoch": 973.58,
      "learning_rate": 0.0026799360298387083,
      "loss": 0.454,
      "step": 603620
    },
    {
      "epoch": 973.61,
      "learning_rate": 0.002676710226612902,
      "loss": 0.4523,
      "step": 603640
    },
    {
      "epoch": 973.65,
      "learning_rate": 0.0026734844233870965,
      "loss": 0.457,
      "step": 603660
    },
    {
      "epoch": 973.68,
      "learning_rate": 0.002670258620161291,
      "loss": 0.4524,
      "step": 603680
    },
    {
      "epoch": 973.71,
      "learning_rate": 0.002667032816935485,
      "loss": 0.4593,
      "step": 603700
    },
    {
      "epoch": 973.74,
      "learning_rate": 0.0026638070137096795,
      "loss": 0.4599,
      "step": 603720
    },
    {
      "epoch": 973.77,
      "learning_rate": 0.002660581210483874,
      "loss": 0.4524,
      "step": 603740
    },
    {
      "epoch": 973.81,
      "learning_rate": 0.002657355407258068,
      "loss": 0.4562,
      "step": 603760
    },
    {
      "epoch": 973.84,
      "learning_rate": 0.002654129604032262,
      "loss": 0.4595,
      "step": 603780
    },
    {
      "epoch": 973.87,
      "learning_rate": 0.0026509038008064563,
      "loss": 0.4563,
      "step": 603800
    },
    {
      "epoch": 973.9,
      "learning_rate": 0.00264767799758064,
      "loss": 0.4628,
      "step": 603820
    },
    {
      "epoch": 973.94,
      "learning_rate": 0.0026444521943548337,
      "loss": 0.4563,
      "step": 603840
    },
    {
      "epoch": 973.97,
      "learning_rate": 0.002641226391129028,
      "loss": 0.4558,
      "step": 603860
    },
    {
      "epoch": 974.0,
      "learning_rate": 0.0026380005879032224,
      "loss": 0.4535,
      "step": 603880
    },
    {
      "epoch": 974.0,
      "eval_accuracy": {
        "accuracy": 0.79822027944735
      },
      "eval_loss": 0.8174799084663391,
      "eval_runtime": 3.3132,
      "eval_samples_per_second": 3866.612,
      "eval_steps_per_second": 60.666,
      "step": 603880
    },
    {
      "epoch": 974.03,
      "learning_rate": 0.0026347747846774167,
      "loss": 0.4524,
      "step": 603900
    },
    {
      "epoch": 974.06,
      "learning_rate": 0.002631548981451611,
      "loss": 0.4553,
      "step": 603920
    },
    {
      "epoch": 974.1,
      "learning_rate": 0.0026283231782258053,
      "loss": 0.4475,
      "step": 603940
    },
    {
      "epoch": 974.13,
      "learning_rate": 0.0026250973749999996,
      "loss": 0.4553,
      "step": 603960
    },
    {
      "epoch": 974.16,
      "learning_rate": 0.0026218715717741935,
      "loss": 0.4592,
      "step": 603980
    },
    {
      "epoch": 974.19,
      "learning_rate": 0.002618645768548388,
      "loss": 0.453,
      "step": 604000
    },
    {
      "epoch": 974.23,
      "learning_rate": 0.002615419965322582,
      "loss": 0.4542,
      "step": 604020
    },
    {
      "epoch": 974.26,
      "learning_rate": 0.0026121941620967765,
      "loss": 0.4494,
      "step": 604040
    },
    {
      "epoch": 974.29,
      "learning_rate": 0.002608968358870971,
      "loss": 0.4584,
      "step": 604060
    },
    {
      "epoch": 974.32,
      "learning_rate": 0.002605742555645165,
      "loss": 0.4501,
      "step": 604080
    },
    {
      "epoch": 974.35,
      "learning_rate": 0.0026025167524193595,
      "loss": 0.4598,
      "step": 604100
    },
    {
      "epoch": 974.39,
      "learning_rate": 0.0025992909491935534,
      "loss": 0.4469,
      "step": 604120
    },
    {
      "epoch": 974.42,
      "learning_rate": 0.002596065145967737,
      "loss": 0.4592,
      "step": 604140
    },
    {
      "epoch": 974.45,
      "learning_rate": 0.002592839342741931,
      "loss": 0.4486,
      "step": 604160
    },
    {
      "epoch": 974.48,
      "learning_rate": 0.002589613539516125,
      "loss": 0.4505,
      "step": 604180
    },
    {
      "epoch": 974.52,
      "learning_rate": 0.0025863877362903194,
      "loss": 0.4482,
      "step": 604200
    },
    {
      "epoch": 974.55,
      "learning_rate": 0.0025831619330645137,
      "loss": 0.448,
      "step": 604220
    },
    {
      "epoch": 974.58,
      "learning_rate": 0.002579936129838708,
      "loss": 0.4612,
      "step": 604240
    },
    {
      "epoch": 974.61,
      "learning_rate": 0.0025767103266129024,
      "loss": 0.4649,
      "step": 604260
    },
    {
      "epoch": 974.65,
      "learning_rate": 0.0025734845233870967,
      "loss": 0.4534,
      "step": 604280
    },
    {
      "epoch": 974.68,
      "learning_rate": 0.002570258720161291,
      "loss": 0.4622,
      "step": 604300
    },
    {
      "epoch": 974.71,
      "learning_rate": 0.002567032916935485,
      "loss": 0.451,
      "step": 604320
    },
    {
      "epoch": 974.74,
      "learning_rate": 0.0025638071137096792,
      "loss": 0.4581,
      "step": 604340
    },
    {
      "epoch": 974.77,
      "learning_rate": 0.0025605813104838736,
      "loss": 0.4606,
      "step": 604360
    },
    {
      "epoch": 974.81,
      "learning_rate": 0.002557355507258068,
      "loss": 0.4508,
      "step": 604380
    },
    {
      "epoch": 974.84,
      "learning_rate": 0.002554129704032262,
      "loss": 0.4449,
      "step": 604400
    },
    {
      "epoch": 974.87,
      "learning_rate": 0.0025509039008064565,
      "loss": 0.4496,
      "step": 604420
    },
    {
      "epoch": 974.9,
      "learning_rate": 0.0025476780975806396,
      "loss": 0.4481,
      "step": 604440
    },
    {
      "epoch": 974.94,
      "learning_rate": 0.002544452294354834,
      "loss": 0.4627,
      "step": 604460
    },
    {
      "epoch": 974.97,
      "learning_rate": 0.0025412264911290282,
      "loss": 0.4554,
      "step": 604480
    },
    {
      "epoch": 975.0,
      "learning_rate": 0.002538161978064519,
      "loss": 0.4464,
      "step": 604500
    },
    {
      "epoch": 975.0,
      "eval_accuracy": {
        "accuracy": 0.7992350323940364
      },
      "eval_loss": 0.8139598369598389,
      "eval_runtime": 3.5403,
      "eval_samples_per_second": 3618.647,
      "eval_steps_per_second": 56.775,
      "step": 604500
    },
    {
      "epoch": 975.03,
      "learning_rate": 0.002534936174838713,
      "loss": 0.4557,
      "step": 604520
    },
    {
      "epoch": 975.06,
      "learning_rate": 0.002531710371612907,
      "loss": 0.4582,
      "step": 604540
    },
    {
      "epoch": 975.1,
      "learning_rate": 0.0025284845683871014,
      "loss": 0.4506,
      "step": 604560
    },
    {
      "epoch": 975.13,
      "learning_rate": 0.0025252587651612957,
      "loss": 0.4445,
      "step": 604580
    },
    {
      "epoch": 975.16,
      "learning_rate": 0.0025220329619354788,
      "loss": 0.4498,
      "step": 604600
    },
    {
      "epoch": 975.19,
      "learning_rate": 0.002518807158709673,
      "loss": 0.4518,
      "step": 604620
    },
    {
      "epoch": 975.23,
      "learning_rate": 0.0025155813554838674,
      "loss": 0.4545,
      "step": 604640
    },
    {
      "epoch": 975.26,
      "learning_rate": 0.0025123555522580617,
      "loss": 0.4528,
      "step": 604660
    },
    {
      "epoch": 975.29,
      "learning_rate": 0.002509129749032256,
      "loss": 0.4567,
      "step": 604680
    },
    {
      "epoch": 975.32,
      "learning_rate": 0.0025059039458064504,
      "loss": 0.4559,
      "step": 604700
    },
    {
      "epoch": 975.35,
      "learning_rate": 0.0025026781425806447,
      "loss": 0.4528,
      "step": 604720
    },
    {
      "epoch": 975.39,
      "learning_rate": 0.0024994523393548386,
      "loss": 0.4548,
      "step": 604740
    },
    {
      "epoch": 975.42,
      "learning_rate": 0.002496226536129033,
      "loss": 0.4541,
      "step": 604760
    },
    {
      "epoch": 975.45,
      "learning_rate": 0.0024930007329032272,
      "loss": 0.4532,
      "step": 604780
    },
    {
      "epoch": 975.48,
      "learning_rate": 0.0024897749296774216,
      "loss": 0.4512,
      "step": 604800
    },
    {
      "epoch": 975.52,
      "learning_rate": 0.002486549126451616,
      "loss": 0.4473,
      "step": 604820
    },
    {
      "epoch": 975.55,
      "learning_rate": 0.0024833233232258102,
      "loss": 0.461,
      "step": 604840
    },
    {
      "epoch": 975.58,
      "learning_rate": 0.0024800975200000045,
      "loss": 0.4529,
      "step": 604860
    },
    {
      "epoch": 975.61,
      "learning_rate": 0.0024768717167741984,
      "loss": 0.4603,
      "step": 604880
    },
    {
      "epoch": 975.65,
      "learning_rate": 0.002473645913548382,
      "loss": 0.4561,
      "step": 604900
    },
    {
      "epoch": 975.68,
      "learning_rate": 0.002470420110322576,
      "loss": 0.4505,
      "step": 604920
    },
    {
      "epoch": 975.71,
      "learning_rate": 0.00246719430709677,
      "loss": 0.452,
      "step": 604940
    },
    {
      "epoch": 975.74,
      "learning_rate": 0.0024639685038709645,
      "loss": 0.4468,
      "step": 604960
    },
    {
      "epoch": 975.77,
      "learning_rate": 0.0024607427006451588,
      "loss": 0.4519,
      "step": 604980
    },
    {
      "epoch": 975.81,
      "learning_rate": 0.002457516897419353,
      "loss": 0.4525,
      "step": 605000
    },
    {
      "epoch": 975.84,
      "learning_rate": 0.0024542910941935474,
      "loss": 0.4562,
      "step": 605020
    },
    {
      "epoch": 975.87,
      "learning_rate": 0.0024510652909677418,
      "loss": 0.4503,
      "step": 605040
    },
    {
      "epoch": 975.9,
      "learning_rate": 0.0024478394877419356,
      "loss": 0.4516,
      "step": 605060
    },
    {
      "epoch": 975.94,
      "learning_rate": 0.00244461368451613,
      "loss": 0.455,
      "step": 605080
    },
    {
      "epoch": 975.97,
      "learning_rate": 0.0024413878812903243,
      "loss": 0.4547,
      "step": 605100
    },
    {
      "epoch": 976.0,
      "learning_rate": 0.0024381620780645186,
      "loss": 0.4537,
      "step": 605120
    },
    {
      "epoch": 976.0,
      "eval_accuracy": {
        "accuracy": 0.7996253219889158
      },
      "eval_loss": 0.812424898147583,
      "eval_runtime": 3.6203,
      "eval_samples_per_second": 3538.689,
      "eval_steps_per_second": 55.521,
      "step": 605120
    },
    {
      "epoch": 976.03,
      "learning_rate": 0.002434936274838713,
      "loss": 0.4613,
      "step": 605140
    },
    {
      "epoch": 976.06,
      "learning_rate": 0.0024317104716129073,
      "loss": 0.4592,
      "step": 605160
    },
    {
      "epoch": 976.1,
      "learning_rate": 0.0024284846683871016,
      "loss": 0.4489,
      "step": 605180
    },
    {
      "epoch": 976.13,
      "learning_rate": 0.0024252588651612955,
      "loss": 0.4564,
      "step": 605200
    },
    {
      "epoch": 976.16,
      "learning_rate": 0.002422033061935479,
      "loss": 0.4452,
      "step": 605220
    },
    {
      "epoch": 976.19,
      "learning_rate": 0.0024188072587096733,
      "loss": 0.4535,
      "step": 605240
    },
    {
      "epoch": 976.23,
      "learning_rate": 0.002415581455483867,
      "loss": 0.4456,
      "step": 605260
    },
    {
      "epoch": 976.26,
      "learning_rate": 0.0024123556522580615,
      "loss": 0.45,
      "step": 605280
    },
    {
      "epoch": 976.29,
      "learning_rate": 0.002409129849032256,
      "loss": 0.4608,
      "step": 605300
    },
    {
      "epoch": 976.32,
      "learning_rate": 0.00240590404580645,
      "loss": 0.4499,
      "step": 605320
    },
    {
      "epoch": 976.35,
      "learning_rate": 0.0024026782425806445,
      "loss": 0.4567,
      "step": 605340
    },
    {
      "epoch": 976.39,
      "learning_rate": 0.002399452439354839,
      "loss": 0.4522,
      "step": 605360
    },
    {
      "epoch": 976.42,
      "learning_rate": 0.002396226636129033,
      "loss": 0.4523,
      "step": 605380
    },
    {
      "epoch": 976.45,
      "learning_rate": 0.002393000832903227,
      "loss": 0.4448,
      "step": 605400
    },
    {
      "epoch": 976.48,
      "learning_rate": 0.0023897750296774213,
      "loss": 0.4432,
      "step": 605420
    },
    {
      "epoch": 976.52,
      "learning_rate": 0.0023865492264516157,
      "loss": 0.4482,
      "step": 605440
    },
    {
      "epoch": 976.55,
      "learning_rate": 0.00238332342322581,
      "loss": 0.4576,
      "step": 605460
    },
    {
      "epoch": 976.58,
      "learning_rate": 0.0023800976200000043,
      "loss": 0.4498,
      "step": 605480
    },
    {
      "epoch": 976.61,
      "learning_rate": 0.0023768718167741986,
      "loss": 0.4502,
      "step": 605500
    },
    {
      "epoch": 976.65,
      "learning_rate": 0.0023736460135483817,
      "loss": 0.4518,
      "step": 605520
    },
    {
      "epoch": 976.68,
      "learning_rate": 0.002370420210322576,
      "loss": 0.4561,
      "step": 605540
    },
    {
      "epoch": 976.71,
      "learning_rate": 0.0023671944070967703,
      "loss": 0.4506,
      "step": 605560
    },
    {
      "epoch": 976.74,
      "learning_rate": 0.0023639686038709642,
      "loss": 0.4534,
      "step": 605580
    },
    {
      "epoch": 976.77,
      "learning_rate": 0.0023607428006451586,
      "loss": 0.4501,
      "step": 605600
    },
    {
      "epoch": 976.81,
      "learning_rate": 0.002357516997419353,
      "loss": 0.452,
      "step": 605620
    },
    {
      "epoch": 976.84,
      "learning_rate": 0.002354291194193547,
      "loss": 0.4631,
      "step": 605640
    },
    {
      "epoch": 976.87,
      "learning_rate": 0.0023510653909677415,
      "loss": 0.4556,
      "step": 605660
    },
    {
      "epoch": 976.9,
      "learning_rate": 0.002347839587741936,
      "loss": 0.4565,
      "step": 605680
    },
    {
      "epoch": 976.94,
      "learning_rate": 0.00234461378451613,
      "loss": 0.4538,
      "step": 605700
    },
    {
      "epoch": 976.97,
      "learning_rate": 0.002341387981290324,
      "loss": 0.4559,
      "step": 605720
    },
    {
      "epoch": 977.0,
      "learning_rate": 0.0023381621780645184,
      "loss": 0.452,
      "step": 605740
    },
    {
      "epoch": 977.0,
      "eval_accuracy": {
        "accuracy": 0.798844742799157
      },
      "eval_loss": 0.8145288228988647,
      "eval_runtime": 3.3618,
      "eval_samples_per_second": 3810.775,
      "eval_steps_per_second": 59.79,
      "step": 605740
    },
    {
      "epoch": 977.03,
      "learning_rate": 0.0023349363748387127,
      "loss": 0.4474,
      "step": 605760
    },
    {
      "epoch": 977.06,
      "learning_rate": 0.002331710571612907,
      "loss": 0.4509,
      "step": 605780
    },
    {
      "epoch": 977.1,
      "learning_rate": 0.0023284847683871014,
      "loss": 0.4504,
      "step": 605800
    },
    {
      "epoch": 977.13,
      "learning_rate": 0.0023252589651612957,
      "loss": 0.4449,
      "step": 605820
    },
    {
      "epoch": 977.16,
      "learning_rate": 0.0023220331619354787,
      "loss": 0.4549,
      "step": 605840
    },
    {
      "epoch": 977.19,
      "learning_rate": 0.002318807358709673,
      "loss": 0.4369,
      "step": 605860
    },
    {
      "epoch": 977.23,
      "learning_rate": 0.0023155815554838674,
      "loss": 0.4493,
      "step": 605880
    },
    {
      "epoch": 977.26,
      "learning_rate": 0.0023123557522580617,
      "loss": 0.4548,
      "step": 605900
    },
    {
      "epoch": 977.29,
      "learning_rate": 0.0023091299490322556,
      "loss": 0.4592,
      "step": 605920
    },
    {
      "epoch": 977.32,
      "learning_rate": 0.00230590414580645,
      "loss": 0.4482,
      "step": 605940
    },
    {
      "epoch": 977.35,
      "learning_rate": 0.0023026783425806443,
      "loss": 0.447,
      "step": 605960
    },
    {
      "epoch": 977.39,
      "learning_rate": 0.0022994525393548386,
      "loss": 0.4529,
      "step": 605980
    },
    {
      "epoch": 977.42,
      "learning_rate": 0.002296226736129033,
      "loss": 0.457,
      "step": 606000
    },
    {
      "epoch": 977.45,
      "learning_rate": 0.0022930009329032272,
      "loss": 0.4533,
      "step": 606020
    },
    {
      "epoch": 977.48,
      "learning_rate": 0.0022897751296774215,
      "loss": 0.4528,
      "step": 606040
    },
    {
      "epoch": 977.52,
      "learning_rate": 0.0022865493264516154,
      "loss": 0.446,
      "step": 606060
    },
    {
      "epoch": 977.55,
      "learning_rate": 0.0022833235232258098,
      "loss": 0.4529,
      "step": 606080
    },
    {
      "epoch": 977.58,
      "learning_rate": 0.002280097720000004,
      "loss": 0.4524,
      "step": 606100
    },
    {
      "epoch": 977.61,
      "learning_rate": 0.0022768719167741984,
      "loss": 0.4523,
      "step": 606120
    },
    {
      "epoch": 977.65,
      "learning_rate": 0.0022736461135483815,
      "loss": 0.4492,
      "step": 606140
    },
    {
      "epoch": 977.68,
      "learning_rate": 0.002270420310322576,
      "loss": 0.4546,
      "step": 606160
    },
    {
      "epoch": 977.71,
      "learning_rate": 0.00226719450709677,
      "loss": 0.4688,
      "step": 606180
    },
    {
      "epoch": 977.74,
      "learning_rate": 0.0022639687038709644,
      "loss": 0.4565,
      "step": 606200
    },
    {
      "epoch": 977.77,
      "learning_rate": 0.0022607429006451588,
      "loss": 0.4459,
      "step": 606220
    },
    {
      "epoch": 977.81,
      "learning_rate": 0.002257517097419353,
      "loss": 0.4495,
      "step": 606240
    },
    {
      "epoch": 977.84,
      "learning_rate": 0.002254291294193547,
      "loss": 0.4564,
      "step": 606260
    },
    {
      "epoch": 977.87,
      "learning_rate": 0.0022510654909677413,
      "loss": 0.4585,
      "step": 606280
    },
    {
      "epoch": 977.9,
      "learning_rate": 0.0022478396877419356,
      "loss": 0.4564,
      "step": 606300
    },
    {
      "epoch": 977.94,
      "learning_rate": 0.00224461388451613,
      "loss": 0.4537,
      "step": 606320
    },
    {
      "epoch": 977.97,
      "learning_rate": 0.0022413880812903243,
      "loss": 0.461,
      "step": 606340
    },
    {
      "epoch": 978.0,
      "learning_rate": 0.0022381622780645186,
      "loss": 0.443,
      "step": 606360
    },
    {
      "epoch": 978.0,
      "eval_accuracy": {
        "accuracy": 0.7991569744750605
      },
      "eval_loss": 0.8137481808662415,
      "eval_runtime": 3.23,
      "eval_samples_per_second": 3966.283,
      "eval_steps_per_second": 62.23,
      "step": 606360
    },
    {
      "epoch": 978.03,
      "learning_rate": 0.002234936474838713,
      "loss": 0.4531,
      "step": 606380
    },
    {
      "epoch": 978.06,
      "learning_rate": 0.002231710671612907,
      "loss": 0.452,
      "step": 606400
    },
    {
      "epoch": 978.1,
      "learning_rate": 0.002228484868387101,
      "loss": 0.4559,
      "step": 606420
    },
    {
      "epoch": 978.13,
      "learning_rate": 0.0022252590651612955,
      "loss": 0.4531,
      "step": 606440
    },
    {
      "epoch": 978.16,
      "learning_rate": 0.0022220332619354785,
      "loss": 0.4428,
      "step": 606460
    },
    {
      "epoch": 978.19,
      "learning_rate": 0.002218807458709673,
      "loss": 0.4508,
      "step": 606480
    },
    {
      "epoch": 978.23,
      "learning_rate": 0.002215581655483867,
      "loss": 0.452,
      "step": 606500
    },
    {
      "epoch": 978.26,
      "learning_rate": 0.0022123558522580615,
      "loss": 0.4512,
      "step": 606520
    },
    {
      "epoch": 978.29,
      "learning_rate": 0.002209130049032256,
      "loss": 0.4502,
      "step": 606540
    },
    {
      "epoch": 978.32,
      "learning_rate": 0.00220590424580645,
      "loss": 0.4453,
      "step": 606560
    },
    {
      "epoch": 978.35,
      "learning_rate": 0.002202678442580644,
      "loss": 0.4564,
      "step": 606580
    },
    {
      "epoch": 978.39,
      "learning_rate": 0.0021994526393548383,
      "loss": 0.4506,
      "step": 606600
    },
    {
      "epoch": 978.42,
      "learning_rate": 0.0021962268361290327,
      "loss": 0.4499,
      "step": 606620
    },
    {
      "epoch": 978.45,
      "learning_rate": 0.002193001032903227,
      "loss": 0.4521,
      "step": 606640
    },
    {
      "epoch": 978.48,
      "learning_rate": 0.0021897752296774213,
      "loss": 0.4546,
      "step": 606660
    },
    {
      "epoch": 978.52,
      "learning_rate": 0.0021865494264516156,
      "loss": 0.4469,
      "step": 606680
    },
    {
      "epoch": 978.55,
      "learning_rate": 0.00218332362322581,
      "loss": 0.4532,
      "step": 606700
    },
    {
      "epoch": 978.58,
      "learning_rate": 0.002180097820000004,
      "loss": 0.4516,
      "step": 606720
    },
    {
      "epoch": 978.61,
      "learning_rate": 0.002176872016774198,
      "loss": 0.4429,
      "step": 606740
    },
    {
      "epoch": 978.65,
      "learning_rate": 0.0021736462135483817,
      "loss": 0.4627,
      "step": 606760
    },
    {
      "epoch": 978.68,
      "learning_rate": 0.0021704204103225756,
      "loss": 0.451,
      "step": 606780
    },
    {
      "epoch": 978.71,
      "learning_rate": 0.00216719460709677,
      "loss": 0.4514,
      "step": 606800
    },
    {
      "epoch": 978.74,
      "learning_rate": 0.002163968803870964,
      "loss": 0.4527,
      "step": 606820
    },
    {
      "epoch": 978.77,
      "learning_rate": 0.0021607430006451585,
      "loss": 0.4615,
      "step": 606840
    },
    {
      "epoch": 978.81,
      "learning_rate": 0.002157517197419353,
      "loss": 0.4488,
      "step": 606860
    },
    {
      "epoch": 978.84,
      "learning_rate": 0.002154291394193547,
      "loss": 0.4427,
      "step": 606880
    },
    {
      "epoch": 978.87,
      "learning_rate": 0.0021510655909677415,
      "loss": 0.4588,
      "step": 606900
    },
    {
      "epoch": 978.9,
      "learning_rate": 0.0021478397877419354,
      "loss": 0.4535,
      "step": 606920
    },
    {
      "epoch": 978.94,
      "learning_rate": 0.0021446139845161297,
      "loss": 0.4518,
      "step": 606940
    },
    {
      "epoch": 978.97,
      "learning_rate": 0.002141388181290324,
      "loss": 0.45,
      "step": 606960
    },
    {
      "epoch": 979.0,
      "learning_rate": 0.002138323668225804,
      "loss": 0.4591,
      "step": 606980
    },
    {
      "epoch": 979.0,
      "eval_accuracy": {
        "accuracy": 0.8004839590976505
      },
      "eval_loss": 0.8108921647071838,
      "eval_runtime": 3.1526,
      "eval_samples_per_second": 4063.652,
      "eval_steps_per_second": 63.757,
      "step": 606980
    },
    {
      "epoch": 979.03,
      "learning_rate": 0.0021350978649999977,
      "loss": 0.4491,
      "step": 607000
    },
    {
      "epoch": 979.06,
      "learning_rate": 0.002131872061774192,
      "loss": 0.456,
      "step": 607020
    },
    {
      "epoch": 979.1,
      "learning_rate": 0.0021286462585483864,
      "loss": 0.4483,
      "step": 607040
    },
    {
      "epoch": 979.13,
      "learning_rate": 0.0021254204553225807,
      "loss": 0.4454,
      "step": 607060
    },
    {
      "epoch": 979.16,
      "learning_rate": 0.002122194652096775,
      "loss": 0.4398,
      "step": 607080
    },
    {
      "epoch": 979.19,
      "learning_rate": 0.0021189688488709693,
      "loss": 0.453,
      "step": 607100
    },
    {
      "epoch": 979.23,
      "learning_rate": 0.0021157430456451637,
      "loss": 0.4535,
      "step": 607120
    },
    {
      "epoch": 979.26,
      "learning_rate": 0.0021125172424193575,
      "loss": 0.4537,
      "step": 607140
    },
    {
      "epoch": 979.29,
      "learning_rate": 0.002109291439193552,
      "loss": 0.4568,
      "step": 607160
    },
    {
      "epoch": 979.32,
      "learning_rate": 0.002106065635967746,
      "loss": 0.4511,
      "step": 607180
    },
    {
      "epoch": 979.35,
      "learning_rate": 0.0021028398327419405,
      "loss": 0.4528,
      "step": 607200
    },
    {
      "epoch": 979.39,
      "learning_rate": 0.0020996140295161236,
      "loss": 0.4542,
      "step": 607220
    },
    {
      "epoch": 979.42,
      "learning_rate": 0.002096388226290318,
      "loss": 0.4478,
      "step": 607240
    },
    {
      "epoch": 979.45,
      "learning_rate": 0.002093162423064512,
      "loss": 0.456,
      "step": 607260
    },
    {
      "epoch": 979.48,
      "learning_rate": 0.0020899366198387065,
      "loss": 0.4514,
      "step": 607280
    },
    {
      "epoch": 979.52,
      "learning_rate": 0.002086710816612901,
      "loss": 0.4482,
      "step": 607300
    },
    {
      "epoch": 979.55,
      "learning_rate": 0.002083485013387095,
      "loss": 0.4544,
      "step": 607320
    },
    {
      "epoch": 979.58,
      "learning_rate": 0.002080259210161289,
      "loss": 0.4533,
      "step": 607340
    },
    {
      "epoch": 979.61,
      "learning_rate": 0.0020770334069354834,
      "loss": 0.4561,
      "step": 607360
    },
    {
      "epoch": 979.65,
      "learning_rate": 0.0020738076037096777,
      "loss": 0.4511,
      "step": 607380
    },
    {
      "epoch": 979.68,
      "learning_rate": 0.002070581800483872,
      "loss": 0.4521,
      "step": 607400
    },
    {
      "epoch": 979.71,
      "learning_rate": 0.0020673559972580664,
      "loss": 0.4542,
      "step": 607420
    },
    {
      "epoch": 979.74,
      "learning_rate": 0.0020641301940322607,
      "loss": 0.4546,
      "step": 607440
    },
    {
      "epoch": 979.77,
      "learning_rate": 0.002060904390806455,
      "loss": 0.4462,
      "step": 607460
    },
    {
      "epoch": 979.81,
      "learning_rate": 0.002057678587580649,
      "loss": 0.4523,
      "step": 607480
    },
    {
      "epoch": 979.84,
      "learning_rate": 0.0020544527843548432,
      "loss": 0.4566,
      "step": 607500
    },
    {
      "epoch": 979.87,
      "learning_rate": 0.0020512269811290376,
      "loss": 0.4411,
      "step": 607520
    },
    {
      "epoch": 979.9,
      "learning_rate": 0.0020480011779032206,
      "loss": 0.4482,
      "step": 607540
    },
    {
      "epoch": 979.94,
      "learning_rate": 0.002044775374677415,
      "loss": 0.4519,
      "step": 607560
    },
    {
      "epoch": 979.97,
      "learning_rate": 0.0020415495714516093,
      "loss": 0.4465,
      "step": 607580
    },
    {
      "epoch": 980.0,
      "learning_rate": 0.0020383237682258036,
      "loss": 0.4551,
      "step": 607600
    },
    {
      "epoch": 980.0,
      "eval_accuracy": {
        "accuracy": 0.7999375536648193
      },
      "eval_loss": 0.8088132739067078,
      "eval_runtime": 3.2136,
      "eval_samples_per_second": 3986.542,
      "eval_steps_per_second": 62.547,
      "step": 607600
    },
    {
      "epoch": 980.03,
      "learning_rate": 0.002035097964999998,
      "loss": 0.4547,
      "step": 607620
    },
    {
      "epoch": 980.06,
      "learning_rate": 0.0020318721617741922,
      "loss": 0.4543,
      "step": 607640
    },
    {
      "epoch": 980.1,
      "learning_rate": 0.002028646358548386,
      "loss": 0.4418,
      "step": 607660
    },
    {
      "epoch": 980.13,
      "learning_rate": 0.0020254205553225805,
      "loss": 0.4494,
      "step": 607680
    },
    {
      "epoch": 980.16,
      "learning_rate": 0.0020221947520967748,
      "loss": 0.4442,
      "step": 607700
    },
    {
      "epoch": 980.19,
      "learning_rate": 0.002018968948870969,
      "loss": 0.4514,
      "step": 607720
    },
    {
      "epoch": 980.23,
      "learning_rate": 0.0020157431456451634,
      "loss": 0.453,
      "step": 607740
    },
    {
      "epoch": 980.26,
      "learning_rate": 0.0020125173424193578,
      "loss": 0.4519,
      "step": 607760
    },
    {
      "epoch": 980.29,
      "learning_rate": 0.002009291539193552,
      "loss": 0.4491,
      "step": 607780
    },
    {
      "epoch": 980.32,
      "learning_rate": 0.002006065735967746,
      "loss": 0.4559,
      "step": 607800
    },
    {
      "epoch": 980.35,
      "learning_rate": 0.0020028399327419403,
      "loss": 0.4525,
      "step": 607820
    },
    {
      "epoch": 980.39,
      "learning_rate": 0.0019996141295161238,
      "loss": 0.451,
      "step": 607840
    },
    {
      "epoch": 980.42,
      "learning_rate": 0.0019963883262903177,
      "loss": 0.4564,
      "step": 607860
    },
    {
      "epoch": 980.45,
      "learning_rate": 0.001993162523064512,
      "loss": 0.4423,
      "step": 607880
    },
    {
      "epoch": 980.48,
      "learning_rate": 0.0019899367198387063,
      "loss": 0.4554,
      "step": 607900
    },
    {
      "epoch": 980.52,
      "learning_rate": 0.0019867109166129006,
      "loss": 0.4504,
      "step": 607920
    },
    {
      "epoch": 980.55,
      "learning_rate": 0.001983485113387095,
      "loss": 0.4497,
      "step": 607940
    },
    {
      "epoch": 980.58,
      "learning_rate": 0.0019802593101612893,
      "loss": 0.4491,
      "step": 607960
    },
    {
      "epoch": 980.61,
      "learning_rate": 0.0019770335069354836,
      "loss": 0.4541,
      "step": 607980
    },
    {
      "epoch": 980.65,
      "learning_rate": 0.0019738077037096775,
      "loss": 0.4552,
      "step": 608000
    },
    {
      "epoch": 980.68,
      "learning_rate": 0.001970581900483872,
      "loss": 0.4519,
      "step": 608020
    },
    {
      "epoch": 980.71,
      "learning_rate": 0.001967356097258066,
      "loss": 0.4468,
      "step": 608040
    },
    {
      "epoch": 980.74,
      "learning_rate": 0.0019641302940322605,
      "loss": 0.4488,
      "step": 608060
    },
    {
      "epoch": 980.77,
      "learning_rate": 0.001960904490806455,
      "loss": 0.4527,
      "step": 608080
    },
    {
      "epoch": 980.81,
      "learning_rate": 0.001957678687580649,
      "loss": 0.4413,
      "step": 608100
    },
    {
      "epoch": 980.84,
      "learning_rate": 0.0019544528843548434,
      "loss": 0.4439,
      "step": 608120
    },
    {
      "epoch": 980.87,
      "learning_rate": 0.0019512270811290378,
      "loss": 0.4579,
      "step": 608140
    },
    {
      "epoch": 980.9,
      "learning_rate": 0.0019480012779032208,
      "loss": 0.4544,
      "step": 608160
    },
    {
      "epoch": 980.94,
      "learning_rate": 0.0019447754746774151,
      "loss": 0.4503,
      "step": 608180
    },
    {
      "epoch": 980.97,
      "learning_rate": 0.0019415496714516095,
      "loss": 0.4529,
      "step": 608200
    },
    {
      "epoch": 981.0,
      "learning_rate": 0.0019383238682258036,
      "loss": 0.4552,
      "step": 608220
    },
    {
      "epoch": 981.0,
      "eval_accuracy": {
        "accuracy": 0.7999375536648193
      },
      "eval_loss": 0.8093166947364807,
      "eval_runtime": 3.1694,
      "eval_samples_per_second": 4042.099,
      "eval_steps_per_second": 63.419,
      "step": 608220
    },
    {
      "epoch": 981.03,
      "learning_rate": 0.001935098064999998,
      "loss": 0.4522,
      "step": 608240
    },
    {
      "epoch": 981.06,
      "learning_rate": 0.001931872261774192,
      "loss": 0.4394,
      "step": 608260
    },
    {
      "epoch": 981.1,
      "learning_rate": 0.0019286464585483868,
      "loss": 0.4414,
      "step": 608280
    },
    {
      "epoch": 981.13,
      "learning_rate": 0.0019254206553225807,
      "loss": 0.4511,
      "step": 608300
    },
    {
      "epoch": 981.16,
      "learning_rate": 0.0019221948520967748,
      "loss": 0.4438,
      "step": 608320
    },
    {
      "epoch": 981.19,
      "learning_rate": 0.0019189690488709693,
      "loss": 0.4507,
      "step": 608340
    },
    {
      "epoch": 981.23,
      "learning_rate": 0.0019157432456451632,
      "loss": 0.457,
      "step": 608360
    },
    {
      "epoch": 981.26,
      "learning_rate": 0.001912517442419358,
      "loss": 0.4525,
      "step": 608380
    },
    {
      "epoch": 981.29,
      "learning_rate": 0.001909291639193552,
      "loss": 0.4467,
      "step": 608400
    },
    {
      "epoch": 981.32,
      "learning_rate": 0.0019060658359677464,
      "loss": 0.4608,
      "step": 608420
    },
    {
      "epoch": 981.35,
      "learning_rate": 0.0019028400327419405,
      "loss": 0.4472,
      "step": 608440
    },
    {
      "epoch": 981.39,
      "learning_rate": 0.0018996142295161238,
      "loss": 0.4406,
      "step": 608460
    },
    {
      "epoch": 981.42,
      "learning_rate": 0.0018963884262903179,
      "loss": 0.4444,
      "step": 608480
    },
    {
      "epoch": 981.45,
      "learning_rate": 0.0018931626230645122,
      "loss": 0.4477,
      "step": 608500
    },
    {
      "epoch": 981.48,
      "learning_rate": 0.0018899368198387065,
      "loss": 0.45,
      "step": 608520
    },
    {
      "epoch": 981.52,
      "learning_rate": 0.0018867110166129006,
      "loss": 0.4583,
      "step": 608540
    },
    {
      "epoch": 981.55,
      "learning_rate": 0.001883485213387095,
      "loss": 0.4523,
      "step": 608560
    },
    {
      "epoch": 981.58,
      "learning_rate": 0.001880259410161289,
      "loss": 0.4428,
      "step": 608580
    },
    {
      "epoch": 981.61,
      "learning_rate": 0.0018770336069354838,
      "loss": 0.4552,
      "step": 608600
    },
    {
      "epoch": 981.65,
      "learning_rate": 0.0018738078037096777,
      "loss": 0.4571,
      "step": 608620
    },
    {
      "epoch": 981.68,
      "learning_rate": 0.0018705820004838718,
      "loss": 0.4485,
      "step": 608640
    },
    {
      "epoch": 981.71,
      "learning_rate": 0.0018673561972580664,
      "loss": 0.4536,
      "step": 608660
    },
    {
      "epoch": 981.74,
      "learning_rate": 0.0018641303940322607,
      "loss": 0.4538,
      "step": 608680
    },
    {
      "epoch": 981.77,
      "learning_rate": 0.001860904590806455,
      "loss": 0.4571,
      "step": 608700
    },
    {
      "epoch": 981.81,
      "learning_rate": 0.0018576787875806491,
      "loss": 0.445,
      "step": 608720
    },
    {
      "epoch": 981.84,
      "learning_rate": 0.0018544529843548434,
      "loss": 0.4512,
      "step": 608740
    },
    {
      "epoch": 981.87,
      "learning_rate": 0.0018512271811290375,
      "loss": 0.4526,
      "step": 608760
    },
    {
      "epoch": 981.9,
      "learning_rate": 0.0018480013779032208,
      "loss": 0.4524,
      "step": 608780
    },
    {
      "epoch": 981.94,
      "learning_rate": 0.001844775574677415,
      "loss": 0.4472,
      "step": 608800
    },
    {
      "epoch": 981.97,
      "learning_rate": 0.0018415497714516092,
      "loss": 0.4527,
      "step": 608820
    },
    {
      "epoch": 982.0,
      "learning_rate": 0.0018383239682258036,
      "loss": 0.452,
      "step": 608840
    },
    {
      "epoch": 982.0,
      "eval_accuracy": {
        "accuracy": 0.801420654125361
      },
      "eval_loss": 0.8114866018295288,
      "eval_runtime": 4.4174,
      "eval_samples_per_second": 2900.111,
      "eval_steps_per_second": 45.502,
      "step": 608840
    },
    {
      "epoch": 982.03,
      "learning_rate": 0.0018350981649999977,
      "loss": 0.4584,
      "step": 608860
    },
    {
      "epoch": 982.06,
      "learning_rate": 0.0018318723617741922,
      "loss": 0.4447,
      "step": 608880
    },
    {
      "epoch": 982.1,
      "learning_rate": 0.001828646558548386,
      "loss": 0.4453,
      "step": 608900
    },
    {
      "epoch": 982.13,
      "learning_rate": 0.0018254207553225809,
      "loss": 0.455,
      "step": 608920
    },
    {
      "epoch": 982.16,
      "learning_rate": 0.001822194952096775,
      "loss": 0.4571,
      "step": 608940
    },
    {
      "epoch": 982.19,
      "learning_rate": 0.0018189691488709689,
      "loss": 0.4565,
      "step": 608960
    },
    {
      "epoch": 982.23,
      "learning_rate": 0.0018157433456451634,
      "loss": 0.4439,
      "step": 608980
    },
    {
      "epoch": 982.26,
      "learning_rate": 0.0018125175424193577,
      "loss": 0.4498,
      "step": 609000
    },
    {
      "epoch": 982.29,
      "learning_rate": 0.001809291739193552,
      "loss": 0.4589,
      "step": 609020
    },
    {
      "epoch": 982.32,
      "learning_rate": 0.0018060659359677462,
      "loss": 0.4489,
      "step": 609040
    },
    {
      "epoch": 982.35,
      "learning_rate": 0.0018028401327419405,
      "loss": 0.4469,
      "step": 609060
    },
    {
      "epoch": 982.39,
      "learning_rate": 0.0017996143295161235,
      "loss": 0.4472,
      "step": 609080
    },
    {
      "epoch": 982.42,
      "learning_rate": 0.0017963885262903179,
      "loss": 0.4497,
      "step": 609100
    },
    {
      "epoch": 982.45,
      "learning_rate": 0.001793162723064512,
      "loss": 0.4507,
      "step": 609120
    },
    {
      "epoch": 982.48,
      "learning_rate": 0.0017899369198387067,
      "loss": 0.4492,
      "step": 609140
    },
    {
      "epoch": 982.52,
      "learning_rate": 0.0017867111166129006,
      "loss": 0.4476,
      "step": 609160
    },
    {
      "epoch": 982.55,
      "learning_rate": 0.0017834853133870947,
      "loss": 0.4486,
      "step": 609180
    },
    {
      "epoch": 982.58,
      "learning_rate": 0.0017802595101612893,
      "loss": 0.4554,
      "step": 609200
    },
    {
      "epoch": 982.61,
      "learning_rate": 0.0017770337069354832,
      "loss": 0.4386,
      "step": 609220
    },
    {
      "epoch": 982.65,
      "learning_rate": 0.001773807903709678,
      "loss": 0.4539,
      "step": 609240
    },
    {
      "epoch": 982.68,
      "learning_rate": 0.001770582100483872,
      "loss": 0.4443,
      "step": 609260
    },
    {
      "epoch": 982.71,
      "learning_rate": 0.0017673562972580663,
      "loss": 0.4474,
      "step": 609280
    },
    {
      "epoch": 982.74,
      "learning_rate": 0.0017641304940322605,
      "loss": 0.4617,
      "step": 609300
    },
    {
      "epoch": 982.77,
      "learning_rate": 0.0017609046908064548,
      "loss": 0.4532,
      "step": 609320
    },
    {
      "epoch": 982.81,
      "learning_rate": 0.001757678887580649,
      "loss": 0.4507,
      "step": 609340
    },
    {
      "epoch": 982.84,
      "learning_rate": 0.0017544530843548432,
      "loss": 0.4493,
      "step": 609360
    },
    {
      "epoch": 982.87,
      "learning_rate": 0.0017512272811290375,
      "loss": 0.4515,
      "step": 609380
    },
    {
      "epoch": 982.9,
      "learning_rate": 0.0017480014779032206,
      "loss": 0.4385,
      "step": 609400
    },
    {
      "epoch": 982.94,
      "learning_rate": 0.001744775674677415,
      "loss": 0.4442,
      "step": 609420
    },
    {
      "epoch": 982.97,
      "learning_rate": 0.001741549871451609,
      "loss": 0.4441,
      "step": 609440
    },
    {
      "epoch": 983.0,
      "learning_rate": 0.0017383240682258038,
      "loss": 0.4528,
      "step": 609460
    },
    {
      "epoch": 983.0,
      "eval_accuracy": {
        "accuracy": 0.8015767699633127
      },
      "eval_loss": 0.8122106194496155,
      "eval_runtime": 3.2763,
      "eval_samples_per_second": 3910.186,
      "eval_steps_per_second": 61.349,
      "step": 609460
    },
    {
      "epoch": 983.03,
      "learning_rate": 0.0017350982649999977,
      "loss": 0.4475,
      "step": 609480
    },
    {
      "epoch": 983.06,
      "learning_rate": 0.0017318724617741918,
      "loss": 0.4453,
      "step": 609500
    },
    {
      "epoch": 983.1,
      "learning_rate": 0.0017286466585483863,
      "loss": 0.4489,
      "step": 609520
    },
    {
      "epoch": 983.13,
      "learning_rate": 0.0017254208553225806,
      "loss": 0.4402,
      "step": 609540
    },
    {
      "epoch": 983.16,
      "learning_rate": 0.001722195052096775,
      "loss": 0.4505,
      "step": 609560
    },
    {
      "epoch": 983.19,
      "learning_rate": 0.001718969248870969,
      "loss": 0.45,
      "step": 609580
    },
    {
      "epoch": 983.23,
      "learning_rate": 0.0017157434456451634,
      "loss": 0.4436,
      "step": 609600
    },
    {
      "epoch": 983.26,
      "learning_rate": 0.0017125176424193575,
      "loss": 0.4454,
      "step": 609620
    },
    {
      "epoch": 983.29,
      "learning_rate": 0.0017092918391935518,
      "loss": 0.4512,
      "step": 609640
    },
    {
      "epoch": 983.32,
      "learning_rate": 0.0017060660359677461,
      "loss": 0.4469,
      "step": 609660
    },
    {
      "epoch": 983.35,
      "learning_rate": 0.0017028402327419403,
      "loss": 0.4542,
      "step": 609680
    },
    {
      "epoch": 983.39,
      "learning_rate": 0.0016996144295161346,
      "loss": 0.4472,
      "step": 609700
    },
    {
      "epoch": 983.42,
      "learning_rate": 0.0016963886262903176,
      "loss": 0.4494,
      "step": 609720
    },
    {
      "epoch": 983.45,
      "learning_rate": 0.001693162823064512,
      "loss": 0.4506,
      "step": 609740
    },
    {
      "epoch": 983.48,
      "learning_rate": 0.001689937019838706,
      "loss": 0.4527,
      "step": 609760
    },
    {
      "epoch": 983.52,
      "learning_rate": 0.0016867112166129008,
      "loss": 0.4508,
      "step": 609780
    },
    {
      "epoch": 983.55,
      "learning_rate": 0.001683485413387095,
      "loss": 0.4442,
      "step": 609800
    },
    {
      "epoch": 983.58,
      "learning_rate": 0.0016802596101612888,
      "loss": 0.4577,
      "step": 609820
    },
    {
      "epoch": 983.61,
      "learning_rate": 0.0016770338069354834,
      "loss": 0.4493,
      "step": 609840
    },
    {
      "epoch": 983.65,
      "learning_rate": 0.0016738080037096777,
      "loss": 0.4476,
      "step": 609860
    },
    {
      "epoch": 983.68,
      "learning_rate": 0.001670582200483872,
      "loss": 0.4568,
      "step": 609880
    },
    {
      "epoch": 983.71,
      "learning_rate": 0.0016673563972580661,
      "loss": 0.4539,
      "step": 609900
    },
    {
      "epoch": 983.74,
      "learning_rate": 0.0016641305940322604,
      "loss": 0.4494,
      "step": 609920
    },
    {
      "epoch": 983.77,
      "learning_rate": 0.0016609047908064545,
      "loss": 0.4434,
      "step": 609940
    },
    {
      "epoch": 983.81,
      "learning_rate": 0.0016576789875806489,
      "loss": 0.4467,
      "step": 609960
    },
    {
      "epoch": 983.84,
      "learning_rate": 0.0016544531843548432,
      "loss": 0.4446,
      "step": 609980
    },
    {
      "epoch": 983.87,
      "learning_rate": 0.0016512273811290373,
      "loss": 0.4478,
      "step": 610000
    },
    {
      "epoch": 983.9,
      "learning_rate": 0.0016480015779032206,
      "loss": 0.4551,
      "step": 610020
    },
    {
      "epoch": 983.94,
      "learning_rate": 0.0016447757746774147,
      "loss": 0.4501,
      "step": 610040
    },
    {
      "epoch": 983.97,
      "learning_rate": 0.0016415499714516092,
      "loss": 0.4461,
      "step": 610060
    },
    {
      "epoch": 984.0,
      "learning_rate": 0.0016384854583870998,
      "loss": 0.4554,
      "step": 610080
    },
    {
      "epoch": 984.0,
      "eval_accuracy": {
        "accuracy": 0.7986886269612052
      },
      "eval_loss": 0.8092015981674194,
      "eval_runtime": 3.1094,
      "eval_samples_per_second": 4120.09,
      "eval_steps_per_second": 64.643,
      "step": 610080
    },
    {
      "epoch": 984.03,
      "learning_rate": 0.0016352596551612942,
      "loss": 0.4532,
      "step": 610100
    },
    {
      "epoch": 984.06,
      "learning_rate": 0.0016320338519354883,
      "loss": 0.4523,
      "step": 610120
    },
    {
      "epoch": 984.1,
      "learning_rate": 0.0016288080487096826,
      "loss": 0.449,
      "step": 610140
    },
    {
      "epoch": 984.13,
      "learning_rate": 0.0016255822454838656,
      "loss": 0.4486,
      "step": 610160
    },
    {
      "epoch": 984.16,
      "learning_rate": 0.00162235644225806,
      "loss": 0.4442,
      "step": 610180
    },
    {
      "epoch": 984.19,
      "learning_rate": 0.001619130639032254,
      "loss": 0.4435,
      "step": 610200
    },
    {
      "epoch": 984.23,
      "learning_rate": 0.0016159048358064488,
      "loss": 0.4576,
      "step": 610220
    },
    {
      "epoch": 984.26,
      "learning_rate": 0.0016126790325806427,
      "loss": 0.4438,
      "step": 610240
    },
    {
      "epoch": 984.29,
      "learning_rate": 0.0016094532293548368,
      "loss": 0.4496,
      "step": 610260
    },
    {
      "epoch": 984.32,
      "learning_rate": 0.0016062274261290314,
      "loss": 0.4461,
      "step": 610280
    },
    {
      "epoch": 984.35,
      "learning_rate": 0.0016030016229032253,
      "loss": 0.4485,
      "step": 610300
    },
    {
      "epoch": 984.39,
      "learning_rate": 0.00159977581967742,
      "loss": 0.4536,
      "step": 610320
    },
    {
      "epoch": 984.42,
      "learning_rate": 0.0015965500164516141,
      "loss": 0.4454,
      "step": 610340
    },
    {
      "epoch": 984.45,
      "learning_rate": 0.0015933242132258084,
      "loss": 0.4538,
      "step": 610360
    },
    {
      "epoch": 984.48,
      "learning_rate": 0.0015900984100000026,
      "loss": 0.4545,
      "step": 610380
    },
    {
      "epoch": 984.52,
      "learning_rate": 0.0015868726067741969,
      "loss": 0.4494,
      "step": 610400
    },
    {
      "epoch": 984.55,
      "learning_rate": 0.0015836468035483912,
      "loss": 0.4489,
      "step": 610420
    },
    {
      "epoch": 984.58,
      "learning_rate": 0.0015804210003225853,
      "loss": 0.4399,
      "step": 610440
    },
    {
      "epoch": 984.61,
      "learning_rate": 0.0015771951970967796,
      "loss": 0.4451,
      "step": 610460
    },
    {
      "epoch": 984.65,
      "learning_rate": 0.0015739693938709627,
      "loss": 0.4495,
      "step": 610480
    },
    {
      "epoch": 984.68,
      "learning_rate": 0.001570743590645157,
      "loss": 0.4424,
      "step": 610500
    },
    {
      "epoch": 984.71,
      "learning_rate": 0.0015675177874193511,
      "loss": 0.4551,
      "step": 610520
    },
    {
      "epoch": 984.74,
      "learning_rate": 0.0015642919841935459,
      "loss": 0.4429,
      "step": 610540
    },
    {
      "epoch": 984.77,
      "learning_rate": 0.0015610661809677398,
      "loss": 0.4457,
      "step": 610560
    },
    {
      "epoch": 984.81,
      "learning_rate": 0.001557840377741934,
      "loss": 0.4493,
      "step": 610580
    },
    {
      "epoch": 984.84,
      "learning_rate": 0.0015546145745161284,
      "loss": 0.4453,
      "step": 610600
    },
    {
      "epoch": 984.87,
      "learning_rate": 0.0015513887712903227,
      "loss": 0.4471,
      "step": 610620
    },
    {
      "epoch": 984.9,
      "learning_rate": 0.0015481629680645168,
      "loss": 0.4467,
      "step": 610640
    },
    {
      "epoch": 984.94,
      "learning_rate": 0.0015449371648387112,
      "loss": 0.4548,
      "step": 610660
    },
    {
      "epoch": 984.97,
      "learning_rate": 0.0015417113616129055,
      "loss": 0.4521,
      "step": 610680
    },
    {
      "epoch": 985.0,
      "learning_rate": 0.0015384855583870996,
      "loss": 0.4541,
      "step": 610700
    },
    {
      "epoch": 985.0,
      "eval_accuracy": {
        "accuracy": 0.800796190773554
      },
      "eval_loss": 0.8076396584510803,
      "eval_runtime": 3.147,
      "eval_samples_per_second": 4070.872,
      "eval_steps_per_second": 63.871,
      "step": 610700
    },
    {
      "epoch": 985.03,
      "learning_rate": 0.001535259755161294,
      "loss": 0.4462,
      "step": 610720
    },
    {
      "epoch": 985.06,
      "learning_rate": 0.0015320339519354883,
      "loss": 0.4473,
      "step": 610740
    },
    {
      "epoch": 985.1,
      "learning_rate": 0.0015288081487096826,
      "loss": 0.4554,
      "step": 610760
    },
    {
      "epoch": 985.13,
      "learning_rate": 0.0015255823454838656,
      "loss": 0.4412,
      "step": 610780
    },
    {
      "epoch": 985.16,
      "learning_rate": 0.00152235654225806,
      "loss": 0.4511,
      "step": 610800
    },
    {
      "epoch": 985.19,
      "learning_rate": 0.0015191307390322543,
      "loss": 0.4412,
      "step": 610820
    },
    {
      "epoch": 985.23,
      "learning_rate": 0.0015159049358064484,
      "loss": 0.4484,
      "step": 610840
    },
    {
      "epoch": 985.26,
      "learning_rate": 0.0015126791325806427,
      "loss": 0.4514,
      "step": 610860
    },
    {
      "epoch": 985.29,
      "learning_rate": 0.001509453329354837,
      "loss": 0.4487,
      "step": 610880
    },
    {
      "epoch": 985.32,
      "learning_rate": 0.0015062275261290311,
      "loss": 0.4442,
      "step": 610900
    },
    {
      "epoch": 985.35,
      "learning_rate": 0.0015030017229032255,
      "loss": 0.4452,
      "step": 610920
    },
    {
      "epoch": 985.39,
      "learning_rate": 0.0014997759196774198,
      "loss": 0.4548,
      "step": 610940
    },
    {
      "epoch": 985.42,
      "learning_rate": 0.0014965501164516141,
      "loss": 0.4537,
      "step": 610960
    },
    {
      "epoch": 985.45,
      "learning_rate": 0.0014933243132258082,
      "loss": 0.4405,
      "step": 610980
    },
    {
      "epoch": 985.48,
      "learning_rate": 0.0014900985100000025,
      "loss": 0.4538,
      "step": 611000
    },
    {
      "epoch": 985.52,
      "learning_rate": 0.0014868727067741969,
      "loss": 0.4546,
      "step": 611020
    },
    {
      "epoch": 985.55,
      "learning_rate": 0.001483646903548391,
      "loss": 0.446,
      "step": 611040
    },
    {
      "epoch": 985.58,
      "learning_rate": 0.0014804211003225853,
      "loss": 0.4432,
      "step": 611060
    },
    {
      "epoch": 985.61,
      "learning_rate": 0.0014771952970967796,
      "loss": 0.4426,
      "step": 611080
    },
    {
      "epoch": 985.65,
      "learning_rate": 0.0014739694938709627,
      "loss": 0.4508,
      "step": 611100
    },
    {
      "epoch": 985.68,
      "learning_rate": 0.001470743690645157,
      "loss": 0.4396,
      "step": 611120
    },
    {
      "epoch": 985.71,
      "learning_rate": 0.0014675178874193513,
      "loss": 0.4522,
      "step": 611140
    },
    {
      "epoch": 985.74,
      "learning_rate": 0.0014642920841935454,
      "loss": 0.4417,
      "step": 611160
    },
    {
      "epoch": 985.77,
      "learning_rate": 0.0014610662809677398,
      "loss": 0.4497,
      "step": 611180
    },
    {
      "epoch": 985.81,
      "learning_rate": 0.001457840477741934,
      "loss": 0.4545,
      "step": 611200
    },
    {
      "epoch": 985.84,
      "learning_rate": 0.0014546146745161284,
      "loss": 0.4508,
      "step": 611220
    },
    {
      "epoch": 985.87,
      "learning_rate": 0.0014513888712903225,
      "loss": 0.4512,
      "step": 611240
    },
    {
      "epoch": 985.9,
      "learning_rate": 0.0014481630680645168,
      "loss": 0.4518,
      "step": 611260
    },
    {
      "epoch": 985.94,
      "learning_rate": 0.0014449372648387112,
      "loss": 0.4404,
      "step": 611280
    },
    {
      "epoch": 985.97,
      "learning_rate": 0.0014417114616129053,
      "loss": 0.4463,
      "step": 611300
    },
    {
      "epoch": 986.0,
      "learning_rate": 0.0014384856583870996,
      "loss": 0.4547,
      "step": 611320
    },
    {
      "epoch": 986.0,
      "eval_accuracy": {
        "accuracy": 0.7999375536648193
      },
      "eval_loss": 0.8070211410522461,
      "eval_runtime": 3.2253,
      "eval_samples_per_second": 3972.002,
      "eval_steps_per_second": 62.319,
      "step": 611320
    },
    {
      "epoch": 986.03,
      "learning_rate": 0.001435259855161294,
      "loss": 0.445,
      "step": 611340
    },
    {
      "epoch": 986.06,
      "learning_rate": 0.0014320340519354882,
      "loss": 0.4425,
      "step": 611360
    },
    {
      "epoch": 986.1,
      "learning_rate": 0.0014288082487096824,
      "loss": 0.4466,
      "step": 611380
    },
    {
      "epoch": 986.13,
      "learning_rate": 0.0014255824454838656,
      "loss": 0.4519,
      "step": 611400
    },
    {
      "epoch": 986.16,
      "learning_rate": 0.0014223566422580597,
      "loss": 0.4529,
      "step": 611420
    },
    {
      "epoch": 986.19,
      "learning_rate": 0.001419130839032254,
      "loss": 0.4432,
      "step": 611440
    },
    {
      "epoch": 986.23,
      "learning_rate": 0.0014159050358064484,
      "loss": 0.4543,
      "step": 611460
    },
    {
      "epoch": 986.26,
      "learning_rate": 0.0014126792325806427,
      "loss": 0.4454,
      "step": 611480
    },
    {
      "epoch": 986.29,
      "learning_rate": 0.0014094534293548368,
      "loss": 0.4389,
      "step": 611500
    },
    {
      "epoch": 986.32,
      "learning_rate": 0.0014062276261290311,
      "loss": 0.4621,
      "step": 611520
    },
    {
      "epoch": 986.35,
      "learning_rate": 0.0014030018229032255,
      "loss": 0.4436,
      "step": 611540
    },
    {
      "epoch": 986.39,
      "learning_rate": 0.0013997760196774196,
      "loss": 0.4499,
      "step": 611560
    },
    {
      "epoch": 986.42,
      "learning_rate": 0.0013965502164516139,
      "loss": 0.447,
      "step": 611580
    },
    {
      "epoch": 986.45,
      "learning_rate": 0.0013933244132258082,
      "loss": 0.4507,
      "step": 611600
    },
    {
      "epoch": 986.48,
      "learning_rate": 0.0013900986100000025,
      "loss": 0.4547,
      "step": 611620
    },
    {
      "epoch": 986.52,
      "learning_rate": 0.0013868728067741966,
      "loss": 0.4445,
      "step": 611640
    },
    {
      "epoch": 986.55,
      "learning_rate": 0.001383647003548391,
      "loss": 0.438,
      "step": 611660
    },
    {
      "epoch": 986.58,
      "learning_rate": 0.0013804212003225853,
      "loss": 0.4362,
      "step": 611680
    },
    {
      "epoch": 986.61,
      "learning_rate": 0.0013771953970967794,
      "loss": 0.4421,
      "step": 611700
    },
    {
      "epoch": 986.65,
      "learning_rate": 0.0013739695938709627,
      "loss": 0.4509,
      "step": 611720
    },
    {
      "epoch": 986.68,
      "learning_rate": 0.001370743790645157,
      "loss": 0.4482,
      "step": 611740
    },
    {
      "epoch": 986.71,
      "learning_rate": 0.001367517987419351,
      "loss": 0.4477,
      "step": 611760
    },
    {
      "epoch": 986.74,
      "learning_rate": 0.0013642921841935454,
      "loss": 0.4517,
      "step": 611780
    },
    {
      "epoch": 986.77,
      "learning_rate": 0.0013610663809677397,
      "loss": 0.4473,
      "step": 611800
    },
    {
      "epoch": 986.81,
      "learning_rate": 0.0013578405777419339,
      "loss": 0.4415,
      "step": 611820
    },
    {
      "epoch": 986.84,
      "learning_rate": 0.0013546147745161282,
      "loss": 0.454,
      "step": 611840
    },
    {
      "epoch": 986.87,
      "learning_rate": 0.0013513889712903225,
      "loss": 0.4448,
      "step": 611860
    },
    {
      "epoch": 986.9,
      "learning_rate": 0.0013481631680645168,
      "loss": 0.4461,
      "step": 611880
    },
    {
      "epoch": 986.94,
      "learning_rate": 0.001344937364838711,
      "loss": 0.4537,
      "step": 611900
    },
    {
      "epoch": 986.97,
      "learning_rate": 0.0013417115616129053,
      "loss": 0.4521,
      "step": 611920
    },
    {
      "epoch": 987.0,
      "learning_rate": 0.0013384857583870996,
      "loss": 0.4529,
      "step": 611940
    },
    {
      "epoch": 987.0,
      "eval_accuracy": {
        "accuracy": 0.8025915229099992
      },
      "eval_loss": 0.8086068630218506,
      "eval_runtime": 3.3621,
      "eval_samples_per_second": 3810.372,
      "eval_steps_per_second": 59.783,
      "step": 611940
    },
    {
      "epoch": 987.03,
      "learning_rate": 0.0013352599551612937,
      "loss": 0.4436,
      "step": 611960
    },
    {
      "epoch": 987.06,
      "learning_rate": 0.001332034151935488,
      "loss": 0.4531,
      "step": 611980
    },
    {
      "epoch": 987.1,
      "learning_rate": 0.0013288083487096823,
      "loss": 0.449,
      "step": 612000
    },
    {
      "epoch": 987.13,
      "learning_rate": 0.0013255825454838767,
      "loss": 0.4389,
      "step": 612020
    },
    {
      "epoch": 987.16,
      "learning_rate": 0.0013223567422580597,
      "loss": 0.4435,
      "step": 612040
    },
    {
      "epoch": 987.19,
      "learning_rate": 0.001319130939032254,
      "loss": 0.4423,
      "step": 612060
    },
    {
      "epoch": 987.23,
      "learning_rate": 0.0013159051358064484,
      "loss": 0.4413,
      "step": 612080
    },
    {
      "epoch": 987.26,
      "learning_rate": 0.0013126793325806425,
      "loss": 0.4524,
      "step": 612100
    },
    {
      "epoch": 987.29,
      "learning_rate": 0.0013094535293548368,
      "loss": 0.443,
      "step": 612120
    },
    {
      "epoch": 987.32,
      "learning_rate": 0.0013062277261290311,
      "loss": 0.4499,
      "step": 612140
    },
    {
      "epoch": 987.35,
      "learning_rate": 0.0013030019229032252,
      "loss": 0.441,
      "step": 612160
    },
    {
      "epoch": 987.39,
      "learning_rate": 0.0012997761196774195,
      "loss": 0.4537,
      "step": 612180
    },
    {
      "epoch": 987.42,
      "learning_rate": 0.0012965503164516139,
      "loss": 0.4543,
      "step": 612200
    },
    {
      "epoch": 987.45,
      "learning_rate": 0.001293324513225808,
      "loss": 0.456,
      "step": 612220
    },
    {
      "epoch": 987.48,
      "learning_rate": 0.0012900987100000023,
      "loss": 0.4531,
      "step": 612240
    },
    {
      "epoch": 987.52,
      "learning_rate": 0.0012868729067741966,
      "loss": 0.4401,
      "step": 612260
    },
    {
      "epoch": 987.55,
      "learning_rate": 0.001283647103548391,
      "loss": 0.4577,
      "step": 612280
    },
    {
      "epoch": 987.58,
      "learning_rate": 0.001280421300322585,
      "loss": 0.4368,
      "step": 612300
    },
    {
      "epoch": 987.61,
      "learning_rate": 0.0012771954970967794,
      "loss": 0.4484,
      "step": 612320
    },
    {
      "epoch": 987.65,
      "learning_rate": 0.0012739696938709627,
      "loss": 0.4551,
      "step": 612340
    },
    {
      "epoch": 987.68,
      "learning_rate": 0.0012707438906451568,
      "loss": 0.453,
      "step": 612360
    },
    {
      "epoch": 987.71,
      "learning_rate": 0.001267518087419351,
      "loss": 0.4538,
      "step": 612380
    },
    {
      "epoch": 987.74,
      "learning_rate": 0.0012642922841935454,
      "loss": 0.4388,
      "step": 612400
    },
    {
      "epoch": 987.77,
      "learning_rate": 0.0012610664809677395,
      "loss": 0.4478,
      "step": 612420
    },
    {
      "epoch": 987.81,
      "learning_rate": 0.0012578406777419338,
      "loss": 0.4422,
      "step": 612440
    },
    {
      "epoch": 987.84,
      "learning_rate": 0.0012546148745161282,
      "loss": 0.4522,
      "step": 612460
    },
    {
      "epoch": 987.87,
      "learning_rate": 0.0012513890712903225,
      "loss": 0.4497,
      "step": 612480
    },
    {
      "epoch": 987.9,
      "learning_rate": 0.0012481632680645166,
      "loss": 0.4415,
      "step": 612500
    },
    {
      "epoch": 987.94,
      "learning_rate": 0.001244937464838711,
      "loss": 0.4498,
      "step": 612520
    },
    {
      "epoch": 987.97,
      "learning_rate": 0.0012417116616129052,
      "loss": 0.4296,
      "step": 612540
    },
    {
      "epoch": 988.0,
      "learning_rate": 0.0012384858583870994,
      "loss": 0.4477,
      "step": 612560
    },
    {
      "epoch": 988.0,
      "eval_accuracy": {
        "accuracy": 0.8011084224494575
      },
      "eval_loss": 0.8075258731842041,
      "eval_runtime": 3.2291,
      "eval_samples_per_second": 3967.375,
      "eval_steps_per_second": 62.247,
      "step": 612560
    },
    {
      "epoch": 988.03,
      "learning_rate": 0.0012352600551612937,
      "loss": 0.4437,
      "step": 612580
    },
    {
      "epoch": 988.06,
      "learning_rate": 0.001232034251935488,
      "loss": 0.4438,
      "step": 612600
    },
    {
      "epoch": 988.1,
      "learning_rate": 0.0012288084487096821,
      "loss": 0.4527,
      "step": 612620
    },
    {
      "epoch": 988.13,
      "learning_rate": 0.0012255826454838764,
      "loss": 0.4486,
      "step": 612640
    },
    {
      "epoch": 988.16,
      "learning_rate": 0.0012223568422580597,
      "loss": 0.4482,
      "step": 612660
    },
    {
      "epoch": 988.19,
      "learning_rate": 0.0012191310390322538,
      "loss": 0.4437,
      "step": 612680
    },
    {
      "epoch": 988.23,
      "learning_rate": 0.0012159052358064481,
      "loss": 0.441,
      "step": 612700
    },
    {
      "epoch": 988.26,
      "learning_rate": 0.0012126794325806425,
      "loss": 0.4509,
      "step": 612720
    },
    {
      "epoch": 988.29,
      "learning_rate": 0.0012094536293548368,
      "loss": 0.4496,
      "step": 612740
    },
    {
      "epoch": 988.32,
      "learning_rate": 0.0012062278261290309,
      "loss": 0.4505,
      "step": 612760
    },
    {
      "epoch": 988.35,
      "learning_rate": 0.0012030020229032252,
      "loss": 0.4505,
      "step": 612780
    },
    {
      "epoch": 988.39,
      "learning_rate": 0.0011997762196774195,
      "loss": 0.4459,
      "step": 612800
    },
    {
      "epoch": 988.42,
      "learning_rate": 0.0011965504164516136,
      "loss": 0.4479,
      "step": 612820
    },
    {
      "epoch": 988.45,
      "learning_rate": 0.001193324613225808,
      "loss": 0.4469,
      "step": 612840
    },
    {
      "epoch": 988.48,
      "learning_rate": 0.0011900988100000023,
      "loss": 0.4433,
      "step": 612860
    },
    {
      "epoch": 988.52,
      "learning_rate": 0.0011868730067741966,
      "loss": 0.4426,
      "step": 612880
    },
    {
      "epoch": 988.55,
      "learning_rate": 0.0011836472035483907,
      "loss": 0.4457,
      "step": 612900
    },
    {
      "epoch": 988.58,
      "learning_rate": 0.001180421400322585,
      "loss": 0.4507,
      "step": 612920
    },
    {
      "epoch": 988.61,
      "learning_rate": 0.0011771955970967794,
      "loss": 0.4477,
      "step": 612940
    },
    {
      "epoch": 988.65,
      "learning_rate": 0.0011739697938709624,
      "loss": 0.4482,
      "step": 612960
    },
    {
      "epoch": 988.68,
      "learning_rate": 0.0011707439906451567,
      "loss": 0.448,
      "step": 612980
    },
    {
      "epoch": 988.71,
      "learning_rate": 0.001167518187419351,
      "loss": 0.4442,
      "step": 613000
    },
    {
      "epoch": 988.74,
      "learning_rate": 0.0011642923841935452,
      "loss": 0.4389,
      "step": 613020
    },
    {
      "epoch": 988.77,
      "learning_rate": 0.0011610665809677395,
      "loss": 0.4383,
      "step": 613040
    },
    {
      "epoch": 988.81,
      "learning_rate": 0.0011578407777419338,
      "loss": 0.4458,
      "step": 613060
    },
    {
      "epoch": 988.84,
      "learning_rate": 0.001154614974516128,
      "loss": 0.4496,
      "step": 613080
    },
    {
      "epoch": 988.87,
      "learning_rate": 0.0011513891712903223,
      "loss": 0.4551,
      "step": 613100
    },
    {
      "epoch": 988.9,
      "learning_rate": 0.0011481633680645166,
      "loss": 0.4428,
      "step": 613120
    },
    {
      "epoch": 988.94,
      "learning_rate": 0.001144937564838711,
      "loss": 0.4472,
      "step": 613140
    },
    {
      "epoch": 988.97,
      "learning_rate": 0.001141711761612905,
      "loss": 0.4431,
      "step": 613160
    },
    {
      "epoch": 989.0,
      "learning_rate": 0.0011384859583870993,
      "loss": 0.4523,
      "step": 613180
    },
    {
      "epoch": 989.0,
      "eval_accuracy": {
        "accuracy": 0.8004839590976505
      },
      "eval_loss": 0.8069623708724976,
      "eval_runtime": 3.1528,
      "eval_samples_per_second": 4063.371,
      "eval_steps_per_second": 63.753,
      "step": 613180
    },
    {
      "epoch": 989.03,
      "learning_rate": 0.0011352601551612937,
      "loss": 0.4406,
      "step": 613200
    },
    {
      "epoch": 989.06,
      "learning_rate": 0.0011320343519354878,
      "loss": 0.4521,
      "step": 613220
    },
    {
      "epoch": 989.1,
      "learning_rate": 0.001128808548709682,
      "loss": 0.4509,
      "step": 613240
    },
    {
      "epoch": 989.13,
      "learning_rate": 0.0011255827454838764,
      "loss": 0.449,
      "step": 613260
    },
    {
      "epoch": 989.16,
      "learning_rate": 0.0011223569422580595,
      "loss": 0.444,
      "step": 613280
    },
    {
      "epoch": 989.19,
      "learning_rate": 0.0011191311390322538,
      "loss": 0.4495,
      "step": 613300
    },
    {
      "epoch": 989.23,
      "learning_rate": 0.0011159053358064481,
      "loss": 0.4412,
      "step": 613320
    },
    {
      "epoch": 989.26,
      "learning_rate": 0.0011126795325806422,
      "loss": 0.4445,
      "step": 613340
    },
    {
      "epoch": 989.29,
      "learning_rate": 0.0011094537293548366,
      "loss": 0.439,
      "step": 613360
    },
    {
      "epoch": 989.32,
      "learning_rate": 0.0011062279261290309,
      "loss": 0.4528,
      "step": 613380
    },
    {
      "epoch": 989.35,
      "learning_rate": 0.0011030021229032252,
      "loss": 0.4518,
      "step": 613400
    },
    {
      "epoch": 989.39,
      "learning_rate": 0.0010997763196774193,
      "loss": 0.443,
      "step": 613420
    },
    {
      "epoch": 989.42,
      "learning_rate": 0.0010965505164516136,
      "loss": 0.4432,
      "step": 613440
    },
    {
      "epoch": 989.45,
      "learning_rate": 0.001093324713225808,
      "loss": 0.4469,
      "step": 613460
    },
    {
      "epoch": 989.48,
      "learning_rate": 0.001090098910000002,
      "loss": 0.4448,
      "step": 613480
    },
    {
      "epoch": 989.52,
      "learning_rate": 0.0010868731067741964,
      "loss": 0.4425,
      "step": 613500
    },
    {
      "epoch": 989.55,
      "learning_rate": 0.0010836473035483907,
      "loss": 0.4456,
      "step": 613520
    },
    {
      "epoch": 989.58,
      "learning_rate": 0.001080421500322585,
      "loss": 0.4463,
      "step": 613540
    },
    {
      "epoch": 989.61,
      "learning_rate": 0.0010771956970967791,
      "loss": 0.4424,
      "step": 613560
    },
    {
      "epoch": 989.65,
      "learning_rate": 0.0010739698938709624,
      "loss": 0.4454,
      "step": 613580
    },
    {
      "epoch": 989.68,
      "learning_rate": 0.0010707440906451567,
      "loss": 0.4487,
      "step": 613600
    },
    {
      "epoch": 989.71,
      "learning_rate": 0.0010675182874193508,
      "loss": 0.4354,
      "step": 613620
    },
    {
      "epoch": 989.74,
      "learning_rate": 0.0010642924841935452,
      "loss": 0.4402,
      "step": 613640
    },
    {
      "epoch": 989.77,
      "learning_rate": 0.0010610666809677395,
      "loss": 0.4497,
      "step": 613660
    },
    {
      "epoch": 989.81,
      "learning_rate": 0.0010578408777419336,
      "loss": 0.44,
      "step": 613680
    },
    {
      "epoch": 989.84,
      "learning_rate": 0.001054615074516128,
      "loss": 0.4456,
      "step": 613700
    },
    {
      "epoch": 989.87,
      "learning_rate": 0.0010513892712903223,
      "loss": 0.4568,
      "step": 613720
    },
    {
      "epoch": 989.9,
      "learning_rate": 0.0010481634680645164,
      "loss": 0.4526,
      "step": 613740
    },
    {
      "epoch": 989.94,
      "learning_rate": 0.0010449376648387107,
      "loss": 0.4474,
      "step": 613760
    },
    {
      "epoch": 989.97,
      "learning_rate": 0.001041711861612905,
      "loss": 0.4497,
      "step": 613780
    },
    {
      "epoch": 990.0,
      "learning_rate": 0.0010386473485483846,
      "loss": 0.444,
      "step": 613800
    },
    {
      "epoch": 990.0,
      "eval_accuracy": {
        "accuracy": 0.8011864803684334
      },
      "eval_loss": 0.806786060333252,
      "eval_runtime": 4.188,
      "eval_samples_per_second": 3058.952,
      "eval_steps_per_second": 47.994,
      "step": 613800
    },
    {
      "epoch": 990.03,
      "learning_rate": 0.0010354215453225789,
      "loss": 0.4406,
      "step": 613820
    },
    {
      "epoch": 990.06,
      "learning_rate": 0.001032195742096773,
      "loss": 0.4447,
      "step": 613840
    },
    {
      "epoch": 990.1,
      "learning_rate": 0.0010289699388709673,
      "loss": 0.4467,
      "step": 613860
    },
    {
      "epoch": 990.13,
      "learning_rate": 0.0010257441356451616,
      "loss": 0.4474,
      "step": 613880
    },
    {
      "epoch": 990.16,
      "learning_rate": 0.0010225183324193558,
      "loss": 0.4448,
      "step": 613900
    },
    {
      "epoch": 990.19,
      "learning_rate": 0.00101929252919355,
      "loss": 0.4511,
      "step": 613920
    },
    {
      "epoch": 990.23,
      "learning_rate": 0.0010160667259677444,
      "loss": 0.4494,
      "step": 613940
    },
    {
      "epoch": 990.26,
      "learning_rate": 0.0010128409227419387,
      "loss": 0.4441,
      "step": 613960
    },
    {
      "epoch": 990.29,
      "learning_rate": 0.0010096151195161328,
      "loss": 0.4426,
      "step": 613980
    },
    {
      "epoch": 990.32,
      "learning_rate": 0.0010063893162903272,
      "loss": 0.4429,
      "step": 614000
    },
    {
      "epoch": 990.35,
      "learning_rate": 0.0010031635130645215,
      "loss": 0.4377,
      "step": 614020
    },
    {
      "epoch": 990.39,
      "learning_rate": 0.0009999377098387045,
      "loss": 0.4451,
      "step": 614040
    },
    {
      "epoch": 990.42,
      "learning_rate": 0.0009967119066128989,
      "loss": 0.4409,
      "step": 614060
    },
    {
      "epoch": 990.45,
      "learning_rate": 0.0009934861033870932,
      "loss": 0.4439,
      "step": 614080
    },
    {
      "epoch": 990.48,
      "learning_rate": 0.0009902603001612873,
      "loss": 0.4527,
      "step": 614100
    },
    {
      "epoch": 990.52,
      "learning_rate": 0.0009870344969354816,
      "loss": 0.4437,
      "step": 614120
    },
    {
      "epoch": 990.55,
      "learning_rate": 0.000983808693709676,
      "loss": 0.4499,
      "step": 614140
    },
    {
      "epoch": 990.58,
      "learning_rate": 0.00098058289048387,
      "loss": 0.4505,
      "step": 614160
    },
    {
      "epoch": 990.61,
      "learning_rate": 0.0009773570872580644,
      "loss": 0.449,
      "step": 614180
    },
    {
      "epoch": 990.65,
      "learning_rate": 0.0009741312840322587,
      "loss": 0.4563,
      "step": 614200
    },
    {
      "epoch": 990.68,
      "learning_rate": 0.0009709054808064527,
      "loss": 0.4461,
      "step": 614220
    },
    {
      "epoch": 990.71,
      "learning_rate": 0.0009676796775806471,
      "loss": 0.4505,
      "step": 614240
    },
    {
      "epoch": 990.74,
      "learning_rate": 0.0009644538743548413,
      "loss": 0.4453,
      "step": 614260
    },
    {
      "epoch": 990.77,
      "learning_rate": 0.0009612280711290356,
      "loss": 0.4398,
      "step": 614280
    },
    {
      "epoch": 990.81,
      "learning_rate": 0.0009580022679032299,
      "loss": 0.4431,
      "step": 614300
    },
    {
      "epoch": 990.84,
      "learning_rate": 0.0009547764646774241,
      "loss": 0.45,
      "step": 614320
    },
    {
      "epoch": 990.87,
      "learning_rate": 0.0009515506614516185,
      "loss": 0.4477,
      "step": 614340
    },
    {
      "epoch": 990.9,
      "learning_rate": 0.0009483248582258016,
      "loss": 0.4369,
      "step": 614360
    },
    {
      "epoch": 990.94,
      "learning_rate": 0.0009450990549999959,
      "loss": 0.441,
      "step": 614380
    },
    {
      "epoch": 990.97,
      "learning_rate": 0.0009418732517741901,
      "loss": 0.4458,
      "step": 614400
    },
    {
      "epoch": 991.0,
      "learning_rate": 0.0009386474485483843,
      "loss": 0.4422,
      "step": 614420
    },
    {
      "epoch": 991.0,
      "eval_accuracy": {
        "accuracy": 0.8010303645304816
      },
      "eval_loss": 0.8060840964317322,
      "eval_runtime": 3.875,
      "eval_samples_per_second": 3306.107,
      "eval_steps_per_second": 51.872,
      "step": 614420
    },
    {
      "epoch": 991.03,
      "learning_rate": 0.0009354216453225786,
      "loss": 0.4501,
      "step": 614440
    },
    {
      "epoch": 991.06,
      "learning_rate": 0.0009321958420967728,
      "loss": 0.4531,
      "step": 614460
    },
    {
      "epoch": 991.1,
      "learning_rate": 0.0009289700388709671,
      "loss": 0.4391,
      "step": 614480
    },
    {
      "epoch": 991.13,
      "learning_rate": 0.0009257442356451614,
      "loss": 0.4448,
      "step": 614500
    },
    {
      "epoch": 991.16,
      "learning_rate": 0.0009225184324193557,
      "loss": 0.4509,
      "step": 614520
    },
    {
      "epoch": 991.19,
      "learning_rate": 0.00091929262919355,
      "loss": 0.4455,
      "step": 614540
    },
    {
      "epoch": 991.23,
      "learning_rate": 0.0009160668259677442,
      "loss": 0.4415,
      "step": 614560
    },
    {
      "epoch": 991.26,
      "learning_rate": 0.0009128410227419384,
      "loss": 0.4402,
      "step": 614580
    },
    {
      "epoch": 991.29,
      "learning_rate": 0.0009096152195161326,
      "loss": 0.4419,
      "step": 614600
    },
    {
      "epoch": 991.32,
      "learning_rate": 0.0009063894162903269,
      "loss": 0.4454,
      "step": 614620
    },
    {
      "epoch": 991.35,
      "learning_rate": 0.0009031636130645213,
      "loss": 0.4445,
      "step": 614640
    },
    {
      "epoch": 991.39,
      "learning_rate": 0.0008999378098387044,
      "loss": 0.4443,
      "step": 614660
    },
    {
      "epoch": 991.42,
      "learning_rate": 0.0008967120066128986,
      "loss": 0.4459,
      "step": 614680
    },
    {
      "epoch": 991.45,
      "learning_rate": 0.000893486203387093,
      "loss": 0.4376,
      "step": 614700
    },
    {
      "epoch": 991.48,
      "learning_rate": 0.0008902604001612872,
      "loss": 0.4446,
      "step": 614720
    },
    {
      "epoch": 991.52,
      "learning_rate": 0.0008870345969354814,
      "loss": 0.4474,
      "step": 614740
    },
    {
      "epoch": 991.55,
      "learning_rate": 0.0008838087937096756,
      "loss": 0.4488,
      "step": 614760
    },
    {
      "epoch": 991.58,
      "learning_rate": 0.0008805829904838698,
      "loss": 0.4469,
      "step": 614780
    },
    {
      "epoch": 991.61,
      "learning_rate": 0.0008773571872580642,
      "loss": 0.4499,
      "step": 614800
    },
    {
      "epoch": 991.65,
      "learning_rate": 0.0008741313840322585,
      "loss": 0.4412,
      "step": 614820
    },
    {
      "epoch": 991.68,
      "learning_rate": 0.0008709055808064528,
      "loss": 0.4453,
      "step": 614840
    },
    {
      "epoch": 991.71,
      "learning_rate": 0.000867679777580647,
      "loss": 0.4452,
      "step": 614860
    },
    {
      "epoch": 991.74,
      "learning_rate": 0.0008644539743548412,
      "loss": 0.4462,
      "step": 614880
    },
    {
      "epoch": 991.77,
      "learning_rate": 0.0008612281711290354,
      "loss": 0.4443,
      "step": 614900
    },
    {
      "epoch": 991.81,
      "learning_rate": 0.0008580023679032297,
      "loss": 0.4383,
      "step": 614920
    },
    {
      "epoch": 991.84,
      "learning_rate": 0.0008547765646774241,
      "loss": 0.4443,
      "step": 614940
    },
    {
      "epoch": 991.87,
      "learning_rate": 0.0008515507614516183,
      "loss": 0.4378,
      "step": 614960
    },
    {
      "epoch": 991.9,
      "learning_rate": 0.0008483249582258015,
      "loss": 0.452,
      "step": 614980
    },
    {
      "epoch": 991.94,
      "learning_rate": 0.0008450991549999957,
      "loss": 0.4484,
      "step": 615000
    },
    {
      "epoch": 991.97,
      "learning_rate": 0.00084187335177419,
      "loss": 0.4419,
      "step": 615020
    },
    {
      "epoch": 992.0,
      "learning_rate": 0.0008386475485483842,
      "loss": 0.45,
      "step": 615040
    },
    {
      "epoch": 992.0,
      "eval_accuracy": {
        "accuracy": 0.802747638747951
      },
      "eval_loss": 0.8063517212867737,
      "eval_runtime": 3.3941,
      "eval_samples_per_second": 3774.441,
      "eval_steps_per_second": 59.22,
      "step": 615040
    },
    {
      "epoch": 992.03,
      "learning_rate": 0.0008354217453225786,
      "loss": 0.448,
      "step": 615060
    },
    {
      "epoch": 992.06,
      "learning_rate": 0.0008321959420967726,
      "loss": 0.4436,
      "step": 615080
    },
    {
      "epoch": 992.1,
      "learning_rate": 0.0008289701388709671,
      "loss": 0.4484,
      "step": 615100
    },
    {
      "epoch": 992.13,
      "learning_rate": 0.0008257443356451613,
      "loss": 0.4386,
      "step": 615120
    },
    {
      "epoch": 992.16,
      "learning_rate": 0.0008225185324193555,
      "loss": 0.4418,
      "step": 615140
    },
    {
      "epoch": 992.19,
      "learning_rate": 0.0008192927291935498,
      "loss": 0.4352,
      "step": 615160
    },
    {
      "epoch": 992.23,
      "learning_rate": 0.000816066925967744,
      "loss": 0.4452,
      "step": 615180
    },
    {
      "epoch": 992.26,
      "learning_rate": 0.0008128411227419385,
      "loss": 0.4446,
      "step": 615200
    },
    {
      "epoch": 992.29,
      "learning_rate": 0.0008096153195161325,
      "loss": 0.4466,
      "step": 615220
    },
    {
      "epoch": 992.32,
      "learning_rate": 0.0008063895162903269,
      "loss": 0.4483,
      "step": 615240
    },
    {
      "epoch": 992.35,
      "learning_rate": 0.0008031637130645211,
      "loss": 0.4449,
      "step": 615260
    },
    {
      "epoch": 992.39,
      "learning_rate": 0.0007999379098387043,
      "loss": 0.447,
      "step": 615280
    },
    {
      "epoch": 992.42,
      "learning_rate": 0.0007967121066128985,
      "loss": 0.4396,
      "step": 615300
    },
    {
      "epoch": 992.45,
      "learning_rate": 0.0007934863033870927,
      "loss": 0.4394,
      "step": 615320
    },
    {
      "epoch": 992.48,
      "learning_rate": 0.000790260500161287,
      "loss": 0.4451,
      "step": 615340
    },
    {
      "epoch": 992.52,
      "learning_rate": 0.0007870346969354814,
      "loss": 0.4565,
      "step": 615360
    },
    {
      "epoch": 992.55,
      "learning_rate": 0.0007838088937096757,
      "loss": 0.4479,
      "step": 615380
    },
    {
      "epoch": 992.58,
      "learning_rate": 0.0007805830904838698,
      "loss": 0.4415,
      "step": 615400
    },
    {
      "epoch": 992.61,
      "learning_rate": 0.0007773572872580641,
      "loss": 0.4432,
      "step": 615420
    },
    {
      "epoch": 992.65,
      "learning_rate": 0.0007741314840322583,
      "loss": 0.4421,
      "step": 615440
    },
    {
      "epoch": 992.68,
      "learning_rate": 0.0007709056808064527,
      "loss": 0.4404,
      "step": 615460
    },
    {
      "epoch": 992.71,
      "learning_rate": 0.0007676798775806469,
      "loss": 0.4443,
      "step": 615480
    },
    {
      "epoch": 992.74,
      "learning_rate": 0.0007644540743548412,
      "loss": 0.4428,
      "step": 615500
    },
    {
      "epoch": 992.77,
      "learning_rate": 0.0007612282711290354,
      "loss": 0.439,
      "step": 615520
    },
    {
      "epoch": 992.81,
      "learning_rate": 0.0007580024679032296,
      "loss": 0.451,
      "step": 615540
    },
    {
      "epoch": 992.84,
      "learning_rate": 0.000754776664677424,
      "loss": 0.4435,
      "step": 615560
    },
    {
      "epoch": 992.87,
      "learning_rate": 0.0007515508614516182,
      "loss": 0.4386,
      "step": 615580
    },
    {
      "epoch": 992.9,
      "learning_rate": 0.0007483250582258013,
      "loss": 0.4576,
      "step": 615600
    },
    {
      "epoch": 992.94,
      "learning_rate": 0.0007450992549999957,
      "loss": 0.4503,
      "step": 615620
    },
    {
      "epoch": 992.97,
      "learning_rate": 0.0007418734517741899,
      "loss": 0.4424,
      "step": 615640
    },
    {
      "epoch": 993.0,
      "learning_rate": 0.0007386476485483842,
      "loss": 0.4464,
      "step": 615660
    },
    {
      "epoch": 993.0,
      "eval_accuracy": {
        "accuracy": 0.8008742486925299
      },
      "eval_loss": 0.8040918707847595,
      "eval_runtime": 3.4637,
      "eval_samples_per_second": 3698.671,
      "eval_steps_per_second": 58.031,
      "step": 615660
    },
    {
      "epoch": 993.03,
      "learning_rate": 0.0007354218453225784,
      "loss": 0.4461,
      "step": 615680
    },
    {
      "epoch": 993.06,
      "learning_rate": 0.0007321960420967726,
      "loss": 0.4513,
      "step": 615700
    },
    {
      "epoch": 993.1,
      "learning_rate": 0.000728970238870967,
      "loss": 0.4388,
      "step": 615720
    },
    {
      "epoch": 993.13,
      "learning_rate": 0.0007257444356451612,
      "loss": 0.4449,
      "step": 615740
    },
    {
      "epoch": 993.16,
      "learning_rate": 0.0007225186324193555,
      "loss": 0.4422,
      "step": 615760
    },
    {
      "epoch": 993.19,
      "learning_rate": 0.0007192928291935497,
      "loss": 0.4398,
      "step": 615780
    },
    {
      "epoch": 993.23,
      "learning_rate": 0.000716067025967744,
      "loss": 0.4368,
      "step": 615800
    },
    {
      "epoch": 993.26,
      "learning_rate": 0.0007128412227419383,
      "loss": 0.4398,
      "step": 615820
    },
    {
      "epoch": 993.29,
      "learning_rate": 0.0007096154195161325,
      "loss": 0.4461,
      "step": 615840
    },
    {
      "epoch": 993.32,
      "learning_rate": 0.0007063896162903268,
      "loss": 0.4432,
      "step": 615860
    },
    {
      "epoch": 993.35,
      "learning_rate": 0.000703163813064521,
      "loss": 0.4429,
      "step": 615880
    },
    {
      "epoch": 993.39,
      "learning_rate": 0.0006999380098387042,
      "loss": 0.4468,
      "step": 615900
    },
    {
      "epoch": 993.42,
      "learning_rate": 0.0006967122066128985,
      "loss": 0.4309,
      "step": 615920
    },
    {
      "epoch": 993.45,
      "learning_rate": 0.0006934864033870927,
      "loss": 0.4377,
      "step": 615940
    },
    {
      "epoch": 993.48,
      "learning_rate": 0.0006902606001612869,
      "loss": 0.444,
      "step": 615960
    },
    {
      "epoch": 993.52,
      "learning_rate": 0.0006870347969354813,
      "loss": 0.4433,
      "step": 615980
    },
    {
      "epoch": 993.55,
      "learning_rate": 0.0006838089937096755,
      "loss": 0.4426,
      "step": 616000
    },
    {
      "epoch": 993.58,
      "learning_rate": 0.0006805831904838698,
      "loss": 0.453,
      "step": 616020
    },
    {
      "epoch": 993.61,
      "learning_rate": 0.000677357387258064,
      "loss": 0.4399,
      "step": 616040
    },
    {
      "epoch": 993.65,
      "learning_rate": 0.0006741315840322583,
      "loss": 0.4442,
      "step": 616060
    },
    {
      "epoch": 993.68,
      "learning_rate": 0.0006709057808064525,
      "loss": 0.4431,
      "step": 616080
    },
    {
      "epoch": 993.71,
      "learning_rate": 0.0006676799775806468,
      "loss": 0.4473,
      "step": 616100
    },
    {
      "epoch": 993.74,
      "learning_rate": 0.0006644541743548411,
      "loss": 0.4434,
      "step": 616120
    },
    {
      "epoch": 993.77,
      "learning_rate": 0.0006612283711290353,
      "loss": 0.4517,
      "step": 616140
    },
    {
      "epoch": 993.81,
      "learning_rate": 0.0006580025679032296,
      "loss": 0.4544,
      "step": 616160
    },
    {
      "epoch": 993.84,
      "learning_rate": 0.0006547767646774238,
      "loss": 0.4426,
      "step": 616180
    },
    {
      "epoch": 993.87,
      "learning_rate": 0.0006515509614516182,
      "loss": 0.4504,
      "step": 616200
    },
    {
      "epoch": 993.9,
      "learning_rate": 0.0006483251582258013,
      "loss": 0.4478,
      "step": 616220
    },
    {
      "epoch": 993.94,
      "learning_rate": 0.0006450993549999955,
      "loss": 0.4417,
      "step": 616240
    },
    {
      "epoch": 993.97,
      "learning_rate": 0.0006418735517741898,
      "loss": 0.4414,
      "step": 616260
    },
    {
      "epoch": 994.0,
      "learning_rate": 0.0006386477485483841,
      "loss": 0.4471,
      "step": 616280
    },
    {
      "epoch": 994.0,
      "eval_accuracy": {
        "accuracy": 0.8011864803684334
      },
      "eval_loss": 0.8040153384208679,
      "eval_runtime": 3.187,
      "eval_samples_per_second": 4019.758,
      "eval_steps_per_second": 63.069,
      "step": 616280
    },
    {
      "epoch": 994.03,
      "learning_rate": 0.0006354219453225783,
      "loss": 0.4408,
      "step": 616300
    },
    {
      "epoch": 994.06,
      "learning_rate": 0.0006321961420967726,
      "loss": 0.4421,
      "step": 616320
    },
    {
      "epoch": 994.1,
      "learning_rate": 0.0006289703388709668,
      "loss": 0.4457,
      "step": 616340
    },
    {
      "epoch": 994.13,
      "learning_rate": 0.0006257445356451612,
      "loss": 0.4394,
      "step": 616360
    },
    {
      "epoch": 994.16,
      "learning_rate": 0.0006225187324193554,
      "loss": 0.4345,
      "step": 616380
    },
    {
      "epoch": 994.19,
      "learning_rate": 0.0006192929291935496,
      "loss": 0.4456,
      "step": 616400
    },
    {
      "epoch": 994.23,
      "learning_rate": 0.0006160671259677439,
      "loss": 0.4504,
      "step": 616420
    },
    {
      "epoch": 994.26,
      "learning_rate": 0.0006128413227419381,
      "loss": 0.441,
      "step": 616440
    },
    {
      "epoch": 994.29,
      "learning_rate": 0.0006096155195161325,
      "loss": 0.4351,
      "step": 616460
    },
    {
      "epoch": 994.32,
      "learning_rate": 0.0006063897162903267,
      "loss": 0.4406,
      "step": 616480
    },
    {
      "epoch": 994.35,
      "learning_rate": 0.0006031639130645209,
      "loss": 0.4352,
      "step": 616500
    },
    {
      "epoch": 994.39,
      "learning_rate": 0.000599938109838704,
      "loss": 0.4467,
      "step": 616520
    },
    {
      "epoch": 994.42,
      "learning_rate": 0.0005967123066128984,
      "loss": 0.4519,
      "step": 616540
    },
    {
      "epoch": 994.45,
      "learning_rate": 0.0005934865033870926,
      "loss": 0.4516,
      "step": 616560
    },
    {
      "epoch": 994.48,
      "learning_rate": 0.0005902607001612869,
      "loss": 0.4476,
      "step": 616580
    },
    {
      "epoch": 994.52,
      "learning_rate": 0.0005870348969354811,
      "loss": 0.4435,
      "step": 616600
    },
    {
      "epoch": 994.55,
      "learning_rate": 0.0005838090937096755,
      "loss": 0.4453,
      "step": 616620
    },
    {
      "epoch": 994.58,
      "learning_rate": 0.0005805832904838697,
      "loss": 0.4485,
      "step": 616640
    },
    {
      "epoch": 994.61,
      "learning_rate": 0.0005773574872580639,
      "loss": 0.4445,
      "step": 616660
    },
    {
      "epoch": 994.65,
      "learning_rate": 0.0005741316840322582,
      "loss": 0.437,
      "step": 616680
    },
    {
      "epoch": 994.68,
      "learning_rate": 0.0005709058808064524,
      "loss": 0.441,
      "step": 616700
    },
    {
      "epoch": 994.71,
      "learning_rate": 0.0005676800775806468,
      "loss": 0.4497,
      "step": 616720
    },
    {
      "epoch": 994.74,
      "learning_rate": 0.000564454274354841,
      "loss": 0.4394,
      "step": 616740
    },
    {
      "epoch": 994.77,
      "learning_rate": 0.0005612284711290353,
      "loss": 0.4347,
      "step": 616760
    },
    {
      "epoch": 994.81,
      "learning_rate": 0.0005580026679032295,
      "loss": 0.4506,
      "step": 616780
    },
    {
      "epoch": 994.84,
      "learning_rate": 0.0005547768646774237,
      "loss": 0.4463,
      "step": 616800
    },
    {
      "epoch": 994.87,
      "learning_rate": 0.000551551061451618,
      "loss": 0.4392,
      "step": 616820
    },
    {
      "epoch": 994.9,
      "learning_rate": 0.0005483252582258012,
      "loss": 0.4461,
      "step": 616840
    },
    {
      "epoch": 994.94,
      "learning_rate": 0.0005450994549999954,
      "loss": 0.4391,
      "step": 616860
    },
    {
      "epoch": 994.97,
      "learning_rate": 0.0005418736517741897,
      "loss": 0.4451,
      "step": 616880
    },
    {
      "epoch": 995.0,
      "learning_rate": 0.000538647848548384,
      "loss": 0.4465,
      "step": 616900
    },
    {
      "epoch": 995.0,
      "eval_accuracy": {
        "accuracy": 0.8011084224494575
      },
      "eval_loss": 0.8043272495269775,
      "eval_runtime": 3.2321,
      "eval_samples_per_second": 3963.648,
      "eval_steps_per_second": 62.188,
      "step": 616900
    },
    {
      "epoch": 995.03,
      "learning_rate": 0.0005354220453225783,
      "loss": 0.4418,
      "step": 616920
    },
    {
      "epoch": 995.06,
      "learning_rate": 0.0005321962420967725,
      "loss": 0.444,
      "step": 616940
    },
    {
      "epoch": 995.1,
      "learning_rate": 0.0005289704388709667,
      "loss": 0.4461,
      "step": 616960
    },
    {
      "epoch": 995.13,
      "learning_rate": 0.000525744635645161,
      "loss": 0.4425,
      "step": 616980
    },
    {
      "epoch": 995.16,
      "learning_rate": 0.0005225188324193553,
      "loss": 0.4398,
      "step": 617000
    },
    {
      "epoch": 995.19,
      "learning_rate": 0.0005192930291935496,
      "loss": 0.4453,
      "step": 617020
    },
    {
      "epoch": 995.23,
      "learning_rate": 0.0005160672259677438,
      "loss": 0.4464,
      "step": 617040
    },
    {
      "epoch": 995.26,
      "learning_rate": 0.000512841422741938,
      "loss": 0.4379,
      "step": 617060
    },
    {
      "epoch": 995.29,
      "learning_rate": 0.0005096156195161323,
      "loss": 0.4439,
      "step": 617080
    },
    {
      "epoch": 995.32,
      "learning_rate": 0.0005063898162903266,
      "loss": 0.4472,
      "step": 617100
    },
    {
      "epoch": 995.35,
      "learning_rate": 0.0005031640130645209,
      "loss": 0.4508,
      "step": 617120
    },
    {
      "epoch": 995.39,
      "learning_rate": 0.0004999382098387151,
      "loss": 0.434,
      "step": 617140
    },
    {
      "epoch": 995.42,
      "learning_rate": 0.0004967124066128983,
      "loss": 0.4413,
      "step": 617160
    },
    {
      "epoch": 995.45,
      "learning_rate": 0.0004934866033870926,
      "loss": 0.4392,
      "step": 617180
    },
    {
      "epoch": 995.48,
      "learning_rate": 0.0004902608001612868,
      "loss": 0.4451,
      "step": 617200
    },
    {
      "epoch": 995.52,
      "learning_rate": 0.0004870349969354811,
      "loss": 0.4332,
      "step": 617220
    },
    {
      "epoch": 995.55,
      "learning_rate": 0.0004838091937096754,
      "loss": 0.4497,
      "step": 617240
    },
    {
      "epoch": 995.58,
      "learning_rate": 0.0004805833904838696,
      "loss": 0.4433,
      "step": 617260
    },
    {
      "epoch": 995.61,
      "learning_rate": 0.0004773575872580639,
      "loss": 0.4409,
      "step": 617280
    },
    {
      "epoch": 995.65,
      "learning_rate": 0.0004741317840322582,
      "loss": 0.4456,
      "step": 617300
    },
    {
      "epoch": 995.68,
      "learning_rate": 0.0004709059808064524,
      "loss": 0.4461,
      "step": 617320
    },
    {
      "epoch": 995.71,
      "learning_rate": 0.00046768017758064663,
      "loss": 0.4447,
      "step": 617340
    },
    {
      "epoch": 995.74,
      "learning_rate": 0.00046445437435484096,
      "loss": 0.4467,
      "step": 617360
    },
    {
      "epoch": 995.77,
      "learning_rate": 0.00046122857112903523,
      "loss": 0.4385,
      "step": 617380
    },
    {
      "epoch": 995.81,
      "learning_rate": 0.00045800276790322944,
      "loss": 0.4426,
      "step": 617400
    },
    {
      "epoch": 995.84,
      "learning_rate": 0.0004547769646774237,
      "loss": 0.4403,
      "step": 617420
    },
    {
      "epoch": 995.87,
      "learning_rate": 0.00045155116145161804,
      "loss": 0.4447,
      "step": 617440
    },
    {
      "epoch": 995.9,
      "learning_rate": 0.00044832535822580114,
      "loss": 0.442,
      "step": 617460
    },
    {
      "epoch": 995.94,
      "learning_rate": 0.0004450995549999954,
      "loss": 0.438,
      "step": 617480
    },
    {
      "epoch": 995.97,
      "learning_rate": 0.00044187375177418974,
      "loss": 0.4464,
      "step": 617500
    },
    {
      "epoch": 996.0,
      "learning_rate": 0.00043864794854838395,
      "loss": 0.4431,
      "step": 617520
    },
    {
      "epoch": 996.0,
      "eval_accuracy": {
        "accuracy": 0.8025134649910234
      },
      "eval_loss": 0.8044759035110474,
      "eval_runtime": 3.1929,
      "eval_samples_per_second": 4012.402,
      "eval_steps_per_second": 62.953,
      "step": 617520
    },
    {
      "epoch": 996.03,
      "learning_rate": 0.00043542214532257817,
      "loss": 0.4396,
      "step": 617540
    },
    {
      "epoch": 996.06,
      "learning_rate": 0.00043219634209677244,
      "loss": 0.45,
      "step": 617560
    },
    {
      "epoch": 996.1,
      "learning_rate": 0.00042897053887096666,
      "loss": 0.4329,
      "step": 617580
    },
    {
      "epoch": 996.13,
      "learning_rate": 0.000425744735645161,
      "loss": 0.4387,
      "step": 617600
    },
    {
      "epoch": 996.16,
      "learning_rate": 0.00042251893241935525,
      "loss": 0.4462,
      "step": 617620
    },
    {
      "epoch": 996.19,
      "learning_rate": 0.0004192931291935496,
      "loss": 0.439,
      "step": 617640
    },
    {
      "epoch": 996.23,
      "learning_rate": 0.0004160673259677438,
      "loss": 0.4468,
      "step": 617660
    },
    {
      "epoch": 996.26,
      "learning_rate": 0.000412841522741938,
      "loss": 0.4375,
      "step": 617680
    },
    {
      "epoch": 996.29,
      "learning_rate": 0.0004096157195161323,
      "loss": 0.4449,
      "step": 617700
    },
    {
      "epoch": 996.32,
      "learning_rate": 0.0004063899162903265,
      "loss": 0.4438,
      "step": 617720
    },
    {
      "epoch": 996.35,
      "learning_rate": 0.0004031641130645208,
      "loss": 0.4456,
      "step": 617740
    },
    {
      "epoch": 996.39,
      "learning_rate": 0.0003999383098387151,
      "loss": 0.4353,
      "step": 617760
    },
    {
      "epoch": 996.42,
      "learning_rate": 0.0003967125066128982,
      "loss": 0.4485,
      "step": 617780
    },
    {
      "epoch": 996.45,
      "learning_rate": 0.0003934867033870925,
      "loss": 0.4377,
      "step": 617800
    },
    {
      "epoch": 996.48,
      "learning_rate": 0.0003902609001612868,
      "loss": 0.4408,
      "step": 617820
    },
    {
      "epoch": 996.52,
      "learning_rate": 0.000387035096935481,
      "loss": 0.4437,
      "step": 617840
    },
    {
      "epoch": 996.55,
      "learning_rate": 0.00038380929370967527,
      "loss": 0.452,
      "step": 617860
    },
    {
      "epoch": 996.58,
      "learning_rate": 0.00038074478064516594,
      "loss": 0.4472,
      "step": 617880
    },
    {
      "epoch": 996.61,
      "learning_rate": 0.0003775189774193602,
      "loss": 0.4469,
      "step": 617900
    },
    {
      "epoch": 996.65,
      "learning_rate": 0.00037429317419354337,
      "loss": 0.4419,
      "step": 617920
    },
    {
      "epoch": 996.68,
      "learning_rate": 0.00037106737096773764,
      "loss": 0.4437,
      "step": 617940
    },
    {
      "epoch": 996.71,
      "learning_rate": 0.0003678415677419319,
      "loss": 0.4471,
      "step": 617960
    },
    {
      "epoch": 996.74,
      "learning_rate": 0.0003646157645161261,
      "loss": 0.4371,
      "step": 617980
    },
    {
      "epoch": 996.77,
      "learning_rate": 0.0003613899612903204,
      "loss": 0.443,
      "step": 618000
    },
    {
      "epoch": 996.81,
      "learning_rate": 0.00035816415806451466,
      "loss": 0.4446,
      "step": 618020
    },
    {
      "epoch": 996.84,
      "learning_rate": 0.00035493835483870893,
      "loss": 0.4335,
      "step": 618040
    },
    {
      "epoch": 996.87,
      "learning_rate": 0.0003517125516129032,
      "loss": 0.4444,
      "step": 618060
    },
    {
      "epoch": 996.9,
      "learning_rate": 0.0003484867483870975,
      "loss": 0.4441,
      "step": 618080
    },
    {
      "epoch": 996.94,
      "learning_rate": 0.0003452609451612917,
      "loss": 0.4392,
      "step": 618100
    },
    {
      "epoch": 996.97,
      "learning_rate": 0.00034203514193548596,
      "loss": 0.4385,
      "step": 618120
    },
    {
      "epoch": 997.0,
      "learning_rate": 0.00033880933870968023,
      "loss": 0.4415,
      "step": 618140
    },
    {
      "epoch": 997.0,
      "eval_accuracy": {
        "accuracy": 0.8022012333151198
      },
      "eval_loss": 0.8025311231613159,
      "eval_runtime": 3.7525,
      "eval_samples_per_second": 3413.949,
      "eval_steps_per_second": 53.564,
      "step": 618140
    },
    {
      "epoch": 997.03,
      "learning_rate": 0.0003355835354838745,
      "loss": 0.4367,
      "step": 618160
    },
    {
      "epoch": 997.06,
      "learning_rate": 0.00033235773225806877,
      "loss": 0.4339,
      "step": 618180
    },
    {
      "epoch": 997.1,
      "learning_rate": 0.00032913192903226304,
      "loss": 0.4459,
      "step": 618200
    },
    {
      "epoch": 997.13,
      "learning_rate": 0.0003259061258064462,
      "loss": 0.4444,
      "step": 618220
    },
    {
      "epoch": 997.16,
      "learning_rate": 0.00032268032258064047,
      "loss": 0.4475,
      "step": 618240
    },
    {
      "epoch": 997.19,
      "learning_rate": 0.0003194545193548347,
      "loss": 0.4431,
      "step": 618260
    },
    {
      "epoch": 997.23,
      "learning_rate": 0.00031622871612902896,
      "loss": 0.4503,
      "step": 618280
    },
    {
      "epoch": 997.26,
      "learning_rate": 0.0003130029129032232,
      "loss": 0.4424,
      "step": 618300
    },
    {
      "epoch": 997.29,
      "learning_rate": 0.0003097771096774175,
      "loss": 0.4377,
      "step": 618320
    },
    {
      "epoch": 997.32,
      "learning_rate": 0.00030655130645161177,
      "loss": 0.4439,
      "step": 618340
    },
    {
      "epoch": 997.35,
      "learning_rate": 0.00030332550322580604,
      "loss": 0.4434,
      "step": 618360
    },
    {
      "epoch": 997.39,
      "learning_rate": 0.00030009970000000025,
      "loss": 0.4385,
      "step": 618380
    },
    {
      "epoch": 997.42,
      "learning_rate": 0.0002968738967741945,
      "loss": 0.4349,
      "step": 618400
    },
    {
      "epoch": 997.45,
      "learning_rate": 0.0002936480935483888,
      "loss": 0.4373,
      "step": 618420
    },
    {
      "epoch": 997.48,
      "learning_rate": 0.00029042229032258306,
      "loss": 0.431,
      "step": 618440
    },
    {
      "epoch": 997.52,
      "learning_rate": 0.00028719648709677733,
      "loss": 0.4401,
      "step": 618460
    },
    {
      "epoch": 997.55,
      "learning_rate": 0.0002839706838709716,
      "loss": 0.4504,
      "step": 618480
    },
    {
      "epoch": 997.58,
      "learning_rate": 0.0002807448806451658,
      "loss": 0.4474,
      "step": 618500
    },
    {
      "epoch": 997.61,
      "learning_rate": 0.0002775190774193601,
      "loss": 0.4454,
      "step": 618520
    },
    {
      "epoch": 997.65,
      "learning_rate": 0.00027429327419354325,
      "loss": 0.4429,
      "step": 618540
    },
    {
      "epoch": 997.68,
      "learning_rate": 0.0002710674709677375,
      "loss": 0.4399,
      "step": 618560
    },
    {
      "epoch": 997.71,
      "learning_rate": 0.0002678416677419318,
      "loss": 0.4484,
      "step": 618580
    },
    {
      "epoch": 997.74,
      "learning_rate": 0.00026461586451612606,
      "loss": 0.441,
      "step": 618600
    },
    {
      "epoch": 997.77,
      "learning_rate": 0.00026139006129032033,
      "loss": 0.4441,
      "step": 618620
    },
    {
      "epoch": 997.81,
      "learning_rate": 0.0002581642580645146,
      "loss": 0.4374,
      "step": 618640
    },
    {
      "epoch": 997.84,
      "learning_rate": 0.0002549384548387088,
      "loss": 0.4373,
      "step": 618660
    },
    {
      "epoch": 997.87,
      "learning_rate": 0.0002517126516129031,
      "loss": 0.4435,
      "step": 618680
    },
    {
      "epoch": 997.9,
      "learning_rate": 0.00024848684838709736,
      "loss": 0.4444,
      "step": 618700
    },
    {
      "epoch": 997.94,
      "learning_rate": 0.0002452610451612916,
      "loss": 0.444,
      "step": 618720
    },
    {
      "epoch": 997.97,
      "learning_rate": 0.0002420352419354859,
      "loss": 0.4422,
      "step": 618740
    },
    {
      "epoch": 998.0,
      "learning_rate": 0.00023897072887096545,
      "loss": 0.44,
      "step": 618760
    },
    {
      "epoch": 998.0,
      "eval_accuracy": {
        "accuracy": 0.8025134649910234
      },
      "eval_loss": 0.8018662333488464,
      "eval_runtime": 3.2273,
      "eval_samples_per_second": 3969.616,
      "eval_steps_per_second": 62.282,
      "step": 618760
    },
    {
      "epoch": 998.03,
      "learning_rate": 0.00023574492564515967,
      "loss": 0.4411,
      "step": 618780
    },
    {
      "epoch": 998.06,
      "learning_rate": 0.00023251912241935397,
      "loss": 0.4402,
      "step": 618800
    },
    {
      "epoch": 998.1,
      "learning_rate": 0.00022929331919354824,
      "loss": 0.4397,
      "step": 618820
    },
    {
      "epoch": 998.13,
      "learning_rate": 0.00022606751596774248,
      "loss": 0.4353,
      "step": 618840
    },
    {
      "epoch": 998.16,
      "learning_rate": 0.00022284171274193675,
      "loss": 0.4405,
      "step": 618860
    },
    {
      "epoch": 998.19,
      "learning_rate": 0.000219615909516131,
      "loss": 0.4474,
      "step": 618880
    },
    {
      "epoch": 998.23,
      "learning_rate": 0.0002163901062903253,
      "loss": 0.4361,
      "step": 618900
    },
    {
      "epoch": 998.26,
      "learning_rate": 0.0002131643030645195,
      "loss": 0.4416,
      "step": 618920
    },
    {
      "epoch": 998.29,
      "learning_rate": 0.0002099384998387138,
      "loss": 0.4417,
      "step": 618940
    },
    {
      "epoch": 998.32,
      "learning_rate": 0.00020671269661290805,
      "loss": 0.433,
      "step": 618960
    },
    {
      "epoch": 998.35,
      "learning_rate": 0.00020348689338710232,
      "loss": 0.4446,
      "step": 618980
    },
    {
      "epoch": 998.39,
      "learning_rate": 0.00020026109016128545,
      "loss": 0.4419,
      "step": 619000
    },
    {
      "epoch": 998.42,
      "learning_rate": 0.00019703528693547974,
      "loss": 0.445,
      "step": 619020
    },
    {
      "epoch": 998.45,
      "learning_rate": 0.000193809483709674,
      "loss": 0.4472,
      "step": 619040
    },
    {
      "epoch": 998.48,
      "learning_rate": 0.00019058368048386826,
      "loss": 0.444,
      "step": 619060
    },
    {
      "epoch": 998.52,
      "learning_rate": 0.00018735787725806253,
      "loss": 0.4385,
      "step": 619080
    },
    {
      "epoch": 998.55,
      "learning_rate": 0.0001841320740322568,
      "loss": 0.437,
      "step": 619100
    },
    {
      "epoch": 998.58,
      "learning_rate": 0.00018090627080645104,
      "loss": 0.4464,
      "step": 619120
    },
    {
      "epoch": 998.61,
      "learning_rate": 0.0001776804675806453,
      "loss": 0.4387,
      "step": 619140
    },
    {
      "epoch": 998.65,
      "learning_rate": 0.00017445466435483958,
      "loss": 0.4397,
      "step": 619160
    },
    {
      "epoch": 998.68,
      "learning_rate": 0.00017122886112903382,
      "loss": 0.4395,
      "step": 619180
    },
    {
      "epoch": 998.71,
      "learning_rate": 0.0001680030579032281,
      "loss": 0.4411,
      "step": 619200
    },
    {
      "epoch": 998.74,
      "learning_rate": 0.00016477725467742236,
      "loss": 0.4463,
      "step": 619220
    },
    {
      "epoch": 998.77,
      "learning_rate": 0.0001615514514516166,
      "loss": 0.4409,
      "step": 619240
    },
    {
      "epoch": 998.81,
      "learning_rate": 0.00015832564822581088,
      "loss": 0.4437,
      "step": 619260
    },
    {
      "epoch": 998.84,
      "learning_rate": 0.00015509984500000515,
      "loss": 0.4496,
      "step": 619280
    },
    {
      "epoch": 998.87,
      "learning_rate": 0.0001518740417741883,
      "loss": 0.4423,
      "step": 619300
    },
    {
      "epoch": 998.9,
      "learning_rate": 0.00014864823854838255,
      "loss": 0.4274,
      "step": 619320
    },
    {
      "epoch": 998.94,
      "learning_rate": 0.00014542243532257682,
      "loss": 0.444,
      "step": 619340
    },
    {
      "epoch": 998.97,
      "learning_rate": 0.0001421966320967711,
      "loss": 0.4492,
      "step": 619360
    },
    {
      "epoch": 999.0,
      "learning_rate": 0.00013897082887096536,
      "loss": 0.4406,
      "step": 619380
    },
    {
      "epoch": 999.0,
      "eval_accuracy": {
        "accuracy": 0.8033721020997581
      },
      "eval_loss": 0.8013738393783569,
      "eval_runtime": 3.2654,
      "eval_samples_per_second": 3923.251,
      "eval_steps_per_second": 61.554,
      "step": 619380
    },
    {
      "epoch": 999.03,
      "learning_rate": 0.0001357450256451596,
      "loss": 0.4374,
      "step": 619400
    },
    {
      "epoch": 999.06,
      "learning_rate": 0.00013251922241935387,
      "loss": 0.4376,
      "step": 619420
    },
    {
      "epoch": 999.1,
      "learning_rate": 0.00012929341919354814,
      "loss": 0.4459,
      "step": 619440
    },
    {
      "epoch": 999.13,
      "learning_rate": 0.00012606761596774239,
      "loss": 0.443,
      "step": 619460
    },
    {
      "epoch": 999.16,
      "learning_rate": 0.00012284181274193666,
      "loss": 0.4385,
      "step": 619480
    },
    {
      "epoch": 999.19,
      "learning_rate": 0.00011961600951613091,
      "loss": 0.4442,
      "step": 619500
    },
    {
      "epoch": 999.23,
      "learning_rate": 0.00011639020629032517,
      "loss": 0.4404,
      "step": 619520
    },
    {
      "epoch": 999.26,
      "learning_rate": 0.00011316440306451944,
      "loss": 0.4359,
      "step": 619540
    },
    {
      "epoch": 999.29,
      "learning_rate": 0.0001099385998387137,
      "loss": 0.4401,
      "step": 619560
    },
    {
      "epoch": 999.32,
      "learning_rate": 0.00010671279661290798,
      "loss": 0.4387,
      "step": 619580
    },
    {
      "epoch": 999.35,
      "learning_rate": 0.00010348699338710221,
      "loss": 0.4388,
      "step": 619600
    },
    {
      "epoch": 999.39,
      "learning_rate": 0.00010026119016128537,
      "loss": 0.4393,
      "step": 619620
    },
    {
      "epoch": 999.42,
      "learning_rate": 9.703538693547965e-05,
      "loss": 0.4406,
      "step": 619640
    },
    {
      "epoch": 999.45,
      "learning_rate": 9.380958370967391e-05,
      "loss": 0.4433,
      "step": 619660
    },
    {
      "epoch": 999.48,
      "learning_rate": 9.058378048386816e-05,
      "loss": 0.4386,
      "step": 619680
    },
    {
      "epoch": 999.52,
      "learning_rate": 8.735797725806243e-05,
      "loss": 0.4393,
      "step": 619700
    },
    {
      "epoch": 999.55,
      "learning_rate": 8.413217403225669e-05,
      "loss": 0.4366,
      "step": 619720
    },
    {
      "epoch": 999.58,
      "learning_rate": 8.090637080645096e-05,
      "loss": 0.4385,
      "step": 619740
    },
    {
      "epoch": 999.61,
      "learning_rate": 7.768056758064522e-05,
      "loss": 0.4435,
      "step": 619760
    },
    {
      "epoch": 999.65,
      "learning_rate": 7.445476435483947e-05,
      "loss": 0.4516,
      "step": 619780
    },
    {
      "epoch": 999.68,
      "learning_rate": 7.122896112903375e-05,
      "loss": 0.4361,
      "step": 619800
    },
    {
      "epoch": 999.71,
      "learning_rate": 6.8003157903228e-05,
      "loss": 0.441,
      "step": 619820
    },
    {
      "epoch": 999.74,
      "learning_rate": 6.477735467742226e-05,
      "loss": 0.4443,
      "step": 619840
    },
    {
      "epoch": 999.77,
      "learning_rate": 6.155155145161653e-05,
      "loss": 0.4423,
      "step": 619860
    },
    {
      "epoch": 999.81,
      "learning_rate": 5.8325748225810785e-05,
      "loss": 0.4386,
      "step": 619880
    },
    {
      "epoch": 999.84,
      "learning_rate": 5.5099945000005056e-05,
      "loss": 0.4414,
      "step": 619900
    },
    {
      "epoch": 999.87,
      "learning_rate": 5.187414177418821e-05,
      "loss": 0.4401,
      "step": 619920
    },
    {
      "epoch": 999.9,
      "learning_rate": 4.864833854838247e-05,
      "loss": 0.4331,
      "step": 619940
    },
    {
      "epoch": 999.94,
      "learning_rate": 4.542253532257673e-05,
      "loss": 0.4483,
      "step": 619960
    },
    {
      "epoch": 999.97,
      "learning_rate": 4.2196732096770996e-05,
      "loss": 0.4466,
      "step": 619980
    },
    {
      "epoch": 1000.0,
      "learning_rate": 3.897092887096525e-05,
      "loss": 0.4439,
      "step": 620000
    },
    {
      "epoch": 1000.0,
      "eval_accuracy": {
        "accuracy": 0.8036062758566856
      },
      "eval_loss": 0.8012474775314331,
      "eval_runtime": 3.5125,
      "eval_samples_per_second": 3647.221,
      "eval_steps_per_second": 57.224,
      "step": 620000
    }
  ],
  "max_steps": 620000,
  "num_train_epochs": 1000,
  "total_flos": 0.0,
  "trial_name": null,
  "trial_params": null
}
